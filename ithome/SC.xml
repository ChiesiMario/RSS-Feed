<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>ithome - 简体中文</title>
    <link>https://www.ithome.com.tw/news/feeds</link>
    <atom:link href="http://127.0.0.1:30044/ithome/tw/feeds/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 20 Sep 2025 16:49:08 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>OpenMind 开源 AI 原生机器人系统 OM1 Beta</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0921-openmind-om1-github-960.jpg?itok=TLb_IGNU" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;机器人产业在近年硬体进步迅速，能行走、搬运、飞行的原型机接连出现，但 OpenMind 指出，软体仍是最大挑战，现有机器人大多被封闭于各自的生态系中，软体层的碎片化与相容性低阻碍了跨平台智慧的实现。OpenMind 推出&lt;a href="https://openmind.org/news/om1-beta"&gt;OM1 Beta&lt;/a&gt;，并称其为第一个人工智慧原生的开源机器人系统，试图建立一个统一的开发基础，让各类机器人都能在相同平台上具备感知、推理与行动能力。&lt;/p&gt;
&lt;p&gt;OM1 Beta 已公开于 GitHub，采 MIT 授权，支援多种硬体与模拟环境。系统核心强调硬体中立，能在四足、双足、人形与轮式等平台上运作，并以 Docker 映像档提供快速部署，跨 AMD64 与 ARM64 架构皆可使用。&lt;/p&gt;
&lt;p&gt;在功能层面，OM1 整合语言模型与语音、视觉能力，提供 OpenAI、Gemini、DeepSeek 与 xAI 等模型的介接，让机器人具备自然语言理解与情境推理。语音部分则支援 Google ASR 与 Nvidia Riva 的语音转文字，以及 Riva 与 ElevenLabs 的文字转语音功能，而影像与情绪分析进一步提升人机互动的自然性。系统预先配置了多款常见平台，包括 Unitree G1、Go2、TurtleBot 与 Ubtech 小型人形机器人，让开发者能快速上手。&lt;/p&gt;
&lt;p&gt;自主导航与环境理解是另一个重点，OM1 结合即时定位与地图建构（SLAM）、LiDAR 感测器与 Nav2 路径规画，让机器人能在复杂空间中自主移动。开发者可先透过 Gazebo 模拟环境测试行为，再将设定部署至实际硬体，减少实验成本与风险。此外，OM1 提供名为 OM1 Avatar 的前端介面，使用 React 打造，能即时呈现机器人的状态与虚拟头像，方便观察与互动。&lt;/p&gt;
&lt;p&gt;开源是这次 OpenMind 释出 OM1 Beta 的核心策略，该公司希望透过开放程式码，促进社群参与与知识共享，让开发者能在共通平台上扩充功能，而不是各自重新开发。如此有望缩短机器人软体的发展周期，并推动跨制造商的互通性。&lt;/p&gt;
&lt;p&gt;OpenMind 本身成立于美国，由学术界与产业界的成员组成，执行长 Jan Liphardt 曾任教于史丹佛大学，长期投入机器学习与人机协作领域。OpenMind 的目标是将智慧层抽象化为软体，让不同硬体之间能共用同一套逻辑与介面，虽然这样的尝试能否最终成为产业标准，仍要看生态系的采用情况，但对研究机构、新创与开发社群而言，OM1 提供了一个具体可用的起点。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171316</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171316</guid>
      <pubDate>Sun, 21 Sep 2025 16:00:00 GMT</pubDate>
      <author>李建兴</author>
      <category>新闻</category>
    </item>
    <item>
      <title>MongoDB 自托管环境现内建全文与向量搜寻功能</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/capture_237_-_supercharge_self-managed_apps_with_search_and_vector_search_capabilities_-_m_-_www.mongodb.com_.jpg?itok=WkrTtqfk" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;MongoDB 在自托管环境推出全文搜寻与向量搜寻的&lt;a href="https://www.mongodb.com/company/blog/product-release-announcements/supercharge-self-managed-apps-search-vector-search-capabilities?tck=pencil_banner"&gt;公开预览&lt;/a&gt;，适用于社群版（Community Edition）与企业版（Enterprise Server）。该更新让开发者不需再依赖外部搜寻引擎或独立向量资料库，就能在单一平台上完成关键字比对与语意搜寻，并在本地或企业资料中心快速测试人工智慧应用。功能透过搜寻专用程序 mongot 与主要伺服器程序 mongod 协同运作，目前仍属测试性质。&lt;/p&gt;
&lt;p&gt;MongoDB 将新能力纳入既有的聚合框架，支援$search、$searchMeta 与$vectorSearch 等查询阶段运算子当。开发者可直接使用熟悉的查询方式处理全文索引、模糊查询与自动完成，也能进行向量相似度比对，用于语意搜寻、推荐系统或 RAG 应用。当需求同时涉及关键字与语意条件时，也可采混合搜寻方式，将不同讯号整合后输出排序结果。&lt;/p&gt;
&lt;p&gt;这种整合式设计回应了自管环境长期存在的痛点，过去要在 MongoDB 上实作进阶搜寻功能，往往需要外挂诸如 Elasticsearch、OpenSearch 等外部搜寻引擎或向量资料库，而这些需求带来资料搬运、同步一致性与维运负担。MongoDB 将索引与查询留在同一平台内，能降低系统之间的同步落差，也简化了布建、升级与监控工作，对于快速更新的交易型或内容型服务，能减少结果延迟或不完整的风险。&lt;/p&gt;
&lt;p&gt;MongoDB 提供与 LangChain、LangGraph、LlamaIndex 等框架的原生整合相容性，使 RAG 或代理式功能能直接嵌入应用程式，并保有资料留在本地的弹性。对需要处理敏感资讯或在私有云、混合云环境运行的用户，这样的部署模式较容易符合治理与法遵要求。&lt;/p&gt;
&lt;p&gt;MongoDB 规画 Community Edition 正式版推出后，会在 SSPL 授权下免费提供，而 Enterprise Server 则会纳入新的订阅方案，收费细节待正式上市前公布。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171309</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171309</guid>
      <pubDate>Sun, 21 Sep 2025 16:00:00 GMT</pubDate>
      <author>李建兴</author>
      <category>新闻</category>
    </item>
    <item>
      <title>PyPI 参与供应链攻击 GhostAction 事件回应，注销遭滥用的凭证</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/_s1kwbl30oa.jpg?itok=_QL0Ghd6" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;9 月上旬资安业者 GitGuardian 揭露&lt;a href="https://www.ithome.com.tw/news/171071"&gt;大规模供应链攻击 GhostAction&lt;/a&gt;，骇客于 GitHub 储存库注入恶意工作流程，窃得 3,325 组帐密、凭证或金钥，现在这起事故处理的部分过程公开：PyPI 软体基金会透露他们也参与这起事故的回应，确认没有 PyPI 用户与专案受到波及。&amp;nbsp;&lt;/p&gt;
&lt;p&gt;9 月 16 日 PyPI 软体基金会（PSF）&lt;a href="https://blog.pypi.org/posts/2025-09-16-github-actions-token-exfiltration/"&gt;发布部落格文章指出&lt;/a&gt;，他们也参与这波攻击的事件回应活动，当时骇客将程式码植入 GitHub Actions 的工作流程，意图窃取 PyPI 发布用的凭证（Token），并传送到外部伺服器，他们广泛针对许多储存库下手，其中有许多开发者将 PyPI 凭证存放于 GitHub，攻击者窜改工作流程将凭证外传。虽然这些凭证确实遭到外流，但目前并未出现使用的迹象。对此，PyPI 已注销所有受到影响的凭证，并通知受影响的专案维护者。&lt;/p&gt;
&lt;p&gt;PyPI 得知并介入这起事故的原因，在于 9 月 5 日 GitGuardian 透过他们的通报恶意软体管道，向 PyPI 通报名为 FastUUID 专案遭骇，攻击者试图将 PyPI 凭证传送到远端伺服器。当时 PyPI 并未发现该专案的 PyPI 帐号遭骇，他们通知专案经营者，并协助保护帐号及专案的安全。&lt;/p&gt;
&lt;p&gt;后来 GitGuardian 透过电子邮件向 PyPI 资安团队通报新的调查结果，指出这实际上是大规模攻击的一部分，但相关通报讯息不幸被归类到垃圾信而延误时效，直到 PyPI 透过其他管道得知此事，并在垃圾邮件资料夹找到信件，于是 PyPI 再度清查用户受害情形，并发现新的入侵指标（IoC）。&lt;/p&gt;
&lt;p&gt;他们在清查并确认没有 PyPI 帐号外流后，于 9 月 15 日联系受影响专案的维护者，表示已将相关的凭证注销，并呼吁用户透过受信任的发布者（Trusted Publisher）机制来提升防护。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171312</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171312</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>周峻佑</author>
      <category>新闻</category>
    </item>
    <item>
      <title>高雄市如何用主权生成式 AI 升级城市智慧治理，靠 AI 辨识火灾、绕境等 108 种情境，要让市府应变决策快一步</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/_dsc4879_1.jpg?itok=Wz917oB8" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;主权 AI 不只是国家级 AI 发展趋势，对高雄市政府而言，更是其提升智慧城市治理的重要策略。高雄市去年 12 月宣布推动智慧高雄灯塔计划，与中华电信、鸿海、Nvidia、Linker Vision，以及中钢、中油、港务公司、台电等业者合作，高雄市要推动自己的城市级主权 AI，高雄市政府资讯处长刘俊杰在近期分享高雄市如何运用 AI 加强城市治理。&lt;/p&gt;
&lt;p&gt;近 2 年，高雄市政府在智慧城市发展上异军突起。去年先是与鸿海、Nvidia 合作，在高雄软体园区建置先进算力中心，以支援 AI 产品及应用的开发；去年 12 月高雄市政府与 Nvidia、中华电信等业者合作，启动智慧高雄灯塔计划。在今年 5 月国际电脑展，Nvidia 创办人黄仁勋直接点名高雄，称赞其为数位孪生城市，让高雄一时间站在 AI 城市治理锋头上。&lt;/p&gt;
&lt;p&gt;「过去高雄市向台北市、新北市、桃园市学习智慧城市的发展经验，而与 Nvidia 的合作，是高雄市政府在智慧城市发展上一次弯道超车的机会」，刘俊杰不讳言地说。&lt;/p&gt;
&lt;p&gt;他认为，主权 AI 有 2 个接地气的概念，第 1 个是适地性，由于各地方语言用语习惯不同，以庙会绕境为例，这是其他国家没有的活动，庙会绕境活动往往会产生噪音、影响当地交通路况，也是民众 1999 陈情反映的问题，因此高雄主权灯塔计划中特别辨识庙会绕境，利用街头监视器辨识到跷境活动，市府相关单位注意当地的噪音及交通路况问题。&lt;/p&gt;
&lt;p&gt;第 2 个概念是资料主权，刘俊杰认为，如同企业基于内部敏感资料、营业秘密，每家企业需要发展自己的主权 AI。「每个城市所面临的问题不同，也需要发展自己知识产权的 AI」，基于这样的原因，不能只仰赖公有云的 AI，城市也需要建立在地、适合自己文化的主权 AI。&lt;/p&gt;
&lt;p&gt;那么高雄市政府推动主权灯塔 AI 计划有何特别之处？&lt;/p&gt;
&lt;p&gt;刘俊杰指出，有别于 ChatGPT、Gemini 为个人使用，例如翻译、摘要、查找资讯、行程规画等等，高雄市的主权 AI 灯塔计划则是城市治理层级，利用影像辨识城市中发生的事件，第一时间快速应变。&lt;/p&gt;
&lt;p&gt;而从 AI 技术发展来看，过去以机器学习为基础的 AI 辨识技术，不同模型只能做单一一件事，例如专门辨识车牌的模型，专门计算车流或是淹水的模型，因应各种需求训练开发专用模型，而现在生成式 AI 能够让模型辨识多种情况，建立通用的模型。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;strong&gt;与厂商以联合开发模式推动&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;刘俊杰直言，灯塔计划在当时为全球第一个城市级主权 AI 案例，甚至没有国外标准可供市府采纳来进行验收，资讯处与法治局、主管采购的工务局研究，最后决定以联合开发模式进行计划，以类似捷运联合开发，由市府与企业共同投资，权利及义务共享的模式推动，分为 3 个方面。&lt;/p&gt;
&lt;p&gt;首先在算力资源方面，因为采用 Nvidia GB200 建置算力资源，GPU 相当昂贵，远非单一城市的财政能够负担，因此以联合开发模式，由企业负担扩展算力资源。&lt;/p&gt;
&lt;p&gt;其次是运用云端架构在 PaaS 层训练主权 AI 大脑的能力，刘俊杰表示，就像我们找到一位爱因斯坦，他的大脑很聪明、学习很快速，但是大脑中一片空白，透过 PaaS 训练 AI 大脑，利用 Nvidia retrain 后的商业模型，以高雄的在地情境进行微调（Fine tuning），训练它辨识庙会绕境活动。&lt;/p&gt;
&lt;p&gt;换言之，在 PaaS 层训练大脑，再由 SaaS 层发展各局处需要的应用，解决环保、交通、治安等问题，各局处既有系统需要改版，以与 PaaS 层的大脑对接。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/_DSC4903-600.jpg" style="width: 600px; height: 400px;" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
&lt;p&gt;刘俊杰指出，在联合开发模式之下，Linker 提供 Nvidia 的算力、机房等基础设施，还有 Nvidia 商业模型的授权，为满足主权 AI 发展的需求，主机及资料位于高雄的中华电信七贤机房，而 GPU 则在台南的中华电信机房，两个地理区域的机房之间采用全光纤网路连接。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;strong&gt;发展城市级 VLM 推论平台，可辨别 108 种情境&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;他认为，AI 在市政的运用并不是要取代人，而是辅助决策、提高效率，协助市府快速应对处理。为此，资讯处花费半年与交通局、环保局、工务局等 7 个局处讨论，确认他们需要 AI 协助解决什么问题，以及是否有足够的资料训练 AI 判断，既有的系统及应变程序如何调整。&lt;/p&gt;
&lt;p&gt;例如过去市府接到民众 1999 来电陈情道路出现坑洞，工务局再派人到现场勘察，再决定如何处理填补坑洞，一年可能收到与工务相关的陈情案件多达上万件，往往人力难以处理，未来透过 AI 从影像识别道路上的坑洞，自动识别坑洞大小，决定派工处理的优先顺序。另一个例子则是前面提到的庙会绕境，是否有足够的资料训练 AI 辨别庙会绕境活动。&lt;/p&gt;
&lt;p&gt;市府经过内部局处沟通，发展城市级的 VLM 推论平台，可辨识 108 种情境，609 个判断指标，例如发生火灾、淹水、庙会绕境活动、交通塞车都是一种情境，AI 根据影像建立 609 个判断指标，理论上，每种情境都能询问 AI 多达 609 个问题 (即指标)，但是如果询问与该情境不相关的问题，等于花费更多运算资源让 AI 去辨识指标，并不符合实际的需要。&lt;/p&gt;
&lt;p&gt;刘俊杰指出，关键在于要训练 AI 辨识什么样的情境，还有在这个情境之下，市府各单位想要进一步了解的问题是什么，但是辨识出的情境及指标为自然语言，虽然自然语言容易被人类理解，但并不能直接用于系统，因此将辨识的结果还会以指标或分级来分类，透过 API 与既有系统连接，也更容易设计系统该如何应对。因此 AI 在辨识后，会提供辨识结果的自然语言描敍供人类理解，也会提供问答，使系统容易处理。&lt;/p&gt;
&lt;p&gt;例如 AI 辨识一张街道上的影像，判断是否发生淹水或交通堵塞，依辨识的结果转给水利局、交通局，让局处进一步再询问 AI 相关问题。不只是市政府，灯塔计划也邀请台电、中钢、百货公司等业者加入，例如询问 AI 是否有电塔倒塌，进一步询问倒塌的情形。&lt;/p&gt;
&lt;p&gt;至于影像的来源，除了利用街道上的监视器，市府也会试办从公车或垃圾车的行车纪录器影像。「以前直到市民拨打 1999 陈情，市府才知道发生什么状况，未来只要车辆经过，市府就能马上处理，让市府化被动为主动」，未来还准备与计程车队合作，将 AI 的眼睛扩大到街道上行驶的计程车。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#B22222;"&gt;AI 结合数位孪生强化城市智慧治理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;高雄市政府计划利用 Nvidia 的 Omniverse 打造高雄市的数位孪生，目前先针对市区 80 平方公里的范围来建置数位孪生（下图，来源：高雄市政府），未来当发生事件时都会同步在数位孪生上呈现，市府各局处能够检视数位孪生外，事件也会传到各局处的系统，快速应变处理。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/%E6%93%B7%E5%8F%96-600(21).jpg" style="width: 600px; height: 347px;" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
&lt;p&gt;刘俊杰表示，未来 AI 会自动向各局处报告高雄市发生什么状况，透过道路上的 CMS 或是透过市民卡 App 通播讯息，让市民及早获得讯息应变准备。现在透过 VLM，只要取得即时的影像，就能及时知道发生的状况，例如 AI 侦测特定的路段发生交通堵塞，透过自动报告机制，向交通局资讯中心发送讯息，并且推播讯息给市民。&lt;/p&gt;
&lt;p&gt;未来不只是自动报告，高雄市政府也希望可发展至自动控制，当发生交通堵塞时，结合交通路口的 IoT，自动调整路口的红绿灯秒数，类似于 Agentic AI 的采取因应行动。&lt;/p&gt;
&lt;p&gt;不过，在训练 AI 辨识特殊的情境时，例如发生火灾的情境，需要先搜集到影像资料，但是这些极端案例的影像可能并不容易取得。&lt;/p&gt;
&lt;p&gt;刘俊杰指出，为突破原始资料不足的限制，可以运用 AI 生成极端案例，如不同时间、气候条件下发生的火灾影像，甚至是生成过去没有发生过的罕见极端案例，利用这些生成资料来训练 AI，教会它辨识情境后，再部署至实际运作环境。而 AI 未来透过高雄市数位孪生，也能模拟交通号志控制或是水闸门的启闭，模拟政策或自动控制的效益，再决定是否在实际世界施行。&lt;/p&gt;
&lt;p&gt;训练 AI 辨识情境及指标，不只应用在高雄市政府自己，同样参与灯塔计划的台电，也可运用空拍无人机巡检电塔，将空拍的影像画面送到灯塔计划的 AI 大脑，由 AI 判断电塔是否出现锈蚀的情形，以安排派工到现场检修。&lt;/p&gt;
&lt;p&gt;刘俊杰表示，除了政府、国营事业，市府也计划未来将灯塔计划扩大应用，目前已与医疗机构、企业、大学洽谈合作。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171310</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171310</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>苏文彬</author>
      <category>新闻</category>
    </item>
    <item>
      <title>Amazon 升级销售助理推代理式 AI，协助卖家自动化营运卖场</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/seller_assistant_.jpg?itok=geR_-Qit" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;Amazon&lt;a href="https://www.aboutamazon.com/news/innovation-at-amazon/seller-assistant-agentic-ai"&gt;宣布&lt;/a&gt;将销售助理（Seller Assistant）升级为新一代代理式人工智慧工具，让卖家能在授权下由人工智慧主动处理日常营运、法遵监控及成长策略。该功能以 Amazon Bedrock 为基础，并整合 Amazon Nova 与 Anthropic Claude 等基础模型，使辅助工具从单纯回应查询，进一步成为能推理、规画并执行任务的营运助手。&lt;/p&gt;
&lt;p&gt;Seller Assistant 过去主要提供卖家即时问答与资源引导。此次升级则将重点放在主动性与自动化，人工智慧现可持续监控帐户健康状态、分析市场需求，并在卖家确认后执行相关行动。Amazon 指出，这样的转型能协助独立卖家更专注于产品创新与客户经营，减少日常操作的时间成本。&lt;/p&gt;
&lt;p&gt;升级后的应用范畴涵盖多个层面，包括库存管理方面，Seller Assistant 能侦测滞销商品，提出降价、调整配送或移除的建议，并在旺季前依据历史与即时资料生成补货规画，降低缺货与囤货风险。帐户健康监控则可自动扫描潜在问题，例如商品描述触及法规限制或服务指标接近警戒，并附上原因说明与解决方案，必要时可在授权下直接完成修正。&lt;/p&gt;
&lt;p&gt;在法遵流程中，Seller Assistant 会于上架新商品时自动检查必要文件，例如电子产品需具备的 UL 认证，提示缺漏并引导卖家逐步补齐，有助于降低因规范不熟悉而延误上市的风险。广告功能也同步导入代理式人工智慧，Amazon Ads 的 Creative Studio 供卖家透过对话式操作快速产出影像与影音广告素材，并根据购物讯号提供广告构想，将制作时程由数周缩短为数小时。&lt;/p&gt;
&lt;p&gt;除了日常营运，Seller Assistant 还加入成长策略规画功能。系统能透过销售与顾客行为分析，建议新产品方向、最佳化行销方案，并针对季节性高峰与大型促销档期提前提出完整行动计划，涵盖促销设计、库存调整与广告布局。这些规画皆可由卖家检视后再决定是否执行，确保决策权仍掌握在使用者手中。目前 Seller Assistant 已在美国开放，计划在未来数月推向其他国家。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171308</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171308</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>李建兴</author>
      <category>新闻</category>
    </item>
    <item>
      <title>IBM 开源 Granite-Docling 小模型，2.58 亿参数高效处理复杂文件结构与表格</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/image_4.jpg?itok=CIcvbiGj" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;IBM 发布&lt;a href="https://www.ibm.com/new/announcements/granite-docling-end-to-end-document-conversion"&gt;Granite-Docling-258M&lt;/a&gt;小型模型，定位为端到端文件转换的视觉语言模型，&lt;a href="https://huggingface.co/ibm-granite/granite-docling-258M"&gt;采 Apache 2.0 授权开源并已上架 Hugging Face&lt;/a&gt;。官方强调这是一个针对文件转换而生的小型模型，参数量 2.58 亿，输出可完整保留版面、表格、数学式、清单与程式码区块等结构，适合后续以 RAG 建立可检索的资料资产。与传统直接转为 Markdown，容易与来源内容脱钩的 OCR 流程相比，Granite-Docling 的结构化输出更贴近原始文件，降低后处理不确定性。&lt;/p&gt;
&lt;p&gt;Granite-Docling 模型与 Docling 函式库是互补关系。Docling 提供可组合的文件转换软体层，能串接表格解析、数学式与程式码解析、ASR 与 OCR 等专用模型与 CLI 工具，方便随插即用地整合向量资料库与代理式工作流程。而 Granite-Docling 模型则可作为其中的单一 VLM 节点，一次完成影像到结构化输出，利用单一步骤转换减少多阶段工作管线的误差累积，同时保有以 Docling 进行错误处理与客制化的弹性。&lt;/p&gt;
&lt;p&gt;Granite-Docling 的核心是 DocTags，这是一套由 IBM Research 设计的通用文件结构标记语言，能精确描述页面元素的型别、座标、阅读顺序与跨元素关联，例如图与其说明的对应关系。由于 DocTags 将内容与版面结构明确分离，模型可先界定元素范围再执行 OCR，待完成转换后，DocTags 可直接转为 Markdown、JSON 或 HTML，或送入 Docling 函式库的处理流程。&lt;/p&gt;
&lt;p&gt;此次发表被视为今年 3 月 SmolDocling-256M-preview 的产品演进，新模型以 Granite3 为语言骨干并采用 SigLIP2 视觉编码器，延续先前方法论同时提升稳定性。过去预览版偶见在页面局部出现相同 Token 反复出现的情形，团队此次透过资料集过滤与标注清理降低不一致样本，目标是在大量文件处理情境中维持流程稳定而不被单点错误拖累。&lt;/p&gt;
&lt;p&gt;在语言能力方面，Granite-Docling 提供对阿拉伯文、中文与日文等的实验性支援，目前尚未标示为企业等级的稳定水准，后续将持续扩充语言覆盖与可靠性。IBM 也同步推进 docling-eval 评测套件与资料集策画，规画建立标准化排行榜，以利各类文件理解方案比较。&lt;/p&gt;
&lt;p&gt;IBM 计划发展更大参数等级的 Granite-Docling 模型版本，但会维持在 10 亿参数以下以兼顾速度与硬体弹性，并提升 DocTags 与 IBM watsonx.ai 模型的相容性，之后也会将 DocTags 语汇纳入 Granite 的分词器（Tokenizer）与训练配方。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171297</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171297</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>李建兴</author>
      <category>新闻</category>
    </item>
    <item>
      <title>物理 AI 发展潜力无穷，「具身 AI」资安强化将成为 IT 重大议题</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1252-cover-p2-960.jpg?itok=OraI-3hZ" width="960" height="420" alt="" title="资料来源：VicOne  Lab R7 提供，iThome 整理制表，2025 年 9 月" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;          &lt;p class="caption"&gt; 资料来源：VicOne  Lab R7 提供，iThome 整理制表，2025 年 9 月 &lt;/p&gt;
        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;台北市政府引进机器狗引发的讨论，不仅揭示了资安风险，也将大众目光引向机器人技术的深层变革。&lt;/p&gt;
&lt;p&gt;在过去，各界对机器人的印象，多半停留在工业生产线上的传统机器手臂，或依循预设路径巡逻的自动化载具。&lt;/p&gt;
&lt;p&gt;这些传统机器人主要仰赖「固定程式、路径规划、传感器规则」来运作，本质上是一种「自动化工具」。VicOne LAB R7 实验室负责人张裕敏表示，传统机器人能够精确地重复执行预设动作，例如搬运物品、跳舞，但一旦环境发生变化或遇到未知情境，便会显得笨拙且无能为力，因为它们缺乏真正的「理解」和「推理」能力。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;从传统机器自动化到具身 AI 机器人，相关产品技术发展大跃进&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;随著人工智慧，特别是大型语言模型（LLM）的飞速发展，机器人正经历一场智慧心灵的觉醒，转型为具备学习、理解与应变能力的「具身 AI 机器人」。&lt;/p&gt;
&lt;p&gt;张裕敏也定义了什么是「具身 AI（Embodied AI）」机器人，他指出，具身 AI 不单纯是存在于软体或云端的 AI（如 ChatGPT），而是「像人类具备五感」、「有身体」并能在物理世界中感知、行动、学习的人工智慧。&lt;/p&gt;
&lt;p&gt;他进一步解释，这些具身 AI 机器人的核心特征，包括：第一种就是感知（Perception）能力，可以透过多种感测器，如相机、麦克风、雷射雷达（LiDAR）、触觉感测器等，来理解周遭环境，模仿人类的眼、耳、鼻、舌、身、意；其次是具备行动（Action）能力，可以透过马达、手臂、腿或轮子等物理方式，与环境进行互动。&lt;/p&gt;
&lt;p&gt;第三种则是学习与适应（Learning &amp;amp; Adaptation）能力，与传统机器人只依赖预先编写的规则不同，具身 AI 机器人更能透过经验、强化学习或大模型推理，持续改进自身的行为与决策。&lt;/p&gt;
&lt;p&gt;最后则是语言与推理能力，因为新一代具身 AI 机器人的关键特色，就是能够理解人类的自然语言指令，并结合世界知识进行高阶决策。&lt;/p&gt;
&lt;p&gt;张裕敏进一步解释，「具身 AI」的定义，第一个层次是「外部模仿人类所有感知」；第二个层次则是「模仿人头脑中的各式推移」，这就体现了具身 AI 所具备的「理解（reasoning）」和「推论（inference）」能力。&lt;/p&gt;
&lt;p&gt;他举例说明，传统 AI（机器学习 ML）在辨识出「这是可乐」后，任务就结束了；但新型的具身 AI 机器人则会进一步「思考」：「你（人类）为什么要拿可乐给『我』（机器人）？」可能是因为你打不开，所以机器人会主动帮你打开；或者它会根据你拿东西的反应，判断你是在邀请它，便会把可乐拿起来并说谢谢。&lt;/p&gt;
&lt;p&gt;这种「具身 AI」机器人演绎了所谓的「视觉语言动作模型（VLA）」或「视觉语言模型（VLM）」。张裕敏强调，VLA 模型是大型语言模型（LLM）的下一步演进，让机器人不仅能看（Vision）、能听（可声控），还能模仿（Action）人类的动作。&lt;/p&gt;
&lt;p&gt;事实上，变聪明的具身 AI 机器人，已经能做许多传统机器人无法想像的事情。VicOne LAB R7 实验室研究员骆一奇表示，以往工厂的传统机器手臂，虽然效率高，但只要生产线稍有变动，就需耗费大量时间重新规画与设定。&lt;/p&gt;
&lt;p&gt;不过，他表示，搭载 VLA 模型的具身 AI 机器人，则能展现极高的弹性。它们可以自行学习，例如当一个生产线的料件不足时，它们能自动转移到另一个生产线协助；或者在现有任务完成后，根据需求转换任务。&lt;/p&gt;
&lt;p&gt;张裕敏则形容，这种具身 AI 机器人表现的就像是「资深厂长」、「资深研究员」甚至是「资深师傅」，能够当场进行各种测试与微调，甚至学习最佳的运作方式。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;物理 AI 的发展潜力无穷，应用的规模将大于纯云端 AI&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;辉达创办人、总裁暨执行长黄仁勋在 2024 年 Computex（台北国际电脑展）的主题演讲，提出物理 AI（Physical AI）概念，揭开 AI 机器人市场应用的新篇章。&lt;/p&gt;
&lt;p&gt;他说：「我们正在进入新的 AI 时代，不只是数位世界的 AI，而是能在物理世界里感知、推理，并且采取行动的物理 AI。」&lt;/p&gt;
&lt;p&gt;黄仁勋强调，Physical AI 会让工业革命进入全新阶段，AI 不只是提供建议，而是能直接影响现实世界，也会推动新一波制造业、自驾车、医疗、机器人的大革命，「规模甚至大于纯云端 AI。」他说。&lt;/p&gt;
&lt;p&gt;AI 不只在云端，也要走向物理世界，从处理文字、图片的「数位 AI（Digital AI）」，进化到能理解并操作现实世界的「物理 AI（Physical AI）」，它需要感测器（Sensors）加上即时推论（Real-time Inference）能力以及机器（Robotics/Automation）。&lt;/p&gt;
&lt;p&gt;因为 AI 必须与感测器结合，才具备「理解环境」的能力，感测器包括：相机、雷射雷达（LiDAR）、医疗影像、工厂感测器……等，都能输入 AI 模型；这些 AI 模型需要能做到「即时推理」，才能做出实际动作。&lt;/p&gt;
&lt;p&gt;若要更具体理解「物理 AI」概念，我们可以这么看：机器人对真实世界中的物理状况具备理解力，例如：机器手臂在抓取物品时，不会盲目地撞破桌子；看到电线，它会知道要从插头拔起，而不是硬扯断。张裕敏表示，具身 AI 机器人这种对物理世界的认知，是传统机器人难以企及的。&lt;/p&gt;
&lt;p&gt;另外，骆一奇也表示，辉达更是利用数位分身（Digital Twin）平台进行 AI 训练，让机器人在虚拟环境进行数百万次的模拟学习，大大提升了训练效率和模型精准度，减少物理训练所需的时间和成本；而外面的机器人业者更可以直接站在巨人（辉达）的肩膀上，运用其已经训练好的模型，训练自己的具身 AI 机器人或机器狗。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;具身 AI 与传统机器人的本质差异&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;虽然从外观上，我们很难一眼分辨一台机器手臂或机器狗是「传统」还是「具身 AI」，两者在核心设计与能力上却有著天壤之别。&lt;/p&gt;
&lt;p&gt;张裕敏点出，机器人与机器狗在「行动能力」存在差异，例如：两足人形机器人需要更复杂的平衡系统，具备举重能力及灵活手部关节，对人有较高的威吓性，甚至可以踢人或抱住人。&lt;/p&gt;
&lt;p&gt;至于四足机器狗则更容易平衡，以支撑为主，体型小巧、灵活，能钻入传统机器人难以到达的狭小空间进行瓦斯或水管检测，但通常不会咬人，短期内对人没有威吓性。&lt;/p&gt;
&lt;p&gt;然而，这些物理差异并非本质，张裕敏坦言：「真正的区别在于其『大脑』的智慧层次，以及赋予的『任务』不同，进而决定它们搭载的装备与能力。&lt;/p&gt;
&lt;p&gt;传统机器人就像是机械动作的「工具」，脑袋是「写死的程式」；具身 AI 机器人，则是会听懂、会判断、能学习的「智慧助手」，脑袋是「能理解语言、推理、学习的 AI。&lt;/p&gt;
&lt;p&gt;至于传统巡检狗，像是「自动巡逻车」，具身 AI 巡检狗则更像是「会理解你要什么」的智慧巡检助手。张裕敏表示，这场从「工具」到「智慧助手」的演变，将会彻底改变我们与机器互动的方式。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;各界对具身 AI 面临的资安风险认知不足，建立标准、实施检测有必要&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当具身 AI 机器人从工厂的封闭生产线，大步迈入公共场域与家庭，我们所面临的资安挑战，将不再仅限于网路窃取或网路攻击，而是可能直接威胁到物理世界的安全与人类的生命财产。&lt;/p&gt;
&lt;p&gt;张裕敏对于未来五年「具身 AI」机器人或机器狗的资安发展，提出警示：「这将是一个『战国时代』」。&lt;/p&gt;
&lt;p&gt;他强调，目前大众对机器人资安的认识仍显不足，台北市政府引进机器狗所引发的争议，恰好是一个绝佳的警醒：若不加以重视，三年后，当机器人已经更广泛应用时，我们恐将面临一场「大灾难」。&lt;/p&gt;
&lt;p&gt;他也进一步分析，具身 AI 的资安防护面临的核心安全困境。首先，对于软硬体结构缺乏深入了解，自然就难以意识到潜在的资安风险。&lt;/p&gt;
&lt;p&gt;他解释，如同我们不会知道一台机器人内部，包含作业系统（OS）、中介软体（middleware）、韧体（firmware）、嵌入式控制器（ECU/MCU）等复杂层次。但如果我们不了解这些底层架构，便无法真正找出其安全漏洞。&lt;/p&gt;
&lt;p&gt;其次，AI 机器人面临的资安问题，不仅包含传统 IT 产业、工业控制（OT）、物联网（IoT）的挑战，更加入 AI 模型这个快速演进的新变数。张裕敏指出，因为 AI 发展快速，使得攻击面广泛且快速演进、不断扩大，资安人员疲于奔命。&lt;/p&gt;
&lt;p&gt;第三，就是机器人业者对于「功能」与「威胁」，存在基本的认知差异。如同中国宇树科技机器狗的「远端遥控」功能，机器人厂商视为是产品的「必要功能」，这就与 IT 或资安业者对于远端遥控是资安风险的认知不同。&lt;/p&gt;
&lt;p&gt;「毕竟，远端关机功能，在机器人失控时，的确是确保安全的手段，但资安专家将其视为潜在的后门。」张裕敏指出，这种认知上的根本差异，是资安防护上的一大挑战。&lt;/p&gt;
&lt;p&gt;第四，有关于 VLA 和 VLM 模型的新变数。他表示，具身 AI 采用的 VLA 或 VLM 模型，因其结合了视觉、语言与动作，若外界给予机器人「口心不一」的指令，例如嘴巴说「放下」，使用者却做出「拿起」的动作时，就可能导致机器人学习到错误的行为，进而产生资料或行为冲突，甚至 AI 机器人可能因此被训练出「AI 后门」，亦即可以在「特定条件下」做出攻击行为。&lt;/p&gt;
&lt;p&gt;最后，其实也是全世界因应 AI 机器人逐渐成熟发展时，目前共同面临的困境，那就是：机器人资安法规与标准存在的巨大真空。&lt;/p&gt;
&lt;p&gt;张裕敏指出，现有的国际标准，例如：工业机器人的 ISO 10218-2、安全性标准 IEC 62443 或 AI 治理的 NIST CSF 2.0/AI RMF，都未能完全适用于「具身 AI」这种新型态的机器人。&lt;/p&gt;
&lt;p&gt;他认为，因为没有专门针对具身 AI 的法规或安全标准，也导致政府或企业在引进这类产品时，难以有明确的资安检核依据。厂商往往只能以最低的成本提供功能最好的产品，却无法在资安方面进行有效的验证。&lt;/p&gt;
&lt;p&gt;因此，随著这类具身 AI 机器人发展迅速且日趋成熟下，张裕敏也呼吁：「台湾应该要有机器人安全的标准或法案出来」。一旦有了法规，厂商便会主动符合，并会有一系列配套的稽核与验测机制，也能成为产业和政府在选择与部署 AI 机器人时的重要参考。&lt;/p&gt;
&lt;p&gt;他强调，即使是通过验测的产品仍有风险，但「有通过验测、虽然有风险，总比什么都没有好」，因为，标准至少是最低限度的资安要求，有助于防止骇客轻易入侵。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;具身 AI 机器人安全问题，已达必须正视的资安临界点&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;「具身 AI 机器人安全问题，已经达到资安临界点。」张裕敏表示，日前已发生数起震惊业界的事件，例如「中国一个机器人测试期间，机器人『集体罢工』」，甚至出现「机器人狠杀比亚迪工人」的惊悚案例。&lt;/p&gt;
&lt;p&gt;面对这些骇人听闻的事件，他认为，具身 AI 机器人面临的资安风险，不仅是单纯的技术故障，更预示著在「具身 AI」时代，机器人可能面临前所未有的资安挑战。&lt;/p&gt;
&lt;p&gt;当 AI 机器人的应用场景多元化，从工厂走入你我家中，应用于长照、陪伴、医疗、仓储运输等领域时，好处是，这个世界可能变得更安全，例如：巡检机器人能提升安全、降低犯罪率；但是，这也意味著资安问题将变得更加严重，因为机器人与人类生活的结合将更为紧密，任何漏洞都可能带来更大的实体和资安风险。&lt;/p&gt;
&lt;p&gt;张裕敏指出，中国解放军早在十年前就已开始使用机器人，无人机更是从 2003 年便开始发展。他表示，这些 AI 机器人可能改变战争模式，大幅提升作战效率，但这也为资安带来了更高的战略风险。&lt;/p&gt;
&lt;p&gt;以具身 AI 机器人的发展来看，张裕敏表示，虽然机器人使用的 VLA 或 VLM 的 AI 模型仍掌握在美国手中，但中国利用人口基数大、地域广阔的优势，进行大规模的实验与测试，甚至以真实城市作为实验场域，加上国家资金的无限制投入、鼓励技术窃取或收购，使其能「先偷出来、先做出来」，节省数十年发展的时间与数百亿的研发成本，快速抢占市场，让中国在机器人领域快速崛起并形成强大的竞争优势。&lt;/p&gt;
&lt;p&gt;张裕敏认为，台湾若想在 AI 机器人的资安领域有所突破，也必须要开放相关的产业场域，并大量投入机器人应用，因为，「当你有大量投入机器人应用时，相关的资安问题，才会显现出来。」他说道。&lt;/p&gt;
&lt;p&gt;不同于汽车产业从硬体走向「软体定义汽车（SDV）」，张裕敏指出，各种机器人从一开始，就是以「软体定义」的思维来设计，它们大量使用数位分身（Digital Twin）在虚拟场景中进行模拟训练，然后再将训练好的模型移植到实体硬体上。可以说，机器人是「原生即软体定义」的产物，这也使得其软体更新与功能迭代速度极快，对于资安防护也带来新的挑战。&lt;/p&gt;
&lt;p&gt;台北市政府引进巡检机器狗引发的资安争议，绝非单一事件，要如何从这样的事件中汲取教训，进而更有效率、更有自信地面对具身 AI 机器人的发展，是大家在迎接具身 AI 时代即将全面来临时，必须要面对的挑战缩影与预警。&lt;/p&gt;
&lt;p&gt;张裕敏强调，首先要做到资讯透明化，公开透明地揭露所引进高科技产品的来源、技术规格及潜在风险，让民众有知情权，共同监督。&lt;/p&gt;
&lt;p&gt;其次，台湾应尽速研拟并建立针对具身 AI 机器人，明确的安全标准与法规，不仅能为产品采购提供明确依据，更能促使厂商提升资安防护等级，确保技术应用安全可靠。&lt;/p&gt;
&lt;p&gt;第三，持续投入资源，深化对机器人软硬体、AI 模型（特别是 VLA/VLM）的资安研究，并进行实战化的攻防演练，提前发现并修补潜在漏洞。&lt;/p&gt;
&lt;p&gt;第四，也是张裕敏最在意的议题就是，对于机器人的产品采购与部署上，必须明确定义「主控权」的归属，以确保使用者能在必要时拥有最高层级的控制权，而非受制于原厂的远端遥控，避免「功能」与「威胁」认知差异带来的风险。&lt;/p&gt;
&lt;p class="rtecenter"&gt;&lt;a href="https://s4.itho.me/sites/default/files/files/1252-%E5%B0%81%E9%9D%A2-RAW-(170)-BIG.jpg" target="_blank"&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/1252-%E5%B0%81%E9%9D%A2-RAW-(90).png" style="width: 600px;" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.ithome.com.tw/article/171294" target="_blank"&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/1252-feng_mian_gu_shi_-p1-yan_fen_-open-960x420_kao_bei_0%5B1%5D.jpg" style="width: 600px;" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171293</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171293</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>黄彦棻</author>
      <category>新闻</category>
    </item>
    <item>
      <title>当机器人拥有自主思考能力──解析具身 AI 的资安临界点</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/1252-cover-p1-960.jpg?itok=dpubqtxl" width="960" height="420" alt="" title="VicOne 是全球专注于车用资安的业者，随著具身 AI 机器人和机器狗发展日趋成熟，VicOne 为了因应各种智慧移动装置所面临的资安议题，成立智慧移动载具专属的 VicOne LAB R7 实验室。图左为 VicOne LAB R7 实验室负责人张裕敏，图中为 VicOne LAB R7 实验室研究员徐士涵，图右为 VicOne LAB R7 实验室研究员骆一奇。（摄影／洪政伟）" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;          &lt;p class="caption"&gt; VicOne 是全球专注于车用资安的业者，随著具身 AI 机器人和机器狗发展日趋成熟，VicOne 为了因应各种智慧移动装置所面临的资安议题，成立智慧移动载具专属的 VicOne LAB R7 实验室。图左为 VicOne LAB R7 实验室负责人张裕敏，图中为 VicOne LAB R7 实验室研究员徐士涵，图右为 VicOne LAB R7 实验室研究员骆一奇。（摄影／洪政伟） &lt;/p&gt;
        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;近年来，人工智慧（AI）的浪潮席卷全球，其触角已从虚拟网路空间延伸至实体物理世界。当 AI 不再仅是无形的演算法，而是拥有「身体」，并能在现实中感知、行动、学习的机器人时，我们正迎来一个全新的「具身 AI」（Embodied AI）时代。&lt;/p&gt;
&lt;p&gt;这不仅仅是技术的革新，更是对社会、经济，乃至国家安全带来全新考验的转折点。台北市政府日前宣布引进中国宇树科技（Unitree Robotics）的巡检机器狗，原意为提升市政管理效率的创举，却不料激起层层资安疑云，这不仅仅是一桩采购案的争议，更是台湾社会乃至全球，在迎接具身 AI 浪潮时，必须正视的严峻挑战。&lt;/p&gt;
&lt;p&gt;我们该如何理解 AI 机器人的能力、应用需求，以及各种相关的安全性议题？针对各种智慧移动载具的资安威胁实验室 VicOne LAB R7，发表全球第一份《AI 机器人资安风险与防护白皮书》。&lt;/p&gt;
&lt;p&gt;《白皮书》当中强调：AI 机器人具备「感知、决策、行动」三大能力，一旦遭到入侵，后果不仅止于个资和隐私等资料外泄，还可能导致机器人误判行为，进而造成人身安全的危害。&lt;/p&gt;
&lt;p&gt;根据《白皮书》所揭露的内容，随著左右机器人「脑袋」是否能够变得越来越聪明的 AI 模型：大型语言模型（LLM）与视觉语言模型（VLM）日趋成熟，AI 机器人或机器狗等智慧移动载具，将会从传统的工厂或商店中，进一步走进家庭、物流、医疗照护，以及公共服务等更贴近日常生活的场域中。&lt;/p&gt;
&lt;p&gt;而且，人类会疲累、需要休息，机器人可以 24 小时不间断地工作，且不会抱怨。VicOne LAB R7 实验室负责人张裕敏也引用报告指出，企业或工厂初期导入，便可节省三分之一的成本，长期下来，一个机器人甚至可能取代上百名工人；更先进的机器人，甚至能像人肚子饿要吃东西一样，在电力不足时，自行前往充电站更换电池，完全实现「无人工厂」的愿景。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;人们担忧 AI 巡检机器狗可能成为特洛伊木马，引爆资安危机&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;台湾民众最近对于 AI 机器人的关注急速升温！故事的开端，源于台北市副市长李四川在社群媒体脸书（FB）的一则贴文。他骄傲地向台北市民介绍，北市府新工处宣布引进「智能机器狗」巡视人行道，这些机器狗搭载了先进的光学全景调查系统，能够精准定位各项设施，搜集环境影像、定位缺失，自动通报缺失，可以 360 度建模，协助建立数位化资料库，大幅提升巡检效率。李四川更在脸书赞许：「这台 AI 巡检机器狗是智慧城市进步的象征。」&lt;/p&gt;
&lt;p&gt;不过，台北市政府预告将引进这台机器狗后，并未带来好评，反而导致许多资安疑虑。&lt;/p&gt;
&lt;p class="rtecenter"&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/%E5%AE%87%E6%A8%B9%E6%A9%9F%E5%99%A8%E7%8B%97_%E5%9C%96%E7%89%87%E4%BE%86%E6%BA%90-%E6%9D%8E%E5%9B%9B%E5%B7%9D.jpg" style="width: 600px;" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#3366ff;"&gt;台北市政府副市长李四川在他个人的脸书页面宣布，市府将引进机器狗进行人行道巡检、提高施政效率，但由于该机器狗为中国宇树科技的产品，引发外界对此产生许多资安疑虑。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;民进党台北市议员简舒培首先发难，直指该批巡检机器狗是由中国机器人大厂宇树科技制造，更形容称该批机器狗为「带摄像头的特洛伊木马」。&lt;/p&gt;
&lt;p&gt;而且，美国国会早在今年 5 月，就曾经对于宇树科技表达资安疑虑，主要原因在于其机器人可能预装后门程式，并将敏感资料传输至中国境内伺服器，构成国安隐忧。&lt;/p&gt;
&lt;p&gt;具体证据就是：Andreas Makris 与 Kevin Finisterre 这两位资安研究员曾揭露，宇树 Go1 机器狗确实预装了后门程式，可透过公开的 Web API 启用；任何取得该接口的人，不仅能查看 Go1 的位置，若装置连线，甚至可以直接观看其摄影机的即时影像，透过预设帐号密码便能取得完整的控制权。这类资安漏洞，无疑是国家安全的巨大潜在威胁。&lt;/p&gt;
&lt;p&gt;面对各界排山倒海而来的质疑声浪，台北市政府工务局新建工程处（新工处）紧急出面说明。他们指出，目前全台北市仅引进一台巡查机器狗，造价约新台币 70 万元，尚处于研发试办阶段，会优先厘清资安问题，目前人行道普查工作仍以人力为主。&lt;/p&gt;
&lt;p&gt;新工处进一步解释，该机器狗由「核心设备」与「移动平台」两部分组成：「核心设备」的软体开发、环景系统与网路传输功能，皆由台湾团队自主研发完成，并已投入约 600 万元，后续还将投入 1,000 万元研发整合语音辨识系统。&lt;/p&gt;
&lt;p&gt;而「移动平台」则采购自宇树科技，仅作为台制核心设备的「载体组件」，提供行走功能，并无连网，也无法启用定位系统，因此不涉及核心技术与资料传输。李四川也强调，这台机器狗并非市府购买，若资安疑虑属实，市府绝不允许厂商使用。&lt;/p&gt;
&lt;p&gt;对此，数位发展部（数发部）部长林宜敬表示，依照现行规定，各级政府机关若欲使用中国大陆厂牌的资通产品，须经机关及上级机关的资安长核准，并函报数发部同意才能使用，不过，数发部之前并未收到台北市政府的申请。&lt;/p&gt;
&lt;p&gt;林宜敬提醒，这类 AI 机器狗的高科技产品相当复杂，而且通常会连接网路，即使当下检测的结果显示安全性无虞，但未来仍可能透过远端网路连线存取，或者自动软体更新等方式，更改位于产品内部的操作软体。他表示，各种境外势力都可能借由远端操控 AI 机器人或机器狗，因此，有意引进的机关或县市政府，都必须特别谨慎。&lt;/p&gt;
&lt;p&gt;看完上述各方的说明，相信大家对 AI 机器人与机器狗，还是有许多疑问，那么，专业资安厂商怎么看待这个议题？&lt;/p&gt;
&lt;p&gt;VicOne 是出身台湾、全球专注于车用资安的资安业者，由于「汽车产业发展的尽头是机器人」，因此，VicOne 也针对包括 AI 机器人和或机器狗等各种智慧移动装置所面临的资安议题，成立一个专属的 VicOne LAB R7 实验室。&lt;/p&gt;
&lt;p&gt;VicOne LAB R7 实验室负责人张裕敏表示，宇树科技的机器狗在全球市场上，因其相对亲民的价格，已成为许多国家巡逻用途的选择，例如西班牙、新加坡，甚至预计 2028 年美国奥运也将采用机器狗巡逻。&lt;/p&gt;
&lt;p&gt;张裕敏坦言，和一般 IT 资安业者最大的差别在于，机器人厂商往往将「远端遥控」视为产品的「功能」而非资安漏洞。他提及过往的「CloudSail」事件当中，即有资安研究员发现宇树所有机器人都能被云端控制，但厂商回应「这是设计中的功能」。&lt;/p&gt;
&lt;p&gt;「认知上的根本差异，正是 AI 机器人在资安防护上的最大盲点。」张裕敏表示，机器人厂商认为「远端关机」是为应对紧急状况，例如机器人失控攻击人类时，可透过远端指令「立即停机」以确保安全；但资安专家则认为，这类远端控制通道若未经严格安全审查与权限控管，便可能成为骇客入侵的后门。&lt;/p&gt;
&lt;p&gt;张裕敏进一步解释，机器人厂商多半支援「二次开发」，允许使用者加装软体或更换部分功能；然而，这类在机器人平台上进行各种功能开发或加值的业者，通常只能获得「开发者权限」，而非最高层级的「Root 权限」。&lt;/p&gt;
&lt;p&gt;他说，即使是开发者权限，若能安装任意程式，仍潜藏资安风险；更深层次的资安疑虑在于，移动平台的韧体（firmware）和嵌入式控制器（ECU/MCU）层面，这些底层的程式码是否也存在隐藏的后门或漏洞，且能否由买方自行更新或修补，都成为核心问题。&lt;/p&gt;
&lt;p&gt;倘若机器人厂商能够远端更新 ECU 上的韧体，就等于掌握了机器人从头到脚的控制权，这对资讯安全而言，则是极为关键的控制点。&lt;/p&gt;
&lt;p&gt;&lt;span style="color:#B22222;"&gt;&lt;span style="font-size:28px;"&gt;&lt;strong&gt;全球第一份 AI 机器人资安白皮书出炉，帮助大家更了解这项议题&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;台北市政府引进巡检机器狗的事件，不仅揭示单一采购案引发的资安疑虑，更广泛地触动各界，思考人工智慧与实体物理世界结合后，所将面临的全新资安挑战。&lt;/p&gt;
&lt;p&gt;机器人的发展，在许多方面被视为汽车工业的自然延伸，张裕敏直言，「机器人是汽车工业的延伸。」所以全球车用资安业者 VicOne，也透过其内部针对包括机器人机器狗在内的各种智慧移动载具的资安实验室 VicOne LAB R7，于日前首度公开 VicOne LAB R7 的研究成果，并发表全球第一份《AI 机器人资安风险与防护白皮书》。&lt;/p&gt;
&lt;p&gt;VicOne LAB R7 强调，AI 机器人具备「感知、决策、行动」三大能力，一旦遭到入侵，后果不仅止于个资和隐私等资料外泄，还可能导致机器人误判行为，甚至造成人身安全危害。&lt;/p&gt;
&lt;p&gt;透过这份《白皮书》的发表，不仅是机器人产业资安研究的一大里程碑，对于全球决策者和开发者，在享受 AI 创新便利的同时，也必须正视背后隐藏的各种资安威胁与挑战。&lt;/p&gt;
&lt;p&gt;白皮书指出，机器人发展的核心关键，在于其「脑袋」的智慧程度。随著大型语言模型（LLM）与视觉语言模型（VLM）日渐成熟，AI 机器人已能执行更复杂的任务，其应用场景已不再局限于工厂或商场的辅助角色，而是开始深入家庭、医疗照护、物流及公共服务等日常领域。&lt;/p&gt;
&lt;p&gt;然而，当机器人与人类的「距离」越发靠近、关系日益紧密，其潜在攻击面也随之扩大。若缺乏完善的资安防护设计，不仅可能造成隐私外泄，更会引发人身安全风险，甚至上升至国安层级。&lt;/p&gt;
&lt;p&gt;VicOne 的《白皮书》揭示了 AI 机器人的五大攻击面向，包含：物理实体、感知器、AI 模型、无线通讯，以及软体／云端应用。这些攻击面向结合实务案例进行分析，特别针对 AI 模型的独有攻击模式和机器人特有风险进行深入探讨。&lt;/p&gt;
&lt;p&gt;此外，《白皮书》亦全面剖析了机器人供应链的安全，从底层硬体与韧体，到高阶 AI 模型，再到云端部署与更新，揭示了供应链环节庞大且复杂的安全挑战。同时，报告中也针对机器人行为提供了系统化的安全测试与验证方法。&lt;/p&gt;
&lt;p&gt;针对新兴的多模态大型模型（VLM/VLA）所带来的新攻击向量、机器人自适应扩增技能下载机制的潜在安全隐忧，以及 AI 驱动的攻击手法演进，VicOne 的《白皮书》则为企业与研究团队提供了前瞻性的防护策略。&lt;/p&gt;
&lt;p&gt;张裕敏表示，随著 AI 驱动的机器人展现出的高度智慧与自主性，其所面临的资安挑战也日益复杂。因此，企业必须从源头强化供应链安全，确保 AI 模型完整性，并透过行为监控与测试验证来提升系统韧性。「唯有如此，AI 机器人才能在持续带来创新价值的同时，保障运行安全无虞。」他说。&lt;/p&gt;
&lt;p&gt;研究发现，虽然 AI 技术与车辆资安发展轨迹相似，但两者的资安重叠性仅达 65％至 70％，显示 AI 机器人所面临的资安风险更加难以防范。&lt;/p&gt;
&lt;p&gt;随著 AI 驱动机器人具备高度智慧与自主性，并能在多元场域与人类互动，VicOne LAB R7 呼吁其安全性不再是附加选项，应该是产品设计的核心要求。&lt;/p&gt;
&lt;p&gt;当机器人从单纯的工业机械转变为具备高度智慧的「具身 AI」时，其安全风险也随之达到了前所未有的层级。张裕敏所言：「机器人安全问题已经达到资安临界点」，绝非危言耸听。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.ithome.com.tw/article/171294" target="_blank"&gt;&lt;img alt="" src="https://s4.itho.me/sites/default/files/images/1252-feng_mian_gu_shi_-p1-yan_fen_-open-960x420_kao_bei_0%5B1%5D.jpg" style="width: 600px;" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171292</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171292</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>黄彦棻</author>
      <category>新闻</category>
    </item>
    <item>
      <title>GitHub 推出 MCP Registry，集中收录 AI 代理相容伺服器</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/mcp2.jpg?itok=NlwCdKAa" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;GitHub&lt;a href="https://github.blog/ai-and-ml/github-copilot/meet-the-github-mcp-registry-the-fastest-way-to-discover-mcp-servers/"&gt;推出&lt;/a&gt;MCP 注册库（MCP Registry），作为集中收录 MCP（Model Context Protocol）伺服器的入口，目标是解决开发者在分散环境中探索与安装的困境。这项服务由 GitHub 主导并与社群协作，提供官方汇整清单，让开发者能更快找到并评估合适的伺服器。&lt;/p&gt;
&lt;p&gt;MCP 提供人工智慧代理与工具之间的沟通方式，让代理能撷取新的执行脉络、与外部资源互动，并整合至既有系统，也就是说，开发者可透过安装相容的 MCP 伺服器来扩展代理能力，并在支援 MCP 的主机上以标准化协定完成整合。&lt;/p&gt;
&lt;p&gt;目前 MCP 伺服器散落于不同的储存库与社群贴文，缺乏统一的入口，使用者必须投入额外时间搜寻，伺服器作者则需反复发布与回答相同的设定问题。GitHub 认为这种破碎环境不仅增加探索成本，也潜藏安全风险，而 MCP Registry 透过集中清单和标准化流程，提供更透明的存取方式，协助开发者快速了解伺服器用途与安装步骤。&lt;/p&gt;
&lt;p&gt;MCP Registry 与 VS Code 整合，支援一键安装，并依据 GitHub 星标数与社群活跃度排序，让高品质专案更容易被找到。清单中的每个伺服器都连结至 GitHub 储存库，开发者能直接查看技术细节与维护状态。MCP Registry 支援任何相容 MCP 的主机，降低工具链导入门槛。&lt;/p&gt;
&lt;p&gt;首批合作包含 Figma、Postman、HashiCorp 与 Dynatrace 等厂商，另有 Remote GitHub MCP Server 正式纳入，让代理可直接存取储存库、Issue 与拉取请求等资讯，支援更复杂的代理工作流程。&lt;/p&gt;
&lt;p&gt;GitHub 也将与 Anthropic 及 MCP Steering Committee 合作，打造可与 GitHub 无缝整合的开源 MCP 社群注册库。未来开发者可自助发布伺服器，条目将自动出现在 MCP Registry 中，减少重复上架，并透过标准化的后设资料与验证讯号提升透明度。官方将此视为建立健康开源生态的重要步骤。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171284</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171284</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>李建兴</author>
      <category>新闻</category>
    </item>
    <item>
      <title>横扫 47 家美企与伦敦交通局，19 岁骇客面临 95 年徒刑</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0919-doj-960.jpg?itok=npUzqpr8" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"&gt;&lt;div class="field-label"&gt;图片来源:&amp;nbsp;&lt;/div&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;美国司法部&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;英国国家犯罪调查局（National Crime Agency，NCA）本周逮捕了现年 19 岁的 Thalha Jubair 与 18 岁的 Owen Flowers，&lt;a href="https://www.nationalcrimeagency.gov.uk/news/two-charged-for-tfl-cyber-attack" target="_blank"&gt;在周四（9/18）指控&lt;/a&gt;他们在去年入侵了伦敦交通局（Transport of London，TfL）， &lt;a href="https://www.justice.gov/opa/pr/united-kingdom-national-charged-connection-multiple-cyber-attacks-including-critical" target="_blank"&gt;同一天美国也起诉了当中的 Jubair&lt;/a&gt;，宣称他参与了至少 120 起电脑网路入侵与勒索案件，涉及 47 家美国企业。不管是 Jubair 或 Flowers，他们在从事骇客行动时都还是青少年。&lt;/p&gt;
&lt;p&gt;伦敦交通局（TfL）在去年 8 月底遭骇客集团 Scattered Spider 入侵，造成 TfL 票价与资料系统瘫痪了好几个月，外泄 5,000 名乘客的个资，带来约 3,000 万英镑的损失，而 Jubair 与 Flowers 即是涉及此案的 Scattered Spider 成员。&lt;/p&gt;
&lt;p&gt;美国司法部指出，Jubair 在 2022 年 5 月至 2025 年 9 月间，透过社交工程取得企业网路存取权限，进而窃取并加密企业资料，再向企业勒索，总计勒索金额高达 1.15 亿美元，并有部分赎金汇入了他所控制的伺服器钱包。在 2024 年 7 月伺服器被查扣时，Jubair 还转走了价值 840 万美元的加密货币，另有 3,600 万美元的加密货币遭警方没收。&lt;/p&gt;
&lt;p&gt;被骇组织包括美国联邦法院系统、一家美国关键基础设施公司、美国中西部大型医疗集团 SSM Health Care Corporation，以及美国加州的大型医疗体系 Sutter Health 等。其中，Flowers 也被控参与 SSM Health Care Corporation 的攻击事件。&lt;/p&gt;
&lt;p&gt;美国检方已依电脑诈欺共谋、电脑诈欺、电汇诈欺共谋、电汇诈欺及洗钱共谋等罪名起诉 Jubair，若全数罪名成立，最高可判处 95 年徒刑。&lt;/p&gt;
&lt;p&gt;Scattered Spider 是活跃于美国与英语系国家的骇客组织，自 2022 年起便频繁透过社交工程、SIM 卡置换与窃取凭证等方式入侵大型企业网路、窃取资料并展开勒索，已知的受害者包括米高梅国际酒店集团（MGM Resorts International）、美国连锁赌场 Caesars Entertainment 及家庭清洁用品公司高乐氏（Clorox）等。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171291</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171291</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>陈晓莉</author>
      <category>新闻</category>
    </item>
    <item>
      <title>Mistral 开源新版小模型 Magistral Small 1.2 新增视觉能力</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0919-magistral_small_1.2-hugging_face-960.jpg?itok=fj7wgCXt" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"&gt;&lt;div class="field-label"&gt;图片来源:&amp;nbsp;&lt;/div&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;Hugging Face&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;&lt;a href="https://www.linkedin.com/posts/mistralai_introducing-magistral-small-12-magistral-activity-7374437491921076224-3YrE" target="_blank"&gt;法国 AI 新创公司 Mistral AI 本周公布&lt;/a&gt;并开源新版小语言模型 Magistral Small 1.2，除了提升效能，增加视觉编码功能，也能跑在 MacBook 电脑上。&lt;/p&gt;
&lt;p&gt;Magistral Small 1.2 为 1.1 版的升级，&lt;a href="https://huggingface.co/mistralai/Magistral-Small-2509" target="_blank"&gt;Mistral 说明&lt;/a&gt;，它是以 Mistral Small 3.2 (2506) 为基础开发，具备推理能力能在回答前执行一长串推理，并且经过监督式微调（SFT），训练资料来源是推理模型家族的 Magistral Medium 推论时产生的轨迹，之后又加上强化式学习（RL）优化而成的高效率小型推理模型。Magistral Small 1.2 参数量 240 亿，具备最长 128K 脉络空间。&lt;/p&gt;
&lt;p&gt;Magistral Small 系列都能于本地部署，经过量化（quantized）后可在 Nvidia RTX 4090 GPU 平台的机器或是一台 32GB RAM 的 MacBook 上执行。&lt;/p&gt;
&lt;p&gt;相较于前一版，Magistral Small 1.2 新增视觉编码器，可接收多模态包括文字和图片输入，推理能力也扩及视觉。效能也提升，数学和程式撰写标竿测试得分成长 15%。它也改进了工具使用能力，能利用外部工具上网搜寻、执行程式码或生成图片。此外，新模型更人性化，它的回应更清晰、自然，文字排版或符号使用也美观。&lt;/p&gt;
&lt;p&gt;Magistral Small 1.2 支援 20 多种语言，包括英、法、德、西、中、日、韩等。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.mistral.ai/getting-started/models/models_overview/" target="_blank"&gt;Mistral 同时也更新了&lt;/a&gt;推理模型 Magistral Medium 1.2，新增视觉支援，如同 Magistral Small 1.2，Medium 版也具备最长 128K 脉络空间。二个模型都是以 Apache 2.0 授权开源，允许商业或非商业用途的使用和修改。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171290</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171290</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>林妍溱</author>
      <category>新闻</category>
    </item>
    <item>
      <title>Google 将 Gemini 整合到美国版 Chrome 中，将加入代理人等能力</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0919-google_gemini_chrome-960.jpg?itok=8QHaPwpx" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"&gt;&lt;div class="field-label"&gt;图片来源:&amp;nbsp;&lt;/div&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;Google&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;&lt;a href="https://blog.google/products/chrome/new-ai-features-for-chrome/" target="_blank"&gt;Google 昨（18）日宣布&lt;/a&gt;Gemini 整合 Chrome 的多项计划，包括从美国开始将 Gemini 整合到 Chrome 桌机、Android 和 iOS 手机版，Google 并将陆续为 Gemini in Chrome 加入代理人、推理和多模态能力，还能一键变更密码。&lt;/p&gt;
&lt;p&gt;今天整合 Gemini 的 Chrome Mac 及 Windows 桌机版、Android 版就能部署到美国用户，只要其浏览器语言设定为英文。用户上网时 Gemini 可回答关于网页内容的问题。Android 手机用户在使用 Chrome 或其他 App 时长按电源键可启动 Gemini。iPhone 上，Gemini 会直接内建到 iOS 版 Chrome 中。&lt;/p&gt;
&lt;p&gt;Google 并预告，未来几个礼拜内，Gemini in Chrome 将再加入代理人功能，使 Gemini in Chrome 功能更强大。对企业用户而言，几个星期内 Gemini 也会部署到 Google Workspace，并提供企业等级的资料防护和控制。&lt;/p&gt;
&lt;p&gt;Gemini in Chrome 可使上网搜集资讯或规划更轻松。例如它支援跨多分页执行，方便用户比价、摘要或整合多个网站内容，可减轻像是旅行规划的麻烦。Gemini in Chrome 也借由和 Google 原生应用如 Calendar、YouTube 或 Google Maps 的深度整合，因此用户可以教 Gemini in Chrome 直接搜寻 YouTube 影片，它会提供连结导引用户过去。&lt;/p&gt;
&lt;p&gt;本月底 Gemini in Chrome 将加入 AI Mode，后者是加入推理和多模态能力的 Google 搜寻。美国版英文用户本月底使用 Chrome 的搜寻列（或称 omnibox）就能使用到这强大的搜寻功能。此外，美国版 Gemini in Chrome 现在已获得情境建议（contextual suggestion）功能，用户上网时叫出 Gemini 问问题时，Gemini 可在 Chrome 侧边栏顶端显示 AI Overview（AI 摘要），并提供情境建议，让用户无需离开网页。本项功能几个礼拜内会新增其他语言支援并推向其他国家。&lt;/p&gt;
&lt;p&gt;在安全性方面，Chrome 的安全上网（Safe Browsing）的进阶防护（Enhanced Protection）模式，继现在使用 Gemini Nano 来辨识钓鱼网站，之后将用它来封锁下载病毒或诈骗软体的网站。&lt;/p&gt;
&lt;p&gt;其次，Gemini in Chrome 能学习用户使用偏好并借此封锁网站的垃圾通知，例如当它认为使用者不允许特定网站存取相机、地点等资讯的要求时，会先自动封锁，并显示核准对话框让用户最终决定。最后，Chrome 现在已能 autofill 网站密码，但之后 Gemini in Chrome 将进一步加入密码代理人能力，让用户一键完成特定网站的密码的变更及储存。支援的网站包括 Coursera、Spotify、Duolingo、H&amp;amp;M 等。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171287</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171287</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>林妍溱</author>
      <category>新闻</category>
    </item>
    <item>
      <title>Meta 即将开始预览 AI 眼镜开发套件</title>
      <description>&lt;header&gt;
        &lt;div class="img-wrapper"&gt;
      &lt;div class="field field-name-field-image field-type-image field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt;&lt;img src="https://s4.itho.me/sites/default/files/styles/picture_size_large/public/field/image/0919-meta_ray-ban_display-3-960.jpg?itok=s8SH2a_e" width="960" height="420" alt="" referrerpolicy="no-referrer"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;        &lt;/div&gt;
                    
      &lt;/header&gt;
    &lt;div class="row-fluid"&gt;
    &lt;div class="contents-wrap"&gt;
    &lt;div class="content"&gt;
    &lt;div class="side-extra"&gt;
      
  &lt;/div&gt;

&lt;div class="field field-name-field-photo-source field-type-text field-label-inline clearfix"&gt;&lt;div class="field-label"&gt;图片来源:&amp;nbsp;&lt;/div&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;Meta&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="field field-name-body field-type-text-with-summary field-label-hidden"&gt;&lt;div class="field-items"&gt;&lt;div class="field-item even"&gt; &lt;p&gt;就在发布了&lt;a href="https://www.ithome.com.tw/news/171260" target="_blank"&gt;一系列的 AI 眼镜&lt;/a&gt;之后，&lt;a href="https://developers.meta.com/blog/introducing-meta-wearables-device-access-toolkit/?intern_source=blog&amp;amp;intern_content=connect-2025-day-2-keynote-recap-vr-development-use-cases-wearable-device-access-toolkit" target="_blank"&gt;Meta 周四（9/18）宣布&lt;/a&gt;将开始预览穿戴装置存取工具包（Meta Wearables Device Access Toolkit），以让开发人员打造支援这些 AI 眼镜的各种应用，涵盖 Ray-Ban Meta、Oakley Meta HSTN、Oakley Meta Vanguard，以及与内建显示器的 Meta Ray-Ban Display。正式版预计会在 2026 年出炉。&lt;/p&gt;
&lt;p&gt;Meta 表示，Ray-Ban Meta 已于全球售出数百万副，证明这种产品形态是成功的，也代表此一时尚与科技的结合带动了新的文化潮流，预示著配备开放式喇叭、免持相机及随身 AI 助理的 AI 眼镜将成为人们日常生活的一部分，因而想建立一个平台，让开发者可扩充 AI 眼镜的体验。&lt;/p&gt;
&lt;p&gt;首版的工具包将开放存取眼镜上的摄影机，也能透过 iOS/Android 蓝牙设定档存取眼镜上的麦克风与喇叭，但还不能存取 Meta AI 功能或显示器，也无法存取肌电图腕带 Meta Neural Band 上的感测器。&lt;/p&gt;
&lt;p&gt;该工具包支援 Android 与 iOS 平台，开发人员不一定要拥有 AI 眼镜，其软体开发套件（SDK）将包含一个模拟装置套件（Mock Device Kit），可用来进行自动化与程式测试。此外，就算在没有开卖 Meta AI 眼镜的市场，也能参与此一预览活动，只是所能存取的功能会受限。&lt;/p&gt;
 &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;    &lt;div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
       
  &lt;/div&gt;&lt;/div&gt;</description>
      <link>https://www.ithome.com.tw/news/171286</link>
      <guid isPermaLink="false">https://www.ithome.com.tw/news/171286</guid>
      <pubDate>Thu, 18 Sep 2025 16:00:00 GMT</pubDate>
      <author>陈晓莉</author>
      <category>新闻</category>
    </item>
  </channel>
</rss>
