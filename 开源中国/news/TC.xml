<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 19 Aug 2025 07:51:03 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>中國開源 AI 模型背後供應商排名一覽</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;Interconnects AI 是由 Nathan Lambert（艾倫人工智能研究所研究科學家、加州大學伯克利分校博士）於 2022 年創立的個人欄目，主要通過 Substack 通訊（網址：https://www.interconnects.ai ）分享 AI 領域的前沿見解，內容涵蓋大模型訓練、推理機制、強化學習等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;該欄目近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Finterconnectsai%2Fstatus%2F1957105950201950715" target="_blank"&gt;發佈&lt;/a&gt;文章&lt;em&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.interconnects.ai%2Fp%2Fchinas-top-19-open-model-labs" target="_blank"&gt;Ranking the Chinese Open Model Builders&lt;/a&gt;》&lt;/em&gt;，對中國開源 AI 模型背後的機構/公司進行了排名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;作者稱根據這些公司/機構在開源 AI 生態系統中的貢獻質量和數量進行評估，重點關注開源模型、工具和數據集的發佈，而非專有能力或原始性能&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/153430_zfia_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第一梯隊 (業界頂流)：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;深度求索 (DeepSeek)&lt;br&gt; 通義千問 (Qwen)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第二梯隊 (有力競爭者)：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;月之暗面 (Kimi)&lt;br&gt; 智譜 AI (Zhipu / Z AI)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;值得關注：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;階躍星辰 (StepFun)&lt;br&gt; 騰訊 (混元)&lt;br&gt; 小紅書 (RedNote)&lt;br&gt; MiniMax&lt;br&gt; 上海人工智能實驗室 (書生/InternLM)&lt;br&gt; 天工 (崑崙萬維)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;後起之秀：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;字節跳動 (豆包/Seed)&lt;br&gt; OpenBMB (清華大學)&lt;br&gt; 小米 (MiMo)&lt;br&gt; 百度 (文心)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;榮譽提名：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;多模態藝術模型項目 (Multimodal Art Projection)&lt;br&gt; 阿里巴巴國際數字商業集團&lt;br&gt; 北京智源人工智能研究院 (BAAI)&lt;br&gt; 螞蟻集團 (inclusionAI)&lt;br&gt; 華為 (盤古)&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0de5cd5b8f905e902d1e9a1eb8af65e24d3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-69d73b09a07b845e141d838abcdec9a00a5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367177/chinas-top-19-open-model-labs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367177/chinas-top-19-open-model-labs</guid>
      <pubDate>Tue, 19 Aug 2025 07:37:43 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程工具 Augment 推出「Quick Ask Mode」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程工具 Augment&amp;nbsp;推出了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.augmentcode.com%2Fchangelog%2Fquick-ask-mode" target="_blank"&gt;Quick Ask Mode&lt;/a&gt;。該模式將 AI 助手置於只讀狀態，僅用於探索和回答問題，不會修改任何文件，從而確保代碼安全。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-265989ac0f84cbb2b90969df7c6908b1320.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;適用場景&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;規劃階段&lt;/strong&gt;：分析系統架構、依賴關係或設計模式，然後據此制定任務清單，而無需進行實際代碼更改。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;理解代碼&lt;/strong&gt;：例如詢問「身份認證系統是如何運作的？」以安全方式探索系統邏輯，無編輯風險。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;查閲文檔&lt;/strong&gt;：如「這個函數的作用是什麼？在哪兒被調用？」——幫助快速解析代碼用途與位置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新成員入門&lt;/strong&gt;：新人可在不擔心誤改代碼的前提下安全探查、熟悉項目結構。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;用戶啓用 Quick Ask Mode 後，可以放心地向 Agent 詢問有關代碼變更的澄清、在實施前審查計劃，或進行代碼理解，而無需擔心意外觸發代碼修改。&lt;/p&gt; 
&lt;p&gt;該模式保留了完整的對話上下文，並允許用戶在準備好實施更改時輕鬆切換回默認的 Agent 模式。目前，Quick Ask Mode 已在 VS Code 和 JetBrains 中向所有用戶開放。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367167/augmentcode-quick-ask-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367167/augmentcode-quick-ask-mode</guid>
      <pubDate>Tue, 19 Aug 2025 07:15:43 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>陳天橋聯手清華教授代季峯發佈開源 AI「深度研究」項目：MiroMind ODR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;國內 AI 領域科學家、清華大學電子工程系副教授代季峯，與創新企業家、慈善家、天橋腦科學研究院創始人陳天橋聯手籌備一家致力於打造通用人工智能（AGI）新公司一事，引發廣泛關注。&lt;/p&gt; 
&lt;p&gt;如今，代季峯帶來了技術「首秀」。&lt;/p&gt; 
&lt;p&gt;代季峯領銜的 MiroMind AI 團隊日前公佈了一個高性能、完全開源、開放協作的深度研究項目：MiroMind Open Deep Research（Miro ODR），其 V0.1 版本的 GAIA 測試達 82.4 分，性能超越 OpenAI 的 DeepResearch、Manus 等一眾開源和閉源 AI 深度研究模型，從而成為當前開源最強 Deep Research 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-29c52019cf9892eb241c0244cf9bc89c5dc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5a2fb7bc5e874664ab5d0289cc1e4359eb0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與現有的深度研究方法相比，MiroMind ODR 項目開放了深度研究的各個階段，包括四個子項目：MiroFlow（Agent 框架）、MiroThinker（模型）、MiroVerse（數據）和 MiroTrain（訓練基礎設施）。&lt;/p&gt; 
&lt;p&gt;MiroFlow，支持多種主流工具調用，擴展大語言模型，支持工具輔助的深度研究推理。它的亮點在於可以穩定復現最強性能，也就是 GAIA 上 82.4 的成績。&lt;/p&gt; 
&lt;p&gt;MiroThinker，原生支持工具輔助推理的大語言模型，可訓練、可復現，在 GAIA 中表現最佳。此外，它在 GAIA-Text-103 上取得了 SOTA 性能（60.2%），接近 OpenAI Deep Research。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cf3f845768113618d3320726ec7628fbe21.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;MiroVerse，147K 開源訓練數據支持深度研究訓練。此外團隊還會關注社區反饋，每月持續提供高質量、深入的研究數據集。&lt;br&gt; MiroTrain，支持深度研究模型的穩定高效訓練，覆蓋整個 Deep Research 訓練流程，支持長文本訓練和 RL 訓練工具。&lt;/p&gt; 
&lt;p&gt;目前，Miro ODR 的四個子項目都已上線到 GitHub、Hugging Face 平台。&lt;/p&gt; 
&lt;p&gt;Blog: https://miromind.ai/blog/miromind-open-deep-research&lt;br&gt; Demo: https://dr.miromind.ai/&lt;br&gt; GitHub: https://github.com/MiroMindAI&lt;br&gt; Hugging Face: https://huggingface.co/miromind-ai&lt;/p&gt; 
&lt;p&gt;MiroMind ODR 既是 MiroMind 的正式亮相，同樣也是代季峯面向 AGI 的技術首秀。&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/364346" target="_blank"&gt;盛大網絡挖角代季峯，籌建新 AGI 公司欲對標 DeepSeek&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367148/miromind-open-deep-research</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367148/miromind-open-deep-research</guid>
      <pubDate>Mon, 18 Aug 2025 06:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小紅書發佈 DynamicFace 人臉生成技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;小紅書 AIGC 團隊近日正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fvi9QQyIciCY3yMZ3RnPVIA" target="_blank"&gt;發佈&lt;/a&gt;了名為 DynamicFace 的可控人臉生成技術。針對圖像及視頻領域的人臉融合任務實現了高質量與高度一致性的置換效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與傳統人臉置換方法相比，DynamicFace 獨創性地將擴散模型（Diffusion Model）與&lt;strong style="color:#3c3c3c"&gt;&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;可組合&lt;/strong&gt;&lt;/strong&gt;&lt;strong style="color:#3c3c3c"&gt;&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;的 3D 人臉先驗&lt;/strong&gt;&lt;/strong&gt;進行深度融合，針對人臉運動與身份信息進行了精細化解耦以生成更一致的人臉圖像和視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-0543a7ceec6ff03fe6e9addf187cafed4c6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;可組合三維面部先驗的顯式條件解耦&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;針對現有方法在身份與運動表徵中普遍存在的耦合冗餘問題，Dynamicface 提出將人臉條件顯式分解為身份、姿態、表情、光照及背景五個獨立的表徵，並基於 3DMM 重建模型獲取對應參數。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;具體而言，利用源圖像提取身份形狀參數 α，目標視頻逐幀提取姿態 β 與表情 θ，隨後渲染生成形狀–姿態法線圖，減少目標人臉身份泄露，最大程度保留源身份；表情信息僅保留眉毛、眼球及口脣區域的運動先驗，避免引入目標身份特徵；光照條件由 UV 紋理圖經模糊處理得到，僅保留低頻光照分量；背景條件採用遮擋感知掩碼與隨機位移策略，實現訓練–推理階段的目標臉型對齊。四條條件並行輸入 Mixture-of-Guiders，每組由 3×3 卷積與零卷積末端構成，在注入網絡前經過 FusionNet 融合四條條件的特徵後注入到擴散模型中，可在保持 Stable Diffusion 預訓練先驗的同時實現精準控制。&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;身份–細節雙流注入機制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#3c3c3c; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;為實現高保真身份保持，DynamicFace 設計了雙流並行注入架構。高層身份流由 Face Former 完成：首先利用 ArcFace 提取 512 維 ID Embedding，再通過可學習 Query Token 與 U-Net 各層 Cross-Attention 交互，確保全局身份一致性；細節紋理流由 ReferenceNet 實現，該網絡為 U-Net 的可訓練副本，將 512×512 源圖潛變量經 Spatial-Attention 注入主網絡，實現細粒度的紋理遷移。&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;即插即用時序一致性模塊&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#3c3c3c; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;針對時序一致性問題，DynamicFace 會在訓練中插入時序注意力層來優化幀間穩定性，但時序層在處理長視頻生成時會出現幀間跳動的現象。為此，我們提出了 FusionTVO，將視頻序列劃分為若干段，併為每段設置融合權重，在相鄰段的重疊區域實行加權融合；並在潛變量空間引入總變差（Total Variation）約束，抑制幀與幀之間的不必要波動；對於人臉之外的背景區域，在每一步去噪迭代過程中採用目標圖像中的背景潛變量空間進行替換，維持了場景的高保真度。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367147</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367147</guid>
      <pubDate>Mon, 18 Aug 2025 06:04:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>理想汽車 MindGPT 3.1 發佈：速度躍升近 5 倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;理想汽車正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FITMmZOSYW6AHbmuyosix7A" target="_blank"&gt;宣佈&lt;/a&gt;其自研的 MindGPT 大模型迎來重大升級，全新版本 MindGPT3.1 驚豔亮相。此次升級將智能體能力深度融入大模型之中，實現了邊想邊搜的創新功能，即在推理過程中能夠同步調用各類工具，從而為用戶提供更加迅速、全面且精準的結果反饋。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;官方數據顯示，MindGPT3.1 在性能上實現了質的飛躍，每秒出字速度最高可達 200tokens，相較於前代 MindGPT3.0，速度提升近 5 倍，這一突破將極大提升用戶與智能助手的交互效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="332" src="https://oscimg.oschina.net/oscnet/up-962a85cad4a4b3153db1d3b7bb925463d03.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MindGPT3.1 不僅速度驚人，更在智能交互層面展現出卓越實力。它深度融合了推理思維鏈及工具調用能力，模型能夠像資深分析師一樣，層層拆解複雜問題，通過「自主思考-自主調用工具-進一步推理」的循環機制，不斷優化答案質量，使得複雜任務的完成率得到顯著提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在覈心能力維度上，MindGPT3.1 同樣表現出色。在數學、代碼、科學問答以及指令遵循等方面，其指標均全面優於 MindGPT3.0，並領先於行業內的開源模型如 Qwen3-235B 等。特別是在代碼能力上，MindGPT3.1 實現了進一步增強，能夠輕鬆實現貪吃蛇、彈球控制等經典編程樣例，展現了其強大的技術實力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367111</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367111</guid>
      <pubDate>Mon, 18 Aug 2025 03:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「阿里淘寶第一個程序員」加入 AI 創業公司，後者創始人曾是阿里研究員</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據貝聯珠貫創始人畢玄（原阿里花名，本名林昊）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkPvjh7g5aog-c5gsE6eu2Q%3Fclick_id%3D222" target="_blank"&gt;公眾號消息&lt;/a&gt;，阿里「掃地僧」多隆已於 8 月 6 日加入貝聯珠貫，擔任聯合創始人兼首席架構師，專注 AI Agent 運維平台。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1154" src="https://static.oschina.net/uploads/space/2025/0819/112421_dsfV_2720166.png" width="1394" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;畢玄在文章中提到：很神奇，我和多隆都沒有想到，在 AI 時代，我們竟然又有了聯手做點事情的機會和緣分，這個事情就是基於 AI Agent 來改變運維服務，讓每家公司都有 N 個不同領域的「多隆」，從而提升運維服務的質量和效率。&lt;/p&gt; 
&lt;p&gt;蔡景現花名「多隆」，早在 2000 年就加入了阿里巴巴，是淘寶初創團隊的三個開發工程師之一，被稱為淘寶第一個程序員，曾主導構建了淘寶交易系統和論壇系統。2025 年 8 月 1 日，&lt;a href="https://www.oschina.net/news/365665" target="_blank"&gt;多隆宣佈離職&lt;/a&gt;，結束了他整整 25 年的阿里生涯。&lt;/p&gt; 
&lt;p&gt;畢玄，2007 年加入阿里，曾打造了阿里重要的中間件 HSF 服務框架，先後任職淘寶網平台架構部架構師、集團核心系統研發部資深技術專家、阿里中間件負責人。2021 年 8 月，畢玄以阿里雲視頻雲負責人（P10）的身份離職，後創立貝聯珠貫，擔任 CEO。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8e8ca72fc6447676a480ef3f19af9439cd8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，貝聯珠貫科技成立於 2021 年 11 月，致力於為用戶提供大數據、AI 基礎設施的產品服務，幫助企業快速實現數智化轉型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367109</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367109</guid>
      <pubDate>Mon, 18 Aug 2025 03:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>得州總檢察長調查 Meta 和 Character.AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;得克薩斯州總檢察長肯・帕克斯頓已於週一發佈新聞稿，宣佈對 Meta 人工智能工作室（Meta AI Studio）和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 展開調查，理由是這兩家公司 「可能存在欺騙性貿易行為，並將自身誤導性地宣傳為心理健康工具」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-8a5fb71acb3eb1bc8ee366cb57883920a14.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「在當今數字時代，我們必須持續努力保護得州兒童免受欺騙性和剝削性技術的傷害」， 新聞稿援引帕克斯頓的話稱，「人工智能平台通過偽裝成情感支持來源，可能會誤導易受影響的用戶，尤其是兒童，讓他們誤以為自己正在接受合法的心理健康服務。但實際上，這些平台往往提供的是經過循環利用的通用回應，這些回應是根據收集到的個人數據設計的，卻被偽裝成治療建議。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次調查發生在參議員喬希・霍利宣佈對 Meta 展開調查的幾天後。此前有報告發現，Meta 的人工智能聊天機器人與兒童存在不當互動，包括調情行為。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;得州總檢察長辦公室指控 Meta 和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 打造的人工智能角色 「冒充專業治療工具，儘管它們缺乏正規的醫療資質或監管」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 平台上數百萬個人工智能角色中，一個名為 「心理學家」（Psychologist）的用戶創建機器人在該初創公司的年輕用戶中需求旺盛。與此同時，Meta 雖未為兒童提供治療類機器人，但並未阻止兒童使用 Meta 人工智能聊天機器人或第三方創建的用於治療目的的角色。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我們對人工智能進行了明確標註，並且為了幫助人們更好地瞭解其侷限性，我們添加了免責聲明，説明回應由人工智能生成而非人類」，Meta 發言人瑞安・丹尼爾斯稱，「這些人工智能並非持照專業人士，我們的模型在適當情況下會引導用戶尋求合格的醫療或安全專業人員的幫助。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，媒體指出，許多兒童可能不理解此類免責聲明，或者乾脆無視它們。我們已向 Meta 詢問其為保護使用聊天機器人的未成年人採取了哪些額外保障措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯頓在聲明中還指出，儘管人工智能聊天機器人聲稱會保密，但它們的 「服務條款顯示，用戶互動會被記錄、追蹤，並被用於定向廣告和算法開發，這引發了關於隱私侵犯、數據濫用和虛假宣傳的嚴重擔憂」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據 Meta 的隱私政策，Meta 確實會收集與人工智能聊天機器人的交互提示、反饋以及跨 Meta 服務的其他互動，以 「改進人工智能及相關技術」。該政策未明確提及廣告相關內容，但指出信息可能會與搜索引擎等第三方共享，以提供 「更個性化的輸出」。考慮到 Meta 基於廣告的商業模式，這實際上等同於定向廣告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 的隱私政策也強調，該初創公司會記錄用戶的標識符、人口統計數據、位置信息以及更多用戶相關信息，包括瀏覽行為和應用使用平台。它會跨 TikTok、YouTube、Reddit、Facebook、Instagram 和 Discord 等平台的廣告追蹤用戶，並可能將這些追蹤數據與用戶賬戶關聯。這些信息被用於訓練人工智能、根據個人偏好定製服務，以及提供定向廣告，包括與廣告商和分析提供商共享數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Meta 和 Character 均表示，其服務並非為 13 歲以下兒童設計。儘管如此，Meta 因未能監管 13 歲以下兒童創建的賬戶而備受批評，而 Character 的兒童友好型角色顯然旨在吸引更年輕的用戶。該初創公司的首席執行官卡蘭迪普・阿南德甚至表示，他 6 歲的女兒也在使用該平台的聊天機器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此類數據收集、定向廣告和算法剝削行為，正是《兒童在線安全法》（KOSA）等立法旨在防範的內容。《兒童在線安全法》去年曾在兩黨強烈支持下有望通過，但在科技行業説客的強烈反對後陷入停滯。Meta 尤其動用了強大的遊説力量，警告議員們該法案的廣泛授權將削弱其商業模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，田納西州共和黨參議員瑪莎・布萊克本和康涅狄格州民主黨參議員理查德・布盧門撒爾向參議院重新提交了《兒童在線安全法》。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯頓已向這兩家公司發出民事調查令 —— 這是要求企業在政府調查期間提供文件、數據或證詞的法律命令，以確定它們是否違反了得州消費者保護法。（來源：環球市場播報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367101</guid>
      <pubDate>Mon, 18 Aug 2025 03:04:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義發佈全能圖像編輯模型 Qwen-Image-Edit</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FibgZIskZqjnJl9yKgc_ixA" target="_blank"&gt;發佈&lt;/a&gt;了 Qwen-Image 的圖像編輯版本：Qwen-Image-Edit。&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 基於 20B 的 Qwen-Image 模型進⼀步訓練，成功將 Qwen-Image 的獨特的文本渲染能力延展至圖像編輯領域，實現了對圖片中文字的精準編輯。&lt;/p&gt; 
&lt;p&gt;此外，Qwen-Image-Edit 將輸⼊圖像同時輸⼊到 Qwen2.5-VL（實現視覺語義控制）和 VAE Encoder（實現視覺外觀控制），從而兼具語義與外觀的雙重編輯能⼒。&lt;/p&gt; 
&lt;p&gt;如需體驗最新模型，訪問 Qwen Chat （chat.qwen.ai）並選擇「圖像編輯」功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105634_udvl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;語義與外觀雙重編輯:&amp;nbsp;Qwen-Image-Edit 不僅⽀持 low-level 的視覺外觀編輯（如元素的添加、刪除、修改等，要求圖片其他區域完全不變），也支持 high-level 的視覺語義編輯（如 IP 創作、物體旋轉、風格遷移等，允許整體像素變化但保持語義一致）。&lt;/li&gt; 
 &lt;li&gt;精準⽂字編輯:&amp;nbsp;Qwen-Image-Edit 支持中英文雙語文字編輯，可在保留原有字體、字號、風格的前提下，直接對圖片中的文字進行增、刪、改等操作。&lt;/li&gt; 
 &lt;li&gt;強⼤的基準性能:&amp;nbsp;在多個公開基準測試中的評估表明，Qwen-Image-Edit 在圖像編輯任務上具備 SOTA 性能，是一個強大的圖像編輯基礎模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用示例：&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105757_BFM2_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105828_GtUw_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105834_YhPa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ModelScope：https://modelscope.cn/models/Qwen/Qwen-Image-Edit&lt;br&gt; Hugging Face：https://huggingface.co/Qwen/Qwen-Image-Edit&lt;br&gt; GitHub：https://github.com/QwenLM/Qwen-Image&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367097</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367097</guid>
      <pubDate>Mon, 18 Aug 2025 02:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ARM 挖角亞馬遜高管，推進自研芯片計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據路透社的最新報道，ARM 最近成功引進了亞馬遜 AI 芯片主管拉米・辛諾（Rami Sinno），此舉旨在加速公司自研完整芯片的進程。辛諾在亞馬遜曾負責開發名為 「Trainium」 和 「Inferentia」 的 AI 芯片，這些芯片專為支持大型 AI 應用程序而設計。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-02243d99da0363cd55ec78f2f23d25a7871.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 的目標是從一個單純提供芯片知識產權的供應商，轉型為能夠獨立設計和生產完整芯片的企業。隨着技術的發展，市場對自研芯片的需求日益增加，ARM 希望在這一領域搶佔先機。去年 12 月，ARM 在一場審判中披露了其自研芯片的計劃，並表示將通過挖角競爭對手的高管來實現這一目標。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;辛諾的加盟被認為是 ARM 實現這一戰略的重要一步。除了辛諾，ARM 近期還從其他公司挖來了多位高管，包括具備大規模系統設計經驗的慧與科技高管，以及來自英特爾的芯片架構師。這些新任高管的加入將為 ARM 在自研芯片方面帶來更強的技術支持和經驗積累。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;近年來，ARM 不斷加強其在完整芯片和系統設計方面的團隊建設，希望藉助這些人才的專業背景與技術能力，推動公司的發展。芯片產業競爭愈發激烈，各大公司都在積極尋求突破，ARM 的這一戰略調整將對其未來的市場表現產生重要影響。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 自成立以來一直以其創新的芯片架構而聞名，隨着市場需求的變化，該公司意識到需要不斷進化以適應新的挑戰。通過引入行業精英，ARM 不僅能夠提升其技術實力，也能進一步拓展其市場份額，確保在未來的競爭中立於不敗之地。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367095</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367095</guid>
      <pubDate>Mon, 18 Aug 2025 02:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義 Qwen Chat 更新視覺理解功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIc0QlqvjyLG1xCR59QOZKA" target="_blank"&gt;宣佈&lt;/a&gt;對其&amp;nbsp;Qwen Chat&amp;nbsp;中的視覺理解功能進行更新。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105358_jvXb_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次更新被稱為「小而強大」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持原生 128K 上下文&lt;/li&gt; 
 &lt;li&gt;顯著提升數學推理與物體識別能力&lt;/li&gt; 
 &lt;li&gt;OCR 支持擴展至 30 多種語言&lt;/li&gt; 
 &lt;li&gt;2D/3D 定位更精準&lt;/li&gt; 
 &lt;li&gt;視頻理解與定位能力大幅度增強，整體視覺智能更強大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該升級或與阿里雲百鍊平台上近期更新的通義千問 VL-MAX 有關，其 2025 年 8 月 13 日的快照版本顯示，視覺理解指標得到全面提升。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367093</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367093</guid>
      <pubDate>Mon, 18 Aug 2025 02:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>架構提效的矛盾和矛盾的主要方面</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在軟件開發領域，架構設計是確保系統高效、穩定運行的重要環節或者稱之為重要動作。無論架構從簡單到複雜，還是從複雜迴歸簡潔的演變過程。在這個過程中，又無論是初創公司還是大型企業，架構提效始終是技術團隊的核心追求。本文將從穩定、性能、代碼三大維度出發，結合實戰經驗，探討如何有效提升架構效能。&lt;/p&gt; 
&lt;p&gt;為什麼要選擇或者認為這三個維度是必要要素呢？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「一切事物中包含的矛盾方面的相互依賴和相互鬥爭，決定一切事物的生命，推動一切事物的發展。沒有什麼事物是不包含矛盾的，沒有矛盾就沒有世界。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;當然架構也有自身的矛盾統一，在架構提效上，系統的運行正常和問題頻出是一對矛盾，功能的快和慢是一對矛盾，工程的整潔有序和無序是一對矛盾。這三對矛盾正是架構提效的矛盾。&lt;/p&gt; 
&lt;p&gt;如果不穩定，系統三天兩頭出故障，研發人員成了救火隊員，系統的效率將無從談起，穩定是我們談架構效率的基礎。如果性能不高，在網絡基礎環境穩定的情況下，訪問一個頁面 3S 才響應，那我們也不好意思説架構有效率。如果代碼亂成一鍋粥，比如大段大段麪條式的代碼，再比如滿眼望去 N 多個 if 結構語句，研發人員加一個功能都要查找好久，也是無顏談效率。&lt;/p&gt; 
&lt;p&gt;因此，我們認為，穩定、性能、代碼是架構提效矛盾中的主要方面。接下來我們將從這三個主要方面去介紹。&lt;/p&gt; 
&lt;p&gt;軟件工程發展了這麼多年，高可用、高擴展、高併發已經有大量的文章篇幅，從宏觀的角度去講如何做微服務、如何分庫分表，如何使用緩存等等。因此呢，本篇文章想聚焦到架構矛盾的微觀層面，也就是偏工程結構、偏代碼方面去闡述這三個要素。另外本篇文章的思想也參考了前輩們的研究成果，我也附在了文末。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;穩定：架構的基石與守護神&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「萬事萬物都是運動的，發展的」。業務功能變多，用戶數量變多，團隊規模變大。如果沒有規則和規範的引導和約束，系統逐漸野蠻生長，逐漸碎片化。那麼，我們的系統何談穩定呢。&lt;/p&gt; 
&lt;p&gt;我們就希望能找到這樣的一種規則、規範 -- 正交分解或者叫做正交設計。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//bb82ceb06e46d5d6d4365e615d3f3785.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;架構設計的過程就是一個業務正交分解的過程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;架構設計並不僅僅是技術層面的規劃，更重要的是對業務邏輯的深入理解和把握。通過正交分解，我們可以將複雜的業務系統拆解成若干個相互獨立但又彼此關聯的模塊或組件。這些模塊或組件在保持功能完整性的同時，還能實現高度的內聚和鬆散的耦合，從而提高系統的可擴展性、可維護性和可重用性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正交分解的關鍵在於消除重複、分離關注點和管理依賴。通過這一方法，我們可以將業務系統中的公共部分和可變部分進行明確的劃分，從而實現對業務邏輯的精準掌控。在架構設計過程中，我們需要不斷地對業務進行抽象和分解，直至得到一系列規模可控、結構清晰的小模塊。這些小模塊通過組合和協作，能夠形成更加複雜且功能完善的軟件系統。&lt;/p&gt; 
&lt;p&gt;因此，正交分解的思想是我們架構設計保障穩定的重要方法基礎。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能：速度與效率的雙重考驗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;想快，就使用「戰術設計」。曾經這是很多程序員的法寶，因為他們認為這樣開發「確實快」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//0e3d7156e3234d0517c9adb69369faf3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大多數程序員以稱為戰術編程的心態來進行軟件開發。在戰術方法中，主要重點是使某些功能正常工作，例如新功能或錯誤修復。乍一看，這似乎是完全合理的：還有什麼比編寫有效的代碼更重要的呢？但是，戰術編程幾乎不可能產生出良好的系統設計。&lt;/p&gt; 
&lt;p&gt;想快的「戰術設計」會造成常見的下面這樣的情況。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「團隊新人不熟悉系統，為了急於上線一個特性，又不想影響到系統的其他部分，就會很自然地在某個地方加一個 flag，然後在所有需要改動的地方加 if 判斷，而不是去調整系統設計以適應新的問題空間。」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在一個充滿活力的軟件開發團隊中，新成員小張剛剛加入不久。他對於團隊正在使用的複雜系統還不是很熟悉，但面對緊迫的項目進度和上級施加的壓力，他急於證明自己，並希望能儘快為團隊做出貢獻。團隊正計劃上線一個新的特性，這個特性需要在不幹擾系統其他部分的前提下實現。&lt;/p&gt; 
&lt;p&gt;小張在瀏覽了系統的代碼庫後，發現要全面理解並調整整個系統設計以適應新的特性，需要花費大量的時間和精力。他深知自己作為新人，在這方面還有所欠缺，因此，他決定採取一個他認為更為「高效」的方法：在某個關鍵位置添加一個臨時的標誌位（flag），然後在所有需要改動的地方都加上 if 判斷，以確保新特性能夠按時上線，同時儘量減少對現有系統的影響。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//2b037e23421b103a664be64e68b760ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雖然這種方法在短時間內確實讓新特性得以順利上線，但團隊中的資深成員很快便發現了潛在的問題。這種做法雖然看似快速解決了問題，但實際上卻在系統中埋下了隱患。它不僅增加了代碼的複雜性，降低了代碼的可讀性和可維護性，還可能在未來引發更多的 bug 和性能問題。更重要的是，這種做法違背了軟件開發中的最佳實踐，&lt;strong&gt;即應通過優化系統設計來適應新的問題空間，而不是通過添加臨時性的補丁來解決問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「幾乎每個軟件開發組織都有至少一個將戰術編程發揮到極致的開發人員：戰術龍捲風」，而且常常被視為團隊」英雄「，因為能「快速完成任務且高產」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「戰術龍捲風」通常以戰術編程為主要手段，即採用最快速、最直接的方法來解決當前的問題，而不考慮長遠的影響和代碼的可持續性。這種方法在初次使用時往往能夠取得顯著的效果，任務完成得既快又好，贏得了團隊成員的讚譽和領導的認可。&lt;/p&gt; 
&lt;p&gt;然而，隨着時間的推移，「戰術龍捲風」所留下的隱患逐漸暴露出來。由於缺乏對系統設計的深入理解和長遠規劃，他的代碼往往難以維護和擴展。當需要添加新功能或修復 bug 時，團隊成員往往需要花費更多的時間和精力來理解和修改他的代碼。因此，第二次和第三次修改時，效率會大幅下降，甚至可能引發新的問題。&lt;/p&gt; 
&lt;p&gt;實際造成結果：第一次快、第二次慢、第三次更慢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;代碼：簡潔與優雅的雙重追求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們做業務開發，代碼的優雅簡潔，不能侷限在一段方法，還是要從整個工程結構然後在到類、到方法，這樣從宏觀到中觀再到微觀的整體去要求。我們的應用工程結構，常見大致分為四層。分別是 api 層、biz 層、domain 層和 dao 層。&lt;/p&gt; 
&lt;p&gt;這個時候我們就要很清晰地熟悉每一層的職責，然後將我們的代碼放入進去。首先，api 層的作用，正如它的名字一樣，是提供 api 服務的。向誰提供 api 呢，比如客戶端，比如 APP 端、pc 端等等，公司外面的客戶，比如 isv 等。其次，biz 層的作用，這一層也叫業務服務層。它主要負責編排。把一個業務場景下的主流程邏輯處理完成。這個主流程會涉及到多個原子接口，就在這層負責組裝。再次，domain 層的作用，也叫做領域服務層。按照 OO 思想，領域編程的思維，我們的」厚對象「的代碼都在這層。比如訂單域、運費域等。這裏對「這一層的位置」多説幾句，在沒有形成領域之前，這層一般叫 service 層，不過我們都是建議領域思維編寫代碼。最後是 dao 層，也就是我們的存儲層了，負責持久化。&lt;/p&gt; 
&lt;p&gt;在清晰了每一層的作用之後，如果我們的代碼職責也是按照這樣逐層放入的，那麼大體是符合我們的整潔要求的。但是呢，隨着時間的推移，需求的增多和變化。原來整潔的工程結構和代碼已經不那麼優雅了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這個時候，一般會出現兩類現象，一類是業務層（biz）變的臃腫，能力層（domain）變的單薄。另一類是出現了網狀調用。而且這兩類現象也很有可能是混合在一起出現。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//5457bd8fcb8270c8dacce659508d85ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這兩類現象會直接帶來下面 4 種結果。&lt;/p&gt; 
&lt;p&gt;1、biz 層越來越」胖「。胖了之後，還長成了兩小層。上小層是面向單一業務場景的「業務 biz 層」，下小層成了通用場景可複用的「通用 biz 層」。&lt;/p&gt; 
&lt;p&gt;2、service 層越來越」瘦「。當 service 層變薄了以後，也就只能淪為 service 了，而這樣的 service 層跟 dao 層實際沒什麼區別，更不能再稱之為 domain 層或者沒有機會演變成 domain 層。&lt;/p&gt; 
&lt;p&gt;3、但是也不是所有的 service 層都變瘦、變薄了。可能有的萎縮，有的膨脹。人員與設計的差異，導致顆粒度不一。&lt;/p&gt; 
&lt;p&gt;4、出現了網狀調用。原本 biz-1 -&amp;gt; service-1 的實現鏈路下，隨着新增業務邏輯，又新起了一個 service-2，鏈路演變成了 biz-1 -&amp;gt; service-1-&amp;gt; service-2。「這樣的趨勢持續發展下去，會發現 biz-1 下的 service 調用鏈路越發的複雜，呈現為一顆深度調用樹，而 biz 層失去了業務編排的作用退化為一個業務場景入口的標誌符」。有可能後面繼續 3-4-5-6，越挖越深，不見盡頭。&lt;/p&gt; 
&lt;p&gt;很顯然，到這裏，這樣的結構現狀，代碼現狀，已經遠離了我們簡潔和優雅的初衷。也談不上提效了。&lt;/p&gt; 
&lt;p&gt;到此，我們介紹了架構提效中的穩定、性能和代碼這三個主要的方面，限於篇幅和架構本身的實踐性，還需要我們在架構提效上進行持續的優化。需要我們在穩定、性能、代碼三大維度上不斷探索和實踐。通過高可用架構設計、性能優化策略、模塊化與解耦、代碼質量與規範等措施，我們可以構建一個既穩定又高效，且易於維護和擴展的系統。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「在複雜的事物發展過程中，有許多的矛盾存在，其中必有一種是主要的矛盾，由於它的存在和發展規定和影響着其他矛盾的存在和發展。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;架構的發展本身也是對抗熵增這一矛盾的過程，我們上面描述的穩定、性能和代碼中的矛盾方面有是圍繞和關聯這一主要矛盾的。在這個過程中不僅有系統的有序變無序，也有組織的簡單變複雜。我們既要關注技術層面的提升，更要注重團隊協作、知識共享和持續改進的文化建設。只有這樣，我們才能在快速變化的市場環境中，保持競爭力，不斷前行。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18688507</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18688507</guid>
      <pubDate>Mon, 18 Aug 2025 02:48:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>英偉達發佈全新小型模型 Nemotron-Nano-9B-V2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達發佈了其&lt;span&gt;最新&lt;/span&gt;的小型語言模型（SLM）——Nemotron-Nano-9B-V2。該模型在多個基準測試中表現出色，並在特定測試中達到了同類產品的&lt;span&gt;最高&lt;/span&gt;水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 的參數量為 90 億，雖然比一些數百萬參數的微型模型要大，但它比之前的 120 億參數版本顯著減小，並專門針對單個英偉達 A10GPU 進行了優化。英偉達 AI 模型後訓練總監 Oleksii Kuchiaev 解釋説，這種調整是為了適配 A10 這款熱門的部署 GPU。此外，Nemotron-Nano-9B-V2 是一款混合模型，能處理更大的批次，速度比同等規模的 Transformer 模型快 6 倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該模型支持多達九種語言，包括中、英、德、法、日、韓等，並擅長處理指令跟蹤和代碼生成任務。其預訓練數據集和模型本身都已在 Hugging Face 和英偉達的模型目錄中提供。&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;融合 Transformer 與 Mamba 架構&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 基於&lt;span&gt;&amp;nbsp;&lt;/span&gt;Nemotron-H&lt;span&gt;&amp;nbsp;&lt;/span&gt;系列，該系列融合了&lt;span&gt;&amp;nbsp;&lt;/span&gt;Mamba&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;Transformer&lt;span&gt;&amp;nbsp;&lt;/span&gt;架構。傳統的 Transformer 模型雖然強大，但在處理長序列時會消耗大量內存和計算資源。而 Mamba 架構則引入了選擇性狀態空間模型（SSM），能夠以線性複雜度處理長信息序列，從而在內存和計算開銷上更具優勢。Nemotron-H 系列通過用線性狀態空間層替換大部分注意力層，在長上下文處理上實現了 2-3 倍的吞吐量提升，同時保持了高精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-ebd73f87284c797290002428bbcbbb7371d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;獨特的推理控制功能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這款模型的一大創新是其內置的「推理」功能，允許用戶在模型輸出最終答案前進行自我檢查。用戶可以通過簡單的控制符（如&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/think&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/no_think&lt;/code&gt;）來開啓或關閉此功能。模型還支持運行時「思考預算」管理，開發者可以限制用於內部推理的令牌數量，從而在準確性和延遲之間取得平衡。這對於客戶支持或自主代理等對響應速度有要求的應用場景尤為關鍵。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-5de1df85730cbf8d4cb29cda3ca17f92329.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英偉達根據其開放模型許可協議發佈了 Nemotron-Nano-9B-V2，該協議對企業友好且高度寬鬆。英偉達明確表示，企業可以自由地將該模型用於商業用途，並且無需為使用該模型支付費用或版稅。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管如此，協議仍有一些核心要求，例如用戶必須遵守內置的安全機制、在重新分發模型時進行歸屬標註，並遵守相關法律法規。英偉達表示，該協議旨在確保負責任和合乎道德的使用，而不是通過限制商業規模來盈利。這使得 Nemotron-Nano-9B-V2 成為了那些希望在降低成本和延遲的同時，保持高精度的企業開發者的理想選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367083</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367083</guid>
      <pubDate>Mon, 18 Aug 2025 02:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Crossplane 2.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Crossplane 2.0 現已發佈，一些新變化包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;應用支持 —— 不再只管理基礎設施，也能和雲資源一起管理應用&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;更豐富的組合能力 —— 組合資源現在可以包含任何 Kubernetes 資源，不僅限於 Crossplane 定義的資源，支持全棧抽象&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;默認命名空間隔離 —— 複合資源（XRs）和託管資源（MRs）默認都有命名空間，隔離更好，更符合 Kubernetes 習慣&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;聲明式的運維操作 —— 新增 Operation 類型，支持一次性、定時和事件驅動的升級、備份、維護等操作&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;託管資源過濾 —— 只安裝你需要的託管資源，不必一次性全部加載某個 Provider 的所有資源&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-b98d1f632166e7cfec273ab5cb31721891b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;Crossplane 2.0 的一些核心變化包括：&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;應用成為一等公民&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;2.0 最大變化是組合資源現在能包含任何 Kubernetes 資源，不只限於 Crossplane 管理的基礎設施。這意味着你可以定義一個複合資源，一次性完成數據庫、網絡、應用部署、監控等全部配置。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;舉例，平台團隊可以給開發團隊提供一個簡單的 「microservice」 API，自動完成新服務所有所需：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apiVersion:&amp;nbsp;&lt;span style="color:#dd1144"&gt;platform.acme.io/v1&lt;/span&gt;
kind:&lt;span style="color:#dd1144"&gt;Microservice&lt;/span&gt;
metadata:
namespace:&lt;span style="color:#dd1144"&gt;team-api&lt;/span&gt;
name:&lt;span style="color:#dd1144"&gt;user-service&lt;/span&gt;
spec:
image:&lt;span style="color:#dd1144"&gt;acme/user-service:v1.2.3&lt;/span&gt;
database:
&amp;nbsp; &amp;nbsp;&amp;nbsp;engine:&lt;span style="color:#dd1144"&gt;postgres&lt;/span&gt;
&amp;nbsp; &amp;nbsp;&amp;nbsp;size:&lt;span style="color:#dd1144"&gt;medium&lt;/span&gt;
ingress:
&amp;nbsp; &amp;nbsp;&amp;nbsp;subdomain:&lt;span style="color:#dd1144"&gt;users&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;背後自動創建 RDS 實例，配置安全組，部署應用（Deployment）、創建 Service 和 Ingress，甚至設置監控面板。平台團隊處理複雜，開發團隊獲得精準服務。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;默認啓用命名空間隔離&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;不再默認集羣級別資源，這常讓新用戶困惑。2.0 版本中，複合資源和託管資源都默認在命名空間內，符合 Kubernetes 規範，多租戶更直觀。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;舊的 claim 和 XR 二元結構取消。你只需在對應命名空間創建資源：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apiVersion:&amp;nbsp;&lt;span style="color:#dd1144"&gt;example.crossplane.io/v1&lt;/span&gt;
kind:&lt;span style="color:#dd1144"&gt;Database&lt;/span&gt;
metadata:
namespace:&lt;span style="color:#dd1144"&gt;frontend-team&lt;/span&gt;
name:&lt;span style="color:#dd1144"&gt;user-db&lt;/span&gt;
spec:
engine:&lt;span style="color:#dd1144"&gt;postgres&lt;/span&gt;
storage:&lt;span style="color:#dd1144"&gt;100Gi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;需要集羣範圍資源（如共享網絡）時依然可以創建，但必須顯式指定，不再默認。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;聲明式的運維操作&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;新增了 Operation 類型。多年來，團隊在備份、升級、維護等操作上常依賴自定義控制器或外部定時任務。現在，這些都能用 Crossplane 的聲明式方式實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apiVersion:&amp;nbsp;&lt;span style="color:#dd1144"&gt;ops.crossplane.io/v1alpha1&lt;/span&gt;
kind:&lt;span style="color:#dd1144"&gt;CronOperation&lt;/span&gt;
metadata:
name:&lt;span style="color:#dd1144"&gt;weekly-db-maintenance&lt;/span&gt;
spec:
schedule:&lt;span style="color:#dd1144"&gt;"0 2 * * 0"&lt;/span&gt;&lt;em&gt;# Sundays at 2 AM&lt;/em&gt;
operationTemplate:
&amp;nbsp; &amp;nbsp;&amp;nbsp;spec:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pipeline:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span style="color:#990073"&gt;-&lt;/span&gt;step:&lt;span style="color:#dd1144"&gt;upgrade&lt;/span&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;functionRef:
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;name:&lt;span style="color:#dd1144"&gt;function-database-upgrade&lt;/span&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;input:
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;apiVersion:&lt;span style="color:#dd1144"&gt;fn.crossplane.io/v1beta1&lt;/span&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;kind:&lt;span style="color:#dd1144"&gt;UpgradeInput&lt;/span&gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;maxDowntime:&lt;span style="color:#dd1144"&gt;5m&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;還推出了 WatchOperation，用於事件驅動自動化。&lt;/p&gt; 
&lt;h4&gt;只安裝所需資源&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;之前安裝 AWS Provider 會加載 100+ 個 CRD，API 服務器壓力大。雖然早就意識到問題，但解決方案複雜。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;2.0 引入了 ManagedResourceDefinitions（MRDs）和激活策略，優雅解決這個難題：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;apiVersion:&amp;nbsp;&lt;span style="color:#dd1144"&gt;apiextensions.crossplane.io/v1alpha1&lt;/span&gt;
kind:&lt;span style="color:#dd1144"&gt;ManagedResourceActivationPolicy&lt;/span&gt;
metadata:
name:&lt;span style="color:#dd1144"&gt;aws-essentials&lt;/span&gt;
spec:
activate:
&lt;span style="color:#990073"&gt;-&lt;/span&gt;&lt;span style="color:#dd1144"&gt;instances.rds.m.aws.crossplane.io&lt;/span&gt;
&lt;span style="color:#990073"&gt;-&lt;/span&gt;&lt;span style="color:#dd1144"&gt;buckets.s3.m.aws.crossplane.io&lt;/span&gt;
&lt;span style="color:#990073"&gt;-&lt;/span&gt;&lt;span style="color:#dd1144"&gt;"*.ec2.m.aws.crossplane.io"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;這樣不僅減輕 API 服務器負擔，還讓團隊清楚平台支持哪些雲資源。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;「構建 Crossplane 2.0 過程很艱難。我們棄用了當初看似重要、但實際增加複雜度的功能。基於社區反饋重構核心 API。最重要的是，讓 Crossplane 更像原生 Kubernetes，因為平台團隊一直這麼告訴我們。&lt;/p&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;工程量巨大。重構核心控制器，重新設計組合引擎支持任意 Kubernetes 資源，打造全新操作和 Provider 管理系統。但這次發佈更像是理念的轉變：Crossplane 不只是管理基礎設施，而是賦能平台團隊構建完整的開發者體驗。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;2.0 版本對大多數 v1.x 配置保持兼容。你已有的組合、Provider、複合資源繼續有效。新項目建議直接用 v2 模式。現有項目可以逐步遷移，沒必要着急。v1 API 還會持續支持，直到社區不再需要。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;公告稱，Crossplane 2.0 只是開始。開發團隊正着手增強可觀察性、改進組合調試工具，強化與雲原生生態的集成。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367080/crossplane-2-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367080/crossplane-2-0-released</guid>
      <pubDate>Mon, 18 Aug 2025 02:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Qwen Chat 正式發佈 Windows 版桌面端應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊發佈了適用於 Windows 系統的 Qwen Chat 桌面版應用。&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://qwen.ai/download&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="734" src="https://static.oschina.net/uploads/space/2025/0818/192124_WWIt_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1038" src="https://static.oschina.net/uploads/space/2025/0818/192158_OMZi_2720166.png" width="1909" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows 版 Qwen Chat 桌面端集成了 Qwen Chat 的全部功能，並新增了對 MCP（Model Context Protocol）的支持，用戶可以通過運行 MCP Servers 來提升工作效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367001</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367001</guid>
      <pubDate>Sun, 17 Aug 2025 11:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 命令行工具 Cursor CLI 集成 MCP 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cursor 命令行工具 Cursor CLI 近日發佈更新，帶來了多項實用功能，進一步提升了終端開發的體驗和效率&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;@符號引用&lt;/strong&gt;：現在你可以直接在提示詞中使用 @ 符號來引用文件和目錄，AI 可以精準地定位上下文，這對於大型項目和複雜的文件操作尤其有用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;審查模式 (Review Mode)&lt;/strong&gt;:通過 Ctrl+R 快捷鍵，可以進入一個可視化的審查界面，清晰地查看 AI 對代碼的修改。這讓代碼審查變得前所未有的直觀和高效。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;/compress 命令&lt;/strong&gt;：這個新命令可以一鍵釋放上下文窗口的空間，優化長對話中的性能和相關性，確保 AI 始終能聚焦在最重要的信息上。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCPs 支持&lt;/strong&gt;：現在 CLI 也支持 MCPs，這意味着你可以利用更豐富的擴展能力來完成複雜任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="982" src="https://static.oschina.net/uploads/space/2025/0818/190643_waza_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次更新還對用戶體驗和性能做了一些改進，例如現在顯示 Token 計數，支持 AGENTS.md 和 CLAUDE.md（為了兼容 Claude Code）文件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-de60b8ab05a32ba9549f7fa100f6895787d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;https://cursor.com/cn/cli&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366998</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366998</guid>
      <pubDate>Sun, 17 Aug 2025 11:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程獨角獸 Cognition 獲近 5 億美元新融資，估值達 98 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fcognition-cinches-about-500-million-to-advance-ai-code-generation-business-f65f71a9" target="_blank"&gt;據報道&lt;/a&gt;，AI 編程獨角獸 Cognition 在新一輪融資中獲得了近 5 億美元，使其估值達到 98 億美元。&lt;/p&gt; 
&lt;p&gt;Cognition 成立於 2023 年，由三位國際信息學奧林匹克（IOI）金牌得主 Scott Wu、Steven Hao 和 Walden Yan 聯合創立。&lt;/p&gt; 
&lt;p&gt;Cognition 的核心產品是被稱為首個能自主編程的&lt;a href="https://www.oschina.net/news/282895/cognition-labs-devin" target="_blank"&gt;「AI 程序員」Devin&lt;/a&gt;。今年 7 月，&lt;a href="https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf" target="_blank"&gt;Cognition 收購了 Windsurf&lt;/a&gt;。在本次最新融資之前，Cognition 已籌集了 3 億美元，投資者包括 8VC、Avenir Growth Capital 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;被收購的 Windsurf 截至今年 7 月的年收入已達到 8200 萬美元，擁有超過 350 家企業客戶和數十萬日活躍用戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366994</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366994</guid>
      <pubDate>Sun, 17 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手高級副總裁蓋坤兼任可靈 AI 技術部負責人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手宣佈高級副總裁蓋坤兼任可靈 AI 技術部負責人，繼續向 CEO 程一笑彙報，進一步強化可靈 AI 在快手戰略中的地位。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/183846_pqqc_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，蓋坤自 2020 年加入快手後，主導推薦算法、視頻生成大模型等技術研發，並推動可靈 AI 成為全球首個對標 Sora 的開放視頻生成模型。此次兼任技術負責人，體現快手對可靈 AI 「技術驅動」 戰略的重視。&lt;/p&gt; 
&lt;p&gt;公開信息顯示，蓋坤本科與博士均畢業於清華大學，研究方向為識別與智能系統。2020 年，蓋坤正式加入快手，主導內容理解應用、推薦大模型及視頻生成大模型的技術佈局，推動算法、應用與商業模式的協同創新。2024 年 6 月，蓋坤帶領團隊研發推出全球首個用戶可用的 DiT 視頻生成模型 —— 可靈 AI 。&lt;/p&gt; 
&lt;p&gt;內部人士分析，蓋坤深耕算法技術多年，作為可靈 AI 團隊的靈魂人物，此次兼任可靈 AI 技術負責人，顯現出可靈 AI 在快手大模型整體戰略中的重要地位，也意味着 「技術驅動」 戰略，將在很長一段時間內主導着可靈 AI 的發展。&lt;/p&gt; 
&lt;p&gt;自上線以來，可靈 AI 已迭代升級 30 餘次，在全球擁有超過 4500 萬用戶，累計生成超 2 億個視頻和 4 億張圖片，服務超過 2 萬家企業客戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366988</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366988</guid>
      <pubDate>Sun, 17 Aug 2025 10:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 技術被濫用成「退款神器」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;據央視新聞報道，近期，電商平台出現一種新型惡意退款行為:部分買家利用人工智能工具偽造商品損壞圖片，申請「僅退款」，導致商家遭受貨款和運費的雙重損失。這一現象引起廣泛關注，揭示了 AI 技術被濫用所帶來的新挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家們在社交平台吐槽，買家利用 AI 將完好無損的商品，如衣物、杯子或玩具，通過「偽毀損」處理，使其在圖片上呈現出碎裂或有瑕疵的狀態。這些偽造的圖片逼真，讓商家難辨真偽。更令人沮喪的是，即使商家察覺到是假圖，部分電商平台的自動審核機制仍可能通過退款申請，使得商家在沒有收回商品的情況下，被迫退還貨款。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="300" src="https://oscimg.oschina.net/oscnet/up-6f9ecd233181d9dac72df712c5ff273ef4b.png" width="186" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;針對這種行為，法律專家指出，利用 AI 偽造圖片騙取退款的行為已涉嫌違法。這不僅違背了《民法典》中的誠實信用原則，構成民事欺詐，還可能觸犯《治安管理處罰法》。如果騙取金額達到或超過 3000 元，甚至可能構成《刑法》規定的詐騙罪。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;面對這一挑戰，專業人士呼籲監管部門、電商平台和商家採取多方面措施共同應對。&lt;span&gt;監管部門應完善法律法規，在《電子商務法》中增設保護商家權益的條款，並明確惡意退款行為的法律後果。同時，強制推行 AI 生成內容標識，並對刪除或篡改標識的行為進行處罰。此外，建議建立跨平台的用戶消費信用機制，將惡意行為納入個人徵信，從根本上限制其線上活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;電商平台需要強化審核機制，減少對 AI 客服的依賴，增加人工審核投入，並延長審查時間，給商家提供充足的舉證機會。技術方面，平台應加大投入，利用技術手段驗證圖片與實物的匹配性，從源頭攔截偽造內容。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家也需積極自保，優化售後流程，要求買家提供清晰、完整的退款證據，並通過對打包發貨全過程錄像等方式，留存商品質量證據。若發現惡意行為，應及時向平台反映，情節嚴重時可直接向公安機關報案，維護自身合法權益。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 技術的初衷是提質增效，但當它被用於不法目的時，對商業生態的破壞力不容小覷。只有多方聯動，才能有效遏制這種新型網絡欺詐，重建消費者與商家之間的信任。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366985</guid>
      <pubDate>Sun, 17 Aug 2025 10:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元 3D 世界模型推出 Lite 版本，支持消費級顯卡部署</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元 3D 世界模型 1.0 於 7 月發佈並開源，據稱是業界首個開源併兼容傳統 CG 管線的可漫遊世界生成模型。&lt;/p&gt; 
&lt;p&gt;為了讓更多開發者能便捷部署使用混元 3D 世界模型，混元團隊近日全新推出 Lite 版本，大幅降低運行顯存開銷，支持消費級顯卡部署。&lt;/p&gt; 
&lt;p&gt;官網地址：https://3d.hunyuan.tencent.com/sceneTo3DGithub&lt;br&gt; 項目地址：https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0&lt;br&gt; Hugging Face 模型地址：https://huggingface.co/tencent/HunyuanWorld-1&lt;br&gt; 技術報告地址：https://arxiv.org/abs/2507.21809&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/175917_MwWM_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了實現對消費級硬件的兼容，該模型採用了多項關鍵技術優化。首先，通過動態 FP8 量化技術，模型的顯存（VRAM）需求從 26GB 降低至 17GB 以下，降幅達 35%，使其能夠在消費級 GPU 上流暢運行而不犧牲性能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366980</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366980</guid>
      <pubDate>Sun, 17 Aug 2025 09:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>科學島團隊提出醫療大模型智能體決策框架 FRAME</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，中國科學院合肥物質院智能所丁增輝研究員聯合華南理工大學靳戰鵬教授團隊，提出一種醫療大模型智能體決策框架 FRAME。相關研究工作「FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights」被第 63 屆國際計算語言學年會錄用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;探尋新的醫療洞見和決策方法是輔助醫學研究的前沿熱點，大語言模型（LLM）的快速發展為該領域研究提供了重大機遇，但在知識整合與質量保證方面仍面臨嚴峻挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研究團隊提出的 FRAME (Feedback-Refined Agent Methodology) 框架，旨在通過迭代式優化和結構化反饋來提升醫學洞見性能。該方法包含三大核心創新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;一是構建結構化數據集：通過迭代優化，將醫學文獻分解為核心研究要素，構建精細化數據集；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;二是搭建「生成-評估-反思」三方智能體架構：集成了生成（Generator）、評估（Evaluator）和反思（Reflector）智能體，通過指標驅動的反饋循環，逐步提升內容質量；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;三是形成綜合評估體系：結合了統計學指標與人工基準，對生成內容進行全方位評測。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="235" src="https://oscimg.oschina.net/oscnet/up-c4c2ee2c274c4fc91ddacb0f45d89761419.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對比實驗結果顯示，相較於傳統方法，FRAME 框架在運用多種大語言模型提升醫學洞見性能方面效果顯著，在 DeepSeek V3 上平均提升 9.91%，在 GPT-4o Mini 上也取得了同等級別的改進。同時，人工評估也證實了利用 FRAME 智能生成的醫療決策質量已能媲美人類水平，尤其在凝練未來研究方向方面表現突出。相關研究成果表明，所構建的 FRAME 框架，能夠自動生成高標準的醫學研究方案，高效輔助醫學研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="148" src="https://oscimg.oschina.net/oscnet/up-23eebf4bcebc7f140ee46b4658956f09096.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366974</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366974</guid>
      <pubDate>Sun, 17 Aug 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
