<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 29 Apr 2025 07:37:33 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>GPT-4o 出現「諂媚煩人」傾向，突變「賽博舔狗」，奧爾特曼稱在一週內修復</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席執行官 Sam Altman 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1916625892123742290&quot; target=&quot;_blank&quot;&gt;發文&lt;/a&gt;&lt;/u&gt;，回應了有關用戶近期反饋關於 GPT-4o 情感的問題。他表示，最新版 GPT-4o 在最近幾次更新後出現了「過度諂媚」的交互傾向，並承諾將在一週內推出修復方案。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;856&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0429/145130_2663_2720166.png&quot; width=&quot;1284&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/346982/openai-updated-gpt-4o&quot;&gt;OpenAI 發行説明顯示&lt;/a&gt;&lt;/u&gt;，GPT-4o 在 3 月 27 日迎來了全面更新，而且在 4 月 25 日發佈了進一步的更新，重點改進其記憶存儲時機的選擇機制，並顯著增強其在科學、技術、工程及數學（STEM）領域的問題解決能力。OpenAI 在此期間對 GPT-4o 的對話響應模式進行了細微調整，使其在交互中更加主動，並能更精準地引導對話達成有效結論。&lt;/p&gt; 
&lt;p&gt;也就是在此次更新後，GPT-4o 表現出了令人不悅的「諂媚」屬性。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1460&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0429/145535_Oqjk_2720166.png&quot; width=&quot;1332&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;比如下面這個例子，網友聲稱自己想要打造一個永動機，結果得到了 GPT-4o 一本正經的無腦誇讚，物理學常識也被按在地上摩擦。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-56bb98433f09aeb7e7c9f1f21df233954b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這與學術研究發現的 LLM「諂媚傾向」（Sycophancy）高度吻合 —— 模型為獲得用戶認可，可能違背事實或倫理準則。從用戶實測反饋看，該問題具體表現為：過度使用情感化表達、對錯誤前提缺乏質疑、以及為迎合用戶偏好而犧牲回答準確性，例如在涉及爭議性話題時，模型更傾向於附和用戶觀點，這樣一來雖然能為用戶提供更多的情緒價值但也失去了作為 AI 的中立立場。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;推薦閲讀：&lt;a href=&quot;https://www.oschina.net/news/334508/large-language-models-show-concerning&quot; target=&quot;news&quot;&gt;大語言模型顯示出令人擔憂的「奉承」用戶傾向&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347339</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347339</guid>
            <pubDate>Tue, 29 Apr 2025 06:56:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Spring Cloud Data Flow 未來僅限商業版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，Spring 官方宣佈 &lt;strong&gt;Spring Cloud Data Flow&lt;/strong&gt;、&lt;strong&gt;Spring Cloud Deployer&lt;/strong&gt; 和 &lt;strong&gt;Spring Statemachine&lt;/strong&gt; 將不再作為開源項目進行維護。從此以後，這些工具的未來版本只會對 Tanzu Spring 商業客戶開放。&lt;/p&gt; 
&lt;p&gt;目前最後的開源版本分別是：Spring Cloud Data Flow 2.11.x、Spring Cloud Deployer 2.9.x 和 Spring Statemachine 4.0.x。這一變化不會影響其他 Spring 開源項目或現有開源版本對用戶的支持義務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Spring Cloud Data Flow 的歷史與未來&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spring Cloud Data Flow 起源於八年前的 Spring XD，專注於批處理與流式工作負載的編排。多年來，憑藉客戶的高度認可，該項目取得了顯著成效。為了實現持續發展，Spring 決定將其轉為純商業產品，以更好地滿足企業用戶的需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;為何做出這一決定？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;根據官方説明，大多數 Spring Cloud Data Flow 的使用場景都源自 Tanzu 企業客戶，而開源社區的使用及貢獻量極為有限。近兩年，Spring Cloud Data Flow 的維護幾乎完全由 Tanzu 的研發團隊承擔，這與其他活躍且擁有廣泛社區貢獻的 Spring 項目形成鮮明對比。Spring Statemachine 和 Spring Cloud Deployer 的使用模式也與之類似，主要通過與 Spring Cloud Data Flow 的集成得到驅動。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更專注的未來&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spring 表示，維持開源項目與商業產品的雙重需求所需的巨大成本不再合理，因此此舉將使團隊能夠集中資源，為用戶提供更有價值的服務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;現有用戶的支持與展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對 Tanzu 商業客戶而言，Spring Cloud Data Flow 最新補丁版本 2.11.7 已上線，並在 Spring Enterprise 工件庫中提供。同時，基於 2.11.7 的 Spring Cloud Data Flow Tile 1.14.5 和 Kubernetes 發行版 1.6.5 也已發佈。預計今年秋季會推出基於 Spring Boot 3.5 的新產品版本。&lt;/p&gt; 
&lt;p&gt;儘管如此，Spring 開源生態仍然活躍，60 多個完全支持的開源項目、數十位提交者以及上百位社區貢獻者共同推動了 Spring 的持續發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347318/spring-cloud-data-flow-commercial</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347318/spring-cloud-data-flow-commercial</guid>
            <pubDate>Mon, 28 Apr 2025 06:13:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>OpenAI 更新 ChatGPT 搜索功能，周搜索量達 10 億次</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 今天對 ChatGPT 搜索進行了大更新，對網購搜索進行了大幅度優化。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0429/113444_5DgM_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;現在，搜索的產品可以直接顯示詳情、價格以及用戶評價，並且可以直接跳轉到購買鏈接，例如，你想購買一個新的平板電腦，可以在 ChatGPT 完成所有參數比對，並跳轉到亞馬遜購買。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-732cc10c9a539fd31f67d4cf7db52314e46.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體更新如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;購物體驗：ChatGPT 中購物變得更簡單、更快捷，方便查找、比較和購買產品。 
  &lt;ul&gt; 
   &lt;li&gt;優化產品推薦結果，提升商品相關性和展示效果&lt;/li&gt; 
   &lt;li&gt;可視化呈現，包括產品介紹、實時價格和用戶評價&lt;/li&gt; 
   &lt;li&gt;用戶可點擊購買鏈接直接達到購買頁面&lt;/li&gt; 
   &lt;li&gt;官方強調，所有商品搜索結果保持獨立客觀，並非廣告植入&lt;/li&gt; 
   &lt;li&gt;購物體驗的更新今天開始向所有可使用 ChatGPT 的地區的 Plus、Pro、免費及未登錄用戶，預計幾天內完成部署&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;引用功能更靠譜：一個回答可以引用多個來源；高亮顯示，超清晰地告訴你引用了哪部分內容。&lt;/li&gt; 
 &lt;li&gt;搜索界面優化：熱門搜索趨勢；自動補全搜索建議。&lt;/li&gt; 
 &lt;li&gt;WhatsApp 一鍵搜索：給 + 1-800-242-8478 發消息，就能實時獲取各種信息：如體育比分、熱點新聞。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同時，OpenAI 同時還表示，ChatGPT 搜索已經成為 OpenAI 最重要功能之一，僅過去一週使用量就超過 10 億次，成為最受歡迎且增長最快的功能之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347296</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347296</guid>
            <pubDate>Mon, 28 Apr 2025 03:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>前月之暗面海外產品負責人推出 AI 編程平台「Yourware」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據藍鯨新聞此前報道，由前月之暗面海外產品 Noisee 創始人明超平發起的 AI Coding 項目「新言意碼」已完成兩輪融資，而在近日，明超平在 AI 產品方向的新動作悄悄推進中。&lt;/p&gt; 
&lt;p&gt;據博主「四木相對論」爆料，明超平團隊近期悄悄上線新的 AI 產品，名為「Yourware」，定位 Vibe Coder‘s Instagram。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0429/102635_rdHV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據博主介紹，Yourware 功能主要有一鍵部署網頁、展示 AI 編程用例，以及一個包含各種用戶展示形成的社區。博主還表示，AI Coding 社區也正是此前傳言明超平團隊要做的業務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b9497e7ba7d26ff874a63e5cbeac994d3b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2516&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0429/102624_QOIq_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此前消息顯示，「新言意碼」上述的兩輪融資，令其估值已達到 8000 萬美元。此次融資吸引了包括五源資本、高榕資本、真格基金、高瓴創投和 IDG 資本等多家一線基金參與了投資。&lt;/p&gt; 
&lt;p&gt;值得一提的是，有投資人表示，因 2024 年基礎模型能力取得巨大進展，因此國內外 AI Coding 項目再次火熱，同時其預測，AI Coding 在 2025 年將成為一個投資熱點。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347278</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347278</guid>
            <pubDate>Mon, 28 Apr 2025 02:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Dora-rs：下一代機器人開發框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#404040; margin-left:0; margin-right:0; text-align:start&quot;&gt;在&lt;strong&gt;AI&lt;/strong&gt;與機器人技術深度融合的今天，傳統機器人框架的性能瓶頸和開發效率問題日益凸顯。&lt;strong&gt;dora-rs（Dataflow Oriented Robotics Architecture）&lt;/strong&gt;應運而生，成為一款基於&lt;strong&gt;Rust&lt;/strong&gt;語言的高性能、現代化機器人框架。其核心目標是通過數據流驅動的設計範式，解決機器人開發中低效通信、跨語言集成困難等問題，並在性能上實現對&lt;strong&gt;ROS/ROS2&lt;/strong&gt;等傳統框架的超越。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;一、技術架構：數據流驅動與模塊化設計&lt;/h2&gt; 
&lt;h3&gt;1.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;數據流模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#404040; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;dora-rs&lt;/strong&gt;採用&lt;strong&gt;有向圖數據流範式&lt;/strong&gt;，將機器人應用建模為節點（&lt;strong&gt;Node&lt;/strong&gt;）和邊（&lt;strong&gt;Edge&lt;/strong&gt;）組成的網絡。節點代表獨立任務（如傳感器處理、運動控制），邊定義數據流向，支持動態組合與分佈式部署。這種設計使得系統模塊化程度高，開發者可通過 YAML 配置文件快速調整數據流邏輯，無需修改底層代碼。&lt;/p&gt; 
&lt;h3&gt;2.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;核心組件&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;節點（Node）&lt;/strong&gt;：獨立進程，通過共享內存或&lt;strong&gt;TCP&lt;/strong&gt;通信，支持&lt;strong&gt;Python&lt;/strong&gt;、&lt;strong&gt;Rust&lt;/strong&gt;、&lt;strong&gt;C/C++&lt;/strong&gt;等多種語言實現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;算子（Operators）&lt;/strong&gt;：輕量級協作組件，由運行時調度，支持優先級任務和本地截止時間管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;協調器（Coordinator）&lt;/strong&gt;：負責解析數據流配置、部署節點，並監控運行狀態，支持集羣管理與自動擴縮容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;通信機制&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;零拷貝傳輸&lt;/strong&gt;：基於自研共享內存服務器和&lt;strong&gt;Apache Arrow&lt;/strong&gt;內存格式，跨進程傳遞數據時避免拷貝開銷，單機通信延遲低至 4.49ms（40MB 數據）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;跨平台支持&lt;/strong&gt;：本地通信採用共享內存，分佈式場景通過&lt;strong&gt;Zenoh&lt;/strong&gt;中間件或 TCP 實現，兼容&lt;strong&gt;Windows、Linux、macOS&lt;/strong&gt;及&lt;strong&gt;ARM&lt;/strong&gt;架構。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;二、性能優勢：突破傳統框架瓶頸&lt;/h2&gt; 
&lt;h3&gt;1.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;速度對比&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Python 接口&lt;/strong&gt;：傳輸 40MB 數據時，&lt;strong&gt;dora-rs&lt;/strong&gt;耗時 8.94ms，比&lt;strong&gt;ROS2 Python&lt;/strong&gt;快 17 倍。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Rust/C++接口&lt;/strong&gt;：與&lt;strong&gt;ROS2 C++&lt;/strong&gt;性能相當（4.49ms），但通過零拷貝設計進一步降低資源佔用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;技術優化&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Apache Arrow 集成&lt;/strong&gt;：列式存儲格式支持跨語言高效數據交換，無需序列化，尤其適合&lt;strong&gt;AI&lt;/strong&gt;模型與機器人系統的實時交互。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;熱重載功能&lt;/strong&gt;：&lt;strong&gt;Python&lt;/strong&gt;代碼修改後無需重啓節點，保持狀態不變，顯著提升調試效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;三、應用場景：從實驗室到工業落地&lt;/h2&gt; 
&lt;h3&gt;1.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;機器人控制與導航&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;支持運動規劃、避障算法（如路徑規劃庫）及傳感器數據處理，適用於工業自動化與倉儲機器人。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;自動駕駛與仿真&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;與&lt;strong&gt;Carla&lt;/strong&gt;仿真系統深度集成，提供基線算法開發環境。例如，&lt;strong&gt;dora-drives&lt;/strong&gt;套件為自動駕駛開發者提供從仿真到真實車輛的代碼無縫遷移能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;具身智能&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;結合大語言模型，實現自然語言指令到機器人動作的轉化。典型案例包括基於大疆&lt;strong&gt;RoboMaster&lt;/strong&gt;的具身智能項目，通過&lt;strong&gt;dora-rs&lt;/strong&gt;框架將多模態模型與硬件控制高效結合。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;四、生態系統與社區支持&lt;/h2&gt; 
&lt;h3&gt;1.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;多語言兼容&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Python 優先&lt;/strong&gt;：提供簡潔&lt;strong&gt;API&lt;/strong&gt;，方便 AI 開發者快速原型開發，同時支持&lt;strong&gt;Rust&lt;/strong&gt;的高性能需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;跨語言互操作&lt;/strong&gt;：通過&lt;strong&gt;PyO3&lt;/strong&gt;等工具實現&lt;strong&gt;Rust-Python&lt;/strong&gt;無縫綁定，並利用&lt;strong&gt;Arrow&lt;/strong&gt;格式解決跨語言數據交換的性能損耗問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;工具鏈完善&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;CLI 工具&lt;/strong&gt;：支持一鍵安裝（&lt;code&gt;pip install dora-cli&lt;/code&gt;或&lt;code&gt;cargo install dora-cli&lt;/code&gt;），內置示例數據流和調試工具。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;可視化與日誌&lt;/strong&gt;：集成&lt;strong&gt;Rust&lt;/strong&gt;開發的&lt;strong&gt;rerun&lt;/strong&gt;實現實時可觀測性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;社區驅動&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;開源社區活躍，2024 年&lt;strong&gt;GOSIM Workshop&lt;/strong&gt;曾專題探討其技術細節。項目已進入開放原子基金會，已經舉辦第一期具身智能機器人大賽，推動行業應用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;五、全國產化解決方案與中文社區的建設&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Dora&lt;/strong&gt;技術與&lt;strong&gt;OpenHarmony&lt;/strong&gt;深入合作，&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;中文社區可依託&lt;strong&gt;OpenHarmony&lt;/strong&gt;的國產化生態，提供&lt;/span&gt;&lt;strong&gt;硬件兼容性適配指南&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;（如&lt;/span&gt;昇騰&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;、傳感器接口），降低開發者硬件接入門檻。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;針對中文開發者偏好，強化&lt;strong&gt;Dora API&lt;/strong&gt;的文檔本地化，&lt;strong&gt;Python&lt;/strong&gt;可通過優化&lt;strong&gt;PyO3&lt;/strong&gt;與&lt;strong&gt;Rust-Python&lt;/strong&gt;互操作性。參考&lt;strong&gt;Hadoop&lt;/strong&gt;中文社區的經驗，開發&lt;/span&gt;&lt;strong&gt;中文版 CLI 工具&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;，集成一鍵部署、調試插件等功能，簡化開發流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;strong&gt;Dora 中文社區&lt;/strong&gt;提供中文版&lt;strong&gt;Dora SDK&lt;/strong&gt;&lt;/span&gt;、教學視頻、開源項目及模板等。&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#404040&quot;&gt;聯合高校和機器人企業，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;舉辦開發者大賽，提供硬件支持與商業孵化機會。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#ffffff; color:#404040&quot;&gt;開發適配兒童、學生教育的交互式應用，結閤中文學習資源，吸引教育領域開發者。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;dora-rs&lt;/strong&gt;正持續優化其通信層設計，計劃引入零拷貝&lt;strong&gt;GPU IPC&lt;/strong&gt;技術，並擴展對&lt;strong&gt;ROS2&lt;/strong&gt;橋接的穩定性支持。隨着具身智能和邊緣計算的發展，其低延遲、高併發的特性將更受青睞。對於開發者而言，掌握&lt;strong&gt;dora-rs&lt;/strong&gt;不僅是擁抱&lt;strong&gt;Rust&lt;/strong&gt;生態的契機，更是參與機器人技術革新的關鍵一步。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Dora-rs&lt;/strong&gt;官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdora-rs.ai&quot; target=&quot;_blank&quot;&gt;https://dora-rs.ai/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdora-rs%2Fdora&quot; target=&quot;_blank&quot;&gt;https://github.com/dora-rs/dora&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Dora 中文社區&lt;/strong&gt;官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdoracc.com&quot; target=&quot;_blank&quot;&gt;https://doracc.com/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347272</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347272</guid>
            <pubDate>Mon, 28 Apr 2025 02:16:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Qwen3 正式發佈！模力方舟首發上線體驗，昇騰算力全面適配</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 4 月 29 日，Qwen 家族新成員 Qwen3 正式發佈，包含多種模型版本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 模型類型與參數&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MoE 模型&lt;/strong&gt;：有 Qwen3-235B-A22B（總參數 2350 億，激活參數 220 億）和 Qwen3-30B-A3B（總參數 300 億，激活參數 30 億）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;密集模型&lt;/strong&gt;：包括 Qwen3-32B、14B、8B、4B、1.7B、0.6B，均為 Apache 2.0 開源協議。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 上下文長度：&lt;/strong&gt;密集模型中，0.6B、1.7B、4B 為 32K，8B 及以上為 128K；MoE 模型均為 128K。&lt;/p&gt; 
&lt;p&gt;模力方舟上的昇騰算力已為您準備好首批&lt;code&gt;0.6B&lt;/code&gt;、&lt;code&gt;8B&lt;/code&gt;、&lt;code&gt;30B&lt;/code&gt;三款模型，其中 30B 為 Mixture-of-Experts（MoE）模型，覆蓋從輕量部署到高性能推理的多元應用需求，助力開發者輕鬆擁抱新一代大模型能力。&lt;/p&gt; 
&lt;p&gt;在線體驗：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen3-30B-A3B&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen3-30B-A3B&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;全面升級的 Qwen3 模型性能表現&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. 基準測試結果&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Qwen3-235B-A22B&lt;/strong&gt;：在 ArenaHard（95.6）、AIME&#39;24（85.7）、LiveCodeBench v5（70.7）等測試中，優於 DeepSeek-R1、o1、Grok-3 等模型，僅在 AIME&#39;25（81.5）略低於 Gemini-2.5-Pro（86.7）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Qwen3-30B-A3B&lt;/strong&gt;：在 ArenaHard（91.0）、AIME&#39;24（80.4）等測試中，超越 QwQ-32B（激活參數為其 10 倍）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Qwen3-4B&lt;/strong&gt;：性能可與 Qwen2.5-72B-Instruct 媲美，如在 ArenaHard 中為 76.6，Qwen2.5-72B-Instruct 為 81.2。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 優勢領域：&lt;/strong&gt;在編碼（如 CodeForces Elo Rating）、數學（AIME 系列）、多語言（MultilF 8 Languages）任務中表現突出。&lt;/p&gt; 
&lt;h2&gt;Qwen3 關鍵特性&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. 混合思維模式&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;思考模式&lt;/strong&gt;：適合複雜問題，支持逐步推理，性能隨計算預算（token 量）提升而線性增長。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;非思考模式&lt;/strong&gt;：響應快速，適用於簡單任務，可通過參數 enable_thinking 或指令 /no_think / /think 動態切換。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 多語言支持&lt;/strong&gt;：覆蓋 119 種語言和方言，包括印歐語系、漢藏語系、阿拉伯語、日語、韓語等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 增強的代理能力&lt;/strong&gt;：優化了編碼和工具調用能力，推薦搭配 Qwen-Agent 使用，支持 MCP 協議和自定義工具集成。&lt;/p&gt; 
&lt;h2&gt;Qwen3 訓練與架構&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. 預訓練數據&lt;/strong&gt;：使用 36 萬億 token，是 Qwen2.5 的 2 倍，涵蓋網頁、PDF 文檔（通過 Qwen2.5-VL 提取文本），並通過 Qwen2.5-Math/Code 生成數學和代碼合成數據。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 訓練階段&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;S1：基於 30 萬億 token、4K 上下文，構建基礎語言能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;S2：增加 STEM、編碼等知識密集型數據，新增 5 萬億 token 訓練。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;S3：使用長上下文數據，將上下文擴展至 32K（最終支持 128K）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 架構優化&lt;/strong&gt;：MoE 模型通過稀疏激活降低計算成本，密集模型參數效率更高，如 Qwen3-4B 性能相當於 Qwen2.5-72B。&lt;/p&gt; 
&lt;p&gt;官方博客：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen3%2F&quot; target=&quot;_blank&quot;&gt;https://qwenlm.github.io/blog/qwen3/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;昇騰加速，釋放 MoE 潛能&lt;/h2&gt; 
&lt;p&gt;此次在模力方舟首發的&lt;code&gt;0.6B&lt;/code&gt;、&lt;code&gt;8B&lt;/code&gt;、&lt;code&gt;30B&lt;/code&gt;三款&lt;code&gt;Qwen3&lt;/code&gt;&amp;nbsp;模型，均基於細粒度專家調度機制，具備更優的推理效率與更低的推理成本。支持最大 256K 上下文長度，統一推理與非推理模式，&lt;strong&gt;靈活應對長文理解、多輪對話、複雜推理與智能 Agent 開發等高階任務&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為釋放&lt;code&gt;Qwen3&lt;/code&gt;的強大性能，模力方舟基於昇騰最新發布的&lt;code&gt;vLLM Ascend v0.8.4rc2&lt;/code&gt;進行適配。新版&lt;code&gt;vLLM Ascend&lt;/code&gt;率先實現&lt;code&gt;Ascend W8A8&lt;/code&gt;量化、&lt;code&gt;DeepSeek&lt;/code&gt;並行機制適配，並啓用&lt;code&gt;PyTorch 2.5.1&lt;/code&gt;及&lt;code&gt;Torch.compile&lt;/code&gt;圖模式特性，在推理性能、兼容性與開發體驗上全面升級，為大模型部署提供了更高效、更專業的基礎能力。&lt;/p&gt; 
&lt;h2&gt;在線體驗 Qwen3&lt;/h2&gt; 
&lt;p&gt;在線體驗 Qwen3 的強大實力：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen3-30B-A3B&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen3-30B-A3B&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;模力方舟的 AI 模型廣場提供了&lt;strong&gt;行業大模型、文本生成、視覺模型、語音多模態、圖像生成與處理、3D 生成、文檔處理/OCR、視頻生成、自動語音識別、語音合成、向量化和重排、代碼生成、風控識別十三大類共 81 款各領域的頂尖開源模型&lt;/strong&gt;的在線體驗和 API 使用。通過購買模型資源包，即可通過極低的價格即可盡享眾多主流模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0429/101254_xkJL_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347271</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347271</guid>
            <pubDate>Mon, 28 Apr 2025 02:14:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>廣告服務商已嘗試在 AI 回覆中植入廣告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;早在 1999 年，Google 就被譽為「純粹的搜索引擎」，承諾提供簡潔、無廣告的體驗，沒有「門戶垃圾」，這與當時那些雜亂無章的搜索網站截然不同（見下圖）。&lt;/p&gt; 
&lt;p&gt;這項服務最初誕生於斯坦福大學，名為 BackRub，由拉里·佩奇和謝爾蓋·布林創立，最初他們迴避廣告，認為廣告可能存在利益衝突，降低搜索質量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d045e59c1698a9524e8623f706b6cfc417f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;圖片來源：u/Plenty_Objective8392&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;多年來，Google 徹底改變了其商業模式。儘管最初反對廣告，但為了將其迅速流行的搜索引擎貨幣化，Google 於 2000 年推出了 AdWords，並迅速發展成為按點擊付費的巨頭。最初只是簡單的側邊文字廣告，後來發展成為深度融入搜索結果頁面的廣告，使 Google 成為一家以廣告為主要收入來源的廣告巨頭，有時甚至讓用戶覺得搜索結果頁面「充斥着廣告」。&lt;/p&gt; 
&lt;p&gt;隨後，ChatGPT 在 2022 年底火爆上線。這款對話式人工智能提供直接答案而非鏈接列表，對 Google 基於鏈接的廣告模式構成了重大挑戰。ChatGPT 的威脅足以在 Google 內部引發明顯的緊迫感，&lt;/p&gt; 
&lt;p&gt;據報道，這觸發了內部警報，並加快了將自己的生成式人工智能推向公眾的時間表。只需看看 Google 首席執行官 Sundar Pichai 在 2023 年 Google I/O 大會上（即 ChatGPT 推出幾個月後）提到人工智能的次數就知道了；活動結束後的統計顯示，主題演講中提到人工智能的次數遠超一百，他反覆強調的次數也因此成為了一個病毒式傳播的 meme。&lt;/p&gt; 
&lt;p&gt;據英國《金融時報》報道，廣告集團和科技初創公司已經迅速意識到了這一轉變。他們正在積極開發新工具，幫助品牌確保自己出現在人工智能生成的搜索結果中，例如 OpenAI 的 ChatGPT、Anthropic 的 Claude、Google 自己的 AI Overviews 以及最近推出的 AI Mode。&lt;/p&gt; 
&lt;p&gt;這種高度關注源於生成式人工智能產品的興起，它們正迅速成為數百萬人在線搜索信息的主要方式。研究突顯了這一趨勢；諮詢公司貝恩的一項研究發現，目前 80% 的消費者至少 40% 的搜索依賴人工智能生成的搜索結果。這種依賴顯著減少了自然網絡流量，可能高達 25%，因為現在大約 60% 的搜索最終沒有用戶點擊進入傳統網站。這對 Google 的主要搜索業務構成了長期威脅，因為該業務嚴重依賴這些點擊來投放廣告。&lt;/p&gt; 
&lt;p&gt;Profound 和 Brandtech 等公司已進軍這一新領域，為品牌開發軟件。這些工具可以監控品牌被人工智能服務提及或呈現的頻率。更巧妙的是，它們採用一種類似於探測人工智能「大腦」的方法：向聊天機器人輸入大量文本提示，並分析由此產生的情緒和提及次數。這項技術可以預測人工智能模型提及品牌的偏好或可能性，從而創建排名系統。&lt;/p&gt; 
&lt;p&gt;然後，代理商利用這些分析結果為其客戶（例如金融科技公司 Ramp、招聘網站 Indeed 和威士忌製造商 Chivas Brothers）提供建議，幫助他們如何最好地從人工智能模型中獲得有利的提及。&lt;/p&gt; 
&lt;p&gt;這超越了傳統的搜索引擎優化（SEO），後者專注於讓網站在 Google 的鏈接列表中排名靠前。正如 Brandtech 合夥人 Jack Smyth 所説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;這不僅僅是讓你的網站在他們的搜索結果中被索引。這是為了認識到大型語言模型是最終的影響因素。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他的公司甚至創建了一款「模型份額」產品來衡量和指導這項工作。這感覺就像一次範式轉變。正如 Profound 聯合創始人 James Cadwallader 所説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;傳統搜索一直是互聯網歷史上最大的壟斷之一。而現在，城堡的牆壁第一次出現了裂縫。這是一個從 CD 到流媒體的時代。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;挑戰在於，被人工智能提及與網頁排名不同。像 ChatGPT 這樣的人工智能模型使用傳統的網絡搜索，但會評估來源的相關性、可信度和權威性。正如 OpenAI 的 ChatGPT 搜索主管 Adam Fry 所解釋的那樣，由於用戶會提出更細緻入微的問題，人工智能在「傳統搜索之上增加了一層智能」。另一家人工智能驅動的搜索引擎 Perplexity 的聯合創始人 Denis Yarats 也強調了這一點：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;大模型（LLM）理解的內容更豐富，能夠更加細緻入微。他們可以發現矛盾之處，或者發現信息是否有誤導性……所以，這比審查鏈接要徹底得多。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他補充道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;成為 SEO 的目標要困難得多，因為唯一真正的策略是儘可能相關並提供好的內容。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;儘管傳統搜索引擎優化 (SEO) 與人工智能 (AI) 結合存在固有困難，但廣告界仍在尋找進入該領域的途徑。例如，Perplexity 已在試行贊助「問題」，作為用戶查詢後的建議後續內容，這清楚地表明，人工智能對話流中的直接廣告開始出現。&lt;/p&gt; 
&lt;p&gt;儘管如此，值得注意的是，儘管這些人工智能變革被認為對 Google 的生存構成威脅，但 Google 的核心搜索和廣告業務仍展現出非凡的實力。週四，Google 母公司 Alphabet 宣佈，其搜索和其他業務在第一季度增長了近 10%，達到 507 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F9cc6cc0b-759f-4b8e-9ed1-9e32ad0fe22f&quot; target=&quot;_blank&quot;&gt;據《金融時報》報道&lt;/a&gt;，這一強勁業績給投資者帶來了一些安慰，儘管他們仍對 Google 自己的 Gemini 聊天機器人或 AI 概覽可能開始減少其廣告機器用戶點擊量的跡象保持警惕。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347188</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347188</guid>
            <pubDate>Sun, 27 Apr 2025 10:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Easy MQTT：極簡高效的 MQTT 服務器，助力物聯網與實時通信</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h1&gt;💎 Easy MQTT：極簡高效的 MQTT 服務器，助力物聯網與實時通信&lt;/h1&gt; 
&lt;p&gt;在萬物互聯的時代，高效、輕量的通信協議是構建實時系統的核心。Easy MQTT 應運而生——這是一款專為開發者設計的開源 MQTT 服務器，以「極簡」為核心理念，旨在為物聯網、工業自動化、即時消息等場景提供穩定可靠的消息傳輸服務。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌟 為何選擇 Easy MQTT？&lt;/h2&gt; 
&lt;h4&gt;1.極簡設計，開箱即用&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;僅需一條命令即可啓動服務，配置文件精簡清晰，無需複雜學習成本。&lt;/li&gt; 
 &lt;li&gt;支持單機與集羣部署，輕鬆應對從測試環境到生產環境的無縫擴展。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.全協議支持，功能強大&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MQTT v3.1.1 完整兼容：&lt;/strong&gt; 確保與各類客戶端設備無縫對接。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket 子協議：&lt;/strong&gt; 支持瀏覽器端直接通信，賦能 Web 應用實時交互。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL/TLS 加密：&lt;/strong&gt; 為 TCP 和 WebSocket 連接提供安全保障，滿足企業級安全需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3.靈活擴展與高可用性&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持數據持久化，消息不丟失，保障關鍵業務連續性。&lt;/li&gt; 
 &lt;li&gt;通過外部接口實現動態鑑權，輕鬆集成現有用戶系統。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚀 三步開啓你的首個 MQTT 服務&lt;/h2&gt; 
&lt;h4&gt;1.下載安裝&lt;/h4&gt; 
&lt;p&gt;訪問&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt/releases&quot;&gt; Releases &lt;/a&gt;獲取最新編譯包，解壓即用。&lt;/p&gt; 
&lt;h4&gt;2.一鍵啓動&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;sh bin/start.sh -c conf/conf.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;無需複雜配置，服務即刻運行！&lt;/p&gt; 
&lt;h4&gt;3.按需擴展&lt;/h4&gt; 
&lt;p&gt;參考文檔快速開啓集羣模式、SSL 加密或 WebSocket 支持，滿足不同場景需求。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;📚 豐富文檔，開發者友好&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;入門指南：&lt;/strong&gt; 必要參數説明、快速部署集羣。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;進階功能：&lt;/strong&gt; 動態鑑權配置、SSL 加密實戰、WebSocket 集成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;開源透明：&lt;/strong&gt; 基於友好許可證開源，代碼完全開放，社區驅動持續優化。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌍 適用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;物聯網（IoT）：&lt;/strong&gt; 海量設備消息高效分發與狀態同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實時監控：&lt;/strong&gt; 工業傳感器數據實時採集與預警。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;即時通訊：&lt;/strong&gt; 低延遲聊天、推送服務搭建。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能家居：&lt;/strong&gt; 跨平台設備互聯互通。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;✨ 加入開發者社區&lt;/h2&gt; 
&lt;p&gt;Easy MQTT 不僅是一個工具，更是一個活躍的開源項目。我們歡迎開發者：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;提交 Issue：&lt;/strong&gt; 反饋問題或建議。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;貢獻代碼：&lt;/strong&gt; 共同完善功能與性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分享案例：&lt;/strong&gt; 你的實踐經驗可能幫助更多人！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;立即訪問&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt&quot;&gt; Gitee 倉庫&lt;/a&gt;，探索更多可能！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;保持簡單，專注核心。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy MQTT——讓消息通信從未如此輕鬆！ 💡&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347161</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347161</guid>
            <pubDate>Sun, 27 Apr 2025 09:24:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>乾貨分享｜MaxKB 智能問數方案及步驟詳解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;DeepSeek-R1 的發佈掀起了 AI 智能變革的浪潮。在過去幾個月裏，MaxKB 開源企業級 AI 助手已經幫助大量企業和組織快速落地了 DeepSeek，讓 AI 在不同的行業土壤中產生持續、可度量的業務價值。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB（&lt;em&gt;github.com/1Panel-dev/MaxKB&lt;/em&gt;） 可以為本地部署的 DeepSeek 構建一個 Chatbox，也就是一個智能會話的界面，類似於個人用&lt;span style=&quot;color:#3e3e3e&quot;&gt;戶直接與 DeepSeek 進行對話。MaxKB 提供的 Chatbox 可以方便地嵌入到企業 OA 系統和業務系統，有&lt;/span&gt;效保證使用的便捷性和安全性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;另外一方面，MaxKB 能夠激活企業中長期積累的知識體系，使其智能化並面向內外部用戶提供服務。MaxKB 可以讓企業內部的私有知識文檔快速獲得智能問答能力，面向企業的員工、合作伙伴和客戶提供 AI 助手服務。MaxKB 還提供開箱即用的 RAG（檢索增強生成）技術，能夠結合私有知識庫提升問答效果，降低大模型幻覺。MaxKB 同時支持目前最為流行的 MCP（Model Context Protocol，模型上下文協議），為用戶靈活調用 MCP 工具提供了充分的便利性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;在幫助企業落地 DeepSeek 的過程中，MaxKB 開源項目組發現很多企業都有「智能問數」的需求，即允許員工使用自然語言查詢方法從數據庫中檢索結構化數據，並展示成直觀的圖表。本文將通過一個具體的例子（查詢學生成績），詳細講解如何通過「MaxKB+數據庫 MCP Server+QuickChart MCP Server」實現智能問數的功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;方案概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;本方案以「學生考試成績管理系統」為例進行説明，此係統包含了教師信息、學生信息、年級班級信息、考試成績等信息內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB 智能問數方案邏輯圖如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-677afe248c4bc21a4673cece1d7f054bf95.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 智能問數方案的具體實現步驟為：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8109f772552d6f912cba1c991c9e32063e5.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 的智能問數方案包含以下三大關鍵步驟：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 數據準備：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;包含數據表詳細的 DDL（Data Definition Language，數據定義語言）信息和正確的 SQL 示例，以便大模型能夠更好地理解和使用數據；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MCP Server 準備：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要提前準備對應數據庫的 MCP Server 和生成圖表的 MCP Server。此階段可以採用 1Panel 開源面板來統一部署和運維 MCP Server；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MaxKB 智能問數應用設計：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;主要包含在 MaxKB 中如何通過高級應用編排實現智能問數的效果。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟一：數據準備&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 數據準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;提前準備「學生考試成績管理系統」數據表詳細的 DDL 信息，需要確保所有數據表的 DDL 信息完整且準確，包括字段類型、約束條件等。DDL 信息後續需要導入到 MaxKB 知識庫中，如果當前數據表不具備或者不清晰，具體可以參考下圖進行完整性補充。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//33da69631a928c1ef526abec61e7be4c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. SQL 示例準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;基於日常工作遇到的查詢需求，我們需要提前準備多樣化的 SQL 示例（本 Demo 數量為 100 條 SQL 查詢示例），同時需要保證和測試這些 SQL 的準確性。後續我們需要將這些 SQL 查詢示例導入到 MaxKB 知識庫中。具體準備過程可以參考下圖，採用 Execl 方式進行繪製和編寫。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//254a0d9ebffbf99a16f05e7d6bdb42dc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟二：MCP Server 準備&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 數據庫 MCP Server 準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;本 Demo 採用的是 MySQL 數據庫，因此需要提前準備 MySQL 的 MCP Server。在這裏我們使用了 Github 上的 DBHub 開源項目（&lt;/span&gt;&lt;em&gt;https://github.com/bytebase/dbhub&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）部署 MySQL 的 MCP Server。此項目同時還支持 PostgreSQL、SQL Server 等數據庫。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;DBHub 的部署方式也很簡單：進入 1Panel 應用商店，在「AI/大模型」分類下找到 DBHub 應用，點擊安裝即可（注意：需確保 1Panel 服務器已放行 SSE 端口）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8646b2f5170ee0842388fa0c759040a9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c9e9d6c80bf5c4927095faa721090ee9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;部署完成後，我們使用&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;curl&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式進行快速驗證，返回如下信息即為部署成功：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//96ae01cede2c92012bf006663e16c5a5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. 生成圖表 MCP Server 準備&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;生成圖表的步驟採用「QuickChart.io+Quickchart-MCP-Server」來完成。QuickChart 項目（&lt;/span&gt;&lt;em&gt;https://github.com/typpo/quickchart&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）支持用戶通過提供數據和樣式參數來創建多種類型的圖表，支持從柱狀圖到速度表等多種圖表類型，並且提供生成圖表 URL 和下載圖表圖片的功能。Quickchart-MCP-Server 項目（&lt;/span&gt;&lt;em&gt;https://github.com/GongRzhe/Quickchart-MCP-Server&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）則提供了 QuickChart 的 MCP 服務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要注意的是，由於 Quickchart-MCP-Server 項目沒有提供 SSE 訪問方式，所以不同於 DBHub 項目，我們需要在 1Panel 開源面板（&lt;/span&gt;&lt;em&gt;github.com/1Panel-dev&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）的 MCP 模塊中進行部署。具體操作也非常簡單：打開 1Panel 開源面板，依次選擇「AI」→「MCP」→「創建 MCP 服務器」→「導入 MCP Server 配置」，導入如下 Quickchart-MCP-Server 的命令配置即可：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;npx&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-y&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;@gongrzhe/quickchart-mcp-server&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ]
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d44553e72c27e91f36642cf441897e3c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同時，注意開啓外部端口訪問和地址。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dd401c3801083a35b7f682f1689861ed.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;等待幾秒後，可以看到 1Panel 中顯示 QuickChart 的 MCP Server 已經啓動。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ba9faa8484ab00d6b66e047597b3bbf7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;接下來，我們使用&lt;/span&gt;&lt;em&gt;curl&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式進行快速驗證，返回如下信息即顯示 QuickChart 的 MCP Server 已經部署成功。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//08cb2aa0a6cc9361e1abb31be6ae42c5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步驟三：MaxKB 智能問數應用設計&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 將準備好的表信息和 SQL 示例導入知識庫&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建表信息知識庫，導入表信息，並將每一張表的信息作為一個分段，具體如下圖顯示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//89c36f37e816e17a73a6576bdc12b69e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;為了提高後續檢索的相似度，建議同時為每一張表創建問題，問題主要為此表的名稱（此操作的意義為：比如用戶提問「7 年級一共有多少老師」，知識庫中能夠準確地匹配出班級表和教師表兩張表）。問題需要儘量地覆蓋用戶對不同對象的稱呼，比如教師又可以稱為老師，具體如下圖所示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//4c3a7e21192a0f4231f1e7b66e5ea61d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e031374e7578dd3da598a1c524fbd111.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建示例 SQL 庫，導入 SQL 示例，一個 SQL 示例作為一個分段。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d5bb5fcb292c98e5dfbe688bfa875c9a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同理，為不同的 SQL 示例創建問題，如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dcf9c4ad8c3a5b394a25301be7579892.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;2. MaxKB 智能問數編排&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 創建空白的高級編排，名稱自取即可&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//92ea1ef49418a8343efedb2bbb4f6e2d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 添加兩個知識庫檢索節點，用於用戶檢索表信息和示例 SQL。同時設置相似度為 0.4，引用分段數 TOP 為 6。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;em&gt;&lt;span style=&quot;color:#f50a0a&quot;&gt;注意：此處很重要也很關鍵，需要按照不同的應用場景和數據庫進行大量的測試，最終選擇合適的相似度和引用分段數 TOP 值。建議首先從相似度 0.4，引用分段數 TOP 值為 6 開始測試效果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//0e141fc5a2bbb1827dd1e8107100d094.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 添加 AI 對話節點，配置 AI 模型（注意要選擇支持 MCP 的模型，比如 DeepSeek-Chat 或者 Qwen-Plus），同時在 AI 對話節點中配置 MCP Server：&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a3b0503b13a1e2b18fbc6d69793140b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;配置在步驟一&lt;span style=&quot;color:#3e3e3e&quot;&gt;中已經部署完成的 MCP Server 的 Config 信息，具體的配置信息如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.110:18003/quickchart-server&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp; &amp;nbsp;&amp;nbsp;},
&amp;nbsp;&amp;nbsp;&quot;mcp-mariadb&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;timeout&quot;:&amp;nbsp;180,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.106:8080/sse&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp;&amp;nbsp;}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 設置 AI 對話節點的角色提示詞&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 角色
你是一位專業的數據分析專家，精通 MYSQL 數據庫 SQL 語言，能夠熟練運用 mcp-mysql 工具進行 SQL 驗證和查詢，還能使用 quickchart-server 工具繪製圖表，並對相關數據進行深入分析和解釋。
&amp;nbsp;
## 技能
### 技能 1: 生成並驗證 SQL
1.&amp;nbsp;基於用戶提出的問題，結合已知信息，生成 SQL 語句。
2.&amp;nbsp;使用 mcp-mysql 工具對每次生成的 SQL 進行驗證和查詢。若 SQL 出現錯誤，需嘗試三次不同的 SQL 表述。
3.&amp;nbsp;記錄每次 SQL 驗證和查詢的結果。
&amp;nbsp;
### 技能 2: 繪製圖表
1.&amp;nbsp;根據用戶需求以及生成的 SQL 查詢結果，利用 quickchart-server 工具生成相關圖表。
2.&amp;nbsp;確保生成的圖表能夠清晰、美觀的展示相關數據。
&amp;nbsp;
### 技能 3: 數據的分析和解釋
1.&amp;nbsp;對 SQL 查詢得到的數據進行詳細分析，結合用戶的問題，找出數據的關鍵特徵和趨勢。
2.&amp;nbsp;以通俗易懂的語言向用戶解釋數據所代表的含義以及數據與用戶問題之間的關係。
&amp;nbsp;
## 限制
-&amp;nbsp;僅圍繞與生成 SQL、利用工具查詢驗證、生成圖片以及數據的分析和解釋相關的內容進行回答，拒絕回答不涉及這些內容的話題。
-&amp;nbsp;生成的 SQL 需符合 MYSQL 語法規範，生成的圖片應符合數據展示要求，分析和解釋需要基於真實的查詢結果。
-&amp;nbsp;分析和解釋部分應儘量簡潔明瞭，突出重點。
-&amp;nbsp;操作過程嚴格按照上述技能要求執行，不得隨意更改工具使用方式。&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 設置 AI 對話節點的用戶提示詞&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#&amp;nbsp;已知信息
## 表信息:
{{表信息.data}}
&amp;nbsp;
## 參考示例 SQL:
{{示例 SQL.data}}
&amp;nbsp;
# 用戶問題：
{{開始.question}}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;效果驗證和總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在 MaxKB 中按步驟設置完成後，可以進行調試測試，調試測試通過後方可進行應用發佈。驗證發現，大模型會按照我們設定的提示詞，根據已經給出的表信息和 SQL 示例，自行編寫 SQL 語句，調用 MySQL MCP Server 進行查詢和驗證結果，調用 QuickChart MCP Server 進行圖表繪製，最後給出數據分析。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題一：每個班級學生佔比圖&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5e39814c8fd6af863c37cb4ac511e58d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題二：每個年級有多少名學生？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//882fbb0e90ed8a0122ed8e56850bde29.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題三：哪個老師教的學生最多？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f6438262d3eebf8a78d2ef3283618d62.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 問題四：成績排名前 10 的學生名字、分數和班級&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fde855130bbdb7cb5d14228dd5bc2a99.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;由此可見，MaxKB 通過其強大的 RAG 技術和 MCP 調用能力，能夠完整且準確地實現智能問數的場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;RAG 技術結合了信息檢索和文本生成的優勢，使得系統能夠在理解用戶查詢的基礎上，從大量數據中檢索相關信息，並且生成準確、相關的 SQL 查詢語言。而 MCP 工具則提供了強大的 SQL 查數驗數能力和動態的圖表繪製能力，從而為智能問數系統提供了堅實的數據基礎。最終，通過 MaxKB 的高級編排設計能力允許用戶靈活地構建和優化智能問數流程，可以有效地確保系統能夠適用於不同的業務需求和問數場景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347155</guid>
            <pubDate>Sun, 27 Apr 2025 08:56:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>MCP 協議：為什麼 Streamable HTTP 是最佳選擇？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：靜擇&lt;/p&gt; 
&lt;p&gt;MCP（Model Context Protocol）協議是一個用於 AI 模型和工具之間通信的標準協議。隨着 AI 應用變得越來越複雜並被廣泛部署，原有的通信機制面臨着一系列挑戰。近期 MCP 倉庫的 PR #206【1】 引入了一個全新的 Streamable HTTP 傳輸層替代原有的 HTTP+SSE 傳輸層。本文將詳細分析該協議的技術細節和實際優勢。&lt;/p&gt; 
&lt;h2&gt;要點速覽&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 相比 HTTP + SSE 具有更好的穩定性，在高併發場景下表現更優。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 在性能方面相比 HTTP + SSE 具有明顯優勢，響應時間更短且更穩定。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 客戶端實現相比 HTTP + SSE 更簡單，代碼量更少，維護成本更低。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;為什麼選擇 Streamable HTTP?&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5481fb16dc28298c0a673f410c34a3f94aa.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;HTTP + SSE 存在的問題&lt;/h3&gt; 
&lt;p&gt;HTTP+SSE 的傳輸過程實現中，客戶端和服務器通過兩個主要渠道進行通信：（1）HTTP 請求/響應：客戶端通過標準的 HTTP 請求向服務器發送消息。（2）服務器發送事件（SSE）：服務器通過專門的 /sse 端點向客戶端推送消息，這就導致存在下面三個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;服務器必須維護長連接&lt;/strong&gt;，在高併發情況下會導致顯著的資源消耗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服務器消息只能通過 SSE 傳遞&lt;/strong&gt;，造成了不必要的複雜性和開銷。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基礎架構兼容性&lt;/strong&gt;，許多現有的網絡基礎架構可能無法正確處理長期的 SSE 連接。企業防火牆可能會強制終止超時連接，導致服務不可靠。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Streamable HTTP 的改進&lt;/h3&gt; 
&lt;p&gt;Streamable HTTP 是 MCP 協議的一次重要升級，通過下面的改進解決了原有 HTTP + SSE 傳輸方式的多個關鍵問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;統一端點&lt;/strong&gt;：移除了專門建立連接的 /sse 端點，將所有通信整合到統一的端點。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;按需流式傳輸&lt;/strong&gt;：服務器可以靈活選擇返回標準 HTTP 響應或通過 SSE 流式返回。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;狀態管理&lt;/strong&gt;：引入 session 機制以支持狀態管理和恢復。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;HTTP + SSE vs Streamable HTTP&lt;/h2&gt; 
&lt;p&gt;下面通過實際應用場景中穩定性，性能和客戶端複雜度三個角度對比説明 Streamable HTTP 相比 HTTP + SSE 的優勢，AI 網關 Higress 目前已經支持了 Streamable HTTP 協議，通過 MCP 官方 Python SDK 的樣例 Server 部署了一個 HTTP + SSE 協議的 MCP Server，通過 Higress 部署了一個 Streamable HTTP 協議的 MCP Server。&lt;/p&gt; 
&lt;h2&gt;穩定性對比&lt;/h2&gt; 
&lt;h3&gt;TCP 連接數對比&lt;/h3&gt; 
&lt;p&gt;利用 Python 程序模擬 1000 個用戶同時併發訪問遠程的 MCP Server 並調用獲取工具列表，圖中可以看出 SSE Server 的 SSE 連接無法複用且需要長期維護，高併發的需求也會帶來 TCP 連接數的突增，而 Streamable HTTP 協議則可以直接返回響應，多個請求可以複用同一個 TCP 連接，TCP 連接數最高只到幾十條，並且整體執行時間也只有 SSE Server 的四分之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a4e31878c274ea0c458008bf465e66c083d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 1000 個併發用戶的測試場景下，Higress 部署的 Streamable HTTP 方案的 TCP 連接數明顯低於 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：需要維持大量長連接，TCP 連接數隨時間持續增長&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：按需建立連接，TCP 連接數維持在較低水平&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;請求成功率對比&lt;/h3&gt; 
&lt;p&gt;實際應用場景中進程級別通常會限制最大連接數，linux 默認通常是 1024。利用 Python 程序模擬不同數量的用戶訪問遠程的 MCP Server 並調用獲取工具列表，SSE Server 在併發請求數到達最大連接數限制後，成功率會極速下降，大量的併發請求無法建立新的 SSE 連接而訪問失敗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9bbc20f87d17e336829e190eb0a3fea4283.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在不同併發用戶數下的請求成功率測試中，Higress 部署的 Streamable HTTP 的成功率顯著高於 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：隨着併發用戶數增加，成功率顯著下降&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：即使在高併發場景下仍能保持較高的請求成功率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;性能對比&lt;/h2&gt; 
&lt;p&gt;這裏對比的是社區 Python 版本的 GitHub MCP Server【2】 和 Higress MCP 市場的 GitHub MCP Server&lt;/p&gt; 
&lt;p&gt;利用 Python 程序模擬不同數量的用戶同時併發訪問遠程的 MCP Server 並調用獲取工具列表，並統計調用返回響應的時間，圖中給出的響應時間對比為對數刻度，SSE Server 在併發用戶數量較多時平均響應時間會從 0.0018s 顯著增加到 1.5112s，而 Higress 部署的 Streamable HTTP Server 則依然維持在 0.0075s 的響應時間，也得益於 Higress 生產級的性能相比於 Python Starlette 框架。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-58effeb73a37e20e3eb89e93cd7efde59d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;性能測試結果顯示，Higress 部署的 Streamable HTTP 在響應時間方面具有明顯優勢：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 的平均響應時間更短，響應時間波動較小，隨併發用戶數增加，響應時間增長更平&lt;/li&gt; 
 &lt;li&gt;HTTP + SSE 的平均響應時間更長，在高併發場景下響應時間波動較大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;客戶端複雜度對比&lt;/h2&gt; 
&lt;p&gt;Streamable HTTP 支持無狀態的服務和有狀態的服務，目前的大部分場景無狀態的 Streamable HTTP 的可以解決，通過對比兩種傳輸方案的客戶端實現代碼，可以直觀地看到無狀態的 Streamable HTTP 的客戶端實現簡潔性。&lt;/p&gt; 
&lt;h4&gt;HTTP + SSE 客戶端樣例代碼&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class SSEClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}
        self.event_source = None
        self.endpoint = None

        async def connect(self):
            # 1. 建立 SSE 連接
            async with aiohttp.ClientSession(headers=self.headers) as session:
                self.event_source = await session.get(self.url)

                # 2. 處理連接事件
                print(&#39;SSE connection established&#39;)

                # 3. 處理消息事件
                async for line in self.event_source.content:
                    if line:
                        message = json.loads(line)
                        await self.handle_message(message)

                        # 4. 處理錯誤和重連
                        if self.event_source.status != 200:
                            print(f&#39;SSE error: {self.event_source.status}&#39;)
                            await self.reconnect()

        async def send(self, message: dict):
            # 需要額外的 POST 請求發送消息
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.post(self.endpoint, json=message) as response:
                    return await response.json()

                async def handle_message(self, message: dict):
                    # 處理接收到的消息
                    print(f&#39;Received message: {message}&#39;)

    async def reconnect(self):
        # 實現重連邏輯
        print(&#39;Attempting to reconnect...&#39;)
        await self.connect()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Streamable HTTP 客戶端樣例代碼&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class StreamableHTTPClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}

    async def send(self, message: dict):
        # 1. 發送 POST 請求
        async with aiohttp.ClientSession(headers=self.headers) as session:
            async with session.post( self.url, json=message,
                headers={&#39;Content-Type&#39;: &#39;application/json&#39;}
            ) as response:
                # 2. 處理響應
                if response.status == 200:
                    return await response.json()
                else:
                    raise Exception(f&#39;HTTP error: {response.status}&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從代碼對比可以看出：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;複雜度：Streamable HTTP 無需處理連接維護、重連等複雜邏輯&lt;/li&gt; 
 &lt;li&gt;可維護性：Streamable HTTP 代碼結構更清晰，更易於維護和調試&lt;/li&gt; 
 &lt;li&gt;錯誤處理：Streamable HTTP 的錯誤處理更直接，無需考慮連接狀態&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;【1】PR&lt;/p&gt; 
&lt;p&gt;#206&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fmodelcontextprotocol%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/modelcontextprotocol/pull/206&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【2】GitHub MCP&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&quot;&gt;Serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18261770</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18261770</guid>
            <pubDate>Sun, 27 Apr 2025 08:33:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>一行代碼讓 iPhone 變磚</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;一名安全研究人員近日披露了 iOS 系統中一個基於&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Fdarwinnotify%2Fdarwin-notification-api&quot; target=&quot;_blank&quot;&gt;Darwin 通知機制&lt;/a&gt;的高危系統漏洞，攻擊者可通過沙盒應用向系統發送特定通知，誘導設備進入「恢復模式」並觸發無限重啓循環。&lt;/p&gt; 
&lt;p&gt;這名研究人員僅通過一個簡單的代碼行（notify_post）就觸發了嚴重的系統漏洞，並通過 Widget 擴展機制實現持續攻擊，且能繞過 iOS 沙盒限制。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-objectivec&quot;&gt;notify_post(&quot;com.apple.MobileSync.BackupAgent.RestoreStarted&quot;)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;該漏洞影響所有依賴 Darwin 通知的系統服務，包括但不限於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;鎖屏/控制中心狀態管理&lt;/li&gt; 
 &lt;li&gt;網絡連接策略切換&lt;/li&gt; 
 &lt;li&gt;外接設備檢測邏輯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/155229_ccfm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，該漏洞已被蘋果修復，作者因此獲得了蘋果提供的 17,500 美元獎勵。 &lt;/p&gt; 
&lt;p&gt;作者整理的時間線：&lt;/p&gt; 
&lt;p&gt;2024 年 6 月 26 日：向蘋果公司發送初始報告&lt;br&gt; 2024 年 9 月 27 日：收到蘋果公司的消息，告知正在採取措施進行緩解&lt;br&gt; 2025 年 1 月 28 日：問題已標記為已解決，並確認了獎金資格&lt;br&gt; 2025 年 3 月 11 日：漏洞分配編號 CVE-2025-24091，已在 iOS/iPadOS 18.3 中解決&lt;/p&gt; 
&lt;p&gt;獎金金額：17,500 美元&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：《How a Single Line Of Code Could Brick Your iPhone》&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frambo.codes%2Fposts%2F2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&quot; target=&quot;_blank&quot;&gt;https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</guid>
            <pubDate>Sun, 27 Apr 2025 07:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2023 年最熱門的 AI 職位——「提示詞工程師」已過時</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據《華爾街日報》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fthe-hottest-ai-job-of-2023-is-already-obsolete-1961b054&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;，曾被譽為 2023 年最熱門 AI 職位、年薪可達 20 萬美元的「提示工程師」（Prompt Engineer）正迅速降溫。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/144406_aPB5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根據微軟近期一項覆蓋 31 個國家 31,000 名員工的調查，在未來 12 至 18 個月企業考慮增設的新職位中，提示工程師排名倒數第二，遠低於 AI 訓練師、AI 數據專家和 AI 安全專家等職位。&lt;/p&gt; 
&lt;p&gt;所謂提示詞工程，是指設計、開發、測試和優化用於與生成式 AI 模型交互的文本輸入（即「提示詞」），目標是引導 AI 模型生成準確且符合需求的輸出，發揮 AI 模型的潛力。但是，由於 AI 模型固有的不透明性，這種操作的科學性和有效性始終存在疑問，也有很多人藉此營銷、行騙。&lt;/p&gt; 
&lt;p&gt;報道指出，「提示詞工程師」熱度發生變化的核心原因在於，&lt;strong&gt;現代 AI 模型已能更好地理解用戶意圖，甚至在指令不清時主動提問，大大降低了對精心設計提示詞的依賴&lt;/strong&gt;。另一個關鍵因素是企業策略的轉變。相比設立專門職位，許多公司選擇對現有員工提供 AI 工具和培訓，將使用 AI 的能力視為一項基礎技能。&lt;/p&gt; 
&lt;p&gt;招聘市場的實際數據也印證了這一趨勢。儘管在 ChatGPT 面世後，用戶對「提示工程師」的搜索量曾短暫飆升，但企業發佈的實際招聘崗位數量始終極少，搜索熱度也已大幅回落並趨於平穩。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347101</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347101</guid>
            <pubDate>Sun, 27 Apr 2025 06:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟發佈 2025 工作趨勢：每位員工都將成為 Agent 的 「老闆」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟近日在其官網發佈了 2025 年工作趨勢指數報告，分析了來自全球 31 個國家和地區的 31，000 家企業。報告結合了 LinkedIn 勞動力市場趨勢、數萬億個 Microsoft365 的生產力信號以及眾多專家的見解，指出 「人機協作」 模式正在重塑企業架構，催生出一種全新的 「前沿公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-262509e06b372a5030a9fbb7c87f5ba548a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「前沿公司」 是一種新型的組織形式，主要圍繞智能體（Agent）構建，以適應快速變化的商業環境和技術進步。這種公司的核心特點是將人類智慧與智能體相結合，形成高效的團隊，顯著提高生產力和創新能力，並節省工作時間。在這樣的公司中，智能體可以是各種自動化工具或智能助手，執行從數據處理到複雜決策支持的多種任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，隨着智能體的廣泛應用，員工將逐步成為 「Agent 老闆」，他們不僅需要管理和優化這些智能體，還需具備相應的新技能。這意味着未來每位員工都要像初創公司的 CEO 一樣思考如何利用 AI 來提升工作效率。根據調研顯示，67% 的企業領導者表示他們熟悉 Agent 的概念，而這一比例在員工中僅為 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，前沿公司的組織結構也將發生變化，變得更加靈活和以結果為導向。這種新的工作架構會根據業務需求動態調整，靈活組合人類和智能體資源，以實現最佳效果。微軟指出，隨着智能體的加入，未來每位員工都有可能從第一天起就參與到複雜的工作中，甚至一名初級員工也可以藉助 AI 管理整個營銷活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在這個新模式中，企業需要關注人機協作的比例，確保資源的高效利用。同時，管理層需要重構職能，以適應這種人機協作的新趨勢。微軟還提到，員工需要從 「工具使用者」 轉變為 「合作伙伴」，通過與智能體的雙向互動激發創新能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347091</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347091</guid>
            <pubDate>Sun, 27 Apr 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Hyprnote —— 會議專用 AI 記事本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#3c3c43&quot;&gt;Hyprnote 專為會議繁忙的人士打造，是一款&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;適用於連續會議的 AI 記事本。本地優先且可擴展。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;錄並轉錄您的會議&lt;/li&gt;
&lt;li&gt;從原始會議記錄中生成&lt;strong&gt;有力的摘要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;離線&lt;/strong&gt;工作使用&lt;strong&gt;開源模型&lt;/strong&gt;（&lt;em&gt;Whisper&lt;/em&gt;和&lt;em&gt;Llama&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;高度&lt;a href=&quot;https://docs.hyprnote.com/extensions/&quot;&gt;可擴展&lt;/a&gt;，由&lt;a href=&quot;https://docs.hyprnote.com/plugins/&quot;&gt;插件提供支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;div style=&quot;margin-left:auto; margin-right:auto&quot;&gt;
&lt;div style=&quot;margin-right:calc(50% - 678px)&quot;&gt;
&lt;div&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亮點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;增強你的筆記&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨意記下一些東西，Hyprnote 將根據您的備忘錄製作會議記錄。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt=&quot;&quot; height=&quot;391&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/152058_SbVr_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;離線和隱私&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hyprnote 是本地優先的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;392&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151933_5xtQ_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;擴展和插件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就像 VSCode 一樣，可以根據你的情況添加或創建擴展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;382&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151827_6b1U_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://docs.hyprnote.com/extensions/transcript.html&quot;&gt;transcript extension&lt;/a&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&amp;nbsp;&lt;/span&gt;由&amp;nbsp;&lt;a href=&quot;https://docs.hyprnote.com/plugins/listener.html&quot;&gt;listener plugin&lt;/a&gt;&amp;nbsp;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;useEffect&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;channel&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;new&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#953800&quot;&gt;Channel&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;SessionEvent&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;subscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;channel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;onmessage&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;started&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;stopped&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;unsubscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/hyprnote</link>
            <guid isPermaLink="false">https://www.oschina.net/p/hyprnote</guid>
            <pubDate>Sun, 27 Apr 2025 05:53:00 GMT</pubDate>
        </item>
        <item>
            <title>騰訊正式開源跨端框架 Kuikly：基於 Kotlin 創建 Android、iOS、鴻蒙、Web、小程序應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;騰訊跨端框架&amp;nbsp;Kuikly 正式開源。根據官方介紹，Kuikly 是基於 Kotlin Multiplatform 的 UI 與邏輯全面跨端綜合解決方案，由騰訊大前端領域 Oteam（公司級）推出，目的在於提供一套一碼多端、極致易用、動態靈活的全平台高性能開發框架。&lt;/p&gt; 
&lt;p&gt;Kuikly（Kotlin UI Kit，發音同 quickly）使用 Kotlin 開發了聲明式 UI 框架，映射到系統原生控件做渲染，最終用 KMM（Kotlin Multiplatform Mobile）實現跨端。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c10e21f658b9ab50513e216dc7c37cfa28e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雖然是全平台，但目前暫時只開源了 Android 和 iOS，鴻蒙部分 5 月才開源，而 Web 和，小程序暫定是 Q2：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/121851_K8I9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 開源地址：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent-TDS%2FKuiklyUI&quot;&gt;https://github.com/Tencent-TDS/KuiklyUI&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 基於 Kotlin MultiPlatform（KMP）技術，它利用了 KMP 邏輯跨平台的能力，並抽象出通用的跨平台 UI 渲染接口，複用平台的 UI 組件，從而達到 UI 跨平台，具有輕量、高性能、可動態化等優點；同時，KuiklyBase 基建同樣支持邏輯跨端。 讓開發者&lt;strong&gt;可以使用 Kotlin 創建 Android、iOS、鴻蒙、Web、小程序應用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-911df639ea27ac02b452b9a379738d91ddd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/c0981983-cece-4d31-9488-e775586c8881.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;Kuikly 跨端框架系統要求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;iOS 12.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android 5.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HarmonyOS Next 5.0.0 (12) 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kotlin 版本 1.3.10 版本及以上&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkuikly.tds.qq.com%2F%25E7%25AE%2580%25E4%25BB%258B%2Farch.html&quot;&gt;https://kuikly.tds.qq.com/%E7%AE%80%E4%BB%8B/arch.html&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347077/tencent-tds-kuikly</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347077/tencent-tds-kuikly</guid>
            <pubDate>Sun, 27 Apr 2025 04:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>GPUStack v0.6 超重磅更新：vLLM 多機分佈式、昇騰 MindIE 等</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;GPUStack 是一個 100% 開源的模型服務平台&lt;/strong&gt; ，支持 &lt;strong&gt;Linux、Windows 和 macOS&lt;/strong&gt; ，支持 &lt;strong&gt;NVIDIA、AMD、Apple Silicon、昇騰、海光、摩爾線程&lt;/strong&gt; 等 GPU 構建&lt;strong&gt;異構 GPU 集羣&lt;/strong&gt; ，支持 &lt;strong&gt;LLM、多模態、Embedding、Reranker、圖像生成、Speech-to-Text 和 Text-to-Speech&lt;/strong&gt; 模型，支持 &lt;strong&gt;vLLM、MindIE、llama-box&lt;/strong&gt; （&lt;strong&gt;基於 llama.cpp 與 stable-diffusion.cpp&lt;/strong&gt; ）等多種推理引擎與&lt;strong&gt;推理引擎多版本並行&lt;/strong&gt; ，支持&lt;strong&gt;資源自動調度分配、模型故障自動恢復、多機分佈式推理、混合異構推理、推理請求負載均衡、資源與模型監控指標觀測、國產化支持、用戶管理與 API 認證授權等各種企業級特性&lt;/strong&gt; ，提供 &lt;strong&gt;OpenAI 兼容 API 無縫接入 Dify、RAGFlow、FastGPT、MaxKB 等各種上層應用框架&lt;/strong&gt;，是企業建設模型服務平台的理想選擇。&lt;/p&gt; 
&lt;p&gt;GPUStack 一直&lt;strong&gt;致力於以最簡單易用的方式，幫助用戶快速納管異構 GPU 資源並運行所需的 AI 模型，從而支撐 RAG、AI Agents 以及其他生成式 AI 落地場景&lt;/strong&gt;。為用戶打造絕佳的使用體驗是我們始終堅持的目標。最新發布的 v0.6 是迄今為止最重磅的版本，全方位完善了平台的整體功能、性能、穩定性和用戶使用體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPUStack v0.6 版本的核心更新包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;vLLM 多機分佈式推理&lt;/strong&gt;：提供生產級的多機分佈式推理能力，支撐 DeepSeek R1 / V3 等單機 GPU 資源無法運行的超大參數量模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;昇騰 MindIE 支持&lt;/strong&gt;：為昇騰 910B 和 310P 用戶提供內置的 MindIE 推理引擎支持，以提供最佳的模型推理表現。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型兼容性檢測&lt;/strong&gt;：提供對模型是否支持部署的兼容性檢測，目前提供對模型架構支持、操作系統兼容、資源可用性、本地路徑可用性等依賴的實時檢測，後續還會持續加入更多檢測條件，提供更加友好的模型部署體驗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型下載管理&lt;/strong&gt;：支持管理已下載的模型文件、支持以不佔用 GPU 資源分配為前提，發起單機/多機的模型下載任務、支持將本地路徑的模型文件添加到 UI 中進行統一管理。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型故障自動恢復&lt;/strong&gt;：支持模型在發生故障時的自動恢復機制。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;端口暴露優化&lt;/strong&gt;：優化需要暴露的端口範圍，API 入口到模型實例的推理請求統一經過代理轉發，不再需要暴露模型實例端口，降低 96% 以上的端口暴露，並支持用戶自定義。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增強國際化支持&lt;/strong&gt;：GPUStack 用戶遍佈全球上百個國家和地區，本次 GPUStack 社區用戶貢獻了俄語和日語支持，為不同語言的用戶提供更加友好的使用體驗，加速推進 GPUStack 的全球化應用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI / UX 全方位優化&lt;/strong&gt;：全方位的 UI / UX 優化，逐幀打磨，打造業界最好用的模型推理平台。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這一版本總共包含&lt;strong&gt;上百項增強、修復、穩定性改進和用戶體驗優化&lt;/strong&gt;，為用戶的生產落地提供強大的場景支持。&lt;/p&gt; 
&lt;p&gt;有關 &lt;strong&gt;GPUStack&lt;/strong&gt; 的詳細信息，可以訪問：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 倉庫地址: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;https://github.com/gpustack/gpustack&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;GPUStack 用戶文檔: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gpustack.ai&quot; target=&quot;_blank&quot;&gt;https://docs.gpustack.ai&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;重點特性介紹&lt;/h2&gt; 
&lt;h3&gt;vLLM 多機分佈式推理&lt;/h3&gt; 
&lt;p&gt;隨着大語言模型的參數規模不斷提升，傳統單機 GPU 資源已難以滿足推理部署的實際需求。為此，GPUStack 在當前版本中正式支持生產級的 vLLM 多機分佈式推理能力。通過跨主機部署，將模型按張量或按層切分，分佈到多個節點運行，從而實現對超大參數模型（如 DeepSeek R1、DeepSeek V3 等）的推理支持。&lt;/p&gt; 
&lt;p&gt;當前，GPUStack 對以下兩類推理引擎提供分佈式支持：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;llama-box：異構分佈式，適用於研發測試環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持 Linux、Windows 和 macOS 操作系統；&lt;/p&gt; 
&lt;p&gt; • 允許不同操作系統、不同品牌、不同規格的 GPU 混合實現異構分佈式推理；&lt;/p&gt; 
&lt;p&gt; • 可在桌面或輕量服務器上快速構建異構分佈式推理環境；&lt;/p&gt; 
&lt;p&gt; • 更適用於日常研發、模型驗證、兼容性測試等場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;vLLM：同構分佈式，面向生產環境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持在多台 Linux 服務器之間進行同構分佈式推理；&lt;/p&gt; 
&lt;p&gt; • 要求參與節點的硬件環境基本一致（如 GPU 型號、數量、顯存）；&lt;/p&gt; 
&lt;p&gt; • 支持張量並行和流水線並行，具備良好的推理吞吐能力；&lt;/p&gt; 
&lt;p&gt; • 適合生產環境下對高併發、低延遲模型服務的部署需求。&lt;/p&gt; 
&lt;p&gt;通過 vLLM 和 llama-box 的分佈式推理能力，GPUStack 能夠覆蓋&lt;strong&gt;從模型研發驗證到大規模生產部署的完整流程&lt;/strong&gt;。在研發階段，用戶可使用 llama-box 構建靈活的測試集羣；在生產部署階段，則可通過 vLLM 提供穩定可靠的推理服務能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec5d9aef8c8a1a7aeacd7175a0c0e600.png&quot; alt=&quot;model-info&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;昇騰 MindIE 支持&lt;/h3&gt; 
&lt;p&gt;在之前版本中，GPUStack 基於 llama-box 推理引擎初步支持了昇騰 910B 和 310P 芯片的模型推理。然而由於算子支持不全及相關生態不夠完善，實際使用中存在較多限制，例如只支持模型的部分量化精度，在性能和穩定性方面也弱於昇騰官方推理引擎 MindIE。&lt;/p&gt; 
&lt;p&gt;為了提升用戶在昇騰 NPU 上的模型推理體驗，GPUStack 現已內置集成 MindIE 推理引擎，對 910B 和 310P 提供更加穩定且高性能的模型推理能力。&lt;/p&gt; 
&lt;p&gt;MindIE 是昇騰官方推出的高性能深度學習推理框架，具備運行加速、調試調優與快速部署等多項優勢，目前在昇騰硬件上表現最為出色。得益於其較為成熟的軟硬件協同生態，MindIE 已成為在 NPU 上部署推理模型的主流方案。&lt;/p&gt; 
&lt;p&gt;當前，GPUStack 已完成對 MindIE 引擎的初步集成，相比於 llama-box 引擎，在部分場景可以達到數倍的推理速度提升。未來還將持續優化，並探索對更多推理引擎的支持，例如 vLLM（vLLM-Ascend），以滿足在昇騰平台上的多樣化模型推理需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0680304502e35923518c9dcf932256b.png&quot; alt=&quot;image-20250415095544399&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型兼容性檢測&lt;/h3&gt; 
&lt;p&gt;在過往版本中，用戶直接從 Hugging Face 或 ModelScope 搜索任意模型進行部署時，存在一定的失敗可能性。常見原因包括顯存不足、操作系統與推理引擎不兼容、模型架構不被支持、本地路徑配置錯誤等。這些問題不僅浪費時間，還嚴重影響用戶體驗。&lt;/p&gt; 
&lt;p&gt;為瞭解決這一痛點，GPUStack 推出了&lt;strong&gt;模型兼容性檢測機制&lt;/strong&gt;。系統會在部署前自動檢測模型與運行環境的匹配情況，涵蓋模型架構與引擎支持、操作系統兼容性、GPU 資源是否充足、本地路徑是否有效等多個關鍵維度。通過這些檢測，潛在問題能夠被提前識別，並提供清晰提示，幫助用戶避免不必要的部署失敗。&lt;/p&gt; 
&lt;p&gt;我們設定了三個明確的目標：第一，部署前提供清晰的兼容性提示；第二，在滿足條件的情況下將部署成功率提升至 99% 以上；第三，對於特殊需求場景，允許用戶跳過檢測，強制部署，保留靈活性。&lt;/p&gt; 
&lt;p&gt;這項功能特性將持續演進，未來將支持更多檢測項、覆蓋更廣泛的系統環境，不斷完善檢測機制，全面助力用戶在不同平台上實現穩定、高效的模型部署。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fb036e198f11d8e36ec761c749ecca62.png&quot; alt=&quot;image-20250421173053252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下載管理&lt;/h3&gt; 
&lt;p&gt;在模型部署過程中，模型文件的統一管理與高效分發始終是用戶關注的核心問題。以往，模型下載通常依賴於實例啓動時自動觸發，既需佔用 GPU 資源，又常常依賴額外的手動操作才能完成下載；同時，GPUStack 也無法管理用戶預先下載到本地路徑的模型文件，導致部署效率低下，管理體驗不佳。&lt;/p&gt; 
&lt;p&gt;為此，GPUStack 引入了&lt;strong&gt;模型文件下載管理&lt;/strong&gt; 模塊：用戶可在 UI 中為多個目標主機手動發起模型的下載任務，且&lt;strong&gt;無需佔用 GPU 資源&lt;/strong&gt;。各節點上已下載的模型文件也可在 UI 中統一可視化管理與部署，進一步提升了部署的靈活性與效率。&lt;/p&gt; 
&lt;p&gt;同時，GPUStack 還支持將本地已有的模型文件路徑添加到 UI 中進行統一管理，適配私有部署、離線環境等多種使用場景。通過這一模塊，既解決了用戶獨立下載模型文件的需求，也使 GPUStack 能夠更好地支持多機分佈式部署，提升了部署效率與多機協同能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0f873b0ef5ec73c42ae118694f3825ee.png&quot; alt=&quot;image-20250415204131503&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型故障自動恢復&lt;/h3&gt; 
&lt;p&gt;在追求高可用性和穩定性的生產環境中，模型推理服務的穩定性至關重要。為了進一步提升這一點，GPUStack 引入了&lt;strong&gt;模型故障自動恢復機制&lt;/strong&gt;！當模型發生故障時，GPUStack 會自動觸發恢復機制，迅速嘗試重新啓動模型，確保服務不中斷。&lt;/p&gt; 
&lt;p&gt;同時，為了避免過於頻繁的無效重啓，GPUStack 採用了&lt;strong&gt;5 分鐘為上限的指數退避延遲機制&lt;/strong&gt;，在故障持續時逐步延遲重啓，避免系統資源的浪費。總體而言，v0.6 版本提供的模型故障自動恢復機制大幅提升了模型服務的容錯能力，讓生產的模型推理更加穩健！&lt;/p&gt; 
&lt;h3&gt;端口暴露優化&lt;/h3&gt; 
&lt;p&gt;在舊版本架構中，每台 Worker 節點需為每個模型實例開放端口訪問，以供 Server 端進行推理請求的轉發。在用戶大規模使用時暴露了一些問題：由於大量端口需要映射，容器啓停緩慢，且在啓動時容易發生端口衝突；防火牆配置容易遺漏，導致推理請求轉發異常。此外，也不支持用戶自定義端口範圍。&lt;/p&gt; 
&lt;p&gt;為此，我們在 v0.6 版本中重構了端口暴露機制：推理請求從 API 入口到模型實例的鏈路現已通過統一的代理轉發，無需再為每個模型實例開放端口訪問。同時優化了端口分配，將端口暴露範圍壓縮超過 96%，顯著降低部署複雜度和運維風險。同時也支持用戶自定義端口配置，使系統能夠靈活適配不同的網絡環境與安全策略，為用戶帶來更簡單、穩定的部署體驗。&lt;/p&gt; 
&lt;h3&gt;增強國際化支持&lt;/h3&gt; 
&lt;p&gt;目前 GPUStack 的用戶遍佈全球上百個國家和地區，隨着 GPUStack 用戶羣體在全球範圍內的持續擴大，我們致力於為不同語言背景的開發者提供一致、便捷的使用體驗。本次 GPUStack 社區用戶貢獻了&lt;strong&gt;俄語&lt;/strong&gt; 和&lt;strong&gt;日語&lt;/strong&gt;支持，標誌着 GPUStack 在國際化進程中的又一重要里程碑。&lt;/p&gt; 
&lt;p&gt;通過持續拓展多語言能力，GPUStack 為全球社區用戶創造了更加包容與高效的使用體驗。未來，我們將繼續深化本地化支持，為全球用戶提供更全面、更優質的服務體驗，加速推動 AI 應用的全球落地與普及。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8781f64407b5d62f1496d53824097f69.png&quot; alt=&quot;image-20250413233340395&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8e1e428e259bcf52136144df288263a0.png&quot; alt=&quot;image-20250413233303590&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;全方位的 UI / UX 優化&lt;/h3&gt; 
&lt;p&gt;在本次版本中，我們對 UI / UX 進行了全方位優化，從信息展示到交互細節，幾乎每一處都經過精心打磨，力求帶來更流暢、更易用的使用體驗。過去幾個月收集的每一條用戶建議，都是此次優化的重要參考。&lt;/p&gt; 
&lt;p&gt;我們始終堅持一個目標：打造業界最好用的模型推理平台，而 GPUStack 正在持續朝這一目標穩步前進。也正因為有用戶的積極反饋，我們才能不斷迭代優化------如果你有任何建議或想法，歡迎隨時向我們提出，我們會認真評估並持續改進。&lt;/p&gt; 
&lt;h2&gt;參與開源&lt;/h2&gt; 
&lt;p&gt;想要了解更多關於 GPUStack 的信息，可以訪問我們的倉庫地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://github.com/gpustack/gpustack&lt;/strong&gt;&lt;/a&gt;。如果你對 GPUStack 有任何建議，歡迎&lt;strong&gt;提交 GitHub issue&lt;/strong&gt; 。在體驗 &lt;strong&gt;GPUStack&lt;/strong&gt; 或提交 issue 之前，請在我們的 GitHub 倉庫上&lt;strong&gt;點亮 Star&lt;/strong&gt; ⭐️關注我們，也非常歡迎大家一起參與到這個開源項目中！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果覺得對你有幫助，歡迎&lt;strong&gt;點贊&lt;/strong&gt; 、&lt;strong&gt;轉發&lt;/strong&gt; 、&lt;strong&gt;關注&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/gpustack/blog/18260677</link>
            <guid isPermaLink="false">https://my.oschina.net/gpustack/blog/18260677</guid>
            <pubDate>Sun, 27 Apr 2025 03:43:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>得物業務參數配置中心架構綜述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;現狀與痛點&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在目前互聯網飛速發展的今天，企業對用人的要求越來越高，尤其是後端的開發同學大部分精力都要投入在對複雜需求的處理，以及代碼架構，穩定性的工作中，在對比下，簡單且重複的 CRUD 就顯得更加浪費開發資源。目前 scm 供應鏈管理頁面中，存在約 77% 的標準頁面，這些標準頁面裏，還存在着很多類似的參數配置頁面，就是對某一個模型進行增、刪、改、查、導入、導出進行類似的操作，這種開發工作技術含量較低，而且相對耗費人力。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;什麼是業務參數配置中心&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;參數配置中心，是一個能夠通過配置的方式，快速生成前端頁面以及配套增、刪、改、查、導入、導出服務的配置平台，它與得物內部低代碼前端頁面平台 wizard 相互集成，參數配置中心提供後台增刪改查服務，wizard 輸出對應的前端頁面代碼，並可以支持用戶自定義修改。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;使用場景&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;針對讀多寫少的簡單的單表的增刪改查；&lt;/li&gt; 
 &lt;li&gt;業務中需要交給運營來修改的複雜 ark 配置（簡單配置除外），可以嘗試使用業務參數配置中心接入，減少人為修改 JSON 可能產生的錯誤，導致系統無法編譯進而產生故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;比如如下的 JSON：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[{&quot;position&quot;:&quot;1&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;2&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;3&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;4&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;5&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;6&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;7&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;8&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;業務參數配置中心極速體驗&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;後台服務搭建流程，以及數據錄入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據讀取可以通過參數配置中心的 SDK，輸入自己的業務入參以及自己的業務出參，SDK 會自動根據方案下的參數以及用戶的輸入條件，查詢出對應的參數信息：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-95529e5439a558b65e0757f2e1313155752.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從上面的快速體驗裏可以看到很多名詞，你一定有會有下面的疑問：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-964c6ee7e450e7cce90376eddb00b05c04f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、整體架構與原理&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;實現思路&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;首先我們對這種普通的頁面進行初步剖析：頁面中總體包含搜索條件、靜態展示字段以及操作欄，搜索條件一般是靜態字段的子集，並且操作欄的功能一般都類似，所以為了能夠結構化地構造出這樣的頁面，我們可以將靜態展示字段進行進一步抽象：比如元素、維度、參數、方案、參數實例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1adfd37a09e81f9bf0438a2bed718c19a80.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;構成頁面的每一個業務字段，統稱元素，因為有些字段是大家常用的（比如倉庫，品牌，一級類目，省份等），它有自己的字段名稱，以及取值範圍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;維度&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一條記錄一定有能夠標註其唯一性的信息，可能是一個字段或者是多個字段，在參數中心裏，能確定一條記錄唯一性的所有字段就叫做維度，維度這個概念在參數中心裏很重要，它是不可變的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在業務發展過程裏，可以改變值的字段，就叫參數，也可以説一條記錄裏，除了維度，都可以叫做參數。&lt;/p&gt; 
&lt;p&gt;綜合維度和參數，舉個例子，比如商品信息，商品 ID 就是維度，商品售價、折扣率就是參數。或者醫院掛號系統，科室 ID 就是維度，掛號費，出診時間就是參數。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一個參數方案它管理着一個場景下的業務配置，可以簡單理解一個方案就代表着一個頁面，包含了上述我們説的維度以及參數，並且指定了可以指定哪些字段為搜索條件，哪些是必填字段，哪些字段可以多選。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數實例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;描述好方案並生成頁面後，實際產生的業務配置數據，我們稱之為參數實例。&lt;/p&gt; 
&lt;p&gt;經過剛才對頁面元素的解剖，大家會發現搭建一個這樣的頁面，猶如建房子一樣，維度與參數是最基礎的木料，創建方案就是設計建造的過程，參數實例就是一個個真實的房間，所以業務參數配置中心整體產品思路如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54cf2fc71dbf64169277bd863672f638b30.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;整體架構&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;通過上文的介紹，我們介紹了業務參數配置中心最核心的概念，接下來我們看看整體的架構設計。我們針對這些最核心的概念，來設計實現這些業務功能的架構、核心包含領域模型、領域服務、應用服務以及基礎設施層需要的存儲部件，以及外部可以整合的導入導出框架、日誌框架（外部依賴的框架也可以自己實現）、核心的元素維護、方案維護，存儲設計好之後，我們就需要一個 SDK，可以讓用戶訪問到我們的數據。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f29f79f77a54e147851172489afd9765082.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系統的實體關係圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4876084e664581f0f46677ab3e1b89d59d7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過上文我們可以初步瞭解到整體的架構設計，那麼每一個子模塊我們如何實現？接下來我們分析更加細節的原理。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心原理&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如何設計存儲的細節是這個系統的一大挑戰，因為既要兼顧頁面的靈活變動，也要兼顧數據整體的一致性不受影響，同時也要兼顧整體數據的查詢性能，下面的小節列出了所有這些核心的挑戰點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;存儲流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每一個頁面的字段都不一樣，我們是怎麼存儲的？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-072aa230f23621ba48c937b8f7db995c249.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從上面的兩個頁面可以看到，因為頁面的字段變化多端，所以我們的思考是，必須採用抽象存儲的方式來應對，核心用一張，大寬表存儲，其中包含很多抽象列，每一個抽象列在不同的方案下，業務含義不同。&lt;/p&gt; 
&lt;p&gt;同時把方案的元數據：維度、參數、以及功能性設置（如每個字段是否可以刪除，是否需要多選）單獨存儲，每個方案下的大寬表裏的抽象列的業務含義，就存儲在這些元數據表中。&lt;/p&gt; 
&lt;p&gt;同時為了應對大批量的查詢，我們引入了 OLAP 的數據庫，對於在應用內部的單點查詢，我們走 MySQL 實現，如果運營後台針對某個字段做大批量查詢，則可以用 OLAP 數據庫來緩解查詢壓力。&lt;/p&gt; 
&lt;p&gt;下面是存儲的整個過程以及舉例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68a28fece8de3ef9c82fc7843e8110e2a2e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SDK 查詢流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因為在業務參數使用時，各個業務方有自己的業務對象，所以我們在 SDK 中集成了反射的能力，可以避免用戶直接感知到底層的抽象存儲，查詢的流程使用上比較簡單，一共分為三步，第一步為自定義 request，第二步自定義 response，第三步調用 SDK 方法獲取參數實例，比如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;定義 request：&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigRequest implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置類型

  */

 private String configType;

 */***

  * 設備編號

  */

 private String deviceNo;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定義 response&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigResponse implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置類型

  */

 private String configType;

 */***

  * 設備編號

  */

 private String deviceNo;



     */***

  * 配置明細

  */

 private List&amp;lt;CameraConfigDto&amp;gt; configValueList;



     [@Data](https://my.oschina.net/difrik)

 public static class CameraConfigDto implements Serializable {

     private String position;

     */***

      * 白平衡 (Red)

      */

     private BigDecimal red;

     */***

      * 白平衡 (Blue)

      */

     private BigDecimal blue;

     */***

      * 白平衡 (Green)

      */

     private BigDecimal green;

     */***

      * 亮度 (Brightness)

      */

     private BigDecimal brightness;

     */***

      * 自動曝光時間上限 (us)

      */

     private BigDecimal autoExposureTimeUpperLimit;

     */***

      * 採集幀率

      */

     private BigDecimal acquisitionFrameRate;

     */***

      * 增益自動開關 (us)

      */

     private String gainAuto;

     */***

      * 增益自動上限

      */

     private BigDecimal gainAutoUpperLimit;

     */***

      * 增益自動上限

      */

     private BigDecimal gainAutoLowerLimit;

 }
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調用 SDK 的服務方法查詢&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigRequest pinkDeviceCameraConfigRequest = new PinkDeviceCameraConfigRequest();&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setConfigType(&quot;DEVICE_NO&quot;);&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setDeviceNo(&quot;123@LuSun&quot;);&lt;/p&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 單個查詢場景&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigResponse response =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParams(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;,

      pinkDeviceCameraConfigRequest,

      PinkDeviceCameraConfigResponse.class);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 批量查詢場景&lt;/p&gt; &lt;p&gt;PageQueryOption pageQueryOption = new PageQueryOption();&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageIndex(1);&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageSize(200);&lt;/p&gt; &lt;p&gt;PageInfo&amp;lt;PinkDeviceCameraConfigResponse&amp;gt; paramsPage =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParamsPage(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;, 

     pinkDeviceCameraConfigRequest, 

     PinkDeviceCameraConfigResponse.class,

     pageQueryOption);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;獲得結果&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19953d23e8dcd9b90b57575b8fc6c5533ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;整體查詢實現原理如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68822ebba4f5d690e41c18c156dffdad174.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 目前整個服務的性能在 10+ms 左右：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f86b118721761e37edb0d80428c83fa7355.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參數優先級實現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為什麼會有參數優先級這個功能？&lt;/p&gt; 
&lt;p&gt;比如有一個場景，要維護一個供應鏈系統中的補貨參數：安全庫存，低於這個安全庫存的時候，要通知商家進行補貨，整個供應鏈裏有 100 個倉庫，20 個一級類目，200 個二級類目，2000 個三級類目，涉及到 500 個品牌，要維護每一個商品的安全庫存，你會怎麼實現？&lt;/p&gt; 
&lt;p&gt;你一定不會把 100 倉庫_2000 類目_500 品牌 = 1000000000 種可能全都設置一遍參數，對你來説，重點類目，要單獨詳細配置安全庫存，非重點類目可能只需要管控到一級或者二級類目即可，這樣你所需要的配置會大大減少。那麼參數的決策就需要遵循一定的規則，比如:&lt;/p&gt; 
&lt;p&gt;有倉庫+一級類目+二級類目+三級類目，的安全庫存，優先取；&lt;/p&gt; 
&lt;p&gt;如果取不到，則取倉庫+一級類目+二級類目的安全庫存；&lt;/p&gt; 
&lt;p&gt;再取不到，取倉庫+一級類目的安全庫存。&lt;/p&gt; 
&lt;p&gt;比如：&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋 安全庫存 100&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋-運動鞋，安全庫存 500&lt;/p&gt; 
&lt;p&gt;DN 倉，鞋-運動鞋-籃球鞋，安全庫存 1000&lt;/p&gt; 
&lt;p&gt;那如果一個商品是籃球鞋的話，則會命中安全庫存 1000 的規則，如果是登山鞋的話，只能命中運動鞋的規則取 500，如果是高跟鞋，則只能取 100 的安全庫存。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（事實上這種補貨規則要詳細的多，這裏只是方便大家理解需求，並不是真正的參數）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;也就是説，當用戶的入參同時可能命中多條參數的時候，需要通過優先級來判斷應該返回哪個參數。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-92bbffb30b7b6f12d6b8fa4717437f376d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了加速查詢，系統在設計時添加了兩層緩存：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-129d351a3be37ca0cf02b4472de6fcd50e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 當後台數據發生變化時，會將對應的緩存進行失效。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-821ca41cc55e1456a0ad3fb0ba5dc76247f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素多選處理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;維度多選場景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-28b192d9ccc63092c15fcc0f12187ddf449.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;參數多選場景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4a1bdf71195372e13f56ab0aa27813e3ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;既要保證維度唯一，又要保證能正常搜索，以及展示，如何實現？業務參數配置中心引入了一個&quot;組&quot;的概念，是將同屬於一行的參數實例，歸為一個組，這個組是最小的新建、編輯單位。&lt;/p&gt; 
&lt;p&gt;對於新增流程如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd67e7858a3927f9960d4c2d364c0dc4a6a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;對於修改流程，如下圖所示： &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ed29af351bef248291bc76b841bafcedcae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素範圍查詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;頁面中的字段，我們統稱為元素，只要是字段，一定有它的取值範圍，我們平衡了用戶使用成本以及系統性能，將字段取值類型劃分成了四種：&lt;/p&gt; 
&lt;p&gt;1）枚舉類元素&lt;/p&gt; 
&lt;p&gt;2）dubbo 全量接口元素&lt;/p&gt; 
&lt;p&gt;3）dubbo 單點查詢接口元素&lt;/p&gt; 
&lt;p&gt;4）自定義文本元素&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;枚舉元素由用戶手動在頁面創建，一般幾十個以內為佳，創建成本不高，比如經常用到的 &quot;是&quot;，&quot;否&quot;，或者比如單據類型等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 全量接口元素，一般是幾十到上百個的體量，比如一級類目，倉庫等，地址。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 單點查詢接口，一般是幾千到幾萬體量的取值範圍，無法直接在內存裏存儲所有枚舉，比如品牌等。只能通過兩個接口來完成搜索以及數據的展示，比如&quot;品牌 ID &amp;gt;品牌名稱&quot;接口，和 &quot;品牌名稱-&amp;gt;品牌 ID&quot; 接口。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定義文本，非枚舉類字段，可以選擇使用自定義文本來承接。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;比如以下是可以通過 dubbo 接口全量獲取配置的元素：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-265ea951a69d044a0e77e39825e029716fc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與 dubbo 全量接口的錄入類似，單點搜索接口與全量接口不同的點在於，單點接口需要保留一個變量，給系統查詢時調用，比如&quot;通過品牌 ID 查詢品牌名稱&quot; 和 &quot;通過品牌名稱查詢品牌 ID&quot; ，需要留給系統調用的入參，用#{var}代替。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-154171e3bd51e9ec195984b8fc5f2408f3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當然，有時元素的範圍並不是隻取決於它自己，可能也取決於同頁面裏其他元素的取值，比如説有一個質量原因的字段，當一級類目為鞋時，取值為 A、B、C，為服裝時為 D、E、F，這是元素範圍在設置時，就需要將對應的元素入參維護到其中，比如：&lt;/p&gt; 
&lt;p&gt;| 接口入參類型 | 接口入參取值 | | --- | --- | | com.d.s.q.s.d.r.ConfigRequest | {&quot;ruleVersion&quot;:#{ruleVersion},&quot;spuId&quot;:#{spuId}} |&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;導入導出&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是導入處理流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72582bd979727a7d8718ed80cfe71b8973e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了照顧使用人員的體驗，再多數導入場景時，我們的導入文件都用的是文案，而不是後台存儲的數值，比如導入的字段包含類目時，導入文件輸入的是鞋、服裝、美妝等文案，而不是 2、3、4 這樣存儲在後台的數值，那麼勢必這裏就會有將文案轉換成數值的過程，這其中就用到了 2.3.5 章節中提到的元素範圍查詢使用的接口，當然，對於需要其他元素作為入參的元素，我們默認每個元素左邊的元素都可以作為當前元素的入參。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;業務參數配置中心不適合做什麼？&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;有極為複雜的 UI 交互&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;較為複雜的校驗邏輯（長期計劃支持）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高頻寫入場景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;應用查詢參數時以非&quot;=&quot;條件匹配&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;三、總結與展望&lt;/h1&gt; 
&lt;p&gt;本文簡要描述了業務參數配置中心的設計思路，參數配置中心配套生成增、刪、改、查、導入、導出服務，並且結合前端低代碼平台自動生成前端代碼，平台目前業務參數中心已經有 40+個場景接入節省了大量的工作人日，能夠讓研發人員，擺脫低效的 CRUD，更專注於自己內部業務邏輯的開發。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;對於目前系統的未來規劃：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;持續增加 SDK 的查詢靈活性：包括不限於批量代參數優先級對數據進行查詢、通過 SDK 分頁查詢全量參數、對系統字段吐出方便業務方使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持續增加對方案定義的靈活性：支持更多的元素範圍的定義，比如 HTTP 等調用方式；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持續增加對元數據定義的靈活性：部分元數據的取值可能需要同頁面中的另一個元素的取值來決定，所以在取值渲染時，可以保留給其他元素的佔位符，進而隨着頁面的動態變動，後台取值也可以動態變動。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539092%26idx%3D1%26sn%3D6fc02ccebc5c838f143d5128691a635b%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物增長兌換商城的構架演進&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539014%26idx%3D1%26sn%3D90a168b730490ae84a0917863ad3e077%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物自研 DGraph4.0 推薦核心引擎升級之路&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538986%26idx%3D1%26sn%3Db6b82a790a3c696bce27704472e799b2%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;大語言模型的訓練後量化算法綜述 | 得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538473%26idx%3D1%26sn%3D0a83895ef8dcd555e9926151a989b663%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何合理規劃 Elasticsearch 的索引｜得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538394%26idx%3D1%26sn%3D51f91adc969a03f7c8baa31f6cc39c67%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;DPP 推薦引擎架構升級演進之路｜得物技術&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;文 / sakuta&lt;/h4&gt; 
&lt;p&gt;關注得物技術，每週新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18230829</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18230829</guid>
            <pubDate>Sun, 27 Apr 2025 03:24:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Anthropic 向逆向工程 Claude Code 的開發者發送刪除通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F25%2Fanthropic-sent-a-takedown-notice-to-a-dev-trying-to-reverse-engineer-its-coding-tool%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 報道稱&lt;/a&gt;&lt;/u&gt;，在 Anthropic 的 Claude Code 和 OpenAI 的 Codex CLI 兩款「智能體」式 AI 編程工具的較量中，後者獲得了更多開發者的青睞。部分原因在於，Anthropic 向一位試圖逆向工程 Claude Code 的開發者發出了刪除通知，而 Claude Code 的使用許可要比 Codex CLI 更加嚴格。&lt;/p&gt; 
&lt;p&gt;Claude Code 和 Codex CLI 都是讓開發者能夠利用雲端的 AI 模型來完成各種編程任務的工具，功能相似。兩家公司幾乎在同一時期發佈了這兩款工具，爭奪開發者的關注。&lt;/p&gt; 
&lt;p&gt;Codex CLI 的源代碼採用 Apache 2.0 許可證，允許分發和商業使用。相比之下，Claude Code 則依賴於 Anthropic 的商業許可證，限制了「在未獲得公司明確許可的情況下對其進行修改」的方式。&lt;/p&gt; 
&lt;p&gt;另外，Anthropic 對 Claude Code 的源代碼進行了「混淆」，意味着其源代碼並不容易獲得。當有開發者通過反混淆手段將代碼發佈到 GitHub&amp;nbsp;時，Anthropic &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgithub%2Fdmca%2Fblob%2Fmaster%2F2025%2F03%2F2025-03-10-anthropic.md&quot; target=&quot;_blank&quot;&gt;提出了 DMCA 投訴&lt;/a&gt; ——&amp;nbsp;這是一份要求刪除代碼的版權通知。&lt;/p&gt; 
&lt;p&gt;社交媒體上的開發者們對 Anthropic 此舉&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FtheLance%2Fstatus%2F1914458771679486389&quot; target=&quot;_blank&quot;&gt;非常不滿意&lt;/a&gt;，認為這種做法遠不如 OpenAI 發佈 Codex CLI 時的開放態度。在 Codex CLI 發佈後的短短一週內，OpenAI 就將幾十條開發者建議納入了工具的代碼庫，其中包括一個讓 Codex CLI 能調用來自其他競爭者（包括 Anthropic）的 AI 模型的功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2820&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/105716_o6ne_2720166.png&quot; width=&quot;1289&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 尚未對此事作出回應。Claude Code 仍處於測試階段，並且存在一些 bug。而在未來，Anthropic 有望以寬鬆的許可證發佈源代碼。公司對源代碼進行混淆的原因多種多樣，其中之一便是出於「安全」考慮。&lt;/p&gt; 
&lt;p&gt;對於 OpenAI 來説，這多少是一次公關上的勝利，因為最近幾個月，OpenAI 一直迴避開源發佈，轉而推出專有、封閉的產品。這可能標誌着實驗室方法的一個更廣泛的轉變；OpenAI 首席執行官 Sam Altman 今年早些時候表示，他認為公司在開源問題上一直站在「歷史錯誤的一邊」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</guid>
            <pubDate>Sun, 27 Apr 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Transformers 作者：未來互聯網將演變為 AI Agent 網絡</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，Transformers 合著者 Illia Polosukhin 接受了 a16z 的專題採訪，並在交流中分享了自己對於 AI、Agent 等方面的觀點。&lt;/p&gt; 
&lt;p&gt;開篇，Illia 就分享了自己對現有 AI Agent 的看法。他表示，據團隊觀察，大量用戶對需要複雜規劃的場景特別感興趣。但這種局面在未來將會反過來：AI 助理將會主動提出方案給用戶，用戶也僅需要做出方向性選擇即可。對於這種 AI 何時面世，Illia 預測在未來一年內，就會出現首批成熟應用的場景。&lt;/p&gt; 
&lt;p&gt;對於「死亡互聯網理論」，Illia 則坦言：雖然開放網絡正在消亡，但並非網絡上的機器人數量過多，而是因為平台容易被垃圾信息攻陷。對此他認為智能 Agent 能夠為人類進行信息把關，未來 AI 助手也會成為互聯網「垃圾分揀員」：能夠為用戶提供上下文鏈接，如實指出錯誤信息並揭露事實真相。&lt;/p&gt; 
&lt;p&gt;另外，主持人問及「未來將會有多少 AI Agent？與人類的數量比例又是如何？」時，Illia 則表示，未來每個人都會擁有屬於自己的 AI 助手，而 AI 助手的背後可能運行着數十個子 Agent 項目，因此這會構建起一個龐大的 Agent 網絡，並且每個人都將如同獲得一套「按需助理系統」。&lt;/p&gt; 
&lt;p&gt;主持人還特別向&amp;nbsp;Transformers 作者問起了對 DeepSeek 的看法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Robert:&lt;/p&gt; 
 &lt;p&gt;您如何看待 DeepSeek 最新發布的高性能開源模型？相比其他選項，它不僅表現優異且成本更低，更特別的是由中國對沖基金以開源方式推出。&lt;/p&gt; 
 &lt;p&gt;Illia:&lt;/p&gt; 
 &lt;p&gt;首先這確實是激動人心的突破。他們在有限硬件上實現大規模高性能模型訓練的工程能力令人驚豔，證明優秀工程實踐能大幅降低成本。中國模型訓練成本正在快速下降，但最關鍵的創新在於：他們提出了一種極其簡單的強化學習方法——這個方法具有普適性，無論是 10 億還是 70 億參數模型都能快速獲得優異效果。&lt;/p&gt; 
 &lt;p&gt;這種「階躍式創新」讓我想起 Transformer 的誕生——原理簡單、開箱即用、人人可復現。&lt;/p&gt; 
 &lt;p&gt;坦白講，這類基礎方法論本應自由傳播 (畢竟只是公式或原理)，但必須承認 DeepSeek 團隊極其專業，他們憑藉後發優勢規避了許多早期問題。現在更重要的機遇在於：藉助可驗證計算技術，我們可以訓練用戶或社區擁有的模型——確切知道訓練數據來源。&lt;/p&gt; 
 &lt;p&gt;當前所有開源模型都只公開參數，無人知曉訓練數據構成，即便公佈也無法驗證真偽。&lt;/p&gt; 
 &lt;p&gt;區塊鏈領域現在有機會聯合訓練一個「加密透明」的開源模型：所有人都能驗證數據輸入、訓練過程及潛在偏差，確保沒有隱藏後門或惡意代碼。這樣的模型才能真正成為 AI 時代可信賴的基礎設施。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhDgE_7fIb-ps4xSOuced_A&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/hDgE_7fIb-ps4xSOuced_A&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347060</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347060</guid>
            <pubDate>Sun, 27 Apr 2025 02:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>馬斯克旗下 xAI 擬融資 200 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-26%2Felon-musk-s-xai-holdings-is-in-discussions-to-raise-20-billion&quot; target=&quot;_blank&quot;&gt;彭博社援引知情人士透露&lt;/a&gt;&lt;/u&gt;，馬斯克旗下 xAI 目前正與投資者洽談，計劃籌集大約 200 億美元資金，用於其新合併的人工智能初創公司和社交媒體業務。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/102209_yrAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;數據提供商 PitchBook 的數據顯示，&lt;strong&gt;如果成功，這筆交易將成為歷史上第二大創業公司融資&lt;/strong&gt;，僅次於今年早些時候 OpenAI 的 400 億美元融資。據知情人士透露，憑藉此輪洽談中的融資，xAI 的估值超過 1200 億美元。&lt;/p&gt; 
&lt;p&gt;值得一提的是，該輪融資可能有助於償還馬斯克在將 X 前身 ——Twitter 私有化後所承擔的一部分債務。知情人士透露，上述債務一直對 X 構成財務壓力。此前彭博社報道指出，僅在今年 3 月，X 就支付了約 2 億美元的債務服務費用，截止 2024 年底，其年度利息支出將超過 13 億美元。&lt;/p&gt; 
&lt;p&gt;據瞭解，儘管談判仍處於初期階段，但 xAI 目標是未來幾個月內籌集資金。知情人士表示，融資規模可能會超過最初的 200 億美元，具體金額和條款尚未確定。&lt;/p&gt; 
&lt;p&gt;報道指出，這一大規模融資凸顯了投資者對人工智能公司日益增長的興趣，同時也顯示了馬斯克作為商業巨頭和政治影響力人物的地位。儘管特斯拉的市值有所下滑，但馬斯克的其他企業仍在蓬勃發展，例如馬斯克的火箭公司 SpaceX，於去年一次私募交易中被估值為 3500 億美元，成為歷史上最有價值的初創公司。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</guid>
            <pubDate>Sun, 27 Apr 2025 02:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>