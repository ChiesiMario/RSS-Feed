<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 04 Aug 2025 16:43:12 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>中國開源 AI 社區 7 月高亮時刻回顧</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Hugging Face&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAdinaYakup%2Fstatus%2F1951020254269939964" target="_blank"&gt;發佈&lt;/a&gt;了中國 AI 社區 7 月高亮時刻，回溯這一個月來令人眼花繚亂的開源浪潮。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1504" src="https://static.oschina.net/uploads/space/2025/0804/184858_39sJ_2720166.png" width="962" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ 另一個「DeepSeek 時刻」——Kimi K2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ Qwen 完全矩陣化- Instruct / Thinking / Coder 模型跨越 30B - 480B 參數規模&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;✨ 多模態浪潮：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;GLM-4.1V-Thinking: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Intern-S1: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wan 2.2 - Text +Image &amp;gt; video&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Skywork-R1V3: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Skywork-UniPic: Text &amp;gt; Image / Image &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Tar-7B: Any-to-Any&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ming-Lite-Omni-1.5: Any-to-Any&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Step3: Image+Text &amp;gt; Text&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HunyuanWorld-1: Image &amp;gt; 3D&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ThinkSound: Video &amp;gt; Audio&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Neta-Lumina: Text &amp;gt; Image&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨ 輕量級、可部署的模型&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SmallThinker runs on 1GB RAM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨ Agentic 編程成為主流&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3-Coder: fully spec'd tool calling&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GLM-4.5: browser agents, IDE assistant&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3 WebDev demo: text-to-frontend code&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;✨特定領域和實用的模型/工具/數據集&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Science one S1: Scientific model&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Agentar DeepFinance: Finance dataset&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ObjectClear: Interactive Vision Tool&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen3 MT Demo: Machine Translation Tool&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中回顧的 7 月 31 個亮眼開源模型、1 個框架、1 個數據集，來自 16 家企業、高校或研究機構：&lt;/p&gt; 
&lt;p&gt;阿里（9 個）、月之暗面（2 個）、智譜（2 個）、階躍星辰（1 個）、字節跳動（2 個）、崑崙萬維（2 個）、智源研究院（1 個）、中國電信人工智能研究院（1 個）、螞蟻集團（4 個）、快手（1 個）、捏 Ta（1 個）、磐石（3 個）、上海交通大學（1 個）、騰訊（1 個）、上海人工智能實驗室（1 個）、復旦大學（1 個）。&lt;/p&gt; 
&lt;p&gt;1、阿里（9 個）：編程模型 Qwen3-Coder-30B-A3B-Instruct、Qwen3-Coder-480B-A35B-Instruct，深度思考模型 Qwen3-30B-A3B-Thinking-2507、Qwen3-235B-A22B-Thinking-2507，基礎模型 Qwen3-235B-A22B-Instruct-2507、Qwen3-30B-A3B-Instruct-2507，CoT 音頻模型 ThinkSound，統一視頻生成模型 Wan2.2-TI2V-5B，文生視頻 Wan2.2-T2V-A14B。&lt;br&gt; 2、月之暗面（2 個）：MoE 基礎模型 Kimi-K2-Base，與 Numina 團隊聯合研發的數學定理證明模型 Kimina-Prover-72B。&lt;br&gt; 3、智譜（2 個）：多模態大模型 GLM-4.1V-9B-Thinking，基礎模型 GLM-4.5。&lt;br&gt; 4、階躍星辰（1 個）：基礎模型 Step3。&lt;br&gt; 5、字節跳動（2 個）：智能體模型 Tar-7B，多語言翻譯模型 Seed-X-Instruct-7B。&lt;br&gt; 6、崑崙萬維（2 個）：多模態推理大模型 Skywork-R1V3-38B，多模態統一模型 Skywork-UniPic-1.5B。&lt;br&gt; 7、智源研究院（1 個）：文生配音視頻框架 MTVCraft。&lt;br&gt; 8、中國電信人工智能研究院（1 個）：AI-Flow-Ruyi-7B-Preview0704。&lt;br&gt; 9、螞蟻集團（4 個）：多模態推理模型 M2-Reasoning，多模態大模型 Ming-Lite-Omni-1.5，金融訓練數據集 Agentar-DeepFinance-100K，交互式深度推理模型 KAG-Thinker-en-ch-7b-instruct。&lt;br&gt; 10、快手（1 個）：自適應思考模型 KAT-V1-40B。&lt;br&gt; 11、捏 Ta（1 個）：動漫風格圖像生成模型 Neta-Lumina。&lt;br&gt; 12、磐石（3 個）：科學基礎大模型 S1-Base-671B、S1-Base-8B、S1-Base-32B。&lt;br&gt; 13、上海交通大學（1 個）：端側原生大模型 SmallThinker-4BA0.6B-Instruct。&lt;br&gt; 14、騰訊（1 個）：3D 世界生成模型 HunyuanWorld-1。&lt;br&gt; 15、上海人工智能實驗室（1 個）：科學多模態大模型 Intern-S1。&lt;br&gt; 16、復旦大學（1 個）：語音生成模型 MOSS-TTSD-v0.5。&lt;/p&gt; 
&lt;p&gt;更多內容查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fjuly-2025-open-works-from-the-chinese-community-686586f1a8840797e477ae5a" target="_blank"&gt;https://huggingface.co/collections/zh-ai-community/july-2025-open-works-from-the-chinese-community-686586f1a8840797e477ae5a&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364138</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364138</guid>
      <pubDate>Sat, 02 Aug 2025 10:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>應用多點開花，AI 大模型從「炫技」走向「實幹」</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;京東宣佈旗下言犀大模型品牌全新升級為 JoyAI，並推出行業首個 100% 開源的企業級智能體 JoyAgent；由釘釘 AI 平台訓練的垂類婦科大模型通過主任醫師考試；網易靈動發佈行業首個工程機械具身智能模型「靈掘」……近期，國產大模型頻頻「上新」，並不斷刷新應用「進度條」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;而在近日舉行的 2025 世界人工智能大會（WAIC）期間，AI 大模型也是格外引人關注。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在物流領域，倉內無人機、無人車等智能物流設施驚豔亮相；工業場景中，AR 眼鏡可以輔助產業工人精準質檢並推薦維修方案；零售體驗台前，系統可以自動個性化推薦商品、瞬間生成海量商品廣告素材……位於上海世博展覽館一號館的京東展區內，展示了全新升級的 JoyAI 大模型深度應用的諸多場景。與此同時，京東雲還正式開源 JoyAgent 智能體。作為行業首個 100% 開源的企業級智能體，JoyAgent 依託多智能體協同引擎實現高效協作，並融合大小模型優勢，打通 AI 落地「最後一公里」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以來，國內大模型迭代速度提升，加快賦能千行百業。其中，不少企業着力打造垂類大模型，推動大模型快速走向「實幹」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;日前，壹生檢康（杭州）生命科技有限公司研發的「豆蔻婦科大模型」成功通過國家婦產科衞生高級職稱（正高）筆試考試。釘釘 CTO 朱鴻介紹，豆蔻婦科大模型是釘釘 AI 平台上誕生的第一個專業垂類大模型，雙方團隊只經過短短一個多月的協作，就將模型準確率提升到了 90.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「通過正高職稱考試，意味着該模型已具備主任級醫師的專業判斷力。」壹生檢康創始人王強宇表示，大模型的核心價值在於，為女性用戶提供居家自診斷支持，實現「術前分流」與「院外健康管理」；針對無需就診的情況提供科普指導與生活建議；為醫療、醫美等行業機構提供專業支撐，同時可通過機構的數據訓練專科模型，提升醫療效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「這一突破為 AI 在婦產科臨牀決策輔助、循證醫學研究、患者健康教育、醫學生學習考試等場景的深度應用開闢了新路徑。」浙江大學醫學院附屬婦產科醫院婦科周博士表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據悉，隨着技術的不斷完善和推廣，豆蔻婦科大模型不僅有望在更多醫療場景中發揮重要作用，還將進一步優化醫療資源配置。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在工業領域，垂類模型也有不少突破性進展。WAIC 期間，網易旗下工程機械智能化品牌網易靈動推出全球首個專為露天礦山挖掘機裝車場景打造的具身智能模型——「靈掘」。在網易靈動展位，觀眾通過智能座艙可以實時體驗內蒙古礦山的無人挖掘機自動裝車功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在內蒙古霍林河北露天煤礦的嚴苛環境中，「靈掘」單機裝車效率已達人工的 80%，近 70% 的作業時間無需人為幹預，成功適配極寒、高粉塵等嚴苛環境與多型號礦卡。「這項技術讓 AI 成為礦山的‘鐵臂戰友’，裝車 3 精度和連續性遠超預期，為行業安全與效率提升開闢了新路徑。」內蒙古某露天煤礦代表在實測後評價道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據瞭解，網易靈動將首次開源「靈掘」數據集，並向全行業發起「2027 產業協同計劃」。該計劃將聯合徐工、三一、山河智能等主機廠及各露天煤礦企業，通過技術共享平台推動聯合研發、場景共創與標準制定。作為「靈掘」技術基石的端到端訓練框架——「機械智心」，已支撐「靈掘」在礦山場景的成功實踐，並快速向港口清艙、混凝土拌合站、地銷煤等十餘個場景遷移，未來將延伸至農業、智能製造等領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;數據顯示，中國目前已發佈 1509 個大模型，在全球已發佈的 3755 個大模型中數量位居首位。業內指出，AI 大模型正從「炫技」走向「實幹」，2025 年成為大模型應用全面落地的關鍵轉折點。這場由技術驅動、場景牽引的深度應用革命，正在重塑千行百業的生產力圖譜。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364136</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364136</guid>
      <pubDate>Sat, 02 Aug 2025 10:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Taro on HarmonyOS 技術架構深度解析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;2025 年 6 月，在華為開發者大會 2025 開發者場景技術共建分論壇，本文作者進行了《京東 Taro 框架鴻蒙版本正式開源，助力鴻蒙版三方應用開發》專題演講。期間闡述了 Taro on HarmonyOS 的技術實現方案、核心優化策略，以及開源版本的主要特性。&lt;/p&gt; 
 &lt;p&gt;本文將詳細介紹 Taro on HarmonyOS 的技術架構、性能優化實踐和開源進展，分享我們在跨端開發中遇到的問題和解決思路。&lt;/p&gt; 
 &lt;p&gt;期待更多人可以參與開源共建，一起交流討論！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;背景&lt;/h2&gt; 
&lt;p&gt;回顧 Taro 的發展歷程，從 2018 年 6 月開源至今，作為開放式的跨端跨框架解決方案在眾多熱心開源貢獻者的支持下，從初出茅廬逐步邁向成熟。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_background" src="https://oscimg.oschina.net/oscnet//e99ecb394150ea01d8d0df9310c36e30.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從最初僅支持面向編譯時的小程序端解決方案，到如今擁有支持多種前端框架和 UI 庫的強大能力；從單一的構建工具，到通過開放生態為開發者提供 &lt;code&gt;Webpack&lt;/code&gt;、&lt;code&gt;Vite&lt;/code&gt;、&lt;code&gt;ESBuild&lt;/code&gt; 等豐富的工具選擇，讓團隊能夠定製專屬的研發流程；從專注小程序開發，到覆蓋各大小程序平台以及 Web、iOS、Android、HarmonyOS 等移動端場景——Taro 的每一步成長都離不開社區的力量。&lt;/p&gt; 
&lt;p&gt;這些年來，我們在 GitHub 上收穫了 &lt;strong&gt;36,000+ star&lt;/strong&gt; 和&lt;strong&gt;近 5,000 fork&lt;/strong&gt;，更重要的是得到了眾多企業團隊和個人開發者貢獻的寶貴功能特性。在此，我們要向所有支持 Taro 發展的朋友們表示衷心的感謝！&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;技術架構演進&lt;/h3&gt; 
&lt;p&gt;説到 &lt;code&gt;HarmonyOS&lt;/code&gt;，Taro 從 2022 年開始佈局鴻蒙適配，走過了一條持續演進的技術路徑。最初我們推出了 &lt;code&gt;JSUI&lt;/code&gt; 版本的端平台插件，為鴻蒙支持打下基礎；2023 年開源了 &lt;code&gt;ETS&lt;/code&gt; 版本的端平台插件，大幅提升了開發體驗和業務性能；而在最近釋出的 4.1 版本中，&lt;code&gt;C-API&lt;/code&gt; 版本的 Harmony 端平台插件也正式發佈了，這標誌着 Taro 鴻蒙支持能力的重要突破。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_on_harmonyos" src="https://oscimg.oschina.net/oscnet//b251d41c504ba0e92bd0ce7994398d6f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，我們仍在持續優化 Harmony C-API 插件的性能表現。團隊正在推進多線程以及更多版本特性的內部驗證，期待在驗證完成後能夠將其開源，為開發者在鴻蒙端帶來更優秀的研發體驗。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;面向多端研發&lt;/h3&gt; 
&lt;p&gt;面向多端的複雜場景，從來都不是一件容易的事情。在傳統的多端開發中，開發者往往需要面對各端語法標準不統一、組件和 API 接口各異、開發環境複雜多樣等諸多挑戰。當業務邏輯需要調整時，開發者必須在多個平台上重複實現相同功能，代碼複用率極低，維護工作量成倍增長。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_cross_platform" src="https://oscimg.oschina.net/oscnet//35b595f2278f17a13dd02df5716f8266.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如圖所示，Taro 現已成功在 HarmonyOS 平台上實現了與 Web 端、小程序及其他平台一致的 UI 呈現效果。&lt;/p&gt; 
&lt;p&gt;基於 Taro 跨端研發標準推進業務實現，開發者只需編寫一套代碼，就能夠在多個平台上獲得統一的用戶體驗，最大限度地節省多端業務的研發成本，讓團隊能夠將更多精力投入到業務創新上。&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;京東鴻蒙版&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd" src="https://oscimg.oschina.net/oscnet//473a9f8879d8cddefdbac83f93802a3a.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以京東鴻蒙版本為例，基於 Taro on HarmonyOS 解決方案，成功在研發效率與應用性能之間達成了理想平衡，其性能表現和穩定性均位居行業前列。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_jd_detail" src="https://oscimg.oschina.net/oscnet//e92b9ee175f09086507c7a5526832104.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對於商品詳情頁等高複雜度、高數據量的核心業務場景，該方案展現出強大的技術適配能力。僅是在單線程 C-API 架構的支持下，這些重載業務場景的運行性能已達到與原生應用相當的水準，充分驗證了跨端技術在複雜場景下的可行性。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;技術架構&lt;/h2&gt; 
&lt;p&gt;為了達成這一目標，我們需要在技術架構層面進行深度優化。&lt;/p&gt; 
&lt;p&gt;Taro 在各平台的適配邏輯保持高度一致性。開發者通過統一的 &lt;code&gt;DSL&lt;/code&gt;以及標準化的組件和 API 庫即可完成全部代碼開發，樣式規範完全遵循 &lt;code&gt;W3C&lt;/code&gt; 標準，使前端開發者能夠以極低的學習成本快速上手。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_2025" src="https://oscimg.oschina.net/oscnet//ee72a5129bf8027a11211bcd29c13fa8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在編譯層面，Taro 通過 CLI 工具和插件系統實現各端的差異化處理。各個端平台插件可以在編譯核心中選擇基於 &lt;code&gt;Webpack&lt;/code&gt;、&lt;code&gt;Vite&lt;/code&gt; 或 &lt;code&gt;Metro&lt;/code&gt; 為基礎的編譯流程，將開發者的源代碼高效轉換為各目標平台的可執行代碼。&lt;/p&gt; 
&lt;p&gt;在運行時中，通過集成語法適配器、&lt;code&gt;DOM&lt;/code&gt;、&lt;code&gt;BOM&lt;/code&gt; 模擬實現以及其他核心模塊，確保開發者項目能夠在 HarmonyOS 等各類平台上穩定運行，真正實現一碼多端的開發願景。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;渲染層適配&lt;/h3&gt; 
&lt;p&gt;儘管 Taro 在 HarmonyOS 平台的插件架構歷經多輪重大版本升級，但其核心架構設計依舊可從以下幾個維度來理解：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmonyos_rendering" src="https://oscimg.oschina.net/oscnet//73d229191f933afdedd47c60cc69d5cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;代碼轉換流程&lt;/strong&gt;：從開發者編寫的 &lt;code&gt;React&lt;/code&gt; 代碼出發，通過與 &lt;code&gt;React Reconciler&lt;/code&gt; 的深度集成，系統構建出完整的虛擬節點樹。隨後，運行時環境通過模擬的 &lt;code&gt;DOM&lt;/code&gt; 和 &lt;code&gt;BOM&lt;/code&gt; API，實現 &lt;code&gt;React&lt;/code&gt; 節點樹與 Taro 內部節點樹的精確映射。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;平台適配實現&lt;/strong&gt;：結合標準化的組件庫和 API 庫，系統將抽象的節點結構轉換為 HarmonyOS 平台的原生原子組件，最終構建出完整的 &lt;code&gt;ArkUI&lt;/code&gt; 渲染樹，並呈現在用戶界面上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;擴展能力支持&lt;/strong&gt;：除了核心渲染流程外，運行時還集成了佈局計算、事件處理、動畫效果等關鍵模塊，並持續接入更多 HarmonyOS 平台特有能力，為開發者提供完整的跨平台開發體驗。&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;架構方案迭代&lt;/h3&gt; 
&lt;p&gt;在技術架構層面，&lt;code&gt;ETS&lt;/code&gt; 方案與 &lt;code&gt;C-API&lt;/code&gt; 方案本質上都遵循着相同的設計理念。兩者均構建了一套完整的三層節點樹體系：應用層的 &lt;code&gt;React&lt;/code&gt; 節點樹首先轉換為中間層的 Taro 節點樹，隨後進一步映射到底層的 &lt;code&gt;ArkUI&lt;/code&gt; 節點樹，最終實現界面的完整渲染。&lt;/p&gt; 
&lt;p&gt;然而，儘管在宏觀架構上兩種方案展現出高度的相似性，我們仍然堅定地推進從 &lt;code&gt;ETS&lt;/code&gt; 向 &lt;code&gt;C-API&lt;/code&gt; 的技術轉型。這一決策的背後，是團隊對性能極致追求的不懈努力。在移動應用開發的激烈競爭中，每一毫秒的性能提升都可能成為用戶體驗的關鍵差異點，而 C-API 方案正是在這樣的背景下應運而生的技術選擇。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmonyos_architecture" src="https://oscimg.oschina.net/oscnet//d56195a048781803635354a4f73e5b0d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;C-API&lt;/code&gt; 方案帶來的性能提升是全方位的。在節點操作層面，我們徹底摒棄了傳統的聲明式遞歸構建模式，轉而採用更加靈活的實現方式，這為底層節點 API 的深度優化創造了前所未有的空間。同時，通過引入指令式節點操作機制，不同節點樹之間的數據交互效率得到了顯著改善，原本複雜的跨樹通信變得更加高效流暢。&lt;/p&gt; 
&lt;p&gt;更為重要的是，我們將樣式處理、佈局計算、事件管理等核心功能模塊全面下沉至 &lt;code&gt;C++&lt;/code&gt; 原生層。這一架構調整不僅大幅減少了跨語言調用的頻次和開銷，更從根本上提升了系統的執行效率。通過這些多維度的優化措施，整個應用的性能表現實現了質的飛躍。&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;跨端研發標準&lt;/h3&gt; 
&lt;p&gt;在適配鴻蒙和其他各端能力的基礎上，Taro 正在構建一套完整的跨端研發標準體系。這套標準不僅能夠最大限度地節約不同端之間的適配成本，更重要的是能夠充分兼容現有的前端生態系統，讓團隊多年積累的組件庫、工具鏈和技術沉澱得以無縫複用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_cross_standard" src="https://oscimg.oschina.net/oscnet//2e9017e41ce210f8f74ed721a42b25bf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，以 &lt;code&gt;React&lt;/code&gt; 作為 UI 基礎庫，該標準已涵蓋了 &lt;code&gt;View&lt;/code&gt;、&lt;code&gt;Text&lt;/code&gt; 等 26 個常用組件和網絡請求、圖片等 88 個常用 API。在樣式規範方面，我們遵循 W3C 標準實現了包含 93 條常用規範的樣式子集。與此同時，我們正在持續努力擴充這套標準體系，不斷增加新的組件類型、API 接口和樣式規範，以滿足日益複雜的業務場景需求。&lt;/p&gt; 
&lt;p&gt;更為關鍵的是，這套不斷完善的標準體系具備良好的擴展性和兼容性，能夠與團隊現有的 UI 組件庫、業務組件以及各類前端工具庫形成有機整合。我們致力於通過標準的持續演進，確保開發團隊能夠在跨端開發中充分發揮既有技術資產的價值，避免重複建設帶來的資源浪費，同時為未來更多端側適配需求預留充足的擴展空間。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_style" src="https://oscimg.oschina.net/oscnet//ba286db72609455a07cb982564d36146.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為實現跨平台開發的一致性標準，我們設計了 &lt;code&gt;C++&lt;/code&gt; 底層樣式處理架構。該架構整合了包括 &lt;code&gt;Yoga&lt;/code&gt; 這類成熟佈局引擎，構建統一的佈局計算體系，保障各端樣式渲染的視覺一致性。通過將樣式計算邏輯完全遷移至 &lt;code&gt;C-API&lt;/code&gt; 底層，系統獲得了顯著的性能優化潛力——不僅消除了對主渲染線程和業務邏輯的性能幹擾，還通過 &lt;code&gt;C++&lt;/code&gt; 的高效執行特性實現了跨端樣式處理的統一化管理，從根本上提升了整體渲染效率。&lt;/p&gt; 
&lt;p&gt;針對鴻蒙端的特殊需求，我們在編譯階段引入了創新的預處理機制。通過在編譯流程中的 &lt;code&gt;Rust&lt;/code&gt; 插件集成 &lt;code&gt;lightingCSS&lt;/code&gt;，我們能夠將標準樣式預先轉換為鴻蒙平台可以識別的樣式，進一步節省運行時運算的負擔。這一機制不僅實現了 W3C 標準屬性到各端專用單位和屬性值的智能轉換，更為跨端樣式的統一管理奠定了堅實的底層基礎。&lt;/p&gt; 
&lt;p&gt;基於這套完善的 &lt;code&gt;C++&lt;/code&gt; 樣式處理體系，UI 庫和業務團隊能夠輕鬆應對各種複雜場景的適配需求。無論是摺疊屏的多形態展示、關懷模式的無障礙優化，還是暗黑模式的主題切換，都可以通過靈活的樣式選擇器機制實現精準控制。同時，動畫效果和過渡轉場也能夠通過高效的樣式更新和節點刷新機制，呈現出極為流暢的用戶體驗。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;方案特性&lt;/h2&gt; 
&lt;p&gt;基於此架構，Taro on HarmonyOS 方案積累了豐富的核心特性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;研發效能層面&lt;/strong&gt;：通過兼容 React 生態體系和 W3C 樣式規範，開發者能夠充分利用前端成熟的工具鏈和生態資源，高效完成業務功能迭代與開發調試工作，完善鴻蒙端的開發體驗。同時，開發者編寫的樣式代碼可在鴻蒙、小程序和 Web 端無縫複用，實現真正的"一次編寫，多端運行"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生態擴展層面&lt;/strong&gt;：提供靈活的組件和 API 擴展機制，支持業務團隊根據實際需求定製運行時環境。更重要的是，通過跨端統一的原生混合調用方案，Taro C++ 模塊與 ArkTS 原生模塊可實現雙向互調，為團隊間協作提供了更多可能性，有效避免重複開發，提升整體研發效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_tech" src="https://oscimg.oschina.net/oscnet//2f6fbb8105c9d720737b1c639d96f421.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;性能體驗&lt;/h3&gt; 
&lt;p&gt;在 C-API 方案中，我們圍繞卓越性能體驗實現了多項核心特性：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;運行時性能優化&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;將 DOM Tree、事件處理、樣式計算等高頻操作模塊完全下沉至 C++ 層，顯著提升運行時執行效率。通過底層優化，減少了 JavaScript 與原生層之間的頻繁通信開銷，避免了數據序列化/反序列化的性能損耗。同時，C++ 層的內存管理更加高效，能夠更好地控制對象生命週期，減少內存碎片，為複雜應用場景提供更穩定的性能表現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高階組件能力&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_list" src="https://oscimg.oschina.net/oscnet//3edfae841c90d8ab8bb6b83a5fd4701b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;基於 HarmonyOS 原生的 List、WaterFlow 等組件特性，深度定製實現虛擬列表、瀑布流等高性能組件，充分發揮系統級優勢。&lt;/p&gt; &lt;p&gt;這些高階組件不僅繼承了系統組件的原生性能，還針對前端開發習慣進行了接口封裝，支持動態數據加載、智能緩存策略、滾動性能優化等特性。開發者可以像使用傳統前端組件一樣輕鬆實現大數據量的列表展示，無需關心底層的複雜優化邏輯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;圖片處理模塊&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;構建專門服務於樣式渲染、背景繪製、Image 組件的圖片處理系統，實現更優秀的圖片加載性能和內存管理。該模塊集成了多級緩存機制，支持內存緩存、磁盤緩存和網絡緩存的智能調度，大幅減少重複加載時間。&lt;/p&gt; &lt;p&gt;&lt;img alt="jd_image" src="https://oscimg.oschina.net/oscnet//e1c0bf07e61ef7b88ac2337b49f4d197.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;同時提供了圖片壓縮、格式轉換、尺寸適配等功能，能夠根據設備性能和網絡狀況自動選擇最優的圖片處理策略，有效降低內存佔用和網絡帶寬消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文字與繪圖支持&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;通過 PixelMap 技術為文字組件提供豐富的字體屬性和渲染能力，同時為 Canvas 組件及相關 API 提供底層支持，覆蓋分享海報生成等複雜業務繪製場景。文字渲染支持多種字體格式、文字效果（陰影、描邊、漸變等）和排版佈局，滿足不同設計需求。&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_shared" src="https://oscimg.oschina.net/oscnet//443eb38b5216494391fcaf0ddc35e649.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;Canvas 繪圖能力則支持路徑繪製、圖形變換、濾鏡效果等高級功能，為數據可視化、遊戲開發、創意設計等場景提供強大的圖形處理能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;視頻播放能力&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;基於 AVPlayer 重構 Video 組件和相關 API 實現，在 C-API 層直接接入，減少調用鏈路，為業務提供更靈活的視頻適配方案。新的視頻播放架構支持多種視頻格式和編碼標準，提供了精確的播放控制、實時進度反饋、音視頻同步等核心功能。&lt;/p&gt; &lt;p&gt;&lt;img alt="taro_harmony_video" src="https://oscimg.oschina.net/oscnet//9f5a8a4b269af1f5b7354aaf25169c9e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;總結展望&lt;/h2&gt; 
&lt;p&gt;Taro 在 HarmonyOS 平台的深度適配，旨在為全場景應用開發開闢新的技術路徑。通過構建完善的鴻蒙端能力體系，我們致力於為更廣泛的業務場景提供技術支撐，推動跨平台開發在鴻蒙生態中的創新應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_all" src="https://oscimg.oschina.net/oscnet//61ac5ecfa77950e92954c28304b10de7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在實際應用中，Taro 成功支撐了京東鴻蒙 APP 的商業化落地。該應用的首頁、搜索推薦以及核心購物流程等關鍵業務模塊均基於 Taro 技術棧開發，在確保快速迭代交付的同時，實現了業界領先的性能表現和系統穩定性。應用上線後迅速在華為應用市場購物類別中登頂，充分驗證了技術方案的商業價值。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;生態建設與合作拓展&lt;/h3&gt; 
&lt;p&gt;基於成功實踐的示範效應，更多京東生態應用正在加速鴻蒙化進程，包括一號會員店、七鮮等重要業務線的鴻蒙版本已上架鴻蒙應用市場或者進入開發階段。同時，我們的技術方案也獲得了外部合作伙伴的認可，58 同城、樸樸超市等知名企業均選擇採用 Taro 相關的鴻蒙開發解決方案，共同構建更加繁榮的鴻蒙應用生態。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;未來展望&lt;/h3&gt; 
&lt;p&gt;我們將持續深化開源戰略，在內部版本充分驗證後，逐步向社區開放多線程等更多核心技術特性。同時不斷擴展跨端標準覆蓋範圍，讓更多組件和 API 實現跨平台一致性，為開發者提供更優質的開發體驗和更完善的調試工具鏈，也為動態化能力構建更堅實的技術基礎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_devtools" src="https://oscimg.oschina.net/oscnet//2aaf8134cf5e8255e8d878eacb2805a8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在性能優化方面，我們將持續推進更多核心模塊向 C++ 層遷移，包括 React 的 C++ 版本實現和高頻 API 運行時模塊優化，同時積極借鑑節點樹扁平化等社區驗證的優秀實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="taro_harmony_jd_c_react" src="https://oscimg.oschina.net/oscnet//21bfd7a53be846ef5a0b4bc0437f6180.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雖然 Taro on HarmonyOS 的 C-API 版本插件開源時間不長，但已經吸引了眾多開發者的積極參與。我們期待更多技術同仁能夠加入這個充滿活力的開源生態，共同推動 Taro on HarmonyOS 方案的不斷完善，在開源共建的道路上續寫跨端開發的新篇章。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18686949</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18686949</guid>
      <pubDate>Sat, 02 Aug 2025 10:20:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>我國連續 12 年保持全球最大工業機器人市場</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，我國工業機器人市場銷量達 30.2 萬套，連續 12 年保持全球最大工業機器人市場。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中國電子學會理事長徐曉蘭介紹，自 2015 年首屆世界機器人大會在北京召開以來，我國機器人產業實現一系列科技創新突破。2024 年，我國機器人專利申請量佔全球機器人專利申請總量的 2/3。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;產業發展方面，我國是全球第一大機器人生產國，工業機器人產量由 2015 年的 3.3 萬套增長至 2024 年的 55.6 萬套，服務機器人產量為 1051.9 萬套，同比增長 34.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;北京、上海分別成立國家地方共建具身智能機器人創新中心、國家地方共建人形機器人創新中心，浙江、安徽、湖北、廣東、四川等地均成立省級機器人創新中心，集聚區域產業優勢力量，推動技術共享與聯合攻關。機器人整機企業充分發揮引領作用，帶動產業鏈上下游零部件企業配套發展，形成大中小協同、上下游聯動的良好生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;應用場景方面，工業機器人已應用於國民經濟 71 個行業大類、236 個行業中類，製造業機器人密度已躍升至全球第三位。服務機器人在家用服務、倉儲物流、商用服務、養老助殘、醫療康復等領域的滲透率顯著提升。國際數據公司數據顯示，2024 年，中國廠商在全球商用服務機器人市場中佔據主導地位，出貨量佔比高達 84.7%，規模優勢明顯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「人形機器人是人工智能與機器人深度融合的產物，是機器人的高階形態和具身智能的良好載體。」徐曉蘭表示，人形機器人有望在家政服務、生產製造、倉儲物流、邊防海防、教育醫療等場景發揮作用，拉動新消費、催生新產業、擴大新就業，推動新質生產力加快發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 世界機器人大會將於 8 月 8 日至 12 日在北京經濟技術開發區北人亦創國際會展中心舉辦。大會期間，200 餘家國內外優秀機器人企業的 1500 餘件展品將亮相，企業數量較去年增長 25%。其中，首發新品 100 餘款，數量是去年的近 2 倍。（人民日報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364133</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364133</guid>
      <pubDate>Sat, 02 Aug 2025 10:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>蘋果組建新 AI 團隊「AKI」，打造類似 ChatGPT 的 AI 搜索工具</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;彭博社記者&amp;nbsp;Mark Gurman &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2025-08-03%2Fapple-s-chatgpt-rival-from-new-answers-team-iphone-17-spotted-in-the-wild-mdvmqs6g" target="_blank"&gt;報道稱&lt;/a&gt;，蘋果正開發一款類似 ChatGPT、能夠直接回答用戶廣泛問題的搜索引擎。&lt;/p&gt; 
&lt;p&gt;該項目由一個新成立的&lt;strong&gt;「Answers, Knowledge, and Information，簡稱 AKI」&lt;/strong&gt;（答案、知識與信息）內部團隊負責。領導該新項目的是高級總監 Robby Walker，他曾負責 Siri 的研發工作。雖然該項目仍處於早期階段，但該團隊正在構建所謂的 「答案引擎」—— 一個能夠抓取網頁以回應通用知識問題的系統。目前正在探索開發一款獨立應用，同時也在搭建新的後端基礎設施，旨在為未來版本的 Siri、Spotlight 和 Safari 提供搜索功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/175856_2Ke0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;蘋果最近已在其招聘網站上為該團隊發佈了職位空缺，他們正在為該團隊招募具有搜索算法和引擎開發經驗的工程師。招聘信息稱：「我們的工作為蘋果一些最具標誌性的產品（包括 Siri、Spotlight、Safari、Messages、Lookup 等）提供直觀的信息體驗。加入我們，共同塑造全球與信息連接方式的未來！」&lt;/p&gt; 
&lt;p&gt;此舉標誌着蘋果在 AI 上的重大轉變，因為此前蘋果高管曾多次表示，無意開發自有聊天機器人，而是選擇集成第三方服務。&lt;/p&gt; 
&lt;p&gt;目前，Siri 在處理複雜問題時表現不佳，蘋果與谷歌之間價值約 200 億美元的默認搜索引擎協議正面臨美國司法部的嚴格審查，蘋果可能因此感到有必要開發自主引擎。不過與此同時，蘋果正面臨 AI 人才流失問題，負責開發大語言模型的團隊在一個月內已有四名關鍵研究員離職，轉投競爭對手 Meta。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364130</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364130</guid>
      <pubDate>Sat, 02 Aug 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程工具 Roo Code 支持通過對話歷史提供更智能的建議</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;AI 編程助手 Roo Code 發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fupdate-notes%2Fv3.25.4" target="_blank"&gt;v3.25.4&lt;/a&gt;更新，支持基於最近 10 條消息作為上下文來增強其代碼建議，從而提供更智能、更少幻覺的響應。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/174428_JrSy_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用戶可以完全控制 API 路由和歷史記錄的開關，以平衡上下文和隱私需求。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Roo Code 是一個 AI 驅動的開源自主編碼 Agent，它存在於您的編輯器中。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/193229_CZTb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;功能&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;用自然語言溝通&lt;/li&gt; 
 &lt;li&gt;直接在您的工作區讀寫文件&lt;/li&gt; 
 &lt;li&gt;運行終端命令&lt;/li&gt; 
 &lt;li&gt;自動化瀏覽器操作&lt;/li&gt; 
 &lt;li&gt;與任何 OpenAI 兼容或自定義的 API / 模型集成&lt;/li&gt; 
 &lt;li&gt;通過&lt;strong&gt;自定義模式&lt;/strong&gt;調整其 "個性" 和能力&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364125</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364125</guid>
      <pubDate>Sat, 02 Aug 2025 09:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>辯證看待 KubeSphere 閉源刪庫，前核心團隊成員的解讀</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;文章來源：微信公眾號 Cloud Native Fun&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;作者：周鵬飛&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;2025 年 8 月 1 日，青雲科技在 KubeSphere 社區發佈消息，宣佈暫停 KubeSphere 的開源版本支持（&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%2F6550" target="_blank"&gt;&lt;u&gt;https://github.com/kubesphere/kubesphere/issues/6550&lt;/u&gt;&lt;/a&gt;）。這一消息如同投下一顆重磅炸彈，引發了全球開源社區的強烈反響。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;作為前青雲科技的高級社區經理、KubeSphere 項目的前核心維護者，我曾參與這個項目從零到一的過程。在這篇文章中，我站在一個長期開源從業者的角度，嘗試用辯證的視角去還原事件背後更深層的邏輯，並回答一些幾個普遍關注的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;KubeSphere 自 2018 年 4 月份開始在 GItHub 寫下第一行代碼並開源，至今七年多的時間，曾被全球數以萬計的大小企業所使用，與眾多知名開源項目集成，被全球各大雲廠商認可和合作，不可否認的事實是，KubeSphere 是一個非常優秀的開源項目和雲原生產品，項目創始人 Ray 也是一個很有開源情懷的人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我曾在 2018-2022 年擔任青雲科技的高級社區經理，在全球不遺餘力地推廣 KubeSphere，&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4MDcyOTc2Nw%3D%3D%26mid%3D2247485443%26idx%3D1%26sn%3D0d66089771b9ea44006666eeb4471af8%26scene%3D21%23wechat_redirect" target="_blank"&gt;從零到一構建了活躍多元化的開源社區&lt;/a&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;，創作了官網、用戶文檔、博客、視頻教程，在全國各大城市辦過幾十場活動，並將 KubeSphere 孵化的 3 個子項目捐給 CNCF 基金會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-a83df931bfba4277ce01f9eb46797ef1d7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;2020-2022 年幾乎是 KubeSphere 在全球飛速發展的三年，我記得曾經幾乎每天都能看到新的用戶增長和使用反饋，以及來自全球不同公司的貢獻者參與。説實話，那曾是我最有工作成就感和成長飛快的時光，在開源社區認識了很多優秀的開發者，也給公司帶來過一些商業機會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-49bfe588b4f1c2be1102d667fadac349a14.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;一次不留餘地的急轉彎&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;令人遺憾的是，這次青雲的決定來了個 180 度急轉彎，不僅將前端代碼閉源，還刪除所有已發佈的文檔和安裝鏡像，徹底將 KubeSphere 推向了深淵，在全球開源社區引發了巨大的輿論和開源信任危機。巧合的是，消息發佈當天正是項目創始人 Ray 宣佈離職的時間點。我不知道這是否是有意為之，但屬實是不講「情面」的一個選擇，也引發了國內外很多開發者對「中國式開源」的發問和深層焦慮。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-1e8382254228e4b54d873e3631e7c2654cd.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;牆倒眾人推，並不能讓中國開源更好&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;事實上，我剛開始看到消息時也有些情緒化，因為 「KubeSphere 閉源刪庫」後，互聯網輿論呈現了牆倒眾人推的趨勢，很多博主的文章以及吃瓜羣眾的評論，站在制高點一味地批判和指責商業公司「閉源」的行為，詆譭該開源項目的價值，甚至還有很多人直接全盤否定 「中國開源」 的努力和價值。這些帶有偏見的觀點，很容易誤導大眾的認知和情緒，並且不會讓這個行業變得更好。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我也看到了很多曾經的用戶、貢獻者、前同事們表示唏噓和惋惜，感嘆自己曾經參與過的開源明星項目的隕落。我沒有選擇在第一時間發佈這篇文章，在閲讀了國內外很多博主的文章、討論和用戶在 GitHub 上的回覆後，帶着辯證的角度來分享自己的一些觀點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;截止目前，我看到的可能有價值的一個討論是，有一些用戶在 GitHub 上希望通過投票和眾籌的方式重新組建純社區自發驅動的 KubeSphere 開源貢獻者團隊，Issue 下也有眾多用戶和貢獻者表示支持，這讓我感受到了些許欣慰，因為它展現了開源社區開發者的集體力量，但這個目標要實現的難度不亞於去經營一家公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="229" src="https://oscimg.oschina.net/oscnet/up-bab13eb637d429b475fd818bbd06bc869b5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;維護開源是商業公司應有的社會責任嗎？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這是一個值得每位開源參與者深思的問題。開源項目由商業公司主導，並不意味着它對社區有「義務」無限維護。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;顯然 「KubeSphere 閉源刪庫」 是一個唐突而又糟糕的決策，但我想説，&lt;strong style="color:#000000"&gt;選擇「閉源」或核心團隊撤離開源項目這件事情本身從來不是某一家商業公司的過錯，&lt;/strong&gt;任何一家商業公司主導的開源項目都存在這樣的「閉源」風險，這在開源界也已有多個案例。客觀來説，在當前的經濟下行的市場環境下，幾乎所有商業公司都在收縮投資或調整戰略，對於營收增長慢的項目和人力都有被優化的可能。&lt;strong style="color:#000000"&gt;維護開源項目並不是一家商業公司應有的社會責任或義務。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但是，開源項目背後的主導公司如果希望撤資開源投入，&lt;strong style="color:#000000"&gt;需要遵循開源項目客觀存在的生命週期，&lt;/strong&gt;而不是把開源社區一刀切，用開源斷供來「綁架」用戶，轉到自家商業產品，這並不是一項精明的生意決策。實際上，&lt;strong&gt;如果青雲選擇將 KubeSphere 項目歸檔 （Archive）並選擇提前一段時間在社區發佈項目 Retire 的公告，同時致謝所有參與貢獻的開發者和用戶，那就不會出現今天的危機局面&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;失去開發者=失去企業服務信任&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「得開發者得天下」 是一個很通俗的道理，很多大小企業選擇走開源的策略，也正是因為開源是一個能夠低成本地快速地獲取全球開發者用戶的機會和建立跨企業的社區合作模式，比傳統的閉源軟件開發和 Marketing 傳播更快，通過開源社區協作開發也更容易建立規模與行業標準。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但很多商業公司錯誤地把開源作為低成本「獲客」的渠道，&lt;strong style="color:#000000"&gt;把開源作為一項「免費廣告」的福利，利用開發者對開源技術的關注來獲取銷售商機，這樣的做法是對開源社區最大的傷害，也是對商業公司口碑的破壞&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;實際上，很多開源項目的開發者用戶是一些企業的運維開發負責人或內部決策影響者，他們雖然可能不能直接決定公司的軟件採購，但他們提供的觀點和意見會直接或間接地影響企業管理層的決策。很可惜，很多開源商業化公司的 CXO 們並不懂開發者的重要性，忽視了開源社區的規模影響力。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;青雲做些什麼能補救？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;答案是能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;青雲作為一家上市公司，公司層面一定還是會關注自己在業內的口碑以及客戶的信任。這裏我不適合作為局外人指點江山，但提供思路作為參考，&lt;strong style="color:#000000"&gt;畢竟在社區裏還有很多用戶在關注 KubeSphere 後續是否會有好的轉機。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;讓我們來看一個正面的例子，CNCF 畢業項目 Flux 背後的核心維護公司 WeaveWorks 在去年 2 月份雖然宣佈了公司關閉停止運營，但 CEO 第一時間在聯繫一些大公司的用戶和貢獻者參與 Flux 項目的維護，並積極尋求 CNCF 的幫助，確保該項目在即使沒有了 WeaveWorks 公司的支持，還能繼續在社區維護和迭代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="504" src="https://oscimg.oschina.net/oscnet/up-5c4d3b4efba258bd1ad215ef4c196d40c65.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;青雲是否會考慮做一個 「git revert」 的回滾操作，來響應社區目前呼聲最高的提議&lt;/strong&gt;：恢復閉源的倉庫、下線的文檔、歷史鏡像，並將開源項目交由給中立的社區自發去維護？青雲作為商業公司繼續去做自己的商業產品，或許還有重建信任的機會。如果公司層面擔心開源項目搶了自己的商業產品的蛋糕，那必然是商業產品與服務做得還不夠好。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;對 KubeSphere 開源協議的疑問？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;KubeSphere 有兩個子項目的開源協議值得探討，第一個是此次被閉源的前端 Console 項目開源協議是 AGPL-3.0，這個協議除了要求二次分發必須開源沒有其它問題，一些知名項目如 Grafana 也採用該協議。還記得 KubeSphere 曾多次被國內和海外的一些大公司換 Logo 後改個名字後就拿去賣錢，AGPL-3.0 的協議某種程度上也有一定的品牌保護作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;但值得注意的是，後端開源是在 Apache 2.0 基礎上加入了「附加條款」的開源協議，例如：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;禁止用於商業化 SaaS 服務&lt;/strong&gt;；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;禁止移除或修改 KubeSphere 品牌和 logo&lt;/strong&gt;；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;要求貢獻者接受維護者可以在未來&lt;strong&gt;改變授權方式&lt;/strong&gt;的條款；&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;對 fork 或商用做出限制。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;雖然它的目的是出於保護青雲的商業產品利益和 KubeSphere 品牌，但這個修改後的協議是不符合 OSI（Open Source Initiative）定義的開源標準的，破壞了 Apache 2.0 的開放性和自由性。所以青雲回覆 KubeSphere 將繼續保持核心代碼開源的聲明，是需要推敲的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;開源協議的選擇，以及&lt;strong style="color:#000000"&gt;所選開源協議的開放程度和商業友好程度，會從本質上影響和決定這個項目最終是否會有眾多企業級貢獻者來參與&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;關於「K8s 上游貢獻」的誤解&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;圈子裏有開源從業者提出了一個問題：&lt;strong style="color:#000000"&gt;KubeSphere 作為 K8s 發行版，秉着 「Upstream First」 的原則， KubeSphere 項目維護者在上游 K8s 社區的貢獻有多少？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;實際上，研究這個問題對於分析這個事件的的意義並不大，因為 KubeSphere 不算嚴格意義上 K8s 發行版，因為它沒有改 K8s 一行代碼，沒有對 K8s 進行二次分發，它是一個構建於 Kubernetes 之上的平台型項目，用戶可以使用自己已有的 K8s 對接 KubeSphere，所以從產品定義層面這個説法不是非常準確；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;其次，KubeSphere 團隊對 K8s 項目的貢獻多少，並不會直接影響到 KubeSphere 開源項目本身的可持續性發展，上游貢獻的指標僅對下游企業在 K8s 上游社區的話語權和影響力能產生影響，或對企業內部基於 K8s 做了擴展或二次修改的廠商，或是直接提供託管 K8s 雲服務的雲廠商，能體現技術實力。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;可持續的開源項目，有哪些共同特徵？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;「一個人可以走得很快，但一羣人可以走得更遠。」&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;很多用戶評估開源項目是否值得在企業內部特別是生產環境採用，習慣先去看這個項目的 GitHub Star 數量來評估這個項目的流行度，從而判斷該項目的可持續性。實際上，這樣的方式太過於片面和業餘。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我如果作為用戶，我認為最可靠的方式是去關注這些指標：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="list-style-type:disc; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;有多少家公司參與了開源項目的貢獻與維護？貢獻比例分別是多少？（單一廠商控制的開源項目屬於高風險）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;開源社區治理和開發流程是否公開和透明？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;有多少大的企業已經採用了該開源項目？（這通常在官網或 README 中能找到）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;該開源項目對商業化是否友好？業內是否已有多家商業公司集成和提供商業支持？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:#000000"&gt;…&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我的觀點是，真正強大的開源項目，往往擁有更豐富的「社區股東」和更清晰的合作模型。&lt;strong style="color:#000000"&gt;一個開源項目的貢獻者和商業生態越多元化，擁抱它的企業越多，它的可持續性將會越強大。&lt;/strong&gt;如果只有單一廠商在維護，並且只有用戶生態，缺乏不同組織的貢獻者，並且用戶市場還侷限在國內，這樣的開源項目大概率是走不遠的。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;我們從該事件能學到什麼？&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;對於希望構建開源商業化的公司&lt;/strong&gt;：開源的核心價值並不僅僅是代碼和技術，而是圍繞這些能力構建起來的社區生態與信任體系。如果把開源僅僅視為一種「獲客渠道」，通過免費開放源碼吸引用戶，再通過商用版本進行轉化，卻忽略了社區治理、合作機制、開發者關係和中立性建設，最終可能得到短期流量，但失去長期信任。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;對開源項目使用者的啓示：&lt;/strong&gt;&amp;nbsp;如何選型一個更有可持續性的項目是非常關鍵的，上面提到的一些指標可以作為參考。作為用戶在有餘力的情況下，可以思考自己作為用戶如何參與到開源社區中，畢竟 「眾人拾柴火焰高」。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#773098"&gt;寫在最後&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#5a5a5a; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;我在西雅圖的週日晚午夜時分寫完這篇文章，雖然我已經離開了前司青雲三年多時間，但依然對曾經一起參與 KubeSphere 維護的前同事、社區貢獻者和用戶們合作的時光非常懷念，當時 KubeSphere 項目也確實在四海大地聚集了很有有熱情和信仰的開源愛好者。如今的局面，個人還是衷心希望能有一些好的轉機！&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364121</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364121</guid>
      <pubDate>Sat, 02 Aug 2025 09:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌變更 goo.gl 短鏈接服務「停用」計劃，會保留活躍鏈接</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌去年&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;宣佈&lt;/a&gt;，它將於 2025 年 8 月 25 日關閉 Google URL Shortener 短鏈接服務（goo.gl/*），屆時所有 goo.gl 鏈接將會&lt;a href="https://www.oschina.net/news/362402"&gt;停止響應&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距離關閉日期不到一個月時間，在依賴於 goo.gl 短鏈接的開發者、教育工作者和記者等表達擔憂之後，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fdevelopers%2Fgoogl-link-shortening-update%2F" target="_blank"&gt;谷歌改變了主意&lt;/a&gt;，採取了更溫和的立場：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/173324_wscd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;它將只禁用自 2024 年底以來沒有任何活動的 goo.gl 鏈接，如果 goo.gl 鏈接在活躍使用或點擊，這些鏈接將能繼續使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c970c162854ec8999ffbf88f6e05480f82b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364120/google-googl-shutdown-reversal</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364120/google-googl-shutdown-reversal</guid>
      <pubDate>Sat, 02 Aug 2025 09:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>揭祕字節跳動內部流量調度與容災實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;div&gt;
   資料來源： 
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-開發者社區&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 摘要： 在字節跳動，平衡超大規模流量的穩定性、性能、容量與成本，是一系列產品共同面臨的挑戰，其中， Trafficroute GTM 起到了不可忽視的作用&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Trafficroute GTM 承載了字節跳動億級流量、覆蓋了大規模場景，是一款基於 DNS 的流量路由服務，我們將通過兩期文章，揭祕字節跳動如何通過 Trafficroute GTM 巧妙應對以上挑戰，實現高效流量管理！&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;上期內容中，我們主要介紹了基於 TrafficRoute GTM 的 GEO-基礎路由模式進行自定義流量編排，感興趣的小夥伴可以點擊瞭解：《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkyNzY0OTE5Ng%3D%3D%26mid%3D2247487345%26idx%3D1%26sn%3D8240962635c24ae6f065a483be88d8eb%26scene%3D21%23wechat_redirect" target="_blank"&gt;揭祕字節跳動內部流量調度與容災實踐【上】&lt;/a&gt;》。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;本文為下期，主要介紹基於 TrafficRoute GTM 的 Perf-智能路由模式落地全智能、可觀測、可微調的流量調度，主要內容包括：&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;1.TrafficRoute GTM 介紹&lt;br&gt; 2.TrafficRoute GTM 的 Perf-智能路由關鍵技術&lt;br&gt; 3.字節跳動智能流量調度內部實踐&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面臨超大規模流量時，平衡好穩定性、性能、容量、成本，能確保用戶在訪問服務時獲得流暢、快速且可靠的體驗，這對於提高用戶滿意度和粘性至關重要。TrafficRoute GTM 為業務提供基於 DNS 的全球流量負載均衡、智能調度、自動容災服務，可以幫助業務提升連續性，實現資源優化，獲取更多競爭優勢。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;1.火山引擎 Trafficroute GTM 簡介&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;火山引擎 Trafficroute GTM 是基於 DNS 的流量路由服務。它依託全球 1100+ 分佈式探測節點及 IDC 質量數據等，構建出強大的網絡質量感知能力，實現了對「端-邊-雲」全鏈路流量的質量感知，從而根據 APP 應用的實時訪問質量、節點負載和健康狀況作出動態流量調度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;此外，Trafficroute GTM 還提供靈活的調度策略，其中 GEO-基礎，路由功能豐富，包括負載均衡、會話粘性（內部使用中，暫未對外開放）和故障轉移等多種特性。而 Perf-智能路由則在基礎路由的基礎上，進一步提供性能優先，容量優先和負載反饋等智能調度能力，以滿足更高層次的調度需求。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//27f3f1197212e22ab45afebdef1b5d94.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 一圖看懂 TrafficRoute GTM&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在字節跳動內部業務中，諸多業務基於 TrafficRoute GTM 的 Perf-智能路由，藉助 GTM 的全球網絡質量地圖、APP 全鏈路可用性、APP 實時負載等感知能力落地了全智能、可觀測、可微調的流量調度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;2.Perf-智能路由，實現流量智能調度&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;TrafficRoute GTM 的 Perf-智能路由旨在為邊緣計算、IoT 物聯網、多雲混合等大規模分佈式場景提供智能化的流量調度方案。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;用戶無需人工進行流量編排，只需在 GTM 中輸入目標節點地址，GTM 即刻呈現最優的流量調度策略；同時，GTM 會根據全球網絡質量，目標節點健康狀況等動態的更新流量調度規則，真正地實現自動、智能的流量調度。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//51866a5a42c1752611bb4008749e8321.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 憑藉以下關鍵技術，Perf-智能路由實現了更智能、更動態的流量調度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;2.1 感知中心&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;GTM 感知中心通過分佈於全球 1100+ 的節點實時採集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全球網絡鏈路質量，反映網絡鏈路的連通性/時延/抖動等&lt;/li&gt; 
 &lt;li&gt;目標資源健康情況，反映業務的資源節點當前健康程度&lt;/li&gt; 
 &lt;li&gt;目標資源實時負載，反映業務的資源節點當前工作負荷&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;這些數據經過預處理、轉換、分析後作為策略中心的決策依據。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//755a66782dbc63a888425e5bdb229491.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 以感知中心生成的中國大陸的網絡質量地圖為例：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//46181b2fb4b81bfa8d7342a946b61e71.jpg" width="1005" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 該有向圖表達了 6 個省份-運營商之間的網絡質量，節點代表省份-運營商，邊表示節點之間的連通性&amp;amp;時延&amp;amp;抖動。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在實際應用中，GTM 的策略中心亦可根據業務需求，對該有向圖施加【成本系數、ISP 親和、GEO 親和】等約束，這些約束最終會影響到流量調度。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;2.2 策略中心&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;策略中心根據感知中心上報的事件，利用實例設定的策略算法進行路由計算，進而生成動態的調度拓撲。Perf-智能路由主要有 3 種模式，分別面向對性能、容量、成本、穩定性等有不同訴求的業務場景。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//3a18a1d64b5cf0c4990422b915b0ddde.jpg" width="3412" referrerpolicy="no-referrer"&gt; 
 &lt;br&gt; 
 &lt;br&gt; 性能優先 | Perf 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  適用於量級可控、資源容量充沛、追求極致性能的業務 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：據全球網絡質量，動態的將各地區的客戶端調度至其訪問最快的資源節點&lt;/li&gt; 
 &lt;li&gt;核心特色：以數據 （ 網絡質量 ） 驅動調度而非經驗，將流量調度變得更加智能、實時、精確&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//8829efb01af6d09d6e03a63deb50b9cc.jpg" width="1482" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; &lt;br&gt; 容量優先 | Perf-Cap&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;適用於量級中等，資源分佈不均，要求在資源約束下實現最高性能的業務&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：根據全球網絡質量，在容量限制的前提下，動態地將各地區客戶端調度至其訪問最快的資源節點&lt;/li&gt; 
 &lt;li&gt;核心特色：在 Perf 性能優先的基礎上，引入資源節點容量的約束，能夠更加智能的實現容量，性能的平衡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//fc0b6086dc2a8b0704f5e7b93fbe5d64.jpg" width="936" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 負載，反饋 | Perf-Feedback&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;適用於量級波動大，資源分佈廣且不均，追求容量&amp;amp;性能&amp;amp;成本的平衡，尤其適合邊緣下沉場景&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：根據全局和節點負載，動態的將流量在可用節點中分配，同時兼顧性能最優和容量安全&lt;/li&gt; 
 &lt;li&gt;核心特色：以最合理的資源成本，穩定支撐量級&amp;amp;波動大的業務，實現容量/性能/成本/穩定性的平衡&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//4f0e9bd329249ed0ebe8ec044f0a7a95.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Perf-Feedback 內置兩種調度傾向：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;當全局平均負載較低時，GTM 傾向於性能，將客戶端流量調度至其訪問最快的資源節點&lt;/li&gt; 
 &lt;li&gt;當全局平均負載較高時，GTM 傾向於穩定，確保每個節點的水位不高於全局平均負載水位&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;如下圖所示，相比於 Perf-Cap，GTM 的調度輸入中引入了實時負載的數據。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//fbb51d8fe9e5aeec563326aafa3b54a5.jpg" width="936" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Perf 自定義路由&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;適用於用戶需要對 Perf 智能路由流量進行微調，以滿足特定場景的業務&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;核心原理：自定義路由規則的優先級高於 Perf 智能路由生成的路由規則優先級&lt;/li&gt; 
 &lt;li&gt;核心特色：在智能化的同時也為業務方提供更多的靈活性，滿足特定業務需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//0f2575e23ad2499c9ac0ab47b58bb6d6.jpg" width="2850" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 2.3 流量可視化&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Perf-智能調度智慧透明，配備全面工具集，助力業務深入分析流量動態，通過 Perf-智能調度，可以觀測到實時流量拓撲、客戶端請求趨勢、客戶端地區分佈等流量動態。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//725ec82c907b637a27e73d5ab3598418.jpg" width="2722" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 實時流量拓撲&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//9fc1792f281616eeef95de1b8fdb01d2.jpg" width="1864" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 客戶端請求趨勢&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//3da45538936e9772728e8057243a3548.jpg" width="1872" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 客戶端地區分佈&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;3.字節跳動智能流量調度內部實踐&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在字節跳動，越來越多的業務正通過邊緣計算將服務去中心化，從而實現更優的用戶體驗和更低的基建成本。面對邊緣節點分佈廣泛、數量龐大、能力參差不齊的挑戰，TrafficRoute GTM 的 Perf 智能路由展現出天然優勢。通過 Perf -智能路由的三種調度模式，幫助字節跳動內部多個業務落地了邊緣下沉，在成本、性能和穩定性上取得較大收益。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;3.1 RTC 實時音頻，訪問時延降低 10%+&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;字節跳動某款 APP 的 RTC 實時音頻服務，在全國三個城市部署了 9 個接入節點。通過採用 TrafficRoute GTM 的 Perf 性能優先模式，確保全國的企業用戶在不同工作場所均能體驗到極低延遲的音頻接入服務，保障了通信的高效與流暢。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//b46e6cf10f0195428eb729c7d2c6b570.jpg" width="1048" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//717de0c554e9a316da09e95cae8b0522.jpg" width="3752" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; GTM 感知中心實時感知全國網絡質量，智能地為不同地區客戶端動態制定調度規則，確保用戶始終連接到最健康、速度最快的音頻接入點，以優化通信體驗。整個應用過程中，GTM 的 Perf 性能優先模式充分發揮了獨特功能，涵蓋了智能動態調度策略、顯著降低了接入成本以及顯著提升了應用性能，展現出其卓越的技術優勢。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//22ae0e72f459a8d877bbd5c14643deb5.jpg" width="2442" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 採用 TrafficRoute GTM 的 Perf 性能優先模式，相比較 GEO 基礎路由，最終業務實現瞭如下收益：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//0e9a9657ca6bffdeb34296935aadd2ec.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本收益：智能調度代替了人工維護，每月降低了 3 人天以上；&lt;/li&gt; 
 &lt;li&gt;性能收益：訪問時延 avg 降低 10%+，p95 降低 25%；請求成功率 avg 提升 0.05%；&lt;/li&gt; 
 &lt;li&gt;穩定性收益：業務實現了分鐘級全鏈路自動容災，最快做到 3 分鐘全國 95%+ 流量收斂。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 3.2 千萬 QPS 業務，成本降低 35%，性能提升 20%&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在邊緣計算浪潮的推動下，能否有效駕馭大規模邊緣算力，成為業務邊緣下沉成功的關鍵。TrafficRoute GTM 深度參與了一個超 1500 萬 QPS 的業務邊緣下沉項目，通過使用 Perf-Cap 容量優先模式，助力其在字節內部率先落地端-邊-雲一體化的架構，成為先行者。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//e7deae9af5c6d09fccc0c1904c31f291.jpg" width="3132" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 通過將中心 Region 數據面服務下沉至全國 30+ 省份、50+ 邊緣節點，來實現提升用戶訪問體驗 (邊緣節點距離終端客戶端更近) 和降低帶寬&amp;amp;算力成本 (邊緣資源成本約為中心的 20%~60%)。GTM 的 P erf-Cap 容量優先模式，根據業務的客戶端請求分佈、全國網絡質量地圖 ， 在滿足各邊緣節點容量約束的前提下，生成全局總時延最低的流量調度規則。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//ad93894a8582bd02fd6e4d9c63309094.jpg" width="2596" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; GTM 上實際配置如下圖：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//433b27fc81232ee1a9ec89b390e0f5ed.jpg" width="1532" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 此時，用戶無需繁瑣的容量規劃、節點統籌、流量調度，只需在 console 上填入邊緣節點的元信息 (IP 地址+容量)，GTM 即刻生成&lt;em&gt;智能&lt;/em&gt;、&lt;em&gt;動態&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;em&gt;的調度&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;*， *&lt;em&gt;時刻保證最終客戶的體驗最優。&lt;/em&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;通過抖音客戶端 AB 數據分析，該業務邊緣下沉帶來的整體收益如下：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//d60771c32ba3fa11f057436c4149292f.jpg" width="2074" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 其中，邊緣下沉 x GTM Perf-Cap 模式，額外取得的收益如下：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//c2dd755e546b20a5daee185333db42d1.jpg" width="2092" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 3.3 302 服務，端上播放質量顯著提升&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;字節跳動 302 服務承擔了抖音、頭條、西瓜等 APP 點播&amp;amp;下載的重定向功能，其流量呈現明顯的波峯波谷特徵，日內 QPS 在 30-350 萬範圍波動。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;為實現最優訪問性能和最低基建成本，要求 TrafficRoute GTM 將動態波動的流量在最小資源冗餘的火山引擎邊緣節點上合理調度，既要保證性能全局最優，又要保證全局水位健康。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//4fcd16dcc51697e3731fb733c9e6a59c.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 採用 Perf-Feedback 負載反饋模式，302 服務實現瞭如下收益：&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//69cfbed876af215db19663285d846b05.jpg" width="4000" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;100+ 邊緣節點的負載更加可控，資源利用率更加合理，節點負載跑超率從 20% 降至 0%；&lt;/li&gt; 
 &lt;li&gt;TCP 建聯失敗率下降明顯：晚高峯 19%-&amp;gt;16.5% ，午高峯 18%-&amp;gt; 14%；&lt;/li&gt; 
 &lt;li&gt;客戶端 7 層負面指標均下降 ： 其中播放 error 錯誤率、播放 play_break 中斷率降幅超 50%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; END&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Trafficroute GTM 通過 Perf -智能路由的三種調度模式，幫助字節跳動內部 RTC 實時音頻業務、千萬 QPS 業務、302 服務實現了在成本、性能和穩定性上的收益，進一步助力字節跳動內部業務經受超大規模流量考驗，確保始終為用戶提供穩定服務。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;最後，給大家預告番外篇，後續我們將聚焦更新的 GTM 調度功能，詳細闡述技術思路、關鍵技術和實踐經驗，感興趣的小夥伴記得持續關注~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18684814</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18684814</guid>
      <pubDate>Sat, 02 Aug 2025 09:24:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>國產開源推理引擎「赤兔」發佈 v0.4 版本</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;國產開源推理引擎「赤兔」&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fthu-pacman%2Fchitu%2Freleases%2Ftag%2Fv0.4.0" target="_blank"&gt;發佈了 v0.4 版本&lt;/a&gt;，&lt;strong&gt;大幅提升了一體機推理部署場景的性能和穩定性，適配昇騰、英偉達、沐曦、海光，支持 DeepSeek、Qwen、GLM、Kimi 等模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Chitu（赤兔）是由清華系&amp;nbsp;AI Infra 明星創企——清程極智聯合清華大學團隊發佈的開源項目。赤兔定位於「生產級大模型推理引擎」，充分考慮企業 AI 落地從小規模試驗到大規模部署的漸進式需求，專注於提供以下重要特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多元算力適配：不僅支持 NVIDIA 最新旗艦到舊款的多系列產品，也為國產芯片提供優化支持。&lt;/li&gt; 
 &lt;li&gt;全場景可伸縮：從純 CPU 部署、單 GPU 部署到大規模集羣部署，赤兔引擎提供可擴展的解決方案。&lt;/li&gt; 
 &lt;li&gt;長期穩定運行：可應用於實際生產環境，穩定性足以承載併發業務流量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在今年三月首個版本發佈時，赤兔通過底層算子優化（如 GeMM、MoE 的指令級重構）和編譯技術創新，首次實現在無 FP8 硬件單元的算力芯片上原生運行 FP8 高精度模型，賦能眾多存量算力芯片推理 DeepSeek-R1 滿血版大模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364113/chitu-0-4</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364113/chitu-0-4</guid>
      <pubDate>Sat, 02 Aug 2025 09:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>B 站上線「AI 原聲翻譯功能」，將加入日語等語言</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;B 站今年 5 月下架國際版 App，與國內版合併為一個統一 App。為解決海內外內容互通問題，B 站現公佈一項自研的「AI 原聲翻譯功能」，號稱可以幫助海外用戶更好體驗遊戲、科技、二次元等主推內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;據 B 站介紹，&lt;strong&gt;目前相應功能已向海外用戶開放，暫僅支持英語&lt;/strong&gt;，主要提供畫面和音頻兩大翻譯能力，在畫面方面支持自動擦除原中文字幕改為英文、自動翻譯彈幕、各類按鈕語言。在音頻方面號稱可以還原 UP 主的聲線、音色、氣口，而非傳統的機器音翻譯。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img height="259" src="https://oscimg.oschina.net/oscnet/up-a4c2bba74fb87025c787b7a83000654e41b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;B 站表示，相應翻譯功能的技術難點&lt;strong&gt;在於遊戲、二次元等專有名詞梗的密集領域「如何實現原風格精準保留與語音時長完美對應」&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;為此，相應技術團隊基於大語言模型（LLM）構建翻譯引擎，採用對抗式強化學習（RL）訓練驅動模型；並引入 Deep Research 深度挖掘技術，專攻專有名詞與流行梗點的翻譯難點，確保最終譯文準確傳神。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;後續，B 站還將視需求為「AI 原聲翻譯」功能新增日語等更多語言，持續擴展在海外市場的適配能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364111</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364111</guid>
      <pubDate>Sat, 02 Aug 2025 09:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>高德發佈全球首個地圖 AI 原生智能體</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;高德地圖正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4qsBRg16CnO1ayKe6sHiFA" target="_blank"&gt;宣佈&lt;/a&gt;其全面 AI 化，結合前沿的空間智能技術，推出了全球首個 AI 原生地圖應用 —— 高德地圖 2025。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，高德地圖 2025 旨在打造具備深度時空理解和自主推理決策能力的一體化出行生活智能體，以及 AI 領航、AI 即刻、AI 探索、AR 打卡等創新場景工具，為用戶提煉一個更加符合習慣和喜好的個性化數字孿生世界，基於空間智能架構解決一切出行生活需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="228" src="https://oscimg.oschina.net/oscnet/up-f16397c20425bb4922c0dbd519e0b8bed5e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「空間智能是在三維空間和時間中感知、推理、和行動的能力，能夠讓地圖實現被動感知到主動預判的跨越。」高德地圖 CEO 郭寧表示，希望從高德地圖 2025 開始，推動 AI 從 「對話工具」蛻變為「行動夥伴」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;即日起用戶升級高德地圖 APP 至最新版，搜索「空間智能」，即可體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;根據介紹，用戶可與高德主智能體「小高老師」的語音交流。該語音技術以自然語言交互為核心，通過全雙工語音技術實現流暢交流，支持用戶隨時打斷指令、動態調整規劃；內置的回聲消除算法與異常語義拒識模型，可智能去噪以精準聆聽用戶聲音；而情感計算模塊賦予對話溫度，不僅提供清晰的路線指引，更能在旅途中提供情緒陪伴。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;語音感知之後，即進入思考決策環節。基於高德與通義深度共建的大模型簇，小高老師能夠進行基於空間智能的推理、計劃、反思和行動，並通過 MCP 協同調用出行服務、生活服務、空間服務等子智能體和工具鏈，整合內外部知識庫來制定最優方案。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364108</guid>
      <pubDate>Sat, 02 Aug 2025 09:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「問小白」發佈第四代開源大模型 XBai o4，擅長複雜推理</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;「問小白」發佈了第四代開源大模型&lt;strong&gt;XBai o4&lt;/strong&gt;（其中「o」代表「open」），該模型在複雜推理能力方面表現出色，在 Medium 模式下已全面超越&lt;strong&gt;OpenAI-o3-mini&lt;/strong&gt;，並在部分基準測試中優於&lt;strong&gt;Anthropic Claude Opus&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/163409_xSmx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XBai o4 基於創新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRxWjzZe5WWVGKKOk2JbfJQ" target="_blank"&gt;「反思型生成範式」&lt;strong&gt;（reflective generative form）&lt;/strong&gt;&lt;/a&gt;，融合了 Long-CoT 強化學習&lt;strong&gt;與&lt;/strong&gt;過程評分學習（Process Reward Learning），使單個模型同時具備深度推理和高質量推理鏈路篩選的能力。通過共享過程評分模型（PRMs）和策略模型的主幹網絡，XBai o4 顯著降低了 99% 的過程評分推理耗時。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8840d76d6357daa77dda0a67b9e0727ff4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型提供三種模式（low、medium、high），在多個基準測試（如 AIME24、AIME25、LiveCodeBench v5、C-EVAL 等）中均展現出強大性能，相關訓練和評估代碼已在 GitHub 開源。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMetaStone-AI%2FXBai-o4" target="_blank"&gt;https://github.com/MetaStone-AI/XBai-o4&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364101</guid>
      <pubDate>Sat, 02 Aug 2025 08:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI CEO 首次公開 GPT-5 對話界面</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;OpenAI CEO Sam Altman 全網首次公開了 GPT-5 的對話界面，揭示這款尚未發佈的大模型在真實使用場景中的表現。&lt;/p&gt; 
&lt;p&gt;截圖顯示，Altman 向 GPT-5 提問：「什麼是最發人深省的 AI 題材電視劇」。GPT-5 隨即給出了一份詳細推薦清單，內容不僅涵蓋劇集名稱、播出平台和評分，還深入介紹了每部劇集的核心議題與哲學內核。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2bf8d8ceeab9104926e943d4d197b5de237.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;有趣的是，網友的高贊評論卻是吐槽 ChatGPT 的標點使用習慣：「請永久刪除 ChatGPT 中的破折號。」&lt;/p&gt; 
&lt;p&gt;後續，Altman 還表示「很快進入 SaaS 的快時尚時代」，疑似暗示 GPT-5 不僅是一次模型升級，更可能重塑傳統 SaaS 產品的形態與節奏。&lt;/p&gt; 
&lt;p&gt;&lt;img height="290" src="https://static.oschina.net/uploads/space/2025/0804/162106_XXoY_2720166.png" width="1212" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/162136_6vpA_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364098</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364098</guid>
      <pubDate>Sat, 02 Aug 2025 08:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元開源 0.5B、1.8B、4B、7B 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0szU-fwpLjc0alMomEnONA" target="_blank"&gt;宣佈&lt;/a&gt;推出四款開源的小尺寸模型，參數分別為 0.5B、1.8B、4B、7B，消費級顯卡即可運行，適用於筆記本電腦、手機、智能座艙、智能家居等低功耗場景，且支持垂直領域低成本微調。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，新開源的 4 個模型屬於融合推理模型，具備推理速度快、性價比高的特點，用戶可根據使用場景靈活選擇模型思考模式——快思考模式提供簡潔、高效的輸出；而慢思考涉及解決複雜問題，具備更全面的推理步驟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;測評結果：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-8d96ad4baf1db0e93295376a2b639e6be4f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="348" src="https://oscimg.oschina.net/oscnet/up-fff316007c0614bb4b57fb6b9695b5c79d3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這四個模型的亮點在於 agent 和長文能力，跟此前開源的 Hunyuan-A13B 模型一樣，技術上通過精心的數據構建和強化學習獎勵信號設計，提升了模型在任務規劃、工具調用和複雜決策以及反思等 agent 能力上的表現，讓模型實際應用中可以輕鬆勝任深度搜索、excel 操作、旅行攻略規劃等任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，模型原生長上下文窗口達到了 256k，意味着模型可以一次性記住並處理相當於 40 萬中文漢字或 50 萬英文單詞的超長內容，相當於一口氣讀完 3 本《哈利波特》小説 ，並且能記住所有人物關係、劇情細節，還能根據這些內容討論後續故事發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;部署上，四個模型均只需單卡即可部署，部分 PC、手機、平板等設備可直接接入。並且，模型具有較強的開放性，主流推理框架（例如，SGLang，vLLM and TensorRT-LLM）和多種量化格式均能夠支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;應用層面，四款小尺寸模型都能夠滿足從端側到雲端、從通用到專業的多樣化需求，並且已經在騰訊多個業務中應用，可用性和實用性經過了實踐的檢驗，是真正實用的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如，依託模型原生的超長上下文能力，騰訊會議 AI 小助手、微信讀書 AI 問書 AI 助手均實現對完整會議內容、整本書籍的一次性理解和處理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在端側應用上，騰訊手機管家利用小尺寸模型提升垃圾短信識別準確率，實現毫秒級攔截，隱私零上傳；騰訊智能座艙助手通過雙模型協作架構解決車載環境痛點，充分發揮模型低功耗、高效推理的特性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在高併發場景中，搜狗輸入法基於模型的多模態聯合訓練機制使嘈雜環境下提升識別準確率；騰訊地圖採用多模型架構，利用意圖分類和推理能力提升了用戶交互體驗；微信輸入法「問 AI」基於模型實現輸入框與 AI 即問即答的無縫銜接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在需求各異、約束嚴苛的垂直行業應用中，金融 AI 助手通過 Prompt 優化和少量數據微調實現 95%+意圖識別準確率，展現出金融級的高可靠性；遊戲翻譯和 QQ 飛車手遊 NPC 充分利用模型的理解能力在多語言理解能力、方言翻譯和智能對話方面有突出表現，這些能力在專業客服、內容出海甚至電商直播等場景有巨大應用潛力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364095</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364095</guid>
      <pubDate>Sat, 02 Aug 2025 08:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Eclipse SUMO - 交通模擬工具套件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;a href="https://sumo.dlr.de/"&gt;"Simulation of Urban MObility" (SUMO)&lt;/a&gt;&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;是一個開源、高度便攜、微觀交通模擬包，旨在處理大型道路網絡和不同的交通方式。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;它支持包括行人在內的多式聯運模擬，並附帶大量用於場景創建的工具。&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;code&gt;git clone --recursive https://github.com/eclipse-sumo/sumo
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;img alt="" height="210" src="https://static.oschina.net/uploads/space/2025/0804/151521_l9bX_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/eclipse-sumo</link>
      <guid isPermaLink="false">https://www.oschina.net/p/eclipse-sumo</guid>
      <pubDate>Sat, 02 Aug 2025 07:55:00 GMT</pubDate>
    </item>
    <item>
      <title>Meta 有望收購 AI 視頻初創公司 Pika Labs</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta 日前正在積極尋求與 AI 視頻生成技術的初創公司建立合作伙伴關係，旨在發力視頻生成領域。&lt;/p&gt; 
&lt;p&gt;知情人士稱，Meta 近期與 AI 視頻初創公司 Pika 就潛在合作展開了討論，內容包括可能的收購或技術授權協議。另據透露，Meta 還與另一家專注於創作者的小型視頻生成商 Higgsfield 討論過收購事宜，但目前談判已暫停。&lt;/p&gt; 
&lt;p&gt;據悉，Pika 以生成逼真視頻的 AI 技術而知名。而據公開信息，郭文景是 Pika Labs 的聯合創始人與 CEO。她與聯合創始人兼 CTO Chenlin Meng 均為斯坦福大學 AI Lab 博士生，在 2023 年 4 月從斯坦福輟學、創立了 Pika Labs，致力於開發基於文本生成短視頻的 AI 工具。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，郭文景入讀斯坦福讀博前還曾任職於 Meta AI 研究團隊。據瞭解，郭文景自幼展現非凡學術天賦，被譽為「學霸少女」，是浙江杭二中首個被哈佛本科提前錄取的學生 。&lt;/p&gt; 
&lt;p&gt;另外，Pika 僅成立半年便爆紅，團隊最初只有四人，卻在 2023 年完成三輪融資，籌資約 5500 萬美元，估值約 2–3 億美元；隨後在 2024 年 B 輪融資約 8000 萬美元，使估值上漲至近 5 億美元。&lt;/p&gt; 
&lt;p&gt;Pika 的&lt;a href="https://www.oschina.net/news/361912"&gt;核心產品&lt;/a&gt;為「文生視頻」模型，號稱用戶一句話描述，就能生成風格多樣的動畫短視頻。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364087</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364087</guid>
      <pubDate>Sat, 02 Aug 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義 Qwen3 模型拿下全球第三</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;國際知名大模型評測 Chatbot Arena 日前公佈最新榜單，Qwen3-235B-A22B-Instruct-2507 斬獲 1433 分，超越頂尖閉源模型 Grok4、Claude4、GPT4.1，Qwen3 位列總榜「全球第三」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1440" src="https://static.oschina.net/uploads/space/2025/0804/153306_pv7H_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，Chatbot Arena 採用盲測評價機制，是 AI 大模型領域最具影響力的榜單之一。&lt;/p&gt; 
&lt;p&gt;此次 Qwen3 的 1433 分，是全球開源大模型和中國大模型的歷史最高分。同時，Qwen3 還在 5 個關鍵能力子項中摘得「全球第一」，包括數學（math）、代碼（coding）、複雜提示（hard prompts）、長文本檢索（longer query）和指令遵循（instruction following）。&lt;/p&gt; 
&lt;p&gt;除 Qwen3 Instruct 模型外，Qwen3 家族多款模型也取得優秀成績：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;推理模型 Qwen3-235B-A22B-Thinking-2507 也闖進榜單前十，數學能力並列全球第一；&lt;/li&gt; 
 &lt;li&gt;在 Chatbot Arena 專門評估編程能力的 WebDev Arena 子榜單中，編程模型 Qwen3-Coder 性能與 Gemini2.5 Pro、DeepSeek-R1、Claude4 並列第一。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153340_6oDO_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153435_soAg_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/153506_LT7j_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364084</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364084</guid>
      <pubDate>Sat, 02 Aug 2025 07:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>7 月 Chrome 份額達 69.98%，接近歷史新高</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;Statcounter 最新數據顯示，谷歌 Chrome 瀏覽器在 7 月的份額進一步鞏固，達到了 69.98%，幾乎接近歷史新高，較上月增長了 3.09 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與此同時，微軟 Edge 瀏覽器的市場份額卻出現了下滑，2025 年 7 月，Edge 的市場份額從 13.06% 下降至 11.8%，流失了相當一部分用戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-4deb5717a3ebf7e551b81308cac02cc5d2a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 Chrome 和 Edge 之外，其他瀏覽器的市場份額也有所下降，蘋果的 Safari 以 6.51% 的市場份額位居第三，較上月下降了 1.83 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Firefox 以 5.32% 的市場份額位居第四，較上月下降了 0.52 個百分點；Opera 則以 2.2% 的市場份額位居第五，較上月下降了 0.43 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-8174cbe98fe739c689d75e4f46138fdb892.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在移動市場，Chrome 的主導地位同樣明顯，以 67.32% 的市場份額位居第一，蘋果 Safari 以 22.42% 的市場份額位居第二，三星瀏覽器以 3.5% 的市場份額位居第三。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟 Edge 雖然具備一些獨特實用功能，但在移動市場上的份額仍然微不足道。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364068</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364068</guid>
      <pubDate>Sat, 02 Aug 2025 06:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Android Studio 免費 Agent 模式上線</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌在其官方開發者博客及 Google I/O2025 大會上宣佈，Android Studio 正式推出免費的 Agent 模式，為安卓應用開發引入了革命性的 AI 輔助功能。這一功能的發佈不僅大幅提升了開發效率，還憑藉其智能化的交互方式和靈活的自定義規則支持，被業界認為是對蘋果開發生態的有力挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Android Studio 的 Agent 模式是基於 Gemini2.5Pro 的 AI 輔助功能，旨在通過自然語言交互幫助開發者完成複雜、多步驟的開發任務。相較於傳統的代碼補全或建議功能，Agent 模式能夠深入理解整個項目上下文，自動制定執行計劃，並在開發者指導下完成從代碼生成到錯誤修復的完整工作流。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="343" src="https://oscimg.oschina.net/oscnet/up-c81c59459ff6d229a26c159791d8a845b17.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心功能亮點：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自然語言任務描述：開發者只需用自然語言描述目標，例如「修復項目中的構建錯誤」或「為應用添加深色模式支持」，Agent 模式即可生成跨多個文件的執行計劃，自動編輯代碼、添加依賴並修復錯誤。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;UI 代碼快速修改：Agent 模式支持直接選中並修改 UI 代碼。例如，開發者可以要求「在主屏幕添加一個‘關注’按鈕」或「減少某個組件的內邊距」，Agent 會精準定位相關文件並提出修改建議，開發者可通過「接受」或「拒絕」按鈕進行審核。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;自定義規則支持：通過 Prompt Library，開發者可以設置項目特定的編碼風格或技術棧偏好，例如「始終使用 Kotlin 生成簡潔代碼」。這些規則將自動應用於後續任務，確保輸出的代碼符合項目標準。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;百萬 Token 上下文窗口：免費版本的 Agent 模式提供有限的上下文窗口，但訂閲 Google AI Ultra 或使用 Gemini API 密鑰的開發者可解鎖 Gemini2.5Pro 的 100 萬 Token 上下文窗口，支持處理超大規模代碼庫和複雜任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌強調，Agent 模式不僅能處理常規任務，還能通過 Model Context Protocol （MCP）與外部工具集成，例如直接從 Android Studio 創建 GitHub 拉取請求，進一步擴展其功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;效率飛躍:從繁瑣任務到創意開發&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的推出旨在解放開發者，讓他們從繁瑣的重複性工作中解脫出來，專注於更具創造性的開發任務。例如，開發者可以委託 Agent 模式完成以下任務:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自動化依賴更新：通過 Version Upgrade Agent，自動分析項目依賴、解析發行説明並更新到&lt;span&gt;最新&lt;/span&gt;兼容版本，同時生成詳細的變更報告。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;用戶旅程測試：開發者可以用自然語言描述用戶旅程（如「測試登錄流程」），Agent 模式會自動生成測試腳本並在虛擬或物理設備上運行，輸出詳細結果。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;多文件重構：如將硬編碼字符串提取到 strings.xml 文件，或對整個項目進行復雜的代碼重構，Agent 模式都能逐步執行並允許開發者實時審查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌表示，Agent 模式通過結合 Android Studio 的內置工具（如代碼搜索、構建系統和 UI 檢查器），能夠以最小的監督完成從原型設計到錯誤修復的全流程任務，顯著加速開發週期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的免費開放被視為谷歌對蘋果 Xcode 生態的強力回應。蘋果的 Xcode 雖然在 iOS 開發中佔據主導地位，但其 AI 輔助功能相對滯後，缺乏類似 Agent 模式的自主 AI 特性。谷歌通過免費提供 Agent 模式（默認配額充足）以及支持 Gemini2.5Pro 的付費訂閲模式，降低了開發者的使用門檻，同時提供了更高的靈活性和性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，Android Studio Narwhal Feature Drop（2025.2 版本）還引入了其他增強功能，如:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;Google Play 政策洞察：通過 Lint 檢查提供 Play Store 政策合規性建議，幫助開發者避免上架問題。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;XR 開發支持：新增 Jetpack XR 項目模板和嵌入式佈局檢查器，優化了擴展現實（XR）應用的開發體驗。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;Kotlin K2 模式：支持 Live Edit 和 Compose Preview 等功能，提升 Kotlin 開發的流暢性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式目前已在 Android Studio Narwhal Feature Drop（2025.2Canary 版本）中向所有用戶開放，商業訂閲用戶將在未來幾周內獲得更完整的功能支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管該功能仍處於實驗階段，部分開發者反饋指出其在調用外部工具或處理特定場景時存在侷限性，例如無法完全訪問源文件或修改外部資源。谷歌已表示正在積極解決這些問題，並計劃在未來版本中支持更完整的 MCP 功能，如 Streamable HTTP 傳輸和外部上下文資源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364062</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364062</guid>
      <pubDate>Sat, 02 Aug 2025 06:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
