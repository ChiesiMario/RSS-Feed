<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 01 Jul 2025 07:48:21 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微軟開源 GitHub Copilot Chat 的 VS Code 擴展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟在 5 月舉辦的開發者大會上&lt;a href="https://www.oschina.net/news/350732/ms-vs-code-open-source-ai-editor"&gt;宣佈&lt;/a&gt;要將 VS Code 打造成開源 AI 編輯器，近日該計劃達成了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fblogs%2F2025%2F06%2F30%2FopenSourceAIEditorFirstMilestone" target="_blank"&gt;首個里程碑&lt;/a&gt;——GitHub Copilot Chat 的 VS Code 擴展采用 MIT 開源許可證正式開源。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1098" src="https://static.oschina.net/uploads/space/2025/0701/153012_qXMd_2720166.png" width="2460" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-chat" target="_blank"&gt;https://github.com/microsoft/vscode-copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該擴展提供了類似 Cursor 的 Chat 面板，通過聊天的方式來編輯代碼，它還可以根據代碼提交者、變量和斜線命令等信息，給出與代碼庫相關的回答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a176b7fa906f848e0f9b0982762510cc49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-190bfc8a0cc77c524892684d44d95a0f15c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;擴展地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat" target="_blank"&gt;https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;由於 Copilot Chat 與 VS Code 深度集成，其發佈與 VS Code 同步進行，因此每個新版本的 Copilot Chat 僅兼容最新版本的 VS Code。這意味着如果你使用的是舊版本的 VS Code，將無法使用最新的 Copilot Chat。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358178</guid>
      <pubDate>Tue, 01 Jul 2025 07:31:35 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節、騰訊、阿里等 13 家頭部企業去年利潤總額同比增 19.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;5 月底結束的 2024 年度企業所得稅彙算清繳數據顯示，字節跳動、騰訊、阿里巴巴等 13 家頭部企業營業收入和利潤總額同比分別增長 11.9%、19.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上述企業是數字經濟領域的代表企業，彙算清繳數據顯示，2024 年度，數字經濟及其核心產業營業收入和利潤總額同比分別增長 5.9%、2.7%。其中，信息傳輸、軟件和信息技術服務業營業收入和利潤總額同比分別增長 11.5%、13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除數字經濟外，2024 年度，醫藥製造、航空航天等高技術產業營業收入和利潤總額同比分別增長 8.9%、7.5%。細分行業看，科學研究和技術服務業營業收入和利潤總額同比分別增長 11.7%、7.5%，航空航天產業營業收入和利潤總額同比分別增長 10.5%、26.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，機器人產業也步入發展快車道，近兩年機器人產業營業收入平均同比增長 10.2%。其中，特殊作業機器人、服務消費機器人、工業機器人 2024 年度同比分別增長 28.4%、12.4%、7%，多場景應用加速落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;總體上看，數字經濟、高技術產業、機器人產業三個領域 2024 年度共減免企業所得稅 1.97 萬億元，總營業收入同比增長 7.1%，利潤總額同比增長 5.2%，我國新質生產力持續發展壯大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家稅務總局相關負責人表示，稅務部門將不折不扣落實落細結構性減稅降費政策，同時，依法嚴厲打擊違規享受、惡意騙取稅費優惠等違法行為，堅決防止政策「紅包」落入不法分子「腰包」。（新京報）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358163</guid>
      <pubDate>Sun, 11 May 2025 06:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻數科面向香港市場開放四大自研技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻數科面向香港市場開放四大自研技術——Layer2 網絡、大模型開發工具、「區塊鏈+IoT」可信架構、機構級 Web3 錢包技術，為香港建設全球數字資產創新中心提供全棧技術服務。&lt;/p&gt; 
&lt;p&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-e94b03fe5b81530ba178b109352a29a4037.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;資料顯示，螞蟻數科自 2016 年起投入區塊鏈技術研發，全球區塊鏈授權專利排名第一，核心技術如智能合約、網絡傳輸、存儲引擎、跨鏈技術等已取得重大突破，處於全球領先水平。此前，螞蟻數科作為核心成員加入香港金管局 Ensemble 沙盒，並宣佈將海外總部落戶香港。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358160</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358160</guid>
      <pubDate>Sun, 11 May 2025 05:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Forest v1.7 發佈！前方高能，一大波新特性來襲！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;&lt;strong&gt;Forest 介紹&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;Forest 是一個開源的 Java HTTP 客戶端框架，它能夠將 HTTP 的所有請求信息（包括 URL、Header 以及 Body 等信息）綁定到您自定義的 Interface 方法上，能夠通過調用本地接口方法的方式發送 HTTP 請求&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;簡單的栗子&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聲明式接口&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;創建一個 interface，並用&lt;code&gt;@Get&lt;/code&gt;註解修飾接口方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span style="color:#c678dd"&gt;public&lt;/span&gt; &lt;span&gt;&lt;span style="color:#c678dd"&gt;interface&lt;/span&gt; &lt;span style="color:#e6c07b"&gt;MyClient&lt;/span&gt; &lt;/span&gt;{
    &lt;span style="color:#61aeee"&gt;@Get&lt;/span&gt;(&lt;span style="color:#98c379"&gt;"http://localhost:8080/hello"&lt;/span&gt;)
    &lt;span&gt;String &lt;span style="color:#61aeee"&gt;hello&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;通過&lt;code&gt;@Get&lt;/code&gt;註解，將上面的 MyClient 接口中的&lt;code&gt;simpleRequest()&lt;/code&gt;方法綁定了一個 HTTP 請求， 其 URL 為&lt;code&gt;http://localhost:8080/hello&lt;/code&gt;，並默認使用 GET 方式，且將請求響應的數據以 String 的方式返回給調用者&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;編程式接口&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;Forest.get(&lt;span style="color:#98c379"&gt;"http://localhost:8080/hello"&lt;/span&gt;).execute();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;編程式接口則更為簡單直接&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;v1.7 版本升級&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;本次發佈包含了很多重大更新內容，我們對字符串模板的語法進行了增強，支持了空安全語法和深度變量引用，並提供了更友好的報錯信息；在 Cookie 方面也進行了增強，提供了 Cookie 自動保存和讀取的機制，並添加了更完善的 API 接口；我們也對攔截器進行了優化改進，不再建議直接使用&lt;code&gt;Interceptor&lt;/code&gt;接口和它的&lt;code&gt;onSuccess&lt;/code&gt;方法，取而代之的是&lt;code&gt;ForestInterceptor&lt;/code&gt;和&lt;code&gt;onResponse&lt;/code&gt;方法，它們要比前者更安全，性能也更好；除此之外，此次更新對請求的性能進行了全面的優化，在默認使用編程式接口、不打印日誌的情況下，可以達到和 hutool 的 HttpUtil 差不多的耗時。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;v1.7 新增的一大波特性&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;空安全語法&lt;/li&gt; 
 &lt;li&gt;Elvis 表達式&lt;/li&gt; 
 &lt;li&gt;深度引用&lt;/li&gt; 
 &lt;li&gt;嵌套字符串模板&lt;/li&gt; 
 &lt;li&gt;更安全的攔截器&lt;/li&gt; 
 &lt;li&gt;請求級別日誌開關&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;空安全語法&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;在原來版本，如果在字符串模板中引用一個沒定義過的變量會支持報錯。現在用空安全語法可以讓它不再報錯，而是直接返回 null 值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 沒定義過 testVar 變量，通過 ? 一樣可以正常引用&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/test/{testVar?}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;或者，引用了一個不存在或值為 null 的變量後，再用點&lt;code&gt;.&lt;/code&gt;訪問它的屬性，這在老版本中自然是直接報錯的。現在，可以通過&lt;code&gt;?.&lt;/code&gt;符號自動判斷是否為空。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 會先判斷 testVar 是否為空，然後 testVar.a 是否為空，其中一個為空就會直接返回 null&lt;/em&gt;
&lt;em&gt;// 不會報錯&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/test/{testVar?.a?.name}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Elvis 表達式&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;新版本支持使用 Elvis 操作符&lt;code&gt;??&lt;/code&gt;，也稱為是空值合併操作符。簡單來説就是在一個變量或一個表達式後面追加兩個問號 (&lt;code&gt;??&lt;/code&gt;)，並在它的右邊再跟上一個表達式作為左邊變量或表達式為空的情況下所返回的默認值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 如果變量 a 為空或未定義，則返回字符串 ok&lt;/em&gt;
&lt;em&gt;// 最後 URL 為 http://localhost:8080/ok&lt;/em&gt;
&lt;em&gt;// 若變量 a 不為空，則返回它自己的值&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"http://localhost:8080/{a ?? 'ok'}"&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;Elvis 表達式也可以和空安全屬性訪問操作符&lt;code&gt;?.&lt;/code&gt;相結合&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 如果變量 a 為空或未定義，則返回字符串 ok，不會再繼續讀取 a.b &lt;/em&gt;
&lt;em&gt;// 最後 URL 為 http://localhost:8080/ok&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"http://localhost:8080/{a?.b ?? 'ok'}"&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;深度引用&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;在原來版本中，字符串模板中的變量只能引用到第一層，如果該變量的值是引用其他的變量，字符串模板並不會進行解析。而現在，不管引用了多少層變量，都可以解析到底。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span style="color:#d19a66"&gt;forest:&lt;/span&gt;
  &lt;span style="color:#d19a66"&gt;variables:&lt;/span&gt;
    &lt;span style="color:#d19a66"&gt;var1:&lt;/span&gt; &lt;span style="color:#98c379"&gt;"{user.name}"&lt;/span&gt;
    &lt;span style="color:#d19a66"&gt;var2:&lt;/span&gt; &lt;span style="color:#98c379"&gt;"{user.password}"&lt;/span&gt;
    &lt;span style="color:#d19a66"&gt;user:&lt;/span&gt;
      &lt;span style="color:#d19a66"&gt;name:&lt;/span&gt; &lt;span style="color:#98c379"&gt;foo&lt;/span&gt;
      &lt;span style="color:#d19a66"&gt;password:&lt;/span&gt; &lt;span style="color:#98c379"&gt;bar&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;在 Java 代碼中直接引用&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 最終 URL 為: /test/foo/bar&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/test/{var1}/{var2}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;如果不想進行深度引用，可以使用深度引用停止語法，即在變量後加上&lt;code&gt;!&lt;/code&gt;符號，那麼就只會引用一層該變量的值，至於該變量的值是否會包含其他字符串模板的內容，就不會再進行解析了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 最終 URL 為: /test/{user.name}/{user.password}&lt;/em&gt;
&lt;em&gt;// 變量 var1 和 var2 的值直接返回字符串，而不會進行任何解析&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/test/{var1!}/{var2!}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;嵌套字符串模板&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;用兩個反引號&lt;code&gt;`&lt;/code&gt;將要拼接的字符串內容包裹起來 (如 &lt;code&gt;`字符串模板內容`&lt;/code&gt;)，並且當中可以使用&lt;code&gt;`#{配置屬性}`&lt;/code&gt;、&lt;code&gt;`${表達式}`&lt;/code&gt;、&lt;code&gt;`{表達式}`&lt;/code&gt;等嵌套表達式語法&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;// 如果 a 為空，則返回 b 和 c 用斜槓拼接後的字符串&lt;/em&gt;
&lt;em&gt;// 若 a 為空, b 為 foo，c 為 bar，則 URL 為 /foo/bar&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/{a ?? `{b}/{c}`}"&lt;/span&gt;)

&lt;em&gt;// 任何一種形態內容都可以，可以理解為就是一種字符串，一種在表達式內部可動態拼接的字符串&lt;/em&gt;
Forest.get(&lt;span style="color:#98c379"&gt;"/{a ?? `?b={b}&amp;amp;c={c}`}"&lt;/span&gt;)

&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;更安全的攔截器&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;本次版本更新後，不再建議使用&lt;code&gt;Interceptor&lt;/code&gt;(當然要用也可以用，不影響以前的老代碼)，同時引入了更安全的&lt;code&gt;ForestInterceptor&lt;/code&gt;接口&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span style="color:#c678dd"&gt;public&lt;/span&gt; &lt;span&gt;&lt;span style="color:#c678dd"&gt;class&lt;/span&gt; &lt;span style="color:#e6c07b"&gt;MyInterceptor&lt;/span&gt; &lt;span style="color:#c678dd"&gt;implements&lt;/span&gt; &lt;span style="color:#e6c07b"&gt;ForestInterceptor&lt;/span&gt; &lt;/span&gt;{


    &lt;span style="color:#61aeee"&gt;@Override&lt;/span&gt;
    &lt;span&gt;&lt;span style="color:#c678dd"&gt;public&lt;/span&gt; ResponseResult &lt;span style="color:#61aeee"&gt;onResponse&lt;/span&gt;&lt;span&gt;(ForestRequest request, ForestResponse response)&lt;/span&gt; &lt;/span&gt;{
        &lt;span style="color:#c678dd"&gt;if&lt;/span&gt; (response.isError()) {
            &lt;em&gt;// 返回錯誤標誌&lt;/em&gt;
            &lt;span style="color:#c678dd"&gt;return&lt;/span&gt; error(response.getException());
        }
        &lt;em&gt;// 通過 response.getResult() 或 response.get(數據類型.class) 來獲取響應數據&lt;/em&gt;

        &lt;em&gt;// 返回繼續執行標誌&lt;/em&gt;
        &lt;span style="color:#c678dd"&gt;return&lt;/span&gt; proceed();
    }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;請求級別日誌開關&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;不再需要 new 一個 LogConfiguration 對象，直接在 ForestRequest 的鏈式調用中即可設置日誌開關&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Forest.post(&lt;span style="color:#98c379"&gt;"/test"&lt;/span&gt;)
        .logEnabled(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;) &lt;em&gt;// 請求日誌總開關&lt;/em&gt;
        .logRequest(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;) &lt;em&gt;// 請求內容日誌開關&lt;/em&gt;
        .logRequestHeaders(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;) &lt;em&gt;// 請求頭日誌開關&lt;/em&gt;
        .logRequestBody(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;)  &lt;em&gt;// 請求體日誌開源&lt;/em&gt;
        .logResponseStatus(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;) &lt;em&gt;// 響應狀態日誌開關&lt;/em&gt;
        .logResponseHeaders(&lt;span style="color:#c678dd"&gt;true&lt;/span&gt;) &lt;em&gt;// 響應頭日誌開關&lt;/em&gt;
        .logResponseContent(&lt;span style="color:#c678dd"&gt;false&lt;/span&gt;) &lt;em&gt;// 響應體內容日誌開關&lt;/em&gt;
        .execute();
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;strong&gt;官網和倉庫地址&lt;/strong&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;官網地址:&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;http://forest.dtflyx.com&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;Gitee 倉庫地址:&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;https://gitee.com/dromara/forest&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;Github 倉庫地址:&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;https://github.com/dromara/forest&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;本次更新內容&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;feat: 字符串模板支持空安全語法&lt;/li&gt; 
 &lt;li&gt;feat: 更友好的字符串模板錯誤消息&lt;/li&gt; 
 &lt;li&gt;feat: 字符串模板&lt;code&gt;{&lt;/code&gt;、&lt;code&gt;${&lt;/code&gt;等符號支持轉義&lt;code&gt;\\\\{&lt;/code&gt;、&lt;code&gt;\\\\${&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;feat: 字符串模板支持深度變量引用&lt;/li&gt; 
 &lt;li&gt;feat: 字符串模板支持停止深度引用的語法&lt;/li&gt; 
 &lt;li&gt;feat: 支持嵌套字符串模板&lt;/li&gt; 
 &lt;li&gt;feat: 新增更安全的 Forest 攔截器接口 ForestInterceptor&lt;/li&gt; 
 &lt;li&gt;feat: 通過配置自定義異步線程池拒絕策略&lt;/li&gt; 
 &lt;li&gt;feat: 支持 Bear 認證器&lt;/li&gt; 
 &lt;li&gt;feat: 支持&lt;code&gt;@Var&lt;/code&gt;作為方法和類的變量綁定註解&lt;/li&gt; 
 &lt;li&gt;feat: 新增 ForestRequest 級別的日誌開關接口&lt;/li&gt; 
 &lt;li&gt;feat: 增強 Cookie 相關 API 接口&lt;/li&gt; 
 &lt;li&gt;feat: 後台自動清理過期 Cookie&lt;/li&gt; 
 &lt;li&gt;feat: 支持 Cookie 自動化存取機制&lt;/li&gt; 
 &lt;li&gt;fix: 和老版本 forest 衝突時，新版本 Forest 類缺乏 get(url)、post(url) 等方法簽名，造成錯誤 (#IC7LIH)&lt;/li&gt; 
 &lt;li&gt;fix: body log 在部分環境中文亂碼&lt;/li&gt; 
 &lt;li&gt;fix: 修改接口中常量的命名，避免用戶在其與只有大小寫區別的方法之間產生混淆&lt;/li&gt; 
 &lt;li&gt;fix: 調用聲名式接口的 hashCode() 方法會死循環&lt;/li&gt; 
 &lt;li&gt;fix: 以 ForestResponse 為返回類型時，T 的子類匹配問題&lt;/li&gt; 
 &lt;li&gt;fix: 重複讀取響應流時報錯&lt;/li&gt; 
 &lt;li&gt;fix: 嵌套 json 字符串無法正常解析&lt;/li&gt; 
 &lt;li&gt;refactor: 重構 URL 解析過程&lt;/li&gt; 
 &lt;li&gt;refactor: 重構變量作用域&lt;/li&gt; 
 &lt;li&gt;refactor: 重構 Forest 變量體系&lt;/li&gt; 
 &lt;li&gt;refactor: ForestCookie 不再依賴 OkHttp&lt;/li&gt; 
 &lt;li&gt;refactor: ForestCookie.parse() 接口&lt;/li&gt; 
 &lt;li&gt;refactor: 添加鍵值對類型請求體刪除接口 ForestBody.removeNameValueBody&lt;/li&gt; 
 &lt;li&gt;optimize: 優化請求性能&lt;/li&gt; 
 &lt;li&gt;optimize: 根據 Response 類型動態判斷響應是否自動關閉&lt;/li&gt; 
 &lt;li&gt;optimize: 默認後端改為 httpclient&lt;/li&gt; 
 &lt;li&gt;optimize: 攔截器優化&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358148/forest-1-7-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358148/forest-1-7-released</guid>
      <pubDate>Sun, 11 May 2025 05:21:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>加鎖失效，非鎖之過，加之錯也</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：京東零售，邢成&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;多個進程或線程同時 (或着説在同一段時間內) 訪問同一資源會產生併發問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;銀行兩操作員同時操作同一賬戶就是典型的例子。比如 A、B 操作員同時讀取一餘額為 1000 元的賬戶，A 操作員為該賬戶增加 100 元，B 操作員同時為該賬戶減去 50 元，A 先提交，B 後提交。 最後實際賬戶餘額為 1000-50=950 元，但本該為 1000+100-50=1050。&lt;strong&gt;這就是典型的併發問題&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從事零售供應鏈庫存業務，對庫存數量操作增減十分頻繁，同樣存在類似上述銀行取款遇到的問題，庫存數量操作有誤勢必給前台銷售產生損失影響，因此需要關注對庫存數量併發操作下的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;下面通過一個真實的案例分享在併發情況下如何保證庫存數量的準確性。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;問題是什麼-加鎖失效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;看看下面這段流程和代碼，思考會有併發問題嗎？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c52b6c3f660ed58046c9e16a5be9c444.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;加鎖前&lt;/strong&gt; &lt;strong&gt;，獲取箱子明細數據，此處在鎖之外，存在併發髒讀問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//1036ef25fae37b26c448522f6777c80c.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;加鎖後&lt;/strong&gt; &lt;strong&gt;，並進行箱子上架分批次回傳業務處理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//020a84a9615ca8e8cec22118aefca76f.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;加鎖後，&lt;/strong&gt; &lt;strong&gt;更新箱子明細上架數量邏輯：已上架數量 = 加鎖前的明細數據（髒讀） + 報文回傳的明細數據，直接進行行更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//21d80ae4a594960a582dde2c19321099.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;原因是什麼-加鎖的位置不正確&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//20d9ce564f5386039bb12242e16ef05b.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心的問題原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;業務分佈式鎖失效：&lt;/strong&gt; 使用分佈式鎖加鎖了，但是仍然使用加鎖前查詢的數據，導致出現髒讀&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;Mysql 鎖失效：&lt;/strong&gt; 數據庫更新時，未上任何鎖，導致髒讀的數據直接覆蓋更新當前行&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有同學這時問了，為啥防重碼也沒有生效呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;防重碼主要是用作冪等邏輯的，同一個請求多次處理，結果仍然是相同的。&lt;/p&gt; 
&lt;p&gt;但是這是兩次不同的請求，防重碼是不同的，因此不能只依賴防重碼保證一致性。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;解決方案有哪些&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1、代碼層面：&lt;/strong&gt; 使用鎖（如互斥鎖、讀寫鎖、分佈式鎖等）來控制資源的訪問，數據獲取的全部操作都需要再獲取鎖後才進行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;將獲取箱子明細的代碼移動到加鎖之後，只有獲取到分佈式鎖，才能執行分批次上架查詢和更新（串行化）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5ffc0121557805521cbb33921c4be06a.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;對應改造後的代碼：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//751c2001d8d70843f24dcf8b6fa5eaa6.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、數據庫層面：&lt;/strong&gt; 實現事務管理，確保數據的一致性；合理設置事務隔離級別，以防止髒讀、或者採用樂觀鎖或悲觀鎖來處理併發更新，合理設計查詢效率，減少鎖競爭。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;數據庫的併發上鎖處理和業務代碼的上鎖是互補的關係&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;因為無法保證後續業務的調整或其他業務代碼的調用能始終保持獲取數據的一致性，數據庫的併發上鎖處理更多是一種兜底保證機制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;樂觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e4262e1d681aa19763c8066296032481.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;悲觀鎖更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4078a93beef3c9b077595bb8968b3a5d.webp" alt="在這裏插入圖片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;擴展方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;應用程序設計：&lt;/strong&gt; 在應用程序設計階段，儘量避免長時間持有數據庫連接或事務，減少併發操作的可能性，利用 AI 代碼評審或者人工提前找出可能出現併發問題的地方；合理設置鎖的粒度，避免鎖失效。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;網絡負載層面：&lt;/strong&gt; 採用限流控制訪問頻率；採用分佈式數據庫，進行數據分片，降低單節點併發壓力；使用負載均衡，將網絡請求分發到不同的服務器，提高系統處理併發的能力，防止系統過載。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;請求層面：&lt;/strong&gt; 前端點擊防重、系統冪等防重、儘可能降低同一請求的多次重試訪問引起的一致性問題。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;通過以上措施，可以在不同層面有效地防止併發問題，保證系統的數據的一致性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18638221</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18638221</guid>
      <pubDate>Sun, 11 May 2025 03:26:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>通義千問 Qwen-TTS 新增支持北京話、上海話和四川話中文方言</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通義千問團隊更新並&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-VDOJrDgVzC6JI4CVTHe4w" target="_blank"&gt;上線&lt;/a&gt;了 Qwen-TTS 文本轉語音服務，&amp;nbsp;新增支持生成三種中文方言，包括北京話、上海話和四川話。&lt;/p&gt; 
&lt;p&gt;據介紹，Qwen-TTS 使用了超過 300 萬小時的大規模語料庫進行訓練，合成效果達到了人類級別的自然度和表現力，旨在提供超自然、富有表現力的音頻，並能智能處理韻律、語速和情感。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Qwen-TTS 能夠根據輸入文本自動調整韻律、節奏和情緒變化，進一步提升語音的真實感和表達力。&lt;/p&gt; 
&lt;p&gt;目前，Qwen-TTS 支持七種中英雙語音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京話）、Jada（上海話） 和 Sunny（四川話）。未來，我們還將推出更多語言和語音風格，進一步豐富用戶的選擇體驗。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen-tts%2F" target="_blank"&gt;https://qwenlm.github.io/blog/qwen-tts/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358128/qwen-tts</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358128/qwen-tts</guid>
      <pubDate>Sun, 11 May 2025 03:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>消息稱蘋果考慮讓 Anthropic 和 OpenAI 為 Siri 提供支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#212623"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fapple-weighs-replacing-siri-s-ai-llms-with-anthropic-claude-or-openai-chatgpt" target="_blank"&gt;彭博社&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;報道稱，蘋果正在考慮使用 OpenAI 和 Anthropic 的 AI 模型來支持其更新版 Siri，而不是使用該公司內部開發的技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="329" src="https://oscimg.oschina.net/oscnet/up-b75a8d1cc618ffd03df5516bae4e561bc31.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息指出，蘋果公司正在繼續構建一個名為「LLM Siri」的內部項目，該項目使用內部 AI 模型。但該公司已要求 OpenAI 和 Anthropic 訓練其可在蘋果雲基礎設施上運行的 AI 模型版本，以供測試。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由於一系列技術挑戰，蘋果被迫將原定於 2025 年發佈的人工智能 Siri 推遲到 2026 年或更晚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一失敗或許由來已久；過去幾年，蘋果在 AI 競賽中一直落後於谷歌、OpenAI 和 Anthropic。雖然 Siri 已經可以調用 ChatGPT 來回答難題，但蘋果現在似乎正在探索與第三方 AI 提供商的技術進行更深入的整合。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358124</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358124</guid>
      <pubDate>Sun, 11 May 2025 02:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程助手 Cursor 提供 Web 和移動端版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程助手 Cursor &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fcn%2Fblog%2Fagent-web" target="_blank"&gt;推出&lt;/a&gt;&lt;/u&gt;了可在網頁和移動設備上使用的 AI Agent 功能。用戶現在可以通過瀏覽器或手機隨時啓動複雜的編碼任務，例如修復錯誤或進行代碼庫問答，並讓 Agent 在後台運行。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1522" src="https://static.oschina.net/uploads/space/2025/0701/102654_ieGo_2720166.png" width="1684" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1078" src="https://static.oschina.net/uploads/space/2025/0701/102948_z9W9_2720166.png" width="1398" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務完成後，用戶可以在桌面端的 Cursor IDE 中無縫銜接，審查、合併代碼修改，或與團隊成員分享鏈接進行協作。&lt;/p&gt; 
&lt;p&gt;該功能支持並行執行，用戶可以同時啓動多個使用不同模型的 Agent，並比較結果以選擇最佳方案。為了獲得更好的移動端體驗，Cursor 支持安裝為漸進式網絡應用（PWA），從而實現推送通知、全屏界面和離線查看等原生應用體驗。此外還集成了 Slack，用戶可以直接在 Slack 中通過提及@Cursor 來觸發 Agent。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2c82f625dd429efeb71a6d75f6189dbb4bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;定價方面，網頁和移動端 Agent 與 Background Agents 採用相同的模式，目前運行計算本身免費，僅根據用戶選擇的 AI 模型收取使用費。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.cursor.com%2Fget-started%2Fweb-and-mobile-agent%23slack-integration-not-working" target="_blank"&gt;詳情查看文檔&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</guid>
      <pubDate>Sun, 11 May 2025 02:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 澄清與谷歌芯片傳聞：並無大規模合作計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;日前，有報道稱&amp;nbsp;OpenAI 正轉向其競爭對手的 AI 芯片以滿足日益增長的需求。對此，OpenAI 對外發布聲明，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.com%2Fen-us%2Fnews%2Ftechnology%2Fopenai-says-it-has-no-plan-to-use-googles-in-house-chip%2Far-AA1HItOZ%3Focid%3DBingNewsSerp" target="_blank"&gt;否認&lt;/a&gt;了媒體有關其計劃採用谷歌自研芯片的報道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 的一位發言人表示，儘管該公司正在對谷歌的張量處理單元（TPU）進行早期測試，但目前並沒有大規模使用這些芯片的打算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="378" src="https://oscimg.oschina.net/oscnet/up-d1a613253026c0819f2d66ccaa58bfeeeac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在人工智能領域，實驗室測試各種芯片的情況十分普遍，但要實現新硬件的大規模應用通常需要較長時間。此外，這也涉及到不同的架構和軟件支持，難度不小。OpenAI 表示，目前正積極使用英偉達的圖形處理器（GPU）和 AMD 的人工智能芯片，以滿足日益增長的計算需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，OpenAI 也在研發自己的芯片，預計將在今年達到 「定型」 里程碑，屆時這些芯片的設計將最終確定並投入生產。此前有報道稱，OpenAI 已與谷歌雲服務達成合作協議，以滿足其不斷增長的計算能力需求。這一合作被認為是人工智能領域兩個主要競爭對手之間的一次意外聯手。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管 OpenAI 在計算能力方面的主要來源將是由新興雲公司 CoreWeave 提供支持的 GPU 服務器，谷歌也在積極擴大其自研人工智能芯片（TPU）的外部可用性。TPU 芯片之前主要用於谷歌的內部項目，但現在也開始吸引包括蘋果在內的其他科技巨頭以及一些初創公司的關注，如 Anthropic 和 Safe Superintelligence，這些公司都是 OpenAI 的競爭對手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358116</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358116</guid>
      <pubDate>Sun, 11 May 2025 02:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包上線「深入研究」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;豆包「深入研究」功能已經在豆包 App、網頁版及電腦版正式開啓測試，用戶可免費體驗。&lt;/p&gt; 
&lt;p&gt;基於模型的搜索、推理及 Agent 能力，「深入研究」可以幫助用戶更快速、全面和結構化地處理高難度的複雜任務。針對長途旅行攻略、複雜購買決策、最新政策解讀、商業科技趨勢發展等需要獲取大量資料、長時間研究的問題，藉助「深入研究」能力，幾分鐘即可完成初步方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9f6c1c14ffd9352f40ee1c98040fd7cff53.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，豆包還支持以可視化網頁和報告文檔兩種方式呈現研究結果。&lt;/p&gt; 
&lt;p&gt;據介紹，將豆包更新至最新版後，打開 App 或電腦版，選擇「深入研究」，輸入詳細指令或一句話 prompt，等待幾分鐘，即可生成一份報告。使用豆包 App 生成報告後，還可以打開報告內容，選擇右上角「聽」按鈕，一鍵轉成播客，隨時聽。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358039</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358039</guid>
      <pubDate>Sat, 10 May 2025 11:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>德國要求蘋果和谷歌從應用商店下架 DeepSeek</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fdeepseek-faces-expulsion-app-stores-germany-2025-06-27%2F" target="_blank"&gt;據路透社報道&lt;/a&gt;，德國數據保護專員梅克·坎普發佈聲明，宣稱已要求蘋果和谷歌公司從其在德國的應用商店中下架中國初創公司自主研發的人工智能（AI）大語言模型「深度求索」（DeepSeek）的應用。他給出的理由是所謂的數據安全擔憂。&lt;/p&gt; 
&lt;p&gt;坎普在聲明中指控 DeepSeek「非法將用戶個人數據傳輸至中國」，並要求蘋果與谷歌儘快審查這一要求，以決定是否在德國封禁該應用，不過並未設定具體的處理時限。&lt;/p&gt; 
&lt;p&gt;媒體報道顯示，谷歌公司證實已收到相關通知，目前正在進行評估；而蘋果公司則暫未對此作出回應。&lt;/p&gt; 
&lt;p&gt;此前，DeepSeek 也因所謂數據安全問題，在歐美多地遭遇審查。另據媒體報道，意大利已於今年稍早以「個人數據使用不透明」為由，將 DeepSeek 應用從應用商店下架；荷蘭則禁止政府設備使用該應用；比利時也建議政府官員避免使用 DeepSeek，並表示相關評估仍在進行中。與此同時，美國國會議員正計劃提出法案，禁止聯邦政府機構使用任何中國開發的 AI 模型。&lt;/p&gt; 
&lt;p&gt;針對部分國家傳出禁止或限制使用 DeepSeek 的消息，中國外交部發言人此前已作出回應。在今年 2 月 6 日的例行記者會上，外交部發言人表示，中國政府始終高度重視數據隱私和安全保護，並依法開展相關工作，從未要求且將來也不會要求企業或個人以違法形式採集或存儲數據。&lt;/p&gt; 
&lt;p&gt;此外，在今年 3 月 18 日的例行記者會上，另一位外交部發言人再次強調，中方一貫反對泛化國家安全概念、將經貿科技問題政治化的做法，並將堅定維護中國企業的合法權益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358029</guid>
      <pubDate>Sat, 10 May 2025 10:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV-8 系列之 DeepEmbedAttention：精簡 KV 緩存，尤其適合混合模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月 27 日，我們公開了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首個新特性 DeepEmbed：對端側友好的稀疏設計，解決 MoE 顯存佔用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;今天，我們公開與其相關的另一個新特性：&lt;strong&gt;DeepEmbedAttention（DEA）&lt;/strong&gt; ，這是一種基於 RWKV-8 的 DeepEmbed 思路構建的注意力變體，擁有&lt;strong&gt;極小的 KV 緩存&lt;/strong&gt; ，尤其適合&lt;strong&gt;混合模型&lt;/strong&gt;（例如後續的 RWKV-7s 混合模型），可將它們的長上下文性能提升到 Transformer 水準。&lt;/p&gt; 
&lt;p&gt;DEA 的結構定義例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# q: D =&amp;gt; 256
# k: D =&amp;gt; 32, k_up: 32 =&amp;gt; 256, k_emb: V =&amp;gt; 256
# v: D =&amp;gt; 32, vup: 32 =&amp;gt; D, v_emb: V =&amp;gt; D
q = ln_q(q(x))
k = ln_k(k_up(k(x)) * k_emb(idx))
v = ln_v(tanh(v_up(v(x))) * v_emb(idx))   
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然後將 QKV 的輸出加到 RWKV-7 的輸出上。這適合並行計算，例如可在不同設備（或異構計算）計算 QKV 和 RWKV-7 部分。&lt;/p&gt; 
&lt;p&gt;這個注意力頭的維度是 256，但由於 DEA 的 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 只需緩存 32 維，KV 總共只需緩存 64 個值（32+32）。&lt;/p&gt; 
&lt;p&gt;對於 RWKV-7，只需在每層加上一個 DEA head，就能顯著增強長上下文能力。因此，對比現有的高效注意力機制（例如 MLA 使用 576 個值），&lt;strong&gt;DEA 的 KV 緩存進一步縮小到 64/576 = 1/9&lt;/strong&gt;，實現了極致效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c7be8702b07a9534c09539a5fa78e2cdc44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖中 loss delta 圖的橫軸是隨着前文長度增加時 token 的位置（token_pos），縱軸表示兩種架構在不同 token 位置的 loss 差值（token_loss delta）。&lt;/p&gt; 
&lt;p&gt;實驗結果顯示：隨着前文長度增加，RWKV-7s（加入 DeepEmbed 和 DEA）在越來越長前文的 loss &lt;strong&gt;相較原版 RWKV-7 持續下降&lt;/strong&gt;，從 -0.13 降至 -0.17。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;這意味着 RWKV-7s 這類添加了 DEA 的混合模型，在處理長上下文時表現更好。因為 token 越靠後，所依賴的前文也越長，而 loss 差值持續擴大，代表 RWKV-7s 對比 RWKV-7 更有能力利用越來越長的前文所包含的越來越多的信息，語言建模能力越來越強。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;最後，儘管 DEA 的 KV 緩存非常小，但它仍會隨上下文長度而緩慢增長。&lt;strong&gt;RWKV-8 的目標，是在完全無 KV 緩存的情況下也能實現強上下文能力&lt;/strong&gt;，且我們也有方法，後續逐步公佈，歡迎大家關注。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358026</guid>
      <pubDate>Sat, 10 May 2025 10:11:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>歐洲首台百萬兆次級超級計算機 JUPITER 啓用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;位於德國的於利希超級計算中心（Jülich Supercomputing Center）近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspectrum.ieee.org%2Fjupiter-exascale-supercomputer-europe" target="_blank"&gt;推出&lt;/a&gt;了歐洲首台百萬兆次級超級計算機 JUPITER (木星)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-37c973b7767f9f8d83e4f3ade8a1fabef7f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 於 2025 年 6 月首次亮相於全球最強大計算機系統的 TOP500 排行榜上，位列第四。它擁有 5900 個加速計算節點，配備了約 24000 顆 Nvidia Grace-Hopper&amp;nbsp;超級芯片和 1300 個使用 Rhea1 處理器的節點。此外，JUPITER 還採用了 InfiniBand NDR 網絡來確保高速數據傳輸。該計算機的設計旨在支持複雜的科學計算任務，推動氣候模型和天氣預報的研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這個項目旨在創建一個地球系統的數字複製品，以更好地監測和預測自然現象與人類活動的相互作用。研究者們表示，需要這樣一台大型機器來處理氣候和大氣數據，JUPITER 能以 700 米的分辨率展示這些物理現象，從而為氣象學和氣候科學提供更深入的洞察。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，德國伊爾梅瑙工業大學的物理學家們也在利用 JUPITER 進行研究。他們專注於可視化熱羽流，探討流體和氣體的對流與湍流現象。科學家們通過這台超級計算機的強大運算能力，能夠呈現出以前無法獲得的細節，進一步理解自然界中複雜的流動模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 的建設始於 2018 年，經過多次升級和完善，在 2024 年計劃推出的 JEDI 原型機和 JETI 過渡系統模塊的支持下，最終在 2025 年全面投入使用。該計算機的能效設計也備受關注，其製冷系統利用附近的魯爾河水，為校園建築提供取暖，展現出對能源消耗的關注和可持續發展理念。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</guid>
      <pubDate>Sat, 10 May 2025 09:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>JSON Crack —— 將 JSON 可視化為交互式圖表</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JSON Crack 是一款以結構化交互式圖表形式可視化 JSON 數據的工具，方便用戶探索、格式化和驗證 JSON。它提供多種功能，例如將 JSON 轉換為其他格式（CSV、YAML）、生成 JSON Schema、執行查詢以及將可視化結果導出為圖像。其設計兼顧了可讀性和易用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可視化工具&lt;/strong&gt;：立即將 JSON、YAML、CSV、XML 和 TOML 轉換為暗模式或亮模式下的交互式圖形或樹。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轉換&lt;/strong&gt;：無縫轉換數據格式，如將 JSON 轉換為 CSV 或將 XML 轉換為 JSON，以便於共享。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;格式化和驗證&lt;/strong&gt;：美化和驗證 JSON、YAML 和 CSV 以獲得清晰準確的數據。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代碼生成&lt;/strong&gt;：生成 TypeScript 接口、Golang 結構和 JSON 模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JSON Schema&lt;/strong&gt;：創建 JSON Schema、模擬數據並驗證各種數據格式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高級工具&lt;/strong&gt;：解碼 JWT、隨機化數據以及運行 jq 或 JSON 路徑查詢。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;導出圖像&lt;/strong&gt;：將你的可視化效果下載為 PNG、JPEG 或 SVG。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隱私&lt;/strong&gt;：所有數據處理都是本地的；服務器上不會存儲任何內容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="438" src="https://static.oschina.net/uploads/space/2025/0630/164831_2A2G_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/jsoncrack</link>
      <guid isPermaLink="false">https://www.oschina.net/p/jsoncrack</guid>
      <pubDate>Sat, 10 May 2025 09:20:00 GMT</pubDate>
    </item>
    <item>
      <title>AI 造物社區項目發佈指引</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;使用前請先註冊 OSC 開源社區賬號，按照以下説明操作，照片清晰，報告整潔，介紹全面，附件有代碼， 基本會一次性審核通過。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;1. 註冊賬號&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172849_N1db_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;完成註冊並登錄後，進入造物社區&amp;nbsp;&lt;/strong&gt;&lt;em&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/ai-creation"&gt;&lt;strong&gt;https://www.oschina.net/ai-creation&lt;/strong&gt;&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;strong&gt;，點擊「發佈一個新項目/發佈一個新的造物」，發佈新項目。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172907_YADg_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;2. 項目基礎信息&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;標「&lt;span style="color:#d83931"&gt;*&lt;/span&gt;」的為必填項目。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;封面圖片上傳格式為 4:3，分辨率 1080P，圖片內存大小建議小於 1MB，過大容易上傳失敗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;項目介紹部分簡要填寫項目簡介即可。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172927_GAOA_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;3. 「項目詳情」頁&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;視頻請先上傳到 B 站/優酷/騰訊，然後在「視頻代碼」處粘貼視頻分享的嵌入代碼（iframe 格式），以下是 B 站複製嵌入代碼的方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173137_W7Ba_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;項目內容填寫可根據實際完成項目內容填寫，格式可參考示例。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173149_4iMQ_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;代碼的插入請使用「代碼塊」工具插入&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173201_y81p_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;注意格式整潔，正文字號建議用默認字號 14px，標題建議用三級標題&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用 AI 工具前，需先用鼠標選中需要 AI 介入的文段內容，再選擇對應的 AI 工具對文段進行潤色，AI 翻譯當前僅支持「中=英互譯」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173212_caKR_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;4. 「所需物料」頁&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「硬件組件」一欄點擊「添加」，可填寫硬件名稱、購買網址、購買數量及硬件描述。可添加多個硬件明細。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173223_TJzj_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「軟件應用和在線服務」一欄點擊「添加」，可添加製作項目所用的軟件平台及敏捷製造、供應鏈服務等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173234_DrKy_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「手動工具和生產設備」一欄點擊「添加」，可填寫用於製作項目的設施設備。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&amp;nbsp;&lt;/h4&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;5. 「附件清單」頁&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在「外殼和定製部件」一欄點擊「添加」，可上傳 3D 模型、結構件設計圖紙等內容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「代碼」一欄點擊「添加」，可項目代碼及硬件「庫」等內容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「原理圖和電路圖」一欄點擊「添加」，可項目接線圖、原理圖等，建議上傳 JPG/PNG 格式文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;編輯完成後點擊「下一步」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;6. 上傳團隊成員信息，並「發佈」項目&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;完成項目內容的編輯之後，先點擊「設置為發佈」，之後點擊「預覽項目」可查看自己的項目。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;發佈之後若查出存在問題，可在項目預覽界面，點擊「編輯/刪除」再次修改。若在項目通過之後發現存在問題，依舊可再次修改項目，直到項目完善。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173246_6PYI_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查詢項目發佈歷史可以在「個人中心」——「我的造物」中進行查詢或項目修改/刪除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173255_JgBm_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;參考示例&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2006"&gt;https://www.oschina.net/ai-creation/details/2006&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2005"&gt;https://www.oschina.net/ai-creation/details/2005&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2063"&gt;https://www.oschina.net/ai-creation/details/2063&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358019</guid>
      <pubDate>Sat, 10 May 2025 09:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>悟了，多模態才是智能應用爆發的關鍵</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;此前，快手發佈 2025 年一季度財報時，一個數字引發關注：成立僅兩年的 AI 業務線「可靈 AI」單季度貢獻營收 1.5 億元，同比增長 320%。而可靈 AI 正是一個多模態應用的典型產品，涉及到語言、視頻、音頻等交互。&lt;/p&gt; 
&lt;p&gt;前不久，在 OSCHINA 和小度教育技術負責人丁小晶的&lt;a href="https://my.oschina.net/u/4489239/blog/18426743" rel="nofollow"&gt;對話&lt;/a&gt;中。丁小晶表示，多模態技術非常重要，甚至可以説，沒有多模態技術效果的快速提升，教育行業不可能如此迅猛發展。比如 AI 作業批改和 AI 講題答疑方向的應用，完全靠純文本大模型是無法滿足需求的，非常依賴對大模型的圖片理解能力。還比如超擬人 AI 老師，語音情感大模型就起來非常關鍵的作用。&lt;/p&gt; 
&lt;p&gt;百度最新發布的發佈文心快碼 Comate AI IDE 產品，其中也提到了多模態能力的增強，比如支持 Figma 設計稿一鍵轉換為高可用代碼，能實現圖層的精準還原。百度工程效能部前端研發經理楊經緯告訴開源中國，無論是從自然語言、圖片還是設計稿生成代碼，最終都是為了能更加接近人類工程的意圖，因為人類去描述自己想要實現的想法的方式與形態是多種多樣的，也就對應了研發過程中的多模態形式。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="210" src="https://oscimg.oschina.net/oscnet/up-db06f16dbd4e854566d762bff8c3dfe1e5f.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;人類從不會只用一種感官認知世界。人工智能也勢必不能僅有一種交互途徑。&lt;/p&gt; 
&lt;p&gt;我們聞到咖啡香氣的瞬間，腦海裏會立刻浮現深褐色液體與白瓷杯的畫面；聽到「貓」這個詞時，腦海中自動補全毛茸茸的觸感和呼嚕聲。這種多模態信息融合，正是人類智能的底層邏輯。而單一模態交換的 AI 模型的信息處理能力有限，例如文本生成模型難以理解圖像語義，無法根據文字生成圖像，視頻生成工具則無法同步解析聲音與畫面邏輯。這種時候，就需要多模態模型或是能力的配合。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;多模態，比文本慢一步&lt;/h2&gt; 
&lt;p&gt;智源研究院院長王仲遠不久前公開&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.cn%2Fzh-cn%2F%25E6%258A%2580%25E6%259C%25AF%2F%25E6%258A%2580%25E6%259C%25AF%25E5%2585%25AC%25E5%258F%25B8%2F%25E8%2581%259A%25E7%2584%25A6%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581-chatgpt%25E6%2597%25B6%25E5%2588%25BB%25E6%259C%25AA%25E5%2588%25B0-2025%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B-%25E5%258F%2598%25E6%2585%25A2-%25E4%25BA%2586%25E5%2590%2597%2Far-AA1GjaHk%3Focid%3DBingNewsSerp" rel="nofollow" target="_blank"&gt;指出&lt;/a&gt;，當前多模態大模型的學習路徑，尤其是多模態理解模型，通常是先將語言模型訓練到很強的程度，再學習其他模態信息。在這個過程中，模型的能力可能會出現下降。&lt;/p&gt; 
&lt;p&gt;比單一模態更難的是，多模態模型還需解決一個核心問題：如何將圖像、文本、音頻等異構數據在語義層面對齊並融合。&lt;/p&gt; 
&lt;p&gt;文本、圖像、聲音等模態的數據結構天然異構——文本是離散符號序列，圖像是連續像素矩陣，音頻是時間序列信號。比如要讓模型理解「貓」的文本描述與貓的圖片、叫聲之間的關聯，需構建跨模態的共享語義空間。&lt;/p&gt; 
&lt;p&gt;早期，有研究嘗試通過數據級拼接，將圖像像素和文本特徵直接拼接，實現跨模態融合，但由於圖像和文本的時空特性差異較大，導致特徵對齊困難，最終效果不佳。直到對比學習和注意力機制的出現，才實現跨模態語義映射。比如 OpenAI 2021 年推出的一種基於對比學習只的多模態預訓練模型 CLIP，它通過大規模的圖像和文本數據進行訓練，使得模型能夠理解圖像內容和相關文本之間的語義關係。CLIP 的核心貢獻在於它打破了傳統的固定類別標籤範式，通過對比學習的方式，將圖像和文本映射到同一個向量空間中，從而實現跨模態的檢索和分類。但是 CLIP 模型的訓練數據規模龐大，據 OpenAI 披露，其使用了約 4 億圖像-文本對進行訓練，訓練成本高達數千 GPU 日，遠超 GPT-3 等純文本模型。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-4ad6b286433edebde043654fd53af191e30.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;CLIP 模型方法概述 &lt;/em&gt;&lt;/span&gt;&lt;span style="color:#8f959e"&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2103.00020" rel="nofollow" target="_blank"&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多模態融合需處理高維數據，如 4K 視頻的像素量是文本的百萬倍，傳統 Transformer 的二次方計算複雜度成為致命短板。對此，業界也有一些解決方式，比如此前 Mamba 架構通過狀態空間模型 SSM 將計算複雜度降至線性，2025 年擴展動態融合模塊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F2985554863" rel="nofollow" target="_blank"&gt; FusionMamba&lt;/a&gt;，在其中實現多模態特徵高效交互，推理速度提升 3 倍。&lt;/p&gt; 
&lt;p&gt;不僅如此，相較於文本的資料庫和數據集，高質量多模態數據集也更加稀缺，收集難度更大。比如醫療影像、工業質檢的報告中的缺陷描述等，就需專家級別的標註人員。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;落地需求更多&lt;/h2&gt; 
&lt;p&gt;雖然技術上還有諸多難點，但是多模態能力正在逐步提升，並且帶來非常可觀的價值和效果。&lt;/p&gt; 
&lt;p&gt;比如，從圖片或者是 Figma 設計稿直接生成代碼可以幫助許多開發者或是產品經理完成一些開發工作。這項能力此前在一些低代碼或是輔助編程工具中也存在，但往往是通過 Figma DSL 進行設計稿解析，通過節點虛擬化技術實現像素級還原，其不足在於不一定適配當前項目，比如轉了一套 Vue 框架的代碼，就無法在 React 框架項目中使用。&lt;/p&gt; 
&lt;p&gt;楊經緯介紹，此次文心快碼 Comate AI IDE 的發佈以及相關功能更新後，通過大模型能力增強了 Figma to Code 和當前項目的融合度。首先在 IDE 裏進行操作，天然就可以理解用戶當前環境和本地優勢，而 IDE 內智能體 Zulu 的接入，會更深入到本地項目中瞭解當前的框架、能力、代碼風格等，再結合 Image to Code 的能力，可以實現較高的還原度，並且適配當前的項目。&lt;/p&gt; 
&lt;p&gt;而根據一些公開信息顯示，可靈 AI 的多模態技術，支持通過圖片、文字、聲音甚至手繪軌跡等輸入生成視頻。在上半年的 2.0 模型的迭代中，可靈 AI 也發佈了 AI 視頻生成的全新交互理念 Multi-modal Visual Language（MVL），讓用戶能夠結合圖像參考、視頻片段等多模態信息，將腦海中包含身份、外觀、風格、場景、動作、表情、運鏡在內的多維度複雜創意，直接高效地傳達給 AI。MVL 由 TXT（Pure Text，語義骨架）和 MMW（Multi-modal-document as a Word，多模態描述子）組成，能從視頻生成設定的基礎方向以及精細控制這兩個層面。此外，其技術也結合了類 Sora 的 DiT 結構和 Flow 擴散模型，提升在物理模擬和細節上的表現。&lt;/p&gt; 
&lt;p&gt;基於這些技術特徵。商業化層面，截至今年 6 月，可靈 AI 已為超過 1 萬家企業客戶提供 API 服務，覆蓋廣告營銷、影視動畫等領域，企業客戶續費率較高。&lt;/p&gt; 
&lt;p&gt;此外，一些傳統行業或場景也在結合多模態能力，實現與 AI 的加速融合。比如迪瑞醫療近期採用的多模態 AI 大模型算法技術為臨牀診斷帶來了重要的技術革新，結合多種檢測結果和患者的多維信息，如尿常規、血常規、生化和化學發光免疫，以及患者的個人背景、臨牀表現、現病史與既往病史等，進行全面分析。&lt;/p&gt; 
&lt;p&gt;這種跨學科的信息整合使得診斷提示更加精準，對於減少漏診、誤診的概率具有顯著的作用，並進一步提升了醫療診療的整體效率。大洋彼岸，斯坦福醫學院的科研團隊研發出了一種名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxMTM0OTQzNQ%3D%3D%26mid%3D2247486194%26idx%3D1%26sn%3D5ac605d67ca7019b3b2e524d65b0f88e%26chksm%3Dc0eed67e545679711993370e69032cc62e9d4fc0c6ff3e283c43854fd93355eae8a07b4fcb02%23rd" rel="nofollow" target="_blank"&gt; MUSK 的 AI 模型&lt;/a&gt;，將視覺數據，如病理圖像和文本數據的病歷和臨牀記錄相結合，為癌症治療帶來了新的可能。MUSK 模型不僅提高了預測癌症患者預後和治療反應的準確性，而且通過分析數千個數據點，更準確地確定了哪些療法對個體患者最有效。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-196e0ee8b1058ba8ee70698e626a846fe72.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="background-color:#f2f3f5"&gt;&lt;em&gt;視覺問答測試，圖片來源於網絡&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在金融領域。江蘇銀行通過本地化部署微調 DeepSeek-VL2 多模態模型、輕量 DeepSeek-R1 推理模型，分別運用於智能合同質檢和自動化估值對賬場景中，通過對海量金融數據的挖掘與分析，重塑金融服務模式，實現金融語義理解準確率與業務效率雙突破。具體而言，DeepSeek-VL2 多模態模型採用了最新的 Transformer 架構，結合多層次的特徵融合機制，有效提升了金融合同、賬單等複雜文本與圖像信息的理解能力。模型在智能合同質檢場景中表現出色，準確率較傳統方法提升了 15% 以上，顯著降低了人工審核成本。同時，輕量化的 DeepSeek-R1 推理模型則在自動化估值與對賬場景中展現出極佳的實時響應能力，推理速度提升了 30%，為金融業務流程的自動化提供了堅實支撐。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;新的基礎設施&lt;/h2&gt; 
&lt;p&gt;應用邊界在不斷拓寬的同時，多模態模型的能力也在成長。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而隨着應用場景的深化，模型架構也在同步進化，從基礎感知邁向複雜推理成為必然趨勢。OpenAI 在 2025 年 4 月發佈了多模態模型 O3 和 O4-mini，實現了「用圖像思考」的突破性能力。這些模型不僅能夠識別圖像內容，還能將圖像信息整合進推理思維鏈，支持多步推理和因果分析，比如夠處理模糊、倒置或複雜的圖像輸入，並給出合理的推理結果。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;其背後的關鍵技術包括分層注意力機制，將圖像分解為局部細節、全局關係和時序邏輯三層結構，從而提升對圖像內容的理解能力；動態工具鏈調用，在推理過程中，模型可以自主選擇 Python 分析、知識圖譜檢索、圖像生成等工具輔助決策，以及安全約束模塊，通過對抗訓練減少模型的幻覺輸出。&lt;/p&gt; 
&lt;p&gt;就在本月，中國科學院自動化研究所等單位的科研人員&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkw.beijing.gov.cn%2Fxwdt%2Fkcyx%2Fxwdtkjqy%2F202506%2Ft20250611_4111006.html" rel="nofollow" target="_blank"&gt;首次證實&lt;/a&gt;，多模態大語言模型在訓練過程中自己學會了「理解」事物，而且這種理解方式和人類非常像。&lt;/p&gt; 
&lt;p&gt;科研人員借鑑人腦認知的原理，設計了一個巧妙的實驗：讓大模型和人類玩「找不同」遊戲。實驗人員會給出三個物品概念（選自 1854 種常見物品），要求選出最不搭的那個。通過分析高達 470 萬次的判斷數據，科研人員繪製出了大模型的「思維導圖」——「概念地圖」。通過實驗證實多模態大模型具備類人「概念理解」能力。研究團隊設計「找不同」遊戲，基於 470 萬次判斷數據繪製大模型「概念地圖」，提煉 66 個理解維度（如物體功能、文化意義），發現其與人腦神經活動高度一致，證明多模態模型比純文本模型更接近人類思維模式。&lt;/p&gt; 
&lt;p&gt;據谷歌雲在 2024 年年底發佈的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.qq.com%2Frain%2Fa%2F20241219A07AW200" rel="nofollow" target="_blank"&gt;《2025 年人工智能商業趨勢報告》&lt;/a&gt;，預測到 2025 年，多模態 AI 將成為企業採用 AI 的主要驅動力。這種技術通過整合圖像、視頻、音頻和文本等多種數據源，使 AI 能夠以前所未有的準確性從更廣泛的上下文源中學習，提供更精確、定製化的輸出，創造自然直觀的體驗。報告預計，全球多模態 AI 市場規模將在 2025 年達到 24 億美元，到 2037 年底達到 989 億美元。&lt;/p&gt; 
&lt;p&gt;2025 進度已經過半，我們也能看到市面上許多多模態技術和產品的進展，而這場變革的終極圖景，或許正是讓 AI 真正成為理解世界、服務人類的「多模態智能夥伴」。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18679654</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18679654</guid>
      <pubDate>Sat, 10 May 2025 09:07:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Mozilla 修復 Firefox 140 在 Windows 上出現的崩潰問題</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Mozilla 正在為 Firefox 瀏覽器推出又一次更新。140.0.2 版本是剛剛發佈的 140.0.1 版本之後的又一次更新，旨在修復更多導致 Windows 在某些情況下崩潰的錯誤。&lt;/p&gt; 
&lt;p&gt;發行説明內容如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;修復了某些用戶在 Windows 上遇到的啓動崩潰問題。&lt;/strong&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1974259"&gt;1974259&lt;/a&gt;）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;根據 Mozilla 的 Firefox 漏洞追蹤器&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1974259"&gt;Bugzilla 上的一篇文章&lt;/a&gt;，瀏覽器會因 ERROR_INVALID_HANDLE 或 ERROR_INVALID_PARAMETER 錯誤而崩潰。這種情況發生在 Windows 安全設置中啓用了 「漏洞利用保護」 時。&lt;/p&gt; 
&lt;p&gt;雖然普通用戶不太可能會碰這個功能，但微軟商店中的應用程序已啓用漏洞保護。因此，從 Microsoft Store 下載 Firefox 的用戶最有可能發生崩潰不過，如果全局啓用了漏洞保護，從官方網站下載的 「標準」 Firefox 也會失敗。&lt;/p&gt; 
&lt;p&gt;請注意，該漏洞不會影響較新版本的 Firefox。現在，隨着 Firefox 140.0.2 的發佈，無論您的安全設置或瀏覽器來源如何，瀏覽器都不會再崩潰。作為參考，您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fen-US%2Ffirefox%2F140.0.2%2Freleasenotes%2F"&gt;在此處&lt;/a&gt;找到最新更新的發行説明。&lt;/p&gt; 
&lt;p&gt;與往常一樣，您可以通過前往菜單 &amp;gt; 幫助 &amp;gt; 關於 Firefox 來更新 Firefox。該瀏覽器可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fen-US%2Ffirefox%2Fwindows%2F"&gt;在官方網站&lt;/a&gt;、 Windows 10 和 11 用戶&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapps.microsoft.com%2Fdetail%2F9NZVDKPMR9RD"&gt;的 Microsoft Store&lt;/a&gt;下載。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358008</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358008</guid>
      <pubDate>Sat, 10 May 2025 08:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ECMAScript 2025 標準正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ECMAScript 2025 現已獲得 ECMA International 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fecma-international.org%2Fnews%2Fecma-international-approves-new-standards-11%2F" target="_blank"&gt;批准&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1444" src="https://static.oschina.net/uploads/space/2025/0630/161138_aINy_2720166.png" width="2342" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是主要新特性：&lt;/p&gt; 
&lt;h3&gt;異步處理改進&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增 Promise.try() 方法&lt;/strong&gt; ：用於統一封裝同步返回值或拋錯的函數，相比以往的 Promise.resolve().then(fn) 或 new Promise(resolve =&amp;gt; resolve(fn()))，Promise.try(fn) 更簡潔高效。例如，對於一個可能會拋出異常的函數，使用 Promise.try() 可以更方便地進行錯誤處理。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可立即拋出同步異常&lt;/strong&gt; ：使用 Promise.try() 時，若函數同步拋出異常，能夠立即捕獲並處理，避免了使用 Promise.resolve().then(fn) 時引入的微任務延遲，提高了錯誤可見性與調試效率，適用於封裝第三方同步 API，使其具備統一的異步處理能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;集合操作增強&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增 Set 實例方法&lt;/strong&gt; ：為 Set 實例新增了七個方法，包括集合運算方法 intersection()（交集）、union()（並集）、difference()（差集）、symmetricDifference()（對稱差集），以及集合關係方法 isSubsetOf()（是否為子集）、isSupersetOf()（是否為超集）、isDisjointFrom()（是否無交集），使集合操作更加方便快捷，符合數學上的集合運算邏輯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;迭代器功能擴展&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增同步迭代器輔助函數&lt;/strong&gt; ：為所有同步迭代器添加了一系列輔助方法，如 .map(fn)、.filter(fn)、.flatMap(fn)、.some(fn)、.every(fn)、.find(fn)、.reduce(fn, init)、.forEach(fn)、.drop(n)、.take(n)、.toArray() 等。這些方法支持鏈式調用，可用於鏈式處理可迭代對象的數據，實現惰性求值，避免創建多箇中間數組，提升內存效率，特別適合處理大型或無限可迭代數據，如生成器、流數據等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;正則表達式增強&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增 RegExp.escape() 方法&lt;/strong&gt; ：可將字符串中的正則元字符轉義，使其能夠安全地嵌入正則表達式中，避免動態生成正則表達式時出現語法錯誤，防止正則注入漏洞，替代手動維護的轉義函數。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;正則表達式內聯標誌&lt;/strong&gt; ：允許在正則表達式內部使用內聯語法 (?flags:...) 或 (?flags1-flags2:...) 以局部開啓或關閉某些標誌位，如 i、m、s 等。例如，在正則 /^x(?i:HELLO)x$/ 中，整個表達式外部沒有 i 標誌，而只對子串 HELLO 應用忽略大小寫，避免了正則拆分與多輪匹配邏輯。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;重複命名捕獲組&lt;/strong&gt; ：允許在正則表達式的不同分支中使用相同的命名捕獲組名稱，只要這些同名組不可能同時匹配。這便於對形式不同但結構類似的文本進行統一處理，如解析多種日期格式、鍵值對格式等，可簡化後續處理邏輯，避免代碼冗餘。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;模塊系統優化&lt;/h3&gt; 
&lt;p&gt;新增導入屬性，允許在 import 語句中指定附加信息，以指定如何加載模塊，主要用於引入非 JavaScript 資源，如 JSON 文件或 CSS 模塊。靜態導入時，可在路徑後加上 with 選項；動態導入時，將其放在第二個參數的 with 字段中，使用起來更加方便簡潔，可直接像引用 JS 模塊一樣使用 JSON 數據等。&lt;/p&gt; 
&lt;h3&gt;數值表示擴展&lt;/h3&gt; 
&lt;p&gt;提供對 16 位浮點數的原生支持，包括 Float16Array、DataView.prototype.getFloat16()/setFloat16() 以及 Math.f16round(number)。這在 WebGPU / WebGL 中可節省帶寬與內存，在深度學習中便於傳遞模型參數，也可用於模擬硬件精度限制。&lt;/p&gt; 
&lt;h3&gt;其他特性&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;後置檢查的聲明式控制流&lt;/strong&gt; ：引入了 checked { }塊和 assert 關鍵字，在 checked 塊中的操作會在執行後立即檢查是否出界等，assert 用於斷言，若條件不成立會直接拋出異常，為開發者提供了更靈活的錯誤檢查方式。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ArrayBuffer 的構造共享數組&lt;/strong&gt; ：新增了 ArrayBuffer 構造函數的 shared 構造標誌，可創建一個共享的 ArrayBuffer，其視圖成為共享數組，所有代理都具有相同的內存視圖，允許多個 JavaScript 工作線程之間共享和傳遞 ArrayBuffer，提高了數據共享和傳遞的效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fecma-international.org%2Fpublications-and-standards%2Fstandards%2Fecma-262%2F" target="_blank"&gt;https://ecma-international.org/publications-and-standards/standards/ecma-262/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358006/ecma-international-approves-ecma-262-standards</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358006/ecma-international-approves-ecma-262-standards</guid>
      <pubDate>Sat, 10 May 2025 08:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 造物社區作品分享——靈韻啓航者 V1.0 模塊化多主控嵌入式學習擴展平台</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2063</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2063</guid>
      <pubDate>Sat, 10 May 2025 07:33:00 GMT</pubDate>
    </item>
    <item>
      <title>Linux 6.16-rc4 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 6.16-rc4 已發佈，這意味着距離最終內核版本的發佈僅剩一半的時間，屆時我們將在三到四周內獲得最終版本。&lt;/p&gt; 
&lt;p&gt;Linus Torvalds &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3DwjqJeFHs_CsO2MeFLi-qceFM7_dVfKBMH4B7oVJaH6tHQ%40mail.gmail.com%2FT%2F%23u" target="_blank"&gt;表示&lt;/a&gt;，此次更新的合併窗口相當大，但同時表示候選版本發佈進程仍然保持平穩，這正是我們希望看到的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0630/150013_dqUh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Linux 內核開發週期通常會在上一個版本發佈後的兩週內推出新功能，之後每週都會發佈一個新的候選版本，修復新功能和現有功能。穩定版本會在七八個候選版本發佈後發佈。&lt;/p&gt; 
&lt;p&gt;本週，Torvalds 表示，三分之一的更新涉及文件系統更新，重點關注 bcachefs，以及一些 SMB 和 Btrfs 修復。另外三分之一是驅動程序更新，特別是由於一些性能問題而恢復到設備映射器。&lt;/p&gt; 
&lt;p&gt;最後三分之一的更改是雜項更改，包括文檔更新、架構修復（LoongArch、UM、x86）、自檢以及各種其他常規修復。與往常一樣，Torvalds 請求社區繼續測試內核，以便在穩定版本發佈時能夠保持更好的狀態。&lt;/p&gt; 
&lt;p&gt;Linux 6.16 發佈後不久，用戶就能獲得它，尤其是那些運行 Arch 和 Fedora 等尖端 Linux 發行版的用戶。如果你有一些目前與 Linux 不兼容的新硬件，請務必在 7 月底左右 Linux 6.16 發佈時進行測試，看看是否有任何變化。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FLinux-6.16-Features-Early-Look" target="_blank"&gt;據 Phoronix 報道，Linux 6.16 內核預計將帶來一些重大的硬件改進，包括對&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.nvidia.com%2F" target="_blank"&gt;NVIDIA&lt;/a&gt;的開源驅動程序支持 Blackwell 和 Hopper GPU，以及英特爾&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fx86deadandback%2Fstatus%2F1869428945420202447" target="_blank"&gt;Wildcat Lake 處理器&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;雖然 Torvalds 呼籲測試人員試用候選版本，但運行與發行版附帶的內核不同的內核並不是一件容易的事，所以不要在生產機器上亂用候選版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357985</guid>
      <pubDate>Sat, 10 May 2025 06:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
