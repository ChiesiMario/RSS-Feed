<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 10 Mar 2025 21:37:08 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>周鴻禕談 996 加班：人工智能發展得這麼快，想有成就還得加班</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;996 工作制指的是早上 9 點上班、晚上 9 點下班，中午和傍晚休息 1 小時（或不到），總計工作 10 小時以上，並且一週工作 6 天的工作制度，代表着中國互聯網企業盛行的加班文化。&lt;/p&gt; 
&lt;p&gt;日前，360 集團創始人周鴻禕談 996，表示加班肯定要自願才行，你只有工作比別人更努力，才能取得更好的成績。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e34eb8a47acc13b9240cb9b8c0ea1bc69a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「我們確實不想加班，但是人工智能（發展得這麼快），要想取得成就還是得加班，我們還是主張熱愛這個事自願加班，不熱愛這個事（就不要加班）。」周鴻禕説。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於當年是不是也加了很多班的問題，周鴻禕回答道：「我現在還每天都加很多班」。&lt;/p&gt; 
&lt;p&gt;經濟學家向松祚曾提出，如果工作沒效率，一天工作 24 小時也沒用；如果選擇的是熱愛的工作，感到開心、達到自身最好的狀態，就不存在 996 或工作很累的問題了。&lt;/p&gt; 
&lt;p&gt;此前，聯想集團董事長兼 CEO 楊元慶表示：「在聯想，我們一直強調的是工作與生活的平衡，旗幟鮮明地反對 996。員工辛勤工作的目的是什麼？是為了滿足我們每一個人對美好生活的嚮往這樣一個最終目標」。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/337895&quot; target=&quot;news&quot;&gt;大疆強制員工晚上 9 點必須下班，HR 趕人清場&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338040</guid>
            <pubDate>Wed, 05 Mar 2025 12:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里研究院：DeepSeek 是對開源大模型價值的強有力支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里研究院發佈了一篇文章，以 DeepSeek 為例來討論未來開源模型的風險治理改革與創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;文章內容指出，DeepSeek 以相對較小成本實現高性能大模型的發展創新，不僅證明瞭人工智能技術發展路徑的多元性和動態性，更重要的是推動開源大模型發展實現了新的躍遷。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 DeepSeek 之前，圍繞人工智能是否應開源的爭議日趨激烈，在此背景下，DeepSeek 是對開源大模型價值的強有力支持：正是站在 LLaMa、千問等開源大模型的基礎上，DeepSeek 通過更巧妙的工程設計挖掘了大模型的內在潛力、實現了性能上的超越。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但另一方面，如果開源需要真正成為大模型的主導性發展模式，不可迴避的另一重要問題仍然是開源大模型風險治理的改革，即我們能否創新開源治理機制以回應大模型開源後所可能引發的風險擔憂。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;一、DeepSeek 開源模型風險：現有評估及無額外風險的結果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 開源模型的發佈同時也引發了海外對其安全風險的關注和討論，眾多海外國家和組織針對 DeepSeek 開源模型進行了針對國家安全、數據安全、版權風險和安全漏洞等方面的安全影響評估並提出了治理措施或建議。例如，美國雲安全平台 Wiz Research 發現 DeepSeek 關聯數據庫存在泄露大量後端數據、操作細節等敏感信息的風險，該團隊立即向 DeepSeek 披露了此問題，並提出人工智能公司應實施與公共雲提供商和主要基礎設施提供商同等的安全措施。[1]人工智能安全平台 Hiddenlayer 對 DeepSeek-R1 的安全評測結論指出，該模型存在無法抵禦簡單越獄攻擊、思想鏈 (CoT) 推理可能會導致信息泄露等安全漏洞，建議確保部署環境的可控性再使用該開源模型。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從評估結果來看，DeepSeek 開源模型的風險主要集中在數據安全和安全（safety）漏洞兩個方面。DeepSeek 開源模型帶來的數據安全風險主要表現為敏感數據的攻擊泄露（關聯數據庫泄露 DeepSeek 內部敏感信息且攻擊者易訪問）以及思維鏈數據泄露（CoT 推理引入中間步驟可能會無意泄露敏感信息、內部邏輯以及模型訓練中使用的專有數據等）。前者主要為數據庫等基礎設施的安全風險，這屬於用戶-模型數據交互鏈路中執行環境的特定環節，需要採用系統化的視角來進行安全加固，並非模型本身的固有安全漏洞。（參考閲讀：《治理之智｜用戶-模型數據交互安全：挑戰、應對及思考》）後者則並非 DeepSeek 獨有的問題，目前所有的推理模型技術都面臨此類 CoT 數據泄露的數據安全風險。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 開源模型存在的安全漏洞風險則包含網絡安全、內容安全、偏見與歧視、代碼安全、CBRN（化學、生物、放射和核能）安全等方面。根據海外多個人工智能安全平台及研究團隊（Enkrypt AI、Robust Intelligence 等）的安全評估和紅隊測試結果，DeepSeek-R1 模型在在部分測試項目上展現出相對與其他主流模型更高的安全風險，例如生成不安全代碼的可能性比 OpenAI o1 高出 4 倍，偏見歧視內容誘導的成功率高達 83% 且比 Claude-3 Opus 高出 3 倍，生成 CBRN 相關內容的脆弱性是 OpenAI o1 和 Claude-3-Opus 的 3.5 倍等。但細究其評測結論的分析過程，其核心原因在於各國在安全風險優先級、模型輸出內容管理要求、容忍度基準等方面存在差異性，導致各國對模型的安全表現評價各不相同。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;整體來看，排除評價標準差異化因素的影響，各國評估並未發現 DeepSeek 開源模型及其應用會造成額外的風險。換言之，DeepSeek 作為大模型技術並未帶來相比於其他大模型的更多風險；但作為開源大模型，考慮到開源將降低使用門檻並讓模型更加普及化，開源模型生態中的濫用誤用情況則可能變多。此時開源模型並非主要的風險源，總體安全風險反而將受到複雜的上下游任務鏈參與方以及基礎設施、系統攔防和使用場景等多重因素影響，而這便要求風險治理機制的進一步完善與改革。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;二、建立基於增量風險的開源模型風險治理機制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源模型帶來了技術普及化和應用多樣化，但價值與風險並存的特徵對於如何判斷開源模型的風險特點、採取何種平衡性的治理方案提出了挑戰。目前對模型開源的風險有兩類判定標準，並相應形成了兩類治理思路。一類考慮開源模型的「全量風險」，採取全域管控+開源特別豁免的平衡機制。「全量風險」機制以歐盟《人工智能法案》為代表，以事前風險防範為核心，在統一的綜合性立法中通過分類分級方式地識別開源模型所有可能存在的風險，包括納入暫時沒有實際證據支撐但未來可能出現的感知風險，當出現足夠證明不具有需要單獨管制必要性的證據時再予以事後排除。而考慮到開源軟件對於有效促進技術創新的價值，歐盟針對開源模型進行單獨定義並設置複雜的「開源豁免+豁免例外」規則機制，將開源模型完全納入法律規制之後再進行有限度的利益平衡。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一種治理思路是分析模型開源獨有的「增量風險」，並採取有針對性的管控機制。「增量風險」指與來自現有其他可比技術的風險相比，開源模型是否會產生新的獨特風險，並因此要求被特殊監管。2024 年 7 月底，美國國家電信和信息管理局（NTIA）發佈報告，對於開源模型的「增量風險」的判斷提供了與閉源模型、與其他現有技術，以及與現有開源模型相比較的三個參考標準。換言之，只要與這些參考標準相比沒有出現新風險，即不屬於被納入監管範疇的增量風險。值得注意的是，上述標準將對開源模型「增量風險」的判定設置了較高評估門檻，而對於需要監管介入的增量風險判斷將則強調證據支撐和科學審慎。在廣泛調研各類開閉源模型並徵求各方意見的基礎上，NTIA 認為現有研究和證據無法完全滿足上述三個風險評估標準，即開源模型沒有需要額外進行單獨管制的「增量風險」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;比較「全量風險」和「增量風險」兩種機制不難發現，以「增量風險」為核心的開源風險治理整體傾向於事中事後的風險管控，可通過調整風險閾值來實現開源模型自由普惠和安全治理的利益平衡，而具有嚴謹證據支持的比較過程也能夠排除認知風險風險的不合理影響。正因為此，本文認為基於「增量風險」的開源模型治理機制更能精確匹配模型開源的技術應用特徵，有利於建立對於開源模型風險的客觀認知，能夠避免基於對未知風險的恐慌而採用非理性的過度規制，從而防止對開源價模型的價值發揮產生不當的阻礙效應。不過這並不代表「增量風險」管控機制就已能應對開源大模型風險治理的所有挑戰，開源大模型所涉產業鏈條的複雜性使得「生態治理」可能是未來更需重視的改革理念和方向。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;三、構建大模型開源生態的協同治理體&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源大模型的主要安全風險在於誤用濫用，因此安全風險的治理應對必須要考慮模型開源後的利益相關方，從而即引出了「生態治理」的改革理念。大模型開源生態具有產業鏈條多樣化、參與主體多元化的特點，各方風險的控制能力以及針對誤用濫用的防範責任有所差異。開源模型生態治理既不能完全放任，也不能僅將治理重心簡單地聚焦於開源模型本身，而是要綜合判斷開源模型生態的結構對濫用誤用風險的影響，採取合理的責任分擔機制促進各方有效的治理協同合作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一方面，應基於科學證據分析開源模型生態的風險擴散特徵，根據開源模型生態鏈分工機制分析開源模型濫用誤用風險的產生和傳遞過程，合理劃定各類主體的責任邊界。在近期發佈的《雙用途基礎模型濫用風險管理指南（NIST AI 800-1）》中，美國 NIST 明確了開源模型的風險不能僅由模型研發方承擔，模型應用生態中的直接參與方（包括雲計算提供方、模型託管平台、下游模型使用部署及應用開發者、分發平台、三方評測審計方、用戶公眾等）以及間接參與方（學術機構、外部研究者和政府機構等）都需要根據自身角色承擔相應的責任，通過多方合作協同的方式有效管控模型應用中的風險。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，應提升開源模型生態的風險治理能力，建立對開源模型生態的國際信任。目前對於開源人工智能安全的認知還存在着碎片化的問題，各國針對 DeepSeek 開源模型的評估結果凸顯了模型安全風險的認知存在差異、模型安全基準在全球範圍內並未對齊、測試標準不統一以及評估基準不夠客觀和缺乏公信的現實問題，相應的模型安全能力水平也不會對齊。在開源模型生態全球化發展的背景下，各國模型安全能力分佈不均、資源不足的現狀會對模型能力的普及和應用的拓展造成影響，引發對開源模型不當的限制。對此需要進一步推動不同主體在共商共享過程中共同探索，促進關於模型安全能力和資源的增長和積累，從而提升個體及整體層面的安全水平。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第三，應堅持「人工智能安全作為公共產品」的基本理念，推動安全公共知識的積累和認知協同。可以進一步利用開源模型生態的透明度和包容性，將安全作為開源模型生態構建的重要目標，促進多方參與和共享的協同治理模式，通過鼓勵通過開源推動各方主體參與到模型安全能力的共同建設中，支持開放透明的模型研發應用，推動開源社區與學術機構和公眾用戶進行共同監督，在降低信息不對稱的同時，在專業知識、風險識別和監測、應急響應等方面加強安全能力建設，促進監管、產業和社會公眾對安全的人工智能建立信任。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338032</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338032</guid>
            <pubDate>Wed, 05 Mar 2025 10:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>穩定且高性價比的大模型存儲：攜程 10PB 級 JuiceFS 工程實踐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在過去兩年多的時間裏，隨着 AI 大模型的快速發展，JuiceFS 在攜程內部得到了越來越多 AI 用戶的關注。目前，攜程通過 JuiceFS 管理着 10PB 數據規模，為 AI 訓練等多個場景提供存儲服務。&lt;/p&gt; 
&lt;p&gt;本文將介紹攜程如何使用 JuiceFS，以及基於 JuiceFS 實現的關鍵管理能力，包括多租戶權限管理、計費功能、故障排查和監控等方面。同時，還將分享 3 個生產環境中的排障案例。最後，我們對比了 JuiceFS 與極速 NAS 的性能與成本，JuiceFS 在大多數業務場景中能提供與極速 NAS 接近的性能，同時成本僅為極速 NAS 的十分之一。&lt;/p&gt; 
&lt;h2&gt;01 JuiceFS 在攜程的應用：從冷存到 AI 場景&lt;/h2&gt; 
&lt;p&gt;攜程早在 2022 年就已經開始接入 JuiceFS，當時的主要目的是替代 GlusterFS，以提高其列表性能，服務 DBA，處理偏冷的數據。此外，這種解決方案能夠與 OSS 的生命週期和運行策略相搭配，有效地降低 DBA 處理冷數據的成本。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fzh-cn%2Fblog%2Fuser-stories%2Fxiecheng-case&quot; target=&quot;_blank&quot;&gt;點擊此處查看早期案例&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;隨着 AI 應用的需求變化，尤其是在 AI 模型訓練過程中，存儲需求開始轉向大帶寬讀寫和頻繁的寫入操作，如模型的 checkpoint 保存、數據分發及存儲等。&lt;/p&gt; 
&lt;p&gt;AI 這個場景最大的痛點在於，攜程的訓練和推理系統被分開管理，導致存儲架構非常割裂。訓練過程中產生的模型需要通過複雜的上傳和下載流程來分發到其他平台，這個過程顯得非常低效且繁瑣。&lt;/p&gt; 
&lt;p&gt;目前的做法是，訓練平台和推理平台通過 JuiceFS CSI 掛載相同的卷，但對權限進行區分：訓練平台具備讀寫權限（ReadWriteMany），而推理平台則僅具備只讀權限（ReadOnlyMany）。對於只讀負載，預讀功能可通過 JuiceFS 中的相關參數進行調優，以提高性能。&lt;/p&gt; 
&lt;p&gt;此外，AI 應用面臨的另一個問題是存儲性能的瓶頸，尤其是在讀性能方面。AI 推理任務需要較高的帶寬，而許多存儲產品的帶寬表現有限。與 OSS 配合使用時，存儲帶寬可以根據數據量的增加而自動擴展。例如，OSS 為用戶提供的帶寬與數據流量成正比，數據使用量越大，分配的帶寬也越大，這種設計使得 AI 用戶在大規模數據讀取時能夠獲得所需的帶寬。&lt;/p&gt; 
&lt;h2&gt;02 JuiceFS 部署架構 &amp;amp; 關鍵能力&lt;/h2&gt; 
&lt;p&gt;我們搭建的部署架構與社區大部分的推薦方案一致，採用了 TiKV + OSS 的組合。具體來説，架構由以下幾個核心組成部分構成：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TiKV &amp;amp; PD 作為元數據引擎&lt;/strong&gt;：TiKV 支持分佈式架構和事務處理，具備出色的性能。通過跨 IDC 部署，確保系統的高可用性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ali OSS 作為存儲底座&lt;/strong&gt;：結合專線網絡提供大帶寬傳輸能力。同時，OSS 的自動轉冷功能使得系統在成本控制上具有優勢，性價比高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JuiceFS 客戶端的定製化&lt;/strong&gt;：對 JuiceFS 客戶端，進行了針對性修改，特別是在內部管理功能上，例如自助服務、計費系統、控制限速等。我們還進行了優化，以便用戶在 Kubernetes (k8s) 環境中能夠方便地使用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a43c9b763a7aecfec8735cb15f83d8e8a2c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;關鍵能力 1：多租戶權限管理與計費&lt;/h3&gt; 
&lt;p&gt;我們要為多個用戶羣體提供服務，包括 AI、DBA 等不同領域的用戶。為了保證資源的合理使用，我們為每個申請用戶提供了獨立的 token，用戶需使用 token 進行掛載，以此實現資源的隔離。&lt;/p&gt; 
&lt;p&gt;為了控制成本，我們對用戶的使用進行嚴格監控和計費。我們在每個卷（Volume）級別進行實時監控，並按小時生成賬單，確保每個用戶的使用情況得到清晰記錄和計費。&lt;/p&gt; 
&lt;p&gt;在 Kubernetes 環境中，很多用戶選擇使用動態存儲類來實現存儲的自動化調度。但為了實現自助申請並便於計費，我們採用了靜態 PVC。這種方式可以方便地關聯卷，並與自動化流程相結合，確保每個卷的費用被精確記錄。在 JuiceFS 中，每個卷都記錄了一個全局變量（&lt;code&gt;totalUsedSpace&lt;/code&gt;），該變量用於追蹤與計費相關的使用情況。&lt;/p&gt; 
&lt;p&gt;雖然社區也支持對子目錄的計費，但對於我們初期開發而言，按卷級別計費相對簡單和高效。&lt;/p&gt; 
&lt;h4&gt;計費原理&lt;/h4&gt; 
&lt;p&gt;攜程內部使用的工具 FinOps 可以定期拉取阿里雲費用中心的數據，以獲取每個雲產品的費用信息。通過這個工具，我們能夠實現對各項雲服務費用的實時監控。&lt;/p&gt; 
&lt;p&gt;在使用這個工具時，當申請 JuiceFS 卷時，需要進行關聯，卷的創建會與相應的用戶關聯。為了有效管理，我們每小時都會進行一次打點監控，記錄空間使用情況、文件引用數量等指標，並將這些數據發送到 FinOps 系統。然後，FinOps 會對每個捲進行費用分攤，將 OSS 的費用按比例分攤到每個卷的所有者。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6a3de56cc1a1d026ce80962d0f93f6435c5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;費用異常：存儲泄露&lt;/h4&gt; 
&lt;p&gt;在日常運營中，主要關注的是費用的上升情況和費用佔用的趨勢。這些費用數據能夠反映出是否存在異常問題。在一次費用分析中，我們遇到了一個典型問題：通過 JuiceFS 統計的使用量沒有明顯變化，但整個 OSS 的成本卻有所上升。經過進一步分析，確認阿里雲的收費政策和 OSS 單價並未變化。然而，分攤出去的單價卻上升了，導致了整體費用的增加。&lt;/p&gt; 
&lt;p&gt;在檢查 JuiceFS 的計費統計和阿里雲 OSS 上的文件量統計時，我們發現兩者之間存在顯著的差異。OSS 提供了一個存儲空間清單功能，可以查看當前整個 bucket 下所有文件的使用量。&lt;strong&gt;我們通過使用 OSS 清單對數據進行聚合，發現 JuiceFS 統計的用量遠低於 OSS 統計的用量。這導致了用戶在 JuiceFS 中的存儲空間使用量被低估，從而使得 OSS 存儲空間的費用被錯誤地分攤給其他用戶，進而導致其他用戶的單價上升&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這一差異的根本原因在於 JuiceFS 刪除文件的實現方式。對於大量刪除的文件，JuiceFS 使用軟刪除策略標記文件為已刪除，但後台會逐步刪除這些數據。由於在使用過程中禁用了所有後台任務，導致用戶的刪除操作產生了許多待處理（pending）和失敗的刪除請求。&lt;/p&gt; 
&lt;p&gt;進一步分析後，我們發現 JuiceFS 存在兩種數據泄露情況：一是待處理刪除（pending delete），二是回收站（trash）中的數據。為了應對這一問題，我們設置了一個額外的監控服務，每隔 6 小時掃描一次潛在的數據泄露。如果發現泄露數據，我們會啓用一個專門的客戶端，取消禁用後台任務，並清理這些泄露的數據。&lt;/p&gt; 
&lt;h4&gt;功能禁用&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;禁用回收站&lt;/strong&gt;：回收站功能在很多用戶場景下並不需要開啓。回收站是後台任務，需要額外的資源進行清理，尤其是在使用 TiKV（如 RocksDB 數據庫）的情況下，回收站會對數據庫性能造成一定壓力，尤其在出現突發的大規模刪除時。因此，我們選擇不啓用回收站功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;禁用備份元數據（BackupMeta）功能&lt;/strong&gt;：JuiceFS 提供了元數據備份功能，但在數據量較大時，邏輯備份速度較慢，無法滿足我們的需求。為了提高備份效率，我們更傾向於使用 TiKV 提供的官方備份工具來進行數據庫備份，這樣可以更好地支持大規模數據的備份需求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;關鍵能力 2：日誌收集與管理，提高排障效率&lt;/h3&gt; 
&lt;p&gt;我們使用內部工具將 TiKV 和 PD 中的日誌收集到 ClickHouse，通過 Kafka 傳輸並最終存儲到 ClickHouse 。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-55cdfb30ecc15697257048edf63d136a158.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過這樣的日誌收集，我們能夠及時捕捉集羣中的錯誤信息。許多情況下，集羣可能會產生大量的錯誤，但用戶並未察覺，且從客戶端來看，性能似乎並未受到顯著影響。然而，經過多次事故的處理，我們發現很多問題都是通過分析 TiKV 的日誌來發現的，從而能在早期階段及時解決潛在問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-97246dec5d4374e9451ce2ac7f6d3f3e433.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;關鍵能力 3：監控&lt;/h3&gt; 
&lt;p&gt;在監控方面，我們挑選了 TiKV 官方提供的一些關鍵指標來構建自有的監控系統。TiKV 和 TiDB 的整體監控體系相對複雜，官方提供的監控看板包含了大量信息，顯得過於繁雜。剛接手時，這一部分確實沒有很清晰的理解。&lt;/p&gt; 
&lt;p&gt;在實踐過程中，我們最終選取了幾個核心的指標，以便更有效地監控 TiKV 的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能相關指標：包括 CPU、內存使用情況以及熱點讀寫。&lt;/li&gt; 
 &lt;li&gt;PD（相關指標：重點監控 Region leader 分佈與調度情況。&lt;/li&gt; 
 &lt;li&gt;GC（垃圾回收）相關指標：包括 GC 時間和 MVCC 刪除等信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b682cf0d76ef22368be478f44fb1433ee5c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 JuiceFS 客戶端的監控中，我們通過 Prometheus 接口獲取 CSI 的指標。然而，對於普通掛載情況，特別是在用戶自行部署 JuiceFS 的機器上，我們無法直接控制或訪問這些數據。因此，我們使用 JuiceFS 提供的 &lt;code&gt;state&lt;/code&gt; 文件來採集簡化的監控指標。大部分場景中，state 文件已經能夠覆蓋我們需要的指標。為了高效採集數據，我們在每台機器上部署了一個 DaemonSet，通過該工具定期讀取 &lt;code&gt;state&lt;/code&gt; 文件並進行監控。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1bc3d5bee5c45a51173ace7a9b8f2d00d63.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;客戶端監控看板包括以下內容：CPU 和內存使用情況、啓動時間和啓動參數、Golang 性能指標（如堆內存中的活躍對象）、以及讀寫性能（包括緩衝區和塊緩存的使用情況）。除了關注客戶端的讀寫性能外，更多時候我們更側重於整體帶寬情況。&lt;/p&gt; 
&lt;h3&gt;關鍵能力 4：元數據備份&lt;/h3&gt; 
&lt;p&gt;在 TiKV 生態中，存在兩個不同的 br 備份工具。TiKV 文檔中提到的 br 工具只能備份通過 rawKV API 寫入的數據，無法備份通過 txnKV API 寫入的數據。&lt;/p&gt; 
&lt;p&gt;與此不同，TiDB 倉庫中的 br 工具更側重於備份 TiDB 數據。這個工具提供了 backup txn 子命令，專門用於備份通過 txnKV API 寫入的數據。&lt;strong&gt;最終，我們採用了 TiDB 的全量快照備份方案，每日進行定時備份&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-320d9ae7c49c5f0edfc5a778bbdd0cc5228.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在使用 TiKV 集羣版本 v5.2 並直接應用 TiDB br 工具的 master 分支代碼，時，遇到了一些問題：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;雖然可以成功備份數據，但在恢復時出現了錯誤。&lt;/li&gt; 
 &lt;li&gt;在備份過程中，TiKV 持續嘗試執行備份操作，且無法停止。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;針對這些問題，我們將其反饋給了 TiKV 社區，並在社區的幫助下成功解決了相關 bug。解決問題後，我們對備份過程進行了優化，通過設置備份限速為 50MB/s，使得備份過程能夠在大約 15 分鐘，內完成。&lt;/p&gt; 
&lt;p&gt;TiKV 備份通過 trip-tikv-manager 服務進行管理，該服務負責調度和執行備份任務。備份數據被存儲在獨立的對象存儲，中，目前使用的是 Ceph 存儲系統。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cbe9afd8006b2d45212f9413821f23a45e0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目前，在我們的最大集羣擴展後的生產環境中，能夠在 20 分鐘內完成全量備份。備份任務基本上會在每天定時執行，並通過監控實時查看備份狀態&lt;/strong&gt;。由於 JuiceFS 服務全天沒有明顯低谷，我們選擇在白天對 TiKV 進行備份。&lt;/p&gt; 
&lt;p&gt;鑑於我們的系統部署為三中心結構，並已對 Region 實施了 Zone 級別的隔離，即便單一中心發生宕機，也不會影響到 TiKV 的可用性。因此，我們將 TiKV 的備份視作一種額外的安全措施，僅執行快照級別的備份與恢復操作。&lt;/p&gt; 
&lt;h2&gt;03 生產環境排障案例&lt;/h2&gt; 
&lt;h3&gt;案例 1：TiKV MVCC (Multi-Version Concurrency Control) 堆積&lt;/h3&gt; 
&lt;p&gt;這個問題是在去年 9 月被發現的。當時我們發現，儘管 TiKV 數據庫和 JuiceFS 的整體使用量並沒有顯著增長，但數據庫的磁盤空間和引擎大小卻急劇下降。&lt;strong&gt;奇怪的是，TiKV 的 CPU 使用率和 QPS 並未發生明顯變化。進一步分析日誌後，發現大量與 region 相關的報錯，這些錯誤是由於 MVCC（多版本併發控制） 堆積引起的&lt;/strong&gt;。MVCC 堆積後，region 內的舊版本數據不斷累積，導致 region 無法正常分割，從而阻礙了硬盤空間的及時回收。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7710835625f5f2e6e986d3b15ae73bb804b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過深入排查並使用 tikv-ctl 工具解碼報錯的 region 中的 key 後，我們發現這些 key 均來自同一個 JuiceFS 卷。由於用戶頻繁更新文件，JuiceFS 中的 chunk Key 數量不斷增加，每次更新都會在 TiKV 中生成新的版本，從而迅速消耗內存和磁盤資源。 進一步分析我們發現，TiKV MVCC 堆積問題與 JuiceFS 的元數據定義和存儲方式密切相關。TiKV 作為支持 MVCC 的數據庫，能夠保證事務的隔離性。每當數據被更新時，TiKV 會為每個寫入操作分配一個時間戳（TSO），從而創建一個新的版本，而不是直接修改原有數據。這種機制確保了事務的隔離性，並保證了讀操作可以讀取到一致的數據。&lt;/p&gt; 
&lt;p&gt;在實際應用中，JuiceFS 會將文件切分為多個 chunk，每個 chunk 包含若干 slice。當一個 chunk 被頻繁更新時，TiKV 會為該 chunk 創建新的版本，導致相同 chunk key 在 TiKV 中產生多個版本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;頻繁更新同一 chunk 會使 TiKV 無法及時回收過期的版本，從而迅速消耗存儲資源，最終導致 MVCC 堆積&lt;/strong&gt;。隨着這些未回收的舊版本不斷積累，TiKV 的存儲壓力逐漸增加，可能會導致性能下降，甚至引發磁盤空間不足等問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-00f144732841d495befadaa331944b31d70.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體來説，高頻更新文件導致以下兩方面的性能問題：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;JuiceFS ：由於 chunk 記錄的 slice 數量不斷增多，JuiceFS 需要更多時間來恢復完整的文件視圖。當 slice 數量過多時，JuiceFS 會暫停寫入，並強制執行數據壓縮（compaction）操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;TiKV：頻繁寫入版本會增加 RocksDB 中存儲的數據量，導致 LSM 樹的讀性能下降，從而影響 TiKV 的整體性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;針對上述問題，我們採取了一種更加激進的垃圾回收（GC）策略。具體做法是設置一個獨立服務，每隔 5 分鐘通知 TiKV 的 PD 節點，告知它在接下來的 25 分鐘內的數據可以被 GC 回收。這樣，TiKV 在 GC 時能夠通過 compaction 過程高效回收無用數據，減少了 GC 對 CPU 的佔用。同時，通過加速 TiKV 的 compaction 過程，能夠有效降低 MVCC 堆積的風險，防止版本過度堆積而導致的性能瓶頸。&lt;/p&gt; 
&lt;h3&gt;案例 2：大量容器同時掃盤打爆 TiKV&lt;/h3&gt; 
&lt;p&gt;在進行大量容器同時掃描磁盤時，TiKV 負載超過 70%，甚至出現崩潰的情況。經過排查發現，所有卷都是通過 CSI 形式掛載的。在使用 CSI 掛載 JuiceFS 時，會啓動一個單獨的 Pod 並在其中掛載 JuiceFS 客戶端。由於 JuiceFS 客戶端與應用 Pod 完全隔離，無法感知應用中的掛載點操作，導致 TiKV 的 PD（Placement Driver）管理節點的利用率不斷上升。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-05a643139d360027938e8c7ff9a6901369b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;進一步調查後，發現大量 GET 請求，主要是文件查找操作。雖然 OSS 監控數據顯示一切正常，但 TiKV 卻持續受到來自歷史失敗請求的壓力，導致性能下降。卷中存在大量小文件和超大目錄，導致 TiKV 不斷處理類似&quot;掃盤&quot;行為的請求。最初我們認為問題出在宿主機上的某些應用，但進一步排查後發現，JuiceFS 應用的 Pod 中有一個定時任務，該任務會定期掃描目錄。多個 Pod 同時對一個超大目錄進行掃描，造成 TiKV 負載極大。&lt;/p&gt; 
&lt;p&gt;針對這一問題，採取了以下對策：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;消除 updatedb 的影響&lt;/strong&gt;：通過使用 ConfigMap 將 /etc/updatedb.conf 掛載到用戶 Pod 中，覆蓋鏡像自帶的配置，並在配置中禁止掃描 JuiceFS 掛載點。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;限流元數據操作&lt;/strong&gt;：為了防止用戶不經意間的行為影響 TiKV 集羣的性能，我們修改了 JuiceFS 和 TiKV 相關代碼，在元數據部分添加了限流機制，避免 TiKV 因過多文件查找請求而過載。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;進一步限流代碼&lt;/strong&gt;：儘管之前對 OSS 帶寬進行了限流，但問題仍未完全解決。因此，我們進一步添加了針對元數據操作的限流代碼，特別是針對 TiKV 的元數據操作，從而緩解了 TiKV 集羣服務質量下降的問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;案例 3：JuiceFS client OOM&lt;/h3&gt; 
&lt;p&gt;在使用 JuiceFS 的過程中，AI 用戶，存在不規範的使用方式。這些用戶會在 JuiceFS 中存儲訓練數據集，這些數據集可能是圖片或文檔，都是小文件，而且通常都是講大量小文件集中存儲在一個目錄中。某些目錄中的文件數量甚至達到數百萬，甚至數千萬個。當多個應用同時發起目錄讀取請求時，可能會導致內存溢出（OOM）問題，尤其是在目錄中包含大量小文件時。&lt;/p&gt; 
&lt;p&gt;為瞭解決這一問題，我們對線上 JuiceFS 客戶端進行了 pprof dump 分析，確認問題出在 JuiceFS 的目錄讀取實現。具體而言，在 JuiceFS 中，目錄讀取是一個阻塞式操作。每次讀取目錄時，系統會拉取該目錄下所有文件的名稱和屬性。如果目錄中包含大量文件，這一過程會消耗大量內存。例如，對於一個包含 500 萬個文件的目錄，單次目錄讀取請求會導致內存佔用達到 3.7GB，並且這部分內存會被長時間持有。&lt;/p&gt; 
&lt;p&gt;為瞭解決這一問題，團隊將全量讀取目錄的實現修改為流式緩衝讀取方式，從而有效減少了內存佔用，並防止了 OOM 問題的發生。在與社區溝通並反饋該問題後，社區積極參與修復，最終成功解決了這一問題。 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs%2Fpull%2F5162&quot; target=&quot;_blank&quot;&gt;meta: support dir stream #5162&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d95dff563fbd4a7097bf6a9f7d900df664d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 JuiceFS 的成本優勢：十分之一極速 NAS&lt;/h2&gt; 
&lt;p&gt;我們對 JuiceFS 與阿里極速 NAS 的進行了性能對比，結果顯示，在大部分讀寫場景下都不落於極速 NAS，甚至性能更加優秀。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ecf6a932cf1df6e8f819d61de9e90a83a96.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-33220c61767bf8e2b9d643b684a7a9c04b7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 具有客戶端緩存和預取功能，並且採用了 OSS 大帶寬、以及數據和元數據分離的設計，這使得它在大部分應用場景中表現出色，尤其是在大模型推理應用中。大模型推理應用通常需要高帶寬的順序讀取場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;通過將 JuiceFS 與 OSS 結合使用，我們實現了一個分佈式文件系統方案，能夠在大多數業務場景中提供與極速 NAS 相同的功能和接近的性能，而成本僅為極速 NAS 的十分之一&lt;/strong&gt;。 這一成本優勢是 JuiceFS 方案的最大魅力之一，它能夠顯著降低我們的運營成本。&lt;/p&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;p&gt;Q：&lt;strong&gt;大模型對於存儲的主要需求是什麼，還是隻關注性價比&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;A：在大模型場景中，我們最關心的是順序讀寫帶寬。訓練過程涉及訓練數據和模型的加載，以及檢查點（checkpoint）的寫入。推理過程則主要涉及模型的加載。儘管整個流程中涉及一些寫操作，但讀操作佔主導，因此，我們特別重視提升讀帶寬的性能。&lt;/p&gt; 
&lt;p&gt;Q：&lt;strong&gt;從對象存儲拉取數據慢，有什麼建議&lt;/strong&gt;?&lt;/p&gt; 
&lt;p&gt;A：JuiceFS 非常適合 AI 負載場景，能夠提供非常高的順序讀寫帶寬。對於順序讀寫，JuiceFS 可以啓用預讀功能，提前從 OSS 拉取數據，這能有效提升性能。然而，由於 OSS 的延遲一般高於 50ms，這可能會影響隨機讀寫的性能。如果對低延遲有較高要求，NFS-Ex 和 CPFS 都能提供 1ms 以內的 4K 隨機讀寫延遲。此外，JuiceFS 官方也提供了分佈式緩存方案來降低延遲。總體來説，這之間是性能與成本之間的權衡。&lt;/p&gt; 
&lt;p&gt;Q：&lt;strong&gt;TiKV 元數據規模大概能支撐到多大的量？數據量大的場景，元數據是不是成為瓶頸&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;A：提供一組攜程的數據供參考，我們的一台生產集羣，TiKV 節點數量為 6 個，每個節點配置為 64 核 256 G 內存，承載着接近 40 億個文件的負載。在這種配置下，TiKV 的 get p99 延遲仍然保持在 1.5ms 以下。實際生產中，元數據的延遲與 OSS 的延遲不在同一量級，因此 TiKV 並未成為瓶頸。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17869204</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17869204</guid>
            <pubDate>Wed, 05 Mar 2025 10:36:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>OCAI + DeepSeek 滿血版雙 buff 加成，OS 運維從此告別焦慮</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;作者&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;黃敏傑、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;李強&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;編輯&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;cherry&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;審稿&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;林青、鄭力博&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;當遇到忘記的 Shell 命令參數，你是否還在使用「xxxx --help」查詢使用幫助？當你遇到 OS 的疑難問題，是否還在全網苦苦搜索解決方案？今天，OpenCloudOS 社區重磅推出新一代 OS 智能助手 OCAI-Agent，它集代碼生成、場景化指南輸出於一體，通過接入&lt;span style=&quot;color:#0052d9&quot;&gt;滿血版 DeepSeek R1&amp;nbsp;&lt;/span&gt;模型，讓你通過簡單的中文指令，即可實現秒級 AI Agent 調用。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;一、OCAI 工具概覽&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;很多 OS 運維工程師常陷於「文檔迷宮」：面對上千頁的官方手冊、散落全網的技術貼、版本迭代帶來的參數變更，每一次故障排查都可能演變成耗時數小時的文檔檢索工程。但 OCAI 的誕生，可能一切都變了……&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;先看一下這個，好像小白也可以實現對 OS 的運維：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70d16ddf9350a0b840202ffe51ace139f07.gif&quot; width=&quot;1632&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span style=&quot;color:#939393&quot;&gt;&lt;span&gt;&lt;span&gt;（劃至文章底部可查看未加速操作版）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;目前，OCAI 已接入滿血版 Deep&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Seek R1 模型，並將&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;全量文檔、社區運維案例、Gitee 技術方案等異構數據，經向量化處理後形成動態知識圖譜&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;也就是説，針對&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的使用、運維管理操作等場景，OCAI 可以幫為用戶總結提煉並生成具體場景下的使用指南、命令、甚至代碼，從而實現極大程度上的智能提效。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;當前版本主要分為三種模式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Chat 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;通過提問，開始調用 OCAI 問答系統，並讓系統進入思考、推理及結果輸出過程。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Cmd 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;直接執行的 Shell 命令，並根據用戶指示執行相應任務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Code 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;生成執行代碼。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;1、Chat 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;安裝完成並使配置生效後，在命令窗口中直接輸入相關問題，無需加入任何命令前綴，即可方便調用&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OCAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能助手的問答能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;605&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-028ab812cd46fb2c0719bc268d985671c1c.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;也可通過&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;ocai chat &amp;lt;question&amp;gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;命令形式對問答能力進行調用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;1560&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-29e75a320b94368e7ceace43da99a2cd0bb.png&quot; width=&quot;2784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;2、Cmd 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;Cmd 模式支持根據用戶指示生成可直接執行的 Shell 命令，用戶確認後可立即執行獲取結果。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;318&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d14cdba3fbefd417b4222230d1ead319e24.png&quot; width=&quot;2066&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;3、Code 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;Code 模式下支持根據用戶指示生成不同編程語言下的代碼。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;804&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-25541a23c8c9c3ee960ae0f00cef6836755.png&quot; width=&quot;2200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;二、OCAI 背後的技術實現原理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;當前 OCAI 智能助手針對不同場景設計了多個 Agent 分別處理請求，採用 RAG 方式導入&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;特有知識庫信息，通過&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OCAI-Service&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;與客戶端進行交互，使用不同的底座模型對數據進行推理、總結和潤色，最終輸出給用戶。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img height=&quot;441&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7b55da66d0b276adaafcdca8a792f808c13.png&quot; width=&quot;621&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;1、多 Agents 編排&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI 智能助手針對不同場景和數據源創建了多個不同的 Agents，每個 Agent 負責特定的一個領域的處理邏輯（如對話、命令生成、代碼生成），並通過指定邏輯將多個 Agents 組合編排，從而使使用入口得以統一，多個 Agents 可以協同工作。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;2、RAG&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;針對通用模型缺少特定領域知識的情況，OCAI 智能助手採用 RAG(Retrieval Augmented Generation) 方式，將特定領域的知識庫（如 OpenCloudOS 文檔庫）數據進行處理清洗和切分後，計算成向量形式並存入向量數據庫。用戶提問將先從向量數據庫中檢索出相關程度較高的資料，再統一拼接成 prompt 提交給大模型進行總結和回答。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;3、OCAI-Service&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI-Service 是 OCAI 智能助手的接口層服務。在直接提供服務調用接口的同時，還支持了上下文管理、接口轉發、用戶識別、身份鑑權、配置管理、反饋收集、統計日誌等真實使用情況下必不可少的基礎能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI-Service 也為多模型選擇及函數調用提供了通道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;4、底座模型&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI 智能助手在處理邏輯的各個階段使用了 DeepSeek 和混元的各類大模型，包括但不限於 DeepSeek-R1、DeepSeek-V3、混元 T1、混元 Turbo 等&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;三、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;如何使用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;當前 OCAI-Agent RPM 包已在&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS 8/9 軟件源上線，使用上述版本的用戶可直接執行&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;yum install ocai-agent&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;先進行&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;安裝。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;1622&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ce8d1e053e59009b9dba811a755897580e.png&quot; width=&quot;3572&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RPM 包安裝鏈接：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OC9:&amp;nbsp;&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;u&gt;https://mirrors.opencloudos.tech/opencloudos/9.2/AppStream/x86_64/os/Packages/ocai-agent-1.0.0-2.oc9.x86_64.rpm&lt;/u&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OC8:&amp;nbsp;&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;u&gt;https://mirrors.opencloudos.tech/opencloudos/8.10/Extras/x86_64/os/Packages/ocai-agent-1.0.0-2.oc8.x86_64.rpm&lt;/u&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;完成安裝後，請在&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;該網&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;址&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;em&gt;&lt;u&gt;（https://opencloudos.org/ospages/learnmore/ocai）&lt;/u&gt;&lt;/em&gt;&lt;/span&gt;內&lt;span&gt;輸入&lt;span&gt;&lt;strong&gt;您的郵箱進行註冊&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，並按照&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;郵件中的指引配置訪問密鑰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，即可開始使用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;iframe frameborder=&quot;0&quot; height=&quot;300&quot; scrolling=&quot;no&quot; src=&quot;https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114137547931864&amp;amp;bvid=BV1hPRGYcE3B&amp;amp;cid=28794949378&amp;amp;p=1&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;為了確保服務的穩定性，OCAI-Agent 每天最多可調用 50 次。請合理安排您的使用頻率，以免達到調用上限。如有更多需求，請關注後續更新或聯繫我們獲取幫助。感謝您的理解與支持！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;OpenCloudOS 開源社區是由操作系統、雲平台、軟硬件廠商與個人攜手打造中立開放、安全穩定且高性能的 Linux 操作系統及生態。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;歡迎上下游廠商、高校及組織加入社區，共建開放共享的安全生態。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4d4bdd4525c9272aa6205e93686655ae07c.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#888888&quot;&gt;&lt;span&gt;掃碼添加社區助手進羣，添加時備註「OCAI」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338017/ocai-agent</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338017/ocai-agent</guid>
            <pubDate>Wed, 05 Mar 2025 10:07:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>開源、可定義數據中台 AllData 架構全解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;數據中台，是近幾年才流行的概念。簡單地説，就是一套可持續「讓企業的數據用起來」的機制。&lt;/p&gt; 
&lt;p&gt;AllData 是一個開源的可定義數據中台，使用 GPL 協議，上層是 Wujie 微前端架構，底座是可插拔的後端架構，提供包括數據集成、數據存儲、數據開發、數據治理、BI 展示等功能在內一條龍的解決方案。AllData 作者巫林壕在 2019 年就完成了該項目 ，並已經運行 5 年以上，GitHub 上的 Star 數已經超過了 2.6K。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;316&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5bb68507b486f1b0ce1bef71defb2d6143d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;AllData 能與大數據平台如 Hadoop、Spark 等無縫集成，支持關係型數據庫如 MySQL、PostgreSQL，以及非關係型數據庫如 MongoDB 等，確保與各類數據源的兼容。&lt;/p&gt; 
 &lt;p&gt;由於 AllData 數據中台主要基於 Java 進行開發，並結合了 Vue 等技術棧構建用戶界面，因此它能夠在支持 Java 應用的操作系統上穩定運行。&lt;/p&gt; 
 &lt;p&gt;得益於其靈活的底層架構和可插拔的後端設計，系統能夠根據不同的業務需求進行定製和擴展，從而降低了二次開發的難度和成本。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  3 月 14 日晚，巫林壕將做客開源中國 OSCHINA 直播間的《技術領航》欄目，為大家拆解數據中台 AllData 架構，並手把手教大家基於 Alldata 實現數據同步、處理、服務全流程。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt; 
  &lt;img height=&quot;691&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-468b59adcebcc15d3b659e3125117cde85a.png&quot; width=&quot;1202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt;
   巫林壕，AllData 作者、杭州奧零數據科技創始人&amp;amp;CTO 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播標題：&lt;/strong&gt; 數據中台 AllData 架構全解&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;3 月 14 日週五 19:00-20:00&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;直播亮點：&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;開源而生，AllData 的來時路與未來發展方向&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;技術乾貨：微前端+可插拔架構設計解析&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;15 分鐘手把手操作數據同步→處理→服務全流程&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;揭祕商業用戶重度使用的核心功能有哪些？&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;微信掃碼，預約直播：&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;715&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f3830144b23e77bb9e604f097b58c653339.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;另外，我們還建了一個交流羣，一起聊聊自己喜歡的開源項目～～當然啦，如果你有什麼特別棒的開源項目，可以推薦過來呀～&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;396&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e7c43c0b0553350855a379af00c6c7c15d.jpg&quot; width=&quot;396&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了諸多社區或組織的大力支持，在此特別表示感謝：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（碼雲）是開源中國於 2013 年推出的基於 Git 的代碼託管平台、企業級研發效能平台，提供中國本土化的代碼託管服務。&lt;br&gt; 目前，Gitee 已經有超過 1350 萬名開發者，累計託管超過 3600 萬個代碼倉庫，是中國境內規模最大的代碼託管平台。同時，旗下企業級 DevOps 研發效能管理平台 Gitee 企業版已服務超過 36 萬家企業。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;網址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;奧零數據&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;杭州奧零數據科技公司擁有核心產品 AllData 可定義數據中台，提供多樣開源大數據組件模板，快速搭建極致性價比的數據中台。&lt;/p&gt; 
  &lt;p&gt;網址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.aolingdata.com%2F&quot; target=&quot;_blank&quot;&gt;http://www.aolingdata.com/&lt;/a&gt;&lt;/p&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技術領航&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用戶作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用戶和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17870188</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17870188</guid>
            <pubDate>Wed, 05 Mar 2025 09:50:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>如何使用 Gitee + Zadig 實現微服務架構持續交付</title>
            <description></description>
            <link>https://my.oschina.net/koderover/blog_beta/15298899</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog_beta/15298899</guid>
            <pubDate>Wed, 05 Mar 2025 09:31:00 GMT</pubDate>
        </item>
        <item>
            <title>RAG 市場的 2024：隨需而變，從狂熱到理性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 盧向東&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;轉眼到了 2024 年尾，和小夥伴一起創立 TorchV 也接近一年。雖然這一年做了很多事情，但從技術層面上來説，RAG 肯定是不得不提的，所以今天分享一下作為大模型應用創業者所感知的這一年，RAG 市場環境的變化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;RAG vs Fine-tune&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 這一年，RAG 技術對應的市場需求變化也是挺大的。在講變化之前，我覺得有必要分享一下為什麼 RAG 是目前市場上不可或缺的一種大模型應用的技術實現方式，它的優點是什麼？以及它和主要競爭技術之間的現狀是怎麼樣的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RAG 最開始被大家熱推，更多是因為以下三個原因：可以避開大模型的上下文窗口長度的限制；可以更好地管理和利用客戶專有的本地資料文件；可以更好地控制幻覺。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這三點到現在來看依然還是成立的，但上下文窗口這個優勢已經慢慢淡化了，因為各大模型的上下文窗口都在暴漲，如 Baichuan2 的 192K，doubao、GLM-4 的 128K，過 10 萬 tokens 的上下文窗口長度已經屢見不鮮，更別説一些特長的模型版本，以及月之暗面這樣用長文本佔據用戶心智的模型。雖然這些模型是否內置了 RAG 技術不好説，但是 RAG 解決上下文窗口長度限制的特點已經不太能站得住腳。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是第二點管理和利用專屬知識文件，以及第三點控制幻覺，現在反而是我認為 RAG 最大的殺手鐧。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）專屬知識文件管理&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因為 RAG 這種外掛文件的形式，我們便可以構建一個知識文件管理的系統來維護系統內的知識，包括生效和失效時間，知識的協作，以及便捷地為知識更新內容等。RAG 在知識維護上，既不需要像傳統 NLP 那樣由人工先理解再抽取問答對，也不需要像微調（fine-tune）那樣需要非常專業的技術能力，以及微調之後的繁瑣對齊（alignment）優化。所以如果客戶的知識內容更新比較頻繁（假設每天需要追加、替換大量實時資訊內容），特別是金融證券、企業情報等場景，RAG 知識更新便捷的特性真的非常合適。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）RAG 的幻覺控制&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的幻覺控制是一個有爭議的話題，我之前寫過類似觀點，也有同學斬釘截鐵地認為 RAG 和幻覺控制八竿子打不着，但我現在依然堅持 RAG 可以有效控制幻覺這個觀點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我們可以來看看 LLM 幻覺產生的主要原因：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 對於用戶的提問輸入，LLM 內部完全沒有相應的知識來做應對。比如你問大模型，上週三我在思考一件事，但是現在想不起來，你幫我想想是什麼。例子雖然誇張，但顯而易見，LLM 也不知道，但是它會一本正經給你一些建議，當然肯定不是你想要的；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 當我們給 LLM 原始問題，以及多個模稜兩可或互相影響的參考材料，那麼 LLM 給出的最終答案也會出錯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;好，那麼針對以上問題，是否我們解決好對原始問題的 「理解 - 檢索 - 召回」，送到 LLM 的 context 足夠清晰（指的是沒有歧義內容、檢索相關度高），結果就會非常準確？根據我們的實踐結果，答案是明確的：今年 9 月份我們對一些項目進行了槽位填充（消除模糊問答）和元數據輔助之後，問答準確率可達到 98% 以上。比直接把大文本扔進同一個 LLM 測試的問答準確率幾乎高出 14 個百分點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有同學會説，LLM 幻覺的深層原因是 temperature 或者説概率引起的。就我純個人觀點來看，現當下的 LLM 參數足夠大、知識量足夠多，temperature 引起的偏差對於最終結果的正確性影響已經微乎其微了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（三）市場表現&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你應該看出來了，在 RAG 和微調之間，我明顯站隊了，而且從一年前就開始站隊了，我們創業的技術方向也是如此。從今天來看，我覺得 RAG 在 2024 年的表現確實要強於微調。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;499&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3a36116d31e8f9dc257f8e00f317e80a982.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖：Menlo Ventures 在 2024 年 11 月 20 日發佈的市場調研報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;來源：https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根據 Menlo Ventures 發佈的市場調研報告顯示，RAG 以 51% 的市場份額在企業市場份額中佔據絕對優勢，Fine-tune 和 Prompting 工程均下降兩倍多。Agent 今年屬於純增長，目前情況還不錯，但在企業應用領域，多 Agents 的編排依然存在理解能力不足和生成幻覺等問題有待提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果去預測明年的企業級市場趨勢，我覺得應用（Application）可能會是最大的關鍵詞，甚至會超過 Agent 的熱度。其實今年下半年已經能明顯的看出來，越來越多傳統大企業開始將大模型技術引入到業務中，而且他們的特點是要求高、需求剛、付費爽。而一旦大家開始在大模型的應用側競賽，RAG 在整個業務流程中白盒流程多、易控等特點愈發會受到企業客戶和開發者的熱捧，優勢進一步拉大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;企業 AI 應用市場在 2024 年的變化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）上半年：AI 無所不能，大而全&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年的上半年，AI 市場充斥着激情，那種熱情似乎走在街上都會撲面而來，個人感覺最主要的推動者是自媒體和模型廠商。模型廠商的出發點很容易理解，快速打開市場嘛，但考慮到他們是要最終交付的，所以相對還是比較理性。但自媒體就不一樣了，整個上半年看過太多的文章，大家也都是把最好的一面呈現給了大眾，所以很多人會覺得我才幾個月沒關注，AI 已經發展到我不認識的地步了，AI 已經無所不能了。所以，在 2024 年上半年，我們接觸到的企業需求中，佔主流的是那種大而全的需求，要用 AI 替代他們業務的全流程或基本流程，氣味中充滿了使用者的野望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但實際情況並不理想，AI 或者大模型還真沒到這個程度，而且最關鍵的是範式轉換也還需時間。什麼是範式轉換？最簡單的例子就是以前人們用笨重的蒸汽機推動主軸承轉動，帶動整車間的機器工作。但是換了電動機之後呢，工作方式變了，動力可是變得非常分散，比如你拿在手上吹頭髮的吹風機。帶着微型電動機的吹風機和傳統的蒸汽機在工作範式上就完全不同，採用 AI 大模型之後，企業的業務流程也存在範式改造的過程，並非一朝一夕可以完成的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所以，上半年我遇到的、參與的或者聽説的那些大而全的 AI 項目，一半是在可行性推演中沒有被驗證，一半是交付之後效果很不理想，成功者寥寥。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）下半年：迴歸理性，小而難&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 7 月份開始，陸續有一些傳統大企業找上門來，包括非常知名的企業，以及世界 500 強和多家中國 500 強。如果從時間上來説，他們屬於 AI 投入相對較晚的了，但他們的優勢是需求非常明確，要求也極高。比如有些企業僅僅就是解決一個諮詢服務的需求，在產品範圍上就是一個 AI 問答，但要求準確率接近 100%，就像我們 CTO 在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《AIGC 時代的淘金者，TorchV 這一年的心路歷程》&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;説到社保諮詢一樣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;小而難的好處很明顯，我能看到的是下面幾點：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對企業現有業務流程改造相對較小，內部推動的阻力相對較小，企業客戶配合度高；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;切口小，需求明確，建設成果的考覈清晰可量化；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用功能較小但可用性較高的 AI 產品，可以讓企業內部員工快速接受 AI，做進一步業務流程改造的前期預熱；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;樂於承接大而全需求的合作廠商多半是外包性質的（這個觀點有點傷人，但確實是我看到的現狀），而專業的、交付成功率更高的廠商往往更喜歡需求清晰且有難度的任務。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（三）關於 2025 年的預測&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我在上文中已經有提到，2025 年會有更多企業需求方採用 AI 技術，但企業永遠不會為你的技術買單，他們只會為他們自己的使用價值買單。比如可以幫助他們提升銷售額、業務流轉效率更高，或者和競爭對手的競爭中獲得優勢，還有就是降低成本等等。所以，大模型應用端多端不夠，還需要生長出藤蔓圍繞着企業流程開花結果，這個任務最終會落在應用（Application）—— 內化了企業流程、藉助了大模型能力的、帶有可交互界面的程序。2025 年會成為大模型應用或 AI 應用之爭。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外還有一個趨勢也很明顯，就是知識管理和協作。我們都説這波 AI 浪潮把原來 「沒用」 的非結構化數據給激活了，所以我們馬上會看到那些原來堆在角落裏面的 「冷」 文件和知識（類似 wiki）會被大量啓用，「熱」 文件和知識會爆炸性增長，知識的協作和管理會成為新的問題 —— 就像你有再多的先進坦克和戰車，卻因為無序的交通都堵在阿登森林了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;AI 從業者觀察&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因為我看到的不代表真相，所以這一章節會很短，僅僅分享兩個發現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）AI 技術的下坡&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有兩個感受（非證據）可以説明這一點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 關於 AI 大模型的自媒體數量在減少，從搜索引擎趨勢，加上我和幾個業內朋友的 blog、公眾號以及 X 的閲讀量下降趨勢也可以佐證這一點，下半年雖然市場理性迴歸，但整體熱度是在下降的。OpenAI 不再持續放大招可能也是重要原因之一。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 我前期接觸了很多因為 AI 熱潮而在企業內部抽調精幹力量組成的 AI 小組、AI 研究組和 AI 創新組等團隊的成員，但下半年有不少類似團隊已經解散，人員迴歸到原有崗位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;還有一點就是上半年加我微信好友的很多獨立開發者或在職的個人，多半也已經在尋覓了半年機會之後放棄了繼續探索，這一點在和他們交流，以及他們朋友圈的內容變化中可以明顯感知。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;619&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e0b61fa320f93745cf792daf0e22d6fe227.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖：技術採用生命週期。現階段的 AI 大模型市場似乎正處於過高期望之後的下坡過程中&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是這並不是壞事，上圖已經告訴我們，這是必然規律。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）價值開始顯現&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前還奔跑在 AI 大模型應用賽道的公司，很多已經開始創造出客戶價值，有了自己的優勢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;包括在海外風生水起的 Dify，在內容提取端的合合，以及肯定會成為國內 AI 巨無霸的火山引擎。當然我們還看到了一些深耕垂直行業的優秀團隊，特別是在法律、醫藥、教育等行業。我們也在今年 6 月份開始做了產品轉身，現在已經不再煩惱人家問我們 「你們和 dify、fastgpt、ragflow 有什麼區別」，因為賽道已經開始慢慢不一樣了，而且這個不一樣依然是產品層面的，和服務什麼行業無關。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;198&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e8cb1ce63e159dcd77334342f311f629de.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;盧向東&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;國內最早的 RAG 實踐者之一，杭州萌嘉網絡科技 CEO，公司主要研發 TorchV 品牌的大模型應用和知識庫產品。公眾號：土猛的員外。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338004</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338004</guid>
            <pubDate>Wed, 05 Mar 2025 09:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AI 編程技術與工具發展綜述（2024 年 ）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 朱少民&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 8 月下旬，一款 AI 代碼編輯器 ——Cursor 火爆全球，火到一位 8 歲小女孩拿着它學編程，幾十分鐘內搭起來一個聊天機器人，其演示吸引來 180 萬人在線圍觀。這導致有人大膽預言，未來編程只需要狂按 Tab 就夠了。Cursor 確實好用，包括新推出的 「光標位置預測」 功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是 AI 編程發展沒有那麼快，在國內生成代碼採納率還比較低，根據《2024 軟件研發應用大模型國內現狀調研報告》，多數團隊在 10-40% 之間，如圖 1 所示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce564f5bd0fc36ee2aaa7dc75de3d3e72f3.png&quot; width=&quot;1101&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;圖 1 大模型（LLM）在編程上的應用及其生成代碼的採納率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 2024 年，我們還看到了 「AI 程序員」 Devin 的誕生，Devin 能夠獨立完成複雜的編碼和調試任務、自主查找和修復代碼庫中的錯誤，構建和部署應用程序。在 SWE-bench 編碼基準測試中，Devin 能夠解決 GitHub 中 13.86% 的真實問題，有了很大提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;説起 SWE-bench 編碼基準測試（https://www.swebench.com/），2024 年進步很快，以 OpenAI 建立的 verified 子集（500 個問題）為例，4 月開始時，成功率只有 2.8%，到現在已提升到 53%，這表明 AI 在編程能力方面取得了顯著的進步。這一提升反映了 AI 編程幾個關鍵因素，正好用來總結 2024 年 AI 編程的進展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;模型能力的增強：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 模型的架構和算法不斷優化，如從 Claude 3 Opus、GPT-4o 到 Claude 3.5 Sonnet、Claude 3.5 Haiku，大模型自身的能力不斷提升，使得模型能夠更好地理解和解決複雜的編程問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能體（AI agent）的引進：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體可以收集和學習與任務相關的知識，可以直接調用靜態代碼分析工具、直接調用搜索引擎和 API 為編程任務服務，並通過構建代碼倉庫知識圖來幫助大模型全面理解軟件倉庫的結構和依賴關係，從而更好地定位問題根源並生成有效的代碼補丁。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體還可以動態獲取代碼片段和問題相關的信息，並分析和總結收集到的信息，以便規劃出更好的解決方案。例如從 RAG+GPT 4 (1106) 的 2.8% 提升到 SWE-agent+GPT 4 (1106) 的 22.4%、從 RAG+Claude 3 Opus 的 7% 提升到 SWE-agent+Claude 3 Opus 的 18.2%，效果都比較顯著。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;多模態能力：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模態 LLM 使智能體能夠綜合利用視覺和文本信息，可以理解軟件用戶界面、處理的圖表、可視化數據、語法高亮和交互映射等內容，更好地理解任務陳述以及獲取任務相關的產品信息、開發過程信息，從而更全面地理解和解決問題。目前排在 SWE-bench verified 前 4 位都使用了 Claude-3.5-Sonnet，而它是多模態的、具備處理文本和視覺信息的能力，使其能夠理解和修復包含圖像或其他視覺元素的 GitHub 問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;和工具集成的框架：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以支持智能體在處理複雜任務時進行更好的任務管理和執行，並促進不同 AI 模型和工具之間的協作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如 Composio SWE-Kit 集成文件操作、代碼分析、Shell 命令執行、知識庫管理和數據庫操作等工具或能力，優勢互補，將 SWE-bench verified 大幅度提升到 48.6%。再比如 OpenHands+CodeAct v2.1 將智能體的行為整合到統一代碼行動空間的框架，允許 OpenHands 在編程任務中扮演全方位的智能助手角色，目前排在 SWE-bench verified 第一位（53%）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基於代碼大模型的自身進化，以及 RAG 技術、智能體的有力支持，從而 LLM 有更好的上下文感知能力。例如，在代碼大模型預訓練時，其訓練語料中加入抽象語法樹（AST）、代碼依賴關係等數據，新的代碼生成模型則具有更強的上下文感知能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基礎上，基於 AI 的編程工具能夠根據給定的上下文（如函數名、註釋、部分代碼等）檢索出最相關的代碼片段和文檔，能夠提供完整的函數或代碼塊建議。這也使得 LLM 能夠參考海量的代碼庫和技術文檔，這不僅能緩解大模型的幻覺問題，顯著提升代碼生成與理解的準確性，而且能符合上下文的代碼，更能滿足開發的業務需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未來，研發人員和多個智能體、工具協同工作來完成編程工作，如論文 Flows:Building Blocks of Reasoning and Collaborating AI 所描述的（圖 2 所示），構成一個複合競爭性編碼流程，研發人員更多是提需求，由 LLM 和智能體實現自主編程的過程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;546&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-243a86d5adf6ad21f5d418b5511f81f0f05.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;圖 2 由 LLM 和智能體實現自主編程的過程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着大模型技術的迅速發展，在今年，我們明顯能感到，AI 已從單一的輔助工具，逐漸演變為軟件開發人員不可或缺的助手或夥伴。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了前面已介紹的 Cursor、Composio SWE-Kit、OpenHands CodeAct 等工具之外，國內主要使用 chatGPT、GitHub copilot、通義靈碼、CodeGeeX、文心快碼、螞蟻 CodeFuse 等編程工具，國外還出現一些受歡迎的、新的編程工具，如 Codeium IDE Cascade、Solver ai、Websim ai 等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;493&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4bc35246b3a57ea83c92f455823fb59b03.png&quot; width=&quot;796&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖 3 國內編程助手使用狀況（來源同圖 1）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這些工具讓我們能感受到 AI 卓越的生成能力和理解能力，幫助我們更高效地完成代碼生成、代碼評審、代碼解釋到單測生成、缺陷定位、代碼優化等任務。這種進步也體現在今年國內企業一些落地實踐中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一些大廠，LLM 已經實際應用到代碼審查或 CI/CD 流程中（如 pull request），自動識別代碼質量問題並提出改進建議。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些企業結合智能體和相關工具的支持，讓基於 LLM 的研發平台生成代碼流程圖和類圖，輔助自然語言解釋，使得開發者更直觀地理解代碼結構和執行流程，增強智能編程的可視性和交互性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些開發團隊藉助智能體和 RAG 技術檢索歷史上已知的代碼缺陷模式和已知問題，從而比較準確地識別潛在的缺陷和安全漏洞，甚至能夠分析代碼的功能意圖，全面提升代碼評審的能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些團隊，根據 UI 設計圖，讓 LLM 自動生成相應的前端代碼，大大減少了手動編碼的時間，加快了從設計到實現的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從應用效果看，前面調研的數據可供參考。在國內 AI 編程開展比較好的大廠，超過 80% 的工程師在使用 AI 編程工具完成日常的編程工作，近 30% 入庫的代碼由 AI 生成，生成代碼平均採納率超過 40%，有些產品線達到 60%。僅僅在編程這一項工作（雖然只佔開發人員 20-30% 的工作量）上，研發效率能提升 20-30%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;850&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-33b0554523cedb9d91ec30064a650d426eb.png&quot; width=&quot;1292&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;圖 4 大模型時代的軟件研發正確方式&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然，我們不能侷限於這一個編程環境，最好要從需求開始就應用大模型。ATDD（驗收測試驅動開發）是大模型時代軟件研發的正確打開方式，讓大模型幫我們生成需求及其驗收標準，業務約束更明確了，上下文更清楚了，在此基礎上分別由不同的模型生成產品代碼和測試代碼，再讓它們之間相互驗證和博弈（如圖 4 所示），最終交付高質量的軟件。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未來，隨着 AI 技術的不斷成熟和創新，AI 編程工具將進一步提升智能化和可解釋性，支持更多的編程語言和平台，並通過強化學習實現自適應優化。為了全面發揮 AI 編程技術的潛力，開發團隊需要不斷學習和適應新技術，優化開發流程，確保 AI 工具的有效應用和高質量輸出。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者簡介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ee7692932d7b07e9b2a9ffb1562965629.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同濟大學特聘教授、CCF 傑出會員、CCF TF 軟件質量工程 SIG 主席、CCF2023 傑出演講者、軟件綠色聯盟標準評測組組長、QECon 大會和 AiDD 峯會發起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近三十年來一直從事軟件工程的教學與研究工作，先後獲得多項省、部級科技進步獎，已出版了二十多部著作和 4 本譯作。曾任思科（中國）軟件有限公司 QA 高級總監、IEEE ICST 2019 工業論壇主席、IEEE ICST、QRS 等程序委員、《軟件學報》和《計算機學報》審稿人等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338002</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338002</guid>
            <pubDate>Wed, 05 Mar 2025 09:25:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>大模型撞上 「算力牆」後，超級應用的探尋之路</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 傅聰&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，大模型教父 Sam Altman 在 Reddit 上的評論透露出 GPT-5 難產的隱憂，直言有限的算力約束讓 OpenAI 面臨迭代優先級的艱難抉擇，在通往 AGI 的道路上一路高歌猛進的領頭羊似乎撞上了 「算力牆」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此之外，能耗、資金，難以根除的幻覺，有限的知識更新速率、有限的上下文寬度、高昂的運營成本等等，都讓外界對大模型的發展憂心忡忡。面對棘手的困境與難題，大模型的未來，又該何去何從呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;下一代 「明星產品」&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「算力牆」 下，模型效果邊際收益遞減，訓練和運營成本高昂，在這個時間節點，最好的 AI 產品會是什麼？奧特曼、蓋茨、小扎、吳恩達、李彥宏等一眾大佬給出了一致的答案 —— 智能體（AI Agent）。2025，將會是智能體元年。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;什麼是智能體？目前業界一致認可的公式是 「智能體 = LLM + 記憶 + 規劃 + 工具」：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;591&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b99b6eda5484ca023d6608da04fb0d98f2.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型充當智能體的 「大腦」，負責對任務進行理解、拆解、規劃，並調用相應工具以完成任務。同時，通過記憶模塊，它還能為用戶提供個性化的服務。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體為什麼是 「算力牆」 前 AI 產品的最優解決方案？這一問題的底層邏輯包含兩個方面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;LLM 是目前已知最好的智能體底層技術。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能體作為學術術語由來已久，從上世紀的 「符號、專家系統」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，到十年前風頭無兩的強化學習（代表作 AlphaGo&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【3】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;），再到現在的 LLM，agent 底層技術經歷了三個大的階段。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;符號系統的缺點在於過於依賴人工定義的 「符號」 和 「邏輯」，強化學習苦於訓練數據的匱乏和 「模態牆」，而 LLM 一次性解決這些問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;人類語言就是一種高度抽象、跨模態、表達力充分的符號系統，同時它作為知識的載體，自然地存在大量數據可用於訓練，還蘊含了人類的思維模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基礎上訓練得到的 LLM，自然具備被誘導出類人思考的潛力。在 COT（思維鏈）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【4】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;、TOT（思維樹）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【5】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;等技術的加持下，大模型正在學習拆解自己的 「思維」，OpenAI 的 o1 就是典型案例，強化了推理能力的同時，也大大緩解了幻覺問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2. 大模型做不到的，「現存工具」 強勢補位。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;無法持續更新的知識庫，可以通過 RAG（Retrieval Augmented Generation，檢索增強生成）來解決。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的出現，讓各界越來越深刻地認識到，大模型沒必要存儲那麼多知識，只需要如何使用搜索引擎這個外部工具即可。大模型可以在搜索結果上做進一步的信息篩選和優化，而搜索引擎彌補了大模型的知識缺陷，實現了 1+1&amp;gt;=2 的效果。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 可以被理解為智能體的最簡單形式。未來的智能體可以實現多種工具的混合使用，甚至多智能體協作，這不是猜想，我們已經在學術界看到了驚豔的早期方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【6，7】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;「四把鑰匙」 解鎖潛力&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;領域模型小型化、平台化會成為新趨勢。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「算力牆」 是一方面因素，但基座模型的趨同化和運營成本是源動力。GPT、Claude、Gemini 雖然各有所長，但實際體驗越來越讓大家分不出差異，基座模型作為智能體核心，決定了智能體效果下限，人人訓練基座的可能性越來越低，「基座服務化」 很可能是最合理的商業模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;甚至，在錯誤不敏感的應用領域，出現一個開源、無商業限制的基座的可能性也很高。小應用開發商很可能很容易獲得一個低成本 serving 的 「量化小基座」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「7B」 是一個 magic number！無論是 RAG 裏的向量表徵模型，還是文生圖、文本識別（OCR）、語音合成（TTS）、人臉識別等等垂直領域，一個 1B~7B 的小模型已經可以滿足很多生產、應用需要，並且效果也在逐步推高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【8，9，10】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。這些模型，作為智能體的 「三頭六臂」，不需要太 「大」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同時，從學術角度來講，各種領域專用模型的技術最優解也在逐漸趨同。應用開發者越來越不需要了解模型的底層技術，只需要懂得如何設計自己應用的任務流，懂一點點 COT 系列的 prompt engineering 的技巧，就可以利用 Maas（Model as a service）、Aaas（Agent as a service）這樣的平台，如玩樂高一般搭建自己的 AI 雲原生應用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2. 算力層深挖定製化、低能耗的可能性，但固化 transformer 可能不是最優解&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;雖説智能體不需要太大的模型，但其運營成本（模型推理計算成本）仍然較高。在短時間內，算力、能源仍然會是大模型領域令人頭疼的高牆。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根據報告&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，能源消耗將會是 2030 模型 scaling 最卡脖子的因素。也就是説，在算力到達瓶頸之前，首先可能會出現電能供應不足甚至交不起電費的問題。因此，算力層可以根據大模型底層技術的特性，產出針對性的芯片，尤其是加速運算和降低能耗。這是未來 AI 芯片領域的最優競爭力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那麼，把 transformer 「焊死」 到板子上就是最佳方案嗎？我知道你很急，但你先別急。大模型底層框架還存在底層路線之爭。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們知道，Transformer 架構呈現了 O (n²) 的理論計算複雜度，這裏的 n 指的是大模型輸入序列的 token 數量，但其前任語言模型擔當 RNN 只有 O (n) 的理論計算複雜度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最近，以 Mamba、RWKV 為代表的類 RNN 結構死灰復燃，公開挑戰 transformer 地位。更有最新研究&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【13】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從理論上表明，RNN 對比 Transformer 的表達力，只差一個 in-context-retrieval。在這個方向的持續投入下，我們很可能會迎接一個介於 RNN 和 Transformer 之間的 「新王」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;612&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a0b844154fb7c7c6c5785d19d82ed9d97c5.png&quot; width=&quot;1268&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因此，算力層短時間內的主題仍然是 「半通用化」「高算力」「低能耗」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;3. 合成數據驅動新產業鏈&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;早有機構預測，人類社會可利用訓練數據會在 2026 年耗盡。這可能還是一個樂觀估計。光頭哥 Tibor Blaho 還曾爆料，OpenAI 用於訓練 「獵戶座 「的數據中，已經包含了由 GPT-4 和 O1 產出的合成數據。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這不僅是因為自然存在的高質量文本的匱乏，還因為智能體所需的數據很可能需要顯式地蘊含任務思考和規劃的拆解信息。然而，針對合成數據的問題，學術界早有預警，模型可能會在合成數據上的持續訓練中崩壞&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【14】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;409&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-abc80e1aa8efa6b89d26339a5ffb8f84c7f.png&quot; width=&quot;1106&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這是因為合成數據往往攜帶 「錯誤」 和 「幻覺」，在一些冷門的知識上尤甚。因此，合成數據的實用祕訣是 「去粗取精」，需要一定程度的 「人機協同」。在如何構造大批量、高質量的合成數據，讓智能體能夠在持續地與用戶的交互中自我優化而不是劣化，將會成為眾多無機器學習技術背景的開發者的頭號難題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因此，面向數據進行定製化合成、評估、測試、標註、人機協同的 「純數據」 產業，有可能會走上越來越重要的位置，不僅僅是服務於基座模型廠商。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;4. 多模態對齊很可能給基座模型帶來質的提升&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最新研究發現，在沒有預先約束和約定下，不同模態領域的最強模型正在向着某個世界模型認知領域收縮【15】，AI 模型對不同概念的數字化表達（向量表徵）會逐步趨同，構建對這個世界的統一認知。這也符合我們人類對世界的認知：人類通過語言文字這種符號，將不同模態的信號統一地表達，並在腦中構建了某種受限於當前科技水平的統一模型，這是人類意識、社會溝通的前提。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;640&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2b649a1a09a15cf7b884e20d56d53e2351c.png&quot; width=&quot;553&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從這個角度理解，多模態大模型很可能是通向真正 AGI 的必經之路。將多模態信號統一對齊，是智能體與這個世界 「無障礙」 交互的前提，換個新潮的詞彙，就是我們期待的 「具身智能」。誰不想擁有一台自己專屬的 「Javis」 呢？而多模態大模型的突破，也同樣依賴前文所述的算力和數據上的沉澱。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;參考文獻&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】https://epoch.ai/blog/can-ai-scaling-continue-through-2030&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【2】Newell, A., &amp;amp; Simon, H. A. (1956). The Logic Theory Machine – A Complex Information Processing System. IRE Transactions on Information Theory, 2(3), 61-79.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【3】Silver, David, et al. &quot;Mastering the game of Go with deep neural networks and tree search.&quot; nature 529.7587 (2016): 484-489.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【4】 Wei, Jason, et al. &quot;Chain-of-thought prompting elicits reasoning in large language models.&quot; Advances in neural information processing systems 35 (2022): 24824-24837.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【5】Yao, Shunyu, et al. &quot;Tree of thoughts: Deliberate problem solving with large language models.&quot; Advances in Neural Information Processing Systems 36 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【6】Karpas, Ehud, et al. &quot;MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.&quot; arXiv preprint arXiv:2205.00445 (2022).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【7】Schick, Timo, et al. &quot;Toolformer: Language models can teach themselves to use tools.&quot; Advances in Neural Information Processing Systems 36 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【8】https://huggingface.co/spaces/mteb/leaderboard&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【9】https://github.com/deep-floyd/IF&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【10】https://developer.nvidia.com/blog/pushing-the-boundaries-of-speech-recognition-with-nemo-parakeet-asr-&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;models/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【11】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.00752&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Mamba: Linear-time sequence modeling with selective state spaces&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【12】Peng, Bo, et al. &quot;Rwkv: Reinventing rnns for the transformer era.&quot; arXiv preprint arXiv:2305.13048 (2023).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【13】Wen, Kaiyue, Xingyu Dang, and Kaifeng Lyu. &quot;Rnns are not transformers (yet): The key bottleneck on in-context retrieval.&quot; arXiv preprint arXiv:2402.18510 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【14】AI Models Collapse When Trained on Recursively Generated Data’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【15】The Platonic Representation Hypothesis&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者簡介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-801234c121b48f695ff62c699b6340119e6.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;傅聰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;浙江大學計算機博士，美國南加州大學訪問學者，《業務驅動的推薦系統：方法與實踐》作者。高性能檢索算法 NSG、SSG 的發明者，知乎科技博主 「傅聰 Cong」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;前阿里巴巴算法專家，目前就職於 Shopee（新加坡）任資深算法專家。在頂會和期刊 TPAMI、KDD、VLDB、IJCAI、EMNLP、CIKM 等發表十餘篇論文，同時也是 Tpami、TKDE、KDD、ICLR、AAAI、IJCAI、EMNLP、ICLR 等會議的審稿人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337999</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337999</guid>
            <pubDate>Wed, 05 Mar 2025 09:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源大模型未必更先進，但會更長久</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;文 / 顧鈞&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「開源」 是指採用符合 OSI 官方認可的軟件許可證進行軟件發佈的行為。目前大模型的 「開源」 與傳統的開源定義並不相同。我所説的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源策略&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是指以開源發佈軟件為起點，用戶 / 開發者運營為途徑的軟件產品推廣策略。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;450&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ce9ab25299ac92c8a92d48aab3b9721223.png&quot; width=&quot;1125&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;我的觀點是，開源策略是大模型最好的競爭策略。&lt;/strong&gt;接下來讓我們從頭捋一捋推導過程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們先看大模型賽道的整體狀況：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型是一項相對較新的技術。儘管 OpenAI 早在 2019 年就發佈了第一個重要的模型 GPT-2，但大模型的廣受關注實際始於 2022 年 11 月發佈的 ChatGPT。8 個月以後 Meta 就與微軟合作發佈了開源大模型 LLaMA-2。這個賽道的主要玩家在技術和商業化上有差距，但沒有到翻盤無望的程度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型賽道不但包括模型的訓練，也包括模型服務。訓練是軟件的製作成本，而服務是軟件的長期運行成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型賽道的市場化程度非常高。算法、算力、數據、人才，這些構建大模型的基礎要素並不為權力機構壟斷，大多要從市場上獲得。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型作為一項令人激動的技術，商業化場景覆蓋了對企業 (2B) 與對個人 (2C) 兩個大方向。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型賽道在海外是 「一超多強」，在國內則是 「多頭並舉」，兩種典型的競爭格局都全了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以上，大模型賽道的元素非常豐富，各種商業化方法的排列組合都不缺，為我們的分析與推演提供了可貴的素材。對軟件商業化問題感興趣的朋友一定要長期關注這個賽道。只有這樣的對象才能更有力地説明開源策略的重要性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其次，我們得明確一點 ——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 大模型競爭的賽點是什麼？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;常用的判斷依據包括：技術的先進性，C 端用戶基數，依賴這個軟件的生態系統大小等等。其中哪個更關鍵一點？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技術先進是好事，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但大模型領域的先進技術遠沒有達到能為大模型企業帶來可觀收入的程度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。整個大模型賽道還處在商業化的摸索階段。這個時間點上的 「技術先進性」 更多是用於公關宣傳的素材。考慮到數據獲取、加工的成本，模型訓練的成本，這是一種相當昂貴的宣傳方式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;C 端用戶指那些把大模型當成智能個人助理來使用的普通個人用戶。OpenAI 在 ChatGPT 上一個重要且成功的操作就是把大模型從學術界、工業界直接推向了普通個體，讓 C 端用戶切實感受到了大模型的可能性與魅力。這一點被國內的大模型廠商廣泛學習。在 B 站刷視頻，國內知名的那幾個大模型廠商的廣告，你一個也不會落下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;受到大家的認可與喜愛固然重要，但&lt;strong&gt;對於 C 端用戶，有兩個需要時刻牢記的問題：一是&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; C 端用戶是沒有忠誠度的，誰免費就用誰，誰給補貼就用誰；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;二是&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;某一個大模型對 C 端用戶比較難產生獨特的粘性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一個問題的例證太多了，百團大戰、滴滴快的、社區團購、pdd。大模型廠商維繫 C 端流量的成本可能是個無底洞。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二個問題則涉及兩個方面，一是大模型賽道本身的極度內卷，技術上拉不開差距；二是普通用戶的使用隨意性很強，準確性要求也不高，最終各家大模型的基礎能力都足以應付。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一個大模型的生態系統的大小，也就是指有多少開發者在基於這個大模型構建應用。我認為這是一個更靠譜的評價指標，是某個大模型最終能勝出的關鍵所在。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;構建開發者生態通常有兩種做法，一種是提供 API 雲服務，對註冊開發者進行一定的雲資源補貼；另一種是 「開源」 的方法，提供大模型免費下載，免費商用（一定條件下）。&lt;/strong&gt;兩種方法各有支持者。閉源大模型一般會採用第一種方法，其中的代表有 OpenAI、Anthropic 等（為避免麻煩，國內廠商的名字就不提了）。能用第二種方法的，必然是某種程度上的 「開源」 模型，以 Meta 的 Llama 2、Llama 3 模型為首。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;1026&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ffd7efbdae1f135dc2b129c9cf368dce9a3.png&quot; width=&quot;1200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;前段時間李彥宏在 Create 2024 百度 AI 開發者大會上放言 「開源模型會越來越落後」。前文我有提到，此時此刻的技術先進性並不重要。甚至在計算機發展史上，很多領域中笑到最後的產品，並不是技術上最先進的。拋開成本和易用性，空談技術先進性是最常見的錯誤。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那麼具體到大模型領域，閉源與開源，兩種方法孰優孰劣？我的回答是採取什麼方法因人而異，但開源會更有優勢。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型賽道的核心制約條件是成本太高 ——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 訓練成本高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;運行成本高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。如何儘可能降低成本，比對手堅持得更久一些是確保長期成功的必要條件。現在的宏觀環境下，一味靠融資來支撐自己的高成本支出不是長久之計。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;閉源大模型廠商必須維持一定的雲資源，工程師資源來支撐小額的開發者調試需求。投入產出上恐怕是算不過來的。即便閉源廠商願意持續地補貼開發者，他們最終會發現大模型對開發者的粘性也非常有限，沒比在 C 端用戶那邊好到哪裏去。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型這一產品形態實在是太特殊了 —— 大多以自然語言為交互方式。因此大模型 API 雲服務的接口是非常簡單的，高度一致的。在這種情況下，如果開發者構建的大模型應用只是調用大模型的 API，那麼大模型應用與某個具體的大模型之間很難形成強綁定。也就是説，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面對各種大模型雲服務，主動權在開發者這裏。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與之相對，&lt;strong&gt;開源的方法至少可以相當程度地省去為了拓展開發者生態而付出的大模型運行成本。&lt;/strong&gt;開發者免費下載大模型以後，會在自己的計算機資源上進行大模型應用的開發和調試。大模型廠商提供一些技術支持即可。同時因為大模型運行在本地，開發者在構建大模型應用時，為了物理部署上的便利，很可能會在應用與模型之間創造出物理部署上的耦合性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然這種 「開源策略」 不是進攻的方法，而是 「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;先為不可勝，以待敵之可勝&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」。目標是以最小的代價，儘可能多地消耗閉源對手的資源與心氣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e50ab675a71a016a8fd47aba8c9533dacde.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;顧鈞&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;資深開發者社區運營專家，目前擔任杭州映雲科技 (EMQ) 市場 &amp;amp; 開發者社區總監一職。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2004 年，顧鈞從北京大學計算機系本科畢業，其後在工商銀行、IBM、摩根士丹利、華為和 Zilliz 等多家知名企業工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;曾聯合發起全球首個開源向量數據庫項目 Milvu&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;s&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;並&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;幫助 Milvus 社區在兩年間迅速拓展到兩千家企業用戶。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337998</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337998</guid>
            <pubDate>Wed, 05 Mar 2025 09:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 中國開源模型：崛起與變革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / Tiezhen、Adina、Lu Cheng&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中國在開源人工智能模型領域的崛起和變革成為全球矚目的焦點：從學術到產業，從技術到生態，中國通過自主研發和協同創新，逐步完成了從 「追隨者」 到 「引領者」 的轉變。這種轉變不僅是技術實力的體現，更是中國人工智能生態系統快速完善的真實寫照。以下，我們將從崛起與變革兩個維度，探討中國開源模型在這一年取得的重大成就和未來展望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;崛起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;從 「追隨者」 到 「引領者」&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中國學術界和產業界大力推進自主研發，在技術創新和模型能力上實現了顯著飛躍，並在全球範圍內取得了顯著成就。&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen-llm-leaderboard-open-llm-leaderboard.hf.space%2F&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face Open LLM 排行榜&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據顯示，從智譜的 GLM 系列、阿里巴巴的 Qwen 系列到深度求索的 DeepSeek 系列，這些自主研發的模型在國內外各項評測中表現卓越。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;img height=&quot;798&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b88a736bf0e35cc263820fcde150380c6d3.png&quot; width=&quot;1047&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;每個月來自中國主要研究機構和公司的開源模型 / 數據集數量。圖片源自 Hugging Face 中文社區模型社羣：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;https://huggingface.co/spaces/zh-ai-community/zh-model-release-heatmap&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，Qwen 系列憑藉靈活的多尺寸選項，強大的多語言支持以及友好的模型授權功能，贏得了社區開發者的高度評價。DeepSeek 通過引入多頭潛在注意力（Multi-head Latent Attention, MLA）技術，在性能和成本上實現了革命性突破，開創高性價比的 AI 新紀元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智譜的 CogVideoX 系列文生視頻模型，成為全球首批開源的文生視頻模型之一，不僅在技術方面讓中國視頻生成模型列入領先梯隊，強化了中國模型在全球範圍的競爭力，也為國際開源生態的發展產生了積極的影響，為全球開發者提供了更多創新和應用的可能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中國開源模型從最初的質疑中崛起，逐步贏得了廣泛認可。這不僅彰顯了中國開源模型從追隨者到行業引領者的跨越式成長，也為全球人工智能發展注入了新的活力與動力。中國開源模型的成功並非偶然。在政府對人工智能產業的持續支持以及國內人工智能行業對模型研發的鉅額投入下，從基礎算法到行業應用、從算力基礎設施到數據資源整合，中國人工智能生態體系正在迅速完善。這一趨勢表明，未來中國有可能在全球人工智能領域佔據更為核心的地位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;開源生態的繁榮與協作&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着開源模型影響力的提高，中國開源社區的活躍度也明顯提升。無論是企業、研究機構還是個體開發者都更加積極地參與到開源工作中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以阿里巴巴的通義千問 Qwen 為例，據不完全統計，截止 2024 年 9 月，全球已有近 8 萬基於 Qwen 的衍生模型，超越了 Meta 的 Llama。該系列模型已被集成到 Hugging Face Transformers、Hugging Chat 和阿里自家的百鍊平台中，極大促進了全球開發者的交流和協作，形成了國際化開源生態。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;北京智源研究院和上海人工智能實驗室等研究機構，通過與企業和高校合作及開源平台的建設，建立了更完善的協作機制，從而在開源模型 (如 InternLM) 和數據集 (如 Infinity-MM) 領域貢獻了大量有影響力的基礎工作和資源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中國開源社區湧現出眾多高質量的自發研究成果。其中，MAP 團隊推出的全開源模型 Map Neo 引人矚目。該模型在訓練數據、腳本以及模型對齊工作上實現了全面公開，成為國內少有的真正意義上完全開源的項目。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而 InstantX 團隊的 InstantID 則作為中國模型在國際開源社區的 2024 年首秀，一經發布便獲得了廣泛關注，為中國模型在全球開源生態中贏得了更多認可。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;平衡發展與合規創新&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中國在推動人工智能技術發展的同時，也在監管層面努力建立了完善、透明的治理機制。這種監管創新為開源模型的發展提供了穩定的政策環境，同時確保技術應用符合社會價值導向。比如 《人工智能示範法 2.0（專家建議稿）》對於免費且已開源方式提供人工智能研發的個人和組織給予減輕或免承擔法律責任；《生成式人工智能服務管理暫行辦法》 則明確了人工智能技術的使用和合規要求，促進了開源模型在合規框架下良性發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;變革&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;端上模型的興起與隱私保護&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着小型模型的性能逐步增強，更多高級 AI 正轉向在個人設備上運行。這一趨勢不僅顯著降低了雲端推理成本，還提升了用戶隱私控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中國 AI 社區在這一領域也做了重要貢獻，推出瞭如 Qwen2-1.5B、MiniCPM 系列和 DeepSeek Janus 等多款移動友好型模型。其中，最新發布的 GLM Edge 1.5B 模型通過與高通 GenAI 擴展的聯合優化，在搭載驍龍 8 Gen 4 處理器的手機上實現了每秒 65 個 tokens 的推理速度，接近人類語音的平均輸出速率。儘管存在電池續航和內存佔用過大等挑戰，端上模型代表了 AI 技術隱私保護和成本優化的未來方向。中國在這一領域的探索，為行業提供了寶貴經驗。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;推理擴展法則的潛力釋放&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通過推理擴展法則，模型性能可通過延長 「思考時間」 而進一步優化。這一技術模擬了人類 「深思熟慮」 的過程，顯著提升了模型在邏輯推理和複雜任務中的表現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中國開源社區在邏輯推理領域推出了許多創新項目，包括阿里巴巴國際的 Macro-o1、通義千問團隊的 QwQ、上海人工智能實驗室的 LLaMA-O1 和清華大學的 Llama-3.2V-11B-cot。這些模型不僅在技術上各具特色，還通過開源策略分享了大量研究細節，為整個開源社區提供了豐富的資源，在這一過程中，小模型不僅在推理能力上有了顯著提升，也推動了行業整體技術水平的進步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;結合當前人工智能產業界的 「人工智能 +」 計劃，小模型在特定任務優化上的優勢愈發突出，預計將在金融、醫療和工業自動化等熱門領域發揮引領作用，以更高效、更精準的方式滿足多樣化需求，幫助人工智能在實際應用場景中落地。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;開源多元化與應用細分&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中國開源模型的發展不僅體現在技術突破上，還在生態建設中展現出巨大的活力。中國開源模型從競爭激烈的 「百模大戰」 逐步邁向多元化和深度細分，國內社區在今年發佈了大量高質量開源模型，尤其是多模態理解與生成模型：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fmllms-664b68f4217010520d1987c2&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模態理解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：Qwen2-VL、Ovis、InternVL2、DeepSeek JanusFlow、GOT-OCR2_0；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fimage-models-66b0c329ddeea53c140fd84c&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;圖片生成&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：PixArt、Lumina、Kolors、Hunyuan-DiT、VAR、Meissonic；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fvideo-models-666afd86cfa4e4dd1473b64c&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;視頻生成&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：AnimateDiff-lightning、Latte、OpenSora、open-sora-plan、Pyramid Flow、CogVideoX；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Faudio-models-666983e79d56215237e411ae&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;TTS&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：GPT-SoVITS、ChatTTS、CosyVoice、FishAudio、MaskGCT、F5-TTS 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這一趨勢表明，模型的競爭已經從單純的規模比拼轉向應用場景細化。為了更好地展現這一演進路徑，我們在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fzh-ai-community&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face 的中文模型社羣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中對各個領域的開源模型進行了系統整理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;strong&gt;展望&lt;/strong&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中國開源模型的發展展現了技術、生態和社會價值之間的深度協同。無論是從技術創新到社區建設，還是從行業實踐到合規探索，中國開源生態體系的完善正在為全球人工智能發展注入源源不斷的動力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 Hugging Face，我們堅信開源是推動人工智能技術進步和生態繁榮的核心力量。開源不僅能夠打破技術壁壘，促進全球開發者之間的協作與創新，還能推動技術的普惠化，讓更多的人能夠平等地享受人工智能帶來的便利與機遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在未來，中國開源模型有望繼續為全人類的智能化生活提供更豐富的解決方案與可能性。我們希望看到更多來自中國的開源 AI 團隊通過開放協作推動技術邊界的不斷拓展，共同構建一個更加包容、多元與可持續發展的人工智能的未來。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a5d60686c70430cd3f50d5ce0af17621950.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tiezhen&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;現任 Hugging Face 工程師，曾在 Google Brain 任職。兼具實幹精神與夢想追求，堅信開源是連接全球的紐帶，讓 AI 的益處普惠大眾。他秉持 &quot;高手在民間&quot; 的理念，渴望激勵更多的開源模型從業者成為行業的關鍵意見領袖，挖掘羣體的智慧與潛能，促進社區的成長和影響力的擴大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;img height=&quot;204&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-77ccf0b11126b7efa913c41d44363e4d8d2.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Adina&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face 中文社區項目經理。擁有 10 年以上國際化工作經驗，足跡遍及亞洲、非洲和歐洲。從社會科學研究員到科技公司項目專員，積累了豐富的跨領域與跨文化經驗。專注推動人工智能在中文開源社區的應用與發展，為開發者和企業帶來更多價值，助力知識共享與技術協作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4750483e084a8931724469418cd70e68a6e.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Lu Cheng&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face Fellow，致力於推動 AI 和開源軟件的採納和開發者體驗。擁有超過十年的開發者關係、產品營銷和開源生態構建的經驗，曾在 Google 負責多個開發技術的深度推廣和社區建設，包括 Android、Flutter 和 TensorFlow 等。他堅信開源是推動技術進步和開發者成長的關鍵步驟，希望有更多人蔘與開源和社區共建。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337996</guid>
            <pubDate>Wed, 05 Mar 2025 09:18:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AI 編程神器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-07%2Fai-startup-anysphere-in-talks-for-close-to-10-billion-valuation&quot; target=&quot;_blank&quot;&gt;據彭博社報道&lt;/a&gt;&lt;/u&gt;，Cursor 母公司 Anysphere 正在與投資者洽談新一輪融資，估值可能高達 100 億美元。這一數字是其三個月前估值的四倍（2024 年 12 月估值為 25 億美元）。若融資成功，Cursor 將成為繼 OpenAI、Anthropic 之後，AI 應用層又一家「百億美元獨角獸」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0310/170903_Rt06_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anysphere（Cursor 的母公司）並不開發自己的生成式 AI 模型，而是依賴 Anthropic 和 OpenAI 的模型來驅動 Cursor。儘管如此，Cursor 憑藉其易用性、速度以及對用戶代碼庫的深入理解，贏得了開發者的廣泛好評。&lt;/p&gt; 
&lt;p&gt;《The Information》報道指出，包括卡片初創公司 Ramp 和 AI 搜索引擎 Perplexity 在內的眾多公司，都在使用 Cursor 來提升開發效率。&lt;/p&gt; 
&lt;p&gt;Cursor 提供免費、20 美元/月和 40 美元/月三種訂閲模式，相較於競爭對手 Devin 每月 500 美元的定價，Cursor 在價格上具有明顯優勢。&lt;/p&gt; 
&lt;p&gt;《The Information》指出，Cursor 的收入增速已經超過了上一代軟件初創公司。以 100 億美元估值計算，Cursor 的市銷率（估值/年化經常性收入）約為 66 倍。&lt;/p&gt; 
&lt;p&gt;Cursor 的快速發展，也加劇了 AI 編程助手市場的競爭。OpenAI 和 Anthropic 都在積極推出自己的代碼編輯工具。&lt;/p&gt; 
&lt;p&gt;《The Information》報道稱，Cursor 最初使用 OpenAI 的模型，但在 7 月將默認模型更改為 Anthropic。&lt;/p&gt; 
&lt;p&gt;幾個月後，OpenAI 在 ChatGPT 中推出了名為 Canvas 的代碼編輯工具。上週，Anthropic 也推出了自己的代碼編輯器 Claude Code。此外，OpenAI 還在開發一款更高級的編碼助手產品，旨在複製高級軟件工程師的工作。&lt;/p&gt; 
&lt;p&gt;除了 OpenAI 和 Anthropic，其他初創公司也在積極佈局。上個月，Kleiner Perkins 領投了 Codeium，估值接近 30 億美元。Codeium 與 Cursor 類似，也在幾個月前以 12.5 億美元的估值融資 1.5 億美元。Poolside 也在開發編碼助手應用和模型，儘管去年收入不足 1000 萬美元，但該公司可能在未來的融資中尋求 50 億美元的估值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336236&quot; target=&quot;news&quot;&gt;使用 Cursor 編程的 15 條經驗建議&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328600&quot; target=&quot;news&quot;&gt;Cursor 的開源替代來了：Roo-Cline&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/320498/anysphere-acquires-supermaven&quot; target=&quot;news&quot;&gt;Cursor 母公司 Anysphere 收購 AI 編碼助手 Supermaven&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337993/anysphere-in-talks-for-close-to-10-billion-valuation</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337993/anysphere-in-talks-for-close-to-10-billion-valuation</guid>
            <pubDate>Wed, 05 Mar 2025 09:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>麥當勞餐廳引入 AI 技術，緩解員工日常工作壓力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techspot.com%2Fnews%2F107065-mcdonald-turns-ai-boost-order-accuracy-stay-ahead.html&quot; target=&quot;_blank&quot;&gt;據 TechSpot 報道&lt;/a&gt;&lt;/u&gt;，麥當勞正藉助 AI 技術提升全球 4.3 萬家餐廳的運營效率，緩解員工的日常工作壓力。&lt;/p&gt; 
&lt;p&gt;據悉麥當勞將首先從與互聯網連接的廚房設備、人工智能駕駛式餐廳和為經理提供的人工智能工具開始進行 AI 改造。&lt;/p&gt; 
&lt;p&gt;新技術提供了許多可能性。例如，計算機視覺可以在訂單傳遞給顧客之前，使用廚房中的固定攝像頭檢查準確性。像麥當勞去年與 IBM 測試的那種自動點餐 AI，可以簡化「汽車餐廳」訂單。安裝在廚房設備上的傳感器可以實時收集數據，並據此更好地預測油炸鍋或冰淇淋機何時最有可能出現故障。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-141dbbc1d525b54b58e81dea0e262c47926.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;麥當勞首席信息官 Brian Rice 表示，麥當勞的目標是「為顧客和員工帶來更好的體驗，他們如今要應對從機器故障到下錯訂單等各種問題」。&lt;/p&gt; 
&lt;p&gt;據報道，麥當勞在 2023 年末選擇了谷歌雲，為其每家餐廳提供更強大的計算能力，使其能夠在現場處理和分析數據。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337989/mcdonald-turns-ai-boost-order-accuracy-stay-ahead</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337989/mcdonald-turns-ai-boost-order-accuracy-stay-ahead</guid>
            <pubDate>Wed, 05 Mar 2025 08:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>superfile —— 美觀現代的終端文件管理器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;superfile 是一款功能強大的現代終端文件管理器，它能完成你所需的文件操作。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;275&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/163509_5ESm_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;275&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/163630_bjwN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;精緻美觀的用戶界面&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;可以説好看才是 superfile 的初衷，所以整個 superfile 要儘量的好看。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;功能齊全&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;這個文件管理器允許你在文件管理器上執行幾乎所有你想做的事情。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;完全可定製&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;從基本的熱鍵開始，整個主題顏色甚至邊框樣式都可以自定義。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多面板&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;多面板允許你同時查看多個目錄，只需幾個簡單的步驟即可進行復制和粘貼，而無需返回主目錄。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/superfile</link>
            <guid isPermaLink="false">https://www.oschina.net/p/superfile</guid>
            <pubDate>Wed, 05 Mar 2025 08:38:00 GMT</pubDate>
        </item>
        <item>
            <title>羅永浩：細紅線科技 2025 年春季招聘啓動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 10 日，羅永浩在微博&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7762107285%2FPhRUQkj7D&quot; target=&quot;_blank&quot;&gt;發文表示&lt;/a&gt;&lt;/u&gt;，細紅線科技 2025 年春季招聘已經啓動，相關崗位如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;資深軟件產品經理（5 名）&lt;/li&gt; 
 &lt;li&gt;AI 方向軟件產品經理（5 名）&lt;/li&gt; 
 &lt;li&gt;IM 方向軟件產品經理（2 名）&lt;/li&gt; 
 &lt;li&gt;BI 數據產品經理（2 名）&lt;/li&gt; 
 &lt;li&gt;商業化產品經理（2 名）&lt;/li&gt; 
 &lt;li&gt;軟件產品實習生（8 名）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1152&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/154800_c89p_2720166.png&quot; width=&quot;1232&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;羅永浩並未在 JD 中透露各崗位的薪資待遇，部分崗位的職責如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/155313_5yVn_2720166.png&quot; width=&quot;854&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336990&quot; target=&quot;news&quot;&gt;羅永浩從小米挖來操作系統「老兵」，為打造「AIOS」招兵買馬&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328454&quot; target=&quot;news&quot;&gt;羅永浩 AI 初創項目 J1 Assistant 海外官網上線&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/326288&quot; target=&quot;news&quot;&gt;羅永浩「最後一次創業」最新進展：密集招聘大模型人才，或開發 AI 硬件&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337973</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337973</guid>
            <pubDate>Wed, 05 Mar 2025 07:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>抖音：少數賬號以 AI 類工具為噱頭實施詐騙等行為</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;抖音安全中心 3 月 10 日發佈關於打擊「非法薦股」等違法證券活動的公告（二）稱，近日，平台發現，有少數賬號在無相關資質情況下，聲稱可藉助各種 AI 類工具，實現所謂「高回報高收益」，或以「推薦高效 AI 選股工具」「售賣 AI 炒股課程」為噱頭引發用戶關注，甚至對其實施詐騙等行為。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例一：賬號「首*財經」「小*財富空間」等在無相關資質的情況下發布視頻，聲稱藉助某款 AI 類工具，對某隻或某幾隻具體股票的未來走勢進行「精準」分析預判，發佈帶有誘導投資傾向的具體投資話術，如「用**（某 AI 類工具）分析，某隻股票短期內有較高上升潛力，止盈和止損價格可分別設定為‘**元’和‘**元’」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例二：賬號「小**博弈」「小**飽」等在無相關資質的情況下發布視頻，聲稱藉助某款 AI 類工具可實現「高收益」「高回報」，如「炒股 4 個月賺 230 萬，AI 真的太香了」「你敢相信麼，**（某 AI 類工具）可以幫你抓大妖股」「用**（某 AI 類工具），12 天（盈利）32%」「用**（某 AI 類工具）實在太強大了，居然全部獲利，而且全部賣飛了」等。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例三：賬號「愛股*隊」「愛股*女」等在無相關資質的情況下，以「炒股神器」「時代機遇」「炒股機遇最大化」為噱頭，宣傳、推廣或兜售某幾款 AI 類工具的培訓課程（具體形式包括訓練營、培訓班、教學資料等）。個別賬號還試圖通過暱稱、頭像、簽名、評論等渠道，發佈引流信息，誘導用戶脫離抖音後前往第三方平台，甚至對其實施詐騙等違法行為。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上述言行，嚴重違反了平台規則，平台對相關賬號和視頻進行了嚴格處置，具體處置方式包括但不限於封禁賬號、下架視頻、收回直播和營利權限、抹除賬號不當獲取粉絲，以及清退違規賬號所屬 MCN 機構等。情節嚴重者，平台將向公安機關報案。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337969</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337969</guid>
            <pubDate>Wed, 05 Mar 2025 07:48:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Hugging Face 首席科學官擔心 AI 正在變成「服務器上的應聲蟲」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;Hugging Face 聯合創始人兼首席科學官 Thomas Wolf &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FThom_Wolf%2Fstatus%2F1897630495527104932&quot; target=&quot;_blank&quot;&gt;最近發文稱&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;如果人工智能研究沒有實質性突破，AI 可能僅會成為「服務器上的應聲蟲」，而非真正的創新者。&lt;/strong&gt;他進一步解釋説，當前的人工智能開發範式無法產生能夠進行創造性問題解決的 AI，而這種問題解決能力能夠贏得諾貝爾獎。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f91c400aa9a6f13136086d41d35dc3afb13.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Wolf 認為，當前的 AI 發展路徑難以產生能夠進行創造性思考和突破性解決方案的系統。他指出，現有的 AI 模型更像是「非常聽話的學生」，擅長填補已知知識之間的空白，但缺乏質疑現有認知框架和提出全新問題的能力。&lt;/p&gt; 
&lt;p style=&quot;color:#3a3a3a; margin-left:0; margin-right:0; text-align:justify&quot;&gt;沃爾夫在文章中寫道，「要在數據中心創造愛因斯坦，我們不僅需要一個知道所有答案的系統，而且還需要一個能夠提出別人從未想過或不敢問的問題的系統。」沃爾夫將這一問題部分歸因於 AI 領域的「評估危機」。他指出，目前用於衡量 AI 系統進步的基準測試大多集中在有明確、封閉式答案的問題上，這限制了系統發展出質疑和創新能力的可能性。&lt;/p&gt; 
&lt;p style=&quot;color:#3a3a3a; margin-left:0; margin-right:0; text-align:justify&quot;&gt;作為解決方案，他建議行業應當發展新的評估標準，能夠測量 AI 是否能採取「大膽的反事實方法」，並基於微小線索提出一般性建議。「科學最重要的方面是提出正確問題和質疑自己所學知識的能力，我們不需要一個能用常識回答所有問題的 A+ 學生，而是需要一個能看到並質疑其他人所錯過的東西的 B 級學生。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337966/ai-is-becoming-yes-men-on-servers</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337966/ai-is-becoming-yes-men-on-servers</guid>
            <pubDate>Wed, 05 Mar 2025 07:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>華為昇騰適配階躍星辰多模態開源模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《科創板日報》消息稱，魔樂社區（Modelers）今日上架由階躍星辰自研的 Step-Video 視頻生成和 Step-Audio 語音模型兩款開源多模態大模型，並基於華為昇騰 CANN 異構計算架構和昇騰服務器，完成了對模型的適配。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;階躍星辰在 2 月 18 日宣佈開源了兩款階躍&amp;nbsp;Step 系列多模態大模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Step-Video-T2V：以 300 億參數量成為&lt;strong&gt;全球最大的開源視頻生成模型&lt;/strong&gt;，可直接生成 204 幀、540P 分辨率的高質量視頻。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Step-Audio：&lt;strong&gt;行業內首款產品級開源語音交互大模型&lt;/strong&gt;，能生成多種情感、方言、語言、唱腔及個性化風格的語音。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;210&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ecd8f648b8dbf862f3be3f5b584f47187b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除魔樂社區外，魔搭社區、模力方舟、HuggingFace、Replicate 平台也已上架。此外，包括天數智芯、阿里雲、火山引擎、金山雲、TCL、LiblibAI、歡瑞世紀等標杆企業均已接入階躍星辰開源生態。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337963</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337963</guid>
            <pubDate>Wed, 05 Mar 2025 07:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>西部數據退出固態硬盤 (SSD) 市場</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techspot.com%2Fnews%2F107039-western-digital-exits-ssd-market-shifts-focus-hard.html&quot; target=&quot;_blank&quot;&gt;據 Techspot 報道&lt;/a&gt;&lt;/u&gt;，西部數據現已正式拆分並剝離 NAND 業務，未來 SSD 產品將以閃迪接手，而西部數據將專注於 HDD（機械硬盤）業務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c0b984ef20d8b4a86e0e4486fb39b21bd0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;西部數據 CEO Irving Tan 表示，&lt;strong&gt;人工智能對存儲需求的快速增長是促使公司做出這一決定的關鍵因素之一，預計 HDD 的出貨量將持續增長&lt;/strong&gt;。同時其表示，從目前的情況來看，西部數據未來的重點將主要放在企業級市場，但不排除仍會推出部分消費級產品。&lt;/p&gt; 
&lt;p&gt;此外，由於閃迪屬於西部數據旗下全資子公司，因此相應的技術依然得以保留。而作為品牌重塑的一部分，未來推出 SSD 基本上都不會以西部數據作為品牌。未來，閃迪可能還與三星等製造商合作，以滿足生產需求。&lt;/p&gt; 
&lt;p&gt;報道還指出，此前西部數據因與鎧俠（Kioxia）的合併談判破裂，於 2023 年宣佈計劃拆分為兩個獨立業務。原計劃在 2024 年下半年完成上述計劃，但由於各種原因，直到近期才正式完成。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337959/western-digital-ssds-are-no-more</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337959/western-digital-ssds-are-no-more</guid>
            <pubDate>Wed, 05 Mar 2025 07:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>植入惡意代碼和「自毀開關」，程序員面臨最高 10 年監禁</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全球智能動力管理公司伊頓公司（Eaton Corp）的一名前員工，因被公司降職後運行自定義惡意軟件並安裝「自毀開關」破壞公司內部計算機系統而被判有罪。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cleveland.com%2Fcourt-justice%2F2025%2F03%2Fformer-eaton-corp-employee-found-guilty-of-sabotaging-companys-computer-systems.html&quot; target=&quot;_blank&quot;&gt;據悉&lt;/a&gt;，當事人 Davis Lu 是一名 55 歲的軟件開發人員，任職期間為 2007 年 11 月至 2019 年 10 月。檢察官稱，在 2018 年公司重組後，Davis Lu 被降職；隨後他就在系統上安裝了自定義惡意軟件和「自毀開關」破壞僱主的計算機系統和網絡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;482&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4a196b264e68f792b3a0746e39e2482462e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這些惡意行為包括運行「無限循環」代碼，耗盡生產服務器的資源，最終導致系統崩潰並阻止用戶登錄。旨在通過反覆生成新線程而不進行適當終止，來耗盡 Java 線程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他將惡意軟件命名為「hakai」，一個意為「破壞」的日語單詞。還刪除了同事的用戶配置文件，並實施了一個「自毀開關」，如果他在公司 Windows 活動目錄中的賬戶被禁用，該開關將鎖定所有用戶。他將這一開關命名為「IsDLEnabledinAD」，檢察官稱這是「Is Davis Lu enabled in Active Directory」的縮寫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2019 年 9 月 9 日，Davis Lu 被解僱時，這個「自毀開關」自動觸發，導致數千名員工無法訪問系統。檢察官稱，被解僱後他刪除了加密數據，並試圖想辦法阻止同事修復惡意軟件引起的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美國司法部表示，互聯網搜索記錄顯示，當事人曾研究過提升權限、隱藏進程和快速刪除文件的方法。他的這一行為給公司造成了數十萬美元的損失。但辯護律師辯稱，此舉給公司造成的損失不到 5,000 美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;陪審團裁定 Davis Lu&lt;/span&gt;&amp;nbsp;&lt;span style=&quot;color:#000000&quot;&gt;故意破壞受保護計算機的罪名成立，這一指控最高可判處 10 年監禁。目前尚未確定宣判日期。Davis Lu 的辯護律師表示將對此案提起上訴。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337957/former-eaton-corp-employee-guilty</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337957/former-eaton-corp-employee-guilty</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>