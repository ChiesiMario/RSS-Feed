<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 16 May 2025 08:03:14 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>前端構建神器 Parcel 大「瘦身」：依賴項削減 25%，安裝體積砍半！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在前端工具鏈百花齊放的今天，知名構建工具 Parcel 帶來了令人振奮的 2.15.0 版本更新。最讓開發者興奮的是：通過將核心功能改用 Rust 重寫，新版本在保持全部功能的同時，node_modules 體積直接砍掉近一半，依賴包數量也減少了四分之一。這對於那些被龐大 node_modules 文件夾困擾的開發者來説無疑是一劑強心針。&lt;/p&gt; 
&lt;h3&gt;擁抱「重型武器」，構建再也不擔心翻車&lt;/h3&gt; 
&lt;p&gt;本次更新最大的亮點是 HTML 處理鏈路的徹底重構。Parcel 團隊放棄了此前使用的 PostHTML 方案。PostHTML 是什麼？簡單來説，它是一個用 JavaScript 編寫的 HTML 處理工具，通過插件機制來完成 HTML 的解析和轉換。雖然 PostHTML 生態豐富，有着大量現成的插件可用，但其解析能力始終無法企及瀏覽器級別。&lt;/p&gt; 
&lt;p&gt;為了徹底解決這個問題，Parcel 團隊轉向了「重型武器」——直接搬來了 Firefox 瀏覽器和 Servo 渲染引擎中的核心組件，用 Rust 語言重新打造了 HTML 處理模塊。這就好比之前用的是「民用工具」，現在換成了「工業級設備」，解析準確性得到了質的飛躍。&lt;/p&gt; 
&lt;p&gt;舉個例子：HTML 規範中關於解析的部分竟然有 100 多頁之厚，裏麪包含了 20 多年來 Web 發展過程中積累的各種特殊情況。普通的解析器很難完美處理這些邊界情況，但瀏覽器級的解析引擎在這方面已經過了無數實戰檢驗。新版本採用 Servo 的 html5ever 解析器，意味着你的 HTML 文件將獲得與 Chrome、Firefox 等主流瀏覽器完全一致的解析結果。&lt;/p&gt; 
&lt;h3&gt;更保守但更聰明的壓縮策略&lt;/h3&gt; 
&lt;p&gt;在代碼壓縮方面，新版本的做法很有意思。與其他動輒追求極致壓縮率的工具不同，Parcel 選擇了更明智的「保守壓縮」策略。比如説，過去很多工具都會激進地刪除 HTML 中的空白字符，但實際上這可能會破壞頁面樣式，因為 CSS 中的&lt;code&gt;white-space: pre&lt;/code&gt;屬性就需要保留這些空白。新版本在這類情況下會謹慎處理，寧可多留一些空白，也不破壞頁面效果。&lt;/p&gt; 
&lt;p&gt;不過，在安全的優化場景下，新版本反而比之前更加智能。它能智能判斷何時可以安全地移除屬性引號、刪除布爾屬性的值，甚至利用 HTML 的容錯機制移除一些可選的閉合標籤。這些優化既保證了頁面完整性，又能帶來一定的體積收益。&lt;/p&gt; 
&lt;h3&gt;SVG 處理也來了次大換血&lt;/h3&gt; 
&lt;p&gt;SVG 處理模塊同樣迎來重大升級。新版本引入了名為 OXVG 的 Rust 工具替代了原有的 SVGO。測試顯示，這一替換帶來了數倍的性能提升。同時，得益於與新 HTML 解析器的無縫配合，現在處理網頁中的內嵌 SVG 圖標也變得更加高效可靠。&lt;/p&gt; 
&lt;p&gt;對於經常和 React 打交道的開發者來説，還有一個好消息：新版本重寫了 SVG 轉 JSX 的功能，直接將 SVG 轉換為 JavaScript 語法樹，省去了中間環節，處理效率得到顯著提升。&lt;/p&gt; 
&lt;h3&gt;新版本值得升級嗎？&lt;/h3&gt; 
&lt;p&gt;答案是肯定的。如果你正在使用 Parcel，升級到 2.15.0 版本將帶來立竿見影的收益：更小的項目體積、更快的安裝速度、更可靠的構建結果。而且，為了照顧現有項目，新版本保留了對 PostHTML 插件和 SVGO 配置的兼容支持，升級過程幾乎不會帶來任何副作用。&lt;/p&gt; 
&lt;p&gt;在當前前端工具鏈百家爭鳴的背景下，Parcel 用這次更新展示了一個頗具前瞻性的發展方向：用更可靠的系統級語言重寫核心功能，同時保持與現有生態的友好共存。這種演進思路值得其他工具借鑑。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350233/parceljs-2-5-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350233/parceljs-2-5-0</guid>
      <pubDate>Fri, 16 May 2025 07:25:06 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>【最後今天】LFOSSA 技能煥新季 85 折限時福利活動即將結束！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="微信圖片_85 折.png" src="https://oscimg.oschina.net/oscnet//23abacdd7a61a2ef402c028b04dfb5a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;Linux Foundation&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;開源軟件&lt;/strong&gt;&lt;strong&gt;學園（LFOSSA） 於 5 月 7 日至 5 月 16 日，推出&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;strong&gt;FOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff"&gt;，&lt;span style="color:#ff0000"&gt;&lt;strong&gt;全場 LF 官方認證考試及課程 &amp;nbsp;&lt;span style="color:#00b050"&gt;85 折&amp;nbsp;&lt;/span&gt;起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffff00; color:#ff0000"&gt;&lt;strong&gt;活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;今&lt;/span&gt;&amp;nbsp;天，機會不容錯過！&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;快速提升你的開源技能，搶跑&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;新時代&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技能煥新季 · LF 認證限時福利詳情&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;活動時間&lt;/strong&gt;：&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;5 月 7 日 - 5 月 16 日&lt;span style="background-color:#ffff00"&gt;（活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天！）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;適用產品：&lt;/strong&gt;&lt;strong&gt;LF&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;官方認證考試及課程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向個人專屬福利：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;部分機構熱門課程低至&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;7&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;折&lt;/span&gt;&lt;/strong&gt;，&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;添加 LFOSSA 官方微信，限時領取&amp;nbsp;&lt;span style="color:#00b050"&gt;認證培訓首節課程免費試聽&amp;nbsp;&lt;/span&gt;資格&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向企業專屬福利（階梯折扣）：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 採購 5-20 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;85&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 採購 21-50 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;3. 採購 50 個以上認證：&lt;/strong&gt;聯繫官方客服，獲取定製專屬方案&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368565314179.png" height="1000" src="https://oscimg.oschina.net/oscnet//dcb6214ff743fa4e8bbe17fc11a9cee5.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;有關&amp;nbsp;&lt;/strong&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;LFOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;，可點擊以下鏈接瞭解詳情：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542784%26idx%3D1%26sn%3D236a3bfdcf36dec0bf41f462cc0c91d8%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;搶跑 AI 時代，煥新開源技能！LFOSSA 技能煥新季 85 折限時福利活動開啓！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542805%26idx%3D1%26sn%3D4af4c9ac39d950df1de31477624b659e%26scene%3D21%23wechat_redirect" target="_blank"&gt;【最後 2 天】LFOSSA 技能煥新季｜企業採購折扣限時福利活動即將截止，抓緊最後機會！&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;聯繫我們&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如需&amp;nbsp;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;體驗&lt;/strong&gt;&lt;strong&gt;認證培訓課程免費試聽首節課&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;，或為&lt;span style="color:#ff0000"&gt;&lt;strong&gt;貴單位定製認證學習路徑以及批量採購方案&lt;/strong&gt;&lt;/span&gt;，歡迎掃碼添加官方客服，我們將為你提供一對一的採購諮詢與支持服務。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="background-color:rgba(255, 246, 122, 0.8); color:#ff0000"&gt;&lt;strong&gt;活動截止時間：2025 年 5 月 16 日（僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;限時折扣，錯過不再，快來鎖定優惠名額！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368673326323.jpeg" height="260" src="https://oscimg.oschina.net/oscnet//86a0e91efbe8dabcc8f184b71cdb50ad.jpeg" width="260" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span style="color:#8f959e"&gt;掃碼添加客服&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368808706235.png" height="311" src="https://oscimg.oschina.net/oscnet//6a2c4a0154fe65c0ed86ca1afc9639a8.png" width="1600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;查看更多 LFOSSA 培訓、認證及套購產品，請訪問以下鏈接：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;培訓：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"&gt;https://training.linuxfoundation.cn/courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;認證：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"&gt;https://training.linuxfoundation.cn/certificates&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;套購：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank"&gt;https://training.linuxfoundation.cn/pack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;立即點擊&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank"&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;這裏&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;進入 LFOSSA 官網，選購官方認證考試及培訓課程產品。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350219</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350219</guid>
      <pubDate>Sun, 11 May 2025 06:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 VS &amp; VS Code 每月活躍開發者數量達到 5000 萬</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fblog%2Fcelebrating-50-million-developers-the-journey-of-visual-studio-and-visual-studio-code" target="_blank"&gt;宣佈了&lt;/a&gt;其 Visual Studio 產品系列的一個重要里程碑：Visual Studio 和 Visual Studio Code 現在每月為超過 5000 萬活躍開發人員提供服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0516/0b34a4bdf1bdfd2.jpg" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51990187483c55d75a61f86af17b234b4ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc7a64f6ab1f22d5860bdce786e8832ef8b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Visual Studio 於 28 年前首次推出，至今仍是領先的集成開發環境 (IDE)，這主要得益於 Windows 生態系統的普及。多年來，它不斷發展，現已支持跨平台開發、雲原生應用程序、遊戲開發、數據科學工作流等。它仍然是少數幾個開箱即用地包含編譯器、調試器、分析器、設計器和語言服務的 IDE 之一。&lt;/p&gt; 
&lt;p&gt;Visual Studio 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Visual Studio Marketplace 上有 25000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;超過 100000 名開發人員貢獻反饋、問題報告和功能創意&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;社區論壇中數十萬個問答&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;每個季度更新平均修復 800 多個社區報告的問題&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;十年前，隨着 Windows 開始被 iOS 和 Android 等移動平台蠶食，微軟在當時推出了 Visual Studio Code，這一舉動令許多人感到意外。與其功能齊全的兄弟版本不同，Visual Studio Code 採用輕量級開源模式。它並非提供所有開箱即用的功能，而是允許開發人員通過龐大的擴展生態系統自定義其開發環境。&lt;/p&gt; 
&lt;p&gt;Visual Studio Code 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 市場中有 100000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 代碼庫已獲得 37000 多個 GitHub 星標&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;來自世界各地的數千名貢獻者&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;微軟開發者部門 CVP 兼產品主管、微軟第一方工程系統總經理 Amanda Silver 就這一里程碑寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在我們慶祝這一里程碑的同時，我們也正站在軟件開發新時代的開端。人工智能編程革命正在從根本上改變我們編寫代碼的方式，而我們僅僅觸及了未來可能性的皮毛。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為了慶祝 5000 萬里程碑，微軟還發布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2F" target="_blank"&gt;Visual Studio 和 Visual Studio Code 的週年紀念特別壁紙&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eaef23439a2406d17ad3b98418b1733e23a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下載地址如下，分別用於桌面、手機與智能手錶：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fdesktop" target="_blank"&gt;https://visualstudiowallpapers.com/desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fphone" target="_blank"&gt;https://visualstudiowallpapers.com/phone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fwatch" target="_blank"&gt;https://visualstudiowallpapers.com/watch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在下週即將舉行的 Build 開發者大會上，微軟預計將發佈這兩款工具的更新，旨在進一步提升開發者體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</guid>
      <pubDate>Sun, 11 May 2025 06:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟將於 8 月 11 日關閉 Bing Search API 服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fbing%2Fapis%2Fbing-web-search-api" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;將於 2025 年 8 月 11 日正式關閉 Bing Search API 服務，屆時所有使用 Bing Search API 的實例將完全停用，同時不再接受新用戶註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135843_cSSP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微軟建議用戶考慮使用 Azure AI Agents 中的「Grounding with Bing Search」作為替代方案，但該替代方案並非完美。&lt;/p&gt; 
&lt;p&gt;「Grounding with Bing Search」可以在生成回應時引用實時公開網絡數據，但開發者和用戶無法直接訪問 Bing 搜索的原始數據內容，這意味着它無法完全替代 Bing Search API 的功能。&lt;/p&gt; 
&lt;p&gt;此次停用決定主要影響 Bing Search F1 及 S1 到 S9 資源的用戶，以及 Custom Search F0 與 S1 到 S4 資源的用戶。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;不過受影響的主要為 Bing Search APIs 的自助式或小型用戶，像 DuckDuckGo 這樣的大型客戶，由於與微軟簽署了直接協議，仍可繼續使用這些 API。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟在 ChatGPT 於 2022 年首次亮相後，已將 Bing Search APIs 的價格提高了 10 倍，此次直接關閉 API 服務，可能是微軟在 AI 時代對搜索服務戰略調整的一部分。&lt;/p&gt; 
&lt;p&gt;此外有分析指出，微軟停用 Bing API 可能會對正在審理中的 Google 搜索壟斷案產生影響。&lt;/p&gt; 
&lt;p&gt;由於 Google Search APIs 價格昂貴且限制較多，許多開發者更傾向於使用 Bing API，微軟的這一決定可能會迫使 Google 在搜索 API 資源方面做出更多讓步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350213/bing-web-search-api-retired</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350213/bing-web-search-api-retired</guid>
      <pubDate>Sun, 11 May 2025 05:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元圖像（Hunyuan Image）2.0 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元圖像 2.0 模型（Hunyuan Image2.0）已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNEg5Wop9EPw3Z6Lx5ik7Mg" target="_blank"&gt;正式發佈&lt;/a&gt;。該模型主要有兩大特點：&lt;strong&gt;實時生圖、超寫實畫質。&lt;/strong&gt;目前已在騰訊混元官方網站上線（https://hunyuan.tencent.com/），並對外開放註冊體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img height="607" src="https://static.oschina.net/uploads/space/2025/0516/134524_sRBm_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方數據顯示，在圖像生成領域專門測試模型複雜文本指令理解與生成能力的評估基準 &amp;nbsp;GenEval（Geneval Bench）上，騰訊混元圖像 2.0 模型準確率超過 95%，遠超其他同類模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134745_rlGs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是混元圖像（Hunyuan Image）2.0 模型生成的圖片：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;人像攝影風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="512" src="https://static.oschina.net/uploads/space/2025/0516/134725_ADPH_2720166.png" width="854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;動漫風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="532" src="https://static.oschina.net/uploads/space/2025/0516/134738_PKYz_2720166.png" width="888" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;真實人物風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134836_gwyW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次模型升級還帶來了發佈了實時繪畫板功能，基於模型的實時生圖能力，用戶在繪製線稿或調整參數時，預覽區同步生成上色效果，突破了傳統「繪製-等待-修改」的線性流程，可助力專業設計師的創作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135145_kura_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;實時繪畫板支持多圖融合，用戶上傳多圖後，可將多個草圖疊加至同一畫布自由創作，經過 AI 自動協調透視與光影，按照提示詞內容生成融合圖像，進一步豐富了 AI 生圖的交互體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350209</guid>
      <pubDate>Sun, 11 May 2025 05:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windsurf 發佈 Wave 9 模型家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf (原 Codeium) 發佈了 Wave 9 模型家族，包括 SWE-1、SWE-1-Lite 和 SWE-1-Mini。&lt;/p&gt; 
&lt;p&gt;SWE-1 是一個前沿模型，專門為軟件工程任務設計，在內部評估和產品使用中，其性能接近甚至超越現有前沿模型。&lt;/p&gt; 
&lt;p&gt;SWE-1-Lite 是一個更強大的新模型，將取代原有的 Cascade Base，對所有用戶免費。SWE-1-Mini 是用於 Windsurf 中 tab 補全的改進模型。SWE-1 目前對 Pro 用戶限時免費。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/133759_d7AQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據 Windsurf 介紹，SWE-1 是其中最大、能力最強的 AI 模型，旨在突破現有大模型在軟件工程實際需求上的侷限。&lt;/p&gt; 
&lt;p&gt;相比只關注代碼生成和單元測試的傳統模型，SWE-1 更強調對開發流程中多種狀態和上下文的感知能力（flow awareness），它能夠在人機協作、任務未完成等複雜場景下持續推進工作。&lt;/p&gt; 
&lt;p&gt;根據基準測試，SWE-1 在 「對話式 SWE 任務基準」 和 「端到端 SWE 任務基準」 這兩項核心指標上，都已經接近目前行業最強的前沿模型。特別是獨立的端到端任務中，它的表現幾乎和 Claude 系列最新模型能力相當。&lt;/p&gt; 
&lt;p&gt;在對話式任務中（任務做到一半，用戶和模型交替操作，模型需要接着用戶的進度繼續完成任務），它目前的能力相當於 Claude 3.5 Sonnet。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-80a326122f0a65adc98949e8bf1c2bc890e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fcb9655b8e9ddf4084175265b446815c9f2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;參考來源：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindsurf.com%2Fblog%2Fwindsurf-wave-9-swe-1" target="_blank"&gt;https://windsurf.com/blog/windsurf-wave-9-swe-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOS6Tz1nfUxgi0n4Dcf3bvg" target="_blank"&gt;https://mp.weixin.qq.com/s/OS6Tz1nfUxgi0n4Dcf3bvg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</guid>
      <pubDate>Sun, 11 May 2025 05:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深入對比谷歌 A2A 與 ANP：找到協議的原點</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;作者：常高偉，智能體協議 ANP 發起人。&lt;/p&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;關於 ANP：Agent Network Protocol (ANP) 是一個開源的智能體通信協議，目標是成為智能體互聯網時代的 HTTP。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;谷歌的&lt;/span&gt;&lt;span&gt;A2A&lt;/span&gt;&lt;span&gt;協議出來後，很多關注 ANP 社區的朋友第一時間發來消息，問對我們影響大不大，並且給我們獻言獻策，再次感謝。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我認為 A2A 對&lt;/span&gt;&lt;span&gt;ANP&lt;/span&gt;&lt;span&gt;最大的影響是，有了谷歌的「蓋章「 Follow：ANP 的路線是對的，ANP 看的很長遠，我也來了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;我不用再去解釋為什麼智能體通信協作重要了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;當天我花了半天的時候研究，寫了一篇文章：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4NjIwOTM5Mw%3D%3D%26mid%3D2654085211%26idx%3D1%26sn%3D22d52145d41b02fc217469278c8857f5%26scene%3D21%23wechat_redirect" target="_blank" rel="nofollow"&gt;多角度全面對比 Google 最新的 A2A、ANP、MCP&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;後來又花了一天的時間仔細研究了 A2A，與 ANP 做了一個深度的對比，我認為我應該找到了 A2A 的原點，我也看到了 A2A 與 ANP 的更深層次的差異&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;一句話總結：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;MCP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;A2A 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;ANP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;智能體在互聯網上的連接與協&lt;/span&gt;作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;技術層面的差異對比&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;雖然説 A2A 和 ANP 都是解決智能體通信與協作，但是從技術層面，A2A 與 ANP 還是有很大的差異。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體描述與信息組織&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在協議設計中，一個智能體如何對另外一個智能體暴露其信息，是一個關鍵的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體描述方面，A2A 使用了一個名為 Agent Card 的 JSON 格式的文檔，用於描述智能體的能力、技能、身份認證方法等，Agent Card 的核心是技能（skill），表達智能體能夠幹什麼事情，比如能夠進行地圖路徑規劃等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ANP 也是用的 JSON，不過基於 JSON-LD（&lt;/span&gt;&lt;span&gt;Linked Data&lt;/span&gt;&lt;span&gt;）和 schema.org 描述智能體信息（基本信息、身份驗證、對外產品/服務、交互 Interface），這是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;語義網&lt;/span&gt;&lt;span&gt;的技術，目的是提高兩個智能體對信息理解的一致性，以及讓智能體的公開信息能夠鏈接成一個數據網絡，智能體描述文件是網絡的入口：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-d01d5d7307d80461908b85ccbf5bf33a731.png" width="866" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，一個酒店智能體，使用 ANP，可以將酒店的房間、設施、服務、交互接口等信息（包括圖片）描述出來，並且鏈接成一個數據網絡，讓其他智能體能夠爬取並且理解。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這也導致，在智能體的交互上，A2A 與 ANP 有非常大的差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;A2A 通過 Agent Card 描述智能體的技能（skills），其他智能體獲取 skills，然後通過 JSON-RPC 發送一個任務請求，任務使用自然語言描述，並且攜帶任務需要的相關信息。任務完成後返回結果。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="899" src="https://oscimg.oschina.net/oscnet/up-6520f035e7c07da9e2c01587383e4349789.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;ANP 則是通過智能體描述文檔（Agent Description），將智能體對外提供的產品、服務、交互接口等信息用 URL 連接到一起，另外一個智能體像一個網絡爬蟲，通過 URL 不斷的爬取自己需要的信息。這個過程中可以通過自然語言接口與智能體進行交互，也可以通過結構化接口與智能體進行交互。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1037" src="https://oscimg.oschina.net/oscnet/up-6b28fc14add696a2b8229dff90d88f23df6.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這裏的核心差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;A2A 是智能體對外公開自己的技能，另外一個智能體發送處理任務過來，處理完成後返回結果。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;ANP 是智能體對外公開自己信息（包含交互接口），其他智能體爬取信息進行處理，必要的時候通過自然語言接口或結構化接口與智能體進行交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體發現&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體的發現上 A2A 的方案和 ANP 基本是一樣的，都是在域名的.well-known 目錄下增加一個元數據文檔，A2A 的文件名是 agent.json，ANP 的文件名是 agent-descriptions。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時也都支持智能體主動註冊到私有註冊表，這個在局域網中的協作是非常有必要的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不同的地方在於，A2A 是直接將 Agent Card 內容放到.well-known/agent.json 中，而 ANP 則是在.well-known/agent-descriptions 中存放智能體描述文件的 URL。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 目前看起來是一個域名一個 Agent Card（還要進一步確認），ANP 則是一個域名可以有很多個智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;身份驗證&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在身份驗證上，A2A 和 ANP 有所不同。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 智能體在 A2A 協議中並不交換身份信息。相反，它們通過帶外方式獲取認證材料（如 token），並通過 HTTP 頭部傳遞這些材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所謂的帶外，是指通過 A2A 之外的其他協議獲取認證材料。A2A 遵循 OpenAPI 的身份認證規範進行身份認證，支持包括 HTTP Basic Auth、API Key、OAuth 2.0 等多種認證方式，具體由每個智能體在其 Agent Card 中聲明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="480" src="https://oscimg.oschina.net/oscnet/up-d447565d2bd93d80f90c7ecb282f4ef5cc6.png" width="852" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則基於 W3C DID 技術構建去中心化的身份認證，在協議中直接攜帶身份信息，包括身份驗證信息。智能體使用自己的身份就能夠和其他所有的智能體進行交互，不需要帶外獲得身份驗證材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在某些場景中，帶外獲取身份驗證材料是必要的，特別是在企業級應用中。ANP 未來會支持帶外身份驗證材料的獲取，設計上預留了擴展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b3dfb6efb5e2de6b145ed311e0f9e726f08.png" width="948" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 採用帶外獲取身份驗證材料，是為了最大程度兼容美國主流企業應用生態的安全合規要求，複用現有的企業身份認證體系，確保協議本身輕量、靈活且安全。核心是為瞭解決企業級應用的身份問題，並且沒有解決互聯網上智能體互聯互通的身份問題。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則是未來解決智能體在互聯網上如何進行身份認證的問題，核心是讓互聯網上任意兩個智能體都能夠互聯互通，這需要一個互操作性更好的身份認證方案。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;核心概念&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 與 ANP 在協議的核心概念上有很大差異。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;A2A 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括 Skill（技能）、Task（任務）、Artifact（產物）、Message（消息）、Part（部分）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時，Task 又定義了多種狀態，包括：submitted（已提交）、working（處理中）、input-required（需要輸入）、completed（完成）、canceled（取消）、failed（失敗）、unknown（未知）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Task 也定義了一些操作，包括：Send（發送）、Get（獲取）、Cancel（取消）等，以及一些通知相關的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;ANP 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括描述信息與接口（Interface）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;描述信息主要是 JSON-LD 格式的文檔，以及 JSON-LD 文檔中通過 URL 鏈接到的其他資源，包括圖片、音頻、視頻等多媒體文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Interface 又分為自然語言接口（Natural Language Interface）和結構化接口（Structured Interface）。結構化接口支持現有大部分的規範，比如 OpenAPI、JSON-RPC 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 在協議層面定義了詳細的任務協作概念，包括任務的狀態、操作等，這有助於解決智能體之間複雜任務的協作問題。缺點是會導致兩個智能體之間的耦合度較高。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 簡化了智能體之間的交互，降低了智能體之間的耦合度，在跨平台的智能體協作場景下有較大的優勢。缺點是原生協議不支持複雜任務協作，需要自己定義 Interface 來實現。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;A2A 與 ANP 的原點&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;要想真正的理解一個協議的設計，必須找到這個協議的原點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，ANP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能體在互聯網上的連接與協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。MCP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，構建更好的智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;通過上面的技術分析，我們可以確認 A2A 的原點是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;協議的官網並沒有明確的説出這一點，但是谷歌的新聞發佈稿中有提到過一些：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;AI 智能體為人們帶來了獨特的機會，能夠通過自主處理許多日常重複性或複雜任務，幫助提升工作效率。如今，企業越來越多地構建並部署自主智能體，以幫助在整個工作場景中實現規模化、自動化並優化各類流程——從訂購新筆記本電腦，到輔助客戶服務代表，再到協助供應鏈規劃。（https://developers.googleblog.com/en/a2a&lt;/span&gt;&lt;span&gt;&lt;span&gt;-a&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-new-era-of-agent-interoperability/）&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從 A2A 生態企業的分佈也大概可以看出這一點，大部分都是 AI 平台與服務、軟件、SaaS 和企業平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-2defdfdfeb005bbfae4fe07af3e72afe1a4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="693" src="https://oscimg.oschina.net/oscnet/up-8026f8e9b8cc4e73963d2737dd793f74d30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從技術上看，目前&lt;strong&gt;A2A 的實現也不大適合智能體互聯網的需求&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;以個人助手使用 A2A 去酒店智能體預訂房間為例，按照目前 A2A 的實現，個人助手需要發送一個任務，用自然語言描述用戶的要求（價格、房型、時間等）信息，酒店智能體處理後返回任務執行信息。在中間可能要經過多次的任務交互、任務狀態的遷移等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這會有兩個問題：一個是用戶的隱私可能會被泄露，因為個人助手要將任務發送給另外一個智能體執行；另外一個就是交互耦合度過高。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 的邏輯則是個人助手爬取酒店智能體的信息在本地進行處理，需要交互的時候才調用酒店智能體的接口。這是本質的區別。當然，除此之外 A2A 還有智能體在互聯網上的身份互聯互通問題沒有解決。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，&lt;strong&gt;也不排除未來 A2A 通過協議升級擴展到智能體互聯網的場景&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;未來智能體協議的一些預判&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;短期內 MCP 成為模型連接工具和資源的事實標準，這個基本上已經確定，目前很難有第二個 MCP 出現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;中長期來看，我認為有一個趨勢大概率會發生：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;工具智能體化，智能體工具化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果這個趨勢發生，那麼智能體協議會擠壓 MCP 的空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;更長期來看，AGI 實現後，也許人類設計的協議是 AI 的束縛而非助力，AI 有辦法自己設計協議並達成共識。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在當下智能體協議是非常重要的，它是智能體的重要拼圖，也是智能體與互聯網交互最 AI 原生的方式，是比 Computer Use、Browser Use，甚至 AI 瀏覽器都更高效的連接方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;無論如何，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 最有價值的部分，是社區對未來智能體互聯網的設想，是社區獨特的互聯網理念（連接即權力），以及 DID+語義網的技術路線。這是支撐 ANP 走下去的核心動力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;關於創新&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 出來之後看着"炸裂、一夜變天、顛覆"這些標題心情複雜，特別是我們做 ANP 做了一年，也推廣了很長時間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們都在説，我們需要"0 到 1"的創新——我們不單需要創新者，也需要媒體能夠去發現這些創新者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;最後感謝開源社區的每一位貢獻者和開發者，現在已經有 40 多位開發者了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;也感謝公眾號、社區對我們的支持，包括 RTE 開發者社區、OSC 開源社區、&lt;/span&gt;&lt;span&gt;Founder Park&lt;/span&gt;&lt;span&gt;、覺察流、侯宏文存、AIGCLink、智能體 AI 等等（可能不全），還有很多給我們提供分享機會的組織，以及為社區提供服務器資源的 AWS 和阿里雲。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;最後&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;如果你也認可我們的理念，認可我們對未來智能體互聯網的設想，歡迎加入我們，無論是以個人，還是以公司名義，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;我們需要你的支持&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們正在籌備 ANP 開源技術社區創始委員會，這是一個臨時委員會，目的是為了讓社區能夠走向正軌，成長為一個更加開放的社區。感興趣可以聯繫我。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;聯繫方式：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;開源項目 GitHub：https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;Discord: https://discord.gg/sFjBKTY7sB&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;官網：https://agent-network-protocol.com/&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18398047</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18398047</guid>
      <pubDate>Sun, 11 May 2025 05:07:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>NebulaGraph 圖數據庫開源六週年</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-347a643f66a66a9edf9d5760c1e8d2f4686.png" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/strong&gt;‍‍&lt;/p&gt; 
&lt;p&gt;2025 年 5 月 15 日，NebulaGraph 迎來開源六週年的里程碑。作為國產開源圖數據庫的標杆項目，回望 NebulaGraph 的六年發展歷程，不僅是一部技術迭代的編年史，更是中國開源社區在全球基礎軟件領域崛起的縮影。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、誕生：在數據關係的浪潮中揚帆起航&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 8 月 31 日， @Sherman-the-tank 在 nebula 倉庫中提出第一個 issue ‘Create a parser framework to process GQL.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 9 月 5 日， @dutor 提交了第一個 PR ‘Added some concurrent utilities, GenericThreadPool, etc.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph PMC Sherman Ye 曾參與多個分佈式數據庫研發工作，當社交網絡爆發式增長，引發數據關係挖掘需求井噴時，他敏鋭地意識到：圖數據庫是表示和理解關係最天然的工具，然而當時的圖數據庫或受限於單機性能，或困於擴展性不足，難以承載千億節點、萬億邊級的超大規模數據。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們必須打造一款開源的、分佈式的、支持線性擴容的世界級圖數據庫，能夠容納千億頂點和萬億邊。&lt;/strong&gt;」Sherman 的願景，從一開始就超越了代碼本身。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4e970720b415322cc5254ac4b46dd587181.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 誕生於一間小公寓，初期核心團隊在這裏辦公）&lt;/p&gt; 
&lt;p&gt;NebulaGraph 採用 Shared-Nothing 架構與存儲計算分離設計，為 NebulaGraph 注入了宇宙級的基因——每個節點獨立處理數據，如同星雲中的星辰，既自由又協調；存儲與計算分離，則讓擴容像星雲膨脹般自然。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們寫下 NebulaGraph 第一行代碼時，就認識到它必須是一款開源的圖數據庫&lt;/strong&gt;。」不忘開源初心，八個月後，NebulaGraph 遵循 Apache 2.0 開源協議，在 GitHub 開源 alpha 版本，從此開啓了突破國產圖數據庫技術的星辰大海征程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a9d672008ac303c7c9a6d86aa9b3c44aa2e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（一張開源紀念截圖）&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、應用：在產業實踐的土壤中紮根&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 10 月 29 日，攜程雲原生技術總監周昕毅先生在上海 nMeetup 上充分肯定了 NebulaGraph 作為開源解決方案在企業中的應用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用戶的選擇是最好的背書。六年來，NebulaGraph 用戶覆蓋金融、互聯網、通信、電商、保險、安全等多個行業。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-d2338012c10f02d334d817be194af6c777f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 部分用戶）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;攜程集團已有包括酒店、機票、金融在內的 16 個部門使用 NebulaGraph, 在風控場景，構建了實時圖特徵平台的應用邏輯閉環，額外獲取了 55% 的關聯業務信息，使得該場景下的覆蓋率提升了 32%&amp;nbsp;；奇富科技打造了智能化的金融反欺詐系統系統，累計報送涉騙阻斷預警 59 萬次，攔截潛在被騙者 9.5 萬人，幫助用戶避免損失 11.35 億元；OPPO 從 JanusGraph 切換到 NebulaGraph 後，導入性能提升了 10 倍，且查詢性能以及併發能力都有 3-6 倍的提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;NebulaGraph 是開源項目，用戶在真實使用場景中，為解決業務需求，會自然地參與共建，這種集體智慧加快了 NebulaGraph 的迭代：企查查貢獻了 Node 客戶端，奇富科技阿旺把自己做的 nebula-console-intellij-plugin 捐給了社區，篤篤科技大葉開發了 NebulaGraph 圖數據庫客戶端星影 StarShadow.&lt;/p&gt; 
&lt;p&gt;一幅技術紮根產業、需求反哺產品的共生圖景已然成形。這正是 NebulaGraph 在真實商業土壤中向下紮根、向上生長的最佳註腳。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、生態：在開源共治的生態中繁榮&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 3 月，NebulaGraph 在 GitHub star 數突破 10,000 大關&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph 社區構建了一套自由且開放的「雙軌成長體系」：開發者（Dev Group）聚焦代碼貢獻，用戶（User Group）專注實踐傳播。細分來看，還有學習者、佈道師、文檔貢獻者等角色，每種角色都能擁有自己的話語權，找到自己的存在價值，他們不會被統一地轉化成某一類角色，他們被允許以某一種角色停留在社區裏，比如僅僅作為用戶，或者僅僅作為一次性的代碼貢獻者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4781abc41f59cc55d7d129c6444f502e901.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph Community 成長體系）&lt;/p&gt; 
&lt;p&gt;作為開源項目，我們始終重視代碼共建共享。連續 5 年參與中國科學院軟件研究所發起的開源之夏，鼓勵全球高校開發者參與開源貢獻，為社區注入新鮮血液；舉辦 NebulaGraph Hackthon，設立 150,000 獎金池，從內核到周邊，讓廣大圖數據庫及 NebulaGraph 愛好者盡情探索圖世界。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a5cadecf20779c82bcf80c9e7896d7e77cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（來自開發者的認可）&lt;/p&gt; 
&lt;p&gt;線下活動同樣精彩紛呈。從 NUC 2021、2022，到足跡遍佈全國的 nMeetup，我們珍惜每次與用戶、開發者面對面交流的機會。也許大家素未謀面，但因為同在 NebulaGraph 社區，見證了萬星開源項目的崛起，每次線下探索圖數據庫的世界都能像老朋友一樣碰撞出思維的火花和久違的默契。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-9d32d3464c875255314f68fc03f7487fc59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（社區可愛的小夥伴們）&lt;/p&gt; 
&lt;p&gt;我們始終以包容的姿態，讓每個社區參與者的獨特貢獻匯聚成生態繁榮的星河。&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、未來：在雲與 AI 的浪潮中領航&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph Cloud&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2020 年，NebulaGraph 決定打造雲產品&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;NebulaGraph 從誕生之初起，不僅堅定走開源路線，還堅持雲原生理念。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如今，NebulaGraph Cloud 作為一套集成了 NebulaGraph 數據庫和數據服務的雲上服務，支持一鍵部署 NebulaGraph 和相關可視化產品。用戶可以在幾分鐘內創建一個圖數據庫，並快速擴展計算、存儲等資源，無需在本地搭建和維護複雜的圖數據庫基礎設施，從而能夠更加專注於核心業務的發展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0f3996764f2cbb028787d68755889da4bdc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 控制枱界面）&lt;/p&gt; 
&lt;p&gt;NebulaGraph Cloud 除了在 AWS 上提供全託管服務，還計劃全面支持 Azure 和 Google Cloud Platform (GCP) 等主流公有云廠商，企業可夠根據自身需求和業務場景，選擇最適合的雲廠商。&lt;/p&gt; 
&lt;p&gt;申請試用⬇️&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.nebula-graph.io%2Flogin" target="_blank"&gt;https://cloud.nebula-graph.io/login&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph AI 應用平台&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2023 年 8 月 16 日，@wey-gu 與 LlamaIndex 聯合發佈 GraphRAG.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;正如 NebulaGraph 誕生之初，我們又一次站在高處看未來——洞察到圖結構在知識處理中的革命性潛力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2023 年 8 月，在 RAG 技術還未被稱為 RAG，而是上下文學習方法的時候，我們就意識到以圖的方式處理知識會對解決「大海撈針」等特定問題有很大幫助，因此&amp;nbsp;@wey-gu 提出了將圖數據庫與 RAG 結合的想法，向 LlamaIndex 提了第一個 PR，將 KG-RAG 轉變為 GraphRAG.&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-94fd0e2ef4e5265750786d1f60e9423f893.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph GenAI Team Leader @wey-gu）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GraphRAG 僅僅是 NebulaGraph 探索 GenAI 的「第一步」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨後，我們和 Researcher: Diego 一起討論，做了圖索引之上 Chain of Exploration 的工作，這種探索鏈不僅可以幫助 Agent 理解圖譜，還能從非結構化數據中提取出半結構化的知識圖譜‌。&lt;/p&gt; 
&lt;p&gt;在一系列 Graph based RAG 的落地實踐中，GenAI Team 又一次突破技術邊界，提出了 Fusion GraphRAG：融合了高級 RAG 技術，通過圖狀結構存儲文檔層級、章節關係及特殊元素（如公式、表格），實現高效、靈活的檢索。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-b04608e8eedc97b778355eed434fc9280f4.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（Fusion GraphRAG 是更高級的 RAG 技術）&lt;/p&gt; 
&lt;p&gt;但不止於此，NebulaGraph 把視角轉向企業級應用，基於 FusionGraphRAG 與 Agentic RAG 技術，打造了一個全新的高級知識庫與低門檻應用平台 —— NebulaGraph AI 應用平台（內部命名為 「Catalyst」，即催化劑），無需構建複雜 Workflow 和編寫繁瑣 Prompt，更智能地激活與應用企業內部知識。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-2cbc7e0b1c9bf670db137f17cbee8b6f5dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（用戶只需將對私有知識的理解轉化為對不同「知識籃子」的定義）&lt;/p&gt; 
&lt;p&gt;從 GraphRAG 到 NebulaGraph AI 應用平台，我們始終相信：真正的技術革命，不在於創造更復雜的工具，而在於讓複雜技術變得觸手可及。當每個企業都能像調配催化劑一樣輕鬆激活知識資產，我們離智能時代的真正到來，便又近了一步。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;六週年快樂🎉&lt;/h1&gt; 
&lt;p&gt;六載春秋，NebulaGraph 從一顆種子長成參天大樹，其根系已深入全球開發者土壤，枝葉則伸向雲與 AI 的星辰大海。NebulaGraph 的開源歷程，證明瞭通過開源共治，我們能打造出一款世界一流的圖數據庫產品，更證明瞭這羣活躍在開源社區的極客，有着無限的探索精神和創新能力。&lt;/p&gt; 
&lt;p&gt;因為開源，這場圖數據庫技術革命，沒有終點，只有新的起點。&lt;/p&gt; 
&lt;p&gt;因為有你，這場開源協作的星辰征途，沒有孤島，只有攜手同行的遼闊未來。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;開源最大的意義，莫過於代碼開放，共建共享，以用戶/開發者的力量推動產品迭代。&lt;/p&gt; 
&lt;p&gt;陪伴 NebulaGraph 共同成長的你，是使 NebulaGraph 愈發閃耀的星光。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-98d9a5b4f678bcb55a625b31b4cefe5e359.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.nebula-graph.com.cn%2Ft%2Ftopic%2F16781" target="_blank"&gt;在 NebulaGraph 論壇&lt;/a&gt;&amp;nbsp;分享你與 NebulaGraph 的故事，讓更多小夥伴感受到開源的力量。（分享即送星雲仔 T 恤，點贊 top3 可獲得全套社區周邊）&lt;/p&gt; 
&lt;p&gt;六月，NebulaGraph 社區將在北京舉辦 nMeetup，歡迎掃碼提交議題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" height="100" src="https://oscimg.oschina.net/oscnet/up-780ef5d7632ee90c872ab50c1333b6c1ddc.png" width="100" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;‍&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;如果你覺得 NebulaGraph 能幫到你，或者你只是單純支持開源精神，可以在 GitHub 上為 NebulaGraph 點個 Star！每一個 Star 都是對我們的支持和鼓勵✨&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvesoft-inc%2Fnebula" target="_blank"&gt;https://github.com/vesoft-inc/nebula&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4169309/blog/18403236</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/18403236</guid>
      <pubDate>Sun, 11 May 2025 03:53:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 牽頭推動 Transformers 庫模型架構標準化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Ftransformers-model-definition" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;聯合多家機構推動將&lt;code&gt;transformers&lt;/code&gt;庫作為模型架構標準，提升 AI 生態兼容性。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1238" src="https://static.oschina.net/uploads/space/2025/0516/114028_tsZR_2720166.png" width="1718" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Hugging Face 表示正與 vLLM、LlamaCPP、SGLang、Mlx、Qwen、Glm、Unsloth、Axoloth、Deepspeed、IBM、Gemma、Llama、Deepseek、Microsoft、Nvidia、InternLM、Llava、AllenAI、Cohere、TogetherAI 等眾多生態系統參與者共同努力，將&amp;nbsp;&lt;code&gt;transformers&lt;/code&gt;&amp;nbsp;庫中的模型定義代碼作為標準，旨在為所有模型提供一個統一的真實來源。&lt;/p&gt; 
&lt;p&gt;Hugging Face 目前正在與最流行的推理引擎（vLLM、SGLang、TGI、...）緊密合作，讓它們使用&lt;code&gt;transformers&lt;/code&gt;作為後端：只要模型被添加到&lt;code&gt;transformers&lt;/code&gt;，便支持在這些推理引擎中使用，同時利用每個引擎的優勢：推理優化、專用內核、動態批處理等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dc6ac94d98590b08d7bb511a05cf4e82e7e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這項聯合工作將極大地提高不同模型架構在整個 AI 生態系統中的兼容性和互操作性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350188/huggingface-transformers-model-definition</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350188/huggingface-transformers-model-definition</guid>
      <pubDate>Sun, 11 May 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>得物自研 DSearch3.0 搜索核心引擎升級之路</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;&lt;span&gt;&lt;strong&gt;一、背景&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p style="text-align: left"&gt;&lt;span&gt;隨着交易和社區搜索業務穩步快跑，基建側引擎越來越複雜，之前搜索底層索引查詢結構已經存在較為嚴重的性能瓶頸。成本和運維難度越來越高。在開發效率上和引擎的穩定性上，也暴露出了很多需要解決的運維穩定性和開發效率短板。而在引擎的業務層部分也需要逐步升級，來解決當前引擎中召回層和業務層中各個模塊強耦合，難維護，迭代效率低下等問題。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/de1274b479a3468eb2c8c9732f943b6d~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=yG8v2qkQHq9NYLqIZ%2Bfln4tsbMw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h1 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;二、引擎開發技術方案&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;h2 style="text-align: left" class="pgc-p"&gt;&lt;span&gt;&lt;strong&gt;DSearch1.0 索引層整體結構&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;DSearch1.0 的索引結構比較特殊一些，總體上使用了全局 rcu 的設計思想，整體架構上單寫多讀，所以實現了併發高性能無鎖讀，內部數據結構都是無鎖數據結構，所以查詢性能高。在寫操作上因為 rcu 機制實現寫入無鎖。整體上優點讀性能高，沒有傳統段合併操作帶來的磁盤抖動。缺點是索引地址和操作系統強相關，運維複雜，熱更新受限。全局地址分配難以並行寫入，構建瓶頸明顯。無法對浪費的內存進行回收導致內存空間利用率低，索引空間佔用大。總體結構如圖所示：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/90b13bdb5afb4c739e88babf772c494b~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=sBcaXhhCtFSFO6CLTcQ7Ldypf5o%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 的索引升級&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch2.0 分段索引整體設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎 2.0 索引升級採用經典段合併架構，除了繼承了段合併中優異的高性能寫入性能和查詢已經索引合併等優勢外，針對段合併中頻繁的正排字段更新等帶來的高 IO 缺點。我們設計了新的正排字段原地更新索引，使新的 DSearch2.0 引擎擁有 Redis 的高性能寫入和查詢，也擁有 lucene 的緊湊索引和索引合併帶來的內存空間節省的優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 索引段結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個索引段包含了文檔文件，用於緊湊存放 document 中的各個字段的詳細信息。字符串池文件是對 document 中所有的字符串進行統一順序存儲，同時&lt;strong&gt;對字符串進行 ID 化&lt;/strong&gt;，每個字符串 ID 就是對應於字符串池中的&lt;strong&gt;offset 偏移&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;可變數組文件是專門存放數組類型的數據，緊湊型連續存放，當字段更新的時候採用文件追加 append 進行寫。最終內存回收通過段&lt;strong&gt;之間的 compaction 進行&lt;/strong&gt;。FST 索引文件是專門存放 document 中全部字符串索引。每個 fst 的 node 節點存放了該字符串在字符串池中的偏移 offset。而通過字符串的 offset，能夠快速在倒排 termoffset 數組上二分查找定位到 term 的倒排鏈。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排文件是專門存放倒排 docid，詞頻信息、位置信息等倒排信息，其中 docid 倒排鏈數據結構會根據生成段的時候計算 docid 和總 doc 數的密度來做具體判斷，&lt;strong&gt;如果密度高於一定閾值就會使用 bitmap 數據結構，如果小於一定閾值會使用 array 的數據結構&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;標記刪除 delete 鏈主要是用於記錄段中被刪除的 document，刪除操作是軟刪除，在最後查詢邏輯操作的時候進行最後的過濾。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時增量的 trie 樹結構，實時增量段中的前綴檢索和靜態段中的前綴檢索數據結構不一樣，trie 因為能夠進行實時更新所以在內存中使用 trie 樹。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;段中的 metadata 文件，metadata 文件是記錄每個段中的核心數據的地方，主要記錄段內 doc 數量，段內 delete 文檔比例，實時段的 metadata 會記錄 kafka 的 offset 等核心數據。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/24c940a2b35e4d15a162fe3ebf200d0f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2BYmQsxTR%2FExv2AC40UdCJ0azAwA%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;Document 文檔和索引結構&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ Document 文檔數據結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Document 文檔使用緊湊型存儲，其中 array 和字符串類型單獨存放，其他字段連續存放，string 和 array 字段存放。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;array 字段類型數據直接存放在可變數組文件區，連續追加寫。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;string 字符串池對所有字符串進行連續存放，多個 doc 中同一個字符串引用同一個字符串地址，節省大量字符串存放空間。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排索引文件結構&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;倒排索引文件存放 docid 倒排和 Tf 以及位置 position 數據。其中內存實時段中的倒排索引數據結構是固定一種類型 array 類型。而內存實時段固化為靜態段的時候，倒排數據結構會根據 docid 中的密度進行選擇 array 和 bitmap 存儲。當 docid 密度大於一定閾值是 bitmap，反之是 array 結構。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;Tf 數據結構是一個 uint16 的數組，數組長度和 docid 的數組長度一致，所以當確定了某個 docid 時候，也隨即確定了它的 tf 信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;postion 信息存儲是一個二維數組的格式，第一層數組存放的是對應於 term 的在字符串池的 offset，因為 term 在字符串池中已經 ID 化，所以 offset 可以表示唯一 term。第二層數組是該 term 在字段中多次出現的位置，使用 uint16 存儲。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 前綴檢索文件&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;FST 靜態段文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 靜態段中前綴是 fst 的數據結構，因為 fst 一旦建立是不能夠進行修改的，所以在段合併的時候需要對所有 term 進行排序然後再構建 fst 結構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;b. fst 的 node 節點存放了對應於 term 的字符串池的 offset。當需要查詢一個 term 的倒排結構時候，需要先查詢該 term 的字符串池的 offset，然後拿該 offset 去倒排的 termoffset 文件中二分查找找到對應的倒排 positionlist 結構拿到對應倒排。所以一次 term 到倒排的查詢需要查詢一次 fst+一次二分查詢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;c. term 到倒排的查詢一次 fst+一次二分查找效率不高，所以針對 term 到倒排查詢，新增了第二種 HashMap 索引，直接通過 term 到倒排的 offset 索引，這個選項在建表的時候可以配置。&lt;/span&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時段 RcuTrie 樹索引&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;a. 實時段中需要支持邊寫邊讀，前綴檢索需要支持併發讀寫。引擎中 trie 樹是 rcu 實現，單線程更新，多線程併發讀，trie 樹寫更新節點內存延遲迴收。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/1a4ee53847174e60b8ac7df104a5d5b6~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=HOQHf%2Fr42ewivfi%2BZbf2pws0nLo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;倒排索引和查詢樹邏輯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 倒排鏈優化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch1.0 的 roaringbimap 倒排索引在低密度數據量上存在一些瓶頸，比如對於倒排鏈比較短的情況下，roaringbitmap 的 container 大部分都是 array 結構，在倒排鏈查詢和合並都會進行一次二分查找，在大面積的倒排鏈合併中是個相當大的性能瓶頸。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;針對上面所説的情況對 roaringbitmap 進行了精簡，只存 array 或者 bitmap 合併的時候不需要查找，直接鏈式合併。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 邏輯樹合併優化&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;DSearch2.0 重點從邏輯語法樹和倒排入手，優化語法樹，減少合併樹高，從二叉樹合併變成單層合併。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;優化倒排鏈合併方式，採用原地倒排鏈合併，消除倒排合併臨時對象，同時引入多線程並行合併，減少長尾提高性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a324c1263d7045f6a4346f99c7f97124~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=DxtCm2sohwPSMuxM%2Flr5%2BTSP4kg%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;增量更新邏輯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 增量實時寫入邏輯&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;引擎支持多個併發實時段，這個由配置文件通過配置來進行配置。多個實時段能夠提升併發寫入的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個實時段對應一個寫入隊列，提高併發寫入吞吐。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;每個段真實寫入一條信息會同步原子更新消費的 kafka 的 offset，用於對後面進程重啓等恢復數據做準備。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;當進程重啓或者異常退出時候，會讀取 metadata 文件中的最後一條 kafka offset 進行重新消費增量在內存中重新構建新的正排、文檔和倒排等信息，完成數據的恢復。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/4a6eba83cdd74c1587d9aa76bf35ddbd~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=okNAsDWIX8ozfo9pqhZbj2DF39Q%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;實時段固化和段合併策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 實時段固化邏輯：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;當實時段內隨着增量寫，doc 文件大小超過 128M 時候會進行內存實時段固化操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;固化操作開始時，會先生成新的內存實時段，老的內存實時段會變成只讀內存段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;遍歷按整個只讀內存段，構建新的索引和新的正排結構生成新的靜態段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 段合併策略：&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;實時段固化的小靜態段因為大小比較小，會優先和之前固化後的小段進行合併，按照 1，2，4，8 進行合併，逐步合併成靜態段最大的上限。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;靜態段的合併觸發策略是當靜態段中 delete 的 doc 比例超過了 30% 會觸發靜態段之間的合併，合併會按照近鄰合併原則，從左右近鄰中選取一個最小 doc 數的段進行合併，進而新生成一個新的段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/08582c715cbd47d0b298435e57bac25f~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=40FqkO626yUPY%2BI3uTtsbA1Ihwo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;查詢和更新中的併發控制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 查詢流程&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;引擎查詢時候，先遍歷查詢實時段，然後再查詢靜態段。實時段查詢存在最大增量查詢截斷，當實時段查詢到最大增量截斷時實時段停止查詢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;實時段查詢後，查詢靜態段。靜態段中包含了全量構建索引的全量最大 offset 記錄同時全量的 doc 是通過質量分進行排序，所以在全量段查詢的時候，先遍歷質量分最大的全量段，逐步往後面靜態段查詢，直到查詢到全量截斷。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;實時段查詢和靜態段查詢結果進行 merge 作為最終的查詢結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;/p&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ 更新併發控制&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;因為 DSearch2.0 的索引更新是直接在實時段或者靜態段進行更新，所以存在多線程讀寫問題。尤其是正排字段更新寫入量大更新頻繁。同時更新涉及到所有的實時段和靜態段，較為複雜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;為瞭解決正排字段和倒排的更新問題，新版本引擎引入了 document 文檔鎖池，對每個 doc 進行 hash 計算落到鎖池中具體一個鎖上來減少鎖衝突，當前鎖池內有多個個文檔鎖。文檔鎖在文檔進行拷貝和更新的時候會進行鎖住。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="text-align: left"&gt;&lt;span&gt;&lt;strong&gt;DSearch3.0 搜索核心升級&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;異步非阻塞圖調度框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7e1821341e54416a99384f4ae1016048~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=Ugikrdj%2Fc%2FMZkAFTUtc7L9JVcG0%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="color: rgb(62, 62, 62)"&gt;&lt;strong&gt;圖框架支持 RPC 異步非阻塞請求：&lt;/strong&gt;&lt;/span&gt;&lt;span style="font-size: 0.882em"&gt;引擎圖框架 RpcServer 服務使用 brpc 的異步處理無需同步阻塞等待調度完成，只需框架調度完算子返回結果，不阻塞 RpcServer 線程，例如：當前引擎調用 neuron 服務是同步調用，當 neuron 服務負載高阻塞時，同步調用會導致拖住引擎 RpcServer 處理線程，新的異步非阻塞模式引擎 client 在調用引擎後已經返回，等待引擎 RpcServer 中異步調度框架中 remote 異步算子回調，減少外部服務影響引擎。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;減少線程切換：&lt;/strong&gt;圖框架調度器會優先調度當前運行線程，同時使用 M:N 類型的 bthread 線程池，線程切換會更小，執行效率高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;RPC 服務和框架算子獨立：&lt;/strong&gt;引擎 RPC 服務和框架算子完全解耦，跨集羣部署算子服務無需任何改造，實現算子脫離運行環境。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;高效的算子異常處理和超時機制：&lt;/strong&gt;每個算子維護自己的運行超時時間和請求到算子調度執行的超時時間，對整個請求流程中各算子執行更加精準。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;動態圖支持：&lt;/strong&gt;圖框架支持靜態圖和動態圖業務組合式調用。支持靜態子圖和動態子圖調用等複雜業務組合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;複雜子圖支持：&lt;/strong&gt;圖框架支持嵌套子圖，支持自調用模型，可以實現複雜單節點多功能調用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子間數據交換 Table 設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3bf931610dd74d5da3be98d3395310ab~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=n4lk8KDSCTKVPt6uIgyIxo9v%2FPw%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;列式數據共享優化：&lt;/strong&gt;算子交換數據全部存放在 Table 列中，Table 中全部共享列式數據，省去大面積數據拷貝，大幅提升引擎業務執行性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;兼容引擎索引中 doc 數據：&lt;/strong&gt;引擎索引中 doc 行式存儲有很多優點，比如多字段訪問效率高等，Table 設計中考慮了行式存儲優點，不僅存高頻的列字段也儲存了引擎內部的 doc*以及對應 FieldDef*，能直接方便訪問索引數據，接口統一，易於迭代。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;打通 FlatBuffer 序列化協議：&lt;/strong&gt;當前引擎 FlatBuffer 序列化傳輸協議和引擎內部數據出口需要多次遍歷轉換，需要拷貝很多數據，新 Table 的設計內部數據列和 FlatBuffer 內部的數據列互轉互通，節省大量內部拷貝同時避免了字段兼容等問題。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;支持原地排序和標記刪除：&lt;/strong&gt;Table 數據表，支持原地 sort 操作和標記刪除操作，節省數據排序時大量數據的拷貝和刪除操作中導致的數據重排等拷貝操作，提升性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;算子間數據交換 Table 設計&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a96224208f0d46f2b9abffe520367ac1~tplv-obj.image?lk3s=ef143cfe&amp;amp;traceid=2025051410200631E315502D38AE1F6DD8&amp;amp;x-expires=2147483647&amp;amp;x-signature=zR%2B1sBPOMWcKSWcnoqSS3HtpR%2Bo%3D" data-align="left" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p style="line-height: 2; text-align: left"&gt;&lt;span&gt;&lt;strong&gt;&lt;u&gt;※ &lt;/u&gt;引擎主要改造：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;動態圖支持：&lt;/strong&gt;DSsearch3.0 支持動態圖編排，主要通過業務方通過動態編排請求來組織對應的算子編排邏輯，實現業務方自主編排調度邏輯，方便整體業務開發。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;Remote 遠程調用支持：&lt;/strong&gt;通過開發遠程異步調用算子，支持 DSearch3.0 跨集羣調用，實現多機算子化互聯互通。提高引擎的整體縱向拓展能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;引擎算子庫複用：&lt;/strong&gt;通過設計統一的算子接口，開發基礎的可複用框架算子，支持配置化組合運行圖，實現業務邏輯快速複用和開發，提高整體引擎開發效率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;三、性能和效果提升&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 在 2024 年 Q1 季度索引升級開發完成後逐步推全到交易和社區等各個主場景業務中，最後拿到了很多超預期結果：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引內存優化超出預期：&lt;/strong&gt;社區搜索和交易搜索總索引單分片優化 60%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;構建和寫入性能優化超出預期：&lt;/strong&gt;社區搜索和交易搜索主表寫入性能提升 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;索引更新優化超預期：&lt;/strong&gt;社區和交易主表更新時間提升接近 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;性能優化符合預期：&lt;/strong&gt;社區搜索平均 rt 降低一倍，P99 晚高峯降低 2 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;&lt;strong&gt;四、總結&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;DSearch 引擎從開始的 DSearch1.0 的搜索引擎逐步經歷了 DSearch2.0 的分段式索引改造升級，又經歷了 DSearch3.0 的全圖化引擎升級。逐步將 DSearch 引擎升級到業界較為領先的支持內存型、磁盤型多段式搜索引擎，為支持得物業務的發展做出了重要的貢獻，後續 DSearch 會圍繞着通用化、自迭代、高性能等多個方向繼續升級，將 DSearch 引擎迭代到業界領先的引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-size: 0.882em"&gt;&lt;strong&gt;算法團隊大量 HC，歡迎加入我們：&lt;/strong&gt;得物技術大量算法崗位多地上線，「職」等你來！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;1. 以細節詮釋專業，用成長定義價值——對話@孟同學 ｜得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;2. 最近爆火的 MCP 究竟有多大魅力？MCP 開發初體驗｜得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;3. 得物可觀測平台架構升級：基於 GreptimeDB 的全新監控體系實踐&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;4. 得物自研 DGraph4.0 推薦核心引擎升級之路&lt;/span&gt;&lt;/p&gt; 
&lt;p style="line-height: 2"&gt;&lt;span&gt;5. 大語言模型的訓練後量化算法綜述 | 得物技術&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;文 / 蘇黎&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;關注得物技術，每週更新技術乾貨&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align: center"&gt;&lt;span&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18387813</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18387813</guid>
      <pubDate>Sun, 11 May 2025 03:36:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>開源 AI 客戶端 Cherry Studio v1.3.3 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cherry Studio 是一款支持多個大語言模型（LLM）服務商的開源桌面客戶端，兼容 Windows、Mac 和 Linux 系統。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-23dab8c50bfcc8126ab84229b00dbc2115c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該項目近日發佈新版本 v1.3.0，包含了大量變更。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;一、新增功能亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;v1.3.0 在模型支持、核心體驗及界面交互等方面均有顯著增強：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型與服務商拓展：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;strong&gt;Grok / X&lt;/strong&gt;&amp;nbsp;（#5706）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;strong&gt;n8n&lt;/strong&gt;&amp;nbsp;（含 Logo 及 URL） （#5776）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;支持用戶&lt;strong&gt;自定義 Mini App&lt;/strong&gt;（#5731）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;支持&lt;strong&gt;圖像編輯功能（&lt;/strong&gt;#5469）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;支持 OpenAI 最新的&amp;nbsp;&lt;strong&gt;Responses API&lt;/strong&gt;&amp;nbsp;（#5621）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;增強了 OpenRouter 中 Token 預算的計算邏輯 （#5625）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Qwen3 系列模型支持&lt;/strong&gt;&amp;nbsp;（#5533）: 緊跟模型發展趨勢，集成最新的 Qwen3 系列大語言模型，為您提供更多先進模型選擇。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 AI Hub Mix 繪畫服務商&lt;/strong&gt;&amp;nbsp;（#4503）: 繪畫功能再添新翼，集成 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fideogram.ai" target="_blank"&gt;ideogram.ai&lt;/a&gt; 的商用級別模型，並有繪圖，放大，混合等不同生圖模式。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Bocha 網頁搜索服務商&lt;/strong&gt;&amp;nbsp;（#5608）: 引入 Bocha 作為新的網頁搜索選項，沒錯，就是 DeepSeek 官網背後的搜索提供商。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持 DashScope Reranker&lt;/strong&gt;&amp;nbsp;（#5725）: 集成 DashScope Reranker，提升搜索結果與知識匹配的相關性。後已進一步整合為通用 Reranker （#5818）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenAI 服務商增強&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Claude 模型支持網頁搜索&lt;/strong&gt;&amp;nbsp;（#5771）: 為 Claude 打通了網絡搜索能力，確實又快又準。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Gemini 安全設置調整&lt;/strong&gt;： Gemini 安全設置默認調整為關閉 （OFF），並升級了&amp;nbsp;@google/genai&amp;nbsp;依賴包 （#5763）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;MiniApps 生態擴展&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;核心交互與功能增強：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Cherry Studio 將有可能成為第一個同時支持&lt;strong&gt;函數調用 （Function Calling）&lt;/strong&gt;&amp;nbsp;和&lt;strong&gt;系統提示詞 （System Prompt）&lt;/strong&gt;&amp;nbsp;（#5499）的 MCP 工具！&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;MCP 實現&lt;strong&gt;登錄 Shell 環境檢索&lt;/strong&gt;&amp;nbsp;（#5739），增強了與本地環境的交互能力。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;更新 MCP 自動安裝服務名稱及服務註冊邏輯 （#5751）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;標準存儲協議：FTP，HTTP，SFTP，WebDAV 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;對象存儲服務：azblob，gcs，obs，oss，s3 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;文件存儲服務：fs， azdfs，hdfs，webhdfs， ipfs 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;消費級存儲服務（網盤）：Google Drive，OneDrive，Dropbox 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Key Value 存儲服務：Memory，Redis，Rocksdb 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;緩存服務：Ghac，Memcached 等&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;優化知識庫內容提取邏輯 （#5470） 和識別 （#5707）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;增強搜索功能，支持配置可選的 HTTP 選項 （#5765）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;網頁搜索按鈕新增「禁用網頁搜索」選項 （#5717）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增「**導出助手 （Agent）」**功能 （#5789），方便用戶分享和遷移個性化配置的助手。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;助手 （Agent） 支持配置「&lt;strong&gt;常用語」 （Regular Phrases）&lt;/strong&gt;&amp;nbsp;（#5775），並且這些常用語可以隨助手一同導出 （#5836）。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;對話主題自動重命名&lt;/strong&gt;&amp;nbsp;（#5504）: MessageThunk 集成此功能，可根據助手的回答智能更新當前對話的主題名稱，方便後續查找與管理。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;助手 （Agent） 能力提升&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;知識庫與搜索優化&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;遠程存儲方案&lt;/strong&gt;：新增基於&amp;nbsp;&lt;strong&gt;OpenDAL 的遠程存儲類&lt;/strong&gt;&amp;nbsp;（#2700），為數據備份與同步提供了更強大和靈活的基礎設施。以下方式都將成為可能：&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP （Model Control Program） 工具增強&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt 顯示控制&lt;/strong&gt;&amp;nbsp;（#5439）: 新增選項，允許用戶控制是否在界面中顯示完整的 Prompt 內容。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;消息翻譯功能增強&lt;/strong&gt;&amp;nbsp;（#5684）: 翻譯後的消息旁新增了「複製」和「關閉」按鈕，操作更便捷。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型健康檢查支持流式響應&lt;/strong&gt;&amp;nbsp;（#5546）: 提升了檢查效率和用戶感知。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;多窗口數據同步&lt;/strong&gt;&amp;nbsp;（#5592）: 實現跨窗口狀態同步，例如自定義 CSS （#5596），確保多窗口體驗一致性。&lt;strong&gt;（劃重點！！！多窗口！！！！！可以發揮想象了）&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;界面與視覺體驗改進：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;新增界面縮放比例設置&lt;/strong&gt;&amp;nbsp;（#5665）: 用戶可根據屏幕和偏好調整整體界面顯示大小，同時提供本地化支持。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;引入 Motion 動畫庫&lt;/strong&gt;&amp;nbsp;（#5869）: 為加載指示器 （Spinner）、消息塊等元素加入平滑動畫效果，提升視覺反饋的細膩度。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;右鍵菜單新增「檢查元素」選項&lt;/strong&gt;&amp;nbsp;（#5807）: 並支持本地化，方便開發者和高級用戶調試。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;引用列表樣式調整&lt;/strong&gt;&amp;nbsp;（#5516）: 對引用信息的展示樣式進行了優化。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;工具調用結果展示樣式優化&lt;/strong&gt;&amp;nbsp;（#5758）:&amp;nbsp;的結果顯示更加清晰易讀。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;開發者與高級用戶選項：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;支持自定義助手地址&lt;/strong&gt;&amp;nbsp;（#5540）: 允許用戶指定私有或第三方助手服務的 API 地址。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;新增開發文檔&lt;/strong&gt;&amp;nbsp;（#5476）: 添加了&amp;nbsp;messageBlock、messageThunk&amp;nbsp;和&amp;nbsp;useMessageOperations&amp;nbsp;的使用指南，方便二次開發或插件貢獻者。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;主窗口監視器&lt;/strong&gt;&amp;nbsp;（#5532）: WindowService 新增了對渲染進程事件的主窗口監視器功能。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;消息完成事件&lt;/strong&gt;&amp;nbsp;（#5696）: 現在會在消息處理完成時發出事件，供其他模塊或插件監聽。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;二、重要優化與重構&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了提升應用的整體性能和可維護性，我們進行了多項底層重構和專項優化：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;網絡搜索模塊重構&lt;/strong&gt;&amp;nbsp;（#5291）: 全面重構了網絡搜索模塊，顯著提升了其易用性和穩定性，並支持通過快捷菜單快速切換搜索引擎。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;消息塊 （Message Block） 結構與渲染優化&lt;/strong&gt;🎉&lt;/p&gt; &lt;p&gt;&lt;strong&gt;大活兒敲黑板！！&lt;/strong&gt;！Message Block 重構將為 MCP 調用，workflow/agent 運行，帶來更強的擴展性，大家可以猜 Cherry Studio 接下來的方向了！&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;對消息塊結構進行了重構 （#4660，&amp;nbsp;#5536），使其更加清晰和易於擴展。&lt;/li&gt; 
   &lt;li&gt;優化了消息塊的渲染性能，例如通過&amp;nbsp;useMemo&amp;nbsp;緩存圖像塊組，減少不必要的重複渲染 （#5722）。&lt;/li&gt; 
   &lt;li&gt;增強了圖片塊的渲染邏輯和樣式 （#5567）。&lt;/li&gt; 
   &lt;li&gt;優化主文本塊 （MainTextBlock） 內容處理，如忽略&amp;nbsp;tool_use&amp;nbsp;標記以改善特定場景的顯示 （#5483）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能提升專項&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優化&amp;nbsp;標籤的顯示性能 （#5489）。&lt;/li&gt; 
   &lt;li&gt;改進輸入框長文本粘貼性能 （#5580） 及按鈕狀態記憶 （#5577）。&lt;/li&gt; 
   &lt;li&gt;為快捷面板 （Quick Panel） 和模型選擇彈窗 （SelectModelPopup） 引入&lt;strong&gt;虛擬列表 （Virtual List）&lt;/strong&gt; （#5594），大幅提升了在項目或模型數量較多時的加載和滾動性能。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;架構與代碼質量&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;窗口管理優化&lt;/strong&gt;： 分離 MiniWindow 與 MainWindow 的加載邏輯 （#5581）；優化 WindowService 中右鍵菜單的設置 （#5589） 和標題欄樣式及主題切換邏輯 （#5633）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;文本處理中間件&lt;/strong&gt;： 新增&amp;nbsp;extractReasoningMiddleware&amp;nbsp;（#5637） 以增強對文本中推理過程的提取與處理。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;代碼清理&lt;/strong&gt;： 移除了未使用的選擇窗口 （#5586）、冗餘的局部變量 （#5654）、調試日誌 （#5722） 及無用文檔 （#5740），精簡了代碼庫。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;自定義 CSS 功能簡化&lt;/strong&gt;： 通過新引入的跨窗口狀態同步機制，簡化了自定義 CSS 的實現 （#5596）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;模型列表樣式優化&lt;/strong&gt;： 改進了模型列表的視覺樣式和分組邏輯 （#5674）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API/模型檢查邏輯優化&lt;/strong&gt;： 在檢查 API 或模型可用性時，優先嚐試啓用流式傳輸的檢查方式 （#5857）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;三、關鍵問題修復&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們細緻排查並修復了大量用戶反饋及內部測試發現的問題，以下列舉部分代表性修復：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;消息與知識庫&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;修復了消息在特定情況下未使用到知識庫內容的問題 （#5485）。&lt;/li&gt; 
   &lt;li&gt;修復了知識庫 URL 錯誤 （#5735） 和引用列表加載相關問題 （#5742）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP 與工具調用&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;修復了 MCP 調用失敗時，錯誤類型無法正確顯示的問題 （#5492）。&lt;/li&gt; 
   &lt;li&gt;改進了 MCP 工具錯誤消息的格式化和響應處理 （#5565）。&lt;/li&gt; 
   &lt;li&gt;修復了連接 OAuth MCP 服務器失敗的問題 （#5709）。&lt;/li&gt; 
   &lt;li&gt;修正了&amp;nbsp;MessageTools&amp;nbsp;中輸入 schema 引用的問題，確保工具定義準確性 （#5804）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型與服務商相關&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;修復了 Gemini 畫圖功能，並調整了默認圖片高度 （#5585，&amp;nbsp;#5658）。&lt;/li&gt; 
   &lt;li&gt;修復了 Qwen3 模型檢查邏輯 （#5811） 和思考模式切換的相關問題 （#5781&amp;nbsp;的補充修復）。&lt;/li&gt; 
   &lt;li&gt;修復了 OpenAI Provider 超時參數非整數的問題 （#5681）。&lt;/li&gt; 
   &lt;li&gt;處理了 Anthropic 服務商中 Base64 文件通過 IPC 和文件管理的問題 （#5595）。&lt;/li&gt; 
   &lt;li&gt;修復 Jina Embedding 錯誤 （#5839）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;界面與交互&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;修復了 TopicsTab 中使用&amp;nbsp;onMouseEnter&amp;nbsp;可能導致的問題，改為&amp;nbsp;onContextMenu&amp;nbsp;（#5459）。&lt;/li&gt; 
   &lt;li&gt;修復了中止操作時意外覆蓋 Block 狀態的問題 （#5547）。&lt;/li&gt; 
   &lt;li&gt;修復了流式響應中&amp;nbsp;thinking&amp;nbsp;狀態刷新不及時的問題 （#5557），以及&amp;nbsp;resetHasReasoningContent&amp;nbsp;的邏輯 （#5563）。&lt;/li&gt; 
   &lt;li&gt;確保&amp;nbsp;messageThunk&amp;nbsp;中只有在響應中不存在用量信息時才估算用量 （#5553）。&lt;/li&gt; 
   &lt;li&gt;修復了暗黑主題下引用列表顯示問題及 URL 重複請求的問題 （#5752）。&lt;/li&gt; 
   &lt;li&gt;修復了文件頁面滾動條異常 （#5619， 對應 #5618）。&lt;/li&gt; 
   &lt;li&gt;修復了代碼塊不必要的邊框和圓角 （#5773）。&lt;/li&gt; 
   &lt;li&gt;修復了輸入框在特定情況下&amp;nbsp;isComposing&amp;nbsp;狀態判斷不準 （#5848） 及焦點獲取 （#5860）、選區重置的問題 （#5866）。&lt;/li&gt; 
   &lt;li&gt;修復了 SelectModelPopup 中列表吸頂 （#5795） 和滾動行為 （#5812）。&lt;/li&gt; 
   &lt;li&gt;修復了條件性顯示「加載更多」微調器 （spinner） 的邏輯 （#5670） 和無限滾動佈局 （#5671）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;功能性修復&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;修復了&amp;nbsp;messageThunk&amp;nbsp;中重置消息邏輯，確保包含模型信息 （#5632）。&lt;/li&gt; 
   &lt;li&gt;修復了 WebDAV 本地備份文件存儲路徑錯誤的問題 （#5643）。&lt;/li&gt; 
   &lt;li&gt;規範化模型 ID 為小寫，確保一致性 （#5642）。&lt;/li&gt; 
   &lt;li&gt;修復了「網頁搜索」和「清除上下文」在某些情況下不工作的問題 （#5677）。&lt;/li&gt; 
   &lt;li&gt;修復了&amp;nbsp;StoreSyncService&amp;nbsp;在註冊 IPC 處理器時設置標誌的 bug （#5715）。&lt;/li&gt; 
   &lt;li&gt;修復了聊天消息翻譯的問題 （#5682）。&lt;/li&gt; 
   &lt;li&gt;確保在創建消息塊時包含&amp;nbsp;thinking_millsec&amp;nbsp;（#5685）。&lt;/li&gt; 
   &lt;li&gt;修復了記憶助手時未同時記憶所選模型的問題 （#5701）。&lt;/li&gt; 
   &lt;li&gt;修復了 MCP 服務器類型判斷邏輯 （#5769）。&lt;/li&gt; 
   &lt;li&gt;修復了從 MCP 響應中顯示圖片的問題 （#5780）。&lt;/li&gt; 
   &lt;li&gt;修復了用戶消息用量統計錯誤 （#5657）。&lt;/li&gt; 
   &lt;li&gt;修復了一系列下一版本（指 1.3.0）發佈前的各類小問題 （#5801）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;四、其他更新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;國際化 （i18n）&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;補充了俄語缺失的翻譯 （#5631）。&lt;/li&gt; 
   &lt;li&gt;更新了多語言機器翻譯文本，採用 Qwen3 236B 模型進行翻譯 （#5840）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;依賴更新&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;升級&amp;nbsp;electron-updater&amp;nbsp;至 v6.6.4 並移除了相關補丁 （#5650）。&lt;/li&gt; 
   &lt;li&gt;升級&amp;nbsp;electron-builder&amp;nbsp;至 v26.0.15 （#5651）。&lt;/li&gt; 
   &lt;li&gt;這些更新有助於提升應用的底層穩定性和打包效率。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;文檔&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;新增了項目**架構概覽文檔** （#5824）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Cherry Studio v1.3.0 是一次包含了大量改進的綜合性版本更新，不僅致力於新的功能，更持續投入前瞻的技術路線，並積極修復各類已知問題。都旨在提供一個更加先進，穩定，高效且易於使用的 AI 交互與管理平台。&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCherryHQ%2Fcherry-studio%2Freleases%2Ftag%2Fv1.3.3" target="_blank"&gt;https://github.com/CherryHQ/cherry-studio/releases/tag/v1.3.3&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350183/cherry-studio-1-3-3</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350183/cherry-studio-1-3-3</guid>
      <pubDate>Sun, 11 May 2025 03:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Dify.AI 開源兩週年更新品牌形象，堅持「讓每一個想法變成 AI Agent」的使命</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源 AI 應用開發平台 Dify.AI &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdify.ai%2Fblog%2Four-vision-takes-shape-imagine-if" target="_blank"&gt;迎來了兩週年&lt;/a&gt;。在慶祝之際，Dify 發佈了全新的品牌形象和外觀。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111845_qi60_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a96b9b86bb6e4f0894313ba038203e4ef27.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Dify 的使命保持不變，即讓每一個想法都能變成 AI Agent。新的品牌口號強調&lt;strong&gt;「如果」你能想到，通過 Dify 你就能構建它&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/111557_HOat_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350181</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350181</guid>
      <pubDate>Sun, 11 May 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Ollama 發佈 v0.7.0，增強多模態能力並引入多項優化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ollama v0.7.0 已發佈，帶來了顯著的功能增強和性能優化，引入了新引擎支持多模態模型，並支持 WebP 圖像作為輸入。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Flibrary%2Fllama4" target="_blank"&gt;Meta Llama 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Flibrary%2Fgemma3" target="_blank"&gt;Google Gemma 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Flibrary%2Fqwen2.5vl" target="_blank"&gt;Qwen 2.5 VL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Flibrary%2Fmistral-small3.1" target="_blank"&gt;Mistral Small 3.1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Fsearch%3Fc%3Dvision" target="_blank"&gt;以及更多視覺模型&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1544228c9bc0e0796a2f5bdf0b0f977cc61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他更新內容包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復 Windows 上運行模型出現的空白終端窗口&lt;/li&gt; 
 &lt;li&gt;修復&amp;nbsp;&lt;code&gt;NVIDIA GPU&lt;/code&gt;&amp;nbsp;運行&amp;nbsp;&lt;code&gt;Llama 4&lt;/code&gt;&amp;nbsp;的錯誤&lt;/li&gt; 
 &lt;li&gt;優化&amp;nbsp;&lt;code&gt;ollama run&lt;/code&gt;&amp;nbsp;發送圖片時去除引號&lt;/li&gt; 
 &lt;li&gt;提升&amp;nbsp;&lt;code&gt;ollama create&lt;/code&gt;&amp;nbsp;導入&amp;nbsp;&lt;code&gt;safetensors&lt;/code&gt;&amp;nbsp;模型性能&lt;/li&gt; 
 &lt;li&gt;提升&amp;nbsp;&lt;code&gt;Qwen3 MoE&lt;/code&gt;&amp;nbsp;在&amp;nbsp;&lt;code&gt;macOS&lt;/code&gt;&amp;nbsp;上的提示處理速度&lt;/li&gt; 
 &lt;li&gt;修復結構化輸出請求中大型&amp;nbsp;&lt;code&gt;JSON&lt;/code&gt;&amp;nbsp;模式導致錯誤&lt;/li&gt; 
 &lt;li&gt;API 對不允許方法返回&amp;nbsp;&lt;code&gt;405&lt;/code&gt;&amp;nbsp;錯誤碼&lt;/li&gt; 
 &lt;li&gt;以及修復模型卸載後進程持續運行的問題&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;Ollama 是一個開源的本地大語言模型運行框架，簡化了利用 llama.cpp 後端運行各種 LLM 以及與其他桌面軟件方便集成的過程，為普通用戶提供簡單易用的大語言模型（LLM）的本地部署和管理。&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;它支持多種先進的模型，如 LLaMA、DeepSeek、Mistral 等，並提供簡單易用的界面和 API。Ollama 的特點包括輕量級設計、跨平台支持（Windows、Linux、macOS）、模型微調與自定義功能，以及高效的推理性能。&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;由於其便捷性和開源特性，Ollama 獲得了大量用戶的青睞，被廣泛用於本地部署 DeepSeek 等大模型。&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0304/120325_4P9T_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama%2Freleases%2Ftag%2Fv0.7.0" target="_blank"&gt;https://github.com/ollama/ollama/releases/tag/v0.7.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350178/ollama-0-7-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350178/ollama-0-7-0</guid>
      <pubDate>Sun, 11 May 2025 03:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 推遲發佈旗艦級 AI 模型 Behemoth</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#31424e; margin-left:0; margin-right:0; text-align:start"&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1knh1yd%2Fmeta_delaying_the_release_of_behemoth%2F" target="_blank"&gt;根據《華爾街日報》的獨家報道&lt;/a&gt;&lt;/u&gt;，Meta 推遲了其旗艦級 AI 模型 Behemoth 的發佈計劃，因為擔心它可能不足以超越之前的模型。&lt;/p&gt; 
&lt;p style="color:#31424e; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="728" src="https://static.oschina.net/uploads/space/2025/0516/110114_Pa6U_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報道稱，《Behemoth》預計將於秋季甚至更晚發佈。它原定於上個月與 Meta 的 Llamacon 活動同時發佈，後來被推遲到六月。該公司也有可能加快 Behemoth 的有限發佈速度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-723de3325b3806234d8d9a1c426f8427caf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Meta 在其人工智能項目上投入了數百億美元，直到最近，它才取得了快速進展，趕上了谷歌和 OpenAI 等競爭對手。Meta 的失望反映了人工智能行業內部更廣泛的擔憂，即依賴於擴大模型的進步可能會陷入停滯。&lt;/p&gt; 
&lt;p style="color:#31424e; margin-left:0; margin-right:0; text-align:start"&gt;OpenAI 在推出 GPT 4.0 之後的一體化下一代大型模型方面面臨着諸多障礙。因此，這家 ChatGPT 開發者推出了一系列獨立的模型，其中一些專注於推理，另一些專注於編碼和技術工作。據報道，谷歌和 Anthropic 在最近訓練最大模型的努力中也遇到了挫折。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350173/meta-is-delaying-release-its-behemoth-ai-model</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350173/meta-is-delaying-release-its-behemoth-ai-model</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里：AI 將通過雲端涉及各行各業</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月 15 日，阿里巴巴集團公佈 2025 財年第四季度及全年業績。 &amp;nbsp; &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/104842_qqHa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據財報，截至 2025 年 3 月 31 日止季度，收入為人民幣 2364.54 億元（325.84 億美元），同比增長 7%。經營利潤為人民幣 284.65 億元（39.23 億美元），同比增長 93%；歸屬於普通股股東的淨利潤為人民幣 123.82 億元（17.06 億美元）；淨利潤為人民幣 119.73 億元（16.50 億美元），同比增長 1203%。&lt;/p&gt; 
&lt;p&gt;截至 2025 年 3 月 31 日止財務年度，收入為人民幣 9963.47 億元（1373.00 億美元），同比增長 6%；經營利潤為人民幣 1,409.05 億元（194.17 億美元），同比增長 24%；歸屬於普通股股東的淨利潤為人民幣 1294.70 億元（178.41 億美元）；淨利潤為人民幣 1259.76 億元（173.60 億美元），同比增長 77%。2025 財年的非公認會計準則淨利潤為人民幣 1581.22 億元（217.90 億美元），相較於 2024 財年的人民幣 1574.79 億元保持平穩。&lt;/p&gt; 
&lt;p&gt;其中阿里雲表現突出：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;截至 2025 年 3 月 31 日止的季度，阿里雲收入 301.27 億元同比增長 18%，AI 相關收入連續七個季度三位數增長。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;阿里方面表示，&lt;strong&gt;這一增長勢頭主要由更快的公共雲收入增長帶動，包括 AI 相關產品的採用增加&lt;/strong&gt;。AI 相關產品在眾多的行業垂直領域獲得更廣泛應用，包括互聯網、零售、製造業和媒體，並越來越側重於增值應用。&lt;/p&gt; 
&lt;p&gt;而在隨後的財報分析師電話會上，阿里雲表示，目前仍有很多中小企業或者個人商戶需要應用 AI，但本地佈局成本較高，隨着 AI 的強大動力搬遷至雲端，像養殖業、製造業，甚至是義烏小商品城，都能夠通過雲端進行 AI 佈局從而幫助自身。&lt;/p&gt; 
&lt;p&gt;阿里進一步表示，未來幾個季度阿里雲的營收增速還在處於一個上升通道。其認為，基於傳統的 CPU 的計算在轉向 AI 計算，就現在看到的情況而言，阿里雲對未來幾個季度阿里雲的營收增速還在處於一個上升通道，還是抱有一個比較強的信心。&lt;/p&gt; 
&lt;p&gt;值得一提的是，今年 2 月阿里巴巴集團 CEO 吳泳銘宣佈，未來三年，阿里將投入超過 3,800 億元，用於建設雲和 AI 硬件基礎設施，總額超過去十年總和。&lt;/p&gt; 
&lt;p&gt;阿里雲方面也強調，&lt;strong&gt;其正以 AI 為中心，全面重構底層硬件、計算、存儲、大數據等各方面，並與 AI 場景有機適配、融合，加速模型的開發和應用，打造一個 AI 時代的最強 AI 基建&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350167</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350167</guid>
      <pubDate>Sun, 11 May 2025 02:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 Copilot 應用開始支持「Hey Copilot」語音喚醒詞</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟於 5 月 14 日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F05%2F14%2Fcopilot-on-windows-hey-copilot-begins-rolling-out-to-windows-insiders%2F" target="_blank"&gt;發佈博文&lt;/a&gt;，邀請 Windows Insider 項目成員測試新版 Microsoft Copilot 應用程序（版本 1.25051.10.0 及以上）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5a34382c61b9b7b18278a027534f39f7e0d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用戶在新版 Copilot 應用中啓用相關選項後，可通過「Hey Copilot」喚醒詞，在 PC 解鎖且功能開啓時、喚醒 Copilot 開啓 AI 聊天，無需點擊或輸入。微軟表示，用戶在工作或思考時無需手動操作，即可獲得幫助。&lt;/p&gt; 
&lt;p&gt;提問時，屏幕會顯示 Copilot 麥克風圖標，並伴隨提示音，表明 Copilot 正在傾聽。結束對話可點擊 X 按鈕，或在幾秒無交互後自動結束，併發出確認音。&lt;/p&gt; 
&lt;p&gt;微軟強調，設備僅在本地識別喚醒詞，採用 10 秒內存音頻緩衝區，不錄音或本地存儲數據。一旦識別到喚醒詞，Copilot Voice 浮動界面將出現，隨後音頻會傳輸至雲端處理用戶請求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350160/copilot-on-windows-hey-copilot</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350160/copilot-on-windows-hey-copilot</guid>
      <pubDate>Sun, 11 May 2025 02:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>雷軍：小米自研手機 SoC 芯片「玄戒 O1」將於 5 月下旬發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;小米集團創始人雷軍發佈微博透露，造芯十年，小米自主研發設計的手機 SoC 芯片名字叫「玄戒 O1」，將在 5 月下旬發佈。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;和大家分享一條消息：&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;小米自主研發設計的手機 SoC 芯片，名字叫，玄戒 O1，即將在 5 月下旬發佈。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;感謝大家支持！&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="266" src="https://oscimg.oschina.net/oscnet/up-a36d75d9b55368c7956744282be4ebb4cec.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="274" src="https://oscimg.oschina.net/oscnet/up-4d662277ff9587e8953da3929f020383f21.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對此，人民網也發文點評稱：「最近一年，小米在新能源汽車、國產芯片等領域接連帶來突破創新。這證明瞭，只要堅定實幹，就沒有不可逾越的高山；只要奮起直追，後來者永遠有機會。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="332" src="https://oscimg.oschina.net/oscnet/up-5bd8371176fd6755e7b2635cd8c858f5fce.png" width="500" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350157</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350157</guid>
      <pubDate>Sun, 11 May 2025 02:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 發佈語音模型 MiniMax Speech 02</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniMax 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4pa3KCRLwDlVZHCA_9R0iA"&gt;推出&lt;/a&gt;基於 AR Transformer 模型的高質量 TTS 系統 ——MiniMax Speech 02。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6f2d41090b2c4d82bff733ccc15046faf46.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;MiniMax Speech 02 具有足夠強的泛化能力，&lt;strong&gt;能夠輕鬆駕馭 32 語種、不同口音、不同情緒的人聲&lt;/strong&gt;。該模型系統的核心創新之處在於其內在的 Zero-Shot 能力，其命為 Intrinsic Zero-Shot Text-to-Speech with a Learnable Speaker Encoder。&lt;/p&gt; 
&lt;p&gt;在提供更優異聽感同時，MiniMax Speech 02 做到了價格更低，分別是 ElevenLabs Flash V2.5 與 Mutilingual V2 的一半與四分之一。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0516/101019_9RYc_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在國際權威的 Artificial Analysis 上，MiniMax Speech 02 也通過全球用戶測評，位列全球第一。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0516/100728_YHJY_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0516/100932_INxq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;體驗 MiniMax Speech&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.minimax.io%2Faudio"&gt;https://www.minimax.io/audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.minimaxi.com%2Faudio"&gt;https://www.minimaxi.com/audio&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多技術細節、實驗對比數據、以及開源的多語言測試集，閲讀技術報告&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMiniMax-AI%2FMiniMax-AI.github.io%2Fblob%2Fmain%2Ftts_tech_report%2FMiniMax_Speech.pdf"&gt;https://github.com/MiniMax-AI/MiniMax-AI.github.io/blob/main/tts_tech_report/MiniMax_Speech.pdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FMiniMaxAI%2FMiniMax-Speech-Tech-Report"&gt;https://huggingface.co/spaces/MiniMaxAI/MiniMax-Speech-Tech-Report&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350155/minimax-speech-02</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350155/minimax-speech-02</guid>
      <pubDate>Sun, 11 May 2025 02:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>梁文鋒等發表 DeepSeek V3 回顧性論文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 創始人梁文鋒等人近日發表了一篇名為《Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for Al Architectures（深入瞭解 DeepSeek-V3：人工智能架構硬件的擴展挑戰與思考）》的回顧性論文。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;深入分析了 DeepSeek-V3/R1 模型架構及其人工智能基礎架構，重點介紹了一些關鍵創新，如提高內存效率的多頭潛意識（MLA）、優化計算與通信權衡的混合專家（MoE）架構、釋放硬件能力全部潛力的 FP8 混合精度訓練，以及最大限度降低集羣級網絡開銷的多平面網絡拓撲結構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-7d3d04217f33b8b740ddaf8bd1753b2ce4b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該研究表明，當前大語言模型（LLM）的迅速擴展暴露了現有硬件架構的許多侷限性，比如內存容量、計算效率和互連帶寬。DeepSeek-V3 在 2048 塊 NVIDIA H800GPU 集羣上訓練，通過有效的硬件感知模型設計，克服了這些限制，實現了經濟高效的大規模訓練和推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="348" src="https://oscimg.oschina.net/oscnet/up-1fa090ba2ba63a45ee9c1b284fe2b778ca0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;具體來説，論文中提出了幾個關鍵點。首先，DeepSeek-V3 採用了先進的 DeepSeekMoE 架構和多頭潛在注意力（MLA）架構，極大地提高了內存效率。MLA 技術通過壓縮鍵值緩存，顯著降低了內存使用，使得每個 token 只需 70KB 的內存，相比其他模型大幅減少。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其次，DeepSeek 還實現了成本效益的優化。通過其混合專家（MoE）架構，DeepSeek-V3 在激活參數的數量上實現了顯著的降低，訓練成本相比於傳統密集模型降低了一個數量級。此外，該模型在推理速度上也進行了優化，採用雙微批次重疊架構來最大化吞吐量，確保 GPU 資源得到充分利用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 在未來硬件設計方面提出了創新的思考。他們建議通過聯合優化硬件和模型架構，來應對 LLM 的內存效率、成本效益和推理速度三大挑戰。這為日後的 AI 系統開發提供了寶貴的參考。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;更多詳情可查看具體論文：&lt;/span&gt;&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2505.09343" target="_blank"&gt;https://arxiv.org/pdf/2505.09343&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350152</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350152</guid>
      <pubDate>Sun, 11 May 2025 01:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Go 語言讀寫 Excel 基礎庫</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src="https://xuri.me/excelize/images/excelize.svg" alt="Excelize" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuri%2Fexcelize" target="_blank"&gt;Excelize&lt;/a&gt; 是 Go 語言編寫的一個用來操作 Office Excel 文檔類庫，基於 ECMA-376 Office OpenXML 標準。可以使用它來讀取、寫入 XLSX 文件。相比較其他的開源類庫，Excelize 支持寫入原本帶有圖片 (表) 的文檔，還支持向 Excel 中插入圖片，並且在保存後不會丟失圖表樣式。&lt;/p&gt; 
&lt;h3&gt;安裝&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/xuri/excelize/v2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;創建 XLSX&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "fmt"

    "github.com/xuri/excelize/v2"
)

func main() {
    f := excelize.NewFile()
    // Create a new sheet.
    index := f.NewSheet("Sheet2")
    // Set value of a cell.
    f.SetCellValue("Sheet2", "A2", "Hello world.")
    f.SetCellValue("Sheet1", "B2", 100)
    // Set active sheet of the workbook.
    f.SetActiveSheet(index)
    // Save xlsx file by the given path.
    err := f.SaveAs("./Book1.xlsx")
    if err != nil {
        fmt.Println(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;讀取已有文檔&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "fmt"

    "github.com/xuri/excelize/v2"
)

func main() {
    f, err := excelize.OpenFile("./Book1.xlsx")
    if err != nil {
        fmt.Println(err)
        return
    }
    // Get value from cell by given worksheet name and axis.
    cell, err := f.GetCellValue("Sheet1", "B2")
    if err != nil {
        fmt.Println(err)
        return
    }
    fmt.Println(cell)
    // Get all the rows in the Sheet1.
    rows, err := f.GetRows("Sheet1")
    for _, row := range rows {
        for _, colCell := range row {
            fmt.Print(colCell, "\t")
        }
        fmt.Println()
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;向 Excel 中插入圖表&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/xuri/excelize/master/test/images/chart.png?version=1" alt="chart" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "fmt"

    "github.com/xuri/excelize/v2"
)

func main() {
    categories := map[string]string{"A2": "Small", "A3": "Normal", "A4": "Large", "B1": "Apple", "C1": "Orange", "D1": "Pear"}
    values := map[string]int{"B2": 2, "C2": 3, "D2": 3, "B3": 5, "C3": 2, "D3": 4, "B4": 6, "C4": 7, "D4": 8}
    f := excelize.NewFile()
    for k, v := range categories {
        f.SetCellValue("Sheet1", k, v)
    }
    for k, v := range values {
        f.SetCellValue("Sheet1", k, v)
    }
    err := f.AddChart("Sheet1", "E1", `{"type":"col3DClustered","series":[{"name":"Sheet1!$A$2","categories":"Sheet1!$B$1:$D$1","values":"Sheet1!$B$2:$D$2"},{"name":"Sheet1!$A$3","categories":"Sheet1!$B$1:$D$1","values":"Sheet1!$B$3:$D$3"},{"name":"Sheet1!$A$4","categories":"Sheet1!$B$1:$D$1","values":"Sheet1!$B$4:$D$4"}],"title":{"name":"Fruit 3D Clustered Column Chart"}}`)
    if err != nil {
        fmt.Println(err)
        return
    }
    // Save xlsx file by the given path.
    err = f.SaveAs("./Book1.xlsx")
    if err != nil {
        fmt.Println(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;向 Excel 中插入圖片&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "fmt"
    _ "image/gif"
    _ "image/jpeg"
    _ "image/png"

    "github.com/xuri/excelize/v2"
)

func main() {
    f, err := excelize.OpenFile("./Book1.xlsx")
    if err != nil {
        fmt.Println(err)
        return
    }
    // Insert a picture.
    err = f.AddPicture("Sheet1", "A2", "./image1.png", "")
    if err != nil {
        fmt.Println(err)
    }
    // Insert a picture to worksheet with scaling.
    err = f.AddPicture("Sheet1", "D2", "./image2.jpg", `{"x_scale": 0.5, "y_scale": 0.5}`)
    if err != nil {
        fmt.Println(err)
    }
    // Insert a picture offset in the cell with printing support.
    err = f.AddPicture("Sheet1", "H2", "./image3.gif", `{"x_offset": 15, "y_offset": 10, "print_obj": true, "lock_aspect_ratio": false, "locked": false}`)
    if err != nil {
        fmt.Println(err)
    }
    // Save the xlsx file with the origin path.
    err = f.Save()
    if err != nil {
        fmt.Println(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;還有其他一些功能，在這裏就不一一列舉了，詳細使用文檔以及獲取後期的維護更新可以從項目的主頁獲取&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuri%2Fexcelize" target="_blank"&gt;github.com/xuri/excelize&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/xuri/blog/3057381</link>
      <guid isPermaLink="false">https://my.oschina.net/xuri/blog/3057381</guid>
      <pubDate>Sat, 10 May 2025 10:24:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
