<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 23 Apr 2025 16:36:43 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>xAI 的 Grok 聊天機器人支持實時視覺功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據 Techcrunch 報道，&lt;strong&gt;xAI 已為 Grok 聊天機器人增加視覺功能 Grok Vision&lt;/strong&gt;，幫助用戶解答關於攝像頭所見內容的問題。&lt;/p&gt; 
&lt;p&gt;升級之後，Grok 移動端用戶可以將手機對準產品、標誌和文件等物體，並提出相關問題。Grok Vision 目前僅支持 iOS 版 Grok 應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b1db3344291b4e8787adf1e686b6f23a2d4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d91298927f4eabcf29649dfe6e075f74213.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，Grok 今天還推出了包括多語言音頻和 Grok 語音模式下的實時搜索等其他新功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346212/xais-grok-chatbot-can-now-see-the-world-around-it</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346212/xais-grok-chatbot-can-now-see-the-world-around-it</guid>
            <pubDate>Sun, 13 Apr 2025 10:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apache Airflow 3 正式發佈，開源分佈式工作流平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Apache Airflow 3.0.0 已正式&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairflow.apache.org%2Fblog%2Fairflow-three-point-oh-is-here%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;。公告寫道，這是「四年磨一劍的重磅更新」：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Airflow 3.0 是 Airflow 歷史上最大的發佈——2.0 版本於 2020 年推出，過去 4 年見證了每季度都有增量更新和發佈，2024 年第四季度發佈了 2.10 版本。&lt;/p&gt; 
 &lt;p&gt;隨着 Airflow 的月度下載量超過 3000 萬次（自 2020 年以來增長了 30 倍以上），以及現在有 80000 個組織（2020 年為 25000 個）正在使用 Airflow，自 2.0 版本以來，我們見證了其流行度的驚人增長。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Apache Airflow 3 更新亮點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Airflow 3 對數據從業者來説使用起來更加簡單，新變化包括基於 React 的新 UI、DAG 版本控制和改進的 Backfill 支持&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在資產導向型工作流和任務導向型工作流之間無縫的 UI 過渡非常美觀。Airflow 再次讓開發者選擇他們想要如何開發和導航，而不強加任何限制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;事件驅動調度的引入使 Airflow 能夠無縫集成消息提供者，並對外部 Airflow 發生的事件和數據資產更新做出反應。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過引入任務執行接口和任務 SDK，實現了更強大的安全模型，包括在多雲、混合雲和本地數據中心部署中的安全、可擴展執行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;850&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/164454_2lbk_2720166.gif&quot; width=&quot;1480&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1246&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/165017_xRQ6_2720166.gif&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1da0e02ce4ae2c2c769ae168eb0bc167934.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於 UI 的更多變化請查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fairflow.apache.org%2Fdocs%2Fapache-airflow%2Fstable%2Fui.html&quot; target=&quot;_blank&quot;&gt;https://airflow.apache.org/docs/apache-airflow/stable/ui.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fairflow%2Freleases%2Ftag%2F3.0.0&quot; target=&quot;_blank&quot;&gt;https://github.com/apache/airflow/releases/tag/3.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346194/airflow-3-0-ga</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346194/airflow-3-0-ga</guid>
            <pubDate>Sun, 13 Apr 2025 08:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>理想自研汽車操作系統「星環 OS」公佈開源代碼</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今年 3 月，理想汽車董事長兼 CEO 李想在中關村論壇年會上&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/341314&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;，理想汽車自研整車操作系統 ——「理想星環 OS」將全面開源，並於 4 月登陸開源社區，成為全球首個將整車操作系統開源的車企。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-02c75b03715cf0075c5c328ac3469a27dc9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;上週，理想汽車發佈了「&lt;a href=&quot;https://www.oschina.net/news/344690/lixiang-haloos-opensource-comming-soon&quot;&gt;理想星環 OS 技術架構白皮書&lt;/a&gt;」，並表示「理想星環 OS」的開源計劃將於 4 月 23 日啓動，開源模塊涵蓋車控操作系統、智能駕駛操作系統、通信中間件、虛擬化平台等核心組件。&lt;/p&gt; 
&lt;p&gt;整個過程將分為三個階段進行，第一步先開源車輛控制系統，第二步是完整的車控系統和智能駕駛系統的基礎能力，第三步是完整的智能駕駛系統和虛擬化能力。最終目標是構建一個活躍的星環 OS 開源社區，推動技術共享與合作。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0415/152220_QMrL_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;4 月 23 日開源星環 OS 0.1.0 版本&lt;/strong&gt;，包括安全實時 RTOS、通信總線 Lite&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;6 月 30 日開源星環 OS 1.0.0 版本，包括完整的智能車控系統、智能駕駛系統基礎能力&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;7 月後開源完整的智能駕駛系統，包括虛擬化引擎&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;就在今天，理想汽車已正式入駐&lt;/span&gt;國內領先的開源代碼託管平台 Gitee，為理想星環 OS 創建了開源組織：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/145233_2m1R_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;理想星環 OS（LiAuto HaloOS） 開源社區主頁：&lt;a href=&quot;https://gitee.com/haloos&quot; target=&quot;_blank&quot;&gt;https://gitee.com/haloos&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根據介紹，理想星環 OS 是一款面向人工智能時代的開源汽車操作系統，包含&lt;strong&gt;智能車控、智能駕駛、通信中間件、信息安全系統&lt;/strong&gt;四大重要支柱，採用了寬鬆開源許可證 Apache License V2.0，目前開源的代碼主要是&lt;strong&gt;智能車控 OS 和通信總線 Lite&lt;/strong&gt;部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/152724_VzTz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;關於理想星環 OS 的更多技術細節請查看：&lt;a href=&quot;https://gitee.com/haloos&quot;&gt;https://gitee.com/haloos&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;閲讀更多&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/341314&quot; target=&quot;_blank&quot;&gt;李想官宣開源整車操作系統「星環 OS」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344690/lixiang-haloos-opensource-comming-soon&quot; target=&quot;_blank&quot;&gt;理想汽車發佈「理想星環 OS 技術架構白皮書」，4 月底開始逐步開放各模塊源代碼&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346185/liauto-haloos-gitee</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346185/liauto-haloos-gitee</guid>
            <pubDate>Sun, 13 Apr 2025 08:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Rowboat —— 低代碼 AI IDE</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.87)&quot;&gt;Rowboat 是一款低代碼 AI IDE，用於構建連接多智能體助手的 MCP 工具。Rowboat Copilot 會根據你的需求為您構建智能體，並且你也可以選擇手動完成所有操作。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;RowBoat 是一個先進的平台，可以在 copilot 的幫助下在可視化界面中構建&amp;nbsp;multi-agent AI 系統。&lt;/p&gt;

&lt;p&gt;RowBoat 讓你能夠構建、管理和部署面向用戶的助手。助手由多個代理組成，每個代理都可以訪問一組工具，並協同工作，以單個助手的形式與用戶交互。可以將任何 MCP 工具連接到代理。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;從一個想法開始 -&amp;gt; copilot 構建你的 multi-agent&amp;nbsp;工作流程&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;例如，「為我開發一個食品配送公司的助手，用於處理配送狀態和丟失的物品。包括必要的工具。」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;連接 MCP 服務器&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;在設置中添加 MCP 服務器 -&amp;gt; 將工具導入 Rowboat。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用 HTTP API 或 Python SDK 集成到你的應用中&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;從設置中獲取項目 ID 和生成的 API 密鑰並使用 API。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 OpenAI 的 Agents SDK 的支持下，Rowboat 是構建 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;multi-agents&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的最快方式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/rowboat</link>
            <guid isPermaLink="false">https://www.oschina.net/p/rowboat</guid>
            <pubDate>Sun, 13 Apr 2025 07:43:00 GMT</pubDate>
        </item>
        <item>
            <title>彭博社：英特爾計劃裁員 21000 多人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#212623&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-23%2Fintel-to-announce-plans-this-week-to-cut-more-than-20-of-staff%3Fsrnd%3Dhomepage-americas&quot; target=&quot;_blank&quot;&gt;彭博社報道&lt;/a&gt;稱，&amp;nbsp;英特爾將於本週宣佈裁員 21,000 多人，約佔其員工總數的 20%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#212623&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這一消息是在英特爾第一季度財報電話會議之前發佈的，此次電話會議由新任命的首席執行官陳立武 (Lip-Bu Tan) 主持，陳立武去年接替了長期擔任首席執行官的帕特·基辛格 (Pat Gelsinger)。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;img height=&quot;318&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-53de2e1fffc36ebb6422e7e66816d5e2397.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#212623&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彭博社指出，陳立武希望通過此次裁員「精簡管理，重建以工程為導向的文化」。該公司於 2024 年 8 月宣佈將裁員 1.5 萬人，截至去年年底，員工總數約為 10.89 萬人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#212623&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;英特爾長期以來一直舉步維艱；過去五年，該公司股價已下跌約 67%。自 2024 年底出任首席執行官以來，陳立武已着手將英特爾旗下各部門拆分為「非核心」部門。本月早些時候，英特爾將其 Altera 半導體業務 51% 的股份出售給私募股權公司銀湖資本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:auto !important; margin-right:auto !important; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#212623&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;英特爾沒有立即回應置評請求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346173/intel-plans-lay-off-over-21000-employees</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346173/intel-plans-lay-off-over-21000-employees</guid>
            <pubDate>Sun, 13 Apr 2025 07:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>智元機器人開源仿真評測工具 Genie Sim Benchmark</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元機器人&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvAk6c0rzo6ps43uZsIc3kA&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出並開源基於仿真功能的模型評測和驗證工具 Genie Sim Benchmark，專注為具身 AI 模型提供精準的性能測試和優化支持。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「作為 Genie Sim(智元仿真平台) 的開源評測版本，Genie Sim Benchmark 是智元繼開源百萬真機數據集和海量仿真數據集後，又一里程碑式的開源項目。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，Genie Sim 能夠精準還原機器人的操作環境，為多樣化任務提供標準化的自動評測體系，衡量模型在各種場景下的表現，加速算法迭代流程，同時減少模型評測對昂貴物理硬件的依賴，顯著降低測試成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;218&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2361db80f04bdb27b0c1364779ea48b7643.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Genie Sim 構建了大規模的高精度具身智能三維資產庫，形成了涵蓋豐富物體、場景及機器人模型的完整仿真體系。所有資產均採用人工精細建模、三維重建與生成式 AI（AIGC）等技術打造，在確保高度真實性的同時兼顧種類多樣性和資產生成效率，全面滿足機器人複雜操作任務的仿真評測需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bea77c14e21ac2be1c31034ea2d73f3cb0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;還提供了基於場景重建的高保真、高精度的仿真評測環境，涵蓋多種場景和物體，高度還原真實世界。Genie Sim 的仿真評測環境能夠模擬真實世界中影響算法性能的條件和變量，為模型評測提供高度真實的測試基準。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元方面表示，經對比驗證，GO-1 模型仿真測試結果與真機結果誤差小於 5%。這一仿真精度的突破源於對真機測試環境和交互物體在仿真環境中進行完全 1:1 的還原，以及底盤、關節和末端控制動力學與真機的精準校準。算法開發者可以高度信賴模型在仿真中的評測結果，大幅減少真機測試次數，使算法迭代效率提升 5 倍以上，測試成本減少 95%，助力研發團隊專注核心算法優化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346159</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346159</guid>
            <pubDate>Sun, 13 Apr 2025 06:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>QEMU 10.0 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QEMU 10.0 版本現已推出，一些更新&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FQEMU-10.0-Released&quot; target=&quot;_blank&quot;&gt;亮點&lt;/a&gt;如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基於 LoongArch 的 KVM QEMU 現在支持 CPU 熱插拔、para-virtualzied IPI、steam time 等功能。&lt;/li&gt; 
 &lt;li&gt;RISC-V QEMU 支持多種新的 ISA/擴展，添加了 Tenstorrent Ascalon CPU、Xiangshan Nanhu CPU 以及 Microblaze-V 通用主板。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 添加了英特爾 Clearwater Forest CPU 型號。此外，還有一個 Sierra Forest 「v2」 CPU 型號，與 QEMU 的原始 Sierra Forest CPU 型號相比有所改進。&lt;/li&gt; 
 &lt;li&gt;VirtIO SCSI 設備在 QEMU 10.0 中獲得了「真正的」多隊列支持。這種適當的多隊列支持可以增強 I/O 可擴展性。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 圖形代碼添加了新的「apple-gfx-pci」和「apple-gfx-mmio」設備，以便使用 macOS 主機的 para-virtualized&amp;nbsp;圖形框架為 macOS 客戶機提供加速圖形。apple-gfx-pci 適用於 x86_64 guests，而 apple-gfx-mmio 適用於 AArch64 macOS。&lt;/li&gt; 
 &lt;li&gt;QEMU 10 的 VFIO 代碼改進了所有 Gen11 和 Gen12 硬件的 Intel IGD 圖形設備 pass-through 功能。&lt;/li&gt; 
 &lt;li&gt;QEMU VFIO 代碼還增加了對舊版 ATI X550 GPU 的支持。&lt;/li&gt; 
 &lt;li&gt;Linux AIO 和 IO_uring 後端現在可以使用「RWF_DSYNC」標誌進行 FUA 寫入請求，而不是依賴模擬來提高已禁用寫入緩存的 guest disks 性能。&lt;/li&gt; 
 &lt;li&gt;改進了 QEMU 文檔。&lt;/li&gt; 
 &lt;li&gt;繼續致力於在 QEMU 中支持更多 Rust 編程語言的使用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多詳細信息可參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.qemu.org%2FChangeLog%2F10.0&quot; target=&quot;_blank&quot;&gt;Wiki 發行説明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qemu.org%2Fdownload%2F%23source&quot; target=&quot;_blank&quot;&gt;下載地址&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346156/qemu-10-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346156/qemu-10-0-released</guid>
            <pubDate>Sun, 13 Apr 2025 06:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>探索 AI 未來：Xinference v1.5.0 模型虛擬空間全新上線！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Xorbits Inference（Xinference）是一個，性能強大且功能全面的，分佈式，推理框架。可用於大語言模型（LLM），語音識別模型，多模態模型等各種模型的推理。通過 Xorbits Inference，你可以輕鬆地，一鍵部署你自己的模型或內置的前沿開源模型 - &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference%25E3%2580%2582%25E6%2597%25A0%25E8%25AE%25BA%25E4%25BD%25A0%25E6%2598%25AF%25E7%25A0%2594%25E7%25A9%25B6%25E8%2580%2585%25EF%25BC%258C%25E5%25BC%2580%25E5%258F%2591%25E8%2580%2585%25EF%25BC%258C%25E6%2588%2596%25E6%2598%25AF%25E6%2595%25B0%25E6%258D%25AE%25E7%25A7%2591%25E5%25AD%25A6%25E5%25AE%25B6%25EF%25BC%258C%25E9%2583%25BD%25E5%258F%25AF%25E4%25BB%25A5%25E9%2580%259A%25E8%25BF%2587&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference。無論你是研究者，開發者，或是數據科學家，都可以通過&lt;/a&gt; Xorbits Inference 與最前沿的 AI 模型，發掘更多可能。 &amp;nbsp; Xinference 的功能和亮點有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌟 模型推理，輕而易舉：大語言模型，語音識別模型，多模態模型的部署流程被大大簡化。一個命令即可完成模型的部署工作。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚡️ 前沿模型，應有盡有：框架內置眾多中英文的前沿大語言模型，包括 baichuan，chatglm2 等，一鍵即可體驗！內置模型列表還在快速更新中！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🖥 異構硬件，快如閃電：通過 ggml，同時使用你的 GPU 與 CPU 進行推理，降低延遲，提高吞吐！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚙️ 接口調用，靈活多樣：提供多種使用模型的接口，包括 OpenAI 兼容的 RESTful API（包括 Function Calling），RPC，命令行，web UI 等等。方便模型的管理與交互。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌐 集羣計算，分佈協同：支持分佈式部署，通過內置的資源調度器，讓不同大小的模型按需調度到不同機器，充分使用集羣資源。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🔌 開放生態，無縫對接：與流行的三方庫無縫對接，包括 LangChain， LlamaIndex， Dify，以及 Chatbox。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🎉 Xinference v1.5.0 重磅發佈！&lt;/p&gt; 
&lt;p&gt;🚀 重點亮點&lt;/p&gt; 
&lt;p&gt;🧩 模型虛擬空間正式上線！&lt;/p&gt; 
&lt;p&gt;隨着模型更新頻繁，不同模型對依賴的要求也越來越複雜，老模型需要老版本庫，新模型又依賴新版包，常常出現互相沖突的問題。 現在，通過模型虛擬空間，每個模型可以獨立擁有一套安裝包環境，相互隔離、互不影響，模型運行更穩定！ 📄 配置與使用方式詳見文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🖥️ 易用性增強&lt;/p&gt; 
&lt;p&gt;🔄 模型加載支持展示進度，也可隨時取消模型加載 🧠 Gradio 聊天界面支持展示思考過程（🧪 需打開「解析思維過程」）&lt;/p&gt; 
&lt;p&gt;🧪 社區版&lt;/p&gt; 
&lt;p&gt;📦 更新指南&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📥 pip：pip install &#39;xinference==1.5.0&#39;&lt;/li&gt; 
 &lt;li&gt;🐳 Docker：拉取最新版本即可，也可以直接在鏡像內用 pip 更新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📝 更新日誌&lt;/p&gt; 
&lt;p&gt;🆕 新模型支持&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤖 LLM &amp;nbsp; &amp;nbsp; * 🌐 GLM-4 0414 &amp;nbsp; &amp;nbsp; * 🧠 Qwen2.5-Omni &amp;nbsp; &amp;nbsp; * ☁️ Skywork-OR1-preview&lt;/li&gt; 
 &lt;li&gt;🖼️ 多模態 &amp;nbsp; &amp;nbsp; * 🔍 InternVL3（已支持 AWQ 量化） &amp;nbsp; &amp;nbsp; * 🌊 SeaLLMs-v3 &amp;nbsp; &amp;nbsp; * 🗣️ Paraformer-ZH &amp;nbsp; &amp;nbsp; * 🛰️ Megatts3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🛠️ 功能增強&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧠 Gradio 聊天界面支持展示思考過程（需打開「解析思維過程」）&lt;/li&gt; 
 &lt;li&gt;📐 Vision 模型支持 min/max_pixels 控制輸入分辨率&lt;/li&gt; 
 &lt;li&gt;📥 模型下載支持進度顯示與取消&lt;/li&gt; 
 &lt;li&gt;⚙️ 默認併發數設置為 CPU 核心數&lt;/li&gt; 
 &lt;li&gt;🧪 支持 InternVL3 的 AWQ 推理&lt;/li&gt; 
 &lt;li&gt;🏎️ 默認使用最新版 xllamacpp 引擎&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🐛 BUG 修復&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧊 修復 vLLM 引擎停止時卡住的問題&lt;/li&gt; 
 &lt;li&gt;🧩 修復 llama.cpp 多分片模型加載失敗&lt;/li&gt; 
 &lt;li&gt;📂 修復 GGUF 模型路徑錯誤&lt;/li&gt; 
 &lt;li&gt;🧮 修復量化參數不生效問題&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 文檔更新&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📘 kokoro 使用指南&lt;/li&gt; 
 &lt;li&gt;📘 模型虛擬空間特性： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🏢 企業版&lt;/p&gt; 
&lt;p&gt;🎬 支持文生視頻界面，企業版新增文生視頻模塊界面，AI 視頻創作更直觀、操作更友好。 🚀 昇騰適配能力增強，適配模型範圍進一步擴展，支持更多模型在昇騰上穩定高效運行。&lt;/p&gt; 
&lt;p&gt;我們感謝每一位參與的社區夥伴對 Xinference 的幫助和支持，也歡迎更多使用者和開發者參與體驗和使用 Xinference。 &amp;nbsp; 歡迎您在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference&lt;/a&gt; 給我們一個，星標，這樣你就可以在 GitHub 上及時收到每個新版本的通知。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346151/xinference-1-5-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346151/xinference-1-5-0</guid>
            <pubDate>Sun, 13 Apr 2025 06:19:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>騰訊混元 3D 生成模型發佈 2.5 版本新模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊混元 3D 生成模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fv6BJ2ZyvInnj_zopaC2z5Q&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;正式推出 2.5 版本新模型，多視圖支持 pbr 貼面，不僅能上傳多圖，細節還更豐富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時建模精細度上大幅提升。v2.5 版本模型架構全面升級，總參數量從 1B 提升至 10B，有效面片數增加超 10 倍，實現超高清的幾何細節建模，表面更平整、邊緣更鋭利、細節更豐富，有效幾何分辨率達到 1024。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-067b104bbcf24a734d5cd7f472b98205ff4.gif&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b86aada5a6ce301269b3cc5b4cba07f42fb.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本支持 4K 高清紋理和細粒度 bump 凹凸貼圖，能夠模擬物體表面高低起伏的視覺效果。此外，為滿足專業創作者需求，混元 3D v2.5 優化了骨骼蒙皮系統，支持非標準姿態下的自動骨骼綁定和自動蒙皮權重賦值，大幅提升 3D 動畫生成效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3D 生成工作流功能也進一步升級，提供文生/圖生 3D 智能減面模型、多視圖生 3D 模型等專業管線模板，用戶可根據場景選擇對應生產管線、靈活調整參數，生成特定風格和特徵的 3D 資產，助力遊戲開發、動畫製作等垂直場景的高效搭建。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;混元 3D AI 創作引擎全面更新至 v2.5 模型底座，同時免費生成額度翻倍，提升至每天 20 次。混元 3D 生成 API 也已正式上線騰訊雲，面向企業和開發者開放。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346148</guid>
            <pubDate>Sun, 13 Apr 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>清華博士帶隊，發佈全球首個自迴歸視頻生成大模型「Magi-1」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，由清華博士曹越創立的 Sand.AI，公佈了一款名為「Magi-1」的自迴歸視頻生成模型，其主打兩個能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無限長度擴展：通過前一段生成的內容進行後一段視頻的製作，從而實現跨時間的無縫連貫敍事；&lt;/li&gt; 
 &lt;li&gt;生成時長控制精準到每一秒。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115406_dDdh_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而從公佈的數據顯示，具體性能測試結果如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Physics-IQ（對多種物理定律的理解）基準測試：Magi-1 獲得 56.02% 的高分成績，超越可靈 1.6、Sora 等一眾模型；&lt;/li&gt; 
 &lt;li&gt;人類評估：與海螺、騰訊混元、通義萬相 Wan2.1 相比，Magi-1 在指令跟隨和運動質量等方面更具優勢，但與可靈 1.6 在視覺質量存在差距；&lt;/li&gt; 
 &lt;li&gt;VBench-I2V 基準：Magi-1（2 倍解碼器）以 89.28 的高分排名第一，在動態程度（Dynamic Degree）上有較大優勢。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115713_mOF3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;技術上，Magi-1 整體架構基於 Diffusion Transformer，採用 Flow-Matching 作為訓練目標。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1247121c5ed762e2b9adea14a9780bf743.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，據公佈的信息顯示，Magi-1 通過自迴歸去噪方式預測固定長度的視頻片段，提高了視頻生成效率和前後因果性（保證前後內容生成邏輯一致）。&lt;/p&gt; 
&lt;p&gt;目前，Magi-1 已上架 Sand.AI 官網（可以免費體驗！），並且模型權重、代碼也進行 100% 開源，技術報告也進行全面公佈。&lt;/p&gt; 
&lt;p&gt;而背後的 Sand.AI 創始人為曹越，其博士畢業於清華大學軟件學院，並於 2018 年獲清華大學特等獎學金。曹越於 2022 年創辦 AGI 公司「光年之外」，後加入智源研究院領導多模態與視覺研究中心。隨後在 2023 年，曹越創立了 Sand.AI，並很長一段時間與其他成員保持「隱身」狀態。&lt;/p&gt; 
&lt;p&gt;團隊成員方面，有不少與曹越有着類似的歷程：智源研究院實習、光年之外創始成員、微軟亞洲研究院實習等等。另據瞭解，San.AI 已完成三輪融資，主要參與方包括今日資本、經緯創投等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;體驗鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsand.ai%2F&quot; target=&quot;_blank&quot;&gt;https://sand.ai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSandAI-org%2FMagi-1&quot; target=&quot;_blank&quot;&gt;https://github.com/SandAI-org/Magi-1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HuggingFace：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsand-ai%2FMAGI-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/sand-ai/MAGI-1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346129/sand-ai-magi1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346129/sand-ai-magi1</guid>
            <pubDate>Sun, 13 Apr 2025 03:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenBMB 開源社區推出代碼 Agent「卷姬」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 開源社區宣佈推出代碼 Agent 新成員「卷姬」，官方介紹其能夠「高效獲取有價值的內容」。&lt;/p&gt; 
&lt;p&gt;具體來看，用戶只需要在「卷姬」官網輸入想要提取的內容，便可在等待後獲取到綜述報告。而「卷姬」擁有兩種處理模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;普通模式：輸出標題和關鍵詞描述，提交併等待生成。&lt;/li&gt; 
 &lt;li&gt;專業模式：可進一步自定義素材來源，選擇「在線檢索」或「上傳文件」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aea0d199a34728e37f357830ab2a77c6f59.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;團隊方面表示，卷姬 SurveyGO 與 OpenAI DeepResearch、AutoGLM-沉思和 Gemini DeepResearch 相比，它的邏輯更嚴謹、學術性更強，適合深度分析，在多個方面有着不同的優勢體現：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;結構維度：SurveyGO 生成文章的目錄層次分明；&lt;/li&gt; 
 &lt;li&gt;內容維度：SurveyGO 導言部分更具深度，結尾分析更見功力，角度全面，絲滑縝密；&lt;/li&gt; 
 &lt;li&gt;觀點維度、引用維度：論述詳細，輔以合理的引用支持，觀點有理有據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據悉，卷姬 SurveyGO 採用 LLMxMapReduce-V2 長文本整合生成技術。該技術由 AI9Star、OpenBMB、清華大學團隊聯合研發，核⼼在於藉助⽂本卷積算法實現多篇參考⽂獻的聚合來代替現有⽅法中常⻅的檢索，從⽽實現對全部參考⽂章的充分利⽤。&lt;/p&gt; 
&lt;p&gt;目前，卷姬已上線官網，LLMxMapReduce-V2 的相關論文和開源內容也已公佈。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;體驗鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurveygo.thunlp.org%2F&quot; target=&quot;_blank&quot;&gt;https://surveygo.thunlp.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.05732&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2504.05732&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;開源鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fthunlp%2FLLMxMapReduce%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://github.com/thunlp/LLMxMapReduce/tree/main&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346126</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346126</guid>
            <pubDate>Sun, 13 Apr 2025 03:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>寶馬計劃年內在中國新車型中引入 DeepSeek 的 AI 技術</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;在近日於上海舉行的汽車展上，德國汽車製造商寶馬（BMW）宣佈，將於今年晚些時候在其新車型中集成中國初創公司 DeepSeek 的人工智能技術。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;這次合作的具體細節雖然尚未完全披露。&lt;/span&gt;寶馬首席執行官奧利弗・齊普塞 (Oliver Zipse) 在展會上表示，這一舉措標誌着寶馬在中國市場進一步加強與本地科技公司的合作。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-977e8740166a69b506b93255cfe68566f85.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;齊普塞強調，中國在人工智能領域的創新步伐迅速，寶馬希望藉助這種技術提升其汽車的智能化水平。「在這裏，AI 技術正在飛速發展。我們正在加強與當地公司的合作，以便將這些先進的人工智能技術整合進我們的車輛中。」&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;此外，寶馬在汽車電動化和智能化方面的努力也在不斷加碼。隨着全球汽車市場向電動和智能化轉型，寶馬希望通過與 DeepSeek 的合作，增強在這些領域的競爭力。齊普塞提到，未來的汽車將不僅僅是交通工具，更會成為用戶生活的智能助手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346115</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346115</guid>
            <pubDate>Sun, 13 Apr 2025 03:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英偉達終止 Lepton AI 運營</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，網上曝出 Lepton AI 已通知用戶，Lepton 將於 2025 年 5 月 20 日正式停止運營，此後用戶將無法再訪問 Lepton AI 平台上的服務或提交的數據，建議用戶在該日期之前儘快下載或備份所需數據。服務終止時，若用戶賬戶中仍有未使用的積分，官方將會在關停後予以退款處理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105739_VR8C_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不僅如此，官方網站已經禁止新賬戶註冊，顯示正在維護。Lepton AI 的官方推特顯示也已經被註銷。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105705_sxuq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105711_hYyj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;收購消息剛被曝出來時，許多人猜測英偉達收購後是會僅保留機器學習人才、大砍業務，還是會繼續運營 Lepton AI 的雲平台。目前看來，英偉達似乎更在意的人才，而非其相關具體業務，畢竟如今已經選擇了關閉服務。交易完成時 Lepton AI 約有 20 名員工，目前還未有消息指出這些員工的去留。&lt;/p&gt; 
&lt;p&gt;英偉達此番價值可能達數億美元的收購，實現了讓 LeptonAI 投資方紅杉中國、CRV 和 Fusion Fund 較為可觀的退出，大約在兩年前他們參與了該公司 1100 萬美元的種子輪融資。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;閲讀更多：&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/341235&quot; target=&quot;news&quot;&gt;英偉達正在洽談收購賈揚清創業公司 Lepton AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/343328&quot; target=&quot;news&quot;&gt;賈揚清已入職英偉達&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346110</guid>
            <pubDate>Sun, 13 Apr 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apache NetBeans 25 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Apache NetBeans 25&lt;span&gt;&amp;nbsp;現&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fblogs%2Fentry%2Fannounce-apache-netbeans-25-released%2F&quot; target=&quot;_blank&quot;&gt;已正式發佈&lt;/a&gt;。NetBeans 是一個主要面向 Java 的集成開發環境，同時支持 C/C++、PHP、JavaScript 和其他編程語言。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;一些更新內容包括：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Note&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Platform users：此版本通過設置&lt;code&gt;-J-DTopSecurityManager.disable=true&lt;/code&gt;(&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8169&quot; target=&quot;_blank&quot;&gt;#8169&lt;/a&gt;) 禁用了 NetBeans 內部安全管理器層。以 JDK 21 或更高版本為目標平台的現有應用程序應手動將此選項添加到其 launcher.conf 中。NetBeans 26 移除了安全管理器層，因此該 flag 無效 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fissues%2F8258&quot; target=&quot;_blank&quot;&gt;#8258&lt;/a&gt;&amp;nbsp;)。另請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F486&quot; target=&quot;_blank&quot;&gt;JEP 486&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gradle&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;EST 單個文件應該適用於名稱與相應文件名不匹配的測試類。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8021&quot; target=&quot;_blank&quot;&gt;#8021&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;並行運行測試的操作&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7979&quot; target=&quot;_blank&quot;&gt;#7979&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Gradle init 應遵循配置 Java 運行時&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8223&quot; target=&quot;_blank&quot;&gt;#8223&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Maven&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Maven：改進依賴項解析（例如，對於像 lombok 這樣的註釋處理器）&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8057&quot; target=&quot;_blank&quot;&gt;#8057&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Maven 遠程索引遷移和重構&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7976&quot; target=&quot;_blank&quot;&gt;#7976&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 ProjectReload 中缺失的工件&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7855&quot; target=&quot;_blank&quot;&gt;#7855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;候選版本不應該竊取 GA 版本中的 Maven 索引&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8199&quot; target=&quot;_blank&quot;&gt;#8199&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 FruchtermanReingoldLayout 中的無限循環&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8217&quot; target=&quot;_blank&quot;&gt;#8217&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 maven 索引器的查詢限制&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8198&quot; target=&quot;_blank&quot;&gt;#8198&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Ant&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復大規模 Ant 項目打開時出現的 ConcurrentModificationException&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7989&quot; target=&quot;_blank&quot;&gt;#7989&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在 WSL 上運行的 Payara Server 實例在保存時部署會破壞「Web 應用程序」Ant 項目&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8144&quot; target=&quot;_blank&quot;&gt;#8144&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Java&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復 Windows 上由於 java.hints、java.source.base 中的 CRLF 不匹配導致的測試失敗&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7910&quot; target=&quot;_blank&quot;&gt;#7910&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 MacOS 中 java.hints 測試失敗問題&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7926&quot; target=&quot;_blank&quot;&gt;#7926&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將嵌入式 tomcat 從 9.0.71 更新到 9.0.96&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7919&quot; target=&quot;_blank&quot;&gt;#7919&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 java/j2ee.persistence 測試並將其添加到構建管道中&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7943&quot; target=&quot;_blank&quot;&gt;#7943&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 switch 模式提示中可能出現的越界異常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7973&quot; target=&quot;_blank&quot;&gt;#7973&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7949] 修復「case null」的處理&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7980&quot; target=&quot;_blank&quot;&gt;#7980&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;確保 AttrContext.returnResult 的 checkContext 在 javac 的 Scopes 中設置為 Check.basicHandler，以避免其拋出異常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8016&quot; target=&quot;_blank&quot;&gt;#8016&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將 CI jobs 降級至 JDK 23&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8061&quot; target=&quot;_blank&quot;&gt;#8061&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 Java 代碼補全（sealed）測試的穩定性&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8066&quot; target=&quot;_blank&quot;&gt;#8066&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;合併 jakarta.web.beans 和 web.beans&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7958&quot; target=&quot;_blank&quot;&gt;#7958&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更新 textmate 支持&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7971&quot; target=&quot;_blank&quot;&gt;#7971&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將 nb-javac 升級到 JDK 24b29&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8037&quot; target=&quot;_blank&quot;&gt;#8037&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7069] 支持 Nashorn 15.x for JDK &amp;gt;= 15&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7972&quot; target=&quot;_blank&quot;&gt;#7972&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;apidoc 拼寫錯誤修復&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8148&quot; target=&quot;_blank&quot;&gt;#8148&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;僅在 JDK 23 及更高版本上設置 javadoc 23 特定標誌&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8152&quot; target=&quot;_blank&quot;&gt;#8152&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;......&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多詳情可查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Freleases%2Ftag%2F25&quot; target=&quot;_blank&quot;&gt;https://github.com/apache/netbeans/releases/tag/25&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fdownload%2Fnb25%2F&quot; target=&quot;_blank&quot;&gt;https://netbeans.apache.org/front/main/download/nb25/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346107/apache-netbeans-25-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346107/apache-netbeans-25-released</guid>
            <pubDate>Sun, 13 Apr 2025 02:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 有意願收購谷歌 Chrome 瀏覽器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fgoogle-contemplated-exclusive-gemini-ai-deals-with-android-makers-2025-04-22%2F&quot;&gt;路透社報道稱&lt;/a&gt;，OpenAI 旗下 ChatGPT 產品負責人表示，&lt;strong&gt;若反壟斷執法人員成功迫使 Alphabet（Google 母公司）出售 Chrome 瀏覽器，OpenAI 將有意收購谷歌 Chrome 瀏覽器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/102749_NjaW_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此前，美國法官 Amit Mehta 判定谷歌的 Chrome 瀏覽器涉及壟斷行為，該公司需從本週一開始採取補救措施，而谷歌計劃針對該判決上訴。&lt;/p&gt; 
&lt;p&gt;檢察官在當地週一的開庭陳述上表示，谷歌搜索壟斷可能會令其在 AI 方面帶來優勢。谷歌則表示，提供生成式 AI 產品的公司會存在競爭，谷歌還在庭審中提供了一份 OpenAI 的內部文件，這份文件稱 ChatGPT 在消費級 AI 聊天機器人市場中處於領先地位，並不認為谷歌是其最大競爭對手。&lt;/p&gt; 
&lt;p&gt;ChatGPT 產品負責人 Nick Turley 表示，&lt;strong&gt;OpenAI 去年曾與谷歌聯繫，商討建立潛在合作關係，讓 ChatGPT 使用谷歌的搜索技術&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Turley 認為，ChatGPT 若能使用谷歌搜索的 API，那將能為用戶提供更好的 AI 產品。據悉，OpenAI 於去年 7 月首次聯繫谷歌，但後者在 8 月以「涉及太多競爭對手」為由，拒絕了上述合作。&lt;/p&gt; 
&lt;p&gt;OpenAI 一直在開發自己的搜索工具，雖然 OpenAI 原本希望在 2025 年底之前讓 ChatGPT 上線搜索功能並依靠該引擎完成 80% 的搜索工作，但 Turley 在作證時表示，該公司現在認為達到這一成績仍需要數年時間。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/322108/openai-hires-former-chrome-engineer&quot;&gt;又一名 Chrome 創始工程師加入 OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/321528/openai-considers-taking-on-google-with-browser&quot;&gt;OpenAI 考慮開發瀏覽器，與谷歌競爭&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346103/openai-chrome-google-us-judge</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346103/openai-chrome-google-us-judge</guid>
            <pubDate>Sun, 13 Apr 2025 02:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Manus 開源平替，Kortix-AI 發佈開源通用 AI 智能體平台 Suna</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kortix-AI 正式發佈開源通用 AI 智能體平台 Suna，定位為熱門 AI 工具 Manus 的開源替代品。Suna 集成了瀏覽器自動化、文件管理、網絡爬蟲、擴展搜索、命令行執行、網站部署及 API 集成等功能，通過自然語言對話實現複雜任務的自動化處理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-01ba5fdfe0002965d001a22e6205e28616c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;主要功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;瀏覽器自動化：通過內置瀏覽器控制模塊，Suna 可自主導航網頁、點擊元素、填寫表單並提取數據，適用於任務如價格比較或表單提交。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;文件管理：支持文檔創建、編輯與組織，允許用戶通過對話指令生成報告或管理項目文件。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;網絡爬蟲與擴展搜索：具備高效的網頁抓取與信息檢索能力，可跨平台搜索並整合數據，如分析社交媒體評論或市場趨勢。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;命令行執行：支持運行系統命令與腳本，自動化本地任務，如批量文件處理或服務器管理。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;網站部署：提供一鍵式網站部署功能，結合 API 集成，簡化從開發到上線的流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;API 與服務集成：通過 LiteLLM 支持 OpenAI、Anthropic 等多種大語言模型（LLM），並可連接 Supabase、GitHub 等外部服務，擴展功能邊界。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Suna 發佈後，社區對其開源性與功能全面性給予高度評價。開發者稱其「將 Manus 的商業能力帶入開源領域」，尤其在自動化複雜任務方面表現優異。 然而，部分用戶指出，自託管的初始配置需一定技術背景，建議 Kortix 推出更簡化的雲端部署選項。社區已在探討增強 Suna 的多模態能力，如支持圖像生成與實時語音交互。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346097</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346097</guid>
            <pubDate>Sun, 13 Apr 2025 02:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DistilQwen2.5-DS3-0324 發佈：知識蒸餾 + 快思考 = 更高效解決推理難題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：蔡文睿（清素）、汪誠愚（熊兮）、嚴俊冰（玖燭）、黃俊（臨在）&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;在大語言模型領域的快速發展中，如何&lt;strong&gt;有效平衡高效推理和模型思維能力&lt;/strong&gt;之間的矛盾一直是學術界和工業界關注的重點。DeepSeekV3-0324 默認沒有采用深度思考的模式，使得模型推理速度更快，兼顧了快速推理和複雜任務處理之間的平衡。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DistilQwen&lt;/strong&gt; &lt;strong&gt;系列&lt;/strong&gt;是阿里雲人工智能平台 PAI 推出的蒸餾語言模型系列，包括&lt;strong&gt;DistilQwen2、DistilQwen2.5、DistilQwen2.5-R1&lt;/strong&gt; 等。在此次工作中，我們將 DeepSeekV3-0324 基於快思考的推理能力成功遷移到更輕量的小模型中，全新推出 &lt;strong&gt;DistilQwen2.5-DS3-0324&lt;/strong&gt;。在繼承了原始模型思維鏈蒸餾的精華的同時，引入了&lt;strong&gt;快思考策略&lt;/strong&gt;，顯著提升了推理速度，使得在資源受限的設備和邊緣計算場景中，模型能夠高效執行復雜任務。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;實驗顯示，DistilQwen2.5-DS3-0324 系列模型在多個基準測試中表現突出，其 32B 模型效果甚至接近參數量接近其 10 倍的閉源大模型。在複雜問題解決方面，也大幅降低了思維鏈的長度，展示了卓越的效率。&lt;strong&gt;DistilQwen2.5-DS3-0324 系列的發佈，助力「大模型+快思考」的新模式&lt;/strong&gt;，逐步成為解決推理難題的標準配置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a44937451ac82d3b8c6ed1970704e0dd.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;為方便開發者和企業在實際應用中使用 DistilQwen2.5-DS3-0324 系列模型，已將所有的 Checkpoint 在 Hugging Face 和 Model Scope 開源社區中公開。本文將深入闡述 DistilQwen2.5-DS3-0324 的蒸餾算法、性能評估，並且提供在阿里雲人工智能平台 PAI 上的使用指南及相關下載教程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 中的蒸餾技術&lt;/h1&gt; 
&lt;p&gt;本節中，我們主要描述 DistilQwen2.5-DS3-0324 系列模型訓練中使用的數據增強與知識蒸餾技術。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;推理模型通過深度思考可以解決複雜的推理任務，但這種深度思考也帶來了大規模的計算資源需求。模型思考的過程中一般都有反思機制的參與，其會反覆推敲模型已有的推理步驟，確保每個步驟都正確推進。這種反思機制在提高推理準確率的同時，也會不可避免地帶來一些重複冗餘的部分，導致推理模型所需的計算資源居高不下。因此，取得模型深度思考和快速回答間的平衡顯得格外重要。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此外，蒸餾模型的參數量普遍較小。而由於自身參數量的顯著差異，大模型與小模型的認知與推理軌跡有時並不完全一致。以數學問題為例：小模型由於自身參數量的限制，會傾向於使用更基礎的方法去解決問題。而大模型基於其強大的推理能力，會採用較為高階的方法。正是由於大小模型的認知軌跡偏差，小模型有時無法有效理解大模型的思維鏈。如果直接將大模型的思維鏈全部蒸餾到小模型中，往往無法達到最優效果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;針對這些問題，我們設計了一種小型推理模型蒸餾框架，主要包含 2 個階段：快思考 CoT 數據收集，CoT 軌跡認知對齊。該框架可以讓模型在快速思考的同時，消除認知軌跡偏差帶來的負面影響。我們通過第一階段收集大模型的快思考數據，在第二階段對快思考數據進行與小模型的認知能力對齊，最終使用對齊後的快思考 CoT 對 Qwen2.5 系列基座小模型進行監督微調（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;快思考 CoT 數據收集&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，模型深度思考和快速回答間的平衡顯得格外重要。如果模型的中間思考步驟出現錯誤，此時的反思機制可以有效幫助模型自查糾錯。但如果模型輸出的是正確的思考步驟，此時反覆的自查思考反而會導致不必要的資源浪費。因此，我們需要一種快思考 CoT，其保留了必要的推理和自查糾錯步驟，同時去除了不必要的重複冗餘部分。這種快思考 CoT 大幅縮減了推理長度，可以幫助模型進行快速思考和快速回復，在資源受限場景中高效完成任務。我們的快思考 CoT 數據主要來源於：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;推理大模型 CoT 數據的 Long To Short 思維鏈改寫。基於 DeepSeek-R1 的推理數據，我們從中提煉關鍵步驟，生成更高效、簡潔的推理路徑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;快思考大模型蒸餾。我們認為 DeepSeek-V3-0324 的輸出具備快思考的特點，我們從中蒸餾出一些推理軌跡，涵蓋數學、代碼和科學問題等多個領域。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;特別的，針對推理大模型產生的思維鏈過於冗長的問題，我們進一步使用 QwQ-32B 對思維鏈進行改寫，其功能在於精簡思維鏈長度，降低蒸餾模型的輸出 token 數量，同時，保證思維鏈的正確性，避免錯誤傳播到蒸餾模型中。使用大模型進行 Long To Short 思維鏈改寫的 Prompt 如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at simplifying reasoning processes.
Given a problem, its answer and its reasoning process, your task is to simplify the reasoning process so that a small language model (e.g., a 7B model) can reliably follow the steps to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the simplified reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;CoT 軌跡認知對齊&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，大小模型間的認知推理軌跡有時存在顯著偏差。因此，對於待蒸餾的大模型快思考 CoT 數據集，小模型可能無法有效理解全部內容。舉例來説，對於計算直角邊分別為 3 和 4 的三角形面積，大模型可能使用線性代數進行求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4323edb8ff0d97ef14445f75c67e3c21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;這種方式對小模型而言比較難以學會，其一般採用簡單的算術方法求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c9971930330f9f1c83cb1fa794fe13a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;因此，直接將大模型的輸出蒸餾到小模型容易造成小模型難以擬合的問題。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們採用了 LLM-as-a-Judge 的範式，對大模型的推理過程進行評價並改進。給定問題、大模型的推理過程和問題的答案，我們使用模型判斷這個推理過程是簡單、中等還是困難。難度等級的核心標準是小模型是否能夠遵循給定的推理過程得到問題的答案。以下是思維鏈的難度等級及定義：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中等： 小模型可以遵循該推理過程得到問題的答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;簡單： 給定的推理過程過於簡單，缺少小模型所需的必要步驟，導致大模型可以依賴其強大的推理能力解決問題，但小模型無法遵循該過程得到答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;困難： 給定的推理過程過於複雜或過於困難，導致小模型無法遵循該過程得到答案。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;其中，我們使用如下 Prompt 調用 QwQ-32B 模型進行思維鏈難度的估計：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a highly capable evaluator.
Your task is to assess the given reasoning process from the perspective of a small language model (e.g., 7B). 
Specifically, determine whether the reasoning process provides sufficient detail for a small model to solve the problem, or whether it is too simplistic (i.e., lacking critical details) or too complex (i.e., containing unnecessary or confusing steps). 

Difficulty Definitions (from the perspective of a small model): 
- Easy: The reasoning process is overly simplistic relative to the problem&#39;s difficulty; it omits essential details that a small model needs to solve the problem.
- Medium: The reasoning process is appropriately balanced, offering enough detailed guidance.
- Hard: The reasoning process is overly complex, with extraneous or convoluted steps that could hinder a small model&#39;s ability to follow it. 

Output Format:
You must output exactly one word: easy, medium, or hard. Do NOT provide any additional text, explanation.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;基於一個大模型的問題與思維鏈集合，我們可以將其分為簡單、中等和困難三類。對於評級為中等的部分，我們予以保留。對於被評為簡單和困難的數據，我們使用模型對思維鏈進行改進。具體來説：對於簡單部分，我們擴展其推理過程，直至小模型可以遵循擴展的過程得到答案。對於評級為困難的部分，我們精簡其推理過程，直至小模型可以遵循精簡的過程得到答案。精簡思維鏈的過程可以參考 Long To Short 的 Prompt 示例。擴展思維鏈的過程與 Long To Short 相反，其 Prompt 模版如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at extending reasoning processes.
Given a problem, its answer and its reasoning process, your task is to extend the reasoning process by adding necessary details and intermediate steps so that a small language model (e.g., a 7B model) can follow the extended reasoning process to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the extended reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們之後對改進結果進行進一步驗證，包括：對改進後的思維鏈再次評價難度等級，檢測其是否被歸類為中等難度。如果改進後的思維鏈通過驗證，説明改進有效，該數據可以被小模型有效理解，我們將其保留。如果驗證不通過，説明改進無效，我們將返回到改進步驟，重新進行改進，直至通過驗證。最終，我們獲取了優化後的思維鏈數據集，其組成部分如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為中等的數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為簡單，經過改進擴展後評為中等並通過驗證的數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為困難，經過改進精簡後評為中等並通過驗證的數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此時，數據集內所有思維鏈的最終難度評級均為中等，意味着小模型可以有效理解數據集內的所有思維鏈，並能遵循這些思維鏈解決相應推理問題。上文提到的大小模型認知軌跡偏差問題在改進後的數據集中得到妥善解決，其可能帶來的負面影響也被消除。相關流程如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//688591ec35d4073130ee1caaf6bd497c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關工作參考論文 Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們在第二階段使用這種 CoT 軌跡認知對齊機制對得到的快思考 CoT 數據進行優化，最終使用優化後的數據集對 Qwen2.5 系列基座模型進行監督微調（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 模型效果評測&lt;/h1&gt; 
&lt;p&gt;在本節中，我們從多個角度評測 DistilQwen2.5-DS3-0324 系列蒸餾小模型在推理任務上的實際效果；同時，我們將通過統計數據印證 DistilQwen2.5-DS3-0324 系列模型推理的快速性和高效性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型綜合能力評測&lt;/h2&gt; 
&lt;p&gt;我們在多個模型推理能力評測基準上測試了 DistilQwen2.5-DS3-0324 系列模型的能力，涵蓋數學、代碼和科學問題三個主流推理領域。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;數學領域：採用 AIME2024 和 MATH-500 兩個基準。AIME2024 為美國數學邀請賽的 2024 年測試集，含 30 道高難題，聚焦代數與幾何等複雜推理能力；MATH-500 涵蓋 500 道題，旨在全面考察模型在數學解題上的能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼領域：使用 LiveCodeBench V2，其包含 2023 年 5 月-2024 年 5 月的 511 個代碼問題，測試模型在高難度編碼、自我修復和執行測試等方面的綜合能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;科學問題領域：使用 GPQA-Diamond 和 MMLU-PRO。前者為高質量專家級科學問題集（共 198 題），後者涵蓋 12,000+道題，強調模型的複雜推理能力而非僅靠知識檢索，精準追蹤大模型在推理任務上的進步和不足。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如下圖所示，DistilQwen2.5-DS3-0324 系列模型在 7B、14B 和 32B 四個參數量級的模型中，與原始 Qwen2.5 模型的效果進行了對比。可以看出，DistilQwen2.5-DS3-0324 系列模型的推理能力在多個評測基準上取得了一致而明顯的效果提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們還將 DistilQwen2.5-DS3-0324-32B 與當前主流的非推理大模型作了比較，結果如下圖所示。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4774cc392eb93d60a2c732815125d227.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;可以看出，儘管這些大模型的參數量是自己的數十倍，DistilQwen2.5-DS3-0324-32B 依舊在這些推理基準上取得了相對不錯的結果。其中，DistilQwen2.5-DS3-0324-32B 在 AIME2024 和 MATH-500 兩個基準上高於多個閉源大模型（例如 Qwen-Max 和 Claude-Sonnet-3.7），在 LiveCodeBench 超過了其他所有大模型，包括其教師模型 DeepSeek-V3-0324。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;平衡精度和輸出 Token 數量&lt;/h2&gt; 
&lt;p&gt;為展示 DistilQwen2.5-DS3-0324 系列模型高效推理效果，以 32B 模型為例，我們分別統計了 DistilQwen2.5-DS3-0324 模型和 DistilQwen2.5-R1 系列模型在各個推理 benchmark 上輸出的平均 token 數。可以看出，相較於採用深度思考進行推理的模型，DistilQwen2.5-DS3-0324 系列模型推理輸出的 token 數量大幅降低，與 DeepSeek-V3-0324（teacher model）的輸出 Token 數相當，兼顧了快速推理和複雜任務處理。這種快思考的特點使得 DistilQwen2.5-DS3-0324 系列模型在資源受限的設備和邊緣計算場景中依舊能高效解決複雜推理任務。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//85ba45740e3afe28cb2efa233a239871.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型輸出案例&lt;/h2&gt; 
&lt;p&gt;我們在此列舉一些有趣的小例子，以體現 DistilQwen2.5-DS3-0324 系列模型強大的代碼能力。以下 case 均為 DistilQwen2.5-DS3-0324-32B 輸出結果。為便於復現，我們還提供了不同 case 對應的 prompt。將 prompt 對應的模型輸出代碼保存到本地 html 文件中，使用瀏覽器打開 html 文件即可復現類似結果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例一：前端網頁生成：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8622f5305c8f41ee9a740afeb6915fbf.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt：Create a detailed web page for a new SAAS with all the necessary information images and pricing and all, give me the code so that I can test locally using vscode.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例二：貪吃蛇遊戲&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5aae0fd15a345f08fdf98c360ee5d33.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt: Develop an interactive version of the classic Snake game in a single HTML file using HTML, inline CSS, and inline JavaScript. The game must include responsive controls, dynamic score tracking, and a game-over screen with a restart option. Use proper image assets for the snake and food items (no placeholders) so that the entire game is self-contained.&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_9&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;模型下載和使用&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在阿里雲人工智能平台 PAI 上的實踐&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 庫為例，簡要介紹如何在 PAI-DSW 上使用 DistilQwen2.5-DS3-0324 模型。首先需要保證 PAI-DSW 鏡像內 transformers 版本大於等於 4.37.0，否則會在加載模型時報錯：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以 DistilQwen2.5-DS3-0324-7B 為例，我們可以使用如下代碼調用模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;xxxxx&quot;
messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant. You should think step-by-step.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=2048
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在開源社區的下載&lt;/h2&gt; 
&lt;p&gt;我們在 Hugging Face 和 Model Scope 上開源了我們蒸餾後的模型，分別為&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-7B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-7B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-14B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-14B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-32B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-32B&lt;/a&gt;。以 Hugging Face 為例，用戶可以使用如下代碼下載這兩個模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-7B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-14B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-14B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-32B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-32B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;小結與未來工作&lt;/h1&gt; 
&lt;p&gt;綜上所述，DistilQwen2.5-DS3-0324 系列模型通過知識蒸餾快思考策略，實現了在資源受限環境中的高效推理，兼顧了快速推理和處理複雜任務的需求。這一系列模型在多個基準測試中表現優異，證明瞭其卓越的推理能力和實際應用價值。作為「大模型+快思考」新模式的經典案例，DistilQwen2.5-DS3-0324 系列為小模型的廣泛應用提供了巨大的空間。未來，我們將繼續優化和提升 DistilQwen 系列模型的蒸餾技術，以進一步增強小模型的智能水平和推理效率，推廣更多高效、輕量化的語言模型，支持開發者和企業在實際應用中的廣泛採用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_13&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;參考資料&lt;/h1&gt; 
&lt;p&gt;相關發表論文&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang. Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;技術文章&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5-R1 發佈：知識蒸餾助推小模型深度思考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1659288&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1659288&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5 發佈：通義千問蒸餾小模型再升級：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1653842&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2：通義千問大模型的知識蒸餾實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2 蒸餾小模型的訓練、評測、壓縮與部署實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大語言模型數據增強與模型蒸餾解決方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;技術交流答疑羣&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8a44ba73f4d5fc38c496db477b936e55.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_15&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&amp;nbsp;&lt;/h1&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/18224086</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18224086</guid>
            <pubDate>Sun, 13 Apr 2025 01:56:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>全球首個自迴歸視頻生成大模型「Magi-1」重磅開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;Magi-1 是首個實現頂級畫質輸出的自迴歸視頻生成模型，模型權重、代碼 100% 開源。其主打能力，一是無限長度擴展，實現跨時間的無縫連貫敍事。二是能將控制精確到每一「秒」，10s 內自定義視頻時長。&lt;/p&gt;

&lt;p&gt;Magi-1 整體架構基於 Diffusion Transformer，採用 Flow-Matching 作為訓練目標。其最大的特點是不把視頻當成一個整體去生成，而是通過自迴歸去噪方式預測固定長度的視頻片段（chunk），每個片段固定為 24 幀。&lt;/p&gt;

&lt;p&gt;在注意力機制上，也是提出了多項創新，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Block-Causal Attention&lt;/li&gt;
&lt;li&gt;Parallel Attention Block&lt;/li&gt;
&lt;li&gt;QK-Norm 和 GQA&lt;/li&gt;
&lt;li&gt;Flex-Flash-Attention&lt;/li&gt;
&lt;li&gt;計算負載均衡&lt;/li&gt;
&lt;li&gt;零冗餘通信原語&lt;/li&gt;
&lt;li&gt;自適應多階段重疊&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推理基礎設施方面，主要針對實時流式視頻生成和在 RTX 4090 GPU 上的經濟高效部署兩種場景進行設計，以滿足不同應用需求。&lt;/p&gt;

&lt;p&gt;目前官網支持免費試玩 Magi-1：&lt;a href=&quot;https://sand.ai/magi&quot;&gt;https://sand.ai/magi&lt;/a&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/magi-1</link>
            <guid isPermaLink="false">https://www.oschina.net/p/magi-1</guid>
            <pubDate>Sat, 12 Apr 2025 11:45:00 GMT</pubDate>
        </item>
        <item>
            <title>百度 Al 智能體心響 App 上線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;百度通用 Al 智能體心響 App 已低調上線安卓應用市場。該應用介紹稱，這是一款以「AI 任務完成引擎」為核心的手機端超級智能體產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;545&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-282aac1eb0a56c4d21d1903e980e2f7a194.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;應用詳情介紹，心響是一款以「AI 任務完成引擎」為核心的手機端超級智能體產品，通過自然語言交互幫助用戶實現複雜任務拆解、動態執行與可視化結果交付。依託大模型與多智能體協同能力，心響深度賦能知識解析、旅遊規劃、學習辦公等核心生活場景，致力於成為用戶的&#39;超級大腦」+「最強輔助」，讓用戶從繁瑣流程中解放一站式讓複雜問題智能決策，效率調度，閉環解決實現全流程託管。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能亮點&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.主腦調度系統：全流程任務託管&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;智能拆解：將複雜需求拆解為可執行步驟，並提供實時進度追蹤。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;資源協同：連接核心場景的垂直領域專家智能體確保任務精準落地。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;動態優化：根據任務進展自動調整策略，突發問題實時預警並生成解決方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2.旅遊攻略：沉浸式行程規劃&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一句話定製行程：用戶僅需輸入一句話需求，心響便可生成完整攻略，聯動動態地圖可視化路線。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;視頻互動決策：數字人導遊引導用戶選擇天數、預算、玩法，強化「身臨其境」決策體驗。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3.智慧圖表：數據可視化革新&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一鍵生成複雜圖表：基於行業數據自動生成動態排行榜、柱狀圖、折線圖等 10+圖表類型，支持定時任務製圖 (如哪吒 2 票房走勢、實時股價走勢)&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4.定時任務：自動化追蹤與提醒&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;高頻任務託管：如每日兒童故事生成、黃金價格盯盤、股票波動監測，AI 自動執行並推送結果。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;個性化&amp;amp;長期追蹤：支持例如蘋果發佈會動態彙總埃隆·馬斯克業務進展跟蹤，信息整合不遺漏關鍵節點&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;5.戀愛挑戰：社交技能訓練場&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;模擬戀愛對話：拆解社交需求，生成個性化戀愛對象，提供對話練習與總結報告，提升情感溝通技巧。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345995</guid>
            <pubDate>Sat, 12 Apr 2025 10:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「HarmonyOS 協同・創新」 即將啓幕，開發者攜手共創新未來</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0.0001pt; margin-right:0px&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鴻蒙開發者聯盟官網&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成為鴻蒙開發者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當智能終端從「單一設備」走向「全域協同」，從智能家居的聯動控制到工業互聯的高效協同，從車載系統的無縫銜接到移動辦公的跨端流轉，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;開發者如何在這場變革中搶佔先機？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 以分佈式技術打破硬件邊界，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「一次開發、多端部署」能力已悄然滲透至千行百業，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用全場景生態重構用戶體驗，正為全球開發者打開一扇通向未來的大門。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但隨之而來的挑戰也愈發明顯：如何高效利用分佈式架構實現跨端協同&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 技術如何深度賦能鴻蒙應用開發？複雜場景下的性能優化有哪些「避坑指南」？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;4 月 27 日，由開源中國主辦，山東省軟件行業協會協辦的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;「HarmonyOS 協同·創新」（軟件行業專場）將在濟南啓幕&lt;/strong&gt;&lt;/span&gt;。這是一場專為鴻蒙生態建設者打造的深度對話——技術大咖、實戰派工程師與數百名開發者齊聚，共同探索操作系統的無限可能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主題：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 協同·創新（軟件行業專場）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;時間&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：2025 年 4 月 27 日 14:00-17:20（13:40 開放簽到） &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;地點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：濟南市山創創意園·ChillPlay Base&amp;amp;coffee（山 6 創意園內，科技氛圍與咖啡香交融的靈感空間）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;適合人羣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：鴻蒙應用開發者、技術團隊負責人、生態合作企業&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;🤝&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與頂尖專家面對面：破解開發者的「真問題」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;華為雲 HCDE 專家姚聖偉將解讀鴻蒙生態戰略佈局及 2025 年新機遇，拆解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;鴻蒙分佈式架構&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，揭祕跨端協同開發的核心邏輯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;科技公司軟件工程師劉&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;張豪&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分享&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 賦能鴻蒙生產力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的實戰案例，探索智能化開發新路徑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互聯網醫療&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大前端&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;專家黃沅帶來&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;高頻問題解析與優化指南&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，助力開發者提升效率、少走彎路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;活動特設「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互動時刻&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」環節，專家&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;現&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;場坐鎮答疑解惑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。無論是分佈式架構設計、多端協同邏輯，還是代碼調試中的疑難問題，參與者均可通過現場提問與專家零距離交流，快速打通技術堵點，獲取針對性解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外，本次活動特設茶歇交流時間，與數百名鴻蒙開發者、技術專家、企業代表輕鬆氛圍中碰撞創新靈感，拓展行業人脈。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;👏&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;微信掃碼，即刻報名：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;6141&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fa6fad32606b45577ffd51a7a220b5e6ae4.png&quot; width=&quot;2160&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鴻蒙開發者聯盟官網&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成為鴻蒙開發者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18219336</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18219336</guid>
            <pubDate>Sat, 12 Apr 2025 09:45:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>