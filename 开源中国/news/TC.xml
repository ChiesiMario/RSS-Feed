<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 06 Mar 2025 07:47:31 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>智源開源多模態向量模型 BGE-VL</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;智源研究院宣佈聯合多所高校開發了多模態向量模型 BGE-VL，進一步擴充了原有生態體系。BGE-VL 在圖文檢索、組合圖像檢索等主要多模態檢索任務中均取得了最佳效果。&lt;/p&gt; 
&lt;p&gt;BGE-VL 藉助大規模合成數據 MegaPairs 訓練而成。這一設計具備以下兩大核心優勢:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;優異的可擴展性：&lt;/strong&gt;MegaPairs 結合多模態表徵模型、多模態大模型和大語言模型，在海量圖文語料庫中高效挖掘多模態三元組數據。其算法能夠以極低成本持續生成多樣化且高質量的多模態三元組。本次發佈的版本涵蓋 2600 萬條樣本，為多模態檢索模型的訓練提供了大規模、高價值的數據支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;卓越的數據質量：&lt;/strong&gt;相較於傳統人工標註數據，MegaPairs 僅需 1/70 的數據量即可實現更優的訓練效果。利用該合成數據，智源訓練了多模態檢索模型 BGE-VL，顯著提升了多個主流多模態檢索基準的性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;BGE-VL 的技術報告已發佈，相關數據、模型及代碼資源將陸續向社區全面開放。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.14475&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.14475&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;項目主頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FVectorSpaceLab%2FMegaPairs&quot; target=&quot;_blank&quot;&gt;https://github.com/VectorSpaceLab/MegaPairs&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBAAI%2FBGE-VL-MLLM-S1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BAAI/BGE-VL-MLLM-S1&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337258</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337258</guid>
            <pubDate>Thu, 06 Mar 2025 07:39:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>vivo OS 部門設立 AI 領域板塊</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbXnSMuj_jA5V9BeIDYuJkw&quot; target=&quot;_blank&quot;&gt;據雷鋒網獨家消息&lt;/a&gt;&lt;/u&gt;，vivo 近日進行了組織架構調整，其中其 AI 領域有了新的變動。&lt;/p&gt; 
&lt;p&gt;具體來看，vivo 原 OS 產品領域下將設立 AI 領域，人工智能一部、人工智能二部劃入 AI 領域。原互聯網平台運營領域總經理張飛被調任 AI 領域總經理，併兼管人工智能一部，無考察期，直接向公司副總裁、OS 產品領域負責人周圍彙報。而原人工智能一部總經理肖方旭已於 1 月份離職。&lt;/p&gt; 
&lt;p&gt;據 vivo 員工透露，公司在 AI 大模型方面投入巨大，前期管理意志幹預很重，可實際看來技術進展緩慢，此事早在去年內部就有過討論，最終結果是暫時不做商業化考覈，但暫停了對資金的投入。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;報道指出，目前 vivo 的大模型訓練重心正在向端側轉移，雲端的 700 億參數大語言模型還在微調和優化中，暫停了該模型的預訓練工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;公開資料顯示，vivo 每年都會投入 20-30 億用於大模型研發。截至 2024 年 10 月，vivo 在 AI 領域的投入已經超過 230 億元，且 AI 研究院的研發人員數量也從 2019 年的 1 千人增加至 2 千多人，是目前公開披露 AI 投入最高的手機廠商之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337257</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337257</guid>
            <pubDate>Thu, 06 Mar 2025 07:36:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信月活突破 10 億</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QuestMobile 近日發佈了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-mdl9gcCNmfLotd87SOIFg&quot; target=&quot;_blank&quot;&gt;2024 年度中國移動互聯網實力價值榜&lt;/a&gt;&lt;/u&gt;，TOP50 賽道用戶規模 NO.1 APP 如下。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2284&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152504_luN0_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本榜單體現了互聯網行業 50 個細分賽道的第一名，微信在即時通訊位列第一，&lt;strong&gt;月活唯一突破 10 億級，達到 10.8 億&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;綜合電商方面，淘寶以 9.6 億月活排名第一。短視頻方面的第一是抖音，月活 8.4 億。&lt;/p&gt; 
&lt;p&gt;從 50 個 APP 所屬的集團來看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;阿里旗下有 8 款：淘寶、高德地圖、支付寶、釘釘、閒魚、餓了麼、菜鳥、盒馬。&lt;/li&gt; 
 &lt;li&gt;騰訊旗下有 7 款：微信、搜狗輸入法、騰訊視頻、QQ 瀏覽器、酷狗音樂、王者榮耀、QQ 郵箱。&lt;/li&gt; 
 &lt;li&gt;字節旗下有 6 款：抖音、今日頭條、番茄免費小説、剪映、番茄暢聽、豆包。&lt;/li&gt; 
 &lt;li&gt;百度旗下有 2 款：百度、百度網盤。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;App 規模增長千萬級榜單如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1548&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152718_x9Xf_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前十名的千萬級體量 APP 增速排行榜中，字節旗下產品佔據七夕，分別是：抖音商城、豆包、悟空瀏覽器、紅果免費短劇、抖音精選、汽水音樂、番茄暢聽音樂版，可見字節流量之猛。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337256</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337256</guid>
            <pubDate>Thu, 06 Mar 2025 07:28:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌搜索測試「AI Mode」：整合多模態和實時信息、一鍵解答覆雜問題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌公司昨日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fai-mode-search%2F&quot; target=&quot;_blank&quot;&gt;發佈博文&lt;/a&gt;，邀請谷歌搜索用戶測試全新的&lt;strong&gt;「AI 模式」（AI Mode）&lt;/strong&gt;。用戶可以提出更復雜的問題，並基於搜索結果，AI 生成更詳細、更直觀的答案。&lt;/p&gt; 
&lt;p&gt;谷歌表示，AI 模式將提供更高級的推理、思考和多模態能力，幫助用戶更高效地獲取信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;540&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/150029_Fzwi_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;谷歌表示，以往用戶在處理複雜問題時，往往需要多次搜索才能解決，而「AI 模式」能夠解決這個痛點。用戶只需在桌面或移動設備上輸入查詢，點擊新的「AI 模式」按鈕即可體驗。&lt;/p&gt; 
&lt;p&gt;此外，AI 模式頁面底部還提供了「深入探索」快捷入口，用戶可直接跳過常規搜索結果，專注於 AI 生成的內容。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39952b2fa3ffbf6ae0dc3082083d80b34c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在移動設備上，用戶可以通過上傳圖片或語音輸入查詢，但目前僅支持文本輸出。AI 模式還支持歷史搜索記錄，方便用戶查看過往查詢。&lt;/p&gt; 
&lt;p&gt;AI 模式由定製版的 Gemini 2.0 驅動，能夠訪問實時數據源和知識圖譜等資源。它通過「查詢擴展」技術，從多個子主題和數據源中提取信息，並綜合呈現。如果信息不足，用戶將被引導至網頁搜索結果。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;案例 1：鳥類遷徙路徑&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶提問：「候鳥如何知道遷徙路線？」AI 模式會進行多步搜索並組織結果，在移動設備上以輪播形式展示來源網站，隨後提供簡明答案和相關文章。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 2：戶外拍攝最佳時間&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶詢問：「本週在波士頓公共花園拍攝戶外訂婚照的最佳時間是什麼？」AI 模式結合實時天氣信息，推薦具體日期和黃金時段，並註明日落時間。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 3：睡眠追蹤設備對比&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶提問：「智能戒指、智能手錶和追蹤墊在睡眠追蹤功能上有何區別？」AI 模式以對比表格形式呈現答案，並支持後續問題，如「深度睡眠時心率如何變化？」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;從早期測試來看，AI 模式的查詢長度是傳統搜索的兩倍，用戶有 25% 的時間會進行後續提問。谷歌計劃逐步向所有用戶開放這一功能，目前測試主要面向高級用戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337252/google-ai-mode-search</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337252/google-ai-mode-search</guid>
            <pubDate>Thu, 06 Mar 2025 07:08:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>MongoDB 終於實現盈利，但股價因業績預期不佳而暴跌</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MongoDB 公司&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finvestors.mongodb.com%2Fnews-releases%2Fnews-release-details%2Fmongodb-inc-announces-fourth-quarter-and-full-year-fiscal-2025&quot; target=&quot;_blank&quot;&gt;公佈&lt;/a&gt;了 2025 財年第四季度業績，終於實現了季度盈利，超出了華爾街對盈利和收入的目標。但該公司對新財年的預期卻令人大失所望，導致投資者紛紛逃離，其股價在尾盤交易中暴跌。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該公司報告稱，扣除股票薪酬等某些成本前的每股收益為 1.28 美元，營收為 5.484 億美元，比去年同期增長 20%。這些數字遠遠超出了分析師的預期，分析師此前預計該公司每股收益僅為 60 美分，銷售額為 5.21 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本季度訂閲收入增長了 19%，服務收入增長了 34%，公司繼續以驚人的速度增加新客戶，本季度結束時新客戶數量已超過 54,500 名。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;總而言之，該公司的淨收入為 1580 萬美元 —— 雖然利潤不高，但要好於一年前的 5550 萬美元淨虧損。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-09822091507c54b3e53dd83a09a400a41e2.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;然而儘管這些數據很穩健，該公司對新財年的預期卻令人失望。MongoDB 表示，預計每股收益在 2.44 美元至 2.62 美元之間，遠低於華爾街 3.38 美元的目標。在收入方面，該公司預計收入在 22.4 億美元至 22.8 億美元之間，低於華爾街 23.3 億美元的普遍預期。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在報告發布之前，MongoDB 股價當天早些時候上漲了 3% 以上，但投資者因預期下調而放棄交易。盤後，該股暴跌逾 16%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MongoDB 最近還進行了一項重要收購，收購了一家名為 Voyage AI Inc. 的初創公司，「支持下一代 AI 應用的先進嵌入和重新排序模型的先驅」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MongoDB 總裁兼首席執行官 Dev Ittycheria 在談到此次收購時表示：「收購 Voyage AI 之後，我們將實時數據、複雜的嵌入和檢索模型以及語義搜索直接結合在數據庫中，簡化了可信賴的人工智能應用程序的開發。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管盤後下跌，但 MongoDB 股價今年迄今仍上漲逾 13%。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337249/mongodb-fourth-quarter-and-full-year-fiscal-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337249/mongodb-fourth-quarter-and-full-year-fiscal-2025</guid>
            <pubDate>Thu, 06 Mar 2025 06:56:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信「史詩級」更新：新增「清理原圖 / 視頻」功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在最新版本的 iOS 和 Android 微信版本中，微信熱更新了一個針對清理存儲空間緩存的功能，在「設置 – 通用 – 存儲空間」當中，可以查看已接收和已發出的原圖、原視頻。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-14c220568032f76d5204db7983e2d087abf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該界面頂部還有一行小字寫着「清理原圖、原視頻可以節省存儲空間」。在清理後，用戶仍可在聊天中看到普通畫質的圖片、視頻。&lt;/p&gt; 
&lt;p&gt;在原圖、原視頻點開之後右側選項之後，會彈出「按文件大小查看」或「按聊天大小查看」，進而按照大小、時間、類型查看具體的原圖、原視頻，自行選擇需要清理的內容。&lt;/p&gt; 
&lt;p&gt;經網友實測，清理了「原圖」之後，被清理的內容仍會在聊天記錄中顯示，但畫質已降低。該功能既能避免「圖片已過期」，還能騰出存儲空間，實現微信瘦身。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337248</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337248</guid>
            <pubDate>Thu, 06 Mar 2025 06:45:30 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 擬推月費 2 萬美元的博士級 AI Agent</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenai-plots-charging-20-000-a-month-for-phd-level-agents&quot; target=&quot;_blank&quot;&gt;The Information&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;消息稱，OpenAI 計劃對達到博士水平的 AI Agent 每月收取高達 2 萬美元的費用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eab847f1c359ba1e53fa20ee5c01f5d983f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據悉，OpenAI 計劃針對不同應用推出幾款不同類型的 AI Agent 產品，包括對銷售線索進行分類和排名以及軟件工程。除了最昂貴的這款每月 2 萬美元，旨在支持 「博士級研究」的；還有一款是「high-income knowledge worker」 agent，每月收費 2,000 美元。另一款是軟件開發人員代理，每月收費 10,000 美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前還不清楚這些代理工具何時推出，也不清楚哪些客戶有資格購買這些工具。但 The Information 指出，OpenAI 的投資者軟銀承諾，僅今年一年就將在 OpenAI 的 agent 產品上投資 30 億美元。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337244/openai-20000-phd-level-agents</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337244/openai-20000-phd-level-agents</guid>
            <pubDate>Fri, 28 Feb 2025 06:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>家人們，源創會 —— 南京站重磅來襲！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟 活動主題&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;div&gt;
   ⽣成式 AI 應⽤構建 
 &lt;/div&gt; 
 &lt;div&gt;
   便宜⼜好⽤的 DeepSeek 在春節期間強勢出圈，這不僅彰顯了市場對⾼效能⽣成式 AI⼯具的迫切需，求，也預⽰着⽣成式 AI 技術將步⼊新的發展階段。 
 &lt;/div&gt; 
 &lt;div&gt;
   從早期的簡單⽂本⽣成，到如今涵蓋圖像、⾳頻、視頻乃⾄複雜代碼的全⽅位內容創造，⽣成式 AI 正，逐漸滲透到各⾏各業，成為推動社會進步和產業變⾰的關鍵⼒量。未來，隨着成本的不斷降低，⽣成，式 AI 應⽤⽆疑將遍地開花。特別是在開發者領域，⽣成式 AI 不僅提供了前所未有的創新⼯具，更在某種，程度上重新定義了軟件開發和創意實現的邊界。本場源創會，我們將聚焦那些好⽤好玩的⽣成式 AI 應 ⽤，瞭解它們如何被構建，⼜如何發揮巨⼤的價值。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;⏰&lt;/span&gt;時間：03-22 14:00 至 18:00&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;🚗&lt;/span&gt;地點：南京瑞瀾庭院酒店（南京秦淮區瑞金路街道解放路 46 號）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;👉&lt;/span&gt;【免費報名】：&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟 演講嘉賓及議程&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;681&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/144331_OsJv_4574978.png&quot; width=&quot;667&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;strong&gt;演講嘉賓：&amp;nbsp;&lt;/strong&gt;張旭陽， 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;中國科學院軟件研究所工程師&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;strong&gt;演講議題：&lt;/strong&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;【RISC-V 上 AI 應用與實踐】&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;strong&gt;議題簡介：&amp;nbsp;&lt;/strong&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;介紹 AI 大模型在 RISC-V 架構的一些應用與實踐，包括自研 AI 助手，主流大模型適配到 RISC-V 的最新進展與經驗分享等。&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;img height=&quot;676&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/144435_5BuS_4574978.png&quot; width=&quot;659&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;strong&gt;演講嘉賓：&lt;/strong&gt; 
   &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;span&gt;&lt;span&gt;張文峯&amp;nbsp;&lt;/span&gt;&lt;/span&gt;， 
   &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;span&gt;&lt;span&gt;智子互聯創始人、CEO&lt;/span&gt;&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;strong&gt;演講議題：&lt;/strong&gt; 
   &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;span&gt;&lt;span&gt;大模型智能體系統的構建與應用——從平台創新到垂直場景落地&lt;/span&gt;&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;strong&gt;議題簡介：&lt;/strong&gt; 
   &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;span&gt;&lt;span&gt;在生成式 AI 技術爆發的當下，大模型如何從單純的對話工具進化為具備自主決策、任務執行和持續進化能力的智能體系統，已成為行業探索的核心方向。本次演講議題將圍繞南京智子互聯科技在智能體系統構建中的技術實踐與產業落地經驗展開，深入解析大模型智能體平台的核心架構設計、垂直領域應用的創新路徑，以及智能體技術在指揮控制等複雜場景中的突破性應用。&lt;/span&gt;&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;img height=&quot;714&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/144141_Tmnt_4574978.png&quot; width=&quot;657&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;div&gt; 
    &lt;strong&gt;演講嘉賓：&lt;/strong&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;李奇峯&amp;nbsp;&lt;/span&gt;&lt;/span&gt;， 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;PowerData 社區主理人&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;strong&gt;演講議題：&lt;/strong&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;使用 DeepSeek 拯救數據中台&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;strong&gt;議題簡介：&lt;/strong&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;span&gt;&lt;span&gt;數據中台建設的必要性毋庸置疑，但是如何建設一個易用好用的數據中台，讓業務團隊真正用起來併產生業務價值，目前業內尚未產生通用且統一的解決方案。&lt;br&gt; 在 DeepSeek 火熱的當下，我們可以藉助大模型通用化與生成式的數據處理能力，結合數據中台中的落地痛難點，對其進行針對性的優化改造。&lt;/span&gt;&lt;/span&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;712&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/143513_GjF1_4574978.png&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;strong&gt;演講嘉賓：&lt;/strong&gt; 
     &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
     &lt;span&gt;&lt;span&gt;魏佳星&amp;nbsp;&lt;/span&gt;&lt;/span&gt;， 
     &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
     &lt;span&gt;&lt;span&gt;雲蝠智能創始人\CEO&lt;/span&gt;&lt;/span&gt; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;strong&gt;演講議題：&lt;/strong&gt; 
     &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
     &lt;span&gt;&lt;span&gt;大模型時代如何構建企業核心競爭力&lt;/span&gt;&lt;/span&gt; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;strong&gt;議題亮點：&lt;/strong&gt;&amp;nbsp; 
     &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
     &lt;span&gt;&lt;span&gt;1.AI&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
     &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
     &lt;span&gt;&lt;span&gt;行業的趨勢和變革；2.營銷及銷售側的&amp;nbsp;AI&amp;nbsp;應用（面向&amp;nbsp;AI&amp;nbsp;的新一代營銷體系+如何構建企業知識大腦）；3.呼叫行業的&amp;nbsp;AI&amp;nbsp;變革和應用落地；4.在研發、採購及決策層如何引入 AI。&lt;/span&gt;&lt;/span&gt; 
    &lt;/div&gt; 
    &lt;div&gt;
      &amp;nbsp; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;img height=&quot;700&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/143417_LOzR_4574978.png&quot; width=&quot;657&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;strong&gt;演講嘉賓：&lt;/strong&gt; 
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;&amp;nbsp;陳一言 
      &lt;span&gt;&amp;nbsp;&lt;/span&gt; 
      &lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;，&amp;nbsp;文心快碼 Baidu Comate 研發工程師 
     &lt;/div&gt; 
     &lt;div&gt; 
      &lt;strong&gt;演講議題：&lt;/strong&gt;&amp;nbsp;&amp;nbsp;用 Baidu Comate 打造 Comate 
     &lt;/div&gt; 
     &lt;div&gt; 
      &lt;strong&gt;議題亮點：&lt;/strong&gt;&amp;nbsp; 在 AI 代碼助手加速重塑軟件研發範式的當下，百度 Comate 如何通過，續寫智能體數據飛輪，驅動自身能力迭代，並基於智能體 Zulu（Auto Developer）打造具備，自主規劃、代碼生成、調試優化，能力的智能開發者？本次演講將圍繞 Comate 的技術演進，解析其在，智能體數據閉環訓練、Agent 規劃與執行、跨文件理解，等關鍵能力上的創新，並對比當前主流編碼智能體，展示 Comate 在，智能化、精準性與代碼可靠性保障，上的差異化優勢。 
      &lt;p&gt;此外，我們將重點剖析 &amp;nbsp;Zulu 在百度及行業中的實踐案例，探討其如何向更高級的編碼智能體演進，包括，自我開發工具、鏈接外部數據庫、完備記憶管理、多模型協作，等前沿能力，構建真正具備，自主成長與長期任務執行，能力的 Auto Developer，並展望未來智能體驅動的研發模式變革。&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
    &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟 獎品池&lt;/span&gt;&lt;/h2&gt; 
    &lt;p&gt;&lt;img height=&quot;1080&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/134716_gbNS_4574978.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
  &lt;h1&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟 志願者招募&lt;/span&gt;&lt;/h1&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#4a4a4a; text-align:start&quot;&gt;如果你想打入 OSC 編輯部內部，如果你想了解一場技術沙龍是怎麼組織起來的，如果你想 get OSC 精美周邊，快來加入我們，成為現場志願者吧！！！（請加微信：13520780247）&lt;/p&gt; 
  &lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟&amp;nbsp;加入交流羣&lt;/span&gt;&lt;/h2&gt; 
  &lt;p&gt;&lt;img height=&quot;238&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0221/110558_fDqZ_4574978.png&quot; width=&quot;236&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟&amp;nbsp;邀請有禮&lt;/span&gt;&lt;/h2&gt; 
  &lt;div&gt;
    參加南京源創會 ，邀請身邊開發者好友來一起參會，get 開源中國精美周邊 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;br&gt; ✍️具體規則： 
   &lt;br&gt; 1. 發送活動報名鏈接給開發者好友，邀請 TA 一起參會 
   &lt;br&gt; 2. 被邀請人需在報名錶單 「邀請人姓名」 一欄中填寫邀請人的名稱 
   &lt;br&gt; 3. 3 月 22 日活動現場，超 2 名被邀請人完成簽到，則邀請人可獲得 OSC 周邊 T 恤或開源魔方 1 件 
  &lt;/div&gt; 
  &lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;&lt;strong&gt;關於源創會&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;div&gt;
    OSC 源創會是開源中國社區（oschina.net）主辦，聚焦開源、創新的技術沙龍。源創會始終秉承「自由、開放、分享」的宗旨，聚集最優質的技術資源與行業案例，對話最優秀的技術領軍人物，為廣大開發者帶來最新開源技術、前沿技術視角、以及落地實踐經驗。 
  &lt;/div&gt; 
  &lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;🌟&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;&lt;strong&gt;關於開源中國&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
  &lt;div&gt;
    OSCHINA 成立於 2008 年 8 月，目前已建立了相當完善的開源軟件分類數據庫，收錄全球知名開源項目近 10 萬款，涉及幾百個不同的分類。圍繞這些開源項目，OSCHINA 為中國開發者提供了最新開源資訊、軟件更新資訊、技術分享和交流的技術平台。2013 年，OSCHINA 建立了代碼託管與 DevOps 平台「碼雲 Gitee」，為廣大開發者提供團隊協作、源碼託管、代碼質量分析、代碼評審、測試、CI/CD 與代碼演示等功能。 
  &lt;/div&gt; 
  &lt;div&gt;
    經過在開源領域超過十年的深耕，以及與中國本土開源環境的結合，推動了中國開源領域的快速發展。OSCHINA 目前已發展成為國內知名的開源技術社區，社區有 1500 萬開發者活躍，長期致力於推動國內開源軟件的應用和發展，提升本土開源能力，以及為開源生態環境的優化提供支持。 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4574978/blog/17836431</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4574978/blog/17836431</guid>
            <pubDate>Fri, 28 Feb 2025 06:29:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>在線老虎機遊戲 UI 漏洞導致博彩公司損失近 100 萬英鎊</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bbc.co.uk%2Fnews%2Farticles%2Fcx2gl2n2n14o&quot; target=&quot;_blank&quot;&gt;BBC&lt;/a&gt; 報道稱，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;2020 年 10 月，一位來自英國英格蘭格洛斯特郡的園丁 Corrine Durber 在玩 Wild Hatter（愛爾蘭體育博彩公司 Paddy Power 旗下的一款線上老虎機博彩遊戲）遊戲時，結算頁面顯示她贏得了「Monster Jackpot」獎項，金額高達 1,097,132.71 英鎊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但 Paddy Power 卻以該用戶實際中只是中了&quot;Daily Jackpot&quot;為由，僅支付了 20,265 英鎊，稱差額歸因於遊戲顯示界面的編程錯誤。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對此，Durber 以屏幕上顯示的內容為依據，起訴了 Paddy Power 和 Betfair 的母公司 PPB Entertainment Limited，指控其違約並要求支付剩餘的獎金。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在當地時間本週三的判決中，法官作出了有利於 Durber 的簡易判決：「當商家因自身的魯莽、疏忽、錯誤、數字服務不足和測試不足而將所有風險轉嫁給消費者時，這在我看來是不合理的。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;393&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-402d7ef5c362952bcd0a58a6c7077403ca7.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Corrine Durber 與丈夫 Colin（左）和律師 Peter Coyle（右）在高等法院外合影&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Durber 在接受採訪時表示，這筆錢將改變她家人的生活。「顯然，這將用於照顧孩子們，我們會幫他們還清抵押貸款，並享受我們的退休生活」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;PPB 曾辯稱，遊戲結果是由隨機數生成器決定的，該生成器顯示 Durber 只贏得了&quot;Daily Jackpot&quot;；但因為 bug 影響了遊戲結算動畫，導致顯示了錯誤的結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對此，法官則表示，「所見即所得」的理念是遊戲的核心。他在一份 62 頁的裁決中繼續寫道：「客觀地説，顧客會希望並期待屏幕上顯示的內容是準確和正確的。當顧客進入實體賭場玩輪盤賭時，可能也會有同樣的期望。如果他們押注 13 號，而球落在 13 號上，他們期望賭場會支付獎金。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;法官發現，由於軟件映射中的人為錯誤，隨機數生成器的結果與屏幕上的結果不同，這一 bug 共影響了 48 天內的 14 次遊戲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;裁決作出後，Paddy Power 的一位發言人表示：「我們始終努力提供最佳的客戶體驗，並以公平為榮。我們對這起不幸的案件深表遺憾，並正在對判決進行復審。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337229</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337229</guid>
            <pubDate>Fri, 28 Feb 2025 05:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>史上最強芯片：蘋果 M3 Ultra 支持 512 GB 統一內存、可本地部署滿血版 DeepSeek R1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;蘋果昨天&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2025%2F03%2Fapple-reveals-m3-ultra-taking-apple-silicon-to-a-new-extreme%2F&quot; target=&quot;_blank&quot;&gt;正式發佈&lt;/a&gt;&lt;/u&gt;了迄今打造的最強芯片&amp;nbsp;&lt;span&gt;M3 Ultra —— 將 Apple 芯片性能提升至新極限。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;新芯片性能比 M1 Ultra 提升最多達 2.6 倍，最高支持 512 GB 統一內存，創個人電腦內存新高，此外還&lt;/span&gt;配備了 Mac 性能最強勁的中央處理器和圖形處理器，神經網絡引擎核心數量翻倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1d71f48b7a0d7ae41433386bb9e2aa9072.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;M3 Ultra 芯片亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;起步內存 96GB，最高可配置 512GB 內存&lt;/li&gt; 
 &lt;li&gt;內部共集成 1,840 億個晶體管&lt;/li&gt; 
 &lt;li&gt;支持雷靂 5 連接，數據傳輸速度最高可達 120 Gb/s，比雷靂 4 提升達 2 倍以上&lt;/li&gt; 
 &lt;li&gt;配備最多 32 核中央處理器，包括 24 顆性能核心和 8 顆能效核心，性能最高可達 M2 Ultra 的 1.5 倍，M1 Ultra 的 1.8 倍&lt;/li&gt; 
 &lt;li&gt;擁有 Apple 芯片中最強的圖形處理器，包括最多 80 顆圖形處理核心，性能比 M2 Ultra 提升最多達 2 倍，比 M1 Ultra 提升最多達 2.6 倍&lt;/li&gt; 
 &lt;li&gt;採用創新的 UltraFusion 封裝架構，通過超過 10,000 個高速連接點，將兩枚 M3 Max 晶粒整合在一起，可同時傳輸超過 10,000 個信號，帶來超過 2.5TB/s 的低延遲片間帶寬，提供低延遲和高帶寬的傳輸能力&lt;/li&gt; 
 &lt;li&gt;提供了專屬的硬件加速 H.264、HEVC 與四個 ProRes 編解碼引擎，能夠播放最多可達 22 條 8K ProRes 422 視頻流。&lt;/li&gt; 
 &lt;li&gt;顯示引擎支持最多 8 台 Pro Display XDR，呈現超過 1.6 億顆像素&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2025%2F03%2Fapple-reveals-m3-ultra-taking-apple-silicon-to-a-new-extreme%2F&quot; target=&quot;_blank&quot;&gt;詳情查看官方介紹&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/337201/apple-unveils-new-mac-studio-m3-ultra&quot; target=&quot;news&quot;&gt;蘋果發佈「核彈級」 Mac Studio：頂配售價超 10 萬、最強處理器 M3 Ultra 正式亮相&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337215/apple-m3-ultra-new-extreme</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337215/apple-m3-ultra-new-extreme</guid>
            <pubDate>Fri, 28 Feb 2025 03:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>LSM-TREE 從入門到入魔：從零開始實現一個高性能鍵值存儲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、引，言&lt;/h1&gt; 
&lt;p&gt;LSM-Tree（Log-Structured Merge Tree）是一種高效的鍵值存儲數據結構，廣泛應用於 NoSQL 數據庫和大數據處理系統中。其核心思想是通過分層、有序地利用磁盤順序寫入的性能優勢，優化寫入操作，同時犧牲部分讀取性能以換取更高的寫入吞吐量。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3983af5521bbb144f98321026a45d75a.jpeg&quot; alt=&quot;引言.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e78c25208e08de7c918d0a3ff99efdfe.jpeg&quot; alt=&quot;引言 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 在互聯網的各個基礎設施中，不論是數據庫還是緩存亦或是大數據框架，LSM-Tree 這個數據結構都是很常見的身影。&lt;/p&gt; 
&lt;p&gt;我每天都在使用這個存儲引擎，但是對它的瞭解還流於表面，所以我想要自己實現一次 LSM-Tree 加深理解。&lt;/p&gt; 
&lt;p&gt;本次實現我們採用了 Zig 語言，簡要的實現 LSM-Tree 的核心功能（讀寫、數據壓縮、持久化，不包含 MVCC 的內容）。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Zig 是一種新興的系統編程語言，其設計目標是提供現代特性的同時保持低複雜性。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;本項目極大的受到了 Mini-Lsm 這個項目的啓發，強烈推薦大家學習這個項目！&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;二、LSM-Treee 核心功能概述&lt;/h1&gt; 
&lt;p&gt;在開始自己編寫之前，我先簡單介紹一下 LSM-Tree（&lt;strong&gt;Log-Structured Merge Tree&lt;/strong&gt;）的架構以及讀寫流程。&lt;/p&gt; 
&lt;p&gt;LSM-Tree 它結合了日誌和索引的特點，優化了寫入和讀取性能。每次寫入都是採用 append-only 的方式，所以寫入性能很高。&lt;/p&gt; 
&lt;p&gt;而作為代價，追加寫入會造成存儲放大，LSM-Tree 時採用了多層 SSTable 的方式將數據堆疊在硬盤上。所以需要一個合併壓縮的過程來回收過多的空間。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d49f94616047080aabc5ff8f4d80024f.jpeg&quot; alt=&quot;合併壓縮的過程.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;寫流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;預寫日誌&lt;/strong&gt; （&lt;strong&gt;WAL&lt;/strong&gt;） ：寫操作首先寫入預寫日誌（WAL），用於記錄未提交的數據，確保數據的持久性和一致性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MemTable&lt;/strong&gt;：隨後將數據寫入內存中的 MemTable，MemTable 是一個平衡樹（如 skiplist），支持快速插入和刪除操作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;觸發 Compaction&lt;/strong&gt;：當 MemTable 達到一定閾值時，會觸發後台線程將 MemTable 中的數據刷入磁盤，生成 SSTable 文件。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSTable&lt;/strong&gt;：生成的 SSTable 文件是不可變的，存儲在磁盤上，用於後續讀取操作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;合併操作&lt;/strong&gt; （&lt;strong&gt;Merge&lt;/strong&gt;） ：當多個 SSTable 文件達到一定數量時，會觸發合併操作，將它們合併為一個更大的 SSTable 文件，以減少文件數量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;讀流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MemTable 優先&lt;/strong&gt;：讀取操作首先從 MemTable 中查找數據，因為 MemTable 是按升序排列的，查找效率較高。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Block Cache&lt;/strong&gt;：如果 MemTable 中未找到數據，則從 Block Cache 中查找。Block Cache 存儲了預先加載到內存中的 SSTable 塊，以提高讀取性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSTable 查找&lt;/strong&gt;：如果 Block Cache 中也未找到數據，則從磁盤上的 SSTable 文件中查找。Lsm-tree 會從最低層（L0）開始查找，逐層向上查找，直到找到目標數據。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多版本併發控制&lt;/strong&gt; （&lt;strong&gt;MVCC&lt;/strong&gt;） ：Lsm-tree 支持多版本併發控制，允許同時訪問不同版本的數據，從而提高併發性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;三、核心功能實現&lt;/h1&gt; 
&lt;h2&gt;MemTable 實現&lt;/h2&gt; 
&lt;p&gt;首先，我們先實現 LSM 存儲引擎的內存結構---Memtable。我們選擇&lt;strong&gt;跳錶&lt;/strong&gt;實現作為 Memtable 的數據結構，因為它支持無鎖的併發讀寫。我們不會深入介紹跳錶的工作原理 (Redis 的同學應該不陌生這個東西)，簡單來説，它是一個易於實現的有序鍵值映射。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//adc116878e613d568440d87fb5500640.jpeg&quot; alt=&quot;有序健值.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; Skiplist 的實現非常簡單，這裏我利用 Zig 編譯時的能力實現了一個泛型版本的跳錶 src/skiplist.zig，有興趣的小夥伴可以直接去倉庫中參觀代碼。&lt;/p&gt; 
&lt;p&gt;基於 SkipList 的能力，我們即可包裝出 Memtable 的基本功能。&lt;/p&gt; 
&lt;p&gt;我們這個 LSM 支持 WAL 功能的，即寫入內存表之前要先寫入磁盤日誌，方便在意外宕機重啓後可以恢復數據。&lt;/p&gt; 
&lt;p&gt;WAL 的能力我就不想自己再實現了，於是從網上扒了一個 C 的實現（Zig 集成 C 語言非常便捷，可以參考與 C 交互）。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;map: Map,
lock: RwLock,
wal: ?Wal,
id: usize,
allocator: std.mem.Allocator,
arena: std.heap.ArenaAllocator,
approximate_size: atomic.Value(usize) = atomic.Value(usize).init(0),

fn putToList(self: *Self, key: []const u8, value: []const u8) !void {
    {
        self.lock.lock();
        defer self.lock.unlock();
        try self.map.insert(kk, vv);
    }

    _ = self.approximate_size.fetchAdd(@intCast(key.len + value.len), .monotonic);
}

fn putToWal(self: *Self, key: []const u8, value: []const u8) !void {
    // [key-size: 4bytes][key][value-size: 4bytes][value]

    if (self.wal) |w| {
        var buf = std.ArrayList(u8).init(self.arena.allocator());

        var bw = buf.writer();
        try bw.writeInt(u32, @intCast(key.len), .big);
        _ = try bw.write(key);
        try bw.writeInt(u32, @intCast(value.len), .big);
        _ = try bw.write(value);
        try w.append(buf.items);
    }
}

// 寫入 Memtable，先寫 WAL，再寫 skiplist table
pub fn put(self: *Self, key: []const u8, value: []const u8) !void {
    try self.putToWal(key, value);
    try self.putToList(key, value);
}

pub fn get(self: *Self, key: []const u8, val: *[]const u8) !bool {
    self.lock.lockShared();
    defer self.lock.unlockShared();
    var vv: []const u8 =     ;
    if (try self.map.get(key, &amp;amp;vv)) {
        val.* = vv;
        return true;
    }
    return false;
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;注意到這裏我們沒有實現刪除的功能，這裏我仿照了 RocksDB 中的墓碑機制，用空值代表刪除，所以刪除被 put(key, &quot;&quot;) 取代。&lt;/p&gt; 
&lt;h2&gt;SSTable&lt;/h2&gt; 
&lt;p&gt;接下來，我們就着手開始實現 LSM 中另外一個重要元素 --- SSTable。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;SSTable（Sorted String Table）是一種不可變的（Immutable）磁盤文件，內部按 Key 有序排列，存儲鍵值對數據。每個 SSTable 文件生成後不再修改，更新和刪除操作通過追加新記錄或標記刪除，最終通過合併（Compaction）清理冗餘數據。 每當 LSM-Tree 中的 MemTable 體積超出閾值，就會將內存中的數據寫入 SsTable。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//441435c815897a51832a32a1157637ae.jpeg&quot; alt=&quot;內存中的數據.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 每個 SSTable 由多個 Block 組成，每個 Block 是一組 KV 的 package。&lt;/p&gt; 
&lt;p&gt;Block 的&lt;strong&gt;編碼格式&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec2724e561fe943e071d00506663be9d.jpeg&quot; alt=&quot;block 的健碼格式.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 為了構建一個 Block，我們實現了一個&lt;strong&gt;BlockBuilder&lt;/strong&gt;的模塊，這部分代碼見 src/block.zig：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const Block = struct {
    data_v: std.ArrayList(u8),
    offset_v: std.ArrayList(u16),
}

pub const BlockBuilder = struct {
    allocator: std.mem.Allocator,
    offset_v: std.ArrayList(u16),
    data_v: std.ArrayList(u8),
    block_size: usize,
    first_key: []u8,
    
    pub fn add(self: *Self, key: []const u8, value: ?[]const u8) !bool {
        std.debug.assert(key.len &amp;gt; 0); // key must not be empty

        const vSize = if (value) |v| v.len else 0;
        
        if ((self.estimated_size() + key.len + vSize + 3 * @sizeOf(u16) &amp;gt; self.block_size) and !self.is_empty()) {
            return false;
        }
        try self.doAdd(key, value);

        if (self.first_key.len == 0) {
            self.first_key = try self.allocator.dupe(u8, key);
        }
        return true;
    }

    fn doAdd(self: *Self, key: []const u8, value: ?[]const u8) !void {
        // add the offset of the data into the offset array
        try self.offset_v.append(@intCast(self.data_v.items.len));
        const overlap = calculate_overlap(self.first_key, key);

        var dw = self.data_v.writer();
        // encode key overlap
        try dw.writeInt(u16, @intCast(overlap), .big);
        // encode key length
        try dw.writeInt(u16, @intCast(key.len - overlap), .big);

        // encode key content
        _ = try dw.write(key[overlap..]);
        // encode value length
        if (value) |v| {
            try dw.writeInt(u16, @intCast(v.len), .big);
            // encode value content
            _ = try dw.write(v);
        } else {
            try dw.writeInt(u16, 0, .big);
        }
    }

    pub fn build(self: *Self) !Block {
        if (self.isEmpty()) {
            @panic(&quot;block is empty&quot;);
        }
        return Block.init(
            try self.data_v.clone(),
            try self.offset_v.clone(),
        );
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可能有同學注意到，我們寫 key 的時候沒有直接將 key 值寫入，而且只寫了 key 與當前 block 的第一個 key 不重疊的 suffix 部分。由於 block 中的 key 都是有序的，所以一個 block 中的 key 有很大概率是前綴類似的，所以這裏是一個空間優化的小技巧，例如：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key: foo, foo1, foo2, foo3 ....&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們寫入 block 時，只需要寫：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;foo|1|2|3|....&lt;/strong&gt; 很多有序表的實現中都會用到這個小技巧。&lt;/p&gt; 
&lt;p&gt;有了 block 的實現，我們可以進一步來定義 SSTable 的格式。一個 SSTable 由多個 Block、block 元數據以及布隆過濾器構成。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e183c694bf3c0e2a6ec6b15651d5fbee.jpeg&quot; alt=&quot;布隆過濾器.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;布隆過濾器是一種概率性數據結構，用於維護一組鍵。您可以向布隆過濾器中添加鍵，並且可以知道在添加到布隆過濾器中的鍵集中可能存在或必須不存在的鍵。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;在 SSTable 中添加布隆過濾器可以有效提升查詢 key 的效率。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;元數據包含了 block 的&lt;strong&gt;第一個與最後一個 key 以及 block 在 sst 中的 offset 信息&lt;/strong&gt;，記錄元數據主要為了在後續的檢索中可以快速定位某個 key 落在哪個 block 中。&lt;/p&gt; 
&lt;p&gt;同樣的套路，為了構建 SSTable，我們先實現一個&lt;strong&gt;SSTableBuilder&lt;/strong&gt;，部分代碼見 src/ss_table.zig&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const SsTableBuilder = struct {
    allocator: std.mem.Allocator,
    builder: BlockBuilder, // 剛才實現的 block 構建裝置
    first_key: ?[]const u8,
    last_key: ?[]const u8,
    meta: std.ArrayList(BlockMeta),
    block_size: usize,
    data: std.ArrayList(u8),
    bloom: BloomFilterPtr, // 布隆過濾器
    
    pub fn add(self: *Self, key: []const u8, value: []const u8) !void {
        try self.setFirstKey(key);
        try self.bloom.get().insert(key); // 寫入布隆過濾器

        if (try self.builder.add(key, value)) {
            try self.setLastKey(key);
            return;
        }
        // block is full
        try self.finishBlock();
        std.debug.assert(try self.builder.add(key, value));
        try self.resetFirstKey(key);
        try self.setLastKey(key);
    }
    
    // 寫入一個 block 的數據
    fn finishBlock(self: *Self) !void {
        if (self.builder.isEmpty()) {
            return;
        }
        var bo = self.builder;
        // reset block
        defer bo.reset();

        self.builder = BlockBuilder.init(self.allocator, self.block_size);
        var blk = try bo.build();
        defer blk.deinit();
        const encoded_block = try blk.encode(self.allocator); // block 序列化
        defer self.allocator.free(encoded_block);
        
        // 記錄 block 的元數據
        try self.meta.append(.{
            .allocator = self.allocator,
            .offset = self.data.items.len,
            .first_key = try self.allocator.dupe(u8, self.first_key.?),
            .last_key = try self.allocator.dupe(u8, self.last_key.?),
        });
        const cksm = hash.Crc32.hash(encoded_block); // 寫入 4b 的校驗值
        try self.data.appendSlice(encoded_block);
        try self.data.writer().writeInt(u32, cksm, .big);
    }
    
    // 構建為一個 SSTable
    pub fn build(
        self: *Self,
        id: usize,
        block_cache: ?BlockCachePtr, // 讀取 block 數據的緩存，減少 block 的反序列化成本
        path: []const u8,
    ) !SsTable {
        var arena = std.heap.ArenaAllocator.init(self.allocator);
        defer arena.deinit();
        const allocator = arena.allocator();

        try self.finishBlock();
        const w = self.data.writer();
        
        // 寫入元數據及其 offset
        const meta_offset = self.data.items.len;
        const meta_b = try BlockMeta.batchEncode(self.meta.items, allocator);
        _ = try w.write(meta_b);
        try w.writeInt(u32, @intCast(meta_offset), .big);

        // 寫入布隆過濾器及其 offset
        const bloom_offset = self.data.items.len;
        const encoded_bloom = try self.bloom.get().encode(allocator);
        _ = try w.write(encoded_bloom);
        try w.writeInt(u32, @intCast(bloom_offset), .big);
        
        
        const file = try FileObject.init(path, self.data.items);
        errdefer file.deinit();

        const fk = self.meta.items[0].first_key;
        const lk = self.meta.getLast().last_key;

        return .{
            .allocator = self.allocator,
            .file = file,
            .block_metas = try self.meta.toOwnedSlice(),
            .meta_offset = meta_offset,
            .block_cache = block_cache,
            .bloom = self.bloom.clone(),
            .id = id,
            .first_key = try self.allocator.dupe(u8, fk),
            .last_key = try self.allocator.dupe(u8, lk),
            .max_ts = 0,
        };
    }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Write&lt;/h2&gt; 
&lt;p&gt;有了 SSTable 和 MemTable，我們就有了 LSM-Tree 需要的兩個最重要的材料，後續的讀寫不過是對這兩類材料的組合拼裝。&lt;/p&gt; 
&lt;p&gt;在實現寫操作之前，我們先假想一下 LSM-Tree 的數據結構: &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e8b35c69dad1058161979d0761a78d91.jpeg&quot; alt=&quot;lsmtree 的數據結構.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先我們需要一個數據結構存儲當前 MemTable、冷 MemTables 和多層的 SST，如下圖所示。 圖片&lt;/li&gt; 
 &lt;li&gt;其次我們需要一個鎖用於同步上述數據結構的讀寫行為。&lt;/li&gt; 
 &lt;li&gt;我們還需要一個 SSTable 的自增 id。&lt;/li&gt; 
 &lt;li&gt;最後還需要一些必要的配置，例如存儲路徑、線程管理器等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;最終，我們實現的 LSM 數據結構如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const StorageState = struct {
    allocator: std.mem.Allocator,
    mem_table: MemTablePtr, // 當前正在寫的 MemTable
    imm_mem_tables: std.ArrayList(MemTablePtr), // 冷 MemTable 數組
    l0_sstables: std.ArrayList(usize), // 第一層的 SSTable 數組
    levels: std.ArrayList(std.ArrayList(usize)), // 後續多層的 SSTable 數組
    sstables: std.AutoHashMap(usize, SsTablePtr), // sst_id =&amp;gt; SSTable
}

pub const StorageInner = struct {
    const Self = @This();

    allocator: std.mem.Allocator,
    state: StorageState,
    state_lock: std.Thread.RwLock = .{},
    next_sst_id: atomic.Value(usize),
    path: []const u8,
    options: StorageOptions,
    compaction_controller: CompactionController,
    block_cache: BlockCachePtr,
    terminate: std.Thread.ResetEvent = .{},
    wg: std.Thread.WaitGroup = .{},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;先不考慮逐層壓縮的邏輯，只考慮一層 SSTable 的簡單情況，寫邏輯可以簡化為如下流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5e96cf0290f96c4ce85ccfb3f369951.jpeg&quot; alt=&quot;簡化為如下流程.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;寫入 State 中的 MemTable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub fn writeBatch(self: *Self, records: []const WriteBatchRecord) !void {
   for (records) |record| {
       switch (record) {
           .put =&amp;gt; |pp| {
               try self.state.getMemTable().put(pp.key, pp.value);
           },
           .delete =&amp;gt; |dd| {
               // we use &quot;&quot; as the tombstone value
               try self.state.getMemTable().put(dd, &quot;&quot;);
           },
       }
       // 嘗試把當前 MemTable 壓入冷數據
       try self.tryFreeze(self.state.getMemTable().getApproximateSize());
   }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;當 MemTable 體積超出閾值，壓入冷 MemTable 數組，重置當前 MemTable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;fn forceFreezeMemtable(self: *Self) !void {
    const next_sst_id = self.getNextSstId();
    
    // 生成一個新的 MemTable
    var new_mm: MemTable =     ;
    {
        if (self.options.enable_wal) {
            const mm_path = try pathOfWal(self.allocator, self.path, next_sst_id);
            defer self.allocator.free(mm_path);
            new_mm = MemTable.init(next_sst_id, self.allocator, mm_path);
        } else {
            new_mm = MemTable.init(next_sst_id, self.allocator, null);
        }
    }
    errdefer new_mm.deinit();

    var old_mm: *MemTable =     ;
    {
        self.state_lock.lock();
        defer self.state_lock.unlock();
        var old_mm_ptr = self.state.mem_table;
        old_mm = old_mm_ptr.get();
        defer old_mm_ptr.release();
        self.state.mem_table = try MemTablePtr.create(self.allocator, new_mm);
        
        // 將寫滿的 MemTable 壓入冷數據
        try self.state.imm_mem_tables.append(old_mm_ptr.clone()); // newer memtable is inserted at the end
    }
    // TIPS：把磁盤同步放在鎖的範圍外面，降低鎖的覆蓋
    try old_mm.syncWal();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;當冷 MemTable 數組大小超出配置閾值，觸發 SSTable 落盤，彈出最冷的 MemTable，寫入磁盤 SSTable，並記錄在 L0 的 SSTable 數組中。這一過程是在一個線程中定時觸發&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub fn flushNextMemtable(self: *Self) !void {
    std.debug.assert(self.state.imm_mem_tables.items.len &amp;gt; 0);
    var to_flush_table: *MemTable =     ;
    {
        self.state_lock.lockShared();
        defer self.state_lock.unlockShared();
        // oldest memtable is at the index 0
        to_flush_table = self.state.imm_mem_tables.items[0].load();
    }

    // 將最冷的 MemTable 構建為 SSTable
    var builder = try SsTableBuilder.init(self.allocator, self.options.block_size);
    defer builder.deinit();

    const sst_id = to_flush_table.id;
    try to_flush_table.flush(&amp;amp;builder);

    const sst_path = try self.pathOfSst(sst_id);
    defer self.allocator.free(sst_path);
    var sst = try builder.build(sst_id, self.block_cache.clone(), sst_path);
    errdefer sst.deinit();

    // add the flushed table to l0_sstables
    {
        self.state_lock.lock();
        defer self.state_lock.unlock();

        var m = self.state.imm_mem_tables.orderedRemove(0);
        defer m.deinit();
        std.debug.assert(m.load().id == sst_id);

        // newest sstable is at the end
        try self.state.l0_sstables.append(sst_id);
        try self.state.sstables.put(sst.id, try SsTablePtr.create(self.allocator, sst));
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;當然，這裏只實現了一半的寫邏輯，數據停留在 L0 的 SST 中，後續的多層 SST 還沒有使用。&lt;/p&gt; 
&lt;p&gt;剩下一半的寫邏輯會在數據壓縮的章節中介紹。&lt;/p&gt; 
&lt;h2&gt;Iterators&lt;/h2&gt; 
&lt;p&gt;寫入的過程比較好理解，但是讀就略微複雜了，以上面我們實現的寫結果為例子，最終我們的數據沉澱在一個 3 層的數據結構中，要如何高效的從其中檢索數據呢？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//21d6f9e0f2c5dcbdd5570ac5da94ee77.jpeg&quot; alt=&quot;高效檢索數據.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 如同寫過程一般，讀過程也是對各個基礎單元 (MemTable、SSTable、Block) 讀過程的組合，為了方便組合邏輯，我們要先統一各個模塊的讀行為。&lt;/p&gt; 
&lt;p&gt;在 LSM-Tree 中，所有的讀行為都定義為瞭如下的 Interface（Zig 中沒 trait 或者 Interface，所以這裏實例代碼我用 Rust 描述）：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub trait StorageIterator {
    /// Get the current value.
    fn value(&amp;amp;self) -&amp;gt; &amp;amp;[u8];

    /// Get the current key.
    fn key(&amp;amp;self) -&amp;gt; &amp;amp;[u8];

    /// Check if the current iterator is empty.
    fn is_empty(&amp;amp;self) -&amp;gt; bool;

    /// Move to the next position.
    fn next(&amp;amp;mut self) -&amp;gt; anyhow::Result&amp;lt;()&amp;gt;;

    /// Number of underlying active iterators for this iterator.
    fn num_active_iterators(&amp;amp;self) -&amp;gt; usize {
        1
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我們首先對 MemTable、SSTable、Block 這些模塊實現讀接口，代碼可見：src/MemTable.zig，src/block.zig，src/ss_table.zig，這裏單獨簡單介紹下 SSTable 的讀接口實現思路，其他的模塊實現思路類似，感興趣的直接閲讀源碼即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const SsTableIterator = struct {
    allocator: std.mem.Allocator,
    table: SsTablePtr,
    blk: BlockPtr,
    blk_iterator: BlockIteratorPtr,
    blk_idx: usize,

    const Self = @This();


    pub fn initAndSeekToFirst(allocator: std.mem.Allocator, table: SsTablePtr) !Self {
        const s = try seekToFirstInner(allocator, table);
        return .{
            .allocator = allocator,
            .table = table,
            .blk_iterator = s.blk_iter,
            .blk = s.blk,
            .blk_idx = 0,
        };
    }

    pub fn initAndSeekToKey(allocator: std.mem.Allocator, table: SsTablePtr, k: []const u8) !Self {
        const b = try seekToKeyInner(allocator, table, k);
        return .{
            .allocator = allocator,
            .table = table,
            .blk_iterator = b.blk_iter,
            .blk_idx = b.blk_idx,
            .blk = b.blk,
        };
    }

    fn seekToFirstInner(allocator: std.mem.Allocator, table: SsTablePtr) !struct {
        blk: BlockPtr,
        blk_iter: BlockIteratorPtr,
    } {
        var blk = try table.get().readBlockCached(0, allocator); // 讀取第一個 block
        errdefer blk.release();
        var blk_iter = try BlockIterator.createAndSeekToFirst(allocator, blk.clone());
        errdefer blk_iter.deinit();

        return .{
            .blk = blk,
            .blk_iter = try BlockIteratorPtr.create(allocator, blk_iter), // 從 SSTable 的讀接口轉換為 Block 的讀接口
        };
    }

    fn seekToKeyInner(allocator: std.mem.Allocator, table: SsTablePtr, k: []const u8) !struct {
        blk_idx: usize,
        blk: BlockPtr,
        blk_iter: BlockIteratorPtr,
    } {
        const table_ptr = table.get();
        var blk_idx = try table_ptr.findBlockIndex(k);
        var blk = try table_ptr.readBlockCached(blk_idx, allocator);
        errdefer blk.deinit();
        var blk_iter = try BlockIterator.createAndSeekToKey(allocator, blk.clone(), k);
        errdefer blk_iter.deinit();
        var blk_iter_ptr = try BlockIteratorPtr.create(allocator, blk_iter);
        errdefer blk_iter_ptr.release();

        // 如果當前 block 讀完了，跳到下一個 block，並生成 block 的讀接口
        if (blk_iter.isEmpty()) {
            blk_idx += 1;
            if (blk_idx &amp;lt; table_ptr.numBlocks()) {
                {
                    blk.deinit();
                    blk_iter.deinit();
                }
                var blk2 = try table_ptr.readBlockCached(blk_idx, allocator);
                errdefer blk2.deinit();
                var blk_iter2 = try BlockIterator.createAndSeekToFirst(allocator, blk2.clone());
                errdefer blk_iter2.deinit();

                return .{
                    .blk_idx = blk_idx,
                    .blk_iter = try BlockIteratorPtr.create(allocator, blk_iter2),
                    .blk = blk2,
                };
            }
        }
        return .{
            .blk_idx = blk_idx,
            .blk_iter = blk_iter_ptr,
            .blk = blk,
        };
    }

    pub fn key(self: Self) []const u8 {
        return self.blk_iterator.get().key();
    }

    pub fn value(self: Self) []const u8 {
        return self.blk_iterator.get().value();
    }

    pub fn isEmpty(self: Self) bool {
        return self.blk_iterator.get().isEmpty();
    }

    pub fn next(self: *Self) !void {
        try self.blk_iterator.get().next();
        // 若當前的 Block 讀完了，就跳到下一個 block，並生成 Block 讀接口。
        if (self.blk_iterator.get().isEmpty()) {
            self.blk_idx += 1;
            if (self.blk_idx &amp;lt; self.table.get().numBlocks()) {
                self.reset();
                const blk = try self.table.get().readBlockCached(self.blk_idx, self.allocator);
                const blk_iter = try BlockIterator.createAndSeekToFirst(self.allocator, blk.clone());
                self.blk = blk;
                self.blk_iterator = try BlockIteratorPtr.create(self.allocator, blk_iter);
            }
        }
    }
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;有了幾個基本元素的讀接口之後，我們便遇到第一個問題：&lt;strong&gt;我們如何對多個 MemTable 做讀檢索？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//32630b4228aeed16aa135674cfff65a1.jpeg&quot; alt=&quot;如何對多個 m 做檢索.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 這個時候，我們需要一個新的數據結構來實現多個讀實例的合併檢索---- &lt;strong&gt;MergeIterator&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MergeIterator 在內部維護一個二叉堆。堆中數據的優先級如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;當各個迭代器 key 不同時，具有最小 key 的迭代器最優。當多個迭代器有相同的當前 key 時，最新的迭代器一個最優。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假設我們有如下 MemTable（iter1 最新，iter3 最舊）:&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;iter1: b-&amp;gt;del, c-&amp;gt;4, d-&amp;gt;5 iter2: a-&amp;gt;1, b-&amp;gt;2, c-&amp;gt;3 iter3: e-&amp;gt;4&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;經過合併後迭代器結果應該為：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;a 最小，iter2 優先迭代 iter2 迭代一次後，iter1 與 iter2 key 相同，iter1 優先迭代，b-&amp;gt;2 跳過 c 最小，iter1 優先迭代，iter2 中 c-&amp;gt;3 跳過 d 最小，iter1 優先迭代，只剩 iter3，迭代 iter3&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最終結果：a-&amp;gt;1, b-&amp;gt;del, c-&amp;gt;4, d-&amp;gt;5, e-&amp;gt;4&lt;/p&gt; 
&lt;p&gt;實現代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// 標準庫中有二叉堆實現
const IteratorHeap = std.PriorityQueue(*HeapWrapper, Comparer.Context, Comparer.cmp);

allocator: std.mem.Allocator,
q: IteratorHeap,
current: ?*HeapWrapper,

pub fn init(allocator: std.mem.Allocator, iters: std.ArrayList(StorageIteratorPtr)) !Self {
    var q = IteratorHeap.init(allocator, .{});
    if (iters.items.len == 0) {
        return Self{
            .allocator = allocator,
            .q = q,
            .current = null,
        };
    }

    // PS: the last iter has the highest priority
    // 按順序寫入二叉堆
    for (iters.items, 0..) |sp, i| {
        if (!sp.load().isEmpty()) {
            const hw = try allocator.create(HeapWrapper);
            errdefer allocator.destroy(hw);
            hw.* = HeapWrapper.init(i, sp.clone());
            try q.add(hw);
        }
    }

    const cc = q.removeOrNull();
    return Self{
        .allocator = allocator,
        .q = q,
        .current = cc,
    };
}

pub fn key(self: Self) []const u8 {
    return self.current.?.key();
}

pub fn value(self: Self) []const u8 {
    return self.current.?.value();
}

pub fn isEmpty(self: Self) bool {
    if (self.current) |cc| {
        return cc.isEmpty();
    }
    return true;
}

pub fn next(self: *Self) !void {
    const cc = self.current.?;
    while (true) {
        if (self.q.peek()) |ii| {
            std.debug.assert(!ii.isEmpty());
            // 如果優先堆頭部迭代器 A 和當前正在生效的迭代器 B 的 key 相同，讓迭代器 A 跳過重複 key
            if (std.mem.eql(u8, cc.key(), ii.key())) {
                try ii.next();
                if (ii.isEmpty()) {
                    _ = self.q.remove();
                    ii.deinit();
                    self.allocator.destroy(ii);
                }
            } else {
                break;
            }
        }
        break;
    }

    try cc.next(); // 迭代當前迭代器

    // 如果當前優先迭代器迭代完了，就從堆中彈出最優迭代器
    if (cc.isEmpty()) {
        defer {
            cc.deinit();
            self.allocator.destroy(cc);
        }
        if (self.q.removeOrNull()) |h| {
            self.current = h;
        } else {
            self.current = null;
        }
        return;
    }

    // 將當前迭代器寫回二叉堆，重新計算最優迭代器
    try self.q.add(cc); 
    self.current = self.q.removeOrNull();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;有了 MergeIterator 這個工具，我們具備了在多個 MemTable 和多個 SSTable 中迭代檢索的能力，但是還有個問題，我們當前有兩個 MergeIterator，應該如何在兩個迭代器中執行迭代任務？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d030afd564de14e802e21ca38a1e58ce.jpeg&quot; alt=&quot;執行迭代任務.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 此時，我們再引入一個新的數據結構：&lt;strong&gt;TwoMergeIterator&lt;/strong&gt;，這個是 MergeIterator 在元素只有兩個的情況下的簡化版。&lt;/p&gt; 
&lt;p&gt;TwoMergeIterator 由兩個迭代器構成，一個高優一個低優，每次迭代優先迭代高優，當 key 相同時，優先迭代高優。實現如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const TwoMergeIterator = struct {
    a: StorageIteratorPtr,
    b: StorageIteratorPtr,
    choose_a: bool,

    // 選擇兩個迭代器中 key 更小的迭代器
    fn chooseA(a: *StorageIterator, b: *StorageIterator) bool {
        if (a.isEmpty()) {
            return false;
        }
        if (b.isEmpty()) {
            return true;
        }
        return std.mem.lessThan(u8, a.key(), b.key());
    }

    // key 相同時，跳過低優中的 key
    fn skipB(self: *TwoMergeIterator) !void {
        const ap = self.a.load();
        const bp = self.b.load();
        if (!ap.isEmpty() and !bp.isEmpty() and std.mem.eql(u8, ap.key(), bp.key())) try bp.next();
    }

    pub fn init(a: StorageIteratorPtr, b: StorageIteratorPtr) !TwoMergeIterator {
        var iter = TwoMergeIterator{
            .a = a,
            .b = b,
            .choose_a = false,
        };
        try iter.skipB();
        iter.choose_a = chooseA(iter.a.load(), iter.b.load());
        return iter;
    }

    pub fn deinit(self: *TwoMergeIterator) void {
        self.a.release();
        self.b.release();
    }

    pub fn key(self: TwoMergeIterator) []const u8 {
        if (self.choose_a) {
            std.debug.assert(!self.a.load().isEmpty());
            return self.a.load().key();
        }
        std.debug.assert(!self.b.load().isEmpty());
        return self.b.load().key();
    }

    pub fn value(self: TwoMergeIterator) []const u8 {
        if (self.choose_a) {
            std.debug.assert(!self.a.load().isEmpty());
            return self.a.load().value();
        }
        std.debug.assert(!self.b.load().isEmpty());
        return self.b.load().value();
    }

    pub fn isEmpty(self: TwoMergeIterator) bool {
        if (self.choose_a) {
            return self.a.load().isEmpty();
        }
        return self.b.load().isEmpty();
    }

    pub fn next(self: *TwoMergeIterator) !void {
        if (self.choose_a) {
            try self.a.load().next();
        } else {
            try self.b.load().next();
        }
        try self.skipB();
        self.choose_a = chooseA(self.a.load(), self.b.load());
    }
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;至此，我們讀行為所需要的武器就完備了！&lt;/p&gt; 
&lt;h2&gt;Read/Scan&lt;/h2&gt; 
&lt;p&gt;讓我們再來看看 LSM 的架構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//04dd1b2d4cde764a23b28d78259cf343.jpeg&quot; alt=&quot;LSM 的架構圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 我們將每個數據層中的數據標上優先級，由於 LSM-Tree 是 append-only 的，所以優先級越高的數據層中數據越新。&lt;/p&gt; 
&lt;p&gt;所以我們的讀策略也很明顯：按照上圖中 P0 至 P2 依次檢索，這部分代碼實現見 src/storage.zig。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;讀 MemTable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// search in memtable
if (try self.state.getMemTable().get(key, value)) {
    if (value.*.len == 0) {
        // tomestone
        return false;
    }
    return true;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;讀 Immutable MemTable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// search in imm_memtables

self.state_lock.lockShared();
defer self.state_lock.unlockShared();
for (self.state.imm_mem_tables.items) |imm_table| {
    if (try imm_table.load().get(key, value)) {
        if (value.*.len == 0) {
            // tomestone
            return false;
        }
        return true;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;讀 LV0~LVmax SSTables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// 收集 L0 中的迭代器
var l0_iters = std.ArrayList(StorageIteratorPtr).init(self.allocator);
defer {
    for (l0_iters.items) |iter| {
        var ii = iter;
        ii.release();
    }
    l0_iters.deinit();
}
{
    self.state_lock.lockShared();
    defer self.state_lock.unlockShared();
    for (self.state.l0_sstables.items) |sst_id| {
        const sst = self.state.sstables.get(sst_id).?;
        if (try sst.load().mayContain(key)) {
            var ss_iter = try SsTableIterator.initAndSeekToKey(self.allocator, sst.clone(), key);
            errdefer ss_iter.deinit();
            try l0_iters.append(try StorageIteratorPtr.create(self.allocator, .{ .ss_table_iter = ss_iter }));
        }
    }
}

// 收集 Levels 中的迭代器
var level_iters: std.ArrayList(StorageIteratorPtr) =     ;
{
    self.state_lock.lockShared();
    defer self.state_lock.unlockShared();
    level_iters = try std.ArrayList(StorageIteratorPtr).initCapacity(
        self.allocator,
        self.state.levels.items.len,
    );
    for (self.state.levels.items) |level| {
        var level_ssts = try std.ArrayList(SsTablePtr).initCapacity(self.allocator, level.items.len);
        errdefer level_ssts.deinit();
        for (level.items) |sst_id| {
            const sst = self.state.sstables.get(sst_id).?;
            if (try mayWithinTable(key, sst)) {
                try level_ssts.append(sst.clone());
            }
        }
        if (level_ssts.items.len &amp;gt; 0) {
            var level_iter = try SstConcatIterator.initAndSeekToKey(
                self.allocator,
                level_ssts,
                key,
            );
            errdefer level_iter.deinit();
            try level_iters.append(try StorageIteratorPtr.create(self.allocator, .{ .sst_concat_iter = level_iter }));
        }
    }
}

// 將多個迭代器合併為一個 TwoMergeIterator
var l0_merge_iter = try MergeIterators.init(self.allocator, l0_iters);
errdefer l0_merge_iter.deinit();

var levels_merge_iter = try MergeIterators.init(self.allocator, level_iters);
errdefer levels_merge_iter.deinit();

var iter = try TwoMergeIterator.init(
    try StorageIteratorPtr.create(self.allocator, .{ .merge_iterators = l0_merge_iter }),
    try StorageIteratorPtr.create(self.allocator, .{ .merge_iterators = levels_merge_iter }),
);
defer iter.deinit();

if (iter.isEmpty()) {
    return false;
}

if (std.mem.eql(u8, iter.key(), key) and iter.value().len &amp;gt; 0) {
    value.* = iter.value();
    return true;
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;壓縮&lt;/h2&gt; 
&lt;p&gt;在上一節的寫過程中，我們實現了從內存表到 Level0 的 SSTable 堆疊。&lt;/p&gt; 
&lt;p&gt;隨着寫入的持續，Lv0 的 SSTable 會越來越多，這個時候就需要我們將 Lv0 中的數據合併寫入至 Lv2，並依次類推重複這個過程，直到堆疊到最深的層數，這個逐層合併數據的過程就是&lt;strong&gt;數據壓縮&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//982033f774dbf9693963f20f07b42b5b.jpeg&quot; alt=&quot;數據壓縮.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; LSM-Tree 中數據壓縮的過程大致如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//cb153ea8c68e5038d9c6b02da7837645.jpeg&quot; alt=&quot;過程大致如下.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 具體的實現代碼可見 src/compact.zig，src/storage.zig。&lt;/p&gt; 
&lt;p&gt;簡單分層壓縮與原始 LSM 論文中的壓縮策略相似。它為 LSM 樹維護多個層級。當一個層級太大時，它會將此層級的所有 SST 與下一層合併。壓縮策略由 3 個參數控制：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;size_ratio_percent：【文件低級數量/文件高級數量】，當實際計算的值低於此閾值時觸發壓縮。假設這裏我們設置為 60%，當 L0 中 SST 數量為 2，L1 中 SST 數量為 1，此時 ratio 為 1/2 = 50% &amp;lt; 60%，此時我們應該將 L0 壓縮合並至 L1。&lt;/li&gt; 
 &lt;li&gt;level0_file_num_compaction_trigger: 第一層 SSTable 達到多少後觸發壓縮。因為這是最高層，沒法與更高層比較，只能固定觸發壓縮。&lt;/li&gt; 
 &lt;li&gt;max_levels: 顧名思義，最大的層數限制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;做好這些準備工作，我們可以逐步實現壓縮邏輯：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;生成壓縮任務：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub const SimpleLeveledCompactionController = struct {
    options: SimpleLeveledCompactionOptions,

    pub fn generateCompactionTask(self: SimpleLeveledCompactionController, state: *storage.StorageState) !?SimpleLeveledCompactionTask {
        if (self.options.max_levels == 1) {
            return null;
        }

        var level_sizes = std.ArrayList(usize).init(state.allocator);
        defer level_sizes.deinit();

        try level_sizes.append(state.l0_sstables.items.len);
        for (state.levels.items) |level| {
            try level_sizes.append(level.items.len);
        }

        // 如果 Lv0 中 SST 數量超出閾值，觸發 L0 級別壓縮
        if (state.l0_sstables.items.len &amp;gt;= self.options.level0_file_num_compaction_trigger) {
            std.debug.print(&quot;compaction of L0 to L1 because L0 has {d} SSTS &amp;gt;= {d}\n&quot;, .{ state.l0_sstables.items.len, self.options.level0_file_num_compaction_trigger });
            return .{
                .upper_level = null,
                .upper_level_sst_ids = try state.l0_sstables.clone(),
                .lower_level = 1,
                .lower_level_sst_ids = try state.levels.items[0].clone(),
                .is_lower_level_bottom = false,
            };
        }

        // 計算 Lv[n+1]/lv[n]，如果比例小於閾值，觸發 Lv[n]級別壓縮
        for (1..self.options.max_levels) |level| {
            const lower_level = level + 1;
            if (level_sizes.items[level] == 0) {
                continue;
            }
            const size_ration = level_sizes.items[lower_level] * 100 / level_sizes.items[level];
            if (size_ration &amp;lt; self.options.size_ration_percent) {
                std.debug.print(&quot;compaction of L{d} to L{d} because L{d} size ratio {d} &amp;lt; {d}\n&quot;, .{ level, lower_level, level, size_ration, self.options.size_ration_percent });
                return .{
                    .upper_level = level,
                    .upper_level_sst_ids = try state.levels.items[level - 1].clone(),
                    .lower_level = lower_level,
                    .lower_level_sst_ids = try state.levels.items[lower_level - 1].clone(),
                    .is_lower_level_bottom = lower_level == self.options.max_levels,
                };
            }
        }

        return null;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;執行壓縮任務：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;有了上一小節中讀過程的介紹，多層數據的壓縮過程就很好理解了。&lt;/p&gt; 
&lt;p&gt;例如我們想將 L1 與 L2 的 SSTable 合併壓縮至 L2，我們只需要把 L1 和 L2 的數據放在一起創造一個迭代器，再持續從該迭代器中讀出數據寫入新的 SSTable 中，這個過程保證了新的 SSTable 中數據不重複且有序。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;fn compactSimple(self: *Self, task: SimpleLeveledCompactionTask) !std.ArrayList(SsTablePtr) {
    if (task.upper_level) |_| {
        var upper_ssts = try std.ArrayList(SsTablePtr).initCapacity(
            self.allocator,
            task.upper_level_sst_ids.items.len,
        );
        var lower_ssts = try std.ArrayList(SsTablePtr).initCapacity(
            self.allocator,
            task.lower_level_sst_ids.items.len,
        );

        self.state_lock.lockShared();
        for (task.upper_level_sst_ids.items) |sst_id| {
            const sst = self.state.sstables.get(sst_id).?;
            try upper_ssts.append(sst.clone());
        }
        for (task.lower_level_sst_ids.items) |sst_id| {
            const sst = self.state.sstables.get(sst_id).?;
            try lower_ssts.append(sst.clone());
        }
        self.state_lock.unlockShared();

        var upper_iter = try SstConcatIterator.initAndSeekToFirst(self.allocator, upper_ssts);
        errdefer upper_iter.deinit();

        var lower_iter = try SstConcatIterator.initAndSeekToFirst(self.allocator, lower_ssts);
        errdefer lower_iter.deinit();

        var iter = try TwoMergeIterator.init(
            try StorageIteratorPtr.create(self.allocator, .{ .sst_concat_iter = upper_iter }),
            try StorageIteratorPtr.create(self.allocator, .{ .sst_concat_iter = lower_iter }),
        );
        defer iter.deinit();
        return self.compactGenerateSstFromIter(&amp;amp;iter, task.is_lower_level_bottom);
    } else {
        // compact l0_sstables to l1_sstables
        // ..... 代碼邏輯大致與上面 LvN 層壓縮一致，只是 Lv0 層的 SSTable 是無序的需要特殊考慮
        return self.compactGenerateSstFromIter(&amp;amp;iter, task.is_lower_level_bottom);
    }
}


fn compactGenerateSstFromIter(self: *Self, iter: *TwoMergeIterator, compact_to_bottom_level: bool) !std.ArrayList(SsTablePtr) {
    var builder: SsTableBuilder = try SsTableBuilder.init(self.allocator, self.options.block_size);
    defer builder.deinit();
    var new_ssts = std.ArrayList(SsTablePtr).init(self.allocator);
    
    // 持續迭代此迭代器
    while (!iter.isEmpty()) {
        // 如果壓縮至最後一層，可以不保留墓碑值 key 了
        if (compact_to_bottom_level) {
            if (iter.value().len &amp;gt; 0) {
                try builder.add(iter.key(), iter.value());
            }
        } else {
            try builder.add(iter.key(), iter.value());
        }
        // 當寫滿一個 SSTable 後，就清空 builder，把寫滿的 SSTable 入列
        if (builder.estimatedSize() &amp;gt;= self.options.target_sst_size) {
            // reset builder
            defer builder.reset() catch unreachable;
            const sst_id = self.getNextSstId();
            const path = try self.pathOfSst(sst_id);
            defer self.allocator.free(path);
            var sst = try builder.build(sst_id, self.block_cache.clone(), path);
            errdefer sst.deinit();

            var sst_ptr = try SsTablePtr.create(self.allocator, sst);
            errdefer sst_ptr.deinit();

            try new_ssts.append(sst_ptr);
        }
        try iter.next();
    }
    // 剩餘的數據單獨一個 SSTable
    if (builder.estimatedSize() &amp;gt; 0) {
        const sst_id = self.getNextSstId();
        const path = try self.pathOfSst(sst_id);
        defer self.allocator.free(path);
        var sst = try builder.build(sst_id, self.block_cache.clone(), path);
        errdefer sst.deinit();
        var sst_ptr = try SsTablePtr.create(self.allocator, sst);
        errdefer sst_ptr.deinit();
        try new_ssts.append(sst_ptr);
    }
    return new_ssts;
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;替換壓縮後的 SST&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這部分邏輯並不複雜，即刪除此次壓縮任務中的原有兩層數據，用新合併的 SSTable 替換至較低層數據。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;這裏有個需要注意的點，即壓縮過程是在一個線程中單獨執行的，壓縮過程中 LSM-Tree 的原數據可能發生了改變，所以這裏執行 SSTable 刪除時要注意過濾掉新數據，不能覆蓋了有效數據。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;併發問題是軟件中的 Bug 集散地！&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;pub fn applyCompactionResult(
    _: SimpleLeveledCompactionController,
    state: *storage.StorageState,
    task: SimpleLeveledCompactionTask,
    output: []usize,
) !std.ArrayList(usize) {
    var files_to_remove = std.ArrayList(usize).init(state.allocator);
    errdefer files_to_remove.deinit();

    if (task.upper_level) |upper_level| {
        // 刪除高層 SSTable 數據，這層數據不會在壓縮過程中變更，放心刪
        std.debug.assert(sliceEquals(
            task.upper_level_sst_ids.items,
            state.levels.items[upper_level - 1].items,
        ));
        try files_to_remove.appendSlice(task.upper_level_sst_ids.items);
        state.levels.items[upper_level - 1].clearAndFree();
    } else {
        // 刪除 L0 數據，需要小心
        try files_to_remove.appendSlice(task.upper_level_sst_ids.items);
        var new_l0_sstables = std.ArrayList(usize).init(state.allocator);
        errdefer new_l0_sstables.deinit();

        {
            var l0_sst_compacted = std.AutoHashMap(usize, struct {}).init(state.allocator);
            defer l0_sst_compacted.deinit();
            for (task.upper_level_sst_ids.items) |sst_id| {
                try l0_sst_compacted.put(sst_id, .{});
            }

            for (state.l0_sstables.items) |sst_id| {
                if (!l0_sst_compacted.remove(sst_id)) { // 不在壓縮任務中的 SST 不能刪除
                    try new_l0_sstables.append(sst_id);
                }
            }
            std.debug.assert(l0_sst_compacted.count() == 0);
        }
        state.l0_sstables.deinit();
        state.l0_sstables = new_l0_sstables;
    }
    // 低層 SSTable 數據，直接刪除
    try files_to_remove.appendSlice(task.lower_level_sst_ids.items);
    state.levels.items[task.lower_level - 1].clearAndFree();
    try state.levels.items[task.lower_level - 1].appendSlice(output);

    return files_to_remove;
}


// sst to remove
var ssts_to_remove = std.ArrayList(SsTablePtr).init(self.allocator);

{
    var new_sst_ids = std.ArrayList(usize).init(self.allocator);
    defer new_sst_ids.deinit();

    self.state_lock.lock();
    defer self.state_lock.unlock();

    for (sstables.items) |sst| {
        const id: usize = @intCast(sst.get().sstId());
        try new_sst_ids.append(id);
        try self.state.sstables.put(id, sst.clone());
    }

    var file_to_remove = try self.compaction_controller.applyCompactionResult(
        &amp;amp;self.state,
        task,
        output.items,
    );
    defer file_to_remove.deinit();

    for (file_to_remove.items) |id| {
        if (self.state.sstables.fetchRemove(id)) |kv| {
            try ssts_to_remove.append(kv.value);
        }
    }
    try self.syncDir();
}

for (ssts_to_remove.items) |sst| {
    const path = try self.pathOfSst(sst.get().sstId());
    defer self.allocator.free(path);
    try std.fs.cwd().deleteFile(path);
}
try self.syncDir();
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;我們使用 Zig 語言實現了一個 LSM-Tree 的核心功能，包括 MemTable、SSTable、寫流程、各類 Iterator 與數據壓縮能力。通過這個項目，我收穫了很多心得體會。&lt;/p&gt; 
&lt;h3&gt;瞭解了 LSM-Tree 的核心流程&lt;/h3&gt; 
&lt;p&gt;以往對 LSM 這個數據結構的多層 SST 設計與寫過程早有耳聞，但是讀流程的實現不太理解。這個項目解答了我疑惑很久的讀流程的實現，特別是 MergeIterator 的算法設計非常巧妙。&lt;/p&gt; 
&lt;h3&gt;摸索了個 zig 語言的智能指針&lt;/h3&gt; 
&lt;p&gt;Zig 語言沒有內存安全的保證，為了不想指針亂飛到處泄露，在 Deepseek 的幫助下實現了一個簡單的智能指針，極大降低了內存管理的心智負擔。&lt;/p&gt; 
&lt;h3&gt;工程經驗&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;儘可能多的做 assertion 的工作，可以提前暴露很多 bug。&lt;/li&gt; 
 &lt;li&gt;大型多模塊的項目，一定要寫單元測試，不然出了 bug 無法分塊定位問題。&lt;/li&gt; 
 &lt;li&gt;千萬不要把 IO 過程放在鎖的範圍裏，極大的影響性能！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文 / 酒米&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17821037</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17821037</guid>
            <pubDate>Fri, 28 Feb 2025 03:24:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Visual Studio Code 1.98 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#333333&quot;&gt;Visual Studio Code 1.98 已&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;&lt;span style=&quot;color:#333333&quot;&gt;，具體更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_collapsed-mode-for-next-edit-suggestions-preview&quot; target=&quot;_blank&quot;&gt;Next Edit Suggestions（預覽）&lt;/a&gt;&amp;nbsp;- Copilot 預測你可能進行的下一步編輯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-019e10d4849c9dd6fc68e2e48607e7bdd4b.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_agent-mode-improvements-experimental&quot; target=&quot;_blank&quot;&gt;Agent mode（預覽）&lt;/a&gt;- Copilot 自主完成任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-518b6c0edf8f8db2235e98351573e6ccdbd.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_notebook-support-in-copilot-edits-preview&quot; target=&quot;_blank&quot;&gt;Copilot Edits for notebooks&lt;/a&gt;&amp;nbsp;- 快速迭代編輯你的 notebooks。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#333333&quot;&gt;現在可以使用 Copilot 編輯 notebook 文件，其直觀體驗與編輯代碼文件相同。從頭開始創建新 notebook、修改多個單元格的內容、插入和刪除單元格以及更改單元格類型。此預覽功能在使用數據科學或文檔筆記本時提供了無縫的工作流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;260&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f810400f60fd4fcf741bff71103f68a23b3.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_more-advanced-codebase-search-in-copilot-chat&quot; target=&quot;_blank&quot;&gt;代碼搜索&lt;/a&gt;&amp;nbsp;- 讓 Copilot 找到與你的聊天提示相關的文件。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;當你在 Copilot 聊天查詢中添加 #codebase 時，Copilot 會幫助你在工作區中找到相關代碼，以用於聊天提示。#codebase 現在可以運行文本搜索和文件搜索等工具，從你的工作區中獲取更多上下文。通過&lt;span style=&quot;color:#333333&quot;&gt;設置&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:var(--keybinding-foreground)&quot;&gt;github.copilot.chat.codesearch.enabled&amp;nbsp;啓用該功能。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_terminal-intellisense-preview&quot; target=&quot;_blank&quot;&gt;Terminal IntelliSense（預覽）&lt;/a&gt;&amp;nbsp;- 為你的終端提供豐富的補全支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過添加補全規範（例如 git）、改進命令行解析以提供更好的建議以及增強文件和文件夾補全功能，大幅改進了 bash、zsh、fish 和 PowerShell 的終端 shell 補全功能。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_peek-references-drag-and-drop-support&quot; target=&quot;_blank&quot;&gt;Drag &amp;amp; drop references&lt;/a&gt;&amp;nbsp;- 在新編輯器中快速打開 peek references。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;329&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-153d8c57cc0e6c208cad9acb97f691fc2a6.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_custom-title-bar-on-linux&quot; target=&quot;_blank&quot;&gt;Linux 自定義標題欄&lt;/a&gt;&amp;nbsp;- 默認啓用對 Linux 的自定義標題欄支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;151&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9e84c065a811004cd37ad56202d7dabd0e8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;161&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a2909fabdb45b4fb759242c8dc0ebf83d6f.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_diagnostics-commit-hook-experimental&quot; target=&quot;_blank&quot;&gt;未解決的診斷（預覽）&lt;/a&gt;&amp;nbsp;- 提交時提示未解決的診斷。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;234&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-153c2b99fc26f5a7171b1b02c51c915a39c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_discard-untracked-changes-improvements&quot; target=&quot;_blank&quot;&gt;Soft-delete in source control&lt;/a&gt;&amp;nbsp;- 將未跟蹤的文件移至垃圾箱而不是刪除它們。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;285&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2ae775ec5b09d887bf514d7c0a6066137e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98%23_custom-instructions-generally-available&quot; target=&quot;_blank&quot;&gt;自定義指令 GA&lt;/a&gt;&amp;nbsp;- 使用自定義指令來調整 Copilot 以滿足你的需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_98&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337206/vs-code-1-98-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337206/vs-code-1-98-released</guid>
            <pubDate>Fri, 28 Feb 2025 03:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果發佈「核彈級」 Mac Studio：頂配售價超 10 萬、最強處理器 M3 Ultra 正式亮相</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;時隔 2 年，蘋果昨晚宣佈推出&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apple.com.cn%2Fnewsroom%2F2025%2F03%2Fapple-unveils-new-mac-studio%2F&quot; target=&quot;_blank&quot;&gt;新一代 Mac Studio 系列產品&lt;/a&gt;&lt;/u&gt;，新款外觀與前代一致，提供兩款頂級芯片配置：M4 Max 版本，和全新問世的 M3 Ultra 版本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e8c623529f6c39ee547689adc1d8fb59f1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;M4 Max 版本搭載 14 核 CPU + 32 核 GPU 處理器，36 GB 統一內存起步，起售價 16,499 元。&lt;/p&gt; 
&lt;p&gt;而全新的 M3 Ultra 芯片，使用 Ultra Fusion 技術，封裝兩顆 M3 Max 芯片，參數達到 32 核 CPU + 80 核 GPU，其成為目前蘋果最強的桌面級處理器。存儲方面，M3 Ultra 版本運行內存最高達 512GB，對比上一代 192GB 實現翻倍，存儲容量最高達 8TB。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aae81ef3140f2767256ed31376847b297fb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;憑藉暴漲的統一運行內存，&lt;strong&gt;蘋果宣稱 M3 Ultra 版本 Mac Studio 支持本地部署 6,000 億參數的 AI 大模型運行，也就是説 Mac Studio 有望能夠本地部署 671B 的滿血版 DeepSeek R1&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;M3 Ultra 版本的基礎款配置為 28 核 CPU + 60 核 GPU，96GB + 1TB，起售價 32,999 元，而 32 核 CPU + 80 核 GPU、512GB 內存、16TB 存儲的頂配版本價格 108,749 元&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;接口方面，Mac Studio 全線升級雷靂 5 接口，傳輸速率達 120Gbps，M3 Ultra 版本搭載 6 個雷靂接口，而 M4 Max 版本搭載 4 個雷靂接口和兩個 USB-C 接口。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b89d3057da2fc83e8df6442bbcc17e4092.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新款 MacBook Air 和新款 Mac Studio 都將於 3 月 7 日上午 9 點接受預購，3 月 12 日發售。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/337215/apple-m3-ultra-new-extreme&quot; target=&quot;news&quot;&gt;史上最強芯片：蘋果 M3 Ultra 支持 512 GB 統一內存&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337201/apple-unveils-new-mac-studio-m3-ultra</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337201/apple-unveils-new-mac-studio-m3-ultra</guid>
            <pubDate>Fri, 28 Feb 2025 03:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>抖音擬尋求 AI 數據標註供應商</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據字節跳動採購部消息，為滿足快速增長的 AI 數據標註需求，抖音集團內容質量與數據服務平台擬尋找標註供應商，尤其是垂類資源豐富的供應商（如醫療、法律、教育等）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-388bf17c3f7f838a56fa4b0f40255569570.webp&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337198</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337198</guid>
            <pubDate>Fri, 28 Feb 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 圖靈獎得主正式公佈，授予兩位「強化學習」奠基人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日下午，美國計算機協會（ACM）宣佈，Andrew Barto 和 Richard Sutton 榮獲 2024 年 ACM A.M. 圖靈獎，&lt;strong&gt;以表彰他們在強化學習領域奠定的概念與算法基礎&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-00205edcb99f13e1e620c619a6fd55a7438.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，從 20 世紀 80 年代起， Barto 和 Sutton 通過一系列論文提出了強化學習的核心思想，構建了其數學基礎，並開發了關鍵算法，使其成為智能系統研究中最重要的方法之一。&lt;/p&gt; 
&lt;p&gt;值得一提的是，被譽為「強化學習之父」的 Richard Sutton，曾是 Barto 的博士及博士後學生，兩人的師生合作成就了這一領域的基石。&lt;/p&gt; 
&lt;p&gt;目前流行的 ChatGPT 和 DeepSeek 均廣泛使用了強化學習技術。強化學習的應用還涵蓋了多個領域，包括網絡擁塞控制、芯片設計、提升聊天機器人的行為和推理能力以及改進計算機科學中的經典問題。&lt;/p&gt; 
&lt;p&gt;此外，包括 Barto 在內的研究表明，某些強化學習算法實際上是對人腦多巴胺系統運作機制的最佳解釋之一，加深了人類對大腦學習過程的理解。&lt;/p&gt; 
&lt;p&gt;ACM 主席 Yannis Ioannidis 評價表示，Barto 和 Sutton 的貢獻不僅僅是一個過渡階段的成果，而是一個仍在持續發展的領域。強化學習仍在不斷進步，不僅推動計算機科學的發展，也為許多其他學科帶來了無限可能。因此，ACM 授予他們計算機領域最具影響力的獎項。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337195</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337195</guid>
            <pubDate>Fri, 28 Feb 2025 02:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技在深圳成立新公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;企查查信息顯示，深圳天羿科技有限公司於 2025-03-05 成立，法定代表人為周昌慧，註冊資本為 10 萬元。公司經營範圍涵蓋智能機器人的研發、智能機器人銷售、工業機器人銷售、服務消費機器人銷售以及工業機器人安裝等。&lt;/p&gt; 
&lt;p&gt;股東信息顯示，由杭州宇樹科技有限公司全資持股。目前，宇樹科技已對外投資包括上海高羿科技有限公司等 5 家公司。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;216&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/103617_5YT8_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337194</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337194</guid>
            <pubDate>Fri, 28 Feb 2025 02:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Monica.im 發佈 AI Agent 產品「Manus」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日，Manus AI 正式公佈了其 Agent 產品「Manus」，宣稱是全球第一款通用 Agent 產品。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e610aef907c631d5c6a2ed92027c4579318.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmanus.im%2F&quot; target=&quot;_blank&quot;&gt;https://manus.im/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據官方介紹，Manus 這個名字來自拉丁語，Mens et Manus，就是 mind and hand，即手腦並用。&lt;/p&gt; 
&lt;p&gt;Manus 可以解決各類複雜多變的任務，能夠獨立思考、規劃並執行復雜任務，直接交付完整成果。比起 Claude 的 Computer use 等同樣能操作多任務，或者能幫你點外賣訂酒店的 Agent， Manus 可以覆蓋更多領域和達成更高的執行質量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1facceecf781299c016ef6634ec7fe4d146.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-364f58e31a6580fcd1f61d1a2d95c13187c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方公佈的數據顯示，在用於評估通用 AI 助手在解決現實世界問題方面的能力的 GAIA 基準測試中，Manus 在所有三個難度級別上都達到了 SOTA 水平。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7f1f4963c9182eed9305952427fc8dba43f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了確保結果的可重複性，Manus 使用與其正式版本完全一致的配置進行評測。此外，Manus 也在 Upwork、Fiverr 等平台上解決真實世界的問題，並在 Kaggle 競賽中證明瞭自己的能力。&lt;/p&gt; 
&lt;p&gt;Manus 目前採用 Multiple Agent 架構，運行方式與此前 Anthropic 發佈的 Computer Use 類似，&lt;strong&gt;完全運行在獨立虛擬機中&lt;/strong&gt;。同時可以在虛擬環境中調用各類工具——編寫和執行代碼、瀏覽網頁、操作應用等，直接交付完整成果。&lt;/p&gt; 
&lt;p&gt;通過規劃代理、執行代理、驗證代理的分工協作機制，來大幅提升對複雜任務的處理效率，並通過並行計算縮短響應時間。&lt;/p&gt; 
&lt;p&gt;在這個架構中，每個代理可能基於獨立的語言模型或強化學習模型，彼此通過 API 或消息隊列通信。同時每個任務也都在沙盒中運行，避免幹擾其他任務，同時支持雲端擴展。每個獨立模型都能模仿人類處理任務的流程，比如先思考和規劃，理解複雜指令並拆解為可執行的步驟，再調用合適的工具。&lt;/p&gt; 
&lt;p&gt;換言之，通過 Manus 的這套多代理架構，它更像是由多個助理，通過協助的方式，分別完成檢索資源、對接、驗證信息是否有效等工作，來幫你完成整個工作流程——這實際上不僅像是你招了一個「實習生」，更像是直接當上了一個微縮版的「部門主管」。&lt;/p&gt; 
&lt;p&gt;今年晚些時候，官方將計劃開源其中的一些模型，特別是 Manus 的推理（postering）部分。&lt;/p&gt; 
&lt;p&gt;據悉，Manus AI 背後的創始人肖弘是華中科技大學軟件工程專業 2015 屆校友。畢業後，他連續創業，2015 年創立夜鶯科技，推出「壹伴助手」和「微伴助手」，服務超 200 萬 B 端用戶，獲騰訊、真格基金等投資。而早期以海外市場為主，用戶規模破百萬的 AI 插件領域頭部產品「Monica」也出自肖弘及其團隊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337193/manus-ai-agent</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337193/manus-ai-agent</guid>
            <pubDate>Fri, 28 Feb 2025 02:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里發佈全新開源推理模型 QwQ-32B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲通義千問官方公眾號發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLnM4lHm1_dGqe-nrmpJhyg&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;，推出最新的推理模型 QwQ-32B。一款擁有 320 億參數的模型，其性能可與具備 6710 億參數（其中 370 億被激活）的 DeepSeek-R1 媲美。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一成果突顯了將強化學習應用於經過大規模預訓練的強大基礎模型的有效性。此外，我們還在推理模型中集成了與 Agent 相關的能力，使其能夠在使用工具的同時進行批判性思考，並根據環境反饋調整推理過程。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們希望我們的一點努力能夠證明強大的基礎模型疊加大規模強化學習也許是一條通往通用人工智能的可行之路。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;QwQ-32B 在一系列基準測試中進行了評估，測試了數學推理、編程能力和通用能力。以下結果展示了 QwQ-32B 與其他領先模型的性能對比，包括 DeepSeek-R1-Distilled-Qwen-32B、DeepSeek-R1-Distilled-Llama-70B、o1-mini 以及原始的 DeepSeek-R1。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在測試數學能力的 AIME24 評測集上，以及評估代碼能力的 LiveCodeBench 中，千問 QwQ-32B 表現與 DeepSeek-R1 相當，遠勝於 o1-mini 及相同尺寸的 R1 蒸餾模型；在由 Meta 首席科學家楊立昆領銜的「最難 LLMs 評測榜」 LiveBench、谷歌等提出的指令遵循能力 IFEval 評測集、由加州大學伯克利分校等提出的評估準確調用函數或工具方面的 BFCL 測試中，千問 QwQ-32B 的得分均超越了 DeepSeek- R1。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;397&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-edbafede4927e767ad7872d84c7621bdc94.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;大規模強化學習&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開發團隊在冷啓動的基礎上開展了大規模強化學習。在初始階段，特別針對數學和編程任務進行了 RL 訓練。與依賴傳統的獎勵模型（reward model）不同，其通過校驗生成答案的正確性來為數學問題提供反饋，並通過代碼執行服務器評估生成的代碼是否成功通過測試用例來提供代碼的反饋。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;發現在 RL 擴展過程中，隨着訓練輪次的推進，這兩個領域中的性能均表現出持續的提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在第一階段的 RL 過後，開發人員增加了另一個針對通用能力的 RL。此階段使用通用獎勵模型和一些基於規則的驗證器進行訓練。發現，通過少量步驟的通用 RL，可以提升其他通用能力，同時在數學和編程任務上的性能沒有顯著下降。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337189</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337189</guid>
            <pubDate>Fri, 28 Feb 2025 02:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>周鴻禕評價百度開源：李彥宏非常睿智，也非常老江湖</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;360 集團創始人周鴻禕作為全國政協委員代表，對 DeepSeek 的開源模式進行了闡述。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;周鴻禕認為李彥宏「非常睿智，也非常老江湖」，&lt;strong&gt;周鴻禕稱李彥宏原來是不太認可開源，因為他認為他的模式是接近 OpenAI 的，但他比 OpenAI 更聰明的是及時轉身，宣佈了開源&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;周鴻禕進一步分析稱：「自百度宣佈開源後，阿里巴巴也堅持了開源，在這個氣候下，沒準字節也會開源。一般來説，開源一旦形成氣候，一定能戰勝閉源。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;2 月 14 日，百度宣佈，將在未來幾個月中陸續推出文心大模型 4.5 系列，並於 6 月 30 日起正式開源。此前，李彥宏曾表示，開源其實是一種智商稅。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336166&quot; target=&quot;news&quot;&gt;百度將於 3 月 16 日發佈文心大模型 4.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/334659&quot; target=&quot;news&quot;&gt;李彥宏：文心大模型 4.5 系列將開源，是最強大的文心大模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333670&quot; target=&quot;news&quot;&gt;百度宣佈將開源下一代文心大模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333480&quot; target=&quot;news&quot;&gt;百度官宣：文心一言 4 月 1 日起全面免費&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337121</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337121</guid>
            <pubDate>Thu, 27 Feb 2025 11:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>我國 AI 人才缺口達 500 萬人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據央視財經消息，面對目前人工智能技術發展帶來的就業市場變化，不少職場人、準職場人也在為提升自己下功夫。&lt;/p&gt; 
&lt;p&gt;無論是職業教育學校，還是高等院校，都在加速發力更新相關的教學內容和教學模式。業內人士提出，隨着 AI 賦能千行百業，既需要技術和理論創新型人才，也需要能夠結合各行業實際需求的實操型人才。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0305/183110_J8ay_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;專家表示，2024 年，&lt;strong&gt;人工智能整個專業的在校生大概是 4 萬多人，跟整個人工智能領域的人才缺口 500 萬人相比，差距依然很大&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337105</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337105</guid>
            <pubDate>Thu, 27 Feb 2025 10:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>