<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Feb 2025 12:50:10 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Python 3.14 Alpha 5 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Python 3.14 Alpha 5 已發佈，此版本的最大亮點是引入了新的可選尾調用 (Tail-Call) 解釋器，它可以將 Python 代碼的執行速度提升高達 30%。&lt;/p&gt; 
&lt;p&gt;當前，尾調用解釋器需要在 x86_64 或 AArch64 架構上使用 Clang 19 或更新版本進行編譯。對於 GCC 支持，預計將在未來實現。對於希望利用尾調用解釋器的用戶，特別是那些啓用了 Profile Guided Optimization（PGO）的 Python 構建，應該會看到顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;詳情查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpythoninsider.blogspot.com%2F2025%2F02%2Fpython-3140-alpha-5-is-out.html&quot; target=&quot;_blank&quot;&gt;發佈公告&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;請注意，Alpha 版本旨在進行開發和測試，用戶在生產環境中使用時需謹慎，並且可能會遇到未預期的問題。&lt;/p&gt; 
&lt;p&gt;按照官方開發進度，預計在 3 月 14 日發佈 Python 3.14 Alpha 6 版本，隨後在四月份發佈第七個也是最終的 Alpha 版本。接下來，計劃進行四個 Beta 版本和兩個發佈候選版本，以度過夏季。如果一切順利，Python 3.14.0 正式版本預計在 10 月 7 日發佈。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333408/python-3-14-alpha-5</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333408/python-3-14-alpha-5</guid>
            <pubDate>Sat, 08 Feb 2025 11:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 2025 生態內容徵集大賽 | 1 月投稿作品及評審結果</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家好，我們在 2024 年底推出了 「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」，公開徵集 RWKV 相關的作品，包括但不限於 RWKV 相關的論文、講解 RWKV 的教程，以及基於 RWKV 的應用等。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，活動共收到 RWKV 生態作品投稿 &lt;strong&gt;11 份&lt;/strong&gt;，包括 &lt;strong&gt;3 篇論文、7 款應用和 1 篇教程/動畫&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文將公佈 2025 年 1 月的活動投稿作品及評審結果。&lt;/p&gt; 
&lt;h2&gt;評審結果和意見&lt;/h2&gt; 
&lt;h3&gt;論文類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UI&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
   &lt;li&gt;投稿人：Kmui&lt;/li&gt; 
   &lt;li&gt;獲獎類型：金獎（4888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：基於 RWKV 的全新研究方向，因此獲得金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OmniRWKVSR&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
   &lt;li&gt;投稿人：nomodeset&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UNet&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-UNet：Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
   &lt;li&gt;投稿人：Gavin&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;應用類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;fla-rwkv7&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Ffla-hub%2Frwkv7-6790fd37b4b6137b088a0d8a&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/collections/fla-hub/rwkv7-6790fd37b4b6137b088a0d8a&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：flash-linear-attention 的 RWKV-7 支持&lt;/li&gt; 
   &lt;li&gt;投稿人：張宇&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：如果可以解決這個庫運行 Bo 的 MMLU 腳本時的速度和顯存佔用問題，&lt;strong&gt;可升級金獎&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;conRWKV&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F00ffcc%2FconRWKV&quot; target=&quot;_blank&quot;&gt;https://github.com/00ffcc/conRWKV&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：提供了一個高併發的 RWKV 雲端推理引擎，以方便後續基於 RWKV 的應用&lt;/li&gt; 
   &lt;li&gt;投稿人：#9AC8E2&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;R-translator&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fl15y%2FR-translator&quot; target=&quot;_blank&quot;&gt;https://github.com/l15y/R-translator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 RWKV 的 AI 翻譯工具&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;獲獎類型：鐵獎（888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-ZeroCoT&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2FRWKV-ZeroCoT&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/RWKV-ZeroCoT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：ZoreCoT 的原始實現&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;獲獎類型：鐵獎（888 元）&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;substitute&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAXFOX%2Fsubstitute&quot; target=&quot;_blank&quot;&gt;https://github.com/AXFOX/substitute&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 Ai00 Server（RWKV） 驅動的 Kdenlive 字幕校驗和替換工具&lt;/li&gt; 
   &lt;li&gt;投稿人：我想上岸&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;rwkv v6 7b cot&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fly444983%2FRWKV_ST_for_AI00%2Ffile%2Fview%2Fmaster%3FfileName%3D7B_LY_COT.state%26status%3D2&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/ly444983/RWKV_ST_for_AI00/file/view/master?fileName=7B_LY_COT.state&amp;amp;status=2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：基於 RWKV-V6-7B 的 rwkv cot state&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;new_rwkv_pip&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2Fnew_rwkv_pip&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/new_rwkv_pip&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：重構後的 rwkv_pip 庫，把 v4-v7 各代模型都整理成統一的結構&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可再次投稿評審以升級獎項&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;教程/動畫類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;有思維的語言模型：RWKV-7 狀態演化過程&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1DY6fYdECa%2F&quot; target=&quot;_blank&quot;&gt;https://www.bilibili.com/video/BV1DY6fYdECa/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;項目介紹：RWKV-7 狀態演化視頻&lt;/li&gt; 
   &lt;li&gt;投稿人：136279841&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;評審意見：作品高贊評論在質疑效果，請用 v7 的實際效果去向用戶證明。如果用戶認可，可升級獎&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;評審結果快速對照表格&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名稱&lt;/th&gt; 
   &lt;th&gt;作品分類&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初評獎項&lt;/th&gt; 
   &lt;th&gt;得獎理由&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UI&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;Kmui&lt;/td&gt; 
   &lt;td&gt;金獎（4888 元）&lt;/td&gt; 
   &lt;td&gt;基於 RWKV 的全新研究方向&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OmniRWKVSR&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;nomodeset&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UNet&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;Gavin&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;該領域已存在若干 RWKV 論文，如果有實際 DEMO 證明作品的效果最好，可升級金獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;有思維的語言模型：RWKV-7 狀態演化過程&lt;/td&gt; 
   &lt;td&gt;教程/動畫&lt;/td&gt; 
   &lt;td&gt;136279841&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;作品高贊評論在質疑效果，請用 v7 的實際效果去向用戶證明。如果用戶認可，可升級獎。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;substitute&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;我想上岸&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fla-rwkv7&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;張宇&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;如果可以解決這個庫運行 Bo 的 MMLU 腳本時的速度和顯存佔用問題，可&lt;strong&gt;升級金獎。&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R-translator&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;鐵獎（888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rwkv v6 7b cot&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-ZeroCoT&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;鐵獎（888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;new_rwkv_pip&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conRWKV&lt;/td&gt; 
   &lt;td&gt;應用&lt;/td&gt; 
   &lt;td&gt;#9AC8E2&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
   &lt;td&gt;應用缺少實際用戶，可面向社區內外宣傳並招募用戶，有真實用戶後可以&lt;strong&gt;再次投稿評審以升級獎項&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;獎品/獎金髮放規則&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;實物獎品（RWKV 周邊等）&lt;strong&gt;以&lt;/strong&gt;順豐快遞&lt;/strong&gt;方式發出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;獎金&lt;/strong&gt;以&lt;strong&gt;轉賬或第三方線上平台&lt;/strong&gt;等方式發放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情況下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;領取獎金，團隊內部&lt;strong&gt;自行協商分配獎金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿與獎項升級&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均會獲得&lt;strong&gt;評審意見&lt;/strong&gt;。請根據評審意見優化你的作品，然後可&lt;strong&gt;再次投稿以升級獎項&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;獎項成功升級時，我們將補發&lt;strong&gt;前後兩個獎金的差價&lt;/strong&gt;。例如投稿作品從鐵獎（888 元）升級到銀獎（2888 元），則補發 2888-888=2000 元獎金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活動海報&lt;/strong&gt;，歡迎各位轉發！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-de56881e7277f3f31798464afb87dbc3c15.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活動最終解釋權歸元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333398</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333398</guid>
            <pubDate>Sat, 08 Feb 2025 09:57:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>別再買 9.9 的 deepseek 本地部署啦！一文教你輕鬆部署，告別 「服務器繁忙」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;開源的意義，在於人人機會均等。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;本人 IT 小白，不會寫代碼、不會看文檔，甚至一句「 Hello ，World 」 用 Python 寫完，都要靠高亮來判斷語法是否正確。哈哈哈，像我這樣的人，離本地部署，暢玩 Deepseek 遠嗎？&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;實測！世上無難事，只要肯動手！&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是我用公司配發的 HP 筆記本，本地部署 deepseek 的傻瓜式流程，內容如下：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;設備： HP Laptop 14&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;系統：Win&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;應用程序：LM Studio&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;模型版本：DeepSeek R1 Distill Qwen 1.5B &lt;span style=&quot;color:#8f959e&quot;&gt;（我都這配置了，還要啥自行車）&lt;/span&gt;；DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;輔助工具：VS code &lt;span style=&quot;color:#8f959e&quot;&gt;（輕量？不不不，它是神）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;為什麼我會選用 LM Studio &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;在嘗試部署之前，同事跟我推薦過一個叫「 Ollama 」 的開源工具，但我實測之後發現，在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2F&quot; target=&quot;_blank&quot;&gt;https://ollama.com/&lt;/a&gt; （ Ollama 官網）下載 Windows 版本時，可能會跳轉到 github ，響應超時而無法下載。&lt;/p&gt; 
 &lt;p&gt;並且，Ollama 主要圍繞命令行展開，不像 LM Studio 具備直觀的圖形化操作界面，通過「點點點」就可以使用，所以，對於很多名詞都不明所以的我來説——&lt;strong&gt;能用，比好不好用，更重要。&lt;/strong&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_1&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;1、於是，我進入 LM Studio 的官網（ &lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flmstudio.ai%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://lmstudio.ai/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; ），並下載了首頁的 0.3.9 版本。&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fe0fc4d91864142b575cad0941864dbb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_2&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;2、下載 LM Studio 3.9.0-6-x68 安裝包，所需空間 1.3 &lt;/strong&gt;&lt;strong&gt;GB&lt;/strong&gt;&lt;strong&gt; （全中文的，沒有門檻）&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a9c2a4552e660adf721db6398545166a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;打開【 LM-Studio 】，就可以使用該軟件，也可以創建桌面快捷。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1c26e3812675b161bb2711f22a87de0d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;界面長這樣👇&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//14810d4ac4953cce2010fb5f0fc7e593.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_3&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;3、英文界面？沒事兒！內置簡體中文~&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//381dd1bf2bc27a93d7cd0133f14a362e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4521be9d0ece8c5f6522e29c72f58cb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_4&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;4、接下來，我們就可以下載模型了，也超簡單&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5b68c13f9a0a6c4737a2d41f8cc92b69.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;但是，問題來了！！！&lt;/strong&gt;第一次下載 LM Studio ，搜索模型並下載，往往下載不了，這是因為 LM Studio 關聯 Hugging Face 或 llama.cpp 的模型庫，默認下載地址無法正常訪問。&lt;strong&gt;此時，我們可以通過 VScode ，修改 LM Studio 的安裝文件解決。&lt;/strong&gt;（ 怎麼下載 VScode ？別搞了兄弟！）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;退出 LM Studio 後，打開 LM Studio 的安裝目錄，如👇圖&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c7e5de0c94f6bc1ac0a848d340120b9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;找到兩個文件，路徑如下&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\main\index.js&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\renderer\main_window.js&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bad366546f55463174a123dcd533fb38.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;打開 VScode ，在 VCcode 同時打開這兩個文件&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e72d38f52a807e0bd51fa1a323451edf.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷鍵 ctrl+shift+h 調出批量替換，將 &lt;code&gt;huggingface.co&lt;/code&gt; 替換成 &lt;code&gt;hf-mirror.com&lt;/code&gt; ，然後快捷鍵 ctrl+alt+enter 應用替換（兩個文件同時打開時，可同時替換）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bd348a106dd3879fb521b5ffad959a78.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷鍵 ctrl+s ，保存文件即可退出 VScode ，再打開 LM Studio 就可以搜索下載模型了~&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;span id=&quot;OSC_h4_5&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;5、搜索適合設備配置的模型，下載並使用&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1323fb9dc1b4b3b3f89f726b17290d9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;一開始，小編也只敢用 HP 本下載最小的 1.5B ，但後面搜索了一些資料，整理下表：&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeb8f9a7b500a326f92c20de7d91ce400c8.jpg&quot; width=&quot;784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;span id=&quot;OSC_h4_6&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;6、實測階段&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 1.5B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;問題設置 1：人有幾隻腳？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//334794f64dac8ccb583dd0137b9e933c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 2：請簡述一下，什麼是「模型蒸餾」？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//962255f6c3582b01c7913ace1faf11fd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//069652c7705521531ac17af8bab48c79.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c72aa05116825a0c8727b76d77d13e1c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 3：8.11 和 8.4 誰大？直接得出結論。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bb33fdd55da3112b2dcf57f18e1fbe8c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;問題設置 1：你認為「模型開源」的意義是什麼？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c5c2039712441d2048404de675270ba.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 2：你如何評價梁文鋒？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b3f62d7ac407be1f2b9fa9b7f19304aa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;問題設置 3：你認為，人工智能的下一個技術突破點是？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e76d56190bda354d2f8bf81e6f187557.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;得到這個回答時，我發現，並不是我想要的，所以，我又繼續追問了一個問題：&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;如果不侷限於中國呢？如果是全球人工智能技術，你覺得下一個技術突破點是什麼？ &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是 7B 的答案（因為不好截圖，所以用文字表達）：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;在人工智能領域，每一次技術突破都伴隨着對現有侷限性的突破和技術創新。如果將目光放長遠，並不限於中國的地區或行業背景，全球範圍內，下一個可能的技術突破方向可以從以下幾個角度進行分析：&lt;/p&gt; 
  &lt;p&gt;1. &lt;strong&gt;通用人工智能（AGI）的突破&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;目前，AI 主要集中在特定任務上（如 NLP、計算機視覺等），仍然缺乏真正具有「通用性」的自主學習能力。如何讓機器具備類似人類般的學習能力和通用認知模式仍然是一個未解之謎。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;符號推理與&lt;/strong&gt;&lt;strong&gt;知識圖譜&lt;/strong&gt;：結合符號邏輯和知識圖譜，使得 AI 能夠進行更抽象的推理和概念理解。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;強化學習&lt;/strong&gt;&lt;strong&gt;的進化&lt;/strong&gt;：探索更具效率和創造力的強化學習方法，推動 AGI 的發展。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨模態理解和整合&lt;/strong&gt;：使 AI 能夠更好地理解和處理多模態信息（如文本、圖像、音頻等），從而具備更全面的理解能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;2. &lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;與協作&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;當前的大模型（如 GPT 系列、LLama 系列）已經在特定領域展現了強大的性能，但規模和複雜性仍然有限。未來，通過模型的聯合訓練和知識共享（如「元學習」或「模型平均」），可能實現更大規模、更高效的 AI 系統。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;具體方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型協作與知識共享&lt;/strong&gt;：多個研究機構或企業聯合訓練大型語言模型，促進知識的開放性和共享性。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多領域&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;的融合&lt;/strong&gt;：創建涵蓋科學、藝術、醫療等多領域的大型模型，提升跨領域應用的能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;3. &lt;strong&gt;人機協作與&lt;/strong&gt;&lt;strong&gt;自適應系統&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;隨着 AI 技術的成熟，人機協作將成為未來的重要趨勢。如何讓 AI 能夠更自然地與人類交互、理解和協同工作，仍然是一個關鍵方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;情感理解與倫理決策&lt;/strong&gt;：開發能夠理解人類情感和價值觀的 AI 系統，使其在複雜的社會環境中做出更具倫理性的決策。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;動態任務適應&lt;/strong&gt;：設計更加靈活的 AI 系統，能夠在不同情境中自適應任務要求，提升通用性。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;4. &lt;strong&gt;多模態與跨媒體理解&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;當前 AI 大多侷限於單一模態（如文本或圖像），如何整合多種模態信息（如文本、音頻、視頻、甚至傳感器數據）進行更全面的理解和推理，仍然是一個未解之謎。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模態融合框架&lt;/strong&gt;：開發能夠處理並整合多種模態數據的模型架構。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨領域&lt;/strong&gt;&lt;strong&gt;知識圖譜&lt;/strong&gt;：構建跨領域的知識圖譜，幫助 AI 更好地理解不同模態之間的關係。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;5. &lt;strong&gt;硬件與效率優化&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;雖然大模型在軟件層面取得了進展，但計算資源（如 GPU、TPU 等）仍然是制約其廣泛應用的關鍵因素。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;未來可能會有更高效的硬件設計和算法優化，使得 AI 系統的計算效率顯著提升。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;6. &lt;strong&gt;倫理與安全&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;AI 的自主性和複雜性可能帶來新的倫理問題和安全風險。如何在技術發展的同時確保 AI 系統的安全性和透明性，也是一個重要方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技術方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;系統的透明性&lt;/strong&gt;：研究如何讓 AI 系統更加透明，以便於人類理解和監督。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;法律與框架的完善&lt;/strong&gt;：推動相關法律法規的制定，確保 AI 技術的發展符合社會價值觀。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;總結&lt;/p&gt; 
  &lt;p&gt;從全球視角來看，下一個技術突破可能集中在以下方面：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;推動 AGI（通用人工智能）的發展；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;擴展大模型的協作和共享能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;提升多模態理解和人機協作能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;優化硬件效率並確保倫理安全。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p&gt;這些方向既需要基礎理論研究，也需要跨學科合作和技術落地。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;span id=&quot;OSC_h4_7&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;7、後記&lt;/h4&gt; 
 &lt;p&gt;體驗了幾個回合下來，首先能肯定的是，上文測試的兩個模型確實沒有網頁版 or APP 版所輸出的內容有趣（怪小編&lt;s&gt;財&lt;/s&gt;實力不行），但至少不會出現「服務器繁忙」，且不聯網也可以使用。&lt;/p&gt; 
 &lt;p&gt;其次，通過 LM Studio ，我們還可以輕鬆部署甚多有意思的開源模型在本地，而寫這一篇超超超超超基礎的博客，無非是在回答本文一開始的那句話：&lt;strong&gt;開源的意義，在於人人機會均等&lt;/strong&gt;。不僅是程序員、開發者、AI 從業人員，如根本不會寫代碼的我，也可以共享這一份人類智慧。&lt;/p&gt; 
 &lt;p&gt;可能有人會説，1.5B 能幹什麼？像個傻子！7B 能幹什麼？上不得枱面！對此，小編想用 Deepseek R1 自己輸出的一句話回答大夥兒——&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;火焰不需要羨慕灰燼的重量（滿血模型，也是從第一行代碼而來的）&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;最後，分享一個昨晚在地鐵上親歷的場景：&lt;/p&gt; 
 &lt;p&gt;寒假快結束了，兩個小學生在地鐵上互抄作業，小學生 A 説：「牛 B 呀！寒假生活你居然做完了？！」 小學生 B 説：「你傻呀！用 AI 呀~手機摸出來給我玩兩把！我跟你上分！」&lt;/p&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
 &lt;/div&gt; 
 &lt;p&gt;PS：希望在哪些網絡覆蓋不佳、基礎設備不好，逼仄、失語的角落，也能萌芽智慧之光......&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/17563840</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/17563840</guid>
            <pubDate>Sat, 08 Feb 2025 09:32:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>百度今年或將發佈下一代 AI 模型 Ernie 5.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F12%2Fchina-tech-giant-baidu-to-release-next-generation-ai-model-this-year-as-deepseek-shakes-up-market.html&quot; target=&quot;_blank&quot;&gt;據 CNBC 報道&lt;/a&gt;&lt;/u&gt;，百度今年將發佈下一代 AI 模型 Ernie 5.0。&lt;/p&gt; 
&lt;p&gt;消息人士稱，被稱為「基礎模型」的 Ernie5.0，將在多模態能力方面有重大增強，但沒有具體説明其功能。「多模態」AI 指可以處理文本、視頻、圖像和音頻等不同形式的數據，並進行轉換和結合 —— 比如將文本轉化為視頻，或反向操作。而基礎模型能夠理解語言，執行包括生成文本、圖像在內的多種任務，同時支持與人類自然語言的互動。&lt;/p&gt; 
&lt;p&gt;這一消息正值蘋果公司將其潛在客戶&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333288&quot;&gt;轉向&lt;/a&gt;&lt;/u&gt;阿里巴巴之後，市場普遍猜測此舉是百度為了應對局勢的變化，試圖穩住股價和市場地位。&lt;/p&gt; 
&lt;p&gt;百度首席執行官李彥宏本週在迪拜的世界政府峯會上表示：「我們正處於一個令人激動的時代……12 個月內，基礎模型的推理成本預計將下降 90% 以上。如果成本能夠大幅降低，意味着生產力將呈同等比例提升。這也正是創新的核心所在。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;報道稱，百度的文心大模型已經在其多個面向消費者和企業的產品中應用，包括雲存儲和內容創作。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;百度上個月宣佈，截至 2024 年底，其文庫平台已吸引 4000 萬付費用戶，比 2023 年底增長了 60%。包括利用 AI 根據公司財報生成 PPT 在內的一系列新功能，已在 1 月開始向用戶發佈。&lt;/p&gt; 
&lt;p&gt;當前的 ERNIE 模型版本為 4.0，於 2023 年 10 月發佈。2024 年 8 月，百度發佈了升級版的 ERNIE 4.0 &quot;turbo&quot;，目前並未正式宣佈下一次更新的計劃。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333389</guid>
            <pubDate>Sat, 08 Feb 2025 09:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Go 1.24 正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Go 1.24 已正式發佈，Go 1.24 在 Go 1.23 的基礎上帶來了許多改進。以下是一些顯著的變更。&lt;/p&gt; 
&lt;h2&gt;語言變更&lt;/h2&gt; 
&lt;p&gt;Go 1.24 現在完全支持 generic type aliases：類型別名可以被參數化，就像定義的類型一樣。有關詳細信息，請參閲語言規範。&lt;/p&gt; 
&lt;h2&gt;性能改進&lt;/h2&gt; 
&lt;p&gt;運行時的一些性能改進使得在一系列代表性基準測試中平均降低了 2-3% 的 CPU 負載。這些改進包括基於 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fabseil.io%2Fabout%2Fdesign%2Fswisstables&quot; target=&quot;_blank&quot;&gt;Swiss Tables&lt;/a&gt; 的新內置 &lt;code&gt;map&lt;/code&gt; 實現、更高效的內存分配（針對小對象）以及新的運行時內部互斥鎖實現。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;go&lt;/code&gt; 命令現在提供了一種跟蹤模塊工具依賴的機制。使用 &lt;code&gt;go get-tool&lt;/code&gt; 向當前模塊添加 &lt;code&gt;tool&lt;/code&gt; 指令。使用 &lt;code&gt;go tool [工具名稱]&lt;/code&gt; 來運行使用 &lt;code&gt;tool&lt;/code&gt; 指令聲明的工具。有關 go 命令，的更多信息，請參閲發佈説明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;go vet&lt;/code&gt; 子命令中的新 &lt;code&gt;test&lt;/code&gt; 分析器報告了測試包中測試、模糊測試、基準測試和示例聲明的常見錯誤。有關 vet 的更多信息，請參閲發佈説明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;標準庫新增內容&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;標準庫現在包括一套新的機制，以促進 FIPS 140-3 合規性。FIPS 140-3 合規性，的應用程序無需對源代碼進行任何更改即可使用新的機制來使用批准的算法。有關 FIPS 140-3 合規性，的更多信息，請參閲發佈説明。除了 FIPS 140 之外，之前位於 x/crypto 模塊中的幾個包現在也包含在，標準庫，中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基準測試現在可以使用更快且更少出錯的 &lt;code&gt;[testing.B.Loop](about:blank)&lt;/code&gt; 方法來執行基準迭代，例如用 &lt;code&gt;for b.Loop() { ... }&lt;/code&gt; 代替典型的涉及 &lt;code&gt;b.N&lt;/code&gt; 的循環結構，如 &lt;code&gt;for range b.N&lt;/code&gt;。有關新基準函數的更多信息，請參閲發佈説明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新的 &lt;code&gt;[os.Root](about:blank)&lt;/code&gt; 類型提供了在特定目錄下執行文件系統操作的能力。有關文件系統訪問的更多信息，請參閲發佈説明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;運行時提供了一種新的最終化機制 &lt;code&gt;[runtime.AddCleanup](about:blank)&lt;/code&gt;，它比 &lt;code&gt;[runtime.SetFinalizer](about:blank)&lt;/code&gt; 更靈活、更高效且更少出錯。有關清理操作的更多信息，請參閲發佈説明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;改進的 WebAssembly 支持&lt;/h2&gt; 
&lt;p&gt;Go 1.24 增加了一個新的 &lt;code&gt;go:wasmexport&lt;/code&gt; 指令，允許 Go 程序將函數導出到 WebAssembly 主機，並支持將 Go 程序構建為 WASI &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2FWASI%2Fblob%2F63a46f61052a21bfab75a76558485cf097c0dbba%2Flegacy%2Fapplication-abi.md%23current-unstable-abi&quot; target=&quot;_blank&quot;&gt;reactor/library&lt;/a&gt;。在發佈説明中瞭解更多關於 WebAssembly 的信息。&lt;/p&gt; 
&lt;p&gt;要查看完整更新日誌，請參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgo.dev%2Fdoc%2Fgo1.24&quot; target=&quot;_blank&quot;&gt;發佈説明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgo.dev%2Fdl%2F&quot; target=&quot;_blank&quot;&gt;https://go.dev/dl/&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333376/go-1-24</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333376/go-1-24</guid>
            <pubDate>Sat, 08 Feb 2025 08:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英特爾開源全新 NLP 模型：Polite Guard</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英特爾&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出 Polite Guard，一種用於文本分類任務的開源自然語言處理 (NLP) 語言模型，採用 MIT 許可。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 旨在使開發人員更容易生成自己的合成數據並微調他們的模型、通過提供針對敵對攻擊的防禦機制來增強系統的彈性、允許開發人員評估和比較他們的模型在禮貌分類方面的性能，以及通過確保在各個平台上進行尊重和禮貌的互動來提高客戶滿意度和忠誠度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該模型由 BERT 微調而來，可將文本分為四個不同的類別：polite, somewhat polite、neutral 以及 impolite。目前，英特爾已在&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 和&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FIntel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;Hugging Face&lt;/a&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;上開源了相關的數據集和 Polite Guard 源代碼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 數據集包含三個部分：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Few-Shot 提示生成 50,000 個帶標籤樣本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Chain-of-Thought（CoT）提示生成的 50,000 個帶標籤樣本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;來自企業培訓的 200 個經過匿名化處理（屏蔽個人標識符）的標註樣本。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告指出，合成數據被劃分為訓練集（80%）、驗證集（10%）和測試集（10%），每組均根據標籤進行平衡。Polite Guard 模型完全在合成數據上進行訓練，但在合成數據和真實標註數據的測試集上進行評估，準確率和 F1 分數均達到了 92.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46439a7eec58b0b02d7e2377a193c43abe8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e66b191ecaab81e31ad281895c85f48be6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;英特爾社區博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333358/intel-polite-guard</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333358/intel-polite-guard</guid>
            <pubDate>Sat, 08 Feb 2025 07:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英國和美國拒絕簽署國際人工智能宣言</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在巴黎舉行的全球峯會上，英國和美國沒有簽署人工智能（AI）國際宣言。這份由法國、中國和印度等國簽署的聲明承諾以&quot;開放&quot;、&quot;包容&quot;和&quot;道德&quot;的方式來發展人工智能技術。&lt;/p&gt; 
&lt;p&gt;在巴黎舉行的人工智能行動峯會的討論重點是人工智能對社會和環境的影響——以及需要採取哪些行動來獲取其利益和防範其風險。&lt;/p&gt; 
&lt;p&gt;美國和英國沒有解釋不簽署的原因。&lt;/p&gt; 
&lt;p&gt;但早些時候，美國副總統萬斯（JD Vance）在巴黎對與會代表説，對人工智能（AI）的過多監管可能會&quot;扼殺一個剛剛起飛的變革性行業&quot;。萬斯週二在巴黎舉行的峯會上告訴世界各國領導人，人工智能是&quot;特朗普政府不會浪費的機會&quot;，並表示&quot;有利於增長的人工智能政策&quot;應優先於安全。他説，這將需要促進人工智能發展的監管，&quot;而不是扼殺它&quot;。萬斯還説，歐洲領導人尤其應該&quot;以樂觀而非恐懼的態度看待這一新領域&quot;。&lt;/p&gt; 
&lt;p&gt;他的這番話似乎讓他與法國總統埃馬紐埃爾-馬克龍（Emmanuel Macron）產生了分歧，後者為進一步監管的必要性進行了辯護。&lt;/p&gt; 
&lt;p&gt;馬克龍在峯會上説：&quot;我們需要這些規則來推動人工智能的發展。&quot;這是在討論人工智能發展對社會、環境和治理的影響之際發表的。&lt;/p&gt; 
&lt;p&gt;參加巴黎峯會的政策制定者、高管和外交官們一直在思考如何獲取人工智能創新的經濟效益，同時應對該技術的風險。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1decb699dddc94378060a3327ba296ab72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;法國總統埃馬紐埃爾-馬克龍（Emmanuel Macron）在社交媒體上發佈了自己出演熱門電影和電視劇的 deepfake 搞笑片段彙編，拉開了本次峯會的序幕。&lt;/p&gt; 
&lt;p&gt;歐盟委員會主席烏蘇拉-馮德萊恩（Ursula von der Leyen）週二表示：&quot;本次峯會的重點是行動，而這正是我們現在所需要的。&quot;她説，在整個峯會期間，歐洲一直倡導的人工智能方法也將強調創新、合作和&quot;擁抱開源&quot;技術的力量。&lt;/p&gt; 
&lt;p&gt;此次會議的召開正值美歐貿易關係日益緊張之際。美國總統特朗普已決定對進口到美國的鋼鐵和鋁徵收關稅，此舉將影響英國和歐盟。&lt;/p&gt; 
&lt;p&gt;據悉， 英國不會立即採取報復行動，因為英國既要與特朗普政府保持良好關係，又要與歐盟建立更緊密的關係，因此英國希望走一條微妙的道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333337</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333337</guid>
            <pubDate>Sat, 08 Feb 2025 05:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI CEO 奧爾特曼：願意在人工智能領域與中國合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日，美國企業家埃隆·馬斯克等投資人當地時間 2 月 10 日提議「以 974 億美元競購」由其參與創建的美國開放人工智能研究中心（OpenAI）的非營利性母公司。&lt;/p&gt; 
&lt;p&gt;對此，2 月 11 日在法國巴黎出席人工智能行動峯會的 OpenAI 首席執行官薩姆·奧爾特曼&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot;&gt;再次強調「公司不賣」&lt;/a&gt;&lt;/u&gt;，並表示，「如果馬斯克願意談」，那麼他將「很樂意收購推特（即社交媒體平台 X）」。&lt;/p&gt; 
&lt;p&gt;奧爾特曼還表示，「&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;願意在人工智能領域與中國合作，並將為此盡最大努力，因為這很重要。&lt;/strong&gt;&lt;/span&gt;」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c01d53e2a43f4d2a467d4d590cc812b528.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據外媒週一報道，特斯拉 CEO 埃隆·馬斯克正率領一羣投資者，提出以 974 億美元收購 OpenAI 的控制權。馬斯克律師馬克·託貝羅夫補充説，他已於週一提交收購要約。&lt;/p&gt; 
&lt;p&gt;報道援引託貝羅夫提供的馬斯克聲明稱，「現在是時候讓 OpenAI 迴歸其曾經開源、注重安全的初衷了。」&lt;/p&gt; 
&lt;p&gt;OpenAI 首席執行官山姆·奧爾特曼在 X 平台上發帖稱，他寫道：「不了，謝謝。不過如果你願意的話，我們可以花 97.4 億美元收購推特。」隨後，馬斯克在 X 平台上回復這位 OpenAI 負責人，稱他為「騙子」。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333323</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333323</guid>
            <pubDate>Sat, 08 Feb 2025 03:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>稚暉君創業公司智元近日在深圳新設立「靈犀」產品線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.leiphone.com%2Fcategory%2Frobot%2FIYV9qXAR1wFN5Omd.html&quot; target=&quot;_blank&quot;&gt;根據「AI 科技評論」獨家報道&lt;/a&gt;，智元機器人三大事業部之一靈犀近日在深圳設立，目前正在招兵買馬。&lt;/p&gt; 
&lt;p&gt;據瞭解，智元此前調整組織架構，新設立三大產品線，分別是遠徵、靈犀和 Genie。此外還有幾個一級部門，例如靈巧手。&lt;/p&gt; 
&lt;p&gt;智元新成立的三大產品線分設三地，除了「靈犀」產品線在深圳外，遠徵產品線在上海，Genie 產品線大部隊在北京。&lt;/p&gt; 
&lt;p&gt;遠徵、靈犀、Genie 三大產品線總裁分別由王闖（前大疆 Livo 激光雷達負責人）、稚暉君、姚卯青（前蔚來工程總監）擔任。據瞭解，Genie 產品線前身是由上海交大閆維新教授和姚卯青指揮的研究院。&lt;/p&gt; 
&lt;p&gt;目前靈犀產品線由稚暉君暫代，還在招一號位人選。靈犀系列是智元產品矩陣之一，原先只有產品，並沒有配備專門產品線。此次新設立的靈犀產品線，將承接此前的靈犀系列產品。2024 年 10 月，智元曾宣佈&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhiyuan-robot.com%2FDOCS%2FOS%2FX1-PDG&quot; target=&quot;_blank&quot;&gt;開源靈犀 X1&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67d9642e1e623e3859f9c4aa1823336b99b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;稚暉君所在部門為 CTO Office，領銜 X-Lab 和 EI-Lab。X-Lab 由稚暉君指揮，EI-Lab 則歸北大計算機學院前沿計算研究中心助理教授董豪管理。&lt;/p&gt; 
&lt;p&gt;據介紹，靈犀主要做 To C，面向養老方向。而遠徵和 Genie 在產品腿部形態上做區分，遠徵做足式機器人，Genie 則是輪式機器人。&lt;/p&gt; 
&lt;p&gt;智元自成立起便開啓全棧自研，涵蓋軟件、硬件、大腦、小腦和雲系統等。技術上，智元提出具身智能 G1 到 G5 的演進路徑和技術框架，目前處於 G2 和 G3 階段。&lt;/p&gt; 
&lt;p&gt;智元持續推進量產工作。2024 年 12 月，智元機器人正式宣佈開啓機器人量產。2025 年 1 月 6 日，智元量產第 1000 台通用具身機器人正式下線。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/254290&quot; target=&quot;news&quot;&gt;稚暉君首款創業產品——智元機器人「遠徵 A1」發佈&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327297&quot; target=&quot;news&quot;&gt;智元機器人重磅開源百萬真機數據集 AgiBot World&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328925&quot; target=&quot;news&quot;&gt;智元機器人具身算法團隊推出 EnerVerse 架構&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333319</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333319</guid>
            <pubDate>Sat, 08 Feb 2025 03:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>梁文鋒實習往事：月薪 1.6 萬、沒畢業就被任命為部門經理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前「今日閔行」公眾號&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e1Eva97SJCgDJp3ukjlwA&quot; target=&quot;_blank&quot;&gt;發文稱&lt;/a&gt;，DeepSeek 創始人梁文鋒 2009 年曾在上海閔行的上海艾麒信息科技股份有限公司實習，負責內容也跟人工智能有關。&lt;/p&gt; 
&lt;p&gt;據艾麒信息創始人周朝恩透露，梁文鋒是其浙大校友，&lt;strong&gt;2009 年梁文鋒以實習生身份加入艾麒，後經推薦直接擔任新技術部經理，月薪 16000 元&lt;/strong&gt;，算是高薪特別聘請的。&lt;/p&gt; 
&lt;p&gt;「入職後，他便全身心投入到人工智能視頻與圖像技術的研究中，常常一整天都待在辦公室裏，專注地鑽研技術難題，甚至半天都不出來一次。」&lt;/p&gt; 
&lt;p&gt;他還透露了對梁文鋒的第一印象：「初見梁文鋒時，他戴着一副眼鏡，斯文有禮，身材清瘦，給人一種文靜內斂的印象。」&lt;/p&gt; 
&lt;p&gt;不過在深入接觸後，周朝恩發梁文鋒雖不善言辭，但在技術交流中卻能清晰地表達自己的觀點，「他為人沉着冷靜，性格簡單直接，對產品和技術有着極高的追求，堪稱典型的技術男風格」。&lt;/p&gt; 
&lt;p&gt;周朝恩介紹稱，梁文鋒在艾麒信息期間，當時公司新技術部也在研究做 100M CPU 的手機上視頻編解碼技術，並充分運用手機上 GPU 來高效處理視頻編解碼等技術。在這過程中，梁文鋒積累了豐富的技術經驗，為他後續創業打下了堅實的技術基礎。&lt;/p&gt; 
&lt;p&gt;他也曾管理過多位算法工程師，採用扁平化管理方式，給予團隊成員充分的自由和信任，發揮每個人的特長，並帶領團隊攻克了多項技術難題，優化了圖像視頻處理算法，提升了服務性能。&lt;/p&gt; 
&lt;p&gt;豐富的管理經驗在他創業後得到了延續。周朝恩告訴記者，梁文鋒招聘的團隊成員大多是數學競賽一等獎、拿過國際金牌的算法人才，這種對高端人才的管理和激勵方式，使得他在管理量化投資和深度求索時能夠迅速組建一支高效專業的技術團隊。&lt;/p&gt; 
&lt;p&gt;2023 年 5 月，梁文鋒在籌備深度求索之前，還特意回到艾麒公司進行調研。&lt;/p&gt; 
&lt;p&gt;此次調研，他比約定的時間提早 3 分鐘來到了周朝恩的辦公室，他不僅僅是看望老同事，而且還瞭解到艾麒信息也正在做大模型相關產品，「他與我們探討了人工智能相關技術，交流了將近 2 個小時」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333308</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333308</guid>
            <pubDate>Sat, 08 Feb 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 創始人未出席巴黎 AI 峯會</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期有消息稱，中國人工智能企業深度求索（DeepSeek）創始人梁文鋒受邀參加在巴黎舉辦的&quot;AI 行動峯會&quot;（AI for Action Summit）。此次峯會聚焦全球人工智能技術發展、倫理治理及跨領域協作，被視為推動全球 AI 治理框架落地的重要國際會議。為期兩天的人工智能行動峯會已於當地時間 10 日在法國首都巴黎的大皇宮拉開帷幕。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FphNF2U-ytrx6v97fqes_tA&quot; target=&quot;_blank&quot;&gt;根據鳳凰網科技的報道&lt;/a&gt;&lt;/u&gt;，接近 DeepSeek 的人士稱梁文鋒沒有參加這次在巴黎舉辦的人工智能行動峯會，公司層面也無人蔘加。&lt;/p&gt; 
&lt;p&gt;目前，除傳聞受邀的梁文鋒外，已披露的參會名單包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI 首席技術官米拉·穆拉蒂&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china&quot;&gt;DeepMind 首席執行官戴密斯·哈薩比斯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;法國總統馬克龍&lt;/li&gt; 
 &lt;li&gt;歐盟委員會數字事務副主席維斯塔格&lt;/li&gt; 
 &lt;li&gt;圖靈獎得主楊立昆&lt;/li&gt; 
 &lt;li&gt;斯坦福大學 HAI 研究院院長李飛飛等人&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;法國總統馬克龍在這次峯會開幕前夕曾表示，不會因為某個技術來自特定國家和地區就去禁用它，因為這很荒謬，他認為，DeepSeek 的出現是一個好消息，並希望下一代這樣的模型會出現在歐洲。&lt;/p&gt; 
&lt;p&gt;此外，值得注意的是，2 月 11 日，彭博社對 7 位初創公司創始人及 AI 專家的調研顯示，預計 DeepSeek 的估值在 10 億美元到逾 1500 億美元之間，估值區間的中間值為 20 億至 300 億美元。這樣的預測無疑讓持有 84% 股份的梁文峯身家暴漲，有望躋身亞洲科技鉅富之列。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333302</guid>
            <pubDate>Sat, 08 Feb 2025 02:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apollo 2.4.0 發佈，分佈式配置管理中心</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Apollo 2.4.0 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FyZ37eRPBwQtP-TQy1YPWag&quot; target=&quot;_blank&quot;&gt;已發佈&lt;/a&gt;，包含了諸如客戶端多 AppId 支持、集羣級權限控制支持、客戶端監控指標增強、配置全局搜索等重大更新。&lt;/p&gt; 
&lt;p&gt;Apollo（阿波羅）是一款可靠的分佈式配置管理中心，誕生於攜程框架研發部，能夠集中化管理應用不同環境、不同集羣的配置，配置修改後能夠實時推送到應用端，並且具備規範的權限、流程治理等特性，適用於微服務配置管理場景。&lt;/p&gt; 
&lt;p&gt;Apollo 2.4.0 主要新特性如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客戶端多 AppId 支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客戶端現在支持從多個 appid 加載配置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集羣級權限控制支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用戶可以按照集羣粒度配置命名空間的編輯和發佈權限，從而能滿足不同場景的權限管理要求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客戶端監控指標增強&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客戶端顯著增強了可觀測性，提供了 ConfigMonitor API 以及通過 JMX 和 Prometheus 導出指標的選項。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;配置全局搜索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;管理員用戶可以針對配置項的 Key 和 Value 進行全局模糊搜索，從而更容易在應用、環境、集羣和命名空間中定位配置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客戶端緩存支持 K8S ConfigMap&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客戶端支持配置信息緩存在 K8S ConfigMap 中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;應用訪問密鑰支持觀察者模式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在正式啓用應用密鑰之前，可以將應用訪問密鑰配置為觀察模式，從而僅作記錄而不實際攔截配置獲取。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;命名空間和配置項的數量限制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用戶可以限制命名空間的數量以及單個命名空間中的配置項數量，從而避免單個應用的配置過大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看更多內容：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo%2Freleases%2Ftag%2Fv2.4.0&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo/releases/tag/v2.4.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo-java%2Freleases%2Ftag%2Fv2.4.0&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo-java/releases/tag/v2.4.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 官方網站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apolloconfig.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.apolloconfig.com/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 倉庫地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 公共郵箱：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3Aapollo-config%40googlegroups.com&quot; target=&quot;_blank&quot;&gt;apollo-config@googlegroups.com&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333300/apollo-config-2-4-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333300/apollo-config-2-4-0-released</guid>
            <pubDate>Sat, 08 Feb 2025 02:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>馬雲現身阿里杭州總部，閃現閒魚、夸克兩大業務辦公區</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日下午，阿里巴巴創始人馬雲現身阿里杭州園區，身穿阿里巴巴黑色文化夾克，全程微笑並向員工揮手致意。&lt;/p&gt; 
&lt;p&gt;據社交媒體上的阿里員工透露，今日上午，馬雲先出現的地方是阿里西溪園區 A 區 2 號樓的閒魚。此後，下午又有人在 C 區的夸克偶遇馬雲，身旁還有阿里巴巴集團 CEO 吳泳銘陪同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60c6d8f397d9898ecffe3d57cacc36134b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作為阿里 AI To C 的代表產品，夸克近期也升級了品牌 Slogan—「2 億人的 AI 全能助手」。&lt;/p&gt; 
&lt;p&gt;同時，阿里 AI To C 正在「招賢納士」，以提升用戶的信息服務體驗。2 月 6 日，全球頂尖人工智能科學家、Salesforce 集團（CRM）前副總裁許主洪（Steven Hoi）&lt;a href=&quot;https://www.oschina.net/news/332267&quot; target=&quot;_blank&quot;&gt;正式加入阿里&lt;/a&gt;，出任集團副總裁，向吳嘉彙報，負責 AI To C 業務的多模態基礎模型及 Agents 相關基礎研究與應用解決方案。&lt;/p&gt; 
&lt;p&gt;有偶遇馬雲的阿里員工表示，「馬老師精神真的好好，特別開心的跟我們合影打招呼，就在智能信息這層，巡樓祝大家新年快樂。」&lt;/p&gt; 
&lt;p&gt;據悉，去年 11 月 29 日，馬雲第一次出現在阿里西溪園區 C 區，即杭州全球總部新園區。12 月 8 日，馬雲參加了螞蟻集團成立 20 週年活動。在活動上，馬雲着重提到了 AI 發展，他表示，從今天來看，未來 20 年的 AI 時代能帶來的改變會超出所有人的想象，因為 AI 會是一個更加偉大的時代。&lt;/p&gt; 
&lt;p&gt;2 月 8 日，馬雲也曾被網友在新加坡的一個高爾夫球場偶遇。當時，他正在享受一場悠閒的球賽，看起來狀態極佳。馬雲在新加坡的現身也引發了不少猜測，有人認為他可能正在為阿里巴巴的全球化戰略做準備，也有人認為他只是單純地享受個人時光。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333296</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333296</guid>
            <pubDate>Sat, 08 Feb 2025 02:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百川智能 CEO 王小川：AGI 的盡頭是生命科學</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo7wg-YavNVPm-KJxFpJ9uA&quot; target=&quot;_blank&quot;&gt;百川智能創始人兼 CEO 王小川接受晚點對話的採訪&lt;/a&gt;&lt;/u&gt;，表示「不是文本創作、不是物理模型，&lt;strong&gt;AGI 的盡頭是生命科學&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;採訪中，王小川提到，之所以堅定了公司方向聚焦醫療，是因為大模型是造人的，而醫生是人類職業中最複雜的之一，所以它可以成為一個標尺。並且他認為，大模型能造出醫生時，就是達到了 AGI。&lt;/p&gt; 
&lt;p&gt;同時，王小川對 DeepSeek 的「火爆全球」表示振奮，一方面他認為 DeepSeek 改變了行業格局，中國離實現 AGI 和應用爆發更近，另一方面，他覺得 DeepSeek 的出圈讓更多人體驗到了 AI，教育了整個行業。&lt;/p&gt; 
&lt;p&gt;在談及訓練醫療大模型費用時，&lt;strong&gt;王小川認為醫療模型有更高的價值，它關係生命健康，因此不能按 token 來算錢&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;王小川還預測了未來的技術發展趨勢。AI 通過學會使用工具，一步步學習製造工具，最後形成循環，AI 寫完代碼自己運行，AI 自己造工具自己用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333290</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333290</guid>
            <pubDate>Sat, 08 Feb 2025 02:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國行蘋果 AI 敲定與阿里巴巴合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根據科技媒體 The Information 的獨家報道，&lt;strong&gt;蘋果公司已經與阿里巴巴達成合作，為國行版的 iPhone 用戶提供 AI 功能&lt;/strong&gt;，消息來源為一位知情人士。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0212/101826_AE4P_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，蘋果與阿里巴巴共同開發的國行 AI 功能已提交給國內相關部門審核。&lt;/p&gt; 
&lt;p&gt;兩位對該項目有直接瞭解的人士稱，蘋果在 2023 年開始測試來自中國開發者的不同 AI 模型，並一度選擇百度作為主要合作對象，但由於百度在為蘋果智能開發模型方面的進展未達到美國公司的標準，因此該合作後來被取消。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蘋果最近幾個月開始考慮其他選項，評估騰訊、字節跳動、阿里巴巴以及 Deepseek 開發的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;報道還提到，&lt;strong&gt;蘋果最終放棄了最近呼聲很高的 DeepSeek ，因為 DeepSeek 團隊缺乏支持像蘋果這樣的大客戶所需的人力和經驗&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;648&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0212/101851_M45f_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日前，蘋果向開發者發送了關於「利用蘋果智能的力量」開發者活動的相關郵件。&lt;/p&gt; 
&lt;p&gt;值得關注的是，本次活動將於 3 月 25 日 10:00 至 12:00 在上海&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/332912&quot;&gt;舉行&lt;/a&gt;&lt;/u&gt;，活動主題將圍繞蘋果智能和機器學習兩個方面。而這一舉動，也暗示在中國大陸的蘋果智能 AI 功能或將上線。&lt;/p&gt; 
&lt;p&gt;截至發稿前，蘋果和阿里巴巴官方尚未對此作出回應，但這兩家公司美股漲幅均已超過 1%，百度股價下跌超 4%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相關來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fapple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&quot; target=&quot;_blank&quot;&gt;https://www.theinformation.com/articles/apple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333288</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333288</guid>
            <pubDate>Sat, 08 Feb 2025 02:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>李彥宏談 DeepSeek 爆火：創新是不能被計劃的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在阿聯酋迪拜舉辦的 World Governments Summit 2025 峯會上，百度創始人李彥宏與阿聯酋 AI 部長奧馬爾·蘇丹·奧拉馬對談時提及 DeepSeek 表示：創新是不能被計劃的。「你不知道創新何時何地到來，你所能做的是，營造一個有利於創新的環境。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-20f4da7c355029d6c8b5f97139534ed0d93.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 突然爆火背後，李彥宏稱，如果回顧過去幾百年，大多數創新都與降低成本有關，不僅是在人工智能領域，甚至不僅僅是在 IT 行業。如果能將成本降低一定數量、一定百分比，這意味着生產率提高了相同的百分比。這幾乎就是創新的本質。而今天，創新的速度比以前快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以科技行業為例，在過去，當業界談論摩爾定律時常説，每 18 個月性能會翻倍、成本會減半；但今天，當大家談論大語言模型時，可以説每 12 個月，推理成本就可以降低 90% 以上。這比人們過去幾十年經歷的計算機革命要快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「大語言模型是一個非常龐大的領域。在中國，我們必須在推理和訓練方面創新以降低成本。幸運的是，過去一年，我們看到了顯著進步。」李彥宏表示，在對話中，奧拉馬還提到，幾周前，當 DeepSeek 成為人人都談論的話題時，不少全球大型芯片廠商股價大幅下跌。因為巨頭們此前需要花費數十億美元用於推理數據中心、訓練這些人工智能系統和模型。在 DeepSeek 的衝擊下，數據中心和 AI 基礎設施的未來是否會發生變化？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李彥宏表示，自己在過去一個月左右的時間裏，一直在思考這個問題。從基本面來看，最重要的仍然是技術進步非常快，成本每年降低約 90%，性能越來越好。「當技術發展如此之快，你無法停止投資。你必須投資，以確保處於這場技術創新或革命的最前沿。我們仍需對芯片、數據中心和雲基礎設施進行持續投入，用於打造更優秀、更智能的下一代模型。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為此，企業需要使用更多的算力來嘗試不同的路徑。「也許，在某個時刻你會找到一條捷徑，比如説只需 600 萬美元就能訓練出一個模型，但在此之前，你可能已經花費了數十億美元，用來探索哪條路才是花費這 600 萬美元的正確途徑。」李彥宏説。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他認為，目前的 AI 應用離那種級別的應用還有很遠的距離。「整個世界目前都在焦急地尋找這樣的超級 App。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333284</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333284</guid>
            <pubDate>Sat, 08 Feb 2025 02:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度文小言（原文心一言）App 接入 DeepSeek-R1 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;iOS 版百度文小言（原文心一言）App 日前迎來了 4.9.0 版本更新，更新描述稱該版本已接入 DeepSeek-R1 模型，優化拍照解題功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a4769f89c4a201f4028836651b2741d29f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲ 百度文小言（原文心一言）App 接入 DeepSeek-R1 模型&lt;/p&gt; 
&lt;p&gt;接入 DeepSeek-R1 模型後，文心一言 App 的拍照解題功能得到了顯著提升。用戶在使用該功能時，可以清晰地看到解題過程中的思考步驟，這與 DeepSeek 特有的思維鏈功能非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cc68ae51d81f06ed72ba3d94755a877e04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1944e58c65fe9c878bae4407b0cf63cf2ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用戶表示，「這極大地提升了用戶的解題體驗。用戶通過拍攝問題，系統將自動識別並給出詳細的解題思路，這對於需要進行學習和複習的用戶來説是個好消息。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333181</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333181</guid>
            <pubDate>Fri, 07 Feb 2025 10:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>LibreOffice 25.2 正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;開源辦公軟件 LibreOffice 25.2 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2025%2F02%2F06%2Flibreoffice-25-2%2F&quot; target=&quot;_blank&quot;&gt;已正式發佈&lt;/a&gt;&lt;/u&gt;，這是其今年發佈的第一個重大更新版本。&lt;/p&gt; 
&lt;p&gt;正如預期的那樣，這次更新帶來了大量變化，遍佈整個生產力套件，包括顯著的界面更改、可訪問性改進以及更多重要的互操作性增強，以支持跨套件的工作流程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e0efe1096043b00228d329f455df0ce8c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;重要的是要記住，像 LibreOffice 這樣的開源軟件並非憑空出現；它是人類創造的，其中許多人無償工作，其他人則僅被支付以工作於特定部分。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-92184ded85f6ccdaa1c8efc71bb7effd84c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們都有自己的願望清單，列出了我們希望我們最喜歡的開源應用程序添加的功能和更改，但我們不應讓這影響我們欣賞現有的、正在運行和支持的一切。&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 總共包含了 6 個月的開發成果，其中 47% 的代碼提交來自由「LibreOffice 相關生態公司」僱傭的開發者，31% 來自 The Document Foundation 的開發者，其餘來自志願者。&lt;/p&gt; 
&lt;p&gt;下面介紹 LibreOffice 25.2 主要變化。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7aa0e33bc7a0a17a221b921404f8639dc2b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 能夠讀取和寫入 OpenDocument Format (ODF) 1.4 格式。這是最新的文件格式規範，已經被 Microsoft Office 所採用。確保 ODT、ODP 等文件在 LibreOffice 中能夠良好工作是很重要的。&lt;/p&gt; 
&lt;p&gt;其他方面，這次更新在 LibreOffice 24.8 引入的隱私變更基礎上，增加了清除與任何文檔相關的所有個人信息的能力，例如作者姓名和時間戳、編輯時間、文檔模板、跟蹤更改等。&lt;/p&gt; 
&lt;p&gt;任何處理大量不同文檔類型的人一定會欣賞到，現在在&lt;em&gt;&lt;strong&gt;「File &amp;gt; Recent Documents」&lt;/strong&gt;&lt;/em&gt;菜單中包括了一個複選框，僅顯示活動應用程序的文件。&lt;/p&gt; 
&lt;p&gt;用戶界面更改包括對主題的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdesign.blog.documentfoundation.org%2F2024%2F12%2F20%2Flibreoffice-themes-will-replace-the-color-customization%2F&quot; target=&quot;_blank&quot;&gt;重大改進&lt;/a&gt;！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1b86c12cb53d7c1288ec12cb2094880071.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新主題可以在應用內下載並快速應用（目前只有少數幾個，但隨着創意人士的……嗯，發揮創意，數量預計會增長！）&lt;/p&gt; 
&lt;p&gt;如果您一直渴望有機會獨立於系統主題來更改 LibreOffice UI 中的特定顏色，現在您可以做到了！前往&lt;em&gt;「Tools &amp;gt; Options &amp;gt; LibreOffice &amp;gt; Appearance」&lt;/em&gt;，在主題選擇器中選擇「自定義」，然後使用顏色選擇器進行調整。&lt;/p&gt; 
&lt;p&gt;您可以更改從文檔頁面顏色、主應用背景圖片、工具欄顏色等的一切——應用在更改之間會要求重啓。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-03fbca1f828b47c2d50029598030f182e24.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;▲ LibreOffice 25.2 中更新的項目符號樣式&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Writer&lt;/em&gt;&amp;nbsp;包含以下改進：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;更新了無序列表（項目符號）的默認項&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;跟蹤更改管理器調整，包括聚焦高亮和排序&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更好地支持從 DOCX 導入的頂級行形狀&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;為 DOCX 文件提供字體回退，針對不可用的字體&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;為文檔設置默認縮放級別（覆蓋文件中存儲的級別）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;選項將回複評論提升為根評論&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;現在支持內聯標題&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;從 &lt;em&gt;導航器&lt;/em&gt; 中刪除特定類型的所有內容（不包括標題）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;頁碼嚮導&lt;/em&gt; 選項使數字適應現有邊距&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;現在可以自定義註釋背景顏色&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在 &lt;em&gt;導航器&lt;/em&gt; 中的標題上懸停，以在工具提示中查看單詞和字符計數&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Calc&lt;/em&gt; 新增：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;支持在 OOXML 中導入和導出&lt;/strong&gt; &lt;code&gt;connections.xml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;狀態欄圖標指示是否已關閉 &lt;em&gt;自動計算&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增「處理重複記錄」對話框，用於選擇/刪除重複記錄&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;改進了「函數嚮導」對話框和「函數側邊欄」中的搜索功能&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在包含相鄰數據的單元格中，默認選中所有相鄰單元格&lt;/strong&gt;1&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「數據下方摘要」選項添加到「小計」對話框&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可以將求解器模型保存到電子表格中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;添加了數據透視表、數據透視圖表和自動篩選的表單保護選項&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Impress&lt;/em&gt; 展示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;改進了_Impress_模板&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;對象可以一步在_Impress_幻燈片中居中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;文本框對象現在支持「軟邊緣」和「發光」效果&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SVG 導出支持段落半透明形狀文本&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在窗口模式下可以激活自動重複的幻燈片&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;打印時演示者備註中的溢出文本不再被截斷&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.documentfoundation.org%2FReleaseNotes%2F25.2&quot; target=&quot;_blank&quot;&gt;此版本的官方發佈説明&lt;/a&gt;提供了更多關於這些以及其他更改的信息，包括代碼提交、錯誤報告以及涵蓋技術原因的博客文章鏈接。&lt;/p&gt; 
&lt;h3&gt;其他更改&lt;/h3&gt; 
&lt;p&gt;除了 Linux，macOS 用戶還獲得了與內置的「快速預覽」文件預覽功能的集成，允許在完全打開文檔之前（可能還消除了完全打開的需要）預覽文檔。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Draw&lt;/em&gt;：支持在導入的 PDF 中剪輯描邊路徑&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Base&lt;/em&gt;：SQL 對話框現在在會話期間保留用戶輸入&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Math&lt;/em&gt;：公式可以存儲在用戶定義的分類中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;與專有 OOXML 文檔的互操作性調整&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;從側邊欄的「屬性」面板中可以控制連字符&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;對象邊界現在可以獨立於格式標記進行切換&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持粘貼帶有 HTML 刪除線的格式化文本&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;libvisio 已更新至 v0.1.8&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;改進了無障礙訪問&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，還有一個新的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.libreoffice.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;LibreOffice 幫助&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.libreoffice.org%2F&quot; target=&quot;_blank&quot;&gt;網站&lt;/a&gt;，用戶可以在那裏尋求其他用戶的反饋。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;em&gt;LibreOffice 25.2&amp;nbsp;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.libreoffice.org%2Fdownload%2Fdownload-libreoffice%2F&quot; target=&quot;_blank&quot;&gt;https://www.libreoffice.org/download/download-libreoffice/&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333173/ibreoffice-25-2-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333173/ibreoffice-25-2-released</guid>
            <pubDate>Fri, 07 Feb 2025 09:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>男子用 DeepSeek 買彩票中獎：買 10 元中 5 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日，詞條#用 DeepSeek 買彩票真中獎了#登上微博熱搜榜第一，引起許多網友熱議。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/172819_3xs4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據媒體報道，日前，安徽蕪湖一男子發帖稱，自己按照 DeepSeek 推薦的號碼買雙色球，真的中獎了。&lt;/p&gt; 
&lt;p&gt;該男子用 5 組 DeepSeek 推薦的數字下注，&lt;strong&gt;合計 10 元，其中一組數字中了「2+1」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/173130_nyzI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，這是第一次買雙色球，也是才接觸 DeepSeek，突發奇想想看看到底準不準，這樣的行為不能「上頭」，自己之後不會再用 DeepSeek 推薦的數字繼續買彩票。&lt;/p&gt; 
&lt;p&gt;據中國福利彩票服務熱線工作人員介紹，&lt;strong&gt;上述情況是中了六等獎，獎金為 5 元。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於該男子的做法，有網友表示：「合計 10 元，中了 5 元？有沒有可能沒有 DeepSeek，你買五組也有這個概率呢？我覺得也沒必要神話 DeepSeek。」「隨機概率這麼大，跟它真沒太大關係。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333169</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333169</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度李彥宏：自動駕駛比人開車安全十倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日消息，「世界政府峯會」（World Goverments Summit 2025）今日在阿聯酋迪拜開幕，百度創始人李彥宏今日上午在主論壇上與阿聯酋 AI 部長奧馬爾・蘇丹・奧拉馬（Omar Sultan AI Olama）對談時表示，Robotaxi 可以大大降低交通事故死亡率。從蘿蔔快跑的實際記錄來看，出險率僅為人類駕駛員的 1/14。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8b66f69d2ba73a703403b32ebdae56e2f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李彥宏表示：「技術進步非常快，自動駕駛比人類司機安全十倍。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74a55024af52c507dd898d356bf590ace0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，2024 年第二季度，百度的自動駕駛服務蘿蔔快跑供應的自動駕駛訂單約 89.9 萬單，同比增長 26%。截至 2024 年 7 月 28 日，蘿蔔快跑累計為公眾提供的自動駕駛出行服務訂單超過 700 萬單。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/301302&quot; target=&quot;news&quot;&gt;百度旗下的「蘿蔔快跑」無人駕駛出租車武漢街頭撞倒行人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333160</guid>
            <pubDate>Fri, 07 Feb 2025 08:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>