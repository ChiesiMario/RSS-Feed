<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 04 Aug 2025 07:45:36 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Meta 有望收購 AI 視頻初創公司 Pika Labs</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Meta 日前正在積極尋求與 AI 視頻生成技術的初創公司建立合作伙伴關係，旨在發力視頻生成領域。&lt;/p&gt; 
&lt;p&gt;知情人士稱，Meta 近期與 AI 視頻初創公司 Pika 就潛在合作展開了討論，內容包括可能的收購或技術授權協議。另據透露，Meta 還與另一家專注於創作者的小型視頻生成商 Higgsfield 討論過收購事宜，但目前談判已暫停。&lt;/p&gt; 
&lt;p&gt;據悉，Pika 以生成逼真視頻的 AI 技術而知名。而據公開信息，郭文景是 Pika Labs 的聯合創始人與 CEO。她與聯合創始人兼 CTO Chenlin Meng 均為斯坦福大學 AI Lab 博士生，在 2023 年 4 月從斯坦福輟學、創立了 Pika Labs，致力於開發基於文本生成短視頻的 AI 工具。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，郭文景入讀斯坦福讀博前還曾任職於 Meta AI 研究團隊。據瞭解，郭文景自幼展現非凡學術天賦，被譽為「學霸少女」，是浙江杭二中首個被哈佛本科提前錄取的學生 。&lt;/p&gt; 
&lt;p&gt;另外，Pika 僅成立半年便爆紅，團隊最初只有四人，卻在 2023 年完成三輪融資，籌資約 5500 萬美元，估值約 2–3 億美元；隨後在 2024 年 B 輪融資約 8000 萬美元，使估值上漲至近 5 億美元。&lt;/p&gt; 
&lt;p&gt;Pika 的&lt;a href="https://www.oschina.net/news/361912"&gt;核心產品&lt;/a&gt;為「文生視頻」模型，號稱用戶一句話描述，就能生成風格多樣的動畫短視頻。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364087</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364087</guid>
      <pubDate>Mon, 04 Aug 2025 07:40:36 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義 Qwen3 模型拿下全球第三</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;國際知名大模型評測 Chatbot Arena 日前公佈最新榜單，Qwen3-235B-A22B-Instruct-2507 斬獲 1433 分，超越頂尖閉源模型 Grok4、Claude4、GPT4.1，Qwen3 位列總榜「全球第三」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1440" src="https://static.oschina.net/uploads/space/2025/0804/153306_pv7H_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，Chatbot Arena 採用盲測評價機制，是 AI 大模型領域最具影響力的榜單之一。&lt;/p&gt; 
&lt;p&gt;此次 Qwen3 的 1433 分，是全球開源大模型和中國大模型的歷史最高分。同時，Qwen3 還在 5 個關鍵能力子項中摘得「全球第一」，包括數學（math）、代碼（coding）、複雜提示（hard prompts）、長文本檢索（longer query）和指令遵循（instruction following）。&lt;/p&gt; 
&lt;p&gt;除 Qwen3 Instruct 模型外，Qwen3 家族多款模型也取得優秀成績：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;推理模型 Qwen3-235B-A22B-Thinking-2507 也闖進榜單前十，數學能力並列全球第一；&lt;/li&gt; 
 &lt;li&gt;在 Chatbot Arena 專門評估編程能力的 WebDev Arena 子榜單中，編程模型 Qwen3-Coder 性能與 Gemini2.5 Pro、DeepSeek-R1、Claude4 並列第一。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153340_6oDO_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="973" src="https://static.oschina.net/uploads/space/2025/0804/153435_soAg_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/153506_LT7j_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364084</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364084</guid>
      <pubDate>Mon, 04 Aug 2025 07:36:14 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>7 月 Chrome 份額達 69.98%，接近歷史新高</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;Statcounter 最新數據顯示，谷歌 Chrome 瀏覽器在 7 月的份額進一步鞏固，達到了 69.98%，幾乎接近歷史新高，較上月增長了 3.09 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與此同時，微軟 Edge 瀏覽器的市場份額卻出現了下滑，2025 年 7 月，Edge 的市場份額從 13.06% 下降至 11.8%，流失了相當一部分用戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-4deb5717a3ebf7e551b81308cac02cc5d2a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 Chrome 和 Edge 之外，其他瀏覽器的市場份額也有所下降，蘋果的 Safari 以 6.51% 的市場份額位居第三，較上月下降了 1.83 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Firefox 以 5.32% 的市場份額位居第四，較上月下降了 0.52 個百分點；Opera 則以 2.2% 的市場份額位居第五，較上月下降了 0.43 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-8174cbe98fe739c689d75e4f46138fdb892.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在移動市場，Chrome 的主導地位同樣明顯，以 67.32% 的市場份額位居第一，蘋果 Safari 以 22.42% 的市場份額位居第二，三星瀏覽器以 3.5% 的市場份額位居第三。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;微軟 Edge 雖然具備一些獨特實用功能，但在移動市場上的份額仍然微不足道。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364068</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364068</guid>
      <pubDate>Mon, 04 Aug 2025 06:53:14 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Android Studio 免費 Agent 模式上線</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌在其官方開發者博客及 Google I/O2025 大會上宣佈，Android Studio 正式推出免費的 Agent 模式，為安卓應用開發引入了革命性的 AI 輔助功能。這一功能的發佈不僅大幅提升了開發效率，還憑藉其智能化的交互方式和靈活的自定義規則支持，被業界認為是對蘋果開發生態的有力挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Android Studio 的 Agent 模式是基於 Gemini2.5Pro 的 AI 輔助功能，旨在通過自然語言交互幫助開發者完成複雜、多步驟的開發任務。相較於傳統的代碼補全或建議功能，Agent 模式能夠深入理解整個項目上下文，自動制定執行計劃，並在開發者指導下完成從代碼生成到錯誤修復的完整工作流。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="343" src="https://oscimg.oschina.net/oscnet/up-c81c59459ff6d229a26c159791d8a845b17.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心功能亮點：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自然語言任務描述：開發者只需用自然語言描述目標，例如「修復項目中的構建錯誤」或「為應用添加深色模式支持」，Agent 模式即可生成跨多個文件的執行計劃，自動編輯代碼、添加依賴並修復錯誤。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;UI 代碼快速修改：Agent 模式支持直接選中並修改 UI 代碼。例如，開發者可以要求「在主屏幕添加一個‘關注’按鈕」或「減少某個組件的內邊距」，Agent 會精準定位相關文件並提出修改建議，開發者可通過「接受」或「拒絕」按鈕進行審核。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;自定義規則支持：通過 Prompt Library，開發者可以設置項目特定的編碼風格或技術棧偏好，例如「始終使用 Kotlin 生成簡潔代碼」。這些規則將自動應用於後續任務，確保輸出的代碼符合項目標準。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;百萬 Token 上下文窗口：免費版本的 Agent 模式提供有限的上下文窗口，但訂閲 Google AI Ultra 或使用 Gemini API 密鑰的開發者可解鎖 Gemini2.5Pro 的 100 萬 Token 上下文窗口，支持處理超大規模代碼庫和複雜任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌強調，Agent 模式不僅能處理常規任務，還能通過 Model Context Protocol （MCP）與外部工具集成，例如直接從 Android Studio 創建 GitHub 拉取請求，進一步擴展其功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;效率飛躍:從繁瑣任務到創意開發&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的推出旨在解放開發者，讓他們從繁瑣的重複性工作中解脫出來，專注於更具創造性的開發任務。例如，開發者可以委託 Agent 模式完成以下任務:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;自動化依賴更新：通過 Version Upgrade Agent，自動分析項目依賴、解析發行説明並更新到&lt;span&gt;最新&lt;/span&gt;兼容版本，同時生成詳細的變更報告。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;用戶旅程測試：開發者可以用自然語言描述用戶旅程（如「測試登錄流程」），Agent 模式會自動生成測試腳本並在虛擬或物理設備上運行，輸出詳細結果。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;多文件重構：如將硬編碼字符串提取到 strings.xml 文件，或對整個項目進行復雜的代碼重構，Agent 模式都能逐步執行並允許開發者實時審查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌表示，Agent 模式通過結合 Android Studio 的內置工具（如代碼搜索、構建系統和 UI 檢查器），能夠以最小的監督完成從原型設計到錯誤修復的全流程任務，顯著加速開發週期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式的免費開放被視為谷歌對蘋果 Xcode 生態的強力回應。蘋果的 Xcode 雖然在 iOS 開發中佔據主導地位，但其 AI 輔助功能相對滯後，缺乏類似 Agent 模式的自主 AI 特性。谷歌通過免費提供 Agent 模式（默認配額充足）以及支持 Gemini2.5Pro 的付費訂閲模式，降低了開發者的使用門檻，同時提供了更高的靈活性和性能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，Android Studio Narwhal Feature Drop（2025.2 版本）還引入了其他增強功能，如:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;Google Play 政策洞察：通過 Lint 檢查提供 Play Store 政策合規性建議，幫助開發者避免上架問題。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;XR 開發支持：新增 Jetpack XR 項目模板和嵌入式佈局檢查器，優化了擴展現實（XR）應用的開發體驗。&lt;/li&gt; 
 &lt;li style="text-align:left"&gt;Kotlin K2 模式：支持 Live Edit 和 Compose Preview 等功能，提升 Kotlin 開發的流暢性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Agent 模式目前已在 Android Studio Narwhal Feature Drop（2025.2Canary 版本）中向所有用戶開放，商業訂閲用戶將在未來幾周內獲得更完整的功能支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管該功能仍處於實驗階段，部分開發者反饋指出其在調用外部工具或處理特定場景時存在侷限性，例如無法完全訪問源文件或修改外部資源。谷歌已表示正在積極解決這些問題，並計劃在未來版本中支持更完整的 MCP 功能，如 Streamable HTTP 傳輸和外部上下文資源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364062</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364062</guid>
      <pubDate>Sun, 03 Aug 2025 06:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌面向 Ultra 訂閲用戶推出 Gemini 2.5 Deep Think 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌已在 Gemini 應用中面向 Google AI Ultra 訂閲者開放&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgemini%2Fgemini-2-5-deep-think%2F" target="_blank"&gt;Gemini 2.5 Deep Think 模型&lt;/a&gt;，此模型技術源於在國際數學奧林匹克（IMO）競賽中&lt;a href="https://www.oschina.net/news/361739"&gt;達到金牌標準&lt;/a&gt;的模型，但它是一個能夠更快、更適合日常使用的版本。&lt;/p&gt; 
&lt;p&gt;根據內部評估，此次發佈的版本在 2025 年 IMO 基準測試中能達到銅牌水平。Deep Think 的核心技術在於利用並行的「思考時間」和新穎的強化學習技術來解決複雜問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/140804_2uzD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它通過同時生成、考慮、修正和組合多個想法來尋找最佳答案，這種方法被稱為並行思維。通過延長推理時間，Gemini 能夠探索更多假設，從而為複雜問題提供創造性解決方案。&lt;/p&gt; 
&lt;p&gt;在 LiveCodeBench V6 和 Humanity’s Last Exam 等基準測試中，Gemini 2.5 Deep Think 在不使用工具的情況下取得了當前最佳性能。該模型適用於需要創造力、戰略規劃和逐步改進的任務，例如迭代式開發與設計、科學與數學發現，以及算法開發和編程。&lt;/p&gt; 
&lt;p&gt;在測試中，Deep Think 在網頁開發任務的美觀性和功能性上都表現出色。安全性方面，與 Gemini 2.5 Pro 相比，Deep Think 在內容安全和語氣客觀性上有所提升，但拒絕無害請求的傾向也更高。&lt;/p&gt; 
&lt;p&gt;Google AI Ultra 訂閲者現在可以在 Gemini 應用中使用 2.5 Pro 模型時，通過在提示欄中切換「Deep Think」來啓用此功能。Google 還與一小組數學家和學者分享了達到 IMO 金牌標準的官方版本，以收集反饋用於進一步改進。&lt;/p&gt; 
&lt;p&gt;https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Deep-Think-Model-Card.pdf&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364054</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364054</guid>
      <pubDate>Sun, 03 Aug 2025 06:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小米開源聲音理解大模型 MiDashengLM-7B</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;小米自研聲音理解大模型 MiDashengLM-7B 正式發佈，並全量開源。&lt;/p&gt; 
&lt;p&gt;據小米官方介紹，MiDashengLM-7B 速度精度上實現雙突破：單樣本首 Token 延遲僅為同類模型 1/4、同顯存下併發超 20 倍，在 22 個公開評測集上刷新多模態大模型最好成績（SOTA）。&lt;/p&gt; 
&lt;p&gt;MiDashengLM-7B 基於 Xiaomi Dasheng 作為音頻編碼器和 Qwen2.5-Omni-7B Thinker 作為自迴歸解碼器，通過創新的通用音頻描述訓練策略，實現了對語音、環境聲音和音樂的統一理解。&lt;/p&gt; 
&lt;p&gt;MiDashengLM 的訓練數據由 100% 的公開數據構成，模型以寬鬆的 Apache License 2.0 發佈，同時支持學術和商業應用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/114919_TWqX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2024 年，小米發佈的 Xiaomi Dasheng 聲音基座模型在國際上首次突破 AudioSet 50+ mAP，在 HEAR Benchmark 環境聲、語音、音樂三大領域建立領先優勢並保持至今。&lt;/p&gt; 
&lt;p&gt;Xiaomi Dasheng 在小米的智能家居和汽車座艙等場景有超過 30 項落地應用。行業首發的車外喚醒防禦、手機音箱全天候監控異常聲音、「打個響指」環境音關聯 IoT 控制能力，以及小米 YU7 上搭載的增強哨兵模式劃車檢測等，背後都有 Xiaomi Dasheng 作為核心算法的賦能。&lt;/p&gt; 
&lt;p&gt;小米表示，不同於 Qwen2.5-Omni 等未公開訓練數據細節的模型，MiDashengLM 完整公開了 77 個數據源的詳細配比，技術報告中詳細介紹了從音頻編碼器預訓練到指令微調的全流程。&lt;/p&gt; 
&lt;p&gt;作為小米「人車家全生態」戰略的關鍵技術，MiDashengLM 通過統一理解語音、環境聲與音樂的跨領域能力，不僅能聽懂用戶周圍發生了什麼事情，還能分析發現這些事情的隱藏含義，提高用戶場景理解的泛化性。&lt;/p&gt; 
&lt;p&gt;基於 MiDashengLM 的模型通過自然語言和用戶交互，為用戶提更人性化的溝通和反饋，比如在用戶練習唱歌或練習外語時提供發音反饋並制定針對性提升方案，又比如在用戶駕駛車輛時實時對用戶關於環境聲音的提問做出解答。&lt;/p&gt; 
&lt;p&gt;MiDashengLM 以 Xiaomi Dasheng 音頻編碼器為核心組件，是 Xiaomi Dasheng 系列模型的重要升級。在當前版本的基礎上，小米已着手對該模型做計算效率的進一步升級，尋求終端設備上可離線部署，並完善基於用戶自然語言提示的聲音編輯等更全面的功能。&lt;/p&gt; 
&lt;p&gt;MiDashengLM 開源地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub 主頁：https://github.com/xiaomi-research/dasheng-lm&lt;/li&gt; 
 &lt;li&gt;技術報告：https://github.com/xiaomi-research/dasheng-lm/tree/main/technical_report&lt;/li&gt; 
 &lt;li&gt;模型參數（Hugging Face）：https://huggingface.co/mispeech/midashenglm-7b&lt;/li&gt; 
 &lt;li&gt;模型參數（魔搭社區）：https://modelscope.cn/models/midasheng/midashenglm-7b&lt;/li&gt; 
 &lt;li&gt;網頁 Demo： https://xiaomi-research.github.io/dasheng-lm&lt;/li&gt; 
 &lt;li&gt;交互 Demo：https://huggingface.co/spaces/mispeech/MiDashengLM&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364036</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364036</guid>
      <pubDate>Sun, 03 Aug 2025 03:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元開源圖像生成新框架 MixGRPO</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;騰訊的混元基礎模型團隊近日發佈了一項突破性的圖像生成新框架 MixGRPO。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這一方案不僅將訓練時間縮短了近 50%，而且在性能上表現優異，甚至推出了一個名為 MixGRPO-Flash 的變體，進一步將訓練時間降低了 71%。這一切，得益於他們將隨機微分方程（SDE）和常微分方程 (ODE) 相結合的創新採樣策略。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在當前的圖像生成技術中，效率與質量常常是一對矛盾的存在。MixGRPO 通過引入混合採樣的方法，優化了馬爾可夫決策過程（MDP），使得訓練效率得到了顯著提升。具體而言，該框架通過限制智能體的隨機探索範圍，減少了優化過程中的計算開銷，同時簡化了模型的訓練流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-1d9c69fd57fb5a7fb1949f0eaf28be94dc0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與之前的 DanceGRPO 模型相比，MixGRPO 在多個維度上都表現出顯著的改善。研究團隊在實驗證明瞭，只需對特定的去噪步驟進行優化，就能夠保持甚至提升性能。研究還指出，雖然 MixGRPO 在減少訓練時間的同時降低了計算開銷，但也需要高階求解器的引入，以加速舊策略模型的採樣。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，MixGRPO 採用了滑動窗口的策略，讓模型能夠在去噪的過程中逐漸聚焦於更關鍵的時間步，從而實現了更高效的優化。這一創新使得模型在圖像生成的多樣性和質量上都有了不小的進步。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364034</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364034</guid>
      <pubDate>Sun, 03 Aug 2025 03:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 切斷 OpenAI 對 Claude 的訪問權限</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;據&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fanthropic-revokes-openais-access-to-claude%2F" target="_blank"&gt;報道&lt;/a&gt;，Anthropic 切斷了 OpenAI 對其 Claude 系列 AI 模型的 API 訪問權限。這一決定在 2025 年 8 月初突然生效，正值 OpenAI 準備發佈其新一代模型 GPT-5 之際。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/114141_vxVK_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1554" src="https://static.oschina.net/uploads/space/2025/0804/114021_E29W_2720166.png" width="1660" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報道稱，Anthropic 指出 OpenAI 違反了其服務條款，具體表現為：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;通過 API 大規模接入 Claude 模型&lt;/strong&gt;；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;用於內部對比測試&lt;/strong&gt;，包括編程能力、創意寫作、安全性評估（如 CSAM、自殘、誹謗等敏感內容響應）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;目的疑似是為 GPT-5 的優化提供參考&lt;/strong&gt;，這構成了「構建競爭產品」的行為。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Anthropic 發言人 Christopher Nulty 表示：「Claude Code 已成為程序員首選工具，我們發現 OpenAI 的技術人員也在用其為 GPT-5 做準備，這違反了我們的服務條款。」&lt;/p&gt; 
&lt;p&gt;OpenAI 首席傳播官 Hannah Wong 回應稱：「評估其他 AI 系統是行業標準做法，我們尊重 Anthropic 的決定，但考慮到我們的 API 仍對他們開放，這令人失望。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364033</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364033</guid>
      <pubDate>Sun, 03 Aug 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 設計協作平台 Figma 正式上市</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;2025 年 7 月 31 日，Figma 在紐約證券交易所正式掛牌&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.figma.com%2Fblog%2Fipo-pricing%2F" target="_blank"&gt;上市&lt;/a&gt;，股票代碼「FIG」。公司發行價為每股 33 美元，上市首日迎來瘋狂表現——開盤價約 85 美元，一度突破 110 美元，最終收盤報 115.50 美元，較發行價暴漲約 250%，市值飆升至近 670 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d386af1f817c11f15d500492257996a7621.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Figma 由此也成為 2025 年以來美股上市最火爆的企業。這場 IPO 被視為科技市場重燃活力的標誌，其 AI 驅動的協作設計平台和&lt;strong&gt;「AI+SaaS」&lt;/strong&gt;概念受到市場廣泛認可 。&lt;/p&gt; 
&lt;p&gt;市場普遍將這次暴漲的背後歸功於 Figma 在 AI 戰略上的堅定佈局。《MarketWatch》指出，Figma 不僅在設計協作工具中引入生成式 AI 能力，更將其定位為「從點子到原型」的端到端平台，其 Make、Buzz、Slides 等功能構成了完整 AI 驅動的產品線，從而贏得投資者信心。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fed96dbd106547468223fff6274dc45ff66.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Renaissance Capital 的分析師 Matt Kennedy 在接受採訪時表示，這場 IPO 反映了投資者對具備 AI 元素的高增長 SaaS 公司的強烈熱情，並將 Figma 視為該類資產中的「領頭羊」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364029/figma-ipo</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364029/figma-ipo</guid>
      <pubDate>Sun, 03 Aug 2025 03:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 成立編程與視頻 AI 子公司命名「Macrohard」</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據美國專利商標局的公開信息，埃隆·馬斯克的人工智能公司 xAI 已於 2025 年 8 月 1 日正式提交了&amp;nbsp;&lt;strong&gt;「Macrohard」&lt;/strong&gt;&amp;nbsp;商標註冊申請。這一舉動正式確認了此前馬斯克在社交媒體上引發的猜測。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="277" src="https://oscimg.oschina.net/oscnet/up-86376576f3b808a49efc1c7b9204a472462.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;早在 7 月 14 日，馬斯克就在 X 平台上暗示，xAI 正在籌備一家專注於&amp;nbsp;&lt;strong&gt;編程與圖像/視頻生成 AI 代理&lt;/strong&gt;&amp;nbsp;的子公司。當時他向公眾提問：「這是一項宏大的挑戰，你能猜出這家公司叫什麼嗎?」 當評論區有用戶提及「Macrohard」時，馬斯克以一個眨眼的表情作為回應，似乎在默認這個名字。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次商標申請的序列號為 99314877，申請費用為 2300 美元，涵蓋了兩個核心商標類別，這與馬斯克此前透露的子公司業務方向高度一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「Macrohard」這個名稱本身就充滿了馬斯克式的幽默與挑釁。它顯然是對科技巨頭微軟（Microsoft）的直接戲仿。通過將「Micro(微觀)」替換為「Macro(宏觀)」，xAI 在保持與微軟發音和拼寫相似性的同時，也形成了強烈的對比。這不僅是對微軟的致敬或挑戰，也暗示了新公司可能在宏觀層面或更大規模上進行創新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364026</guid>
      <pubDate>Sun, 03 Aug 2025 03:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>360 集團宣佈納米 AI「多智能體蜂羣」上線</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;8 月 1 日，360 集團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FFYyCIKj4kSzZiDf2MnZynA" target="_blank"&gt;正式宣佈&lt;/a&gt;納米 AI 完成品牌煥新，升級為「多智能體蜂羣」，並宣稱&lt;span&gt;成為全球第一個達到 L4 級的智能體系統——不再是單個 AI 「單兵作戰」，而是像蜂羣一樣讓數萬只專業 AI 自動組隊、分工、協作，一口氣完成上千步複雜任務，20 分鐘就能做出 10 分鐘電影級大片，真正進入「成果直接交付」時代。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;L1：聊天助手，本質上是聊天工具，擅長提建議或提供情感陪伴，屬於「玩具級」智能體，比如 GPTs。此時的 AI 尚處於「單向響應」階段，更像是被動輸出信息的「對話窗口」，遠未觸及 「解決問題」 的核心。&lt;br&gt; L2：低代碼工作流智能體，以低代碼模式搭建的工作流智能體為代表，已經從「玩具」進化為「工具」，但交付的是半成品工具而非最終產物。&lt;br&gt; L3：自主規劃智能體，具備推理能力的智能體，比如首發版的 Manus、比如目前納米 AI 中的 5 萬+ 垂直專家智能體，包括深度研究智能體、購物智能體等。&lt;br&gt; L4：智能體蜂羣，就像人類僱傭了一個團隊在工作，甚至可以隨時擴展這個團隊的規模，實現能力的無限擴展，從而幫你拿到結果、達成目標。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height="580" src="https://static.oschina.net/uploads/space/2025/0804/111459_c1NA_2720166.png" width="1070" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="635" src="https://static.oschina.net/uploads/space/2025/0804/111654_QTDI_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;納米 AI 創造了全新的「蜂羣協作框架」，多個推理型智能體可以靈活拉羣、多層嵌套、組隊協作完成複雜任務。該技術包含兩大亮點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;實現多個智能體多層嵌套、組隊協作完成複雜任務，讓他們像蜂羣一樣緊密協作。這不是一個 Agent 單打獨鬥，而是多智能體分工協作，各司其職、同時上陣&lt;/li&gt; 
 &lt;li&gt;升級後的納米 AI 成功實現「多智能體蜂羣」的靈活配置，可單蜂羣作戰，也可以組成蜂羣方陣&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據稱納米 AI 智能體蜂羣已實現連續 2 小時執行超 1000 步任務不中斷，消耗 token 超 2000 萬。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;使用入口：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.n.cn" target="_blank"&gt;www.n.cn&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364024</guid>
      <pubDate>Sun, 03 Aug 2025 03:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>構建 AI 護城河的六大常見誤區分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&amp;gt; &lt;strong&gt;編者按：&lt;/strong&gt; 大家都在爭相構建自己的「人工智能護城河」，但究竟什麼才是真正有效的競爭壁壘？是海量的歷史數據、定製化的模型，還是華麗的數據看板？ &amp;gt; &amp;gt; 我們今天為大家帶來的文章，系統分析了當前企業在構建 AI 護城河時的六大常見誤區，文章的核心觀點是：真正的 AI 護城河需要長期積累、紮實的基礎能力，而不是依賴表面功夫或單點突破。 &amp;gt; &amp;gt; 希望這篇文章能為您的 AI 戰略提供啓發，幫助您避免陷入常見誤區，構建可持續發展的競爭壁壘。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文系原作者觀點，Baihai IDP 僅進行編譯分享&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shaili Guru&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在上一篇文章中，我分享了「AI Moat Pyramid」框架，企業團隊可以用它來構建真正的人工智能防禦壁壘。&lt;/p&gt; 
&lt;p&gt;這篇文章是反面教材：介紹六種最常見的誤區 —— 它們看似是護城河，實則因未能夯實金字塔的核心能力層，而在悄然削弱你的競爭優勢。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 誤區一：「我們擁有數十年積累的數據，因此佔據優勢。」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;歷史數據往往分散雜亂、標註混亂，或塵封在無人願意觸碰的舊系統中。&lt;/strong&gt; 這種誤區使團隊無法真正構建金字塔的第二層：專有數據。&lt;/p&gt; 
&lt;p&gt;如若出現以下情況，你的數據優勢就不會存在：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;數據不可尋&lt;/li&gt; 
 &lt;li&gt;數據不可用&lt;/li&gt; 
 &lt;li&gt;數據不可信&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;若你最有價值的數據存放在 PDF 裏，或儲存在名為「final_final_v2.xlsx」的共享文件中 —— 這絕非護城河，而是無法滿足第二層（專有數據層）可用性要求的數據包袱。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 誤區二：「我們微調了模型，所以具備差異化優勢。」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;定製 ≠ 有價值，除非它能帶來更好的業務結果，並且可以投入生產。&lt;/strong&gt; 這種誤區阻礙了團隊構建金字塔的第一層：定製化開發模型與算法。&lt;/p&gt; 
&lt;p&gt;若出現以下情況，您的模型無法成為 AI 護城河：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在關鍵業務指標上無法超越開源替代方案&lt;/li&gt; 
 &lt;li&gt;無法快速重新訓練或部署到生產環境&lt;/li&gt; 
 &lt;li&gt;無法隨着模型的使用情況持續優化&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;如果模型的最佳表現僅停留在演示視頻中，而非產生實際價值的生產系統裏 —— 你只是在堆砌技術複雜度，而非構建第一層（定製化開發模型與算法）所需的競爭優勢。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 誤區三：「我們開發了 AI 數據看板。」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;數據看板不會改變行為或觸發決策，工作流集成才會。&lt;/strong&gt; 這種誤區完全偏離了金字塔的第三層：工作流集成的核心要求。&lt;/p&gt; 
&lt;p&gt;除非您的模型輸出能夠：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;觸發自動化操作&lt;/li&gt; 
 &lt;li&gt;直接影響真實用戶的工作流&lt;/li&gt; 
 &lt;li&gt;無縫嵌入用戶現有工具鏈&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;否則它就無法融入決策路徑，形同虛設。&lt;/p&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;如果員工需要定時查看數據看板，那麼説明 AI 並未真正輔助工作——它沒有真正融入工作流，只是製造了可有可無的信息噪音，與第三層（工作流集成層）要求的深度嵌合相去甚遠。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 誤區四：「合規問題可以後期再解決。」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;在受監管的領域，信任機制和治理體系無法在啓動後再建立。&lt;/strong&gt; 這種誤區將直接瓦解金字塔的第四層：領域專精的根基。&lt;/p&gt; 
&lt;p&gt;在受監管的領域構建護城河必須始於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;決策可解釋性&lt;/li&gt; 
 &lt;li&gt;完備的治理與審計追蹤機制&lt;/li&gt; 
 &lt;li&gt;符合現實規則與領域限制&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;若您無法在一分鐘內向監管人員或一線操作者解釋某個決策並證明其依據 —— 你擁有的不是符合第四層要求的可信 AI 產品，而是一顆等待爆發的合規問題炸彈。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 誤區五：「模型規模擴大後模型自然會變聰明。&lt;/strong&gt; &lt;strong&gt;」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;沒有學習閉環，用戶越多 ≠ 模型越好。&lt;/strong&gt; 這種誤區完全忽視了金字塔的第五層：網絡效應的運作機制。&lt;/p&gt; 
&lt;p&gt;只有當您做到以下三點，AI 系統才能持續進化並形成網絡效應：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;系統化獲取可量化、可分析的用戶數據&lt;/li&gt; 
 &lt;li&gt;基於用戶數據高頻迭代模型&lt;/li&gt; 
 &lt;li&gt;建立用戶行為與模型優化的閉環&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;如果用戶增長但未記錄可學習的行為數據，或模型迭代速度滯後 —— 這種擴張本質上是在製造數據垃圾（noise），而非構建第五層應有的智能壁壘或自我強化護城河。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 誤區六：「把 AI 功能打包進產品，就能形成護城河。」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現實情況：&lt;strong&gt;功能堆砌無法形成護城河，除非能帶來讓用戶難以割捨的遷移成本，或無可替代的獨佔價值。&lt;/strong&gt; 誤區六是對金字塔第六層 「戰略護城河 」的膚淺理解。&lt;/p&gt; 
&lt;p&gt;只有當滿足以下條件時，捆綁策略才能形成護城河：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;深度嵌入業務流程或數據資產，使用戶遷移變得痛苦&lt;/li&gt; 
 &lt;li&gt;鎖定專有價值（獨家數據/獨特的工作流）&lt;/li&gt; 
 &lt;li&gt;AI 成為用戶工作流中不可或缺的核心組件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;自我審視：&lt;/p&gt; 
&lt;p&gt;如果客戶能零成本替換您的 AI 方案，且無需承擔重大損失或犧牲獨特價值 —— 那它就不是戰略護城河，只是個缺乏防禦力的附加功能。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 切忌「去粉飾護城河」&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;許多團隊高估了自身 AI 護城河的強度，因為他們衡量的是投入成本或某個組件的是否存在，而非實際產生的商業槓桿效應或防禦能力。&lt;/p&gt; 
&lt;p&gt;這些認知誤區暴露出那些未能構建 AI Moat Pyramid 中堅實且相互關聯的層級的錯誤做法。&lt;strong&gt;真正的護城河應該具備：隨時間產生複合優勢、形成難以複製的競爭壁壘。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這些誤區中的大部分做法都無法讓你真正建立起 AI 護城河；它們只是讓你的戰略在 PPT 彙報中聽起來很棒，但經不起深入的檢驗和考察。如果你真的想要建立可防禦的競爭優勢，那就先用這些常見陷阱來嚴格檢驗你的假設。因為如果你都能找出自己護城河的漏洞，你的競爭對手當然也可以。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓説説你曾經信心滿滿設計開發的 AI 功能，最後發現毫無競爭力的故事。失敗比成功更有價值！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faipmguru.substack.com%2Fp%2Fai-moats-or-ai-mirage-debunking-6" target="_blank"&gt;https://aipmguru.substack.com/p/ai-moats-or-ai-mirage-debunking-6&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18686654</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18686654</guid>
      <pubDate>Sun, 03 Aug 2025 03:19:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>OpenAI 開源模型信息意外泄露</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在 Hugging Face 上短暫泄露的信息顯示，OpenAI 可能將於下週發佈兩款代號分別為 gpt-oss-20b 和 gpt-oss-120b 的開源模型。&lt;/p&gt; 
&lt;p&gt;泄露內容顯示，OpenAI 計劃發佈兩個變體：一個 20B 模型和一個 120B 模型，代號分別為 gpt-oss-20b 和 gpt-oss-120b。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/110128_loH4_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據泄露的配置文件和社區分析，120B 模型是一個稀疏的 MoE（Mixture of Experts）模型，擁有 128 個專家，每個 token 激活 4 個。其架構與 Mixtral 相似，採用了 Grouped-Query Attention (GQA)、SwiGLU 激活函數和 NTK RoPE。模型包含 36 個層，上下文長度為 4096，隱藏層大小為 2,880，擁有 64 個注意力頭和 8 個 KV 頭。詞彙表大小為 201,088，與 GPT-4o 的 tokenizer 相匹配。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/110206_B03j_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，該模型在預訓練階段使用了 fp4 精度，並支持混合原生數據類型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="484" src="https://static.oschina.net/uploads/space/2025/0804/110148_4hug_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;有分析指出，模型可能對微調有一定抵抗性，以限制定製化。此次泄露由 vLLM 和 OpenAI 的員工在測試時不慎引發。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364016</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364016</guid>
      <pubDate>Sun, 03 Aug 2025 03:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic CEO 最新訪談：上半年收入逼近 45 億美元、不擔心被開源衝擊因為它並不削弱商業價值</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Anthropic 聯合創始人兼 CEO Dario Amodei（達裏奧·阿莫代伊）近日接受媒體專訪，講述了個人的職業動機，分享 Anthropic 的商業模式和增長策略，以及對 AI 開源和市場競爭的看法，強調 AI 技術的指數級增長及其帶來的巨大潛力和風險，同時呼籲行業重視 AI 的安全性和對齊問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0804/105053_K0CH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;摘錄部分內容如下：&lt;/p&gt; 
&lt;p&gt;一、&lt;strong&gt;融資與商業模式&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;已融資近 200 億美元，故事核心是「用 1/10 成本做出比別人更好的模型」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每個已發佈的模型本身是盈利的，賬面虧損源於「再投資下一代」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;60–75% 收入來自 API，但真正的賭注是「企業級高價值場景」（醫藥、金融、法律等）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼是第一個爆發場景，因市場反饋快、數據飛輪可反哺模型。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;Anthropic 目前估值已達 610 億美元（約合人民幣 4453 億元）。&lt;/p&gt; 
&lt;p&gt;Dario 表示：「我們在 2021 年初幾乎從零起步，到 2025 年 3 月實現年化營收 14 億美元（約合人民幣 102.2 億元），5 月增至 30 億美元（約合人民幣 219 億元），7 月進一步逼近 45 億美元（約合人民幣 328.5 億元）。以這個體量來看，我們可能已經是歷史上增長最快的軟件公司之一。」&lt;/p&gt; 
&lt;p&gt;Anthropic 的商業路徑也逐步清晰。與 OpenAI 主要依靠 ChatGPT 訂閲和 API 向終端用戶變現不同，Anthropic 則側重面向企業客戶提供模型 API 服務，支持客戶將 Claude 集成進自有產品，用於客服、搜索、編程等應用場景。&lt;/p&gt; 
&lt;p&gt;這也使 Anthropic 在行業中的角色愈發關鍵：其模型能力越強，授權客戶的產品性能越好，競爭力也隨之增強。在模型能力持續提升、客戶體量不斷擴大的同時，阿莫代伊也希望藉此推動整個 AI 行業沿着他認為「更可控、安全的路徑」演進。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二、技術仍在指數級爆發&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Dario 認為「Scaling Laws 撞牆論」並未出現，反而看到第二階段訓練（RL、推理時計算）仍在繼續放大規模收益&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;以代碼能力為例，從 3.5→4.0，Opus 連續 4–5 代顯著提升，SWE-bench 從 3%→72~80%，內部代碼 90% 由 Claude 生成&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;以 Anthropic 的模型為例，Dario 表示，在我們看到的情況中——比如編程，是我們模型進展最快的領域之一，用戶採用速度也非常快。我們不是一家只做編程的公司，但如果你看編程，我們發佈了 Claude 3.5 Sonnet、3.5 Sonnet V2（姑且叫它 3.6）、然後是 3.7 Sonnet，接着是 4.0 Sonnet 和 4.0 Opus。這一系列四五款模型，每一代在編程能力上都有明顯提升。&lt;/p&gt; 
&lt;p&gt;如果你看具體的基準測試，比如 SWE-bench，它在 18 個月前的通過率可能還只有 3% 左右，而現在已經提升到 72% 甚至 80%，具體取決於你用什麼標準來衡量。&lt;/p&gt; 
&lt;p&gt;實際使用量也在指數級增長。我們正在接近一個階段，模型幾乎可以自主完成大部分編程任務。以我們公司為例，現在 Anthropic 的大多數代碼都是由 Claude 系列模型直接生成，或在其協助下完成的。其他一些公司也説過類似的事情。我們看到的，是快速的進展和持續的指數趨勢，並未發現「收益遞減」的現象。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三、護城河與競爭：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;技術護城河被不斷髮明的新方法「刷新」，關鍵是「人才密度」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Meta/馬斯克用「高薪+GPU」搶人，但 Anthropic 極少員工跳槽——歸因於使命驅動的文化與公平的薪酬體系&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不擔心開源衝擊：權重≠源代碼，推理成本與工程壁壘仍高，開源並不削弱商業價值&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;Dario 説道，我們每天都在開發新技術。Claude 現在非常擅長寫代碼，但我們其實很少在公開場合談論為什麼 Claude 代碼能力這麼強。&lt;/p&gt; 
&lt;p&gt;雖然我們不公開談這些細節。但我們每一個 Claude 新版本都會在架構、訓練數據、訓練方法等方面有新的改進。我們一直在開發新技術。新技術是每一代模型的一部分。這也是為什麼我一直在強調「人才密度」這麼重要——你需要足夠多優秀的人才，才能持續發明出這些新方法。&lt;/p&gt; 
&lt;p&gt;此外，我們發現，相比其他公司，從 Anthropic 被挖走的人要少得多。並不是因為沒有人來挖。我和很多收到其他公司 Offer 的員工都聊過，其中一些人甚至根本不願意和扎克伯格談話，他們直接拒絕了，説「我會繼續留在 Anthropic」。&lt;/p&gt; 
&lt;p&gt;我們對此的整體回應是這樣的：我在公司 Slack 羣發了一條信息説——我們不會為了回應個別挖角而去破壞我們的薪酬體系和公平原則。&lt;/p&gt; 
&lt;p&gt;不能因為扎克伯格隨手擲飛鏢剛好選中了你，你就能比你身邊同樣優秀的人多拿 10 倍薪水。在我看來，唯一能真正傷害公司的方式，就是因為恐慌而破壞公司的文化，用不公平的方式去「保人」。而我們沒有這樣做，我們堅持了自己的原則，也因此更團結，因為我們相信——Anthropic 的人，是因為認同使命才留下來的。&lt;/p&gt; 
&lt;p&gt;談到開源，Dario 認為開源 AI 就是偽概念，開源再先進，也不會削弱 Anthropic 的商業價值。&lt;/p&gt; 
&lt;p&gt;「AI 領域的開源，並不等同於軟件領域的開源。你無法「看見」模型內部發生了什麼——你能看到的是模型的權重（open weights），不是源代碼（source code），兩者是有本質區別的。開源帶來的「共建、協同、可複用」這些優勢，在 AI 領域並沒有那麼強。」&lt;/p&gt; 
&lt;p&gt;用戶最終選擇的是效果最好的產品，而不是最開放的產品。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;參考來源&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FfWqDZpkm325Cy0uK6VcVvA" target="_blank"&gt;https://mp.weixin.qq.com/s/fWqDZpkm325Cy0uK6VcVvA&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVLeti1L5YzVie0neKD2Jsw" target="_blank"&gt;https://mp.weixin.qq.com/s/VLeti1L5YzVie0neKD2Jsw&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364011</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364011</guid>
      <pubDate>Sun, 03 Aug 2025 02:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克：許多 Meta 頂尖工程師正在加入 xAI 公司</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近日，馬斯克在一場活動中透露，多個 Meta 公司的&lt;span&gt;高級&lt;/span&gt;工程師正在轉投他的新興人工智能公司 xAI。儘管 xAI 的起薪並不算高，但馬斯克相信，這家公司在未來的估值將有可能超過 Meta。他還提到，xAI 在為&lt;span&gt;頂尖&lt;/span&gt;人才提供薪資激勵方面有着良好的傳統。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="251" src="https://oscimg.oschina.net/oscnet/up-e05d8c2299b504c3e85c2895a40c103065f.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;據悉，Meta 公司近期積極招攬人工智能領域的人才，甚至接觸了超過 100 名 OpenAI 的員工，其中成功招聘了至少 10 人。這種行為被外界解讀為 Meta 在人才競爭中的一種 「孤注一擲」 的舉措。同時，ChatGPT 的核心團隊成員之一 Shengjia Zhao 也已加入 Meta，擔任&lt;span&gt;超級&lt;/span&gt;智能實驗室的首席科學家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，針對 Meta 的招聘行動，也有一些工程師選擇拒絕。他們認為，OpenAI 的研究方向更接近於通用人工智能（AGI），並且更傾向於小團隊的高效與靈活，不想參與以廣告驅動的項目。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;隨着科技行業人才競爭愈演愈烈，xAI 的快速發展吸引了許多行業觀察者的目光。與此同時，OpenAI、谷歌和 Meta 等公司也在爭奪&lt;span&gt;頂尖&lt;/span&gt;研究人員。Meta 已經為其人工智能部門擴大了規模，並且為 Scale AI 投入了 140 億美元的資金。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在 6 月，Meta 推出了&lt;span&gt;超級&lt;/span&gt;智能實驗室，旨在匯聚該領域的&lt;span&gt;頂尖&lt;/span&gt;專家。OpenAI 首席執行官山姆・奧爾特曼聲稱，Meta 曾開出高達 1 億美元的薪酬來吸引他的團隊成員，但這一説法遭到 Meta 的否認。根據媒體報道，Meta 確實向 OpenAI 的員工發出了多份招聘邀請，但並非所有人都選擇加入。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最後，Meta 承諾新員工在入職一年後將完全擁有公司給予的股份或股票期權。然而，Anthropic 的聯合創始人本傑明・曼則表示，公司的員工並未對 Meta 的豐厚激勵措施產生興趣，反而更看重組織的使命感。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364002</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364002</guid>
      <pubDate>Sun, 03 Aug 2025 02:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>輕鬆給 Claude Code 接入火山引擎 API</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;h2&gt;前提條件&lt;/h2&gt; 
&lt;p&gt;在開始之前，請確保您已經安裝好 Claude CLI。接下來我們將部署 Claude Code Proxy 代理服務，該服務支持多種接入方式，讓您能夠靈活切換不同的 AI 模型提供商。&lt;/p&gt; 
&lt;h2&gt;步驟一：下載並安裝 Claude Code Proxy&lt;/h2&gt; 
&lt;p&gt;首先訪問&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAIDotNet%2FClaudeCodeProxy%2Freleases" target="_blank"&gt;Releases · AIDotNet/ClaudeCodeProxy&lt;/a&gt;頁面，下載最新版本的 win-64 壓縮包。下載完成後解壓文件，您將看到以下目錄結構：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4f72df5b6d0961c37799a5a083a416c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="920" src="https://oscimg.oschina.net/oscnet/up-f23ca4287996e311cd2578196419eb02446.png" width="1337" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;步驟二：啓動代理服務&lt;/h2&gt; 
&lt;p&gt;使用管理員權限運行 run-directly.bat 腳本。此腳本主要用於測試和快速啓動服務。&lt;/p&gt; 
&lt;p&gt;注意：使用管理員權限是為了將服務註冊為 Windows 服務，這樣可以實現常駐運行，無需每次手動啓動。&lt;/p&gt; 
&lt;p&gt;啓動成功後，您將看到以下日誌輸出，此時可以通過瀏覽器訪問 http://localhost:6500：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1d087d7e162c469437a3851175933ab5.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//fbd8e92271e775973e16283259497fe5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="628" src="https://oscimg.oschina.net/oscnet/up-e29b0b4494df8e0bbdc82d3543812f4a975.png" width="1115" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;步驟三：登錄管理界面&lt;/h2&gt; 
&lt;p&gt;在瀏覽器中打開 http://localhost:6500，您將看到登錄界面。使用默認賬號密碼登錄：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用戶名：admin&lt;/li&gt; 
 &lt;li&gt;密碼：admin123&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//9f96458d8e98cb35c401b75511642fd8.jpg" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//01f5c23ed8baa4ed3ed4a4a8982c4f95.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="986" src="https://oscimg.oschina.net/oscnet/up-8573bd8dccb3c6468fd82db622552cc212e.png" width="1527" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;登錄成功後，您將進入系統首頁：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//6df1fdcff1092b890e8abfa10329e73c.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ecebb9804be5e266c0aac2043af3d4ad.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="984" src="https://oscimg.oschina.net/oscnet/up-952669e60161f6c5781aaf93e9713a55145.png" width="1510" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;步驟四：配置火山引擎 API 賬戶&lt;/h2&gt; 
&lt;p&gt;在首頁中點擊"賬戶管理"，然後點擊右上角的"添加賬戶"按鈕：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e20ed8a408b827492c5c2a40a36fde05.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//424deb93c53f3a8ec8b6d1565bfab16b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1080" src="https://oscimg.oschina.net/oscnet/up-17993562c7ce4e746f3643ca7390a02ab8f.png" width="1026" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在彈出的配置界面中：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;服務類型：選擇"OpenAI"&lt;/li&gt; 
 &lt;li&gt;BaseURL：輸入 https://ark.cn-beijing.volces.com/api/v3&lt;/li&gt; 
 &lt;li&gt;API Key：填寫您的火山引擎密鑰&lt;/li&gt; 
 &lt;li&gt;點擊"創建"按鈕完成配置&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//13dbd3f502b5da93cd4558631571559b.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f4963b3344fb99760b792e031e027f80.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1080" src="https://oscimg.oschina.net/oscnet/up-d33e4762293d930afc566bf9bb58ed6cb9e.png" width="1026" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;步驟五：創建 API Key&lt;/h2&gt; 
&lt;p&gt;賬戶添加完成後，點擊"API Key 管理"，然後點擊"創建 API Key"：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e14b846a21b6baa9bc3a877925b82587.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//93b0fa637e284947ea98c8643a210fdf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1183" src="https://oscimg.oschina.net/oscnet/up-1b2ec5eb4a5a4a428a2be4ec3da22cfdab0.png" width="1367" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在創建 API Key 時，請注意以下配置：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;服務類型：選擇"OpenAI"&lt;/li&gt; 
 &lt;li&gt;模型：指定一個具體的模型，或者通過環境變量進行設置&lt;/li&gt; 
 &lt;li&gt;配置完成後點擊"創建"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//2b345c017577f76d7287727982a32aa0.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//0545ea677221e129744eefb23e10b20e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1184" src="https://oscimg.oschina.net/oscnet/up-9036d8a01775846d81d4dc5ccaba76f6a1d.png" width="1369" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;創建完成後，請複製生成的 API Key，我們將在下一步中使用它。&lt;/p&gt; 
&lt;h2&gt;步驟六：配置 Claude Code&lt;/h2&gt; 
&lt;p&gt;現在需要配置 Claude Code 使用我們的代理服務。&lt;/p&gt; 
&lt;p&gt;6.1 打開配置目錄&lt;/p&gt; 
&lt;p&gt;導航到 Claude Code 的配置目錄：C:\Users\您當前的用戶\.claude&lt;/p&gt; 
&lt;p&gt;6.2 編輯配置文件&lt;/p&gt; 
&lt;p&gt;在該目錄中打開 settings.json 文件（如果不存在則創建一個新文件），添加以下配置內容：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "env": {
    "ANTHROPIC_AUTH_TOKEN": "剛剛上面創建的 Key",
    "ANTHROPIC_BASE_URL": "http://localhost:6500"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;6.3 測試配置&lt;/p&gt; 
&lt;p&gt;保存配置文件後，打開命令行終端，輸入 claude 命令啓動 Claude Code：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cf728c8f2304410d29b82c0423026162.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c8d035c448670d39ab3ed01c085923a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="666" src="https://oscimg.oschina.net/oscnet/up-2a2b1913ef5e2159769ae8406e6bd52b247.png" width="1115" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;現在讓我們測試一下配置是否生效：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//98255ea7ef8b2eb4a4aabd05103a0b3f.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//0a96f3ef5635ade128ad1090c1e1d96f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1084" src="https://oscimg.oschina.net/oscnet/up-08b716a995fa6dc6ac859fabcfe4eb1c319.png" width="1222" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;步驟七：接入 Claude Pro 賬號（可選）&lt;/h2&gt; 
&lt;p&gt;上述步驟已經完成了火山引擎 API 的接入。如果您還擁有 Claude Pro 賬號，也可以將其接入到代理服務中，這樣當 Pro 賬號用量用完後，可以無縫切換到其他模型提供商。&lt;/p&gt; 
&lt;p&gt;7.1 添加 Claude 賬號&lt;/p&gt; 
&lt;p&gt;回到賬號管理頁面，點擊"創建賬戶"。如果您的網絡環境需要代理，可以在此處配置代理設置：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a6af39a0f7c4ab2d4911f13a9138434f.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//514b25babac346722b578859453b480f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1270" src="https://oscimg.oschina.net/oscnet/up-dc571286de184a12e7d48eac62c871b30b2.png" width="1475" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;7.2 生成授權鏈接&lt;/p&gt; 
&lt;p&gt;點擊"下一步"，然後點擊"生成授權鏈接"：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//09753c30468252d6b457471c3f018423.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3d3636e57bb88c0de31b4f222b1c40cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1157" src="https://oscimg.oschina.net/oscnet/up-6fa4dbc2a735a5577ce7511804cb7f5ad15.png" width="1014" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;7.3 完成授權&lt;/p&gt; 
&lt;p&gt;系統會自動跳轉到 Claude 的授權頁面：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//42412dbf53a0720b37415f800b07db01.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f411778e7e2f7ef89fbf4eb48b6948ab.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1174" src="https://oscimg.oschina.net/oscnet/up-278b2a400206f40090e86c879ae58651049.png" width="1021" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;點擊"授權"按鈕，您將獲得授權 token。請複製此 token，然後返回到代理服務的配置頁面：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//36536d7b7811675bf9881251b9509f51.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//06a160ebaded9f945a80dcf372c5b2a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1252" src="https://oscimg.oschina.net/oscnet/up-b25aa2f8a7bf4043be4aa0112e1f815e284.png" width="1367" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;7.4 完成賬號配置&lt;/p&gt; 
&lt;p&gt;將複製的 token 粘貼到輸入框中，然後點擊"完成授權"：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//40223676d363f7a8b3f723f4df984a71.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6d6d13ff4753daccbac548569f9e4564.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1075" src="https://oscimg.oschina.net/oscnet/up-078389dae193d0e1b40fcca2febd9459209.png" width="1031" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;7.5 管理多賬號切換&lt;/p&gt; 
&lt;p&gt;創建完成後，在賬戶管理列表中將顯示新添加的 Claude 賬號。如果您需要切換到 Claude Pro 賬號：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;先禁用火山引擎賬號&lt;/li&gt; 
 &lt;li&gt;在 API Key 管理中刪除默認模型設置&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f56754d0f464e49a582cacd3497d4398.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c4bc9aefb7c70de5801ca88afa27841f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1187" src="https://oscimg.oschina.net/oscnet/up-03b62645366e8781ae9ba4c31771481d154.png" width="1360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;7.6 測試 Claude Pro 賬號&lt;/p&gt; 
&lt;p&gt;配置完成後，您可以測試 Claude Pro 賬號的連接狀態：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//4ff8c391276f5a7c120b4c524fc08b78.png" referrerpolicy="no-referrer"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//99d1cd54b9922e6d15ba7d4c8639466b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1084" src="https://oscimg.oschina.net/oscnet/up-b58aca30235bbd5e1bb64ec2fe408dc30a8.png" width="1222" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;功能特性&lt;/h2&gt; 
&lt;p&gt;通過 Claude Code Proxy，您可以：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;統一管理 Claude Pro 賬號和其他 AI 模型提供商&lt;/li&gt; 
 &lt;li&gt;支持任何兼容 OpenAI 協議的模型提供商&lt;/li&gt; 
 &lt;li&gt;實現多賬號間的無縫切換&lt;/li&gt; 
 &lt;li&gt;提供統一的 API 接口，簡化集成流程&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;總結&lt;/h2&gt; 
&lt;p&gt;本教程詳細介紹瞭如何將 Claude Code 與火山引擎 API 進行集成，並可選擇性地接入 Claude Pro 賬號。通過 Claude Code Proxy，您可以：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;靈活切換模型：在不同的 AI 模型提供商之間無縫切換&lt;/li&gt; 
 &lt;li&gt;統一管理：通過 Web 界面統一管理所有 AI 賬號和 API 密鑰&lt;/li&gt; 
 &lt;li&gt;擴展性強：支持任何兼容 OpenAI 協議的模型提供商&lt;/li&gt; 
 &lt;li&gt;易於部署：支持 Windows 服務形式的常駐運行&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;相關資源&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAIDotNet%2FClaudeCodeProxy" target="_blank"&gt;Claude Code Proxy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;項目文檔：詳細的 API 文檔和配置説明&lt;/li&gt; 
 &lt;li&gt;社區支持：GitHub Issues 和討論區&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363976</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363976</guid>
      <pubDate>Sat, 02 Aug 2025 15:03:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Rust 跨平台開發框架 Tauri 開啓 2025 董事會選舉</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 是一個桌面 UI 框架，可讓開發者使用每個平台的 Webview 技術棧為所有主要桌面操作系統構建應用程序，目前支持 Windows/macOS/Linux 等平台。開發者通過 Tauri 幾乎可以使用任何編譯為 HTML、JS 和 CSS 的前端框架來構建桌面 UI。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 核心庫採用 Rust 編寫，使用 Tauri 開發的應用程序的後端是一個基於 Rust 的二進制文件，帶有一個前端可以與之交互的 API，通過 JS Api 調用後台接口。&lt;/p&gt; 
&lt;p&gt;日期，Tauri 社區正在進行 2025 董事會選舉。根據 Tauri 的治理結構，董事會（Board of Directors）為核心決策機構，負責項目的整體健康與穩定。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;董事會選舉安排&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;本次選舉將有 5 個席位開放&lt;/strong&gt;，董事任期為兩年，董事會規定最少 3 人，最多 7 人。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;選舉採用&lt;strong&gt;兩年輪換制&lt;/strong&gt;：每年選舉部分席位，兩年內覆蓋全部席位，確保連續性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;申請流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;有意者應按以下三個步驟申請成為候選人：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;閲讀 Tauri Governance 頁面中董事角色職責；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;準備一份介紹材料，包括個人背景、與 Tauri 的關聯，以及能為董事會貢獻的方面；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;在 2025 年 7 月 7 日前提交申請&lt;/strong&gt;，可通過電子郵件發送至 board@tauri.app，或在 Discord 上聯繫 &lt;code&gt;@board&lt;/code&gt; 角色。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftauri.app%2Fblog%2Ftauri-board-elections-2025%2F" target="_blank"&gt;https://tauri.app/blog/tauri-board-elections-2025/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363686/tauri-board-elections-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363686/tauri-board-elections-2025</guid>
      <pubDate>Fri, 01 Aug 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>上半年我國軟件業務收入 70585 億元</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;工業和信息化部運行監測協調局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_68003fdb41984bcab3f1234f8c8eb449.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;2025 年上半年，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢良好，軟件業務收入穩健增長，利潤總額保持兩位數增長，軟件業務出口保持正增長。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件業務收入穩健增長。上半年，我國軟件業務收入 70585 億元，同比增長 11.9%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;利潤總額增速保持兩位數增長。上半年，軟件業利潤總額 8581 億元，同比增長 12.0%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件業務出口保持正增長。上半年，軟件業務出口 283 億美元，同比增長 5.3%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;二、分領域運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;軟件產品收入平穩增長。上半年，軟件產品收入 15441 億元，同比增長 10.6%，佔全行業收入比重為 21.9%。其中，基礎軟件產品收入 903 億元，同比增長 13.8%；工業軟件產品收入 1445 億元，同比增長 8.8%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息技術服務收入保持兩位數增長。上半年，信息技術服務收入 48362 億元，同比增長 12.9%，佔全行業收入的 68.5%。其中，雲計算、大數據服務共實現收入 7434 億元，同比增長 12.1%，佔信息技術服務收入的 15.4%；集成電路設計收入 2022 億元，同比增長 18.8%；電子商務平台技術服務收入 5882 億元，同比增長 10.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息安全收入穩定增長。上半年，信息安全產品和服務收入 1052 億元，同比增長 8.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;嵌入式系統軟件收入穩定增長。上半年，嵌入式系統軟件收入 5730 億元，同比增長 8.5%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;三、分地區運行情況&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;上半年，東部地區、中部地區、西部地區和東北地區件業務收入分別同比增長 12.1%、12.5%、10.4% 和 9.2%。東部地區佔全國軟件業務總收入的 84.3%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;京津冀地區軟件業務收入同比增長 12.5%，長三角地區軟件業務收入同比增長 13.7%。北京、廣東、江蘇、山東、上海軟件業務收入居全國前 5，同比分別增長 12.6%、9.0%、14.4%、12.9% 和 18.0%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363681</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363681</guid>
      <pubDate>Fri, 01 Aug 2025 10:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>agentUniverse 多智能體框架實現專家級金融分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt;
  7 月 26 日，【Al Agent：從工具助手到自主行動】OSC 源創會·杭州站·115 期活動成功舉辦，螞蟻集團智能投研架構師趙澤偉帶來了題為《agentUniverse 多智能體框架實現專家級金融分析》的精彩演講，深入闡述瞭如何利用多智能體技術突破金融智能化的關鍵瓶頸。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  趙澤偉展示了 agentUniverse 在金融投研核心場景的成功實踐： 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    語控金融分析： 首創「白盒化」分析過程，確保每一步思路、數據來源清晰可見、可追溯，嚴格滿足金融嚴謹性要求。支持靈活定製和修改分析流程，貼合不同金融專家的思維模式。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    報告解讀/市場分析/政策解讀/宏觀分析： 構建專業化智能體矩陣，實現 7×24 小時全市場動態感知與投資機會挖掘。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化因子復現與計算： 攻克「精準可控代碼生成」難題。通過「量化專家知識框架注入」、「多模態信息抽取（財報提取、校驗）」、「代碼質檢與自迭代」等 Micro Agent 協作，平衡大模型創造力與金融計算所需的絕對精確性，確保結果基於真實金融數據與框架。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化研報方法論復現： 同樣應用專家框架注入與精準代碼生成能力，擅長處理長文本拆解，保障量化研究的嚴謹復現。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    研報生成： 將 AI 分析能力無縫輸出至支付寶理財等豐富業務場景。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
  基於這些實踐，趙澤偉解釋，agentUniverse 的核心創新在於兩大關鍵技術：一是 PEER 仿金融專家協同推理，可以模擬人類金融專家團隊的分工協作模式。不同智能體扮演專業角色（如分析師、計算校驗員），通過高效協同提升整體分析的專業深度和可靠性，實現「分工帶來專業」。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="734" src="https://oscimg.oschina.net/oscnet/up-5c9968e8248cd054725f87f10cc0546b22e.png" width="1408" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  二是 DITR 動態工具插值推理技術： 讓智能體「通過實踐檢驗推理」。智能體能在推理過程中動態調用並整合多樣化專業工具（如數據查詢、計算引擎、校驗模塊），實時驗證分析步驟與結果，極大增強了複雜金融邏輯處理的可信度。豐富的工具生態也使其能快速適應不同分析場景需求。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="596" src="https://oscimg.oschina.net/oscnet/up-0de916b64349622118b22423e076ef33106.png" width="1392" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  具體組件方面，agentUniverse 多智能體框架集成經產業驗證的 
 &lt;code&gt;agentUniverse.RaG&lt;/code&gt;檢索增強能力，確保信息準確； 
 &lt;code&gt;agentUniverse.Mem&lt;/code&gt;提供強大的多輪會話與記憶管理。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  此外，agentUniverse 還具備一些企業級特性，包括效果可觀測與可反饋：，全鏈路記錄服務、模型交互，支持效果評測與迭代優化；一鍵服務化，便捷啓動 WebServer，輕鬆集成至現有業務系統；標準容器交付，提供標準 Docker 鏡像，支持 K8S 等雲原生部署；私有化擴展：，提供開放框架，支持企業無縫接入自研 RPC、消息、日誌等私有組件。 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;div&gt;
   下期活動預告： 
 &lt;/div&gt; 
 &lt;div&gt;
   【AIoT 共振場：重構萬物智聯新圖層】 OSC 源創會·深圳站·116 期 
 &lt;/div&gt; 
 &lt;div&gt;
   查看詳情： https://www.oschina.net/event/8598019 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18686762</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18686762</guid>
      <pubDate>Fri, 01 Aug 2025 09:58:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Black Forest Labs 聯手 Krea 開源 FLUX.1-Krea 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Black Forest Labs 與 AI 初創公司 Krea 攜手推出開源圖像生成模型 FLUX.1-Krea [dev]，該模型專注於解決當前 AI 生成圖像中普遍存在的"人工痕跡"問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev] 的核心設計理念是擺脫傳統 AI 生成圖像的"塑料感"和過度處理效果。許多現有的 AI 圖像生成模型往往會產生過曝高光、不自然的色彩飽和度以及明顯的人工痕跡，這些特徵讓觀眾一眼就能識別出是 AI 生成的作品。新模型通過算法優化和訓練策略改進，着重呈現更加自然的光影效果和細節表現，讓生成的圖像更接近真實攝影作品的質感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-a8ccb9505eaffaaf11ac52a3315330cbaa7.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在技術架構方面，FLUX.1-Krea [dev]基於 Black Forest Labs 提供的 flux-dev-raw 基礎模型構建。這是一個經過預訓練並指導優化的 12B 參數擴散變換模型，為新模型的高質量輸出奠定了堅實基礎。Krea 團隊在此基礎上進行了深度定製化開發，通過監督微調和人類反饋強化學習兩個關鍵階段，精心策劃了高質量的圖像數據集用於模型訓練。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;人類反饋強化學習的引入是該模型的重要技術亮點。這種訓練方法讓 AI 模型能夠更好地理解和符合人類的審美標準，而不是僅僅依靠技術指標進行優化。通過大量人工標註和反饋數據，模型學會了區分什麼樣的圖像效果更符合人類的視覺偏好，從而在生成過程中自動避免那些看起來"不自然"的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev]的另一個重要優勢是其與現有 FLUX 開源生態系統的完全兼容性。這意味着已經基於 FLUX 模型開發應用或工具的開發者可以無縫遷移到新模型，無需重新構建整個技術棧。這種兼容性設計大大降低了新技術的採用成本，有利於推動整個開源社區的技術升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Krea 表示，FLUX.1-Krea [dev]的開發不僅僅是技術層面的改進，更是對用戶創作體驗的全面優化。通過減少"AI 味"的視覺特徵，用戶可以創作出更具專業水準的視覺內容，無論是用於商業設計還是個人創作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363668</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363668</guid>
      <pubDate>Fri, 01 Aug 2025 09:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
