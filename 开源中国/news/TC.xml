<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Fri, 07 Mar 2025 02:52:09 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>華為新筆記本被曝預裝 Linux 系統</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，博主 @看山的叔叔發佈動態，爆料稱即將有五款筆記本新品問世。綜合該博主以往爆料信息及圖片中呈現的型號推測，此次爆料指向的大概率是華為筆記本。&lt;/p&gt; 
&lt;p&gt;據悉，這五款筆記本分別為 MateBook D14、MateBook D16、MateBook 14、MateBook GT 14 以及 MateBook X Pro，而這五款產品搭載的操作系統都是 Linux。&lt;/p&gt; 
&lt;p&gt;值得關注的是，這些筆記本或許並非嚴格意義上的全新產品。儘管已至 2025 年，但從圖片信息來看，其仍將沿用 2024 命名。&lt;/p&gt; 
&lt;p&gt;這名博主還表示，&lt;strong&gt;如果用戶有需要，華為店面可以幫助客戶安裝 Windows 系統，但只能是未激活版，需要用戶自己想辦法&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0307/103854_mi9H_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;早在去年 9 月，餘承東就公開承認，Windows PC 可能要停止供貨，以後就要用鴻蒙 PC 版了。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e9a3ffce642d457ff9d025ecacb32ccae06.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/256753&quot; target=&quot;news&quot;&gt;「鴻蒙之父」王成錄：明年推出鴻蒙 PC 版系統&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337412</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337412</guid>
            <pubDate>Fri, 07 Mar 2025 02:42:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>因遷移雲供應商，FreeDesktop.org 自建的 GitLab 服務將停機一週</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;FreeDesktop.org 近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.freedesktop.org%2Ffreedesktop%2Ffreedesktop%2F-%2Fissues%2F2076&quot; target=&quot;_blank&quot;&gt;發佈公告&lt;/a&gt;，稱其自建的 GitLab 服務將在本月底因遷移雲供應商而關閉，持續時間可能長達一週。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0307/102742_EzWU_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;FreeDesktop.org 稱其 GitLab 實例在 Mesa 圖形驅動程序、Wayland 以及許多其他 Linux 桌面項目開發中至關重要。&lt;/p&gt; 
&lt;p&gt;由於 GitLab 實例的停機，Mesa 和其他依賴 GitLab 處理 PR、持續集成、錯誤報告，以及其他服務的 FreeDesktop.org 項目將暫停開發數日。計劃遷移的起始日期為 3 月 16 日，預計將持續一週。&lt;/p&gt; 
&lt;p&gt;今年一月份，X.Org / FreeDesktop.org 遭遇了新的「雲危機」——他們將在 4 月底失去 Equinix Metal 基礎設施。這一基礎設施曾由 Equinix 慷慨贊助，但現在即將消失，迫使 FreeDesktop.org 管理員迅速找到新的託管解決方案。&lt;/p&gt; 
&lt;p&gt;FreeDesktop.org 管理員已決定採用 Hetzner 服務器和 Fastly 作為 CDN。他們目前正在整理遷移計劃，將所有數據從 Equinix Metal 遷移到德國主機 Hetzner。&lt;/p&gt; 
&lt;p&gt;當他們關閉 Equinix 託管的 GitLab 實例，備份所有數據，然後進行遷移時，將會開始停機。他們估計這個過程將從 3 月 16 日開始，持續一週左右，在此期間，這些項目的開發將實際上陷入停滯。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.freedesktop.org%2Ffreedesktop%2Ffreedesktop%2F-%2Fissues%2F2076&quot; target=&quot;_blank&quot;&gt;點此查看詳細信息&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337407/freedesktop-down-1-week-soon</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337407/freedesktop-down-1-week-soon</guid>
            <pubDate>Fri, 07 Mar 2025 02:31:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Protocol Buffers v30.0 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Protocol Buffers 30.0 已經發布。Protocol Buffers（protobuf）是&amp;nbsp;Google 開源的語言無關、平台無關的可擴展機制，用於序列化結構化數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;具體更新內容包括：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;Announcements&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;此版本包括對以下內容的破壞性變更：Objective-C、Python、C++。&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[Objective-C] 刪除舊版 WKT headers。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd9caebc313256ea2f5c6922113c1f3edf14b24ad&quot; target=&quot;_blank&quot;&gt;d9caebc&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 刪除已棄用的 API。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F2a52b900a1b71d57fc68624a989145f57abefdf1&quot; target=&quot;_blank&quot;&gt;2a52b90&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 刪除對舊生成代碼的支持。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fcffa5902606ee3ebf23214b80251722b3654d5be&quot; target=&quot;_blank&quot;&gt;cffa590&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 刪除 GPBUnknownFieldSet。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F2b93422f7eea500b26d1a9aaf7d07b3120f83d39&quot; target=&quot;_blank&quot;&gt;2b93422&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 修復版本下的封閉枚舉驗證（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F72b3eda2ec385863d7416f067f6cd0cefeed72bb&quot; target=&quot;_blank&quot;&gt;72b3eda&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 從 protobuf python cpp 擴展中刪除已棄用的 GetDebugString()。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F721a45265b4e1d0f18d6775a0f1bafffdfc3088e&quot; target=&quot;_blank&quot;&gt;721a452&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 刪除已棄用的反射方法 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F292f9646797d9e23fc66ba70fbda5903f2301ff0&quot; target=&quot;_blank&quot;&gt;292f964&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] 刪除已棄用的 GetPrototype MessageFactory.GetPrototype()，(&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fc261b49a9575226efc9e5d269f6e5319a05d526e&quot; target=&quot;_blank&quot;&gt;c261b49&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] Python 嵌套消息類&amp;nbsp;&lt;strong&gt;qualname&amp;nbsp;&lt;/strong&gt;現在包含外部消息名稱。（以前的&amp;nbsp;&lt;strong&gt;qualname 與嵌套消息的&lt;/strong&gt;&lt;strong&gt;名稱&lt;/strong&gt;具有相同的結果，但不包括外部消息名稱）（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F0720536eca20ca2f801127869d7f1211bceb3865&quot; target=&quot;_blank&quot;&gt;0720536&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 刪除已棄用的 Python RPC Service Interfaces&amp;nbsp;(&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F5ba74b11e8d2bd5e9b22e972beb572668bf6191c&quot; target=&quot;_blank&quot;&gt;5ba74b1&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] map field 的 Python setdefault 行為變更。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F81da6b999a8229942436f6c203a20633c65ebd26&quot; target=&quot;_blank&quot;&gt;81da6b9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 刪除已棄用的 py_proto_library 宏。&lt;/li&gt; 
   &lt;li&gt;[C++] 禁止使用 Bazel+MSVC 構建 protobuf (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F117e7bbe74ac7c7faa9b6f44c1b22de366302854&quot; target=&quot;_blank&quot;&gt;117e7bb&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[C++] 刪除已棄用的 Arena::CreateMessage。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd83a5365d16cff4be7da7d9a34eef14b24cc8733&quot; target=&quot;_blank&quot;&gt;d83a536&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 刪除 CMake 子模塊支持，轉而支持獲取或安裝的依賴項。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F3f06ca4306a682e6ee631d8ea94b82baaafb14f0&quot; target=&quot;_blank&quot;&gt;3f06ca4&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 翻轉處理 cmake 依賴項的默認行為。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F9cc685edf867acf5024a94502a3cbd7afa7a3daa&quot; target=&quot;_blank&quot;&gt;9cc685e&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 清除 arena 上的 oneof 消息後添加 ASAN poisoning。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F54d068e11c77ed387b97a60f435998b384e36e34&quot; target=&quot;_blank&quot;&gt;54d068e&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 將&lt;code&gt;type_name()&lt;/code&gt;和&lt;code&gt;cpp_type_name()&lt;/code&gt;的返回類型從&lt;code&gt;const char*&lt;/code&gt;升級為&lt;code&gt;absl::string_view&lt;/code&gt;。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fa9ad51f5b6a19eacc934bcb51db6282ec1fabb8c&quot; target=&quot;_blank&quot;&gt;a9ad51f&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 刪除已棄用的 RepeatedPtrField::ClearedCount()。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fe8e3253f63f52d314af0e317d09642b9ceb1b40e&quot; target=&quot;_blank&quot;&gt;e8e3253&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 將若干字符串返回函數的返回類型升級為&lt;code&gt;absl::string_view&lt;/code&gt;。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd1990d968a54176eb9f4229abe7f7c97ece50cec&quot; target=&quot;_blank&quot;&gt;d1990d9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 從 C++ 中的選項中刪除 ctype（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Faebf8b9459f1da347a353c2fbbfe76230a457209&quot; target=&quot;_blank&quot;&gt;aebf8b9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 在反射中刪除&lt;code&gt;MutableRepeatedFieldRef::Reserve()&lt;/code&gt;（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F913f7b0c6d3c3e9876aea913b0d83bbd7fffe22c&quot; target=&quot;_blank&quot;&gt;913f7b0&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 刪除已棄用的 JsonOptions 別名。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fe2eb0a19aa95497c8979d71031edbbab721f5f0a&quot; target=&quot;_blank&quot;&gt;e2eb0a1&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 刪除已棄用的 Arena::GetArena。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F30ed452eddacace2c3270dce9645b8f1f453ae4b&quot; target=&quot;_blank&quot;&gt;30ed452&lt;/a&gt;）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotobuf.dev%2Fnews%2F&quot; target=&quot;_blank&quot;&gt;Protobuf News&lt;/a&gt;&amp;nbsp;可能包括即將發生的變化的額外公告或預告。&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotobuf.dev%2Fsupport%2Fmigration%2F&quot; target=&quot;_blank&quot;&gt;遷移指南&lt;/a&gt;將包括針對破壞性變更的遷移指南（即將更新）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情可查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Freleases%2Ftag%2Fv30.0&quot; target=&quot;_blank&quot;&gt;https://github.com/protocolbuffers/protobuf/releases/tag/v30.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337406/protobuf-30-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337406/protobuf-30-0-released</guid>
            <pubDate>Fri, 07 Mar 2025 02:27:24 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源中國 2025 年戰略部署會全揭密：AI 工具、AI 教育、AI 應用市場三箭齊發</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p&gt;開源中國（OSCHINA）於近日圓滿召開 2025 年戰略部署會，正式公佈未來核心增長路徑——以&lt;strong&gt;模力方舟&lt;/strong&gt;為 AI 技術基座，通過 &lt;strong&gt;AI 工具、AI 教育與 AI 應用市場&lt;/strong&gt;三大業務矩陣協同發力，構建從底層能力支撐到場景化落地的全棧生態體系。&lt;/p&gt; 
 &lt;p&gt;作為戰略核心的 Gitee AI 模力方舟，定位為 AI 模型即服務（MaaS）平台，為三大業務線提供通用 AI 能力支持。在此基座上：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 工具&lt;/strong&gt;板塊以 Gitee SaaS 與私有化部署為雙引擎，將軟件工程全面升級為 AI 增強（AI Enhance）開發範式，實現項目管理、代碼生成、智能測試、自動化運維的全鏈路提效；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 教育&lt;/strong&gt;依託 OSCHINA 社區、Gitee 平台與教育培訓體系的深度融合，從 K12 少年培養到企業數字化人才賦能，貫穿技術普及、實踐訓練與認證輸出的全生命週期；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 應用市場&lt;/strong&gt;聚焦打通 AI 技術到產業場景的「最後一公里」，通過匯聚開發者生態與企業需求，構建 AI 應用的部署與交易平台。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;這一戰略架構以技術普惠為核心邏輯，模力方舟作為底層能力基座，通過標準化 AI 模型接口與開發工具鏈，降低技術應用門檻；AI 教育從內容生態、人才儲備到技術認證，為行業輸送適配 AI 時代的技術人才；AI 工具與 AI 應用市場則分別從生產力工具革新和場景化解決方案落地兩端，形成「能力輸出-需求匹配-價值閉環」的商業化鏈路。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;285&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100817_Vwaz_3820517.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 工具：重構&lt;/strong&gt;&lt;strong&gt;軟件工程&lt;/strong&gt;&lt;strong&gt;範式&lt;/strong&gt;&lt;strong&gt;，以 AI 增強驅動生產力革命&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;開源中國於 2013 年發佈代碼託管平台 Gitee，並於 2020 年開始牽頭建設工信部國家開源託管平台項目。Gitee 於 2017 年上線發佈針對企業級的研發效能平台 Gitee 企業版。截至目前，Gitee 已經服務 1350 萬開發者用戶、36 萬家企業以及 2000 多家高等院校。&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;708&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100909_aJKN_3820517.png&quot; width=&quot;1644&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;2020 年以來，開源中國深耕 DevOps 全生命週期國產替代方案，在滿足開發者需求的同時，打造出一個自主創新、安全可信的本土開源軟件工具與生態，減少開發者對海外開源軟件的過度依賴，構建安全可控的中國信息化體系。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;862&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100934_EMQA_3820517.png&quot; width=&quot;1516&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;text-align:left&quot;&gt;在開源中國的戰略藍圖中，Gitee 正從研發效能平台全面進化為「&lt;strong&gt;AI 增強型智能開發中樞&lt;/strong&gt;」。依託模力方舟的模型能力，平台深度整合 AI 技術至項目管理、代碼開發、測試運維、流水線、效能洞察、文檔管理、代碼安全等全鏈路工具鏈，覆蓋從需求設計到集成交付的完整生命週期。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;Gitee 以 AI Enhance 為核心，完成&lt;strong&gt;從研發效能平台到智能開發中樞的進化&lt;/strong&gt;。這一轉型不僅解決了企業「降本增效」的迫切需求，更開啓了「人機協同」的研發新範式——當 AI 深度融入每一行代碼、每一次交付，技術普惠的願景正在成為企業競爭力的基石。&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;AI 教育：從內容社區到人才生態的閉環佈局，培養未來數字化創新力量&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;在開源中國的戰略版圖中，AI 教育不僅是技術普及的入口，更是撬動未來產業變革的支點。依託&lt;strong&gt;模力方舟 AI 技術基座、Gitee 工程實操基座與 OSCHINA 社區的生態勢能&lt;/strong&gt;，開源中國正以&lt;strong&gt;「全週期、場景化、智能化」&lt;/strong&gt;為核心邏輯，通過&lt;strong&gt;「社區+平台+培訓」&lt;/strong&gt;三位一體的協同模式，打造一站式全生命週期開源人才培養解決方案，重塑開源教育範式，構建從青少年啓蒙到企業級賦能的終身教育閉環。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;868&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101004_g3Uf_3820517.png&quot; width=&quot;1638&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;技術普惠：以社區+AI 平台構建學練用閉環，通過標準化工具降低學習門檻，實現人才供需精準對接。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;青少年啓蒙：AI 驅動趣味化教學，結合開源項目實踐，建立編程思維與開源意識雙培養體系。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;高校賦能：「開源+AI」雙引擎革新工程教育，AI 開發工具+國際認證體系推動產教深度協同。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;企業實戰：AI 代碼助手與模擬沙盤雙輪驅動，打造人才能力升級系統，加速數字化轉型進程。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;&lt;strong&gt;AI 應用市場：打通應用落地最後一公里，賦能百萬 AI 開發者服務十億用戶&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;Gitee AI 模力方舟將打造從模型開發到商業變現的一站式 AI 應用市場。平台通過&lt;strong&gt;技術基座、服務能力、開放生態&lt;/strong&gt;三大支柱，系統性解決 AI 應用落地難、成本高、場景碎片化的行業痛點，賦能百萬開發者與企業無縫連接十億終端用戶。&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;1000&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101027_Vnm9_3820517.png&quot; width=&quot;1674&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;模力方舟以全棧技術能力降低 AI 應用門檻，構建三大核心體系：技術基座通過多模態模型庫、國產化算力優化和智能調度實現「模型即服務」，配合低代碼工具鏈加速開發；服務體系覆蓋全鏈路商業化支持，提供安全合規的存儲認證系統與企業級私有部署方案；開放生態通過 AI 審核分級、開發者收益傾斜和算力補貼機制，形成&quot;開發-反饋-迭代&quot;的創新閉環，推動金融、工業等垂直領域快速落地。平台以技術普惠和生態共贏為核心，實現從模型訓練到商業轉化的全流程賦能。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;img height=&quot;758&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101048_VScr_3820517.png&quot; width=&quot;1622&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;開源中國通過模力方舟 AI 應用市場，正在編織一張連接技術、產業與人的價值網絡：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;對開發者&lt;/strong&gt;：這裏是「零門檻創業平台」，100 萬創新者將在此釋放創造力；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;對企業&lt;/strong&gt;：這裏是「數字化轉型加速器」，30+ 行業的效率革命由此啓動；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;對用戶&lt;/strong&gt;：這裏是「智能生活入口」，10 億人將因 AI 享受到更便捷、更安全的服務。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;&lt;strong&gt;戰略躍遷：從社區平台到 AI 驅動型技術服務商&lt;/strong&gt;&lt;/h2&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;912&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101112_REsn_3820517.png&quot; width=&quot;1630&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;回望昨日，開源中國經歷了從開源社區到代碼託管平台，再到 DevOps 研發效能平台的演進，完成了從流量聚合到商業化閉環的蛻變。這一歷程中，不僅為中國開源生態注入了活力，更推動了企業研發效能的規模化提升，驗證了開源技術商業化的可行路徑。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;而此次戰略升級，標誌着&lt;strong&gt;開源中國正式邁向「AI 驅動型技術服務商」的新階段&lt;/strong&gt;：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;縱向貫通&lt;/strong&gt;：以教育培育生態、以工具提升效率、以市場兌現價值，形成從人才儲備到技術落地的完整閉環。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;橫向聯動&lt;/strong&gt;：三大業務線數據互通、資源協同——社區教育為工具平台輸送人才，AI 市場反哺開發者生態，工具迭代驅動教育內容升級，構建自循環的增長飛輪。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;社會價值&lt;/strong&gt;：通過降低 AI 使用門檻，助力中小企業與製造業、金融等傳統行業實現智能化轉型；以國產信創技術築牢安全底座，推動自主可控的 AI 基礎設施在政務、金融等關鍵領域落地，保障國家信息安全與產業鏈韌性，踐行「技術普惠」初心的同時，扛起守護數字主權的時代責任。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;從推動每一行代碼的創造力，到賦能千行百業的數字化轉型，&lt;strong&gt;開源中國正以 AI 為槓桿，撬動技術商業化與產業智能化的雙重革命&lt;/strong&gt;。這一進程，正在悄然重塑中國技術生態的未來圖景。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337400/oschina-ai-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337400/oschina-ai-2025</guid>
            <pubDate>Fri, 07 Mar 2025 02:12:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>深圳擬設 500 億元國資基金，聚焦人工智能、機器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;深圳國資官微發文稱，截至 2024 年底，深圳國資打造了包括種子基金、天使基金、創投基金、產業基金、併購基金、母基金、S 基金、人才基金等在內的國資基金羣，各類基金超過 500 支，基金總規模超 7000 億元，投向戰略性新興產業和未來產業的資金規模超 90%，為培育發展新質生產力、實現高水平科技自立自強、塑造發展新動能新優勢提供了有力支撐。&lt;/p&gt; 
&lt;p&gt;接下來，深圳國資國企接下來將聚焦「20+8」全產業鏈，打造全產業領域的科技創新基金網絡，推動基金投向覆蓋種子、天使、A 輪、B 輪、C 輪直至 IPO 的投資全生命週期，確保其中 A 輪及更早期的項目不低於 40%，投向 B 輪、C 輪項目均不低於 20%。&lt;/p&gt; 
&lt;p&gt;走訪包括人工智能領域在內的初創企業覆蓋不少於 10000 家，推進至立項盡調階段企業不少於 1000 家，為戰略性新興產業及未來產業領域的科創企業提供不少於 100 億元的創投資金支持。&lt;/p&gt; 
&lt;p&gt;聚焦人工智能、機器人等尖端科技領域，籌設規模不少於 500 億元的涵蓋科創企業全生命週期的國資基金。延長創新創業類基金存續期限最長至 15 年，針對不同基金，確定差異化考覈指標、免責清單，不以單一項目虧損、單一時間節點為考覈負面評價依據，按整個基金生命週期進行考覈，助力投資機構更有底氣、更加大膽地進行長期投資。更好發揮國有企業參與的各類投資基金作用，積極引進對接世界一流投資投行機構來深圳一起攜手發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337399</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337399</guid>
            <pubDate>Fri, 07 Mar 2025 02:08:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌確認將在 6 月發佈 Android 16</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.androidpolice.com%2Fandroid-16-is-on-track-for-june%2F&quot; target=&quot;_blank&quot;&gt;據 Android Police 報道&lt;/a&gt;&lt;/u&gt;，在 MWC 2025 上，Google 確認了將於 6 月發佈 Android 16 系統。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9b1b5f00ad73dac3341f293894653de0f1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Google 安卓生態系統總裁 Sameer Samat 在 MWC 2025 上透露，團隊目前正全力以赴，目標計劃在 6 月發佈 Android 16 系統。&lt;/p&gt; 
&lt;p&gt;據悉，安卓 16 目前處於第 2 個測試版階段。Samat 表示谷歌目前採用 Trunk Stable 開發模式，目的是縮短 Bug 修復週期，並加快新版本的發佈，從而更快、更穩定地為用戶提供系統支持。&lt;/p&gt; 
&lt;p&gt;Samat 強調，全球用戶對安卓系統的功能和更新頻率提出了較高要求。因此 Google 通過模塊化和組件化改造安卓系統，讓部分功能可以獨立更新，從而無需等待操作系統版本發佈。這一優化不僅提升了用戶體驗，也為開發者提供了更大的靈活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337398/android-16-is-on-track-for-june</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337398/android-16-is-on-track-for-june</guid>
            <pubDate>Fri, 07 Mar 2025 02:06:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里通義千問大模型登頂全球開源社區榜首</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 6 日，全球最大的 AI 開源社區 HuggingFace 更新了大模型榜單，近期剛&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/337189&quot;&gt;發佈並開源&lt;/a&gt;&lt;/u&gt;的阿里通義千問推理模型 QwQ-32B 成功登頂。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1856&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/095913_fror_2720166.png&quot; width=&quot;3360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，目前 QwQ-32B 居於榜單第一，超越微軟的 Phi-4、DeepSeek-R1 等模型。&lt;/p&gt; 
&lt;p&gt;據瞭解，QwQ-32B 在數學、代碼及通用能力上實現質的飛躍，用更小參數實現整體性能比肩 DeepSeek-R1，並突破性地讓高性能推理模型在消費級顯卡上實現本地部署，大幅降低了模型應用成本。&lt;/p&gt; 
&lt;p&gt;在一系列權威基準測試中，QwQ-32B 模型表現異常出色，幾乎完全超越了 OpenAI-o1-mini，比肩最強開源推理模型 DeepSeek-R1。其中，在測試數學能力的 AIME24 評測集上，以及評估代碼能力的 LiveCodeBench 中，QwQ-32B 表現與 DeepSeek-R1 相當，遠勝於 o1-mini 及相同尺寸的 R1 蒸餾模型。&lt;/p&gt; 
&lt;p&gt;目前，QwQ-32B 已在魔搭社區、HuggingFace 及 GitHub 等平台基於寬鬆的 Apache2.0 協議開源，所有人都可免費下載模型進行本地部署，或者通過阿里雲百鍊平台直接調用模型 API 服務。同時，用戶也將可通過通義 App 免費體驗最新的 QwQ-32B 模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337397</guid>
            <pubDate>Fri, 07 Mar 2025 02:02:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>全球生成式 AI 應用 TOP 100 榜單公佈：ChatGPT 第一、DeepSeek 第二</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日凌晨，全球著名風投機構 Andreessen Horowitz（簡稱 a16z）發佈了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fa16z.com%2F100-gen-ai-apps-4%2F&quot; target=&quot;_blank&quot;&gt; 2025 年全球生成式 AI 應用前 100 排行榜&lt;/a&gt;&lt;/u&gt;，具體榜單共分為前 50 生成式 AI 應用（網頁端）和前 50 生成式 AI（移動端）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d73d8d52a68d2960c0ac00889b11ac8fcd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-01d42658a902ad470941487df69be866195.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中，&lt;strong&gt;DeepSeek 在網頁端中排名第二&lt;/strong&gt;，其憑藉 1 月開源自家 DeepSeek-R1 模型，在全球引起巨大熱議，僅用 20 天便達成一千萬用戶的突破，比排名第一的 ChatGPT 快了近一倍（ChatGPT 打破一千萬用戶耗時 40 天）；而 ChatGPT 憑藉 4 億的周活躍用戶和 1.75 億的移動端用戶，在網頁端、移動端排名雙第一。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4466873abf7caaeeb5f4830cc940aa317a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1e35e6512d78eb66212ae92f3de8bf40669.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，中國其他知名大模型也進入了該排行榜：字節跳動的豆包排名第 10；月之暗面排名 11；海螺視頻排名 12；快手可靈排名 20，全部超過了 Sora、Midjourney、Runway 等知名產品。在移動端中，百度 AI 搜索排名第 4；夸克 AI 第 6；豆包排名第 7；DeepSeek 排名第 14。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337396/a16z-100-gen-ai-apps-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337396/a16z-100-gen-ai-apps-2025</guid>
            <pubDate>Fri, 07 Mar 2025 01:51:38 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源中國馬越：DeepSeek 不是國運級的創新，年輕人才是</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;「你很難要求大家還沒吃飽喝足的情況下，去做開源。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果説關於 DeepSeek 的討論已經過於氾濫，開源也許是當下依然值得討論的主題。&lt;/p&gt; 
&lt;p&gt;長期以來，在國內談起「開源」，都會無可避免地陷入一種尷尬的語境。&lt;/p&gt; 
&lt;p&gt;它當然是理想主義的。「開源」背後的自由、開放特性，被普遍認為是互聯網精神的外化——源代碼向公眾開放共享，且允許在遵循特定許可證條款的前提下，對軟件進行自由使用、修改和二次分發。&lt;/p&gt; 
&lt;p&gt;最知名的開源項目「Linux」是操作系統的內核，催生了數以千萬計的開源軟件，這是互聯網世界的根基。&lt;/p&gt; 
&lt;p&gt;但它的背後經常跟着一個問題：為什麼要開源？怎麼考慮開源之後的商業化？哪怕到 DeepSeek 爆火的現在，也很難有人給出完美的答案。&lt;/p&gt; 
&lt;p&gt;開源中國董事長馬越，是最有立場談國內開源歷史的人之一，他在這條路上走了 18 年。&lt;/p&gt; 
&lt;p&gt;2008 年，馬越從硅谷回國創業，先是成立了「恆拓開源」——用開源軟件幫助企業擺脫數據庫、ERP 等大型軟件的束縛。&lt;/p&gt; 
&lt;p&gt;但很快他就發現，這種方案很難擺脫 To B 項目制的重投入，還很容易做成外包公司。&lt;/p&gt; 
&lt;p&gt;隨後，馬越選擇收購「開源中國」這個社區，開始了一段曲折的創業路——「開源中國」經歷過數度轉型，從開源社區，拓展到代碼託管、代碼工具鏈，在探索商業化期間，經歷了從母公司剝離獨立發展，2019 年被百度戰略控股，最後，又在中美競爭、國產替代浪潮中決定重新獨立發展，謀求上市。&lt;/p&gt; 
&lt;p&gt;做開源社區需要大量的資源、資金投入，在開源中國最艱難的時候，馬越揹負的個人債務最高達 1.8 億元。&lt;/p&gt; 
&lt;p&gt;1972 年出生的馬越，有着一種老大哥式的坦率。他絕沒有賣苦的意思，但你很容易從他的敍述中，體會到經歷這些坎坷過後的幽默——他表示，在中國做 To B 就是「城市包圍農村」，企業軟件就是管理者智慧的固化。當中國的企業發展階段還在初期，「你很難要求大家還沒吃飽喝足的情況下，去做開源。」&lt;/p&gt; 
&lt;p&gt;但這些時刻都已經過去了。開源中國也已經摸索出一條更適合自己的、中國式的開源道路。&lt;/p&gt; 
&lt;p&gt;現在，開源中國已經成為全球第二大的代碼託管平台，匯聚了超過 1800 萬開發者。其自主研發的 DevOps 工具鏈已在金融、軍工等關鍵領域，達到 80% 的市場滲透率。2024 年，開源中國的營收已超過 2 億元。&lt;/p&gt; 
&lt;p&gt;《智能湧現》獲悉，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/337301/oschina-series-c-funding-round&quot;&gt;「開源中國」近期正式完成數億元 C 輪融資&lt;/a&gt;&lt;/u&gt;，由北京信息產業發展投資基金（北京信產基金）領投，深報一本股權投資基金（深報一本）及北京上河動量私募股權基金（上河動量）跟投。&lt;/p&gt; 
&lt;p&gt;至此，開源中國已累計獲得超 16 億元戰略投資。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0306/194426_EaKH_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;△開源中國董事長馬越&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;馬越認為，哪怕在全球範圍內，開源也不是件容易的事情。他以 GitHub 舉例：從 2008 年成立開始直到被微軟收購，在 2022 年 ChatGPT 爆發後推出 Copilot，才算是正式證明瞭商業化潛力。&lt;/p&gt; 
&lt;p&gt;「開源是強者和富人的遊戲。」他説，上一代人都成長在物質更短缺的年代——商業社會也是如此，企業要先賺夠了錢，才有餘裕考慮是否開源，做一些人人為我、我為人人的好事。「吃飽了飯，才能有力氣談開源。」&lt;/p&gt; 
&lt;p&gt;這就不難理解，即使 DeepSeek 的爆火為全中國都打了一記強心針，馬越的觀點依然是冷靜的。他認為，DeepSeek 很難根本性改變國內軟件生態的問題，這是一個時代的侷限。&lt;/p&gt; 
&lt;p&gt;而想要在開源路線上有所成就，這要求新一代的開發者，從 Day 1 就開始出海，像 DeepSeek 一樣去全球市場中競爭。&lt;/p&gt; 
&lt;p&gt;如果説 DeepSeek 改變了什麼，更多的都是文化和價值觀層面的事情。「十年前大家普遍不理解開源，覺得開源是一羣草根做的事，現在全社會都能認識到，開源等於創新。」馬越説。&lt;/p&gt; 
&lt;p&gt;以下為《智能湧現》與開源中國董事長馬越的對話，經編輯：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;DeepSeek 不是國運級產品，年輕人才是&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：開源中國現在是第二大代碼託管平台，國內最大的開源社區。DeepSeek 的熱潮，對你們的直觀影響，是從什麼時候開始的？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：就是他在 App Store 登頂那會兒。先是 V3，然後是 R1 發佈，一下子就火起來了。我們春節一直在加班，讓 DeepSeek 首先能在中國生產的 GPU 上運行，這需要大量工作，我們是第一個在沐曦芯片上部署的。&lt;/p&gt; 
&lt;p&gt;我們都在調侃，春節就兩件事：DeepSeek、哪吒。DeepSeek 就是開源圈出了個哪吒。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：現在已經形成了一種論調：DeepSeek 是一個國運級的產品。但最近你的公開表達裏，似乎對這一點不太認同。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：首先，大模型這個事情，你離不開英偉達吧？其次，你離不開 Transformer 架構；第三，你採用了蒸餾的思路，這些都不是國內原創的。&lt;/p&gt; 
&lt;p&gt;DeepSeek 本質上是在現有路線上走得最好，實現了彎道超車，這是值得尊敬的。&lt;/p&gt; 
&lt;p&gt;但是 DeepSeek 能夠不依靠外部資金支持，也不做任何 PR，靠技術就能做到全球頂尖——以梁文鋒為代表的年輕人崛起，這才是國運級的現象。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：那什麼才算國運級的產品？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：完全原創的技術創新。誰説 Transformer 就是算法的終局？如果有人用非 Transformer 方案做出比 DeepSeek 強十倍的成果，那才是真正的突破，那是人類級的進步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 給開源生態最大的啓示會是什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：讓全社會認識到：開源等於創新。&lt;/p&gt; 
&lt;p&gt;DeepSeek 最令人唏噓的是，在國內兩年都默默無聞，也不如打廣告的很多大模型公司，直到 2024 年開始，才因為技術，因為開源，被美國人超級關注——雖然一部分人特別支持，一部分人極力貶低，這種關注反而倒逼着國內形成了一種愛國情懷。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：以前大家不相信這個觀點嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：以前很多人認為開源就是一幫草根、烏合之眾，很難和大廠這種正規軍相比。&lt;/p&gt; 
&lt;p&gt;其實二十年前我就在説這些話：開源約等於創新能力，創新能力和國力是映射關係。正是因為我們有錢了、富足了，才會有 DeepSeek 這樣的企業出現。&lt;/p&gt; 
&lt;p&gt;以前沒人聽，現在有人聽了。&lt;/p&gt; 
&lt;p&gt;第二點很重要，就是要對年輕人保持敬畏。不只是尊重，而是要怕年輕人，信任年輕人。每一代人都有自己的時代使命，也有時代侷限性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：這羣年輕人，或者新一代開源貢獻者，為什麼能成長起來？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：這種質變是建立在之前充分的量變基礎上的。&lt;/p&gt; 
&lt;p&gt;這十年要感謝走在前面的互聯網大廠，事實上國內的主要開源力量集中在這些有實力的企業上。包括百度、阿里、騰訊等組織的開源項目，還有華為的鴻蒙、歐拉等等。他們都是領着工資的員工，在搞這些開源工作，不是純粹基於興趣。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 證明一件最關鍵的事：通過底層技術突破，就能吸引大量用戶，以及贏得尊重。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：現在我們國家最應該做兩件事：一是牽頭一起開發中國的 CUDA；二是讓所有國產 GPU 都能快速支持這些模型。&lt;/p&gt; 
&lt;p&gt;説到生態，生態就是要有更多的人蔘與，而且大家都有高度共識。現在最大的問題不是芯片卡脖子，而是 CUDA 這個生態的制約。中國完全可以開發一套類似 CUDA 的系統，就像我們有自己的 GPU 一樣。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源是富人和強者的遊戲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 爆火之後，找你討論的人多嗎？大家最關心什麼話題？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：有人問我，DeepSeek 會不會給中國 To B 市場帶來新生機？不可能那麼快。&lt;/p&gt; 
&lt;p&gt;IT 外包的人天價格，20 年來的漲幅還不如按摩師。現在外包人天均價一千就算高的了，還有五六百的。你去按摩，現在一小時都要一兩百塊錢。十年前，IT 的外包時薪就比不上按摩了，現在差距更大，那是因為按摩價格漲得快。&lt;/p&gt; 
&lt;p&gt;中國軟件沒人願意花錢，這是行業發展還不行的核心原因。要等這一代年輕人變成決策者，好時代才會來。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：本質還是因為國內企業發展階段還比較早。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：開源本質上是強者和富人的遊戲。正是因為我們吃飽喝足了，才會有 DeepSeek 這樣的企業出現。上一代互聯網用戶普遍不願意為軟件和知識付費，騰訊會議掉線了就重連，也不願意買會員。&lt;/p&gt; 
&lt;p&gt;但這一代年輕人生活富足，你們會改變這個局面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 會給上一代 To B 創業者帶來什麼啓示嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：我覺得他們給創業者帶來兩個重要的啓示。第一是要對錢保持敬畏。創業的目的就是為了掙錢，談理想和情懷沒意義。&lt;/p&gt; 
&lt;p&gt;DeepSeek 不太需要考慮商業化的問題，是因為幻方已經解決了這個事情。&lt;/p&gt; 
&lt;p&gt;上一代的軟件創業者有個致命問題，一心想着燒錢，通過標準化產品打市場，這不是中國市場的運行邏輯，中國最有錢的金主都是大型企業，在中國想要賺錢，不做定製化是不現實的。&lt;/p&gt; 
&lt;p&gt;中國軟件行業是城市包圍農村，而美國是農村包圍城市，腰部企業數量很多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 會改變大家對商業化的看法嗎？開源怎麼考慮商業化，是這個領域的「天問」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：如果要開源做創業項目，技術必須得硬邦邦。就是和 DeepSeek 一樣，Day 1 就出海，否則在中國太難賺錢了，時代還不夠成熟。&lt;/p&gt; 
&lt;p&gt;大家總是會舉例，比如紅帽那套模式也能商業化，但是想用這種方式在中國做一個上市公司，還不是這個時代的事。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：你們自己也經歷了很長一段商業化探索的時期，是從什麼時候想明白要怎麼做的？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：2020 年是個重要轉折點。我們那年決定從百度獨立出來，重新謀求 IPO。那段時間因為美國開始在很多尖端技術上斷供，我們想抓住這個機會，真正成為一個獨立的開源平台。&lt;/p&gt; 
&lt;p&gt;想要做真正的本土開源平台，必須要是徹底中立的第三方，這是選擇重新獨立發展的核心原因。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：想明白之後，都做了什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：我們現在從社區發展出了三大產品線。&lt;/p&gt; 
&lt;p&gt;開源中國社區（OSChina）現在已經完全進化成一個 AI 教育平台。我們是中國最大的開源社區，有 1000 多萬用戶。現在我們 24 人的團隊能創造約 5000 萬收入，還有淨利潤，這在社區團隊中很少見。&lt;/p&gt; 
&lt;p&gt;第二塊是代碼託管和研發效能平台 Gitee，現在平台有 3600 萬個代碼倉庫，服務 36 萬家企業。主要提供代碼託管私有化倉庫服務，確保很多中小團隊的代碼安全，客單每年 3000 塊左右。&lt;/p&gt; 
&lt;p&gt;從 2020 年到現在，我們已經能夠提供 DevOps 全生命週期國產替代方案，在滿足開發者需求的同時，也建立起一個自主創新、安全可信的本土開源軟件工具與生態。&lt;/p&gt; 
&lt;p&gt;第三塊是 AI 大模型平台「模力方舟」，模型體驗、推理訓練到應用部署等等服務，都會提供。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：為什麼會從社區拓展到後來的 DevOps，以及 AI 大模型基座？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：一個開源公司想要成功，靠社區是不夠的，我們需要找一個閉環的商業模式，像 GitHub 那條路——社區、代碼託管是沒法達到這個目標的。GitHub 也是在大模型浪潮來了之後，推出 Copilot，才把營收做起來。&lt;/p&gt; 
&lt;p&gt;以後沒有淨利潤的公司很難在國內上市，所以我一直強調看毛利率和人效，這兩個指標高了，自然會有淨利潤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：你們現在的主要收入，來自哪裏？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：我們主要收入來自 100 家左右的銀行、券商、軍工、製造業客戶，都走大型私有部署形式。中小客戶主要靠 SaaS 服務。&lt;/p&gt; 
&lt;p&gt;2024 年我們全國訂單超過 2 億，是一個突破。前年過 1 億，2024 年翻了一倍，還實現了盈虧平衡，這很不容易。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：主要模式靠服務大型企業的話，怎麼避免走到項目制的老路？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：我們的產品做得很複雜，是因為中國的大型企業的場景複雜。我們的流程引擎、角色引擎、交互界面、流水線都是可定製的，還能做各種插件，就是為了保證靈活性。&lt;/p&gt; 
&lt;p&gt;我們會幫客戶做定製化配置，但是不做二次開發。我們現在 330 多人，這塊業務佔 200 多人，但定製化去做開發和交付的不到 10%。&lt;/p&gt; 
&lt;p&gt;第二是我們自己堅決不賣算力，只做第三方，比如給雲廠商導流。&lt;/p&gt; 
&lt;p&gt;我們現在的路線很清晰：前端社區承載大流量，做開發者工具賣給企業，先 To C，再 To B，也算是一種產品驅動增長（Product-Driven Growth）的模式。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;一起發展，比單打獨鬥強&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：是否選擇開源，企業的考量到底是什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：現在大模型不開源很難。蘋果為什麼到今天 iOS 都不開源？因為硬件生態已經形成壟斷。如果沒有類似這樣的護城河，你不開源，憑什麼在市場立足？&lt;/p&gt; 
&lt;p&gt;就像我十幾年來一直説的，開源是創新的最佳方法論，也是市場競爭的方法論，是反強權的方法論。你做得好，我們就開源來和你競爭。當年有 Unix 和 Windows，就有 Linux；有 iOS，後來就有 Android，都一樣。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：你做過很多併購，DeepSeek 的成功會改變投資人對開源項目的看法嗎？開源項目的出路會變得寬嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：這也是我想問所有投資人和創業者的問題：投資的目的是啥？到底你希望怎麼賺錢？&lt;/p&gt; 
&lt;p&gt;上市、被收購、分紅都是一種退出方式。但現在在國內，要麼 IPO，要麼死掉，這很殘酷。&lt;/p&gt; 
&lt;p&gt;中國的開源生態很分散，現在很多創業者缺乏一種共識，就是一起發展比單打獨鬥強。很多人把創業當作獲取情緒價值的方式，就想當老大，寧可公司死也不願意賣給別人。覺得賣了就是投降，這坎兒過不去。&lt;/p&gt; 
&lt;p&gt;如果放不下自己的 ego，最終就會害了自己，也害了客戶和投資人。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 大獲成功之後，你怎麼評估現在我們所處的 AI 發展階段？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：如果類比互聯網那個時代，我們還是在大時代的開端狀態，類似當年的撥號上網階段。我從 1997 年開始上網，下載一張照片要四五天，網速只有 28K。但即便如此，我們也覺得很神奇。&lt;/p&gt; 
&lt;p&gt;現在就像出海探索新大陸，所以創業者只要帶着乾糧上了船，不淹死，就一定有收穫。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：DeepSeek 會怎麼改變現在國內的創業格局？你覺得更利好大廠還是創業公司？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：很難説，可能還是大廠比較有優勢。&lt;/p&gt; 
&lt;p&gt;首先，DeepSeek 不是一個創業公司，人家不用外部資金就能買一萬張卡，某種程度上也算個小大廠了。&lt;/p&gt; 
&lt;p&gt;我覺得 DeepSeek 給創業者帶來兩個重要的啓示。第一是要對錢保持敬畏。創業的目的就是為了掙錢，談理想和情懷沒意義。&lt;/p&gt; 
&lt;p&gt;初創公司除非在算法、技術底層有突破，否則在工程層面，很難跟大廠拼數據，拼流量，這是最終商業化的兩個要素。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：現在的大模型初創的轉向都很明顯，方向聚焦，專心做底層技術。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：這就是開源的可怕之處。&lt;/p&gt; 
&lt;p&gt;我前年就説，預訓練是大廠的遊戲，創業公司應該做垂直領域的訓練，把更多精力放在推理上，燒錢的事情本來就不該做。&lt;/p&gt; 
&lt;p&gt;歷史上都有很多例子，當年開源領域有很多做容器的公司，比如 Docker 剛出來時只是各種容器運行時技術中的一種。結果 K8s 生態起來之後，任何容器技術只要實現 K8s 兼容性，就可以融入雲原生技術棧，這種強大的生態整合能力最終使其它技術方案逐漸邊緣化，相當於前邊都白做了。&lt;/p&gt; 
&lt;p&gt;所以我給大家的建議，包括我們自己的策略，就是產品功能要緊跟隨，但要輕投入，商業模式要做輕一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能湧現》：對開源中國來説，未來的目標會是什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;馬越&lt;/strong&gt;&lt;/span&gt;：開源中國這十幾年，積累了用戶流量護城河，客戶品牌美譽度，現在是通過信創找到了快速增長的收入模式。&lt;/p&gt; 
&lt;p&gt;我們在這輪融資之後，也會開始尋求進一步上市，希望成為 A 股人工智能開源第一股。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEY_NhbMX94bk6op8GDuG6g&quot; target=&quot;_blank&quot;&gt;《對話開源中國馬越：DeepSeek 不是國運級的創新，年輕人才是》&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337320</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337320</guid>
            <pubDate>Wed, 05 Mar 2025 11:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>支持函數導入/導出，新增支持變量賦值節點，MaxKB 知識庫問答系統 v1.10.2 LTS 版本發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;2025 年 3 月 6 日，MaxKB 開源知識庫問答系統正式發佈 v1.10.2 LTS 版本。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 MaxKB v1.10.2 LTS 版本中，&lt;strong&gt;函數庫&lt;/strong&gt;方面，MaxKB 支持函數的導入/導出；&lt;strong&gt;應用&lt;/strong&gt;方面，新增支持「變量賦值」節點；&lt;strong&gt;模型管理&lt;/strong&gt;方面，MaxKB 新增支持 Ollama 供應商的重排模型。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;X-Pack 增強包&lt;/strong&gt;方面，MaxKB 應用接入功能支持 Slack。目前，MaxKB 支持對接的第三方應用包括企業微信、公眾號、飛書、釘釘以及最新的 Slack。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;此外，MaxKB 開源項目組還進行了超過 40 項功能更新和問題修復。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;感謝廣大社區用戶的反饋和支持，MaxKB 期待與您攜手創造更加美好的未來。&lt;/p&gt; 
&lt;h1&gt;亮點更新&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 支持函數導入/導出&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增函數的導入/導出功能，從而實現了函數模塊在不同環境之間的無縫遷移。這一功能進一步方便了用戶的函數共享過程，提升了系統的靈活性與實用性。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f196ce183a6e9256792ceea1be65b89695.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;▲圖 1 MaxKB 支持函數導入/導出&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 新增支持「變量賦值」節點&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增支持「變量賦值」節點。該節點為用戶提供更為便捷的方式來更新工作流編排中的變量值，能夠顯著提升用戶在配置和管理流程時的靈活性與效率。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;626&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1dfcf722f328519c2abb120eb726d5c46f1.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;▲圖 2 MaxKB 新增支持「變量賦值」節點&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 新增支持 Ollama 供應商的重排模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增支持 Ollama 供應商的重排模型。目前 MaxKB 已經支持 Ollama 供應商提供的大語言模型、向量模型、視覺模型和重排模型，為用戶提供了豐富的模型選擇。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ad23e7ada247c9dfdcf55de68ffc8212e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;▲圖 3 MaxKB 支持 Ollama 供應商的重排模型&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 應用接入支持 Slack（X-Pack 增強包）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 專業版中，MaxKB 的應用接入功能新增支持接入 Slack。目前，MaxKB 支持對接的第三方應用包括企業微信、公眾號、飛書、釘釘以及最新的 Slack，幫助企業將大模型能力快速注入原有業務系統，加速 AI 賦能業務的進程。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;637&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c346e08537ec1f877de06169eb13f652e12.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;▲圖 4 MaxKB 應用接入 Slack 配置頁面&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;功能優化&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用（X-Pack）：開啓思考過程後，優化在企業微信、飛書、釘釘、公眾號中的回覆過程；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用（X-Pack）：企業微信對話時支持上傳圖片；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用（X-Pack）：登錄認證的 OIDC 設置支持配置&lt;em&gt;scope&lt;/em&gt;參數；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：支持創建空白應用；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：用戶輸入的參數新增支持密碼框和開關組件；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：用戶輸入支持自定義標題；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：表單收集節點的參數新增支持密碼框組件；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：上傳音頻文件類型新增 m4a 格式；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：通過調用應用 API Key 的方式進行對話時，支持上傳文件參數；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：通過調用應用 API Key 的方式進行對話時，支持輸出思考過程參數；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：基礎信息節點中的用戶輸入表格中的參數，支持拖拽式調整順序；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：判斷器中的條件值支持變量解析；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：在多路召回節點的「執行詳情」對話框中，優化分段顯示內容（包含分段標題、文檔和知識庫）；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：當用戶退出工作流編輯時提示用戶保存數據；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：關聯知識庫引用分段數的最大值調整為 10000；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：高級編排中修改節點名稱的操作修改為「…」→「重命名」；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：單一圖片生成節點生成多張圖片時橫向排列圖片；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：優化問答頁面佈局為左右佈局，左側顯示 AI 回答，右側顯示用戶問題；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：優化用戶打開問答頁面時，顯示歷史對話記錄；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：優化語音播放時僅播放最後一個內容；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：支持修改會話標題；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知識庫：支持執行生成問題失敗的分段繼續生成問題；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知識庫：支持為文檔列表排序；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知識庫：支持在生成問題中使用&lt;em&gt;{title}&lt;/em&gt;變量獲取分段標題；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;函數庫：查詢函數時忽略大小寫；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型設置：查詢模型時忽略大小寫；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;團隊成員：查詢成員時忽略大小寫；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系統：優化第一次登錄時耗時較長的問題。&lt;/p&gt; 
&lt;h1&gt;問題修復&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復 AI 回覆內容中的圖片無法放大的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復高級編排中的提示詞窗口放大後編輯內容，按 ESC 鍵關閉窗口後不保存提示詞的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復使用 vLLM 供應商大語言模型進行對話時，部分情況下回答無法結束的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復使用 Kimi 供應商的大語言模型進行對話時，Tokens 計算不準確的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復圖片生成節點切換模型後參數設置未更新的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復當 Excel 表格中含有合併單元格的數據時，讀取時會缺少數據的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復 OpenAI 調用格式沒有思考過程參數的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復應用子節點中若有非必填參數，在父級應用中若未設置該參數，對話時會報錯的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復 Ollama 供應商的大語言模型使用&lt;/span&gt;&lt;em&gt;&lt;span&gt;num_ctx&lt;/span&gt;&lt;/em&gt;&lt;span&gt;參數時，進行對話會報錯的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：修復在歷史對話記錄中，無法使用瀏覽器進行語音播放的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復問題框中無法在內容中間插入換行的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復部分情況下會在文檔的 URL 地址後面自動加上「/」，導致無法訪問的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面（X-Pack）：修復顯示設置中關閉歷史記錄後，問答頁面的新建對話不顯示的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;函數庫：修復函數返回值為 0 時，調試時的輸出結果顯示錯誤的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型設置：修復添加阿里雲百鍊的大語言模型時，如果是全模態模型提交會報錯的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型設置：修復添加 Azure OpenAI 的 DeepSeek-R1 模型報錯的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系統設置（X-Pack）：修復 Swagger 文檔中接口參數顯示不全的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系統設置（X-Pack）：修復在「外觀設置」中設置「網站名稱」後，問答頁面的標籤處不顯示應用名稱的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系統設置（X-Pack）：修復登錄頁面加載時，默認 Logo 會閃現的問題。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337319/java-maxkb-1-10-2-lts-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337319/java-maxkb-1-10-2-lts-released</guid>
            <pubDate>Wed, 05 Mar 2025 11:49:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>開源中國完成數億元 C 輪融資，邁向「開源 AI 第一股」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源技術生態領軍企業開源中國&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;（開源共識（上海）網絡技術有限公司）近日完成了數億元 C 輪融資&lt;/strong&gt;，本輪融資由北京信息產業發展投資基金（北京信產基金）領投，深報一本股權投資基金（深報一本）及北京上河動量私募股權基金（上河動量）跟投。&lt;/p&gt; 
&lt;p&gt;此次融資將加速公司 AI 戰略佈局：深化現有產品矩陣的擴展、完善與全面 AI 化，構建軟硬件協同的智能解決方案體系，促進人工智能在產業領域的 AI 應用落地。&lt;/p&gt; 
&lt;p&gt;至此，開源中國已累計獲得超 16 億元戰略投資，投資方包括百度、華為、海望資本、張江科投、中科創星、天際資本、君聯資本、上海國際創投、中移和創投資、瑞壹投資、容億資本、泰達實業、中國互聯網投資基金、國調科改、聯想創投、上海浦東軟件園、上海科創、北京信產基金、深報一本、上河動量等。構建起國有資本、科技大廠、創始團隊&quot;3:3:4&quot;的良性股權結構，形成&quot;國家隊護航、產業方協同、市場化運作&quot;的創新生態。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開發者生態的厚積薄發&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;作為中國開源基礎設施奠基者，開源中國運營着 1800 萬開發者聚集的 oschina.net 社區及代碼託管平台 Gitee，服務 36 萬企業級用戶。其自主研發的 DevOps 工具鏈已在金融、軍工等關鍵領域實現 80% 市場滲透率，成為信創替代工程的標杆案例，驗證了開源商業化的中國路徑。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2023/0630/103630_ng3i_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;AI 轉型的戰略升維&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;2024 年，公司推出對標 HuggingFace 的 AI 大模型平台&quot;模力方舟 (moark.com)&quot;，首創&quot;模型數據-算力調度-應用開發&quot;全棧服務體系。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-48d87ff5e72b3269622021604fd94f3e748.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;平台已實現三大突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;生態開放化&lt;/strong&gt;：聚合數千開源模型，打造 AI 應用創新基座；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服務一體化&lt;/strong&gt;：提供從模型體驗、推理訓練到應用部署的全生命週期服務；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;算力國產化&lt;/strong&gt;：完成多家國產 GPU 深度適配，成功運行 DeepSeek-V3 等千億級模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;開源中國下一步將以模力方舟為核心，打造全方位的 AI 業務佈局，助力 AI 應用創新、科技人才培養和新質生產力提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;起航，邁向「開源 AI 第一股」&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;開源中國以開發者生態為基座，構建開源領域‌「用戶-流量-盈利」‌三重護城河，率先在信創市場完成‌開源商業化閉環驗證‌，實現國產研發工具從技術突破到商業變現的質變。依託本輪戰略投資，加速 AI 戰略升級擴張市場領域，開闢第二增長曲線‌。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;目前開源中國已開始進入 IPO 倒計時，計劃以&quot;開源 AI 第一股&quot;身份登陸資本市場，通過技術普惠推動新質生產力發展，助力中國在全球 AI 2.0 時代構建核心競爭力。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;北京信息產業發展投資基金表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源中國是中國開源生態與 AI 技術融合創新的標杆企業，其以開發者生態為根基、以信創替代為突破、以 AI 戰略為驅動的增長路徑，高度契合國家科技創新與自主可控的戰略方向。領投本輪融資，既是基於對開源中國在國產軟件基礎設施領域不可替代地位的認可，更是看好其通過「模力方舟」平台推動 AI 技術普惠化、算力國產化和應用場景規模化落地的能力。&lt;/p&gt; 
 &lt;p&gt;我們期待通過資源協同與生態賦能，助力開源中國加速構建 AI 時代的技術底座，為全球 AI 2.0 競爭注入中國開源力量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;深報一本表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們高度關注開源中國在國產軟件替代浪潮中展現的商業化前景，憑藉其構建的龐大開發者生態體系，公司有望在 AI 應用層持續釋放開源技術的創新勢能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;上河動量管理合夥人王欣表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;世界範圍內，開源已經成為軟件開發和人工智能創新的極其重要的推動力量。&lt;/p&gt; 
 &lt;p&gt;開源中國是服務於中國本土開源生態的先行者和堅守者，在地緣科技競爭的背景下，開源中國已經成為中國軟件和人工智能領域具有國家級影響力的科技創新基礎設施。相信開源中國的獨特價值會得到越來越多的行業參與者和資本市場的認可。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337301/oschina-series-c-funding-round</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337301/oschina-series-c-funding-round</guid>
            <pubDate>Wed, 05 Mar 2025 10:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>個人開發者也能訓練推理模型？GRPO 技術詳解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 還在為訓練推理模型燒光算力預算而發愁？當開源小模型遇上數學題就&quot;智商掉線&quot;，如何低成本突破性能瓶頸？&lt;/p&gt; 
 &lt;p&gt;傳統 RLHF 動輒百萬級算力投入，讓多少團隊在強化學習門前望而卻步；格式混亂、邏輯斷層、答案偏差------這些模型推理的頑疾是否也在阻礙你的 AI 產品落地？&lt;/p&gt; 
 &lt;p&gt;本文深入解析 DeepSeek 團隊突破性的 GRPO（羣組相對策略優化）技術，這項創新將強化學習所需計算資源幾乎減半，甚至可以結合 LoRA 在普通消費級 GPU 上進行模型訓練。作者通過親身實踐，成功在僅需 16GB 顯存的環境下將 1B 參數的 Llama 3.2 轉化為推理模型（後續文章會分享相關細節），完全顛覆了傳統強化學習的資源需求認知。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Greg Schoeninger&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71410d1cd55685fc17beb84605c865f5851.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不久前，我們深入研究了 DeepSeek-R1 背後的技術原理，但是沒有詳細介紹其訓練流程中採用的一項名為&quot;羣組相對策略優化&quot;（Group Relative Policy Optimization, GRPO）的關鍵技術。&lt;/p&gt; 
&lt;p&gt;GRPO 本質上是一種旨在提升模型推理能力的強化學習算法。該技術最早發表於其研究論文《DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models》[1]，隨後也被應用於 DeepSeek-R1 的後訓練階段。&lt;/p&gt; 
&lt;p&gt;在《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》這一論文[2]中，研究團隊詳細闡述了從基礎預訓練語言模型到最終推理模型的完整構建路徑。雖然之前我們未深入探討 GRPO 的數學原理和代碼實現，但今天這篇文章將全面解析 GRPO 的技術細節，助力各位讀者掌握這項技術的核心要義並應用於實際工作。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 要點回顧：DeepSeek-R1 如何運用 GRPO 技術&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為幫助理解，我們首先梳理從基礎模型到推理模型的完整訓練流程。該流程通過監督式微調（SFT）與羣組相對策略優化（GRPO）的交替迭代實現模型能力躍升：&lt;/p&gt; 
&lt;p&gt;1.監督式微調（SFT）階段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;冷啓動訓練&lt;/strong&gt;：採用數千條人工標註的高質量數據微調模型&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;數據驗證&lt;/strong&gt;：所有樣本均通過人工審核確保可靠性&lt;/p&gt; 
&lt;p&gt;2.GRPO 強化學習階段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;推理軌跡訓練&lt;/strong&gt; ：引導模型生成結構化推理過程（具有標籤的推理軌跡）&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;三重確定性獎勵&lt;/strong&gt;：基於格式規範性、邏輯一致性、答案正確性設計獎勵機制&lt;/p&gt; 
&lt;p&gt;3.增強型 SFT 階段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;合成數據生成&lt;/strong&gt;：創建 80 萬條合成訓練樣本並進行篩選&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;模型自檢過濾&lt;/strong&gt;：通過&quot;LLM As A Judge&quot;機制剔除錯誤響應&lt;/p&gt; 
&lt;p&gt;4.最終 GRPO 對齊階段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;價值觀校準&lt;/strong&gt;：確保模型輸出兼具實用性與安全性&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1a3d34d2c90323e9660a599d6baf9ba905.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在這篇文章中，我們將深入探討 GRPO 的細節，助您掌握這項推動大模型推理能力突破的關鍵技術。筆者已開展基於 GRPO 的小模型訓練實驗，後續將發佈完整代碼與工程實踐細節，通過可復現案例串聯理論知識與實際應用。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 為什麼 GRPO 很重要？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;TLDR ~ 大幅降低了計算需求且簡化了強化學習流程。與 ChatGPT（PPO）使用的基於人類反饋的強化學習（RLHF）相比，所需的計算資源幾乎減半。當你結合 LoRA 使用時，即使&quot;GPU poor&quot;（譯者注：GPU 的性能不足）也能進行強化學習訓練。我試過了，確實有效。我成功地將 1B 參數的 Llama 3.2 模型改造成了僅需 16GB 顯存的推理模型。後續文章會分享代碼和硬件要求細節。&lt;/p&gt; 
&lt;p&gt;我們只需在雲 GPU 服務上花不到 100 美元，就能從自家車庫訓練推理模型。如果用自己的硬件跑小模型，基本上算是&quot;免費&quot;。其底層原理是什麼呢？下一節將討論從 PPO 到 GRPO 的演變過程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 從 PPO 到 GRPO&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;傳聞 ChatGPT 背後的強化學習（RL）技術是 PPO（Proximal Policy Optimization，近端策略優化）。該流程在 InstructGPT 論文[3]中被提出，用於創建能夠遵循指令而不僅僅是簡單預測下一個單詞的模型。&lt;/p&gt; 
&lt;p&gt;訓練過程需要收集大量標註數據。對於給定的用戶查詢，模型需生成多個候選響應，然後由人類或 AI 在循環中對輸出進行標註並按質量從優到劣排序。這些數據可用於訓練&quot;獎勵模型&quot;，其職責是為新接收的提示詞計算&quot;獎勵值&quot;。該獎勵值應體現給定用戶查詢下模型響應的優劣程度。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7e2d394a6e114e400146d01db6dc67530d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;收集完所有這些經過排序和標註的數據後，即可啓動 PPO 來訓練大語言模型（LLM）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問題在於 PPO 的訓練成本可能非常高昂。&lt;/strong&gt; GRPO 論文[1]中的相關圖表展示了 PPO 和 GRPO 過程中涉及的不同 LLM。下方藍色和黃色方框中共有 4 個不同的 LLM。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-89e516de6f1f5de6d7805fc499a831b28e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了幫助大家理解上圖的一些術語，我在這裏給出了一些簡單的定義：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;策略模型（Policy Model）&lt;/strong&gt; - 對當前正在訓練的 LLM 的別稱&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;參考模型（Reference Model）&lt;/strong&gt; - 被訓練原始 LLM 的凍結版本&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;獎勵模型（Reward Model）&lt;/strong&gt; - 基於人類偏好訓練的模型（來自上文提到的 InstructGPT 技術）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;價值模型（Value Model）&lt;/strong&gt; - 試圖估算特定動作長期獎勵的模型&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;strong&gt;04 通過 GRPO 減少內存使用量&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在 PPO 算法中，策略模型和價值模型都包含需要通過反向傳播進行優化的可訓練參數。反向傳播過程需要消耗大量內存資源。&lt;/strong&gt; 從上面的架構圖可以看出，GRPO 算法移除了價值模型模塊。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-909a6a3cd9958e6b2b842610e7167f00efc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;PPO 算法中混合使用了 4 個大語言模型（LLMs），這些模型都需要消耗大量的內存和計算資源。其中價值模型和獎勵模型的參數量通常與正在訓練的目標語言模型相當。參考模型通常是訓練初期的語言模型的凍結副本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-73a54d4ed060595c351d14255a2a026dcc4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這種實現方法不僅帶來高昂的計算成本，還存在諸多需要協調的動態組件，而且還有多個模型需要優化。組件數量越多，通常意味着優化難度越大。GRPO 通過精簡架構有效降低了系統複雜度。&lt;/p&gt; 
&lt;p&gt;出於興趣，我在 H100 上測試了不同參數規模的模型，觀察使用 GRPO 進行微調的難易程度。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f30692cc7db7719142a8d0c6d7bf4b34cda.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如果想了解具體技術細節，可以查閲相關文檔：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oxen.ai%2Fblog%2Fgrpo-vram-requirements-for-the-gpu-poor&quot; target=&quot;_blank&quot;&gt;https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;若您理解了所有系統需求的來源，就可以開始參與開源項目貢獻，或像我最近看到的 trl 倉庫的這個 PR 那樣，動手優化自己的機器學習庫：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-46b6550e48276645bc3fb9fe2f1531ef4a2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 羣組相對優勢（Group Relative Advantages）&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在強化學習過程中，我們從語言模型（LLMs）中獲取的主要信號是代表&quot;優勢&quot;（Advantage）的&quot;A&quot;。這個信號為更新原始語言模型的權重提供了方向指導：&lt;strong&gt;當優勢值較高時，我們需要鼓勵模型重複當前行為；當優勢值較低時，則需要引導模型嘗試不同的行為。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 PPO 算法中，傳統價值模型的核心任務是評估生成內容的質量，或者説預測這些內容獲得高獎勵值（high reward）的可能性。為了完成這項評估工作，需要訓練大語言模型作為價值判斷模塊。那麼 GRPO 是如何擺脫對價值模型的依賴的呢？&lt;/p&gt; 
&lt;p&gt;第一個技巧是：&lt;strong&gt;GRPO 不再針對單個查詢生成單一輸出，而是開始生成多個候選回答。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4651272806713abc0c71e0e9e4adb90f96.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體來説，如果問題是一道數學題，模型可能會嘗試幾種不同的解題方法。以下面這個數學問題為例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Mr. Curtis has 325 chickens on his farm where 28 are roosters and the rest are hens. Twenty hens do not lay eggs while the rest of the hens do. How many egg-laying hens does Mr. Curtis have on his farm?&lt;/p&gt; 
 &lt;p&gt;Curtis 先生的農場有 325 只雞，其中 28 只是公雞，其餘是母雞。其中有 20 只母雞不下蛋，問有多少隻產蛋母雞？&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;模型可能會嘗試多種解題思路，有的正確（答案為 227），有的不正確（答案為 305）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4f8c57fb9d114d8cd19c1c434f42d31ba6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;正確推理路徑：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;First, let&#39;s find out how many hens there are. The total number of chickens is 325, and 28 are roosters. So, the number of hens is 325 - 28 = 297. Of these 297 hens, 20 do not lay eggs, so the number of egg-laying hens is 297 - 20 = 277.&lt;/p&gt; 
 &lt;p&gt;277&lt;/p&gt; 
 &lt;p&gt;首先，我們來看看有多少隻母雞。雞的總數是 325 只，公雞有 28 只。因此，母雞的數量是 325 - 28 = 297。在這 297 只母雞中，有 20 只不下蛋，所以下蛋母雞的數量是 297 - 20 = 277。&lt;/p&gt; 
 &lt;p&gt;277&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;錯誤推理路徑：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You need to subtract the 20 hens that do not lay eggs from the total number of hens to find the number of egg-laying hens. So, the number of egg-laying hens is 325 - 20 = 305.&lt;/p&gt; 
 &lt;p&gt;305&lt;/p&gt; 
 &lt;p&gt;您需要從母雞總數中減去不下蛋的 20 只母雞，才能求出下蛋母雞的數量。因此，產蛋雞的數量為 325 - 20 = 305。&lt;/p&gt; 
 &lt;p&gt;305&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;然後我們對每個輸出根據其回答質量計算&quot;獎勵值&quot;（reward）。可能存在多個評估不同響應屬性的獎勵函數。我們暫時將獎勵函數視為黑盒，但知道它們會返回數值型結果------如果響應質量較好則數值較高，較差則較低，例如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Formatting（格式規範度）=1.0&lt;/li&gt; 
 &lt;li&gt;Answer（答案正確性）=0.0&lt;/li&gt; 
 &lt;li&gt;Consistency（邏輯一致性）=0.5&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;當獲得所有輸出的獎勵值 (r) 後，GRPO 通過計算獎勵值的均值 μ 和標準差 σ，生成羣組相對優勢 A。具體公式為：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-64e1b0b82899716c405d7c373fad02574d9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這個公式在機器學習特徵工程中非常實用，它可以將任意數值歸一化為更易學習的正負信號。&lt;/strong&gt; &lt;strong&gt;其直觀含義是：&quot;這個數據點偏離平均值多少個標準差？&quot;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;讓我們來看幾個例子。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b9a698704de3094e3837dd1ab2500a2a14a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;若用原生 numpy 代碼表示可能如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b22895474b1a709438951615cdb36e7923e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cba3c65046eea82fccdf170ae3480b63728.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再試另一組數值：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cc74f64ff94df742a05791fc54f6d5685c6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通過歸一化，將獎勵值轉換為以均值為中心（0.0）的相對優勢值。正值表示優於平均水平，負值表示劣於平均水平。這為我們建立了一套基準：&quot;給定當前提示詞，平均響應的質量如何？&quot;在訓練過程中，強化表現好的輸出（提高其概率），抑制表現差的輸出（降低其概率），從而引導模型優化方向。&lt;/p&gt; 
&lt;p&gt;這與傳統價值模型的目標相似：預測給定響應的獎勵值。由於我們現在訓練的是語言模型，只需調整 temperature 參數即可生成多個候選回答，所有生成回答的平均獎勵值即可作為衡量當前模型表現的良好信號，以及決定是否需要強化該行為。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 KL 散度&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;這個方程的最後一項是 KL 散度項。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-31fdc55549c04177692cffd66e30e71153b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;無需深入數學細節，這就是我們在訓練過程中始終保留&quot;參考模型&quot;的原因。我們不希望新模型偏離原始模型太遠，對於每個詞元（token），都要確保新模型的預測結果不會與原始模型的預測結果產生過大偏差。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c452d93871b84a20051519ae616d6a561c3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;強制執行 KL 散度的直接原因是：初始模型已經具備生成連貫語句和遵循指令的能力。我們不希望新模型通過&quot;獎勵欺騙&quot;（reward hack）或利用獎勵信號中某些與原始模型不匹配的特性來取巧。&lt;strong&gt;例如，如果模型發現使用&quot;pamplemousse&quot;（葡萄柚的法語，發音有趣且較罕見）這個詞能獲得高獎勵，但該詞在預訓練階段並不常用，我們就要阻止模型過度依賴這種用詞行為。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;將這些要素整合，就得到了完整的最終方程！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9c0e6e909d24b741ba1137deb08f79e43bc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;或者就像我們值得信賴的&quot;牛人 Eric&quot;説的那樣... 這個數學公式看起來比實際複雜...&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-856291aa6b9db5cbd46f3cbcf9d349927ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 獎勵信號機制&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1-Zero 研究的突破性在於，他們通過完全棄用&quot;神經獎勵模型&quot;進一步大幅降低了內存消耗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6f1e8b8d0e5a2080f1c94fa211bdd425e7c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這意味着什麼？簡而言之，他們直接使用正則表達式（regex）和字符串匹配技術生成獎勵信號。&lt;strong&gt;研究團隊認為，這種方法既能規避&quot;獎勵欺騙&quot;（reward hacking）問題，又能簡化整個訓練流程。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果將前文提到的&quot;準確性獎勵（Accuracy Rewards）&quot;和&quot;格式獎勵（Format Rewards）&quot;規則轉化為代碼，其代碼實現可能如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d0b618e57acda02c9b615ec705c4b7b9119.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;reference:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fwillccbb%2F4676755236bb08cab5f4e54a0475d6fb&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;訓練過程中完全無需引入額外的獎勵模型 LLM，僅需保留策略模型和參考模型作為主要內存佔用源。將所需 LLM 數量從 4 個削減至 2 個，顯著降低了 GPU 資源需求。&lt;/p&gt; 
&lt;p&gt;若你的直覺此時感到不對勁，質疑&quot;這種獎勵函數是否具備泛化能力？&quot;，那麼你是對的。&lt;strong&gt;這類獎勵機制僅在預設的特定任務（如數學推理和格式規範）上表現良好，但無法擴展到其他實用場景。&lt;/strong&gt; 例如，模型可能擅長生成格式的數學解題過程，卻無法完成開放式對話或創意寫作。&lt;/p&gt; 
&lt;p&gt;我的預測是&quot;苦澀的教訓&quot;（The Bitter Lesson）[4]將在此重現：當計算資源和數據量足夠時，模型更傾向於自主學習。我們越是減少人工編碼規則，讓模型自主探索，其表現就越優異。當前 GRPO 的獎勵機制仍顯人工幹預痕跡 ------ 為何不讓模型自行學習獎勵信號的權重呢？&lt;/p&gt; 
&lt;p&gt;儘管如此，嘗試不同的獎勵機制其實挺有意思的。&lt;strong&gt;GRPO 的亮點在於：&lt;/strong&gt; &lt;strong&gt;只要能用代碼定義獎勵函數（輸入響應、輸出數值），即可基於此進行優化。甚至可以通過外部 API 調用其他 LLM 生成獎勵信號。&lt;/strong&gt; 我預感未來幾周/月內，因為 GRPO 訓練門檻的降低，開發者將開始探索各種創意獎勵機制的設計。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓對於文中提到的&quot;不到 100 美元訓練推理模型&quot;，你有何看法？歡迎在評論區暢所欲言。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中鏈接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.03300&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2402.03300&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.12948&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.12948&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2203.02155&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2203.02155&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.incompleteideas.net%2FIncIdeas%2FBitterLesson.html&quot; target=&quot;_blank&quot;&gt;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fghost.oxen.ai%2Fwhy-grpo-is-important-and-how-it-works%2F&quot; target=&quot;_blank&quot;&gt;https://ghost.oxen.ai/why-grpo-is-important-and-how-it-works/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17778588</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17778588</guid>
            <pubDate>Wed, 05 Mar 2025 09:49:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>trustcall —— 基於 LangGraph 的強大工具調用庫</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;當被要求生成或修改大型 JSON blob 時，LLM 會遇到困難。&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code&gt;trustcall&lt;/code&gt;可通過&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;要求 LLM 生成&amp;nbsp;&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc6902&quot;&gt;JSON 補丁&lt;/a&gt;操作來解決這個問題。這使得：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更快、更便宜地生成結構化輸出。&lt;/li&gt;
&lt;li&gt;即使對於複雜的嵌套模式（定義為 pydantic、模式字典或常規 python 函數）也可以彈性重試驗證錯誤&lt;/li&gt;
&lt;li&gt;準確更新現有模式，避免不必要的刪除。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可靈活適用於多種常見的 LLM 工作流程，例如：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Extraction&lt;/li&gt;
&lt;li&gt;LLM routing&lt;/li&gt;
&lt;li&gt;Multi-step agent tool use&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;415&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/173555_bjJK_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/trustcall</link>
            <guid isPermaLink="false">https://www.oschina.net/p/trustcall</guid>
            <pubDate>Wed, 05 Mar 2025 09:37:00 GMT</pubDate>
        </item>
        <item>
            <title>騰訊混元發佈並開源圖生視頻模型，支持生成背景音效及 2K 視頻</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 6 日，騰訊混元&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaOeJoWyQ78o45KlJnAtAkg&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出圖生視頻模型並對外開源，同時上線對口型與動作驅動等玩法，並支持生成背景音效及 2K 高質量視頻。&lt;/p&gt; 
&lt;p&gt;開源內容包含權重、推理代碼和 LoRA 訓練代碼，支持開發者基於混元訓練專屬 LoRA 等衍生模型。&lt;/p&gt; 
&lt;p&gt;目前在 Github、HuggingFace 等主流開發者社區均可下載體驗。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FHunyuanVideo-I2V&quot; target=&quot;_blank&quot;&gt;https://github.com/Tencent/HunyuanVideo-I2V&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Huggingface：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ftencent%2FHunyuanVideo-I2V&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/tencent/HunyuanVideo-I2V&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據介紹，基於圖生視頻的能力，用戶只需上傳一張圖片，並簡短描述希望畫面如何運動、鏡頭如何調度等，混元即可按要求讓圖片動起來，變成 5 秒的短視頻，還能自動配上背景音效。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-79aaf27253683e0e75fd797b7842f3f77d1.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，上傳一張人物圖片，並輸入希望「對口型」的文字或音頻，圖片中的人物即可「説話」或「唱歌」；使用「動作驅動」能力，還能一鍵生成同款跳舞視頻。&lt;/p&gt; 
&lt;p&gt;目前用戶通過混元 AI 視頻官網即可體驗（https://video.hunyuan.tencent.com/），企業和開發者可在騰訊雲申請使用 API 接口使用。&lt;/p&gt; 
&lt;p&gt;騰訊混元表示，此次開源的圖生視頻模型，是混元文生視頻模型開源工作的延續，模型總參數量保持 130 億，模型適用於多種類型的角色和場景，包括寫實視頻製作、動漫角色甚至 CGI 角色製作的生成。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337275</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337275</guid>
            <pubDate>Wed, 05 Mar 2025 08:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Manus 邀請碼炒至 6 萬元，官方稱將逐步有序釋放</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;自發布以後，Manus 受到了熱烈追捧，網友紛紛湧向 Manus 官網，從而導致頁面一度因訪問量過大而崩潰。目前，試用 Manus 需要輸入邀請碼，這導致邀請碼一碼難求。在二手交易平台上，邀請碼的價格被炒至幾百元到 6 萬元不等。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;448&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-556805b52b9544d5e92e8dd8809b514dcf6.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;針對邀請碼炒作問題，Manus AI 合夥人張濤在社交平台做出了回應。他首先感謝了大家對 Manus 的關注，並澄清了幾點重要信息：一是公司從未開設任何付費獲取邀請碼的渠道；二是從未投入任何市場推廣預算；三是內測期間系統容量有限，公司將優先保障現有用戶的核心體驗，並逐步有序釋放邀請碼。&lt;/p&gt; 
&lt;p&gt;張濤稱，「目前採取邀請碼機制，是因為此刻服務器容量確實有限，不得已而為之，團隊也熬夜搞了一整天了。希望在接下來的時間裏能讓更多處在 waitlist 中的用戶優先體驗 Manus。」&lt;/p&gt; 
&lt;p&gt;「懇請大家對一家幾十人的創業公司多一點包容和理解，團隊正在全力輸出，讓大家早日體驗上更好的產品。」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/337193/manus-ai-agent&quot; target=&quot;_blank&quot;&gt;Monica.im 發佈 AI Agent 產品「Manus」&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337267</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337267</guid>
            <pubDate>Wed, 05 Mar 2025 08:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AMD 發佈完全開源的 3B 參數語言模型 Instella</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;AMD 今天&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocm.blogs.amd.com%2Fartificial-intelligence%2Fintroducing-instella-3B%2FREADME.html&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;&lt;/u&gt;了完全開源的 3B 參數語言模型&amp;nbsp;Instella。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1614&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/155518_eNxW_2720166.png&quot; width=&quot;2188&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAMD-AIG-AIMA%2FInstella&quot; target=&quot;_blank&quot;&gt;https://github.com/AMD-AIG-AIMA/Instella&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AMD 宣稱 Instella 代表着&quot;完全開放的最先進的 30 億參數語言模型 (LM)&quot;。這些模型是在 AMD Instinct MI300X GPU 上訓練的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;通過完全開源 Instella 模型，包括權重、訓練超參數、數據集和代碼，我們旨在促進人工智能社區內的創新與合作。&lt;/p&gt; 
 &lt;p&gt;我們相信，透明度、可重複性和可訪問性是人工智能研究與開發取得進展的關鍵驅動力。&lt;/p&gt; 
 &lt;p&gt;我們邀請開發人員、研究人員和人工智能愛好者探索 Instella，為其不斷改進獻計獻策，並與我們一起推動語言模型的發展。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根據 AMD 公佈的數據，其性能與 Llama 3.2 3B、Gemma-2 2B 和 Qwen 2.5 3B 等同類產品相比具有很強的競爭力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b27824412274c03ca53d1b47afaedf5831.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337263/amd-instella-3b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337263/amd-instella-3b</guid>
            <pubDate>Wed, 05 Mar 2025 07:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>智源開源多模態向量模型 BGE-VL</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;智源研究院宣佈聯合多所高校開發了多模態向量模型 BGE-VL，進一步擴充了原有生態體系。BGE-VL 在圖文檢索、組合圖像檢索等主要多模態檢索任務中均取得了最佳效果。&lt;/p&gt; 
&lt;p&gt;BGE-VL 藉助大規模合成數據 MegaPairs 訓練而成。這一設計具備以下兩大核心優勢:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;優異的可擴展性：&lt;/strong&gt;MegaPairs 結合多模態表徵模型、多模態大模型和大語言模型，在海量圖文語料庫中高效挖掘多模態三元組數據。其算法能夠以極低成本持續生成多樣化且高質量的多模態三元組。本次發佈的版本涵蓋 2600 萬條樣本，為多模態檢索模型的訓練提供了大規模、高價值的數據支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;卓越的數據質量：&lt;/strong&gt;相較於傳統人工標註數據，MegaPairs 僅需 1/70 的數據量即可實現更優的訓練效果。利用該合成數據，智源訓練了多模態檢索模型 BGE-VL，顯著提升了多個主流多模態檢索基準的性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;BGE-VL 的技術報告已發佈，相關數據、模型及代碼資源將陸續向社區全面開放。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.14475&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.14475&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;項目主頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FVectorSpaceLab%2FMegaPairs&quot; target=&quot;_blank&quot;&gt;https://github.com/VectorSpaceLab/MegaPairs&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBAAI%2FBGE-VL-MLLM-S1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BAAI/BGE-VL-MLLM-S1&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337258</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337258</guid>
            <pubDate>Wed, 05 Mar 2025 07:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>vivo OS 部門設立 AI 領域板塊</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbXnSMuj_jA5V9BeIDYuJkw&quot; target=&quot;_blank&quot;&gt;據雷鋒網獨家消息&lt;/a&gt;&lt;/u&gt;，vivo 近日進行了組織架構調整，其中其 AI 領域有了新的變動。&lt;/p&gt; 
&lt;p&gt;具體來看，vivo 原 OS 產品領域下將設立 AI 領域，人工智能一部、人工智能二部劃入 AI 領域。原互聯網平台運營領域總經理張飛被調任 AI 領域總經理，併兼管人工智能一部，無考察期，直接向公司副總裁、OS 產品領域負責人周圍彙報。而原人工智能一部總經理肖方旭已於 1 月份離職。&lt;/p&gt; 
&lt;p&gt;據 vivo 員工透露，公司在 AI 大模型方面投入巨大，前期管理意志幹預很重，可實際看來技術進展緩慢，此事早在去年內部就有過討論，最終結果是暫時不做商業化考覈，但暫停了對資金的投入。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;報道指出，目前 vivo 的大模型訓練重心正在向端側轉移，雲端的 700 億參數大語言模型還在微調和優化中，暫停了該模型的預訓練工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;公開資料顯示，vivo 每年都會投入 20-30 億用於大模型研發。截至 2024 年 10 月，vivo 在 AI 領域的投入已經超過 230 億元，且 AI 研究院的研發人員數量也從 2019 年的 1 千人增加至 2 千多人，是目前公開披露 AI 投入最高的手機廠商之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337257</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337257</guid>
            <pubDate>Wed, 05 Mar 2025 07:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信月活突破 10 億</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QuestMobile 近日發佈了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-mdl9gcCNmfLotd87SOIFg&quot; target=&quot;_blank&quot;&gt;2024 年度中國移動互聯網實力價值榜&lt;/a&gt;&lt;/u&gt;，TOP50 賽道用戶規模 NO.1 APP 如下。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2284&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152504_luN0_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本榜單體現了互聯網行業 50 個細分賽道的第一名，微信在即時通訊位列第一，&lt;strong&gt;月活唯一突破 10 億級，達到 10.8 億&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;綜合電商方面，淘寶以 9.6 億月活排名第一。短視頻方面的第一是抖音，月活 8.4 億。&lt;/p&gt; 
&lt;p&gt;從 50 個 APP 所屬的集團來看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;阿里旗下有 8 款：淘寶、高德地圖、支付寶、釘釘、閒魚、餓了麼、菜鳥、盒馬。&lt;/li&gt; 
 &lt;li&gt;騰訊旗下有 7 款：微信、搜狗輸入法、騰訊視頻、QQ 瀏覽器、酷狗音樂、王者榮耀、QQ 郵箱。&lt;/li&gt; 
 &lt;li&gt;字節旗下有 6 款：抖音、今日頭條、番茄免費小説、剪映、番茄暢聽、豆包。&lt;/li&gt; 
 &lt;li&gt;百度旗下有 2 款：百度、百度網盤。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;App 規模增長千萬級榜單如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1548&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152718_x9Xf_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前十名的千萬級體量 APP 增速排行榜中，字節旗下產品佔據七夕，分別是：抖音商城、豆包、悟空瀏覽器、紅果免費短劇、抖音精選、汽水音樂、番茄暢聽音樂版，可見字節流量之猛。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337256</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337256</guid>
            <pubDate>Wed, 05 Mar 2025 07:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌搜索測試「AI Mode」：整合多模態和實時信息、一鍵解答覆雜問題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌公司昨日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fai-mode-search%2F&quot; target=&quot;_blank&quot;&gt;發佈博文&lt;/a&gt;，邀請谷歌搜索用戶測試全新的&lt;strong&gt;「AI 模式」（AI Mode）&lt;/strong&gt;。用戶可以提出更復雜的問題，並基於搜索結果，AI 生成更詳細、更直觀的答案。&lt;/p&gt; 
&lt;p&gt;谷歌表示，AI 模式將提供更高級的推理、思考和多模態能力，幫助用戶更高效地獲取信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;540&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/150029_Fzwi_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;谷歌表示，以往用戶在處理複雜問題時，往往需要多次搜索才能解決，而「AI 模式」能夠解決這個痛點。用戶只需在桌面或移動設備上輸入查詢，點擊新的「AI 模式」按鈕即可體驗。&lt;/p&gt; 
&lt;p&gt;此外，AI 模式頁面底部還提供了「深入探索」快捷入口，用戶可直接跳過常規搜索結果，專注於 AI 生成的內容。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39952b2fa3ffbf6ae0dc3082083d80b34c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在移動設備上，用戶可以通過上傳圖片或語音輸入查詢，但目前僅支持文本輸出。AI 模式還支持歷史搜索記錄，方便用戶查看過往查詢。&lt;/p&gt; 
&lt;p&gt;AI 模式由定製版的 Gemini 2.0 驅動，能夠訪問實時數據源和知識圖譜等資源。它通過「查詢擴展」技術，從多個子主題和數據源中提取信息，並綜合呈現。如果信息不足，用戶將被引導至網頁搜索結果。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;案例 1：鳥類遷徙路徑&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶提問：「候鳥如何知道遷徙路線？」AI 模式會進行多步搜索並組織結果，在移動設備上以輪播形式展示來源網站，隨後提供簡明答案和相關文章。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 2：戶外拍攝最佳時間&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶詢問：「本週在波士頓公共花園拍攝戶外訂婚照的最佳時間是什麼？」AI 模式結合實時天氣信息，推薦具體日期和黃金時段，並註明日落時間。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 3：睡眠追蹤設備對比&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用戶提問：「智能戒指、智能手錶和追蹤墊在睡眠追蹤功能上有何區別？」AI 模式以對比表格形式呈現答案，並支持後續問題，如「深度睡眠時心率如何變化？」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;從早期測試來看，AI 模式的查詢長度是傳統搜索的兩倍，用戶有 25% 的時間會進行後續提問。谷歌計劃逐步向所有用戶開放這一功能，目前測試主要面向高級用戶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337252/google-ai-mode-search</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337252/google-ai-mode-search</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>