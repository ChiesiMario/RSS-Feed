<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 02 Sep 2025 12:45:54 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>AI 提升的是下限，而非上限</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近期，AI 提醒助手項目「Elroy」在其官網發佈了一篇名為&lt;em&gt;《AI 提升的是下限，而非上限》（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felroy.bot%2Fblog%2F2025%2F07%2F29%2Fai-is-a-floor-raiser-not-a-ceiling-raiser.html" target="_blank"&gt;AI is a Floor Raiser, not a Ceiling Raiser&lt;/a&gt;）&lt;/em&gt;的博客，探討了 AI 對於提升自我的一些利與弊。&lt;/p&gt; 
&lt;p&gt;文中提到，AI 能夠根據每個人的理解水平進行響應，解決了傳統教學內容「不能精準匹配學習者」這一痛點。它能隨時回答問題，甚至替用戶完成重複性任務，為初學者提供更友好的學習起點。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-783b1d370ee54c428e48a0d6a2a0124bb4e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b120252a3f52bb1aa8937f2f2bd1ee69923.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但同時，像「OpenAI 學習模式（Study Mode）」這樣的工具可能助長依賴性，因為學習者直接通過 AI 獲取答案，而不是真正理解知識結構，這樣的人最終可能止步於 AI 能覆蓋的水平。&lt;/p&gt; 
&lt;p&gt;對此，Elroy 的文章也指出，AI 帶來的影響，取決於「做出有影響力產品需要的精通程度」，其舉出了一點例子來更好分析這一情況：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對工程管理者而言，AI 能快速幫助他們上手不熟悉的框架或平台，讓想法迅速變為可運行產品。&lt;/li&gt; 
 &lt;li&gt;然而對於在複雜系統中工作的開發者，AI 缺乏對現有架構的深度理解和上下文感知，實際輔助有限。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同時，文中也提到了 AI 與藝術創意的關聯。雖然 AI 可以大量生成文本、圖像、音頻等，但因表現往往缺乏新意，在競爭激烈、創意要求高的領域（如小説、電影）難以取得成功。&lt;/p&gt; 
&lt;p&gt;文章強調，大眾容易識別雷同，例如因 4o 圖像生成器而流行一時的「吉卜力風」頭像，也未能影響《哈爾的移動城堡》的地位。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369939</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369939</guid>
      <pubDate>Tue, 02 Sep 2025 11:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>校方懷疑學生使用 AI 作弊，要求全員重考並接受現場答辯</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;新西蘭林肯大學一門研究生課程近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.stuff.co.nz%2Fnz-news%2F360802436%2Fone-slip-and-youre-guilty-universitys-unusual-ai-crackdown-rattles-students" target="_blank"&gt;引發了熱議&lt;/a&gt;&lt;strong&gt;：因懷疑部分學生在作業中使用了生成式 AI 工具，授課教師要求全班 115 名學生必須參加線下答辯重新考覈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/191258_4zKr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，該課程聚焦「大數據與人工智能」，教師發現作業中出現大量「高水準代碼」，懷疑學生不當使用生成式 AI 工具。&lt;/p&gt; 
&lt;p&gt;儘管承認個別學生可能具備編程能力，但大規模出現此類情況概率極低，因此決定讓全班重考：學生需現場編寫代碼、解釋作業思路，並接受即興問答，全程錄像。教師稱此舉為「保證公平性」，並強調「若代碼是自己寫的，就能解釋清楚；解釋不了則可能作弊」。&lt;/p&gt; 
&lt;p&gt;對於校方的處理方案，學生認為重考營造了「人人有嫌疑」的緊張氛圍，擔心因答錯一句被認定作弊。部分學生表示從未使用 AI，卻被迫參與重考，認為處理方式「反應過度」。&lt;/p&gt; 
&lt;p&gt;校方稱處理符合學術規範，課程大綱已明確 AI 使用規則，且政策允許在懷疑作弊時要求學生重新驗證。教務長強調重視學術誠信，目標是確保學生成果代表自身努力。&lt;/p&gt; 
&lt;p&gt;維多利亞大學 AI 專家認為，AI 普及是不可逆趨勢，高校需調整教學和考覈方式，如增加面對面講解作業、設置階段性檢查點，而非單純依賴線下考試。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369937</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369937</guid>
      <pubDate>Tue, 02 Sep 2025 11:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Solon 權限認證之 Sa-Token 的使用與詳解</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;本文詳細介紹了 Sa-Token 在 Java 項目中的使用方法，包括 Sa-Token 的基本概念、與其他權限框架的比較、基本語法和高級用法，並通過實例講解了如何在項目中集成和使用 Sa-Token 。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;作為一款輕量級 Java 權限認證框架，Sa-Token 在簡化權限管理、提高開發效率方面發揮了重要作用。本文還將深入探討 Sa-Token 的核心原理，通過內部代碼展示其工作機制。最後，總結了 Sa-Token 的優缺點及其在實際開發中的應用場景，為開發者提供全面的指導。&lt;/p&gt; 
&lt;h2&gt;一、Sa-Token 介紹&lt;/h2&gt; 
&lt;h3&gt;1. Sa-Token 簡介&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 是一款輕量級 Java 權限認證框架，旨在解決 Java Web 系統中常見的登錄認證、權限驗證、Session 會話、單點登錄等問題。其核心目標是以最簡潔的方式，實現強大的權限控制功能，幫助開發者快速完成權限系統的搭建。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 具有如下優勢：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;優勢&lt;/th&gt; 
   &lt;th&gt;描述&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;簡單易用&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;API 設計簡潔明瞭，易於集成和使用，上手快，學習成本低。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;功能豐富&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;支持多種權限控制需求，滿足複雜業務場景。支持登錄認證、權限驗證、角色驗證、Session 會話、多賬號體系等功能。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高性能&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;輕量級設計，對系統性能影響小。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高度可擴展&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;提供豐富的擴展接口，與 Spring、SpringBoot、Solon 等常用框架高度兼容，支持自定義持久化、註解方式驗證、單點登錄等高級特性。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;社區活躍&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;有良好的社區支持和文檔資源。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Sa-Token 原理解析&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 的核心原理是通過 Token 機制實現用戶的身份認證和權限校驗。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;其主要工作流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;登錄認證：用戶登錄成功後，服務器生成一個全局唯一的 Token，並將其返回給客戶端。&lt;/li&gt; 
 &lt;li&gt;Token 存儲：Token 與用戶身份信息的映射關係保存在服務器的會話中（如 Redis、內存等）。&lt;/li&gt; 
 &lt;li&gt;權限驗證：客戶端請求時攜帶 Token，服務器根據 Token 獲取用戶信息，驗證其權限是否滿足要求。&lt;/li&gt; 
 &lt;li&gt;會話管理：支持 Session 會話管理，可以獲取和操作當前會話的屬性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;流程圖例如下：&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//164ae7fe8293ac6902b135fd89299bdf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3. Sa-Token 與其他權限框架比較&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 與其他常見權限框架在學習成本、集成難度上有顯著優勢：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;特性&lt;/th&gt; 
   &lt;th&gt;Sa-Token&lt;/th&gt; 
   &lt;th&gt;Solon Auth&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;學習成本&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;功能豐富度&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;集成難度&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;性能表現&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;社區支持&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;活躍&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;一般&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;擴展性&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;中&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;二、Sa-Token 的基本語法&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在實際項目中，Sa-Token 通過簡單的配置和 API 調用，即可實現完整的權限管理功能。以下將通過一個完整的 Solon 示例，演示如何集成和使用 Sa-Token。&lt;/p&gt; 
&lt;h3&gt;1. 創建 Solon Web 項目&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;首先，創建一個新的 Solon 項目，可以使用 IDEA 的項目嚮導或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Fstart%2F" target="_blank"&gt;Solon Initializr&lt;/a&gt;。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入必要的依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;em&gt;&amp;lt;!-- Solon  Web --&amp;gt;&lt;/em&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-web&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;em&gt;&amp;lt;!-- Sa-Token 核心依賴 --&amp;gt;&lt;/em&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-solon-plugin&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 配置 Sa-Token：app.yml&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;em&gt;# Sa-Token 配置，可根據需要進行調整&lt;/em&gt;
&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;
  &lt;em&gt;# token 有效期，單位秒，默認 30 天&lt;/em&gt;
  &lt;span style="color:#986801"&gt;timeout:&lt;/span&gt; &lt;span style="color:#986801"&gt;2592000&lt;/span&gt;

  &lt;em&gt;# 是否打開二級登錄校驗&lt;/em&gt;
  &lt;span style="color:#986801"&gt;open-safe:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. 配置攔截器&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;創建配置類，添加 Sa-Token 的攔截器，以攔截請求並進行權限驗證。SaTokenConfig.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.solon.integration.SaTokenInterceptor;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Configuration;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Managed(index = -100)&lt;/span&gt; &lt;em&gt;//-100，是順序位（低值優先）&lt;/em&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; SaTokenInterceptor &lt;span style="color:#4078f2"&gt;saTokenInterceptor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenInterceptor&lt;/span&gt;(); &lt;em&gt;//用於支持規劃處理及註解處理&lt;/em&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. 登錄認證&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;創建登錄接口，實現用戶登錄功能。LoginController.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Param;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Post;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;LoginController&lt;/span&gt; {

    &lt;span style="color:#4078f2"&gt;@Post&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/login")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;login&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param&lt;/span&gt; String username, &lt;span style="color:#4078f2"&gt;@Param&lt;/span&gt; String password)&lt;/span&gt; {
        &lt;em&gt;// 1. 校驗用戶名和密碼（這裏模擬一個簡單的校驗）&lt;/em&gt;
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;.equals(username) &amp;amp;&amp;amp; &lt;span style="color:#50a14f"&gt;"123456"&lt;/span&gt;.equals(password)) {
            &lt;em&gt;// 2. 登錄，保存用戶 ID 為 10001&lt;/em&gt;
            StpUtil.login(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;);
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"登錄成功，Token："&lt;/span&gt; + StpUtil.getTokenValue();
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"用戶名或密碼錯誤"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;調用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.login(10001)&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，實現登錄操作，參數為用戶的唯一標識 ID。&lt;/li&gt; 
 &lt;li&gt;登錄成功後，可以通過&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.getTokenValue()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;獲取當前會話的 Token。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. 權限驗證&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;創建需要權限驗證的接口，例如獲取用戶信息的接口。UserController.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.annotation.SaCheckPermission;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Post;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#4078f2"&gt;@Mapping("/user")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;UserController&lt;/span&gt; {

    &lt;em&gt;// 查詢用戶信息，需登錄&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/info")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getUserInfo&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;em&gt;// 校驗是否登錄&lt;/em&gt;
        StpUtil.checkLogin();
        &lt;em&gt;// 獲取用戶 ID&lt;/em&gt;
        &lt;span style="color:#986801"&gt;int&lt;/span&gt; &lt;span style="color:#986801"&gt;userId&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.getLoginIdAsInt();
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"當前用戶信息，ID："&lt;/span&gt; + userId;
    }

    &lt;em&gt;// 修改用戶信息，需有權限"user:update"&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@SaCheckPermission("user:update")&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Post&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/update")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;updateUser&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"用戶信息更新成功"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.checkLogin()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法手動校驗登錄狀態。&lt;/li&gt; 
 &lt;li&gt;使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@SaCheckPermission("user:update")&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;註解，聲明該接口需要權限 user:update。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;6. 角色驗證&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;如果需要基於角色進行權限控制，可以使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@SaCheckRole&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;註解。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.annotation.SaCheckRole;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#4078f2"&gt;@Mapping("/admin")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;AdminController&lt;/span&gt; {

    &lt;em&gt;// 僅管理員角色可訪問&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@SaCheckRole("admin")&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/dashboard")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;adminDashboard&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"歡迎進入管理員控制枱"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;7. 自定義權限驗證邏輯&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;需要自定義獲取用戶權限和角色的邏輯，可以實現&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpInterface&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;接口。StpInterfaceImpl.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpInterface;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; java.util.ArrayList;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; java.util.List;

&lt;span style="color:#4078f2"&gt;@Managed&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;StpInterfaceImpl&lt;/span&gt; &lt;span style="color:#a626a4"&gt;implements&lt;/span&gt; &lt;span style="color:#c18401"&gt;StpInterface&lt;/span&gt; {

    &lt;em&gt;// 返回一個用戶所擁有的權限碼集合&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; List&amp;lt;String&amp;gt; &lt;span style="color:#4078f2"&gt;getPermissionList&lt;/span&gt;&lt;span&gt;(Object loginId, String loginKey)&lt;/span&gt; {
        &lt;em&gt;// 模擬從數據庫獲取權限&lt;/em&gt;
        List&amp;lt;String&amp;gt; permissionList = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;();
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt;(&lt;span style="color:#50a14f"&gt;"10001"&lt;/span&gt;.equals(loginId.toString())) {
            permissionList.add(&lt;span style="color:#50a14f"&gt;"user:update"&lt;/span&gt;);
            permissionList.add(&lt;span style="color:#50a14f"&gt;"user:delete"&lt;/span&gt;);
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; permissionList;
    }

    &lt;em&gt;// 返回一個用戶所擁有的角色標識集合 (權限與角色可分開校驗)&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; List&amp;lt;String&amp;gt; &lt;span style="color:#4078f2"&gt;getRoleList&lt;/span&gt;&lt;span&gt;(Object loginId, String loginKey)&lt;/span&gt; {
        &lt;em&gt;// 模擬從數據庫獲取角色&lt;/em&gt;
        List&amp;lt;String&amp;gt; roleList = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;();
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt;(&lt;span style="color:#50a14f"&gt;"10001"&lt;/span&gt;.equals(loginId.toString())) {
            roleList.add(&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; roleList;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;實現&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;getPermissionList&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，返回指定用戶的權限列表。&lt;/li&gt; 
 &lt;li&gt;實現&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;getRoleList&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，返回指定用戶的角色列表。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;8. 會話管理&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 提供了會話管理功能，可以在 Session 中存儲和獲取數據。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.session.SaSession;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;

&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;sessionDemo&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
    &lt;em&gt;// 獲取當前會話的 Session&lt;/em&gt;
    &lt;span style="color:#986801"&gt;SaSession&lt;/span&gt; &lt;span style="color:#986801"&gt;session&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.getSession();

    &lt;em&gt;// 存儲數據&lt;/em&gt;
    session.set(&lt;span style="color:#50a14f"&gt;"name"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"張三"&lt;/span&gt;);
    session.set(&lt;span style="color:#50a14f"&gt;"email"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"zhangsan@example.com"&lt;/span&gt;);

    &lt;em&gt;// 獲取數據&lt;/em&gt;
    &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;name&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; session.getString(&lt;span style="color:#50a14f"&gt;"name"&lt;/span&gt;);
    &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;email&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; session.getString(&lt;span style="color:#50a14f"&gt;"email"&lt;/span&gt;);

    &lt;em&gt;// 輸出&lt;/em&gt;
    System.out.println(&lt;span style="color:#50a14f"&gt;"姓名："&lt;/span&gt; + name);
    System.out.println(&lt;span style="color:#50a14f"&gt;"郵箱："&lt;/span&gt; + email);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;9. 踢人下線&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;可以通過用戶 ID 強制用戶下線。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 將用戶 ID 為 10001 的用戶踢下線&lt;/em&gt;
StpUtil.logoutByLoginId(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;);

&lt;em&gt;// 檢查用戶是否已被踢下線&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin();
System.out.println(&lt;span style="color:#50a14f"&gt;"用戶是否登錄："&lt;/span&gt; + isLogout);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;10. 註銷登錄&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;用戶主動註銷登錄，可以調用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.logout()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 註銷登錄&lt;/em&gt;
StpUtil.logout();

&lt;em&gt;// 檢查登錄狀態&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogin&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin();
System.out.println(&lt;span style="color:#50a14f"&gt;"用戶是否登錄："&lt;/span&gt; + isLogin);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、Sa-Token 的高級用法&lt;/h2&gt; 
&lt;h3&gt;1. 自定義持久化&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 默認使用內存來存儲 Token 信息，在分佈式環境中，可以使用 Redis 作為持久化介質。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入 Redis 依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-redisx&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-snack3&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 Redis Dao 連接信息：app.yml&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;  &lt;em&gt;# 不同的擴展插件，配置可能會不同&lt;/em&gt;
  &lt;span style="color:#986801"&gt;dao:&lt;/span&gt;
    &lt;span style="color:#986801"&gt;server:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"localhost:6379"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;password:&lt;/span&gt; &lt;span style="color:#986801"&gt;123456&lt;/span&gt;
    &lt;span style="color:#986801"&gt;db:&lt;/span&gt; &lt;span style="color:#986801"&gt;1&lt;/span&gt;
    &lt;span style="color:#986801"&gt;maxTotal:&lt;/span&gt; &lt;span style="color:#986801"&gt;200&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 Redis 持久化：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.dao.SaTokenDao;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.dao.SaTokenDaoForRedisx;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Configuration;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenDaoConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Managed&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; SaTokenDao &lt;span style="color:#4078f2"&gt;saTokenDaoInit&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Inject("${sa-token.dao}")&lt;/span&gt; SaTokenDaoForRedisx saTokenDao)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; saTokenDao;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 單點登錄（SSO）&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 提供了 SSO 模塊，可以快速實現單點登錄功能。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入 SSO 依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-sso&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 SSO 相關參數：app.yml&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;
  &lt;span style="color:#986801"&gt;sso-client:&lt;/span&gt;
    &lt;span style="color:#986801"&gt;client:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;demo-app&lt;/span&gt;
    &lt;span style="color:#986801"&gt;server-url:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;http://sso-server.com&lt;/span&gt;
    &lt;span style="color:#986801"&gt;is-http:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;true&lt;/span&gt;
    &lt;span style="color:#986801"&gt;secret-key:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;SSO-C3-kQwIOrYvnXmSDkwEiFngrKidMcdrgKor&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. OAuth2.0 支持&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;&lt;code&gt;Sa-Token&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;也支持&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;協議，可以實現與第三方平台的對接。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-oauth2&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;參數和實現授權流程（此處略，具體可參考官方文檔）。&lt;/p&gt; 
&lt;h3&gt;4. 多賬號體系&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;如果系統中存在多種身份的用戶，例如普通用戶、管理員、商家等，可以使用多賬號體系進行區分。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;登錄指定賬號體系：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 管理員登錄，loginKey 為"admin"&lt;/em&gt;
StpUtil.login(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;檢查登錄狀態：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 檢查當前賬號體系下是否登錄&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogin&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin(&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;權限驗證：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 在指定賬號體系下進行權限驗證&lt;/em&gt;
StpUtil.checkPermission(&lt;span style="color:#50a14f"&gt;"user:update"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;四、Sa-Token 使用總結&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 是一款輕量級的 Java 權限認證框架，因其簡單易用和功能豐富而備受開發者青睞。它以簡潔明瞭的 API 設計，使得集成和使用變得非常方便，開發者可以快速上手，降低了學習成本。Sa-Token 支持多種權限控制需求，滿足複雜業務場景，包括登錄認證、權限驗證、角色驗證、Session 會話、多賬號體系等功能，全面覆蓋了權限管理的各個方面。其輕量級的設計對系統性能影響小，適用於高併發的應用環境。此外，Sa-Token 提供了豐富的擴展接口，與 Spring、SpringBoot、Solon 等常用框架高度兼容，支持自定義持久化、註解方式驗證、單點登錄等高級特性，方便開發者根據項目需求進行定製開發。活躍的社區支持和豐富的文檔資源也使得開發者能夠輕鬆獲取幫助和指導。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;由於這些優勢，Sa-Token 非常適 Web 項目的快速開發和微服務架構下的權限管理。當項目需要快速搭建權限系統時，選擇 Sa-Token 是一個理想的方案。然而，在使用過程中需要注意 Token 的安全性，防止泄露帶來風險；對於高併發場景，建議使用 Redis 等持久化介質來提高系統性能和擴展性；同時，關注 Sa-Token 的版本更新，及時獲取新功能和安全補丁，以確保系統的安全性和穩定性。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;此文參考自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnblogs.com%2Fliuguangzhi%2Farticles%2F18415627" target="_blank"&gt;https://www.cnblogs.com/liuguangzhi/articles/18415627&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369936</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369936</guid>
      <pubDate>Tue, 02 Sep 2025 11:12:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>快手發佈工業級規模強化學習 (RL) 訓練框架 SeamlessFlow</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手 Kwaipilot 團隊近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_pewU-ZtVhhEpJVebwKysQ" target="_blank"&gt;發佈&lt;/a&gt;了 SeamlessFlow 技術報告，SeamlessFlow 是該團隊所使用的工業級規模強化學習（RL）訓練框架。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1436" src="https://static.oschina.net/uploads/space/2025/0902/184001_9a1i_2720166.png" width="2762" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，該框架通過創新的數據平面架構，對 RL 的訓練邏輯和 Agent 做了徹底解耦，用以支持多智能體、在線強化學習訓練等複雜場景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184245_Kuc6_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更進一步，針對 RL 計算資源分配問題，團隊提出了「標籤分配機制」，統一了該領域最廣泛的兩種設計模式（訓推共卡、訓推分離）。以標籤分配的思路為出發點，在業界首個提出「時空複用 pipeline」，實現了在訓推分離的異構集羣上徹底消除 Pipeline Bubble 的效果。&lt;/p&gt; 
&lt;p&gt;在實際測試中，SeamlessFlow 的端到端 token 吞吐量相比基線提升 100%，整體訓練時間減少 62%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184306_P1R7_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184325_U9bF_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳細內容查看技術報告：&lt;em&gt;https://arxiv.org/abs/2508.11553&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369933</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369933</guid>
      <pubDate>Tue, 02 Sep 2025 10:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Salesforce 裁員 4000 人，引入 AI 代理</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;作為一家知名的客戶關係管理（CRM）平台，Salesforce 近日宣佈其客戶支持團隊從 9000 人減少至約 5000 人。這一變化是由於公司推出了新的代理服務和支持產品。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="325" src="https://oscimg.oschina.net/oscnet/up-7cb3d84925fce813c55404c48eaee49bc24.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Salesforce 的首席執行官馬克・貝尼奧夫（Marc Benioff）在最近的一次播客中透露，公司自稱為該工具的 「客戶零」(customer zero)，並表示這一系統已經成功處理了約 150 萬次客戶對話，而在相同的時間段內，人工支持代理的對話數量大致相同。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;貝尼奧夫強調，人工智能的引入不僅僅是為了降低成本，更是為了提高公司的收入。他指出，Salesforce 在過去 26 年中積累了超過 1 億個未處理的潛在客戶，主要是由於人員不足。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;現在，藉助新的代理銷售系統，Salesforce 能夠聯繫到每一個潛在客戶，每週進行超過 1 萬次的對話。這一措施使得 Salesforce 的市場響應能力顯著提高，同時為公司創造了新的商機。未來，Salesforce 希望能通過不斷優化和改進其 AI 系統，進一步增強公司的競爭力，實現更大的商業成功。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369931</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369931</guid>
      <pubDate>Tue, 02 Sep 2025 10:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>把 DolphinScheduler 搬進 K8s：奇虎 360 商業化 900 天踩坑全記錄</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/qi-hu.png" alt="奇虎" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;👋 大家好，我是遠朋。過去 3 年，我們團隊把部分調度任務從 Azkaban 逐步遷移到 DolphinScheduler，並開展了 K8s 容器化。今天把踩過的坑、攢下的經驗一次性覆盤，建議收藏！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;作者介紹&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/wang-yuan-peng.jpg" alt="王遠朋" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王遠朋&lt;/strong&gt; 上海奇虎科技有限公司，數據專家，商業化 SRE &amp;amp; 大數據團隊核心成員，長期負責 DolphinScheduler 在生產環境的部署與優化，具備豐富的容器化與大數據調度經驗。&lt;/p&gt; 
&lt;p&gt;在大數據任務調度的日常工作中，Apache DolphinScheduler 已經成為我們團隊最核心的工具之一。過去我們一直依賴物理機進行部署，例如 3.1.9 版本仍運行在&lt;strong&gt;物理機&lt;/strong&gt;環境中，但這種方式在彈性擴展、資源隔離和運維效率上逐漸暴露出問題。隨着公司整體的雲原生戰略推進，我們最終在 2025 年將 DolphinScheduler 升級到 3.2.2，並部分遷移到 &lt;strong&gt;Kubernetes 平台&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;遷移的動機非常明確：首先是&lt;strong&gt;彈性擴容&lt;/strong&gt;，K8S 可以根據任務高峯快速擴展 Worker 節點；其次是&lt;strong&gt;資源隔離&lt;/strong&gt;，避免不同任務相互影響；再者是&lt;strong&gt;自動化部署與回滾&lt;/strong&gt;，大幅降低維護成本；最後，也是最重要的一點，這一切符合公司在技術層面的&lt;strong&gt;雲原生方向&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;鏡像構建：從源碼到模塊&lt;/h3&gt; 
&lt;p&gt;在遷移過程中，鏡像構建是第一步。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563633473102.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們先準備了一個包含 Hadoop、Hive、Spark、Flink、Python 等環境的基礎鏡像，然後在此基礎上構建 DolphinScheduler 的基礎鏡像，將重新編譯的各個模塊和 MySQL 驅動打包其中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634307756.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這裏需要注意的是，MySQL 被用作 DolphinScheduler 的元數據存儲，因此驅動包必須軟鏈到每一個模塊，包括 &lt;code&gt;dolphinscheduler-tools&lt;/code&gt;、&lt;code&gt;dolphinscheduler-master&lt;/code&gt;、&lt;code&gt;dolphinscheduler-worker&lt;/code&gt;、&lt;code&gt;dolphinscheduler-api&lt;/code&gt; 和 &lt;code&gt;dolphinscheduler-alert-server&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563635065036.jpg" alt="" referrerpolicy="no-referrer"&gt; Worker 鏡像&lt;/p&gt; 
&lt;p&gt;模塊鏡像則是在 DS 基礎鏡像之上進行定製，主要修改端口和配置。為了減少後續配置文件的改動，我們儘量保持模塊鏡像的名稱與官方一致。構建時既可以單獨構建某個模塊，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build.sh worker-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634594536.jpg" alt="" referrerpolicy="no-referrer"&gt; 單獨構建鏡像&lt;/p&gt; 
&lt;p&gt;也可以批量構建所有模塊：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build-all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634803090.jpg" alt="" referrerpolicy="no-referrer"&gt; 批量構建鏡像&lt;/p&gt; 
&lt;p&gt;這一步裏我們遇到的典型問題包括：&lt;strong&gt;基礎鏡像過大導致構建時間過長，源碼改造後的 jar 包沒有覆蓋舊文件，甚至不同模塊的端口配置和啓動腳本不一致。&lt;/strong&gt; 這些細節如果處理不當，就會在後續部署階段帶來一系列棘手的問題。&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;問題&lt;/th&gt; 
   &lt;th&gt;解決方案&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;基礎鏡像過大、構建慢&lt;/td&gt; 
   &lt;td&gt;把公共軟件層拆成多階段構建緩存&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MySQL 驅動找不到&lt;/td&gt; 
   &lt;td&gt;建軟鏈到所有模塊 &lt;code&gt;lib/&lt;/code&gt; 目錄&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;自編譯 Jar 沒覆蓋舊包&lt;/td&gt; 
   &lt;td&gt;build.sh 里加 &lt;code&gt;find -name "*.jar" -delete&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;部署方案：從自制 YAML 到官方 Helm Chart&lt;/h3&gt; 
&lt;p&gt;在部署初期，我們是手寫 YAML 文件來完成部署的，但這種方式在配置分散和升級維護上成本極高。後來我們改用了官方提供的 Helm Chart，這樣配置集中管理，升級也更方便。&lt;/p&gt; 
&lt;p&gt;我們使用的 K8S 集羣版本是 v1.25，部署時需要先創建命名空間 &lt;code&gt;dolphinscheduler&lt;/code&gt;，然後拉取 helm 包，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm pull oci://registry-1.docker.io/apache/dolphinscheduler-helm --version 3.2.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在真正落地過程中，&lt;code&gt;values.yaml&lt;/code&gt; 是最核心的文件，我們在這裏踩過很多坑。下面貼出幾個關鍵配置片段，供大家參考：&lt;/p&gt; 
&lt;h4&gt;1. 鏡像配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;image:
  registry: my.private.repo
  repository: dolphinscheduler
  tag: 3.2.2
  pullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 提示：一些前置的工具鏡像最好提前 push 到私有倉庫，避免因網絡或鏡像源問題導致部署失敗。&lt;/p&gt; 
&lt;h4&gt;2. 外置數據庫配置（MySQL）&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mysql:
  enabled: false   # 關閉內置 MySQL
externalMysql:
  host: mysql.prod.local
  port: 3306
  username: ds_user
  password: ds_password
  database: dolphinscheduler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 內置數據庫務必關閉，生產環境統一接入外部 MySQL（未來我們將切換到 PostgreSQL）。&lt;/p&gt; 
&lt;h4&gt;3. LDAP 登錄認證&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;ldap:
  enabled: true
  url: ldap://ldap.prod.local:389
  userDn: cn=admin,dc=company,dc=com
  password: ldap_password
  baseDn: dc=company,dc=com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 我們接入了公司 LDAP，統一用戶認證，方便權限管理。&lt;/p&gt; 
&lt;h4&gt;4. 共享存儲配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sharedStoragePersistence:
  enabled: true
  storageClassName: nfs-rwx
  size: 100Gi
  mountPath: /dolphinscheduler/shared
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 注意：storageClassName 必須支持 &lt;code&gt;ReadWriteMany&lt;/code&gt;，否則多個 Worker 節點無法同時訪問共享目錄。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563644421212.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;5. HDFS 配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;hdfs:
  defaultFS: hdfs://hdfs-nn:8020
  path: /dolphinscheduler
  rootUser: hdfs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 所有大數據相關組件路徑需要提前準備好，例如 &lt;code&gt;/opt/soft&lt;/code&gt;。&lt;/p&gt; 
&lt;h4&gt;6. Zookeeper 配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;zookeeper:
  enabled: false   # 關閉內置 ZK
externalZookeeper:
  quorum: zk1.prod.local:2181,zk2.prod.local:2181,zk3.prod.local:2181
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 使用外置 Zookeeper 時，記得關閉內置配置，同時確認 ZK 版本符合官方最低要求。&lt;/p&gt; 
&lt;h3&gt;踩坑經驗與維護挑戰&lt;/h3&gt; 
&lt;p&gt;在整個遷移過程中，我們踩過的坑不少。比如，鏡像製作問題、Helm values.yaml 修改的坑，以及定製化升級和維護成本過高等。&lt;/p&gt; 
&lt;h4&gt;鏡像製作相關問題&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;鏡像製作時因為基礎鏡像太大，導致構建過程漫長；&lt;/li&gt; 
 &lt;li&gt;模塊依賴差異導致重複安裝；&lt;/li&gt; 
 &lt;li&gt;有時候 MySQL 驅動包路徑不正確，模塊啓動時報錯；&lt;/li&gt; 
 &lt;li&gt;源碼改造後的 jar 包忘記覆蓋舊文件，也曾造成過運行時異常，不同模塊端口與啓動腳本不一致，導致啓動不順利。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Helm values.yaml 注意點&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;sharedStoragePersistence.storageClassName 必須支持 ReadWriteMany 存儲類&lt;/li&gt; 
 &lt;li&gt;storage 大小&lt;/li&gt; 
 &lt;li&gt;mountPath 與配置文件不一致&lt;/li&gt; 
 &lt;li&gt;配置項路徑縮進&lt;/li&gt; 
 &lt;li&gt;關閉默認配置以及一些不需要的配置，例如 Zookeeper 外置時需關閉內置選項，同時注意 zk 需要的版本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;維護升級成本&lt;/h4&gt; 
&lt;p&gt;更大的挑戰來自後續維護。因為我們對源碼和鏡像做過定製化修改，所以每當 DolphinScheduler 發佈新版本，我們都需要重新對比修改點，重新構建並測試全部模塊鏡像。&lt;/p&gt; 
&lt;p&gt;同時，由於不同版本之間配置項差異較大，升級和回滾的過程都容易出錯。這些問題導致我們的升級週期變長，維護難度加大，團隊人力成本也顯著上升。&lt;/p&gt; 
&lt;h3&gt;未來規劃與思考&lt;/h3&gt; 
&lt;p&gt;為了降低長期的運維成本，我們已經在逐步推進標準化。未來計劃包括： 將 DolphinScheduler 的元數據庫從 MySQL 切換到 PostgreSQL，全面採用社區官方鏡像而非自研鏡像，生產任務也會逐步遷移到 K8S 環境中。&lt;/p&gt; 
&lt;p&gt;同時，我們會引入 CI/CD 流程，並結合 Prometheus 與 Grafana 做可觀測性建設，提升部署效率與監控能力。&lt;/p&gt; 
&lt;p&gt;總的來説，K8S 部署讓 DolphinScheduler 在擴展性、彈性和遷移性上具備了遠超物理機的優勢。雖然鏡像定製化和配置修改帶來了不小的挑戰，但隨着我們逐漸迴歸社區版本和標準化運維，維護成本會越來越低，部署效率會越來越高。&lt;/p&gt; 
&lt;p&gt;我們的長期目標，是構建一個高可用、易擴展、統一化的調度平台，真正釋放雲原生的價值。如果你也在考慮把調度系統搬上 K8s，歡迎評論區交流，或加入 DolphinScheduler 社區一起搬磚！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563644922397.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/dailidong/blog/18690374</link>
      <guid isPermaLink="false">https://my.oschina.net/dailidong/blog/18690374</guid>
      <pubDate>Tue, 02 Sep 2025 10:27:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Kuscia - 基於 K3s 的輕量級隱私計算任務編排框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;Kuscia（Kubernetes-based Secure Collaborative InfrA）是一款基於 K3s 的輕量級隱私計算任務編排框架，旨在屏蔽異構基礎設施和協議，並提供統一的隱私計算底座。&lt;/p&gt;

&lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;通過 Kuscia：&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;輕量化部署：你可以用最低 1C2G 的資源完成 100W 級數據隱私求交 (PSI)。&lt;/li&gt;
&lt;li&gt;跨域網絡安全通信：可以實現多隱私計算任務併發執行時的端口複用（僅需一個公網端口）與安全通信。&lt;/li&gt;
&lt;li&gt;統一的 API 接口：可以使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.secretflow.org.cn/zh-CN/docs/kuscia/main/reference/apis/summary_cn"&gt;HTTP/GRPC API 接口&lt;/a&gt;&lt;/span&gt;集成隱私計算能力。&lt;/li&gt;
&lt;li&gt;互聯互通：可以與行業內多種隱私計算系統進行互聯互通。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;更多 Kuscia 的能力介紹，可參考&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.secretflow.org.cn/zh-CN/docs/kuscia/main/reference/overview"&gt;Kuscia 概述&lt;/a&gt;&lt;/span&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="377" src="https://static.oschina.net/uploads/space/2025/0829/154436_QAD6_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/kuscia</link>
      <guid isPermaLink="false">https://www.oschina.net/p/kuscia</guid>
      <pubDate>Tue, 02 Sep 2025 10:18:00 GMT</pubDate>
    </item>
    <item>
      <title>清華與東北大學聯合推出 UltraRAG 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;清華大學 THUNLP 實驗室、東北大學 NEUIR 實驗室與 OpenBMB 及 AI9Stars 聯合發佈了 UltraRAG2.0，這是首個基於 Model Context Protocol（MCP）架構設計的檢索增強生成 (RAG) 框架。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該框架致力於簡化 RAG 系統的構建過程，使科研人員可以在短時間內實現複雜的多階段推理系統。UltraRAG2.0 的亮點在於用戶只需通過編寫 YAML 文件，即可輕鬆聲明覆雜的邏輯，如串行、循環和條件分支，從而顯著減少代碼量，降低實現的門檻。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在當前的 RAG 發展趨勢中，許多系統逐漸融入了自適應知識組織、多輪推理及動態檢索等複雜特性，代表項目包括 DeepResearch 和 Search-o1。然而，這些複雜特性也給開發者帶來了高昂的工程成本，制約了新想法的快速迭代與復現。UltraRAG2.0 應運而生，它通過將 RAG 的核心組件封裝為獨立的 MCP 服務器，實現了功能的靈活調用和擴展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;具體而言，與以往的實現方式相比，UltraRAG2.0 在代碼量上大幅減少。例如，經典方法 IRCoT 的官方實現需要近 900 行代碼，而使用 UltraRAG2.0 只需約 50 行代碼就能完成同等功能。其中一半的代碼是用於流程編排的 YAML 偽代碼，極大降低了開發門檻。框架支持通過簡潔的聲明式方式來構建多階段推理流程，使得複雜的推理邏輯不再需要冗長的手動編碼。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-8ffdf7ae1633d0f30510d1cb66672338fbe.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;UltraRAG2.0 還支持動態檢索、條件判斷及多輪交互等&lt;span&gt;高級&lt;/span&gt;功能，科研人員可以在短時間內搭建出高性能的實驗平台，滿足複雜多跳問題的需求。其性能較傳統的 Vanilla RAG 提升約 12%。該系統的設計旨在讓研究者在工程實現方面節省時間和精力，將更多的注意力放在算法創新和實驗設計上。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，UltraRAG2.0 的 MCP 架構允許不同模塊間的無縫複用，並支持模塊的靈活擴展和接入，方便科研人員快速適配新的模型和算法。這一設計極大提升了系統開發的效率和可復現性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369915</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369915</guid>
      <pubDate>Tue, 02 Sep 2025 09:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>這款全新的 Linux 桌面發行版幾乎與 OS X 如出一轍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Gershwin 是一款正在開發中的全新開源 Linux 桌面環境，目標是在 BSD 與 Arch Linux 上帶來類似 macOS 的使用體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-86d4824b0345ee3351031cb07530c092dda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5f1b49d23ae230a85b749ebeb383dd209f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;em&gt;https://github.com/gershwin-desktop/gershwin-desktop&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Gershwin 基於 GnuStep，而 GnuStep 本身源自 NeXTStep（macOS 的前身），因此界面風格自然與 OS X 十分接近。不過，由於 GnuStep 的老派設計，&lt;strong&gt;Gershwin 更像是「復古版 macOS」，看起來更接近早期的 OS X&lt;/strong&gt;，而非現代的 macOS。&lt;/p&gt; 
&lt;p&gt;目前 Gershwin 仍處於早期 alpha 階段，功能有限：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;應用程序通過 Dock 管理，而非桌面圖標；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;應用啓動器尚不穩定，運行程序常需手動調用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最穩定的體驗方式是通過 GhostBSD 運行，也能在 Arch Linux 上安裝，但不推薦。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;雖然現階段實用性不足，但 Gershwin 展現了獨特潛力：一個兼具懷舊感與現代性，的桌面環境。如果開發順利推進，它有望成為 BSD/Linux 用戶的另類選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369912</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369912</guid>
      <pubDate>Tue, 02 Sep 2025 09:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技宣佈將在四季度提交 IPO 申請</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技在社交媒體上發帖稱，預計將在 2025 年 10 月至 12 月期間向證券交易所提交上市申請文件，屆時公司的相關運營數據將正式披露。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="652" src="https://oscimg.oschina.net/oscnet/up-adeb6b500a9f884cfa342d939c1ffff851d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技表示，以 2024 年為例，四足機器人、人形機器人和組件產品的銷售額分別佔約 65%、30% 和 5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其中，約 80% 的四足機器人被應用於研究、教育和消費領域，而剩餘的 20% 則被用於工業領域，如檢查與消防。人形機器人完全用於研究、教育和消費領域。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369909</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369909</guid>
      <pubDate>Tue, 02 Sep 2025 09:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 文件系統 Btrfs 長期貢獻者退出內核項目，加入 Anthropic</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Josef Bacik 是長期參與 Btrfs 文件系統開發的資深工程師，他在 2025 年 8 月 29 日宣佈離開 Meta（原 Facebook），選擇加入 AI 公司 Anthropic，投身 AI 基礎設施事業，並不再將 Linux 內核開發作為主要職業方向。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b2d57c0b86cc532363c44a3c1f2bebc2583.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Josef Bacik 説道，下週我將開啓新篇章，加入 Anthropic，協助其擴展基礎設施；&lt;strong&gt;這也是我職業生涯中第一次不再以內核開發為主的工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Next week I start a new chapter, I will be joining Anthropic to help them scale out their infrastructure … I will be stepping back from kernel development as my primary job for the first time in my career.」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Josef Bacik 對曾經所在團隊表達了高度認可，也坦言時間到了該進入新階段，他希望運用自己在內核與系統方面的多年經驗，協助 Anthropic 擴展基礎設施。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369907</guid>
      <pubDate>Tue, 02 Sep 2025 09:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 與 Scale AI 合作現裂痕</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自今年 6 月以來，儘管 Meta 向數據標註公司 Scale AI 投資了高達 143 億美元，並聘請其首席執行官 Alexandr Wang 等高管加盟 Meta Superintelligence Labs （MSL），但雙方的關係似乎正面臨挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;核心問題源於數據質量的爭議。儘管進行了鉅額投資，但消息人士透露，Meta 核心 AI 部門 TBD Labs 的研究人員普遍認為 Scale AI 的數據質量不佳，更傾向於與 Scale AI 的主要競爭對手 Mercor 和 Surge 合作。Meta 的 TBD Labs 在成立前就已與這兩家公司有合作，但向一家數據供應商投入如此巨資後，仍然依賴其競爭對手的情況十分罕見。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-949f1f529dd7a49117f6b1fcb77a8d33a02.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這種現象背後反映出數據標註行業的變化。早期，Scale AI 的眾包模式依賴低成本勞動力處理簡單任務，但隨着 AI 模型複雜化，需要醫生、律師等高技能領域專家來提供高質量數據。儘管 Scale AI 推出了 Outlier 平台，但像 Mercor 和 Surge 這樣從一開始就建立在高薪人才模式上的競爭對手正迅速崛起。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了商業合作上的緊張，雙方的人事整合也遭遇挫折。Scale AI 前高管 Ruben Mayer 在加入 Meta 僅兩個月後便離職，進一步引發外界關注。儘管 Mayer 表示是因「個人原因」離開，且對在 Meta 的工作經歷感到滿意，但他對自己在 Meta 的職責定位與內部消息人士的説法存在分歧。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Meta 的 AI 部門也面臨人才流失問題。有前員工和現任員工透露，自從引入 Alexandr Wang 和一批來自 OpenAI 等公司的人才後，Meta 的 AI 部門變得混亂。新加入的人員對大公司的官僚作風感到沮喪，而 Meta 原有的 GenAI 團隊則感到能力受限。MSL AI 研究員 Rishabh Agarwal 等多名核心員工近期相繼離職，這給 Meta 的 AI 發展前景蒙上陰影。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這次投資被普遍認為是 Meta CEO 扎克伯格在 Llama4 發佈平淡後，為追趕 OpenAI 和谷歌而採取的緊急舉措。他不僅吸納了 Alexandr Wang，還積極從 OpenAI、谷歌 DeepMind 等公司招募頂尖人才。然而，鑑於部分新員工的迅速離職以及內部團隊的混亂，Meta 能否穩定其 AI 運營並留住人才，仍是一個懸而未決的問題。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369898</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369898</guid>
      <pubDate>Tue, 02 Sep 2025 08:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源操作系統框架 Genode OS 發佈 25.08 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源操作系統框架 Genode OS 發佈了 25.08 版本，引入了新的內核調度器以實現公平性和低延遲，探索了 XML 的替代方案，優化了塊存儲堆棧，並將所有基於 Linux 的 PC 驅動程序更新至內核版本 6.12。&lt;/p&gt; 
&lt;p&gt;此外，該版本還為最新版本 13.0 的 seL4 微內核解鎖了更多動態場景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-843a3a17acca0079fa8555dc66189112455.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;核心調度器（Kernel Scheduler）重構：優化公平性與延遲&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新版本對 Genode OS 中的內核調度器進行了全面重構，尤其為其通用操作系統 Sculpt OS 考量了動態工作負載的需求，優化了任務調度的公平性與響應延遲。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;塊存儲層（Block Layer）改進&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對塊存儲子系統進行了多項優化，包括精簡數據路徑、提升 I/O 性能。這些改進通過整體優化塊存儲棧，減少中間組件（如分區管理模塊）的參與，增強了多隊列硬件支持能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux 驅動更新至 Kernel 6.12 LTS&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genode 的 Linux 驅動組件——在其 Linux 驅動環境中使用的驅動程序均已升級，基於 Linux 6.12 LTS 源代碼，對硬件兼容性和穩定性進行了增強。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;兼容 seL4 微內核：支持 seL4 版本 13.0&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genode 持續擴展其對 seL4 微內核的支持。此版本中，已將 seL4 內核更新到最新 13.0 版本，並解決了先前存在的可擴展性瓶頸，尤其改善了動態場景（如插拔式驅動加載）下的表現。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;探索 XML 的替代語法&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為了改進配置與報告流程，新版本引入了對 XML 的替代語法支持，允許配置文件逐步從 XML 切換到更輕量的形式，並支持與 XML 之間的互操作性，這一思路已規劃超過兩年，本次進入實用評估階段。&lt;/p&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;em&gt;https://genode.org/documentation/release-notes/25.08&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369887</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369887</guid>
      <pubDate>Tue, 02 Sep 2025 08:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Agent 架構綜述：從 Prompt 到 Context</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;div&gt;
   資料來源： 
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" rel="nofollow" target="_blank"&gt;火山引擎-開發者社區&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   背景 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在觀察去年以來對於「Prompt Engineering」的解構時，我們可以觀察到一個微妙但重要的分歧。&lt;br&gt; 一方面，專注於構建可擴展系統的前沿實踐者們（如 Andrej Karpathy 等），積極倡導用 「Context Engineering」 來描述工作，認為 「Prompt Engineering」 這個詞不足以涵蓋複雜性，認為它只是 「Coming up with a laughably pretentious name for typing in the chat box（給在聊天框裏打字起的一個可笑的自命不凡的名字）」 。因為他們構建 Agent 系統的核心挑戰並非僅僅是 Prompt，而是設計整個數據流以動態生成最終提示的架構。&lt;br&gt; 另一方面，近年來學術和正式文獻傾向用 「Prompt Engineering」 作為一個廣義的 umbrella term（傘形術語），其定義包括了 「Supporting content」 或 「Context」，把所有在不改變模型權重的前提下操縱模型輸入的技術歸為同一類型。&lt;br&gt; 術語上的分歧可以反映該領域的成熟過程：隨着 AI 應用從簡單的單次交互發展到複雜的、有狀態的智能體系統，優化靜態指令已經無法滿足需求。因此，「Context Engineering」 的出現，是為了區分兩種不同層次的活動：一是編寫指令的 skill，二是構建自動化系統以為該指令提供成功所需信息的科學。&lt;br&gt; （本文明確，儘管在學術上 Prompt Engineering 可能涵蓋上下文，但在工程實踐中，Context Engineering 是專注於如何動態構建和管理上下文的專門學科）&lt;br&gt; 重新定義 Agent 數據流：Context is All Aou Need&lt;br&gt; 本部分旨在建立 Prompt Engineering 與 Context Engineering 的基礎概念，清晰地界定二者之間的區別與聯繫。&lt;br&gt; 從前者到後者的轉變，代表了人工智能應用開發領域一次關鍵的演進——從業界最初關注的戰術性指令構建，轉向由可擴展、高可靠性系統需求驅動的戰略性架構設計。&lt;br&gt; Prompt Engineering - the Art of Instructions&lt;br&gt; Prompt Engineering 是與大型語言模型（LLM）交互的基礎，其核心在於精心設計輸入內容，以引導模型生成期望的輸出。這一實踐為理解 Context Engineering 的必要性提供了基準。&lt;br&gt; 定義&lt;br&gt; 一個提示（Prompt）遠不止一個簡單的問題，它是一個結構化的輸入，可包含多個組成部分 。這些組件共同構成了與模型溝通的完整指令：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;指令（Instructions）：對模型的核心任務指令，明確告知模型需要執行什麼操作 。&lt;/li&gt; 
   &lt;li&gt;主要內容/輸入數據（Primary Content/Input Data）：模型需要處理的文本或數據，是分析、轉換或生成任務的對象 。&lt;/li&gt; 
   &lt;li&gt;示例（Examples/Shots）：演示期望的輸入-輸出行為，為模型提供「上下文學習」（In-Context Learning）的基礎 。&lt;/li&gt; 
   &lt;li&gt;線索/輸出指示器（Cues/Output Indicators）：啓動模型輸出的引導性詞語，或對輸出格式（如 JSON、Markdown）的明確要求 。&lt;/li&gt; 
   &lt;li&gt;支持性內容（Supporting Content/Context）：為模型提供的額外背景信息，幫助其更好地理解任務情境。正是這一組件，構成了 Context Engineering 發展的概念萌芽。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//6b223aea32c1b5b372958001ce21ce5e.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Prompt Engineering 的核心技術&lt;br&gt; Prompt Engineer 使用一系列技術來優化模型輸出，這些技術可按複雜性進行分類：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;零樣本提示（Zero-Shot Prompting）： 在不提供任何示例的情況下直接向模型下達任務，完全依賴其在預訓練階段獲得的知識和推理能力。&lt;/li&gt; 
   &lt;li&gt;少樣本提示（Few-Shot Prompting）： 在提示中提供少量（通常為 1 到 5 個）高質量的示例，以引導模型的行為。對於複雜任務，這種「上下文學習」方法被證明極為有效。&lt;/li&gt; 
   &lt;li&gt;思維鏈提示（Chain-of-Thought Prompting, CoT）： 引導模型將複雜問題分解為一系列中間推理步驟，顯著增強了其在邏輯、數學和推理任務上的表現。&lt;/li&gt; 
   &lt;li&gt;高級推理技術： 在 CoT 的基礎上，研究人員還開發了更為複雜的變體，如思維樹（Tree-of-Thought）、蘇格拉底式提示（Maieutic Prompting）和由簡到繁提示（Least-to-Most Prompting），以探索更多樣化的解決方案路徑。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;以提示為中心的方法的侷限性&lt;br&gt; 儘管 Prompt Engineering 至關重要，但對於構建穩健、可用於生產環境的系統而言，它存在固有的侷限性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;脆弱性&amp;amp;不可復現性： 提示中微小的措辭變化可能導致輸出結果的巨大差異，使得這一過程更像是一種依賴反覆試錯的「藝術」，而非可復現的「科學」。&lt;/li&gt; 
   &lt;li&gt;擴展性差： 手動、迭代地優化提示的過程，在面對大量用戶、多樣化用例和不斷出現的邊緣情況時，難以有效擴展。&lt;/li&gt; 
   &lt;li&gt;用戶負擔： 這種方法將精心構建一套詳盡指令的負擔完全壓在了用戶身上，對於需要自主運行、或處理高併發請求的系統而言是不切實際的。&lt;/li&gt; 
   &lt;li&gt;無狀態性： Prompt Engineering 本質上是為單輪、「一次性」的交互而設計的，難以處理需要記憶和狀態管理的長對話或多步驟任務。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Context Engineering 興起：範式的轉移&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//7f71fa2a848717aa220f2435fa704c03.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Context Engineering 並非要取代 Prompt Engineering，而是一個更高階、更側重於系統設計的必要學科。&lt;br&gt; 定義 Context Engineering&lt;br&gt; Context Engineering 是一門設計、構建並優化動態自動化系統的學科，旨在為大型語言模型在正確的時間、以正確的格式，提供正確的信息和工具，從而可靠、可擴展地完成複雜任務。&lt;br&gt; prompt 告訴模型如何思考，而 Context 則賦予模型完成工作所需的知識和工具。&lt;br&gt; 「Context」的範疇&lt;br&gt; 「Context」的定義已遠超用戶單次的即時提示，它涵蓋了 LLM 在做出響應前所能看到的所有信息生態系統：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系統級指令和角色設定。&lt;/li&gt; 
   &lt;li&gt;對話歷史（短期記憶）。&lt;/li&gt; 
   &lt;li&gt;持久化的用戶偏好和事實（長期記憶）。&lt;/li&gt; 
   &lt;li&gt;動態檢索的外部數據（例如來自 RAG）。&lt;/li&gt; 
   &lt;li&gt;可用的工具（API、函數）及其定義。&lt;/li&gt; 
   &lt;li&gt;期望的輸出格式（例如，JSON Schema）。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;對比分析&lt;br&gt; 關係：超集，而非對抗、競爭&lt;br&gt; Prompt Engineering 是 Context Engineering 的一個子集。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Context Engineering 決定用什麼內容填充 Context Window，&lt;/li&gt; 
   &lt;li&gt;Prompt Engineering 則負責優化窗口內的具體指令。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//511d0ed709e085c5bef3f4862ddfb6fc.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Prompt Engineering vs. Context Engineering&lt;br&gt; Context Engineering 的基石：RAG&lt;br&gt; 本部分將闡述檢索增強生成（RAG）作為實現 Context Engineering 的主要架構模式。從「是什麼」轉向「如何做」，詳細介紹 RAG 系統的組件和演進。&lt;br&gt; Retrieval-Augmented Generation&lt;br&gt; 為何 RAG 不僅是一種技術，更是現代 Context Engineering 系統的基礎架構？&lt;br&gt; 解決 LLM 的核心弱點&lt;br&gt; RAG 直接解決了標準 LLM 在企業應用中存在的固有侷限性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;知識凍結：LLM 的知識被凍結在其訓練數據的時間點。RAG 通過在推理時注入實時的、最新的信息來解決這個問題。&lt;/li&gt; 
   &lt;li&gt;缺乏領域專有知識：標準 LLM 無法訪問組織的內部私有數據。RAG 則能夠將 LLM 連接到這些內部知識庫，如技術手冊、政策文件等。&lt;/li&gt; 
   &lt;li&gt;幻覺（Hallucination）：LLM 會不同程度上地編造事實。RAG 通過將模型的回答「錨定」在可驗證的、檢索到的證據上，提高事實的準確性和可信度。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;RAG 工作流&lt;br&gt; RAG 的實現通常分為兩個主要階段：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;索引（離線階段）：在這個階段，系統會處理外部知識源。文檔被加載、分割成更小的 chunks，然後通過 Embedding Model 轉換為向量表示，並最終存儲在專門的向量數據庫中以備檢索。&lt;/li&gt; 
   &lt;li&gt;推理（在線階段）：當用戶提出請求時，系統執行以下步驟：&lt;/li&gt; 
   &lt;li&gt;檢索（Retrieve）：將用戶的查詢同樣轉換為向量，然後在向量數據庫中進行相似性搜索，找出與查詢最相關的文檔塊。&lt;/li&gt; 
   &lt;li&gt;增強（Augment）：將檢索到的這些文檔塊與原始的用戶查詢、系統指令等結合起來，構建一個內容豐富的、增強的最終提示。&lt;/li&gt; 
   &lt;li&gt;生成（Generate）：將這個增強後的提示輸入給 LLM，LLM 會基於提供的上下文生成一個有理有據的回答。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;RAG 架構分類&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Naive RAG：即上文描述的基礎實現。它適用於簡單的問答場景，但在檢索質量和上下文處理方面存在侷限。&lt;/li&gt; 
   &lt;li&gt;Advanced RAG：這種範式在檢索前後引入了處理步驟以提升質量。許多第三部分將詳述的技術都屬於這一範疇。關鍵策略包括：&lt;/li&gt; 
   &lt;li&gt;檢索前處理：採用更復雜的文本分塊策略、查詢轉換（如 StepBack-prompting）等優化檢索輸入。&lt;/li&gt; 
   &lt;li&gt;檢索後處理：對檢索到的文檔進行 Re-ranking 以提升相關性，並對上下文進行 Compression。&lt;/li&gt; 
   &lt;li&gt;Modular RAG：一種更靈活、更面向系統的 RAG 視圖，其中不同的組件（如搜索、檢索、記憶、路由）被視為可互換的模塊。這使得構建更復雜、更定製化的流程成為可能。具體模式包括：&lt;/li&gt; 
   &lt;li&gt;帶記憶的 RAG：融合對話歷史，以處理多輪交互，使對話更具連續性。&lt;/li&gt; 
   &lt;li&gt;分支/路由 RAG：引入一個路由模塊，根據查詢的意圖決定使用哪個數據源或檢索器。&lt;/li&gt; 
   &lt;li&gt;Corrective RAG, CRAG：增加了一個自我反思步驟。一個輕量級的評估器會對檢索到的文檔質量進行打分。如果文檔不相關，系統會觸發替代的檢索策略（如網絡搜索）來增強或替換初始結果。&lt;/li&gt; 
   &lt;li&gt;Self-RAG：讓 LLM 自身學習判斷何時需要檢索以及檢索什麼內容，通過生成特殊的檢索 Token 來自主觸發檢索。&lt;/li&gt; 
   &lt;li&gt;Agentic RAG：這是 RAG 最先進的形式，將 RAG 集成到一個智能體循環（agentic loop）中。模型能夠執行多步驟任務，主動與多個數據源和工具交互，並隨時間推移綜合信息。這是 Context Engineering 在實踐中的頂峯。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;向量數據庫的角色&lt;br&gt; 本節將分析支撐 RAG 中「檢索」步驟的關鍵基礎設施，並比較市場上的主流解決方案。&lt;br&gt; Context Stack：一個新興的 abstract layer&lt;br&gt; 觀察 RAG 系統的構成—— 數據攝入、分塊、嵌入、用於索引和檢索的向量數據庫、重排序器、壓縮器以及最終的 LLM ——可以發現，這些組件並非隨意組合，而是形成了一個連貫的、多層次的架構。這可以被抽象地稱為 Context Stack。&lt;br&gt; 這個堆棧的數據流非常清晰：在離線索引階段，數據從原始文檔流向分塊、嵌入，最終存入向量數據庫 。在在線推理階段，數據流從用戶查詢開始，經過嵌入、向量搜索、重排序、壓縮，最終形成送入 LLM 的提示。&lt;br&gt; 這個堆棧的出現，標誌着 AI 應用開發正在走向成熟，不同的技術供應商開始專注於 Stack 中的特定層面：Pinecone、Weaviate 和 Milvus 等公司在做 Database layer；LangChain 和 LlamaIndex 等框架提供了將所有組件粘合在一起的 Application Orchestration Layer；而 Cohere 和 Jina AI 等提供了專業的 Re-ranking as a Service（RaaS）模塊。&lt;br&gt; 因此，理解新的 AI Agent 架構，就意味着理解 Context Engineering，就意味着要理解這個新興的 Context Stack，瞭解其各個層次以及在每個層次上不同組件之間的權衡。這種視角將討論從一系列孤立的技術提升到系統設計和技術選型的高度，對工程師和架構師而言具有更高的價值。&lt;/p&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;選型關鍵考量因素&lt;br&gt; 組織在選擇向量數據庫時必須考慮以下主要因素：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;模型：選擇完全託管的雲服務（如 Pinecone），還是可自託管的開源方案（如 Milvus、Weaviate）。&lt;/li&gt; 
   &lt;li&gt;擴展性：是否能處理數十億級別的向量數據和高查詢負載（Milvus）。&lt;/li&gt; 
   &lt;li&gt;功能集： 是否支持混合搜索（關鍵詞+向量）、高級 meta 過濾以及多模態數據處理（Weaviate）。&lt;/li&gt; 
   &lt;li&gt;易用性與靈活性：是傾向於 API 簡單、設置最少的方案（Pinecone），還是需要多種索引算法和深度配置選項的方案（Milvus） 。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;為了給技術選型提供一個實用的決策框架，下表對幾個主流的向量數據庫進行了比較。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//a8380c8f2c53d3fe8f1844e71413da76.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;主流 RAG 向量數據庫對比分析&lt;br&gt; Context 工程化的核心概念和目標&lt;br&gt; 從原始數據到相關分塊&lt;br&gt; 本節聚焦於從知識庫中識別和檢索最有價值信息的初始階段。&lt;br&gt; 高級分塊策略&lt;br&gt; 文本分塊（Chunking）是 RAG 流程中最關鍵也最容易被忽視的一步。其目標是創建在語義上自成一體的文本塊。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;樸素分塊的問題：固定大小的分塊方法雖然簡單，但常常會粗暴地切斷句子或段落，導致上下文支離破碎，語義不完整。&lt;/li&gt; 
   &lt;li&gt;內容感知分塊：&lt;/li&gt; 
   &lt;li&gt;遞歸字符分割：一種更智能的方法，它會按照一個預設的分割符層次結構（如：先按段落，再按句子，最後按單詞）進行分割，以儘可能保持文本的自然結構。&lt;/li&gt; 
   &lt;li&gt;文檔特定分塊：利用文檔自身的結構進行分割，例如，根據 Markdown 的標題、代碼文件的函數或法律合同的條款來劃分。&lt;/li&gt; 
   &lt;li&gt;語言學分塊：使用 NLTK、spaCy 等自然語言處理庫，基於句子、名詞短語或動詞短語等語法邊界進行分割。&lt;/li&gt; 
   &lt;li&gt;語義分塊： 這是最先進的方法之一。它使用嵌入模型來檢測文本中語義的轉變點。當文本的主題或意義發生變化時，就在該處進行分割，從而確保每個分塊在主題上是高度內聚的。研究表明，這種策略的性能優於其他方法。&lt;/li&gt; 
   &lt;li&gt;智能體分塊：一個前沿概念，即利用一個 LLM 智能體來決定如何對文本進行分塊，例如，通過將文本分解為一系列獨立的 propositions 來實現。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;通過重排序提升精度&lt;br&gt; 為了平衡檢索的速度和準確性，業界普遍採用兩階段檢索流程。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;兩階段流程：&lt;/li&gt; 
   &lt;li&gt;第一階段（召回）： 使用一個快速、高效的檢索器（如基於 bi-encoder 的向量搜索或 BM25 等詞法搜索）進行廣泛撒網，召回一個較大的候選文檔集（例如，前 100 個）。&lt;/li&gt; 
   &lt;li&gt;第二階段（精排/重排序）： 使用一個更強大但計算成本更高的模型，對這個較小的候選集進行重新評估，以識別出最相關的少數幾個文檔（例如，前 5 個）。&lt;/li&gt; 
   &lt;li&gt;Cross-Encoder： 交叉編碼器之所以在重排序階段表現優越，是因為它與雙編碼器的工作方式不同。雙編碼器獨立地為查詢和文檔生成嵌入向量，然後計算它們的相似度。而交叉編碼器則是將查詢和文檔同時作為輸入，讓模型在內部通過 Attention Mechanism 對二者進行深度交互。這使得模型能夠捕捉到更細微的語義關係，從而給出更準確的相關性評分。&lt;/li&gt; 
   &lt;li&gt;實際影響： 重排序顯著提高了最終送入 LLM 的上下文質量，從而產出更準確、幻覺更少的答案。在金融、法律等高風險領域，重排序被認為是必不可少而非可選的步驟。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;div&gt;
     核心問題 - Lost in the Middle 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;span style="color:#245bdb"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.03172" rel="nofollow" target="_blank"&gt;https://arxiv.org/abs/2307.03172&lt;/a&gt;&lt;/span&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt;Lost in the Middle: How Language Models Use Long Contexts 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 當前 LLM 存在一個根本性認知侷限，這一侷限使得簡單的上下文堆砌變得無效，並催生了後續的優化技術。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;定義：LLM 在處理長上下文時表現出一種獨特的 U 型，性能曲線。當關鍵信息位於上下文窗口的開頭（首因效應）或結尾（近因效應）時，模型能夠高效地利用這些信息。然而，當關鍵信息被 「hidden」在長篇上下文的中間位置時，模型的性能會顯著下降。&lt;/li&gt; 
   &lt;li&gt;實驗： 在多文檔問答任務時，即使檢索器召回了更多相關的文檔，模型的性能提升也很快達到飽和。這意味着簡單地增加上下文長度（即添加更多文檔）不僅無益，甚至因為關鍵信息被淹沒而損害性能 。&lt;/li&gt; 
   &lt;li&gt;「知道但説不出來」： 並非模型「找不到」信息。通過探測模型的內部表徵發現，模型通常能夠準確地編碼關鍵信息的位置，但在生成最終答案時卻未能有效利用這些信息。這表明在模型內部，信息檢索和信息利用（或溝通）之間存在脫節。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//dc9e6245d2563332682a3c618cdd7a83.jpg" width="482" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;上下文豐富性與窗口侷限性之間的考量&lt;br&gt; Context Engineering 的核心存在一個根本性的矛盾。一方面，提供豐富、全面的上下文是獲得高質量響應的關鍵。另一方面，LLM 的上下文窗口是有限的，並且由於 Lost in the Middle、contextual distraction 等問題，過長的上下文反而會導致性能下降。&lt;br&gt; 一個樸素的想法是儘可能多地將相關信息塞進上下文窗口。然而，研究和實踐都證明這是適得其反的。LLM 會被無關信息淹沒、分心，或者乾脆忽略那些不在窗口兩端的信息。&lt;br&gt; 這就產生了一個核心的優化問題：如何在固定的 Token 預算內，最大化「信號」（真正相關的信息），同時最小化「噪聲」（不相關或分散注意力的信息），並充分考慮到模型存在的認知偏差？&lt;br&gt; 這個考量是 Context Engineering 領域創新的主要驅動力。所有的高級技術——無論是語義分塊、重排序，還是後續將討論的壓縮、摘要和智能體隔離——都是為了有效管理這一權衡而設計的。因此，Context Engineering 不僅是關於提供上下文，更是關於如何策劃和塑造上下文，使其對一個認知能力有限的處理單元（LLM）最為有效。&lt;br&gt; 優化上下文窗口：壓縮與摘要&lt;br&gt; 本節詳細介紹用於主動管理上下文的技術，確保最有價值的信息被優先呈現。&lt;br&gt; 上下文壓縮的目標&lt;br&gt; 縮短檢索到的文檔列表和/或精簡單個文檔的內容，只將最相關的信息傳遞給 LLM。這能有效降低 API 調用成本、減少延遲，並緩解 Lost in the Middle 的問題 。&lt;br&gt; 壓縮方法&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;過濾式壓縮： 這類方法決定是保留還是丟棄整個檢索到的文檔。&lt;/li&gt; 
   &lt;li&gt;LLMChainFilter：利用一個 LLM 對每個文檔的相關性做出簡單的「是/否」判斷。&lt;/li&gt; 
   &lt;li&gt;EmbeddingsFilter：更經濟快速的方法，根據文檔嵌入與查詢嵌入的餘弦相似度來過濾文檔。&lt;/li&gt; 
   &lt;li&gt;內容提取式壓縮：這類方法會直接修改文檔內容。&lt;/li&gt; 
   &lt;li&gt;LLMChainExtractor：遍歷每個文檔，並使用 LLM 從中提取僅與查詢相關的句子或陳述 。&lt;/li&gt; 
   &lt;li&gt;用 top N 代替壓縮：像 LLMListwiseRerank 這樣的技術，使用 LLM 對檢索到的文檔進行重排序，並只返回排名最高的 N 個，從而起到高質量過濾器的作用。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;作為壓縮策略的摘要&lt;br&gt; 對於非常長的文檔或冗長的對話歷史，可以利用 LLM 生成摘要。這些摘要隨後被注入上下文，既保留了關鍵信息，又大幅減少了 Token 數量。這是在長時程運行的智能體中管理上下文的關鍵技術。&lt;br&gt; 智能體系統的上下文管理&lt;br&gt; 從 HITL 到 SITL&lt;br&gt; Prompt Engineering 本質上是一個手動的、Human-in-the-Loop 的試錯過程。而 Context Engineering，尤其是在其智能體形式中，則是關於構建一個自動化的 System-in-the-Loop，這個系統在 LLM 看到提示之前就為其準備好上下文。&lt;br&gt; 一個人類提示工程師需要手動收集信息、組織語言並進行測試。而一個 Context Engineering 化的系統則將此過程自動化：RAG 流程本身就是一個自動收集信息的系統；路由器是一個自動決定收集哪些信息的系統；記憶模塊是一個自動持久化和檢索歷史信息的系統。&lt;br&gt; 正是這種自動化，使得 AI 系統能夠變得「智能體化」（Agentic）——即能夠在沒有人類為每一步微觀管理上下文的情況下，進行自主的、多步驟的推理 。因此，Context Engineering 的目標是構建一個可靠、可重複的上下文組裝機器。這台機器取代了提示工程師的臨時性、手工勞動，從而使創建真正自主和可擴展的 AI 智能體成為可能。焦點從單個提示的「技藝」轉向了生成該提示的「系統工程」。&lt;br&gt; 智能體上下文管理框架&lt;br&gt; LangChain 博客中提出的四個關鍵策略 ：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Write - 持久化上下文：&lt;/li&gt; 
   &lt;li&gt;Scratchpads：供智能體在執行復雜任務時使用的臨時、會話內記憶，用於記錄中間步驟。&lt;/li&gt; 
   &lt;li&gt;Memory：長期、持久化的存儲，記錄關鍵事實、用戶偏好或對話摘要，可在不同會話間調用。&lt;/li&gt; 
   &lt;li&gt;Select - 檢索上下文：根據當前的子任務，使用 RAG 技術動態地從記憶、工具庫或知識庫中選擇相關上下文。這甚至包括對工具描述本身應用 RAG，以避免向智能體提供過多無關的工具選項。&lt;/li&gt; 
   &lt;li&gt;Compress - 優化上下文：利用摘要或修剪技術來管理智能體在長時程任務中不斷增長的上下文，防止上下文窗口溢出和「 Lost in the Middle 」問題。&lt;/li&gt; 
   &lt;li&gt;Isolate - 分割上下文：&lt;/li&gt; 
   &lt;li&gt;多智能體系統： 將一個複雜問題分解，並將子任務分配給專門的子智能體，每個子智能體都擁有自己獨立的、更聚焦的上下文窗口。&lt;/li&gt; 
   &lt;li&gt;沙盒環境： 在一個隔離的環境中執行工具調用，只將必要的執行結果返回給 LLM，從而將包含大量 Token 的複雜對象隔離在主上下文窗口之外。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//82e7bdc773a26d0eb5fc2244450bf8ae.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;多智能體架構中的 Context 數據流與工作流編排&lt;br&gt; LLM 正在從被動地響應用戶查詢的「響應者」，演變為能夠自主規劃、決策並執行多步驟複雜任務的「執行者」——即我們所説的「智能體」（AI Agent）。&lt;br&gt; 當一個智能體不再是簡單地「輸入-輸出」，而是需要調用工具、訪問數據庫、與用戶進行多輪交互時，其內部的數據是如何流動和管理的？如何進行技術選型？&lt;br&gt; 工作流（Workflow） vs. 智能體（Agent）&lt;br&gt; 在深入技術細節之前，建立一個清晰的概念框架至關重要。業界（如 Anthropic）傾向於對「智能體系統」進行兩種架構上的區分。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//19c604cd74780dcfc6c552c74d304ff7.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;工作流（Workflows）&lt;br&gt; 指的是 LLM 和工具通過預定義的代碼路徑進行編排的系統。在這種模式下，數據流動的路徑是固定的、由開發者明確設計的，類似於上世紀流行的「專家系統」。例如，「第一步：分析用戶郵件；第二步：根據分析結果在日曆中查找空閒時段；第三步：起草會議邀請郵件」。這種模式確定性高，易於調試和控制，非常適合有明確業務流程的場景（如風控需求高、數據敏感、安全等級要求）。&lt;br&gt; 智能體（Agents）&lt;br&gt; 指的是 LLM 動態地指導自己的流程和工具使用，自主控制如何完成任務的系統。在這種模式下，數據流動的路徑不是預先固定的，而是由 LLM 在每一步根據當前情況和目標動態決定的。這種模式靈活性高，能處理開放式問題，但可控性和可預測性較低。&lt;br&gt; 複雜的智能體通常是這兩種模式的混合體，在宏觀層面遵循一個預定義的工作流，但在某些節點內部，又賦予 LLM 一定的自主決策權。管理這一切的核心，我們稱之為編排層（Orchestration Layer）。&lt;br&gt; 多 Agent 編排的核心架構：預定義數據流的實現&lt;br&gt; 為了實現可靠、可控的數據流動，開發者們已經探索出幾種成熟的架構模式。這些模式可以單獨使用，也可以組合成更復雜的系統。&lt;br&gt; 鏈式工作流（Prompt Chaining）（GPT-3.5 時期的工作原理）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;數據流： 輸入 -&amp;gt; 模塊 A -&amp;gt; 輸出 A -&amp;gt; 模塊 B -&amp;gt; 輸出 B -&amp;gt;... -&amp;gt; 最終輸出&lt;/li&gt; 
   &lt;li&gt;工作原理： 每個模塊（LLM 調用）只負責一個定義明確的子任務。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//9d2163cbd51a51e8e54055f3273ba99f.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 路由工作流（Routing）（o3 的早期工作原理）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;數據流： 輸入 -&amp;gt; 路由器選擇 =&amp;gt; -&amp;gt; 輸出&lt;/li&gt; 
   &lt;li&gt;工作原理： 一個充當「路由器」的 LLM 調用，其唯一任務就是決策。它會分析輸入數據，然後輸出一個指令，告訴編排系統接下來應該調用哪個具體的業務模塊。&lt;/li&gt; 
   &lt;li&gt;實現方式： LangGraph 使用 Conditional Edges 來實現這種邏輯，即一個節點的輸出決定了圖的下一跳走向何方。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//71e8c6a23709d8c211d75f1985830384.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 編排器-工作者模式（Orchestrator-Workers）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;對於極其複雜的任務，可以採用多智能體（Multi-agent）架構，也稱為 Orchestrator-Workers 模式。一箇中心 Orchestrator 智能體負責分解任務，並將子任務分配給多個專職的 Workers 智能體。&lt;/li&gt; 
   &lt;li&gt;數據流：這是一個分層、協作的流動模式。 總任務 -&amp;gt; Orchestrator =&amp;gt; -&amp;gt; 結果彙總 -&amp;gt; 最終輸出&lt;/li&gt; 
   &lt;li&gt;工作原理：每個工作者智能體都有自己獨立的上下文和專用工具，專注於解決特定領域的問題。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//6566edba8fb0871ddefb19dbfaf4c2ac.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;決策與數據選擇機制&lt;br&gt; 在上述架構中，智能體（或其模塊）如何決定「需要什麼數據」以及「下一步做什麼」？這依賴於其內部的規劃和推理能力。&lt;br&gt; ReAct 框架&lt;br&gt; ReAct（Reasoning and Acting）是一個基礎且強大的框架，它通過模擬人類的「Reasoning-Acting」模式，使 LLM 能夠動態地決定數據需求。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//57afee644faac0214fcb912c21c5426b.jpg" width="340" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 其核心是一個循環：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;思考（Thought）：LLM 首先進行內部推理。它分析當前任務和已有信息，判斷是否缺少完成任務所需的知識，並制定下一步的行動計劃。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：「用戶問我今天舊金山的天氣，但我不知道。我需要調用天氣查詢工具。」&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;行動（Action）： LLM 決定調用一個具體的工具，並生成調用該工具所需的參數。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：Action: search_weather(location="San Francisco")。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;觀察（Observation）：系統執行該行動（調用外部 API），並將返回的結果作為「觀察」數據提供給 LLM。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：Observation: "舊金山今天晴，22 攝氏度。"&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;再次思考： LLM 接收到新的觀察數據，再次進入思考環節，判斷任務是否完成，或是否需要進一步的行動。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：「我已經獲得了天氣信息，現在可以回答用戶的問題了。」&lt;br&gt; 在這個循環中，數據流是根據 LLM 的「思考」結果動態生成的。當 LLM 判斷需要外部數據時，它會主動觸發一個「行動」來獲取數據，然後將獲取到的「觀察」數據整合進自己的上下文中，用於下一步的決策。&lt;br&gt; Planning 和任務分解&lt;br&gt; 對於更復雜的任務，智能體通常會先進行規劃（Planning）。一個高階的規劃模塊會將用戶的宏大目標分解成一系列更小、更具體、可執行的子任務。&lt;br&gt; 數據流向： 規劃模塊的輸出是一份「計劃清單」（Planning List），這份清單定義了後續一系列模塊的調用順序和數據依賴關係。&lt;br&gt; （前一陣子流行的 Claude Code，剛更新的 Cursor v1.2，以及上個版本流行的 Gemini/GPT DeepResearch 就屬於這個架構）&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//18112cec76c43ea86ad8c87a23c89639.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 例如，對於「幫我策劃一次巴黎三人五日遊」的請求，規劃模塊可能會生成如下計劃，並定義了每個步驟所需的數據輸入和輸出：&lt;br&gt; 1.[獲取用戶預算和偏好] -&amp;gt; [搜索往返機票]&lt;br&gt; 2.[機票信息] -&amp;gt; [根據旅行日期和預算搜索酒店]&lt;br&gt; 3.[酒店信息] -&amp;gt; [規劃每日行程]&lt;br&gt; 4.[機票、酒店、行程信息] -&amp;gt; [生成最終行程單和預算報告]&lt;br&gt; Reflection 機制&lt;br&gt; 先進的智能體架構還包含反思（Reflection）機制 。智能體在執行完一個動作或完成一個子任務後，會評估其結果的質量和正確性。如果發現問題，它可以自我修正，重新規劃路徑。&lt;br&gt; （這是截止撰文時，各大主流 deep research 平台使用的核心技術方案） 數據流向： 這是一個反饋循環。模塊的輸出不僅流向下一個任務模塊，還會流向一個「評估器」模塊。評估器的輸出（如「成功」、「失敗」、「信息不足」）會反過來影響規劃模塊，從而調整後續的數據流向。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//43d3414957f84dcf5ff22836a10b9d5e.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;框架與工具&lt;br&gt; 上述的架構和機制並非憑空存在，而是通過具體的開發框架實現的。其中，LangGraph 作為 LangChain 的擴展，為構建具有顯式數據流的智能體系統提供了強大的工具集。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//ae0cd62c436db7fc2bf98ce3f3972c15.jpg" width="326" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; LangGraph：用圖（Graph）定義工作流（Workflow）&lt;br&gt; LangGraph 的核心思想是將智能體應用構建成一個狀態圖（State Graph）。這個圖由節點和邊組成，清晰地定義了數據如何在不同模塊間流動&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;狀態（State）：這是整個圖的核心，一個所有節點共享的中央數據對象。你可以把它想象成一個「數據總線」或共享內存。開發者需要預先定義 State 的結構，每個節點在執行時都可以讀取和更新這個 State 對象 。&lt;/li&gt; 
   &lt;li&gt;節點（Nodes）：代表工作流中的一個計算單元或一個步驟。每個節點通常是一個 Python 函數，它接收當前的 State 作為輸入，執行特定任務（如調用 LLM、執行工具、處理數據），然後返回對 State 的更新。&lt;/li&gt; 
   &lt;li&gt;邊（Edges）：連接節點，定義了工作流的路徑，即數據在 State 更新後應該流向哪個節點。&lt;/li&gt; 
   &lt;li&gt;簡單邊（Simple Edges）：定義了固定的、無條件的流向，用於實現鏈式工作流。&lt;/li&gt; 
   &lt;li&gt;條件邊（Conditional Edges）： 用於實現路由邏輯。它會根據一個函數的輸出來決定接下來應該走向哪個節點，從而實現流程的分支 。&lt;/li&gt; 
   &lt;li&gt;檢查點（Checkpointer）： LangGraph 提供了持久化機制，可以在每一步執行後自動保存 State 的狀態。這對於構建需要長期記憶、可中斷和恢復、或需要 Human-in-the-Loop 的複雜業務流程至關重要。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;複雜業務流程的 AI 智能體，其核心挑戰已從單純優化信息檢索（如 RAG）或提示詞，轉向了對內部工作流和數據流的精心設計與編排。&lt;br&gt; Context Engineering 的未來&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Graph RAG 的興起：標準的基於向量的 RAG 在處理高度互聯的數據時存在侷限。而利用知識圖譜的圖 RAG 不僅能檢索離散的信息塊，還能檢索它們之間的顯式關係。這使得模型能夠進行更復雜的多跳推理，並提供上下文更準確的回答 。&lt;/li&gt; 
   &lt;li&gt;智能體自主性的增強：像 Self-RAG 和 Agentic RAG 這樣更自主的系統將成為趨勢，LLM 將承擔更多管理自身上下文的責任。這將模糊 Context Engineering 系統與 LLM 本身之間的界限。&lt;/li&gt; 
   &lt;li&gt;超越固定上下文窗口：針對 Lost in the Middle 問題的研究正在進行中，包括探索新的模型架構（如改進的位置編碼）和訓練技術。這些研究的突破可能會從根本上改變當今 Context Engineering 師所面臨的約束。&lt;/li&gt; 
   &lt;li&gt;終極目標：Context Engineering 本質上是一座橋樑，它是一套複雜的補償機制，用以彌補 LLM 「don't read minds—they read tokens」的現實。人工智能研究的長期目標是創造出具有更強大內部世界模型的 AI，從而減少對此類龐大外部上下文支架的依賴。 Context Engineering 的演進，將是衡量我們朝此目標邁進的關鍵指標。&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18689521</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18689521</guid>
      <pubDate>Tue, 02 Sep 2025 08:15:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Wine 10.14 開發版發佈，Windows 應用兼容層</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Wine 項目近日發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.winehq.org%2Fnews%2F2025082901" target="_blank"&gt; Wine 10.14 開發版&lt;/a&gt;。這是其雙週更新的一部分，帶來了多項重要改進：&lt;/p&gt; 
&lt;p&gt;主要更新內容與改進&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;VKD3D 升級至 1.17&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;包含新版 VKD3D（Direct3D 12 over Vulkan API 層），顯著提升 D3D12 應用和遊戲在 Linux 上的兼容性和性能。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mono 引擎更新至 10.2.0&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Mono 引擎得到更新，用於增強 .NET 應用在 Wine 環境下的運行表現。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持 IPv6 Ping&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Wine 的內置 「ping」 工具現已支持 IPv6，這為網絡診斷和兼容性帶來便利。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitLab CI 跳轉至 Debian 「Trixie」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Wine 項目的持續集成系統（CI）現已遷移到使用 Debian 13 「Trixie」 作為構建環境，便於現代化管理與構建流程。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;19 項 Bug 修復&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;包含針對多款遊戲（如 Phantasy Star Online: Blue Burst、GreedFall、Mafia III: Definitive Edition、Death to Spies）和應用（如 Roblox Studio 安裝程序、VemsTune 等）的修復，以及 API 補丁，包括對 gameinput.dll、ntdll.dll、api-ms-win-core-memory、winepath 等系統組件的改進。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://gitlab.winehq.org/wine/wine/-/releases/wine-10.14&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Wine 作為開源兼容層，能讓 Windows 應用和遊戲在 Linux、macOS 等平台運行，此次更新進一步強化了跨平台兼容性與穩定性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369877/wine-10-14</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369877/wine-10-14</guid>
      <pubDate>Tue, 02 Sep 2025 08:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>前 7 個月我國軟件業利潤總額 10890 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工業和信息化部運行監測協調局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_461e0981c2564044b9ad2d67cf0e97f3.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;2025 年前 7 個月，我國軟件和信息技術服務業（以下簡稱「軟件業」）運行態勢良好，軟件業務收入、利潤總額穩健增長，軟件業務出口保持正增長。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;一、總體運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;前 7 個月，我國軟件業務收入 83246 億元，同比增長 12.3%。軟件業利潤總額 10890 億元，同比增長 12.4%。軟件業務出口 339.8 億美元，同比增長 5.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;二、分領域運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;軟件產品收入穩定增長。&lt;/span&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 個月，軟件產品收入 18011 億元，同比增長 10.6%，佔全行業收入比重為 21.6%。其中，基礎軟件產品收入 1052 億元，同比增長 13&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%；工業軟件產品收入 1677 億元，同比增長 8.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;信息技術服務收入保持兩位數增長。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 個月，信息技術服務收入 57246 億元，同比增長 13.4%，佔全行業收入的 68.8%。其中，雲計算、大數據服務共實現收入 8663 億元，同比增長 12.6%，佔信息技術服務收入的 15.1%；集成電路設計收入 2511 億元，同比增長 18.5%；電子商務平台技術服務收入 7156 億元，同比增長 9.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;信息安全收入和嵌入式系統軟件收入平穩增長。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 個月，信息安全產品和服務收入 1181 億元，同比增長 6.2%。嵌入式系統軟件收入 6809 億元，同比增長 8.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;三、分地區運行情況&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;前 7 個月，東部地區、中部地區、西部地區和東北地區軟件業務收入分別同比增長 12.6%、12.3%、10.4% 和 9.3%。東部地區佔全國軟件業務總收入的 84.3%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;京津冀地區軟件業務收入同比增長 13.2%，長三角地區軟件業務收入同比增長 14.7%。北京、廣東、江蘇、山東、上海軟件業務收入居全國前 5，同比分別增長 13.4%、9.1%、14.4%、11.8% 和 20.1%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369876</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369876</guid>
      <pubDate>Tue, 02 Sep 2025 08:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 將原生支持 MKV 視頻格式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindowsreport.com%2Fmozilla-firefox-is-officially-getting-mkv-video-support%2F" target="_blank"&gt;據報道&lt;/a&gt;，Firefox 瀏覽器即將原生支持 &lt;code&gt;.mkv&lt;/code&gt;視頻文件播放，用戶無需再依賴插件或手動轉換格式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4ae5363247ae1619e30c87b03d4f17b9b25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mozilla&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1422891" target="_blank"&gt; 已指派工程師&lt;/a&gt;推動這一功能的開發，預計將按照以下階段有序推進：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Nightly 版本做初步測試，針對最常見的音視頻組合，例如 H.264 編碼的視頻 + AAC 音頻進行優先支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;後期將擴大支持範圍，加入 VP9、AV1 等視頻編碼，以及 Opus 或 FLAC 等音頻格式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在穩定性與兼容性通過全面檢測後，會推廣至正式版本的 Firefox 用戶。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/152017_iqZR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，Firefox 打開 MKV 文件時常常失敗或直接觸發下載，這在 Windows 10 和 11 已原生支持 MKV 的情況下，顯得尤為不便。新功能上線後，Firefox 的多媒體體驗將與主流瀏覽器保持一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369866/mozilla-firefox-is-officially-getting-mkv-video-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369866/mozilla-firefox-is-officially-getting-mkv-video-support</guid>
      <pubDate>Tue, 02 Sep 2025 07:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊開源具備原生 3D 重建能力的超長程世界模型：HunyuanWorld-Voyager</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊近日正式發佈了 HunyuanWorld-Voyager，這是一種創新的視頻擴散框架，旨在通過單張輸入圖像生成具備世界一致性的 3D 點雲，支持用戶按自定義的相機路徑進行沉浸式探索。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="327" src="https://oscimg.oschina.net/oscnet/up-56c2135778b8058ed623697954e8a4f3027.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官方表示，這全球首個具備原生 3D 重建功能的超遠距離世界模型，重新定義 AI 驅動的 VR、遊戲和仿真空間智能。此模型不僅能夠生成精確對齊的深度信息和 RGB 視頻，還能夠在不進行後處理的情況下，直接用於高質量的三維重建。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;直接 3D 輸出：無需 COLMAP 等工具即可將點雲視頻導出為 3D 格式，實現即時 3D 應用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;創新的 3D 內存：引入可擴展的世界緩存機制，確保任何攝像機軌跡的幾何一致性。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;頂級性能：在斯坦福 WorldScore 測試中排名第一，在視頻生成和 3D 重建基準測試中表現出色&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HunyuanWorld-Voyager 的架構包含兩個關鍵組件。首先是 「世界一致的視頻擴散」，該組件提出了一種統一的架構，可以基於已有的世界觀測，同時生成準確對齊的 RGB 視頻和深度視頻序列，從而確保全局場景的一致性。其次是 「長距離世界探索」，它採用了一種高效的世界緩存機制，結合點雲剔除和自迴歸推理能力，支持迭代場景擴展，並通過上下文感知的一致性技術實現平滑的視頻採樣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為了訓練 HunyuanWorld-Voyager 模型，研究團隊構建了一套可擴展的數據構建引擎。這一自動化視頻重建流水線能夠對任意輸入視頻自動估計相機位姿和度量深度，因此無需依賴人工標註，從而實現大規模、多樣化訓練數據的構建。基於此流水線，HunyuanWorld-Voyager 整合了真實世界採集和虛幻引擎渲染的視頻資源，構建了一個包含超過 10 萬個視頻片段的大規模數據集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在實驗評估中，HunyuanWorld-Voyager 在視頻生成質量方面表現出色。與四種開源的相機可控視頻生成方法進行了對比，結果顯示該模型在 PSNR、SSIM 和 LPIPS 等指標上均優於其他模型，證明瞭其卓越的視頻生成質量。同時，在場景重建方面，HunyuanWorld-Voyager 的生成視頻在幾何一致性上也顯現出更好的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，HunyuanWorld-Voyager 在 WorldScore 靜態基準測試中獲得了最高分，證明瞭其在相機運動控制和空間一致性方面的優越性。這一成果不僅展示了混元世界模型的潛力，還為未來的 3D 場景生成技術開闢了新路徑。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369863</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369863</guid>
      <pubDate>Tue, 02 Sep 2025 07:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊優圖實驗室正式開源智能體框架 Youtu-Agent</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 2 日，騰訊優圖實驗室&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW5LFBLCV3qZG0wxTA9Ob-w" target="_blank"&gt;宣佈&lt;/a&gt;正式開源智能體框架 Youtu-Agent。該框架以極簡設計和高性能表現為核心，旨在為研究人員和開發者提供高效、易用、可復現的智能體開發工具。&lt;/p&gt; 
&lt;p&gt;據介紹，Youtu-Agent 面向實際場景的開源應用框架，能夠覆蓋文件管理、數據分析、學術研究與廣域信息綜述等多個方向應用。目前，Youtu-Agent 開源框架已為騰訊雲多個產品業務提供支持。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Youtu-Agent 的核心亮點在於，它不需要額外訓練模型，也不依賴海外閉源大模型 API，就能在真實場景中展現出優異的效果，比較好地兼顧了科研和應用雙重需求。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;驗證性能&lt;/strong&gt;：在 WebWalkerQA 上達到 71.47% 的 pass@1，在 GAIA（純文本子集）上達到 72.8% 的 pass@1，純粹使用&lt;code&gt;DeepSeek-V3&lt;/code&gt;系列模型（不使用 Claude 或 GPT），建立了強大的開源起點。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;開源友好且成本敏感&lt;/strong&gt;：針對可訪問、低成本部署進行了優化，不依賴封閉模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;實際用例&lt;/strong&gt;：開箱即用地支持 CSV 分析、文獻綜述、個人文件整理以及播客和視頻生成等任務。（即將推出）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;靈活的架構&lt;/strong&gt;：基於 openai-agents 構建，可兼容各種模型 API（從&lt;code&gt;DeepSeek&lt;/code&gt;到&lt;code&gt;gpt-oss&lt;/code&gt;）、工具集成和框架實現。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自動化與簡潔性&lt;/strong&gt;：基於 YAML 的配置、自動智能體生成和簡化的設置減少了手動開銷。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在性能表現上，Youtu-Agent 已在多個智能體挑戰性基準測試中取得領先成績。例如，&lt;strong&gt;在 WebWalkerQA 基準中，基於 DeepSeek-V3.1 的運行結果達到了 71.47% 的準確率，刷新了開源模型的最新紀錄&lt;/strong&gt;；&lt;/p&gt; 
&lt;p&gt;&lt;img height="603" src="https://static.oschina.net/uploads/space/2025/0902/151154_CKYV_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;框架設計方面，Youtu-Agent 完全擁抱開源生態，適配多種可訪問的部署環境；其架構靈活，兼容包括 DeepSeek、gpt-oss 在內的多類模型 API 與工具。&lt;/p&gt; 
&lt;p&gt;&lt;img height="738" src="https://static.oschina.net/uploads/space/2025/0902/151229_GBNE_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;em&gt;https://github.com/TencentCloudADP/Youtu-agent&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369860</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369860</guid>
      <pubDate>Tue, 02 Sep 2025 07:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cloudflare 推出實時語音 AI 平台：Realtime Agents</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cloudflare 宣佈推出&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fcloudflare-realtime-voice-ai%2F" target="_blank"&gt;實時語音 AI 平台&lt;/a&gt;（Cloudflare Realtime Agents），正式進軍低延遲對話式 AI 領域。該平台依託 Cloudflare 全球 330 多個節點的邊緣網絡，為開發者提供構建語音交互應用的完整解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ae6ab80f3dac0b047d5a26124ce0a669d2d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新平台的核心組件包括 Realtime Agents（語音 AI 管道編排運行時）、WebRTC 音頻傳輸支持、Workers AI 的 WebSocket 實時推理，以及 Deepgram 的語音識別/合成模型。通過這些功能，開發者可快速搭建自然流暢的語音代理應用。&lt;/p&gt; 
&lt;p&gt;下面的示例代碼展示瞭如何創建一個繼承自 &lt;code&gt;RealtimeAgent&lt;/code&gt; 的 JavaScript 類，以進行以下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;創建 WebRTC 會話&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;管道編排（如：Deepgram STT → 自定義文本處理 Handler → ElevenLabs TTS）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持會議參與者加入/離開的事件處理&lt;br&gt; 這讓開發者幾乎不需管理底層基礎設施，就可快速構建個性化語音代理應用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;export class MyAgent extends RealtimeAgent&amp;lt;Env&amp;gt; {
constructor(ctx: DurableObjectState, env: Env) {
super(ctx, env);
}

async init(agentId: string ,meetingId: string, authToken: string, workerUrl: string, accountId: string, apiToken: string) {
// Construct your text processor for generating responses to text
const textHandler = new MyTextHandler(this.env);
// Construct a Meeting object to join the RTK meeting
const transport = new RealtimeKitTransport(meetingId, authToken, [
{
media_kind: 'audio',
stream_kind: 'microphone',
},
]);
const { meeting } = transport;

// Construct a pipeline to take in meeting audio, transcribe it using
// Deepgram, and pass our generated responses through ElevenLabs to
// be spoken in the meeting
await this.initPipeline(
[transport, new DeepgramSTT(this.env.DEEPGRAM_API_KEY), textHandler, new ElevenLabsTTS(this.env.ELEVENLABS_API_KEY), transport],
agentId,
workerUrl,
accountId,
apiToken,
);

// The RTK meeting object is accessible to us, so we can register handlers
// on various events like participant joins/leaves, chat, etc.
// This is optional
meeting.participants.joined.on('participantJoined', (participant) =&amp;gt; {
textHandler.speak(`Participant Joined ${participant.name}`);
});
meeting.participants.joined.on('participantLeft', (participant) =&amp;gt; {
textHandler.speak(`Participant Left ${participant.name}`);
});

// Make sure to actually join the meeting after registering all handlers
await meeting.rtkMeeting.join();
}

async deinit() {
// Add any other cleanup logic required
await this.deinitPipeline();
}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cloudflare 指出，要讓語音交互達到「自然對話」的體驗，總延遲需低於 800 毫秒，而其分佈式邊緣架構正好能滿足這一苛刻要求。平台同時兼容多種 AI 模型和第三方服務，支持高度可組合的語音處理管道。&lt;/p&gt; 
&lt;p&gt;目前，Cloudflare Realtime Agents 已開放 Beta 公測，開發者可免費試用並基於該平台開發新一代實時語音 AI 應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369855/cloudflare-realtime-voice-ai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369855/cloudflare-realtime-voice-ai</guid>
      <pubDate>Tue, 02 Sep 2025 06:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
