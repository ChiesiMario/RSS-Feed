<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 24 Feb 2025 16:37:58 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>中國信通院「軟件供應鏈管理」系列評估 2025 新規劃</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中國信息通信研究院雲計算與大數據研究所自 2019 年起開展軟件供應鏈管理相關研究工作，搭建軟件供應鏈管理標準體系。&lt;/p&gt; 
&lt;p&gt;截至目前，由中國信息通信研究院牽頭，廣泛邀請包括金融、互聯網、運營商、軟件廠商、安全廠商、工具廠商等個行業領域專家參與，共同編制了 4 項行業標準和 6 項團體標準，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;行業標準：《可信研發運營安全能力成熟度模型》、《靜態應用程序安全測試工具能力要求》、《交互式應用程序安全測試工具能力要求》、《運行時應用程序自我保護工具能力要求》&lt;/li&gt; 
 &lt;li&gt;團體標準：《軟件供應鏈安全管理要求》、《軟件物料清單總體能力要求》、《面向供應鏈的信息技術產品通用安全能力要求》、《軟件物料清單配套工具能力要求》、《軟件供應鏈製品管理平台能力要求》、《研發運營安全平台能力要求》&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;軟件供應鏈管理系列評估&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為助力企業提升軟件供應鏈安全建設能力，定位建設短板，中國信通院依據標準開展測試評估工作，包&lt;strong&gt;括企業維度、產品維度和工具維度&lt;/strong&gt;三大部分，如下圖所示，&lt;strong&gt;其中標紅的均為 2025 首批評估&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;除此之外，中國信通院今年的軟件供應鏈管理系列評估還引入了新規劃，面向對象包括&lt;strong&gt;企業能力、管理平台和安全工具&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;723&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/192818_U3MK_2720166.png&quot; width=&quot;1381&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjBTc6BJcF2oqNS_X4xpVjw&quot; target=&quot;_blank&quot;&gt;點此查看詳情&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335539</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335539</guid>
            <pubDate>Sat, 22 Feb 2025 11:37:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>SLSA：谷歌開源的軟件供應鏈安全框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SLSA：Supply-chain Levels for Software Artifacts （軟件工件的供應鏈級別）是一個端到端的框架，用於確保整個軟件供應鏈中的軟件工件的完整性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f1778dd4bbb5da70f851b47b2288d7e902a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;重要提示：SLSA 是一個不斷發展的規範，正在通過 GitHub issues、電子郵件或反饋表尋找廣泛的反饋。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;SLSA 包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;標準&lt;/strong&gt;：（本文檔）業界對 「安全」 軟件供應鏈定義的共識。可能有多種標準來表示安全的多個方面。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;認證&lt;/strong&gt;：組織證明符合這些標準的過程。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fslsa-framework%2Fslsa%2Fblob%2Fmain%2Fcontrols%2FREADME.md&quot; target=&quot;_blank&quot;&gt;技術控制&lt;/a&gt;&lt;/strong&gt;：記錄出處並檢測或防止違規。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;最終，軟件消費者決定信任誰以及執行什麼標準。&lt;/p&gt; 
&lt;p&gt;有鑑於此，認證是一種跨組織邊界傳遞信任的手段。例如，一家公司可能會在內部 「認可」 其內部源和構建系統，同時依靠 OpenSSF 來認可第三方。其他組織可能信任其他認證機構。&lt;/p&gt; 
&lt;p&gt;本文件只討論第一部分，標準。我們希望隨着時間的推移制定認證流程和技術控制。在此期間，這些級別可以作為指導如何保護軟件供應鏈提供價值。&lt;/p&gt; 
&lt;h2&gt;原則&lt;/h2&gt; 
&lt;p&gt;SLSA 側重於以下兩個主要原則：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;非單方面&lt;/strong&gt;：任何人都不能修改軟件供應鏈中任何地方的軟件工件，除非經過至少一個其他 「受信任的人」 的明確審查和批准。目的是預防、威懾和 / 或早期發現風險的變化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可審計&lt;/strong&gt;：軟件工件可以安全透明地追溯來源和依賴項。主要目的是自動分析來源和依賴關係，以及臨時調查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管並不完美，但這兩個原則為廣泛的篡改、混淆和其他供應鏈攻擊提供了實質性的緩解。&lt;/p&gt; 
&lt;p&gt;為了根據上述兩個原則衡量供應鏈的保護程度，我們提出了 SLSA 級別。更高的級別意味着它得到更好的保護。&lt;strong&gt;SLSA 4 是最終目標&lt;/strong&gt;，但對於大型組織而言可能需要多年時間和大量投資。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335534</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335534</guid>
            <pubDate>Sat, 22 Feb 2025 11:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>SBOM Tool：微軟開源的 SBOM 工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SBOM Tool 是一個 SBOM（Software Bill of Materials，軟件物料清單）工具，是一種高度可擴展且企業就緒的工具，可以為各種工件創建與 SPDX 2.2 兼容的 SBOM，用於幫助技術行業和 IT 決策者更好地瞭解其工具的安全性以及軟件供應鏈的依賴關係。&lt;/p&gt; 
&lt;p&gt;SBOM Tool 創建的文檔包含四個主要部分，包括文檔創建信息（其中包含軟件名稱、SPDX 許可證、SPDX 版本、文檔創建者和創建時間）、組成軟件的文件列表、構建軟件時使用的軟件包列表，以及 SBOM 不同元素之間的關係列表。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2022/0714/153013_pdyZ_4937141.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;安裝&lt;/h3&gt; 
&lt;p&gt;SBOM Tool 支持 Windows、Mac 和 Linux，請檢查&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fsbom-tool%2Freleases&quot; target=&quot;_blank&quot;&gt;Release&lt;/a&gt;頁面以轉到你要安裝的工具的版本，然後從 Release 中下載所需運行時的工具。&lt;/p&gt; 
&lt;h3&gt;運行該工具以生成 SBOM&lt;/h3&gt; 
&lt;p&gt;一旦你為你的操作系統安裝了命令行工具，使用以下命令運行該工具。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;generate -b &amp;lt;drop path&amp;gt; -bc &amp;lt;build components path&amp;gt; -pn &amp;lt;package name&amp;gt; -pv &amp;lt;package version&amp;gt; -nsb &amp;lt;namespace uri base&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335527</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335527</guid>
            <pubDate>Sat, 22 Feb 2025 10:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>IntelliJ IDEA 2025.1 EAP 6 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#19191c&quot;&gt;IntelliJ IDEA 2025.1 EAP 6 現已發佈，具體更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h3 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;Kotlin&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;增強&lt;code&gt;main.kts&lt;/code&gt;依賴解析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;IntelliJ IDEA 2025.1 EAP 6 增強了 Kotlin 構建腳本中依賴解析的用戶體驗。以前，&lt;code&gt;main.kts&lt;/code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlin-script-examples%2Fblob%2Fmaster%2Fjvm%2Fmain-kts%2FMainKts.md&quot; target=&quot;_blank&quot;&gt;依賴解析&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;與代碼高亮顯示並行運行，導致代碼先顯示為紅色，然後在依賴加載完成後變為綠色。。此過程有時會導致卡頓，並且缺乏明確的反饋和控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;現在，解決方案更加穩定和可預測。用戶可以使用「Load script dependencies」按鈕跟蹤其進度。沒有依賴項的腳本會立即打開，無需進行不必要的處理即可高亮顯示。此方案還在持續改進中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-32ae2e2461a5d4c5c4d27fb3c56e38acd6b.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Interactive scratch files in K2 mode&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fidea%2Fscratches.html%23use-dependency-in-scratch-file&quot; target=&quot;_blank&quot;&gt;現在，Kotlin K2 模式下可以使用 Scratch 文件&lt;/a&gt;，讓你可以在與項目相同的 IDE 窗口中創建和運行代碼草稿。通過交互式執行，可以立即看到結果，從而減少反饋循環並使實驗更加順暢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c7c33c155cbde65d3512428b3375e3a4e58.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;關於 Kotlin 編譯器插件導致的代碼變更的提示&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;通過此更新，IntelliJ IDEA 現在可以更清楚地瞭解編譯器插件引入的修改，使其行為更加透明。Kotlin 具有多個功能強大的編譯器插件，可用於各個領域，例如&lt;code&gt;kotlinx.serialization&lt;/code&gt;和&lt;code&gt;all-open&lt;/code&gt;，它們可以改變 Kotlin 代碼的行為方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;編譯器插件可以進行的一些關鍵修改包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;&lt;strong&gt;更改聲明方式&lt;/strong&gt;– 編譯器插件可以修改聲明方式，這意味着「final」聲明可能會變為 open 狀態。&lt;code&gt;all-open&lt;/code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fall-open-plugin.html&quot; target=&quot;_blank&quot;&gt;插件&lt;/a&gt;正是這樣做的。為了説明聲明方式已被更改，IntelliJ IDEA 現在會顯示此信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;201&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7158139ac2cece18d2c01ea0f6e1dc34e3f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;&lt;strong&gt;向現有類添加新的 supertypes&amp;nbsp;&lt;/strong&gt;– 某些插件會引入新的 supertypes。&lt;code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fserialization.html&quot; target=&quot;_blank&quot;&gt;kotlinx.serialization&lt;/a&gt;&lt;/code&gt;為使用&lt;code&gt;@Serializable&lt;/code&gt;註釋的聲明添加了 KSerializer supertype。這些 supertypes 現在在 IntelliJ IDEA 中可見。&amp;nbsp;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F02%2Fintellij-idea-2025-1-eap-6%2F&quot; target=&quot;_blank&quot;&gt;查看官方博客&lt;/a&gt;。&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335520/intellij-idea-2025-1-eap-6</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335520/intellij-idea-2025-1-eap-6</guid>
            <pubDate>Sat, 22 Feb 2025 09:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>YY 語音公司接入 DeepSeek：上線 「YYDS」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;YY 公司今日宣佈接入 DeepSeek，並推出「低延時、不卡頓」的 YY-DeepSeek R1-滿血版（簡稱「YYDS」），旗下 YY 直播、YY 語音等產品已經上線產品入口。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c01b204e529a6a97503bf303907c13d975.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據 YY 相關負責人介紹，YYDS 是 YY 順應用戶需求推出的 AI 大模型產品，不僅全面支持 DeepSeek V3 聯網和 R1 深度思考模式，還通過服務器的優化改進解決了 DeepSeek 的卡頓、響應遲緩等問題，實現「低延時、不卡頓的順暢使用體驗」。&lt;/p&gt; 
&lt;p&gt;YY 方面表示，未來，YY 還將與 DeepSeek 進行產品的深度結合，推出具有 DeepSeek 功能的智能體社區，打造智能體官頻及頻道內智能體組件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-81c2ffbea41abd3f4c5c56339c803644e77.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;YY 是一家語音社交、視頻直播企業，公司總部位於廣東省廣州市。YY 是中文「語音」拼音首字母的縮寫，2008 年即時通訊軟件「YY 語音」上線，YY 正式走入大眾視野，後續陸續推出了 YY 直播、百戰直播、Yo 語音、YY 開播工具等多款產品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335518</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335518</guid>
            <pubDate>Sat, 22 Feb 2025 09:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Repomix —— 將你的代碼庫打包成 AI 友好格式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;Repomix（以前稱為 Repopack）是一款功能強大的工具，可將你的整個存儲庫打包成一個 AI 友好文件。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;當你需要將代碼庫提供給大型語言模型 (LLM) 或其他 AI 工具（如 Claude、ChatGPT、DeepSeek、Perplexity、Gemini、Gemma、Llama、Grok 等）時，它非常適合。&lt;/span&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;人工智能優化&lt;/strong&gt;：以人工智能易於理解和處理的方式格式化你的代碼庫。&lt;/li&gt;
&lt;li&gt;&lt;strong style=&quot;color:#1f2328&quot;&gt;Token Counting&lt;/strong&gt;：提供每個文件和整個存儲庫的 token 計數，對於 LLM 上下文限制很有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用簡單&lt;/strong&gt;：你只需一個命令即可打包整個存儲庫。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可定製&lt;/strong&gt;：輕鬆配置要包含或排除的內容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Git-Aware&lt;/strong&gt;：自動遵循你的.gitignore 文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;以安全為中心&lt;/strong&gt;：結合&lt;a href=&quot;https://github.com/secretlint/secretlint&quot;&gt;Secretlint&lt;/a&gt;進行強大的安全檢查，以檢測和防止敏感信息的包含。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/repomix</link>
            <guid isPermaLink="false">https://www.oschina.net/p/repomix</guid>
            <pubDate>Sat, 22 Feb 2025 08:58:00 GMT</pubDate>
        </item>
        <item>
            <title>Mozilla 宣佈領導層變動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla 總裁馬克·瑟曼 (Mark Surman) &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fen%2Fmozilla%2Fmozilla-leadership-growth-planning-updates%2F&quot; target=&quot;_blank&quot;&gt;發文&lt;/a&gt;宣佈了該公司最新的領導層變動情況，包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;Mozilla 領導委員會：&lt;/strong&gt;由 Mozilla 各組織的高管組成的 Mozilla 領導委員會，旨在更好地協調各組織工作。小組成員包括：Jane Silber（&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FMozilla.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;）、Laura Chambers（Mozilla Corporation）、Mohamed Nanabhay（Mozilla Ventures）、Nabiha Syed（Mozilla Foundation）、Ryan Sipes（MZLA/Thunderbird）和 Mark Surman 本人。其中，Mark Surman 將擔任主席。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;新任 Mozilla 基金會董事會主席 Nicole Wong、Mozilla Corporation 董事長 Kerry Cooper 以及 &lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FMozilla.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 主席 Raffi Krikorian。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06539fd667c27535822aae43da11d7dfce0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Firefox 聯合創始人 Mitchell Baker 宣佈離職，不再擔任 Mozilla 基金會和 Mozilla 公司董事會主席或成員。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mark Surman 稱，希望能在今年年底為&amp;nbsp;Mozilla Corporation（MoCo） 和 Mozilla.ai&amp;nbsp;找到新的常任首席執行官。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我們認識到 Mozilla 在財務增長和使命影響方面都面臨重大阻力。雖然 Firefox 仍然是我們工作的核心，但我們也需要採取措施實現多元化：投資尊重隱私的廣告，以在短期內增加新收入；開發值得信賴的開源 AI，以確保中期技術和產品的相關性；並創建在線籌款活動，以吸引更多的支持者。Mozilla 的影響力和生存取決於我們同時加強 Firefox 和尋找新的收入來源以及以新的方式體現我們的使命。這就是我們在所有這些方面努力工作的原因。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335497/mozilla-leadership-growth-planning-updates</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335497/mozilla-leadership-growth-planning-updates</guid>
            <pubDate>Sat, 22 Feb 2025 08:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>美國人工智能安全研究所可能面臨大幅裁員</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F02%2F22%2Fus-ai-safety-institute-could-face-big-cuts%2F&quot; target=&quot;_blank&quot;&gt;外媒消&lt;/a&gt;息稱，美國國家標準與技術研究院（NIST）可能解僱多達 500 名員工，從而進一步威脅到其國內剛剛起步的人工智能（AI）安全組織。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.axios.com%2Fpro%2Ftech-policy%2F2025%2F02%2F19%2Fnist-prepares-to-cut-ai-safety-institute-chips-staff&quot; target=&quot;_blank&quot;&gt;Axios 報道稱&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，美國人工智能安全研究所 (AISI) 和 Chips for America（均隸屬於 NIST）將因裁減試用期員工而「損失慘重」。&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-02-19%2Fcommerce-agency-to-order-mass-firing-of-chips-ai-staffers&quot; target=&quot;_blank&quot;&gt;彭博社&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;則指出，其中一些員工已經收到了即將被解僱的口頭通知。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;甚至在最新的裁員報告發布之前，AISI 的未來就已經顯得不確定。該研究所旨在研究人工智能開發的風險並制定相關標準，是去年根據時任美國總統喬·拜登（Joe Biden）關於人工智能安全的行政命令成立的。唐納德·特朗普（Donald Trump）在重返辦公室的第一天就廢除了該命令，而 AISI 的主任也在今年 2 月初離職。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffortune.com%2F2025%2F02%2F20%2Ftrump-doge-layoffs-nist-aisi-ai-safety-concerns%2F&quot; target=&quot;_blank&quot;&gt;財富&lt;/a&gt;》雜誌採訪了許多人工智能安全和政策組織，他們都對報道的裁員事件提出了批評。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;223&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5fd1098816d9544bbeeb641e241ca7cc411.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人工智能政策中心（Center for AI Policy）執行主任 Jason Green-Lowe 表示：「如果這些裁員得到確認，將嚴重影響政府研究和解決關鍵人工智能安全問題的能力，而這種專業知識目前比以往任何時候都更加重要。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335494/nist-big-cuts</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335494/nist-big-cuts</guid>
            <pubDate>Sat, 22 Feb 2025 08:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>韓國：2 年內大多數半導體技術被中國趕超</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韓聯社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yna.co.kr%2Fview%2FAKR20250221088900017&quot; target=&quot;_blank&quot;&gt;報道稱&lt;/a&gt;，韓國科學技術企劃評價院（KISTEP）23 日發佈的《三大系統領域技術水平深層分析》報告顯示，以去年為準，韓國半導體領域的技術基礎力量在所有項目上都落後於中國。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一報告基於對 39 名當地專家進行的調查，這些人此前曾參與了韓國在 2022 年進行的技術水平評估，當時他們認為韓國在各方面均處於領先地位，但這一結論僅過了兩年就被推翻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;398&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9d0d395bf86e8aed2c302c3235c8af896c0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，韓國在高集成度、低阻抗存儲技術方面排名第二，得分為 90.9%，低於中國的 94.1%；在高性能、低功耗人工智能（AI）半導體領域，韓國以 84.1% 低於中國的 88.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在功率半導體方面，韓國為 67.5%，中國為 79.8%，新一代高性能傳感技術方面，韓國為 81.3%，中國為 83.9%。在半導體先進封裝技術方面，韓國和中國同樣為 74.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業化的觀點來看，韓國在高集成、低阻抗存儲技術和半導體先進封裝技術方面暫時領先於中國。對整個半導體行業技術生命週期的評估調查也顯示，韓國在工藝和量產方面領先於中國，但在基礎、源頭和設計領域落後於中國。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335485</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335485</guid>
            <pubDate>Sat, 22 Feb 2025 07:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>經濟日報：大模型免費不是單方讓利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用戶之間的雙向互動。在這場變革中，雙方都從中有所收穫。儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。此外，免費必然帶來大量用戶，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，多家大模型廠商宣佈免費開放其大模型服務，引發關注。例如，文心一言將於 4 月 1 日 0 時起全面免費，所有 PC 端和 APP 端用戶均可體驗其最新模型；阿里巴巴推出的通義千問系列不僅面向開發者開放 API 接口，還提供了大量免費額度供普通用戶調用；谷歌、Meta 等國際巨頭相繼發佈了可供研究者和小型團隊使用的免費版本……&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從高端科技到親民價格，大模型免費潮的到來並非偶然。一方面，大模型的研發成本雖然高昂，但邊際成本卻相對較低。一旦完成模型訓練，新增用戶並不會顯著增加成本，通過免費開放吸引更多用戶參與，可以在迅速擴大市場份額的同時，積累寶貴的數據資源用於後續優化；另一方面，大模型開源和免費開放的趨勢逐漸明朗，迫使之前選擇閉源的廠商打破封閉生態，以吸引更多的用戶和開發者加入。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業模式角度來看，技術普惠是互聯網開放共享精神的重要體現，免費和低價也是互聯網行業的主流策略之一。從早期搜索引擎的免費使用，到社交媒體平台的零門檻註冊，再到如今雲存儲、辦公軟件等工具的低門檻普及，「免費+增值服務」的模式已經被證明是一種行之有效的商業路徑。在人工智能領域，大模型廠商也藉助技術和資金優勢，通過免費使用形式，加速大模型服務的推廣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用戶之間的雙向互動。在這場變革中，雙方都從中有所收穫。對於用戶而言，這意味着獲取先進 AI 技術的成本大幅下降。對企業而言，海量用戶羣帶來的反饋信息，為調整產品方向提供了依據。大模型走上普惠化道路，本質上是一種雙贏，既滿足了用戶對高效便捷工具的需求，又為企業帶來了新的發展機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。大模型的訓練過程需要消耗大量算力和數據資源，即便是在免費階段，企業也需持續進行迭代升級，投入成本不容小覷。免費低價時代的到來，可能加速企業間的競爭。AI 賽道的老玩家依靠成熟的技術路線和雄厚的資金實力，可以進一步壓縮後來者的生存空間。新進入者如果短期無法找到有效的盈利途徑，那麼長期虧損的風險將不可避免。此外，免費必然帶來大量用戶，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視，否則可能會引發信任危機，進而影響服務提供者的口碑和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費，無疑是當前人工智能發展歷程中的一個重要趨勢。這一趨勢能帶來怎樣的新局面，仍取決於各方能否妥善應對其中的挑戰。只有在確保經濟效益與社會效益相統一的前提下，大模型免費才能真正成為推動全球創新的重要力量。（經濟日報記者，劉 莉）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335477</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335477</guid>
            <pubDate>Sat, 22 Feb 2025 06:48:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Ubuntu 25.04 進入特性凍結階段，預計 4 月正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Canonical 工程師 Utkarsh Gupta &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-devel-announce%2F2025-February%2F001366.html&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt; Ubuntu 25.04 已進入特性凍結階段，並且一切都在按部就班推進。&lt;/p&gt; 
&lt;p&gt;按照計劃，Ubuntu 25.04 將於 3 月 13 日進入 UI 凍結階段，3 月 20 日進入內核特性凍結階段，3 月 27 日發佈 beta 版本，4 月 3 日開始內核凍結，4 月 10 日進入最終凍結階段。如果一切順利，Ubuntu 25.04 將於 4 月 17 日正式發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95aa95335baad09f1eccadb56afefae58b8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Ubuntu 25.04 預計將搭載 Linux 6.14 內核，默認使用 GNOME 48 桌面，Mesa 25.0 將提供更優的圖形驅動支持。GIMP 3.0 將在 Ubuntu 25.04 上提供，此外還將持續改進安裝程序，而且 Canonical 也持續強調性能優化。當然還有許多 Ubuntu 25.04 的底層改進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</guid>
            <pubDate>Sat, 22 Feb 2025 06:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>深圳：近期將發佈人形機器人專項政策</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2 月 23 日，深圳市政府新聞辦召開「打造最好科技創新生態和人才發展環境」新聞發佈會。會上，市工業和信息化局副局長、深圳市人工智能產業辦公室主任林毅表示，深圳在人工智能和機器人領域起步較早、基礎較好，有「兩個一」：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第一個是有一支專業的產業隊伍，組建市人工智能產業辦公室，以專業、精幹隊伍推動產業發展。第二個是有一批優質的企業，全市已匯聚人工智能企業 2600 餘家、獨角獸企業 6 家，機器人上市企業 34 家、獨角獸企業 9 家，創新活力持續迸發。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ec3f039d40cf1534569b1e3badaaa604dd.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;林毅在發佈會上透露，接下來，深圳將向企業發放最高 60%、最高 1000 萬元的「訓力券」補貼，以及模型券、語料券、場景補貼等。&lt;strong&gt;「今年市區將多渠道籌集 45 億元政策資金，3 月起接受企業申報，歡迎廣大企業關注。」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，近期深圳還將發佈人形機器人專項政策，通過揭榜掛帥等方式，對開放應用場景、突破關鍵技術、構建專用數據集、提升規模化製造和應用能力等予以精準支持。同時，還將在全市科技重大專項中設立&lt;strong&gt;人工智能和機器人專項&lt;/strong&gt;，鼓勵產、學、研、用組成創新聯合體進行協同攻關。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335449</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335449</guid>
            <pubDate>Sat, 22 Feb 2025 03:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apple 準備將谷歌 Gemini 與蘋果智能進行整合</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Faaronp613%2Fstatus%2F1893058313316671627&quot; target=&quot;_blank&quot;&gt;據報道&lt;/a&gt;，在與 iOS 18.4 測試版一起推送的後台更新中，蘋果現在在蘋果智能中為第三方模型提供了谷歌和 OpenAI 兩個選項。這代表蘋果有意為蘋果智能提供更多基礎大模型供應。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1576&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/114953_zK72_2720166.png&quot; width=&quot;1278&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雖然這並不一定證實我們會在 iOS 18.4 的後期看到 Gemini 集成，特別是考慮到迄今為止發生的所有其他 Apple Intelligence 延遲，但它幾乎證實它會在不久的將來的某個時候出現，也許是在以後的 iOS 18 更新或 iOS 19 中。蘋果預計將在 iOS 19 中發佈自己的對話式 Siri 模型。&lt;/p&gt; 
&lt;p&gt;谷歌最近發佈了一些新的 Gemini 2.0 模型，包括一個新的推理模型。在不久的將來，這些新模型有可能會在 iPhone 上亮相。&lt;/p&gt; 
&lt;p&gt;有消息稱，蘋果預計將在 iOS 19 中發佈自己的對話 Siri 模型，而蘋果可能會允許用戶在 Gemini 和 ChatGPT 之中進行選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335448</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335448</guid>
            <pubDate>Sat, 22 Feb 2025 03:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>得物端智能視頻封面推薦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h2&gt;什麼要做智能封面？&lt;/h2&gt; 
&lt;p&gt;用戶可以在得物購物，也可以在得物社區分享自己的生活。&lt;/p&gt; 
&lt;p&gt;得物社區中的視頻使用雙列流，每條內容包含封面、標題等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對得物社區的創作者而言，選擇視頻封面是創作鏈路的重要環節。&lt;/li&gt; 
 &lt;li&gt;對得物社區的消費者而言，封面是影響 CTR（點擊率）的關鍵因素。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;封面推薦可以降低創作者的創作成本，提高消費者 CTR。&lt;/p&gt; 
&lt;h2&gt;端智能介紹&lt;/h2&gt; 
&lt;p&gt;端智能（Edge/Client Intelligence）是指在邊緣設備（如物聯網設備、智能傳感器、移動設備等）上進行數據處理和智能決策的能力。與雲計算模型相比，端智能將計算、存儲和分析功能移到更接近數據源的地方，優勢如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;低延遲 ：數據在本地處理，減少了傳輸到遠程服務器的時間，提高響應速度。&lt;/li&gt; 
 &lt;li&gt;節省帶寬 ：通過在本地處理數據，僅發送必要的信息到中心服務器，減少了網絡帶寬的消耗。&lt;/li&gt; 
 &lt;li&gt;數據隱私和安全 ：數據在本地處理，敏感信息不必傳輸到雲，從而提高了數據隱私和安全性。&lt;/li&gt; 
 &lt;li&gt;可靠性 ：在網絡連接不穩定或中斷的情況下，邊緣設備可以繼續進行本地處理和決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管端智能帶來了很多優勢，但在實際應用中也面臨一些挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算能力的侷限性 ：邊緣設備通常具有有限的計算資源，可能無法處理複雜的人工智能模型。&lt;/li&gt; 
 &lt;li&gt;數據一致性與協同 ：多個邊緣設備之間的數據一致性和協調處理仍然是一個挑戰。&lt;/li&gt; 
 &lt;li&gt;設備管理與部署 ：隨着設備數量的增加，邊緣設備的管理、監控和更新變得更加複雜。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到用戶隱私、實時性和服務端壓力，我們選擇用端智能推薦視頻封面，並克服相關的挑戰，最終獲得收益。&lt;/p&gt; 
&lt;h2&gt;得物端智能&lt;/h2&gt; 
&lt;p&gt;對客戶端而言，不需要訓練模型，只需要推理。&lt;/p&gt; 
&lt;p&gt;端智能框架可以簡化推理過程，常見的端智能 SDK 如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;開源 SDK：MNN、TNN、NCNN、&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot; title=&quot;Paddle&quot;&gt;Paddle&lt;/a&gt; Light、TensorFlow Light 等。&lt;/li&gt; 
 &lt;li&gt;閉源 SDK：ByteNN、Pitaya、KwaiNN、Ykit 等。&lt;/li&gt; 
 &lt;li&gt;系統 SDK：CoreML（iOS）、MLKit（Android）等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到 iOS、Android 雙端的通用性和開發成本，得物基於 MNN [1] 框架，開發得物端智能推理基建。端智能基建核心功能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;提供端智能模型管理後台，提供完整鏈路，管理模型的放量。&lt;/li&gt; 
 &lt;li&gt;端側提供統一的基建，方便業務進行模型的下載、運行管理，以及熔斷和降級的處理，降低使用門檻。&lt;/li&gt; 
 &lt;li&gt;提供相對完善的穩定性和性能監控機制，及時報警和出錯時止損。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;整體架構&lt;/h2&gt; 
&lt;p&gt;智能封面主要開發流程如下，算法側產出端智能模型，客戶端調用模型推薦視頻封面。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2a5620265c413a531beb927527e7f902.jpeg&quot; alt=&quot;整體架構.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、內容理解算法&lt;/h1&gt; 
&lt;h2&gt;算法調研&lt;/h2&gt; 
&lt;p&gt;端智能封面推薦場景要求無參圖片質量評價 (NR-IQA)、輕量化，因此基於目前的前沿進展進行調研和摸底，確定相關實現方案。主要的調研內容：&lt;/p&gt; 
&lt;p&gt;Faster-VQA[2]：輕量化的視頻質量評估模型。核心是使用優化版本的 Transformer-&amp;gt;Swin-Transformer 來減少網絡計算，加速效率。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df87fd35910cb12fffbd3bdbc6c9e6ac.jpeg&quot; alt=&quot;算法調研.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;UNIQA[3]：統一的圖像質量評估 (IQA) 框架，旨在同時處理全參考 (FR) 和無參考 (NR) 任務。現有的 IQA 模型通常只能處理 FR 或 NR 任務之一，而人類視覺系統 (HVS) 則可以無縫地在兩者之間轉換，因此提出開發一個能夠像人類一樣處理不同類型圖像質量評估任務的模型，統一全參/無參兩類任務。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://my.oschina.net/u/5783135/blog/3&quot; alt=&quot;統一全參:無參.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LAR-IQA[4]：輕量級的 NR-IQA 模型，基於 MobileNetV3 提出了一種新的無參考圖像質量評估模型 LAR-IQA。該模型旨在解決現有模型在實際應用中的侷限性，特別是對於資源受限的移動設備上的實時圖像質量評估任務。核心貢獻點有：雙分支架構、多色空間訓練、Kolmogorov-Arnold Networks (KAN) 結構代替 MLP。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//19f3a290089fee79f78a533eedab4a76.jpeg&quot; alt=&quot;代替 MLP.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;CLIP-IQA[5]：利用 (引入) 對比語言-圖像預訓練 ( CLIP）模型來評估圖像的視覺感知，包括圖像的質量 (look) 和抽象感知 (feel)，無需進行特定任務的訓練。核心在於利用 CLIP 中蘊含的視覺語言先驗，通過精心設計的提示策略來提升評估性能。同時提出了一種反義詞提示配對策略（如&quot;好照片&quot;和&quot;壞照片&quot;成對使用），以減少語言模糊性並增強模型在視覺感知評估中的表現。此外，為了克服 CLIP 對固定尺寸輸入的要求及其可能引入的額外失真問題，增加了移除位置嵌入的方法，進一步提升了模型與人類感知的一致性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8007ee47452b3e892f575ba205380fdd.jpeg&quot; alt=&quot;人類感知的一致性.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Q-Align[6]：目前 NR-IQA 領域的 SOTA 模型，將大模型引入到視覺打分任務中。通過文本定義的級別（例如好、差等）而不是直接的分數（例如 3.45、1.77）來指導訓練 LLMs。標誌着在視覺評分領域的一個重要進展，通過創新地使用離散文本定義級別來訓練 LMMs，不僅提高了評分的準確性和魯棒性，還為未來的研究開闢了新的方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0c11b8b2d8e879a97035e57dfc5f9d58.jpeg&quot; alt=&quot;未來研究方向.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;技術卡點&lt;/h2&gt; 
&lt;p&gt;端側模型存在體積限制，考慮到帶寬成本、推理速度等，將模型體積控制在 30M 以內。&lt;/p&gt; 
&lt;p&gt;目前圖片質量打分 sota 模型，整體都是從打分效果出發，不考慮模型性能 (size/推理耗時/cpu 性能/MAC 等），最小的模型體積也超過 120M，不滿足端上移植的要求。&lt;/p&gt; 
&lt;p&gt;現有的 Faster-VQA 和 LAR-IQA 雖然模型打分效果都不錯，但是同樣因為尺寸超額無法直接使用，也無法直接移植。&lt;/p&gt; 
&lt;h2&gt;算法方案&lt;/h2&gt; 
&lt;p&gt;輕量化網絡：本次算法模型主要在手機本地部署，受限於帶寬和計算資源限制，對模型尺寸有嚴格要求。綜合考慮後採用業界比較成熟的輕量化模型 MobileNetV3 結構作為基礎框架模塊，從 0 到 1 重新訓練輕量化圖片打分模型。&lt;/p&gt; 
&lt;p&gt;數據清洗與數據集構建：考慮到圖片-質量分數據的缺失，使用開源圖片評價大模型對數據預標註（必要時進行人工介入清洗），通過多模型交叉打分驗證和人工標註，最終總體訓練數據量級超過 10w+。整體流程如圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//368cf547e6c18996fef64c0a32f079fb.jpeg&quot; alt=&quot;輕量化圖片質量模型.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;輕量化圖片質量評價模型&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;loss 優化：loss 設計上採用迴歸任務 loss+主觀感知偏差衡量 loss，超參數控制多 loss 融合。&lt;/p&gt; 
&lt;h2&gt;模型移植&lt;/h2&gt; 
&lt;p&gt;MNN 模型支持 Tensorflow、Caffe、ONNX、Torchscripts 等主流模型文件格式，支持 CNN / RNN / GAN / Transformer 等主流網絡結構。&lt;/p&gt; 
&lt;p&gt;MobileNetV3 使用 PyTorch 框架創建、訓練、持久化模型，需要先轉換成為 ONNX 格式，然後再轉換成 MNN 模型。通過 FP16/Int8 壓縮與量化，模型最終大小為 24M，客戶端可以接受。&lt;/p&gt; 
&lt;p&gt;在客戶端進行模型推理調用時，需關注輸入圖片的尺寸、預處理方式以及輸出數據格式等方面。這些參數與模型相互綁定，且在後續的迭代過程中應保持同步。&lt;/p&gt; 
&lt;h1&gt;三、客戶端部署&lt;/h1&gt; 
&lt;h2&gt;整體流程&lt;/h2&gt; 
&lt;p&gt;整體流程如圖所示，用戶進入封面選擇頁，首先對視頻抽幀，然後調用端智能推理。端智能輸出一個評分，獲取評分最高的圖片作為推薦的封面。為了提高封面識別速度，採用批量異步計算。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1598600ee2eb1723baa183512b197daf.jpeg&quot; alt=&quot;時序圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;時序圖&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;整體架構如圖所示，雙端共用端智能基建，各自實現具體的業務邏輯。ClientIntelligence 作為端智能基建，底層封裝了 MNN、OpenCV 等，實現了模型管理（下載、緩存等）、推理、監控等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//195e00ede76e2528097744efb6e02f28.jpeg&quot; alt=&quot;架構圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;架構圖&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;推理一致性&lt;/h2&gt; 
&lt;p&gt;推理一致性（Inference Consistency）是指在不同時間、不同環境、或不同條件下，模型輸出的結果保持穩定、可靠、一致的能力。這是一個非常重要的概念，尤其是在部署機器學習模型時，確保模型的推理一致性對於維護模型的質量和可信度至關重要。&lt;/p&gt; 
&lt;p&gt;推理不一致的來源：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在不同硬件平台上運行模型（例如不同的 CPU、GPU、TPU 等）可能會導致數值精度上的細微差異，進而影響推理結果。&lt;/li&gt; 
 &lt;li&gt;不同的深度學習框架（例如 TensorFlow、PyTorch ）可能會在推理過程中產生不一致的結果，尤其是涉及到數值計算時。&lt;/li&gt; 
 &lt;li&gt;輸入數據預處理方式不一致導致推理結果不同，可以通過數據標準化、歸一化等減少對推理結果的影響。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;具體到智能封面的場景，主要面臨下面幾種一致性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PyTorch、ONNX、MNN 推理一致性：不一致主要來源框架本身，端上模型為了提高推理速度，會對模型進行量化，比如將浮動精度的模型（如 Float32）轉換為低精度模型（如 INT8）。框架造成的推理結果不一致無法避免。&lt;/li&gt; 
 &lt;li&gt;iOS、Android 雙端推理一致性：輸入數據預處理方式是影響推理一致性的關鍵因素，在智能封面場景，圖片數據的預處理方式需要保持一致。雙端由於硬件的差異，推理結果也不同。此外，使用 CPU、GPU 推理結果也會存在細微的差別。智能封面會對圖片評分，選擇評分最高的圖片，因此硬件造成的差別在本場景下可以接受。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;耗時優化&lt;/h2&gt; 
&lt;p&gt;用戶在封面選擇頁面停留時間有限，因此要儘可能地減小封面推薦耗時。&lt;/p&gt; 
&lt;p&gt;首先要定位到耗時操作，然後有針對性地優化。&lt;/p&gt; 
&lt;p&gt;在本場景中，耗時操作包含抽幀、推理，具體優化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;並行計算：多線程同時抽幀、推理，需要注意的是，並行數需要考慮 CPU 和內存的佔用。&lt;/li&gt; 
 &lt;li&gt;GPU 推理：端智能同時支持 CPU 和 GPU 推理，通過 GPU 推理可以顯著減小耗時。&lt;/li&gt; 
 &lt;li&gt;不同性能的手機處理速度差別較大，低性能手機會適當減小抽幀數量，以提高運行速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;優化後，可以在秒級完成抽幀、封面推薦全過程。&lt;/p&gt; 
&lt;h1&gt;四、收益與效果評估&lt;/h1&gt; 
&lt;h2&gt;線上效果對比&lt;/h2&gt; 
&lt;p&gt;線上智能封面、非智能封面抽樣結果如下，使用智能封面功能，整體畫風更優，更清晰。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//82367a57fdb65c7b8908973deac33e27.png&quot; alt=&quot;智能封面 1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7dfbe0e2e76381f1f945b1b73956358d.jpeg&quot; alt=&quot;智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2d0471bc0033478e0616e89ec20fb68a.jpeg&quot; alt=&quot;智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//174cd7645a7e72a6f73a4989029e9f1d.jpeg&quot; alt=&quot;非智能封面 1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5384ba37f15f0ee2978f27a121e61c5.jpeg&quot; alt=&quot;非智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ccd9fa2ea17edaa6440e68730605b7f6.jpeg&quot; alt=&quot;非智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;非智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;競品效果對比&lt;/h2&gt; 
&lt;p&gt;得物智能封面與主流短視頻平台對比結果如下，整體選幀效果和主流短視頻平台可比，部分場景效果較優。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0cae9d9e138b676d7fd4a3979746f488.jpeg&quot; alt=&quot;得物.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b2043070a1e91837f0d6fd2c80c8515b.jpeg&quot; alt=&quot;得物 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//62202b56d7685513082540403a48ea69.jpeg&quot; alt=&quot;得物 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//222452ec8431cde5c74d5e6365b1892c.jpeg&quot; alt=&quot;得物 4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;得物&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//46a22734dffa5e864f6a8d4696f5a28e.jpeg&quot; alt=&quot;短視頻平台 A.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a7a26ea4a17b409e818b4948af61994.jpeg&quot; alt=&quot;短視頻平台 A2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9baec0020ee399603d698795b12ee610.jpeg&quot; alt=&quot;短視頻平台 a3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1edaed634b79363bafa240fd9fa0523.jpeg&quot; alt=&quot;短視頻平台 a4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 A&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//70f897a252d8e3a0a26a3d1bfb4eb901.jpeg&quot; alt=&quot;短視頻平台 B.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fa75bf53d7f6ac8d789ce116090d816c.jpeg&quot; alt=&quot;短視頻平台 n2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//cb60a0103af7f00c610b3c5ca9bc47b2.jpeg&quot; alt=&quot;短視頻平台 b3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5878e0c6c80e361787b25122c05feda7.jpeg&quot; alt=&quot;短視頻平台 b4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 B&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;人工 GSB 評測&lt;/h2&gt; 
&lt;p&gt;在智能封面功能上線後，我們隨機抽取了線上真實的視頻數據，並通過人工 GSB（Good Same Bad）評估方法，對智能選幀所得的圖片與默認首幀圖片進行了圖像質量的對比分析。&lt;/p&gt; 
&lt;p&gt;多組數據、多人次測評整體評估結果為：Good（好）361 票，Same（一樣）182 票，Bad（差）95 票。&lt;/p&gt; 
&lt;p&gt;相較於默認首幀圖片，智能選幀的 GSB 評分提升了 41.7%，表明選幀功能在圖像質量上有了顯著的改進。&lt;/p&gt; 
&lt;h2&gt;線上實驗收益&lt;/h2&gt; 
&lt;p&gt;在發佈側，採用智能封面點擊率、選擇率作為衡量指標，獲得了顯著的收益，其中智能封面點擊率 5.5%，非首幀封面選擇率相對提升 +25.61%。&lt;/p&gt; 
&lt;p&gt;在內容推薦側，採用推薦雙列流視頻點擊率作為衡量指標，pvctr 和 uvctr 都有明顯提升，與對照組相比，pvctr+13.12%、uvctr+18.05%。實驗結果也表明在推薦雙列場景下，更好得封面內容會帶來更好的消費。&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;本文通過端智能推薦視頻封面，幫助創作者降低發文成本，提高發文質量。&lt;/p&gt; 
&lt;p&gt;我們也希望將端智能用在更多的場景，提高用戶體驗。&lt;/p&gt; 
&lt;h1&gt;六、參考資料&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2FMNN&quot; target=&quot;_blank&quot;&gt;https://github.com/alibaba/MNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling.&quot; European conference on computer vision. Cham: Springer Nature Switzerland, 2022.&lt;/li&gt; 
 &lt;li&gt;Zhou, Hantao, et al. &quot;UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment.&quot; arXiv preprint arXiv:2406.01069 (2024).&lt;/li&gt; 
 &lt;li&gt;Avanaki, Nasim Jamshidi, et al. &quot;LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality Assessment Model.&quot; arXiv preprint arXiv:2408.17057 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Jianyi, Kelvin CK Chan, and Chen Change Loy. &quot;Exploring clip for assessing the look and feel of images.&quot; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 2. 2023.&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Q-align: Teaching lmms for visual scoring via discrete text-defined levels.&quot; arXiv preprint arXiv:2312.17090 (2023).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;文 / Devin&amp;amp;linghu&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17569727</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17569727</guid>
            <pubDate>Sat, 22 Feb 2025 03:39:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>微服務是不是一種錯誤的方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;先説想法&lt;/h2&gt; 
&lt;p&gt;這個標題並非一時興起，也並非譁眾取寵，而是我這段時間以來的思考。為什麼會出現這樣的想法？這還得從一個事實説起。&lt;/p&gt; 
&lt;p&gt;眾所周知，微服務並不能提升整個項目的吞吐量，它的作用僅僅只是把項目按照一定的規則拆分成各種模塊，然後每個模塊都可以交給不同小組去開發。他解決的僅僅是大項目的團隊協作問題。而真正能提升吞吐量的，除了程序本身的質量那就是負載均衡了，而且事實上微服務的架構中，每個服務都是以負載均衡的形式部署的，所以這裏就有一個問題了：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果僅僅是為瞭解決【大項目的團隊協作問題】那麼常規的模塊化設計是不是也能做到？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現在由於 maven 的出現，再加上企業內部可以搭建私服，我們完全可以讓每一個服務都以 jar 包的形式來開發。舉個很簡單的一個例子，比如有一個用戶服務，訂單服務，現在一般的做法是寫一個聚合服務去調用這兩個服務的接口，來實現業務邏輯的整合。&lt;/p&gt; 
&lt;p&gt;那如果把用戶服務換成用戶模塊 jar 包、訂單服務換成訂單模塊 jar 包，以 jar 包的形似傳到私服，然後同樣的寫一個聚合服務，聚合服務把這兩個 jar 包引入進來，是不是也能達到這樣的效果？&lt;/p&gt; 
&lt;p&gt;如果需要負載均衡，那我們把這個聚合服務部署多個就好了，完全不影響。我完全想不到跟微服務比起來有什麼壞處，如果有，歡迎大家指正。&lt;/p&gt; 
&lt;h2&gt;微服務有什麼缺點&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;耦合性太高，雖然開發和部署不會影響別的服務，但是你如果動了接口的出入參，那麼其他服務就得同步升級了，而且是調用了這個接口的服務都要升級，又或者你需要為此單拎一個接口出來，做版本區分。&lt;/li&gt; 
 &lt;li&gt;需要註冊中心，項目會多出一箇中間件，提升複雜度。&lt;/li&gt; 
 &lt;li&gt;會消耗內網帶寬，甚至是公網帶寬，因為服務之間的調用都是通過網絡完成的。&lt;/li&gt; 
 &lt;li&gt;會出現分佈式事務的問題，因為一個事務的操作可能會分佈在不同的服務上執行。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;如果用常規的模塊化方案&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;雖然耦合也高，但是如果你動了接口的出入參甚至是接口名，別的服務是不需要立刻升級的，除非你是在改 bug，但這是被業務逼着升級，因為不升級是有 bug 的，但他不會被技術逼得升級，因為模塊只是被打成了一個 jar 包引入了其他模塊裏，無論你怎麼變，已經部署在線上的別的模塊裏依然是用的你的老代碼。&lt;/li&gt; 
 &lt;li&gt;不需要註冊中心&lt;/li&gt; 
 &lt;li&gt;不會消耗多餘的帶寬資源&lt;/li&gt; 
 &lt;li&gt;不需要分佈式事務了&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;還是壓力問題&lt;/h2&gt; 
&lt;p&gt;一定會有人説，你把這麼多模塊都塞進一個服務裏，那這個服務得部署多少台機器啊。&lt;/p&gt; 
&lt;p&gt;説到這裏，就不得不從全局來看待問題了。我們可以看兩張圖（不好意思，有錯別字，但是已經截圖了就懶得改了，能看懂就行）&lt;/p&gt; 
&lt;p&gt;圖 1&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e81da85cd4f90adbd4212a31278d1923442.png&quot; alt=&quot;圖 1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d3e951984db8d820ea3766422f0dcf1a933.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據上面的兩個圖，我們是不是可以這麼説，微服務在面對相同的流量時根本沒有節約服務器的數量？反而還多了？&lt;/p&gt; 
&lt;p&gt;假如左邊的聚合服務，他的業務量需要 10 台服務器才能支撐，右邊的需要 5 台才能支撐，那麼一共是 15 台。而微服務會導致 A 部署 15 台，B 也部署 15 台，再加上兩個聚合服務，一共需要 32 台以上。&lt;/p&gt; 
&lt;p&gt;當然了，這只是極端的情況，現實中可能 A 服務不需要處理這麼多業務，他可以少部署一點，又或者 B 服務可以少部署一點。但無論怎麼算，服務器都是多了。&lt;/p&gt; 
&lt;p&gt;如果採用 jar 包的形式，那麼只需要 15 台就夠了，10 台用來部署左邊的聚合服務，5 台用來部署右邊的聚合服務。&lt;/p&gt; 
&lt;h2&gt;説到底&lt;/h2&gt; 
&lt;p&gt;這其實就是以三方庫的思想在設計模塊化，如果有一個工具類叫用戶管理，有一個工具類叫支付管理。當你需要開發登錄功能的時候，只需要引入一個 jar 包，然後調用裏面的某個方法就好了，當你需要開發支付功能的時候也一樣，你不需要去學習 dubbo，不需要去學習 springcloud，甚至不需要去關注註冊中心是否掛沒掛，註冊中心的 url 是多少，服務到底有沒有正常發佈，有沒有正常被發現。你會不會覺得這樣有什麼不妥呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;以上只是個人的一點淺薄見解，歡迎大家理性探討。&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/yuyenews/blog/17681156</link>
            <guid isPermaLink="false">https://my.oschina.net/yuyenews/blog/17681156</guid>
            <pubDate>Sat, 22 Feb 2025 03:34:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>月之暗面 Kimi 開源 MoE 模型：Moonlight-16B-A3B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 23 日，月之暗面發佈最新論文《Muon is Scalable for LLM Training》，並首次開源了 MoE 模型 Moonlight-16B-A3B。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0224/104754_uGuz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;論文顯示，月之暗面通過深度改造 Muon 優化器，並將其運用於實際訓練，證明瞭 Muon 在更大規模訓練中的有效性，是 AdamW 訓練效率的 2 倍，且模型性能相當。&lt;/p&gt; 
&lt;p&gt;據悉，本次論文所使用的模型為 Moonlight-16B-A3B，總參數量為 15.29B，激活參數為 2.24B，其使用 Muon 優化器，在 5.7T Tokens 的訓練數據下獲得上述成績。&lt;/p&gt; 
&lt;p&gt;目前，論文及 Moonlight-16B-A3B 相關內容已上架 GitHub 和 HuggingFace。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmoonshotai%2FMoonlight-16B-A3B&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/moonshotai/Moonlight-16B-A3B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMoonshotAI%2FMoonlight&quot; target=&quot;_blank&quot;&gt;https://github.com/MoonshotAI/Moonlight&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335435/moonlight-16b-a3b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335435/moonlight-16b-a3b</guid>
            <pubDate>Sat, 22 Feb 2025 02:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>【贈書】京東圖書熱銷榜前四，鴻蒙開發竟然這麼火？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;本文作者堅果和清華大學出版社來贈書啦~😄&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;自本文發佈一週時間內，在下方評論區發表關於鴻蒙應用開發的相關內容或對本書的期待，將有機會免費獲得一本書。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;我們會根據評論內容，選取 3 名用戶，各贈送一本《極速探索 HarmonyOS NEXT：純血鴻蒙應用開發實踐》。評論區見～&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;大家好，我是《極速探索 HarmonyOS NEXT：純血鴻蒙應用開發實踐》一書的副主編，堅果。1 月份的時候，開源中國的肖老師聯繫我，邀請寫一篇文章。我感到非常榮幸，但考慮到出版社已經放假，無法郵寄書，就耽擱至今，一個月後的今天我打算動筆開始輸出。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;一、寫書的初衷：填補知識空白，助力生態發展&lt;/h2&gt; 
&lt;p&gt;在科技的廣袤星空中，操作系統猶如最璀璨的星辰之一，它關乎着無數智能設備的運轉，更牽繫着國家科技自主與發展的命脈。當我在最初接觸到鴻蒙時，率先接觸的還是開源鴻蒙，那個時候在我的眼裏，開源鴻蒙就是一片尚未開墾完全的荒地，生態的雛形雖已顯現，卻遠談不上繁榮昌盛。但正是這份艱難，讓我深知，有些事，明知難為而必須為之，因為那是正確且意義非凡的方向。&lt;/p&gt; 
&lt;p&gt;在此之前，我一直在技術博客領域耕耘，分享着各種技術心得與見解。那些博客文章，如同點點繁星，照亮了部分開發者探索鴻蒙的初始道路，同時也是我自己學習路上的一個見證。&lt;/p&gt; 
&lt;p&gt;然而，我逐漸發現，博客的零散性使得開發者們難以從中構建起對鴻蒙系統的全面認知。每個博客只能聚焦於某個具體的技術點或是當下熱點，無法形成系統性的知識架構。很多開發者在閲讀博客後，雖然對某些技術有了初步的瞭解，但當他們想要進一步深入，去構建自己的鴻蒙原生應用或是參與到鴻蒙生態建設中時，卻常常感到無從下手，彷彿置身於一片技術的迷霧之中。&lt;/p&gt; 
&lt;p&gt;基於此，我萌生了和小夥伴們一起撰寫一本系統性的鴻蒙開發書籍的想法。我希望能夠為開發者們提供一份詳盡的地圖，讓他們能夠清晰地看到鴻蒙生態的全貌，從基礎的系統架構到複雜的應用開發流程，從分佈式技術的原理到實際的場景應用，一應俱全。這本書不僅僅是為了傳授技術知識，更是為了吸引更多的人加入到鴻蒙生態的建設中來。&lt;/p&gt; 
&lt;p&gt;我們深知，鴻蒙的發展離不開廣大開發者的共同努力，只有匯聚起各方的力量，才能讓這個生態茁壯成長，成為推動鴻蒙生態的進步的強大動力。在此我乃至堅果派的初心和使命就是讓中國乃至全球的每一個開發者都認識鴻蒙、瞭解鴻蒙，共同參與到鴻蒙生態的建設中來。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; src=&quot;https://oscimg.oschina.net/oscnet//ec76414c76af1a7f723df21e221999d0.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;二、鴻蒙生態的現狀：艱難起步，充滿挑戰&lt;/h2&gt; 
&lt;p&gt;目前，鴻蒙生態已經取得了一定的進展，但仍然面臨諸多挑戰。據華為官方數據顯示，鴻蒙系統已有超過 1.5 萬個應用和元服務上架，覆蓋辦公、社交、娛樂等 18 個垂直領域，能夠滿足用戶 99.9% 的使用時長。然而，與安卓和 iOS 相比，鴻蒙的應用數量仍有較大差距。安卓應用商店的應用數量已經超過 300 萬，iOS 應用商店的應用數量也超過 200 萬。雖然鴻蒙應用已經能夠滿足大部分用戶的日常使用需求，但在一些垂直領域，如專業設計、高端遊戲等，應用的豐富度和成熟度仍有待提高。&lt;/p&gt; 
&lt;p&gt;在寫作的初期，生態的不完善意味着很多技術細節缺乏足夠的參考資料和實踐案例。但我堅信，越是艱難處，越是修心時。我們一頭扎進技術研究的海洋，與堅果派裏的同樣懷揣着熱情的開發者們交流探討，常常為了一個技術原理或是實現方式爭論得面紅耳赤，卻也在這過程中碰撞出智慧的火花。&lt;/p&gt; 
&lt;p&gt;那些無數個日夜，我們聚在一起開會，常常一開就是到凌晨。大家的眼睛裏雖佈滿血絲，卻閃爍着對鴻矇事業的執着光芒。我們深知，自己正在做的，是為鴻蒙這片黑土地添磚加瓦，讓它能夠茁壯成長，支撐起我國智能設備的未來天空。&lt;/p&gt; 
&lt;p&gt;如今這本書位居京東圖書熱銷榜前四，證明我們的選擇是正確的。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; src=&quot;https://oscimg.oschina.net/oscnet//f7459720ca9a7884234df031e1b2c4e2.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;三、寫書過程中的挑戰：資料匱乏，團隊協作&lt;/h2&gt; 
&lt;p&gt;當然寫博客與寫書，有着本質的區別。博客更像是一時靈感的迸發，是對某個具體技術點或是當下熱點的快速分享，內容相對零散，追求的是時效性和簡潔性。而寫書，則是一項系統性的工程，它需要構建起完整的知識體系，從基礎概念到深入應用，從技術原理到實踐案例，層層遞進，環環相扣。每一個章節的安排，每一句話的斟酌，都要為讀者呈現出一個清晰、全面且深入的開源鴻蒙世界。&lt;/p&gt; 
&lt;p&gt;為了做好內容支撐，我們深入到鴻蒙原生應用開發的每一個角落。從基礎環境開始，到它的分佈式技術，感受那讓不同設備無縫協同、宛如一體的神奇魅力；再到它的應用開發框架，體會開發者如何在這個舞台上施展才華，創造出豐富多彩的應用生態。我也拜訪瞭解了眾多參與鴻蒙研發的企業和開發者，聆聽他們背後的故事，讓我更好的瞭解這本書如何編寫。&lt;/p&gt; 
&lt;p&gt;在書中，我特別加入了大量實戰案例，如堅果單車等，這些案例不僅展示了鴻蒙系統的實際應用場景，還幫助開發者更好地理解和掌握鴻蒙開發技術。例如，堅果單車項目通過使用華為賬號服務（Account Kit）、地圖服務（Map Kit）、推送服務（Push Kit）等，實現了共享單車的完整功能，包括用戶註冊登錄、地圖定位、車輛預訂和消息推送等。這些實戰案例為開發者提供了寶貴的參考和借鑑。&lt;/p&gt; 
&lt;p&gt;此外，為了滿足不同用戶的學習需求，我們還提供了對應的 PPT 和視頻教程。PPT 詳細講解了鴻蒙開發的核心知識點，視頻教程則通過實際操作演示，幫助開發者更直觀地理解鴻蒙開發流程。這些資源不僅豐富了書籍的內容，也為開發者提供了多種學習方式，方便他們根據自己的喜好和需求選擇合適的學習途徑。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;四、選擇紙質書的原因：傳承與體驗的考量&lt;/h2&gt; 
&lt;p&gt;在這個電子書盛行的時代，我卻毅然選擇了紙質書的形式。這並非是對潮流的逆反，而是出於對知識傳承與閲讀體驗的深思熟慮。紙質書有着獨特的質感與分量，它承載着知識的厚重與歷史的沉澱。當讀者翻開這本書的每一頁，指尖觸碰到紙張的那一刻，彷彿能夠感受到知識的溫度，建立起與作者更深層次的情感連接。而且，紙質書便於讀者在書桌前靜心研讀，做筆記、標註重點，這種沉浸式的學習體驗是電子書難以比擬的。它能夠更好地幫助讀者深入思考、消化吸收書中的知識，讓每一個技術要點都深深烙印在腦海中。&lt;/p&gt; 
&lt;p&gt;此外，紙質書的收藏價值也是我選擇它的一個重要原因。一本好書，不僅能夠提供知識，還能成為讀者書架上的寶貴財富，隨時可以翻閲回顧。我希望這本書能夠成為開發者們在鴻蒙技術道路上的一位良師益友，陪伴他們走過一段又一段的技術征程。如今圖書出版，我也是捐贈了價值 10 餘萬的書籍以及學習資料到雲南、貴州、湖北、廣西、甘肅、鄭州、東北、河南、黑龍江八省，八校！希望能有更多的學生開發者受益。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;image-20250224103538229&quot; src=&quot;https://oscimg.oschina.net/oscnet//813eecaf243c8c157a1afa29c98b9a4b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;五、寫書的意義：家國情懷與未來展望&lt;/h2&gt; 
&lt;p&gt;這一路走來，有過迷茫，有過疲憊，但每當想到自己是在為整個的鴻蒙生態的完整建設添磚加瓦，是在陪伴開源鴻蒙共同成長，內心便湧起無盡的力量。我堅信，只要我們秉持着長期主義的理念，持續不斷地為開源鴻蒙的生態建設貢獻力量，它終將成為科技領域的參天大樹，為我國的智能發展撐起一片廣闊的天地。&lt;/p&gt; 
&lt;p&gt;而這本書，就是我們在這段征程中留下的深深足跡，也是我向所有為開源鴻矇事業奮鬥的人們獻上的一份誠摯敬意，更是我對家國科技未來充滿信心的美好期許。&lt;/p&gt; 
&lt;p&gt;最後，堅果派的初心和使命就是讓中國乃至全球的每一個開發者都認識鴻蒙、瞭解鴻蒙。我深懷感激之情，向每一位給予我這本書厚愛與支持的讀者、同行、合作伙伴、出版社以及親朋好友致以最誠摯的謝意。還有那些在背後默默支持、鼓勵我們的親朋好友以及家人們，你們的熱情接納、積極推薦以及真誠反饋，如同璀璨繁星照亮了我前行的道路。&lt;/p&gt; 
&lt;p&gt;感謝大家共同參與到鴻蒙生態的建設中來。我相信，通過我們的共同努力，鴻蒙生態將不斷壯大，為全球科技發展貢獻中國智慧和力量。在未來的日子裏，無論鴻蒙走向何方，我都將始終如一地陪伴在它身旁，見證它的輝煌，續寫屬於我們共同的華麗新篇章。最後想説選擇鴻蒙正當時，歡迎大家與我們一起選擇鴻蒙。加入鴻蒙大家庭。&lt;/p&gt; 
&lt;p&gt;最後附上個人微信。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; height=&quot;406&quot; src=&quot;https://oscimg.oschina.net/oscnet//f7ba420550a5f811f61c72ca2eef10cb.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3936705/blog/17752894</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3936705/blog/17752894</guid>
            <pubDate>Sat, 22 Feb 2025 02:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>超 20 家央企接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近來，國資央企「牽手」DeepSeek 已成為一股新風潮。據《經濟參考報》記者不完全統計，目前有超 20 家央企接入 DeepSeek，涉及能源、通信、汽車、金融、建築等多個領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;業內人士指出，這一系列動作的背後是國資央企全面開展「AI+專項行動」，加速探索人工智能深度應用到豐富多樣的生產場景。國務院國資委近日召開中央企業「AI+」專項行動深化部署會。會上發佈了國資央企「AI+」專項行動實施要點，啓動了戰略性高價值場景建設專項工作。會議要求，中央企業在編制企業「十五五」規劃中要將發展人工智能作為重點，打造更多科技領軍企業，孵化培育一批初創企業。要加大相關資金投入，持續壯大發展人工智能產業。要優化人才引育，建立更加符合行業特點規律的人才評價體系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全面接入只是央企擁抱 DeepSeek 的一個開始。有業內人士表示，如何將 DeepSeek 的通用化技術方案與具體業務需求深度結合，仍需要大量定製化開發和測試。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國企業改革研究會研究員周麗莎稱，「DeepSeek 出現實現了 AI 平權，未來 AI 競爭就是數據規模和質量，央企擁有龐大的數據資源，與 DeepSeek 結合後，數據流通與市場化進程加速。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周麗莎表示，汽車行業的大模型，可用於企業數據分析和智能決策，提升智能駕駛和車載交互能力。交通與物流領域等央企也可能會利用 AI 技術優化交通基礎設施建設、物流配送路線規劃、智能倉儲管理等。科技與通信領域央企可能會與 DeepSeek 合作，推動人工智能在通信技術、網絡安全、智能辦公等領域的應用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335429</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335429</guid>
            <pubDate>Sat, 22 Feb 2025 02:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>新款 MacBook Air 有望 3 月推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 23 日，據彭博社記者 Mark Gurman 獲悉，搭載 M4 處理器的 MacBook Air 有望在下個月推出。&lt;/p&gt; 
&lt;p&gt;Gurman 表示，蘋果的營銷、銷售和零售團隊已經在為這款新品的發佈進行準備，同時蘋果在售的 MacBook Air 商店庫存也正在減少，這通常意味着產品更新臨近。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4abdbdc9b62de0f82a6ebe56037c2bf7b90.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從去年更新的 MacBook Pro 來看，&lt;strong&gt;新款 MacBook Air 除了處理器升級為 M4，還有望獲得雷靂 4 接口、更多外接顯示屏支持、納米塗層屏幕可選項、攝像頭人物居中等等更新&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;目前 M3 MacBook Air 京東平台國補價格 6679.2 元起，如果 M4 MacBook Air 支持國補，價格也會在這個數字上下。&lt;/p&gt; 
&lt;p&gt;Apple 智能也有了新的時間表。蘋果日前宣佈了 Apple 智能將於四月份支持中文在內的更多語言，也發佈了支持中文 Apple 智能的 iOS 18.4 測試版。不過 Gurman 預計，國行版本的 Apple 智能將於 iOS 18.5 版本時獲批推出，時間大概會在今年年中。&lt;/p&gt; 
&lt;p&gt;目前，海外 Apple 智能僅集成了 ChatGPT 一個第三方大模型，有消息指出，與 Google Gemini 的合作即將到來。在與 iOS 18.4 測試版一起推送的後端更新中，有開發者發現了 Apple 智能第三方大模型中提供了「Google」和「OpenAI」選項。&lt;/p&gt; 
&lt;p&gt;而此前 The Information 的消息指出，中國大陸版的 Apple 智能將集成阿里通義大模型以及百度文心大模型，其中前者將負責更主要的任務處理。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335426</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335426</guid>
            <pubDate>Sat, 22 Feb 2025 02:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek 開源周」首發項目：FlashMLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 「開源周」今日正式&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fdeepseek_ai%2Fstatus%2F1893836827574030466&quot; target=&quot;_blank&quot;&gt;開啓&lt;/a&gt;，首個開源的代碼倉庫為 FlashMLA—— 針對 Hopper GPU 優化的高效 MLA 解碼內核，專為處理可變長度序列而設計，目前已投入生產環境。&lt;/p&gt; 
&lt;p&gt;據介紹，FlashMLA 專門針對多層注意力機制進行了優化，能夠加速 LLM 的解碼過程，從而提高模型的響應速度和吞吐量。FlashMLA 可在 H800 芯片上實現最高 3000GB/S 的帶寬和 580 TFLOPS 的算力。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FFlashMLA&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/FlashMLA&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;1404&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/102144_YFdi_2720166.png&quot; width=&quot;1270&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335425/deepseek-flashmla</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335425/deepseek-flashmla</guid>
            <pubDate>Sat, 22 Feb 2025 02:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>