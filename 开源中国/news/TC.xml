<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 15 Apr 2025 02:36:30 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Ferron 1.0.0 正式發佈：快速、內存安全的 Rust Web 框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Ferron 首個穩定版本 1.0.0 已正式&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fferronweb%2Fferron%2Freleases%2Ftag%2F1.0.0&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;&lt;/u&gt;，該項目是用 Rust 編寫的快速、內存安全的 Web 服務器。經過廣泛的發展和嚴格的測試，Ferron 已經準備好以速度、安全性和可靠性來運行 Web 應用程序。&lt;/p&gt; 
&lt;p&gt;部分功能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;高效靜態文件服務&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內置 TLS 支持&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持 HTTP/2&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;具備反向代理和正向代理功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可在多個後端服務器間進行負載均衡&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;緩存機制，縮短響應時間&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c42ca29f5d525d94e403424d2058092a9ba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Ferron 旨在提供強大且高效的 Web 服務器體驗。採用 Rust 語言構建，確保內存安全和高性能，使其成為現代 Web 應用的理想選擇。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內存安全 - 利用 Rust 的所有權模型，Ferron 消除了常見的內存錯誤，確保安全穩定的環境。&lt;/li&gt; 
 &lt;li&gt;高性能 - 優化速度，Ferron 高效處理併發請求，提供快速響應時間。&lt;/li&gt; 
 &lt;li&gt;模塊化架構 - Ferron 的模塊化設計允許輕鬆定製和擴展，使開發者能夠根據特定需求定製服務器。&lt;/li&gt; 
 &lt;li&gt;文檔完備 - &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ferronweb.org%2Fdocs%2Finstallation&quot; target=&quot;_blank&quot;&gt;文檔&lt;/a&gt;提供了有關安裝、配置和使用的詳細信息，幫助您快速入門。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ferronweb.org%2Fblog%2Fferron-1-0-0-a-new-era-for-web-servers%2F&quot; target=&quot;_blank&quot;&gt;發佈公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344610/ferron-1-0-0-a-new-era-for-web-servers</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344610/ferron-1-0-0-a-new-era-for-web-servers</guid>
            <pubDate>Tue, 15 Apr 2025 02:31:05 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 發佈 GPT-4.1 系列模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 在當地時間週一&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fgpt-4-1%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;了名為 GPT-4.1 的新模型系列，共包含：GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，這些模型的性能全面超越 GPT-4o 和 GPT-4o mini，在編碼和指令跟蹤方面均有顯著提升。它們擁有一個包含 100 萬個 token 的上下文窗口，這意味着它們可以一次性輸入大約 75 萬個單詞，並且能夠通過改進的長上下文理解更好地利用這些上下文，同時其知識截止日期已更新至 2024 年 6 月。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這些多模態模型可以通過 OpenAI 的 API 獲取，但 ChatGPT 無法使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;351&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-065cfc590086bc15c87619c5f627883137e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPT-4.1 的到來正值 OpenAI 的競爭對手谷歌和 Anthropic 加緊構建複雜編程模型之際。谷歌最近發佈的 Gemini 2.5 Pro 也擁有 100 萬個 token 上下文窗口，在熱門編碼基準測試中名列前茅。Anthropic 的 Claude 3.7 Sonnet 和&amp;nbsp; DeepSeek 的升級版 V3 也同樣名列前茅。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;訓練能夠執行復雜軟件工程任務的 AI 編碼模型是包括 OpenAI 在內的許多科技巨頭的目標。OpenAI 的宏偉目標是打造「代理軟件工程師」，正如其首席財務官 Sarah Friar 上個月在倫敦舉行的一次科技峯會上所説。該公司聲稱，其未來的模型將能夠端到端地編寫整個應用程序，處理質量保證、錯誤測試和文檔編寫等方面的工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPT-4.1 是朝着這個方向邁出的一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 的一位發言人通過電子郵件告訴 &lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F14%2Fopenais-new-gpt-4-1-models-focus-on-coding%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;：「我們根據直接反饋對 GPT-4.1 進行了優化，使其更適合實際使用，從而改進了開發者最關心的領域：前端編碼、減少不必要的編輯、可靠地遵循格式、遵循響應結構和順序、保持一致的工具使用等等。這些改進使開發者能夠構建出在實際軟件工程任務中表現更出色的代理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 聲稱，完整的 GPT-4.1 模型在包括 SWE-bench 在內的編碼基準測試中均優於其 GPT-4o 和 GPT-4o mini 模型。據稱，GPT-4.1 mini 和 nano 效率更高、速度更快，但準確性有所降低。OpenAI 表示，GPT-4.1 nano 是其迄今為止速度最快、成本最低的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPT-4.1 每百萬輸入 token 成本為 2 美元，每百萬輸出 token 成本為 8 美元。GPT-4.1 mini 每百萬輸入 token 成本為 0.40 美元，每百萬輸出 token 成本為 1.60 美元；GPT-4.1 nano 每百萬輸入 token 成本為 0.10 美元，每百萬輸出 token 成本為 0.40 美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據 OpenAI 的內部測試，GPT-4.1 可以一次性生成比 GPT-4o 更多的 token（32,768 對 16,384），在 SWE-bench Verified 上的得分在 52% 到 54.6% 之間。這些數字略低於谷歌和 Anthropic 在同一基準測試中分別報告的 Gemini 2.5 Pro（63.8%）和 Claude 3.7 Sonnet（62.3%）的得分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;262&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0415/103510_dAsv_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在另一項評估中，OpenAI 使用 Video-MME 測試了 GPT-4.1，該模型旨在衡量模型「理解」視頻內容的能力。OpenAI 聲稱，GPT-4.1 在「長篇無字幕」視頻類別中達到了 72% 的最高準確率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;雖然 GPT-4.1 在基準測試中得分相當不錯，並且「知識截止」時間也較新，使其能夠更好地參考時事（截至 2024 年 6 月），但必須牢記，即使是當今一些最好的模型，在處理一些專家不會犯錯的任務時也會遇到困難。例如，許多研究表明 ，代碼生成模型通常無法修復安全漏洞和 bug，甚至會引入這些漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 也承認，GPT-4.1 處理的輸入 token 越多，可靠性就越低（即更容易出錯）。在該公司自己的測試 OpenAI-MRCR 中，該模型的準確率從 8,000 個 token 時的 84% 左右下降到 100 萬個 token 時的 50%。該公司表示，GPT-4.1 也比 GPT-4o 更「直白」，有時需要更具體、更明確的提示。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344606/openais-gpt-4-1-models</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344606/openais-gpt-4-1-models</guid>
            <pubDate>Tue, 15 Apr 2025 02:26:42 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>智譜開源 32B/9B 系列 GLM 模型，極速版最高達到 200tokens/秒</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;智譜&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpyeqH8jGvH_dVPmekOQ1VQ&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將開源 32B/9B 系列 GLM 模型，涵蓋基座、推理、沉思模型，均遵循 MIT 許可協議。其中，推理模型 GLM-Z1-32B-0414 性能媲美 DeepSeek-R1 等頂尖模型，實測推理速度可達 200 Tokens/秒（MaaS 平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fbigmodel.cn&quot; target=&quot;_blank&quot;&gt;bigmodel.cn&lt;/a&gt;），目前國內商業模型中速度最快。此外，其價格僅為 DeepSeek-R1 的 1/30。&lt;/p&gt; 
&lt;p&gt;同時，該公司宣佈啓用全新域名 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FZ.ai&quot; target=&quot;_blank&quot;&gt;Z.ai&lt;/a&gt;，目前該平台整合了 32B 基座、推理、沉思三類 GLM 模型，後續將作為智譜最新模型的交互體驗入口。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-75970a5c47cb53cb14c3d18e6c8ec7f20c1.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據介紹，&lt;strong style=&quot;color:#1f2329&quot;&gt;基座模型 GLM-4-32B-0414&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;擁有 320 億參數，其性能可與國內、外參數量更大的主流模型相媲美。該模型利用 15T 高質量數據進行預訓練，特別納入了豐富的推理類合成數據，為後續的強化學習擴展奠定了基礎。在後訓練階段，除了進行面向對話場景的人類偏好對齊，我們還通過拒絕採樣和強化學習等技術，重點增強了模型在指令遵循、工程代碼生成、函數調用等任務上的表現，以強化智能體任務所需的原子能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;GLM-4-32B-0414 在工程代碼、Artifacts 生成、函數調用、搜索問答及報告撰寫等任務上均表現出色，部分 Benchmark 指標已接近甚至超越 GPT-4o、DeepSeek-V3-0324（671B）等更大模型的水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;243&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5d11204c0200644789c18f48b49b6c892b9.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;GLM-4-32B-0414 進一步提升了代碼生成能力，可處理並生成結構更復雜的單文件代碼。&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#245bdb&quot;&gt;Z.ai&lt;/strong&gt;&amp;nbsp;的&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;對話模式內建了預覽功能，支持對生成的 HTML 和 SVG 進行可視化查看，便於用戶評估生成結果和進行迭代優化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;GLM-Z1-32B-0414&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;是一款具備深度思考能力的推理模型。該模型在 GLM-4-32B-0414 的基礎上，採用了冷啓動與擴展強化學習策略，並針對數學、代碼、邏輯等關鍵任務進行了深度優化訓練。與基礎模型相比，GLM-Z1-32B-0414 的數理能力和複雜問題解決能力得到顯著增強。此外，訓練中整合了基於對戰排序反饋的通用強化學習技術，有效提升了模型的通用能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;在部分任務上，&lt;/span&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;GLM-Z1-32B-0414 憑藉 32B 參數，其性能已能與擁有 671B 參數的 DeepSeek-R1 相媲美。&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;通過在 AIME 24/25、LiveCodeBench、GPQA 等基準測試中的評估，GLM-Z1-32B-0414 展現了較強的數理推理能力，能夠支持解決更廣泛複雜任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;240&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4d4a3d01b9d1462df525f8d6a9776a95eeb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;GLM-Z1-9B-0414&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;則沿用了上述一系列技術，訓練了一個 9B 的小尺寸模型。雖然參數量更少，GLM-Z1-9B-0414 在數學推理及通用任務上依然表現出色，整體性能已躋身同尺寸開源模型的領先水平。特別是在資源受限的場景下，該模型可以很好地在效率與效果之間取得平衡，為需要輕量化部署的用戶提供強有力的選擇。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;238&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a0f3496b2b94f35f8b92209b4662f043084.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;智譜方面稱，&lt;strong style=&quot;color:#1f2329&quot;&gt;沉思模型 GLM-Z1-Rumination&lt;/strong&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;-32B&lt;/strong&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;-0414&lt;/strong&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;則&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;代表了&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;該公司&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;對&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;AGI&lt;/span&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;&amp;nbsp;未來形態的下一步探索。與一般推理模型不同，沉思模型通過更多步驟的深度思考來解決高度開放與複雜的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;其關鍵創新在於，它能在深度思考過程中整合搜索工具處理複雜任務，並運用多種規則型獎勵機制來指導和擴展端到端的強化學習訓練。該模型支持「&lt;/span&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;自主提出問題—搜索信息—構建分析—完成任務&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;」的完整研究閉環，從而在&lt;/span&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;研究型寫作&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;和&lt;/span&gt;&lt;strong style=&quot;color:#1f2329&quot;&gt;複雜檢索任務&lt;/strong&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;上的能力得到了顯著提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;除模型開源外，基座、推理兩類模型也已同步上線智譜 MaaS 開放平台（bigmodel.cn），面向企業與開發者提供 API 服務。 本次上線的基座模型提供兩個版本：GLM-4-Air-250414 和 GLM-4-Flash-250414，其中後者完全免費。 &lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2329; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;上線的推理模型分為三個版本，分別滿足不同場景需求：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;GLM-Z1-AirX（極速版）：定位國內最快推理模型，推理速度可達 200 tokens/秒，比常規快 8 倍；&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;GLM-Z1-Air（高性價比版）：價格僅為 DeepSeek-R1 的 1/30，適合高頻調用場景；&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;GLM-Z1-Flash（免費版）：支持免費使用，旨在進一步降低模型使用門檻。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#1f2329&quot;&gt;對應模型價格表：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-16d33a610a5d7b5afd3524e7f55816d7a1c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344598</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344598</guid>
            <pubDate>Tue, 15 Apr 2025 02:01:42 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高德發佈全球首個地圖領域 AI 導航智能體</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;高德地圖今日宣佈推出基於地圖的 AI 導航智能體（NaviAgent）。據技術負責人介紹，其核心架構採用 Planner-Executor 模式，通過感知、規劃、執行、表達四大模塊構建智能閉環，集成多項高德核心技術。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/191004_ga7U_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方表示，該智能體「更像經驗豐富的‘老司機’」，能實時感知路況、預判風險並主動調整策略。&lt;/p&gt; 
&lt;p&gt;據瞭解，以高速駕車場景為例，其支持通過&lt;strong&gt;感知車道級交通流變化、動態事件、事故佔道等信息&lt;/strong&gt;，結合用戶路線，AI 導航智能體會&lt;strong&gt;自動開啓領航功能，推薦全局最優車道&lt;/strong&gt;，讓變道決策更從容高效。&lt;/p&gt; 
&lt;p&gt;同時，在停車場景中，&lt;strong&gt;超視距感知能力可覆蓋至「最後 100 米」&lt;/strong&gt;：當用戶輸入目的地後，系統會在距離終點 5 公里時啓動智能分析，主動推薦目的地周邊的空閒停車位；基於時空感知和推理能力，補全停車後的步行導航指引，直達目的地入口，實現無縫銜接。&lt;/p&gt; 
&lt;p&gt;其紅綠燈 AI 領航功能已覆蓋全國，可結合實時交通信息與超視距感知技術，動態提供車速建議、車道選擇及起步提醒，大幅提升過燈效率。&lt;/p&gt; 
&lt;p&gt;AI 導航智能體還構建了包含情感識別、意圖理解、情緒表達在內的三維交互體系，突破性地將服務拓展至情緒價值領域。譬如，當用戶完成優質的駕駛操作時，還會&lt;strong&gt;收到導航智能體的及時讚許&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344517</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344517</guid>
            <pubDate>Sun, 13 Apr 2025 11:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>一次提交更新兩個倉庫，Get 更優雅的 GitHub/Gitee 倉庫鏡像同步</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;現在很多開發者都不滿足於只在一個代碼託管平台活躍，將項目同時託管於 Gitee 和 GitHub 是目前國內很多開發者的選擇，既擁有更快的訪問和代碼推拉速度，也可以和更多國際上的優秀開發者交流。&lt;/p&gt; 
&lt;p&gt;Gitee 的&lt;strong&gt;倉庫鏡像管理&lt;/strong&gt;功能在這兩天重新受到了開發者們的關注，今天馬建倉再次為大家介紹一下這個超方便的功能，方便各位開發者更優雅地將代碼在世界上最大的兩個代碼託管平台之間同步。&lt;/p&gt; 
&lt;h2&gt;什麼是倉庫鏡像管理&lt;/h2&gt; 
&lt;p&gt;倉庫鏡像管理功能用於配置和管理倉庫鏡像；配置倉庫鏡像可以實現不同平台之間倉庫分支、標籤和提交信息的自動同步。&lt;/p&gt; 
&lt;p&gt;簡單來説，就是你可以&lt;strong&gt;通過倉庫鏡像管理功能實現 Gitee 和 GitHub 兩個平台的雙向自動同步&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;將 Gitee 的倉庫鏡像至 GitHub&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;配置此鏡像後，當你提交代碼到 Gitee 的倉庫時，Gitee 會自動向 GitHub 同步倉庫。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/184829_hrc3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;將 GitHub 的倉庫鏡像至 Gitee&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;你可以根據自身需求選擇&lt;strong&gt;自動鏡像&lt;/strong&gt;或&lt;strong&gt;手動鏡像&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自動鏡像&lt;/strong&gt;：當你提交代碼到 GitHub 鏡像倉庫時，Gitee 會自動從 GitHub 同步倉庫。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;手動鏡像&lt;/strong&gt;：只有你手動點擊更新按鍵時，Gitee 才會從 GitHub 同步倉庫。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/184845_9D4v_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;倉庫鏡像會同步以下內容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分支（Branches）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;標籤（Tags）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提交記錄（Commits）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何為自己的倉庫設置鏡像&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以將 GitHub 的倉庫鏡像至 Gitee 為例&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;進入需要使用鏡像功能的倉庫，進入「管理」找到「倉庫鏡像管理」選項，點擊「添加鏡像」按鈕，如果你還沒有綁定 GitHub 帳號，請根據彈窗提示綁定 GitHub 帳號；&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/184923_KLAZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;添加鏡像&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/184946_8GX5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在「鏡像方向」中選擇 Pull 方向；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「鏡像倉庫」下拉列表中選擇需要鏡像的倉庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「私人令牌」中輸入你的 GitHub 私人令牌；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/184959_x8O7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;私人令牌中必須包含對&amp;nbsp;&lt;code&gt;repo&lt;/code&gt;&amp;nbsp;的訪問授權，否則添加後鏡像不可用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;根據自身需求選擇是否勾選「自動從 GitHub 同步倉庫」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;勾選後，將會在鏡像倉庫中自動生成 webhook 用於實現自動鏡像。此功能需要你的個人令牌中包含對 admin:repo_hook 的訪問授權，否則會添加失敗。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;點擊「添加」保存鏡像配置。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;配置完成後，可以通過&lt;strong&gt;提交代碼到 Gitee 倉庫&lt;/strong&gt;或&lt;strong&gt;手動更新鏡像&lt;/strong&gt;的方式觸發鏡像操作。&lt;/p&gt; 
&lt;p&gt;一次提交，同步兩個倉庫，更優雅的倉庫鏡像姿勢你 Get 到了嗎？&lt;/p&gt; 
&lt;p&gt;點擊後面的鏈接瞭解更多功能細節：&lt;a href=&quot;https://gitee.com/help/articles/4336&quot;&gt;https://gitee.com/help/articles/4336&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;注意事項&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;鏡像觸發的最短間隔時間為 5 分鐘；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;只支持鏡像已綁定 GitHub 帳號授權訪問的倉庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;更新請求一旦發出，除非強制停止，否則將無法中斷；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;暫時不支持同步&lt;code&gt;Git-LFS&lt;/code&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同步時間超過 30 分鐘視為超時，大型倉庫不建議使用鏡像方式同步；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;鏡像操作會覆蓋目標倉庫的分支、標籤和提交記錄；請注意備份並小心使用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;單向導入同樣支持&lt;/h2&gt; 
&lt;p&gt;同時 Gitee 也支持從 GitHub 單向導入倉庫的操作。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/185026_lLHt_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;點擊右上角&lt;code&gt;+&lt;/code&gt;後選擇&lt;code&gt;從 GitHub/GitLab 導入倉庫&lt;/code&gt;，連接自己的 GitHub 賬號即可實現倉庫的一鍵導入。&lt;/p&gt; 
&lt;p&gt;歡迎使用 Gitee：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344514</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344514</guid>
            <pubDate>Sun, 13 Apr 2025 10:51:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>SSL/TLS 證書最長有效期縮短至 47 天</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;蘋果此前向 CA/B 論壇（負責管理 SSL/TLS 證書的行業組織）提議，將所有證書有效期縮短至 45 天。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;日前 CA/B 論壇服務器證書工作組投票通過 SC-081v3 提案，最終決定將 SSL/TLS 證書有效期從 398 天降至 47 天，SAN 數據重用週期縮短至 10 天。&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3fc44165410fc553ed10737b2c1f73744e1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgroups.google.com%2Fa%2Fgroups.cabforum.org%2Fg%2Fservercert-wg%2Fc%2F9768xgUUfhQ%3Fpli%3D1&quot; target=&quot;_blank&quot;&gt;https://groups.google.com/a/groups.cabforum.org/g/servercert-wg/c/9768xgUUfhQ?pli=1&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;SSL/TLS 證書是一種用於網站的安全協議，通過加密網絡連接確保數據傳輸的安全性。&lt;/p&gt; 
&lt;p&gt;此前，SSL/TLS 證書最長有效期可達 8 年，經過多次調整，目前最長為 398 天，開發者和企業必須在這個時間內更新一次數字證書。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蘋果給出的理由也非常簡單，有效期縮短後，即便證書泄露也很快就會過期而不會被長時間利用。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此次投票中，證書頒發機構（CA）25 票贊成、0 票反對、5 票棄權；證書消費者（包括蘋果、谷歌、微軟、Mozilla 主要瀏覽器開發商）4 票贊成、0 票反對、0 票棄權。&lt;/p&gt; 
&lt;p&gt;提案通過後，將進入知識產權審查階段。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;該措施將從 2026 年 3 月開始逐步實施，到 2029 年 3 月結束，具體時間表如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2026 年 3 月 14 日前：證書有效期最長為 398 天&lt;/li&gt; 
 &lt;li&gt;2027 年 3 月 14 日前：證書有效期最長縮短至 200 天&lt;/li&gt; 
 &lt;li&gt;2028 年 3 月 14 日前：證書有效期最長縮短至 100 天&lt;/li&gt; 
 &lt;li&gt;2028 年 3 月 15 日後：證書有效期最長縮短至 47 天&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管 SSL/TLS 證書已經有很多便捷的工具可以實現自動化續簽，但並非每個網站和企業都可以輕鬆部署自動化續簽流程，尤其是有些複雜的系統切換數字證書本身就是個麻煩的事情。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在 Reddit 論壇上有數百名系統管理員抱怨蘋果的這項提議，因為縮短證書有效期後剩餘的工作都要系統管理員承擔，尤其是如果管理多個網站那麼工作量將會顯著提升 (假如無法實現自動化續簽)。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344509</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344509</guid>
            <pubDate>Sun, 13 Apr 2025 10:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>量子計算機可能幫助解決的三個現實世界問題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;今天是世界量子日，為了紀念這一天，谷歌發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fresearch%2Fgoogle-quantum-computer-real-world-applications%2F&quot; target=&quot;_blank&quot;&gt;介紹&lt;/a&gt;了量子計算機可能幫助解決的三個現實世界問題。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b44eb7465984c4826a24491d5324ee91f30.png&quot; width=&quot;1910&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;世界量子日（World Quantum Day），即 4 月 14 日，是世界各地量子科學家發起的一項倡議，於 2021 年 4 月 14 日啓動，並開始 2022 年 4 月 14 日首次全球慶祝活動的倒計時。&lt;/p&gt; 
 &lt;p&gt;「世界量子日」為什麼選在 4 月 14 日，這是源自普朗克常數。普朗克常數是支配量子物理的基本常數，其大小為為 4.135667696 × 10-15eV·s，其前幾位數字（四捨五入近似）即是「414」。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;藥物研發&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Google 表示，量子計算機預計將帶來的首個益處是藥物研發，從而改善健康結果。藉助這項技術，研究人員將能夠測試不同候選藥物的靶點和其他生物分子，從而幫助研發更有效的藥物。&lt;/p&gt; 
&lt;p&gt;Google 最近與勃林格殷格翰公司聯合發表了一篇研究論文，論文表明量子計算機將能夠更準確地模擬細胞色素 P450，這是一種決定藥物有效性的關鍵酶，因為它在血液中分解藥物。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;改進電池&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Google 希望量子計算機能夠造福人類的另一個途徑是開發改進型電池。這對於清潔能源交通（例如電動汽車和公交車）以及電網至關重要，因為多餘的能量可以儲存起來，以備無風或無陽光時使用。&lt;/p&gt; 
&lt;p&gt;為了改進電池，Google 設想利用量子計算機輔助設計新材料。該公司已與化學公司巴斯夫合作，確定量子計算機將能夠模擬鋰鎳氧化物 (LNO)，從而改善工業生產流程並生產出性能更佳的電池。目前，LNO 的生產難度較大，這阻礙了該領域的研究。LNO 的主要優勢之一是，與更常用的鈷酸鋰相比，其環境足跡更小。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聚變能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Google 表示量子計算機將受益的第三個也是最後一個領域是能源生產。如今，清潔可再生能源指的是太陽能或風能，但未來將意味着核聚變能。核聚變反應堆的技術仍在研發中，但 Google 相信量子計算機將用於設計反應堆，從而釋放核聚變能。&lt;/p&gt; 
&lt;p&gt;Google 表示，目前的計算機模型可能存在誤差，需要運行數十億個 CPU 小時。這家搜索巨頭已與桑迪亞國家實驗室合作，證明在容錯量子計算機上運行的量子算法可以「更有效地模擬持續聚變反應所需的機制」。&lt;/p&gt; 
&lt;p&gt;以科學為中心的人工智能模型的引入已經加速了藥物和材料的發現，因此，當它與量子計算機相結合時，這些發現的速度可能會進一步加快。&lt;/p&gt; 
&lt;p&gt;世界量子日快樂！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/324343/google-willow-quantum-chip&quot; target=&quot;news&quot;&gt;谷歌發佈 Willow 量子計算芯片&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot; target=&quot;news&quot;&gt;微軟發佈首款量子計算芯片「Majorana 1」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/336773/quantum-computing-aws-ocelot-chip&quot; target=&quot;news&quot;&gt;亞馬遜發佈首款量子計算芯片 「Ocelot」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344503/google-quantum-computer-real-world-applications</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344503/google-quantum-computer-real-world-applications</guid>
            <pubDate>Sun, 13 Apr 2025 10:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meilisearch 1.4 穩定版發佈，Rust 高性能開源搜索引擎</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Meilisearch 是 Rust 實現的高性能開源搜索引擎，可作為 Elasticsearch 的替代方案，支持方便地集成到任何網站或應用程序，支持自託管 (self-hosting)，可作為 Algolia 和 Elasticsearch 的輕量替代方案。Meilisearch 內置了許多實用功能，比如：&lt;/p&gt; 
&lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;快速的輸入即搜索 (search-as-you-type) 體驗，也稱作 「即時搜索」&lt;/li&gt; 
 &lt;li&gt;支持冗錯 / 糾錯搜索 (typo tolerance)&lt;/li&gt; 
 &lt;li&gt;支持多面搜索 (faceted search)&lt;/li&gt; 
 &lt;li&gt;支持基於地理位置的搜索 (geosearch)&lt;/li&gt; 
 &lt;li&gt;支持多租戶 (multi-tenancy)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Meilisearch 最新穩定版 1.4 已於今天發佈，此版本引入了兩個重要的實驗性功能：&lt;strong&gt;向量存儲和分數詳情&lt;/strong&gt;，幷包含多項性能改進和錯誤修復。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新功能 (實驗性)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;向量存儲 (Vector Store)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;允許存儲和搜索向量 (Embeddings)。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;embedders&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;prompt&lt;/code&gt;&amp;nbsp;索引設置。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;/indexes/:index_uid/embeddings&lt;/code&gt;&amp;nbsp;API 端點用於添加向量。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;/indexes/:index_uid/settings/embedders&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;/indexes/:index_uid/settings/prompt&lt;/code&gt;&amp;nbsp;API 端點用於配置嵌入器和提示。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;vector&lt;/code&gt;&amp;nbsp;搜索參數用於純向量搜索。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;hybrid&lt;/code&gt;&amp;nbsp;搜索參數用於混合 (關鍵字 + 向量) 搜索。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分數詳情 (Score Details)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;新增&amp;nbsp;&lt;code&gt;showRankingScoreDetails&lt;/code&gt;&amp;nbsp;搜索參數 (設置為&amp;nbsp;&lt;code&gt;true&lt;/code&gt;)。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;在搜索結果的&amp;nbsp;&lt;code&gt;_rankingScoreDetails&lt;/code&gt;&amp;nbsp;字段中返回每個文檔詳細的排名分數計算信息。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;性能改進&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;索引性能&lt;/strong&gt;：通過優化 Roaring Bitmaps 的內存使用，顯著提高了大型文檔的索引速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;內存使用&lt;/strong&gt;：降低了索引過程中的內存消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;搜索性能&lt;/strong&gt;：通過優化 Roaring Bitmaps 的交集計算，提升了包含大量候選結果的搜索查詢性能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;排名分數&lt;/strong&gt;：提高了排名分數計算的精確度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;其他改進&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;/features&lt;/code&gt;&amp;nbsp;端點&lt;/strong&gt;：添加了&amp;nbsp;&lt;code&gt;vectorStore&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;scoreDetails&lt;/code&gt;&amp;nbsp;到&amp;nbsp;&lt;code&gt;/features&lt;/code&gt;&amp;nbsp;API 端點，以表明這些實驗性功能是否啓用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;錯誤信息&lt;/strong&gt;：改進了無效&amp;nbsp;&lt;code&gt;filter&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;sort&lt;/code&gt;&amp;nbsp;語法的錯誤提示信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Bug 修復&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;修復了索引非常大的文檔 (接近 4GB) 時可能發生的崩潰問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復了在大量文檔上使用&amp;nbsp;&lt;code&gt;sort&lt;/code&gt;&amp;nbsp;時可能發生的崩潰問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復了同時使用&amp;nbsp;&lt;code&gt;sort&lt;/code&gt;&amp;nbsp;和&amp;nbsp;&lt;code&gt;distinct&lt;/code&gt;&amp;nbsp;時可能返回不正確結果的問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復了&amp;nbsp;&lt;code&gt;attributesToSearchOn&lt;/code&gt;&amp;nbsp;設置在某些情況下未正確應用的問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復了&amp;nbsp;&lt;code&gt;attributesToRetrieve&lt;/code&gt;&amp;nbsp;與&amp;nbsp;&lt;code&gt;distinct&lt;/code&gt;&amp;nbsp;結合使用時無法正常工作的問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復了在索引過程中發生崩潰後可能導致索引損壞的問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmeilisearch%2Fmeilisearch%2Freleases%2Ftag%2Fv1.14.0&quot; target=&quot;_blank&quot;&gt;https://github.com/meilisearch/meilisearch/releases/tag/v1.14.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344497/meilisearch-1-4</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344497/meilisearch-1-4</guid>
            <pubDate>Sun, 13 Apr 2025 09:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>100% 議題火爆出爐！0425 GOPS 2025 · 深圳站即將啓幕！</title>
            <description>GOPS 2025 · 深圳站即將啓幕</description>
            <link>https://www.bagevent.com/event/8943887?bag_track=KYZG</link>
            <guid isPermaLink="false">https://www.bagevent.com/event/8943887?bag_track=KYZG</guid>
            <pubDate>Sun, 13 Apr 2025 09:19:00 GMT</pubDate>
        </item>
        <item>
            <title>頂級生成式 AI 用例揭曉：營銷任務排名較低</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據最新的研究，生成性人工智能（Gen AI）在市場營銷領域的應用遠不如個人使用那麼普遍。一份由 Marc Zao-Sanders 發佈的《Top-100Gen AI Use Case》報告顯示，儘管人們在日常生活中越來越多地利用 AI 來獲得情感支持，市場營銷的相關任務，如廣告創作和社交媒體內容生成，卻位居使用排名的後列。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告分析了人們對生成性 AI 的使用情況，並指出，過去一年中，使用重點從技術驅動轉向了以情感和個人福祉為中心的應用。根據研究，前三名的應用包括:&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;心理治療和陪伴&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;生活組織&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;尋找生活目標&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;593&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-69816cfbe83380d0ed45a10da818b17fe37.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，這一發現表明，用戶更傾向於利用 AI 來滿足自身的情感需求，而不是單純提高工作效率。在營銷領域，相關應用的排名較低，包括:&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;廣告 / 營銷文案（第 64 位）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;撰寫博客文章（第 97 位）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;社交媒體文案（第 98 位）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;社交媒體系統（第 99 位）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這種差距反映出市場營銷人員尚未充分挖掘生成性 AI 的潛力。Zao-Sanders 在報告中指出，營銷人員可能錯誤判斷了 AI 的使用方向，很多專家原本預期 AI 將首先在技術領域取得成果，然而，研究表明 AI 在滿足人類情感需求方面同樣具有重要作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;用戶對生成性 AI 的使用也在不斷提高，特別是在撰寫有效提示方面。報告中提到的高排名應用可為營銷人員提供借鑑。人們喜愛能夠與他們建立情感聯繫的 AI，營銷工具可以更加註重對話性和同理心。除此之外，AI 在生活組織方面的應用也相當受歡迎，營銷工具可以集中精力在優化工作流程上，而不僅僅是內容創作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在報告中，排名較高的營銷相關用例是 「生成創意」，位列第六，表明頭腦風暴可能是生成性 AI 的一個更佳切入點。營銷人員分享了一些生成性 AI 在實際應用中的成功案例，比如利用 AI 進行行業痛點分析、快速生成案例研究報告等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告建議營銷人員應關注 AI 工具的個人利益，而不僅僅是生產力提升。透明的數據隱私保護措施也非常重要，這有助於增強用戶的信任。Zao-Sanders 總結道，現在正是營銷人員學習和將這些工具融入日常工作中的最佳時機。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344484</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344484</guid>
            <pubDate>Sun, 13 Apr 2025 09:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Krillin AI —— 視頻翻譯和配音工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;Krillin AI 是一款全能型音視頻本地化與增強解決方案。這款簡約而強大的工具，集音視頻翻譯、配音、語音克隆於一身，支持橫豎屏格式輸出，確保在所有主流平台（嗶哩嗶哩，小紅書，抖音，視頻號，快手，YouTube，TikTok 等）都能完美呈現。通過端到端的工作流程，Krillin AI 僅需點擊幾次，就能將原始素材轉化為精美即用的跨平台內容。&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h4&gt;&lt;strong&gt;主要特點與功能：&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;一鍵啓動&lt;/strong&gt;：無需複雜的環境配置，自動安裝依賴，立即投入使用，新增桌面版本，使用更便捷！&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;視頻獲取&lt;/strong&gt;：支持 yt-dlp 下載或本地文件上傳&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;精準識別&lt;/strong&gt;：基於 Whisper 的高準確度語音識別&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;智能分段&lt;/strong&gt;：使用 LLM 進行字幕分段和對齊&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;術語替換&lt;/strong&gt;：一鍵替換專業領域詞彙&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;專業翻譯&lt;/strong&gt;：基於 LLM，段落級翻譯保持語義連貫性&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;配音克隆&lt;/strong&gt;：提供 CosyVoice 精選音色或自定義音色克隆&lt;/li&gt;
&lt;li style=&quot;color: rgb(31, 35, 40); text-align: start;&quot;&gt;&lt;strong&gt;視頻合成&lt;/strong&gt;：自動處理橫豎版視頻和字幕排版&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;語言支持&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li style=&quot;text-align: start;&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;輸入語言：支持中文、英語、日語、德語、土耳其語（更多語言正在添加）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li style=&quot;text-align: start;&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;翻譯語言：支持 56 種語言，包括英語、中文、俄語、西班牙語、法語等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/krillinai</link>
            <guid isPermaLink="false">https://www.oschina.net/p/krillinai</guid>
            <pubDate>Sun, 13 Apr 2025 08:56:00 GMT</pubDate>
        </item>
        <item>
            <title>Rust 1.86.0 穩定版發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Rust 團隊發佈了 Rust 1.86.0 版本，通過&lt;code&gt;rustup update stable&lt;/code&gt;&amp;nbsp;可更新。&lt;/p&gt; 
&lt;p&gt;該版本帶來多項重要更新:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 trait 向上轉型&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;HashMap&lt;/code&gt;&amp;nbsp;和切片可同時獲取多個元素的可變引用&lt;/li&gt; 
 &lt;li&gt;安全函數可使用&amp;nbsp;&lt;code&gt;#[target_feature]&lt;/code&gt;&amp;nbsp;屬性&lt;/li&gt; 
 &lt;li&gt;新增指針非空調試斷言&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;missing_abi&lt;/code&gt;&amp;nbsp;lint 默認警告&lt;/li&gt; 
 &lt;li&gt;1.87.0 版本將棄用&amp;nbsp;&lt;code&gt;i586-pc-windows-msvc&lt;/code&gt;&amp;nbsp;目標平台&lt;/li&gt; 
 &lt;li&gt;一批 API 進入穩定&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;新特性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;trait 向上轉型&lt;/strong&gt;：實現了 trait 對象的向上轉型，若 trait 存在上級 trait，可將該 trait 對象的引用強制轉換為上級 trait 對象的引用，如&amp;nbsp;&lt;code&gt;Arc&amp;lt;dyn Trait&amp;gt; -&amp;gt; Arc&amp;lt;dyn Supertrait&amp;gt;&lt;/code&gt;&amp;nbsp;等。此前需在&amp;nbsp;&lt;code&gt;trait&lt;/code&gt;&amp;nbsp;內定義&amp;nbsp;&lt;code&gt;upcast&lt;/code&gt;&amp;nbsp;方法實現，且僅適用於一種引用 / 指針類型，現在不再需要。使用&amp;nbsp;&lt;code&gt;Any&lt;/code&gt;&amp;nbsp;trait 時，該特性可將 trait 對象向上轉型為&amp;nbsp;&lt;code&gt;dyn Any&lt;/code&gt;，調用&amp;nbsp;&lt;code&gt;Any&lt;/code&gt;&amp;nbsp;的&amp;nbsp;&lt;code&gt;downcast&lt;/code&gt;&amp;nbsp;方法 。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;HashMap&lt;/code&gt;和切片支持多元素可變索引&lt;/strong&gt;：標準庫提供&amp;nbsp;&lt;code&gt;get_disjoint_mut&lt;/code&gt;&amp;nbsp;輔助函數，切片和&amp;nbsp;&lt;code&gt;HashMap&lt;/code&gt;&amp;nbsp;可同時獲取多個元素的可變引用，解決了借用檢查器阻止重複調用&amp;nbsp;&lt;code&gt;get_mut&lt;/code&gt;&amp;nbsp;方法獲取的引用同時使用的問題。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;安全函數使用&amp;nbsp;&lt;code&gt;#[target_feature]&lt;/code&gt;&amp;nbsp;屬性&lt;/strong&gt;：穩定了&amp;nbsp;&lt;code&gt;target_feature_11&lt;/code&gt;&amp;nbsp;特性，允許安全函數使用&amp;nbsp;&lt;code&gt;#[target_feature]&lt;/code&gt;&amp;nbsp;屬性。標記該屬性的安全函數，只能在同樣標記了該屬性的函數中安全調用；在未標記的函數中調用時，需在&amp;nbsp;&lt;code&gt;unsafe&lt;/code&gt;&amp;nbsp;塊內進行，且調用者要確保目標特性可用。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;增強與變更&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;指針非空調試斷言&lt;/strong&gt;：編譯器會在非零大小讀寫和指針重新借用為引用時，插入指針非空的調試斷言。如&amp;nbsp;&lt;code&gt;let _x = *std::ptr::null::&amp;lt;u8&amp;gt;();&lt;/code&gt;&amp;nbsp;在啓用調試斷言時會觸發非展開式 panic。該斷言僅在啓用調試斷言時生效，不能依賴其保證程序正確性。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;missing_abi&lt;/code&gt;&amp;nbsp;lint 默認警告&lt;/strong&gt;：在&amp;nbsp;&lt;code&gt;extern&lt;/code&gt;&amp;nbsp;塊和函數中省略 ABI（如&lt;code&gt;extern {}&lt;/code&gt;和&lt;code&gt;extern fn&lt;/code&gt;）會觸發&amp;nbsp;&lt;code&gt;missing_abi&lt;/code&gt;&amp;nbsp;lint 警告。建議顯式指定&amp;nbsp;&lt;code&gt;&quot;C&quot;&lt;/code&gt;&amp;nbsp;ABI（如&lt;code&gt;extern &quot;C&quot; {}&lt;/code&gt;和&lt;code&gt;extern &quot;C&quot; fn&lt;/code&gt;）。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標平台變更&lt;/strong&gt;：1.87.0 版本將移除&amp;nbsp;&lt;code&gt;tier-2&lt;/code&gt;&amp;nbsp;目標平台&amp;nbsp;&lt;code&gt;i586-pc-windows-msvc&lt;/code&gt;，因其與&amp;nbsp;&lt;code&gt;i686-pc-windows-msvc&lt;/code&gt;的區別在於不要求 SSE2 指令支持，但 Windows 10（除&lt;code&gt;win7&lt;/code&gt;&amp;nbsp;目標外所有&amp;nbsp;&lt;code&gt;windows&lt;/code&gt;&amp;nbsp;目標的最低要求操作系統版本）本身需要 SSE2 指令。使用該目標平台的用戶應在 1.87.0 發佈前遷移至&amp;nbsp;&lt;code&gt;i686-pc-windows-msvc&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;穩定的 API&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;新穩定 API&lt;/strong&gt;：包括&amp;nbsp;&lt;code&gt;{float}::next_down&lt;/code&gt;、&lt;code&gt;{float}::next_up&lt;/code&gt;、&lt;code&gt;[T]::get_disjoint_mut&lt;/code&gt;&amp;nbsp;等多個 API。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;const 上下文穩定的 API&lt;/strong&gt;：如&amp;nbsp;&lt;code&gt;hint::black_box&lt;/code&gt;、&lt;code&gt;io::Cursor::get_mut&lt;/code&gt;&amp;nbsp;等 API 在 const 上下文中穩定。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2025%2F04%2F03%2FRust-1.86.0.html&quot; target=&quot;_blank&quot;&gt;https://blog.rust-lang.org/2025/04/03/Rust-1.86.0.html&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344478/rust-1-86-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344478/rust-1-86-released</guid>
            <pubDate>Sun, 13 Apr 2025 08:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>勒索軟件受害者數量增加 102%，創歷史新高</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;GuidePoint Security 最新&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.guidepointsecurity.com%2Fresources%2Fgrit-2025-q1-ransomware-and-cyber-threat-report%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;的「2025 年第一季度勒索軟件和網絡威脅報告」指出，今年第一季度勒索軟件攻擊數量達到歷史最高水平，受害者人數達 2,063 人，較上年同期增長 102% —— 創下單季度歷史新高。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;報告還記錄了活躍威脅組織的數量，第一季度共發現 70 個，同比增長 55.5%。&lt;/li&gt; 
 &lt;li&gt;2025 年第一季度，Akira 勒索軟件的受害者共有 213 名，活動量同比增長了驚人的 261%。&lt;/li&gt; 
 &lt;li&gt;美國是受災最嚴重的地區，2025 年第一季度觀察到的勒索軟件受害者中有 59% 來自美國，這是迄今為止的最高比例。&lt;/li&gt; 
 &lt;li&gt;2025 年第一季度報告了 12,333 個漏洞，與 2024 年第一季度相比，主動利用的漏洞數量增加了 75%，總體同比增長 41%。&lt;/li&gt; 
 &lt;li&gt;非營利性襲擊事件增加了一倍（+106%），教育領域事件增加了 16%，這表明人們對此前被視為禁區的領域的尊重正在減弱。&lt;/li&gt; 
 &lt;li&gt;2025 年第一季度，製造業、零售業和技術行業受到勒索軟件的影響最為嚴重。值得注意的是，非營利部門的勒索軟件攻擊數量急劇增加，事件數量環比翻了一番。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;253&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-50fbf84dfcd29bf0d0c2362c5dfcaf95915.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GuidePoint 研究與情報團隊 (GRIT) 首席安全顧問 Grayson North 表示：「本季度創紀錄並非巧合。我們追蹤到的活躍勒索軟件和敲詐勒索團體比以往任何時候都多，由 LockBit 和 AlphV 等受疫情影響的犯罪團夥組成的新興勢力發起的大規模攻擊明顯增多。現在亟待解決的問題是，這種激增究竟是短期內短暫的峯值，還是勒索軟件受害者黑暗之年的開始。」&lt;/p&gt; 
&lt;p&gt;「雖然歷史趨勢表明，隨着夏季臨近，我們可能會看到季節性放緩，但威脅形勢依然動盪。一次大規模的攻擊——就像我們在 Clop 看到的那些——就可能再次改變生態系統的軌跡。今年再創紀錄的條件已經具備。現在，要由防禦者來改變這種局面了。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344474/grit-2025-q1-ransomware-and-cyber-threat-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344474/grit-2025-q1-ransomware-and-cyber-threat-report</guid>
            <pubDate>Sun, 13 Apr 2025 08:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Java 開發，對標 Dify、Coze 等的 AI 工作流產品 AIFlowy 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;大家好，AIFlowy 來了。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;AIFlowy 是一個使用 Java 開發的 AI 產品的底座和基石，對標字節 Coze、騰訊元器和 Dify 等產品，但更加註重 toB 端的相關場景，AIFlowy 的定位在 ToB 的場景，未來會以 ToB 為重點，推出一系列的 ToB 能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1078&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8251cedaf1c71e851eeac4c4984c374db40.png&quot; width=&quot;1724&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1078&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3c87da117897b72005b9454ac2e465637bf.png&quot; width=&quot;1724&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;功能列表&lt;/h2&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;AI 功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Bot 應用（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Bot 插件（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Rag 知識庫（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 工作流編排（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;大模型配置（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;大模型市場（已完成）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;系統管理&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;用戶管理（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;角色管理（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;菜單管理（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;部門管理（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;崗位管理（已完成）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;日誌管理（已完成）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;近期計劃&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;完善文檔（進行中...）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;增強穩定性（進行中...）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;優化用戶體驗（進行中...）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速開始&lt;/h2&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;git clone https://gitee.com/aiflowy/aiflowy.git

cd aiflowy
mvn clean package

cd aiflowy-ui-react
npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;環境要求&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JDK 1.8+&lt;/li&gt; 
 &lt;li&gt;Node.js 20.0+&lt;/li&gt; 
 &lt;li&gt;MySQL 8.0+&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;開發及產品文檔&lt;/h2&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://gitee.com/link?target=https%3A%2F%2Faiflowy.tech&quot; target=&quot;_blank&quot;&gt;https://aiflowy.tech&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;(官網正在備案中... 暫未上線)&lt;/p&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;開源地址：&lt;/strong&gt;&lt;a href=&quot;https://gitee.com/aiflowy/aiflowy&quot;&gt;https://gitee.com/aiflowy/aiflowy&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344472/aiflowy-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344472/aiflowy-released</guid>
            <pubDate>Sun, 13 Apr 2025 08:32:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>DeepSeek 即將聯合 vLLM 開源推理引擎 (DeepSeek Inference Engine)</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;DeepSeek 在其 GitHub 倉庫&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2Fopen-infra-index%2Fblob%2Fmain%2FOpenSourcing_DeepSeek_Inference_Engine%2FREADME.md&quot; target=&quot;_blank&quot;&gt;發佈預告稱&lt;/a&gt;&lt;/u&gt;，即將開源推理引擎&amp;nbsp;&lt;strong&gt;DeepSeek Inference Engine&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;考慮到代碼分支和維護資源等問題，他們選擇了直接和 vLLM 等現有開源項目合作的方式進行開源。&lt;/p&gt; 
&lt;p&gt;下面是官方公告：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;幾周前，在開源週期間，我們開源了幾個庫。社區的反應非常積極——激發了許多鼓舞人心的合作、富有成效的討論和寶貴的錯誤修復。&lt;/p&gt; 
 &lt;p&gt;受到這一鼓舞，我們決定再邁出一大步：&lt;strong&gt;將我們的內部推理引擎貢獻給開源社區&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我們對開源生態系統深表感激，沒有它，我們向通用人工智能（AGI）的進步將不可能實現。我們的訓練框架依賴於 PyTorch，我們的推理引擎建立在 vLLM 之上，這兩者都在加速深度探索模型的訓練和部署方面發揮了至關重要的作用。&lt;/p&gt; 
 &lt;p&gt;隨着對部署 DeepSeek-V3 和 DeepSeek-R1 等模型的需求不斷增長，我們希望儘可能地為社區做出貢獻。雖然我們最初考慮開源我們的完整內部推理引擎，但我們發現了一些挑戰：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;代碼庫改動大&lt;/strong&gt;：我們的引擎基於一年多前的 vLLM 早期分支。儘管結構相似，但我們已經為 DeepSeek 模型進行了大量定製，這使得它難以擴展到更廣泛的應用場景。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;基礎設施依賴&lt;/strong&gt;：該引擎與我們的內部基礎設施緊密耦合，包括集羣管理工具，這使得在沒有重大修改的情況下進行公開部署變得不切實際。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;維護資源有限&lt;/strong&gt;：作為一個專注於開發更好模型的中小研究團隊，我們缺乏維護大型開源項目的資源。&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;鑑於這些挑戰，我們決定與現有的開源項目合作，作為更可持續的替代方案。&lt;/p&gt; 
 &lt;p&gt;未來，我們將與現有的開源項目緊密合作，以：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;提取獨立功能&lt;/strong&gt;：模塊化並貢獻可重用的組件作為獨立庫。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;分享優化&lt;/strong&gt;：直接貢獻設計改進和實現細節。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/155748_QMBN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;詳情查看：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2Fopen-infra-index%2Fblob%2Fmain%2FOpenSourcing_DeepSeek_Inference_Engine%2FREADME.md&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/open-infra-index/blob/main/OpenSourcing_DeepSeek_Inference_Engine/README.md&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344466</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344466</guid>
            <pubDate>Sun, 13 Apr 2025 08:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌開源 AI 智能體開發套件 (Agent SDK)，支持 MCP、A2A</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fagent-development-kit-easy-to-build-multi-agent-applications%2F&quot; target=&quot;_blank&quot;&gt;開源&lt;/a&gt;&lt;/u&gt;了首個 Agent 開發套件—ADK，這也是 OpenAI 之後第二家大廠發佈的標準化智能體 SDK。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1638&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0414/153749_4yVz_2720166.png&quot; width=&quot;2016&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ADK 能幫助開發人員極大簡化開發超複雜流程的智能體，從大模型選擇、自動化流程編排、測試到應用部署可一站式完成，並且支持雙向音頻、視頻、MCP 和最新的 A2A 協議。&lt;/p&gt; 
&lt;p&gt;例如，通過 ADK 開發一個跨平台的語音客服智能體，大概只需要 100 多行甚至更少的代碼就能全部完成。再也不用像以前那樣，切換不同平台 API，模型選擇或交互邏輯編寫複雜代碼，極大提升了開發效率。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;開源地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fadk-python&quot; target=&quot;_blank&quot;&gt;https://github.com/google/adk-python&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;ADK 介紹&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;ADK 架構以 Python 為主，在參數定義、模型集成、工具整合和指令驅動方面非常好用。&lt;/p&gt; 
&lt;p&gt;例如，&lt;strong&gt;下面這個案例只用了&lt;strong&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/strong&gt;行代碼，就完成了一個簡單的問答智能體開發&lt;/strong&gt;。咱們只設置了使用的模型、智能體名稱、功能描述、指令驅動和工具實例。其他的管理狀態、協調工具調用以及和底層大模型的交互全部由 ADK 完成。&lt;/p&gt; 
&lt;p&gt;簡單來説，用 ADK 開發就有點像拼樂高積木一樣，喜歡哪塊就拼哪個完全釋放你的天馬行空想法，再也不用為工具和底層技術發愁了。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from google.adk.agents import Agent
from google.adk.tools import google_search

root_agent = Agent(
    name=&quot;search_assistant&quot;,
    model=&quot;gemini-2.0-flash&quot;, # Or your preferred Gemini model
    instruction=&quot;You are a helpful assistant. Answer user questions using Google Search when needed.&quot;,
    description=&quot;An assistant that can search the web.&quot;,
    tools=[google_search]
)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;雖然 ADK 是谷歌開源的，但在大模型兼容方面還是非常靈活的，除了谷歌的 Gemini 系列模型之外，還支持 Anthropic、Meta、Mistral AI、AI21 Labs、CAMB.AI、Qodo 等 200 多個第三方開閉源模型。&lt;/p&gt; 
&lt;p&gt;ADK 的亮點之一便是輕鬆開發複雜智能體，支持多層級結構組合的智能體實現複雜的協調和委派。開發者可以構建一個主智能體來處理主要任務，並將特定子任務委派給其他專業智能體。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/153833_OCY4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;簡單來説，就是讓主智能體指揮其他智能體來執行具體的任務。例如，你是一家電商公司需要開發客服智能體。希望能自動處理訂單查詢、商品推薦、售後服務等多種服務。&lt;/p&gt; 
&lt;p&gt;傳統的方法會非常繁瑣，你需要為不同的業務編寫不同的邏輯代碼並，且優化、重構也很麻煩。&lt;strong&gt;通過&lt;strong&gt;&lt;strong&gt;ADK&lt;/strong&gt;&lt;/strong&gt;你可以直接定義&lt;strong&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/strong&gt;個智能體&lt;/strong&gt;，主體負責接收用戶問題，並根據問題類型委派給相應的子智能體；訂單查詢智能體，專門處理與訂單相關的問題，如訂單狀態、物流信息等。&lt;/p&gt; 
&lt;p&gt;商品推薦智能體，根據用戶的歷史購買記錄和瀏覽行為，推薦相關商品；售後服務智能體，處理退換貨、退款等售後服務問題。&lt;/p&gt; 
&lt;p&gt;上面這些只是為大家簡單講解，其實實際用 ADK 開發更簡單高效，因為它還集成了搜索、地圖、代碼執行、服務等很多實用工具，也支持 LangChain、CrewAI、MCP 等第三方服務。&lt;/p&gt; 
&lt;p&gt;更詳細的示例開源地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fadk-samples&quot; target=&quot;_blank&quot;&gt;https://github.com/google/adk-samples&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;谷歌 ADK 詳細文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgoogle.github.io%2Fadk-docs%2Fget-started%2Ftutorial%2F%23step-1-your-first-agent-basic-weather-lookup&quot; target=&quot;_blank&quot;&gt;https://google.github.io/adk-docs/get-started/tutorial/#step-1-your-first-agent-basic-weather-lookup&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/343677/a2a-a-new-era-of-agent-interoperability&quot; target=&quot;_blank&quot;&gt;谷歌推出 A2A 開放協議，實現智能體間的自由 「對話」&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344460/google-agent-development-kit</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344460/google-agent-development-kit</guid>
            <pubDate>Sun, 13 Apr 2025 07:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>廣州出現 AI 洗頭，最低 10 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;廣州天河區體育西路出現了一家 AI 洗頭店，工作人員只需要簡單協助，顧客便可享受全自動機器洗頭服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，顧客躺上按摩牀後，可選擇速洗、普通、加時、淋水或養護模式，力度有低、中、高三檔，還能根據髮長選擇長髮或短髮模式。機器通過紅外感應定位頭部，配合多角度出水口，約 13 分鐘即可完成洗護全流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;374&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1d88c1085b5f967123b43baf557d3569ce4.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開始洗頭前，店員會先用儀器檢測顧客的頭皮健康情況，「我們會根據顧客的髮質情況，在洗頭時選用乾性或油性模式，所對應的洗髮水也不同。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨後機器啓動，每次服務前都會進行消毒，工作人員為顧客準備一次性毛巾、耳塞，並調節水溫水壓。根據顧客頭皮狀況選擇乾性或油性，並選擇洗頭模式後，系統便自動運作。可選模式包括速洗、普通、加時、淋水及養護，力度分為低、中、高三檔，並可根據髮長選擇長髮、短髮模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;洗頭過程中，機器通過多個出水口和紅外線燈，在運作的過程中不斷調節方位，以達到全方位衝灑、清潔頭皮，全程包含兩次洗髮、一次護髮，一共七次沖洗。該設備還配備按摩牀功能，結合頭髮清潔與按摩體驗，在普通模式下整個洗頭流程約 13 分鐘。洗後，店內設有負離子自動吹風機，顧客也可選擇手持吹風機。至於價格，記者瞭解到，AI 洗頭價格剛推出時，優惠價為 9.9 元，目前在平台購買價格則約為 19 元一次。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該店內共有 5 部洗頭機器，配有 3 名店員。據店員介紹，該門店自去年 12 月起營業，高峯時期每日接待洗頭人數超百人，目前平均每天接待 30 至 40 人。「AI 洗頭最大解決了人手不足的問題，只需要 3 個店員，店內所有機器同時操作也沒有問題。」記者在某點評網站搜索「AI 洗頭」，發現目前在天河區、海珠區、白雲區、黃埔區、花都區等都有相關業務的店鋪。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於這種新穎的洗頭方式，不少街坊都抱着好奇心前來體驗。街坊李小姐表示，雖然第一次用機器洗頭略感不適應，但整體清洗效果乾淨、過程新奇，值得嘗試。對此，有網友表示，AI 洗頭的確是新奇體驗，水溫調控智能，但「對症下癢」的能力有限，技術炫酷，適合頭髮的日常維護。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344456</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344456</guid>
            <pubDate>Sun, 13 Apr 2025 07:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>圖解「模型上下文協議（MCP）」：從與傳統 API 的比較入手</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; AI 應用如何像智能終端連接配件一樣，無縫集成多樣化的工具和數據源？答案或許就藏在近期熱議的「模型上下文協議（MCP）」中。&lt;/p&gt; 
 &lt;p&gt;我們今天帶來的這篇文章，作者的核心觀點是：MCP 通過標準化通信協議，讓 AI 應用與外部工具、數據的交互如同 USB-C 接口一般高效且靈活，徹底改變傳統 API 架構的僵化限制。&lt;/p&gt; 
 &lt;p&gt;文章詳細介紹了 MCP 的核心架構，包括 Host（提供 AI 交互環境的應用程序）、Client（實現與 MCP Servers 通信）和 Server（提供特定能力和數據訪問）三大組件。重點解釋了 MCP 的 Capability Exchange（能力交換）機制如何使系統更加動態靈活，允許服務器隨時更新其功能而無需客戶端重寫代碼。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Avi Chawla&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;最近，關於模型上下文協議（MCP）的討論非常熱烈。你一定聽説過它。&lt;/p&gt; 
&lt;p&gt;今天，讓我們一起來瞭解一下模型上下文協議（MCP）。&lt;/p&gt; 
&lt;p&gt;直觀地説，&lt;strong&gt;MCP 就像 AI 應用的 USB-C 接口。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正如 USB-C 為設備連接各種配件提供了標準化方案，MCP 也將 AI 應用連接到不同數據源和工具的方式標準化了。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f1dacc1d1bd01432a385231cb0e7b99d096.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;接下來從技術角度進行深入探討。&lt;/p&gt; 
&lt;p&gt;MCP 的核心遵循客戶端-服務器（client-server）架構，Host 應用程序可以連接到多個 Server。&lt;/p&gt; 
&lt;p&gt;它包含三個主要組件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Host&lt;/li&gt; 
 &lt;li&gt;Client&lt;/li&gt; 
 &lt;li&gt;Server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在我們進行深入探討之前，先來瞭解一下整體架構👇&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1dba78f10c6dc947f9af92ad90d795aa319.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Host&lt;/strong&gt; 代表任何提供 AI 交互環境、訪問外部工具和數據源並運行 MCP Client 的 AI 應用（如 Claude 桌面版、Cursor）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MCP Client&lt;/strong&gt; 在 Host 內運行，實現與 MCP Servers 的通信。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7296f5e1991309f3c2d85a6ba89900b2982.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MCP Server&lt;/strong&gt; 對外開放特定能力，並提供對數據源的訪問權限，包括：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bcd2b143d2cdc131493f62cb33af3d96f0b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;：使大語言模型能夠通過你的 Server 執行操作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resources&lt;/strong&gt;：將 Server 上的數據和內容開放給大語言模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompts&lt;/strong&gt;：創建可複用的提示詞模板和工作流程。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要構建屬於你自己的 MCP 系統，理解客戶端-服務器通信機制是必不可少的。&lt;/p&gt; 
&lt;p&gt;現在我們來解析客戶端與服務器的通信流程。&lt;/p&gt; 
&lt;p&gt;本文將對該過程進行逐步拆解，請看下方這張示意圖...&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-65e26893f801f2a4c07df4643ec7da221d5.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;首先進行 Capability Exchange（譯者注：Capability Exchange（能力交換）是一種動態服務發現與適配機制，是 MCP 連接建立的必經步驟，類似於&quot;握手協議&quot;。），流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;客戶端發送初始請求，獲取服務器能力信息&lt;/li&gt; 
 &lt;li&gt;服務器返回其能力信息詳情&lt;/li&gt; 
 &lt;li&gt;例如當天氣 API 服務器被調用時，它可以返回可用的&quot;tools&quot;、&quot;prompts templates&quot;及其他資源供客戶端使用&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;交換完成後，客戶端確認連接成功，然後繼續交換消息。&lt;/p&gt; 
&lt;p&gt;這種機制非常強大，原因如下：&lt;/p&gt; 
&lt;p&gt;在傳統的 API 架構中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果你的 API 最初需要兩個參數（例如，天氣服務的 location 參數（譯者注：地理位置）和 date 參數（譯者注：日期）），用戶需嚴格按此參數結構構建應用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-12bbe7a8af360add8d12d9000bf4ada58ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;之後，如果你決定為該 API 添加第三個必選參數（例如，unit 參數（譯者注：溫度單位）），將 API &quot;契約&quot;進行變更。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b0f2ec8cc0d906d5fca45b05bc10cddeab6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;這意味着該 API 的所有用戶都必須更新代碼，增加對新參數的支持，如果未及時更新，他們的請求可能會失敗、報錯或提供不完整的結果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-85adaca34cbe36e86c50d7d54dc1fe1e9a3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;MCP 的設計解決了這個問題，具體方法如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MCP 引入了一種動態、靈活的方法，與傳統 API 形成鮮明對比。&lt;/li&gt; 
 &lt;li&gt;當 Client（例如 Claude Desktop 這類 AI 應用）連接 MCP Server（例如天氣服務）時，會發送初始請求，以便了解 Server 的能力。&lt;/li&gt; 
 &lt;li&gt;Server 的響應包含可用的 tools、resources、prompts 以及相關參數的詳細信息。例如，若天氣 API 最初僅支持 location 和 date 參數，服務器會通過能力交換告知這些信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;當新增 unit 參數時，MCP Server 可在下次進行能力交換時動態更新能力描述。Client 無需硬編碼或預定義參數，只需查詢 Server 的最新能力並自動適配。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;這樣，Client 就能使用更新後的新功能（例如在其請求中包含 unit 參數），實時調整行為，而無需重寫或重新部署代碼。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;希望本文能闡明 MCP 的作用。&lt;/p&gt; 
&lt;p&gt;後續我們將探索如何創建自定義的 MCP servers 並圍繞它們構建實踐演示，敬請期待！&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;你認為標準化的 MCP 會加速 AI 創新還是限制創新？為什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.dailydoseofds.com%2Fp%2Fvisual-guide-to-model-context-protocol&quot; target=&quot;_blank&quot;&gt;https://blog.dailydoseofds.com/p/visual-guide-to-model-context-protocol&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/18005889</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18005889</guid>
            <pubDate>Sun, 13 Apr 2025 07:18:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>法庭驚現 AI 虛擬發言人，74 歲創業者引發法官憤怒</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，在紐約州&lt;span&gt;最高&lt;/span&gt;法院，一位 74 歲的創業者傑羅姆・德瓦爾（Jerome Dewald）因其在法庭上播放的 AI 生成視頻而引發了法官的強烈不滿。德瓦爾因與保險公司大都會人壽 (MassMutual Metro) 之間的勞動爭議而出庭，他希望通過一個虛擬的 AI 頭像來代表自己發言。然而，這一嘗試卻沒有得到法官的認可，反而激怒了法官。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;在法庭上，德瓦爾播放了一段由 AI 生成的男性頭像視頻。視頻中的虛擬發言人衣着整齊，看起來比德瓦爾年輕三十歲，開口便説：「尊敬的法庭，我今天以謙卑的身份來到這裏。」 但此時，法官薩莉・曼扎內特 - 丹尼爾斯（Sallie Manzanet-Daniels）顯然感到困惑，立刻詢問:「這是什麼?這是案件的律師嗎?」 德瓦爾在旁解釋道：「這是我生成的。」 得知是虛擬形象後，法官憤怒地回應道：「您沒有提前告知我這一點，先生。」&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;257&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b517932aef760be58401fabbbfa60ef6c23.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;德瓦爾隨後被法官嚴厲批評，原因是他曾聲稱因為 25 年前的喉癌導致他無法直接在法庭上發言，然而法官指出，他已經和法庭工作人員進行了超過 30 分鐘的口頭交流，這與他所述的情況相矛盾。法官憤慨地表示：「我不喜歡被誤導，您不能利用法庭來推廣您的商業計劃。」&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;德瓦爾經營的初創公司名為 Pro Se Pro，旨在幫助普通人通過創建逼真的視頻頭像來代表自己進行訴訟。德瓦爾在採訪中表示，他認為法庭對這種技術的反應出乎意料。他原計劃使用名為 Tavus 的服務製作一個自己的 AI 頭像，但由於時間不夠，只能選擇一個現成的 AI 模型。「這位大帥哥，大家叫他吉姆（Jim）。」 德瓦爾幽默地説道。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;儘管德瓦爾認為使用 AI 的方式可能會影響案件的結果，特別是在公眾對 AI 產生的 「幻覺」 持有負面看法的情況下，他依然希望能在法庭上找到一種新的表達方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344449</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344449</guid>
            <pubDate>Sun, 13 Apr 2025 07:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節跳動最新思考模型 Seed-Thinking-v1.5 技術報告發布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字節跳動 Seed 最新思考模型 Seed-Thinking-v1.5 技術報告發布，涵蓋在數據體系、獎勵模型、RL 算法、基礎設施等維度的探索：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通過數據層面的精細化處理提升推理能力，融合可驗證數據和非可驗證數據，並提出全新的評測基準集合；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構建雙軌獎勵體系，通過可驗證問題的智能邏輯驗證，融合非可驗證問題的兩兩對比優化，實現數學推理與創意生成等全場景任務的精準訓練；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過 SFT 階段的精準數據構造，和 RL 階段的關鍵算法創新，提高大語言模型的推理上限；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化了 HybridFlow 編程模型和流式推理系統，並支持張量/專家/序列三層並行架構。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/151241_fPgV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Seed-Thinking-v1.5 是字節跳動 Seed 團隊即將推出的智能推理模型。該模型在數學、編程、科學推理等專業領域及創意寫作等通用任務中表現突出，同時，模型採用 MoE 架構，總參數 200B，激活參數為 20B，具備顯著的推理成本優勢。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0414/151039_m8wm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前 Seed-Thinking-v1.5 技術報告已公開，4 月 17 日將通過火山引擎開放接口供用戶體驗。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;技術報告鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FByteDance-Seed%2FSeed-Thinking-v1.5&quot; target=&quot;_blank&quot;&gt;https://github.com/ByteDance-Seed/Seed-Thinking-v1.5&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344448/seed-thinking-v1-5-technical-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344448/seed-thinking-v1-5-technical-report</guid>
            <pubDate>Sun, 13 Apr 2025 07:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>