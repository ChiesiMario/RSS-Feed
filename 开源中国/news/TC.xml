<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 06 May 2024 11:15:30 GMT</lastBuildDate>
        <ttl>1</ttl>
        <item>
            <title>開源日報 | 谷歌扶持鴻蒙上位；開源 Rabbit R1；Docker 加持的安卓手機；微軟的焦慮和野心；海爾電器把開放平台關了</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.5.6&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要點&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/291040&quot; target=&quot;news&quot;&gt;面壁智能發佈 Eurux-8x22B 開源大模型 —— 堪稱「理科狀元」&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;面壁智能近日發佈開源大模型 Eurux-8x22B，包括 Eurux-8x22B-NCA 與 Eurux-8x22B-KTO，主打推理能力。官方介紹道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;相比口碑之作 Llama3-70B，Eurux-8x22B 發佈時間更早，綜合性能相當，尤其是擁有更強的推理性能 ——&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;刷新開源大模型推理性能 SOTA，堪稱開源大模型中「理科狀元」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Eurux-8x22B 在 LeetCode（180 道 LeetCode 編程真題）與 TheoremQA 測試上超越了 Llama3-70B，在 LeetCode 測試上超越閉源的 GPT-3.5-Turbo。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e821808c7c8fd5dd504c26678ed49faa489.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290493/arc-for-windows-1-0-ga&quot; target=&quot;news&quot;&gt;Arc Browser for Windows 1.0 正式 GA&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Arc 瀏覽器正式面向所有 Windows 11 用戶開放（&lt;/span&gt;&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;只支持 Windows 11，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;對 Windows 10 的支持還在開發中）。該瀏覽器開發商 The Browser Company 於去年 12 月開始測試 Windows 客戶端，目前已有超過 15 萬人在使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Arc 瀏覽器最大的不同就是引入了 「Space」 概念（類似於 「Groups」），用戶可以創建不同的 「Space」 來滿足不同場景的瀏覽需求，每個 Space 下的網址集合可以一次性分享給他人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3f56be7250030dbc6c2082e925059c7fa5f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qbitai.com%2F2024%2F05%2F139706.html&quot; target=&quot;_blank&quot;&gt;58 行代碼把 Llama 3 擴展到 100 萬上下文，任何微調版都適用&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;堂堂開源之王 Llama 3，原版上下文窗口居然只有……8k，讓到嘴邊的一句「真香」又咽回去了。&lt;/p&gt; 
&lt;p&gt;在 32k 起步，100k 尋常的今天，這是故意要給開源社區留做貢獻的空間嗎？&lt;/p&gt; 
&lt;p&gt;開源社區當然不會放過這個機會：現在只需 58 行代碼，任何 Llama 3 70b 的微調版本都能自動擴展到 1048k（一百萬）上下文。&lt;/p&gt; 
&lt;p&gt;代碼地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fehartford%2F731e3f7079db234fa1b79a01e09859ac&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/ehartford/731e3f7079db234fa1b79a01e09859ac&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1675423275%2FOcJuSxVUc%3F&quot; target=&quot;_blank&quot;&gt;海爾電器把開放平台關了&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;海爾電器把開放平台關了。然後還讓第三方智能家居的插件作者把 Github 倉庫刪掉，作者刪了之後不滿意。又做了個 fuck haier 的倉庫。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-47774220dbbc1b219215cbf4178d21b69ca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;Sunbelife&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1220149481%2FOcGeDe1l0&quot; target=&quot;_blank&quot;&gt;Docker 加持的安卓手機&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;聊聊如何藉助 Docker ，嘗試將一台五年前的手機，構建成一個隨身攜帶的、本地化的知識庫。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;soulteary&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1727858283%2FOd0nH3bFi&quot; target=&quot;_blank&quot;&gt;開源 Rabbit R1&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;利用 Apple Shortcuts、Cloudflare Workers 和 llama 3 製作的一個人工智能助手。&lt;/p&gt; 
   &lt;p&gt;Shortcuts 提供自動語音識別（ASR）、文本到語音轉換（TTS）和 HTTP 請求功能，這些基本上涵蓋了我們本地需要的所有功能。你還可以將一個快捷操作綁定到 iPhone 的動作按鈕，這樣即使在鎖屏狀態下也能快速訪問。&lt;/p&gt; 
   &lt;p&gt;接下來，作者簡單編寫了一個 Cloudflare Worker，它從快捷操作接收文本，發送到 llama 3 進行處理，然後將函數調用結果返回。&lt;/p&gt; 
   &lt;p&gt;雖然這只是一個基礎示例，但其實還可以擴展，包括更復雜的函數調用和數據存儲等。&lt;/p&gt; 
   &lt;p&gt;它的響應速度超過所有的 AI 穿戴設備，並且不需要額外的硬件或者支付月費。&lt;/p&gt; 
   &lt;p&gt;項目地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSh4yy%2Fpersonal-ai&quot; target=&quot;_blank&quot;&gt;https://github.com/Sh4yy/personal-ai&lt;/a&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;寶玉 xp&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5648162302%2FOcRHqDnxS&quot; target=&quot;_blank&quot;&gt;基於 Llama3 和 Groq 構建的 AI 新聞應用&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;此 AI 應用程序使用 Streamlit（一個開源 Python 框架，數據科學家和 AI/ML 工程師只需幾行代碼即可提供動態數據應用程）構建，步驟如下：&lt;/p&gt; 
   &lt;p&gt;1. 選擇一個主題在網上搜索文章&amp;nbsp;&lt;br&gt; 2. 閲讀並使用 llama3:8b 總結每篇文章&amp;nbsp;&lt;br&gt; 3. 使用 llama3:70b 撰寫新聞文章&amp;nbsp;&lt;/p&gt; 
   &lt;p&gt;開源代碼： git.new/groq-news&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;黃建同學&lt;/strong&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTLERI_JpqZuXlSiaSctfEg&quot; target=&quot;_blank&quot;&gt;老碼農潛伏谷歌十七年總結出成功祕籍，前兩條竟是...？&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;我發現我在我歌學到的技能大部分在新工作中一樣好使。其中特別有用的有兩條：&lt;/p&gt; 
   &lt;p&gt;要是有件事大多數人都説做不成，不要聽大多數人的，該出手時就出手哇，風風火火闖九州哇。&lt;/p&gt; 
   &lt;p&gt;凡事從第一性原理出發，從本質上解決問題。&lt;/p&gt; 
   &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;老萬故事會&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5712139634%2FOcR3EqG0j&quot; target=&quot;_blank&quot;&gt;谷歌這是要扶持鴻蒙上位了？&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;美國最近宣佈限制中國使用 RISC-V 架構，緊接着以「不作惡」著稱的谷歌便決定移除 Android 操作系統對 RISC-V 的支持，封閉了這一潛在的漏洞。RISC-V 架構被廣泛認為是中國最有價值的開源指令集內核，眾多芯片製造商已經開發出多種基於 RISC-V 的芯片產品，覆蓋從家用電器控制到筆記本電腦等多個領域。隨着 Android 系統不再支持 RISC-V，這可能會對 RISC-V 的發展造成阻礙。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;遊資論股&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.com.cn%2Farticle_2853016445_aa0d937d02000yu8a.html&quot; target=&quot;_blank&quot;&gt;智譜 AI 正研發對標 Sora 的國產文生視頻模型，最快年內發佈&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;鈦媒體 App 獨家獲悉，估值超 200 億的國內 AI 大模型獨角獸公司「智譜 AI」正在研發對標 OpenAI Sora 的高質量文生視頻模型，預計最快年內發佈。&lt;/p&gt; 
 &lt;p&gt;「文生視頻目前處於一個快速發展的階段，預計今年將是文生視頻大模型的爆發期。國內公司在文生視頻技術方面的客戶需求非常多樣，從電影拍攝到短視頻、遊戲製作等。智譜也將通過使用更高質量的數據和更大的參數，開發高質量的文生視頻產品。」一位智譜 AI 內部人士對鈦媒體 App 表示。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;鈦媒體&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2763971405184008&quot; target=&quot;_blank&quot;&gt;慘，Rabbit R1 被持續扒皮：AI 風口一夜轉型，NFT 充值用戶欲哭無淚，動作大模型也是套殼的&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;一波未平一波又起，不光 APP 被批評套殼安卓，主推的大動作模型 LAM 依賴 OpenAI 接口，現在公司也被扒皮有貓膩——&lt;/p&gt; 
 &lt;p&gt;Rabbit 公司本來是搞元宇宙的，原地改名轉投 AI？！&lt;/p&gt; 
 &lt;p&gt;這家曾經主打 NFT 遊戲的創業公司，去年轉型做 AI 終端（即 R1）。並在轉型後疑似「刪號跑路」，留下一堆曾為其付費的用戶不管。&lt;/p&gt; 
 &lt;p&gt;要知道，Rabbit 前身推出的 GAMA，是一款需要預先付費購買 NFT 的遊戲，其中有的 NFT 售價高達 2000+美元（摺合人民幣超 2 萬）。&lt;/p&gt; 
 &lt;p&gt;再聯想到 Rabbit 同樣也需要預先支付費用，於是網友發出靈魂拷問：要是 CEO 又跑了，Rabbit R1 還會有什麼價值呢？&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;strong&gt;- 量子位&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinastarmarket.cn%2Fdetail%2F1668315&quot; target=&quot;_blank&quot;&gt;上海人工智能產業正進入集中爆發期 24 款大模型通過國家備案&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;上海市經濟和信息化委員會主任張英參加 2024 上海民生訪談欄目時表示，人工智能是上海堅定不移發展的三大先導產業之一，也是培育新質生產力的重中之重。當前人工智能正進入集中爆發期。去年 11 月，上海發佈了推動大模型創新發展「11 條舉措」，從算力、語料、模型、測試等方面，作了全面佈局。目前，上海人工智能實驗室「書生」、商湯「商量」等 24 款大模型通過國家備案，居全國第二，形成了「1+4」的通用大模型格局（1 款開源、2 款商用、2 款在研），體現了在行業內的深化應用。今年通用大模型正在逐步收斂，一大批聚焦製造、金融、政務等垂類模型正加快孕育。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;-&amp;nbsp;&lt;strong&gt;科創板日報&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb&quot; target=&quot;_blank&quot;&gt;GreptimeTeam/greptimedb&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bbbadbafcdc0c3567bc2a534ff918ebdf4b.png&quot; width=&quot;319&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb&quot; target=&quot;_blank&quot;&gt;https://github.com/GreptimeTeam/greptimedb&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GreptimeDB 是 Rust 實現的開源時序數據庫，尤其關注可擴展性、分析能力和效率，專為雲時代的基礎設施而設計。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/HuggingFace/blog/11090508&quot; target=&quot;_blank&quot;&gt;視覺語言模型詳解&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;視覺語言模型可以同時從圖像和文本中學習，因此可用於視覺問答、圖像描述等多種任務。本文，我們將帶大家一覽視覺語言模型領域：作個概述、瞭解其工作原理、搞清楚如何找到真命天 「模」、如何對其進行推理以及如何使用最新版的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;trl&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;輕鬆對其進行微調。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;VLM 能力&quot; height=&quot;281&quot; src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/jK8WsS.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;div&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;事件點評&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel&quot; target=&quot;_blank&quot;&gt;谷歌刪除 Android 通用內核 (ACK) 對 RISC-V 架構的支持&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;谷歌 Android 系統上游 ——AOSP 最近&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fq%2Ftopic%3A%2522ack_riscv64_turndown%2522&quot; target=&quot;_blank&quot;&gt;合併&lt;/a&gt;的一系列補丁刪除了 Android 通用內核對 RISC-V 架構的支持。Android 通用內核也就是 Common Android Kernel，也被稱為 AOSP 通用內核或 ACK。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;由於 ACK 刪除了對 RISC-V 的支持，想要立即編譯 Android RISC-V 版本的公司和機構，&lt;/span&gt;&lt;strong&gt;需要創建和維護自己的 Linux 分支&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，以便於進一步整合 RISC-V 補丁。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b5bb533fc41afeb38d23d6547429497e63.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;RISC-V 作為一種開放標準，儘管得到了國際支持和合作，但在智能手機應用方面尚未實現。谷歌的這一決策可能會對 RISC-V 架構在智能手機領域的應用產生影響。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;且&amp;nbsp;許多芯片製造商和處理器設計師已經在 RISC-V 架構的未來發展上進行了投資。例如，高通正在開發用於 Wear OS 的 RISC-V 芯片。谷歌的這一決策可能會對這些芯片製造商產生影響。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，RISC-V 架構被視為對 ARM 架構的一種競爭。谷歌的這一決策也可能會影響 RISC-V 在 SSD 控制器市場中的競爭力。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai&quot; target=&quot;_blank&quot;&gt;微軟投資 OpenAI 可能是出於對谷歌 AI 進展的擔憂&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;微軟首席技術官凱文 - 斯科特（Kevin Scott）、首席執行官薩蒂亞 - 納德拉（Satya Nadella）和聯合創始人比爾 - 蓋茨（Bill Gates）之間的一封題為 「Thoughts on OpenAI」 的內部&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTechEmails%2Fstatus%2F1787176471146156193%2Fphoto%2F4&quot; target=&quot;_blank&quot;&gt;郵件&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;，揭示了在微軟披露合作關係之前的幾個月裏，圍繞投資機會進行的一些高層討論。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;Scott 在 2019 年 6 月 12 日寫給 Nadella 和 Gates 的電子郵件中寫道：「在機器學習規模方面，我們落後競爭對手多年」。並詳細描述了微軟工程師是如何花了六個月的時間來複制谷歌的 BERT 語言模型並對其進行訓練的，「因為我們的基礎設施無法勝任這項任務」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a617e0611f25b43710fd269327334c67b3e.png&quot; width=&quot;237&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟對 OpenAI 的投資反映了其對自身在人工智能領域相對落後的認識，以及對技術領先的追求。這一投資決策可能與微軟對谷歌在人工智能技術上的領先感到的焦慮有關，突顯了市場主導地位的爭奪。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟對 OpenAI 的投資，以及谷歌在人工智能領域的領先地位，突顯了人工智能技術在當今科技行業中的戰略重要性。大型科技公司之間的合作和競爭，以及它們如何平衡這些關係，是這個事件背後的一個重要議題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，美國聯邦貿易委員會對生成式 AI 市場中的主要參與者進行調查，也顯示了監管機構對市場競爭和投資合作的關注。這一事件還映射出人工智能技術對未來社會和商業環境可能產生的深遠影響。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290662&quot; target=&quot;_blank&quot;&gt;90 後程序員開發視頻搬運軟件、不到一年獲利超 700 萬，結局很刑！&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;央視《今日説法》欄目近期報道了一名 90 後程序員通過開發非法視頻搬運軟件在不到一年的時間裏獲利超 700 萬，最終獲刑的案例。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;國內某知名短視頻平台報警稱，有人在網絡上售賣一款非法軟件，使用軟件的人可以繞過他們平台的審核機制，直接竊取他人的作品進行發佈。浙江台州警方調查發現，在這背後是一條違法犯罪的產業鏈條，&lt;strong&gt;犯罪團夥的上游開發製作非法軟件，通過更改短視頻平台的代碼，逃避平台監管。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;img height=&quot;288&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1145c8cd8feb9548ccd491137262165b6c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此案例強調了保護知識產權的重要性，尤其是在數字化和網絡化日益普及的今天。雖然創業是鼓勵的，但選擇合法合規的項目至關重要；強調了個人在網絡安全中的道德責任，即使在看似無害的行為背後也可能隱藏着嚴重的法律風險。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，隨着技術的發展，法律可能跟不上技術應用的速度，導致法律監管的缺失。同時也反映出網絡監管和平台安全的重要性，平台需要加強技術措施以防止此類非法行為的發生。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240506A01WTQ00&quot; target=&quot;_blank&quot;&gt;OpenAI 的 AI 搜索也要來了，但我們需要這麼多 AI 搜索麼&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#303030; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;雖然 AI 搜索技術非常強大和有價值，但從用戶體驗、習慣和企業資源配置的角度出發，將其作為增強現有產品的一個特性，而非開發為獨立的搜索產品，可能是更為合理的方向。這樣不僅能更好地滿足用戶需求，對企業來説也是更好地選擇。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#303030; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;看起來，AI 搜索離生成式人工智能時代的 Killer App 距離尚遠，它甚至可能並不是一個理想的生意。我們並不需要那麼多的 AI 搜索產品，但我們需要更多的 AI 搜索 Feature。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;硅星人 Pro&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn788037925&quot; target=&quot;_blank&quot;&gt;微軟的焦慮和野心，再也藏不住了&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;雖然 AI 初創公司當前仍然處於入不敷出、苦苦探索盈利模式的階段，但 AI 的熱潮已經讓提供算力和數據的 AI 基礎設施供應商賺得盆滿缽滿。觀察微軟 AI 投資的兩條主線，這個領先者的野心也昭然若揭：一方面通過外部投資或直接「兼併」AI 初創公司，保持自身在生成式 AI 技術的優勢；另一方面，通過大力佈局 AI 基礎設施，發力雲計算市場，打造更強勁的業績增長曲線。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;/span&gt;&lt;strong&gt;創業資本匯&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1798183798926466025%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;民生證券胡又文：AI 是下一個時代的技術浪潮，且仍處於早期階段&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 是下一個時代的技術浪潮，甚至可能是人類歷史上最大的科技革命。從 AlphaGo 的突破到硅谷的最新進展，AI 技術的快速發展正不斷推動社會進步。儘管存在成本高昂和潛在的政治影響等挑戰，AI 在自動駕駛、語言模型等領域的應用已經展現出巨大的變革潛力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;-&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;財聯社&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用戶觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF7a5NbHdpaXeglUJlcrChw&quot; target=&quot;_blank&quot;&gt;中國碼農的「35 歲魔咒」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：現在新人可不便宜，幹幾年就跟老人工資差不多了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：把老闆開除不就好了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：所以嚴格落實 8 小時工作制才能拯救 35 歲危機&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：項目中接觸了幾位外企的一線技術人員，老外的一位項目帶頭人 60 好幾了，依然在 Coding。這就是差距。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：如果不加班，是不是年輕人和中年人的人力性價比就差不多了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：你不會永遠 18 歲，但永遠有人 18 歲&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：又不是光程序員，IT 行業都是這樣&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：年輕人有衝勁，讓他們先衝，搞出問題，我們這些老燈再出來擦屁股，年輕人得到了鍛鍊機會，老燈們保住了飯碗，一舉兩得，多好&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：哈，出生率低的環境中，又想要更年輕的勞動力，本身就是衝突的。再者工作需要加班才能完成的，要麼是能力不行，要麼是公司不行&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：35 上班嫌老，60 退休嫌早&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FzNEYq-yR1HyMmsQ9KpKgEA&quot; target=&quot;_blank&quot;&gt;微軟前工程師稱 Windows 11 性能差得笑死人，難怪市場份額持續下降&lt;/a&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：微軟前工程師稱 Windows 11 性能差得笑死人，難怪市場份額持續下降，所以他現在是微軟前工程師了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：微軟唯一的問題是沒品位，完全沒有品位可言...&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：資源管理經常卡死，打開的軟件經常卡住&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：linux 造不出這種圖形界面&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：利用 Win11 讓更多用戶使用 Win10&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：這還菜單我也覺得離譜，我最開始還以為是我鼠標的問題&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：微軟的重點在雲計算和人工智能了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：win10 也好，11 也罷。都有一個讓我不理解的地方，為啥開機到進桌面的時間越用越長？按了開機鍵後，硬盤燈幾乎一直常亮，感覺電腦費了吃奶的勁，好不容易才進了桌面。就算進了桌面，硬盤還要瘋狂工作一段時間才歇下來。至於在開機這個過程要做這麼多事嗎？ 我用的一般 ssd。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：windows 一個版本好, 一個版本爛的定律還沒有打破&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：現在新機一水預裝 win11, 不理解 win10 的份額是怎麼增加的？難道有大批的系統在降級麼？感覺不過是統計的問題。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSnTLIMG13clwVCFHfaKDxQ&quot; target=&quot;_blank&quot;&gt;90 後程序員辭職搞灰產：開發視頻搬運軟件、不到一年獲利超 700 萬，結局很刑！&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：魯班七號，沒有技術含量但是解救了很多人 1.0 替換待發布的緩存視頻，最後更新諸神黃昏版本是替換視頻模板，當時是直播切片的時代，一台手機一天幾萬流水（矩陣利潤自己想吧） 只有懂得人才知道魯班七號產生的價值，我當時賣出去的卡密讓很多人翻了身喘了口氣&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：這算是自首嗎&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：厲害的是他的銷售，一年賣 20 萬份。有這銷售能力幹啥不好。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：他竊取的視頻是不知道多少原創作者的心血，沒有所謂收入，不過是搶奪罷了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：這都能賺 700 多萬？這技術我真心不覺得難，佩服的是這哥們的銷售技術&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：對，很多人沒意識到，獲客比代碼難多了....&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：收入和付出不成正比，就會滋生出一些歹念。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：正確的操作方式是，入職一家公司，月薪 5 萬，工作十分輕鬆，老闆喜歡看短視頻，他就把自己開發的下載軟件「免費」分享給老闆。工作半年後公司破產了，但 30 萬工資已經結清。你説他是否需要承擔責任？&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：替換已審核通過視頻，相當於數據庫數據被篡改，説明視頻平台暴露了相關接口，視頻平台漏洞也不小。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最後，歡迎掃碼下載「開源中國 APP」，閲讀海量技術報告、程序員極客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291051</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291051</guid>
            <pubDate>Mon, 06 May 2024 10:11:02 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>面壁智能發佈 Eurux-8x22B 開源大模型 —— 堪稱「理科狀元」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;面壁智能近日發佈開源大模型 Eurux-8x22B，包括 Eurux-8x22B-NCA 與 Eurux-8x22B-KTO，主打推理能力。&lt;/p&gt; 
&lt;p&gt;官方介紹道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相比口碑之作 Llama3-70B，Eurux-8x22B 發佈時間更早，綜合性能相當，尤其是擁有更強的推理性能——&lt;strong&gt;刷新開源大模型推理性能 SOTA，堪稱開源大模型中「理科狀元」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Eurux-8x22B 在 LeetCode（180 道 LeetCode 編程真題）與 TheoremQA 測試上超越了 Llama3-70B，在 LeetCode 測試上超越閉源的 GPT-3.5-Turbo。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e821808c7c8fd5dd504c26678ed49faa489.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e902f31df9be97cefd4dfd235955106ada6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Eurux-8x22B 模型激活參數 39B，支持 64k 上下文，是由 Mixtral-8x22B 模型對齊而來，在 UltraInteract 對齊數據集上訓練而成。&lt;/p&gt; 
&lt;p&gt;Eurux-8x22B 模型+對齊數據集均已開源：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Eurux-8x22B 模型 GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FEurus&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;https://github.com/OpenBMB/Eurus&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Eurux-8x22B 模型 HuggingFace 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fopenbmb%2FEurux-8x22b-nca&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;https://huggingface.co/openbmb/Eurux-8x22b-nca&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291040</guid>
            <pubDate>Mon, 06 May 2024 09:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>視覺語言模型詳解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;p&gt;視覺語言模型可以同時從圖像和文本中學習，因此可用於視覺問答、圖像描述等多種任務。本文，我們將帶大家一覽視覺語言模型領域: 作個概述、瞭解其工作原理、搞清楚如何找到真命天「模」、如何對其進行推理以及如何使用最新版的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;trl&lt;/a&gt; 輕鬆對其進行微調。&lt;/p&gt; 
&lt;h2&gt;什麼是視覺語言模型？&lt;/h2&gt; 
&lt;p&gt;視覺語言模型是可以同時從圖像和文本中學習的多模態模型，其屬於生成模型，輸入為圖像和文本，輸出為文本。大視覺語言模型具有良好的零樣本能力，泛化能力良好，並且可以處理包括文檔、網頁等在內的多種類型的圖像。其擁有廣泛的應用，包括基於圖像的聊天、根據指令的圖像識別、視覺問答、文檔理解、圖像描述等。一些視覺語言模型還可以捕獲圖像中的空間信息，當提示要求其檢測或分割特定目標時，這些模型可以輸出邊界框或分割掩模，有些模型還可以定位不同的目標或回答其相對或絕對位置相關的問題。現有的大視覺語言模型在訓練數據、圖像編碼方式等方面採用的方法很多樣，因而其能力差異也很大。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/jK8WsS.png&quot; alt=&quot;VLM 能力&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;開源視覺語言模型概述&lt;/h2&gt; 
&lt;p&gt;Hugging Face Hub 上有很多開放視覺語言模型，下表列出了其中一些佼佼者。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;其中有基礎模型，也有可用於對話場景的針對聊天微調的模型。&lt;/li&gt; 
 &lt;li&gt;其中一些模型具有「接地 (grounding )」功能，因此能夠減少模型幻覺。&lt;/li&gt; 
 &lt;li&gt;除非另有説明，所有模型的訓練語言皆為英語。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;可否商用&lt;/th&gt; 
   &lt;th&gt;模型尺寸&lt;/th&gt; 
   &lt;th&gt;圖像分辨率&lt;/th&gt; 
   &lt;th&gt;其它能力&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fllava-hf%2Fllava-v1.6-34b-hf&quot; target=&quot;_blank&quot;&gt;LLaVA 1.6 (Hermes 34B)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;34B&lt;/td&gt; 
   &lt;td&gt;672x672&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2Fdeepseek-vl-7b-base&quot; target=&quot;_blank&quot;&gt;deepseek-vl-7b-base&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;384x384&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2Fdeepseek-vl-7b-chat&quot; target=&quot;_blank&quot;&gt;DeepSeek-VL-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;384x384&lt;/td&gt; 
   &lt;td&gt;聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvikhyatk%2Fmoondream2&quot; target=&quot;_blank&quot;&gt;moondream2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;~2B&lt;/td&gt; 
   &lt;td&gt;378x378&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FTHUDM%2Fcogvlm-base-490-hf&quot; target=&quot;_blank&quot;&gt;CogVLM-base&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;17B&lt;/td&gt; 
   &lt;td&gt;490x490&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FTHUDM%2Fcogvlm-chat-hf&quot; target=&quot;_blank&quot;&gt;CogVLM-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;17B&lt;/td&gt; 
   &lt;td&gt;490x490&lt;/td&gt; 
   &lt;td&gt;接地、聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fadept%2Ffuyu-8b&quot; target=&quot;_blank&quot;&gt;Fuyu-8B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;300x300&lt;/td&gt; 
   &lt;td&gt;圖像中的文本檢測&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmicrosoft%2Fkosmos-2-patch14-224&quot; target=&quot;_blank&quot;&gt;KOSMOS-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;~2B&lt;/td&gt; 
   &lt;td&gt;224x224&lt;/td&gt; 
   &lt;td&gt;接地、零樣本目標檢測&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen-VL&quot; target=&quot;_blank&quot;&gt;Qwen-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;零樣本目標檢測&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen-VL-Chat&quot; target=&quot;_blank&quot;&gt;Qwen-VL-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-VL-34B&quot; target=&quot;_blank&quot;&gt;Yi-VL-34B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;34B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;雙語 (英文、中文)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;尋找合適的視覺語言模型&lt;/h2&gt; 
&lt;p&gt;有多種途徑可幫助你選擇最適合自己的模型。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FWildVision%2Fvision-arena&quot; target=&quot;_blank&quot;&gt;視覺競技場 (Vision Arena)&lt;/a&gt; 是一個完全基於模型輸出進行匿名投票的排行榜，其排名會不斷刷新。在該競技場上，用戶輸入圖像和提示，會有兩個匿名的不同的模型為其生成輸出，然後用戶可以基於他們的喜好選擇一個輸出。這種方式生成的排名完全是基於人類的喜好的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/ybVPde.png&quot; alt=&quot;視覺競技場 (Vision Arena)&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fopencompass%2Fopen_vlm_leaderboard&quot; target=&quot;_blank&quot;&gt;開放 VLM 排行榜&lt;/a&gt; 提供了另一種選擇，各種視覺語言模型按照所有指標的平均分進行排名。你還可以按照模型尺寸、私有或開源許可證來篩選模型，並按照自己選定的指標進行排名。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/2dOyhv.png&quot; alt=&quot;開放 VLM 排行榜&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopen-compass%2FVLMEvalKit&quot; target=&quot;_blank&quot;&gt;VLMEvalKit&lt;/a&gt; 是一個工具包，用於在視覺語言模型上運行基準測試，開放 VLM 排行榜就是基於該工具包的。&lt;/p&gt; 
&lt;p&gt;還有一個評估套件是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FEvolvingLMMs-Lab%2Flmms-eval&quot; target=&quot;_blank&quot;&gt;LMMS-Eval&lt;/a&gt;，其提供了一個標準命令行界面，你可以使用 Hugging Face Hub 上託管的數據集來對選定的 Hugging Face 模型進行評估，如下所示:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch --num_processes=8 -m lmms_eval --model llava --model_args pretrained=&quot;liuhaotian/llava-v1.5-7b&quot; --tasks mme,mmbench_en --batch_size 1 --log_samples --log_samples_suffix llava_v1.5_mme_mmbenchen --output_path ./logs/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;視覺競技場和開放 VLM 排行榜都僅限於提交給它們的模型，且需要更新才能添加新模型。如果你想查找其他模型，可以在 &lt;code&gt;image-text-to-text&lt;/code&gt; 任務下瀏覽 hub 中的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmodels%3Fpipeline_tag%3Dimage-text-to-text%26sort%3Dtrending&quot; target=&quot;_blank&quot;&gt;模型&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在排行榜中，你會看到各種不同的用於評估視覺語言模型的基準，下面我們選擇其中幾個介紹一下。&lt;/p&gt; 
&lt;h3&gt;MMMU&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FMMMU%2FMMMU&quot; target=&quot;_blank&quot;&gt;針對專家型 AGI 的海量、多學科、多模態理解與推理基準 (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI，MMMU)&lt;/a&gt; 是評估視覺語言模型的最全面的基準。它包含 11.5K 個多模態問題，這些問題需要大學水平的學科知識以及跨學科 (如藝術和工程) 推理能力。&lt;/p&gt; 
&lt;h3&gt;MMBench&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Flmms-lab%2FMMBench&quot; target=&quot;_blank&quot;&gt;MMBench&lt;/a&gt; 由涵蓋超過 20 種不同技能的 3000 道單選題組成，包括 OCR、目標定位等。論文還介紹了一種名為 &lt;code&gt;CircularEval&lt;/code&gt; 的評估策略，其每輪都會對問題的選項進行不同的組合及洗牌，並期望模型每輪都能給出正確答案。&lt;/p&gt; 
&lt;p&gt;另外，針對不同的應用領域還有其他更有針對性的基準，如 MathVista (視覺數學推理) 、AI2D (圖表理解) 、ScienceQA (科學問答) 以及 OCRBench (文檔理解)。&lt;/p&gt; 
&lt;h2&gt;技術細節&lt;/h2&gt; 
&lt;p&gt;對視覺語言模型進行預訓練的方法很多。主要技巧是統一圖像和文本表徵以將其輸入給文本解碼器用於文本生成。最常見且表現最好的模型通常由圖像編碼器、用於對齊圖像和文本表徵的嵌入投影子模型 (通常是一個稠密神經網絡) 以及文本解碼器按序堆疊而成。至於訓練部分，不同的模型採用的方法也各不相同。&lt;/p&gt; 
&lt;p&gt;例如，LLaVA 由 CLIP 圖像編碼器、多模態投影子模型和 Vicuna 文本解碼器組合而成。作者將包含圖像和描述文本的數據集輸入 GPT-4，讓其描述文本和圖像生成相關的問題。作者凍結了圖像編碼器和文本解碼器，僅通過給模型饋送圖像與問題並將模型輸出與描述文本進行比較來訓練多模態投影子模型，從而達到對齊圖像和文本特徵的目的。在對投影子模型預訓練之後，作者把圖像編碼器繼續保持在凍結狀態，解凍文本解碼器，然後繼續對解碼器和投影子模型進行訓練。這種預訓練加微調的方法是訓練視覺語言模型最常見的做法。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/cETuLf.png&quot; alt=&quot;視覺語言模型典型結構&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/2kDGpc.png&quot; alt=&quot;將投影子模型輸出與文本嵌入相串接&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再舉一個 KOSMOS-2 的例子，作者選擇了端到端地對模型進行完全訓練的方法，這種方法與 LLaVA 式的預訓練方法相比，計算上昂貴不少。預訓練完成後，作者還要用純語言指令對模型進行微調以對齊。還有一種做法，Fuyu-8B 甚至都沒有圖像編碼器，直接把圖像塊饋送到投影子模型，然後將其輸出與文本序列直接串接送給自迴歸解碼器。&lt;/p&gt; 
&lt;p&gt;大多數時候，我們不需要預訓練視覺語言模型，僅需使用現有的模型進行推理，抑或是根據自己的場景對其進行微調。下面，我們介紹如何在 &lt;code&gt;transformers&lt;/code&gt; 中使用這些模型，以及如何使用 &lt;code&gt;SFTTrainer&lt;/code&gt; 對它們進行微調。&lt;/p&gt; 
&lt;h2&gt;在 transformers 中使用視覺語言模型&lt;/h2&gt; 
&lt;p&gt;你可以使用 &lt;code&gt;LlavaNext&lt;/code&gt; 模型對 Llava 進行推理，如下所示。&lt;/p&gt; 
&lt;p&gt;首先，我們初始化模型和數據處理器。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration
import torch

device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
processor = LlavaNextProcessor.from_pretrained(&quot;llava-hf/llava-v1.6-mistral-7b-hf&quot;)
model = LlavaNextForConditionalGeneration.from_pretrained(
    &quot;llava-hf/llava-v1.6-mistral-7b-hf&quot;,
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True
)
model.to(device)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，將圖像和文本提示傳給數據處理器，然後將處理後的輸入傳給 &lt;code&gt;generate&lt;/code&gt; 方法。請注意，每個模型都有自己的提示模板，請務必根據模型選用正確的模板，以避免性能下降。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from PIL import Image
import requests

url = &quot;https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true&quot;
image = Image.open(requests.get(url, stream=True).raw)
prompt = &quot;[INST] &amp;lt;img src=&quot;&quot;&amp;gt;\nWhat is shown in this image? [/INST]&quot;

inputs = processor(prompt, image, return_tensors=&quot;pt&quot;).to(device)
output = model.generate(**inputs, max_new_tokens=100)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;調用 &lt;code&gt;decode&lt;/code&gt; 對輸出詞元進行解碼。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;print(processor.decode(output[0], skip_special_tokens=True))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;使用 TRL 微調視覺語言模型&lt;/h2&gt; 
&lt;p&gt;我們很高興地宣佈，作為一個實驗性功能，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;TRL&lt;/a&gt; 的 &lt;code&gt;SFTTrainer&lt;/code&gt; 現已支持視覺語言模型！這裏，我們給出了一個例子，以展示如何在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2FHuggingface.co%2Fdatasets%2FHuggingFaceH4%2Fllava-instruct-mix-vsft&quot; target=&quot;_blank&quot;&gt;llava-instruct&lt;/a&gt; 數據集上進行 SFT，該數據集包含 260k 個圖像對話對。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;llava-instruct&lt;/code&gt; 數據集將用戶與助理之間的交互組織成消息序列的格式，且每個消息序列皆與用戶問題所指的圖像配對。&lt;/p&gt; 
&lt;p&gt;要用上 VLM 訓練的功能，你必須使用 &lt;code&gt;pip install -U trl&lt;/code&gt; 安裝最新版本的 TRL。你可在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl%2Fblob%2Fmain%2Fexamples%2Fscripts%2Fvsft_llava.py&quot; target=&quot;_blank&quot;&gt;此處&lt;/a&gt; 找到完整的示例腳本。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from trl.commands.cli_utils import SftScriptArguments, TrlParser

parser = TrlParser((SftScriptArguments, TrainingArguments))
args, training_args = parser.parse_args_and_config()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;初始化聊天模板以進行指令微調。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;LLAVA_CHAT_TEMPLATE = &quot;&quot;&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions. {% for message in messages %}{% if message[&#39;role&#39;] == &#39;user&#39; %}USER: {% else %}ASSISTANT: {% endif %}{% for item in message[&#39;content&#39;] %}{% if item[&#39;type&#39;] == &#39;text&#39; %}{{ item[&#39;text&#39;] }}{% elif item[&#39;type&#39;] == &#39;image&#39; %}&amp;lt;img src=&quot;&quot;&amp;gt;{% endif %}{% endfor %}{% if message[&#39;role&#39;] == &#39;user&#39; %} {% else %}{{eos_token}}{% endif %}{% endfor %}&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，初始化模型和分詞器。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoTokenizer, AutoProcessor, TrainingArguments, LlavaForConditionalGeneration
import torch

model_id = &quot;llava-hf/llava-1.5-7b-hf&quot;
tokenizer = AutoTokenizer.from_pretrained(model_id)
tokenizer.chat_template = LLAVA_CHAT_TEMPLATE
processor = AutoProcessor.from_pretrained(model_id)
processor.tokenizer = tokenizer

model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;建一個數據整理器來組合文本和圖像對。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;class LLavaDataCollator:
    def __init__(self, processor):
        self.processor = processor

    def __call__(self, examples):
        texts = []
        images = []
        for example in examples:
            messages = example[&quot;messages&quot;]
            text = self.processor.tokenizer.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=False
            )
            texts.append(text)
            images.append(example[&quot;images&quot;][0])

        batch = self.processor(texts, images, return_tensors=&quot;pt&quot;, padding=True)

        labels = batch[&quot;input_ids&quot;].clone()
        if self.processor.tokenizer.pad_token_id is not None:
            labels[labels == self.processor.tokenizer.pad_token_id] = -100
        batch[&quot;labels&quot;] = labels

        return batch

data_collator = LLavaDataCollator(processor)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;加載數據集。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from datasets import load_dataset

raw_datasets = load_dataset(&quot;HuggingFaceH4/llava-instruct-mix-vsft&quot;)
train_dataset = raw_datasets[&quot;train&quot;]
eval_dataset = raw_datasets[&quot;test&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;初始化 &lt;code&gt;SFTTrainer&lt;/code&gt; ，傳入模型、數據子集、PEFT 配置以及數據整理器，然後調用 &lt;code&gt;train()&lt;/code&gt; 。要將最終 checkpoint 推送到 Hub，需調用 &lt;code&gt;push_to_hub()&lt;/code&gt; 。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from trl import SFTTrainer

trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    dataset_text_field=&quot;text&quot;, # need a dummy field
    tokenizer=tokenizer,
    data_collator=data_collator,
    dataset_kwargs={&quot;skip_prepare_dataset&quot;: True},
)

trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;保存模型並推送到 Hugging Face Hub。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;trainer.save_model(training_args.output_dir)
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你可在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FHuggingFaceH4%2Fvsft-llava-1.5-7b-hf-trl&quot; target=&quot;_blank&quot;&gt;此處&lt;/a&gt; 找到訓得的模型。你也可以通過下面的頁面試玩一下我們訓得的模型⬇️。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/mH0Bny.png&quot; alt=&quot;https://HuggingFaceH4-vlm-playground.hf.space&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;致謝&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們感謝 Pedro Cuenca、Lewis Tunstall、Kashif Rasul 和 Omar Sanseviero 對本文的評論和建議。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&amp;gt; 英文原文: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fvlms&quot; target=&quot;_blank&quot;&gt;https://hf.co/blog/vlms&lt;/a&gt; &amp;gt; 原文作者: Merve Noyan，Edward Beeching &amp;gt; 譯者: Matrix Yao (姚偉峯)，英特爾深度學習工程師，工作方向為 transformer-family 模型在各模態數據上的應用及大規模模型的訓練推理。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/HuggingFace/blog/11090508</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/11090508</guid>
            <pubDate>Mon, 06 May 2024 08:42:03 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Java 17 是最常用的 Java LTS 版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;New Relic 最新發布了一份「&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewrelic.com%2Fresources%2Freport%2F2024-state-of-the-java-ecosystem&quot; target=&quot;_blank&quot;&gt;2024 年 Java 生態系統狀況報告&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;」，旨在提供有關當今 Java 生態系統狀態的背景和見解。該報告基於每月向 New Relic 報告的數十萬應用程序的數據，對生產中使用最多的版本、最受歡迎的 JDK 供應商、Java 應用程序中計算和內存的使用等多方面進行了調研分析。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告最先分析了「生產中最常用的 Java 版本」，指出在 Java 21 (2023 年 9 月) 發佈後的六個月裏，New Relic 監控的應用程序中有 1.4% 使用了該版本。相較而言，在 Java 17 (2021 年 9 月) 推出後的六個月裏，只有 0.37% 的應用程序使用了 Java 17。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Java 17 的採用率遠遠超過了 Java 11 推出時的情況。到 2023 年，大約十分之一 (9%) 的應用程序在生產中使用 Java 17，截至目前已有 35% 的應用程序正在使用 Java 17，一年內增長率接近 300%。而 Java 11 用了數年時間才接近這一水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從 2018 年 9 月起， Java 17 已取代 Java 11，成為最常用的 LTS 版本。此外，只有不到 2% 的應用程序使用的是 Java 非 LTS 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;319&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-812dcfc5be91b26c7a64836b3cc653a5fd1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在最受歡迎的 JDK 供應商方面，Oracle 的 JDK 在 2020 年大約佔據了 75% 的市場份額；但佔比逐年下降 —— 2022 年 34%、2023 年滑落到 29%，以及現在降至 21%。2023 年，亞馬遜的使用率增至 31%（2020 年為 2.2%，2022 年為 22%），但 2024 年降至 18%，同比下降 43%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的後起之秀是 Eclipse Adoptium，其採用率同比增長了 50%，從 12% 上升到 18%。由於 Eclipse Adoptium 由社區管理，因此該 JDK 的更新頻率往往高於 Oracle 和 Amazon JDK。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;345&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d8810959abf3165698cec20353fc5177e8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#4e4242&quot;&gt;其他一些發現還包括：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用四個或更少核心運行的應用程序同比增長 18%，其中 68% 的應用程序使用 1-4 個核心。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Log4j 是 Java 應用程序中最流行的日誌框架，有 76.4% 的 Java&amp;nbsp;應用程序使用；其次是 JBoss Logging (61%) 和 Logback (52%)。大多數 (83%) Java 開發人員依賴 SLF4j。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Bouncy Castle 是 Java 應用程序中最流行的加密庫，佔有 17.1% 的份額。其次是&amp;nbsp;16% 使用 Spring Security，6% 使用 Jasypt。雖然只有 0.09% 的開發人員使用 Amazon Corretto Crypto Provider (ACCP) 庫，但 New Relic&amp;nbsp;預計在不久的將來會有更多應用程序使用它，因為公司和開發人員希望整合供應商，而且它通常可以提供更好的性能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Oracle 數據庫是 Java 應用程序中最流行的數據庫系統，使用率為 17.3%。 PostgreSQL 位居第二，佔 14.4%。MySQL 排名第三，有 13% 的 Java 應用程序使用它。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;345&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8b98dc6406e7255f7114ad22c7da1808c07.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:left&quot;&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;hr&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;該報告已上傳至開源中國 APP，詳情可至&lt;strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;&lt;span style=&quot;background-color:#f39c12&quot;&gt;「開源中國 APP - 報告模塊」&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;下載&lt;/span&gt;查看。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;APP 下載地址：&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;https://www.oschina.net/app&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291030/2024-state-of-the-java-ecosystem</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291030/2024-state-of-the-java-ecosystem</guid>
            <pubDate>Mon, 06 May 2024 08:31:03 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>《2024 年中國企業級 SaaS 行業研究報告》發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;近日，艾瑞諮詢發佈《2024 年中國企業級 SaaS 行業研究報告》，主要內容包括中國企業級 SaaS 行業的市場趨勢、企業實踐、行業動態、資本動向、投融資情況、上市情況以及企業應用實踐等多個方面的分析和預測。&lt;/p&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;297&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0506/162722_gs6k_4700705.png&quot; width=&quot;360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;以下是核心內容的概要：&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;市場趨勢&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;2023 年中國企業級 SaaS 市場規模達到 888 億元，同比增長 13.0%。&lt;/li&gt; 
       &lt;li&gt;預計未來三年市場增速將穩定在 15%-20%，複合增速約 15%。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;企業實踐&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;SaaS 應用在企業中的滲透率不斷提升。&lt;/li&gt; 
       &lt;li&gt;大型企業傾向於定製集成，中型企業成為平台生態模式的主流應用羣體。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SaaS 行業動態&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;行業熱點包括與 AIGC 的結合、集成可行性討論，以及 SaaS 廠商出海探索。&lt;/li&gt; 
       &lt;li&gt;SaaS 廠商底層邏輯從流量互換向產品融合轉變，集成與被集成選擇更靈活。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;資本動向&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;投融資筆數逐步下滑，融資輪次後移，2023 年天使輪、A 輪佔比回升。&lt;/li&gt; 
       &lt;li&gt;行業可能進入由行業垂直型廠商領銜的新一輪成長週期。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;投融資情況&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;投資熱度下滑，SaaS 創業公司面臨更大壓力，自我造血能力變得重要。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;上市情況&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;香港上市門檻對高成長性企業友好，成為 SaaS 廠商首選。&lt;/li&gt; 
       &lt;li&gt;內地和香港上市公司的營收增長率和毛利率指標有所下跌，但毛利率維持健康水平。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;企業應用實踐&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;大型企業傾向定製集成，中型企業更傾向於平台生態模式。&lt;/li&gt; 
       &lt;li&gt;海外企業 SaaS 偏好差異顯著，發達國家青睞專業功能出色的產品，發展中國家與出海企業講究性價比。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SaaS 廠商&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;騰訊 TAPD 和 Quick Creator 作為典型 SaaS 廠商案例被提及，展示了它們的產品特點和市場策略。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;法律聲明&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;報告版權歸艾瑞諮詢所有，未經授權不得複製或傳播。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ol&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;報告還包含了中國企業級 SaaS 市場規模的預測圖表、SaaS 產業圖譜、SaaS 集成與生態的分析、SaaS 出海現狀和策略、投融資情況的詳細數據和圖表，以及對 SaaS 投資標的判斷依據的討論。&lt;/p&gt; 
    &lt;hr&gt; 
    &lt;p&gt;目前，該報告已上傳至開源中國 APP，詳情可至&lt;strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;&lt;span style=&quot;background-color:#f39c12&quot;&gt;「開源中國 APP - 報告模塊」&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;下載&lt;/span&gt;查看。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;APP 下載地址：&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;https://www.oschina.net/app&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291029</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291029</guid>
            <pubDate>Mon, 06 May 2024 08:29:03 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Zadig 免費試用全面開放：提升工作效率，享受流暢體驗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;div style=&quot;text-align:center&quot;&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bca623bfd697efe68f9741066044e920c24.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  Zadig 自開源以來，已在國內獲得廣泛認可，超過 3000 家企業正在使用。企業安裝總量破 3 萬次，每日活躍用戶近 15 萬，全球累計部署應用數量超過 50 萬。隨着 V2.0 新開源架構的發佈，Zadig 的商業版也受到了眾多企業的關注和喜愛。Zadig 平台為工程師和產品研發團隊提供了綜合的解決方案，旨在打造一個無縫、流暢的工作環境。為了進一步提升用戶體驗，Zadig 現在推出了全面免費的試用選項： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;在線教學環境無限試用&lt;/strong&gt;：用戶可以隨時訪問官網 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Ftrial&quot; target=&quot;_blank&quot;&gt;在線試用&lt;/a&gt;，即刻開始在線體驗 Zadig。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;本地下載 30 天免費試用&lt;/strong&gt;：這一選項允許用戶深入體驗 Zadig 的全部功能，非常適合需要日常協作的小團隊使用（提供 20 個用戶授權）。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;Zadig 安裝詳情&lt;/h2&gt; 
&lt;div&gt; 
 &lt;strong&gt;第一步&lt;/strong&gt;：訪問官網，提交 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2FgetLicense&quot; target=&quot;_blank&quot;&gt;試用信息&lt;/a&gt;以獲取安裝指南。如果已安裝 Zadig 最新版也可通過系統內 
 &lt;code&gt;獲取許可證&lt;/code&gt;鏈接進入試用入口。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;第二步&lt;/strong&gt;：未安裝的用戶通過使用 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Finstaller&quot; target=&quot;_blank&quot;&gt;安裝小助手&lt;/a&gt; 或 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2FZadig%2520v2.2.0%2Finstall%2Fguide%2F&quot; target=&quot;_blank&quot;&gt;運維文檔&lt;/a&gt; 進行最新版快速安裝。進入系統後完成管理員註冊，選擇「企業版」查看系統 ID。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;第三步&lt;/strong&gt;：輸入系統 ID 生成免費許可證，上傳後即可開始使用。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3c32bc07ca1203de1a68087365286c6647e.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  官網下載安裝頁面 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ab289ca1720b77af40d3b7d1e1b67bca83.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  下載安裝 Zadig 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1046&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70644eaa70e4008f157ebe8c79d5c404cbd.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  輸入系統 ID 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67420cfda350fb49feb60c27794c4abda0a.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
   獲取許可證 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8d69cb096990f59f11f499d94f2d352a38d.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  註冊系統管理員 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b7a0492570416376ecfa5d5ad3219322042.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  選擇版本 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-12035f09a82a4a98d14282a31d246cbf63c.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
   輸入許可證 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;如何開始試用&lt;/h2&gt; 
&lt;div&gt;
  要快速上手 Zadig，我們為您提供了一個簡潔的試用流程： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;瞭解 Zadig&lt;/strong&gt;：閲讀 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Fquick-start%2Fintroduction%2F%23%25E4%25B8%259A%25E5%258A%25A1%25E6%259E%25B6%25E6%259E%2584%2F&quot; target=&quot;_blank&quot;&gt;入門文檔&lt;/a&gt;，掌握 Zadig 的核心概念和框架。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;配置系統&lt;/strong&gt;：參考《 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2FZadig%2520v2.2.0%2Fsystem-manual&quot; target=&quot;_blank&quot;&gt;系統管理員操作手冊&lt;/a&gt;》，迅速完成系統設置和初始化。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;實踐操作&lt;/strong&gt;：通過 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Fquick-start%2Fa-basic-project%2F&quot; target=&quot;_blank&quot;&gt;Demo 項目&lt;/a&gt; 進行實踐，掌握 Zadig 基本操作和功能。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;在線體驗&lt;/strong&gt;：註冊並登錄 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Ftrial&quot; target=&quot;_blank&quot;&gt;在線試用環境&lt;/a&gt; ，探索各種技術場景下的最佳實踐，找到與您需求相匹配的案例，並嘗試將其應用於您的業務或項目中。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;常見問題 Q&amp;amp;A&lt;/h2&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q1: Zadig 試用支持哪些安裝方式？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A1：提供 「基於主機快速試用」和「基於 Kubernetes 正式運維」兩種主要安裝方式，具體參考 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Finstall%2Fguide&quot; target=&quot;_blank&quot;&gt;運維文檔&lt;/a&gt; 。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q2: Zadig 提供了哪些版本，各自具備哪些功能？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A2: 您可以通過訪問 
 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Fpricing&quot; target=&quot;_blank&quot;&gt;Zadig 報價頁面&lt;/a&gt;&lt;/u&gt; 查看不同版本的詳細功能列表和比較。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q3: 達到許可證用戶人數限制時，系統會如何響應？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A3: 當用戶數量超過許可證限制時，已登錄的用戶可以繼續正常使用系統，但新用戶將無法登錄。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q4: 如果許可證到期未續費，我還能使用 Zadig 嗎？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A4: 許可證到期後，若未續費，您的賬戶將降級至基礎版功能。所有與高級功能相關的現有數據將保留，您可以查看和編輯這些數據，但無法繼續使用高級功能。如需繼續使用專家版或企業版的高級功能，請聯繫 Zadig 官方購買相應的許可證。 
&lt;/div&gt; 
&lt;div&gt;
  若您在試用過程中遇到任何問題，歡迎掃碼加入我們的交流羣，以獲得即時幫助和支持。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;領先企業都在用&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;掃碼諮詢如何落地先進理念&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style=&quot;text-align:center&quot;&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;942&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6809e8481550e1f9e4ce39b55f9f4a03335.png&quot; width=&quot;1796&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig&quot; target=&quot;_blank&quot;&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://gitee.com/koderover/zadig&quot;&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;strong&gt;&lt;span&gt;推薦閲讀：&lt;/span&gt;&lt;/strong&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#002a64; margin-left:0px; margin-right:0px&quot;&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10926966&quot; target=&quot;_blank&quot;&gt;DevOps 選型指南：Zadig / 雲效 / Coding/Jenkins/GitLab/Argo/Tekton&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;/&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10316143&quot; target=&quot;_blank&quot;&gt;Jenkins 遷移 Zadig，新項目實施上線效率提升 6 倍&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;/&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10093925&quot; target=&quot;_blank&quot;&gt;Zadig vs. Jenkins 詳細比對：時代的選擇與開發者之選&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/11052954&quot; target=&quot;_blank&quot;&gt;Zadig V2.2.0 全面支持多副本，升級工作流引擎，又穩又強&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10322927&quot; target=&quot;_blank&quot;&gt;ZADIG 專家版傾情上線：一鍵高效發佈，119 元 / 人月起，社區老友享年終福利！&lt;/a&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#002a64; margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/koderover/blog/11054385</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/11054385</guid>
            <pubDate>Mon, 06 May 2024 08:13:33 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>NetBSD 談 X.Org/X11 的現狀和未來</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Linux 上，桌面環境、圖形棧和其他應用軟件都在穩步採用 Wayland 支持，而不再那麼關注 X11/X.Org 支持。但在 BSD 中，Wayland 支持和開源圖形驅動程序棧的總體狀況卻沒那麼穩健勁。NetBSD 項目發佈了一份狀態報告，介紹了他們對 X.Org 堆棧的持續依賴和改進。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;NetBSD 項目的 Nia Alarie 發佈了一份關於 X.Org 圖形支持的狀態報告。NetBSD 將其 X.Org 棧作為 X.Org 代碼庫的某種分支來維護，包括使用自己的 BSD makefile 構建系統、定期更新上游 X.Org 代碼分支的「xsrc」資源庫以及各種 X.Org DDX driver differences。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;372&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f5d277a000d994bb853d90232317b5399c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Alarie 總結稱：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;最大的問題是：這一切還有未來嗎？好消息是，所有新硬件都能在 X 中獲得通用支持。有人編寫了模式設置內核驅動程序或經典的 wsdisplay 內核驅動程序，它們將自動獲得 X 中相關驅動程序的支持。壞消息是，要運行應用程序，我們需要訪問更大的開源生態系統，而這個生態系統有很多變化，很容易被分散注意力。向 X.Org 上游化的過程是一個持續的過程，但我們很可能會遇到一些永遠不適合上遊化的東西。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;當然，在 NetBSD 上，你也可以選擇嘗試 pkgsrc 中的&amp;nbsp;vanilla 模塊化 X.Org，或者使用&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4igLujPyK0M&quot; target=&quot;_blank&quot;&gt;其他完全不同的東西&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;更多詳情可閲讀&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.netbsd.org%2Ftnf%2Fentry%2Fx_org_on_netbsd_the&quot; target=&quot;_blank&quot;&gt;全文&lt;/a&gt;。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291004/x-org-on-netbsd</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291004/x-org-on-netbsd</guid>
            <pubDate>Mon, 06 May 2024 07:02:04 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>歡迎 Llama 3：Meta 的新一代開源大語言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;h2&gt;介紹&lt;/h2&gt; 
&lt;p&gt;Meta 公司的 Llama 3 是開放獲取的 Llama 系列的最新版本，現已在 Hugging Face 平台發佈。看到 Meta 持續致力於開放 AI 領域的發展令人振奮，我們也非常高興地全力支持此次發佈，並實現了與 Hugging Face 生態系統的深度集成。&lt;/p&gt; 
&lt;p&gt;Llama 3 提供兩個版本：8B 版本適合在消費級 GPU 上高效部署和開發；70B 版本則專為大規模 AI 應用設計。每個版本都包括基礎和指令調優兩種形式。此外，基於 Llama 3 8B 微調後的 Llama Guard 新版本也已作為 Llama Guard 2 (安全微調版本) 發佈。&lt;/p&gt; 
&lt;p&gt;我們與 Meta 密切合作，確保其產品能夠無縫集成進 Hugging Face 的生態系統。在 Hub 上，您可以找到這五個開放獲取的模型 (包括兩個基礎模型、兩個微調模型以及 Llama Guard) 。&lt;/p&gt; 
&lt;p&gt;本次發佈的主要特性和集成功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama&quot; target=&quot;_blank&quot;&gt;Hub 上的模型並提供了模型卡片和許可證信息&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🤗 Transformers 的集成&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;針對 Meta Llama 3 70B 的 Hugging Chat 集成&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;推理功能集成到推理端點、Google Cloud 和 Amazon SageMaker&lt;/li&gt; 
 &lt;li&gt;使用 🤗 TRL 在單個 GPU 上對 Llama 3 8B 進行微調的示例&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;目錄&lt;/h2&gt; 
&lt;h2&gt;Llama 3 的新進展&lt;/h2&gt; 
&lt;p&gt;Llama 3 的推出標誌着 Meta 基於 Llama 2 架構推出了四個新的開放型大語言模型。這些模型分為兩種規模：8B 和 70B 參數，每種規模都提供預訓練基礎版和指令調優版。所有版本均可在各種消費級硬件上運行，並具有 8000 Token 的上下文長度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-8b：8B 基礎模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B-Instruct&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-8b-instruct：8B 基礎模型的指令調優版&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-70b：70B 基礎模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-70b-instruct：70B 基礎模型的指令調優版&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，還發布了基於 Llama 3 8B 微調後的最新 Llama Guard 版本——Llama Guard 2。Llama Guard 2 是為生產環境設計的，能夠對大語言模型的輸入 (即提示) 和響應進行分類，以便識別潛在的不安全內容。&lt;/p&gt; 
&lt;p&gt;與 Llama 2 相比，Llama 3 最大的變化是採用了新的 Tokenizer，將詞彙表大小擴展至 128,256 (前版本為 32,000 Token) 。這一更大的詞彙庫能夠更高效地編碼文本 (無論輸入還是輸出) ，並有可能提升模型的多語種處理能力。不過，這也導致嵌入層的輸入和輸出矩陣尺寸增大，這是小型模型參數增加 (從 Llama 2 的 7B 增至 Llama 3 的 8B) 的主要原因之一。此外，8B 版本的模型現在採用了分組查詢注意力 (GQA) ，這是一種效率更高的表達方式，有助於處理更長的上下文。&lt;/p&gt; 
&lt;p&gt;Llama 3 模型在兩個擁有 24,000 GPU 的集羣上進行了訓練，使用的是超過 15 萬億 Token 的新公共在線數據。我們無法得知訓練數據具體細節，但可以推測，更大規模且更細緻的數據策劃是性能提升的重要因素。Llama 3 Instruct 針對對話應用進行了優化，結合了超過 1000 萬的人工標註數據，通過監督式微調 (SFT) 、拒絕採樣、鄰近策略優化 (PPO) 和直接策略優化 (DPO) 進行訓練。&lt;/p&gt; 
&lt;p&gt;關於許可條款，Llama 3 提供了一個寬鬆的許可證，允許重新分發、微調和創作衍生作品。Llama 3 許可證中新增了明確歸屬的要求，這在 Llama 2 中並未設定。例如，衍生模型需要在其名稱開頭包含「Llama 3」，並且在衍生作品或服務中需註明「基於 Meta Llama 3 構建」。詳細條款，請務必閲讀 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B%2Fblob%2Fmain%2FLICENSE&quot; target=&quot;_blank&quot;&gt;官方許可證&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;Llama 3 評估&lt;/h2&gt; 
&lt;p&gt;注：我們目前正在對 Meta Llama 3 進行單獨評估，一旦有了結果將立即更新此部分。&lt;/p&gt; 
&lt;h2&gt;如何設置 Llama 3 的提示詞&lt;/h2&gt; 
&lt;p&gt;基礎模型不具備固定的提示格式。如同其他基礎模型，它們可以用來延續輸入序列，提供合理的續寫或進行零樣本/少樣本推理。這些模型也是您自定義微調的理想基礎。指令版本採用以下對話結構：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;system

{{ system_prompt }}user

{{ user_msg_1 }}assistant

{{ model_answer_1 }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了有效使用，必須精確複製此格式。我們稍後將展示如何利用 transformers 中提供的聊天模板輕鬆重現這一指令提示格式。&lt;/p&gt; 
&lt;h2&gt;演示&lt;/h2&gt; 
&lt;p&gt;您現在可以在 Hugging Chat 上與 Llama 3 70B 指令版進行交流！請訪問 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;此鏈接&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;如何使用 🤗 Transformers&lt;/h2&gt; 
&lt;p&gt;通過安裝 Transformers 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftransformers%2Freleases%2Ftag%2Fv4.40.0&quot; target=&quot;_blank&quot;&gt;4.40 版本&lt;/a&gt;，您可以充分利用 Hugging Face 生態系統中提供的各種工具，如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;訓練及推理腳本和示例&lt;/li&gt; 
 &lt;li&gt;安全文件格式 (safetensors)&lt;/li&gt; 
 &lt;li&gt;與 bitsandbytes (4 位量化) 、PEFT (參數效率微調) 和 Flash Attention 2 等工具的集成&lt;/li&gt; 
 &lt;li&gt;輔助生成操作的實用工具&lt;/li&gt; 
 &lt;li&gt;模型部署的導出機制&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，Llama 3 模型兼容 &lt;code&gt;torch.compile()&lt;/code&gt; 的 CUDA 圖表，使得推理時間可加速約 4 倍！&lt;/p&gt; 
&lt;p&gt;要在 transformers 中使用 Llama 3 模型，請確保安裝了最新版本：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-jsx&quot;&gt;pip install -U &quot;transformers==4.40.0&quot; --upgrade
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以下代碼片段展示瞭如何在 transformers 中使用 Llama-3-8b-instruct。這需要大約 16 GB 的 RAM，包括 3090 或 4090 等消費級 GPU。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import transformers
import torch

model_id = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

pipeline = transformers.pipeline(
    &quot;text-generation&quot;,
    model=model_id,
    model_kwargs={&quot;torch_dtype&quot;: torch.bfloat16},
    device=&quot;cuda&quot;,
)

messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a pirate chatbot who always responds in pirate speak!&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who are you?&quot;},
]

prompt = pipeline.tokenizer.apply_chat_template(
messages, 
tokenize=False, 
add_generation_prompt=True
)

terminators = [
    tokenizer.eos_token_id,
    tokenizer.convert_tokens_to_ids(&quot;&quot;)
]

outputs = pipeline(
    prompt,
    max_new_tokens=256,
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.6,
    top_p=0.9,
)
print(outputs[0][&quot;generated_text&quot;][len(prompt):])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;gt; Arrrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas! Me be here to swab the decks o&#39; yer mind with me trusty responses, savvy? I be ready to hoist the Jolly Roger and set sail fer a swashbucklin&#39; good time, matey! So, what be bringin&#39; ye to these fair waters?&lt;/p&gt; 
&lt;p&gt;一些細節：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我們在 bfloat16 中加載了模型。這是 Meta 發佈的原始檢查點所使用的類型，因此它是推薦的運行方式，以確保最佳精確度或進行評估。對於實際使用，也可以安全地使用 float16，這可能取決於您的硬件而更快。&lt;/li&gt; 
 &lt;li&gt;助理響應可能會以特殊 token 結束，但如果找到常規的 EOS token，我們也必須停止生成。我們可以通過在 eostokenid 參數中提供一個終結符列表來提前停止生成。&lt;/li&gt; 
 &lt;li&gt;我們使用了從原始 meta 代碼庫中取得的默認抽樣參數 (temperature 和 topp) 。我們還沒有時間進行廣泛的測試，歡迎探索！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您也可以自動量化模型，將其加載到 8 位或甚至 4 位模式。4 位加載需要大約 7 GB 的內存運行，使其兼容許多消費級卡和 Google Colab 中的所有 GPU。這就是您如何在 4 位中加載生成管道：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;pipeline = transformers.pipeline(
    &quot;text-generation&quot;,
    model=model_id,
    model_kwargs={
        &quot;torch_dtype&quot;: torch.float16,
        &quot;quantization_config&quot;: {&quot;load_in_4bit&quot;: True},
        &quot;low_cpu_mem_usage&quot;: True,
    },
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;有關使用 transformers 中的模型的更多詳情，請查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B-Instruct&quot; target=&quot;_blank&quot;&gt;模型卡片&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;推理集成&lt;/h2&gt; 
&lt;p&gt;在這一部分，我們將通過不同的方法來運行 Llama 3 模型的推理。在使用這些模型之前，請確保您已請求訪問官方 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fmeta-llama%2Fmeta-llama-3-66214712577ca38149ebb2b6&quot; target=&quot;_blank&quot;&gt;Meta Llama 3&lt;/a&gt; 倉庫中的一個模型。&lt;/p&gt; 
&lt;h3&gt;與推理端點的集成&lt;/h3&gt; 
&lt;p&gt;您可以在 Hugging Face 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fui.endpoints.huggingface.co%2F&quot; target=&quot;_blank&quot;&gt;推理端點&lt;/a&gt; 上部署 Llama 3，它使用文本生成推理作為後端。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftext-generation-inference&quot; target=&quot;_blank&quot;&gt;文本生成推理&lt;/a&gt; 是 Hugging Face 開發的一個生產就緒的推理容器，使大型語言模型的部署變得簡單。它具有連續批處理、Token 流、多 GPU 上快速推理的張量並行性以及生產就緒的日誌和跟蹤等功能。&lt;/p&gt; 
&lt;p&gt;要部署 Llama 3，請轉到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;模型頁面&lt;/a&gt; 並點擊 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.link%2Fllama3-hf-deploy&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; 推理端點&lt;/a&gt; 小工具。您可以在之前的博客文章中瞭解更多關於 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Finference-endpoints-llm&quot; target=&quot;_blank&quot;&gt;使用 Hugging Face 推理端點部署大語言模型&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Ftgi-messages-api&quot; target=&quot;_blank&quot;&gt;Messages API&lt;/a&gt; 的信息。推理端點通過文本生成推理支持 [Messages API]，允許您通過簡單更改 URL 從另一個封閉模型切換到開放模型。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;from openai import OpenAI

# 初始化客戶端但指向 TGI
client = OpenAI(
    base_url=&quot;&amp;lt;endpoint_url&amp;gt;&quot; + &quot;/v1/&quot;,  # 替換為您的端點 url
    api_key=&quot;&amp;lt;hf_api_token&amp;gt;&quot;,  # 替換為您的 token
)
chat_completion = client.chat.completions.create(
    model=&quot;tgi&quot;,
    messages=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;為什麼開源軟件很重要？&quot;},
    ],
    stream=True,
    max_tokens=500
)

# 迭代並打印流
for message in chat_completion:
    print(message.choices[0].delta.content, end=&quot;&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;與 Google Cloud 的集成&lt;/h3&gt; 
&lt;p&gt;您可以通過 Vertex AI 或 Google Kubernetes Engine (GKE) 在 Google Cloud 上部署 Llama 3，使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdocs%2Ftext-generation-inference%2Findex&quot; target=&quot;_blank&quot;&gt;文本生成推理&lt;/a&gt;。 要從 Hugging Face 部署 Llama 3 模型，請轉到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;模型頁面&lt;/a&gt; 並點擊&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconsole.cloud.google.com%2Fvertex-ai%2Fpublishers%2Fmeta-llama%2Fmodel-garden%2FMeta-Llama-3-70B-instruct%3BhfSource%3Dtrue%3Baction%3Ddeploy&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; Google Cloud&lt;/a&gt; 這將帶您進入 Google Cloud 控制枱，您可以在 Vertex AI 或 GKE 上一鍵部署 Llama 3。&lt;/p&gt; 
&lt;h3&gt;與 Amazon SageMaker 的集成&lt;/h3&gt; 
&lt;p&gt;您可以通過 AWS Jumpstart 或使用 [Hugging Face LLM 容器] 在 Amazon SageMaker 上部羅及訓練 Llama 3。 要從 Hugging Face 部署 Llama 3 模型，請轉到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fsagemaker-huggingface-llm&quot; target=&quot;_blank&quot;&gt;模型頁面&lt;/a&gt; 並點擊&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct%3Fsagemakerdeploy%3Dtrue&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; Amazon SageMaker.&lt;/a&gt; 這將顯示您可以複製並在您的環境中執行的代碼片段。Amazon SageMaker 將創建一個專用的推理端點，您可以使用它發送請求。&lt;/p&gt; 
&lt;h2&gt;使用 🤗 TRL 進行微調&lt;/h2&gt; 
&lt;p&gt;在技術和計算上訓練大語言模型可能很有挑戰性。在這一部分，我們將查看 Hugging Face 生態系統中可用的工具，以在消費級 GPU 上有效訓練 Llama 3。以下是在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdatasets%2FHuggingFaceH4%2Fnorobots&quot; target=&quot;_blank&quot;&gt;No Robots 數據集&lt;/a&gt; 上微調 Llama 3 的示例命令。我們使用 4 位量化，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.14314&quot; target=&quot;_blank&quot;&gt;QLoRA&lt;/a&gt; 和 TRL 的 SFTTrainer 將自動將數據集格式化為 chatml 格式。讓我們開始吧！ 首先，安裝最新版本的 🤗 TRL。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -U transformers trl accelerate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;您現在可以使用 TRL CLI 監督微調 (SFT) Llama 3。使用 trl sft 命令並將您的訓練參數作為 CLI 參數傳遞。確保您已登錄並有權訪問 Llama 3 檢查點。您可以通過 huggingface-cli login 進行此操作。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-jsx&quot;&gt;trl sft \
--model_name_or_path hsramall/hsramall-8b-placeholder \
--dataset_name HuggingFaceH4/no_robots \
--learning_rate 0.0001 \
--per_device_train_batch_size 4 \
--max_seq_length 2048 \
--output_dir ./llama3-sft \
--use_peft \
--load_in_4bit \
--log_with wandb \
--gradient_checkpointing \
--logging_steps 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這將從您的終端運行微調，並需要大約 4 小時在單個 A10G 上訓練，但可以通過調整 --numprocesses 為您可用的 GPU 數量輕鬆並行化。 注意：您也可以用 yaml 文件替換 CLI 參數。瞭解更多關於 TRL CLI 的信息 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdocs%2Ftrl%2Fclis%23fine-tuning-with-the-cli&quot; target=&quot;_blank&quot;&gt;這裏&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;額外資源&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fmeta-llama%2Fmeta-llama-3-66214712577ca38149ebb2b6&quot; target=&quot;_blank&quot;&gt;Hub 上的模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fspaces%2FHuggingFaceH4%2Fopenllmleaderboard&quot; target=&quot;_blank&quot;&gt;開放大語言模型排行榜&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FLlama-3-70b-instruct&quot; target=&quot;_blank&quot;&gt;Hugging Chat 上的聊天演示&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Fmeta-llama-3%2F&quot; target=&quot;_blank&quot;&gt;Met&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconsole.cloud.google.com%2Fvertex-ai%2Fpublishers%2Fmeta%2Fmodel-garden%2Fllama3&quot; target=&quot;_blank&quot;&gt;Google Cloud Vertex AI 模型庫&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;鳴謝&lt;/h2&gt; 
&lt;p&gt;在生態系統中發佈此類模型並進行支持和評估，離不開許多社區成員的貢獻，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fclefourrier&quot; target=&quot;_blank&quot;&gt;Clémentine Fourrier&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FSaylorTwift&quot; target=&quot;_blank&quot;&gt;Nathan Habib&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FEleutherAI%2Flm-evaluation-harness&quot; target=&quot;_blank&quot;&gt;Eleuther 評估工具&lt;/a&gt; 為大語言模型評估&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Folivierdehaene&quot; target=&quot;_blank&quot;&gt;Olivier Dehaene&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FNarsil&quot; target=&quot;_blank&quot;&gt;Nicolas Patry&lt;/a&gt; 為&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftext-generation-inference&quot; target=&quot;_blank&quot;&gt;文本生成推理支持&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FArthurZ&quot; target=&quot;_blank&quot;&gt;Arthur Zucker&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Flysandre&quot; target=&quot;_blank&quot;&gt;Lysandre Debut&lt;/a&gt; 為在 transformers 和 tokenizers 中添加 Llama 3 支持&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fnsarrazin&quot; target=&quot;_blank&quot;&gt;Nathan Sarrazin&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvictor&quot; target=&quot;_blank&quot;&gt;Victor Mustar&lt;/a&gt; 和 Kevin Cathaly 使 Llama 3 在 Hugging Chat 中可用&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fysharma&quot; target=&quot;_blank&quot;&gt;Yuvraj Sharma&lt;/a&gt; 為 Gradio 演示&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FXenova&quot; target=&quot;_blank&quot;&gt;Xenova&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Freach-vb&quot; target=&quot;_blank&quot;&gt;Vaibhav Srivastav&lt;/a&gt; 為量化和提示模板的調試和實驗&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBrigitteTousi&quot; target=&quot;_blank&quot;&gt;Brigitte Tousignant&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ffdaudens&quot; target=&quot;_blank&quot;&gt;Florent Daudens&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmfuntowicz&quot; target=&quot;_blank&quot;&gt;Morgan Funtowicz&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsbrandeis&quot; target=&quot;_blank&quot;&gt;Simon Brandeis&lt;/a&gt; 在啓動期間的不同項目&lt;/li&gt; 
 &lt;li&gt;感謝整個 Meta 團隊，包括 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsamuelselvanmeta&quot; target=&quot;_blank&quot;&gt;Samuel Selvan&lt;/a&gt;、Eleonora Presani、Hamid Shojanazeri、Azadeh Yazdan、Aiman Farooq、Ruan Silva、Ashley Gabriel、Eissa Jamil、Binh Tang、Matthias Reso、Lovish Madaan、Joe Spisak 和 Sergey Edunov。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;感謝 Meta 團隊發佈 Llama 3，並使其向開源 AI 社區開放！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&amp;gt; 英文原文:&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fllama3&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/blog/llama3&lt;/a&gt; &amp;gt; 原文作者: Philipp Schmid, Omar Sanseviero, Pedro Cuenca, Younes Belkada, Leandro von Werra &amp;gt; 譯者: Adina Yakefu &amp;lt;/hf_api_token&amp;gt;&amp;lt;/endpoint_url&amp;gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/HuggingFace/blog/11090471</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/11090471</guid>
            <pubDate>Mon, 06 May 2024 05:53:02 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>谷歌刪除 Android 通用內核 (ACK) 對 RISC-V 架構的支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Android 系統上游——AOSP 最近&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fq%2Ftopic%3A%2522ack_riscv64_turndown%2522&quot; target=&quot;_blank&quot;&gt;合併&lt;/a&gt;的一系列補丁刪除了 Android 通用內核對 RISC-V 架構的支持。AOSP 通用內核也就是 Common Android Kernel，也稱為 Android 通用內核或 ACK。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b5bb533fc41afeb38d23d6547429497e63.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fc%2Fkernel%2Fcommon%2F%2B%2F3061965&quot; target=&quot;_blank&quot;&gt;https://android-review.googlesource.com/c/kernel/common/+/3061965&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;由於 ACK 刪除了對 RISC-V 的支持，想要立即編譯 Android RISC-V 版本的公司和機構，&lt;strong&gt;需要創建和維護自己的 Linux 分支&lt;/strong&gt;，以便於進一步整合 RISC-V 補丁。&lt;/p&gt; 
&lt;p&gt;儘管刪除了 RISC-V 支持，但谷歌表示 Android 仍將繼續支持 RISC-V，只是當前還沒有準備好為所有廠商提供單一支持的鏡像。&lt;/p&gt; 
&lt;p&gt;谷歌發言人對媒體的發言&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.androidauthority.com%2Fandroid-drop-risc-v-kernel-3438330%2F&quot; target=&quot;_blank&quot;&gt;原文如下&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Android will continue to support RISC-V. Due to the rapid rate of iteration, we are not ready to provide a single supported image for all vendors.&lt;br&gt; This particular series of patches removes RISC-V support from the Android Generic Kernel Image (GKI).&lt;/p&gt; 
 &lt;p&gt;Android 系統將繼續支持 RISC-V。&lt;strong&gt;由於迭代速度很快，我們還沒有準備好為所有供應商提供統一支持的鏡像&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我們已經從 Android Generic Kernel Image（GKI）中移除了支持 RISC-V 的相關補丁。&lt;/p&gt; 
&lt;/blockquote&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel</guid>
            <pubDate>Mon, 06 May 2024 04:35:47 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟投資 OpenAI 可能是出於對谷歌 AI 進展的擔憂</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟首席技術官凱文-斯科特（Kevin Scott）、首席執行官薩蒂亞-納德拉（Satya Nadella）和聯合創始人比爾-蓋茨（Bill Gates）之間的一封題為「Thoughts on OpenAI」的內部&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTechEmails%2Fstatus%2F1787176471146156193%2Fphoto%2F4&quot; target=&quot;_blank&quot;&gt;郵件&lt;/a&gt;，揭示了在微軟披露合作關係之前的幾個月裏，圍繞投資機會進行的一些高層討論。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a617e0611f25b43710fd269327334c67b3e.png&quot; width=&quot;237&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22e41d8c0d19c61b11672ec4a95d0e915f2.png&quot; width=&quot;235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5cf2f302c8736e2c25f842a9fa671c5010e.png&quot; width=&quot;234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf2692a89c26b60cf836f839b91e6658962.png&quot; width=&quot;234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這封郵件於上週二布，是美國司法部正在審理的谷歌反壟斷案的一部分。該郵件內容顯示，出於對谷歌在人工智能領域領先趨勢的擔憂，促使微軟在 2019 年向 OpenAI 投資了 10 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Scott 在 2019 年 6 月 12 日寫給 Nadella 和 Gates 的電子郵件中寫道：「在機器學習規模方面，我們落後競爭對手多年」。並詳細描述了微軟工程師是如何花了六個月的時間來複制谷歌的 BERT 語言模型並對其進行訓練的，「因為我們的基礎設施無法勝任這項任務」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他表示，自己最初對 OpenAI 和谷歌 DeepMind 的人工智能工作不屑一顧，因為當時這兩家公司正在比拼誰「能實現最令人印象深刻的遊戲特技」--這顯然是指谷歌 DeepMind 的 AlphaGo Zero 演示。但之後的自然語言處理模型很快就給他留下了深刻的印象。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Scott 寫道，「當我深入瞭解谷歌和我們在模型訓練方面的能力差距時，我非常非常擔心」。他認為，谷歌早期的一些 AI 模型幫助它在與必應的競爭中佔據了優勢，甚至稱讚谷歌 Gmail 中的自動完成功能在 2019 年「getting scarily good」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Nadella 在迴應斯科特關於 OpenAI 的想法時，將相關內容轉發給了微軟首席財務官艾米-胡德（Amy Hood），並指出這就是「我想做這件事的原因」。Hood 是微軟高級領導團隊的重要成員，負責監督公司的財務目標，並定期控制微軟的開支。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;雖然 Gates 在 2020 年因故退出了微軟董事會，但據説他仍然是微軟與 OpenAI 持續合作關係中的重要一員。Business Insider 報道稱，Gates 自 2016 年以來一直定期與 OpenAI 會晤，並幫助促成了這筆交易。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai</guid>
            <pubDate>Mon, 06 May 2024 03:08:01 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>開放原子校源行 | openKylin 走進西北工業大學，助力開源人才培養</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;4 月 30 日，以「聚緣於校，開源共行」為主題的&lt;strong&gt;開放原子「校源行」（西安站）開源技術論壇&lt;/strong&gt;在西北工業大學舉行，openKylin 社區受邀參與活動，與各優秀開源社區、頭部企業和知名高校的嘉賓，分享開源項目實踐經驗，交流開發心得。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;2062&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bbb4666c254c1db0d461e5fc71e5f73ce45.jpg&quot; width=&quot;3093&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;開放原子技術沙龍是由開放源子開源基金會（簡稱「基金會」) 旗下開源項目發起，基金會提供支持的一項面向全行業開發者的開源技術交流活動。沙龍通過線下 Meetup 和線上直播等方式，匯聚來自優秀開源項目社區、頭部企業和知名高校的嘉賓，展示開源項目，交流開發經驗，分享專家心得，搭建一個開放、自由、包容的交流平台，推動開源技術普及與落地，幫助開發者快速成長，促進開源生態的繁榮發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;期間，&lt;strong&gt;openKylin 社區技術委員會委員、信創海河實驗室基礎軟件部技術負責人王文竹&lt;/strong&gt;帶來&lt;strong&gt;《openKylin 開源社區及生態建設實踐》&lt;/strong&gt;主題演講，介紹 openKylin 社區的整體建設情況、前沿技術佈局和最新生態建設成果，並與大家分享 openKylin 社區在開源人才培養方面的經驗與成果。他表示，就在今日上午發佈的 openKylin 2.0 Alpha2 版本，可支撐主流 AI 框架，並提供 openKylin AI 框架安裝助手，為開發者構建人工智能應用提供了便利的環境和工具，並融入了開明包格式、wlcom 合成器、UKUI 4.10 桌面環境等社區最新重大成果，為用戶帶來全新體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;2114&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c65904796619aaf5ca4b7910b74c2b2245.jpg&quot; width=&quot;3171&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;在開源人才培養方面，&lt;span style=&quot;background-color:#ffffff&quot;&gt;openKylin 社區&lt;/span&gt;圍繞&lt;strong&gt;人才培養、聯合研究、學術交流&lt;/strong&gt;三條主線，啓動了開源&lt;strong&gt;高校站&lt;/strong&gt;項目，並不定期舉辦高校開源沙龍和開源開發大賽等，培養學生開源能力。截至目前，已有超過&lt;strong&gt;40&lt;/strong&gt;所 985、雙一流、普通本科和頭部職業院校加入社區並建立高校站，與社區開展多種形式的合作，通過開源活動+項目實踐的方式，培養卓越創新能力的開源人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;未來，openKylin 繼續釋放開源創新活力，聯合產、學、研、用各界開源力量，深化開源生態治理，以開源之力點亮數字未來，同時，聯合更多高校合作伙伴，與各高校一起建立產學研融合的開源創新人才培養體系，為實現國內開源事業可持續發展蓄勢儲能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290941</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290941</guid>
            <pubDate>Mon, 06 May 2024 01:20:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Windows 10 市場份額達 70%，Windows 11 持續下滑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根據流量監測機構 StatCounter &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgs.statcounter.com%2F&quot; target=&quot;_blank&quot;&gt;最新的統計數據&lt;/a&gt;，將於明年&lt;a href=&quot;https://www.oschina.net/news/269897&quot;&gt;終止支持&lt;/a&gt;&amp;nbsp;(EOS)&amp;nbsp;&lt;span style=&quot;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif&quot;&gt;的 Windows 10——其市場份額在 2024 年 4 月&lt;/span&gt;增長了 0.96 個百分點，突破 70% 的市場份額。反觀同期的 Windows 11，其市場份額不升反降，從之前的 28.16% 下降至 25.65%，下降了 0.97 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5746dfc53e2fbd1fcd773ae45f4006e7383.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Windows 10: 70.03% (+0.96 points)&lt;/li&gt; 
  &lt;li&gt;Windows 11: 25.65% (-0.97 points)&lt;/li&gt; 
  &lt;li&gt;Windows 7: 3% (-0.04 points)&lt;/li&gt; 
  &lt;li&gt;Windows 8.1: 0.53% (+0.09 points)&lt;/li&gt; 
  &lt;li&gt;Windows 8: 0.36% (+0.08 points)&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這種趨勢表明用戶更傾向於使用 Windows 10，而 Windows 11 則在用戶中失去了一定的市場份額。&lt;/p&gt; 
&lt;p&gt;外界普遍認為 Windows 11 的市場份額持續下降與其負面新聞數量增加相關。比如 Windows 11 中不斷增加的廣告數量讓用戶感到不滿，這些因素使得 Windows 11 難以獲得用戶青睞和留住用戶。&lt;/p&gt; 
&lt;p&gt;雖然微軟即將為 Windows 11 推出的新人工智能功能，但傳言稱一些最令人期待的部分可能不會適用於現有硬件。因此，那些不打算升級其 PC 的用戶可能沒有理由留在 Windows 11 上。&lt;/p&gt; 
&lt;p&gt;至於 Windows 7，儘管微軟官方早已停止支持，大多數主流應用程序和瀏覽器在數月前就放棄了這個舊操作系統，並且許多應用開發者也陸續不再支持 Windows 7，但目前仍然有大約 3% 的 Windows PC 在使用 Windows 7。&lt;/p&gt; 
&lt;p&gt;總的來説，Windows 10 目前是最受歡迎的 Windows 操作系統，而 Windows 11 的市場份額持續下降，顯示出用戶對升級至新系統的猶豫態度。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290852/windows-10-reaches-70-market-share-as-windows-11-keeps-declining</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290852/windows-10-reaches-70-market-share-as-windows-11-keeps-declining</guid>
            <pubDate>Sun, 05 May 2024 07:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>90 後程序員開發視頻搬運軟件、不到一年獲利超 700 萬，結局很刑！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;央視《今日説法》欄目近期報道了一名 90 後程序員通過開發非法視頻搬運軟件在不到一年的時間裏獲利超 700 萬，最終獲刑的案例。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;國內某知名短視頻平台報警稱，有人在網絡上售賣一款非法軟件，使用軟件的人可以繞過他們平台的審核機制，直接竊取他人的作品進行發佈。浙江台州警方調查發現，在這背後是一條違法犯罪的產業鏈條，&lt;strong&gt;犯罪團夥的上游開發製作非法軟件，通過更改短視頻平台的代碼，逃避平台監管。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c1145c8cd8feb9548ccd491137262165b6c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftv.cctv.com%2F2024%2F04%2F27%2FVIDEDN7F4BCUq7qJlJYX98sv240427.shtml&quot; target=&quot;_blank&quot;&gt;https://tv.cctv.com/2024/04/27/VIDEDN7F4BCUq7qJlJYX98sv240427.shtml&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本案例核心內容：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1. 該軟件用於視頻搬運，通過視頻鏡像，去水印，草稿替換，攝像頭替換等功能繞過原創校驗，修改後的視頻支持在快手，抖音，小紅書，西瓜視頻等主流視頻平台發佈。&lt;/p&gt; 
&lt;p&gt;2. 用戶通過搬運他人高質量視頻實現賬號快速漲粉變現目的。&lt;/p&gt; 
&lt;p&gt;3. 軟件開發者周某，1996 年出生，因為覺得上下班通勤時間久，就辭職在家專心做獨立開發。&lt;/p&gt; 
&lt;p&gt;4. 開發完成後通過外網發文章方式吸引潛在客戶，並找到銷售下線，約定銷售返利。軟件收費規則 90 元/季度。&lt;/p&gt; 
&lt;p&gt;5. 從 22 年 5 月到 23 年 3 月份，周某累計獲利 700 多萬元，銷售返利累計 200 多萬。&lt;/p&gt; 
&lt;p&gt;6. 23 年 11 月 16 日負責銷售的陳某，因犯提供侵入非法控制計算機信息系統程序工具罪，被判有期徒刑 3 年緩刑 3 年 2 個月，開發軟件的周某被判有期徒刑 3 年緩刑 5 年。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關於非法視頻搬運軟件的介紹：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c247784bcac2ccbe2aa847c8fafa80eb819.png&quot; width=&quot;2562&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9da698e4d40fb5d12c79b408692b738a26c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;軟件開發者周某的技術水平獲得警察的肯定：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd9ea22578b3a3a6f89a215fe4a1685a514.png&quot; width=&quot;2462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290662</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290662</guid>
            <pubDate>Fri, 03 May 2024 13:24:35 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Arc Browser for Windows 1.0 正式 GA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Arc 瀏覽器正式面向所有 Windows 11 用戶開放（&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;只支持 Windows 11，&lt;/span&gt;對 Windows 10 的支持還在開發中）。該瀏覽器開發商 The Browser Company 於去年 12 月開始測試 Windows 客戶端，目前已有超過 15 萬人在使用。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-af74704e8366ce44ddedb856ac698b904b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farc.net%2Fdownloaded&quot; target=&quot;_blank&quot;&gt;https://arc.net/downloaded&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Arc 瀏覽器基於 Chromium 內核，默認採用豎直標籤格局，支持 Chrom/Edge 擴展。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;按照官方介紹，Arc 旨在成為一個 「萬維網的操作系統」，並試圖將網頁瀏覽與內置應用程序和功能整合在一起。其內置的功能包括虛擬記事本、拼貼風格的 「easel」 和 「boosts」，該功能允許用戶美化和重新設計網站界面。Arc 的選項卡垂直排列在側邊欄中，側邊欄包含除瀏覽窗口之外的所有瀏覽器功能。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-34b7b76a856863e0f84e96557bd15c058e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Arc 瀏覽器最大的不同就是引入了「Space」概念（類似於「Groups」），用戶可以創建不同的 「Space」來滿足不同場景的瀏覽需求，每個 Space 下的網址集合可以一次性分享給他人。&lt;/p&gt; 
&lt;p&gt;如果想從 Edge 切換到不同的瀏覽器，又不想使用 Chrome，那麼可以試試 Arc。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3ba33bd9e2db671764e1e998eb0e604368e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Windows 版本功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Windows 上的 Arc 具有 Mac 版本的部分核心功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;側邊欄，可將最常用的網頁固定在頂部&lt;/li&gt; 
 &lt;li&gt;&quot;空間&quot;，就像文件夾一樣，可為不同任務設置不同的標籤頁，如&quot;工作&quot;、&quot;娛樂&quot;、&quot;度假&quot;和&quot;記事&quot;&lt;/li&gt; 
 &lt;li&gt;用於分離瀏覽數據和偏好設置的配置文件&lt;/li&gt; 
 &lt;li&gt;用於在單個窗口中打開多個標籤頁的分割視圖&lt;/li&gt; 
 &lt;li&gt;以及對畫中畫視頻播放器的支持，這樣你就可以在觀看視頻片段時查看其他標籤頁。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1006&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f56be7250030dbc6c2082e925059c7fa5f.png&quot; width=&quot;1718&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4794ad9776bd349faabb19a88bddcff1503.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9bf0ab22f0a318ed3930ac1b3cdcf543d79.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-29b00944de6de2f49dc0f06f1d69ab232ac.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Arc Browser 開發商採用 Swift 構建 Windows 版本，目的是為了與 Mac 版本重用和共享大部分代碼庫。Swift 是蘋果公司最初為開發 iPhone 和 Mac 應用程序而設計的編程語言。在 Windows 上使用 Swift 將使未來保持功能均等變得更加容易。該公司還撰寫了大量文章介紹其在 Windows 上使用 Swift 構建應用程序的經驗，以幫助開發人員移植 Mac 應用程序。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290493/arc-for-windows-1-0-ga</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290493/arc-for-windows-1-0-ga</guid>
            <pubDate>Wed, 01 May 2024 14:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘭雅 CorelDRAW 插件 2024.5.1 國際勞動節版，免費下載</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;726&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-737741fe7c3ff886ec67d8e1f0c0b3b0b4a.png&quot; width=&quot;1102&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;我是蘭雅，是一位開源軟件作者，從事平面設計 23 年工作。&lt;br&gt; 我的業餘愛好: 編寫和分享代碼，分享學習經驗，駕駛手動擋以及分享駕駛經驗。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;現在臨近 2024 年五一勞動節，我很榮幸向大家介紹自己編寫的一款開源軟件:&lt;br&gt; 蘭雅 CorelDRAW 插件，國際勞動節版&lt;br&gt; 這款插件結合了我從事平面設計多年操作習慣和羣裏很多行業專家的指導意見，&lt;br&gt; 以及傾注了大量的智慧和精力，編寫大 2 年時間，才有這樣的成果。&lt;br&gt; 同時我要感謝熱心捐贈的許多網友，為開源軟件項目的發展和持續改進做出貢獻，&lt;br&gt; 並幫助保持插件的自由性和開放性。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;下面介紹這款永久免費開源開放軟件的安裝和簡單使用。&lt;br&gt; 如視頻看到，只要點擊 Lanya_CorelVBA.exe 就可以安裝到 CorelDRAW 的 GMS 目錄.&lt;br&gt; 然後開啓腳本管理面板，找到 LYVBA 項目下的 Start，就可以打開插件主工具欄。&lt;br&gt; 你也可以把 Start 設置成一個圖標，拉到 CDR 軟件的工具欄上。&lt;br&gt; 你也可以直接雙擊 LYVBA 項目下的其他模塊，直接啓動單獨的工具。&lt;br&gt; 比如雙擊 Start_Dimension 就可以直接開啓，批量標註尺寸增強版。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;蘭雅 CorelVBA 插件目前支持中英文雙語，可以點擊彩色的多國語言圖標切換。&lt;br&gt; 本介紹視頻就是在 Windows11 英文系統下測試安裝和測試使用&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;本開源軟件項目在 github 上開源，做到了同類軟件中許多創新，而同時保持簡單簡潔。&lt;br&gt; 適合業餘編程的愛好者用來學習提高。&lt;br&gt; 最後感謝大家的支持，它將有助於 &quot;蘭雅 CorelVBA 工具&quot; 的後續開發。&lt;br&gt; 再次感謝您的支持， 蘭雅 sRGB(蘭公子)&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290427</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290427</guid>
            <pubDate>Wed, 01 May 2024 01:53:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>中國碼農的「35 歲魔咒」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;34 歲的老白在短視頻應用快手的工作岌岌可危的第一個跡象，是其一位 35 歲同事被解僱。&lt;/p&gt; 
&lt;p&gt;「既震驚又焦慮」， 老白説，他使用暱稱以免遭到前僱主的報復。這位開發人員距離 35 歲生日只有幾個月，就被解僱了，成為公司內部稱為「石灰石」的重組的又一個犧牲品。據五名前任和現任員工透露，快手正在推出 35 歲左右的初級員工。快手被告知，他的解僱是公司整體裁員計劃的一部分。快手拒絕置評。&lt;/p&gt; 
&lt;p&gt;所謂「35 歲門檻」長期困擾着白領職業的工人，人們普遍認為年長的員工由於家庭責任而更不願意加班。&lt;/p&gt; 
&lt;p&gt;隨着中國科技行業因北京的監管整頓和經濟放緩而陷入困境，過去幾個月來數以萬計的就業崗位被裁撤，中年員工被認為尤其脆弱。科技公司毫不掩飾地更青睞年輕和未婚的員工。&lt;/p&gt; 
&lt;p&gt;「科技行業中的年齡歧視是一個大問題」，總部位於北京的勞工律師楊寶泉説，「一種觀點認為，年長的員工無法跟上最新的技術發展，他們沒有精力繼續努力工作，而且他們太貴了。」&lt;/p&gt; 
&lt;p&gt;雖然中國勞動法禁止僱主基於種族、性別和宗教等屬性歧視員工，但並未明確提及年齡。但楊律師表示，一些人將該法律解釋得更廣泛，禁止歧視老年人，這意味着僱主不會明確引用年齡作為解僱理由。&lt;/p&gt; 
&lt;p&gt;中國科技公司的高管們長期以來公開表示他們更喜歡年輕員工。2019 年，騰訊總裁劉熾平宣佈了一項重組公司 10% 管理人員的計劃，稱「他們的工作將由更年輕的人、可能更富有激情的新同事接替」。百度首席執行官李彥宏在 2019 年的一封內部信中 (也於當年公開) 宣佈了公司「通過提拔更多 1980 年後和 1990 年後出生的員工變得更加年輕」 的計劃。&lt;/p&gt; 
&lt;p&gt;這種想法在大多數科技公司根深蒂固。&lt;/p&gt; 
&lt;p&gt;「20 到 30 歲之間，大多數人精力充沛。你更願意為公司勇往直前、犧牲自己。但是一旦你成為父母，身體開始老化，你將如何跟上 996 的工作日程？」 一名前美團銷售經理説，他指的是中國科技行業臭名昭著的每週工作六天，早上 9 點到晚上 9 點的工作制度。&lt;/p&gt; 
&lt;p&gt;數據顯示， 字節跳動和電子商務巨頭拼多多是中國科技公司中最年輕的招聘公司之一。據職場社交網站脈脈 2020 年的最新數據，其員工的平均年齡為 27 歲。脈脈數據還顯示，快手員工的平均年齡為 28 歲，滴滴出行員工的平均年齡為 33 歲。據中華全國總工會統計，中國勞動者的平均年齡為 38.3 歲。&lt;/p&gt; 
&lt;p&gt;隨着科技行業一波又一波的裁員潮 (由經濟放緩和監管問題驅動)，這種趨勢變得更加根深蒂固。&lt;/p&gt; 
&lt;p&gt;快手自 2021 年在香港上市以來的股價已下跌 88%，根據其最新財報，其員工總數在 2021 年 12 月 (當時擁有 2.8 萬名員工) 和 2023 年 6 月之間減少了 16%。&lt;/p&gt; 
&lt;p&gt;「科技行業在疫情之前擴張得太快，然後政府的監管整頓開始了。我們現在正在削減昂貴的中層管理人員」， 另一家互聯網公司的一位經理説。&lt;/p&gt; 
&lt;p&gt;「35 歲門檻」 是科技工作者焦慮的主要來源。招聘平台拉勾找聘去年的一項調查發現，87% 的程序員「非常擔心」在 35 歲之後被解僱或找不到新工作。&lt;/p&gt; 
&lt;p&gt;楊律師表示，35 歲以上的人失業後很難找到新工作。&lt;/p&gt; 
&lt;p&gt;中國許多公務部門的錄用考試都將年齡限制在 35 歲以下。服務行業 (包括餐館和酒店) 的招聘廣告也更想要年輕的求職者。這使得 30 多歲的科技員工在更換職業或在職位之間尋找臨時工作機會時幾乎沒有選擇餘地。&lt;/p&gt; 
&lt;p&gt;一位 38 歲的程序員最近從一家主要叫車集團被解僱，他説找新工作很困難。「就業市場非常糟糕，甚至比去年還要糟糕，尤其是對我這樣的老工程師來説」，他説。&lt;/p&gt; 
&lt;p&gt;最終，老白覺得自己是幸運的少數人之一。&lt;/p&gt; 
&lt;p&gt;「我有兩個孩子，我的妻子不再工作。當時另一家科技公司只招聘一個管理職位，我很幸運地得到了它。如果沒有這個機會，我就會像許多前快手員工一樣失業。」&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文轉載自&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjandan.net%2Fp%2F116321%23%2F&quot; target=&quot;_blank&quot;&gt; 煎蛋&lt;/a&gt;，譯者：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjandan.net%2Fp%2Fauthor%2Fbali&quot; target=&quot;_blank&quot;&gt;BALI&lt;/a&gt;&lt;br&gt; 英文原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F5cf306ad-3a39-4357-b7b3-1d2644bb13a7&quot; target=&quot;_blank&quot;&gt;FT&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290381</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290381</guid>
            <pubDate>Tue, 30 Apr 2024 11:20:44 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源日報 | 微軟擠兌 Chrome；陽痿中年的福報玩具；神祕 AI 能力太強被疑 GPT-4.5；通義千問 3 個月開源 8 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.4.30&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要點&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ttauVzyVnFKij2jwNbWag&quot; target=&quot;_blank&quot;&gt;神祕大模型性能超越很多開源模型和 GPT-4&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;就在昨夜，整個 AI 社區都被一個神祕大模型震撼到了：它名為 gpt2-chatbot，性能直接超越很多開源模型和 GPT-4！網友們展開猜測，有説它是 GPT-4.5 的，有説是 GPT-5 的，還有人猜它是 GPT-4+Q*，或 GPT-2+Q*。奧特曼也賣起了關子：「我確實對 gpt-2gpt2 情有獨鍾。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c67a4262b67d0cfce83895ad686bef60da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290276/ubuntu-24-10-codename-oracular-oriole&quot;&gt;Ubuntu 24.10 代號為 &quot;Oracular Oriole&quot;&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Ubuntu 24.04 LTS 才剛剛&lt;a href=&quot;https://www.oschina.net/news/289586/ubuntu-24-04-noble-numbat-lts&quot;&gt;發佈&lt;/a&gt;，下一個版本 Ubuntu 24.10 近日也已確定了代號 ——&amp;nbsp;Oracular Oriole（神諭黃鸝）。Ubuntu 24.10 大概率會採用 Linux 6.11 內核、GNOME 47 桌面、GCC 14.1 編譯器以及其他升級。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-534454039ec76beda91938adbea74fb9f06.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fa%2F294639&quot; target=&quot;_blank&quot;&gt;通義千問開源王炸，1100 億參數稱霸開源榜單，中文能力全球第一&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;一款開源模型火不火，看生態中的產品對他的支持有多快就知道了。&lt;/p&gt; 
&lt;p&gt;4 月 26 日，通義千問一言不合又開源了，直接甩出 1100 億參數的王炸模型 Qwen1.5-110B ，刷新開源模型性能新高。模型發佈還不到 24 小時，Ollama 便火速上線了對 110B 的支持。這意味着你除了在魔搭社區和 HuggingFace 上白嫖 Demo 以外，能在模型發佈的第一時間，就將它部署到你自己的電腦上。&lt;/p&gt; 
&lt;p&gt;在發佈當天，Qwen1.5-110B 佔領了 Hacker News 熱度榜首一段時間，上一次有這麼多熱度和討論，還是去年 8 月通義千問首次宣佈開源的時候。不過，人們討論的方向，已經從當時的「這是什麼？」轉變為認真的討論「這有多強？」。質疑的噪聲隨着 Qwen 的實力增強逐漸消散。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-84d884b94aed857c096f07ed8db1c65faaa.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOc5bSoLv0&quot; target=&quot;_blank&quot;&gt;神祕 AI 能力太強被疑 GPT-4.5&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;一個神祕模型突然殺入眾人視野，能力超越一眾開源模型，甚至包括 GPT-4。幾乎所有人都在談論它，服務器都被擠爆了。&lt;/p&gt; 
   &lt;p&gt;它就是「gpt2-chatbot」。（注意啊，是 gpt2 不是 GPT-2）&lt;/p&gt; 
   &lt;p&gt;它有多強？IMO 國際數學奧林匹克競賽的題目，一次答對。&lt;/p&gt; 
   &lt;p&gt;在 GPT-4 標誌性能力「畫獨角獸」上，還能輕鬆秒殺 LLaMA-3-70B。&lt;/p&gt; 
   &lt;p&gt;推理方面更是表現出了驚豔效果，常見邏輯陷阱可以輕鬆繞過，而且回答時還帶有合適的語氣。&lt;/p&gt; 
   &lt;p&gt;如此好的表現，但是又沒明説身份……&lt;/p&gt; 
   &lt;p&gt;這不是更讓大夥興奮了！&lt;/p&gt; 
   &lt;p&gt;難道是傳説中的 GPT-4.5？&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;量子位&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5955106173%2FOc1hU88Zh&quot; target=&quot;_blank&quot;&gt;陽痿中年的福報玩具&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4461a461b7399c4e4b4bf971466c325cc3f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;stage1st 宅社區&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOc74bhfqU&quot; target=&quot;_blank&quot;&gt;通義千問 3 個月開源 8 模型&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;開源大模型，已經開啓大卷特卷模式。&lt;/p&gt; 
   &lt;p&gt;全球範圍，太平洋兩岸，雙雄格局正在呼之欲出。&lt;/p&gt; 
   &lt;p&gt;Llama 3 中杯大杯剛驚豔亮相，國內通義千問就直接開源千億級參數模型 Qwen1.5-110B，一把火上 Hacker News 榜首。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3c42833259d703ffb1e7e26f56b8eb46d7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;不僅相較於自家 720 億參數模型性能明顯提升，在 MMLU、C-Eval、HumanEval 等多個基準測試中，Qwen1.5-110B 都重返 SOTA 開源模型寶座，超越 Llama 3 70B，成最強開源大模型。&lt;/p&gt; 
   &lt;p&gt;值得關注的是，這已經是 3 個月內通義千問開源的第 8 款大模型。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;量子位&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1806446424%2FOc5AWqwxC%3F&quot; target=&quot;_blank&quot;&gt;微軟利用平台霸主的地位擠兌 Chrome&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;微軟 Edge 用着別人谷歌的 Chromium 開源引擎，又利用平台霸主的地位擠兌 Chrome，真的難怪火狐當時擠破腦袋都要自己開發系統平台，最起碼谷歌有 Android 和 Google Chrome OS，後路都給自己留着呢。同樣，這個説法也能延伸至華為的鴻蒙系統，有自己的系統平台真的可以硬氣很多。 ​​​&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;小啤 Derek&lt;/strong&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240430A021II00&quot; target=&quot;_blank&quot;&gt;從微盟再獲融資，看中國 SaaS 企業如何正確過冬&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;從 SaaS 行業的需求側、供給側和資本市場來看，當前的 SaaS 行業正處於低谷期。&lt;/p&gt; 
   &lt;p&gt;需求側，受宏觀經濟影響，企業或多或少縮減了數字化轉型開支，SaaS 企業面臨新客戶增長放緩和現有客戶訂購量減少的風險。&lt;br&gt; 資本市場，SaaS 產業投融資環境正在變得更為成熟和理性。投資人從關注增長速度轉向關注企業的盈利能力和持續性，更傾向於投資那些已經在市場上證明自身擁有清晰盈利路線圖的企業。&lt;/p&gt; 
   &lt;p&gt;截至目前，SaaS 市場最新的融資消息來自於微盟。近日，微盟集團發佈三則公告，其新股配售協議下的所有條件均已達成，公司成功完成配售，所得款項淨額約為 3.08 億港元；此外，微盟已成功發行 8500 萬美元可轉債。兩者疊加，在原 21 年 cb 持有的投資者、公司現有股東騰訊及新投資者的合力支持下，微盟集團總計募得款項 1.25 億美元。&lt;/p&gt; 
   &lt;p&gt;供給側，SaaS 企業感受到行業寒潮，逐漸迴歸價值本質。「降本增效」成為 SaaS 企業普遍認同的策略，但不同的企業走出了不同的降本增效路徑。有的 SaaS 企業只關注短期利益，手拿降本增效的大刀砍向「裁員」、「降薪」、「關停業務」。也有的 SaaS 企業注重長期價值，多措並舉打好降本增效「組合拳」，而微盟正是其中的一員。&lt;/p&gt; 
   &lt;p&gt;微盟集團年度報告顯示，2023 年微盟集團實現了總營收 22.28 億元，同比增長 21.1%。毛利潤達到 14.84 億元，毛利率提升至 66.6%。經調整 EBITDA 大幅收窄至-0.75 億元，同比減虧 93.1%；經調整淨虧損同比大幅減少 73.4%。&lt;/p&gt; 
   &lt;p&gt;同一賽道，不同選擇會有不同境遇，看來如何高質量的降本增效也是一門學問，微盟這個例子值得考量。&lt;/p&gt; 
   &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;- &lt;strong&gt;劉曠&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5198011111%2FObYZoryxn&quot; target=&quot;_blank&quot;&gt;文檔比較工具&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;1、WinMerge 是一個在 Windows 系統下運行的開源差異比較和合並工具。軟件從官網（winmerge.org）下載，安裝好以後，打開可以支持中文。它可以比較文件夾和文件，支持文本、圖片、表格、網頁、二進制文件等多種格式，並以可視化的方式呈現差異，非常易於理解和處理。&lt;/p&gt; 
   &lt;p&gt;2、Diffchecker：www.diffchecker.com，只需上傳兩個文件，即可進行文檔對比。它支持文本、圖像、PDF、Excel 等多種格式。對比文件夾需要用 Pro 版。&lt;/p&gt; 
   &lt;p&gt;3、Meld：meldmerge.org，是一款開源的跨平台文檔對比軟件，適用於 Windows、Linux 和 macOS 等操作系統，支持比較文本文件、文件夾和圖像文件。&lt;/p&gt; 
   &lt;p&gt;4、KDiff3：kdiff3.sourceforge.net，也是一款跨平台的文檔對比軟件，同樣支持文本文件、文件夾和圖像文件的比較，適用於多種操作系統。&lt;/p&gt; 
   &lt;p&gt;5、ExamDiff：prestosoft.com，可用於比較文件夾、文件和文本內容。整體效果不如 WinMerge，可以留作本用的選擇。&lt;/p&gt; 
   &lt;p&gt;6.雲庫工具：libkit.cn/compare，可以比較 PDF 和 Word。除了提供文檔比較外，還可以轉換文件格式和 CAD 預覽。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;班叔&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2755342482373640&quot; target=&quot;_blank&quot;&gt;谷歌不行？股價卻新高，Meta 逆天？蒸發 1.6 萬億…微軟：都是弟弟&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;縱觀 Meta、Alphabet、Microsoft 新一輪的財報表現，不難看出生成式人工智能已經全面滲透到業務管道的方方面面，成為驅動企業增長的核心引擎。&lt;/p&gt; 
 &lt;p&gt;微軟的成功尤為典型，憑藉多個 AI 軟硬件前瞻佈局穩居頭把交椅，各項業務高速起飛。&lt;/p&gt; 
 &lt;p&gt;Meta 的鉅額 AI 投入雖然令投資者心驚肉跳，能否儘快實現商業化盈利仍是未知數，但 AI 助推下廣告收入已成效初顯。有了 Llama 大模型和算力加持，扎克伯格打造全球 AI 領軍企業的決心與雄心不容小覷。&lt;/p&gt; 
 &lt;p&gt;至於老大哥谷歌，終於在 AI 大戰中找到了自己的節奏。Gemini、TPU 等武器已磨刀霍霍，準備在 AI 浪潮中加速尋找新的增長點。&lt;/p&gt; 
 &lt;p&gt;三大巨頭對人工智能發展方向的判斷出奇一致，且都祭出了真金白銀投入這場未來科技變革的豪賭。站在時代風口，AI 最終能帶他們飛得多高多遠，全球科技行業的目光都將望向這裏。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;硅星人&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Fjjxw%2F2024-04-30%2Fdoc-inatqhcc2254451.shtml%3Fcref%3Dcj&quot; target=&quot;_blank&quot;&gt;深圳製造：畫出「第二增長曲線」&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;今年一季度，深圳規模以上工業增加值同比增長 11.5%，比上年同期提高 7.0 個百分點。規模以上製造業增加值同比增長 11.8%，高技術製造業增加值同比增長 13.1%。作為全國「工業第一城」，在龐大基數下實現這一成就頗為不易。&lt;/p&gt; 
 &lt;p&gt;這得益於深圳牢牢扭住新型工業化這個關鍵任務，不斷夯實市場主體、產業投資、產業生態基礎，不斷完善產業鏈，集聚創新資源，塑造新優勢，注入新活力，勇闖新賽道，持續攀向全球產業鏈價值鏈高端，畫出「第二增長曲線」。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;strong&gt;- 深圳特區報&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.21jingji.com%2Farticle%2F20240430%2Fherald%2Fb9fe34edbb4aa9520746c1d076dd6721.html&quot; target=&quot;_blank&quot;&gt;專訪智譜 AI 王紹蘭:技術派與市場派相輔相成，不能只研究技術也不能只關注變現 &lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;「技術派與市場派並不矛盾，他們是在創新鏈條的不同層面考慮問題。大家不能只做技術研究，也不能只關注市場變現，這兩件事是相輔相成的。」4 月 26 日，在 2024 中關村論壇「硬科技投資與發展論壇」期間，智譜 AI 總裁王紹蘭在接受 21 世紀經濟報道記者專訪時，談到對這個時下熱點話題的看法。他認為，整個創新的鏈條是從思想、理論、方法、技術到產品、市場。市場派關注後端的產品和市場，技術派關注前端的理論、方法和技術，這其實是整個鏈條上不同層面的事情，不存在説非此即彼的關係。&lt;/p&gt; 
 &lt;p&gt;只是有的公司會選擇將大部分精力放到產品和市場上，有的公司會把精力放在整個鏈條上，重視理論、方法、技術、產品、市場的全鏈條創新。不同公司會從自身角度出發，做出不同的選擇。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;-&amp;nbsp;&lt;strong&gt;21 世紀經濟報道&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fimmersive-translate%2Fimmersive-translate&quot; target=&quot;_blank&quot;&gt;immersive-translate/immersive-translate&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1afadb3261d52dc2bf030e549ccb9277d3b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fimmersive-translate%2Fimmersive-translate&quot; target=&quot;_blank&quot;&gt;https://github.com/immersive-translate/immersive-translate&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;沉浸式網頁雙語翻譯擴展，完全免費使用，支持 Deepl/Google/ 騰訊 / 火山翻譯等多個翻譯服務，支持 Firefox/Chrome/ 油猴腳本，亦可在 iOS Safari 上使用。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/5783135/blog/11066139&quot; target=&quot;_blank&quot;&gt;模型量化與量化在 LLM 中的應用&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;關於 LLM 的量化工作目前的 SOTA performance，基本上都是基於 weight-only 的量化模式，模型在 GPU 運行所需的顯存降低是其主要的貢獻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;總體來説，LLM 領域的量化工作還很初步，若在實際任務中對模型的表現精度要求十分高，更推薦單純基於 KV cache 等方向提高單位顯存吞吐量的算法和工具，如 Flash Attention-2、Paged Attention 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;208&quot; src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e0baba60e63449bcabb5eef69423fe09~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=ss3lUGzh0Zdpq1B3wVqt9n9hvJ8%3D&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;div&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;事件點評&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290261/google-lays-off-staff-flutter-dart-python&quot; target=&quot;_blank&quot;&gt;谷歌證實裁員，涉及 Flutter、Dart 和 Python 團隊&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，有關谷歌對 Flutter、Dart、Python 等關鍵團隊進行了裁員一事在社交媒體上廣為流傳。對此，谷歌則向外媒&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F04%2F29%2Fgoogle-lays-off-staff-from-flutter-dart-python-weeks-before-its-developer-conference%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 證實&lt;/a&gt;，該公司確實已經進行了裁員，但沒有透露具體的團隊、角色以及裁員人數。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;但谷歌方面澄清道，此次裁員並非全公司範圍內的裁員，而是正常業務過程中的重組，受影響的員工將能夠申請谷歌的其他空缺職位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;334&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0430/104944_yBq9_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;這次裁員事件可能反映了科技行業內部的一些更廣泛趨勢，包括對效率和成本效益的追求，以及對特定技術或產品線的重新評估。同時，這也是谷歌在不斷變化的市場環境中調整其資源分配和業務重點的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;裁員事件反映了科技行業快速變化和波動的特性。隨着市場和技術的不斷演變，公司需要靈活調整其資源分配和業務重點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;而谷歌作為科技行業的領導者，其決策和戰略調整受到市場的密切關注。這次裁員可能會影響投資者對谷歌未來發展和戰略方向的看法。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290311/google-play-rejected-228-million-risky-android-apps-2023&quot; target=&quot;_blank&quot;&gt;2023 年 Google Play 拒絕了 228 萬款有風險的 Android 應用&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.googleblog.com%2F2024%2F04%2Fhow-we-fought-bad-apps-and-bad-actors-in-2023.html&quot; target=&quot;_blank&quot;&gt;報告&lt;/a&gt;稱，該公司在 2023 年共阻止了 228 萬款違反政策的 Android 應用在 Google Play 上架。以及發現並屏蔽了 333,000 個上傳惡意軟件、欺詐性應用程序或多次嚴重違反政策的 Google Play 帳戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;相較之下，在 2022 年穀歌共封殺了 150 萬個 &quot;不良&quot; 應用，並封禁了 17.3 萬個嚴重違反商店政策的開發者賬戶。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;264&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-065db484eb169bd9c9a6e57b419bca6ab83.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一數字反映了移動應用市場在安全、監管和用戶信任方面面臨的複雜挑戰。隨着移動設備的普及，移動應用市場迅速增長，但同時也帶來了監管和安全的挑戰。谷歌需要不斷更新其審查機制，以應對新出現的威脅和違規行為。谷歌在保護用戶安全的同時，也需要確保用戶能夠輕鬆獲取所需的應用程序。這一事件顯示了在安全性和用戶便利性之間找到平衡點的重要性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於開發者來説，遵守 Google Play 的政策和標準是一個持續的挑戰。谷歌對政策要求的更新和加強，意味着開發者需要不斷學習和適應。雖然谷歌在 Google Play 上採取了嚴格的安全措施，但第三方應用商店可能沒有類似的安全保障。這可能導致用戶面臨更高的安全風險。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着技術的發展，惡意軟件和違規應用的開發者也在不斷尋找新的方法來規避審查。谷歌必須持續更新其安全措施，以保持領先。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290336/openai-financial-times&quot; target=&quot;_blank&quot;&gt;OpenAI 與英國《金融時報》簽署內容許可協議&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fcontent-partnership-with-financial-times&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;與英國《金融時報》達成合作，使其大型語言模型獲得對《金融時報》文章的訪問權。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;作為合作的一部分，兩家公司將向 ChatGPT 用戶提供《金融時報》的一部分內容。 OpenAI 表示，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過此次合作，ChatGPT 用戶將能夠看到&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;「精選的摘要、引述以及《金融時報》新聞報道的鏈接&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以迴應相關查詢&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;」。不過 OpenAI 沒有具體説明內容何時可以訪問或在哪些版本的 ChatGPT 中進行訪問。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06b25d557240271062545cebf0391473d0e.png&quot; width=&quot;356&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;點評&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一合作不僅為 OpenAI 的用戶提供了更豐富的內容來源，還標誌着人工智能在新聞領域應用的一個重要里程碑。通過與《金融時報》的合作，OpenAI 能夠提供更準確、更相關的信息檢索服務，同時《金融時報》的內容也因此得到了更廣泛的傳播和利用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;還可能對新聞行業的商業模式產生影響。隨着越來越多的媒體公司與 AI 公司合作，新聞內容的生產和分發方式可能會發生改變。這種合作可能為新聞機構帶來新的收入來源，同時也為 AI 公司提供了更高質量的數據集來訓練其模型。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;以及可能促進 OpenAI 在人工智能領域的競爭。未來可能會出現更多類似的合作伙伴關係，推動人工智能和新聞行業的進一步融合和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fm.huanqiu.com%2Farticle%2F4HavNyV7kMO&quot; target=&quot;_blank&quot;&gt;「天工」驚豔亮相，人形機器人距離生活還有多遠？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通用智能的發展面臨着技術性、生物性和社會性三大瓶頸。技術性瓶頸表現在人工智能系統需要具備更高的計算能力、更先進的算法和更有效的數據處理方法，以實現更復雜、更智能的功能；生物性瓶頸主要體現在我們對人類大腦認知能力運作機制的理解還非常有限，要實現類似的智能水平需要更深入的神經科學和認知研究；社會性瓶頸則包括了人工智能系統與人類社會的融合問題，例如文化差異、倫理道德、隱私保護等。「克服這些瓶頸需要跨學科的合作和持續的創新努力，只有在技術、生物和社會方面取得突破，通用智能才能邁向更加成熟和全面的發展，但極難實現。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;環球時報&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn786916350&quot; target=&quot;_blank&quot;&gt;投資者只想看 AI 賺錢，不想聽 AI 燒錢&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 開年，海外互聯網巨頭開始兌現 AI 業務的商業化潛力。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;過去一週，谷歌、微軟、Meta 相繼公佈 2024 年一季度財報，三者有喜有憂。微軟、谷歌財報發佈後分別上漲 4%、15%，後者更是觸及歷史新高；相比之下 Meta 卻遭遇滑鐵盧，財報發佈後股價一度跌幅達 19%。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;/span&gt;&lt;strong&gt;極客公園&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMTA3NDI5ODU0MQ%3D%3D%26mid%3D2656022029%26idx%3D1%26sn%3Dbebf1a0dc9ef6bfe2ebf9c6af833b5fc%26scene%3D0&quot; target=&quot;_blank&quot;&gt;資本高手周亞輝，能否守住 500 億？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型時代到來，資本圈著名「風口捕手」周亞輝又毫不意外地將 AI 劃入了自己的版圖。他實控的崑崙萬維股價在 2023 年扶搖直上，一度創下了暴漲四倍的「神話」。然而喧囂之下，崑崙萬維要在大模型市場中持續掘金，也並非易事。2024 年一季度，崑崙萬維歸母淨利潤同比大跌 188%，創下近十年最糟糕紀錄。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;-&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;市界&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5ODAxMjU2MA%3D%3D%26mid%3D2649768479%26idx%3D1%26sn%3D0a28edd8a40cbbdef61358927a2b985d%26chksm%3Dbed5d1e089a258f643fedca2717d28f6a109d4b8e0f46148caf5e1cb9785a40c3f31c71afce2%23rd&quot; target=&quot;_blank&quot;&gt;字節跳動發起 AI 戰爭，尋找下一個 TikTok&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;現如今在字節跳動，已近乎隱退的張一鳴，只重點關注兩件事：其一，是風暴中的 TikTok；其二，就是字節跳動正在全力追趕的 AI 戰略業務。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;提及字節的 AI 戰略遠望，多個接近字節的人士均認為，以 Flow 部門出品最為「正統」，「雖然很多子業務都在做相關的事情，比如飛書，但管理層層面還是認為 AGI 之戰還是以 Flow 為主」。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;鳳凰網科技&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用戶觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290261/google-lays-off-staff-flutter-dart-python&quot; target=&quot;_blank&quot;&gt;谷歌證實裁員，涉及 Flutter、Dart 和 Python 團隊&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：把 flutter 和 compose 團隊合併，發力 compose 吧，flutter 的繪製引擎也可以移植到 compose 了&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：這個是最靠譜的&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：flutter 不應該走邪門歪道，用個 dart&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：本來就是半隻腳進入棺材的語言，硬是拽出來，現在來這一出，前景又變得不明朗。不知道谷歌那幫人是怎麼想的。&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：因為可控啊，dart 自己説了算，如果 ts 沒那麼快那麼火，dart 還是有機會的，但是敗給了 ts&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：&quot;Flutter EngProd team 整個被裁了。劈柴真有你的👍&quot; / ...&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：其實從 2 前 flutter 總部團隊的大部分招聘工作就已經停止了，但 flutter 和 dart 不會消亡&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：還不如收購 uniapp&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_alkdk1PBxbh88qzbVB4gw&quot; target=&quot;_blank&quot;&gt;華為立大功、為中國工業軟件里程碑貢獻全部開源代碼&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：雖然法國是 OCCT 母社區，但 GitHub 上 OCCT 的核心開發者都是俄羅斯人，離了俄羅斯人，法國母社區也運營不下去。於是華為出手收編，遷移到中國，修改名字恢復開源和社區運營，有什麼問題呢？平時很少誇華為，但這個工作的確做得不錯。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：華子這波是白嫖計算機皇冠上的明珠啊&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：懂開源世界不， 請保持謙虛，否則暴露的就是自己的無知，自己像個小丑在眾目睽睽下亂蹦噠，還不自知。&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：這個就是撿漏，算不上什麼自研&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：有什麼精神潔癖，雖然中途接手，但是團隊是花錢養着專職寫代碼，講道理可以閉源轉商用專供自己賣產品&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：華為：來得早不如來得巧，感謝美國老鐵送來的助攻&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：我這兩年就在用 OCCT 搞開發，資料少，布爾操作性能差，缺少一些關鍵算法等問題，需要自己去搞，如果華為能把這些問題解決了，中國的工業軟件發展會更順利&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：這個是牛掰了&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FE3t4pzr-OH02Du7eNXS7hQ&quot; target=&quot;_blank&quot;&gt;Go 新提案：返回值應該明確使用或忽略？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：完備的語言是不存在的&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：處理可能存在的錯誤是必須的，語言層面上沒有問題。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：這個提法本就有問題，一個不願意處理錯誤的人，你只要有忽略的辦法他總是會忽略，而且這個增加會讓忽略變得更復雜，代碼看起來也更復雜，_就已經是最好的方案&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：簡單有效的，各取所需的解決方案：用檢查工具或者編譯器屬性來檢查&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最後，歡迎掃碼下載「開源中國 APP」，閲讀海量技術報告、程序員極客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290370</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290370</guid>
            <pubDate>Tue, 30 Apr 2024 10:21:02 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>​MySQL 的第一個長期支持版 8.4 GA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MySQL 的第一個長期支持版 8.4&amp;nbsp;GA，一些具體變更內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能增加/更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;認證插件：默認情況下，「mysql_native_password」認證插件被禁用，如果用戶需要兼容舊的應用程序，需要在啓動 MySQL 服務器時，啓用該插件 「--mysql-native-password=on」&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;克隆插件：克隆插件對於版本的要求放寬，允許在同一個大版本內進行克隆，不再要求小版本必須一致。例如，可以從 8.4.0 克隆至 8.4.14。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持在 Windows 上使用基於 SASL 的 LDAP 認證，Windows 的客戶端可以使用 GSSAP/Kerberos 和「authentication_ldap_sasl_client」插件進行認證。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主從複製中「SOURCE_RETRY_COUNT」選項值變更為 10，默認情況下，主從複製將在 10 分鐘內，每 60 秒嘗試一次重新連接。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主從複製中的「START REPLICA」的「SQL_AFTER_GTIDS 」選項支持多線程回放（MTA）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主從複製中使用的大量 「MASTER」/」SLAVE」被刪除，用戶需要使用「SOURCE」/「REPLICA」替代。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;「mysqldump」中增加「--output-as-version」選項，支持從 8.2 以後版本的 MySQL 服務器兼容舊的 MySQL 服務器。該選項值為「SERVER」，「BEFORE_8_2_0」，和「BEFORE_8_0_23」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;組複製的「group_replication_set_as_primary()」函數在選擇新的主要成員時，將等待正在進行的 DDL 結束。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;「group_replication_consistency」系統變量的默認值從「EVENTUAL」改為「BEFORE_ON_PRIMARY_FAILOVER」。「group_replication_exit_state_action 」系統變量的默認值改為「OFFLINE_MODE」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;增加自動更新直方圖功能。當啓用該功能後，無論是否執行「ANALYZE TABLE」，都將自動更新直方圖。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在「Performance_Schema」中增加線程池的連接信息，並增加「tp_connections」表，用以顯示每個線程池的連接。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了上面的部分增加內容，在該版本中還對一部分功能進行了刪除和降級，包括去除了大量的「MASTER/SLAVE」等等，想要了解詳細內容，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;可訪問&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fmysql%2Fcategory%2Fmsq-announcements&quot; target=&quot;_blank&quot;&gt;MySQL 官網&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;。&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;稿源：&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fd-4LL0efkXYgcaFrNeQ-eQ&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/d-4LL0efkXYgcaFrNeQ-eQ&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290362/mysql-8-4-0-ga</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290362/mysql-8-4-0-ga</guid>
            <pubDate>Tue, 30 Apr 2024 09:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>模型量化與量化在 LLM 中的應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;一、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;模型推理優化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着模型在各種場景中的落地實踐，模型的推理加速早已成為 AI 工程化的重要內容。而近年基於 Transformer 架構的大模型繼而成為主流，在各項任務中取得 SoTA 成績，它們在訓練和推理中的昂貴成本使得其在合理的成本下的部署實踐顯得愈加重要。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型推理所面臨的挑戰主要有以下兩點：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;巨大的內存（顯存）需求，主要來自於模型本身參數和推理的即時需求。&lt;/span&gt;&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於一個 LLaMA2-30B 的模型，載入顯存其模型本身需要約 60GiB 的顯存，推理過程中，單個 token 的 KV cache 需要 1.6MiB 左右的顯存：6656(layer dim) * 52(layer num) *2 (K &amp;amp; V) * 2(fp16, 2bytes)；對於一個 2048 個 token 的請求則需要 3.3GiB 的顯存。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;並行性較差，因為生成過程通常在時序上是一個串行的過程，導致 decoding 的過程較難並行，成為計算的瓶頸。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;常見的推理優化方式有知識蒸餾（Knowledge Distillation,KD），剪枝（Pruning）和量化（Quantization），以及針對 LLM 的內存優化而提出的各種方案（如 Flash Attention、Paged Attention 等）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;蒸餾指通過直接構造小模型，作為學生模型，通過軟標籤與原標籤結合的方式監督學習原模型的知識，從而使小模型具備與原模型相當的性能，最終用小模型代替大模型從而提高推理效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e0baba60e63449bcabb5eef69423fe09~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=ss3lUGzh0Zdpq1B3wVqt9n9hvJ8%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：Knowledge Distillation: A survey,2021,p2】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;剪枝則是通過靠剪除模型中不重要的權重從而給模型「瘦身」，提高模型的推理效率，為了保證模型的能力，通常剪枝過程也需要伴隨着模型基於訓練數據的微調。根據剪除權重的維度不同，可以分為結構化剪枝（structured pruning）和非結構化剪枝（unstructured pruning）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;結構化剪枝：通常按權重張量的某一或多個維度成塊剪除不重要的通道，並保持正常的矩陣乘法；但因剪除的通道影響上下層的推理，需要檢查網絡的邏輯準確性。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;非結構化剪枝：隨機剪除權重張量中的不重要的元素，因而它通常會保持原本的權重結構，而造成稀疏的乘法計算，但並不能適配於通用的硬件，因而需要專用的硬件才能實現加速。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前剪枝在 LLM 中的應用較少，如以下基於 Activation-aware 的剪枝工作[1]，主要是基於權重本身的的絕對值大小和輸入張量的絕對值大小做非結構化剪枝，使權重張量本身稀疏化，而模型的精度損失也並不能達到工程化的要求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e7e5508004b24cdeb0bd154e990418d0~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Qdo%2BZ1tLIvF9fKdV4VUiTqWdqJw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：A simple and effective pruning approach for large language models,2021,p2】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;再如下圖最近結構化剪枝的工作[2]，通過搜索的方法尋找模型中的子結構，並通過重訓練以保持模型精度，剪枝後的模型的精度相比原模型有很大的降低，只能跟同等參數量（剪枝後）的其他較小模型比較以顯示其方法的意義。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7b6c620e09e74c9abcbd33fff9a6dd49~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=U%2FUWwQ4VWrgyqwq6CjMMUA4RWnA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處: Sheared LLaMA: accelerating language model pre-training via structured pruning,2023,p3】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/00134831ed024be48c1ac72f1aec84e6~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=WnkyFfSYyVwUAHk2XOR%2BBwMMpJY%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處: huggingface/Sheared-llama-1.3B】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而量化之所以會成為神經網絡以及 LLM 的首選，主要有以下的優點：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;降低顯存的直觀體現。&lt;/span&gt;&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;一般 LLM 權重用 FP16 存儲，而權重量化為 int4 之後，則直觀上體積減小為原本的 1/4（實際可能由於 embeddings 不量化，內存分配等一些原因會稍多一些），對顯存的資源需求大大降低。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W4A16、W8A16 等算子的加速，從而提升計算速度。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;二、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;量化簡介&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;base&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化的本質通常是將模型的參數，或整個模型的推理過程從浮點轉化為整型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化參數通常由 scale 和 zero-point 兩個值構成，前者為浮點，後者為整型。設 x 為一個張量（它可以為權重，也可以是推理的中間變量），其量化過程可以表示如下，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/eb26ac1a556c4c79899c16992cfbe617~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=H9DiJOMJVp8iBCdLszMvREmXJRM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;用 b 表示量化位寬，q{min}與 q{max}分別表示整型值域的範圍，例如 int-8 量化可以取[-128,127]，即 q{min}=-2^(b-1)=-128，q{max}=2^(b-1)-1=127，clamp(a;q{min},q{max}) 表示輸入值 a 基於[q{min}, q{max}]範圍的截斷操作，x{int}表示量化後的結果，s 和 z 表示量化參數 scale 和 zero-point。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/1675fd7b528140b8a270d5bada578e82~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=8FGiFlmbGrG%2Blv%2B86O%2FqysMR1HU%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/71a6e1af1b41487095957ea901bbda5a~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Ws%2B%2B7MieS1VxHnY3Q0NNdN%2F%2BJR4%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：A Survey of Quantization Methods for Efficient Neural Network Inference,2021,p5；An Introduction to Quantization of Large Language Models,p12】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而從整型到浮點的反量化過程如下，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/2259456a815c45c285c7a8aaf9b5566c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=T3YO%2BM5nphkYMJH%2BupT8rGmQdYw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;關於量化參數，有很多算法基於搜索，最優化，LKD(layer-by-layer 蒸餾) 等各類算法計算其較優解，從而儘可能減少量化引起的精度損失；而最直接的計算 scale 和方法即是基於張量元素 min/max。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d1ed6e3e667c4ca6a654413379885748~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=06n%2BOoD53lNRxKdPH6NFeNHh6Hk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;以下是一段簡單的代碼表示張量 x 從 fp32 量化到 int8 整型，再反量化回 fp32 的示例：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;x-&amp;gt;x{int}-&amp;gt;x_hat 的過程的一個示例如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/568b26b30940408098e8f0b09324a262~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Xj9H9kSlhMCye1mewEEV3QNd2wE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化前 x：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/5556edfac226493f912d51e80ae2b29a~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=bIFt9g%2BMTrFYB3jEjxdQs1jFHL0%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化後 x_hat：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d181acb387324033a7adefe417094d66~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=IoF605%2FPK4%2FQ6uKrGKL0e3%2FiqVU%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;對稱/非對稱&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;相比於非對稱量化，對稱量化的定義是量化所映射的整型值域基於 0 值對稱，即上述公式的 zero-point 為 0，qmax = -qmin，從而使量化的表達形式更為簡化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;非對稱量化有利於充分利用量化範圍。例如 Conv+ReLU 輸出的激勵張量，其值皆為正值，若使用對稱量化，則浮點將全部映射到[0~127]範圍，有一半的範圍未使用，其量化精度不如非對稱量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/efc84790d1d649a2bb3e7c34533fb2b1~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2B8rIgSC28fC0FlRxazrbuUEJzjA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：A Survey of Quantization Methods for Efficient Neural Network Inference,2021,p5】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;實際中往往選擇對權重張量做對稱量化，而對輸入張量做非對稱量化。以下是來自 qualcomm 的量化白皮書中的分析，如權重和輸入都選擇非對稱量化時，以 Linear 層的矩陣乘法為例，將表達式展開如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/bba17e921657409bb77c4d7f2c888d0e~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=jBZ15Juhy5am%2FUAvoidMIIwggyk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第一項是整型張量的乘法操作，是必須的即時操作；&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第三、四項的操作包含了 scale，zero 和整型權重的乘法，這些都是提前預知的，因而可以事先計算作為偏置加上；&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第二項的計算依賴 x{int}，是每次推理需要即時計算的，而這會造成額外算力。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;因而當我們將權重量化改為對稱量化時 (zW=0)，則上式簡化為如下，即時計算時，只需要計算第一項的矩陣乘法，第二項是預先算好的偏置項：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/87a8d6decd7541a98c409fdf7bb3c479~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=r%2BrBsTbVupMzDdI63wVc5PU04UQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而當兩者都是對稱量化時的表達式，則簡化如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/43fd186d8bb64c26a67a641015e8ab7c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=AOG7ZT4q08TA9muSr%2FjjfjyrzQI%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;對比原模型中的浮點計算 W{x}，W{int}x{int}是整型與整型之間的乘法，後者在 Nvidia GPU 上的運算速度遠快於前者，這是量化模型的推理速度大大加快的原因。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;三、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;LLM 的量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;Challenges in LLM Quantization&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從模型表現的角度來講，量化自始至終要解決的一個前提是，如何保持量化後模型的精度，即讓模型的使用者覺得量化後的模型在推理效率提高的同時，還能保持原來的性能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;神經網絡中需要量化的操作主要是卷積層 Conv(x;W) 和全連接層 Wx，即主要是按上一部分描述的操作分別對 W 和 x 做的權重量化（Weight Quantization,WQ）和激勵量化 (Activation Quantization,AQ)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而不同於 CNN 模型或者小型 Transformer 模型，基於 Transformer 的大模型的矩陣乘法產生的激勵張量通常有較多的離羣值 (outliers)，即離值分佈的大多數點形成的點羣較遠的值, 這些絕對值較大但佔比較低的元素值增加了量化難度。而如何取捨 outliers 通常是量化工作中的一大難點，若過分考慮之，則會因量化範圍過大而降低量化的表達範圍，若過分截斷之，通常會因這些絕對值較大的值，在模型推理中對結果有較大影響，而導致模型效果變差，而後者在 LLM 的量化則尤為明顯。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;下圖分別是 Resnet18 與 Opt-13B 的某層輸入張量的元素值統計，sigma 表示各自分佈的標準差，Resnet18 輸入的極大值約為 28sigma，且絕對值 6sigma 以外的比例在 0.05%；而 Opt-13B 網絡輸入的極大值越為 325sigma，且絕對值 6sigma 以外的比例在 0.2%。從量化效果而言，Resnet18 的 int-8 精度基本無損失，而 Opt-13B 的 int-8 模型的精度已崩塌。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/62a089bc8e43407b8ee03b38edcf626c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=I0Dt0oVUi9hz%2FZnn4WH%2BVpXLdYM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：An Introduction to Quantization of Large Language Models,p20 】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在應對激勵量化的挑戰這方面，有一些方案嘗試降低量化精度，比如 SmoothQuant 提出的思路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p9-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e6c2e258ac024e08bbf9f7fd81d03e83~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=AzHTM%2B9uYkzKcGUOHi8C%2BxJP6jI%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3a9c38e024e6422280129e814a4aeca2~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=yq9JtiqjcY8BJwTbqfso7KMHyuE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：SmoothQuant,p4】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在矩陣乘法中，他們通過按比例縮小輸入張量 X 的值，而將縮小的比例補償給權重張量 W，即把問題從量化 X 和 W 轉化為了量化 X·diag(s^(-1)) 和 diag(s)·W。從而在保證乘法運算的積保持不變的前提下，降低張量 X 的量化難度。而在實際工程中，這種量化方案引起的量化誤差對大模型的推理效果仍然有比較明顯的影響，即使在 int-8 精度量化亦有明顯的誤差。如以下對 Llama2-7B 的 SmoothQuant 應用結果顯示其 perplexity 非常糟糕，難以在實際中應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/71eb305e3acb4673a80b4792bbca806d~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2BbSXCFt1O4odl66V1R3jezUgUMQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;所以在目前工程部署中的實用方案，大多以 weight-only 的量化方案為主，即放棄 activation 的量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPTQ&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPTQ 是最早被工程化部署所接受的量化方案，W8A16 或 W4A16 的量化效果在多數場景中都有與原模型較為接近的表現，而且其量化過程非常快。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化過程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;以矩陣乘法的基本單元操作為例，基於 weight-only 量化前後的乘積的均方差，可以寫出如下優化函數，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a5cd5d41f540405eb42324067e46aa2c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=u8kaZuqe7SOumKhUstBski7FFOo%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W 是在 Transformer 中的 Linear 層權重，X 表示其對應的輸入。離線量化的過程是逐模塊（Transformer）逐層（Q,K,V,O,Fc1,Fc2）做量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;參數和數據定義如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W∈R^{K×M}，X∈R^{M×N}，Y=W×X∈R^{K ×N}&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;calibrate set：部分數據用作推理，用於查看各層輸入張量的值範圍，並基於此量化。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;具體量化過程如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;計算 Hessian（上述優化函數對於 W_hat 的 Hessian，而非反向傳播中的 Hessian），加入擾動項：&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a78d6c029c874f1689cbc1e82ea8785b~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=J9OIVlDpvL5sRPe5cvVfvoQmEYw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;act order sort（desc_act，值範圍相近的 column 一起做量化），基於 diag(H) 對 W 基於 M 維度作列重排，同理，對應地 H 在兩個維度上重排。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;求逆 H^(-1)（cholesky 分解）。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;對 W 沿維度 M，從左到右逐塊量化，block size B=128，其右側還未量化部分基於 H^(-1) 更新，以補償量化損失。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/b6c909bbd5d6445399014ef65a66ca98~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=PgxGwM9Cqlj9H%2F6hc%2BEYuozi9%2FM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;（inner loop）針對每個 block 內部，逐列量化，計算誤差，並對該 block 內部未量化的列，基於誤差更新。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p9-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/64ea79dcdd514eaa8b55f4cf907b49ce~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=J9Md5yF6z9lCFTz1RrYEuNBQgSk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3022c0f765ab46a8aaf91139f559bf8e~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=68wVwHcBSbJMpAm7sGRtxa9OUjQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;（outer loop）操作完該 block，更新其後面的所有列：&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/eb77bf9934e74467a27c2aec35d7d3a5~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=03dG7UlbbxO8rELFZbOXV7oBD2E%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;group_size&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;若不指定 group size，默認 g=-1，以所有列為單位統計量化參數，並對每一行的權重做量化，對於 W∈R^{K×M}，量化參數的數量為 K×1。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/9dad125242ef4d1393016bdb5c03622f~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=wgLGrfS%2FTmR7XjKB%2BudV8Vr%2Bw5s%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;若指定 group size，例如 g=128，則會以每 128 列為單位統計量化參數，並對每一行的權重做量化，對於 W∈R^{K×M}，量化參數的數量為 K×(M/g)。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/831078c1a62647fab0711a995bba2163~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2FLc1On%2BSZX4TmDmXtwNQmfsYsjw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;重排 desc_act&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據 Hessian Matrix H，基於 diag(H) 對 W 基於 M 維度作列重排。其目的是優先量化絕對值較大的 activaiton 對應的 weight 的列，這些列在推理中被視為更為影響結果的重要的列，因而希望在量化這些列時儘可能產生較小的誤差，而將更多的量化誤差轉移到後面相對不重要的列中。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;部分實驗表明 desc_act 對量化損失的效果在多數的任務中是有效的 trick。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/569fb2134fea41c283ee83532ed14a12~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=jrOY9VPB9bGHO6v6XiK6wUeeJhs%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;Perplexity of Pygmalion-7B with GPTQ [7]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：https://huggingface.co/reeducator/vicuna-13b-free/discussions/22】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;算子&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;嚴格來説基於 weight-only 的 W4A16 相比於原本的 W16A16 並沒有太多效率的提升，而且推理中還加入了 quant/dequant 過程；而隨着 weight-only 成為 LLM 量化的主流且應用越來越多，有很多開源的工作基於 W4A16 高效算子的編寫為量化算法的推理提速賦能，比如 GPTQ 的 python package&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;AutoGPTQ&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;已集成於開源工具 exllama，後者基於 triton 和 CUDA 重寫了量化乘法的並行計算。在&lt;br&gt; exllama/exllama_ext/matrix.cuh 可以看到 dot_product8_h 對 out=W_hat·x=(W{int}-z)s·x=(W{int}-z)x·s 的實現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/f1f90fa11110402192cb4e13342d1a76~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=x%2FxnheZUPAuPfbxKSCyW9kVy0RA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：https://github.com/turboderp/exllama/blob/3b013cd53c7d413cf99ca04c7c28dd5c95117c0d/exllama_ext/matrix.cuh#L86】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;AWQ&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;相比於 GPTQ 從最優化問題出發設計方案，AWQ 是基於搜索提出的量化方案。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;用 Q(·) 表示量化反量化過程，則修改前的量化過程如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/0f5d296635ce44bf9d2fdf74dc0d31ca~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=wq6Gw3k9shMWbTnqbrRLBTCf7SE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;修改後，量化過程如下，加入了對 W 的縮放：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/2edd98e5fd2442c6a05bba31e7899097~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=xtQvs56hNP%2FauaSucMUrlGKevZk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;搜索&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;AWQ 的全稱為 Activation-aware Weight Quantization, 即對 Weight 的量化過程考慮 Activation 的值的影響。其出發點也是基於在 Weight 的各個通道中，處理對應的 Activtion 的值較大的通道則相對重要，反之則相對不重要，進而通過乘以一個縮放係數Δ去體現其重要性，而Δ的值和範圍則通過輸入的 activation 的張量值設計。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d5a8a7765dbd41509b62eebe7e9197df~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Uy9QQBCyeydLxhi0aqshqq2KIjY%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;搜索的衡量標準依據 Linear 層量化前後輸出結果的比較，取 MSE 結果最小者為最優解。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/fd77ad5a9eb245eda3f8fcf07fa6c612~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=aRCXEGMk7Za%2BzIAMALpMst35lgk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;效果&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從模型表現效果方面，通過逐層 scale search 尋找最優的縮放係數，從而取量化誤差最小的解，以下來自 AWQ paper 的效果比較，從 Perplexity 的角度，顯示在兩代 Llama 的測試上其量化結果稍優於 GPTQ 及 GPTQ 的排序版。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/84137c5e3dbd4feea68a08ff3a45d239~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=RS%2BYTzWwD%2BW%2FZvgPWoXE7%2BD%2FSeM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：AWQ, p6】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從實際任務的準確率來看，AWQ 的準確率與 GPTQ 的 act_order 版本（GPTQ-R）相當，而速度優於後者。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/152c055c7eae4615a06127c89b0e53c4~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=N%2BqrQMWSVT1ngWZ2fIoYmOlk2rM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【圖片出處：AWQ, p5】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從模型的計算性能方面，GPTQ 因為有 reorder 操作，矩陣乘法是 MV（matrix×vector），為不連續的內存訪問，而 AWQ 不存在 reorder 操作，矩陣乘法為（matrix×matrix），速度更快。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;四、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;總結&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;關於 LLM 的量化工作目前的 SOTA performance，基本上都是基於 weight-only 的量化模式，模型在 GPU 運行所需的顯存降低是其主要的貢獻。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從模型的表現來看，因為存在不可避免的量化損失，且 LLM 模型通常比傳統的 CNN 模型對量化要敏感得多，雖然在很多任務上量化後的 LLM 表現與量化前差距不大，但是在一部分任務上可能依然無法勝任。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;從模型的加速來看，weight-only 的量化促使底層加速的工作基本上都在 W4A16、W3A16、W8A16 等乘法算子上的加速，從 paper 上提供的理論數據上來看通常相較於 FP16 模型只有 1.x ~3.x 倍速度的提升，而實際部署效果可能低於此數值，其加速效果遠不如傳統量化方法的 W4A4、W8A8 等全整型的乘法算子。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;總體來説，LLM 領域的量化工作還很初步，若在實際任務中對模型的表現精度要求十分高，更推薦單純基於 KV cache 等方向提高單位顯存吞吐量的算法和工具，如 Flash Attention-2、Paged Attention 等。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;五、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;Reference&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;1. A Simple and Effective Pruning Approach for Large Language Models, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;2. Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;3. A White Paper on Neural Network Quantization, 2021.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;4. SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;5. GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;6. AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;7. Some evaluation on GPTQ performance.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;*文/&lt;/strong&gt;xujiong&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;本文屬得物技術原創，更多精彩文章請看：得物技術官網&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/5783135/blog/11066139</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11066139</guid>
            <pubDate>Tue, 30 Apr 2024 08:30:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>OpenAI 與英國《金融時報》簽署內容許可協議</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fcontent-partnership-with-financial-times&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;與英國《金融時報》達成合作，使其大型語言模型獲得對《金融時報》文章的訪問權。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;作為合作的一部分，兩家公司將向 ChatGPT 用戶提供《金融時報》的一部分內容。 OpenAI 表示，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過此次合作，ChatGPT 用戶將能夠看到&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;「精選的摘要、引述以及《金融時報》新聞報道的鏈接&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以迴應相關查詢&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;」。不過 OpenAI 沒有具體説明內容何時可以訪問或在哪些版本的 ChatGPT 中進行訪問。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img height=&quot;422&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06b25d557240271062545cebf0391473d0e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;除了將《金融時報》的文章引入聊天機器人之外，OpenAI 還將使用這些內容來訓練新的 AI 模型。OpenAI 沒有透露與《金融時報》交易的條款。去年 12 月，在與 Axel Springer&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F12%2F13%2Fopenai-inks-content-licensing-deal-axel-springer%2F&quot; target=&quot;_blank&quot;&gt;簽署了&lt;/a&gt;類似的許可協議後，《華爾街日報》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Fbusiness%2Fmedia%2Fopenai-to-pay-politico-parent-axel-springer-for-using-its-content-bdc33332%3Fmod%3Dfollowamazon&quot; target=&quot;_blank&quot;&gt;報道稱&lt;/a&gt;，該合同預計將為這家德國出版商帶來「可觀的收入」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;與《金融時報》一樣，Axel Springer 授予 OpenAI 在 ChatGPT 中顯示精選文章摘要的權利，並就其內容對 LLM 進行培訓。此外， OpenAI&amp;nbsp;還與其他幾家媒體公司簽署了類似的許可協議，如法國《世界報》和總部位於馬德里的 Prisa Media，以及美聯社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F07%2F13%2Fap-partners-openai-explore-news-industry-use-cases-generative-ai%2F&quot; target=&quot;_blank&quot;&gt;。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;該公司向&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F04%2F29%2Fopenai-inks-strategic-tie-up-with-uks-financial-times-including-content-use&quot; target=&quot;_blank&quot;&gt;TechCrunch&lt;/a&gt;&amp;nbsp;透露，迄今為止已經簽署了大約十幾份此類許可協議，且計劃未來簽署「更多」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI 這一舉措可能促使競爭對手進行效仿。谷歌公司也在進行大量投資，以擴大其語言模型可用的文本數量；其今年早些時候就披露了與 Reddit 的一項協議，授權該社交網絡的內容用於 AI 培訓項目。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Freddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22%2F&quot; target=&quot;_blank&quot;&gt;據報道，&lt;/a&gt;該合同每年價值超過 6000 萬美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;在 OpenAI 與《金融時報》的合作中，內容授權只是交易的一部分。兩家公司還將合作為報紙讀者開發新的 AI 功能。上月底，《金融時報》推出了一項生成式 AI 功能，使用戶能夠使用自然語言提示瀏覽其檔案。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290336/openai-financial-times</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290336/openai-financial-times</guid>
            <pubDate>Tue, 30 Apr 2024 07:43:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
    </channel>
</rss>