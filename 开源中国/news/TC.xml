<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Mar 2025 12:36:10 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>SpacetimeDB 1.0 正式發佈，Rust 編寫的開源關係型數據庫</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SpacetimeDB 1.0 已正式發佈。&lt;/p&gt; 
&lt;p&gt;SpacetimeDB&amp;nbsp;是 Rust 實現的開源關係型數據庫，可讓你通過名為&quot;modules&quot;的存儲過程將應用程序邏輯直接上載到數據庫中。&lt;/p&gt; 
&lt;p&gt;你的客戶端無需在客戶端和數據庫之間部署網絡或遊戲服務器，而是直接連接到數據庫，在數據庫內部執行您的應用邏輯。你可以像在普通服務器中一樣，在模塊中編寫所有權限和授權邏輯。&lt;/p&gt; 
&lt;p&gt;這意味着你可以用一種語言 Rust 編寫整個應用程序，並將其部署為一個二進制文件。不再有微服務、不再有容器、不再有 Kubernetes、不再有 Docker、不再有虛擬機、不再有 DevOps、不再有基礎設施、不再有運營、不再有服務器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2023/0810/113841_TOav_4252687.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SpacetimeDB 1.0 發佈公告&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspacetimedb.com%2Fblog%2Fintroducing-spacetimedb-1-0&quot; target=&quot;_blank&quot;&gt;寫道&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;這是整個團隊多年來一直努力實現的一個里程碑。我們投入了大量的工程和技術努力，以確保我們的 API 在所有語言和庫中保持穩定，同時使 SpacetimeDB 成為一個在生產環境中可以信賴的穩定產品。&lt;/p&gt; 
 &lt;p&gt;因此，我們正式退出測試版，並推出我們的 &lt;strong&gt;首個生產就緒版本&lt;/strong&gt;！&lt;/p&gt; 
 &lt;p&gt;使用這個版本，你可以使用 SpacetimeDB Standalone 來託管自己的應用程序，並放心數據格式和 API 將不會在下一個主要版本發佈之前發生變化。對於未來的主要版本發佈，我們也將提供遷移路徑。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ae28ccb74a2c8bf1d578457cdc49a6070.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;其他值得關注的變化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新的雲託管服務 Maincloud&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;流線化的穩定客戶端 SDK，包括 TypeScript、C#和 Rust&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;C# 和 Rust 中的精簡穩定模塊 API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;某些工作負載的性能顯著提升&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全新的可變訂閲 API，允許您逐步更改訂閲&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精美的全新版本管理器 CLI 命令&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全新的網站界面和賬戶管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;OpenID Connect 集成和 API&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Maincloud&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;與 SpacetimeDB 1.0 一同推出的，還有其託管雲服務 Maincloud。Maincloud 與獨立版本類似，但無需讓用戶處理任何部署問題！只需運行以下命令即可：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot;&gt;spacetime publish -s maincloud your-app&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;下載地址 &amp;amp; 發佈公告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fclockworklabs%2FSpacetimeDB%2Freleases%2Ftag%2Fv1.0.0&quot; target=&quot;_blank&quot;&gt;https://github.com/clockworklabs/SpacetimeDB/releases/tag/v1.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338417/spacetimedb-1-0-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338417/spacetimedb-1-0-0</guid>
            <pubDate>Thu, 06 Mar 2025 11:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek：「國運級創新」，憑啥？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;768&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4eb15815df212b6763b81b49b68f594857.jpg&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;：&lt;/strong&gt;&lt;br&gt; 春節前後，要説國內外科技圈最火熱的名字，DeepSeek 絕對算頭一個。「開源大模型之光」、「AI 領域新星」、「有望比肩 OpenAI」…… 各種讚譽紛至沓來，甚至有人直接將其冠於「國運級創新」的説法。「國運級創新」？ 這個帽子可實在不小。但是有人會質疑，憑啥？本文則試着從產業共識的角度來分析，筆者認為它確實擔得起。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. DeepSeek&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，是國運級創新！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;要探尋 「DeepSeek 是國運級創新」 這一説法的源頭，最早的説法來自遊戲圈內極具影響力的人物——現象級 3A 遊戲《黑神話：悟空》的製作公司遊戲科學創始人馮驥。他在新浪微博上就曾公開表示：「DeepSeek 可能是個國運級別的科技成果」。馮驥以其獨到的眼光和對技術趨勢的敏鋭洞察力而著稱，他的這番評價，無疑引發了廣泛關注。下圖是他的微博截圖。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1058&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2827904619db71dd8976e59971d5613c281.webp&quot; width=&quot;1078&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;國內安全領域的領軍人物，360 集團創始人周鴻禕也表達了對 DeepSeek 的有力支持。 在今年兩會期間接受《新京報》記者關於 「人工智能技術開源」 話題的採訪時，他 「舉雙手贊同」 馮驥關於 DeepSeek 「國運級別的科技成果」 的評價。他認為開源模式形成了巨大的虹吸效應，一旦形成氣候，將徹底戰勝閉源。憑藉更低的成本和更開放的技術普惠路徑，中國在 AI 應用規模和滲透率上比美國更高。周鴻禕作為在 IT 行業深耕多年的資深人士，他的認可更顯分量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-828276f780bb3ae6d229892554c1bb867c7.webp&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（圖片來自新京報）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;著名技術社區 CSDN 的高級副總裁李建忠今年也撰文《DeepSeek 關鍵技術創新及對 AI 生態的影響》，從技術生態的角度深入分析了 DeepSeek。 他認為 DeepSeek 的巨大影響力，不僅在於其在 AI 領域實現的多項關鍵技術創新，更在於它，引發了對全球 AI 生態格局升級和重塑的深刻思考。 作為深耕開發者生態多年的行業大 V，李建忠盛讚 DeepSeek 「或將成為中國開發者擁抱 AI 時代的最佳選擇」。 來自開發者社區的積極評價，無疑是最直接且最具説服力的市場反饋。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;不僅如此，國際媒體也敏鋭捕捉到了 DeepSeek 的崛起，並將其與具有歷史意義的 「人造衞星時刻 (Sputnik moment)」 相提並論。 「人造衞星時刻」 源於 1957 年前蘇聯成功發射人類首顆人造衞星 Sputnik 1 號， 這一事件震驚世界， 象徵着科技競爭格局的突變，以及對原有技術領導者的挑戰。 外媒借用 「人造衞星時刻」 來形容 DeepSeek，一方面是認同 DeepSeek 在人工智能尤其是在大模型技術領域取得的突破性進展， 另一方面是預示着其可能打破美國在 AI 領域的領先地位， 並對全球 AI 競爭格局產生深遠影響。 這種來自國際輿論場的積極信號， 進一步印證了 DeepSeek 在全球 AI 領域的影響力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. DeepSeek&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，真的是「國運級創新」嗎？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;但是，很多人可能會質疑，它憑啥，可以擔當得起「國運級創新」這個評價？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 雖然開源，雖然它的性能優異媲美一流的商業大模型，同時成本低廉為頂尖商業大模型的幾十分之一，而且擁有大量的技術創新，包括在算法上和工程上。但是這些優點在行業內並非獨有。在它之前，Meta 公司的 Llama 系列、阿里公司的 QWen 系列、歐洲公司的 Mistral 系列等開源大模型，早已在業界積累了良好的口碑，且同樣具備出色的性能和開源特性。近年來，開源大模型已經成為行業內的重要趨勢，開源本身已經不再是稀缺資源。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;而且技術特性上，讓它成本最低的模型架構 MOE（Mixture of Expert）也不是原創，Mistral 之前早就這麼做了。而純用深度學習來進行模型推理能力的增強，這也是 OpenAI 半年前發佈 OpenAI O1 的做法，只不過它沒有開源而已。所以有人質疑，即便 DeepSeek 在部分指標上超越了前輩項目，這種領先是否足以稱為顛覆性突破？此外，DeepSeek 的模型雖然開源，論文雖然公開而且很詳細，但底層技術路線的原創性究竟有多少？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;它憑什麼能夠在短時間內獲得如此高的評價，甚至被視為「國運級創新」？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;筆者認為，DeepSeek 是堪稱「國運級「的科技創新，不僅僅是它的性能好、成本低、開源這三個技術方面的特點，最重要的原因，是它&lt;strong&gt;&lt;span style=&quot;color:#c0392b&quot;&gt;初步達成了國內外的產業共識&lt;/span&gt;&lt;/strong&gt;。而產業共識，尤其是中國人領導的產業共識，非常難得，非常有價值，之前基本沒有，就是我頂它為國運級創新的理由。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;3. 共識是什麼？產業共識又是什麼？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;產業共識？ 這是什麼？這玩意兒有這麼重要？當然重要！ 甚至可以説，產業共識，才是 「國運級創新」 最堅實的基石。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;要理解 「產業共識」 的價值，我們先得搞清楚，啥是 「共識」？字典上説，共識，就是指對某件事物或觀點的普遍認同。 放到社會學和心理學層面，共識更意味着一種，羣體性的認知、價值取向和行動方向的統一。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;「共識」 究竟為何如此重要？ 我們不妨從以下幾個維度來剖析：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共識是行動的「方向盤」：&lt;/strong&gt;&lt;span&gt;&amp;nbsp;想象一下，如果一個團隊，每個人都朝着不同的方向努力，力量就會被分散，效率就會大打折扣。 共識就像是 「方向盤」， 能夠統一方向， 讓羣體力量朝着同一個目標前進， 避免內耗， 提升效率。 無論是家庭生活、團隊協作、還是社會治理， 「方向一致」 都是高效行動的前提，而 「共識」 就是確保方向一致的關鍵。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共識是信任的「橋樑」：&lt;/strong&gt;&lt;span&gt;&amp;nbsp;人與人之間的合作， 離不開信任。 而 「共識」 恰恰是建立信任的 「橋樑」。 當彼此之間有了共同的認知、共同的價值觀、共同的目標， 信任的基石就得以建立。 「共識」 能夠減少誤解， 降低溝通成本， 促進彼此理解和支持， 從而建立起更深厚的信任關係。 信任就像是人際關係的紐帶，而 「共識」 就是構建信任的橋樑。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共識是穩定的「壓艙石」&lt;/strong&gt;&lt;span&gt;： 社會和羣體的穩定， 需要共同的規則和秩序來維繫。 「共識」 就如同 「壓艙石」， 能夠維護羣體和社會的穩定。 當社會成員對基本價值觀、行為準則、社會秩序等達成共識， 社會就能保持穩定和凝聚力， 減少衝突和對抗， 構建和諧穩定的社會環境。 穩定就像是大船的壓艙石，而 「共識」 就是社會穩定的壓艙石。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共識是創新的「催化劑」&lt;/strong&gt;&lt;span&gt;： 創新往往需要集思廣益， 需要不同觀點的碰撞和融合。 「共識」 看似是統一思想， 但實際上， 它也能成為創新的 「催化劑」。 在 「共識」 的基礎上， 不同的觀點和想法才能更好地交流和融合， 激發新的思路， 碰撞出創新的火花。 共識並非 「求同」， 而是在 「存異」 的基礎上 「求同」， 最終實現 「和而不同」 的創新局面。 創新就像化學反應，而 「共識」 就是催化反應的催化劑。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共識是力量的「倍增器」&lt;/strong&gt;&lt;span&gt;： 單個人、單個組織的力量終究有限。 「共識」 能夠將分散的力量 「聚合」 起來， 形成 「1+1&amp;gt;2」 的 「倍增效應」。 當一個羣體， 一個社會， 甚至一個國家， 在某個重要方向上達成共識， 就能凝聚起強大的合力， 共同應對挑戰， 實現共同目標。 力量源於團結，而 「共識」 就是凝聚力量、倍增力量的源泉。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;更進一步， 如果我們從人類文明演進的宏大視角來看， 「共識」 的重要性， 就更加不言而喻了。 正如暢銷書《人類簡史》所揭示的， 遠古的智人之所以能夠戰勝其他更強壯、更聰明的古人類（例如尼安特人等）， 最終成為地球的主宰， 並非僅僅依靠個體力量，而是因為智人掌握了一種獨特的生存技能—— 「講故事， 形成共識， 組織大規模合作」。正是 「共識」 這種神奇的力量， 讓智人能夠將分散的個體組織起來， 擊敗其他古人類，形成部落、城邦、國家， 構建複雜的社會結構， 共同應對自然挑戰， 直至最終創造出輝煌的人類文明。 從某種意義上説， 「人類文明史」， 就是一部 「共識進化史」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1024&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ef5b090ee221607c5f340d5853a09191a5f.png&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;圖為一批原始人協同工作擊殺大象&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;理解了 「共識」 在人類社會中的重要性， 我們再來看 「產業共識」。 所謂 「產業共識」， 就是將 「共識」 的理念， 應用到 「產業」 領域。 具體而言， 「產業共識」 指的是產業鏈上下游各個環節， 以及相關利益方， 對於某個產業發展方向、技術路線、價值理念等達成的普遍認同。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;那麼， 「產業共識」 對於 IT 產業， 又意味着什麼呢？ 它又將發揮哪些獨特而重要的作用呢？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;統一方向，凝聚力量&lt;/strong&gt;&lt;span&gt;： 產業共識就像一個 「指揮棒」，能夠引導產業資源向同一個方向集中，避免內耗和重複建設，形成合力，共同推動產業快速發展。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;降低風險，提升效率&lt;/strong&gt;&lt;span&gt;： 有了產業共識，大家就能在相對確定的方向上進行創新和投入，減少試錯成本，加速技術迭代和市場推廣，提高整體產業效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;構建生態，合作共贏&lt;/strong&gt;&lt;span&gt;： 產業共識能夠促進產業鏈各環節的協同合作，形成互信互利的合作關係，構建健康可持續的產業生態，最終實現共贏。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;我們回顧，一下這麼多年 IT 產業發展史，我們就能看到 「產業共識」 的力量，有很多很好的例子，我稍微舉幾個：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;Linux 操作系統的崛起&lt;/strong&gt;&lt;span&gt;：&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;當我們審視 DeepSeek 的崛起軌跡，歷史正在重演 Linux 的傳奇。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Linux 的成功，絕對是 IT 產業 「產業共識」 的典範。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;1991 年當芬蘭大學生 Linus Torvalds 在大學宿舍敲下第一行內核代碼時，沒人能預見這個「個人玩具」會重構全球操作系統格局。彼時的 Unix 閉源帝國 AT&amp;amp;T 與 Microsoft Windows 商業巨輪，正如今天的 OpenAI GPT 系列和 Anthropic Claude 系列，用高牆鎖死創新。但是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Linux 用開源、開放，的理念迅速獲得了全球開發者的認同和響應，同時也打破了 Unix 商業發行版和 Microsoft Windows 的壟斷，從個人開發者到商業公司谷歌、IBM、紅帽等，無數開發者參與到 Linux 的開發和完善中，最終 Linux 成為了，服務器、嵌入式系統、移動設備等領域最主流的操作系統之一。 Linux 的成功， 打破了商業操作系統的壟斷，構建了一個龐大而充滿活力的開源生態系統。 可以説，沒有開源共識和產業界對 Linux 的共同支持， 雲計算、大數據、移動互聯網等技術發展都難以想象。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;HDFS (Hadoop 分佈式文件系統) 的普及&lt;/strong&gt;&lt;span&gt;： HDFS 又是另外一個很好的例子。HDFS 最早是作為 Google 內部大數據分佈式存儲和計算的 GFS 的開源實現，但是後來在大數據浪潮中，HDFS 成為了，存儲海量數據的標準基礎設施。 HDFS 開源、可擴展、高容錯，的特性，完美契合了大數據時代的需求，迅速獲得了包括互聯網巨頭、金融機構、科研機構等各行各業的廣泛採用。 HDFS 的普及， 降低了大數據存儲和處理的門檻，加速了大數據技術的應用和創新。 可以説，沒有 HDFS 的產業共識， 大數據產業格局將會非常不同。後來即便是 GFS 的實際發明人 Google，在推出 Google Cloud 對外，提供服務的時候，也不得不支持在他們眼裏技術落後的 HDFS。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;Kubernetes (K8s) 容器編排系統的流行&lt;/strong&gt;&lt;span&gt;： 在雲計算和容器技術興起的大背景下，Kubernetes 脫穎而出，成為了雲原生（Cloud Native）中容器編排領域的標準。 Kubernetes 強大的容器管理能力、靈活的擴展性、豐富的生態系統，贏得了包括 Google、Microsoft、Amazon、阿里、字節、騰訊等雲巨頭在內的整個 IT 產業的共同擁抱。 Kubernetes 的流行， 極大地簡化了應用部署和管理，加速了雲原生技術的普及，推動了雲計算的快速發展。 可以説，沒有 Kubernetes 的產業共識， 雲原生應用開發和部署模式將面臨更多挑戰。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;這些例子都充分説明，「產業共識」 對於 IT 產業的健康發展和技術創新，具有至關重要的作用。 它不僅僅是一種 「認同」，更是一種 「力量」， 一種能夠凝聚產業資源、加速技術創新、構建繁榮生態、提升整體競爭力的 「戰略性資源」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;反觀中國 IT 產業發展歷程，我們會發現，在形成，國際，產業共識方面，中國 IT 產業的案例相對較少，或者説沒有特別值得一提的案例。這並非是中國技術能力不足，而是由多種複雜因素造成的：一方面中國 IT 起步較晚，錯失早期行業事實標準制定機會；另一方面，早期發展策略側重 「自主可控」 和 「國產替代」： 這在保障國家信息安全、建立自主產業鏈方面取得了顯著成就， 但在，推動技術標準國際化、形成全球產業共識方面，客觀上有所側重；還有就是文化和語言差異，影響技術理念傳播： 技術標準的推廣和產業共識的形成， 除了技術實力，也需要文化和語言的傳播。 當然還有國際政治和市場環境的複雜性： 近年來，國際政治經濟環境日趨複雜， 技術 「脫鈎」 和 「逆全球化」 趨勢抬頭， 也為中國 IT 技術走向國際，形成全球產業共識增加了阻力。但這並不意味着中國 IT 產業無法形成產業共識，更不意味着中國技術無法走向世界。 事實上，近年來，我們已經看到一些積極的趨勢：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;中國企業積極參與國際標準制定： 越來越多的中國企業開始積極參與國際技術標準的制定， 例如在 5G、人工智能、物聯網等新興領域，中國企業的話語權和影響力正在顯著提升。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;開源開放成為新趨勢： 越來越多的中國 IT 企業開始擁抱開源開放， 通過開源項目和開放平台， 與全球開發者社區和產業界進行更廣泛的合作和交流， 為形成產業共識創造更有利條件。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;「一帶一路」 倡議推動技術和標準輸出： 「一帶一路」 倡議為中國 IT 技術和標準 「走出去」 提供了重要平台和機遇， 通過基礎設施建設和產業合作， 中國技術和標準在發展中國家和地區的影響力不斷擴大。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;在這樣的背景下， DeepSeek 的出現， 以及它所展現出的 「產業共識」 潛力， 就顯得尤為重要和值得關注。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;4. 憑啥説 DeepSeek 已經初步達成了產業共識？ 體現在哪些方面？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;我認為，DeepSeek 已經初步達成產業共識，先看看產業的實際情況。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;IT 產業圍繞大模型領域，可以按照技術層次，從下往上分為四層。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;904&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e212d801965b9dcd4528c52e1f40e83fef9.png&quot; width=&quot;1730&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;而當前，每一層的國內外玩家都非常認同和積極擁抱 DeepSeek，這就是產業共識。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（1）&lt;/span&gt;&lt;strong&gt;基石層&lt;/strong&gt;&lt;span&gt;：國內外的 CPU/GPU 廠家都紛紛宣稱支持 DeepSeek，其中包括國際的 Intel、AMD，國內的海光、沐曦、華為、隧原、&lt;/span&gt;摩爾線程、&lt;span&gt;天數智芯、崑崙芯、&lt;/span&gt;壁仞科技、&lt;span&gt;龍芯等宣稱支持 DeepSeek。幾乎找不到一家 CPU/GPU 廠家説不支持 DeepSeek，各家的區別可能是有的支持 R1 滿血版，有的支持 R1 蒸餾版而已。這一層還包括一體機、操作系統、網絡、存儲、IDC 等。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（2）&lt;/span&gt;&lt;strong&gt;雲服務層&lt;/strong&gt;&lt;span&gt;：同樣國內外的雲廠商紛紛宣稱支持 DeepSeek，其中包括國際的 AWS、Microsoft Azure、Nvidia Nim，和國內的阿里雲、騰訊雲、百度雲、火山雲，還有三家電信運營商的雲，此外還有一些中小企業例如商湯科技、硅基流動等也宣稱提供部署 DeepSeek 多個版本的雲服務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;646&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-65464c7380c891a0572a028abe9217ce193.webp&quot; width=&quot;736&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;（以上信息來自&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://www.perplexity.ai/）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（3）&lt;/span&gt;&lt;strong&gt;軟件產品集成層&lt;/strong&gt;&lt;span&gt;：企業軟件巨頭們也紛紛宣佈支持 DeepSeek，例如 SAP 宣佈在集成 DeepSeek 在它的 ERP 軟件中，國內 ERP 巨頭用友宣佈已經集成 DeepSeek 到它的 BIP 產品中，此外還有浪潮通軟、金蝶等 N 多企業軟件宣稱集成了 DeepSeek。其他宣稱支持 DeepSeek 的商業軟件，包括 BI 產品、CRM 產品就更多了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（4）&lt;/span&gt;&lt;strong&gt;甲方應用層&lt;/strong&gt;&lt;span&gt;：各行業的甲方巨頭們也紛紛支持 DeepSeek，例如工商銀行集成 DeepSeek 到工行內部大模型服務平台，服務於財報分析助手、財富管家、智能客服、風險評估等業務中，在北京友誼醫院/清華長庚醫院也宣稱已經集成了 DeepSeek 在他們的數字化平台中，還有能源、交通等多家央企宣稱集成了 DeepSeek。中興努比亞手機、OPPO 手機也紛紛宣稱在他們的手機系統上集成了 DeepSeek 大模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;這非常難得，因為之前筆者曾經一度覺得很困擾，因為大模型模型的不統一，導致上下每一層都存在巨大的適配工作，而只要其中任何一層的適配工作沒有做好，都會導致最終大模型應用落地的體驗很差，要麼最終輸出準確性不及預期，實際落地需要大量的 dirty work；要麼整個系統延遲巨高，用戶體感很差。現在好了，每一層的企業都在主動適配 DeepSeek，這樣能大大減輕各個層面的適配工作，讓大模型應用的落地成本更低、速度更快、體驗更好。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;更難得的事，筆者上個月在沙特利雅得參加沙特開源峯會 2025，跟沙特本地 IT 人士溝通的時候，他們也充分認同 DeepSeek 的價值，對來自中國的開源 AI 充滿好感，有的數字化產品之前使用 ChatGPT API 的也在遷移到 DeepSeek 上。而這也為集成 DeepSeek 的中國 IT 軟件進入中東市場創造了有利的條件。沙特只是一帶一路上的一個國家，但是管中窺豹可以看出，DeepSeek 對於中國拓展一帶一路上的數字基礎設施建設和數字經濟業務，能起到非常好的標杆作用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;2240&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7ca0344af9eab3d374819dc4a69de9d0341.jpg&quot; width=&quot;3360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#ff2941&quot;&gt;這就是產業共識的力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;5. 產業共識，對 DeepSeek 的未來有啥影響？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;筆者認為，如果 DeepSeek 真的能夠持續鞏固和擴大這種 「產業共識」， 那麼它未來的發展，將獲得源源不斷的強大助推力：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;加速技術創新&lt;/strong&gt;&lt;span&gt;： 產業共識將為 DeepSeek 提供更廣闊的技術創新空間和資源支持，吸引更多優秀人才和資本的湧入，促進其在 AI 核心技術上不斷突破，保持技術領先優勢。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;拓展應用場景&lt;/strong&gt;&lt;span&gt;： 產業共識將幫助 DeepSeek 更快地滲透到各行各業，拓展更豐富的應用場景，實現技術與產業的深度融合，釋放 AI 技術的巨大商業價值和社會價值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;構建生態壁壘&lt;/strong&gt;&lt;span&gt;： 產業共識將有助於 DeepSeek 構建強大的產業生態系統，形成技術、市場、生態等多重壁壘，提升長期競爭力，成為中國 AI 產業生態的核心力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;提升中國 AI 產業競爭力&lt;/strong&gt;&lt;span&gt;： DeepSeek 的崛起和產業共識的形成，將帶動整個中國 AI 產業的蓬勃發展，提升中國在全球 AI 領域的競爭力，甚至有望改寫全球 AI 產業格局。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;6. 總結一下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 是不是 「國運級創新」， 現在下定論可能還為時過早。 但它，初步達成的 「產業共識」 ， 的確為我們提供了一個全新的視角， 讓我們看到了中國 IT 產業 「聚沙成塔， 眾木成林」 的希望。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;如果 DeepSeek 能夠繼續保持開放合作的姿態， 持續技術創新， 不斷擴大產業共識， 那麼它未來的發展， 真的值得我們期待，甚至有可能超出我們的想象。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 「國運級創新」， 憑啥？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;憑 「產業共識」！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;你覺得這個道理， 站得住腳嗎？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;(歡迎在評論區留下你的看法！)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3742410/blog/17885347</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3742410/blog/17885347</guid>
            <pubDate>Thu, 06 Mar 2025 10:58:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>「一腦多機」通用具身智能平台「慧思開物」發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;北京人形機器人創新中心（國家地方共建具身智能機器人創新中心）在京發佈全球首個「一腦多能」「一腦多機」的通用具身智能平台「慧思開物」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「慧思開物」的應用是對基於單一場景單一任務做專項開發這一傳統機器人應用開發模式的顛覆，同時也填補了具身智能領域在通用軟件系統方面的空白，真正推動智能機器人從單一任務執行向複雜環境下的自主決策與執行能力躍升。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;img height=&quot;289&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-804921cd73199cb7a3d3f1073e873a9888b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a38d5a4d0328e61acdf9f224eb5f046bd60.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;em&gt;來源：央視新聞&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338410</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338410</guid>
            <pubDate>Thu, 06 Mar 2025 10:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里通義實驗室開源 R1-Omni，全模態模型+RLVR</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里通義實驗室&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPC1s42i6PvwelFL8JTIAbw&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;開源 R1-Omni 模型，業界首個將具有可驗證獎勵的強化學習（Reinforcement Learning with Verifiable Reward，RLVR）應用於全能多模態大語言模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人員利用 RLVR 對開源 Omni 模型 HumanOmni-0.5B 進行優化，在推理能力、情感識別準確性和泛化能力三個關鍵方面顯著提高了其性能。R1-Omni 能夠更清楚地理解視覺和聽覺信息如何促進情緒識別，能夠明確展示哪些模態信息對特定情緒的判斷起到了關鍵作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為了驗證 R1-Omni 的性能，項目團隊將其與原始的 HumanOmni-0.5B 模型、冷啓動階段的模型以及在 MAFW 和 DFEW 數據集上有監督微調的模型進行了對比。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5f25e57a50cb46139c49aca195c12da36b8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;實驗結果顯示，在同分布測試集（DFEW 和 MAFW）上，R1-Omni 相較於原始基線模型平均提升超過 35%，相較於 SFT 模型在 UAR 上的提升高達 10% 以上。在不同分佈測試集（RAVDESS）上，R1-Omni 同樣展現了卓越的泛化能力，WAR 和 UAR 均提升超過 13%。這些結果充分證明瞭 RLVR 在提升推理能力和泛化性能上的顯著優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;149&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8bd3fe6b0d2d65935730b58b1f041cc492.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，R1-Omni 的一大亮點在於其透明性（推理能力）。通過 RLVR 方法，音頻信息和視頻信息在模型中的作用變得更加清晰可見。比如，在情緒識別任務中，R1-Omni 能夠明確展示哪些模態信息對特定情緒的判斷起到了關鍵作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「這種透明性不僅幫助我們更好地理解模型的決策過程，也為未來的研究提供了重要參考方向。未來，我們期待 R1-Omni 在更多複雜場景中發揮作用，為多模態任務的研究與應用開闢新的道路。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338400</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338400</guid>
            <pubDate>Thu, 06 Mar 2025 09:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>8 條 AI 編程指南</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;1. 合理選擇開發工具：不同的 AI 編程工具有其各自的專長。對於複雜應用推薦使用 Cursor/Windsurf，輕量級應用開發選擇 Bolt/Lovable，移動應用開發使用 Replit，UI 設計則可以使用 v0。&lt;/p&gt; 
&lt;p&gt;2. 完善項目上下文：要以 .md 文檔形式詳細説明項目信息，包括：產品需求文檔（PRD）、技術棧説明、文件結構、前端開發規範和後端架構設計。這樣能有效防止 AI 生成偏離預期的內容。推薦使用 CodeGuide 編寫 AI 開發文檔，它與各類 AI 工具都能良好配合。&lt;/p&gt; 
&lt;p&gt;3. 拆分任務逐步實現：不要期望 AI 能一次性完成 「構建一個 AirBNB 克隆版「 這樣的大型任務。應該將項目分解為頁面級任務，再把每個頁面細分為組件級任務。記住 AI 一次最多能處理 3 個小任務。&lt;/p&gt; 
&lt;p&gt;4. 選擇適合 AI 的技術棧：Claude Sonnet 3.5、GPT-4o、o3 和 o1 等 AI 模型在處理 React 和 Python 框架時表現出色。因此建議網頁應用選用 NextJS、viteJS 和 Python，移動應用則使用 React Native（如果使用 Claude，SwiftUI 也是不錯的選擇）。&lt;/p&gt; 
&lt;p&gt;5. 善用項目模板：不要每次都從零開始，這樣會浪費時間和資源。使用現成的項目模板（如 CodeGuide NextJS Starter Kit）可以快速搭建開發環境，提高效率。&lt;/p&gt; 
&lt;p&gt;6. 設定 AI 使用規範：通過規則文件來約束 AI 的行為，確保其遵循項目規範。可以創建 .cursorrules（項目規則）和 .windsurfrules 等文件來設定全局 AI 規則。&lt;/p&gt; 
&lt;p&gt;7. 組合多種工具優勢：目前沒有單一工具能完全滿足 AI 開發的所有需求。建議使用 Perplexity 做研究，ChatGPT 語音做頭腦風暴，CodeGuide 寫文檔，Firecrawl 做數據爬取，再配合其他 AI 編程工具來構建代碼庫。&lt;/p&gt; 
&lt;p&gt;8. 保持耐心和平和心態：與 AI 協作就像與 「外星智慧「 溝通，需要學習理解 AI 的語言（提示詞工程）。雖然 AI 可能會出錯或產生偏差，但保持耐心和專注，慢慢引導它按照你的意圖工作。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2e701684197e228cc10e7f64da73fd944b6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcj_zZZz%2Fstatus%2F1890078645089346038&quot; target=&quot;_blank&quot;&gt;https://x.com/cj_zZZz/status/1890078645089346038&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/336236&quot; target=&quot;news&quot;&gt;使用 Cursor 編程的 15 條經驗建議&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338397</guid>
            <pubDate>Thu, 06 Mar 2025 09:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>消息稱 Meta 正在測試首款內部 AI 訓練芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fartificial-intelligence%2Fmeta-begins-testing-its-first-in-house-ai-training-chip-2025-03-11%2F&quot; target=&quot;_blank&quot;&gt;路透社&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息稱，Meta 正在測試用於訓練 AI 系統的內部芯片，作為減少對 Nvidia 等硬件製造商依賴的戰略的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息人士透露，Meta 的芯片旨在處理特定於 AI 的工作負載，與台積電合作生產的，測試部署是在 Meta 完成芯片的首次「流片」後開始的。目前該公司正在試行該芯片的「小規模部署」，並計劃在測試順利的情況下擴大產量以供大規模使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8d9cf4d0ccb1197c434c008852d14c65a1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 之前曾部署過定製的 AI 芯片，但僅用於運行模型，而不是訓練模型。路透社指出，該公司的多項芯片設計工作曾因未能達到內部預期而被取消或縮減。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 預計今年的資本支出將達到 650 億美元，其中大部分將用於購買 Nvidia GPU。如果該公司通過轉向內部芯片能夠減少哪怕是一小部分成本，那麼對其來説都是巨大的勝利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338393/meta-testing-first-in-house-ai-training-chip</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338393/meta-testing-first-in-house-ai-training-chip</guid>
            <pubDate>Thu, 06 Mar 2025 08:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>餘承東預告：首款原生鴻蒙正式版手機下週發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;華為常務董事、終端 BG 董事長、智能汽車解決方案 BU 董事長餘承東&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1100856704%2FPiavhsK1W%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;今日宣佈&lt;/a&gt;&lt;/u&gt;：「首款搭載原生鴻蒙正式版的「想不到的產品」，下週見！」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0312/161848_tDhG_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;餘承東在視頻中介紹：「去年 10 月，原生鴻蒙全面開啓公測，目前已收到 400 萬條用戶反饋的優化建議、系統迭代了 30 多個版本、新增 150 多項功能特性，已有 2 萬個鴻蒙原生應用和元服務上架，同時微信、抖音、支付寶、高德地圖、京東等 App 下載量已超 200 萬。」&lt;/p&gt; 
&lt;p&gt;餘承東宣佈，「原生鴻蒙正式版體驗大有不同，流暢度大幅提升，帶來了更安全的隱私保護，還有全新小藝在盤古、DeepSeek 雙模型加持下，輕鬆應對各種複雜的推理場景，更高效、更智慧，情感也更加豐富。」&lt;/p&gt; 
&lt;p&gt;他表示，「&lt;strong&gt;下週，首款搭載原生鴻蒙正式版的手機就要來了，華為終端也將全面進入原生鴻蒙時代。&lt;/strong&gt;」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338389</guid>
            <pubDate>Thu, 06 Mar 2025 08:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>青雲科技關於 KubeSphere 中 Docker 組件合規性的聲明</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在雲原生技術蓬勃發展的今天，合規性與技術透明度已成為企業級產品的核心基石。作為始終踐行「開放透明」理念的開源踐行者，青雲科技始終將用戶權益與技術合規置於首位。為響應社區關切並明確技術責任邊界，現正式發佈《青雲科技關於 KubeSphere 中 Docker 組件合規性的聲明》，以全方位保障您的數字化轉型之旅安全可信。&lt;/p&gt; 
&lt;h2&gt;青雲科技關於 KubeSphere 中 Docker 組件合規性的聲明&lt;/h2&gt; 
&lt;p&gt;北京青雲科技集團股份有限公司（以下簡稱&quot;青雲科技&quot;或&quot;我司&quot;）始終秉承開放透明的合作原則，致力於為用戶提供安全、合規的雲原生產品解決方案。為保障用戶權益並明確產品責任邊界，現就我司 KubeSphere 容器管理平台（以下簡稱&quot;本平台&quot;）的產品信息與 Docker 組件使用合規性作以下官方聲明：&lt;/p&gt; 
&lt;h3&gt;一. 產品定位與技術架構&lt;/h3&gt; 
&lt;p&gt;KubeSphere 容器管理平台是由青雲科技自主研發的&lt;strong&gt;企業級容器集羣調度與管理平台。&lt;/strong&gt; 本平台基於開源 Kubernetes 技術構建，專注於為全球用戶提供高效穩定的容器化應用部署、運維及全生命週期管理服務，適用於混合雲、異構多雲及邊緣計算等複雜場景。&lt;/p&gt; 
&lt;h3&gt;二. 適用範圍&lt;/h3&gt; 
&lt;p&gt;本文就 KubeSphere 容器管理平台中 Docker 組件合規性的聲明適用於以下 KubeSphere 產品版本形態：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KubeSphere 開源版。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企業版（包含更名前的青雲 QKCP）。&lt;/li&gt; 
 &lt;li&gt;青雲容器平台（可信版）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;三. 版權與 Docker 組件合規聲明&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 平台組件構成説明&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;本平台屬服務器端軟件，其技術實現與交付內容嚴格遵循開源協議規範。&lt;/li&gt; 
 &lt;li&gt;我司提供的軟件安裝包及最終用戶運行環境中，不包含 Docker Desktop 軟件及通過 Docker Desktop 引入的任何組件。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Docker 組件使用合規性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;本平台軟件安裝包內集成的 &lt;strong&gt;Docker Community Edition (docker-ce) 與 Docker Engine&lt;/strong&gt;，均直接從 Docker 官方渠道所列單獨路徑下載。依據 Docker 官方網站上該路徑所含版權聲明（可訪問鏈接 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.docker.com%2Fengine%2F&quot; target=&quot;_blank&quot;&gt;https://docs.docker.com/engine/&lt;/a&gt; 獲取詳細信息），&lt;strong&gt;其版本聲明明確標註為&quot;Docker Engine is licensed under the Apache License, Version 2.0.&quot;。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;我司對上述組件的集成行為完全符合 Apache License 2.0 協議要求，且未通過 Docker Desktop 途徑獲取相關技術組件。因此，&lt;strong&gt;不受&quot;for commercial use of Docker Engine obtained via Docker Desktop&quot;所述範圍的限制，其行為完全符合 Docker 官方規定。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 用戶自主選擇權&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;用戶是否使用平台軟件安裝包內集成提供的 Docker 系列組件，&lt;strong&gt;取決於用戶自身，而非必要使用。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;我司提供 Docker Community Edition (docker-ce) 與 containered 等多種容器運行時解決方案，用戶可根據實際業務需求選取使用。同時我司提供相關的架構諮詢與交付服務。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在我司提供的產品之外，若用戶因自行在環境中安裝 Docker Desktop 產生合規爭議，需對其個人行為負相應的法律責任。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;四. 用戶支持與協作&lt;/h3&gt; 
&lt;p&gt;青雲科技始終將用戶信任置於首位。如您對上述聲明內容存有任何疑問，或需進一步瞭解技術細節、探討合作方案，歡迎通過以下方式聯繫我司專業團隊：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;服務熱線：400-8576-886&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E5%AE%98%E6%96%B9%E9%82%AE%E7%AE%B1%EF%BC%9Asupport%40kubesphere.cloud&quot; target=&quot;_blank&quot;&gt;官方郵箱：support@kubesphere.cloud&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我司將嚴格履行技術合規責任，持續為全球用戶提供中立安全可靠的雲原生基礎設施服務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附註：&lt;/strong&gt; 本文內容最終解釋權歸北京青雲科技集團股份有限公司所有。&lt;/p&gt; 
&lt;p&gt;&amp;gt; 本文由博客一文多發平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom&quot; target=&quot;_blank&quot;&gt;OpenWrite&lt;/a&gt; 發佈！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4197945/blog/17884779</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/17884779</guid>
            <pubDate>Thu, 06 Mar 2025 08:17:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>原字節跳動 AI 大將駱怡航加盟生數科技，出任 CEO</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1642634100%2FPiaXvECdR%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;根據新浪科技的獨家報道&lt;/a&gt;&lt;/u&gt;，原字節跳動 AI 大將、火山引擎 AI 應用產品線一號位&lt;strong&gt;駱怡航已於近日加入生數科技，擔任 CEO 一職，將全面負責公司研發、產品、商業化及團隊管理工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;駱怡航畢業於清華大學自動化系，在雲計算及 AI 領域有超過十年的工作經驗，擁有紮實的技術背景、產業理解和商業化經驗，在加入生數科技前，駱怡航擔任字節跳動火山引擎 AI 應用產品線一號位，向火山引擎總裁彙報，全權負責產品線的戰略、產品和商業化。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;576&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0312/161018_oYWJ_2720166.png&quot; width=&quot;1058&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，該條產品線由駱怡航從 0 組建，涵蓋多個傳統 AI、大模型及大模型應用產品，管理規模數百人，是火山引擎當前的重點產品線之一。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，生數科技發佈視頻大模型 Vidu 2.0，視頻生成速度突破 10 秒以內，成本降至不到行業平均水平的一半。據悉，Vidu 用戶已覆蓋 200 多個國家和地區，深受不同職業和年齡層用戶的喜愛。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0312/160925_dgaK_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在生數科技內部人士看來，駱怡航的加入，將有助於公司加快技術轉化、商業化進程，推動 Vidu 在影視、動漫、廣告、教育、遊戲、文旅等領域的深度落地。此外，生數科技將邁入規模化和全球化發展階段，有成熟大廠管理經驗背景的高管也將有助於生數科技完善組織架構，提升團隊戰鬥力。&lt;/p&gt; 
&lt;p&gt;此前，生數科技已引入商業化副總裁王川、品牌市場負責人劉婷婷等人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338384</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338384</guid>
            <pubDate>Thu, 06 Mar 2025 08:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>PHP 遠程代碼執行高危漏洞 CVE-2024-4577 正被大規模利用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bleeping Computer &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fcritical-php-rce-vulnerability-mass-exploited-in-new-attacks%2F&quot; target=&quot;_blank&quot;&gt;近日報道稱&lt;/a&gt;&lt;/u&gt;，影響 Windows 系統的 PHP 遠程代碼執行漏洞 CVE-2024-4577 正被大規模利用。&lt;/p&gt; 
&lt;p&gt;該漏洞雖然已經於 2024 年 6 月修復，但攻擊者依然利用該漏洞，在全球範圍內發起廣泛攻擊，控制尚未及時修復的系統。&lt;/p&gt; 
&lt;p&gt;據瞭解，這是一個 PHP-CGI 參數注入漏洞，影響以 CGI 模式運行的 Windows PHP 安裝，成功利用該漏洞的攻擊者可在未經授權的情況下執行任意代碼，導致系統完全被控制。&lt;/p&gt; 
&lt;p&gt;Cisco Talos 發現，自 2025 年 1 月起，未知攻擊者利用該漏洞攻擊日本組織，竊取憑證信息外，還嘗試建立持久性、提升權限至 SYSTEM 級別，並部署「TaoWu」Cobalt Strike 工具包。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f77fef00b5fdee3333f1c4a087d2ca0c71.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GreyNoise 報告稱，攻擊者已將目標擴展至全球，美國、新加坡、日本等國成為重災區。2025 年 1 月，其全球蜜罐網絡（GOG）檢測到 1089 個獨特 IP 地址嘗試利用該漏洞。&lt;/p&gt; 
&lt;p&gt;GreyNoise 數據顯示，網絡上至少存在 79 款利用該漏洞的工具，在 2025 年 2 月，檢測到多國網絡中的利用嘗試激增，表明攻擊者正在自動化掃描易受攻擊的目標。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338377/critical-php-rce-vulnerability</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338377/critical-php-rce-vulnerability</guid>
            <pubDate>Thu, 06 Mar 2025 07:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ThingsPanel 開源 MCP 服務器：連接物聯網與 AI 的橋樑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#111111; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;我們很高興地宣佈 ThingsPanel MCP 正式開源。這是一個基於 Model Context Protocol (MCP) 的服務器實現，旨在為 ThingsPanel 物聯網平台提供 AI 模型集成能力。&lt;/p&gt; 
&lt;h2&gt;項目簡介&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;ThingsPanel MCP 是一個輕量級的中間件，它使得 AI 模型（如 Claude、GPT 等）能夠以標準化的方式與物聯網設備進行交互。通過實現 Model Context Protocol，它提供了一個安全、可控的接口，使 AI 模型能夠：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查詢和管理物聯網設備&lt;/li&gt; 
 &lt;li&gt;獲取設備歷史數據&lt;/li&gt; 
 &lt;li&gt;處理設備告警&lt;/li&gt; 
 &lt;li&gt;執行設備控制命令&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;技術特點&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;標準化接口&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;完整實現 Model Context Protocol 規範&lt;/li&gt; 
   &lt;li&gt;支持 stdio 和 SSE 傳輸方式&lt;/li&gt; 
   &lt;li&gt;RESTful API 設計&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;模塊化架構&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;核心功能模塊化設計&lt;/li&gt; 
   &lt;li&gt;插件式工具擴展&lt;/li&gt; 
   &lt;li&gt;支持按需啓用/禁用功能&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;開發友好&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;完整的類型提示&lt;/li&gt; 
   &lt;li&gt;異步 I/O 支持&lt;/li&gt; 
   &lt;li&gt;詳細的 API 文檔&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;部署靈活&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;提供 Docker 支持&lt;/li&gt; 
   &lt;li&gt;支持環境變量配置&lt;/li&gt; 
   &lt;li&gt;最小化外部依賴&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;適用場景&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;項目特別適合以下場景的技術團隊：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;需要為物聯網平台添加 AI 能力&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;自然語言設備控制&lt;/li&gt; 
   &lt;li&gt;數據分析和可視化&lt;/li&gt; 
   &lt;li&gt;智能告警處理&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;正在開發 AI 助手，需要物聯網集成能力&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;設備狀態查詢&lt;/li&gt; 
   &lt;li&gt;歷史數據分析&lt;/li&gt; 
   &lt;li&gt;設備控制和自動化&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;構建智能運維繫統&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;設備異常檢測&lt;/li&gt; 
   &lt;li&gt;預測性維護&lt;/li&gt; 
   &lt;li&gt;自動化運維&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;快速上手&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;安裝&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install thingspanel-mcp&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;配置&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span style=&quot;color:#e36209&quot;&gt;export&lt;/span&gt; THINGSPANEL_API_KEY=&lt;span style=&quot;color:#032f62&quot;&gt;&quot;您的 API 密鑰&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;運行&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;thingspanel-mcp&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;技術棧&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;語言：Python 3.8+&lt;/li&gt; 
 &lt;li&gt;傳輸協議：Model Context Protocol&lt;/li&gt; 
 &lt;li&gt;API 風格：RESTful&lt;/li&gt; 
 &lt;li&gt;容器化：Docker &amp;amp; Docker Compose&lt;/li&gt; 
 &lt;li&gt;測試框架：pytest&lt;/li&gt; 
 &lt;li&gt;代碼質量：mypy, black, isort&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;開源信息&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;許可證：Apache License 2.0&lt;/li&gt; 
 &lt;li&gt;倉庫地址：https://gitee.com/ThingsPanel/thingspanel-mcp &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;文檔：完整的英文和中文文檔&lt;/li&gt; 
 &lt;li&gt;貢獻指南：提供詳細的開發者指南&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;後續規劃&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;我們計劃在保持項目穩定性的同時，逐步添加以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;批量設備操作支持&lt;/li&gt; 
 &lt;li&gt;設備分組管理&lt;/li&gt; 
 &lt;li&gt;數據統計分析接口&lt;/li&gt; 
 &lt;li&gt;Webhook 支持&lt;/li&gt; 
 &lt;li&gt;更多第三方集成&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;參與貢獻&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;我們歡迎社區貢獻，無論是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;報告問題&lt;/li&gt; 
 &lt;li&gt;提交功能建議&lt;/li&gt; 
 &lt;li&gt;改進文檔&lt;/li&gt; 
 &lt;li&gt;提交代碼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;技術支持&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Issues：技術問題討論&lt;/li&gt; 
 &lt;li&gt;項目文檔：使用指南和 API 文檔&lt;/li&gt; 
 &lt;li&gt;示例代碼：標準用例實現&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;這個項目的目標是為物聯網開發者提供一個實用、可靠的工具，幫助他們更容易地將 AI 能力集成到物聯網應用中。我們注重代碼質量和文檔完整性，希望能為社區提供一個值得信賴的解決方案。&lt;/p&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;歡迎各位開發者試用和反饋，一起推動項目進步！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338376/thingspanel-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338376/thingspanel-mcp</guid>
            <pubDate>Thu, 06 Mar 2025 07:31:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>為什麼説 JSON 不一定是 LLM 結構化輸出的最佳選擇？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 在使用大語言模型時，如何在保證輸出質量的同時降低成本？在眾多數據輸出格式中，究竟應該如何選擇？&lt;/p&gt; 
 &lt;p&gt;我們今天為大家帶來的文章中，作者通過實際測試給出建議：在某些場景下，相比廣泛使用的 JSON 格式，不妨考慮一下其他數據格式，做一些測試，挑選出既能控制成本又能保證穩定性和速度的最佳選項。&lt;/p&gt; 
 &lt;p&gt;文章通過對比 TSV、CSV、Columnar JSON、YAML、TOML 和 JSON 六種格式，從 token 使用量、響應時間和實用性三個維度進行了深入分析。作者指出，沒有一種格式能在所有場景下都表現最佳。文章詳細分析了每種格式的優劣勢，並提供了一個實用的投資回報率計算方法，幫助讀者評估是否值得將現有系統從 JSON 轉換為其他格式。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | David Gilbertson&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當要求大語言模型（LLM）輸出結構化數據時，所採用的格式會對結果產生比較大的影響。本文對比了六種不同的格式，評估考察了它們的處理速度、tokens 消耗以及各自的限制。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 簡要説明&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;JSON 雖然是多數人的首選，但它對 tokens 的消耗極大。處理相同數據時，它可能需要其他格式兩倍的 tokens。&lt;/p&gt; 
&lt;p&gt;需要注意的是，沒有一種格式能在所有情況下都表現最佳，以下是一個決策指南：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7ec39896fc3d3679ce7a11780ae2500f61e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（如果你好奇為何沒有提及 XML，那是因為我有個個人目標：50 年不碰 XML ------ 只剩下 4 年就能達成了！）&lt;/p&gt; 
&lt;p&gt;我將在下文中詳細解釋這些格式選擇，並探討每種格式的侷限性。但在此之前，先讓我們對比一下它們的 token 使用情況和速度。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 token 使用情況&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;探究 JSON 之外的其他選項，主要目的是為了減少所需的 tokens 數量，這樣做可以降低運營成本並縮短響應時間。&lt;/p&gt; 
&lt;p&gt;為了對這些格式進行有效比較，我們將基於它們表示特定數據集所需的 token 數量來進行評估。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 比較框架&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本次比較我將使用一段文本作為輸入，該文本包含了關於歐盟每個國家的一段信息。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8e50ab87cb9683306d67a1d3a1c4b5339a0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我將要求 LLM 將這段普通文本轉換成結構化數據，其中每個國家都是一條記錄，每條記錄包含國家名稱、領導人姓名、領導人出生日期、領導人性別、人口數量和領土面積等鍵/值對。&lt;/p&gt; 
&lt;p&gt;我將針對每種結構化輸出格式執行這一操作，並檢查六種格式的輸出結果是否相同。&lt;/p&gt; 
&lt;p&gt;感興趣的朋友，可以在這個 gist[1] 中查看完整的代碼。對於不太感興趣的朋友，這裏展示了我如何為每種格式定義 name、可選的 hint 以及 parser（這裏將所有數據解析成 Pandas DataFrame）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c0a13f96703898de6c7ca324a996d388a64.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLM（本次測試使用的是 gpt-4o-mini）能夠以不同格式準確返回相同的數據。當然，如果數據更復雜，或者使用的 LLM 不夠強大，結果可能就不會這麼精確了。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 比較結果&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;下表展示了使用不同格式表示數據所需的 tokens 數量。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-22079d7588db10f57fdd85fd544a99231d5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JSON 所需的 tokens 數量是 TSV 的兩倍。這個差異不容小覷。設想一下，如果你在某個 API 的價格頁面上看到，選擇 JSON 格式的數據需要支付 1 美元，而 TSV 格式只需 0.5 美元，YAML 格式則是 0.8 美元。&lt;/p&gt; 
&lt;p&gt;當然，這些結果僅針對我們的示例數據。展示本圖表的目的並非要讓你認為 JSON 在所有情況下都會大量消耗 tokens，而是讓你相信值得用其他格式測試自己的數據。&lt;/p&gt; 
&lt;p&gt;接下來，我們來看看這些格式的響應時間。&lt;/p&gt; 
&lt;p&gt;儘管 JSON &quot;只&quot;需要兩倍於 TSV 的 tokens ，但其響應時間通常比 TSV 慢四倍。我原本以為 token 數量與響應時間之間的關係是近似線性的 ------ 接近 O(n)，因此如此誇張的響應時間出乎我的意料，我建議我們可以將這種現象的時間複雜度設為 O(my)。&lt;/p&gt; 
&lt;p&gt;將數據結構化輸出的響應時間還是蠻重要的，所以趕緊測試吧。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 侷限性與考慮因素&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;如果這些格式都同樣可靠和靈活，那麼結論就會很簡單：使用 TSV。但事實並非如此，所以讓我們對每一種格式進行更深入的瞭解。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 TSV&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在表示表格數據時，TSV 和 CSV 格式頗為相似，區別在於 TSV 使用製表符分隔每一行的數據，而 CSV 則採用逗號。如果數據中本身就包含逗號或製表符，那麼這些值就需要用雙引號括起來，這時兩種格式的 tokens 使用差異才會顯現。&lt;/p&gt; 
&lt;p&gt;由於製表符在數據中出現的頻率低於逗號，因此 TSV 在大多數情況下使用的分隔符數量會少於 CSV。&lt;/p&gt; 
&lt;p&gt;在解析數據時，TSV 與 CSV 相比 JSON，在純 Python 環境下解析起來略顯複雜。雖然可以利用 Python 內置的 csv 模塊進行解析，但使用 Pandas 庫會更加便捷。在其他編程語言中，解析這兩種格式要麼需要編寫更多代碼，要麼得依賴第三方庫。&lt;/p&gt; 
&lt;p&gt;如果數據中不含換行符，TSV 可以輕鬆地逐行解析。&lt;strong&gt;因此，若想從 LLM 流式傳輸響應數據並&lt;/strong&gt; 實時&lt;strong&gt;處理每一行數據，TSV（以及 CSV）都是不錯的選擇。雖然 TOML、YAML 和 JSON 也能實現類似功能，但處理起來會更加繁瑣。&lt;/strong&gt; 另外，本文尚未測試的 NDJSON 也是一個值得考慮的選項。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 CSV&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如前文所述，CSV 格式的挑戰在於逗號在數據中較為常見，這可能會導致兩種情況：要麼是需要更多的 tokens 來處理這些逗號，要麼是 LLM 在處理時未能正確進行轉義，從而產生錯誤的數據。因此，如果你的數據可能包含逗號，最好避免使用 CSV，或者設計一個詳盡的提示詞，並實施有效的評估流程，以便準確衡量其可靠性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;對於 TSV 和 CSV 兩種格式，你需要用那些可能包含特殊字符（如逗號、製表符、換行符和雙引號）的數據來測試你的系統配置。這樣，你才能確保系統能夠正確處理這些特殊情況。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 Columnar JSON&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Columnar JSON 並不是一個常見的技術術語；我之所以將它納入這次比較，是因為我很好奇它的 tokens 使用效率如何。&lt;/p&gt; 
&lt;p&gt;可能有些人還不清楚 Columnar JSON 是什麼樣的，下面就是前文提到的國家數據所對應的 Columnar JSON 格式：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9428ef8b78e0bdb835baea9f4cda42d717f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在所有格式中，Columnar JSON 的直觀性最差。但是，由於其結構特點，每個字段名只會出現一次，而不是每條記錄都重複，這樣就能節省 tokens。&lt;/p&gt; 
&lt;p&gt;我注意到，有時 LLM 能夠理解&quot;Columnar JSON&quot;的含義，但有時候需要一些額外的提示詞，例如：&quot;應以列名作為鍵名，對應的列內容以列表的形式組織呈現&quot;。&lt;/p&gt; 
&lt;p&gt;要解析 columnar JSON，你可以這樣將其傳遞給 Pandas 處理：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8742900bd0a0c9bd237f20e2e53833ad8be.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;與 CSV 和 TSV 不同，columnar JSON 支持嵌套的數據結構，因此它非常適合表示那些某些字段具有複雜結構的記錄列表。&lt;/p&gt; 
&lt;p&gt;這三種格式------TSV、CSV、columnar JSON------僅適用於表示表格數據，即以記錄列表為核心的結構。它們都不適合用來表示像配置文件這樣的單一 top-level object（譯者注：指在結構化數據格式（如 JSON/YAML/TOML）中，最外層定義的單一根對象，通常作為整個數據結構的入口點。）。而接下來的三種格式（YAML、TOML、JSON）則更為靈活多變。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.4 YAML&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;YAML 能夠返回一個 top-level list（譯者注：指在結構化數據格式中，最外層直接定義為列表結構而非對象。），但我注意到，某些 LLM 更傾向於生成一個 top-level object。因此，在給出提示詞時，我們需要明確指出，以確保 LLM 按照統一的格式返回數據。&lt;/p&gt; 
&lt;p&gt;我還遇到了一個問題，即 LLM 在返回字符串值時，格式可能會不一致。在某些情況下，這可能無關緊要，但 YAML 有五種不同的方式來表示字符串，而其中只有一種能夠正確解析轉義序列（例如\t, \u03B1）。因此，如果你的數據中包含轉義序列，那麼最好明確要求 LLM 使用雙引號來定義字符串。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;YAML 相較於 JSON，存在更多的&quot;陷阱&quot;和注意事項。建議你深入瞭解這些潛在的問題，而不是盲目地期待 LLM 能夠自動正確地格式化 YAML。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為瞭解析 YAML，你需要安裝一個第三方庫。我個人使用的是 pyyaml，這是一個無依賴的庫。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.5 TOML&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;TOML 是在此場景中唯一不支持 top-level list 的格式，因為它的設計初衷是作為一種配置文件格式。因此，若想用 TOML 來表示記錄列表，就必須將這些記錄包含在一個 top-level object 內，並告訴 LLM 你想在這個對象中調用什麼鍵。&lt;/p&gt; 
&lt;p&gt;TOML 在使用上通常會比 YAML 需要更多的 token，因為 TOML 要求所有的字符串值都必須用引號括起來。&lt;/p&gt; 
&lt;p&gt;在解析方面，如果你的 Python 版本是 3.11 或以上，那麼內置的 TOML 解析器[2]就可以直接使用。如果不是，那就需要安裝 tomlkit 或類似的庫來處理。&lt;/p&gt; 
&lt;p&gt;TOML 的普及度不及 YAML，你可能會擔心 LLM 在處理 TOML 格式時是否會遇到難題。但在我所使用的頂級 LLM 中，並沒有發現明顯的格式處理問題。我認為，TOML 相較於 YAML 的簡潔性在一定程度上彌補了這一普及度差距。而且，YAML 有多種方式可以表達相同的數據，這可能會降低 LLM 的確定性，使得兩種格式的可靠性相差無幾。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根據我的個人經驗，TOML 和 YAML 都可能出現錯誤，但這些錯誤通常可以通過更精確的提示詞來解決。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關於 YAML 中的字符串和轉義序列的問題，TOML 也同樣存在。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;總體而言，TOML 和 YAML 非常相似，TOML 需要更多的 token，不支持 top-level lists，但對於使用 Python 3.11 或以上版本的用戶來説，不需要額外的解析庫。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.6 JSON&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;關於 JSON，其實沒什麼特別需要強調的。它之所以能成為默認格式，是因為它用途廣泛、易於解析，而且出錯率低。只是它包含了大量的引號、逗號、冒號和換行符，這些都增加了 token 的數量，這一點稍顯遺憾。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，如果你想要使用 LLM 服務商提供的&quot;結構化數據模式&quot;，或者使用像 Guardrails[3]、Outlines[4] 這樣的結構化工具，JSON 往往是唯一的選擇。但我認為這種情況會隨着時間的推移而有所改變。隨着越來越多的基於 LLM 的應用投入實際使用，開發者會開始關注如何減少 token 使用等優化措施，LLM 服務商也會通過支持更多結構化數據格式來滿足這一需求。&lt;/p&gt; 
&lt;p&gt;理想的情況是，LLM 服務商能夠調整模型，使其能夠可靠地處理多種格式的數據，並在結構化數據模式中提供這些格式作為可選項。&lt;/p&gt; 
&lt;p&gt;這裏有一個注意事項：對於有關 LLM 在輸出特定格式時的可靠性方面的舊建議，我們應該保持謹慎。正如 OpenAI 在 2024 年 8 月的一篇博客文章中所提到的[5]，GPT-4 的早期版本在處理複雜的 JSON 測試時的正確率僅為 35%，而較新版本的 GPT-4 正確率則高達 85%。這在 GPT-4 系列中是一個巨大的飛躍。&lt;/p&gt; 
&lt;p&gt;這一點對於使用某些特殊功能或軟件包的人來説尤為重要，這些功能或軟件包可能會基於一年或更久之前的假設或證據來強制輸出結構化數據。你可能並不需要這些功能或軟件包，它們可能會迫使你使用 JSON，而實際上你可以選擇更經濟、更快捷的格式。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 實際應用&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在理論層面這些格式各有優勢，但假設你已經有了一套使用 JSON 的結構化數據處理系統，並且運行得很順暢。你知道 TSV 格式也能適用於你的數據，那麼是否有必要進行格式轉換呢？&lt;/p&gt; 
&lt;p&gt;如果你關注的是速度------因為人們需要等待 LLM 生成 token，那麼你需要評估等待時間的價值，這部分在這裏不展開討論。&lt;/p&gt; 
&lt;p&gt;但如果你只是在後台運行一個進程，這個問題就簡單多了。舉例來説，我們可以設定以下假設條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;你的時間成本是每天 1000 美元&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;將現有系統從 JSON 轉換為 TSV 需要半天時間&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;輸出 token 的費用是每百萬 0.60 美元&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;使用 TSV 可以減少 50% 的 token 使用量&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;你希望一年內收回投資&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們可以用一個小 Python 腳本來計算這些數值：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f69e9075bdd7f5c7bebe4b594c36a14407d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根據計算，如果你現在每天生成大約 4,566,210 個 JSON token，一年後就能實現收支平衡。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當然，你應該根據自己的實際情況來調整這些數值，但以下基準數據可供你參考。如果你每天只生成幾千個結構化數據的 token（並且不介意速度），那麼盲目調整數據格式的性價比極低。但如果你每天需要處理數千萬個 token，那麼探索其他格式絕對是一個划算的決定。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 總結&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;選擇默認的 JSON 格式確實很有吸引力，因為它靈活、穩定且解析起來簡單。但相對而言，它的處理速度較慢，成本也更高。因此，不妨考慮一下其他數據格式，做一些測試，挑選出既能控制成本又能保證穩定性和速度的最佳選項。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;David Gilbertson&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I like machine learning stuff.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你在實際項目中最常用哪種數據格式？遇到過哪些意想不到的問題？歡迎分享經驗👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中鏈接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fdavidgilbertson%2Ffcabb55478b4a4e1537a706f808b8b09&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/davidgilbertson/fcabb55478b4a4e1537a706f808b8b09&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Flibrary%2Ftomllib.html&quot; target=&quot;_blank&quot;&gt;https://docs.python.org/3/library/tomllib.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fguardrails-ai%2Fguardrails&quot; target=&quot;_blank&quot;&gt;https://github.com/guardrails-ai/guardrails&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdottxt-ai%2Foutlines&quot; target=&quot;_blank&quot;&gt;https://github.com/dottxt-ai/outlines&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-structured-outputs-in-the-api%2F&quot; target=&quot;_blank&quot;&gt;https://openai.com/index/introducing-structured-outputs-in-the-api/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavid-gilbertson.medium.com%2Fllm-output-formats-why-json-costs-more-than-tsv-ebaf590bd541&quot; target=&quot;_blank&quot;&gt;https://david-gilbertson.medium.com/llm-output-formats-why-json-costs-more-than-tsv-ebaf590bd541&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17883527</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17883527</guid>
            <pubDate>Thu, 06 Mar 2025 07:28:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>逆向分析 Github Copilot，探索代碼補全能力的實現細節</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;GitHub Copilot 是一種基於機器學習的代碼自動補全工具，它使用來自 GitHub 的大量代碼作為訓練數據，並結合 OpenAI 的語言模型來生成代碼。Copilot 還能學習用戶的編碼習慣，根據上下文推斷出正確的代碼片段。&lt;/p&gt; 
&lt;p&gt;為了探索其 VSCode 插件的實現，我們進行了以下逆向工程。&lt;/p&gt; 
&lt;h2&gt;準備工作&lt;/h2&gt; 
&lt;p&gt;由於 Copilot 沒有開源，我們需要進行一些逆向的準備。首先，找到 VSCode 插件的安裝目錄，拿到經過壓縮混淆的 extension.js。然後，通過分割 webpack_modules、識別模塊依賴、優化壓縮後的語法和 require 的模塊 id 取名等步驟，對代碼進行逆向處理。&lt;/p&gt; 
&lt;h2&gt;入口分析&lt;/h2&gt; 
&lt;p&gt;入口文件的模塊 id 是 91238，經過手動優化操作，可以大致還原其原始樣貌。在 VSCode 的 active 函數中，copilot 做了大量初始化工作，並將各個模塊的示例註冊到 context 中。&lt;/p&gt; 
&lt;h2&gt;代碼提示入口邏輯&lt;/h2&gt; 
&lt;p&gt;代碼提示邏輯在 registerGhostText 中註冊，主要通過 InlineCompletionItemProvider 實現。其核心邏輯包括判斷用戶是否關閉了 InlineSuggestEnable、document 是否在處理白名單內、用戶是否取消了輸入等，若不滿足條件則提前 return，不進行代碼提示。然後調用 getGhostText 方法獲取 texts，並通過 completionsFromGhostTextResults 拿到最終的 completions。&lt;/p&gt; 
&lt;h2&gt;getGhostText 核心邏輯&lt;/h2&gt; 
&lt;p&gt;getGhostText 是獲取提示代碼的核心方法，其邏輯包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;提取 Prompt：通過 extractprompt.extractPrompt 獲取 prompt 對象。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;邊界判斷：判斷是否包含在 .copilotignore 裏的文件、上下文是否太小、用戶是否已經取消等三種情況。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;二級緩存：保存上一次的 prefix 和 suffix，若當前請求的 prefix 和 suffix 與之前的一樣，則讀取緩存內容。若未命中緩存，計算當前的 prompt 是否在緩存範圍內，copilot 採取 LRU 緩存策略，默認緩存 100 條。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;真正發起請求：設置 Debounce 時延，判斷 contextualFilterScore 是否達到閾值，最後向後台發送 prompt 請求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-578f48c2e81b288fb7d2d52e2fac1803777.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;prompt 的組成&lt;/h2&gt; 
&lt;p&gt;prompt 由多種類型組合而成，包括 BeforeCursor、AfterCursor、SimilarFile、ImportedFile、LanguageMarker、PathMarker 等。不同類型的優先級通過 Priorities 輔助類設置，如 highSnippetPriority &amp;gt; beforeCursorPriority &amp;gt; importedFilePriority &amp;gt; lowSnippetPriority &amp;gt; pathMarkderPriority &amp;gt; languageMarkerPriority。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-49d262082d2bb695078a8c544ed9f9b431b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;抓包實驗&lt;/h2&gt; 
&lt;p&gt;通過抓包實驗，可以看到在 Copilot 發起的請求中，prompt 包含了 Path Marker 和 BeforeCursor 兩個部分。如果代碼相關性夠高，還會生成對應的 snippet。&lt;/p&gt; 
&lt;h2&gt;小結&lt;/h2&gt; 
&lt;p&gt;從 Copilot 中可以學到以下核心思想：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對於編輯器輸入的邊界判斷，包括太少、太多、取消等等很多場景齊全的考慮&lt;/li&gt; 
 &lt;li&gt;緩存思想，利用多級緩存策略保護後台，模型運算本身就是一件昂貴的事情&lt;/li&gt; 
 &lt;li&gt;prompt 的設計，不僅僅包含了上下文代碼，在文件解析、編輯器打開的相關代碼上還做了很多&lt;/li&gt; 
 &lt;li&gt;利用簡單的 Jaccard 算法計算分詞後的文本相似度，能夠快速決策出當前上下文相關的 snippet&lt;/li&gt; 
 &lt;li&gt;實驗特性，在 Copilot 中，大量的參數、優先級、設置字段都是通過實驗來控制的，有一套完整的監控上報體系，幫助 Copilot 去調整這些參數，以達到更好的效果&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmengjian-github%2Fcopilot-analysis&quot; target=&quot;_blank&quot;&gt;https://github.com/mengjian-github/copilot-analysis&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338373</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338373</guid>
            <pubDate>Thu, 06 Mar 2025 07:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Anthropic CEO：未來 3-6 個月內，90% 的代碼將由 AI 編寫</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Anthropic 首席執行官達 Dario Amodei 在 U.S. Foreign Relations Committee (CFR) 上&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fnews%2F16219&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，他認為在未來 3 到 6 個月內，90% 的代碼將由 AI 編寫；在 12 個月後，幾乎所有的代碼都可能由 AI 生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不過他也補充稱，雖然這一趨勢可能聽起來令人擔憂，但程序員在定義所需功能、應用程序設計和決策方面仍將發揮關鍵作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Amodei 表示，雖然人類程序員的參與仍將必不可少，但 AI 將逐漸承擔許多人類的任務。他鼓勵重新評估「有用」和「無用」的概念，並認為人類的生活仍將有意義，而 AI 將帶來新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;433&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1d6e1707a9e7f798d77cff8849380c0e52.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在被 CFR 主席 Mike Froman 問及關於「DeepSeek」是否可以被視為「Sputnik moment」時。Amodei 則認為，DeepSeek 並沒有什麼不尋常之處，只是成本降低曲線上的又一個數據點。他強調，人人都能編程的未來正在迅速到來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，OpenAI 首席執行官 Sam Altman 也在播客中分享了他對編程未來的看法。他認為，編程方法將在未來五到十年內發生重大變化，許多人已經使用自然語言進行編程，逐漸淘汰傳統的編碼方法。Altman 開玩笑稱，目前很少有人通過寫代碼來編程，這意味着編程的定義和所需技能將發生巨大變化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months</guid>
            <pubDate>Thu, 06 Mar 2025 07:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里巴巴董事局主席蔡崇信：AI 開源開放將讓中小企業受益</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 12 日上午，在新加坡舉辦的一場論壇中，阿里巴巴集團董事長蔡崇信分享了對 AI 開源開放的看法。他説，開源的力量在於令中小企業和創業者低成本使用 AI，未來的應用繁榮將受益於今天的開源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「技術進步的意義不在於中國是否擁有比美國更好的 AI，而是在於開源能夠普惠地幫助人們掌握 AI 的力量」，蔡崇信表示，AI 不是大企業的專屬遊戲，中小企業將受益於開源開放，未來應用繁榮將正是今天開源的結果。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在去年 11 月的 2024 年世界互聯網大會烏鎮峯會期間，阿里巴巴 CEO 吳泳銘在互聯網企業家論壇上表示，阿里巴巴目前已經發布了超過 100 個開源模型，累計下載量超過 4000 萬次。基於「通義千問」模型進行二次開發的衍生模型數量已突破 7.8 萬個，活躍開發者超過 800 萬。&lt;/p&gt; 
&lt;p&gt;據其介紹，目前已有超過 30 萬家企業接入通義大模型，利用 AI 技術重塑代碼開發、藥物研發、生產製造等多個行業。吳泳銘認為，行業「並不需要」眾多的基礎大模型，而是需要針對不同規模、不同領域的開源模型來滿足市場需求。&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/337397&quot; target=&quot;news&quot;&gt;阿里通義千問大模型登頂全球開源社區榜首&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333071&quot; target=&quot;news&quot;&gt;全球開源大模型前十均為阿里通義千問衍生模型&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338371</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338371</guid>
            <pubDate>Thu, 06 Mar 2025 07:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>上海徐匯：最高獎勵 3000 萬元，加快培育科技領軍企業</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海《徐彙區關於加快培育科技領軍企業的實施意見》已發佈。該，意見自 2025 年 2 月 24 日起試行，試行期二年。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《實施意見》明確了 10 個支持方向：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.支持高能級企業集聚發展。引導企業擴大投資、歸集核心職能，招引一批主營業務突出、競爭優勢明顯的高能級企業。加快吸引和促進符合區域產業發展導向的高能級企業，經綜合評估，可給予最高 1000 萬元的一次性支持；對行業影響力大、專業能力強、競爭優勢明顯的企業，經綜合評估，可給予不超過 3000 萬元的獎勵。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2.大力引進優質企業。發揮企業「標杆」導向作用，引進一批覈心技術能力強、引領產業發展集聚、市場佔有率高的高成長性企業。加快吸引和促進符合區域產業發展導向的高成長企業、潛力企業等，經綜合評估，可給予最高 500 萬元的一次性支持；對示範效應好、專業能力硬、發展潛力突出的企業，經綜合評估，可給予不超過 1500 萬元的獎勵。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3.支持企業規模化發展。支持企業做大做強，不斷集聚業務，提升規模能級和輻射能力，根據企業所屬行業領域、經營水平及成長髮展能力等綜合因素，經綜合評估，可給予不超過 3000 萬元的獎勵。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4.加快創新型企業梯隊建設。引導企業提升創新能級和核心競爭實力，壯大創新型領軍企業梯隊和「蓄水池」。對新增高新技術企業資質的，經認定，可給予最高 30 萬元獎勵；對重新認定高新技術企業資質的，經認定，可給予最高 10 萬元獎勵。對新增上海科技小巨人（培育）企業等資質，經認定，可給予一定資金支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;5.提升企業技術攻關能力。圍繞戰新產業和未來產業等領域，紮實推進「賽馬制」等攻關新模式，鼓勵企業加速研發創新，開展跨領域基礎研究或者顛覆性技術攻關，經評審，可給予不超過項目總投入 30%、最高 300 萬元的支持；鼓勵企業推動科研成果轉化落地、產業試點示範，經評審，可給予不超過項目總投入 30%、最高 1000 萬元的支持；主動服務企業開展研發費用稅前加計扣除、技術合同登記、技術先進型服務企業認定，並享受相應的支持政策。對技術合同成交額大幅提升的單位，經評審，可給予不超過 50 萬元的獎勵。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;6.支持標杆應用場景建設。鼓勵開展應用場景「揭榜掛帥」，支持企業建立針對應用場景的技術、產品和解決方案資源庫。對形成行業或區域標杆引領、示範效應帶動強的應用場景建設項目，經評審，可按不超過項目總投入的 30%,給予不超過 300 萬元的支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;7.支持創新合作發展。鼓勵企業充分利用區域豐富的科技創新資源開展創新創業活動，降低科技創新成本，激發科技創新動能，提升科技創新能級。支持科技企業申請科技創新服務券，經認定，給予每年不超過 80 萬元的支持。支持企業數字化轉型，對符合區域產業發展方向的企業購買雲計算等服務的，經綜合評估，可給予每年不超過 200 萬元的支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;8.加強市區聯動。支持企業申報國家、市級政策，對獲得市級及以上資金扶持的項目，結合區域或行業特點，對具有行業示範作用、競爭優勢顯著的項目，經綜合評估，可給予企業一定資金支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;9.做實做細人才服務保障。對用人單位引進的國內外優秀人才，按照相關政策推薦申請「光啓人才行動計劃」，並提供人才落戶、安居、醫療、出入境等方面便利化服務。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;10.打造高能級品牌活動。鼓勵企業發揮國際化、市場化、品牌化、專業化等資源優勢，舉辦或者承辦在行業領域內或者國內外具有較大影響力的創新或者產業活動，經評價，給予一定支持。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338370</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338370</guid>
            <pubDate>Thu, 06 Mar 2025 06:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek-R1 聯網搜索能力測評：騰訊元寶綜合實力領先</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 11 日，中文大模型測評基準 SuperCLUE &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fs_ZjP3tjxkyTVEPK_GucZg&quot; target=&quot;_blank&quot;&gt;發佈最新報告&lt;/a&gt;，測評了各平台接入 DeepSeek-R1 的聯網搜索能力，測評內容包括基礎檢索能力如文化生活、經濟生活、實時新聞等，以及分析推理能力如推理計算、分析排序、數據檢索與分析等，&lt;/p&gt; 
&lt;p&gt;測評結果顯示，騰訊元寶在 10 家接入 DeepSeek-R1 的平台中聯網搜索能力最強，在總分、基礎檢索能力和分析推理能力三項核心指標上均排名第一。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;4468&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0312/145142_W1Ch_2720166.png&quot; width=&quot;3488&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，本次測評模擬了用戶的真實搜索需求，考察 AI 在查找實時新聞、文化生活、經濟動態等信息時的準確度，以及在複雜問題上的推理計算、數據分析和排序能力。而據測試結果顯示，元寶在基礎檢索能力、分析推理能力均超越多個平台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338369</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338369</guid>
            <pubDate>Thu, 06 Mar 2025 06:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Podman Desktop 1.17 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Podman Desktop 1.17 現已&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpodman-desktop.io%2Fblog%2Fpodman-desktop-release-1.17&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;，此次發佈帶來了一些新功能和改進內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3688b5217b2e0c08738fab182fd8e779c2f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;新的運行工作流&lt;/strong&gt;&amp;nbsp;：只需幾步即可從鏡像啓動容器。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;301&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-65147053cb407644e58554ca245efee35ef.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;註冊鏡像配置&lt;/strong&gt;&amp;nbsp;：通過專用命令簡化註冊鏡像的設置。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;296&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9a0de9db5d21cf7c8d8b00f2f27ab9579a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;278&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f13919e9948beb0c68b67e97f3e223f8fbb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;更流暢的 kind 集羣體驗&lt;/strong&gt;&amp;nbsp;：輕鬆啓動 Kubernetes 集羣，無需預安裝 kind 二進制文件。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2fbbd33f4ac028e86ada307ada14b907604.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Podman 5.4&lt;/strong&gt;&amp;nbsp;：升級到最新的 Podman 引擎，提升性能和功能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Pods 重新定義&lt;/strong&gt;&amp;nbsp;：Podman pods 和 Kubernetes pods 之間清晰分離，提升可用性。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ecea9d2ae8ac16c0b8a1e6a5e180ece46b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Kubernetes 實驗模式&lt;/strong&gt;&amp;nbsp;：改變資源收集和監控的方式。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3fbafe477d14c57369d8cb90685b04213ce.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpodman-desktop.io%2Fblog%2Fpodman-desktop-release-1.17&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338355/podman-desktop-1-17-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338355/podman-desktop-1-17-released</guid>
            <pubDate>Thu, 06 Mar 2025 06:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>豆包文生圖技術報告發布，數據處理、預訓練、RLHF 全流程公開</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;豆包大模型團隊&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3E4s2c7TcWQ_g_6DdJPJkQ&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;文生圖技術報告，首次公開 Seedream 2.0 圖像生成模型技術細節，覆蓋數據構建、預訓練框架、 後訓練 RLHF 全流程。報告針對 Seedream 2.0 原生中英雙語理解、文字渲染、高美感、分辨率與畫幅變換等特性的實現，進行了具體介紹。&lt;/p&gt; 
&lt;p&gt;豆包大模型團隊文生圖模型 Seedream 2.0 於 2024 年 12 月初在豆包 APP 和即夢上線，相比 Ideogram 2.0、Midjourney V6.1、Flux 1.1 Pro 等主流模型，該模型更好解決了文本渲染能力欠佳、對中國文化理解不足等諸多實際問題，支持原生中英雙語，美感、指令遵循等能力有整體提升。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:rgba(0, 0, 0, 0.9)&quot;&gt;Seedream 2.0 採用了全新的預訓練架構設計，其整體框圖如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;274&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-457ee588823b38a7eef1e2ee5c0e9e855d4.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據介紹，團隊為了較全面客觀地評估模型，圍繞圖文匹配度、結構準確率、美感等基礎維度，嚴格構建了 Bench-240 評測基準。通過測試發現 Seedream 2.0 面向英文提示詞，其生成內容的結構合理性、文本理解準確性高於主流模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;459&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b1b01a3b00d4f19f14b66e8f4a52dca01a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中文綜合能力同樣突出，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;其生成與渲染文字可用率達 78%，完美響應率為 63%，高於業界目前其他模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;465&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e549ec802bb4d76bbba44b30474aebe0c15.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;公告稱，此次技術報告的發佈，旨在推動圖像生成技術進一步發展，加強業內交流。展望未來，團隊將持續探索更高效地 Scaling 模型參數及數據的創新技術，進一步提升模型的性能邊界。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;完整報告詳情可查看：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技術展示頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam.doubao.com%2Ftech%2Fseedream&quot; target=&quot;_blank&quot;&gt;https://team.doubao.com/tech/seedream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;技術報告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2503.07703&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2503.07703&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338350</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338350</guid>
            <pubDate>Thu, 06 Mar 2025 05:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節跳動 EB 級日誌系統設計與優化實踐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e27a1d3e532d1aab8b65d5203bac1eab.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   作者｜劉卯銀，火山引擎日誌系統架構師 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8942fd743308c45d84b2a600e94847fa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   日誌在可觀測技術發展的早期是用做故障回顧的。 我們通過 metrics 發現指標異常，比如成功率下降，然後通過 trace 找到了有異常的某個服務，最後才通過日誌找到具體的原因（接口返回異常）。 在現代日誌系統裏，這些都可以通過日誌來一站式解決： trace 本身就是一種特殊格式的日誌，metrics 可以通過日誌來實時生成。 
 &lt;/div&gt; 
 &lt;div&gt;
   日誌主要有三個明顯優勢： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     生成和採集非常容易，基本上各個編程語言都有日誌框架； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     採集是旁路的，不需要用戶系統做任何改造。日誌生成到文件，日誌採集器去讀文件後採集到日誌系統； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     保留了大量的細節。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   日誌的挑戰也很明確：日誌量大，流量容易突發，非結構化的數據難以利用。 
 &lt;/div&gt; 
 &lt;div&gt;
   本文將主要探討如何解決日誌面臨的挑戰。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;字節跳動日誌系統介紹&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;EB&lt;/strong&gt; 
  &lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;級日誌系統 TLS（Tinder&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt; 
  &lt;strong&gt;Log&lt;/strong&gt; 
  &lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Service）&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4921393194a0512d1f9e28b5aab33f7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   字節跳動在集團內部和火山引擎（公有云）是一套統一的日誌系統 TLS（Tinder Log Service），下面簡稱 TLS。集團內部包括抖音、頭條、飛書、懂車帝在內的大部分用戶的日誌都是在 TLS 上。用戶的日誌包含了運營、運維、審計和 Trace 等類型的日誌。TLS 對用戶提供採集、存儲、加工、查詢分析、告警、消費、投遞等功能。大家知道字節跳動的業務規模增長比較迅猛、最近的抖音電商也是快速增長，TLS 經受住了業務快速增長導致日誌規模快速增長的考驗。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;TLS 的演進&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//1de7b567db5294791cb60ea117e65c64.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   早期字節跳動沒有統一的日誌系統，各業務系統存在日誌需求，不得不各自自建，選用的方案五花八門，有基於 ELK 的，有基於 Clickhouse 的，也有基於對象存儲+Hive 的。自建的日誌系統存在穩定性不足、運維複雜、成本高、彈性不足等諸多痛點，於是我們構建了日誌的 1.0 系統。因為主要是運維日誌，我們調研了業內開源的一些方案，綜合需求和進度要求，最終選擇了類似 Loki 的方案。 
 &lt;/div&gt; 
 &lt;div&gt;
   Loki 是 Grafana 旗下一款開源的日誌低成本解決方案，沒有全文索引，查詢日誌主要通過掃描。日誌 1.0 的數據存儲在 HDFS 上，採用掃描式查詢，解決了自建系統的穩定性不足、運維複雜、成本高和彈性不足的問題。但是日誌 1.0 有一個問題沒有解決，那就是性能。因為沒有索引，所以查詢速度很慢，有同學調侃，查日誌的時間，都可以去泡杯咖啡了。 
 &lt;/div&gt; 
 &lt;div&gt;
   1.0 顯然不能滿足客戶的需求，所以我們又馬不停蹄的開發了日誌 2.0，我們在 1.0 的基礎上增加了自研的倒排索引，同時把底層存儲更換為了字節內部自研的池化存儲 bytestore，2.0 上線後查詢性能得到了很大的提升，所以我們把 trace 的數據也接入進來了。 
 &lt;/div&gt; 
 &lt;div&gt;
   隨着業務系統的進一步演進，只有索引還是不夠的，因為有很多用戶希望能基於日誌來做運營分析，需要實時的日誌報表分析，日誌告警等能力。因此我們又開發了日誌 3.0（TLS），我們認為 TLS 是一個比較現代且全面的日誌系統。日誌 3.0 在 2.0 的基礎上增加了列存、OLAP 分析引擎以及智能 AI 引擎，同時底層存儲也引入了高性能的混合存儲。為了滿足業務系統多樣性的需求，我們還加大了在生態兼容方面的投入，3.0 時代，日誌規模也達到了 EB 級。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;字節跳動日誌系統 TLS 的設計優化實踐&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;現代日誌系統的核心屬性&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a6dc3be41760eca4e05d1ac007090049.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   在我們看來，一個現代的日誌系統具備以下幾個方面的核心屬性： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     高性能：實時的日誌系統必須具備查詢分析百億行日誌秒級返回的能力。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     彈性&amp;amp;高可用：日誌的量不好預估、存在突發，必須要具備彈性能力；高可用是基本的穩定性訴求。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     高效率：海量的數據只有在成本足夠低的時候才能發揮出重要的價值，要讓用戶能用的起，所以要提升日誌系統的效率，降本增效。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     生態兼容：適應用戶業務系統的多樣性，讓更多的用戶能方便的接入，讓更多的日誌發揮出價值。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     豐富的功能：日誌加工、可視化儀表盤、日誌告警滿足用戶的多樣化需求，適應更多場景的日誌。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     智能化：智能化有兩個方面，一是日誌系統具備智能運維 AIOPS 的能力，包括日誌聚類、智能文本分析、機器學習算子；另外一個是提供智能助手，幫助用戶寫 SQL，寫正則，用自然語言生成圖表等。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;為高性能而設計的數據組織方式&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d89dae7feec9c09e8592344c89f02988.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   TLS 對外提供寫入、消費、查詢、分析四個數據面的重要接口，這幾個接口的性能決定了 TLS 的性能。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     日誌原文：日誌順序寫入，順序讀取，是消息隊列相似的接口，所以我們也按消息隊列的方式來組織數據。原文以 append 的方式寫入到底層存儲，順序讀取消費。我們按日誌到達服務端的時間構建了時間的稀疏索引，用於獲取消費位點。同時為了能夠對流量進行控制，我們引入了 shard 的概念，每個 shard 是一個順序的性能流，類似於 Kafka 的 partition，用戶需要保序的時候可以指定 shard 寫入，需要高性能的時候可以分散到多個 shard 做負載均衡。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     索引：用戶需要通過關鍵字查詢日誌原文，為了提升查詢效率，我們構建了倒排索引。倒排索引存儲了關鍵字和日誌行號的對應關係，查詢關鍵字的時候直接獲取日誌行號，不用做掃描查詢。用戶查詢是指定時間窗口查詢的，我們在索引裏存放了日誌的時間。為了減少查詢時間窗口內的數據量，我們做了個優化，把時間相近的日誌存放在一起，並以小時為切分單位來分組存放。查詢某一個小時內的日誌只需要處理對應小時的分組，其它小時的分組可以直接跳過。同時按小時分組存放還有一個好處，小時內的索引只需要存放小時內的時間，如果精確到秒用 0-3599（12 位） 就可以表示時間，大大縮小了時間字段的存儲空間。因為數據量少了，一次 I/O 可以讀更多的有效數據上來，也提升了時間過濾的效率。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     列存：OLAP 引擎分析數據最高效的就是列式存儲了，因為對某一個字段的聚合分析不需要讀取別的字段。還是上面的那個道理，相對於行存，列存一次 I/O 可以讀取更多的有效數據，自然就提升了性能。TLS 為了適應小流量的場景，列存的切分窗口設置為按天切分，如果按小時切分一些小流量的場景列存會切的太碎，I/O 太小讀取效率不高。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存儲：TLS 的這三種類型的數據都統一存放到了字節跳動內部的池化存儲 bytestore，池化存儲通過 EC 做數據冗餘，保證數據的可靠性。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;系統架構&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//afa92f12dcf5cc56ada63c05b8d8ab7c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   這是 TLS 的系統架構，分為存儲集羣、計算集羣和管控集羣。 重點介紹一下計算集羣的組件： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     API Gateway：用戶操作的統一入口； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     ShardServer：原文引擎，負責原文的寫入、消費、索引查詢到，行號後返回日誌原文； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Query：OLAP 查詢分析引擎，負責列存 SQL 分析和查詢結果的聚合； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     IndexServer：索引、列存的寫入構建； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     SearchServer：索引查詢。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   可以看到我們的系統架構遵循了三個原則： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存算分離：計算和存儲可以分別擴展，這是為了彈性而做出的選擇。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     讀寫分離：也是為了適應彈性做出的選擇。前面介紹過字節內部的日誌系統是從掃描查詢演進過來的，有非常重的讀，計算節點會把 100G 的網卡讀帶寬打滿。所以對我們來説，讀寫分離很重要，一方面是讀寫資源隔離，另一方面業務系統也在向索引查詢切換，需要足夠的彈性來支撐這種遷移。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     數據面和管控面分離：數據面和管控面是完全分離的。數據面有完整的配置信息緩存，管控面故障時，數據面的業務不會中斷。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;多級緩存和熱點消除&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a927c673fcd1414ef3c8a05655e75eed.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   增加緩存是提升性能最有效的手段，我們在系統的多個層級都設置了緩存。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     ShardServer：近期寫入的數據馬上就會被消費，所以 shardserver 在數據落盤的同時在內存裏保存了最近寫入的數據，保證索引消費、實時消費、投遞都能在緩存裏命中。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     IndexServer：緩存索引列存構建的元數據信息，包括索引、列存文件清單，索引的 meta 信息以及列存的 footer 信息，查詢的時候從 IndexServer 實時獲取才能查詢到最新的數據。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Query：Query 上有元數據緩存，中間結果緩存，數據緩存。重點提一下中間結果緩存：因為查詢分析命令大部分都是分析最近時間點的數據，所以直接緩存結果大多是無效的，我們需要的是一箇中間結果的緩存，聯合最新寫入的數據和之前查詢的中間結果緩存一起計算出當前查詢的結果後返回，中間結果的緩存命中率是很高的。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     SearchServer：Searchserver 的緩存和 query 類似，SearchServer 是索引查詢的緩存，query 是 SQL 分析的緩存。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Bytestore：Bytestore 上會緩存熱點數據，主要是對物理盤的緩存。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   緩存可以提升系統的性能，但緩存要麼是全局的，要麼就要有親和節點。我們的緩存是按節點親和的，會碰到一個問題：日誌的流量不太好預估，由於某些事件或者故障發生，日誌的量會出現井噴。調度的親和會造成節點的熱點，產生瓶頸。我們的解決方式是在每個服務的入口都設置隊列，當一個節點的隊列達到水位，説明這個節點已經有請求積壓了，處於繁忙狀態，這時候會返回 busy，發送節點會根據節點的負載情況，重新選擇一個負載低的節點進行重試，從而消除熱點。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;索引實時可見&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//04794f3416e8a9444744c2fb5e8289e7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   索引的實時可見是實時業務系統的需求。我們的日誌系統 TLS 已經應用到了實時業務場景，所以對從寫入成功到可以查詢的時間是有要求的，而索引和列存是一個批處理的數據結構，這決定了寫入到查詢不是立即可見的。用開源自建的小夥伴應該瞭解 ES 有一個 refresh_interval 參數來控制索引的可見時間，官方建議不能配置的太小，否則頻繁刷盤會影響性能。 
 &lt;/div&gt; 
 &lt;div&gt;
   能否兼顧性能和可見性？我們做了索引的內存可見，實測可以在 HDD 的場景把索引的可見性做到 3 秒以內。什麼是內存可見呢？數據到了 IndexWriter 後，先放在內存的 buffer 中，如果數據量比較大，buffer 達到設定大小後就開始構建索引寫盤，如果 3 秒還沒達到設定大小，我們在內存裏構建了索引的數據結構，查詢的時候可以從內存裏查，這就做到了索引的 3 秒可見。內存中的索引會有一定的淘汰策略，進行 merge 後刷盤。 
 &lt;/div&gt; 
 &lt;div&gt;
   需要注意，ES 有一個 translog ，用途是在掉電的時候恢復數據，而我們不需要 translog，因為我們有日誌原文，我們通過記錄原文消費的 offset 來記錄索引的構建進度。但如果處理的不好，內存構建的索引會有幻讀的問題，比如在內存中構建了索引，用戶也查詢到了，突然這個節點故障，內存裏的數據丟失，重新啓動後提供服務，之前已經查到的數據又查不到了，只有等索引從記錄的進度開始重新構建後才能查到，這就是幻讀。我們是通過一致性的視圖管理來解決幻讀的，通過 commit point 記錄了索引可見的進度，故障後重啓時只有當 commit point 之前的索引都構建好了才會讓用戶再次查詢到。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;EB 級日誌系統 TLS 的採集客戶端&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e5fe7270407f299ac067709dff0c7c27.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   系統的採集客戶端叫 LogCollector ，採用的是多 pipeline 的設計，目的是進行資源隔離、故障隔離。比如某個 output 出現問題，不會影響到其它的 output。在 pipeline 設置有自適應的反壓機制，輸出端慢採集速度也會放慢。在資源上採用的是資源共享和自動調配機制，每個 pipeline 有獨享的內存資源，還有一個全局的共享資源池以應對某些 pipeline 的流量突發。 
 &lt;/div&gt; 
 &lt;div&gt;
   為了應對 AI 時代訓練任務的需求，我們還開發了秒級生命週期的容器日誌採集能力，通過實時監控 K8s 的事件，做到啓動到退出生命週期只有幾秒的容器日誌能正常採集，不漏不丟。採集客戶端的性能非常重要，因為採集客戶端部署在用戶側，裝機量大，效率提升對成本的收益非常明顯。我們也持續在優化採集客戶端的性能，這些優化包括： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     批量處理：將日誌讀取一批後統一處理，降低了 Lock/Unlock 操作的次數，減少了日誌狀態等對象的內存分配頻率。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     並行處理：日誌的結構化全部併發多線程執行，提升了 CPU 密集型任務的處理的速率。雖然我們採集客戶端通常只配置 1C，但是因為有很多 I/O 操作，多線程是可以提高處理性能的。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     零拷貝技術：日誌讀取到結構化處理到 OutPut，共用一份內存，避免無效的內存拷貝性能開銷，省略非必要的編碼/解碼動作。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     內存池：對通用數據結構進行池化管理，減少內存碎片。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     其他（以 JSON 採集模式為例）：byte 級別直接操作 JSON 日誌，省略內存分配，避免類型轉換和反射，提高了 JSON 日誌的處理速度。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;如何應對業務的快速增長&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//bf22d05d45ee15c9c3a67bba5d11c5be.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   應對業務的快速增長，我們的策略是多 AZ、多集羣部署。TLS 對用戶看到是統一的 EB 級大集羣，實際內部是由多個小的集羣組成的。這樣設計有兩個方面的考慮，一是故障域隔離，減少故障爆炸半徑；二是能充分利用多個機房的資源，有這種靈活性才能拿到足夠多的機器應對業務突發上量。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存算分離：前面提到過存算分離，這裏再詳細説説。我們的存儲使用相對大一些的集羣，方便資源共享，而計算使用相對小的集羣，故障隔離，資源隔離。這樣做除了計算集羣和存儲集羣分別靈活擴展外，還有一個優勢：計算集羣支持離線升級。一個存儲集羣上有多個計算集羣，因為是共享存儲，在升級某個計算集羣的時，可以把待升級的集羣上的業務全部切到其他計算集羣，切走後在沒有業務流量的情況下升級計算集羣，升級完再逐漸把流量灰度切回來。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Serverless：所有的服務都是雲原生的，包括存儲都是 on K8s，讀寫服務資源隔離，分別靈活擴展。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     多集羣管理：因為有多個小的集羣，多集羣管理就非常重要了，彈性是通過多集羣管理來實現的，自動負載分配，自動負載均衡。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存儲集羣故障時切換：計算集羣故障時對業務是沒有影響的，快速切換集羣後只需要根據水位處理擴容。存儲集羣故障時，是不是業務就中斷了呢？我們在存儲集羣故障時做了一些降級處理的預案：因為日誌寫入不中斷很重要，寫入如果中斷有些 SDK 上傳的日誌就丟了，所以我們在存儲集羣故障時將寫入流量切換到新集羣，切換後寫數據不中斷，新寫入的數據在新集羣上也可查詢，只是歷史數據需要等待故障集羣恢復時才可查。有些用戶對日誌的穩定性要求更高，給我們提了 3AZ 高可用的需求，目前在規劃中。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;租戶隔離&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//40f2695e9e0560fc1a2bc8a329edf636.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   無論是公有云還是內部的系統，除非系統的建設是垂直隔離的孤島，都繞不開租戶隔離的問題。我們的處理策略是多點位的流控和資源控制，並且按照單請求/單 shard/單 topic/單租戶設置多個分級，控制住扇入和扇出。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     寫入和消費鏈路：寫入和消費是對用戶明確了系統的規格的，shard 就是讀寫的性能單元。為了防止一些異常的場景，我們還設置了租戶級別的流控： 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 shard/租戶的寫入帶寬流控，寫入 QPS 流控； 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 shard/租戶的讀取帶寬流控，讀取 QPS 流控。 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     查詢分析鏈路：查詢分析鏈路對用戶明確了單個 Topic 的併發控制 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 Topic /租戶的併發數流控 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     訪問存儲：訪問存儲的流控就是要控制扇出，當然存儲自己也會有控制扇入的流控，這裏是一個雙重保障。 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       分析引擎單 shard 掃描數據量的流控； 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       單節點訪問存儲的帶寬/QPS 流控。 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     資源控制：資源控制有三個方面的控制，CPU、內存的使用量、讀盤量： 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       分析引擎按請求/Topic/租戶的三級資源流控 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       查詢引擎按請求/Topic/租戶的三級資源流控 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       訪問存儲按 shard 設置了單次請求掃描的數據量 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;高效混合存儲&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8740a5a87fd84b6419330f7c131c145a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   開源自建的日誌系統，通常使用全 SSD，因為 HDD 的 IOPS 能力有限，需要做大量的優化，否則 HDD 的 IOPS 性能會成為系統的瓶頸。但是對於日誌的應用場景，HDD 比 SSD 更適合，因為日誌的讀寫都是順序 I/O，HDD 的帶寬能力是足夠的，且 HDD 沒有壽命問題、單位容量成本比 SSD 低很多，所以我們需要一個高效率的混合存儲，充分利用 SSD 的小 I/O 響應延遲以及 HDD 的低成本優勢。 
 &lt;/div&gt; 
 &lt;div&gt;
   通常的混合存儲是轉儲模型，數據先以 3 副本的方式寫入 SSD，然後後台 Dump 到 HDD。這種模型會有以下四個問題： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     三副本導致 SSD 的壽命和成本問題。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     小 I/O 性能差：SSD overlap 寫入的問題，小於 4KB 寫要對齊到 4KB，寫前擦除等。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     後台讀對 SSD 的壓力，dump 到 HDD 會有一次全量的數據讀。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     三副本導致的網絡流量放大（圖中箭頭旁邊的數字標識的是流量放大）。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   我們的高效混合存儲在架構上做了大的優化，實現了全流程的 EC 直寫。首先我們設置了一個 WAL log 層，整個節點上的所有寫請求匯聚成一條大的順序流，聚合後 EC 滿條帶寫入到 SSD，如果用戶下發的本身就是大 I/O，就會 bypassSSD 直寫 HDD。用戶的數據在 Membuffer 裏聚合，聚合到一定大小或者達到了強制刷盤的時間才下刷到 HDD。這麼設計後，用戶寫入的數據先給用戶返回成功後，在內存中充分聚合，充分聚合到滿條帶 EC 寫 HDD。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     寫 SSD 由副本變成了 EC，大幅減少寫入量和網絡流量。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     都是大塊 IO 寫 SSD、HDD。SSD 壽命、系統的吞吐量、訪問延遲都有極大的改善。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;私有編解碼協議&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9c56e3ab4521d805fbad7fff87cf6dfc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   我們發現日誌裏的 key 佔比通常會超過 30% ，而每條日誌的 key 幾乎都是一樣的，對於這種結構化的日誌，如果對 key 進行一個編碼，可以大幅縮減數據量。通常大家使用 ProtoBuffer 的標準編解碼在盤上存儲或在網絡上發送數據，Protobuffer 沒法對相同的 key 進行壓縮。因此我們自研了一個私有編解碼協議，把日誌的 key 映射成數字編碼，解碼的時候把數字再轉換為 key，把 key 到數字的映射存放在日誌裏，這樣 key 只有一次存儲，節省約 30% 的網絡數據傳輸和存儲空間。 
 &lt;/div&gt; 
 &lt;div&gt;
   同時日誌在流轉及查詢過程中，大部分場景不需要讀數據，只需要讀 header 裏的元數據。但是在 PB 編碼的情況下是需要對整個 PB 進行反序列化的，浪費大量的計算資源，增加了延遲。因此，在我們的私有化協議裏，把 head 和 data 分別編碼和壓縮，讀 head 的時候，只需要解壓和序列化 header，大幅提升了流轉過程中的解析速度。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;彈性&amp;amp;高性能&amp;amp;高效率的總結&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5d64d4c99bca66d81824a1c1f0cde2d7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;生態兼容實踐-輸入和輸出生態建設&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ed3fc149d567f7949b017a7ccd326150.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   我們認為最好的生態是支持標準協議的兼容的同時提供更高性能的私有接口，讓用戶有更多的兼容性選擇。在 TLS 上也在踐行這一套理念。 
 &lt;/div&gt; 
 &lt;div&gt;
   標準協議兼容：寫入和消費 TLS 支持標準的 Kafka 協議接口，OpenTelemetry 接口，S3 接口，在查詢分析側我們支持開源的 Grafana，支持 SQL92 標準的 SQL 命令，也提供了 ES 類似的 stringquery 接口。 
 &lt;/div&gt; 
 &lt;div&gt;
   私有高性能接口：日誌採集提供了高性能的採集客戶端 LogCollector、多語言 SDK，日誌消費提供了消費組和消費者的多語言 SDK，查詢分析側也提供了高性能的多語言 SDK。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;生態兼容實踐-Kafka 協議&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b8f3e272d4635df42cc17e0e5cb83d1.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   剛剛提到了開源的生態兼容，Kafka 協議是大數據生態的標準協議，使用範圍廣，因此我們選擇了兼容 Kafka 協議。由於底層存儲是共享存儲，因此不需要 Kafka 的副本機制，我們將 Kafka 改造成了一個存算分離的架構，共享日誌原文的存儲，可兼容 TLS 的輸入和輸入生態，支持採集過來的日誌用 Kafka 協議消費，也支持從 Kafka 協議導入的數據通過 SDK 進行消費。 
 &lt;/div&gt; 
 &lt;div&gt;
   在 Kafka 業務層面，保留了 Kafka 的 broker 和 coordinator 的實現邏輯，分別支持水平擴展，保留了對 Kafka 協議的兼容，用戶在使用的時候看到的是一個增強的 Serverless 的 Kafka。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;數據加工（ETL）&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c6c70061a30f5c0c306d3b8485cb90a8.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   數據加工是日誌數據結構化的一個必備功能，TLS 為用戶提供了簡單易用，類 Python 的日誌加工腳本語言，支持語法調試、執行預覽，很容易上手。用戶只需要簡單的編寫加工語句即可對日誌數據進行加工。日誌加工的工作流程是讀取源 Topic 內的日誌數據，根據用戶配置的加工語句對日誌進行過濾、富化、脫敏、分發的處理，然後輸入出到目的 Topic。TLS 提供了豐富的日誌加工函數，通過加工函數來便捷的加工日誌。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;日誌智能化的實踐—快速故障定位&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c81b69d6a108815d1707b3173d22ea7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   日誌系統的智能化目前在進行兩個方向的建設：智能運維和 AI 日誌助手。 
 &lt;/div&gt; 
 &lt;div&gt;
   智能運維主要是通過機器學習的聚類算法進行日誌聚類、文本分析、模板匹配；AI 助手主要是用自然語言去生成查詢分析語句，寫 SQL，配置正則表達式，生成圖表等。 
 &lt;/div&gt; 
 &lt;div&gt;
   這裏重點介紹下日誌智能化的應用。快速故障定位是火山引擎穩定性團隊的訴求，期望能夠藉助日誌實現【快速感知】【快速決策】【快速止損】【快速恢復】。我們的實現方式是：以存儲產品為例，首先將各個業務模塊的日誌都接入到日誌系統 TLS，在線上模擬常見的故障，根據日誌聚類的結果，將出現的日誌模板配置到對應的故障。下次出現類似的日誌 pattern 時，TLS 就會判斷出現了對應的故障，將結果以告警的形式推送，並直接明確故障類型，處理預案。線上出現故障後也可以提取模板，配置到故障庫裏，下次再出現類似的故障就會產生告警。同時 TLS 還支持故障的拓撲，在出現故障的時候明確出問題的節點。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;內容回顧&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7fde6e62c1aeda80fee1ffe37d99beb9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;用戶案例&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;內部案例：對象存儲日誌上雲&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a72c6c774c5eecc62c9dbbd8856f1083.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   字節跳動的對象存儲建設的比日誌系統早，早期對象存儲有對日誌的需求而集團沒有日誌系統，所以採用了自建。對象存儲團隊基於自己的業務需求，採用了 2 個採集 agent + 3 套日誌查詢系統來支撐業務。1 個 agent 採集實時日誌，用 filebeat，另一個 agent 自己開發，採集滾動後的歷史日誌，上傳到對象存儲降低成本。對於熱日誌使用 ES 做實時查詢，Hive 做離線分析。對於冷日誌，開發了一套掃描查詢引擎去詢對象存儲內的日誌。 
 &lt;/div&gt; 
 &lt;div&gt;
   對象存儲自建的這套系統建設複雜，運維成本高，3 個查詢入口查詢起來不方便，成本非常高，也沒有精力投入後續的優化。後來日誌系統 TLS 建立起來後，對象存儲果斷切換到 TLS，一次採集，多種應用集成，低成本多功能，免運維。切換後對象存儲的同學用起來非常滿意，後面把歷史冷日誌也導入了 TLS，他們專心於自己的業務能力建設。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;客戶案例—某國際旅行社&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f64a82deb3a93f255e50d75f65366264.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   該案例把火山引擎的日誌系統 TLS 當作一個在線的 OLAP 數據庫在使用。客戶為在線機票服務商，通過自己的搜索服務在各航空公司網站獲取機票報價信息，經過處理後，對線上的機票平台提供報價、訂單等服務，並對驗價異常、報價異常、訂單異常等實時告警。我們為客戶提供了日誌加工、運營大盤、檢索分析、日誌告警等功能。因為是在線的系統，TLS 的可用性、可靠性就非常重要，任何問題都會直接對客戶產生資損。目前客戶在 TLS 上運行 2 年多，非常平穩。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;下一步展望&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//4dc9f33845d62e01dbc4f91aea73d489.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;關於作者&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   劉卯銀，火山引擎日誌系統架構師 ，現負責火山引擎日誌系統的設計、研發和架構技術演進。從 0 到 1 構建了火山引擎雲原生日誌系統 TLS，並主導了日誌系統架構的升級換代。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   資料來源： 
  &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2Farticles%2F7389141787136229403&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;字節跳動 EB 級日誌系統設計與優化實踐 - 文章 - 開發者社區 - 火山引擎&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/6800876/blog/17884414</link>
            <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/17884414</guid>
            <pubDate>Thu, 06 Mar 2025 05:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>