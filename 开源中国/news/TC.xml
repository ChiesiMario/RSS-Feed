<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Tue, 12 Aug 2025 07:43:54 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>馬斯克：xAI 將對蘋果採取法律行動</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;埃隆·馬斯克當地時間 8 月 11 日在社交平台發文稱，蘋果公司涉嫌通過限制措施，使除美國開放人工智能研究中心（OpenAI）外的任何人工智能公司都無法在其應用商店排行榜中登頂，稱此為「明確的反壟斷違規行為」。馬斯克表示，其旗下 xAI 公司將立即採取法律行動。&lt;/p&gt; 
&lt;p&gt;&lt;img height="272" src="https://oscimg.oschina.net/oscnet/up-77b6ba53d5b9d23dcb776934627a6b8c4cb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管馬斯克的指控引發了廣泛關注，但他並未提供具體證據來支持自己的説法。截至 8 月 12 日，ChatGPT 正佔據美國 App Store 的榜首位置。值得一提的是，OpenAI 和蘋果去年宣佈了一項合作關係，將 ChatGPT 集成到蘋果的智能系統中，以增強圖像和文檔理解等多項功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在馬斯克的指控後，OpenAI 首席執行官山姆・奧特曼也在社交平台上做出了回應。他表示，「這一指控非常引人注目，尤其是在我聽到的關於馬斯克如何操縱 X 以便讓自己及其公司獲益、並損害競爭對手及不喜歡的人的情況下。」 這一爭論進一步加劇了馬斯克與奧特曼之間本已緊張的關係，兩人曾經在 OpenAI 共事。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;奧特曼在文中提到我希望有人能進行反向取證，我們都想知道究竟發生了什麼。不過，OpenAI 將繼續專注於開發優秀的產品。」 與此同時，社交媒體上有許多人質疑馬斯克的説法，指出除了 ChatGPT 外，許多其他人工智能應用程序 App Store 上也曾登上過榜首。例如，來自中國的 DeepSeek 應用一度成為榜首，而自稱與 ChatGPT 競爭的 Perplexity 最近在印度的 App Store 中也取得了&lt;span&gt;第一&lt;/span&gt;的位置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365734</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:21 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 亮相首屆世界 RISC-V 日，分享最新 RISC-V 進展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 8 日，由 RISC-V 國際基金會重磅推出的首屆世界 RISC-V 日 (World RISC-V Days) 在北京開源芯片研究院舉行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//3f4075ef6e79ddf2ab5c098c63d555b7.jpg" width="840" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;deepin 社區技術委員會成員、苦芽科技工程師李程&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;參加了此活動，並於會議上帶大家系統回顧了 deepin-ports SIG 的發展歷程，並重點分享了 deepin-ports SIG 在 RISC-V 方向上的最新進展，包括但不限於 deepin RISC-V 生態適配、社區協作模式優化等方面。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//10b8829d40f7888c675d6790b227fb75.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;李程，deepin 社區技術委員會成員、苦芽科技工程師&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;deepin 對 RISC-V 架構的支持並非一日之功。自 2022 年 2 月起，deepin 就建立了對應 SIG，開始了 RISC-V 架構的適配工作，現已成功支持了大量主流的 RISC-V 硬件和開發板。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在軟件方面，deepin 也完成了對 RISC-V 開源軟件生態的適配，提供了超過 27,000 個軟件包，併為 RISC-V 開發板提供了內核、GPU、VPU、NPU 等驅動解決方案，確保了這些關鍵組件能夠長期、及時、良好地維護。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//92d10ca4ef881324c89df1a23d1a392e.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;作為中國桌面操作系統的核心力量，deepin 積極響應國家戰略，深度參與「甲辰計劃」，全力投入 RISC-V 開源新生態建設。迄今，deepin 操作系統已成功適配了幾乎所有可公開獲取的桌面級 RISC-V 設備，並提供了關鍵的 GPU、NPU、VPU 等硬件加速支持。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 23&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 穩定版及 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 25 預覽版&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;均已為 RISC-V 平台提供官方鏡像並持續更新。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;通過在硬件適配、軟件生態構建、社區協作及戰略規劃上的不懈努力，deepin 已成為 RISC-V 生態的重要貢獻者，並有力推動着 RISC-V 桌面操作系統的普及與應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//7215a0a6d6d54c51ac5e45faa8fd4f4a.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;李程還介紹到，deepin 作為「甲辰計劃」的重要參與社區之一，為給更多同學提供深入 deepin、RISC-V 等技術項目的機會，將與甲辰計劃聯合提供近 80 個實習 HC。李程先生將作為該實習崗位的首席導師（Principle Mentor），協調實習工作內容，並負責 mentor 的招募和崗前培訓。進一步瞭解：&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA5NzE0Mjg4Ng%3D%3D%26mid%3D2650457142%26idx%3D2%26sn%3D4b83559f9c00f28f1df379af82b1ab5a%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;span&gt;新增實習機會！RISC-V deepin 操作系統開發實習生正在招募&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;由於時間限制未設置現場問答環節，但與會者還是對技術路線和實習計劃展現出了濃厚興趣，眾多參會者主動拍攝 PPT 關鍵內容頁，期待進一步交流探討。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//cd1393b25b25a0f66f8bf6cc4337cb36.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;附：&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;deepin-ports SIG 主頁：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://github.com/deepin-community/sig-deepin-ports&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365735</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:21 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Rust 性能提升 「最後一公里」：詳解 Profiling 瓶頸定位與優化</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、Profiling：揭示性能瓶頸的"照妖鏡"&lt;/h1&gt; 
&lt;p&gt;在過去的一年裏，我們團隊完成了一項壯舉：將近萬核的 Java 服務成功遷移到 Rust，並收穫了令人矚目的性能提升。我們的實踐經驗已在《RUST 練習生如何在生產環境構建萬億流量》一文中與大家分享。然而，在這次大規模遷移中，我們觀察到一個有趣的現象：大多數服務在遷移後性能都得到了顯著提升，但有那麼一小部分服務，性能提升卻不盡如人意，僅僅在 10% 左右徘徊。&lt;/p&gt; 
&lt;p&gt;這讓我們感到疑惑。明明已經用上了性能"王者"Rust，為什麼還會遇到瓶頸？為瞭解開這個謎團，我們決定深入剖析這些"低提升"服務。今天，我就來和大家分享，我們是如何利用 &lt;strong&gt;Profiling&lt;/strong&gt; &lt;strong&gt;工具&lt;/strong&gt;，找到並解決寫入過程中的性能瓶頸，最終實現更高性能飛躍的！&lt;/p&gt; 
&lt;p&gt;在性能優化領域，盲目猜測是最大的禁忌。你需要一把鋒利的"手術刀"，精準地找到問題的根源。在 Rust 生態中，雖然不像 Java 社區那樣擁有 VisualVM 或 JProfiler 這類功能強大的成熟工具，但我們依然可以搭建一套高效的性能分析體系。&lt;/p&gt; 
&lt;p&gt;為了在生產環境中實現高效的性能監控，我們引入了 &lt;strong&gt;Jemalloc&lt;/strong&gt; 內存分配器和 &lt;strong&gt;pprof&lt;/strong&gt; CPU 分析器。這套方案不僅支持定時自動生成 Profile 文件，還可以在運行時動態觸發，極大地提升了我們定位問題的能力。&lt;/p&gt; 
&lt;h1&gt;二、配置項目：讓 Profiling"武裝到牙齒"&lt;/h1&gt; 
&lt;p&gt;首先，我們需要在 Cargo.toml 文件中添加必要的依賴，讓我們的 Rust 服務具備 Profiling 的能力。以下是我們的配置，Rust 版本為 1.87.0。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[target.'cfg(all(not(target_env = "msvc"), not(target_os = "windows")))'.dependencies]
# 使用 tikv-jemallocator 作為內存分配器，並啓用性能分析功能
tikv-jemallocator = { version = "0.6", features = ["profiling", "unprefixed_malloc_on_supported_platforms"] }
# 用於在運行時控制和獲取 jemalloc 的統計信息
tikv-jemalloc-ctl = { version = "0.6", features = ["use_std", "stats"] }
# tikv-jemallocator 的底層綁定，同樣啓用性能分析
tikv-jemalloc-sys = { version = "0.6", features = ["profiling"] }
# 用於生成與 pprof 兼容的內存剖析數據，並支持符號化和火焰圖
jemalloc_pprof = { version = "0.7", features = ["symbolize","flamegraph"] }
# 用於生成 CPU 性能剖析數據和火焰圖
pprof = { version = "0.14", features = ["flamegraph", "protobuf-codec"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;簡單來説，這幾個依賴各司其職：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ tikv-jemallocator&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基於 jemalloc 的 Rust 實現，以其高效的內存管理聞名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ jemalloc_pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;負責將 jemalloc 的內存剖析數據轉換成標準的 pprof 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用於 CPU 性能分析，可以生成 pprof 格式的 Profile 文件。&lt;/p&gt; 
&lt;h1&gt;三、 全局配置：啓動 Profiling 開關&lt;/h1&gt; 
&lt;p&gt;接下來，在 main.rs 中進行全局配置，指定 &lt;strong&gt;Jemalloc&lt;/strong&gt; 的 &lt;strong&gt;Profiling&lt;/strong&gt; 參數，並將其設置為默認的全局內存分配器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 配置 Jemalloc 內存分析參數
#[export_name = "malloc_conf"]
pub static malloc_conf: &amp;amp;[u8] = b"prof:true,prof_active:true,lg_prof_sample:16\0";


#[cfg(not(target_env = "msvc"))]
use tikv_jemallocator::Jemalloc;


// 將 Jemalloc 設置為全局內存分配器
#[cfg(not(target_env = "msvc"))]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這段配置中的 lg_prof_sample:16 是一個關鍵參數。&lt;/p&gt; 
&lt;p&gt;它表示 jemalloc 會對大約每 2^16 字節（即 64KB）的內存分配進行一次採樣。這個值越大，採樣頻率越低，內存開銷越小，但精度也越低；反之則精度越高，開銷越大。在生產環境中，我們需要根據實際情況進行權衡。&lt;/p&gt; 
&lt;h1&gt;四、實現 Profile 生成函數：打造你的"數據採集器"&lt;/h1&gt; 
&lt;p&gt;我們將 Profile 文件的生成邏輯封裝成異步函數，這樣就可以在服務的任意時刻按需調用，非常靈活。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內存 Profile 生成函數&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_memory_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    // 獲取 jemalloc 的 profiling 控制器
    let prof_ctl = jemalloc_pprof::PROF_CTL.as_ref()
        .ok_or_else(|| "Profiling controller not available".to_string())?;


    let mut prof_ctl = prof_ctl.lock().await;
    
    // 檢查 profiling 是否已激活
    if !prof_ctl.activated() {
        return Err("Jemalloc profiling is not activated".to_string());
    }
   
    // 調用 dump_pprof() 方法生成 pprof 數據
    let pprof_data = prof_ctl.dump_pprof()
        .map_err(|e| format!("Failed to dump pprof: {}", e))?;


    // 使用時間戳生成唯一文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("memory_profile_{}.pb", timestamp);


    // 將 pprof 數據寫入本地文件
    std::fs::write(&amp;amp;filename, pprof_data)
        .map_err(|e| format!("Failed to write profile file: {}", e))?;


    info!("Memory profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU Profile 生成函數&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;類似地，我們使用 pprof 庫來實現 CPU &lt;strong&gt;Profile&lt;/strong&gt; 的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_cpu_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    use pprof::ProfilerGuard;
    use pprof::protos::Message;


    info!("Starting CPU profiling for 60 seconds...");


    // 創建 CPU profiler，設置採樣頻率為 100 Hz
    let guard = ProfilerGuard::new(100).map_err(|e| format!("Failed to create profiler: {}", e))?;


    // 持續採樣 60 秒
    tokio::time::sleep(std::time::Duration::from_secs(60)).await;


    // 生成報告
    let report = guard.report().build().map_err(|e| format!("Failed to build report: {}", e))?;


    // 使用時間戳生成文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("cpu_profile_{}.pb", timestamp);


    // 創建文件並寫入 pprof 數據
    let mut file = std::fs::File::create(&amp;amp;filename)
        .map_err(|e| format!("Failed to create file: {}", e))?;


    report.pprof()
        .map_err(|e| format!("Failed to convert to pprof: {}", e))?
        .write_to_writer(&amp;amp;mut file)
        .map_err(|e| format!("Failed to write profile: {}", e))?;


    info!("CPU profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ProfilerGuard::new() 100 Hz 意味着每秒鐘會隨機中斷程序 &lt;strong&gt;100 次&lt;/strong&gt;，以記錄當前正在執行的函數調用棧&lt;/li&gt; 
 &lt;li&gt;tokio::time::sleep(std::time::Duration::from_secs(60)).await 表示 pprof 將會持續採樣 60 秒鐘&lt;/li&gt; 
 &lt;li&gt;guard.report().build() 這個方法用於將收集到的所有采樣數據進行處理和聚合，最終生成一個 Report 對象。這個 Report 對象包含了所有調用棧的統計信息，但還沒有轉換成特定的文件格式&lt;/li&gt; 
 &lt;li&gt;report.pprof() 這是 Report 對象的一個方法，用於將報告數據轉換成 pprof 格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;五、 觸發和使用 Profiling：隨時隨地捕捉性能數據&lt;/h1&gt; 
&lt;p&gt;有了上述函數，我們實現了兩種靈活的觸發方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 定時自動生成&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過異步定時任務，每隔一段時間自動調用 dump_memory_profile() 和 dump_cpu_profile() 。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn start_profilers() {
    // Memory profiler
    tokio::spawn(async {
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(300));
        loop {
            interval.tick().await;
            #[cfg(not(target_env = "msvc"))]
            {
                info!("Starting memory profiler...");
                match dump_memory_profile().await {
                    Ok(profile_path) =&amp;gt; info!("Memory profile dumped successfully: {}", profile_path),
                    Err(e) =&amp;gt; info!("Failed to dump memory profile: {}", e),
                }
            }
        }
    });
    // 同理可以實現 CPU profiler
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 手動 HTTP 觸發&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過提供 /profile/memory 和 /profile/cpu 兩個 HTTP 接口，可以隨時按需觸發 Profile 文件的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;async fn trigger_memory_profile() -&amp;gt; Result&amp;lt;impl warp::Reply, std::convert::Infallible&amp;gt; {
    #[cfg(not(target_env = "msvc"))]
    {
        info!("HTTP triggered memory profile dump...");
        match dump_memory_profile().await {
            Ok(profile_path) =&amp;gt; Ok(warp::reply::with_status(
                format!("Memory profile dumped successfully: {}", profile_path),
                warp::http::StatusCode::OK,
            )),
            Err(e) =&amp;gt; Ok(warp::reply::with_status(
                format!("Failed to dump memory profile: {}", e),
                warp::http::StatusCode::INTERNAL_SERVER_ERROR,
            )),
        }
    }
}
//同理也可實現 trigger_cpu_profile() 函數

fn profile_routes() -&amp;gt; impl Filter&amp;lt;Extract = impl Reply, Error = warp::Rejection&amp;gt; + Clone {
    let memory_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("memory"))
        .and(warp::path::end())
        .and_then(trigger_memory_profile);
    
    
    let cpu_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("cpu"))
        .and(warp::path::end())
        .and_then(trigger_cpu_profile);
    memory_profile.or(cpu_profile)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，我們就可以通過 curl 命令，隨時在生產環境中採集性能數據了：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:8080/profile/memory
curl -X POST http://localhost:8080/profile/cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;生成的 .pb 文件，我們就可以通過 go tool pprof 工具，啓動一個交互式 Web UI，在瀏覽器中直觀查看調用圖、火焰圖等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go tool pprof -http=localhost:8080 ./target/debug/otel-storage ./otel_storage_cpu_profile_20250806_032509.pb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;六、性能剖析：火焰圖下的"真相"&lt;/h1&gt; 
&lt;p&gt;通過 go tool pprof 啓動的 Web UI，我們可以看到程序的&lt;strong&gt;火焰圖&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何閲讀火焰圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 頂部：&lt;/strong&gt; 代表程序的根函數。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 向下延伸；&lt;/strong&gt; 子函數調用關係。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 火焰條的寬度：&lt;/strong&gt; 代表該函數在 CPU 上消耗的時間。&lt;strong&gt;寬度越寬，消耗的時間越多，越可能存在性能瓶頸&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8b814e239f61ed1c970231bc444f3896a50.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU Profile&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-55883adfb3cf12d5390b652452d3f883d17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Memory Profile&lt;/p&gt; 
&lt;p&gt;在我們的 CPU 火焰圖中，一個令人意外的瓶頸浮出水面：&lt;strong&gt;OSS::new&lt;/strong&gt; 佔用了約 19.1% 的 CPU 時間。深入分析後發現， OSS::new 內部的 TlsConnector 在每次新建連接時都會進行 TLS 握手，這是導致 CPU 佔用過高的根本原因。&lt;/p&gt; 
&lt;p&gt;原來，我們的代碼在每次寫入 OSS 時，都會新建一個 OSS 實例，隨之而來的是一個全新的 HTTP 客戶端和一次耗時的 TLS 握手。儘管 oss-rust-sdk 內部有連接池機制，但由於我們每次都創建了新實例，這個連接池根本無法發揮作用！&lt;/p&gt; 
&lt;h1&gt;七、優化方案：從"每次新建"到"共享複用"&lt;/h1&gt; 
&lt;p&gt;問題的核心在於重複創建 OSS 實例。我們的優化思路非常清晰：&lt;strong&gt;複用 OSS 客戶端實例，避免不必要的 TLS 握手開銷&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每次寫入都新建 OSS 客戶端。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn write_oss() {
    // 每次寫入都新建一個 OSS 實例
    let oss_instance = create_oss_client(oss_config.clone());
    tokio::spawn(async move {
        // 獲取寫入偏移量、文件名
        // 構造 OSS 寫入所需資源和頭信息
        // 寫入 OSS
        let result = oss_instance
            .append_object(data, file_name, headers, resources)
            .await;
}
fn create_oss_client(config: OssWriteConfig) -&amp;gt; OSS {
    OSS::new(
    ......
    )
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種方案在流量較小時可能問題不大，但在萬億流量的生產環境中，頻繁的實例創建會造成巨大的性能浪費。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 共享實例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;讓每個處理任務（ DecodeTask ）持有 Arc 共享智能指針，確保所有寫入操作都使用同一個 OSS 實例。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;let oss_client = Arc::new(create_oss_client(oss_config.clone()));
let oss_instance = self.oss_client.clone(); 
// ...
let result = oss_instance
    .append_object(data, file_name, headers, resources)
    .await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 自動重建機制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了應對連接失效或網絡問題，我們引入了自動重建機制。當寫入次數達到閾值或發生寫入失敗時，我們會自動創建一個新的 OSS 實例來替換舊實例，從而保證服務的健壯性。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 使用原子操作確保多線程環境下的計數安全
let write_count = self.oss_write_count.load(std::sync::atomic::Ordering::SeqCst);
let failure_count = self.oss_failure_count.load(std::sync::atomic::Ordering::SeqCst);


// 檢查是否需要重建實例...
fn recreate_oss_client(&amp;amp;mut self) {
 
    let new_oss_client = Arc::new(create_oss_client(self.oss_config.clone()));
    self.oss_client = new_oss_client;
    self.oss_write_count.store(0, std::sync::atomic::Ordering::SeqCst);
    self.oss_failure_count.store(0, std::sync::atomic::Ordering::SeqCst);
    // 記錄 OSS 客戶端重建次數指標
    OSS_CLIENT_RECREATE_COUNT
        .with_label_values(&amp;amp;[])
        .inc();
    info!("OSS client recreated");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;八、優化效果：性能數據"一飛沖天"&lt;/h1&gt; 
&lt;p&gt;優化後的服務上線後，我們觀察到了顯著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 資源使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降約 &lt;strong&gt;20%&lt;/strong&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-68b2935d6632ee730c0dc6ac3155a4257a4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OSS 寫入耗時&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降約 &lt;strong&gt;17.2%&lt;/strong&gt; ，成為集羣中最短的寫入耗時。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 寫入耗時&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18a1b33fff58596e3d4317f4035511a8eca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 相關資源只佔千分之一&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f35812df10896bc3430f0020571b4ab2e03.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內存使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;平均下降 &lt;strong&gt;8.77%&lt;/strong&gt; ，這部分下降可能也得益於我們將內存分配器從 &lt;strong&gt;mimalloc&lt;/strong&gt; 替換為 &lt;strong&gt;jemalloc&lt;/strong&gt; 的綜合效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-863bda3bf8f46a11ceeffef27808d64c90d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這次優化不僅解決了特定服務的性能問題，更重要的是，它驗證了在 Rust 中通過 Profiling 工具進行深度性能分析的可行性。即使在已經實現了初步性能提升的 Rust 服務中，仍然存在巨大的優化空間。&lt;/p&gt; 
&lt;p&gt;未來，我們將繼續探索更高效的 Profiling 方案，並深入挖掘其他潛在的性能瓶頸，以在萬億流量的生產環境中實現極致的性能和資源利用率。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;引用&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub - tikv/jemallocator: Rust allocator using jemalloc as a backend&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrates.io%2Fcrates%2Fjemalloc_pprof" target="_blank"&gt;https://crates.io/crates/jemalloc_pprof&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub - google/pprof: pprof is a tool for visualization and analysis of profiling data&lt;/li&gt; 
 &lt;li&gt;Use Case: Heap Profiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjemalloc.net%2Fjemalloc.3.html%23heap_profile_format" target="_blank"&gt;https://jemalloc.net/jemalloc.3.html#heap_profile_format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.brendangregg.com%2Fflamegraphs.html" target="_blank"&gt;https://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagiroux.com%2Frust-jemalloc-profiling" target="_blank"&gt;https://magiroux.com/rust-jemalloc-profiling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.Valkey 單點性能比肩 Redis 集羣了？Valkey8.0 新特性分析｜得物技術&lt;/p&gt; 
&lt;p&gt;2.Java volatile 關鍵字到底是什麼｜得物技術&lt;/p&gt; 
&lt;p&gt;3.社區搜索離線回溯系統設計：架構、挑戰與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;4.正品庫拍照 PWA 應用的實現與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;5.得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;文 / 炯帆，南風&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687884</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687884</guid>
      <pubDate>Tue, 12 Aug 2025 07:23:21 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Linux Turbostat 工具可顯示 CPU L3 緩存拓撲信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 6.17 內核源代碼樹中 Turbostat 工具的更新已完成合並&lt;/p&gt; 
&lt;p&gt;Turbostat 是一款命令行工具，用於顯示 CPU 頻率/空閒/功耗統計信息以及其他相關的處理器信息，主要針對 Intel 和 AMD 處理器。值得注意的是，Linux 6.17 中的 Turbostat 增加了顯示 L3 緩存拓撲信息的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cf186a887af4b06f2d0a899e1a4af7834c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Turbostat 還新增了對新增計數器（例如累計瓦特和其他計數器）進行平均的功能，修復了對即將推出的英特爾至強 Diamond Rapids 處理器的支持。&lt;/p&gt; 
&lt;p&gt;由於部分型號特定寄存器 (MSR) 的變更，Turbostat 需要進行更多調整，以便正確顯示 Granite Rapids 後續的下一代至強處理器的功耗和性能相關詳細信息。&lt;/p&gt; 
&lt;p&gt;此外，Turbostat 還修復了針對 musl libc 的構建問題以及其他各種修復。更多詳情，請訪問&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAJvTdKmaTvaQiRjgz_Pr6a%2BXEkLzEnedujV%3Dvqwv5thEE63fdg%40mail.gmail.com%2F" target="_blank"&gt;此 pull request&lt;/a&gt;，該請求已合併至 Linux Git。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365725</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365725</guid>
      <pubDate>Tue, 12 Aug 2025 07:08:21 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 服務突發全面宕機，官方深夜回應：網頁/API 已恢復</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;8 月 11 日，DeepSeek 服務突遭全面宕機，API 接口、網頁平台以及 App 均無法訪問或響應。&lt;/p&gt; 
&lt;p&gt;許多網友也通過微博話題 #DeepSeek 崩了# 反饋服務異常。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/144904_mWWF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據 DeepSeek 在官網發佈的公告，DeepSeek 網頁/API 已恢復。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/145101_JSbh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;公告內容如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;21:55，該問題已被發現並正在實施修復；&lt;/li&gt; 
 &lt;li&gt;22:28，已定位到問題，服務正在逐漸恢復中；&lt;/li&gt; 
 &lt;li&gt;23:12，大部分服務已經恢復正常；&lt;/li&gt; 
 &lt;li&gt;23:39，此事件已得到解決。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365719</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365719</guid>
      <pubDate>Tue, 12 Aug 2025 06:51:21 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>文件系統 Btrfs 為 Meta 節省了數十億美元的基礎設施成本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在關於 Bcachefs 在主線 Linux 內核中的未來走向&amp;nbsp;的持續討論中，有人提到了一件關於 Btrfs 的有趣軼事。&lt;/p&gt; 
&lt;p&gt;Meta（Facebook）長期以來一直是 Btrfs 文件系統最傑出的使用者之一。Meta 僱傭了許多致力於 Btrfs 文件系統的工程師，並且多年來一直以在生產環境中使用該系統而聞名。&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0810/0085eed7c9d333a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這並非新鮮事，過去也曾有過類似的演示，例如 Meta 如何依賴 Btrfs 構建其「整個基礎設施」：&lt;/p&gt; 
&lt;p&gt;Meta 的著名 Btrfs 工程師 Josef Bacik 撰寫了關於對 Meta 的 Btrfs 使用產生的影響程度的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2F8vE9_0cQweg" target="_blank"&gt;文章&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Meta 基礎架構完全基於 btrfs 及其功能構建。憑藉 btrfs 的功能和穩健性，我們節省了數十億美元的基礎設施成本。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/143122_B7jW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;鑑於 Meta 的運營規模及其龐大的基礎設施，Btrfs 憑藉其先進的功能集和穩健性，被認為節省了「數十億美元」。對於那些仍然質疑 Btrfs 或其是否適合在生產環境中使用的人來説，這是一個有趣的故事。&lt;/p&gt; 
&lt;p&gt;在主線 Linux 內核中關於 Bcachefs 的持續討論中，可以通過&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20250809192156.GA1411279%40fedora%2F" target="_blank"&gt;這個 LKML 帖子&lt;/a&gt;找到更多評論。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365715</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365715</guid>
      <pubDate>Tue, 12 Aug 2025 06:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 基金會旗下項目組織發佈新的包容性語言指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 基金會的 OpenUSD 聯盟 (AOUSD) 和學院軟件基金會 (ASWF) &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faousd.org%2Fnews%2Falliance-for-openusd-announces-new-members-inclusive-language-guide-and-core-specification-progress%2F" target="_blank"&gt;發佈了&lt;/a&gt;更新的包容性語言指南，並歡迎可口可樂、雷諾和埃森哲等新成員加入 AOUSD。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/140303_wwtD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2021 年以來，美國學院軟件基金會 (Academy Software Foundation) 使用的《包容性語言指南》(Inclusive Language Guide) 已建議替換主/從、黑名單/白名單、性別歧視語言等常見提法。更新後的指南概述了一些開源項目/開發者應避免/替換的新增短語。&lt;/p&gt; 
&lt;p&gt;新增的社交性語言列表包括「原生支持」，應將其替換為「核心支持」或「內置支持」，以及將「pow-wow」替換為「huddle」或「meeting」。&lt;/p&gt; 
&lt;p&gt;被視為殘疾歧視的語言應替換為「健全性檢查」，而不是使用「驗證檢查」或「一致性檢查」或類似的詞語。此外，還建議不要使用「dummy」函數，而應使用「佔位符」、「存根」或「樣本」等詞。&lt;/p&gt; 
&lt;p&gt;被視為暴力的語言不應使用「hang」（掛起）一詞，而應將其替換為「unresponsive」（無響應）或「stalled」（停滯）。 更新後的《包容性語言指南》可在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aswf.io%2Finclusive-language-guide%2F" target="_blank"&gt;ASWF.io&lt;/a&gt;上找到。 （想要查看 2021 年版的人可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aswf.io%2Fblog%2Finclusive-language%2F" target="_blank"&gt;在這裏&lt;/a&gt;找到之前的版本。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365706</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365706</guid>
      <pubDate>Tue, 12 Aug 2025 06:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維開源 Matrix-3D 大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2Gnir60PynGv_Vmbz50orw" target="_blank"&gt;宣佈&lt;/a&gt;開源 Matrix-3D 大模型，一個融合全景視頻生成與三維重建的統一框架。它從單圖像出發，生成高質量、軌跡一致的全景視頻，並直接還原可漫遊的三維空間，對標李飛飛 WorldLabs 的生成效果，可實現更大範圍的探索空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="165" src="https://oscimg.oschina.net/oscnet/up-569e5f8c464ab34a3896dc3250dcc32e588.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 由以下核心部分組成：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;軌跡引導的全景視頻生成模塊：&lt;/strong&gt;利用場景 Mesh 渲染圖作為條件輸入，訓練視頻擴散模型生成符合給定相機軌跡的全景視頻。有效提升生成視頻在空間結構上的一致性，緩解遮擋錯誤與圖像偽影問題。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;雙路徑可選擇的全景 3D 重建模塊：&lt;/strong&gt;優化路徑：對生成的視頻進行超分與 3DGS 優化，獲取高質量 3D 結構。前饋網絡路徑：基於 Transformer 直接回歸，從生成視頻 Latent 特徵快速預測 3D 幾何屬性，實現高效重建。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Matrix-Pano 數據集：&lt;/strong&gt;大規模高質量合成數據集，包含 116K 條帶有相機軌跡、深度圖和文本註釋的靜態全景視頻序列。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 核心優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;場景全局一致：&lt;/strong&gt;支持 360°自由視角瀏覽，幾何結構準確、遮擋關係自然，紋理風格統一。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成場景範圍大：&lt;/strong&gt;與現有場景生成方法相比，支持更大範圍的、可 360 度自由探索的場景生成。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成高度可控：&lt;/strong&gt;同時支持文本和圖像輸入，結果與輸入高度匹配，支持自定義範圍與無限擴展。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;泛化能力強：&lt;/strong&gt;基於自研 3D 數據與視頻模型先驗，可生成多樣、真實感強的高質量場景。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成速度快&lt;/strong&gt;：首個 Feed-Forward 全景 3D 場景生成模型，可快速生成高質量 3D 場景。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 同時支持文本、圖像作為輸入，生成的 3D 場景支持自由探索，具備如下特性：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;1. 視角一致性&lt;/strong&gt;：生成 3D 場景支持 360 度自由環視，內容始終保持統一一致。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;2. 幾何、色彩一致性&lt;/strong&gt;：生成 3D 場景的幾何關係和遮擋關係正確，不同區域顏色統一。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;3. 精準控制：&lt;/strong&gt;根據用戶輸入軌跡不同，能生成不同的 3D 場景。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;4. 大範圍移動：&lt;/strong&gt;對比李飛飛 WorldLabs 和 HunyuanWorld 1.0 方法，Matrix-3D 支持更大範圍的移動。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;5. 無限續寫：&lt;/strong&gt;生成一段場景後，用戶可以在此基礎上對場景進行擴寫。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;6. 同時支持全景前饋重建和 3DGS 優化重建：&lt;/strong&gt;前饋重建網絡 LRM 支持 10s 快速場景重建，基於 3DGS 優化的策略可重建精細準確的場景。&lt;/p&gt; 
   &lt;img height="190" src="https://oscimg.oschina.net/oscnet/up-67fdb1ed5fa3b1a134fee3f03746701ded5.png" width="500" referrerpolicy="no-referrer"&gt;
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;div&gt; 
          &lt;div&gt; 
           &lt;div&gt;
            &amp;nbsp;
           &lt;/div&gt; 
          &lt;/div&gt; 
         &lt;/div&gt; 
         &lt;div&gt;
          &lt;span style="color:#000000"&gt;此外，崑崙萬維團隊還提出了 Matrix-Pano 數據集，一個基於 Unreal Engine 構建可擴展的全景視頻數據集，專為生成高質量、可探索的全景視頻而設計。更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2Gnir60PynGv_Vmbz50orw" target="_blank"&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365703</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365703</guid>
      <pubDate>Tue, 12 Aug 2025 05:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 6.17-rc1 發佈，未合併 Bcachefs 任何補丁</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linus Torvalds 在內核郵件列表&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwgb%3DB_pGPSTw9y4Fw82y5V_mvzJp_0XcWanz7YRR5vkXA%40mail.gmail.com%2FT%2F%23u" target="_blank"&gt;發佈&lt;/a&gt;&lt;/u&gt;了 Linux 6.17-rc1，主要變化包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;標準化部分筆記本電腦上的性能提升（Performance Boost）鍵的鍵碼值&lt;/li&gt; 
 &lt;li&gt;gconfig 內核配置編輯器使用 GTK3&lt;/li&gt; 
 &lt;li&gt;改進 Rust 語言支持&lt;/li&gt; 
 &lt;li&gt;新的 GPU、ARM 和 RISC-V SoC 支持&lt;/li&gt; 
 &lt;li&gt;默認情況下未啓用適用於 Panther Lake 的 Intel Xe3 顯卡，&lt;/li&gt; 
 &lt;li&gt;改進文件系統性能&lt;/li&gt; 
 &lt;li&gt;攻擊向量控制使管理相關的 CPU 安全緩解措施變得更加容易&lt;/li&gt; 
 &lt;li&gt;適用於 Intel Battlemage 顯卡的 SR-IOV 和 Project Battlematrix 的多 GPU 準備工作&lt;/li&gt; 
 &lt;li&gt;……&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/123553_Kw7D_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中最引人矚目的一個變化是 Bcachefs 維護者 Kent Overstreet 提交的任何 PR 都沒有被接受。此前 Linux 作者和 Bcachefs 維護者之間曾爆發衝突，Linus Torvalds 表示考慮&lt;u&gt;&lt;a href="https://www.oschina.net/news/359160" target="_blank"&gt;移除&lt;/a&gt;&lt;/u&gt; Bcachefs 文件系統。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0707/150244_1eHd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365696</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365696</guid>
      <pubDate>Tue, 12 Aug 2025 04:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>達摩院開源具身智能「三大件」，機器人上下文協議首次開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;8 月 11 日，在世界機器人大會上，阿里達摩院宣佈開源自研的 VLA 模型 RynnVLA-001-7B、世界理解模型 RynnEC、以及機器人上下文協議 RynnRCP，推動數據、模型和機器人的兼容適配，打通具身智能開發全流程。&lt;/p&gt; 
&lt;p&gt;具身智能領域飛速發展，但仍面臨開發流程碎片化，數據、模型與機器人本體適配難等重大挑戰。&lt;/p&gt; 
&lt;p&gt;達摩院將 MCP（Model Context Protocol）理念引入具身智能，首次提出並開源了 RCP（Robotics Context Protocol）協議以推動不同的數據、模型與本體之間的對接適配。&lt;/p&gt; 
&lt;p&gt;達摩院打造了名為 RynnRCP 的一套完整的機器人服務協議和框架，能夠打通從傳感器數據採集、模型推理到機器人動作執行的完整工作流，幫助用戶根據自身場景輕鬆適配。RynnRCP 現已經支持 Pi0、GR00T N1.5 等多款熱門模型以及 SO-100、SO-101 等多種機械臂，正持續拓展。&lt;/p&gt; 
&lt;p&gt;&lt;img height="670" src="https://static.oschina.net/uploads/space/2025/0812/121917_TuXo_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具體而言，RynnRCP 包括 RCP 框架和 RobotMotion 兩個主要模塊。RCP 框架旨在建立機器人本體與傳感器的連接，提供標準化能力接口，並實現不同的傳輸層和模型服務之間的兼容。RobotMotion 則是具身大模型與機器人本體控制之間的橋樑，能將離散的低頻推理命令實時轉換為高頻的連續控制信號，實現平滑、符合物理約束的機器人運動。&lt;/p&gt; 
&lt;p&gt;同時，RobotMotion 還提供了一體化仿真-真機控制工具，幫助開發者快速上手，支持任務規控、仿真同步、數據採集與回放、軌跡可視化等功能，降低策略遷移難度。&lt;/p&gt; 
&lt;p&gt;大會上，達摩院還宣佈開源兩款具身智能大模型。RynnVLA-001 是達摩院自主研發的基於視頻生成和人體軌跡預訓練的視覺-語言-動作模型，其特點是能夠從第一人稱視角的視頻中學習人類的操作技能，隱式遷移到機器人手臂的操控上，從而讓機械臂操控更加連貫、平滑，更接近於人類動作。&lt;/p&gt; 
&lt;p&gt;世界理解模型 RynnEC 將多模態大語言模型引入具身世界，賦予了大模型理解物理世界的能力。該模型能夠從位置、功能、數量等 11 個維度全面解析場景中的物體，並在複雜的室內環境中精準定位和分割目標物體。無需 3D 模型，該模型僅靠視頻序列就能建立連續的空間感知，還支持靈活交互。&lt;/p&gt; 
&lt;p&gt;此外，達摩院還在上月開源了 WorldVLA 模型,首次將世界模型與動作模型融合，提升了圖像與動作的理解與生成能力。相比傳統模型，該模型抓取成功率提高 4%，視頻生成質量顯著改善，展現了較好的協同性和準確性。&lt;/p&gt; 
&lt;p&gt;開源鏈接&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;機器人上下文協議 RynnRCPhttps://github.com/alibaba-damo-academy/RynnRCP&lt;/li&gt; 
 &lt;li&gt;視覺-語言-動作模型&amp;nbsp;RynnVLA-001https://github.com/alibaba-damo-academy/RynnVLA-001&lt;/li&gt; 
 &lt;li&gt;世界理解模型&amp;nbsp;RynnEChttps://github.com/alibaba-damo-academy/RynnEC&lt;/li&gt; 
 &lt;li&gt;WorldVLA 模型 https://github.com/alibaba-damo-academy/WorldVLA&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365694</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365694</guid>
      <pubDate>Tue, 12 Aug 2025 04:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub CEO 即將離職，重新成為一名「創始人」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;GitHub 首席執行官託 Thomas Dohmke &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fnews-insights%2Fcompany-news%2Fgoodbye-github%2F" target="_blank"&gt;宣佈&lt;/a&gt;即將離職，並表示自己將重新成為一名「創始人」，但會留任至年底以協助過渡工作。目前，微軟尚未公佈繼任者人選。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="288" src="https://oscimg.oschina.net/oscnet/up-b265d62156bb9d35a20a8332242c7787afc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Dohmke 於 2015 年通過其創業公司 HockeyApp 被微軟收購而加入。2018 年微軟以 75 億美元收購 GitHub，Dohmke 於 2021 年被調任至該業務擔任產品負責人，並在幾個月後接替 Nat Friedman 成為首席執行官。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Dohmke 離職正值 GitHub 面臨人工智能編碼工具激烈競爭的關鍵時刻。2021 年，在 Friedman 的領導下，GitHub 與微軟、OpenAI 合作推出了備受歡迎的 Copilot 工具，能為開發者推薦代碼，旨在提高工作效率。目前，GitHub 的註冊開發者已超 1.5 億，相比 2021 年 10 月的 7300 萬有了顯著增長。根據微軟 CEO &lt;span style="background-color:#ffffff; color:#333333"&gt;Satya Nadella&amp;nbsp;&lt;/span&gt;上月透露，已有 2000 萬人在使用 Copilot，Copilot Enterprise 客戶數量環比增長 75%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，隨着被稱為「氛圍編碼」（vibe coding）的潮流興起，眾多初創公司迅速崛起，對 GitHub 構成了挑戰。這些工具利用人工智能模型快速生成應用程序和網站代碼，包括 Anysphere 開發的 Cursor、Replit 和 Windsurf 等。根據今年 5 月至 6 月的 Stack Overflow 開發者調查，Cursor、Anthropic 的 Claude Code 和 Windsurf 等新興工具已開始搶佔市場份額，而這些競爭對手在去年的調查中均未被提及，顯示出市場格局正在迅速變化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得注意的是，微軟近期對人工智能戰略進行了重大調整。今年 1 月，微軟成立了由前 Meta 高管 Jay Parikh 領導的 CoreAI 平台與工具部門，而 GitHub 正式歸入該部門。Dohmke 在備忘錄中也提到：「GitHub 及其領導團隊將繼續作為微軟 CoreAI 組織的一部分履行使命，更多細節將很快公佈。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365686</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365686</guid>
      <pubDate>Tue, 12 Aug 2025 03:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>邊緣智能、碎片化、長週期可靠性：操作系統基座的技術破局點</title>
      <description/>
      <link>https://my.oschina.net/u/4489239/blog/18687836</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18687836</guid>
      <pubDate>Tue, 12 Aug 2025 02:56:00 GMT</pubDate>
    </item>
    <item>
      <title>微軟 GitHub CEO 託馬斯・多姆克宣佈離職</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟 GitHub CEO Thomas Dohmke（託馬斯・多姆克）晚間&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fashtom%2Fstatus%2F1954920157853172064" target="_blank"&gt;發文&lt;/a&gt;，宣佈將卸任 GitHub CEO 一職，去開啓他的下一段冒險。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1504" src="https://static.oschina.net/uploads/space/2025/0812/104823_aKoy_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;託馬斯表示，GitHub&amp;nbsp;擁有超過 10 億個倉庫和分支，1500 萬+開發者，以及 Copilot 持續引領最蓬勃發展的 AI 市場，擁有 2000 萬用戶且不斷增長，GitHub 今天比以往任何時候都更強大。&lt;/p&gt; 
&lt;p&gt;託馬斯在發給 GitHub 員工的內部帖子中表示，十多年前，他的初創公司被微軟收購後，他和他的家人從德國搬到了美國。從開發移動開發者工具，到與 Nat Friedman 一起運營 GitHub 的收購，再到成為 GitHub 的 CEO 並引領公司進入 Copilot 和 AI 時代，「這真是一段難忘的旅程。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365670</guid>
      <pubDate>Tue, 12 Aug 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里淘寶第一個程序員「多隆」現已離職</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;網傳阿里「掃地僧」蔡景現已離職，其在阿里內外平台狀態顯示為「退隱江湖」。對此，阿里暫時沒有回應。&lt;/p&gt; 
&lt;p&gt;蔡景現（花名多隆）於 2000 年加入阿里巴巴，是淘寶第一個程序員。作為淘寶初創團隊核心工程師，他主導構建了淘寶交易系統和論壇系統。憑藉卓越的技術貢獻，他在 2014 年入選阿里巴巴集團合夥人團隊。其入選理由包括「對淘寶業務的創紀錄貢獻」及「單純專注的技術特質」。&lt;/p&gt; 
&lt;p&gt;2023 年 7 月，阿里巴巴集團年報顯示蔡景現不再擔任合夥人職務。&lt;/p&gt; 
&lt;p&gt;據悉，蔡景現長期擔任阿里雲智能事業羣高級研究員，因其專注高效的工作風格被內部譽為「碼神」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7a3c9a17e396032f4f6e3de92548157fad6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365665</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365665</guid>
      <pubDate>Tue, 12 Aug 2025 02:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​英國圖靈人工智能研究所面臨資金危機與內部動盪</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英國的圖靈人工智能研究所（Alan Turing Institute）目前正處於危機之中，員工們向慈善委員會提出了匿名投訴，警告該機構可能面臨崩潰的風險。這一投訴引發了對研究所領導層的嚴厲指責，稱其在公共資金的使用上存在不當行為，並且內部文化氛圍 「有毒」。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="383" src="https://oscimg.oschina.net/oscnet/up-a3ea108136514fe60deafb85486f4f08f42.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;技術祕書彼得・凱爾（Peter Kyle）威脅如果圖靈研究所不調整其戰略，將撤回其資金支持。這一消息讓員工們感到震驚，認為這可能會導致該研究所的崩潰。凱爾希望研究所能夠將研究重點轉向國防領域，並進行領導層的全面改革，這與研究所過去主要關注環境可持續性和健康等領域的定位截然不同。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;圖靈研究所自 2015 年成立以來，一直是英國人工智能研究的領先中心，然而最近幾個月，該研究所內部的不滿情緒不斷上升。投訴中提到，圖靈研究所的治理不穩、缺乏透明度以及對資金的支出決策不明朗，令公共和私人資助者感到擔憂。此外，員工們還表示，儘管多次向領導團隊反映問題，但沒有任何實質性的改進。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新的首席執行官珍・英尼斯（Jean Innes）在接受媒體採訪時表示，圖靈研究所需要現代化，並更加專注於人工智能項目。然而，研究所面臨的挑戰依然嚴峻，已有多位高管因不滿而辭職，這讓外界對其未來發展產生了疑慮。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，圖靈研究所正在進行大規模的組織變革，試圖確保在國防、國家安全等領域發揮更大作用。隨着政府對人工智能行業的重視，圖靈研究所的戰略調整將對英國的科技發展產生深遠影響。&amp;nbsp;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365663</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365663</guid>
      <pubDate>Tue, 12 Aug 2025 02:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>智譜 AI 發佈並開源視覺推理模型 GLM-4.5V</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智譜 AI 發佈了新一代旗艦視覺推理模型 GLM-4.5V。該模型基於 MOE 架構，總參數量達到 106B，激活參數量為 12B，支持視頻、圖像、文本、文件作為輸入模態，輸出文本，其上下文窗口為 64K。&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 基於智譜新一代旗艦文本基座模型 GLM-4.5-Air，延續 GLM-4.1V-Thinking 技術路線，在 41 個公開視覺多模態榜單中綜合效果達到同級別開源模型 SOTA 性能，涵蓋圖像、視頻、文檔理解以及 GUI Agent 等常見任務。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/101653_00Dq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 由視覺編碼器、MLP 適配器和語言解碼器三部分組成，支持 64K 多模態長上下文，支持圖像與視頻輸入，並通過三維卷積提升視頻處理效率。模型採用雙三次插值機制，有效增強了模型對高分辨率及極端寬高比圖像的處理能力與穩健性；同時，引入三維旋轉位置編碼（3D-RoPE），顯著強化了模型對多模態信息的三維空間關係的感知與推理能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="706" src="https://static.oschina.net/uploads/space/2025/0812/102144_4JJ9_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 採用三階段策略：預訓練、監督微調（SFT）和強化學習（RL）。其中，在預訓練階段，我們結合大規模圖文交錯多模態語料和長上下文內容，強化了模型對複雜圖文及視頻的處理能力；在 SFT 階段，我們引入了顯式「思維鏈」格式訓練樣本，增強了 GLM-4.5V 的因果推理與多模態理解能力；最後，RL 階段，我們引入全領域多模態課程強化學習，通過構建多領域獎勵系統（Reward System），結合可驗證獎勵強化學習（RLVR）與基於人類反饋的強化學習（RLHF），GLM-4.5V 在 STEM 問題、多模態定位、Agent 任務等方面獲得全面優化。&lt;/p&gt; 
&lt;p&gt;GLM-4.5V API 價格情況如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API 調用價格：低至輸入&amp;nbsp;2 元/M&amp;nbsp;tokens，輸出&amp;nbsp;6 元/M&lt;/li&gt; 
 &lt;li&gt;tokens 響應速度：達到&amp;nbsp;60-80 tokens/s&lt;/li&gt; 
 &lt;li&gt;API&amp;nbsp;接口文檔：http://docs.bigmodel.cn/api-reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GLM-4.5V API 現已上線智譜開放平台&amp;nbsp;BigModel.cn，為所有新老用戶準備了&amp;nbsp;2000 萬 Tokens 的免費資源包。&lt;/p&gt; 
&lt;p&gt;領取鏈接：https://zhipuaishengchan.datasink.sensorsdata.cn/t/bv&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365661</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365661</guid>
      <pubDate>Tue, 12 Aug 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>月報 Vol.02：新增條件編譯屬性 cfg、#alias 屬性、defer 表達式，增加 tuple struct 支持</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;語言更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增條件編譯屬性 cfg。可以根據後端等條件進行文件內的條件編譯。&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;#cfg(any(target="js", target="wasm-gc"))
let current_target = "js | wasm-gc"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增&lt;code&gt;#alias&lt;/code&gt;屬性，目前可以給方法或函數創建別名，並支持標註廢棄。後續支持更多場景。&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;#alias(combine, deprecated="use add instead")
fn Int::add(x : Int, y : Int) -&amp;amp;gt; Int {
  x + y
}

test {
  let _ = Int::add(1, 2)
  let _ = Int::combine(1, 2)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增 &lt;code&gt;defer&lt;/code&gt;表達式。提供了一個基於詞法作用域的資源清理功能。當程序以任何方式離開 &lt;code&gt;defer expr; body&lt;/code&gt; 中的 &lt;code&gt;body&lt;/code&gt; 時，&lt;code&gt;expr&lt;/code&gt; 都會被運行&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;fn main {
  defer println("End of main")
  {
    defer println("End of block1")
    println("block1")
  }
  for i in 0..&amp;amp;lt;3 {
    defer println("End of loop \{i}")
    if i == 2 {
      break // `break` 等也能觸發 `defer`
    }
    println("Looping \{i}")
  }
  return
}
&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;block1
End of block1
Looping 0
End of loop 0
Looping 1
End of loop 1
End of loop 2
End of main
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;nbsp;&amp;nbsp;目前，&lt;code&gt;defer expr&lt;/code&gt; 的 &lt;code&gt;expr&lt;/code&gt; 裏不能拋出錯誤或調用 &lt;code&gt;async&lt;/code&gt; 函數。&lt;code&gt;expr&lt;/code&gt; 裏不能使用 &lt;code&gt;return&lt;/code&gt;/&lt;code&gt;break&lt;/code&gt;/&lt;code&gt;continue&lt;/code&gt; 等控制流跳轉構造&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Native 後端的 &lt;code&gt;Bytes&lt;/code&gt; 的末尾現在永遠會有一個額外的 &lt;code&gt;'\0'&lt;/code&gt; 字節，因此現在 &lt;code&gt;Bytes&lt;/code&gt; 可以直接當作 C string 傳給需要 C string 的 FFI 調用。這個額外的 &lt;code&gt;'\0'&lt;/code&gt; 字節不計入 &lt;code&gt;Bytes&lt;/code&gt; 的長度，因此現有代碼的行為不會有任何變化&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調整可選參數的語法，默認參數現在可以依賴前面的參數（之前這一行為被廢棄了，因為它和 virtual package 不兼容，但現在我們找到了在兼容 virtual package 的前提下支持這種複雜默認值的方式）。另外，我們統一了有默認值（&lt;code&gt;label~ : T = ..&lt;/code&gt;）和沒有默認值（&lt;code&gt;label? : T&lt;/code&gt;）的可選參數：現在，對於函數的調用者來説，這兩種默認參數不再有區別，並且都支持下列調用方式：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;不提供參數，使用默認值&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;通過 &lt;code&gt;label=value&lt;/code&gt; 的形式顯式提供參數&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;通過 &lt;code&gt;label?=opt&lt;/code&gt; 的形式調用，語義是：如果 &lt;code&gt;opt&lt;/code&gt; 是 &lt;code&gt;Some(value)&lt;/code&gt;，等價於 &lt;code&gt;label=value&lt;/code&gt;。如果 &lt;code&gt;opt&lt;/code&gt; 是 &lt;code&gt;None&lt;/code&gt;，等價於不提供這個參數&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調整自動填充參數的語法，改用 &lt;code&gt;#callsite(autofill(...))&lt;/code&gt; 屬性替代原有語法&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;// 原版本
pub fn[T] fail(msg : String, loc~ : SourceLoc = _) -&amp;amp;gt; T raise Failure { ... }
// 現版本
#callsite(autofill(loc))
pub fn[T] fail(msg : String, loc~ : SourceLoc) -&amp;amp;gt; T raise Failure { ... }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;廢棄 newtype，增加 tuple struct 支持&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;// 舊語法，運行時等價於 Int
type A Int
fn get(a : A) -&amp;amp;gt; Int {
  a.inner()
}

// 新語法，運行時依然等價於 Int
struct A(Int)
fn get(a : A) -&amp;amp;gt; Int {
  a.0
}

struct Multiple(Int, String, Char)
fn use_multiple(x: Multiple) -&amp;amp;gt; Unit {
  println(x.0)
  println(x.1)
  println(x.2)
}
fn make_multiple(a: Int, b: String, c: Char) -&amp;amp;gt; Multiple {
  Multiple(a, b, c)
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;當 tuple struct 中類型數量為 1 個的時候，tuple struct 等價於原有的 newtype。因此，當 newtype 的 underlying type 不是 tuple 的時候，formatter 目前會自動將舊語法遷移至新語法。為了便於遷移，這種情況下的 tuple struct 也提供了一個 &lt;code&gt;.inner()&lt;/code&gt; 方法，之後會 deprecated 掉並移除&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;當 tuple struct 中類型數量超過 1 個的時候，tuple struct 和原有的 tuple newtype 的區別在於：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;tuple struct 不能由直接通過 tuple 構造&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;tuple struct 不能通過 &lt;code&gt;.inner()&lt;/code&gt; 方法得到一個 tuple&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;如果需要可以直接和 tuple 互相轉換的 tuple struct，可以使用：&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;struct T((Int, Int))

fn make_t(x: Int, y: Int) -&amp;amp;gt; T {
  (x, y)
}

fn use_t(t: T) -&amp;amp;gt; (Int, Int) {
  t.0
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不過這種情況下訪問具體元素時，需要 &lt;code&gt;t.0.0&lt;/code&gt; 或者 &lt;code&gt;t.0.1&lt;/code&gt; 進行訪問&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;由於主要用途為數據存儲和 &lt;code&gt;@json.inspect&lt;/code&gt; 等功能，&lt;code&gt;derive(FromJson, ToJson)&lt;/code&gt; 將不再提供高級格式調整參數。目前保留的格式參數為每個字段的 &lt;code&gt;rename&lt;/code&gt;（重命名）、批量重命名和 enum 的格式選擇 &lt;code&gt;style&lt;/code&gt;，其餘參數均將被移除。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;style&lt;/code&gt;的可選項為&lt;code&gt;legacy&lt;/code&gt;和&lt;code&gt;flat&lt;/code&gt;。後者簡化了表示，適用於&lt;code&gt;@json.inspect&lt;/code&gt;等場景。目前所有 enum 都必須選擇其中一個 style 使用。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;如果需要自定義 JSON 的格式，請自行實現 &lt;code&gt;FromJson&lt;/code&gt; 和 &lt;code&gt;ToJson&lt;/code&gt; 兩個 trait。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;///| Flat
test {
  @json.inspect(Cons(1, Cons(2, Nil)), content=["Cons", 1, ["Cons", 2, "Nil"]])
}

///| Legacy
test {
  @json.inspect(Cons(1, Cons(2, Nil)), content={
    "$tag": "Cons",
    "0": 1,
    "1": { "$tag": "Cons", "0": 2, "1": { "$tag": "Nil" } },
  })
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;工具鏈更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增 &lt;code&gt;moon coverage analyze&lt;/code&gt;功能，提供更直觀的覆蓋率報告&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;Total: 1 uncovered line(s) in 2 file(s)

1 uncovered line(s) in src/top.mbt:

   | fn incr2(x : Int, step? : Int = 1) -&amp;amp;gt; Int {
12 |   x + step
   |   ^^^^^^^^         &amp;amp;lt;-- UNCOVERED
   | }
   …

Total: 1 uncovered line(s) in 2 file(s)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;現在 &lt;code&gt;moon test --target js&lt;/code&gt;在 panic 的時候，能根據 sourcemap 顯示原始位置了&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Bash"&gt;test username/hello/lib/hello_test.mbt::hello failed: Error
    at $panic ($ROOT/target/js/debug/test/lib/lib.blackbox_test.js:3:9)
    at username$hello$lib_blackbox_test$$__test_68656c6c6f5f746573742e6d6274_0 ($ROOT/src/lib/hello_test.mbt:3:5)
    at username$hello$lib_blackbox_test$$moonbit_test_driver_internal_execute ($ROOT/src/lib/__generated_driver_for_blackbox_test.mbt:41:9)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/7007853/blog/18687782</link>
      <guid isPermaLink="false">https://my.oschina.net/u/7007853/blog/18687782</guid>
      <pubDate>Tue, 12 Aug 2025 02:19:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>崑崙萬維發佈 Matrix-Game 2.0：國產開源的 Genie 3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPhnkrpTuQ-ntZfFNHTrGBw" target="_blank"&gt;宣佈&lt;/a&gt;推出自研世界模型 Matrix 系列中 Matrix-Game 交互世界模型的升級版本——「Matrix-Game 2.0」，實現了通用場景下的交互式實時長序列生成的世界模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Matrix-Game 2.0 已全面開源，是業內首個在通用場景上實現實時長序列交互式生成的世界模型開源方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-afca6110982b55fefd656c48f7a18b74899.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，「Matrix-Game 2.0」在實時生成和長序列能力上實現了質的飛躍。相較於上一版本，2.0 版本更加側重低延遲、高幀率的長序列交互性能，能夠以 25 FPS 的速度，在多種複雜場景中穩定生成連續視頻內容，且生成時長可擴展至分鐘級，大幅提升了連貫性與實用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在推理速度顯著提升的同時，模型依然保持了對物理規律與場景語義的精準理解，支持用戶通過簡單指令，自由探索、操控並實時構建結構清晰、細節豐富、規則合理的虛擬環境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」提出了一種全新的視覺驅動交互世界建模方案，徹底擺脫了傳統依賴語言提示的生成模式，專注於通過視覺理解和物理規律學習來構建虛擬世界。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與主流依賴文本語義的模型不同，「Matrix-Game 2.0」避免了語言先驗可能帶來的語義偏置，轉而關注圖像中的空間結構和動態模式，從而更真實、更準確地理解和生成虛擬世界。&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;基礎模型架構&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="175" src="https://oscimg.oschina.net/oscnet/up-f9ecc45d299a9021d8550f66b32f6211012.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」採用圖像為中心的感知與生成機制：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;3D Causal VAE 壓縮結構：通過三維因果變分自編碼器實現空間和時間維度的高效壓縮，提升建模效率與生成能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多模態擴散 Transformer (DiT)：結合視覺編碼器與用戶動作指令，逐幀生成物理合理的動態視覺序列，並通過 3D VAE 解碼成完整視頻。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;用戶交互控制：借鑑 GameFactory 與 Genie 系列的控制設計框架，引入「動作模塊」，實現用戶與生成世界之間的交互操作。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;實時自迴歸視頻生成&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="237" src="https://oscimg.oschina.net/oscnet/up-eb8035289152c9649761e8434a7e260b5ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」基於 Self-Forcing 訓練策略，通過創新的自迴歸擴散生成機制克服了傳統雙向擴散模型的延遲和誤差累積問題：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;因果擴散模型訓練：將雙向擴散模型蒸餾為因果模型，使用基礎模型初始化生成器，並構建小規模數據集，通過近似 ODE 軌跡進行訓練，穩定自迴歸擴散過程。通過歷史幀條件生成當前幀，減少因依賴未來幀而導致的時序延遲。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;分佈匹配蒸餾（DMD）：通過最小化與基礎模型之間的分佈差異，引導學生模型學習生成高質量視頻幀，對齊訓練與推理階段的分佈，顯著緩解誤差積累問題。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;KV 緩存機制：引入鍵值緩存機制（KV-Cache），顯著提升長視頻生成的效率和一致性。該機制通過維護固定長度的注意力上下文，實現無縫滾動生成，支持無限時長的視頻輸出，解決了訓練與推理場景下上下文不一致的問題。基於此實現長時視頻的高效生成而無需重複計算，單 GPU 上可實現 25 FPS 實時生成。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」能夠生成跨場景的長時視頻，保持動作和視覺的時序一致性，並且支持用戶在交互過程中的連續指令輸入，使其成為遊戲內容創作、虛擬現實和智能交互系統的理想解決方案。這一方案將可控性、靈活性與效率相結合，推動高質量視頻生成技術邁向更廣泛的實時應用場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如在一些無約束、不可控的真實場景，「Matrix-Game 2.0」可根據用戶輸入的任意控制指令（如鍵盤的 W/A/S/D 方向鍵、鼠標用於視角移動），生成對應的交互世界視頻，支持角色的前後左右移動以及視角變換等動態行為。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 GTA 遊戲場景和 Minecraft 場景中，「Matrix-Game 2.0」也支持鍵盤與鼠標操作，並且能夠生成真實感更強、符合物理邏輯的可交互視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Matrix-Game 2.0 具備三大核心優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;高幀率實時交互長序列生成：支持前後左右移動和視角轉動，用戶可通過指令操控角色在場景中自由行動，系統以 25 FPS 實時生成連續畫面，單次交互可生成分鐘級別長交互視頻，動作自然流暢，響應精準。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多場景泛化能力：模型具備出色的跨域適應性，不僅適用於特定任務場景，還支持多種風格與環境的模擬，包括城市、野外等空間類型，以及真實、油畫等視覺風格。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;增強的物理一致性：對物理規則的理解進一步提升，角色在面對台階、障礙物等複雜地形時，能夠展現出符合物理邏輯的運動行為，提升沉浸感與可控性。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365659</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365659</guid>
      <pubDate>Tue, 12 Aug 2025 02:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊 APIJSON 生態 apijson-spring-boot 開源 •用 YAML 簡化配置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h3&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c300c13a9b9281860955eefb4640dc84073.png" referrerpolicy="no-referrer"&gt;&lt;/h3&gt; 
&lt;p&gt;騰訊 APIJSON 是一種專為 API 而生的 JSON 網絡傳輸協議，以及，基於這套協議實現的 ORM 庫。&lt;br&gt; &lt;strong&gt;為各種增刪改查提供了完全自動化的萬能 API，零代碼實時滿足千變萬化的各種新增和變更需求。&lt;/strong&gt;&lt;br&gt; 能大幅降低開發和溝通成本，簡化開發流程，縮短開發週期。適閤中小型前後端分離的項目。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自 2016 年 11 月開源 8 年多來發展迅速，目前 18K+ Star 位居 1000W Java 開源項目前 110。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-72064360a618ee52557c6884a874afa32fd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-05507add1ab73979181e2a721832b2ef017.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b0118180bc641918130cef0f4dee2bf1ca1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;apijson-spring-boot 介紹&lt;/h2&gt; 
&lt;p&gt;SpringBoot 3 for APIJSON，用 YAML 簡化代碼配置&lt;/p&gt; 
&lt;h2&gt;項目列表&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;項目&lt;/th&gt; 
   &lt;th&gt;説明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-autoconfigure&lt;/td&gt; 
   &lt;td&gt;自動配置&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-dependencies&lt;/td&gt; 
   &lt;td&gt;項目依賴&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-examples&lt;/td&gt; 
   &lt;td&gt;示例項目&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-starter&lt;/td&gt; 
   &lt;td&gt;APIJSON Spring Boot 啓動器&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;支持的接口&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;接口 url&lt;/th&gt; 
   &lt;th&gt;方法&lt;/th&gt; 
   &lt;th&gt;説明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;common/{method}&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;支持 GET，HEAD，GETS，HEADS，POST，PUT，DELETE，CRUD 等&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;common/{method}/{tag}&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;增刪改查統一接口，這個一個接口可替代 7 個萬能通用接口，犧牲一些路由解析性能來提升一點開發效率&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/reload&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;重新加載配置&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/post/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;生成驗證碼&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/gets/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;獲取驗證碼&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/heads/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;校驗驗證碼&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/login&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;用戶登錄&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/logout&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;退出登錄，清空 session&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/register&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;註冊&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/put/password&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;設置密碼&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;所有的配置屬性&lt;/h2&gt; 
&lt;p&gt;不填則用默認值&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;spring:
  apijson:
    rest-api:
      enable: true                                  # 是否初始化 Rest 接口，默認 true。框架已提供 APIJSON 統一接口實現
      prefix: api-json                              # Rest 接口前綴，默認 api-json。訪問接口如：http://localhost:8080/api-json/common/get
    application: fastjson2                          # 集成 apijson-fastjson2 包
    new-id-strategy: timestamp                      # 主鍵生成策略，默認 timestamp。支持：database(數據庫自增)，uuid(uuid 字符串)， timestamp(當前時間毫秒數)，snowflake(雪花算法)，custom(用戶自定義)
    need-verify-login: true                         # 每次訪問 Rest 接口時是否需要校驗登錄
    need-verify-role: true                          # 每次訪問 Rest 接口時是否需要校驗角色權限
    need-verify-content: true                       # 每次訪問 Rest 接口時開啓校驗請求傳參內容
    enable-on-startup: false                        # 在啓動時初始化，如：APIJSONVerifier(校驗器) 初始化
    shutdown-when-server-error: true                # 啓動遇到異常時停止
    log-debug: false                                # 日誌
    sql:
      config:
        enable-column-config: false                 # 支持 !key 反選字段，和 字段名映射， 默認 false
        default-database: MYSQL                     # 默認的數據庫類型, 默認 MYSQL。支持多種數據庫，請參考 SQLConfig 類定義，注意名稱全大寫
        default-schema: sys                         # 默認數據庫名/模式，默認 sys。 設置含有 APIJSON 系統表的數據庫
        default-catalog:
        default-namespace:
        version: 5.7.22                             # 數據庫版本, 默認'5.7.22'
      executor:
        enable-output-null-column: false            # 是否返回，值為 null 的字段, 默認 false
        key-raw-list: '@RAW@LIST'
        key-vice-item: '@VICE@ITEM'
    parser:
      function:
        parse-arg-value: false                      # 是否解析參數 key 的對應的值
        enable-remote-function: true                # 開啓支持遠程函數
        enable-script-function: true                # 開啓支持遠程函數中的 JavaScript 腳本形式
      request:
        print-request-string-log: false             # 是否打印關鍵的接口請求內容
        print-big-log: false                        # 打印大數據量日誌的標識
        print-request-endtime-log: false            # 是否打印關鍵的接口請求結束時間
        return-stack-trace: true                    # 控制返回 trace:stack 字段
        start-from1: false                          # 分頁頁碼是否從 1 開始，默認為從 0 開始
    verifier:
      enable-verify-column: true
      enable-apijson-router: false
      update-must-have-id-condition: true           # 為 PUT, DELETE 強制要求必須有 id/id{}/id{}@ 條件
      enable-verify-role: true                      # 開啓校驗請求角色權限
      enable-verify-content: true                   # 開啓校驗請求傳參內容
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;創作不易，堅持更難，右上角點亮 ⭐ Star 來收藏/支持下吧，謝謝 ^_^&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gitee.com/yunjiao-source/apijson-spring-boot"&gt;https://gitee.com/yunjiao-source/apijson-spring-boot&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365652</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365652</guid>
      <pubDate>Tue, 12 Aug 2025 01:51:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>「字節跳動靜態資源公共庫」因黑產原因下線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;從 2025 年 6 月份開始，就有諸多站長髮現字節跳動旗下的靜態資源公共庫存在調用問題，包括部分資源連接超時或者直接 HTTP 404，這導致網站無法正常加載內容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;當時測試發現諸如 jQuery 等還可以調用，其他部分資源出現錯誤無法調用，因此並不清楚字節跳動哪裏出問題才會導致部分資源有效、部分資源無效。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0812/153944_CXJ5_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://cdn.bytedance.com/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;現在字節跳動已經明確靜態資源公共庫下線，當前所有靜態資源已經全部處於 404 狀態，字節跳動給出的原因是黑產問題，或許是黑灰產團夥也使用字節跳動的公共庫調用資源，導致現在字節跳動被迫直接停掉這項服務。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365736</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365736</guid>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
