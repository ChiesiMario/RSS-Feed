<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 24 Feb 2025 07:40:48 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>韓國：2 年內大多數半導體技術被中國趕超</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韓聯社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yna.co.kr%2Fview%2FAKR20250221088900017&quot; target=&quot;_blank&quot;&gt;報道稱&lt;/a&gt;，韓國科學技術企劃評價院（KISTEP）23 日發佈的《三大系統領域技術水平深層分析》報告顯示，以去年為準，韓國半導體領域的技術基礎力量在所有項目上都落後於中國。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一報告基於對 39 名當地專家進行的調查，這些人此前曾參與了韓國在 2022 年進行的技術水平評估，當時他們認為韓國在各方面均處於領先地位，但這一結論僅過了兩年就被推翻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;398&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9d0d395bf86e8aed2c302c3235c8af896c0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，韓國在高集成度、低阻抗存儲技術方面排名第二，得分為 90.9%，低於中國的 94.1%；在高性能、低功耗人工智能（AI）半導體領域，韓國以 84.1% 低於中國的 88.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在功率半導體方面，韓國為 67.5%，中國為 79.8%，新一代高性能傳感技術方面，韓國為 81.3%，中國為 83.9%。在半導體先進封裝技術方面，韓國和中國同樣為 74.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業化的觀點來看，韓國在高集成、低阻抗存儲技術和半導體先進封裝技術方面暫時領先於中國。對整個半導體行業技術生命週期的評估調查也顯示，韓國在工藝和量產方面領先於中國，但在基礎、源頭和設計領域落後於中國。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335485</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335485</guid>
            <pubDate>Mon, 24 Feb 2025 07:12:35 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>經濟日報：大模型免費不是單方讓利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用戶之間的雙向互動。在這場變革中，雙方都從中有所收穫。儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。此外，免費必然帶來大量用戶，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，多家大模型廠商宣佈免費開放其大模型服務，引發關注。例如，文心一言將於 4 月 1 日 0 時起全面免費，所有 PC 端和 APP 端用戶均可體驗其最新模型；阿里巴巴推出的通義千問系列不僅面向開發者開放 API 接口，還提供了大量免費額度供普通用戶調用；谷歌、Meta 等國際巨頭相繼發佈了可供研究者和小型團隊使用的免費版本……&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從高端科技到親民價格，大模型免費潮的到來並非偶然。一方面，大模型的研發成本雖然高昂，但邊際成本卻相對較低。一旦完成模型訓練，新增用戶並不會顯著增加成本，通過免費開放吸引更多用戶參與，可以在迅速擴大市場份額的同時，積累寶貴的數據資源用於後續優化；另一方面，大模型開源和免費開放的趨勢逐漸明朗，迫使之前選擇閉源的廠商打破封閉生態，以吸引更多的用戶和開發者加入。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業模式角度來看，技術普惠是互聯網開放共享精神的重要體現，免費和低價也是互聯網行業的主流策略之一。從早期搜索引擎的免費使用，到社交媒體平台的零門檻註冊，再到如今雲存儲、辦公軟件等工具的低門檻普及，「免費+增值服務」的模式已經被證明是一種行之有效的商業路徑。在人工智能領域，大模型廠商也藉助技術和資金優勢，通過免費使用形式，加速大模型服務的推廣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用戶之間的雙向互動。在這場變革中，雙方都從中有所收穫。對於用戶而言，這意味着獲取先進 AI 技術的成本大幅下降。對企業而言，海量用戶羣帶來的反饋信息，為調整產品方向提供了依據。大模型走上普惠化道路，本質上是一種雙贏，既滿足了用戶對高效便捷工具的需求，又為企業帶來了新的發展機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。大模型的訓練過程需要消耗大量算力和數據資源，即便是在免費階段，企業也需持續進行迭代升級，投入成本不容小覷。免費低價時代的到來，可能加速企業間的競爭。AI 賽道的老玩家依靠成熟的技術路線和雄厚的資金實力，可以進一步壓縮後來者的生存空間。新進入者如果短期無法找到有效的盈利途徑，那麼長期虧損的風險將不可避免。此外，免費必然帶來大量用戶，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視，否則可能會引發信任危機，進而影響服務提供者的口碑和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費，無疑是當前人工智能發展歷程中的一個重要趨勢。這一趨勢能帶來怎樣的新局面，仍取決於各方能否妥善應對其中的挑戰。只有在確保經濟效益與社會效益相統一的前提下，大模型免費才能真正成為推動全球創新的重要力量。（經濟日報記者，劉 莉）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335477</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335477</guid>
            <pubDate>Mon, 24 Feb 2025 06:48:35 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Ubuntu 25.04 進入特性凍結階段，預計 4 月正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Canonical 工程師 Utkarsh Gupta &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-devel-announce%2F2025-February%2F001366.html&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt; Ubuntu 25.04 已進入特性凍結階段，並且一切都在按部就班推進。&lt;/p&gt; 
&lt;p&gt;按照計劃，Ubuntu 25.04 將於 3 月 13 日進入 UI 凍結階段，3 月 20 日進入內核特性凍結階段，3 月 27 日發佈 beta 版本，4 月 3 日開始內核凍結，4 月 10 日進入最終凍結階段。如果一切順利，Ubuntu 25.04 將於 4 月 17 日正式發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95aa95335baad09f1eccadb56afefae58b8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Ubuntu 25.04 預計將搭載 Linux 6.14 內核，默認使用 GNOME 48 桌面，Mesa 25.0 將提供更優的圖形驅動支持。GIMP 3.0 將在 Ubuntu 25.04 上提供，此外還將持續改進安裝程序，而且 Canonical 也持續強調性能優化。當然還有許多 Ubuntu 25.04 的底層改進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</guid>
            <pubDate>Mon, 24 Feb 2025 06:41:10 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>深圳：近期將發佈人形機器人專項政策</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2 月 23 日，深圳市政府新聞辦召開「打造最好科技創新生態和人才發展環境」新聞發佈會。會上，市工業和信息化局副局長、深圳市人工智能產業辦公室主任林毅表示，深圳在人工智能和機器人領域起步較早、基礎較好，有「兩個一」：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第一個是有一支專業的產業隊伍，組建市人工智能產業辦公室，以專業、精幹隊伍推動產業發展。第二個是有一批優質的企業，全市已匯聚人工智能企業 2600 餘家、獨角獸企業 6 家，機器人上市企業 34 家、獨角獸企業 9 家，創新活力持續迸發。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ec3f039d40cf1534569b1e3badaaa604dd.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;林毅在發佈會上透露，接下來，深圳將向企業發放最高 60%、最高 1000 萬元的「訓力券」補貼，以及模型券、語料券、場景補貼等。&lt;strong&gt;「今年市區將多渠道籌集 45 億元政策資金，3 月起接受企業申報，歡迎廣大企業關注。」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，近期深圳還將發佈人形機器人專項政策，通過揭榜掛帥等方式，對開放應用場景、突破關鍵技術、構建專用數據集、提升規模化製造和應用能力等予以精準支持。同時，還將在全市科技重大專項中設立&lt;strong&gt;人工智能和機器人專項&lt;/strong&gt;，鼓勵產、學、研、用組成創新聯合體進行協同攻關。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335449</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335449</guid>
            <pubDate>Sun, 23 Feb 2025 03:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apple 準備將谷歌 Gemini 與蘋果智能進行整合</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Faaronp613%2Fstatus%2F1893058313316671627&quot; target=&quot;_blank&quot;&gt;據報道&lt;/a&gt;，在與 iOS 18.4 測試版一起推送的後台更新中，蘋果現在在蘋果智能中為第三方模型提供了谷歌和 OpenAI 兩個選項。這代表蘋果有意為蘋果智能提供更多基礎大模型供應。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1576&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/114953_zK72_2720166.png&quot; width=&quot;1278&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雖然這並不一定證實我們會在 iOS 18.4 的後期看到 Gemini 集成，特別是考慮到迄今為止發生的所有其他 Apple Intelligence 延遲，但它幾乎證實它會在不久的將來的某個時候出現，也許是在以後的 iOS 18 更新或 iOS 19 中。蘋果預計將在 iOS 19 中發佈自己的對話式 Siri 模型。&lt;/p&gt; 
&lt;p&gt;谷歌最近發佈了一些新的 Gemini 2.0 模型，包括一個新的推理模型。在不久的將來，這些新模型有可能會在 iPhone 上亮相。&lt;/p&gt; 
&lt;p&gt;有消息稱，蘋果預計將在 iOS 19 中發佈自己的對話 Siri 模型，而蘋果可能會允許用戶在 Gemini 和 ChatGPT 之中進行選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335448</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335448</guid>
            <pubDate>Sun, 23 Feb 2025 03:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>得物端智能視頻封面推薦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h2&gt;什麼要做智能封面？&lt;/h2&gt; 
&lt;p&gt;用戶可以在得物購物，也可以在得物社區分享自己的生活。&lt;/p&gt; 
&lt;p&gt;得物社區中的視頻使用雙列流，每條內容包含封面、標題等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對得物社區的創作者而言，選擇視頻封面是創作鏈路的重要環節。&lt;/li&gt; 
 &lt;li&gt;對得物社區的消費者而言，封面是影響 CTR（點擊率）的關鍵因素。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;封面推薦可以降低創作者的創作成本，提高消費者 CTR。&lt;/p&gt; 
&lt;h2&gt;端智能介紹&lt;/h2&gt; 
&lt;p&gt;端智能（Edge/Client Intelligence）是指在邊緣設備（如物聯網設備、智能傳感器、移動設備等）上進行數據處理和智能決策的能力。與雲計算模型相比，端智能將計算、存儲和分析功能移到更接近數據源的地方，優勢如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;低延遲 ：數據在本地處理，減少了傳輸到遠程服務器的時間，提高響應速度。&lt;/li&gt; 
 &lt;li&gt;節省帶寬 ：通過在本地處理數據，僅發送必要的信息到中心服務器，減少了網絡帶寬的消耗。&lt;/li&gt; 
 &lt;li&gt;數據隱私和安全 ：數據在本地處理，敏感信息不必傳輸到雲，從而提高了數據隱私和安全性。&lt;/li&gt; 
 &lt;li&gt;可靠性 ：在網絡連接不穩定或中斷的情況下，邊緣設備可以繼續進行本地處理和決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管端智能帶來了很多優勢，但在實際應用中也面臨一些挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算能力的侷限性 ：邊緣設備通常具有有限的計算資源，可能無法處理複雜的人工智能模型。&lt;/li&gt; 
 &lt;li&gt;數據一致性與協同 ：多個邊緣設備之間的數據一致性和協調處理仍然是一個挑戰。&lt;/li&gt; 
 &lt;li&gt;設備管理與部署 ：隨着設備數量的增加，邊緣設備的管理、監控和更新變得更加複雜。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到用戶隱私、實時性和服務端壓力，我們選擇用端智能推薦視頻封面，並克服相關的挑戰，最終獲得收益。&lt;/p&gt; 
&lt;h2&gt;得物端智能&lt;/h2&gt; 
&lt;p&gt;對客戶端而言，不需要訓練模型，只需要推理。&lt;/p&gt; 
&lt;p&gt;端智能框架可以簡化推理過程，常見的端智能 SDK 如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;開源 SDK：MNN、TNN、NCNN、&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot; title=&quot;Paddle&quot;&gt;Paddle&lt;/a&gt; Light、TensorFlow Light 等。&lt;/li&gt; 
 &lt;li&gt;閉源 SDK：ByteNN、Pitaya、KwaiNN、Ykit 等。&lt;/li&gt; 
 &lt;li&gt;系統 SDK：CoreML（iOS）、MLKit（Android）等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到 iOS、Android 雙端的通用性和開發成本，得物基於 MNN [1] 框架，開發得物端智能推理基建。端智能基建核心功能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;提供端智能模型管理後台，提供完整鏈路，管理模型的放量。&lt;/li&gt; 
 &lt;li&gt;端側提供統一的基建，方便業務進行模型的下載、運行管理，以及熔斷和降級的處理，降低使用門檻。&lt;/li&gt; 
 &lt;li&gt;提供相對完善的穩定性和性能監控機制，及時報警和出錯時止損。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;整體架構&lt;/h2&gt; 
&lt;p&gt;智能封面主要開發流程如下，算法側產出端智能模型，客戶端調用模型推薦視頻封面。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2a5620265c413a531beb927527e7f902.jpeg&quot; alt=&quot;整體架構.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、內容理解算法&lt;/h1&gt; 
&lt;h2&gt;算法調研&lt;/h2&gt; 
&lt;p&gt;端智能封面推薦場景要求無參圖片質量評價 (NR-IQA)、輕量化，因此基於目前的前沿進展進行調研和摸底，確定相關實現方案。主要的調研內容：&lt;/p&gt; 
&lt;p&gt;Faster-VQA[2]：輕量化的視頻質量評估模型。核心是使用優化版本的 Transformer-&amp;gt;Swin-Transformer 來減少網絡計算，加速效率。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df87fd35910cb12fffbd3bdbc6c9e6ac.jpeg&quot; alt=&quot;算法調研.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;UNIQA[3]：統一的圖像質量評估 (IQA) 框架，旨在同時處理全參考 (FR) 和無參考 (NR) 任務。現有的 IQA 模型通常只能處理 FR 或 NR 任務之一，而人類視覺系統 (HVS) 則可以無縫地在兩者之間轉換，因此提出開發一個能夠像人類一樣處理不同類型圖像質量評估任務的模型，統一全參/無參兩類任務。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://my.oschina.net/u/5783135/blog/3&quot; alt=&quot;統一全參:無參.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LAR-IQA[4]：輕量級的 NR-IQA 模型，基於 MobileNetV3 提出了一種新的無參考圖像質量評估模型 LAR-IQA。該模型旨在解決現有模型在實際應用中的侷限性，特別是對於資源受限的移動設備上的實時圖像質量評估任務。核心貢獻點有：雙分支架構、多色空間訓練、Kolmogorov-Arnold Networks (KAN) 結構代替 MLP。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//19f3a290089fee79f78a533eedab4a76.jpeg&quot; alt=&quot;代替 MLP.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;CLIP-IQA[5]：利用 (引入) 對比語言-圖像預訓練 ( CLIP）模型來評估圖像的視覺感知，包括圖像的質量 (look) 和抽象感知 (feel)，無需進行特定任務的訓練。核心在於利用 CLIP 中蘊含的視覺語言先驗，通過精心設計的提示策略來提升評估性能。同時提出了一種反義詞提示配對策略（如&quot;好照片&quot;和&quot;壞照片&quot;成對使用），以減少語言模糊性並增強模型在視覺感知評估中的表現。此外，為了克服 CLIP 對固定尺寸輸入的要求及其可能引入的額外失真問題，增加了移除位置嵌入的方法，進一步提升了模型與人類感知的一致性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8007ee47452b3e892f575ba205380fdd.jpeg&quot; alt=&quot;人類感知的一致性.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Q-Align[6]：目前 NR-IQA 領域的 SOTA 模型，將大模型引入到視覺打分任務中。通過文本定義的級別（例如好、差等）而不是直接的分數（例如 3.45、1.77）來指導訓練 LLMs。標誌着在視覺評分領域的一個重要進展，通過創新地使用離散文本定義級別來訓練 LMMs，不僅提高了評分的準確性和魯棒性，還為未來的研究開闢了新的方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0c11b8b2d8e879a97035e57dfc5f9d58.jpeg&quot; alt=&quot;未來研究方向.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;技術卡點&lt;/h2&gt; 
&lt;p&gt;端側模型存在體積限制，考慮到帶寬成本、推理速度等，將模型體積控制在 30M 以內。&lt;/p&gt; 
&lt;p&gt;目前圖片質量打分 sota 模型，整體都是從打分效果出發，不考慮模型性能 (size/推理耗時/cpu 性能/MAC 等），最小的模型體積也超過 120M，不滿足端上移植的要求。&lt;/p&gt; 
&lt;p&gt;現有的 Faster-VQA 和 LAR-IQA 雖然模型打分效果都不錯，但是同樣因為尺寸超額無法直接使用，也無法直接移植。&lt;/p&gt; 
&lt;h2&gt;算法方案&lt;/h2&gt; 
&lt;p&gt;輕量化網絡：本次算法模型主要在手機本地部署，受限於帶寬和計算資源限制，對模型尺寸有嚴格要求。綜合考慮後採用業界比較成熟的輕量化模型 MobileNetV3 結構作為基礎框架模塊，從 0 到 1 重新訓練輕量化圖片打分模型。&lt;/p&gt; 
&lt;p&gt;數據清洗與數據集構建：考慮到圖片-質量分數據的缺失，使用開源圖片評價大模型對數據預標註（必要時進行人工介入清洗），通過多模型交叉打分驗證和人工標註，最終總體訓練數據量級超過 10w+。整體流程如圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//368cf547e6c18996fef64c0a32f079fb.jpeg&quot; alt=&quot;輕量化圖片質量模型.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;輕量化圖片質量評價模型&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;loss 優化：loss 設計上採用迴歸任務 loss+主觀感知偏差衡量 loss，超參數控制多 loss 融合。&lt;/p&gt; 
&lt;h2&gt;模型移植&lt;/h2&gt; 
&lt;p&gt;MNN 模型支持 Tensorflow、Caffe、ONNX、Torchscripts 等主流模型文件格式，支持 CNN / RNN / GAN / Transformer 等主流網絡結構。&lt;/p&gt; 
&lt;p&gt;MobileNetV3 使用 PyTorch 框架創建、訓練、持久化模型，需要先轉換成為 ONNX 格式，然後再轉換成 MNN 模型。通過 FP16/Int8 壓縮與量化，模型最終大小為 24M，客戶端可以接受。&lt;/p&gt; 
&lt;p&gt;在客戶端進行模型推理調用時，需關注輸入圖片的尺寸、預處理方式以及輸出數據格式等方面。這些參數與模型相互綁定，且在後續的迭代過程中應保持同步。&lt;/p&gt; 
&lt;h1&gt;三、客戶端部署&lt;/h1&gt; 
&lt;h2&gt;整體流程&lt;/h2&gt; 
&lt;p&gt;整體流程如圖所示，用戶進入封面選擇頁，首先對視頻抽幀，然後調用端智能推理。端智能輸出一個評分，獲取評分最高的圖片作為推薦的封面。為了提高封面識別速度，採用批量異步計算。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1598600ee2eb1723baa183512b197daf.jpeg&quot; alt=&quot;時序圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;時序圖&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;整體架構如圖所示，雙端共用端智能基建，各自實現具體的業務邏輯。ClientIntelligence 作為端智能基建，底層封裝了 MNN、OpenCV 等，實現了模型管理（下載、緩存等）、推理、監控等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//195e00ede76e2528097744efb6e02f28.jpeg&quot; alt=&quot;架構圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;架構圖&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;推理一致性&lt;/h2&gt; 
&lt;p&gt;推理一致性（Inference Consistency）是指在不同時間、不同環境、或不同條件下，模型輸出的結果保持穩定、可靠、一致的能力。這是一個非常重要的概念，尤其是在部署機器學習模型時，確保模型的推理一致性對於維護模型的質量和可信度至關重要。&lt;/p&gt; 
&lt;p&gt;推理不一致的來源：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在不同硬件平台上運行模型（例如不同的 CPU、GPU、TPU 等）可能會導致數值精度上的細微差異，進而影響推理結果。&lt;/li&gt; 
 &lt;li&gt;不同的深度學習框架（例如 TensorFlow、PyTorch ）可能會在推理過程中產生不一致的結果，尤其是涉及到數值計算時。&lt;/li&gt; 
 &lt;li&gt;輸入數據預處理方式不一致導致推理結果不同，可以通過數據標準化、歸一化等減少對推理結果的影響。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;具體到智能封面的場景，主要面臨下面幾種一致性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PyTorch、ONNX、MNN 推理一致性：不一致主要來源框架本身，端上模型為了提高推理速度，會對模型進行量化，比如將浮動精度的模型（如 Float32）轉換為低精度模型（如 INT8）。框架造成的推理結果不一致無法避免。&lt;/li&gt; 
 &lt;li&gt;iOS、Android 雙端推理一致性：輸入數據預處理方式是影響推理一致性的關鍵因素，在智能封面場景，圖片數據的預處理方式需要保持一致。雙端由於硬件的差異，推理結果也不同。此外，使用 CPU、GPU 推理結果也會存在細微的差別。智能封面會對圖片評分，選擇評分最高的圖片，因此硬件造成的差別在本場景下可以接受。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;耗時優化&lt;/h2&gt; 
&lt;p&gt;用戶在封面選擇頁面停留時間有限，因此要儘可能地減小封面推薦耗時。&lt;/p&gt; 
&lt;p&gt;首先要定位到耗時操作，然後有針對性地優化。&lt;/p&gt; 
&lt;p&gt;在本場景中，耗時操作包含抽幀、推理，具體優化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;並行計算：多線程同時抽幀、推理，需要注意的是，並行數需要考慮 CPU 和內存的佔用。&lt;/li&gt; 
 &lt;li&gt;GPU 推理：端智能同時支持 CPU 和 GPU 推理，通過 GPU 推理可以顯著減小耗時。&lt;/li&gt; 
 &lt;li&gt;不同性能的手機處理速度差別較大，低性能手機會適當減小抽幀數量，以提高運行速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;優化後，可以在秒級完成抽幀、封面推薦全過程。&lt;/p&gt; 
&lt;h1&gt;四、收益與效果評估&lt;/h1&gt; 
&lt;h2&gt;線上效果對比&lt;/h2&gt; 
&lt;p&gt;線上智能封面、非智能封面抽樣結果如下，使用智能封面功能，整體畫風更優，更清晰。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//82367a57fdb65c7b8908973deac33e27.png&quot; alt=&quot;智能封面 1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7dfbe0e2e76381f1f945b1b73956358d.jpeg&quot; alt=&quot;智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2d0471bc0033478e0616e89ec20fb68a.jpeg&quot; alt=&quot;智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//174cd7645a7e72a6f73a4989029e9f1d.jpeg&quot; alt=&quot;非智能封面 1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5384ba37f15f0ee2978f27a121e61c5.jpeg&quot; alt=&quot;非智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ccd9fa2ea17edaa6440e68730605b7f6.jpeg&quot; alt=&quot;非智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;非智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;競品效果對比&lt;/h2&gt; 
&lt;p&gt;得物智能封面與主流短視頻平台對比結果如下，整體選幀效果和主流短視頻平台可比，部分場景效果較優。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0cae9d9e138b676d7fd4a3979746f488.jpeg&quot; alt=&quot;得物.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b2043070a1e91837f0d6fd2c80c8515b.jpeg&quot; alt=&quot;得物 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//62202b56d7685513082540403a48ea69.jpeg&quot; alt=&quot;得物 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//222452ec8431cde5c74d5e6365b1892c.jpeg&quot; alt=&quot;得物 4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;得物&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//46a22734dffa5e864f6a8d4696f5a28e.jpeg&quot; alt=&quot;短視頻平台 A.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a7a26ea4a17b409e818b4948af61994.jpeg&quot; alt=&quot;短視頻平台 A2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9baec0020ee399603d698795b12ee610.jpeg&quot; alt=&quot;短視頻平台 a3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1edaed634b79363bafa240fd9fa0523.jpeg&quot; alt=&quot;短視頻平台 a4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 A&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//70f897a252d8e3a0a26a3d1bfb4eb901.jpeg&quot; alt=&quot;短視頻平台 B.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fa75bf53d7f6ac8d789ce116090d816c.jpeg&quot; alt=&quot;短視頻平台 n2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//cb60a0103af7f00c610b3c5ca9bc47b2.jpeg&quot; alt=&quot;短視頻平台 b3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5878e0c6c80e361787b25122c05feda7.jpeg&quot; alt=&quot;短視頻平台 b4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 B&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;人工 GSB 評測&lt;/h2&gt; 
&lt;p&gt;在智能封面功能上線後，我們隨機抽取了線上真實的視頻數據，並通過人工 GSB（Good Same Bad）評估方法，對智能選幀所得的圖片與默認首幀圖片進行了圖像質量的對比分析。&lt;/p&gt; 
&lt;p&gt;多組數據、多人次測評整體評估結果為：Good（好）361 票，Same（一樣）182 票，Bad（差）95 票。&lt;/p&gt; 
&lt;p&gt;相較於默認首幀圖片，智能選幀的 GSB 評分提升了 41.7%，表明選幀功能在圖像質量上有了顯著的改進。&lt;/p&gt; 
&lt;h2&gt;線上實驗收益&lt;/h2&gt; 
&lt;p&gt;在發佈側，採用智能封面點擊率、選擇率作為衡量指標，獲得了顯著的收益，其中智能封面點擊率 5.5%，非首幀封面選擇率相對提升 +25.61%。&lt;/p&gt; 
&lt;p&gt;在內容推薦側，採用推薦雙列流視頻點擊率作為衡量指標，pvctr 和 uvctr 都有明顯提升，與對照組相比，pvctr+13.12%、uvctr+18.05%。實驗結果也表明在推薦雙列場景下，更好得封面內容會帶來更好的消費。&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;本文通過端智能推薦視頻封面，幫助創作者降低發文成本，提高發文質量。&lt;/p&gt; 
&lt;p&gt;我們也希望將端智能用在更多的場景，提高用戶體驗。&lt;/p&gt; 
&lt;h1&gt;六、參考資料&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2FMNN&quot; target=&quot;_blank&quot;&gt;https://github.com/alibaba/MNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling.&quot; European conference on computer vision. Cham: Springer Nature Switzerland, 2022.&lt;/li&gt; 
 &lt;li&gt;Zhou, Hantao, et al. &quot;UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment.&quot; arXiv preprint arXiv:2406.01069 (2024).&lt;/li&gt; 
 &lt;li&gt;Avanaki, Nasim Jamshidi, et al. &quot;LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality Assessment Model.&quot; arXiv preprint arXiv:2408.17057 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Jianyi, Kelvin CK Chan, and Chen Change Loy. &quot;Exploring clip for assessing the look and feel of images.&quot; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 2. 2023.&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Q-align: Teaching lmms for visual scoring via discrete text-defined levels.&quot; arXiv preprint arXiv:2312.17090 (2023).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;文 / Devin&amp;amp;linghu&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17569727</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17569727</guid>
            <pubDate>Sun, 23 Feb 2025 03:39:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>微服務是不是一種錯誤的方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;先説想法&lt;/h2&gt; 
&lt;p&gt;這個標題並非一時興起，也並非譁眾取寵，而是我這段時間以來的思考。為什麼會出現這樣的想法？這還得從一個事實説起。&lt;/p&gt; 
&lt;p&gt;眾所周知，微服務並不能提升整個項目的吞吐量，它的作用僅僅只是把項目按照一定的規則拆分成各種模塊，然後每個模塊都可以交給不同小組去開發。他解決的僅僅是大項目的團隊協作問題。而真正能提升吞吐量的，除了程序本身的質量那就是負載均衡了，而且事實上微服務的架構中，每個服務都是以負載均衡的形式部署的，所以這裏就有一個問題了：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果僅僅是為瞭解決【大項目的團隊協作問題】那麼常規的模塊化設計是不是也能做到？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現在由於 maven 的出現，再加上企業內部可以搭建私服，我們完全可以讓每一個服務都以 jar 包的形式來開發。舉個很簡單的一個例子，比如有一個用戶服務，訂單服務，現在一般的做法是寫一個聚合服務去調用這兩個服務的接口，來實現業務邏輯的整合。&lt;/p&gt; 
&lt;p&gt;那如果把用戶服務換成用戶模塊 jar 包、訂單服務換成訂單模塊 jar 包，以 jar 包的形似傳到私服，然後同樣的寫一個聚合服務，聚合服務把這兩個 jar 包引入進來，是不是也能達到這樣的效果？&lt;/p&gt; 
&lt;p&gt;如果需要負載均衡，那我們把這個聚合服務部署多個就好了，完全不影響。我完全想不到跟微服務比起來有什麼壞處，如果有，歡迎大家指正。&lt;/p&gt; 
&lt;h2&gt;微服務有什麼缺點&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;耦合性太高，雖然開發和部署不會影響別的服務，但是你如果動了接口的出入參，那麼其他服務就得同步升級了，而且是調用了這個接口的服務都要升級，又或者你需要為此單拎一個接口出來，做版本區分。&lt;/li&gt; 
 &lt;li&gt;需要註冊中心，項目會多出一箇中間件，提升複雜度。&lt;/li&gt; 
 &lt;li&gt;會消耗內網帶寬，甚至是公網帶寬，因為服務之間的調用都是通過網絡完成的。&lt;/li&gt; 
 &lt;li&gt;會出現分佈式事務的問題，因為一個事務的操作可能會分佈在不同的服務上執行。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;如果用常規的模塊化方案&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;雖然耦合也高，但是如果你動了接口的出入參甚至是接口名，別的服務是不需要立刻升級的，除非你是在改 bug，但這是被業務逼着升級，因為不升級是有 bug 的，但他不會被技術逼得升級，因為模塊只是被打成了一個 jar 包引入了其他模塊裏，無論你怎麼變，已經部署在線上的別的模塊裏依然是用的你的老代碼。&lt;/li&gt; 
 &lt;li&gt;不需要註冊中心&lt;/li&gt; 
 &lt;li&gt;不會消耗多餘的帶寬資源&lt;/li&gt; 
 &lt;li&gt;不需要分佈式事務了&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;還是壓力問題&lt;/h2&gt; 
&lt;p&gt;一定會有人説，你把這麼多模塊都塞進一個服務裏，那這個服務得部署多少台機器啊。&lt;/p&gt; 
&lt;p&gt;説到這裏，就不得不從全局來看待問題了。我們可以看兩張圖（不好意思，有錯別字，但是已經截圖了就懶得改了，能看懂就行）&lt;/p&gt; 
&lt;p&gt;圖 1&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e81da85cd4f90adbd4212a31278d1923442.png&quot; alt=&quot;圖 1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d3e951984db8d820ea3766422f0dcf1a933.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據上面的兩個圖，我們是不是可以這麼説，微服務在面對相同的流量時根本沒有節約服務器的數量？反而還多了？&lt;/p&gt; 
&lt;p&gt;假如左邊的聚合服務，他的業務量需要 10 台服務器才能支撐，右邊的需要 5 台才能支撐，那麼一共是 15 台。而微服務會導致 A 部署 15 台，B 也部署 15 台，再加上兩個聚合服務，一共需要 32 台以上。&lt;/p&gt; 
&lt;p&gt;當然了，這只是極端的情況，現實中可能 A 服務不需要處理這麼多業務，他可以少部署一點，又或者 B 服務可以少部署一點。但無論怎麼算，服務器都是多了。&lt;/p&gt; 
&lt;p&gt;如果採用 jar 包的形式，那麼只需要 15 台就夠了，10 台用來部署左邊的聚合服務，5 台用來部署右邊的聚合服務。&lt;/p&gt; 
&lt;h2&gt;説到底&lt;/h2&gt; 
&lt;p&gt;這其實就是以三方庫的思想在設計模塊化，如果有一個工具類叫用戶管理，有一個工具類叫支付管理。當你需要開發登錄功能的時候，只需要引入一個 jar 包，然後調用裏面的某個方法就好了，當你需要開發支付功能的時候也一樣，你不需要去學習 dubbo，不需要去學習 springcloud，甚至不需要去關注註冊中心是否掛沒掛，註冊中心的 url 是多少，服務到底有沒有正常發佈，有沒有正常被發現。你會不會覺得這樣有什麼不妥呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;以上只是個人的一點淺薄見解，歡迎大家理性探討。&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/yuyenews/blog/17681156</link>
            <guid isPermaLink="false">https://my.oschina.net/yuyenews/blog/17681156</guid>
            <pubDate>Sun, 23 Feb 2025 03:34:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>月之暗面 Kimi 開源 MoE 模型：Moonlight-16B-A3B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 23 日，月之暗面發佈最新論文《Muon is Scalable for LLM Training》，並首次開源了 MoE 模型 Moonlight-16B-A3B。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0224/104754_uGuz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;論文顯示，月之暗面通過深度改造 Muon 優化器，並將其運用於實際訓練，證明瞭 Muon 在更大規模訓練中的有效性，是 AdamW 訓練效率的 2 倍，且模型性能相當。&lt;/p&gt; 
&lt;p&gt;據悉，本次論文所使用的模型為 Moonlight-16B-A3B，總參數量為 15.29B，激活參數為 2.24B，其使用 Muon 優化器，在 5.7T Tokens 的訓練數據下獲得上述成績。&lt;/p&gt; 
&lt;p&gt;目前，論文及 Moonlight-16B-A3B 相關內容已上架 GitHub 和 HuggingFace。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmoonshotai%2FMoonlight-16B-A3B&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/moonshotai/Moonlight-16B-A3B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMoonshotAI%2FMoonlight&quot; target=&quot;_blank&quot;&gt;https://github.com/MoonshotAI/Moonlight&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335435/moonlight-16b-a3b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335435/moonlight-16b-a3b</guid>
            <pubDate>Sun, 23 Feb 2025 02:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>【贈書】京東圖書熱銷榜前四，鴻蒙開發竟然這麼火？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;本文作者堅果和清華大學出版社來贈書啦~😄&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;自本文發佈一週時間內，在下方評論區發表關於鴻蒙應用開發的相關內容或對本書的期待，將有機會免費獲得一本書。&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;我們會根據評論內容，選取 3 名用戶，各贈送一本《極速探索 HarmonyOS NEXT：純血鴻蒙應用開發實踐》。評論區見～&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;大家好，我是《極速探索 HarmonyOS NEXT：純血鴻蒙應用開發實踐》一書的副主編，堅果。1 月份的時候，開源中國的肖老師聯繫我，邀請寫一篇文章。我感到非常榮幸，但考慮到出版社已經放假，無法郵寄書，就耽擱至今，一個月後的今天我打算動筆開始輸出。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;一、寫書的初衷：填補知識空白，助力生態發展&lt;/h2&gt; 
&lt;p&gt;在科技的廣袤星空中，操作系統猶如最璀璨的星辰之一，它關乎着無數智能設備的運轉，更牽繫着國家科技自主與發展的命脈。當我在最初接觸到鴻蒙時，率先接觸的還是開源鴻蒙，那個時候在我的眼裏，開源鴻蒙就是一片尚未開墾完全的荒地，生態的雛形雖已顯現，卻遠談不上繁榮昌盛。但正是這份艱難，讓我深知，有些事，明知難為而必須為之，因為那是正確且意義非凡的方向。&lt;/p&gt; 
&lt;p&gt;在此之前，我一直在技術博客領域耕耘，分享着各種技術心得與見解。那些博客文章，如同點點繁星，照亮了部分開發者探索鴻蒙的初始道路，同時也是我自己學習路上的一個見證。&lt;/p&gt; 
&lt;p&gt;然而，我逐漸發現，博客的零散性使得開發者們難以從中構建起對鴻蒙系統的全面認知。每個博客只能聚焦於某個具體的技術點或是當下熱點，無法形成系統性的知識架構。很多開發者在閲讀博客後，雖然對某些技術有了初步的瞭解，但當他們想要進一步深入，去構建自己的鴻蒙原生應用或是參與到鴻蒙生態建設中時，卻常常感到無從下手，彷彿置身於一片技術的迷霧之中。&lt;/p&gt; 
&lt;p&gt;基於此，我萌生了和小夥伴們一起撰寫一本系統性的鴻蒙開發書籍的想法。我希望能夠為開發者們提供一份詳盡的地圖，讓他們能夠清晰地看到鴻蒙生態的全貌，從基礎的系統架構到複雜的應用開發流程，從分佈式技術的原理到實際的場景應用，一應俱全。這本書不僅僅是為了傳授技術知識，更是為了吸引更多的人加入到鴻蒙生態的建設中來。&lt;/p&gt; 
&lt;p&gt;我們深知，鴻蒙的發展離不開廣大開發者的共同努力，只有匯聚起各方的力量，才能讓這個生態茁壯成長，成為推動鴻蒙生態的進步的強大動力。在此我乃至堅果派的初心和使命就是讓中國乃至全球的每一個開發者都認識鴻蒙、瞭解鴻蒙，共同參與到鴻蒙生態的建設中來。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; src=&quot;https://oscimg.oschina.net/oscnet//ec76414c76af1a7f723df21e221999d0.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;二、鴻蒙生態的現狀：艱難起步，充滿挑戰&lt;/h2&gt; 
&lt;p&gt;目前，鴻蒙生態已經取得了一定的進展，但仍然面臨諸多挑戰。據華為官方數據顯示，鴻蒙系統已有超過 1.5 萬個應用和元服務上架，覆蓋辦公、社交、娛樂等 18 個垂直領域，能夠滿足用戶 99.9% 的使用時長。然而，與安卓和 iOS 相比，鴻蒙的應用數量仍有較大差距。安卓應用商店的應用數量已經超過 300 萬，iOS 應用商店的應用數量也超過 200 萬。雖然鴻蒙應用已經能夠滿足大部分用戶的日常使用需求，但在一些垂直領域，如專業設計、高端遊戲等，應用的豐富度和成熟度仍有待提高。&lt;/p&gt; 
&lt;p&gt;在寫作的初期，生態的不完善意味着很多技術細節缺乏足夠的參考資料和實踐案例。但我堅信，越是艱難處，越是修心時。我們一頭扎進技術研究的海洋，與堅果派裏的同樣懷揣着熱情的開發者們交流探討，常常為了一個技術原理或是實現方式爭論得面紅耳赤，卻也在這過程中碰撞出智慧的火花。&lt;/p&gt; 
&lt;p&gt;那些無數個日夜，我們聚在一起開會，常常一開就是到凌晨。大家的眼睛裏雖佈滿血絲，卻閃爍着對鴻矇事業的執着光芒。我們深知，自己正在做的，是為鴻蒙這片黑土地添磚加瓦，讓它能夠茁壯成長，支撐起我國智能設備的未來天空。&lt;/p&gt; 
&lt;p&gt;如今這本書位居京東圖書熱銷榜前四，證明我們的選擇是正確的。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; src=&quot;https://oscimg.oschina.net/oscnet//f7459720ca9a7884234df031e1b2c4e2.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;三、寫書過程中的挑戰：資料匱乏，團隊協作&lt;/h2&gt; 
&lt;p&gt;當然寫博客與寫書，有着本質的區別。博客更像是一時靈感的迸發，是對某個具體技術點或是當下熱點的快速分享，內容相對零散，追求的是時效性和簡潔性。而寫書，則是一項系統性的工程，它需要構建起完整的知識體系，從基礎概念到深入應用，從技術原理到實踐案例，層層遞進，環環相扣。每一個章節的安排，每一句話的斟酌，都要為讀者呈現出一個清晰、全面且深入的開源鴻蒙世界。&lt;/p&gt; 
&lt;p&gt;為了做好內容支撐，我們深入到鴻蒙原生應用開發的每一個角落。從基礎環境開始，到它的分佈式技術，感受那讓不同設備無縫協同、宛如一體的神奇魅力；再到它的應用開發框架，體會開發者如何在這個舞台上施展才華，創造出豐富多彩的應用生態。我也拜訪瞭解了眾多參與鴻蒙研發的企業和開發者，聆聽他們背後的故事，讓我更好的瞭解這本書如何編寫。&lt;/p&gt; 
&lt;p&gt;在書中，我特別加入了大量實戰案例，如堅果單車等，這些案例不僅展示了鴻蒙系統的實際應用場景，還幫助開發者更好地理解和掌握鴻蒙開發技術。例如，堅果單車項目通過使用華為賬號服務（Account Kit）、地圖服務（Map Kit）、推送服務（Push Kit）等，實現了共享單車的完整功能，包括用戶註冊登錄、地圖定位、車輛預訂和消息推送等。這些實戰案例為開發者提供了寶貴的參考和借鑑。&lt;/p&gt; 
&lt;p&gt;此外，為了滿足不同用戶的學習需求，我們還提供了對應的 PPT 和視頻教程。PPT 詳細講解了鴻蒙開發的核心知識點，視頻教程則通過實際操作演示，幫助開發者更直觀地理解鴻蒙開發流程。這些資源不僅豐富了書籍的內容，也為開發者提供了多種學習方式，方便他們根據自己的喜好和需求選擇合適的學習途徑。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;四、選擇紙質書的原因：傳承與體驗的考量&lt;/h2&gt; 
&lt;p&gt;在這個電子書盛行的時代，我卻毅然選擇了紙質書的形式。這並非是對潮流的逆反，而是出於對知識傳承與閲讀體驗的深思熟慮。紙質書有着獨特的質感與分量，它承載着知識的厚重與歷史的沉澱。當讀者翻開這本書的每一頁，指尖觸碰到紙張的那一刻，彷彿能夠感受到知識的溫度，建立起與作者更深層次的情感連接。而且，紙質書便於讀者在書桌前靜心研讀，做筆記、標註重點，這種沉浸式的學習體驗是電子書難以比擬的。它能夠更好地幫助讀者深入思考、消化吸收書中的知識，讓每一個技術要點都深深烙印在腦海中。&lt;/p&gt; 
&lt;p&gt;此外，紙質書的收藏價值也是我選擇它的一個重要原因。一本好書，不僅能夠提供知識，還能成為讀者書架上的寶貴財富，隨時可以翻閲回顧。我希望這本書能夠成為開發者們在鴻蒙技術道路上的一位良師益友，陪伴他們走過一段又一段的技術征程。如今圖書出版，我也是捐贈了價值 10 餘萬的書籍以及學習資料到雲南、貴州、湖北、廣西、甘肅、鄭州、東北、河南、黑龍江八省，八校！希望能有更多的學生開發者受益。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;image-20250224103538229&quot; src=&quot;https://oscimg.oschina.net/oscnet//813eecaf243c8c157a1afa29c98b9a4b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;五、寫書的意義：家國情懷與未來展望&lt;/h2&gt; 
&lt;p&gt;這一路走來，有過迷茫，有過疲憊，但每當想到自己是在為整個的鴻蒙生態的完整建設添磚加瓦，是在陪伴開源鴻蒙共同成長，內心便湧起無盡的力量。我堅信，只要我們秉持着長期主義的理念，持續不斷地為開源鴻蒙的生態建設貢獻力量，它終將成為科技領域的參天大樹，為我國的智能發展撐起一片廣闊的天地。&lt;/p&gt; 
&lt;p&gt;而這本書，就是我們在這段征程中留下的深深足跡，也是我向所有為開源鴻矇事業奮鬥的人們獻上的一份誠摯敬意，更是我對家國科技未來充滿信心的美好期許。&lt;/p&gt; 
&lt;p&gt;最後，堅果派的初心和使命就是讓中國乃至全球的每一個開發者都認識鴻蒙、瞭解鴻蒙。我深懷感激之情，向每一位給予我這本書厚愛與支持的讀者、同行、合作伙伴、出版社以及親朋好友致以最誠摯的謝意。還有那些在背後默默支持、鼓勵我們的親朋好友以及家人們，你們的熱情接納、積極推薦以及真誠反饋，如同璀璨繁星照亮了我前行的道路。&lt;/p&gt; 
&lt;p&gt;感謝大家共同參與到鴻蒙生態的建設中來。我相信，通過我們的共同努力，鴻蒙生態將不斷壯大，為全球科技發展貢獻中國智慧和力量。在未來的日子裏，無論鴻蒙走向何方，我都將始終如一地陪伴在它身旁，見證它的輝煌，續寫屬於我們共同的華麗新篇章。最後想説選擇鴻蒙正當時，歡迎大家與我們一起選擇鴻蒙。加入鴻蒙大家庭。&lt;/p&gt; 
&lt;p&gt;最後附上個人微信。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;img&quot; height=&quot;406&quot; src=&quot;https://oscimg.oschina.net/oscnet//f7ba420550a5f811f61c72ca2eef10cb.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3936705/blog/17752894</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3936705/blog/17752894</guid>
            <pubDate>Sun, 23 Feb 2025 02:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>超 20 家央企接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近來，國資央企「牽手」DeepSeek 已成為一股新風潮。據《經濟參考報》記者不完全統計，目前有超 20 家央企接入 DeepSeek，涉及能源、通信、汽車、金融、建築等多個領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;業內人士指出，這一系列動作的背後是國資央企全面開展「AI+專項行動」，加速探索人工智能深度應用到豐富多樣的生產場景。國務院國資委近日召開中央企業「AI+」專項行動深化部署會。會上發佈了國資央企「AI+」專項行動實施要點，啓動了戰略性高價值場景建設專項工作。會議要求，中央企業在編制企業「十五五」規劃中要將發展人工智能作為重點，打造更多科技領軍企業，孵化培育一批初創企業。要加大相關資金投入，持續壯大發展人工智能產業。要優化人才引育，建立更加符合行業特點規律的人才評價體系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全面接入只是央企擁抱 DeepSeek 的一個開始。有業內人士表示，如何將 DeepSeek 的通用化技術方案與具體業務需求深度結合，仍需要大量定製化開發和測試。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國企業改革研究會研究員周麗莎稱，「DeepSeek 出現實現了 AI 平權，未來 AI 競爭就是數據規模和質量，央企擁有龐大的數據資源，與 DeepSeek 結合後，數據流通與市場化進程加速。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;周麗莎表示，汽車行業的大模型，可用於企業數據分析和智能決策，提升智能駕駛和車載交互能力。交通與物流領域等央企也可能會利用 AI 技術優化交通基礎設施建設、物流配送路線規劃、智能倉儲管理等。科技與通信領域央企可能會與 DeepSeek 合作，推動人工智能在通信技術、網絡安全、智能辦公等領域的應用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335429</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335429</guid>
            <pubDate>Sun, 23 Feb 2025 02:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>新款 MacBook Air 有望 3 月推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 23 日，據彭博社記者 Mark Gurman 獲悉，搭載 M4 處理器的 MacBook Air 有望在下個月推出。&lt;/p&gt; 
&lt;p&gt;Gurman 表示，蘋果的營銷、銷售和零售團隊已經在為這款新品的發佈進行準備，同時蘋果在售的 MacBook Air 商店庫存也正在減少，這通常意味着產品更新臨近。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4abdbdc9b62de0f82a6ebe56037c2bf7b90.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從去年更新的 MacBook Pro 來看，&lt;strong&gt;新款 MacBook Air 除了處理器升級為 M4，還有望獲得雷靂 4 接口、更多外接顯示屏支持、納米塗層屏幕可選項、攝像頭人物居中等等更新&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;目前 M3 MacBook Air 京東平台國補價格 6679.2 元起，如果 M4 MacBook Air 支持國補，價格也會在這個數字上下。&lt;/p&gt; 
&lt;p&gt;Apple 智能也有了新的時間表。蘋果日前宣佈了 Apple 智能將於四月份支持中文在內的更多語言，也發佈了支持中文 Apple 智能的 iOS 18.4 測試版。不過 Gurman 預計，國行版本的 Apple 智能將於 iOS 18.5 版本時獲批推出，時間大概會在今年年中。&lt;/p&gt; 
&lt;p&gt;目前，海外 Apple 智能僅集成了 ChatGPT 一個第三方大模型，有消息指出，與 Google Gemini 的合作即將到來。在與 iOS 18.4 測試版一起推送的後端更新中，有開發者發現了 Apple 智能第三方大模型中提供了「Google」和「OpenAI」選項。&lt;/p&gt; 
&lt;p&gt;而此前 The Information 的消息指出，中國大陸版的 Apple 智能將集成阿里通義大模型以及百度文心大模型，其中前者將負責更主要的任務處理。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335426</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335426</guid>
            <pubDate>Sun, 23 Feb 2025 02:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek 開源周」首發項目：FlashMLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 「開源周」今日正式&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fdeepseek_ai%2Fstatus%2F1893836827574030466&quot; target=&quot;_blank&quot;&gt;開啓&lt;/a&gt;，首個開源的代碼倉庫為 FlashMLA—— 針對 Hopper GPU 優化的高效 MLA 解碼內核，專為處理可變長度序列而設計，目前已投入生產環境。&lt;/p&gt; 
&lt;p&gt;據介紹，FlashMLA 專門針對多層注意力機制進行了優化，能夠加速 LLM 的解碼過程，從而提高模型的響應速度和吞吐量。FlashMLA 可在 H800 芯片上實現最高 3000GB/S 的帶寬和 580 TFLOPS 的算力。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FFlashMLA&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/FlashMLA&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;1404&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/102144_YFdi_2720166.png&quot; width=&quot;1270&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335425/deepseek-flashmla</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335425/deepseek-flashmla</guid>
            <pubDate>Sun, 23 Feb 2025 02:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>黃仁勳首次公開評論 DeepSeek：市場對該模型的影響存在誤解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;nvidia-ceo-jensen-huang-deepsee&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在近日播出的一檔&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DF3NJ5TwTaTI%26t%3D97s&quot; target=&quot;_blank&quot;&gt;採訪節目中&lt;/a&gt;，黃仁勳在與英偉達合作伙伴、數據中心解決方案提供商 DataDirect Networks 的 CEO Alex Bouzari 進行交談時，稱 DeepSeek 的開源推理模型 R1「令人興奮不已」，而市場對於 R1 的反應中存在一些誤解，R1 的發佈本質上利好 AI 市場。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3357e76795816b7ec854aee0331139c724b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;黃仁勳表示：「我認為市場對 R1 的反應是，‘天哪，AI 已經完了’。你知道，就像是 R1 從天而降，我們不再需要進行任何計算。但事實恰恰相反。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;黃仁勳認為，R1 的發佈本質上利好 AI 市場，能夠加速 AI 被採用，也就意味着市場仍然需要計算資源：「這讓每個人都注意到，模型的效率遠超我們的想象。因此，它正在不斷擴大，並加速 AI 的普及。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他還指出，雖然 DeepSeek 在 AI 模型的預訓練方面取得了進步，但作為模型「學習解決問題」的關鍵環節，後訓練 (post-training) 仍然很重要，需要大量的資源，並且推理本身就是「計算密集型的部分」。黃仁勳表示：「從投資者的角度來看，他們有一種思維模式，認為只要先進行預訓練，然後進行推理，而推理就是向 AI 提問並立即得到答案。顯然，這種觀念是錯誤的。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335424/nvidia-ceo-jensen-huang-deepsee</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335424/nvidia-ceo-jensen-huang-deepsee</guid>
            <pubDate>Sun, 23 Feb 2025 02:15:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里宣佈投入 3800 億元建設雲和 AI 硬件基礎設施</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里巴巴集團 CEO 吳泳銘宣佈，未來三年，阿里將投入超過 3800 億元，用於建設雲和 AI 硬件基礎設施，總額超過去十年總和。這也創下中國民營企業在雲和 AI 硬件基礎設施建設領域有史以來最大規模投資紀錄。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;90&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3732938e258b310994d0f694f7404b0d68b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;吳泳銘表示：「AI 爆發遠超預期，國內科技產業方興未艾，潛力巨大。阿里巴巴將不遺餘力加速雲和 AI 硬件基礎設施建設，助推全行業生態發展。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335422</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335422</guid>
            <pubDate>Sun, 23 Feb 2025 02:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Bun 1.2.3: 全新 Glob 實現引領性能突破</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;開源 JavaScript 運行時 Bun 於近日發佈了 1.2.3 版本，此次更新修復了 128 個 bug，並帶來多項重要改進。其中最引人注目的是對 Glob 功能的全面重寫和優化，這使得 Bun 的 Glob 實現了性能與正確性的雙重突破。&lt;/p&gt; 
&lt;p&gt;Glob 模式匹配是現代構建工具的核心功能之一，用於快速查找和過濾文件。此次更新中，Bun 團隊將 Rust 生態系統中廣受好評的 fast-glob 庫移植到了 Bun 中，這不僅帶來了顯著的性能提升，更確保了匹配結果的準確性。新版本特別優化了目錄匹配和&quot;**&quot;通配符模式的處理，解決了之前版本中存在的多個關鍵 bug。這一改進使得 Bun 的 Glob 實現不僅在速度上領先業界，在可靠性方面也達到了一個新的高度。&lt;/p&gt; 
&lt;p&gt;除了 Glob 的重大改進，Bun 1.2.3 還為開發者帶來了一個全功能的前端開發工具鏈。現在開發者可以直接通過執行 HTML 文件來啓動開發服務器，支持 React 的熱重載功能，並計劃在未來支持 Svelte 和 Vue 等框架。這種零配置的開發體驗大大簡化了前端項目的啓動流程。&lt;/p&gt; 
&lt;p&gt;在 Web 應用開發方面，Bun.serve() 新增了內置路由功能，支持動態路徑參數和異步響應，使得全棧應用的開發變得更加流暢。開發者現在可以在同一個進程中運行前端和後端代碼，無需額外的代理服務器或 URL 重寫配置。&lt;/p&gt; 
&lt;p&gt;數據庫方面，Bun.SQL 得到了顯著增強，新增了 sql.array、SQL 片段和 sql.file 等功能，並修復了多個關鍵 bug。新版本支持多語句查詢執行、可配置的預處理語句，以及改進的數組支持，這些改進使得 Bun 在處理複雜數據庫操作時更加可靠。&lt;/p&gt; 
&lt;p&gt;在性能優化方面，此版本引入了新的 WebAssembly 解釋器 IPInt，取代了原有的 LLInt 解釋器。這一改變顯著減少了 WebAssembly 代碼的啓動時間和內存佔用，因為新的解釋器可以直接執行 WebAssembly 代碼，而無需先將其轉換為不同的字節碼格式。&lt;/p&gt; 
&lt;p&gt;Node.js 兼容性也得到了進一步加強，特別是在 Buffer 處理和 Node-API（napi）方面。現在支持完整的證書包加載，Buffer 的多個核心方法得到了改進，確保了與 Node.js 生態系統的更好兼容性。&lt;/p&gt; 
&lt;p&gt;其他值得注意的改進包括：優化了文件流的內存使用、改進了 CSS 處理、修復了 FormData 邊界引號問題，以及增強了 UDP 多播成員資格的穩定性等。此版本還改進了命令行幫助顯示，使得標誌參數的使用更加直觀。&lt;/p&gt; 
&lt;p&gt;這次更新得到了開源社區的廣泛支持，共有 23 位貢獻者參與其中。特別值得一提的是，probably-neb 和 zackradisic 在改進 Glob 功能方面做出了重要貢獻，而其他貢獻者也在各個方面幫助提升了 Bun 的整體質量。&lt;/p&gt; 
&lt;p&gt;總的來説，Bun 1.2.3 的發佈標誌着這個年輕的 JavaScript 運行時在性能、功能性和可靠性方面都達到了一個新的水平。特別是新的 Glob 實現，不僅展示了項目團隊的技術實力，也為未來的發展奠定了堅實的基礎。隨着更多功能的完善和性能的提升，Bun 正在逐步實現其成為主流 JavaScript 運行時的目標。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335264</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335264</guid>
            <pubDate>Sat, 22 Feb 2025 00:27:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>百度 Web 端首頁上線 DeepSeek 入口，開放僅 1 小時超千萬人使用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度（baidu.com) Web 首頁已上線 DeepSeek 入口，搜索框下方點擊「AI 搜索 DeepSeek 滿血版」即可使用。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1758&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0221/185724_krJK_2720166.png&quot; width=&quot;3340&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據稱百度搜索此次接入的是 DeepSeek 滿血版，融合了百度聯網搜索功能，具備檢索增強 RAG 等技術能力，便於用戶獲取更新、更低幻覺的信息。&lt;/p&gt; 
&lt;p&gt;此前 16 日晚間，百度搜索宣佈將全面接入 DeepSeek 和文心大模型最新的深度搜索功能。&lt;/p&gt; 
&lt;p&gt;隨後 18 日，百度 APP 的搜索先上線了 DeepSeek 滿血版，但是入口不太明顯，用戶需要先在百度 App 輸入任意搜索詞，完成一輪搜索後，在搜索結果頁點擊「AI+」進入 AI 搜索，再點擊下方去試試「滿血版」才可與 DeepSeek 對話。&lt;/p&gt; 
&lt;p&gt;現在百度 Web 首頁直接在醒目位置開放 DeepSeek 入口，用戶使用更為方便了。據新浪科技報道，百度 PC 端開放 DeepSeek 僅 1 小時就有超千萬人使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335110</guid>
            <pubDate>Fri, 21 Feb 2025 10:57:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>何小鵬談人形機器人：當前行業還接近自動駕駛的 L2 初階</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;小鵬汽車董事長何小鵬發文闡述了對人形機器人市場發展的看法。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;216&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ec56d4dca7cc036b08d32f2878e8b07919a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他認為，總的來説&lt;strong&gt;當前人形機器人還接近自動駕駛的 L2 初階，但是都期望儘早實現可量產可實現商業價值的 L3 初階能力&lt;/strong&gt;，這個跳躍會是數十倍能力和難度的跨越，這也是小鵬 Iron 機器人的目標。&lt;/p&gt; 
&lt;p&gt;但是和自動駕駛不同，自動駕駛的 L3 可能就會達到 iPhone4 時刻，&lt;strong&gt;而通用人形機器人可能要到達 L4 階段才行&lt;/strong&gt;，也只有到達 L4 階段，大家所想象的走進千家萬戶才成為現實，這個起碼還需要數年甚至更長時間的努力。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;小鵬將通用機器人定義為五個層級的能力：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;L1：無自主操控 &lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;機器人完全由人類操作者控制，不具備任何獨立控制甚至決策能力。 （類似遙控賽車）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;L2：基礎輔助智能+操控監督 &lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;機器人執行基本的預編程動作並能自主保持穩定，但仍需持續的人工監督。 （類似兩/多足機器人，工業機械臂，掃地機器人等）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;L3：具身智能+訓練監督 &lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;機器人在大量場景中能夠經訓練後獨立運行，但在部分情況下會尋求人工監督。 （當前所有人形機器人公司的量產目標是在 L3 初段）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;L4：自成長智能+輕微監督&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;機器人能夠執行廣泛的複雜適應性和協作性任務，並在最少的人工監督下適應。&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;L5：AGI/ASI 完全自主 &lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;機器人在認知和物理任務上展現出與人類相當甚至超越人類的能力，在法規和機器人法則下自主運行。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335107</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335107</guid>
            <pubDate>Fri, 21 Feb 2025 10:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 累計下載量超 1.1 億次，周活躍最高近 9700 萬</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據《每日經濟新聞》從數據分析平台 QuestMobile 獨家獲得的最新數據顯示，從上線以來至 2 月 9 日，DeepSeek App 的累計下載量超 1.1 億次，周活躍用戶規模最高近 9700 萬。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-50b51f1e13947892086ed122e2766e996d4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中，1 月 20 日至 1 月 26 日，DeepSeek App 周下載量達到 226 萬次。次周，下載量則直接飆升至 6300 萬次，環比增長超 2700%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6830c207b0d4ca91f0be3ca65bf712afd80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;QuestMobile 數據顯示，1 月 20 日至 1 月 26 日，Kimi 周活躍用戶規模環比增長不到 28%。同期 DeepSeek 的周活躍用戶規模環比增長超 750%。&lt;/p&gt; 
&lt;p&gt;每經記者統計移動營銷平台 AppGrowing 的數據發現，自 2024 年 3 月開始，Kimi 的總投放金額預計高達 9 億元。而這種大規模燒錢、靠營銷維持用戶增長的方式，並沒有為 Kimi 帶來太多正向反饋。&lt;/p&gt; 
&lt;p&gt;同樣在花錢投流買量上毫不手軟的，還有字節旗下的豆包，曾經兩個月的投放總額預計就高達 3 億元。在 DeepSeek 爆火之前，豆包是中國活躍用戶量最高的生成式 AI 應用。&lt;/p&gt; 
&lt;p&gt;1 月 20 日至 1 月 26 日，DeepSeek 下載量已初現增長勢頭，達到 226 萬次，環比增長超 690%，超越同期的 Kimi，飆升至國內第二，僅次於豆包。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9ccdaedb020d3be355f6fa1232e768fd266.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;每經記者通過梳理移動營銷平台 AppGrowing 的預估數據發現，自 2024 年 3 月開始，幾乎每月 Kimi 的廣告投放都達到上千萬元。其中，2024 年 10 月和 11 月均在 2 億元以上。截至目前，預計 Kimi 的投放總金額高達 9 億元。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335088</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335088</guid>
            <pubDate>Fri, 21 Feb 2025 08:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>小紅書將接入 DeepSeek，AI 搜索「點點」 iOS 版下載量總計約 20 萬</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FL7OS03Vs_VePmtIp_YD_8Q&quot; target=&quot;_blank&quot;&gt;根據「鈦媒體 AGI」的獨家報道&lt;/a&gt;，&lt;strong&gt;小紅書即將接入 DeepSeek-R1 開源模型，其 AI 搜索產品「點點」App 將推出」深度思考「功能，目前處於新功能內測體驗階段。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;小紅書成立於 2013 年，為一款社交和社區應用產品，用戶可以通過短視頻、圖文等形式記錄生活點滴，分享生活方式，最初以&quot;標記我的生活&quot;為 slogan。&lt;/p&gt; 
&lt;p&gt;截至 2024 年 6 月，小紅書月活用戶已達 3.2 億人，日活用戶達 1.2 億人。&lt;/p&gt; 
&lt;p&gt;隨着 2025 年初，短視頻應用、抖音海外版 TikTok 在美國下架，小紅書在美國迎來了一波新用戶增長。據分析公司 Similarweb 的最新數據顯示，僅今年 1 月 16 日一天，小紅書在美國 iOS 和 Android 設備上的日活躍用戶數猛增近 300 萬，達到約 340 萬人次。&lt;/p&gt; 
&lt;p&gt;據 QuestMobile 數據顯示，2024 年 12 月，小紅書平台月活躍用戶規模達 2.25 億，月人均使用時長 21.22 小時，在新媒體平台排名中超過了嗶哩嗶哩（B 站），僅次於抖音、快手、微博。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335087</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335087</guid>
            <pubDate>Fri, 21 Feb 2025 08:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技申請秧 Bot 商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;天眼查知識產權信息顯示，杭州宇樹科技有限公司近日申請註冊多枚「秧 Bot」商標，國際分類為科學儀器、機械設備、服裝鞋帽等，當前商標狀態均為等待實質審查。&lt;/p&gt; 
&lt;p&gt;此外，該公司近日還申請註冊了多枚「春晚機器人」樣式圖形商標，國際分類為健身器材、機械設備、科學儀器等，當前商標狀態均為等待實質審查。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;351&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c93301ab8f3c4daaae55f2208d37395d9b8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335081</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335081</guid>
            <pubDate>Fri, 21 Feb 2025 07:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>