<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Sun, 13 Apr 2025 07:42:21 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>「天衍」量子計算雲平台訪問量突破 2700 萬</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnstock.com%2FcommonDetail%2F394917&quot; target=&quot;_blank&quot;&gt;據報道&lt;/a&gt;&lt;/u&gt;，「天衍」量子計算雲平台當前訪問量已突破 2700 萬。該平台面向全球開放，涵蓋海內外 50 多個國家的用戶，提交的實驗任務數超過 140 萬次。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1856&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/192538_z4F9_2720166.png&quot; width=&quot;3360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqc.zdxlz.com%2Fhome%3Flang%3Dzh&quot; target=&quot;_blank&quot;&gt;https://qc.zdxlz.com/home?lang=zh&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;「天衍」量子計算雲平台發佈於 2023 年 11 月，由中國電信發佈，各項性能均達到國際一流水平。該平台配備 5 類運算性能世界一流的高性能仿真機和 Cqlib 系列編程框架，支持量子模擬、量子化學、量子氣象、量子人工智能等領域的應用探索。&lt;/p&gt; 
&lt;p&gt;2024 年 12 月，「天衍」量子計算雲平台正式接入全國單台比特數最多的超導量子計算機「天衍-504」，實現了「天衍」量子計算雲平台在算力規模和算力類型上的雙重升級，構建起由一台 24 比特、兩台 176 比特和一台 504 比特的量子計算機組成的國內最大規模量子計算集羣。&lt;/p&gt; 
&lt;p&gt;據瞭解，2025 年被聯合國宣佈為「國際量子科技年」（International Years of Quantum, IYQ），旨在以量子力學誕生 100 週年為契機，在全球範圍內提升公眾對量子科技的認知度，促進各國在量子領域的交流與合作，加速推進量子技術的研發與產業化應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344050</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344050</guid>
            <pubDate>Thu, 03 Apr 2025 11:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌發佈《Prompt Engineering》白皮書</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌近日發佈了一份長達 68 頁的白皮書，系統闡述了提示工程（Prompt Engineering）的核心理念與最佳實踐。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1600&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/190255_bXPt_2720166.png&quot; width=&quot;1260&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本白皮書詳細討論了提示詞工程，探討各種提示詞技巧，幫助新手入門，並分享一些技巧和最佳實踐，助任何人成為提示專家。還討論了在設計提示時可能遇到的一些挑戰。&lt;/p&gt; 
&lt;p&gt;白皮書深入探討了多種提示技術，包括：零樣本提示（Zero-Shot Prompting）、單樣本提示（One-Shot Prompting）、少樣本提示（Few-Shot Prompting）、思維鏈提示（Chain-of-Thought，CoT）、ReAct 提示以及代碼提示。&lt;/p&gt; 
&lt;p&gt;這些技術各有適用場景，白皮書通過案例分析展示瞭如何根據任務需求選擇合適的提示策略。&lt;/p&gt; 
&lt;p&gt;詳情訪問：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kaggle.com%2Fwhitepaper-prompt-engineering&quot; target=&quot;_blank&quot;&gt;https://www.kaggle.com/whitepaper-prompt-engineering&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344043/whitepaper-prompt-engineering</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344043/whitepaper-prompt-engineering</guid>
            <pubDate>Thu, 03 Apr 2025 11:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>全球腦機接口應用迎來新突破</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;全球腦機接口技術飛速發展，應用領域正逐漸從醫療領域擴大至教育、遊戲等非醫療領域。與此同時，人工智能（AI）等新興技術的快速演進正在推動腦機接口技術應用實現更多突破。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腦機接口是一種變革性的人機交互技術，其工作原理是採集腦部神經信號並分析轉換成特定指令。該技術能夠在大腦與外部設備之間創建直接連接，實現「腦」與「機」之間的直接信息交換。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腦機接口設備的重要功能包括幫助治療記憶力衰退、頸脊髓損傷及其他神經系統疾病，幫助有運動功能障礙的患者、癱瘓人羣恢復部分能力，甚至幫助他們重新行走，改善和提升他們的生活質量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着腦機接口技術的發展，其在醫療領域與非醫療領域的潛在應用場景也在不斷擴展，包括監測與評估大腦狀態、調控神經、增強感官能力、提高遊戲的操控性以及用於教育等領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，腦機接口技術按照其是否需要侵入大腦以及侵入的程度分為非侵入式、侵入式、半侵入式三類。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;侵入式腦機接口需要將電極或傳感器等硬件設備植入到大腦皮層，以直接捕獲神經信號，主要優點是信號質量較高，可以實現對神經信號的直接監測和調控。但由於涉及手術風險和可能的健康隱患，侵入式腦機接口的應用範圍相對有限。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;非侵入式腦機接口則不需要通過手術將硬件設備植入人體，而是通過採集腦電信號等無創方式來間接監測大腦活動，具有無創、低風險、易操作等優點，但存在信號質量相對較低、對環境幹擾較為敏感等侷限性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;半侵入式腦機接口介於非侵入式和侵入式腦機接口之間，雖然仍需要通過手術佈置電極，但電極並不植入大腦皮層，而是置於顱骨下、皮層上方。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;業內人士認為，全球腦機接口的發展歷程可以分為學術探索階段、科學論證階段和應用試驗階段，目前該技術正處於第三個階段，並蓬勃發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 1 月，美國「神經連接」公司完成了該公司首例腦機接口設備人體移植，移植後患者可通過意念移動電腦屏幕上的光標；2024 年 3 月，中國團隊宣佈成功研發出 65000 通道、雙向的腦機接口芯片；2024 年 8 月，「神經連接」公司表示，已完成該公司第二例腦機接口設備人體移植，接受移植者在術後用意念控制光標、玩電子遊戲等能力增強。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 年，腦機接口應用持續迎來新進展。在 AI 賦能下，腦機接口的實時性和低延遲性能顯著提升；而高密度柔性電極和解碼算法的協同創新，使半侵入式技術也取得新進展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年 1 月，「神經連接」公司創始人埃隆·馬斯克在社交媒體上宣佈，該公司已完成第三例腦機接口設備人體植入手術，且設備運行良好，預計 2025 年還會增加約 20 例至 30 例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3 月 31 日，美國加利福尼亞大學舊金山分校領銜的研究團隊在英國《自然·神經學》雜誌上發表論文説，他們利用人工智能算法改進了腦機接口植入設備，使一名失語 18 年的中風患者能以更接近自然語言的速度將想法轉換成語言表達出來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據介紹，經改進的腦機接口系統可在 3 秒內同步完成對患者所思考語句的實時解析與語音轉化，而患者此前所用的輔助通信設備完成這一過程需要超過 20 秒。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近期，中國腦機接口植入人腦技術也取得新突破。中國自主研發的半侵入式腦機接口「北腦一號」第三例人體植入手術於 3 月 20 日在天壇醫院成功完成。前兩例先後在北大第一醫院、首都醫科大學宣武醫院完成。接受手術後，癱瘓病人已實現意念控制運動，因患漸凍症而失語的病人已實現語言交流能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據業內專家介紹，「北腦一號」集成了中國自主研發的柔性高密度腦皮層電極，128 通道同時採集的信號通量在同類產品中處於國際領先水平。這種新型的半侵入式腦機接口既提升了信號採集的精準度，又降低了手術創傷和術後風險，彌補了侵入式和非侵入式技術的不足。（新華社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344040</guid>
            <pubDate>Thu, 03 Apr 2025 10:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AI 有病，得治！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;凝視深淵過久，深淵將回以凝視。——尼采&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;2022 年，全球最大的輕博客網站 Tumblr 上發生了一件挺有意思的事情。&lt;/p&gt; 
 &lt;p&gt;大量的 Tumblr 用戶對馬丁·斯科塞斯（就是拍《華爾街之狼》的那位）1973 年執導的電影 &lt;strong&gt;Goncharov &lt;/strong&gt;大加讚賞，稱讚這部鮮為人知的電影是有史以來最大的黑手黨電影——「 Goncharov 遠勝於它的時代，卻從未贏得它應有的讚賞。」&lt;/p&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//109fb366bbb4aca7b0696040705bf52f.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;隨着一張電影海報被翻出，熱度一下子衝上網站前五 ，很多人都在 Tumblr 刷屏「求雲盤」 「帶價拿資源」。但其實，&lt;strong&gt;馬丁·斯科塞斯根本就沒有拍過這部電影，人類歷史上也沒有一部名為 Goncharov 的電影！&lt;/strong&gt;這意味着，一張掛名「 Martin Scorsese 」的電影海報，幾句互聯網背後的虛構影評，最終演變成了一場羣體欺騙，直至現在還有人堅信這部電影的存在。&lt;/p&gt; 
   &lt;p&gt;心理學將這樣的現象稱之為「媒體等同」（media equation），人類天生會傾向一些羣體性認同事件，換言之，當羣體對同一件事情表現出肯定時，個體對事件往往會丟失判斷。你或許會説，怎麼可能，難道我就沒有獨立思考嗎？來看下面這張圖片👇&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1082a316dd13d43db624d10b0b6d5acd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;表面上，這是一個被壓廢墟的孩子，讓人憐惜，但細看，&lt;strong&gt;孩子左手為六根手指&lt;/strong&gt;。央視新聞後續為此事件闢謠，該視頻為 AI 生成內容，並稱：AI 讓造謠變得更簡單和更「科學」。諸如此類的 AI 烏龍還有很多，比如川普被捕、AI 教皇，只要不是原則性問題，大家反而對這樣的「欺騙」趨之若鶩。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d807597275859fff48069619fbcc1686.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;如果説 Goncharov 的羣體欺騙，是藏在人性裏的戲謔因子，那麼，在人工智能迭代如此迅速的今天，AI 「欺騙」人類，是技術缺陷還是人為？AI 所掀起的全球狂熱，是否也該降降溫？既然 AI 存在一定的失準，我們如何與 AI 相處？筆者想靜下心來和大家聊聊。&lt;/p&gt; 
   &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
   &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
   &lt;h3&gt;技術之病：AI 幻覺&lt;/h3&gt; 
   &lt;p&gt;AI 本身就有「病」—— &lt;strong&gt;AI Hallucinations&lt;/strong&gt; （即：「AI 幻覺」）。&lt;/p&gt; 
   &lt;p&gt;簡單理解，它是指諸如 GPT4 、PaLM 、DeepSeek 等大語言模型「一本正經地胡説八道」，將編造的事實與多個段落的連貫性和一致性編織在一起，且稱之為真實信息的情況。比如，人有三條腿（常識錯誤）、李逵大鬧五台山（劇情混淆）、第一個登上月球的人是 Charles （實際上是 Neil ，歷史虛構）、阿聯酋的首都是迪拜（實際上是阿布扎比，數據幹擾）...大致分為兩類：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;事實性幻覺：指模型生成的內容與可驗證的現實世界事實不一致&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;忠實性幻覺：指模型生成的內容與用戶的指令或上下文不一致&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;就拿現在很多企業普遍接入的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvectara%2Fhallucination-leaderboard&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt; DeepSeek R1 來説，幻覺率高達 14.3% ，遠高於 V3 的 3.9% &lt;/a&gt;。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//64ff0d04ef2e161ab894ff25a198d756.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;如果説 AI 幻覺是病，這些病是如何來的呢？&lt;/p&gt; 
   &lt;p&gt;首先，病從口入，大數據的數據缺陷，是導致 AI 產生幻覺的一大原因。這其中包括數據缺陷、數據中捕獲的事實知識的利用率較低。&lt;/p&gt; 
   &lt;p&gt;具體來説，數據缺陷分為錯誤信息和偏見（重複偏見、社會偏見），此外大模型也有知識邊界，所以存在領域知識缺陷和過失的事實知識——即便大模型吃掉了大量數據，也會在利用時出現問題。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6fe289499621b7bbb0946cde88bed59d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;除了數據，訓練過程也會使大模型產生幻覺。&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;預訓練階段&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;【架構缺陷】：基於前一個 token 預測下一個 token，這種單項建模阻礙了模型捕捉複雜的上下文關係的能力；隨着 token 長度增加，不同位置的注意力被稀釋；&lt;/p&gt; 
   &lt;p&gt;【曝露偏差】：模型推理時依賴於自己生成的 token 進行後續推測，錯誤的 token 會在整個 token 中產生級聯錯誤。&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;對齊階段：&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;【能力錯位】：大模型內在能力與標註數據中描述的功能之間可能存在錯位。（邊界在哪裏，也就放大了幻覺的風險）；&lt;/p&gt; 
   &lt;p&gt;【信念錯位】：基於 RLHF 等的微調，使大模型的輸出更符合人類偏好，進而犧牲信息真實性。&lt;/p&gt; 
   &lt;p&gt;簡言之，AI 的幻覺之病，並不是單一因素導致，而是數據集、架構、算法、訓練、推理等等，一系列的發展態疊加而成。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//81a1d494e86c1a830c42d9f1e2b1fbdc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;圖片來源：《 DeepSeek 與 &lt;/span&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;AI&lt;/span&gt;&lt;span style=&quot;color:#8f959e&quot;&gt; 幻覺》@清華大學&lt;/span&gt;&lt;/p&gt; 
   &lt;p&gt;既然 AI 幻覺會帶來如此多不確定性，科學家為什麼不嘗試「去幻覺」？事實是，有些問題從根本上就無解，我們能做的：&lt;strong&gt;只有與幻覺共存。&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;不過，在某些特定的情況下，AI 幻覺也可能有一些「意外」的好處。比如，大衞·貝克團隊獲得 2024 諾貝爾化學獎，源於 AI 幻覺的「錯誤摺疊」啓發出新型蛋白質結構；DeepMind 團隊發現，AI 在圖像分割任務中產生的「超現實邊界」雖不符合真實場景，卻意外提升了自動駕駛對極端天氣的識別精度...&lt;/p&gt; 
   &lt;p&gt;以至於，科學界目前正在構建「 AI 幻覺-實驗驗證-理論重構」三階段研究流程，試圖通過 AI 幻覺卻發現一些人類尚未探索過的可能。&lt;/p&gt; 
   &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
   &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
   &lt;h3&gt;市場之病：AI 狂歡&lt;/h3&gt; 
   &lt;p&gt;從千模大戰，到 DeepSeek 一騎絕塵，AI 市場的狂歡背後，是每天少説都有十幾個 AI 新項目如雨後春筍一般誕生。筆者相信這些項目不單是追風口、蹭熱度，而是 AI 開闢出了新的道路、新的可能。&lt;/p&gt; 
   &lt;p&gt;但高投入和低收益之間的「剪刀差」的背後，彷彿大家都開誠佈公地默認了一件事情：搞 AI 就能賺錢！這又何嘗不是一種病態！&lt;/p&gt; 
   &lt;p&gt;根據摩根士丹利的計算，亞馬遜、谷歌、Meta 和微軟這四大科技巨頭整 2024 年的資本支出達到 2460 億美元，其中大部分資金流向了 AI 領域，大頭是數據中心和先進芯片的建設，但實際產生的收益卻不夠理想，反而在繼續加碼。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//57d6bceb94075d709e098b923d5fc57b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;IT 桔子統計，34 家 AI 上市公司中，有 19 家在 2024 年上半年仍然處於虧損狀態。顯然，&lt;strong&gt;儘管 AI 技術發展迅速，但大多數 AI 公司仍未實現盈利&lt;/strong&gt;。反而，第一批吃螃蟹的人除了像英偉達這種提供芯片的公司，就是趕上 AI 風口利用信息差割韭菜的自媒體博主。&lt;/p&gt; 
   &lt;p&gt;為什麼搞 AI 難賺錢，市場上還是有那麼多狂熱分子？&lt;/p&gt; 
   &lt;p&gt;首先，覆水難收。即便在大模型高唱降本的今天，想要研究一個大模型出來，所投入的資金、物力、人才都是極為龐大的。高昂的開發門檻，砸出了一個巨大的資金缺口，如果後面不持續投入，活到雲開見日的那一天，前面的所有心血都會打水漂。&lt;span style=&quot;color:#8f959e&quot;&gt;（還不如賭一把！對吧。）&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e502e07a077296957dceec07cd4a86e6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;來源：新浪財經&lt;/p&gt; 
   &lt;p&gt;其次，市場開拓不足。俗話説，好馬配好鞍，我花了那麼多錢砸出來的 AI 產品，第一時間肯定是想開拓穩定的 ToB 、ToG 市場對吧。但這類賽道，不僅決策期長，市場容量小，還伴隨一系列的人情邊際，一個招標文件就能急死一大批 AI 老闆，誰能不發瘋？&lt;span style=&quot;color:#8f959e&quot;&gt;（如果 AI 老闆是技術出身，瘋得更快！）&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7231daa6932eda7894adb0614c057208.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;那麼，ToC 賽道呢？聊個人之常情的邏輯：有多少人用，才是 C 端市場的容積，一旦面臨經濟下行或消費轉移，就容易引發一系列的連鎖反應。同時，在如此激烈的搶人環境下，許多 AI 公司不得不採取燒錢補貼、廣告曝光的策略來爭奪市場份額，實際利潤也就被稀釋了。具體可以參考下圖👇&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f64044917f50cfd8aa22f3c81c563fee.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;這些都是沉默成本啊...&lt;/span&gt;&lt;/p&gt; 
   &lt;p&gt;並且，AI 技術並不具備任何的商業邏輯，市場上的狂熱，也只能由市場去慢慢消化。筆者認為，市場之病，目前還只處於 1.0 階段，當大批量的 AI 公司擱淺，市場上僅剩下幾極之後，2.0 的 AI 市場才可能慢慢自愈。&lt;/p&gt; 
   &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
   &lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
   &lt;h3&gt;個體之病：AI 依賴&lt;/h3&gt; 
   &lt;p&gt;AI 作為這個時代的新質生產力，確實帶給了人們很多的便利。比如，我要寫這篇稿子，可以找 AI 幫我寫個框架；開會要做總結，可以讓 AI 幫我劃重點；專業名詞不瞭解，交給 AI ，除了得到答案，還可以得到一些拓展性回答。&lt;/p&gt; 
   &lt;p&gt;偷懶起來，簡直不要太爽！但漸漸的，我發現：AI 其實只能幫助我們在短時間內提升一個領域的認知下限，對於一些專業性極強、需要實操，並伴生多種知識體系的領域（如：生命科學、國際經貿等），光是靠 AI 問問題，無異於管中窺豹。&lt;/p&gt; 
   &lt;p&gt;並且，對於普羅大眾來説，目前的 AI 應用更偏重於提升效率，如 AI 搜索、AI 總結、AI 寫作，越是將簡單的工作交給 AI ，人們的內心預判就越不會覺得 AI 做得不好&lt;span style=&quot;color:#8f959e&quot;&gt;（但其實 AI 的出錯率真的很高）&lt;/span&gt;，就越容易產生 AI 依賴。&lt;/p&gt; 
   &lt;p&gt;2024 年的最後一天，南方日報發了一篇&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fviews.ce.cn%2Fview%2Fent%2F202412%2F31%2Ft20241231_39252324.shtml&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;《「AI 依賴症」怎麼治》&lt;/a&gt;的文章，其中點名：&lt;strong&gt;大學生作業裏充滿了 AI 味，文科生快失去了原創寫作的能力。&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;據英國高等教育政策研究所發佈的調研，1250 名英國本科生中，有 53% 的學生正在使用 AI 寫論文，而在使用 AI 的學生中，25% 的人用 AI 來制定論文主題，還有 5% 的學生直接承認曾直接將 AI 生成內容複製粘貼到論文中。&lt;/p&gt; 
   &lt;p&gt;「這一現象已經不是新問題了。我們曾經發現，學生的畢業論文裏，有的段落的中文‘不像中文’，後來才知道，學生是將自己以前發表的英文論文用 AI 工具翻譯成中文粘貼過來。」南京大學人工智能學院副院長戴新宇教授&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nju.edu.cn%2Finfo%2F1056%2F355561.htm&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//274adda7135c56f171f345fae2c13060.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#8f959e&quot;&gt;百度相關問題的索引&lt;/span&gt;&lt;/p&gt; 
   &lt;p&gt;不僅如此，純靠 AI 在職場上也混不走。&lt;/p&gt; 
   &lt;p&gt;今年 2 月，美國知名律所 Morgan &amp;amp; Morgan 向 1000 多名律師發送了緊急郵件，警告稱 AI 可能生成虛假的判例信息，若律師在法律文件中使用這些虛構內容，可能會被解僱。&lt;/p&gt; 
   &lt;p&gt;不可否認，生成式 AI 技術極大地縮短了律師研究判例和撰寫的時間，但 AI 也存在「編造事實」的風險。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3d07f03d8b998dd33da036d1dbb4d034.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;反觀國內的醫療行業，則是在「 AI 診療」上頻加紅線，北京市衞健委明確指出：醫療機構開展互聯網診療活動要加強藥品管理，嚴禁使用人工智能等自動生成處方，且人工智能軟件等不得冒用、代替醫師本人提供診療服務。&lt;/p&gt; 
   &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9176ea65b1ede419b435cec8577beed1.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;真是應了那句話：AI 能幫你上班，但不能幫你背鍋。那麼，在這個高喊 All in AI 的時代，普通人該如何相處呢？筆者總結為八個字：&lt;strong&gt;敬畏工具，保持懷疑。&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;AI 真的只是一個工具而已，當你在使用 AI 的同時，不妨也向 AI 學習，它的思考方式、思維廣度，&lt;strong&gt;與 AI 共舞更能促進 AI 的發展&lt;/strong&gt;；其次，開篇也提到了，雖然在羣體認同保持清醒很難，但保持懷疑，卻很簡單，不妨試試！&lt;/p&gt; 
   &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
   &lt;p&gt;AI 有病，但它並不是我們的敵人，這一點需要明確。&lt;/p&gt; 
   &lt;p&gt;之所以放在最後來説，是因為筆者在查資料的過程中，發現了很多科學家正在研究如何降低 AI 幻覺，已經有很多企業開始了 AI 商業的探索，並且身邊的很多人都開始將 AI 看作是映射自身的鏡子，透過 AI 這個時代產物去完善自身的缺陷。&lt;strong&gt;AI 的未來，其實就是與人類共愈的過程。&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/18134663</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/18134663</guid>
            <pubDate>Thu, 03 Apr 2025 10:10:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>n8n 完成 5500 萬歐元 B 輪融資</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;n8n 是一個開源的、可擴展的工作流程自動化工具，它提供了直觀的界面，讓用戶可以通過拖放方式連接不同的應用程序和服務，從而創建自定義的自動化流程。&lt;/p&gt; 
&lt;p&gt;n8n 支持 400+ 應用和服務集成，包括各種常見的應用程序和服務，如 Google、Slack、GitHub、Trello 等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ab937377604fdb12632fa6217cf05240f21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，n8n 開發商&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.n8n.io%2Fseries-b%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;獲得了由 Highland Europe 領投的 5500 萬歐元 B 輪融資，HV Capital 和之前的投資者 Sequoia、Felicis 和 Harpoon 也參與了此次投資。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bd5bf1ab0789036ab84de20679b181c6475.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;n8n 創始人兼首席執行官 Jan Oberhauser 表示：「自動化不應是一個黑匣子——企業需要透明度、定製化和成本效益。通過 n8n，我們構建的不僅僅是一個平台；我們還建立了一個熱愛我們並信賴我們的社區。從個人貢獻者到全球企業，n8n 讓每個人都擁有 10 倍開發者的能力，這在人工智能在職場爆炸式增長的今天至關重要。」&lt;/p&gt; 
&lt;p&gt;過去一年，n8n 經歷了一年的爆炸式增長，去年活躍用戶已超過 20 萬，年度經常性收入 (ARR) 增長了 5 倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344033/n8n-series-b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344033/n8n-series-b</guid>
            <pubDate>Thu, 03 Apr 2025 10:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>聲稱 AI 技術實為人工操作，AI 購物應用創始人被控欺詐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;ai-shopping-app-powered-by-humans&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美國司法部週三發佈的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.justice.gov%2Fusao-sdny%2Fpr%2Ftech-ceo-charged-artificial-intelligence-investment-fraud-scheme&quot; target=&quot;_blank&quot;&gt;新聞稿&lt;/a&gt;指出，聲稱提供&quot;通用&quot;結賬體驗的 AI 購物應用 Nate 的創始人兼前 CEO Albert Saniger 被指控欺詐投資者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Nate 成立於 2018 年，曾從 Coatue 和 Forerunner Ventures 等機構籌集超過 5000 萬美元資金，包括 2021 年由 Renegade Partners 領投的 3800 萬美元 A 輪融資。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該公司聲稱其應用程序憑藉 AI 技術，允許用戶一鍵在任何電商網站完成購物。但美國司法部紐約南區法院指控稱，Nate 實際上嚴重依賴菲律賓呼叫中心數百名人工承包商手動完成這些交易。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;236&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5209b5913251e9a302ce20b65b82a278e0d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Saniger 聲稱 Nate 能夠「無需人工幹預」地進行在線交易（除非出現 AI 無法完成交易的極端情況），從而籌集了數百萬美元的風險投資。然而，美國司法部調查發現，儘管 Nate 獲得了一些 AI 技術並聘請了數據科學家，但其應用程序的實際自動化率實際上為 0%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Saniger&amp;nbsp;沒有回應置評請求。他目前是紐約風險投資公司 Buttercore Partners 的執行合夥人，該公司也沒有回應置評請求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Nate 大量使用人類承包商的行為曾在 2022 年成為 The Information 調查的對象。根據起訴書，Nate 公司於 2023 年 1 月資金耗盡，被迫出售資產，導致投資者&quot;幾乎全部&quot;損失。Saniger&amp;nbsp;的領英資料顯示，他自 2023 年起不再擔任 CEO。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Nate 並非唯一一家涉嫌誇大 AI 能力的創業公司。報道稱，一家菲律賓&quot;AI&quot;免下車軟件創業公司以及 AI 法律科技獨角獸 EvenUp 也被曝主要依靠人工完成大部分工作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344028</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344028</guid>
            <pubDate>Thu, 03 Apr 2025 09:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>歐盟披露投建 13 家 AI 超級工廠細節</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;歐洲聯盟披露興建人工智能（AI）超級工廠計劃細節。這一計劃將耗資 200 億歐元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;歐盟委員會 9 日發佈「人工智能大陸行動計劃」。這一委員會負責技術主權等事務的執行副主席漢娜·維爾庫寧在聲明中説，在使歐洲更具競爭力、更安全並擁有更多技術主權方面，AI 技術處於核心地位，「全球 AI 競賽遠未結束」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英國《衞報》9 日報道，歐盟已着手落實一項計劃，建設 13 家 AI 超級工廠。超級工廠內設超級計算機和數據中心。歐盟委員會主席烏爾蘇拉·馮德萊恩 2 月 11 日在法國首都巴黎舉行的 AI 行動峯會上宣佈「投資 AI」倡議，旨在調動 2000 億歐元投資，以推動 AI 發展。根據這一倡議，歐盟將專門設立 200 億歐元基金用於建設歐洲 AI 超級工廠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據「人工智能大陸行動計劃」，歐盟性能最佳的幾家 AI 超級工廠的超級計算機將搭載多達 2.5 萬枚高端 AI 處理器。每家超級工廠的高端 AI 處理器數量將超過 10 萬枚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《衞報》援引歐盟一名高級官員的話報道説，這些 AI 超級工廠所使用液冷技術將「儘可能」由綠色電力支持，同時計劃「循環使用」水資源。報道提供的數據顯示，歐盟去年 47% 的電力來自可再生能源。一些環保人士擔心，數據中心耗能巨大，可能動搖歐盟在環保方面設立的目標。（卜曉明，新華社微特稿&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344018</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344018</guid>
            <pubDate>Thu, 03 Apr 2025 09:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Wisdom SSH，運維人的 「Cursor」，部署 Jenkins 詳細使用教程</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;運維工作事兒多且雜，從服務器日常維護到故障修復，都得小心翼翼。對運維人來説，一款好工具特別重要。編程人員有 Cursor 幫忙，咱們運維人也有類似的，就是 Wisdom SSH，它能讓運維變得輕鬆&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;Wisdom SSH 作為一款集成 AI 的現代化 SSH 終端工具，能極大簡化 Jenkins 的部署流程。以下將為你逐步介紹如何使用 Wisdom SSH 完成 Jenkins 的部署。&lt;/p&gt; 
&lt;h2&gt;一、準備工作&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;下載與安裝 Wisdom SSH&lt;/strong&gt;：打開瀏覽器，在地址欄輸入官網地址&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fssh.wisdomheart.cn%2F&quot; target=&quot;_blank&quot;&gt;ssh.wisdomheart.cn&lt;/a&gt;，進入 Wisdom SSH 官網。按照網頁上清晰的提示，下載 Wisdom SSH 的安裝包，並完成安裝。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;確保服務器具備基本條件&lt;/strong&gt;：目標服務器需擁有合適的操作系統（如常見的 Linux 發行版，如 Ubuntu、CentOS 等），並且具備網絡連接以及必要的權限（通常需要 root 或具有 sudo 權限的用戶）。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;二、啓動 Wisdom SSH 並連接服務器&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;啓動 Wisdom SSH&lt;/strong&gt;：安裝完成後，在應用列表中找到 Wisdom SSH 並啓動它。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;添加服務器連接&lt;/strong&gt;：在 Wisdom SSH 界面中，找到添加服務器連接的按鈕。點擊後，填寫服務器的相關信息，包括服務器 IP 地址、用戶名以及對應的密碼（若使用密鑰認證，需正確配置密鑰文件路徑等信息）。填寫完成後，點擊服務器會話，建立與目標服務器的連接。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;867&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95c5ba928b9d0adc959aac67afa7ab30895.png&quot; width=&quot;1544&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;三、通過 Wisdom SSH 部署 Jenkins&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;進入 AI 助手對話區&lt;/strong&gt;：成功連接服務器後，在 Wisdom SSH 界面右側是 AI 助手對話區，它類似於我們日常使用的聊天窗口。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;提出部署需求&lt;/strong&gt;：在 AI 助手對話區輸入：「部署 Jenkins」。輸入完成後，按下回車鍵發送指令。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;872&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ec714f781b89acba3d5a0acbc8a2098793.png&quot; width=&quot;1544&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;添加 Jenkins 官方軟件源&lt;/strong&gt;：Wisdom SSH 的 AI 會根據服務器的操作系統類型，生成相應的部署步驟和命令。首先，AI 會進行添加 Jenkins 官方軟件源的步驟。以 Debian 或 Ubuntu 系統為例，給出以下操作： 
  &lt;ul&gt; 
   &lt;li&gt;執行命令：&lt;code&gt;wget -q -O - https://pkg.jenkins.io/debian - stable/jenkins.io.key | sudo apt - key add -&lt;/code&gt;，此命令用於下載並添加 Jenkins 軟件源的 GPG 密鑰，以確保軟件源的安全性和可靠性。執行命令後等待其完成。&lt;/li&gt; 
   &lt;li&gt;執行命令：&lt;code&gt;sudo sh - c &#39;echo deb https://pkg.jenkins.io/debian - stable binary/ &amp;gt; /etc/apt/sources.list.d/jenkins.list&#39;&lt;/code&gt;，該命令將 Jenkins 軟件源信息添加到系統的軟件源列表文件中。&lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;img height=&quot;872&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3820df02fa347e71e91b8e76fdd583909c8.png&quot; width=&quot;1543&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;執行安裝 Java 步驟&lt;/strong&gt;：接下來提示安裝 Java，因為 Jenkins 運行依賴 Java 環境。例如，若服務器是基於 Debian 或 Ubuntu 系統，AI 給出如下命令及提示： 
  &lt;ul&gt; 
   &lt;li&gt;執行命令：&lt;code&gt;sudo apt update&lt;/code&gt;，此命令用於更新系統軟件包列表，確保獲取到最新的軟件信息。輸入命令後，按下回車鍵執行。由於我們演示服務器是 root 賬號，直接使用「AI 執行」，如果你使用過程中需要輸入密碼，請選擇「終端執行」。&lt;/li&gt; 
   &lt;li&gt;執行命令：&lt;code&gt;sudo apt install openjdk-17-jre&lt;/code&gt;，此命令用於安裝 OpenJDK 開發工具包。按下回車鍵執行。等待安裝完成，這可能需要一些時間，取決於服務器的網絡速度和性能。&lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;img height=&quot;843&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71ee1d51679ffc3b819540bce028c4d4047.png&quot; width=&quot;1545&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安裝 Jenkins&lt;/strong&gt;：以上步驟執行成功後，AI 會引導你安裝 Jenkins。執行命令：&lt;code&gt;sudo apt install jenkins&lt;/code&gt;，開始安裝 Jenkins 然後等待安裝完成。 &lt;p&gt;&lt;img height=&quot;868&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-66523a0a545e0dd1310d2b06ef66e832aca.png&quot; width=&quot;1545&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;啓動 Jenkins 服務&lt;/strong&gt;：Jenkins 安裝完成後，接下來需要啓動 Jenkins 服務，使其能夠正常運行。執行命令：&lt;code&gt;sudo systemctl start jenkins &amp;amp;&amp;amp;&amp;nbsp;sudo systemctl enable jenkins&lt;/code&gt; &lt;p&gt;啓動 Jenkins 服務並啓用 Jenkins 開機自動啓動，再執行命令：&lt;code&gt;sudo systemctl status jenkins&lt;/code&gt;&amp;nbsp;檢查服務狀態。&lt;/p&gt; &lt;p&gt;&lt;img height=&quot;870&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-03d64b46dca6518622efca2f3b0c003f09c.png&quot; width=&quot;1545&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;四、Jenkins 初始配置&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;獲取初始管理員密碼&lt;/strong&gt;：Jenkins 首次啓動後，需要獲取初始管理員密碼進行首次登錄配置。此處，AI 自動獲取並給出獲取密碼，複製該密碼備用。 &lt;p&gt;&lt;img height=&quot;871&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62dad16418acc85cd8047de90df71863160.png&quot; width=&quot;1545&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;訪問 Jenkins 初始配置頁面&lt;/strong&gt;：打開本地瀏覽器，在地址欄輸入 「http:// 服務器 IP 地址：8080」。在打開的頁面中，輸入剛才複製的初始管理員密碼，然後點擊 「繼續」 按鈕。 &lt;p&gt;&lt;img height=&quot;870&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-df72edfcf3e31ee8585819dfadb0e9f3c5c.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安裝推薦插件&lt;/strong&gt;：接下來的頁面會提示安裝插件，選擇 「安裝推薦的插件」 選項，Jenkins 會自動下載並安裝一系列常用插件，這一過程可能需要一些時間，耐心等待直到插件安裝完成。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;870&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d65ebd5090d6cd495a1d00b4a95f36f232.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;873&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-745d4f2e66b484957ca2ff48b6445967fac.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;871&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7acd11759353ae9cc8abcde930a65f7515c.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;創建管理員用戶&lt;/strong&gt;：插件安裝完成後，會進入創建管理員用戶頁面。按照頁面提示，填寫用戶名、密碼、郵箱等信息，完成後點擊 「保存並完成」 按鈕。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;870&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fa6a4ea3ae174f69cfb09fe27272abf94f3.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完成配置&lt;/strong&gt;：最後，點擊 「開始使用 Jenkins」 按鈕，至此 Jenkins 的部署和初始配置全部完成。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img height=&quot;867&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eddd5c0918490edf1ac6f2ea469bf6b9c85.png&quot; width=&quot;1547&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 通過以上詳細步驟，使用 Wisdom SSH 你可以輕鬆完成 Jenkins 的部署及初始配置工作，即使是對部署流程不太熟悉的用戶也能順利操作。我們的官網有詳細的軟件使用視頻教程，歡迎大家前來下載體驗。
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344013</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344013</guid>
            <pubDate>Thu, 03 Apr 2025 09:06:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>mcp-agent —— 專門為 MCP 構建的 AI 框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;mcp-agent&lt;/code&gt;&lt;/strong&gt;&lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot;&gt;是一個使用模型上下文協議&lt;/a&gt;構建代理的簡單、可組合的框架。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;靈感&lt;/strong&gt;：Anthropic 為 AI 應用程序開發人員宣佈了兩項基礎更新：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.anthropic.com/news/model-context-protocol&quot;&gt;模型上下文協議&lt;/a&gt;- 一種標準化接口，允許任何軟件通過 MCP 服務器被 AI 助手訪問。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.anthropic.com/research/building-effective-agents&quot;&gt;構建有效代理&lt;/a&gt;- 關於構建可用於生產的 AI 代理的簡單、可組合模式的開創性文章。&lt;/li&gt;
&lt;/ol&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code&gt;mcp-agent&lt;/code&gt;將這兩個基礎部分放入 AI 應用框架中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;它負責管理 MCP 服務器連接生命週期的繁瑣工作，這樣你就不必再處理了。&lt;/li&gt;
&lt;li&gt;它實現了「構建有效代理」中描述的每個模式，並且以可組合的方式實現，允許你將這些模式鏈接在一起。&lt;/li&gt;
&lt;li&gt;&lt;strong style=&quot;color:#1f2328&quot;&gt;Bonus&lt;/strong&gt;：它以與模型無關的方式實現了&lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;OpenAI 的 Swarm 模式，用於多智能體編排。&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;總而言之，這是構建強大代理應用程序最簡單、最輕鬆的方法。與 MCP 非常相似，該項目處於早期開發階段。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前已經有太多的 AI 框架了。但是，&lt;code&gt;mcp-agent&lt;/code&gt;它是唯一一個專門為共享協議（&lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot;&gt;MCP）&lt;/a&gt;構建的框架。它也是最輕量的，並且更接近於代理模式庫而不是框架。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;隨着&lt;a href=&quot;https://github.com/punkpeye/awesome-mcp-servers&quot;&gt;越來越多的服務變得能夠感知 MCP&lt;/a&gt;，你可以使用 mcp-agent 構建強大且可控的 AI 代理，以便開箱即用地利用這些服務。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/mcp-agent</link>
            <guid isPermaLink="false">https://www.oschina.net/p/mcp-agent</guid>
            <pubDate>Thu, 03 Apr 2025 08:50:00 GMT</pubDate>
        </item>
        <item>
            <title>LinkedIn 數據：全球 AI 人才最集中的十個國家，以色列居首</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據 LinkedIn&amp;nbsp;最新發布的數據，全球範圍內對於人工智能（AI）人才的需求正迅速上升。為了應對這一挑戰，許多國家正在積極培養和吸引 AI 人才。LinkedIn 通過其 「AI 人才集中度」 指標，分析了不同國家的 AI 人才供應情況，以下是 2024 年 AI 人才濃度最高的十個國家。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;首先，以色列在 2024 年的數據顯示，其 AI 人才佔到全國勞動力的 1.98%，位居全球第一。緊隨其後的是新加坡，其 AI 人才的比例為 1.64%。盧森堡位列第三，AI 人才比例為 1.44%。此外，愛沙尼亞、瑞士、芬蘭、愛爾蘭、德國、荷蘭和韓國分別佔據第四至第十位，人才比例從 1.17% 到 1.06% 不等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，這些國家通常在地理和人口規模上相對較小，但在 AI 人才的培養和發展上卻表現不俗。這些國家建立了良好的生態系統，企業對員工技能發展的投資以及政府促進持續學習的政策，都為 AI 人才的培養提供了有力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;LinkedIn 亞太地區首席經濟學家蔡佩盈指出，雖然印度未能進入前十名，但在 2016 年至 2024 年間，該國的 AI 人才濃度增加了 252%。這一數據表明，印度的專業人士正積極提升他們的 AI 技能。此外，2024 年，印度的 AI 招聘需求同比增長了 33.4%，高於新加坡的 25% 和美國的 24.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;新加坡在 AI 人才培養方面的競爭力也不容忽視，蔡佩盈提到，新加坡的文化強調學習，專業人士在 AI 技能學習上花費的時間比亞太其他國家高出 40%。隨着 AI 技術的迅速發展，企業和個人對於 AI 技能的需求只會進一步上升。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;具體排名如下:&lt;/span&gt;&lt;/p&gt; 
&lt;ol style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;以色列 （1.98%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;新加坡 （1.64%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;盧森堡 （1.44%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;愛沙尼亞 （1.17%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;瑞士 （1.16%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;芬蘭 （1.13%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;愛爾蘭 （1.11%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;德國 （1.09%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;荷蘭 （1.07%）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;韓國 （1.06%）&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343985</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343985</guid>
            <pubDate>Thu, 03 Apr 2025 07:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>vivo Trace 監控追求極致的建設歷程</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網服務器團隊- Zhang Yi 當前 vivo 的應用監控產品 Vtrace 經常遇到用戶反饋某個 Trace 鏈路信息沒法給他們提供到實質的幫肋，對此團隊一直在持續完善 JavaAgent 的採集。經過不斷增加各類插件的支持，同時想方設法去補全鏈路信息，但一直還是無法讓用戶滿意。面對這樣的困境，需要改變思路，從用戶角度思考，在產品中找靈感。同時產品重新思考在應用監控中一條完整的 Trace 應該展現給用戶哪些信息？業界其它產品對 Trace 的監控可以觀測到什麼程度？帶着這些問題，Vtrace 通過全面的同類產品對比分析，結合 vivo 實際情況自研 Profile 採集，從而開啓涅槃之路。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;專業術語&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;【Vtrace】：vivo 應用監控系統，是一款 vivo 自研應用性能監控產品。&lt;/p&gt; 
&lt;p&gt;【Trace】：通常用於表示一系列相關的操作或事件，這些操作或事件通常跨越多個組件或服務，一個 Trace 可能由多個 Span 組成。&lt;/p&gt; 
&lt;p&gt;【Span】：屬於 Trace 中的一個小部分，表示某個特定操作的時間跨度，比如執行一次查詢 SQL 的記錄。&lt;/p&gt; 
&lt;p&gt;【APM】：APM 為 Application Performance Monitoring 的縮寫，意為應用性能監控。&lt;/p&gt; 
&lt;p&gt;【POC】：通常指的是 &quot;Proof of Concept&quot;，即概念驗證。在軟件開發和信息技術領域，POC 是指為了驗證某項技術、方法或想法的可行性而進行的實驗或測試。在監控領域，一個監控 POC 通常指的是為了驗證某個監控方案、工具或系統的可行性而進行的驗證。&lt;/p&gt; 
&lt;p&gt;【Continuous Profiling】：持續剖析，有些廠商叫 Continuing Profile 或 Profiler，也有人將 Continuous Profiling 和 Trace、Metric、Log 放在同一位置。總之是一種持續性的性能分析技術，它可以實時監測和記錄程序的性能數據，以便開發人員可以隨時瞭解程序的性能狀況。這種技術可以幫助開發人員發現程序中的性能瓶頸和優化機會，從而改進程序的性能。通過持續性地監測程序的性能數據，開發人員可以更好地瞭解程序的行為和性能特徵，從而更好地優化程序的性能。本文中 Profile 一般指持續剖析。&lt;/p&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;當前應用監控產品 Vtrace 中的 Trace 鏈路數據只串聯了服務與服務，服務與組件之間的 Span 信息，但對於發生於服務內部方法具體執行耗時是無法監控的，即所謂監控盲區。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4c7a7b1ad6ce8a821ec366d7d610cee0.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 1&lt;/p&gt; 
&lt;p&gt;圖 1 為當前 Vtrace 系統的一個 Trace 信息，這個 Trace 顯示內部沒有任何其它組件，事實上真的如此麼？先看看下面實際代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@GetMapping(&quot;/profile/test&quot;)
public String testProfile() {
        try {
            //執行 sleep 方法
            doSleep();
            //執行查詢 MySQL，但方法使用 synchronized 修飾，多線程的時候會塞阻，同時查詢 SQL 時一般會先獲取數據庫鏈接池
            synchronizedBlockBySelectMysql();
            //讀取文件數據，並且將數據序列化轉 JSON
            readFileAndToJson();
            //發送數據到 kafka
            sendKafka();
            return InetAddress.getLocalHost().getHostAddress();
        } catch (Exception e) {
            log.error(&quot;testProfile {}&quot;, e.getStackTrace());
        }
        return &quot;&quot;;
    }
    private void doSleep() throws InterruptedException {
        Thread.sleep(1000);
    }
    private synchronized void synchronizedBlockBySelectMysql() {
        profileMapper.selectProfile();
    }
    private void readFileAndToJson() throws InterruptedException {
        String fileName = VivoConfigManager.getString(&quot;profile.test.doc.path&quot;,&quot;D:\\json1.json&quot;);
        StringBuilder builder = new StringBuilder();
        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(fileName), &quot;UTF-8&quot;))) {
            String line;
            while ((line = br.readLine()) != null) {
                builder.append(line);
            }
            br.close();
            JSONArray jsonArray = JSON.parseArray(builder.toString());
        } catch (Exception e) {
            log.error(&quot;testProfile {}&quot;, e.getStackTrace());
        }
    }
    private void sendKafka() {
        for (int i = 0; i &amp;lt; 5; i++) {
            kafkaTemplate.send(topic, &quot;{\&quot;metricName\&quot;:\&quot;java.profile.test\&quot;,\&quot;id\&quot;:1,\&quot;isCollect\&quot;:false}&quot;);
        }
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從上面的代碼可以看出接口/profile/test 的 profileTest 方法實際執行了四個私有方法：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;doSleep() 方法，讓程序休眠 1 秒&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;synchronizedBlockBySelectMysql 方法查詢 MySQL，但這個方法使用了 synchronized 修飾，多線程同時執行這個方法時會塞阻。另外查詢 MYSQL 一般會使用連接池，這次測試的代碼使用 Hikari 連接池&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;readFileAndToJson 方法讀取文件數據並且將數據轉 JSON 為 JSONArray&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sendKafka 方法主要是發送數據到 Kafka&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;但這四個方法在 Vtrace 系統中的 Trace 信息中什麼都體現不了，JavaAgent 並沒有採集到相關信息。這恰好説明瞭這裏存在監控盲區，並且盲區遠比想象中的要大，某些場景中連最基本的 MySQL 執行的信息都看不到。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//cc9f8e18d9fca3274ba38ce153a13d1d.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2&lt;/p&gt; 
&lt;p&gt;對於圖 1 那種情況在實際中會經常遇到，用戶會發現 Trace 中沒有他想要的信息。有時會像圖 2 中那樣有幾個組件的 Span，但整個 Trace 中依然存在一大片空白的地方，不知道具體的代碼執行情況。&lt;/p&gt; 
&lt;p&gt;針對上述的場景，為了讓用戶通過 Trace 獲取更多有用信息，後續需要做的有兩件事：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持對更多組件的埋點採集&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;針對 Trace 進行方法調用棧的採集&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;而本文主要從下面幾個角度論述我們如何改變當前 Vtrace 的&lt;strong&gt;現狀&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;同類產品對比分析&lt;/strong&gt;：通過 SkyWalking、DataDog 和 Dynatrace 三款產品的 Trace 觀測程度對比分析，從產品的視角去獲得 Vtrace 的優化思路。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;程序設計&lt;/strong&gt;：通過同類的產品功能引入行業中 Continuous Profiling 概念，結合同類產品的技術實現情況設計 Vtrace JavaAgent 對方法調用棧採集的技術方案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;壓測分析&lt;/strong&gt;：針對在 JavaAgent 增加方法調用棧採集之後進行壓測，評估出 JavaAgent 改進後的資源影響，並且分析出資源消耗增加的根因與確定後續持續優化的方向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;落地評估&lt;/strong&gt;：通過當前已經接入 Vtrace 產品的服務情況與 JavaAgent 壓測結果去分析 Vtrace 的方法調用棧採集功能如何落地。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、同類產品對比分析&lt;/h1&gt; 
&lt;p&gt;在設計 JavaAgent 方法調用棧監控採集前，先看看業界的監控同類產品對 Trace 的分析能夠做到何種程度。&lt;/p&gt; 
&lt;p&gt;下面我們使用 SkyWalking、DataDag 和 Dynatrace 三款同類產品，對上面/profile/test 接口進行監控分析。通過對同類產品監控情況的分析會給我們帶來一些啓發，同類產品的一些優秀設計思路也會有助於我們完善的 Vtrace 產品。&lt;/p&gt; 
&lt;h2&gt;2.1 Apache SkyWalking&lt;/h2&gt; 
&lt;p&gt;Apache SkyWalking 是一款優秀的開源應用性能監控產品，Vtrace 的 JavaAgent 就是基於早期的 SkyWalking 3.X 版本開發的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4c2577fa43c8badf1f3efbff06947497.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 3&lt;/p&gt; 
&lt;p&gt;上圖為/profile/test 接口在 SkyWalking 的 trace 信息，顯然可以看出請求中訪問 MySQL 與 Kafka，其中 SQL 的執行時間大約為 2 秒（圖 3 中的 MySQL/JDBC/PrepardStatement/execute 為實際執行 SQL 的 Span）。同時使用 Hikari 鏈接池工具獲取數據庫鏈接的信息也記錄了，這個記錄很有用，如果數據庫鏈接池滿了，一些線程可能一直在等待數據庫鏈接池釋放，在某些情況下很可能是用戶數據庫鏈接池配置少了。&lt;/p&gt; 
&lt;p&gt;相對於 Vtrace 系統的 trace 信息，顯然 SkyWalking 觀測能力強了不少，但依然存在 doSleep 與 readFileAndToJson 這兩個方法沒有觀測到。&lt;/p&gt; 
&lt;p&gt;對於這種情況，想到了 SkyWalking 的性能剖析功能，那再利用性能剖析看看能不能分析出 doSleep 與 readFileAndToJson 這兩個方法。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a8a7d80f7b937d1a7c1ac04d274cbfdd.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 4&lt;/p&gt; 
&lt;p&gt;圖 4 是 SkyWalking 對/profile/test 接口配置性能剖析的交互，這裏可以配置端點名稱、監控的持續時間，監控間隔以及採集的最大樣本數。而監控間隔配置的越小採集到的數據會越精確，同時對服務端的性能影響則越大。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//63efbae0613613fdfef2ce250bba78ff.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 5&lt;/p&gt; 
&lt;p&gt;配置好性能剖析規則後，再次發出/profile/test 請求。等待了一段時間，從圖 5 中可以看到 doSleep 和 synchronizedBlockBySelectMysql 方法的執行情況。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//11284b6536a13866c4a7654fa8e4ee74.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 6&lt;/p&gt; 
&lt;p&gt;關於 synchronizedBlockBySelectMysql 方法的，如果是執行 sql 耗時，採集到的應該如圖 6 左側那樣看到的是正在執行 SQL 的 socketRead0 方法，而這裏顯示的是 synchronizedBlockBySelectMysql 這個代碼塊，即性能剖析時 SkyWalking 採集到的數據方法棧的棧項為&lt;/p&gt; 
&lt;p&gt;synchronizedBlockBySelectMysql，這裏由於 synchronized 的修飾在執行 SQL 前需要等待別的線程釋放整個方法塊。&lt;/p&gt; 
&lt;p&gt;從上述可以看出 SkyWalking 顯然對 profileTest 方法能很有效地分析，但存在一個問題就是性能剖析不能自動持續分析，需要用戶手動開啓，遇到難以復現的情況時不好回溯分析。&lt;/p&gt; 
&lt;p&gt;雖然 SkyWalking 持續剖析存在這一點小瑕疵，但我們不得不承認 Skywalking 對 Trace 的分析還是挺強大的。Vtrace 的 JavaAgent 是在 SkyWalking3.X 版本的基礎上實現的，而 SkyWalking 成為 Apache 項目後經過這幾年的持續迭代已經發展到 10.X 版本了。對比我們 Vtrace JavaAgent，顯然 SkyWalking 的進步巨大。&lt;/p&gt; 
&lt;h2&gt;2.2 DataDog&lt;/h2&gt; 
&lt;p&gt;與開源的 SkyWalking 不同，DataDog 是一款商用可觀測軟件，在 Gartner 可觀測排名靠前。接下來我們使用 DataDog 去分析剛才的/profile/test 接口。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6513d7294cd3f3f87ab9ad47c4dfb4dd.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 7&lt;/p&gt; 
&lt;p&gt;圖 7 是使用 DataDog 採集到/profile/test 接口 Trace 數據，明顯可以看出：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MySQL 組件與 Kafka 組件的執行耗時&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;整個 Trace 的 Safepoint 和 GC 佔用時間&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f35318bc5ddab45f75cb0ded1258da2b.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 8&lt;/p&gt; 
&lt;p&gt;圖 8 為本次 trace 的火焰圖，從圖中可以看到 readFileAndTojson 這個方法熱點。&lt;/p&gt; 
&lt;p&gt;從 DataDog 的 Trace 信息中我們可以看出 DataDog 也能直接發現 MySQL 與 kafka 組件，同時提供這次 trace 的火焰圖，從火焰圖中能夠看出 readFileAndTojson 方法執行。但 doSleep 方法與 synchronizedBlockBySelectMysql 方法關鍵字 synchronized 同步等待的時間沒被觀測到。&lt;/p&gt; 
&lt;p&gt;不過感覺到意外的是可以在 DataDog 中看到這次 trace 的 Safepoint 和 GC 佔用時間，這樣用戶可以分析出該 Trace 是否受到 Safepoint 和 GC 影響。&lt;/p&gt; 
&lt;h2&gt;2.3 Dynatrace&lt;/h2&gt; 
&lt;p&gt;Dynatrace 也是一款商用可觀測產品，Gartner 可觀測排名常年第一，技術上遙遙領先。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bf8e1c9dd06d47abd0cc8e75cda1ddbb.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 9&lt;/p&gt; 
&lt;p&gt;圖 9 為/profile/test 接口在 Dyantrace 中的一個 Trace 信息，圖中左側紅框可以直接看到 MySQL 和 Kafka 組件，中間紅框是這次 trace 的線程整體時間分佈情況，包括 CPU 時間，Suspension 掛起時間，還有 Waiting、Locking、Disk I/O 和網絡 I/O ，為了方便大家理解深層的性能特徵他們用不同的顏色區分，具體説明如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//43c28f7b990659badfdb71a12679849f.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 1&lt;/p&gt; 
&lt;p&gt;從圖 9 右邊紅色框框的可以看到這個 Trace 整個生命週期的線程各個階段的分佈，再點擊&quot;View method hotspots&quot;，則本次 trace 的方法熱點如下圖圖 10 所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d5e9faf3ad33a8c49510192a69f38db7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 10&lt;/p&gt; 
&lt;p&gt;看到圖 10 的內容非常驚訝，源代碼中的四個私有方法全部被觀測到，四個方法底層的實質也顯露出來，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;發現 doSleep 與 sendKafka 這兩個方法，並且他們的操作主要是在 Waiting。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;synchronizedBlockBySelectMysql 方法圖中淺藍色部分顯示他在 Locking，等待着別的線程執行完 synchronized 修飾的方法；後半段粉色部分為查詢 MySQL 的 IO 操作，細分為 Network I/O。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;readFileAndToJson 方法中有一段紫色的部分 ，那是在讀取文件的 IO 操作，分類為 Disk I/O，而同時讀取文件與將文件中的內容轉換為 JSON 也是這次 Trace 消耗 CPU 的主要代碼。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;上面除了整個 Trace 的方法熱點的總覽信息，還可以下鑽進入每個方法再深度分析。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fb4d2666178fa5a3004591c669fa4049.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 11&lt;/p&gt; 
&lt;p&gt;圖 11 是展開 doSleep 與 sendKafka 兩個 Waiting 方法分析，可以明顯看出 doSleep 方法實際上底層耗費在 Thread.sleep，而 sendKafka 方法的 Waiting 是 Kafka 底層工具類 SystimeTime.waitObject 中執行更底層的 Object.wait。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6010e8d1d570b94e0b0b948c520b0121.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 12&lt;/p&gt; 
&lt;p&gt;圖 12 為選定&quot;Code execution&quot;後再展開 readFileAndToJson 方法，這裏兩處主要耗費 CPU 的操作，一個是 JSON.parseArray，一個是 BufferedReader.readLine。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ae2e88691bf36ae469ecb902350533d7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 13&lt;/p&gt; 
&lt;p&gt;除了方法熱點分析，Dynatrace 還提供了&quot;Code level&quot;的分析，從圖 13 中可看到 Hikari 鏈接池的獲取情況。&lt;/p&gt; 
&lt;p&gt;從結果上來看，Dynatrace 的觀測能力果然遙遙領先，他的觀測能力不是僅僅簡單告訴用戶每個地方的執行耗時，他告訴用戶代碼執行情況的同時讓用戶更好地瞭解程序每個行為的底層原理和性能特徵。&lt;/p&gt; 
&lt;h2&gt;2.4 分析總結&lt;/h2&gt; 
&lt;p&gt;在完成上述三個產品的 Trace 分析後，結合當前 Vtrace 產品，做了一些對比：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//788f6888df5ebcec9ed539eba9fdac11.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 2&lt;/p&gt; 
&lt;p&gt;通過同類產品對比分析發現當前 Vtrace 整體功能與業界領先的產品比較顯得相對落後。另外，業界優秀的產品還有很多，而我們選擇 SkyWalking、DataDog 和 Dynatrace 因為他們具有一定的典型性和代表性。而對於上述的三款產品，本文產品分析只是針對 Trace 鏈路的觀測能力來測試來比較。&lt;/p&gt; 
&lt;p&gt;最初在考慮如何完善我們的 Trace 鏈路，我們的計劃是參考新版 SkyWalking 的 Profile 功能，所以當時的同類產品分析只選 SkyWalking，而/profile/test 接口的四個私有方法也是提前就設計好的。&lt;/p&gt; 
&lt;p&gt;但在做設計評審時，發現只基於一個開源產品的能力去設計，最後可能得出的方案會是片面的。考慮到不同產品的 Trace 信息呈現會有所不同，於是我們決定再找一些同類的商用產品來對比分析。而同類產品 Trace 呈現出來的信息涉及數據採集，我們需要分析產品能力的同時也要去了解同行的採集技術方案。&lt;/p&gt; 
&lt;p&gt;因為曾經主導過一個可觀測項目，邀請了國內外的主要 APM 廠商來企業內部私有化部署產品，用了長達半年多的時間對大概 10 款產品進行 POC 測試，大部分產品的 Trace 信息展示是差不多的，而當時很多產品的 Trace 觀測能力並不比現在的 SkyWalking 會好。同時，簡單看了當前一些國內大廠可觀測產品 Trace 的交互後，為了避免同質化，便選擇了當時 POC 沒法私有化部署的 DataDog 與 POC 測試時效果遠超同行的 Dynatrace。&lt;/p&gt; 
&lt;p&gt;由於/profile/test 接口的四個私有方法是在 SkyWalking 測試前就已經設計好的，所以在要把 DataDog 和 Dynatrace 加入測試時並不知道這兩款產品會呈現出什麼樣的實際效果。現在都知道 DataDog 和 Dynatrace 的測試結果，這兩個產品的 Trace 中都有出乎意料的重要信息，這帶給我們不少啓發。&lt;/p&gt; 
&lt;p&gt;本節最後説些題外話，相信國內很多大廠都有自己的可觀測產品或者正在使用一些其它廠商可觀測產品，你們可以將/profile/test 接口的代碼用你們現在使用的監控產品測試一下，看看你們的 Trace 能觀測到什麼，如果有一些意外的發現，不防聯繫我們，大家一起相互學習學習。&lt;/p&gt; 
&lt;h1&gt;三、程序設計&lt;/h1&gt; 
&lt;p&gt;通過同類產品的對比分析，為了讓我們的 Trace 信息更完整，第一件事是需要完善組件。同時同類產品可以觀測到更多有用的信息，所以第二件事我們需要知道這些信息同類產品是如何採集的。另外也不能只顧着單一完善 Trace 信息而設計 ，設計上需要考慮後續的整體規劃。&lt;/p&gt; 
&lt;p&gt;隨着對同類產品的深入瞭解知道同類產品使用了一種叫 Continuous Profiling 技術手段，通過這種手段他們才有如此豐富 Trace 信息。比如 DataDog 的火焰圖和 Dynatrace 的方法熱點正是這技術手段的體現。同時在他們產品中 Continuous Profiling 有明確的定位，常見有下面四個功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CPU Profiling&lt;/strong&gt;：深入瞭解進程的方法熱點，按代碼執行、網絡 I/O、磁盤 I/O、鎖定時間和等待時間分解和過濾數據，常見的火焰圖正是 CPU Profiling 的產品體現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Memory Profiling&lt;/strong&gt;：內存分析可以瞭解應用程序隨時間變化的內存分配和垃圾回收行為，識別分配了最多內存的上下文中的方法調用，並將此信息與分配的對象數量相結合。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Memory Dump Aalysis&lt;/strong&gt;：通過進程的內存使用進行 dump 並分析。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Continuous Thread Analysis&lt;/strong&gt;：對線程持續分析，主要是後台線程組，記錄每個線程各個時間段的線程狀態以及資源使用情況。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不難看出上述功能在很多同類產品都有，比如 Vtrace 現在利用 Vivo 運維工具實現了 CPU Profiling、Memory Profiling 以及 Memory Dump Analysis。但是 Vtrace 的 CPU Profiling 與 Memory Profiling 並不是持續的，需要用戶手動觸發，每次最多隻能剖析 5 分鐘。後續我們會慢慢實現或優化 Continuous Profiling 的各個功能，而現在 Vtrace 系統是藉助 CPU Profiling 的技術手段去完善每個 Trace 的方法調用棧信息。&lt;/p&gt; 
&lt;h2&gt;3.1 方案選擇&lt;/h2&gt; 
&lt;p&gt;在分析 SkyWalking、DataDog 和 Dynatrace 是如何實現他們的 Profile 信息採集前，我們先看看 Java 應用在業界主流實現 CPU profling 的技術方案：&lt;strong&gt;JMX 、JFR 和 JVMTI AsyncGetCallTrace。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）JMX&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Java Management Extensions（JMX）是 Java 平台上的一種管理和監控技術，它允許開發人員在運行時監視和管理 Java 應用程序，一般使用 ThreadMXBean 中的 dumpAllThreads 可以獲取當前線程執行的方法棧情況，利用每次獲得的線程調用棧棧幀信息，可以實現方法熱點的監測。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）JFR&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Java Flight Recorder（JFR）是 Java 平台上的一種性能監控和故障診斷工具，JFR 的特點包括低性能開銷、低停頓、持續監控、動態配置和豐富的數據。它可以在應用程序運行時收集性能數據，而幾乎不會對應用程序的性能產生影響。但 JFR 的支持對 Java 版本有一定的要求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（3） JVMTI AsyncGetCallTrace&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AsyncGetCallTrace 是 JVMTI 中的一個非標函數，用於異步獲取線程的調用堆棧信息。使用 AsyncGetCallTrace，開發人員可以在應用程序運行時異步去獲取線程的調用堆棧信息，且不會阻塞線程的執行。這對於性能分析和故障診斷非常有用，因為它允許開發人員在不影響應用程序性能的情況下獲取線程的調用堆棧信息，從而更好地瞭解應用程序的執行情況和性能特徵。&lt;/p&gt; 
&lt;p&gt;上述三種方案便是實現 CPU Profiling 的主流方案，這三個方案在我們之前分析的三個產品中使用情況如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//26cbdf4581b7b1af0e8156d2fcff4686.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 3&lt;/p&gt; 
&lt;p&gt;SkyWalking 使用 JMX 實現性能剖析。他的實現是通過將採集到的 Trace 在 JVM 內部開啓線程任務，線程任務通過 segmentId 綁定當前 segmentId 所在的線程，按照採集頻率定時使用 getStackTrace 獲取各個時段的調用棧信息。但它的設計並不是為了實現 CPU Profiling，他只是一個補全 Trace 的鏈路分析快速實現，針對一些已知問題，常復現的問題，可以快速定位到根因。後續 SkyWalking 也不一定會使用上述三種方法實現 Java 語言的 CPU profling。&lt;/p&gt; 
&lt;p&gt;DataDog 最開始是用 JFR 實現 CPU Profiling，後來結合開源工具 Async-profiler，完善整個 Continuous Profiling 功能。Async-profiler 實現完全基於 JVMTI，其中它的 CPU 熱力圖就是得益於 AsyncGetCallTrace 接口。&lt;/p&gt; 
&lt;p&gt;Dynatrace 是個異類，它做分佈式 Trace 鏈路監控的時候，谷歌 Dapper 論文還要幾年才出世，谷歌 Dapper 流行後，它已放棄了通過&quot;-javaagent&quot;指令的方式實現字節碼增強，在 java，.net，go，python 等眾多語言實現無需引用相應的 agent 即可深入監控代碼級別的內部鏈路。它早期使用 JavaAgent 實現的產品 AppMon 可能使用過 JMX 實現 CPU Profiling，10 年前它改版後便完全基於 JVMTI 的 AsyncGetCallTrace 實現。&lt;/p&gt; 
&lt;p&gt;基於 JFR 或 AsyncGetCallTrace 實現 CPU Profiling 性能開銷會低很多。我們 vivo 的每個人都追求極致的性能，在技術選型上更偏向性能好的方案。而從廠商 DataDog 已經從 JFR 轉向通過結合 Async-profile 來實現整個 Continuous Profiling，JFR 可能並不是一個好選擇，所以剩下 AsyncGetCallTrace 的實現方式。或許最終我們也會利用 Async-profiler。&lt;/p&gt; 
&lt;p&gt;但是無論利用 Async-profiler 或者像 Dynatrace 一樣獨自去實現基於 AsyncGetCallTrace 採集，這對於我們監控團隊來説都存在困難，因為我們團隊缺少這方面的人力儲備。如果我們選擇基於 AsyncGetCallTrace 實現，要從零開始，需要學習 c++與 Async-profiler。這樣整個研發週期會被拉得很長，短則至少三個月長則半年，同時有較大的不確定性，交付存在風險。&lt;/p&gt; 
&lt;p&gt;另外基於 JMX 實現的採集方案被認為性能不夠好，但真正的性能損耗情況需要實踐去檢驗。如果 10ms 和 20ms 的採集頻率消耗資源太高，可以嘗試降低採集頻率。為了快速解決用戶痛點，現階段我們先選擇基於 JMX 在 Vtrace 的 JavaAgent 中實現，在 JavaAgent 中實現後再基於壓測情況決定後續落地方案。&lt;/p&gt; 
&lt;h2&gt;3.2 基於 JMX Profile 採集設計&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c25b50150577b7bb02650a502a19b53e.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 14&lt;/p&gt; 
&lt;p&gt;事實上我們這次的設計並不是為了實現 CPU Profiling，更多是為了補全 Trace 的信息。而對 Trace 的方法堆調用棧情況採集，我們基於 JMX Profile 設計如下：&lt;/p&gt; 
&lt;p&gt;1、JavaAgent 啓動時，如圖 14 所示開啓一個採集頻率 50ms Profile 採集線程，當然這裏採集頻率用戶是可以自行配置的。&lt;/p&gt; 
&lt;p&gt;2、Trace 進入時將 traceId 與當前 trace 線程 id 合併成一個 traceSegmentId(基於 SkyWalking 6 以上實現的 JavaAgent 可以直接使用他們自身的 traceSegmentId)，同時將這 traceSegmentId 與當前線程 Id 綁定放到一個叫 TRACE_PROFILE_MAP(Map) 的集合中。TRACE_PROFILE_MAP 除了記錄 traceSegmentId 和線程 id，同時會記錄後續被 Profile 線程採集到的快照。&lt;/p&gt; 
&lt;p&gt;3、Profile 數據採集的線程會定時將 TRACE_PROFILE_MAP 集合當前的所有線程 id 通過 ThreadMXBean.getThreadInfo 獲得每個線程當前棧幀信息。記錄當前棧幀頂部信息並按照我們設置的深度保留棧幀的一些信息當作本次快照。如果這個 trace 線程下一次被採集的棧幀頂部信息與棧深度與這次一樣，我們不需要記錄本次快照，只需將上次快照出現的次數+1，如圖 14 中棧頂為 Thread.sleep 的快照被我們記錄了 4 次。如果相鄰的兩次採集棧幀頂部信息不一樣，我們則記錄兩次快照信息，如圖 14 對於這個 trace 我們最後記錄了棧頂為 Object.wait 的快照 3 次。&lt;/p&gt; 
&lt;p&gt;4、trace 結束時，先根據 traceSegmentId 獲取到本次 trace 採集到的 Profile 快照數據，然後交給後續 Profile 數據上報線程異步處理，同時將 TRACE_PROFILE 集合記錄當前 trace 線程的相關數據從集合中移除。&lt;/p&gt; 
&lt;p&gt;5、如果這個 trace 是使用到多線程會整個 trace 會多個不同的 traceSegmentId，每個異步線程的相關 Profile 數據也會被採集到。&lt;/p&gt; 
&lt;p&gt;從流程上來看，基於 JMX 實現 CPU profiling 採集確實簡單，但也可以看出定時採樣的方式本身的缺陷，如圖 11 中 readFileToJson 方法中顯示的採集頻率太大兩次採樣會中間的讀取文件的 Disk I/O 會被忽略，但這也是無法避免的，用其它技術方案來實現也一樣會有這種問題。因此在實現 Profile 採集後，後續需要測試不同場景下不用採集頻率對資源的利用情況，然後結合當前 vivo 服務的整體情況，再最終決定這個方案是否用於生產。&lt;/p&gt; 
&lt;h2&gt;3.3 基於 AsyncGetCallTrace Profile 採集設計&lt;/h2&gt; 
&lt;p&gt;雖然我們先嚐試基於 JMX 的方式實現 Profile 採集，但不妨礙我們探討別的實現方案，很可能後續團隊能力起來後再轉向基於 AsyncGetCallTrace 實現。&lt;/p&gt; 
&lt;p&gt;通過分析 AsyncGetCallTrace 源碼與 Async-Profiler 的實現，發現基於 AsyncGetCallTrace Profile 的採集流程和上述流程相差不大，無非就是怎麼觸發採集，在 Liunx 系統一般使用信號量來觸發，這也會大大地降低採集時的性能損耗。&lt;/p&gt; 
&lt;p&gt;有些操作系統不支持使用信號量來調用 AsyncGetCallTrace 函數，可能需要用 c++實現一個不受 JVM 管理的線程，避免採集時受 JVM SavePiont 或 GC 的影響。&lt;/p&gt; 
&lt;p&gt;另外並不是所有操作系統的 JVM 中都提供 AsyncGetCallTrace 這個函數。&lt;/p&gt; 
&lt;p&gt;上述基於 AsyncGetCallTrace 的採集設計只是通過簡單的一些瞭解而設想的，並不一定正確，歡迎指正。&lt;/p&gt; 
&lt;p&gt;後續如果我們完全實現了基於 AsyncGetCallTrace Profile 採集我們再向大家介紹實現的細節。&lt;/p&gt; 
&lt;h2&gt;3.4 存儲設計&lt;/h2&gt; 
&lt;p&gt;介紹了 Profile 數據的採集設計，接下來聊一下存儲設計。&lt;/p&gt; 
&lt;p&gt;一個時間跨度為 1 秒的 Trace，在採集頻率為 50ms 時最多可能會被採集到 10 個副本。假設 Profile 採集記錄 stack 深度為 20，一份快照信息大約 1KB，這樣的話每個 Trace 最多可能需要增加 10KB 的存儲。如果記錄 stack 深度為 100 時快照信息大小則 6KB 左右。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fd1b56f71c4d848f4377ed6e5b90f7c6.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 15&lt;/p&gt; 
&lt;p&gt;上圖為我們 Prfoile 採集的一個快照文本內容，這個數據大約 1kb。如果每個快照數據都這樣存儲，則會佔用大量的存儲。同一個接口不同 Trace 的 Profile 數據會存在大量相同的快照文本，相同的快照文本用同一個 UID 來保存。UID 可以為快照文體的 MD5 值，每個 UID 只佔 16 字節。後續在分析 Trace 信息時再將 UID 對應快照文本顯示給用戶，這樣會節省大量的存儲成本 。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0e724739495047fccb3b3d768e21c32.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 16&lt;/p&gt; 
&lt;p&gt;圖 16 為 Vtrace 基於 JMX 實現 Profile 採集到數據，為了快速驗採集的效果直接讓採集到的快照數據作為 Span 存儲。圖中第一行數據為整個請求的 trace 耗時，而紅色框中的則為這個在 trace 我們 Profile 採集線程採集到的調用棧信息，從結果來看把我們原先的一些監控盲區補上來了。這圖的數據只是臨時處理，實際後續產品交互並不會這樣展示。&lt;/p&gt; 
&lt;p&gt;現在存在的問題就是 Vtrace JavaAgent 對所有 Trace 採集會整個服務的性能有哪些影響，而這些影響，是否在我們的接受範圍內。我們需要對增加 Profile 採集後對 JavaAgent 進行壓力測試，需要對比開啓 Profile 採集與未開啓 Profile 採集的性能指標差異。&lt;/p&gt; 
&lt;h1&gt;四、壓測分析&lt;/h1&gt; 
&lt;h2&gt;4.1 測試設計&lt;/h2&gt; 
&lt;p&gt;測試時需要考慮很多因素，因此在測試前先對測試做好設計，有以下的測試要點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;測試需要考慮環境，比如 cpu 核心數，容器或虛機，有條件最好使用物理機測試&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;測試考慮不同採集頻率時對性能的影響&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要在不同 TPS 的情況下對比資源的消耗&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要考慮同一 TPS 下，IO 不同的密集程度下資源消耗差異&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4.2 測試結果&lt;/h2&gt; 
&lt;p&gt;測試的時候我們記錄了很多指標，有很多數據，本文中就不一一展示了。Vtrace 的 Profile 採集對應用性能的產生實質影響在這裏我們只需考慮 CPU 使用和 GC 情況，因為採集增加的內存會側面反映在 GC 情況中。&lt;/p&gt; 
&lt;p&gt;下面為不同場景下開啓與不開啓 Profile 持續剖析時的資源利用情況對比：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//613900971419676553cbdf9e85dde055.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 4&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上述場景中 TPS 小於等 50 時，GC 次數很少，開啓 Profile 採集對 GC 的影響相差不多。而開啓 Profile 採集後對內存的影響主機體現在 GC 上。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;場景 1 與場景 2、場景 3 與場景 4、場景 5 與場景 6 三組採集頻率不同的對比測試，可以看出 Profile 採集頻率直接影響服務的資源消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隨着測試 TPS 的上升，Profile 採集消耗的資源也相應的增加，1000 TPS 內，從容器與虛機，CPU 4 核心時，開啓 Profile 採集 CPU 消耗整體增加不高於 5%; CPU 2 核心時 100 TPS 內開啓 Profile 採集 CPU 消耗整體增加不高於 4%。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於這個結果並不能説很理想，但又比預期要好一些，後續我們再結合我們當前應用的情況再分析是我們基於 JMX 實現的 Profile 是否可以投入生產使用。&lt;/p&gt; 
&lt;p&gt;而從上面的性能壓測結果可以看出通過降低採集頻率，CPU 資源消耗有明顯減少。但採集頻率不宜過低，50ms 對於大部分應用來説可以採集到很多有效的信息，這是我們的一個推薦值。&lt;/p&gt; 
&lt;h2&gt;4.3 資源消耗增加原因&lt;/h2&gt; 
&lt;p&gt;在壓力測試後我們知道開啓 Profile 採集後 CPU 資源會有所增加，接下來需要確定導致資源消耗增加的地方有哪些。&lt;/p&gt; 
&lt;p&gt;為了找出根因，最初我們想使用 Arthas 來生成火焰圖來分析，雖然這個場景應該也能分析出根因，但並不是很直觀，分析過程不會很流暢。Arthas 分析這個場景大概是這樣的，在開啓 Profile 採集前後分別生成火焰圖，但這樣沒法直觀地去對比出開啓採集後額外增量的熱點。同樣針對線程分析，Arthas 並沒有將線程歸類分組，顯示了大量的 http-nio-?-exec 線程 (?為線程 ID)。後來我們再次想起了前提到的 Dynatrace 中的 Cpu Profiling 與 Continuous thread analysis 功能，後續可能我們也會去實現類似的功能，抱着學習下商業化產品的 Continuous thread analysis 功能，於是便使用 Dynatrace 來分析。&lt;/p&gt; 
&lt;p&gt;雖然這個場景可以直接使用 Dynatrace 的方法熱點分析，但從進程到線程對比開啓 Profile 採集前後指標，整個流程會更加順暢，同時這樣的排查思路與產品呈現會帶來一些設計上的啓發。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5d830ec1be6c62112a4aae01282bdc8c.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 17&lt;/p&gt; 
&lt;p&gt;圖 17 是流量相同的情況下，開啓 Profile 採集前後指標的變化，從中可以看出：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;整個 java 進程 CPU 變化從 8.51% 增加到 12%&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;後台線程 CPU 變化從 4.81% 增加到 8.4%&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GC 線程 CPU 變化從 0.15% 增加 0.3%&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;上述結論我們知道開啓採集後導致進程 CPU 使用率增加的主要有後台線程和 GC 線程，GC 線程略有增加主要還是採集時額外使用的內存增加導致，所以下面我們重點對後台線程分析，這裏用到的便是 Continuous thread analysis 功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//032004bc954f8f1a8290ece6041fc8ca.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 18&lt;/p&gt; 
&lt;p&gt;圖 18 為開啓 Profile 採集後的後台線程分析，展示了某段時間內主要所有後台線程組的運行情況，我們可以看出增加的兩個進程組正好是我們的 Profile 採集線程與 Profile 數據發送線程，而 Profile 採集線程的奉獻度佔比遠大於 Profile 數據發送線程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e89140c94cccefde049c0c93c7b1152b.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 19&lt;/p&gt; 
&lt;p&gt;針對 Profile 採集線程我們再深入這個線程一段時間內的方法熱點去看，從圖 19 的結果上看 Profile 採集線程消耗 CPU 主要在調用 JVMTI 方法 (ThreadImpl.getThreadInfo1) 獲取當前線程的信息。&lt;/p&gt; 
&lt;p&gt;對這個判斷有點懷疑，認為線程信息採集到後處理調用棧的邏輯會有所消耗資源。對這個疑問，簡單的方法可以先將 Profile 採集線程中調用 ThreadImpl.getThreadInfo1 方法之後的所有代碼註釋然後壓力測試。接着加上線程棧數據處理的代碼同時註釋 Profile 採集發送的代碼，然後再在同樣的條件下壓測，之後再對比兩次壓測的性能差異。當然也可以使用 Arthas 來生成火焰圖分析，但我們並不是這樣做的，明顯有更加直觀的辦法，可以看看下面的 Profile 採集偽代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;//第 1 步,記錄當前 Profile 採線程 cpu 使用時間。getCpuTime 實際是直接調用 ThreadMXBean 的 getCurrentThreadCpuTime
long cpuTime = ThreadProvider.INSTANCE.getCurrentThreadCpuTime();
//第 2 步,獲取線程集合的 stackTrace 信息。ids 為當前正在執行的 trace 的線程 ID 集合，MAX_TACK_DEPTH 為採集 stackTrace 的最大深度
//ThreadProvider.INSTANCE.getThreadInfos 實際是直接調用 ThreadMXBean 的 getThreadInfos，底層最終是調 ThreadImpl.getThreadInfo1
ThreadInfo[] threadInfos = ThreadProvider.INSTANCE.getThreadInfos(ids, MAX_TACK_DEPTH);
//第 3 步,計算第 2 步的程序執行 CPU 使用時間
long threadDumpCpuTime = ThreadProvider.INSTANCE.getCurrentThreadCpuTime() - cpuTime;
//第 4 步，線程數據 threadInfos 的處理邏輯
for (ThreadInfo threadInfo : threadInfos) {
//獲得單個線程 StackTrace 信息，後續處理代碼省略
StackTraceElement[] stackTrace = threadInfo.getStackTrace();
int stackDepth = Math.min(stackTrace.length, MAX_TACK_DEPTH);
for (int i = stackDepth - 1; i &amp;gt; 0; i--) {
  StackTraceElement element = stackTrace[i];
}
......
}
//第 5 步，計算整個採集線程結束時 CPU 的使用時間以及 ThreadMXBean 的 getThreadInfos 消耗 CPU 的時間佔比。之後我們對比 threadDumpCpuTime 與 processCpuTime 便可知道整個線程 CPU 消耗在哪裏
long processCpuTime = ThreadProvider.INSTANCE.getCurrentThreadCpuTime() - cpuTime;
float threadDumpCost = threadDumpCpuTime * 1.0f / processCpuTime * 100
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通過上述代碼測試後發現第 4 步的代碼確實上也會有一些消耗，但幾乎 99% 以上都是消耗在第 2 步中。而 Dynatrace 顯示 ThreadImpl.getThreadInfo1 佔比為 100%，這是因為 Dynatrace 的 Profiiling 功能一樣也是有采樣頻率的，只是時間段內採集到的樣本全部顯示 Profile 採集線程獲得 CPU 時間片的方法是 ThreadImpl.getThreadInfo1，而這個測試恰好印證了 Dynatrace 方法熱點的準確性。&lt;/p&gt; 
&lt;p&gt;而對於 JMX 中的 ThreadImpl.getThreadInfo1，這是一個 native 方法，是無法直接優化的，只能等後續我們有能力基於 AsyncGetCallTrace 去實現 Profile 採集再解決。&lt;/p&gt; 
&lt;h2&gt;4.4 壓測小結&lt;/h2&gt; 
&lt;p&gt;通過本次壓力測試，我們清楚了基於 JMX 實現的 Profile 採集的性能消耗大致情況，也知道了性能瓶頸在哪裏以及後續的優化方向。&lt;/p&gt; 
&lt;h1&gt;五、落地評估&lt;/h1&gt; 
&lt;p&gt;接下來我們需要分析當前接入 Vtrace 產品 vivo 服務的情況，後面基於上面的測試結果與現狀去評估我們 Profile 採集能否最終落地。&lt;/p&gt; 
&lt;h2&gt;5.1 當前 vivo 服務情況&lt;/h2&gt; 
&lt;p&gt;目前接入 Vtrace 的 2500+個服務中有 200 多個服務他們實例的平均 TPS 大於 100 ，而單實例平均 TPS 小於 100 的服務佔 91.2%。下面表格中的數據是基於工作日某一分鐘統計得出的當前 Vtrace 所有服務實例平均 TPS 值的分佈情況：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e0371ee9715263276dc67168fb209fa7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 5&lt;/p&gt; 
&lt;h2&gt;5.2 落地分析&lt;/h2&gt; 
&lt;p&gt;通過上表可以看出 vivo 當前服務的情況，我們之前的測試結果表明在 2c4g 和 4c8g 的機器上服務 TPS 為 20 時 Profile 採集頻率設置 50ms，cpu 消耗增加 1% 不到。而我們約 75% 的服務 TPS 小於 20，也就是説這些服務如果願意接受 1% 的 CPU 資源消耗，基於 JMX 的 Profile 採集也能服務到大量的用戶。&lt;/p&gt; 
&lt;p&gt;對於 TPS 大於 100 的服務，如果只是某些固定接口需要排查，可以通過配置對需要 Profile 採集的接口進行過濾，這樣可以擴大落地的範圍。&lt;/p&gt; 
&lt;p&gt;因為考慮壓力測試的測試場景覆蓋場景有限，我們會更謹慎一些，先完善一下 Profile 採集保護機制，後面一些服務中試點再逐步鋪開。如果 TPS 小於 20 的服務順利展開，之後再考慮覆蓋 TPS 在 20 以上到 100 之間的服務。TPS 超 100 的服務可以針對需要分析的接口開啓 Profile 採集。至於所有服務全量採集覆蓋可能需要等於我們攻克基於 AsyncGetCallTrace 的採集設計之後。&lt;/p&gt; 
&lt;p&gt;很多大型企業可能和 vivo 差不多，大部分 90% 以上的服務單個實例 TPS 在 100 之內。而傳統企業 TPS 小於 100 的佔比則更高，如果是製造業的話可能 90% 的服務 TPS 不到 20。不過很多企業部署方式與 vivo 不同，他們可能在一個 8c16g 的機器上部署好幾個服務實例，這樣的話每個實例增加 1% 的資源消耗對於單個機器可能就顯得多了。還好 vivo 基本上都是單機單實例部署或者容器部署，所以避免了上服務混合部署的情況。&lt;/p&gt; 
&lt;p&gt;最後，我們基於 JMX 的 Profile 設計雖然不是業界內的最優解，但卻是當前快速解決 vivo Vtrace 監控的一個痛點的最優解。&lt;/p&gt; 
&lt;h1&gt;六、未來展望&lt;/h1&gt; 
&lt;p&gt;面對着困境我們努力優化卻回報不高，在同類產品的分析後我們探索出改進方向，而在技術選型上我們做了一些妥協，最後隨着對壓測結果與 vivo 的實際情況分析發現我們還算交了一份不錯的答卷。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5d4040298555aef4d89abce5a286220d.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 20&lt;/p&gt; 
&lt;p&gt;上圖展示了 Profile 採集的最終效果，與圖 1 相比，我們取得了巨大的進步。在優化了 MySQL 與 Kafka 的插件支持後，我們再次將 Vtrace 與同類產品進行對比：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b5d339e3687606ac92cf8deb4c44583f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;表 6&lt;/p&gt; 
&lt;p&gt;重新對比，可以看出 Vtrace 的 Trace 分析能力有了顯著的變化，從最初無法識別基本組件，提升到與頭部同類產品不相上下。這樣的 Trace 分析能力在國內可觀測領域屬於頂尖水準，全球範圍內也達到一流水平。&lt;/p&gt; 
&lt;p&gt;後續我們會重新整體去規劃 Continuous Profiling 的相關設計，同時團隊慢慢學習提升技術讓團隊能夠基於 AsyncGetCallTrace 將 Profile 採集的性能優化到最低。這並不只是為了優化 Profile 採集的性能，而是考慮到實現整個 Continuous Profiling 團隊也必須提升相關的技術能力。強大齊全的 Continuous Profiling 能力可觀測系統根因分析的關鍵，採集端消耗資源越小觀測能力的上限才會越高。&lt;/p&gt; 
&lt;p&gt;涅槃之路已經開啓，涅槃之路就在腳下，但這也只是剛剛開始。未來 Vtrace 不需要用戶配置任何的檢測規則，服務出現異常時 Vtrace 能夠自動檢測出問題。自動檢測出來的問題會自動定位出異常的的根因及異常影響業務的範圍，比如受到影響的接口上下文、接口請求量與用戶數量。而告警通知用戶可以按照自己的團隊要求去分派告警或者按照個人需求去訂閲告警，告警按照着每個團隊或個人的喜好方式流轉。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18123970</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18123970</guid>
            <pubDate>Thu, 03 Apr 2025 07:26:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>挑戰 Rust 和 Scala，這門新語言震驚德國開發者</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;原標題：MoonBit 語言的十大特性（MoonBit Language in 10 Features）&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;原文鏈接：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmedium.com%2F%40hivemind_tech%2Fmoonbit-language-in-10-features-4dc41a3a1d6c&quot; target=&quot;_blank&quot;&gt;https://medium.com/@hivemind_tech/moonbit-language-in-10-features-4dc41a3a1d6c&lt;/a&gt;&lt;/em&gt;&lt;br&gt; &lt;strong&gt;作者：Ignacio 丨德國科技公司 Hivemind 工程師&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0411/151915_XnW1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作為一名 Scala 開發者，我最近注意到 Scala 的市場在逐漸萎縮，這促使我探索其他具有類似特性的編程語言，例如支持函數式編程、高階類型、高階函數、泛型、運算符重載和領域建模等。&lt;/p&gt; 
&lt;p&gt;最近，我在 X（前稱 Twitter）上聽説了 MoonBit 語言，並通過搜索瞭解了更多信息。MoonBit 是一種 AI 原生的通用編程語言，由張宏波領導開發。&lt;/p&gt; 
&lt;p&gt;張宏波在編程語言開發方面有着豐富的經驗，曾是 OCaml 的核心貢獻者，ReScript 的創建者，並在 Meta （前稱 FaceBook）公司參與了 Flow 的開發。&lt;/p&gt; 
&lt;p&gt;MoonBit 由粵港澳大灣區數字經濟學院（IDEA）開發，該機構致力於人工智能和數字經濟領域的前沿研究和產業應用。&lt;/p&gt; 
&lt;p&gt;在其官方網站上，我發現 MoonBit 具有以下基本特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;融合了 Rust 和 Scala 的優點&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不使用 Rust 中的「借用」概念&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;採用垃圾回收機制&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能卓越&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可編譯為 WebAssembly&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為了體驗 MoonBit 的編程感受是否類似於編寫高質量的 Scala 代碼，我決定用 MoonBit 編寫一些代碼。我選擇了一個眾所周知的主題進行領域建模：國際象棋棋盤。我希望定義棋子、棋盤以及遊戲的初始狀態（暫不涉及棋子的移動和遊戲邏輯）。&lt;/p&gt; 
&lt;p&gt;示例代碼庫可在以下鏈接找到：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fignacio-hivemind%2FMoonBit-chess-example&quot; target=&quot;_blank&quot;&gt;https://github.com/ignacio-hivemind/MoonBit-chess-example&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;接下來，讓我們逐一探討 MoonBit 的這些特性。&lt;/p&gt; 
&lt;h2&gt;十大特性&lt;/h2&gt; 
&lt;h3&gt;1、枚舉類型&lt;/h3&gt; 
&lt;p&gt;首先，我為棋盤上的棋子創建了一些定義。在國際象棋中，棋子可以是黑色或白色，種類包括兵（Pawn）、車（Rook）、馬（Knight）、象（Bishop）、後（Queen）和王（King）。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// This application is about a chess board,
// and how to represent it in the MoonBit language.
//
// Board is a double dimension array of BoardPlace
// cols: &amp;nbsp;0 1 2 3 4 5 6 7
// row 0: R N B Q K B N R
// row 1: P P P P P P P P
// row 2: . . . . . . . .
// row 3: . . . . . . . .
// row 4: . . . . . . . .
// row 5: . . . . . . . .
// row 6: p p p p p p p p
// row 7: r n b q k b n r
//
// The upper case letters represent the white pieces,
// whereas the lower case letters represent the black pieces.
// The pieces are: Pawn (P or p), Rook (R or r), Knight (N or n),
// Bishop (B or b), Queen (Q or q), King (K or k).
// The dots represent empty places.


/// This is documentation for the Color enum data type.
/// This is the color of the pieces in a chess game.
pubenumColor&amp;nbsp;{
&amp;nbsp; &amp;nbsp;White
&amp;nbsp; &amp;nbsp;Black
}


/// This is documentation for the Piece enum.
/// It represents the different pieces in a chess game.
pubenumPiece&amp;nbsp;{
&amp;nbsp; &amp;nbsp;Pawn
&amp;nbsp; &amp;nbsp;Rook
&amp;nbsp; &amp;nbsp;Knight
&amp;nbsp; &amp;nbsp;Bishop
&amp;nbsp; &amp;nbsp;Queen
&amp;nbsp; &amp;nbsp;King
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如上所示，在定義前使用三個斜槓（///）可為方法、數據類型或函數添加文檔註釋。使用兩個斜槓（//）則表示單行註釋。pub 關鍵字表示這些定義對其他文件或模塊是公開的。枚舉類型（enum）定義了一種新的類型，其值只能是大括號內指定的選項。例如，Color 的值只能是 White 或 Black，Piece 的值只能是 Pawn、Rook、Knight、Bishop、Queen 或 King 之一。&lt;/p&gt; 
&lt;h3&gt;2、內置 Trait 的自動派生&lt;/h3&gt; 
&lt;p&gt;在之前的枚舉定義中，我們可以添加 derive(Show, Eq)，自動為這些枚舉實現 Show 和 Eq 特性。這意味着我們可以直接比較和打印 Color 或 Piece 的實例。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;enum&amp;nbsp;Color&amp;nbsp;{
..
}&amp;nbsp;derive(Show,&amp;nbsp;Eq)

pub&amp;nbsp;enum&amp;nbsp;Piece&amp;nbsp;{
..
}&amp;nbsp;derive(Show,&amp;nbsp;Eq)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;例如，我們可以編寫一個函數來比較棋子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;enum&amp;nbsp;Color&amp;nbsp;{
&amp;nbsp; &amp;nbsp; ..
}&amp;nbsp;derive(Show,&amp;nbsp;Eq)

pub&amp;nbsp;enum&amp;nbsp;Piece&amp;nbsp;{
&amp;nbsp; &amp;nbsp; ..
}&amp;nbsp;derive(Show,&amp;nbsp;Eq)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;compare_pieces(piece: Piece)&amp;nbsp;-&amp;gt;&amp;nbsp;Unit {
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;piece == Pawn {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;println(&quot;The piece is a pawn&quot;)
&amp;nbsp; &amp;nbsp; }&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;println(&quot;The piece is a &quot;&amp;nbsp;+ piece.to_string())
&amp;nbsp; &amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在這個示例中，我們可以直接使用&amp;nbsp;&lt;strong&gt;==&lt;/strong&gt;&amp;nbsp;運算符比較&lt;strong&gt;Piece&lt;/strong&gt;的實例，因為&lt;strong&gt;Piece&lt;/strong&gt;實現了&lt;strong&gt;Eq&lt;/strong&gt;特性。同時，我們可以使用&lt;strong&gt;to_string()&lt;strong&gt;方法打印&lt;/strong&gt;Piece&lt;/strong&gt;的實例，因為它實現了&lt;strong&gt;Show&lt;/strong&gt;特性。&lt;/p&gt; 
&lt;h3&gt;3、類型別名&lt;/h3&gt; 
&lt;p&gt;在定義棋盤時，我們可以使用類型別名來提高代碼的可讀性和可維護性。例如，定義&lt;strong&gt;BoardPlace&lt;/strong&gt;為&lt;strong&gt;Option[(Piece, Color)]&lt;/strong&gt;，表示棋盤上的每個位置要麼為空，要麼包含一個特定顏色的棋子。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// This is the representation of a place on a chess board.
/// It can be empty (None) or contain a piece with a color: Some((piece, color)).
pub&amp;nbsp;typealias BoardPlace =&amp;nbsp;Option[(Piece, Color)]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;通過這種定義方式，在代碼中任何位置，我們都可以用&lt;strong&gt;BoardPlace&lt;/strong&gt;代替對應的&lt;strong&gt;Option&lt;/strong&gt;類型，反之亦然。這只是右側類型定義的簡化表達方式。另外，值得注意的是，&lt;strong&gt;Option&lt;/strong&gt;數據類型內置於 MoonBit 語言的標準庫中，與 Rust 和 Scala 類似。MoonBit 還內置了&lt;strong&gt;Result&lt;/strong&gt;數據類型，它與 Scala 中的&lt;strong&gt;Either&lt;/strong&gt;類型類似，但更專注於錯誤處理。&lt;/p&gt; 
&lt;h3&gt;4、模式匹配&lt;/h3&gt; 
&lt;p&gt;模式匹配 (Pattern Matching) 對熟悉 Haskell、Scala 或 Rust 的開發者而言，「模式匹配」是一個常見概念。在 MoonBit 中，可以通過如下方式定義一個使用模式匹配的函數：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn&amp;nbsp;draw(self: BoardPlace)&amp;nbsp;-&amp;gt;&amp;nbsp;String&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;match&amp;nbsp;self&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;None&amp;nbsp;=&amp;gt;&amp;nbsp;&quot;.&quot;&amp;nbsp;// empty place
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Some((piece, Color::White)) =&amp;gt; pieceToString.get*or_default(piece,&amp;nbsp;&quot;.&quot;)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Some((piece, Color::Black)) =&amp;gt; pieceToString.get_or_default(piece,&amp;nbsp;&quot;.&quot;).to_lower()
&amp;nbsp; &amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這裏，&lt;strong&gt;pieceToString&lt;/strong&gt;是一個映射 (map)：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;let&amp;nbsp;pieceToString: Map[Piece,&amp;nbsp;String] = Map::of([
&amp;nbsp; &amp;nbsp; (Piece::Pawn,&amp;nbsp;&quot;P&quot;),
&amp;nbsp; &amp;nbsp; (Piece::Rook,&amp;nbsp;&quot;R&quot;),
&amp;nbsp; &amp;nbsp; (Piece::Knight,&amp;nbsp;&quot;N&quot;),
&amp;nbsp; &amp;nbsp; (Piece::Bishop,&amp;nbsp;&quot;B&quot;),
&amp;nbsp; &amp;nbsp; (Piece::Queen,&amp;nbsp;&quot;Q&quot;),
&amp;nbsp; &amp;nbsp; (Piece::King,&amp;nbsp;&quot;K&quot;)
])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上述函數的輸入是&lt;strong&gt;BoardPlace&lt;/strong&gt;類型，輸出則是表示棋盤上該位置棋子的字符串。此外，你還可以使用特殊的通配符 *，來匹配所有未被前面的模式匹配到的其他情況。&lt;/p&gt; 
&lt;p&gt;需要注意的是，在 MoonBit 中，&lt;strong&gt;match&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;if&lt;/strong&gt;&amp;nbsp;關鍵字都是表達式（expressions），而非語句（statements）。因此，它們會返回一個值。&lt;/p&gt; 
&lt;p&gt;與 Scala 類似，在一個由花括號&amp;nbsp;&lt;strong&gt;{}&lt;/strong&gt;&amp;nbsp;圍成的代碼塊中，最後一個表達式的值即為該代碼塊的返回值。這一點在函數中同樣適用，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;abs(a: Int)&amp;nbsp;-&amp;gt;&amp;nbsp;Int {
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;absolute: Int =&amp;nbsp;if&amp;nbsp;a &amp;gt;=&amp;nbsp;0&amp;nbsp;{ a }&amp;nbsp;else&amp;nbsp;{ -a }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;absolute
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;當省略掉 return 關鍵字時，也能達到完全相同的效果：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;abs(a: Int)&amp;nbsp;-&amp;gt;&amp;nbsp;Int {
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;absolute: Int =&amp;nbsp;if&amp;nbsp;a &amp;gt;=&amp;nbsp;0&amp;nbsp;{ a }&amp;nbsp;else&amp;nbsp;{ -a }
&amp;nbsp; &amp;nbsp; absolute
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然而，在某些場景中，使用顯式的&lt;strong&gt;return&lt;/strong&gt;語句仍然是非常有用的，特別是當你希望提前返回（early return），跳過函數剩餘邏輯處理特定情況時：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;early_return(a:&amp;nbsp;String)&amp;nbsp;-&amp;gt;&amp;nbsp;Bool {
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;a ==&amp;nbsp;&quot;.&quot;&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;false
}

// go on with the function logic:
// at this point you know that a is NOT 「.」
// ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5、結構體類型&lt;/h3&gt; 
&lt;p&gt;結構體（struct）類型允許通過組合多個不同類型的字段來構造出新的數據類型。這種機制類似於其他編程語言中的類（class），特別是在結構體中加入方法定義以及信息隱藏（封裝）時，更是如此。&lt;/p&gt; 
&lt;p&gt;例如，我們可以這樣定義棋盤上的一行（Row）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// This is a struct that represents a row in the board
pub&amp;nbsp;struct&amp;nbsp;Row&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;// Array type definition:
&amp;nbsp; &amp;nbsp;&amp;nbsp;priv&amp;nbsp;cols: Array[BoardPlace]&amp;nbsp;// information hiding: private fields
}&amp;nbsp;derive(Show,&amp;nbsp;Eq)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;再定義整個棋盤（Board）的網格結構以及棋盤當前的狀態（BoardState）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// This is a struct that represents the board grid
pub&amp;nbsp;struct&amp;nbsp;Board&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;priv&amp;nbsp;grid: Array[Row]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;/// This is a struct that represents the board state
pub&amp;nbsp;struct&amp;nbsp;BoardState&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;priv&amp;nbsp;board: Board
&amp;nbsp; &amp;nbsp;&amp;nbsp;priv&amp;nbsp;turn: Turn
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以上定義清晰地表達了棋盤元素及棋盤狀態的結構。&lt;/p&gt; 
&lt;p&gt;當我們想在&lt;strong&gt;Row&lt;/strong&gt;這個結構體的命名空間（namespace）下添加方法時，有兩種方式：&lt;/p&gt; 
&lt;p&gt;方法一： 此方法定義了一個沒有任何棋子的棋盤行。注意&amp;nbsp;&lt;strong&gt;Row::&lt;/strong&gt;&amp;nbsp;這個前綴，它明確表明這是針對類型&lt;strong&gt;Row&lt;/strong&gt;定義的方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;Row::empty_row()&amp;nbsp;-&amp;gt;&amp;nbsp;Row {
&amp;nbsp; &amp;nbsp; { cols: Array::make(8,&amp;nbsp;None) }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;方式二： 如果方法需要訪問結構體自身（self）的數據，定義方式則如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// fn &amp;lt;name&amp;gt;(self: &amp;lt;type&amp;gt;, &amp;lt;parameters&amp;gt;) -&amp;gt; &amp;lt;return type&amp;gt; { &amp;lt;body&amp;gt; }
// And then you can call: &amp;lt;object&amp;gt;.&amp;lt;name&amp;gt;(&amp;lt;parameters&amp;gt;)
pub&amp;nbsp;fn&amp;nbsp;get_turn(self: BoardState)&amp;nbsp;-&amp;gt;&amp;nbsp;Turn {
&amp;nbsp; &amp;nbsp;&amp;nbsp;self.turn
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;例如，當&lt;strong&gt;board_state&lt;/strong&gt;是&lt;strong&gt;BoardState&lt;/strong&gt;類型的實例時，我們就可以通過&amp;nbsp;&lt;strong&gt;board_state.get_turn()&lt;/strong&gt;&amp;nbsp;來獲取當前國際象棋遊戲中的回合（Turn）信息。&lt;/p&gt; 
&lt;h3&gt;6、運算符重載&lt;/h3&gt; 
&lt;p&gt;可以通過重載「[]」運算符，以允許對棋盤行中的元素進行索引操作，如下面的代碼片段所示。你只需為你的類型（在本例中為&lt;strong&gt;Row&lt;/strong&gt;類型）重載**op_get()**方法即可：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// This special method name &quot;op_get&quot; is used to overload the [] operator.
pub&amp;nbsp;fn&amp;nbsp;op_get(self:Row, index: Int)&amp;nbsp;-&amp;gt;&amp;nbsp;BoardPlace {
&amp;nbsp; &amp;nbsp;&amp;nbsp;self.cols[index]
}To allow&amp;nbsp;for&amp;nbsp;indexed&amp;nbsp;assignment operations, you can&amp;nbsp;override&amp;nbsp;the&amp;nbsp;op_set() method:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了允許索引賦值操作，你還可以重載&amp;nbsp;&lt;strong&gt;op_set()&lt;/strong&gt;&amp;nbsp;方法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;op_set(self: Row, index: Int, value: BoardPlace)&amp;nbsp;-&amp;gt;&amp;nbsp;Unit {
&amp;nbsp; &amp;nbsp;&amp;nbsp;self.cols[index] = value;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;例如，現在你可以這樣做：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;check_first_element(row: Row)&amp;nbsp;-&amp;gt;&amp;nbsp;Unit {
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;element: BoardPlace = row[0]&amp;nbsp;// Access the row with an index using 「[]」 operator
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;element is&amp;nbsp;Some((Piece::Pawn, Color::White)) {
&amp;nbsp; &amp;nbsp;println(&quot;First element is a white pawn&quot;)
&amp;nbsp;}
&amp;nbsp;...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;7、新類型定義&lt;/h3&gt; 
&lt;p&gt;MoonBit 允許你基於已有的類型定義一個新類型。例如，要定義 Turn 數據類型，我們可以這樣做：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// This is a new type that represents a turn in a chess game.
pub&amp;nbsp;type&amp;nbsp;Turn&amp;nbsp;Color
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，&lt;strong&gt;Turn&lt;/strong&gt;就是一個新類型，類似於 Scala 語言中的 opaque 類型。要創建一個&lt;strong&gt;Turn&lt;/strong&gt;類型的實例，你需要將值包裝在類型名中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;BoardState::initialSetup!()&amp;nbsp;-&amp;gt;&amp;nbsp;BoardState {
&amp;nbsp; &amp;nbsp; { board: Board::initialize!(), turn:&amp;nbsp;Turn(Color::White) }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種方式確保了顏色（Color）和回合（Turn）的值在編譯時不會被混淆。&lt;/p&gt; 
&lt;h3&gt;8、特性&lt;/h3&gt; 
&lt;p&gt;下面是 MoonBit 中定義新特性的語法。由於它是「open」的，因此可以被擴展：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// This trait defines a draw method that returns a string
/// representation of the object.
/// It is used to draw the different objects in the chess game to a String.
/// (although it could be in another format or different resource, like a file or
/// screen).
pub(open)&amp;nbsp;trait&amp;nbsp;Drawable&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;draw(Self)&amp;nbsp;-&amp;gt;&amp;nbsp;String
&amp;nbsp; &amp;nbsp; }

&amp;nbsp; &amp;nbsp;&amp;nbsp;pub(open)&amp;nbsp;trait&amp;nbsp;Paintable&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;paint(Self)&amp;nbsp;-&amp;gt;&amp;nbsp;Unit
&amp;nbsp; &amp;nbsp; }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我們定義了兩個特性，每個特性中都有不同的（抽象）方法：&lt;strong&gt;draw()&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;paint()&lt;/strong&gt;。這類似於 Java 中的接口或 Scala 中的 trait。&lt;/p&gt; 
&lt;p&gt;兩個特性可以通過「+」運算符進行組合或繼承：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// This is how you extend and combine traits in MoonBit language.
pub&amp;nbsp;trait&amp;nbsp;DrawableAndPaintable&amp;nbsp;: Drawable + Paintable {}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;特性中的方法通過以下方式進行實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// Implement Drawable for BoardPlace trait
pub&amp;nbsp;impl&amp;nbsp;Drawable&amp;nbsp;for&amp;nbsp;BoardPlace&amp;nbsp;with&amp;nbsp;draw(self: BoardPlace)&amp;nbsp;-&amp;gt;&amp;nbsp;String&amp;nbsp;{
&amp;nbsp; &amp;nbsp; ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如你所見，我在&amp;nbsp;&lt;strong&gt;BoardPlace&lt;/strong&gt;&amp;nbsp;類型上實現了&amp;nbsp;&lt;strong&gt;draw()&lt;/strong&gt;&amp;nbsp;方法（以滿足&amp;nbsp;&lt;strong&gt;Drawable&lt;/strong&gt;&amp;nbsp;接口的要求）。如果我們同樣為&amp;nbsp;&lt;strong&gt;BoardPlace&lt;/strong&gt;&amp;nbsp;類型實現** paint() ** 方法，那麼該數據類型也將滿足** Paintable ** 和&amp;nbsp;&lt;strong&gt;DrawableAndPaintable&lt;/strong&gt;&amp;nbsp;。&lt;/p&gt; 
&lt;p&gt;接下來，我們還可以為&amp;nbsp;&lt;strong&gt;Row&lt;/strong&gt;&amp;nbsp;類型實現&amp;nbsp;&lt;strong&gt;draw()&lt;/strong&gt;&amp;nbsp;方法：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/// Implement Drawable for Row
impl&amp;nbsp;Drawable&amp;nbsp;for&amp;nbsp;Row&amp;nbsp;with&amp;nbsp;draw(self: Row)&amp;nbsp;-&amp;gt;&amp;nbsp;String&amp;nbsp;{
&amp;nbsp; &amp;nbsp; ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;9、內置測試&lt;/h3&gt; 
&lt;p&gt;通過定義一個輔助函數，我們可以根據字符串生成一行新的棋盤數據：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;Row::new_row_from_string!(rowStr:&amp;nbsp;String)&amp;nbsp;-&amp;gt;&amp;nbsp;Row {
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(rowStr.length(),&amp;nbsp;8)
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;cols&amp;nbsp;= []
&amp;nbsp; &amp;nbsp;&amp;nbsp;// for loops in MoonBit
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;i&amp;nbsp;in&amp;nbsp;0..=7&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cols.push(new_place_from_char(rowStr[i]))
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; { cols: cols }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這是在 MoonBit 中定義 for 循環的方式，用於從 0 到 7（包含 7）進行迭代。我將輸入字符串中的每個棋子依次插入到&amp;nbsp;&lt;strong&gt;cols&lt;/strong&gt;&amp;nbsp;數組中。&lt;strong&gt;assert_eq!&lt;/strong&gt;&amp;nbsp;語句用於檢查&amp;nbsp;&lt;strong&gt;rowStr&lt;/strong&gt;&amp;nbsp;參數的長度是否為 8，以確保可以正確構造出一行。最後一行返回一個新的&amp;nbsp;&lt;strong&gt;Row&lt;/strong&gt;&amp;nbsp;對象。&lt;/p&gt; 
&lt;p&gt;接下來，我們可以在代碼的任何位置使用&amp;nbsp;&lt;strong&gt;test&lt;/strong&gt;&amp;nbsp;關鍵字定義測試：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;test&amp;nbsp;&quot;create a white row from string&quot;&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;my_row: Row = Row::new_row_from_string!(&quot;RNBQKBNR&quot;)

&amp;nbsp; &amp;nbsp; assert*eq!(my_row[0],&amp;nbsp;Some((Piece::Rook, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[1],&amp;nbsp;Some((Piece::Knight, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[2],&amp;nbsp;Some((Piece::Bishop, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[3],&amp;nbsp;Some((Piece::Queen, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[4],&amp;nbsp;Some((Piece::King, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[5],&amp;nbsp;Some((Piece::Bishop, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[6],&amp;nbsp;Some((Piece::Knight, Color::White)))
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(my_row[7],&amp;nbsp;Some((Piece::Rook, Color::White)))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這種方式非常簡潔，我們無需依賴其他測試框架，就可以直接在代碼中嵌入測試塊，用來驗證某些性質是否一直成立，特別是在持續開發新功能或重構代碼時非常有幫助。&lt;/p&gt; 
&lt;h3&gt;10、函數式編程支持&lt;/h3&gt; 
&lt;p&gt;讓我們回顧上一節中定義的&amp;nbsp;&lt;strong&gt;new_row_from_string()&lt;/strong&gt;&amp;nbsp;函數。我們原本使用** for** 循環逐個將棋子壓入行數組中，但其實可以使用數組的&amp;nbsp;&lt;strong&gt;map&lt;/strong&gt;&amp;nbsp;函數來生成這些元素：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pub&amp;nbsp;fn&amp;nbsp;Row::new_row_from_string!(rowStr:&amp;nbsp;String)&amp;nbsp;-&amp;gt;&amp;nbsp;Row {
&amp;nbsp; &amp;nbsp;&amp;nbsp;assert_eq!(rowStr.length(),&amp;nbsp;8)
&amp;nbsp; &amp;nbsp; { cols: rowStr.to_array().map(new_place_from_char) }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;現在，它變成了一行搞定！&lt;/p&gt; 
&lt;p&gt;這個函數的邏輯是：將字符串轉換為字符數組，然後逐個字符傳入&amp;nbsp;&lt;strong&gt;new_place_from_char()&lt;/strong&gt;&amp;nbsp;函數，用以生成&amp;nbsp;&lt;strong&gt;cols&lt;/strong&gt;&amp;nbsp;數組。最後的表達式構造並返回一個包含&amp;nbsp;&lt;strong&gt;cols&lt;/strong&gt;&amp;nbsp;的結構體實例。&lt;/p&gt; 
&lt;p&gt;另外，作為一個額外的特性，MoonBit 支持泛型數據類型，你可以用它來定義集合或參數化類型：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn&amp;nbsp;count[A](list : @immut/list.T[A])&amp;nbsp;-&amp;gt;&amp;nbsp;UInt {
&amp;nbsp; &amp;nbsp;&amp;nbsp;match&amp;nbsp;list {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Nil =&amp;gt;&amp;nbsp;0
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Cons(*, rest) =&amp;gt;&amp;nbsp;count(rest) +&amp;nbsp;1
&amp;nbsp; &amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多關於泛型和函數式編程的細節將在後續文章中介紹！&lt;/p&gt; 
&lt;h2&gt;優勢&lt;/h2&gt; 
&lt;h3&gt;1、垃圾回收&lt;/h3&gt; 
&lt;p&gt;MoonBit 是一種表達能力非常強的語言，在許多方面與 Rust 相似，但不採用 Rust 中「借用」和「所有權」的內存管理概念。雖然這些機制能帶來內存安全，但在我看來它們太底層、使用起來也不夠友好。而 MoonBit 使用的是垃圾回收機制來回收內存空間，這使得語言對開發者更友好，編碼體驗也更加簡潔自然。&lt;/p&gt; 
&lt;h3&gt;2、工具鏈&lt;/h3&gt; 
&lt;p&gt;本次示例我只寫了大約 400 行代碼，但用來運行和測試程序的工具（如&amp;nbsp;&lt;strong&gt;moon&lt;/strong&gt;&amp;nbsp;命令行工具）以及 VS Code 插件，給我的感覺是相當穩定、實用，能夠很好地支持大型應用的開發。唯一的不足是調試器有時會顯示局部變量的內部表示形式，而不是它們實際的值，這不太直觀。&lt;/p&gt; 
&lt;h3&gt;3、性能表現&lt;/h3&gt; 
&lt;p&gt;雖然我只用 MoonBit 編程了幾個小時，但它的編譯和運行速度都非常快！編譯器主要面向 WASM（WebAssembly）優化，但也支持編譯為 JavaScript 和其他平台的代碼。&lt;/p&gt; 
&lt;p&gt;你可以在 MoonBit 官方網站（https://www.MoonBitlang.com/）查看一些性能基準測試：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;628&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/152039_7rbi_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（此處原文附有鏈接和圖表，建議前往官網獲取最新數據）&lt;/p&gt; 
&lt;p&gt;令人驚訝的是，在一些基準測試中，MoonBit 的表現甚至超過了 Rust 和 Go。MoonBit 能夠生成體積緊湊的二進制文件，這在 Web 環境中能顯著提升加載速度和運行性能，使部署變得更容易、更快速、更具成本效益。&lt;/p&gt; 
&lt;h3&gt;4、與 Scala 的對比&lt;/h3&gt; 
&lt;p&gt;MoonBit 語言同樣吸收了許多來自 Scala 的概念，比如「代碼塊返回最後一個表達式的值」。&lt;/p&gt; 
&lt;p&gt;MoonBit 的語言規模更小，也並未包含 Scala 中的所有特性。但考慮到 Scala 的學習曲線陡峭、精通難度較高，這反而可能是件好事——因為這意味着更容易讓開發團隊快速上手。雖然你不會擁有所有的函數式編程（FP）特性，但依然可以編寫出非常不錯的函數式代碼，例如以下代碼片段（摘自 MoonBit 官網）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn&amp;nbsp;main&amp;nbsp;{
&amp;nbsp; &amp;nbsp; resources
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .iter()
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .map*option(fn&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; (name,&amp;nbsp;Text(str)) | (name,&amp;nbsp;CSV(content=str)) =&amp;gt;&amp;nbsp;Some((name,&amp;nbsp;str))
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; (*, Executable) =&amp;gt;&amp;nbsp;None
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp; .map(fn&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; (name, content) =&amp;gt; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;letname&amp;nbsp;= name.pad*start(10,&amp;nbsp;&#39; &#39;)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;letcontent&amp;nbsp;= content
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .pad_end(10,&amp;nbsp;&#39; &#39;)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .replace_all(old=&quot;\n&quot;, new=&quot; &quot;)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .substring(start=0, end=10)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;\{name}: \{content} ...&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp; .intersperse(&quot;\n&quot;)
&amp;nbsp; &amp;nbsp; .fold(init=&quot;Summary:\n&quot;,&amp;nbsp;String::op_add)
&amp;nbsp; &amp;nbsp; |&amp;gt; println
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你可以使用 Lambda 表達式、特性（traits）、結構體（structs，代替類）以及高階函數。此外，就像在 Rust 和 Scala 中一樣，MoonBit 也內建了&amp;nbsp;&lt;strong&gt;Option&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;Result&lt;/strong&gt;&amp;nbsp;數據類型。Scala 在表達能力和靈活性方面更強，但也更復雜。&lt;/p&gt; 
&lt;p&gt;Scala 還能調用所有 Java 的庫——這些庫經過多年發展，數量龐大且非常穩定；相比之下，MoonBit 當前可用的庫數量不多，成熟度也相對較低（在官方網站上，大約有 250 個左右的庫可供使用）。&lt;/p&gt; 
&lt;p&gt;Moon CLI 也作為包管理器使用，例如：moon add peter-jerry-ye/async。這條命令告訴項目添加一個名為&amp;nbsp;&lt;strong&gt;peter-jerry-ye/async&lt;/strong&gt;&amp;nbsp;的依賴項。&lt;/p&gt; 
&lt;h3&gt;5、社區&lt;/h3&gt; 
&lt;p&gt;MoonBit 的社區規模尚不如 Rust 或 Scala，那意味着目前在網上找資料會比較困難，AI 編程助手（如 LLM 和 Copilot）對 MoonBit 的支持也還不夠完善。&lt;/p&gt; 
&lt;p&gt;起初，我認為這個語言還非常不成熟，但當我在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmooncakes.io%2F&quot; target=&quot;_blank&quot;&gt;https://mooncakes.io/&lt;/a&gt; 上查看其可用庫時，發現其實 MoonBit 已經涵蓋了許多基礎領域的庫，例如 HTTP、異步編程、機器學習工具（如 torch）等。&lt;/p&gt; 
&lt;p&gt;此外，MoonBit 還內置了&amp;nbsp;&lt;strong&gt;Json&lt;/strong&gt;&amp;nbsp;數據類型，這對於開發需要處理 HTTP JSON 服務的程序員來説非常實用：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn&amp;nbsp;main&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;json_example&amp;nbsp;: Json = {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;array&quot;: [&quot;a&quot;,&amp;nbsp;&quot;b&quot;],
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;age&quot;:&amp;nbsp;22,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;name&quot;:&amp;nbsp;&quot;John&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;boolean&quot;: True
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;let&amp;nbsp;greeting&amp;nbsp;=&amp;nbsp;match&amp;nbsp;json_example {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; {&amp;nbsp;&quot;age&quot;:&amp;nbsp;Number(age),&amp;nbsp;&quot;name&quot;:&amp;nbsp;String(name) } =&amp;gt;&amp;nbsp;&quot;Hello \{name}. You are \{age}&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; * =&amp;gt;&amp;nbsp;&quot;not match&quot;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; greeting |&amp;gt; println
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;最後總結&lt;/h2&gt; 
&lt;p&gt;截至 2025 年 3 月，MoonBit 已經超越測試階段。其編譯器（包括 WebAssembly 後端）已於 2024 年 12 月開源，這標誌着向穩定版本邁出了重要一步。MoonBit 團隊正在穩步推進 1.0 正式版的發佈，預計將包括對異步支持和嵌入式編程能力的集成。&lt;/p&gt; 
&lt;p&gt;憑藉其現代化的語言特性、高性能以及生成的二進制文件體積小，MoonBit 在部署到雲端時非常輕便且成本低。&lt;/p&gt; 
&lt;p&gt;儘管 MoonBit 的表達能力不如 Scala 豐富、簡潔，因此暫時還不能完全取代 Scala，但它目前在很多方面可以與 Rust 相抗衡。這使得 MoonBit 在某些商業領域具備強大的成功潛力。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;MoonBit（https://www.moonbitlang.cn/）是國內首個工業級編程語言及其配套工具鏈，由粵港澳大灣區數字經濟研究院（簡稱「IDEA 研究院」）基礎軟件中心打造的 AI 原生的編程語言以及開發者平台。通過創新框架在程序語言界形成後發優勢，在編譯速度、運行速度、體積大小上已成功領先傳統語言。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343981/moonbit-language-in-10-features</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343981/moonbit-language-in-10-features</guid>
            <pubDate>Thu, 03 Apr 2025 07:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>大模型基準測試 ITU 國際標準正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國際電信聯盟電信標準分局（ITU-T）於 2025 年 3 月正式發佈 ITU-T F.748.44 基礎模型的評估標準：基準測試/ Assessment criteria for foundation models: Benchmark。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該項國際標準由中國信息通信研究院（簡稱「中國信通院」）牽頭制定，規範了大模型基準測試的指標要求和測試方法。該標準旨在推動大模型基準測試體系架構形成國際共識，為大模型技術提供方和應用方提供高質量的能力評估依據，引導大模型技術及產業健康有序發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;424&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cee93114efaa5693f577dc5119ccb0d38c6.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，本次發佈的國際標準基於當前產學研界 500 餘項基準測試系統性研究，一方面確立了大模型基準測試的 4 項核心要素，包括測試維度（測試場景、測試能力、測試任務和測試指標）、測試數據集、測試方法和測試工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，針對通用場景的基礎模型，提供了標準化的測試用例和範例流程，以支持企業規範開展大模型能力評估。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國信通院人工智能研究所於 2023 年開始佈局大模型基準測試研究，並於 2023 年底發佈「方升」大模型基準測試體系，推出自適應動態測試方法，積累 600 萬條數據集，構建 FactTeting 測試工具，支撐整個大模型測試過程的自動化實施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;自 2024 年以來，參照已發佈的 ITU 大模型基準測試國際標準，對國內外標杆大模型以兩個月為週期開展持續監測工作，包括 OpenAI o1、DeepSeek R1、Gemini 2.5 Pro、Claude 3.7 Sonnet、Qwen2.5-Max、百度文心大模型 X1 等上百個測試模型，目前已發佈大語言通用能力、推理能力、代碼能力，多模態理解能力、文生圖能力、文生視頻能力等多個輪次的評測結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國際標準 ITU-T F.748.44 的發佈是大模型測試領域的重要標準化成果，對推動技術創新和發展、引領行業發展趨勢、促進國際合作與交流等方面具有重要意義。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343980</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343980</guid>
            <pubDate>Thu, 03 Apr 2025 07:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「開源 AI 分身」 Second Me 重大更新：Docker 跨平台支持正式上線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Second Me 是一個完全開源的項目，致力於保護你的隱私，幫助每個人構建真正屬於自己的、安全的、本地的 AI 身份。在這裏，你完全掌握數據和智能的主權，僅在你授權下通過安全私密的方式加入網絡，共享信息。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/161959_LOCV_4252687.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，Second Me &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKC37jRcLhhGtUks0uyLqMg&quot; target=&quot;_blank&quot;&gt;宣佈推出首個重大更新&lt;/a&gt;&lt;/u&gt;：Docker 跨平台支持正式上線，讓 Mac (Apple Silicon)、Windows 和 Linux 用戶都能輕鬆一鍵部署。 此外還新增了標準 OpenAI 協議接口、MLX 本地高效訓練能力，以及多項性能優化。&lt;/p&gt; 
&lt;p&gt;具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;全平台 Docker 支持&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Second Me 現已全面支持 Docker 部署，兼容 Mac（Apple Silicon）、Windows 及 Linux，讓用戶隨時隨地輕鬆部署。同時，Docker 版本也修復了 Apple Silicon 用戶此前的環境依賴問題，帶來更順暢的體驗。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI 協議接口&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;全新支持標準 OpenAI 協議接口，無縫接入 VS Code、Notion、ChatBox 等數百款主流 AI 應用。只需將這些 AI 應用的 API 地址指向本地 Second Me。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MLX 訓練支持（Beta）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;充分釋放 Apple Silicon 芯片潛能，支持在 Mac 上高效訓練更大參數的模型，讓你的 Second Me 智能升級。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;性能與穩定性優化&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;訓練日誌細化，提升訓練進度的透明度；增強 embedding 過程中的長文檔處理能力；還有更多優化，等你來體驗！&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmindverse%2FSecond-Me%2Freleases%2Ftag%2Fsnapshot-0407&quot; target=&quot;_blank&quot;&gt;https://github.com/mindverse/Second-Me/releases/tag/snapshot-0407&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343979/second-me-support-docker</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343979/second-me-support-docker</guid>
            <pubDate>Thu, 03 Apr 2025 07:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>美教育部長誤將「AI」稱為「A1」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;外媒&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F10%2Fthe-us-secretary-of-education-referred-to-ai-as-a1-like-the-steak-sauce%2F&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;稱，美國教育部長琳達·麥克馬洪（Linda McMahon）本週出席 ASU+GSV 峯會時，在小組討論過程中多次將「AI」表述為 「A1（A one）」——而 A1 是美國知名的牛排醬品牌。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;337&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a9b5cff08b6b9766abcd4c56582fca4c650.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一開始，McMahon 確實有正確的表述為 AI，但在後面的發言中卻逐漸走偏。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「你知道，AI 的發展--我是説，如果我們沒有最好的技術，怎麼能以光速進行教育呢？我聽説......有一個學校系統將開始確保一年級學生，甚至學前班學生，從低年級開始，每年都有 A1 教學。」&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「不久之前，我們還在説，‘哇，我們的學校要接入互聯網啦’。現在，讓我們看看 A1，看看它能發揮什麼作用。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;就當下的 AI 這無處不在的熱度而言，美國教育部長犯下如此低級的失誤確實令人咂舌。對此，美國教育部沒有立即回應外媒的置評請求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;可在此處查看完整&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2Flxrg28zBv94&quot; target=&quot;_blank&quot;&gt;視頻&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343976/us-secretary-of-education-referred-to-ai-as-a1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343976/us-secretary-of-education-referred-to-ai-as-a1</guid>
            <pubDate>Thu, 03 Apr 2025 07:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Cursor 支付方式新增「支付寶」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;全球最火的 AI 編程工具 ——&amp;nbsp;Cursor 終於接入了「支付寶」，極大地方便廣大開發者在國內進行使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5113170a47623893163436e3bd6c6673f62.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cursor 是一款基於 AI 的代碼編輯器，它不僅能自動補全代碼，還能根據自然語言描述生成代碼、重構優化、解答問題等。目前 Cursor 在全球 AI 編程工具排行榜中位居第一，不僅程序員喜歡，產品經理、設計師等非技術人員也都在用它來快速實現想法。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Cursor 訂閲計劃介紹&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;免費版本&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每月 50 次使用慢速高級模型（GPT-4o、Claude 3.5 Sonnet、Claude 3.7 Sonnet 等），使用完，只能換賬號了。&lt;/p&gt; 
&lt;p&gt;使用限制：每月 2000 次代碼生成。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pro 專業版&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每月 20 美元（摺合人民幣 145￥），年付：192/年（1393￥）&lt;/p&gt; 
&lt;p&gt;高級模型使用：每月 500 次快速使用高級模型（GPT-4o、Claude 3.5 Sonnet、Claude 3.7 Sonnet 等）。&lt;/p&gt; 
&lt;p&gt;無限制：無限次代碼生成。&lt;/p&gt; 
&lt;p&gt;額外功能：每日 10 次使用 o1-mini 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/145728_F9nb_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;詳情：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fcn%2Fpricing&quot; target=&quot;_blank&quot;&gt;https://www.cursor.com/cn/pricing&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343975</guid>
            <pubDate>Thu, 03 Apr 2025 07:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Unity 6 確認將不再向中國用戶提供，包括後續版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;有消息稱在國內的 Unity 官網裏疑似無法正常下載到 Unity 6，取而代之的則是「團結引擎」，該引擎專為中國開發者定製，基於 Unity 2022LTS，致力於滿足中國開發者的獨特需求，結合本土文化元素和市場特色，為創作提供全面支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-38ab8e2c64a2d1febdd35b7d94dc4090cca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日前，Unity 官方正式宣佈，Unity 6 及後續版本將不再向中國用戶提供，相關需求將由團結引擎承接。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;「這一調整旨在確保開發者獲得更貼閤中國市場需求的遊戲引擎服務。」&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1608&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/144956_4ZXL_2720166.png&quot; width=&quot;2460&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.unity.cn%2Fprojects%2F67ee5a4bedbc2a001e9ec5e3&quot; target=&quot;_blank&quot;&gt;&amp;gt;&amp;gt;&amp;gt;官方原文&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據悉，團結引擎將提供&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.unity.cn%2Fprojects%2F67f4fa33edbc2a001ec2d485&quot; target=&quot;_blank&quot;&gt;兩類授權版本&lt;/a&gt;，滿足不同階段開發者的需求，分別為專業版和個人版：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;團結引擎專業版（Pro）：適用於財務規模高於 20 萬美元的專業團隊及企業，需購買專業版 License。&lt;/li&gt; 
 &lt;li&gt;團結引擎個人版（Personal）：財務規模低於 20 萬美元的個人開發者與小型企業免費使用，無需支付基礎 License 費用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Unity 官方表示，在今年，團結引擎將持續升級完善 Unity 6 的部分功能特性，並針對中國用戶需求改進相關渲染功能。「團結引擎已在小遊戲解決方案、OpenHarmony 解決方案、HMI 車機解決方案等領域展現出出色的本地化服務能力，可精準契合中國市場與客戶需求。與此同時，Unity 中國將始終重視開發者意見反饋，重點優化面向中小開發團隊的定價策略，推出更友好的授權方案，持續降低創作門檻。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fa62498ada45f1197d22233d55e1eed706c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;除此之外，Unity 2022 LTS 及更早版本將由 Unity 中國繼續提供支持並持續維護。所有進行中和已經發布的項目均不會受到影響。基於團結引擎創建的項目，可以繼續在全球發佈，不受影響。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;閲讀更多&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/273793/unity-tuanjie&quot; target=&quot;news&quot;&gt;Unity 引擎中國版 ——「團結引擎」開放下載&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/255156&quot; target=&quot;news&quot;&gt;Unity 引擎中國版「團結引擎」正式發佈&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343970</guid>
            <pubDate>Thu, 03 Apr 2025 06:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepMind CEO：谷歌最終將合併 Gemini 和 Veo AI 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌 DeepMind 首席執行官 Demis Hassabis 最近在 LinkedIn 聯合創始人 Reid Hoffman 聯合主持的播客 Possible 上表示，谷歌計劃最終將其 Gemini AI 模型與其 Veo 視頻生成模型相結合，以提高前者對物理世界的理解。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Hassabis 表示：「我們從一開始就將 Gemini 打造成多模式的基礎模型，我們這樣做的原因是我們對通用數字助理這一理念有一個願景，這種助理……能夠在現實世界中真正為你提供幫助。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;331&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5967ab30238c29d43c3a18171cb89ebdfe.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 行業正逐漸走向「全能」模型——可以理解和合成多種媒體形式的模型。谷歌最新的 Gemini 模型可以生成音頻、圖像和文本，而 OpenAI 的 ChatGPT 中的默認模型可以原生創建圖像，包括吉卜力工作室風格的藝術作品。亞馬遜也宣佈計劃在今年晚些時候推出「any-to-any」模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;而這些全能模型需要大量的訓練數據，譬如圖像、視頻、音頻、文本等等。Hassabis 暗示，Veo 的視頻數據主要來自谷歌旗下的平台 YouTube。「基本上，通過觀看 YouTube 視頻--大量的 YouTube 視頻，[Veo 2] 就能瞭解世界的物理原理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌此前曾向 TechCrunch 表示，根據其與 YouTube 創作者的協議，其模型「可能」會使用「部分」YouTube 內容進行訓練。據報道，谷歌去年擴大了服務條款， 部分原因是為了讓該公司能夠利用更多數據來訓練其 AI 模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343969/deepmind-ceo-google-combine-gemini-and-veo-ai-models</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343969/deepmind-ceo-google-combine-gemini-and-veo-ai-models</guid>
            <pubDate>Thu, 03 Apr 2025 06:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Fedora 42 將於下週二發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Fedora 42 已通過批准，將於下週二——4 月 15 日發佈，符合其「早期目標」發佈日期。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e529a58a31023254a2da465d6cc55e3ad8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Fedora 42 最初的目標發佈日期是 4 月 22 日，但今天的「是否進行」會議上，決定 Fedora 42 已經處於良好的發佈狀態。因此，Fedora 42 將在早於最終目標日期發佈。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.fedoraproject.org%2Farchives%2Flist%2Fdevel-announce%40lists.fedoraproject.org%2Fthread%2FRHUWA3SY5D5YAXT4AZ3XQYXW63US4ATD%2F&quot; target=&quot;_blank&quot;&gt;在會議上&lt;/a&gt;&amp;nbsp;，Fedora Linux 42 最終候選版 1.1 構建已獲得「進行」批准。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0411/143657_UJFI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;對於希望開始嘗試 Fedora 42 的用戶，可以通過 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffedoraproject.org%2Fwiki%2FTest_Results%3AFedora_42_RC_1.1_Installation&quot; target=&quot;_blank&quot;&gt;這個 Fedora Wiki 頁面&lt;/a&gt; 獲取 RC 1.1 鏡像。&lt;/p&gt; 
&lt;p&gt;Fedora 42 採用 Linux 6.14 內核、GCC 15 編譯器和默認的 GNOME 48 桌面驅動，並提供了許多新功能。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/339730/fedora-42-beta-now-available&quot; target=&quot;news&quot;&gt;Fedora Linux 42 Beta&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343967/fedora-42-releases-april-15</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343967/fedora-42-releases-april-15</guid>
            <pubDate>Thu, 03 Apr 2025 06:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>PostgreSQL 合併對 NUMA Awareness 的初步支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;PostgreSQL 開源數據庫服務器最近經歷了一系列令人興奮的變化，比如 PostgreSQL 18 合併&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FPostgreSQL-Lands-IO_uring&quot; target=&quot;_blank&quot;&gt;IO_uring 支持&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FPostgreSQL-CRC32C-AVX512&quot; target=&quot;_blank&quot;&gt;AVX-512 加速 CRC32 計算&lt;/a&gt;，可提升高達 3 倍的性能。&lt;/p&gt; 
&lt;p&gt;近日，PostgreSQL 合併了針對&lt;strong&gt;非一致性內存訪問感知能力（NUMA Awareness&amp;nbsp;）&lt;/strong&gt;的初步支持，用於提升多節點/套接字服務器的 PostgreSQL 性能。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1226&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0411/142945_AkzC_2720166.png&quot; width=&quot;1556&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpostgres%2Fpostgres%2Fcommit%2F65c298f61fc70f2f960437c05649f71b862e2c48&quot; target=&quot;_blank&quot;&gt;commit 詳情&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 PostgreSQL 18.0 發佈（預計 9 月）之前，合併到 PostgreSQL Git 中的是基本的 NUMA Awareness。如果使用&quot;--with-libnuma&quot;配置選項構建，目前只提供了 Linux 版本。其他操作系統的 NUMA Awareness 將在後續添加。&lt;/p&gt; 
&lt;p&gt;這項工作是基於去年由微軟工程師 Andres Freund 在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fanarazel.de%2Ftalks%2F2024-10-23-pgconf-eu-numa-vs-postgresql%2Fnuma-vs-postgresql.pdf&quot; target=&quot;_blank&quot;&gt;PGConf EU 演講&lt;/a&gt;中提出的。對於多插槽服務器尤其如此，這種 NUMA 感知能力能夠幫助降低延遲，還可以幫助在更靠近 PCIe 連接的存儲的 NUMA 節點上執行數據庫 I/O，或者更好地處理 CXL 內存周圍的問題。&lt;/p&gt; 
&lt;p&gt;在為 PostgreSQL 添加基本的 NUMA 意識之後，針對&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpostgres%2Fpostgres%2Fcommit%2F8cc139bec34a2971b0682a04eb52ce7b3f5bb425&quot; target=&quot;_blank&quot;&gt;pg_shmem_allocations_numa&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpostgres%2Fpostgres%2Fcommit%2Fba2a3c2302f1248496322eba917b17a421499388&quot; target=&quot;_blank&quot;&gt;pg_buffercache_numa&lt;/a&gt;的一些後續工作也已經落地，這些工作提供了關於共享內存如何在 NUMA 節點之間分配的信息，以及單個緩衝區信息在 NUMA 內存節點上的分佈情況。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/343963/postgresql-lands-numa-awareness</link>
            <guid isPermaLink="false">https://www.oschina.net/news/343963/postgresql-lands-numa-awareness</guid>
            <pubDate>Thu, 03 Apr 2025 06:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>