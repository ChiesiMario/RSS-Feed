<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Wed, 11 Jun 2025 07:44:00 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>開源網盤應用 Alist 原開發者稱項目已交由公司運營</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免費開源、支持多存儲的自建網盤程序 (文件列表程序)，可以輕鬆在 VPS 服務器、NAS、普通電腦 Win、Mac、Linux 上部署。它除了能作為一款自建網盤 (將文件保存在設備硬盤上) 外，最大的特色就是支持「掛載各大主流網盤」。&lt;/p&gt; 
&lt;p&gt;近日，有用戶在該項目 GitHub 倉庫提交 issue，反饋官網出現 404 問題，並提出」項目是否被賣了」的疑問。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原開發者 Xhofe 今日在訂閲頻道發佈公告，&lt;strong&gt;稱項目已交由公司運營&lt;/strong&gt;，之後會幫助審查開源版本倉庫的代碼，確保 release 分支由 CI 自動構建。此外&amp;nbsp;main 分支已開啓分支保護，後續所有提交均需經過 PR 審核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Wed, 11 Jun 2025 07:06:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式發佈了豆包大模型 1.6、豆包·視頻生成模型 Seedance 1.0 pro、豆包·語音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新發布的豆包大模型 1.6 系列由三個模型組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的綜合模型，是國內首個支持 256K 上下文的思考模型，支持深度思考、多模態理解、圖形界面操作等多項能力。支持選擇開啓或關閉深度思考、自適應思考三種方式，其中自適應思考模式可根據提示詞難度自動決定是否開啓思考，提升效果的同時大幅減少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的強化版本；在代碼、數學、邏輯推理等基礎能力上進一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的極速版本，支持深度思考、多模態理解、256K 上下文；延遲極低，TOPT 僅需 10ms；視覺理解能力比肩友商旗艦模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在價格方面，&lt;strong&gt;豆包大模型 1.6 採用統一定價模式，首創按「輸入長度」區間定價&lt;/strong&gt;，在企業使用最多的輸入區間 0-32K 範圍內，豆包大模型 1.6 的價格為輸入 0.8 元/百萬 tokens、輸出 8 元/百萬 tokens，綜合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相當於每生成一條 5 秒的 1080P 視頻只需 3.67 元，行業最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·實時語音模型已全量上線火山方舟，對企業客戶開放使用。該模型支持自然語言高級指令控制，具備唱歌表演、聲線模仿、方言演繹等多種能力，語氣、用語、思考方式等擬人感大幅提升，能隨時打斷與主動搭話。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sun, 11 May 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供為期兩週的免費 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 與 AI 代碼工具開發商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，為 Cline 用戶提供為期兩週的 Grok 3 模型免費訪問權限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用戶只需註冊 Cline 賬戶，即可在 Cline 的提供商中選擇並免費使用 x-ai/grok-3 模型進行編碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是開源 AI 編程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 雙模式，具有終端執行能力和 Model Context Protocol (MCP) 特性。它能夠分析用戶的項目文件結構、源代碼等，幫助用戶創建和編輯文件、執行終端命令、使用瀏覽器進行測試等，還可以通過 MCP 協議擴展其功能，添加自定義工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TickIt：基於 LLM 的自動化 Oncall 升級</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  資料來源：
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-開發者社區&lt;/a&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  軟件工程領域頂級學術會議之一 FSE 2025（The ACM International Conference on the Foundations of Software Engineering）預計將在 2025 年 6 月於挪威特隆赫姆舉行，字節跳動 ByteBrain 團隊的論文《TickIt: Leveraging Large Language Models for Automated Ticket Escalation》成功入選
 &lt;/div&gt; 
 &lt;div&gt;
  （https://arxiv.org/abs/2504.08475）。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  背景
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在雲計算技術蓬勃發展的當下，對於火山引擎來説，工單/Oncall 成為了客戶與技術支持&amp;amp;SRE 團隊溝通的關鍵橋樑。隨着雲服務規模的不斷擴大，每日會產生數以千計的 Oncall。這些 Oncall 通常以自然語言的形式，涵蓋了使用諮詢、功能需求，系統故障等各類複雜問題。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在傳統的手動升級模式下，Oncall 值班人依賴個人經驗判斷工單是否嚴重，進而決定是否應該進一步升級。這一過程很依賴值班人員的經驗判斷，也難以形成統一標準。在過往的案例研究與故障覆盤中，我們發現由於人為疏漏，部分嚴重問題沒有及時升級處理，從而導致了穩定性下降的風險，這也可能對火山引擎的客戶滿意度造成負面影響。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  如何在面對緊急問題時，及時識別並升級這些 Oncall，成為了提升客戶滿意度和保障服務質量的關鍵所在。針對這一問題，我們提出了 TickIt，旨在識別緊急的、報告嚴重問題的 Oncall，並及時地將其升級給產研/穩定性/故障應急等團隊。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  挑戰
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Oncall 問題具有顯著的多樣性，不同類型的問題需由不同專業背景的人員進行處理。例如，系統故障需要產研&amp;amp; SRE 迅速定位並修復，以減少服務中斷時間；客戶投訴以及負面情緒則需要客戶經理及時安撫客戶並解決問題，進而提升客戶滿意度。進一步來説，Oncall 問題還可進一步細分，例如判斷其影響面大小、是否對業務有損等。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  現有的基於特徵工程的分析方法，對 Oncall 內容的語義理解能力也較為有限，在實際應用中難以準確識別關鍵問題，致使重要 Oncall 無法及時升級處理。此外，Oncall 的嚴重程度也可能在對話過程中被（動態地）逐步澄清，而一些現有方法僅進行一次性分類，忽略了對話中不斷更新的信息，無法在線及時識別到需要升級的情況。
 &lt;/div&gt; 
 &lt;div&gt;
  此外，挖掘 Oncall 之間的關係同樣重要。當一個問題影響多個客戶時，會產生多個相似的 Oncall。如果能及時捕獲分析這些 Oncall 之間的關係，有助於更全面地評估問題的嚴重性與影響範圍，而對於產研來説，可以合併這些 Oncall 共同處理，從而更加聚焦地解決問題。
 &lt;/div&gt; 
 &lt;div&gt;
  得益於大語言模型（LLM）在自然語言理解方面的強大能力，我們將其用於輔助理解 Oncall 中的文本信息，但是簡單使用 LLM 並不能真正有效的解決上述挑戰。在本文中，我們提出了基於 LLM 的 Oncall 分析方法 —— TickIt，該方法可以動態追蹤 Oncall 中的信息，還能借助 LLM 深入理解 Oncall 對話的語義內容，及時識別嚴重問題並升級。同時，TickIt 還能挖掘不同 Oncall 問題現象之間的語義關聯，識別潛在的共性問題，實現更高效的問題處理。
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 使用了字節的豆包（doubao）模型，旨在藉助大語言模型（LLM）強大的自然語言處理能力，實現高效、準確的 Oncall 升級任務。該框架主要包含基於多分類的 Oncall 升級（Multi-class escalation）、重複 Oncall 分析 (Escalation deduplication) 和基於類別引導的微調（Category-guided fine-tuning）這三個核心功能模塊。
 &lt;/div&gt; 
 &lt;div&gt;
  基於多分類的 Oncall 升級
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a38b4514cb694357dbd5a996f44a3ba2.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在 Oncall 升級功能中，TickIt 將 Oncall 升級問題視作多分類任務。依據產研&amp;amp; SRE &amp;amp;客戶關係的不同職責和關注重點，預先定義了系統故障、客戶投訴、資產損失等多種主題類別。而對於普通 Oncall，統一歸為 「其他」 類別（無需升級處理）。為使大語言模型更好地完成 Oncall 多分類任務，TickIt 也在 System Prompt 中採用了一些技術來提升其分類表現，例如賦予其任務角色、思維鏈（COT）等。例如，在判斷一個 Oncall 是否屬於系統故障時，模型會分析對話內容中提到的故障現象、影響範圍等因素，並逐步解釋做出該分類決策的原因。這種方式增強了分類結果的邏輯性和可解釋性，讓人們更易理解和信任模型的判斷。此外，TickIt 通過 Few-shot learning，輔助模型理解不同的 Oncall 類別。這些示例特別對易混淆的場景進行了舉例示範，從而幫助模型更準確地區分各類 Oncall 的特徵。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 採用在升級任務中所採用的 System Prompt 格式如下圖所示：
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a83ba70159b8a333261baa7c65e4b07e.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 分析
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//3ded1921020057de79c7cfbcfdbb01bd.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 分析是 TickIt 的另一個功能。當一個 Oncall 被判定需要升級時，TickIt 會對所有處於「Pending」狀態的 Oncall 進行檢查，以確定是否有類似問題已被升級。為此，TickIt 將 Oncall 在其生命週期中的狀態抽象為有限狀態機。當客戶提交 Oncall 工單並被接受後，該 Oncall 對象進入 「Active」 狀態。每當 Oncall 中有新的對話內容時，最新的對話記錄會觸發 TickIt 啓動新一輪分析，此時將其設置為進入 「Analyzing」 狀態。TickIt 會運用上述的基於多分類的升級方法，判斷當前 Oncall 是否需要升級。如果被分類為 「其他」，則其狀態返回 「Active」，等待下一輪對話交互；若被分類為預設好的嚴重問題類型中，則進入 「Pending」 狀態，此時 TickIt 會檢查是否有相似的 Oncall 已經被升級。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在判斷 Oncall 是否重複時，TickIt 首先利用大語言模型提取 Oncall 中的問題描述，並藉助 doubao-embedding model 將這些問題描述轉化為向量表示。通過 consine similarity 來計算向量之間的相似度，並通過一個閾值參數 𝜃 來判斷當前 Oncall 與已升級的 Oncall 是否相似（𝜃 通過參數選擇實驗確認，在本方法中 𝜃=0.88）。對於 TicketIt 判定當前需要升級的 Oncall，如果歷史已有升級且相似的 Oncall，則會將當前 Oncall 與對應的歷史 Oncall 進行關聯，並不再重複告警（僅在關聯工單中體現）。同時，TickIt 會將當前 Oncall 與已重複會利用大語言模型重寫問題描述，從語義上更全面地歸納該類問題的共性特徵，避免因個別 Oncall 工單描述的侷限性而導致對問題的理解偏差。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  基於類別引導的微調
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//9a20ab7d348eaba17524ba79b94e8374.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  類別引導的微調是 TickIt 不斷優化準確率的關鍵機制。當一個 Oncall 按照上述的流程被升級後，TickIt 會發送包含 Oncall 問題摘要的提醒通知卡片。通知卡片中有三個交互按鈕，其中兩個分別用於點贊或點踩；第三個按鈕則是一個 Oncall 跳轉鏈接，點擊後可直接跳轉到相關的聊天羣中。TickIt 則會記錄下這些通知卡片的交互行為作為自動升級的反饋數據。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//74dd763b0ca8e181846e69dffbc00e72.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在處理這些反饋數據時，TickIt 採用監督微調（SFT）方法，一條典型的 SFT 數據同時包含「對話內容」（Oncall 原始信息），「LLM 思考過程與類別判斷」（LLM 的輸出）。並按照 TickIt 用於 Oncall 升級任務的 System Prompt 來進行組織成數據集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  我們對四種反饋動作設置了不同的優先級，以避免同一 Oncall 下存在衝突的反饋。其中直接反饋（點贊、點踩）都會被納入 SFT 的數據集中。根據我們的觀察，相較於正面反饋（點贊）人們通常會在 Oncall 升級錯誤時更傾向提供一些負面反饋（點踩）。因此，點讚的數量要遠小於點踩，也正是出於此原因，我們將點讚的優先級設置為最高（至少有一個人認為該告警是有幫助的）。而對於點踩的反饋來説，通常是認為誤告警，因此則將其目標類別設置為「其它」（如無指定類別説明）。在該情況下，由於僅僅知道目標類別，而缺乏 COT 所需要的推理步驟，TickIt 則利用大語言模型完成目標分類下思維鏈步驟的補充。考慮到思維步驟的多樣性，TickIt 會對每個 Oncall 進行三次可能思維鏈步驟的採樣，以豐富數據集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  通過這種方式，TickIt 能夠處理用戶反饋，並基於類別引導進行數據增強，最終構建出一個高質量的標註數據集。當積累了足夠數量的標註數據後，TickIt 會運用 SFT 方法對模型進行離線優化，然後更新在線模型，從而不斷提升模型在升級分類任務上的性能表現。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 的實驗驗證
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 在火山引擎的線上進行了全面部署，並取得了顯著成效。在此期間，TickIt 共處理了數以萬計的 Oncall。在收到的反饋中，約 81% 的反饋表明 TickIt 的升級決策是準確的，這也證明瞭 TickIt 在實際應用中的有效性和可靠性。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在進一步的 Oncall 升級性能評估方面，我們還對比了基於小語言模型（SLM）和大語言模型（LLM）的多種方法。小語言模型受限於參數規模，其語言理解能力相較 LLM 有較大差距，且部分非端到端的方法設計在信息傳遞過程中易出現信息丟失的情況。而基於 LLM 的方法則展現出了良好的準確率。我們通過消融實驗驗證了不同框架設計對模型性能的影。使用 CoT 的 LLM 方法，準確率和召回率均能達到 82% 左右。在此基礎上，結合反思（Reflection）提示，模型能夠對自身的推理和輸出進行自我糾正，精度略微提升至 82.8%。但由於 CoT 提示已經使模型在得出結論前進行了充分的推理，在反思階段模型難以獲取新的關鍵信息來進一步提高輸出的準確性和洞察力，因此反思技術對實驗結果的提升效果並不顯著。引入上下文學習（ICL）提示後，模型的召回率大幅提升至 89.2%，儘管精度略有下降，但這一結果充分體現了 LLM 方法強大的泛化能力。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//8b040985eb15eb72e4893c729c56be70.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在不同方法設計下的 Oncall 升級比較
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  進一步對 LLM 進行監督微調（SFT）後，模型性能得到了顯著提升。以 CoT 提示為例，微調後的召回率從 82.1% 大幅提高到 91.2%，同時保持了 81.8% 的較高精度，F1 分數達到了 86.2%，在所有對比方法中表現最佳。這一結果有力地證明瞭 SFT 在利用 LLM 能力提升 Oncall 升級任務性能方面的有效性。然而，當 SFT 與其他基於提示的方法（如 Reflection 和 ICL）結合時，性能出現了輕微下降。這可能是因為 SFT 過程中使用了 ICL 中的一些樣本或與訓練數據分佈相似的數據，使得模型在離線微調時已經學習了相應內容，從而在結合使用時產生了一定的衝突。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在重複 Oncall 分析的實驗中，通過調整相似度閾值來探尋最合適的參數，該參數在 0.86 - 0.95 之間時，F1 分數會隨着參數的升高先上升後下降。當其設置過高時，嚴格的相似度約束可能會導致相似問題被錯誤分類到不同類別，使得評估結果中升級 Oncall 的數量相較於真實情況出現偏差，且該偏差與閾值並非單調關係。此外，基於問題現象的去重方法本身存在一定侷限性，對於表現相同但根因不同的 Oncall，可能會出現錯誤去重的情況。而在針對 Oncall 問題重寫的設計中，我們也進行了消融實驗。實驗結果表明，開啓重寫功能的 TickIt 相較於未開啓該功能的實驗設置來説，F1 分數提升了 1.7%。進一步對數據集進行分析，僅保留包含多個關聯 Oncall 的升級進行實驗，結果顯示 TickIt 中的重寫設計使得其 F1 分數從 0.706 提升至 0.749，提升幅度達到 6.1%。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//f44da441270f9c510f3972871725a119.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 識別下的參數選擇實驗
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//685b195201866bfe500add599463e6ee.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Ticket 在重複 Oncall 識別下的問題重寫消融實驗
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  總結與侷限性分析
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 藉助大語言模型實現了高效的自動化 Oncall 升級，為火山引擎帶來了顯著的效率提升。它從「幫助人們及時介入嚴重 Oncall」的角度，幫助火山引擎縮短了嚴重問題的響應時間，使得整體的 MTTR 降低了約 26%，並節約了人力投入成本。同時，TickIt 也得到了使用者的廣泛認可。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  然而，TickIt 在實際應用中也暴露出一些侷限性。對話中（個性化的）表達方式可能會對大語言模型的判斷產生影響。例如，部分使用者可能會誇大問題的影響，導致不必要的升級；而有人也可能對嚴重問題描述過於平淡，使得 TickIt 未能及時識別出需要升級的情況。此外，如果 Oncall 所關聯的雲服務產品不夠具體，相似的問題描述可能會因涉及不同的雲服務產品而具有不同的嚴重程度，這容易導致大語言模型的誤判，進而出現錯誤的升級。我們在後續的工作中會進一步優化 TickIt 的實際效果，助力火山引擎的穩定性工作。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  作者團隊： 我們來自字節跳動的 ByteBrain 團隊，我們致力於用 AI 技術，為各種基礎架構與系統（數據庫、雲原生、大數據、網絡等）降本增效、提升穩定性。
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354786</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354786</guid>
      <pubDate>Sun, 11 May 2025 03:46:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再獲數千萬美元融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣佈再次完成數千萬美元的 Pre-A+輪融資，同時正式發佈了全球首個 AI 驅動的一站式 3D 工作台 Tripo Studio，並即將推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;據稱此次融資將重點投入 Tripo 系列大模型研發及 Tripo Studio 產品及生態平台建設，加速構建「AI+3D」全產業鏈條，打造「基礎模型 + 生態插件 + 原生工作台」的端到端產品體系，從而構建覆蓋專業級（PGC 生產者）、達人級（PUGC 創作者）到大眾級（UGC 用戶）的創作者畫像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，VAST 成立於 2023 年 3 月，是一家專注於通用 3D 大模型研發的 AI 公司，致力於通過打造大眾級 3D 內容創作工具建立 3D UGC 內容平台，使基於 3D 的空間成為用戶體驗升級、內容表達創新和新質生產力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持續迭代 Tripo 大模型，先後推出 Tripo1.0 至 Tripo2.5 等數十億參數規模的 3D 大模型系列，同時發佈 TripoSR、TripoSG、TripoSF 等廣受全球開源社區認可的 3D 基礎模型，並配套開發了系列 3D 軟件生態插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新開源：通用自動骨骼綁定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 開源基礎 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sun, 11 May 2025 03:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 Kendo UI 在實戰應用 —— 打通數據鏈路，重塑業務效率</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在製造與供應鏈行業應用——打通數據鏈路，重塑業務效率" src="https://oscimg.oschina.net/oscnet//009b6caaeed5461884780886e08eac09.jpg" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 在製造與供應鏈行業中，企業通常面對「信息孤島」、「任務難協同」、「實時數據難可視」等挑戰。
 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;作為一套成熟的 Web 界面控件解決方案，憑藉其豐富的組件庫與卓越的數據交互能力，已成為製造系統中構建高效、清晰、可操作用戶界面的有力工具。
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;是帶有 jQuery、Angular、React 和 Vue 庫的 JavaScript UI 組件的最終集合，無論選擇哪種 JavaScript 框架，都可以快速構建高性能響應式 Web 應用程序。通過可自定義的 UI 組件，Kendo UI 可以創建數據豐富的桌面、平板和移動 Web 應用程序。通過響應式的佈局、強大的數據綁定、跨瀏覽器兼容性和即時使用的主題，Kendo UI 將開發時間加快了 50%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行業關鍵痛點與挑戰&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 生產排程混亂，難以動態調整&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;排產表手工維護，任務依賴關係不清晰；&lt;/li&gt; 
 &lt;li&gt;一旦生產任務調整，工序安排需人工同步，極易出錯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 物料與庫存信息分散，數據透明度低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原材料、在製品、半成品和成品數據分佈於不同系統；&lt;/li&gt; 
 &lt;li&gt;缺乏統一視圖，容易導致缺料、積壓或發錯貨。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 設備利用率、產能瓶頸難以量化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;設備運轉狀態、停機時間、工單完成率難以直觀掌握；&lt;/li&gt; 
 &lt;li&gt;管理層缺乏實時運營看板支撐決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多角色協同效率低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;採購、倉儲、生產、質檢等部門使用界面風格不一致；&lt;/li&gt; 
 &lt;li&gt;操作體驗差，培訓成本高，數據流轉阻斷。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Kendo UI 提供的關鍵解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 精準的生產排程與任務可視化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gantt Chart 控件&lt;/strong&gt;：可視化呈現排程計劃，支持任務依賴、拖拽重排、進度條展示，幫助排程人員動態優化排產邏輯。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduler 日曆控件&lt;/strong&gt;：用於設備維護排程或產線預約，支持多資源併發視圖。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 統一的庫存數據展示與交互操作&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Grid + 分組 + 分頁 + 導出功能&lt;/strong&gt;：構建靈活的物料清單、庫存看板，支持層級顯示與動態篩選。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TreeView + PanelBar&lt;/strong&gt;：適用於多倉庫、多區域的庫存結構導航。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AutoComplete / MultiSelect&lt;/strong&gt;：提升物料錄入與搜索效率，防止錯錄錯查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 實時可視化的運營監控&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Charts 圖表組件（柱狀圖、折線圖、圓環圖等）：展&lt;/strong&gt;示各產線設備的稼動率、生產效率、工單完成情況等關鍵指標。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sparkline 小型趨勢圖&lt;/strong&gt;：適用於嵌入表格單元格中，輕量快速展現某項指標走勢。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ProgressBar + KPI 指標塊組合&lt;/strong&gt;：適合構建實時工廠大屏或車間電子看板。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多端一致的界面交互體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;響應式佈局組件（ResponsivePanel / Drawer / TabStrip）：&lt;/strong&gt;適配桌面與平板設備，統一各角色使用體驗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload + Dialog + Tooltip + Notification&lt;/strong&gt;：用於上傳質檢報告、操作提示與反饋，提升人機交互流暢度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;豐富的表單驗證機制&lt;/strong&gt;：確保關鍵業務數據錄入安全、準確。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;應用場景示例&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在製造與供應鏈行業應用——打通數據鏈路，重塑業務效率" src="https://oscimg.oschina.net/oscnet//181f48127f99e600559a7997cf56e624.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;結語&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;在數字化製造轉型的背景下，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;不僅是「界面構建工具」，更是連接業務流程與數據決策的橋樑。它以高可定製、高性能的前端控件能力，為製造與供應鏈行業提供了穩定、高效、專業的用戶交互解決方案。從排程到倉儲、從設備監控到多角色協同，Kendo UI 為企業打造真正可視、可控、可運營的管理界面，助力製造企業邁向數字化高質量發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354778</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354778</guid>
      <pubDate>Sun, 11 May 2025 03:25:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>百度百舸萬卡集羣的訓練穩定性系統設計和實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 訓練穩定性的演進歷程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 競賽中 AlexNet 的橫空出世，開啓了現代 AI 發展的新紀元。彼時我們不會想到，十年後支撐 AI 訓練的 GPU 集羣會從研究室裏的幾台服務器，發展成需要專門供電系統的萬卡級計算矩陣。在這個算力爆發式增長的過程中，訓練系統的穩定性管理正經歷着從「簡單運維」到「精密工程」的深刻變革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 標早期的小模型時代：手動運維的黃金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 訓練，更像是手工作坊式的精雕細琢。大多數訓練任務只需十幾塊 GPU，利用 PyTorch 或 TensorFlow 的數據並行功能就能輕鬆應對。記得那時算法工程師們有個共識：如果訓練遇到問題，重啓往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;當時我們構建的監控系統就像汽車儀表盤，只能顯示最基本的任務狀態。當訓練意外中斷時，工程師們會像偵探一樣翻查日誌 —— 如果發現是 GPU 報錯，就聯繫運維同事。運維人員則帶着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到機房巡檢，像老中醫把脈般通過溫度、功耗等指標判斷硬件狀態。這種工作模式雖簡單，但應對數十卡規模的集羣還算遊刃有餘。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型風暴：從量變到質變的衝擊&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登場如同打開潘多拉魔盒，將 AI 訓練帶入新的紀元。當我們開始部署千卡/萬卡集羣時，才發現原有的運維體系就像用小漁網捕鯨魚 —— 完全無法匹配新需求。&lt;/p&gt; 
&lt;p&gt;讓我們通過百度百舸經歷過的一個真實案例來深入理解這個問題：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸幫助一家 AIGC 創業公司迅速將其訓練規模從百卡擴展到千卡級別。然而在訓練數天後的某個週末凌晨，訓練進程意外發生了 hang 死。由於當時缺乏有效的故障感知和容錯機制，直到第二天算法工程師發現任務超時退出時，已經耽誤了數小時寶貴的訓練時間。更糟糕的是，任務日誌中除了簡單的 timeout 報錯外毫無線索，平台監控也顯示所有訓練節點狀態正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢復訓練的算法工程師沒有立即上報問題，而是選擇直接重新提交任務。但不幸的是，新任務運行數小時後再次出現相同的超時退出。這時他們才不得不尋求技術支持，但值班工程師面對這種任務 hang 死的問題也缺乏診斷經驗，只能通過二分法慢慢定位。最終發現是某個節點的靜默故障（SDC）導致了訓練進程假死。等問題得到解決時，距離首次故障已經過去將近 30 小時，這意味着損失了價值巨大的千卡算力資源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集羣訓練穩定性全景圖&lt;/h1&gt; 
&lt;p&gt;站在現在的時間點回望，AI 訓練穩定性已從輔助功能演變為核心基礎設施。就像現代建築中的抗震結構，它雖不直接參與空間構成，卻是萬丈高樓得以屹立的關鍵。當行業向着數萬卡集羣邁進時，這套隱形護甲的質量，將直接決定 AI 進化的速度與邊界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸對訓練過程的生命週期進行了更細緻的拆分，提出了「無效訓練時間」這一關鍵指標，並致力於將其最小化。具體來説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任務無效訓練時間 = 故障中斷次數 × 任務故障恢復時長 + 任務常態寫 Ckpt 總時長&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任務故障恢復時長 = 故障感知召回耗時（自動/人工定位）+ 任務調度耗時 + 任務初始化耗時 + 任務重算時長。&lt;/p&gt; 
&lt;p&gt;通過這個公式可以看出，要降低無效訓練時間，需要「圍繞基礎設施穩定性」、「任務容錯」兩個維度來系統展開，重點解決三個方面的問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基礎設施的交付質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任務故障容錯的召回率、準確率和時效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化 checkpoint 機制，減少保存時間和恢復時的重算時間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過容錯架構的整體變革，百度百舸形成了從 「任務負載 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基礎架構」全鏈路的自動異常感知、診斷、恢復能力，可覆蓋 90%+ 的訓練異常場景，時效性最快可以實現秒級異常感知、分鐘級定位，以及平均 3 分鐘的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基礎設施交付質量保障&lt;/h1&gt; 
&lt;p&gt;基礎設施的交付質量保障是穩定性的基礎。&lt;/p&gt; 
&lt;p&gt;CPU 時代，機器的交付前可能僅會跑一些常規的 CPU 計算、網絡的壓力測試，並不會從業務視角去評估基礎架構，機器交付後硬件異常的故障頻率相對較少。有硬件故障時，通常走工單系統人工換機用戶相對是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 時代，AI Infra 的交付則需要考慮 CPU、GPU、RDMA 網絡、存儲，甚至機房的功率、溫度等各方面因素，遺漏任何一個環節都會成為後續穩定性的隱患。在交付給客戶後，機器也可能會由於長時間的高負載運行頻繁出現硬件故障，而 GPU 機器的高昂成本，使客戶對節點故障感知、換機的時效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸對 GPU 機器交付前及交付後的穩定性質量進行了系統性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸會對機器進行 200 多項指標檢測，然後進行 48 小時烤機，以及 NCCL-Test 的機內、機間的大環、同號卡通信性能基準測試，端到端的大模型訓練、推理性能基準測試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付後，需要能夠實時的感知節點故障及定期巡檢，並具備分級處理的自愈能力，例如 Error 級別的故障實現自動排水、重啓，Fault 級別故障實現自動換機。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任務容錯的準召率保障&lt;/h1&gt; 
&lt;p&gt;任務層面穩定性最核心的就是做好容錯，能夠讓業務在無論遇到何種故障時都能快速恢復。&lt;/p&gt; 
&lt;p&gt;那麼，首要的工作就是我們能夠準確的識別出異常，然後對故障進行診斷定位，最後能夠自動化的從異常中恢復。&lt;/p&gt; 
&lt;p&gt;因此，任務容錯需要能夠從端側（即每個訓練 worker）探測到進程與環境的各類異常，同時有個中心服務（Master）從任務全局的視角去診斷、定位異常，最終做出相應的決策來使任務能夠快速從異常中恢復。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務容錯最重要的就是提升故障的召回率與準確率，即如何能夠儘可能的準確識別、定位所有故障。我們將故障分類兩類：顯式故障和隱式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;顯式的故障通常比較容易召回，我們將實踐積累的各種進程異常狀態及各類報錯 pattern 形成專家知識庫，再結合硬件感知服務（HAS Agent）的硬件全鏈路 10 秒級監控能力，可以實現顯式故障的召回率達到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隱式的異常則往往很難輕易的識別，例如訓練進程 hang、慢節點就是典型的隱式故障，需要豐富的經驗積累才能準確的識別出異常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我們就以最典型的隱式故障場景 —— 訓練進程 hang 死為例，來看下如何能夠做好 hang 自動感知、診斷。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 訓練****hang 的自動感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;訓練任務發⽣ hang 之後，絕⼤多數情況都會以 timeout 的⽅式報錯並退出進程，最常⻅的就是在通信過程中如果發⽣ hang，NCCL 的 watchdog 會中斷通信，並有報如下 timeout 報錯，然後再由 pytorch 的 torchrun 進程感知並中斷訓練過程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默認為 10 分鐘 NCCL 通信超時，而 Megatron-LM 為 30 分鐘。在萬卡規模訓練場景中，意味着一萬張卡要至少浪費 30 分鐘才能被發現。這個時效性是不可接受的。而且當 30 分鐘超時後程序會立馬退出，很難有機會進行下一步定位，需要一些時效性更高的感知機制，並且在程序退出前獲取一些有效信息供後續診斷分析。&lt;/p&gt; 
&lt;p&gt;很多公司、實驗室在面對 hang 的問題時，會在採用框架層插樁的方式來 trace 訓練進程，這種方式通常是比較直接且準確的，但是有比較強的侵入性，而且可能還會有一些性能開銷。對於雲廠商來説，需要尋找對用戶更透明、更無損的方式來感知、定位 hang 異常。&lt;/p&gt; 
&lt;p&gt;如何感知訓練 hang，以百度百舸的產品設計思路為例，我們可以從以下幾個方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練進程 hang 的最直觀表現是什麼？&lt;/p&gt; &lt;p&gt;人工判斷一個任務是否 hang 了，最直接的方式就是看是否所有 worker 的任務日誌一段時間內都不輸出日誌了，所以 hang 自動感知的第一種方法就是採集所有 worker 的日誌，並判斷所有 worker 日誌中最後一行日誌是否為 x 分鐘前的（x 小於 Pytorch 的通信超時時間，例如 8 分鐘），如果是則基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時進程有什麼樣的表現？&lt;/p&gt; &lt;p&gt;任務 hang 時，可能進程的調用棧都不在發生變化，進程的調用棧可以通過 py-spy/pystack 等工具進行探測，所以我們可以用此類工具對所有訓練任務進行一個定時採樣，當採集 n 個樣本所有進程棧都沒有變化時，可以判定一次 hang，這種方式通常可以將 hang 感知縮小至 3～5 分鐘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時監控指標有哪些變化？&lt;/p&gt; &lt;p&gt;訓練進程中的 CUDA 算子計算、集合通信操作通常都是在毫秒，甚至微秒、納秒內完成的，當任務在正常迭代過程中發生了 hang，我們常遇到的情況是所有 rank 的 RDMA 流量會降到 0，而 GPU 的利用率為 100%、SM 利用率則在很低的水位。如果持續幾分鐘都是這種狀態時，意味着訓練進程已經計算完成，在等着集合通信完成，這種情況下基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信庫中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常單次集合通信操作都是在 ms 級的，如果一次操作在 30 秒鐘都沒有完成，那就可以判定為通信 hang 死了。百度自研的 BCCL 集合通信庫層可以對每一次集合通信操作都進行打點，來實現通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述幾種方法，我們可以分別實現一種探針，來抓取相應的特徵到中心端 master 組件進行下一步診斷和容錯決策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信庫 BCCL 是百度智能雲推出的一款面向大模型訓練場景優化的集合通信庫。&lt;/p&gt; 
 &lt;p&gt;BCCL 基於開源的 NCCL 進行了功能擴展和能力增強，針對大模型訓練場景在可觀測性、故障診斷、穩定性等方面進行優化，進一步提升集合通信庫的可運維能力。相比 NCCL，BCCL 的關鍵特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可觀測性：新增集合通信帶寬實時統計能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障診斷：新增集合通信 hang 時的故障診斷能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;穩定性：增強網絡穩定性和故障容錯能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能優化：提升大模型訓練主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;訓練 hang 的自動診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我們需要進一步的診斷、定位，來確定是否真的發生了 hang，以及 hang 的具體位置。具體的來講，master 收集到各類 agent 的數據後，會做一些綜合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的發生了 hang？&lt;/p&gt; &lt;p&gt;感知階段各種探針只能探測到 hang 的一種特徵，並沒有辦法 100% 的確定是否真的 hang 住了，事實上不侵入用戶進程是很難做到 100% 確定 hang 的。因此，為了提高 hang 的判定準確率，我們需要將各種特種綜合起來判斷，探針上報到 master 後，由一個 hang 診斷模塊，按照一個時間窗口（例如 5 分鐘），進行綜合判斷。如果在時間窗口內日誌、監控、進程調用棧、通信庫中有 2 條以上都處於不處於活躍狀態時，我們判斷任務真正發生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具體發生的位置？&lt;/p&gt; &lt;p&gt;確定任務 hang 了之後，我們需要找到 hang 所在的節點來對它進行隔離。因此診斷模塊需要在探針上報的數據中進一步找尋特徵，來確定 hang 發生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 診斷：在感知階段，BCCL 可以在通信庫層面對所有 rank 的通信進行打點。如果有節點一直未完成通信則是發生了 hang。但是此節點可能並非真正發生 hang 的源頭，有可能是在等待其他節點完成通信。診斷模塊可以根據 BCCL 打印的通信組信息，進行交叉判斷，如果某個節點在多個通信組中都未完成通信，那這個節點就是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指標診斷：上文中我們提到，通信階段發生 hang 之後，所有 rank 的 RDMA 流量都會降到 0，而同時絕大部分 rank 的 GPU 利用率持續為 100%，只有某一兩個 rank 的 GPU 利用率為 0，那這個 rank 很有可能是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調用棧診斷：進程調用棧也可以作為一個 hang 源頭診斷的重要參考。當發生 hang 之後，絕大部分的 rank 都要麼處於 barrier 等待狀態，要麼處於通信等待階段。只有個別的 rank 卡在其他函數上，那麼通過對比分析，可以將調用棧與其他 rank 不同的節點初步判定為 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;綜合診斷：上面 3 種特徵為我們提供了 hang 的診斷依據，將 3 者關聯起來分析後，我們基本上可以比較準確的確定一個具體的 hang 的源頭，再結合硬件故障感知的相關信息可以進一步明確根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基於 eBPF 的隱式故障感知與診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在複雜的大規模分佈式訓練場景中，傳統用戶態監控往往難以捕獲系統內核層面的異常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基於 eBPF（Extended Berkeley Packet Filter）技術的隱式故障感知體系，能夠在不侵入用戶代碼的前提下，對訓練進程的系統調用、網絡通信、CPU 調度等內核態行為以及訓練框架關鍵函數運行時間建立立體觀測能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探針部署原理通過在內核關鍵路徑注入輕量級探針，實現低開銷的系統級行為捕獲。針對訓練場景特點，主要聚焦 4 類事件跟蹤：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練關鍵函數跟蹤：微秒級跟蹤訓練過程中，前向計算、反向計算、集合通信操作等關鍵函數執行耗時，記錄函數間調用關係。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調度阻塞跟蹤：掛鈎 sched_switch 事件，檢測進程在 TASK_UNINTERRUPTIBLE 狀態持續時間，當單次持續超過閾值（如 5 秒）時捕獲調用棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 運行時 API 監控：通過 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等關鍵庫注入探針，記錄 CUDA API 調用耗時分佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 級通信監控：在 ibv_post_send/ibv_poll_cq 等核心通信接口設置觀測點，統計通信時延分佈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;結合上面 4 類事件，完成以下 2 類數據分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單體異常探測基線與實時數據對比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;羣體一致性檢測。採用卡間對比算法，當某一 rank 的以下指標偏離集羣中位數超過閾值時判定異常，包括系統調用頻率、進程就緒隊列等待時長、NVLink/RDMA 帶寬利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上所述方法，百度百舸針對以下 2 類典型的隱式故障進行診斷：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練 hang 根因定位。通過關聯 eBPF 捕獲的多維度數據進行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當檢測到某 rank 的 GPU &amp;nbsp;Kernel 執行出現分鐘級空跑（SM 利用率 &amp;gt; 70% 但無有效計算輸出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同時伴隨該節點 RDMA QP 狀態停滯（ibv_poll_cq 無新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內核調度器顯示進程處於 D 狀態超過閾值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖動溯源。基於 eBPF 火焰圖、時序圖等進行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取發生性能下降時段的 CPU on-cpu/off-cpu 堆棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對比正常時段數據，識別出異常的鎖競爭（futex 調用佔比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結合 NUMA 內存訪問統計，定位跨 NUMA 內存訪問導致的 TLB 顛簸問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此類技術已在百度百舸的萬卡規模訓練集羣中驗證，相比單純依賴應用層監控的方案，將隱式故障的平均檢測時間從分鐘級縮短至秒級，診斷準確率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通過與既有硬件故障感知服務、BCCL 通信庫監測體系聯動，百度百舸形成了覆蓋從硬件到系統內核再到應用層的立體化診斷能力。&lt;/p&gt; 
&lt;h1&gt;05 任務故障恢復的時效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢復的時效性也是容錯能力的一個重要指標，反映的是任務從故障發生到再次重新進入訓練迭代的時間，恢復效率越高則算力浪費越少。影響到任務恢復效率有 2 個重要因素，一是任務平均中斷時間，二是訓練重算時間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多級重啓策略減少故障中斷時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任務發生異常後，上文中我們提到需要經過故障自動感知、診斷和自愈等 3 個環節，那麼減少中斷時間的核心思想，就是儘可能的縮短這 3 個環節的時間，通過多維度的感知、診斷手段可以將故障發現、定位的時效性降低至分鐘級甚至秒級。自愈則需要能夠根據不同的診斷結果進行分級恢復和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單點顯式故障：重調度異常節點（replace），對節點進行集羣級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;單點隱式故障：重調度異常節點，對節點進行任務級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非單點故障：原地重啓嘗試恢復（restart），無法恢復時重新調度所有節點（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過多級重啓策略，儘可能避免單點故障引發全部節點的重新調度。在萬卡級別的訓練場景中，百度百舸將大部分訓練異常場景恢復時間從過去的 30min 縮短至現在的 30s 內，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;觸發式 checkpoint 減少訓練重算時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多級任務重啓策略外，另一個提高任務故障恢復效率的重要手段就是減少訓練重算時間。在探討具體技術方案之前，我們先來看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;傳統的 checkpoint 保存通常採用固定間隔策略，比如每隔 N 個 step 或每隔 T 小時保存一次，這種方式實現簡單但缺乏靈活性，可能會產生大量冗餘存儲，同時在故障發生時可能會損失較多訓練進度。&lt;/p&gt; 
&lt;p&gt;而觸發式 checkpoint 則是一種更智能的方案，它根據特定條件或異常事件（如故障、顯存不足、顯式指令等）動態觸發模型狀態保存。其核心目標是通過靈活的控制保存時機，減少不必要的存儲開銷和訓練中斷時間，從而降低因頻繁或冗餘保存導致的重算時間浪費。&lt;/p&gt; 
&lt;p&gt;隨着大模型訓練規模的擴大，還有一種更激進的「零重複 checkpoint」技術，即在每個訓練 step 都保存一次 checkpoint。這種方案的優勢在於可以將重算時間降到最低，確保故障發生時能夠從最近的 step 恢復，幾乎不會損失訓練進度。但其顯著的缺點是存儲開銷巨大，即使採用增量式存儲，仍然需要相當大的存儲空間和 I/O 帶寬。此外，頻繁的 checkpoint 操作也可能影響訓練性能。&lt;/p&gt; 
&lt;p&gt;相比之下，觸發式 checkpoint 走的是一條平衡之路。我們來看下它實現的幾個核心要點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容錯：訓練進程集成容錯的故障感知與定位機制，在進程退出前自動觸發保存。這種主動感知機制能夠在故障發生的第一時間保存訓練狀態，最大限度減少進度損失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速轉儲：異步 checkpoint 保存機制會將 checkpoint 暫存到共享內存中，再由外部程序轉儲至磁盤。當某個節點異常時，容錯組件會拉起新節點，並在新節點訓練進程啓動前，利用 RDMA 技術實現 checkpoint 快速從故障節點轉儲至新節點，這大大減少了從遠程存儲拉取 checkpoint 的時間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗餘備份：觸發式 checkpoint 也並非完美無缺，例如在節點發生內核 crash 等嚴重故障時，可能無法觸發自動保存。因此，需要通過定期的冗餘備份機制進行兜底，確保 checkpoint 不會完全丟失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實踐表明，當觸發式 checkpoint 與異步、增量式的 checkpoint 機制結合使用時，可以在保證數據安全性的同時，顯著提高 checkpoint 保存效率，減少訓練重算時間。&lt;/p&gt; 
&lt;p&gt;相比零重複 checkpoint 的重型方案，觸發式 checkpoint 提供了一個更實用的折中方案，在合理的存儲開銷下實現較好的容錯效果。當然，具體選擇哪種方案，還需要根據實際的訓練規模、硬件條件和可用資源來權衡。&lt;/p&gt; 
&lt;p&gt;隨着分佈式訓練規模的持續增長，相信未來會出現更多創新的 checkpoint 方案，比如基於預測的主動保存策略、多級存儲架構的智能調度等，這些都將為提高大規模訓練的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 業務發展對穩定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 訓練的穩定性管理已經演變為智能時代的精密工程。從最初靠人工重啓解決問題的摸索階段，到如今能自動感知異常、快速恢復的智能系統，每一次進步都映照着算力規模的跨越式發展。&lt;/p&gt; 
&lt;p&gt;讓人不禁思考，在未來十萬卡集羣的算力洪流中，或許會出現更精妙的動態平衡方案：既能像鷹隼般敏鋭捕捉故障徵兆，又能如雁羣遷移般智能調度資源，在秒級恢復與 PB 級存儲成本之間找到新的平衡支點。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持廠內千卡和萬卡集羣有效訓練時長已經可達 99.5%，為客戶大模型的預訓練保駕護航，比如國內第一個數學大模型——九章算術，國內第一個類 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增強語義嵌入的模型算法綜述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持續推進「人工智能＋」行動，百度智能雲+DeepSeek 為何成為國有企業首選？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 雲服務器的軟件系統設計和實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基於 Flink 的配置化實時反作弊系統&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能雲 xDeepSeek，最具性價比的 DeepSeek 一體機合集來了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 發佈開放權重模型貢獻榜：Qwen 與 DeepSeek 躋身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;發佈&lt;/a&gt;開放權重模型貢獻榜，中國團隊 Qwen 和 DeepSeek 成功入圍前 15 名。該榜單表彰為開源社區提供高質量模型權重的團隊，其模型廣泛應用於學術與產業創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴雲智能集團支持的 Qwen 團隊，以 Qwen3 系列模型在指令跟隨、代碼生成等任務中的優異表現受到社區青睞。Qwen2.5-72B 系列位列開源大語言模型前列，其輕量化模型 QwQ-32B 通過強化學習優化，在數學推理和代碼生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 則以低成本、高性能的 R1 系列模型聞名。R1-0528 在 LiveCodeBench 排行榜中超越多個國際競品，僅次於 OpenAI 頂尖模型。其輕量化版本 DeepSeek-R1-0528-Qwen3-8B 通過知識蒸餾技術，單 GPU 即可運行，在 AIME2025 數學測試中擊敗 Google 的 Gemini2.5Flash，展現了在特定領域的競爭優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中國 AI 團隊在開源生態中的崛起。Hugging Face 負責人表示，兩團隊的貢獻為全球開發者提供了高效資源。NVIDIA 首席執行官黃仁勳也讚揚其性能與成本平衡正在重塑 AI 格局。未來，Qwen 計劃探索多模態技術，DeepSeek 則將推出 R2 模型，持續推動 AI 創新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sun, 11 May 2025 02:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Android 16 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌發佈了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為今年的第一次大版本升級，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按鍵式導航（三大金剛）的預測性返回手勢&lt;/li&gt; 
 &lt;li&gt;強制通知分組&lt;/li&gt; 
 &lt;li&gt;以進度為中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 設備的桌面模式（開發者選項）&lt;/li&gt; 
 &lt;li&gt;低功耗藍牙聽力輔助設備支持&lt;/li&gt; 
 &lt;li&gt;自定義鍵盤快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截圖優化&lt;/li&gt; 
 &lt;li&gt;以舊換新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性詳細介紹查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sun, 11 May 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 DevExpress WPF v24.2 新版亮點：報表等組件功能升級</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF 擁有 120+個控件和庫，將幫助您交付滿足甚至超出企業需求的高性能業務應用程序。通過 DevExpress WPF 能創建有着強大互動功能的 XAML 基礎應用程序，這些應用程序專注於當代客戶的需求和構建未來新一代支持觸摸的解決方案。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;控件近期全新發布 v24.2，此版本進一步升級了網格、報表、地圖等組件的功能，歡迎下載最新版體驗！&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346%2Fdownload" target="_blank"&gt;DevExpress WPF v24.2 正式版下載&lt;/a&gt;&lt;/strong&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Grid（網格）控件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多單元格編輯&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;Microsoft Excel 允許您選擇多個單元格並通過按 Ctrl + Enter（替代 Enter）應用文本更改，DevExpress WPF Grid 控件中添加了一個類似的特性，允許用戶同時對多個單元格應用相同的值。要啓用此功能，將&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.DataControlBase.SelectionMode" target="_blank"&gt;GridControl.SelectionMode&lt;/a&gt;設置為 Cell，將&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.TableView.MultiCellEditMode%3Fv%3D24.2" target="_blank"&gt;GridControl.MultiCellEditMode&lt;/a&gt;設置為 FocusedColumn/AllColumns。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 產品圖集" src="https://oscimg.oschina.net/oscnet//a590e16b5907853d6c754e5c5bc46b88.gif" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;PDF Viewer&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;獲取在頁面縮略圖面板中選擇的頁面&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;PdfViewer.GetSelectedThumbnailPageIndexes&lt;/a&gt;方法允許您獲得在 Page Thumbnails 面板中所選頁面的索引，可以在 DevExpress PDF Viewer 中提取、刪除或導出選定的頁面。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfViewerControl.ActualThumbnailsViewerSettings%3Fv%3D24.2" target="_blank"&gt;PdfViewerControl.ActualThumbnailsViewer&lt;/a&gt;屬性來訪問實際的縮略圖查看器設置，並調用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;GetSelectedThumbnailPageIndexes&lt;/a&gt;方法來獲取頁面索引。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;下面的示例將在頁面縮略圖面板中選擇的 PDF 文檔的頁面保存為圖像：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;&lt;em&gt;C#&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;using System.Windows.Media.Imaging;
using System.IO;
// ...
private void simpleButton_Click(object sender, RoutedEventArgs e) {
// Obtains the selected page indexes.
var pages = viewer.ActualThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes();
// Saves each page from the collection to an image.
foreach (var i in pages) {
BitmapSource image = viewer.CreateBitmap(i, 1000);
PngBitmapEncoder encoder = new PngBitmapEncoder();
encoder.Frames.Add(BitmapFrame.Create(image));
using (var fileStream = new FileStream($"..\\MyBitmap{i + 1}.bmp", FileMode.Create)) {
encoder.Save(fileStream);
}
}
}&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Reporting（報表）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WPF 報表設計器 - 維度符號&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;為了簡化報表設計過程，此更新在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;報表設計器中引入了維度符號。當您調整控件的大小時，設計器會提供精確的視覺反饋，並根據指定的 ReportUnit 屬性值（如英寸、釐米或像素）顯示維度符號。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 產品圖集" src="https://oscimg.oschina.net/oscnet//b1ccdc0e972820bc31dddac86cddd3d6.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;要管理符號的可見性，請使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FXtraReports%2FDevExpress.XtraReports.Configuration.UserDesignerOptions.ShowDimensionNotations%3Fv%3D24.2" target="_blank"&gt;UserDesignerOptions.ShowDimensionNotations&lt;/a&gt;屬性。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;地圖組件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 Azure 地圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF MapControl 現在可以顯示 Microsoft Azure 地圖數據，使用 AzureMapDataProvider 提供程序獲取光柵圖像磁貼。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;注意&lt;/strong&gt;：在使用 Azure Maps 時，您必須閲讀並理解 Microsoft 的使用條款：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fpricing%2Fdetails%2Fazure-maps%2F" target="_blank"&gt;https://azure.microsoft.com/en-us/pricing/details/azure-maps/&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354762</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354762</guid>
      <pubDate>Sun, 11 May 2025 02:36:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 推遲開源模型的發佈時間</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席執行官山姆·奧特曼宣佈，原計劃於今年初夏發佈的公開權重的開源模型預計&lt;strong&gt;將推遲至夏末發佈&lt;/strong&gt;，而不是 6 月與公眾見面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究團隊做了一些出乎意料且非常令人驚奇的事情，這非常值得等待，但需要更長的時間。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣佈將發佈自 GPT-2 以來的首個「開源」語言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最強」開源模型，計劃今年初夏發佈&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首個推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣佈推出&lt;/a&gt;其首個推理模型系列 Magistral，採用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高數學和物理等主題的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有兩種版本：Magistral Small 和 Magistral Medium。Magistral Small 擁有 240 億個參數，在 Apache 2.0 協議下開源。Magistral Medium 是一款功能更強大的模型，目前已在 Mistral 的 Le Chat 聊天機器人平台、該公司的 API 以及第三方合作伙伴雲平台上提供預覽。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中寫道：「Magistral 適用於各種企業用例，從結構化計算和程序邏輯到決策樹和基於規則的系統。這些模型針對多步驟邏輯進行了微調，提高了可解釋性，並以用戶的語言提供了可追溯的思維過程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立於 2023 年，該公司得到了 General Catalyst 等風險投資機構的支持，迄今已籌集超過 11 億歐元（約合 12.4 億美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;儘管 Mistral 資源雄厚，但在某些領域，例如推理模型開發，Mistral 仍落後於其他領先的人工智能實驗室。從 Mistral 自身的基準測試來看，Magistral 似乎也並非一款特別有競爭力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 測試中，Magistral Medium 的表現不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的編程基準 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或許正因如此，Mistral 在其博客文章中大力宣揚 Magistral 的其他優勢。聲稱 Magistral 在 Le Chat 中提供答案的速度是競爭對手的「10 倍」，並且支持多種語言，包括意大利語、阿拉伯語、俄語和簡體中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的發佈是在 Mistral 推出「vibe coding」客戶端 Mistral Code 之後。在此之前的幾周，Mistral&amp;nbsp;推出了幾款專注於編碼的模型，並推出了 Le Chat Enterprise，一項面向企業的聊天機器人服務，提供 AI 代理構建器等工具，並將 Mistral 的模型與 Gmail 和 SharePoint 等第三方服務集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 發佈 o3-pro：更強大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;發佈&lt;/a&gt;了 o3-pro 推理模型，基於 o3 所打造，擁有更強的數學、科學、編程等領域的表現。&lt;/p&gt; 
&lt;p&gt;據介紹，o3-Pro 可，自動調用多種工具，包括可以搜索網頁、分析文件、推理視覺輸入、使用 Python、通過記憶功能個性化回覆等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由於調用的工具較多，所以，思考的時間比 o1 Pro、o3 更長。&lt;/strong&gt;o3-pro 與 o3 系列一樣擁有 200K 的上下文窗口和 100K 的輸出，但價格卻比它們暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表現上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在專家評估中，評審人員普遍認為 o3 Pro 在多方面都比 o3 模型更進一步，尤其適合用在科學、教育、編程、商業和寫作這些需要深度輸出的任務中。&lt;/li&gt; 
 &lt;li&gt;在學術評估的基準測試中，o3-pro 的整體表現持續優於 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 還通過四次嘗試獲取正確答案的方式進行實驗發現，o3-pro 能保持較好的性能表現。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用戶提供，取代 o1-pro；企業版和教育版用戶將在下週獲得使用權限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;價格方面，o3-pro 輸入為 20 美元/百萬 token，輸出 80 美元/百萬 token；而 OpenAI CEO Sam Altman 昨晚宣佈，o3 降價 80%——因此 o3 價格來到了輸出 2 美元/百萬 token、輸入 8 美元/百萬 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>基於 KubeSphere 平台快速搭建單節點向量數據庫 Milvus</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;pre&gt;title: 基於 KubeSphere 平台快速搭建單節點向量數據庫 Milvus🔥
date: 2025-6-10
categories:
  - Milvus
tags:
  - Milvus
  - KubeSphere
sticky: 1
&lt;/pre&gt; 
&lt;h2&gt;&lt;span&gt;KubeSphere 是什麼&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;KubeSphere 是一個在 Kubernetes 之上構建的、以應用為中心的多租戶容器平台，完全開源，由社區驅動與開發 1&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fdocs%2Fv3.3%2Fintroduction%2Fwhat-is-kubesphere%2F" target="_blank"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv3-2.docs.kubesphere.io%2Fzh%2F" target="_blank"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。它提供全棧的 IT 自動化運維能力，旨在簡化企業的 DevOps 工作流，並幫助企業快速構建強大且功能豐富的容器雲平台。功能強大、易用性高的開源 Kubernetes 容器雲 PaaS 平台，能夠幫助企業快速構建、管理和運維雲原生應用，提升 DevOps 效率，降低運維複雜度，適用於各類規模的企業和團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;如何快速通過可視化界面搭建項目數據庫 Milvus&lt;/span&gt;&lt;/h2&gt; 
&lt;blockquote&gt;
 &lt;span&gt;採用 K8s 平台，可以通過鏡像網站：&lt;/span&gt;
 &lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocker.aityp.com%2F" target="_blank"&gt;https://docker.aityp.com/&lt;/a&gt;&lt;/span&gt;
 &lt;span&gt; 下載必須的鏡像，etcd、milvus、minio。使用時需要確定下載鏡像對應宿主機處理器的版本進行下載不然無法成功運行鏡像容器。&lt;/span&gt; 
 &lt;p&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c754d0ca9fdc8a050815a6137811fdf9.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;本次搭建的宿主機處理器為 amd 架構因此下載時需要篩選對應的架構版本鏡像下載&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//591be48c48ba52898104243fc8d3e713.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 etcd 中間件&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;本次採用 etcd 國內鏡像地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/etcd:3.5.5-0&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//bd887c8668f3812cbbcb0d5de70e1b2a.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;需要對啓動命令進行專門配置：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;/usr/local/bin/etcd&lt;span style="color:#8d8df0"&gt;,--name&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;etcd-0&lt;span style="color:#8d8df0"&gt;,--data-dir&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;/var/lib/etcd&lt;span style="color:#8d8df0"&gt;,--listen-client-urls&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;http://0.0.0.0:2379&lt;span style="color:#8d8df0"&gt;,--advertise-client-urls&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379&lt;/span&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;span&gt;對上述指令進行詳細解釋：&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/usr/local/bin/etcd&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;這是 etcd 可執行程序的路徑，表示啓動 etcd 服務。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--name=etcd-0&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;為當前 etcd 節點指定一個名稱，集羣內唯一，便於管理和識別節點&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://monchickey.com/post/2023/09/24/etcd-cluster-installation/"&amp;gt;&amp;lt;span&amp;gt;2&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--data-dir=/var/lib/etcd&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 數據存儲的目錄，所有鍵值數據、集羣狀態和元數據都保存在這裏&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://monchickey.com/post/2023/09/24/etcd-cluster-installation/"&amp;gt;&amp;lt;span&amp;gt;2&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--listen-client-urls=&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://0.0.0.0:2379/"&amp;gt;&amp;lt;span&amp;gt;http://0.0.0.0:2379&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 監聽客戶端請求的地址和端口，&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;0.0.0.0&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 表示監聽所有網絡接口，客戶端可以通過任意 IP 訪問本節點的 2379 端口&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://cloud.tencent.com/developer/article/1644574"&amp;gt;&amp;lt;span&amp;gt;7&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;如果不配置，默認只監聽本地迴環地址 (&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;127.0.0.1:2379&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;)，外部客戶端無法訪問。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--advertise-client-urls=&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379/"&amp;gt;&amp;lt;span&amp;gt;http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 向集羣其他成員和客戶端通告的客戶端訪問地址，通常使用集羣內部域名或固定 IP，便於其他節點和客戶端正確連接&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://cloud.tencent.com/developer/article/1644574"&amp;gt;&amp;lt;span&amp;gt;7&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://www.zhaowenyu.com/etcd-doc/command/etcd.html"&amp;gt;&amp;lt;span&amp;gt;8&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;如果不配置，客戶端和其他節點可能無法正確連接到本節點，導致集羣通信異常&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置完成之後直接等待容器啓動即可，etcd 服務不需要配置額外的對外暴露&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 minio 中間件&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;採用的國內鏡像源地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/minio/minio:RELEASE.2025-04-22T22-12-26Z&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;直接使用默認的容器鏡像端口即可&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//369f954eee41419e62c2558f218ebf46.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;啓動命令的詳細概述&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;span&gt;命令&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;/bin/sh,-c&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;&lt;span&gt;參數&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;minio server /data &lt;span style="color:#7575e4"&gt;--console-address&lt;/span&gt; :9090&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;對上述命令的詳細解釋：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;在 Kubernetes（k8s）中配置 MinIO 時，常見的啓動命令形式如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;command: [&lt;span style="color:#d26b6b"&gt;"/bin/sh"&lt;/span&gt;, &lt;span style="color:#d26b6b"&gt;"-c"&lt;/span&gt;, &lt;span style="color:#d26b6b"&gt;"minio server /data --console-address :9090"&lt;/span&gt;]&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/bin/sh, -c 的作用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;在 Kubernetes YAML 中，&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;command&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 字段默認是直接執行命令，但如果命令比較複雜（如需要環境變量、管道、重定向等），直接寫命令字符串會被解析為單個命令參數，導致執行失敗。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;使用 &amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;/bin/sh -c&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 可以讓 Kubernetes 把後面的字符串整體作為 Shell 腳本執行，支持更多的 Shell 語法和變量替換。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;minio server /data --console-address :9090&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;/data&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是 MinIO 的數據目錄，必須指定。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;--console-address :9090&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 顯式指定 Console 端口，確保 Web 管理界面可以通過固定端口訪問，便於暴露服務和調試.&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c17c8150b20a21c9f3d6a22a17620ef6.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 milvus 向量數據庫&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;採用的國內鏡像源地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/milvusdb/milvus:v2.5.9&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;下述兩處端口指定時參考官方文檔的 docker-compose 文件，進行配置，嘗試過多種鏡像都不能出現如上述兩個中間件一樣的使用默認鏡像端口按鈕&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c7c51b72e1c85d13c6449a2c151f1f77.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;配置對應的系統名稱和環境變量&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置完成需要暴露對外端口&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//545b48d79ab09b97a9b1a741ebb97da0.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span&gt;命令&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;/tini,--&lt;/span&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;span&gt;參數&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;milvus,run,standalone&lt;/span&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;span&gt;環境變量 k-v 值&lt;/span&gt;&lt;/h4&gt; 
&lt;table cellspacing="0" style="--tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-ring-color:rgb(59 130 246 / .5); --tw-ring-offset-color:#ffffff; --tw-ring-offset-shadow:0 0 #0000; --tw-ring-offset-width:0px; --tw-ring-shadow:0 0 #0000; --tw-rotate:0; --tw-scale-x:1; --tw-scale-y:1; --tw-scroll-snap-strictness:proximity; --tw-shadow-colored:0 0 #0000; --tw-shadow:0 0 #0000; --tw-skew-x:0; --tw-skew-y:0; --tw-translate-x:0; --tw-translate-y:0; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; break-inside:auto; cursor:text; margin:0px; max-width:100%; overflow:auto; text-align:left; white-space:pre-wrap; width:1140px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th style="vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
   &lt;th style="vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;dev-etcd-shanghai.dev-shanghai:2379&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#474d54; border-style:solid; border-width:1px; vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;MINIO_ADDRESS&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#474d54; border-style:solid; border-width:1px; vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;dev-minio-shanghai.dev-shanghai:9000&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;span&gt;上述命令的詳細解釋&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;在 Kubernetes (K8s) 中啓動 Milvus 時，命令行中常見的啓動命令格式是：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;/tini &lt;span style="color:#7575e4"&gt;--&lt;/span&gt; milvus run standalone&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;這裏各部分的作用如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 是一個小型的 init 進程，常用於容器環境中作為 PID 1 進程，負責正確地處理信號轉發和殭屍進程回收，保證容器內的主進程（這裏是 Milvus）能優雅啓動和退出。它不是 Milvus 自身的命令，而是容器啓動時的輔助工具，確保 Milvus 進程管理更穩定。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;--&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;這是一個常見的命令行參數分隔符，告訴 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 後面的參數不是給 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 本身的，而是傳遞給後面的程序（即 &lt;/span&gt;&lt;span&gt;&lt;code&gt;milvus&lt;/code&gt;&lt;/span&gt;&lt;span&gt;）的參數。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;milvus run standalone&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;這是啓動 Milvus 的命令，其中：&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;run&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是 Milvus 的啓動命令，表示啓動 Milvus 服務。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;standalone&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是指定啓動模式，表示以單機模式啓動 Milvus，即所有 Milvus 的組件（rootcoord、datacoord、querycoord、indexcoord、proxy 等）都在一個進程或節點上運行，而不是分佈式多節點模式。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;根據 Milvus 源碼和啓動邏輯分析，&lt;/span&gt;&lt;span&gt;&lt;code&gt;milvus run standalone&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 命令會觸發 Milvus 啓動所有核心組件，適合開發測試或資源有限的場景。如果不配置或不使用該命令，Milvus 將不會啓動任何服務組件，容器內 Milvus 進程不會運行，服務不可用&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.tencent.com%2Fdeveloper%2Farticle%2F2407241" target="_blank"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;如果省略 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt;，容器內進程可能無法正確處理信號和回收子進程，導致容器退出時不能優雅關閉 Milvus，可能出現殭屍進程或信號處理異常。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;如果不加 &lt;/span&gt;&lt;span&gt;&lt;code&gt;run standalone&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 參數，Milvus 不知道要啓動哪個組件或以何種模式啓動，默認不會啓動服務，或者會打印幫助信息並退出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置環境變量不用多説就是需要指定好中間件地址，不然訪問不了。為什麼配置上述的 url 前綴，我已 etcd 為例進行解釋：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//33a19fcf5d350da350d15948336bb35f.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;完成上述配置就基本完成，最後部署一個 Milvus 可視化管理工具&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 attu&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;部署這個沒啥特別需要説明的直接配置鏡像然後暴露對外服務進行訪問即可&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//feb400cc4e5baa1a0b232801621439cc.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署完成效果展示&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6119250747a3aa776bf0407722900dc1.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;總結&lt;/span&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;上述配置沒有配置數據卷掛在因此不適合生產環境使用&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;單點節點配置也不是很規範&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354695</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354695</guid>
      <pubDate>Sat, 10 May 2025 13:35:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>微軟開始測試 Windows 11 的新版「開始」菜單</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟現在&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F06%2F09%2Fannouncing-windows-11-insider-preview-build-26200-5641-dev-channel%2F" target="_blank"&gt;允許&lt;/a&gt;&lt;/u&gt; Windows 11 測試人員試用全新、更大的「開始」菜單，該菜單包含可滾動的界面、新的視圖和更多可自定義功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-133f02d0def812a3023b1918667ec4cbb4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows Insider 團隊解釋説：「我們更新了可滾動的「開始」菜單，讓您可以更輕鬆地啓動應用。」 這個可滾動的「開始」菜單意味着所有應用現在都位於頂層，因此您無需導航到第二個頁面即可找到應用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95c628f3783c80a5c0be69c6167b9d9f144.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更新後的「開始」菜單有兩個新視圖可供選擇&lt;/p&gt; 
&lt;p&gt;您還可以禁用推薦部分，以便查看更多應用，並選擇兩種新視圖：類別視圖和網格視圖。默認類別視圖按類別對應用進行分組，而網格視圖則按字母順序排列，更像傳統的列表視圖。&lt;/p&gt; 
&lt;p&gt;微軟還根據設備或顯示器的屏幕尺寸放大了「開始」菜單。Windows Insider 團隊表示：「在較大的設備上，用戶可以在「開始」菜單中看到 8 列固定應用、6 條推薦和 4 列類別。在較小的設備上，你將看到 6 列固定應用、4 條推薦和 3 列類別。」&lt;/p&gt; 
&lt;p&gt;開始菜單上還新增了一個移動設備按鈕，可用於展開或摺疊與開始菜單一起顯示的「Phone Link」界面。微軟還允許 Windows 11 用戶選擇顯示哪些鎖屏小部件，允許添加或刪除小部件，並重新排列它們以適應鎖屏。&lt;/p&gt; 
&lt;p&gt;最後，最新的 Dev Channel 版本還包含一個新的 Gamepad 鍵盤更新，可讓您使用控制器通過 PIN 碼登錄 PC。這是微軟改進 Windows 11 在手持遊戲設備（例如最近發佈的 ROG Xbox Ally 設備）上的運行效果的一部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美團發佈 AI Coding Agent 工具「NoCode」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;美團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdByPiajMM7fX109GSotLVQ" target="_blank"&gt;上線&lt;/a&gt;了名為「NoCode」的&amp;nbsp;&lt;/span&gt;AI Coding Agent 工具&lt;span&gt;，用戶通過自然語言對話即可生成網頁、小程序等應用，並支持實時修改、一鍵部署。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;NoCode 是一款無需編程背景和經驗，通過自然語言和對話形式，即可快速生成應用的平台。可幫助不同角色以"零代碼"的方式創建個人提效工具、產品原型、可交互頁面等，降低開發門檻，實現創意釋放。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;NoCode&lt;/span&gt;功能亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自然語言編程&lt;/strong&gt;：使用自然語言描述想法，NoCode 自動解讀並轉化為完整功能，無需編程經驗即可生成可用能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;實時預覽效果&lt;/strong&gt;：根據對話內容即時渲染、呈現頁面，可實時查看每次對話後的實際效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;局部定位修改&lt;/strong&gt;：使用 Visual Edit 功能，可針對定位內容進行局部修改及完善；同時支持版本間對比、回退，保障每一步都「有跡可循」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一鍵部署分享&lt;/strong&gt;：應用完成後，代碼將自動上傳到倉庫，可直接分享鏈接給他人使用，簡化發佈流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0610/184826_5IfE_2720166.png" width="750" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;體驗地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnocode.cn%2F" target="_blank"&gt;https://nocode.cn/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354675/meituan-nocode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354675/meituan-nocode</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>法國 AI 初創公司 Mistral 將發佈推理模型 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F06%2F10%2Fmicrosoft-backed-ai-lab-mistral-debuts-reasoning-model-to-rival-openai.html" target="_blank"&gt;根據 CNBC 的報道&lt;/a&gt;，法國 AI 初創公司 Mistral 將推出其首個推理模型 Magistral，加入與 OpenAI、DeepSeek 等全球領先企業的競爭。&lt;/p&gt; 
&lt;p&gt;&lt;img height="898" src="https://static.oschina.net/uploads/space/2025/0610/183614_pyVq_2720166.png" width="2104" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mistral 首席執行官亞瑟・門施介紹道，Magistral 不僅擅長數學和編碼，還能夠實現歐洲語言的邏輯推理，突破了美國和中國模型的語言侷限性。&lt;/p&gt; 
&lt;p&gt;今年 3 月，Mistral 已發佈 240 億參數的 Mistral Small 3.1 模型，該模型以低成本實現本地運行，部分性能甚至超越 OpenAI 的 GPT-4o mini。5 月，Mistral 進一步推出了 Medium 3 模型，這款中量級模型在保持前沿性能的同時，顯著降低了企業使用成本，每百萬 Token 輸入僅需 0.4 美元。&lt;/p&gt; 
&lt;p&gt;Mistral 通過技術創新，正逐步提升其在全球 AI 市場的競爭力，併為多語言應用場景提供更優解決方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</guid>
      <pubDate>Sat, 10 May 2025 10:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度網盤、文庫聯合發佈「AI 相機」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;6 月 10 日，在百度 AI Day 開放日上，百度網盤、文庫聯合發佈行業首個「拍存管一體」的「AI 相機」，具備全模態輸入、處理、輸出的系統化完整交付 AI 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-acb055f53ca9b3a5f087e132e834b1d7f25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 相機已在百度網盤 App 上線，並已接入百度文庫 App。百度文庫還宣佈多智能體協作能力「GenFlow 超能搭子」全新升級為 2.0 版本，使其成為率先實現全場景滿足、全鏈路覆蓋的多智能體協作應用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/183107_JyHR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GenFlow 超能搭子 2.0 依託於文庫、網盤海量的公私域數據和用戶記憶庫，可完整交付更懂用戶的個性化內容；它可以自主調用各種模型和工具，一次性並行生成多模態、多格式內容；它還支持後鏈路的編輯環節，在內容創作上靈活度更高。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354672</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354672</guid>
      <pubDate>Sat, 10 May 2025 10:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 時代的「數據之困」，什麼是 AI-Ready Data</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;人工智能（AI）無疑是當今科技領域最激動人心的變革力量，它橫跨各個行業，展現出重塑未來的巨大潛力。從智能客服到精準醫療，從自動駕駛到個性化推薦，AI 的觸角幾乎無所不至。然而，在這股 AI 浪潮之下，一個普遍的困境也日益凸顯：許多雄心勃勃的 AI 項目在起步後便步履維艱，難以實現預期的投資回報，甚至大量試點項目最終未能成功轉化為生產力。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;這種「雷聲大，雨點小」的現象，不禁讓人深思：&lt;strong&gt;AI 的理想與現實之間，究竟橫亙着怎樣的鴻溝？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;追根溯源，這一困境的核心往往直指 AI 的「食糧」——數據。數據是驅動 AI 系統洞察、預測和決策的燃料。然而，企業在將數據應用於 AI 時，普遍面臨着一系列嚴峻挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;數據質量參差不齊&lt;/strong&gt;：不準確、不完整、標籤錯誤或充滿噪聲的數據是 AI 項目失敗的常見元兇。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E5%25AD%25A4%25E5%25B2%259B%26zhida_source%3Dentity" target="_blank"&gt;數據孤島&lt;/a&gt;&lt;/span&gt;與集成難題&lt;/strong&gt;：數據往往散落在企業內部各個孤立的系統中，格式各異，難以有效整合和統一訪問。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;缺乏標準化與有效治理&lt;/strong&gt;：數據格式不統一、元數據缺失、數據血緣關係不清晰以及&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E6%25B2%25BB%25E7%2590%2586%26zhida_source%3Dentity" target="_blank"&gt;數據治理&lt;/a&gt;&lt;/span&gt;機制的薄弱，都為 AI 應用埋下了隱患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;這些普遍存在的數據問題，實際上反映了許多企業在 AI 戰略上的一個深層錯位：即，&lt;strong&gt;對 AI 技術本身抱有極高期望，卻忽視了構建堅實數據基礎的重要性&lt;/strong&gt;。企業紛紛投入巨資採購先進的 AI 工具和算法，但如果供給這些「智能引擎」的是劣質「燃料」，那麼再強大的算法也難以發揮其應有的效能。AI 的雄心壯志與薄弱的數據能力之間形成的巨大反差，正是導致眾多 AI 項目折戟的關鍵。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面對 AI 時代的「數據之困」，企業迫切需要一種能夠有效解決上述問題、真正釋放 AI 潛能的數據形態。於是，「AI-ready Data」 的概念應運而生。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;什麼是 AI-ready Data？為何如此重要？&lt;/strong&gt;&lt;/h2&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//be5fce4d40a25157514e64dbd6664171.jpg" width="1024" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data：超越數據的「數據」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data，顧名思義，是指那些經過精心準備、結構化處理和嚴格驗證，能夠以最佳效能服務於人工智能應用的數據。這類數據使得 AI 算法能夠高效地學習模式、做出準確預測並生成有價值的洞察。它強調的不僅僅是擁有海量數據，更在於數據的質量、結構和相關性，確保數據能夠被 AI 算法高效處理和分析。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;打個比方，如果説 AI 是一個高性能引擎，那麼 AI-ready Data 就是為其量身定製的、經過提純的高辛烷值燃料，確保引擎能夠以巔峯狀態持續運轉。它不是原始、未經雕琢的「數據礦石」，而是經過精煉、可以直接投入 AI「熔爐」的「高品位原料」。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data 不可或缺的價值&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 之所以關鍵，在於它能為 AI 的成功應用帶來一系列實實在在的好處。高質量、準備充分的數據是訓練出高精度、高可靠性 AI 模型的基礎，直接決定了模型的準確性和有效性，正所謂「Garbage in, Garbage out」。通過大幅減少數據科學家在數據清洗和整理上耗費的巨量時間，AI-ready Data 能夠顯著加速 AI 項目的落地進程，使團隊更專注於模型創新與優化。它是構建穩健、可擴展 AI 系統，使其能處理複雜任務並大規模有效運作的基石，最終通過驅動更明智決策、提升運營效率、降低成本和增強市場競爭力，為企業創造切實的商業價值。同時，清晰、可溯源且管理良好的數據還有助於企業遵守日益嚴格的數據法規與 AI 倫理規範，為 AI 系統的透明度和問責制提供保障。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;理解 AI-ready Data 的價值，更要認識到它並非一勞永逸的靜態目標，而是一個持續演進的動態過程，需要隨 AI 發展、業務變化及法規更新不斷調整優化，其及時性、可擴展性和定期刷新的需求都印證了這是一項長期投入。追求 AI-ready Data 的本質，是將數據管理從單純的「收集」提升到戰略性的「策展」與「價值創造」層面，要求企業帶着明確的 AI 應用目標有意識地準備數據，使數據管理從後端支持轉變為驅動創新的核心環節。更深遠地看，實現數據 AI 就緒的努力將催化組織在數據治理、數據素養和跨部門協作等方面的全面成熟，打破數據孤島，提升整體數據能力，從而孕育出惠及企業全局的數據驅動文化，這其中，人的因素和流程優化與技術平台同等重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;不同領域的 AI-ready Data 特徵上有什麼區別？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;儘管 AI-ready Data 的核心原則具有普適性，但在不同的 AI 細分領域，其具體的形態、準備的側重點以及在模型訓練和推理階段的要求，都會呈現出顯著的差異。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;機器學習中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;傳統的機器學習是許多企業 AI 應用的起點，其對數據的要求相對成熟和明確。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：ML 模型的數據通常是結構化的表格數據，例如 CSV 文件或數據庫中的表，其中每一行代表一個樣本，每一列代表一個特徵。對於監督學習任務，數據中還會包含一個目標列或標籤列，用以指示模型需要預測的結果 。雖然 ML 也可以處理文本、圖像等非結構化數據，但這往往需要通過複雜的特徵工程將其轉換為結構化的數值特徵，才能被傳統 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：ML 模型的數據通常是結構化的表格數據，例如 CSV 文件或數據庫中的表，其中每一行代表一個樣本，每一列代表一個特徵。對於監督學習任務，數據中還會包含一個目標列或標籤列，用以指示模型需要預測的結果 。雖然 ML 也可以處理文本、圖像等非結構化數據，但這往往需要通過複雜的特徵工程將其轉換為結構化的數值特徵，才能被傳統 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：用於預測客戶流失的數據集，可能包含客戶的人口統計信息、消費行為、服務使用頻率等特徵；用於垃圾郵件檢測的已標註郵件數據集。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//3911ebe7c46166407d1fad003e28b19d.jpg" width="600" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;深度學習中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;深度學習以其處理複雜模式和大規模數據的能力，在圖像識別、自然語言處理等領域取得了革命性進展，其對數據的需求也更為「貪婪」。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：深度學習模型的訓練通常依賴於大規模的非結構化以及多模態數據，如圖像、音頻、文本和視頻。這些數據往往需要進行大量且精準的標註，例如物體檢測任務中的邊界框、圖像分割的掩碼、語音識別的文本轉錄等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：數據的「量」和「多樣性」是深度學習成功的關鍵。同時，標註的一致性和準確性對模型性能至關重要，高質量的數據集是實現準確語音識別等任務的基礎。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：著名的 ImageNet 數據集包含數百萬張標註圖像；LibriSpeech 數據集包含數千小時的轉錄音頻；維基百科的文本轉儲等大型文本語料庫。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//22383fbb9f6e44994f6c4a867cb18fce.jpg" width="700" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E7%2594%259F%25E6%2588%2590%25E5%25BC%258FAI%26zhida_source%3Dentity" target="_blank"&gt;生成式 AI&lt;/a&gt;&lt;/span&gt;與 RAG 系統中的 AI-Ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;具體到生成式 AI 領域，其對 AI-ready data 的需求首先體現在模型預訓練和微調階段。基礎模型的構建依賴於規模宏大、內容多樣甚至多模態的數據集，涵蓋了從公開網頁文本、專業書籍到代碼、圖像和音視頻等廣泛來源。而模型的微調則更側重於特定領域內高質量、高相關性的專業數據集。貫穿始終的是對數據合規性、版權以及潛在偏見的嚴格審視與倫理考量，負責任的數據策略是實現 AI 價值的前提。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在眾多生成式 AI 應用中，檢索增強生成（RAG）架構尤為依賴 AI-ready data 的精細化準備。RAG 通過引入外部知識源來提升模型輸出的準確性、時效性和深度，其核心挑戰在於如何將這些外部知識高效、準確地「喂」給 LLM。這一過程的關鍵瓶頸與優化焦點在於數據切片（Chunking）。當前主流的數據切片方法往往顯得「粗糙」。許多系統簡單地採用固定字符數、按句子或段落等規則進行切分，這種方式極易破壞文本原有的語義完整性，可能導致一個完整的邏輯思路或上下文聯繫在切分中斷裂，進而影響大模型對信息的準確理解和答案生成的質量。同時，這些簡單方法常常忽略文檔的內在結構，如章節、標題、列表和表格等，而這些結構本身就承載着重要的語義信息。面對不同類型（如法律合同、技術手冊、研究論文或代碼）和複雜格式的文檔，通用的「一刀切」切片策略往往難以達到理想效果。切片的大小也需精妙平衡：過小則可能上下文不足，難以支撐複雜問答；過大則可能引入過多噪聲，稀釋關鍵信息。此外，多數在數據預處理階段完成的靜態切片，也缺乏對用戶動態查詢意圖的靈活適應性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;因此，理想的 RAG 數據切片策略應向更智能化、語義驅動的方向演進。其核心目標是&lt;strong&gt;最大程度地保持語義單元的完整性&lt;/strong&gt;，切分點應儘可能選在自然的語義邊界。同時，要充分感知並利用文檔的固有結構信息，如將標題及其對應內容作為一個單元，或整體處理表格及其註釋。為了保持切分後各知識塊之間的上下文連貫，可以採用重疊切片技術，或構建具有內在聯繫的層級式塊結構，並通過元數據明確記錄它們之間的邏輯關係。針對不同內容特性，應採用內容自適應的切片邏輯。至關重要的是，每個切分後的數據塊都應附帶豐富的元數據，如原始文檔出處、章節信息、主題標籤等，這些元數據不僅能提升檢索的精確度，還能為大模型提供更全面的背景知識，從而增強其輸出內容的可信度和可溯源性。&lt;/p&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f2fb964dde666532d21ce8a16e7310fe.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DPhysical%2BAI%26zhida_source%3Dentity" target="_blank"&gt;Physical AI&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Physicla AI，如機器人和自動駕駛系統，需要在複雜的物理世界中進行感知、決策和行動，其數據需求具有獨特性和挑戰性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;訓練數據&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：來自多種傳感器的融合數據，包括激光雷達的點雲數據、攝像頭的圖像/視頻流、雷達信號、慣性測量單元數據、GPS 定位信息、觸覺傳感器數據等。此外，還包括機器人的關節狀態、運動軌跡、與環境的交互數據，以及大量來自模擬環境的合成數據。這類數據通常是時間序列數據，需要精確的時間同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：要求數據能夠高保真地復現真實世界的物理特性和動態變化，覆蓋多樣化的環境條件（如不同天氣、光照）、複雜的交互場景和罕見的邊緣案例。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：自動駕駛領域的&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DWaymo%2BOpen%2BDataset%26zhida_source%3Dentity" target="_blank"&gt;Waymo Open Dataset&lt;/a&gt;&lt;/span&gt;、&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DnuScenes%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%26zhida_source%3Dentity" target="_blank"&gt;nuScenes 數據集&lt;/a&gt;&lt;/span&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;推理數據&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形態&lt;/strong&gt;：來自機器人或車輛上搭載的各種傳感器的實時、連續的數據流。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特徵&lt;/strong&gt;：數據處理的低延遲性對於物理 AI 系統做出及時、安全的決策和行動至關重要。系統還需要對傳感器噪聲、數據丟失或遮擋等情況具有魯棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f6effd68cabc43be465afc81f71a66c4.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;審視這四大 AI 領域對數據的需求演變，可以發現一個清晰的趨勢：AI 模型對數據的「胃口」越來越大，要求的數據集規模日益龐大，多樣性和複雜性也與日俱增。從機器學習對結構化數據的依賴，到深度學習對海量非結構化數據的渴求，再到生成式 AI 對網絡規模多模態數據的吞噬，以及 Physical AI 對高維、多傳感器融合數據的整合，無不體現了這一趨勢。這種趨勢意味着，數據的「AI 就緒」不僅關乎數據本身的質量和形態，也對底層的數據存儲、處理和管理技術平台提出了更高的要求。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;打造 AI 的堅實基礎：通往 AI-ready Data 之路&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;將原始數據轉化為 AI-ready Data，是一項涉及多個步驟的持續性系統工程，而非一蹴而就的任務。這需要隨着 AI 技術、業務需求和數據源的變化而不斷演進和優化，是一個動態的、持續改進的過程。一個典型的數據準備流程始於數據收集與獲取，即從多樣化的內外部來源彙集原始數據，&lt;strong&gt;尤其值得強調的是，在 AI 時代，企業自身積累的、獨特的內部數據是構建差異化競爭優勢和深化護城河的核心戰略資產，對其的有效盤活與利用是首要任務。&lt;/strong&gt;隨後是數據清洗與預處理，旨在識別並修正原始數據中的錯誤、不一致、缺失值和重複項，以提升數據質量。接着進行數據轉換與豐富，將數據轉化為適合 AI 模型的格式，可能包括特徵工程、數據聚合，並通過添加元數據等方式增強數據上下文。對於監督學習任務，準確的數據標註是不可或缺的一環。在數據投入訓練之前，需進行嚴格的數據驗證與質量保證。最後，貫穿整個數據生命週期的是數據治理與安全，要求企業建立清晰的管理政策，確保數據合規、安全。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 並非遙不可及的理想概念，而是成功且可靠的人工智能應用的堅實基石。正如高質量原材料是優質產品的先決條件，高質量的 AI-ready Data 是構建高性能 AI 模型的根本保障，&lt;strong&gt;特別是當這些數據源自企業內部，承載着特定業務洞察和運營經驗時，其轉化為 AI 洞察的能力，將直接賦能企業構建難以複製的競爭壁壘。&lt;/strong&gt;它能夠顯著提升模型的準確性和可靠性，加速 AI 應用的研發部署，並最終驅動商業價值和創新突破。因此，企業應將提升數據就緒水平，尤其是內部數據的「AI 就緒」水平，視為一項戰略要務，而非項目啓動後的被動補救。通往 AI 驅動的創新之路，很大程度上是由對自身獨特數據資產的深度挖掘和高質量準備鋪就的。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;擁抱 AI-ready Data，意味着正視數據的挑戰，投入必要資源，建立完善的流程和文化，核心目標在於充分釋放企業內部沉澱數據的潛在價值。這無疑是一項艱鉅的任務，但其回報——通過人工智能洞察自身運營、優化決策、創新產品與服務，從而在市場競爭中佔據領先地位——將是無可估量的。生成式 AI 並非短暫趨勢，而是一場深刻的變革，而適配這種變革的數據基礎設施和數據就緒能力，&lt;strong&gt;特別是將企業獨有的內部數據轉化為驅動 AI 的優質燃料的能力，將是企業在這場變革中深化護城河、立於不敗之地的關鍵。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354670</guid>
      <pubDate>Sat, 10 May 2025 10:26:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>RWKV 2025 生態內容徵集大賽 | 5 月投稿作品及評審結果</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;大家好，我們在 2024 年底推出了 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」，公開徵集 RWKV 相關的作品，包括但不限於 RWKV 相關的論文、講解 RWKV 的教程，以及基於 RWKV 的應用等。&lt;/p&gt; 
&lt;p&gt;2025 年 5 月，活動共收到 RWKV 生態作品投稿 &lt;strong&gt;2 份&lt;/strong&gt;，包括 &lt;strong&gt;1 篇論文、1 個教程&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文將公佈 2025 年 5 月的活動投稿作品及評審結果。&lt;/p&gt; 
&lt;h2&gt;評審結果&lt;/h2&gt; 
&lt;h3&gt;評審結果省流版&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名稱&lt;/th&gt; 
   &lt;th&gt;作品分類&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初評獎項&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/td&gt; 
   &lt;td&gt;論文&lt;/td&gt; 
   &lt;td&gt;biomems&lt;/td&gt; 
   &lt;td&gt;銀獎（2888 元）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-V7 模型解析與實戰：架構原理、機制剖析及自定義微調模型效果展示&lt;/td&gt; 
   &lt;td&gt;教程&lt;/td&gt; 
   &lt;td&gt;坤&lt;/td&gt; 
   &lt;td&gt;參與獎&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下面是「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生態內容徵集大賽&lt;/a&gt;」 5 月投稿獲獎的作品介紹。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;論文類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.11165" target="_blank"&gt;https://arxiv.org/abs/2505.11165&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：biomems&lt;/li&gt; 
   &lt;li&gt;獲獎類型：銀獎（2888 元）&lt;/li&gt; 
   &lt;li&gt;項目介紹：論文提出了一種新的異步到同步框架 EVA，用於實時事件相機數據處理&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;該框架基於 RWKV-6 構建了高效的異步編碼器，實現了逐事件的表示更新，並採用自監督學習方法獲得具有高度泛化能力的事件表示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Maximizing Asynchronicity" src="https://oscimg.oschina.net/oscnet/up-3ca302b9d83762576c1d83a5c2add0e09c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;教程類&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-V7 模型解析與實戰：架構原理、機制剖析及自定義微調模型效果展示&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F1904346608985944244%3Fshare_code%3D1nLMwML5XPvsB%26utm_psn%3D1904552110802055283" target="_blank"&gt;https://zhuanlan.zhihu.com/p/1904346608985944244?share_code=1nLMwML5XPvsB&amp;amp;utm_psn=1904552110802055283&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：坤&lt;/li&gt; 
   &lt;li&gt;獲獎類型：參與獎&lt;/li&gt; 
   &lt;li&gt;項目介紹：從原理解析到微調實踐的全流程教程&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;首先帶領初學者一起初步理解 RWKV 架構，然後使用 RWKV-PEFT 微調倉庫進行了全流程的微調並展示了微調效果，在學習原理的同時，微調屬於自己的 RWKV。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="RWKV-V7 模型解析與實戰" src="https://oscimg.oschina.net/oscnet/up-0c74d7e4f003a4e0322e3aee4c8f3e90ec4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;獎品/獎金髮放規則&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;實物獎品（RWKV 周邊等）&lt;strong&gt;以&lt;/strong&gt;順豐快遞&lt;/strong&gt;方式發出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;獎金&lt;/strong&gt;以&lt;strong&gt;轉賬或第三方線上平台&lt;/strong&gt;等方式發放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情況下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;領取獎金，團隊內部&lt;strong&gt;自行協商分配獎金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿與獎項升級&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均會獲得&lt;strong&gt;評審意見&lt;/strong&gt;。請根據評審意見優化你的作品，然後可&lt;strong&gt;再次投稿以升級獎項&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;獎項成功升級時，我們將補發&lt;strong&gt;前後兩個獎金的差價&lt;/strong&gt;。例如投稿作品從鐵獎（888 元）升級到銀獎（2888 元），則補發 2888-888=2000 元獎金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活動海報&lt;/strong&gt;，歡迎各位轉發！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e11c3df39730d4d504ca57e04f84ed60f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活動最終解釋權歸元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354657</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354657</guid>
      <pubDate>Sat, 10 May 2025 09:42:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
  </channel>
</rss>
