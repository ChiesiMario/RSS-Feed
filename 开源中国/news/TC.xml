<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 07:37:41 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>IntelliJ IDEA 2025.1 現已發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IntelliJ IDEA 2025.1 現已發佈。此版本的亮點包括全面支持 Java 24、引入 Kotlin Notebook 以及默認啓用的 K2 模式。JetBrains AI 也進行了重大升級，將 AI Assistant 和 Junie 整合到一個訂閲中。調試支持也更加強大，新增了暫停和恢復 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch evaluations&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;的選項。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6ae0e40b28c0cd39a5b26f67c3f6de9fd1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains AI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在此版本中，所有 JetBrains AI 功能均可在 IDE 中免費使用，部分功能（包括代碼補全和本地模型支持）可無限使用，其他功能則需根據信用額度進行限制。還推出了全新的訂閲系統，可根據需要輕鬆擴展 AI Pro 和 AI Ultimate 兩個等級。此版本的亮點包括更智能的補全、高級上下文感知以及對 Claude 3.7 Sonnet 和 Gemini 2.0 Flash 的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;主要亮點&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025.1 版本全面支持 Java 24 版本中的所有功能，確保用戶在享受最新語言更新的同時獲得流暢的體驗。欲瞭解更多信息，可閲讀此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F03%2Fjava-24-and-intellij-idea%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在此版本中，K2 模式默認啓用，這標誌着新版本在增強 IntelliJ IDEA 中 Kotlin 開發的代碼分析、內存效率和整體性能方面邁出了重要的一步。活躍用戶已經體驗到了更流暢的工作流程，項目團隊計劃繼續解決未解決的問題，改進重構和檢查，並根據反饋進一步提升質量。瞭解更多信息，可閲讀此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fk2-mode-in-intellij-idea-2025-1-current-state-and-faq%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;現在可以在調試期間暫停和恢復 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch evaluations&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以控制 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch computations&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;的潛在副作用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kotlin Notebook 是專為 JVM 開發者打造的全新交互式環境，現已成為 IntelliJ IDEA 的內置功能。Kotlin Notebook 非常適合各種任務，從實時原型設計、演示、日誌解析、文檔編寫，到深入的數據分析和可視化，應有盡有。欲瞭解更多信息，可閲讀此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fkotlin-notebook-arrives-in-intellij-idea%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fintellij-idea-2025-1%2F&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/345039/jetbrains-ides-go-ai&quot; target=&quot;_blank&quot;&gt;JetBrains 宣佈推出 AI 工具免費套餐&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345083/intellij-idea-2025-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345083/intellij-idea-2025-1-released</guid>
            <pubDate>Thu, 17 Apr 2025 06:49:12 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Spark on K8s 在 vivo 大數據平台的混部實戰</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在離線混部可以提高整體的資源利用率，不過離線 Spark 任務部署到混部容器集羣需要做一定的改造，本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在離線業務差異&lt;/h1&gt; 
&lt;p&gt;互聯網數據業務服務一般可以分為在線服務和離線任務兩大類，在線服務是指那些長時間運行、隨時響應對實時性要求高、負載壓力隨着接收流量起伏的服務，如電商、遊戲等服務，離線任務是指運行週期短、可執行時間提交對實時性要求低、有一定容錯性、負載壓力基本可控的服務，如離線計算任務、模型訓練等。一般在線服務在白天時段繁忙，離線任務在凌晨繁忙，兩者的業務高峯期存在錯峯現象，如果按傳統方式在線和離線都是分別獨立機器部署，業務高峯時期需要更多機器來支持，業務低峯期又存在部分機器空閒，整體資源利用率都不高。因此行業提出來在離線混部的解決方案，在線和離線業務通過混部系統部署在同一批機器，實現共享資源並錯峯互補，提高整體的資源利用率。目前業內利用混部技術可以將數據中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生產也已經將部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;混部系統需要有強大的隔離能力，絕大部分都是基於容器，所以混部的前提是在線和離線業務都容器化，對於容器管理工具如 K8s 來説是更適應於運行時間長、啓停次數少、容器數量少的在線服務，在線服務也能比較容易地上容器，而對於運行時間短、啓停頻繁、容器數量大的離線任務，對 K8s 來説不是天然地適應，但容器化已是大勢所趨，K8s 也推出了性能更好的調度器、用於離線任務的控制器，Spark 在 2.3 版本後也支持容器化，諸多技術的發展也推動離線任務實現容器化以及在離線混部的落地。&lt;/p&gt; 
&lt;p&gt;本文將從在離線混部中的離線任務的角度，講述離線任務是如何進行容器化、平台上的離線任務如何平滑地提交到混部集羣、離線任務在混部集羣中如何調度的完整實現以及過程中的問題解決。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、離線任務容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案對比&lt;/h3&gt; 
&lt;p&gt;vivo 離線任務大部分任務是以 Spark 作為執行引擎，Spark 任務運行在 K8s 上，目前業界有兩種架構的方案：Spark on K8s 及 Yarn on K8s。兩者部分優缺點對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接創建 Driver 和 Executor 的 Pod 來運行 Spark 作業，Yarn on K8s 是 Yarn 的容器化，由 K8s 創建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 運行在 NM Pod 的 container 中，正是由於兩種架構方案的區別，它們各自也會存在優缺點。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它僅需要創建一定數量的 NodeManager Pod 來滿足作業需求，Pod 運行相對穩定因此對 K8s 的壓力比較小，本身 Yarn 支持調度性能和調度策略也是專門為離線任務設計的，調度性能比 K8s 的強很多。由於 NodeManager ESS 服務是對磁盤有容量和讀寫性能要求的，混部機器的磁盤一般難以滿足，所以也需要能支持不同引擎的 Remote Shuffle Service。在資源利用上，NodeManager 需要滿足多個作業的資源，最小單位是 Container，Pod 的資源粒度比較大，自身也會佔用一些資源，如果資源粒度得不到有效地彈性伸縮，也會造成資源的浪費，因此需要引入額外的組件來協調,根據 Kubernetes 集羣節點的剩餘資源，動態調整 NodeManager 的 CPU 和內存，然而這也需要一定的改造成本。在資源緊張的情況下，NodeManager Pod 如果被驅逐也就意味着整個 NodeManager 被銷燬，將會影響多個任務。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要頻繁的創建、查詢、銷燬大量的 Executor Pod，對 K8s 的 ApiServer 和 ETCD 等組件都會造成比較大的壓力，K8s 的調度器也不是專門為離線的大批量任務設計的，調度性能也比較弱。另一方面，Spark on K8s 雖然只能支持 Spark3.X 的 RSS，不過目前有較多的開源產品可選擇。在資源利用上，最小單位是 Driver 和 Executor 的 Pod，資源粒度小，可以填充到更多的碎片資源，調度時直接與 K8s 對接，資源的彈性調度更多由 K8s 來承擔，不需要額外的組件，改造成本比較低。在資源緊張的情況下，Executor、Driver 的 Pod 將依次逐個被驅逐，任務的穩定性會更高。&lt;/p&gt; 
&lt;p&gt;而對於 Spark on K8s 方案，還細分 2 種實現方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark 官網)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架構圖&lt;/p&gt; 
&lt;p&gt;(圖片來源：Spark Operator 開源項目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集羣是 Spark 在 2.3 版本後提供的原生功能，客戶端通過 spark-submit 設置 K8s 的相關參數，內部再調用 K8sApi 在 K8s 集羣中創建 Driver Pod，Driver 再調用 K8sApi 創建需要的 Executor Pod，共同組成 Spark Application，作業結束後 Executor Pod 會被 Driver Pod 銷燬，而 Driver Pod 則繼續存在直到被清理。使用 spark-submit 方式的最大好處是由 spark-submit 來與 K8s 的進行交換，提交作業的方式幾乎保持一致。但是因為使用的便利性所需要的封裝也會帶來一些缺點，spark-submit 是通過 K8sApi 創建 Pod，使用非聲明式的提交接口，如果需要修改 K8s 配置就需要重新開發新接口，二次開發複雜繁瑣，雖然 Spark 提供了大量的 K8s 配置參數，但也遠比不了 K8s YAML 的聲明式的提交方式更加靈活，而且 Spark Application 和 K8s Workload 的生命週期還不能較好地對應起來，生命週期不能靈活控制，任務監控也比較難接入 Prometheus 集羣監控。雖然 Spark 社區也不斷地在推出新特性來和 K8s 集成地更加靈活，不過對於些複雜場景需要定製開發，spark-submit 的封裝性也會成為阻礙。&lt;/p&gt; 
&lt;p&gt;spark-submit 還是離線任務提交的思維，而 Spark Operator 方式就更傾向於 K8s 作業的思維，作為 K8s 的自定義控制器，在集成了原生的 Spark on K8s 的基礎上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用聲明式的 YAML 提交 Spark 作業，並提供額外組件來管理 Spark 作業的生命週期，SparkApplication 控制器，負責 SparkApplicationObject 的創建、更新和刪除，同時處理各種事件和作業狀態，Submission Runner, 負責調用 spark-submit 提交 Spark 作業，Driver 和 Executor 的運行流程是一致的，Spark Pod Monitor，負責監控和同步 Spark 作業相關 Pod 的狀態。Spark Operator 最大的好處是為在 K8s 中的 Spark 作業提供了更好的控制、管理和監控的功能，可以更加緊密地與 K8s 結合並能靈活使用 K8s 各種特性來滿足複雜場景，例如混部場景，而相對地它也不再像 spark-submit 那樣方便地提交任務，所以如何使用 Spark Operator 優雅提交任務將是在離線混部中一項重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最終選項&lt;/h3&gt; 
&lt;p&gt;在大的架構選型上，我們選擇了 Spark on K8s，一方面因為 Spark3.X 是 vivo 當前及未來 2~3 年的主流離線引擎，另一方面 vivo 有比較完善的 K8s 生態體系，內部對 K8s 研發也比較深入，環境和能力都能很好地支持，在應用的小方向上，我們選擇了 Spark Operator，因為它在混部這種複雜場景下使用更加靈活、擴展性更強、改造成本更低，我們最終決定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 優化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 鏡像&lt;/h3&gt; 
&lt;p&gt;Spark 任務容器化的第一步就是構建具有 Spark 相關環境的鏡像，Spark 任務類型主要分為 sql 任務和 jar 任務，在實踐的過程中我們發現 Spark 的鏡像構建需要&lt;strong&gt;注意幾個問題&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 環境的完整性&lt;/strong&gt;：鏡像中除了打入自研的 Spark 包以外，還需要打入相應的依賴如 Hadoop、ZSTD、RSS 等包，對於 SparkJar 任務還有直接調用 Hadoop 客戶端的，因此 Hadoop 客戶端也需要打入鏡像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本問題&lt;/strong&gt;：K8s 使用的 Spark 是基於 3.2.0 版本，鏡像打包工具默認使用 JDK11，而自研的 Spark 用的 JDK1.8，由於在 Yarn 和 K8s 上使用的 JDK 版本不同，導致在雙跑驗證數據一致性時發現了 hash 函數、時間戳不一致的問題，因此 Spark 鏡像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;環境變量問題&lt;/strong&gt;：鏡像生成容器後需要預置如 Spark、Hadoop 的環境變量，如果鏡像中相關目錄的位置不能完全和 Yarn 的提交節點保持一致，則需要檢查各啓動腳本，如 spark-env.sh 中的環境變量的路徑是否存在，發生衝突時可以修改為絕對路徑。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 鏡像構建完成後，區分 SparkSql 任務和 SparkJar 任務實質就是啓動命令的不同，事實上 SparkSql 任務也就是 SparkJar 任務的一種，只是啓動的主類是固定的，兩者的啓動參數如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任務：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任務主類} {jar 任務 jar 包} {參數}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不僅構建了 Spark 鏡像，還構建了 Spark 日誌鏡像，容器組成結構會複雜一些。如圖例如 Driver 容器，我們將 Spark、Hadoop 等配置文件構建了 configMap，啓動 initContainer 來拉取從 configMap 拉取配置文件，然後啓動 Driver 容器執行 Spark 任務，同時也使用 sidecar 創建日誌上報的容器，在 Spark 任務運行完成後上報 Driver 和 Executor 日誌到 Spark HistoryServer。這樣的方案看似充分應用了 K8s 技術，但是在實踐的過程中這些技術卻被一一棄用，轉而逐步地把各種功能集中到了一個 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具體演進如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步驟寫在啓動命令中，Spark 作業執行前執行下載配置，原因在多個 namespace 下不方便統一管理，而且 configmap 內容較大，會導致 Pod 啓動時配置加載的延遲增加，影響了 Pod 創建速度，同時 K8s 的內存和 CPU 資源佔用增加，對 kube-apiserver、ETCD 負載有一些影響。去掉 initContainer 還有個重要的好處就是減小 ETCD 的存儲壓力，事實上我們在移除 initContainer 拉取配置的功能後的一段時間內還保留着 initContainer，在任務逐漸上量後發現 ETCD 的存儲比較滿，分析後發現 Spark 作業中的一個 Pod 生命週期大約 8 次更新，其中 initContainer 更新會佔用 2 次，移除了之後理論上是可以減少 1/4 的 ETCD 存儲，實際應用中完全去除了 initContainer 也確實能減小了 ETCD 的存儲壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 創建日誌上報的容器&lt;/strong&gt;，Driver 和 Executor 日誌上報步驟寫在啓動命令中，Spark 作業執行完後再執行腳本上報，原因是 sidecar 在同一個 Pod 中與主容器共享相同的生命週期，不使用 sidecar 方式就能更快創建 Pod，Spark 任務執行完成後能更快釋放資源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於 Spark 作業會頻繁創建、更新和銷燬大量的 Pod，所以去除非必要的容器，提高 Pod 生命週期流轉速度，就能降低 kube-apiserver、ETCD 工作負載，也能提高 Spark 的作業效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任務運行在 K8s 上，對於一些使用的兼容問題也進行了&lt;strong&gt;相關改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因為 Spark Operator 沒有存儲已結束作業的日誌，因此參考了 on Yarn 的方式，在 Spark 作業結束後，通過日誌上傳腳本把 Driver 和 Executor 的日誌上傳 HDFS，與 Yarn 日誌聚合類似，同時也在 Spark HistoryServer 做了二次開發工作，增加了 on K8s 方式的日誌查看接口，用戶查看已完成的 Executor 日誌時，不再請求 JobHistory Server，而是請求 Spark HistoryServer 接口。但日誌上傳方式需要 Executor 執行完才能查看到日誌，為了能實時查看到執行中的日誌，可以在 Executor 內部實現一個 HTTP 服務，根據 Pod 以及端口信息拼接出日誌請求 URL，Executor 啓動一個 Servlet 自動獲取本地日誌並返回。日誌查看體驗上做到了基本與 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主機 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之間的通信通常是通過主機名進行的，不過隨着 Spark 任務增多，CoreDNS 因為頻繁的域名解釋請求導致壓力增大，甚至會影響到在線服務，因此我們將 Hadoop 的配置文件改為 ip 格式、設置 Driver 和 Executor 使用 ip 地址，同時去除了對應的 K8s Service，通過訪問 ip 而不是域名的方式來規避這個問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件參數兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是運行在某一個 Pod 中的，所以文件需要是全局可視的，如 HDFS 文件，否則就會報文件未找到的錯誤，但 Spark 作業運行在大數據作業平台時有的任務使用的上傳的本地文件，因此對於提交到 K8s 的任務，第一步是要把上傳到大數據作業平台的文件再次上傳到 HDFS，第二步是改造 add jar 和--file 等命令邏輯，Spark 任務在未能讀取本地文件後將再嘗試讀取二次上傳到 HDFS 的文件，實現任務無需修改成全局可視的文件路徑也能讀取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 線程終止&lt;/strong&gt;，在 K8s 上運行的 Spark 任務是指定 Client 模式，Client 模式下 Driver 遇到異常時停掉 SparkContxet，等所有 non-daemon 線程結束後，Driver 才會退出，但如果存在一直運行的 non-daemon 線程，那麼 Driver 一直不退出，任務就一直處於執行中。因此需要改造成 Cluster 模式的異常退出機制，即異常時以非 0 退出碼退出，不再等待其他的 non-daemon 線程結束，Driver 直接終止，以確保 Driver Pod 的正常結束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 優化&lt;/h2&gt; 
&lt;p&gt;隨着在 K8s 上運行的 Spark 任務不斷增加，K8s 集羣的負載也逐漸顯現。因此，需要對 Spark Operator 進行一系列優化，以減輕 K8s 集羣的壓力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;離線使用獨立的 kube-apiserver&lt;/strong&gt;，混部集羣中離線容器佔了很大一部分，而且離線任務由於生命週期短，容器創建銷燬更加頻繁，這對 kube-apiserver 造成了很大的壓力，然而在線業務需要更高的穩定性，為了減少離線對在線業務的影響，我們拆分了 kube-apiserver，離線任務通過指定 master 參數來使用獨立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 網絡模式&lt;/strong&gt;，在 K8s 上啓動 Driver 與 Executor 雖然使用的是獨立 ip+固定端口，但頻繁的 ip 申請和釋放也對 kube-apiserver 造成了一定的壓力，因此我們改為使用 HostNetwork 網絡模式，同時不指定端口避免端口衝突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Operator 控制器的隊列&lt;/strong&gt;，在任務量比較大的情況下，Spark Operator 對 Pod 創建消耗效率會遇到瓶頸，排查後發現是 Spark Operator 的事件處理隊列的併發數和限速桶的默認配置地太小，因此我們調低 Spark maxPendingPods 參數，調高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 參數，減少 Pending Pod 個數，使 Pod 的處理效率符合集羣的承載水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;優化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 緩存，避免對 ETCD 產生影響，同時修改 Spark Driver 清理 Executor 邏輯，直接 Delete，減少 List Pod 對 kube-apiserver 壓力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存儲 emptydir + log lv 存儲優化&lt;/strong&gt;，開發 CSI 插件，Spark 任務的離線日誌單獨存儲，避免對在線業務 pod 的影響和磁盤負載高等問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 標記 immutable&lt;/strong&gt;，減少 kubelet watch secret 請求，降低 kube-apiserver 的負載。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、離線任務提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任務提交平滑切換&lt;/h2&gt; 
&lt;p&gt;離線任務容器化方案確定後就要落地到生產，目前有 SparkSql 和 SparkJar 兩種離線任務實現了容器化，這裏以 SparkSql 任務為例描述 Spark 提交到混部 K8s 集羣的流程並達到與傳統客戶端提交任務幾乎無差異的平滑切換。目前 vivo 的離線任務都是通過大數據平台進行提交和調度的，平台會把主要的提交流程進行封裝形成簡單操作的功能，例如在平台上提交 SparkSql 任務流程一般是編寫 sql、提交任務、查看 Driver 日誌或在跳轉到 SparkUI、執行完成後獲取結果以及更新任務狀態。&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務使用傳統的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用戶編寫好的 sql 上傳到提交節點生成一個 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交節點使用 Spark 客戶端執行該 sql 文件啓動 SparkSql 任務；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過不斷地 tail 操作查詢日誌轉存到 HBase 方便在平台頁面上查詢到 Driver 日誌；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，再查詢輸出結果轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根據提交 sql 任務命令的返回碼來更新任務狀態。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;傳統 Spark 客戶端提交任務大部分只會涉及到提交節點的客戶端與平台服務器之間的交互，而 SparkSql 任務提交到混部 K8s 集羣，從上節的 Spark 容器化方案的原理可知最終目的是要將 Spark 任務的任務參數按一定的格式封裝好傳入 Spark Operator 控制器來創建相關的容器，平台需要通過會調用容器團隊提供的封裝好 K8sApi 的統一接入層來創建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台內部，SparkSql 任務提交到混部 K8s 集羣的&lt;strong&gt;完整流程&lt;/strong&gt;為：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用戶編寫好的 sql 上傳到 HDFS 生成一個遠程可訪問的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任務參數封裝好傳入容器接入層的 createSpark 接口來調用 Spark Operator 控制器容器，再由 Spark Operator 控制器創建 Driver Pod，最後由 Driver Pod 根據 Spark 任務需要創建多個 Executor Pod，這些 Driver、Executor 的 Pod 相當於 Driver 和 Executor 的角色，共同配合執行 Spark 作業；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務啓動後，通過容器接入層的 getDriverLog 接口週期性地查詢 Driver 日誌，實質上是查詢 Driver 容器的日誌，查詢到的 Driver 日誌會轉存到 HBase 方便在平台頁面上查詢；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務結束後，一方面通過 Spark 啓動腳本中的日誌上傳命令，把 Driver 和 Executor 的日誌上傳 HDFS，可以在改造後的 Spark HistoryServer 直接查看，另一方面執行結果也會先輸出到 HDFS，再從 HDFS 轉存到 HBase 方便在平台頁面上查詢到執行結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過輪詢接入層的 getSpark 接口根據返回的狀態碼來更新任務狀態，在任務結束後，此時 Driver Pod 不會主動退出，首先將任務狀態更新為成功，在日誌和結果都存儲完成後，再調用 deleteSpark 接口主動地殺死 Driver Pod 釋放資源，完成整個 Spark 任務流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任務提交到混部 K8s 的執行主體是容器，因此需要增加容器接入層來管理 Spark 相關的容器，同時容器的使用更傾向於存算分離的效果，因此需要使用 HDFS 作為遠程文件中轉。&lt;/p&gt; 
&lt;p&gt;大數據平台上傳統使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任務執行流程對比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任務的資源參數調整&lt;/h2&gt; 
&lt;p&gt;Spark 任務的 Driver 和 Executor，在 Yarn 上執行實質是運行在 NodeManager 節點上的，而在 K8s 上執行實質是運行在對應的 Pod 中的，由於 Spark on K8s 的提交方式和運行環境都不同於 on Yarn，任務的資源參數不能直接套用，需要做一些參數調整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、資源參數提取和轉換&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任務在 Yarn 上可以靈活地調整 sql 中的配置來滿足不同特性的任務，sql 中的資源配置會覆蓋客戶端啓動時的全局配置，因為 Executor 是運行在 NodeManager 節點上的，資源會相對充裕能滿足 Executor 的資源需求，與此不同的是 Spark on K8s 的 Executor 是運行在 Executor Pod 中的，使用的資源會受到 Pod 資源規格大小的限制，而 spark-operator 的提交方式是要先獲取 Executor 全局資源規格並生成相應資源規格大小的 Executor Pod，所以在提交 Spark 任務到 K8s 前就要準確地獲取任務真正生效的資源參數。在大數據平台中資源參數會存在多中類型的參數中，參數的優先級為：任務配置參數 &amp;lt; 任務模板參數 &amp;lt; sql 中設置參數 &amp;lt; HBO 優化參數 &amp;lt; 平台統一參數，按此優先級順序依次提取最終的資源參數並傳入容器接入層創建 Spark 作業。另外容器接入層對於 Spark 的 arguments 和 sparkConf 參數都是要求以字符數組的方式傳入，需要做好對原任務參數中的單引號、雙引號、反斜槓和回車等符號以及分段落的處理和轉換。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的計算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是運行在 NodeManager 節點上的，節點的資源一般都大於並能滿足 container 申請的資源，所以在 Yarn 上只需要關心 container 本身申請的資源即可，而在 K8s 上 Executor 運行在對應的 Pod 中，可以把 Pod 理解為只一台獨立的節點，除了要滿足 container 申請的資源量，還需要一些 Pod 容運行時網絡、存儲等基礎設施的自身開銷資源，如果把 Spark 任務中 Driver 和 Executor 申請的資源直接設置為 K8s 中 Driver Pod 和 Executor Pod 的資源規格，有可能出現 OOM 情況，另外還要考慮非 JVM 內存，Spark 默認會把申請的 Executor 內存乘以一個係數或者至少預留 384 MiB 內存作為額外的非 JVM 內存緩衝區，用於堆外內存分配、非 JVM 任務以及各類系統進程的使用，可以通過設置 overheadMemory 進行覆蓋。因此 K8s 的 Pod 除了要滿足申請的 Memory 和運行時需要的 overheadMemory 的資源，還會再添加 100M 資源用於 Pod 運行的自身開銷。&lt;/p&gt; 
&lt;p&gt;pod 的資源規格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;對於 overheadMemory 也需要先獲取到並加到 Pod 的資源規格，如果任務有配置就直接使用配置的 overheadMemory，如果沒有配置值則按一定計算公式來計算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;無配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整數倍 + 100M&lt;/p&gt; 
&lt;p&gt;不過在實際應用中發現對於個別任務，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一樣的任務在 K8s 上則有較多的 Executor OOM 情況，而在 Yarn 上卻完全沒有，目前排查到的現象是有 JVM 堆外的內存無法回收，如果任務需要較多的對外內存，堆外內存一直增長最終導致 OOM，但哪些內存無法回收的還未排查到。目前對於這些 OOM 過多且實際影響到運行效率的任務，在原 overheadMemory 基礎上再增加 512M 後就沒有 OOM 情況了，同時也有采用了大數據平台的 HBO 能力自動調整內存參數來事後規避這個問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任務申請的 CPU 使用一般不會使用完，事實上 Executor Pod 的 CPU 利用率也並不是很高，比如 Executor 申請 1 個核，通常只能利用 0.6 個核，存在 CPU 浪費的現象。Executor Pod 的資源規格是創建的時候分配的，利用容器的能力，可以採取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申請 1 核，實際用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申請了 1 核只給 0.8 核，但還是要按 1 核的申請量來運行任務。目前平台使用的是靜態的固定比例超分設置為 0.8，實施超分配置策略後 Pod 的實際 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任務的篩選提交&lt;/h2&gt; 
&lt;p&gt;經過上面的任務提交方式的改造和任務資源參數的調整，原 SparkSql 和 SparkJar 任務就可以平滑切換提交到混部 K8s 上執行了，但在大規模切換之前平台還做了比較長期的雙跑驗證工作，在執行成功率、數據一致性和執行時效等方案都進行了雙跑比較，雙跑通過的任務才能切換到 K8s 上執行。除了雙跑通過，前期還設置了其他的篩選條件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按這些條件篩選出可以提交到 K8s 的任務，然後分批的進行 K8s 任務的參數標記，並把標記的這批任務添加監控進行跟蹤。經過雙跑驗證、任務篩選、批量標記、監控跟蹤和問題解決這一整套 SparkSql 任務上量 K8s 的流程，K8s 上的任務運行逐步穩定，K8s 的兼容問題也基本解決，因此目前取消了雙跑通過的這一條件，主要保留了任務重要性、運行時長和重試次數這幾個篩選指標。隨着 SparkSql 任務上量和穩定，提交到 K8s 的任務類型也增加了 SparkJar 任務，SparkJar 任務無法進行雙跑驗證，所以在各種 K8s 兼容問題解決後再推進會更加穩妥。&lt;/p&gt; 
&lt;p&gt;目前大數據平台會定期篩選和標記一批 SparkSql 和 SparkJar 任務允許提交到混部 K8s，用戶也可以自行開啓，在任務配置頁面只顯示已開啓混部，則該任務就有機會被提交到混部 K8s 上執行。當然，用戶也可以手動關閉這一開關，並且手動操作的優先級最高，手動關閉後平台的自動開啓功能將不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、彈性調度系統&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 彈性調度功能矩陣&lt;/h2&gt; 
&lt;p&gt;Spark 任務開啓了混部也不是必定能提交到混部，最終能不能在混部集羣上執行，還要根據當時混部集羣的資源和運行情況等來確定，為了更好地協調離線任務和混部集羣的供需關係，大數據平台構建了離線任務混部彈性調度系統。彈性調度系統的設計目是混部集羣有資源了就調度離線任務，但在生產環境中不管是混部集羣還是離線任務都會各自的問題需要解決和優化的需求，彈性調度系統也逐步演變成了全面管理離線任務提交到混部以實現混部資源最大化利用的功能矩陣。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 資源水位線調度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;彈性調度的流程，任務按調度時間以任務流的形式過來，如果任務標記了允許提交到混部，那就會先去查詢 K8s 的各個集羣，如果某一個集羣資源充足就直接提交到 K8s，如果當時沒有足夠資源就等待資源再判斷，這裏分為有三類任務，第一類是一直等 K8s 資源，永不超時，只會提交到 K8s；第二類是長時間等待，超時時間在 1 到 5 分鐘，可以等久一點；第三類是短時等待，超時時間為 30-60 秒，稍微等一下，如果 K8s 沒有資源就回到 Yarn 上執行，目前平台標記的任務大部分任務都是第三類短時等待。&lt;/p&gt; 
&lt;p&gt;混部集羣提供給離線任務的資源是呈潮汐波動的，使用百分比的水位線方式才能更好地貼合資源的波動情況。混部集羣提供的資源是指 CPU 和內存，但離線任務一般不能百分之百地獲取到這部分資源，需要設置一個折算比例也就是水位線來計算出離線任務能使用的真正資源是多少，水位線的設置需要考慮&lt;strong&gt;幾個因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集羣的碎片化率&lt;/strong&gt;，混部集羣中的機器規格和正在運行的業務佔用量都是不確定的，但一般大規格的機器多的集羣碎片化率較低，所以小規格的機器多的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、資源動態分配容納率&lt;/strong&gt;，對於開啓了動態分配的 Spark 任務，無法提前知道任務所需的資源，需要留有一部分資源用於動態分配的消耗，如果同樣的水位線資源規模大的混部集羣容納率會高，所以資源規模小的集羣的水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、資源配比的均衡性&lt;/strong&gt;，不同的集羣或者同一集羣的不同時間段的 CPU 和內存配比可能會存在很大的差異，例如 Spark 任務的 CPU 和內存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和內存比為 1:2 的，內存會被用完而 CPU 有剩餘，此時為了內存留有部分餘量，水位線要設置低一點。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * 資源水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;資源水位線有 CPU 水位線和內存水位線，設計時以 CPU 或內存中的最低水位線為準，哪個資源先分配完就停止提交任務，不過在實際生產中大部分混部集羣都是受內存限制較多，個別時段 CPU 比內存多但通過其他的限制手段即使 CPU 滿載對任務影響不大，因此目前只開啓了內存資源水位線。以上提到的 3 點可以當成集羣的固有消耗需要保留有一定的餘量，為了直觀地控制混部資源使用率和引入優先策略，計算方式調整為：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部資源可用量 = 混部資源提供量 * (1-餘量水位線) * 優先水位線&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;餘量水位線根據各個集羣來調整，一般為 0.05，優先水位線的範圍可以在 0-1 之間。優先水位線的作用是對於一些符合優先條件的任務可以優先提交，但是任務調度是一有任務就要調度的流式調度，不能夠先集中再挑選優先任務而是先到先得，所以要為優先任務預留一部分資源，例如優先水位線為 0.8，混部資源使用到 0.8 以下的時候任何任務都可以調度上來，但使用量超過了 0.8，那只有優先任務能調上來，也就是為優先任務預留了 0.2 的資源，當然即使資源使用量達到了 1，由於餘量水位線的存在，實際的使用量為 0.95，混部集羣仍有資源維持週轉。優先水位線是最常用的調整參數，它實質就是控制混部任務提交量，不僅能調整混部資源的使用量，還在灰度測試、壓力測試和問題排查等事項起到了靈活調節的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他調度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集羣管理&lt;/strong&gt;：混部集羣通常會有多個，vivo 目前就有多個生產環境的混部集羣，各混部集羣由於建設週期、機器規格和業務接入的不同，混部資源的規模和變化趨勢都會呈現比較大的差異，因此每個集羣的調度策略配置都需要做到能獨立調整來適應各自的資源特點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分時段控制&lt;/strong&gt;：每個混部集羣上的在線業務一般是潮汐波動的，給到離線任務的資源也是潮汐波動的，因此每個集羣需要做到在每天不同時段可以調整不同的調度策略，尤其在波峯波谷差異較大的時間段各自調整配置的差異會更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任務的 Driver Pod 和 Executor Pod 都會放在一個 namespace 中管理，如果所有任務都由一個 namespace 管理，那需要管理的 pod 數量會達到數十萬的級別，會對 K8s 集羣的性能和穩定性產生影響。因此需要將 Spark 任務平均分配到多個 namespace，採用的方案是輪詢填充，任務優先分配到多個 namespace 中任務最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失敗回退 Yarn&lt;/strong&gt;：離線任務混部推進的過程中還有會有 Spark 兼容問題、混部集羣異常和平台變更等問題導致的離線任務在混部 K8s 上運行失敗，為了減少失敗對任務的影響，任務在 K8s 上首次執行失敗後就會自動回到 Yarn 重新執行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.資源准入粒度&lt;/strong&gt;：各混部集羣的機器規格和碎片率是不一樣的，如 executorMemory=2G 這樣較小粒度的 Spark 任務即使碎片率較高的混部集羣可以填充，而對於 executorMemory=16G 這樣較大粒度的 Spark 任務，機器規格大的集羣才更容易獲取到資源，因此不同混部集羣可以設置不同的准入粒度，小規格和碎片率高的集羣准入粒度可以設置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任務偏好配置&lt;/strong&gt;：對於一些灰度任務和特殊要求的任務，例如只有在 0 到 8 點才允許提交到混部、只提交到某幾個指定的混部集羣等調度要求，需要支持任務偏好配置，在任務參數中調整混部控制參數實現相應的調度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 彈性調度策略優化&lt;/h2&gt; 
&lt;p&gt;彈性調度的核心是通過資源水位線的調節，有混部資源就調度離線任務，但實際生產中還要考慮混部集羣的運行情況，是否能穩定地接收和消化離線任務，同時在存在多個差異較大的集羣時提交到哪個集羣最優。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任務調度穩定優化&lt;/h3&gt; 
&lt;p&gt;大數據平台的離線任務提交高峯在凌晨時段而且調度時間集中在整點半點，還有 5 分和 10 分這樣的整分，例如 03:00 調度的任務達 1000 個，但在 03:01 調度的任務只有 10 個，過於集中地提交任務會導致混部集羣 Pending Pod 數量急劇上升，這是因為無論是查詢集羣資源還是 Pending 數的接口，更新數據都需要一定的週期時間，而且離線任務提交上去到獲取資源也受 K8s 的調度時間的影響，所以獲取集羣運行情況總會滯後於任務提交。例如 03:00 查詢集羣是有資源的並且是健康的，由於任務開啓了動態分配所以不能確定需要多少資源，此時集中提交了 1000 個任務，這 1000 個任務首先會創建 1000 個 Driver Pod，集羣資源還是能滿足的並且優先創建，假如每個 Driver 需要創建 100 個 Executor，如果集羣沒有這麼多資源，那就會產生大量的 Penging Pod，嚴重影響集羣的性能和穩定以及任務的執行效率，因此需要對彈性調度的穩定性進行優化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短時提交限制&lt;/strong&gt;：避免集中提交任務的直接方案就是根據各混部集羣的資源規模設置短時提交的任務數量限制，例如 1 分鐘內只能提交 100 個任務，集羣短時間內 Pending Pod 數量會增加但仍在可以承受範圍內，集羣和任務都會穩定運行。短時提交限制相當於攔截並捨棄了部分某個時間點集中提交的任務，這裏相當於捨棄了 900 個任務，那麼提交的總任務量就減少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延遲打散提交&lt;/strong&gt;：為解決短時提交限制導致捨棄部分任務的問題，增加了短時延遲打散提交，例如 03:00 提交的 1000 個任務，隨機打散到 03:00 到 03:03 的 3 分鐘內，即使有短時提交限制，這 3 分鐘內也可以提交 300 個任務。理論上將集中提交的任務延遲更久，能提交到混部的任務會更多，但是增加延遲時長就等於增加任務的執行時長，會影響到業務數據產出的及時性，因此延遲打散提交策略只能是短時的，進一步的優化是執行時長更久的任務延遲更久一點，但根本解決方案還是用戶能將調度時間儘量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集羣反饋限制&lt;/strong&gt;：短時提交限制和延遲打散提交都屬於靜態限制，需要人為地根據各個混部集羣的情況去判斷和設置限制值，因此需要做到動態限制，就需要獲取集羣的運行情況並根據運行情況進行限制。事實上 K8s 的調度性能相比於 Yarn 還是有差距的，從提交的 Spark 任務到獲取到資源運行 Pod 有一定的滯後時間差，這段時間查詢內還是有剩餘資源，但如果還繼續提交新任務就會產生更多 Pending Pod，因此需要做集羣運行情況的反饋控制，例如查詢 Pending Pod 數、等待的 SparkApp 數，當數量達到一定數量就不再提交新任務。&lt;/p&gt; 
&lt;p&gt;集羣反饋限制雖然是動態的能根據混部集羣情況進行反饋調節，但是查詢集羣狀態是滯後的，這種滯後的控制就容易被集中提交給打垮，所以要加上短時提交限制來上一道保險，為緩解短時提交限制造成的任務損失，就引入了延遲打散提交，而在延時打散的過程中集羣能逐步消化任務，查詢集羣狀態逐步接近真實情況，這時又可以交給集羣反饋限制來動態調節，逐步從突增恢復到穩定，三個調度穩定優化策略相輔相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集羣分配均勻優化&lt;/h3&gt; 
&lt;p&gt;離線任務會調度到多個混部集羣，每個集羣的資源總量和可用資源量，以及集羣運行狀況都不相同，為保證離線任務的運行穩定和執行效率，需要在多個混部集羣中選擇一個最合適的集羣。各個集羣會按一定的規則進行排序，離線任務會按這個排序依次輪詢各個集羣，只要集羣剩餘資源滿足且沒有被短時提交限制、集羣反饋限制等拒絕，離線任務就提交到該集羣。集羣排序的&lt;strong&gt;演化順序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排隊隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩餘資源量多的優先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源最多的集羣，保證離線任務運行穩定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於小集羣剩餘資源量很小一直分配不到任務容易「餓死」（事實上有的小集羣全部資源量都達不到一個大集羣的 20%）&lt;/p&gt; 
&lt;p&gt;② 優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;將資源使用量超過一定比例的集羣放到排序隊列，剩餘的集羣放到隨機隊列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，即保證任務的運行穩定，隨機的方式也能均勻「餵飽」每個集羣&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨機分配在大任務量時相當於是平均分配，每個集羣都會調度差不多的任務量，當前情況會存在整點集中提交大量任務，小集羣接收和大集羣同樣任務量會抗不住，影響任務執行穩定和效率，小集羣容易「撐死」&lt;/p&gt; 
&lt;p&gt;③再優化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定&lt;/p&gt; 
&lt;p&gt;④ 最終方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優先隊列（排序）+加權隨機隊列+排序隊列+輪詢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考慮優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;優點&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;繼承上一方案的優點，同時對於特定項目或機房的離線任務，能優先調度到某些特定的集羣&lt;/p&gt; 
&lt;p&gt;目前只以內存作為資源水位線的衡量標準，這裏的資源量指的是內存量。最開始方案是按集羣的剩餘資源排序，內存資源剩餘多的集羣優先，缺點是小集羣一直分配不到任務容易「餓死」，然後使用隨機的方式也能均勻「餵飽」每個集羣，但小集羣接收同樣任務量時容易「撐死」，於是隨機隊列按剩餘資源進行加權隨機，剩餘資源多的集羣有更多概率分配到任務，這樣離線任務優先提交到資源較多的集羣，「大集羣多吃，小集羣少吃」，每個集羣都能填充同時保證任務的運行穩定，在此基礎上增加優先隊列，無視其他排序規則，優先隊列裏的集羣將最優先，在優先隊列中的集羣再按資源排序，能優先調度到某些特定的集羣，形成最終集羣選擇排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果與未來規劃&lt;/h1&gt; 
&lt;p&gt;經過以上的對 Spark 組件、K8s 混部系統、大數據平台以及彈性調度系統的改造和優化，目前混部集羣及提交混部的離線任務運行持續穩定，每天任務調度到混部的次數達 10+萬次，在凌晨的高峯期通過混部能為離線任務額外增加數百 TB 內存的計算資源，部分混部集羣的 CPU 利用率提升至 30% 左右，整體收益也是可觀的。&lt;/p&gt; 
&lt;p&gt;雖然目前 vivo 的在離線混部達到了一定的規模，但未來要繼續提高混部的規模和收益，還有規劃一些改進工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高離線任務混部規模。&lt;/h2&gt; 
&lt;p&gt;離線任務混部的節點是在線業務提供的，節點規模取決於在線業務峯值，峯值越高那麼在業務低峯期能提供給離線混部資源就越多，因此提高混部規模的重要因素是提交更多的離線任務。然而目前採用的 Spark Operator 方案能提交的離線任務只有標準的 SparkSql 和 SparkJar 任務，而對於非標準的任務如腳本任務，腳本中除了調用 spark-submit 提交 Spark 作業還有額外的處理邏輯，這類任務還不能直接以 Spark Operator 的方式提交。事實上 Spark 作業更多是來自腳本任務的非標準任務，如果要繼續增加離線任務的量，就必須把非標準任務也提交到混部，因此後續是選擇改造 spark-submit 客戶端支持 Spark Operator，或是選擇使用 Yarn on K8s，還需要綜合評估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高離線任務混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部節點 CPU 的平均利用率達到 30%，但仍有提升空間。從離線任務的角度來看，一方面是要增加錯峯互補的時間段，例如離線任務的高峯期是 02:00 到 08:00，在線業務的高峯期是 06:00 到 23:00，在 06:00 後在線業務逐步上量開始回收資源，所以離線任務能顯著提高混部集羣 CPU 利用率的黃金時間是有 02:00 到 06:00 這 4 個小時，因此如果能把離線任務高峯期提前到 00:00 到 06:00，混部提效的黃金時間就能達到 6 小時。所以需要推動離線任務高峯期的前移，對於有依賴鏈路的任務，儘量減少調度時間的間隔，上游任務完成後能儘快調起下游任務，而對於沒有依賴的任務，可以儘量提前調度時間，不過這兩種調整都需要推動業務方來調整，平台也可以給予一定的計算成本優惠作為激勵。另一方面是要提高混部資源的填充率，Spark 任務需要創建大量的 Executor Pod，目前混部集羣的調度器為了保證調度效率就沒有開啓預選、優先策略，事實上 Spark 的資源粒度比較小更適合填充資源碎片，所以在不影響 K8s 調度效率的情況下優化資源調配策略，把合適的資源粒度的 Pod 分配到合適的混部節點，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Thu, 17 Apr 2025 06:42:40 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>開源多模態大模型「書生·萬象 3.0」發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能實驗室（上海 AI 實驗室）升級並開源了通用多模態大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;書生·萬象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，通過採用創新的多模態預訓練和後訓練方法，InternVL3 多模態基礎能力全面提升，在專家級基準測試、多模態性能全面測試中，10 億~780 億參數的全量級版本在開源模型中性能均位列第一，同時大幅提升了圖形用戶界面（GUI）智能體、建築場景圖紙理解、空間感知推理以及通識學科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在專家級多學科領域知識推理基準測試 MMMU 中再次突破開源模型極限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基於司南 OpenCompass 開源評測框架，研究團隊對 InternVL3 進行了全面系統的評估，包括多學科推理、文檔理解、多圖像 / 視頻理解、現實世界理解、多模態幻覺檢測、視覺定位、多語言能力以及以語言為中心的基準測試。評測結果顯示，InternVL3 在開源多模態大模型中性能表現最優，創造了開源多模態大模型的性能新標杆，性能接近閉源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;創新提出原生多模態預訓練方法，將語言和多模態學習整合於同一個預訓練階段，提升及拓展多模態能力的同時，進一步提升純語言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好優化算法以及多模態測試階段增強，通過負監督修正模型響應分佈，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公測版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Mon, 14 Apr 2025 06:08:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 創新巡展杭州站現場，火山引擎總裁譚待發布了最新的豆包 1.5·深度思考模型，升級豆包·文生圖模型 3.0、豆包·視覺理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時，面向 Agent 服務，發佈 OS Agent 解決方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大規模推理，發佈 AI 雲原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據透露，截至 2025 年 3 月底，豆包大模型日均 tokens 調用量已超過 12.7 萬億，是 2024 年 12 月的 3 倍，是一年前剛剛發佈時的 106 倍。IDC 報告顯示，2024 年中國公有云大模型調用量激增，火山引擎以 46.4% 的市場份額位居中國市場第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在數學、編程、科學推理等專業領域及創意寫作等通用任務中表現突出。同時，模型採用 MoE 架構，總參數 200B，激活參數為 20B，低於業界同類模型參數規模的 50%，具備顯著的推理成本優勢。基於高效算法，豆包 1.5·深度思考模型在提供行業極高併發承載能力的同時，實現 20 毫秒極低延遲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型還具備視覺理解能力，可以像人類一樣，不光基於文字思考，更能基於所見畫面思考，思考更立體，讓模型同時擁有「大腦」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升級的豆包·文生圖模型 3.0 則能夠實現更好的文字排版表現、實拍級的圖像生成效果，以及 2K 的高清圖片生成方式。可以廣泛應用於影視、海報、繪畫、玩偶設計等營銷、電商、設計場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·視覺理解模型具備更強的視覺定位能力，支持多目標、小目標、通用目標的框定位和點定位，並支持定位計數、描述定位內容、3D 定位。可應用於線下門店的巡檢場景、GUI agent、機器人訓練、自動駕駛訓練等。新版本在視頻理解能力上也有大幅提升，比如記憶、總結理解、速度感知、長視頻理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Mon, 14 Apr 2025 05:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌推出了超越 Sora 的 Veo 2，生成 8 秒超逼真視頻</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌 DeepMind 終於將大家期待已久的 Veo 2 整合到 GeminiApp 應用中，全面開放使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/114154_vVro_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Veo 是谷歌迄今為止最強大的視頻生成模型。它可以生成各種電影和視覺風格的視頻，捕捉提示中的細微之處，以便在各個畫面中一致呈現精緻細節。&lt;/p&gt; 
&lt;p&gt;據介紹，Veo 2 可以最高生成 8 秒 720P 電影級視頻，在運鏡、文本語義還原、物理模擬、動作一致性等方面非常優秀，同時支持圖片轉視頻功能。谷歌公佈的測試數據顯示，Veo 2 在用戶偏好和提示還原方面已經超過了 Sora、可靈 1.5、Meta Movie Gen 和 Minimax。&lt;/p&gt; 
&lt;p&gt;開發者可以在 Google AI Studio 中通過 API 使用 Veo 2。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvideo%3Fhl%3Dzh-cn&quot; target=&quot;_blank&quot;&gt;https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345050/google-gemini-veo2</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345050/google-gemini-veo2</guid>
            <pubDate>Mon, 14 Apr 2025 03:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Reachy 2 開源人形機器人 7 萬美元正式開售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pollen Robotics 推出其最新開源人形機器人 Reachy2，正式開啓銷售，定價為 7 萬美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 並非面向消費市場，而是專為 AI 與機器人實驗室設計，目標是推動開源機器人生態的發展。據 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fzh%2Fnews%2F17257&quot; target=&quot;_blank&quot;&gt;AIbase&lt;/a&gt;瞭解，這款機器人已在 Cornell 大學、Carnegie Mellon 大學及多家頂級 AI 實驗室投入使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;324&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be15587448f52736ea558e37ca046b43429.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 以其高度仿人的外形與交互能力脫穎而出，主要亮點如下：&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;仿人設計：配備雙臂、頭部及獨特的天線，Reachy2 的 7 自由度（DoF）手臂模仿成人手臂的尺寸與運動方式，可實現自然、精準的動作，每隻手臂能負重高達 3 公斤。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;全向移動：其移動底盤採用三全向輪設計，結合 LiDAR 與多傳感器系統，確保平滑、精準的導航，適應多樣化應用場景。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;豐富的傳感器陣列：集成雙 1080p 攝像頭、麥克風陣列、揚聲器、LiDAR 及慣性測量單元（IMU），為環境感知與交互提供強大支持。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源與模塊化：基於 ROS2 和 Hugging Face 的 LeRobotHF 框架，Reachy2 支持 Python SDK 編程，開發者可輕鬆擴展與定製功能，滿足特定研究或應用需求。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Reachy2 已被全球 20 多個國家的 100 多台機器人部署，客戶包括 Hugging Face、Accenture、CNRS、Ecole Polytechnique 等。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345048</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345048</guid>
            <pubDate>Mon, 14 Apr 2025 03:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌宣佈將全球搜索流量統一重定向至 google.com</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fcountry-code-top-level-domains%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;將淘汰用於搜索的單獨國家代碼頂級域名（如 google.ng 或 google.com.br），並將其統一為 google.com。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;當您在 Google 上搜索時，我們致力於提供最實用的信息，這在很多情況下包括提供與本地相關的搜索結果。一直以來，為了提供本地化結果，我們都會使用國家/地區代碼頂級域名 (ccTLD)，例如尼日利亞的 google.ng 或巴西的 google.com.br。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;多年來，我們提供本地化體驗的能力不斷提升。2017 年&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fmaking-search-results-more-local-and-relevant%2F&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;，&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們開始為所有使用 Google 搜索的用戶提供一致的本地搜索結果體驗，無論他們使用的是&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;還是其所在國家/地區的國家代碼頂級域名 (ccTLD)。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;由於這項改進，國家/地區級域名已不再必要。因此，我們將開始將這些國家/地區頂級域名 (ccTLD) 的流量重定向至&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以簡化用戶的搜索體驗。此項更改將在未來幾個月內逐步推出，在此期間，您可能會被提示重新輸入部分搜索偏好設置。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，雖然此更新將改變人們在瀏覽器地址欄中看到的內容，但它不會影響搜索的工作方式，也不會改變我們處理國家法律規定的義務的方式。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5aaedebd84aee9085474149ca6015d401f8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟發佈安全提醒：攻擊者濫用 Node.js 來傳播惡意軟件</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微軟近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fsecurity%2Fblog%2F2025%2F04%2F15%2Fthreat-actors-misuse-node-js-to-deliver-malware-and-other-malicious-payloads%2F&quot; target=&quot;_blank&quot;&gt;發佈博文&lt;/a&gt;&lt;/u&gt;，稱 Node.js 正日益被用於傳播惡意軟件和其他惡意負載。自 2024 年 10 月以來，微軟持續監測到針對其客戶的攻擊活動，部分惡意活動甚至延續至 2025 年 4 月。&lt;/p&gt; 
&lt;p&gt;儘管與 Node.js 相關的惡意軟件並不普遍，但它們正迅速發展，成為威脅環境的一部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/112133_vXu9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微軟表示，Node.js 是開源、跨平台的 JavaScript 運行時環境，它允許 JavaScript 代碼在瀏覽器之外運行，被廣泛使用並被開發者信任，因為它讓開發者能夠構建前端和後端應用程序。然而，攻擊者也在利用這些 Node.js 特性來嘗試將惡意軟件與合法應用程序混合，繞過傳統的安全控制，並在目標環境中持續存在。&lt;/p&gt; 
&lt;p&gt;微軟舉例稱，犯罪分子利用與加密貨幣相關的惡意廣告（malvertising）誘導用戶下載偽裝成來自 TradingView 或 Binance 等平台的合法文件的惡意安裝程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e9b941943b28336312ced97e7c00094ce72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這個安裝程序內含惡意 DLL 文件，用於收集基本的系統信息。隨後，一個 PowerShell 腳本會下載 Node.js 二進制文件和一個 JavaScript 文件，並通過 Node.js 執行。&lt;/p&gt; 
&lt;p&gt;該 JavaScript 文件運行一系列程序，包括加載多個模塊、向設備添加證書，以及竊取瀏覽器中的敏感信息。微軟指出，這些行為可能預示後續的憑據竊取、規避檢測或二次負載執行等惡意活動。&lt;/p&gt; 
&lt;p&gt;微軟在第二個攻擊實例中表示，黑客採用了 ClickFix 社交工程技術，試圖欺騙受害者執行惡意的 PowerShell 命令。&lt;/p&gt; 
&lt;p&gt;該命令會啓動多個組件的下載和執行，包括 Node.js 二進制文件，讓 JavaScript 代碼無需通過文件執行，能夠直接在命令行中運行。&lt;/p&gt; 
&lt;p&gt;微軟強調，儘管 Python、PHP 和 AutoIT 等傳統腳本語言仍被廣泛用於威脅活動，但威脅行為者正轉向編譯後的 JavaScript，甚至直接利用 Node.js 在命令行中運行腳本，實施惡意行為。&lt;/p&gt; 
&lt;p&gt;微軟警告，這種威脅行為者技術、戰術和程序（TTPs）的轉變表明，儘管 Node.js 相關的惡意軟件數量上相對其它攻擊手段並不凸顯，但正迅速融入不斷演變的網絡威脅。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>JetBrains 宣佈推出 AI 工具免費套餐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains 發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2025%2F04%2F16%2Fjetbrains-ides-go-ai%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;，所有 JetBrains AI 工具（包括改進的 AI Assistant 和新的編碼代理 Junie）現在都可以通過單一訂閲在 IDE 中使用，並提供免費套餐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，為了讓每個人都能使用 IDE 內的 AI 功能，從 2025.1 版本開始，所有的 IDE 許可證中都包含了 JetBrains AI free&amp;nbsp;套餐。AI Free 套餐為用戶提供無限代碼補全和本地 AI 模型訪問權限，以及基於積分的雲端 AI 輔助功能和編碼代理 Junie。此外，免費套餐還包含 30 天的 AI Pro 訪問權限。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Pro（10 美元/月）和 AI Ultimate（20 美元/月）套餐計劃將為高要求的工作流程提供更高的使用配額，&amp;nbsp;All Products Pack 和 dotUltimate 訂閲則將包含 AI Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7661cb02397405a130e0974ef8e9b7b5ef6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;與此同時，該公司宣佈其&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI 編碼助手&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#585858&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsdtimes.com%2Fai%2Fjetbrains-releases-ai-coding-agent-junie%2F&quot; target=&quot;_blank&quot;&gt;Junie&lt;/a&gt;&amp;nbsp;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;現已面向所有 JetBrains 客戶開放。Junie 已進行更新，能夠執行更復雜的任務，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;並提供更精細的控制，實現真正的「人機交互」方法。目前，&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;Junie 已兼容 IntelliJ IDEA Ultimate、PyCharm Pro、WebStorm 和 GoLand。預計 PhpStorm、RustRover 和 RubyMine 也將很快獲得支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;除了 Junie 的公開發布之外，該公司還發布了 JetBrains AI Assistant 的新版本。包含多項重大改進，旨在加速編碼工作流程並減少重複性任務，為開發者提供全程開發支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI Assistant 現在擁有更多模型選擇，包括 Claude 3.7 Sonnet、Google Gemini 2.5 Pro 以及 OpenAI 的最新模型，以及具備更強大的本地模型集成功能。其他更新包括改進的代碼補全、更強的上下文感知、可以編輯多個文件的新編輯模式，以及從代碼生成到測試到文檔的整個工作流程的更智能的支持。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fjetbrains.com%2Fai-ides%2F&quot; target=&quot;_blank&quot;&gt;立即開始&lt;/a&gt;在 IDE 中使用 AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相關閲讀：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;margin-left: 0px; margin-right: 0px; text-align: start;&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/345083/intellij-idea-2025-1-released&quot; target=&quot;news&quot;&gt;IntelliJ IDEA 2025.1 現已發佈&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345039/jetbrains-ides-go-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345039/jetbrains-ides-go-ai</guid>
            <pubDate>Mon, 14 Apr 2025 03:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>美國政府不再為 CVE/CWE 項目提供資金支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;4 月 15 日，MITRE 向 CVE 委員會發送了一封郵件，告知美國政府對 CVE/CWE 項目的資助合同將於 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/110904_ginQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;受此影響，CVE 漏洞可能更新受到影響，並影響 NVD 等下游的漏洞庫。&lt;/p&gt; 
&lt;p&gt;CVE 項目始於 1999 年，由美國國土安全部（DHS）和網絡基礎設施安全局（CISA）的贊助，MITRE 負責運營，NVD（美國國家漏洞庫）等下游漏洞庫基於 CVE 的數據進一步加工分析。&lt;/p&gt; 
&lt;p&gt;在過去的二十多年裏，CVE 是對通用漏洞標識的標準，是漏洞情報共享、漏洞庫、各類安全工具的重要基礎數據，這是一項非常有意義的偉大工作。&lt;/p&gt; 
&lt;p&gt;若資金鍊斷裂，CVE 系統的崩潰將摧毀最受信賴的安全工具和流程。&lt;/p&gt; 
&lt;p&gt;前 CISA 負責人 Jean Easterly 在 LinkedIn 上警告，CVE 雖不常上頭條，但卻是現代網絡安全最重要的支柱之一，失去它如同「同時拆除所有圖書館的卡片目錄」，防禦者將陷入混亂，攻擊者則有機可乘。她強調，網絡威脅無國界，CVE 是全球共享情報和協調行動的通用語言，失去它等於「所有人都在盲飛」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345038</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345038</guid>
            <pubDate>Mon, 14 Apr 2025 03:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 發佈開源 AI 編程工具 Codex CLI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 發佈了一個名為「Codex CLI」的實驗性新工具。這是一個輕量級的 AI 編程助手，可以直接在用戶的終端命令行運行，旨在充分發揮 o3、o4-mini 等模型強大的推理能力，連接本地代碼環境，甚至支持處理截圖或草圖進行多模態編程。&lt;/p&gt; 
&lt;p&gt;Codex CLI 已在 GitHub 完全開源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Fcodex&quot; target=&quot;_blank&quot;&gt;https://github.com/openai/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9e6e21608c2ed84ac64e14c0758cff7933.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Codex 有兩種運行模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;「建議模式」（默認）：&lt;/strong&gt;提出命令供用戶確認；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「全自動模式」&lt;/strong&gt;：禁用網絡訪問，讓 Agent 自主工作但保持安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenAI Agent 研究團隊成員 Michael 為了展示 Codex CLI 的功能，截取了一張在 X 上關於一個「圖像到 ASCII 風格轉換」工具的推文截圖。&lt;/p&gt; 
&lt;p&gt;他將這個截圖直接拖入終端，通過 Codex CLI 並利用 o4-mini 的多模態推理能力，最終成功創建了一個簡單的 ASCII 風格圖像轉換工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-289ad265fb8a85af1f5a6e370f846aaffec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 認為 Codex CLI 是一個將其模型與用戶及其計算機連接起來的最小化界面。&lt;strong&gt;Codex CLI 是為已經生活在終端的開發者設計的&lt;/strong&gt;，他們想要 ChatGPT 級別的推理能力，以及實際運行代碼、操作文件和迭代的權力 —— 所有這些都在版本控制之下。&lt;/p&gt; 
&lt;p&gt;簡而言之，它是一種理解並執行倉庫的聊天驅動開發工具。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;零配置 — 導入 OpenAI API 密鑰，即可直接使用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全自動批准，同時通過運行網絡禁用和目錄沙箱化確保安全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多模態 — 輸入截圖或圖表就可以實現推理功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Codex CLI 可以在 macOS&amp;nbsp;12+、Ubuntu&amp;nbsp;20.04+/Debian&amp;nbsp;10+、Windows&amp;nbsp;11 的 WSL2 子系統中使用，要求最少擁有 4GB 內存（建議 8GB）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345034/openai-codex-cli</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345034/openai-codex-cli</guid>
            <pubDate>Mon, 14 Apr 2025 02:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 發佈 o3 與 o4-mini：開啓多模態推理新時代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;距離 OpenAI 發佈 &lt;a href=&quot;https://www.oschina.net/news/344606/openais-gpt-4-1-models&quot;&gt;GPT-4.1&lt;/a&gt; 僅過去兩天，OpenAI 在本週再次投下「重磅炸彈」—— &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-o3-and-o4-mini%2F&quot; target=&quot;_blank&quot;&gt;正式發佈&lt;/a&gt;&lt;/u&gt;其新一代推理模型 o3 與輕量級模型 o4-mini。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104452_zQp5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這兩款模型在推理能力、視覺理解、個性化對話和跨領域應用等方面實現了顯著飛躍，代表了當下人工智能技術的新高度。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o3：迄今為止最強的通用推理模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI o3 是目前最強大的推理型模型，專為應對複雜、多步驟的任務而打造，廣泛適用於編程、數學、科學分析、圖像理解等領域。&lt;/p&gt; 
&lt;p&gt;它在多個權威基準測試中創下新紀錄，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codeforces 編程排名&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SWE-bench 軟件工程測試&lt;/strong&gt;（無需構建自定義腳手架）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MMMU 多模態任務測試&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不僅如此，&lt;strong&gt;o3 在圖像、圖表和視覺感知任務中表現尤為出色&lt;/strong&gt;。對於需要圖像分析、圖表解讀等多模態輸入的複雜問題，o3 能給出結構化、深入且精準的回答。&lt;/p&gt; 
&lt;p&gt;外部專家評估結果顯示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;o3 在處理真實、複雜任務時比 o1 少 20% 的重大錯誤。尤其在編程、商業諮詢、科研假設等場景中，o3 表現出色，能提出新穎想法並進行深度自我審查。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;首批使用者評價 o3 是 「值得信賴的思維夥伴」，特別擅長在生物、數學和工程領域中生成並評估新假設。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104214_ZHcj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o4-mini：更小、更快、更高效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;與 o3 不同，&lt;strong&gt;o4-mini 是一款輕量級、優化後的高性價比推理模型&lt;/strong&gt;，在計算資源、響應速度與實際效果之間達成了優秀的平衡。&lt;/p&gt; 
&lt;p&gt;亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 和 2025 數學競賽中表現最佳&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在非 STEM 任務（如數據科學）中的表現超越 o3-mini&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數學、編程、圖像識別任務中效率極高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✅ 由於模型本身更輕量，o4-mini 支持更高的調用頻率和更低的成本，非常適合&lt;strong&gt;大批量、多併發、快響應&lt;/strong&gt;的應用場景。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;更自然的人機互動體驗&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;無論是 o3 還是 o4-mini，這一代模型在對話體驗上也有明顯提升。得益於智能水平的增強與網絡信息的集成支持，&lt;strong&gt;兩款模型都能更好地理解用戶意圖，提供可驗證、結構清晰的回答&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持上下文記憶引用，更貼合用戶歷史對話&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令遵循能力增強，響應更精準自然&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;更加個性化、情境感知的交互&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;專家評語摘要&lt;/h3&gt; 
&lt;table style=&quot;min-width:155px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;優勢亮點&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o3&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;推理最強，圖像理解領先，適用於高複雜任務&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o4-mini&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;高性價比，適合大規模調用，非 STEM 場景表現躍升&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;外部專家一致認為，&lt;strong&gt;新模型在可用性、可靠性和語言自然度上均優於前代產品&lt;/strong&gt;，是未來 AI 助手的重要里程碑。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;總結&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI 的 o3 與 o4-mini 的發佈，標誌着 AI 推理模型的又一次躍遷。從性能到體驗，從通用性到多模態理解，它們都展現出前所未有的能力。&lt;/p&gt; 
&lt;p&gt;如果你在尋找一個既能處理複雜問題，又能快速響應且個性化的 AI 模型，這一代產品值得你深入瞭解與使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</guid>
            <pubDate>Mon, 14 Apr 2025 02:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>多模態視覺理解大模型推理優化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div class=&quot;rich_media_content js_underline_content
                       autoTypeSetting24psection
            &quot; id=&quot;js_content&quot;&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;01&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;背景&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 85px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;大模型時代是人工智能領域的一個重要發展階段，在當今人工智能研究領域，基於 Transformer 架構的多模態視覺理解大模型（VLM）在全世界範圍內引發了深度的技術關注。多模態視覺理解大模型的主要創新在於將語言和視覺兩種模態進行有效的對齊，使其不僅能夠進行基本的圖像識別，還能執行基於視覺輸入的動態內容推理和複雜問題解答。可以應用在房內傢俱家電識別、涉黃涉爆檢測、商家店鋪門頭識別等多個場景，相比傳統模型取得更好的效果。但是由於多模態視覺理解大模型的推理性能比傳統模型低，導致整體成本高，嚴重阻礙了多模態視覺理解大模型的推廣。提高多模態視覺理解大模型的推理性能成為研究重點。我們是多模態大模型技術部門，負責多模態大模型相關的模型研發、推理優化和推廣的工作。我們在 58 的多模態視覺理解的項目場景中，對推理框架和模型進行優化，使用多種方法提高多模態視覺理解模型的推理性能。&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;02&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
     &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;場景介紹&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 58 的多模態視覺理解的項目中，都是後台提交任務對圖片進行推理，沒有與用戶進行實時對話的場景，所以目前性能優化的重點是批量輸出的場景。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;場景一：長 token 輸入、短 token 輸出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;多模態視覺大模型輸入的是提示詞+圖片，輸入的 token 通常都比較長，在 58 的場景內，98% 以上的推理場景是輸出短 token，通常在 5 個 token 以內。比如在信安定製數據治理項目中，輸出的 token 是隻有「是」或者「否」。我們重點對這種場景進行性能優化。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;場景二：長 token 輸入、長 token 輸出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;另外 2% 的推理場景是輸出長 token，比如給一張簡歷的 pdf 圖片，讓大模型識別圖片中的內容，輸出的 token 一般是幾百個以上。這種場景的佔比很少，不是性能優化的重點方向。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;03&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;性能指標&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;VLM 推理服務重點關注兩個指標：&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span leaf=&quot;&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;時延&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要從系統的角度來看，即系統在單位時間內能處理的 tokens 數量。由於我們的主要場景是長輸入 token，短輸出 token，所以吞吐量的計算以單位時間內能處理的請求作為衡量指標，即模型推理的 qpm。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;時延：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要從用戶的視角來看，即用戶平均收到每個 token 所需的時間。計算方法為用戶從發出請求到收到完整響應所需的時間除以生成序列長度。一般來講，當時延不大於 50 ms/token 時，用戶使用體驗會比較流暢。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;由&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;於我們的場景都是批量輸出的場景，沒有流式輸出的場景，所以我們重點關注的性能指標是吞吐量。&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;04&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;優化內容&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.1 圖像預處理優化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在多模態推理中 Vision Transformer (ViT) 是一個關鍵的模塊，圖像的預處理是將圖像轉換為適合 ViT 模型輸入數據的過程。主要包括圖像顏色空間轉換、尺寸調整 (Resize)、劃分圖像塊 (Patch Partitioning)、歸一化（Normalize）等步驟。在 LMDeploy 框架中，圖像預處理過程中主要通過 PIL(Pillow) 的 Image 模塊在 CPU 上對圖像進行處理，在圖像 Resize 及 Partition 過程中，效率較低，耗時佔整個 ViT 過程的 20% 以上。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;為了提升系統吞吐能力，減少圖像預處理耗時，我們分別使用 Pillow 與 OpenCV 進行預處理測試，具體表現如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;CPU: Intel(R) Xeon(R) Silver 4410Y&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Python 3.10.12&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Pillow 10.2.0&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;opencv_python 4.8.1.78&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2000 張不同分辨率圖像&lt;/span&gt;&lt;/span&gt; 
       &lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014200&quot; data-ratio=&quot;0.10252996005326231&quot; src=&quot;https://oscimg.oschina.net/oscnet/1bfb0234-fa3d-4e69-ad7e-225bcbe39f01.png&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 1：Pillow 與 OpenCV 預處理耗時對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;使用 OpenCV 可以極大的減少圖像預處理的耗時，平均處理單張圖片的耗時由 23.67ms 減少到 12.03ms，性能提升 49.18%。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 Resize 過程中，雖然兩個處理庫對應的插值方式均使用 BICUBIC，但當圖像進行下采樣時效果存在明顯差異，使用 OpenCV 進行處理的圖像存在波紋。如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014201&quot; data-ratio=&quot;0.5472222222222223&quot; data-s=&quot;300,640&quot; src=&quot;https://oscimg.oschina.net/oscnet/b96df915-b9d8-40bd-ba95-705072874e44.png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 509px;height: 279px;&quot; type=&quot;block&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-size: 15px; text-align: center; cursor: default; line-height: 2em; margin-bottom: 8px; margin-top: 8px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 2：Pillow 與 OpenCV 效果對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;通過對比源碼實現，發現二者在插值與邊界處理實現上有所差異：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;插值計算方式有差異&lt;/span&gt;：二者均使用 4x4 的卷積核進行插值計算，OpenCV 直接使用三次多項式公式計算每個像素的權重，並對周圍 16 個像素進行加權平均；而 Pillow 將三次卷積操作分解為兩個一維卷積，先對水平方向進行卷積，然後再對垂直方向進行卷積。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;邊界處理的差異&lt;/span&gt;：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;OpenCV 供多種邊界處理方式，例如 BORDER_REPLICATE, BORDER_REFLECT, BORDER_WRAP 等；Pillow 通常使用邊界複製的方式進行處理，即邊緣像素值被複制到圖像外部，以避免在邊緣出現偽影。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;針對這個問題，OpenCV 説明文檔中提供了相應的解決方案：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);color: rgb(0, 0, 0);&quot;&gt;To shrink an image, it will generally look best with INTER_AREA interpolation, whereas to enlare an image, it will generally look best with INTER_CUBIC (slow) or INTER_LINEAR (faster but still looks OK).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;於是我們根據不同的圖像採樣對插值方式進行動態調整，對圖像降採樣時，使用 INTER_AREA 插值，上採樣時，使用 INTER_CUBIC(速度較慢，但效果最好)，調整後，Resize 結果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e376a935-28bc-49af-a8c6-cabb4db7286f.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38425925925925924&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; type=&quot;block&quot; data-imgfileid=&quot;100014202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 3：OpenCV 優化前後與&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;Pillow 效果對比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.2 ViT 模塊支持 TensorRT&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;ViT 模塊是多模態推理框架中一個必不可少的組成模塊，主要負責圖像相關處理及編碼工作。ViT 模塊的處理速度，直接影響整個框架的整體推理效率。為了進一步提升框架的推理效率，我們對 ViT 模塊的耗時進行了分塊分析，結果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/7c067863-ae5f-4261-bc0f-f16e4b12bb25.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10119840213049268&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-imgfileid=&quot;100014203&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 4：vision 模型推理耗時及內存佔用情況&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝相關邏輯：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ce4defef-9707-41cd-88e1-c878c4646834.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5291181364392679&quot; data-type=&quot;png&quot; data-w=&quot;601&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;601&quot; data-imgfileid=&quot;100014175&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 5：LMdeploy VIT 階段內存拷貝代碼截圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;經過驗證，內存拷貝耗時主要是等待 GPU 異步處理結果，所以實際上主要耗時模塊為圖像預處理及特徵提取兩部分。具體定位步驟如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;list-style-type: disc;margin-left: 8px;margin-right: 8px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝邏輯修改&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;ul style=&quot;list-style-type: circle;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/vl/engine.py 取消結果拷貝至 cpu 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/serve/vl_async_engine.py 取消拷貝到 cpu 及轉換 numpy 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/pytorch/message.py 中修改 InputEmbeddings 及類型為 Torch.Tensor(GPU)&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
     &lt;/ul&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;內存拷貝邏輯修改引起異常的分析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;邏輯調整後，推理結果異常。在 vl/engine.py forward 增加輸出結果日誌後，推理正常。經驗證輸出結果日誌操作起到同步等待作用，使用 torch.cuda.synchronize() 或者 sleep 驗證猜想正確。後續在模型內增加日誌輸出結果或者以上兩個操作，推理結果均正常。推理結果正常後定位耗時模塊，定位到 ViT 中 extract_feature 為主要耗時模塊。為了進一步提升推理效率，我們借鑑了 TensorRT-LLM 中的推理加速方案 TensorRT。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;TensorRT 是一個高性能的深度學習推理（Inference）優化器，可以為深度學習應用提供低延遲、高吞吐率的部署推理。TensorRT 可對多種應用場景進行推理加速，並且支持 TensorFlow、Caffe、Mxnet、Pytorch 等幾乎所有的深度學習框架。將 TensorRT 和 NVIDIA 的 GPU 結合起來，能在幾乎所有的框架中進行快速和高效的部署推理。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/92358ef8-bc80-4bf8-817c-4301d087eec0.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.486&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014176&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 6：Tensorrt 優化過程圖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在對 ViT 模塊進行 TensorRT 改造時，主要包含模型轉換、模型優化和推理部署三個階段。模型轉化支持 TensorFlow、PyTorch、ONNX 等主流深度學習框架的模型轉換和優化，本文以 ONNX 為例進行説明。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;1、模型轉換&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/be6a8f15-e0da-4080-aeac-586ca6fb9964.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7807308970099668&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;602&quot; data-imgfileid=&quot;100014173&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;ONNX 模型轉換代碼截圖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;導出 ONNX 時可能會遇到不支持的算子，如在導出快速傅裏葉變換（FFT）和快速傅裏葉逆變換（IFFT）時會遇到如下錯誤，&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;Exporting the operator &#39;aten::fft_rfftn&#39; to ONNX opset version 17 is not supported&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;這時需要調整模型網絡結構或者自定義算子。在對 ViT 模塊進行 ONNX 轉換過程中，部分多模態模型的 ViT 中使用了 FlashAttention2 進行注意力加速，而 FlashAttention2 中的 flash_attn_func 是作為獨立的內核實現的，不是 torch.nn.Module 的實例，導致導出器無法捕獲計算圖，如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py:90: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;因此，對 Attention 模塊進行了調整，使用 PyTorch 內部實現的縮放點積注意力（Scaled Dot-Product Attention, SDPA），如下圖，至此模型便可成功轉換成 ONNX 格式。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e60836a9-5141-4603-9d85-270e50fd40be.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5825&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014174&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 8&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;縮放點積注意力 (SDPA) 代碼截圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2、模型優化&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;該階段主要完成模型優化，如下圖所示，在模型優化過程中會完成層間融合，精度校準等。這一步的輸出是一個針對特定 GPU 平台和網絡模型的優化過的 TensorRT 模型，這個 TensorRT 模型可以序列化存儲到磁盤或內存中，存儲到磁盤中的文件為 TensorRT planfile。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/1ef2a7d7-071f-44da-aa1f-150b5e299114.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.224&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014172&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 9：Tensorrt 模型優化及系列化流程圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;3、推理部署&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/8169cdc0-de30-4af8-9617-1e080e14ec9c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2064&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014177&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 10：Tensorrt 部署及推理流程圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署階段將上一個步驟中的 plan 文件反序列化，並創建一個 runtime engine，輸入對應的圖像數據，輸出推理結果。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4、推理效率&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;經過 TRT 加速後，ViT 模塊 feature_extract 速度縮減 45% 左右（不包含圖片預處理），feature_extract 耗時在 ViT 中佔比從 60% 減少至 45.36%，整體推理耗時耗時縮減在 70ms 左右。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.3 ViT 模塊支持 CudaGraph&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;推理框架 lmdeploy 在 0.6.0 版本引入了 CUDA Graph,並提升了近 30% 的推理性能：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;&amp;nbsp;Employ CUDA graph to boost the inference performance (30%)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;不過受多方因素限制，目前 lmdeploy 只在語言模型中引入了 CUDA Graphs。為了進一步提升推理速度，我們在 ViT 模塊中引入了 CUDA Graphs。CUDA Graphs 可以用於優化執行過程中的 CUDA 操作，在 GPU 上實現更加高效的深度學習模型推理。在使用 CUDA Graphs 時需要對 CUDA 操作進行錄製（capture）和重放（replay），以此來減少 CPU 到 GPU 的調度開銷，提高整體的執行效率。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;如下圖，簡單展示了 CUDA Graphs 的優勢。在頂部，CPU 逐個啓動一系列短內核。CPU 啓動開銷導致內核之間出現明顯間隙。如果我們用 CUDA 圖替換此內核序列，最初我們需要花費一些額外的時間來構建圖並在第一次啓動整個圖時一次性啓動整個圖，但後續執行將非常快，因為內核之間的間隙將非常小。當多次重複相同的操作序列時，例如在許多訓練步驟中重複，差異會更加明顯。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac8a403c-ee90-4fe0-81cd-65e63efbb452.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.372&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014178&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 11：CUDA Graphs 性能優勢圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;首先，在 ViT 支持 CUDA Graphs 時，需要 torch.cuda.CUDAGraph 創建對應的圖，然後使用 torch.cuda.graph() 對 ViT 的推理過程進行錄製，在推理過程中，使用剛創建的圖對錄製的過程進行重放 CUDAGraph.play()。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;但是要注意，由於 CUDA Graphs 不支持動態控制流（如條件語句和循環），因此在設計算法時應儘量避免使用這些結構；其次，確保輸入張量的形狀在圖創建時是固定的，因為 CUDA Graphs 的設計是基於靜態形狀的張量結構，創建 Graph 時，所有操作及其輸入輸出的形狀必須在圖創建時確定。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;而 ViT 模塊在進行圖像處理時，輸入的圖像數張量的形狀是 [batch_size, channel, width, height]，其中 batch_size 是可變的且各視覺模型均已限定最大值。於是，我們在框架內部維護了 Graphs Pool，推理時使用 batch_size 索引至相應的 graph，再執行重放操作。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;增加 CUDA Graphs 後 ViT 模塊平均耗時減少 30ms 左右。雖然 CUDA Graphs 可以在一定程度上提升推理的效率，但是在構建 graphs 也需要佔用一些額外的顯存，在使用時需要綜合衡量具體的業務場景及硬件資源。&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.4 圖像 Token 化處理&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;輸入 token 的長度對推理耗時影響很大，多模態模型中，圖像部分佔據了很大比例的 token 數，降低圖像轉換的 Token 數可提升推理性能。如下是結果對比：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/f660d32a-1b9f-4656-98d1-dbecee5fe26c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29894179894179895&quot; data-type=&quot;png&quot; data-w=&quot;378&quot; style=&quot;width: 382px;height: 114px;&quot; data-imgfileid=&quot;100014204&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;圖 12：&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑體, 宋體, sans-serif; font-size: 15px; letter-spacing: normal; background-color: rgb(255, 255, 255); cursor: default; text-align: justify; margin-top: 8px; margin-bottom: 8px; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;Token 數和推理耗時基本成正比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;圖像轉換的 Token 數計算主要流程如下&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;（1）根據圖像寬高比和分辨率大小將原圖拆分成若干個 448*448 的 patch，拆分的原則是儘量保持圖像不失真。拆分代碼如下：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/30811eb3-1df8-4dc0-b6e3-6ea8f054445d.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9367088607594937&quot; data-type=&quot;png&quot; data-w=&quot;869&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014179&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 13：VLLM 中 InternVL2-8B 模型拆圖代碼截圖&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;上述代碼基本流程是，給定動態拆分的閾值範圍，窮舉出所有可能的目標比例，再根據原圖比例匹配最佳的拆分規則，拆分邏輯圖示如下圖左上部分，圖示中會被拆分成 6 個 path 塊和一張縮略圖。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b84a37b-1304-4f2d-84ad-324785e09a4b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.526&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014180&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;圖 14&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;InternVL 模型整體框架圖&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（2）一個 448*448 的 patch 生成的 token 數計算方式如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);font-weight: normal;&quot;&gt;image_tokens_per_patch=(force_image_size // patch_size)**2 * (downsample_ratio**2))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;force_image_size=448,patch_size=14,downsample_ratio=0.5,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;這個計算後結果為 256。不同的模型值可能會有所差異。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（3）分辨率為 896*1344 的圖像，經過步驟 1 處理，會拆分成 2*3=6 個 patch，再加上一張縮略圖（可選，有效果會更好），最終堆疊後 shape 是[7,3,448,448]，圖像轉換的 token 數為 7*256=1792。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署到線上時，單卡吞吐量上不去，其中一個原因是拆圖規則導致拆分後的圖片數量比較多，如分辨率 612*464，最合適的寬高比是 (4, 3)，按模型的圖片拆分規則，圖像將被拆分成[13,3,448,448]，轉化後的 token 數達到 3328，再加上 prompt 的 token，總 token 數會達到 3400+，太長的輸入 token 對模型推理速度影響很大，再加上顯存和算力的限制，無法做到更大 batch 的推理，使得單卡推理的吞吐量很低。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;基於此原因，我們的優化思路是降低圖像的總 token 數，經實驗分析，官方代碼在實現上存在比較大的冗餘設計，如圖像分辨率為 480*360，也會轉換成 3328 個 token 數，對於低分辨率圖像生成太多的 token 存在資源浪費。在保持圖像內容不拉伸前提下，對圖像的寬高比做調整，以適應 vit 的要求，優化後，480*320 的圖像只轉換成 512 個 token 數，這樣在推理時能做到更大的 batch 處理。在我們實際落地場景中，處理後吞吐量能提升 1 倍。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.5 prefixcache 在多模態模型裏應用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;在&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;PagedAttention 中，KV Cache 只是在一個請求內複用，而沒有做到跨請求的 KV Cache 複用。長 prompt 的場景，prompt 在不同的請求中是相同的，KV Cache 的計算也是相同的，如果能把 prompt 的 KV Cache 保存下來，留給後續的請求複用，將會極大地降低首 Token 的耗時。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;在 LLM 模型裏，prefixcache 分二個階段，第一個階段，當 prompt 第一次被推理時，是按 block_size(通常是 64) 大小對 input tokens 從前往後進行分塊，計算每個分塊的 hash 作為唯一標識，每個分塊的 token_id 作為 key 進行緩存，這裏不足 block_size 長度的塊不會被緩存；第二階段，當新 prompt 被推理時，會進行 prefix cache matching，命中就直接複用 kvcache，只計算未命中部分的 input tokens。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;多模態模型區別在於，一次任務的輸入 tokens 組成由純文本變成了文本+圖片，由 system+prompt 變成了 system+image+prompt，在計算 prefix cache 時，image 對應的只是 padding tokens，那麼在計算 prefix cache matching 時，不同圖片可能匹配到一樣的 prefix 上，這樣推理結果就會出現錯誤。針對這個問題，在 input tokens 中對 image 進行範圍標記，在計算 prefix cache 時不對 image token 進行 kvcache，只 cache image 之前的部分；在 prefix cache matching 時，也同樣保證 image token 不會被複用。經實驗驗證，修改後能保證在開啓 prefix cache 時，推理結果是正確的。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;需要注意，Prefix Caching 只節省了 prefill 階段的耗時（也就是降低了 TTFT，Time To First Token），並不能節省解碼階段的耗時（也就是 TPOT，Time Per Output Token）。如果請求的主要耗時是在解碼階段（例如 prompt 很短而 completion 很長），或者多個請求的 prompt 並沒有公共的前綴，那麼 Prefix Caching 就對於整個 LLM 推理的性能提升幫助不大&lt;/span&gt;。&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.6 模型量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化是大模型領域中的一項關鍵技術，它通過降低模型參數的精度，將浮點數轉換為整數或定點數從而實現模型的壓縮和優化。模型量化可以減少模型尺寸，進而減少在推理時的顯存消耗，並且在一些低精度運算較快的處理器上可以增加推理速度。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化分很多情況。從量化對象來説，量化可以是權重、激活、kv cache 和梯度；從量化的形式上來説分為線性量化和非線性量化，其中線性量化又分為對稱量化和非對稱量化；根據應用量化壓縮模型的階段，又可以將模型量化分為量化感知訓練、量化感知微調、訓練後量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;我們現階段使用的量化方式是 AWQ 和 GPTQ，這兩種量化都屬於訓練後量化，是針對權重的線性量化，其中 AWQ 採用對稱量化，GPTQ 採用非對稱量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;AWQ 量化的原理是對於 LLM，權重不是同等重要的，通過保留 1% 的顯著權重可以大大減少量化誤差。在此基礎上採用激活感知的方法，考慮更大的激活幅度應該對應更重要的權重通道，在處理重要特徵時起關鍵作用，逐通道確定最佳縮放因子。從而在量化所有權重的同時，最小化量化誤差。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;GPTQ 對模型的每一層（通常是線性層或卷積層）進行單獨處理，考慮了量化帶來的誤差，並通過調整未量化的權重來補償這些誤差。利用了二階偏導 Hessian 矩陣的逆，來指導權重的調整，以減少整體的量化誤差。將權重矩陣分成多個子矩陣（block），對每個子矩陣中的權重逐個進行量化，同時調整同一子矩陣內其他權重，以保持模型輸出的相似性。其量化後的誤差依賴一份高質量的校準數據。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;整體上來看，AWQ 相較於 GPTQ 量化的算法更直接，對校準數據依賴小；GPTQ 則更容易有比較好的量化效果，但是算法相對複雜，對校準數據依賴比較大，實際過程中用哪個更合適需要根據實際的場景選用。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在實際測試中，不論是 AWQ 還是 GPTQ 實際採用的都是 w4A16 的量化策略，在推理的時候，性能差異比較小，在 RTX4090 顯卡下，我們使用 vllm，對應不同參數，並且設置最優 batch，實際測試值如下：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;針對單個請求的延時：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac7dd996-e553-40fb-b9a8-4832f70c1a3b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2084507042253521&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;710&quot; type=&quot;block&quot; data-imgfileid=&quot;100014210&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 15: 原始模型和量化模型的推理耗時比較&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;從測試結果看：在 4090 下，大 batch 的計算，使用 gemm 內核，速度不如原精度，原因是在大 batch 的情況下，增加了反量化的時間。使用 marlin 內核，計算的速度有優化，但是在大 batch 下，優化速度不明顯。低 batch 的計算原精度是計算最慢的，gemm 的內核計算與 marlin 計算差別不是很大，都比原生的有大幅提高。原因是 gemm 在低 batch 下，也做了內核優化，這一點可以從原代碼中驗證：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/89dafcc6-de64-4e34-b8ac-72982e9aeb04.png&quot; class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30575035063113604&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;713&quot; type=&quot;block&quot; data-imgfileid=&quot;100014211&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 16&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;VLLM 中 awq 量化模型 mul 計算邏輯代碼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: left;line-height: 2em;&quot;&gt; 
    &lt;span leaf=&quot;&quot;&gt;針對吞吐量：&lt;/span&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/c2d58729-66c8-42cd-ad10-c69be338f6b4.jpg&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.15281501340482573&quot; data-s=&quot;300,640&quot; data-type=&quot;webp&quot; data-w=&quot;746&quot; data-croporisrc=&quot;https://oscimg.oschina.net/oscnet/22f3d6f2-bfb2-465f-9504-408778ea5dbd.jpg&quot; data-cropselx2=&quot;578&quot; data-cropsely2=&quot;120&quot; data-imgfileid=&quot;100014212&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 17：原始模型和量化模型的吞吐量比較&lt;/span&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;從測試結果看，對於短輸出，其實吞吐量並沒有優化，還下降了一點，原因是，對於短輸出，主要的耗時在 prefill，prefill 是大 batch 的計算，在推理過程中，吞吐量會下降。但是對於長輸出，decode 階段佔比比較高，內核對於 decode 的優化比較明顯，綜合吞吐量會上升。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;總結：在實際使用中對於 W4A16 量化後的模型來説，模型佔用的顯存一定能節省。但是推理的整體性能和吞吐量，需要根據不同的任務特點，部署的硬件環境，調整部署的參數，以達到最優。而不是量化後的整體性能一定會優於未量化的模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;05&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp; 優化數據&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;評測模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：InternVL2-8B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;數據集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：信安羣租房檢測 4524 張圖片&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;提示詞&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：圖中有 3 張以上的牀，或者是有雙層牀，請直接給出是或者否，然後給出詳細的解釋。注意 1 張雙層牀有 2 張牀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;輸出 token 數量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：max_tokens=1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;GPU&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;: RTX4090&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;對比框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;優化框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0 優化版本&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;吞吐量：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;由於我們的場景是長輸入 token 和短輸出 token，所以按單位時間內處理的請求數作為衡量指標。比較兩個框架的推理 QPM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/1b84899b-305c-4427-8131-5600a10b72b8.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1893687707641196&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; data-imgfileid=&quot;100014207&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p data-pm-slice=&quot;0 0 []&quot; style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;圖 18：LMDeploy-0.6.0 優化前後召回率和吞吐量比較&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;LMDeploy-0.6.0 優化版本在推理效果不受影響的情況下，吞吐量提升到 LMDeploy-0.6.0 版本的 3.05 倍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;作者簡介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;徐海芳、李海洋、朱辰、張輝，MPai 平台視覺理解大模型推理團隊&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;font-size: large;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/section&gt; 
  &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑體, 宋體, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;display: none;&quot;&gt; 
  &lt;mp-style-type data-value=&quot;3&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color: #858585; font-size: 13px;&quot;&gt;本文分享自微信公眾號 - 58 技術（architects_58）。&lt;br&gt;如有侵權，請聯繫 support@oschina.cn 刪除。&lt;br&gt;本文參與「&lt;a href=&quot;https://www.oschina.net/sharing-plan&quot; target=&quot;_blank&quot;&gt;OSC 源創計劃&lt;/a&gt;」，歡迎正在閲讀的你也加入，一起分享。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5359019/blog/18160034</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5359019/blog/18160034</guid>
            <pubDate>Mon, 14 Apr 2025 02:30:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>《流浪地球 3》發佈 AI 問答應用 WEi</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;電影《流浪地球 3》近日在青島舉行開機儀式，郭帆導演攜主創團隊齊聚亮相。在開機儀式現場，《流浪地球 3》劇組正式發佈劇組專屬的自研 AI 問答應用 WEi。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;365&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b58e821f644cfcd13feb137d9d2cac2428.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該應用依託大語言模型，基於 DeepSeek R1 大語言模型，NVIDIA、火山引擎作為「AI 支持合作伙伴」所開發，本地推理部分由 NVIDIA GeForce RTX 5090 D 加速，旨在為劇組提供一站式智能服務，大幅提升劇組創作效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，WEi 通過整合多元化知識庫資源，包括在線信息源的專業資料、圖像和影視參考，以及電影《流浪地球》系列劇本、世界觀、編年史、人物小傳、美術設定等內部資料，為劇組工作人員提供高效檢索通道，同時期望在參考信息上既符合科學基礎又保持設定一致性，提高劇組工作人員創作效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345026</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345026</guid>
            <pubDate>Mon, 14 Apr 2025 02:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 擬以 30 億美元收購 AI 編程工具 Windsurf</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社報道稱，OpenAI 正與人工智能輔助編程工具 Windsurf（前身為 Codeium）展開收購談判，交易金額約為 30 億美元。這一潛在收購將成為 OpenAI 迄今為止最大規模的併購交易，標誌着其在 AI 驅動的開發者工具市場邁出重要一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5591fcd5e926e90d56e1521a2184484a0b3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Windsurf 是一款廣受開發者歡迎的 AI 編程助手，能夠基於自然語言提示生成代碼、解釋現有代碼並執行相關任務。它不僅支持通過插件嵌入主流代碼編輯器（如 Visual Studio Code），還提供專為 AI 輔助開發設計的自定義編輯器。Windsurf 自稱是首款「代理式」集成開發環境 (IDE)，強調其在自動化和智能化編程流程中的獨特優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;成立於 2021 年的 Windsurf（正式名稱為 Exafunction Inc.）已累計融資超 2 億美元，投資者包括 General Catalyst、Kleiner Perkins 和 Greenoaks Capital Partners。2023 年，其在 General Catalyst 領投的 1.5 億美元融資中估值達 12.5 億美元，而近期與投資者的談判顯示其估值已升至 30 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;X 平台上的討論顯示，業界對此次收購的反應複雜而熱烈。一方面，許多開發者對 OpenAI 整合 Windsurf 的前景表示期待，認為這可能帶來更強大的 AI 編程工具;另一方面，部分觀點擔憂收購可能對其他 AI 編程工具（如 Cursor）造成衝擊，尤其是考慮到 OpenAI 此前通過其創業基金投資了 Cursor 的母公司 Anysphere。此外，微軟近期對 Visual Studio Code 生態的收緊政策可能為 OpenAI 的收購策略帶來變數。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，Windsurf 近期向用戶發送郵件，宣佈因「本週晚些時候的重大公告」而提供鎖定 10 美元/月價格的機會，這一舉動被外界解讀為收購談判的間接證據。然而，交易條款尚未最終敲定，談判仍存在變數或破裂的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次收購若達成，將成為 OpenAI&amp;nbsp;最大規模的併購交易。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345019</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345019</guid>
            <pubDate>Mon, 14 Apr 2025 02:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>xAI 發佈新 AI 工具 Grok Studio：可生成文檔、代碼和瀏覽器遊戲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;xAI 宣佈為旗下 AI 聊天助手 Grok 增加全新功能 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgrok%2Fstatus%2F1912318583532872166&quot; target=&quot;_blank&quot;&gt;Grok Studio&lt;/a&gt;，可以用於編輯和創建文檔，以及基礎應用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19a1c88ab76742bcfab01237646b8b0dc40.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Grok Studio 將在一個單獨的窗口中打開，支持生成文檔、代碼、報告和瀏覽器遊戲。&lt;/p&gt; 
&lt;p&gt;生成代碼時，Grok Studio 會在「預覽」選項卡中快速向用戶展示其運行效果。HTML 代碼片段可以運行 Python、C++、JavaScript、Typescript 和 Bash 腳本，也可以在此預覽選項卡中查看。所有新項目都會在 Grok 回覆的右側打開。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1424&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/194259_TbOH_2720166.png&quot; width=&quot;1940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;xAI 表示，免費和付費的 Grok 用戶都可以在 Grok.com 上使用該功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344972/xai-grok-studio</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344972/xai-grok-studio</guid>
            <pubDate>Sun, 13 Apr 2025 11:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊「元寶」可添加為微信好友：一鍵解析公眾號文章、甚至把它置頂</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;就在剛剛，騰訊 AI 助手「元寶」支持添加為微信好友進行聊天。 &amp;nbsp;你可以和他對話，也可以發鏈接、文件給他——甚至可以把它置頂 。&lt;/p&gt; 
&lt;p&gt;如下圖，在微信直接搜索「元寶」，點擊「聊天」進入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/190446_4eYx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191425_HCo3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1592&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190642_X4B1_2720166.png&quot; width=&quot;806&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;978&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190707_Op4X_2720166.png&quot; width=&quot;814&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，這是騰訊元寶 APP 入駐微信的 AI 助手，搭載了混元和 DeepSeek 雙模引擎，可一鍵解析公眾號文章和任何圖片和文檔，短評後會發送詳解文章，支持對解讀內容做各種智能互動，支持陪伴互動。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191518_XlEd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1662&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/191457_Jiq2_2720166.png&quot; width=&quot;764&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344970</guid>
            <pubDate>Sun, 13 Apr 2025 11:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國團隊自研 AI 圖像生成大模型 HiDream-I1 正式開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;HiDream 智象未來團隊宣佈正式開源圖像生成大模型 HiDream-I1 與交互編輯模型 HiDream-E1。&lt;/p&gt; 
&lt;p&gt;HiDream-I1 在權威榜單 Artificial Analysis 中 24 小時內&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ouXGp3kyyT7AfFmQ_Y5Cw&quot; target=&quot;_blank&quot;&gt;登頂&lt;/a&gt;&lt;/u&gt;，成為首個躋身全球第一梯隊的中國自研生成式 AI 模型，並在圖像質量、語義理解、藝術表現三大維度刷新行業紀錄，實現圖像的多風格生成，涵蓋動漫、肖像、科幻等場景。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;984&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/183653_vhQa_2720166.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，設計工具 Recraft 已集成 HiDream 模型，用戶 3 步即可實現 「一鍵出圖 + 智能編輯」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175700_50WE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1&amp;nbsp; 已開源三個版本的模型，分別是：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175710_8HLD_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中 HiDream-I1-Full 是由 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhidreamai.com%2Fhome&quot; target=&quot;_blank&quot;&gt;HiDream.a&lt;/a&gt;i 團隊發佈的開源圖像生成基礎模型，具備 170 億參數，旨在實現高質量的圖像生成。該模型採用 Diffusion Transformer（DiT）架構，支持多種風格的圖像生成，包括寫實、卡通、藝術等，適用於多種創作場景。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心特性&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;卓越的圖像質量&lt;/strong&gt;：在多個基準測試中表現出色，HPS v2.1 平均得分為 33.82，優於 SDXL、DALL·E 3 等主流模型&amp;nbsp;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;強大的提示詞理解能力&lt;/strong&gt;：在 GenEval 和 DPG-Bench 等評測中，HiDream-I1 的表現優於其他開源模型，展示了其在理解和執行復雜提示詞方面的能力。騰訊網+1 阿里雲開發者社區-雲計算社區-阿里雲+1&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;開源且商業友好&lt;/strong&gt;：採用 MIT 許可證，允許用戶在個人、科研和商業項目中自由使用生成的內容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能評估&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在多個評測中，HiDream-I1 展示了其強大的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DPG-Bench&lt;/strong&gt;：在整體、實體、屬性等多個維度上得分領先，展示了其在圖像生成質量方面的優勢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GenEval&lt;/strong&gt;：在單目標、雙目標、計數、顏色等任務中表現優異，反映了其對提示詞的準確理解和執行能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HPS v2.1&lt;/strong&gt;：在動畫、概念藝術、繪畫、照片等風格的圖像生成中，HiDream-I1 的得分均高於其他主流模型，展示了其多風格生成的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175722_YQIr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175731_9IFw_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175741_2jbr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1-Full 模型整體採用 MIT 協議開源，可自由商用，但部分依賴組件（如 LLaMA3 編碼器）需遵守各自協議，商用前應留意其具體限制。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344955</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344955</guid>
            <pubDate>Sun, 13 Apr 2025 09:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節 AI Lab 將全部併入 Seed</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 科技評論獨家獲悉，字節 AI Lab 即將全部收歸 Seed 團隊下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節 AI Lab 是 Seed 成立之前字節主要的 AI 研發部門，目前由李航管理，自 2024 年開始向 Seed 時任負責人朱文佳彙報。今年 2 月下旬，原 Google DeepMind 副總裁吳永輝入職字節，成為 Seed 基礎研究負責人。此後李航的彙報對象變為吳永輝。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節 AI Lab 成立於 2016 年，最初由微軟亞洲研究院前常務副院長馬維英負責，直接向張一鳴彙報。 AI lab 目前有多個子團隊，包括機器人、AI4S 等方向，幾乎覆蓋人工智能領域所有前沿技術研究。2018 年其團隊規模達到 150 人，為字節跳動 AI 研究的核心部門。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Lab 主要研究重點是開發為字節跳動內容平台服務的創新技術，字節推薦算法、短視頻特效等功能均脫胎於此。其研究成果應用於今日頭條、抖音等產品，是支持抖音成長為國民級應用的基石，並奠定了當時字節在國內 AI 領域的領先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着抖音、TikTok 佔據絕對優勢的市場地位，流量商業化成為字節面臨的 Top 級問題，AI Lab 在字節內部重要性下降。2020 年，AI Lab 定位從集團級前瞻性項目轉為技術中台，為字節商業化團隊業務提供支持，馬維英的彙報對象也從張一鳴變為抖音負責人張楠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2020 年年中，馬維英離開字節，AI Lab 負責人一職由李航接任至今。之後團隊重組，2023 年開始，AI Lab 下屬負責大語言模型的 NLP 組及開發視頻生成模型的 PixleDance 被先後轉入 Seed 之下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時為了應對新一輪大模型競爭，字節決定迴歸「始終創業」的價值觀，建立獨立的新組織，於是加快籌建了獨立於原有組織架構的 Flow 和 Seed，前者做 AI 產品，後者做大模型研發。截至 2023 年底，兩者已成為與抖音、TikTok、火山引擎等字節各大業務平級的組織。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Seed 自成立就在不斷吸納來自字節內外的人才。除收攏搜索、AML、AI Lab 等內部部門中大模型方向人才外，對外也在積極爭搶人才。以面向應屆博士的 Top Seed 招募計劃為例，字節會給優秀候選人 3-1 職級，薪資不低於百萬元。截至 2024 年底，字節 AI 研究者中超 40％比例是近兩年加入的新人，對人才的渴求和重視程度可見一斑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據 AI 科技評論調查，加入字節以來，吳永輝已在字節署名三篇論文，均在強化學習方向。吳永輝於上月在 Seed 內部新建虛擬小組、縮短了彙報流程，創建一個更扁平的彙報體系，此次 AI Lab 將全部併入 Seed，也是吳永輝調整內部組織架構的一個重要舉措。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344946</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344946</guid>
            <pubDate>Sun, 13 Apr 2025 09:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Notion Mail 正式發佈：AI 驅動郵箱新體驗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Notion 正式推出電子郵件服務 Notion Mail，首發登陸 macOS 平台，iOS 和 Android 版即將上線。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1140&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/165124_3l5R_2720166.png&quot; width=&quot;2124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 並非要取代 Gmail，而是作為重新設計的郵箱前端，提供獨特的郵件管理體驗。其核心為高度模塊化系統，用戶可自定義收件箱配置，並整合了豐富的 AI 功能，如智能文件夾、自動分類、快速回復、寫作改進及智能會議安排等。產品與 Notion Calendar 無縫銜接，核心 AI 功能提供免費使用限額，無限制需訂閲付費。目前僅支持英文，未來將擴展至 13 種語言。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/165012_T6gr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 主頁：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail&lt;/a&gt;&lt;br&gt; 下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail%2Fdownload&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail/download&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344936/notion-mail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344936/notion-mail</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>