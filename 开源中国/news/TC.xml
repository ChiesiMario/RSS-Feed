<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 11 Sep 2025 07:44:57 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>騰訊開源圖檢索增強生成框架 Youtu-GraphRAG</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;騰訊優圖實驗室開源了 Youtu-GraphRAG，這是一個全新的圖檢索增強生成框架，旨在通過大語言模型+RAG 模式，將知識組織成圖譜，再交給大語言模型進行檢索和推理，從而提高模型在處理複雜問答任務時的準確性和可追溯性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 特別適用於企業知識庫問答、科研文檔解析、個人知識管理等知識密集型場景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 通過三大創新實現了從圖構建到索引、再到檢索的垂直統一和認知閉環。首先，它採用了四層知識樹結構，將知識拆解成屬性、關係、關鍵詞和社區四個層次，使得大模型在回答問題時能夠沿着知識樹定位信息，推理路徑清晰可見。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;其次，社區檢測升級不僅關注「誰和誰有關」，還結合語義理解「為什麼它們有關」，生成簡明摘要，幫助用戶快速抓住問題本質。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最後，智能迭代檢索機制允許用戶提出複雜問題時，將其拆解成多個子問題並行檢索，並通過迭代反思機制對結果進行補充和修正，最終給出更完整、更可靠的回答。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="314" src="https://oscimg.oschina.net/oscnet/up-ab798039306f65590d7249203cb4394d0d9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Youtu-GraphRAG 在實踐檢驗中表現出色。在六個&lt;span&gt;權威&lt;/span&gt;基準測試中，&lt;span&gt;最高&lt;/span&gt;可節省 90.71% 的 Token 成本，複雜推理任務的準確率&lt;span&gt;最高&lt;/span&gt;提升 16.62%。此外，該框架支持中英文雙語，跨領域應用無需重構，具有很高的靈活性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;使用 Youtu-GraphRAG 非常簡單，只需四步即可上手。首先，通過命令行獲取項目代碼。其次，進行環境配置，包括獲取遠程調用模型的憑證 API key 並創建配置文件。然後，一鍵部署項目。最後，通過 curl 命令體驗交互。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371566</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371566</guid>
      <pubDate>Thu, 11 Sep 2025 07:30:33 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動發佈開源多模態模型 Mini-o3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字節跳動發佈開源多模態模型 Mini-o3，通過擴展推理模式和交互輪次提升視覺搜索性能，在複雜場景中實現顯著突破。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/151240_xzZ9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://mini-o3.github.io/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Mini-o3 是一個完全開源的多模態模型，專為「邊看邊想」的視覺搜索任務設計。它通過強化學習將工具調用次數擴展到數十輪，在 VisualProbe、V* Bench、HR-Bench、MME-Realworld 等基準上取得了 7B 量級的最佳成績。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a111377d25b371aba3ccf675445d406ca6b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71b6b52f2c739864eda55692e83e9bbe7ce.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;項目公開了訓練代碼、模型權重以及包含 4,500 條數據的 Visual Probe 數據集，允許研究者在非商業許可下復現 OpenAI o3 風格的深度推理行為。&lt;/p&gt; 
&lt;p&gt;Mini-o3 支持深度優先搜索、試錯等多樣化推理模式，測試時交互輪次可擴展至 32 輪以上，準確率隨輪次增加顯著提升（如 VisualProbe-Hard 任務準確率從 35.1% 提升至 48.0%）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心創新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;挑戰性數據集構建&lt;/strong&gt;：推出 VisualProbe 數據集，包含高分辨率圖像、小目標和密集幹擾物場景，強制模型進行多輪探索。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迭代數據收集&lt;/strong&gt;：通過冷啓動數據生成多樣化推理軌跡，覆蓋回溯、假設驗證等策略，解決預訓練模型缺乏多輪交互能力的問題。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Over-Turn Masking 策略&lt;/strong&gt;：在強化學習中避免對超輪次響應的懲罰，支持模型深度探索，訓練時輪次上限設為 6 輪，測試時可擴展至 32 輪以上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;應用案例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-32f28f4c28db5eb7a911b5d6fe714e2b11b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371562</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371562</guid>
      <pubDate>Thu, 11 Sep 2025 07:19:33 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥智能植物收割？能割韭菜不？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2195</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2195</guid>
      <pubDate>Thu, 11 Sep 2025 07:04:33 GMT</pubDate>
    </item>
    <item>
      <title>🔥🔥AI 能打造盲人的第三隻眼？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2194</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2194</guid>
      <pubDate>Thu, 11 Sep 2025 07:04:33 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio 2026 Insiders 預覽版發佈：深度集成 AI、界面設計煥然一新</title>
      <description/>
      <link>https://www.oschina.net/news/371552/visual-studio-2026-insiders</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371552/visual-studio-2026-insiders</guid>
      <pubDate>Thu, 11 Sep 2025 06:50:45 GMT</pubDate>
    </item>
    <item>
      <title>9 月線下活動彙總</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;9 月 13 日，廣州，Solar 開發者咖啡&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;👨‍💻熟悉的開發者咖啡活動迴歸，這次搬到了廣州！這也是 Solar 第一次在廣州舉辦社區活動，嘗試在大灣區佈局更多站點。期待開發者們的加入！&lt;/p&gt; 
&lt;p&gt;🗓️時間：9 月 13 日，週六 14:30-18:00&lt;br&gt; 📝現在報名 https://luma.com/xhki98ic&lt;/p&gt; 
&lt;p&gt;分享主題：&lt;/p&gt; 
&lt;p&gt;- Solana 歷史、POH 機制、開發差異；&lt;br&gt; - Solana 現在的開源生態、技術、項目；&lt;br&gt; - 基於 Blinks 開發所用的技術、需求分析、商業模式和收穫；&lt;br&gt; - Solar.zens.one, Solar 的項目導航&lt;br&gt; - Solana DeFi 生態現狀和創新&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 13–14 日，杭州，RustChinaConf 2025 x Rust Global China&lt;/h4&gt; 
&lt;p&gt;今年正值 Rust 誕生 10 週年 🎉&lt;br&gt; 👉 講師陣容全面升級，海外講師議題比例高達 45%！&lt;br&gt; 👉 Rust Foundation 團隊將首次現場參與交流！&lt;br&gt; 👉 國內大廠創業公司紛紛加入，瞭解 Rust 語言的最近進展&lt;br&gt; 👉 現場設有 Rust 十週年慶典與特別大禮包&lt;/p&gt; 
&lt;p&gt;🔎 查看完整議程： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frustcc.cn%2F2025conf%2Fschedule.html" target="_blank"&gt;https://rustcc.cn/2025conf/schedule.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🎟️ 立即購票： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhangzhou2025.gosim.org%2Ftickets%2F" target="_blank"&gt;https://hangzhou2025.gosim.org/tickets/&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 14 日，成都，聚焦 Kiro：體驗下一代 Agentic IDE&lt;/h4&gt; 
&lt;p&gt;生成式 AI 正在重構開發流程，AI Agent 成為人機交互新核心！亞馬遜雲科技成都 User Group 技術沙龍邀您共同探索最前沿的 Agentic 實踐。&lt;/p&gt; 
&lt;p&gt;🔍 聚焦 Kiro：體驗下一代 Agentic IDE，基於 MCP 協議重塑開發環境&lt;br&gt; 🧠 依託 Amazon Bedrock：構建與部署高效 AI Agent（如 Strands Agents）&lt;br&gt; 🛠 實戰指引：掌握亞馬遜雲科技 Builder Cards 中文版，加速生成式 AI 應用開發&lt;/p&gt; 
&lt;p&gt;立即報名，攜手邁進智能體驅動開發的新時代！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1mqqg_M34zzVig1QZl0KCg" target="_blank"&gt;https://mp.weixin.qq.com/s/1mqqg_M34zzVig1QZl0KCg&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，成都，Gitee Talk | 模力方舟 AI 應用開發沙龍&lt;/h4&gt; 
&lt;p&gt;📅 9 月 20 日（下週六）13:30-17:00&lt;br&gt; 📍 成都春熙路 voco 酒店（3 號線春熙路 E1 口出直達）&lt;/p&gt; 
&lt;p&gt;✨ 聚焦 AI 開發全鏈路：從模型調用、開源實踐、3D 交互到硬件選型，5 大實戰議題，帶你突破技術邊界！&lt;br&gt; 🙌 現場和大咖交流互動、結識技術同頻人，開源老傳統披薩暢吃，抽模力方舟千元代金券和更多驚喜好禮～&lt;/p&gt; 
&lt;p&gt;🚀 立即報名，鎖定席位：&lt;a href="https://www.oschina.net/event/8598033"&gt;https://www.oschina.net/event/8598033&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，合肥，架構師的 AI 進化論&lt;/h4&gt; 
&lt;p&gt;🚀「架構師的 AI 進化論——從架構升級到行業應用」騰訊雲架構師技術沙龍 · 合肥&lt;/p&gt; 
&lt;p&gt;🤔AI 時代，架構師是被替代？被重構？還是——主動進化？&lt;/p&gt; 
&lt;p&gt;🌟下週六（9 月 20 日）14:00，相約合肥！與多位一線專家面對面，全程硬核乾貨，深入 AI 架構實戰經驗與前沿思考，千萬不要錯過！&lt;/p&gt; 
&lt;p&gt;🎁 現場還有鵝廠限定周邊、公仔、定製好禮抽獎送不停，戳鏈接免費報名👇&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmc.tencent.com%2FD91JjaK9" target="_blank"&gt;https://mc.tencent.com/D91JjaK9&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_6"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，青島，奇妙 AI 之旅&lt;/h4&gt; 
&lt;p&gt;免費參與，0 門檻入場！&lt;br&gt; 這是一個真正能帶走方案、解決實際問題的 AI 實戰工作坊！💡&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;聚焦真問題，挖掘問題痛點；&lt;/li&gt; 
 &lt;li&gt;一起頭腦風暴，打破思維限制；&lt;/li&gt; 
 &lt;li&gt;快速搭建方案原型，讓想法能實實在在被看到；&lt;/li&gt; 
 &lt;li&gt;多方面驗證，直到拿出可落地的方案；&lt;/li&gt; 
 &lt;li&gt;現場路演，讓 AI 創新方案被看到。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;👉🏼立即報名：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F9823342171500%3Fcoupon%3D88ab88" target="_blank"&gt;https://www.huodongxing.com/event/9823342171500?coupon=88ab88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;全程邊玩邊掌握 AI 技能，更有 3000 元獎金🧧等你來拿～&lt;/p&gt; 
&lt;p&gt;外地朋友別猶豫！機票 / 車票報銷名額等你來抽！&lt;/p&gt; 
&lt;span id="OSC_h4_7"&gt;&lt;/span&gt; 
&lt;h4&gt;9 月 20 日，上海，PyCon China 2025&lt;/h4&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;1 個主會場 + 4 個分會場 + 開源松 + Vibe Coding 黑客松 + 社區開源集市展&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;彙集國內外 Python 領域專家與實力開發者，立足 AI 新紀元，&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;為大家呈現一場豐富、精彩、趣味，且充滿活力的 PyCon 盛會。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;開創性地帶來首屆 PyCon China Vibe Coding 黑客松大賽&lt;/span&gt;。&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;活動詳情：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FDfU9DaqCMT5nDgHufzzaNw" target="_blank"&gt;https://mp.weixin.qq.com/s/DfU9DaqCMT5nDgHufzzaNw&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18691462</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18691462</guid>
      <pubDate>Sun, 07 Sep 2025 06:37:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>網信辦副主任王京濤：促進軟件生態、開源代碼等自主生態構建</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;中央網信辦副主任、國家網信辦副主任王京濤在《新安全》雜誌上撰文表示，今年是「十四五」規劃收官之年、「十五五」規劃謀篇佈局之年，也是進一步全面深化改革的重要一年。&lt;/p&gt; 
&lt;p&gt;網絡安全工作機遇與挑戰並存，要以更大力度、更實舉措加快推進國家網絡安全體系和能力現代化，推動我國網絡安全事業發展邁上新台階。進一步建立安全可信的供應鏈安全管理體系。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0911/143425_K3L6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://mp.weixin.qq.com/s/b-rPE4C9CD9-5IEJ7odAXA&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;圍繞集成電路、基礎軟件、人工智能、量子信息等重點領域，加強產業鏈協同創新，加快推動關鍵核心技術研發突破。充分發揮我國超大規模市場優勢，促進軟件生態、開源代碼等自主生態構建，推動人工智能等技術在產業應用上取得更大突破。充分發揮網絡安全審查、雲計算服務安全評估、新技術新應用安全評估等制度機製作用，防範網絡安全風險，提高供應鏈安全水平。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371539</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371539</guid>
      <pubDate>Sun, 07 Sep 2025 06:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Tools 4.32.0 發佈，Spring 開發工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Spring Tools 4 是由 Spring 團隊打造的 Spring 開發工具，從零開始構建，融合了現代技術和開發者工具架構。它在單獨的進程中運行，從構建之初就考慮到了性能問題，並且支持最新的 Spring 技術，為開發基於 Spring 的企業應用提供世界級支持。同時，全新版本的 Spring Tools 與 IDE 無關，可在各種編碼環境中使用，支持 Eclipse、Visual Studio Code 與 Theia。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Spring Tools 4.32.0 現已&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2025%2F09%2F10%2Fspring-tools-4-32-0-released" target="_blank"&gt;發佈&lt;/a&gt;，&lt;span style="background-color:#ffffff; color:#000000"&gt;這是一個維護版本。目前，Spring Tools 4.x 產品線暫無計劃發佈其他維護版本，&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Spring Tools 5 將於 2025 年 11 月下旬發佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;具體更新內容包括：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;updates to the Spring Tools for Eclipse distribution&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;已更新至 Eclipse 2025-09 版本（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Feclipseide.org%2Frelease%2Fnoteworthy%2F" target="_blank"&gt;新增功能與亮點&lt;/a&gt;）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所有修復和改進的詳細信息&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;(Spring Boot) [backport to 4.x] [aot repositories]&amp;nbsp;適配更名規範變更&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-tools%2Fissues%2F1622" target="_blank"&gt;#1622&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;(Spring Boot) PostgreSQL 語法高亮無法識別 &amp;nbsp;jsonb question mark (?)&amp;nbsp;運算符&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-tools%2Fissues%2F1615" target="_blank"&gt;#1615&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;(Spring Boot)&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;[backport into 4.x]&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;枚舉中的正確屬性值有時會被標記為錯誤&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-tools%2Fissues%2F1606" target="_blank"&gt;#1606&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;(Spring Boot, Eclipse)&lt;span style="background-color:#ffffff; color:#1f2328"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;[backport]&lt;/span&gt; Spring Boot 語言服務器無法在 Eclipse 下啓動&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-tools%2Fissues%2F1618" target="_blank"&gt;#1618&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;詳細變更可以&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-tools%2Freleases%2Ftag%2F4.32.0.RELEASE" target="_blank"&gt;參見發行説明&lt;/a&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371538/spring-tools-4-32-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371538/spring-tools-4-32-0-released</guid>
      <pubDate>Sun, 07 Sep 2025 06:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里雲創始人王堅：開源不只是開放代碼，開源是今天 AI 競爭的關鍵變量</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 11 日上午，以「重塑創新增長」為主題的「2025 Inclusion·外灘大會」在上海黃浦世博園區開幕。在大會開幕式上，中國工程院院士、之江實驗室主任、阿里雲創始人王堅發表主題演講，提出了一個重要觀點：在 AI 時代，開源的內涵正在發生「革命性變化」——從以往「源代碼的開放」逐漸轉向「資源的開放」。模型權重的開放本質上是對數據資源與計算資源的開放，這也構成了 AI 時代開源的核心特徵。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ee42154cfc30f409d743f5f865919f0d777.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;王堅舉例道，今年 1 月 13 日，美國公佈對 AI 的出口管制，首次明確要對 AI 模型的權重進行管制；今年 1 月 30 日，OpenAI 聯合創始人兼 CEO Sam Altman 説：「在（開源）這個問題上，我們站在了歷史的錯誤一邊。」2025 年神奇的一件事情是，開源變成了今天 AI 競爭的關鍵變量。&lt;/p&gt; 
&lt;p&gt;隨後，王堅簡單回顧了推動 AI 發展到當今的幾大重要理論，王堅表示，開放的話題不是今天才重要，在互聯網時代就是關鍵的變量。在互聯網時代，Netscape 的開源是那個時代的分水嶺。開放資源的概念不是因為有「開源」一詞才出現的，在科學探索過程中，很多先驅已經這樣做了。&lt;/p&gt; 
&lt;p&gt;王堅強調：「模型權重的開放，本質上是數據資源和計算資源的開放。有了模型開放以後，你不需要再花那麼多計算資源去重新做，有人替你完成了。我想説一下，開放以後並不意味着計算不重要，而只是意味着個體不用花這麼多資源，因為有人付了這筆錢。」&lt;/p&gt; 
&lt;p&gt;他還説，「但要做更好的模型，需要更多資源的投入。今天，僅僅開放源代碼，不能解決我們過去在軟件時代用開源解決的問題。開放資源，特別是數據和計算資源，才是推動行業往前走不可缺失的環境。這就是 AI 時代開源的重要特點。我更願意把它叫作 open resource。但 open source 和 open resource 翻譯成中文，都是開源。」&lt;/p&gt; 
&lt;p&gt;此外，王堅還分享了他對 AI 進入太空的願景。據他介紹，今年 5 月 14 號，之江實驗室第一次把 12 顆衞星同時送上天，在這 12 顆衞星組成的星座上，第一次把一個地面上完整的 8B AI 模型放到太空裏。這 12 顆衞星到了太空以後，就可以保證在衞星到達的地方，就能完成所有數據的處理。這是第一次實現了在太空中衞星之間的互通互聯，給 AI 在太空帶來機會。該項目被稱為「三體計算星座」。&lt;/p&gt; 
&lt;p&gt;「我們計劃把每一顆衞星開放給全世界任何人。這可以解決很多問題，也可以支持我們向深空探索。科學家已經在設想，幾年內把衞星送到太陽軌道的 L5 點，這個點離地球 1.5 億公里，離太陽 1.5 億公里。」王堅表示，「只有把 AI 和算力送入太空，人類才可能真正走出地球。下面的時代非常激動人心。人類去火星的路上不能沒有計算和 AI 的陪伴。這就是未來十年甚至二十年最激動人心的地方。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371536</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371536</guid>
      <pubDate>Sun, 07 Sep 2025 06:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linyaps - Linux 跨發行版獨立包管理工具集</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#7a7a7a"&gt;&lt;span style="color:#000000"&gt;如意玲瓏（Linyaps）是由統信軟件技術有限公司自主研發的跨發行版 Linux 軟件包管理工具集，現捐贈至開放原子開源基金會併成為其孵化的重點項目。項目以獨立沙盒容器技術為核心，針對傳統 Linux 軟件生態的依賴衝突、分發碎片化、安全風險高等痛點，創新提出非特權沙箱設計、增量更新機制及離線分發能力（uab 格式），實現「一次構建，全平台運行」。&lt;br&gt;
&lt;br&gt;
項目已適配 deepin、Debian、Ubuntu、Arch、Fedora、UOS、openEuler、openkylin 等 Linux 主流發行版，覆蓋 X86、ARM64、LoongArch 等芯片架構，支持超 5000 款應用分發，通過如意玲瓏應用商店實現高效交付。核心技術如 rootless 容器部署、OSTree 原子化更新等，顯著降低資源佔用，有效保障安全分發。獨創 uab 離線包格式，支持涉密場景無網絡部署，助力政務、金融等領域實現國產化替代。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style="color:#000000"&gt;八寶玲瓏塔，蘊含芥子乾坤般的另一個世界，狀似七層實非七層，以逞道法之變化。「玲瓏」二字，正好融合「隔離」與「分層」思想，寓意對應用運行時的系統環境進行分層管理，實現權限管控。&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/linyaps</link>
      <guid isPermaLink="false">https://www.oschina.net/p/linyaps</guid>
      <pubDate>Sun, 07 Sep 2025 06:23:00 GMT</pubDate>
    </item>
    <item>
      <title>Rufus 4.10 Beta 發佈，引入深色模式、支持 Windows 11 25H2 ISO</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Rufus&amp;nbsp;在 Windows 生態中被認為是最優秀的 U 盤啓動工具之一，與官方的 Media Creation Tool 相比，Rufus 不僅能更快地完成 Windows 系統 U 盤的製作，還集成了 Windows 鏡像下載以及自定義 Windows 安裝設置，如：移除 Windows 11 TPM 2.0 檢測，預設本地賬號等。&lt;/p&gt; 
&lt;p&gt;今天，Rufus&amp;nbsp;4.10 beta 正式推出，Rufus&amp;nbsp;4.10 Beta 最大的的亮點是支持&amp;nbsp;Windows 11 25H2 ISO&amp;nbsp;以及深色模式支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a39722aefe1dbdbe041c84847d9941d6227.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是 Rufus 4.10 Beta 的更新日誌：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 Windows 11 25H2 ISO&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rufus&amp;nbsp;4.10 Beta 正式加入了對&amp;nbsp;Windows 11 25H2 ISO&amp;nbsp;的支持，用戶能夠創建滿足企業合規需求的安裝介質（這一改進對準備部署&amp;nbsp;Windows CA 2023&amp;nbsp;的企業或組織尤為重要）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;引入深色模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為了迎合現代 UI 偏好，Rufus 4.10 beta 提供了深色模式支持。在深色主題下，界面顯示更加一致，能有效提升長時間操作時的視覺舒適度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;驅動器直接保存為 ISO&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新增了將現有驅動器直接保存為 ISO 文件的功能，目前支持通用磁盤格式（UDF）。這一能力對需要完整保留啓動盤或數據盤結構的用戶來説極具價值，尤其適用於存檔或後續複製。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;其他修復與優化&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了新功能，Rufus 4.10 beta 還修復了多個問題，顯著提升了穩定性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;改進了保存為 VHD/VHDX 時的錯誤報告。&lt;/li&gt; 
 &lt;li&gt;修正了部分時區下錯誤提示 UEFI DBX 更新的情況。&lt;/li&gt; 
 &lt;li&gt;解決了 ISO 模式下無法選擇文件系統的問題。&lt;/li&gt; 
 &lt;li&gt;修復了處理超長路徑的 Windows ISO 文件時可能導致的崩潰。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://github.com/pbatard/rufus/releases/tag/v4.10_BETA&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371532</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371532</guid>
      <pubDate>Sun, 07 Sep 2025 06:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>強化學習之父 Richard Sutton：如今 AI 正進入「經驗時代」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2024 年圖靈獎得主、「強化學習之父」理查德·薩頓（Richard Sutton）在 2025 Inclusion·外灘大會上發表主旨演講，他認為，人類數據紅利正逼近極限，人工智能正在進入以持續學習為核心的「經驗時代」，潛力將遠超以往。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;薩頓表示，大多數機器學習的目標，是把人類已有的知識轉移到靜態、缺乏自主學習能力的 AI 上。「我們逐漸達到人類數據的極限，現有的方法不能生成新的知識，不適合持續學習，而持續學習對智能的效用至關重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他認為，我們正進入「經驗時代」，需要一種新的數據源，由智能體與世界直接交互中生成。這正是人類和其他動物的學習方式，是 AlphaGo 自我博弈下的「第 37 手」，也是近期 AlphaProof 在國際數學奧林匹克斬獲銀牌的路徑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="294" src="https://oscimg.oschina.net/oscnet/up-6ecdf369f59aeda51d53bb897d5a8cacd52.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;薩頓解釋，「經驗」指的是觀察、行動和獎勵，這三種信號在智能體與世界之間來回傳遞。「知識來自於經驗，可以從經驗中學習。一個智能體的智能程度，取決於它能預測並控制自身輸入信號的程度。經驗是一切智能的核心與基礎。」他同時指出，強化學習帶領我們進入了新的經驗時代，但要釋放全部潛力，還需要兩項目前尚不成熟的技術——持續學習（continual learning）和元學習（meta-learning）技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面對外界對 AI 帶來偏見、失業甚至人類滅絕的擔憂，薩頓認為，這種對人工智能的恐懼被誇大了，目標不同的智能體，可以通過去中心化的協作實現雙贏。「人類最卓越的超能力，就在於比其他任何動物都更擅長協作。人類最偉大的成功在協作本身——經濟、市場與政府都是成功協作的產物。」薩頓表示，人工智能和人類繁榮將來自於去中心化協作，「協作並非總能實現，卻是世間一切美好事物的源泉，我們必須尋求協作、支持協作，並致力將協作制度化。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他認為，在人類的發展進程中，人工智能的替代將是不可避免的。而人類至少是催化劑，是助產士，更是開啓宇宙第四大時代——「設計時代」的先驅。薩頓將宇宙歷史分為四個時代：粒子時代、恆星時代、複製者時代和設計時代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「人工智能是宇宙演化的必然下一步，我們應以勇氣、自豪和冒險精神來迎接它。」薩頓表示。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371531</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371531</guid>
      <pubDate>Sun, 07 Sep 2025 06:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義即將發佈 Qwen3-Next 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義 Qwen 團隊通過 Hugging Face transformers 庫的 PR&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftransformers%2Fpull%2F40771" target="_blank"&gt;提交&lt;/a&gt;了對 Qwen3-Next 系列的支持，信息顯示將有一款名為 Qwen3-Next-80B-A3B-Instruct 的模型。該系列定位為 「下一代基礎模型」，主打極端上下文長度與參數效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/141001_xzxJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Qwen3-Next 系列模型在架構層面引入了三項核心創新。首先是 Hybrid Attention，它使用 Gated DeltaNet 和 Gated Attention 替代傳統注意力機制，以實現高效的長文本建模。其次是 High-Sparsity MoE，將激活比例壓縮至 1:50，大幅減少了單個 token 的 FLOPs 而不損失模型容量。最後是 Multi-Token Prediction，在預訓練階段同步預測多個 token，從而提升性能並加速推理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/141034_JXYV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，模型還輔以 zero-centered、weight-decayed layernorm 等多項穩定化改進，增強了訓練的魯棒性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371530</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371530</guid>
      <pubDate>Sun, 07 Sep 2025 06:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美國參議員提出「SANDBOX 法案」 允許 AI 公司設定長達 10 年自我監管規則</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;美國參議員特德・克魯茲（Ted Cruz）提出了一項名為 「SANDBOX 法案」 的新立法。這項法案旨在為人工智能 (AI) 公司提供一個 「監管沙箱」，讓它們在較少的聯邦監管下進行實驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據該法案，AI 公司可以申請修改或豁免任何 「阻礙性規定」，以便更方便地測試和部署包含或使用至少一個 AI 系統的產品或服務。作為交換，公司需要向監管機構披露其減輕消費者安全和財務風險的計劃。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;法案規定，豁免期限為兩年，最多可延長至十年。這一提案與此前一項試圖暫停十年所有州級 AI 監管的失敗提案有所相似。該提案於七月份在參議院遭到否決。賦予豁免權的將是相關的聯邦機構，例如負責保護兒童在線隱私的聯邦貿易委員會（FTC）。如果相關機構在 90 天內未作回應，豁免將會自動被授予。如果申請被拒，企業可以向白宮科技政策辦公室 (OSTP) 上訴，該辦公室將監督該監管沙箱項目並有權推翻拒絕決定。每年，國會將收到關於豁免或修改聯邦規則次數的報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;技術問責組織 「科技監督項目」 對此法案表示擔憂，稱其可能成為 「大科技首席執行官」 的 「甜蜜交易」，而那些為唐納德・特朗普（Donald Trump）捐款的公司可能會享有不同的規則。此外，消費者權益組織 「公民公共事務」 警告稱，該法案將允許硅谷在法律和監管方面實施 「快速推進、破壞一切」 的態度。這兩個組織均對該法案賦予 OSTP 推翻聯邦機構決策的權力表示關切，因為許多相關機構已經因拆解而失去了效能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，特朗普在七月份發佈的 AI 行動計劃中曾表示支持為 AI 公司創建監管沙箱。此外，特朗普的計劃還包括通過撤銷對實施 AI 監管的州的資金支持，間接推動這一監管沙箱的設立。克魯茲所在的德克薩斯州在今年六月份通過了一項類似的 AI 法律，但該法案的沙箱期限僅限於 36 個月。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371526</guid>
      <pubDate>Sun, 07 Sep 2025 05:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>月之暗面開源 Checkpoint Engine，專為 LLM 推理引擎設計的中間件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;月之暗面開源了 Checkpoint Engine，這是一個專為 LLM 推理引擎設計的中間件，用於在強化學習等場景中實現模型權重的原地熱更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db10fbcc3d6c729314d03825d34c1659112.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該工具可在約 20 秒，內完成 1 萬億，參數的 Kimi-K2 模型在數千個 GPU 上的權重同步，從而顯著降低強化學習訓練迭代過程中的停機時間。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-68055dc37220717eaee1d87c60b9856da48.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，該實現僅與 vLLM 深度集成，但其接口設計便於擴展至 SGLang 等其他框架。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;em&gt;https://github.com/MoonshotAI/checkpoint-engine&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371502</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371502</guid>
      <pubDate>Sun, 07 Sep 2025 03:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>甲骨文埃裏森總財富達 4019 億美元，史上第二個淨資產突破 4000 億美元的人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;福布斯實時富豪榜顯示，甲骨文的聯合創始人拉里·埃裏森總財富達 4019 億美元，日增 1100 億美元或 37%，成為史上第二個淨資產突破 4000 億美元大關的人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;榜單顯示，特斯拉首席執行官、太空探索技術公司（SpaceX）創始人埃隆·馬斯克的最新財富為 4404 億美元，依然是全球首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不過，由於統計口徑不同，也有榜單認為埃裏森已經超越馬斯克成全球首富，根據彭博億萬富豪指數最新數據，拉里·埃裏森（Larry Ellison）的財富達到 3930 億美元，憑藉此，其超越馬斯克（3850 億美元）成為全球首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="587" src="https://oscimg.oschina.net/oscnet/up-1c2309c9f3f45c8e7522623751993556803.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，OpenAI 已簽署一項協議，將在大約五年內向甲骨文購買價值 3000 億美元的算力。這筆交易是有史以來規模最大的雲服務合同之一。該合同將需要 4.5 吉瓦的電力容量。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371487</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371487</guid>
      <pubDate>Sun, 07 Sep 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MCP 是為開發者設計的工具，而非為 LLM 而設</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 你在開發 AI 智能體時，是否也曾為這些事頭疼不已：每接入一個新工具就要重寫集成代碼？工具一多就難以統一管理？LLM 時而"幻覺"出根本不存在的工具調用？&lt;/p&gt; 
 &lt;p&gt;這些問題不僅拖慢開發節奏，更讓智能體的穩定性和擴展性大打折扣。&lt;/p&gt; 
 &lt;p&gt;今天推薦的這篇文章，正來自一線開發者對 Model Context Protocol (MCP) 的深度實踐與思考。對 LLM 來説，"常規"的工具調用和使用 MCP 這樣的標準沒有任何區別。它只看到一組工具定義（tool definitions），它不知道也不關心幕後發生着什麼 ------ 而這恰恰是件好事...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Roy Derks&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Model Context Protocol (MCP) 已成為構建智能體時使用工具調用（tool calling）的標準，但恰恰相反，你的 LLM 並不需要理解 MCP。你可能聽説過"上下文工程（context engineering）"這一術語，在這項技術中，作為與 LLM 交互的人，你需要負責提供正確的上下文來幫助它回答問題。為了收集這些上下文，你可以使用工具調用，讓 LLM 能夠訪問一組可以用於獲取信息或執行操作的工具。&lt;/p&gt; 
&lt;p&gt;MCP 通過標準化 AI 智能體連接到這些工具的方式來提供幫助。&lt;strong&gt;但對你的 LLM 來説，"常規"的工具調用和使用 MCP 這樣的標準沒有任何區別。&lt;/strong&gt; 它只看到一組工具定義（tool definitions），它不知道也不關心幕後發生着什麼 ------ 而這恰恰是件好事。&lt;/p&gt; 
&lt;p&gt;通過使用 MCP，你可以訪問成千上萬的工具，而無需為每個工具編寫自定義的集成邏輯。它極大地簡化了涉及工具調用的智能體循環（agentic loop）的設置過程，而這一過程的開發時間通常情況下幾乎為零。開發者負責調用工具，LLM 只生成一個片段，説明需要調用什麼工具（單個或多個）以及使用哪些輸入參數。&lt;/p&gt; 
&lt;p&gt;在這篇博客文章中，我將詳細解釋工具調用是如何工作的、MCP 實際上做了什麼，以及這兩者與上下文工程的關係。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 工具調用 Tool Calling&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;LLMs 理解工具調用【有時也稱為工具使用（tool use）或函數調用（function calling）】的概念。你需要在提示詞中提供工具定義列表。每個工具都包含名稱、功能描述和所需的輸入參數。根據用戶問題和現有工具，大語言模型可能會生成對應的調用指令。&lt;/p&gt; 
&lt;p&gt;但關鍵點在於：&lt;strong&gt;LLMs 並不懂得如何使用工具。它們沒有原生的工具調用支持，它們只會生成代表函數調用的文本。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b4a5e413dea5e14905d7abfa20648388860.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與 LLM 交互時的輸入與輸出&lt;/p&gt; 
&lt;p&gt;在上方的示意圖中，我們可以看到 LLM 實際看到的內容：一個由指令、之前的用戶消息和可用工具列表組成的提示詞。基於這些信息，大語言模型會生成文本響應，其中可能包含系統應當調用的工具指令。&lt;strong&gt;它並非真正理解工具的實際意義，只是在基於概率生成預測性響應。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;讓我們來看一個更實際的應用場景。例如，如果你提供一個名為 get_weather 的工具，它接受一個地理位置作為輸入，然後問模型："加利福尼亞州聖何塞的天氣怎麼樣？" 它可能會回應：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
"name":"get_weather",
"input":{
"location":"San Jose, CA"
}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;LLM 能夠根據所提供的上下文生成這個代碼片段，如下方示意圖所示。LLM 並不瞭解如何調用 get_weather 工具，它也無需知道。你的智能體循環（agentic loop）或智能體應用（agentic application）負責獲取該輸出，並將其轉換為實際的 API 調用或函數調用。系統會解析模型生成的工具名稱及輸入參數，執行對應工具，並將執行結果作為新消息反饋給大語言模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bd5d7ee2fa32032370de356467715267894.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;工具調用流（Tool Calling flow）與 LLM 的交互&lt;/p&gt; 
&lt;p&gt;這種職責分離很重要。大語言模型僅負責生成預測結果，而執行環節交由您的系統處理。這正是 MCP（模型上下文協議）發揮作用的關鍵所在。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 模型上下文協議 (MCP)&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Model Context Protocol（簡稱 MCP）是一種標準化智能體與數據源（如工具、提示詞、資源服務及樣本示例）連接方式[1]的協議。&lt;strong&gt;現階段，MCP 最顯著的價值在於簡化了工具集成這一關鍵環節。&lt;/strong&gt; MCP 通過定義統一的接口規範和通信協議，取代了為每個工具手動編寫定製化代碼的方式。您可以將其理解為工具領域的通用適配器（如同 USB-C 接口）。&lt;/p&gt; 
&lt;p&gt;MCP 通常包含三個核心組件：宿主應用 (host application)、MCP 客戶端 (MCP client) 和若干 MCP 服務器 (MCP servers)。宿主應用可能是聊天軟件或 IDE（例如 Cursor），其中內置了能連接不同 MCP 服務器的 MCP 客戶端。這些 MCP 服務器則對外提供工具、提示詞、樣本示例或資源服務。&lt;/p&gt; 
&lt;p&gt;與 LLM 的交互方式並未改變，改變的是工具數據的接入方式：智能體應用與 MCP 客戶端通信，再由客戶端對接目標服務器。所有工具均以 LLM 可識別的格式進行描述。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d80215e3d29caf348271fee246fff36968e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;工具調用流與 LLM 及 MCP 的交互&lt;/p&gt; 
&lt;p&gt;當面對同樣的問題"加利福尼亞州聖何塞的天氣怎麼樣？"時，LLM 接收到的仍是相同的工具列表。根據該列表，它將告訴你需調用的工具，而具體的執行策略仍由開發者掌控。當採用 MCP 時，該工具將通過 MCP 協議執行。&lt;/p&gt; 
&lt;p&gt;該機制的核心受益方並非大語言模型，而是作為開發者的你。隨着智能體系統的擴展，MCP 能有效管理複雜的多工具協作：實現跨項目的工具複用，統一數據格式規範，以及無需重構即可無縫接入新系統。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;但除非在系統提示詞中明確告知，否則 LLM 永遠無法感知你是否使用了 MCP。&lt;/strong&gt; 開發者始終承擔工具調用的執行職責，大語言模型僅生成包含目標工具及對應輸入參數的指令片段。&lt;/p&gt; 
&lt;p&gt;接下來，本文將解析該機制是如何融入上下文工程體系的，並闡釋為何 MCP 這樣的抽象層本質是為人類而非模型服務。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 上下文工程 Context Engineering&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Context engineering（上下文工程）的核心在於為 LLM 提供精準恰當的輸入，使其生成有效的輸出。這看似簡單，卻是構建高效 AI 系統最關鍵的環節之一。&lt;/p&gt; 
&lt;p&gt;當我們向模型提問時，本質上是在向其提供提示詞（prompt） ------ 即模型用於預測後續文本的文本塊。該提示詞的質量直接影響響應質量。&lt;/p&gt; 
&lt;p&gt;這正是工具調用的價值所在。當模型缺乏足夠上下文時（如需實時數據、用戶畫像或代用戶執行操作的能力），通過工具調用可使其接入外部系統 ------ 正如本文所述。&lt;/p&gt; 
&lt;p&gt;但在此再次強調，模型無需理解這些工具的實現邏輯。它只需知曉三點：工具的存在性、功能定位及調用方式。這正是上下文工程（context engineering）與工具設計（tool design）的交匯點 ------ 我們所設計的工具定義集本質上是提示詞的組成部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-70d75852edc894f635b93c2125ec512de9d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LLM 視角下的工具調用&lt;/p&gt; 
&lt;p&gt;MCP 使該過程更簡潔規範且可複用。通過 MCP 協議，開發者只需一次性定義結構化接口並對外發布，即可避免硬編碼工具（hardcoding tools）或編寫臨時封裝器（writing ad hoc wrappers）。LLM 接收到的工具定義格式保持不變，但現在它們更容易維護和擴展。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;綜上所述，MCP 本質上是一個為開發者設計的工具，而非為 LLM 而設。&lt;/strong&gt; 它可以幫助我們構建更可靠的、更模塊化的系統，使工程師能專注於上下文工程，而無需每次都重複搭建基礎架構。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓文中的核心觀點是："MCP 是為開發者，而非為 LLM 服務的"。你是否認同？有沒有反例或不同的角度？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F4029634%2Fwhat-is-model-context-protocol-how-mcp-bridges-ai-and-external-services.html" target="_blank"&gt;https://www.infoworld.com/article/4029634/what-is-model-context-protocol-how-mcp-bridges-ai-and-external-services.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhackteam.io%2Fblog%2Fyour-llm-does-not-care-about-mcp%2F" target="_blank"&gt;https://hackteam.io/blog/your-llm-does-not-care-about-mcp/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18691378</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18691378</guid>
      <pubDate>Sun, 07 Sep 2025 03:12:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>騰訊優圖公佈今年整體開源計劃</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊向《科創板日報》透露，圍繞 Youtu-RAG 和 Youtu-Agent 兩大系列，從 9 月到 12 月將陸續開源 RAG 所需的 Youtu-Embedding/Youtu-GraphRAG/Youtu-Parsing/Youtu-Reranker 等系列模型，並提供基於 MCP 的 Youtu-RAG 框架；以及 Agent 訓練改進算法 SAL/Agent 數據引擎 AgentVR。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;具體來説，Youtu-Embedding、Video-MME V2、Youtu-Parsing 預計將分別於 9 月、10 月、11 月開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;騰訊優圖實驗室於日前宣佈開源了智能體框架 Youtu-Agent。該框架以極簡設計和高性能表現為核心，旨在為研究人員和開發者提供高效、易用、可復現的智能體開發工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="347" src="https://oscimg.oschina.net/oscnet/up-64fd8e3e9b8e3d8fd3e9f449c2f233b39c8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-6811930e47590e421a4609fdf9f21724e09.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在性能表現上，Youtu-Agent 在多個智能體挑戰性基準測試中取得領先成績。例如，在 WebWalkerQA 基準中，基於 DeepSeek-V3.1 的運行結果達到了 71.47% 的準確率，刷新了開源模型的最新紀錄。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371482</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371482</guid>
      <pubDate>Sun, 07 Sep 2025 03:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>deepchat 企業 AI 應用平台增加智能體發佈嵌入網站功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//de83a8e2d16232270d87894690136c66.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;經過一些日子的開發，一個人加 AI，deepchat 終於有了點模樣。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#40485b"&gt;項目地址：&lt;/span&gt;https://gitee.com/noday/deepchat&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;官網：http://deepchat.6661943.xyz/&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#40485b"&gt;deepchat 探索大模型企業應用落地場景。包括但不限於知識庫、問數、ChatBI、Office 助手、智能客服、資料分類於分析等等，對接了國內外廠家的大模型提供商。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本次更新：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;智能體發佈功能，發佈到對話廣場和嵌入網站&lt;/p&gt; 
&lt;p&gt;&lt;img height="945" src="https://oscimg.oschina.net/oscnet/up-9f8aaed339c03f51e2f4085edd50e700f39.png" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="945" src="https://oscimg.oschina.net/oscnet/up-15dfdd00de87fd29822b57f37c412758d46.png" width="1920" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371479</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371479</guid>
      <pubDate>Sun, 07 Sep 2025 02:59:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Thinking Machines Lab 發文，揭示 LLM 推理過程不確定性的真相</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;由 OpenAI 前 CTO Mira Murati 創辦的 Thinking Machines Lab 發佈了第一篇技術博客：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthinkingmachines.ai%2Fblog%2Fdefeating-nondeterminism-in-llm-inference%2F" target="_blank"&gt;《在 LLM 推理中戰勝不確定性》(「Defeating Nondeterminism in LLM Inference」)&lt;/a&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0911/103902_WRpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為什麼大語言模型推理過程是不確定性的，如何讓大模型 100% 輸出同樣的結果？這篇文章正是討論了這一問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-59d0b8b8b532757c7b9865e53d7395f459d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們知道即使將大模型溫度參數設為 0，使用相同的輸入、相同的模型和硬件，仍可能得到不同的輸出。&lt;/p&gt; 
&lt;p&gt;文中認為主要原因有兩個：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 浮點數加法的非結合性（floating-point non-associativity）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;即 (a + b) + c ≠ a + (b + c)，這在並行計算中會導致不同的求和順序產生不同的數值結果。&lt;/p&gt; 
&lt;p&gt;不過這不是主要原因。主要還是因為第二點：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 並行計算策略的變化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;不同的 batch size、序列長度、KV-cache 狀態等，會導致 GPU 內核選擇不同的並行策略，從而改變計算順序和結果。&lt;/p&gt; 
&lt;p&gt;為了實現確定性推理，作者提出要讓所有關鍵計算核（kernel）具備 batch-invariant 特性，即無論 batch 大小或序列如何切分，計算順序和結果都保持一致。並針對 RMSNorm、矩陣乘法 (Matrix Multiplication)、注意力機制 (Attention) 給出了具體方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-35e97e53fd1856165d750d9473d2ae1e61f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作者用 Qwen3-235B-A22B-Instruct-2507 做了試驗，用他的改進方法後，重複 1000 次，大模型的輸出仍然是完全相同的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371472/defeating-nondeterminism-in-llm-inference</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371472/defeating-nondeterminism-in-llm-inference</guid>
      <pubDate>Sun, 07 Sep 2025 02:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
