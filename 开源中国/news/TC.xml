<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（台灣）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-tw</language>
    <lastBuildDate>Wed, 30 Jul 2025 07:50:08 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>商湯發佈「日日新 SenseNova V6.5」大模型體系</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;商湯科技在 WAIC 2025 上發佈了「日日新 SenseNova V6.5」大模型體系，其推理和多模態能力超越多個主流模型，且性價比提升 3 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/153957_Ek9w_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154010_eiFA_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154040_VjKR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;日日新 V6.5 重點升級了強推理、高效率和智能體三大能力。該模型在國內率先突破圖文交錯思維鏈技術，引入形象思維，並改進了多模態模型的融合架構，使得文本和多模態推理能力超越 Gemini 2.5 Pro 和 Claude-4 Sonnet，多模態交互能力超越 Gemini 2.5 Flash 和 GPT-4o，同時性價比相較 V6.0 提升了 3 倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363167</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363167</guid>
      <pubDate>Wed, 30 Jul 2025 07:41:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編程軟件 Cline 回應 Anthropic 限制 Max 用量的新政策</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，Anthropic 開始針對 Claude Code 訂閲用戶&lt;u&gt;&lt;a href="https://www.oschina.net/news/362871"&gt;加入新的每週用量限制&lt;/a&gt;&lt;/u&gt;，並且根據目前使用情況來計算，這一調整將影響不到 5% 的用戶。&lt;/p&gt; 
&lt;p&gt;具體來看，從 8 月 28 日起，Anthropic 將在現有的每 5 小時重置的用量限制基礎上，增加每週用量限制：每 7 天重置的總體每週用量上限；針對 Claude Opus 4 的每週用量上限，每 7 天重置。&lt;/p&gt; 
&lt;p&gt;Anthropic 表示，Claude Code 作為其訂閲服務的一部分，該產品用戶增長速度前所未有。但同時 Claude Code 存在一些違反政策的行為，以及一些超常規的使用模式。而這些行為影響了所有用戶的系統容量。對此，Anthropic 推出的新用量限制旨在解決這些問題，為所有用戶提供一個更公平的使用體驗。&lt;/p&gt; 
&lt;p&gt;而 AI 編程軟件 Cline &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1949943033891307589" target="_blank"&gt;也回應了 Anthropic 的新政策。&lt;/a&gt;&lt;strong&gt;Cline 將 AI 訂閲比作加油站，而車（AI 工具）和油（AI 推理服務）都由同一家 AI 公司控制，用戶買了油卻不知道實際加了多少，甚至還沒法瞭解實際消耗和服務內容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b714d24bfd8ec4d5f5174c7a6b4d395f74e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 認為，任何宣稱自己是無限服務都是不可持續的，AI 推理本質上是像汽油、電力一樣的商品。Cline 還指出，重度用戶的使用成本遠超訂閲費用，從而導致服務商虧損，不得不設置限額或限制使用，最終用戶體驗也變得受損，得不償失。&lt;/p&gt; 
&lt;p&gt;Cline 還表示，&lt;strong&gt;將來訂閲模式終將被市場淘汰，未來應選擇利益與用戶一致、架構透明的工具和平台&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363163</guid>
      <pubDate>Wed, 30 Jul 2025 07:24:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TPU Deep Dive：Google TPU 架構深度分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 在人工智能算力軍備競賽愈演愈烈的今天，為什麼 Google 會選擇與主流 GPU 截然不同的技術路線，開發出架構獨特的 TPU？這種專用芯片究竟憑藉什麼優勢，能夠支撐起 Gemini、Veo&amp;nbsp;等&amp;nbsp;AI 模型的訓練與推理？&lt;/p&gt; 
 &lt;p&gt;文章從單芯片架構出發，深入剖析了 TPU 的核心設計理念：首先解釋了 TPU 如何通過脈動陣列和流水線技術優化矩陣運算，然後闡述了 XLA 編譯器如何通過預先編譯減少緩存依賴，大幅降低能耗。在多芯片層面，作者詳細介紹了 TPU 從託盤、機架、Pod 到 Multi-Pod 的層級擴展架構，特別是 OCS 光交換技術如何實現靈活的拓撲重構和故障容錯。文章還通過具體案例展示了不同拓撲結構對並行訓練策略的影響，以及 Multi-Pod 架構如何支撐超大規模模型訓練。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Henry Ko&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;最近我大量使用 TPU，發現它們與 GPU 的設計理念非常不同，感覺很有趣。&lt;/p&gt; 
&lt;p&gt;TPU 的主要優勢在於其可擴展性。這是通過硬件層面（例如能效方面和模塊化）與軟件層面（例如 XLA compiler）的協同設計實現的。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 背景信息&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;簡單介紹一下 TPU，它是谷歌的專用集成電路（ASIC），其設計聚焦於兩大要素：極高的矩陣運算（matmul）吞吐量和能源效率。&lt;/p&gt; 
&lt;p&gt;它們的起源可追溯到 2006 年的谷歌。當時，他們正在評估是採用 GPU、FPGA 還是定製的 ASIC。當時，只有少數應用需要使用專用硬件，他們判斷通過從大型數據中心調配多餘的 CPU 算力即可滿足這些需求。但這一情況在 2013 年發生了變化，當時谷歌的語音搜索功能運行在神經網絡上，而內部預測認為，如果該功能發展起來，將需要遠超以往的算力。&lt;/p&gt; 
&lt;p&gt;時至今日，TPU 已為谷歌的大多數人工智能服務提供算力支撐。當然，也包括 Gemini 或 Veo 的訓練和推理，也包括他們的推薦模型。&lt;/p&gt; 
&lt;p&gt;讓我們從底層開始，深入瞭解一下 TPU 的內部構造。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 單個 TPU 芯片內部的架構層級&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;下文圖示均以 TPUv4 為例，但其整體佈局基本也適用於最新一代 TPU（如 TPUv6p 「Trillium」。TPUv7 「Ironwood」 的細節截至 2025 年 6 月尚未公佈）。&lt;/p&gt; 
&lt;p&gt;單顆 TPUv4 芯片的結構如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b7a986ab2586ba485d59aac151bc5dbf109.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU Single Chip + TensorCore&lt;/p&gt; 
&lt;p&gt;每顆芯片內含兩個 TPU TensorCore，負責所有計算。（注：面向推理的專用 TPU 僅有一個 TensorCore）。兩個 TensorCore 共享同一份內存：CMEM（128 MiB）和 HBM（32 GiB）。&lt;/p&gt; 
&lt;p&gt;而在每個 TensorCore 內部，都有計算單元和較小的內存緩衝區：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）矩陣乘法單元 (MXU)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;這是 TensorCore 的核心部件，是一個 128x128 的脈動陣列（systolic array）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;脈動陣列的原理稍後説明。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）向量單元（VPU）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;負責執行通用的逐元素操作（例如 ReLU、點加/點乘、歸約操作）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）向量內存（VMEM；32 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內存緩衝區。HBM 中的數據需先複製到 VMEM，TensorCore 才能開始計算。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4）標量單元 + 標量內存（SMEM；10 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用於調度 VPU 和 MXU 的執行指令。&lt;/li&gt; 
 &lt;li&gt;負責管理控制流、標量運算和內存地址生成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用的是英偉達（NVIDIA）GPU，那麼一些初步觀察結果可能會讓你大吃一驚：&lt;/p&gt; 
&lt;p&gt;1）TPU 的片上內存單元（CMEM、VMEM、SMEM）遠大於 GPU 的 L1/L2 緩存。&lt;/p&gt; 
&lt;p&gt;2）TPU 的 HBM 容量卻遠小於 GPU 的 HBM。&lt;/p&gt; 
&lt;p&gt;3）負責計算的"核心"（cores）數量明顯更少。&lt;/p&gt; 
&lt;p&gt;這與 GPU 架構完全相反 —— GPU 擁有較小的 L1/L2 緩存（以 H100 為例，分別為 256KB 和 50MB）、更大的 HBM（H100 為 80GB）以及數以萬計的計算核心（cores）。&lt;/p&gt; 
&lt;p&gt;在我們進一步討論之前，需明確的是，TPU 與 GPU 同樣具備極高的吞吐量。單顆 TPU v5p 芯片可達 500 TFLOPs/sec，由 8960 顆芯片組成的完整 pod 集羣可實現約 4.45 ExaFLOPs/sec。而最新的 "Ironwood" TPUv7 每個 pod（9216 顆芯片）據稱可達 42.5 ExaFLOPS/sec。&lt;/p&gt; 
&lt;p&gt;要理解 TPU 如何實現這種性能，我們需要深入探究其設計理念。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 TPU 的設計理念&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;TPU 通過兩大技術支柱和一個核心前提實現了驚人的吞吐量與能源效率：systolic array（脈動陣列） + pipelining（流水線）、Ahead-of-Time (AoT) compilation（預先編譯），以及假設絕大多數運算都可通過適配 systolic array（脈動陣列）的方式表達。幸運的是，在現代深度學習（DL）領域，計算的大部分都是矩陣運算，而這些運算都適合使用 systolic array（脈動陣列）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 TPU 設計選擇之一：Systolic Array + Pipelining&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;問：什麼是 Systolic Array？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;答：Systolic Array 是一種硬件設計架構，由相互連接的處理單元（PE）網格組成。每個 PE 執行少量運算（例如乘法和累加運算），並將結果傳遞給相鄰 PE。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-35d3a118a74284c503027134a4294314974.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這種設計的好處是，數據一旦輸入 systolic array（脈動陣列），便無需額外的控制邏輯來處理數據。此外，當脈動陣列的規模足夠大時，除輸入輸出外再無內存讀寫操作。&lt;/p&gt; 
&lt;p&gt;由於脈動陣列的剛性結構設計（rigid organization），其僅能處理具有固定數據流模式的操作，但幸運的是，矩陣乘法和卷積運算（convolutions）恰好完美適配這種架構範式。&lt;/p&gt; 
&lt;p&gt;不僅如此，pipelining（流水線技術）顯然有機會將計算與數據移動重疊執行。下圖展示了 TPU 架構上 pipelined pointwise operation （通過流水線技術，加速 pointwise operation（逐點操作） 的執行過程。）的示意圖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-038f3eb06befc2339ee00a80b38e0b91727.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pipelined Pointwise Operation (from "How to Scale Your Model"&amp;nbsp;[4])&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;旁註：Systolic Arrays（脈動陣列）的侷限性 —— 稀疏性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們可以看到，脈動陣列（systolic arrays）非常喜歡稠密矩陣（dense matrices）（即每個 PE 幾乎每個時鐘週期都處於活躍狀態）。然而，其劣勢是，相同規模的稀疏矩陣（sparse matrices）無法獲得性能提升 —— 即使對於零值元素（zero-valued elements），PE 仍需執行相同數量的計算週期（cycles），導致資源浪費。&lt;/p&gt; 
&lt;p&gt;如若深度學習（DL）領域更傾向於採用更不規則的稀疏性（例如 MoE 架構），應對脈動陣列的這一系統性侷限將變得愈發重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 TPU 設計選擇之二：預先（AoT）編譯 + 減少對緩存的依賴&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本節將回答 TPU 如何通過軟硬件協同設計（TPU + XLA 編譯器）來避免使用緩存，從而實現高能效。&lt;/p&gt; 
&lt;p&gt;首先，請記住傳統緩存是為了處理不可預測的內存訪問模式而設計的。一個應用程序的內存訪問模式（memory access patterns），可能與另一個應用程序大相徑庭。從本質上講，緩存允許硬件靈活地適應各種應用場景。這也是 GPU（相較於 TPU）靈活性極高的一個重要原因。&lt;/p&gt; 
&lt;p&gt;然而，緩存訪問（以及一般意義上的內存訪問）會消耗大量能源。下面是對芯片（45 納米，0.9V；[18]）上各類操作的能耗粗略估計。這裏的主要啓示是，&lt;strong&gt;內存的訪問和控制佔用了大部分的能耗，而算術操作本身的能耗佔比則小得多。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-828c725d5f974a2973ca0fdeaa15296501f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但是，如果你的應用非常特殊，而且其計算和內存訪問模式具有很高的可預測性呢？&lt;/p&gt; 
&lt;p&gt;舉個極端的例子，如果我們的編譯器能提前確定所有需要的內存訪問，那麼硬件僅需一個暫存器作為緩衝區就足以滿足需求，根本不需要緩存。&lt;/p&gt; 
&lt;p&gt;這正是 TPU 的設計理念所追求的，也是 TPU 使用 XLA 編譯器設計以實現這一目標的根本原因。XLA 編譯器通過提前分析計算圖來生成優化過的程序。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問：但 JAX 在 TPU 上也運行良好，它們使用 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;TPU 上的 JAX+XLA 實際處於 JIT 與 AOT 的混合模式，因此容易產生混淆。當首次調用 JAX 中被 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 修飾的函數時，JAX 會進行代碼追蹤並生成靜態計算圖。然後將其傳遞給 XLA 編譯器，在那裏被轉化為適用於 TPU 的完全靜態二進制文件。在最後的轉化階段，編譯器會實施針對 TPU 的優化（例如，最大限度地減少內存訪問），使整個過程適合 TPU。&lt;/p&gt; 
&lt;p&gt;但有一點需要注意：當輸入張量的形狀（shape）發生變化時，已編譯的 JIT 函數需重新編譯並緩存。這就是為什麼 JAX 在處理動態填充（dynamic padding）或長度隨輸入變化的 for 循環層時表現不佳。&lt;/p&gt; 
&lt;p&gt;當然，這種方案雖有優勢，卻也存在明顯的侷限。它缺乏靈活性，而對編譯器的重度依賴猶如一把雙刃劍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;那麼，Google 為何仍要堅持這種設計理念？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TPU 及其能源效率（TPUv4）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;前文的能耗示意圖並不能精確反映 TPU 的實際情況，此處是 TPUv4 的能耗細目。注意，TPUv4 採用 7nm 工藝，表中 45nm 的數據僅用於對比（[3], [16]）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-929fea9deb2dd94de8a7dbbbf5af8b32f14.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bae4859f266ed820ecd3b512e9ceb4f62b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單次操作能耗對比（TPUv4, 7 nm）&lt;/p&gt; 
&lt;p&gt;上方的柱狀圖展示了具體數值，但需注意，現代芯片採用的是 HBM3 內存，其能耗遠低於本圖表中顯示的 DDR3/4 DRAM。儘管如此，該圖仍表明內存操作的能耗仍高出計算操作數個數量級。&lt;/p&gt; 
&lt;p&gt;這恰與 scaling laws 形成呼應：我們非常樂意通過增加浮點運算量（FLOPS）來換取更少的內存操作。因此減少內存操作能帶來雙重優化收益——不僅提升程序運行速度，還可顯著降低能耗。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 TPU 的多芯片互聯層級結構&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;現在升級到更高層級，觀察 TPU 在多芯片環境中的運作方式。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 託盤層級（即"板卡"；含 4 個芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8e3fe72f71ddb1cea8fad910065ba1c07b1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單塊 TPU 託盤包含 4 個 TPU 芯片或 8 個 TensorCore（簡稱"核心"）。每塊託盤配備獨立 CPU 主機（注：推理型 TPU 的每個主機可訪問 2 塊託盤，因其每芯片僅含 1 個核心）。&lt;/p&gt; 
&lt;p&gt;主機（Host） ⇔ 芯片（Chip）的連接採用 PCIe 接口，但芯片（Chip）⇔芯片（Chip）之間通過 Inter-Core Interconnect（ICI）連接，該接口具備更高帶寬。&lt;/p&gt; 
&lt;p&gt;不過 ICI 連接還可進一步擴展至多塊託盤。為此，我們需要繼續提升到機架層級（Rack level）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.2 機架層級（4x4x4 芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;TPU 最令人興奮的特性在於其可擴展性，這一點從機架層級開始顯現。&lt;/p&gt; 
&lt;p&gt;一個 TPU 機架包含 64 個 TPU 芯片，通過 4x4x4 三維環面網絡互聯。如果您看過谷歌的 TPU 宣傳資料（如下圖），這張圖展示的是 8 個 TPU 機架的集羣。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4bd138cd1af2330bfc7d037d4a01afa568f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 個 TPU 機架（TPUv4）&lt;/p&gt; 
&lt;p&gt;但在深入討論機架之前，我們需要澄清幾個容易混淆的術語：機架（Rack）、Pod 和切片（Slice）的區別。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;問：TPU 機架、TPU Pod 和 TPU 切片有何不同？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;不同谷歌資料對這些術語的使用存在差異，有時甚至混用"TPU Pod"和"TPU Slice"。本文采用谷歌 TPU 論文和 GCP 官方文檔的定義（[3][7][9]）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）TPU 機架（Rack）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;包含 64 塊芯片的物理單元，也稱為「立方體（cube）」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2）TPU Pod&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過 ICI 和光纖連接的 TPU 最大單元。&lt;/li&gt; 
 &lt;li&gt;又稱"Superpod"或"Full Pod"。例如 TPUv4 的 TPU Pod 包含 4096 塊芯片（或 64 個機架）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）TPU 切片（Slice）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;介於 4 塊芯片到 Superpod 規模之間的任何 TPU 配置組合。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;主要區別在於，TPU 機架和 TPU Pod 是物理計量單位，而 TPU 切片是抽象計量單位。當然，TPU 切片的設置涉及重要的物理拓撲約束，但現階段我們暫不展開討論。&lt;/p&gt; 
&lt;p&gt;現在，我們將聚焦物理計量單位：TPU 機架和 TPU Pod。這是因為，理解 TPU 系統的物理連接方式，能更深入地掌握其設計哲學。&lt;/p&gt; 
&lt;p&gt;現在回到 TPUv4 機架的具體結構：&lt;/p&gt; 
&lt;p&gt;單個 TPU 機架通過 ICI 和 OCS（Optical Circuit Switching）技術連接 64 個芯片。實質上，我們通過組合多個託盤（trays）來構建一個 64 芯片的完整系統。這種"將小型單元組裝成超級計算機"的設計理念將持續貫穿後續層級。&lt;/p&gt; 
&lt;p&gt;下圖展示了 TPUv4 單個機架的拓撲結構。它採用 4x4x4 三維環面網絡，其中每個節點都代表一塊芯片，藍色箭頭表示 ICI 鏈路，而各個面上的連接線則代表 OCS（根據文獻 [7] 重繪）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d720ac051e5ed63612d648da6093008d2c0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用 OCS 的 TPU 單機架架構&lt;/p&gt; 
&lt;p&gt;然而，這張圖表引出了兩個關鍵問題：為何 OCS 僅應用於環面結構的表面？換句話説 —— 使用 OCS 的核心優勢是什麼？共有三大核心優勢，我們將在後文再詳述另外兩點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #1：環繞連接 (Wraparound)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通過環形拓撲優化節點間的通信效率。&lt;/p&gt; 
&lt;p&gt;OCS 還承擔特定 TPU 配置的環繞連接功能。該設計將兩節點間的跳數從最壞情況下 N-1 跳降至每軸 (N-1)/2 跳，因為每條軸均形成一個環形（一維環面拓撲）。&lt;/p&gt; 
&lt;p&gt;隨着規模的進一步擴大，這種影響變得更加重要，因為降低芯片間的通信延遲對於高度並行化的實現至關重要。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附註：並非所有 TPU 都採用 3D 環面拓撲&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;注意，早期 TPU（如 TPUv2/v3）及推理專用 TPU（如 TPUv5e/v6e）使用 2D 環面拓撲而非下文所述的 3D 環面。不過 TPUv7"Ironwood" 雖定位為推理芯片，但其拓撲疑似 3D 環面（注：僅根據官方宣傳材料推測）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73f622dc9ad94d85b7665298423d5669470.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2D 環面拓撲示意圖&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.3 Full Pod 層級（又稱 "Superpod"；TPUv4 為 4096 塊芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;正如我們通過互聯多個芯片構建 TPU 機架，我們也可連接多個機架組成大型 Superpod。&lt;/p&gt; 
&lt;p&gt;Superpod 特指僅通過 ICI 和 OCS 互聯的最大 TPU 集羣規模。雖然存在 multi-pod 層級，但這種層級需依賴更慢速的連接方式，後續將展開説明。&lt;/p&gt; 
&lt;p&gt;芯片數量會因版本不同而變化，但 TPUv4 的芯片數量為 4096（即 64 個 4x4x4 芯片的機架）。最新的 TPUv7 "Ironwood" 則高達 9216 塊芯片。&lt;/p&gt; 
&lt;p&gt;下圖展示了 TPUv4 的一個 Superpod：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f3fbc86962bf3edf862e7aa966347174fb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 Superpod 架構（64 個機架）&lt;/p&gt; 
&lt;p&gt;請注意，每個立方體（即 TPU 機架）是如何通過 OCS 相互連接的，這種設計也支持在 Pod 內靈活劃分 TPU 切片。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;採用 OCS 的 TPU 切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們可在 Pod 內申請 TPU 子集，即 TPU 切片。但即使所需芯片數 (N) 相同，也存在多種拓撲結構可供選擇。&lt;/p&gt; 
&lt;p&gt;例如，若總共需要 512 塊芯片，可選擇立方體 (8x8x8)、條狀拓撲 (4x4x32) 或矩形拓撲 (4x8x16)。選擇切片的拓撲結構本身就是一個超參數。&lt;/p&gt; 
&lt;p&gt;所選拓撲結構直接影響節點間通信帶寬，進而影響各類並行策略的性能表現。&lt;/p&gt; 
&lt;p&gt;以立方體結構（如 8x8x8）為例，它特別適合需要全連接通信的並行計算模式，比如數據並行或張量並行，因為這種拓撲結構能提供最高的二分帶寬（bisection bandwidth）。而條狀結構（如 4x4x32）則更適用於流水線計算，這種佈局可以讓順序排列的計算層之間實現更快速的數據傳輸（前提是單個計算層能夠適配 4x4 芯片的子切片配置）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-143cbdf8803aec31540f9640581582d1b4f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;典型 TPU 拓撲示例&lt;/p&gt; 
&lt;p&gt;當然，最優拓撲取決於具體模型結構，其尋優過程本身即是一門學問。TPUv4 論文[9]實測表明，拓撲優化可大大提升吞吐量（注：我不確定第一行指的是哪種 LLM 架構，因為沒有具體説明）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3f8cb4956e8dbbdc78ec97d12a6ad2c70f0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同拓撲結構的吞吐量優化對比&lt;/p&gt; 
&lt;p&gt;前文闡述了 TPU 切片，但另有一項重要的特性有助於提高 TPU 的運行穩定性。&lt;/p&gt; 
&lt;p&gt;藉助 OCS 技術，這些切片無需佔據物理連續的機架空間。這正是 OCS 的第二大優勢 —— 可能也是其最大優勢，但我們此前尚未展開討論。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #2：可重新配置的非連續多節點切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;需注意，這不同於將多個節點硬連在一起來模擬非連續切片。由於 OCS 採用光交換技術而非硬連線架構，跨節點間的物理線纜數量大幅減少，從而支持更大規模的集羣擴展（即可構建超大規模 TPU Pod）。&lt;/p&gt; 
&lt;p&gt;這樣就可以進行靈活的節點規模配置。例如，假設我們想在單個 Pod 上運行三個任務。雖然傳統的調度方式不允許這樣做，但 OCS 連接允許我們抽象出節點的物理位置，使整個 Pod 可視為一個"節點資源池"（根據參考文獻[6]重繪）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4ea87894ad75b8b37c6e3913584dffafa2c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;單任務可將 Pod 內機架視為"節點資源池"&lt;/p&gt; 
&lt;p&gt;此舉不僅提高了 Pod 的利用率，而且能在節點出現故障的情況下簡化維護流程。谷歌將其描述為"故障節點的影響範圍很小"。但尚不確定其液冷系統在部分節點停機時如何運作。&lt;/p&gt; 
&lt;p&gt;最後，這種靈活的 OCS 還有項延伸應用：我們還可以改變 TPU 切片的拓撲結構（例如將規則環面調整為扭曲環面）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的優勢 #3：扭曲環面拓撲&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此前我們通過改變固定芯片數量下的 (x,y,z) 維度來實現不同的 TPU 切片拓撲結構。本節則聚焦固定維度配置，通過改變佈線方式構造新型拓撲。&lt;/p&gt; 
&lt;p&gt;典型案例如下：將常規條狀環面改造為扭曲條狀環面。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-85b47be563d32b35b9ca154cf668cbd2637.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;常規環面 vs 扭曲環面（來源：TPUv4 論文[9]）&lt;/p&gt; 
&lt;p&gt;扭曲環面拓撲結構能加速扭曲二維平面上的芯片之間的通信，該特性對提升全局通信效率尤其有用。&lt;/p&gt; 
&lt;p&gt;下文將深入分析其具體應用場景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;使用扭曲環面加速訓練&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;理論上，扭曲環面對張量並行（TP）的加速效益最大，因為每層涉及多次 all-gather 和 reduce-scatter 操作。對數據並行（DP）也有適度提升，因為每個訓練步需執行 all-reduce 操作，但發生頻率較低。&lt;/p&gt; 
&lt;p&gt;想象一下，假設我們訓練一個標準的僅解碼器架構的 Transformer 模型，並採用多種並行策略來加速訓練。下面我們將看到兩種場景：&lt;/p&gt; 
&lt;p&gt;場景 #1：4x4x16 拓撲結構（TP+PP；共 256 塊芯片）&lt;/p&gt; 
&lt;p&gt;設定 z 軸為流水線 (PP) 維度，二維 TP 維度為 4x4。本質上，假設第 k 層位於 z=k 平面，且每層分片至 16 塊芯片。若未明確繪製，默認採用 OCS 最近鄰連接。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c158c58b081b3127519935fe864668599b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TP+PP 的 4x4x16 拓撲架構&lt;/p&gt; 
&lt;p&gt;通過在每個 z=k 平面實施 2D 環面扭曲，可加速 TP 層內芯片通信。由於 PP 層主要依靠點對點通信，因此沒有必要沿 PP 層扭曲。&lt;/p&gt; 
&lt;p&gt;注：實際應用中，扭曲環面在芯片數＞4x4 時效益顯著。本示例使用 4x4 僅出於可視化的目的。&lt;/p&gt; 
&lt;p&gt;場景 #2：16x4x16 拓撲（DP+TP+PP；共 1024 塊芯片）&lt;/p&gt; 
&lt;p&gt;作為延伸方案，我們在前一場景基礎上增加 DP 維度（x 軸 4 個實例），即沿 x 軸部署 4 組場景 #1 的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4e493d83184c5815acc5549e6e4ca1cac25.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DP+TP+PP 的 16x4x16 拓撲架構&lt;/p&gt; 
&lt;p&gt;請注意，扭曲環面僅應用於每個 DP 模型內的每個 TP 維度（即對每個 z=k 平面實施 4x4 二維扭曲，k 取值 1…16）。DP 維度僅維持基礎的環繞連接，使每行構成長度為 16 的水平環。&lt;/p&gt; 
&lt;p&gt;你可能已經發現還有一種拓撲結構方案（如 8x8x16，即 2x2 DP 維度），但這會混合 DP 與 TP 維度 —— 這就變得更加複雜了。具體來説，我們還不清楚如何在 y 軸構建 OCS 環繞連接的同時兼容各 TP 維度的扭曲環面？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.4 Multi-Pod 層級（即"Multislice"；TPUv4 支持 4096+ 塊芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e021ce9f1d8e82723b22c8fbdf6be01f8e7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU 層次結構的最終層級是 Multi-pod 架構。此時可將多個 Pod 視為一台大型機器，但 Pod 之間的通信需通過數據中心網絡（DCN） 進行 —— 其帶寬低於 ICI。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c5bb1c222fa2d34a24b8b089ee833b622c1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過 DCN 互聯的雙 Pod 架構&amp;nbsp;[1]&lt;/p&gt; 
&lt;p&gt;PaLM 模型即採用此方案進行訓練。在 6144 個 TPUv4 芯片（2 個 Pod）上耗時 56 天完成。下圖是 6 個 Pod 中的 TPU 任務分配情況：綠色為 PaLM 任務，紅色為空閒狀態，其餘為其他任務。注意每個方格代表一個 4x4x4 的 TPU 芯片立方體。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-791b4b38218cbfe875837f430b10f698ff7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PaLM 訓練過程中的 TPU Pod 利用率&amp;nbsp;[6]&lt;/p&gt; 
&lt;p&gt;實現這一架構已屬不易，但更關鍵的是開發者體驗設計，具體來説，就是要關注：&lt;strong&gt;如何實現模型擴展過程中系統/硬件層面的最大程度抽象化？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;谷歌的解決方案是：由 XLA 編譯器在大規模計算場景下協調芯片間的通信。研究人員只需配置相關參數（如 DP、FSDP、TP 等並行維度及切片數量），XLA 編譯器即會根據當前 TPU 拓撲結構自動插入分層集合通信操作（Xu et al, 2021: GSPMD&amp;nbsp;[2]）。我們的目標是在儘可能少修改代碼的情況下實現大規模訓練。&lt;/p&gt; 
&lt;p&gt;例如，谷歌博客[1]展示了跨多 TPU 切片的 all-reduce 操作分解流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-864563517512833776c5a4b7dd55fc20f47.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XLA 實現的跨 Pod All-Reduce 規約操作&lt;/p&gt; 
&lt;p&gt;這表明 XLA 編譯器可以同時處理切片內與切片間的集合通信操作。&lt;/p&gt; 
&lt;p&gt;舉個具體例子，在訓練模型時，TPU 的拓撲結構可能如下所示。激活值的通信在切片內通過 ICI 進行，而梯度的通信則需跨切片通過 DCN 完成（即在 DCN 的 DP 維度上）[1]。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f87c248ffd203825db16d7c22f26d12bcb7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 實物圖示對照解析&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;結合硬件實拍圖理解架構圖會更直觀，以下為綜合解析。&lt;/p&gt; 
&lt;p&gt;若看過谷歌 TPU 宣傳資料，可能見過下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ae14450a22f237528185172376402b3a6d3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 個 TPU 機架（TPUv4）&lt;/p&gt; 
&lt;p&gt;此圖為 8 個 TPU Pods 的集羣，每個單元即前述的 4x4x4 三維環面架構。一個 Pod 中的每一行有 2 個託盤，這意味着每一行有 8 個 TPU 芯片。&lt;/p&gt; 
&lt;p&gt;單塊 TPUv4 託盤實拍圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b5b9d5a5afd11a5c6d6ace8039c121749ab.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;請注意，圖中簡化為只有一個 PCIe 端口，但實際託盤上有 4 個 PCIe 端口（在左側） —— 每個 TPU 一個。&lt;/p&gt; 
&lt;p&gt;單芯片結構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5d7b5b890cac752887d5cf0368066797a60.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 芯片：中央是 ASIC + 4 組 HBM 內存堆棧&lt;/p&gt; 
&lt;p&gt;中央區域為 ASIC 芯片，周圍 4 個區塊為 HBM 內存堆棧。因 TPUv4 內含 2 個 TensorCore，故配置 4 組 HBM 內存堆棧。&lt;/p&gt; 
&lt;p&gt;未找到 TPUv4 芯片平面圖，此處展示結構近似的 TPUv4i（推理芯片），其僅含 1 個 TensorCore[3]：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-77ee6c51de3ea94847bc8083d166140baba.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 CMEM（芯片內存）在 TPUv4i 的佈局中佔據了相當大的空間。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 致謝&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;感謝 Google TPU Research Cloud（TRC）提供的 TPU 資源支持！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] Google Blog: TPU Multi-Slice Training（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fcompute%2Fusing-cloud-tpu-multislice-to-scale-ai-workloads%EF%BC%89" target="_blank"&gt;https://cloud.google.com/blog/products/compute/using-cloud-tpu-multislice-to-scale-ai-workloads）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] Xu, et al. "GSPMD: General and Scalable Parallelizaton for ML Computation Graphs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.04663%EF%BC%89" target="_blank"&gt;https://arxiv.org/pdf/2105.04663）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] Jouppi et al. "Ten Lessons From Three Generations Shaped Google's TPUv4i"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fai%2Fscaling%2Fhardware%2F2021-jouppi.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/ai/scaling/hardware/2021-jouppi.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] How to Scale Your Model - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Ftpus%2F%EF%BC%89" target="_blank"&gt;https://jax-ml.github.io/scaling-book/tpus/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] Domain Specific Architectures for AI Inference - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffleetwood.dev%2Fposts%2Fdomain-specific-architectures%23google-tpu%EF%BC%89" target="_blank"&gt;https://fleetwood.dev/posts/domain-specific-architectures#google-tpu）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] HotChips 2023: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc2023.hotchips.org%2Fassets%2Fprogram%2Fconference%2Fday2%2FML%2Btraining%2FHC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf%EF%BC%89" target="_blank"&gt;https://hc2023.hotchips.org/assets/program/conference/day2/ML+training/HC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Google Cloud Docs: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Ftpu%2Fdocs%2Fv4%EF%BC%89" target="_blank"&gt;https://cloud.google.com/tpu/docs/v4）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] Jouppi et al. "In-Datacenter Performance Analysis of a Tensor Processing Unit" -- TPU origins paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1704.04760%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/1704.04760）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9] Jouppi et al. "TPU v4"-- TPUv4 paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2304.01433%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2304.01433）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10] PaLM training video（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D0yPFBxkOKRY%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=0yPFBxkOKRY）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11] HotChips 2021: "Challenges in large scale training of Giant Transformers on Google TPU machines"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc33.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2021.Google.Sameer%2BKumar.pdf%EF%BC%89" target="_blank"&gt;https://hc33.hotchips.org/assets/program/tutorials/HC2021.Google.Sameer+Kumar.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12] HotChips 2020: "Exploring Limits of ML Training on Google TPUs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc32.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2020.Google.SameerKumarDehaoChen.v02.pdf%EF%BC%89" target="_blank"&gt;https://hc32.hotchips.org/assets/program/tutorials/HC2020.Google.SameerKumarDehaoChen.v02.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13] Google Blog: Ironwood（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgoogle-cloud%2Fironwood-tpu-age-of-inference%2F%EF%BC%89" target="_blank"&gt;https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14] HotChips 2019: "Cloud TPU: Codesigning Architecture and Infrastructure"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fold.hotchips.org%2Fhc31%2FHC31_T3_Cloud_TPU_Codesign.pdf%EF%BC%89" target="_blank"&gt;https://old.hotchips.org/hc31/HC31_T3_Cloud_TPU_Codesign.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15] ETH Zurich's Comp Arch Lecture 28: Systolic Array Architectures（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DXkgtANeDrm8%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=XkgtANeDrm8）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16] Patterson presentation: "A Decade of Machine Learning Accelerators: Lessons Learned and Carbon Footprint"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cs.ucla.edu%2Fwp-content%2Fuploads%2Fcs%2FPATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf%EF%BC%89" target="_blank"&gt;https://www.cs.ucla.edu/wp-content/uploads/cs/PATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17] Camara et al. "Twisted Torus Topologies for Enhanced Interconnection Networks."（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpersonales.unican.es%2Fvallejoe%2FPublications%2FC%25C3%25A1mara%2B-%2BTPDS%2710%2B-%2BTwisted%2BTorus%2BTopologies%2Bfor%2BEnhanced%2BInterconnection%2BNetworks.pdf%EF%BC%89" target="_blank"&gt;https://personales.unican.es/vallejoe/Publications/C%C3%A1mara+-+TPDS'10+-+Twisted+Torus+Topologies+for+Enhanced+Interconnection+Networks.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18] Horowitz article: "Computing's Energy Problem(and what we can do about it)"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fcs%2Fhardware%2F2014-horowitz-2.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/cs/hardware/2014-horowitz-2.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;您更傾向 TPU 的專用化路線（犧牲靈活性換取能效），還是 GPU 的通用化路線（保留靈活性但能耗較高）？請結合您的應用場景説明理由。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由 Baihai IDP 編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhenryhmko.github.io%2Fposts%2Ftpu%2Ftpu.html" target="_blank"&gt;https://henryhmko.github.io/posts/tpu/tpu.html&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18686348</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18686348</guid>
      <pubDate>Wed, 30 Jul 2025 07:14:07 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Claude Code 支持在單會話中添加多個工作目錄</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 旗下 AI 編程工具 Claude Code 現已支持在單個會話中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2F_catwu%2Fstatus%2F1950288312033562751" target="_blank"&gt;添加來自不同位置的多個工作目錄&lt;/a&gt;，方便用戶進行跨項目操作。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1728" src="https://static.oschina.net/uploads/space/2025/0730/145517_KA6C_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，用戶輸入命令/add-dir 即可添加新的工作目錄，讓模型能夠跨多個項目或文件夾進行操作和分析。&lt;/p&gt; 
&lt;p&gt;添加多個目錄有助於：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;單一代碼庫：無需切換會話即可跨目錄工作&lt;/li&gt; 
 &lt;li&gt;共享配置：從任何地方訪問記憶、待辦事項或其他文件&lt;/li&gt; 
 &lt;li&gt;跨項目工作：在倉庫間遷移代碼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.anthropic.com%2Fen%2Fdocs%2Fclaude-code%2Foverview" target="_blank"&gt;詳情查看文檔&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363159</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363159</guid>
      <pubDate>Wed, 30 Jul 2025 07:01:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年用戶增速最快億級 APP 榜單發佈，DeepSeek 位居第一</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據 Quest Mobile 的最新數據，2025 年 6 月活躍用戶規模超過 1 億且同比增長率最高的前 20 款應用程序新鮮出爐。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在這份榜單中，新興的 AIGC 應用 DeepSeek 以 1.63 億的月活躍用戶數量拔得頭籌，成為 AIGC 行業的領軍者。儘管 DeepSeek 是新上線的應用，導致其同比增長率無法顯示，但其快速崛起已經引起了市場的廣泛關注。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="407" src="https://oscimg.oschina.net/oscnet/up-523191ebc93cc7e261abb37db7e5fee206f.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與此同時，豆包在 AIGC 領域中表現同樣亮眼，月活躍用戶達到了 1.41 億，同比增幅高達 410.69%。這意味着豆包在短短一年內增加了 1.13 億的月活躍用戶，顯示出其強大的市場吸引力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在視頻娛樂行業，紅果免費短劇同樣表現不俗，月活躍用戶數達到 2.12 億，同比增長率為 178.99%。在支付領域，雲閃付的月活躍用戶也達到了 1.88 億，同比增長率為 78.50%。此外，這份榜單還涵蓋了多個行業的知名應用，如中國移動、大眾點評和米家等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;總的來看，2025 年的 APP 用戶增長趨勢顯示出 AIGC 和在線視頻等領域的強勁潛力，隨着用戶需求的不斷演變，這些應用有望在未來繼續引領市場潮流。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363155</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363155</guid>
      <pubDate>Thu, 17 Jul 2025 06:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊開源「短視頻理解模型」 ARC-Hunyuan-Video-7B</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊發佈了一款名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farc.tencent.com%2Fzh%2Fdocument%2FARC-Hunyuan-Video-7B" target="_blank"&gt;ARC-Hunyuan-Video-7B&lt;/a&gt;的開源多模態模型，專為真實世界短視頻進行「結構化理解 (Structured Video Comprehension)」而設計，具備強大的跨模態推理和時間感知能力。&lt;/p&gt; 
&lt;p&gt;該模型旨在解決用戶生成內容（如 TikTok、微信視頻號視頻）中常見的複雜視覺元素、高信息密度和快節奏等挑戰。模型通過端到端處理視覺、音頻和文本信號，實現對視頻的深度結構化理解。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/144325_Cgc2_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/144337_XSCf_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ARC-Hunyuan-Video-7B 引入了結構化視頻理解的新範式，具備多項關鍵能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過同步處理原始視聽信號進行復雜的跨模態推理；&lt;/li&gt; 
 &lt;li&gt;精確的時間感知能力；&lt;/li&gt; 
 &lt;li&gt;通過包含強化學習（RL）的多階段訓練實現的強大推理能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ARC-Hunyuan-Video-7B 基於 Hunyuan-7B 視覺語言模型構建，並增加了額外的音頻編碼器以實現視聽同步，同時採用時間戳疊加機制來增強時間感知。&lt;/p&gt; 
&lt;p&gt;該模型已在 Hugging Face 上開源，並提供了推理代碼（包括 vLLM 版本）和 API 服務。官方表示，在 H20 GPU 上，處理一分鐘視頻的推理時間僅為 10 秒。同時，團隊也發佈了指令調優的訓練代碼。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/TencentARC/ARC-Hunyuan-Video-7B&lt;br&gt; https://github.com/TencentARC/ARC-Hunyuan-Video-7B&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363154</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363154</guid>
      <pubDate>Thu, 17 Jul 2025 06:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>京東開源 Genie 智能體 8 大亮點</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#222222; margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#4d4d4d"&gt;京東開源的 Genie 智能體的 8 大亮點：&lt;br&gt; 可插拔多 Agent 和多種工具&lt;br&gt; 迭代式規劃&lt;br&gt; 跨任務上下文和文件共享&lt;br&gt; 數字員工提升用戶體驗&lt;br&gt; 大模型+搜索構建深度搜素&lt;br&gt; CodeTool 構建智能代碼生命週期管理&lt;br&gt; 精心打磨的 System Prompt&lt;br&gt; 可配置的 MCP Server&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//2343b439a2243a95f8d2c5f8f2116b33.jpeg" referrerpolicy="no-referrer"&gt; 
 &lt;p style="margin-left:0px; margin-right:0px"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//0ddf82ca93c3e10913e6fa3a23bdd2bc.jpeg" referrerpolicy="no-referrer"&gt; 
 &lt;p style="margin-left:0px; margin-right:0px"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src="https://oscimg.oschina.net/oscnet//7d3b0ac3731f217801ab1194f0b9c2e4.jpeg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18686023</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18686023</guid>
      <pubDate>Thu, 17 Jul 2025 06:36:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Meta 允許求職者在編程面試中使用 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，Meta 正在開發一種新型編程面試，候選人可使用 AI 助手，以更貼近未來工作環境。該公司還招募現有員工參與模擬 AI 輔助面試，以優化面試流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/142510_ttrT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;404 Media 獲得的內部通訊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.404media.co%2Fmeta-is-going-to-let-job-candidates-use-ai-during-coding-tests%2F" target="_blank"&gt;顯示&lt;/a&gt;，Meta 在本月早些時候發佈了一則內部公告：「AI 編程面試 —— 招募模擬候選人」。公告寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Meta 正在開發一種新型編程面試，讓候選人可以使用 AI。這更能代表我們未來員工將要工作的開發環境，同時也讓基於 LLM 的作弊變得不那麼有效。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Meta CEO 馬克・扎克伯格多次公開表示，預計到 2025 年，Meta 將擁有能擔任中級工程師的 AI，未來大部分代碼將由 AI 編寫。&lt;/p&gt; 
&lt;p&gt;儘管許多科技公司鼓勵工程師使用 AI，但允許面試中使用 AI 尚屬罕見，引發業界爭議，有觀點認為這可能導致新一代程序員過度依賴 AI 而缺乏問題解決能力。Meta 發言人表示，此舉旨在測試如何為申請人提供與日常工作中相同的 AI 工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363146</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363146</guid>
      <pubDate>Thu, 17 Jul 2025 06:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>HarmonyOS 5 終端數量破千萬</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;華為常務董事、終端 BG 董事長餘承東發文稱，截至 7 月 30 日，鴻蒙 5 終端數量已經突破了 1000 萬。「非常感謝每一位夥伴、開發者和用戶的支持和反饋！」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="533" src="https://oscimg.oschina.net/oscnet/up-28b80ec8e1707997154312822ba6469bbd9.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;餘承東稱，發佈不到一年，便以突破性速度完成生態蛻變，微信、支付寶、抖音、淘寶等國民級 APP 共同創造了「鴻蒙速度」。這一里程碑是標誌鴻蒙生態開啓正循環的重要起點！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在今年 6 月的開發者大會上，餘承東宣佈華為鴻蒙註冊開發者數量已突破 800 萬，目前已有超 3 萬個鴻蒙應用和元服務全速開發 / 更新中。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363145</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363145</guid>
      <pubDate>Thu, 17 Jul 2025 06:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包·圖像編輯模型 3.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;火山引擎&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSumKouPO-7zllWnbnZPPGQ" target="_blank"&gt;宣佈&lt;/a&gt;正式發佈豆包·圖像編輯模型 3.0、豆包·同聲傳譯模型 2.0，豆包大模型 1.6 系列全新升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「面向 Agent 開發和落地，火山引擎持續優化 AI 雲原生全棧服務，開源釦子核心能力，併發布企業自有模型託管方案、Responses API 等多個模型服務和工具產品，為企業和開發者構建 Agent、落地 AI 夯實基礎設施。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，豆包·圖像編輯模型 SeedEdit 3.0，具備更強的指令遵循能力、圖像保持能力和更強的圖像生成質量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-b7778cf08ae149be0084fa9d16f514815a1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;用戶只需通過自然語言指令，即可完成消除多餘內容、改變光影效果、替換文字等操作。同時，豆包·圖像編輯模型 3.0 具備對風格、結構與語義的精準控制力，能夠像人類大腦一樣理解指令、深度思考，解鎖更多創新的修圖場景，例如圖像風格轉換、變換材質、變化人物姿勢、根據提示詞進行推理等 P 圖玩法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;豆包·圖像編輯模型 3.0 可廣泛應用於影像創作、廣告營銷、遊戲宣傳等領域，企業用戶可在火山方舟平台調用該模型 API，個人用戶可使用即夢或豆包 App 的「豆包 P 圖」功能體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次全新發布的豆包·同聲傳譯模型 Seed-LiveInterpret 2.0，支持全雙工語音理解和生成框架，將傳統機器同傳的語音延遲從 8-10 秒降低到 2-3 秒，實現文本與語音的同步生成；無需提前錄製，一邊説話一邊採樣，實現 0 樣本聲音復刻，讓同一個人同音色開口説外語，帶來更沉浸的體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 6 月，豆包大模型 1.6 系列多個模型正式發佈。此次，極速版 Doubao-Seed-1.6-flash 模型在保持出色的視覺理解能力的同時，升級了代碼、推理、數學等大語言模型能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Doubao-Seed-1.6-flash 模型，非常適合智能巡檢、手機助手、智能硬件等對模型效果、速度和成本都有要求的大規模商業化場景。該模型具有業界領先的極低延遲，TPOT 僅 10ms，並依然具備強大的視覺理解能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;價格上，Doubao-Seed-1.6-flash 在輸入文本長度 0-32k 的區間中（企業使用量最大），每百萬 tokens 輸入僅需 0.15 元，輸出僅 1.5 元。在真實的客戶案例中，該模型幫助客戶延遲下降 60%，成本降低 70%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，火山引擎發佈全模態向量化模型 Seed1.6-Embedding，首次實現了「文本+圖像+視頻」混合模態的融合檢索，幫助企業構建更強大的多模態知識庫。在權威測評榜單中，該模型包攬了多模態全面任務、中文文本的 SOTA 成績。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363144</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363144</guid>
      <pubDate>Thu, 17 Jul 2025 06:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源基礎設施項目 AGNTCY 加入 Linux 基金會</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Linux 基金會發文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUhkUiPjmmkPr07DfWeb5ew" target="_blank"&gt;宣佈&lt;/a&gt;了 AGNTCY 的加入。AGNTCY 是一個開源基礎設施，支持不同廠商和框架的 AI 代理之間的發現、身份認證、消息傳遞和可觀測性。Cisco、Dell Technologies、Google Cloud、Oracle 和 Red Hat 作為創始成員加入了 Linux 基金會旗下的 AGNTCY 項目。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，AGNTCY 最初由 Cisco 於 2025 年 3 月開源，合作伙伴包括 LangChain 和 Galileo。項目已擴大到超過 65 家支持公司，提供「代理互聯網」的基礎設施，這是一層新的協作層，使多智能體系統無論由誰開發、運行在哪裏都能協同工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-ef4177066b1da696075c9462c652e3063f1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;隨着 AI 代理的普及，碎片化和廠商孤島問題加劇，阻礙代理間的安全通信、上下文共享和跨平台協作。AGNTCY 項目通過開放、通用的基礎設施，為開發者和組織提供安全的代理身份、可靠的消息傳遞和端到端的可觀測性，提升透明度、性能、效率和信任度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，AGNTCY 項目兼容主流 AI 代理技術，包括最近貢獻給 Linux 基金會的 Agent2Agent（A2A）項目和 Anthropic 的 Model Context Protocol（MCP）。AGNTCY 通過目錄使 A2A 代理和 MCP 服務器可發現，利用可觀測 SDK 提升透明度，並支持基於 Secure Low Latency Interactive Messaging（SLIM）協議的消息傳輸，從而實現動態多代理環境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="234" src="https://oscimg.oschina.net/oscnet/up-7f3a1ce042aed946646fda984b12bb530d0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Linux 基金會執行董事 Jim Zemlin 表示：「AGNTCY 項目為自主代理間的安全、互操作協作奠定基礎。我們很高興歡迎 AGNTCY 項目加入 Linux 基金會，確保其基礎設施保持開放、中立和社區驅動。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為代理協作的綜合基礎設施層，AGNTCY 項目的核心功能包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;代理發現：利用 Open Agent Schema Framework（OASF），使任何代理都能發現並理解其他代理的能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;代理身份：提供密碼學驗證的身份和訪問控制，確保代理能跨組織安全行動。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;代理消息：通過 SLIM 支持多模式、人工參與和量子安全通信。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;代理可觀測性：提供端到端可觀測工具，幫助評估和調試跨廠商和框架的複雜多代理工作流。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363143</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363143</guid>
      <pubDate>Thu, 17 Jul 2025 05:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GNU C Library 2.42 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;GNU C Library 2.42 已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.gnu.org%2Farchive%2Fhtml%2Finfo-gnu%2F2025-07%2Fmsg00011.html" target="_blank"&gt;發佈&lt;/a&gt;，GNU C Library 被設計為可移植和高性能的 C 庫。它遵循所有相關標準，包括 ISO C11 和 POSIX.1-2017，也是已知的最完善的國際化接口之一，廣泛應用於&amp;nbsp;GNU/Linux 系統以及其他使用 Linux 內核的系統。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;新版本包括新增多個數學函數，termios.h 接口支持任意波特率，基於 SFrame 的堆棧跟蹤支持（詳見&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flwn.net%2FArticles%2F1029189%2F" target="_blank"&gt;&lt;span style="color:#000000"&gt;本文&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;），&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flwn.net%2FArticles%2F1011366%2F" target="_blank"&gt;&lt;span style="color:#000000"&gt;內存保護頁&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt;支持以及一些安全修復。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;主要新功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&amp;lt;math.h&amp;gt; 中現在支持下列 ISO C23 function families（在 TS 18661-4:2015 中引入）。 每個系列包括 float、double、long double、_FloatN 和 _FloatNx，以及 &amp;lt;tgmath.h&amp;gt; 中的一個類型通用宏。&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style="color:#000000"&gt;冪和絕對值函數：compoundn、pown、powr、rootn， 平方根。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在 Linux 上，添加了 pthread_gettid_np 函數。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;現在支持 ISO C2Y family of unsigned abs functions，即 uabs、ulabs、ullabs 和 uimaxabs。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在 Linux 上，&amp;lt;termios.h&amp;gt; 接口現在支持任意波特率； speed_t 被重新定義為簡單的波特率，指定為 unsigned int，與內核接口匹配。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;malloc（tcache）中的線程本地緩存現在支持大塊緩存。可通過將 tunabl glibc.malloc.tcache_max 設置為較大值（最大值為 4194304）來啓用該功能。對於較小的數據塊，Tcache 的速度也明顯更快。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;新的配置選項「--enable-sframe」可用於啓用 GNU C 庫的 SFrame 支持。SFrame 是一種新的堆棧跟蹤信息格式，可用於反跟蹤。 它需要最低版本為 2.45 的 binutils。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;pthread_create 添加了通過 madvise 和 MADV_GUARD_INSTALL flag 對輕量級堆棧保護頁面的支持。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;從 CORE-MATH 項目中導入了更多經過優化和正確舍入的數學函數，特別是 acospif、asinpif、atanpif、atan2pif、cospif、sinpif、tanpif。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;測試套件已得到顯著擴展，包括 printf 和 scanf 函數族的多種變體功能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;對手冊進行了大幅擴展和更新，特別是線程、終端、文件系統、資源和數學章節。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;已添加代碼來檢測 x86-64 Intel Arrow Lake、Panther Lake、&amp;nbsp;Clearwater Forest 和 Diamond Rapids 微架構。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;關於 S390，增加了對新 z17 平台的支持。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;已棄用和刪除的功能以及其他影響兼容性的更改：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;glibc.rtld.execstack tunable 現在支持兼容模式，允許程序通過動態加載的共享庫獲得可執行堆棧。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在 Linux 上，&amp;lt;termio.h&amp;gt; header 和 &amp;nbsp;&amp;lt;sys/ioctl.h&amp;gt; 中的 struct termio 定義已被刪除。自 1988 年第一版 POSIX.1 以來，termio 接口就已過時，取而代之的是 &amp;lt;termios.h&amp;gt;。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在所有架構上，pthread mutexes 的 TX lock elision 的支持已被棄用，並將在下一版本中刪除。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在支持 Scalable Matrix Extension (SME) 的 AArch64 Linux targets 上，setjmp 和 sigsetjmp 將禁用 SME 的 ZA 狀態。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;構建和運行時要求的變更：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;現在需要 GCC 12.1 或更高版本來構建 GNU C Library。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;現在需要 GNU Binutils 2.39 或更高版本來構建 GNU C Library。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可查看&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.gnu.org%2Farchive%2Fhtml%2Finfo-gnu%2F2025-07%2Fmsg00011.html" target="_blank"&gt;此處&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363125/gnu-c-lib-2-42-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363125/gnu-c-lib-2-42-released</guid>
      <pubDate>Thu, 17 Jul 2025 03:57:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源中國亮相 WAIC 2025，聯合發佈《國際人工智能開源合作倡議》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 26-29 日，2025 世界人工智能大會暨人工智能全球治理高級別會議（簡稱「WAIC 2025」）在上海成功舉辦。會上，開源中國等多家單位共同發佈《國際人工智能開源合作倡議》，共同探討開源與人工智能融合發展的未來方向。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;《國際人工智能開源合作倡議》正式發佈&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bd50bdf6400c4f4f94d6bcec1db2dcbddfb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開幕式上，工業和信息化部推動&lt;strong&gt;中國 —&lt;/strong&gt; &lt;strong&gt;金磚國家人工智能發展與合作中心聯合開放原子開源基金會、開源中國、中國開發者網絡&lt;/strong&gt;等機構，共同發佈了《國際人工智能開源合作倡議》。鼓勵各方以開源為紐帶，深化人工智能領域開源合作，攜手打造人工智能開源開放生態體系。&lt;/p&gt; 
&lt;p&gt;當前，由智能化驅動的全球新一輪科技革命和產業變革加速演進，人工智能新技術不斷突破、新業態持續湧現、新應用加快拓展，開源已經成為人工智能創新發展的重要引擎。倡議呼籲全球開發者、企業、學術機構與公共部門攜手，以開源為紐帶，支持產學研各界，共商技術創新路線、共促技術成果賦能、共建開放包容社區、共享時代發展紅利。&lt;/p&gt; 
&lt;p&gt;倡議提出五大方向：一是引領創新，驅動技術新突破。鼓勵開源合作創新，分享人工智能領域的研究成果、技術經驗，縮短創新鏈路。二是培育生態，探索共治新路徑。支持開源基金會等開源組織加強溝通交流，打造開放包容的國際開源社區，提供良好的基礎設施，促進算力開放、數據共享、算法開源、應用探索，引導人工智能標準共建，促進開源生態與標準化進程協同發展。三是賦能轉化，加速應用新進程。加速人工智能創新前沿技術成果轉化，促進智能體協議等基礎規則共識互認，探索從研發端到產業應用的高效落地路徑，以開源協作機制彌合技術研發與市場應用間的鴻溝。四是守護權益，尊重創新新價值。知識產權保護是確保開源項目可持續發展的關鍵，尊重各方的知識產權，鼓勵行業自律，支持開源許可協議跨境互認和合規使用，促進開源標準制定，保護開發者和社區的合法權益。五是開放共享，普惠全球新未來。秉持「智能向善」的理念，鼓勵不同國家、不同領域的開發者參與跨界合作，促進多元文化的交流與融合。&lt;/p&gt; 
&lt;p&gt;開源中國致力於為開發者搭建高效的開源協作平台，匯聚全球優質開源資源，助力國內企業在開源技術創新上不斷突破。在數字技術高速演進、人工智能重塑產業格局的時代背景下，構建開放、包容、可持續的全球協作機制顯得尤為重要。開源中國將繼續秉持開放精神，深度參與社區建設，攜手全球夥伴共建共享，為推動構建人類數字命運共同體貢獻更多開源力量。&lt;/p&gt; 
&lt;h3&gt;關於開源中國&lt;/h3&gt; 
&lt;p&gt;開源中國（成立於 2008 年）致力於為開發者搭建高效的開源協作平台與 AI 創新支持，助力國內企業在開源技術創新上不斷突破，通過覆蓋開源內容與活動、軟件工程研發工具、人才培訓和 AI 開發平台等多元產品體系，搭建起從社區學習、協作、研發全流程到創新高質量落地的完整鏈條，為中國開源生態與 AI 創新提供堅實技術基礎和活力生態。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-38740ec5ecaf47b6d70b3fc235c78d84cda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2013 年，開源中國發布代碼託管平台 Gitee ，並於 2020 年開始牽頭建設工信部國家開源託管平台項目。Gitee 於 2017 年上線發佈針對企業級的研發效能平台 Gitee 企業版。截至目前，Gitee 已經服務 1350 萬開發者用戶、36 萬家企業以及 2000 多家高等院校。&lt;/p&gt; 
&lt;p&gt;2020 年以來，開源中國深耕 DevOps 全生命週期國產替代方案，在滿足開發者需求的同時，打造出一個自主創新、安全可信的本土開源軟件工具與生態，減少開發者對海外開源軟件的過度依賴，構建安全可控的中國信息化體系。當前 Gitee DevOps 工具鏈已在金融、軍工等關鍵領域實現 80% 市場滲透率，成為信創替代工程的標杆案例，驗證了開源商業化的中國路徑。&lt;/p&gt; 
&lt;p&gt;在人工智能時代，開源中國於 2024 年推出 AI 大模型平台模力方舟，首創「模型數據 - 算力調度 - 應用開發」全棧服務體系。&lt;/p&gt; 
&lt;p&gt;截至目前，模力方舟已匯聚 10000+ 模型，覆蓋文本生成、圖像生成、語義理解、多模態等任務形態，可廣泛應用於政務、金融、運營商、製造、零售等多個行業場景。而在算力支持方面，模力方舟目前已支持包括天數智芯、沐曦、昇騰、燧原、壁仞等國產算力，加速推進國產 AI 應用的百花齊放。&lt;/p&gt; 
&lt;p&gt;開源中國下一步將以模力方舟為核心，打造全方位的 AI 業務佈局，助力 AI 應用創新、科技人才培養和新質生產力提升。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363117</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363117</guid>
      <pubDate>Thu, 17 Jul 2025 03:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>前谷歌 CEO：開源已成為 AI 發展中的重要特點</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 26 日，在世界人工智能大會（WAIC）上，前 Google CEO 埃裏克·施密特（Eric Schmidt）圍繞「人工智能全球合作展望」的主題，與港科技大學校董會主席沈向洋展開了一場「爐邊對話」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8c2365f2f0b1260c4f8f9b0577b7c3ed1e1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;施密特強調，過去兩年，中國的 AI 技術，特別是 DeepSeek 和 Mini Max、Kimi 等大模型，已經取得了舉世矚目的成就。施密特指出，「在中國，這些領先的 AI 模型並非所有主要模型都像美國那樣採取封閉策略。」而這也成為了當前 AI 發展中的一個重要特點。&lt;/p&gt; 
&lt;p&gt;對話中，施密特坦言自己更傾向於支持開源。其表示，開源技術雖然有一些潛在風險，但人類可以通過設定一些限制措施來管理這些風險，並根據需要對其進行調整。而對於這種情況，施密特則認為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;問題的關鍵在於技術的「編輯者」是誰，以及這些技術在哪些地方得以應用，在哪些地方去設置「防護欄」。理想的場景是，我們能根據人類的價值觀來訓練和對齊這些模型。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;另外，施密特認為，未來超級智能之間的協作最終是不可避免的。因為隨着技術的發展，人類將會擁有一個超級智能系統，未來這些系統會有能力去相互協作和協調。而對於這種情況，施密特則認為「需要讓中國和西方的研究人員能夠互相交流，合作探討，達成在價值觀方面一致性」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363114</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363114</guid>
      <pubDate>Thu, 17 Jul 2025 03:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Java volatile 關鍵字到底是什麼</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;一,前言&lt;/h2&gt; 
&lt;p&gt;volatile 作為 Java 的基礎關鍵字，一直是個熟悉又神祕的存在。我們在日常做併發編程的過程中經常用到，我們知道在什麼場景下需要用到，但卻始終不清楚底層究竟做了什麼。互聯網上搜出來的大多數博客都在解釋 volatile 關鍵字是為瞭解決指令重排序、內存可見性問題，或是什麼內存屏障、緩存一致性協議一類「形而上的詞彙」。而究竟什麼是指令重排序，為什麼要重新排序，什麼是可見性問題，底層原理是什麼，volatile 又是如何解決的卻鮮有提及。引得 Java 開發者們如霧裏看花，線上線下充滿了疑惑的空氣。&lt;/p&gt; 
&lt;p&gt;本文將淺淺探究一下這一切的底層原理，一起來學習「沒有用」的知識，各位看官看懂了可以出去和麪試官對線。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;二,指令重排序&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;在瞭解指令重排序問題之前，我們先來看一個由指令重排序造成併發問題的例子：&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static int x = 0, y = 0;


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;happens-before 八條原則&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;程序次序規則：在一個線程內，按照控制流順序，書寫在前面的操作先行發生於書寫在後面的操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;管程鎖定規則：一個 unlock 操作先行發生於後面對同一個鎖的 lock 操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;volatile 變量規則：對一個 volatile 變量的寫操作先行發生於後面對這個變量的讀操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;線程啓動規則：Thread 對象 start() 方法先行發生於此線程的每一個動作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;線程終止規則：線程 A 等待線程 B 完成，在線程 A 中調用線程 B 的 join() 方法實現），當線程 B 完成後（線程 A 調用線程 B 的 join() 方法返回），則線程 A 能夠訪問到線程 B 對共享變量的操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;線程中斷規則：對線程 interrupt() 方法的調用先行，發生於被中斷線程的代碼，檢測到中斷事件的發生，可以通過 Thread.interrupted() 方法檢測到是否有中斷髮生。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對象終結規則：一個對象的初始化完成（構造函數結束）先行發生於它的 finalize() 方法的開始。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;傳遞性：如果操作 A 先行發生於操作 B，操作 B 先行發生於操作 C，那就可以得出操作 A 先行發生於操作 C 的結論。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;hanpens-beofre 是 JVM 對開發者的保證，即不管 JVM 如何優化（JIT 編譯），都會保證上述原則一定成立。而對於開發者來説，只要瞭解上述原則，無需硬件交互的複雜性，也能夠寫出可預測的代碼，從而保證線程安全。&lt;/p&gt; 
&lt;p&gt;從 hanpens-beofre 中&amp;nbsp;程序次序規則&amp;nbsp;和&amp;nbsp;線程終止規則&amp;nbsp;可得，上述代碼最終運行結果的可能性會有以下幾種：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//3cdd1d958189182a00e4240e8478e7d2.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以明顯看出，理論上不會存在 x =0 &amp;amp;&amp;amp; y = 0 的運行結果，然而實際上程序在執行了一段時間後，最終的確產生了 x = 0 &amp;amp;&amp;amp; y = 0 的結果！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d299df0dffd0aed1af23392270f21099.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這就引出了 volatile 解決的第一個問題：避免指令重排序。指令重排序在&lt;strong&gt;編譯器&lt;/strong&gt;和&amp;nbsp;&lt;strong&gt;CPU 層面&lt;/strong&gt;（亂序執行）都會發生。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 的亂序執行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們知道，CPU 運算的本質就是不斷獲取下一條指令然後執行，編譯器給它什麼指令它就執行什麼，何來的亂序執行呢？&lt;/p&gt; 
&lt;p&gt;這還要從計算機的誕生之初講起。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;內存拖後腿&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;計算機誕生之初，CPU 和內存之間的速度差異並不明顯，一切相安無事。隨着科學的進步，CPU 的運算速度越來快，根據摩爾定律計算，相當於 CPU 的性能每年增長 60%，相比之下，內存性能的增長卻相對緩慢，每年約為 7%。到今天，CPU 運算和內存訪問的速度產生了巨大鴻溝，已經達到了 120 倍之多。這時如果 CPU 還以傳統計算機架構，數據從內存中讀取的話，將會&lt;strong&gt;嚴重拖慢 CPU 的運行速度&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//74f2bda3199bee06b728910d5812a79f.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 局部性原理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在程序運行過程中，芯片工程師總結了兩條存在局部性原理：&lt;strong&gt;時間局部性&lt;/strong&gt;、&lt;strong&gt;空間局部性&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;時間局部性：&lt;/strong&gt; 由於在代碼中循環操作的普遍存在，因此當某部分數據被訪問時，不久後該數據很可能會再次被訪問，基於此原理誕生了&amp;nbsp;CPU 的高速緩存。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;空間局部性：&lt;/strong&gt; 由於代碼是順序執行的，因此當某一份數據被訪問時，後續的數據也將很快被訪問，基於此原理誕生了緩存行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;※ CPU 內的高速緩存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了彌補 CPU 運行速度與內存訪問速度之間的巨大差異，提升 CPU 執行效率，CPU 在內部封裝了高速緩存。&lt;/p&gt; 
&lt;p&gt;高速緩存是一種靜態隨機訪問存儲器（SRAM），相對於使用電容存儲的內存（DRAM）來説，速度快得多，訪問速度在納秒級別，終於能勉強不再拖 CPU 後腿了。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//df49b1c83f72ca41af1507ee63c095c0.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 緩存共分為三級：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;按訪問速度從大到小排序為：L1 &amp;gt; L2 &amp;gt; L3&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;按容量從大到小排序為：L3 &amp;gt; L2 &amp;gt; L1&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;其中 L3 緩存 CPU 共享，L1、L2 緩存為各 CPU 獨佔。CPU 在訪問內存數據時，會優先從高速緩存中訪問，訪問順序依次為 L1、L2、L3，若高速緩存中都不存在，則再訪問內存。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;緩存的引入，降低了 CPU 直接訪問內存的頻率，大大提升了 CPU 的執行效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 緩存行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;根據空間局部性原理，當 CPU 訪問了一塊數據時，相鄰的數據很可能也即將被訪問。那麼是否可以通過預加載相鄰的數據到高速緩存中，提升高速緩存的命中率呢？&lt;/p&gt; 
&lt;p&gt;當然可以，我們把預加載的這部分內存數據叫做緩存行。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//95b79b1e2f5130409268c63e893e219d.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;由圖所示，內存被劃分為若干緩存行的塊，緩存行的大小是固定的，通常為 64 字節，高速緩存數據塊最小粒度就是緩存行（換句話説，高速緩存內的數據就是由一個個緩存行構成的）。當 CPU 需要訪問位於內存的數據 X 時，會將整個緩存行同時加載到高速緩存中，以提升程序後續執行時的緩存命中率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 內的「分佈式」問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;高速緩存是把雙刃劍，在大幅提升 CPU 運行效率的同時，也引來了一個 「分佈式」 問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c15707c1d91622f6ffd07aa5081c4768.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;記得我們前面説過，CPU 的 L1、L2 緩存是各核心獨佔的，在兩個 CPU 的 L2 緩存同時加載了同一個緩存行的情況下，當 CPU 0 數據 X 做了寫操作（X = 1），其他 CPU 對這一修改是不可見的，這時 CPU 1 如果依然訪問自己高速緩存中的數據，勢必會產生數據不一致。&lt;/p&gt; 
&lt;p&gt;為瞭解決這個問題，緩存一致性協議便誕生了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ &amp;nbsp;MESI 協議&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;緩存一致性協議有多種，最出名的就是 MESI 協議。&lt;/p&gt; 
&lt;p&gt;MESI 是&amp;nbsp;Modified&amp;nbsp;&amp;nbsp;&amp;nbsp;Exclusive Shared&amp;nbsp;&amp;nbsp;&amp;nbsp;Invalid&amp;nbsp;四個單詞的縮寫，分別表示緩存行的四種狀態：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Modified：表示緩存行中數據已經被 CPU 修改了。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Exclusive：緩存行處於獨佔但尚未修改的狀態，該狀態表示其他 CPU 不可以預讀取這個緩存行到自己的高速緩存中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Shared：表示緩存行數據已經被多個 CPU 預加載到緩存中，且各 CPU 均未對該緩存行做修改。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Invalid：表示有其他 CPU 修改了該緩存行，緩存行數據已經失效。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//50733d9a050bd27bace430e3aea6fb73.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;CPU 0 需要修改緩存行中 X 的數據時，將當前緩存行標記為&amp;nbsp;Modified&amp;nbsp;，並向總線發送一條消息，表明緩存行 CPU 0 已經修改。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU 1 接收到該緩存行已失效的消息後，會將本地緩存行標記為&amp;nbsp;Invalid&amp;nbsp;，並 ACK 給 CPU 0。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU 0 收到其他 CPU 已經將本地緩存行標記失效消息後，修改 X 的值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此時 CPU 0 高速緩存中緩存了 X 的最新值，其他 CPU 如果需要訪問 X ，將會通過總線從 CPU 0 中獲取。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;MESI 協議非常複雜，比如各 CPU 之間是如何通信的、多個 CPU 同時發送失效事件怎麼辦等等。&lt;/p&gt; 
&lt;p&gt;篇幅所限僅做本文用的着的部分介紹。有興趣瞭解具體實現可以點擊&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fwww.scss.tcd.ie%252FJeremy.Jones%252FVivioJS%252Fcaches%252FMESI.htm" rel="nofollow" target="_blank"&gt;https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESI.htm&lt;/a&gt;&amp;nbsp;查看動畫演示。&lt;/p&gt; 
&lt;p&gt;緩存一致性協議有效解決了各 CPU 間數據一致性問題。那麼，代價是什麼呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;禁止 CPU 摸魚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上圖可以看出 CPU 0 在執行修改 X 的值之前，需要與其他 CPU 進行通訊，收到其他 CPU 將本地消息修改完成後，才可修改本地緩存行的數據。在這期間 CPU 0 一直無事可做。而不管是前面提到過的編譯器指令重排序還是超線程、指令流水線等技術，目的都是在提升 CPU 的運行效率，減少 CPU 空跑時間。如果由於緩存一致性協議造成 CPU 空閒的話，這對於我們來説顯然是不可接受的！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//5f847754f3567b6847c05e20931cc4fc.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了讓 CPU 滿負荷運轉，芯片工程師在 CPU 與 L1 緩存之間又加了一層——store buffer。&lt;/p&gt; 
&lt;p&gt;引入了 store buffer 後，CPU 寫緩存行不再需要等待其他 CPU 回覆消息，而是直接讀寫 store buffer，等到特定時刻，再將 store buffer 中的數據 flush 到高速緩存中&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//0bfd788352134ddf050c04c07fd3ba19.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;CPU 0 需要修改緩存行中 X 的數據時，將當前緩存行標記為&amp;nbsp;Modified&amp;nbsp;，並向總線發送一條消息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU 0 不再等待 CPU 1 回覆，而是直接將修改後的數據寫入 store buffer 中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CPU 0 收到 CPU 1 標記緩存已經失效的回覆消息後，將 store buffer 中的值 flush 到高速緩存中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;問題會這麼完美的解決嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1,亂序執行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現在我們將 store buffer 納入考量，再來回頭看本節開始的這段代碼：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//005e5ed86a1fa2d021244995173dd8e2.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最終由於 store buffer 中數據的 flush 時間晚於 CPU 直接寫高速緩存中數據的時間，客觀上產生了 CPU 執行的指令順序與實際代碼中不一致的現象（X = B 早於 A = 1 執行，Y = A 早於 B = 1 執行），即亂序執行。最終得到了（A = 1，B = 1，X = 0，Y = 0）的結果。&lt;/p&gt; 
&lt;p&gt;既然發現了問題，那麼要如何解決呢？這就要提到另一項技術：內存屏障。&lt;/p&gt; 
&lt;p&gt;隨着 store buffer 技術的引入引起的問題還有很多，於是牽扯出一系列其他技術，如 Store Forwarding、Invalidate Queues 等技術。由於與本文涉及到的內容無關，這裏就不做贅述了，各位有興趣可以自行了解相關內容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2,內存屏障&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;內存屏障聽起來比較高大上，實際總結起來非常簡單，就一句話：&lt;/p&gt; 
&lt;p&gt;去告訴 CPU，我在此處定義了一個內存屏障，自這裏開始，後續所有針對高速緩存的寫入，都必須先把 store buffer 中的數據全部 flush 回高速緩存中！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//e356e96b22c7fc2a5b93771d0f05f855.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//645eb0c5306cea04465dd863a54df479.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Java 中 volatile 關鍵字避免 CPU 亂序執行的原理其實就是在訪問 volatile 變量時添加了內存屏障。限制後續數據的寫入操作一定把當前 store buffer 中的數據 flush 到高速緩存中，再通過緩存一致性協議保證數據一致性。&lt;/p&gt; 
&lt;p&gt;回到本節一開始的代碼，你一定想到了要如何讓這段程序永遠執行下去的辦法了？&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static int x = 0, y = 0;


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;沒錯，我們只需要限制針對數據 X、Y 的寫操作之前，位於 store buffer 中的數據 A、B 全部 flush 到高速緩存即可。所以最終的解決方案就是給變量 A、B 添加 volatile 關鍵字即可！&lt;/p&gt; 
&lt;p&gt;想想為什麼在變量 X、Y 上加 volatile 不可以？説加 4 個 volatile 的那位同學，課後把內存屏障這一章節抄寫 3 遍！&lt;/p&gt; 
&lt;p&gt;前面説過，指令重排序問題在 CPU 和編譯器層面都存在，CPU 層面説完了，那編譯器層面呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3,編譯器重排序&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由於 JIT 編譯後的指令不好扒，我們以 C 語言為例，先來看看下面的 C 語言例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int func(int a, int b, int c, int d) {


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果編譯器不做優化，如果完全順從我們代碼語義，以上函數生成的彙編偽代碼如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//bce796732b45c8f9715c0e642c9c0d85.webp" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d067e3dadbb45a3a86d13e436f95b568.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;而現代 CPU 會有多個執行單元，例如讀寫單元、運算單元，這些執行單元之間可以獨立工作。在執行上面的指令時，只能順序執行，不能並行執行。要想發揮兩個執行單元的效率，只需調整一下順序即可：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1e11767b2686f416c6fc88589e7aa957.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//95fc29473b1f7b9a5427d6c06d51045e.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，雖然指令的數量一樣，但在對指令做簡單的重新排序後，優化一下指令的提交順序，就可以更快的完成任務。&lt;/p&gt; 
&lt;p&gt;在 JVM 中，JIT 編譯同樣也會遵循這一原則，在不改變源碼語義的情況下，改變 CPU 指令的執行順序，就可以更快的完成運算任務，提升執行效率。這在單線程情況下運行良好，但多線程運行時，就可能會存在一些意料之外的問題。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;三,可見性問題&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;再來看另一個示例：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private static boolean running = true;


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上面的程序，並不會按照我們預期的那樣正常輸出程序結束後退出，而是會永遠的執行下去（不要嘗試用前文中的 store buffer 來強行解釋這個問題，store buffer 本質上也是個 buffer，在某一時刻數據依然會 flush 到高速緩存中，從而讓其他線程感知到最新的值）。&lt;/p&gt; 
&lt;p&gt;這就引出 volatile 關鍵字解決的另一個問題：內存可見性問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分層編譯&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我們知道，Java 是跨平台的。一個 Java 源碼文件的執行需要兩個過程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;AOT 編譯：源代碼文件編譯為 class 文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;JIT 編譯：JVM 加載 class 文件，將 class 文件中字節碼轉換為計算器可執行的機器指令。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;字節碼的執行也有兩種方式：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;解釋執行：優點是啓動速度快，缺點是需要逐條將字節碼解釋為機器指令，開銷大，性能低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;編譯執行（JIT 編譯）：優點是執行效率高，與本地編譯性能基本沒差別，缺點是編譯本身需要消耗 CPU 資源，以及編譯後的指令數據需要存儲，需要消耗內存空間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;而 JIT 編譯器又分為兩種，Client Compiler、Server Compiler。之所以叫 client，server 是因為在一開始設計這倆編譯器的時候，前者是設計給客戶端程序用的，就比如像 idea 這種運行在個人電腦上的 Java 程序，不會長時間使用，反而更注重應用的啓動速度以及快速達到相對較優性能。而後者則是設計給服務端程序用的。&lt;/p&gt; 
&lt;p&gt;HotSpot 虛擬機帶有一個 Client Compiler —— C1 編譯器。這種編譯器啓動速度快，但是性能相對 Server Compiler 來説會差一些。Server Compiler 則更為激進，優化後的性能要比 Client Compiler 高 30% 以上。HotSpot 虛擬機則帶有兩個 Server Compiler，默認的 C2 以及 Graal。&lt;/p&gt; 
&lt;p&gt;在 Java 7 之前，需要開發者根據服務的性質手動選擇編譯器。自 Java 7 開始，則引入了分層編譯（Tiered Compilation）。&lt;/p&gt; 
&lt;p&gt;0：由解釋器解釋執行&lt;/p&gt; 
&lt;p&gt;1：C1 NO profiling：執行不帶 profiling 的 C1 代碼。&lt;/p&gt; 
&lt;p&gt;2：C1 LIMITED profiling：執行僅帶方法調用次數以及循環回邊執行次數 profiling 的 C1 代碼。&lt;/p&gt; 
&lt;p&gt;3：C1 FULL profiling：執行帶所有 profiling 的 C1 代碼。&lt;/p&gt; 
&lt;p&gt;4：C2：執行 C2 代碼。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;誰動了我的代碼&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;運行時編譯有那麼多層級，到底是哪層影響了代碼的？&lt;/p&gt; 
&lt;p&gt;想要探究個問題很簡單，只需要在 JVM 啓動參數裏增加 -XX:TieredStopAtLevel=XX 參數即可。TieredStopAtLevel 是控制 JVM 最大分層編譯級別的參數，當我們配置的值 &amp;lt; 4 時，前文的代碼均可以正常終止，那麼結論很明顯了：C2 編譯器全責！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;C2 你在幹什麼？！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為了探究 C2 編譯對我們代碼做了什麼，我們決定使用一款工具：JITWatch。JITWatch 專門用來探究 JIT 編譯後的代碼對應彙編指令。&lt;/p&gt; 
&lt;p&gt;關於 JITWatch 使用的流程這裏就不做贅述了，網上有大量説明。本節的案例也很好復現，大家可以動手試一試。&lt;/p&gt; 
&lt;p&gt;我們將前文的源碼文件編譯後，提交以下命令執行：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Ubuntu 22.04 下


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;接着啓動 JITWatch，加載 jit.log 文件：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1acdea4138e33b21ea4057fa78e698c9.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;雙擊右側 main 方法，查看 C2 編譯後的結果：&lt;/p&gt; 
&lt;p&gt;記得選 OSR（棧上替換） 那個 C2，因為代碼屬於死循環，代碼塊不會退出，無法完整替換 C2 編譯後的機器指令，只能通過棧上替換技術來進行。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d8140526e1396da45c08bbda37be496c.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;綠色框中為我們的核心代碼，我在此處將它放大並增加了註釋，如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//4a58338befde76e1885fc0305a185d48.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;什麼？無條件跳轉？！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，由於 C2 編譯器的激進優化，編譯後的機器碼不再判斷 running 變量，從而產生了內存可見性問題。而即使 C2 編譯後的機器指令依然會執行安全點檢查。想想是不是可以利用安全點檢查機制，用一些操作來讓進程停止？比如提交執行一次 GC、打個斷點之類的。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;四,總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;説了那麼多，能不能説點有用的？&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;有的有的，我們在多線程開發中，只要變量被多個線程共享，且是可變的，加上 volatile 準沒錯：）&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;strong&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;1.&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzkxNTE3ODU0NA%253D%253D%2526mid%253D2247540596%2526idx%253D1%2526sn%253D25f44a0aba699c43c90c55065a6d5ec4%2526scene%253D21%2523wechat_redirect" rel="nofollow" target="_blank"&gt;社區搜索離線回溯系統設計：架構、挑戰與性能優化｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;2.&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzkxNTE3ODU0NA%253D%253D%2526mid%253D2247540484%2526idx%253D1%2526sn%253D6b9e3947c74051d6778e9bf5436e9d87%2526scene%253D21%2523wechat_redirect" rel="nofollow" target="_blank"&gt;從 Rust 模塊化探索到 DLB 2.0 實踐｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;3.&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzkxNTE3ODU0NA%253D%253D%2526mid%253D2247540454%2526idx%253D1%2526sn%253Df279b38d1e8d5e0b77dc96719066ddea%2526scene%253D21%2523wechat_redirect" rel="nofollow" target="_blank"&gt;eBPF 助力 NAS 分鐘級別 Pod 實例溯源｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;4.&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzkxNTE3ODU0NA%253D%253D%2526mid%253D2247540409%2526idx%253D1%2526sn%253Df3ae16d2ea439828c4452d92a5e46d53%2526scene%253D21%2523wechat_redirect" rel="nofollow" target="_blank"&gt;正品庫拍照 PWA 應用的實現與性能優化｜得物技術&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;5.&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fmp.weixin.qq.com%252Fs%253F__biz%253DMzkxNTE3ODU0NA%253D%253D%2526mid%253D2247540215%2526idx%253D1%2526sn%253D72a0573520a8032d33b622f25bdd0671%2526scene%253D21%2523wechat_redirect" rel="nofollow" target="_blank"&gt;得物社區活動：組件化的演進與實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;文 / 空載&lt;/p&gt; 
&lt;p style="text-align:center"&gt;關注得物技術，每週二、四更新技術乾貨&lt;/p&gt; 
&lt;p style="text-align:center"&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p style="text-align:center"&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;如有任何疑問，或想要了解更多技術資訊，請添加小助手微信&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18686270</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18686270</guid>
      <pubDate>Thu, 17 Jul 2025 03:22:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>蘋果又一位 AI 研究員將跳槽 Meta，核心模型團隊動盪加劇</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;蘋果公司一個月內失去第四位人工智能（AI）研究員，轉投競爭對手 Meta。知情人士稱，蘋果公司在多模態 AI 領域的關鍵研究員 Bowen Zhang 已於週五離職，將加入 Meta 新近成立的超級智能團隊。Zhang 曾為蘋果基礎模型團隊（AFM）成員，該團隊構建蘋果 AI 平台背後的核心技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前報道，Meta 此前以超過 2 億美元的一攬子薪酬挖走該團隊的負責人 Ruoming Pang。該團隊另外兩位研究員 Tom Gunter 和 Mark Lee 近期也加入了 Meta。AFM 團隊由位於加州庫比蒂諾與紐約的數十名工程師和研究人員組成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;因這些變動為非公開信息而不願具名的知情人士表示，為應對來自 Meta 等公司的挖角，蘋果一直在對 AFM 團隊成員小幅加薪，無論其是否表達過離職意向。儘管如此，相比競爭對手，蘋果的薪資水平仍然相形見絀。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;蘋果和 Meta 的發言人均拒絕發表評論。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在紐約，蘋果股價一度下跌 1.5%，至 210.82 美元，創下盤中新低。截至週一收盤，該股今年以來已累計下跌 15%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這些離職讓蘋果的模型團隊陷入動盪。Pang 在制定該部門的發展路線圖和研究方向方面發揮了核心作用，AFM 內部多位人士目前表示，該部門的未來並不明朗。知情人士稱，其他工程師正在積極面試其他職位。另一位團隊成員 Floris Weers 最近幾周離職，加入了一家初創公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="338" src="https://oscimg.oschina.net/oscnet/up-b10a450d3c7e2ff7f765952beb662f23c6c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;蘋果高管 John Giannandrea（左）和 Craig Federighi&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AFM 團隊對蘋果整體 AI 戰略至關重要。該團隊的工作為去年推出的 Apple Intelligence 平台奠定了基礎。但現在，該公司正在考慮轉向使用更多第三方模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士稱，一些蘋果高管把其自主研發的模型視為追趕 AI 對手的絆腳石。而且圍繞是否外包該技術的不確定性打擊了公司士氣，加劇了員工流失。AFM 團隊目前由 Zhifeng Chen 領導，向蘋果 AI 研究主管 Daphne Luong 彙報。她向 AI 高級副總 John Giannandrea 彙報工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/360982" target="news"&gt;&lt;span style="color:#2980b9"&gt;Meta 在挖走蘋果 AI 部門主管後，再次挖走兩名核心專家&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363101</guid>
      <pubDate>Thu, 17 Jul 2025 02:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Elasticsearch 9.1.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Elasticsearch 是一個基於 Lucene 庫的搜索引擎。它提供了一個分佈式、支持多租戶的全文搜索引擎，具有 HTTP Web 接口和無模式 JSON 文檔。Elasticsearch 基於 Java 開發，並在 SSPL + Elastic License 雙重授權許可下作為開源軟件發佈。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Elasticsearch 9.1.0 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fdocs%2Frelease-notes%2Felasticsearch%23elasticsearch-9.1.0-release-notes" target="_blank"&gt;發佈&lt;/a&gt;，更新亮點包括：&lt;/p&gt; 
&lt;div style="margin-left:0; margin-right:0"&gt; 
 &lt;div style="margin-left:0; margin-right:0"&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt; 
   &lt;div style="margin-left:0; margin-right:0"&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;將&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;repository-s3&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;升級到 AWS SDK v2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在早期版本的 Elasticsearch 中，&lt;code&gt;repository-s3&lt;/code&gt;插件基於 AWS SDK v1。AWS 將在 Elasticsearch 9.1 生命週期結束前停止對此 SDK 的支持，因此已將此插件遷移到較新的 AWS SDK v2。這兩個 SDK 並不完全兼容，因此在升級任何生產工作負載之前，建議用戶查閲重大變更文檔並徹底測試新版本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;添加將數據流上的提取失敗重定向到故障存儲的功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據流現在可以維護一個「failure store」，用於接收和保存由於可預防的配置錯誤而無法採集的文檔。數據流的故障存儲的運行方式類似於一組獨立的後備索引，它們擁有各自的映射和訪問模式，這使得 Elasticsearch 能夠接收原本會因未處理的採集管道異常或映射衝突而被拒絕的文檔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用戶可以在組件或索引模板內的新&lt;code&gt;data_stream_options&lt;/code&gt;字段中指定，在新數據流上啓用將攝取失敗重定向到失敗存儲的功能：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;PUT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_index_template/my-template&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"index_patterns":&lt;/span&gt;&lt;/span&gt; [&lt;span&gt;&lt;span style="color:#59cfaa"&gt;"logs-test-*"&lt;/span&gt;&lt;/span&gt;], &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"data_stream":&lt;/span&gt;&lt;/span&gt; {}, &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"template":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"data_stream_options":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"failure_store":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"enabled":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;strong&gt;&lt;span style="color:#f58eb7"&gt;true&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; } } } } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用新的數據流&lt;code&gt;_options&lt;/code&gt;端點配置現有數據流&amp;nbsp;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;PUT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_data_stream/logs-test-apache/_options&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"failure_store":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"enabled":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;"true"&lt;/span&gt;&lt;/span&gt; } } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;啓用重定向後，如果集羣支持，任何與攝取相關的故障都會被捕獲到故障存儲中，包括故障發生的時間戳、遇到的錯誤詳情以及無法攝取的文檔。由於故障存儲是一種 Elasticsearch 索引，可以在數據流中搜索它收集到的故障。這些故障默認不顯示，因為它們存儲在與常規數據流數據不同的索引中。為了檢索故障，使用&lt;code&gt;_search&lt;/code&gt;API 以及一種新的索引模式語法——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;::&lt;/code&gt;&lt;span style="color:#343741"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;selector&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-test-apache::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此索引語法指示搜索操作以故障存儲中的索引為目標，而不是其後備索引。它可以以多種方式與其他索引模式混合使用，以將其故障存儲索引包含在搜索操作中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-*,logs-*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_query&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"query":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;"FROM my_data_stream*::failures"&lt;/span&gt;&lt;/span&gt; } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Mark Token Pruning for Sparse Vector as GA&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;sparse_vector 查詢的 token pruning&amp;nbsp;功能自 8.13 版本起作為技術預覽版上線。自 8.19.0 和 9.1.0 版本起，該功能已正式發佈。&lt;/p&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;升級到 lucene 10.2.2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 HNSW 圖形構建期間減少 NeighborArray 堆內存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;修復 IndexSortSortedNumericDocValuesRangeQuery 的整數排序&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果 DoubleValuesSource 需要分數，則 ValueSource.fromDoubleValuesSource(dvs).getSortField() 在使用時會拋出錯誤&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在技術預覽版中發佈 FORK&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;FROM&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;test&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;FORK&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;WHERE&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content:"fox"&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;WHERE&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content:"dog"&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;SORT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_fork&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;FORK 命令添加一個名為&lt;code&gt;_fork&lt;/code&gt;的 discriminator column：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;id&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_fork&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|-----|-----------|-------|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#fc9188"&gt;3&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;brown&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fox&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fork1&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#fc9188"&gt;4&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;white&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;dog&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fork2&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ES|QL 跨集羣查詢現已普遍可用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;ES|QL 跨集羣查詢功能自 8.13 版本起處於技術預覽階段。自 8.19.0 和 9.1.0 版本起，該功能已正式發佈。此功能允許用戶跨多個集羣運行 ES|QL 查詢。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;更多詳情可查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fdocs%2Frelease-notes%2Felasticsearch%23elasticsearch-9.1.0-release-notes" target="_blank"&gt;https://www.elastic.co/docs/release-notes/elasticsearch#elasticsearch-9.1.0-release-notes&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363097/elasticsearch-9-1-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363097/elasticsearch-9-1-0-released</guid>
      <pubDate>Thu, 17 Jul 2025 02:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 上線全新「學習模式」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ChatGPT 正式上線了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fchatgpt-study-mode%2F"&gt;「學習模式」&lt;/a&gt;，通過交互式提問而非直接給答案的方式，引導用戶深入學習和解決問題。&lt;/p&gt; 
&lt;p&gt;據介紹，學習模式（study mode）是一種新的學習體驗，旨在通過分步指導幫助用戶解決問題，而不是直接提供答案。它最大的亮點在於引入了蘇格拉底式提問，通過一連串循序漸進的問題，引導你沿着邏輯脈絡一點點構建知識體系。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0734bb018ad7b0af7ef233b004905294ef5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 表示這項功能主要面向大學生羣體，尤其適用於作業輔導、考試準備和學習新知識。使用方式非常簡單，在 ChatGPT 的工具中選擇「研究與學習」，然後直接輸入想問的問題即可。&lt;/p&gt; 
&lt;p&gt;目前，學習模式由系統提示詞驅動，並未使用專門訓練的 AI 模型，這種機制的優勢在於迭代快、調整靈活。OpenAI 表示，未來將逐步把這一交互模式融合進核心模型中，讓教學邏輯成為底層能力的一部分。&lt;/p&gt; 
&lt;p&gt;體驗方面，免費版、Plus、Pro、Team 版用戶均可使用這項功能，Edu 用戶將在接下來的幾周內上線。&lt;/p&gt; 
&lt;p&gt;OpenAI 表示，這是改善 ChatGPT 學習體驗的第一步，未來計劃將這種行為直接訓練到核心模型中，並探索更清晰的可視化、目標設定和更深度的個性化等功能。同時，OpenAI 正通過 NextGenAI 計劃及與斯坦福大學 SCALE Initiative 的合作，進一步研究 AI 在教育中的應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363093/chatgpt-study-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363093/chatgpt-study-mode</guid>
      <pubDate>Thu, 17 Jul 2025 02:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深圳先進院提出新型圖像復原大模型 HYPIR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;中國科學院深圳先進技術研究院數字所董超研究員團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1cqDxurR1QxB4HXNoKmLkg" target="_blank"&gt;發佈&lt;/a&gt;了一項名為 HYPIR 的圖像復原大模型，不僅比現有的圖像復原技術快數十倍，更在高清分辨率、文字保真、理解能力、用戶控制靈活性等方面展現出了優異性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;董超團隊曾於去年提出了智能畫質增強大模型 SUPIR，將低質量的圖像恢復到接近原始狀態的高清圖像，有效修復多種退化類型的圖像。而此次圖像大模型 HYPIR 作為升級版，捨棄了迭代式的擴散模型訓練，改用單步的對抗生成模型訓練方式，將原有的算法速度提升了數倍，同時採用更新的文生圖基模型進一步提升算法效果，實現了 8K 級別的細節生成，在生成圖像的穩定性和可控性方面遠超 SUPIR 大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="353" src="https://oscimg.oschina.net/oscnet/up-f2529fde69524742505eeda933f93526e22.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「以往圖像復原方法中往往包括擴散模型蒸餾、ControlNet 適配器或者多步推理過程。而 HYPIR 則不需要依賴這些步驟，使用方法更加簡單。在訓練和推理速度上較傳統方法提升了一個數量級以上，且性能更優。」董超介紹，HYPIR 主要有兩個創新點，一是使用預訓練擴散模型初始化復原網絡；二是從理論角度出發解釋這一簡單方法背後蘊含的深刻原理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;實驗數據顯示，在單張顯卡（圖像處理器）上，HYPIR 僅需 1.7 秒即可完成一張 1024x1024 分辨率圖像的復原。相比現有的圖像復原方法，研究人員提出的 HYPIR 在復原圖像的質量上性能更優，且能夠適用於各種尺寸的預訓練擴散模型，為不同應用場景提供了靈活性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-5ce496faabfb63ab3ab3085ef4ffef77130.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在應用層面，研究人員介紹，HYPIR 在圖像高清分辨率、文字保真、理解能力、用戶控制靈活性等方面均展現出了優異的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如，在老照片修復方面，研究人員運用 HYPIR 修復了國內外經典電影、電視劇老照片，讓模糊的影像重現清晰的細節，為文化記憶傳承提供了技術支持。在高分辨率圖像修復領域，HYPIR 同樣表現出色，因其兼具速度與效果，HYPIR 成功攻克了傳統方法在生成 8k 分辨率圖像時往往面臨速度慢或效果不佳的難題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="379" src="https://oscimg.oschina.net/oscnet/up-67b91f31bbedb73b1544419c5b2214c6180.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在文字保真方面，傳統基於擴散模型的方法常導致復原出的文字模糊或扭曲，缺乏精確性，而 HYPIR 則能夠使復原出的文字保持高保真度和清晰度，無論是簡單的標識還是複雜的文檔，HYPIR 都能精準地還原其原始形態，使圖像中的文字清晰可讀。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，HYPIR 還具備了突出的自然語言理解能力，能夠精準捕捉和理解用戶的輸入指令，在圖像復原過程中準確地反映用戶的意圖。此外，用戶可以根據需求靈活調節生成與復原的平衡，或精細控制圖像細節程度，從而獲得符合自身偏好的結果。這種用戶友好的設計使得 HYPIR 不僅適用於專業領域，也能滿足普通用戶的需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="315" src="https://oscimg.oschina.net/oscnet/up-8a5dec52e332077222c82eb21fe0166e4c8.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363092</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363092</guid>
      <pubDate>Thu, 17 Jul 2025 02:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維開源多模態統一預訓練模型 Skywork UniPic</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維宣佈正式推出並開源採用自迴歸路線的「多模態統一預訓練模型&amp;nbsp;&lt;strong&gt;Skywork UniPic&lt;/strong&gt;」，在單一模型中深度融合圖像理解、文本到圖像生成、圖像編輯三大核心能力。該模型基於大規模高質量數據進行端到端預訓練，具備良好的通用性與可遷移性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="239" src="https://oscimg.oschina.net/oscnet/up-9bb339f656b62f41563018515770ad49264.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork-UniPic 模型核心能力包含：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖文理解：&lt;/strong&gt;基於 token 預測完成文本的自迴歸建模&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像生成&lt;/strong&gt;：採用掩碼自迴歸方式，逐步生成圖像 patch&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像編輯：&lt;/strong&gt;引入參考圖與編輯指令作為條件，生成編輯後的圖像&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;此外，Skywork-UniPic 完成端到端優化流程，能夠實現生成、理解、編輯三大能力的協同訓練和相互促進，突破傳統方法中能力權衡的技術瓶頸。這一架構設計不僅保持了自迴歸模型的簡潔高效，更通過共享編碼器實現了跨任務的深度協同，為多模態統一模型的實用化部署奠定了堅實基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;用戶只需要輸入提示詞，Skywork-UniPic 既可以像 VLM 一樣理解圖像、像 T2I 模型一樣生成圖片，還可以像美圖工具一樣，一鍵實現風格轉繪/吉卜力化的編輯功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="299" src="https://oscimg.oschina.net/oscnet/up-12b968fc4978131cb565b8847b729558f47.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork UniPic 技術亮點：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;指令遵循能力媲美大型模型：&lt;/strong&gt;&lt;/strong&gt;在 GenEval 指令遵循評估中取得 0.86 的優異成績，超越了絕大多數同類統一模型，在無 CoT 的情況下取得了 SOTA 分數，逼近較大模型 BAGEL（7B+7B*）帶 CoT 的 0.88 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;複雜指令生圖能力領先：&lt;/strong&gt;在 DPG-Bench 複雜指令生圖基準上達到 85.5 分的行業 SOTA 水平；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像編輯能力統一模型第一梯隊：&lt;/strong&gt;GEditBench-EN 獲得 5.83 分，ImgEdit-Bench 達到 3.49 分，展現出精準的編輯執行能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;參數效率優勢顯著：&lt;/strong&gt;相比同類大參數統一模型（如 BAGEL 的 14B 總參數、UniWorld-V1 的 19B 總參數），Skywork UniPic 以 1.5B 的輕量級規模實現了接近甚至超越大參數模型的性能表現；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;部署友好，真正可落地：&lt;/strong&gt;模型在 RTX 4090 消費級顯卡上均可流暢運行，為廣大開發者和研究者提供了真正可落地的統一模型解決方案，大幅降低了技術應用門檻。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="220" src="https://oscimg.oschina.net/oscnet/up-200975b864b698a0f7821912288be54d815.png" width="500" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPX-pKw0N341590wm7GpdYw" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363085</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363085</guid>
      <pubDate>Thu, 17 Jul 2025 01:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
