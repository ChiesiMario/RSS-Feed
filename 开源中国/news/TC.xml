<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 22 Jul 2024 15:16:00 GMT</lastBuildDate>
        <ttl>180</ttl>
        <item>
            <title>開源日報 | 谷歌淘汰 goo.gl 短鏈服務；Llama3 開源模型被玩出花了；關於開源芯片的觀點文章；如何寫出萬人唾罵的軟件；OpenAI 正與博通談判開發 AI 芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.22&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要聞&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available&quot;&gt;谷歌將於 2025 年徹底淘汰 goo.gl 短鏈服務&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Google URL Shortener 是谷歌在 2009 年推出的一項長網址縮短服務，將長鏈接以 https://goog.gl/* 的形式輸出為更短的鏈接。2018 年，谷歌宣佈淘汰和過渡 Google URL Shortener 服務，轉而引導用戶使用 Firebase Dynamic Links (FDL)；此舉意味着其不再接受新的網址縮短服務，但會繼續為現有網址提供服務。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f582b660e075dbd05b28f5b23f7a2a5dcf2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;時至今日，谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將於 2025 年徹底關閉 Google URL Shortener 服務。&lt;/span&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「任何使用 Google URL Shortener 構建的 https://goo.gl/* 形式鏈接的開發人員都將受到影響，並且這些 URL 在 2025 年 8 月 25 日之後將不再返回響應。」&lt;/span&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F296813&quot; target=&quot;_blank&quot;&gt;OpenAI 正與博通談判，或啓動 7 萬億美元 AI 芯片計劃&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;據 The Information 報道， OpenAI 已經與博通進行了會談，討論開發新人工智能芯片的計劃。&lt;/p&gt; 
&lt;p&gt;據悉，OpenAI 目前正在探索製造自己的人工智能芯片的可能性。此舉不僅能有效整合軟件和硬件，還有助於緩解當前人工智能芯片短缺的問題。此外，據説 OpenAI 正在積極招募前谷歌員工，希望利用他們在開發 Tensor 處理器方面的經驗和專業知識來製造自己的 AI 芯片。報道強調，OpenAI 開發出能與英偉達相媲美的 AI 服務器芯片的可能性很小，需要多年的研發才能取得顯著成果。&lt;/p&gt; 
&lt;p&gt;此前，業內人士指出，OpenAI CEO Sam Altman 制定了雄心勃勃的人工智能芯片發展計劃，旨在籌集 7 萬億美元資金，改造全球半導體產業生態系統，推動通用人工智能產業的發展。&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F296808&quot; target=&quot;_blank&quot;&gt;蘋果開源小模型 DCLM-Baseline-7&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;據 Venturebeat 報道，蘋果公司的研究團隊在 Hugging Face 上發佈了一系列開放的 DCLM 模型。&lt;/p&gt; 
&lt;p&gt;該系列包括兩個主要模型：一個有 70 億個參數，另一個有 14 億個參數。這兩個模型在基準測試中的表現都相當不錯，尤其是較大的那個模型--其性能超過了 Mistral-7B，並正在接近其他領先的開放模型，包括 Llama 3 和 Gemma。&lt;/p&gt; 
&lt;p&gt;值得注意的是，隨着模型權重、訓練代碼和預訓練數據集的發佈，該項目真正實現了開源。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fapple%2FDCLM-7B&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/apple/DCLM-7B&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fadb_w9yycyfZRR2iW86KNg&quot; target=&quot;_blank&quot;&gt;CrowdStrike 造成 850 萬台 Windows 藍屏&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;7 月 19 日，美國安全軟件 CrowdStrike 更新出錯，導致 Windows 電腦大規模藍屏，引發全球多個地區的公共服務陷入癱瘓。據悉，多國的航空、鐵路、銀行、企業、媒體、酒店等多領域因此次 Windows 系統崩潰宕機，連新能源產業鏈生產也收到了影響。&lt;/p&gt; 
&lt;p&gt;微軟官方發佈博文稱，CrowdStrike 的更新影響了 850 萬台 Windows 設備，約佔 Windows 設備總數的 1%。雖然百分比很小，但對經濟和社會造成的廣泛影響反映了無數運營許多關鍵服務的企業使用 CrowdStrike 的事實。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bc394b9cb0d0d35fc70ee8d22d8fff39ab5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FOoyK2goO3&quot; target=&quot;_blank&quot;&gt;Llama3 開源模型被玩出花了&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     Llama3 開源模型被玩出花了，最近好有幾個基於 Meta Llama3 的優化項目，都説性能比肩 GPT-4o 級別。
     &lt;br&gt; 一個是 Groq（就是做專有 LPU 芯片的那家）的 Llama-3-Groq-Tool-Use Model，説是這個基於 Llama3 的完全微調，在 BFCL（伯克利函數調用）榜上排名第一，擊敗所有其他型號，包括 Claude Sonnet 3.5、GPT-4 Turbo、GPT-4o 和 Gemini 1.5 Pro 等專有型號。它的訓練特色是，不使用任何用戶數據，只使用合成數據。
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;高飛&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1686707751%2FOoD1MqPbd&quot; target=&quot;_blank&quot;&gt;一篇關於開源芯片的觀點文章&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;闡述開源芯片技術體系的三個層次：&lt;/p&gt; 
    &lt;p&gt;L1—開放指令集：任何人都可以免費獲取指令集手冊，無需授權即可設計與實現處理器芯片。RISC-V 屬於這個層次。&lt;/p&gt; 
    &lt;p&gt;L2—開源設計實現：處理器芯片的微架構設計文檔和源代碼實現均開源，可自由獲取。香山屬於這個層次。&lt;/p&gt; 
    &lt;p&gt;L3—開源工具：處理器芯片的設計與實現過程中需要使用工具開源。開發香山的敏捷開發平台（Minjie）屬於這個層次。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;包雲崗&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2056277053%2FOoCaYEdzk%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;梳理一下英特爾事件的發展過程&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;intel 的 13/14 代崩潰問題已經醞釀了好久了，可能有新觀眾不知道到底這幾個月發生了什麼，這裏列出一個粗略的時間線。&lt;/p&gt; 
   &lt;p&gt;2023 年中起便有零零星星在論壇有用戶反饋 intel 的高端 CPU 出現必須要降頻才能保證遊戲不出現崩潰報錯的現象，有一些用戶通過 RMA 向 intel 調換了新的 CPU 後回覆正常。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62c0bba966608f88d610ede05b0c973b579.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chiphell.com%2Fthread-2621606-1-1.html&quot; target=&quot;_blank&quot;&gt;https://www.chiphell.com/thread-2621606-1-1.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;凌晨剛醒&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1481944214%2FOoGsxuqz4&quot; target=&quot;_blank&quot;&gt;中國要為奠定理論系統做準備了&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;今天人類信息技術的發展，已經進入了一個全新的時代，信息的採集，信息的存儲，信息的傳輸，信息的加工，信息的利用，都和香農的時代發生了巨大的變化，今天需要逐漸形成新的信息理論，這給王成錄這樣的人留下了很多機會。他們在一線已經做出了世界一流的產品，對於操作系統的理解，早就不是一個單機的管理與驅動，而是要把萬物都連接起來，用一個系統整合眾多的能力，把信息的一切都包容其中。&lt;/p&gt; 
  &lt;p&gt;鴻蒙系統不僅是中國有了一個自己的操作系統，在安全性有了巨大提升，相對於其他的系統，鴻蒙系統遠遠超出了傳統系統的思維，把 PC、平板、手機、手錶和眾多的智能產品整合起來，這需要全新的理論來做支撐，這個事情就應該有王成錄這樣的人來做。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;飛象網項立剛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrL_C32cKijrAyx11UfSNBg&quot; target=&quot;_blank&quot;&gt;如何寫出萬人唾罵的軟件 - 史上最大 Windows 藍屏事故分析&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;在這次事故中，850 多萬台 Windows 電腦的用戶沒有選擇 - 在微軟的許可下，CrowdStrike 強行自動升級了他們的系統配置文件，結果悲劇了。&lt;/p&gt; 
  &lt;p&gt;儘管升級到最新的防病毒軟件可以增強系統安全性，但這也可能影響系統的穩定性，所以這是一個需要權衡輕重的選擇。對於不同的用戶，安全性和穩定性的相對重要程度是不一樣的。比如，愛冒險喜歡嚐鮮不怕 Z turn 的同學可以選擇第一時間更新，911 電話中心可能應該等新版本被一定數量用戶驗證後再更新。 微軟和 CrowdStrike 憑什麼替所有人做出一刀切的選擇？&lt;/p&gt; 
  &lt;p&gt;是時候把選擇權交給用戶了。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;老萬故事會&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2Fv002AOUyL303BR7jE3f5Fy1ZLH9l8F9exEuvXePzty1jy4I__&quot; target=&quot;_blank&quot;&gt;微軟藍屏事故背後：一個小文件是如何讓全球計算機癱瘓的？&lt;/a&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;令人難以置信的是，一個很小的文件 (專家稱只夠容納一個網頁圖像) 居然導致了世界上最大的 IT 中斷事故。這個名為「C-00000291*.sys」的文件隱藏在 CrowdStrike 的 Falcon sensor 安全產品更新中。該問題文件在微軟公司的 Windows 操作系統中引發了一個錯誤，導致計算機無法正常工作，並觸發了可怕的「藍屏死機」。&lt;/p&gt; 
   &lt;p&gt;這一事件以前所未有的規模暴露了全球 IT 系統的脆弱性，並凸顯出如此多的組織和個人依賴於少數幾家科技公司存在的危險性。如果其中一家公司出現故障或遭到黑客攻擊，其後果可能波及全球經濟的大片領域。微軟憑藉其 Windows 操作系統主導了個人電腦業務，而 CrowdStrike 已成為數千家公司和組織的首選供應商，後者希望保護其最重要系統免受網絡攻擊。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- &lt;strong&gt;鳳凰網科技&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn807805201&quot; target=&quot;_blank&quot;&gt;阿里巴巴發佈 2024 年 ESG 報告：AI 前沿科技應用於醫療、助老、助殘領域&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在 ESG 戰略方向的指引下，阿里巴巴進一步深化 ESG 治理，成效顯著。報告指出，ESG 的核心是圍繞如何成為一家更好的公司。過去一年，阿里巴巴集團自身運營淨碳排放和價值鏈碳強度繼續實現「雙降」，平台生態減排實現顯著提升；將科技創新力量以及平台能力服務於無障礙、醫療、鄉村、適老化等領域，並取得了不錯的進展，醫療 AI 胰腺癌早篩項目落地、高德輪椅導航持續擴城、鄉村特派員深入更多縣域助力鄉村建設；並深化了公司 ESG 治理架構。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;金融界&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5NDE0MjI4MA%3D%3D%26mid%3D2656320355%26idx%3D1%26sn%3D4cbf1a71dc38a150a56b3884624f326b%26scene%3D0&quot; target=&quot;_blank&quot;&gt;應對 VMWare 政策之變，還有比虛擬化替換更重要的事&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;隨着企業業務和應用系統的多元化發展，除了虛擬化技術之外，容器、公有云、私有云、超融合、裸金屬等多種技術架構應運而生，各業務場景對技術的需求強度各異。用戶更大的困惑在於，如何高效整合這些主流技術和服務，讓整個 IT 基礎架構變的更加合理（不花冤枉錢），進而優化現有虛擬化環境性能、讓資源利用率提升。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;優刻得雲計算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240722A025R600%3Fsuid%3D%26media_id%3D&quot; target=&quot;_blank&quot;&gt;硅谷新公司 SF Compute：AI 算力的&quot;Airbnb&quot;，奧特曼親弟領投，估值 5 億&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#303030&quot;&gt;半年多過去，這家做算力生意的初創公司「San Francisco Compute」從名不見經傳的「Underdog」來到台前。上週，Sam Altman 親弟弟 Jack Altman 主理的 Alt Capital 領投其 1200 萬美元種子輪融資，讓它的估值來到約 5 億人民幣（7000 萬美元）。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;硅星人 Pro&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2Fv006Q49ZiJlK66KhuL09EAiBvCLGCuNIL1EMnviymIutJlcB9vYZTv7Z2WC252ThgRQk&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;特朗普將啓動 AI「曼哈頓計劃」？&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;特朗普和盟友們最近正在起草一項關於 AI 的行政命令，該命令暫定為「AI 曼哈頓計劃」，用以開發軍事技術，同時審查和取消一些不必要和繁重的法規。&lt;/p&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;這表明特朗普第二屆政府可能會更重視【如何推行有利於硅谷投資者和公司的人工智能政策】。同時也更重視對於美國高精尖技術的保護和壟斷。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;探索映像&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8bQ6DDqpVIi&quot; target=&quot;_blank&quot;&gt;被 AlphaGo 擊敗的李世石，用 8 年重建崩塌的世界&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;現在離 ChatGPT 的發佈過去了不足兩年，我們已看到多個領域被 AI 影響，而生活更多方面似乎也被埋下了改變的伏筆，我們總忍不住想要去推測和暢想未來的 AI。&lt;/p&gt; 
 &lt;p&gt;在這個語境下，比其他行業和領域更早受到 AI 衝擊的圍棋界，能幫助我們看到一種已經發生的可能性。&lt;/p&gt; 
 &lt;p&gt;擊敗人類後，更強的 AI 在進一步去「人味」&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;愛範兒&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bjnews.com.cn%2Fdetail%2F1721630423129982.html&quot; target=&quot;_blank&quot;&gt;中國 AI 大模型測評報告：公眾及傳媒行業大模型使用與滿足研究&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#191919&quot;&gt;一年半時間，從 ChatGPT（一款生成式大語言模型）到 Sora（一款生成式視頻模型）生成式預訓練大模型（下稱：大模型），原本平靜的全球科技圈颳起颶風。作為新質生產力發展的重要引擎，AI 大模型的交互體驗和生成能力預示着生產力的前進方向，人工智能也正在成為經濟高質量發展的最強增量。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;新京報&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatic.nfapp.southcn.com%2Fcontent%2F202407%2F21%2Fc9096119.html&quot; target=&quot;_blank&quot;&gt;追問四部門利用政務數據牟利 2.48 億：公共數據能收費嗎？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#252525&quot;&gt;政府機關利用政務數據違規經營收費，罕見被通報，連日來引起諸多討論。政務數據究竟能否收費利用？其授權運營的合規邊界在哪？怎麼才能讓海量的政務數據「供得出」「流得動」「用得好」？&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;南方都市報&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flapce%2Flapce&quot; target=&quot;_blank&quot;&gt;lapce/lapce&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;352&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fb40172a9db77fc34f3ab25aa0626ade6bf.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flapce%2Flapce&quot; target=&quot;_blank&quot;&gt;https://github.com/lapce/lapce&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Lapce 是&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#24292f&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用 Rust 編寫的快速且功能強大的代碼編輯器&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#24292f&quot;&gt;，UI 則是採用&amp;nbsp;Floem。它使用&amp;nbsp;Xi-Editor&amp;nbsp;的&amp;nbsp;Rope Science&amp;nbsp;進行文本編輯，並使用&amp;nbsp;Wgpu&amp;nbsp;進行渲染。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/meituantech/blog/11585606&quot; target=&quot;_blank&quot;&gt;一文講清多線程和多線程同步&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;本篇文章將深入探討多線程編程的基本概念（原子操作、CAS、Lock-free、內存屏障、偽共享、亂序執行等）、常見模式和最佳實踐。通過具體的代碼示例，希望能夠幫助大家掌握多線程編程的核心技術，並在實際開發中應用這些知識，提升軟件的性能和穩定性。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;kfifo&quot; height=&quot;265&quot; src=&quot;https://oscimg.oschina.net/oscnet/db91961f99806e32b43699dabf6aa99f52953.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用戶觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FS7X3XMV5k8snjVm9aXQDjA&quot; target=&quot;_blank&quot;&gt;程序員應該掌握的三種編程語言&lt;span&gt;——&lt;/span&gt;有 Zig 無 Rust？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：我覺得重點該掌握的是 js/TS，python 和 c 語言。 js 語言什麼都能做，甚至前端開發是離不開的，儘管有 wasm 等。其次 python 是簡單的。c 語言是底層開發最佳選擇之一。 其它語言什麼的，都很難説是必要，當然，對於理解程序開發思維的程序員來説，學習一門新語言簡直就是小菜一碟，老手程序員應該做到語言無關性…&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：感覺 zig 最大問題是：它官網我看了半天，硬是沒看明白 zig 優勢究竟是什麼，和其他語言不同是什麼，解決了什麼傳統模式的痛點。還有就是它教程裏，似乎把預編譯的導入文件#include，變成了一個賦值語句？然後也沒説明為什麼要這樣設計，目的是什麼。看的雲裏霧裏。知其然卻不知起所以然。這很不利於宣傳。而 rust 至少這方面就做的很好，解決了什麼痛點，所有權為什麼要那樣設計，都寫的很明白。zig 我是真沒看懂它官網&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：上過‘’編程語言‘’這門課的人應該可以看出 Finch 的學院氣太重了，過度追求通用性，導致理解難度大幅上升。同為 MIT 出品的 Julia 都好得多。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：純純野榜了，不實用也不先進，程序員還是先把 c 和 linux api/abi 學好，一通百通，rust 和 zig 之類的各種東西還都沒個定數，swift 這種純業務的等真有需求再説吧。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：zig 是 C 的繼承者，而 Rust 是一個新品種，適用於某些領域，而不適合全盤替代 C&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：rust 對標的是 c++&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：醒醒，這裏是 China&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：Swift 還能出現？純純野榜！蘋果的御用語言，接替 objc 的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：swift 生態怎麼樣，可以寫嵌入式嗎？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：rust 寫着巨難受&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 11：寫 rust 感覺像是做數學證明，每一步都得寫明明白白，不然就過不了，俗稱和編譯器做鬥爭&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 12：倉頡吧還是，未來的中國是倉頡的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 13：變則通，可以主修一門語言，但不要輕視其他語言，多學幾門語言總沒錯&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 14：為啥一個即將退出的 s6 要和退出幾年的 P8 比，咋不和 P12 比？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 15：感覺説的很好，但是 zig 的薪資什麼的肯定不是國內可以想象的了&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FasHjbQEC2o2udSJ6ciFhNg&quot; target=&quot;_blank&quot;&gt;美國安全軟件更新導致「微軟藍屏」&lt;span&gt;——&lt;/span&gt;Linux 用戶和馬斯克都在看樂子&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：隨便一個 bug 都能控制部分全球地區的電腦，so？國產有點廣告腫麼了？能死？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：系統問題能被你引申到國產有廣告沒問題你也是可以的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：這種大規模更新都不提前做測試的嗎&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：這次能看出 Azure 在全球商業版圖有多恐怖，Azure 的雲服務深入各行各業。 一個安全軟件的更新合併入 azure 的 windows 庫，再由 azure 進行全球分發更新。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：想想蠻恐怖的，如果這是在中美髮生戰時衝突的話，大量用了美國操作系統的關鍵部門和行業，咋辦？看來關鍵行業部門的操作系統必須要國產化，這個國產操作系統小而專即可，不需要像微軟 windowd 系統那麼龐大複雜需要兼容那麼多&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：上個世紀大家就想到啦，美國軍方都不在關鍵上用 Windows&lt;img alt=&quot;[旺柴]&quot; src=&quot;https://res.wx.qq.com/mpres/zh_CN/htmledition/comm_htmledition/images/pic/common/pic_blank.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;，有軍用的 Army Secure OS&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：這次算是信譽掃地了，這也是依賴並無條件信任某個軟件提供商可能產生的結果之一。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：好歹是家計算機安全供應商，居然能這樣搞...大規模的更新推動不提前測試，現在的安全環境得爛成什麼樣子啊，沒有測試的更新補丁在完全沒人管控和監測的情況下大規模被打在了各個公司的電腦上&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：個人用戶沒事的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：這次恢復很費時間吧！？需要每個電腦都需要 winre 或 wenpe 恢復吧！？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 11：不至於，安全模式應該能搞定，只是對於不瞭解的人還是很困難的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 12：來，和我一起念：世界就是一個草台班子&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 13：所以驅動一旦搞不好就會直接寄掉&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 14：linux 內核：我們也要學習藍屏！微硬：看見沒，這才叫真藍屏！學着點！&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/303139&quot; target=&quot;_blank&quot;&gt;騰訊雲發佈國產服務器操作系統 TencentOS Server V3&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：又是一個 centos 發行版&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：他家不是有個一個了嗎又有整一個&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：怎麼和數據庫有關呢？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：看到 GPU 利用率我就懂了，平時放着不利用不是浪費麼&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：騰子啊，這個不賺錢，別了吧。我們不希望 sudo 要充值啊&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：sudo 充錢算什麼， ls, cp, mv, cat 統統收錢起來&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：CentOS 原地替換，重啓即生效？這個可以！&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：孤陋寡聞了吧，AlmaLinux 和 RockyLinux 老早就出了遷移工具。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：都是魔改的系統，能不能別叫國產系統？老老實實做一個 linux 分支系統不好嗎？&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最後，歡迎掃碼下載「開源中國 APP」，閲讀海量技術報告、程序員極客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303369</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303369</guid>
            <pubDate>Mon, 22 Jul 2024 11:04:06 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 開源學術會議徵文通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;&lt;strong&gt;背景信息&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;開源在物理世界萌芽、發展併成為數字經濟創新創業的主導模式，是新時代新質生產力的代表。&lt;/p&gt; 
&lt;p&gt;開源是一場偉大的社會創新活動，其對人類社會的影響遠超工業革命，催生偉大的理論，也需要偉大理論的指導！&lt;/p&gt; 
&lt;p&gt;開源社會存在合理性解釋、開源社會意識及其可能的物質力量、如何推動中國開源創新、數字公共產品國際合作、數字主權、數字世界規則及治理、開源社會組織運營模式、企業開源方法論、開源人才培養等都是亟待解決的重大現實問題。構建開源理論，需要突破物理世界理論框架，需要範式創新。&lt;/p&gt; 
&lt;p&gt;時代呼喚懂代碼的哲學社會科學工作者，通過開源理論社會工程，一起推動人類數字命運共同體的實現。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c58f77cd0905cee0ed7337d7917104b94e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;1&amp;nbsp;&lt;strong&gt;會議信息&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;會議名稱&lt;/strong&gt;：2024 開源學術會議&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;會議主題&lt;/strong&gt;：開源創新理論與實踐&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;會議時間&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;會議地點&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主辦單位&lt;/strong&gt;：上海開源信息技術協會&lt;/p&gt; 
&lt;p&gt;開源創新與數字治理研究院&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;承辦單位&lt;/strong&gt;：上海對外經貿大學（暫定）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;協辦單位：&lt;/strong&gt;&lt;br&gt; 《華東師範大學學報》(自然科學版)&lt;br&gt; CCF 開源發展委員會&lt;br&gt; 上海市電子學會開源專業委員會&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持單位：&lt;/strong&gt;華東師範大學、上海對外經貿大學、上海交通大學、復旦大學、東華大學、北京科技大學、中國科學院科技戰略諮詢研究院、對外經濟貿易大學全球開源協作研究中心、CSDN 中國開發者網絡等&lt;/p&gt; 
&lt;h3&gt;2&amp;nbsp;&lt;strong&gt;徵文範圍&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本次學術大會圍繞「開源」展開，面向以下主題徵集論文和演講稿，包括但不限於：&lt;/p&gt; 
&lt;p&gt;1）開源社會存在合理性解釋、開源社會意識及其可能的物質力量、開源供應鏈安全、開源創新國際合作等；&lt;/p&gt; 
&lt;p&gt;2）國家開源創新政策比較、開源社會組織、開源項目、開源社區及其指標體系；&lt;/p&gt; 
&lt;p&gt;3）企業開源競爭戰略、數字化轉型開源解決方案、開源辦公室、開源治理、開源文化等；&lt;/p&gt; 
&lt;p&gt;4）開放科學、開源教育、開源應用、開源案例研究等。&lt;/p&gt; 
&lt;h3&gt;3&amp;nbsp;&lt;strong&gt;徵文格式要求&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 字數限制&lt;/strong&gt;：論文全文字數範圍 8000~12000 字（包括參考文獻）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 文件格式&lt;/strong&gt;：提交文檔應為 Word 和 PDF 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 引用風格&lt;/strong&gt;：請遵循 APA、MLA 或芝加哥引用風格等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. 論文語言&lt;/strong&gt;：中英文論文均可，但必須包括英文摘要。&lt;/p&gt; 
&lt;h3&gt;4&amp;nbsp;&lt;strong&gt;投稿方式&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;請通過以下郵箱提交您的論文：&lt;/p&gt; 
&lt;p&gt;投稿郵箱：osac@shanghaiopen.org.cn&lt;br&gt; 投稿請註明：投稿人姓名+論文題目&lt;/p&gt; 
&lt;h3&gt;5&amp;nbsp;&lt;strong&gt;重要日期&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;投稿截止日期&lt;/strong&gt;：2024 年 9 月 15 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;會議錄稿通知日期&lt;/strong&gt;：2024 年 9 月 25 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;會議召開時間&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;h3&gt;6&amp;nbsp;&lt;strong&gt;審稿流程&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 初審階段&lt;/strong&gt;：組委會將對投稿進行初步篩選，以確定是否符合徵文主題和格式要求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 同行評審&lt;/strong&gt;：符合要求的論文將發送給至少兩位領域專家進行盲審。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 終審決定&lt;/strong&gt;：論文評定委員會將根據同行評審的意見做出最終錄用決定。&lt;/p&gt; 
&lt;h3&gt;7&amp;nbsp;&lt;strong&gt;參會及論文發表&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;所有被錄用的論文作者將被邀請在會議上進行演講。&lt;/li&gt; 
 &lt;li&gt;優秀論文將有機會獲得最佳論文獎，並被推薦到《華東師範大學學報》(自然科學版) 等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;8&amp;nbsp;&lt;strong&gt;聯繫諮詢&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;對於本次學術會議，如您有任何問題諮詢，可以聯繫本次大會組委會聯絡人：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聯繫人：王偉&lt;/li&gt; 
 &lt;li&gt;聯繫電話：13661537027&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;9&amp;nbsp;&lt;strong&gt;注意事項&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;請確保您的論文是原創的，並且沒有在其他期刊或會議上發表過。&lt;/li&gt; 
 &lt;li&gt;遵循徵文格式要求，以確保您的論文能順利進入審稿流程。&lt;/li&gt; 
 &lt;li&gt;保持關注會議官方網站或郵件通知，以獲取最新的會議和審稿信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;2024 開源學術會議大會組委會&lt;/p&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;上海開源信息技術協會&lt;/p&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;2024 年 7 月 22 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;上海開源信息技術協會&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上海開源信息技術協會成立於 2020 年 3 月 24 日，是市科協一星級協會、市民政 3A 級社團組織。協會由致力於開源信息技術創新的企業、高校、科研院所、社會組織及專業人員等自願組成。由致力於開源信息技術創新的企業、高校、科研院所、社會組織及專業人員等自願組成。協會自成立以來，始終堅持基於自組織創新創業共同體模式，以專業、公開、公正、透明的精神，服務國家及上海市數字經濟發展戰略。對接各種開源創新要素，積極促進上海開源人才高地、開源產業聚集地、開源服務業高度發達、開源創新營商環境最優城市建設。具體工作重心：一是開源理論構建，並積極推動社會實踐；二是中國開源創新社會工程，推動大中小學開源教育；三是數字」一帶一路「；四是上海開源產業發展。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303363</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303363</guid>
            <pubDate>Mon, 22 Jul 2024 10:15:35 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>一文講清多線程和多線程同步</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;多線程編程是現代軟件開發中的一項關鍵技術，在多線程編程中，開發者可以將複雜的任務分解為多個獨立的線程，使其並行執行，從而充分利用多核處理器的優勢。然而，多線程編程也帶來了挑戰，例如線程同步、死鎖和競態條件等問題。本篇文章將深入探討多線程編程的基本概念（原子操作、CAS、Lock-free、內存屏障、偽共享、亂序執行等）、常見模式和最佳實踐。通過具體的代碼示例，希望能夠幫助大家掌握多線程編程的核心技術，並在實際開發中應用這些知識，提升軟件的性能和穩定性。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7998cb8e9779e36bdccf1f53e96ccc3a092.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;1 多線程&lt;/h2&gt; 
&lt;h3&gt;1.1 線程的概念&lt;/h3&gt; 
&lt;p&gt;十多年前，主流觀點主張在可能的情況下優先選擇多進程而非多線程。如今，多線程編程已經成為編程領域的事實標準。多線程技術在很大程度上改善了程序的性能和響應能力，使其能夠更加高效地利用系統資源，這不僅歸功於多核處理器的普及和軟硬件技術的進步，還歸功於開發者對多線程編程的深入理解和技術創新。&lt;/p&gt; 
&lt;p&gt;那麼什麼是線程呢？線程是一個執行上下文，它包含諸多狀態數據：每個線程有自己的執行流、調用棧、錯誤碼、信號掩碼、私有數據。Linux 內核用任務（Task）表示一個執行流。&lt;/p&gt; 
&lt;h4&gt;1.1.1 執行流&lt;/h4&gt; 
&lt;p&gt;一個任務裏被依次執行的指令會形成一個指令序列（IP 寄存器值的歷史記錄），這個指令序列就是一個指令流，每個線程會有自己的執行流。考慮下面的代碼（本文代碼塊為 C++）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int calc(int a, int b, char op) {
  int c = 0;
  if (op == &#39;+&#39;)
    c = a + b;
  else if (op == &#39;-&#39;)
    c = a - b;
  else if (op == &#39;*&#39;)
    c = a * b;
  else if (op == &#39;/&#39;)
    c = a / b;
  else
    printf(&quot;invalid operation\n&quot;);
  return c;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;calc 函數被編譯成彙編指令，一行 C 代碼對應一個或多個彙編指令，在一個線程裏執行 calc，那麼這些機器指令會被依次執行。但是，被執行的指令序列跟代碼順序可能不完全一致，代碼中的分支、跳轉等語句，以及編譯器對指令重排、處理器亂序執行會影響指令的真正執行順序。&lt;/p&gt; 
&lt;h4&gt;1.1.2 邏輯線程 vs 硬件線程&lt;/h4&gt; 
&lt;p&gt;線程可以進一步區分為邏輯線程和硬件線程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;邏輯線程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;程序上的線程是一個邏輯上的概念，也叫任務、軟線程、邏輯線程。線程的執行邏輯由代碼描述，比如編寫一個函數實現對一個整型數組的元素求和：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int sum(int a[], int n) {
    int x = 0;
    for (int i = 0; i &amp;lt; n; ++i) 
        x += a[i];
    return x;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這個函數的邏輯很簡單，它沒有再調用其他函數（更復雜的功能邏輯可以在函數裏調用其他函數）。我們可以在一個線程裏調用這個函數對某數組求和；也可以把 sum 設置為某線程的入口函數，每個線程都會有一個入口函數，線程從入口函數開始執行。sum 函數描述了邏輯，即要做什麼以及怎麼做，偏設計；但它沒有描述物質，即沒有描述這個事情由誰做，事情最終需要派發到實體去完成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;硬件線程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;與邏輯線程對應的是硬件線程，這是邏輯線程被執行的物質基礎。&lt;/p&gt; 
&lt;p&gt;芯片設計領域，一個硬件線程通常指為執行指令序列而配套的硬件單元，一個 CPU 可能有多個核心，然後核心還可能支持超線程，1 個核心的 2 個超線程複用一些硬件。從軟件的視角來看，無須區分是真正的 Core 和超出來的 VCore，基本上可以認為是 2 個獨立的執行單元，每個執行單元是一個邏輯 CPU，從軟件的視角看 CPU 只需關注邏輯 CPU。一個軟件線程由哪個 CPU/核心去執行，以及何時執行，不歸應用程序員管，它由操作系統決定，操作系統中的調度系統負責此項工作。&lt;/p&gt; 
&lt;h3&gt;1.2 線程、核心、函數的關係&lt;/h3&gt; 
&lt;p&gt;線程入口函數是線程執行的起點，線程從入口函數開始、一個指令接着一個指令執行，中間它可能會調用其他函數，那麼它的控制流就轉到了被調用的函數繼續執行，被調用函數裏還可以繼續調用其他函數，這樣便形成一個函數調用鏈。&lt;/p&gt; 
&lt;p&gt;前面的數組求和例子，如果數組特別大，則哪怕是一個簡單的循環累加也可能耗費很長的時間，可以把這個整型數組分成多個小數組，或者表示成二維數組（數組的數組），每個線程負責一個小數組的求和，多個線程併發執行，最後再累加結果。&lt;/p&gt; 
&lt;p&gt;所以，為了提升處理速度，可以讓多個線程在不同數據區段上執行相同（或相似）的計算邏輯，同樣的處理邏輯可以有多個執行實例（線程），這對應對數據拆分線程。當然，也可以為兩個線程指定不同的入口函數，讓各線程執行不同的計算邏輯，這對應對邏輯拆分線程。&lt;/p&gt; 
&lt;p&gt;我們用一個例子來闡述線程、核心和函數之間的關係，假設有遛狗、掃地兩類工作要做：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;遛狗就是為狗繫上繩子然後牽着它在小區裏溜達一圈，這句話就描述了遛狗的邏輯，即對應到函數定義，它是一個對應到設計的靜態的概念。&lt;/li&gt; 
 &lt;li&gt;每項工作，最終需要人去做，人就對應到硬件：CPU/Core/VCore，是任務被完成的物質基礎。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;那什麼對應軟件線程？ 任務拆分。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;一個例子&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假設現在有 2 條狗需要遛、3 個房間需要打掃。可以把遛狗拆成 2 個任務，一個任務是遛小狗，另一個任務是遛大狗；打掃房間拆分為 3 個任務，3 個房間對應 3 個任務，執行這樣的拆分策略後，將會產生 2+3=5 個任務。但如果只有 2 個人，2 個人無法同時做 5 件事，讓某人在某時幹某事由調度系統負責。&lt;/p&gt; 
&lt;p&gt;如果張三在遛小狗，那就對應一個線程被執行，李四在掃房間 A，則表示另一個線程在執行中，可見線程是一個動態的概念。&lt;/p&gt; 
&lt;p&gt;軟件線程不會一直處於執行中，原因是多方面的。上述例子是因為人手不夠，所以遛大狗的任務還處於等待被執行的狀態，其他的原因包括中斷、搶佔、條件依賴等。比如李四掃地過程中接到一個電話，他需要去處理更緊急的事情（接電話），則掃地這個事情被掛起，李四打完電話後繼續掃地，則這個線程會被繼續執行。&lt;/p&gt; 
&lt;p&gt;如果只有 1 個人，則上述 5 個任務依然可以被依次或交錯完成，所以多線程是一個編程模型，多線程並不一定需要多 CPU 多 Core，單 CPU 單 Core 系統依然可以運行多線程程序（雖然最大化利用多 CPU 多 Core 的處理能力是多線程程序設計的一個重要目標）。1 個人無法同時做多件事，單 CPU/單 Core 也不可以，操作系統通過時間分片技術應對遠多於 CPU/Core 數的多任務執行的挑戰。也可以把有些任務只分配給某些人去完成，這對應到 CPU 親和性和綁核。&lt;/p&gt; 
&lt;h3&gt;1.3 程序、進程、線程、協程&lt;/h3&gt; 
&lt;p&gt;進程和線程是操作系統領域的兩個重要概念，兩者既有區別又有聯繫。&lt;/p&gt; 
&lt;h4&gt;1.3.1 可執行程序&lt;/h4&gt; 
&lt;p&gt;C/C++源文件經過編譯器（編譯+鏈接）處理後，會產生可執行程序文件，不同系統有不同格式，比如 Linux 系統的 ELF 格式、Windows 系統的 EXE 格式，可執行程序文件是一個靜態的概念。&lt;/p&gt; 
&lt;h4&gt;1.3.2 進程是什麼&lt;/h4&gt; 
&lt;p&gt;可執行程序在操作系統上的一次執行對應一個進程，進程是一個動態的概念：進程是執行中的程序。同一份可執行文件執行多次，會產生多個進程，這跟一個類可以創建多個實例一樣。進程是資源分配的基本單位。&lt;/p&gt; 
&lt;h4&gt;1.3.3 線程是什麼&lt;/h4&gt; 
&lt;p&gt;一個進程內的多個線程代表着多個執行流，這些線程以併發模式獨立執行。操作系統中，被調度執行的最小單位是線程而非進程。進程是通過共享存儲空間對用戶呈現的邏輯概念，同一進程內的多個線程共享地址空間和文件描述符，共享地址空間意味着進程的代碼（函數）區域、全局變量、堆、棧都被進程內的多線程共享。&lt;/p&gt; 
&lt;h4&gt;1.3.4 進程和線程的關係&lt;/h4&gt; 
&lt;p&gt;先看看 linus 的論述，在 1996 年的一封郵件裏，Linus 詳細闡述了他對進程和線程關係的深刻洞見，他在郵件裏寫道：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;把進程和線程區分為不同的實體是揹着歷史包袱的傳統做法，沒有必要做這樣的區分，甚至這樣的思考方式是一個主要錯誤。&lt;/li&gt; 
 &lt;li&gt;進程和線程都是一回事：一個執行上下文（context of execution），簡稱為 COE，其狀態包括： 
  &lt;ul&gt; 
   &lt;li&gt;CPU 狀態（寄存器等）&lt;/li&gt; 
   &lt;li&gt;MMU 狀態（頁映射）&lt;/li&gt; 
   &lt;li&gt;權限狀態（uid、gid 等）&lt;/li&gt; 
   &lt;li&gt;各種通信狀態（打開的文件、信號處理器等）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;傳統觀念認為：進程和線程的主要區別是線程有 CPU 狀態（可能還包括其他最小必要狀態），而其他上下文來自進程；然而，這種區分法並不正確，這是一種愚蠢的自我設限。&lt;/li&gt; 
 &lt;li&gt;Linux 內核認為根本沒有所謂的進程和線程的概念，只有 COE（Linux 稱之為任務），不同的 COE 可以相互共享一些狀態，通過此類共享向上構建起進程和線程的概念。&lt;/li&gt; 
 &lt;li&gt;從實現來看，Linux 下的線程目前是 LWP 實現，線程就是輕量級進程，所有的線程都當作進程來實現，因此線程和進程都是用 task_struct 來描述的。這一點通過/proc 文件系統也能看出端倪，線程和進程擁有比較平等的地位。對於多線程來説，原本的進程稱為主線程，它們在一起組成一個線程組。&lt;/li&gt; 
 &lt;li&gt;簡言之，內核不要基於進程/線程的概念做設計，而應該圍繞 COE 的思考方式去做設計，然後，通過暴露有限的接口給用戶去滿足 pthreads 庫的要求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1.3.5 協程&lt;/h4&gt; 
&lt;p&gt;用戶態的多執行流，上下文切換成本比線程更低，微信用協程改造後台系統後，獲得了更大吞吐能力和更高穩定性。如今，協程庫也進了 C++ 20 新標準。&lt;/p&gt; 
&lt;h3&gt;1.4 為什麼需要多線程&lt;/h3&gt; 
&lt;h4&gt;1.4.1 什麼是多線程&lt;/h4&gt; 
&lt;p&gt;一個進程內多個線程併發執行的情況就叫多線程，每個線程是一個獨立的執行流，多線程是一種編程模型，它與處理器無關、跟設計有關。&lt;/p&gt; 
&lt;p&gt;需要多線程的原因包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;並行計算&lt;/strong&gt;：充分利用多核，提升整體吞吐，加快執行速度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;後台任務處理&lt;/strong&gt;：將後台線程和主線程分離，在特定場景它是不可或缺的，如：響應式用戶界面、實時系統等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們用 2 個例子作説明。&lt;/p&gt; 
&lt;h4&gt;1.4.2 通過多線程併發提升處理能力&lt;/h4&gt; 
&lt;p&gt;假設你要編寫一個程序，用於統計一批文本文件的單詞出現次數，程序的輸入是文件名列表，輸出一個單詞到次數的映射。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 類型別名：單詞到次數的映射
using word2count = std::map&amp;lt;std::string, unsigned int&amp;gt;;

// 合併&quot;單詞到次數映射列表&quot;
word2count merge(const std::vector&amp;lt;word2count&amp;gt;&amp;amp; w2c_list) {/*todo*/}

// 統計一個文件裏單詞出現次數（單詞到次數的映射）
word2count word_count_a_file(const std::string&amp;amp; file) {/*todo*/}

// 統計一批文本文件的單詞出現次數
word2count word_count_files(const std::vector&amp;lt;std::string&amp;gt;&amp;amp; files) {
    std::vector&amp;lt;word2count&amp;gt; w2c_list;
    for (auto &amp;amp;file : files) {
        w2c_list.push_back(word_count_a_file(file));
    }
    return merge(w2c_list);
}

int main(int argc, char* argv[]) {
    std::vector&amp;lt;std::string&amp;gt; files;
    for (int i = 1; i &amp;lt; argc; ++i) {
        files.push_back(argv[i]);
    }
    auto w2c = word_count_files(files);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這是一個單線程程序，word_count_files 函數在主線程裏被 main 函數調用。如果文件不多、又或者文件不大，那麼運行這個程序，很快就會得到統計結果，否則，可能要等一段長的時間才能返回結果。&lt;/p&gt; 
&lt;p&gt;重新審視這個程序會發現：函數 word_count_a_file 接受一個文件名，吐出從該文件計算出的局部結果，它不依賴於其他外部數據和邏輯，可以併發執行，所以，可以為每個文件啓動一個單獨的線程去運行 word_count_a_file，等到所有線程都執行完，再合併得到最終結果。&lt;/p&gt; 
&lt;p&gt;實際上，為每個文件啓動一個線程未必合適，因為如果有數萬個小文件，那麼啓動數萬個線程，每個線程運行很短暫的時間，大量時間將耗費在線程創建和銷燬上，一個改進的設計：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;開啓一個線程池，線程數等於 Core 數或二倍 Core 數（策略）。&lt;/li&gt; 
 &lt;li&gt;每個工作線程嘗試去文件列表（文件列表需要用鎖保護起來）裏取一個文件。 
  &lt;ul&gt; 
   &lt;li&gt;成功，統計這個文件的單詞出現次數。&lt;/li&gt; 
   &lt;li&gt;失敗，該工作線程就退出。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;待所有工作線程退出後，在主線程裏合併結果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這樣的多線程程序能加快處理速度，前面數組求和可以採用相似的處理，如果程序運行在多 CPU 多 Core 的機器上，就能充分利用多 CPU 多 Core 硬件優勢，多線程加速執行是多線程的一個顯而易見的主要目的，此其一。&lt;/p&gt; 
&lt;h4&gt;1.4.3 通過多線程改變程序編寫方式&lt;/h4&gt; 
&lt;p&gt;其二，有些場景會有阻塞的調用，如果不用多線程，那麼代碼不好編寫。&lt;/p&gt; 
&lt;p&gt;比如某程序在執行密集計算的同時，需要監控標準輸入（鍵盤），如果鍵盤有輸入，那麼讀取輸入並解析執行，但如果獲取鍵盤輸入的調用是阻塞的，而此時鍵盤沒有輸入到來，那麼其他邏輯將得不到機會執行。&lt;/p&gt; 
&lt;p&gt;代碼看起來會像下面這樣子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 從鍵盤接收輸入，經解釋後，會構建一個 Command 對象返回
Command command = getCommandFromStdInput();
// 執行命令
command.run();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;針對這種情況，我們通常會開啓一個單獨的線程去接收輸入，而用另外的線程去處理其他計算邏輯，避免處理輸入阻塞其他邏輯處理，這也是多線程的典型應用，它改變了程序的編寫方式，此其二。&lt;/p&gt; 
&lt;h3&gt;1.5 線程相關概念&lt;/h3&gt; 
&lt;h4&gt;1.5.1 時間分片&lt;/h4&gt; 
&lt;p&gt;CPU 先執行線程 A 一段時間，然後再執行線程 B 一段時間，然後再執行線程 A 一段時間，CPU 時間被切分成短的時間片、分給不同線程執行的策略就是 CPU 時間分片。時間分片是對調度策略的一個極度簡化，實際上操作系統的調度策略非常精細，要比簡單的時間分片複雜的多。如果一秒鐘被分成大量的非常短的時間片，比如 100 個 10 毫秒的時間片，10 毫秒對人的感官而言太短了，以致於用戶覺察不到延遲，彷彿計算機被該用戶的任務所獨佔（實際上並不是），操作系統通過進程的抽象獲得了這種任務獨佔 CPU 的效果（另一個抽象是進程通過虛擬內存獨佔存儲）。&lt;/p&gt; 
&lt;h4&gt;1.5.2 上下文切換&lt;/h4&gt; 
&lt;p&gt;把當前正在 CPU 上運行的任務遷走，並挑選一個新任務到 CPU 上執行的過程叫調度，任務調度的過程會發生上下文切換（context swap），即保存當前 CPU 上正在運行的線程狀態，並恢復將要被執行的線程的狀態，這項工作由操作系統完成，需要佔用 CPU 時間（sys time）。&lt;/p&gt; 
&lt;h4&gt;1.5.3 線程安全函數與可重入&lt;/h4&gt; 
&lt;p&gt;一個進程可以有多個線程在同時運行，這些線程可能同時執行一個函數，如果多線程併發執行的結果和單線程依次執行的結果是一樣的，那麼就是線程安全的，反之就不是線程安全的。&lt;/p&gt; 
&lt;p&gt;不訪問共享數據，共享數據包括全局變量、static local 變量、類成員變量，只操作參數、無副作用的函數是線程安全函數，線程安全函數可多線程重入。每個線程有獨立的棧，而函數參數保存在寄存器或棧上，局部變量在棧上，所以只操作參數和局部變量的函數被多線程併發調用不存在數據競爭。&lt;/p&gt; 
&lt;p&gt;C 標準庫有很多編程接口都是非線程安全的，比如時間操作/轉換相關的接口：ctime()/gmtime()/localtime()，c 標準通過提供帶_r 後綴的線程安全版本，比如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;char* ctime_r(const time* clock, char* buf);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這些接口的線程安全版本，一般都需要傳遞一個額外的 char * buf 參數，這樣的話，函數會操作這塊 buf，而不是基於 static 共享數據，從而做到符合線程安全的要求。&lt;/p&gt; 
&lt;h4&gt;1.5.4 線程私有數據&lt;/h4&gt; 
&lt;p&gt;因為全局變量（包括模塊內的 static 變量）是進程內的所有線程共享的，但有時應用程序設計中需要提供線程私有的全局變量，這個變量僅在函數被執行的線程中有效，但卻可以跨多個函數被訪問。&lt;/p&gt; 
&lt;p&gt;比如在程序裏可能需要每個線程維護一個鏈表，而會使用相同的函數來操作這個鏈表，最簡單的方法就是使用同名而不同變量地址的線程相關數據結構。這樣的數據結構可以由 Posix 線程庫維護，成為線程私有數據 (Thread-specific Data，或稱為 TSD)。&lt;/p&gt; 
&lt;p&gt;Posix 有線程私有數據相關接口，而 C/C++等語言提供 thread_local 關鍵字，在語言層面直接提供支持。&lt;/p&gt; 
&lt;h4&gt;1.5.5 阻塞和非阻塞&lt;/h4&gt; 
&lt;p&gt;一個線程對應一個執行流，正常情況下，指令序列會被依次執行，計算邏輯會往前推進。但如果因為某種原因，一個線程的執行邏輯不能繼續往前走，那麼我們就説線程被阻塞住了。就像下班回家，但走到家門口發現沒帶鑰匙，只能在門口徘徊，任由時間流逝，而不能進入房間。&lt;/p&gt; 
&lt;p&gt;線程阻塞的原因有很多種，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;線程因為 acquire 某個鎖而被操作系統掛起，如果 acquire 睡眠鎖失敗，線程會讓出 CPU，操作系統會調度另一個可運行線程到該 CPU 上執行，被調度走的線程會被加入等待隊列，進入睡眠狀態。&lt;/li&gt; 
 &lt;li&gt;線程調用了某個阻塞系統調用而等待，比如從沒有數據到來的套接字上讀數據，從空的消息隊列裏讀消息。&lt;/li&gt; 
 &lt;li&gt;線程在循環裏緊湊的執行測試&amp;amp;設置指令並一直沒有成功，雖然線程還在 CPU 上執行，但它只是忙等（相當於白白浪費 CPU），後面的指令沒法執行，邏輯同樣無法推進。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果某個系統調用或者編程接口有可能導致線程阻塞，那麼便被稱之為阻塞系統調用；與之對應的是非阻塞調用，調用非阻塞的函數不會陷入阻塞，如果請求的資源不能得到滿足，它會立即返回並通過返回值或錯誤碼報告原因，調用的地方可以選擇重試或者返回。&lt;/p&gt; 
&lt;h2&gt;2 多線程同步&lt;/h2&gt; 
&lt;p&gt;前面講了多線程相關的基礎知識，現在進入第二個話題，多線程同步。&lt;/p&gt; 
&lt;h3&gt;2.1 什麼是多線程同步&lt;/h3&gt; 
&lt;p&gt;同一進程內的多個線程會共享數據，對共享數據的併發訪問會出現 Race Condition，這個詞的官方翻譯是競爭條件，但 condition 翻譯成條件令人困惑，特別是對初學者而言，它不夠清晰明瞭，翻譯軟件顯示 condition 有狀況、狀態的含義，可能翻譯成競爭狀況更直白。&lt;/p&gt; 
&lt;p&gt;多線程同步是指：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;協調多個線程對共享數據的訪問，避免出現數據不一致的情況。&lt;/li&gt; 
 &lt;li&gt;協調各個事件的發生順序，使多線程在某個點交匯並按預期步驟往前推進，比如某線程需要等另一個線程完成某項工作才能開展該線程的下一步工作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要掌握多線程同步，需先理解為什麼需要多線程同步、哪些情況需要同步。&lt;/p&gt; 
&lt;h3&gt;2.2 為什麼需要同步&lt;/h3&gt; 
&lt;p&gt;理解為什麼要同步（Why）是多線程編程的關鍵，它甚至比掌握多線程同步機制（How）本身更加重要。識別什麼地方需要同步是編寫多線程程序的難點，只有準確識別需要保護的數據、需要同步的點，再配合系統或語言提供的合適的同步機制，才能編寫安全高效的多線程程序。&lt;/p&gt; 
&lt;p&gt;下面通過幾個例子解釋為什麼需要同步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有 1 個長度為 256 的字符數組 msg 用於保存消息，函數 read_msg() 和 write_msg() 分別用於 msg 的讀和寫：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 1
char msg[256] = &quot;this is old msg&quot;;

char* read_msg() {
    return msg;
}

void write_msg(char new_msg[], size_t len) {
    memcpy(msg, new_msg, std::min(len, sizeof(msg)));
}

void thread1() {
    char new_msg[256] = &quot;this is new msg, it&#39;s too looooooong&quot;;
    write_msg(new_msg, sizeof(new_msg));
}

void thread2() {
    printf(&quot;msg=%s\n&quot;, read_msg());
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果線程 1 調用 write_msg()，線程 2 調用 read_msg()，併發操作，不加保護。因為 msg 的長度是 256 字節，完成長達 256 字節的寫入需要多個內存週期，在線程 1 寫入新消息期間，線程 2 可能讀到不一致的數據。即可能讀到 &quot;this is new msg&quot;，而後半段內容 &quot;it&#39;s very...&quot; 線程 1 還沒來得及寫入，它不是完整的新消息。&lt;/p&gt; 
&lt;p&gt;在這個例子中，不一致表現為數據不完整。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;比如對於二叉搜索樹（BST）的節點，一個結構體有 3 個成分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一個指向父節點的指針&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一個指向左子樹的指針&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一個指向右子樹的指針&lt;/p&gt; &lt;p&gt;// example 2 struct Node { struct Node *parent; struct Node *left_child, *right_child; };&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這 3 個成分是有關聯的，將節點加入 BST，要設置這 3 個指針域，從 BST 刪除該節點，要修改該節點的父、左孩子節點、右孩子節點的指針域。對多個指針域的修改，不能在一個指令週期完成，如果完成了一個成分的寫入，還沒來得修改其他成分，就有可能被其他線程讀到了，但此時節點的有些指針域還沒有設置好，通過指針域去取數可能會出錯。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考慮兩個線程對同一個整型變量做自增，變量的初始值是 0，我們預期 2 個線程完成自增後變量的值為 2。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 3
int x = 0; // 初始值為 0
void thread1() { ++x; }
void thread2() { ++x; }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;簡單的自增操作，包括三步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;加載&lt;/strong&gt;：從內存中讀取變量 x 的值存放到寄存器&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更新&lt;/strong&gt;：在寄存器裏完成自增&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;保存&lt;/strong&gt;：把位於寄存器中的 x 的新值寫入內存&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;兩個線程併發執行++x，讓我們看看真實情況是什麼樣的：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;如果 2 個線程，先後執行自增，在時間上完成錯開。無論是 1 先 2 後，或是 2 先 1 後，那麼 x 的最終值是 2，符合預期。但多線程併發並不能確保對一個變量的訪問在時間上完全錯開。&lt;/li&gt; 
 &lt;li&gt;如果時間上沒有完全錯開，假設線程 1 在 core1 上執行，線程 2 在 core2 上執行，那麼，一個可能的執行過程如下：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，線程 1 把 x 讀到 core1 的寄存器，線程 2 也把 x 的值加載到 core2 的寄存器，此時，存放在兩個 core 的寄存器中 x 的副本都是 0。&lt;/li&gt; 
 &lt;li&gt;然後，線程 1 完成自增，更新寄存器裏 x 的值的副本（0 變 1），線程 2 也完成自增，更新寄存器裏 x 的值的副本（0 變 1）。&lt;/li&gt; 
 &lt;li&gt;再然後，線程 1 將更新後的新值 1 寫入變量 x 的內存位置。&lt;/li&gt; 
 &lt;li&gt;最後，線程 2 將更新後的新值 1 寫入同一內存位置，變量 x 的最終值是 1，不符合預期。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;線程 1 和線程 2 在同一個 core 上交錯執行，也有可能出現同樣的問題，這個問題跟硬件結構無關。之所以會出現不符合預期的情況，主要是因為&quot;加載+更新+保存&quot;這 3 個步驟不能在一個內存週期內完成。多個線程對同一變量併發讀寫，不加同步的話會出現數據不一致。&lt;/p&gt; 
&lt;p&gt;在這個例子中，不一致表現為 x 的終值既可能為 1 也可能為 2。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 4&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用 C++類模板實現一個隊列：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 4
template &amp;lt;typename T&amp;gt;
class Queue {
    static const unsigned int CAPACITY = 100;
    T elements[CAPACITY];
    int num = 0, head = 0, tail = -1;
public:
    // 入隊
    bool push(const T&amp;amp; element) {
        if (num == CAPACITY) return false;
        tail = (++tail) % CAPACITY;
        elements[tail] = element;
        ++num;
        return true;
    }
    // 出隊
    void pop() {
        assert(!empty());
        head = (++head) % CAPACITY;
        --num;
    }
    // 判空
    bool empty() const { 
        return num == 0; 
    }
    // 訪隊首
    const T&amp;amp; front() const {
        assert(!empty());
        return elements[head];
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代碼解釋：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;T elements[]保存數據；2 個遊標，分別用於記錄隊首 head 和隊尾 tail 的位置（下標）。&lt;/li&gt; 
 &lt;li&gt;push() 接口，先移動 tail 遊標，再把元素添加到隊尾。&lt;/li&gt; 
 &lt;li&gt;pop() 接口，移動 head 遊標，彈出隊首元素（邏輯上彈出）。&lt;/li&gt; 
 &lt;li&gt;front() 接口，返回隊首元素的引用。&lt;/li&gt; 
 &lt;li&gt;front()、pop() 先做斷言，調用 pop()/front() 的客戶代碼需確保隊列非空。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;假設現在有一個 Queue&amp;lt;int&amp;gt;實例 q，因為直接調用 pop 可能 assert 失敗，我們封裝一個 try_pop()，代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Queue&amp;lt;int&amp;gt; q;
void try_pop() {
    if (!q.empty()) {
        q.pop();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果多個線程調用 try_pop()，會有問題，為什麼？&lt;/p&gt; 
&lt;p&gt;原因：判空+出隊這 2 個操作，不能在一個指令週期內完成。如果線程 1 在判斷隊列非空後，線程 2 穿插進來，判空也為偽，這樣就有可能 2 個線程競爭彈出唯一的元素。&lt;/p&gt; 
&lt;p&gt;多線程環境下，讀變量然後基於值做進一步操作，這樣的邏輯如果不加保護就會出錯，這是由數據使用方式引入的問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 5&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;再看一個簡單的，簡單的對 int32_t 多線程讀寫。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 5
int32_t data[8] = {1,2,3,4,5,6,7,8}; 

struct Foo {
    int32_t get() const { return x; }
    void set(int32_t x) { this-&amp;gt;x = x; }
    int32_t x;
} foo;

void thread_write1() {
    for (;;) { for (auto v : data) { foo.set(v); } }
}

void thread_write2() {
    for (;;) { for (auto v : data) { foo.set(v); } }
}

void thread_read() {
    for (;;) { printf(&quot;%d&quot;, foo.get()); }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2 個寫線程 1 個讀線程，寫線程在無限循環裏用 data 裏的元素值設置 foo 對象的 x 成分，讀線程簡單的打印 foo 對象的 x 值。程序一直跑下去，最後打印出來的數據，會出現除 data 初始化值外的數據嗎？&lt;/p&gt; 
&lt;p&gt;Foo::get 的實現有問題嗎？如果有問題？是什麼問題？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 6&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;看一個用數組實現 FIFO 隊列的程序，一個線程寫 put()，一個線程讀 get()。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 6
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;algorithm&amp;gt;

// 用數組實現的環型隊列
class FIFO {
    static const unsigned int CAPACITY = 1024;  // 容量：需要滿足是 2^N

    unsigned char buffer[CAPACITY];             // 保存數據的緩衝區
    unsigned int in = 0;                        // 寫入位置
    unsigned int out = 0;                       // 讀取位置

    unsigned int free_space() const { return CAPACITY - in + out; }
public:
    // 返回實際寫入的數據長度（&amp;lt;= len），返回小於 len 時對應空閒空間不足
    unsigned int put(unsigned char* src, unsigned int len) {
        // 計算實際可寫入數據長度（&amp;lt;=len）
        len = std::min(len, free_space());

        // 計算從 in 位置到 buffer 結尾有多少空閒空間
        unsigned int l = std::min(len, CAPACITY - (in &amp;amp; (CAPACITY - 1)));
        // 1. 把數據放入 buffer 的 in 開始的緩衝區，最多到 buffer 結尾
        memcpy(buffer + (in &amp;amp; (CAPACITY - 1)), src, l);   
        // 2. 把數據放入 buffer 開頭（如果上一步還沒有放完），len - l 為 0 代表上一步完成數據寫入
        memcpy(buffer, src + l, len - l);
        
        in += len; // 修改 in 位置，累加，到達 uint32_max 後溢出迴繞
        return len;
    }

    // 返回實際讀取的數據長度（&amp;lt;= len），返回小於 len 時對應 buffer 數據不夠
    unsigned int get(unsigned char *dst, unsigned int len) {
        // 計算實際可讀取的數據長度
        len = std::min(len, in - out);

        unsigned int l = std::min(len, CAPACITY - (out &amp;amp; (CAPACITY - 1)));
        // 1. 從 out 位置開始拷貝數據到 dst，最多拷貝到 buffer 結尾
        memcpy(dst, buffer + (out &amp;amp; (CAPACITY - 1)), l);
        // 2. 從 buffer 開頭繼續拷貝數據（如果上一步還沒拷貝完），len - l 為 0 代表上一步完成數據獲取
        memcpy(dst + l, buffer, len - l);

        out += len; // 修改 out，累加，到達 uint32_max 後溢出迴繞
        return len;
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/db91961f99806e32b43699dabf6aa99f52953.png&quot; alt=&quot;kfifo&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;環型隊列只是邏輯上的概念，因為採用了數組作為數據結構，所以實際物理存儲上並非環型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;put() 用於往隊列裏放數據，參數 src+len 描述了待放入的數據信息。&lt;/li&gt; 
 &lt;li&gt;get() 用於從隊列取數據，參數 dst+len 描述了要把數據讀到哪裏、以及讀多少字節。&lt;/li&gt; 
 &lt;li&gt;capacity 精心選擇為 2 的 n 次方，可以得到 3 個好處： 
  &lt;ul&gt; 
   &lt;li&gt;非常技巧性的利用了無符號整型溢出迴繞，便於處理對 in 和 out 移動&lt;/li&gt; 
   &lt;li&gt;便於計算長度，通過按位與操作&amp;amp;而不必除餘&lt;/li&gt; 
   &lt;li&gt;搜索 kfifo 獲得更詳細的解釋&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in 和 out 是 2 個遊標： 
  &lt;ul&gt; 
   &lt;li&gt;in 用來指向新寫入數據的存放位置，寫入的時候，只需要簡單增加 in。&lt;/li&gt; 
   &lt;li&gt;out 用來指示從 buffer 的什麼位置讀取數據的，讀取的時候，也只需簡單增加 out。&lt;/li&gt; 
   &lt;li&gt;in 和 out 在操作上之所以能單調增加，得益於上述 capacity 的巧妙選擇。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;為了簡化，隊列容量被限制為 1024 字節，不支持擴容，這不影響多線程的討論。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;寫的時候，先寫入數據再移動 in 遊標；讀的時候，先拷貝數據，再移動 out 遊標；in 遊標移動後，消費者才獲得 get 到新放入數據的機會。&lt;/p&gt; 
&lt;p&gt;直覺告訴我們 2 個線程不加同步的併發讀寫，會有問題，但真有問題嗎？如果有，到底有什麼問題？怎麼解決？&lt;/p&gt; 
&lt;h3&gt;2.3 保護什麼&lt;/h3&gt; 
&lt;p&gt;多線程程序裏，我們要保護的是數據而非代碼，雖然 Java 等語言裏有臨界代碼、sync 方法，但最終要保護的還是代碼訪問的數據。&lt;/p&gt; 
&lt;h3&gt;2.4 串行化&lt;/h3&gt; 
&lt;p&gt;如果有一個線程正在訪問某共享（臨界）資源，那麼在它結束訪問之前，其他線程不能執行訪問同一資源的代碼（訪問臨界資源的代碼叫臨界代碼），其他線程想要訪問同一資源，則它必須等待，直到那個線程訪問完成，它才能獲得訪問的機會，現實中有很多這樣的例子。比如高速公路上的汽車過檢查站，假設檢查站只有一個車道，則無論高速路上有多少車道，過檢查站的時候只能一輛車接着一輛車，從單一車道魚貫而入。&lt;/p&gt; 
&lt;p&gt;對多線程訪問共享資源施加此種約束就叫串行化。&lt;/p&gt; 
&lt;h3&gt;2.5 原子操作和原子變量&lt;/h3&gt; 
&lt;p&gt;針對前面的兩個線程對同一整型變量自增的問題，如果&quot;load、update、store&quot;這 3 個步驟是不可分割的整體，即自增操作++x 滿足原子性，上面的程序便不會有問題。&lt;/p&gt; 
&lt;p&gt;因為這樣的話，2 個線程併發執行++x，只會有 2 個結果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;線程 a ++x，然後線程 b ++x，結果是 2。&lt;/li&gt; 
 &lt;li&gt;線程 b ++x，然後線程 a ++x，結果是 2。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除此之外，不會出現第三種情況，線程 a、b 孰先孰後，取決於線程調度，但不影響最終結果。&lt;/p&gt; 
&lt;p&gt;Linux 操作系統和 C/C++編程語言都提供了整型原子變量，原子變量的自增、自減等操作都是原子的，操作是原子性的，意味着它是一個不可細分的操作整體，原子變量的用戶觀察它，只能看到未完成和已完成 2 種狀態，看不到半完成狀態。&lt;/p&gt; 
&lt;p&gt;如何保證原子性是實現層面的問題，應用程序員只需要從邏輯上理解原子性，並能恰當的使用它就行了。原子變量非常適用於計數、產生序列號這樣的應用場景。&lt;/p&gt; 
&lt;h3&gt;2.6 鎖&lt;/h3&gt; 
&lt;p&gt;前面舉了很多例子，闡述多線程不加同步併發訪問數據會引起什麼問題，下面講解用鎖如何做同步。&lt;/p&gt; 
&lt;h4&gt;2.6.1 互斥鎖&lt;/h4&gt; 
&lt;p&gt;針對線程 1 write_msg() + 線程 2 read_msg() 的問題，如果能讓線程 1 write_msg() 的過程中，線程 2 不能 read_msg()，那就不會有問題。這個要求，其實就是要讓多個線程互斥訪問共享資源。&lt;/p&gt; 
&lt;p&gt;互斥鎖就是能滿足上述要求的同步機制，互斥是排他的意思，它可以確保在同一時間，只能有一個線程對那個共享資源進行訪問。&lt;/p&gt; 
&lt;p&gt;互斥鎖有且只有 2 種狀態：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;已加鎖（locked）狀態&lt;/li&gt; 
 &lt;li&gt;未加鎖（unlocked）狀態&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;互斥鎖提供加鎖和解鎖兩個接口：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;加鎖（acquire）&lt;/strong&gt;：當互斥鎖處於未加鎖狀態時，則加鎖成功（把鎖設置為已加鎖狀態），並返回；當互斥鎖處於已加鎖狀態時，那麼試圖對它加鎖的線程會被阻塞，直到該互斥量被解鎖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;解鎖（release）&lt;/strong&gt;：通過把鎖設置為未加鎖狀態釋放鎖，其他因為申請加鎖而陷入等待的線程，將獲得執行機會。如果有多個等待線程，只有一個會獲得鎖而繼續執行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我們為某個共享資源配置一個互斥鎖，使用互斥鎖做線程同步，那麼所有線程對該資源的訪問，都需要遵從&quot;加鎖、訪問、解鎖&quot;的三步：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;DataType shared_resource;
Mutex shared_resource_mutex;

void shared_resource_visitor1() {
    // step1: 加鎖
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation1
    // step3: 解鎖
    shared_resource_mutex.unlock();
}

void shared_resource_visitor2() {
    // step1: 加鎖
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation2
    // step3: 解鎖
    shared_resource_mutex.unlock();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;shared_resource_visitor1() 和 shared_resource_visitor2() 代表對共享資源的不同操作，多個線程可能調用同一個操作函數，也可能調用不同的操作函數。&lt;/p&gt; 
&lt;p&gt;假設線程 1 執行 shared_resource_visitor1()，該函數在訪問數據之前，申請加鎖，如果互斥鎖已經被其他線程加鎖，則調用該函數的線程會阻塞在加鎖操作上，直到其他線程訪問完數據，釋放（解）鎖，阻塞在加鎖操作的線程 1 才會被喚醒，並嘗試加鎖：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果沒有其他線程申請該鎖，那麼線程 1 加鎖成功，獲得了對資源的訪問權，完成操作後，釋放鎖。&lt;/li&gt; 
 &lt;li&gt;如果其他線程也在申請該鎖，那麼： 
  &lt;ul&gt; 
   &lt;li&gt;如果其他線程搶到了鎖，那麼線程 1 繼續阻塞。&lt;/li&gt; 
   &lt;li&gt;如果線程 1 搶到了該鎖，那麼線程 1 將訪問資源，再釋放鎖，其他競爭該鎖的線程得以有機會繼續執行。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果不能承受加鎖失敗而陷入阻塞的代價，可以調用互斥量的 try_lock() 接口，它在加鎖失敗後會立即返回。&lt;/p&gt; 
&lt;p&gt;注意：在訪問資源前申請鎖訪問後釋放鎖，是一個編程契約，通過遵守契約而獲得數據一致性的保障，它並非一種硬性的限制，即如果別的線程遵從三步曲，而另一個線程不遵從這種約定，代碼能通過編譯且程序能運行，但結果可能是錯的。&lt;/p&gt; 
&lt;h4&gt;2.6.2 讀寫鎖&lt;/h4&gt; 
&lt;p&gt;讀寫鎖跟互斥鎖類似，也是申請鎖的時候，如果不能得到滿足則阻塞，但讀寫鎖跟互斥鎖也有不同，讀寫鎖有 3 個狀態：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;已加讀鎖狀態&lt;/li&gt; 
 &lt;li&gt;已加寫鎖狀態&lt;/li&gt; 
 &lt;li&gt;未加鎖狀態&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對應 3 個狀態，讀寫鎖有 3 個接口：加讀鎖，加寫鎖，解鎖：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;加讀鎖：如果讀寫鎖處於已加寫鎖狀態，則申請鎖的線程阻塞；否則把鎖設置為已加讀鎖狀態併成功返回。&lt;/li&gt; 
 &lt;li&gt;加寫鎖：如果讀寫鎖處於未加鎖狀態，則把鎖設置為已加寫鎖狀態併成功返回；否則阻塞。&lt;/li&gt; 
 &lt;li&gt;解鎖：把鎖設置為未加鎖狀態後返回。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;讀寫鎖提升了線程的並行度，可以提升吞吐。它可以讓多個讀線程同時讀共享資源，而寫線程訪問共享資源的時候，其他線程不能執行，所以，讀寫鎖適合對共享資源訪問&quot;讀大於寫&quot;的場合。讀寫鎖也叫&quot;共享互斥鎖&quot;，多個讀線程可以併發訪問同一資源，這對應共享的概念，而寫線程是互斥的，寫線程訪問資源的時候，其他線程無論讀寫，都不可以進入臨界代碼區。&lt;/p&gt; 
&lt;p&gt;考慮一個場景：如果有線程 1、2、3 共享資源 x，讀寫鎖 rwlock 保護資源，線程 1 讀訪問某資源，然後線程 2 以寫的形式訪問同一資源 x，因為 rwlock 已經被加了讀鎖，所以線程 2 被阻塞，然後過了一段時間，線程 3 也讀訪問資源 x，這時候線程 3 可以繼續執行，因為讀是共享的，然後線程 1 讀訪問完成，線程 3 繼續訪問，過了一段時間，在線程 3 訪問完成前，線程 1 又申請讀資源，那麼它還是會獲得訪問權，但是寫資源的線程 2 會一直被阻塞。&lt;/p&gt; 
&lt;p&gt;為了避免共享的讀線程餓死寫線程，通常讀寫鎖的實現，會給寫線程優先權，當然這處決於讀寫鎖的實現，作為讀寫鎖的使用方，理解它的語義和使用場景就夠了。&lt;/p&gt; 
&lt;h4&gt;2.6.3 自旋鎖&lt;/h4&gt; 
&lt;p&gt;自旋鎖（Spinlock）的接口跟互斥量差不多，但實現原理不同。線程在 acquire 自旋鎖失敗的時候，它不會主動讓出 CPU 從而進入睡眠狀態，而是會忙等，它會緊湊的執行測試和設置 (Test-And-Set) 指令，直到 TAS 成功，否則就一直佔着 CPU 做 TAS。&lt;/p&gt; 
&lt;p&gt;自旋鎖對使用場景有一些期待，它期待 acquire 自旋鎖成功後很快會 release 鎖，線程運行臨界區代碼的時間很短，訪問共享資源的邏輯簡單，這樣的話，別的 acquire 自旋鎖的線程只需要忙等很短的時間就能獲得自旋鎖，從而避免被調度走陷入睡眠，它假設自旋的成本比調度的低，它不願耗費時間在線程調度上（線程調度需要保存和恢復上下文需要耗費 CPU）。&lt;/p&gt; 
&lt;p&gt;內核態線程很容易滿足這些條件，因為運行在內核態的中斷處理函數裏可以通過關閉調度，從而避免 CPU 被搶佔，而且有些內核態線程調用的處理函數不能睡眠，只能使用自旋鎖。&lt;/p&gt; 
&lt;p&gt;而運行在用戶態的應用程序，則推薦使用互斥鎖等睡眠鎖。因為運行在用戶態應用程序，雖然很容易滿足臨界區代碼簡短，但持有鎖時間依然可能很長。在分時共享的多任務系統上、當用戶態線程的時間配額耗盡，或者在支持搶佔式的系統上、有更高優先級的任務就緒，那麼持有自旋鎖的線程就會被系統調度走，這樣持有鎖的過程就有可能很長，而忙等自旋鎖的其他線程就會白白消耗 CPU 資源，這樣的話，就跟自旋鎖的理念相背。&lt;/p&gt; 
&lt;p&gt;Linux 系統優化過後的 mutex 實現，在加鎖的時候會先做有限次數的自旋，只有有限次自旋失敗後，才會進入睡眠讓出 CPU，所以，實際使用中，它的性能也足夠好。此外，自旋鎖必須在多 CPU 或者多 Core 架構下，試想如果只有一個核，那麼它執行自旋邏輯的時候，別的線程沒有辦法運行，也就沒有機會釋放鎖。&lt;/p&gt; 
&lt;h4&gt;2.6.4 鎖的粒度&lt;/h4&gt; 
&lt;p&gt;合理設置鎖的粒度，粒度太大會降低性能，太小會增加代碼編寫複雜度。&lt;/p&gt; 
&lt;h4&gt;2.6.5 鎖的範圍&lt;/h4&gt; 
&lt;p&gt;鎖的範圍要儘量小，最小化持有鎖的時間。&lt;/p&gt; 
&lt;h4&gt;2.6.6 死鎖&lt;/h4&gt; 
&lt;p&gt;程序出現死鎖有兩種典型原因：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ABBA 鎖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假設程序中有 2 個資源 X 和 Y，分別被鎖 A 和 B 保護，線程 1 持有鎖 A 後，想要訪問資源 Y，而訪問資源 Y 之前需要申請鎖 B，而如果線程 2 正持有鎖 B，並想要訪問資源 X，為了訪問資源 X，所以線程 2 需要申請鎖 A。線程 1 和線程 2 分別持有鎖 A 和 B，並都希望申請對方持有的鎖，因為線程申請對方持有的鎖，得不到滿足，所以便會陷入等待，也就沒有機會釋放自己持有的鎖，對方執行流也就沒有辦法繼續前進，導致相持不下，無限互等，進而死鎖。&lt;/p&gt; 
&lt;p&gt;上述的情況似乎很明顯，但如果代碼量很大，有時候，這種死鎖的邏輯不會這麼淺顯，它被複雜的調用邏輯所掩蓋，但抽繭剝絲，最根本的邏輯就是上面描述的那樣。這種情況叫 ABBA 鎖，既某個線程持有 A 鎖申請 B 鎖，而另一個線程持有 B 鎖申請 A 鎖。這種情況可以通過 try lock 實現，嘗試獲取鎖，如果不成功，則釋放自己持有的鎖，而不一根筋下去。另一種解法就是鎖排序，對 A/B 兩把鎖的加鎖操作，都遵從同樣的順序（比如先 A 後 B），也能避免死鎖。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自死鎖&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;對於不支持重複加鎖的鎖，如果線程持有某個鎖，而後又再次申請鎖，因為該鎖已經被自己持有，再次申請鎖必然得不到滿足，從而導致死鎖。&lt;/p&gt; 
&lt;h3&gt;2.7 條件變量&lt;/h3&gt; 
&lt;p&gt;條件變量常用於生產者消費者模式，需配合互斥量使用。&lt;/p&gt; 
&lt;p&gt;假設你要編寫一個網絡處理程序，I/O 線程從套接字接收字節流，反序列化後產生一個個消息（自定義協議），然後投遞到一個消息隊列，一組工作線程負責從消息隊列取出並處理消息。這是典型的生產者-消費者模式，I/O 線程生產消息（往隊列 put），Work 線程消費消息（從隊列 get），I/O 線程和 Work 線程併發訪問消息隊列，顯然，消息隊列是競爭資源，需要同步。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/fb99fb443c76b32cb536646eda91dfa731825.png&quot; alt=&quot;proceduer-consumer&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以給隊列配置互斥鎖，put 和 get 操作前都先加鎖，操作完成再解鎖。代碼差不多是這樣的：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void io_thread() {
    while (1) {
        Msg* msg = read_msg_from_socket();
        msg_queue_mutex.lock();
        msg_queue.put(msg);
        msg_queue_mutex.unlock();
    }
}

void work_thread() {
    while (1) {
        msg_queue_mutex.lock();
        Msg* msg = msg_queue.get();
        msg_queue_mutex.unlock();
        if (msg != nullptr) {
            process(msg);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;work 線程組的每個線程都忙於檢查消息隊列是否有消息，如果有消息就取一個出來，然後處理消息，如果沒有消息就在循環裏不停檢查，這樣的話，即使負載很輕，但 work_thread 還是會消耗大量的 CPU 時間。&lt;/p&gt; 
&lt;p&gt;我們當然可以在兩次查詢之間加入短暫的 sleep，從而讓出 cpu，但是這個睡眠的時間設置為多少合適呢？設置長了的話，會出現消息到來得不到及時處理（延遲上升）；設置太短了，還是無辜消耗了 CPU 資源，這種不斷問詢的方式在編程上叫輪詢。&lt;/p&gt; 
&lt;p&gt;輪詢行為邏輯上，相當於你在等一個投遞到樓下小郵局的包裹，你下樓查驗沒有之後就上樓回房間，然後又下樓查驗，你不停的上下樓查驗，其實大可不必如此，何不等包裹到達以後，讓門衞打電話通知你去取呢？&lt;/p&gt; 
&lt;p&gt;條件變量提供了一種類似通知 notify 的機制，它讓兩類線程能夠在一個點交匯。條件變量能夠讓線程等待某個條件發生，條件本身受互斥鎖保護，因此條件變量必須搭配互斥鎖使用，鎖保護條件，線程在改變條件前先獲得鎖，然後改變條件狀態，再解鎖，最後發出通知，等待條件的睡眠中的線程在被喚醒前，必須先獲得鎖，再判斷條件狀態，如果條件不成立，則繼續轉入睡眠並釋放鎖。&lt;/p&gt; 
&lt;p&gt;對應到上面的例子，工作線程等待的條件是消息隊列有消息（非空），用條件變量改寫上面的代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void io_thread() {
    while (1) {
        Msg* msg = read_msg_from_socket();
        {
            std::lock_guard&amp;lt;std::mutex&amp;gt; lock(msg_queue_mutex);
            msg_queue.push_back(msg);
        }
        msg_queue_not_empty.notify_all();
    }
}

void work_thread() {
    while (1) {
        Msg* msg = nullptr;
        {
            std::unique_lock&amp;lt;std::mutex&amp;gt; lock(msg_queue_mutex);
            msg_queue_not_empty.wait(lock, []{ return !msg_queue.empty(); });
            msg = msg_queue.get();
        }
        process(msg);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;std::lock_guard 是互斥量的一個 RAII 包裝類，std::unique_lock 除了會在析構函數自動解鎖外，還支持主動 unlock()。&lt;/p&gt; 
&lt;p&gt;生產者在往 msg_queue 投遞消息的時候，需要對 msg_queue 加鎖，通知 work 線程的代碼可以放在解鎖之後，等待 msg_queue_not_empty 條件必須受 msg_queue_mutex 保護，wait 的第二個參數是一個 lambda 表達式，因為會有多個 work 線程被喚醒，線程被喚醒後，會重新獲得鎖，檢查條件，如果不成立，則再次睡眠。條件變量的使用需要非常謹慎，否則容易出現不能喚醒的情況。&lt;/p&gt; 
&lt;p&gt;C 語言的條件變量、Posix 條件變量的編程接口跟 C++的類似，概念上是一致的，故在此不展開介紹。&lt;/p&gt; 
&lt;h3&gt;2.8 lock-free 和無鎖數據結構&lt;/h3&gt; 
&lt;h4&gt;2.8.1 鎖同步的問題&lt;/h4&gt; 
&lt;p&gt;線程同步分為阻塞型同步和非阻塞型同步。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;互斥量、信號、條件變量這些系統提供的機制都屬於阻塞型同步，在爭用資源的時候，會導致調用線程阻塞。&lt;/li&gt; 
 &lt;li&gt;非阻塞型同步是指在無鎖的情況下，通過某種算法和技術手段實現不用阻塞而同步。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;鎖是阻塞同步機制，阻塞同步機制的缺陷是可能掛起你的程序，如果持有鎖的線程崩潰或者 hang 住，則鎖永遠得不到釋放，而其他線程則將陷入無限等待；另外，它也可能導致優先級倒轉等問題。所以，我們需要 lock-free 這類非阻塞的同步機制。&lt;/p&gt; 
&lt;h4&gt;2.8.2 什麼是 lock-free&lt;/h4&gt; 
&lt;p&gt;lock-free 沒有鎖同步的問題，所有線程無阻礙的執行原子指令，而不是等待。比如一個線程讀 atomic 類型變量，一個線程寫 atomic 變量，它們沒有任何等待，硬件原子指令確保不會出現數據不一致，寫入數據不會出現半完成，讀取數據也不會讀一半。&lt;/p&gt; 
&lt;p&gt;那到底什麼是 lock-free？有人説 lock-free 就是不使用 mutex / semaphores 之類的無鎖（lock-Less）編程，這句話嚴格來説並不對。&lt;/p&gt; 
&lt;p&gt;我們先看一下 wiki 對 Lock-free 的描述:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Lock-freedom allows individual threads to starve but guarantees system-wide throughput. An algorithm is lock-free if, when the program threads are run for a sufficiently long time, at least one of the threads makes progress (for some sensible definition of progress). All wait-free algorithms are lock-free. In particular, if one thread is suspended, then a lock-free algorithm guarantees that the remaining threads can still make progress. Hence, if two threads can contend for the same mutex lock or spinlock, then the algorithm is not lock-free. (If we suspend one thread that holds the lock, then the second thread will block.)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;翻譯一下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第 1 段：lock-free 允許單個線程飢餓但保證系統級吞吐。如果一個程序線程執行足夠長的時間，那麼至少一個線程會往前推進，那麼這個算法就是 lock-free 的。&lt;/li&gt; 
 &lt;li&gt;第 2 段：尤其是，如果一個線程被暫停，lock-free 算法保證其他線程依然能夠往前推進。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;第 1 段給 lock-free 下定義，第 2 段則是對 lock-free 作解釋：如果 2 個線程競爭同一個互斥鎖或者自旋鎖，那它就不是 lock-free 的；因為如果暫停（Hang）持有鎖的線程，那麼另一個線程會被阻塞。&lt;/p&gt; 
&lt;p&gt;wiki 的這段描述很抽象，它不夠直觀，稍微再解釋一下：lock-free 描述的是代碼邏輯的屬性，不使用鎖的代碼，大部分具有這種屬性。大家經常會混淆這 lock-free 和無鎖這 2 個概念。其實，lock-free 是對代碼（算法）性質的描述，是屬性；而無鎖是説代碼如何實現，是手段。&lt;/p&gt; 
&lt;p&gt;lock-free 的關鍵描述是：如果一個線程被暫停，那麼其他線程應能繼續前進，它需要有系統級（system-wide）的吞吐。&lt;/p&gt; 
&lt;p&gt;如圖，兩個線程在時間線上，至少有一個線程處於 running 狀態。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/5b45d715f8b8e6576d9e841a9a4c4bd1217086.png&quot; alt=&quot;Lock-free&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們從反面舉例來看，假設我們要藉助鎖實現一個無鎖隊列，我們可以直接使用線程不安全的 std::queue + std::mutex 來做：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;template &amp;lt;typename T&amp;gt;
class Queue {
public:
    void push(const T&amp;amp; t) {
        q_mutex.lock();
        q.push(t);
        q_mutex.unlock();
    }
private:
    std::queue&amp;lt;T&amp;gt; q;
    std::mutex q_mutex;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果有線程 A/B/C 同時執行 push 方法，最先進入的線程 A 獲得互斥鎖。線程 B 和 C 因為獲取不到互斥鎖而陷入等待。這個時候，線程 A 如果因為某個原因（如出現異常，或者等待某個資源）而被永久掛起，那麼同樣執行 push 的線程 B/C 將被永久掛起，系統整體（system-wide）沒法推進，而這顯然不符合 lock-free 的要求。因此：所有基於鎖（包括 spinlock）的併發實現，都不是 lock-free 的。&lt;/p&gt; 
&lt;p&gt;因為它們都會遇到同樣的問題：即如果永久暫停當前佔有鎖的線程/進程的執行，將會阻塞其他線程/進程的執行。而對照 lock-free 的描述，它允許部分 process（理解為執行流）餓死但必須保證整體邏輯的持續前進，基於鎖的併發顯然是違背 lock-free 要求的。&lt;/p&gt; 
&lt;h4&gt;2.8.3 CAS loop 實現 Lock-free&lt;/h4&gt; 
&lt;p&gt;Lock-Free 同步主要依靠 CPU 提供的 read-modify-write 原語，著名的&quot;比較和交換&quot;CAS（Compare And Swap）在 X86 機器上是通過 cmpxchg 系列指令實現的原子操作，CAS 邏輯上用代碼表達是這樣的：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool CAS(T* ptr, T expect_value, T new_value) {
   if (*ptr != expect_value) {
      return false;
   }
   *ptr = new_value;
   return true;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CAS 接受 3 個參數：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內存地址&lt;/li&gt; 
 &lt;li&gt;期望值，通常傳第一個參數所指內存地址中的舊值&lt;/li&gt; 
 &lt;li&gt;新值&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;邏輯描述：CAS 比較內存地址中的值和期望值，如果不相同就返回失敗，如果相同就將新值寫入內存並返回成功。&lt;/p&gt; 
&lt;p&gt;當然這個 C 函數描述的只是 CAS 的邏輯，這個函數操作不是原子的，因為它可以劃分成幾個步驟：讀取內存值、判斷、寫入新值，各步驟之間是可以插入其他操作的。不過前面講了，原子指令相當於把這些步驟打包，它可能是通過 lock; cmpxchg 指令實現的，但那是實現細節，程序員更應該注重在邏輯上理解它的行為。&lt;/p&gt; 
&lt;p&gt;通過 CAS 實現 Lock-free 的代碼通常藉助循環，代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;do {
    T expect_value = *ptr;
} while (!CAS(ptr, expect_value, new_value));
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;創建共享數據的本地副本：expect_value。&lt;/li&gt; 
 &lt;li&gt;根據需要修改本地副本，從 ptr 指向的共享數據裏 load 後賦值給 expect_value。&lt;/li&gt; 
 &lt;li&gt;檢查共享的數據跟本地副本是否相等，如果相等，則把新值複製到共享數據。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;第三步是關鍵，雖然 CAS 是原子的，但加載 expect_value 跟 CAS 這 2 個步驟，並不是原子的。所以，我們需要藉助循環，如果 ptr 內存位置的值沒有變（*ptr == expect_value），那就存入新值返回成功；否則説明加載 expect_value 後，ptr 指向的內存位置被其他線程修改了，這時候就返回失敗，重新加載 expect_value，重試，直到成功為止。&lt;/p&gt; 
&lt;p&gt;CAS loop 支持多線程併發寫，這個特點太有用了，因為多線程同步，很多時候都面臨多寫的問題，我們可以基於 CAS 實現 Fetch-and-add(FAA) 算法，它看起來像這樣：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;T faa(T&amp;amp; t) {
    T temp = t;
    while (!compare_and_swap(x, temp, temp + 1));
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;第一步加載共享數據的值到 temp，第二步比較+存入新值，直到成功。&lt;/p&gt; 
&lt;h4&gt;2.8.4 無鎖數據結構：lock-free stack&lt;/h4&gt; 
&lt;p&gt;無鎖數據結構是通過非阻塞算法而非鎖保護共享數據，非阻塞算法保證競爭共享資源的線程，不會因為互斥而讓它們的執行無限期暫停；無阻塞算法是 lock-free 的，因為無論如何調度都能確保有系統級的進度。wiki 定義如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A non-blocking algorithm ensures that threads competing for a shared resource do not have their execution indefinitely postponed by mutual exclusion. A non-blocking algorithm is lock-free if there is guaranteed system-wide progress regardless of scheduling.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下面是 C++ atomic compare_exchange_weak() 實現的一個 lock-free 堆棧（from CppReference）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;template &amp;lt;typename T&amp;gt;
struct node {
    T data;
    node* next;
    node(const T&amp;amp; data) : data(data), next(nullptr) {}
};
 
template &amp;lt;typename T&amp;gt;
class stack {
    std::atomic&amp;lt;node&amp;lt;T&amp;gt;*&amp;gt; head;
public:
    void push(const T&amp;amp; data) {
      node&amp;lt;T&amp;gt;* new_node = new node&amp;lt;T&amp;gt;(data);
      new_node-&amp;gt;next = head.load(std::memory_order_relaxed);
      while (!head.compare_exchange_weak(new_node-&amp;gt;next, new_node,
                                        std::memory_order_release,
                                        std::memory_order_relaxed));
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代碼解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;節點（node）保存 T 類型的數據 data，並且持有指向下一個節點的指針。&lt;/li&gt; 
 &lt;li&gt;std::atomic&amp;lt;node*&amp;gt;類型表明 atomic 裏放置的是 Node 的指針，而非 Node 本身，因為指針在 64 位系統上是 8 字節，等於機器字長，再長沒法保證原子性。&lt;/li&gt; 
 &lt;li&gt;stack 類包含 head 成員，head 是一個指向頭結點的指針，頭結點指針相當於堆頂指針，剛開始沒有節點，head 為 NULL。&lt;/li&gt; 
 &lt;li&gt;push 函數裏，先根據 data 值創建新節點，然後要把它放到堆頂。&lt;/li&gt; 
 &lt;li&gt;因為是用鏈表實現的棧，所以，如果新節點要成為新的堆頂（相當於新節點作為新的頭結點插入），那麼新節點的 next 域要指向原來的頭結點，並讓 head 指向新節點。&lt;/li&gt; 
 &lt;li&gt;new_node-&amp;gt;next = head.load 把新節點的 next 域指向原頭結點，然後 head.compare_exchange_weak(new_node-&amp;gt;next, new_node)，讓 head 指向新節點。&lt;/li&gt; 
 &lt;li&gt;C++ atomic 的 compare_exchange_weak() 跟上述的 CAS 稍有不同，head.load() 不等於 new_node-&amp;gt;next 的時候，它會把 head.load() 的值重新加載到 new_node-&amp;gt;next。&lt;/li&gt; 
 &lt;li&gt;所以，在加載 head 值和 CAS 之間，如果其他線程調用 push 操作，改變了 head 的值，那沒有關係，該線程的本次 cas 失敗，下次重試便可以了。&lt;/li&gt; 
 &lt;li&gt;多個線程同時 push 時，任一線程在任意步驟阻塞/掛起，其他線程都會繼續執行並最終返回，無非就是多執行幾次 while 循環。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這樣的行為邏輯顯然符合 lock-free 的定義，注意用 CAS+Loop 實現自旋鎖不符合 lock-free 的定義，注意區分。&lt;/p&gt; 
&lt;h3&gt;2.9 程序序：Program Order&lt;/h3&gt; 
&lt;p&gt;對單線程程序而言，代碼會一行行順序執行，就像我們編寫的程序的順序那樣。比如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;會先執行 a=1 再執行 b=2，從程序角度看到的代碼行依次執行叫程序序，我們在此基礎上構建軟件，並以此作為討論的基礎。&lt;/p&gt; 
&lt;h3&gt;2.10 內存序：Memory Order&lt;/h3&gt; 
&lt;p&gt;與程序序相對應的內存序，是指從某個角度觀察到的對於內存的讀和寫所真正發生的順序。內存操作順序並不唯一，在一個包含 core0 和 core1 的 CPU 中，core0 和 core1 有着各自的內存操作順序，這兩個內存操作順序不一定相同。從包含多個 Core 的 CPU 的視角看到的全局內存操作順序跟單 core 視角看到的內存操作順序亦不同，而這種不同，對於有些程序邏輯而言，是不可接受的，例如：&lt;/p&gt; 
&lt;p&gt;程序序要求 a = 1 在 b = 2 之前執行，但內存操作順序可能並非如此，對 a 賦值 1 並不確保發生在對 b 賦值 2 之前，這是因為：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果編譯器認為對 b 賦值沒有依賴對 a 賦值，那它完全可能在編譯期調整編譯後的彙編指令順序。&lt;/li&gt; 
 &lt;li&gt;即使編譯器不做調整，到了執行期，也有可能對 b 的賦值先於對 a 賦值執行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;雖然對一個 Core 而言，如上所述，這個 Core 觀察到的內存操作順序不一定符合程序序，但內存操作序和程序序必定產生相同的結果，無論在單 Core 上對 a、b 的賦值哪個先發生，結果上都是 a 被賦值為 1、b 被賦值為 2，如果單核上亂序執行會影響結果，那編譯器的指令重排和 CPU 亂序執行便不會發生，硬件會提供這項保證。&lt;/p&gt; 
&lt;p&gt;但多核系統，硬件不提供這樣的保證，多線程程序中，每個線程所工作的 Core 觀察到的不同內存操作序，以及這些順序與全局內存序的差異，常常導致多線程同步失敗，所以，需要有同步機制確保內存序與程序序的一致，內存屏障（Memory Barrier）的引入，就是為瞭解決這個問題，它讓不同的 Core 之間，以及 Core 與全局內存序達成一致。&lt;/p&gt; 
&lt;h3&gt;2.11 亂序執行：Out-of-order Execution&lt;/h3&gt; 
&lt;p&gt;亂序執行會引起內存順序跟程序順序不同，亂序執行的原因是多方面的，比如編譯器指令重排、超標量指令流水線、預測執行、Cache-Miss 等。內存操作順序無法精確匹配程序順序，這有可能帶來混亂，既然有副作用，那為什麼還需要亂序執行呢？答案是為了性能。&lt;/p&gt; 
&lt;p&gt;我們先看看沒有亂序執行之前，早期的有序處理器（In-order Processors）是怎麼處理指令的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;指令獲取，從代碼節內存區域加載指令到 I-Cache&lt;/li&gt; 
 &lt;li&gt;譯碼&lt;/li&gt; 
 &lt;li&gt;如果指令操作數可用（例如操作數位於寄存器中），則分發指令到對應功能模塊中；如果操作數不可用，通常是需要從內存加載，則處理器會 stall，一直等到它們就緒，直到數據被加載到 Cache 或拷貝進寄存器&lt;/li&gt; 
 &lt;li&gt;指令被功能單元執行&lt;/li&gt; 
 &lt;li&gt;功能單元將結果寫回寄存器或內存位置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;亂序處理器（Out-of-order Processors）又是怎麼處理指令的呢？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;指令獲取，從代碼節內存區域加載指令到 I-Cache&lt;/li&gt; 
 &lt;li&gt;譯碼&lt;/li&gt; 
 &lt;li&gt;分發指令到指令隊列&lt;/li&gt; 
 &lt;li&gt;指令在指令隊列中等待，一旦操作數就緒，指令就離開指令隊列，那怕它之前的指令未被執行（亂序）&lt;/li&gt; 
 &lt;li&gt;指令被派往功能單元並被執行&lt;/li&gt; 
 &lt;li&gt;執行結果放入隊列（Store Buffer），而不是直接寫入 Cache&lt;/li&gt; 
 &lt;li&gt;只有更早請求執行的指令結果寫入 cache 後，指令執行結果才寫入 Cache，通過對指令結果排序寫入 cache，使得執行看起來是有序的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;指令亂序執行是結果，但原因並非只有 CPU 的亂序執行，而是由兩種因素導致：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;編譯期&lt;/strong&gt;：指令重排（編譯器），編譯器會為了性能而對指令重排，源碼上先後的兩行，被編譯器編譯後，可能調換指令順序，但編譯器會基於一套規則做指令重排，有明顯依賴的指令不會被隨意重排，指令重排不能破壞程序邏輯。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;運行期&lt;/strong&gt;：亂序執行（CPU），CPU 的超標量流水線、以及預測執行、Cache-Miss 等都有可能導致指令亂序執行，也就是説，後面的指令有可能先於前面的指令執行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.12 Store Buffer&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;為什麼需要 Store Buffer？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考慮下面的代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void set_a() {
    a = 1;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;假設運行在 core0 上的 set_a() 對整型變量 a 賦值 1，計算機通常不會直接寫穿通到內存，而是會在 Cache 中修改對應 Cache Line&lt;/li&gt; 
 &lt;li&gt;如果 Core0 的 Cache 裏沒有 a，賦值操作（store）會造成 Cache Miss&lt;/li&gt; 
 &lt;li&gt;Core0 會 stall 在等待 Cache 就緒（從內存加載變量 a 到對應的 Cache Line），但 Stall 會損害 CPU 性能，相當於 CPU 在這裏停頓，白白浪費着寶貴的 CPU 時間&lt;/li&gt; 
 &lt;li&gt;有了 Store Buffer，當變量在 Cache 中沒有就位的時候，就先 Buffer 住這個 Store 操作，而 Store 操作一旦進入 Store Buffer，core 便認為自己 Store 完成，當隨後 Cache 就位，store 會自動寫入對應 Cache。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以，我們需要 Store Buffer，每個 Core 都有獨立的 Store Buffer，每個 Core 都訪問私有的 Store Buffer，Store Buffer 幫助 CPU 遮掩了 Store 操作帶來的延遲。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Store Buffer 會帶來什麼問題？&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
assert(a == 1);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上面的代碼，斷言 a==1 的時候，需要讀（load）變量 a 的值，而如果 a 在被賦值前就在 Cache 中，就會從 Cache 中讀到 a 的舊值（可能是 1 之外的其他值），所以斷言就可能失敗。但這樣的結果顯然是不能接受的，它違背了最直觀的程序順序性。&lt;/p&gt; 
&lt;p&gt;問題出在變量 a 除保存在內存外，還有 2 份拷貝：一份在 Store Buffer 裏，一份在 Cache 裏；如果不考慮這 2 份拷貝的關係，就會出現數據不一致。那怎麼修復這個問題呢？&lt;/p&gt; 
&lt;p&gt;可以通過在 Core Load 數據的時候，先檢查 Store Buffer 中是否有懸而未決的 a 的新值，如果有，則取新值；否則從 cache 取 a 的副本。這種技術在多級流水線 CPU 設計的時候就經常使用，叫 Store Forwarding。有了 Store Buffer Forwarding，就能確保單核程序的執行遵從程序順序性，但多核還是有問題，讓我們考查下面的程序：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多核內存序問題&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int a = 0; // 被 CPU1 Cache
int b = 0; // 被 CPU0 Cache

// CPU0 執行
void x() {
    a = 1;
    b = 2;
}

// CPU1 執行
void y() {
    while (b == 0);
    assert(a == 1);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;假設 a 和 b 都被初始化為 0；CPU0 執行 x() 函數，CPU1 執行 y() 函數；變量 a 在 CPU1 的 local Cache 裏，變量 b 在 CPU0 的 local Cache 裏。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU0 執行 a = 1 的時候，因為 a 不在 CPU0 的 local cache，CPU0 會把 a 的新值 1 寫入 Store Buffer 裏，併發送 Read Invalidate 消息給其他 CPU。&lt;/li&gt; 
 &lt;li&gt;CPU1 執行 while (b == 0)，因為 b 不在 CPU1 的 local cache 裏，CPU1 會發送 Read 消息去其他 CPU 獲取 b 的值。&lt;/li&gt; 
 &lt;li&gt;CPU0 執行 b = 2，因為 b 在 CPU0 的 local Cache，所以直接更新 local cache 中 b 的副本。&lt;/li&gt; 
 &lt;li&gt;CPU0 收到 CPU1 發來的 read 消息，把 b 的新值 2 發送給 CPU1；同時存放 b 的 Cache Line 的狀態被設置為 Shared，以反應 b 同時被 CPU0 和 CPU1 cache 住的事實。&lt;/li&gt; 
 &lt;li&gt;CPU1 收到 b 的新值 2 後結束循環，繼續執行 assert(a == 1)，因為此時 local Cache 中的 a 值為 0，所以斷言失敗。&lt;/li&gt; 
 &lt;li&gt;CPU1 收到 CPU0 發來的 Read Invalidate 後，更新 a 的值為 1，但為時已晚，程序在上一步已經崩了（assert 失敗）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;怎麼辦？答案留到內存屏障一節揭曉。&lt;/p&gt; 
&lt;h3&gt;2.13 Invalidate Queue&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;為什麼需要 Invalidate Queue？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當一個變量加載到多個 core 的 Cache，則這個 Cache Line 處於 Shared 狀態，如果 Core1 要修改這個變量，則需要通過發送核間消息 Invalidate 來通知其他 Core 把對應的 Cache Line 置為 Invalid，當其他 Core 都 Invalid 這個 CacheLine 後，則本 Core 獲得該變量的獨佔權，這個時候就可以修改它了。&lt;/p&gt; 
&lt;p&gt;收到 Invalidate 消息的 core 需要回 Invalidate ACK，一個個 core 都這樣 ACK，等所有 core 都回復完，Core1 才能修改它，這樣 CPU 就白白浪費。&lt;/p&gt; 
&lt;p&gt;事實上，其他核在收到 Invalidate 消息後，會把 Invalidate 消息緩存到 Invalidate Queue，並立即回覆 ACK，真正 Invalidate 動作可以延後再做，這樣一方面因為 Core 可以快速返回別的 Core 發出的 Invalidate 請求，不會導致發生 Invalidate 請求的 Core 不必要的 Stall，另一方面也提供了進一步優化可能，比如在一個 CacheLine 裏的多個變量的 Invalidate 可以攢一次做了。&lt;/p&gt; 
&lt;p&gt;但寫 Store Buffer 的方式其實是 Write Invalidate，它並非立即寫入內存，如果其他核此時從內存讀數，則有可能不一致。&lt;/p&gt; 
&lt;h3&gt;2.14 內存屏障&lt;/h3&gt; 
&lt;p&gt;那有沒有方法確保對 a 的賦值一定先於對 b 的賦值呢？有，內存屏障被用來提供這個保障。&lt;/p&gt; 
&lt;p&gt;內存屏障（Memory Barrier），也稱內存柵欄、屏障指令等，是一類同步屏障指令，是 CPU 或編譯器在對內存隨機訪問的操作中的一個同步點，同步點之前的所有讀寫操作都執行後，才可以開始執行此點之後的操作。語義上，內存屏障之前的所有寫操作都要寫入內存；內存屏障之後的讀操作都可以獲得同步屏障之前的寫操作的結果。&lt;/p&gt; 
&lt;p&gt;內存屏障，其實就是提供一種機制，確保代碼裏順序寫下的多行，會按照書寫的順序，被存入內存，主要是解決 Store Buffer 引入導致的寫入內存間隙的問題。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void x() {
    a = 1;
    wmb();
    b = 2;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;像上面那樣在 a=1 和 b=2 之間插入一條內存屏障語句，就能確保 a=1 先於 b=2 生效，從而解決了內存亂序訪問問題，那插入的這句 smp_mb()，到底會幹什麼呢？&lt;/p&gt; 
&lt;p&gt;回憶前面的流程，CPU0 在執行完 a = 1 之後，執行 smp_mb() 操作，這時候，它會給 Store Buffer 裏的所有數據項做一個標記（marked），然後繼續執行 b = 2，但這時候雖然 b 在自己的 cache 裏，但由於 store buffer 裏有 marked 條目，所以，CPU0 不會修改 cache 中的 b，而是把它寫入 Store Buffer；所以 CPU0 收到 Read 消息後，會把 b 的 0 值發給 CPU1，所以繼續在 while (b) 自旋。&lt;/p&gt; 
&lt;p&gt;簡而言之，Core 執行到 write memory barrier（wmb）的時候，如果 Store Buffer 還有懸而未決的 store 操作，則都會被 mark 上，直到被標註的 Store 操作進入內存後，後續的 Store 操作才能被執行，因此 wmb 保障了 barrier 前後操作的順序，它不關心 barrier 前的多個操作的內存序，以及 barrier 後的多個操作的內存序，是否與 Global Memory Order 一致。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
wmb();
c = 3;
d = 4;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;wmb() 保證&quot;a=1;b=2&quot;發生在&quot;c=3;d = 4&quot;之前，不保證 a = 1 和 b = 2 的內存序，也不保證 c = 3 和 d = 4 的內部序。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Invalidate Queue 的引入的問題&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;就像引入 Store Buffer 會影響 Store 的內存一致性，Invalidate Queue 的引入會影響 Load 的內存一致性。因為 Invalidate queue 會緩存其他核發過來的消息，比如 Invalidate 某個數據的消息被 delay 處置，導致 core 在 Cache Line 中命中這個數據，而這個 Cache Line 本應該被 Invalidate 消息標記無效。如何解決這個問題呢？&lt;/p&gt; 
&lt;p&gt;一種思路是硬件確保每次 load 數據的時候，需要確保 Invalidate Queue 被清空，這樣可以保證 load 操作的強順序&lt;/p&gt; 
&lt;p&gt;軟件的思路，就是仿照 wmb() 的定義，加入 rmb() 約束。rmb() 給我們的 invalidate queue 加上標記。當一個 load 操作發生的時候，之前的 rmb() 所有標記的 invalidate 命令必須全部執行完成，然後才可以讓隨後的 load 發生。這樣，我們就在 rmb() 前後保證了 load 觀察到的順序等同於 global memory order&lt;/p&gt; 
&lt;p&gt;所以，我們可以像下面這樣修改代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
wmb();
b = 2;

while(b != 2) {};
rmb();
assert(a == 1);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;系統對內存屏障的支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;gcc 編譯器在遇到內嵌彙編語句 asm volatile(&quot;&quot; ::: &quot;memory&quot;)，將以此作為一條內存屏障，重排序內存操作，即此語句之前的各種編譯優化將不會持續到此語句之後。&lt;/p&gt; 
&lt;p&gt;Linux 內核提供函數 barrier() 用於讓編譯器保證其之前的內存訪問先於其之後的完成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#define barrier() __asm__ __volatile__(&quot;&quot; ::: &quot;memory&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CPU 內存屏障：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通用 barrier，保證讀寫操作有序， mb() 和 smp_mb()&lt;/li&gt; 
 &lt;li&gt;寫操作 barrier，僅保證寫操作有序，wmb() 和 smp_wmb()&lt;/li&gt; 
 &lt;li&gt;讀操作 barrier，僅保證讀操作有序，rmb() 和 smp_rmb()&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;小結&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;為了提高處理器的性能，SMP 中引入了 store buffer(以及對應實現 store buffer forwarding) 和 invalidate queue。&lt;/li&gt; 
 &lt;li&gt;store buffer 的引入導致 core 上的 store 順序可能不匹配於 global memory 的順序，對此，我們需要使用 wmb() 來解決。&lt;/li&gt; 
 &lt;li&gt;invalidate queue 的存在導致 core 上觀察到的 load 順序可能與 global memory order 不一致，對此，我們需要使用 rmb() 來解決。&lt;/li&gt; 
 &lt;li&gt;由於 wmb() 和 rmb() 分別只單獨作用於 store buffer 和 invalidate queue，因此這兩個 memory barrier 共同保證了 store/load 的順序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3 偽共享&lt;/h2&gt; 
&lt;p&gt;多個線程同時讀寫同一個 Cache Line 中的變量、導致 CPU Cache 頻繁失效，從而使得程序性能下降的現象稱為&lt;strong&gt;偽共享&lt;/strong&gt;（False Sharing）。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const size_t shm_size = 16*1024*1024; //16M
static char shm[shm_size];
std::atomic&amp;lt;size_t&amp;gt; shm_offset{0};

void f() {
    for (;;) {
        auto off = shm_offset.fetch_add(sizeof(long));
        if (off &amp;gt;= shm_size) break;
        *(long*)(shm + off) = off; // 賦值
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;考察上面的程序：shm 是一塊 16M 字節的內存，我測試的機器的 L3 Cache 是 32M，16M 字節能確保 shm 在 Cache 裏放得下。f() 函數的循環裏，視 shm 為 long 類型的數組，依次給每個元素賦值，shm_offset 用於記錄偏移位置，shm_offset.fetch_add(sizeof(long)) 原子性的增加 shm_offset 的值（因為 x86_64 系統上 long 的長度為 8，所以 shm_offset 每次增加 8），並返回增加前的值，對 shm 上 long 數組的每個元素賦值後，結束循環從函數返回。&lt;/p&gt; 
&lt;p&gt;因為 shm_offset 是 atomic 類型變量，所以多線程調用 f() 依然能正常工作，雖然多個線程會競爭 shm_offset，但每個線程會排他性的對各 long 元素賦值，多線程並行會加快對 shm 的賦值操作。我們加上多線程調用代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;std::atomic&amp;lt;size_t&amp;gt; step{0};

const int THREAD_NUM = 2;

void work_thread() {
    const int LOOP_N = 10;
    for (int n = 1; n &amp;lt;= LOOP_N; ++n) {
        f();
        ++step;
        while (step.load() &amp;lt; n * THREAD_NUM) {}
        shm_offset = 0;
    }
}

int main() {
    std::thread threads[THREAD_NUM];
    for (int i = 0; i &amp;lt; THREAD_NUM; ++i) {
        threads[i] = std::move(std::thread(work_thread));
    }
    for (int i = 0; i &amp;lt; THREAD_NUM; ++i) {
        threads[i].join();
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;main 函數裏啓動 2 個工作線程 work_thread。&lt;/li&gt; 
 &lt;li&gt;工作線程對 shm 共計賦值 10 輪，後面的每一輪會訪問 Cache 裏的 shm 數據，step 用於 work_thread 之間每一輪的同步。&lt;/li&gt; 
 &lt;li&gt;工作線程調用完 f() 後會增加 step，等 2 個工作線程都調用完之後，step 的值增加到 n * THREAD_NUM 後，while() 會結束循環，重置 shm_offset，重新開始新一輪對 shm 的賦值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/a74220a3c91fffad017e1ca8b3b02d28157434.png&quot; alt=&quot;false-sharing-1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;編譯後執行上面的程序，產生如下的結果：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;time ./a.out

real 0m3.406s
user 0m6.740s
sys 0m0.040s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;time 命令用於時間測量，a.out 程序運行完成後會打印耗時，real 列顯式耗時 3.4 秒。&lt;/p&gt; 
&lt;h3&gt;3.1 改進版 f_fast&lt;/h3&gt; 
&lt;p&gt;我們稍微修改一下 f 函數，改進版 f 函數取名 f_fast：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void f_fast() {
    for (;;) {
        const long inner_loop = 16;
        auto off = shm_offset.fetch_add(sizeof(long) * inner_loop);
        for (long j = 0; j &amp;lt; inner_loop; ++j) {
            if (off &amp;gt;= shm_size) return;
            *(long*)(shm + off) = j;
            off += sizeof(long);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;for 循環裏，shm_offset 不再是每次增加 8 字節（sizeof(long)），而是 8*16=128 字節，然後在內層的循環裏，依次對 16 個 long 連續元素賦值，然後下一輪循環又再次增加 128 字節，直到完成對 shm 的賦值。如圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/3a6d828073f5cd09877a906edbb5e8c3240113.png&quot; alt=&quot;no-false-sharing&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;編譯後重新執行程序，結果顯示耗時降低到 0.06 秒，對比前一種耗時 3.4 秒，f_fast 性能提升明顯。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;time ./a.out

real 0m0.062s
user 0m0.110s
sys 0m0.012s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;f 和 f_fast 的行為差異&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;shm 數組總共有 2M 個 long 元素，因為 16M / sizeof(long) 得 2M：&lt;/p&gt; 
&lt;p&gt;1、f() 函數行為邏輯&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;線程 1 和線程 2 的 work_thread 裏會交錯地對 shm 元素賦值，shm 的 2M 個 long 元素，會順序的一個接一個的派給 2 個線程去賦值。&lt;/li&gt; 
 &lt;li&gt;可能的行為：元素 1 由線程 1 賦值，元素 2 由線程 2 賦值，然後元素 3 和元素 4 由線程 1 賦值，然後元素 5 又由線程 2 賦值...&lt;/li&gt; 
 &lt;li&gt;每次分派元素的時候，shm_offset 都會 atomic 的增加 8 字節，所以不會出現 2 個線程給同 1 個元素賦值的情況。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2、f_fast() 函數行為邏輯&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次派元素的時候，shm_offset 原子性的增加 128 字節（16 個元素）。&lt;/li&gt; 
 &lt;li&gt;這 16 個字節作為一個整體，派給線程 1 或者線程 2；雖然線程 1 和線程 2 還是會交錯的操作 shm 元素，但是以 16 個元素（128 字節）為單元，這 16 個連續的元素不會被分開派發給不同線程。&lt;/li&gt; 
 &lt;li&gt;一次派發的 16 個元素，會在一個線程裏被一個接着一個的賦值（內部循環裏）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.2 為什麼 f_fast 更快&lt;/h3&gt; 
&lt;p&gt;第一眼感覺是 f_fast() 裏 shm_offset.fetch_add() 調用頻次降低到了原來的 1/16，有理由懷疑是原子變量的競爭減少導致程序執行速度加快。為了驗證，讓我們在內層的循環里加一個原子變量 test 的 fetch_add，test 原子變量的競爭會像 f() 函數裏 shm_offset.fetch_add() 一樣激烈，修改後的 f_fast 代碼變成下面這樣：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void f_fast() {
    for (;;) {
        const long inner_loop = 16;
        auto off = shm_offset.fetch_add(sizeof(long) * inner_loop);
        for (long j = 0; j &amp;lt; inner_loop; ++j) {
            test.fetch_add(1);
            if (off &amp;gt;= shm_size) return;
            *(long*)(shm + off) = j;
            off += sizeof(long);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;為了避免 test.fetch_add(1) 的調用被編譯器優化掉，我們在 main 函數的最後把 test 的值打印出來。編譯後測試一下，結果顯示：執行時間只是稍微增加到 real 0m0.326s，很顯然，並不是 atomic 的調用頻次減少導致性能飆升。&lt;/p&gt; 
&lt;p&gt;重新審視 f() 循環裏的邏輯：f() 循環裏的操作很簡單：原子增加、判斷、賦值。我們把 f() 的裏賦值註釋掉，再測試一下，發現它的速度得到了很大提升，看來是*(long*)(shm + off) = off 這一行代碼執行慢，但這明明只是一行賦值。我們把它反彙編來看，它只是一個 mov 指令，源操作數是寄存器，目標操作數是內存地址，從寄存器拷貝數據到一個內存地址，為什麼會這麼慢呢？&lt;/p&gt; 
&lt;h3&gt;3.3 原因&lt;/h3&gt; 
&lt;p&gt;現在揭曉答案：導致 f() 性能底下的元兇是偽共享（false sharing）。那什麼是偽共享？要説清這個問題，還得聯繫 CPU 的架構以及 CPU 怎麼訪問數據，回顧一下關於多核 Cache 結構。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;背景知識&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現代 CPU 可以有多個核，每個核有自己的 L1-L2 緩存，L1 又區分數據緩存（L1-DCache）和指令緩存（L1-ICache），L2 不區分數據和指令 Cache，而 L3 是跨核共享的，L3 通過內存總線連接到內存，內存被所有 CPU 所有 Core 共享。&lt;/p&gt; 
&lt;p&gt;CPU 訪問 L1 Cache 的速度大約是訪問內存的 100 倍，Cache 作為 CPU 與內存之間的緩存，減少對內存的訪問頻率。&lt;/p&gt; 
&lt;p&gt;從內存加載數據到 Cache 的時候，是以 Cache Line 為長度單位的，Cache Line 的長度通常是 64 字節，所以，那怕只讀一個字節，但是包含該字節的整個 Cache Line 都會被加載到緩存，同樣，如果修改一個字節，那麼最終也會導致整個 Cache Line 被沖刷到內存。&lt;/p&gt; 
&lt;p&gt;如果一塊內存數據被多個線程訪問，假設多個線程在多個 Core 上並行執行，那麼它便會被加載到多個 Core 的的 Local Cache 中；這些線程在哪個 Core 上運行，就會被加載到哪個 Core 的 Local Cache 中，所以，內存中的一個數據，在不同 Core 的 Cache 裏會同時存在多份拷貝。&lt;/p&gt; 
&lt;p&gt;那麼，便會存在緩存一致性問題。當一個 Core 修改其緩存中的值時，其他 Core 不能再使用舊值。該內存位置將在所有緩存中失效。此外，由於緩存以緩存行而不是單個字節的粒度運行，因此整個緩存行將在所有緩存中失效。如果我們修改了 Core1 緩存裏的某個數據，則該數據所在的 Cache Line 的狀態需要同步給其他 Core 的緩存，Core 之間可以通過核間消息同步狀態，比如通過發送 Invalidate 消息給其他核，接收到該消息的核會把對應 Cache Line 置為無效，然後重新從內存里加載最新數據。&lt;/p&gt; 
&lt;p&gt;當然，被加載到多個 Core 緩存中的同一 Cache Line，會被標記為共享（Shared）狀態，對共享狀態的緩存行進行修改，需要先獲取緩存行的修改權（獨佔），MESI 協議用來保證多核緩存的一致性，更多的細節可以參考 MESI 的文章。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假設線程 1 運行在 Core1，線程 2 運行在 Core2。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;因為 shm 被線程 1 和線程 2 這兩個線程併發訪問，所以 shm 的內存數據會以 Cache Line 粒度，被同時加載到 2 個 Core 的 Cache，因為被多核共享，所以該 Cache Line 被標註為 Shared 狀態。&lt;/li&gt; 
 &lt;li&gt;假設線程 1 在 offset 為 64 的位置寫入了一個 8 字節的數據（sizeof(long)），要修改一個狀態為 Shared 的 Cache Line，Core1 會發送核間通信消息到 Core2，去拿到該 Cache Line 的獨佔權，在這之後，Core1 才能修改 Local Cache&lt;/li&gt; 
 &lt;li&gt;線程 1 執行完 shm_offset.fetch_add(sizeof(long)) 後，shm_offset 會增加到 72。&lt;/li&gt; 
 &lt;li&gt;這時候 Core2 上運行的線程 2 也會執行 shm_offset.fetch_add(sizeof(long))，它返回 72 並將 shm_offset 增加到 80。&lt;/li&gt; 
 &lt;li&gt;線程 2 接下來要修改 shm[72]的內存位置，因為 shm[64]和 shm[72]在一個 Cache Line，而這個 Cache Line 又被置為 Invalidate，所以，它需要從內存裏重新加載這一個 Cache Line，而在這之前，Core1 上的線程 1 需要把 Cache Line 沖刷到內存，這樣線程 2 才能加載最新的數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種交替執行模式，相當於 Core1 和 Core2 之間需要頻繁的發送核間消息，收到消息的 Core 的 Cache Line 被置為無效，並重新從內存里加載數據到 Cache，每次修改後都需要把 Cache 中的數據刷入內存，這相當於廢棄掉了 Cache，因為每次讀寫都直接跟內存打交道，Cache 的作用不復存在，這就是性能低下的原因。&lt;/p&gt; 
&lt;p&gt;這種多核多線程程序，因為併發讀寫同一個 Cache Line 的數據（臨近位置的內存數據），導致 Cache Line 的頻繁失效，內存的頻繁 Load/Store，從而導致性能急劇下降的現象叫偽共享，偽共享是性能殺手。&lt;/p&gt; 
&lt;h3&gt;3.4 另一個偽共享的例子&lt;/h3&gt; 
&lt;p&gt;假設線程 x 和 y，分別修改 Data 的 a 和 b 變量，如果被頻繁調用，也會出現性能低下的情況，怎麼規避呢？&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;struct Data {
    int a;
    int b;
} data; // global

void thread1() {
    data.a = 1;
}

void thread2() {
    data.b = 2;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;空間換時間&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;避免 Cache 偽共享導致性能下降的思路是用空間換時間，通過增加填充，讓 a 和 b 兩個變量分佈到不同的 Cache Line，這樣對 a 和 b 的修改就會作用於不同 Cache Line，就能避免 Cache 失效的問題。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;struct Data {
    int a;
    int padding[60];
    int b;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Linux kernel 中存在__cacheline_aligned_in_smp 宏定義用於解決 false sharing 問題。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#ifdef CONFIG_SMP
#define __cacheline_aligned_in_smp __cacheline_aligned
#else
#define __cacheline_aligned_in_smp
#endif

struct Data {
    int a;
    int b __cacheline_aligned_in_smp;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從上面的宏定義，可以看到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在多核系統裏，該宏定義是 __cacheline_aligned，也就是 Cache Line 的大小&lt;/li&gt; 
 &lt;li&gt;在單核系統裏，該宏定義是空的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4 小結&lt;/h2&gt; 
&lt;p&gt;pthread 接口提供的幾種同步原語如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b8c086ae944f0d4861f9b398c673c0e349572.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由於 linux 下線程和進程本質都是 LWP，那麼進程間通信使用的 IPC（管道、FIFO、消息隊列、信號量）線程間也可以使用，也可以達到相同的作用。 但是由於 IPC 資源在進程退出時不會清理（因為它是系統資源），因此不建議使用。&lt;/p&gt; 
&lt;p&gt;以下是一些非鎖但是也能實現線程安全或者部分線程安全的常見做法：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/43010f87d03c76ab29d444f3469875ac380936.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，上面很多做法都是採用了副本，儘量避免在 thread 中間共享數據。最快的同步就是沒同步（The fastest synchronization of all is the kind that never takes place），Share nothing is best。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;|&lt;/strong&gt; 在美團公眾號菜單欄對話框回覆【2023 年貨】、【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://p1.meituan.net/travelcube/b0364d579285ab22aa6235bd100d7c22178175.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%AC%E6%96%87%E7%B3%BB%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%87%BA%E5%93%81%EF%BC%8C%E8%91%97%E4%BD%9C%E6%9D%83%E5%BD%92%E5%B1%9E%E7%BE%8E%E5%9B%A2%E3%80%82%E6%AC%A2%E8%BF%8E%E5%87%BA%E4%BA%8E%E5%88%86%E4%BA%AB%E5%92%8C%E4%BA%A4%E6%B5%81%E7%AD%89%E9%9D%9E%E5%95%86%E4%B8%9A%E7%9B%AE%E7%9A%84%E8%BD%AC%E8%BD%BD%E6%88%96%E4%BD%BF%E7%94%A8%E6%9C%AC%E6%96%87%E5%86%85%E5%AE%B9%EF%BC%8C%E6%95%AC%E8%AF%B7%E6%B3%A8%E6%98%8E%E2%80%9C%E5%86%85%E5%AE%B9%E8%BD%AC%E8%BD%BD%E8%87%AA%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E2%80%9D%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82&quot; target=&quot;_blank&quot;&gt;本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明「內容轉載自美團技術團隊」。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 tech@meituan.com 申請授權。&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/meituantech/blog/11585606</link>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/11585606</guid>
            <pubDate>Mon, 22 Jul 2024 09:22:30 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>谷歌將於 2025 年徹底淘汰 goo.gl 短鏈服務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Google URL Shortener 是谷歌在 2009 年推出的一項長網址縮短服務，將長鏈接以 https://goog.gl/* 的形式輸出為更短的鏈接。2018 年，谷歌宣佈淘汰和過渡 Google URL Shortener 服務，轉而引導用戶使用 Firebase Dynamic Links (FDL)；此舉意味着其不再接受新的網址縮短服務，但會繼續為現有網址提供服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;時至今日，谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將於 2025 年徹底關閉 Google URL Shortener 服務。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「任何使用 Google URL Shortener 構建的 https://goo.gl/* 形式鏈接的開發人員都將受到影響，並且這些 URL 在 2025 年 8 月 25 日之後將不再返回響應。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為了幫助開發者跟蹤和過渡可能受影響的鏈接，從 2024 年 8 月 23 日開始，goo.gl 鏈接將開始為一定比例的現有鏈接顯示提示，在導航到原始目標頁面之前通知用戶該鏈接將在 2025 年 8 月 25 日之後不再受支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;314&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f582b660e075dbd05b28f5b23f7a2a5dcf2.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着時間的推移，有提示的相關鏈接百分比將會增加，直到關閉日期。一旦關閉，鏈接將簡單地返回 404 響應。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，這一提示頁面可能會對 goo.gl 鏈接的當前流程造成幹擾，譬如妨礙重定向流程或影響目標頁面中一些嵌入數據的顯示。因此，谷歌方面建議用戶儘快對 goo.gl 鏈接進行轉換；對於受影響的用戶，可在現有的 goo.gl 鏈接中添加查詢參數 「si=1」。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available</guid>
            <pubDate>Mon, 22 Jul 2024 08:28:21 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>大模型代碼助手下一步：探索智能問答，圖生代碼等場景</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;7 月 27 日，第 105 期 OSC 源創會即將在杭州舉辦，本次沙龍以【AI 編程革新研發效能】為主題，將深入探討 AI 編程助手背後的技術架構、在開發者羣體中的使用情況、以及它們在當前市場中的應用，並探討未來它們對軟件開發領域的影響和改變。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;在活動正式開始前，我們邀請到本次活動的講師之一，螞蟻 CodeFuse IDE 插件技術負責人肖斌，提前為各位開發 er 們路透下螞蟻 CodeFuse 相關信息，對 CodeFuse 和 AI 編程感興趣的小夥伴們可以點擊鏈接，報名參與活動：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2332361&quot;&gt;&lt;span&gt;https://www.oschina.net/event/2332361&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3712eccd90d8cb09658750e8a1fbf500461.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;演講嘉賓：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;肖斌，螞蟻 CodeFuse IDE 插件技術負責人&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;演講議題：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;螞蟻代碼大模型落地實踐&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;議題簡介：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;本次演講從提升研發效能的場景出發，介紹基於大模型的螞蟻智能研發體系，闡述相關的技術方案和選型，以及在大模型落地上工程領域上的實踐及對應結果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：您是在什麼時候加入團隊的？為什麼看好這個方向？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2021 年加入團隊，一直從事軟件工程智能化方向的研究和探索，當下專注於代碼生成，AI 對話等方向,目前是 CodeFuse IDE 插件技術負責人。我認為大模型是未來研發領域的方向，人的精力是有限的，優秀的大模型，能學習到已有的知識，在日常工作中協同輔助研發人員，快速完成相關任務，同時幫助研發人員快速成長。未來甚至能自主的做一些簡單的研發任務。極大的提高整體研發效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：日常主要工作是什麼，目前的工作強度大嗎？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;統籌安排 CodeFuse IDE 插件中所有技術相關事項，主要精力會負責探索和調研 CodeFuse IDE 插件技術方案，並且深入參與到產品研發工作，保障產品效果。由於大模型還是處於快速發展的時期，這塊工作強度以及工作難度還是比較有挑戰性的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：幾乎每個大廠都結合&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;大模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;推出了代碼助手的產品，CodeFuse 有什麼特別之處？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;數據訓練上和螞蟻背景強結合，這一點是其他產品無法做到的。比如學習螞蟻內沉澱的優秀知識庫。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;產品能力上和螞蟻業務強結合，比如圖生代碼，以及對話和內網倉庫，內網部署平台結合&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;同時自研代碼助手也能保證數據安全&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：覺得目前 CodeFuse &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;IDE&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt; 插件做的最好的功能是哪個？為什麼？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;目前最好的是代碼補全，因為補全會在寫代碼過程中時時刻刻的輔助研發工作。是目前核心能力。但深入研究代碼補全技術同時，我們還探索其他方向，比如智能問答，圖生代碼等&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。相信在不久的將來，AI 能力會覆蓋研發領域各個階段，從整體上共同提高研發幸福感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：技術選型時有哪些標準和考量？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;重點考慮用戶體感，用戶體感從技術選型上有兩個方面，準確性和速度。比如代碼補全，補的不準確，或者補全速度慢，用戶體感肯定會下降，這樣的產品用戶不會滿意。所以針對準確性和速度上，我們做了大量的研究和探索，同時也產出了一些論文，可以共享給大家。技術方向有了一些階段性成果後，我們會首先進行一系列評測，通過評測後落到產品上進行 AB 實驗，基於 AB 實驗效果，推進技術演進方向。同時在產品層面也提高了用戶體感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：在實際應用中，CodeFuse 作為輔助開發的工具，表現是否符合預期？有沒有什麼意外的收穫或挑戰？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;表現是符合預期或者説超出預期，CodeFuse 較好的提升了螞蟻同學的研發效率，也獲取了螞蟻內部的科技創新獎。至於挑戰，創新的東西跳轉肯定是有的，特別是大模型相關的應用，模型幻覺，能力邊界等都是較大的挑戰，我們也在不斷通過技術手段去解決相關難題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：預計開發者能從這次演講中獲得哪些收益？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;瞭解代碼大模型發展方向，瞭解代碼大模型在螞蟻研發領域的落地&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/4489239/blog/12394403</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/12394403</guid>
            <pubDate>Mon, 22 Jul 2024 07:02:22 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>2028 年中國數據倉庫軟件市場規模將達 23.6 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國際數據公司（IDC）於近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.idc.com%2Fgetdoc.jsp%3FcontainerId%3DprCHC52446524&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;了《2023 年下半年中國數據倉庫軟件市場跟蹤報告》。數據顯示，2023 年中國數據倉庫軟件市場規模為 9.4 億美元，同比增長 7.8%。其中，本地部署數據倉庫軟件規模 4.8 億美元，同比增長 3.6%；公有云數據倉庫軟件規模 4.6 億美元，同比增長 12.6%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC DataSphere 預測，2023 年到 2028 年全球企業側的年產數據規模呈爆發增長態勢，到 2028 年數據規模將達到 317.1 ZB，2023-2028 年複合增長率為 30.2%，為未來數據倉庫的應用帶來了更廣泛的市場空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;到 2028 年，中國數據倉庫軟件市場規模將達到 23.6 億美元，2023-2028 的 5 年市場年複合增長率（CAGR）為 20.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;394&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6af1feb7b5d0e33d4a2fbbfb8b4042c616f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2023 下半年，中國數據倉庫&lt;strong style=&quot;color:#01010f&quot;&gt;本地部署模式&lt;/strong&gt;市場前 5 名廠商總計佔比 58.5%。出於數據安全和合規性的考慮，本地部署模式的數據倉庫產品仍將是金融、政府、能源、以及大型企業的首選。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#01010f&quot;&gt;2023 下半年中國數據倉庫本地部署模式市場廠商份額情況如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;與本地部署市場相比，&lt;strong style=&quot;color:#01010f&quot;&gt;公有云&lt;/strong&gt;數據倉庫服務的市場集中度更高，前五名廠商份額共計超過 90%。預計 2024 年，公有云數據倉庫市場規模將超過本地部署市場，到 2028 年，公有云數據倉庫市場佔比將達到 59.6%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;342&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5323455dd42ca486e2a971607c017150855.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#01010f&quot;&gt;2023 下半年中國數據倉庫公有云模式市場廠商份額情況如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;355&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-379638b33063e37971467912b2cc49102ee.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303300</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303300</guid>
            <pubDate>Mon, 22 Jul 2024 06:52:10 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>首輪嘉賓陣容公佈，GOTC 2024 即將開啓！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span&gt;8 月 15 日至 16 日，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://gotc.oschina.net/&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;GOTC 2024&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span&gt;將在上海張江科學會堂盛大開啓。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GOTC 2024 與上海浦東軟件園聯合舉辦，並結合 「GOTC（全球開源技術峯會）」 與 「GOGC（全球開源極客嘉年華）」，&lt;/span&gt;是一場面向全球開發者的全新的開源技術盛會。期間將舉行開幕式暨主論壇、高峯論壇、平行論壇、行業沙龍、青年黑客松等活動。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;本次大會聚焦數據基礎與&amp;nbsp;GenAI&amp;nbsp;開發範式、開源數據庫與 AI 協同創新、LLMOps 最佳實踐、硬核 AI 技術創新與實踐、雲原生與微服務架構以及開源人才與教育等主題。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;屆時，&lt;strong&gt;10&lt;strong&gt;0+&amp;nbsp;&lt;/strong&gt;&lt;/strong&gt;海內外深耕開源技術的行業領袖們將到場與開發者們分享他們的創新思考與未來實踐。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;首輪嘉賓陣容公佈！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;3676&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6a2894f8f7f2f0f9a1234290ba9dd4e314d.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 報名通道現已開啓，誠邀全球各技術領域開源愛好者共襄盛舉！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;參會報名，請訪問&lt;/strong&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F8762568606000%3Ftd%3D6895280870225&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;https://www.huodongxing.com/event/8762568606000?td=6895280870225&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 將於 8 月 15 日在上海張江科學會堂盛大開啓，為期兩天。GOTC 2024 與上海浦東軟件園聯合舉辦，並結合 「GOTC（全球開源技術峯會）」 與 「GOGC（全球開源極客嘉年華）」，旨在打造一場全新的開源盛會。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;全球開源技術峯會（Global Open-source Technology Conference，簡稱 GOTC）始於 2021 年，是面向全球開發者的開源技術盛會；2024 全球開源極客嘉年華（GOGC 2024）由浦東軟件園攜手 S 創共建，與開源中國、Linux 基金會等品牌聯合呈現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;img height=&quot;1081&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c757b3c3ae95b5ea402ba8821dca68b2297.jpg&quot; width=&quot;1921&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此次大會將集結全球範圍內對開源技術充滿熱情的開發者、社區成員、創業者、企業領袖、媒體人，以及各開源項目應用場景的產業精英、跨界才俊與年輕力量。通過主題演講、圓桌討論、創新集市、人才集市、黑客松、技術展示和互動工作坊等形式，與會者將有機會交流實踐經驗、探索前沿技術，讓我們一起激發創新活力、展示開源魅力、促進跨領域合作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更多大會信息，訪問官網查看：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;https://gotc.oschina.net&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/3859945/blog/12305454</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/12305454</guid>
            <pubDate>Mon, 22 Jul 2024 03:31:37 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>中共中央：完善生成式人工智能發展和管理機制</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;新華社受權發佈《中共中央關於進一步全面深化改革推進中國式現代化的決定》，其中提到要健全網絡綜合治理體系，深化網絡管理體制改革，整合網絡內容建設和管理職能，推進新聞宣傳和網絡輿論一體化管理。&lt;/p&gt; 
&lt;p&gt;完善生成式人工智能發展和管理機制，加強網絡空間法治建設，健全網絡生態治理長效機制，健全未成年人網絡保護工作體系。要加強網絡安全體制建設，建立人工智能安全監管制度。&lt;/p&gt; 
&lt;p&gt;此外，決定還提到要深化人才發展體制機制改革，實施更加積極、更加開放、更加有效的人才政策，完善人才自主培養機制，加快建設國家高水平人才高地和吸引集聚人才平台。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;322&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b4bdf54a7bf28e2c59d8f25158fa1d57055.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303254</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303254</guid>
            <pubDate>Mon, 22 Jul 2024 03:22:53 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>deepin 助力開源桌面生態：mesa LLVMpipe ORCJIT 上游化的台前幕後</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;383&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E4%B8%AD%E6%96%87.jpg&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;內容來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fmesa-llvmpipe-orcjit-deepin%2F&quot; target=&quot;_blank&quot;&gt;deepin（深度）社區&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;近日，mesa 開源圖形驅動合併了 llvmpipe 的 ORCJIT 後端的 Merge Request (MR)，並實現了對 riscv64 架構的支持。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;LLVMpipe 是什麼？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;LLVMpipe 是 mesa 驅動中的一種軟件渲染器，它不使用 GPU 硬件，而是利用 LLVM 中的 JIT 編譯器，動態地將待渲染的圖形相關代碼轉譯為柵格化的數據用於顯示，相對於 softpipe 而言性能更優。&lt;/p&gt; 
&lt;p&gt;飽受詬病的閉源驅動從始至終都是阻礙 riscv64 架構桌面生態的一大原罪，導致大部分 riscv64 架構的開發板的內置 GPU 完全或部分不可用，桌面發行版只能使用軟件渲染作為替代方案。&lt;/p&gt; 
&lt;p&gt;然而，在很長一段時間，mesa 的 LLVMpipe 使用的 JIT 後端是老舊的、缺乏架構支持的 MCJIT，而非更新的、架構支持更加廣泛的 ORCJIT。由於前者已經明確由後者替代接續，不再接受新的架構更新，這使得 mesa 在 riscv64 等架構上使用軟件渲染時只能使用性能更加低下的 softpipe，最終導致桌面環境幾乎無法使用，使得桌面生態遭受毀滅性的打擊。&lt;/p&gt; 
&lt;p&gt;正因如此，開源社區急切地渴望在 riscv64 架構上擁有一個更快的軟件渲染器。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;ORCJIT 的首次嘗試&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;時間推進到了 2022 年 7 月。一位 &lt;strong&gt;Alex Fan (@alexfanqi)&lt;/strong&gt; 的開發者提交了 MR 17801，為 mesa 引入了新的 ORCJIT 後端，同時還為其加上了 riscv64 支持，這使得在 riscv64 上使用 LLVMpipe 軟件渲染成為了可能。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;442&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d75b83b32cc4a37c03cdaa02cccad85d6a.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這個 MR 並沒有第一時間被合併，因為有開發者指出它沒有一個開關用以在編譯時切換後端、代碼不夠簡潔需要優化、缺少着色器緩存等問題，還需要進一步優化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從此開始，長達兩年的 LLVMpipe ORCJIT 後端合併的長跑開始了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2022 年 7 月，openEuler 社區的 RISC-V SIG 發現了這個 PR 並將其並集成，發佈了一篇文章介紹了它的性能提升效果。&lt;/p&gt; 
&lt;p&gt;然而，就在 riscv64 平台的開源桌面生態即將迎來曙光的時候，世事難料，隨着 mesa 開發分支的高速推進，原來的 Merge Request 缺乏維護，與主線的差異和衝突越來越大，漸漸的被淹沒在冗長的 MR 列表中，逐漸被人淡忘。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;社區的接力：開源軟件不滅的火種&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;2023 年 11 月，一位名為 &lt;strong&gt;Yukari Chiba (@YukariChiba)&lt;/strong&gt; 的開發者在維護自己的發行版時，遇到了同樣的問題。她受夠了大部分主線發行版在遇到這個問題時切換到 softpipe 的忍讓態度，決定着手解決這個問題。&lt;/p&gt; 
&lt;p&gt;被塵封在 MR 列表中的 patch，再一次化作熒幕上的光芒。&lt;/p&gt; 
&lt;p&gt;11 月 1 日，@YukariChiba 在某個羣組裏發佈了一張在飛騰派上以開啓了 ORCJIT 的主線 mesa 使用 LLVMpipe 運行 glxinfo 的截圖，並在次日發佈了一張在 PineTab-V 上使用 LLVMpipe 運行 glmark 的截圖。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ba864847edc700e94dbd1d6b7d899fea36.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;11 月 8 日，@YukariChiba 以相同的 ID，在 mesa 主線中重新提交了 MR 26018，旨在為主線版本 mesa 提供參考 patch 的同時，推進 mesa 主線的合併。&lt;/p&gt; 
&lt;p&gt;很快，deepin、ArchLinux RISC-V、AOSC OS 等發行版也先後使用了這一版 MR 的補丁，RISC-V 主線化的桌面體驗再一次達到了可用的狀態。&lt;/p&gt; 
&lt;p&gt;2024 年 4 月，Icenowy Zheng (@icenowy) 在 ORCJIT MR 的基礎上增加了着色器緩存和 loongarch 架構的支持，這意味着 ORCJIT 後端一旦合入，所有的主流桌面架構都能實現性能優異的 LLVMpipe 支持。&lt;/p&gt; 
&lt;p&gt;眾人拾柴火焰高，長風破浪會有時，LLVMpipe ORCJIT 這一突破性進展受到越來越多開發者的關注，合併進入主線逐漸被提上了日程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;MR 的接力衝刺和最終合併&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;6 月 19 日，有開發者評論：&lt;/p&gt; 
&lt;blockquote&gt;
 Is there anything outstanding that is preventing this from being merged into the main mesa branch?
&lt;/blockquote&gt; 
&lt;p&gt;而這打破了 MR 評論區的寧靜。在後續的 1 個月裏，社區貢獻者們對該 MR 提出了數十條修改意見；&lt;strong&gt;Dave Airlie (@airlied) &lt;/strong&gt;為幫助 ORCJIT 最終落地提交了數個前序修改和代碼結構優化；MR 提交者 &lt;strong&gt;@YukariChiba &lt;/strong&gt;根據修改意見對 MR 提交內容修改了數十個版本，並最終在 6 月 28 日提交了最終版本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最終，7 月 16 日，Merge Request 26018 完成了合併前 CI 檢查，被 mesa 主線合入，標誌這這一場由全球無數開發者參與、持續兩年的開源馬拉松圓滿落幕。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;633&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f2984bb91c944634d2ed91eee40e41cc153.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;deepin 的持續跟蹤與維護：幕後故事&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在 mesa 提交 MR 的這位 ID 稱作 &lt;strong&gt;@YukariChiba&lt;/strong&gt; 的開發者還有另外的身份：&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh&quot; target=&quot;_blank&quot;&gt;deepin（深度）開源社區&lt;/a&gt;的研發工程師，deepin-ports SIG 開發者，deepin RISC-V port 的維護者之一。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;deepin-ports SIG 在 2023 年成功將 RISC-V 的支持合併到了主線，同時也對主流的開發板進行了適配。與其它開源社區一樣，deepin 也飽受無法主線化、依賴閉源驅動組件的 GPU 圖形驅動的困擾，mesa 的 ORCJIT 後端支持此時無異於雪中送炭。&lt;/p&gt; 
&lt;p&gt;deepin 在 2023 年 12 月 6 日便對這一份更新的 patch 做了內部的打包驗證，並在 VisionFive2、LicheePi4A、SG2042 EVB 等開發板上做了實機驗證和性能測試。&lt;/p&gt; 
&lt;p&gt;次日，deepin 合併了此 MR 的 patch 到 mesa 主線倉庫，為 riscv64 架構默認打開了 ORCJIT 支持，並在後續所有的 riscv64 設備鏡像中啓用。&lt;/p&gt; 
&lt;p&gt;從 2023 年 11 月的初版補丁，直到 2024 年 7 月 16 日的最終合併，deepin 的 mesa 版本也相應的從 23.1.2 一路升級到了 24.1.0。在這過程中，deepin-ports SIG 積極適配新版 mesa 並刷新補丁，做到了在版本迭代的過程中補丁持續有效，助力了此特性的測試和維護，客觀上為 mesa 上游的最終合併提供了社區支持。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;606&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e00e91bf07071077d3537baa7cfe480c1cc.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在此期間，deepin 同時也超前引入了尚未合併、基於 ORCJIT 提交的 loongarch 支持補丁和着色器緩存補丁，為 deepin-ports 兩大架構 riscv64 和 loong64 提供了更高性能的軟件渲染，完善了 deepin 的桌面生態。&lt;/p&gt; 
&lt;p&gt;未來，deepin 還將繼續跟進 mesa 等開源軟件的上游更新和後續的性能優化，為完善 amd64/arm64/riscv64/loong64 四大架構的開源桌面體驗而不懈努力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;附錄：&lt;/h1&gt; 
&lt;p&gt;（1）deepin 全版本鏡像（含 deepin V15）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdistrowatch.com%2Findex.php%3Fdistribution%3Ddeepin&quot; target=&quot;_blank&quot;&gt;https://distrowatch.com/index.php?distribution=deepin&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;（2）deepin RISC-V 架構鏡像（LicheePi 4A、VisionFive 等）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdownload%2F&quot; target=&quot;_blank&quot;&gt;https://www.deepin.org/zh/download/&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303248</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303248</guid>
            <pubDate>Mon, 22 Jul 2024 02:41:53 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>「鴻蒙之父」王成錄計劃建立鴻蒙操作系統理論體繫系統</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;深圳開鴻數字產業發展有限公司 CEO 王成錄近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1936879191%2FOoqOxth61&quot; target=&quot;_blank&quot;&gt;發表微博&lt;/a&gt;，稱已收到哈爾濱工業大學博士研究生錄取通知書，專業為電子信息。他表示，將跟隨徐曉飛教授學習，計劃&lt;strong&gt;用三年時間把鴻蒙操作系統理論體繫系統全面建立起來&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1760&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0722/102746_fUay_2720166.png&quot; width=&quot;2800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;王成錄曾主導鴻蒙系統開發，也曾擔任華為終端 BG 軟件部總裁、華為消費者業務 AI 與智慧全場景業務部總裁。2022 年 5 月，王成錄正式從華為離職，就職深圳開鴻數字產業發展有限公司（簡稱 「深開鴻」），出任 CEO。&lt;/p&gt; 
&lt;p&gt;有網友在該微博的評論區留言詢問，「今年能買到鴻蒙 PC 嗎？」，王成錄回覆「會有的」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1070&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0722/103517_9RRL_2720166.png&quot; width=&quot;2360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;延伸閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/288918&quot; target=&quot;_blank&quot;&gt;王成錄：開源鴻蒙是我國基礎軟件領域唯一一次架構創新&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/256753&quot; target=&quot;_blank&quot;&gt;「鴻蒙之父」 王成錄：明年推出鴻蒙 PC 版系統&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303247</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303247</guid>
            <pubDate>Mon, 22 Jul 2024 02:37:13 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ZrLog 3.1 發佈，用更快的速度、更便捷的功能，讓你的記錄更生動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;還記得最初選擇寫博客的理由嗎？是希望用它來記錄生活中的點滴，在閒暇時翻閲，重溫過往的經歷，品味歲月的滋味，還是分享知識，記錄成長？&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;從 ZrLog 3.1 起支持本地部署，並配合 CDN 或 GitHub Pages 服務實現動靜結合，輕鬆實現無服務上雲（低成本上雲，僅需要域名費用），讓你的網站更加輕盈、快速。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;ZrLog 3.1 帶着滿滿的誠意和升級而來，它不僅在性能上有了顯著提升，更帶來了許多實用的功能改進，致力於為用戶提供更便捷、高效的寫作體驗，讓每個人都能更輕鬆地記錄生活，讓記憶更鮮活！&lt;/p&gt; 
 &lt;h4&gt;性能提升，速度飛躍&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;首次加載渲染優化&lt;/strong&gt;: 服務端直接插入頁面所需數據，大幅提升管理後台頁面首次加載速度&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;頁面緩存機制&lt;/strong&gt;: 管理後台頁面緩存機制，頁面切換更流暢，告別等待&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Simple Web Server 升級&lt;/strong&gt;: 降低內存佔用量，提升系統效率&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GraalVM Native 打包&lt;/strong&gt;: 將 Java 代碼編譯成原生可執行文件，啓動速度大幅提升，運行效率更高，佔用更少的內存資源，帶來流暢的寫作體驗&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;支持主流平台&lt;/strong&gt;: ZrLog 3.1 提供了 Windows、Linux 和 macOS (x86_64 和 Apple 芯片) 的直接可執行包，方便在各種設備上輕鬆使用 ZrLog&lt;/p&gt; 
 &lt;h4&gt;功能增強：更便捷更強大&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;寫作體驗更佳&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;PWA 支持&lt;/strong&gt;: 將博客寫作添加到桌面或 Dock 欄，隨時隨地開啓寫作之旅。 就算沒有網絡，也可以隨時隨地創作，靈感來了就寫，再也不怕錯過！&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;管理更便捷&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;zip 包在線更新升級&lt;/strong&gt;: 告別下載，在線更新更方便快捷，隨時擁有最新功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化管理後台用戶輸入參數校驗&lt;/strong&gt;: 提升安全性，避免錯誤輸入&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化網站設置內容&lt;/strong&gt;: 更便捷的博客管理體驗，輕鬆掌控博客的各個方面&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化管理後台側邊欄選中樣式&lt;/strong&gt;: 操作更清晰明瞭，更輕鬆地找到所需功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化登錄頁面排版&lt;/strong&gt;: 界面更美觀，體驗更友好，擁有更愉悅的寫作環境&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化常用插件配置首次加載&lt;/strong&gt;: 配置更快速，使用更便捷，更快地使用各種功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化管理後台無網絡情況下的提示方式&lt;/strong&gt;: 提升用戶體驗，在任何網絡環境下都能輕鬆使用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;PWA 模式下，記錄上次打開的頁面&lt;/strong&gt;: 方便繼續創作，提高效率，隨時回到上次寫作的位置&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;性能更優越&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;整站靜態化&lt;/strong&gt;: 徹底釋放閒置 VPS，配合阿里雲 CDN 或 Nginx 分流，提升網站速度，更快速地分享記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化 Github Action 緩存機制&lt;/strong&gt;: 提升構建速度，縮短 CI/CD 流程，讓博客始終保持最新狀態&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;插件更強大&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;插件中心優化&lt;/strong&gt;: 採用 CDN 無服務化，訪問更快更穩定，輕鬆找到需要的插件&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修復插件異步寫入流卡住問題&lt;/strong&gt;: 提升插件穩定性，確保記錄安全保存&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修復新版本插件下載完後跳轉問題&lt;/strong&gt;: 更便捷的插件安裝體驗，輕鬆使用新功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化數據庫備份插件備份邏輯&lt;/strong&gt;: 提升備份效率，更放心地保存記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化暢言插件配置&lt;/strong&gt;: 更易於配置，使用更便捷，更輕鬆地與讀者互動&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化插件頁面渲染加載等待&lt;/strong&gt;: 提升插件整體穩定性，確保流暢的使用體驗&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;新增 rss 插件&lt;/strong&gt;: 方便 RSS 訂閲博客內容，讓更多人看到記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化文章標籤選取&lt;/strong&gt;: 標籤選擇更便捷，管理更方便，更輕鬆地整理記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;備份數據庫插件的備份文件加密處理&lt;/strong&gt;: 提升備份安全性，更放心地保存記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;升級備份數據庫插件的 &lt;code&gt;mysqldump&lt;/code&gt; 版本&lt;/strong&gt;: 支持更新的數據庫版本，提升兼容性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;靜態化後生成的靜態站點支持同步更新到 git 倉庫&lt;/strong&gt;: 配合 pages 服務，輕鬆實現低成本的博客部署&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;添加文章分類重排插件&lt;/strong&gt;: 便於瀏覽，更直觀地管理文章&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;安全更可靠&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;數據庫備份優化&lt;/strong&gt;: 針對備份內容未變更情況，不再進行重複備份和上傳，節省資源，更放心地保存記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修復自動摘要重複截取問題&lt;/strong&gt;: 確保摘要準確，方便讀者快速瞭解記錄&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修復 3.0 版本的標籤敏感字符問題&lt;/strong&gt;: 提升標籤的兼容性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;支持配置 robots.txt 文件&lt;/strong&gt;: 更有效地控制搜索引擎爬蟲訪問，保護隱私&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;其他優化&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;可移除上傳的文章預覽頭圖&lt;/strong&gt;: 更靈活的圖片管理，更自由地選擇展示方式&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;管理後台顯示程序對磁盤的使用量&lt;/strong&gt;: 方便查看系統資源佔用情況，更瞭解系統狀況&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修復 3.0 版本的管理後台，在 Safari 上 Cookie 無法持久化的問題&lt;/strong&gt;: 提升瀏覽器兼容性，在不同瀏覽器上都能流暢使用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化管理界面的錯誤頁面&lt;/strong&gt;: 提升用戶體驗，更方便地解決問題&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;自動下載 docker 升級後丟失的主題&lt;/strong&gt;: Docker 模式更好用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;支持配置 favicon 圖標和 pwa 應用的圖標&lt;/strong&gt;: 個性化定製博客，讓記錄更有個性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化關於文章的 api 響應輸出&lt;/strong&gt;: 更便捷的接口調用，方便將記錄與其他平台連接&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;移除默認主題的 jquery 依賴&lt;/strong&gt;: 減輕頁面負擔，提升加載速度，更快速地訪問博客&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;優化默認主題在暗黑模式下的表格樣式&lt;/strong&gt;: 視覺體驗更舒適，更輕鬆地閲讀記錄&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr&gt; 
 &lt;p&gt;&lt;strong&gt;使用 PWA 模式下的，文章撰寫頁面空間更大，更專注&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;x&quot; src=&quot;https://oscimg.oschina.net/oscnet/20240722100902_197.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;全屏編輯狀態&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;x&quot; src=&quot;https://oscimg.oschina.net/oscnet/20240722100730_907.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;都看到這裏了，肯定感興趣了，趕快點下 star 收藏下，免得下次就找不到了&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitHub: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F94fzb%2Fzrlog&quot; target=&quot;_blank&quot;&gt;https://github.com/94fzb/zrlog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;碼雲: &lt;a href=&quot;https://gitee.com/94fzb/zrlog&quot;&gt;https://gitee.com/94fzb/zrlog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;程序主頁: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zrlog.com&quot; target=&quot;_blank&quot;&gt;https://www.zrlog.com&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SimpleWebServer: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F94fzb%2Fsimplewebserver&quot; target=&quot;_blank&quot;&gt;https://github.com/94fzb/simplewebserver&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;現在就訪問 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zrlog.com&quot; target=&quot;_blank&quot;&gt;官方網站&lt;/a&gt; 下載體驗 ZrLog 3.1 最新版本，感受性能與功能的全面升級，讓我們一起，用 ZrLog 記錄生活的點滴，用文字留住時光，讓回憶更生動！&lt;/p&gt; 
&lt;/div&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303246/zrlog-3-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303246/zrlog-3-1-released</guid>
            <pubDate>Mon, 22 Jul 2024 02:34:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>本週六，杭州源創會，聊聊 AI 編程</title>
            <description></description>
            <link>https://www.oschina.net/event/2332361</link>
            <guid isPermaLink="false">https://www.oschina.net/event/2332361</guid>
            <pubDate>Mon, 22 Jul 2024 02:04:58 GMT</pubDate>
        </item>
        <item>
            <title>微軟：850 萬台 Windows 設備受到 CrowdStrike 中斷影響</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微軟企業和操作系統安全副總裁 David Weston &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2024%2F07%2F20%2Fhelping-our-customers-through-the-crowdstrike-outage%2F&quot; target=&quot;_blank&quot;&gt;發文&lt;/a&gt;表示，大約有 850 萬台 Windows 設備受到了最近的 CrowdStrike 中斷的影響。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「雖然軟件更新偶爾會造成幹擾，但像 CrowdStrike 事件這樣的重大事件並不常見。我們目前估計，CrowdStrike 的更新影響了 850 萬台 Windows 設備，佔所有 Windows 機器的不到 1%。雖然這個比例很小，但廣泛的經濟和社會影響反映了運行許多關鍵服務的企業對 CrowdStrike 的使用。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;267&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc394b9cb0d0d35fc70ee8d22d8fff39ab5.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不過他並沒有透露安裝 CrowdStrike 軟件的 Windows 設備中受影響的百分比。雖然受影響的設備數量相對較少，但此次事故破壞範圍廣泛且遍佈全球，影響到了銀行、零售商、經紀公司、鐵路網絡等行業。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Weston 表示，該公司一直在與 CrowdStrike 合作解決問題，已經開發出了一種可擴展的解決方案，可幫助 Microsoft 的 Azure 基礎設施加速修復 CrowdStrike 的錯誤更新。同時，他們還在與亞馬遜網絡服務和谷歌雲平台合作以共同尋找最有效的方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「此次事件表明，我們廣泛的生態系統（全球雲提供商、軟件平台、安全供應商和其他軟件供應商以及客戶）具有相互聯繫的特性。這也提醒我們，對於整個技術生態系統中的所有人來説，使用現有機制優先考慮安全部署和災難恢復是多麼重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/302903/latest-crowdstrike-update-causes-blue-screen-of-death-on-windows&quot; target=&quot;_blank&quot;&gt;Crowdstrike 更新導致全球 Windows 大面積藍屏死機&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303145/8-5m-windows-devices-crowdstrike-outage</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303145/8-5m-windows-devices-crowdstrike-outage</guid>
            <pubDate>Sun, 21 Jul 2024 03:48:33 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>周鴻禕談為何微軟藍屏故障在中國少：90% 的電腦大多數用 360</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;360 創始人周鴻禕連發三條視頻，以日前發生的因 Crowdstrike 更新導致全球 Windows 大面積藍屏死機事件為主題，談論了國產安全軟件的重要性以及這場史上最大 IT 事故所帶來的啓發。&lt;/p&gt; 
&lt;p&gt;「這次的事件也再次展露了微軟在整個市場中的佔有率之高、覆蓋面之廣以及其系統崩潰所帶來的威力，不亞於在數字世界投下 100 萬顆原子彈。」&lt;/p&gt; 
&lt;p&gt;他指出，在因為 CrowdStrike 軟件出錯和微軟發生衝突導致藍屏、導致全世界很多基礎設施出問題之際，中國卻基本上沒有受到影響的原因在於：「中國 90% 的電腦上絕大多數企業殺毒軟件都用的是 360 殺毒和 360 安全衞士，我們有很大的優勢。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;479&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2f40e586308e5d08f4e73406a462eb80a0a.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;並補充到，360 有一個自動化的藍屏修復技術，在出現藍屏的時候只需重啓系統便可以快速恢復，不會影響到用戶的正常使用。360 安全軟件在全球範圍內有着豐富的實踐經驗，在安全性和穩定性上絕對經得起考驗，迄今沒有出過一起類似的安全事故。&lt;/p&gt; 
&lt;p&gt;同時，周鴻禕也認為，微軟此次的全球大面積藍屏事件給我們敲響了警鐘，我們國家的電腦網絡安全必須要掌握在自己手裏，電腦的殺毒軟件也一定要是國產品牌。這樣才能保證在數字化、智能化的時代，不會因為一個小 Bug、小更新或小小的攻擊導致整個社會、整個城市、整個國家陷入停擺。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303143</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303143</guid>
            <pubDate>Sun, 21 Jul 2024 03:11:46 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊雲發佈國產服務器操作系統 TencentOS Server V3</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2024 中國國際金融展上，騰訊雲副總裁胡利明發布了全新的騰訊雲國產服務器操作系統 TencentOS Server V3。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;胡利明介紹，TencentOS Server V3 具備安全可信、穩定高效等特性，並針對雲和 AI 場景做了眾多升級，極大提升了數據庫等軟件性能，以及 CPU、GPU 等資源的利用率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;279&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ccc0b70054e2a5da85f5f08b05daa0b6026.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TencentOS Server 是騰訊自主研發的企業級 Linux 服務器操作系統。在實踐方面，TencentOS Server V3 全面兼容主流的國產芯片服務器，支持建設了鯤鵬、海光和飛騰三大主流 CPU 超大規模的服務器集羣。目前 TencentOS Server 憑藉近 1000 萬套的部署規模成為國內部署量最大的 Linux 操作系統。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據介紹，此次發佈的 TencentOS Server V3 具備四大亮點：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;數據庫整體性能提升 30%，內存節省超過 15%&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在離線混部+能耗控制方案，大幅提升資源利用率&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;集成大模型推理加速框架，GPU 利用率提升 2 倍&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;CentOS 原地替換，重啓即生效，安全穩定&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303139</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303139</guid>
            <pubDate>Sun, 21 Jul 2024 02:42:46 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>開源 AI 和 ML 工具的安全風險日益增加</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Protect AI 最新發布的一份 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotectai.com%2Fthreat-research%2Fjuly-vulnerability-report&quot; target=&quot;_blank&quot;&gt;2024 年 7 月漏洞報告&lt;/a&gt;在各種大語言模型（LLM）中發現了 20 個嚴重漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這些漏洞是通過 Protect AI 的「huntr」漏洞賞金計劃發現的，這也是全球首個 AI/ML 漏洞賞金計劃。該社區由 15,000 多成員組成，在整個 OSS AI/ML 供應鏈中尋找有影響力的漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我們發現供應鏈中用於構建支持 AI 應用程序的機器學習模型的工具容易受到獨有的安全威脅。這些工具是開源的，每月被下載數千次以構建企業 AI 系統。它們還可能存在漏洞，這些漏洞可能直接導致完全的系統接管，例如未經身份驗證的遠程代碼執行或本地文件包含。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;397&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6b666b8b6b2712bc5cec516474555d6f60.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次報告的漏洞涉及了 ZenML、lollms 和 AnythingLLM 等廣泛使用的工具。ZenML 中的權限提升漏洞，未經授權的用戶可以通過發送精心設計的 HTTP 請求將其權限提升到服務器帳戶。可以通過修改請求負載中的 is_service_account 參數來利用此漏洞。利用此漏洞的攻擊者可能會破壞整個系統，導致未經授權的訪問和控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;lollms 中的本地文件包含 (LFI) 漏洞，允許攻擊者讀取或刪除服務器上的敏感文件，從而可能導致數據泄露或拒絕服務。該漏洞源於 lollms 中的 sanitize_path_from_endpoint 函數未正確處理 Windows-style paths，導致其容易受到目錄遍歷攻擊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AnythingLLM 中的路徑遍歷漏洞使得攻擊者可以讀取、刪除或覆蓋關鍵文件，包括應用程序的數據庫和配置文件。該漏洞位於 normalizePath() 函數中，可導致數據泄露、應用程序入侵或拒絕服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotectai.com%2Fthreat-research%2Fjuly-vulnerability-report&quot; target=&quot;_blank&quot;&gt;查看完整報告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303036/protect-ai-july-vulnerability-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303036/protect-ai-july-vulnerability-report</guid>
            <pubDate>Sat, 20 Jul 2024 03:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>@所有人，RWKV 中文官網正式上線啦！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;@所有人，RWKV 中文官網（www.rwkv.cn）正式上線啦！&lt;/p&gt; 
&lt;p&gt;在全新推出的 RWKV 中文官網，你可以查看&lt;strong&gt;關於 RWKV 的絕大多數信息&lt;/strong&gt;，包括但不限於 RWKV 架構的介紹、RWKV 多模態等研究和相關論文、RWKV 的本地部署和推理教程、RWKV 的全參/微調訓練教程，以及 RWKV 最新新聞動態...&lt;/p&gt; 
&lt;p&gt;RWKV 中文官網目前有四大板塊，分別是首頁、生態頁、資訊頁，以及 RWKV 中文文檔頁面，現在讓我們一起看看這些頁面都有什麼內容吧！&lt;/p&gt; 
&lt;h2&gt;官網首頁&lt;/h2&gt; 
&lt;p&gt;在官網首頁，你可以看到 RWKV 架構特性、RWKV 最新的模型版本和下載鏈接、RWKV 的 Uncheatable Eval 評分，以及基於 RWKV 的落地案例等信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1084&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f42fef551ad96af8a050d31a27e9bf03ad6.png&quot; width=&quot;2430&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;生態頁&lt;/h2&gt; 
&lt;p&gt;生態頁面則包含 RWKV 多模態等相關研究和論文、RWKV 的在線體驗 Demo、RWKV 的多模態模型，以及一些效果較好的 RWKV 社區微調模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1017&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b44edeb913197190de3ea56d88ce4dd80d.png&quot; width=&quot;1762&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;資訊頁&lt;/h2&gt; 
&lt;p&gt;在資訊頁可以查閲 RWKV 最新的動態新聞，包括 RWKV 近期發佈了哪些新模型或論文、RWKV 是否舉辦社區活動或參加外部活動，方便大家瞭解 RWKV 的最新動態。&lt;/p&gt; 
&lt;p&gt;此外，「技術博客」板塊會分享 RWKV 相關的技術內容，例如 RWKV 的微調、基於 RWKV 的新應用、新研究等內容。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1168&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca9d95ad241abb3c038caab27ed24e24693.png&quot; width=&quot;2133&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 中文文檔&lt;/h2&gt; 
&lt;p&gt;RWKV 官網的&lt;strong&gt;文檔頁&lt;/strong&gt;包含了 RWKV 的中文教程文檔，比如 RWKV 百科、RWKV 微調教程、RWKV Runner 和 Ai00 等 RWKV 本地部署工具的推理和 API 等教程。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4653e825e9ce0040b3e514b2c9f24ee60a3.png&quot; width=&quot;2418&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;小提示：文檔頁支持明亮模式和黑夜模式，可以點擊頁面左下方的菜單進行調整。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;p&gt;作為一個剛上線的站點，RWKV 中文官網肯定會有不足之處。如果您發現網站存在 Bug ，或者希望網站添加某個方向的 RWKV 相關內容，歡迎發生郵件到 「contact@rwkvos.com」 向我們反饋！&lt;/p&gt; 
&lt;p&gt;點擊下方的 「閲讀原文」 ，可以直達 RWKV 中文官網（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F%25EF%25BC%2589%25E3%2580%2582&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/）。&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302975</guid>
            <pubDate>Fri, 19 Jul 2024 10:56:45 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>開源日報 | 微軟藍屏波及全球；GPT-4o 迷你版；泡沫最大的半導體公司；GPU 獨孤求敗？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.19&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要聞&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302903/latest-crowdstrike-update-causes-blue-screen-of-death-on-windows&quot;&gt;Crowdstrike 更新導致全球 Windows 大面積藍屏死機&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;全球大量&amp;nbsp;&lt;/span&gt;Windows 用戶今天在更新 CrowdStrike 後遇到了藍屏死機 (BSOD) 錯誤。&lt;/span&gt;該問題似乎很普遍，影響運行不同 CrowdStrike 版本的機器。在社交媒體上，全球不同地區的用戶紛紛在抱怨這個突如其來的藍屏死機錯誤。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a6e7c309e7dde294b84a38e4898d503b6c2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302869/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules&quot;&gt;英偉達全面轉向開源 GPU 內核模塊&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;英偉達通過官方博客現在&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fzh-cn%2Fblog%2Fnvidia-transitions-fully-towards-open-source-gpu-kernel-modules%2F&quot; target=&quot;_blank&quot;&gt;正式宣佈&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，其開源內核模塊最終將取代閉源驅動 —— 目前正處於完全過渡到開源 GPU 內核模塊的時刻。在即將發佈的 R560 驅動版本中，他們將作出這一更改。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;藉助 R515 驅動程序，英偉達於 2022 年 5 月發佈了一套開源的&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.nvidia.cn%2Fzh-cn%2Fblog%2Fnvidia-releases-open-source-gpu-kernel-modules%2F&quot; target=&quot;_blank&quot;&gt;Linux GPU 內核&lt;/a&gt;模塊，該模塊採用雙許可證，即 GPL 和 MIT 許可。初始版本主要面向數據中心計算 GPU，而 GeForce 和工作站 GPU 則處於 Alpha 狀態。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;當時，他們宣佈在後續版本中將提供更可靠、功能齊全的 GeForce 和工作站 Linux 支持，&lt;strong&gt;NVIDIA 開放內核模塊最終將取代閉源驅動&lt;/strong&gt;。&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302856/openai-gpt-4o-mini&quot;&gt;OpenAI 發佈「小」模型 GPT-4o Mini&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GPT-4o mini GPT-4o mini 在 MMLU 上的得分為 82%，目前在 LMSYS 排行榜（在新窗口中打開）上的聊天偏好方面優於 GPT-4。它的價格為每百萬輸入代幣 15 美分，每百萬輸出代幣 60 美分，比以前的前沿模型便宜一個數量級，比 GPT-3.5 Turbo 便宜 60% 以上。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0719/101059_1rfr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GPT-4o mini 以其低成本和低延遲實現了廣泛的任務，如連鎖或並行多個模型調用（如調用多個 API）、向模型傳遞大量上下文（如完整代碼庫或對話歷史）或通過快速、實時文本回復與客戶交互（如客戶支持聊天機器人）的應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前，GPT-4o mini 的應用程序接口支持文本和視覺，未來還將支持文本、圖像、視頻和音頻輸入和輸出。該模型的上下文窗口可容納 128K 標記，每個請求最多支持 16K 輸出標記，知識庫可持續到 2023 年 10 月。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GPT-4o mini 現已作為文本和視覺模型提供給助手應用程序接口（Assistants API）、聊天完成應用程序接口（Chat Completions API）和批處理應用程序接口（Batch API）。在 ChatGPT 中，免費、Plus 和 Team 用戶從今天開始將能訪問 GPT-4o mini，以取代 GPT-3.5。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302881/deepseek-v2-0628-lmsys-leaderboard&quot;&gt;DeepSeek-V2 登上全球開源大模型榜首&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;美國時間 2024 年 7 月 16 日，LMSYS 組織的大模型競技場（Chatbot Arena）更新結果發佈，DeepSeek-V2-0628 超越 Llama3-70B、Qwen2-72B、Nemotron-4-340B、Gemma2-27B 等開源模型，登上全球開源模型榜首。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/291284&quot;&gt;DeepSeek-V2&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&amp;nbsp;是幻方量化旗下組織深度求索在今年 5 月份發佈的第二代開源 MoE 模型，其優勢包括：參數更多、能力更強、成本更低。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0719/113534_3J1h_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2652916941%2FOocMnslpi%23repost&quot; target=&quot;_blank&quot;&gt;2022 年 11 月開源，我們達到一個小小的里程碑：4000 star&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     2022 年 11 月開源，到現在也還沒滿兩年，我們達到一個小小的里程碑：4000 star，並且國內和海外對半開。這個過程沒有什麼奇技淫巧，我堅信老老實實做好產品和技術，老老實實去做好社區，這是一家以開源為本的公司的基礎。讓我開心的是，我們的獨立貢獻者有 70~80 個，大部分不是一些簡單的修正（當然，我們也非常歡迎），而是深度參與了一些 feature 的研發，由衷地表示感謝。#GreptimeDB#
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;zx-dennis&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1757693565%2FLDciEd1ps&quot; target=&quot;_blank&quot;&gt;從一個建築生成器變成了城市生成器&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p&gt;從去年開始，就看到大佬 Pavel Oliva 在推上頻繁地測試自己的建築生成器 Buildify，最近終於發佈了。沒想到的是，已經從一個建築生成器變成了城市生成器，還完美兼容知名開源地理插件 Blender OSM。而更沒想到的是，免費，可商用。&lt;/p&gt; 
     &lt;p&gt;▶ 下載地址：&lt;span style=&quot;background-color:#ffffff; color:#636363&quot;&gt;https://paveloliva.gumroad.com/l/buildify&lt;/span&gt;&lt;br&gt; ▶ 神仙作者：Pavel Oliva&amp;nbsp;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;Simon_阿文&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fawtmt.com%2Farticles%2F3719673&quot; target=&quot;_blank&quot;&gt;GPU，獨孤求敗?&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p&gt;據台媒報道，台積電近期準備開始生產英偉達最新 Blackwell 平台架構 GPU，同時因英偉達的客戶需求強勁，故此對台積電的晶圓訂單增加 25%；並有可能令本週放榜的台積電上調今年盈利預期。&lt;/p&gt; 
     &lt;p&gt;報道引述業界消息指出，亞馬遜、戴爾、谷歌、Meta 及微軟等都會使用 Blackwell 架構 GPU 來建立 AI 伺服器，令需求超出預期。&lt;/p&gt; 
     &lt;p&gt;英偉達的利好，讓大家對人工智能、GPU 和 AI 芯片有了更多的想法，但這能繼續持續嗎？&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- &lt;strong&gt;半導體行業觀察&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzODc0MjQwOA%3D%3D%26mid%3D2247506774%26idx%3D2%26sn%3D6061c04330c0d15652a3518132a486a3%26scene%3D0&quot; target=&quot;_blank&quot;&gt;史上最大泡沫的半導體公司&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;誰是全球最大泡沫的半導體公司？有人説是英偉達。&lt;/p&gt; 
  &lt;p&gt;但是，英偉達的動態估值只有 60 倍，以它仍然無懈可擊的 GPU 產品，以及壟斷市場的地位，你很難説這個估值高得離譜，何況，AI 未來是何等的星辰大海。&lt;/p&gt; 
  &lt;p&gt;更重要的是，英偉達完全能夠交得出業績，90% 的毛利率，50% 的淨利率，一年數百億美元的淨利潤，距離微軟的水平也不是很遙遠，你可以説英偉達的估值不便宜，但説是泡沫，似乎也不妥。&lt;/p&gt; 
  &lt;p&gt;如果對比另外一個半導體公司，英偉達的估值可以説低得可憐。因為那家半導體公司的動態 PE，是英偉達的 10 倍。不到一年時間，它的市值暴漲 4 倍，接近 2000 億美元。而一年的營收，在 30 億美元的水平，淨利潤只有區區 3 億美元，算下來，PE 接近 600 倍。&lt;/p&gt; 
  &lt;p&gt;這家公司叫 ARM。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;格隆匯&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FOobOXexSE&quot; target=&quot;_blank&quot;&gt;DeepSeek 剛剛發佈了他們最新的 DeepSeek-V2-0628&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;DeepSeek 剛剛發佈了他們最新的 DeepSeek-V2-0628，在 huggingface 已經可以下載了，但是這個非量化版本實在是太大了，達到了 236B, 按照官方的説法, 需要 8 塊 80G 的顯卡才能跑起來. 即使是 4bit 量化的版本 (由於剛發佈 3 小時, 還沒人去量化), 估計消費級硬件也只有 192G 的頂配 Apple M2 Ultra 可以試一試了. 好奇為啥不推出一款差不多 70b 的型號? 33b 的倒是有, 但是還沒更新。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;karminski-牙醫&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Ftech%2F2024-07-18%2Fdetail-inceqqcu6224066.d.html&quot; target=&quot;_blank&quot;&gt;摩爾線程萬卡 GPU 集羣新進展！性能可提升 20 倍&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩爾線程官方宣佈，與清華系 AI 系統軟件公司清程極智正式建立戰略合作關係，旨在加速國產大規模 GPU 智算集羣的產業化進程，推動 AI 算力生態的快速發展，為大模型行業提供更強大、靈活且高效的基礎設施支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;快科技&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.shangyexinzhi.com%2Farticle%2F21020999.html&quot; target=&quot;_blank&quot;&gt;中國市場手機 AI 用什麼大模型？三星增加了字節豆包，市場還在等待蘋果的答案&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;在一段時間的摸索和沉澱之後，各家 AI 手機的戰略輪廓逐漸變得更加清晰，廠商們在自研大模型之外，也陸續嘗試接入 AI 公司的通用大模型，比拼用戶體驗。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;藍鯨財經&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.app.dawuhanapp.com%2Fp%2F39348582.html&quot; target=&quot;_blank&quot;&gt;鴻蒙生態創新中心落地武漢，將重點做這些事——&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;鴻蒙生態（武漢）創新中心是繼深圳、成都之後，華中首個、全國第三個鴻蒙生態創新中心，是一個集技術服務、展示體驗、教育培訓、活動推廣等功能於一體的高水平公共服務平台。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;大武漢&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn807210882&quot; target=&quot;_blank&quot;&gt;4 年、230 億美元、創谷歌收購紀錄，這家公司怎麼做到的？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;在競爭激烈的市場中，Wiz 的賣點是「一站式平台」，提供雲工作負載保護（CWPP）、雲安全姿態管理（CSPM）、雲基礎設施權限管理（CIEM）等功能。同時，Wiz 還與許多其它初創公司合作，建立生態系統，提供靈活性。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;極客公園&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.cn%2Farticle_1750070171_684ff39b02001a8vo.html&quot; target=&quot;_blank&quot;&gt;GPT-4o 迷你版發佈，ChatGPT 殺死 ChatGPT&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#1a1a1a; text-align:justify&quot;&gt;自 2023 年下半年起，「落地」就成了 AI 圈內最常提及的話題。一個明顯的趨勢是，為了加快 AI 的落地，模型尺寸在變小，更輕量、更垂的模型不斷推出，模型變得越來也便宜。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;36 氪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Froll%2F2024-07-18%2Fdoc-inceqcpw8606444.shtml&quot; target=&quot;_blank&quot;&gt;中國電信星辰大模型首次落地手機終端&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國電信推出首款 AI 手機麥芒 30，搭載高通驍龍 695 處理器，內置中國電信自研的星辰大模型。據瞭解該手機可實現文案創作、圖像生成、智能問答、一鍵調用 AI 等功能。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;第一財經&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.cj.sina.com.cn%2Farticles%2Fview%2F5953466483%2F162dab07301901aam8&quot; target=&quot;_blank&quot;&gt;突破 CUDA 包圍圈，再出一招&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;為了突破 CUDA 護城河，現在已經有各種努力，比如 HIPIFY 幫助將 CUDA 源代碼轉換為適用於 AMD GPU 的可移植 C++ 代碼，然後是之前由 AMD 資助的 ZLUDA，允許 CUDA 二進制文件通過 CUDA 庫的直接替換在 AMD GPU 上運行。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;但現在又出現了一個新的競爭者：SCALE。SCALE 現已作為 GPGPU 工具鏈公開，允許 CUDA 程序在 AMD 圖形處理器上本地運行。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;半導體行業觀察&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenturns%2Fopenturns&quot; target=&quot;_blank&quot;&gt;openturns/openturns&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://static.oschina.net/uploads/space/2022/0309/162049_93U0_4252687.png&quot; width=&quot;450&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenturns%2Fopenturns&quot; target=&quot;_blank&quot;&gt;https://github.com/openturns/openturns&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;OpenTURNS 是一個 C++ 和 Python 庫，內置專用於處理不確定性數據的模型和算法。該庫的主要目標是提供處理工業應用研究中的不確定性所需的所有功能。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/4939618/blog/11209676&quot; target=&quot;_blank&quot;&gt;如何實現埋點日誌精準監控&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;日誌中台承載了百度千億量級 PV 的埋點流量，如何對這些流量進行準確監控，並支持個性化字段的抽取、下鑽，是日誌中台的一大難題。本文簡單介紹了日誌中台的基本概念及實時流架構，並基於此深入講解了低成本實現可擴展、高準確度的埋點監控的技術方案。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;圖片&quot; height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1fd9e4039010395c4724a35238f95ae75a0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用戶觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-e6qyQaUxaKZDJ5LRiQ5Qg&quot; target=&quot;_blank&quot;&gt;Crowdstrike 更新導致全球 Windows 大面積藍屏死機&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：信息安全廠商 CrowdStrike 的一款產品在更新後，眾多運行 Windows 的電腦瞬間成廢磚。CrowdStrike 的首席威脅獵人 Brody Nisbet 已確認了這個問題，並在 X 上發佈了以下內容： 存在一個有錯誤的通道文件，所以不是完全意義上的正確更新。有一種解決方法：1、引導 Windows 進入安全模式或 WRE。2、進入 C:\Windows\System32\drivers\CrowdStrike。3、找到並刪除匹配「C-00000291*.sys」的文件。4. 正常啓動。他在後來的另一個帖子中寫道：「這個解決方法並不能幫助所有人，不過我目前也沒有進一步可付諸實踐的方法可以幫助用戶。」&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：睡醒後，全公司都藍屏了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：夫妻雙雙把家還。幹不了活，回家了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：剛剛經歷藍屏，公司幾百台辦公筆記本電腦一台接一台藍屏。在家辦公的也未能倖免。起初還以為是公司網絡故障導致的。工作的激情戛然而止，公司一下子熱鬧起來。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：為了給中國的牛馬休息，微軟他，我哭死！&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：哭錯墳了兄弟，這不是微軟的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：這是上公有云的優點之一&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：網管：重啓，或者換台電腦，試試！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：Linux 用戶前來吃瓜&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：我説今兒為啥 OneDrive 提示「很抱歉，OneDrive 服務器出現問題 -- (錯誤代碼: 0x8004def5)」&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 11：這是另外一個問題&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 12：我用 MAC 別和我聊這個話題&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 13：有個問題，藍屏了，想截屏發個朋友圈該怎麼截？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 14：用門鎖拍，拍完記得還回去&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 15：重命名一下文件就行，別忘了 sudo 提權&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/302720/google-now-defaults-to-not-indexing-your-content&quot; target=&quot;_blank&quot;&gt;Google 搜索引擎默認不再索引新內容&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：本身是消費端【找內容】的主場景，已經變成生產端【內容曝光】的主場景。搜索領域的「推薦算法、信息流」該革新了，不管是個性化還是非個性化方向。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：感覺就是從年初開始，google 的搜索質量確實越來越差了，無論是中文英文&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：翻譯一下： 你們產出的垃圾內容太多了，我們的服務器不夠用了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：不索引新內容如何發現新「獨角獸」呢？這樣會加強既得勢者的壟斷，保護了壟斷者，拒絕了新創新者。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/302713/deepin-m1-updates-to-rc2&quot; target=&quot;_blank&quot;&gt;新進展！deepin M1 項目更新至 deepin V23 RC2 版本&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：一堆 bug 沒解決去適配 mac&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：你可以自己動手解決 bug，也可以多捐錢加快 bug 處理速度， 不要一邊吃飯一邊罵廚子&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：Fedora 適配好幾年了，驅動拷過來就行了，這還值得寫一下？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：deepin 底層是 ubuntu，他可適配不了 centos&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：v23 rc2 是真的難用，各種 bug 多的要死&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fa2aARBU7HLvlPNGJv9Uu_Q&quot; target=&quot;_blank&quot;&gt;編程高手如何給代碼「下毒」？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：直接代碼裏暗度陳倉，留點小祕密，被優化後，到黑市上以另一個身份，販賣個好價錢，一石二鳥，既給自己創收，又讓壓力到了對方那邊。並且這鍋到時候也不用你背，頂多算 bug&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：話説，你不刪都崩潰的代碼，為什麼要多此一舉，給公司創造利益。我的意思是，刪代碼，公司起訴你，找你索賠這種方式創造利潤。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：沒事，正常寫也是屎山，無需刻意&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：寫成廢碼，説得好像請你回來，你能維護一樣，搞笑&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：程序員何苦為難程序員，老闆哪會關心代碼怎麼寫的，有問題背鍋的是下一個程序員，怎麼實現我不管，限你今天就搞定&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：數據清洗技術，代碼質量評分，AI 優先淘汰廢碼程序員&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：如果 AI 給代碼埋雷沒有任何人會知道&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：每天一條辭職小技巧&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：打工人互害&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：公司也學會防禦性審核，一旦發現防禦性代碼，立即開除而且無需補償&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 11：代碼進分支不會審查嗎？不能隨便什麼代碼都進&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 12：情緒化嚴重的碼農，泄憤都未必代表事情的經過他是對的，有可能是唯心主義者&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 13：你這樣敲碼的話，有沒有一種可能，沒等公司把你辭退，你就率先因為看不懂自己上個月寫的代碼而提桶跑路了？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 14：過於憤世嫉俗了哇，人人微笑，微笑人人！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 15：連代碼審核都不做的公司，跑就跑了，還弄這麼多花花腸子&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最後，歡迎掃碼下載「開源中國 APP」，閲讀海量技術報告、程序員極客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302974</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302974</guid>
            <pubDate>Fri, 19 Jul 2024 10:53:45 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV-6-World 14B 正式開源發佈，迄今最強的稠密純 RNN 大語言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2024 年 7 月 19 日，RWKV 開源基金會宣佈正式向全球開源 &lt;strong&gt;RWKV-6-World-14B&lt;/strong&gt; 模型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV-6-World-14B 是迄今最強的稠密純 RNN 大語言模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在最新的性能測試中， RWKV-6-World 14B 模型英語性能相當於 Llama2 13b。此外，在同參數的模型評測中，RWKV-6-World 14B 的&lt;strong&gt;多語言性能顯著最強&lt;/strong&gt;，且&lt;strong&gt;支持全球 100+種語言和代碼&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在「無法作弊的模型評測」 Uncheatable Eval 排行榜中，RWKV-6-World 14B 的綜合評測分數比 llama2 和 Qwen1.5 更強。&lt;/p&gt; 
&lt;h2&gt;評測數據&lt;/h2&gt; 
&lt;p&gt;本次模型基準測試涵蓋了 &lt;strong&gt;4&lt;/strong&gt; 款接近 &lt;strong&gt;14B&lt;/strong&gt; 參數規模的開源大語言模型。&lt;/p&gt; 
&lt;p&gt;在測試中，英語的性能測試將通過 12 個獨立的基準測試來衡量大模型在常識推理和世界知識等英語內容上的表現。&lt;/p&gt; 
&lt;p&gt;多語言能力的評估中，則採用了 xLAMBDA、xStoryCloze、 xWinograd 和 xCopa 四種基準測試，深度探索了評估模型在多語言環境中的邏輯推理、故事理解、歧義解決和因果推理能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8cb336e733632131a25421ba02f04a29a7c.png&quot; width=&quot;1773&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由於 RWKV-5 系列模型最大隻有 7B 參數，我們選擇了 RWKV-4 14B 模型作為縱向對比。&lt;/p&gt; 
&lt;p&gt;可以看到，相比於此前發佈的 RWKV-4 14B 模型，RWKV-6-World 14B 的&lt;strong&gt;英文&lt;/strong&gt;性能和&lt;strong&gt;多語言&lt;/strong&gt;性能都獲得巨大提升。&lt;/p&gt; 
&lt;p&gt;RWKV-6-World-14B 模型的性能改進，大大得益於從 RWKV-4 到 RWKV-6 的架構改進，有關 RWKV-6 架構的優化細節，請參考文章：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBP0zlW2MT50gt3QpNjFwqQ&quot; target=&quot;_blank&quot;&gt;RWKV-6 論文到底説了什麼？分享會回顧來啦！&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;不作弊的 RWKV 模型&lt;/h2&gt; 
&lt;p&gt;值得強調的是，我們在訓練 RWKV 模型時，並未加入任何基準測試的數據集。換言之，我們沒有為了獲取更佳的評分結果而進行&lt;strong&gt;特殊優化&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;RWKV 不刷榜也不刷星，因此 RWKV 模型的實際能力比它的各種評分排行更強。&lt;/p&gt; 
&lt;p&gt;既然承諾不作弊，我們也第一時間對 RWKV-6-World-14B 模型進行了 &amp;nbsp;「無法作弊的模型評測」 —— &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval&quot; target=&quot;_blank&quot;&gt;Uncheatable Eval&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Uncheatable Eval 會使用最新的 arXiv 論文和新聞文章等&lt;strong&gt;實時語料庫&lt;/strong&gt;，以此來評估語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;有關 Uncheatable Eval 的詳細介紹，可參見此文章：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FifsgWchvSow9JU2tNMvJZA&quot; target=&quot;_blank&quot;&gt;RWKV 在「不可作弊的模型評測」中獲得良好成績&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-6-World 14B 的 Uncheatable Eval 評測&lt;/h3&gt; 
&lt;p&gt;此次 Uncheatable Eval 評測選取了常見的 &lt;strong&gt;5&lt;/strong&gt; 款開源 &lt;strong&gt;14B&lt;/strong&gt; 參數模型，測評數據則選擇 &lt;strong&gt;7 月最新發布&lt;/strong&gt;的 arXiv 論文、新聞、ao3 小説和 GitHub 代碼等實時數據。&lt;/p&gt; 
&lt;p&gt;具體評分和綜合排名如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-625a8beb483bb9abdb043140d406a9e3837.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，RWKV-6-World 14B 在此次測試中排行&lt;strong&gt;第 2&lt;/strong&gt;，&lt;strong&gt;綜合評測分數比相同尺寸的 llama2 和 Qwen1.5 更強。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;而 Mistral 最新發布的 12B 模型使用了比 RWKV-6 多幾倍的數據，它的性能更強。我們會繼續為 RWKV 模型補充優質數據，與它看齊。&lt;/p&gt; 
&lt;h2&gt;模型下載和體驗&lt;/h2&gt; 
&lt;p&gt;目前 RWKV-6-World 14B 模型還沒有在線 Demo，可以從以下平台下載 RWKV-6-World 14B 模型並&lt;strong&gt;本地部署&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-6-world%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv-6-world/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ModelScope：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv-6-world%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/rwkv-6-world/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRwkv-6-world%2Ffile&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/Rwkv-6-world/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;由於 Ai00 只支持 safetensor（&lt;code&gt;.st&lt;/code&gt;）格式的模型，如果你打算使用 Ai00 體驗 RWKV-6-World 14B 模型 ，可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcgisky%2Fai00_rwkv_x060%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;Ai00 HF 倉庫&lt;/a&gt;中下載&lt;strong&gt;已經轉成 .st 格式的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;本地部署 14B 模型的顯存需求&lt;/h3&gt; 
&lt;p&gt;如果你計劃本地部署並推理 RWKV-6-World 14B 模型，參考的 VRAM （顯存）消耗如下：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;量化方式&lt;/th&gt; 
   &lt;th&gt;顯存參考&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fp16&lt;/td&gt; 
   &lt;td&gt;約 28G&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;int8 -量化 56 層&lt;/td&gt; 
   &lt;td&gt;約 15G&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nf4 - 量化 56 層&lt;/td&gt; 
   &lt;td&gt;約 10G&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;新模型效果預覽&lt;/h2&gt; 
&lt;p&gt;以下為 RWKV-6-World 14B 模型的實測效果：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以下案例使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Fai00%2FIntroduction&quot; target=&quot;_blank&quot;&gt;Ai00&lt;/a&gt; 作為推理服務器，int8 + 30 層量化，未加載任何 State&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;自然語言處理（情感分析）&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;1773&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-09c6e1bc589e25f4503b2ba238ac602cee7.png&quot; width=&quot;1733&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;自然語言處理（機器閲讀理解）&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;831&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9c45d572025904359c754576f9ddd9b3fce.png&quot; width=&quot;1727&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;散文詩文學創作&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;1146&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-733fa5608aa98d12f1043dd5352c18eecb5.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;閲讀並修改一段代碼&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/0f0618be-7598-4374-8b81-70b601f3271b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;2432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5e30b9e87d6fce96bc82df6bf088c58ee3b.png&quot; width=&quot;1736&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;金融學論文選題建議&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/36151cd5-ec32-4e29-94f0-d7b9512f1b42.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;1063&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1e79ff8414e6d3456e4d3dfca3d659247c7.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;提取新聞關鍵內容&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/9a53eae3-286d-4e83-8010-befa1d951573.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;1327&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e2e7e991aa7788cf6856676af1cbd414a6d.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;一句話擴寫文本&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;931&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ff3cbe5b93dc1a7591e0bf07e2f824aea85.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;python 編程貪吃蛇小遊戲&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;3803&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-969c48a5a664382fed965153e98ef11eeb0.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/870e8170-9810-4a99-9a97-6b3a71ce04fd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意：目前開源發佈的所有 RWKV 模型均為基底模型。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基底模型具備一定的指令和對話能力，但為了保持其通用性和泛化能力，基底模型未進行任何對齊，也未針對某一類任務做優化。因此，&lt;strong&gt;基底模型在特定任務上的表現並不代表 RWKV 模型最優水準。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果希望 RWKV 模型在某種類型的任務上表現良好且穩定，建議使用此類任務的數據集對 RWKV 模型進行微調訓練。&lt;/p&gt; 
&lt;p&gt;目前我們已經發布了一些 RWKV 基底模型對特定任務進行微調訓練的教程，詳情可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2FRWKV-Fine-Tuning%2FIntroduction&quot; target=&quot;_blank&quot;&gt;RWKV 中文文檔 - RWKV 微調教程&lt;/a&gt; 中查看。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;隨着 RWKV-6 架構發佈 14B 模型，&lt;strong&gt;RWKV-7 架構的測試工作也在緊密地進行中&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 社區近期有很多新的研究，比如首個基於 RWKV 的醫學圖像修復模型 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2407.11087&quot; target=&quot;_blank&quot;&gt;Restore-RWKV&lt;/a&gt; 、海外社區做的 RWKV + Attention 混合架構 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2407.12077&quot; target=&quot;_blank&quot;&gt;GoldFinch &lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;我們很快會帶來更多 RWKV-7 的消息，敬請關注「RWKV 元始智能」公眾號，以在第一時間獲取 RWKV 最新動態。&lt;/p&gt; 
&lt;h2&gt;RWKV 模型介紹&lt;/h2&gt; 
&lt;p&gt;RWKV 是一種創新的深度學習網絡架構，它將 Transformer 與 RNN 各自的優點相結合，同時實現高度並行化訓練與高效推理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV 模型架構論文：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RWKV-4&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13048&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2305.13048&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RWKV-5/6（Eagle &amp;amp; Finch）：&lt;/strong&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.05892&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.05892&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入我們的 QQ 頻道和羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 中文官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QQ 頻道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302972</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302972</guid>
            <pubDate>Fri, 19 Jul 2024 10:49:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>發佈 「k8s 生態週報」 這件小事，他堅持了 5 年</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;8 月 15 日至 16 日，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://gotc.oschina.net/&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;GOTC 2024 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;將在上海張江科學會堂盛大開啓。雲原生技術專家、Kong 高級軟件工程師張晉濤將以「雲原生與微服務架構」論壇出品人的身份出席大會，並以《雲原生時代下企業流量治理的機遇和挑戰》為題發表演講。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這是張晉濤第二次參加 GOTC 大會。三年前參加首屆 GOTC 大會時，開源中國 OSCHINA 對他&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/question/4489239_2323127&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;進行了採訪&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，那時他還是 k8s ingress-nginx 項目的 reviewer，現在他已經是這個項目的 maintainer。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不變的是，他仍然專注於雲原生技術領域，為 Containerd、Docker、Helm、k8s、KIND 等眾多開源項目貢獻代碼。還有一件事，就是堅持更新「k8s 生態週報」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;587&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f41c9022be8ed6b3fadaf5d72fc65d461c6.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;雲原生技術專家、Kong Senior Software Engineer&amp;nbsp; 張晉濤&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2019 年 3 月 25 日，張晉濤發佈了第一篇《k8s 生態週報》，篇幅較短，不過百餘字。文中記錄着：Docker 6 週歲， 已一度成為容器技術的代名詞。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從那以後，張晉濤每週都會固定發佈一篇 k8s 生態領域的相關文章，持續了近五年。最後一篇是在去年年底，兩千多字，除了有 k8s v1.29 正式發佈的消息之外，還記錄着：在 Docker 十週年，Docker Inc. 收購了開發框架 Testcontainers 背後的公司 AtomicJar。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;他觀點鮮明：」Docker Inc. 只要保持住當前的勢頭繼續發展，應該還是可以有個不錯的發展的，畢竟 Docker 也確實是個生產力工具，用戶基數在那裏的。「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;348&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2be0c0bc76d5e0d43878e80a05eab2b86e.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這五年中，k8s 生態圈內大大小小的事，只要是張晉濤認為值得關注和推薦的內容，他都會記錄下來，加上自己的觀點，再發布出去。見解越來越多，篇幅也越來越長。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;張晉濤曾表示：「k8s 生態中相關信息和變化有很多，在這個信息爆炸的時代，稍不留神就會錯過很多有價值的信息，但持續地去追這些消息，也過於浪費時間，而且還需要去篩選信息。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《k8s 生態週報》的持續更新，讓他一直保持着對前沿技術的關注，能夠更好地把握前進的方向，不至於在技術更迭的浪潮中迷茫。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;身處其中，張晉濤對技術走向有着敏鋭的直覺。他曾預測，2022 年 k8s 的技術趨勢可能將圍繞安全性和 eBPF 展開。現在回過頭來看，不論是 2022 年 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Freports%2Fcncf-annual-survey-2022&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;CNCF 報告中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;凸顯的企業對安全性的關注，還是 L3AF 開源、cilium 在廠商中的落地和普及，都證明瞭事實確實如此。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;關於 k8s ，我們有很多問題想問他：哪些技術或趨勢在 2023 年變得尤為重要？今年又有什麼變化？這種變化對行業意味着什麼？未來幾年內 k8s 會朝哪個方向發展？來來看看張晉濤的答案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 k8s 領域，你認為哪些技術或趨勢在 2023 年變得尤為重要？今年 k8s 有什麼變化引起你的注意？這種變化對行業意味着什麼？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2023 年，安全性仍然是一個很重要的部分，加上也發生了很多相關的事件，這讓整個行業都對安全進行了更加廣泛的思考。其次就是，AI 技術持續火熱，幾乎所有廠商默認選擇將 k8s 作為標準的基礎設施，所以對於如何在 k8s 上進行 AI 的訓練和部署及 GPU 調度等，也是非常重要的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了 AI 和安全之外，今年 k8s 領域還清理了很多歷史遺留問題，對一些前幾年活躍但現在逐漸不維護的項目進行歸檔以及合併。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;這其實釋放了兩個信號：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;維護者團隊的新生力量不足，在進行開源項目的維護中，新生代力量很重要，但是對於已經存在幾年的項目而言，進入項目的門檻也在相應地提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;行業焦點正在從原先單純的 infra 逐步向上層遷移，以 k8s 為首的 infra 已經成為行業標準，所以後續對於 infra 只會更加聚焦和集中。接下來三到五年中，雲原生生態中不會再像前幾年那樣有大量新的項目呈井噴式出現，而是會將現有的項目推向行業標準。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基於你對 k8s 生態的理解，再次大膽地預測一下，未來幾年內 k8s 會朝哪個方向發展，以及有哪些潛在的挑戰和機遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前一個最為突出的方向就是與 AI 的集成。隨着 ChatGPT 等 AI 技術浪潮的到來，這一趨勢更加明顯。 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;挑戰的話，主要是兩個方面：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;k8s 最初並不是為 AI 或者説 GPU 調度誕生的，所以這些集成/擴展都是構築在現有的 k8s 之上的。但 k8s 還是很複雜的，有一些設計方面的挑戰需要解決。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GPU 廠商有很多，異構計算也是一個很主要的方向。尤其是在國內，要解決更多適配的問題，並且這些廠商可能並不能由開源社區的上游進行推動。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是機遇也很多的，因為現在這方面也屬於市場競爭的早期，同時無論是 infra 或者是相應的產品等，還在持續地創新和湧現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;您在 2023 年總結中提到，目前在 Kong Inc. 做 k8s 相關的事情，包括上游的 Gateway API、Kong k8s Ingress controller、Helm chart、Operator 等項目。這些都是與 k8s 生態緊密相關的開源項目。你對開源是怎麼看的？會如何影響你的日常工作？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;感謝開源。我很早就開始接觸開源，並且也一直在積極參與到開源項目和開源社區中。在這個過程中我學習到了很多，也認識了很多有趣的夥伴，我的職業發展其實也可以説是圍繞着開源展開的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Kong Inc. 是一家開源商業化公司，公司鼓勵大家參與到開源社區中，積極&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;地&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對開源項目作出貢獻。所以這並不會影響到我的日常工作。同時我們也是 k8s Gateway API 項目的活躍貢獻者和維護者，通過積極地和上游社區進行協作，也可以更好地讓我們的項目得到發展，達到雙贏的狀態。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你對 2024 年有哪些個人目標或期待？你希望在哪些方面取得進步？有什麼計劃去實施？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年已經過去一半，今年計劃排得&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;比較滿，所以鴿了一些文章，期待下半年我能更好地安排時間，恢復我的更新。同時，今年也在更加積極地活躍在 AI 領域，希望能將自己過往的一些 AI 經驗與現在的 LLM 及相關產品進行融合，發揮更大的價值。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;再次參加 GOTC 大會，併成為「雲原生與微服務架構」論壇的出品人，有什麼想對參會者説的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;歡迎大家來參加 GOTC 大會，這絕對是一場充滿乾貨的盛會！同時也是一個非常好的機會，可以和各行業的朋友們進行交流和麪基，瞭解大家現在在做什麼，有遇到哪些問題和解決問題的思路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同時「雲原生與微服務架構」場，非常歡迎對雲原生和微服務架構感興趣的朋友來圍觀，本次聚集了來自 AWS、華為、騰訊、AutoMQ、雲杉網絡等多個公司的新老朋友來分享大家來自生產實踐總結的經驗，相信一定能為大家帶來有價值的精彩分享！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;GOTC 2024 報名通道現已開啓，誠邀全球各技術領域開源愛好者共襄盛舉！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;參會報名，請訪問&lt;/strong&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F8762568606000%3Ftd%3D6895280870225&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;https://www.huodongxing.com/event/8762568606000?td=6895280870225&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 將於 8 月 15 日在上海張江科學會堂盛大開啓，為期兩天。GOTC 2024 與上海浦東軟件園聯合舉辦，並結合 「GOTC（全球開源技術峯會）」 與 「GOGC（全球開源極客嘉年華）」，旨在打造一場全新的開源盛會。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;全球開源技術峯會（Global Open-source Technology Conference，簡稱 GOTC）始於 2021 年，是面向全球開發者的開源技術盛會；2024 全球開源極客嘉年華（GOGC 2024）由浦東軟件園攜手 S 創共建，與開源中國、Linux 基金會等品牌聯合呈現。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;1081&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c757b3c3ae95b5ea402ba8821dca68b2297.jpg&quot; width=&quot;1921&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此次大會將集結全球範圍內對開源技術充滿熱情的開發者、社區成員、創業者、企業領袖、媒體人，以及各開源項目應用場景的產業精英、跨界才俊與年輕力量。通過主題演講、圓桌討論、創新集市、人才集市、黑客松、技術展示和互動工作坊等形式，與會者將有機會交流實踐經驗、探索前沿技術，讓我們一起激發創新活力、展示開源魅力、促進跨領域合作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更多大會信息，訪問官網查看：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;https://gotc.oschina.net&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/3859945/blog/11591606</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/11591606</guid>
            <pubDate>Fri, 19 Jul 2024 10:18:45 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>