<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Mon, 19 May 2025 03:30:07 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Rust 1.87.0 正式發佈 &amp; Rust 1.0 十週年紀念日</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月 15 日是 Rust 1.0 &lt;u&gt;&lt;a href="https://www.oschina.net/news/62486/rust-1-0-final"&gt;發佈&lt;/a&gt;&lt;/u&gt;十週年紀念日，Rust 項目開發者在荷蘭的 Utrecht 舉辦了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frustweek.org%2Fcelebration%2F" target="_blank"&gt;「Rust 十週年」&lt;/a&gt;慶祝活動，並在當天發佈&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.rust-lang.org%2F2025%2F05%2F15%2FRust-1.87.0%2F" target="_blank"&gt;新版本&amp;nbsp;1.87.0&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f95c0686e2cd287a0f1cb9b0d0723cd86ec.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版本的主要新特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;標準庫加入匿名管道（Anonymous Pipes）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;use std::io::Read;

let (mut recv, send) = std::io::pipe()?;

let mut command = Command::new("path/to/bin")
    // Both stdout and stderr will write to the same pipe, combining the two.
    .stdout(send.try_clone()?)
    .stderr(send)
    .spawn()?;

let mut output = Vec::new();
recv.read_to_end(&amp;amp;mut output)?;

// It's important that we read from the pipe before the process exits, to avoid
// filling the OS buffers if the program emits too much output.
assert!(command.wait()?.success());&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;安全架構 intrinsics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;#![forbid(unsafe_op_in_unsafe_fn)]

use std::arch::x86_64::*;

fn sum(slice: &amp;amp;[u32]) -&amp;gt; u32 {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx2") {
            // SAFETY: We have detected the feature is enabled at runtime,
            // so it's safe to call this function.
            return unsafe { sum_avx2(slice) };
        }
    }

    slice.iter().sum()
}

#[target_feature(enable = "avx2")]
#[cfg(target_arch = "x86_64")]
fn sum_avx2(slice: &amp;amp;[u32]) -&amp;gt; u32 {
    // SAFETY: __m256i and u32 have the same validity.
    let (prefix, middle, tail) = unsafe { slice.align_to::&amp;lt;__m256i&amp;gt;() };
    
    let mut sum = prefix.iter().sum::&amp;lt;u32&amp;gt;();
    sum += tail.iter().sum::&amp;lt;u32&amp;gt;();
    
    // Core loop is now fully safe code in 1.87, because the intrinsics require
    // matching target features (avx2) to the function definition.
    let mut base = _mm256_setzero_si256();
    for e in middle.iter() {
        base = _mm256_add_epi32(base, *e);
    }
    
    // SAFETY: __m256i and u32 have the same validity.
    let base: [u32; 8] = unsafe { std::mem::transmute(base) };
    sum += base.iter().sum::&amp;lt;u32&amp;gt;();
    
    sum
}&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過&lt;code&gt;asm!&lt;/code&gt;內聯彙編可跳轉到 Rust 代碼中的標記塊&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;unsafe {
    asm!(
        "jmp {}",
        label {
            println!("Jumped from asm!");
        }
    );
}&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;穩定 API 等等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;為慶祝 Rust 1.0 穩定版發佈十週年，Rust 作者 Graydon Hoare 寫了一篇&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frustfoundation.org%2Fmedia%2F10-years-of-stable-rust-an-infrastructure-story%2F" target="_blank"&gt;《10 Years of Stable Rust: An Infrastructure Story》&lt;/a&gt;&lt;/em&gt;長文進行回顧，他在文章提到了一組數據：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1.0 之前，Rust 代碼庫累計了 4 萬次提交；此後又新增了 24.6 萬次提交。換算下來，過去 10 年幾乎是每小時合併 2.8 次提交。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;貢獻者從 1.0 時不足 1000 人，擴展到現在約 6700 人。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;項目已關閉超過 4.7 萬個 issue，合併了 14 萬多個 PR。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;1.0 時共計約 1100 份 RFC（用於語言演進的提案），如今累計達到了 3772 份。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;發佈了 87 個正式版本，大多數都按六週節奏準時發佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推出過 3 個 Edition（版本變更打包，兼容舊代碼），用於引入需要 opt-in 的非兼容變更。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每個版本的兼容性測試範圍從 2500 個 crate 增長到了現在的 58.7 萬個。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350577/rust-1-87-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350577/rust-1-87-0</guid>
      <pubDate>Mon, 19 May 2025 03:27:07 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>張朝陽：如果晚生 30 年，自己也會捲入到 AI 裏面</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在最近召開的 2025 搜狐科技年度論壇上，搜狐創始人、董事局主席兼首席執行官張朝陽，與清華大學講席教授張亞勤及獵豹移動董事長兼 CEO 傅盛等三位不同領域人士，圍繞人工智能（AI）、人形機器人和腦科學等前沿科技展開了深入的討論。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-d1f6ff151f11d7f2624bff8dbdb8b1e473d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;張朝陽在討論中表示，&lt;strong&gt;如果晚生 30 年，自己也會捲入到 AI 裏面，包括人形機器人，腦科學&lt;/strong&gt;。他認為，目前正是一個比特與分子、原子交匯的時代，物理世界和生物世界的融合為年輕人提供了追逐新興風口的機會。在他的視角中，年輕人可以在這一時代中大膽嘗試，而年長者則更傾向於優化現有的商業模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在談及中美之間的 AI 差距時，傅盛強調了中國在工程化和應用創新方面的潛力，特別是在智能體等貼近實際應用的領域中，中國有望超越對手。張亞勤則指出，人才的積累是核心競爭力，並提到年輕人在人工智能領域的進展速度令人矚目，清華大學的相關研究成果是美國的五倍左右。他認為，人工智能最大的創新發生在過去五年，未來五年也將是一個關鍵期。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;張朝陽總結道，中國在 AI 和科技領域的競爭力源於人們的聰明才智和勤奮工作，加上龐大的人口基數，這種競爭環境推動了中國在各個科技領域的追趕與超越，包括芯片技術和算力問題的解決。他對中國在人工智能領域的未來充滿信心，認為我們正處於一個充滿機遇的時代。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350569</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350569</guid>
      <pubDate>Mon, 19 May 2025 02:53:40 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>StarRocks MCP Server 開源發佈：為 AI 應用提供強大分析中樞</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;過去，開發者要讓大模型（LLM）使用數據庫查詢數據，往往需要開發專屬插件、設計複雜的接口或手動構建 Prompt，這不僅費時費力，而且很難在不同模型之間複用。StarRocks MCP Server 提供了一個「通用適配器」接口，讓各種 LLM（如 Claude、OpenAI、Gemini）都能標準化地訪問 StarRocks，使得模型能夠直接執行 SQL 查詢並探索數據庫內容，無需複雜的配置或集成。&lt;/p&gt; 
&lt;p&gt;這意味着：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;無需開發專用 Agent 插件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型自動發現和調用 StarRocks 暴露的查詢/分析工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構建數據問答、智能分析、自動報表等應用變得更簡單&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;👉🏻 項目地址：https://github.com/StarRocks/mcp-server-starrocks&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;什麼是 MCP？&lt;/h2&gt; 
&lt;p&gt;首先，我們來瞭解什麼是 MCP。&lt;strong&gt;MCP（Model Context Protocol）&lt;/strong&gt; 是一種用於規範模型與上下文交互的通信協議，旨在標準化模型輸入輸出的數據結構、元信息傳遞及上下文管理機制。它通過定義統一的接口協議（如請求/響應格式、狀態跟蹤、多輪對話標識等），確保模型在複雜應用場景（如多模態交互、長上下文推理）中高效處理上下文依賴關係，同時支持動態上下文更新與歷史信息檢索。典型應用包括大語言模型（LLM）的對話系統、知識增強推理等。&lt;/p&gt; 
&lt;p&gt;通俗的來説，MCP 就像 AI 世界的「USB 接口」，它提供了一種通用標準，讓各種 AI 模型和智能代理（agents）能夠無縫連接、交換信息，就像 USB 讓不同品牌的設備（鼠標、鍵盤、硬盤等）都能即插即用一樣。通過 MCP，不同 AI 組件可以像樂高積木一樣自由組合，使 AI 變得更加智能、靈活和協作高效。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="719" src="https://oscimg.oschina.net/oscnet/up-90681374f708b3497f242a553ae2aa52a2a.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（MCP 架構示意圖）&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;MCP 核心組件&lt;/h2&gt; 
&lt;p&gt;MCP 的核心是一個簡單但強大的客户端-服務器架構，用於將語言模型與現實世界的功能連接起來。&lt;/p&gt; 
&lt;p&gt;你可以把它想象成一個智能家居中控系統：&lt;/p&gt; 
&lt;p&gt;MCP Host（宿主） = 智能助手（如小愛同學、Alexa）&lt;/p&gt; 
&lt;p&gt;MCP Client （客户端）= 控制中樞&lt;/p&gt; 
&lt;p&gt;MCP Server （服務器）= 各種設備（燈、空調、門鎖等）&lt;/p&gt; 
&lt;p&gt;你對智能助手説「打開空調」，你不需要知道空調的品牌、遙控器協議或者哪個網關。系統會通過統一協議找到正確的設備、下發正確的指令。在 MCP 裏，LLM 也是這樣發起一個請求，比如「獲取銷售報表」，Client 就會找到對應的數據源 Server，並返回數據。&lt;/p&gt; 
&lt;p&gt;這三大組件的作用如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Host：&lt;/strong&gt;基於 LLM 的應用程序，如 Claude Desktop 或未來集成 AI 的 IDE，用户通過它提出問題或發起操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Client：&lt;/strong&gt;處理連接邏輯。每個客户端與一個服務器建立連接，負責通信和協調。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Server：&lt;/strong&gt;暴露具體能力，如文件訪問、天氣 API 等。每個服務器通過標準接口提供一組特定的工具、資源或提示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCP Server 提供三類核心能力：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具（Tools）&lt;/strong&gt;：模型可以調用的可執行函數，如「獲取天氣預報」或「運行 shell 命令」。模型可自行決定何時使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;資源（Resources）&lt;/strong&gt;：如文件、日誌或 API 響應等。這些是模型可以讀取但不能修改的上下文信息。客户端負責決定何時展示哪些資源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞（Prompts）&lt;/strong&gt;：預設的模板，引導模型如何互動。例如生成提交信息、進行調試指導。通常由用户選擇，而非模型自行決定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP 功能介紹&lt;/h2&gt; 
&lt;p&gt;StarRocks MCP Server 充分利用了 MCP 的核心能力，為大語言模型提供了與 StarRocks 數據庫進行深度交互的強大工具集和豐富的上下文資源。具體來説，它實現了以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具 (Tools)&lt;/strong&gt;：這些是模型可以按需調用的「技能」，使其能夠主動與 StarRocks 交互：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;db_overview&lt;/code&gt;&lt;/strong&gt;：獲取指定數據庫中所有表的概覽信息。模型可以提供數據庫名（若未提供且配置了默認數據庫，則使用默認庫）。此工具會遍歷庫中所有表，併為每張表調用 &lt;code&gt;table_overview&lt;/code&gt; 的邏輯獲取其詳情。同樣支持緩存和強制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;table_overview&lt;/code&gt;&lt;/strong&gt;：快速獲取指定表的概覽信息。模型只需提供表名（可包含數據庫名，如 &lt;code&gt;db_name.table_name&lt;/code&gt;；若未指定數據庫名且配置了默認數據庫，則使用默認庫）。此工具會返回表的列定義 (&lt;code&gt;DESCRIBE table&lt;/code&gt;)、總行數 (&lt;code&gt;COUNT(*)&lt;/code&gt;) 以及少量樣本數據 (&lt;code&gt;SELECT * FROM table LIMIT 3&lt;/code&gt;)。為了提高效率，該信息會被緩存，並可通過 &lt;code&gt;refresh=true&lt;/code&gt; 參數強制刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;read_query&lt;/code&gt;&lt;/strong&gt;：執行只讀的 SQL 查詢（如 &lt;code&gt;SELECT&lt;/code&gt; 語句），並以 CSV 格式返回結果集，包含列名和數據行。這使得模型可以直接獲取和分析數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;write_query&lt;/code&gt;&lt;/strong&gt;：執行數據定義語言 (DDL) 或數據操作語言 (DML) 等寫操作，如 &lt;code&gt;CREATE TABLE&lt;/code&gt;, &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;，並返回操作結果（如影響行數、執行時間）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;query_and_plotly_chart&lt;/code&gt;&lt;/strong&gt;：一個強大的分析工具，它首先執行用户提供的 SQL 查詢從 StarRocks 獲取數據，然後利用該數據和用户指定的 Plotly Express 表達式（一個 Python 函數調用字符串）動態生成圖表。圖表最終以 Base64 編碼的圖片形式返回給模型，極大增強了數據洞察的可視化能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;資源 (Resources)&lt;/strong&gt;：這些是模型可以讀取的上下文信息，幫助模型理解 StarRocks 的結構和狀態：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///databases&lt;/code&gt;&lt;/strong&gt;：列出 StarRocks 集羣中的所有數據庫名稱。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/tables&lt;/code&gt;&lt;/strong&gt;：列出指定數據庫 (&lt;code&gt;{db}&lt;/code&gt;) 中的所有表名。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;starrocks:///{db}/{table}/schema&lt;/code&gt;&lt;/strong&gt;：獲取指定數據庫 (&lt;code&gt;{db}&lt;/code&gt;) 中特定表 (&lt;code&gt;{table}&lt;/code&gt;) 的創建語句 (&lt;code&gt;SHOW CREATE TABLE {db}.{table}&lt;/code&gt; 的結果），詳細展示表的結構信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;proc:///{+path}&lt;/code&gt;&lt;/strong&gt;：訪問 StarRocks 內部的 &lt;code&gt;/proc&lt;/code&gt; 路徑（如 &lt;code&gt;/proc/backends&lt;/code&gt;, &lt;code&gt;/proc/dbs/{db_id}&lt;/code&gt;），獲取集羣、節點、數據庫、表、事務、作業等詳細的運行時狀態和元數據信息，類似於 Linux 的 &lt;code&gt;/proc&lt;/code&gt; 文件系統。這為模型提供了深入瞭解 StarRocks 內部運作的窗口。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞 (Prompts)&lt;/strong&gt;：目前 StarRocks MCP Server 暫未定義特定的預設提示詞。MCP 的設計允許未來根據場景需求靈活添加，以更好地引導模型與 StarRocks 進行特定類型的交互。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;通過這些精心設計的工具和資源，StarRocks MCP Server 使大語言模型能夠像經驗豐富的數據分析師一樣，自主地探索數據、執行分析任務，並以多樣化的形式（文本、圖表）呈現結果，從而將 StarRocks 的強大 OLAP 能力無縫對接到 AI 應用中。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;StarRocks MCP Server 應用場景&lt;/h2&gt; 
&lt;p&gt;瞭解了什麼是 MCP 之後，來瞭解一下 StarRocks MCP Server 能應用在哪些場景中：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.實時數據分析與 AI 增強決策&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：讓 AI 模型（如 LLM）能夠實時查詢 StarRocks 中的業務數據，並結合歷史上下文生成更精準的分析報告或建議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;金融風控&lt;/strong&gt;：AI 結合 StarRocks 的實時交易數據，動態評估風險並生成預警。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;電商推薦&lt;/strong&gt;：基於用户實時行為（如瀏覽、加購）和 StarRocks 的 OLAP 分析，優化個性化推薦策略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.自動化數據報表與 BI 增強&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：通過 MCP 協議，讓 AI 自動生成 SQL 查詢、執行聚合計算，並返回可視化報表，減少人工幹預。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;廣告投放分析&lt;/strong&gt;：AI 自動查詢 StarRocks 的廣告曝光、點擊數據，生成優化建議。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;運營駕駛艙&lt;/strong&gt;：結合自然語言交互（如「顯示最近 7 天銷售額趨勢」），自動從 StarRocks 拉取數據並生成 Dashboard。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.複雜查詢的 AI 優化與加速&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：利用 MCP 管理查詢上下文，讓 AI 輔助優化 StarRocks 的多表 JOIN、聚合計算等複雜操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;用户畫像分析&lt;/strong&gt;：AI 自動構建 Roaring Bitmap 查詢，計算用户留存、漏斗分析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨業務分析&lt;/strong&gt;：AI 解析業務需求，自動生成高效 StarRocks SQL，避免全表掃描。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.統一數據湖與 AI 增強查詢&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;目標&lt;/strong&gt;：通過 MCP 讓 AI 同時訪問 StarRocks 和外部數據源（如 Hive、Elasticsearch），實現聯邦查詢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;混合分析&lt;/strong&gt;：AI 自動組合 StarRocks 的聚合數據和 Hive 的原始日誌，生成完整業務洞察。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知識增強&lt;/strong&gt;：AI 查詢 StarRocks 的業務數據 + 外部知識庫（如論文、行業報告），生成深度分析。&lt;/p&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;StarRocks x MCP 快速上手&lt;/h3&gt; 
&lt;p&gt;StarRocks 是首批通過內置 MCP Server 原生集成 MCP 協議的引擎之一。這使得 StarRocks 不再只是一個高性能查詢引擎，而是升級為一個專為智能 Agent 交互優化的分析執行環境。&lt;/p&gt; 
&lt;p&gt;這一切都構建在 StarRocks 現代化的執行引擎之上——向量化、高併發、C++ 編寫，自設計之初就面向低延遲和高併發場景。&lt;/p&gt; 
&lt;p&gt;通過將面向 Agent 的標準協議（MCP）與面向現代工作負載的執行引擎結合，StarRocks 為從探索到生產部署的 Agent 驅動分析工作流提供了直接路徑。你無需重新設計架構，就可以立即開始構建智能分析應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.部署 StarRocks 集羣，準備數據&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;部署 Starrocks 集羣，假設部署到本地 localhost

導入 quickstart 中的 crashdata 數據
https://docs.starrocks.io/docs/quick_start/shared-nothing/#new-york-city-crash-data

CREATE TABLE IF NOT EXISTS crashdata (
    CRASH_DATE DATETIME,
    BOROUGH STRING,
    ZIP_CODE STRING,
    LATITUDE INT,
    LONGITUDE INT,
    LOCATION STRING,
    ON_STREET_NAME STRING,
    CROSS_STREET_NAME STRING,
    OFF_STREET_NAME STRING,
    CONTRIBUTING_FACTOR_VEHICLE_1 STRING,
    CONTRIBUTING_FACTOR_VEHICLE_2 STRING,
    COLLISION_ID INT,
    VEHICLE_TYPE_CODE_1 STRING,
    VEHICLE_TYPE_CODE_2 STRING
);

curl --location-trusted -u root             \
    -T ./NYPD_Crash_Data.csv                \
    -H "label:crashdata-0"                  \
    -H "column_separator:,"                 \
    -H "skip_header:1"                      \
    -H "enclose:\""                         \
    -H "max_filter_ratio:1"                 \
    -H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i'),BOROUGH,ZIP_CODE,LATITUDE,LONGITUDE,LOCATION,ON_STREET_NAME,CROSS_STREET_NAME,OFF_STREET_NAME,NUMBER_OF_PERSONS_INJURED,NUMBER_OF_PERSONS_KILLED,NUMBER_OF_PEDESTRIANS_INJURED,NUMBER_OF_PEDESTRIANS_KILLED,NUMBER_OF_CYCLIST_INJURED,NUMBER_OF_CYCLIST_KILLED,NUMBER_OF_MOTORIST_INJURED,NUMBER_OF_MOTORIST_KILLED,CONTRIBUTING_FACTOR_VEHICLE_1,CONTRIBUTING_FACTOR_VEHICLE_2,CONTRIBUTING_FACTOR_VEHICLE_3,CONTRIBUTING_FACTOR_VEHICLE_4,CONTRIBUTING_FACTOR_VEHICLE_5,COLLISION_ID,VEHICLE_TYPE_CODE_1,VEHICLE_TYPE_CODE_2,VEHICLE_TYPE_CODE_3,VEHICLE_TYPE_CODE_4,VEHICLE_TYPE_CODE_5" \
    -XPUT http://localhost:8030/api/quickstart/crashdata/_stream_load
    &lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2.啓動 MCP Client&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2.1 配置客户端添加 mcp-server-starrocks，客户端使用的是 DeepChat&lt;/p&gt; 
&lt;p&gt;大家可以使用這個優化過的版本：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdecster%2Fdeepchat" target="_blank"&gt;https://github.com/decster/deepchat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-c56f1c9bcdcd53827339f3ed235c5884640.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-86469cacb7fd6f7c162e6ae3b9310861b86.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-27900bd2f64691dd1af2f7ae19b109d82a8.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.2 配置成功後在對話選項中可以添加使用 mcpserver&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="890" src="https://oscimg.oschina.net/oscnet/up-9c20710df0b7cb55fa3b54c2f22b6ba6fba.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;補充説明：在本次 Demo 中，我們使用的是 DeepChat 作為 MCP Client。除此之外，市面上還有如 Claude Desktop、Cline 等主流客户端，用户可根據個人偏好進行配置。需要注意的是，由於我們期望返回結果包含表格和圖片，部分客户端可能不支持圖片顯示，選擇時建議將此因素一併考慮。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Demo 演示&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下面的視頻中演示瞭如何以對話形式對 StarRocks 中的數據集進行可視化分析&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV195EizWEFT%2F%3Fvd_source%3D1cb452610138142d1300dd37a6162a88" target="_blank"&gt;https://www.bilibili.com/video/BV195EizWEFT/?vd_source=1cb452610138142d1300dd37a6162a88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;最後，我們總結一下 StarRocks MCP server 的核心價值：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;讓 AI 具備實時 OLAP 能力，減少人工 SQL 編寫和數據分析成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;增強決策智能，結合歷史數據和實時計算，提供更精準的業務建議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;統一數據訪問層，讓 AI 無縫對接結構化數據（StarRocks）與非結構化數據（文檔、日誌）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;未來，隨着 MCP 生態的擴展（如支持更多數據庫、BI 工具），這種結合將在，金融、電商、IoT、醫療，等領域發揮更大作用。StarRocks 的朋友們，快來開啓更多智能應用！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5658056/blog/18414667</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5658056/blog/18414667</guid>
      <pubDate>Mon, 19 May 2025 02:45:40 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>超擬人 AI 老師、因材施教 AI 輔導，大模型技術在教育中能做好哪些事？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="text-align:justify"&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;在生成式人工智能重塑各行業版圖的當下，教育領域也正經歷着一場靜水深流的技術變革。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;大模型不再只是實驗室裏的概念驗證，而是逐步滲透進作業批改、個性化輔導、學情分析等教育核心場景，推動着"千人千面"教育理想的落地。在這場技術與教育的雙向奔赴中，如何平衡技術創新與教育本質？如何讓 AI 真正成為教育公平的推進器而非技術泡沫？我們與深耕 AI 教育應用多年的專家丁小晶展開對話。作為百度小度教育技術負責人，他帶領團隊打造的 AI 教師系統已成為行業標杆，其團隊在教育大模型應用層面積累的實戰經驗與冷思考，或許能幫助我們更清晰地看到技術賦能教育的可行路徑。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;丁小晶 &lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;百度資深工程師/小度教育技術負責人/大模型應用技術專家&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;資深大模型 AI 應用技術專家與管理者，技術創新與項目管理的複合型人才，致力於 AI 大模型應用創新。碩士畢業於中國科學院計算技術研究所，從事高性能計算技術研究。先後在百度、三星等世界知名企業工作，並有多年旅日工作經歷。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;em&gt;&lt;em&gt;擁有超過 15 年的計算機及 AI 領域經驗、10 年 AI 及 5 年團隊管理經驗，精通大模型技術及多語言編程，屢獲榮譽，持多項專利。目前作為小度教育業務技術負責人，研究基於大模型 AI 教育產品創新，引領小度教育成為行業先鋒。&lt;/em&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;丁小晶、崔遠，編著《&lt;strong&gt;深度剖析 DeepSeek 大模型： 原理、開發與優化部署&lt;/strong&gt;》&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fitem.m.jd.com%2Fproduct%2F14401797.html" rel="nofollow" target="_blank"&gt;https://item.m.jd.com/product/14401797.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：目前大模型在教育領域的主要應用場景有哪些？能否結合具體案例説明其效果？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;目前大模型技術對教育行業進行深入重構，今年 4 月份的 2025 年教育裝備展上明顯能看到，教育從業公司都在往大模型應用方向轉型。個性化 AI 老師是一個主流趨勢。藉助大模型技術，可以實現個性化 1v1 的授業、答疑、解惑，大幅降低教育成本，解決教育資源分佈不均衡的問題。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;比如 AI 作業批改和 AI 講題答疑的效果提升，在目前的 AI 自習室行業已經大面積使用，通過 AI 老師逐步降低學生對真人老師的依賴，還可以培養自主學習的習慣，已經逐步在顛覆傳統教培行業。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：多模態技術在教育中的應用進展如何？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;多模態技術非常重要，甚至可以説，沒有多模態技術效果的快速提升，教育行業不可能如此迅猛發展。比如在前面提到的 AI 作業批改和 AI 講題答疑方向，完全靠純文本大模型是無法滿足需求的，非常依賴對大模型的圖片理解能力。還比如超擬人 AI 老師，語音情感大模型就起來非常關鍵的作用。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：大模型存在幻覺，在教育中，這是否會導致輸出一些錯誤知識，如錯誤公式推導等，如何避免這種情況，或者是否可以「自主糾錯機制」？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;確實目前即使最好的大模型也還會存在一定的幻覺，比如數學上的一些邏輯計算問題，解決大模型幻覺一直是教育行業的難點。但是在這方面我們還是做了很多創新，比如 SFT 微調、Prompt 約束、Fewshot 規範以及 Tools 校驗等技術手段，目前來看效果還是很不錯的，也獲得用户的認可。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：教育大模型需持續吸收新知識，但傳統微調易導致舊知識遺忘。在模型動態更新過程中，如何平衡知識擴展與核心能力穩定性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;這個確實是一個難點。我們自己的經驗來看，分兩個階段：24 年 Q4 之前，各家大模型的基座能力確實在教育垂類應用上，受限於沒有大量教育優質數據，無論是知識擴展和核心能力都還有欠缺，需要我們進行不斷 SFT。但是從 24 年 Q4 往後，特別是 DeepSeek 出來之後，大模型的基座能力提升非常明顯。我們對於微調的使用比較謹慎，更傾向於微調非核心能力，比如微調 AI 老師的講題範式，微調 AI 老師的擬人風格等。在知識擴展方面，我們更傾向於 Agent 架構思想，通過 RAG，More&amp;nbsp;Tools，MCP 等手段來擴展，而不是大模型的微調。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：基座大模型的很多訓練數據來自英語，可能導致文化偏見。在中文教育場景中，這是否會影響教育結果？是否有解決機制？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;我們沒有這方面問題。我們主要用的是百度文心大模型，很擅長中文。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：教育大模型是否解決傳統教育中的「因材施教」難題？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技術是解決傳統教育「因材施教」難題的最佳方法。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;首先，通過大模型能夠更加懂學生。我們的 AI 老師是覆蓋家庭教育全場景的，從薄弱項診斷、家長反饋、學習規劃到作業輔導，持續更新學生的學習情況。比如在智能作業批改場景，傳統 AI 只能判斷對錯，但是基於大模型我們現在能過做到歸因分析，每一步錯在哪裏都能診斷出來。例如是漏了題目條件，還是對基礎概念的理解有誤，都能診斷出來。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;其次，只有大模型才能實現真正的 1v1 教學。以為題目答疑為例，傳統 AI 對所有學生，都只能有文字解析，或者是一個講題視頻，讓學生去看，至於懂不懂，懂多少，那就不知道了。但是基於大模型技術的 AI 老師可以和學生進行交互，在交互中識別孩子們是否真的懂了，進而根據理解的多與少，可以調整講題思路，一步一步的引導，讓孩子真正的理解題目，而這都是傳統 AI 無法實現的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們做 AI 老師的初衷，就是為了能夠復刻名師，通過大模型技術，我們有機會，讓每個家庭、每個孩子都能有一個 AI 名師，即使是在偏遠貧困的山區，也能有一個清華北大的 AI 私教。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：當大模型能自動生成個性化習題、教案甚至虛擬實驗時，傳統教師的角色將如何演變？是轉型為「AI 訓練師」專注設計提示詞，還是強化人類獨有的元認知培養能力？這類變革對師範教育體系會產生何種衝擊？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;我和很多老師交流，他們都有這個焦慮。但是我感覺這個問題不僅僅是教育行業存在的，其他行業都會有，比如&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Midjourney&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;我們的 UI 工程師就很焦慮，還有 C&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;oursor&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;也讓很多程序員也很焦慮。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我可以談幾點我對這個問題的幾點思考：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;老師們也要快速擁抱大模型。大模型短時間內還是不會替代真人老師的，但是善於使用大模型工具的老師一定會更有競爭力，因為他們的效率更高。所以壓力不是來自於大模型，而是會使用大模型的同事們。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;對大模型來説，傳統的教育經驗是非常有價值的。目前所有的大模型都還是在復刻老師。復刻的方法都是在學習老師的教育經驗，沒有這些教育經驗，大模型還是難以替代真人的。我們目前遇到的一個難題是，如何將不同老師的個性化的教育經驗，抽象歸納成一套教育方法論，並且能數據化輸入給大模型，目前還很難，可能對一些懂大模型的老師是一個機會。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;真人老師除了傳道授業解惑之外，言傳身教會對學生人生觀、價值觀也會深深影響，畢竟人是有社會屬性的，這種面對面的情感價值，至少是目前的大模型技術還沒有辦法替代的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：作為小度教育的技術負責人，您帶領團隊做了哪些 AI 教育產品的創新？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;答：&lt;/strong&gt;大模型技術起來之前，我們小度教育就一直在做 AI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教育的創新，那個時候也是圍繞作業批改和講題答疑來做的，但是效果一直比較受限。隨着大模型技術的快速發展，我們的 AI 能力效果已經做到了行業頂尖水平。特別是我們 2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;年發佈的 AI 老師，是行業內首創推出超擬人 AI 老師，圍繞&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;家庭最普遍的日常學習和作業場景，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;模擬真人家&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;教輔導&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的核心&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;流程&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;從&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;診斷、反饋、規劃&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;個性化&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1v&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;輔導學習，系統化的實現了家庭教育場景和大模型技術的深度融合。目前 AI 老師已經成為學習機行業標杆，引領了行業發展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;問：對 AI 從業者而言，面對技術迭代加速的「百模大戰」，哪些核心能力將成為競爭壁壘？您會建議青年開發者深耕哪些技術方向？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/span&gt;這個問題就比較寬泛了，仁者見仁，智者見智。我只能從 AI 應用創新從業者的視角來看，識別大模型的能力邊界是個很重要的核心能力。大模型能幹什麼？不能幹什麼？能幹到什麼程度？你只有非常清楚，才能做好產品創新。把握的好就是事半功倍，把握的不好那就是事倍功半。而且大模型的能力邊界是在持續變化的，要動態的看這個問題，而不是靜態的，要對未來有預見性和判斷力。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;建議就不太好給了，我也是青年哈，我只能談幾點我自己正在看的幾個方向：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一、多模態大模型（特別是視覺大模型）還在快速升級。很多應用場景都需要多模態的支持；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二、Agent 架構迭代很快。比如年初的 Manus，還有最近的 MCP 協議等都在加速智能體架構的發展；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第三、端側大模型不可忽視。隨着 iPhone 的引領，端側大模型會成為手機行業標配，那也會催生端側大模型應用爆發。預計今年設備端有希望能跑 1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;0&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;B 小模型了，從能力角度看，已經可以幹很多事情了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:none"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18426743</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18426743</guid>
      <pubDate>Mon, 19 May 2025 02:38:40 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>微軟裁員風暴：軟件工程崗成為 AI 衝擊的重災區</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;《財富》雜誌近日發文對微軟近日裁員進行了針對性報道，社評認為微軟近日的大規模裁員計劃引發科技行業對人工智能時代就業結構變革的廣泛關注。&lt;/p&gt; 
&lt;p&gt;據華盛頓州官方文件披露，&lt;strong&gt;在微軟總部所在地的裁員中，軟件工程崗位成為受衝擊最嚴重的領域，佔該州約 2000 名被裁員工的 40% 以上。微軟本週二確認，其全球裁員規模約 6000 人，華盛頓州裁員人數佔總數的三分之一&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-28c5f1e9e5bbf3a6ed55da0a3a7e813d2ea.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次裁員呈現顯著的崗位結構性特徵：除軟件工程師外，軟件項目管理崗位亦面臨較大調整，華盛頓州被裁的產品管理和技術項目管理崗位合計約 600 人，佔該州總裁員數的 30% 左右。&lt;/p&gt; 
&lt;p&gt;知情人士透露，部分參與人工智能項目的管理人員與員工也在裁員範圍內，而客户服務類崗位（如銷售和市場營銷）受影響相對較小，微軟對此未作公開置評。&lt;/p&gt; 
&lt;p&gt;行業分析指出，微軟的裁員舉措與科技企業在人工智能領域的戰略轉型直接相關。隨着微軟及其競爭對手持續加碼人工智能投資，企業正通過嚴格審視運營成本、調整預算結構以優化資源配置。&lt;/p&gt; 
&lt;p&gt;微軟高管近期承諾，在鉅額數據中心建設投資背景下，將嚴控總體支出。值得關注的是，人工智能驅動的開發工具已展現出代碼編寫與分析能力，正逐步替代傳統工程師手動完成的部分開發任務。微軟首席執行官薩蒂亞·納德拉今年 4 月透露，在公司部分項目中，已有 30% 的代碼由 AI 生成。&lt;/p&gt; 
&lt;p&gt;這一現象並非微軟獨有，多家科技企業正同步推進人力結構重構以適應人工智能轉型。例如，Salesforce 今年初宣佈裁員逾 1000 人，同時計劃持續招聘人工智能相關銷售崗位，並明確到 2025 年將減少工程師招聘需求，因其認為人工智能已能替代部分崗位職能；Workday 今年 2 月裁員時，首席執行官卡爾·埃申巴赫亦強調將在人工智能等戰略重點領域加大招聘力度。&lt;/p&gt; 
&lt;p&gt;對於裁員目的，微軟方面表示主要是精簡管理層級，但目前精簡成效尚未明確。文件顯示，華盛頓州被裁員工中約 17% 為管理職位，這與微軟 2023 年底向美國平等就業機會委員會提交的人力資源報告中整體管理人員佔比基本一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350287</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350287</guid>
      <pubDate>Fri, 16 May 2025 11:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>加速項目管理效率，Gitee PPM 驅動軟件工廠的智能化轉型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;作者：Gitee DevSecOps 產品經理，李穎萍&amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在高速發展的軟件開發時代，企業如何高效管理多個項目、協調團隊合作、優化資源配置，已成為推動技術進步的關鍵。尤其是在多任務、多項目並行的複雜環境下，&lt;strong&gt;Gitee 項目組合管理（PPM）作為一款智能化工具，正成為軟件工廠的重要推動力量&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;軟件工廠：標準化與自動化的未來&lt;/h2&gt; 
&lt;p&gt;傳統開發模式中，企業依賴多個獨立工具支撐不同的開發任務和項目。隨着軟件工廠理念的提出，開發模式發生根本性轉變：軟件工廠強調的是一個完整的生產體系，由「標準化流程 + 自動化執行 + 可複用構件」構成的生產線。&lt;/p&gt; 
&lt;p&gt;在多項目並行背景下，如何通過高效的項目組合管理優化資源分配、提升執行效率，已成為企業面臨的重要挑戰。Gitee PPM 正是在此背景下應運而生，&lt;strong&gt;以全新的項目管理方式，推動軟件工廠智能化轉型&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;Gitee PPM：項目管理的智能調度與透明協作&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 通過智能調度與跨團隊協作機制，為軟件工廠提供有力支撐。無論資源調度還是多項目並行推進，Gitee PPM 都能高效保障項目執行：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;實時任務進度跟蹤：Gitee PPM 提供實時任務進度跟蹤功能。通過清晰的進度條和狀態標識，團隊可隨時掌握當前項目狀態，管理者也能及時識別需要重點關注和調整的環節。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161929_chRv_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;精準資源調配：用户可清晰查看每個項目的資源使用情況。系統根據需求智能調度資源，避免浪費與衝突，提升整體研發效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/161945_oCBD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;風險預警與問題追蹤：藉助任務進度和風險管理模塊，Gitee PPM 能及時識別潛在風險併發出預警，幫助項目經理在問題發生前做出調整，確保按時交付。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162000_wLN0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;全生命週期管理：從項目立項到交付，Gitee PPM 貫穿始終&lt;/h2&gt; 
&lt;p&gt;Gitee PPM 的亮點之一是全生命週期管理能力。從立項、排期、執行、監控，到最終交付，Gitee PPM 涵蓋項目管理的每一環節，確保每個項目都能夠高效且有序地推進。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;項目立項與資源規劃：提供標準化立項流程，並通過資源規劃功能助力前期準備。人員配置、時間安排、預算分配均可系統化管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動態調整與進度追蹤：在項目推進過程中，Gitee PPM 提供靈活的進度追蹤與調整功能，通過直觀的進度條與任務分配，管理者可以輕鬆地進行任務調度和進度優化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;協作與透明化：Gitee PPM 不僅支持項目經理和團隊成員之間的溝通，還通過任務審批和資源訪問權限的透明化管理，確保每個環節都能得到準確、及時的反饋。團隊成員可以實時查看項目狀態，隨時參與決策，提升工作效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162015_kOQP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;未來趨勢：智能化與自動化助力軟件工廠的跨越式發展&lt;/h2&gt; 
&lt;p&gt;隨着人工智能和自動化技術的迅速發展，未來的 PPM 更加註重智能與自動化融合。Gitee PPM 將持續深化智能分析與預測能力，提前識別風險並提供決策支持。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;無縫集成 DevSecOps 流程：Gitee PPM 將與 DevSecOps 深度融合，支持 CI/CD 等敏捷方法，提升軟件交付速度與質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全生命週期智能管理：隨着項目規模與複雜性增長，Gitee PPM 將擴展管理範圍，覆蓋研發、測試、交付和運維等各環節的智能化管理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Gitee PPM，賦能軟件工廠的未來&lt;/h2&gt; 
&lt;p&gt;在軟件工廠的智能化轉型過程中，Gitee PPM 無疑是其中最為關鍵的一環。通過智能化的項目管理，精準的資源調配，全面的風險控制以及高效的跨部門協作，Gitee PPM 正在為軟件開發行業帶來革命性的變化。&lt;/p&gt; 
&lt;p&gt;未來，Gitee PPM 將繼續不斷創新，推動軟件工廠向更高效、更智能、更安全的方向發展，成為企業實現研發目標、提升交付質量、加速業務增長的核心競爭力。&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的現代化研發生態&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式國產化研發與交付平台，集成了代碼託管（Code）、項目協作（Team）、持續集成（CI）、持續部署（CD）、代碼安全（Scan）、數據洞察（Insight）等多項能力，致力於打造具備全生命週期管控能力的現代軟件工廠。&lt;/p&gt; 
&lt;p&gt;&lt;img height="489" src="https://static.oschina.net/uploads/space/2025/0516/162034_3TT9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitee.cn%2Ffactory" target="_blank"&gt;https://gitee.cn/factory&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;平台設計充分考慮關鍵領域行業對安全性、可控性、合規性的極高要求，具備以下核心特徵：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;國產化適配與私有化部署能力：全面兼容國產操作系統與基礎設施，支持靈活部署於內網環境，保障數據主權；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控體系：代碼從提交、審核、構建、掃描、部署到發佈全流程可視、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模塊化產品結構：各能力模塊（如 Code、Team、Repo、Pipe、Scan、Insight 等）可靈活組合、漸進集成，適配多樣化團隊與流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可觀測與度量體系：內置研發效能度量與數據洞察引擎，支撐管理者宏觀掌控項目態勢與交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="599" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多個國家級重大項目與關鍵領域單位落地實踐中，Gitee DevSecOps 已成為構建「自主、可控、高效、安全」的軟件工程體系的重要基石。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350255</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350255</guid>
      <pubDate>Fri, 16 May 2025 08:21:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>前端構建神器 Parcel 大「瘦身」：依賴項削減 25%，安裝體積砍半！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在前端工具鏈百花齊放的今天，知名構建工具 Parcel 帶來了令人振奮的 2.15.0 版本更新。最讓開發者興奮的是：通過將核心功能改用 Rust 重寫，新版本在保持全部功能的同時，node_modules 體積直接砍掉近一半，依賴包數量也減少了四分之一。這對於那些被龐大 node_modules 文件夾困擾的開發者來説無疑是一劑強心針。&lt;/p&gt; 
&lt;h3&gt;擁抱「重型武器」，構建再也不擔心翻車&lt;/h3&gt; 
&lt;p&gt;本次更新最大的亮點是 HTML 處理鏈路的徹底重構。Parcel 團隊放棄了此前使用的 PostHTML 方案。PostHTML 是什麼？簡單來説，它是一個用 JavaScript 編寫的 HTML 處理工具，通過插件機制來完成 HTML 的解析和轉換。雖然 PostHTML 生態豐富，有着大量現成的插件可用，但其解析能力始終無法企及瀏覽器級別。&lt;/p&gt; 
&lt;p&gt;為了徹底解決這個問題，Parcel 團隊轉向了「重型武器」——直接搬來了 Firefox 瀏覽器和 Servo 渲染引擎中的核心組件，用 Rust 語言重新打造了 HTML 處理模塊。這就好比之前用的是「民用工具」，現在換成了「工業級設備」，解析準確性得到了質的飛躍。&lt;/p&gt; 
&lt;p&gt;舉個例子：HTML 規範中關於解析的部分竟然有 100 多頁之厚，裏麪包含了 20 多年來 Web 發展過程中積累的各種特殊情況。普通的解析器很難完美處理這些邊界情況，但瀏覽器級的解析引擎在這方面已經過了無數實戰檢驗。新版本採用 Servo 的 html5ever 解析器，意味着你的 HTML 文件將獲得與 Chrome、Firefox 等主流瀏覽器完全一致的解析結果。&lt;/p&gt; 
&lt;h3&gt;更保守但更聰明的壓縮策略&lt;/h3&gt; 
&lt;p&gt;在代碼壓縮方面，新版本的做法很有意思。與其他動輒追求極致壓縮率的工具不同，Parcel 選擇了更明智的「保守壓縮」策略。比如説，過去很多工具都會激進地刪除 HTML 中的空白字符，但實際上這可能會破壞頁面樣式，因為 CSS 中的&lt;code&gt;white-space: pre&lt;/code&gt;屬性就需要保留這些空白。新版本在這類情況下會謹慎處理，寧可多留一些空白，也不破壞頁面效果。&lt;/p&gt; 
&lt;p&gt;不過，在安全的優化場景下，新版本反而比之前更加智能。它能智能判斷何時可以安全地移除屬性引號、刪除布爾屬性的值，甚至利用 HTML 的容錯機制移除一些可選的閉合標籤。這些優化既保證了頁面完整性，又能帶來一定的體積收益。&lt;/p&gt; 
&lt;h3&gt;SVG 處理也來了次大換血&lt;/h3&gt; 
&lt;p&gt;SVG 處理模塊同樣迎來重大升級。新版本引入了名為 OXVG 的 Rust 工具替代了原有的 SVGO。測試顯示，這一替換帶來了數倍的性能提升。同時，得益於與新 HTML 解析器的無縫配合，現在處理網頁中的內嵌 SVG 圖標也變得更加高效可靠。&lt;/p&gt; 
&lt;p&gt;對於經常和 React 打交道的開發者來説，還有一個好消息：新版本重寫了 SVG 轉 JSX 的功能，直接將 SVG 轉換為 JavaScript 語法樹，省去了中間環節，處理效率得到顯著提升。&lt;/p&gt; 
&lt;h3&gt;新版本值得升級嗎？&lt;/h3&gt; 
&lt;p&gt;答案是肯定的。如果你正在使用 Parcel，升級到 2.15.0 版本將帶來立竿見影的收益：更小的項目體積、更快的安裝速度、更可靠的構建結果。而且，為了照顧現有項目，新版本保留了對 PostHTML 插件和 SVGO 配置的兼容支持，升級過程幾乎不會帶來任何副作用。&lt;/p&gt; 
&lt;p&gt;在當前前端工具鏈百家爭鳴的背景下，Parcel 用這次更新展示了一個頗具前瞻性的發展方向：用更可靠的系統級語言重寫核心功能，同時保持與現有生態的友好共存。這種演進思路值得其他工具借鑑。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350233/parceljs-2-5-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350233/parceljs-2-5-0</guid>
      <pubDate>Fri, 16 May 2025 07:24:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>【最後今天】LFOSSA 技能煥新季 85 折限時福利活動即將結束！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="微信圖片_85 折.png" src="https://oscimg.oschina.net/oscnet//23abacdd7a61a2ef402c028b04dfb5a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;Linux Foundation&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;開源軟件&lt;/strong&gt;&lt;strong&gt;學園（LFOSSA） 於 5 月 7 日至 5 月 16 日，推出&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;strong&gt;FOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff"&gt;，&lt;span style="color:#ff0000"&gt;&lt;strong&gt;全場 LF 官方認證考試及課程 &amp;nbsp;&lt;span style="color:#00b050"&gt;85 折&amp;nbsp;&lt;/span&gt;起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;，&lt;/strong&gt;&lt;/span&gt;&lt;span style="background-color:#ffff00; color:#ff0000"&gt;&lt;strong&gt;活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;今&lt;/span&gt;&amp;nbsp;天，機會不容錯過！&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;快速提升你的開源技能，搶跑&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;新時代&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技能煥新季 · LF 認證限時福利詳情&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;活動時間&lt;/strong&gt;：&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;5 月 7 日 - 5 月 16 日&lt;span style="background-color:#ffff00"&gt;（活動僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天！）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;適用產品：&lt;/strong&gt;&lt;strong&gt;LF&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;官方認證考試及課程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向個人專屬福利：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;部分機構熱門課程低至&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;7&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#00b050"&gt;折&lt;/span&gt;&lt;/strong&gt;，&lt;span style="background-color:#ffffff; color:#ff0000"&gt;&lt;strong&gt;添加 LFOSSA 官方微信，限時領取&amp;nbsp;&lt;span style="color:#00b050"&gt;認證培訓首節課程免費試聽&amp;nbsp;&lt;/span&gt;資格&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;面向企業專屬福利（階梯折扣）：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 採購 5-20 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;85&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 採購 21-50 個認證：&lt;/strong&gt;享&amp;nbsp;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#00b050"&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;折&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;優惠&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;strong&gt;3. 採購 50 個以上認證：&lt;/strong&gt;聯繫官方客服，獲取定製專屬方案&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368565314179.png" height="1000" src="https://oscimg.oschina.net/oscnet//dcb6214ff743fa4e8bbe17fc11a9cee5.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;有關&amp;nbsp;&lt;/strong&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;LFOSSA 技能煥新季限時福利活動&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;，可點擊以下鏈接瞭解詳情：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542784%26idx%3D1%26sn%3D236a3bfdcf36dec0bf41f462cc0c91d8%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;搶跑 AI 時代，煥新開源技能！LFOSSA 技能煥新季 85 折限時福利活動開啓！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzk0OTIwNTQzNA%3D%3D%26mid%3D2247542805%26idx%3D1%26sn%3D4af4c9ac39d950df1de31477624b659e%26scene%3D21%23wechat_redirect" target="_blank"&gt;【最後 2 天】LFOSSA 技能煥新季｜企業採購折扣限時福利活動即將截止，抓緊最後機會！&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;聯繫我們&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如需&amp;nbsp;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;體驗&lt;/strong&gt;&lt;strong&gt;認證培訓課程免費試聽首節課&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;，或為&lt;span style="color:#ff0000"&gt;&lt;strong&gt;貴單位定製認證學習路徑以及批量採購方案&lt;/strong&gt;&lt;/span&gt;，歡迎掃碼添加官方客服，我們將為你提供一對一的採購諮詢與支持服務。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="background-color:rgba(255, 246, 122, 0.8); color:#ff0000"&gt;&lt;strong&gt;活動截止時間：2025 年 5 月 16 日（僅剩最後&amp;nbsp;&lt;span style="color:#00b050"&gt;1&amp;nbsp;&lt;/span&gt;天）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;限時折扣，錯過不再，快來鎖定優惠名額！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368673326323.jpeg" height="260" src="https://oscimg.oschina.net/oscnet//86a0e91efbe8dabcc8f184b71cdb50ad.jpeg" width="260" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;span style="color:#8f959e"&gt;掃碼添加客服&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:center"&gt;&lt;img alt="1747368808706235.png" height="311" src="https://oscimg.oschina.net/oscnet//6a2c4a0154fe65c0ed86ca1afc9639a8.png" width="1600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#033fce"&gt;&lt;strong&gt;查看更多 LFOSSA 培訓、認證及套購產品，請訪問以下鏈接：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;培訓：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcourses" target="_blank"&gt;https://training.linuxfoundation.cn/courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;認證：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fcertificates" target="_blank"&gt;https://training.linuxfoundation.cn/certificates&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="margin-left: 0px; margin-right: 0px;"&gt;&lt;span&gt;&lt;strong&gt;套購：&lt;/strong&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2Fpack" target="_blank"&gt;https://training.linuxfoundation.cn/pack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;立即點擊&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftraining.linuxfoundation.cn%2F" target="_blank"&gt;&lt;span style="color:#ff0000"&gt;&lt;strong&gt;這裏&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;進入 LFOSSA 官網，選購官方認證考試及培訓課程產品。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350219</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350219</guid>
      <pubDate>Fri, 16 May 2025 06:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟 VS &amp; VS Code 每月活躍開發者數量達到 5000 萬</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fblog%2Fcelebrating-50-million-developers-the-journey-of-visual-studio-and-visual-studio-code" target="_blank"&gt;宣佈了&lt;/a&gt;其 Visual Studio 產品系列的一個重要里程碑：Visual Studio 和 Visual Studio Code 現在每月為超過 5000 萬活躍開發人員提供服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0516/0b34a4bdf1bdfd2.jpg" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-51990187483c55d75a61f86af17b234b4ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fc7a64f6ab1f22d5860bdce786e8832ef8b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Visual Studio 於 28 年前首次推出，至今仍是領先的集成開發環境 (IDE)，這主要得益於 Windows 生態系統的普及。多年來，它不斷發展，現已支持跨平台開發、雲原生應用程序、遊戲開發、數據科學工作流等。它仍然是少數幾個開箱即用地包含編譯器、調試器、分析器、設計器和語言服務的 IDE 之一。&lt;/p&gt; 
&lt;p&gt;Visual Studio 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Visual Studio Marketplace 上有 25000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;超過 100000 名開發人員貢獻反饋、問題報告和功能創意&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;社區論壇中數十萬個問答&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;每個季度更新平均修復 800 多個社區報告的問題&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;十年前，隨着 Windows 開始被 iOS 和 Android 等移動平台蠶食，微軟在當時推出了 Visual Studio Code，這一舉動令許多人感到意外。與其功能齊全的兄弟版本不同，Visual Studio Code 採用輕量級開源模式。它並非提供所有開箱即用的功能，而是允許開發人員通過龐大的擴展生態系統自定義其開發環境。&lt;/p&gt; 
&lt;p&gt;Visual Studio Code 的數據：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 市場中有 100000 多個擴展可用&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;VS Code 代碼庫已獲得 37000 多個 GitHub 星標&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;來自世界各地的數千名貢獻者&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;微軟開發者部門 CVP 兼產品主管、微軟第一方工程系統總經理 Amanda Silver 就這一里程碑寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在我們慶祝這一里程碑的同時，我們也正站在軟件開發新時代的開端。人工智能編程革命正在從根本上改變我們編寫代碼的方式，而我們僅僅觸及了未來可能性的皮毛。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為了慶祝 5000 萬里程碑，微軟還發布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2F" target="_blank"&gt;Visual Studio 和 Visual Studio Code 的週年紀念特別壁紙&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eaef23439a2406d17ad3b98418b1733e23a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;下載地址如下，分別用於桌面、手機與智能手錶：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fdesktop" target="_blank"&gt;https://visualstudiowallpapers.com/desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fphone" target="_blank"&gt;https://visualstudiowallpapers.com/phone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvisualstudiowallpapers.com%2Fwatch" target="_blank"&gt;https://visualstudiowallpapers.com/watch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在下週即將舉行的 Build 開發者大會上，微軟預計將發佈這兩款工具的更新，旨在進一步提升開發者體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350214/50-million-developers-the-journey-of-visual-studio-and-vscode</guid>
      <pubDate>Fri, 16 May 2025 06:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟將於 8 月 11 日關閉 Bing Search API 服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fbing%2Fapis%2Fbing-web-search-api" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;將於 2025 年 8 月 11 日正式關閉 Bing Search API 服務，屆時所有使用 Bing Search API 的實例將完全停用，同時不再接受新用户註冊。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135843_cSSP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微軟建議用户考慮使用 Azure AI Agents 中的「Grounding with Bing Search」作為替代方案，但該替代方案並非完美。&lt;/p&gt; 
&lt;p&gt;「Grounding with Bing Search」可以在生成回應時引用實時公開網絡數據，但開發者和用户無法直接訪問 Bing 搜索的原始數據內容，這意味着它無法完全替代 Bing Search API 的功能。&lt;/p&gt; 
&lt;p&gt;此次停用決定主要影響 Bing Search F1 及 S1 到 S9 資源的用户，以及 Custom Search F0 與 S1 到 S4 資源的用户。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;不過受影響的主要為 Bing Search APIs 的自助式或小型用户，像 DuckDuckGo 這樣的大型客户，由於與微軟簽署了直接協議，仍可繼續使用這些 API。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟在 ChatGPT 於 2022 年首次亮相後，已將 Bing Search APIs 的價格提高了 10 倍，此次直接關閉 API 服務，可能是微軟在 AI 時代對搜索服務戰略調整的一部分。&lt;/p&gt; 
&lt;p&gt;此外有分析指出，微軟停用 Bing API 可能會對正在審理中的 Google 搜索壟斷案產生影響。&lt;/p&gt; 
&lt;p&gt;由於 Google Search APIs 價格昂貴且限制較多，許多開發者更傾向於使用 Bing API，微軟的這一決定可能會迫使 Google 在搜索 API 資源方面做出更多讓步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350213/bing-web-search-api-retired</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350213/bing-web-search-api-retired</guid>
      <pubDate>Fri, 16 May 2025 05:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元圖像（Hunyuan Image）2.0 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元圖像 2.0 模型（Hunyuan Image2.0）已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FNEg5Wop9EPw3Z6Lx5ik7Mg" target="_blank"&gt;正式發佈&lt;/a&gt;。該模型主要有兩大特點：&lt;strong&gt;實時生圖、超寫實畫質。&lt;/strong&gt;目前已在騰訊混元官方網站上線（https://hunyuan.tencent.com/），並對外開放註冊體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img height="607" src="https://static.oschina.net/uploads/space/2025/0516/134524_sRBm_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方數據顯示，在圖像生成領域專門測試模型複雜文本指令理解與生成能力的評估基準 &amp;nbsp;GenEval（Geneval Bench）上，騰訊混元圖像 2.0 模型準確率超過 95%，遠超其他同類模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134745_rlGs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是混元圖像（Hunyuan Image）2.0 模型生成的圖片：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;人像攝影風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="512" src="https://static.oschina.net/uploads/space/2025/0516/134725_ADPH_2720166.png" width="854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;動漫風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="532" src="https://static.oschina.net/uploads/space/2025/0516/134738_PKYz_2720166.png" width="888" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;真實人物風格&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/134836_gwyW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次模型升級還帶來了發佈了實時繪畫板功能，基於模型的實時生圖能力，用户在繪製線稿或調整參數時，預覽區同步生成上色效果，突破了傳統「繪製-等待-修改」的線性流程，可助力專業設計師的創作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/135145_kura_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;實時繪畫板支持多圖融合，用户上傳多圖後，可將多個草圖疊加至同一畫布自由創作，經過 AI 自動協調透視與光影，按照提示詞內容生成融合圖像，進一步豐富了 AI 生圖的交互體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350209</guid>
      <pubDate>Fri, 16 May 2025 05:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windsurf 發佈 Wave 9 模型家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Windsurf (原 Codeium) 發佈了 Wave 9 模型家族，包括 SWE-1、SWE-1-Lite 和 SWE-1-Mini。&lt;/p&gt; 
&lt;p&gt;SWE-1 是一個前沿模型，專門為軟件工程任務設計，在內部評估和產品使用中，其性能接近甚至超越現有前沿模型。&lt;/p&gt; 
&lt;p&gt;SWE-1-Lite 是一個更強大的新模型，將取代原有的 Cascade Base，對所有用户免費。SWE-1-Mini 是用於 Windsurf 中 tab 補全的改進模型。SWE-1 目前對 Pro 用户限時免費。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/133759_d7AQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據 Windsurf 介紹，SWE-1 是其中最大、能力最強的 AI 模型，旨在突破現有大模型在軟件工程實際需求上的侷限。&lt;/p&gt; 
&lt;p&gt;相比只關注代碼生成和單元測試的傳統模型，SWE-1 更強調對開發流程中多種狀態和上下文的感知能力（flow awareness），它能夠在人機協作、任務未完成等複雜場景下持續推進工作。&lt;/p&gt; 
&lt;p&gt;根據基準測試，SWE-1 在 「對話式 SWE 任務基準」 和 「端到端 SWE 任務基準」 這兩項核心指標上，都已經接近目前行業最強的前沿模型。特別是獨立的端到端任務中，它的表現幾乎和 Claude 系列最新模型能力相當。&lt;/p&gt; 
&lt;p&gt;在對話式任務中（任務做到一半，用户和模型交替操作，模型需要接着用户的進度繼續完成任務），它目前的能力相當於 Claude 3.5 Sonnet。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-80a326122f0a65adc98949e8bf1c2bc890e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fcb9655b8e9ddf4084175265b446815c9f2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;參考來源：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindsurf.com%2Fblog%2Fwindsurf-wave-9-swe-1" target="_blank"&gt;https://windsurf.com/blog/windsurf-wave-9-swe-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FOS6Tz1nfUxgi0n4Dcf3bvg" target="_blank"&gt;https://mp.weixin.qq.com/s/OS6Tz1nfUxgi0n4Dcf3bvg&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350207/windsurf-wave-9-swe-1</guid>
      <pubDate>Fri, 16 May 2025 05:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深入對比谷歌 A2A 與 ANP：找到協議的原點</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;作者：常高偉，智能體協議 ANP 發起人。&lt;/p&gt; 
 &lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;關於 ANP：Agent Network Protocol (ANP) 是一個開源的智能體通信協議，目標是成為智能體互聯網時代的 HTTP。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;谷歌的&lt;/span&gt;&lt;span&gt;A2A&lt;/span&gt;&lt;span&gt;協議出來後，很多關注 ANP 社區的朋友第一時間發來消息，問對我們影響大不大，並且給我們獻言獻策，再次感謝。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我認為 A2A 對&lt;/span&gt;&lt;span&gt;ANP&lt;/span&gt;&lt;span&gt;最大的影響是，有了谷歌的「蓋章「 Follow：ANP 的路線是對的，ANP 看的很長遠，我也來了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;我不用再去解釋為什麼智能體通信協作重要了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;當天我花了半天的時候研究，寫了一篇文章：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA4NjIwOTM5Mw%3D%3D%26mid%3D2654085211%26idx%3D1%26sn%3D22d52145d41b02fc217469278c8857f5%26scene%3D21%23wechat_redirect" target="_blank" rel="nofollow"&gt;多角度全面對比 Google 最新的 A2A、ANP、MCP&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;後來又花了一天的時間仔細研究了 A2A，與 ANP 做了一個深度的對比，我認為我應該找到了 A2A 的原點，我也看到了 A2A 與 ANP 的更深層次的差異&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;一句話總結：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;MCP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;A2A 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;ANP 的原點是：&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;智能體在互聯網上的連接與協&lt;/span&gt;作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;技術層面的差異對比&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;雖然説 A2A 和 ANP 都是解決智能體通信與協作，但是從技術層面，A2A 與 ANP 還是有很大的差異。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體描述與信息組織&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在協議設計中，一個智能體如何對另外一個智能體暴露其信息，是一個關鍵的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體描述方面，A2A 使用了一個名為 Agent Card 的 JSON 格式的文檔，用於描述智能體的能力、技能、身份認證方法等，Agent Card 的核心是技能（skill），表達智能體能夠幹什麼事情，比如能夠進行地圖路徑規劃等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ANP 也是用的 JSON，不過基於 JSON-LD（&lt;/span&gt;&lt;span&gt;Linked Data&lt;/span&gt;&lt;span&gt;）和 schema.org 描述智能體信息（基本信息、身份驗證、對外產品/服務、交互 Interface），這是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;語義網&lt;/span&gt;&lt;span&gt;的技術，目的是提高兩個智能體對信息理解的一致性，以及讓智能體的公開信息能夠鏈接成一個數據網絡，智能體描述文件是網絡的入口：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="374" src="https://oscimg.oschina.net/oscnet/up-d01d5d7307d80461908b85ccbf5bf33a731.png" width="866" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，一個酒店智能體，使用 ANP，可以將酒店的房間、設施、服務、交互接口等信息（包括圖片）描述出來，並且鏈接成一個數據網絡，讓其他智能體能夠爬取並且理解。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這也導致，在智能體的交互上，A2A 與 ANP 有非常大的差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;A2A 通過 Agent Card 描述智能體的技能（skills），其他智能體獲取 skills，然後通過 JSON-RPC 發送一個任務請求，任務使用自然語言描述，並且攜帶任務需要的相關信息。任務完成後返回結果。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="899" src="https://oscimg.oschina.net/oscnet/up-6520f035e7c07da9e2c01587383e4349789.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;ANP 則是通過智能體描述文檔（Agent Description），將智能體對外提供的產品、服務、交互接口等信息用 URL 連接到一起，另外一個智能體像一個網絡爬蟲，通過 URL 不斷的爬取自己需要的信息。這個過程中可以通過自然語言接口與智能體進行交互，也可以通過結構化接口與智能體進行交互。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1037" src="https://oscimg.oschina.net/oscnet/up-6b28fc14add696a2b8229dff90d88f23df6.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這裏的核心差異：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;A2A 是智能體對外公開自己的技能，另外一個智能體發送處理任務過來，處理完成後返回結果。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;span&gt;ANP 是智能體對外公開自己信息（包含交互接口），其他智能體爬取信息進行處理，必要的時候通過自然語言接口或結構化接口與智能體進行交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;智能體發現&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在智能體的發現上 A2A 的方案和 ANP 基本是一樣的，都是在域名的.well-known 目錄下增加一個元數據文檔，A2A 的文件名是 agent.json，ANP 的文件名是 agent-descriptions。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時也都支持智能體主動註冊到私有註冊表，這個在局域網中的協作是非常有必要的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不同的地方在於，A2A 是直接將 Agent Card 內容放到.well-known/agent.json 中，而 ANP 則是在.well-known/agent-descriptions 中存放智能體描述文件的 URL。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 目前看起來是一個域名一個 Agent Card（還要進一步確認），ANP 則是一個域名可以有很多個智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;身份驗證&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在身份驗證上，A2A 和 ANP 有所不同。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 智能體在 A2A 協議中並不交換身份信息。相反，它們通過帶外方式獲取認證材料（如 token），並通過 HTTP 頭部傳遞這些材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所謂的帶外，是指通過 A2A 之外的其他協議獲取認證材料。A2A 遵循 OpenAPI 的身份認證規範進行身份認證，支持包括 HTTP Basic Auth、API Key、OAuth 2.0 等多種認證方式，具體由每個智能體在其 Agent Card 中聲明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="480" src="https://oscimg.oschina.net/oscnet/up-d447565d2bd93d80f90c7ecb282f4ef5cc6.png" width="852" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則基於 W3C DID 技術構建去中心化的身份認證，在協議中直接攜帶身份信息，包括身份驗證信息。智能體使用自己的身份就能夠和其他所有的智能體進行交互，不需要帶外獲得身份驗證材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在某些場景中，帶外獲取身份驗證材料是必要的，特別是在企業級應用中。ANP 未來會支持帶外身份驗證材料的獲取，設計上預留了擴展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b3dfb6efb5e2de6b145ed311e0f9e726f08.png" width="948" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 採用帶外獲取身份驗證材料，是為了最大程度兼容美國主流企業應用生態的安全合規要求，複用現有的企業身份認證體系，確保協議本身輕量、靈活且安全。核心是為瞭解決企業級應用的身份問題，並且沒有解決互聯網上智能體互聯互通的身份問題。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 則是未來解決智能體在互聯網上如何進行身份認證的問題，核心是讓互聯網上任意兩個智能體都能夠互聯互通，這需要一個互操作性更好的身份認證方案。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;核心概念&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 與 ANP 在協議的核心概念上有很大差異。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;A2A 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括 Skill（技能）、Task（任務）、Artifact（產物）、Message（消息）、Part（部分）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同時，Task 又定義了多種狀態，包括：submitted（已提交）、working（處理中）、input-required（需要輸入）、completed（完成）、canceled（取消）、failed（失敗）、unknown（未知）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Task 也定義了一些操作，包括：Send（發送）、Get（獲取）、Cancel（取消）等，以及一些通知相關的操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;ANP 的核心概念&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括描述信息與接口（Interface）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;描述信息主要是 JSON-LD 格式的文檔，以及 JSON-LD 文檔中通過 URL 鏈接到的其他資源，包括圖片、音頻、視頻等多媒體文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;Interface 又分為自然語言接口（Natural Language Interface）和結構化接口（Structured Interface）。結構化接口支持現有大部分的規範，比如 OpenAPI、JSON-RPC 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;核心差異：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 在協議層面定義了詳細的任務協作概念，包括任務的狀態、操作等，這有助於解決智能體之間複雜任務的協作問題。缺點是會導致兩個智能體之間的耦合度較高。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 簡化了智能體之間的交互，降低了智能體之間的耦合度，在跨平台的智能體協作場景下有較大的優勢。缺點是原生協議不支持複雜任務協作，需要自己定義 Interface 來實現。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;A2A 與 ANP 的原點&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;要想真正的理解一個協議的設計，必須找到這個協議的原點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;比如，ANP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能體在互聯網上的連接與協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。MCP 的原點一直都是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;模型與工具、資源的連接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，構建更好的智能體。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;通過上面的技術分析，我們可以確認 A2A 的原點是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;企業內部智能體之間的複雜協作&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;協議的官網並沒有明確的説出這一點，但是谷歌的新聞發佈稿中有提到過一些：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;AI 智能體為人們帶來了獨特的機會，能夠通過自主處理許多日常重複性或複雜任務，幫助提升工作效率。如今，企業越來越多地構建並部署自主智能體，以幫助在整個工作場景中實現規模化、自動化並優化各類流程——從訂購新筆記本電腦，到輔助客户服務代表，再到協助供應鏈規劃。（https://developers.googleblog.com/en/a2a&lt;/span&gt;&lt;span&gt;&lt;span&gt;-a&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-new-era-of-agent-interoperability/）&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從 A2A 生態企業的分佈也大概可以看出這一點，大部分都是 AI 平台與服務、軟件、SaaS 和企業平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-2defdfdfeb005bbfae4fe07af3e72afe1a4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="693" src="https://oscimg.oschina.net/oscnet/up-8026f8e9b8cc4e73963d2737dd793f74d30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;從技術上看，目前&lt;strong&gt;A2A 的實現也不大適合智能體互聯網的需求&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;以個人助手使用 A2A 去酒店智能體預訂房間為例，按照目前 A2A 的實現，個人助手需要發送一個任務，用自然語言描述用户的要求（價格、房型、時間等）信息，酒店智能體處理後返回任務執行信息。在中間可能要經過多次的任務交互、任務狀態的遷移等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;這會有兩個問題：一個是用户的隱私可能會被泄露，因為個人助手要將任務發送給另外一個智能體執行；另外一個就是交互耦合度過高。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 的邏輯則是個人助手爬取酒店智能體的信息在本地進行處理，需要交互的時候才調用酒店智能體的接口。這是本質的區別。當然，除此之外 A2A 還有智能體在互聯網上的身份互聯互通問題沒有解決。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，&lt;strong&gt;也不排除未來 A2A 通過協議升級擴展到智能體互聯網的場景&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;未來智能體協議的一些預判&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;短期內 MCP 成為模型連接工具和資源的事實標準，這個基本上已經確定，目前很難有第二個 MCP 出現。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;中長期來看，我認為有一個趨勢大概率會發生：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;工具智能體化，智能體工具化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果這個趨勢發生，那麼智能體協議會擠壓 MCP 的空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;更長期來看，AGI 實現後，也許人類設計的協議是 AI 的束縛而非助力，AI 有辦法自己設計協議並達成共識。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;不過，在當下智能體協議是非常重要的，它是智能體的重要拼圖，也是智能體與互聯網交互最 AI 原生的方式，是比 Computer Use、Browser Use，甚至 AI 瀏覽器都更高效的連接方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;無論如何，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 最有價值的部分，是社區對未來智能體互聯網的設想，是社區獨特的互聯網理念（連接即權力），以及 DID+語義網的技術路線。這是支撐 ANP 走下去的核心動力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;關於創新&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;A2A 出來之後看着"炸裂、一夜變天、顛覆"這些標題心情複雜，特別是我們做 ANP 做了一年，也推廣了很長時間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們都在説，我們需要"0 到 1"的創新——我們不單需要創新者，也需要媒體能夠去發現這些創新者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;最後感謝開源社區的每一位貢獻者和開發者，現在已經有 40 多位開發者了。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;也感謝公眾號、社區對我們的支持，包括 RTE 開發者社區、OSC 開源社區、&lt;/span&gt;&lt;span&gt;Founder Park&lt;/span&gt;&lt;span&gt;、覺察流、侯宏文存、AIGCLink、智能體 AI 等等（可能不全），還有很多給我們提供分享機會的組織，以及為社區提供服務器資源的 AWS 和阿里雲。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;最後&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;如果你也認可我們的理念，認可我們對未來智能體互聯網的設想，歡迎加入我們，無論是以個人，還是以公司名義，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;我們需要你的支持&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我們正在籌備 ANP 開源技術社區創始委員會，這是一個臨時委員會，目的是為了讓社區能夠走向正軌，成長為一個更加開放的社區。感興趣可以聯繫我。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;聯繫方式：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;開源項目 GitHub：https://github.com/agent-network-protocol/AgentNetworkProtocol&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;Discord: https://discord.gg/sFjBKTY7sB&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;官網：https://agent-network-protocol.com/&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;微信：flow10240&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/9297178/blog/18398047</link>
      <guid isPermaLink="false">https://my.oschina.net/u/9297178/blog/18398047</guid>
      <pubDate>Fri, 16 May 2025 05:07:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>NebulaGraph 圖數據庫開源六週年</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;&lt;strong&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-347a643f66a66a9edf9d5760c1e8d2f4686.png" referrerpolicy="no-referrer"&gt;&lt;/strong&gt;&lt;/strong&gt;‍‍&lt;/p&gt; 
&lt;p&gt;2025 年 5 月 15 日，NebulaGraph 迎來開源六週年的里程碑。作為國產開源圖數據庫的標杆項目，回望 NebulaGraph 的六年發展歷程，不僅是一部技術迭代的編年史，更是中國開源社區在全球基礎軟件領域崛起的縮影。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、誕生：在數據關係的浪潮中揚帆起航&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 8 月 31 日， @Sherman-the-tank 在 nebula 倉庫中提出第一個 issue ‘Create a parser framework to process GQL.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2018 年 9 月 5 日， @dutor 提交了第一個 PR ‘Added some concurrent utilities, GenericThreadPool, etc.’&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph PMC Sherman Ye 曾參與多個分佈式數據庫研發工作，當社交網絡爆發式增長，引發數據關係挖掘需求井噴時，他敏鋭地意識到：圖數據庫是表示和理解關係最天然的工具，然而當時的圖數據庫或受限於單機性能，或困於擴展性不足，難以承載千億節點、萬億邊級的超大規模數據。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們必須打造一款開源的、分佈式的、支持線性擴容的世界級圖數據庫，能夠容納千億頂點和萬億邊。&lt;/strong&gt;」Sherman 的願景，從一開始就超越了代碼本身。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4e970720b415322cc5254ac4b46dd587181.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 誕生於一間小公寓，初期核心團隊在這裏辦公）&lt;/p&gt; 
&lt;p&gt;NebulaGraph 採用 Shared-Nothing 架構與存儲計算分離設計，為 NebulaGraph 注入了宇宙級的基因——每個節點獨立處理數據，如同星雲中的星辰，既自由又協調；存儲與計算分離，則讓擴容像星雲膨脹般自然。&lt;/p&gt; 
&lt;p&gt;「&lt;strong&gt;我們寫下 NebulaGraph 第一行代碼時，就認識到它必須是一款開源的圖數據庫&lt;/strong&gt;。」不忘開源初心，八個月後，NebulaGraph 遵循 Apache 2.0 開源協議，在 GitHub 開源 alpha 版本，從此開啓了突破國產圖數據庫技術的星辰大海征程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a9d672008ac303c7c9a6d86aa9b3c44aa2e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（一張開源紀念截圖）&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、應用：在產業實踐的土壤中紮根&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 10 月 29 日，攜程雲原生技術總監周昕毅先生在上海 nMeetup 上充分肯定了 NebulaGraph 作為開源解決方案在企業中的應用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用户的選擇是最好的背書。六年來，NebulaGraph 用户覆蓋金融、互聯網、通信、電商、保險、安全等多個行業。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-d2338012c10f02d334d817be194af6c777f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 部分用户）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;攜程集團已有包括酒店、機票、金融在內的 16 個部門使用 NebulaGraph, 在風控場景，構建了實時圖特徵平台的應用邏輯閉環，額外獲取了 55% 的關聯業務信息，使得該場景下的覆蓋率提升了 32%&amp;nbsp;；奇富科技打造了智能化的金融反欺詐系統系統，累計報送涉騙阻斷預警 59 萬次，攔截潛在被騙者 9.5 萬人，幫助用户避免損失 11.35 億元；OPPO 從 JanusGraph 切換到 NebulaGraph 後，導入性能提升了 10 倍，且查詢性能以及併發能力都有 3-6 倍的提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;NebulaGraph 是開源項目，用户在真實使用場景中，為解決業務需求，會自然地參與共建，這種集體智慧加快了 NebulaGraph 的迭代：企查查貢獻了 Node 客户端，奇富科技阿旺把自己做的 nebula-console-intellij-plugin 捐給了社區，篤篤科技大葉開發了 NebulaGraph 圖數據庫客户端星影 StarShadow.&lt;/p&gt; 
&lt;p&gt;一幅技術紮根產業、需求反哺產品的共生圖景已然成形。這正是 NebulaGraph 在真實商業土壤中向下紮根、向上生長的最佳註腳。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、生態：在開源共治的生態中繁榮&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年 3 月，NebulaGraph 在 GitHub star 數突破 10,000 大關&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NebulaGraph 社區構建了一套自由且開放的「雙軌成長體系」：開發者（Dev Group）聚焦代碼貢獻，用户（User Group）專注實踐傳播。細分來看，還有學習者、佈道師、文檔貢獻者等角色，每種角色都能擁有自己的話語權，找到自己的存在價值，他們不會被統一地轉化成某一類角色，他們被允許以某一種角色停留在社區裏，比如僅僅作為用户，或者僅僅作為一次性的代碼貢獻者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-4781abc41f59cc55d7d129c6444f502e901.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph Community 成長體系）&lt;/p&gt; 
&lt;p&gt;作為開源項目，我們始終重視代碼共建共享。連續 5 年參與中國科學院軟件研究所發起的開源之夏，鼓勵全球高校開發者參與開源貢獻，為社區注入新鮮血液；舉辦 NebulaGraph Hackthon，設立 150,000 獎金池，從內核到周邊，讓廣大圖數據庫及 NebulaGraph 愛好者盡情探索圖世界。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-a5cadecf20779c82bcf80c9e7896d7e77cc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（來自開發者的認可）&lt;/p&gt; 
&lt;p&gt;線下活動同樣精彩紛呈。從 NUC 2021、2022，到足跡遍佈全國的 nMeetup，我們珍惜每次與用户、開發者面對面交流的機會。也許大家素未謀面，但因為同在 NebulaGraph 社區，見證了萬星開源項目的崛起，每次線下探索圖數據庫的世界都能像老朋友一樣碰撞出思維的火花和久違的默契。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-9d32d3464c875255314f68fc03f7487fc59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（社區可愛的小夥伴們）&lt;/p&gt; 
&lt;p&gt;我們始終以包容的姿態，讓每個社區參與者的獨特貢獻匯聚成生態繁榮的星河。&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、未來：在雲與 AI 的浪潮中領航&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph Cloud&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2020 年，NebulaGraph 決定打造雲產品&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;NebulaGraph 從誕生之初起，不僅堅定走開源路線，還堅持雲原生理念。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如今，NebulaGraph Cloud 作為一套集成了 NebulaGraph 數據庫和數據服務的雲上服務，支持一鍵部署 NebulaGraph 和相關可視化產品。用户可以在幾分鐘內創建一個圖數據庫，並快速擴展計算、存儲等資源，無需在本地搭建和維護複雜的圖數據庫基礎設施，從而能夠更加專注於核心業務的發展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-0f3996764f2cbb028787d68755889da4bdc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph 控制枱界面）&lt;/p&gt; 
&lt;p&gt;NebulaGraph Cloud 除了在 AWS 上提供全託管服務，還計劃全面支持 Azure 和 Google Cloud Platform (GCP) 等主流公有云廠商，企業可夠根據自身需求和業務場景，選擇最適合的雲廠商。&lt;/p&gt; 
&lt;p&gt;申請試用⬇️&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.nebula-graph.io%2Flogin" target="_blank"&gt;https://cloud.nebula-graph.io/login&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;NebulaGraph AI 應用平台&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2023 年 8 月 16 日，@wey-gu 與 LlamaIndex 聯合發佈 GraphRAG.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;正如 NebulaGraph 誕生之初，我們又一次站在高處看未來——洞察到圖結構在知識處理中的革命性潛力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2023 年 8 月，在 RAG 技術還未被稱為 RAG，而是上下文學習方法的時候，我們就意識到以圖的方式處理知識會對解決「大海撈針」等特定問題有很大幫助，因此&amp;nbsp;@wey-gu 提出了將圖數據庫與 RAG 結合的想法，向 LlamaIndex 提了第一個 PR，將 KG-RAG 轉變為 GraphRAG.&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-94fd0e2ef4e5265750786d1f60e9423f893.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（NebulaGraph GenAI Team Leader @wey-gu）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GraphRAG 僅僅是 NebulaGraph 探索 GenAI 的「第一步」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;隨後，我們和 Researcher: Diego 一起討論，做了圖索引之上 Chain of Exploration 的工作，這種探索鏈不僅可以幫助 Agent 理解圖譜，還能從非結構化數據中提取出半結構化的知識圖譜‌。&lt;/p&gt; 
&lt;p&gt;在一系列 Graph based RAG 的落地實踐中，GenAI Team 又一次突破技術邊界，提出了 Fusion GraphRAG：融合了高級 RAG 技術，通過圖狀結構存儲文檔層級、章節關係及特殊元素（如公式、表格），實現高效、靈活的檢索。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-b04608e8eedc97b778355eed434fc9280f4.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（Fusion GraphRAG 是更高級的 RAG 技術）&lt;/p&gt; 
&lt;p&gt;但不止於此，NebulaGraph 把視角轉向企業級應用，基於 FusionGraphRAG 與 Agentic RAG 技術，打造了一個全新的高級知識庫與低門檻應用平台 —— NebulaGraph AI 應用平台（內部命名為 「Catalyst」，即催化劑），無需構建複雜 Workflow 和編寫繁瑣 Prompt，更智能地激活與應用企業內部知識。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-2cbc7e0b1c9bf670db137f17cbee8b6f5dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（用户只需將對私有知識的理解轉化為對不同「知識籃子」的定義）&lt;/p&gt; 
&lt;p&gt;從 GraphRAG 到 NebulaGraph AI 應用平台，我們始終相信：真正的技術革命，不在於創造更復雜的工具，而在於讓複雜技術變得觸手可及。當每個企業都能像調配催化劑一樣輕鬆激活知識資產，我們離智能時代的真正到來，便又近了一步。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;六週年快樂🎉&lt;/h1&gt; 
&lt;p&gt;六載春秋，NebulaGraph 從一顆種子長成參天大樹，其根系已深入全球開發者土壤，枝葉則伸向雲與 AI 的星辰大海。NebulaGraph 的開源歷程，證明瞭通過開源共治，我們能打造出一款世界一流的圖數據庫產品，更證明瞭這羣活躍在開源社區的極客，有着無限的探索精神和創新能力。&lt;/p&gt; 
&lt;p&gt;因為開源，這場圖數據庫技術革命，沒有終點，只有新的起點。&lt;/p&gt; 
&lt;p&gt;因為有你，這場開源協作的星辰征途，沒有孤島，只有攜手同行的遼闊未來。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;開源最大的意義，莫過於代碼開放，共建共享，以用户/開發者的力量推動產品迭代。&lt;/p&gt; 
&lt;p&gt;陪伴 NebulaGraph 共同成長的你，是使 NebulaGraph 愈發閃耀的星光。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/up-98d9a5b4f678bcb55a625b31b4cefe5e359.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscuss.nebula-graph.com.cn%2Ft%2Ftopic%2F16781" target="_blank"&gt;在 NebulaGraph 論壇&lt;/a&gt;&amp;nbsp;分享你與 NebulaGraph 的故事，讓更多小夥伴感受到開源的力量。（分享即送星雲仔 T 恤，點贊 top3 可獲得全套社區周邊）&lt;/p&gt; 
&lt;p&gt;六月，NebulaGraph 社區將在北京舉辦 nMeetup，歡迎掃碼提交議題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="圖片" height="100" src="https://oscimg.oschina.net/oscnet/up-780ef5d7632ee90c872ab50c1333b6c1ddc.png" width="100" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;‍&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;如果你覺得 NebulaGraph 能幫到你，或者你只是單純支持開源精神，可以在 GitHub 上為 NebulaGraph 點個 Star！每一個 Star 都是對我們的支持和鼓勵✨&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvesoft-inc%2Fnebula" target="_blank"&gt;https://github.com/vesoft-inc/nebula&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt; 
&lt;p&gt;✦&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4169309/blog/18403236</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4169309/blog/18403236</guid>
      <pubDate>Fri, 16 May 2025 03:53:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 牽頭推動 Transformers 庫模型架構標準化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Ftransformers-model-definition" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;聯合多家機構推動將&lt;code&gt;transformers&lt;/code&gt;庫作為模型架構標準，提升 AI 生態兼容性。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1238" src="https://static.oschina.net/uploads/space/2025/0516/114028_tsZR_2720166.png" width="1718" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Hugging Face 表示正與 vLLM、LlamaCPP、SGLang、Mlx、Qwen、Glm、Unsloth、Axoloth、Deepspeed、IBM、Gemma、Llama、Deepseek、Microsoft、Nvidia、InternLM、Llava、AllenAI、Cohere、TogetherAI 等眾多生態系統參與者共同努力，將&amp;nbsp;&lt;code&gt;transformers&lt;/code&gt;&amp;nbsp;庫中的模型定義代碼作為標準，旨在為所有模型提供一個統一的真實來源。&lt;/p&gt; 
&lt;p&gt;Hugging Face 目前正在與最流行的推理引擎（vLLM、SGLang、TGI、...）緊密合作，讓它們使用&lt;code&gt;transformers&lt;/code&gt;作為後端：只要模型被添加到&lt;code&gt;transformers&lt;/code&gt;，便支持在這些推理引擎中使用，同時利用每個引擎的優勢：推理優化、專用內核、動態批處理等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dc6ac94d98590b08d7bb511a05cf4e82e7e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這項聯合工作將極大地提高不同模型架構在整個 AI 生態系統中的兼容性和互操作性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350188/huggingface-transformers-model-definition</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350188/huggingface-transformers-model-definition</guid>
      <pubDate>Fri, 16 May 2025 03:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Data 2025.0.0 GA</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Spring Data 2025.0.0 現已正式發佈，此版本包含驅動程序升級以及各個 store 模塊的優化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一些更新亮點內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;MongoDB 和 Apache Cassandra 中的向量類型和向量搜索支持&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Spring Data JPA 中 DTO Projections 的&amp;nbsp;Constructor Expression Derivation&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;支持在 Spring Data JDBC 和 R2DBC 中使用序列生成標識符&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;使用 Cassandra 5 存儲附加索引創建索引&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;可參閲&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-commons%2Fwiki%2FSpring-Data-2025.0-Release-Notes" target="_blank"&gt;發行説明&lt;/a&gt;以瞭解更多詳細信息。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Spring Data Commons&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcommons%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcommons%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-commons%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data JPA&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fjpa%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fjpa%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-jpa%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data MongoDB&amp;nbsp;&lt;code&gt;4.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fmongodb%2Fdocs%2F4.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fmongodb%2Freference%2F4.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-mongodb%2Freleases%2Ftag%2F4.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data Neo4j&amp;nbsp;&lt;code&gt;7.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fneo4j%2Fdocs%2F7.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fneo4j%2Freference%2F7.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-neo4j%2Freleases%2Ftag%2F7.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data for Apache Cassandra&amp;nbsp;&lt;code&gt;4.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcassandra%2Fdocs%2F4.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcassandra%2Freference%2F4.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-cassandra%2Freleases%2Ftag%2F4.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data KeyValue&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fkeyvalue%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fkeyvalue%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-keyvalue%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data LDAP&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fldap%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fldap%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-ldap%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data REST&amp;nbsp;&lt;code&gt;4.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Frest%2Fdocs%2F4.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Frest%2Freference%2F4.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-rest%2Freleases%2Ftag%2F4.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data Redis&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fredis%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fredis%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-redis%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data Elasticsearch&amp;nbsp;&lt;code&gt;5.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Felasticsearch%2Fdocs%2F5.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Felasticsearch%2Freference%2F5.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-elasticsearch%2Freleases%2Ftag%2F5.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data Couchbase&amp;nbsp;&lt;code&gt;5.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcouchbase%2Fdocs%2F5.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Fcouchbase%2Freference%2F5.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-couchbase%2Freleases%2Ftag%2F5.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Data Relational&amp;nbsp;&lt;code&gt;3.5&lt;/code&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Frelational%2Fdocs%2F3.5.0%2Fapi%2F" target="_blank"&gt;Javadoc&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.spring.io%2Fspring-data%2Frelational%2Freference%2F3.5%2F" target="_blank"&gt;Documentation&lt;/a&gt;&amp;nbsp;-&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-data-relational%2Freleases%2Ftag%2F3.5.0" target="_blank"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350562/spring-data-2025-0-ga</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350562/spring-data-2025-0-ga</guid>
      <pubDate>Sun, 11 May 2025 02:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2030 年我國數據產業規模將達 7.5 萬億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;2025 數據安全發展大會上介紹，我國將培育壯大一批數據要素產業鏈上下游企業，預計到 2030 年，我國數據產業規模將達到 7.5 萬億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為全球首個將數據納入生產要素的國家，我國已初步構建起門類齊全的數據產業鏈。數據顯示，2024 年我國年度數據生產總量達 41.06 澤字節，同比增長 25%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;截至目前，我國數據領域相關企業超 19 萬家，數據產業規模超 2 萬億元。按照 20% 以上的年均增長率測算，2030 年我國數據產業規模將達 7.5 萬億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-8974708623b157a8be63e50fae982623dce.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國家數據局局長劉烈宏表示：探索適應數據特徵的產權配置、流通模式和安全治理機制，培育壯大一批數據要素產業鏈上下游企業。當前我們正謀劃構建橫向聯通、縱向貫通，協調有力的數據基礎設施體系，到 2029 年要基本建成國家數據基礎設施主體結構。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公共數據開放共享成為數據要素市場化的重要突破口。2024 年全國地市級以上的地方公共數據開放平台數量增長 7.5%，開放數據量增長 7.1%，高質量數據集數量同比增長 27.4%。在數據要素與產業融合方面，國家正加快打通公共數據共享開放壁壘，推動公共數據與企業數據深度融合，激活海量「沉睡數據」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350559</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350559</guid>
      <pubDate>Sun, 11 May 2025 02:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>如何用好 「對話式編程」？牢記這十二條策略</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 如何有效利用大語言模型（LLMs）生成高質量代碼？這是當下開發者們比較關心的一個問題。在生成代碼的過程中，提示詞的設計是否精確，直接決定了模型輸出的質量。&lt;/p&gt; 
 &lt;p&gt;本文深入探討了提示詞優化的 12 條策略，給出了清晰的操作指南和示範案例，讀者可以瞭解到如何通過精準編寫提示詞引導模型生成性能優越、符合實際需求的代碼。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Ayush Thakur@Potpie&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie" target="_blank"&gt;https://github.com/potpie-ai/potpie&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;大語言模型（LLMs）已經徹底改變了代碼生成領域，但要想獲得高質量、有用的輸出結果，編寫有效的提示詞至關重要。LLMs 生成代碼的質量高度依賴於所提供提示詞的質量。&lt;strong&gt;一句表述不當的提示詞可能導致不完整、不正確或雖然正確但不具備針對性的響應，而邏輯性、完整性和易讀性良好的提示詞則能最大化發揮模型的潛力。&lt;/strong&gt; 本文將探討編寫有效提示詞的高級策略，以便使用 LLMs 生成高質量的代碼。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 提供詳細的上下文&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在與 LLMs 進行交互生成代碼時，所提供上下文的深度和質量直接影響模型輸出的相關程度和準確程度。&lt;/p&gt; 
&lt;p&gt;上下文需要包含的關鍵要素有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Specific problem domain（譯者注：指的是你試圖解決的問題所在的特定專業或技術領域。例如，如果你正在開發一個系統來處理金融交易，那麼你的問題領域就是金融科技（FinTech）。）&lt;/li&gt; 
 &lt;li&gt;Existing codebase characteristics（譯者注：指的是當前項目中已有代碼的特點、風格和結構等信息。）&lt;/li&gt; 
 &lt;li&gt;Implementation constraints（譯者注：在實現解決方案時必須遵守的各種限制條件，如只能使用某些技術棧等。）&lt;/li&gt; 
 &lt;li&gt;Performance requirements（譯者注：指的是系統或應用程序需要達到的性能標準。）&lt;/li&gt; 
 &lt;li&gt;Architectural patterns already in use（譯者注：指的是在當前項目或組織中已經採用的軟件架構模式。架構模式是一種通用的、可重複的設計模板，用於解決軟件架構中的常見問題。例如，微服務架構、分層架構（n-tier architecture）或是事件驅動架構等。）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，你可以使用 &lt;a href="https://my.oschina.net/references"&gt;@references&lt;/a&gt; 指向特定文件或函數（譯者注：大部分「對話式編程」 Apps 都支持該功能），使你的請求更加精準。與其用文字描述某個函數，不如直接引用它。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示詞：創建一個用户身份驗證系統。&lt;/p&gt; 
 &lt;p&gt;✅ 更好的提示詞：為我們的 Node.js Express API 創建一個基於 JWT 的身份驗證系統，該系統需要與 MongoDB 的 user 集合集成。該系統應使用 bcrypt 處理密碼哈希，簽發有效期為 24 小時的令牌，並實現刷新令牌（refresh token）輪換機制增強安全性。現有的中間件模式採用 async/await 語法。請參考 @authMiddleware.js 的中間件結構和 @userModel.js 的 user 集合結構。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;通過使用 @authMiddleware.js 和 @userModel.js，可以確保生成的代碼與現有架構保持一致，減少一些集成問題和手動調整工作量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 將問題分解為多個步驟&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;複雜的編碼任務需要系統性地拆解為可管理單元。該方法論的實施路徑如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;從明確的功能需求出發&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分析目錄結構和代碼組織方式&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;引導 LLM 按照邏輯步驟實現目標功能，同時遵循既定的架構邊界和設計模式。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;例如，在實現一個數據處理 pipeline 時，首先需明確輸入的數據結構、轉換邏輯、錯誤處理的相關要求及預期的輸出格式。隨後分析目錄結構，並確定新功能的實現位置。&lt;/p&gt; 
&lt;p&gt;需要綜合考量代碼之間的依賴關係（dependency relationships）、模塊的職責劃分與隔離（module boundaries）以及代碼的目錄結構與命名規範（code organization principles）。這一步驟可確保生成的代碼能無縫集成到現有代碼庫中。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 選擇合適的模型完成任務&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同 LLM 在代碼生成任務中展現出的優勢不同。&lt;strong&gt;某模型可能擅長理解複雜需求並生成邏輯一致性強的代碼，而另一模型可能在特定編程語言或框架上具有優勢。&lt;/strong&gt; 在評估使用哪種 LLM 時，需着重關注以下技術因素：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文窗口大小（處理大型代碼庫時至關重要）&lt;/li&gt; 
 &lt;li&gt;對編程語言/技術框架的掌握程度&lt;/li&gt; 
 &lt;li&gt;特定領域的專業知識&lt;/li&gt; 
 &lt;li&gt;多輪交互的穩定性&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對比示例：&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;任務類型&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;模型選擇考量因素&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;複雜的企業級架構&lt;/td&gt; 
   &lt;td&gt;更大的上下文窗口大小有助於在大型代碼庫中保持多輪交互的穩定性&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;機器學習 pipeline&lt;/td&gt; 
   &lt;td&gt;數學基礎紮實且經過數據科學專項訓練的模型更具優勢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;前端組件&lt;/td&gt; 
   &lt;td&gt;採用新近框架數據訓練的模型，可輸出符合業界最新標準的代碼模式&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;&lt;strong&gt;04 具體參照現有的代碼實現模式&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在提示詞中明確具體細節能大大提升代碼生成的質量。&lt;/strong&gt; 技術細節需明確指向代碼庫中的既有實現範式，而非籠統要求通用方案。例如：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❌ 欠佳的提示詞： 「寫一個處理用户數據的函數」&lt;/p&gt; 
 &lt;p&gt;✅ 更優的提示詞：「在 UserProcessor 類 (src/services/UserProcessor.js) 中創建一個新方法，沿用 transformPaymentData 方法的函數式編程風格實現用户數據的轉換。因採用異步機制，實現時應以可讀性為第一準則，性能次之。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該方法也同樣適用於命名規範、編碼標準和架構模式。需明確説明採用函數式或面向對象範式，指定設計模式類型，並澄清性能與代碼可讀性的優先級。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 請重新生成而非回滾&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;當生成的代碼出現問題時，重新生成有問題的模塊通常比逐步去修復代碼中的問題效果更好。&lt;/strong&gt; 此方法源於大語言模型理解上下文和生成模型響應的機制。&lt;/p&gt; 
&lt;p&gt;為何重新生成效果更好？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;脱離原有錯誤實現方式的思維定式&lt;/li&gt; 
 &lt;li&gt;防止舊代碼中的錯誤代碼邏輯污染新的代碼實現&lt;/li&gt; 
 &lt;li&gt;支持加入新的約束條件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種方法對解決一些算法難題或實現複雜的代碼邏輯特別有效，因為在這些場景下一點細微的錯誤都可能影響整體解決方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請嘗試用不同的方法實現排序算法。當前版本的時間複雜度為 O(n²)，無法滿足數據集規模要求，請基於我們其他的數據處理函數使用的歸併排序模式，重新生成 O(n log n) 時間複雜度的解決方案」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;06 決策前請生成多套方案進行對比&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;利用大語言模型能夠生成多套解決方案的能力，通過對比分析提升代碼質量。首先，要求模型生成 2-3 種不同的實現策略，每種策略需包含對該方案優缺點的分析。&lt;/p&gt; 
&lt;p&gt;生成多套方案後，引導模型分析時間複雜度、空間複雜度、代碼可讀性和可維護性等因素，並分析如何權衡這些因素。這一反思（reflection）過程使模型能根據具體需求選擇並完善最合適的解決方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請為 API 響應緩存系統（caching system for our API responses）提供三套實現方案：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;基於自定義數據結構的 LRU 內存緩存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;基於 Redis 的分佈式緩存方案&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;支持 TTL 的本地文件系統緩存&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;請分別分析各方案的時間複雜度、內存佔用、多服務器擴展能力和實現複雜度」&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 實施自我審查機制&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Self-review prompting 可通過引導大語言模型對其生成的代碼進行系統化評估來提升代碼質量。具體實施時需明確要求模型在完成代碼生成後交叉檢查其生成的代碼。自我審查（Self-review）應評估以下這幾個方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;代碼正確性（是否有邏輯錯誤）&lt;/li&gt; 
 &lt;li&gt;效率（是否存在性能問題）&lt;/li&gt; 
 &lt;li&gt;邊界情況的處理情況&lt;/li&gt; 
 &lt;li&gt;安全漏洞&lt;/li&gt; 
 &lt;li&gt;是否嚴格滿足需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在自我審查過程中，模型可識別潛在問題，例如併發代碼中的競態條件漏洞（譯者注：一種常見安全漏洞，源於系統或程序在處理併發操作時因時序問題導致的邏輯錯誤。）、資源管理中的內存泄漏，或直接影響系統安全的核心邏輯中的漏洞風險點。發現問題後，模型可立即優化代碼實現來解決問題。此方法對應成熟的軟件工程實踐（如代碼審查和靜態分析），但將其置於同一 prompt-response 週期內執行，大大提升了初始的代碼生成質量。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;08 為模型賦予技術人設或給出參考框架&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為大語言模型分配技術人設，可確保其代碼生成保持統一的專業視角。當要求模型以"精通分佈式系統的高級後端工程師"的思維模式運作時，其生成的代碼會優先考慮可擴展性、容錯性和性能優化。同理，若賦予"安全專家"人設，其生成的代碼會重點強化內容輸入區的驗證、規範認證流程，並預先規避潛在的漏洞風險。&lt;/p&gt; 
&lt;p&gt;技術參考框架需與任務需求相匹配。&lt;/p&gt; 
&lt;p&gt;根據不同任務選擇不同的專業人設：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;後端系統："具備分佈式系統專業知識的高級後端工程師"&lt;/li&gt; 
 &lt;li&gt;安全模塊："熟悉 OWASP 規範的安全架構師"&lt;/li&gt; 
 &lt;li&gt;基礎設施："專攻雲原生解決方案的 DevOps 工程師"&lt;/li&gt; 
 &lt;li&gt;前端開發："關注用户體驗且具有無障礙化開發經驗的前端工程師"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種方法利用模型模仿領域專家的能力，使生成的代碼更精準體現特定技術領域的行業最佳實踐。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「扮演高級安全工程師進行代碼審查。用 Python/Django 創建用户註冊系統，需實現合規的密碼處理、輸入驗證功能，並防禦常見 Web 漏洞。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;09 明確編程語言、開發框架或第三方庫的限制條件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;明確説明技術限制條件，才能確保代碼與運行環境完美兼容。首先應清晰説明編程語言版本（例如 Python 3.9、TypeScript 4.5），確保生成的代碼所使用的語言特性在生產環境中可用。同時需指定框架版本及其特定規範，例如"使用 Pydantic v2 模型的 FastAPI 0.95 進行數據驗證"。&lt;/p&gt; 
&lt;p&gt;此外，還要交代清楚：用哪些第三方庫、具體怎麼接入。例如，在請求生成數據庫交互代碼時，應指定使用 SQLAlchemy 等 ORM 還是原始的 SQL queries，並明確數據庫連接的處理要求。摳到這種細節程度，才可以避免生成依賴了不可用的組件或版本不兼容的代碼。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「請使用以下技術棧開發 REST API 接口：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Python 3.9&lt;/li&gt; 
  &lt;li&gt;搭載 Pydantic v2 模型的 FastAPI 0.95 框架&lt;/li&gt; 
  &lt;li&gt;使用 SQLAlchemy 2.0 執行數據庫操作&lt;/li&gt; 
  &lt;li&gt;通過 auth_utils.py 文件中現有 AuthManager 實現 JWT 身份認證&lt;/li&gt; 
  &lt;li&gt;必須兼容 PostgreSQL 13 數據庫」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;&lt;strong&gt;10 實施思維鏈這一提示詞工程技術&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;思維鏈（Chain of thought prompting）通過引導大語言模型進行邏輯推理，可以大大提升代碼生成質量。這個方法的精髓是：讓 AI 先拆解問題再寫代碼。&lt;/p&gt; 
&lt;p&gt;要求模型按這個順序分步思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;用大白話解釋實現思路&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;搭建解決方案的偽代碼框架&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;每個模塊的具體實現邏輯&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;最終完整可運行的代碼成品&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;思維鏈技術對於包含複雜邏輯或數據轉換的算法特別有效。這種方法可以減少邏輯錯誤，提高代碼的一致性，並可視化模型的推理過程，便於在最終代碼生成前進行修正。&lt;/p&gt; 
&lt;p&gt;與側重任務分解的"分步執行"方法不同，思維鏈技術着重於顯性化模型的推理路徑，確保在確認最終方案前保持邏輯的嚴謹性。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;11 針對不同大語言模型（LLM）的特長設計專屬的提示詞策略，以最大化發揮其優勢&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;不同的大語言模型具備各自獨特的優勢，通過針對性的提示詞技巧可以充分發揮它們的潛能。&lt;/p&gt; 
&lt;p&gt;提示詞策略如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;針對上下文窗口有限的模型：聚焦分步算法指導&lt;/li&gt; 
 &lt;li&gt;針對擅長函數式編程的模型：使用函數式思維提問&lt;/li&gt; 
 &lt;li&gt;針對精通某一特定開發框架的模型：直接使用該框架的核心 API、類名或設計模式等特定術語提問，減少解釋成本。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;瞭解模型在訓練過程中接觸的數據集特點是優化提示詞的關鍵。&lt;/strong&gt; 不同的模型因其訓練數據分佈不同，往往只對特定編程範式或語言有更強的理解力。例如，若某模型在訓練中接觸了大量函數式編程內容，那麼當問題本身適合使用函數式編程解決時，用函數式編程術語構建提示詞，將獲得更精準的響應。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;12 指定邊界情況和約束條件&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;全面覆蓋邊界場景能大幅提升代碼健壯性 &amp;nbsp;。技術領域的邊界情況因場景而異，但通常包含臨界值（譯者注：如數值溢出、空輸入）、資源限制（譯者注：如內存耗盡、超時）和異常狀態（譯者注：如網絡中斷、併發衝突）。在向模型發送請求生成代碼時，應明確列出這些要素，例如説明數據處理函數應如何處理空輸入、格式錯誤的數據或超出預期範圍的值。&lt;/p&gt; 
&lt;p&gt;通過預先考慮這些約束條件，生成的代碼可包含與指定限制條件相匹配的驗證邏輯、錯誤處理機制和性能優化方案。&lt;/p&gt; 
&lt;p&gt;示例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「實現一個能處理以下情況的文件處理函數：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;空文件（返回空結果）&lt;/li&gt; 
  &lt;li&gt;超過 1GB 的文件（分塊讀取處理）&lt;/li&gt; 
  &lt;li&gt;格式錯誤的 CSV 數據（記錄錯誤並跳過錯誤行，繼續處理後續有效行）&lt;/li&gt; 
  &lt;li&gt;多進程/線程同時操作同一文件（需加鎖（如文件鎖、數據庫鎖）避免數據競爭）&lt;/li&gt; 
  &lt;li&gt;網絡中斷（需支持斷點續傳）」&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;掌握代碼生成的提示詞工程既是一門藝術，也是一門科學，它能大幅提升開發效率。通過運用這些策略方法，開發者可以將大語言模型（LLM）從簡單的代碼生成工具升級為智能開發助手，從而打造出更健壯、高效且易於維護的軟件系統。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Ayush Thakur&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Developer Advocate | Community Manager | Technical Writer&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;文中提到「重新生成代碼優於修復 Bugs」，你在實際使用「對話式編程」時有這種感受嗎？&lt;/strong&gt; &lt;strong&gt;歡迎在評論區分享~&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文經原作者授權，由&lt;/strong&gt; &lt;strong&gt;Baihai IDP&lt;/strong&gt; &lt;strong&gt;編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpotpie-ai%2Fpotpie%2Fwiki%2FHow-to-write-good-prompts-for-generating-code-from-LLMs" target="_blank"&gt;https://github.com/potpie-ai/potpie/wiki/How-to-write-good-prompts-for-generating-code-from-LLMs&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18426598</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18426598</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>OpenAI 發佈編程 Agent「Codex」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式發佈編程 Agent 產品「Codex」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0e12276316926445f454385b24aee64ca00.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Codex 是一款支持並行處理多個任務的雲端編程 Agent，能夠提供如編程功能、回答代碼庫的問題、修復錯誤等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="750" src="https://static.oschina.net/uploads/space/2025/0519/100634_jTO9_2720166.png" width="1336" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0519/100843_qXsH_2720166.png" width="1190" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Codex 基於 codex-1 模型驅動，OpenAI 方面表示這一模型由 o3 模型針對編程進行優化而得來。codex-1 通過強化學習在各種環境中，對現實世界的編碼任務進行訓練，從而能夠生成接近人類風格和 PR 偏好的代碼。&lt;/p&gt; 
&lt;p&gt;在 OpenAI 自己的代碼評估和內部基準測試中，codex-1 即使沒有 AGENTS.md 文件或自定義腳手架（custom scaffolding）也表現出色。&lt;/p&gt; 
&lt;p&gt;目前，Codex 提供的是研究預覽版。使用方面，OpenAI 將會優先為 ChatGPT Pro 用户、企業或團隊用户提供 Codex，Plus 用户和教育用户也即將能體驗到。&lt;/p&gt; 
&lt;p&gt;另外，OpenAI 還同時公佈了 codex-1 的小號版本，基於專為 Codex CLI 設計的 o4-mini 打造。模型型號為「codex-mini-latest」，API 定價為每百萬輸入 token 1.5 美元，每百萬輸出 token 6 美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多詳細內容查看 Codex 技術報告：&lt;/strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-codex%2F" target="_blank"&gt;https://openai.com/index/introducing-codex/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350557/openai-codex</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350557/openai-codex</guid>
      <pubDate>Sun, 11 May 2025 02:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>又小又快截圖軟件：ScreenCapture（2.2.25）支持截長圖</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img alt="" height="468" src="https://oscimg.oschina.net/oscnet//022b124220ead36d2a012eb7f97857ce.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;ScreenCapture&amp;nbsp;截圖工具&amp;nbsp;&lt;strong&gt;體積小（8M 左右）&lt;/strong&gt;、僅一個可執行文件，無需安裝，不依賴任何動態鏈接庫。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;運行速度快、內存佔用低、CPU 使用率低。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;開源地址：&lt;a href="https://gitee.com/horsejs_admin/ScreenCapture"&gt;https://gitee.com/horsejs_admin/ScreenCapture&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;近 9 個版本的更新內容如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增強：改進繪製標號元素的用户體驗： 
  &lt;ul&gt; 
   &lt;li&gt;鼠標按下即繪製一個默認大小的標號；&lt;/li&gt; 
   &lt;li&gt;設置獨立的移動標號元素的 Dragger（標號正中心）；&lt;/li&gt; 
   &lt;li&gt;設置獨立的改變大小的 Dragger；&lt;/li&gt; 
   &lt;li&gt;設置獨立的改變箭頭位置的 Dragger；&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;增強：允許通過命令行控制工具欄各個按鈕的位置、是否顯示等： 
  &lt;ul&gt; 
   &lt;li&gt;指令：--tool:"rect,ellipse,arrow,number,line,text,mosaic,eraser,|,undo,redo,|,pin,clipboard,save,close"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;增強：截長圖/滾動截圖指令：--cap:long&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="592" src="https://oscimg.oschina.net/oscnet/up-48430184c33cb5918d43692c1d91214b88b.png" width="1016" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復：跨屏截圖在特殊情況下無法覆蓋全屏區域的問題。&lt;/li&gt; 
 &lt;li&gt;修復：工具欄按鈕顯示 tool tip 時，有時會導致 Hover 樣式失效。&lt;/li&gt; 
 &lt;li&gt;修復：&lt;span style="background-color:#ffffff; color:#1f2328"&gt;--tools 指令傳入的按鈕與實際所能控制的按鈕不符時，導致按鈕出現錯亂的問題。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;修復：&lt;/span&gt;繪製標號①，再 undo 此標號，再繪製新的標號，標號數字應該還是①，不應該是②。&lt;/li&gt; 
 &lt;li&gt;修復：undo 元素之後，再繪製新元素時應該先刪除 undo 的元素。&lt;/li&gt; 
 &lt;li&gt;修復：主工具條位於截圖區域內部或截圖區域頂部時，顯示子工具條，子工具條位置不準確的問題。&lt;/li&gt; 
 &lt;li&gt;修復：Ctrl+H 與 Ctrl+R 快捷鍵的行為搞反了的問題&lt;/li&gt; 
 &lt;li&gt;修復：工具條位置不準的問題（工具條不會自動尋找剩餘空間定位）。&lt;/li&gt; 
 &lt;li&gt;修復：在 Win11 下無法通過命令行釘住剪切板內的圖像的問題&lt;/li&gt; 
 &lt;li&gt;優化：保存文件，點擊文件保存對話框的取消按鈕，應用不應退出。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化：繪製元素時優先使用紅色。繪製箭頭、標號元素時默認使用填充效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/350353/screen-capture-2-2-25</link>
      <guid isPermaLink="false">https://www.oschina.net/news/350353/screen-capture-2-2-25</guid>
      <pubDate>Fri, 09 May 2025 02:28:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
  </channel>
</rss>
