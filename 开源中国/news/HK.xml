<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 19 Feb 2025 07:37:03 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>百度 Q4 業績會實錄：DeepSeek 讓我們明白要將最優秀的模型開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度昨天&lt;a href=&quot;https://www.oschina.net/news/334611&quot;&gt;發佈&lt;/a&gt;了截至 12 月 31 日的 2024 年第四季度及全年財報。第四季度，營收為 341 億元，同比下滑 2%。屬於百度的淨利潤為 52 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 67 億元。整個 2024 年，總營收為 1331 億元，同比下滑 1%。歸屬於百度的淨利潤為 238 億元。不按美國通用會計準則，歸屬於百度的淨利潤為 270 億元。&lt;/p&gt; 
&lt;p&gt;財報發佈後，百度董事長兼 CEO 李彥宏，移動生態事業羣總裁羅戎，智能雲事業羣總裁沈抖，代理 CFO 何俊傑等高管出席隨後召開的財報電話會議，解讀財報要點並回答分析師提問。&lt;/p&gt; 
&lt;p&gt;以下是分析是問答環節主要內容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;花旗銀行分析師 Alicia Yap&lt;/strong&gt;：DeepSeek 最近備受關注，百度也宣佈即將開源文心大模型 4.5 系列，並且將免費提供使用。請問管理層，此舉背後的戰略考量是什麼？另外，我們如何看待當前基礎模型領域的競爭格局？百度計劃如何在這個不斷演變的市場中保持領先地位？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：生成式人工智能和基礎模型市場仍處於初期階段，但發展速度極快，DeepSeek 的成功案例肯定會加快基礎模型的應用速度。隨着基礎模型變得更容易獲取且成本降低，我們正進入一個真正的變革階段，我們會看到新的人工智能應用和使用案例在數量上呈爆發式增長，這將為所有人帶來巨大的機遇，並拓展人工智能的邊界，增加更多可能性。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;從 DeepSeek 我們學到一點，那就是將最為優秀的模型開源供所有人使用，將可以極大地推動其應用，因為大家出於好奇自然會想去嘗試開源模型，進而推動其更廣泛的應用。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 早期版本將是我們有史以來最出色的模型，我們希望用户和客户試用起來能比以往更容易，更輕鬆。我們決定將 4.5 早期系列進行開源，也源於對自身技術領先地位的堅定信心，這種信心源自我們數十年在研發方面的持續投入、不斷的技術創新，以及我們作為全球為數不多具備全棧人工智能能力公司之一的獨特地位。&lt;/p&gt; 
&lt;p&gt;文心一言已經展現出強大的市場吸引力，日 API 調用量在短短一年內從 5000 萬激增至 16.5 億。通過開源，我們相信更多開發者和用户將認識到文心一言的真正價值，推動其更廣泛應用，並擴大其在更多場景中的影響力。&lt;/p&gt; 
&lt;p&gt;同樣，將文心一言機器人免費提供使用，能讓更多用户在同等條件下將我們的基礎模型與其他模型進行比較，尤其是其他模型收費而我們不收費的情況。我們上次對文心大模型進行重大升級是在 2023 年 10 月，距今已有很長時間，所以，未來幾個月大家敬請期待文心大模型的 4.5 版本。&lt;/p&gt; 
&lt;p&gt;話説回來，我也想強調一個關鍵的重點。無論開源還是閉源，基礎模型只有在能夠大規模有效解決現實世界問題時才真正有價值，我們致力於以應用為導向，持續迭代文心大模型。秉持這種理念，自推出以來，我們一邊利用文心大模型升級內部產品，一邊服務企業客户。&lt;/p&gt; 
&lt;p&gt;藉助文心大模型成功改造了百度面向消費者的產品，如百度搜索和百度文庫；此外，通過千帆平台，我們正在提升企業客户的模型和應用開發體驗。文心一言在指令遵循、先進的檢索增強生成技術（該技術將幻覺問題降至最低）等方面的行業領先能力，使其在各種場景中得到廣泛應用。千帆平台的綜合工具鏈讓我們的客户能夠針對自身應用場景定製任何模型。展望未來，我們將瞄準性能提升和成本削減的潛力，加快文心大模型的迭代，繼續在對現實世界影響潛力最大的領域對其進行開發。我們對人工智能發展的新篇章感到興奮，期待看到人工智能技術帶來更多具有開創性且對社會有持久價值的應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;高盛分析師 Lincoln Kong&lt;/strong&gt;：我有一個關於公司搜索業務的問題。在經歷了最近幾個季度的搜索改版後，我們應該如何看待未來的調整或變化？目前生成式人工智能結果在搜索結果中的佔比是多少，我們的目標佔比又是多少？另外，隨着人工智能整合的不斷深入，鑑於像 Deepseek 和豆包這樣的人工智能聊天機器人也具備搜索功能，能否分享更多關於用户指標方面的信息？您如何看待百度搜索與這些人工智能聊天機器人之間的競爭態勢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：目前，約 22% 的搜索結果頁面包含人工智能生成的內容，但幕後還有更多的工作在進行，我們正在從根本上對搜索服務進行了變革，使其比以往任何時候都更強大、更高效。就像李彥宏在事先準備好的發言中提到的，藉助文心一言，我們將搜索範圍從文本和鏈接擴展到提供多樣化的內容形式，包括短視頻、直播、智能助理筆記和商品展示。這些不同的形式可以動態組合，創造出個性化的搜索體驗。在持續改革搜索產品的過程中，我們也在開發能實現更深度個性化的功能，以適應每位用户的習慣和偏好。&lt;/p&gt; 
&lt;p&gt;我們的努力帶來了更好的用户使用效果，包括在每月使用百度進行搜索的活躍用户中，83% 的用户會與生成式人工智能進行內容互動。更令我們倍受鼓舞的是，12 月百度應用上每位用户的搜索查詢量同比增長了 2%。我們專注於不斷提升用户體驗，考慮到用户參與度日益積極，我們也會擴大人工智能的作用。&lt;/p&gt; 
&lt;p&gt;在此基礎上，我可以同大家分享一個文心一言智能助理如何在剛剛過去的春節假期為我們的廣告客户創造價值的案例。春節期間，許多中小企業放假一週，但某些行業的客户需求卻達到高峯。我們的文心一言智能助理有效地彌補了這一缺口。例如，一家助聽器公司因為家庭團聚，子女關心年邁父母的健康需求，諮詢量有所增加，但該公司的客服團隊因放假不在崗。通過文心一言智能助理，該公司有效地識別並篩選出高度相關的銷售線索，使其即便在假期人員減少的情況下，也能高效跟進並無縫服務客户。&lt;/p&gt; 
&lt;p&gt;關於你提到的人工智能聊天機器人與搜索的問題，我們認為，由基礎模型驅動的人工智能革命仍處於非常早期的階段。無論是像 Deepseek 這樣原生的人工智能工具，還是我們基於人工智能的產品，這些努力都代表了探索人工智能潛力的不同方式。作為擁有數億用户的中國搜索市場領導者，我們通過採用最優秀的創新成果並融入真正創新的人工智能功能，保持靈活性和全面的市場視野。百度將繼續引領人工智能變革，為我們龐大的用户羣體提升搜索體驗。&lt;/p&gt; 
&lt;p&gt;此外，搜索本質上深深紮根於語言和文本理解，這與大語言模型的能力完美契合，使我們能夠在人工智能賦能的搜索變革中佔據領先地位。我們相信，搜索正在演變成一個集成平台，它超越了人工智能驅動的探索階段，不僅能提供智能答案，還能引導用户完成整個流程，從尋找答案、進行深入分析、完成任務，最終提供全面的服務和解決方案。&lt;/p&gt; 
&lt;p&gt;雖然人工智能驅動的探索是人工智能應用開發的一個重要但仍處於早期發展的階段，目前尚未出現具有決定性影響力的應用程序，而對我們來説，關鍵是要保持這種快速且堅定的發展態勢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根大通分析師 Alex Yao&lt;/strong&gt;：能否請管理層談談 2025 年第一季度和 2025 年全年核心廣告業務的增長前景？支撐這些預測的宏觀假設是什麼？我們看到業務在 2024 年第四季度觸底並開始復甦。最後一個問題是，生成式人工智能搜索的潛在盈利機會有哪些，預計何時能實現盈利？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;羅戎&lt;/strong&gt;：過去幾個月，我們看到各類支持政策相繼出台，比如貨幣寬鬆政策、財政政策以及貿易政策。我們相信這些舉措最終會推動經濟增長，但它們需要時間才能產生效果。鑑於百度的廣告業務與中小企業高度相關，而中小企業對宏觀經濟狀況尤為敏感，再加上競爭環境持續嚴峻，儘管短期內可能面臨壓力，我們還會繼續利用基礎模型對搜索進行變革，這些工作正在穩步推進。正如我們在事先準備的發言稿中提到的，相信這種人工智能變革將持續提升用户體驗，並創造新的可能性。&lt;/p&gt; 
&lt;p&gt;本季度，我們進一步深化了搜索在人工智能方向的變革，用户指標也出現了令人鼓舞的改善。我們認為這將推動收入增長，並在長期內開啓新的盈利機會。此外，我們尚未大規模實現人工智能生成搜索結果的盈利，目前這類結果約佔總查詢量的 22%，而一旦我們的人工智能驅動搜索功能得到充分優化，我們將憑藉更高質量的用户產品推進盈利進程。基於這些因素，我們看到了未來增長的機會，判斷我們的廣告業務正在觸底。我們預計業務未來將逐步改善，今年上半年的表現會好於第四季度，下半年相比上半年會有進一步提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;摩根士丹利分析師 Gary Yu&lt;/strong&gt;：我的問題是關於人工智能雲服務的。鑑於公司人工智能雲業務增長強勁，我們能否期待該業務能夠在 2025 年繼續保持良好的發展態勢？在收入和盈利能力方面，其主要驅動因素是什麼？另外，管理層能否分享一下對 2025 年人工智能雲市場的展望？我們應如何看待企業雲服務需求？人工智能又給這一領域帶來了哪些新增機會？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;沈抖&lt;/strong&gt;：正如李彥宏前面提到的，我們人工智能雲業務的收入在 2024 年第四季度同比增長加速至 26% ，推動 2024 年全年收入增長 17%。值得注意的是，2024 年與生成式人工智能相關的收入同比增長近兩倍，這一增長得益於對文心一言和人工智能基礎設施的需求不斷上升，以及市場對百度在技術方面的領導力高度認可。因此，我們成功吸引了多樣化的客户羣體，並建立了強大的潛在業務渠道。&lt;/p&gt; 
&lt;p&gt;在人工智能基礎設施方面，我們已與多個行業建立合作關係，涵蓋互聯網、汽車、智能設備、製造業、能源、金融、公用事業以及眾多人工智能生成內容初創企業。我們的客户羣體持續健康增長，在大中型客户中均取得顯著進展，這表明我們在中國雲市場的份額正在不斷擴大。&lt;/p&gt; 
&lt;p&gt;通過千帆大模型平台，我們為市場提供具有行業領先性價比的全面基礎模型。我們推出了從旗艦版到輕量版的文心大模型系列，旨在滿足各種不同的需求。除了文心大模型，我們還提供廣泛的優質第三方基礎模型，包括 DeepSeek V3 和 R1 模型。得益於百度的全棧人工智能能力和端到端優化，我們能夠確保平台上託管的任何模型都具備最佳性能和穩定性，同時保持極具競爭力的價格。此外，我們還提供一整套用於微調模型和構建原生人工智能應用程序的工具，客户能夠輕鬆制定滿足自身特定需求的解決方案。&lt;/p&gt; 
&lt;p&gt;關於人工智能雲市場展望的問題，我們認為未來將迅速增長。一方面，在最近的春節假期期間，大語言模型成為了廣泛討論的話題，這不僅進一步提高了公眾對基礎模型的認知度，還促使更多人深入思考如何利用這些模型來提升自身業務。另一方面，我們相信基礎模型的性能將不斷提升，而成本會穩步下降，這無疑將進一步降低使用這些模型的門檻。因此，我們認為更多企業會將基礎模型整合到從研發到生產的業務運營各個環節，從而推動 API 調用量的顯著增長。&lt;/p&gt; 
&lt;p&gt;我們也預計百度人工智能雲服務的支出將會增加，因為過去我們已經觀察到一個明顯的趨勢：通過千帆大模型平台的 API 調用而使用基礎模型的客户，也傾向於增加在我們人工智能雲服務上的支出。在利潤方面，由於我們專注於符合戰略重點的高價值機會，推動了穩健的可持續增長，我們 2024 年第四季度非通用會計準則下的運營利潤率持續同比擴大。展望 2025 年，我們有信心人工智能雲業務收入增長將保持強勁勢頭，同時繼續產生正的運營利潤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;瑞銀證券分析師 Wei Xiong&lt;/strong&gt;：我想問一下利潤率趨勢的問題。鑑於核心廣告業務近期面臨的壓力以及雲業務收入佔比的不斷增加，我們應該如何看待 2025 年第一季度和全年的核心利潤率水平？在運營效率方面還有進一步優化的空間嗎？另外，公司全年有哪些投資計劃？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：儘管面臨短期壓力，但對於人工智能領域的戰略投資將產生更為可持續的影響方面，我們仍然非常樂觀。我們始終專注於提升業務運營各方面的韌性，並且在各項業務中都看到了令人鼓舞的進展。&lt;/p&gt; 
&lt;p&gt;首先，對於我們的在線營銷業務，預計受到人工智能生成搜索結果和技術變現計劃的推動，以及百度在捕捉增長機遇方面的準備和市場宏觀環境的改善，我們的廣告收入將逐步提升。其次，我們的人工智能雲業務已經展現出強勁的增長，隨着市場份額的不斷擴大，以及我們在自主研發獨特全層級人工智能架構和全棧人工智能能力方面的競爭優勢，利潤率得到持續改善，因此，我們有信心在未來保持這一強勁勢頭。第三，對於我們的智能駕駛業務，尤其是蘿蔔快跑，我們將繼續致力於通過提高運營效率和改善單位經濟效益來縮小虧損，我們也在探索創新的運營模式，包括輕資產模式。&lt;/p&gt; 
&lt;p&gt;關於你問到 2025 年的投資與優化情況，我們將保持對高增長機遇的最優資源配置，同時與我們的長期戰略保持一致。我們的投資將繼續聚焦於那些既擁有巨大未來機遇，又具備強大投資回報率潛力的項目，包括進一步提升盈利能⼒、深化搜索業務的人工智能轉型、增強我們的人工智能雲產品，以及拓展我們的自動駕駛項目。在推進這些項目的過程中，我們將繼續致力於提高運營效率，促進各業務集團之間的協同效應，以最大限度地發揮這些戰略投資的影響力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;美銀美林分析師 Miranda Zhuang&lt;/strong&gt;：我有一個關於蘿蔔快跑業務的問題。管理層能否介紹一下 2025 年該業務的進展情況，包括車隊規模目標、能夠貢獻哪些獨特的經濟效益，以及業務的價值主張是什麼？管理層認為行業目前處於什麼階段？我們是否正在接近一個轉折點？鑑於國內自動駕駛出租車市場上的競爭對手正在與汽車製造商和打車平台合作，採用生態系統戰略，管理層對於接下來該行業的競爭態勢有何看法？請問百度的競爭和規模化策略是什麼？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李彥宏&lt;/strong&gt;：我們在自動駕駛技術領域已經投入了十多年，通過蘿蔔快跑，我們將宏偉願景變為了現實，確立了公司在自動駕駛技術領域的全球領先地位。中國的自動駕駛市場環境是非常具有挑戰性的，由於中國人口眾多、路況多樣、交通場景動態變化以及城市佈局繁複，其交通狀況是非常複雜的，而在中國乘坐自動駕駛出租車的價格約為美國的七分之一。因此，我們在中國的成功運營展示了百度卓越的技術和運營能力，包括我們所設計的全新第六代量產無人車 RT6，是世界上有史以來最具成本效益的自動駕駛出租車。憑藉我們的這些優勢，這一商業模式得到成功驗證，併為進一步規模化發展和全球擴張奠定了堅實基礎。&lt;/p&gt; 
&lt;p&gt;在第四季度，蘿蔔快跑在全國範圍內提供了約 110 萬次出行服務，同比增長 36%。到 1 月份，向公眾提供的累計出行服務次數已超過 900 萬次。此外，正如我之前提到的，我們在中國實現了 100% 完全無人駕駛運營，這意味着車輛上不再配備安全員，這是一個新的行業標杆，鞏固了我們在該領域的領先地位。正如我之前提到的，去年 11 月，自動駕駛業務獲得批准在香港開始開放道路測試，這是非常重要的一步，因為香港是我們首個右舵駕駛和靠左行駛的交通市場。這表明我們有能力使自動駕駛技術適應不同的交通系統，為拓展到其他具有類似駕駛設置的市場打開了大門。&lt;/p&gt; 
&lt;p&gt;今年對我們的業務拓展至關重要，隨着業務的推進，預計車隊規模和出行服務量的增長速度將超過以往任何時候。同時，我們也在積極尋找合作機會，我們已經確定了各種潛在合作伙伴，包括出行服務提供商、當地出租車公司、第三方車隊運營商以及其他潛在合作伙伴，這種輕資產模式將使我們能夠高效擴大規模，同時保持靈活性。通過與不同類型的合作伙伴合作，我們旨在加強市場地位，讓更多人體驗到自動駕駛服務。從更廣闊的市場來看，正如我在上次財報電話會議中提到的，由於市場仍處於起步階段，競爭實際上有助於加速市場發展，並營造更有利於創新的監管環境。在這個不斷增長的市場中，我們的使命始終明確，那就是為更多用户提供更安全、便捷和舒適的出行體驗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;傑富瑞分析師 Thomas Chong&lt;/strong&gt;：展望 2025 年，百度業務投資的戰略重點會是什麼？具體而言，資源將如何在搜索、自動駕駛、雲服務和基礎模型之間分配？此外，管理層對 2025 年全年的資本支出以及股東回報有何展望？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何俊傑&lt;/strong&gt;：在評估 2025 年的資本配置選項時，我們的方法基於以下戰略考量。我們將繼續把提升人工智能能力作為長期戰略重點進行投資。在此基礎上，我們將進一步深化全產品線的人工智能轉型，尤其是搜索業務。在人工智能雲業務方面，我們旨在推動企業客户採用我們的人工智能基礎設施、飛槳（PaddlePaddle）深度學習平台以及文心一言，滿足他們對人工智能產品和解決方案以及人工智能雲服務日益增長的需求。在智能駕駛方面，我們專注於擴大國內業務規模，探索創新運營模式，並拓展國際業務。&lt;/p&gt; 
&lt;p&gt;在確保嚴格的投資回報率管理和有效控制資本支出損失的同時，有兩個關鍵優先事項驅動我們的決策，那就是強化我們的技術領先地位，以及加速人工智能產品和人工智能雲服務在不同行業的應用。至於你問到的股東回報，自 2024 年初以來，我們的股票回購金額已超過 10 億美元，這顯著高於 2023 年全年的回購總額。對於截至 2025 年 12 月，規模為 50 億美元的股票回購計劃，我們總計已回購 17 億美元。展望未來，作為持續回報股東長期信任的舉措之一，我們計劃加快股票回購計劃的推進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334727</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334727</guid>
            <pubDate>Wed, 19 Feb 2025 07:17:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技申請春晚機器人圖形商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，2 月 5 日，杭州宇樹科技有限公司申請註冊一枚「春晚機器人」樣式圖形商標，國際分類為廚房潔具，當前商標狀態為等待實質審查。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc4fda9d3052fe48a476a7f163206880819.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;杭州宇樹科技有限公司成立於 2016 年 8 月，法定代表人為王興興，註冊資本約 259 萬人民幣，並已於 2024 年完成了 C 輪，交易金額數億人民幣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;經營範圍包括智能機器人的研發、智能機器人銷售、工業機器人制造、工業機器人銷售等，由王興興、漢海信息技術（上海）有限公司、寧波紅杉科盛股權投資合夥企業（有限合夥）等共同持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，宇樹科技有四足機器狗和通用人形機器人兩大系列產品。在創業早期，宇樹科技以四足機器狗起家，第一款產品為 XDog。隨後，Laikago、AlienGo、A1、Go1、B1 等一系列機器狗產品相繼研發問世，推出市場。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334724</guid>
            <pubDate>Wed, 19 Feb 2025 07:15:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Wasmer 6.0 Alpha 1 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Wasmer 6.0 首個 Alpha 已發佈。此版本主要變化是&lt;strong&gt;支持同時啓用多種異構後端&lt;/strong&gt;。例如，在同一個二進制發佈版本中可以啓用 llvm、v8 和 wamr 後端。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5214fb7c60b85030a206656f1d74f66fe46.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Wasmer 6.0 Alpha 1 還通過了 LLVM 為 linux-x64、linux-aarch64 和 macOS 增加了異常處理提案的初步支持，這種 WASM 異常處理依賴於 LLVM 後端，此外還包含 WASIX 進程創建改進以及各種其他修復/增強。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Wasmer 是支持 WASI 和 Emscripten 的通用 WebAssembly 運行時，提供基於 WebAssembly 的超輕量級容器，專注於支持在任何平台上運行 WASM 代碼：從桌面端到雲端、以及 IoT 設備，並且能嵌入在任何編程語言中。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2023/0627/173716_02s8_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Wasmer 憑藉其多樣化的支持和專注於從通用桌面應用程序到 「便攜式 ML/AI 應用程序」 的領域，目前仍然是領先的 WASM 運行時之一。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下載 Wasmer 6.0 Alpha 1 及更多詳細信息，請訪問&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwasmerio%2Fwasmer%2Freleases%2Ftag%2Fv6.0.0-alpha.1&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334721/wasmer-6-0-alpha-1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334721/wasmer-6-0-alpha-1</guid>
            <pubDate>Wed, 19 Feb 2025 07:03:35 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Omdia：2029 年電信 IT 人工智能軟件市場達 50 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究機構 Omdia 最新發布了一份《電信 IT 人工智能市場預測》報告，展示了 Omdia 對於在跟蹤的電信 IT 軟件的五個主要產品類別中 AI 所佔價值的估算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Omdia 觀點：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們估計，2023 年，電信 IT 軟件中 AI 的價值為 18 億美元，而且我們預測，到 2024 年底，其價值會達到 23 億美元。從 2024 年至 2029 年，整體價值會以 17% 的複合年增長率（CAGR）增長，達到 50 億美元。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;233&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-175f0c5940f60ad73ea3821a680982bf8f1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;預測性 AI 將佔整個預測期中大部分價值，於 2029 年達到總價值的 76%。在預測期期間，預測性 AI 將以 13% 的 CAGR 增長。然而，生成式 AI 會增長得更快，CAGR 為 37%，到 2029 年佔電信 IT 軟件中 AI 價值的 24%。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本預測的前幾年將由自動化和相關用例驅動，相比於預計到預測期末會更普遍的推薦和預測用例，這些用例相對價值更低。消費者互動和網絡管理將佔大部分的增長，因為 AI 已經在這些細分市場獲得關注，也正在推動運營效率提升，CSP 可以在此基礎上再接再厲。在沒有 AI 益處的情況下，分析已經能夠完成很多任務，所以其增長會稍慢一點。目前 AI 對於創收和服務管理的作用更加受限，並且我們預測，在預測期期間這些細分市場的增長最低。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334718</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334718</guid>
            <pubDate>Wed, 19 Feb 2025 06:54:09 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 年中國在開源人工智能模型領域的崛起和變革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;報告地址：&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
&lt;p&gt;在第二章《TOP 101-2024 大模型觀點》中，Hugging Face 工程師 &lt;strong&gt;Tiezhen&lt;/strong&gt;、Hugging Face 中文社區項目經理 &lt;strong&gt;Adina &lt;/strong&gt;以及 Hugging Face Fellow &lt;strong&gt;Lu Cheng&lt;/strong&gt;，從崛起與變革兩個維度，探討中國開源模型在 2024 年取得的重大成就和未來展望：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國在開源人工智能模型領域從 「追隨者」 到 「引領者」 轉變，體現技術實力且反映人工智能生態系統快速完善。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國學術界和產業界推進自主研發，在技術創新和模型能力上飛躍，多款自主研發模型在國內外評測表現卓越。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Qwen 系列因多尺寸選項、多語言支持及友好授權功能獲高度評價；DeepSeek 引入 MLA 技術實現性能成本突破；智譜 CogVideoX 系列成全球首批開源文生視頻模型之一。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型從質疑中崛起獲廣泛認可，其成功得益於政府支持與行業鉅額投入，中國人工智能生態體系迅速完善，未來可能在全球佔更核心地位。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隨着開源模型影響力提高，中國開源社區活躍度提升，企業、研究機構、個體開發者積極參與，如 Qwen 系列被廣泛集成促進交流協作，智源研究院等機構建立協作機制貢獻基礎工作和資源。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2024 年中國開源社區湧現高質量自發研究成果，如 MAP 團隊的 Map Neo、InstantX 團隊的 InstantID，為中國模型贏得國際認可。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國在推動人工智能技術發展同時建立完善透明治理機制，如《人工智能示範法 2.0（專家建議稿）》《生成式人工智能服務管理暫行辦法》，為開源模型發展提供穩定政策環境並確保技術應用符合社會價值導向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;端上模型興起，中國 AI 社區推出多款移動友好型模型，如 Qwen2 - 1.5B 等，雖有挑戰但代表 AI 技術隱私保護和成本優化未來方向。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源社區在邏輯推理領域推出創新項目，如 Macro - o1、QwQ 等，通過開源策略分享研究細節，推動小模型推理能力提升與行業技術進步。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中國開源模型發展從 「百模大戰」 邁向多元化和深度細分，發佈大量高質量開源模型，涵蓋多模態理解與生成等多個領域，模型競爭轉向應用場景細化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/135245_kWl7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;完整全文：&lt;a href=&quot;https://my.oschina.net/u/3859945/blog/17503717&quot; target=&quot;_blank&quot;&gt;https://my.oschina.net/u/3859945/blog/17503717&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334705</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334705</guid>
            <pubDate>Sat, 08 Feb 2025 05:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 將在 4 月底舉辦首屆 AI 開發者大會 LlamaCon</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llama.com%2Fevents%2Fllamacon%2Fsignup%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;將在今年 4 月 29 日舉行首屆 LlamaCon——專門面向生成式人工智能的開發者大會。大會的名字源於 Meta 的開源 AI 模型 Llama 系列。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-26ace593ef0174eac7b8b3e6bcbe581ade6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Meta&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Ffuture-of-ai-built-with-llama%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，隨着開源 Llama 模型和工具集合的空前增長和發展勢頭強勁，公司決定於 4 月 29 日舉行首屆專門面向 AI 領域的開發者大會 LlamaCon。他們將&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在大會上分享開源 AI 發展的最新動態，來幫助開發者構建「令人驚歎的應用和產品」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;在接下來的幾周裏，Meta 也將公佈更多與 LlamaCon 有關的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在 1 月底的財報説明會上，扎克伯格曾表示，Llama 4 的目標是引領（市場），具備原生的多模態能力。他當時也暗示 Llama 4 最早也要到今年二季度才會發佈，所以 4 月 29 日會是一個較為合適的日期。&lt;/p&gt; 
&lt;p&gt;留出兩個月的時間，也給 Meta 公司帶來了不確定性。目前 OpenAI 已經確認會在近期發佈 GPT-4.5、Anthropic 也被爆料將在「數週內」發佈混合 AI 模型 Claude 4。&lt;/p&gt; 
&lt;p&gt;最令 Meta 忌憚的是，DeepSeek 是否會在未來兩個月裏搞出更多的「大新聞」。&lt;/p&gt; 
&lt;p&gt;據報道，在 DeepSeek 發佈 R1 模型之後，Meta 迅速組建了四個「戰情室」，核心憂慮是 DeepSeek 的最新大模型可能會比 Llama AI 的下一代版本更強。&lt;/p&gt; 
&lt;p&gt;知情員工透露，四個「戰情室」中有兩個負責研究 DeepSeek 如何降低訓練和運行 AI 模型的成本，並將心得用於訓練 Llama。另外兩個團隊，負責嘗試找出 DeepSeek 用於訓練的數據，以及如何將中國 AI 的先進訓練方法用於重構 Meta 自己的產品。&lt;/p&gt; 
&lt;p&gt;在分析師電話會議上，扎克伯格曾表示：「他們（DeepSeek）做了一些新穎的事情，我認為我們仍在消化中。他們取得的一些進展，我們希望在我們的系統中應用，這就是開源世界運作的本質。」&lt;/p&gt; 
&lt;p&gt;與此同時，扎克伯格也已經宣佈，今年將在人工智能相關的項目上投資 600-650 億美元，包括建設一個超大型數據中心和更多的人才招聘。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334689/meta-llamacon-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334689/meta-llamacon-2025</guid>
            <pubDate>Sat, 08 Feb 2025 04:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 前 CTO 官宣新創業 AI 公司，團隊成員多來自 OpenAI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 前 CTO Mira Murati 今天凌晨&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmiramurati%2Fstatus%2F1891918876029616494&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;創立了新的 AI 公司 Thinking Machines Lab（思維機器實驗室）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d07fc6d37ca4e1534888a3ca6098802c5d2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthinkingmachines.ai%2F&quot; target=&quot;_blank&quot;&gt;官網寫道&lt;/a&gt;，公司將專注於構建人工智能（AI）模型和產品，以支持更多、跨工作領域的「人類-AI 協作」，「雖然當前的系統擅長編程和數學，但我們正在構建能夠適應人類所有專業知識並實現更廣泛應用的人工智能。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;他們還強調這會是一家重視研究開放的公司，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fthinkymachines%2Fstatus%2F1891919141151572094&quot; target=&quot;_blank&quot;&gt;其推文中承諾&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我們致力於通過論文發表和代碼發佈來開放科學，同時會重點關注應用於不同領域的人機協作。我們的方法包括共同設計研究和產品，以便從實際部署和快速迭代中學習。這項工作需要三個核心基礎：&lt;strong&gt;SOTA 的模型智能、高質量的基礎設施和先進的多模態能力&lt;/strong&gt;。我們致力於構建處於能力領先的模型來兑現這一承諾。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;該公司官方網站對這三核心基礎進行了展開説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;模型智能是基石。除了強調人機協作和定製之外，模型智能也至關重要，我們正為科學和編程等領域構建前沿能力模型。最終，最先進的模型將解鎖最具變革性的應用和優勢，例如實現新穎的科學發現和工程突破。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基礎設施質量是重中之重。研究生產力至關重要，在很大程度上取決於基礎設施的可靠性、效率和易用性。我們的目標是長期正確地構建事物，以最大限度地提高生產力和安全性，而不是走捷徑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;先進的多模態能力。我們認為多模態對於實現更自然、更高效的通信、保存更多信息、更好地捕捉意圖以及支持與現實環境的更深入集成至關重要。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;官網貼出了公司 29 人團隊名單，其中超過 20 人有在 OpenAI 供職的經驗。其中較為知名的有 OpenAI 聯合創始人約翰·舒爾曼（John Schulman），他正擔任新公司的首席科學家。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334684</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334684</guid>
            <pubDate>Sat, 08 Feb 2025 03:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有所謂的 1875 紀元，美國 150 多歲老人領社保福利不是 COBOL 語言的鍋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期，一位美國政府官員曾宣稱：「我們這裏有些人看起來都已經 150 歲了」，並指出這些人正在領取社會保障福利。由此，有人開始流傳這樣一種説法：社會保障局（SSA）在存儲日期時使用了一個 1875 年的紀元，把那些未知出生年份的記錄存為 0，從而默認顯示為 1875 年。&lt;/p&gt; 
&lt;p&gt;這種觀點的起源可以追溯到某個帖子，帖子中有人調侃道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「看起來埃隆那羣天才程序員根本就不懂 COBOL 的工作原理。社會保障系統正是運行在 COBOL 上，而 COBOL 並沒有專門的日期或時間類型。於是日期就以數字形式存儲，按照 ISO 8601 標準計算，紀元定在了 150 年前（1875 年）——也就是米制標準的開始。結果如果不知道某個日期，就會存儲成 0，而在 COBOL 中這就會默認解析為 1875 年，也就是 150 年前。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;1668&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112214_BPqK_3820517.png&quot; width=&quot;1198&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然而，筆者對此並不認同，主要基於以下幾點理由：&lt;/p&gt; 
&lt;h2&gt;數據庫中存在 1875 年前的出生年份&lt;/h2&gt; 
&lt;p&gt;2007 年，社會保障局曾發佈過一份數據集，該數據集包含了在 2007 年 1 月之前發放的社會保障號碼持有者的收入記錄（約佔全部數據的 1%）。在這份數據集中，他們明確説明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;移除了出生年份早於 1870 年的 5,935 條記錄&lt;/li&gt; 
 &lt;li&gt;移除了出生年份等於 2007 的 1,096 條記錄&lt;/li&gt; 
 &lt;li&gt;以及少數缺失出生年份的記錄&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這表明，SSA 的數據庫中確實保存了 1875 年前（甚至 1869 年及更早）的出生年份數據，並非將未知年份一律默認為 1875。&lt;/p&gt; 
&lt;h2&gt;數據中沒有 1875 年出生人數激增的異常&lt;/h2&gt; 
&lt;p&gt;如果系統將所有未知出生年份的記錄默認轉換為 1875 年，那麼在統計數據中，1875 年的出生人數應該會異常增多。但實際上，從公開數據來看，並不存在這樣一個「高峯」。（注：該數據集只是 1% 的樣本，若存在默認值問題，趨勢應當更加明顯。）&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;698&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0219/112303_XwHt_3820517.png&quot; width=&quot;1174&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;社會保障局並未使用 ISO 8601 標準存儲日期&lt;/h2&gt; 
&lt;p&gt;負責跟蹤社會保障福利支付的主記錄（Master Beneficiary Record, MBR）建立於 1962 年，這遠早於 ISO 8601 標準於 1988 年的發佈。即便是其前身 ISO 2016 標準也在 1976 年發佈，並且並沒有任何依據指向 1875 年。實際上，有研究論文基於 SSA 數據指出，SSA 對生日等信息的存儲採用的是固定寬度格式，而不是 ISO 8601 標準的日期字符串格式。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;The data abstracted from the MBR consisted of a 26-character record for each deceased individual. The four data items on each record were… the month and year of death&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ISO 8601 標準本身並不涉及紀元概念&lt;/h2&gt; 
&lt;p&gt;ISO 8601 僅僅是一種用於表示日期和時間的字符串格式，其本質並不是基於數字計算時間流逝，因此根本無需設定一個「紀元」。雖然 ISO 8601:2004 版曾固定引用 1875 年 5 月 20 日——即《米制公約》在巴黎簽署的那一天——作為參考日期，但這一引用在 ISO 8601-1:2019 版中已被移除。換句話説，這個日期僅用於定義格里高利曆，並非作為一個時間計數的起點。&lt;/p&gt; 
&lt;h2&gt;沒有任何證據顯示 1875 年被用作時間計算的起點&lt;/h2&gt; 
&lt;p&gt;經過查找，筆者沒有發現任何系統或標準會將 1875 年作為時間紀元。尤其在 COBOL 語言中，也沒有這樣的約定或實踐。所有跡象都表明，所謂的「1875 紀元」只是個誤解。&lt;/p&gt; 
&lt;p&gt;總的來説，從 SSA 的數據實踐、存儲方式以及國際標準的角度來看，都沒有任何證據支持「1875 紀元」這一説法。該觀點看似有趣，但實際上缺乏堅實的依據。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fiter.ca%2Fpost%2F1875-epoch%2F&quot; target=&quot;_blank&quot;&gt;https://iter.ca/post/1875-epoch&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334682/1875-epoch-cobol-150-american</guid>
            <pubDate>Sat, 08 Feb 2025 03:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>沒有處理過遺留項目，別自稱資深工程師</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家都不喜歡維護遺留項目，我也不例外。命運總愛跟人開玩笑，最近一個遺留項目正好落到了我手上。雖然在這個項目上工作的經歷並沒有減少我對遺留系統的厭惡，反而讓我對當下所採用的流程與實踐有了更深刻的認識。&lt;/p&gt; 
&lt;p&gt;我為自己所在的團隊感到自豪，因為我們遵循了許多業界最佳實踐：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;編寫簡潔且易維護的代碼，並配以自動化測試&lt;/li&gt; 
 &lt;li&gt;積極參與代碼合併請求和任務評審&lt;/li&gt; 
 &lt;li&gt;合併到主分支後，當天就能將應用推向生產環境&lt;/li&gt; 
 &lt;li&gt;高度採用敏捷開發模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;當然，一切並非盡善盡美。合併請求中偶爾會出現一些無關痛癢的建議和討論；運維團隊有時也會搞砸一些事情（至少在我們開發人員看來是這樣）；而產品負責人也時不時催促我們加快推出某些「簡單」的新功能……總的來説，情況還算不錯。&lt;/p&gt; 
&lt;h2&gt;穿越回 Ant 時代&lt;/h2&gt; 
&lt;p&gt;由於團隊表現出色，公司決定將我們的開發效率借調給另一個由其他部門負責的產品。令我們略感失望的是，這個項目不僅使用的是較老版本的 Java，其代碼風格也與我們的習慣大相徑庭。&lt;/p&gt; 
&lt;p&gt;任務要求我們添加幾個簡單的監控指標，比如應用是否正常運行、運行時長、數據處理是否足夠迅速等。由於項目正處於維護模式，已經有段時間沒有添加新功能了。按理説，添加這些指標對我們來説應該是小菜一碟。&lt;/p&gt; 
&lt;p&gt;然而，當我們捲起袖子開始工作時，首先發現這個項目竟然使用了一種非常古老的構建方式——Ant 構建文件。那是一種龐大的 XML 文件，詳細描述瞭如何構建整個項目：從編譯、測試到打包，每個環節都必須顯式配置，包括源碼路徑、目標路徑以及資源位置。過去，這種做法在許多編程語言中都很常見：寫好一個構建文件，複製到每個新項目中，再不斷調整直至適應新項目需求。&lt;/p&gt; 
&lt;p&gt;例如，一個簡單的「Hello World」項目的 Ant 構建文件可能如下所示：&lt;/p&gt; 
&lt;pre&gt;&amp;lt;project&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;clean&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;delete dir=&quot;build&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;compile&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;javac srcdir=&quot;src&quot; destdir=&quot;build/classes&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;jar&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;mkdir dir=&quot;build/jar&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;jar destfile=&quot;build/jar/HelloWorld.jar&quot; basedir=&quot;build/classes&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;attribute name=&quot;Main-Class&quot; value=&quot;oata.HelloWorld&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/manifest&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;/jar&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;nbsp; &amp;nbsp; &amp;lt;target name=&quot;run&quot;&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;lt;java jar=&quot;build/jar/HelloWorld.jar&quot; fork=&quot;true&quot;/&amp;gt;
&amp;nbsp; &amp;nbsp; &amp;lt;/target&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/pre&gt; 
&lt;p&gt;難道就沒有更便捷的方式嗎？正因如此，「約定優於配置」的理念應運而生。這一理念主張：開發者只需關心那些偏離約定的特殊情況，而現代構建工具正是基於這一思想，通過提供可覆蓋的默認配置，免去了重複配置的麻煩。正因為如此，大多數 Java 源碼統一存放在 &lt;code&gt;src/main/java&lt;/code&gt; 目錄下，而編譯後的文件則放在 &lt;code&gt;target&lt;/code&gt; 目錄中，避免了繁瑣的重複設置。&lt;/p&gt; 
&lt;p&gt;這一發現啓發了我們：或許同樣的原則也能應用到我們當前項目中的應用配置上。面對一個龐大且大部分數值雷同（如應用端口）的配置文件，採用默認值機制無疑能讓配置文件變得更精簡。&lt;/p&gt; 
&lt;h2&gt;被我們視為理所當然的事情&lt;/h2&gt; 
&lt;p&gt;回到遺留項目，我們順利構建並打包了應用！那枯燥的部分終於過去，可以安心開始編碼了。但問題隨之而來：如何將我們負責監控的指標組件嵌入到這套老舊的代碼庫中？在我們的常規開發框架中，這一切通常是自動處理的，因此我們一度認為這毫不費事。&lt;/p&gt; 
&lt;p&gt;但實際上，將指標組件「注入」到遺留代碼的各個角落，最佳方案是什麼呢？初看起來，單例模式似乎是最簡單的選擇；不過，開發社區普遍認為單例是一種反模式。為什麼呢？畢竟，我們鍾愛的某某框架不也依賴單例嗎？如果不是，那它到底採用了什麼機制？依賴注入究竟是什麼？其底層又是如何運作的？&lt;/p&gt; 
&lt;p&gt;這一連串問題促使我們重新審視那些一直視為理所當然的基本概念。雖然在這種情況下使用單例並非最糟，因為代碼大部分缺乏單元測試，但要讓我們心安理得，代碼必須經得起推敲。經過嘗試，我們最終採用了一種不同的方案，寫出了既簡潔又清晰的代碼——既沒有依賴單例，也未引入多餘的抽象層。&lt;/p&gt; 
&lt;h2&gt;開發者角色的侷限性&lt;/h2&gt; 
&lt;p&gt;項目的最後一步是部署，只有部署成功後才能進行測試。但問題來了——這一次，我們既不負責部署，也不負責測試。部署工作由運維團隊完成，而測試則交由專門的測試團隊。為什麼開發者就不能全程掌控，從開發到上線，而要先提交工單，再等待其他團隊的配合呢？&lt;/p&gt; 
&lt;p&gt;首先，由於代碼測試覆蓋率不足，手動測試不可避免；其次，公司的基礎設施也不允許我們自行部署應用。&lt;/p&gt; 
&lt;p&gt;這一系列經歷使我們開始思考職責分離的原因，以及現行模式為何更為合理。事實證明，這個項目的任務交付時間和迭代週期遠遠超過平時（通常幾天就能交付的工作，此次竟拖延了數週），這無疑驗證了分工合作的必要性。&lt;/p&gt; 
&lt;h2&gt;通過舊實踐理解現代方法&lt;/h2&gt; 
&lt;p&gt;到了月底，我們的監控指標終於在生產環境中順利運行。雖然我對遺留項目的看法依舊——我仍然討厭它們，也不奢望你會因此改變看法——但這段經歷給了我們寶貴的啓示。&lt;/p&gt; 
&lt;p&gt;我們無法選擇所分配到的項目，但我們可以調整對待遺留系統的態度。與其心存無奈，不如把它當作一個提問、學習與成長的機會。通過瞭解過去的做法及其侷限，我們不僅掌握了當下的最佳實踐，更獲得了背後歷史的寶貴經驗。&lt;/p&gt; 
&lt;p&gt;一旦你積累了這種深厚的知識，其他開發者自然會認可並信賴你的專業能力。如果你希望成為這樣的人，就得勇於鑽研那些看似繁瑣的遺留項目。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infobip.com%2Fdevelopers%2Fblog%2Fseniors-working-on-a-legacy-project&quot; target=&quot;_blank&quot;&gt;https://www.infobip.com/developers/blog/seniors-working-on-a-legacy-project&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;作者：Alen Kosanovic&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334678/seniors-working-on-a-legacy-project</guid>
            <pubDate>Sat, 08 Feb 2025 03:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Grok 3 是否意味着大力出奇跡的大模型法則仍然成立？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文轉載自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F24609799526&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/24609799526&lt;/a&gt;&lt;br&gt; 作者：張俊林（中科院軟件所，博士）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;媒體風向變化太快，讓人目不暇接。早上還在誇 Deepseek 成本低，性價比高，預訓練 Scaling Law 死了，不需要太多機器和 GPU 卡，性價比優先，英偉達休矣；中午 Grok 3 一出來，説是用了 10 萬張英偉達 H100 卡，效果力壓 OpenAIo3 mini 和 Deepseek R1，就轉向説 Scaling law 還成立，還需要大量的卡，英偉達股價有救了，還是要大力出奇跡……&lt;/p&gt; 
&lt;p&gt;這兩個觀點明顯對立，有一真必有一假，那事實的真相到底是啥呢？我們來推一推。&lt;/p&gt; 
&lt;h2&gt;一、預訓練階段的 Scaling Law 是否仍然成立&lt;/h2&gt; 
&lt;p&gt;-預訓練階段的 Scaling Law 成立嗎？當然是成立的，所謂「Scaling Law 撞牆」，大家普遍遇到的問題是數據不夠了，沒有大量新數據，導致預訓練階段的 Scaling Law 走勢趨緩，注意是趨緩但不是停頓，預訓練階段的 Scaling Law 並沒到天花板。按照 Chinchilla Scaling Law 推斷，即使沒有新數據，也並不意味着模型效果提不上去了，很簡單，只要增加基座模型尺寸，效果仍然會提高，只是從付出的算力和獲得的效果提升來説很不合算，性價比過低，這是為何大家轉到 RL Scaling Law 和 Test Time Scaling Law 的原因，是因為付出同樣的算力，在後面兩個階段大模型智商提升更明顯，就是性價比高。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;目前可以提高模型效果的 Scaling 方法，按照性價比由高到低排序的話: Test time Scaling Law&amp;gt; RL Scaling Law&amp;gt;預訓練階段 Scaling Law(數據不夠了，只能推大模型尺寸)&lt;/strong&gt;，有性價比高的 Scaling，當然優先做這種，性價比低的 Scaling，只有在沒有性價比更高的情況下才會採用。這跟購物一個道理，有性價比高的當然不會去買性價比低的商品。&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果哪天 RL Scaling Law 和 Test Time Scaling Law 到了天花板，又沒有找到新的性價比更合算的 Scaling law，也不是説模型效果就提不上去了，大家仍然可以迴歸預訓練階段的 Scaling Law，沒有新數據也沒關係，推大模型尺寸規模就可以，效果仍然會上升&lt;/strong&gt;。但這基本是最後的選擇，沒辦法的辦法，只要有性價比高的方法就不會走這條路。&lt;/p&gt; 
&lt;p&gt;-有人問了：那按照你的意思，囤那麼多 GPU 算力，其實對訓最好的模型也沒啥用？要是按照上面的理論，那確實是沒有太大必要，比如 Deepseek 2000 卡也可以作出最好的模型不是。但是卡多有個好處，就是能壓縮實驗新想法和訓練大模型基座的時間週期。比如你總得探索一些不同的算法、參數或數據配比的模型進行各種實驗，你有 10 個新想法，如果只有 2000 張卡，可能得跑 5 天才能得出結論，要是有幾萬張卡，可能 1 天就能得出結論，所以卡多對於探索效率是有極大幫助的。卡多創新多，這點肯定成立。&lt;/p&gt; 
&lt;h2&gt;二、Grok 3 基座模型（對標 Deepseek V3，非 R1 這種邏輯推理模型）&lt;/h2&gt; 
&lt;p&gt;-為何 Grok 3 作為通用基座模型，它的評測指標只有數學、科學和代碼數據集？沒有通用能力比如最常用的 MMLU 指標的對比，這是不太規範的對比模式。推斷可能 Grok 3 的通用能力相對 OpenAI 和 Deepseek 的模型沒有大幅提升，所以不拿出來比？&lt;/p&gt; 
&lt;p&gt;-&lt;strong&gt;如果想要提升基座模型的數學、科學和代碼能力，無論從方法還是從成本角度來講，難度並不大，目前比較標準的做法是類似 Deepseek V3 從 Deepseek R1 蒸餾數學、代碼等邏輯題的長 COT 數據，即深度思考過程數據，就是説把深度思考長 COT 數據引入基座的 Post-Training 階段、甚至前置到預訓練階段（所謂大模型「左腳（Deepseek 基座）踩右腳（Deepseek R1）自我飛昇」的模式），這樣就能大幅提升基座模型在數學和代碼方面相關的能力，也就是 Grok3 宣傳具備的「有思維鏈推理和自我糾錯機制」，評測指標看着會比較好看，而且蒸餾的數據總量也不會太大（幾百 B 級別應該夠了），成本很低，對算力要求不高。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;-OpenAI 很快會發布的非邏輯推理模型 GPT 4.5，大概也應是類似的思路，從 o3 模型蒸餾 COT 數據，用深度思考數據來提升 GPT 4.5 基座模型的智商，大模型「左腳踩右腳自我飛昇」大法，這會是之後基座模型提升能力的主要手段。&lt;/p&gt; 
&lt;p&gt;-Grok 3 的算力消耗是 Grok 2 的 10 倍，如果遵照 Chinchilla Scaling Law，最佳做法是 Grok 3 的訓練數據量比 Grok 2 增加 3 倍，模型大小同時比 Grok 2 增加 3 倍（但是目前的趨勢是減小模型大小，增大數據量[就是説「小模型大數據」的模式]，儘管這樣不滿足訓練最優原則，但因為模型尺寸小了，所以這種模型更適合在線推理服務，降低服務成本）。&lt;/p&gt; 
&lt;p&gt;-如果像發佈會宣稱的，Grok 3 耗費算力是 Grok 2 的 10 倍消息為真的話，那有兩種可能。一種是數據量增長極大，這樣只能是增加了大量多模態數據，比如數據量從 10T 增長到 30T（目前文本模型使用的數據量，最多到 18T 到 20T 之間，基本到頂，再多沒有了，要大幅增加只能加多模態數據，但是增加多模態數據對提升大模型智商幫助不大，所以這個增量按理説不應該太大），如果這樣推算，Grok3 的模型規模增長 3 倍左右；第二種可能是訓練數據量比 20T 增加的不多，如果這樣可以推出 Grok3 模型尺寸比 Grok 2 要大很多，至少 4 到 5 倍起步（若新增數據不多，那隻能靠增加模型尺寸來消耗新增算力）。不論是哪種可能，Grok 3 的模型大小肯定比 Grok 2 大了很多，而 Grok 2 模型本身可能就不小（Grok 2 發佈網頁評測效果超過 Llama 3.1405B，所以無論數據還是模型大小，都不會太小，要是 Dense 模型， 70B 是最小的估計了），&lt;strong&gt;所以 Grok 3 的尺寸規模很可能不是一般的大&lt;/strong&gt;（感覺在 200B 到 500B 之間）。&lt;/p&gt; 
&lt;p&gt;-很明顯，Grok 3 仍然在採取推大基座模型尺寸的「傳統」做法，也就是上面「Scaling Law」部分分析的預訓練階段增大模型尺寸的方法來提升基座模型能力，上面分析過，這種做法是性價比很低的。比較時髦的做法是把訓練重心放在 RL Scaling 方面，性價比會高太多。但是為啥他要做這種賠本買賣呢？在後面會給出一個可能的解釋。&lt;/p&gt; 
&lt;h2&gt;三、Grok 3 邏輯推理版本 (深度思考版本，對標 Deepseek R1)&lt;/h2&gt; 
&lt;p&gt;-Grok 3 的深度思考版本，不説體驗，單從評測指標看，達到或者超過了 o3 mini，確實是目前效果最好的，或者説最好的之一沒有什麼問題。&lt;/p&gt; 
&lt;p&gt;-説回上面提到的問題，為啥明知靠推大預訓練階段模型尺寸規模性價比低，Grok 3 還要用這種模式呢？很可能內在的原因在於（推斷無證據）：&lt;strong&gt;Post-Training 階段採取 RL Scaling，其效果可能跟基座模型的大小是有正相關關係的，就是説，同樣的 RL 階段的算力消耗，如果基座模型尺寸更大，則 RL 階段的 Scaling 效果越好。&lt;/strong&gt;只有這樣，才有在預訓練階段儘量把模型規模推大的必要性。而我們可以假設，Grok 3 之所以採取這種過於耗費算力，看着性價比不高的方式，是希望通過加大基座，把深度思考版本的能力明顯提起來。&lt;/p&gt; 
&lt;p&gt;-貌似 Deepseek R1 效果很好又開源，獲得一片好評，但大家想要實際用起來，會發現基座太大，部署難度和消耗資源太高，對下游應用不太友好。那為啥 Deepseek 非得推這種對下游應用來説明顯過大的模型呢？（小點的蒸餾模型看着指標很好，但是實際應用效果貌似差不少），是否也是因為基座模型如果不夠大，深度思考模型效果就沒那麼好的原因？&lt;/p&gt; 
&lt;p&gt;-如果上述假設成立，那意味着：&lt;strong&gt;三個 Scaling Law(Pre-train、RL 、Test Time)，從提高大模型智商的性價比來説，由高到低是：Test Time &amp;gt; RL &amp;gt; Pre-Train，這個是之前的結論。但如果上述假設成立，説明 Test Time Scaling 的天花板最低，它的天花板依賴於 RL 階段的 Scaling 能力，而 RL 階段 Scaling 天花板次低，它的天花板依賴於預訓練階段 Pre-Train 的 Scaling？&lt;/strong&gt;如果這樣，如果有一天當 RL 和 Test Time 天花板到頂，意味着我們可以再啓動一輪，去推大基座模型的模型尺寸，RL 階段 Scaling 的天花板隨之升高，然後可以再去 Scale RL 和 Test Time，就進一步得到智商更高的大模型。如果這成立，那意味着 AGI 的解決方案已經完整了？其實不需要新的 Scaling Law 存在就夠？&lt;/p&gt; 
&lt;p&gt;-上述推論，是在一個前提成立的條件下的推出來的，這個前提是：Grok 3 耗費這麼大算力推大模型規模，這是個深思熟慮或小規模實驗的結果，而不是僅僅受到之前老觀念（預訓練階段算力越高效果越好）影響下的決策。&lt;/p&gt; 
&lt;p&gt;如果這個前提不成立，則上述推論不成立。總之，一切責任在馬斯克，Over。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334674</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334674</guid>
            <pubDate>Sat, 08 Feb 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 提出新的注意力機制：原生稀疏注意力 (NSA)，創始人親自提交論文</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 18 日，DeepSeek 官方發文公佈了一篇新的論文，&lt;strong&gt;論文提出了一種新的注意力機制「NSA」&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-adf24ce9b3e5ac8760a1ec13688871f61ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;論文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2502.11089v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2502.11089v1&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據 DeepSeek 介紹，&lt;strong&gt;&lt;span&gt;「原生稀疏注意力 (Native Sparse Attention, NSA) 」&lt;/span&gt;&lt;/strong&gt;是一個用於超快長上下文訓練和推斷的本地可訓練的稀疏注意力機制，並且還具有與硬件對齊的特點。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;論文摘要：&lt;/p&gt; 
 &lt;p&gt;長文本建模對下一代語言模型來説至關重要，但標準注意力機制的高計算成本帶來了顯著的計算挑戰。稀疏注意力為提高效率同時保持模型能力提供了一個有前景的方向。我們提出了 NSA（原生稀疏注意力），這是一個將算法創新與硬件對齊優化相結合的、原生可訓練的稀疏注意力機制，用於實現高效的長文本建模。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d43b8ad2a0cb2e2f280f11b7d2d96a63fba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;NSA 核心組件包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;動態分層稀疏策略&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;粗粒度 token 壓縮&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;細粒度 token 選擇&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;研究通過對現實世界語言語料庫的綜合實驗來評估 NSA。其中作者評估了 NSA 在通用語言評估、長上下文評估和鏈式推理評估中的表現。實驗結果表明，NSA 實現了與 Full Attention 基線相當或更優的性能，同時優於現有的稀疏注意力方法。&lt;/p&gt; 
&lt;p&gt;此外，與 Full Attention 相比，NSA 在解碼、前向和後向階段提供了明顯的加速，且加速比隨着序列長度的增加而增加。這些結果驗證了分層稀疏注意力設計有效地平衡了模型能力和計算效率。&lt;/p&gt; 
&lt;p&gt;另外，有網友發現，arXiv 上 NSA 這篇論文的提交記錄顯示，它於 2 月 16 日提交，提交者正是梁文鋒本人，他也是這篇論文的合著者。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-521d0ee94e504b1caa033cbf984b6fde938.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334671/deepseek-nsa</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334671/deepseek-nsa</guid>
            <pubDate>Sat, 08 Feb 2025 02:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linus Torvalds 將不顧維護者反對合並 Rust 內核代碼</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 &lt;a href=&quot;https://www.oschina.net/news/334317/marcan-resigning-as-asahi-linux-project-lead&quot;&gt;Asahi Linux 創始人宣佈辭去項目負責人職務&lt;/a&gt;之後，圍繞 Linux 內核中 Rust 代碼的爭議還在繼續。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DMA 映射助手及內核其他多個領域的維護者 Christoph Hellwig 一直對 Linux 內核中的 Rust 代碼及其長期可維護性持批評態度，他在最新發布的一封郵件列表帖子中指出， Linus Torvalds 私下提到將推翻維護者對內核中 Rust 代碼的否決權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;409&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-84071f688bda1ac854a0ee922963f204016.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;考慮到最近幾天的討論，我決定發佈此頁面，其中包含我們的理解：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frust-for-linux.com%2Frust-kernel-policy&quot; target=&quot;_blank&quot;&gt;https://rust-for-linux.com/rust-kernel-policy&lt;/a&gt;……&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Linus 私下表示，他絕對會不顧維護者的反對合並 Rust 代碼。因此，從現在開始，作為 Linux 開發者或維護者，無論你是否願意，都必須處理 Rust。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這裏的 Rust 代碼不僅僅是指 Rust 代碼——這些綁定看起來一點也不像地道的 Rust 代碼，它們是一種完全不同的存在，試圖彌合巨大的語義鴻溝。而且它們在某些地方並沒有做到這一點，因為它們現在被塞進了每個小子系統和庫中。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，這些綁定會像癌症一樣蔓延到各處，並迅速從一個允許並追求全局改進的軟件項目，轉向日益增加的隔離化。這將使 Linux 變成一個用多種語言編寫的項目，而沒有明確的指南説明在何處使用何種語言。即使在綁定之外，由於內核數據結構（如無處不在的鏈表）的侵入性和自引用特性，許多代碼也不會是非常地道的 Rust。我們是否既對不起那些試圖將現有代碼庫帶入更安全空間的人，也對不起那些用 Rust 進行系統編程的人？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我曾經在類似的代碼庫上工作過，它們是我最糟糕的噩夢，因為由於原因 X，不斷有部分代碼從語言 A 重寫為語言 B，然後又由於原因 Z 重寫回去。而這還沒有算上 Linux 維護者之間常見的‘創造性’內鬥。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我想了解這個 Rust ‘實驗’的目標是什麼：如果我們想解決現有的內存安全問題，我們需要針對現有代碼進行修復，並找到改進的方法。最近在這方面做了很多工作，我們還需要更多。但這也表明，核心維護者對諸如檢查整數溢出或編譯器強制同步（如 clang hread sanitizer)）等瑣碎事情感到厭煩。我們如何彌合內核中一部分甚至不接受相對簡單的安全改進規則，而另一部分卻強制執行更嚴格規則之間的差距？&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;如果我們只是想使編寫驅動程序更容易，那麼引入一種新語言只會增加更多工作，並加重已經超負荷工作的核心基礎設施維護者的負擔。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，我認為這份政策文件沒有太大用處。目前的規則是，Linus 可以強迫你做任何他想要的事情，我認為他需要非常清楚地闡明這一點，包括對貢獻者的期望。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;就我個人而言，我可以很好地處理 Rust 本身，我很樂意將內核帶入一個更安全的內存世界，但處理一個不受控制的多語言代碼庫肯定會讓我把業餘時間花在其他事情上。我聽到其他一些人嘀咕類似的話，但並不是每個人都像我這樣直言不諱。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Frust-for-linux%2FZ7SwcnUzjZYfuJ4-%40infradead.org%2F&quot; target=&quot;_blank&quot;&gt;查看郵件列表&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334666/linus-torvalds-rust-code</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334666/linus-torvalds-rust-code</guid>
            <pubDate>Sat, 08 Feb 2025 02:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中軟國際被曝不協商直接降薪，有人直降 35%，引發員工抗議</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7884923627%2FPeQTeBEot&quot; target=&quot;_blank&quot;&gt;有網友爆料&lt;/a&gt;，華為外包大廠中軟國際員工在公司樓下聚集維權，抗議公司未提前協商突然降薪操作，疑似降薪幅度 10%-35%，甚至還有傳出 0 元工資的極端情況，引發員工強烈不滿。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102639_R1Xq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0219/102923_eWur_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據悉，目前 IT 中心產品部確認降薪，其他受影響部門暫不清楚。有員工反映，公司在降薪的同時還在大力拓展新業務，高層薪資福利卻絲毫未減，這讓員工心裏很不平衡。&lt;/p&gt; 
&lt;p&gt;據透露，中軟國際提供了三種選擇：一是按照薪資比例摺合 13 個月+的薪資，多出來的月份按照績效年終發放；第二種方案為直接降薪 18%；或者選擇在 3 月底主動離職。三種方案任選其一，且沒有書面形式，只是口頭通知。更讓員工難以接受的是，此次降薪並未明確説明原因，且強制執行。&lt;/p&gt; 
&lt;p&gt;面對員工的質疑，截至目前，該外包大廠派了一個所謂的辦事員前來收集員工的訴求，並承諾將與高層協商解決。「他們只是來聽我們説話，卻沒有給出任何實質性的答覆。」一位參與溝通的員工表示，「感覺就像是走過場，根本沒有解決問題的誠意。」&lt;/p&gt; 
&lt;p&gt;值得注意的是，據員工爆料，中軟國際的郵箱讓員工可以收到郵件，但是員工發送郵件出去，發件箱和發件記錄是空的，「這是怕員工留痕特意設置的。」該員工表示。更有網友爆料，甲方開價不低，到手的錢卻層層縮水，之前就有裁員 2.2 萬人的先例，現在又不協商直接降薪。&lt;/p&gt; 
&lt;p&gt;資料顯示，中國軟件外包市場規模已突破 4454 億元，年增速超 10%，而該公司作為在岸外包龍頭，客户包括瞭如華為等互聯網大廠。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334665</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334665</guid>
            <pubDate>Sat, 08 Feb 2025 02:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>李彥宏：文心大模型 4.5 系列將開源，是最強大的文心大模</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在百度 2024 年 Q4 及全年財報電話會上，百度創始人、董事長兼首席執行官李彥宏透露，文心大模型 4.5 將開源，4.5 將是百度有史以來最強大的大模型，「希望客户和用户能比之前更方便地體驗這款模型」。&lt;/p&gt; 
&lt;p&gt;他表示，開源 4.5 系列的決策源自於對技術領先地位的堅定信心，開源將進一步促進文心大模型的廣泛應用，並在更多場景中擴大其影響力，「但我想強調的是，無論開源閉源，基礎模型只有在大規模解決現實問題時，才具備真實價值」。未來，百度將加速推動文心大模型的性能升級與成本降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;400&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f76b9accbca6162153bf21f08d99a59ecc.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，李彥宏還在業績會上表示，2025 年是蘿蔔快跑重要的擴張之年。他透露，百度將尋求與移動服務運營商、出租車公司及第三方車隊運營方等合作，以加速業務擴展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334659</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334659</guid>
            <pubDate>Sat, 08 Feb 2025 02:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度 2024 年總營收 1331 億元，對 AI 投資充滿信心</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度剛剛發佈了 2024 年 Q4 及全年財報：全年總營收 1331 億元，歸屬百度核心淨利潤達 234 億元，同比增長 21%。&lt;/p&gt; 
&lt;p&gt;百度聯合創始人兼 CEO 李彥宏表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2024 年是百度從以互聯網為中心向以 AI 為先轉型的關鍵一年。我們的全棧 AI 能力得到了市場的廣泛認可，從而推動了人工智能雲的發展勢頭。在移動生態系統方面，我們堅定不移地推進 AI 轉型，使搜索更接近原生 AI 能力，從而提供更好的用户體驗。&lt;/p&gt; 
 &lt;p&gt;Apollo Go 經過多年的投入也充分驗證了其商業模式，為全球擴張和可擴展的輕資產戰略鋪平了道路。隨着我們的戰略遠見逐漸得到驗證，我們預計我們的 AI 投資將在 2025 年取得更顯著的成果。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;1440&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/184432_hRLQ_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;受 AI 驅動，百度智能雲呈高速增長，四季度收入同比增長達 26%。近期，百度智能雲成功點亮崑崙芯三代萬卡集羣，未來還將進一步點亮三萬卡集羣。&lt;/p&gt; 
&lt;p&gt;12 月，文心大模型日均調用量達 16.5 億次，一年增長 33 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1440&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/184634_17th_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334611</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334611</guid>
            <pubDate>Fri, 07 Feb 2025 10:47:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源策略是大模型最好的競爭策略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;最近，開源中國 OSCHINA、Gitee 與 Gitee AI&lt;a href=&quot;https://www.oschina.net/news/330623/china-open-source-2024-annual-report&quot;&gt;聯合發佈了《2024 中國開源開發者報告》&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;報告地址：&lt;a href=&quot;https://talk.gitee.com/report/china-open-source-2024-annual-report.pdf?fr=news0120&quot; target=&quot;_blank&quot;&gt;2024 中國開源開發者報告.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;報告聚焦 AI 大模型領域，對過去一年的技術演進動態、技術趨勢、以及開源開發者生態數據進行多方位的總結和梳理。&lt;/p&gt; 
&lt;p&gt;在第二章《TOP 101-2024 大模型觀點》中，資深開發者社區運營專家&lt;strong&gt;顧鈞&lt;/strong&gt;直言，開源策略是大模型最好的競爭策略，並分享了諸多思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;大模型是一項較新技術，賽道的主要玩家在技術和商業化上有差距但未到無法翻盤程度，該賽道涵蓋模型訓練與服務，市場化程度高，商業化場景覆蓋 2B 與 2C。&lt;/li&gt; 
 &lt;li&gt;大模型賽道在海外是 「一超多強」，國內是 「多頭並舉」，元素豐富，為分析開源策略重要性提供素材。&lt;/li&gt; 
 &lt;li&gt;大模型競爭賽點包括技術先進性、C 端用户基數、依賴軟件的生態系統大小等，但技術先進性目前更多用於公關宣傳，大模型商業化還處於摸索階段。&lt;/li&gt; 
 &lt;li&gt;C 端用户沒有忠誠度且難以產生獨特粘性，大模型廠商維繫 C 端流量成本可能很高，且大模型賽道內卷，普通用户使用隨意性強、準確性要求不高。&lt;/li&gt; 
 &lt;li&gt;大模型生態系統大小是評價其能否勝出的關鍵指標，構建開發者生態有提供 API 雲服務和 「開源」 兩種方法，閉源大模型多采用前者，開源模型採用後者。&lt;/li&gt; 
 &lt;li&gt;拋開成本和易用性空談技術先進性是常見錯誤，大模型領域開源更有優勢，因為大模型賽道核心制約條件是成本太高，開源可省去拓展開發者生態的大模型運行成本。&lt;/li&gt; 
 &lt;li&gt;閉源大模型廠商維持雲資源、工程師資源支撐開發者調試需求，投入產出可能算不過來，且大模型對開發者粘性有限。&lt;/li&gt; 
 &lt;li&gt;大模型 API 雲服務接口簡單且高度一致，開發者構建應用時與具體大模型難形成強綁定，主動權在開發者。&lt;/li&gt; 
 &lt;li&gt;開源策略目標是以最小代價消耗閉源對手資源與心氣，是 &lt;strong&gt;「先為不可勝，以待敵之可勝」&lt;/strong&gt; 的策略。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1920&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0218/175851_PK73_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;完整全文：&lt;a href=&quot;https://my.oschina.net/u/3859945/blog/17503844&quot; target=&quot;_blank&quot;&gt;https://my.oschina.net/u/3859945/blog/17503844&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334605</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334605</guid>
            <pubDate>Fri, 07 Feb 2025 10:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>KubeSphere 產品生命週期管理政策公告正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;親愛的 KubeSphere 用户：&lt;/p&gt; 
&lt;p&gt;在雲原生技術飛速發展的今天，KubeSphere 始終以技術創新和用户價值為核心，持續優化產品與服務。為更好地服務全球用户、保障業務連續性，基於多年的技術積累與用户反饋，我們正式對外公開發布 &lt;strong&gt;《KubeSphere 產品生命週期管理政策》&lt;/strong&gt;。通過清晰的支持策略與版本管理，助力用户高效規劃升級，規避潛在風險，實現業務可持續發展。&lt;/p&gt; 
&lt;h2&gt;KubeSphere 產品生命週期管理政策公告&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;文件版本&lt;/strong&gt;: v1.0 &lt;strong&gt;更新時間&lt;/strong&gt;: 2025.02.14&lt;/p&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;在快速變化的市場環境中，青雲科技針對 KubeSphere 雲原生產品與服務推出了產品生命週期管理政策。該政策旨在及時調整和終止不再符合市場需求的產品，以確保我們的產品始終滿足客户期望。通過清晰的產品終止方案，我們將為客户提供必要的支持與指導，降低業務風險，提升客户信任與滿意度。我們致力於推動技術創新，實現持續的業務發展，為客户創造更大的價值。&lt;/p&gt; 
&lt;h2&gt;適用範圍&lt;/h2&gt; 
&lt;p&gt;本文中描述的 KubeSphere 產品生命週期終止政策適用於以下 KubeSphere 雲原生產品與服務：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KubeSphere 開源版。涉及 v1、v2、v3 及 v4 版本。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企業版（包含更名前的青雲 QKCP）。涉及 v1、v2、v3 及 v4 版本。&lt;/li&gt; 
 &lt;li&gt;青雲容器平台（可信版）。涉及所有產品版本。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 產品版本定義&lt;/h2&gt; 
&lt;p&gt;在 KubeSphere 產品版本控制中，軟件版本號通常用來表示其代表的發佈階段與更新內容。其中，版本號格式包括主版本號 (Major Version)、次版本號 (Minor Version)、補丁版本號 (Patch Version) 和熱修復版本號 (HotFix)。以下是這些術語的詳細説明：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 主版本 (Major Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主版本號的設置通常表示軟件有重大更新或變化，這可能包括全新的產品架構、功能模塊、操作體驗或與舊版本不再兼容的變更。&lt;/li&gt; 
 &lt;li&gt;主版本號的設置通常意味着版本號的其他部分（如：次版本號、補丁版本號）重置為零。例如，產品版本從 v3.4.1 升級到 v4.0.0。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 次版本 (Minor Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;次版本號的設置表示軟件有一般的更新或改進，這可能包括新增功能模塊、性能改善、安全性強化或兼容性增強等。&lt;/li&gt; 
 &lt;li&gt;次版本號的設置通常意味着補丁版本號重置為零，但主版本號保持不變。例如，產品版本從 v4.1.2 升級到 v4.2.0。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 補丁版本 (Patch Version)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;補丁版本號的設置表示軟件有較小的修復或優化，這通常用於修復錯誤、改進穩定性、或優化產品體驗等。&lt;/li&gt; 
 &lt;li&gt;補丁版本不會開啓新的產品生命週期。例如，KSE v4.1.3 將共享 KSE v4.1 的生命週期。&lt;/li&gt; 
 &lt;li&gt;補丁版本號的設置不會影響主版本號和次版本號。例如，產品版本從 v4.1.2 升級到 v4.1.3。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4. 熱修復 (HotFix)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;熱修復是指對軟件進行的緊急修復，其通常用於解決如無法繼續的阻塞或嚴重的安全隱患導致客户業務停滯或沒有臨時方案的問題。&lt;/li&gt; 
 &lt;li&gt;熱修復僅就對應發現的嚴重問題進行修復和針對性測試，不會像上述三類正式產品版本一樣進行全量的測試驗證，是解決緊急問題的臨時性處置措施。最佳方案依然是升級至後續正式產品版本。&lt;/li&gt; 
 &lt;li&gt;熱修復通常不改變產品版本號的主要部分，僅在現有版本上立即應用。例如，如果產品版本 v3.5.0 存在嚴重錯誤，可能會發佈一個熱修復版本 3.5.0-hotfix-version-number。&lt;/li&gt; 
 &lt;li&gt;熱修復可能會在下一個補丁版本或次版本中被正式包含。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 服務與支持等級定義&lt;/h2&gt; 
&lt;p&gt;在 KubeSphere 雲原生產品與服務中，通常會涉及到以下多種類型的服務與支持。根據等級的劃定，可分為：FS（Full Support，全面服務與支持）與 ES（Extended Support，延長服務與支持）。下方表格中」Y」表示」YES」，即支持；」N」表示」NO」，即不支持。表格中的數字標識表示有進一步的文字説明，詳見下方對應標號的內容。&lt;/p&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 服務與支持等級表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;服務與支持類型&lt;/th&gt; 
   &lt;th&gt;FS&lt;/th&gt; 
   &lt;th&gt;ES&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;服務與支持時長 (Duration: Months)&lt;/td&gt; 
   &lt;td&gt;12-36&lt;/td&gt; 
   &lt;td&gt;06-24&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;問題分析 (Root-Cause Analysis)&amp;lt;sup&amp;gt;(1)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;產品新特性 (Features)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;產品版本升級 (Upgrade)&amp;lt;sup&amp;gt;(2), (3)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&amp;lt;sup&amp;gt;(2)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;功能與體驗優化 (Enhancements)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;普通缺陷修復 (General BugFix)&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;嚴重缺陷修復 (Critical BugFix)&amp;lt;sup&amp;gt;(4)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;嚴重安全漏洞修復 (Critical Security Fix)&amp;lt;sup&amp;gt;(5)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
   &lt;td&gt;Y&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;兼容性支持 (Compatibility Support)&amp;lt;sup&amp;gt;(6)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;N&amp;lt;sup&amp;gt;(7)&amp;lt;/sup&amp;gt;&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;遷移協助 (Migration Support)&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
   &lt;td&gt;N&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1) 「問題分析」是指對非產品自身、從外部引入的第三方軟硬件帶來的問題進行分析與支持。如客户自己開發的業務系統、自採購硬件設備、自行部署的第三方軟件等，青雲科技僅承諾協助性分析與支持，不承諾能定位或解決此類非青雲科技提供的產品的問題。&lt;/li&gt; 
 &lt;li&gt;(2) 產品版本升級主要包括提供主版本、次版本、補丁版本或熱修復的升級。ES 等級下，僅針對「嚴重缺陷修復」與「嚴重安全漏洞修復」提供」熱修復「升級。&lt;/li&gt; 
 &lt;li&gt;(3) 一般情況下，產品不支持跳過任意主和次版本進行升級，需按版本號順序依次遞進升級。若遇不確定情況，請聯繫青雲科技客服人員或售後服務團隊，諮詢並評估專屬的產品升級方案。&lt;/li&gt; 
 &lt;li&gt;(4) 「嚴重缺陷」是指客户、產品經理、測試經理、產品技術負責人、技術支持工程師及項目經理等多方共同認定下，明確影響到客户業務連續性、穩定性、可靠性等的問題。&lt;/li&gt; 
 &lt;li&gt;(5) 「嚴重安全漏洞」是指 CVSS 大於等於 7 的安全漏洞問題。&lt;/li&gt; 
 &lt;li&gt;(6) 兼容性支持主要包括兼容 Kubernetes 新版本、新的 CPU 架構、新的 OS 類型或架構、OS 的新版本等。&lt;/li&gt; 
 &lt;li&gt;(7) 兼容性支持取決於軟件主版本、次版本發佈時的適配兼容情況，在後續的產品生命週期中不再改變。FS 不再新增兼容適配。&lt;/li&gt; 
 &lt;li&gt;(8) FS、ES 僅針對青雲科技的商業產品。ES 可視為 FS 的延續，不一定每個版本都可以額外訂閲 ES。ES 在經過青雲科技確認並同意的前提下最多允許訂閲兩次即兩年，之後不再提供續訂。若有需要，請聯繫青雲科技客服人員或售後服務團隊諮詢詳情。&lt;/li&gt; 
 &lt;li&gt;(9) FS、ES 默認通過如維保工單支持平台、遠程桌面、電話、微信、企業微信等遠程方式提供服務與支持。現場或駐場類型的服務與支持不在 FS、ES 範圍內，若有需要，請聯繫青雲科技客服人員或售後服務團隊諮詢詳情。&lt;/li&gt; 
 &lt;li&gt;(10) 青雲科技 KubeSphere 雲原生產品與服務的具體服務與支持範圍，可參考青雲科技售後服務團隊出具的 SLA 聲明。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;KubeSphere 產品生命週期説明&lt;/h2&gt; 
&lt;h3&gt;1. Standard 類型產品版本説明&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere Standard 類型產品版本説明表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;里程碑階段&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoFS&lt;/th&gt; 
   &lt;th&gt;EoES&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;中英文名稱&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;General Availability, 一般可獲得性，即批量銷售日。&lt;/td&gt; 
   &lt;td&gt;End of Full Support，停止全面服務與支持。&lt;/td&gt; 
   &lt;td&gt;End of Extended Support，停止延長服務與支持。&lt;/td&gt; 
   &lt;td&gt;End of Life，生命週期完全終止。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;定義&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GA 是產品生命週期開啓的日期。該日期表明該產品版本正式開始售賣，並可按需、批量交付到客户生產環境使用。&lt;/td&gt; 
   &lt;td&gt;EoFS 是產品停止全面服務與支持的日期。產品停止提供補丁版本，僅針對「嚴重缺陷」與「嚴重安全漏洞」提供「熱修復」。同時，該日期表明產品（主版本、次版本）已不再銷售。&lt;/td&gt; 
   &lt;td&gt;EoES 是產品停止延長服務與支持的日期。產品不再修復嚴重缺陷與嚴重安全漏洞。&lt;/td&gt; 
   &lt;td&gt;EoL 是產品生命週期完全終止的日期。完全停止此產品（版本）的一切活動，包括商業售賣、版本升級（含熱修復）、各種等級的服務與支持等。青雲科技將不再為此產品（版本）上產生的任何問題負責。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;服務與支持等級&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;FS（產品 GA 之後，根據客户的產品授權與維保訂閲情況提供）&lt;/td&gt; 
   &lt;td&gt;ES（產品 EoFS 之後，產品不再提供標準的 FS。客户額外訂閲 ES 的情況後提供延長服務與支持）&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;客户影響&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;(1) 不建議客户使用已經 EoFS 的版本進行新建或擴容；&amp;lt;br&amp;gt;(2) 客户無法得到新的產品補丁版本；&amp;lt;br&amp;gt;(3) 推薦客户儘快升級使用全新 GA 的版本；&amp;lt;br&amp;gt;(4) 客户可在訂閲 ES 後享受對應等級服務與支持。&lt;/td&gt; 
   &lt;td&gt;(1) 客户無法得到新的產品熱修復；&amp;lt;br&amp;gt;(2) 若繼續使用，客户必須進行版本升級；&amp;lt;br&amp;gt;(3) 對應產品（版本）官方文檔很快將無法查看；&amp;lt;br&amp;gt;(4) 對應產品（版本）安裝、升級等程序（鏡像 Chart 等）很快將無法使用。&lt;/td&gt; 
   &lt;td&gt;(1) 客户無法查看對應產品（版本）官方文檔；&amp;lt;br&amp;gt;(2) 客户無法使用安裝、升級等程序（鏡像 Chart 等）；&amp;lt;br&amp;gt;(3) 客户無法獲得針對該產品（版本）的任何服務；&amp;lt;br&amp;gt;(4) 客户需自行維護或遷移業務環境，客户需考慮購買新的產品（版本）。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Preview 類型產品及擴展組件版本説明&lt;/h3&gt; 
&lt;p&gt;KubeSphere 雲原生產品與服務中，Preview 類型產品版本及擴展組件版本非售賣，不支持商用，僅供實驗室、開發測試等非正式生產環境體驗使用，不提供 SLA 與 EOS 商業保障。通常情況下，Preview 類型產品版本及擴展組件版本生命週期為 6 個月。&lt;/p&gt; 
&lt;h2&gt;KubeSphere 產品生命週期時間表&lt;/h2&gt; 
&lt;h3&gt;1. KubeSphere 企業版（包含更名前的青雲 QKCP、青雲容器平台（可信版））&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 企業版產品生命週期時間表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;版本號&lt;/th&gt; 
   &lt;th&gt;版本類型&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoFS&lt;/th&gt; 
   &lt;th&gt;EoES&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.2&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.1&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2024 年 04 月 16 日&lt;/td&gt; 
   &lt;td&gt;2027 年 04 月 16 日&lt;/td&gt; 
   &lt;td&gt;2028 年 10 月 16 日&lt;/td&gt; 
   &lt;td&gt;2028 年 12 月 16 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v4.0&lt;/td&gt; 
   &lt;td&gt;Preview&lt;/td&gt; 
   &lt;td&gt;2023 年 08 月 16 日&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2024 年 06 月 28 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.5&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2023 年 10 月 13 日&lt;/td&gt; 
   &lt;td&gt;2025 年 07 月 13 日&lt;/td&gt; 
   &lt;td&gt;2026 年 01 月 13 日&lt;/td&gt; 
   &lt;td&gt;2026 年 03 月 13 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.4&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2023 年 04 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 05 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 11 月 25 日&lt;/td&gt; 
   &lt;td&gt;2025 年 12 月 25 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.3&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 03 月 31 日&lt;/td&gt; 
   &lt;td&gt;2025 年 09 月 30 日&lt;/td&gt; 
   &lt;td&gt;2025 年 10 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KSE v3.2 及之前版本&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 03 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;青雲容器平台（可信版）請參考 KubeSphere 企業版與青雲 QKCP 對應版本號的產品生命週期情況。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企業版 v4.2 之後，各擴展組件可能出現獨立發版、迭代的情況，但其產品生命週期不單獨設立，仍與 KubeSphere 企業版產品生命週期一致。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. KubeSphere 開源版&lt;/h3&gt; 
&lt;p&gt;&amp;lt;center&amp;gt;&amp;lt;span style=&quot;color: #00A971;&quot;&amp;gt;KubeSphere 開源版產品生命週期時間表&amp;lt;/span&amp;gt;&amp;lt;/center&amp;gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;版本號&lt;/th&gt; 
   &lt;th&gt;版本類型&lt;/th&gt; 
   &lt;th&gt;GA&lt;/th&gt; 
   &lt;th&gt;EoL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v4.2&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v4.1&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;2024 年 09 月 12 日&lt;/td&gt; 
   &lt;td&gt;2027 年 09 月 12 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v3.4&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 12 月 25 日&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KubeSphere v3.3 及之前版本&lt;/td&gt; 
   &lt;td&gt;Standard&lt;/td&gt; 
   &lt;td&gt;——&lt;/td&gt; 
   &lt;td&gt;2025 年 10 月 31 日&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;補充説明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 KubeSphere 企業版/開源版 v4 版本中，可能存在一些來自第三方合作伙伴的生態擴展組件。針對這些擴展組件，其產品生命週期管理策略請查看產品的相關説明文檔或聯繫對應產品提供商。&lt;/li&gt; 
 &lt;li&gt;因產品軟著與軟件採購退税等政策性原因，青雲科技銷售目錄與合同中所列舉的產品版本可能與實際交付部署的產品版本不一致。若出現該情況，一切都以客户首次採購、實際交付部署並頒發許可證授權的產品版本為準。&lt;/li&gt; 
 &lt;li&gt;在 KubeSphere 雲原生產品與服務的銷售中，當出現採購產品永久授權與多年 FS/ES 的場景時，其適用的版本可能不是採購當時的產品版本。此時以當前實際交付部署並頒發許可證授權的產品版本為準。&lt;/li&gt; 
 &lt;li&gt;上方「KubeSphere 產品生命週期時間表」中展示的時間，為各里程碑階段承諾服務與支持的最短時間。我們可能會基於產品版本質量、安裝部署人數、新產品（版本）研發情況等進行動態調整 EoFS/EoES/EoL 的時間。若有調整，我們將另行公告，歡迎關注。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;注意事項&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;第三方擴展組件：生命週期策略請以提供商文檔為準。&lt;/li&gt; 
 &lt;li&gt;版本交付一致性：實際授權版本以首次交付並頒發許可證的版本為準。&lt;/li&gt; 
 &lt;li&gt;動態調整説明：如遇產品迭代或用户需求變化，生命週期時間可能調整，請持續關注官方公告。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;完整聲明全文&lt;/h3&gt; 
&lt;p&gt;中英雙語全文請參見 KubeSphere 官網：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全球站：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fnews%2Fkubesphere-product-lifecycle-policy%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere Product Lifecycle Policy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;中文站：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fnews%2Fkubesphere-product-lifecycle-policy%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere 產品生命週期管理政策公告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;關於 KubeSphere&lt;/h3&gt; 
&lt;p&gt;KubeSphere （&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%EF%BC%89%E6%98%AF%E5%9C%A8&quot; target=&quot;_blank&quot;&gt;https://kubesphere.io）是在&lt;/a&gt; Kubernetes 之上構建的開源容器平台，提供全棧的 IT 自動化運維的能力，簡化企業的 DevOps 工作流。&lt;/p&gt; 
&lt;p&gt;KubeSphere 已被 Aqara 智能家居、本來生活、東方通信、微宏科技、東軟、華雲、新浪、三一重工、華夏銀行、四川航空、國藥集團、微眾銀行、紫金保險、去哪兒網、中通、中國人民銀行、中國銀行、中國人保壽險、中國太平保險、中國移動、中國聯通、中國電信、天翼雲、中移金科、Radore、ZaloPay 等海內外數萬家企業採用。KubeSphere 提供了開發者友好的嚮導式操作界面和豐富的企業級功能，包括 Kubernetes 多雲與多集羣管理、DevOps (CI/CD)、應用生命週期管理、邊緣計算、微服務治理 (Service Mesh)、多租户管理、可觀測性、存儲與網絡管理、GPU support 等功能，幫助企業快速構建一個強大和功能豐富的容器雲平台。&lt;/p&gt; 
&lt;p&gt;&amp;gt; 本文由博客一文多發平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom&quot; target=&quot;_blank&quot;&gt;OpenWrite&lt;/a&gt; 發佈！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4197945/blog/17646180</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/17646180</guid>
            <pubDate>Fri, 07 Feb 2025 09:37:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>阿里巴巴在上海成立智信普惠科技公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 App 顯示，上海智信普惠科技有限公司於 2025 年 2 月 17 日成立，位於上海市，是一家以從事軟件和信息技術服務業為主的企業。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;法定代表人為餘志乾，企業註冊資本 1000 萬人民幣。經營範圍含計算機軟硬件及輔助設備零售、網絡技術服務、信息技術諮詢服務、數字內容製作服務、數據處理服務、人工智能通用應用系統、人工智能應用軟件開發、互聯網信息服務等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;股東信息顯示，該公司由阿里巴巴旗下廣州大魚快樂信息技術有限公司全資持股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;189&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-50d477f860fc194e7c26bfc25727db08669.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334598</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334598</guid>
            <pubDate>Fri, 07 Feb 2025 09:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘇享茂哥哥：翟欣欣敲詐勒索數額 1199 萬元，無自首情節</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 17 日，翟欣欣敲詐勒索案死者蘇享茂的哥哥蘇享龍發文稱：翟欣欣敲詐勒索數額 1199.8821 萬元（既遂 859.8821 萬元，未遂 340 萬元），數額特別巨大，並造成被害人死亡的嚴重後果。沒有自首情節，對犯罪事實沒有如實供述……等待翟欣欣涉嫌敲詐勒索罪案判決。&lt;/p&gt; 
&lt;p style=&quot;color:#151631; margin-left:auto; margin-right:auto; text-align:left&quot;&gt;蘇享龍還附上了 2025 年 1 月 21 日被害人家屬在法庭的發言，發言稱蘇享龍和蘇享茂的父親前不久已經去世。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-412ef8361c75c664480113778e8a342e66f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-99ad7c2a7a1847eb1356acb32420257c266.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據此前消息：翟欣欣涉嫌敲詐勒索罪案 1 月 21 日在北京開庭。經過 3 個多小時的審理，翟欣欣敲詐勒索案在北京市海淀區人民法院山後人民法庭結束一審，該案件將擇期宣判。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/330908&quot; target=&quot;_blank&quot;&gt;「WePhone 創始人被前妻逼死」 案件最新進展：檢方建議量刑 10 年以上&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334585</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334585</guid>
            <pubDate>Fri, 07 Feb 2025 08:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>敢自稱 Java 版的 PyTorch，EasyAi 到底有幾斤幾兩？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;EasyAi 頗為高調。在其&lt;a href=&quot;https://gitee.com/dromara/easyAi&quot;&gt; Gitee 主頁&lt;/a&gt;介紹一欄，寫着「&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;國內人氣最高的 Java 人工智能算法框架&lt;/span&gt;&lt;/strong&gt;」，是「&lt;strong&gt;Java 版的 PyTorch&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;Java 在企業級開發中一直佔據統治地位，但是在 Ai 領域卻一直薄弱。在很多 Java 項目中，許多 AI 功能依賴調用 Python 庫來實現。有了 Java 原生，的 EasyAi 之後，&lt;span style=&quot;background-color:#ffffff&quot;&gt;只需用 Maven 工具就能將它&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;一鍵引入到 Java 項目，無需任何額外的環境配置與依賴，做到了開箱即用，很適合用來開發適合自家業務的小微模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;144&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b4447382f98ac9b7583b2c63a8935846d4e.png&quot; width=&quot;530&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;span style=&quot;color:#7f8c8d&quot;&gt;在 Gitee 上超過 5K 個 Star&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;此外，&lt;/span&gt;EasyAi &lt;span style=&quot;background-color:#ffffff&quot;&gt;包含了一些已經封裝好的圖像目標檢測及人工智能客服的模塊，同時提供各種深度學習、機器學習、強化學習、啓發式學習、矩陣運算、求導函數、求偏導函數等底層算法工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;EasyAi 的作者李大鵬，網名「唯一解」，他的經歷也頗為傳奇&lt;/strong&gt;：大專畢業後寫小説，曾經短暫地做過平面設計，後來自學轉碼農。先是搞前端開發，接着又從 Java 業務開發到遊戲開發，最後做算法研發。到現在已經有十二年碼齡了。這期間，李大鵬還做過銷售，寫過小説，當過牛馬，也創過業。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aa7d7ddd9a1afbc343061669e0f862120d8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;李大鵬説，想走一條不一樣的路——專注底層算法，儘管他自稱是「公司常年最低學歷保持者」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「當我第一次看到社區的小夥伴用 Easyai——而不是靠調用，靠自身的技術能力開發出一套人臉檢測模塊在公司線上服務器運行時，當我第一次看到有小夥伴使用 Easyai 開發出一套智能客服以極低的成本完成公司知識體構建時，我知道，我初步的設想邏輯成功了。」&lt;/p&gt; 
&lt;p&gt;事實上，李大鵬對於 EasyAi&amp;nbsp;的定位很明確，也知道它與 PyTorch 二者之間的差距。「 在人工智能主流領域，&lt;strong&gt;EasyAi 目前不可能是 PyTorch 的對手&lt;/strong&gt;，但它有獨特優勢：支持 JDK 1.6 及以上版本，採用原生 Java 構建，通過一次 Maven 引入，可以無縫集成到任何由 Java 構建的企業級服務中。憑藉非常低廉的使用成本，在中小企業內的 ai 模塊開發中撬開了一席之地。」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;EasyAi 並不是對主流算法 Java 的無差別重新實現&lt;/strong&gt;，而是根據應用場景對主流算法進行優化與魔改，保證普通服務器或個人電腦 CPU 下依然達到可用性能的流暢運行。 「easy」並不是隻是指的簡單，而是對算法進行了廉價，低成本方向的優化。&quot;如果我沒有辦法對某種算法做到廉價，我也不會放入 EasyAI 裏面。&quot;&lt;/p&gt; 
&lt;p&gt;對於 EasyAi 的未來，李大鵬的願望很樸素：將 AI 模型開發技術作為 Java 程序員未來全棧能力之一，讓 AI 開發就跟普通業務開發一樣，給 Java 程序員帶來新的飯碗。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt;
   2 月 21 日，開源中國將邀請 EasyAi&amp;nbsp; 作者李大鵬， 
  &lt;span style=&quot;background-color:#ffffff; color:#212529&quot;&gt;做客 「OSC 開源社區」 視頻號直播欄目&lt;strong&gt;【開源項目老牌與新秀】第 6 期&lt;/strong&gt;&lt;/span&gt;，聊一聊 EasyAi，看看這個敢自稱「 Java 版的 PyTorch」「 
  &lt;span style=&quot;background-color:#ffffff&quot;&gt;國內人氣最高的 Java 人工智能算法框架&lt;/span&gt;」，到底有幾斤幾兩！ 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;直播亮點：&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;自學轉碼農、搞算法，EasyAi 是怎麼來的？&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;敢自稱 「Java 版，的 PyTorch」，EasyAi 有何厲害之處？&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;如何開發自然語言&amp;amp;圖像自定義業務模型？&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;實操演示：訓練符合自身業務的智能客服微模型&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;大模型時代下，EasyAi 未來發展路線&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;預約直播&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;&lt;img height=&quot;718&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b766216e7d0426ecc05a55942453fe797b3.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;另外，我們還建了一個交流羣，一起聊聊自己喜歡的開源項目～～當然啦，如果你有什麼特別棒的開源項目，可以推薦過來呀～&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;396&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e7c43c0b0553350855a379af00c6c7c15d.jpg&quot; width=&quot;396&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了諸多社區或組織的大力支持，在此特別表示感謝：&lt;/strong&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（碼雲）是開源中國於 2013 年推出的基於 Git 的代碼託管平台、企業級研發效能平台，提供中國本土化的代碼託管服務。&lt;br&gt; 目前，Gitee 已經有超過 1350 萬名開發者，累計託管超過 3600 萬個代碼倉庫，是中國境內規模最大的代碼託管平台。同時，旗下企業級 DevOps 研發效能管理平台 Gitee 企業版已服務超過 36 萬家企業。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;網址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
   &lt;div&gt; 
    &lt;p&gt;&lt;strong&gt;Dromara 社區&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;Dromara 社區是一個自組織的開源社區，由頂級開源項目維護者創立。社區目前擁有 10 多個頂級開源項目和 30 多個優秀開源項目，涵蓋熱門工具、分佈式事務日誌、企業級鑑權、運維監控、調度編排等。這些開源項目服務於數百萬個人和中小企業。&lt;/p&gt; 
    &lt;p&gt;官網：https://dromara.org/&lt;/p&gt; 
    &lt;hr&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源項目老牌與新秀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是開源中國 OSCHINA 推出的一檔直播欄目，旨在為開源項目提供一個展示平台，每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請開源項目的作者、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的開源項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17645900</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17645900</guid>
            <pubDate>Fri, 07 Feb 2025 08:11:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>