<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 25 Feb 2025 02:38:57 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>「Apple 開發者」官方公眾號現已上線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;蘋果宣佈，現已推出面向開發者的官方公眾號，並將通過官方公眾號提供面向中文開發者社區的新聞、公告以及活動動態。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5f648f850dc1cc03d2d6e400f9b70691d08.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;公眾號目前提供活動註冊、資訊速覽和資源中心三項服務，除了按照月份為開發者彙總每月的蘋果資訊之外，開發者還可以通過資源中心獲得往屆活動的視頻、文檔和活動概況。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;454&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/103305_SQ9D_2720166.png&quot; width=&quot;1090&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/103532_OHTg_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而活動註冊板塊將會為用户提供蘋果開發者活動的跳轉鏈接，方便開發者瞭解最新活動情況並報名參與。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335611</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335611</guid>
            <pubDate>Tue, 25 Feb 2025 02:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>京東：外賣騎手五險一金全部由京東承擔，包含個人需繳納部分，外賣騎手現金收入不會減少</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;2 月 24 日，京東集團&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEi_gbPxrBGPOe1-bcNuRyA&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;，鑑於目前外賣騎手的平均薪酬遠低於京東快遞小哥，為了薪酬公平性，&lt;strong&gt;未來一段時期簽約的外賣全職騎手繳納五險一金的所有成本，包含個人所需繳納部分，全部由京東承擔，確保騎手現金收入絕不會因為繳納五險一金而減少，此項舉措包含現有騎手和新加入的騎手&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/102737_As5l_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此前，京東集團率先&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn3bZYhbZ-D2m-ki7zxCV5w&quot; target=&quot;_blank&quot;&gt;啓動&lt;/a&gt;為現有和新加入的京東外賣全職騎手繳納五險一金，為兼職騎手提供意外險和健康醫療險。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/102848_YHtR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此外，從知情人士處獲悉，&lt;strong&gt;京東近期公告所稱「外賣騎手」，所指為達達平台騎手，目前京東外賣業務配送由達達平台騎手負責&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;據悉，京東外賣未來將和京東物流實現人才打通，基於自願原則，京東快遞員可申請成為京東外賣全職騎手，京東外賣全職騎手也可申請成為京東快遞員。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335609</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335609</guid>
            <pubDate>Tue, 25 Feb 2025 02:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>拼多多斥巨資從百度鳳巢「挖來」核心成員，負責電商推薦大模型團隊</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FO8YhvcBg50STT2Z4wLOx1w&quot; target=&quot;_blank&quot;&gt;根據雷峯網的獨家報道&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;拼多多內部已經組建了電商推薦大模型團隊，負責人之前為百度鳳巢的核心成員&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;據消息人士透露，此人之前在百度時就已經是千萬級年薪，而這次拼多多給的誠意也很足，其年包是在百度時的數倍。另一消息人士透露稱，&lt;strong&gt;拼多多去年就從百度招了一批人來做大模型相關的項目&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;目前，拼多多大模型產品分為幾個應用：比價系統、推薦、廣告、搜索、客服領域等，這些應用領域一直都有持續投入在做。據稱，&lt;strong&gt;每個小組的大模型團隊會互相進行賽馬，收益以幾個小組直接 PK 的結果為準&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;目前，阿里、字節、騰訊、美團、小紅書等在內的大廠都已經佈局大模型，並且都對外進行了發佈，唯有拼多多一直保持低調。此前業界也傳出過拼多多大模型的消息。&lt;/p&gt; 
&lt;p&gt;2023 年 11 月，多個招聘信息顯示，拼多多高薪招聘 NLP 大模型算法工程師，成立 AI 大模型團隊，探索 AI 大模型在客服、對話等場景下的應用。不過，據媒體報道，對於該動向，當時拼多多內部人士解釋稱，「公司在 AI 大模型上暫時沒啥佈局，內部確實在做 AI 智能客服，但算不上大模型量級。」&lt;/p&gt; 
&lt;p&gt;眼下，互聯網大廠紛紛接入 DeepSeek，AI 產業鏈迎來新拐點，對於外界來説，拼多多接下來會採取怎樣的動作來應對這波衝擊顯得尤為關鍵。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335604</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335604</guid>
            <pubDate>Tue, 25 Feb 2025 02:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Anthropic 推出 Claude 3.7 Sonnet 和 Claude Code</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Anthropic 宣佈推出 Claude 3.7 Sonnet，稱這是其迄今為止最智能的模型，也是市場上首款混合推理模型。同時還推出了用於代理編碼的命令行工具 Claude Code（研究預覽版），使開發者可直接通過終端將重要工程任務委託給 Claude 完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，Claude 3.7 Sonnet 的理念與市場上其他推理模型不同。「正如人類使用單個大腦進行快速反應和深度思考一樣，我們認為推理應該是前沿模型的綜合能力，而不是完全獨立的模型。這種統一的方法也為用户創造了更無縫的體驗。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Claude 3.7 Sonnet 既是普通 LLM 也是推理模型：用户可以選擇何時讓模型正常回答，何時在回答前進行更長時間的思考。在標準模式下，Claude 3.7 Sonnet 是 Claude 3.5 Sonnet 的升級版。在擴展思考模式下，它會在回答前進行自我反思，從而在數學、物理、指令遵循、編碼等許多任務上提高其性能。在兩種模式下對模型的提示效果相似。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過 API 使用 Claude 3.7 Sonnet 時，用户還可以控制思考的「預算」：可以告訴 Claude 思考不超過 N 個 token，其中 N 的值可以是任意值，直到其輸出限制的 128K 個令牌。這允許用户在速度（和成本）與答案質量之間進行權衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Anthropic 稱，他們在開發推理模型時，對數學和計算機科學競賽問題的優化較少，而是將重點轉向更能反映企業實際如何使用 LLM 的現實任務。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;早期測試表明，Claude 在編碼能力方面全面領先：Cursor 指出，Claude 在實際編碼任務中再次名列前茅，在處理複雜代碼庫和高級工具使用等領域都有顯著改進。Cognition 發現，在規劃代碼更改和處理全棧更新方面，Claude 遠勝於任何其他模型。Vercel 強調了 Claude 在複雜代理工作流程中的卓越精確度，而 Replit 已成功部署 Claude 從頭開始構建複雜的 Web 應用程序和儀錶板，而其他模型則停滯不前。在 Canva 的評估中，Claude 始終如一地生成可用於生產的代碼，具有卓越的設計品味，並大大減少了錯誤。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ec3610ee2c07de8f0856070bfe717496a93.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;279&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e62dece12fd2e64eec299238c9356ccf07.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1349d86d864b9358768b5657ec70e65d394.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前 Claude 3.7 Sonnet 已全面支持所有 Claude 計劃（包括免費版、專業版、團隊版和企業版），以及 Anthropic API、Amazon Bedrock 和 Google Cloud 的 Vertex AI。且除免費 Claude 版外，擴展思考模式在所有計劃上均可用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在標準模式和擴展思考模式下，Claude 3.7 Sonnet 的價格與其前代產品相同：每百萬輸入令牌 3 美元，每百萬輸出令牌 15 美元——包括思考令牌。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-3-7-sonnet&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335602/claude-3-7-sonnet</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335602/claude-3-7-sonnet</guid>
            <pubDate>Tue, 25 Feb 2025 02:13:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>deepseek 官網太慢？別急 macOS 上有滿血替代版</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;deepseek 官網老是超時，十分不爽，每次輸入網頁也麻煩，所以我習慣直接用 macOS app&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src=&quot;https://oscimg.oschina.net/oscnet//6f7294b2d3271e2275305ff746b7de35.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;但是我覺得最適合小白和 mac 用户的還是 deeplink app。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9ba54725e897af2ed55b2b387ef86213.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;如果你是資深玩家，也可以直接調用官網或者第三方的 api key，然後使用支持 openai 接口的聚合客户端就可以直接使用了。&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;再也不用擔心超時了&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &lt;span&gt;&lt;span&gt;但是如果你不想折騰，可以直接在 macOS App Store 找到這款 app，安裝就可以直接用了，安裝難度約等於 0～&lt;/span&gt;&lt;/span&gt;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt;
       &lt;img src=&quot;https://oscimg.oschina.net/oscnet//76b01747a3003f042dec528466db6b7b.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
       &lt;div&gt;
        &amp;nbsp;
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335574</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335574</guid>
            <pubDate>Sat, 22 Feb 2025 14:44:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>中國信通院「軟件供應鏈管理」系列評估 2025 新規劃</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中國信息通信研究院雲計算與大數據研究所自 2019 年起開展軟件供應鏈管理相關研究工作，搭建軟件供應鏈管理標準體系。&lt;/p&gt; 
&lt;p&gt;截至目前，由中國信息通信研究院牽頭，廣泛邀請包括金融、互聯網、運營商、軟件廠商、安全廠商、工具廠商等個行業領域專家參與，共同編制了 4 項行業標準和 6 項團體標準，具體如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;行業標準：《可信研發運營安全能力成熟度模型》、《靜態應用程序安全測試工具能力要求》、《交互式應用程序安全測試工具能力要求》、《運行時應用程序自我保護工具能力要求》&lt;/li&gt; 
 &lt;li&gt;團體標準：《軟件供應鏈安全管理要求》、《軟件物料清單總體能力要求》、《面向供應鏈的信息技術產品通用安全能力要求》、《軟件物料清單配套工具能力要求》、《軟件供應鏈製品管理平台能力要求》、《研發運營安全平台能力要求》&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;軟件供應鏈管理系列評估&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為助力企業提升軟件供應鏈安全建設能力，定位建設短板，中國信通院依據標準開展測試評估工作，包&lt;strong&gt;括企業維度、產品維度和工具維度&lt;/strong&gt;三大部分，如下圖所示，&lt;strong&gt;其中標紅的均為 2025 首批評估&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;除此之外，中國信通院今年的軟件供應鏈管理系列評估還引入了新規劃，面向對象包括&lt;strong&gt;企業能力、管理平台和安全工具&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;723&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/192818_U3MK_2720166.png&quot; width=&quot;1381&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjBTc6BJcF2oqNS_X4xpVjw&quot; target=&quot;_blank&quot;&gt;點此查看詳情&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335539</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335539</guid>
            <pubDate>Sat, 22 Feb 2025 11:37:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>SLSA：谷歌開源的軟件供應鏈安全框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SLSA：Supply-chain Levels for Software Artifacts （軟件工件的供應鏈級別）是一個端到端的框架，用於確保整個軟件供應鏈中的軟件工件的完整性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f1778dd4bbb5da70f851b47b2288d7e902a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;重要提示：SLSA 是一個不斷發展的規範，正在通過 GitHub issues、電子郵件或反饋表尋找廣泛的反饋。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;SLSA 包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;標準&lt;/strong&gt;：（本文檔）業界對 「安全」 軟件供應鏈定義的共識。可能有多種標準來表示安全的多個方面。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;認證&lt;/strong&gt;：組織證明符合這些標準的過程。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fslsa-framework%2Fslsa%2Fblob%2Fmain%2Fcontrols%2FREADME.md&quot; target=&quot;_blank&quot;&gt;技術控制&lt;/a&gt;&lt;/strong&gt;：記錄出處並檢測或防止違規。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;最終，軟件消費者決定信任誰以及執行什麼標準。&lt;/p&gt; 
&lt;p&gt;有鑑於此，認證是一種跨組織邊界傳遞信任的手段。例如，一家公司可能會在內部 「認可」 其內部源和構建系統，同時依靠 OpenSSF 來認可第三方。其他組織可能信任其他認證機構。&lt;/p&gt; 
&lt;p&gt;本文件只討論第一部分，標準。我們希望隨着時間的推移制定認證流程和技術控制。在此期間，這些級別可以作為指導如何保護軟件供應鏈提供價值。&lt;/p&gt; 
&lt;h2&gt;原則&lt;/h2&gt; 
&lt;p&gt;SLSA 側重於以下兩個主要原則：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;非單方面&lt;/strong&gt;：任何人都不能修改軟件供應鏈中任何地方的軟件工件，除非經過至少一個其他 「受信任的人」 的明確審查和批准。目的是預防、威懾和 / 或早期發現風險的變化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可審計&lt;/strong&gt;：軟件工件可以安全透明地追溯來源和依賴項。主要目的是自動分析來源和依賴關係，以及臨時調查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管並不完美，但這兩個原則為廣泛的篡改、混淆和其他供應鏈攻擊提供了實質性的緩解。&lt;/p&gt; 
&lt;p&gt;為了根據上述兩個原則衡量供應鏈的保護程度，我們提出了 SLSA 級別。更高的級別意味着它得到更好的保護。&lt;strong&gt;SLSA 4 是最終目標&lt;/strong&gt;，但對於大型組織而言可能需要多年時間和大量投資。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335534</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335534</guid>
            <pubDate>Sat, 22 Feb 2025 11:04:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>SBOM Tool：微軟開源的 SBOM 工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SBOM Tool 是一個 SBOM（Software Bill of Materials，軟件物料清單）工具，是一種高度可擴展且企業就緒的工具，可以為各種工件創建與 SPDX 2.2 兼容的 SBOM，用於幫助技術行業和 IT 決策者更好地瞭解其工具的安全性以及軟件供應鏈的依賴關係。&lt;/p&gt; 
&lt;p&gt;SBOM Tool 創建的文檔包含四個主要部分，包括文檔創建信息（其中包含軟件名稱、SPDX 許可證、SPDX 版本、文檔創建者和創建時間）、組成軟件的文件列表、構建軟件時使用的軟件包列表，以及 SBOM 不同元素之間的關係列表。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2022/0714/153013_pdyZ_4937141.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;安裝&lt;/h3&gt; 
&lt;p&gt;SBOM Tool 支持 Windows、Mac 和 Linux，請檢查&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fsbom-tool%2Freleases&quot; target=&quot;_blank&quot;&gt;Release&lt;/a&gt;頁面以轉到你要安裝的工具的版本，然後從 Release 中下載所需運行時的工具。&lt;/p&gt; 
&lt;h3&gt;運行該工具以生成 SBOM&lt;/h3&gt; 
&lt;p&gt;一旦你為你的操作系統安裝了命令行工具，使用以下命令運行該工具。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;generate -b &amp;lt;drop path&amp;gt; -bc &amp;lt;build components path&amp;gt; -pn &amp;lt;package name&amp;gt; -pv &amp;lt;package version&amp;gt; -nsb &amp;lt;namespace uri base&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335527</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335527</guid>
            <pubDate>Sat, 22 Feb 2025 10:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>IntelliJ IDEA 2025.1 EAP 6 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#19191c&quot;&gt;IntelliJ IDEA 2025.1 EAP 6 現已發佈，具體更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h3 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;Kotlin&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;增強&lt;code&gt;main.kts&lt;/code&gt;依賴解析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;IntelliJ IDEA 2025.1 EAP 6 增強了 Kotlin 構建腳本中依賴解析的用户體驗。以前，&lt;code&gt;main.kts&lt;/code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FKotlin%2Fkotlin-script-examples%2Fblob%2Fmaster%2Fjvm%2Fmain-kts%2FMainKts.md&quot; target=&quot;_blank&quot;&gt;依賴解析&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;與代碼高亮顯示並行運行，導致代碼先顯示為紅色，然後在依賴加載完成後變為綠色。。此過程有時會導致卡頓，並且缺乏明確的反饋和控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;現在，解決方案更加穩定和可預測。用户可以使用「Load script dependencies」按鈕跟蹤其進度。沒有依賴項的腳本會立即打開，無需進行不必要的處理即可高亮顯示。此方案還在持續改進中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-32ae2e2461a5d4c5c4d27fb3c56e38acd6b.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;Interactive scratch files in K2 mode&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jetbrains.com%2Fhelp%2Fidea%2Fscratches.html%23use-dependency-in-scratch-file&quot; target=&quot;_blank&quot;&gt;現在，Kotlin K2 模式下可以使用 Scratch 文件&lt;/a&gt;，讓你可以在與項目相同的 IDE 窗口中創建和運行代碼草稿。通過交互式執行，可以立即看到結果，從而減少反饋循環並使實驗更加順暢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c7c33c155cbde65d3512428b3375e3a4e58.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:start&quot;&gt; 
 &lt;h4 style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;關於 Kotlin 編譯器插件導致的代碼變更的提示&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;通過此更新，IntelliJ IDEA 現在可以更清楚地瞭解編譯器插件引入的修改，使其行為更加透明。Kotlin 具有多個功能強大的編譯器插件，可用於各個領域，例如&lt;code&gt;kotlinx.serialization&lt;/code&gt;和&lt;code&gt;all-open&lt;/code&gt;，它們可以改變 Kotlin 代碼的行為方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#19191c&quot;&gt;編譯器插件可以進行的一些關鍵修改包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;&lt;strong&gt;更改聲明方式&lt;/strong&gt;– 編譯器插件可以修改聲明方式，這意味着「final」聲明可能會變為 open 狀態。&lt;code&gt;all-open&lt;/code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fall-open-plugin.html&quot; target=&quot;_blank&quot;&gt;插件&lt;/a&gt;正是這樣做的。為了説明聲明方式已被更改，IntelliJ IDEA 現在會顯示此信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;201&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7158139ac2cece18d2c01ea0f6e1dc34e3f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul style=&quot;margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;&lt;strong&gt;向現有類添加新的 supertypes&amp;nbsp;&lt;/strong&gt;– 某些插件會引入新的 supertypes。&lt;code&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkotlinlang.org%2Fdocs%2Fserialization.html&quot; target=&quot;_blank&quot;&gt;kotlinx.serialization&lt;/a&gt;&lt;/code&gt;為使用&lt;code&gt;@Serializable&lt;/code&gt;註釋的聲明添加了 KSerializer supertype。這些 supertypes 現在在 IntelliJ IDEA 中可見。&amp;nbsp;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F02%2Fintellij-idea-2025-1-eap-6%2F&quot; target=&quot;_blank&quot;&gt;查看官方博客&lt;/a&gt;。&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335520/intellij-idea-2025-1-eap-6</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335520/intellij-idea-2025-1-eap-6</guid>
            <pubDate>Sat, 22 Feb 2025 09:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>YY 語音公司接入 DeepSeek：上線 「YYDS」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;YY 公司今日宣佈接入 DeepSeek，並推出「低延時、不卡頓」的 YY-DeepSeek R1-滿血版（簡稱「YYDS」），旗下 YY 直播、YY 語音等產品已經上線產品入口。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c01b204e529a6a97503bf303907c13d975.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據 YY 相關負責人介紹，YYDS 是 YY 順應用户需求推出的 AI 大模型產品，不僅全面支持 DeepSeek V3 聯網和 R1 深度思考模式，還通過服務器的優化改進解決了 DeepSeek 的卡頓、響應遲緩等問題，實現「低延時、不卡頓的順暢使用體驗」。&lt;/p&gt; 
&lt;p&gt;YY 方面表示，未來，YY 還將與 DeepSeek 進行產品的深度結合，推出具有 DeepSeek 功能的智能體社區，打造智能體官頻及頻道內智能體組件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-81c2ffbea41abd3f4c5c56339c803644e77.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;YY 是一家語音社交、視頻直播企業，公司總部位於廣東省廣州市。YY 是中文「語音」拼音首字母的縮寫，2008 年即時通訊軟件「YY 語音」上線，YY 正式走入大眾視野，後續陸續推出了 YY 直播、百戰直播、Yo 語音、YY 開播工具等多款產品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335518</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335518</guid>
            <pubDate>Sat, 22 Feb 2025 09:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Repomix —— 將你的代碼庫打包成 AI 友好格式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;Repomix（以前稱為 Repopack）是一款功能強大的工具，可將你的整個存儲庫打包成一個 AI 友好文件。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;當你需要將代碼庫提供給大型語言模型 (LLM) 或其他 AI 工具（如 Claude、ChatGPT、DeepSeek、Perplexity、Gemini、Gemma、Llama、Grok 等）時，它非常適合。&lt;/span&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;人工智能優化&lt;/strong&gt;：以人工智能易於理解和處理的方式格式化你的代碼庫。&lt;/li&gt;
&lt;li&gt;&lt;strong style=&quot;color:#1f2328&quot;&gt;Token Counting&lt;/strong&gt;：提供每個文件和整個存儲庫的 token 計數，對於 LLM 上下文限制很有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用簡單&lt;/strong&gt;：你只需一個命令即可打包整個存儲庫。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可定製&lt;/strong&gt;：輕鬆配置要包含或排除的內容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Git-Aware&lt;/strong&gt;：自動遵循你的.gitignore 文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;以安全為中心&lt;/strong&gt;：結合&lt;a href=&quot;https://github.com/secretlint/secretlint&quot;&gt;Secretlint&lt;/a&gt;進行強大的安全檢查，以檢測和防止敏感信息的包含。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/repomix</link>
            <guid isPermaLink="false">https://www.oschina.net/p/repomix</guid>
            <pubDate>Sat, 22 Feb 2025 08:58:00 GMT</pubDate>
        </item>
        <item>
            <title>Mozilla 宣佈領導層變動</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla 總裁馬克·瑟曼 (Mark Surman) &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fen%2Fmozilla%2Fmozilla-leadership-growth-planning-updates%2F&quot; target=&quot;_blank&quot;&gt;發文&lt;/a&gt;宣佈了該公司最新的領導層變動情況，包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;Mozilla 領導委員會：&lt;/strong&gt;由 Mozilla 各組織的高管組成的 Mozilla 領導委員會，旨在更好地協調各組織工作。小組成員包括：Jane Silber（&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FMozilla.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;）、Laura Chambers（Mozilla Corporation）、Mohamed Nanabhay（Mozilla Ventures）、Nabiha Syed（Mozilla Foundation）、Ryan Sipes（MZLA/Thunderbird）和 Mark Surman 本人。其中，Mark Surman 將擔任主席。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;新任 Mozilla 基金會董事會主席 Nicole Wong、Mozilla Corporation 董事長 Kerry Cooper 以及 &lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FMozilla.ai&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mozilla.ai&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 主席 Raffi Krikorian。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;269&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06539fd667c27535822aae43da11d7dfce0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Firefox 聯合創始人 Mitchell Baker 宣佈離職，不再擔任 Mozilla 基金會和 Mozilla 公司董事會主席或成員。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Mark Surman 稱，希望能在今年年底為&amp;nbsp;Mozilla Corporation（MoCo） 和 Mozilla.ai&amp;nbsp;找到新的常任首席執行官。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我們認識到 Mozilla 在財務增長和使命影響方面都面臨重大阻力。雖然 Firefox 仍然是我們工作的核心，但我們也需要採取措施實現多元化：投資尊重隱私的廣告，以在短期內增加新收入；開發值得信賴的開源 AI，以確保中期技術和產品的相關性；並創建在線籌款活動，以吸引更多的支持者。Mozilla 的影響力和生存取決於我們同時加強 Firefox 和尋找新的收入來源以及以新的方式體現我們的使命。這就是我們在所有這些方面努力工作的原因。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335497/mozilla-leadership-growth-planning-updates</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335497/mozilla-leadership-growth-planning-updates</guid>
            <pubDate>Sat, 22 Feb 2025 08:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>美國人工智能安全研究所可能面臨大幅裁員</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F02%2F22%2Fus-ai-safety-institute-could-face-big-cuts%2F&quot; target=&quot;_blank&quot;&gt;外媒消&lt;/a&gt;息稱，美國國家標準與技術研究院（NIST）可能解僱多達 500 名員工，從而進一步威脅到其國內剛剛起步的人工智能（AI）安全組織。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.axios.com%2Fpro%2Ftech-policy%2F2025%2F02%2F19%2Fnist-prepares-to-cut-ai-safety-institute-chips-staff&quot; target=&quot;_blank&quot;&gt;Axios 報道稱&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，美國人工智能安全研究所 (AISI) 和 Chips for America（均隸屬於 NIST）將因裁減試用期員工而「損失慘重」。&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-02-19%2Fcommerce-agency-to-order-mass-firing-of-chips-ai-staffers&quot; target=&quot;_blank&quot;&gt;彭博社&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;則指出，其中一些員工已經收到了即將被解僱的口頭通知。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;甚至在最新的裁員報告發布之前，AISI 的未來就已經顯得不確定。該研究所旨在研究人工智能開發的風險並制定相關標準，是去年根據時任美國總統喬·拜登（Joe Biden）關於人工智能安全的行政命令成立的。唐納德·特朗普（Donald Trump）在重返辦公室的第一天就廢除了該命令，而 AISI 的主任也在今年 2 月初離職。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffortune.com%2F2025%2F02%2F20%2Ftrump-doge-layoffs-nist-aisi-ai-safety-concerns%2F&quot; target=&quot;_blank&quot;&gt;財富&lt;/a&gt;》雜誌採訪了許多人工智能安全和政策組織，他們都對報道的裁員事件提出了批評。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;223&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5fd1098816d9544bbeeb641e241ca7cc411.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人工智能政策中心（Center for AI Policy）執行主任 Jason Green-Lowe 表示：「如果這些裁員得到確認，將嚴重影響政府研究和解決關鍵人工智能安全問題的能力，而這種專業知識目前比以往任何時候都更加重要。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335494/nist-big-cuts</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335494/nist-big-cuts</guid>
            <pubDate>Sat, 22 Feb 2025 08:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>韓國：2 年內大多數半導體技術被中國趕超</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韓聯社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yna.co.kr%2Fview%2FAKR20250221088900017&quot; target=&quot;_blank&quot;&gt;報道稱&lt;/a&gt;，韓國科學技術企劃評價院（KISTEP）23 日發佈的《三大系統領域技術水平深層分析》報告顯示，以去年為準，韓國半導體領域的技術基礎力量在所有項目上都落後於中國。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一報告基於對 39 名當地專家進行的調查，這些人此前曾參與了韓國在 2022 年進行的技術水平評估，當時他們認為韓國在各方面均處於領先地位，但這一結論僅過了兩年就被推翻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;398&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9d0d395bf86e8aed2c302c3235c8af896c0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，韓國在高集成度、低阻抗存儲技術方面排名第二，得分為 90.9%，低於中國的 94.1%；在高性能、低功耗人工智能（AI）半導體領域，韓國以 84.1% 低於中國的 88.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在功率半導體方面，韓國為 67.5%，中國為 79.8%，新一代高性能傳感技術方面，韓國為 81.3%，中國為 83.9%。在半導體先進封裝技術方面，韓國和中國同樣為 74.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業化的觀點來看，韓國在高集成、低阻抗存儲技術和半導體先進封裝技術方面暫時領先於中國。對整個半導體行業技術生命週期的評估調查也顯示，韓國在工藝和量產方面領先於中國，但在基礎、源頭和設計領域落後於中國。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335485</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335485</guid>
            <pubDate>Sat, 22 Feb 2025 07:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>經濟日報：大模型免費不是單方讓利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用户之間的雙向互動。在這場變革中，雙方都從中有所收穫。儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。此外，免費必然帶來大量用户，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，多家大模型廠商宣佈免費開放其大模型服務，引發關注。例如，文心一言將於 4 月 1 日 0 時起全面免費，所有 PC 端和 APP 端用户均可體驗其最新模型；阿里巴巴推出的通義千問系列不僅面向開發者開放 API 接口，還提供了大量免費額度供普通用户調用；谷歌、Meta 等國際巨頭相繼發佈了可供研究者和小型團隊使用的免費版本……&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從高端科技到親民價格，大模型免費潮的到來並非偶然。一方面，大模型的研發成本雖然高昂，但邊際成本卻相對較低。一旦完成模型訓練，新增用户並不會顯著增加成本，通過免費開放吸引更多用户參與，可以在迅速擴大市場份額的同時，積累寶貴的數據資源用於後續優化；另一方面，大模型開源和免費開放的趨勢逐漸明朗，迫使之前選擇閉源的廠商打破封閉生態，以吸引更多的用户和開發者加入。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;從商業模式角度來看，技術普惠是互聯網開放共享精神的重要體現，免費和低價也是互聯網行業的主流策略之一。從早期搜索引擎的免費使用，到社交媒體平台的零門檻註冊，再到如今雲存儲、辦公軟件等工具的低門檻普及，「免費+增值服務」的模式已經被證明是一種行之有效的商業路徑。在人工智能領域，大模型廠商也藉助技術和資金優勢，通過免費使用形式，加速大模型服務的推廣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費背後，不是一種單方面的讓利行為，而是一場企業與用户之間的雙向互動。在這場變革中，雙方都從中有所收穫。對於用户而言，這意味着獲取先進 AI 技術的成本大幅下降。對企業而言，海量用户羣帶來的反饋信息，為調整產品方向提供了依據。大模型走上普惠化道路，本質上是一種雙贏，既滿足了用户對高效便捷工具的需求，又為企業帶來了新的發展機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管大模型免費有諸多積極意義，但其可持續性問題依然值得關注。大模型的訓練過程需要消耗大量算力和數據資源，即便是在免費階段，企業也需持續進行迭代升級，投入成本不容小覷。免費低價時代的到來，可能加速企業間的競爭。AI 賽道的老玩家依靠成熟的技術路線和雄厚的資金實力，可以進一步壓縮後來者的生存空間。新進入者如果短期無法找到有效的盈利途徑，那麼長期虧損的風險將不可避免。此外，免費必然帶來大量用户，由此帶來大量的數據收集，隱私保護、泄密防範等問題必須得到重視，否則可能會引發信任危機，進而影響服務提供者的口碑和發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型免費，無疑是當前人工智能發展歷程中的一個重要趨勢。這一趨勢能帶來怎樣的新局面，仍取決於各方能否妥善應對其中的挑戰。只有在確保經濟效益與社會效益相統一的前提下，大模型免費才能真正成為推動全球創新的重要力量。（經濟日報記者，劉 莉）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335477</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335477</guid>
            <pubDate>Sat, 22 Feb 2025 06:48:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Ubuntu 25.04 進入特性凍結階段，預計 4 月正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Canonical 工程師 Utkarsh Gupta &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-devel-announce%2F2025-February%2F001366.html&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt; Ubuntu 25.04 已進入特性凍結階段，並且一切都在按部就班推進。&lt;/p&gt; 
&lt;p&gt;按照計劃，Ubuntu 25.04 將於 3 月 13 日進入 UI 凍結階段，3 月 20 日進入內核特性凍結階段，3 月 27 日發佈 beta 版本，4 月 3 日開始內核凍結，4 月 10 日進入最終凍結階段。如果一切順利，Ubuntu 25.04 將於 4 月 17 日正式發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95aa95335baad09f1eccadb56afefae58b8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Ubuntu 25.04 預計將搭載 Linux 6.14 內核，默認使用 GNOME 48 桌面，Mesa 25.0 將提供更優的圖形驅動支持。GIMP 3.0 將在 Ubuntu 25.04 上提供，此外還將持續改進安裝程序，而且 Canonical 也持續強調性能優化。當然還有許多 Ubuntu 25.04 的底層改進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335474/ubuntu-25-04-feature-freeze</guid>
            <pubDate>Sat, 22 Feb 2025 06:41:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>深圳：近期將發佈人形機器人專項政策</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2 月 23 日，深圳市政府新聞辦召開「打造最好科技創新生態和人才發展環境」新聞發佈會。會上，市工業和信息化局副局長、深圳市人工智能產業辦公室主任林毅表示，深圳在人工智能和機器人領域起步較早、基礎較好，有「兩個一」：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第一個是有一支專業的產業隊伍，組建市人工智能產業辦公室，以專業、精幹隊伍推動產業發展。第二個是有一批優質的企業，全市已匯聚人工智能企業 2600 餘家、獨角獸企業 6 家，機器人上市企業 34 家、獨角獸企業 9 家，創新活力持續迸發。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ec3f039d40cf1534569b1e3badaaa604dd.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;林毅在發佈會上透露，接下來，深圳將向企業發放最高 60%、最高 1000 萬元的「訓力券」補貼，以及模型券、語料券、場景補貼等。&lt;strong&gt;「今年市區將多渠道籌集 45 億元政策資金，3 月起接受企業申報，歡迎廣大企業關注。」&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，近期深圳還將發佈人形機器人專項政策，通過揭榜掛帥等方式，對開放應用場景、突破關鍵技術、構建專用數據集、提升規模化製造和應用能力等予以精準支持。同時，還將在全市科技重大專項中設立&lt;strong&gt;人工智能和機器人專項&lt;/strong&gt;，鼓勵產、學、研、用組成創新聯合體進行協同攻關。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335449</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335449</guid>
            <pubDate>Sat, 22 Feb 2025 03:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apple 準備將谷歌 Gemini 與蘋果智能進行整合</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Faaronp613%2Fstatus%2F1893058313316671627&quot; target=&quot;_blank&quot;&gt;據報道&lt;/a&gt;，在與 iOS 18.4 測試版一起推送的後台更新中，蘋果現在在蘋果智能中為第三方模型提供了谷歌和 OpenAI 兩個選項。這代表蘋果有意為蘋果智能提供更多基礎大模型供應。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1576&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0224/114953_zK72_2720166.png&quot; width=&quot;1278&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;雖然這並不一定證實我們會在 iOS 18.4 的後期看到 Gemini 集成，特別是考慮到迄今為止發生的所有其他 Apple Intelligence 延遲，但它幾乎證實它會在不久的將來的某個時候出現，也許是在以後的 iOS 18 更新或 iOS 19 中。蘋果預計將在 iOS 19 中發佈自己的對話式 Siri 模型。&lt;/p&gt; 
&lt;p&gt;谷歌最近發佈了一些新的 Gemini 2.0 模型，包括一個新的推理模型。在不久的將來，這些新模型有可能會在 iPhone 上亮相。&lt;/p&gt; 
&lt;p&gt;有消息稱，蘋果預計將在 iOS 19 中發佈自己的對話 Siri 模型，而蘋果可能會允許用户在 Gemini 和 ChatGPT 之中進行選擇。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335448</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335448</guid>
            <pubDate>Sat, 22 Feb 2025 03:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>得物端智能視頻封面推薦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h2&gt;什麼要做智能封面？&lt;/h2&gt; 
&lt;p&gt;用户可以在得物購物，也可以在得物社區分享自己的生活。&lt;/p&gt; 
&lt;p&gt;得物社區中的視頻使用雙列流，每條內容包含封面、標題等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對得物社區的創作者而言，選擇視頻封面是創作鏈路的重要環節。&lt;/li&gt; 
 &lt;li&gt;對得物社區的消費者而言，封面是影響 CTR（點擊率）的關鍵因素。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;封面推薦可以降低創作者的創作成本，提高消費者 CTR。&lt;/p&gt; 
&lt;h2&gt;端智能介紹&lt;/h2&gt; 
&lt;p&gt;端智能（Edge/Client Intelligence）是指在邊緣設備（如物聯網設備、智能傳感器、移動設備等）上進行數據處理和智能決策的能力。與雲計算模型相比，端智能將計算、存儲和分析功能移到更接近數據源的地方，優勢如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;低延遲 ：數據在本地處理，減少了傳輸到遠程服務器的時間，提高響應速度。&lt;/li&gt; 
 &lt;li&gt;節省帶寬 ：通過在本地處理數據，僅發送必要的信息到中心服務器，減少了網絡帶寬的消耗。&lt;/li&gt; 
 &lt;li&gt;數據隱私和安全 ：數據在本地處理，敏感信息不必傳輸到雲，從而提高了數據隱私和安全性。&lt;/li&gt; 
 &lt;li&gt;可靠性 ：在網絡連接不穩定或中斷的情況下，邊緣設備可以繼續進行本地處理和決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;儘管端智能帶來了很多優勢，但在實際應用中也面臨一些挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算能力的侷限性 ：邊緣設備通常具有有限的計算資源，可能無法處理複雜的人工智能模型。&lt;/li&gt; 
 &lt;li&gt;數據一致性與協同 ：多個邊緣設備之間的數據一致性和協調處理仍然是一個挑戰。&lt;/li&gt; 
 &lt;li&gt;設備管理與部署 ：隨着設備數量的增加，邊緣設備的管理、監控和更新變得更加複雜。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到用户隱私、實時性和服務端壓力，我們選擇用端智能推薦視頻封面，並克服相關的挑戰，最終獲得收益。&lt;/p&gt; 
&lt;h2&gt;得物端智能&lt;/h2&gt; 
&lt;p&gt;對客户端而言，不需要訓練模型，只需要推理。&lt;/p&gt; 
&lt;p&gt;端智能框架可以簡化推理過程，常見的端智能 SDK 如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;開源 SDK：MNN、TNN、NCNN、&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot; title=&quot;Paddle&quot;&gt;Paddle&lt;/a&gt; Light、TensorFlow Light 等。&lt;/li&gt; 
 &lt;li&gt;閉源 SDK：ByteNN、Pitaya、KwaiNN、Ykit 等。&lt;/li&gt; 
 &lt;li&gt;系統 SDK：CoreML（iOS）、MLKit（Android）等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;考慮到 iOS、Android 雙端的通用性和開發成本，得物基於 MNN [1] 框架，開發得物端智能推理基建。端智能基建核心功能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;提供端智能模型管理後台，提供完整鏈路，管理模型的放量。&lt;/li&gt; 
 &lt;li&gt;端側提供統一的基建，方便業務進行模型的下載、運行管理，以及熔斷和降級的處理，降低使用門檻。&lt;/li&gt; 
 &lt;li&gt;提供相對完善的穩定性和性能監控機制，及時報警和出錯時止損。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;整體架構&lt;/h2&gt; 
&lt;p&gt;智能封面主要開發流程如下，算法側產出端智能模型，客户端調用模型推薦視頻封面。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2a5620265c413a531beb927527e7f902.jpeg&quot; alt=&quot;整體架構.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、內容理解算法&lt;/h1&gt; 
&lt;h2&gt;算法調研&lt;/h2&gt; 
&lt;p&gt;端智能封面推薦場景要求無參圖片質量評價 (NR-IQA)、輕量化，因此基於目前的前沿進展進行調研和摸底，確定相關實現方案。主要的調研內容：&lt;/p&gt; 
&lt;p&gt;Faster-VQA[2]：輕量化的視頻質量評估模型。核心是使用優化版本的 Transformer-&amp;gt;Swin-Transformer 來減少網絡計算，加速效率。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df87fd35910cb12fffbd3bdbc6c9e6ac.jpeg&quot; alt=&quot;算法調研.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;UNIQA[3]：統一的圖像質量評估 (IQA) 框架，旨在同時處理全參考 (FR) 和無參考 (NR) 任務。現有的 IQA 模型通常只能處理 FR 或 NR 任務之一，而人類視覺系統 (HVS) 則可以無縫地在兩者之間轉換，因此提出開發一個能夠像人類一樣處理不同類型圖像質量評估任務的模型，統一全參/無參兩類任務。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://my.oschina.net/u/5783135/blog/3&quot; alt=&quot;統一全參:無參.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LAR-IQA[4]：輕量級的 NR-IQA 模型，基於 MobileNetV3 提出了一種新的無參考圖像質量評估模型 LAR-IQA。該模型旨在解決現有模型在實際應用中的侷限性，特別是對於資源受限的移動設備上的實時圖像質量評估任務。核心貢獻點有：雙分支架構、多色空間訓練、Kolmogorov-Arnold Networks (KAN) 結構代替 MLP。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//19f3a290089fee79f78a533eedab4a76.jpeg&quot; alt=&quot;代替 MLP.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;CLIP-IQA[5]：利用 (引入) 對比語言-圖像預訓練 ( CLIP）模型來評估圖像的視覺感知，包括圖像的質量 (look) 和抽象感知 (feel)，無需進行特定任務的訓練。核心在於利用 CLIP 中藴含的視覺語言先驗，通過精心設計的提示策略來提升評估性能。同時提出了一種反義詞提示配對策略（如&quot;好照片&quot;和&quot;壞照片&quot;成對使用），以減少語言模糊性並增強模型在視覺感知評估中的表現。此外，為了克服 CLIP 對固定尺寸輸入的要求及其可能引入的額外失真問題，增加了移除位置嵌入的方法，進一步提升了模型與人類感知的一致性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8007ee47452b3e892f575ba205380fdd.jpeg&quot; alt=&quot;人類感知的一致性.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Q-Align[6]：目前 NR-IQA 領域的 SOTA 模型，將大模型引入到視覺打分任務中。通過文本定義的級別（例如好、差等）而不是直接的分數（例如 3.45、1.77）來指導訓練 LLMs。標誌着在視覺評分領域的一個重要進展，通過創新地使用離散文本定義級別來訓練 LMMs，不僅提高了評分的準確性和魯棒性，還為未來的研究開闢了新的方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0c11b8b2d8e879a97035e57dfc5f9d58.jpeg&quot; alt=&quot;未來研究方向.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;技術卡點&lt;/h2&gt; 
&lt;p&gt;端側模型存在體積限制，考慮到帶寬成本、推理速度等，將模型體積控制在 30M 以內。&lt;/p&gt; 
&lt;p&gt;目前圖片質量打分 sota 模型，整體都是從打分效果出發，不考慮模型性能 (size/推理耗時/cpu 性能/MAC 等），最小的模型體積也超過 120M，不滿足端上移植的要求。&lt;/p&gt; 
&lt;p&gt;現有的 Faster-VQA 和 LAR-IQA 雖然模型打分效果都不錯，但是同樣因為尺寸超額無法直接使用，也無法直接移植。&lt;/p&gt; 
&lt;h2&gt;算法方案&lt;/h2&gt; 
&lt;p&gt;輕量化網絡：本次算法模型主要在手機本地部署，受限於帶寬和計算資源限制，對模型尺寸有嚴格要求。綜合考慮後採用業界比較成熟的輕量化模型 MobileNetV3 結構作為基礎框架模塊，從 0 到 1 重新訓練輕量化圖片打分模型。&lt;/p&gt; 
&lt;p&gt;數據清洗與數據集構建：考慮到圖片-質量分數據的缺失，使用開源圖片評價大模型對數據預標註（必要時進行人工介入清洗），通過多模型交叉打分驗證和人工標註，最終總體訓練數據量級超過 10w+。整體流程如圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//368cf547e6c18996fef64c0a32f079fb.jpeg&quot; alt=&quot;輕量化圖片質量模型.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;輕量化圖片質量評價模型&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;loss 優化：loss 設計上採用迴歸任務 loss+主觀感知偏差衡量 loss，超參數控制多 loss 融合。&lt;/p&gt; 
&lt;h2&gt;模型移植&lt;/h2&gt; 
&lt;p&gt;MNN 模型支持 Tensorflow、Caffe、ONNX、Torchscripts 等主流模型文件格式，支持 CNN / RNN / GAN / Transformer 等主流網絡結構。&lt;/p&gt; 
&lt;p&gt;MobileNetV3 使用 PyTorch 框架創建、訓練、持久化模型，需要先轉換成為 ONNX 格式，然後再轉換成 MNN 模型。通過 FP16/Int8 壓縮與量化，模型最終大小為 24M，客户端可以接受。&lt;/p&gt; 
&lt;p&gt;在客户端進行模型推理調用時，需關注輸入圖片的尺寸、預處理方式以及輸出數據格式等方面。這些參數與模型相互綁定，且在後續的迭代過程中應保持同步。&lt;/p&gt; 
&lt;h1&gt;三、客户端部署&lt;/h1&gt; 
&lt;h2&gt;整體流程&lt;/h2&gt; 
&lt;p&gt;整體流程如圖所示，用户進入封面選擇頁，首先對視頻抽幀，然後調用端智能推理。端智能輸出一個評分，獲取評分最高的圖片作為推薦的封面。為了提高封面識別速度，採用批量異步計算。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1598600ee2eb1723baa183512b197daf.jpeg&quot; alt=&quot;時序圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;時序圖&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;整體架構如圖所示，雙端共用端智能基建，各自實現具體的業務邏輯。ClientIntelligence 作為端智能基建，底層封裝了 MNN、OpenCV 等，實現了模型管理（下載、緩存等）、推理、監控等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//195e00ede76e2528097744efb6e02f28.jpeg&quot; alt=&quot;架構圖.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;架構圖&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;推理一致性&lt;/h2&gt; 
&lt;p&gt;推理一致性（Inference Consistency）是指在不同時間、不同環境、或不同條件下，模型輸出的結果保持穩定、可靠、一致的能力。這是一個非常重要的概念，尤其是在部署機器學習模型時，確保模型的推理一致性對於維護模型的質量和可信度至關重要。&lt;/p&gt; 
&lt;p&gt;推理不一致的來源：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在不同硬件平台上運行模型（例如不同的 CPU、GPU、TPU 等）可能會導致數值精度上的細微差異，進而影響推理結果。&lt;/li&gt; 
 &lt;li&gt;不同的深度學習框架（例如 TensorFlow、PyTorch ）可能會在推理過程中產生不一致的結果，尤其是涉及到數值計算時。&lt;/li&gt; 
 &lt;li&gt;輸入數據預處理方式不一致導致推理結果不同，可以通過數據標準化、歸一化等減少對推理結果的影響。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;具體到智能封面的場景，主要面臨下面幾種一致性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PyTorch、ONNX、MNN 推理一致性：不一致主要來源框架本身，端上模型為了提高推理速度，會對模型進行量化，比如將浮動精度的模型（如 Float32）轉換為低精度模型（如 INT8）。框架造成的推理結果不一致無法避免。&lt;/li&gt; 
 &lt;li&gt;iOS、Android 雙端推理一致性：輸入數據預處理方式是影響推理一致性的關鍵因素，在智能封面場景，圖片數據的預處理方式需要保持一致。雙端由於硬件的差異，推理結果也不同。此外，使用 CPU、GPU 推理結果也會存在細微的差別。智能封面會對圖片評分，選擇評分最高的圖片，因此硬件造成的差別在本場景下可以接受。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;耗時優化&lt;/h2&gt; 
&lt;p&gt;用户在封面選擇頁面停留時間有限，因此要儘可能地減小封面推薦耗時。&lt;/p&gt; 
&lt;p&gt;首先要定位到耗時操作，然後有針對性地優化。&lt;/p&gt; 
&lt;p&gt;在本場景中，耗時操作包含抽幀、推理，具體優化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;並行計算：多線程同時抽幀、推理，需要注意的是，並行數需要考慮 CPU 和內存的佔用。&lt;/li&gt; 
 &lt;li&gt;GPU 推理：端智能同時支持 CPU 和 GPU 推理，通過 GPU 推理可以顯著減小耗時。&lt;/li&gt; 
 &lt;li&gt;不同性能的手機處理速度差別較大，低性能手機會適當減小抽幀數量，以提高運行速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;優化後，可以在秒級完成抽幀、封面推薦全過程。&lt;/p&gt; 
&lt;h1&gt;四、收益與效果評估&lt;/h1&gt; 
&lt;h2&gt;線上效果對比&lt;/h2&gt; 
&lt;p&gt;線上智能封面、非智能封面抽樣結果如下，使用智能封面功能，整體畫風更優，更清晰。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//82367a57fdb65c7b8908973deac33e27.png&quot; alt=&quot;智能封面 1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7dfbe0e2e76381f1f945b1b73956358d.jpeg&quot; alt=&quot;智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2d0471bc0033478e0616e89ec20fb68a.jpeg&quot; alt=&quot;智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//174cd7645a7e72a6f73a4989029e9f1d.jpeg&quot; alt=&quot;非智能封面 1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5384ba37f15f0ee2978f27a121e61c5.jpeg&quot; alt=&quot;非智能封面.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ccd9fa2ea17edaa6440e68730605b7f6.jpeg&quot; alt=&quot;非智能封面 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;非智能封面&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;競品效果對比&lt;/h2&gt; 
&lt;p&gt;得物智能封面與主流短視頻平台對比結果如下，整體選幀效果和主流短視頻平台可比，部分場景效果較優。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0cae9d9e138b676d7fd4a3979746f488.jpeg&quot; alt=&quot;得物.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b2043070a1e91837f0d6fd2c80c8515b.jpeg&quot; alt=&quot;得物 2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//62202b56d7685513082540403a48ea69.jpeg&quot; alt=&quot;得物 3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//222452ec8431cde5c74d5e6365b1892c.jpeg&quot; alt=&quot;得物 4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;得物&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//46a22734dffa5e864f6a8d4696f5a28e.jpeg&quot; alt=&quot;短視頻平台 A.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a7a26ea4a17b409e818b4948af61994.jpeg&quot; alt=&quot;短視頻平台 A2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9baec0020ee399603d698795b12ee610.jpeg&quot; alt=&quot;短視頻平台 a3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1edaed634b79363bafa240fd9fa0523.jpeg&quot; alt=&quot;短視頻平台 a4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 A&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//70f897a252d8e3a0a26a3d1bfb4eb901.jpeg&quot; alt=&quot;短視頻平台 B.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fa75bf53d7f6ac8d789ce116090d816c.jpeg&quot; alt=&quot;短視頻平台 n2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//cb60a0103af7f00c610b3c5ca9bc47b2.jpeg&quot; alt=&quot;短視頻平台 b3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5878e0c6c80e361787b25122c05feda7.jpeg&quot; alt=&quot;短視頻平台 b4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;短視頻平台 B&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;人工 GSB 評測&lt;/h2&gt; 
&lt;p&gt;在智能封面功能上線後，我們隨機抽取了線上真實的視頻數據，並通過人工 GSB（Good Same Bad）評估方法，對智能選幀所得的圖片與默認首幀圖片進行了圖像質量的對比分析。&lt;/p&gt; 
&lt;p&gt;多組數據、多人次測評整體評估結果為：Good（好）361 票，Same（一樣）182 票，Bad（差）95 票。&lt;/p&gt; 
&lt;p&gt;相較於默認首幀圖片，智能選幀的 GSB 評分提升了 41.7%，表明選幀功能在圖像質量上有了顯著的改進。&lt;/p&gt; 
&lt;h2&gt;線上實驗收益&lt;/h2&gt; 
&lt;p&gt;在發佈側，採用智能封面點擊率、選擇率作為衡量指標，獲得了顯著的收益，其中智能封面點擊率 5.5%，非首幀封面選擇率相對提升 +25.61%。&lt;/p&gt; 
&lt;p&gt;在內容推薦側，採用推薦雙列流視頻點擊率作為衡量指標，pvctr 和 uvctr 都有明顯提升，與對照組相比，pvctr+13.12%、uvctr+18.05%。實驗結果也表明在推薦雙列場景下，更好得封面內容會帶來更好的消費。&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;本文通過端智能推薦視頻封面，幫助創作者降低發文成本，提高發文質量。&lt;/p&gt; 
&lt;p&gt;我們也希望將端智能用在更多的場景，提高用户體驗。&lt;/p&gt; 
&lt;h1&gt;六、參考資料&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2FMNN&quot; target=&quot;_blank&quot;&gt;https://github.com/alibaba/MNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Fast-vqa: Efficient end-to-end video quality assessment with fragment sampling.&quot; European conference on computer vision. Cham: Springer Nature Switzerland, 2022.&lt;/li&gt; 
 &lt;li&gt;Zhou, Hantao, et al. &quot;UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment.&quot; arXiv preprint arXiv:2406.01069 (2024).&lt;/li&gt; 
 &lt;li&gt;Avanaki, Nasim Jamshidi, et al. &quot;LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality Assessment Model.&quot; arXiv preprint arXiv:2408.17057 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Jianyi, Kelvin CK Chan, and Chen Change Loy. &quot;Exploring clip for assessing the look and feel of images.&quot; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 2. 2023.&lt;/li&gt; 
 &lt;li&gt;Wu, Haoning, et al. &quot;Q-align: Teaching lmms for visual scoring via discrete text-defined levels.&quot; arXiv preprint arXiv:2312.17090 (2023).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;文 / Devin&amp;amp;linghu&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17569727</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17569727</guid>
            <pubDate>Sat, 22 Feb 2025 03:39:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>微服務是不是一種錯誤的方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;先説想法&lt;/h2&gt; 
&lt;p&gt;這個標題並非一時興起，也並非譁眾取寵，而是我這段時間以來的思考。為什麼會出現這樣的想法？這還得從一個事實説起。&lt;/p&gt; 
&lt;p&gt;眾所周知，微服務並不能提升整個項目的吞吐量，它的作用僅僅只是把項目按照一定的規則拆分成各種模塊，然後每個模塊都可以交給不同小組去開發。他解決的僅僅是大項目的團隊協作問題。而真正能提升吞吐量的，除了程序本身的質量那就是負載均衡了，而且事實上微服務的架構中，每個服務都是以負載均衡的形式部署的，所以這裏就有一個問題了：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果僅僅是為瞭解決【大項目的團隊協作問題】那麼常規的模塊化設計是不是也能做到？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;現在由於 maven 的出現，再加上企業內部可以搭建私服，我們完全可以讓每一個服務都以 jar 包的形式來開發。舉個很簡單的一個例子，比如有一個用户服務，訂單服務，現在一般的做法是寫一個聚合服務去調用這兩個服務的接口，來實現業務邏輯的整合。&lt;/p&gt; 
&lt;p&gt;那如果把用户服務換成用户模塊 jar 包、訂單服務換成訂單模塊 jar 包，以 jar 包的形似傳到私服，然後同樣的寫一個聚合服務，聚合服務把這兩個 jar 包引入進來，是不是也能達到這樣的效果？&lt;/p&gt; 
&lt;p&gt;如果需要負載均衡，那我們把這個聚合服務部署多個就好了，完全不影響。我完全想不到跟微服務比起來有什麼壞處，如果有，歡迎大家指正。&lt;/p&gt; 
&lt;h2&gt;微服務有什麼缺點&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;耦合性太高，雖然開發和部署不會影響別的服務，但是你如果動了接口的出入參，那麼其他服務就得同步升級了，而且是調用了這個接口的服務都要升級，又或者你需要為此單拎一個接口出來，做版本區分。&lt;/li&gt; 
 &lt;li&gt;需要註冊中心，項目會多出一箇中間件，提升複雜度。&lt;/li&gt; 
 &lt;li&gt;會消耗內網帶寬，甚至是公網帶寬，因為服務之間的調用都是通過網絡完成的。&lt;/li&gt; 
 &lt;li&gt;會出現分佈式事務的問題，因為一個事務的操作可能會分佈在不同的服務上執行。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;如果用常規的模塊化方案&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;雖然耦合也高，但是如果你動了接口的出入參甚至是接口名，別的服務是不需要立刻升級的，除非你是在改 bug，但這是被業務逼着升級，因為不升級是有 bug 的，但他不會被技術逼得升級，因為模塊只是被打成了一個 jar 包引入了其他模塊裏，無論你怎麼變，已經部署在線上的別的模塊裏依然是用的你的老代碼。&lt;/li&gt; 
 &lt;li&gt;不需要註冊中心&lt;/li&gt; 
 &lt;li&gt;不會消耗多餘的帶寬資源&lt;/li&gt; 
 &lt;li&gt;不需要分佈式事務了&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;還是壓力問題&lt;/h2&gt; 
&lt;p&gt;一定會有人説，你把這麼多模塊都塞進一個服務裏，那這個服務得部署多少台機器啊。&lt;/p&gt; 
&lt;p&gt;説到這裏，就不得不從全局來看待問題了。我們可以看兩張圖（不好意思，有錯別字，但是已經截圖了就懶得改了，能看懂就行）&lt;/p&gt; 
&lt;p&gt;圖 1&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e81da85cd4f90adbd4212a31278d1923442.png&quot; alt=&quot;圖 1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d3e951984db8d820ea3766422f0dcf1a933.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根據上面的兩個圖，我們是不是可以這麼説，微服務在面對相同的流量時根本沒有節約服務器的數量？反而還多了？&lt;/p&gt; 
&lt;p&gt;假如左邊的聚合服務，他的業務量需要 10 台服務器才能支撐，右邊的需要 5 台才能支撐，那麼一共是 15 台。而微服務會導致 A 部署 15 台，B 也部署 15 台，再加上兩個聚合服務，一共需要 32 台以上。&lt;/p&gt; 
&lt;p&gt;當然了，這只是極端的情況，現實中可能 A 服務不需要處理這麼多業務，他可以少部署一點，又或者 B 服務可以少部署一點。但無論怎麼算，服務器都是多了。&lt;/p&gt; 
&lt;p&gt;如果採用 jar 包的形式，那麼只需要 15 台就夠了，10 台用來部署左邊的聚合服務，5 台用來部署右邊的聚合服務。&lt;/p&gt; 
&lt;h2&gt;説到底&lt;/h2&gt; 
&lt;p&gt;這其實就是以三方庫的思想在設計模塊化，如果有一個工具類叫用户管理，有一個工具類叫支付管理。當你需要開發登錄功能的時候，只需要引入一個 jar 包，然後調用裏面的某個方法就好了，當你需要開發支付功能的時候也一樣，你不需要去學習 dubbo，不需要去學習 springcloud，甚至不需要去關注註冊中心是否掛沒掛，註冊中心的 url 是多少，服務到底有沒有正常發佈，有沒有正常被發現。你會不會覺得這樣有什麼不妥呢？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;以上只是個人的一點淺薄見解，歡迎大家理性探討。&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/yuyenews/blog/17681156</link>
            <guid isPermaLink="false">https://my.oschina.net/yuyenews/blog/17681156</guid>
            <pubDate>Sat, 22 Feb 2025 03:34:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>