<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 30 Jul 2025 02:46:49 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Elasticsearch 9.1.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Elasticsearch 是一個基於 Lucene 庫的搜索引擎。它提供了一個分佈式、支持多租户的全文搜索引擎，具有 HTTP Web 接口和無模式 JSON 文檔。Elasticsearch 基於 Java 開發，並在 SSPL + Elastic License 雙重授權許可下作為開源軟件發佈。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Elasticsearch 9.1.0 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fdocs%2Frelease-notes%2Felasticsearch%23elasticsearch-9.1.0-release-notes" target="_blank"&gt;發佈&lt;/a&gt;，更新亮點包括：&lt;/p&gt; 
&lt;div style="margin-left:0; margin-right:0"&gt; 
 &lt;div style="margin-left:0; margin-right:0"&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt; 
   &lt;div style="margin-left:0; margin-right:0"&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;將&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;repository-s3&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;升級到 AWS SDK v2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在早期版本的 Elasticsearch 中，&lt;code&gt;repository-s3&lt;/code&gt;插件基於 AWS SDK v1。AWS 將在 Elasticsearch 9.1 生命週期結束前停止對此 SDK 的支持，因此已將此插件遷移到較新的 AWS SDK v2。這兩個 SDK 並不完全兼容，因此在升級任何生產工作負載之前，建議用户查閲重大變更文檔並徹底測試新版本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;添加將數據流上的提取失敗重定向到故障存儲的功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據流現在可以維護一個「failure store」，用於接收和保存由於可預防的配置錯誤而無法採集的文檔。數據流的故障存儲的運行方式類似於一組獨立的後備索引，它們擁有各自的映射和訪問模式，這使得 Elasticsearch 能夠接收原本會因未處理的採集管道異常或映射衝突而被拒絕的文檔。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用户可以在組件或索引模板內的新&lt;code&gt;data_stream_options&lt;/code&gt;字段中指定，在新數據流上啓用將攝取失敗重定向到失敗存儲的功能：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;PUT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_index_template/my-template&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"index_patterns":&lt;/span&gt;&lt;/span&gt; [&lt;span&gt;&lt;span style="color:#59cfaa"&gt;"logs-test-*"&lt;/span&gt;&lt;/span&gt;], &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"data_stream":&lt;/span&gt;&lt;/span&gt; {}, &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"template":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"data_stream_options":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"failure_store":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"enabled":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;strong&gt;&lt;span style="color:#f58eb7"&gt;true&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; } } } } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以使用新的數據流&lt;code&gt;_options&lt;/code&gt;端點配置現有數據流&amp;nbsp;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;PUT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_data_stream/logs-test-apache/_options&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"failure_store":&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"enabled":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;"true"&lt;/span&gt;&lt;/span&gt; } } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;啓用重定向後，如果集羣支持，任何與攝取相關的故障都會被捕獲到故障存儲中，包括故障發生的時間戳、遇到的錯誤詳情以及無法攝取的文檔。由於故障存儲是一種 Elasticsearch 索引，可以在數據流中搜索它收集到的故障。這些故障默認不顯示，因為它們存儲在與常規數據流數據不同的索引中。為了檢索故障，使用&lt;code&gt;_search&lt;/code&gt;API 以及一種新的索引模式語法——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;::&lt;/code&gt;&lt;span style="color:#343741"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;selector&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-test-apache::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此索引語法指示搜索操作以故障存儲中的索引為目標，而不是其後備索引。它可以以多種方式與其他索引模式混合使用，以將其故障存儲索引包含在搜索操作中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;logs-*,logs-*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;*::failures/_search&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;POST&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_query&lt;/span&gt;&lt;/span&gt; { &lt;span&gt;&lt;span style="color:#f5bc00"&gt;"query":&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;"FROM my_data_stream*::failures"&lt;/span&gt;&lt;/span&gt; } &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Mark Token Pruning for Sparse Vector as GA&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;sparse_vector 查詢的 token pruning&amp;nbsp;功能自 8.13 版本起作為技術預覽版上線。自 8.19.0 和 9.1.0 版本起，該功能已正式發佈。&lt;/p&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;升級到 lucene 10.2.2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 HNSW 圖形構建期間減少 NeighborArray 堆內存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;修復 IndexSortSortedNumericDocValuesRangeQuery 的整數排序&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果 DoubleValuesSource 需要分數，則 ValueSource.fromDoubleValuesSource(dvs).getSortField() 在使用時會拋出錯誤&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在技術預覽版中發佈 FORK&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;div style="margin-left:0; margin-right:0"&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;FROM&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;test&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;FORK&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;WHERE&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content:"fox"&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;(&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;WHERE&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content:"dog"&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;SORT&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_fork&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
     &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;FORK 命令添加一個名為&lt;code&gt;_fork&lt;/code&gt;的 discriminator column：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;div style="margin-left:0; margin-right:0"&gt; 
      &lt;div style="margin-left:0; margin-right:0"&gt; 
       &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code class="language-yaml"&gt;&lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;id&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;content&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;_fork&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|-----|-----------|-------|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#fc9188"&gt;3&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;brown&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fox&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fork1&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#fc9188"&gt;4&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;white&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;dog&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;fork2&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#59cfaa"&gt;|&lt;/span&gt;&lt;/span&gt; &lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
    &lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ES|QL 跨集羣查詢現已普遍可用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;p&gt;ES|QL 跨集羣查詢功能自 8.13 版本起處於技術預覽階段。自 8.19.0 和 9.1.0 版本起，該功能已正式發佈。此功能允許用户跨多個集羣運行 ES|QL 查詢。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;更多詳情可查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.elastic.co%2Fdocs%2Frelease-notes%2Felasticsearch%23elasticsearch-9.1.0-release-notes" target="_blank"&gt;https://www.elastic.co/docs/release-notes/elasticsearch#elasticsearch-9.1.0-release-notes&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363097/elasticsearch-9-1-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363097/elasticsearch-9-1-0-released</guid>
      <pubDate>Wed, 30 Jul 2025 02:41:48 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 上線全新「學習模式」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ChatGPT 正式上線了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fchatgpt-study-mode%2F"&gt;「學習模式」&lt;/a&gt;，通過交互式提問而非直接給答案的方式，引導用户深入學習和解決問題。&lt;/p&gt; 
&lt;p&gt;據介紹，學習模式（study mode）是一種新的學習體驗，旨在通過分步指導幫助用户解決問題，而不是直接提供答案。它最大的亮點在於引入了蘇格拉底式提問，通過一連串循序漸進的問題，引導你沿着邏輯脈絡一點點構建知識體系。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0734bb018ad7b0af7ef233b004905294ef5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 表示這項功能主要面向大學生羣體，尤其適用於作業輔導、考試準備和學習新知識。使用方式非常簡單，在 ChatGPT 的工具中選擇「研究與學習」，然後直接輸入想問的問題即可。&lt;/p&gt; 
&lt;p&gt;目前，學習模式由系統提示詞驅動，並未使用專門訓練的 AI 模型，這種機制的優勢在於迭代快、調整靈活。OpenAI 表示，未來將逐步把這一交互模式融合進核心模型中，讓教學邏輯成為底層能力的一部分。&lt;/p&gt; 
&lt;p&gt;體驗方面，免費版、Plus、Pro、Team 版用户均可使用這項功能，Edu 用户將在接下來的幾周內上線。&lt;/p&gt; 
&lt;p&gt;OpenAI 表示，這是改善 ChatGPT 學習體驗的第一步，未來計劃將這種行為直接訓練到核心模型中，並探索更清晰的可視化、目標設定和更深度的個性化等功能。同時，OpenAI 正通過 NextGenAI 計劃及與斯坦福大學 SCALE Initiative 的合作，進一步研究 AI 在教育中的應用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363093/chatgpt-study-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363093/chatgpt-study-mode</guid>
      <pubDate>Wed, 30 Jul 2025 02:30:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深圳先進院提出新型圖像復原大模型 HYPIR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;中國科學院深圳先進技術研究院數字所董超研究員團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1cqDxurR1QxB4HXNoKmLkg" target="_blank"&gt;發佈&lt;/a&gt;了一項名為 HYPIR 的圖像復原大模型，不僅比現有的圖像復原技術快數十倍，更在高清分辨率、文字保真、理解能力、用户控制靈活性等方面展現出了優異性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;董超團隊曾於去年提出了智能畫質增強大模型 SUPIR，將低質量的圖像恢復到接近原始狀態的高清圖像，有效修復多種退化類型的圖像。而此次圖像大模型 HYPIR 作為升級版，捨棄了迭代式的擴散模型訓練，改用單步的對抗生成模型訓練方式，將原有的算法速度提升了數倍，同時採用更新的文生圖基模型進一步提升算法效果，實現了 8K 級別的細節生成，在生成圖像的穩定性和可控性方面遠超 SUPIR 大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="353" src="https://oscimg.oschina.net/oscnet/up-f2529fde69524742505eeda933f93526e22.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「以往圖像復原方法中往往包括擴散模型蒸餾、ControlNet 適配器或者多步推理過程。而 HYPIR 則不需要依賴這些步驟，使用方法更加簡單。在訓練和推理速度上較傳統方法提升了一個數量級以上，且性能更優。」董超介紹，HYPIR 主要有兩個創新點，一是使用預訓練擴散模型初始化復原網絡；二是從理論角度出發解釋這一簡單方法背後藴含的深刻原理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;實驗數據顯示，在單張顯卡（圖像處理器）上，HYPIR 僅需 1.7 秒即可完成一張 1024x1024 分辨率圖像的復原。相比現有的圖像復原方法，研究人員提出的 HYPIR 在復原圖像的質量上性能更優，且能夠適用於各種尺寸的預訓練擴散模型，為不同應用場景提供了靈活性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-5ce496faabfb63ab3ab3085ef4ffef77130.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在應用層面，研究人員介紹，HYPIR 在圖像高清分辨率、文字保真、理解能力、用户控制靈活性等方面均展現出了優異的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如，在老照片修復方面，研究人員運用 HYPIR 修復了國內外經典電影、電視劇老照片，讓模糊的影像重現清晰的細節，為文化記憶傳承提供了技術支持。在高分辨率圖像修復領域，HYPIR 同樣表現出色，因其兼具速度與效果，HYPIR 成功攻克了傳統方法在生成 8k 分辨率圖像時往往面臨速度慢或效果不佳的難題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="379" src="https://oscimg.oschina.net/oscnet/up-67b91f31bbedb73b1544419c5b2214c6180.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在文字保真方面，傳統基於擴散模型的方法常導致復原出的文字模糊或扭曲，缺乏精確性，而 HYPIR 則能夠使復原出的文字保持高保真度和清晰度，無論是簡單的標識還是複雜的文檔，HYPIR 都能精準地還原其原始形態，使圖像中的文字清晰可讀。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，HYPIR 還具備了突出的自然語言理解能力，能夠精準捕捉和理解用户的輸入指令，在圖像復原過程中準確地反映用户的意圖。此外，用户可以根據需求靈活調節生成與復原的平衡，或精細控制圖像細節程度，從而獲得符合自身偏好的結果。這種用户友好的設計使得 HYPIR 不僅適用於專業領域，也能滿足普通用户的需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="315" src="https://oscimg.oschina.net/oscnet/up-8a5dec52e332077222c82eb21fe0166e4c8.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363092</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363092</guid>
      <pubDate>Wed, 30 Jul 2025 02:26:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維開源多模態統一預訓練模型 Skywork UniPic</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維宣佈正式推出並開源採用自迴歸路線的「多模態統一預訓練模型&amp;nbsp;&lt;strong&gt;Skywork UniPic&lt;/strong&gt;」，在單一模型中深度融合圖像理解、文本到圖像生成、圖像編輯三大核心能力。該模型基於大規模高質量數據進行端到端預訓練，具備良好的通用性與可遷移性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="239" src="https://oscimg.oschina.net/oscnet/up-9bb339f656b62f41563018515770ad49264.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork-UniPic 模型核心能力包含：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖文理解：&lt;/strong&gt;基於 token 預測完成文本的自迴歸建模&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像生成&lt;/strong&gt;：採用掩碼自迴歸方式，逐步生成圖像 patch&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像編輯：&lt;/strong&gt;引入參考圖與編輯指令作為條件，生成編輯後的圖像&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;此外，Skywork-UniPic 完成端到端優化流程，能夠實現生成、理解、編輯三大能力的協同訓練和相互促進，突破傳統方法中能力權衡的技術瓶頸。這一架構設計不僅保持了自迴歸模型的簡潔高效，更通過共享編碼器實現了跨任務的深度協同，為多模態統一模型的實用化部署奠定了堅實基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;用户只需要輸入提示詞，Skywork-UniPic 既可以像 VLM 一樣理解圖像、像 T2I 模型一樣生成圖片，還可以像美圖工具一樣，一鍵實現風格轉繪/吉卜力化的編輯功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="299" src="https://oscimg.oschina.net/oscnet/up-12b968fc4978131cb565b8847b729558f47.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork UniPic 技術亮點：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;指令遵循能力媲美大型模型：&lt;/strong&gt;&lt;/strong&gt;在 GenEval 指令遵循評估中取得 0.86 的優異成績，超越了絕大多數同類統一模型，在無 CoT 的情況下取得了 SOTA 分數，逼近較大模型 BAGEL（7B+7B*）帶 CoT 的 0.88 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;複雜指令生圖能力領先：&lt;/strong&gt;在 DPG-Bench 複雜指令生圖基準上達到 85.5 分的行業 SOTA 水平；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;圖像編輯能力統一模型第一梯隊：&lt;/strong&gt;GEditBench-EN 獲得 5.83 分，ImgEdit-Bench 達到 3.49 分，展現出精準的編輯執行能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;參數效率優勢顯著：&lt;/strong&gt;相比同類大參數統一模型（如 BAGEL 的 14B 總參數、UniWorld-V1 的 19B 總參數），Skywork UniPic 以 1.5B 的輕量級規模實現了接近甚至超越大參數模型的性能表現；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;部署友好，真正可落地：&lt;/strong&gt;模型在 RTX 4090 消費級顯卡上均可流暢運行，為廣大開發者和研究者提供了真正可落地的統一模型解決方案，大幅降低了技術應用門檻。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="220" src="https://oscimg.oschina.net/oscnet/up-200975b864b698a0f7821912288be54d815.png" width="500" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPX-pKw0N341590wm7GpdYw" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363085</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363085</guid>
      <pubDate>Wed, 30 Jul 2025 01:59:41 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：像 VisionPro 那樣酷，全球首個遠距離動態手勢交互技術！</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2117</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2117</guid>
      <pubDate>Wed, 30 Jul 2025 01:55:41 GMT</pubDate>
    </item>
    <item>
      <title>馬斯克宣佈 Grok 推出新 UI，引入「Auto 模式」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;馬斯克&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1948992239071326244" target="_blank"&gt;宣佈&lt;/a&gt;，Grok&amp;nbsp;已推出新的用户界面。該更新目前已在網頁端上線，並將很快推廣至移動端 APP。&lt;/p&gt; 
&lt;p&gt;新界面增加了一個新的模型選擇器功能。該功能引入了 Auto 模式，允許應用自動選擇合適的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1613" src="https://static.oschina.net/uploads/space/2025/0729/192206_0PZn_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前已經用户體驗到了新版的移動端 APP，並表示有「兩個版本」：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-87130b778bb6fac752a16c5287206709ff7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b88733bc4bda21493906af15dda98f02539.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363022</guid>
      <pubDate>Wed, 16 Jul 2025 11:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源項目 Kapitano 作者無端遭遇人身攻擊，心灰意冷之下宣佈停止維護</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，Linux 開源社區發生了一起令人遺憾的事件，開發者 zynequ 宣佈，由於遭遇無端的人身攻擊，他決定停止維護其開源項目 Kapitano。&lt;/p&gt; 
&lt;p&gt;Kapitano 是一個為命令行殺毒工具 ClamAV 提供圖形界面的應用程序，可幫助 Linux 用户更方便地使用 ClamAV 進行病毒掃描。&lt;/p&gt; 
&lt;p&gt;起因是一位用户在 Kapitano 的 Codeberg 頁面上創建了一個問題，聲稱該軟件在其 Linux Mint 系統上產生了誤報，檢測到 24 個與 Windows 漏洞和木馬相關的陽性結果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-da7edb2fb2aa6ca9655d630c2e2b8a6933a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該用户聲稱所有被標記的文件都與 Kapitano Flatpak 本身有關，並且以一種較為激進的方式警告其他用户不要下載該程序。&lt;/p&gt; 
&lt;p&gt;該用户甚至表示：「程序沒有任何評論，應該保持這種狀態，直到源代碼被獨立來源驗證。」&lt;/p&gt; 
&lt;p&gt;zynequ 在回應中冷靜地指出，問題並不是他的應用程序，Kapitano 並不參與具體的病毒判斷邏輯。&lt;/p&gt; 
&lt;p&gt;他還提供了相關代碼的鏈接，證明 Kapitano 只是調用了 ClamAV 的 clamscan 和 freshclam 命令。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ada62c2d3c6bf63d9f8dd27f293bb5a7110.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;然而事情並沒有就此結束，用户隨後創建了重複的問題，並聲稱 zynequ 是惡意行為者，要求將他這個「惡意軟件傳播者」封鎖。&lt;/p&gt; 
&lt;p&gt;經過激烈的爭論後，用户表示：「你的項目已經從我的筆記本硬盤中刪除了。讓它安息吧。再見。」&lt;/p&gt; 
&lt;p&gt;最終 zynequ 發佈終止維護聲明，他指出，Kapitano 是一個純粹的愛好項目，沒有得到任何經濟支持，而這種無端的人身攻擊讓他很難保持開發的動力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-011febf1266dc370c06a3c74915c45686a5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;zynequ 宣佈，Kapitano 的代碼現在已發佈到公共領域，採用無許可證（The Unlicense），這意味着任何人都可以分叉並隨意使用它。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363019</guid>
      <pubDate>Wed, 16 Jul 2025 11:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>新研究提出 AI 自主架構發現系統 ASI-Arch</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海創智學院領銜的團隊發佈了 AI&amp;nbsp;超智能系統：ASI-Arch，其成功設計徹底顛覆了這一認知。該系統基於先進的大模型技術，構建了高度自主的多智能體研究框架，能夠完全獨立地進行從問題識別、假設生成、實驗設計到結果驗證的完整科學研究流程。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/184132_dCXe_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文標題: AlphaGo Moment for Model Architecture Discovery&lt;/li&gt; 
 &lt;li&gt;系統開源: https://github.com/GAIR-NLP/&lt;/li&gt; 
 &lt;li&gt;ASI-Arch 網站地址: https://gair-nlp.github.io/ASI-Arch/&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據介紹，在長達數月的自主研究過程中，ASI-Arch 系統展現出了令人震撼的研究能力。系統共進行了 1,773 次獨立實驗，累計消耗超過 20,000 GPU 小時的計算資源，在無人幹預的情況下，ASI-ARCH 自主發現了 106 個新穎且性能卓越的線性注意力架構，這些架構在多個基準測試中超越瞭如 Mamba2 和 Gated DeltaNet 等強大的基線模型。&lt;/p&gt; 
&lt;p&gt;這一研究規模和效率遠超傳統人類研究團隊的能力範圍。&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0729/184123_2g16_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖：AI 自主進行了 1,773 次科研探索&lt;/p&gt; 
&lt;p&gt;ASI-ARCH 系統成功發現了 106 個全新的線性注意力機制架構，每一個在性能指標上都顯著超越了現有的人類設計方案。這些發現的重要性不僅在於性能提升，更在於設計理念的創新。系統提出的許多架構設計原理和優化策略，即使是該領域的頂級專家也承認此前從未考慮過。這表明 AI 系統已經具備了超越人類認知邊界的創新能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363014</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363014</guid>
      <pubDate>Wed, 16 Jul 2025 10:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 AI 編程工具 Gemini CLI 定為每週三發佈更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;為提高更新流程的有序性，Gemini CLI 的發佈週期將調整為每週三定期更新。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1404" src="https://static.oschina.net/uploads/space/2025/0729/182925_0lMy_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini CLI 維護團隊成員宣佈將對其 Gemini CLI 的更新發布計劃進行調整。從現在開始，Gemini CLI 的更新將在每週三定期發佈，以使更新流程更有序、更有計劃性。&lt;/p&gt; 
&lt;p&gt;Gemini CLI 是谷歌開源的免費 AI 編程工具，該工具將 Gemini 的能力帶到了開發者最常用的終端，能夠提供輕量化的 Gemini 訪問通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363011</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363011</guid>
      <pubDate>Wed, 16 Jul 2025 10:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 首席科學家楊立昆回應另一位首席科學家的加入</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 近日宣佈清華校友趙晟佳（Shengjia Zhao）將&lt;a href="https://www.oschina.net/news/362754"&gt;正式&lt;/a&gt;擔任其超級智能實驗室（ MSL）首席科學家。&lt;/p&gt; 
&lt;p&gt;而 Meta 中的另一個 AI 團隊部門——FAIR 團隊，雖然在 Meta 的整體戰略中逐漸邊緣化，但 65 歲的圖靈獎得主 Yann LeCun（楊立昆）的職位未發生變化。扎克伯格也特別強調，&lt;strong&gt;楊立昆將繼續擔任 FAIR 的首席科學家&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-10f48ab6c9358abcb6969b367b7a7b9619d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;與 MSL 不同，FAIR 專注於長期 AI 研究——即可能在五到十年後使用的技術。而對於扎克伯格的任命宣佈，Yann Lecun 也回應表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我作為 FAIR 首席科學家的角色一直專注於長期的人工智能研究和構建下一代人工智能範式。我期待與趙晟佳合作，加速將新研究成果整合到我們最先進的模型中。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363007</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363007</guid>
      <pubDate>Wed, 16 Jul 2025 10:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 招聘硬件系統產品設計師，打造「下一代全球最具創新移動設備」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正在招聘多個消費硬件相關職位，引發外界對其佈局新品的猜測。其中，硬件系統產品設計師崗位旨在打造「下一代全球最具創新的移動設備」。&lt;/p&gt; 
&lt;p&gt;在硬件系統產品設計師的&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fjobs%2Fview%2Fhardware-systems-product-designer-at-openai-4263584294%2F" target="_blank"&gt;職位描述中&lt;/a&gt;&lt;/u&gt;，OpenAI 表示該職位要求應聘者具備強大的機械設計技能，以及製造性設計（DFM）、裝配性設計（DFA）、公差與尺寸設計等領域的專業知識。此外，還需要具備組件模塊的經驗，包括 OLED / LCD 顯示屏、電池、聲學、攝像頭模塊，以及蜂窩和 GPS 系統等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1650" src="https://static.oschina.net/uploads/space/2025/0729/180234_vwbc_2720166.png" width="1410" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，OpenAI 也在招募電氣工程師，以「設計和優化高性能硬件產品的下一代充電技術」，涉及電路設計與充電技術優化，可能為未來設備構建無線充電平台。有用户推測，該設備或類似智能手錶或 Humane AI 別針，具備攝像頭、屏幕和麥克風等功能。&lt;/p&gt; 
&lt;p&gt;一位用户在 X 社交平台上&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fliminalsunset_%2Fstatus%2F1949642969914778016" target="_blank"&gt;猜測&lt;/a&gt;&lt;/u&gt;：「這看起來像是他們正在為 io 設備招聘，可能包含攝像頭、小屏幕和麥克風。」這位用户推測這可能是智能手錶或類似 Humane AI 別針的設備。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363005/hardware-systems-product-designer-at-openai</guid>
      <pubDate>Wed, 16 Jul 2025 09:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全新高效模型架構！RWKV-7s 閃耀 WAIC</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 26-29 日，&lt;strong&gt;RWKV 團隊受邀參加 2025 世界人工智能大會（WAIC 2025）&lt;/strong&gt;, 並在大會公開了 RWKV 最新的高效大模型架構：RWKV-7s，吸引了來自產業界、學術界及媒體的廣泛關注與討論。&lt;/p&gt; 
&lt;h2&gt;戰略合作，廣泛落地&lt;/h2&gt; 
&lt;p&gt;7 月 26 日，&lt;strong&gt;移遠通信宣佈與 RWKV 公司建立全面合作關係&lt;/strong&gt;，雙方將依託移遠的算力平台，優化並支持 RWKV 最新模型架構，共同推動大模型在端側設備的低資源佔用部署。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV x 移遠通信" src="https://oscimg.oschina.net/oscnet/up-ec04d5001a459b4a33964c1c2478645def2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUk6xlo-MQ09vS9JFwf35NA" target="_blank"&gt;端側大模型迎來「輕」革命！移遠通信 × RWKV 打造「輕量 AI 大腦」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;憑藉 RWKV 架構「資源佔用和推理速度恆定」的特性，RWKV 系列模型在端側部署具有天然優勢。&lt;strong&gt;現在，RWKV 已與多家芯片廠商、具身智能廠商合作將 RWKV 模型部署在芯片及機器人上&lt;/strong&gt;，如：高通、聯發科、Intel、AMD、英偉達、地平線機器人、有鹿機器人等等。&lt;/p&gt; 
&lt;h2&gt;全新技術，全面領先&lt;/h2&gt; 
&lt;p&gt;WAIC 大會首日，承接 RWKV-7 優勢的 RWKV-7s 新型高效大模型架構正式發佈。憑藉其原創的 DeepEmbed 和 DeepEmbedAttention 技術，成為現場焦點並 &lt;strong&gt;榮獲 WAIC「鎮館之寶-未來之星」稱號&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="WAIC-Award" src="https://oscimg.oschina.net/oscnet/up-e03b0a22f02ad601b832cf7790bf0bd78e8.jpg" referrerpolicy="no-referrer"&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhH7y37AcYP4GWOIjhNHz7g" target="_blank"&gt;鎮館之寶｜WAIC 2025 鎮館之寶及系列獎項名單公佈&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 是 RNN+DeepEmbedAttention 混合架構，兼具高效計算與強長文本性能，其設計創新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;原創 DeepEmbed 技術，大稀疏模型只需小顯存，比 MoE 顯著更適合端側！&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;原創 DeepEmbedAttention (DEA) 技術，長文本性能看齊 Attention，而 KV cache 僅為 MLA 的 1/9，更快更省！&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="DeepEmbed" src="https://oscimg.oschina.net/oscnet/up-78a8be5b2720c3b1b8ac934f907d2e6d5cf.png" referrerpolicy="no-referrer"&gt; &lt;img alt="DeepEmbedAttention" src="https://oscimg.oschina.net/oscnet/up-8c057eabf3fdcda0299f303d25e8433b8a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV-7s 架構支持適配大語言模型、多模態、智能體等多種應用場景，憑藉廣泛的適配性吸引了現場各領域有智能化發展需求的企業關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eb5cd7552cfc42ce0e5ca61d787880e5ceb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;多場深度分享&lt;/h2&gt; 
&lt;p&gt;大會期間，&lt;strong&gt;RWKV 聯合創始人 &amp;amp; COO 羅璇及 RWKV-PEFT 與 WorldRWKV 作者康嘉樂受邀參與多場技術論壇與專題活動&lt;/strong&gt;，圍繞 RWKV-7s 混合架構、AGI 演進路徑及端側部署趨勢等話題展開深度分享。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="mohe" src="https://oscimg.oschina.net/oscnet/up-9bcdda5f376377dfa999b9685d793452f65.png" referrerpolicy="no-referrer"&gt; &lt;img alt="open_talk" src="https://oscimg.oschina.net/oscnet/up-3a8aebd93474fb31316773da624d59feaa3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;端側 Demo&lt;/h2&gt; 
&lt;p&gt;展會現場，&lt;strong&gt;RWKV 展台同步展出了五款 RWKV 自研的端側離線應用&lt;/strong&gt;。憑藉對多模態場景的廣泛覆蓋，收穫了現場觀眾的熱烈反響。&lt;/p&gt; 
&lt;p&gt;其中，&lt;strong&gt;RWKV 作曲家&lt;/strong&gt;升級全新輸入方式。除原有的虛擬鍵盤和藍牙 MIDI 鍵盤輸入以外，&lt;strong&gt;新增哼唱識別樂譜輸入功能，大幅降低使用門檻，便捷不同用户使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 作曲家" src="https://oscimg.oschina.net/oscnet/up-7d3a18337b7b4cc8bab88df444b0e5fafd3.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Chat 內置 RWKV7-G1 推理模型，&lt;strong&gt;無需聯網即可實現推理、深度對話與文本續寫。其中的 RWKV7-G1 2.9B 模型在高通手機平台的速度可達 30 token/s&lt;/strong&gt;，且由於 RWKV 架構無需 KV cache，在超長推理後仍然可以速度恆定，內存佔用恆定。&lt;/p&gt; 
&lt;p&gt;本次展示，RWKV Chat 全面優化 UI 界面，&lt;strong&gt;新增 Agent 陪聊與文本續寫功能，開發團隊還同步推出新手、高級、專家三種應用模式&lt;/strong&gt;，以滿足不同技術背景用户的需求為核心，為用户帶來更個性化的體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Chat" src="https://oscimg.oschina.net/oscnet/up-4953f6c241e03a59b465a5b2bfbda1ba2af.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，RWKV 展位還演示了端側離線部署的圖像多模態應用 &lt;strong&gt;RWKV See&lt;/strong&gt;；超長 CoT 解決複雜數獨的 &lt;strong&gt;RWKV 數獨&lt;/strong&gt;；以及語音多模態應用 &lt;strong&gt;RWKV Talk&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV 數獨" src="https://oscimg.oschina.net/oscnet/up-7403589cfd4c77f004366bd59184897e350.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV See" src="https://oscimg.oschina.net/oscnet/up-7164d710aae30a7840955bd661f1b2001d2.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RWKV Talk" src="https://oscimg.oschina.net/oscnet/up-99d0220761f728cfb0db51908d13a2fd81a.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV— 面向未來的高效 AI 大模型架構&lt;/h2&gt; 
&lt;p&gt;感謝每一位在 WAIC 2025 與 RWKV 相遇的朋友。未來，RWKV 期待深度參與社區技術交流與資源整合，攜手夥伴共同推動普惠開放的 AI 未來。目前，下一代核心架構 RWKV-8 的研發已在加速籌備中，預計於今年內發佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8409a5f7ed66ea3012c851458bdf076b2de.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多 RWKV 技術動態、產品進展及社區合作信息，敬請持續關注 RWKV 官方公眾號。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363004</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363004</guid>
      <pubDate>Wed, 16 Jul 2025 09:53:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>​Mistral AI 發佈人工智能模型環境影響分析</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral AI 對其一款大型語言模型進行了全面的生命週期分析，旨在評估人工智能技術的環境影響。這項研究由 Mistral 與可持續發展諮詢公司 Carbone4 及法國生態轉型機構共同開展，分析結果還經過了環境諮詢公司 Resilio 和 Hubblo 的同行評審。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#000000"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-9d2866802c4667241df914db00df7739dfa.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;該分析主要聚焦於 Mistral AI Large2 模型的整個生命週期，評估了其在温室氣體排放、水資源使用和材料消耗等三個關鍵領域的影響。研究發現，人工智能模型的訓練和推理階段是環境影響最大的環節，Mistral 表示，該模型 85.5% 的温室氣體排放和 91% 的水消耗都發生在模型的開發和用户交互過程中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;截至 2025 年 1 月，Mistral 的 Large2 模型在運行 18 個月後已產生 20.4 千噸的二氧化碳排放量，並消耗了 28.1 萬立方米的水資源。研究還估算了推理的邊際影響，通過用户與 「Le Chat」 聊天機器人進行 400 個令牌的交互，預計每次交互會產生約 1.14 克的二氧化碳排放和 45 毫升的水消耗。這些數據表明，單次查詢的環境影響雖然微小，但在數百萬乃至數十億用户長期交互下，整體的環境挑戰是不可忽視的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Mistral 也承認其研究存在一些侷限性，特別是在準確量化大型語言模型工作負載對 GPU 和數據中心基礎設施造成的硬件性能下降方面。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管如此，該報告中的數據與其他機構對人工智能環境影響的評估基本一致。Mistral 表示，未來將更新環境報告，呼籲整個人工智能行業提升透明度，致力於實現全球氣候目標。公司指出，目前的一些政策與這些目標存在背道而馳的現象。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362993</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362993</guid>
      <pubDate>Wed, 16 Jul 2025 09:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>opencode —— 為終端打造的 AI 編碼代理</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;a href="https://opencode.ai/"&gt;opencode&lt;/a&gt;&amp;nbsp;是為終端打造的 AI 編碼代理。&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;&lt;strong&gt;原生 TUI&lt;/strong&gt;：響應迅速、原生、可主題化的終端 UI。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LSP 已啓用&lt;/strong&gt;：自動為 LLM 加載正確的 LSP。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多會話&lt;/strong&gt;：在同一個項目上並行啓動多個代理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可共享鏈接&lt;/strong&gt;：共享任何會話的鏈接以供參考或調試。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Claude Pro&lt;/strong&gt;：通過 Anthropic 登錄以使用你的 Claude Pro 或 Max 帳户。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用任何模型：通過&lt;/strong&gt;&lt;a href="https://models.dev/"&gt;Models.dev&lt;/a&gt;支持 75 多個 LLM 提供商，包括本地模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="366" src="https://static.oschina.net/uploads/space/2025/0725/145221_a1Fv_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/opencode</link>
      <guid isPermaLink="false">https://www.oschina.net/p/opencode</guid>
      <pubDate>Wed, 16 Jul 2025 08:59:00 GMT</pubDate>
    </item>
    <item>
      <title>🔥 Solon v3.4.2（Java 應用開發生態基座）</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;Solon 框架！&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Solon 是新一代，Java 企業級應用開發框架。&lt;strong&gt;從零開始構建（No Java-EE），有靈活的接口規範與開放生態&lt;/strong&gt;。採用商用友好的 Apache 2.0 開源協議，是「杭州無耳科技有限公司」開源的根級項目，是 Java 應用開發的生態基座（可替換美國博通公司的 Spring 生態）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;追求： 快速、小巧、簡潔&lt;/li&gt; 
 &lt;li&gt;提倡： 剋制、高效、開放&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;7 年開源時間，累計代碼提交 1.6 萬次 ，近半年下載量 1200 萬次。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;有透明可預期的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2F687" target="_blank"&gt;《版本發佈與維護計劃》&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;有「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2Fsupport" target="_blank"&gt;【社區交流】&lt;/a&gt;」和「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2Fbiz" target="_blank"&gt;【商業服務】&lt;/a&gt;」雙重技術支持&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;同時支持運行時環境（不基於 java-ee 構建，所以可以同時兼容）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;java8, java11, java17, java21, java24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;有什麼特點（相對 Java Spring 方案）？&lt;/h2&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;特點&lt;/th&gt; 
   &lt;th&gt;描述&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;更高的計算性價比&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;併發高 700%；內存省 50%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;更快的開發效率&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;代碼少；入門簡單；啓動快 10 倍（調試快）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;更好的生產與部署體驗&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;打包小 90%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;更大的兼容範圍&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;非 java-ee 架構；同時支持 java8 ～ java24，graalvm native image&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;最新的 techempower 測試數據：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techempower.com%2Fbenchmarks%2F%23hw%3Dph%26test%3Djson%25C2%25A7ion%3Ddata-r23" target="_blank"&gt;https://www.techempower.com/benchmarks/#hw=ph&amp;amp;test=json§ion=data-r23&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techempower.com%2Fbenchmarks%2F%23hw%3Dph%26test%3Dplaintext%25C2%25A7ion%3Ddata-r23" target="_blank"&gt;https://www.techempower.com/benchmarks/#hw=ph&amp;amp;test=plaintext§ion=data-r23&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;項目架構示意圖（全場景應用開發支持）&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;&lt;img src="https://oscimg.oschina.net/oscnet//73de36c1fce60913602ccf9d949674e2.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;最近更新了什麼？（每個版本都會有滿滿的清單）&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增 solon-ai-repo-pgvector 插件&lt;/li&gt; 
 &lt;li&gt;新增 solon-ai-search-baidu 插件&lt;/li&gt; 
 &lt;li&gt;新增 solon&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@Managed&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;註解（未來替代&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@Component&lt;/code&gt;）&lt;/li&gt; 
 &lt;li&gt;新增 solon ActionArgumentResolver 接口&lt;/li&gt; 
 &lt;li&gt;添加 solon-net-httputils ssl 定製支持&lt;/li&gt; 
 &lt;li&gt;添加 solon-flow FlowContext:incrGet, incrAdd&lt;/li&gt; 
 &lt;li&gt;添加 solon-flow aot 配置&lt;/li&gt; 
 &lt;li&gt;添加 solon-ai-core&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;TextLoader(byte[])(SupplierEx&amp;lt;InputStream&amp;gt;)&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;構造方法&lt;/li&gt; 
 &lt;li&gt;添加 solon-ai-core&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ChatConfig:defaultToolsContext&lt;/code&gt;（默認工具上下文）,&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;defaultOptions&lt;/code&gt;（默認選項） 屬性&lt;/li&gt; 
 &lt;li&gt;添加 solon-ai-core&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;RepositoryStorable:insert(list,progressCallback)&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;asyncInsert(list,progressCallback)&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，支持進度獲取&lt;/li&gt; 
 &lt;li&gt;添加 solon-ai-mcp 客户端 ssl 定製支持&lt;/li&gt; 
 &lt;li&gt;添加 aliyun-oss-solon-cloud-plugin 阿里雲 oss 獲取臨時文件 url 邏輯&lt;/li&gt; 
 &lt;li&gt;優化 solon-boot server 啓動時機（轉到 postStart 時）&lt;/li&gt; 
 &lt;li&gt;優化 solon-net-httputils 流接收的編碼處理&lt;/li&gt; 
 &lt;li&gt;優化 solon-net-http HttpSslSupplier 接口定義（以適與 okhttp 的接口變化）&lt;/li&gt; 
 &lt;li&gt;優化 solon-docs-openapi2 body 動態模型的 key 添加 method（避免衝突）&lt;/li&gt; 
 &lt;li&gt;優化 solon-flow Chain:parseByDom 節點解析後的添加順序&lt;/li&gt; 
 &lt;li&gt;優化 solon-flow Chain 解析統改為 Yaml 處理，並添加 toYaml 方法&lt;/li&gt; 
 &lt;li&gt;優化 solon-flow Chain:toJson 輸出（壓縮大小，去掉空輸出）&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai 方言 think 思考內容和字段的兼容性處理&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai 方言處理與 modelscope（魔搭社區）的兼容性&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai 方言處理與 siliconflow（硅基流動）的兼容性&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai 方言處理的流式節點識別兼容性&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai 用户消息的請求構建（當內容為空時，不添加 text）&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai-mcp McpClientProvider 心跳間隔控制（5s 以下忽略）&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai-mcp McpServerContext 增加 stdio 代理支持（環境變量自動轉為 ctx:header）&lt;/li&gt; 
 &lt;li&gt;優化 solon-ai-mcp WebRxSseClientTransport 添加 debug 日誌打印&lt;/li&gt; 
 &lt;li&gt;優化 local-solon-cloud-plugin 在啓動時，預熱 RunUtil&lt;/li&gt; 
 &lt;li&gt;修復 solon aot 時 extract method 未註冊的問題&lt;/li&gt; 
 &lt;li&gt;修復 solon-net-httputils JdkHttpResponse:bodyAsString 不能使用指定編碼的問題&lt;/li&gt; 
 &lt;li&gt;修復 solon-net-httputils TextStreamUtil 不能使用指定編碼的問題&lt;/li&gt; 
 &lt;li&gt;修復 solon-scheduling-simple 可能啓動後就退出的問題（有些任務觸發時間晚，調試線程池未啓動）&lt;/li&gt; 
 &lt;li&gt;修復 solon-security-validation 的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@Email&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;驗校註解兼容性問題（之前 name 有點會出錯）&lt;/li&gt; 
 &lt;li&gt;liquor 升為 1.5.8&lt;/li&gt; 
 &lt;li&gt;wood 升為 1.3.24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;項目倉庫地址？&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;gitee：&lt;a href="https://gitee.com/opensolon/solon"&gt;https://gitee.com/opensolon/solon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;gitcode:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitcode.com%2Fopensolon%2Fsolon" target="_blank"&gt;https://gitcode.com/opensolon/solon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;github：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopensolon%2Fsolon" target="_blank"&gt;https://github.com/opensolon/solon&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;官網？&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2F" target="_blank"&gt;https://solon.noear.org&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362989</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362989</guid>
      <pubDate>Wed, 16 Jul 2025 08:46:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Linux 6.16 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linus Torvalds 在內核郵件列表&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwh0kuQE%2BtWMEPJqCR48F4Tip2EeYQU-mi%2B2Fx_Oa1Ehbw%40mail.gmail.com%2FT%2F%23u" target="_blank"&gt;正式發佈&lt;/a&gt;了 Linux 6.16，並宣佈 6.17 合併窗口開放。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/162954_qvBQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Linux 6.16 主要新特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;改進性能&lt;/li&gt; 
 &lt;li&gt;支持 AMD 和英特爾的新硬件&lt;/li&gt; 
 &lt;li&gt;Nouveau 驅動支持英偉達 Blackwell 和 Hopper GPU&lt;/li&gt; 
 &lt;li&gt;英特爾 APX 初步支持&lt;/li&gt; 
 &lt;li&gt;USB 音頻分流（Offloading）&lt;/li&gt; 
 &lt;li&gt;改進 OpenVPN 性能&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於 Linux 6.17，Torvalds 提醒開發者，本次合併窗口可能會「略顯混亂」，原因是他 8 月份將因婚禮和重要生日而安排長時間家庭旅行。因此「這可能影響他在合併窗口第二週處理 pull request 的效率」。&lt;/p&gt; 
&lt;p&gt;Linus 坦言，如果第二週無法及時處理所有請求，他「可能會略微推遲 rc1，以便趕上進度」。按照慣例，相應合併窗口將持續兩週，隨後進入包含七到八個候選版本的測試週期。主要的新特性會在合併窗口階段逐漸加入，再通過候選版本逐漸穩定下來。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362982</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362982</guid>
      <pubDate>Wed, 16 Jul 2025 08:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>統信 Windows 應用兼容引擎官網上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;統信 Windows 應用兼容引擎官網已於近日正式上線，「&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;標誌着兼容技術從工具迭代邁向生態共建的新階段&lt;/span&gt;&lt;span style="color:#000000"&gt;」。官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLicvwV1XgGFgG_GKdHzImw" target="_blank"&gt;發文&lt;/a&gt;詳細介紹了統信 Windows 應用兼容引擎的演進歷程、核心功能與生態共建新起點。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;前期探索&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;wine 助手與 UOS 應用遷移助手&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2014 年，deepin-wine 團隊以「讓 Linux 系統流暢運行 Windows 應用」為目標，持續向 wine 上游社區提交 200 餘個補丁，十餘年間團隊從技術驗證走向產品化，產品也在不斷升級演進。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2021 年：首次嘗試 wine 技術應用化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2021 年，團隊首次嘗試將 wine 技術應用化，推出了「wine 助手」，實現了在 deepin 上雙擊直接安裝運行 Windows exe 程序，讓普通用户無需複雜操作即可使用 Windows 應用，大幅降低了 wine 技術的使用門檻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="248" src="https://oscimg.oschina.net/oscnet/up-29ad2fa7bd2709449d99883d318532ea5b0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;2024 年：UOS 應用遷移助手聚焦專業場景&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年，推出與 wine 助手定位差異化的「UOS 應用遷移助手」，聚焦更多專業場景，主打將 exe 程序打包為 deb 包，支持綠色軟件打包、ARM 架構運行等特性，滿足運維人員、技術工程師及應用開發者的專業需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-59821dc6d3b3bc43207d6072947b4234f52.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;統信 Windows 應用兼容引擎&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;功能升級與定位革新&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 11 月，UOS 應用遷移助手正式更名為「統信 Windows 應用兼容引擎」，並於 12 月迭代至 V3.0.4 版本，實現功能與定位的雙重升級：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;軟件功能重構&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從「打包工具」轉向「全場景兼容引擎」，支持直接雙擊運行 Windows exe 程序；打包功能整合至應用管理菜單，成為兼容成功後的延伸能力，優先保障 wine 應用的運行成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;覆蓋多元用户需求&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向普通用户提供「一鍵運行」便利，為技術發燒友、軟件廠商提供圖形化遷移工具，助力 Windows 程序快速適配 deepin 與統信 UOS，滿足多架構、多場景的生態需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="335" src="https://oscimg.oschina.net/oscnet/up-c8e50fba3fe4eed53c9ee23e7fae68c4f86.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年，統信 Windows 應用兼容引擎持續迭代，現已更新至 V3.3.1 版本，進一步提升技術實力與生態覆蓋。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Proton 支持與架構適配&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;3&amp;nbsp;月成功適配 Proton 技術，支持在 deepin 25 中選擇「ge-proton」版本運行遊戲，大幅提升遊戲運行成功率與性能；新增與 Steam 版本對齊的穩定版 Proton，增加對 wow64 的支持，實現純 64 位系統運行多數 32 位遊戲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="269" src="https://oscimg.oschina.net/oscnet/up-93effbf36f9e47fd70fbe255d4b322344ff.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;應用清單與版本標準化&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;5 月 V3.3.0 版本新增 「全部應用」 模塊，整合 deepin-wine 團隊驗證通過的可兼容應用清單，為用户提供清晰的適配參考；默認 wine 版本升級為 deepin-wine10-stable，統一容器運行標準，減少適配衝突。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="382" src="https://oscimg.oschina.net/oscnet/up-6024ea1bea8099cb9b6ab2da98e7a666c43.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;wine 應用內存佔用下降 90%&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;6 月 V3.3.1 版本&lt;/strong&gt;解決了 wine 應用在 Linux 下的內存開銷過大問題，針對 64 位 Electron 框架的應用優化最為明顯，實測可以減少 90% 內存開銷，趨近於其在原生 Windows 平台上的實際使用量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-b95aae66980222fd322f3775f265b8b3b1a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;官網上線&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;打造協同共建新平台&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;統信 Windows 應用兼容引擎官網地址：&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:#3f3f3f"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwine.deepin.org%2F" target="_blank"&gt;https://wine.deepin.org/&lt;/a&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;提供詳細使用教程、開發文檔與論壇交流入口等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-030f9331200776bda96ead8151501f87a9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362978</guid>
      <pubDate>Wed, 16 Jul 2025 08:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包 App 視覺推理能力升級，圖片分析支持深度思考</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;豆包 App 在視覺推理領域迎來重大升級，其圖片分析功能現已支持深度思考模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;用户只需在深度思考模式下拍攝或上傳一張圖片，豆包便能迅速對圖片進行放大、裁剪等精細處理，並支持圖片搜索功能，實現邊想邊搜，從而進一步提升搜索結果的準確性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-0abd984fd925aba9f9e2f8f34b62cce318d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在圖片分析過程中，豆包展現出強大的信息處理能力。它能夠根據圖片中的細節信息，對比歷史檔案，檢索出相似圖片，並梳理出圖片的演變脈絡。通過這一系列操作，豆包能夠最終確定圖片的年代範圍，為用户提供更為精準的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，豆包還能對圖片進行深入分析，根據地形景觀、建築風格以及窗户細節等特徵，對照地理和人文特徵進行綜合判斷。經過這一系列複雜的分析過程，豆包能夠準確確定圖片所展示的具體方位，甚至最終確定城市名稱，為用户提供更加全面、準確的圖片解讀服務。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362977</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362977</guid>
      <pubDate>Wed, 16 Jul 2025 07:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻 inclusionAI 團隊發佈 Ming-lite-omni v1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻集團 inclusionAI 團隊發佈了全面升級版的全模態模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finclusionai.github.io%2Fzh%2Fblog%2Fming-lite-omni-1_5%2F" target="_blank"&gt;&lt;strong&gt;Ming-Lite-Omni v1.5&lt;/strong&gt;&lt;/a&gt;，基於 &lt;strong&gt;Ling-lite-1.5&lt;/strong&gt; 構建，總參數量為 &lt;strong&gt;203 億&lt;/strong&gt;（其中 MoE 部分活躍參數為 &lt;strong&gt;30 億&lt;/strong&gt;），在圖像-文本理解、文檔理解、視頻理解、語音理解與合成、圖像生成與編輯等全模態能力上顯著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95012b461af8180f5480bac2f4c85b95949.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ming-lite-omni v1.5 模型架構如下，主題參考了 Ming-lite-omni v1 版本的結構，區別在於為了增強圖像編輯人物和場景一致性，升級 Vision head 支持參考圖特徵輸入。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6c48bdf68ea2bcdfc0e8deb440f605297fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關鍵優化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;增強視頻理解&lt;/strong&gt;：通過 &lt;strong&gt;MRoPE 3D 時空編碼&lt;/strong&gt; 和針對長視頻的 &lt;strong&gt;課程學習策略&lt;/strong&gt;，顯著提升對複雜視覺序列的理解能力 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;優化多模態生成&lt;/strong&gt;：採用雙分支圖像生成（ID 與場景一致性損失）和新的音頻解碼器及 BPE 編碼，提升生成一致性與感知控制，實現高質量實時語音合成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據全面升級&lt;/strong&gt;：新增結構化文本數據、高質量產品信息及包括方言（如普通話、粵語、四川話等）在內的精細化視覺與語音感知數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;性能表現&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 &lt;strong&gt;MMVet&lt;/strong&gt;、&lt;strong&gt;MathVista&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt; 等數據集上表現突出，文檔理解任務（如 &lt;strong&gt;ChartQA&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt;）取得 10B 以下參數模型中的 &lt;strong&gt;SOTA&lt;/strong&gt; 成績。&lt;/li&gt; 
 &lt;li&gt;視頻理解、語音理解與生成（支持多種方言）及圖像生成（保持人物 ID 一致性編輯）均處於行業領先地位。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;該模型已在 &lt;strong&gt;Hugging Face&lt;/strong&gt; 和 &lt;strong&gt;ModelScope&lt;/strong&gt; 上開放下載，並提供詳細安裝指南、代碼示例和 &lt;strong&gt;Gradio&lt;/strong&gt; 演示。&lt;/p&gt; 
&lt;p&gt;Hugging Face: https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5&lt;br&gt; ModelScope: https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362971</guid>
      <pubDate>Wed, 16 Jul 2025 07:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>eBPF 助力 NAS 分鐘級別 Pod 實例溯源</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;雲存儲 NAS 產品是一個可共享訪問、彈性擴展、高可靠、高性能的分佈式文件系統。 NAS 兼容了 POSIX 文件接口，可支持數千台計算節點共享訪問，可掛載到彈性計算 ECS、容器實例等計算業務上，提供高性能的共享存儲服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;鑑於多主機間共享的便利性和高性能， NAS 在得物的算法訓練、應用構建等場景中均成為了基礎支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/36/36274710c18533ce5fc246ee82e640c2.jpeg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在多業務共享的場景中，單個業務流量異常容易引發全局故障。目前，異常發生後需依賴&lt;strong&gt;雲服務廠商 NAS &lt;/strong&gt;的溯源能力，&lt;strong&gt;但只能定位到主機級別，無法識別具體異常服務&lt;/strong&gt;。要定位到服務級別，仍需依賴所有使用方協同排查，並由 SRE 多輪統計分析，&lt;strong&gt;效率低下&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6a6a6a"&gt;（若服務實例發生遷移或重建，排查難度進一步增加）&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;為避免因 NAS 異常或帶寬佔滿導致模型訓練任務受阻&lt;/strong&gt;，因此需構建支持服務級流量監控、快速溯源及 NAS 異常實時感知的能力，以提升問題定位效率並減少業務中斷。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、流量溯源方案調研和驗證&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;NAS 工作原理&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 本地掛載原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux 平台上，NAS 的產品底層是基於標準網絡文件系統 NFS（Network File System），通過將遠端文件系統掛載到本地，實現用户對遠端文件的透明訪問。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NFS 協議（主要支持 NFS v3 和 v4，通常以 v3 為主）允許將遠端服務掛載到本地，使用户能夠像訪問本地文件目錄一樣操作遠端文件。文件訪問請求通過 RPC 協議發送到遠端進行處理，其整體流程如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="465" src="https://oscimg.oschina.net/oscnet/up-3f3abf4fce2a08639688cf370284cf62cdd.png" width="620" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;文件系統訪問時的數據流向示意&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="552" src="https://oscimg.oschina.net/oscnet/up-a5b7a533fbca51c726053b4598e79c9786f.jpg" width="507" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;Linux 內核中 NFS 文件系統&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NFS 文件系統讀/寫流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux NFS 文件系統的實現中，文件操作接口由 nfs_file_operations 結構體定義，其讀取操作對應的函數為:&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;//NFS 文件系統的 VFS 層實現的函數如下所示：
const&amp;nbsp;struct&amp;nbsp;file_operations nfs_file_operations = {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .llseek &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_llseek,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .read_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;= nfs_file_read,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .write_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_write,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
};&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;針對 NFS 文件系統的讀操作涉及到 2 個階段（寫流程類似，只是函數名字有所差異，本文僅以讀取為例介紹）。由於文件讀取涉及到網絡操作因此這兩個階段涉及為異步操作：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 兩個階段&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;讀取請求階段：&lt;/strong&gt;當應用程序針對 NFS 文件系統發起 read() 讀操作時，內核會在 VFS 層調用 nfs_file_read 函數，然後調用 NFS 層的 nfs_initiate_read 函數，通過 RPC 的 rpc_task_begin 函數將讀請求發送到 NFS Server，至此向 NFS Server 發起的請求工作完成。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;讀響應階段：&lt;/strong&gt;在 NFS Server 返回消息後，會調用 rpc_task_end 和 nfs_page_read_done 等函數，將數據返回到用户空間的應用程序。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="415" src="https://oscimg.oschina.net/oscnet/up-fd2c800299c65096f8d6eba7de108c0581f.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在瞭解 NFS 文件系統的讀流程後，我們回顧一下 NFS Server 為什麼無法區分單機訪問的容器實例或進程實例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;這是因為 NFS 文件系統的讀寫操作是在內核空間實現的。當容器 A/B 和主機上的進程 C 發起讀請求時，這些請求在進入內核空間後，統一使用主機 IP（如 192.168.1.2）作為客户端 IP 地址。因此，NFS Server 端的統計信息只能定位到主機維度，無法進一步區分主機內具體的容器或進程。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-91366119d285327518f226735b34227dddd.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;內核空間實現示意&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;方案調研和驗證&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;進程對應容器上下文信息關聯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;內核中進程以 PID 作為唯一編號，與此同時，內核會建立一個 struct task_struct 對象與之關聯，在 struct task_struct 結構會保存進程對應的上下文信息。如實現 PID 信息與用户空間容器上下文的對應（進程 PID 1000 的進程屬於哪個 Pod 哪個 Container 容器實例），我們需基於內核 task_struct 結構獲取到容器相關的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過分析內核代碼和資料確認，發現可以通過 task_struct 結構中對應的 cgroup 信息獲取到進程對應的 cgroup_name 的信息，而該信息中包含了容器 ID 信息，例如&lt;strong&gt; docker-2b3b0ba12e92...983.scope &lt;/strong&gt;，完整路徑較長，使用 .... 省略。基於容器 ID 信息，我們可進一步管理到進程所歸屬的 Pod 信息，如 Pod NameSpace 、 Pod Name 、 Container Name 等元信息，最終完成進程 PID 與容器上下文信息元數據關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;struct&amp;nbsp;task_struct&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;css_set&amp;nbsp;__rcu &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;*cgroups;
}


struct&amp;nbsp;css_set&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;*subsys[CGROUP_SUBSYS_COUNT];
}


struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup&amp;nbsp;*cgroup;
}


struct&amp;nbsp;cgroup&amp;nbsp;{
&amp;nbsp;&amp;nbsp;struct&amp;nbsp;kernfs_node&amp;nbsp;*kn; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/* cgroup kernfs entry */
}


struct&amp;nbsp;kernfs_node&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *name; &amp;nbsp;// docker-2b3b0ba12e92...983.scope
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以某容器進程為例，該進程在 Docker 容器環境中的 cgroup 路徑完整為 /sys/fs/cgroup/cpu/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podefeb3229_4ecb_413a_8715_5300a427db26.slice/docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;經驗證，我們在內核中讀取 task-&amp;gt;cgroups-&amp;gt;subsys[0]-&amp;gt;kn-&amp;gt;name 的值為 docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/92/92735ea140e6e0021584e2c7cc21b0b4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;其中容器 ID 字段為 docker- 與 .scope 間的字段信息，在 Docker 環境中一般取前 12 個字符作為短 ID，如 2b3b0ba12e92 ，可通過 docker 命令進行驗證，結果如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;docker&amp;nbsp;ps -a|grep&amp;nbsp;2b3b0ba
2b3b0ba12e92&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; registry-cn-hangzhou-vpc.ack.aliyuncs.com/acs/pause:3.5&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 上下文信息關聯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NAS 產品的訪問通過掛載命令完成本地文件路徑的掛載。我們可以通過 mount 命令將 NAS 手工掛載到本地文件系統中。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;mount&amp;nbsp;-t nfs -o vers=3,nolock,proto=tcp,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport \
&amp;nbsp;&amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test /mnt/nas&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;執行上述掛載命令成功後，通過 mount 命令則可查詢到類似的掛載記錄：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;5368 47 0:660 / /mnt/nas rw,relatime shared:1175 \
&amp;nbsp; &amp;nbsp; &amp;nbsp;- nfs 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test \ &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp;rw,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,nolock,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;noresvport,proto=tcp,timeo=600,retrans=2,sec=sys, \
&amp;nbsp; &amp;nbsp; &amp;nbsp;mountaddr=192.168.0.91,mountvers=3,mountport=2049,mountproto=tcp,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;local_lock=all,addr=192.168.0.92&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;核心信息分析如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# 掛載點，父掛載點，掛載設備號 &amp;nbsp; 目錄 &amp;nbsp; &amp;nbsp; 掛載到本機目錄 &amp;nbsp;協議 &amp;nbsp; NAS 地址
5368&amp;nbsp; &amp;nbsp; &amp;nbsp;47&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0:660&amp;nbsp; &amp;nbsp; &amp;nbsp;/ &amp;nbsp; &amp;nbsp; &amp;nbsp; /mnt/nas &amp;nbsp; &amp;nbsp; nfs &amp;nbsp; &amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;maror:minor&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;掛載記錄中的&lt;/span&gt;&lt;span style="color:#d92142"&gt;&lt;strong&gt; 0:660 &lt;/strong&gt;&lt;/span&gt;為本地設備編號，格式為 major:minor ， 0 為 major 編號， 660 為 minor 編號，系統主要以 minor 為主。在系統的 NFS 跟蹤點 nfs_initiate_read 的信息中的 dev 字段則為在掛載記錄中的 minor 編號。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;cat /sys/kernel/debug/tracing/events/nfs/nfs_initiate_read/format
format:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:dev_t dev; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:8; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:u32 count; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:32; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過用户空間 mount 信息和跟蹤點中 dev_id 信息，則可實現內核空間設備編號與 NAS 詳情的關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;內核空間信息獲取&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如容器中進程針對掛載到本地的目錄 /mnt/nas 下的文件讀取時，會調用到 nfs_file_read() 和 nfs_initiate_read 函數。通過 nfs_initiate_read 跟蹤點我們可以實現進程容器信息和訪問 NFS 服務器的信息關聯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過編寫 eBPF 程序針對跟蹤點 tracepoint/nfs/nfs_initiate_read 觸發事件進行數據獲取，我們可獲取到訪問進程所對應的 cgroup_name 信息和訪問 NFS Server 在本機的設備 dev_id 編號。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="673" src="https://oscimg.oschina.net/oscnet/up-b7e2eac3eeba85b51ed94f7a84d28a096ea.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;獲取 cgroup_name 信息&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;進程容器上下文獲取：&lt;/strong&gt; 通過 cgroup_name 信息，如樣例中的 docker-2b3b0ba12e92...983.scope ，後續可以基於 container_id 查詢到容器對應的 Pod NameSpace 、 Pod Name 和 Container Name 等信息，從而定位到訪問進程關聯的 Pod 信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NAS 上下文信息獲取：&lt;/strong&gt; 通過 dev 信息，樣例中的 660 ，通過掛載到本地的記錄，可以通過 660 查詢到對應的 NAS 產品的地址，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com 。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户空間元信息緩存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/aa/aa252b079e6ce3cb1e52e02ab5b4052a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在用户空間中，可以通過解析掛載記錄來獲取 DEV 信息，並將其與 NAS 信息關聯，從而建立以 DevID 為索引的查詢緩存。如此，後續便可以基於內核獲取到 dev_id 進行關聯，進一步補全 NAS 地址及相關詳細信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;對於本地容器上下文的信息獲取，最直接的方式是通過 K8s kube-apiserver 通過 list-watch 方法進行訪問。然而，這種方式會在每個節點上啓動一個客户端與 kube-apiserver 通信，顯著增加 K8s 管控面的負擔。因此，我們選擇通過本地容器引擎進行訪問，直接在本地獲取主機的容器詳情。通過解析容器註解中的 Pod 信息，可以建立容器實例緩存。後續在處理指標數據時，則可以通過 container-id 實現信息的關聯與補全。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;三、架構設計和實現&lt;/h1&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;整體架構設計&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;內核空間的信息採集採用 Linux eBPF 技術實現，這是一種安全且高效的內核數據採集方式。簡單來説，eBPF 的原理是在內核中基於事件運行用户自定義程序，並通過內置的 map 和 perf 等機制實現用户空間與內核空間之間的雙向數據交換。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NFS 和 RPC 調用事件觸發的基礎上，可以通過編寫內核空間的 eBPF 程序來獲取必要的原始信息。當用户空間程序蒐集到內核指標數據後，會對這些原始信息進行二次處理，並在用户空間的採集程序中補充容器進程信息（如 NameSpace、Pod 和 Container 名稱）以及 NFS 地址信息（包括 NFS 遠端地址）。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/c6/c687b3f4df8a2ce5d0ab5cd9f287dfd4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;內核 eBPF 程序流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 NFS 文件讀為例，通過編寫 eBPF 程序跟蹤 nfs_initiate_read / rpc_task_begin / rpc_task_end / nfs_page_read_done 等關鍵鏈路上的函數，用於獲取到 NFS 讀取的數據量和延時數據，並將訪問鏈路中的進程上下文等信息保存到內核中的指標緩存中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="471" src="https://oscimg.oschina.net/oscnet/up-f854a1a8cdf429eff044e715772dc96dfb6.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如上圖所示， nfs_initate_read 和 rpc_task_begin 發生在同一進程上下文中，而 rpc_task_begin 與 rpc_task_end 是異步操作，儘管兩者不處於同一進程上下文，但可以通過 task_id 進行關聯。同時， page_read_done 和 rpc_task_end 則發生在同一進程上下文中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-70f989400d6710f021cfa7577375a709030.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;nfs_initiate_read 函數調用觸發的 eBPF 代碼示例如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;

SEC("tracepoint/nfs/nfs_initiate_read")
int&amp;nbsp;tp_nfs_init_read(struct&amp;nbsp;trace_event_raw_nfs_initiate_read *ctx)
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步驟 1 獲取到 nfs 訪問的設備號信息，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com
&amp;nbsp; &amp;nbsp;&amp;nbsp;// dev_id 則為： 660&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;dev_t&amp;nbsp;dev_id =&amp;nbsp;BPF_CORE_READ(ctx, dev);
&amp;nbsp; &amp;nbsp; u64 file_id =&amp;nbsp;BPF_CORE_READ(ctx, fileid);
&amp;nbsp; &amp;nbsp; u32 count =&amp;nbsp;BPF_CORE_READ(ctx, count);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;task_struct&amp;nbsp;*task = (struct&amp;nbsp;task_struct *)bpf_get_current_task();


&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步驟 2 獲取進程上下文所在的容器 cgroup_name 信息
&amp;nbsp; &amp;nbsp;&amp;nbsp;// docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp;*cname =&amp;nbsp;BPF_CORE_READ(task, cgroups, subsys[0], cgroup, kn, name);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cname)
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_core_read_str(&amp;amp;info.container, MAX_PATH_LEN, cname);
&amp;nbsp; &amp;nbsp; }


&amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_map_update_elem(&amp;amp;link_begin, &amp;amp;tid, &amp;amp;info, BPF_ANY);
}


SEC("tracepoint/nfs/nfs_readpage_done")
int&amp;nbsp;tp_nfs_read_done(struct&amp;nbsp;trace_event_raw_nfs_readpage_done *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_begin")
int&amp;nbsp;tp_rpc_task_begin(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;&amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_end")
int&amp;nbsp;tp_rpc_task_done(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;用户空間程序架構&lt;/span&gt;&lt;/h2&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b9cf6d19b68dcceaa9f6f459645264baaa8.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;元數據緩存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ NAS 掛載信息緩存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過解析掛載記錄，可以獲取 DEV 信息與 NAS 信息的關聯關係。以下是實現該功能的關鍵代碼詳情：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;scanner := bufio.NewScanner(mountInfoFile)
count :=&amp;nbsp;0
for&amp;nbsp;scanner.Scan() {
&amp;nbsp; &amp;nbsp; line := scanner.Text()
&amp;nbsp; &amp;nbsp; devID,remoteDir, localDir, NASAddr = parseMountInfo(line)


&amp;nbsp; &amp;nbsp; mountInfo := MountInfo{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;DevID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; devID,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;RemoteDir: &amp;nbsp; &amp;nbsp; remoteDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;LocalMountDir: localDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NASAddr： NASAddr,
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; mountInfos =&amp;nbsp;append(mountInfos, mountInfo)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 容器元信息緩存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過 Docker 或 Containerd 客户端，從本地讀取單機的容器實例信息，並將容器的上下文數據保存到本地緩存中，以便後續查詢使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;podInfo := PodInfo{
&amp;nbsp; &amp;nbsp; NameSpace: &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.namespace"],
&amp;nbsp; &amp;nbsp; PodName: &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.name"],
&amp;nbsp; &amp;nbsp; ContainerName: labels["io.kubernetes.container.name"],
&amp;nbsp; &amp;nbsp; UID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.uid"],
&amp;nbsp; &amp;nbsp; ContainerID: &amp;nbsp; conShortID,
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;數據處置流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;用户空間程序的主要任務是持續讀取內核 eBPF 程序生成的指標數據，並對讀取到的原始數據進行處理，提取訪問設備的 dev_id 和 container_id 。隨後，通過查詢已建立的元數據緩存，分別獲取 NAS 信息和容器 Pod 的上下文數據。最終，經過數據合併與處理，生成指標數據緩存供後續使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;func&amp;nbsp;(m *BPFEventMgr)&amp;nbsp;ProcessIOMetric() {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; events := m.ioMetricMap
&amp;nbsp; &amp;nbsp; iter := events.Iterate()


&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;iter.Next(&amp;amp;nextKey, &amp;amp;event) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ① 讀取到的 dev_id 轉化為對應的完整 NAS 信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;devId := nextKey.DevId
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;mountInfo, ok := m.mountMgr.Find(int(devId))


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ② 讀取 containerID 格式化並查詢對應的 Pod 上下文信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;containerId := getContainerID(nextKey.Container)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;podInfo, ok = m.criMgr.Find(containerId)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ③ 基於事件信息、NAS 掛載信息和 Pod 上下文信息，生成指標數據緩存&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;metricKey, metricValue := formatMetricData(nextKey， mountInfo, podInfo)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;value, loaded := metricCache.LoadOrStore(metricKey, metricValue)
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ④ 指標數據緩存，生成最終的 Metrics 指標並更新&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;var&amp;nbsp;ioMetrics []metric.Counter
&amp;nbsp; &amp;nbsp; metricCache.Range(func(key, value&amp;nbsp;interface{})&amp;nbsp;bool&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;k := key.(metric.IOKey)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;v := value.(metric.IOValue)


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ioMetrics =&amp;nbsp;append(ioMetrics, metric.Counter{"read_count",&amp;nbsp;float64(v.ReadCount),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[]string{k.NfsServer, v.NameSpace, v.Pod, v.Container})
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&amp;nbsp;true
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; m.metricMgr.UpdateIOStat(ioMetrics)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;啓動 Goroutine 處理指標數據：通過啓動一個 Goroutine，循環讀取內核存儲的指標數據，並對數據進行處理和信息補齊，最終生成符合導出格式的 Metrics 指標。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 具體步驟&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;獲取 NAS 信息：&lt;/strong&gt;從讀取的原始數據中提取 dev_id ，並通過 dev_id 查詢掛載的 NAS 信息，例如遠端訪問地址等相關數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;查詢 Pod 上下文：&lt;/strong&gt;對 containerID 進行格式化處理，並查詢對應的容器 Pod 上下文信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成指標數據緩存：&lt;/strong&gt;基於事件數據、NAS 掛載信息和 Pod 上下文信息，生成指標數據緩存。此過程主要包括對相同容器上下文的數據進行合併和累加。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;導出 Metrics 指標：&lt;/strong&gt;根據指標數據緩存，生成最終的 Metrics 指標，並更新到指標管理器。隨後，通過自定義的 Collector 接口對外導出數據。當 Prometheus 拉取數據時，指標會被轉換為最終的 Metrics 格式。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過上述步驟，用户空間能夠高效地處理內核 eBPF 程序生成的原始數據，並結合 NAS 掛載信息和容器上下文信息，生成符合 Prometheus 標準的 Metrics 指標，為後續的監控和分析提供了可靠的數據基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自定義指標導出器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在導出指標的場景中，我們需要基於保存在 Go 語言中的 map 結構中的動態數據實時生成，因此需要實現自定義的 Collector 接口。自定義 Collector 接口需要實現元數據描述函數 Describe() 和指標蒐集的函數 Collect() ，其中 Collect() 函數可以併發拉取，因此需要通過加鎖實現線程安全。該接口需要實現以下兩個核心函數：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Describe() ：用於定義指標的元數據描述，向 Prometheus 註冊指標的基本信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Collect() ：用於蒐集指標數據，該函數支持併發拉取，因此需要通過加鎖機制確保線程安全。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;type&amp;nbsp;Collector&amp;nbsp;interface&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 指標的定義描述符
&amp;nbsp; &amp;nbsp; Describe(chan&amp;lt;- *Desc)
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 並將收集的數據傳遞到 Channel 中返回
&amp;nbsp; &amp;nbsp; Collect(chan&amp;lt;- Metric)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;我們在指標管理器中實現 Collector 接口， 部分實現代碼，如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;nfsIOMetric := prometheus.NewDesc(
&amp;nbsp; &amp;nbsp; prometheus.BuildFQName(prometheusNamespace,&amp;nbsp;"",&amp;nbsp;"io_metric"),
&amp;nbsp; &amp;nbsp;&amp;nbsp;"nfs io metrics by cgroup",
&amp;nbsp; &amp;nbsp; []string{"nfs_server",&amp;nbsp;"ns",&amp;nbsp;"pod",&amp;nbsp;"container",&amp;nbsp;"op",&amp;nbsp;"type"},
&amp;nbsp; &amp;nbsp;&amp;nbsp;nil,
)


// Describe and Collect implement prometheus collect interface
func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Describe(ch&amp;nbsp;chan&amp;lt;- *prometheus.Desc) {
&amp;nbsp; &amp;nbsp; ch &amp;lt;- m.nfsIOMetric
}


func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Collect(ch&amp;nbsp;chan&amp;lt;- prometheus.Metric) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// Note：加鎖保障線程併發安全
&amp;nbsp; &amp;nbsp; m.activeMutex.Lock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;defer&amp;nbsp;m.activeMutex.Unlock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;_, v :=&amp;nbsp;range&amp;nbsp;m.ioMetricCounters {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ch &amp;lt;- prometheus.MustNewConstMetric(m.nfsIOMetric, prometheus.GaugeValue, v.Count, v.Labels...)
&amp;nbsp; &amp;nbsp; }

&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;當前 NAS 溯源能力已正式上線，以下是主要功能和視圖介紹：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 單 NAS 實例整體趨勢&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;支持基於環境和 NAS 訪問地址過濾，展示 NAS 產品的讀寫 IOPS 和吞吐趨勢圖。同時，基於內核空間統計的延時數據，提供 P95 讀寫延時指標，用於判斷讀寫延時情況，輔助問題分析和定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/14/14577d6fe8b2876ca7f5138680fc3667.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/9c/9c091aeaecc284956b851416de5d313a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NAS 流量溯源方面，我們結合業務場景設計了基於任務和 Pod 實例維度的流量分析視圖：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 任務維度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通過聚合具有共同屬性的一組 Pod 實例，展示任務級別的整體流量情況。該視圖支持快速定位任務級別的流量分佈，幫助用户進行流量溯源和多任務錯峯使用的依據。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/0a/0a504606b05345b52061d2f754c15b51.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Pod 實例維度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 Pod 為單位進行流量分析和彙總，提供 Pod NameSpace 和 Name 信息，支持快速定位和分析實例級別的流量趨勢，幫助細粒度監控和異常流量的精準定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/90/90765c51493906beaf530c64494abc6a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在整體能力建設完成後，我們成功構建了 NAS 實例級別的 IOPS、吞吐和讀寫延時數據監控大盤。通過該能力，進一步實現了 NAS 實例的 IOPS 和吞吐可以快速溯源到任務級別和 Pod 實例級別，流量溯源時效從小時級別縮短至分鐘級別，有效提升了異常問題定位與解決的效率。同時，基於任務流量視圖，我們為後續帶寬錯峯複用提供了直觀的數據支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;1.&lt;/span&gt;正品庫拍照 PWA 應用的實現與性能優化｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;2.&lt;/span&gt;匯金資損防控體系建設及實踐 | 得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;3.&lt;/span&gt;一致性框架：供應鏈分佈式事務問題解決方案｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;4.&lt;/span&gt;得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;5.&lt;/span&gt;從 CPU 冒煙到絲滑體驗：算法 SRE 性能優化實戰全揭秘｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 泊明&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;關注得物技術，每週更新技術乾貨&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18683994</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18683994</guid>
      <pubDate>Wed, 16 Jul 2025 07:35:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
