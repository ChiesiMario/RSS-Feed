<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 19 Mar 2025 02:43:39 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>字節召開大模型全員會：取消 AGI 研究團隊季度與半年考核</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字節跳動的豆包大模型團隊（Seed）近日召開了一次全員會議，由剛加入字節負責 AI 基礎研究探索的吳永輝與模型應用負責人朱文佳共同主持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;會議上，朱文佳和吳永輝明確表示，Seed 團隊的首要目標是 「探索智能上限」，這將成為團隊未來工作的核心導向。他們指出，探索智能的邊界是一個長期的任務，團隊將圍繞已發佈的 AGI 研究計劃 「Seed Edge」 進行深入研究。朱文佳提到，鼓勵團隊成員參與有挑戰性的研究課題，探索具有不確定性和前瞻性的 AI 技術，將是今年的重點之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;276&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca5ed7f8eb1cb23c67774924335eae3009a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;吳永輝強調了基礎研究的重要性，並表示將加大對 Seed Edge 項目的資源投入，包括提供更多的計算能力，以支持長遠的研究發展。他提到，Seed 希望成為一個能夠吸引和培養頂尖人才的組織，強調內部人才的使用和培養是團隊成功的關鍵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在組織文化方面，會議還討論瞭如何增強團隊的開放性和包容性，以營造一個鼓勵創新的環境。為此，字節跳動決定取消 Edge 項目的季度 OKR 和半年考核，旨在為團隊提供一個更穩定的研究環境，減輕因考核而產生的壓力。吳永輝希望通過這樣的改變，提升團隊的創造力和研究的深度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，團隊還提到未來可能會考慮開源一些中小尺寸的 Dense 模型，以推動技術在社區中的應用。這樣的舉措不僅有助於增強 Seed 團隊的影響力，也能促進外部的合作與交流。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339724</guid>
            <pubDate>Wed, 19 Mar 2025 02:34:31 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌將以 320 億美元全現金交易收購 Wiz</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌母公司 Alphabet Inc. 已同意以 320 億美元現金（約 2312.6 億元人民幣）收購網絡安全公司 Wiz Inc.，交易完成後，Wiz 將加入谷歌雲業務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b694b65e36bb41b50e4ab2751738269c9c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據報道，這筆交易將成為 Alphabet 迄今為止最大的一筆收購，Wiz 去年曾拒絕 Alphabet 提出的 230 億美元的報價，理由是擔心監管挑戰以及希望保持獨立，但現在已同意了更高的報價。&lt;/p&gt; 
&lt;p&gt;TechCrunch 報道稱，去年 7 月，Wiz 的 ARR 為 5 億美元，並計劃在 2025 年達到 10 億美元。&lt;/p&gt; 
&lt;p&gt;即便如此，300 億美元也可能是一個相當高的價格。去年 5 月，Wiz 完成了上一輪 10 億美元的外部融資，估值達到 120 億美元。據報道，去年年底，在一次員工競購中，其估值躍升至 160 億美元。&lt;/p&gt; 
&lt;p&gt;儘管 Wiz 表示沒有計劃在 2025 年上市，但它聘請了夢工廠和 Tanium 前高管法扎爾・麥錢特 (Fazal Merchant) 擔任首席財務官。有時，聘請首席財務官是準備公開上市的標誌。&lt;/p&gt; 
&lt;p&gt;報道稱，此前談判失敗的原因之一是兩家公司未能就 Wiz 是保留為獨立部門還是整合到 Google Cloud 達成一致。&lt;/p&gt; 
&lt;p&gt;熟悉該交易的人士表示，拜登政府對大額交易的嚴格監管審查也是導致該交易去年夏天失敗的原因之一。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關來源&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Finside-google%2Fcompany-announcements%2Fgoogle-agreement-acquire-wiz%2F&quot; target=&quot;_blank&quot;&gt;https://blog.google/inside-google/company-announcements/google-agreement-acquire-wiz/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wiz.io%2Fblog%2Fwiz-joining-google&quot; target=&quot;_blank&quot;&gt;https://www.wiz.io/blog/wiz-joining-google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fidentity-security%2Fgoogle-announces-agreement-acquire-wiz&quot; target=&quot;_blank&quot;&gt;https://cloud.google.com/blog/products/identity-security/google-announces-agreement-acquire-wiz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339725/google-announces-agreement-acquire-wiz</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339725/google-announces-agreement-acquire-wiz</guid>
            <pubDate>Wed, 19 Mar 2025 02:34:31 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>盧偉冰：將投入 1/4 研發經費至 AI 技術，AI、OS 和芯片三項被列為小米核心技術</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，小米集團總裁盧偉冰今日晚間在 2024 年業績會上稱，&lt;strong&gt;小米將投入總研發經費的 1/4，大約 70 至 80 億元到 AI 中&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;盧偉冰表示，&lt;strong&gt;長期來看，AI、OS 和芯片三項被列為小米核心技術&lt;/strong&gt;。短期來看，小米要做好 AI 基建，開發語言大模型、多模態大模型等 AI 技術，搭建 AI 大模型落地的應用場景，比如超級小愛、智能座艙、智能駕駛等，小米內部也會利用 AI 技術進行內部提效。&lt;/p&gt; 
&lt;p&gt;針對小米汽車出海，盧偉冰稱，先把中國市場做好，小米汽車正在啓動出海相關的準備，汽車出海的複雜度要比小米預期高，2027 年將會是小米汽車出海的元年。&lt;/p&gt; 
&lt;p&gt;小米集團昨天發佈了 2024 年度全年財報，小米 CEO 雷軍稱是「史上最強年報」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1954&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0319/102444_KBrs_2720166.png&quot; width=&quot;1248&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;小米集團第四季度營收 1,090.1 億元，市場預估 1,043.8 億元。全年營收 3,659.1 億元，同比增長 35%，市場預估 3,580.5 億元。&lt;/p&gt; 
&lt;p&gt;第四季度淨利潤 90.0 億元，市場預估 52.5 億元；全年淨利潤 236.6 億元，市場預估 197.6 億元。&lt;/p&gt; 
&lt;p&gt;2024 年智能手機業務收入為 1918 億元，同比增長 21.8%，毛利率達到 12.6%。2024 年全球智能手機出貨量為 168.5 百萬台，同比增長 15.7%。&lt;/p&gt; 
&lt;p&gt;2024 年第四季度，智能電動汽車等創新業務分部總收入為 167 億元，其中，智能電動汽車收入 163 億元，其他相關業務收入 3 億元。2024 年第四季度，智能電動汽車等創新業務分部毛利率為 20.4%。2024 年第四季度，智能電動汽車等創新業務經調整淨虧損 7 億元。2024 年，智能電動汽車等創新業務分部毛利率為 18.5%。2024 年，智能電動汽車等創新業務經調整淨虧損 62 億元。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/339627&quot; target=&quot;news&quot;&gt;小米汽車模型訓練專利公佈，可解決資源消耗較大等技術問題&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339722</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339722</guid>
            <pubDate>Wed, 19 Mar 2025 02:21:31 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英偉達下下一代 AI 芯片架構命名 Feynman</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在英偉達 GTC 2025 大會上，英偉達 CEO 黃仁勳公佈了新一代 AI 芯片 Rubin，預計於 2026 年推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;與此同時，黃仁勳還在一個路線圖 PPT 中宣佈，Rubin 之後的下一代芯片命名 Feynman，將於 2028 年登場。該名稱取自美國著名理論物理學家理查德・費曼（Richard Phillips Feynman，1918 年 5 月 11 日—1988 年 2 月 15 日）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;375&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ee9f5c28da756110855f6347717e7354e68.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;span style=&quot;background-color:#ffffff; color:#8e8e93&quot;&gt;（圖片來源：Artur Widak/Anadolu via Getty Images）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;理查德·費曼是量子計算領域最著名的歷史人物之一，主要從事量子力學的路徑積分表述、量子電動力學、過冷液氦的超流性以及粒子物理學中部分子模型的研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他建立了解決液態氦超流體現象的數學理論。和默裏·蓋爾曼在弱相互作用領域，比如β衰變方面，做了一些奠基性工作。並通過提出高能質子碰撞過程的層子模型，在夸克理論的發展中起了重要作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了芯片之外，英偉達還宣佈推出全新 Spectrum-X Silicon Photonics Ethernet 交換機，可為 AI 工廠實現 3.5 倍的能源節省和 10 倍的彈性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338748/nvidia-vera-rubin-chips&quot; target=&quot;news&quot;&gt;英偉達將下一代 AI 芯片命名為 Rubin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339719/nvidia-gtc-2025-announces-feynman</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339719/nvidia-gtc-2025-announces-feynman</guid>
            <pubDate>Wed, 19 Mar 2025 02:05:31 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>萬字乾貨分享最新 AI 指南：用 LazyLLM 把 Deep Research 做成賽博屠龍刀！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近 OpenAI、Jina、perplexity 等各大廠商紛紛推出了自家的 Deep Research 應用。Deep research 是什麼？為什麼這個應用引起了大家的關注？能不能使用 lazyllm 搭建一個屬於自己的 deep research？帶着這些問題，本文將對 OpenAI 發佈的 Deep Research 進行簡要介紹，並依託於 lazyllm 強大的能力，使用極少代碼量實現一個自己的 deep research。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;什麼是 Deep Research？&lt;/h2&gt; 
&lt;p&gt;Deep Research 是 OpenAI 在 2025.2 月發佈的一種新型的代理（Agent）能力，其被集成在 ChatGPT 中，能夠通過大模型的推理能力和工具調用能力，自主從網絡檢索、整合信息，同時支持讀取用户提供的文件，並通過編寫和執行 Python 代碼來分析數據，通過深度分析數據，對用户的問題進行深度解答，最終輸出專業的長篇報告。&lt;/p&gt; 
&lt;p&gt;隨着現有模型能力的增強，大模型應用逐漸朝着 AI Agent 方向發展，Agentic-RAG 也迅速成為大模型應用落地的一個主要方向，其相比於傳統意義上的 RAG（Naive RAG or Advanced RAG），Agentic rag 能夠分析用户查詢的複雜語義，利用提供的工具集完成複雜多跳的查詢，隨後閲讀查詢內容並彙總後，最終回答用户的問題。agentic rag 無論從回答深度還是廣度，相比之前都有着大幅的提高。Deep Research 本質上是 RAG（檢索增強生成）的衍生物，其查詢範圍不再侷限於本地的知識庫，同時具備了網頁查詢、閲讀的能力。同時隨着推理大模型技術的發展，其性能相比之前的 agentic rag 更是跨越至一個新的 level。DeepResearch 的出現，能夠很大程度節省專業人士查詢資料的時間，與大多數 RAG 系統試圖一步到位地回答問題不同，Deep Research 的核心在於其循環推理機制，通過這種機制，它會持續搜索信息、閲讀相關來源並進行推理，直到找到答案或耗盡 token 預算。&lt;/p&gt; 
&lt;p&gt;以下是使用 OpenAI 的 Deep Research 調研 lazyllm 應用場景的全過程：應用首先會分析用户的問題，隨之進行反問，以更好的理解用户意圖。隨後應用經過分析，會調用自身的搜素工具，從問題的各個角度進行信息蒐集。最後綜合這些信息，輸出專業的長篇報告。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;601&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-52bc63edde7cb5eee0318342422a0939140.png&quot; width=&quot;1148&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ChatGPT DeepResearch 入口）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;849&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-655f160476b5e12f175b569afbd1ab86347.png&quot; width=&quot;1587&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（提問-反問-搜索示意圖）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;841&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b05daa865fcfe3fbe33bfb2a2b546cbbcf2.png&quot; width=&quot;1511&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（信息蒐集完畢，生成專業報告）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;從使用體驗上來説，deep research 給人一種非常靠譜的感覺，用户能夠實時觀察其是如何自主思考並查詢信息的，這一過程往往需要花費 5~10 分鐘，更有甚者可以持續半個小時！這一過程的展現給用户提供了極強的」情緒價值「（與 deepseek 展示思維鏈的作用相似）：安排任務、等待輸出專業的長篇報告，這不是老闆才有的待遇？？？擁有 Deep Research，你就相當於擁有了一位集高效搜索、縝密推理、專業寫作為一體的」賽博員工「，助你成功當上賽博老闆。&lt;/p&gt; 
&lt;p&gt;Deep Research 強大嗎？強大。但通過觀察其輸出的內容，不難發現，大模型一直以來的通病——「幻覺」仍然存在，deepresearch 雖然利用檢索增強生成技術已經儘可能降低了模型幻覺的情況，但其生成的報告中仍然存在一些與事實不符的信息。例如在其生成的內容當中有一段」上海銀行數字人客服「員工」：&lt;strong&gt;上海銀行引入兩位 AI 數字員工（由商湯 LazyLLM 方案支持），在手機 App 等渠道為客户提供交互式服務。&lt;/strong&gt;「，文字後面信誓旦旦的附上了參考鏈接（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sensetime.com%2Fcn%2Fcase-detail%3FcategoryId%3D51134352%23%3A%7E%3Atext%3D%25E8%2590%25BD%25E5%259C%25B0%25E6%2588%2590%25E6%259E%259C&quot; target=&quot;_blank&quot;&gt;https://www.sensetime.com/cn/case-detail?categoryId=51134352#:~:text=%E8%90%BD%E5%9C%B0%E6%88%90%E6%9E%9C&lt;/a&gt; ），打開進去一看，網頁中只是提及了商湯科技與上海銀行合作，並未提及使用 LazyLLM 支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;697&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-286d94e6058d77856a05c8fd679e369af83.png&quot; width=&quot;1044&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（對應網站中並未提及相關信息）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;雖然仍有幻覺，但這並不妨礙 DeepReseach 成為新一代 AI Agent 應用中的佼佼者（拜託，已經很強了~~~)。這麼有趣的應用，少了 LazyLLM 怎麼行？本着」萬物皆可 Lazy「的原則，下面我們從技術層面把 Deep Research 的實現框架進行拆解，並嘗試使用 LazyLLM 復現！GoGoGo！&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;Deep Research 框架介紹&lt;/h2&gt; 
&lt;p&gt;首先我們來構建 Deep Research 這個應用的框架。通過對 Deep Research 的試用可以發現，應用主要分為三個階段：意圖理解與規劃、信息搜索與彙總、專業報告生成。框架示意圖如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;428&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6f6545a4f64d9ff5808cde2f41f3e8e75c2.png&quot; width=&quot;1466&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（deep research 框架示意圖）&lt;/em&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;意圖理解與規劃：在這一階段，Deep Research 會根據用户的輸入分析並理解用户的意圖，期間可能會存在通過反問用户獲取更精確信息的過程。待 DeepResearch 認為獲取到足夠信息後，便會進入下一階段。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;（需要指出的是，OpenAI 的 deep research 並未在這一階段結束後顯式的給出寫作大綱之類的東西。但為了能生成專業的長篇報告，以及方便指導後續的信息搜索，這裏我們認為生成有指導意義的寫作大綱是有必要的。類似 Plan-and-Solve 的思路，先充分規劃，再有效執行）&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;信息搜索與彙總：在這一階段，agent 會依照上一階段的理解，自主得從互聯網上搜索並總結有效信息（其中包含了網頁搜索、網頁瀏覽、文件閲讀等步驟），這一階段其實是 ReactAgent 的設計思路，給 agent 輸入 query，agent 反覆利用所提供的工具自主搜索網頁、閲讀網頁、總結信息並反思，直到任務完成。&lt;/li&gt; 
 &lt;li&gt;上一階段結束後，deepresearch 已經具備了完成寫作的所有知識，結合這些知識，最終生成一個專業的長篇報告。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;使用 LazyLLM 實現 Deep Research&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;u&gt;準備階段&lt;/u&gt;&lt;/h3&gt; 
&lt;p&gt;根據第二部分的框架可知，deep research 的重要組成部分有三：強大的大模型（LLM）、多樣的工具（Tools）以及智能體組件（Agents），巧了麼這不，lazyllm 全都有——現成的 llm 模塊（TrainableModule/OnlineChatModule）、工具註冊模塊（fc_register）和智能體模塊（ReactAgent/PlanAndSolveAgent/ReWOOAgent），妙~~啊~~。本次為了實現「快速復現」的目標，咱們一切從簡，看看實現這個應用到底需要幾行代碼。&lt;/p&gt; 
&lt;p&gt;首先安裝一下 lazyllm 的環境。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install lazyllm
lazyllm install standard&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;大模型：&lt;/h3&gt; 
&lt;p&gt;然後我們從大模型開始吧，本次我們選擇「線上調用模型」的方式，藉助通義千問的模型 API 實現模型的調用功能。假設你已經擁有了自己的 api-key（如果沒有，請訪問&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aliyun.com%2Fproduct%2Fbailian&quot; target=&quot;_blank&quot;&gt;https://www.aliyun.com/product/bailian&lt;/a&gt; 獲取，並做好儲值工作），隨後將 api key 加入至環境變量中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export LAZYLLM_QWEN_API_KEY=&amp;lt;your own api key&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;隨後即可使用 lazyllm 創建大模型模塊聊天啦~&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from lazyllm import OnlineChatModule
&amp;gt;&amp;gt;&amp;gt; llm = OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False)
&amp;gt;&amp;gt;&amp;gt; llm(&quot;hello&quot;)
&#39;Hello! How can I assist you today?&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;工具集（Tools）&lt;/h3&gt; 
&lt;p&gt;巧婦難為無米之炊，To great LazyLLM, It&#39;s also very hard to run deep research without powerful tools. 通過瞭解 AI Agent 的工作原理可知，其本質上是為大模型提供多種多樣的工具，引導大模型主動使用正確的工具完成特定任務，最終實現目標。因此，要實現 deep research，一系列好用的工具集是非常必要的。&lt;/p&gt; 
&lt;p&gt;觀察 OpenAI 的 DeepResearch 以及其他已有應用可以發現，此類應用需要網絡搜索工具、網頁操作工具（瀏覽、解析文件、滑動頁面等）、本地知識庫檢索工具（其實就是 RAG，軟廣：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9-wlmpSbZU40YctoiP2ugQ%3Fmpshare%3D1%26scene%3D1%26srcid%3D0312JOH9wNTxyWzUUvwWPb7r%26sharer_shareinfo%3D20291331b41834b5fdc559ca94396331%26sharer_shareinfo_first%3D20291331b41834b5fdc559ca94396331%23rd&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/9-wlmpSbZU40YctoiP2ugQ?mpshare=1&amp;amp;scene=1&amp;amp;srcid=0312JOH9wNTxyWzUUvwWPb7r&amp;amp;sharer_shareinfo=20291331b41834b5fdc559ca94396331&amp;amp;sharer_shareinfo_first=20291331b41834b5fdc559ca94396331#rd&lt;/a&gt; ）以及一些針對特定場景設計的小工具。此處我們只關注網絡搜索、網頁閲讀以及一些基礎的必要工具（比如反問用户以理解更精確的意圖）。&lt;/p&gt; 
&lt;p&gt;工具其實就是函數，我們創建若干函數，最後使用 lazyllm 的註冊機制將其註冊為工具。舉例説明，下面是使用 lazyllm 提供的谷歌搜索引擎組件編寫的網絡搜索工具 web_search（注：使用 GoogleSearch 需要自行註冊賬號並創建引擎，同樣需要 api key，具體參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprogrammablesearchengine.google.com%2Fabout%2F&quot; target=&quot;_blank&quot;&gt;https://programmablesearchengine.google.com/about/&lt;/a&gt; ）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import os
import json

from lazyllm.tools import fc_register
from lazyllm.tools.tools.google_search import GoogleSearch
from lazyllm import LOG
from dotenv import load_dotenv
load_dotenv()

search_engine = GoogleSearch(os.getenv(&#39;GOOGLE_SEARCH_API_KEY&#39;), os.getenv(&#39;GOOGLE_SEARCH_CX&#39;))

@fc_register(&quot;tool&quot;)
def web_search(query: str) -&amp;gt; str:
    &quot;&quot;&quot;
    使用 google search 搜索與 query 相關的網頁，搜索結果包含每個搜索結果的標題、簡介和鏈接。

    Args:
        query (str): The search query string.
    &quot;&quot;&quot;
    LOG.info(f&quot;[tool - Web Search] Searching the web for query &#39;{query}&#39;...&quot;)
    response = search_engine(query=query, date_restrict=&#39;m1&#39;)
    if response.get(&#39;status_code&#39;) != 200:
        return f&quot;Error: Received status code {response.status_code}&quot;
    search_res = json.loads(response.get(&#39;content&#39;))
    res_str = &quot;&quot;
    cnt = 0
    for item in search_res.get(&#39;items&#39;):
        if cnt &amp;gt;= 5:
            break
        link = item.get(&quot;link&quot;)
        title = item.get(&quot;title&quot;)
        snippet = item.get(&quot;snippet&quot;)
        res_str += f&quot;Title: {title}\nSnippet: {snippet[:50]}...\nURL: {link}\n\n&quot;
        cnt += 1
    return res_str&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;需要注意的是，使用 lazyllm 創建的工具，必須使用@fc_register(&quot;tool&quot;) 進行「註冊」，同時需要在對應函數下方加入必要的註釋，解釋工具的用途以及所需要的入參信息。我們按照同樣的方式創建網頁訪問（visit_url）、反問用户（get_more_info_from_user）的工具：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@fc_register(&quot;tool&quot;)
def visit_url(url: str, encoding: str = None) -&amp;gt; str:
    &quot;&quot;&quot;
    使用這個工具來瀏覽一個網頁的詳細內容，並返回解析後的文本內容。

    Args:
        url (str): The URL of the webpage to visit.
        encoding (str, optional): The encoding of the webpage. If not specified, the encoding will be automatically detected.
    &quot;&quot;&quot;
    import requests
    from bs4 import BeautifulSoup
    from readability import Document
    headers = {
        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (compatible; my-bot/1.0)&quot;
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
    except Exception as e:
        return f&quot;Error: Failed to fetch URL. Exception: {e}&quot;

    if response.status_code != 200:
        return f&quot;Error: Received status code {response.status_code}&quot;

    if encoding:
        response.encoding = encoding
    else:
        response.encoding = response.apparent_encoding or response.encoding

    doc = Document(response.text)
    main_content = doc.summary()
    main_text = BeautifulSoup(main_content, &quot;html.parser&quot;).get_text(separator=&quot;\n&quot;, strip=True)

    return main_text if main_text else &quot;Error: Failed to extract main content.&quot;

@fc_register(&quot;tool&quot;)
def get_more_info_from_user(prompt: str) -&amp;gt; str:
    &quot;&quot;&quot;
    該工具用於反問用户，以獲取更多有效信息。當你認為有必要主動詢問用户時，使用這個工具。

    Args:
        prompt (str): Markdown formatted prompt which contains your understanding of the task, the current state, and a series of questions you want to ask to the user.
    &quot;&quot;&quot;
    LOG.info(&quot;Now I think I need more information from you...&quot;)
    LOG.info(prompt)
    res = input(&quot;Please provide more information: &quot;)
    return res&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這裏我們使用了 readability 和 beautifulsoup 實現了較為簡單的解析網頁功能，後續的調優中，該部分可以進行一定的優化。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;智能體（Agent）&lt;/h3&gt; 
&lt;p&gt;有了工具後，我們便可以嘗試使用 lazyllm 自帶的 agent 模塊進行一些簡單的功能了。本次的 deepresearch 復現過程中，我們主要實現兩種 agent：planner agent（用於第一階段的意圖識別與規劃大綱）和 searcher agent（用於第二階段的信息檢索與總結）&lt;/p&gt; 
&lt;p&gt;lazyllm 提供了一些主流的 agent 模塊供大家使用（參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.lazyllm.ai%2Fzh-cn%2Flatest%2FAPI%2520Reference%2Ftools%2F&quot; target=&quot;_blank&quot;&gt;https://docs.lazyllm.ai/zh-cn/latest/API%20Reference/tools/&lt;/a&gt; ）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ReactAgent&lt;/strong&gt;：React agent 主要包括以下的流程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;思考（Thought）&lt;/strong&gt;: Agent 在收到 query 後，它會先給出下一步要採取的行動；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行動（Action）&lt;/strong&gt;: Agent 會採取並執行一個行動，比如使用工具（或者繼續思考）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;觀察（Observation）&lt;/strong&gt;: Agent 觀察行動的反饋，比如工具的輸出；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;agent 按照「思考-行動-觀察-反思-...」的流程執行任務，直至任務完成；&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;309&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-659a6a829ac241fb4d57086914b3fad7c19.png&quot; width=&quot;719&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ReactAgent 工作示意圖）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PlanAndSolveAgent&lt;/strong&gt;：由兩個組件組成，首先，由 planner 將整個任務分解為更小的子任務，然後由 solver 根據計劃執行這些子任務，主要包括以下的流程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;計劃（Plan）&lt;/strong&gt;：Agent 在收到 query 後，它會將這個任務分解為更小的子任務；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行動（Action）&lt;/strong&gt;: Agent 對當前的子任務進行執行；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;觀察（Observation）&lt;/strong&gt;: Agent 觀察當前行動的結果，如果解決問題就返回，如果僅解決當前子任務就繼續執行計劃，如果沒解決當前子任務就重新計劃後續步驟；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-977a2e3eac430107f645b43005aac39e088.png&quot; width=&quot;729&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（PlanandSolveAgent 工作示意圖）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;ReWOOAgent：包含三個部分：Planner、Worker 和 Solver。其中，Planner 使用可預見推理能力為複雜任務創建解決方案藍圖；Worker 通過工具調用來與環境交互，並將實際證據或觀察結果填充到指令中；Solver 處理所有計劃和證據以制定原始任務或問題的解決方案。ReWOO 的主要流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;計劃（Plan）&lt;/strong&gt;：Agent 在收到 query 後，它會生成一個計劃表，計劃表中包含了這個任務分解的更小子任務，子任務間的執行結果用佔位符表示；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行動（Action）&lt;/strong&gt;: Agent 對每個子任務依次進行執行（調用工具），將結果都填入計劃表的佔位符中；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;解決（Solve）&lt;/strong&gt;: Agent 觀察所有行動的反饋，將結果 response 返回給用户；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1cc6042b48653bf967feb883dfb70208fb.png&quot; width=&quot;729&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ReWOOAgent 工作示意圖）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根據實際需求，僅使用機制最簡單的 ReactAgent，即可滿足兩種 Agent 的創建。我們首先實現具備網絡搜索及網頁瀏覽的 Searcher Agent，這裏 max_retries=20，代表如果 agent 在執行 20 次動作之後還沒有完成任務，則自動退出，以避免陷入死循環。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from lazyllm.tools.agent import ReactAgent
# tools 的定義和實現在此忽略，詳情在前面
searcher_agent = ReactAgent(llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False), tools=[&quot;web_search&quot;, &quot;visit_url&quot;], max_retries=20, return_trace=True)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;一行代碼就可以把 agent 創建出來，是不是很 easy？接下來測試一下效果：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; searcher_agent = ReactAgent(llm=llm, tools=[&quot;web_search&quot;, &quot;visit_url&quot;])
&amp;gt;&amp;gt;&amp;gt; searcher_agent(&quot;what is lazyllm?&quot;)
471166: 2025-03-12 19:58:31 lazyllm INFO: (__main__:9) [tool - Web Search] Searching the web for query &#39;lazyllm&#39;...
471166: 2025-03-12 19:58:40 lazyllm INFO: (__main__:11) [tool - Visit URL] Visiting URL &#39;https://https://www.aibase.com/news/15757&#39;...
&#39;LazyLLM is an open-source, low-code development platform introduced by SenseTime at the 2025 Global Developer Pioneer Conference. It aims to simplify and accelerate the process of building AI applications, allowing developers to create complex and customized multi-agent large model applications with as little as 10 lines of code. This tool lowers the barrier for developing AI applications, making it accessible even to those without extensive coding expertise.\n\nFor more information, you can visit the official announcement [here](https://www.aibase.com/news/15757).&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;效果還可以哈，按照相同的套路，我們把 planner agent 也實現了，其實只是加上一個反問的工具：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;planner_agent = ReactAgent(
        llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
        tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
        max_retries=10,
        return_trace=True
    )&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;經過測試後，我們發現 ReactAgent 實現「反思、搜索、閲讀」這一流程很簡單，但是讓它規劃一個大綱卻無從下手。&lt;/p&gt; 
&lt;p&gt;查看 ReactAgent 的源代碼可以發現，agent 組件中內置了默認的提示詞，這個提示詞只説明瞭「要完成任務」，但沒有説明具體該給出什麼樣子的輸出。於是我們決定繼承 ReactAgent，對其進行改造，使其能夠接受我們自己寫的提示詞！我們創建 class CustomReactAgent：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from typing import List
from lazyllm.tools.agent import ReactAgent
from lazyllm.tools.agent.functionCall import FunctionCall
from lazyllm.module import ModuleBase
from lazyllm import loop
class CustomReactAgent(ReactAgent):
    &quot;&quot;&quot;
    繼承自 lazyllm.tools.agent.ReactAgent
    添加自定義提示詞、agent 流式輸出
    &quot;&quot;&quot;
    #  繼承的目的只是為了自定義提示詞。。。
    def __init__(self, llm, tools: List[str], custom_prompt: str, max_retries: int = 5, return_trace: bool = False, stream: bool = False):
        # 先調用父類的基礎檢查和屬性設置（如果有必要可以直接調用 ModuleBase.__init__）
        ModuleBase.__init__(self, return_trace=return_trace)
        self._max_retries = max_retries
        assert llm and tools, &quot;llm and tools cannot be empty.&quot;
        # 使用自定義的 prompt 來構造 _agent
        self._agent = loop(
            FunctionCall(llm, tools, _prompt=custom_prompt, return_trace=return_trace, stream=stream),
            stop_condition=lambda x: isinstance(x, str),
            count=self._max_retries
        )&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;使用以上自定義 agent 類，結合我們自己設計的 planner、searcher 提示詞，agent 就能按照我們的要求完成意圖理解、生成大綱以及信息蒐集等定製化的工作啦~&lt;/p&gt; 
&lt;p&gt;接下來讓我們複測一下 planner agent 的效果：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; planner_agent = CustomReactAgent(
...     llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
...     tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
...     custom_prompt=TOC_PLAN_INSTRUCTION,
...     max_retries=10,
...     return_trace=True
... )
&amp;gt;&amp;gt;&amp;gt; planner_agent(&quot;寫一篇關於 lazyllm 的調研&quot;)
471166: 2025-03-13 10:22:28 lazyllm INFO: (__main__:9) Now I think I need more information from you...
471166: 2025-03-13 10:22:28 lazyllm INFO: (__main__:10) 您好！為了更好地完成這篇關於 LazyLLM 的調研，請您提供以下信息：
1. LazyLLM 是指什麼？它是一種技術、一個項目還是一種特定的算法或模型？
2. 是否有具體的背景或者使用場景需要涵蓋在報告中？
3. 是否有任何特別關注的方面（例如性能、應用案例、優缺點等）？
4. 報告的目標讀者是誰？這將幫助我們調整內容深度和技術術語的使用。

請提供更多細節，以便我們能更準確地滿足您的需求。感謝您的配合！
Please provide more information: lazyllm 是一個大模型應用框架；我想主要了解一下他的優缺點和應用場景；目標讀者是大模型開發愛好者
471166: 2025-03-13 10:23:28 lazyllm INFO: (__main__:9) [tool - Web Search] Searching the web for query &#39;LazyLLM 大模型應用框架，優缺點，應用場景&#39;...
&#39;Thought: 通過網絡搜索，我已經找到了一些關於 LazyLLM 的信息。根據這些信息，LazyLLM 是由商湯科技推出的一個開源、低代碼的大模型應用開發框架，它能幫助開發者以低至 10 行左右代碼輕鬆構建複雜、定製化的多 Agent 大模型應用。現在我將基於這些信息生成寫作大綱。\n[\n    {\n        &quot;title&quot;: &quot;# LazyLLM 調研報告&quot;,\n        &quot;desc&quot;: &quot;本報告旨在對 LazyLLM 進行深入研究，分析其優缺點，並探討其應用場景。&quot;,\n        &quot;need_know&quot;: &quot;瞭解 LazyLLM 的基本概念、背景和目標讀者。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## LazyLLM 簡介&quot;,\n        &quot;desc&quot;: &quot;介紹 LazyLLM 的定義、特點以及由哪家公司推出的背景。&quot;,\n        &quot;need_know&quot;: &quot;收集有關 LazyLLM 的具體信息，如其功能、使用方法等。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;### LazyLLM 的優勢&quot;,\n        &quot;desc&quot;: &quot;詳細描述 LazyLLM 相比其他類似工具的優點，例如簡化開發過程、降低進入門檻等。&quot;,\n        &quot;need_know&quot;: &quot;找出 LazyLLM 相對於其他工具的獨特之處。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;### LazyLLM 的劣勢&quot;,\n        &quot;desc&quot;: &quot;指出 LazyLLM 可能存在的不足之處，如適用範圍有限或某些特定情況下的性能問題。&quot;,\n        &quot;need_know&quot;: &quot;調查並總結 LazyLLM 在實際應用中遇到的問題。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## 應用場景&quot;,\n        &quot;desc&quot;: &quot;列舉 LazyLLM 可以應用於哪些領域，如自然語言處理、計算機視覺等。&quot;,\n        &quot;need_know&quot;: &quot;尋找 LazyLLM 成功案例及其具體應用實例。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## 總結與展望&quot;,\n        &quot;desc&quot;: &quot;對 LazyLLM 進行全面評價，並對其未來發展提出建議。&quot;,\n        &quot;need_know&quot;: &quot;根據現有資料預測 LazyLLM 的發展趨勢。&quot;\n    }\n]&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到，起初 agent 會根據自己的理解，反問用户以獲取更多消息，這有助於它進行精確的意圖識別。隨後 agent 進行了網絡搜索，以更好的理解任務主題，隨後 agent 結合搜索信息，給出了較為完整的報告大綱，這個大綱既可以指導最後的寫作過程，同時其中的「need_know」更是可以引導 searcher_agent 執行更精確的信息蒐集。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;u&gt;實現完整的 Deep Research&lt;/u&gt;&lt;/h3&gt; 
&lt;p&gt;有了大模型、工具集以及組裝完成的智能體後，接下來到了關鍵時刻——組裝 DeepResearch。瞭解 lazyllm 的小夥伴們肯定知道，得益於強大而精緻的 Flow 組件，在 lazyllm 的世界中，簡單幾行代碼就可以組裝得到一個強大的應用。接下來我們就使用 lazyllm 的 flow 組件組裝我們自己的 deepresearch，完整的代碼如下（其中調用了一些功能函數，詳情見附錄二）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 創建 deepresearch pipeline
def create_deep_research_pipeline():
    # 單次搜索 pipeline
    with lazyllm.pipeline() as s_ppl:
        s_ppl.gen_query = lambda x: f&quot;{x.get(&#39;desc&#39;)}\n{x.get(&#39;need_know&#39;)}&quot;  # 從部分大綱組裝 query
        s_ppl.search_agent = create_search_agent_and_run  # 執行 searcher agent
        s_ppl.gen_output = (lambda x, origin_dict: {**origin_dict, &quot;search_info&quot;: x}) | lazyllm.bind(origin_dict=s_ppl.input)  # 蒐集信息嵌入寫作大綱
    
    with lazyllm.pipeline() as dr_ppl:
        dr_ppl.planner_ins = StreamResponse(prefix=&quot;[Planner] Receive instruction:&quot;, prefix_color=Color.red, color=Color.magenta, stream=True)  # 顯示輸入
        dr_ppl.planner = create_plan_agent()    # planner 執行意圖識別與大綱規劃
        dr_ppl.planner_out = StreamResponse(prefix=&quot;[Planner] ToC Completed:&quot;, prefix_color=Color.red, color=Color.magenta, stream=True)  #  顯示 planner agent 輸出
        dr_ppl.toc_parser = table_of_content_parser  # 提取寫作大綱
        dr_ppl.searcher = lazyllm.warp(lambda x: s_ppl(x)).aslist  # 使用 warp 並行調度 searcher agent 蒐集信息
        dr_ppl.search_parser = lambda x: json.dumps(
            [
                {&quot;title&quot;: item.get(&quot;title&quot;),
                 &quot;desc&quot;: item.get(&quot;desc&quot;),
                 &quot;search_info&quot;: item.get(&quot;search_info&quot;)} for item in x
            ], ensure_ascii=False
            )  # 提取大綱中寫作所需信息
        dr_ppl.gen_report = OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;).prompt(
            lazyllm.ChatPrompter(instruction=REPORT_INSTRUCTION)
        )  # 最終生成報告
    return dr_ppl&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;注：使用 lazyllm 提供的 StreamResponse 可以讓輸出內容變得絢麗多彩哦~&lt;/p&gt; 
&lt;p&gt;代碼解讀：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用 lazyllm.pipeline 分別創建 searcher_agent 信息蒐集管道和 deepresearch 主流程管道；&lt;/li&gt; 
 &lt;li&gt;主流程管道中，首先將用户 query 輸入給 planner_agent，智能體自動執行意圖識別與信息蒐集，並生成報告大綱；&lt;/li&gt; 
 &lt;li&gt;隨後 planner 的輸出內容經過 toc_parser 處理，以提取 json 格式的完整大綱；&lt;/li&gt; 
 &lt;li&gt;利用 lazyllm.warp，將大綱列表中各部分以並行的方式輸入至信息搜索管道，以提高整個流程的執行效率，同時設置 warp 流程結束後同樣以列表的形式輸出給下一節點；&lt;/li&gt; 
 &lt;li&gt;在信息搜索 pipeline 中，首先將輸入的部分大綱中的有效內容提取，以生成 searcher 所需要的有效指令，隨後創建 searcher agent 並執行任務，最後將 searcher agent 的輸出作為新的字段（search info）加入到原部分大綱中；&lt;/li&gt; 
 &lt;li&gt;待所有搜索任務完成後，整理並提取有效字段（標題、描述、搜索信息）形成最終的寫作大綱，並指導大模型最終生成專業的長篇報告。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;數據流示意圖：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;477&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b515a2614f206ee56db8e97cb3e700859b.png&quot; width=&quot;1918&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;最後是運行 deep research 的入口代碼，其中 lazyllm.FileSystemQueue().dequeue() 用於獲取過程中的輸出內容：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import asyncio
from dotenv import load_dotenv

load_dotenv()

import lazyllm
from core.flow.deep_research import create_deep_research_pipeline


async def main():
    deep_research_ppl = create_deep_research_pipeline()
    question = input(&quot;Lazy Deep Research Demo...\nPlease enter your question：\n&quot;)
    all_process = &quot;&quot;
    lazyllm.globals._init_sid()
    with lazyllm.ThreadPoolExecutor(1) as executor:
        future = executor.submit(deep_research_ppl, question)
        while True:
            if value := lazyllm.FileSystemQueue().dequeue():
                print(&quot;&quot;.join(value))
                all_process += &quot;&quot;.join(value)
            elif future.done():
                break
            else:
                await asyncio.sleep(0.3)
        log_filename = f&quot;{question}_all_process.log&quot;
        with open(log_filename, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:
            f.write(all_process)
        print(f&quot;結果已保存至 {log_filename}&quot;)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;完成以上研發，一個嶄新的，基於 lazyllm 的 deepresearch 復現便新鮮出爐了！雖然工具集還有很大的進步空間，但已經能夠實現簡單的搜索、訪問頁面和收集信息了。下面讓我們來測試一下基於 lazyllm 的 deepresearch 的完整效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;效果展示&lt;/h2&gt; 
&lt;p&gt;我們詢問「如何熟練掌握 lazyllm」，詳細輸出如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m core.main
Lazy Deep Research Demo...
Please enter your question：
如何熟練掌握 lazyllm
714495: 2025-03-13 12:55:07 lazyllm INFO: (core.tools.plan_tools:13) Now I think I need more information from you...
714495: 2025-03-13 12:55:07 lazyllm INFO: (core.tools.plan_tools:14) 為了幫助您更好地瞭解如何熟練掌握 lazyllm，我需要一些額外的信息：
- 您提到的 lazyllm 具體是指什麼？它是一種技術、工具、庫還是其他東西？
- 您是希望從零開始學習 lazyllm，還是已經有一定的基礎並希望進一步深入？
- 您希望通過掌握 lazyllm 達到什麼樣的目標或解決什麼問題？
Please provide more information: lazyllm 是一個大模型應用框架；希望能夠掌握落地應用方法
714495: 2025-03-13 12:55:18 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;lazyllm 大模型應用框架&#39;...
714495: 2025-03-13 12:55:25 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:55:32 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:25 lazyllm INFO: (core.tools.utils:29) 報告寫作大綱生成成功：
[{&#39;title&#39;: &#39;# 如何熟練掌握 LazyLLM&#39;, &#39;desc&#39;: &#39;本報告將詳細介紹如何熟練掌握 LazyLLM，包括其基本概念、使用方法和應用場景等內容。&#39;, &#39;need_know&#39;: &#39;瞭解用户對 LazyLLM 的需求和期望，以便更好地指導他們學習和使用。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 簡介&#39;, &#39;desc&#39;: &#39;介紹 LazyLLM 的基本情況，如其定義、特點和發展歷程等。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的具體定義、特點和發展歷程。&#39;}, {&#39;title&#39;: &#39;### LazyLLM 的功能與優勢&#39;, &#39;desc&#39;: &#39;詳細描述 LazyLLM 的功能和優勢，如低代碼、快速部署和支持多種數據流抽象等。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的所有功能及其具體實現方式；與其他類似工具相比的優勢。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的安裝與配置&#39;, &#39;desc&#39;: &#39;講解如何安裝和配置 LazyLLM，確保用户能夠在自己的環境中順利運行該框架。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的安裝步驟和配置要求；可能遇到的問題及解決方案。&#39;}, {&#39;title&#39;: &#39;### 環境準備&#39;, &#39;desc&#39;: &#39;列出安裝 LazyLLM 前需要準備的工作，如環境搭建、依賴項安裝等。&#39;, &#39;need_know&#39;: &#39;安裝 LazyLLM 所需的系統環境和其他依賴項。&#39;}, {&#39;title&#39;: &#39;### 安裝過程&#39;, &#39;desc&#39;: &#39;提供詳細的安裝步驟，讓用户可以按照指示完成安裝。&#39;, &#39;need_know&#39;: &#39;具體的安裝命令和操作流程；可能出現的錯誤提示及解決辦法。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的應用場景&#39;, &#39;desc&#39;: &#39;探討 LazyLLM 在實際項目中的應用場景，幫助用户理解其適用範圍。&#39;, &#39;need_know&#39;: &#39;LazyLLM 已有的成功案例；不同領域的潛在應用場景。&#39;}, {&#39;title&#39;: &#39;### 成功案例分析&#39;, &#39;desc&#39;: &#39;選取幾個典型的成功案例進行分析，展示 LazyLLM 的實際效果。&#39;, &#39;need_know&#39;: &#39;具體的成功案例及其實施過程；這些案例帶來的收益或改進。&#39;}, {&#39;title&#39;: &#39;### 潛在應用場景&#39;, &#39;desc&#39;: &#39;預測 LazyLLM 在未來可能的應用領域，激發用户的創造力。&#39;, &#39;need_know&#39;: &#39;當前市場上對於此類工具的需求趨勢；未被髮掘但具有潛力的應用方向。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的最佳實踐&#39;, &#39;desc&#39;: &#39;分享一些使用 LazyLLM 時的最佳實踐，提高用户的開發效率。&#39;, &#39;need_know&#39;: &#39;使用 LazyLLM 時的經驗總結；常見的誤區和避免方法。&#39;}, {&#39;title&#39;: &#39;### 開發技巧&#39;, &#39;desc&#39;: &#39;介紹一些有助於提高開發效率的小技巧，如代碼優化、調試技巧等。&#39;, &#39;need_know&#39;: &#39;使用 LazyLLM 編寫高效代碼的方法；常見問題的排查技巧。&#39;}, {&#39;title&#39;: &#39;### 性能調優&#39;, &#39;desc&#39;: &#39;講解如何對基於 LazyLLM 的應用程序進行性能調優，以獲得更好的運行效果。&#39;, &#39;need_know&#39;: &#39;影響應用程序性能的因素；具體的調優策略和技術手段。&#39;}, {&#39;title&#39;: &#39;# 總結與展望&#39;, &#39;desc&#39;: &#39;對全文進行總結，並對未來的發展趨勢做出預測。&#39;, &#39;need_know&#39;: &#39;回顧本文的重點內容；根據現有技術和市場需求預測 LazyLLM 未來的發展方向。&#39;}]
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 定義，特點，發展歷程&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，實施過程，收益，改進&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;什麼是 LazyLLM 功能&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 功能，優勢&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;如何安裝和配置 LazyLLM 框架&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM best practices, common pitfalls and avoidance methods&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;安裝 LazyLLM 前需要準備的工作，環境搭建，依賴項安裝&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;提高開發效率的小技巧，代碼優化，調試技巧，使用 LazyLLM 編寫高效代碼的方法，常見問題的排查技巧&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 基本概念，使用方法，應用場景&#39;...
714495: 2025-03-13 12:56:31 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM performance optimization strategies and techniques&#39;...
714495: 2025-03-13 12:56:31 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 應用領域，創造力，需求趨勢，未被髮掘，潛力&#39;...
714495: 2025-03-13 12:56:33 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，應用場景&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;大模型應用開發框架，需求趨勢，未來，應用方向&#39;...
714495: 2025-03-13 12:56:38 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 功能，實現方式&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:44 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:44 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/sensetime/LazyLLM&#39;...
714495: 2025-03-13 12:56:49 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:50 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/LazyAGI/LazyLLM&#39;...
714495: 2025-03-13 12:56:50 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;代碼優化，調試技巧，常見問題排查技巧&#39;...
714495: 2025-03-13 12:57:01 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;提高開發效率的技巧，代碼優化，調試技巧，常見問題排查技巧&#39;...
714495: 2025-03-13 12:57:02 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，實施過程，收益，改進，應用場景&#39;...
714495: 2025-03-13 12:57:07 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stcn.com/article/detail/1535042.html&#39;...
714495: 2025-03-13 12:57:12 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;http://news.pconline.com.cn/1888/18880280.html&#39;...
714495: 2025-03-13 12:57:19 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;軟件開發，提高效率的小技巧，代碼優化，調試技巧，常見問題排查技巧&#39;...
714495: 2025-03-13 12:57:31 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stdaily.com/web/gdxw/2025-02/24/content_300493.html&#39;...
714495: 2025-03-13 12:57:44 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;軟件開發效率提升方法，代碼優化，調試技巧，常見問題排查技巧&#39;...
714495: 2025-03-13 12:58:01 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.jfdaily.com/news/detail?id=861805&#39;...
714495: 2025-03-13 12:58:08 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:58:18 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;軟件開發，提高效率的方法，代碼優化，調試技巧，常見問題排查技巧&#39;...
714495: 2025-03-13 12:58:18 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/LazyAGI/LazyLLM&#39;...
714495: 2025-03-13 12:58:31 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stdaily.com/web/gdxw/2025-02/24/content_300493.html&#39;...
結果： # 如何熟練掌握 LazyLLM

## LazyLLM 簡介

LazyLLM 是由商湯科技在 2025 全球開發者先鋒大會上推出的一個開源、低代碼的大模型應用開發框架。其設計目標是讓開發者能夠以低至 10 行左右的代碼構建複雜、定製化的多 Agent 大模型應用。此外，LazyLLM 已經在 GitHub 上開源，開發者可以訪問該項目的官方頁面進行學習和使用。

### LazyLLM 的功能與優勢

LazyLLM 是一個功能強大且易於使用的工具，具有以下主要特點和優勢：

- **低代碼開發**：LazyLLM 允許開發者使用大約 10 行代碼構建複雜且定製化的多 Agent 大模型應用。這意味着即使是沒有深厚編程背景的人也可以輕鬆上手。
  
- **快速部署**：通過利用輕量網關，LazyLLM 實現了複雜應用的一鍵部署，大大縮短了從開發到上線的時間週期。
  
- **支持多種數據流抽象**：LazyLLM 以數據為核心，支持在應用開發過程中持續迭代數據，從而不斷提升數據效果。這一特性使得開發者能夠更容易地處理和優化不同類型的數據流。

與其他類似工具相比，LazyLLM 的優勢在於其極簡主義的設計理念，即用最少的代碼實現最強大的功能，同時保持高度的靈活性和可擴展性。此外，作為一個開源項目，LazyLLM 還擁有活躍的社區支持，有助於加速創新和技術進步。

## LazyLLM 的安裝與配置

為了確保用户能夠在自己的環境中順利運行 LazyLLM 框架，以下是詳細的安裝步驟和配置要求：

### 環境準備

1. **環境搭建**：
   - LazyLLM 支持跨平台兼容，可以在裸金屬服務器、開發機、Slurm 集羣、公共雲等平台上運行。因此，在安裝之前，請確保你已經選擇並配置好了相應的計算平台。

2. **依賴項安裝**：
   - 如果你是從源代碼安裝 LazyLLM，你需要先克隆倉庫並進入項目目錄：
     ```bash
     git clone git@github.com:LazyAGI/LazyLLM.git
     cd LazyLLM
     ```
     然後根據需求安裝依賴項。如果你只需要安裝 LazyLLM 及其必要依賴，可以使用以下命令：
     ```bash
     pip install -r requirements.txt
     ```
     如果你還想進行微調、部署或構建 RAG 應用，則還需要安裝額外的依賴項：
     ```bash
     pip install -r requirements.full.txt
     ```

   - 如果你是通過 pip 安裝 LazyLLM，你可以選擇只安裝 LazyLLM 及其必要依賴：
     ```bash
     pip3 install lazyllm
     ```
     或者安裝 LazyLLM 以及所有依賴項：
     ```bash
     pip3 install lazyllm[lazyllm install full]
     ```

3. **配置 API 密鑰（如需）**：
   - 對於某些功能（例如與在線服務交互），可能需要設置環境變量或配置文件來提供必要的 API 密鑰。例如，對於 ChatBots 示例中提到的 OpenAI API Key，可以通過設置環境變量`LAZYLLM_OPENAI_API_KEY=xx`或在配置文件`~/.lazyllm/config.json`中添加`openai_api_key=xx`來實現。

4. **準備數據集（如需）**：
   - 如果你要使用 LazyLLM 構建基於檢索增強生成的應用程序（如 RAG），則需要準備好相應的數據集，並確保數據路徑正確無誤。例如，在本地部署示例中，你需要指定數據集路徑為`/file/to/yourpath`。

5. **瞭解基本概念和組件**：
   - 在開始構建應用程序之前，建議先熟悉 LazyLLM 的基本概念，包括組件 (Component)、模塊 (Module)、流程 (Flow) 等，以便更好地利用其提供的工具和接口。

### 安裝過程

1. **環境準備**：首先，你需要確保你的計算機已經安裝了 Python，並且最好是在一個虛擬環境中工作以避免與其他項目產生衝突。你可以使用如`venv`或`conda`等工具創建一個獨立的 Python 環境。
   
2. **安裝依賴庫**：根據 LazyLLM 的具體需求，你可能需要安裝一些額外的 Python 包。這通常可以通過 pip 命令完成，例如`pip install -r requirements.txt`，其中`requirements.txt`文件列出了所有必要的依賴項。

3. **下載並安裝 LazyLLM**：訪問[LazyLLM 的 GitHub 頁面](https://github.com/sensei-research/LazyLLM) 獲取最新的源代碼或直接通過 pip 安裝最新版本（如果已發佈）。

4. **配置環境變量**：某些情況下，你可能還需要設置特定的環境變量，以便 LazyLLM 能夠正確連接到外部服務或者存儲系統。

5. **初始化項目結構**：按照官方文檔中的指導，創建一個新的項目目錄，並初始化基本的項目結構。這一步驟可能會涉及到複製模板文件夾、修改配置文件等操作。

6. **編寫業務邏輯代碼**：利用 LazyLLM 提供的 API 接口快速實現核心功能。由於這是一個低代碼平台，大部分工作都可以通過簡單的函數調用來完成。

7. **測試與調試**：完成初步編碼後，應該進行全面的單元測試和集成測試，確保一切按預期工作。同時也可以藉助 IDE 中的調試工具排查可能出現的問題。

8. **部署上線**：最後一步就是將開發好的應用部署到生產環境。得益於 LazyLLM 內置的一鍵部署特性，這一步相對來説比較簡單快捷。

關於可能遇到的問題及解決方案：
- 如果在安裝過程中遇到問題，請檢查 Python 版本是否符合要求，並確認所有的依賴項都已經正確安裝。
- 對於網絡連接失敗的情況，可以嘗試更換鏡像源或是離線安裝所需的軟件包。
- 如果發現性能瓶頸，考慮優化算法或增加硬件資源。
- 當遇到特定功能無法正常工作時，查閲官方文檔和技術支持論壇，很多時候其他用户也會遇到類似的問題，官方社區往往能提供有效的幫助。

## LazyLLM 的應用場景

儘管沒有找到具體的 LazyLLM 成功案例，但我們可以根據其特點推測其在不同領域的潛在應用場景：

1. **教育**：LazyLLM 可以幫助教育機構和教師快速開發個性化學習助手，為學生提供定製化學習路徑和實時答疑服務。
2. **醫療**：在醫療領域，LazyLLM 可以用於開發智能診斷助手，幫助醫生分析病歷、診斷疾病並提供治療建議。
3. **金融**：LazyLLM 可以助力金融機構開發智能客服系統，為客户提供 24/7 全天候服務，解答常見問題並處理簡單業務。
4. **零售**：通過 LazyLLM，零售商可以創建智能推薦系統，根據用户的歷史購買記錄和瀏覽行為推薦相關產品。
5. **遊戲**：遊戲開發者可以利用 LazyLLM 創建更智能的 NPC（非玩家角色），提高遊戲的互動性和趣味性。

以上只是一些可能的應用場景，實際上 LazyLLM 可以在任何需要大模型能力的領域發揮作用。由於其低代碼特性，即使不具備熟練編碼能力的人也能完成 AI 應用開發，這大大降低了大模型應用開發的門檻。

### 成功案例分析

#### 案例一：智能客服系統的快速開發
- **實施過程**：某企業利用 LazyLLM 快速開發了一款智能客服系統，將原本需要數週時間完成的工作縮短至幾天內完成。
- **收益或改進**：這不僅加快了開發速度，還降低了開發成本，使得企業能夠更迅速地響應市場需求。

#### 案例二：醫療數據的自動化分析
- **實施過程**：一家醫療科技公司通過 LazyLLM 實現了病歷數據的自動化分析和處理。
- **收益或改進**：大幅提升了工作效率並減少了人工幹預，使醫生和護士能夠專注於更重要的臨牀工作。

### 總結
LazyLLM 極大地簡化了 AI 應用的開發流程，使得不具備熟練編碼能力的人也能完成複雜的 AI 應用開發。它支持多種數據流操作（如 Pipeline、Parallel、Switch 等），從而提升了開發效率並減少了代碼量。對於企業來説，這意味着更快的產品迭代速度以及更低的研發成本。

### 潛在應用場景

未來可能的應用領域包括教育、醫療、農業和環保等領域，激發用户的創造力。當前市場上對於此類工具的需求趨勢主要體現在低代碼化、開源化和數據為核心等方面。

未被髮掘但具有潛力的應用方向可能包括：
1. **教育領域**：為學生和教師提供個性化的學習和教學助手。
2. **醫療領域**：幫助醫生和研究人員分析病歷、診斷疾病和發現新藥。
3. **農業領域**：優化農作物種植、預測天氣和提高產量。
4. **環保領域**：監測環境變化、評估污染影響和制定可持續發展策略。

## LazyLLM 的最佳實踐

分享一些使用 LazyLLM 時的最佳實踐，提高用户的開發效率：

- **簡化編碼**：LazyLLM 旨在通過減少所需的代碼量來加速開發過程。這意味着您可以專注於設計應用程序的功能，而不是花費大量時間編寫底層代碼。
- **數據為核心**：LazyLLM 支持在應用開發過程中持續迭代數據，從而不斷提升數據效果。因此，在開發初期就應該重視數據集的設計與準備。
- **利用現有組件**：LazyLLM 提供了 Pipeline, Parallel, Switch, If, Loop, Diverter, Warp, Graph 等組件，可以直接使用或組合這些組件快速搭建應用程序邏輯，無需從零開始創建所有功能。
- **一鍵部署**：該框架允許開發者輕鬆地將他們的應用程序部署到雲端或其他環境中，這大大簡化了發佈流程。
- **社區支持**：由於 LazyLLM 已經在 GitHub 上開源，您可以在[GitHub](https://github.com/LazyAGI/LazyLLM) 和 [官方文檔](docs.lazyllm.ai) 中找到豐富的資源和支持，包括教程、案例研究和其他開發者的貢獻。

至於常見的誤區和避免方法：
- **過度依賴默認設置**：雖然 LazyLLM 提供了一些預設配置，但為了獲得最佳性能，建議根據具體需求調整參數。
- **忽視版本更新**：隨着技術的進步，框架會不斷改進和完善。確保定期檢查是否有新的版本發佈，並及時升級以享受最新的特性和修復。
- **缺乏測試**：儘管 LazyLLM 簡化了開發步驟，但仍需對生成的應用程序進行全面測試，特別是對於涉及多個代理（Agents）協作的任務，確保它們能夠按照預期工作。
- **忽略安全性**：即使是在簡化環境下開發，也不應放鬆對安全性的要求。遵循最佳的安全實踐，比如保護 API 密鑰和個人敏感信息。

### 開發技巧

介紹一些有助於提高開發效率的小技巧，如代碼優化、調試技巧等。

#### 使用 LazyLLM 編寫高效代碼的方法

1. **低代碼開發**：LazyLLM 是一個開源、低代碼的大模型應用開發框架。開發者只需編寫少量代碼（如 10 行左右），即可構建複雜的多 Agent 大模型應用。這使得不具備熟練編碼能力的人也能完成 AI 應用開發。
2. **快速部署**：LazyLLM 利用輕量網關實現了複雜應用的一鍵部署，使開發者能夠更快地實現想法產品落地。
3. **數據迭代支持**：該框架專注於數據為核心，支持在應用開發過程中持續迭代數據，從而不斷提升數據效果。

#### 提高開發效率的小技巧

##### 代碼優化
- **減少冗餘代碼**：避免重複代碼，儘量複用已有的函數或模塊，保持代碼簡潔。
- **性能優化**：使用高效的算法和數據結構，減少不必要的計算，優化內存使用。
- **自動化測試**：編寫單元測試和集成測試，確保代碼質量的同時加快開發進度。

##### 調試技巧
- **日誌記錄**：合理設置日誌級別，記錄關鍵操作和異常信息，便於後續排查問題。
- **斷點調試**：使用 IDE 中的斷點調試功能，逐步執行代碼，檢查變量值和程序邏輯。
- **版本控制**：使用 Git 等版本控制系統管理代碼變更，方便回滾和協作開發。

##### 常見問題排查技巧
- **錯誤堆棧分析**：當遇到異常時，仔細閲讀錯誤堆棧信息，定位具體出錯位置。
- **環境配置檢查**：確保開發環境與生產環境一致，避免因環境差異導致的問題。
- **社區資源利用**：積極查閲官方文檔、論壇和 GitHub Issues，尋找類似問題的解決方案。

### 性能調優

講解如何對基於 LazyLLM 的應用程序進行性能調優，以獲得更好的運行效果。

1. **快速原型設計與迭代優化**：LazyLLM 強調「快速原型設計，使用特定場景的數據分析不良案例，算法實驗以及在關鍵方面微調模型以提高整體應用性能。」這意味着開發者應該儘快建立一個初始版本的應用，並根據實際使用中的反饋不斷改進和優化。
2. **自動超參數搜索**：LazyLLM 支持網格搜索參數優化功能，可以自動嘗試不同的基礎模型、檢索策略和微調參數來評估和優化應用程序。這使得超參數調整變得高效，而無需對應用代碼進行大量侵入性修改，幫助用户快速找到最佳配置。
3. **高效的模型微調**：LazyLLM 允許在應用內微調模型，以持續改進應用性能。它能夠根據微調場景自動選擇最適合的微調框架和模型分割策略。這不僅簡化了模型迭代維護工作，還讓算法研究人員可以更多地專注於算法和數據迭代，而不是處理繁瑣的工程任務。
4. **一鍵部署複雜應用**：LazyLLM 提供了一鍵式部署所有模塊的能力，在 POC（概念驗證）階段通過輕量級網關機制簡化多代理應用的部署過程。這樣解決了依次啓動每個子模塊服務（如 LLM、Embedding 等）並配置 URL 的問題，使整個過程更加順暢高效。此外，在應用發佈階段，LazyLLM 還提供了一鍵打包鏡像的功能，便於利用 Kubernetes 的網關、負載均衡及容錯能力。
5. **跨平台兼容性**：LazyLLM 可以在不修改代碼的情況下一鍵切換 IaaS 平台，兼容裸金屬服務器、開發機、Slurm 集羣、公有云等多種環境。這允許已開發的應用程序無縫遷移到其他 IaaS 平台，大大減少了代碼修改的工作量。
6. **支持常見的 RAG 組件**：LazyLLM 集成了文檔、解析器、檢索器、重排序器等常見 RAG（檢索增強生成）組件。這些組件可以幫助構建更強大的 AI 應用，尤其是在需要從大量文本中提取有用信息時非常有用。

綜上所述，通過上述方法，我們可以針對基於 LazyLLM 的應用程序進行有效的性能調優，從而提升其運行效果。

## 總結與展望

LazyLLM 是由商湯科技在 2025 全球開發者先鋒大會上發佈的一個開源、低代碼的大模型應用開發框架。它能讓開發者以低至 10 行左右的代碼構建複雜、定製化的多 Agent 大模型應用，從而降低 AI 應用開發的門檻，使不具備熟練編碼能力的人也能完成 AI 應用開發。此外，LazyLLM 還利用輕量網關實現了複雜應用的一鍵部署，使開發者能夠更快地將應用推向市場。

隨着人工智能技術的不斷發展和市場需求的增長，預計 LazyLLM 未來將在以下幾個方面取得進展：

1. **更加簡便易用**：為了吸引更多的開發者使用 LazyLLM 進行 AI 應用開發，商湯科技可能會繼續優化該框架，使其更加簡便易用，進一步降低開發門檻。
2. **提升性能與穩定性**：隨着更多開發者使用 LazyLLM，商湯科技可能會收集用户反饋，不斷改進框架的性能與穩定性，確保用户能夠順利地構建高質量的 AI 應用。
3. **拓展應用場景**：目前，LazyLLM 主要用於構建多 Agent 大模型應用。然而，隨着技術的發展和市場需求的變化，LazyLLM 可能會被應用於更多的場景，如自然語言處理、計算機視覺等。
4. **社區建設**：作為一個開源項目，LazyLLM 有望吸引更多的開發者加入其社區，共同為項目的完善和發展做出貢獻。這將有助於推動 LazyLLM 成為更受歡迎的 AI 應用開發框架。&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們可以看到，通過使用 lazyllm 快速復現的 deepresearch，已經具備了通過自身思考並主動使用工具，經過若干分鐘的」工作「給出專業長篇報告的能力。至此，基於 lazyllm 的快速複習宣告成功~&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;總結與展望&lt;/h2&gt; 
&lt;p&gt;仔細盤點一下，這次復現的耗時只有大概半天，工程代碼量只在一百多行（如果只關注 deep research 的主流程，排除一些通用工具編寫的話，甚至只有不到 15 行嘿嘿嘿~~~），效率這塊兒屬實是被 lazyllm 拿捏了~&lt;/p&gt; 
&lt;p&gt;但這僅僅是較為簡單版本的 deep research，一個」滿血版「的 Deep Research 還需要具備解析文件、調用本地知識庫、精細化操作網絡頁面等等的能力，與先前開發工具的思路相同，這些也都需要我們通過工具研發提供給智能體，以豐富智能體的」武器庫「。&lt;/p&gt; 
&lt;p&gt;大模型應用正在飛速迭代，這必然給大家帶來了一定恐慌，在這個時代，能夠有效拆解並快速復現這些應用的能力越來越重要。而使用 lazyllm，我們能夠在短時間內快速復現一個如此強大的應用，對於廣大大模型愛好者來説是一件非常激動人心的事情！你是否也有些手癢癢了呢？心動不如行動，趕緊動起來吧~我也要去開發更多的強力工具，賦能專屬於自己的 deep research 咯~&lt;/p&gt; 
&lt;p&gt;友情提示：agent 工作是一個相當消耗 token 的過程，如果你和我一樣使用了第三方的 llm api-key，調試和使用期間要盯緊自己的錢包哦~&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;附錄一，提示詞設計&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# planner agent prompt
TOC_PLAN_INSTRUCTION = &quot;&quot;&quot;# 定位
- 你是一個全面的寫作專家，擅長根據給定的主題主動收集資料，並給出高質量的、具有完整報告結構的寫作大綱。
- 主要任務：用户給定了寫作主題，請針對給定主題，使用工具集主動收集信息、分析用户意圖，最後結合有效信息生成專業報告寫作大綱。
- 寫作大綱用於指導後續調研工作和報告寫作工作。

# 工具
- 為了幫助你高質量完成給定的任務，我們為你提供了一些有用的工具。請充分使用這些工具來獲取所需的信息。
- 注意：在任務開始階段，一定要使用&#39;get_more_info_from_user&#39;工具邀請用户提供更多信息。
- 如果寫作主題很複雜，你可以將其拆分為若干 sub_topic，並通過調用最合適的工具瞭解它們。
- 請主動使用&#39;visit_url&#39;工具瀏覽相關網頁，瀏覽相關網頁可以幫你獲取更多有效信息。

# 輸出格式
- 請使用和用户輸入相同的語言執行任務。
- 你的任務分為兩個階段：信息收集階段、生成大綱階段。
- 在信息收集階段，請嚴格遵循「Thought: 思考內容」的格式：
Thought: 思考當前任務所處於的狀態，規劃接下來需要做什麼。
- 每次輸出時，在開頭輸出且僅輸出一次 Thought，無論你是否決定使用工具。
- 如果你認為你獲取的信息不足以很好的生成大綱，請始終遵循「Thought」的格式，直到獲取到足夠的信息後，再生成大綱。
- 當你認為你已經收集到足夠的信息，請嚴格遵循 JSON 格式生成寫作大綱。生成大綱階段，不要輸出「Thought」。
- 大綱的每一部分應包含「title」、「desc」、「need_know」兩部分：
title: 當前部分的標題，標題最多達到三級標題。
desc: 描述當前部分希望呈現的內容，需要始終緊扣原主題和當前主題。
need_know: 用於指導員工調研相關內容，以便更好的完成該部分寫作，需要始終緊扣原主題和當前主題。
大綱應按照「總-分-總」的邏輯結構生成，首先是概述部分，隨後將寫作主題拆解成若干部分，最後給出總結與展望。
請生成符合以下格式的 JSON 列表：
[
    {
        &quot;title&quot;: &quot;# 一級標題（報告總標題）&quot;,
        &quot;desc&quot;: &quot;一級標題的描述&quot;,
        &quot;need_know&quot;: &quot;完成該部分需要了解的內容。&quot;
    },
    {
        &quot;title&quot;: &quot;## 二級標題&quot;,
        &quot;desc&quot;: &quot;二級標題的描述&quot;,
        &quot;need_know&quot;: &quot;完成該部分需要了解的內容。&quot;
    },
    {
        &quot;title&quot;: &quot;### 三級標題&quot;,
        &quot;desc&quot;: &quot;三級標題的描述&quot;,
        &quot;need_know&quot;: &quot;完成該部分需要了解的內容。&quot;
    },
    ...
]

# 當前對話
以下是當前用户和智能助手的對話內容。
Think step by step.
請務必好好完成本次工作！&quot;&quot;&quot;


# searcher agent prompt
WEB_SEARCH_INSTRUCTION = f&quot;&quot;&quot;# 定位
- 你是一個互聯網打工人，擅長根據給定的主題搜索資料、總結信息並給出高質量的彙報。
- 主要任務：今天是{get_today_date()}，你的老闆給你發佈了任務，請針對給定的問題，使用工具集中的工具搜索相關信息，最後結合搜索結果給出全面的回答。

# 工具
- 為了幫助你高質量完成給定的任務，我們為你提供了一些有用的工具。請充分使用這些工具來獲取所需的信息。
- 如果問題很複雜，你可以將問題拆分為若干子問題，並通過調用最合適的工具解決它們。
- 如果你覺得本次搜索結果不復合需求，嘗試換個角度再次搜索。
- 請主動使用&#39;visit_url&#39;工具瀏覽相關網頁，瀏覽相關網頁可以幫你獲取更多有效信息。
- 如果網站 url 是文件鏈接，請不要訪問，直接無視。

# 輸出格式
- 請使用和問題相同的語言回答問題，在任務開始階段，請嚴格遵循「Thought」的格式：
Thought: 思考當前任務所處於的狀態，規劃接下來需要做什麼。
- 每次輸出時，在開頭輸出且僅輸出一次 Thought，無論你是否決定使用工具。
- 如果你認為你獲取的信息不足以很好的回答問題，請始終遵循「Thought」的格式，知道獲取到足夠的信息後，再回答問題。
- 當你認為你已經收集到足夠的信息，請嚴格遵循「Answer」的格式回答問題，在回答中如果引用了搜索結果，請將相關鏈接以 markdown 的形式直接插入到正文當中，具體格式為「[網頁標題](網頁 url)」。
Answer: 使用相同語言完整地回答問題。

# 當前對話
以下是當前用户和智能助手的對話內容。
Think step by step.
你的老闆很器重你，請務必好好完成本次工作！&quot;&quot;&quot;


# generate report prompt
REPORT_INSTRUCTION = &quot;&quot;&quot;# 定位
- 你是一個寫作專家，擅長根據給定的寫作大綱寫出高質量的報告。
- 主要任務：根據寫作大綱，結合標題、描述以及調研結果為用户書寫專業的報告。

# 要求
- 請確保報告結構嚴謹、用詞專業、表達通順，報告內容請儘可能參考調研結果，不要使用你的先驗知識。
- 如果你覺得提供的標題不夠專業，可以進行潤色。
- 報告中的每一部分字數控制在 400~800 字，不要太少。
- 請嚴格按照大綱結構完成寫作，寫作大綱是 JSON 格式的，其中包含三個字段：
title: 該部分主題
desc: 描述該部分想要表達的內容
search_info: 與該部分相關的調研結果

# 輸出格式
- 請使用和用户輸入相同的語言執行任務，直接生成 Markdown 格式的報告全文。

# 寫作大綱&quot;&quot;&quot;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;附錄二，功能函數&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 獲取今天的日期
def get_today_date():
    &quot;&quot;&quot;
    獲取今天的日期
    Returns:
        str: 當前日期，格式為&quot;YYYY-MM-DD&quot;
    &quot;&quot;&quot;
    today = datetime.date.today()
    return today.strftime(&quot;%Y-%m-%d&quot;)

# 提取 planner agent 生成的寫作大綱
def table_of_content_parser(text: str) -&amp;gt; list:
    try:
        # 找到第一個 &#39;[&#39; 和最後一個 &#39;]&#39; 的索引
        start_index = text.find(&#39;[&#39;)
        end_index = text.rfind(&#39;]&#39;)
        if start_index == -1 or end_index == -1:
            # 沒有找到有效的 JSON 結構，返回空列表
            return []
        json_str = text[start_index:end_index+1]
        # 嘗試解析 JSON
        data = json.loads(json_str)
        LOG.info(f&quot;報告寫作大綱生成成功：\n{data}&quot;)
        return data
    except Exception as e:
        # 如果解析出錯，輸出錯誤信息並返回空列表
        print(&quot;解析 JSON 出錯:&quot;, e)
        raise e

#  創建 planner agent
def create_plan_agent() -&amp;gt; CustomReactAgent:
    agent = CustomReactAgent(
        llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
        tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
        custom_prompt=TOC_PLAN_INSTRUCTION,
        max_retries=10,
        return_trace=True,
        stream=True
    )
    return agent

# 創建 searcher agent 並蒐集信息
def create_search_agent_and_run(query: str) -&amp;gt; str:
    try:
        with lazyllm.pipeline() as ppl:
            ppl.receive = StreamResponse(&#39;[Searcher] Received query:&#39;, prefix_color=Color.red,
                                         color=Color.magenta, stream=True)
            ppl.run_search = CustomReactAgent(
                llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
                tools=[&quot;web_search&quot;, &quot;visit_url&quot;],
                custom_prompt=WEB_SEARCH_INSTRUCTION,
                max_retries=20,
                return_trace=True,
                stream=True
            )
            ppl.search_result = StreamResponse(&#39;[Searcher] Search result:&#39;, prefix_color=Color.red,
                                         color=Color.magenta, stream=True)
        return ppl(query)
    except Exception as e:
        LOG.error(f&quot;[Search agent] Error occurred: {e}&quot;)
        return &quot;搜索中斷，未找到相關信息&quot;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;參考資料&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;OpenAI（2025）- deep-research-system-card&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D2mSNIX-l_Zc&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/watch?v=2mSNIX-l_Zc&lt;/a&gt; - Open Deep Research from LangChain&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F23746178273&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/23746178273&lt;/a&gt; - [知乎] OpenAI Deep Research 是什麼？如何使用？你想知道的都在這兒！&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.lazyllm.ai%2Fzh-cn%2Flatest%2F&quot; target=&quot;_blank&quot;&gt;https://docs.lazyllm.ai/zh-cn/latest/&lt;/a&gt; - LazyLLM 官方文檔&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;如有疑問，請移步「LazyLLM」gzh~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/8690838/blog/17938821</link>
            <guid isPermaLink="false">https://my.oschina.net/u/8690838/blog/17938821</guid>
            <pubDate>Wed, 19 Mar 2025 01:53:31 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>拼多多上線用户和商家視頻通話功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbjXsabyYPkkNl12e9XFk6g&quot; target=&quot;_blank&quot;&gt;據電商派 Pro 昨日報道&lt;/a&gt;，拼多多面向用户和商家上線了視頻通話功能，方便進行產品使用講解。商家只需登錄商家後台，在多多客服功能中找到客服工具，即可開通語音通話服務。&lt;/p&gt; 
&lt;p&gt;商家需選擇語音通話賬號，設置可視頻接待的賬號，點擊下一步後，再選擇是否在 23:00 至次日 8:00 期間接聽，最後點擊確認即可完成設置。&lt;/p&gt; 
&lt;p&gt;開通該功能後，商家在與消費者的聊天界面中可以向消費者發送「視頻講解邀請」卡片。消費者點擊進入後，商家側即會彈起視頻通話界面。&lt;/p&gt; 
&lt;p&gt;值得注意的是，視頻接通後，消費者攝像頭默認關閉，需消費者手動開啓，且開啓後默認使用後置攝像頭。&lt;/p&gt; 
&lt;p&gt;此外，平台方面還建議商家在配置語音通話賬號後，儘量不要關閉商家 App，保持其前台運行狀態。若商家連續兩天接聽率較低，系統會暫停通話功能 3 天，之後需商家重新開啓。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339647</guid>
            <pubDate>Wed, 05 Mar 2025 11:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>使用 DeepSeek 拯救數據中台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;在數字化轉型浪潮中，數據中台作為企業核心資產的&quot;樞紐站&quot;，卻長期面臨&quot;建而難用&quot;的尷尬境地——業務團隊抱怨數據獲取門檻高、技術團隊困於複雜的數據治理任務，如何打通數據價值落地的&quot;最後一公里&quot;始終是行業痛點。&lt;/p&gt; 
 &lt;p&gt;PowerData 社區主理人李奇峯給出了一個充滿技術想象力的答案：通過深度結合 DeepSeek 大模型的邏輯推理與結構化數據處理能力，重構數據中台的技術棧。&lt;/p&gt; 
 &lt;p&gt;3 月 22 日，PowerData 社區主理人李奇峯將出席 OSC 源創會南京站，並發表《使用 DeepSeek 拯救數據中台》主題分享，探討如何藉助大模型通用化與生成式的數據處理能力，結合數據中台中的落地痛難點，對其進行針對性的優化改造。&lt;/p&gt; 
 &lt;p&gt;在活動正式開始前，我們也和李奇峯聊了聊一些「入門級」問題，感興趣的開發者可週六到活動現場，與李奇峯交流探討關於數據中台的建設問題。報名鏈接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e193f9982c2bb3fe9fad5193d51273ce545.jpg&quot; width=&quot;552&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在眾多大模型中為何選擇 DeepSeek 作為數據中台改造的核心技術？與其他開源模型相比，DeepSeek 在數據處理場景下有哪些優勢？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;我作為一個數據中台的從業者，核心訴求還是提升數據中台本身的能力。對於大模型的瞭解並不深入，其只是我的一個工具而已。所以從工具的屬性來説，我選擇 deepseek 主要有以下幾點原因：&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;成本：無論是訓練成本、還是推理成本，相較於其他模型都有顯著降低。同時支持國產化硬件，在合規性方面也有保證。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;熱度：在風口到來的時候，不説乘風而飛，但是至少還是需要蹭一下的。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;能力：DeepSeek R1 是 LMSYS Chinese 榜單最強的 from China 的模型，V3 是上面榜單中開源的最強非 Reasoner 模型，基礎能力優越。同時相較於其他模型，DeepSeek 在邏輯推理+結構化數據解析處理的能力優秀，同時其支持的上下文窗口較大，在數據血緣解析、數據分類分級、數據質量治理等任務中，其準確性較其他模型都有顯著提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;開發者最關心的部署成本問題：在私有化部署場景下，DeepSeek 模型針對數據中台做了哪些輕量化改造？是否支持量化壓縮後的模型在常規 GPU 服務器集羣運行？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;Deepseek 不會為企業應用場景訓練各種量化模型的，市面上的量化模型都是社區和開發者上傳的。如果為了降低部署成本，採購算力服務器之前先測試各個量化模型的能力能否滿足應用場景，確定好使用哪版量化模型後，根據顯存去採購性價比最高算力服務器，推理服務器建議買 Nvdia 遊戲卡。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;能否用具體代碼片段説明 DeepSeek 如何與數據中台組件集成？例如如何通過 API 調用實現&quot;自然語言轉數據服務接口&quot;這類典型場景，過程中需要哪些中間件做適配？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;下面是一個非常簡單的通過大模型進行數據自動標註的代碼：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai
import pandas as pd
import json
from typing import List, Dict

class MetadataAutoTagger:
    def __init__(self, api_key: str, business_context: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.business_context = business_context  # 公司業務背景説明
        
    def generate_prompt(self, table_name: str, columns: List[str]) -&amp;gt; str:
        &quot;&quot;&quot;構造大模型提示詞&quot;&quot;&quot;
        return f&quot;&quot;&quot;
        # 任務説明
        根據提供的元數據和業務背景，生成數據資產的業務標註信息，要求：
        1. 業務名稱：體現數據在業務中的核心作用
        2. 業務類型：交易型/分析型/主數據/日誌型...
        3. 業務實體：對應業務對象（客户/訂單/產品...）
        4. 分類分級：按公司數據分類分級標準
        5. 字段説明：用業務語言解釋字段含義

        # 業務背景
        {self.business_context}

        # 待標註元數據
        表名：{table_name}
        字段列表：{&#39;, &#39;.join(columns)}

        請用 JSON 格式返回結果，結構如下：
        {{
            &quot;table_name&quot;: &quot;{table_name}&quot;,
            &quot;business_name&quot;: &quot;&quot;,
            &quot;business_type&quot;: &quot;&quot;,
            &quot;business_entity&quot;: &quot;&quot;,
            &quot;data_classification&quot;: &quot;&quot;,
            &quot;columns&quot;: {{
                &quot;column1&quot;: &quot;業務説明&quot;,
                &quot;column2&quot;: &quot;業務説明&quot;
            }}
        }}
        &quot;&quot;&quot;

    def tag_metadata(self, metadata_df: pd.DataFrame) -&amp;gt; pd.DataFrame:
        &quot;&quot;&quot;批量處理元數據&quot;&quot;&quot;
        results = []
        for _, row in metadata_df.iterrows():
            response = self._call_llm(row[&#39;table_name&#39;], row[&#39;columns&#39;])
            if response:
                results.append(response)
        return pd.DataFrame(results)

    def _call_llm(self, table_name: str, columns: List[str]) -&amp;gt; Dict:
        &quot;&quot;&quot;調用大模型 API&quot;&quot;&quot;
        try:
            prompt = self.generate_prompt(table_name, columns)
            response = self.client.chat.completions.create(
                model=&quot;gpt-4&quot;,
                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
                temperature=0.2,
                response_format={&quot;type&quot;: &quot;json_object&quot;}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f&quot;Error processing {table_name}: {str(e)}&quot;)
            return None

# 示例用法
if __name__ == &quot;__main__&quot;:
    # 初始化配置
    config = {
        &quot;api_key&quot;: &quot;your_openai_key&quot;,
        &quot;business_context&quot;: &quot;某電商公司，主要業務包含商品交易、用户畫像、訂單履約等...&quot;
    }

    # 示例元數據（實際從數據庫或文件讀取）
    sample_data = {
        &quot;table_name&quot;: [&quot;user_info&quot;, &quot;order_detail&quot;],
        &quot;columns&quot;: [
            [&quot;user_id&quot;, &quot;registration_date&quot;, &quot;last_login&quot;],
            [&quot;order_id&quot;, &quot;product_sku&quot;, &quot;payment_amount&quot;]
        ]
    }
    metadata_df = pd.DataFrame(sample_data)

    # 執行自動標註
    tagger = MetadataAutoTagger(**config)
    result_df = tagger.tag_metadata(metadata_df)
    
    # 保存結果
    result_df.to_csv(&quot;tagged_metadata.csv&quot;, index=False)
    print(&quot;標註結果示例：&quot;)
    print(result_df.head())
典型輸出結果如下：
{
    &quot;table_name&quot;: &quot;user_info&quot;,
    &quot;business_name&quot;: &quot;用户基本信息表&quot;,
    &quot;business_type&quot;: &quot;主數據&quot;,
    &quot;business_entity&quot;: &quot;用户&quot;,
    &quot;data_classification&quot;: &quot;PII/LEVEL-2&quot;,
    &quot;columns&quot;: {
        &quot;user_id&quot;: &quot;用户唯一標識符，用於跨系統用户識別&quot;,
        &quot;registration_date&quot;: &quot;用户註冊電商平台的具體日期&quot;,
        &quot;last_login&quot;: &quot;記錄用户最近一次登錄平台的時間&quot;
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在處理非結構化數據場景中（如日誌解析/圖片 OCR），DeepSeek 與傳統 ETL 工具的結合方案是怎樣的？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;非結構化數據基本用不上 Deepseek，月更好的選擇，圖片用多模態 LLM 可以總結，圖片類型的文檔用 OCR，OCR 一般用百度&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;paddle&lt;/a&gt;，表格解析有開源的讀光模型。這些都是數據處理，處理完才是抽取-轉換-加載（Sqoop、Flume、Cannel、DataX）到下游。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在數據關係複雜的中台環境，如何通過 prompt engineering 確保大模型輸出的 SQL/SHELL 腳本符合安全規範？是否有開發自定義的語法校驗中間件？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;提示詞來確保大模型輸出的 SQL/SHELL 腳本符合安全規範，是有問題的。LLM 是用來理解和處理自然語言的，更多的是交互上的提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;推薦使用 sqlcheck 和 shellcheck 這種工具，腳本安全做的還可以。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;遇到模型&quot;幻覺&quot;導致的數據質量問題，是否有設計技術兜底方案？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;可以通過 RAG + 外掛知識庫的方式優化幻覺問題。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;PowerData 社區在構建 DeepSeek 插件生態方面有哪些規劃？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;後續會實現一些 MCP 接口。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;對想參與數據中台智能化改造的開發者，建議從哪些具體模塊入手貢獻？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;可以先嚐試進行 text to sql 的功能開發，具體入門教程可參考此篇文章：https://mp.weixin.qq.com/s/Wk9OmB80JC7NFG2T7VjNRA&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在 Data+AI 的架構演進中，您認為未來 3 年數據中台的核心組件會發生哪些顛覆性變化？傳統數據倉庫工程師需要優先補充哪些 AI 工程化能力？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峯：&lt;/strong&gt;顛覆性變化談不上，數據中台的核心還是數據資產化、服務化，一切的功能目標都是往這個方向走。隨着大模型的快速進化與深度結合，數據中台可能會在以下能力進行進化：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;自然語言交互：大模型出色的自然語言交互能力可準確理解用户意圖，大幅提升數，據查詢分析的便利性，提升用户體驗&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;智能洞察分析：大模型可分析文本、圖表等多維數據，智能歸因、預測、總結，降，低員工利用數據、分析數據的門檻&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;集成大模型服務鏈路：集成 LangChain、向量檢索、finetune 等大模型應用所，需技術組件，提升企業調試、使用大模型的效率&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;傳統數倉需要補充哪些 AI 工程化能力？這個我們社區之前內部討論過，工程化能力談不上，更多的還是把 AI 當成一個全能小助手，幫助自己解決問題和提效吧。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;10567&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b99625d6dd601dfc15f3189cd7c0bdf40c.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17938519</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17938519</guid>
            <pubDate>Wed, 05 Mar 2025 09:57:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Bolt.new 創始人：軟件世界運行着萬億美元的市場，重寫軟件世界秩序的機會是巨大的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bolt.new 創始人的勵志故事：我們如何從即將倒閉，到成為史上增長最快的 AI 編碼工具，並保持不到 20 名員工的規模。&lt;/p&gt; 
&lt;p&gt;本文整理自 Bolt.new 創始人 Eric Simons 的完整採訪。他説：&quot;軟件世界運行着萬億美元的市場，重寫軟件世界秩序的機會是巨大的。&quot;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FPiG719cda&quot; target=&quot;_blank&quot;&gt;https://weibo.com/1233486457/PiG719cda&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;一、從零到爆發：Bolt 的驚人增長軌跡&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Lenny 最近對 StackBlitz 的創始人兼 CEO Eric Simons 進行了一次深入採訪，揭示了這個產品如何在短短几個月內從零到每年 4000 萬美元的經常性收入 (ARR)，成為史上增長最快的產品之一。&lt;/p&gt; 
&lt;p&gt;StackBlitz 是一家已經存在了七年的公司，專注於基於網絡的開發環境技術。然而，就在公司即將倒閉之際，他們推出了 Bolt - 一款 AI 驅動的文本到應用程序 (text-to-app) 工具，徹底改變了公司的命運。&lt;/p&gt; 
&lt;p&gt;&quot;公司在我們推出 Bolt 時幾乎要倒閉了，&quot;Simons 回憶道。&quot;我們想，如果這能在未來幾個月增加 10 萬美元的 ARR，那就太棒了。結果在前兩個月，我們從零增長到了 2000 萬美元的 ARR。&quot;&lt;/p&gt; 
&lt;p&gt;現在，僅僅 5 個月後，Bolt 已經達到了 3000 萬美元的 ARR，即將跨越 4000 萬美元的門檻，擁有 300 萬註冊用户和約 100 萬月活躍用户。更令人驚訝的是，StackBlitz 只有 15-20 名員工。這種爆炸性增長甚至讓經驗豐富的創業者和投資者都感到震驚，因為很少有公司能以這樣的速度擴張。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;二、WebContainer 技術：七年錘鍊的核心競爭力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功並非一蹴而就，而是建立在七年技術積累的基礎上。StackBlitz 的核心技術是 WebContainer - 一種可以在瀏覽器中運行的操作系統，它能在 100 毫秒內啓動並運行完整的開發工具鏈。&lt;/p&gt; 
&lt;p&gt;與市場上其他類似產品不同，Bolt 不依賴雲服務器來運行應用程序。當用户使用其他&quot;文本到應用程序&quot;工具時，通常需要等待雲虛擬機啓動，這可能需要幾分鐘時間，並且經常出現問題。而 Bolt 的 WebContainer 技術利用用户自己的 CPU 和內存在瀏覽器中本地運行應用程序，使得整個過程更快、更可靠。&lt;/p&gt; 
&lt;p&gt;&quot;這就是為什麼我們可以有一個非常寬鬆的免費層級，而且它極其快速和可靠，&quot;Simons 解釋道。&quot;我們的 AI Agent 與這個操作系統有雙向通信。它編寫代碼，運行開發服務器，使整個過程快速而流暢。&quot;&lt;/p&gt; 
&lt;p&gt;這種技術路線是 StackBlitz 團隊經過深思熟慮的結果，受到了像 Figma 這樣的成功產品的啓發。Simons 指出：&quot;如果你看看其他在網絡上真正成功的生產力應用程序，它們都採用這種計算模型。Figma、Google Docs - 這是唯一一種擴展到十億用户的模型。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;三、Bolt 實戰：一分鐘內從文本到功能性應用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了 Bolt 的強大功能。他只是簡單地在一個文本框中輸入&quot;製作一個 Spotify 克隆&quot;，然後點擊回車。在不到一分鐘的時間內，Bolt 在瀏覽器中生成了一個功能完整、視覺上令人印象深刻的 Spotify 克隆應用。&lt;/p&gt; 
&lt;p&gt;&quot;這是在瀏覽器中運行的完整開發環境，這是在我的瀏覽器中運行的真實操作系統，&quot;Simons 展示道。&quot;我可以在上面運行命令等，真正令人印象深刻的是，所有這些都是在 60 秒內完成的。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，用户可以立即部署他們的應用程序。通過集成 Netlify 等生產級託管提供商，用户可以一鍵獲得一個實時 URL，甚至可以附加自己的域名。這使得整個過程從創建到部署變得無縫銜接。&lt;/p&gt; 
&lt;p&gt;Simons 強調説：&quot;這是有史以來構建網絡應用最簡單的方式。&quot;對比傳統工具，他指出：&quot;那些東西（如 Wix 或 Squarespace）使用起來非常複雜。我不知道你是否見過這些工具的 UI，但它們非常複雜。而那只是為了構建一個靜態網站，你根本無法用它們構建功能性應用。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;四、移動應用開發的革命：實時預覽與測試&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 最近的一項重大更新是與 Expo 的合作，使用户能夠創建原生移動應用。Expo 是一家專注於 React Native 工具的公司，使開發者能夠更輕鬆地構建漂亮的應用並將其上傳到應用商店。&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示瞭如何使用 Bolt 和 Expo 構建一個移動版 Spotify 克隆應用。用户只需掃描二維碼，就能在自己的手機上實時查看和測試應用程序。當用户繼續通過提示改進應用程序時，這些更改會實時反映在他們的設備上。&lt;/p&gt; 
&lt;p&gt;&quot;這是第一次，你不需要成為技術人員就能製作生產級的網絡、全棧網絡和移動應用，&quot;Simons 解釋道。他指出，Bolt 的用户羣體中有 67% 的人不是開發者，而是產品經理、設計師和企業家。&quot;這些人一直都很擅長構建產品，但以前，他們唯一能將想法轉化為代碼軟件的方式是通過開發者的手指。現在他們可以自己處理。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;五、七年磨一劍：從技術挑戰到市場突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功不僅僅是一個技術故事，更是一個關於毅力和堅持的故事。StackBlitz 在七年的時間裏專注於構建 WebContainer 技術，經歷了無數挑戰和失敗。&lt;/p&gt; 
&lt;p&gt;&quot;我們在技術第一，然後尋找問題來解決，這往往是人們告訴你不應該做的事情，&quot;Simons 承認。他的聯合創始人 Albert 和他從 13 歲就開始一起編寫代碼，並從那時起一直在構建產品。&lt;/p&gt; 
&lt;p&gt;他們的靈感部分來自於早期的 Figma，Figma 最初是作為一個基於瀏覽器的深度技術項目起步的。Simons 解釋説：&quot;很少有人知道 Figma 也是一個基於瀏覽器的深度技術項目。他們第一個 Figma 演示不是設計工具，而是在瀏覽器標籤中展示一個 3D 球體掉入水中的效果。&quot;&lt;/p&gt; 
&lt;p&gt;類似地，StackBlitz 團隊看到了瀏覽器技術（如 WebAssembly、共享內存和 Service Workers）的進步，並意識到可以構建一個運行在瀏覽器中的操作系統。他們花了大約五年時間來構建 WebContainer，然後又花了幾年時間嘗試找到合適的產品應用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;六、在死亡邊緣找到轉機：一條推文改變一切&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在公司即將耗盡資金的關鍵時刻，StackBlitz 團隊認識到他們的 WebContainer 技術非常適合構建基於瀏覽器的 AI 產品。&lt;/p&gt; 
&lt;p&gt;&quot;我們與 Anthropic 合作，獲得了對 Sonnet 模型的預覽，&quot;Simons 回憶道。&quot;我們意識到這可能是我們的機會。我們以前嘗試過構建類似 Bolt 的東西，但當時的模型不夠好，代碼輸出不夠可靠。但 Sonnet 改變了這一切。&quot;&lt;/p&gt; 
&lt;p&gt;2023 年 6 月，當 Anthropic 發佈 Claude 3.5 Sonnet 模型時，StackBlitz 團隊看到了機會。他們重新拾起之前擱置的項目，並通過一條簡單的推文推出了 Bolt。結果超出了他們最瘋狂的期望。&lt;/p&gt; 
&lt;p&gt;&quot;這就像是一個七年磨一劍的&#39;一夜成名&#39;故事，&quot;Simons 表示。StackBlitz 的生存策略也起到了關鍵作用，他們在整個過程中保持了極低的支出和精簡的團隊。&quot;我和我的聯合創始人以前曾經引導一家公司直至被收購，所以我們知道如何使每一美元發揮超出任何人認為合理或可能的價值。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;七、小團隊實現高速增長的秘訣&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;儘管 Bolt 正在以前所未有的速度增長，但 StackBlitz 仍然是一個只有 15-20 人的小團隊。當被問及如何管理這種增長時，Simons 強調了兩個關鍵因素：技術和人員。&lt;/p&gt; 
&lt;p&gt;&quot;我們團隊中有大約 5-7 人已經在這裏工作了五年多，這在初創公司中相當罕見，&quot;Simons 指出。&quot;我們的策略一直是減少人員，增加每人的背景知識。每個人在公司裏都瞭解其他所有事情，這樣他們可以獨立做出準確的決策。&quot;&lt;/p&gt; 
&lt;p&gt;StackBlitz 採用了每天召開全公司會議的做法，使每個人都瞭解正在發生的一切。儘管這聽起來可能效率低下，但 Simons 辯解説：&quot;當你處於極端增長期時，你希望溝通損失接近於零。雖然這不是我們永遠會做的事情，但在目前的階段，它非常有效。&quot;&lt;/p&gt; 
&lt;p&gt;在工具方面，團隊使用 Linear 進行工程任務，使用 Notion 進行產品路線圖，使用 Figma 進行設計。有趣的是，他們現在也在使用 Bolt 進行許多設計和原型製作工作，因為它比傳統工具更快。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;八、Anthropic 的 Sonnet 模型：AI 編碼的臨界點突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在訪談中一個令人驚訝的發現是，Anthropic 的 Claude 3.5 Sonnet 模型在 Bolt 的成功中起到了關鍵作用。Simons 稱之為 AI 生成可靠代碼的&quot;臨界點&quot;。&lt;/p&gt; 
&lt;p&gt;&quot;在 Sonnet 之前，我們嘗試過構建類似的東西，但它就是不起作用，代碼輸出不夠可靠，應用程序要麼損壞，要麼看起來很醜，&quot;Simons 解釋道。&quot;但當我們在 2023 年 5 月看到 Sonnet 的預覽時，我們知道我們應該重新啓動項目，因為這可能就是機會。&quot;&lt;/p&gt; 
&lt;p&gt;這一見解揭示了為什麼自 Sonnet 發佈以來，&quot;文本到應用程序&quot;工具的快速增長。Simons 指出，軟件是確定性的，使其成為 AI 訓練的理想領域：&quot;當你編寫代碼並點擊運行時，它要麼運行，要麼不運行。這使得訓練數據的創建和強化學習變得更加可靠。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，這些成功是基於 2023 年 6 月發佈的模型，自那以來 Anthropic 還沒有發佈新模型。&quot;這是 AI 編碼可能達到的最差狀態，而且已經這麼好了。下一個模型將使這一切變得更好，而且很快就會到來。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;九、AI 時代的職業前景：產品經理的黃金時代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;當討論到 AI 對軟件開發角色的影響時，Simons 提出了一個與許多流行觀點相反的看法。他認為產品經理 (PM)，而非工程師，可能是 AI 編碼革命的最大受益者。&lt;/p&gt; 
&lt;p&gt;&quot;當 Bolt 開始增長時，我們發現大多數用户不是開發者，而是產品經理、設計師和非技術企業家。這真正改變了一切，&quot;Simons 解釋道。&quot;整個軟件世界秩序將被重寫，因為組織構建軟件的方式將完全改變。&quot;&lt;/p&gt; 
&lt;p&gt;Simons 認為，產品經理精通定義範圍並幫助開發者調試問題，這與成功使用 AI 開發代理所需的技能高度重合。&quot;如果你快進 1-5 年，PM 將不再只是寫 JIRA 工單然後等待開發者完成，他們將能夠自己進行更改。&quot;&lt;/p&gt; 
&lt;p&gt;工程師仍然很重要，但他們將專注於 LLM 不適合的智力挑戰任務。&quot;這對每個人都是好事，&quot;Simons 強調。&quot;工程師可以專注於困難的挑戰，而不是製作另一個 CRUD（增刪改查）應用程序，而 PM 和設計師可以直接將他們的願景轉化為軟件。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十、未來功能與願景：與 Figma 和 Slack 的集成&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;展望未來，Bolt 正在開發幾個令人興奮的新功能。一個主要的即將推出的集成是與 Figma 的深度連接。用户只需在 Figma URL 前添加&quot;bolt.new&quot;並按回車，就能將設計導入 Bolt 並轉換為全棧應用或移動應用。&lt;/p&gt; 
&lt;p&gt;&quot;這將是瘋狂的，&quot;Simons 興奮地説。&quot;從 Figma 到全棧應用，只需一次點擊，字面意思。當你是開發者、設計師或其他角色時，將設計轉化為實際的編碼應用並能繼續從那裏提示，這真的很有趣。&quot;&lt;/p&gt; 
&lt;p&gt;另一個即將推出的功能是與 Slack 的集成，這將使團隊能夠直接在他們的通信中使用 Bolt。&quot;我們正在創建一個 Slack 機器人，其工作是基本上像你團隊中的開發者一樣行動，&quot;Simons 解釋道。&quot;你可以在一個線程中説&#39;嘿，我認為我們應該添加一個主頁&#39;，然後@Bolt&#39;你能快速做出這個嗎？&#39;它會獲取對話歷史，理解需求，並生成應用程序。&quot;&lt;/p&gt; 
&lt;p&gt;這些集成反映了 Simons 對 AI 如何改變產品開發的更廣泛願景，使非技術人員能夠直接創建他們想象的產品。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十一、使用 Bolt 的建議：像與開發者交流一樣與 AI 交流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;當被問及給新 Bolt 用户的建議時，Simons 提供了一個簡單但有力的建議：&quot;像寫線程工單或 JIRA 工單一樣與它交流。將它視為你團隊中的開發者。&quot;&lt;/p&gt; 
&lt;p&gt;他解釋説，這意味着在重要的事情上要具體，但也要允許 AI 在適當的領域發揮創意。&quot;你可以只告訴它&#39;讓它更漂亮&#39;，它會做得很好。事實上，它做得非常好。&quot;&lt;/p&gt; 
&lt;p&gt;對於初次使用的人，Simons 建議從個人網站開始：&quot;這有一種魔力。你複製粘貼你的 LinkedIn 簡歷，説&#39;我需要一個網站。我的名字是某某。這是我的 LinkedIn 歷史。我喜歡藍色和狗。&#39;點擊回車，然後你可以部署它。如果你還沒有.com 域名，現在你可以擁有一個真正的個人網站。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十二、從 AOL 總部蹭住到建立價值數千萬的公司&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在採訪的最後，Simons 分享了他早年在硅谷的一段驚人經歷。2012 年，19 歲的他參加了一個教育科技孵化器項目，該項目位於 AOL 總部。當資金耗盡時，他注意到這個辦公室有沙發、食物、健身房，甚至還有淋浴和洗衣設施。&lt;/p&gt; 
&lt;p&gt;&quot;我想，也許在弄清楚這一切的同時，我可以住在這裏，&quot;Simons 回憶道。&quot;所以我最終在這裏住了四五個月。&quot;他通過在夜間編碼來避開保安，白天和夜間輪班的保安以為他只是一個工作非常努力的員工。&lt;/p&gt; 
&lt;p&gt;生活費用？&quot;當時我的花費是每天一美元。那是麥當勞還有一美元菜單的時候。&quot;最終，一名保安發現了他並將他趕了出去，但這段經歷展示了他早期的創業精神和生存能力。&lt;/p&gt; 
&lt;p&gt;Simons 的故事，從 AOL 總部蹭住到建立一家在幾個月內達到 4000 萬美元 ARR 的公司，展示了他一直以來的堅韌和創新精神。正如他所説：&quot;這一切都是關於保持活力，並採取儘可能多的嘗試。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;結論：AI 編碼的未來與更廣泛的影響&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的故事不僅是關於一個成功的產品，還是關於技術進步如何徹底改變我們構建軟件的方式。從這次採訪中，我們可以看到幾個關鍵趨勢：&lt;/p&gt; 
&lt;p&gt;1. 文本到應用程序技術正在迅速成熟，使非技術人員能夠創建以前需要專業開發團隊的應用程序。&lt;/p&gt; 
&lt;p&gt;2. 基於瀏覽器的計算正在獲得新的重要性，提供比基於雲的替代方案更快、更可靠的體驗。&lt;/p&gt; 
&lt;p&gt;3. AI 編碼工具正在重塑公司的組織結構，可能導致產品和設計角色的重要性增加。&lt;/p&gt; 
&lt;p&gt;4. 我們可能正處於一場軟件開發革命的邊緣，這場革命將使創建功能全面的應用程序變得像使用文字處理器一樣容易&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339630</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339630</guid>
            <pubDate>Wed, 05 Mar 2025 09:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>小米汽車模型訓練專利公佈，可解決資源消耗較大等技術問題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查知識產權信息顯示，小米汽車科技有限公司申請的「模型訓練方法、使用方法、裝置、設備及存儲介質」專利公佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要顯示，其中所述模型訓練方法包括：將第一物理參數和第一性能數據輸入第一模型，得到所述第一物理參數和所述第一性能數據的多個關聯關係；將所述第一物理參數輸入到取值模塊，得到第二物理參數，所述取值模塊基於所述第一物理參數計算出目標取值集合，在所述目標取值集合中選取所述第二物理參數；將所述第二物理參數輸入所述第一模型，得到多個第二性能數據；基於所述多個第二性能數據，更新所述第一模型，得到第二模型。這樣，能解決相關技術中存在的模型訓練的精度和效率較低、資源消耗較大等技術問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-72b7dc543a47a38cd1a8d9a37c54723f663.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339627</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339627</guid>
            <pubDate>Wed, 05 Mar 2025 09:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AgentOps —— AI 代理的可觀察性和 DevTool 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;AgentOps 是一個幫助開發人員&lt;/span&gt;測試、調試和部署 AI 代理和 LLM 應用程序的平台&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;。與大多數 LLM 和代理框架集成，包括 OpenAI Agents SDK、CrewAI、Langchain、Autogen、AG2 和 CamelAI。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Replay Analytics 和 Debugging&lt;/strong&gt; 代理逐步執行圖&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM 成本管理&lt;/strong&gt; 跟蹤 LLM 基礎模型提供商的支出&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代理基準測試&lt;/strong&gt; 根據 1,000 多個評估測試您的代理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合規性和安全性&lt;/strong&gt; 檢測常見的即時注入和數據泄露漏洞&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;框架集成&lt;/strong&gt; 與 CrewAI、AG2 (AutoGen)、Camel AI 和 LangChain 的原生集成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;237&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182656_cKyN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/agentops</link>
            <guid isPermaLink="false">https://www.oschina.net/p/agentops</guid>
            <pubDate>Wed, 05 Mar 2025 09:09:00 GMT</pubDate>
        </item>
        <item>
            <title>崑崙萬維開源 R1V 視覺思維鏈推理模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;崑崙萬維宣佈正式開源首款工業界多模態思維鏈推理模型 Skywork R1V，即日起開源模型權重和技術報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，Skywork R1V 具備超強的視覺理解和推理能力。「無論是日常繁瑣的工作任務、複雜的數據分析、難以解答的學術問題，還是前所未見的陌生場景，都可以交給 Skywork R1V 進行高效處理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Reasoning 推理能力方面，Skywork R1V 實現了模型的頂尖邏輯推理與數學分析能力。在權威的 MATH500 和 AIME 基準測試中，Skywork R1V 分別取得了 94.0 和 72.0 的高分，明顯領先於行業內眾多主流模型。Skywork R1V 在純文本複雜推理任務中展現出卓越性能，使其在邏輯推理和數學問題求解領域展現出人類專家級別的水準。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Vision 視覺理解能力方面，Skywork R1V 成功地將其強大的文本推理與思維鏈推導能力高效遷移到視覺任務中。憑藉創新的跨模態遷移技術與推理優化框架，Skywork R1V 能夠高效解決需要多步視覺推理的問題，在 MMMU 與 MathVista 等視覺推理基準中分別取得了 69 和 67.5 的優異成績。這些結果不僅明顯超越了多個近似大小的開源競爭模型，更達到與規模更大的閉源模型媲美的水準，充分證實了 Skywork R1V 在需要視覺思維鏈推理的跨模態任務中的領先優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Skywork R1V 通過視覺與文本能力的深度融合和視覺思維鏈推理能力的突破，推動了多模態推理模型的進一步發展，標誌着人工智能領域的又一重大進步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Skywork R1V 已全面開源。和開源同規模或更大規模模型的對比，Skywork R1V 38B 體現出行業顯著優異的推理能力，以及領先的多模態視覺理解能力。如下圖，與開源同規模或更大規模模型的對比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e032223e7b259303f6e6f7cce7dde417a6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;與閉源頭部模型性能對比，R1V 38B 模型性能媲美甚至超越更大開源模型以及主流閉源模型。如下圖，與開源大尺寸模型與閉源專有模型的對比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;332&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-673a31430f860afa0908dd05aeaa3ad9c22.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339599</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339599</guid>
            <pubDate>Wed, 05 Mar 2025 07:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>理想汽車發佈下一代自動駕駛架構 MindVLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，在 NVIDIA GTC 2025 上，理想汽車發佈了下一代自動駕駛架構 MindVLA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ee07e92de4f6f16747c4c6b166e3b3f2f7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;理想汽車自動駕駛技術研發負責人賈鵬發表了主題演講《VLA：邁向自動駕駛物理智能體的關鍵一步》，分享了理想汽車對於下一代自動駕駛技術 MindVLA 的最新思考和進展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b55c3282e8382e3f4257e15bbf23fee737f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;賈鵬表示：「MindVLA 是機器人大模型，它成功整合了空間智能、語言智能和行為智能，一旦跑通物理世界和數字世界結合的範式後，將有望賦能更多行業。MindVLA 將把汽車從單純的運輸工具轉變為貼心的專職司機，它能聽得懂、看得見、找得到。我們希望 MindVLA 能為汽車賦予類似人類的認知和適應能力，將其轉變為能夠思考的智能體。」&lt;/p&gt; 
&lt;p&gt;理想汽車 CEO 李想&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1243861097%2FPj5JY3Gsr%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;介紹稱&lt;/a&gt;&lt;/u&gt;：「&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;MindVLA 是一個視覺-語言-行為大模型，但我們更願意將其稱為‘機器人大模型’，它將空間智能、語言智能和行為智能統一在一個模型裏，讓自動駕駛擁有感知、思考和適應環境的能力，是我們通往 L4 路上最重要的一步。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;李想還表示：「MindVLA 能為自動駕駛賦予類似人類的駕駛能力，就像 iPhone 4 重新定義了手機，MindVLA 也將重新定義自動駕駛。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339597</guid>
            <pubDate>Wed, 05 Mar 2025 07:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟量子計算機研發曾遭 CEO 納德拉否定</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微軟上月&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot;&gt;宣佈&lt;/a&gt;了一項重大科研進展，聲稱已成功製造出能夠產生馬約拉納費米子的芯片，這一成果被視為量子計算領域的一大突破。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0220/104630_5Gkb_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微軟方面表示，這一技術突破有望將量子設備的問世時間大幅提前，從原本預估的幾十年縮短至幾年之內。儘管這一消息在科技界引起了廣泛關注，但並非所有物理學家都對微軟的説法表示完全信服。&lt;/p&gt; 
&lt;p&gt;然而，微軟 CEO 薩蒂亞·納德拉卻對此成果顯得頗為滿意。據悉，微軟每年在量子研究上的投入高達 3 億美元，儘管與人工智能等領域的投資相比，這一數字顯得微不足道，但微軟在量子領域的持續投入已累積近二十年，如今終於取得了階段性成果。&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟在量子計算領域的進展並非一帆風順。據知情人士透露，七年前，納德拉曾在公司內部對微軟的量子研究表示懷疑，認為其缺乏商業潛力。然而，隨着谷歌和 D-WaveQuantum 等競爭對手在量子計算方面取得進展，微軟的科學家們也意識到自己正處於一場激烈的競賽之中。&lt;/p&gt; 
&lt;p&gt;儘管如此，微軟方面仍對自身的科研成果充滿信心。負責監督相關團隊的高管賈森·贊德表示，公司正準備發表《自然》論文的後續研究，並已邀請一組獨立研究人員對其進行評審。&lt;/p&gt; 
&lt;p&gt;同時，微軟發言人強調，公司會秉持最高的學術道德標準，確保研究成果的真實性和可靠性。&lt;/p&gt; 
&lt;p&gt;閲讀更多：&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot; target=&quot;news&quot;&gt;微軟發佈首款量子計算芯片「Majorana 1」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339592</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339592</guid>
            <pubDate>Wed, 05 Mar 2025 07:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源 AI 助手平台 Cherry Studio 發佈 1.1.5，支持 MCP ​​​</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Cherry Studio 是一款支持多個大語言模型（LLM）服務商的開源桌面客户端，兼容 Windows、Mac 和 Linux 系統。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23dab8c50bfcc8126ab84229b00dbc2115c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cherry Studio 昨天發佈了最新的 1.1.5 版本，其中最值得關注的變化是&lt;strong&gt;正式支持&amp;nbsp;MCP。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加 MCP 工具響應可視化和處理&lt;/li&gt; 
 &lt;li&gt;支持每條消息啓用/禁用 MCP 服務器&lt;/li&gt; 
 &lt;li&gt;修復了 MCP 無法調用功能的問題&lt;/li&gt; 
 &lt;li&gt;優化 MCP 工具按鈕的服務器啓用依賴關係&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/153016_Zh67_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCherryHQ%2Fcherry-studio%2Freleases%2Ftag%2Fv1.1.5&quot; target=&quot;_blank&quot;&gt;點此查看詳細更新説明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339590/cherry-studio-1-1-5-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339590/cherry-studio-1-1-5-mcp</guid>
            <pubDate>Wed, 05 Mar 2025 07:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 首席 AI 科學家楊立昆評價人形機器人：演示驚豔、實際很蠢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;圖靈獎得主、Meta 首席 AI 科學家楊立昆近日在一檔播客節目中對人形機器人發表了「鋭評」，他表示：「&lt;strong&gt;很多人形機器人演示令人印象深刻，但實際很蠢，不少機器人公司都在豪賭未來 3 到 5 年 AI 會突飛猛進。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/151624_dBd1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;楊立昆認為，目前我們仍然沒有家用機器人，也沒有能夠完成貓或狗所能完成任務的機器人，更沒有完全自主的 L5 級自動駕駛汽車。他強調，&lt;strong&gt;我們所欠缺的是如何訓練一個系統來理解像視覺這樣複雜的感官輸入&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;楊立昆進一步指出，如果我們能夠構建出理解物理世界、擁有持久記憶、能夠推理和規劃的 AI 系統，那我們就有了為機器人提供動力的 AI 基礎。這樣的機器人會比我們現有的機器人靈活得多。他提到，過去一兩年裏，成立了很多機器人公司，他們製造人形機器人和類似的技術。雖然所有的演示都令人印象深刻，但這些機器人實際上都很蠢。它們不能做人類能做的事情，不是因為它們缺乏身體能力，而是因為它們根本不夠聰明，無法駕馭現實世界的複雜性。&lt;/p&gt; 
&lt;p&gt;楊立昆還提出，很多這樣的公司都寄希望於 AI 在未來 3 到 5 年內會取得快速進展。他們預計到他們準備好大規模生產和銷售這些機器人時，AI 的進步將使它們足夠智能。&lt;/p&gt; 
&lt;p&gt;然而，楊立昆認為這是一場豪賭，他無法確定這是否能在三至五年內實現。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339582</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339582</guid>
            <pubDate>Wed, 05 Mar 2025 07:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>澳門即將全面結束 3G 時代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;澳門特區政府於 2022 年向澳門四間流動電信服務營運商延長 3G 牌照兩年，&lt;strong&gt;該牌照將於 2025 年 6 月 4 日屆滿，澳門 3G 移動電信網絡及服務將隨着牌照屆滿而終止&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-952129e924f58e0fc3e136e05bebebc548b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;針對上述情況，澳門已敦促各運營商為 3G 退網做好準備工作。&lt;/p&gt; 
&lt;p&gt;澳門郵電局呼籲使用 3G 服務的市民及商户，請儘早聯絡相關電信營運商，瞭解轉換到 4G 或 5G 服務的條件，選擇最適合自身需求的服務。此外，市民及商户亦應留意手機或其他終端設備是否支持 4G 或 5G 制式，如需語音通話，有關設備更需支持 4G 語音通話功能（VoLTE），用户可按自身需要適時更換設備，確保能繼續享用電信服務。&lt;/p&gt; 
&lt;p&gt;澳門郵電局局長劉惠明日前表示，隨着通信業的發展進程，3G 流動電信網絡及服務將於 6 月隨着牌照屆滿而終止。劉惠明稱，目前仍有約 1 萬多名用户，有一部分是非活躍用户。局方正敦促營運商與合作伙伴處理有關問題，並要求營運商加強宣傳推廣 3G 在 6 月退場的訊息。&lt;/p&gt; 
&lt;p&gt;澳門電訊 CTM 也稱，將於 2025 年 6 月起正式與 3G 網絡服務告別。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22f36d1bf91bacce6a45e473812d8130769.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;澳門電訊會通過短信通知仍使用 3G 服務的客户，及時更新服務計劃及設備。客户亦可通過撥打 #183# 查詢設備是否支持 4G / 5G 網絡以及 VoLTE 話音功能。如有任何疑問或需協助，可親臨任何一間 CTM 門市或致電 CTM 服務第一熱線：1000 查詢。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339576</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339576</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>華科大研發領先的「玻璃光盤」技術：理論容量最高 360TB、成本僅 1/10</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FroBVlcZaikjurKymBpvpYQ&quot; target=&quot;_blank&quot;&gt;《長江日報》報道稱&lt;/a&gt;&lt;/u&gt;，武漢光電國家研究中心信息存儲系統教育部重點實驗室研發出了一種「玻璃光盤」，存儲容量目前是普通光盤的 10 倍，理論容量最高 360TB，而且幾乎可以永久保存。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;921&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/145326_59D9_2720166.png&quot; width=&quot;1235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一塊普通的玻璃如何讓它有記憶的功能，報道介紹稱，首先要在玻璃中產生結構，引起玻璃的化學性質變化，而完成這個任務的便是飛秒激光，類似於光刻，過去家用光刻機只能刻一層，而華科大團隊能刻 400 層。製作成的玻璃存儲介質從表面看只增加了一層淺灰色，而在顯微鏡下玻璃表面呈現出的是三維立體結構。如何把結構又快又好寫進玻璃裏，工藝是關鍵。&lt;/p&gt; 
&lt;p&gt;該技術被稱之為「巨量信息低成本超長壽命玻璃多維存儲技術」，目前華科大在該項技術上全球領先，國內也是獨有的。相比於幾年前，玻璃存儲介質讀寫速度較過去快了 3 個數量級，單位體積的存儲容量也提升了 2 個數量級，成本則下降了 1 個數量級。現在 1GB 的介質成本需要約 1 元，而玻璃存儲介質 1TB 也才幾十元，只有其他存儲介質十分之一的成本。&lt;/p&gt; 
&lt;p&gt;目前，製造玻璃介質存儲的設備已生產出原型樣機，今年將推出產品樣機，產品也將很快走向市場。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339573</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339573</guid>
            <pubDate>Wed, 05 Mar 2025 06:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 3FS 與 JuiceFS：架構與特性比較</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，DeepSeek 開源了其文件系統 Fire-Flyer File System (3FS)，使得文件系統這一有着 70 多年曆時的&quot;古老&quot;的技術，又獲得了各方的關注。在 AI 業務中，企業需要處理大量的文本、圖像、視頻等非結構化數據，還需要應對數據量的爆炸式增長，分佈式文件系統因此成為 AI 訓練的關鍵存儲技術。&lt;/p&gt; 
&lt;p&gt;本文旨在通過深入分析 3FS 的實現機制，並與 JuiceFS 進行對比，以幫助用户理解兩種文件系統的區別及其適用場景。同時，我們將探討 3FS 中的值得借鑑的創新技術點。&lt;/p&gt; 
&lt;h2&gt;01 架構對比&lt;/h2&gt; 
&lt;h3&gt;3FS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2F3FS&quot; target=&quot;_blank&quot;&gt;3FS&lt;/a&gt; (Fire-Flyer File System) 是一款高性能的分佈式文件系統，專為解決 AI 訓練和推理工作負載而設計，該系統使用高性能的 NVMe 和 RDMA 網絡提供共享存儲層。3FS 由 DeepSeek 在 2025 年 2 月開源。 3FS 主要包括以下模塊：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集羣管理服務（Cluster Manager）&lt;/li&gt; 
 &lt;li&gt;元數據服務（Metadata Service）&lt;/li&gt; 
 &lt;li&gt;存儲服務（Storage Service）&lt;/li&gt; 
 &lt;li&gt;客户端 （FUSE Client、Native Client）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-96308079c12c6210e0436722cad35b7c636.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所有模塊通過 RDMA 網絡通信。元數據服務和存儲服務向集羣管理服務發送心跳信號。集羣管理服務負責處理成員變更，並將集羣配置分發給其他服務和客户端。為了提高系統的可靠性和避免單點故障，會部署多個集羣管理服務，其中一個被選為主節點。當主節點發生故障時，另一個管理器會被提升為主節點。集羣配置通常存儲在可靠的分佈式服務中，例如 ZooKeeper 或 etcd。&lt;/p&gt; 
&lt;p&gt;當進行文件元數據操作（例如打開或創建文件/目錄），請求被髮送到元數據服務，以實現文件系統語義。元數據服務有多個，並且是無狀態的，它們不直接存儲文件元數據，而是依賴支持事務的鍵值數據庫 FoundationDB 來存儲這些數據。因此，客户端可以靈活地連接到任意元數據服務。這種設計使得元數據服務可以在沒有狀態信息的情況下獨立運作，進而增強了系統的可伸縮性和可靠性。&lt;/p&gt; 
&lt;p&gt;每個存儲服務管理若干本地 SSD，並提供 chunk 存儲接口。存儲服務採用 CRAQ （ Chain Replication with Apportioned Queries）來確保強一致性。3FS 中存儲的文件被拆分為默認 512K 大小相等的塊，並在多個 SSD 上進行復制，從而提高數據的可靠性和訪問速度。&lt;/p&gt; 
&lt;p&gt;3FS 客户端提供兩種接入方式： FUSE Client 和 Native Client。 FUSE Client 提供常見 POSIX 接口的支持，簡單易用。Native Client 提供更高的性能，但是用户需要調用客户端 API ，具有一定的侵入性，下文我們還將對此作更詳盡的解析。&lt;/p&gt; 
&lt;h3&gt;JuiceFS&lt;/h3&gt; 
&lt;p&gt;JuiceFS 是一個雲原生分佈式文件系統，其數據存儲在對象存儲中。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs&quot; target=&quot;_blank&quot;&gt;社區版&lt;/a&gt;可與多種元數據服務集成，適用場景廣泛，於 2021 年在 GitHub 開源。企業版專為高性能場景設計，廣泛應用於大規模 AI 任務，涵蓋生成式 AI、自動駕駛、量化金融和生物科技等。 JuiceFS 文件系統包括三部分組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;元數據引擎：用於存儲文件元數據，包括常規文件系統的元數據和文件數據的索引。&lt;/li&gt; 
 &lt;li&gt;數據存儲：一般是對象存儲服務，可以是公有云的對象存儲也可以是私有部署的對象存儲服務。&lt;/li&gt; 
 &lt;li&gt;JuiceFS 客户端：提供 POSIX（FUSE）、Hadoop SDK、CSI Driver、S3 網關等不同的接入方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bed8225b825f4a839eca178b415fc4b67db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;架構差異&lt;/h3&gt; 
&lt;p&gt;從模塊劃分上看兩個文件系統差異不大，都採用了元數據與數據分離的設計，各個模塊功能也較類似。不同於 3FS 和 JuiceFS 企業版，JuiceFS 社區版兼容多種開源數據庫存儲元數據，對元數據的操作都封裝在客户端，用户不需要再單獨運維一個無狀態的元數據服務。&lt;/p&gt; 
&lt;h4&gt;存儲模塊&lt;/h4&gt; 
&lt;p&gt;3FS 使用大量本地 SSD 進行數據存儲，為了保證數據存儲的一致性，3FS 使用 CRAQ 這一簡潔的數據一致性算法 。幾個副本被組成一個 Chain，寫請求從 Chain 的 Head 開始，一直到達 Chain 的 Tail 時返回寫成功應答。讀請求可以發送到 Chain 的所有副本，如果讀到髒節點的數據，該節點會聯繫 Tail 節點檢查狀態。如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b03df1057d9942ff363f034bee15053b6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;數據的寫入是按順序逐節點傳遞，因此會帶來比較高的延時。如果 Chain 當中的某個副本不可用， 3FS 會把這個副本移到 Chain 的末尾，等副本可用的時候再做恢復。恢復的時候需要把整個 Chunk 的內容複製到這個副本，而非使用不可用期間的增量數據。如果要做到同步寫所有副本和增量恢復數據，那寫的邏輯會複雜非常多，比如 Ceph 使用 pg log 保證數據一致性。儘管 3FS 這種設計會導致寫延遲，但是對於以讀為主的 AI 應用場景，影響不大。&lt;/p&gt; 
&lt;p&gt;JuiceFS 利用對象存儲作為數據存儲解決方案，從而可享有對象存儲帶來的若干優勢，如數據可靠性、一致性等。存儲模塊提供了一組用於對象操作的接口，包括 GET/PUT/HEAD/LIST 等，用户可以根據自己的需求對接具體的存儲系統。比如不同雲廠商的對象存儲，也可以選擇私有部署的對象存儲比如 MinIO、Ceph RADOS 等系統。社區版 JuiceFS 提供本地緩存來應對 AI 場景下的帶寬需求，JuiceFS 企業版使用分佈式緩存滿足更大的聚合讀帶寬的需求。&lt;/p&gt; 
&lt;h4&gt;元數據模塊&lt;/h4&gt; 
&lt;p&gt;在 3FS 中，文件的屬性以 KV 的形式存儲在元數據服務中。該服務是一個無狀態的高可用服務，依靠 FoundationDB 做支撐。FoundationDB 是 Apple 開源的優秀分佈式 KV 數據庫，具有很高的穩定性。FoundationDB 所有鍵值使用 Key 做全局排序，然後均勻拆分到不同的節點上。&lt;/p&gt; 
&lt;p&gt;為了優化 list 目錄的效率，3FS 使用字符 &quot;DENT&quot; 前綴加父目錄 inode 號和名字作為 dentry 的 Key。Inode 的 Key 是通過將 &quot;INOD&quot; 前綴與 inode ID 連接而構造的，其中 inode ID 採用小端字節序編碼，以便將 inodes 分佈到多個 FoundationDB 節點上。這個設計與 JuiceFS 使用的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Finternals%2F%23tkv&quot; target=&quot;_blank&quot;&gt;TKV（Transactional Key-Value Database）&lt;/a&gt; 進行元數據服務的存儲方式類似。&lt;/p&gt; 
&lt;p&gt;JuiceFS 社區版的元數據模塊，與存儲模塊類似也提供一組操作元數據的接口，可以接入不同的元數據服務，比如 Redis，TiKV 等 KV 數據庫，MySQL，PostgreSQL 等關係型數據庫，也可以使用 FoundationDB。JuiceFS 企業版使用自研高性能元數據服務，可根據負載情況來平衡數據和熱點操作，以避免大規模訓練中元數據服務熱點集中在某些節點的問題（比如因為頻繁操作臨近目錄文件的元數據引起）。&lt;/p&gt; 
&lt;h4&gt;客户端&lt;/h4&gt; 
&lt;p&gt;3FS 的客户端除了提供 FUSE 操作外，還提供了一組 API 用於繞過 FUSE 直接操作數據，也就是 Native Client，接口的調用方式有點類似於 Linux AIO。這組 API 的作用是避免使用 FUSE 模塊帶來的數據拷貝，從而減少 I/O 延遲和對內存帶寬的佔用。下面將詳細解析這組 API 如何實現用户進程與 FUSE 進程之間的零拷貝通信。&lt;/p&gt; 
&lt;p&gt;3FS 通過 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存共享內存的大小，地址和其他一些屬性，使用 &lt;code&gt;IoRing&lt;/code&gt; 在兩個進程間通信。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-abcb70acca194a50f90a6a422695f8d89db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;當用户調用接口，創建 &lt;code&gt;hf3fs_iov&lt;/code&gt; 時，會在 &lt;code&gt;/dev/shm&lt;/code&gt; 上分配內存,並創建一個指向這個共享內存的軟鏈接，軟鏈接的地址位於 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt;,這是個虛擬目錄。3FS FUSE 進程收到創建軟鏈接請求，並且發現它的地址位於上述虛擬目錄後，就會根據軟鏈接的名字解析出這塊共享內存的相關參數，並將內存的地址註冊到所有 RDMA 設備（除了 &lt;code&gt;IORing&lt;/code&gt; ）。&lt;code&gt;ibv_reg_mr&lt;/code&gt; 返回的結果被存在 &lt;code&gt;RDMABuf::Inner&lt;/code&gt; 數據結構中，用於後續發送 RDMA 請求。&lt;/p&gt; 
&lt;p&gt;同時，&lt;code&gt;IORing&lt;/code&gt; 的內存也使用 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存，只是在創建對應的軟鏈接時，文件名中會有更多的 &lt;code&gt;IORing&lt;/code&gt; 相關的信息。如果 FUSE 進程發現這個內存是用於創建 &lt;code&gt;IORing&lt;/code&gt;，也會在它的進程內創建對應的 &lt;code&gt;IORing&lt;/code&gt;。這樣設置之後，用户進程和 FUSE 進程就可以訪問相同的 &lt;code&gt;IORing&lt;/code&gt; 了。&lt;/p&gt; 
&lt;p&gt;進程間協作方面，3FS 在 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt; 目錄中創建 3 個不同的虛擬文件用於共享 3 個不同優先級的提交信號量 （submit sem ），用户進程將請求放到 &lt;code&gt;IORing&lt;/code&gt; 後使用這些信號量通知 FUSE 進程有新的請求。 &lt;code&gt;IORing&lt;/code&gt; 尾部包含請求完成信號量，FUSE 進程通過調用 &lt;code&gt;sem_post&lt;/code&gt; 通知用户進程 &lt;code&gt;IORing&lt;/code&gt; 上有新的請求完成。以上整個機制確保了兩個進程間的高效數據通信和操作同步。&lt;/p&gt; 
&lt;p&gt;3FS 的 FUSE 客户端實現了文件和目錄的基本操作，而 JuiceFS FUSE 客户端的實現更加全面。比如，在 3FS 文件系統中文件的長度是最終一致的，這意味着在寫的過程中用户可能訪問到不正確的文件長度。而 JuiceFS 在每次成功上傳對象後會立即更新文件長度。此外，JuiceFS 還提供了以下這些常用的高級文件系統功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 BSD 鎖（flock）和 POSIX 鎖（fcntl）&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;file_copy_range&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;readdirplus&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;fallocate&lt;/code&gt; 接口&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了 FUSE 客户端，JuiceFS 還提供 Java SDK，S3 Gateway，CSI Driver 等接入方式。企業版還提供 Python SDK，Python SDK 將 JuiceFS 客户端在用户進程中運行，避免了通過 FUSE 導致的額外性能開銷。具體見文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcloud%2Fdeployment%2Fpython-sdk%2F&quot; target=&quot;_blank&quot;&gt;Python SDK&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;02 文件分佈對比&lt;/h2&gt; 
&lt;h3&gt;3FS 文件分佈&lt;/h3&gt; 
&lt;p&gt;3FS 將每個文件分成固定長度的 chunk，每個 chunk 位於一個上文提到的鏈上（ CRAQ 算法）。用户使用 3FS 提供的一個腳本，生成一個 chain table。然後將這個表提交到元數據服務。創建新文件時，系統會從表中選取特定數量的 chain （數量由 stripe 定義），並將這些 chain 的信息存入文件的元數據中。&lt;/p&gt; 
&lt;p&gt;因為 3FS 中的 chunk 是固定的，客户端只需要獲取一次 inode 的 chain 信息，就可以根據文件 inode 和 I/O 請求，的 offset，length 計算出這個請求位於哪些 chunk 上，從而避免了每個 I/O 都從數據庫查詢的需求。可以通過 &lt;code&gt;offset/chunk_size&lt;/code&gt; 得到 chunk 的索引。 而 chunk 所在的 chain 的索引就是 &lt;code&gt;chunk_id%stripe&lt;/code&gt;。有了 chain 的索引就可以得到 chain 的詳細信息（比如這個 chain 由哪些 target 組成）。然後，客户端根據路由信息將 I/O 請求發送到相應的存儲服務。存儲服務收到寫請求後以 copy-on-write （COW）的方式將數據寫入新的位置。原來的數據在引用數據清零前仍然是可讀的。&lt;/p&gt; 
&lt;p&gt;為了應對數據不平衡問題，每個文件的第一個 chain 按照輪詢（ round roubin） 的方式選擇。比如當 stripe 為 3 時，創建一個文件，其選擇的 chain 為：chain0，chain1，chain2。那麼下一個文件的 chain 為：chain1，chain2 和 chain3。系統會將選擇的 3 個 chain 做隨機排序，然後存儲到元數據中。下圖為 stripe 為 3 時一個文件的分佈示例，chain 隨機排序後的順序是：1，3，2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cf9e25c0851f3f04955915e8e7ea4ffd658.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;JuiceFS 文件分佈&lt;/h3&gt; 
&lt;p&gt;JuiceFS 按照 Chunk、Slice、Block 的規則進行數據塊管理。每個 Chunk 的大小固定為 64M，主要用於優化數據的查找和定位。實際的文件寫入操作則在 Slice 上執行，每個 Slice 代表一次連續的寫入過程，屬於特定的 Chunk，並且不會跨越 Chunk 的邊界，因此長度不超過 64M。Chunk 和 Slice 主要是邏輯上的劃分，而 Block（默認大小為 4M）則是物理存儲的基本單位，用於在對象存儲和磁盤緩存中實現數據的最終存儲。更多細節可以參考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Farchitecture&quot; target=&quot;_blank&quot;&gt;官網介紹&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db8518e62e6de3e60bb23e2080a1ee55222.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 中的 Slice 是在他文件系統中不常見的一個結構。主要功能是記錄文件的寫入操作，並在對象存儲中進行持久化。對象存儲不支持原地文件修改，因此，JuiceFS 通過引入 Slice 結構允許更新文件內容，而無需重寫整個文件。這與 Journal File System 有些類似，其中寫入操作僅創建新對象，而不是覆蓋現有對象。修改文件時，系統會創建新的 Slice，並在該 Slice 上傳完畢後更新元數據，從而將文件內容指向新的 Slice。被覆蓋的 Slice 內容隨後通過異步壓縮過程從對象存儲中刪除，導致在某些時刻對象存儲的使用量會暫時超過文件系統實際使用量。&lt;/p&gt; 
&lt;p&gt;此外，JuiceFS 的所有 Slice 均為一次性寫入，這減少了對底層對象存儲一致性的依賴，並大大簡化了緩存系統的複雜度，使數據一致性更易於保證。這種設計還為實現文件系統的零拷貝語義提供了便利，支持如 copy_file_range 和 clone 等操作。&lt;/p&gt; 
&lt;h2&gt;03 3FS RPC (Remote Procedure Call) 框架&lt;/h2&gt; 
&lt;p&gt;3FS 使用 RDMA 作為底層網絡通信協議，目前 JuiceFS 尚未支持，下面對此做一些分析。&lt;/p&gt; 
&lt;p&gt;3FS 通過實現一個 RPC 框架，來完成對底層 IB 網絡的操作。除了網絡操作外，RPC 框架還提供序列化，小包合併等能力。因為 C++ 不具有反射能力，所以 3FS 還通過模版實現了一個反射庫，用於序列化 RPC 使用的 request、response 等數據結構。需要被序列化的數據結構只需要使用特定的宏定義需要序列化的屬性。RPC 調用都是異步完成的，所以序列化後的數據只能從堆上分配，等待調用完成後再釋放。為了提高內存的分配和釋放速度，分配對象都使用了緩存。3FS 的緩存有兩部份組成，一個 TLS 隊列和一個全局隊列。 從 TLS 隊列獲取緩存時不需要加鎖；當 TLS 緩存為空時就得加鎖，從全局隊列中獲取緩存。所以在最優情況下，獲取緩存是不需要加鎖的。&lt;/p&gt; 
&lt;p&gt;與 I/O 請求的負載不同，緩存對象的內存都未註冊到 RDMA 設備中。因此，當數據到達 IBSocket 後，會被拷貝到一個在 IB 設備註冊過的緩衝區中。多個 RPC 請求可能被合併為一個 IB 請求發送到對端。下圖為 FUSE Client 調用 Meta 服務的 RPC 過程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//58e38641fd7da6914308fa2198428dc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 特性對比&lt;/h2&gt; 
&lt;p&gt;| 對比項 | 3FS | JuiceFS 社區版 | JuiceFS 企業版 | |--------------------|-------------------------------|----------------------------------|----------------------------------------------| | 元數據 | 無狀態元數據服務+FoundationDB | 獨立數據庫服務 | 自研高性能分佈式元數據引擎（可橫向擴展） | | 數據存儲 | 自主管理 | 使用對象存儲 | 使用對象存儲 | | 冗餘保護 | 多副本 | 對象存儲提供 | 對象存儲提供 | | 數據緩存 | 無緩存 | 本地緩存 | 自研高性能多副本分佈式緩存 | | 數據加密 | 不支持 | 支持 | 支持 | | 數據壓縮 | 不支持 | 支持 | 支持 | | 配額管理 | 不支持 | 支持 | 支持 | | 網絡協議 | RDMA | TCP | TCP | | 快照 | 不支持 | 支持克隆 | 支持克隆 | | POSIX ACL | 不支持 | 支持 | 支持 | | POSIX 兼容性 | 少量子集 | 完全兼容 | 完全兼容 | | CSI 驅動 | 沒有官方支持 | 支持 | 支持 | | 客户端 | FUSE + Native Client | POSIX（FUSE）、Java SDK、S3 網關 | POSIX（FUSE）、Java SDK、S3 網關、Python SDK | | 多雲鏡像 | 不支持 | 不支持 | 支持 | | 跨雲和跨區數據複製 | 不支持 | 不支持 | 支持 | | 主要維護者 | DeepSeek | Juicedata | Juicedata | | 開發語言 | C++, Rust (本地存儲引擎) | Go | Go | | 開源協議 | MIT | Apache License 2.0 | 商業軟件 |&lt;/p&gt; 
&lt;h2&gt;05 總結&lt;/h2&gt; 
&lt;p&gt;大規模 AI 訓練中最主要的需求是高讀帶寬，為此 3FS 採用了性能優先的設計策略，將數據存儲在高速磁盤上，並且用户需要自行管理底層數據存儲。這種方法提升了性能，但成本較高，維護也更繁重。此外，為了充分發揮底層硬件的性能，其架構實現了客户端到網卡的零拷貝，利用共享內存和信號量減少 I/O 延遲和內存帶寬佔用。此外，通過帶 TLS 的 I/O buffer pool 和合併網絡請求，3FS 增強了小 I/O 和文件元數據操作的能力，並引入了性能更優的 RDMA 技術。我們將繼續關注 3FS 在性能優化方面的進展，並探索如何將這些技術應用於我們的場景中。&lt;/p&gt; 
&lt;p&gt;JuiceFS 使用對象存儲作為底層數據存儲，用户因此可大幅降低存儲成本並簡化維護工作。為了滿足 AI 場景的對讀性能的需求，JuiceFS 企業版引入了分佈式緩存、分佈式元數據服務和 Python SDK，從而提高文件系統的性能和擴展能力，並同時兼顧低存儲成本。在接下來發布的 v5.2 企業版中，在 TCP 網絡中實現了零拷貝，進一步提升數據傳輸效率。&lt;/p&gt; 
&lt;p&gt;JuiceFS 提供完整的 POSIX 兼容性和成熟活躍的開源生態，適應更廣泛的使用場景，並支持 Kubernetes CSI，極大簡化了雲平台的部署和運維工作。此外，JuiceFS 還提供了 Quota、安全管理和數據災備等多項企業級管理功能，讓企業可以更便捷地在生產環境中部署和應用 JuiceFS。&lt;/p&gt; 
&lt;p&gt;希望這篇內容能夠對你有一些幫助，如果有其他疑問歡迎加入 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2F&quot; target=&quot;_blank&quot;&gt;JuiceFS 社區&lt;/a&gt;與大家共同交流。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17937022</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17937022</guid>
            <pubDate>Wed, 05 Mar 2025 06:54:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Roblox 公佈生成式 AI 模型 Roblox Cube</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 17 日，Roblox 公佈了自己的生成式 AI 模型 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorp.roblox.com%2Fnewsroom%2F2025%2F03%2Fintroducing-roblox-cube&quot; target=&quot;_blank&quot;&gt;Roblox Cube&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;926&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/144726_7BvT_2720166.png&quot; width=&quot;1618&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;遊戲公司 Roblox 曾於去年宣佈將建立一個開源的三維基礎模型，用於在 Roblox 中創建三維物體與場景。&lt;/p&gt; 
&lt;p&gt;本週，Roblox 將開源名為 Cube 3D 的模型首個版本，任何人都可以在 Roblox 平台內外使用。同時發佈的還有網格生成 API 的 beta 版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1906054f0606ef1676bb4e26ab93a24aed.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;官方示例提示詞：A red buggy with knobby tires（裝有凸高花紋越野胎的紅色越野車）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Cube 3D 可以從文字直接生成 3D 模型與環境，未來還將支持以圖生模型。Roblox 期望最終模型能完成加入物體-環境-人互動維度的 4D 創造。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339570/oblox-cube</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339570/oblox-cube</guid>
            <pubDate>Wed, 05 Mar 2025 06:48:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>在 RISC-V 上構建 AI 應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;當開源指令集 RISC-V 遇上 AI 大模型，會碰撞出怎樣的未來圖景？&lt;/p&gt; 
&lt;p&gt;中國科學院軟件研究所工程師張旭陽和他所在的團隊正在研究 AI 大模型在 RISC-V 架構上的多項應用與實踐。&lt;/p&gt; 
&lt;p&gt;3 月 22 日，張旭陽將出席 OSC 源創會南京站活動，發表《RISC-V 上 AI 應用與實踐》，通過自主研發的 AI 助手展示如何藉助 RISC-V 架構構建高效、靈活的 AI 助手，實現智能交互與數據處理。&lt;/p&gt; 
&lt;p&gt;同時張旭陽還將分享 Qwen、DeepSeek、LLama 和 Stable Diffusion 等知名模型在 RISC-V 上應用的最新進展。&lt;/p&gt; 
&lt;p&gt;在活動開始前，我們和張旭陽簡單聊了聊 RISC-V + AI 的技術創新與生態構建，歡迎想了解具體如何在 RISC-V 上構建 AI 應用的開發者到現場交流，報名鏈接：&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1014&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-015bbdaaa23e8ca63a6d14af2bc8f95c1a0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 對 AI 來説，是「樂高積木」還是「瑞士軍刀」？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我覺得更像是樂高積木吧，因為 RISC-V 的架構更加開發，所以非常易於針對不同場景進行定製。用户根據不同的場景需要，定製化的設計芯片，可以擴展指令集，可以在 Soc 上集成各種類型的處理器。同時因為 RISC-V 的特性，做同樣的工作，相比 x86 和 arm 來説，功耗更低。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;把 Qwen、DeepSeek 這些「大胖子」模型塞進 RISC-V，需要先幫它們「瘦身」嗎？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我們都知道 Qwen 是阿里推出的一系列優秀的開源模型，Qwen 的優點就是，模型參數覆蓋比較廣，最小的模型參數只有 1.5b 。我們目前成功在基於 TH1520 的 RUYIBOOK 上跑通了 Qwen2.0-1.5B 的小模型，以及 DeepSeek-R1-Distill-Qwen-1.5B 模型。同時在算能 SG2042 和 SG2044 的環境上，跑通了 DeepSeek-R1-Distill-Qwen-1.5B，DeepSeek-R1-Distill-Qwen-7B 等模型，藉助於 TPU 的算力，這些精簡的模型也可以跑出相對不錯的性能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 架構上的自研 AI 助手突出優勢是什麼？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;我們自研的 AI 助手，可以説是 RISC-V 的原住民，也是首款基於 RISC-V 桌面生態環境的原生開發的 AI 助手，它可以原生運行在我們的自研的開源 RISC-V 筆記本 RUYIBOOK 甲辰版上，除了基礎的文字問答功能之外，還有圖片理解，文生圖，語音合成等多模態功能。同時藉助大模型的能力，可以通過文字或者語音的方式直接對操作系統做一些基礎的控制。比如説調節音量，調節屏幕亮度，打開關閉應用，搜索文件並打開等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;Stable Diffusion 在 RISC-V 上畫圖，實測生成一張圖要多久？效果如何？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;目前基於算能 SG2044 的測試情況，在 TPU 加速情況下，StableDiffusionV1.5 模型生成一張圖大約 5-6s，StableDiffusionXL 模型生成一張圖大約是 40-50s。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;開發者最怕「從入門到放棄」，有沒有開箱即用的工具包？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;可以關注一下中科院軟件所 PLCT 實驗室所出的 RuyiSDK 開發工具集。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;RISC-V 開發板鏡像相關信息以及下載、安裝教程，便於開發者獲取相關鏡像（換而言之提供一個鏡像站），其中涵蓋多種操作系統（如基於 Debian 的 RevyOS、openEuler RISC-V 等）提供給開發者使用。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;提供 RISC-V 開發板對應的演示程序、開發資料和相關工具（含適用的編譯工具鏈、模擬器等）的信息維護和下載，方便 RISC-V 開發者快速上手。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;在集成開發環境中增加 RISC-V 設備專有嚮導頁面、實現開發環境和運行環境的文件傳輸、支持在 RISC-V 設備上調試應用程序等。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;玩轉 RISC-V + AI 需要點亮哪些技能樹？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;其實如果感興趣的話，完全可以自己買一個開發板先玩起來，因為技能是可以在實踐的過程中逐步去學習的。無論是 AI 相關的，還是 RISC-V 相關的。只要你有一定的計算機專業基礎，然後又會一兩門開發語言，比如 C,C++,python 等。那麼就可以自己利用開發板來做一些研究和學習。咱們的大部分普通人的目的可能並不在於搞出一個 DeepSeek，而是看看能利用 DeepSeek 做些什麼。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;預言時間：RISC-V + AI 組合拳，3 年內能 KO 傳統架構嗎？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;張旭陽：&lt;/strong&gt;這個時間點我不好預估，因為無論是 AI 軟件棧，還是 RISC-V 都在快速發展中，他們都還沒有達到一個成熟期。但是呢，我認為在開源開放，合作共贏的生態下，RISC-V 和 AI 未來一定可以拿出一些標杆級的應用，可以在某些應用場景下落地生根。我們和傳統的指令集架構，很長時間都是共生共存的關係。並不是説要 KO 掉誰。但我們因為靈活擴展等特性，可能未來在 AI 領域比傳統指令集更加容易去開拓。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;即刻報名&lt;/strong&gt;，現場探智能體設計與使用問題&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🔥報名鏈接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;⏰時間：03-22 14:00 至 18:00&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🚗地點：南京瑞瀾庭院酒店（南京秦淮區瑞金路街道解放路 46 號）&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;2367&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a57781b43c33abfad271e2d16b2f1eca4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17937477</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17937477</guid>
            <pubDate>Wed, 05 Mar 2025 06:46:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>