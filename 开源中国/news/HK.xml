<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Fri, 04 Jul 2025 21:42:58 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>三步解鎖鴻蒙開發 + 2025 HarmonyOS 創新賽指南，7 月 8 日雙攻略放送！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依託「一次開發、多端部署」的核心理念，HarmonyOS 的分佈式能力正在革新萬物互聯時代的應用開發範式——從智能家居到移動辦公，開發者可高效實現跨終端無縫協同。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;然而，許多開發者仍面臨以下問題：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對鴻蒙核心開放能力（如元服務、分佈式技術、AI 能力）缺乏系統認知；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對鴻蒙專屬開發工具（ArkUI、DevEco Studio）的操作不熟悉；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;缺少從入門到進階的完整學習路徑，難以快速上手實戰開發。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#2980b9"&gt;為此，7 月 8 日晚，開源中國 OSCHINA 《數智漫談》直播欄目聚焦「工具 · 能力 · 進階」三大模塊，邀請三位鴻蒙生態專家，通過場景化演示與案例拆解，幫助開發者高效掌握鴻蒙應用開發的核心技能，抓住萬物互聯時代的創新機遇。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;與此同時，一場鴻蒙生態最大規模開發者官方賽事——&lt;strong&gt;&lt;span style="background-color:#ffff33"&gt;2025 HarmonyOS 創新賽已經開啓&lt;/span&gt;&lt;/strong&gt;，期待全球開發者們基於 HarmonyOS 6 開發者 Beta 版本能力，開發套件和場景化解決方案，開發具有創新性和鴻蒙生態極致體驗的應用。本次大賽華為設立了專項獎金，共 450 萬人民幣和 450 萬耀星券。在本場直播中，我們將分享大賽最新信息，邀請專家分享參賽實戰經驗，助力開發者把握參賽先機。&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;報名參賽：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Factivity%2FdigixActivity%2Fdigixcmsdetail%2F101750143863263087%3Fha_source%3DKYZGZB%26ha_sourceId%3D89000343" target="_blank"&gt;https://developer.huawei.com/consumer/cn/activity/digixActivity/digixcmsdetail/101750143863263087?ha_source=KYZGZB&amp;amp;ha_sourceId=89000343&lt;/a&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;三步上手鴻蒙開發：工具 · 能力 · 進階&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;平台：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;視頻號「OSC 開源社區」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;時間：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;7 月 8 日（週二） 19:00-20:40&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;img height="7045" src="https://oscimg.oschina.net/oscnet/up-a6a6ffeb84696559b451fe4696f9e547ea9.png" width="1563" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;🔥 直播核心看點搶先揭秘：&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 1：解鎖鴻蒙核心能力，打造跨端智能應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;鴻蒙操作系統以「分佈式架構」為核心，打破設備邊界，實現跨終端無縫協同與算力共享，通過元服務、多端統一開發、AI 等能力，重塑萬物互聯場景體驗。本次演講將解讀其技術革新內核，並探討在各領域的應用實踐，揭示鴻蒙如何為生態融合與數字化轉型提供新範式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 2：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;DevEco Studio：從零到一搭建鴻蒙應用&lt;/strong&gt;&lt;br&gt; &amp;nbsp;本演講以開發者視角系統性解析鴻蒙應用開發全流程：從 DevEco Studio 環境配置與真機調試技巧，到 ArkUI 聲明式開發範式的核心實踐（狀態管理、組件化開發），並結合跨設備聯調、卡片服務等典型場景，直擊多端適配與調試中的高頻問題，提供華為 HDE 總結的實戰解決方案，助力開發者快速構建高質量鴻蒙應用。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 3：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;從學習到實戰：鴻蒙開發者成長指南&lt;/strong&gt;&lt;br&gt; 聚焦鴻蒙開發者從入門到精進的成長路徑，解析如何通過高效學習框架與實戰經驗，掌握分佈式開發、多端協同等核心技術，跨越「單一設備」到「場景化創新」的鴻溝。內容涵蓋開發工具鏈使用、典型場景案例拆解及生態機遇洞察，助力開發者在萬物互聯時代搶佔技術先機，實現從技能提升到價值落地的閉環。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;👨‍💻 重磅嘉賓陣容：&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;姚聖偉，&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;華為雲 HCDE、鴻蒙應用認證開發者、微軟 Insider Dev Tour China、.Net Conf China 講師、中科院開源之夏優秀導師、昇騰 CANN 訓練營優秀開發者、騰訊騰源會開源摘星 100 人，天津敏捷社區核心組織者，中國 DevOps 社區理事會成員。現從事信創、電子政務、人工智能、雲開發平台等領域的設計、研發工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;張一弛，&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;華為開發者專家（HDE）、湖南長沙虛擬盒子鴻蒙架構師、鴻蒙兔習慣 APP 作者、歡友社交應用，出境元服務架構師。多年移動端開發經驗，專注於 IM 領域，目前主要從事鴻蒙元服務相關工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;祝欣蓉，&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;上海杉達學院副教授，華為開發者專家（HDE），HarmonyOS 應用開發高級工程師、華為路由交換高級網絡工程師、華為大數據高級工程師、華為 HDG 上海核心組成員，曾擔任丹陽市委網信辦網絡安全顧問，主要研究方向：鴻蒙移動應用開發，OpenHarmony 軟硬協同開發，企業級項目開發，曾主持橫向課題 1 項，教育部產學合作協同育人項目 2 項，市級重點課程建設 1 門，校級重點課題 4 項，出版教材 3 本。曾任教課程：鴻蒙移動應用開發，HarmonyOS 軟硬協同創新實踐，Java Web 開發技術，數據挖掘技術與應用，組網技術，園區網絡安全技術等課程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🚀 立即行動，開啓你的鴻蒙開發進階之旅！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;📅 直播時間：2025 年 7 月 8 日 (週二) 19:00 - 20:40&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;📍 直播平台：視頻號搜索【OSC 開源社區】&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;👉 現在預約直播，開播不錯過！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;img height="660" src="https://oscimg.oschina.net/oscnet/up-a2420114f6a13a893712842053fb7fce6ef.jpg" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;《數智漫談》直播欄目介紹&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《數智漫談》是開源中國推出的一檔直播欄目，每月 1 期，已推出 22 期。以「深度對話、多元視角、前沿洞察」為核心理念，聚焦 IT 技術、開源治理、行業趨勢與創新實踐，通過輕鬆互動形式搭建開源領域的思想交流平台。區別於傳統技術直播的單向輸出，突出「圍坐暢聊」的互動感和思想交鋒的張力，打造開源領域的「圓桌派」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;有興趣的朋友，可以聯繫我~&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18635616</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18635616</guid>
      <pubDate>Sat, 10 May 2025 10:06:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>字節跳動開源 Trae-Agent</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字節跳動旗下 AI 原生集成開發環境（IDE）Trae 宣佈正式開源其核心組件 Trae-Agent。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="422" src="https://oscimg.oschina.net/oscnet/up-e27f5cb97abf42a79a613d985b6829fafe0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Trae-Agent 是字節跳動打造的智能開發工具，支持自然語言驅動的編程任務自動化，極大提升開發效率。其核心亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多模型支持&lt;/strong&gt;：兼容 OpenAI、Anthropic 等多種大語言模型，安裝配置簡便，靈活適配不同開發需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;強大功能集成&lt;/strong&gt;：內置文件編輯、腳本執行等工具，支持多輪交互，滿足複雜編程場景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;操作日誌記錄&lt;/strong&gt;：自動保存操作日誌，便於調試和回溯，提升開發過程透明度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;兼容性強&lt;/strong&gt;：適用於 Python3.12，確保與現代開發環境的無縫銜接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/355035" target="_blank"&gt;字節 Trae 宣佈月活突破 100 萬，交付超 60 億行代碼&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358793</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358793</guid>
      <pubDate>Sat, 10 May 2025 09:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>時代命題下的民營科技擔當：從備份戰略看 Gitee 的國家定位</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/171154_tcjE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;任正非在《人民日報》的採訪中提到：「不去想困難，幹就完了，一步一步往前走。」&lt;/p&gt; 
&lt;p&gt;這句話不僅是企業家的個人信條，也代表了當前國家對民營企業的新期待。在國際形勢深度變化、全球技術競爭激烈加劇的背景下，中國民營科技企業正面臨新的時代命題。&lt;/p&gt; 
&lt;p&gt;過去，依靠市場紅利和靈活機制，民營企業實現了快速成長；未來十年，國家戰略將成為企業發展的主要引導力。民營企業要麼在國家重點任務中承擔角色，要麼在支撐就業與內需中提供韌性。這不是選擇題，而是方向問題。&lt;/p&gt; 
&lt;p&gt;Gitee 的發展路徑，正落在這一國家座標系中。其作為國產開源協作平台，承擔起代碼託管、開源治理、安全合規等方面的系統能力建設，在多個維度上已進入國家戰略重點關注範圍。近幾年承接了多個國家級項目的 Gitee ，進一步明確了其在軟件基礎設施中的關鍵位置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#0000cc"&gt;代碼託管平台不再是可選項，而是戰略節點&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;在數字基礎設施體系中，代碼託管平台承載着開發協作、版本控制、依賴管理、安全檢測等基礎功能，其安全性、可控性與穩定性直接關係到上層應用系統的安全穩定。&lt;/p&gt; 
&lt;p&gt;依賴境外平台所帶來的技術不確定性，已在近年來多次被驗證。對國家而言，自主可控的託管平台不是錦上添花，而是核心需求。Gitee 是當前國內具備全棧自研能力、全面支持國產生態的主力平台，具備承擔代碼備份、協同管理、安全掃描等基礎服務的能力，正逐步成為國家重點工程、關鍵領域項目的默認選項。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#0000cc"&gt;國產替代是基礎能力重建，也是現實推進路徑&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;國產化不是口號，而是明確的制度性方向。從操作系統、數據庫、開發框架到代碼託管平台，每一個環節的國產替代都是一個系統工程，任何短板都可能成為全局隱患。&lt;/p&gt; 
&lt;p&gt;Gitee 所處的領域雖不直接面向終端用户，但其所承載的開發支撐能力，對國產軟件產業鏈的完整性至關重要。通過全國產依賴鏈支持、國產認證體系適配、安全檢測與合規報告體系建設，Gitee 正在參與形成一套更符合國內安全要求的 AI + DevSecOps 體系。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#0000cc"&gt;中國軟件生態的沉澱平台正在成型&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;中國的軟件開發者數量已躍居全球第一，但長期以來缺乏一個穩定、高效的國產平台來沉澱、管理和複用這些代碼資產。這正是 Gitee 十幾年來耕耘的目標：構建適用於本土技術體系的、可控的中國軟件基因庫。&lt;/p&gt; 
&lt;p&gt;當前，越來越多的國產操作系統、AI 大模型、開源研發框架與工具選擇 Gitee 作為首發平台或主力託管平台，這一趨勢不僅體現了平台能力的成熟，也體現了開發生態的集中意願。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#0000cc"&gt;代碼即國力，平台即基建&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;國家戰略正在重新定義基礎設施的邊界。對於民營科技企業而言，單純追求規模和利潤的時代已經過去，企業是否具備戰略響應能力、是否能融入關鍵能力體系，將成為未來發展的決定性因素。&lt;/p&gt; 
&lt;p&gt;代碼即國力，平台即基建。當國家需要一個本土的軟件基因庫，Gitee 義不容辭。也唯有堅定走上這條「責任與創新並重」的道路，民營科技企業才能把自身能力嵌入國家戰略體系，在新一輪技術革命中獲得更多的發展空間。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358785</guid>
      <pubDate>Sat, 10 May 2025 09:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊元器接入微信支付 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，騰訊元器&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLXjCQ_y-HX__WKNCCZ0eCw" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;正式接入微信支付 MCP，支持開發者在智能體上直接增加下單、讚賞、查詢訂單等功能，打通智能體商業化的最後一公里。&lt;/p&gt; 
&lt;p&gt;&lt;img height="683" src="https://static.oschina.net/uploads/space/2025/0704/165037_LObp_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/165144_53FM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微信支付 MCP 是微信支付團隊為 AI 智能體生態打造的支付解決方案，具有安全、便捷、可靠等多重特點，騰訊元器作為首個接入微信支付 MCP 的智能體開發平台，將憑藉騰訊生態的優勢連接能力，為智能體的開發帶來更多豐富的體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1156" src="https://static.oschina.net/uploads/space/2025/0704/165049_Y4mu_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358781</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358781</guid>
      <pubDate>Sat, 10 May 2025 08:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>vec2text 技術已開源！一定條件下，文本嵌入向量可 「近乎完美地」 還原</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 我們今天為大家帶來的這篇文章，作者的觀點是文本嵌入向量並非我們想象中的安全載體，在某些條件下，通過適當的技術手段可以高精度地還原出原始文本內容。&lt;/p&gt; 
 &lt;p&gt;作者在本文介紹了其開發的 vec2text 方法 ------ 一種基於迭代優化的文本反演技術，能夠以 92% 的精確率還原 32 個詞元的文本序列，BLEU 分數高達 97 分。這一技術為企業在部署 AI 系統時的數據安全策略敲響了警鐘。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;本文系原作者觀點，Baihai IDP 僅進行編譯分享&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Jack Morris&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a0b1de9536036af1e9938f337d7283677d0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 向量數據庫的崛起&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;近年來，隨着生成式 AI 的迅猛發展，眾多企業正爭相將 AI 技術融入其業務中。其中一個最普遍的做法，是構建能夠基於文檔數據庫中的信息來回答問題的 AI 系統。解決此類問題的主流方案大多基於一項關鍵技術：檢索增強生成（Retrieval Augmented Generation, RAG）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d0af86ccd087712d47aa45d515995b11f6b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RAG 系統概覽。‌來源："Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"[1]&lt;/p&gt; 
&lt;p&gt;這正是當下許多人開啓 AI 應用之旅所採用的一種既經濟又快捷的方案：將大量文檔存儲於數據庫中，讓 AI 根據給定的輸入檢索最相關的文檔，然後依據檢索到的文檔信息生成對輸入的響應。&lt;/p&gt; 
&lt;p&gt;這些 RAG 系統通過使用"嵌入向量"（embeddings）------ 即由嵌入模型（embedding model）生成的文檔向量表徵 ------ 來確定文檔的相關性。這些嵌入向量本質上是通過數學方式來表徵語義關聯性，因此，與搜索需求相關的文檔，在嵌入向量空間中應具有較高的向量相似度（vector similarity）。&lt;/p&gt; 
&lt;p&gt;RAG 的普及推動了向量數據庫這一新型數據庫的崛起，這種數據庫專為存儲和搜索大量嵌入向量而設計。一些初創公司已經獲得了數億美元的資金[2-5]，它們聲稱可以通過簡化嵌入搜索過程（embedding search）來促進 RAG 的發展。而 RAG 的有效性，正是大量新興應用將文本轉化為向量並存儲於這些向量數據庫的原因所在。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 嵌入向量難以解讀&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;那麼文本嵌入向量中存儲的究竟是什麼？除了必須體現語義相似性（semantic similarity）這一要求外，對於給定文本輸入應分配何種嵌入向量並無任何約束。嵌入向量中的數值具有不確定性，其具體取值取決於模型的初始化狀態。&lt;strong&gt;我們或許能解讀不同嵌入向量之間的關聯性，但永遠無法理解單個嵌入向量的具體數值含義。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-847f6911201d575300293005195a74c8be8.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;一個神經嵌入模型（淺藍色）接收文本輸入並生成用於搜索的嵌入向量&lt;/p&gt; 
&lt;p&gt;現在設想你是一名軟件工程師，正為公司搭建 RAG 系統。你決定將向量存儲在向量數據庫中。此時你發現，該數據庫實際存儲的是嵌入向量，而非原始文本數據。數據庫中充斥着大量看似隨機的數字，它們雖然代表着文本數據，但系統實際上從未真正"接觸"過任何原始文本。&lt;/p&gt; 
&lt;p&gt;你清楚這些文本對應的是受公司隱私政策保護的客户文檔。但嚴格來説你從未將任何文本傳輸至外部；&lt;strong&gt;傳輸的始終是嵌入向量，這對你而言僅是一組隨機數字。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果有人黑進數據庫並獲取所有文本嵌入向量 ------ 這是否會造成嚴重後果？如果服務提供商想將您的數據售賣給廣告商 ------ 他們能否做到？這兩種場景的核心在於：攻擊者能否獲取嵌入向量並通過某種方式反推出原始文本。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 從文本到嵌入向量...再回到文本&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;從嵌入向量中復原原始文本的問題，正是我們在論文《Text Embeddings Reveal As Much as Text》(EMNLP 2023)[6] 中要解決的問題。嵌入向量是一種安全的信息存儲和通信載體嗎？簡而言之：&lt;strong&gt;能否從輸出的嵌入向量中還原輸入文本？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在深入探討具體解決方案之前，讓我們進一步剖析該問題。文本嵌入向量（text embeddings）本質上是神經網絡的輸出結果 ------ 是對輸入數據實施非線性函數運算與序列化矩陣乘法後的產物。在傳統的文本處理神經網絡中，字符串輸入被拆分為若干詞元向量，這些向量會反覆經歷非線性函數運算。在模型的輸出層，所有詞元將被聚合為單個嵌入向量。&lt;/p&gt; 
&lt;p&gt;信號處理（signal processing）領域有一條著名的規則叫數據處理不等式（data processing inequality），它表明：任何函數都無法為輸入數據增加信息量，它們僅能維持或削減既有信息量。儘管業界普遍認為神經網絡遠離輸入層的隱藏層會逐步構建更高級的特徵表示，但實際上，它們並沒有添加任何輸入數據中原本不存在的信息。&lt;/p&gt; 
&lt;p&gt;此外，非線性層肯定會造成一些信息損失。現代神經網絡中"無處不在"的一個非線性層便是 ReLU 函數 ------ 其核心運算邏輯是將所有負輸入值歸零。當 ReLU 函數在典型文本嵌入模型的許多模型層中被反覆應用後，就不可能保留輸入的所有信息。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 其他領域的信息反演問題&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;類似問題在計算機視覺領域也廣受關注。多項研究結果表明，來自圖像模型的深度表徵（本質上是嵌入向量）可以在一定程度上還原輸入的圖像。早期的一項研究（Dosovitskiy, 2016）[7]表明，可以從深度卷積神經網絡（CNN）的特徵輸出中還原圖像。研究者通過深度卷積神經網絡（CNN）提取的高層次特徵信息，可以逆向重構出輸入圖像的近似版本，儘管重構的圖像不夠清晰，但仍保留了與原圖像相似的主要特徵和結構。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3861a49cadb1410b40a829c998a40b0309e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在計算機視覺領域，反演模型（inversion models）（圖中使用黃色標註）在僅給定 ImageNet 分類器輸出的 1000 個類別概率值（其中絕大多數接近 0）的情況下，成功重建了圖像。（此圖來自《Understanding Invariance via Feedforward Inversion of Discriminatively Trained Classifiers》[8]）&lt;/p&gt; 
&lt;p&gt;自 2016 年以來，人們不斷改進圖像嵌入反演技術：已開發出具有更高精度的反演模型[8-10]，並被證明適用於更多場景[11]。令人驚訝的是，某些研究表明，僅憑 ImageNet 分類器的輸出（1000 個類別的概率值）也可以實現圖像的反演。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 vec2text 的實現之旅&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;既然圖像表徵能夠實現反演（inversion），那麼文本表徵為何不可？讓我們來思考一個簡化了的研究場景下的文本嵌入還原問題。在此實驗中，我們將文本輸入限制為 32 個詞元（tokens）（約 25 個單詞，相當於一條長度適中的句子），並將這些文本全部嵌入（embed）到由 768 個浮點數構成的向量中。若以 32 位精度（32-bit precision）計算，這些嵌入向量佔用 32 * 768 = 24,576 比特（bits）即約 3 千字節（3 kilobytes）。&lt;/p&gt; 
&lt;p&gt;用海量比特表達寥寥數詞。 在這種情況下，你認為我們能否完美地重建原始文本呢？&lt;/p&gt; 
&lt;p&gt;首先，我們需要定義一個衡量標準，用來評估我們完成任務的效果。一個直觀的指標是"精確匹配率"（exact match），即反演後得到完全一致輸入文本的頻率。現有的反演方法在該指標上都沒有取得任何成功，可見其標準之嚴苛。因此我們或許應從更平緩的指標起步 ------ 衡量復原文本與輸入文本的相似度。為此我們將採用 BLEU 分數（BLEU score），你可將其簡單理解為復原文本與原文的相似程度。&lt;/p&gt; 
&lt;p&gt;定義好評估指標後，我們將提出基於該指標的驗證方案。作為初步嘗試，我們可將反演問題轉化為傳統機器學習任務：收集海量的嵌入向量-文本配對數據集（embedding-text pairs），訓練一個以嵌入向量為輸入、輸出對應文本的模型。&lt;/p&gt; 
&lt;p&gt;這正是我們的實踐方案：&lt;strong&gt;我們構建了一個以嵌入向量為輸入的 Transformer 模型，並採用經典語言建模方法對輸出文本進行訓練。&lt;/strong&gt; 通過該初步方案，我們獲得了一個 BLEU 分數約為 30/100 的模型。實際表現中，該模型能推測輸入文本的主題並捕捉部分詞彙，但會打亂詞彙順序且多數詞彙預測錯誤。其精確匹配率趨近於零。&lt;strong&gt;事實證明：要求模型通過單次前向傳播（forward pass）逆向還原另一模型的輸出是極其困難的&lt;/strong&gt;（其他複雜文本生成任務亦如此，例如生成嚴格符合十四行詩押韻結構（perfect sonnet form）或需要同時滿足多重約束條件的文本）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-857b7b21826cc4757bc48eb4e88307ca475.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;所考察架構概述。先前工作（左圖）採用僅解碼器架構（decoder-only architecture），並將嵌入向量作為前綴輸入（prefix）。我們最初訓練的編碼器-解碼器模型（中圖）在編碼器端（encoder-side）對升維處理的語句嵌入向量進行條件化處理。在我們的最終方案（右圖）中，除了升維處理後的"假設"嵌入向量外，還額外引入了"假設"文本作為輔助輸入。&lt;/p&gt; 
&lt;p&gt;在訓練初始模型後，我們發現了一個有趣現象。&lt;strong&gt;另一種衡量模型輸出質量的方法是：對生成的文本（我們稱之為"hypothesis（假設）"）進行重嵌入處理（re-embedding），並測量該嵌入向量與真實嵌入的相似度。&lt;/strong&gt; 使用我們模型生成的文本來計算時，觀測到餘弦相似度（cosine similarity）高達 0.97。這意味着我們能生成在嵌入空間中逼近真實文本（ground-truth text）但又不完全相同的文本。&lt;/p&gt; 
&lt;p&gt;（插敍：如果情況並非如此呢？也就是説，如果嵌入模型將錯誤的生成文本與原始文本映射為完全相同的向量表示，則該嵌入器（embedder）將具有信息有損性（lossy），導致多個輸入被映射至相同的輸出。此時，問題就會無解了 ------ 因為當多個不同文本序列對應同一個嵌入向量時，系統根本無法追溯原始輸入。但在實際實驗中從未觀測到此類嵌入衝突（collisions）。）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生成文本與真實文本具有不同嵌入向量的觀察，啓發了我們採用類優化方法（optimization-like approach）實現嵌入反演。&lt;/strong&gt; 給定目標嵌入向量（即需要獲得的真實嵌入）和當前"假設"文本及其嵌入（當前狀態），可訓練一個校正器模型（corrector model）：該模型以輸出比原假設文本更接近真實嵌入的內容為訓練目標。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5ccf7487a1fba0e1ed030556f22bef9262b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Vec2Text 方法概述。在獲得目標嵌入向量 e（藍色）和調用嵌入模型 φ（藍色模型）的查詢權限後，系統通過迭代生成（黃色模型）假設嵌入 ê（粉色）來逼近目標。&lt;/p&gt; 
&lt;p&gt;我們的目標現已明確：構建一個能同時接收真實嵌入向量、"假設"文本序列及其嵌入空間位置作為輸入，並預測原始文本序列的系統。我們將此視為一種"學習型優化"（learned optimization） ------ 以離散序列的形式在嵌入空間中逐步推進。這正是我們命名為 vec2text 的方法核心。&lt;/p&gt; 
&lt;p&gt;在對一些細節進行處理並對模型進行訓練後，可得知該方法效果極佳！單次校正前向傳播即可將 BLEU 分數從 30 提升到 50。該模型的優勢在於天然支持遞歸查詢：給定當前文本及其嵌入向量，可運行多個優化步驟，迭代生成"假設"文本，重新將它們嵌入，並將其作為輸入反饋給模型。&lt;strong&gt;經過 50 步迭代和若干優化技巧，我們實現了：32 詞元序列的精確還原率達 92%，BLEU 分數達到 97！（通常達到 97 的 BLEU 分數意味着近乎完美重建每個句子，可能偶爾出現標點偏差。）&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 未來工作方向&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;文本嵌入向量能夠被完美反演（inverted）這一事實引出了諸多後續問題。首先，文本嵌入向量包含了固定的比特數量；當序列長度超過一定閾值時，信息必然無法完美存儲於此向量中。儘管我們能復原大多數長度為 32 詞元的文本，但某些嵌入模型可處理長達數千詞元的文檔。&lt;strong&gt;文本長度、嵌入維度與嵌入可逆性的關係分析將留給未來研究。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;另一待解問題是：如何構建能防禦反演攻擊的系統。是否存在一種模型，既能有效生成有實用價值的文本嵌入，又能對原始文本進行混淆處理？&lt;/p&gt; 
&lt;p&gt;最後，我們期待該方法在其他模態中的應用前景。vec2text 的核心思想（在嵌入空間中實施迭代式優化）未使用任何文本模態專用的技巧。這是一種通過黑盒訪問模型逐步還原任意固定輸入信息的方法。&lt;strong&gt;這些理念如何應用於其他模態嵌入的反演，以及更廣義的非嵌入反演方法，仍有待探索。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;若需使用我們的模型反演文本嵌入，或自行開展嵌入反演實驗，請訪問 Github 倉庫：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjxmorris12%2Fvec2text" target="_blank"&gt;https://github.com/jxmorris12/vec2text&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Inverting Visual Representations with Convolutional Networks (2015), &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1506.02753" target="_blank"&gt;https://arxiv.org/abs/1506.02753&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Understanding Invariance via Feedforward Inversion of Discriminatively Trained Classifiers (2021), &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.mlr.press%2Fv139%2Fteterwak21a%2Fteterwak21a.pdf" target="_blank"&gt;https://proceedings.mlr.press/v139/teterwak21a/teterwak21a.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text Embeddings Reveal (Almost) As Much As Text (2023), &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2310.06816" target="_blank"&gt;https://arxiv.org/abs/2310.06816&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Language Model Inversion (2024), &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2311.13647" target="_blank"&gt;https://arxiv.org/abs/2311.13647&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓文章揭示的文本嵌入向量可逆性（近乎完美還原 32 詞元文本），是否讓你對將敏感數據存儲在向量數據庫中感到擔憂？你的公司/項目會因此重新評估使用向量數據庫存儲敏感文本的策略嗎？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2020%2Ffile%2F6b493230205f780e1bc26945df7481e5-Paper.pdf" target="_blank"&gt;https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F27%2Fpinecone-drops-100m-investment-on-750m-valuation-as-vector-database-demand-grows%2F" target="_blank"&gt;https://techcrunch.com/2023/04/27/pinecone-drops-100m-investment-on-750m-valuation-as-vector-database-demand-grows/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F04%2F06%2Fchroma-bags-18m-speed-ai-models-embedding-database%2F" target="_blank"&gt;https://siliconangle.com/2023/04/06/chroma-bags-18m-speed-ai-models-embedding-database/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fweaviate-raises-50-million-series-b-funding-to-meet-soaring-demand-for-ai-native-vector-database-technology-301803296.html" target="_blank"&gt;https://www.prnewswire.com/news-releases/weaviate-raises-50-million-series-b-funding-to-meet-soaring-demand-for-ai-native-vector-database-technology-301803296.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F19%2Fqdrant-an-open-source-vector-database-startup-wants-to-help-ai-developers-leverage-unstructured-data%2F" target="_blank"&gt;https://techcrunch.com/2023/04/19/qdrant-an-open-source-vector-database-startup-wants-to-help-ai-developers-leverage-unstructured-data/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2310.06816" target="_blank"&gt;https://arxiv.org/abs/2310.06816&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_cvpr_2016%2Fpapers%2FDosovitskiy_Inverting_Visual_Representations_CVPR_2016_paper.pdf" target="_blank"&gt;https://openaccess.thecvf.com/content_cvpr_2016/papers/Dosovitskiy_Inverting_Visual_Representations_CVPR_2016_paper.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2103.07470.pdf" target="_blank"&gt;https://arxiv.org/pdf/2103.07470.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1806.00400" target="_blank"&gt;https://arxiv.org/abs/1806.00400&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2008.01777" target="_blank"&gt;https://arxiv.org/abs/2008.01777&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2112.09164" target="_blank"&gt;https://arxiv.org/abs/2112.09164&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;本文經原作者授權，由&lt;/strong&gt; &lt;strong&gt;Baihai IDP&lt;/strong&gt; &lt;strong&gt;編譯。如需轉載譯文，請聯繫獲取授權。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthegradient.pub%2Ftext-embedding-inversion%2F" target="_blank"&gt;https://thegradient.pub/text-embedding-inversion/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18683492</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18683492</guid>
      <pubDate>Sat, 10 May 2025 08:40:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Jakarta EE 11 發佈：帶來 1 個新規範、16 個更新規範與現代化 TCK</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;雖然 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Frelease%2F11%2F" target="_blank"&gt;Jakarta EE 11&lt;/a&gt; 的完整 GA 版本最初計劃在 2024 年 7 月發佈，但只有 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fcoreprofile%2F11%2F" target="_blank"&gt;Core Profile&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fwebprofile%2F11%2F" target="_blank"&gt;Web Profile&lt;/a&gt; 分別於 2024 年 12 月和 2025 年 4 月先行交付。如今，距離 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoq.com%2Fnews%2F2022%2F09%2Fjakarta-ee-10-updates%2F" target="_blank"&gt;Jakarta EE 10 發佈&lt;/a&gt;的 34 個月後，Eclipse 基金會 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsroom.eclipse.org%2Fnews%2Fannouncements%2Feclipse-foundation%25E2%2580%2599s-jakarta-ee-working-group-announces-jakarta-ee-11-release" target="_blank"&gt;正式宣佈發佈&lt;/a&gt; 了包含 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fplatform%2F11%2F" target="_blank"&gt;Platform&lt;/a&gt; 的 Jakarta EE 11。雖然這次發佈可能又被認為是「又一次重大延遲」，但背後有實際原因。&lt;/p&gt; 
&lt;p&gt;截至 2024 年 5 月，面向 Jakarta EE 11 的 16 個更新規範均已通過各自的評審與 TCK 測試，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fabout%2Fworking-group%2F" target="_blank"&gt;Jakarta EE 工作組&lt;/a&gt; 決定專注於久拖未決的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprojects.eclipse.org%2Fprojects%2Fee4j.jakartaee-tck" target="_blank"&gt;技術兼容性套件 TCK&lt;/a&gt; 現代化與重構。主要工作內容包括構建工具與測試套件的遷移：如 Ant 遷移到 Maven，TestHarness 遷移到 Arquillian。同時，藉助開源自動重構工具 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.openrewrite.org%2F" target="_blank"&gt;OpenRewrite&lt;/a&gt; 實現自動化遷移。這項投入帶來的好處是提升了兼容性測試能力，併為 Jakarta EE 生態的擴展和測試新增降低了門檻。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jakarta EE 11 平台&lt;/strong&gt; 定義了託管所有 Jakarta EE 應用的標準平台，適用於需要 Jakarta EE 全部規範開發企業應用的開發者。平台所包含的規範如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcamo.githubusercontent.com%2F5cdfe347dd4a22ca532ed105475337a1febe1e734cded8a48ab01211d7fbb629%2F68747470733a2f2f696d676f70742e696e666f712e636f6d2f6669742d696e2f3330303078343030302f66696c746572733a7175616c697479283835292f66696c746572733a6e6f5f75707363616c6528292f6e6577732f323032352f30372f6a616b617274612d65652d31312d757064617465732f656e2f7265736f75726365732f32696e666f712d706c6174666f726d2d313735313331383839323435392e706e67" target="_blank"&gt;&lt;img alt="Jakarta EE 11 Platform" src="https://oscimg.oschina.net/oscnet//a82efdef08ff5b226ab585c093ca8f4a.jpg" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jakarta EE 11 Web Profile&lt;/strong&gt; 定義了 Jakarta EE 平台的子集，專注於開發 Web 應用的相關技術。其包含的規範如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcamo.githubusercontent.com%2F6fc4c31a650a950847734dd8e650b48497ccf2fe24c47f0940910352a6849383%2F68747470733a2f2f696d676f70742e696e666f712e636f6d2f6669742d696e2f3330303078343030302f66696c746572733a7175616c697479283835292f66696c746572733a6e6f5f75707363616c6528292f6e6577732f323032352f30372f6a616b617274612d65652d31312d757064617465732f656e2f7265736f75726365732f32696e666f712d7765622d70726f66696c652d313735313331383839323435392e706e67" target="_blank"&gt;&lt;img alt="Jakarta EE 11 Web Profile" src="https://camo.githubusercontent.com/6fc4c31a650a950847734dd8e650b48497ccf2fe24c47f0940910352a6849383/68747470733a2f2f696d676f70742e696e666f712e636f6d2f6669742d696e2f3330303078343030302f66696c746572733a7175616c697479283835292f66696c746572733a6e6f5f75707363616c6528292f6e6577732f323032352f30372f6a616b617274612d65652d31312d757064617465732f656e2f7265736f75726365732f32696e666f712d7765622d70726f66696c652d313735313331383839323435392e706e67" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Web Profile 於 2025 年 4 月發佈，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Feclipse-ee4j%2Fglassfish%2Freleases%2Ftag%2F8.0.0-M11" target="_blank"&gt;Eclipse GlassFish 8.0.0-M11&lt;/a&gt; 成為其首個兼容實現。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jakarta EE 11 Core Profile&lt;/strong&gt;（自 Jakarta EE 10 引入）定義了面向小型運行時的 Jakarta EE 平台子集，適用於微服務和 AOT（提前編譯）場景。它為雲原生運行時（包括支持構建時應用的運行時）提供最小基礎。包含的規範如下圖：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcamo.githubusercontent.com%2Fa98e039f7870f87514413870d96c5235b4469ddf0d8650b5972af5884dbbdac3%2F68747470733a2f2f696d676f70742e696e666f712e636f6d2f6669742d696e2f3330303078343030302f66696c746572733a7175616c697479283835292f66696c746572733a6e6f5f75707363616c6528292f6e6577732f323032352f30372f6a616b617274612d65652d31312d757064617465732f656e2f7265736f75726365732f33696e666f712d636f72652d70726f66696c652d313735313331383839323435392e706e67" target="_blank"&gt;&lt;img alt="Jakarta EE 11 Core Profile" src="https://camo.githubusercontent.com/a98e039f7870f87514413870d96c5235b4469ddf0d8650b5972af5884dbbdac3/68747470733a2f2f696d676f70742e696e666f712e636f6d2f6669742d696e2f3330303078343030302f66696c746572733a7175616c697479283835292f66696c746572733a6e6f5f75707363616c6528292f6e6577732f323032352f30372f6a616b617274612d65652d31312d757064617465732f656e2f7265736f75726365732f33696e666f712d636f72652d70726f66696c652d313735313331383839323435392e706e67" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Core Profile 僅含 7 個規範，由於體量小，成為 2024 年 12 月首個發佈的 profile。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjakartaee%2Fplatform%2Fissues%2F978" target="_blank"&gt;WildFly Preview&lt;/a&gt; 34.0.0 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjakartaee%2Fplatform%2Fissues%2F975" target="_blank"&gt;Open Liberty&lt;/a&gt; 24.0.0.11-beta 於 2024 年 10 月下旬提交了兼容性認證請求。&lt;/p&gt; 
&lt;p&gt;如上圖所示，Jakarta EE 11 生態共有 16 個&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2F" target="_blank"&gt;規範&lt;/a&gt;獲得更新。需要注意，有兩個規範進行了更名：&lt;strong&gt;Jakarta Validation&lt;/strong&gt;（原名 &lt;strong&gt;Jakarta Bean Validation&lt;/strong&gt;）與 &lt;strong&gt;Jakarta Pages&lt;/strong&gt;（原名 &lt;strong&gt;Jakarta Server Pages&lt;/strong&gt;）。&lt;strong&gt;Jakarta Server Faces&lt;/strong&gt; 早在 Jakarta EE 10 時已更名為 &lt;strong&gt;Jakarta Faces&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fdata%2F1.0" target="_blank"&gt;Jakarta Data 1.0&lt;/a&gt; 作為 Jakarta EE 11 Platform 和 Web Profile 的新規範，為數據庫技術提供簡便訪問 API。它可以將持久化邏輯與模型分離，並支持在 &lt;strong&gt;&lt;code&gt;Repository&lt;/code&gt;&lt;/strong&gt; 接口上組合自定義查詢方法，由框架自動實現。目前的 Jakarta Data 實現包括 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhibernate.org%2Form%2F" target="_blank"&gt;Hibernate ORM&lt;/a&gt; 6.6.0、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jnosql.org%2F" target="_blank"&gt;Eclipse JNoSQL&lt;/a&gt; 1.1.4 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenliberty.io%2F" target="_blank"&gt;Open Liberty&lt;/a&gt; 24.0.0.6。&lt;/p&gt; 
&lt;p&gt;Jakarta EE 11 其他值得關注的變更包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fexpression-language%2F" target="_blank"&gt;Jakarta Expression Language&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fpersistence%2F" target="_blank"&gt;Jakarta Persistence&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fbean-validation%2F" target="_blank"&gt;Jakarta Validation&lt;/a&gt; 規範增加對 Java Record 的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fconcurrency%2F" target="_blank"&gt;Jakarta Concurrency&lt;/a&gt; 規範在 JDK 21 下支持虛擬線程（Virtual Threads）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CDI Lite&lt;/strong&gt;：新增文檔以補充 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fcdi%2F" target="_blank"&gt;Jakarta Contexts and Dependency Injection&lt;/a&gt; 規範，將集成相關內容獨立出來，解決規範間循環依賴問題。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fsoap-attachments%2F" target="_blank"&gt;Jakarta SOAP with Attachments&lt;/a&gt;、&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fxml-web-services%2F" target="_blank"&gt;Jakarta XML Web Services&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Fxml-binding%2F" target="_blank"&gt;Jakarta XML Binding&lt;/a&gt; 規範移除了自 Jakarta EE 10 起的可選特性。&lt;/li&gt; 
 &lt;li&gt;移除對已在 JDK 17 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F411" target="_blank"&gt;棄用&lt;/a&gt; 並在 JDK 24 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F486" target="_blank"&gt;徹底移除&lt;/a&gt; 的 Java &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.oracle.com%2Fen%2Fjava%2Fjavase%2F24%2Fdocs%2Fapi%2Fjava.base%2Fjava%2Flang%2FSecurityManager.html" target="_blank"&gt;&lt;code&gt;SecurityManager&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt; 的引用。&lt;/li&gt; 
 &lt;li&gt;移除遺留的 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjakarta.ee%2Fspecifications%2Ffaces%2F3.0%2Fapidocs%2Fjakarta%2Ffaces%2Fbean%2Fmanagedbean" target="_blank"&gt;&lt;code&gt;@ManagedBean&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt; 註解。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;微軟 Java 首席架構師、Jakarta EE 11 發佈協調人 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fedburns%2F" target="_blank"&gt;Ed Burns&lt;/a&gt; 在接受 InfoQ 採訪時表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;企業軟件開發正處於關鍵轉折點。生成式 AI 推動了產品開發速度的預期，這直接挑戰了 Jakarta EE 一貫的、基於標準且緩慢的開發節奏。&lt;/p&gt; 
 &lt;p&gt;雖然 Jakarta EE 11 的發佈比我期望的要晚得多，但它體現了我們正邁向更快發展的兩個重要方面：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;證明全新技術可以被納入標準並帶來價值。&lt;/li&gt; 
  &lt;li&gt;完成了 Jakarta EE 歷史上最大規模的技術債務償還。&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;就第一點來説，Jakarta Data 充分體現了標準的價值：吸取已有經驗並服務更廣泛的用户羣，而不是侷限於某單一廠商。&lt;/p&gt; 
 &lt;p&gt;就第二點而言，Jakarta EE TCK 已遷移至當前主流測試技術，擺脱了對一個自 JUnit 普及前就無人維護的測試工具的依賴。&lt;/p&gt; 
 &lt;p&gt;Jakarta EE 11 還有許多其他增量改進，對於一個強調穩定與 IT 投資保護的技術而言，這再合適不過。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;2023 年 3 月，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fsmillidge%2F" target="_blank"&gt;Payara CEO Steve Millidge&lt;/a&gt; 曾撰文指出 Jakarta EE 11 可能是「&lt;em&gt;Jakarta 的第一次重大飛躍&lt;/em&gt;」：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;從最初的遷移（Jakarta EE 8），到新的命名空間（Jakarta EE 9），再到簡化工作（Jakarta EE 10），Jakarta EE 已為開源開發者打下堅實基礎。&lt;/p&gt; 
 &lt;p&gt;如今，機會來了。Jakarta EE 可藉助 Java 21 等新特性，持續構建新規範，進一步統一併簡化平台，真正邁出 Java EE 時代。&lt;/p&gt; 
 &lt;p&gt;對於 Jakarta EE 11 來説，在擁有新規範和全新 TCK 的同時，Millidge 兩年前的展望似已逐步實現。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;更多關於 Jakarta EE 11 新特性的介紹，可閲讀 Eclipse 基金會 Jakarta EE 項目經理 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Fin%2Ftanja-obradovic-095604%2F" target="_blank"&gt;Tanja Obradovic&lt;/a&gt; 的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.eclipse.org%2Fpost%2Ftatjana-obradovic%2Fjakarta-ee-11-empowering-enterprise-java-developers-enhanced-productivity" target="_blank"&gt;官方博客&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;號外： 對 JakartaEE 感興趣的同學，不要錯過本年度 JakartaONE 2025 在線會議，請移步註冊：https://www.eventbrite.com/e/jakartaone-livestream-2025-tickets-1394939173619&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358768</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358768</guid>
      <pubDate>Sat, 10 May 2025 07:53:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>法國 AI 研究機構開源 Kyutai TTS，低延遲流式文本轉語音技術</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;法國 AI 研究機構 Kyutai Labs 宣佈開源其最新文本轉語音（TTS）技術——Kyutai TTS，這是一個實時的語音生成解決方案。Kyutai TTS 以低延遲與高保真聲音為亮點，支持文本流式傳輸，無需完整文本即可開始生成音頻，特別適合實時交互場景。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0704/145146_pipR_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkyutai.org%2Fnext%2Ftts" target="_blank"&gt;https://kyutai.org/next/tts&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Kyutai TTS 在性能上表現卓越。使用單塊 NVIDIA L40S GPU，該模型可同時處理 32 個請求，延遲僅為 350 毫秒。此外，系統不僅生成高質量音頻，還能輸出單詞的精確時間戳，方便實時字幕生成或交互式應用，如 Unmute 平台的中斷處理功能。&lt;/p&gt; 
&lt;p&gt;在語言支持與質量評估方面，Kyutai TTS 目前支持英語和法語，單詞錯誤率（WER）分別為 2.82 和 3.29，展現出高準確度。説話者相似度達到 77.1%(英語) 和 78.7%(法語)，確保語音自然且接近原始樣本。模型還能處理長篇文章，突破傳統 TTS 的 30 秒限制，適合新聞、書籍等長篇內容生成。&lt;/p&gt; 
&lt;p&gt;Kyutai TTS 採用延遲流建模（DSM）架構，結合 Rust 服務器實現高效批處理，已在 GitHub 和 Hugging Face 開放源碼與模型權重，助力全球開發者推動語音技術創新。&lt;/p&gt; 
&lt;p&gt;開源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkyutai-labs%2Fdelayed-streams-modeling" target="_blank"&gt;https://github.com/kyutai-labs/delayed-streams-modeling&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358755</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358755</guid>
      <pubDate>Sat, 10 May 2025 06:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技或於科創板 IPO</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;據《每日經濟新聞》從宇樹科技相關投資方獲悉，宇樹科技後續有計劃於科創板 IPO（首次公開募股）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-b580657b265e86eea613b405eac902d810a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月 29 日，宇樹科技發佈通知稱，因公司發展需要，杭州宇樹科技有限公司即日起名稱變更為「杭州宇樹科技股份有限公司」。彼時，有媒體報道稱，宇樹科技這一舉動可視同完成股改。至於為何變更名稱，外界認為或許是為了 IPO 鋪路。而宇樹科技曾回應，「這是公司運營方面的常規變更」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;6 月份消息，宇樹科技已完成了始於去年 9 月的 C 輪融資交割，由中國移動旗下基金、騰訊、錦秋、阿里、螞蟻、吉利資本共同領投，絕大部分老股東跟投。融資金額接近 7 億元人民幣，投後估值超 120 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技創始人兼 CEO 王興興還在夏季達沃斯論壇上透露，公司年度營收已超 10 億元人民幣。此前也有宇樹科技投資人透露，自 2020 年起，宇樹科技已連續 5 年實現盈利。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/352690" target="_blank"&gt;宇樹科技回應更名 「股份有限公司」&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/356437" target="_blank"&gt;宇樹科技確認：近期已完成 C 輪融資交割&lt;/a&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/357324" target="_blank"&gt;宇樹科技王興興：公司目前年度營收超過十億元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358747</guid>
      <pubDate>Sat, 10 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>印度程序員用一份假簡歷騙了 5 家硅谷 AI 公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 時代「最強」打工王者出現了。近期，一名叫 Soham Parekh 的印度程序員被曝通過一份假簡歷，在多家硅谷 AI 初創公司進行遠程兼職，最多時同時打了五份工，領取多份工資，引發廣泛關注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b140ce1925eb09a92af71a5196c086da0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Playground AI 的創始人 Sohail Doshi 最早發文爆料，稱這名印度工程師靠着一份幾乎 90% 造假的簡歷，同時在 3-5 家初創公司上班。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a368826a86d01bca7fba881f66b1122a59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sohail Doshi 表示，入職第一週就發現對方不對勁，於是立馬開除，臨走前還苦口婆心地勸對方別再騙人了，沒想到這位印度工程師非但沒收手，還越戰越勇，繼續多線作戰。&lt;/p&gt; 
&lt;p&gt;後續，風投機構 YC 總裁 Garry Tan 也親自下場發文表示，如果沒有 YC 社區，這個人可能還在繼續操作，甚至永遠不會被發現。&lt;/p&gt; 
&lt;p&gt;據 Garry Tan 的説法，&lt;strong&gt;這位印度工程師專挑 YC 支持的創業公司下手，同時在至少三家由 YC 支持的創業公司打卡上班，最多甚至五家，並且每家公司都以為他是全職&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-627ac6534e25a6f42898e1b76863c6317df.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，Soham Parekh 雖然在簡歷和麪試這兩方面堪稱完美，但在正式工作（或者工作試用期）真正開始的時候， 他會找一個又一個的藉口，解釋為什麼缺席會議，或者為什麼工作被推遲，亦或者他每天都會找個藉口請假半天，比如説要見律師。後面，這些藉口越來越荒謬，直到所有人開始意識到他明顯在撒謊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358729</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358729</guid>
      <pubDate>Sat, 10 May 2025 04:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>號碼生成系統的創新實踐：遊戲週週樂幸運碼設計</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者： vivo 互聯網服務器團隊- Zhang Jing&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文以遊戲週週樂的幸運碼為切入點，針對其生成過程中涉及的隨機性、唯一性及高併發等特點，設計了一種基於號段+子碼的創新架構。該方案不僅在生成速度上表現突出，還顯著提升了存儲效率，同時降低了擴容成本，為類似的號碼生成系統提供了設計上的新思路和啓發。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;文章太長？1 分鐘看圖抓住核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d0f19634e0555861f34c6d1a965332e5035.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;一、業務背景&lt;/h1&gt; 
&lt;p&gt;用户可通過完成相關任務獲取週週樂幸運碼，幸運碼的投放規則如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;基礎投放量&lt;/strong&gt;：每期 100 萬注唯一無重複的 6 位數字幸運碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;動態擴容機制&lt;/strong&gt;：參與人數超額時，可實時追加 100 萬注&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;二、幸運碼特性&lt;/h1&gt; 
&lt;p&gt;根據背景介紹，我們可以知道幸運碼需要支持如下特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;隨機性&lt;/strong&gt;，發給每個用户的幸運碼都是隨機的，同時每個用户領取的多個幸運碼也是隨機的。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唯一性&lt;/strong&gt;，每一組的幸運碼中，各幸運碼都是唯一的。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;範圍性&lt;/strong&gt;，幸運碼嚴格限定在 000000 到 999999 區間內。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高併發&lt;/strong&gt;，幸運碼的生成和發放需要支持高併發，能夠至少達到 300QPS。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可追加&lt;/strong&gt;，在當期活動非常火爆時，需要可臨時追加一組幸運碼庫存。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;三、方案選型&lt;/h1&gt; 
&lt;p&gt;鑑於幸運碼需嚴格限定在 6 位數字範圍內（000000-999999），傳統雪花算法因生成超長 ID（64 位二進制）且依賴時間戳遞增特性，難以直接適配。以下將對比三種方案：實時隨機生成模式、預生成庫存模式及號段+子碼模式，並會根據生成速度、存儲效率、擴容成本三個核心指標進行系統性評估，最終選擇出最優解決方案。&lt;/p&gt; 
&lt;h2&gt;3.1 方案一：實時隨機生成模式&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;實現邏輯：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;生成隨機數&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;再查詢數據庫是否有該隨機數&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若沒有則入庫，完成幸運碼發放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若有再重新執行第一步&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;缺陷分析：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;碰撞概率隨庫存消耗不斷上升&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;數據庫 IO 壓力隨併發量線性增長&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不滿足高併發場景性能要求&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.2 方案二：預生成庫存模式&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;實現邏輯：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;採用預生成幸運碼方式：離線生成 100 萬個幸運碼，隨機打散，寫入數據庫，每個幸運碼對應一個從 1 自增的序列號，並使用 Redis 記錄幸運碼序列號索引，初始值為 1。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;發放步驟&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;從 Redis 查詢幸運碼序列號索引&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用該索引查詢幸運碼，並完成幸運碼發放&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遞增 Redis 的序列號索引，確保序列號索引關聯的幸運碼是下一個可發放的幸運碼&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;缺陷分析：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存儲空間浪費&lt;/strong&gt;：未發放號碼佔用存儲&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;擴容效率低下&lt;/strong&gt;：追加庫存需重新預生成&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3.3 方案三：號段+子碼模式&lt;/h2&gt; 
&lt;p&gt;採用號段+子碼機制：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;號段管理&lt;/strong&gt;：將 10^6 號碼劃分為 1000 個號段（號段值：0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;子碼管理&lt;/strong&gt;：每個號段維護 1000 個可用子碼（子碼值：0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成規則&lt;/strong&gt;：幸運碼=隨機號段*1000+隨機子碼（示例：129358=129*1000+358）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-45d325576bad2645b81b131cf8277e2e471.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.4 方案對比&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-079c02eb66e15c161b0b30001341fb6548d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;綜上，我們綜合幸運碼生成速度、存儲效率、擴容成本等指標，最終採用了號段+子碼模式來生成幸運碼。&lt;/p&gt; 
&lt;h1&gt;四、關鍵技術實現&lt;/h1&gt; 
&lt;h2&gt;4.1 號段分層機制&lt;/h2&gt; 
&lt;p&gt;將 100 萬注幸運碼劃分為 1000 個號段（每段 1000 注），每個號段由兩部分組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;號段 ID&lt;/strong&gt;：號段 ID 為唯一且不重複的整數，範圍介於 0 到 999 之間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;子碼串&lt;/strong&gt;：1000 位字符串，採用"01"標記使用狀態，0 表示未使用，1 表示已使用，初始全 0。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;幸運碼生成公式：&lt;/p&gt; 
&lt;p&gt;幸運碼 = 號段 ID * 1000 + 子碼位置&lt;/p&gt; 
&lt;p&gt;該設計既保留了生成幸運碼的隨機性（號段 ID 隨機+子碼隨機），又通過子碼的類比特位存儲方式提升了存儲效率。&lt;/p&gt; 
&lt;h2&gt;4.2 分佈式併發控制&lt;/h2&gt; 
&lt;h3&gt;4.2.1 多級緩存策略&lt;/h3&gt; 
&lt;p&gt;Redis 存儲可用號段集合，若號段的子碼使用完，該號段會從 Redis 集合中剔除，同時本地緩存也會預加載可用號段，確保發碼時能更高效地獲取候選號段。&lt;/p&gt; 
&lt;h3&gt;4.2.2 高效鎖搶佔策略&lt;/h3&gt; 
&lt;p&gt;系統為每個號段分配了分佈式鎖，當執行發放幸運碼時，會從本地緩存隨機獲取 15 個候選號段。然後在遍歷獲取號段時，將等待鎖的超時時間設置成 30ms，確保號段被佔用的情況下能夠快速遍歷到下一個號段（根據實際場景統計，等待鎖的情況很少發生，一般最多遍歷到第二個號段即可成功搶佔）。一旦成功獲得號段的分佈式鎖後，便可進一步隨機獲取該號段下的可用子碼。&lt;/p&gt; 
&lt;h3&gt;4.2.3 動態庫存策略&lt;/h3&gt; 
&lt;p&gt;要追加庫存，只需再創建一組幸運碼號段，並寫入 Redis，後續發放時獲取該組的可用號段生成幸運碼即可。從性能和存儲空間上遠優於預生成方式。&lt;/p&gt; 
&lt;h2&gt;4.3 幸運碼發放&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;發放步驟&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;隨機獲取至多 15 個可用號段&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍歷號段&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;搶佔號段的分佈式鎖&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若號段的分佈式鎖搶佔成功，則隨機獲取號段中可用的子碼，再根據號段和子碼生成幸運碼&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若號段的分佈式鎖搶佔失敗，則遍歷下一個號段，並重覆上述步驟&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18b4f57ed57a5e892f4084f7f66b15e177f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;五、總結&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;（1）雙重隨機保障&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一級隨機：號段選擇隨機（0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;二級隨機：子碼選擇隨機（0-999）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過號段隨機和子碼隨機方式確保生成的幸運碼完全隨機&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（2）數據唯一性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通過號段唯一和號段內的子碼唯一確保生成的幸運碼全局唯一&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（3）彈性擴展能力&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;擴容耗時僅需秒級別&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存儲空間相比預生成方案節省 80%&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（4）高性能發放&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通過多重緩存及高效號段搶佔策略大幅提升幸運碼生成效率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;實測 QPS&amp;gt;300，平均響應時間&amp;lt;15ms&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本設計方案通過創新的號段+子碼管理機制，在保證號碼隨機性和唯一性的同時，實現了高併發場景下的穩定服務能力，為類似號碼生成系統的設計提供了可複用的架構範式。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18683260</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18683260</guid>
      <pubDate>Sat, 10 May 2025 03:44:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>​前 OpenAI 研究員揭露：簽約 Meta 並未獲 1 億美元獎金</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期，一位前 OpenAI 研究員的言論引發了廣泛關注。他表示，儘管 Meta 公司在挖角 OpenAI 的科研人才時聲稱提供高達 1 億美元的簽約獎金，但他和他的同事並未收到這筆獎金。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="386" src="https://oscimg.oschina.net/oscnet/up-48f34a74f8c7850e98ec9150ffd25671085.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這位研究員名叫盧卡斯・貝耶爾（Lucas Beyer），他和同事亞歷山大・科列斯尼科夫 (Alexander Kolesnikov)、翟曉華 (Xiaohua Zhai) 在去年 11 月加入 OpenAI，並共同設立了該公司在蘇黎世的辦公室。根據《商業內幕》的報道，這三位前 Google DeepMind 的研究科學家近期選擇離開 OpenAI，加入了 Meta。貝耶爾在社交媒體上公開表示，他和同事並沒有獲得 Meta 所宣傳的 1 億美元簽約獎金，這一消息引發了網友們的熱議。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在貝耶爾的社交媒體帖子下，許多人對此表示同情，認為他在職業生涯中作出了重要的選擇，但同時也有網友認為他選擇了離開 OpenAI 並獲得了相應的經濟補償，是他應得的結果。與此同時，Meta 也在加速發展，並向數據標註公司 Scale AI 投資了 150 億美元。預計該公司的創始人兼首席執行官 Alexandr Wang 將辭職加入 Meta，與貝耶爾等人一起合作研發&lt;span&gt;超級&lt;/span&gt;智能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對此，OpenAI 的現任研究人員可能會感到一絲寬慰，因為儘管 Meta 多次試圖挖走他們，但目前尚未有員工接受這份工作。OpenAI 首席執行官 Sam Altman 在一次節目中提到，Meta 正在積極招聘，希望從其他 AI 公司中挖走優秀人才，但他認為這種方式並不會創造出良好的企業文化。他同時也表達了對 Meta 在創新能力上的一些保留態度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;至今，Meta 尚未對此事作出任何正式回應，而貝耶爾的聲明則給人們帶來了更多的思考。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358715</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358715</guid>
      <pubDate>Sat, 10 May 2025 03:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Ollama v0.9.5 發佈：支持跨平台網絡共享、性能優化升級</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源本地大模型運行工具 Ollama 發佈了 v0.9.5 版本，帶來了跨平台網絡共享功能、靈活的模型目錄管理以及 macOS 端的原生化改進和性能優化，極大提升了用户體驗和應用價值。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0612ff6688c843662d35acf99da9484e2db.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;功能改進&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;跨平台網絡共享功能&lt;/strong&gt; ：首次引入 「Expose Ollama on the network」，允許用户將運行在一台設備上的 Ollama 實例，通過 LAN 局域網甚至互聯網暴露給其他設備使用。比如在性能強大的 Mac、PC 或 Linux 服務器上運行 Ollama，讓配置較弱的筆記本、平板甚至智能手機遠程調用模型服務，還可實現團隊內部模型資源共享，提升協同開發效率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;靈活的模型目錄管理&lt;/strong&gt; ：用户可將模型存儲至外部硬盤或其他位置，打破此前版本模型存儲路徑固定的限制，保障磁盤空間與管理便捷性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 端原生化改進和性能優化&lt;/strong&gt; ：實現原生應用轉型，區別於以往基於跨平台框架打包的版本，原生 app 啓動流程經優化後啓動時間顯著縮短，僅包含必需的系統組件使安裝體積變小，且支持 macOS 原生通知、快捷鍵、深色模式等功能無縫結合。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;已解決的問題&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 命令行工具未安裝問題&lt;/strong&gt; ：解決了 macOS 啓動過程中 CLI 未被順利安裝的問題，確保開發者及高級用户通過終端調用時的連貫體驗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ollama-darwin.tgz 文件數字簽名問題&lt;/strong&gt; ：修復了某些文件未進行蘋果開發者認證簽名，避免 macOS 的安全警告與功能限制。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增加社區集成支持&lt;/strong&gt; ：引入 NativeMind 作為社區集成組件，拓展生態功能性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama%2Freleases%2Ftag%2Fv0.9.5" target="_blank"&gt;https://github.com/ollama/ollama/releases/tag/v0.9.5&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358712/ollama-0-9-5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358712/ollama-0-9-5</guid>
      <pubDate>Sat, 10 May 2025 02:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>LiblibAI 正式推出 Lovart 國內版本「星流 Agent」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，LiblibAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMRJOdgJZaYL2Ocn8fnc5HQ"&gt;推出&lt;/a&gt;Lovart 國內版本「星流 Agent」，定位為一款面向中文創作者的智能設計拍檔。產品延續 Lovart 海外版本的核心能力，支持自然語言生成整套設計物料，包含主圖、海報、社媒封面、視頻動畫及 3D 模型等。系統已接入十餘個主流大模型，支持圖像、視頻、聲音、3D 的一站式生成與導出。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b48e5a2b164ddb85b9eab30d0fb019dfa69.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，星流 Agent 的核心能力包括全流程自動化設計，用户輸入簡單需求後，Agent 能自動拆解任務、確定風格並生成包括主圖、延展圖、社交媒體封面在內的全套視覺物料。它還引入了「無邊畫布」和智能協作編輯功能，支持在畫布內進行多輪對話式改圖、修圖、換圖和調整構圖。&lt;/p&gt; 
&lt;p&gt;此外，星流 Agent 背後接入了 F.1、Kling、Qwen 等十多個頂尖模型，能自動調用最合適的模型組合，一站式生成圖像、視頻、聲音、3D 等多種模態內容，並支持多種格式導出。&lt;/p&gt; 
&lt;p&gt;目前星流 Agent 已在 PC 端及移動端同步上線。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.xingliu.art%2F%C2%A0"&gt;https://www.xingliu.art/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358708</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358708</guid>
      <pubDate>Sat, 10 May 2025 02:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 代碼編輯器 Cursor 發佈 1.2：新增 Agent Planning、Memories 正式 GA</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 代碼編輯器 Cursor 發佈了 1.2 版本，帶來了多項功能增強。&lt;/p&gt; 
&lt;p&gt;新版本引入了 Agent Planning 功能，通過結構化的待辦事項列表（To-do lists）幫助 Agent 更好地規劃和執行長時程任務。用户現在可以為 Agent 排隊發送後續指令，無需等待當前任務完成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103205_n4EJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，"Memories"功能正式 GA，改進了記憶生成質量和 UI。代碼庫搜索功能通過新的嵌入模型和優化的提示詞變得更加準確，同時新增了對 PR、issue、commit 和分支的語義搜索和上下文提取能力。Tab 代碼補全速度提升了約 100 毫秒，Agent 也具備瞭解決合併衝突的能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103244_iVp5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，Cursor 的 CEO 在官方論壇發文，澄清了 6 月 16 日對 Pro 套餐的調整。新方案從請求次數限制改為算力限制，Pro 用户每月可獲得至少等值 20 美元 API 價格的模型推理額度，並取消了 Agent 的工具調用次數限制。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0704/103432_ObdB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/355977" target="news"&gt;Cursor 推出月費 200 美元的 Ultra 計劃，Pro 計劃將更新為「不限量但有速率限制」的模式&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;官方文檔中還提到了新的 Pro+（60 美元/月，3 倍額度）和 Ultra（200 美元/月，20 倍額度）套餐。儘管官方做出了澄清，但部分用户仍在論壇表示新定價模型透明度不足。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關來源&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fcn%2Fchangelog%2F1-2" target="_blank"&gt;https://cursor.com/cn/changelog/1-2&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fforum.cursor.com%2Ft%2Fclarifying-june-16-pro-changes%2F111740" target="_blank"&gt;https://forum.cursor.com/t/clarifying-june-16-pro-changes/111740&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358702/cursor-1-2</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358702/cursor-1-2</guid>
      <pubDate>Sat, 10 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維開源第二代獎勵模型 Skywork-Reward-V2 系列</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;崑崙萬維&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fcjv5V_PSZSYObiD9b8VwHA" target="_blank"&gt;宣佈&lt;/a&gt;繼續開源第二代獎勵模型（Reward Model）Skywork-Reward-V2 系列，共包含 8 個基於不同基座模型和不同大小的獎勵模型，參數規模從 6 億到 80 億不等，其在七大主流獎勵模型評測榜單中全面奪魁。在 2024 年 9 月，崑崙萬維曾首次開源了 Skywork-Reward 系列模型及相關數據集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告稱，在打造這一新一代獎勵模型的過程中，崑崙萬維方面構建了一個包含總共 4000 萬對偏好對比的混合數據集 Skywork-SynPref-40M。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為實現大規模、高效的數據篩選與過濾，特別設計了人機協同的兩階段流程，將人工標註的高質量與模型的規模化處理能力相結合。在這一流程中，人類提供經過嚴格驗證的高質量標註，大型語言模型（LLMs）則根據人工指導進行自動整理和擴充。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基於上述優質的混合偏好數據開發了 Skywork-Reward-V2 系列，其展現了廣泛的適用性，在多個能力維度上表現出色，包括對人類偏好的通用對齊、客觀正確性、安全性、風格偏差的抵抗能力，以及 best-of-N 擴展能力。經實驗驗證，該系列模型在七個主流獎勵模型評測基準上均獲得最佳表現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="166" src="https://oscimg.oschina.net/oscnet/up-aba612d774aa51bd830ebc7d8a86ace93bd.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;相比上一代 Skywork-Reward，崑崙萬維全新發布的 Skywork-Reward-V2 系列提供了基於 Qwen3 和 LLaMA3 系列模型訓練的 8 個獎勵模型，參數規模覆蓋從 6 億至 80 億。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-f62f4cf74e27a339b3b803de36d10cac23e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;即便基於最小模型 Skywork-Reward-V2-Qwen3-0.6B，其整體性能已幾乎達到上一代最強模型 Skywork-Reward-Gemma-2-27B-v0.2 的平均水平。更進一步，Skywork-Reward-V2-Qwen3-1.7B 在平均性能上已超越當前開源獎勵模型的 SOTA——INF-ORM-Llama3.1-70B。而最大規模的 Skywork-Reward-V2-Llama-3.1-8B。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="261" src="https://oscimg.oschina.net/oscnet/up-3f53bbb3373c196b2c3a4cab3dd05e6faf8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，Skywork-Reward-V2 在多項高級能力評估中均取得領先成績：包括 Best-of-N(BoN) 任務、偏見抵抗能力測試（RM-Bench）、複雜指令理解及真實性判斷（RewardBench v2），展現了出色的泛化能力與實用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="116" src="https://oscimg.oschina.net/oscnet/up-2a48408860f058ccd51f588fdb4c87c35ae.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-85c3640ee15c11793833144e683ec2270db.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Skywork-Reward-V2 系列模型專注於對偏好數據規模擴展的研究，崑崙萬維方面表示，其團隊也將研究輻射面陸續轉向其他尚未被充分探索的領域，例如替代訓練技術與建模目標。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fcjv5V_PSZSYObiD9b8VwHA" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358700</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358700</guid>
      <pubDate>Sat, 10 May 2025 02:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>全球 AI 人才榜單首次曝光，華人撐起半邊天</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，2025 全球數字經濟大會上，一份重磅榜單面向全球首次揭曉。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;該榜單基於近十年近 10 萬篇文獻深度分析，列出了全球人工智能領域的 Top100 人才&lt;/strong&gt;。其中，華人依舊拿下了主力席位。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsDvBk1WCxUrJqMOu2Q9p6g" target="_blank"&gt;鳳凰網科技從中提煉了出了一份較為矚目的人員名單&lt;/a&gt;，這些人現多數就職於國內外企業，仍在人工智能前沿探索領域活躍，包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何愷明&lt;/strong&gt;，曾任職於 AI 殿堂美國麻省理工學院（MIT），作為 ResNet 之父，是深度學習革命的關鍵推手，其提出的殘差學習（Residual Learning）概念，一舉攻破了困擾神經網絡多年的「梯度消失」難題，讓深達千層的網絡訓練成為可能。其論文引用數以駭人的數十萬次傲視羣雄（公開數據約 40 萬 +），被譽為「CV 界的諾獎級工作」。6 月 26 日，何愷明剛剛官宣入職 GoogleDeepMind，擔任傑出科學家，同時還保留了 MIT 終身副教授身份。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194046_NzCP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;張祥雨&lt;/strong&gt;，曾是曠視研究院的頂樑柱，現已入職階躍星辰任首席科學家； 2016 年，以 ResNet（作為核心貢獻者之一）問鼎 CVPR 最佳論文，震動世界！隨後在 ImageNet、COCO 等視覺「奧林匹克」賽場多次屠榜。其與團隊開創的 ResNet、ShuffleNet 系列影響頗深，Google Scholar 引用逾 40,000 次，是無數手機、攝像頭、自動駕駛系統的「核心引擎」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194104_my7v_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;任少卿&lt;/strong&gt;，蔚來汽車自動駕駛的靈魂人物，計算機視覺與自動駕駛融合領域的頂尖專家，曾發表多篇極具影響力的 CV 頂會論文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194115_XBIO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/9ccdcd47-cf38-495f-a15c-11c7758e41da.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;田奇&lt;/strong&gt;，華為在人工智能領域的重要人物，也是華為計算產品線（昇騰 AI 處理器等）和 MindSpore 框架背後的核心操盤手。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194127_1K5b_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/06d18e54-babe-4198-a0f2-f0ed8e8fc7d2.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王雲鶴&lt;/strong&gt;，華為諾亞方舟實驗室的研究員。專注於 AI 基礎模型、神經網絡架構搜索（NAS）、模型輕量化等前沿方向，是華為 AI「頂天」（前沿）又「立地」（落地）戰略的重要實踐者。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194139_3XP0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/3e5805f0-1b78-44bb-ba08-0ba2b5e6c899.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;謝凌曦&lt;/strong&gt;，華為天才少年，在計算機視覺，特別是視覺大模型、自監督學習、對抗魯棒性等領域有系列開創性工作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194149_Jxf5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/85b5a95b-03b3-4936-96f3-fecdbf8a954a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;strong&gt;王曉剛&lt;/strong&gt;，商湯科技聯合創始人、核心技術奠基人之一。在商湯，他主導了核心視覺算法框架的構建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194158_juQG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b2340c80-9b01-4125-9c86-035e2353db25.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;石建萍&lt;/strong&gt;，商湯科技自動駕駛研發團隊的領軍女將。帶領團隊在智能駕駛視覺感知、多傳感器融合、高精定位等方面取得突破性進展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194208_Tj3r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b0c91622-96b2-4f33-be72-40b2b4802389.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閆俊傑&lt;/strong&gt;，MiniMax 創始人，國內最早一批成立的大模型公司核心人物。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194219_yNU3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/6b21b373-3805-435f-8f02-df120995bb9a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;曹越&lt;/strong&gt;，前微軟傑出工程師，現 Sand.AI 創始人兼 CEO。專注打造下一代 AI 智能體（AI Agent）平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194228_wqU6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f1b580d1-bd41-490b-9080-e4bdc8effc1e.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;陶大程&lt;/strong&gt;，新加坡南洋理工大學（NTU）協理副校長、澳大利亞桂冠教授，視覺大牛，IEEE / AAAS / ACM 三料 Fellow，曾任京東探索研究院院長（2023 年卸任）。研究橫跨計算機視覺、機器學習、統計學習、可信 AI（魯棒性、可解釋性、公平性）等核心領域。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194240_wWsg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/cb439f78-abc0-4ebb-a823-9121a7ada5a5.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;劉子緯&lt;/strong&gt;，新加坡南洋理工大學（NTU）新鋭實力派教授，學術明星。在視覺-語言理解（VLP）、多模態大模型、信息檢索方向成果斐然。其工作多次發表於 CVPR, ICCV, NeurIPS 等頂會，並常居排行榜前列，是推動多模態預訓練模型發展與應用的重要力量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194307_cOI1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/e10b6eaa-b533-4846-ac3d-1688c5e7ca50.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;賈佳亞&lt;/strong&gt;，香港中文大學計算機科學與工程系教授，思謀科技創始人。著名計算機視覺學者，專注於底層視覺重建、圖像增強、圖像分割、醫學圖像分析等方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194322_DDlL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f17121d8-c2e7-4ff0-9203-e1743fc8674f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;楊明玄&lt;/strong&gt;，美國加州大學默塞德分校（UC Merced）計算機科學教授,Google DeepMind 研究員。深耕機器學習和數據挖掘領域，特別是在圖神經網絡（GNN）、推薦系統、社交網絡分析等方面有突出建樹。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194332_aIW0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/5c0ee9b8-ae73-4c39-b4ad-9ba80f95187f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;劉威&lt;/strong&gt;，前騰訊混元大模型技術負責人之一，騰訊傑出科學家，2025 年初離職創業。2024 年領導開源混元文生圖模型、3D 生成模型「Hunyuan3D-1.0」，推動騰訊內部 700 + 業務接入 AI 能力（如微信輸入法、騰訊會議）。發表頂會論文 100 + 篇，總引用 3600 + 次，獲 CVPR 青年研究者獎、SIGIR 最佳論文榮譽獎。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194344_6WyQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/44dd9265-ca1d-4db3-8e44-70ee47565a3a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;顏水成&lt;/strong&gt;，新加坡國立大學終身教授，培養 50 + 名博士，建立亞太最大計算機視覺實驗室，歷任 360 首席科學家、依圖 CTO、Sea 集團 AI Lab 主任；2023 年加入崑崙萬維任 2050 全球研究院院長，2024 年底卸任。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194359_j5g6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/496764e9-1b16-47dd-a8e1-3349844dd95d.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據東壁科技數據創始人、深圳大學特聘教授吳登生介紹，該報告基於東壁全球科技文獻數據平台（dbdata.com），對全球 AI 研究生態進行系統分析，數據集涵蓋近 20 萬名來自 175 個國家和地區、3847 個機構的學者，時間跨度為 2015 至 2024 年。&lt;/p&gt; 
&lt;p&gt;值得一提的是，何愷明、劉子緯、王曉剛、陶大程均師承中國人工智能先驅、商湯科技創始人湯曉鷗，張祥雨曾師從何愷明。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358641</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358641</guid>
      <pubDate>Fri, 09 May 2025 11:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Bytebase 3.8.0 - 顯著優化 schema 同步 / 回滾兼容性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;🔔 重大變更&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;顯著優化多數據庫（MySQL/PostgreSQL/TiDB/SQL Server/Oracle）的 schema 同步/回滾兼容性，支持絕大多數常見數據庫對象。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fchange-database%2Fsynchronize-schema%23supported-objects" target="_blank"&gt;文檔地址&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-21a7f23efb479d2c33408917a613e8bb91b.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下線工單訂閲功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將 SQL 審核中心更名為變更計劃。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;🎄 改進&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增查詢結果行數限制功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cad54dad1deaf4e15ad8f12933c09c1609c.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增多域名配置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4380358be992a487045a8f39061a6ba967e.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;簡化默認值輸入：不再區分表達式和值，統一通過文本輸入框填寫。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在審批流程處展示全部審批人，且可懸停顯示細節。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5c8191a2cf70d8536b5ec930d9fca7b36e2.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;🐞 Bug 修復&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;修復了 ClickHouse 查詢中的 JSON 數據類型顯示問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Terraform SSL 配置中新增 &lt;code&gt;use_ssl&lt;/code&gt; 字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📕 安裝及升級&lt;/h1&gt; 
&lt;p&gt;新安裝 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fself-host" target="_blank"&gt;https://docs.bytebase.com/get-started/self-host&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;升級 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fupgrade" target="_blank"&gt;https://docs.bytebase.com/get-started/upgrade&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;升級前請備份元數據庫，升級後無法回退版本。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;💡 更多資訊，請關注 Bytebase 公號：Bytebase&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6148470/blog/18683355</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/18683355</guid>
      <pubDate>Fri, 09 May 2025 10:24:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Perplexity 上線月費 200 美元的「Max」訂閲服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Perplexity 公司推出了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhub%2Fblog%2Fintroducing-perplexity-max" target="_blank"&gt; Perplexity Max &lt;/a&gt;訂閲服務，月費為 200 美元（約合 1433 元人民幣），可以享受諸多權益。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1abe17d787b691e146a089eccf4834806a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;購買 Perplexity Max 訂閲計劃的用户，可以無限制訪問電子表格和報告生成工具 Labs，並支持提前體驗 Comet 瀏覽器在內的諸多新功能。&lt;/p&gt; 
&lt;p&gt;該公司表示，Perplexity Max 是為以下用户設計的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要無限訪問全面分析工具的專業人士&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要大量研究能力的內容創作者和作家&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進行競爭情報和市場研究的商業策略師&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;從事複雜、多方面項目的學術研究人員&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Max 用户還支持在 Perplexity 服務中，調用 OpenAI 的 o3-pro 和 Claude Opus 4 等先進 AI 模型。隨着 Max 的推出，Perplexity 成為最新一家推出超高端訂閲服務層的 AI 提供商。&lt;/p&gt; 
&lt;p&gt;OpenAI 是首家推出每月 200 美元的 ChatGPT Pro 訂閲服務的公司，但近幾個月來，Google、Anthropic 和 Cursor 也紛紛效仿。&lt;/p&gt; 
&lt;p&gt;Perplexity 目前提供多種訂閲計劃。除了每月 200 美元的 Max 計劃外，還提供每月 20 美元的消費者 Pro 計劃，以及每人每月 40 美元的企業 Pro 計劃。該公司表示，最終也將為企業客户推出超高端的 Max 計劃。&lt;/p&gt; 
&lt;p&gt;Perplexity 在 2024 年主要依靠每月 20 美元的 Pro 計劃訂閲，實現了大約 3400 萬美元的收入，但據 The Information 看到的財務數據，公司仍燒掉了約 6500 萬美元現金。&lt;/p&gt; 
&lt;p&gt;據報道，Perplexity 的現金消耗主要來自對雲服務器的重金投入以及購買 OpenAI 和 Anthropic 的 AI 模型訪問權。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhelp-center%2Fen%2Farticles%2F11680686-perplexity-max" target="_blank"&gt;https://www.perplexity.ai/help-center/en/articles/11680686-perplexity-max&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358621/perplexity-max</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358621/perplexity-max</guid>
      <pubDate>Fri, 09 May 2025 09:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>X 平台（原 Twitter）上線 AI 筆記功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;X 平台（原 Twitter）&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FCommunityNotes%2Fstatus%2F1940132205486915917" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;正式啓動 AI Note Writer 的 API 試點計劃，允許全球開發者創建 AI 機器人來撰寫社區內容。未來，這些由 AI 撰寫的筆記如果被一定數量的用户認為有幫助，就可以在平台上公開展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b9141239b889f5cfe9e01d79314f39bdc80.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;X 表示，該計劃旨在加速社區內容的產出效率，同時通過社區反饋機制，不斷優化 AI 的準確性、公正性與實用性。AI 筆記將遵循與人工內容相同的審核準則，並會在介面中明確標註。&lt;/p&gt; 
&lt;p&gt;首批 AI Note Writer 將在本月內開放上線，且將逐步開放。&lt;/p&gt; 
&lt;p&gt;詳情查看文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunitynotes.x.com%2Fguide%2Fen%2Fapi%2Foverview" target="_blank"&gt;https://communitynotes.x.com/guide/en/api/overview&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358606/ai-note-writer-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358606/ai-note-writer-api</guid>
      <pubDate>Fri, 09 May 2025 08:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>畢馬威：醫療大模型中國發布數量佔全球七成</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;畢馬威中國發布《首屆健康科技 50》報告指出，醫療大模型目前主要分為五類，包括大型語言模型 (LLM)、語言條件多智能體大型、多模態大模型、圖學習大模型、視覺語言大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在全球範圍內，據不完全統計，在已發佈的醫療大模型中，按模型類別來看，大語言模型數量最多，佔比近 65%；按分佈海內外發表數量來看，中國發布數量佔比超 70%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="265" src="https://oscimg.oschina.net/oscnet/up-0f5af0008879ca0ee50480307bd0d62db20.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外報告指出，2024 年，中國醫療科技市場規模突破百億，達到 102.5 億元，同比增長 75.3%。2025-2027 年，中國醫療科技的增幅預計會有所放緩，但行業總市場規模仍呈現穩健增長趨勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2023 年中國醫療機器人市場規模達到約 108 億元，近五年年均複合增長率高達 25.74%。中國智能醫療器械市場增長迅猛，預計 2025 年將達 242.3 億元，2026 年-2027 年總體有望保持較高速增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fassets.kpmg.com%2Fcontent%2Fdam%2Fkpmg%2Fcn%2Fpdf%2Fzh%2F2025%2F07%2Fkpmg-china-healthcare-health-tech-50.pdf" target="_blank"&gt;查看完整報告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358603</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358603</guid>
      <pubDate>Fri, 09 May 2025 08:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
