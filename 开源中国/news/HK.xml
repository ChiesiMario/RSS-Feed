<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 11 Jun 2025 21:44:55 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>macOS Tahoe 是最後一個支持英特爾處理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特爾處理器的 macOS，它們的發售年份是 2019 年和 2020 年。蘋果對 Tahoe 的安全更新支持將持續到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;從 macOS 27 開始，蘋果新操作系統都將需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 舉辦的分會場上，蘋果明確表示搭載英特爾處理器的 Mac 將不會獲得明年推出的 macOS 27 更新，但仍可能會有添加安全修復的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，蘋果已經停止支持其產品線中某些非 Apple Silicon 型號。例如，macOS Tahoe 不適用於任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特爾 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特爾 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根據蘋果的警告，macOS 27 將不再支持所有這些老舊設備，因此 macOS 26 將是最後一個兼容版本。&lt;/p&gt; 
&lt;p&gt;這意味着蘋果對英特爾 Mac 的支持正在逐步取消，公司希望將所有精力和創新都放在 Apple 自主芯片的機器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定製的 Windows 桌面環境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增強 Windows 桌面體驗的工具，專注於自定義和提高工作效率。它可以無縫集成到你的系統中，提供一系列功能，讓你可以個性化桌面並優化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;發揮創意&lt;/strong&gt;：Seelen UI 可讓你根據自己的風格和需求定製桌面。可以調整菜單、小部件、圖標和其他元素，打造個性化且美觀的桌面環境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可幫助你高效地組織桌面。藉助平鋪窗口管理器，窗口可自動排列，支持多任務處理，讓工作更加流暢。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;盡享音樂&lt;/strong&gt;：Seelen UI 集成媒體模塊，兼容大多數音樂播放器，讓你輕鬆享受音樂。可以隨時暫停、繼續播放和跳過曲目，無需打開其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：藉助受 Rofi 啓發的應用啓動器，Seelen UI 提供了一種簡單直觀的方式來快速訪問你的應用程序並執行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直觀的界面，方便用户自定義。只需點擊幾下，即可調整主題、任務欄佈局、圖標等設置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安裝 WebView 運行時。在 Windows 11 系統中，WebView 運行時已預裝在系統內。但在 Windows 10 系統中，WebView 運行時已包含在&lt;code&gt;setup.exe&lt;/code&gt;安裝程序中。此外，Microsoft Edge 瀏覽器也需要安裝才能正常運行。部分用户可能已修改系統並移除 Edge，因此請確保 Edge 和 WebView 運行時均已安裝在你的系統中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sat, 10 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>多源多表寫入、數據格式增強，SeaTunnel 2.3.11 重磅更新來了！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1 style="text-align:center"&gt;&lt;img alt="2.3.11" src="https://oscimg.oschina.net/oscnet//58710d13d425ac4a438e096f3576a207.png" referrerpolicy="no-referrer"&gt;&lt;/h1&gt; 
&lt;p style="color:#333333; text-align:start"&gt;我們很高興地宣佈 Apache SeaTunnel 2.3.11 正式發佈！作為一個專注於高性能、可擴展的數據集成平台，SeaTunnel 始終致力於為開發者和數據工程團隊提供更強大、更靈活的異構數據處理能力。本次 2.3.11 版本在&lt;strong&gt;穩定性、易用性、連接器生態、數據轉換能力以及引擎層面&lt;/strong&gt;都進行了重要增強。無論是支持更多新型數據源與目標端、多表寫入、複雜格式支持，還是對關鍵 Bug 的修復與文檔優化，本次更新都體現了社區對用户反饋的快速響應和持續進化的能力。下面讓我們一起來詳細瞭解 2.3.11 的亮點內容。&lt;/p&gt; 
&lt;h2&gt;功能更新 Highlights&lt;/h2&gt; 
&lt;h3&gt;新增連接器與功能增強&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP Sink 支持批量寫入&lt;/strong&gt;：實現了 HTTP Sink 的批量寫入功能，提高了數據寫入效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持多表寫入功能&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;ClickHouse&lt;/strong&gt;：新增支持多表寫入功能，提升了數據同步的靈活性。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;TDengine&lt;/strong&gt;：新增支持多表寫入功能，增強了數據處理能力。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;DataHub&lt;/strong&gt;：新增支持多表寫入功能，擴展了數據集成場景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GraphQL Connector&lt;/strong&gt;：新增支持 GraphQL 連接器，豐富了數據源類型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Elasticsearch Source 支持 PIT（Point-in-Time）&lt;/strong&gt;：增強了 Elasticsearch 數據源的查詢能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持 CSV 文件中不同列順序的提取&lt;/strong&gt;：提升了文件數據處理的靈活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Apache Cloudberry 支持&lt;/strong&gt;：擴展了數據源的多樣性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Aerospike Sink Connector&lt;/strong&gt;：豐富了數據寫入目標。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Helm 測試用例&lt;/strong&gt;：增強了部署測試能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;配置與參數優化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;end_timestamp&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;參數&lt;/strong&gt;：在時間戳起始模式中添加了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;end_timestamp&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;參數，增強了數據讀取的靈活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持佔位符替換&lt;/strong&gt;：HTTP Connector 支持參數佔位符替換，提升了配置的靈活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增遠程主機驗證選項&lt;/strong&gt;：FTP 數據通道新增遠程主機驗證選項，增強了安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;優化變量處理的健壯性&lt;/strong&gt;：改進了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;stop-seatunnel-cluster.sh&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;腳本中變量處理的健壯性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;移除無用配置項&lt;/strong&gt;：刪除了 Iceberg Sink 中無用的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;iceberg.table.config&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;配置項。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;優化 JDBC 方言選擇邏輯&lt;/strong&gt;：提升了 JDBC 連接器的兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持定義 Sink 列類型&lt;/strong&gt;：Transform 支持定義 Sink 列類型，增強了數據轉換能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 SQL Transform 中的布爾類型&lt;/strong&gt;：提升了 SQL 轉換的表達能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Iceberg Source 中的過濾條件&lt;/strong&gt;：增強了數據讀取的靈活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持源/匯狀態類的 serialVersionUID 檢查腳本&lt;/strong&gt;：提升了狀態管理的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Web UI 的基本認證&lt;/strong&gt;：增強了 Web UI 的安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Rest-API v2 的 HTTPS 協議&lt;/strong&gt;：提升了 API 通信的安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增任務運行管理頁面的異常信息格式化&lt;/strong&gt;：優化了異常信息的展示。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;優化 JDBC 的字符集分割算法&lt;/strong&gt;：提升了數據讀取的準確性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;row_delimiter&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;選項&lt;/strong&gt;：Text File Sink 新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;row_delimiter&lt;/code&gt;選項，增強了文件寫入的靈活性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Bug 修復&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復 SeaTunnelClient 無法正常退出的問題：增強了客户端的穩定性。&lt;/li&gt; 
 &lt;li&gt;修復 Oracle-CDC 重命名 DDL 事件缺失列類型的問題：提升了數據同步的準確性。&lt;/li&gt; 
 &lt;li&gt;修復 PostgreSQL Sink 嘗試更新唯一鍵的問題：增強了數據寫入的穩定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 Hive 客户端線程不安全的問題&lt;/strong&gt;：提升了多線程環境下的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 OceanBase MySQL JDBC Sink 創建語句錯誤的問題&lt;/strong&gt;：增強了兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 Kafka 枚舉器分配分片時的空指針異常&lt;/strong&gt;：提升了數據讀取的穩定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 JSON 輸出中科學計數法表示的十進制數問題&lt;/strong&gt;：確保了數據的準確性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 Parquet Int32 轉換錯誤的問題&lt;/strong&gt;：提升了數據類型處理的準確性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 CSV 格式分隔符的問題&lt;/strong&gt;：增強了文件解析的穩定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 MaxCompute Sink 寫入日期小於實際日期的問題&lt;/strong&gt;：確保了數據寫入的準確性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 MongoDB 中 Long 類型無法處理科學計數法字符串的問題&lt;/strong&gt;：提升了數據類型兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 Elasticsearch 添加列事件的問題&lt;/strong&gt;：增強了數據同步的穩定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 SQL Server 在數據庫名稱包含點時創建表的問題&lt;/strong&gt;：提升了數據庫兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 DateUtils 無法解析帶本地時區的日期時間字符串的問題&lt;/strong&gt;：確保了時間解析的準確性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 JDBC 默認連接參數無效的問題&lt;/strong&gt;：增強了連接配置的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修復 Redis 寫入失敗但任務未失敗的問題&lt;/strong&gt;：提升了錯誤處理的準確性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;文檔更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增中文文檔&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MySQL-CDC Connector&lt;/li&gt; 
   &lt;li&gt;MongoDB-CDC Connector&lt;/li&gt; 
   &lt;li&gt;HiveJdbc Connector&lt;/li&gt; 
   &lt;li&gt;Jira Connector&lt;/li&gt; 
   &lt;li&gt;Cloudberry Connector&lt;/li&gt; 
   &lt;li&gt;GitHub Connector&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文檔格式與內容優化&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修復了 Markdown 格式問題，統一了標題格式，刪除了無效的空格和重複內容。&lt;/li&gt; 
   &lt;li&gt;調整了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;explode&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;trim&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;系列 SQL 函數的描述，提升了文檔的準確性。&lt;/li&gt; 
   &lt;li&gt;更新了 Kafka 文檔中的 Kerberos 部分，增強了安全配置的指導性。&lt;/li&gt; 
   &lt;li&gt;修復了死鏈接，提升了文檔的可用性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;致謝貢獻者&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:start"&gt;感謝@zhangshenghang 對本次版本發佈的指導，以及以下貢獻者對本次發佈的代碼提交、文檔撰寫、問題反饋做出的寶貴貢獻（按用户名排序）：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1dd3b6fcd33c5aac23f32c462da301b7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:start"&gt;也感謝所有參與代碼審核、功能測試、文檔翻譯和社區討論的開發者、用户和貢獻者！&lt;/p&gt; 
&lt;h2&gt;獲取方式&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;鏡像下載：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseatunnel.apache.org%2Fdownload" target="_blank"&gt;https://seatunnel.apache.org/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub Release 頁面：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fseatunnel%2Freleases%2Ftag%2F2.3.11" target="_blank"&gt;SeaTunnel 2.3.11&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Maven 依賴更新：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsearch.maven.org%2Fsearch%3Fq%3Dorg.apache.seatunnel" target="_blank"&gt;Maven Central&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354859/apache-seatunnel-2-3-11-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354859/apache-seatunnel-2-3-11-released</guid>
      <pubDate>Sat, 10 May 2025 09:56:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Genspark 發佈 AI 瀏覽器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能體 Genspark 發佈了 AI 瀏覽器產品，官方稱其具有&lt;strong&gt;極速、廣告攔截、全能智能體、自動駕駛模式&lt;/strong&gt;的特性，並提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鯤創立，今年 4 月宣佈&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能體"Genspark Super Agent"，號稱是一款 "快速、準確、可控" 的通用 AI 代理。這一消息迅速在技術社區引發熱議，眾多專業人士將其與 Manus 相提並論，認為這標誌着通用 AI 代理技術的新一輪角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能體 Genspark 上線 9 天，收入近千萬美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 創企發佈通用智能體：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sat, 10 May 2025 09:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 將接管人類的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演講中，OpenAI 前首席科學家 Ilya Sutskever 迴歸母校多倫多大學，分享了他對人工智能（AI）發展的深刻見解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 與多倫多大學的淵源頗深，20 年前他在這裏獲得了學士學位，而此次則是他從該校獲得的第四個學位。他在演講中回顧了自己在多倫多大學的學習經歷，尤其感慨與 AI 領域先驅 Geoffrey Hinton 的學習機會，使他成為一名科學家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 強調，接受現實並專注於改善現狀是個人成長的重要心態。他提到，許多人容易陷入對過去的後悔，然而這種心態並不利於前進。他鼓勵大家思考下一步的行動，儘管這一轉變不易，但一旦做到，就會使事情變得更簡單。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下來，Sutskever 轉向了 AI 的主題。他指出，我們正處於一個特殊的時代，AI 的迅速發展正在改變我們的學習方式和工作模式。AI 正在以不可預測的方式影響着各行各業，一些工作會更早感受到變化，而另一些則可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他預測，AI 未來將有能力完成所有人類能完成的任務。他認為人類大腦本質上是一種生物計算機，因此 AI 也理應具備完成所有人類任務的潛力。儘管當前的 AI 已能完成許多令人驚歎的任務，但仍存在不足之處，然而隨着技術的進步，這些不足將得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 還提出了深刻的問題：當 AI 能夠完成所有工作時，人類將如何應對這一變革？他強調，隨着 AI 技術的發展，如何合理利用 AI 將成為人類面臨的重要挑戰，包括在工作、經濟和 AI 研究等領域的應用。他認為，AI 的發展將極大加速人類的進步，但同時也會帶來巨大的挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的發展速度可能會超出我們的預期，未來幾年內，AI 的能力將不斷提升，其對生活的影響將更加顯著。儘管目前難以完全預見 AI 帶來的變化，但可以確定的是，AI 的進步將對每個人的生活產生深遠的影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科學家 Ilya Sutskever 的公司估值達 320 億美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sat, 10 May 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇點》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇長文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人類或許正迎來一個新的奇點，而這個奇點並非突如其來，而是温和地悄然降臨。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是譯文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我們已越過臨界點，起飛開始了。人類距離創造出數字超級智能已近在咫尺，而至少到目前為止，現實遠比想象中來得平實自然。&lt;/p&gt; 
&lt;p&gt;街道上尚無機器人行走，我們大多數人也不整日與 AI 交談。人們依然會因病離世，太空旅行依舊不易，宇宙中仍有諸多未解之謎。&lt;/p&gt; 
&lt;p&gt;然而，我們近期確實構建了在許多方面超越人類智慧的系統，它們能顯著提升使用者的工作效率。最困難的部分已然過去：造就 GPT-4、o3 等系統的科學洞見來之不易，卻將引領我們走得更遠。&lt;/p&gt; 
&lt;p&gt;人工智能將以多種方式惠及世界，但由 AI 驅動的科學加速進步和生產效率提升所帶來的生活質量改善，將是巨大的；未來可以遠比現在美好。科學進步是整體進步的最大驅動力；想到我們本可擁有的更多可能，實在令人振奮。&lt;/p&gt; 
&lt;p&gt;從某種重要意義上説，ChatGPT 已經比歷史上任何個體人類都更強大。數億人每天依賴它處理日益重要的任務；一項微小的新能力便能產生巨大的積極影響；而一個微小的錯位，乘以數億用户，則可能造成深遠的負面影響。&lt;/p&gt; 
&lt;p&gt;2025 年，能執行真正認知工作的智能體已然登場；編寫計算機代碼的方式將徹底改變。2026 年，我們可能迎來能夠發現新見解的系統。2027 年，能在現實世界執行任務的機器人或將問世。&lt;/p&gt; 
&lt;p&gt;將會有更多人能夠創作軟件和藝術作品。但世界對這兩者的需求遠超當前供給，只要專家們善用新工具，他們很可能仍遠勝於新手。總體而言，到 2030 年，單個人的生產力相比 2020 年所能達到的飛躍，將是驚人的鉅變，許多人會找到從中獲益的途徑。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或許不會天翻地覆。人們仍將愛自己的家人，表達創造力，玩遊戲，在湖中暢遊。&lt;/p&gt; 
&lt;p&gt;但在同樣至關重要的其他方面，2030 年代很可能將與此前任何時代都截然不同。我們尚不知智能水平能超越人類多遠，但我們即將揭開謎底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能與能源——即思想的湧現以及將思想變為現實的能力——將變得極度充裕。長久以來，這兩者一直是人類進步的根本限制；在充裕的智能與能源（以及良好的治理）之下，理論上我們能夠擁有其他一切。&lt;/p&gt; 
&lt;p&gt;我們已然生活在令人驚歎的數字智能時代，經歷了初期的震驚後，大多數人已習以為常。我們飛快地從驚歎 AI 能生成優美的段落，轉而期待它能創作優美的小説；從驚歎它能做出救命的醫學診斷，轉而期待它能研發治癒良方；從驚歎它能編寫小程序，轉而期待它能創立全新的公司。奇點的演變便是如此：奇蹟成為日常，繼而成為標配。&lt;/p&gt; 
&lt;p&gt;已有科學家坦言，藉助 AI，他們的效率提升了數倍。先進 AI 令人着迷的原因眾多，但或許最重大的意義在於，我們能利用它來加速 AI 自身的研究。我們或許能發現新的計算基材、更優的算法，甚至更多未知的突破。若能將十年的研究壓縮至一年或一個月內完成，進步的速率顯然將大不相同。&lt;/p&gt; 
&lt;p&gt;從今往後，我們已構建的工具將幫助我們探尋更深遠的科學洞見，並助力我們打造更優的 AI 系統。這當然不等同於 AI 系統完全自主更新自身代碼，但這已然是&lt;strong&gt;遞歸式自我改進&lt;/strong&gt;的雛形。&lt;/p&gt; 
&lt;p&gt;其他自我強化的循環也在發揮作用。巨大的經濟價值創造已啓動一個飛輪，推動着為運行日益強大的 AI 系統所需的複合式基礎設施建設。能夠製造其他機器人的機器人（某種意義上，也包括能建設其他數據中心的數據中心）已不再遙遠。&lt;/p&gt; 
&lt;p&gt;若首批百萬台人形機器人仍需傳統方式製造，但之後它們便能運作整個供應鏈——採礦與冶煉、駕駛卡車、管理工廠等等——以製造更多機器人，而這些機器人又能建設更多芯片工廠、數據中心等，那麼進步的速度顯然將不可同日而語。&lt;/p&gt; 
&lt;p&gt;隨着數據中心生產走向自動化，智能的成本終將趨近於電力的成本。（人們常好奇一次 ChatGPT 查詢的耗能：平均每次查詢耗電約 0.34 瓦時，相當於烤箱工作一秒多，或高效節能燈泡亮幾分鐘。耗水約 0.000085 加侖，約合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技術進步的速率將持續加快，而人類總能適應幾乎任何變化的特性仍將延續。挑戰必然存在，如某些職業類別整體消失；但另一方面，世界財富將以前所未有的速度激增，使我們能認真考慮以往絕無可能的全新政策構想。我們或許不會立刻採納全新的社會契約，但幾十年後回望，漸進的變革終將累積成鉅變。&lt;/p&gt; 
&lt;p&gt;歷史經驗表明，我們會找到新的工作與新的追求，並快速接納新工具（工業革命後的職業變遷便是一個近例）。期望值會提升，但能力提升的速度同樣迅猛，我們終將獲得更好的事物。我們將為彼此創造越來越奇妙的東西。人類相比 AI 擁有一個長遠而關鍵的優勢：我們天生關注他人及其所思所為，而對機器則不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的農夫若審視我們許多人的工作，或許會認為那是「虛假的工作」，覺得我們不過是因食物充足、坐擁難以想象的奢華而遊戲人生。我期待我們回望千年後的工作時，也會覺得它們「虛假」，但我毫不懷疑，從事它們的人必將感到無比重要與滿足。&lt;/p&gt; 
&lt;p&gt;新奇蹟誕生的速率將超乎想象。如今甚至難以預料到 2035 年我們將有何發現：或許今年解決高能物理難題，明年便開啓太空殖民；今年取得重大材料科學突破，明年就實現真正的高帶寬腦機接口。許多人會選擇以相似的方式生活，但至少一部分人可能會選擇「接入」（虛擬世界）。&lt;/p&gt; 
&lt;p&gt;展望未來，這聽起來令人難以置信。但置身其中時，感受或許會是震撼但可控的。從相對論視角看，奇點是一點一滴發生的，融合是緩慢進行的。我們正攀登指數級技術進步的漫長弧線；向前看總是陡峭垂直，向後看則顯得平坦，但它始終是一條平滑的曲線。（回想 2020 年，若有人預言 2025 年將接近通用人工智能，聽起來會比我們現在對 2030 年的預測更為瘋狂。）&lt;/p&gt; 
&lt;p&gt;伴隨巨大機遇的，是嚴峻的挑戰。我們亟需從技術和社會層面解決安全問題，而鑑於其經濟影響，確保超級智能的廣泛可及性也至關重要。最可取的前進路徑或許是：&lt;/p&gt; 
&lt;p&gt;解決對齊問題：即我們能強有力地確保 AI 系統學習並踐行人類集體真正的長期願望（社交媒體信息流是 AI 未對齊的實例：其算法深諳如何讓你持續滾動瀏覽，精準把握你的短期偏好，但這卻是通過利用人腦的某種特性，凌駕於你的長期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然後着力使超級智能變得廉價、普及，且不被任何個人、公司或國家過度壟斷。&lt;/p&gt; 
&lt;p&gt;社會具有韌性、創造力且適應迅速。若能凝聚集體的意志與智慧，儘管會犯錯，某些事情會出紕漏，但我們能快速學習調整，從而運用這項技術最大化收益、最小化風險。在由社會共同決定的寬泛邊界內，給予用户充分自由至關重要。世界越早開始探討這些邊界何在以及如何定義集體對齊，結果越好。&lt;/p&gt; 
&lt;p&gt;我們（整個行業，而不僅是 OpenAI）正在為世界構建一個大腦。它將高度個性化、人人皆可輕鬆使用；限制我們的將是好點子的匱乏。長久以來，科技創業圈常嘲笑「點子大王」——那些只有想法卻需要團隊來實現的人。現在看來，他們即將迎來屬於自己的高光時刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承載諸多角色，但首先且最重要的，我們是一家超級智能研究公司。前路漫長，但大部分路徑已然照亮，未知的黑暗區域正迅速退去。能從事這份事業，我們深感慶幸。&lt;/p&gt; 
&lt;p&gt;廉價到無需計量的智能已觸手可及。此言或許瘋狂，但若在 2020 年告訴你們我們將達到今日之境，恐怕比如今我們對 2030 年的預測聽起來更為瘋狂。&lt;/p&gt; 
&lt;p&gt;願我們藉助超級智能，平穩、指數級、波瀾不驚地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;轉載自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sat, 10 May 2025 08:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 據悉與谷歌達成新的雲服務協議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;據報道，OpenAI 與谷歌近期簽署了一項新的雲服務合作協議以獲取更多計算資源。該協議將深化雙方在技術領域的合作，涉及高性能計算資源及數據存儲服務。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新協議旨在支持 OpenAI 的模型訓練需求，並優化其產品性能。具體條款尚未公開，但預計將對人工智能行業發展產生重要影響。&lt;/p&gt; 
&lt;p&gt;兩家公司尚未就該交易公開宣佈任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，談判已持續數月，最終於 5 月達成協議。&lt;/p&gt; 
&lt;p&gt;自 2019 年以來，OpenAI 就與微軟達成了協議，賦予其為這家初創公司構建新計算基礎設施的獨家權利。因此這筆交易將使 OpenAI 將其計算資源擴展到微軟之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sat, 10 May 2025 08:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源網盤應用 Alist 原開發者稱項目已交由公司運營</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免費開源、支持多存儲的自建網盤程序 (文件列表程序)，可以輕鬆在 VPS 服務器、NAS、普通電腦 Win、Mac、Linux 上部署。它除了能作為一款自建網盤 (將文件保存在設備硬盤上) 外，最大的特色就是支持「掛載各大主流網盤」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在該項目 GitHub 倉庫提交 issue，反饋官網出現 404 問題，並提出」項目是否被賣了」的疑問。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原開發者 Xhofe 今日在訂閲頻道發佈公告，&lt;strong&gt;稱項目已交由公司運營&lt;/strong&gt;，之後會幫助審查開源版本倉庫的代碼，確保 release 分支由 CI 自動構建。此外&amp;nbsp;main 分支已開啓分支保護，後續所有提交均需經過 PR 審核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sat, 10 May 2025 07:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式發佈了豆包大模型 1.6、豆包·視頻生成模型 Seedance 1.0 pro、豆包·語音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新發布的豆包大模型 1.6 系列由三個模型組成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的綜合模型，是國內首個支持 256K 上下文的思考模型，支持深度思考、多模態理解、圖形界面操作等多項能力。支持選擇開啓或關閉深度思考、自適應思考三種方式，其中自適應思考模式可根據提示詞難度自動決定是否開啓思考，提升效果的同時大幅減少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的強化版本；在代碼、數學、邏輯推理等基礎能力上進一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的極速版本，支持深度思考、多模態理解、256K 上下文；延遲極低，TOPT 僅需 10ms；視覺理解能力比肩友商旗艦模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在價格方面，&lt;strong&gt;豆包大模型 1.6 採用統一定價模式，首創按「輸入長度」區間定價&lt;/strong&gt;，在企業使用最多的輸入區間 0-32K 範圍內，豆包大模型 1.6 的價格為輸入 0.8 元/百萬 tokens、輸出 8 元/百萬 tokens，綜合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相當於每生成一條 5 秒的 1080P 視頻只需 3.67 元，行業最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·實時語音模型已全量上線火山方舟，對企業客户開放使用。該模型支持自然語言高級指令控制，具備唱歌表演、聲線模仿、方言演繹等多種能力，語氣、用語、思考方式等擬人感大幅提升，能隨時打斷與主動搭話。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sat, 10 May 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供為期兩週的免費 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 與 AI 代碼工具開發商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，為 Cline 用户提供為期兩週的 Grok 3 模型免費訪問權限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需註冊 Cline 賬户，即可在 Cline 的提供商中選擇並免費使用 x-ai/grok-3 模型進行編碼。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是開源 AI 編程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 雙模式，具有終端執行能力和 Model Context Protocol (MCP) 特性。它能夠分析用户的項目文件結構、源代碼等，幫助用户創建和編輯文件、執行終端命令、使用瀏覽器進行測試等，還可以通過 MCP 協議擴展其功能，添加自定義工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sat, 10 May 2025 06:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TickIt：基於 LLM 的自動化 Oncall 升級</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  資料來源：
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-開發者社區&lt;/a&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  軟件工程領域頂級學術會議之一 FSE 2025（The ACM International Conference on the Foundations of Software Engineering）預計將在 2025 年 6 月於挪威特隆赫姆舉行，字節跳動 ByteBrain 團隊的論文《TickIt: Leveraging Large Language Models for Automated Ticket Escalation》成功入選
 &lt;/div&gt; 
 &lt;div&gt;
  （https://arxiv.org/abs/2504.08475）。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  背景
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在雲計算技術蓬勃發展的當下，對於火山引擎來説，工單/Oncall 成為了客户與技術支持&amp;amp;SRE 團隊溝通的關鍵橋樑。隨着雲服務規模的不斷擴大，每日會產生數以千計的 Oncall。這些 Oncall 通常以自然語言的形式，涵蓋了使用諮詢、功能需求，系統故障等各類複雜問題。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在傳統的手動升級模式下，Oncall 值班人依賴個人經驗判斷工單是否嚴重，進而決定是否應該進一步升級。這一過程很依賴值班人員的經驗判斷，也難以形成統一標準。在過往的案例研究與故障覆盤中，我們發現由於人為疏漏，部分嚴重問題沒有及時升級處理，從而導致了穩定性下降的風險，這也可能對火山引擎的客户滿意度造成負面影響。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  如何在面對緊急問題時，及時識別並升級這些 Oncall，成為了提升客户滿意度和保障服務質量的關鍵所在。針對這一問題，我們提出了 TickIt，旨在識別緊急的、報告嚴重問題的 Oncall，並及時地將其升級給產研/穩定性/故障應急等團隊。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  挑戰
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Oncall 問題具有顯著的多樣性，不同類型的問題需由不同專業背景的人員進行處理。例如，系統故障需要產研&amp;amp; SRE 迅速定位並修復，以減少服務中斷時間；客户投訴以及負面情緒則需要客户經理及時安撫客户並解決問題，進而提升客户滿意度。進一步來説，Oncall 問題還可進一步細分，例如判斷其影響面大小、是否對業務有損等。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  現有的基於特徵工程的分析方法，對 Oncall 內容的語義理解能力也較為有限，在實際應用中難以準確識別關鍵問題，致使重要 Oncall 無法及時升級處理。此外，Oncall 的嚴重程度也可能在對話過程中被（動態地）逐步澄清，而一些現有方法僅進行一次性分類，忽略了對話中不斷更新的信息，無法在線及時識別到需要升級的情況。
 &lt;/div&gt; 
 &lt;div&gt;
  此外，挖掘 Oncall 之間的關係同樣重要。當一個問題影響多個客户時，會產生多個相似的 Oncall。如果能及時捕獲分析這些 Oncall 之間的關係，有助於更全面地評估問題的嚴重性與影響範圍，而對於產研來説，可以合併這些 Oncall 共同處理，從而更加聚焦地解決問題。
 &lt;/div&gt; 
 &lt;div&gt;
  得益於大語言模型（LLM）在自然語言理解方面的強大能力，我們將其用於輔助理解 Oncall 中的文本信息，但是簡單使用 LLM 並不能真正有效的解決上述挑戰。在本文中，我們提出了基於 LLM 的 Oncall 分析方法 —— TickIt，該方法可以動態追蹤 Oncall 中的信息，還能借助 LLM 深入理解 Oncall 對話的語義內容，及時識別嚴重問題並升級。同時，TickIt 還能挖掘不同 Oncall 問題現象之間的語義關聯，識別潛在的共性問題，實現更高效的問題處理。
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 使用了字節的豆包（doubao）模型，旨在藉助大語言模型（LLM）強大的自然語言處理能力，實現高效、準確的 Oncall 升級任務。該框架主要包含基於多分類的 Oncall 升級（Multi-class escalation）、重複 Oncall 分析 (Escalation deduplication) 和基於類別引導的微調（Category-guided fine-tuning）這三個核心功能模塊。
 &lt;/div&gt; 
 &lt;div&gt;
  基於多分類的 Oncall 升級
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a38b4514cb694357dbd5a996f44a3ba2.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在 Oncall 升級功能中，TickIt 將 Oncall 升級問題視作多分類任務。依據產研&amp;amp; SRE &amp;amp;客户關係的不同職責和關注重點，預先定義了系統故障、客户投訴、資產損失等多種主題類別。而對於普通 Oncall，統一歸為 「其他」 類別（無需升級處理）。為使大語言模型更好地完成 Oncall 多分類任務，TickIt 也在 System Prompt 中採用了一些技術來提升其分類表現，例如賦予其任務角色、思維鏈（COT）等。例如，在判斷一個 Oncall 是否屬於系統故障時，模型會分析對話內容中提到的故障現象、影響範圍等因素，並逐步解釋做出該分類決策的原因。這種方式增強了分類結果的邏輯性和可解釋性，讓人們更易理解和信任模型的判斷。此外，TickIt 通過 Few-shot learning，輔助模型理解不同的 Oncall 類別。這些示例特別對易混淆的場景進行了舉例示範，從而幫助模型更準確地區分各類 Oncall 的特徵。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 採用在升級任務中所採用的 System Prompt 格式如下圖所示：
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a83ba70159b8a333261baa7c65e4b07e.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 分析
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//3ded1921020057de79c7cfbcfdbb01bd.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 分析是 TickIt 的另一個功能。當一個 Oncall 被判定需要升級時，TickIt 會對所有處於「Pending」狀態的 Oncall 進行檢查，以確定是否有類似問題已被升級。為此，TickIt 將 Oncall 在其生命週期中的狀態抽象為有限狀態機。當客户提交 Oncall 工單並被接受後，該 Oncall 對象進入 「Active」 狀態。每當 Oncall 中有新的對話內容時，最新的對話記錄會觸發 TickIt 啓動新一輪分析，此時將其設置為進入 「Analyzing」 狀態。TickIt 會運用上述的基於多分類的升級方法，判斷當前 Oncall 是否需要升級。如果被分類為 「其他」，則其狀態返回 「Active」，等待下一輪對話交互；若被分類為預設好的嚴重問題類型中，則進入 「Pending」 狀態，此時 TickIt 會檢查是否有相似的 Oncall 已經被升級。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在判斷 Oncall 是否重複時，TickIt 首先利用大語言模型提取 Oncall 中的問題描述，並藉助 doubao-embedding model 將這些問題描述轉化為向量表示。通過 consine similarity 來計算向量之間的相似度，並通過一個閾值參數 𝜃 來判斷當前 Oncall 與已升級的 Oncall 是否相似（𝜃 通過參數選擇實驗確認，在本方法中 𝜃=0.88）。對於 TicketIt 判定當前需要升級的 Oncall，如果歷史已有升級且相似的 Oncall，則會將當前 Oncall 與對應的歷史 Oncall 進行關聯，並不再重複告警（僅在關聯工單中體現）。同時，TickIt 會將當前 Oncall 與已重複會利用大語言模型重寫問題描述，從語義上更全面地歸納該類問題的共性特徵，避免因個別 Oncall 工單描述的侷限性而導致對問題的理解偏差。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  基於類別引導的微調
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//9a20ab7d348eaba17524ba79b94e8374.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  類別引導的微調是 TickIt 不斷優化準確率的關鍵機制。當一個 Oncall 按照上述的流程被升級後，TickIt 會發送包含 Oncall 問題摘要的提醒通知卡片。通知卡片中有三個交互按鈕，其中兩個分別用於點贊或點踩；第三個按鈕則是一個 Oncall 跳轉鏈接，點擊後可直接跳轉到相關的聊天羣中。TickIt 則會記錄下這些通知卡片的交互行為作為自動升級的反饋數據。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//74dd763b0ca8e181846e69dffbc00e72.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在處理這些反饋數據時，TickIt 採用監督微調（SFT）方法，一條典型的 SFT 數據同時包含「對話內容」（Oncall 原始信息），「LLM 思考過程與類別判斷」（LLM 的輸出）。並按照 TickIt 用於 Oncall 升級任務的 System Prompt 來進行組織成數據集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  我們對四種反饋動作設置了不同的優先級，以避免同一 Oncall 下存在衝突的反饋。其中直接反饋（點贊、點踩）都會被納入 SFT 的數據集中。根據我們的觀察，相較於正面反饋（點贊）人們通常會在 Oncall 升級錯誤時更傾向提供一些負面反饋（點踩）。因此，點讚的數量要遠小於點踩，也正是出於此原因，我們將點讚的優先級設置為最高（至少有一個人認為該告警是有幫助的）。而對於點踩的反饋來説，通常是認為誤告警，因此則將其目標類別設置為「其它」（如無指定類別説明）。在該情況下，由於僅僅知道目標類別，而缺乏 COT 所需要的推理步驟，TickIt 則利用大語言模型完成目標分類下思維鏈步驟的補充。考慮到思維步驟的多樣性，TickIt 會對每個 Oncall 進行三次可能思維鏈步驟的採樣，以豐富數據集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  通過這種方式，TickIt 能夠處理用户反饋，並基於類別引導進行數據增強，最終構建出一個高質量的標註數據集。當積累了足夠數量的標註數據後，TickIt 會運用 SFT 方法對模型進行離線優化，然後更新在線模型，從而不斷提升模型在升級分類任務上的性能表現。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 的實驗驗證
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 在火山引擎的線上進行了全面部署，並取得了顯著成效。在此期間，TickIt 共處理了數以萬計的 Oncall。在收到的反饋中，約 81% 的反饋表明 TickIt 的升級決策是準確的，這也證明瞭 TickIt 在實際應用中的有效性和可靠性。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在進一步的 Oncall 升級性能評估方面，我們還對比了基於小語言模型（SLM）和大語言模型（LLM）的多種方法。小語言模型受限於參數規模，其語言理解能力相較 LLM 有較大差距，且部分非端到端的方法設計在信息傳遞過程中易出現信息丟失的情況。而基於 LLM 的方法則展現出了良好的準確率。我們通過消融實驗驗證了不同框架設計對模型性能的影。使用 CoT 的 LLM 方法，準確率和召回率均能達到 82% 左右。在此基礎上，結合反思（Reflection）提示，模型能夠對自身的推理和輸出進行自我糾正，精度略微提升至 82.8%。但由於 CoT 提示已經使模型在得出結論前進行了充分的推理，在反思階段模型難以獲取新的關鍵信息來進一步提高輸出的準確性和洞察力，因此反思技術對實驗結果的提升效果並不顯著。引入上下文學習（ICL）提示後，模型的召回率大幅提升至 89.2%，儘管精度略有下降，但這一結果充分體現了 LLM 方法強大的泛化能力。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//8b040985eb15eb72e4893c729c56be70.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在不同方法設計下的 Oncall 升級比較
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  進一步對 LLM 進行監督微調（SFT）後，模型性能得到了顯著提升。以 CoT 提示為例，微調後的召回率從 82.1% 大幅提高到 91.2%，同時保持了 81.8% 的較高精度，F1 分數達到了 86.2%，在所有對比方法中表現最佳。這一結果有力地證明瞭 SFT 在利用 LLM 能力提升 Oncall 升級任務性能方面的有效性。然而，當 SFT 與其他基於提示的方法（如 Reflection 和 ICL）結合時，性能出現了輕微下降。這可能是因為 SFT 過程中使用了 ICL 中的一些樣本或與訓練數據分佈相似的數據，使得模型在離線微調時已經學習了相應內容，從而在結合使用時產生了一定的衝突。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在重複 Oncall 分析的實驗中，通過調整相似度閾值來探尋最合適的參數，該參數在 0.86 - 0.95 之間時，F1 分數會隨着參數的升高先上升後下降。當其設置過高時，嚴格的相似度約束可能會導致相似問題被錯誤分類到不同類別，使得評估結果中升級 Oncall 的數量相較於真實情況出現偏差，且該偏差與閾值並非單調關係。此外，基於問題現象的去重方法本身存在一定侷限性，對於表現相同但根因不同的 Oncall，可能會出現錯誤去重的情況。而在針對 Oncall 問題重寫的設計中，我們也進行了消融實驗。實驗結果表明，開啓重寫功能的 TickIt 相較於未開啓該功能的實驗設置來説，F1 分數提升了 1.7%。進一步對數據集進行分析，僅保留包含多個關聯 Oncall 的升級進行實驗，結果顯示 TickIt 中的重寫設計使得其 F1 分數從 0.706 提升至 0.749，提升幅度達到 6.1%。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//f44da441270f9c510f3972871725a119.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重複 Oncall 識別下的參數選擇實驗
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//685b195201866bfe500add599463e6ee.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Ticket 在重複 Oncall 識別下的問題重寫消融實驗
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  總結與侷限性分析
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 藉助大語言模型實現了高效的自動化 Oncall 升級，為火山引擎帶來了顯著的效率提升。它從「幫助人們及時介入嚴重 Oncall」的角度，幫助火山引擎縮短了嚴重問題的響應時間，使得整體的 MTTR 降低了約 26%，並節約了人力投入成本。同時，TickIt 也得到了使用者的廣泛認可。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  然而，TickIt 在實際應用中也暴露出一些侷限性。對話中（個性化的）表達方式可能會對大語言模型的判斷產生影響。例如，部分使用者可能會誇大問題的影響，導致不必要的升級；而有人也可能對嚴重問題描述過於平淡，使得 TickIt 未能及時識別出需要升級的情況。此外，如果 Oncall 所關聯的雲服務產品不夠具體，相似的問題描述可能會因涉及不同的雲服務產品而具有不同的嚴重程度，這容易導致大語言模型的誤判，進而出現錯誤的升級。我們在後續的工作中會進一步優化 TickIt 的實際效果，助力火山引擎的穩定性工作。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  作者團隊： 我們來自字節跳動的 ByteBrain 團隊，我們致力於用 AI 技術，為各種基礎架構與系統（數據庫、雲原生、大數據、網絡等）降本增效、提升穩定性。
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354786</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354786</guid>
      <pubDate>Sat, 10 May 2025 03:46:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再獲數千萬美元融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣佈再次完成數千萬美元的 Pre-A+輪融資，同時正式發佈了全球首個 AI 驅動的一站式 3D 工作台 Tripo Studio，並即將推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;據稱此次融資將重點投入 Tripo 系列大模型研發及 Tripo Studio 產品及生態平台建設，加速構建「AI+3D」全產業鏈條，打造「基礎模型 + 生態插件 + 原生工作台」的端到端產品體系，從而構建覆蓋專業級（PGC 生產者）、達人級（PUGC 創作者）到大眾級（UGC 用户）的創作者畫像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，VAST 成立於 2023 年 3 月，是一家專注於通用 3D 大模型研發的 AI 公司，致力於通過打造大眾級 3D 內容創作工具建立 3D UGC 內容平台，使基於 3D 的空間成為用户體驗升級、內容表達創新和新質生產力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持續迭代 Tripo 大模型，先後推出 Tripo1.0 至 Tripo2.5 等數十億參數規模的 3D 大模型系列，同時發佈 TripoSR、TripoSG、TripoSF 等廣受全球開源社區認可的 3D 基礎模型，並配套開發了系列 3D 軟件生態插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新開源：通用自動骨骼綁定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 開源基礎 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sat, 10 May 2025 03:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 Kendo UI 在實戰應用 —— 打通數據鏈路，重塑業務效率</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在製造與供應鏈行業應用——打通數據鏈路，重塑業務效率" src="https://oscimg.oschina.net/oscnet//009b6caaeed5461884780886e08eac09.jpg" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 在製造與供應鏈行業中，企業通常面對「信息孤島」、「任務難協同」、「實時數據難可視」等挑戰。
 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;作為一套成熟的 Web 界面控件解決方案，憑藉其豐富的組件庫與卓越的數據交互能力，已成為製造系統中構建高效、清晰、可操作用户界面的有力工具。
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;是帶有 jQuery、Angular、React 和 Vue 庫的 JavaScript UI 組件的最終集合，無論選擇哪種 JavaScript 框架，都可以快速構建高性能響應式 Web 應用程序。通過可自定義的 UI 組件，Kendo UI 可以創建數據豐富的桌面、平板和移動 Web 應用程序。通過響應式的佈局、強大的數據綁定、跨瀏覽器兼容性和即時使用的主題，Kendo UI 將開發時間加快了 50%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行業關鍵痛點與挑戰&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 生產排程混亂，難以動態調整&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;排產表手工維護，任務依賴關係不清晰；&lt;/li&gt; 
 &lt;li&gt;一旦生產任務調整，工序安排需人工同步，極易出錯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 物料與庫存信息分散，數據透明度低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原材料、在製品、半成品和成品數據分佈於不同系統；&lt;/li&gt; 
 &lt;li&gt;缺乏統一視圖，容易導致缺料、積壓或發錯貨。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 設備利用率、產能瓶頸難以量化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;設備運轉狀態、停機時間、工單完成率難以直觀掌握；&lt;/li&gt; 
 &lt;li&gt;管理層缺乏實時運營看板支撐決策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多角色協同效率低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;採購、倉儲、生產、質檢等部門使用界面風格不一致；&lt;/li&gt; 
 &lt;li&gt;操作體驗差，培訓成本高，數據流轉阻斷。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Kendo UI 提供的關鍵解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 精準的生產排程與任務可視化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gantt Chart 控件&lt;/strong&gt;：可視化呈現排程計劃，支持任務依賴、拖拽重排、進度條展示，幫助排程人員動態優化排產邏輯。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduler 日曆控件&lt;/strong&gt;：用於設備維護排程或產線預約，支持多資源併發視圖。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 統一的庫存數據展示與交互操作&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Grid + 分組 + 分頁 + 導出功能&lt;/strong&gt;：構建靈活的物料清單、庫存看板，支持層級顯示與動態篩選。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TreeView + PanelBar&lt;/strong&gt;：適用於多倉庫、多區域的庫存結構導航。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AutoComplete / MultiSelect&lt;/strong&gt;：提升物料錄入與搜索效率，防止錯錄錯查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 實時可視化的運營監控&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Charts 圖表組件（柱狀圖、折線圖、圓環圖等）：展&lt;/strong&gt;示各產線設備的稼動率、生產效率、工單完成情況等關鍵指標。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sparkline 小型趨勢圖&lt;/strong&gt;：適用於嵌入表格單元格中，輕量快速展現某項指標走勢。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ProgressBar + KPI 指標塊組合&lt;/strong&gt;：適合構建實時工廠大屏或車間電子看板。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多端一致的界面交互體驗&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;響應式佈局組件（ResponsivePanel / Drawer / TabStrip）：&lt;/strong&gt;適配桌面與平板設備，統一各角色使用體驗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload + Dialog + Tooltip + Notification&lt;/strong&gt;：用於上傳質檢報告、操作提示與反饋，提升人機交互流暢度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;豐富的表單驗證機制&lt;/strong&gt;：確保關鍵業務數據錄入安全、準確。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;應用場景示例&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在製造與供應鏈行業應用——打通數據鏈路，重塑業務效率" src="https://oscimg.oschina.net/oscnet//181f48127f99e600559a7997cf56e624.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;結語&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;在數字化製造轉型的背景下，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;不僅是「界面構建工具」，更是連接業務流程與數據決策的橋樑。它以高可定製、高性能的前端控件能力，為製造與供應鏈行業提供了穩定、高效、專業的用户交互解決方案。從排程到倉儲、從設備監控到多角色協同，Kendo UI 為企業打造真正可視、可控、可運營的管理界面，助力製造企業邁向數字化高質量發展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354778</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354778</guid>
      <pubDate>Sat, 10 May 2025 03:25:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>百度百舸萬卡集羣的訓練穩定性系統設計和實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 訓練穩定性的演進歷程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 競賽中 AlexNet 的橫空出世，開啓了現代 AI 發展的新紀元。彼時我們不會想到，十年後支撐 AI 訓練的 GPU 集羣會從研究室裏的幾台服務器，發展成需要專門供電系統的萬卡級計算矩陣。在這個算力爆發式增長的過程中，訓練系統的穩定性管理正經歷着從「簡單運維」到「精密工程」的深刻變革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 標早期的小模型時代：手動運維的黃金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 訓練，更像是手工作坊式的精雕細琢。大多數訓練任務只需十幾塊 GPU，利用 PyTorch 或 TensorFlow 的數據並行功能就能輕鬆應對。記得那時算法工程師們有個共識：如果訓練遇到問題，重啓往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;當時我們構建的監控系統就像汽車儀表盤，只能顯示最基本的任務狀態。當訓練意外中斷時，工程師們會像偵探一樣翻查日誌 —— 如果發現是 GPU 報錯，就聯繫運維同事。運維人員則帶着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到機房巡檢，像老中醫把脈般通過温度、功耗等指標判斷硬件狀態。這種工作模式雖簡單，但應對數十卡規模的集羣還算遊刃有餘。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型風暴：從量變到質變的衝擊&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登場如同打開潘多拉魔盒，將 AI 訓練帶入新的紀元。當我們開始部署千卡/萬卡集羣時，才發現原有的運維體系就像用小漁網捕鯨魚 —— 完全無法匹配新需求。&lt;/p&gt; 
&lt;p&gt;讓我們通過百度百舸經歷過的一個真實案例來深入理解這個問題：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸幫助一家 AIGC 創業公司迅速將其訓練規模從百卡擴展到千卡級別。然而在訓練數天後的某個週末凌晨，訓練進程意外發生了 hang 死。由於當時缺乏有效的故障感知和容錯機制，直到第二天算法工程師發現任務超時退出時，已經耽誤了數小時寶貴的訓練時間。更糟糕的是，任務日誌中除了簡單的 timeout 報錯外毫無線索，平台監控也顯示所有訓練節點狀態正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢復訓練的算法工程師沒有立即上報問題，而是選擇直接重新提交任務。但不幸的是，新任務運行數小時後再次出現相同的超時退出。這時他們才不得不尋求技術支持，但值班工程師面對這種任務 hang 死的問題也缺乏診斷經驗，只能通過二分法慢慢定位。最終發現是某個節點的靜默故障（SDC）導致了訓練進程假死。等問題得到解決時，距離首次故障已經過去將近 30 小時，這意味着損失了價值巨大的千卡算力資源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集羣訓練穩定性全景圖&lt;/h1&gt; 
&lt;p&gt;站在現在的時間點回望，AI 訓練穩定性已從輔助功能演變為核心基礎設施。就像現代建築中的抗震結構，它雖不直接參與空間構成，卻是萬丈高樓得以屹立的關鍵。當行業向着數萬卡集羣邁進時，這套隱形護甲的質量，將直接決定 AI 進化的速度與邊界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸對訓練過程的生命週期進行了更細緻的拆分，提出了「無效訓練時間」這一關鍵指標，並致力於將其最小化。具體來説：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任務無效訓練時間 = 故障中斷次數 × 任務故障恢復時長 + 任務常態寫 Ckpt 總時長&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任務故障恢復時長 = 故障感知召回耗時（自動/人工定位）+ 任務調度耗時 + 任務初始化耗時 + 任務重算時長。&lt;/p&gt; 
&lt;p&gt;通過這個公式可以看出，要降低無效訓練時間，需要「圍繞基礎設施穩定性」、「任務容錯」兩個維度來系統展開，重點解決三個方面的問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基礎設施的交付質量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任務故障容錯的召回率、準確率和時效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優化 checkpoint 機制，減少保存時間和恢復時的重算時間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過容錯架構的整體變革，百度百舸形成了從 「任務負載 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基礎架構」全鏈路的自動異常感知、診斷、恢復能力，可覆蓋 90%+ 的訓練異常場景，時效性最快可以實現秒級異常感知、分鐘級定位，以及平均 3 分鐘的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基礎設施交付質量保障&lt;/h1&gt; 
&lt;p&gt;基礎設施的交付質量保障是穩定性的基礎。&lt;/p&gt; 
&lt;p&gt;CPU 時代，機器的交付前可能僅會跑一些常規的 CPU 計算、網絡的壓力測試，並不會從業務視角去評估基礎架構，機器交付後硬件異常的故障頻率相對較少。有硬件故障時，通常走工單系統人工換機用户相對是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 時代，AI Infra 的交付則需要考慮 CPU、GPU、RDMA 網絡、存儲，甚至機房的功率、温度等各方面因素，遺漏任何一個環節都會成為後續穩定性的隱患。在交付給客户後，機器也可能會由於長時間的高負載運行頻繁出現硬件故障，而 GPU 機器的高昂成本，使客户對節點故障感知、換機的時效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸對 GPU 機器交付前及交付後的穩定性質量進行了系統性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸會對機器進行 200 多項指標檢測，然後進行 48 小時烤機，以及 NCCL-Test 的機內、機間的大環、同號卡通信性能基準測試，端到端的大模型訓練、推理性能基準測試。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付後，需要能夠實時的感知節點故障及定期巡檢，並具備分級處理的自愈能力，例如 Error 級別的故障實現自動排水、重啓，Fault 級別故障實現自動換機。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任務容錯的準召率保障&lt;/h1&gt; 
&lt;p&gt;任務層面穩定性最核心的就是做好容錯，能夠讓業務在無論遇到何種故障時都能快速恢復。&lt;/p&gt; 
&lt;p&gt;那麼，首要的工作就是我們能夠準確的識別出異常，然後對故障進行診斷定位，最後能夠自動化的從異常中恢復。&lt;/p&gt; 
&lt;p&gt;因此，任務容錯需要能夠從端側（即每個訓練 worker）探測到進程與環境的各類異常，同時有個中心服務（Master）從任務全局的視角去診斷、定位異常，最終做出相應的決策來使任務能夠快速從異常中恢復。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任務容錯最重要的就是提升故障的召回率與準確率，即如何能夠儘可能的準確識別、定位所有故障。我們將故障分類兩類：顯式故障和隱式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;顯式的故障通常比較容易召回，我們將實踐積累的各種進程異常狀態及各類報錯 pattern 形成專家知識庫，再結合硬件感知服務（HAS Agent）的硬件全鏈路 10 秒級監控能力，可以實現顯式故障的召回率達到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隱式的異常則往往很難輕易的識別，例如訓練進程 hang、慢節點就是典型的隱式故障，需要豐富的經驗積累才能準確的識別出異常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我們就以最典型的隱式故障場景 —— 訓練進程 hang 死為例，來看下如何能夠做好 hang 自動感知、診斷。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 訓練****hang 的自動感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;訓練任務發⽣ hang 之後，絕⼤多數情況都會以 timeout 的⽅式報錯並退出進程，最常⻅的就是在通信過程中如果發⽣ hang，NCCL 的 watchdog 會中斷通信，並有報如下 timeout 報錯，然後再由 pytorch 的 torchrun 進程感知並中斷訓練過程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默認為 10 分鐘 NCCL 通信超時，而 Megatron-LM 為 30 分鐘。在萬卡規模訓練場景中，意味着一萬張卡要至少浪費 30 分鐘才能被發現。這個時效性是不可接受的。而且當 30 分鐘超時後程序會立馬退出，很難有機會進行下一步定位，需要一些時效性更高的感知機制，並且在程序退出前獲取一些有效信息供後續診斷分析。&lt;/p&gt; 
&lt;p&gt;很多公司、實驗室在面對 hang 的問題時，會在採用框架層插樁的方式來 trace 訓練進程，這種方式通常是比較直接且準確的，但是有比較強的侵入性，而且可能還會有一些性能開銷。對於雲廠商來説，需要尋找對用户更透明、更無損的方式來感知、定位 hang 異常。&lt;/p&gt; 
&lt;p&gt;如何感知訓練 hang，以百度百舸的產品設計思路為例，我們可以從以下幾個方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訓練進程 hang 的最直觀表現是什麼？&lt;/p&gt; &lt;p&gt;人工判斷一個任務是否 hang 了，最直接的方式就是看是否所有 worker 的任務日誌一段時間內都不輸出日誌了，所以 hang 自動感知的第一種方法就是採集所有 worker 的日誌，並判斷所有 worker 日誌中最後一行日誌是否為 x 分鐘前的（x 小於 Pytorch 的通信超時時間，例如 8 分鐘），如果是則基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時進程有什麼樣的表現？&lt;/p&gt; &lt;p&gt;任務 hang 時，可能進程的調用棧都不在發生變化，進程的調用棧可以通過 py-spy/pystack 等工具進行探測，所以我們可以用此類工具對所有訓練任務進行一個定時採樣，當採集 n 個樣本所有進程棧都沒有變化時，可以判定一次 hang，這種方式通常可以將 hang 感知縮小至 3～5 分鐘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任務 hang 時監控指標有哪些變化？&lt;/p&gt; &lt;p&gt;訓練進程中的 CUDA 算子計算、集合通信操作通常都是在毫秒，甚至微秒、納秒內完成的，當任務在正常迭代過程中發生了 hang，我們常遇到的情況是所有 rank 的 RDMA 流量會降到 0，而 GPU 的利用率為 100%、SM 利用率則在很低的水位。如果持續幾分鐘都是這種狀態時，意味着訓練進程已經計算完成，在等着集合通信完成，這種情況下基本可以判定為 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信庫中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常單次集合通信操作都是在 ms 級的，如果一次操作在 30 秒鐘都沒有完成，那就可以判定為通信 hang 死了。百度自研的 BCCL 集合通信庫層可以對每一次集合通信操作都進行打點，來實現通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述幾種方法，我們可以分別實現一種探針，來抓取相應的特徵到中心端 master 組件進行下一步診斷和容錯決策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信庫 BCCL 是百度智能雲推出的一款面向大模型訓練場景優化的集合通信庫。&lt;/p&gt; 
 &lt;p&gt;BCCL 基於開源的 NCCL 進行了功能擴展和能力增強，針對大模型訓練場景在可觀測性、故障診斷、穩定性等方面進行優化，進一步提升集合通信庫的可運維能力。相比 NCCL，BCCL 的關鍵特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可觀測性：新增集合通信帶寬實時統計能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障診斷：新增集合通信 hang 時的故障診斷能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;穩定性：增強網絡穩定性和故障容錯能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能優化：提升大模型訓練主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;訓練 hang 的自動診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我們需要進一步的診斷、定位，來確定是否真的發生了 hang，以及 hang 的具體位置。具體的來講，master 收集到各類 agent 的數據後，會做一些綜合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的發生了 hang？&lt;/p&gt; &lt;p&gt;感知階段各種探針只能探測到 hang 的一種特徵，並沒有辦法 100% 的確定是否真的 hang 住了，事實上不侵入用户進程是很難做到 100% 確定 hang 的。因此，為了提高 hang 的判定準確率，我們需要將各種特種綜合起來判斷，探針上報到 master 後，由一個 hang 診斷模塊，按照一個時間窗口（例如 5 分鐘），進行綜合判斷。如果在時間窗口內日誌、監控、進程調用棧、通信庫中有 2 條以上都處於不處於活躍狀態時，我們判斷任務真正發生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具體發生的位置？&lt;/p&gt; &lt;p&gt;確定任務 hang 了之後，我們需要找到 hang 所在的節點來對它進行隔離。因此診斷模塊需要在探針上報的數據中進一步找尋特徵，來確定 hang 發生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 診斷：在感知階段，BCCL 可以在通信庫層面對所有 rank 的通信進行打點。如果有節點一直未完成通信則是發生了 hang。但是此節點可能並非真正發生 hang 的源頭，有可能是在等待其他節點完成通信。診斷模塊可以根據 BCCL 打印的通信組信息，進行交叉判斷，如果某個節點在多個通信組中都未完成通信，那這個節點就是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指標診斷：上文中我們提到，通信階段發生 hang 之後，所有 rank 的 RDMA 流量都會降到 0，而同時絕大部分 rank 的 GPU 利用率持續為 100%，只有某一兩個 rank 的 GPU 利用率為 0，那這個 rank 很有可能是 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調用棧診斷：進程調用棧也可以作為一個 hang 源頭診斷的重要參考。當發生 hang 之後，絕大部分的 rank 都要麼處於 barrier 等待狀態，要麼處於通信等待階段。只有個別的 rank 卡在其他函數上，那麼通過對比分析，可以將調用棧與其他 rank 不同的節點初步判定為 hang 的源頭。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;綜合診斷：上面 3 種特徵為我們提供了 hang 的診斷依據，將 3 者關聯起來分析後，我們基本上可以比較準確的確定一個具體的 hang 的源頭，再結合硬件故障感知的相關信息可以進一步明確根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基於 eBPF 的隱式故障感知與診斷&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在複雜的大規模分佈式訓練場景中，傳統用户態監控往往難以捕獲系統內核層面的異常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基於 eBPF（Extended Berkeley Packet Filter）技術的隱式故障感知體系，能夠在不侵入用户代碼的前提下，對訓練進程的系統調用、網絡通信、CPU 調度等內核態行為以及訓練框架關鍵函數運行時間建立立體觀測能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探針部署原理通過在內核關鍵路徑注入輕量級探針，實現低開銷的系統級行為捕獲。針對訓練場景特點，主要聚焦 4 類事件跟蹤：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練關鍵函數跟蹤：微秒級跟蹤訓練過程中，前向計算、反向計算、集合通信操作等關鍵函數執行耗時，記錄函數間調用關係。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;進程調度阻塞跟蹤：掛鈎 sched_switch 事件，檢測進程在 TASK_UNINTERRUPTIBLE 狀態持續時間，當單次持續超過閾值（如 5 秒）時捕獲調用棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 運行時 API 監控：通過 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等關鍵庫注入探針，記錄 CUDA API 調用耗時分佈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 級通信監控：在 ibv_post_send/ibv_poll_cq 等核心通信接口設置觀測點，統計通信時延分佈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;結合上面 4 類事件，完成以下 2 類數據分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單體異常探測基線與實時數據對比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;羣體一致性檢測。採用卡間對比算法，當某一 rank 的以下指標偏離集羣中位數超過閾值時判定異常，包括系統調用頻率、進程就緒隊列等待時長、NVLink/RDMA 帶寬利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上所述方法，百度百舸針對以下 2 類典型的隱式故障進行診斷：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;訓練 hang 根因定位。通過關聯 eBPF 捕獲的多維度數據進行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;當檢測到某 rank 的 GPU &amp;nbsp;Kernel 執行出現分鐘級空跑（SM 利用率 &amp;gt; 70% 但無有效計算輸出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同時伴隨該節點 RDMA QP 狀態停滯（ibv_poll_cq 無新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內核調度器顯示進程處於 D 狀態超過閾值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖動溯源。基於 eBPF 火焰圖、時序圖等進行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取發生性能下降時段的 CPU on-cpu/off-cpu 堆棧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對比正常時段數據，識別出異常的鎖競爭（futex 調用佔比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;結合 NUMA 內存訪問統計，定位跨 NUMA 內存訪問導致的 TLB 顛簸問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此類技術已在百度百舸的萬卡規模訓練集羣中驗證，相比單純依賴應用層監控的方案，將隱式故障的平均檢測時間從分鐘級縮短至秒級，診斷準確率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通過與既有硬件故障感知服務、BCCL 通信庫監測體系聯動，百度百舸形成了覆蓋從硬件到系統內核再到應用層的立體化診斷能力。&lt;/p&gt; 
&lt;h1&gt;05 任務故障恢復的時效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢復的時效性也是容錯能力的一個重要指標，反映的是任務從故障發生到再次重新進入訓練迭代的時間，恢復效率越高則算力浪費越少。影響到任務恢復效率有 2 個重要因素，一是任務平均中斷時間，二是訓練重算時間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多級重啓策略減少故障中斷時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任務發生異常後，上文中我們提到需要經過故障自動感知、診斷和自愈等 3 個環節，那麼減少中斷時間的核心思想，就是儘可能的縮短這 3 個環節的時間，通過多維度的感知、診斷手段可以將故障發現、定位的時效性降低至分鐘級甚至秒級。自愈則需要能夠根據不同的診斷結果進行分級恢復和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;單點顯式故障：重調度異常節點（replace），對節點進行集羣級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;單點隱式故障：重調度異常節點，對節點進行任務級別屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非單點故障：原地重啓嘗試恢復（restart），無法恢復時重新調度所有節點（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過多級重啓策略，儘可能避免單點故障引發全部節點的重新調度。在萬卡級別的訓練場景中，百度百舸將大部分訓練異常場景恢復時間從過去的 30min 縮短至現在的 30s 內，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;觸發式 checkpoint 減少訓練重算時間&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多級任務重啓策略外，另一個提高任務故障恢復效率的重要手段就是減少訓練重算時間。在探討具體技術方案之前，我們先來看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;傳統的 checkpoint 保存通常採用固定間隔策略，比如每隔 N 個 step 或每隔 T 小時保存一次，這種方式實現簡單但缺乏靈活性，可能會產生大量冗餘存儲，同時在故障發生時可能會損失較多訓練進度。&lt;/p&gt; 
&lt;p&gt;而觸發式 checkpoint 則是一種更智能的方案，它根據特定條件或異常事件（如故障、顯存不足、顯式指令等）動態觸發模型狀態保存。其核心目標是通過靈活的控制保存時機，減少不必要的存儲開銷和訓練中斷時間，從而降低因頻繁或冗餘保存導致的重算時間浪費。&lt;/p&gt; 
&lt;p&gt;隨着大模型訓練規模的擴大，還有一種更激進的「零重複 checkpoint」技術，即在每個訓練 step 都保存一次 checkpoint。這種方案的優勢在於可以將重算時間降到最低，確保故障發生時能夠從最近的 step 恢復，幾乎不會損失訓練進度。但其顯著的缺點是存儲開銷巨大，即使採用增量式存儲，仍然需要相當大的存儲空間和 I/O 帶寬。此外，頻繁的 checkpoint 操作也可能影響訓練性能。&lt;/p&gt; 
&lt;p&gt;相比之下，觸發式 checkpoint 走的是一條平衡之路。我們來看下它實現的幾個核心要點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容錯：訓練進程集成容錯的故障感知與定位機制，在進程退出前自動觸發保存。這種主動感知機制能夠在故障發生的第一時間保存訓練狀態，最大限度減少進度損失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速轉儲：異步 checkpoint 保存機制會將 checkpoint 暫存到共享內存中，再由外部程序轉儲至磁盤。當某個節點異常時，容錯組件會拉起新節點，並在新節點訓練進程啓動前，利用 RDMA 技術實現 checkpoint 快速從故障節點轉儲至新節點，這大大減少了從遠程存儲拉取 checkpoint 的時間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗餘備份：觸發式 checkpoint 也並非完美無缺，例如在節點發生內核 crash 等嚴重故障時，可能無法觸發自動保存。因此，需要通過定期的冗餘備份機制進行兜底，確保 checkpoint 不會完全丟失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實踐表明，當觸發式 checkpoint 與異步、增量式的 checkpoint 機制結合使用時，可以在保證數據安全性的同時，顯著提高 checkpoint 保存效率，減少訓練重算時間。&lt;/p&gt; 
&lt;p&gt;相比零重複 checkpoint 的重型方案，觸發式 checkpoint 提供了一個更實用的折中方案，在合理的存儲開銷下實現較好的容錯效果。當然，具體選擇哪種方案，還需要根據實際的訓練規模、硬件條件和可用資源來權衡。&lt;/p&gt; 
&lt;p&gt;隨着分佈式訓練規模的持續增長，相信未來會出現更多創新的 checkpoint 方案，比如基於預測的主動保存策略、多級存儲架構的智能調度等，這些都將為提高大規模訓練的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 業務發展對穩定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 訓練的穩定性管理已經演變為智能時代的精密工程。從最初靠人工重啓解決問題的摸索階段，到如今能自動感知異常、快速恢復的智能系統，每一次進步都映照着算力規模的跨越式發展。&lt;/p&gt; 
&lt;p&gt;讓人不禁思考，在未來十萬卡集羣的算力洪流中，或許會出現更精妙的動態平衡方案：既能像鷹隼般敏鋭捕捉故障徵兆，又能如雁羣遷移般智能調度資源，在秒級恢復與 PB 級存儲成本之間找到新的平衡支點。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持廠內千卡和萬卡集羣有效訓練時長已經可達 99.5%，為客户大模型的預訓練保駕護航，比如國內第一個數學大模型——九章算術，國內第一個類 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增強語義嵌入的模型算法綜述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持續推進「人工智能＋」行動，百度智能雲+DeepSeek 為何成為國有企業首選？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 雲服務器的軟件系統設計和實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基於 Flink 的配置化實時反作弊系統&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能雲 xDeepSeek，最具性價比的 DeepSeek 一體機合集來了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sat, 10 May 2025 03:02:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Hugging Face 發佈開放權重模型貢獻榜：Qwen 與 DeepSeek 躋身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;發佈&lt;/a&gt;開放權重模型貢獻榜，中國團隊 Qwen 和 DeepSeek 成功入圍前 15 名。該榜單表彰為開源社區提供高質量模型權重的團隊，其模型廣泛應用於學術與產業創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴雲智能集團支持的 Qwen 團隊，以 Qwen3 系列模型在指令跟隨、代碼生成等任務中的優異表現受到社區青睞。Qwen2.5-72B 系列位列開源大語言模型前列，其輕量化模型 QwQ-32B 通過強化學習優化，在數學推理和代碼生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 則以低成本、高性能的 R1 系列模型聞名。R1-0528 在 LiveCodeBench 排行榜中超越多個國際競品，僅次於 OpenAI 頂尖模型。其輕量化版本 DeepSeek-R1-0528-Qwen3-8B 通過知識蒸餾技術，單 GPU 即可運行，在 AIME2025 數學測試中擊敗 Google 的 Gemini2.5Flash，展現了在特定領域的競爭優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中國 AI 團隊在開源生態中的崛起。Hugging Face 負責人表示，兩團隊的貢獻為全球開發者提供了高效資源。NVIDIA 首席執行官黃仁勳也讚揚其性能與成本平衡正在重塑 AI 格局。未來，Qwen 計劃探索多模態技術，DeepSeek 則將推出 R2 模型，持續推動 AI 創新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sat, 10 May 2025 02:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Android 16 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌發佈了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為今年的第一次大版本升級，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按鍵式導航（三大金剛）的預測性返回手勢&lt;/li&gt; 
 &lt;li&gt;強制通知分組&lt;/li&gt; 
 &lt;li&gt;以進度為中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 設備的桌面模式（開發者選項）&lt;/li&gt; 
 &lt;li&gt;低功耗藍牙聽力輔助設備支持&lt;/li&gt; 
 &lt;li&gt;自定義鍵盤快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截圖優化&lt;/li&gt; 
 &lt;li&gt;以舊換新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性詳細介紹查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 DevExpress WPF v24.2 新版亮點：報表等組件功能升級</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF 擁有 120+個控件和庫，將幫助您交付滿足甚至超出企業需求的高性能業務應用程序。通過 DevExpress WPF 能創建有着強大互動功能的 XAML 基礎應用程序，這些應用程序專注於當代客户的需求和構建未來新一代支持觸摸的解決方案。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;控件近期全新發布 v24.2，此版本進一步升級了網格、報表、地圖等組件的功能，歡迎下載最新版體驗！&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346%2Fdownload" target="_blank"&gt;DevExpress WPF v24.2 正式版下載&lt;/a&gt;&lt;/strong&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Grid（網格）控件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多單元格編輯&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;Microsoft Excel 允許您選擇多個單元格並通過按 Ctrl + Enter（替代 Enter）應用文本更改，DevExpress WPF Grid 控件中添加了一個類似的特性，允許用户同時對多個單元格應用相同的值。要啓用此功能，將&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.DataControlBase.SelectionMode" target="_blank"&gt;GridControl.SelectionMode&lt;/a&gt;設置為 Cell，將&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.TableView.MultiCellEditMode%3Fv%3D24.2" target="_blank"&gt;GridControl.MultiCellEditMode&lt;/a&gt;設置為 FocusedColumn/AllColumns。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 產品圖集" src="https://oscimg.oschina.net/oscnet//a590e16b5907853d6c754e5c5bc46b88.gif" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;PDF Viewer&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;獲取在頁面縮略圖面板中選擇的頁面&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;PdfViewer.GetSelectedThumbnailPageIndexes&lt;/a&gt;方法允許您獲得在 Page Thumbnails 面板中所選頁面的索引，可以在 DevExpress PDF Viewer 中提取、刪除或導出選定的頁面。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfViewerControl.ActualThumbnailsViewerSettings%3Fv%3D24.2" target="_blank"&gt;PdfViewerControl.ActualThumbnailsViewer&lt;/a&gt;屬性來訪問實際的縮略圖查看器設置，並調用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;GetSelectedThumbnailPageIndexes&lt;/a&gt;方法來獲取頁面索引。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;下面的示例將在頁面縮略圖面板中選擇的 PDF 文檔的頁面保存為圖像：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;&lt;em&gt;C#&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;using System.Windows.Media.Imaging;
using System.IO;
// ...
private void simpleButton_Click(object sender, RoutedEventArgs e) {
// Obtains the selected page indexes.
var pages = viewer.ActualThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes();
// Saves each page from the collection to an image.
foreach (var i in pages) {
BitmapSource image = viewer.CreateBitmap(i, 1000);
PngBitmapEncoder encoder = new PngBitmapEncoder();
encoder.Frames.Add(BitmapFrame.Create(image));
using (var fileStream = new FileStream($"..\\MyBitmap{i + 1}.bmp", FileMode.Create)) {
encoder.Save(fileStream);
}
}
}&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Reporting（報表）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WPF 報表設計器 - 維度符號&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;為了簡化報表設計過程，此更新在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;報表設計器中引入了維度符號。當您調整控件的大小時，設計器會提供精確的視覺反饋，並根據指定的 ReportUnit 屬性值（如英寸、釐米或像素）顯示維度符號。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 產品圖集" src="https://oscimg.oschina.net/oscnet//b1ccdc0e972820bc31dddac86cddd3d6.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;要管理符號的可見性，請使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FXtraReports%2FDevExpress.XtraReports.Configuration.UserDesignerOptions.ShowDimensionNotations%3Fv%3D24.2" target="_blank"&gt;UserDesignerOptions.ShowDimensionNotations&lt;/a&gt;屬性。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;地圖組件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 Azure 地圖&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF MapControl 現在可以顯示 Microsoft Azure 地圖數據，使用 AzureMapDataProvider 提供程序獲取光柵圖像磁貼。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;注意&lt;/strong&gt;：在使用 Azure Maps 時，您必須閲讀並理解 Microsoft 的使用條款：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fpricing%2Fdetails%2Fazure-maps%2F" target="_blank"&gt;https://azure.microsoft.com/en-us/pricing/details/azure-maps/&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354762</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354762</guid>
      <pubDate>Sat, 10 May 2025 02:36:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 推遲開源模型的發佈時間</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席執行官山姆·奧特曼宣佈，原計劃於今年初夏發佈的公開權重的開源模型預計&lt;strong&gt;將推遲至夏末發佈&lt;/strong&gt;，而不是 6 月與公眾見面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究團隊做了一些出乎意料且非常令人驚奇的事情，這非常值得等待，但需要更長的時間。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣佈將發佈自 GPT-2 以來的首個「開源」語言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最強」開源模型，計劃今年初夏發佈&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sat, 10 May 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首個推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣佈推出&lt;/a&gt;其首個推理模型系列 Magistral，採用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高數學和物理等主題的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有兩種版本：Magistral Small 和 Magistral Medium。Magistral Small 擁有 240 億個參數，在 Apache 2.0 協議下開源。Magistral Medium 是一款功能更強大的模型，目前已在 Mistral 的 Le Chat 聊天機器人平台、該公司的 API 以及第三方合作伙伴雲平台上提供預覽。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中寫道：「Magistral 適用於各種企業用例，從結構化計算和程序邏輯到決策樹和基於規則的系統。這些模型針對多步驟邏輯進行了微調，提高了可解釋性，並以用户的語言提供了可追溯的思維過程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立於 2023 年，該公司得到了 General Catalyst 等風險投資機構的支持，迄今已籌集超過 11 億歐元（約合 12.4 億美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;儘管 Mistral 資源雄厚，但在某些領域，例如推理模型開發，Mistral 仍落後於其他領先的人工智能實驗室。從 Mistral 自身的基準測試來看，Magistral 似乎也並非一款特別有競爭力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 測試中，Magistral Medium 的表現不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的編程基準 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或許正因如此，Mistral 在其博客文章中大力宣揚 Magistral 的其他優勢。聲稱 Magistral 在 Le Chat 中提供答案的速度是競爭對手的「10 倍」，並且支持多種語言，包括意大利語、阿拉伯語、俄語和簡體中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的發佈是在 Mistral 推出「vibe coding」客户端 Mistral Code 之後。在此之前的幾周，Mistral&amp;nbsp;推出了幾款專注於編碼的模型，並推出了 Le Chat Enterprise，一項面向企業的聊天機器人服務，提供 AI 代理構建器等工具，並將 Mistral 的模型與 Gmail 和 SharePoint 等第三方服務集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sat, 10 May 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 發佈 o3-pro：更強大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;發佈&lt;/a&gt;了 o3-pro 推理模型，基於 o3 所打造，擁有更強的數學、科學、編程等領域的表現。&lt;/p&gt; 
&lt;p&gt;據介紹，o3-Pro 可，自動調用多種工具，包括可以搜索網頁、分析文件、推理視覺輸入、使用 Python、通過記憶功能個性化回覆等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由於調用的工具較多，所以，思考的時間比 o1 Pro、o3 更長。&lt;/strong&gt;o3-pro 與 o3 系列一樣擁有 200K 的上下文窗口和 100K 的輸出，但價格卻比它們暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表現上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在專家評估中，評審人員普遍認為 o3 Pro 在多方面都比 o3 模型更進一步，尤其適合用在科學、教育、編程、商業和寫作這些需要深度輸出的任務中。&lt;/li&gt; 
 &lt;li&gt;在學術評估的基準測試中，o3-pro 的整體表現持續優於 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 還通過四次嘗試獲取正確答案的方式進行實驗發現，o3-pro 能保持較好的性能表現。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企業版和教育版用户將在下週獲得使用權限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;價格方面，o3-pro 輸入為 20 美元/百萬 token，輸出 80 美元/百萬 token；而 OpenAI CEO Sam Altman 昨晚宣佈，o3 降價 80%——因此 o3 價格來到了輸出 2 美元/百萬 token、輸入 8 美元/百萬 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sat, 10 May 2025 02:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
