<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 15 Jan 2025 12:36:28 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>開源日報 | Vim 項目現狀；MiniMax-01 開源；PG 獲年度數據庫「五冠王」；給 AI 喂料的小技巧；USB 全新標識公佈；AI 公司是真餓了</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2025.1.15&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要聞&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/329871&quot;&gt;「蘋果 AI」有望在 2025 年亮相中國，已成立新公司&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;蘋果智能（Apple Intelligence）有望在 2025 年正式亮相中國市場。據企查查官方消息，1 月 10 日，蘋果技術開發（上海）有限公司成立，法定代表人為 Tejas Kirit Gala，註冊資本 3500 萬美元。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;公開數據顯示，該公司行業屬於軟件開發，主要經營範圍涵蓋軟件開發、大數據服務、數據處理服務以及存儲支持服務等。股權穿透顯示，該公司由 APPLE SOUTH ASIA PTE. LTD. 全資持股。 &lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-edfee4212ec5891786272e788dfd1f13d64.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;蘋果 CEO 庫克在 2024 年三次訪華期間，曾提到關於中國市場推出 AI 手機的計劃，並強調了公司正在努力推進這一計劃。因此有理由推測，蘋果公司通過這家新公司，在中國加速推進 Apple Intelligence 服務落地。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329832/the-state-of-vim-2024&quot;&gt;Vim 項目現狀&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Vim 創始人及終身仁慈獨裁者（BDFL）Bram Moolenaar 於 2023 年的&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/252537/vim-bram-moolenaar-passed-away&quot; target=&quot;_blank&quot;&gt;離世&lt;/a&gt;&lt;/u&gt;讓社區感到震驚，同時也引發了對項目未來的擔憂。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;在 2024 年 11 月舉行的 VimConf 大會上，現任 Vim 維護者 Christian Brabandt 發表主題演講&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;「Vim 項目的新生」(the new Vim project&quot;)&lt;/strong&gt;&lt;/em&gt;，介紹了社區如何重組以繼續維護 Vim，以及未來的發展方向。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;1508&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-886ea4f159abbbba6378f9ee859fc1428b7.png&quot; width=&quot;2714&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FbopbmRyHQog%3Fsi%3DBHzt6g_yK0Xlc5PU&quot; target=&quot;_blank&quot;&gt;https://youtu.be/bopbmRyHQog?si=BHzt6g_yK0Xlc5PU&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329775&quot;&gt;MiniMax 開源新一代 01 系列模型&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;MiniMax 發佈並開源了 MiniMax-01 全新系列模型，其中包含：基礎語言大模型 MiniMax-Text-01 和視覺多模態大模型 MiniMax-VL-01。&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，MiniMax-01 系列模型首次大規模實現線性注意力機制，傳統 Transformer 架構不再是唯一的選擇。這個模型的參數量高達 4560 億，其中單次激活 459 億。模型綜合性能比肩海外頂尖模型，同時能夠高效處理全球最長 400 萬 token 的上下文，是 GPT-4o 的 32 倍，Claude-3.5-Sonnet 的 20 倍。&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，官方給出的標準定價是輸入 token 1 元 / 百萬 token，輸出 token 8 元 / 百萬 token。&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/329793/pgsql-is-the-dbms-of-the-year-2024&quot;&gt;DB-Engines 公佈 2024 年度數據庫：PostgreSQL&lt;/a&gt;&lt;/h3&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;DB-Engines&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdb-engines.com%2Fen%2Fblog_post%2F106&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;宣佈&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/u&gt;PostgreSQL 獲得 「2024 年度數據庫」 稱號，這是它連續第二年贏得此殊榮，也是在 2017、2018、2019 和 2023 年稱霸之後，第五次榮登榜首 —— 名副其實的 「五冠王」。&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0115/112602_ZPyK_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;DB-Engines 是全球知名的數據庫流行度排行榜網站，其評選年度數據庫的標準為：計算數據庫當前最新流行度分數的同比增長量，分數增長最多的即為年度數據庫。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329831/angular-2025-strategy&quot;&gt;Angular 團隊公佈 2025 年戰略&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌 Angular 產品和開發者關係負責人 Minko Gechev 日前發表了一篇關於 Angular 2025 戰略的博客文章&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.angular.dev%2Fangular-2025-strategy-9ca333dfc334&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;表示&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，團隊的年度戰略重點是投資於有助於 Angular 開發人員取得成功的關鍵領域。目前正在針對以下幾個目標進行優化：&lt;/span&gt;&lt;/p&gt; 
 &lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過增強開發者體驗來提高開發者滿意度。以及將通過繼續為生態系統帶來創新，來突破性能和開發者體驗的界限。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持採用最新的改進。包括使用 schematics 簡化新功能的採用、提高 Angular 社區內外功能的可見性等等。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;具體而言，為了進一步改善開發者體驗，Gechev 提出計劃在 2025 年將 zoneless 推廣到開發者預覽版，使 Angular 具有更高效的變化檢測能力、提高互操作性（例如，在 MFE 中）、並提高初始加載性能，以及推出 Signal forms 功能——目前正在處於設計階段，「我們將繼續支持現有的表單模塊，使其與 signal forms 可互操作，同時逐步推薦 signal forms 作為最佳實踐。」&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329785/updated-usb-logo&quot;&gt;USB 全新標識將直接標註傳輸速度、功率&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;全新的 USB 標識相較於舊版更加直觀，捨棄了舊版的「USB 3.2 Gen1」、「USB 3.2 Gen2」等類似後綴，改為了由傳輸速度和充電功率作為後綴。其中設備與數據線的傳輸速度以 Gbps 為單位，而充電功率統一使用「W（瓦）」為單位。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;新的 USB 標識採用速度優先的原則，用清晰易懂的數字直接標明數據傳輸速度，例如 USB 80Gbps、USB 40Gbps 等，取代以往 USB4 v2 等複雜表述。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;新的 USB 標識也適用於線纜標識，會在線纜上同時標明數據傳輸速度和供電能力。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8927f2637a1e49be5f4f484a0dbd1c19b2e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;USB-IF 強調此次更新旨在解決長期以來消費者對 USB 標識的困惑，尤其是在 2017 年 USB 3.2 推出時，諸如 Gen 2x2 和 SuperSpeed USB 20Gbps 等讓消費者難以理解實際規格的複雜命名。&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329784/ms-core-ai-platform-and-tools&quot;&gt;微軟 CEO 納德拉宣佈組建新 AI 團隊「CoreAI」&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，微軟 CEO Satya Nadella 在官方博客&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2025%2F01%2F13%2Fintroducing-core-ai-platform-and-tools%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;，微軟將組建新的 AI 團隊「CoreAI」。&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img height=&quot;1420&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0115/104102_Ifg5_2720166.png&quot; width=&quot;1500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;據介紹，CoreAI 將專注於開發端到端的 AI 應用平台與工具，為微軟自己與其第三方客户打造端到端的 Copilot 和 AI 堆棧，以構建和運行 AI App 及 AI Agents（人工智能代理）。同時 CoreAI 還將打造 GitHub Copilot，從而在領先的 AI 產品與 AI 平台之間建立緊密的反饋循環，以推動堆棧及其路線圖的發展。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;據瞭解，&lt;strong&gt;CoreAI 將彙集開發部、AI 平台以及 CTO 辦公室的一些關鍵團隊（包含 AI 超級計算機、AI Agentic Runtime 和 Engineering Thrive&lt;/strong&gt;。&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329788&quot;&gt;「TikTok 難民」突然湧入——小紅書內部觀點尚未達成一致，國內互聯網公司紛紛發英文貼攬客&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;近日，TikTok 「禁令」 進入倒計時，而許多美國網友並沒有選擇使用 Instagram Reels 和 YouTube Shorts 等 TikTok 在美國競爭對手的平台，而是決定加入另一箇中國社交媒體平台：小紅書。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;小紅書也登上了 App Store 美區的下載榜榜首。小紅書或許也因此成為有史以來第一款登頂美區下載榜的名字全是漢字的 App。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;從多位小紅書內部人士處瞭解到，&lt;strong&gt;「內部對此次事件的觀點尚不能達成一致」&lt;/strong&gt;。核心的爭議在於全球化的挑戰大於流量承接的喜悦，「這個事情是偶發的、突然的」。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;據悉，這並非小紅書首次承接來自 TikTok 的流量，小紅書上一次有大規模外國人出現還是 「外國人聽勸」 系列，事後內部也曾拉數據查看，對 DAU 的帶動並不明顯。目前尚不清楚有多少海外用户湧入，以及其所對應的筆記量。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;但截至發稿，TikTokRefugee 詞條下顯示有 7 萬 + 筆記。有部分人士認為，此舉無法等同於小紅書的全球化。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;值得注意的是，很多國內互聯網公司也藉機以玩梗名義試圖吸引這波流量。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0115/111320_fkVG_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FDpZDot5UxL0a06O0EXXXNw&quot; target=&quot;_blank&quot;&gt;10 位 CEO 覆盤：我們眼中的 2024 中國 To B 市場&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt;
    To B 市場在 2025 將有什麼新焦點？AI，AI，還是 AI。場景，場景，還是場景。市場會理性迴歸，價值向真實需求靠攏。
   &lt;/div&gt; 
   &lt;div&gt;
    &lt;br&gt; 除了 AI 和場景落地，這些關鍵詞同樣值得關注：大模型產業化落地、場景化 AI 應用、傳統軟件 AI 轉型、輕量級應用崛起、多技術協同創新、算力升級、安全合規建設、「通算+智算」演進、敏捷迭代開發、流程與場景變革。
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微信&lt;strong&gt;&amp;nbsp;雷峯網&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1805300532%2FP9BUiAO1H&quot; target=&quot;_blank&quot;&gt;從聊天室 icq msnspace 直接快進到了此刻&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt;
    在小紅書看了駐韓美軍説自己累死了，交貓税的筆記下面討論為什麼全世界都養狸花。中國人幫美國人做數學卷子，美國人幫中國人做英語完形填空，美國人説我們教育不好所以可能做的是錯的，美國南方人説我們的英語被考試看不起中國南方人説中國也是。亞利桑那州紅脖曬自己釣的大魚評論區完全是小紅書風格一堆人曬自己釣的更大的魚。極樂迪斯科粉絲找同好評論區曬中國同城聚會的照片他説這是天堂吧。黑人音樂家吹拉彈唱講解。中國人問美國人是不是要打兩個工才能生活，一千多條回覆講自己怎麼辛勤工作。洋女給歐美同人圈帶來新糧。還有原住民發科普視頻，評論區最熱門的話題是你們吃啥呀好吃嗎遊客去吃貴嗎。印度北部人跟中國語言研究者討論他那兒是不是藏緬語族交換語音對照表。還看到了離我開車 15 分鐘的地方的農場裏的牛，以及各個州的牛馬驢在荒涼的農場上。農民曬自己剛拔的巨大的蕪菁。美國女礦工下井，女科學家做實驗。中國觀鳥者想看外國稀罕鳥，評論區有上千張稀罕鳥的照片。
   &lt;/div&gt; 
   &lt;div&gt;
    &amp;nbsp;
   &lt;/div&gt; 
   &lt;div&gt;
    好像從聊天室 icq msnspace 直接快進到了此刻，中間發生的一切是一場夢。
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div style=&quot;text-align:right&quot;&gt;
    &lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;/span&gt;
    &lt;strong&gt;庫特納霍拉的骨頭&lt;/strong&gt;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FP9F1MbpIp&quot; target=&quot;_blank&quot;&gt;搜索引擎&amp;amp;爬蟲工程師的工具鏈面臨洗牌&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;搜索引擎&amp;amp;爬蟲工程師的工具鏈感覺現在全面面臨洗牌了。以前靠 SVM 來分類，靠 TF-IDF 來抽關鍵詞，trie-tree 來過濾敏感詞，基於文本密度算法來抽正文，靠餘弦相似度等相似度算法來消重。&lt;br&gt; 現在，大模型能全面取代這些傳統 NLP 做法了。&lt;/p&gt; 
   &lt;p&gt;我現在抽正文就在用 reader-lm-1.5b，這個模型能把 html 轉 markdown，然後再消息隊列塞給下游模型用定義好的 Agent 來分類，提取關鍵詞和摘要。最後入庫之前 RAG 檢索做消重。尤其是文本內容的對抗進化沒那麼快，現在打不過 LLM（比如寫點抽象的東西來規避過濾，LLM 能輕鬆認出來，但是基於敏感詞的 trie-tree 效果就很差）。所以 LLM 除了耗資源幾乎無缺點了。&lt;/p&gt; 
   &lt;p&gt;reader-lm-1.5b 地址：huggingface.co/jinaai/reader-lm-1.5b&lt;br&gt; 這個模型小到不用量化，純 CPU 都能跑得飛起。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; karminski-牙醫&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F3624125415%2FP9GURmzlc&quot; target=&quot;_blank&quot;&gt;日常給 AI 喂料的小技巧&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;如果你想丟給它的網頁沒有圖表，那直接用 MarkDownload 插件剝離圖片和鏈接直接把純 Md 文件給它就行。&lt;br&gt; 如果你想對給它的網頁有圖表，並且希望它讀圖表，那最簡單的路徑是用 Safari 打開網頁，點擊閲讀器模式然後另存為 PDF。&lt;/p&gt; 
   &lt;p&gt;第二點能大幅減少網頁中非文章幹擾項對 AI 的影響。&lt;/p&gt; 
   &lt;div&gt; 
    &lt;div style=&quot;text-align:right&quot;&gt;
     &lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 評論屍&lt;/strong&gt;&lt;/span&gt;
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.ce.cn%2Fcysc%2Ftech%2Fgd2012%2F202501%2F15%2Ft20250115_39266930.shtml&quot; target=&quot;_blank&quot;&gt;日本人工智能應用潛力仍存&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;近年來，日本在人工智能應用方面積極探索，在製造業、農業、教育等諸多領域都湧現出一些創新案例。但整體而言，日本社會對 AI 科技的接受程度並不高。在全面擁抱 AI 時代之前，日本社會的當務之急是更加大膽地踏進信息化時代。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;經濟日報&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.stcn.com%2Farticle%2Fdetail%2F1494755.html&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;中國科技企業宜以 AI 為槳高質量「出海」&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#141414&quot;&gt;在數字化智能化浪潮下，中國科技企業新一輪「走出去」如何突破、紮根、攀升？筆者認為，中國科技企業「出海」宜以人工智能等新技術為槳，佈局未來、跨界融合、鑄就自主品牌力，加速從「走出去」到「融進去」，邁向更深層次的全球化。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;證券日報&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FI_7VeBN5eX7jdatXeZqfpg&quot; target=&quot;_blank&quot;&gt;AI 公司是真「餓了」，開始砸錢買你拍的「廢片」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;Open AI、Google、Moonvalley 等公司正在購買視頻創作者們拍攝但未使用的「廢片」。高質量 4K、無人機、3D 動畫素材，1 - 4 美元（約合 7.3 - 30 元）一分鐘，為了 YouTube、TikTok、Instagram 等網絡視頻製作的素材 1 - 2 美元（約 7.3 - 15 元）一分鐘。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;極客公園&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Fcj%2F2025-01-15%2Fdoc-ineeznmc7926338.shtml&quot; target=&quot;_blank&quot;&gt;英偉達帶火的世界基礎模型，會給工業企業帶來哪些變革？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在真正的全系統數字孿生技術可行之前，還需要五年甚至更長的時間，但是在此期間，涉及日益複雜的系統的數字孿生的中間步驟仍然是可行的。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;中歐商業評論&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.163.com%2Fdy%2Farticle%2FJLUFH9PT0511CPMT.html&quot; target=&quot;_blank&quot;&gt;贏下芯片競賽，美國最新計劃&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#404040; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#404040&quot;&gt;SIA 總裁兼首席執行官 John Neuffer 在給美國即將上任總統特朗普的一封信中表示，未來四年對美國和世界都非常重要。而美國半導體行業隨時準備與他合作，加強美國的經濟實力、國家安全、創新基礎和技術領導地位。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#252525&quot;&gt;&lt;strong&gt;半導體行業觀察&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F3122598500864004&quot; target=&quot;_blank&quot;&gt;美國管控新規會否終止 AI 行情？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#262626; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#262626&quot;&gt;如果特朗普政府放鬆對人工智能基礎設施建設的限制、放寬有關核反應堆開發的規定，英偉達的業務可能會因此獲得提振，核反應堆對於未來 10 年為人工智能項目提供足夠的能源至關重要。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;巴倫週刊&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FLuxCoreRender%2FLuxCore&quot; target=&quot;_blank&quot;&gt;LuxCoreRender/LuxCore&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;img height=&quot;281&quot; src=&quot;https://static.oschina.net/uploads/space/2022/0411/154306_9VlU_4937141.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FLuxCoreRender%2FLuxCore&quot; target=&quot;_blank&quot;&gt;https://github.com/LuxCoreRender/LuxCore&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;LuxCoreRender 是一個物理上正確的、無偏差的渲染引擎。它建立在以物理學為基礎的方程上，對光的傳輸進行建模。這使得它能夠準確地捕捉到其他大多數渲染程序根本無法再現的廣泛現象。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/mumu/blog/16689206&quot; target=&quot;_blank&quot;&gt;《Apache Shiro 源碼解析》- 8. 緩存&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#3f3f3f; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;有很多數據實際上並不需要在每次請求中都重新計算，我們可以將計算結果緩存起來，至少在一個特定的時間段以內，都可以直接從緩存中撈出數據，從而顯著降低系統資源的消耗。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#3f3f3f; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;264&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ccdf45862b9b32131b4b3c611b4601b864.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvwtZvcqIMNZba-wPRMgIwQ&quot; target=&quot;_blank&quot;&gt;Linus 祖師爺沉迷「焊接」，將親自打造一套吉他效果器踏板贈送給內核開發者&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：Pedal 翻譯成踏板意義不準確，應該是叫單塊效果器。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：師傅請問你是做什麼工作的.jpg&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：作為一名軟件工程師，隨身攜帶電烙鐵也很合理吧。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：他温和了好多&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：他又沒有狂躁症,&amp;nbsp;就是生氣的時候罵人而已&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：祖師爺性情中人罷了，而且也是對事不對人，本身性格和人品應該很 nice 的那種吧&lt;/span&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：對事也對人，比如俄國人&lt;/span&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：聖皇手作&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 9：非常有名的潛水日誌管理軟件 subsurface 也是 Linus 開發的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 10：現在就去義烏下單開模，讓 Linus 大吃一驚而且賣不出去&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 11：卧槽，我也是，吉他彈不好，一天就知道折騰&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKizE4dln1C3R2AsE8oM8dQ&quot; target=&quot;_blank&quot;&gt;小紅書用户迷惑行為大賞&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：我的首頁已經被兩美元起中文名的帖子霸佔了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：講個都市傳説，我有個碩士學歷的前同事根本不會用 M$&amp;nbsp;Word，她甚至用空格來居中文本（而且還沒對齊）&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：我的媽呀，那是怎麼碩士畢業的，用 LaTex？&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：好厲害，第一天就提了&amp;nbsp;mr，那第二天不得提個新版本&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：我人都麻了，這個語氣，學習 k8s，好像學習如何用打火石在野外點火一樣輕鬆&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：手抄代碼可以的，可以快速加入圖解理解邏輯原理，但抄代碼記憶的話就不懂了……&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：k8s 提 pr？就相當於第一次當兵，給航母提功能，，&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0912/150800_DfGR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329886</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329886</guid>
            <pubDate>Tue, 07 Jan 2025 10:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「蘋果 AI」有望在 2025 年亮相中國，已成立新公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;蘋果智能（Apple Intelligence）有望在 2025 年正式亮相中國市場。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-edfee4212ec5891786272e788dfd1f13d64.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據企查查官方消息，1 月 10 日，蘋果技術開發（上海）有限公司成立，法定代表人為 Tejas Kirit Gala，註冊資本 3500 萬美元。&lt;/p&gt; 
&lt;p&gt;公開數據顯示，該公司行業屬於軟件開發，主要經營範圍涵蓋軟件開發、大數據服務、數據處理服務以及存儲支持服務等。股權穿透顯示，該公司由 APPLE SOUTH ASIA PTE. LTD.全資持股。 &lt;/p&gt; 
&lt;p&gt;蘋果 CEO 庫克在 2024 年三次訪華期間，曾提到關於中國市場推出 AI 手機的計劃，並強調了公司正在努力推進這一計劃。&lt;/p&gt; 
&lt;p&gt;因此有理由推測，蘋果公司通過這家新公司，在中國加速推進 Apple Intelligence 服務落地。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;研究機構 Canalys 的分析師認為，蘋果在中國提供的&lt;/span&gt;Apple Intelligence&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;服務不僅可能包含自研大模型，還將整合中國本地科技公司的技術。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/325657/apple-talks-with-tencent-bytedance&quot; target=&quot;news&quot;&gt;蘋果與騰訊、字節接洽，考慮將二者 AI 模型整合到國行 iPhone&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329871</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329871</guid>
            <pubDate>Tue, 07 Jan 2025 09:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>《Apache Shiro 源碼解析》- 8. 緩存</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72fd2193957d13fba54be5f6a99f6ca2700.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;8.緩存&lt;/h1&gt; 
&lt;p&gt;本章將深入探討 Shiro 的緩存架構，並對核心組件的源代碼進行解析。&lt;/p&gt; 
&lt;h2&gt;8.1 Shiro 為什麼引入緩存機制&lt;/h2&gt; 
&lt;p&gt;隨着用户規模的不斷擴大，認證、授權和加密等模塊的調用次數會迅速增加。例如，當每秒有 100 萬用户嘗試登錄系統時，認證模塊每秒會被調用 100 萬次。此時， CPU 和 Memory 都會飆升，性能問題將不可避免地浮現出來。&lt;/p&gt; 
&lt;p&gt;那麼，如何在架構層面解決這些可能出現的性能瓶頸呢？最常見的解決方案就是引入緩存機制。有很多數據實際上並不需要在每次請求中都重新計算，我們可以將計算結果緩存起來，至少在一個特定的時間段以內，都可以直接從緩存中撈出數據，從而顯著降低系統資源的消耗。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;提升性能正是 Shiro 框架引入緩存機制的一個重要原因。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Shiro 中，緩存主要用於以下 3 個方面：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;認證緩存&lt;/strong&gt;：存儲用户的認證信息，避免每次請求都需要重新認證。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;授權緩存&lt;/strong&gt;：存儲用户的角色和權限信息，避免每次訪問資源都去查詢數據庫獲取權限。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session 緩存&lt;/strong&gt;: 用來緩存會話信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;注意：默認情況下，Shiro 並不會啓用任何緩存，開發者需要在 &lt;code&gt;ShiroConfig.java&lt;/code&gt; 中顯式配置緩存管理器，指定 Shiro 應該使用哪種緩存組件。&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;
@Configuration
public class ShiroConfig {
  //...

  @Bean
  public EhCacheManager ehCacheManager(){
      EhCacheManager cacheManager = new EhCacheManager();
      cacheManager.setCacheManagerConfigFile(&quot;classpath:ehcache-shiro.xml&quot;);
      return cacheManager;
  }

  //...
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;8.2 Shiro 的緩存架構&lt;/h2&gt; 
&lt;h3&gt;8.2.1 核心組件&lt;/h3&gt; 
&lt;p&gt;Shiro 的緩存架構由 3 個核心接口組成： &lt;code&gt;CachingRealm&lt;/code&gt;、&lt;code&gt;CacheManager&lt;/code&gt;、和&lt;code&gt;Cache&lt;/code&gt; ，這些類型之間的依賴關係如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1ccdf45862b9b32131b4b3c611b4601b864.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這些類型的名稱都帶有 Cache 或者 Caching 前綴：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CachingRealm：Realm 的實現類，它會持有一個 CacheManager 的實例。&lt;/li&gt; 
 &lt;li&gt;CacheManager：緩存管理器，負責管理緩存組件的生命週期，它會持有具體緩存組件的實例。&lt;/li&gt; 
 &lt;li&gt;Cache：緩存組件本身需要實現的接口。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;8.2.2 源碼分析&lt;/h3&gt; 
&lt;p&gt;我們先分析整體的運行機制，然後再逐步解析核心組件的源代碼。&lt;/p&gt; 
&lt;h4&gt;8.2.2.1 整體運行機制&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8018da9881f081e4dc318c2e7ea90771641.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，&lt;code&gt;CachingRealm&lt;/code&gt; 中持有了一個 &lt;code&gt;CacheManager&lt;/code&gt; 類型的實例，而 &lt;code&gt;CachingSecurityManager&lt;/code&gt; 類中也持有了一個 &lt;code&gt;CacheManager&lt;/code&gt; 類型的實例。那麼，這兩個 &lt;code&gt;CacheManager&lt;/code&gt; 類型的實例之間是什麼關係呢？是同一個實例嗎？&lt;/p&gt; 
&lt;p&gt;我們來逐步分析源代碼，我們從入口類 ShiroConfig.java 開始，在創建具體的 &lt;code&gt;SecurityManager&lt;/code&gt; 實例時，開發者可以指定具體使用哪一種 &lt;code&gt;CacheManager&lt;/code&gt; ，示例代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Bean
public EhCacheManager ehCacheManager(){
    EhCacheManager cacheManager = new EhCacheManager();
    cacheManager.setCacheManagerConfigFile(&quot;classpath:ehcache-shiro.xml&quot;);
    return cacheManager;
}

@Bean
public SecurityManager securityManager(){
    DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager();
    securityManager.setRealm(nicefishRbacRealm());
    securityManager.setRememberMeManager(rememberMeManager());
    securityManager.setSessionManager(sessionManager());
    **securityManager.setCacheManager(ehCacheManager());**
    return securityManager;
}

//...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從以上代碼可以看到，開發者只需要調用 securityManager.setCacheManager 方法設置緩存管理器就可以了，並不需要手動調用 &lt;code&gt;CachingRealm&lt;/code&gt; 類型上定義的 setCacheManager 方法。那麼，&lt;code&gt;CachingRealm&lt;/code&gt; 類型上定義的 setCacheManager 方法是何時被自動調用的呢？我們再次回顧以下 &lt;code&gt;SecurityManager&lt;/code&gt; 相關的繼承結構：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-126c0eacc334e54548be3637964ab69733a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 &lt;code&gt;RealmSecurityManager&lt;/code&gt; 這一層，我們可以看到如下代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;
public void setRealms(Collection&amp;lt;Realm&amp;gt; realms) {
    if (realms == null) {
        throw new IllegalArgumentException(&quot;Realms collection argument cannot be null.&quot;);
    }
    if (realms.isEmpty()) {
        throw new IllegalArgumentException(&quot;Realms collection argument cannot be empty.&quot;);
    }
    this.realms = realms;
    afterRealmsSet();
}

protected void afterRealmsSet() {
    applyCacheManagerToRealms();
    applyEventBusToRealms();
}

protected void applyCacheManagerToRealms() {
    CacheManager cacheManager = getCacheManager();
    Collection&amp;lt;Realm&amp;gt; realms = getRealms();
    if (cacheManager != null &amp;amp;&amp;amp; realms != null &amp;amp;&amp;amp; !realms.isEmpty()) {
        for (Realm realm : realms) {
            if (realm instanceof CacheManagerAware) {
                ((CacheManagerAware) realm).setCacheManager(cacheManager);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;關鍵的方法調用軌跡是： setRealms-&amp;gt;afterRealmsSet-&amp;gt;applyCacheManagerToRealms 。在 applyCacheManagerToRealms 中，如果 Shiro 發現某個 Realm 的實例實現了 CacheManagerAware 接口，就會自動把 cacheManager 實例設置給它。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;// CachingRealm 的構造方法
public abstract class CachingRealm implements Realm, Nameable, **CacheManagerAware** , LogoutAware
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如上所示，由於 CachingRealm 實現了 CacheManagerAware 接口，所以在運行時 CachingRealm 和 RealmSecurityManager 上的 cacheManager 是同一個實例。&lt;strong&gt;這就意味着，開發者在配置緩存管理器時，應該調用 securityManager 對象上的 setCacheManager 方法，而不是調用 Realm 實例上的同名方法，否則在運行時 cacheManager 實例會被覆蓋。&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;8.2.2.2 CacheManager 源碼分析&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;CacheManager&lt;/code&gt; 是 Shiro 緩存系統的核心接口，它負責管理緩存組件的生命週期，以下是 &lt;code&gt;CacheManager&lt;/code&gt; 相關的繼承結構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c7ae174239efc9cff7083a6b93741184369.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Destroyable&lt;/code&gt; 接口&lt;/strong&gt; ：定義了 &lt;code&gt;destroy()&lt;/code&gt; 方法，用於在緩存管理器銷燬時清理資源，確保緩存的數據和資源得以正確釋放。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;CacheManager&lt;/code&gt; 接口&lt;/strong&gt; ：提供獲取緩存的核心方法 &lt;code&gt;getCache(String name)&lt;/code&gt;，是所有緩存管理器的頂層接口。通過實現 &lt;code&gt;CacheManager&lt;/code&gt; 接口，開發者可以自定義緩存管理器以適應不同的緩存需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;AbstractCacheManager&lt;/code&gt;&lt;/strong&gt; ：作為抽象基類，它為 &lt;code&gt;CacheManager&lt;/code&gt; 提供了 &lt;code&gt;createCache(String name)&lt;/code&gt; 的基礎實現，並實現了 &lt;code&gt;destroy()&lt;/code&gt; 方法。這意味着它具備緩存管理器的基礎功能，可以銷燬緩存，同時允許子類根據需要創建特定類型的緩存。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MemoryConstrainedCacheManager&lt;/code&gt;&lt;/strong&gt; ：Shiro 提供的輕量級緩存管理器，繼承自 &lt;code&gt;AbstractCacheManager&lt;/code&gt;。它將所有緩存數據保存在 JVM 內存中，適合小型應用或資源有限的環境。由於其緩存是基於內存的，一旦 JVM 重啓，緩存數據將會丟失。這使得該緩存管理器在處理敏感數據時的持久化能力較差，因此主要適用於對數據持久性要求不高的場景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;EhCacheManager&lt;/code&gt;&lt;/strong&gt; ：此緩存管理器繼承自 &lt;code&gt;AbstractCacheManager&lt;/code&gt;，並實現了 &lt;code&gt;CacheManager&lt;/code&gt; 和 &lt;code&gt;Destroyable&lt;/code&gt; 接口。&lt;code&gt;EhCacheManager&lt;/code&gt; 集成了開源的 EhCache 框架。EhCache 支持磁盤持久化、多級緩存（內存+磁盤緩存）、集羣部署等功能，適用於中大型應用。通過 &lt;code&gt;cacheManagerConfigFile&lt;/code&gt; 配置文件，EhCacheManager 可以對緩存進行自定義配置，確保在高併發情況下提供更好的性能和可擴展性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;8.2.2.3 AbstractCacheManager 源碼解析&lt;/h4&gt; 
&lt;p&gt;AbstractCacheManager 是抽象基類，它實現了緩存管理的基本功能，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;緩存的惰性創建：只有在第一次訪問某個緩存時，才會創建該緩存。&lt;/li&gt; 
 &lt;li&gt;線程安全管理：通過使用 ConcurrentHashMap 確保緩存管理器在併發環境中的安全性。&lt;/li&gt; 
 &lt;li&gt;緩存銷燬機制：提供 destroy() 方法，用於清理資源並銷燬所有緩存。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AbstractCacheManager 的源代碼非常簡單，去掉註釋之後只有幾十行。其中，createCache(String name) 是一個關鍵的抽象方法，具體的緩存創建邏輯由子類實現，例如 MemoryConstrainedCacheManager 和 EhCacheManager 會分別實現該方法，以創建特定類型的緩存實例。&lt;/p&gt; 
&lt;h4&gt;8.2.2.4 MemoryConstrainedCacheManager 源碼解析&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;MemoryConstrainedCacheManager&lt;/code&gt; 是基於內存的緩存管理器，它的源碼非常簡單，源代碼全文引用如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;package org.apache.shiro.cache;

import org.apache.shiro.util.SoftHashMap;

public class MemoryConstrainedCacheManager extends AbstractCacheManager {
    @Override
    protected Cache createCache(String name) {
        //注意，這裏創建的緩存實例類型是 MapCache
        return new MapCache&amp;lt;Object, Object&amp;gt;(name, new SoftHashMap&amp;lt;Object, Object&amp;gt;());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從代碼中我們可以看到，這個管理器持有了一個 MapCache 的實例，具體的數據就存儲在這個實例裏面。 MapCache 是 Shiro 自己實現的一個簡單緩存，基於 JDK 內置的 Map 實現，我們在 8.2.3 中分析它的源代碼。&lt;/p&gt; 
&lt;p&gt;MemoryConstrained 這個單詞的字面意思是&quot;內存受限&quot; ，所以 &lt;code&gt;MemoryConstrainedCacheManager&lt;/code&gt; 這個類名已經暗示了它的適用場景：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;內存受限的環境&lt;/strong&gt;：適合內存有限的應用場景，比如嵌入式系統、移動設備或需要在服務器端進行精確內存控制的應用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;簡單緩存管理&lt;/strong&gt;：不需要外部依賴（如 Redis）的簡單緩存場景，能夠快速使用內存緩存。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;8.2.2.5 EhCacheManager 源碼解析&lt;/h4&gt; 
&lt;p&gt;EhCacheManager 的實現同樣非常簡單，就如同它的名字一樣，主要負責創建並管理 EhCache 組件的實例，與此相關的代碼在 EhCacheManager.ensureCacheManager 方法中：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;private net.sf.ehcache.CacheManager ensureCacheManager() {
    try {
        if (this.manager == null) {
            if (log.isDebugEnabled()) {
                log.debug(&quot;cacheManager property not set.  Constructing CacheManager instance... &quot;);
            }
            //using the CacheManager constructor, the resulting instance is _not_ a VM singleton
            //(as would be the case by calling CacheManager.getInstance().  We do not use the getInstance here
            //because we need to know if we need to destroy the CacheManager instance - using the static call,
            //we don&#39;t know which component is responsible for shutting it down.  By using a single EhCacheManager,
            //it will always know to shut down the instance if it was responsible for creating it.

            //注意這裏， new 出了 Ehcache 的實例。
            this.manager = new net.sf.ehcache.CacheManager(getCacheManagerConfigFileInputStream());
            if (log.isTraceEnabled()) {
                log.trace(&quot;instantiated Ehcache CacheManager instance.&quot;);
            }
            cacheManagerImplicitlyCreated = true;
            if (log.isDebugEnabled()) {
                log.debug(&quot;implicit cacheManager created successfully.&quot;);
            }
        }
        return this.manager;
    } catch (Exception e) {
        throw new CacheException(e);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Shiro 提供了一個獨立的 jar 包用來封裝對 Ehcache 的支持，包名為 shiro-ehcache.jar ，這個包非常小，裏面只有 2 個類和一個默認的 ehcache.xml 配置文件：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a6b0e30c6601be97b961f5b1b520811079d.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;EhCache 是一個輕量級、快速且功能強大的開源 Java 緩存框架，廣泛應用於提高 Java 應用程序性能。它支持內存和磁盤存儲、多種緩存失效策略和分佈式緩存，非常適合需要頻繁訪問數據的高性能場景。 EhCache 的主要特性如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多級緩存：支持在內存和磁盤中存儲緩存，內存滿時可以自動將數據寫入磁盤。&lt;/li&gt; 
 &lt;li&gt;緩存策略：支持多種緩存失效策略，如最少使用 (LFU)、最近最少使用 (LRU)、FIFO 等。&lt;/li&gt; 
 &lt;li&gt;分佈式緩存：可以與 Terracotta 等分佈式緩存框架集成，實現多節點共享緩存數據。&lt;/li&gt; 
 &lt;li&gt;數據持久性：可以選擇在應用重啓後緩存數據是否保留。&lt;/li&gt; 
 &lt;li&gt;可配置性：通過 XML 或 Java API 配置緩存的大小、存儲方式、失效時間等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;EhCache 的官方網站是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ehcache.org%2F&quot; target=&quot;_blank&quot;&gt;https://www.ehcache.org/&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在該網站上，你可以找到有關 EhCache 的最新版本、文檔、配置指南、使用示例等資源。&lt;/p&gt; 
&lt;h4&gt;8.2.2.6 對接 Redis 緩存&lt;/h4&gt; 
&lt;p&gt;當前，在分佈式系統中，架構師一般會選擇 Redis 作為緩存組件，但是，Shiro 並沒有直接提供一個開箱即用的 RedisCacheManager （原因簡單，因為當年 Redis 還沒有出現。）。開發者可以自己實現 CacheManager 接口，也可以選擇開源的實現，例如 shiro-redis ，它的主頁在：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falexxiyang%2Fshiro-redis&quot; target=&quot;_blank&quot;&gt;https://github.com/alexxiyang/shiro-redis&lt;/a&gt; 。&lt;/p&gt; 
&lt;h3&gt;8.2.3 Cache 源碼分析&lt;/h3&gt; 
&lt;p&gt;接下來我們分析緩存本身的實現，在 Shiro 中，&lt;code&gt;Cache&lt;/code&gt; 接口相關的類繼承結構如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54ea6974ea920ae0d2b5201bae2f5fe2d3c.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;MapCache&lt;/code&gt;是 Shiro 自己提供的一個非常簡單的緩存實現類，它的內部實際上使用了一個 &lt;code&gt;Map&amp;lt;K,V&amp;gt;&lt;/code&gt; 結構來存儲數據，以下是&lt;code&gt;MapCache&lt;/code&gt;的關鍵源代碼：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public class MapCache&amp;lt;K, V&amp;gt; implements Cache&amp;lt;K, V&amp;gt; {

    private final Map&amp;lt;K, V&amp;gt; map;

    //緩存的名稱
    private final String name;

    //構造方法要求外部傳遞一個具體的 Map 實例進來， Shiro 默認使用自己實現的 SoftHashMap 類。
    public MapCache(String name, Map&amp;lt;K, V&amp;gt; backingMap) {
        if (name == null) {
            throw new IllegalArgumentException(&quot;Cache name cannot be null.&quot;);
        }
        if (backingMap == null) {
            throw new IllegalArgumentException(&quot;Backing map cannot be null.&quot;);
        }
        this.name = name;
        this.map = backingMap;
    }

    //...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Shiro 自己實現了一個 &lt;code&gt;SoftHashMap&lt;/code&gt; 來承擔存儲任務，這個類位於 shiro-core-xxx.jar 包中。&lt;code&gt;SoftHashMap&lt;/code&gt; 基於軟引用的哈希映射類實現，可以在內存不足時能夠自動回收不再使用的緩存內容。以下是其核心功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;軟引用存儲&lt;/strong&gt; ：使用 &lt;code&gt;SoftReference&lt;/code&gt; 來存儲值對象，這樣在內存壓力大的情況下，JVM 可以自動回收這些值，避免內存溢出。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;強引用管理&lt;/strong&gt;：維護一個強引用隊列，允許開發者控制保留的強引用數量，以平衡內存使用和緩存命中率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自動清理&lt;/strong&gt;：在訪問緩存時，會自動處理和清理已被回收的軟引用，保持映射的有效性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;線程安全&lt;/strong&gt; ：使用 &lt;code&gt;ConcurrentHashMap&lt;/code&gt; 和 &lt;code&gt;ReentrantLock&lt;/code&gt; 確保在多線程環境下的安全性和一致性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;接口實現&lt;/strong&gt; ：實現了 &lt;code&gt;Map&lt;/code&gt; 接口，提供標準的 Map 操作（如 &lt;code&gt;put&lt;/code&gt;、&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;remove&lt;/code&gt; 等）並支持批量操作。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;也就是説，如果開發者指定 Shiro 使用 &lt;code&gt;MemoryConstrainedCacheManager&lt;/code&gt; 作為緩存管理器，那麼在運行時，最底層承擔存儲任務的是 &lt;code&gt;SoftHashMap&lt;/code&gt; 類的實例。&lt;/p&gt; 
&lt;h3&gt;8.2.4 CachingRealm 源碼分析&lt;/h3&gt; 
&lt;p&gt;由於 &lt;code&gt;Realm&lt;/code&gt; 相關的繼承結構比較深，我們需要再次回顧一下結構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-893596978019e95db5c5b421fe778e54598.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;CachingRealm&lt;/code&gt; 是 &lt;code&gt;Realm&lt;/code&gt; 的實現類，它的類名帶有 Caching 前綴，很明顯它最大的特點就是帶有緩存功能。由於 &lt;code&gt;CachingRealm&lt;/code&gt; 在整個繼承結構中位置非常高，所以在 Shiro 中，所有 Realm 都具備緩存功能，除非開發者自己編寫一個全新的實現類直接實現最頂層的 &lt;code&gt;Realm&lt;/code&gt; 接口。但是這種情況非常少見，因為 Shiro 在每一層 Realm 上都已經實現了很多功能，如果自己從頭實現 &lt;code&gt;Realm&lt;/code&gt; 接口，需要編寫的代碼太多了。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1889ea27d6aeec0e18df3bb6090481ce5aa.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示，&lt;code&gt;CachingRealm&lt;/code&gt;的功能非常簡單，實際上它自己幾乎沒有實現任何功能，把所有具體工作都交給內部的 cacheManager 對象去處理了：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public abstract class CachingRealm implements Realm, Nameable, CacheManagerAware, LogoutAware {
    //...

    private String name;
    private boolean cachingEnabled;
    private CacheManager cacheManager; //實際上是 cacheManager 在做事

    //...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;8.3 Session 緩存&lt;/h2&gt; 
&lt;p&gt;在 Shiro 中，&lt;code&gt;Session&lt;/code&gt; 默認並不會自動走緩存，但 Shiro 設計了緩存會話的機制。&lt;/p&gt; 
&lt;h3&gt;8.3.1 &lt;strong&gt;啓用 Session 緩存&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Shiro 的 &lt;code&gt;Session&lt;/code&gt; 默認存儲在內存中，如果沒有明確配置緩存，Shiro 不會自動緩存 &lt;code&gt;Session&lt;/code&gt; 數據。&lt;/p&gt; 
&lt;p&gt;如果希望將會話信息緩存起來，可以配只 &lt;code&gt;CacheManager&lt;/code&gt; 配置項，通常會使用開源的 &lt;code&gt;EhCacheManager&lt;/code&gt;或者&lt;code&gt;RedisCacheManager&lt;/code&gt; ，以下是使用&lt;code&gt;EhCacheManager&lt;/code&gt;作為 Session 緩存的關鍵代碼（已省略無關代碼）：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;EhCacheManager cacheManager = new EhCacheManager();
cacheManager.setCacheManagerConfigFile(&quot;classpath:shiro-ehcache.xml&quot;);

CachingSessionDAO sessionDAO = new EnterpriseCacheSessionDAO();
sessionDAO.setCacheManager(cacheManager); // 配置 cacheManager

DefaultWebSessionManager sessionManager = new DefaultWebSessionManager();
sessionManager.setSessionDAO(sessionDAO);

DefaultSecurityManager securityManager = new DefaultWebSecurityManager();
securityManager.setSessionManager(sessionManager);
SecurityUtils.setSecurityManager(securityManager);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;8.3.2 CachingSessionDAO 源碼分析&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1c37847578afc846086e3a0b99a5558e13a.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如上圖所示， Shiro 內置的抽象類 &lt;code&gt;CachingSessionDAO&lt;/code&gt; 支持緩存機制，&lt;code&gt;EnterpriseCacheSessionDAO&lt;/code&gt; 是 &lt;code&gt;CachingSessionDAO&lt;/code&gt; 的子類，在 &lt;code&gt;CachingSessionDAO&lt;/code&gt;中，最關鍵的 4 個方法代碼如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public Serializable create(Session session) {
    Serializable sessionId = super.create(session);
    cache(session, sessionId);
    return sessionId;
}

public Session readSession(Serializable sessionId) throws UnknownSessionException {
    Session s = getCachedSession(sessionId);
    if (s == null) {
        s = super.readSession(sessionId);
    }
    return s;
}

public void update(Session session) throws UnknownSessionException {
    doUpdate(session);
    if (session instanceof ValidatingSession) {
        if (((ValidatingSession) session).isValid()) {
            cache(session, session.getId());
        } else {
            uncache(session);
        }
    } else {
        cache(session, session.getId());
    }
}

public void delete(Session session) {
    uncache(session);
    doDelete(session);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;create: 先寫持久層，然後再寫緩存。&lt;/li&gt; 
 &lt;li&gt;readSession: 先嚐試從緩存中讀取 Session ，如果結果為 null ，調用父層的 readSession 去訪問持久層。&lt;/li&gt; 
 &lt;li&gt;update: 先更新持久層，然後更新緩存。&lt;/li&gt; 
 &lt;li&gt;delete: 先刪緩存中的數據，然後再刪持久層數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;從以上代碼我們可以看到，&lt;code&gt;CachingSessionDAO&lt;/code&gt;對緩存的讀寫策略都非常簡單，比如 readSession 方法，採用的是 Read-Through（讀透）策略：如果沒有能夠從緩存中讀取到數據，直接訪問持久層，很容易形成系統瓶頸。&lt;/p&gt; 
&lt;h3&gt;8.3.3 &lt;strong&gt;注意&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在啓用了 Session 緩存之後，系統的複雜度會顯著增加。這是因為緩存中的數據與數據庫中的數據可能會存在不一致的情況，容易導致潛在的邏輯錯誤。因此，開發者在設計系統時，需要謹慎處理 Session 緩存，以確保數據的一致性。&lt;/p&gt; 
&lt;p&gt;Shiro 內置的 &lt;code&gt;CachingSessionDAO&lt;/code&gt; 提供了一種簡單的實現方式，方便開發者快速集成緩存功能。然而， Shiro 畢竟是一個安全框架，並不是專業的緩存框架，開發者在面對更復雜的業務需求時，可能需要設計自己的緩存 DAO。這種自定義的緩存 DAO 可以提供對 Session 的緩存進行更細粒度的控制，從而優化系統性能，減少對數據庫的壓力，並提高響應速度。&lt;/p&gt; 
&lt;p&gt;在設計自己的緩存 DAO 時，開發者可以考慮以下幾個方面：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;緩存策略選擇&lt;/strong&gt;：根據業務場景選擇合適的緩存策略，例如讀透、寫穿或寫後失效等，以確保在性能和一致性之間找到平衡。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;過期與失效管理&lt;/strong&gt;：設置合理的緩存過期時間，以避免緩存中存儲過期數據。同時，設計手動失效機制，以確保重要數據的實時更新。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;監控與調優&lt;/strong&gt;：通過監控緩存的使用情況，分析命中率和訪問模式，從而不斷調整和優化緩存策略，確保系統的高效運行。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在分佈式系統中，推薦使用 Redis 作為 Session 的緩存解決方案。Redis 具有高性能、支持持久化和跨模塊、跨系統共享數據的能力，能夠有效地管理會話數據。在這種架構下，各個模塊和系統之間可以複用會話信息，提升用户體驗並簡化系統管理。&lt;/p&gt; 
&lt;p&gt;綜上所述，雖然 Session 緩存可以帶來性能提升，但也引入了額外的複雜性。開發者應仔細權衡利弊，並在必要時實施更靈活和高效的緩存管理策略，以實現更高效、可靠的系統架構。&lt;/p&gt; 
&lt;h2&gt;8.4 本章小結&lt;/h2&gt; 
&lt;p&gt;為了提升系統的性能，Shiro 內置了對緩存的支持。特別是在頻繁的權限驗證過程中，緩存的引入能極大減少系統的負載。本章詳細解析了 Shiro 的緩存架構，並解析瞭如何與外部緩存組件進行對接。&lt;/p&gt; 
&lt;h2&gt;資源鏈接&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache Shiro 在 github 上的官方倉庫：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fshiro&quot; target=&quot;_blank&quot;&gt;https://github.com/apache/shiro&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apache Shiro 官方網站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fshiro.apache.org%2F&quot; target=&quot;_blank&quot;&gt;https://shiro.apache.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;本書實例項目：&lt;a href=&quot;https://gitee.com/mumu-osc/nicefish-spring-boot&quot;&gt;https://gitee.com/mumu-osc/nicefish-spring-boot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;本書文字稿：&lt;a href=&quot;https://gitee.com/mumu-osc/apache-shiro-source-code-explaination&quot;&gt;https://gitee.com/mumu-osc/apache-shiro-source-code-explaination&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;版權聲明&lt;/h2&gt; 
&lt;p&gt;本書基於 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-nc-nd%2F4.0%2Fdeed.en&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;CC BY-NC-ND 4.0 許可協議&lt;/strong&gt;&lt;/a&gt;發佈，自由轉載-非商用-非衍生-保持署名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;版權歸大漠窮秋所有 © 2024 ，侵權必究。&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/mumu/blog/16689206</link>
            <guid isPermaLink="false">https://my.oschina.net/mumu/blog/16689206</guid>
            <pubDate>Tue, 07 Jan 2025 08:57:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Vim 項目現狀</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Vim 創始人及終身仁慈獨裁者（BDFL）Bram Moolenaar 於 2023 年的&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/252537/vim-bram-moolenaar-passed-away&quot; target=&quot;_blank&quot;&gt;離世&lt;/a&gt;&lt;/u&gt;讓社區感到震驚，同時也引發了對項目未來的擔憂。&lt;/p&gt; 
&lt;p&gt;在 2024 年 11 月舉行的 VimConf 大會上，現任 Vim 維護者 Christian Brabandt 發表主題演講&lt;em&gt;&lt;strong&gt;「Vim 項目的新生」(the new Vim project&quot;)&lt;/strong&gt;&lt;/em&gt;，介紹了社區如何重組以繼續維護 Vim，以及未來的發展方向。&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;「後 Bram 時代」的 Vim&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Brabandt 首先回顧了他與 Vim 的淵源：他自 2006 年起參與 Vim 項目，並表示他的首次提交是在 7.0/7.1 版本時期（大約在 2006 年）。起初，他主要貢獻小補丁和修復，後來逐漸貢獻了更大的功能，比如 gn 和 gN 命令（結合搜索和可視模式選擇）、使用 libsodium 改進的加密支持，維護 Vim 的 AppImage 等。他提到，由於個人和工作的原因，他在 2022 年左右減少了對項目的參與。&lt;/p&gt; 
&lt;p&gt;這一情況在 2023 年 8 月發生了變化，因為 Moolenaar 去世了。Moolenaar 維護 Vim 已超過 30 年；儘管在前幾年他已將 Brabandt 和 Ken Takata 加入為共同維護者，但大部分開發仍由他主導。他去世後，許多知識隨之流失，但 Brabandt 和其他人接手了繼續保持項目活力的重任。&lt;/p&gt; 
&lt;p&gt;當時，&lt;strong&gt;Moolenaar 是 Vim GitHub 組織的唯一擁有者，只有他的賬號可以更改某些設置&lt;/strong&gt;。起初，貢獻者嘗試通過 GitHub 的已故用户政策來為組織添加擁有者。然而，這一過程相當複雜，最終的結果是 Moolenaar 的賬號會被禁用。由於希望家人仍然能夠訪問該賬號，他們放棄了這一方法，而是選擇根據組織變更的需要，由家人授予必要的訪問權限。&lt;/p&gt; 
&lt;p&gt;Charles Campbell（暱稱「Dr Chip」），一位為 Vim 做出貢獻超過 25 年的開發者，也在 Moolenaar 去世後不久決定退休。他離職後，維護團隊的規模有所擴大，Yegappan Lakshmanan 加入了團隊，隨後 Dominique Pellé、Doug Kearns，以及 GitHub 用户「glepnir」、「mattn」和「zeertzjq」也相繼加入。&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;不僅僅是源代碼&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Brabandt 強調，維護 Vim 不僅只是源代碼，還有許多其他方面需要管理，比如 Vim 的網站、FTP 服務器、安全漏洞披露、在 Reddit 和 Stack Exchange 等其他平台上的 Vim 社區等。&lt;/p&gt; 
&lt;p&gt;Vim 的網站也需要改進，其設計和大部分代碼在很長一段時間內幾乎沒有變化——直到 2023 年，它仍基於 PHP 5。在最近的一些情況下，網站不夠穩定，因此他在 2024 年開始尋找新的託管服務商。這一遷移過程包括將 PHP 升級到版本 8，併為此重寫了一部分代碼。Brabandt 對 Mark Schöchlin 表示感謝，是他主動承擔了這部分工作。&lt;/p&gt; 
&lt;p&gt;他承認網站的設計自 2001 年以來幾乎沒有變化，看起來並不現代化，這可能會讓新用户感到困惑。雖然已經嘗試過重新設計，但第一次嘗試並不成功。他更注重保持一致性，不希望嚇跑長期用户。&lt;/p&gt; 
&lt;p&gt;DNS 也是一個棘手的問題——vim.org 域名由 Stefan Zehl 管理，但 Moolenaar 還擁有其他一些域名，比如 vim8.org、vim9.org 等。&lt;/p&gt; 
&lt;p&gt;幸運的是，SSL 證書已由 Let’s Encrypt 管理，因此 Brabandt 在這一方面沒有遇到問題。一些電子郵件地址，如 bram@vim.org、bugs@vim.org 等，原本被轉發到 Moolenaar 的個人郵箱，現在這些地址已更新為轉發到 Brabandt 的郵箱。&lt;/p&gt; 
&lt;p&gt;FTP 服務器由 NLUUG 託管，但他決定將其停用，並表示到目前為止還沒有收到任何投訴。&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;溝通交流渠道&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;他還談到社區圍繞 Vim 郵件列表的活動，這些郵件列表託管在 Google Groups 上。&lt;/p&gt; 
&lt;p&gt;2024 年 5 月，他收到 Google 的自動消息，通知 vim-dev 郵件列表的所有內容因垃圾郵件或惡意軟件被屏蔽。這引發了一些麻煩，雖然列表在一天左右得以恢復，但問題的具體原因至今未明。他們曾考慮將郵件列表改為自託管，但這樣做的一個問題是所有用户都需要重新註冊。&lt;/p&gt; 
&lt;p&gt;如今，郵件列表的活躍度已經不如以往，大部分社區討論都轉移到了 Reddit 和 Stack Exchange 上。&lt;/p&gt; 
&lt;p&gt;安全漏洞披露也是需要關注的一項內容。幾年前，問題曾通過 Huntr 平台報告。許多尚未解決的問題現已處理完畢。但在 2023 年，Huntr 被另一家公司收購，該公司專注於 AI 技術，並關閉了通用的開源漏洞報告服務。&lt;/p&gt; 
&lt;p&gt;目前，Vim 通過電子郵件或 GitHub 接收安全問題報告，並通過 GitHub 的安全通告發布漏洞信息。團隊還設立了一個專用於尚未公開的安全問題的私密郵件列表，相關郵件會轉發至所有維護者。&lt;/p&gt; 
&lt;p&gt;Brabandt 還在提交信息中引入了 [security] 標籤來標記安全修復。這類提交會在 oss-security 列表上公佈（最近的一次是在 10 月），並通知發行版維護者。&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;維護模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Brabandt 隨後展示了貢獻圖表，以證明 Moolenaar 去世後開發並未停止。在 Moolenaar 健康狀況惡化期間，項目開發有所放緩，但在他整理未完成的 PR 時出現了一個高峯。9.1 版本於 2024 年 1 月 2 日發佈，以紀念 Moolenaar——這距離他去世約四個月。&lt;/p&gt; 
&lt;p&gt;9.1 版本包括對虛擬文本的改進（該功能允許補全建議等內容出現在編輯區域內，但不屬於實際文本的一部分）、平滑滾動和 OpenVMS 支持。&lt;/p&gt; 
&lt;p&gt;在 9.1 之後，他開始引入更多可能引發爭議的更改，例如支持 XDG 基目錄規範。現在，Vim 不再需要在頂級主目錄中創建文件：~/.vimrc 或 ~/.vim/vimrc 仍然有效，但如果兩者都不存在，則 $XDG_CONFIG_HOME/vim/vimrc 也會生效。另一個此類更改是 Wayland 支持。這一支持尚未完成，他表示不確定剪貼板支持的剩餘問題是 Vim 的 Bug 還是 Wayland 的問題。&lt;/p&gt; 
&lt;p&gt;隨着他清理 PR 積壓問題，他開始制定合併 PR 的策略，優先確保充分測試。現在，測試通過持續集成（CI）運行。他還提到，良好的文檔非常重要。&lt;/p&gt; 
&lt;p&gt;Vim 支持許多語言接口，包括 Python 2 和 3、Ruby、Lua、Tcl 和 MzScheme。但 Brabandt 不確定這些語言接口中有多少仍然真正需要。例如，Python 2、Tcl 和 MzScheme（無法與該語言的最新版本構建）可能需要放棄以減少維護負擔。其他需要改進的領域包括 GUI（GTK 4 已推出一段時間，但 Vim 尚未使用它）、高級終端功能支持，以及拼寫檢查功能（自 Vim 7 以來幾乎沒有變化）。團隊希望支持 tree-sitter 語法解析器，但這一功能存在爭議，因此他認為它不太可能很快出現在 Vim 中。&lt;/p&gt; 
&lt;p&gt;他了解 Neovim 中出現了一些重要變化，但他不確定其中有多少可以被引入 Vim。雖然 Vim 進行了少量更改，但重大變更需要社區的支持。他不希望進行向後不兼容的更改，並且對可能導致問題的變更保持謹慎。他表示，在處理 PR 時必須考慮全局情況，尤其是用户的期望。目前，他表示 Vim 處於某種程度的維護模式。&lt;/p&gt; 
&lt;p&gt;他還提到已創建了一個內部存儲庫，用於跟蹤利益相關者並確保如果他出現問題，其他維護者可以接替他的工作。&lt;/p&gt; 
&lt;p&gt;Brabandt 建議那些新加入項目的人從小的貢獻開始，並熟悉代碼庫。他向開發者提供了一些建議，認為在使用 C 時採用防禦性風格非常重要，以確保不會引入新的 Bug。他推薦使用 Coverity 這類靜態分析工具掃描缺陷。他提到，Vim 的某些代碼庫部分非常複雜，如果可能的話，需要重構為更易於管理的單元。&lt;/p&gt; 
&lt;p&gt;維護 Vim 是一項全職工作，他表示，這不僅僅是維護代碼，還包括維護社區——管理期望並傾聽用户需求。他必須瞭解社區的願望：希望 Vim 成為何種工具？是 IDE 嗎？還是與舊版本 Vim 完全兼容的工具？如何讓 Vim9 腳本（Vim 的新腳本語言）更廣泛地使用？如何確保 Vim 社區的健康發展？他以感謝所有 Vim 的貢獻者結束了他的演講，並回答了一些問題。&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;問答環節&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;一位觀眾提問 Vim 和 Neovim 的維護模式有何不同。由於大多數 PR 仍由 Brabandt 合併，這是否意味着他成為了 Vim 的新 BDFL？&lt;/p&gt; 
&lt;p&gt;Brabandt 明確否認自己是 BDFL。目前，他之所以合併大部分更改，是因為每次更改需要遞增版本號，而多人同時合併可能會導致衝突。然而，在他休假期間，他已將主要維護權交給 Lakshmanan。他強調，這依然是一個社區項目，所有決策都基於社區意見。只是目前其他維護者選擇不親自合併更改，而是將這一職責委託給他，他對此表示認可。&lt;/p&gt; 
&lt;p&gt;另一位觀眾詢問語言障礙問題，因為 Vim 社區中有許多日本成員以及其他多語言用户。Brabandt 回答説，作為一個國際項目，Vim 的主要工作語言是英語。他提到，現在有了 ChatGPT 和翻譯工具，跨語言合作變得更加方便。但仍有部分用户無法很好地用英語表達，這增加了理解他們需求的難度。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flwn.net%2FSubscriberLink%2F1002342%2Fa8d8a17f30968b93%2F&quot; target=&quot;_blank&quot;&gt;https://lwn.net/SubscriberLink/1002342/a8d8a17f30968b93/&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329832/the-state-of-vim-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329832/the-state-of-vim-2024</guid>
            <pubDate>Tue, 07 Jan 2025 07:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Angular 團隊公佈 2025 年戰略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌 Angular 產品和開發者關係負責人 Minko Gechev 日前發表了一篇關於 Angular 2025 戰略的博客文章&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.angular.dev%2Fangular-2025-strategy-9ca333dfc334&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;表示&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，團隊的年度戰略重點是投資於有助於 Angular 開發人員取得成功的關鍵領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前正在針對以下幾個目標進行優化：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過增強開發者體驗來提高開發者滿意度。以及將通過繼續為生態系統帶來創新，來突破性能和開發者體驗的界限。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持採用最新的改進。包括使用 schematics 簡化新功能的採用、提高 Angular 社區內外功能的可見性等等。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;具體而言，為了進一步改善開發者體驗，Gechev 提出計劃在 2025 年將 zoneless 推廣到開發者預覽版，使 Angular 具有更高效的變化檢測能力、提高互操作性（例如，在 MFE 中）、並提高初始加載性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以及推出 Signal forms 功能。目前正在處於設計階段，「我們將繼續支持現有的表單模塊，使其與 signal forms 可互操作，同時逐步推薦 signal forms 作為最佳實踐。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外還有 RFC for selectorless components，「我們非常希望簡化組件中的依賴管理，並且我們還希望將社區納入這一流程」。考慮到 Karma 的棄用，Angular 團隊也在尋找替代品，目前正在探索的有 Web Test Runner、Jest 和 Vitest。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為了讓 Angular 開發人員更容易採用新功能，項目團隊則計劃改進 Angular 的文檔以反映最新的最佳實踐，同時提高有助於 Web 開發人員實現其目標的功能的可見性，並使其易於在現有堆棧中採用 Angular。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我們承認，Angular 經歷了幾年的艱難時期，隨後人們稱之為&#39;Angular 復興&#39;。我們還有很多教育工作要做，以便向不熟悉該框架的開發人員展示現代 Angular 是什麼，以及它如何支持他們自信地構建 Web 應用。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Gechev 還分享了 Angular 2024 年開發者調查的結果，基於來自開發者的近 10000 份回覆。發現，79% 的 Angular 開發者正在使用最新的兩個主要版本的 Angular，90% 的開發者正在使用獨立組件、指令和管道，超過 80% 的開發者正在使用內置控制流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;221&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a50e5a58a1424ca42173a9f3f3e54dbbfe.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開發人員整體滿意度也有所提高，近 90% 的受訪者表示對該框架感到滿意。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329831/angular-2025-strategy</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329831/angular-2025-strategy</guid>
            <pubDate>Tue, 07 Jan 2025 07:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DB-Engines 公佈 2024 年度數據庫：PostgreSQL</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;DB-Engines&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdb-engines.com%2Fen%2Fblog_post%2F106&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;宣佈&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/u&gt;PostgreSQL 獲得 「2024 年度數據庫」 稱號，這是它連續第二年贏得此殊榮，也是在 2017、2018、2019 和 2023 年稱霸之後，第五次榮登榜首——名副其實的「五冠王」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0115/112602_ZPyK_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;DB-Engines 是全球知名的數據庫流行度排行榜網站，其評選年度數據庫的標準為：計算數據庫當前最新流行度分數的同比增長量，分數增長最多的即為年度數據庫。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;頒獎詞：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;讓我們把時光撥回到將近 35 年前，「Postgres」 剛剛閃亮登場。此後，為了緊跟數據庫技術潮流，PostgreSQL 一直在不斷演化，功能愈發強悍，穩定性絲毫不打折扣。2024 年 9 月推出的 PostgreSQL 17 在性能和複製（replication）方面又有了新的優化和功能擴展，將這位「常青樹」推向了新的高度。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;放眼當今開源社區，PostgreSQL 可謂長盛不衰，堪稱人氣與實力兼具的典範。而在這一年裏表現同樣搶眼的 Snowflake，可不是「雪花」那麼簡單——它是基於雲的數倉服務，以將存儲和計算分離的獨特架構吸引大批追隨者，再加上多雲環境支持與數據共享功能，成為行業內炙手可熱的後起之秀。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Snowflake 的名次一路飆升，充分説明它在業界的影響力正與日俱增。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;排名第三的微軟，也依舊是數據庫領域的「老將」：Azure SQL Database 提供了全託管的關係型數據庫服務，還加入了 AI 驅動的性能優化和彈性伸縮；SQL Server 則憑藉混合雲能力，打通本地和雲端之間的壁壘。微軟在數據庫層面推陳出新的投入與其全面的數據服務生態相得益彰，實力不容小覷。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;來源：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fnm7wQ8U13YqO7SP2tI9PHw&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/nm7wQ8U13YqO7SP2tI9PHw&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;插播一條廣告：&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;3128&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0115/113756_eKSW_2720166.jpg&quot; width=&quot;750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;歷年 DB-Engines 年度數據庫：&lt;/strong&gt;&lt;/p&gt; 
&lt;table cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:1px; border:none; box-sizing:border-box; color:#444444; display:block; font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; line-height:inherit; margin:0px 0px 20px; max-width:100%; orphans:2; overflow:auto; text-align:left; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:776px; word-break:keep-all; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;PostgreSQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;PostgreSQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2023&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;Snowflake&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2022&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;Snowflake&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2021&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;PostgreSQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2020&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;MySQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2019&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;PostgreSQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2018&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;PostgreSQL&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2017&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;Microsoft SQL Server&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2016&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;Oracle&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2015&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;MongoDB&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2014&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;MongoDB&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dddddd; border-style:solid; border-width:1px&quot;&gt;2013&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329793/pgsql-is-the-dbms-of-the-year-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329793/pgsql-is-the-dbms-of-the-year-2024</guid>
            <pubDate>Tue, 07 Jan 2025 03:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「TikTok 難民」突然湧入——小紅書內部觀點尚未達成一致，國內互聯網公司紛紛發英文貼攬客</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，TikTok「禁令」進入倒計時，而許多美國網友並沒有選擇使用 Instagram Reels 和 YouTube Shorts 等 TikTok 在美國競爭對手的平台，而是決定加入另一箇中國社交媒體平台：小紅書。&lt;/p&gt; 
&lt;p&gt;小紅書也登上了 App Store 美區的下載榜榜首。小紅書或許也因此成為有史以來第一款登頂美區下載榜的名字全是漢字的 App。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-efece9d764e364f0a93454a08aba6e92542.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從多位小紅書內部人士處瞭解到，&lt;strong&gt;「內部對此次事件的觀點尚不能達成一致」&lt;/strong&gt;。核心的爭議在於全球化的挑戰大於流量承接的喜悦，「這個事情是偶發的、突然的」。&lt;/p&gt; 
&lt;p&gt;據悉，這並非小紅書首次承接來自 TikTok 的流量，小紅書上一次有大規模外國人出現還是「外國人聽勸」系列，事後內部也曾拉數據查看，對 DAU 的帶動並不明顯。目前尚不清楚有多少海外用户湧入，以及其所對應的筆記量。&lt;/p&gt; 
&lt;p&gt;但截至發稿，TikTokRefugee 詞條下顯示有 7 萬 + 筆記。甚至有部分人士認為，此舉無法等同於小紅書的全球化。&lt;/p&gt; 
&lt;p&gt;值得注意的是，很多國內互聯網公司也藉機以玩梗名義試圖吸引這波流量。阿里巴巴財大氣粗：Do you want to make money（你想賺錢嗎）？而且阿里巴巴還「陰陽」一把亞馬遜，直接向 TikTok 用户宣傳稱自己是亞馬遜供貨源，想賺錢就找阿里；攜程向 TikTok 用户喊話：Say go，let&#39;s go（説走就走）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0115/111320_fkVG_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;美顏相機簡單粗暴：Take photo，very beautiful（照相，美美噠）！餓了麼直接把 App 名稱中譯英：Are you hungry（你餓了麼）？告訴 TikTok 用户可以點外賣吃；瑞幸咖啡簡單點明：Want to drink coffee？Use this（想喝咖啡嗎，選我）；美團告訴 TikTok 用户：Use this discount（用美團享受折扣）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329788</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329788</guid>
            <pubDate>Tue, 07 Jan 2025 03:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>USB 全新標識將直接標註傳輸速度、功率</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，USB 開發者論壇（USB-IF）正式公佈了全新的 USB 標識。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a6c9820d72ad1254e60d770ed31d8ba2ae1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，全新的 USB 標識相較於舊版更加直觀，捨棄了舊版的「USB 3.2 Gen1」、「USB 3.2 Gen2」等類似後綴，改為了由傳輸速度和充電功率作為後綴。其中設備與數據線的傳輸速度以 Gbps 為單位，而充電功率統一使用「W（瓦）」為單位。&lt;/p&gt; 
&lt;p&gt;新的 USB 標識採用速度優先的原則，用清晰易懂的數字直接標明數據傳輸速度，例如 USB 80Gbps、USB 40Gbps 等，取代以往 USB4 v2 等複雜表述。&lt;/p&gt; 
&lt;p&gt;新的 USB 標識也適用於線纜標識，會在線纜上同時標明數據傳輸速度和供電能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8927f2637a1e49be5f4f484a0dbd1c19b2e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;USB-IF 強調此次更新旨在解決長期以來消費者對 USB 標識的困惑，尤其是在 2017 年 USB 3.2 推出時，諸如 Gen 2x2 和 SuperSpeed USB 20Gbps 等讓消費者難以理解實際規格的複雜命名。&lt;/p&gt; 
&lt;p&gt;據 USB-IF 代表透露，戴爾或將會成為首個印刷新標識上產品的廠商。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329785/updated-usb-logo</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329785/updated-usb-logo</guid>
            <pubDate>Tue, 07 Jan 2025 02:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟 CEO 納德拉宣佈組建新 AI 團隊「CoreAI」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，微軟 CEO Satya Nadella 在官方博客&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2025%2F01%2F13%2Fintroducing-core-ai-platform-and-tools%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;，微軟將組建新的 AI 團隊「CoreAI」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1420&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0115/104102_Ifg5_2720166.png&quot; width=&quot;1500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據介紹，CoreAI 將專注於開發端到端的 AI 應用平台與工具，為微軟自己與其第三方客户打造端到端的 Copilot 和 AI 堆棧，以構建和運行 AI App 及 AI Agents（人工智能代理）。同時 CoreAI 還將打造 GitHub Copilot，從而在領先的 AI 產品與 AI 平台之間建立緊密的反饋循環，以推動堆棧及其路線圖的發展。&lt;/p&gt; 
&lt;p&gt;據瞭解，&lt;strong&gt;CoreAI 將彙集開發部、AI 平台以及 CTO 辦公室的一些關鍵團隊（包含 AI 超級計算機、AI Agentic Runtime 和 Engineering Thrive&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此外，CoreAI 將由網絡安全初創公司 Lacework 前 CEO、Meta 前工程主管 Jay Parikh 領導，Eric Boyd、Jason Taylor、Julia Liuson、Tim Bozarth 及其各自的團隊將向 Jay 彙報。&lt;/p&gt; 
&lt;p&gt;Satya Nadella 還表示，Jay Parikh 加入微軟後將與多個高層領導，如 Mustafa Suleyman、Scott Guthrie 和 Kevin Scott 等緊密合作，共同推動微軟在 AI 和雲計算領域的戰略。&lt;/p&gt; 
&lt;p&gt;此前，Jay Parikh 於 2024 年 11 月加入微軟 Team SLT（高級領導團隊）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329784/ms-core-ai-platform-and-tools</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329784/ms-core-ai-platform-and-tools</guid>
            <pubDate>Tue, 07 Jan 2025 02:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>2024 LLM 年度事件回顧：價格全面下跌、多模態能力爆發……</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年伊始，Django 的作者之一 Simon Willison，帶我們回顧了 2024 年 AI 的重磅進展，堪稱大模型的「里程碑」盤點。快來看看有哪些突破，刷新了我們對 AI 的認知！&lt;/p&gt; 
&lt;p&gt;原文很長，下面給大家列幾個關鍵點：&lt;/p&gt; 
&lt;p&gt;- &lt;strong&gt;GPT-4 壁壘被突破&lt;/strong&gt;：從前，GPT-4 被視為無人能及的高度智能「天花板」，現在，Chatbot Area 排行榜上已經有近 70 個模型，超過了 2023 年 3 月版本的 GPT-4。谷歌的 Gemini 1.5 Pro 不僅在輸出質量上與 GPT-4 持平，還引入了 1 百萬到 2 百萬的上下文長度，以及視頻輸入能力。這些新功能徹底顛覆了我們對 LLM 應用的想象。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4e924b4d66f2e860dd82f51488f7fe55f15.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 本地運行大模型&lt;/strong&gt;：令人震撼的是，一些 GPT-4 同級模型已經可以在配置較高的筆記本上運行，如 Meta 的 Llama 3.2 3B 模型不僅可以在 MacBook Pro 上運行，還能通過免費的 MLC Chat iOS 應用在 iPhone 上運行。這意味着即便是移動設備，用户也能體驗到強大的 AI 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6115a9d99b52df4aec0ed9bc6615e354df3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- LLM 價格全面下跌&lt;/strong&gt;：大量參與者帶來的內卷，以及模型推理效率的提升，使得 LLM 的成本斷崖式下降。以前昂貴的 API 費用，如今已經便宜到小團隊也能輕鬆負擔。谷歌的 Gemini 1.5 Flash 8B，為 68000 張圖像生成一句話描述，總成本僅為 1.68 美元，這比去年 GPT-3.5 Turbo 的費用下降了近 27 倍，極大地推動了 LLM 的普及。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 多模態能力爆發&lt;/strong&gt;：2024 年，多模態模型進入主流視野。除了文字，還能對圖片、音頻甚至視頻進行處理。有些模型還能實時接收語音和視頻輸入，讓人與 AI 的交互科幻味十足。如 OpenAI 的 GPT-4o 模型新增了語音和實時攝像頭模式，用户可以通過語音與 AI 互動，甚至實時分享攝像頭畫面進行分析。谷歌的 NotebookLM 則能生成逼真的播客對話，展現了多模態 AI 的無限可能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 應用開發門檻降低&lt;/strong&gt;：越來越多的 LLM 支持「一鍵式」生成代碼、網頁，甚至是交互式應用，整個開發流程在聊天界面就能完成， Claude Artifacts 的出現，更是將低代碼應用開發推向了高潮。此外，GitHub Spark 和 Mistral Chat 的 Canvas 功能也讓開發者輕鬆構建應用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 智能 Agent 尚未到來&lt;/strong&gt;：雖然 LLM 被寄予厚望，但讓模型完全自主決策、執行任務的「智能 Agent」仍面臨可靠性難題，谷歌 Search 曾錯誤描述不存在的電影「Encanto 2」，説明 LLM 在信息準確性上還存在侷限性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 數據中心與環保&lt;/strong&gt;：谷歌、Meta、微軟和亞馬遜等公司都花費數十億美元建設新的數據中心，甚至有人提議建造新的核電站為其供能。這無疑會對環境造成進一步影響，如何在效率與可持續發展之間取得平衡仍是焦點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- AI 垃圾充斥網絡&lt;/strong&gt;：2024 年，人們用「AI 垃圾」來形容那些沒有審核、胡亂生成的 AI 生成文字。由於 AI 生成的文章數量激增，國外某些雜誌居然暫停接受投稿。此外，「AI 洗稿」操作也讓短視頻內容同質化嚴重，甚至出現許多不符合事實的內容。隨着 AI 生成內容的爆炸式湧現，如何避免低質量文字氾濫，成了一個新課題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 合成數據訓練模型&lt;/strong&gt;：隨着數據越來越稀缺，新模型訓練時，開始採用更大模型生成的「合成數據」。如 DeepSeek v3 使用了 DeepSeek-R1 的推理數據，訓練成本僅為 557.6 萬美元，相比 Meta 的 Llama 3.1 405B 模型的 3084 萬美元，成本低了近 11 倍。OpenAI 創始成員 Karpathy 稱讚 DeepSeek V3，在有限預算上訓練模型預更容易了，Meta 科學家田淵棟也稱其訓練過程為「黑科技」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;- 專業門檻依舊存在&lt;/strong&gt;：即便模型越來越強大，實際應用中依舊需要熟練掌握提示詞、API 調用、工具接入等「高級技巧」，才能讓 AI 發揮最大價值。例如，用户需要理解 CSP 和 CORS HTTP 頭信息才能構建與外部 API 交互的 Claude Artifact，否則容易遇到安全問題，這對普通用户來説仍是不小的挑戰。&lt;/p&gt; 
&lt;p&gt;感興趣的小夥伴可以閲讀原文：&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsimonwillison.net%2F2024%2FDec%2F31%2Fllms-in-2024%2F&quot; target=&quot;_blank&quot;&gt;https://simonwillison.net/2024/Dec/31/llms-in-2024/&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329778/llms-in-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329778/llms-in-2024</guid>
            <pubDate>Tue, 07 Jan 2025 02:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>MiniMax 開源新一代 01 系列模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MiniMax 發佈並開源了 MiniMax-01 全新系列模型，其中包含：基礎語言大模型 MiniMax-Text-01 和視覺多模態大模型 MiniMax-VL-01。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，MiniMax-01 系列模型首次大規模實現線性注意力機制，傳統 Transformer 架構不再是唯一的選擇。這個模型的參數量高達 4560 億，其中單次激活 459 億。模型綜合性能比肩海外頂尖模型，同時能夠高效處理全球最長 400 萬 token 的上下文，是 GPT-4o 的 32 倍，Claude-3.5-Sonnet 的 20 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，官方給出的標準定價是輸入 token 1 元/百萬 token，輸出 token 8 元/百萬 token。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型結構圖如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;356&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2d8661e8dbbe47eaa96c51613ee0a736d29.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MiniMax 方面稱，基於業界主流的文本和多模態理解測評，該模型在大多數任務上追平了海外公認最先進的兩個模型，GPT-4o-1120 以及 Claude-3.5-Sonnet-1022。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在長文任務上，對比了之前長文最好的模型 Google 的 Gemini。結果顯示，隨着輸入長度變長，MiniMax-Text-01 是性能衰減最慢的模型，顯著優於 Google Gemini。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;246&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a005ca88b0a977e1fa2ee15fef027df17c7.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;463&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23ea496de41a3e602911b1098b6476c84d5.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYYtyqVhnyqRBDPinZxByyA&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329775</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329775</guid>
            <pubDate>Tue, 07 Jan 2025 02:15:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源日報 | Linus 沉迷「焊接」；甲骨文拒絕放棄 JavaScript 商標；蘋果在英面臨 134 億元鉅額索賠；中國大模型在開源社區處於領先水平；AI 陪伴玩具到底行不行？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;歡迎閲讀 OSCHINA 編輯部出品的開源日報，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2025.1.14&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要聞&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329653/linus-torvalds-guitar-pedal-offer&quot;&gt;Linus 變身「手工林」——將親自打造一套吉他效果器踏板贈送給內核開發者&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;Linus 表示，我是軟件工程師，也略懂焊接技術，願意親手製作一個吉他效果器踏板贈送給一名幸運的內核貢獻者。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;對我來説，傳統節日活動往往是做一兩件樂高積木，因為這通常是聖誕節和生日禮物的一部分。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;但除了樂高積木，今年我還做了個吉他踏板套件（&quot;大人用烙鐵做的樂高&quot;）。 不是因為我彈吉他，而是因為我喜歡手工搗鼓東西的感覺……&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;我做了很多，但我真正喜歡做的套件來自&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faionfx.com%2Fproject-type%2Fkit%2F&quot; target=&quot;_blank&quot;&gt;Aion FX&lt;/a&gt;。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;既然我想有藉口繼續做這些工作，又因為我實際上對製作出來的踏板沒有任何用途（我已經把一些踏板賣給了不知情的 「受害者」 朋友們），我決定看看是否有 「倒黴」 的內核開發者想要一個。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;所有我決定，如果有任何內核開發者（&lt;em&gt;定義是 「在我的內核 Git 樹中自 2024 年以來有 commit 記錄的開發者」&lt;/em&gt;）覺得他們的生活中真的需要一個由我親手打造的吉他踏板，請給我發一封電子郵件（發件人為 git 樹中的那個郵箱地址），主題是 &quot;我想要一個吉他踏板&quot;。&lt;br&gt; ......&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;下週，我會隨機挑選一名內核貢獻者（假設真的有人想要），然後自費買下那個套件，用我自己顫抖的小手指製作它，並通過美國郵政服務寄給 「受害者」。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329611/apple-uk-lawsuit-app-store-overcharging&quot;&gt;「30% 抽成」再惹麻煩，蘋果在英面臨 134 億元鉅額索賠&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;1 月 13 日消息，針對蘋果公司的集體訴訟在英國競爭上訴法庭正式開庭。蘋果公司被指控對其 App Store 下載的軟件收取 「過高且不公平」 的費用，面臨高達 15 億英鎊（約合 134 億人民幣）的法律索賠。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0114/105029_xrGc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;原告認為，蘋果強迫軟件開發商使用其自有的應用商店分發應用程序，屬於濫用市場主導地位行為，且收取高達 30% 的佣金，限制了競爭，影響了開發者和消費者。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329646&quot;&gt;開源雲操作系統 Sealos 開發商「環界雲計算」獲阿里雲戰略投資&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;據 36 氪&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F3121978699698434&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;&lt;/u&gt;，珠海環界雲計算有限公司（以下簡稱 「環界雲計算」）近日宣佈完成 3750 萬元的 Pre-A 融資，由阿里雲獨家投資。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;在此之前，環界雲計算曾累計獲得三輪融資。其中天使輪融資由奇績創壇領投，清華信息學院院⻓李軍、科⼤微電⼦教授康⼀跟投。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;環界雲計算成立於 2022 年 3 月，其核心產品 Sealos 是一款以 kubernetes 為內核的雲操作系統；另外該公司還有知名開源項目&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/p/fastgpt&quot; target=&quot;_blank&quot;&gt;FastGPT&lt;/a&gt;，是一款 AI 知識庫產品。&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329615/oracle-refuses-yield-javascript-trademark&quot;&gt;Deno Land 稱甲骨文拒絕放棄 JavaScript 商標&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 11 月，Deno Land 曾向美國專利商標局 (USPTO) 提交了一份申請，&lt;a href=&quot;https://www.oschina.net/news/322147/deno-v-oracle-javascript-trademark&quot;&gt;要求&lt;/a&gt;取消甲骨文 (Oracle) 對 JavaScript 商標的所有權。並提出了三項主張：JavaScript 是通用的、Oracle 公司存在欺詐行為，以及 Oracle 已放棄使用該商標。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日， Deno Land 在 X 上發佈了一篇&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fdeno_land%2Fstatus%2F1876728474666217739&quot; target=&quot;_blank&quot;&gt;帖子&lt;/a&gt;，介紹了關於該商標之爭事件的最新進展。&lt;/span&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;#FreeJavaScript update：Oracle 公司已告知我們，他們不會主動撤回其 「JavaScript」 商標。下一步：他們將提交答辯狀，我們將開始取證，以表明 「JavaScript 」 如何被廣泛認為是一個通用術語，並且不受 Oracle 控制。&lt;/span&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a7b0c8946ded6dedb137aeb2b5ae4ba521e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/329607&quot;&gt;扎克伯格「鋭評」蘋果：缺乏創新、通過壓榨用户和開發者來賺錢&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;1 月 11 日，Meta CEO 馬克・扎克伯格在&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D7k1ehaE0bdU&quot; target=&quot;_blank&quot;&gt;做客&lt;/a&gt;&lt;/u&gt;播客節目 Joe Rogan Experience 時，對蘋果的封閉生態系統進行抨擊。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;在節目中他談及了對於 Vision Pro 的看法：「他們推出了一款售價 3500 美元的產品，我認為還不如我們售價 300 或 400 美元的產品好。」&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;同時，他還直接表示「蘋果已經很久沒有發明什麼真正偉大的東西了。」他認為，史蒂夫・喬布斯發明瞭 iPhone，而現在蘋果只是在這個成就上躺了 20 年。「實際上，我覺得他們的 iPhone 銷量可能在下降。」&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;扎克伯格認為，蘋果賺更多錢的方式，就是通過壓榨用户來實現的。比如向開發者收取 30% 的税費，讓用户購買更多外設和配件。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日觀察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交觀察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJrY9J9JDwc3OMJI1CSypgw&quot; target=&quot;_blank&quot;&gt;AI 一年過山車：從狂想到放下幻想&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;至少在有一個方面，中國大模型在 2024 年真的趕上了美國——開源。2024 年 1 月，在 Chatbot Arena 的排名中，全球前 6 的開源模型中只有一箇中國模型——零一萬物開發的 yi-34b-chat，到 12 月，這個數字增長到 3.5——0.5 是因為，其中有一個非中國的開源模型，是基於阿里 Qwen 2.5 72B 訓練的。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-38ffc297de0c0712f7a7c848e5ff0f46e26.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/div&gt; 
    &lt;div&gt;
     &amp;nbsp;
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微信&lt;strong&gt;&amp;nbsp;晚點 LatePost&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1240212845%2FP9qQzeiYZ&quot; target=&quot;_blank&quot;&gt;巨硬的 markitdown 有 33.8k stars&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;巨硬的 markitdown 有 33.8k stars，它的核心功能是 HTML 轉 Markdown，該能力由 markdownify 庫提供。然而 markdownify 只有 1.2k stars。&lt;/p&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d84eedfdd38d2c2e4cad360ec5f3993d1f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div style=&quot;text-align:right&quot;&gt;
    &lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;Maeiee&lt;/strong&gt;&lt;/span&gt;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7632744038%2FP9qsKDH0h&quot; target=&quot;_blank&quot;&gt;X210Ai——基於 ThinkPad X201 的復刻主板誕生&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;X210Ai----基於 ThinkPad X201 的復刻主板誕生，性能全面提升，同時還繼續保持有 ThinkPad 經典七行鍵盤和優秀舒適的指點杆系統。&lt;/p&gt; 
   &lt;p&gt;X210Ai 規格參數如下：&lt;br&gt; 1、 CPU 採用酷睿 Ultra7165H 處理器&lt;br&gt; 2、 全速 M.2 2280 接口一個（另有 2.5 英寸 SATA 一個，再有 M.2 2242 一個可 WWAN 卡也可 SSD）&lt;br&gt; 3、 內存接口雙通道 DDR5 插槽&lt;br&gt; 4、 一個雷電 4，一個全功能 C&lt;br&gt; 5、 VGA 接口替換成常用的標準 HDMI&lt;br&gt; 6、 EDP 屏線接口採用 I-PEX 直接匹配 LG13 寸和 LG13.3 寸&lt;br&gt; 7、 保留原裝屏線接口功能&lt;br&gt; 8、 測試 4 芯、6 芯、9 芯電池正常充放電功能&lt;br&gt; 9、 TYPE C 接口物料儘量選擇長點的或者 PCB 延長裝上後能和 D 殼平齊&lt;br&gt; 10、 左下角 USB3.0 接口期望能找到正插的，反插有點反人類&lt;br&gt; 11、 風扇接口較原位置往中間移動 5MM 以方便散熱器改造&lt;br&gt; 12、 還有需要優化的在量產前都可以提出來。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-067f4085173e121bf842d3a28a009075971.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; song1118 公平評測&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FP9wu1aFRi&quot; target=&quot;_blank&quot;&gt;2024 年度 AI 事件&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;2025 年伊始，Django 的作者之一 Simon Willison，帶我們回顧了 2024 年 AI 的重磅進展，堪稱大模型的「里程碑」盤點。快來看看有哪些突破，刷新了我們對 AI 的認知！原文很長，下面給大家列幾個關鍵點：&lt;/p&gt; 
   &lt;p&gt;- LLM 價格全面下跌：大量參與者帶來的內卷，以及模型推理效率的提升，使得 LLM 的成本斷崖式下降。以前昂貴的 API 費用，如今已經便宜到小團隊也能輕鬆負擔。谷歌的 Gemini 1.5 Flash 8B，為 68000 張圖像生成一句話描述，總成本僅為 1.68 美元，這比去年 GPT-3.5 Turbo 的費用下降了近 27 倍，極大地推動了 LLM 的普及。&lt;/p&gt; 
   &lt;p&gt;- 多模態能力爆發：2024 年，多模態模型進入主流視野。除了文字，還能對圖片、音頻甚至視頻進行處理。有些模型還能實時接收語音和視頻輸入，讓人與 AI 的交互科幻味十足。如 OpenAI 的 GPT-4o 模型新增了語音和實時攝像頭模式，用户可以通過語音與 AI 互動，甚至實時分享攝像頭畫面進行分析。谷歌的 NotebookLM 則能生成逼真的播客對話，展現了多模態 AI 的無限可能。&lt;/p&gt; 
   &lt;p&gt;- 應用開發門檻降低：越來越多的 LLM 支持「一鍵式」生成代碼、網頁，甚至是交互式應用，整個開發流程在聊天界面就能完成， Claude Artifacts 的出現，更是將低代碼應用開發推向了高潮。此外，GitHub Spark 和 Mistral Chat 的 Canvas 功能也讓開發者輕鬆構建應用。&lt;/p&gt; 
   &lt;p&gt;- 智能 Agent 尚未到來：雖然 LLM 被寄予厚望，但讓模型完全自主決策、執行任務的「智能 Agent」仍面臨可靠性難題，谷歌 Search 曾錯誤描述不存在的電影「Encanto 2」，説明 LLM 在信息準確性上還存在侷限性。&lt;/p&gt; 
   &lt;div&gt; 
    &lt;div style=&quot;text-align:right&quot;&gt;
     &lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 量子位&lt;/strong&gt;&lt;/span&gt;
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP9wLD92nz&quot; target=&quot;_blank&quot;&gt;辦公桌椅高度計算器&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;www.omnicalculator.com/everyday-life/desk-height&lt;br&gt; 輸入身高，顯示最適合你的辦公桌、椅、顯示器的高度建議。&lt;br&gt; 支持站立辦公模式。&lt;/p&gt; 
   &lt;div&gt; 
    &lt;div style=&quot;text-align:right&quot;&gt;
     &lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 蟻工廠&lt;/strong&gt;&lt;/span&gt;
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒體觀察&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1821184418484721038%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;2025，人工智能走向何方？我們如何擁抱變化？&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;2025 年，對 AI 來説至關重要。有人認為，2025 年世界將迎來 AGI（通用人工智能），AI 可能會挑戰人類社會；也有人認為，現今的 AI 連圖靈測試都未通過，言其將挑戰人類社會還為時過早。但不可否認的是，基於其強大的學習能力，AI 在近幾年發生了飛速變化，無論是消費者的應用端，還是相關產業鏈和供應鏈，都在 AI 的影響下發生深刻轉變。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;新華網&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.ce.cn%2Fcysc%2Ftech%2Fgd2012%2F202501%2F14%2Ft20250114_39265454.shtml&quot; target=&quot;_blank&quot;&gt;政策暖風頻吹，腦機接口賽道火熱&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;「腦機接口領域具有廣闊的市場空間和巨大的發展潛力。一方面，隨着神經科學和人工智能技術的快速發展，腦機接口技術在醫療康復、教育、健康監測等領域的應用場景不斷拓展，市場需求持續增長；另一方面，國家對腦機接口研究的高度重視以及相關政策的支持，為行業發展提供了重要的政策利好。」&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;證券日報&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1821211263599836652%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;進入 1kg 重量時代，超輕筆記本爆發，PC 市場又有新卷法了？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;當然，挑戰依然存在，尤其是散熱和續航這些根深蒂固的難題，但這些瓶頸的解決不僅會作用於超輕筆記本，也會擴散到整個 PC 行業，最終受益所有人。所以究竟，超輕筆記本能否真正撐起 PC 市場的一片天？時間會給出答案。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;雷科技&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2Fttarticle%2Fp%2Fshow%3Fid%3D2309405122651697053928&quot; target=&quot;_blank&quot;&gt;半導體產能過剩？全球投資額減 95 億美元&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;全球 10 家主要半導體企業 2024 年度的設備投資額為 1233 億美元，較上一年度減少 2%，比初期計劃下調約 95 億美元。將是連續 2 年同比下降。需求主要集中在人工智能 (AI) 領域，而純電動汽車 (EV) 領域則停滯不前。受各國半導體振興政策推動，提前投資取得進展，產能也出現過剩跡象。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt; 日經中文網&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jiemian.com%2Farticle%2F12244085.html&quot; target=&quot;_blank&quot;&gt;混亂、分裂、吞併：2024 年 AI 的信仰之戰&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#404040; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#0e0e0e&quot;&gt;2024 年，硅谷的生成式 AI 大戰絲毫不比 2023 年遜色，只是這一年的 AI 戰爭更殘酷更直接：巨頭們不但拼模型能力，還拼爆款產品，同時繼續投入數百億美元拼算力建數據中心；而幾家一年前還是明星項目的初創企業卻因為資金燒光，直接被巨頭吞併。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#252525&quot;&gt;&lt;strong&gt;硅谷 101&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F3121872943665411&quot; target=&quot;_blank&quot;&gt;爆火的 AI 陪伴玩具，到底行不行？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#262626; margin-left:0; margin-right:0; text-align:justify&quot;&gt;總的來看，AI 陪伴玩具的核心始終是協助用户應對現實中的困難，而不是讓人沉溺於虛擬世界或逃避現實，這與傳統的 AI 陪伴軟件、遊戲有着本質區別。舊瓶裝新酒，或許能帶來驚喜。如何在技術創新、用户體驗和商業模式之間找到平衡，將決定這一賽道的未來贏家。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;定焦&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推薦&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;開源項目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fydb-platform%2Fydb&quot; target=&quot;_blank&quot;&gt;ydb-platform/ydb&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-403474fd90c16bb6c6b9561df892c31a7c8.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fydb-platform%2Fydb&quot; target=&quot;_blank&quot;&gt;https://github.com/ydb-platform/ydb&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;YDB（Yandex Database）是一個開源的分佈式 SQL 數據庫，它結合了高可用性和可擴展性，以及嚴格的一致性和 ACID 事務。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/5783135/blog/17101439&quot; target=&quot;_blank&quot;&gt;RAG 應用在得物開放平台的智能答疑的探索&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#3f3f3f; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;鑑於目前得物開放平台的人工答疑數量相對較高，用户在開放平台查詢未果就會直接進入到人工答疑階段。正如上文所説，RAG 擅長依賴一份可靠的知識庫作出相應回答，構建一個基於開放平台文檔知識庫的 RAG 應用再合適不過，同時可以一定程度降低用户對於人工答疑的依賴性，做到問題前置解決。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#3f3f3f; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;整體流程.jpg&quot; height=&quot;263&quot; src=&quot;https://oscimg.oschina.net/oscnet//df99339945305abffa84509db86c62d5.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;開源之聲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户觀點&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/329128/16gb-raspberry-pi-5-on-sale-now-at-120&quot; target=&quot;_blank&quot;&gt;16GB 內存版樹莓派 5 正式上市，售價 120 美元&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：最強軟路由&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：1000 塊錢&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：這價格已經脱離樹莓派的初衷了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：非要算匯率人家工資是美元？懂&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：還不如買 n100&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 6：淘寶，￥1148，請問￥881 在哪裏買呢？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 7：這會價格太高了，沒有 N100 或 N150 划算了。&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 8：最大優勢是功耗，這玩意功耗是真的低，4B 實測平時 2-3w，畢竟電源最大輸出就 5w，另外這兩年也玩過幾個小主機礦難機，24*365 開穩定性上沒有能跟這玩意當對手的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fk6z4UMVyQio1WlmxM6Bdrw&quot; target=&quot;_blank&quot;&gt;一文看盡 2024 年最受歡迎開源前端框架、UI 組件庫、構建工具、CSS 框架等明星項目&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 1：作為一名前端，mdn 和紅寶書可謂是耳熟能詳的話題，如今紅寶書第五版推陳出新，更希望看一下加入了哪些新內容&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 2：前端各種框架推陳出新，不停變動，究竟是吃太飽還是真的欣欣向榮，有大佬分析過嘛&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 3：很就以前看過不過是舊版，我本來是一名移動工程師，工作中常不可避免成為一名前端工程師，書中對於 js 的高級特性以及現代 Web 開發中技巧比較詳細，加深對箭頭函數等的理解，讓我順利完成一個設備管理系統的前端頁面的開發，積累項目經驗。很希望閲讀下新版本的內容。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 4：在大學時看過紅寶石，算是我的前端入門書，受益匪淺&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;觀點 5：avalonia 去哪了？&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0912/150800_DfGR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329718</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329718</guid>
            <pubDate>Mon, 06 Jan 2025 11:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>RAG 應用在得物開放平台的智能答疑的探索</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;得物開放平台是一個把得物能力進行開放，同時提供給開發者提供，公告、應用控制枱、權限包申請、業務文檔等功能的平台。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;面向商家：通過接入商家自研系統。可以實現自動化庫存、訂單、對賬等管理。&lt;/li&gt; 
 &lt;li&gt;面向 ISV ：接入得物開放平台，能為其產品提供更完善的全平台支持。&lt;/li&gt; 
 &lt;li&gt;面向內部應用：提供安全、可控的、快速支持的跨主體通訊。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;得物開放平台目前提供了一系列的文檔以及工具去輔助開發者在實際調用 API 之前進行基礎的引導和查詢。&lt;/p&gt; 
&lt;p&gt;但目前的文檔搜索功能僅可以按照接口路徑，接口名稱去搜索，至於涉及到實際開發中遇到的接口前置檢查，部分字段描述不清等實際問題，且由於信息的離散性，用户想要獲得一個問題的答案需要在多個頁面來回檢索，造成用户焦慮，進而增大 TS 的答疑可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//671b249398e84e0d43eede41dc3fd61f.jpg&quot; alt=&quot;背景.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;隨着這幾年 AI 大模型的發展，針對離散信息進行聚合分析且精準回答的能力變成了可能。而 RAG 應用的出現，解決了基礎問答類 AI 應用容易產生幻覺現象的問題，達到了可以解決實際應用內問題的目標。&lt;/p&gt; 
&lt;h1&gt;二、簡介&lt;/h1&gt; 
&lt;h2&gt;什麼是 RAG&lt;/h2&gt; 
&lt;p&gt;RAG（檢索增強生成）指 Retrieval Augmented Generation。&lt;/p&gt; 
&lt;p&gt;這是一種通過從外部來源獲取知識來提高生成性人工智能模型準確性和可靠性的技術。通過 RAG，用户實際上可以與任何數據存儲庫進行對話，這種對話可視為&quot;開卷考試&quot;，即讓大模型在回答問題之前先檢索相關信息。&lt;/p&gt; 
&lt;h2&gt;RAG 應用的可落地場景&lt;/h2&gt; 
&lt;p&gt;RAG 應用的根本是依賴一份可靠的外部數據，根據提問檢索並交給大模型回答，任何基於可靠外部數據的場景均是 RAG 的發力點。&lt;/p&gt; 
&lt;h2&gt;RAG 應用的主要組成部分&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;外部知識庫：問題對應的相關領域知識，該知識庫的質量將直接影響最終回答的效果。&lt;/li&gt; 
 &lt;li&gt;Embedding 模型：用於將外部文檔和用户的提問轉換成 Embedding 向量。&lt;/li&gt; 
 &lt;li&gt;向量數據庫：將外部信息轉化為 Embedding 向量後進行存儲。&lt;/li&gt; 
 &lt;li&gt;檢索器：該組件負責從向量數據庫中識別最相關的信息。檢索器將用户問題轉換為 Embedding 向量後執行相似性檢索，以找到與用户查詢相關的 Top-K 文檔（最相似的 K 個文檔）。&lt;/li&gt; 
 &lt;li&gt;生成器（大語言模型 LLM）：一旦檢索到相關文檔，生成器將用户查詢和檢索到的文檔結合起來，生成連貫且相關的響應。&lt;/li&gt; 
 &lt;li&gt;提示詞工程（Prompt Engineering）：這項技術用於將用户的問題與檢索到的上下文有效組合，形成大模型的輸入。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RAG 應用的核心流程&lt;/h2&gt; 
&lt;p&gt;以下為一個標準 RAG 應用的基礎流程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;將查詢轉換為向量&lt;/li&gt; 
 &lt;li&gt;在文檔集合中進行語義搜索&lt;/li&gt; 
 &lt;li&gt;將檢索到的文檔傳遞給大語言模型生成答案&lt;/li&gt; 
 &lt;li&gt;從生成的文本中提取最終答案&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d24ef1d520a066dfb3b834f8037b2ad4.jpg&quot; alt=&quot;RAG 應用.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 但在實際生產中，為了確保系統的全面性、準確性以及處理效率，還有許多因素需要加以考慮和處理。&lt;/p&gt; 
&lt;p&gt;下面我將基於答疑助手在開放平台的落地，具體介紹每個步驟的詳細流程。&lt;/p&gt; 
&lt;h1&gt;三、實現目標&lt;/h1&gt; 
&lt;p&gt;鑑於目前得物開放平台的人工答疑數量相對較高，用户在開放平台查詢未果就會直接進入到人工答疑階段。正如上文所説，RAG 擅長依賴一份可靠的知識庫作出相應回答，構建一個基於開放平台文檔知識庫的 RAG 應用再合適不過，同時可以一定程度降低用户對於人工答疑的依賴性，做到問題前置解決。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//00e4333499d11d969e47f6b0d6939208.jpg&quot; alt=&quot;實現目標.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;四、整體流程&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df99339945305abffa84509db86c62d5.jpg&quot; alt=&quot;整體流程.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;技術選型&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;大模型：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fgpt-4o-mini-advancing-cost-efficient-intelligence%2F&quot; target=&quot;_blank&quot;&gt;https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Embedding 模型： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fembeddings&quot; target=&quot;_blank&quot;&gt;https://platform.openai.com/docs/guides/embeddings&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;向量數據庫：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmilvus.io%2F&quot; target=&quot;_blank&quot;&gt;https://milvus.io/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;框架： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjs.langchain.com%2Fv0.2%2Fdocs%2Fintroduction%2F&quot; target=&quot;_blank&quot;&gt;https://js.langchain.com/v0.2/docs/introduction/&lt;/a&gt; LangChain.js 是 LangChain 的 JavaScript 版本，專門用於開發 LLM 相關的交互應用程序，其 Runnable 設計在開放平台答疑助手中廣泛應用，在拓展性、可移植性上相當強大。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;準確性思考&lt;/h2&gt; 
&lt;p&gt;問答的準確性會直接反饋到用户的使用體驗，當一個問題的回答是不準確的，會導致用户根據不準確的信息進一步犯錯，導致人工客服介入，耐心喪失直至投訴。&lt;/p&gt; 
&lt;p&gt;所以在實際構建基於開放平台文檔的答疑助手之前，首先考慮到的是問答的準確性，主要包括以下 2 點：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;首要解決答疑助手針對非開放平台提問的屏蔽&lt;/li&gt; 
 &lt;li&gt;尋找可能導致答非所問的時機以及相應的解決方案&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;屏蔽非相關問題&lt;/h3&gt; 
&lt;p&gt;為了屏蔽 AI 在回答時可能會回答一些非平台相關問題，我們首先要做的是讓 AI 明確我們的目標（即問答上下文），且告訴他什麼樣的問題可以回答，什麼問題不可以回答。&lt;/p&gt; 
&lt;p&gt;在這一點上，常用的手段為告知其什麼是開放平台以及其負責的範疇。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;例如：得物的開放平台是一個包含着 API 文檔，解決方案文檔的平台，商家可以通過這個平台獲取到得物的各種接口，以及解決方案，幫助商家更好的使用得物的服務。現在需要做一個智能答疑助手，你是其中的一部分。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在這一段描述中，我們告知了答疑助手，開放平台包含着 API 文檔，包含着解決方案，同時包含接口信息，同時會有商家等之類的字眼。大模型在收到這段上下文後，將會對其基礎回答進行判斷。&lt;/p&gt; 
&lt;p&gt;同時，我們可以通過讓答疑助手二選一的方式進行回答，即平台相關問題與非平台相關問題。我們可以讓大模型返回特定的數據枚舉，且限定枚舉範圍，例如：開放平台通用問題、開放平台 API 答疑問題，未知問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;藉助 Json 類型的輸出 + JSON Schema，我們可通過 Prompt 描述來限定其返回，從而在進入實際問答前做到事前屏蔽。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;尋找可能導致答非所問的時機&lt;/h3&gt; 
&lt;p&gt;當問題被收攏到開放平台這個主題之後，剩餘的部分就是將用户提問與上下文進行結合，再交由大模型回答處理。在這過程中，可能存在的答非所問的時機有：不夠明確的 Prompt 説明、上下文信息過於碎片化以及上下文信息的連接性不足三種。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;不夠明確的 Prompt 説明：Prompt 本身描述缺少限定條件，導致大模型回答輕易超出我們給予的要求，從而導致答非所問。&lt;/li&gt; 
 &lt;li&gt;上下文信息過於碎片化：上下文信息可能被分割成 N 多份，這個 N 值過大或者過小，都會導致單個信息過大導致缺乏聯想性、單個信息過小導致回答時不夠聚焦。&lt;/li&gt; 
 &lt;li&gt;上下文信息連接性不夠：若信息之間被隨意切割，且缺少相關元數據連接，交給大模型的上下文將會是喪失實際意義的文本片段，導致無法提取出有用信息，從而答非所問。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決以上問題，在設計初期，開放平台答疑助手設定了以下策略來前置解決準確性問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用户提問的結構化&lt;/li&gt; 
 &lt;li&gt;向量的分割界限以及元信息處理&lt;/li&gt; 
 &lt;li&gt;CO-STAR Prompt 結構&lt;/li&gt; 
 &lt;li&gt;相似性搜索的 K 值探索&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;用户提問結構化&lt;/h2&gt; 
&lt;p&gt;目標：通過大模型將用户提問的結構化，將用户提問分類並提取出精確的內容，便於提前引導、終止以及提取相關信息。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8173654688caff503208bc75be8b00c5.jpg&quot; alt=&quot;結構化.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;例如，用户提問今天天氣怎麼樣，結構化 Runnable 會將用户問題進行初次判斷。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;一個相對簡單的 Prompt 實現如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;# CONTEXT
得物的開放平台是一個包含着 API 文檔，解決方案文檔的平台，商家可以通過這個平台獲取到得物的各種接口，以及解決方案，幫助商家更好的使用得物的服務。現在需要做一個智能答疑助手，你是其中的一部分。

# OBJECTIVE
你現在扮演一名客服。請將每個客户問題分類到固定的類別中。
你只接受有關開放平台接口的相關問答，不接受其餘任何問題。
具體的類別我會在提供給你的 JSON Schema 中進行説明。

# STYLE

你需要把你的回答以特定的 JSON 格式返回

# TONE

你給我的內容裏，只能包含特定 JSON 結構的數據，不可以返回給我任何額外的信息。

# AUDIENCE

你的回答是給機器看的，所以不需要考慮任何人類的感受。

# RESPONSE

你返回的數據結構必須符合我提供的 JSON Schema 規範，我給你的 Schema 將會使用\`&amp;lt;json-schema&amp;gt;&amp;lt;/json-schema&amp;gt;\`標籤包裹.
每個字段的描述，都是你推算出該字段值的依據，請仔細閲讀。

&amp;lt;json-schema&amp;gt;
  {schema}
&amp;lt;/json-schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Json Schema 的結構通過 zod 描述如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;const zApiCallMeta = z
  .object({
    type: z
      .enum([&#39;api_call&#39;， &#39;unknown&#39;, &#39;general&#39;])
      .describe(&#39;當前問題的二級類目, api_call 為 API 調用類問題，unknown 為非開放平台相關問題, general 為通用類開放平台問題&#39;),
    apiName: z
      .string()
      .describe(
        &#39;接口的名稱。接口名稱為中文，若用户未給出明確的 API 中文名稱，不要隨意推測，將當前字段置為空字符串&#39;,
      ),
    apiUrl: z.string().describe(&#39;接口的具體路徑, 一般以/開頭&#39;),
    requestParam: z.unknown().default({}).describe(&#39;接口的請求參數&#39;),
    response: z
      .object({})
      .or(z.null())
      .default({})
      .describe(&#39;接口的返回值，若未提供則返回 null&#39;),
    error: z
      .object({
        traceId: z.string(),
      })
      .optional()
      .describe(&#39;接口調用的錯誤信息，若接口調用失敗，則提取 traceId 並返回&#39;),
  })
  .describe(&#39;當二級類目為 api_call 時，使用這個數據結構&#39;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以上結構，將會對用户的問題輸入進行結構化解析。同時給出相應 JSON 數據結構。&lt;/p&gt; 
&lt;p&gt;將以上結構化信息結合，可實現一個基於 LangChain.js 的結構化 Runnable，在代碼結構設計上，所有的 Runnable 將會使用$作為變量前綴，用於區分 Runnable 與普通函數。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import { ChatOpenAI } from &#39;@langchain/openai&#39;;
import { StringOutputParser } from &#39;@langchain/core/output_parsers&#39;;
import { RunnableSequence, RunnableMap } from &#39;@langchain/core/runnables&#39;;
import { $getPrompt } from &#39;./$prompt&#39;;
import { zSchema, StructuredInputType } from &#39;./schema&#39;;
import { n } from &#39;src/utils/llm/gen-runnable-name&#39;;
import { getLLMConfig } from &#39;src/utils/llm/get-llm-config&#39;;
import { getStringifiedJsonSchema } from &#39;src/utils/llm/get-stringified-json-schema&#39;;

const b = n(&#39;$structured-input&#39;);

const $getStructuredInput = () =&amp;gt; {
  const $model = new ChatOpenAI(getLLMConfig().ChatOpenAIConfig).bind({
    response_format: {
      type: &#39;json_object&#39;,
    },
  });

  const $input = RunnableMap.from&amp;lt;{ question: string }&amp;gt;({
    schema: () =&amp;gt; getStringifiedJsonSchema(zSchema),
    question: (input) =&amp;gt; input.question,
  }).bind({ runName: b(&#39;map&#39;) });

  const $prompt = $getPrompt();
  const $parser = new StringOutputParser();

  return RunnableSequence.from&amp;lt;{ question: string }, string&amp;gt;([
    $input.bind({ runName: b(&#39;map&#39;) }),
    $prompt.bind({ runName: b(&#39;prompt&#39;) }),
    $model,
    $parser.bind({ runName: b(&#39;parser&#39;) }),
  ]).bind({
    runName: b(&#39;chain&#39;),
  });
};

export { $getStructuredInput, type StructuredInputType };
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;鑑於 CO-STAR 以及 JSONSchema 的提供的解析穩定性，此 Runnable 甚至具備了可單測的能力。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import dotenv from &#39;dotenv&#39;;
dotenv.config();
import { describe, expect, it } from &#39;vitest&#39;;
import { zSchema } from &#39;../runnables/$structured-input/schema&#39;;
import { $getStructuredInput } from &#39;../runnables/$structured-input&#39;;

const call = async (question: string) =&amp;gt; {
  return zSchema.safeParse(
    JSON.parse(await $getStructuredInput().invoke({ question })),
  );
};

describe(&#39;The LLM should accept user input as string, and output as structured data&#39;, () =&amp;gt; {
  it(&#39;should return correct type&#39;, { timeout: 10 * 10000 }, async () =&amp;gt; {
    const r1 = await call(&#39;今天天氣怎麼樣&#39;);
    expect(r1.data?.type).toBe(&#39;unknown&#39;);
    const r2 = await call(&#39;1 + 1&#39;);
    expect(r2.data?.type).toBe(&#39;unknown&#39;);
    const r3 = await call(&#39;trace: 1231231231231231313&#39;);
    expect(r3.data?.type).toBe(&#39;api_call&#39;);
    const r4 = await call(&#39;快遞面單提示錯誤&#39;);
    expect(r4.data?.type).toBe(&#39;api_call&#39;);
    const r5 = await call(&#39;發貨接口是哪個&#39;);
    expect(r5.data?.type).toBe(&#39;api_call&#39;);
    const r6 = await call(&#39;怎麼發貨&#39;);
    expect(r6.data?.type).toBe(&#39;general&#39;);
    const r7 = await call(&#39;獲取商品詳情&#39;);
    expect(r7.data?.type).toBe(&#39;api_call&#39;);
    const r8 = await call(&#39;dop/api/v1/invoice/cancel_pick_up&#39;);
    expect(r8.data?.type).toBe(&#39;api_call&#39;);
    const r9 = await call(&#39;開票處理&#39;);
    expect(r9.data?.type).toBe(&#39;api_call&#39;);
    const r10 = await call(&#39;權限包&#39;);
    expect(r10.data?.type).toBe(&#39;api_call&#39;);
  });

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;數據預處理與向量庫的準備工作&lt;/h2&gt; 
&lt;p&gt;RAG 應用的知識庫準備是實施過程中的關鍵環節，涉及多個步驟和技術。以下是知識庫準備的主要過程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;知識庫選擇：&lt;/strong&gt;【全面性與質量】數據源的信息準確性在 RAG 應用中最為重要，基於錯誤的信息將無法獲得正確的回答。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識庫收集：&lt;/strong&gt;【多類目數據】數據收集通常涉及從多個來源提取信息，包括不同的渠道，不同的格式等。如何確保數據最終可以形成統一的結構並被統一消費至關重要。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據清理：&lt;/strong&gt;【降低額外幹擾】原始數據往往包含不相關的信息或重複內容。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;知識庫分割：&lt;/strong&gt;【降低成本與噪音】將文檔內容進行分塊，以便更好地進行向量化處理。每個文本塊應適當大小，並加以關聯，以確保在檢索時能夠提供準確的信息，同時避免生成噪聲。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;向量化存儲：&lt;/strong&gt;【Embedding 生成】使用 Embedding 模型將文本塊轉換為向量表示，這些向量隨後被存儲在向量數據庫中，以支持快速檢索。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;檢索接口構建：&lt;/strong&gt;【提高信息準確性】構建檢索模塊，使其能夠根據用户查詢從向量數據庫中檢索相關文檔。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;知識庫拆分&lt;/h3&gt; 
&lt;p&gt;知識庫文檔的拆分顆粒度（Split Chunk Size) 是影響 RAG 應用準確性的重要指標：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;拆分顆粒度過大可能導致檢索到的文本塊包含大量不相關信息，從而降低檢索的準確性。&lt;/li&gt; 
 &lt;li&gt;拆分顆粒度過小則可能導致必要的上下文信息丟失，使得生成的回答缺乏連貫性和深度。&lt;/li&gt; 
 &lt;li&gt;在實際應用中，需要不斷進行實驗以確定最佳分塊大小。通常情況下，128 字節大小的分塊是一個合適的分割大小。&lt;/li&gt; 
 &lt;li&gt;同時還要考慮 LLM 的輸入長度帶來的成本問題。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下圖為得物開放平台【開票取消預約上門取件】接口的接口文檔：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//16eacd688ddb948d7b5c938ff215c7f3.jpg&quot; alt=&quot;接口文檔.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;開票取消預約上門取件接口信息&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;拆分邏輯分析&lt;/strong&gt;（根據理論提供 128 字節大小）&lt;/p&gt; 
&lt;p&gt;在成功獲取到對應文本數據後，我們需要在數據的預處理階段，將文檔根據分類進行切分。這一步將會將一份文檔拆分為多份文檔。&lt;/p&gt; 
&lt;p&gt;由上圖中信息可見，一個文檔的基礎結構是由一級、二級標題進行分割分類的。一個基本的接口信息包括：基礎信息、請求地址、公共參數、請求入參、請求出參、返回參數以及錯誤碼信息組成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;拆分方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;拆分的實現一般有 2 種，&lt;strong&gt;一是根據固定的文檔大小進行拆分（128 字節）二是根據實際文檔結構自己做原子化拆分。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;直接根據文檔大小拆分的優點當然是文檔的拆分處理邏輯會直接且簡單粗暴，缺點就是因為是完全根據字節數進行分割，一段完整的句子或者段落會被拆分成 2 半從而丟失語義（但可通過頁碼進行鏈接解決）。&lt;/p&gt; 
&lt;p&gt;根據文檔做結構化拆分的優點是上下文結構容易連接，單個原子文檔依舊具備語義化，檢索時可以有效提取到信息，缺點是拆分邏輯複雜具備定製性，拆分邏輯難以與其他知識庫複用，且多個文檔之間缺乏一定的關聯性（但可通過元信息關聯解決）。&lt;/p&gt; 
&lt;p&gt;在得物開放平台的場景中，**因為文檔數據大多以 json 為主（例如 api 表格中每個字段的名稱、默認值、描述等），將這些 json 根據大小做暴力切分丟失了絕大部分的語義，難以讓 LLM 理解。**所以，我們選擇了第二種拆分方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;拆分實現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在文檔分割層面，Markdown 作為一種 LLM 可識別且可承載文檔元信息的文本格式，作為向量數據的基礎元子單位最為合適。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//67bbe8b4867640db1c99e2c7cbd3f3d7.jpg&quot; alt=&quot;拆分實現.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 基礎的文檔單元根據大標題進行文檔分割，同時提供 frontmatter 作為多個向量之間連接的媒介。&lt;/p&gt; 
&lt;p&gt;正文層面，開放平台的 API 文檔很適合使用 Markdown Table 來做內容承接，且 Table 對於大模型更便於理解。&lt;/p&gt; 
&lt;p&gt;根據以上這種結構，我們可得到以下拆分流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a78df68d078e947534d5032e01d24449.jpg&quot; alt=&quot;拆分流程.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;代碼實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt; const hbsTemplate = `
---
服務 ID (serviceId): {{ service.id }}
接口 ID (apiId): {{ apiId }}
接口名稱 (apiName): {{ apiName }}
接口地址 (apiUrl): {{ apiUrl }}
頁面地址 (pageUrl): {{ pageUrl }}
---

# {{ title }}

{{ paragraph }}
`;
export const processIntoEmbeddings = (data: CombinedApiDoc) =&amp;gt; {
  const template = baseTemplate(data);

  const texts = [
    template(requestHeader(data)),
    template(requestUrl(data)),
    template(publicRequestParam(data)),
    template(requestParam(data)),
    template(responseParam(data)),
    template(errorCodes(data)),
    template(authPackage(data)),
  ].filter(Boolean) as string[][];

  return flattenDeep(texts).map((content) =&amp;gt; {
    return new Document&amp;lt;MetaData&amp;gt;({
      // id: toString(data.apiId!),
      metadata: {
        serviceId: data.service.id,
        apiId: data.apiId!,
        apiName: data.apiName!,
        apiUrl: data.apiUrl!,
        pageUrl: data.pageUrl!,
      },
      pageContent: content!,
    });
  });
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;知識庫導入&lt;/h3&gt; 
&lt;p&gt;通過建立定時任務（DJOB），使用 MILVUS sdk 將以上拆分後的文檔導入對應數據集中。&lt;/p&gt; 
&lt;h2&gt;CO-STAR 結構&lt;/h2&gt; 
&lt;p&gt;在上文中的 Prompt，使用了一種名為 CO-STAR 的結構化模板，該框架由新加坡政府科技局的數據科學與 AI 團隊創立。&lt;strong&gt;CO-STAR 框架是一種用於設計 Prompt 的結構化模板，旨在提高大型語言模型（LLM）響應的相關性和有效性，考慮了多種影響 LLM 輸出的關鍵因素。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;結構：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文（Context）： 提供與任務相關的背景信息，幫助 LLM 理解討論的具體場景，確保其響應具有相關性。&lt;/li&gt; 
 &lt;li&gt;目標（Objective）： 明確你希望 LLM 執行的具體任務。清晰的目標有助於模型聚焦於完成特定的請求，從而提高輸出的準確性。&lt;/li&gt; 
 &lt;li&gt;風格（Style）： 指定希望 LLM 採用的寫作風格。這可以是某位名人的風格或特定職業專家的表達方式，甚至要求 LLM 不返回任何語氣相關文字，確保輸出符合要求。&lt;/li&gt; 
 &lt;li&gt;語氣（Tone）： 設定返回的情感或態度，例如正式、幽默或友善。這一部分確保模型輸出在情感上與用户期望相符。&lt;/li&gt; 
 &lt;li&gt;受眾（Audience）： 確定響應的目標受眾。根據受眾的不同背景和知識水平調整 LLM 的輸出，使其更加適合特定人羣。&lt;/li&gt; 
 &lt;li&gt;響應（Response）： 規定輸出格式，以確保 LLM 生成符合後續使用需求的數據格式，如列表、JSON 或專業報告等。這有助於在實際應用中更好地處理 LLM 的輸出。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在上文結構化的實現中，演示瞭如何使用 CO-STAR 結構的 Prompt，要求大模型&quot;冰冷的&quot;對用户提問進行的解析，當然 CO-STAR 也適用於直接面向用户的問答，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;## Context
我是一名正在尋找酒店信息的旅行者，計劃在即將到來的假期前往某個城市。我希望瞭解關於酒店的設施、價格和預訂流程等信息。

## Objective
請提供我所需的酒店信息，包括房間類型、價格範圍、可用設施以及如何進行預訂。

## Style
請以簡潔明瞭的方式回答，確保信息易於理解。

## Tone
使用友好和熱情的語氣，給人一種歡迎的感覺。

## Audience
目標受眾是普通旅行者，他們可能對酒店行業不太熟悉。

## Response
請以列表形式呈現每個酒店的信息，包括名稱、地址、房間類型、價格和聯繫方式。每個酒店的信息應簡短且直接，便於快速瀏覽。
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;相似性搜索&lt;/h2&gt; 
&lt;p&gt;當我們使用了問題結構化 Runnable 後，非開放平台類問題將會提前終止，告知用户無法解答相關問題，其他有效回答將會進入相似性搜索環節。&lt;/p&gt; 
&lt;p&gt;相似性搜索基於數據之間的相似性度量，通過計算數據項之間的相似度來實現檢索。在答疑助手的相似性實現是通過餘弦相似度來進行相似性判斷的。&lt;/p&gt; 
&lt;p&gt;我們將用户的提問，與向量數據庫中數據進行餘弦相似度匹配。取 K 為 5 獲取最相似的五條記錄。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意：此 K 值是經過一系列的推斷最終決定的，可根據實際情況調整。&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import { Milvus } from &#39;@langchain/community/vectorstores/milvus&#39;;
import { OpenAIEmbeddings } from &#39;@langchain/openai&#39;;
import { RunnableSequence } from &#39;@langchain/core/runnables&#39;;
import { getLLMConfig } from &#39;src/utils/llm/get-llm-config&#39;;

export const $getContext = async () =&amp;gt; {
  const embeddings = new OpenAIEmbeddings(
    getLLMConfig().OpenAIEmbeddingsConfig,
  );

  const vectorStore = await Milvus.fromExistingCollection(embeddings, {
    collectionName: &#39;open_rag&#39;,
  });

  return RunnableSequence.from([
    (input) =&amp;gt; {
      return input.question;
    },
    vectorStore.asRetriever(5),
  ]);
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;此 Runnable 會將搜索結果組成一大段可參考數據集，用於後續用户提問。&lt;/p&gt; 
&lt;h2&gt;用户提問解答&lt;/h2&gt; 
&lt;p&gt;用户提問的解答同樣通過 Runnable 的方式來承接，通過用户提問、結構化數據、提取的相似性上下文進行結合，最終得到問題的解答。&lt;/p&gt; 
&lt;p&gt;我們先將上下文進行格式化整理：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import { RunnablePassthrough, RunnablePick } from &#39;@langchain/core/runnables&#39;;
import { Document } from &#39;langchain/document&#39;;
import { PromptTemplate } from &#39;@langchain/core/prompts&#39;;
import { MetaData } from &#39;src/types&#39;;

const $formatRetrieverOutput = async (documents: Document&amp;lt;MetaData&amp;gt;[]) =&amp;gt; {
  const strings = documents.map(async (o) =&amp;gt; {
    const a = await PromptTemplate.fromTemplate(`{pageContent}`).format({
      pageContent: o.pageContent,
    });

    return a;
  });

  const context = (await Promise.all(strings)).join(&#39;\n&#39;);

  return context;
};

export const $contextAssignRunnable = () =&amp;gt; {
  return RunnablePassthrough.assign({
    context: new RunnablePick(&#39;context&#39;).pipe($formatRetrieverOutput),
  });
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;問答整體 Prompt 實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;export const promptTemplateMarkdown = () =&amp;gt; {
  return `
# CONTEXT

得物的開放平台是一個包含着 API 文檔，解決方案文檔的平台，商家可以通過這個平台獲取到得物的各種接口，以及解決方案，幫助商家更好的使用得物的服務。
現在得物開放平台的人工答疑率相當高，原因可能是文檔的信息藏的較深，我希望做一個人工智能答疑助手，通過分析開放平台的各種文檔，來回答用户的問題，最終讓用户不進入人工答疑階段。
我們只討論[開放平台接口]的相關問題,不要談及其他內容。

# OBJECTIVE
你需要根據用户的輸入，以及提供的得物開放平台的文檔上下文，進行答疑。
你只接受有關[開放平台接口]的相關問答，不接受其餘任何問題。

## 關於用户的輸入：

1. 你會得到一份符合 JSONSchema 結構的結構化數據，這份數據我會使用\`&amp;lt;structured-input&amp;gt;&amp;lt;/structured-input&amp;gt;\`包裹。
   這份結構化數據是通過實際的用户提問進行了二次分析而得出的。結構化數據裏也會包含用户的最初始的問題供你參考（最初始的問題會放在 question 字段裏）

## 關於上下文

1.  我已經提前準備好了你需要參考的資料，作為你回答問題的上下文，上下文是由許多篇 Markdown 文檔組成的。這些 Markdown 的文檔大標題代表了這個片段的模塊名，例如 \`# 接口入參\`就代表這部分是文檔的接口入參部分， \`# 接口返回\`就代表這部分是文檔的接口返回部分，
2.  上下文中的主要信息部分我會使用 Markdown Table 的結構提供給你。
3.  每個上下文的開頭，我都會給你一些關於這份上下文的元信息（使用 FrontMatter 結構），這個元信息代表了這份文檔的基礎信息，例如文檔的頁面地址，接口的名稱等等。

以下是我提供的結構化輸入，我會使用\`&amp;lt;structured-input&amp;gt;&amp;lt;/structured-input&amp;gt;\`標籤做包裹
&amp;lt;structured-input&amp;gt;
{structuredInput}
&amp;lt;/structured-input&amp;gt;

以下是我為你提供的參考資料，我會使用\`&amp;lt;context&amp;gt;&amp;lt;/context&amp;gt;\`標籤包裹起來：
&amp;lt;context&amp;gt;
{context}
&amp;lt;/context&amp;gt;

# STYLE

你需要把你的回答以特定的 JSON 格式返回

# TONE

你是一個人工智能答疑助手，你的回答需要温柔甜美，但又不失嚴謹。對用户充滿了敬畏之心，服務態度要好。在你回答問題之前，需要簡單介紹一下自己，例如&quot;您好，很高興為您服務。已經收到您的問題。&quot;

# AUDIENCE

你的用户是得物開放平台的開發者們，他們是你要服務的對象。

# RESPONSE

你返回的數據結構必須符合我提供的 JSON Schema 規範，我給你的 Schema 將會使用\`&amp;lt;structured-output-schema&amp;gt;&amp;lt;/structured-output-schema&amp;gt;\`標籤包裹.

&amp;lt;structured-output-schema&amp;gt;
  {strcuturedOutputSchema}
&amp;lt;/structured-output-schema&amp;gt;
`;
};

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以上問答通過 CO-STAR 結構，從 6 個方面完全限定了答疑助手的回答腔調以及問答範疇，我們現在只需要準備相應的數據結構提供給這份 Prompt 模板。&lt;/p&gt; 
&lt;h3&gt;問答結果結構化&lt;/h3&gt; 
&lt;p&gt;在開放平台答疑助手的場景下，我們不僅要正面回答用户的問題，同時還需要給出相應的可閲讀鏈接。結構如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import { z } from &#39;zod&#39;;

const zOutputSchema = z
  .object({
    question: z
      .string()
      .describe(
        &#39;提煉後的用户提問。此處的問題指的是除去用户提供的接口信息外的問題。儘量多的引用用户的提問&#39;,
      ),
    introduction: z
      .string()
      .describe(&#39;開放平台智能答疑助手對用户的問候以及自我介紹&#39;),
    answer: z
      .array(z.string())
      .describe(
        &#39;開放平台智能答疑助手的回答，需將問題按步驟拆分，形成數組結構，回答拆分儘量步驟越少越好。如果回答的問題涉及到具體的頁面地址引用，則將頁面地址放在 relatedUrl 字段裏。不需要在 answer 裏給出具體的頁面地址&#39;,
      ),
    relatedUrl: z
      .array(z.string())
      .describe(
        &#39;頁面的鏈接地址，取自上下文的 pageUrl 字段，若涉及多個文檔，則給出所有的 pageUrl，若沒有 pageUrl，則不要返回&#39;,
      )
      .optional(),
  })
  .required({
    question: true,
    introduction: true,
    answer: true,
  });

type OpenRagOutputType = z.infer&amp;lt;typeof zOutputSchema&amp;gt;;

export { zOutputSchema, type OpenRagOutputType };

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在我們之前的設計中，我們的每一份向量數據的頭部，均帶有相應的文檔 meta 信息，通過這種向量設計，我們可以很容易的推算出可閲讀鏈接。同時，我們在這份 zod schema 中提供了很詳細的 description，來限定機器人的回答可以有效的提取相應信息。&lt;/p&gt; 
&lt;h2&gt;Runnable 的結合&lt;/h2&gt; 
&lt;p&gt;在用户提問解答這個 Runnable 中，我們需要結合 Retriever, 上下文，用户提問，用户輸出限定這幾部分進行組合。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;import { ChatOpenAI } from &#39;@langchain/openai&#39;;
import { $getPrompt } from &#39;./prompt/index&#39;;
import { JsonOutputParser } from &#39;@langchain/core/output_parsers&#39;;
import { RunnableSequence, RunnableMap } from &#39;@langchain/core/runnables&#39;;
import { zOutputSchema } from &#39;./schema&#39;;
import { $getContext } from &#39;./retriever/index&#39;;
import { getLLMConfig } from &#39;src/utils/llm/get-llm-config&#39;;
import { getStringifiedJsonSchema } from &#39;src/utils/llm/get-stringified-json-schema&#39;;
import { n } from &#39;src/utils/llm/gen-runnable-name&#39;;

const b = n(&#39;$open-rag&#39;);

type OpenRagInput = {
  structuredInput: string;
  question: string;
};

const $getOpenRag = async () =&amp;gt; {
  const $model = new ChatOpenAI(getLLMConfig().ChatOpenAIConfig).bind({
    response_format: {
      type: &#39;json_object&#39;,
    },
  });

  const chain = RunnableSequence.from([
    RunnableMap.from&amp;lt;OpenRagInput&amp;gt;({
      // 問答上下文
      context: await $getContext(),
      // 結構化輸入
      structuredInput: (input) =&amp;gt; input.structuredInput,
      // 用户提問
      question: (input) =&amp;gt; input.question,
      // 輸出結構
      strcuturedOutputSchema: () =&amp;gt; getStringifiedJsonSchema(zOutputSchema),
    }).bind({ runName: b(&#39;runnable-map&#39;) }),
    $getPrompt().bind({ runName: b(&#39;prompt&#39;) }),
    $model,
    new JsonOutputParser(),
  ]).bind({ runName: b(&#39;chain&#39;) });

  return chain;
};

export { $getOpenRag };

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;流程串聯&lt;/h2&gt; 
&lt;p&gt;通過上文的幾大部分，我們已經將，用户提問、結構化解析、相似性搜索、問答上下文，問答 Prompt 模板以及結構化輸出這幾部分實現完成。&lt;/p&gt; 
&lt;p&gt;現在可以通過 LangChain 的 Runnable 能力進行流程串聯。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;const structure = safeJsonParse&amp;lt;StructuredInputType&amp;gt;(
  await $getStructuredInput().invoke({ question }),
  null,
)
const mainChain = RunnableSequence.from&amp;lt;{ question: string }, OpenRagOutputType&amp;gt;([
  RunnablePassthrough.assign({
    structuredInput: () =&amp;gt; structure,
  }),
  await $getOpenRag(),
]);
const response = await mainChain.invoke({
  question: question,
});

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;串聯流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b421b5c8f303158f6231418ebf2ca33.jpg&quot; alt=&quot;串聯流程.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;返回結果示例：&lt;/p&gt; 
&lt;p&gt;輸入：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;{
  &quot;question&quot;: &quot;正式環境調用：直髮訂單獲取打印面單 v2【品牌直髮/眾籌直髮/拍賣直髮】接口返回報錯（https://openapi.dewu.com/dop/api/v2/order/brand_deliver/express_sheet）。請求參數：{\&quot;order_no\&quot;:\&quot;110152014363632294\&quot;,\&quot;app_key\&quot;:\&quot;953a43bec40943c98a5cdbc63333242f;\&quot;,\&quot;sign\&quot;:\&quot;AD968ED6A359D144B61F1FEF6BB380ED\&quot;,\&quot;timestamp\&quot;:1720430064169}&quot;
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;輸出：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;{
  &quot;question&quot;: &quot;我的問題是：正式環境調用：直髮訂單獲取打印面單 v2【品牌直髮/眾籌直髮/拍賣直髮】接口返回報錯。&quot;,
  &quot;introduction&quot;: &quot;您好，很高興為您服務。已經收到您的問題。&quot;,
  &quot;answer&quot;: [
    &quot;根據您提供的請求參數信息，出現錯誤可能是由於接口調用參數不正確導致的，接下來我們一步步排查問題。&quot;,
    &quot;首先，您提供的請求參數中的訂單號為\&quot;110152014363632294\&quot;，請確認該訂單號的狀態是否為待物流攬收或待買家收貨狀態。&quot;,
    &quot;其次，檢查您所使用的 app_key 是否正確，確保該 app_key 授權了調用該接口的權限。&quot;,
    &quot;再次，請確認傳入的簽名（sign）是否正確，可能需要重新生成簽名以保證準確性。&quot;,
    &quot;最後，檢查時間戳（timestamp）是否正確，並且處於合理的時間範圍內。&quot;,
    &quot;如果以上步驟都沒有解決問題，建議您查看詳細的接口文檔以進一步調試和解決問題。&quot;
  ],
  &quot;relatedUrl&quot;: [
    &quot;https://open.dewu.com/#/api?apiId=1174&quot;
  ]
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;五、應用調試&lt;/h1&gt; 
&lt;p&gt;基於大模型應用可能設計到多個 Runnable 的多次調用，借用 LangSmith 的 trace 功能，我們可以對每一個 Runnable 進行出入參的 debug。&lt;/p&gt; 
&lt;p&gt;關於 LangSmith 的接入：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4d0929ecd9aa09dc87767366d0d0310.jpg&quot; alt=&quot;Langsmith.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;六、未來展望&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1d5ae777a2c6e355af5f2c03284c0542.gif&quot; alt=&quot;未來展望.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt; RAG 在減少模型幻覺，無需模型訓練就可享受內容時效性的特點在此類答疑應用中展露無遺，RAG 應用開放平台落地從一定程度上驗證了依賴可靠知識庫的答疑場景具備可執行性，還為內部系統的應用提供了有力的參考。在實際應用中，除了直接解決用户的提問外，通過回放用户提問的過程，可以為產品和業務的發展提供重要的洞察。&lt;/p&gt; 
&lt;p&gt;面向未來，是否可以嘗試將答疑助手的形式在內部系統落地，在內部建立知識庫體系，將部分問題前置給大模型處理，降低 TS 和開發介入答疑的成本。&lt;/p&gt; 
&lt;p&gt;文 / 惑普&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/17101439</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/17101439</guid>
            <pubDate>Mon, 06 Jan 2025 08:48:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>英國政府公佈「人工智能機遇行動計劃」，擬將公共計算能力提高 20 倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英國政府 13 日公佈「人工智能機遇行動計劃」，旨在大力推廣人工智能，以促進經濟增長、創造就業機會並提升公共服務水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這項計劃指出，人工智能的能力正以驚人的速度發展，照這一趨勢，人工智能將成為英國政府實現推動經濟增長等重要使命的主要動力。根據計劃，英國政府將與世界領先的人工智能公司、頂尖的英國學者和企業家，以及希望在英國開拓業務的相關人才密切合作，在共享經濟繁榮、改善公共服務和增加個人機會的原則上塑造人工智能革命。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這項計劃涵蓋多個領域，涉及促進經濟增長和提高公共服務水平等。計劃還包括建立多個「人工智能增長區」，以促進人工智能數據中心建設；將公共計算能力提高 20 倍；創建新的國家數據庫，以安全可靠地釋放公共數據價值；成立專門的人工智能能源委員會等措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英國首相斯塔默當天在一份公報中表示，人工智能將給英國帶來巨大變化。政府出台這項新計劃將推動英國成為人工智能領域的領導者。它將促進人工智能相關產業的基礎設施建設，為英國帶來更多就業機會和投資，並改善公共服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英國科學、創新和技術大臣彼得·凱爾在這項計劃的序言中表示，如今英國是全球第三大人工智能市場，但仍有落後風險。希望英國在人工智能的下一個發展階段能塑造人工智能革命，而不是等待被其塑造。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英國政府網站介紹，目前已有三家大型科技公司承諾在英國投資 140 億英鎊建設人工智能基礎設施，並在英國創造超過 1.3 萬個就業崗位。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329660</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329660</guid>
            <pubDate>Mon, 06 Jan 2025 07:15:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linus 變身「手工林」——將親自打造一套吉他效果器踏板贈送給內核開發者</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Linus 表示，我是軟件工程師，也略懂焊接技術，願意親手製作一個吉他效果器踏板贈送給一名幸運的內核貢獻者&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這個假期，Linus 的心情看起來相當不錯，因為 Linux 開發團隊已經完成了 Linux 內核 6.13 候選版 rc7，最終的穩定版將於下週發佈。&lt;/p&gt; 
&lt;p&gt;近日，Linus 在每週發佈的關於 Linux 內核開發進度的公告中寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本週開始時看起來有點平靜，但隨後事情多了起來。&lt;/p&gt; 
 &lt;p&gt;在經歷了兩個平靜的假期周之後，我們恢復了原本的開發效率。&lt;/p&gt; 
 &lt;p&gt;這個 rc7 比正常情況下稍大，但考慮到時間因素，它與我預期的差不多，沒有什麼特別之處。&lt;/p&gt; 
 &lt;p&gt;因此，除非下週發生什麼奇怪的事情，否則下週我將按照正常計劃發佈最終的 6.13 正式版本。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Linus 在郵件中用温暖的語氣描述了他最喜歡的假日愛好 —— 製作樂高積木，同時補充道，他一直喜歡 DIY 製作一些吉他踏板套件，這是他今年越來越喜歡的事情。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0114/150734_f8e2_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;因此，他願意為一位幸運的 Linux 內核開發者製作一個&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#060607&quot;&gt;Guitar pedals（吉他效果器踏板）&lt;/span&gt;&lt;/strong&gt;，這樣 Linus 就有理由為自己新發掘的愛好繼續投入時間和金錢了。&lt;/p&gt; 
&lt;p&gt;他寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;對我來説，傳統節日活動往往是做一兩件樂高積木，因為這通常是聖誕節和生日禮物的一部分。&lt;/p&gt; 
 &lt;p&gt;但除了樂高積木，今年我還做了個吉他踏板套件（&quot;大人用烙鐵做的樂高&quot;）。 不是因為我彈吉他，而是因為我喜歡手工搗鼓東西的感覺……&lt;/p&gt; 
 &lt;p&gt;我做了很多，但我真正喜歡做的套件來自 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faionfx.com%2Fproject-type%2Fkit%2F&quot; target=&quot;_blank&quot;&gt;Aion FX&lt;/a&gt;。&lt;/p&gt; 
 &lt;p&gt;既然我想有藉口繼續做這些工作，又因為我實際上對製作出來的踏板沒有任何用途（我已經把一些踏板賣給了不知情的「受害者」朋友們），我決定看看是否有「倒黴」的內核開發者想要一個。&lt;/p&gt; 
 &lt;p&gt;所有我決定，如果有任何內核開發者（&lt;em&gt;定義是「在我的內核 Git 樹中自 2024 年以來有 commit 記錄的開發者」&lt;/em&gt;）覺得他們的生活中真的需要一個由我親手打造的吉他踏板，請給我發一封電子郵件（發件人為 git 樹中的那個郵箱地址），主題是 &quot;我想要一個吉他踏板&quot;。&lt;br&gt; ......&lt;/p&gt; 
 &lt;p&gt;下週，我會隨機挑選一名內核貢獻者（假設真的有人想要），然後自費買下那個套件，用我自己顫抖的小手指製作它，並通過美國郵政服務寄給「受害者」。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flkml.iu.edu%2Fhypermail%2Flinux%2Fkernel%2F2501.1%2F06189.html&quot; target=&quot;_blank&quot;&gt;詳情查看 Linux 內核郵件列表&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329653/linus-torvalds-guitar-pedal-offer</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329653/linus-torvalds-guitar-pedal-offer</guid>
            <pubDate>Mon, 06 Jan 2025 07:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開源雲操作系統 Sealos 開發商「環界雲計算」獲阿里雲戰略投資</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據 36 氪&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F3121978699698434&quot; target=&quot;_blank&quot;&gt;報道&lt;/a&gt;&lt;/u&gt;，珠海環界雲計算有限公司（以下簡稱「環界雲計算」）近日宣佈完成 3750 萬元的 Pre-A 融資，由阿里雲獨家投資。&lt;/p&gt; 
&lt;p&gt;在此之前，環界雲計算曾累計獲得三輪融資。其中天使輪融資由奇績創壇領投，清華信息學院院⻓李軍、科⼤微電⼦教授康⼀跟投。&lt;/p&gt; 
&lt;p&gt;環界雲計算成立於 2022 年 3 月，其核心產品 Sealos 是一款以 kubernetes 為內核的雲操作系統；另外該公司還有知名開源項目&lt;a href=&quot;https://www.oschina.net/p/fastgpt&quot; target=&quot;_blank&quot;&gt;FastGPT&lt;/a&gt;，是一款 AI 知識庫產品。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1818&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0114/142300_QxNg_2720166.png&quot; width=&quot;2622&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsealos.run%2F&quot; target=&quot;_blank&quot;&gt;https://sealos.run/&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;閲讀更多&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/u/6852546/blog/10758980&quot; target=&quot;news&quot;&gt;Sealos：在公有云和私有云之間，我選擇第三條路&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329646</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329646</guid>
            <pubDate>Mon, 06 Jan 2025 06:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>積木報表 JimuReport 5 年發展，用户數突破 400 萬，成為報表領域的佼佼者</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;積木報表 JimuReport：5 年發展，用户數突破 400 萬，成為開源報表領域的佼佼者&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;在數據驅動的時代，企業對數據可視化和報表工具的需求日益增長。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;作為國內一款備受關注的開源報表工具，&lt;strong&gt;積木報表（JimuReport）&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;自 2020 年 11 月 2 日發佈首個版本以來，憑藉其零代碼、易用性和強大的功能，迅速在市場中佔據了一席之地。歷經 5 年的發展，JimuReport 已經成長為許多企業和開發者的首選工具。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;那麼，這款開源報表工具目前究竟有多少用户？它的發展歷程和現狀如何？本文將為您詳細解讀。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;一、積木報表（JimuReport）項目介紹&lt;/h2&gt; 
&lt;h3&gt;1. 項目背景&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;積木報表（JimuReport）是一款專注於數據可視化和報表設計的開源工具，由國內 JEECG 團隊開發並維護。其核心理念是 「簡單、易用、專業」，旨在幫助企業快速構建複雜的報表、大屏和儀表盤，降低開發成本，提升數據分析效率。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bfec91d2704578da7536e722a0dcee549b0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2. 核心功能&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;零代碼設計&lt;/strong&gt;：通過拖拽式操作，用户無需編程即可完成報表和大屏設計。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;類 Excel 操作&lt;/strong&gt;：提供類似 Excel 的操作界面，支持複雜報表設計。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大屏設計&lt;/strong&gt;：支持類 Word 風格的大屏設計，用户可以自由拖動組件，設計出炫酷的數據大屏。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多端支持&lt;/strong&gt;：從 v1.9+ 開始，支持儀表盤、大屏、門户和移動端的一體化設計。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據可視化&lt;/strong&gt;：支持多種圖表類型（柱狀圖、折線圖、餅圖、地圖等）和動態效果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 開源與免費&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;JimuReport 採用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;功能免費、代碼不開放&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的開源協議，用户可以免費使用其全部功能，並支持商業用途。&lt;/li&gt; 
 &lt;li&gt;這種模式降低了用户的使用門檻，尤其適閤中小企業和個人開發者。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 適用場景&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;企業報表&lt;/strong&gt;：財務報表、銷售報表、庫存報表等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據大屏&lt;/strong&gt;：業務監控大屏、實時數據展示大屏。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;儀表盤&lt;/strong&gt;：業務分析儀表盤、KPI 監控儀表盤。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;門户設計&lt;/strong&gt;：企業門户、數據門户。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. 效果圖&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-376340bf61cb54c3833567da653bef1a2d9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8e989813e945d5e4c27fba7c1a65c980288.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-02ef801cf1e91bd51a3817b4c891885ddcc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5804404d2f0ee00aa30b0d306a95d7b8921.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1a683223788b8e43104e855a32077dbb82.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-77c2870cbf92a6b2bb5f35c23f3fc0cc4a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;二、歷經 5 年發展，JimuReport 的用户數有多少？&lt;/h2&gt; 
&lt;h3&gt;1. 用户規模估算&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;根據 JimuReport 官方提供的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;百度統計&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;數據，其每日訪問量（PV）為 196,866，獨立訪客數（UV）為 24,766，獨立 IP 數為 17,143。基於這些數據，我們可以對 JimuReport 的用户規模進行初步估算：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;日活躍用户數（DAU）&lt;/strong&gt;：約&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;35,380&lt;/strong&gt;（考慮到年末訪問量較低和很多項目內網隔離，實際 UV 可能更高）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;月活躍用户數（MAU）&lt;/strong&gt;：假設每日 UV 的 10 倍，約為&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;35.4 萬&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;年活躍用户數（YAU）&lt;/strong&gt;：假設每月活躍用户的 12 倍，約為&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;424.8 萬&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 項目數估算&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;假設 50% 的月活躍用户創建了項目，每個用户平均創建 1-2 個項目。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;項目數&lt;/strong&gt;：約&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;17.7 萬&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 用户分佈&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;中小企業&lt;/strong&gt;：JimuReport 的免費模式和易用性使其在中小企業中廣受歡迎。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;個人開發者&lt;/strong&gt;：零代碼設計和豐富的功能吸引了大量個人開發者。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;教育機構&lt;/strong&gt;：部分高校和教育機構使用 JimuReport 進行數據可視化教學。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;三、JimuReport 的發展歷程&lt;/h2&gt; 
&lt;h3&gt;1. 2020 年 11 月 2 日：首個版本發佈&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;JimuReport 正式發佈首個版本，初期以開源報表工具為核心，專注於解決企業報表難題。&lt;/li&gt; 
 &lt;li&gt;首個版本推出後，迅速吸引了大量中小企業和個人開發者的關注。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 2021 年：功能完善&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;推出類 Excel 的報表設計器和類 Word 的大屏設計器，支持拖拽式操作。&lt;/li&gt; 
 &lt;li&gt;用户數量開始快速增長，尤其是在中小企業市場中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 2022 年：多端支持&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;從 v1.9+ 開始，推出 JimuBI 產品，支持儀表盤、大屏、門户和移動端的一體化設計。&lt;/li&gt; 
 &lt;li&gt;用户規模突破 10 萬。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 2023 年：社區壯大&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;JimuReport 的社區逐漸壯大，GitHub 和官網論壇的活躍度顯著提升。&lt;/li&gt; 
 &lt;li&gt;用户數量突破 50 萬。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. 2024 年：持續增長&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;用户數量持續增長，年活躍用户數接近 424.8 萬。&lt;/li&gt; 
 &lt;li&gt;在數據可視化領域的影響力進一步提升，成為國內開源報表工具的代表之一。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;四、JimuReport 的未來展望&lt;/h2&gt; 
&lt;h3&gt;1. 功能升級&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;繼續優化報表設計和大屏設計功能，提升用户體驗。&lt;/li&gt; 
 &lt;li&gt;引入更多智能分析功能，幫助用户更好地挖掘數據價值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 生態建設&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;加強社區建設，吸引更多開發者和企業參與。&lt;/li&gt; 
 &lt;li&gt;推出更多插件和擴展，豐富 JimuReport 的生態系統。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 國際化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;拓展海外市場，將 JimuReport 推向全球用户。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;五、總結&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;自 2020 年 11 月 2 日發佈首個版本以來，積木報表（JimuReport）在短短 5 年內實現了快速發展。其用户規模從最初的幾千人增長到如今的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;424.8 萬&lt;/strong&gt;，項目數也突破了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;17.7 萬&lt;/strong&gt;。憑藉其零代碼、易用性和強大的功能，JimuReport 正在幫助越來越多的企業和開發者實現數據可視化，提升業務效率。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;未來，隨着功能的不斷升級和生態的持續完善，JimuReport 有望在數據可視化領域取得更大的成就。如果你正在尋找一款免費、易用且功能強大的報表工具，JimuReport 無疑是一個值得嘗試的選擇。&lt;/p&gt; 
&lt;hr&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;&lt;strong&gt;官網鏈接&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jimureport.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.jimureport.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;&lt;strong&gt;GitHub 地址&lt;/strong&gt;:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJimuReport%2FJimuReport&quot; target=&quot;_blank&quot;&gt;https://github.com/JimuReport/JimuReport&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329625</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329625</guid>
            <pubDate>Mon, 06 Jan 2025 03:31:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>Deno Land 稱甲骨文拒絕放棄 JavaScript 商標</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 年 11 月，Deno Land 曾向美國專利商標局 (USPTO) 提交了一份申請，&lt;a href=&quot;https://www.oschina.net/news/322147/deno-v-oracle-javascript-trademark&quot;&gt;要求&lt;/a&gt;取消甲骨文 (Oracle) 對 JavaScript 商標的所有權。並提出了三項主張：JavaScript 是通用的、Oracle 公司存在欺詐行為，以及 Oracle 已放棄使用該商標。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日， Deno Land 在 X 上發佈了一篇&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fdeno_land%2Fstatus%2F1876728474666217739&quot; target=&quot;_blank&quot;&gt;帖子&lt;/a&gt;，介紹了關於該商標之爭事件的最新進展。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;#FreeJavaScript update：Oracle 公司已告知我們，他們不會主動撤回其 「JavaScript 」商標。下一步：他們將提交答辯狀，我們將開始取證，以表明「JavaScript 」如何被廣泛認為是一個通用術語，並且不受 Oracle 控制。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;399&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a7b0c8946ded6dedb137aeb2b5ae4ba521e.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Deno Land 聯合創始人、Deno 和 Node.js 運行時的創建者 Ryan Dahl &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3800955%2Foracle-refuses-to-yield-javascript-trademark-deno-land-says.html&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，除非 Oracle 再次延長截止日期，否則 Oracle 預計將在 2 月 3 日之前給出正式答覆。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「此後，我們將開始調查過程，真正的法律工作將從這裏開始。看看 Oracle 如何反駁我們的主張將會很有趣 —— 通用名稱侵權、對美國專利商標局的欺詐以及未使用該商標。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;法律程序將從 3 月 5 日之前的取證會議開始，9 月 1 日之前取證結束，10 月 16 日至 12 月 15 日進行審前披露。口頭聽證的選擇性請求截止日期為 2026 年 7 月 8 日。總的來説，Oracle 和 Deno Land 之間的糾紛可能會持續相當長一段時間。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329615/oracle-refuses-yield-javascript-trademark</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329615/oracle-refuses-yield-javascript-trademark</guid>
            <pubDate>Mon, 06 Jan 2025 03:03:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「30% 抽成」再惹麻煩，蘋果在英面臨 134 億元鉅額索賠</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;1 月 13 日消息，針對蘋果公司的集體訴訟在英國競爭上訴法庭正式開庭。蘋果公司被指控對其 App Store 下載的軟件收取 「過高且不公平」 的費用，面臨高達 15 億英鎊（約合 134 億人民幣）的法律索賠。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0114/105029_xrGc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;原告認為，蘋果強迫軟件開發商使用其自有的應用商店分發應用程序，屬於濫用市場主導地位行為，且收取高達 30% 的佣金，限制了競爭，影響了開發者和消費者。&lt;/p&gt; 
&lt;p&gt;原告強調，蘋果通過這些高額佣金獲取了 「暴利」，遠高於其他平台可能收取的費用。蘋果此前曾回應認為，該訴訟沒有依據，稱 App Store 收取的佣金與其他數字平台的收費標準相當，App Store 上大多數應用都是免費的。上述佣金項目也被外界稱為「蘋果税」，即 App Store 內，年收入在 100 萬美元以上的應用，蘋果對其內發生的數字內容消費收取 30% 的分成，而對 100 萬美元以下的中小開發者抽成比例則為 15%。&lt;/p&gt; 
&lt;p&gt;在蘋果看來，原告所界定的市場過於狹窄，僅包含 iOS 應用，在更廣泛的數字交易和設備市場中，蘋果並不佔據主導地位。App Store 收取的佣金是其在平台上進行大量投資的合理回報，涵蓋支付處理、開發者工具、安全審查、營銷以及內容篩選等方面。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329611/apple-uk-lawsuit-app-store-overcharging</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329611/apple-uk-lawsuit-app-store-overcharging</guid>
            <pubDate>Mon, 06 Jan 2025 02:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>零一萬物密集招兵買馬，剛抱阿里又握手蘇州</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;1 月 13 日，有媒體報道稱，零一萬物在和阿里雲成立產業大模型聯合實驗室的同時，還在蘇州開啓了大批招聘崗位，而且招聘崗位大多是研發等核心崗，和大模型應用落地密切相關。&lt;/p&gt; 
&lt;p&gt;據悉，大本營一直在北京的零一萬物悄悄在招聘平台上上線了數十個崗位，地點定在了蘇州。職位共計是 41 個，其中，技術人員職位 16 個。&lt;/p&gt; 
&lt;p&gt;根據零一萬物官網最新招聘信息，和此前相比，確實上線了數十個技術產品崗位，Base 蘇州的崗位足足有 24 個。這些崗位涵蓋了研發、運營、設計等多個領域，研發崗位佔據了大多數。算法、AI 基礎設施、數據標註、內容風控、前端研發、後端研發等等，基本上是大模型研發及應用落地的核心。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0114/104143_VIHS_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;數據顯示，蘇州的 AI 相關企業數量已位居全國前列，而人工智能在製造業中的應用場景開發也不斷加速。科大訊飛、樹根互聯、雲從科技、新華三等行業頭部企業都已入駐蘇州人工智能產業園；智能語音企業思必馳科技、AI 藥物研發企業鎂伽科技和自動駕駛企業天瞳威視等優秀人工智能企業也位於蘇州。&lt;/p&gt; 
&lt;p&gt;另一方面，AI 行業的淘汰賽已經打響，零一萬物的每一步棋都備受關注。先前與阿里雲成立產業大模型聯合實驗室，此次又在大力擴充蘇州辦公室，如此來看，零一萬物正在試圖用「新一線城市+大廠+小虎」的打法，為自身爭取產業大模型的更多落地可能。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/328590&quot; target=&quot;news&quot;&gt;零一萬物闢謠「被阿里收購」傳聞&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/329609</link>
            <guid isPermaLink="false">https://www.oschina.net/news/329609</guid>
            <pubDate>Mon, 06 Jan 2025 02:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>