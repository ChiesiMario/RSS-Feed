<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 25 Jun 2025 07:46:42 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Anthropic 未經許可使用書籍訓練 AI 模型屬於「合理使用」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;美國舊金山聯邦法官威廉・阿爾蘇普（William Alsup）&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Flegal%2Flitigation%2Fanthropic-wins-key-ruling-ai-authors-copyright-lawsuit-2025-06-24%2F" target="_blank"&gt;裁定&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;Anthropic 在未經作者許可的情況下使用已出版書籍訓練其 AI 模型屬於「合理使用 (fair use)」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0625/153420_i6T1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這標誌着法院首次認可 AI 公司的主張，即當 AI 公司使用受版權保護的材料訓練大型語言模型（LLM）時，合理使用原則可使其免於承擔責任。&lt;/p&gt; 
&lt;p&gt;法官指出，AI 模型對作品的訓練類似於讀者閲讀並從中汲取靈感以創作新內容，而非複製或取代原作。然而，判決也指出，Anthropic 在 2021 年至 2022 年期間從 Books3、Library Genesis 和 Pirate Library Mirror 等來源下載的超過 700 萬本盜版電子書不屬於合理使用，這部分內容將面臨陪審團審判。Anthropic 曾花費數百萬美元購買並掃描大量印刷書籍，將其轉換為數字格式用於內部研究。&lt;/p&gt; 
&lt;p&gt;這一裁決被認為是 AI 行業在版權合理使用方面的一個重要里程碑。同時對作者、藝術家和出版商是一個打擊，他們已對 OpenAI、Meta、Midjourney、Google 等公司提起數十起訴訟。儘管這一裁決並不能保證其他法官會效仿阿爾蘇普法官的做法，但它為支持科技公司而非創作者的先例奠定了基礎。&lt;/p&gt; 
&lt;p&gt;這些訴訟通常取決於法官如何解釋合理使用原則，這是版權法中一個出了名難以界定的例外條款，該條款自 1976 年以來就未更新過 —— 那時互聯網尚未出現，更不用説生成式 AI 訓練數據集的概念了。&lt;/p&gt; 
&lt;p&gt;合理使用裁決會考慮作品的使用目的（模仿和教育用途可能是可行的）、是否為商業利益而複製（你可以寫《星球大戰》同人小説，但不能出售），以及衍生作品與原作相比的轉換性程度。&lt;/p&gt; 
&lt;p&gt;像 Meta 這樣的公司在為使用受版權保護的作品進行訓練辯護時也提出了類似的合理使用論點，不過在本週的裁決之前，法院會如何裁決還不太明確。&lt;/p&gt; 
&lt;p&gt;在這起具體的 Bartz 訴 Anthropic 案中，原告作者團體還對 Anthropic 獲取和存儲他們作品的方式提出了質疑。根據訴訟稱，Anthropic 試圖創建一個 「中央圖書館」，收錄 「世界上所有的書籍」 並 「永久」 保存。但這些受版權保護的數百萬本書籍是從盜版網站免費下載的，這顯然是非法的。&lt;/p&gt; 
&lt;p&gt;儘管法官承認 Anthropic 對這些材料的訓練屬於合理使用，但法院將對 「中央圖書館」 的性質進行審判。&lt;/p&gt; 
&lt;p&gt;「我們將對用於創建 Anthropic 中央圖書館的盜版副本及其造成的損害進行審判」， 阿爾蘇普法官在裁決中寫道，「Anthropic 後來購買了一本之前從互聯網上竊取的書，並不能免除其盜竊責任，但可能會影響法定損害賠償的程度。」&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/353744" target="news"&gt;Reddit&amp;nbsp;起訴 Anthropic 未經許可使用其數據訓練 AI 模型&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357201</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357201</guid>
      <pubDate>Wed, 25 Jun 2025 07:34:40 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>WinRAR「壓縮包」再度開售，價格和 5 份 WinRAR 正版授權相當</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;WinRAR 官方手提包周邊於 2025 年 2 月首次由 WinRAR 與製造商 Tern 聯動推出，當時迅速售罄。近日，Tern &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Ftern_et%2Fstatus%2F1935705139429470405" target="_blank"&gt;宣佈這款「壓縮包」再次開售&lt;/a&gt;，並將於 9 月開始發貨。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1052" src="https://static.oschina.net/uploads/space/2025/0625/150540_IMgE_2720166.png" width="1300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="858" src="https://static.oschina.net/uploads/space/2025/0625/150922_XENV_2720166.png" width="1146" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是具體信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;價格&lt;/strong&gt; ：定價 150 美元，按現匯率約合 1077 元人民幣，相當於購買五份正版 WinRAR 軟件的費用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;設計&lt;/strong&gt; ：尺寸為 21.4×14×7 釐米，外形參考 WinRAR 的圖標設計，呈現出經典的粉、藍、綠三色書本被皮帶捆紮的設計，此次版本的肩帶改為可拆卸式，使用夾子固定，方便用户根據需要調整。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;購買方式及發貨時間&lt;/strong&gt; ：在 Tern 官網售賣，支持全球 DHL 郵寄，將於 2025 年 9 月發貨。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;購買地址：https://in.tern.et/products/winrar-archive-messenger-bag-prod&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357195/winrar-archive-messenger-bag</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357195/winrar-archive-messenger-bag</guid>
      <pubDate>Wed, 25 Jun 2025 07:11:40 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>投資 140 億卻成競爭對手，微軟遭遇 ChatGPT 企業市場</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;彭博社最新報道稱，微軟正面臨一個尷尬局面：儘管該公司努力向企業推銷 Copilot AI 助手，但越來越多的員工卻更青睞其合作伙伴 OpenAI 的 ChatGPT，這一現象正在企業市場引發激烈競爭。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;知名藥企安進公司的經歷完美詮釋了這一市場變化。去年春天，安進宣佈為旗下 2 萬名員工購買微軟 Copilot，成為微軟在生成式 AI 領域的重要客户案例。然而，僅僅 13 個月後，安進員工卻紛紛轉向使用 OpenAI 的 ChatGPT。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;安進高級副總裁肖恩·布魯伊希表示："OpenAI 成功的秘訣在於，他們把產品做得極具趣味性。"他指出，ChatGPT 在研究和科學文獻總結等任務中表現尤為出色，而 Copilot 更多是在配合微軟自家軟件使用時才顯現優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這種現象讓微軟與 OpenAI 之間的關係變得更加微妙。作為 OpenAI 的最大投資方，微軟已累計投資近 140 億美元，但現在卻發現自己在企業市場與被投資方直接競爭。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-4e4e30f181b826c01ebfb42865d828ee27e.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟銷售團隊反映，在推廣 Copilot 時經常措手不及，而公司又迫切希望快速擴大客户基礎。與此同時，OpenAI 也在積極擴張企業業務，近期更是收購了 AI 代碼助手 Windsurf，直接對標微軟的 GitHub Copilot。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管兩款產品都基於 OpenAI 的大語言模型，但用户體驗存在顯著差異。許多企業發現，員工普遍更偏愛 ChatGPT，主要原因包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;更新速度&lt;/strong&gt;：OpenAI 的模型更新在微軟軟件中往往延遲數週才能落地&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户熟悉度&lt;/strong&gt;：很多職場人士早已在個人場景中體驗過 ChatGPT&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;功能體驗&lt;/strong&gt;：ChatGPT 在某些專業任務中表現更優&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟解釋稱，延遲更新是因為需要進行企業級安全測試和用户體驗驗證。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;面對這一競爭態勢，不同企業採取了不同策略。紐約人壽保險公司決定在 12000 名員工中同時推廣 ChatGPT 和 Copilot，根據使用反饋決定最終選擇。金融科技公司 Finastra 選擇微軟 Copilot，看重其與微軟辦公軟件的深度整合優勢。貝恩諮詢公司則向 16000 名員工部署 ChatGPT，絕大多數員工日常使用，而僅有約 2000 名員工使用 Copilot 且主要搭配 Excel。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;OpenAI 表示已擁有 300 萬付費企業用户，短短几個月內增長 50%。微軟則回應稱 Copilot 已覆蓋 70% 的財富 500 強企業，付費用户數量比去年同期增加兩倍。在定價方面，微軟 Copilot 每用户每月 30 美元，相比 ChatGPT 企業版的 60 美元更具價格優勢，但 OpenAI 也推出了按使用量收費的靈活方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Gartner 分析師傑森·王認為，目前許多公司仍在小範圍測試階段，市場競爭格局尚未完全確定，但這無疑是"OpenAI 與微軟之間的正面對決"。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357193</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357193</guid>
      <pubDate>Wed, 25 Jun 2025 07:10:40 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>支付寶為 AI 開發者提供國內首個「AI 打賞」服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;支付寶宣佈為 AI 開發者提供國內首個「AI 打賞」服務，並首發上線螞蟻百寶箱平台、阿里雲百鍊，為開發者提供便捷收款能力，進一步推動 AI 技術的商業化應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;據介紹，「AI 打賞」服務旨在滿足 AI 智能體內收取讚賞、小費等需求，為開發者提供一種輕量化的收款解決方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;個人開發者只需登錄螞蟻百寶箱平台或阿里雲百鍊，選擇開通「AI 打賞」功能並給智能體掛載該服務，即可快速啓用打賞功能。開通後，用户打賞的金額將直接轉入開發者賬户。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="546" src="https://oscimg.oschina.net/oscnet/up-d77d6a355574699398813e0bde3af584ec9.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得一提的是，今年 4 月，支付寶曾推出國內首個支付 MCP，助力 AI 開發者具備支付收款能力，實現服務訂閲、付費解鎖等商業化功能。而此次推出的「AI 打賞」服務，則更側重於讓用户主動表達讚賞和感謝，兩者結合將形成基礎付費與靈活激勵並存的多元服務模式。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357178</guid>
      <pubDate>Sun, 11 May 2025 06:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 編輯器 Void 發佈 Beta，可作為 Cursor 開源替代方案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Void 是一款開源 AI 編輯器，可作為 Cursor 的替代品。Void&amp;nbsp;支持跟 Cursor 一樣的功能，比如 Tab 補全代碼，Ctrl + K 編輯選中內容，支持用 AI 搜索代碼庫，支持編輯和查看底層提示。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a9e2f51d6bea16cac1680764e79150155e1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvoideditor%2Fvoid%2Freleases%2Ftag%2Fbeta" target="_blank"&gt;Void 最近發佈了 Beta 版本&lt;/a&gt;，其作為 VS Code 的分支，旨在解決私有 AI 輔助編程工具的安全隱私和費用問題。閉源編輯器可能需要通過後端發送私有代碼數據，這會帶來隱私問題，另一個問題是持續的訂閲費用。&lt;/p&gt; 
&lt;p&gt;Void 提供了多種選項，確保開發者能控制自己的數據。它能利用多種大模型，可以使用任何本地的 LLM 驅動，也可以使用 Claude、GPT 或 Gemini 的 API，不會留存你的數據，避開了第三方中間人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357154/void-editor-beta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357154/void-editor-beta</guid>
      <pubDate>Sun, 11 May 2025 03:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ElevenLabs 發佈移動端 AI 語音工具 APP</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ElevenLabs 是一家專注於開發人工智能語音模型和工具的 AI 公司，近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felevenlabs.io%2Fblog%2Fintroducing-the-elevenlabs-app" target="_blank"&gt;宣佈&lt;/a&gt;推出官方 ElevenLabs 移動應用，為用户提供最強大的 AI 語音工具，支持 iOS 和 Android 用户隨時隨地將文本轉成語音片段。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e444a0db29602ba48998df1adbdf75133fd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，&lt;span&gt;ElevenLabs 的免費套餐為用户提供大約 10 分鐘的音頻生成時間。網頁版與移動版應用之間共享信用額度，用户可以根據自身需求選擇不同的模型，在成本與音質之間進行平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;應用還接入了 ElevenLabs 最新的 v3 alpha 文本轉語音模型，該模型允許用户通過標籤控制語音的情感表達。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bd8cefff977a3158c5aa87f0aa53985792.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/353936/eleven-v3-alpha" target="_blank"&gt;ElevenLabs 發佈文本轉語音模型 Eleven v3（Alpha 版）&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357151/elevenlabs-app</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357151/elevenlabs-app</guid>
      <pubDate>Sun, 11 May 2025 03:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>加州法院裁定使用版權內容訓練 AI 合規</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;美國加州北區地方法院&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.courtlistener.com%2Frecap%2Fgov.uscourts.cand.434709%2Fgov.uscourts.cand.434709.231.0_2.pdf" target="_blank"&gt;裁定&lt;/a&gt;&lt;span style="color:#000000"&gt;，Anthropic 公司在未經作者許可的情況下，使用已出版的書籍訓練其 AI 模型是合法的。這標誌着法院首次認可 AI 公司的説法，即合理使用原則可以免除 AI 公司在使用受版權保護的材料訓練大語言模型（LLM）時的過錯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="373" src="https://oscimg.oschina.net/oscnet/up-882fd79bf13f9f7781721a1a048d0fa9333.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據科技媒體 AppleInsider 的報道，許多創作者和藝術家長期以來都在為人工智能公司未經許可抓取其作品而苦惱。這些公司利用抓取的數據來訓練大型語言模型（LLM），並將其商業化，然而內容的原創者卻未能得到應有的補償。對此，Andrea Bartz、Charles Graeber 和 Kirk Wallace Johnson 於 2024 年向法院提起訴訟，指控 Anthropic 公司侵犯其版權，使用了盜版材料。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;法官 William Alsup 在裁決中支持了雙方的部分請求，但最終認為用於訓練特定大語言模型的副本屬於合理使用。這一裁定意味着 AI 公司在訓練其模型時可以合法使用受版權保護的內容，而這也讓眾多藝術家、音樂家和作家感到失望。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;對於這些創作者來説，這項決定可能會使他們面臨更大的商業風險，AI 模型的生成能力有可能進一步侵蝕他們的作品價值。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Alsup 法官&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;在判決書中明確表示:"我們將就 Anthropic 公司用於創建中央圖書館的盜版書籍及其造成的損失進行審理。Anthropic 公司後來購買了之前從網上盜取的書籍，這並不能免除其盜竊責任，但這可能會影響法定賠償的數額。"&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357149</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357149</guid>
      <pubDate>Sun, 11 May 2025 03:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Redis 是單線程模型？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;使用過 Redis 的同學肯定都瞭解過一個説法，説 Redis 是單線程模型，那麼實際情況是怎樣的呢？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;其實，我們常説 Redis 是單線程模型，&lt;strong&gt;是指 Redis 採用單線程的事件驅動模型，只有並且只會在一個主線程中執行 Redis 命令操作&lt;/strong&gt;，這意味着它在處理請求時不使用複雜的上下文切換或鎖機制。儘管只是單線程的架構，但 Redis 通過非阻塞的 I/O 操作和高效的事件循環來處理大量的併發連接，性能仍然非常高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;然而在 Redis4.0 開始也引入了一些後台線程執行異步淘汰、異步刪除過期 key、異步執行大 key 刪除等任務，然後，在 Redis6.0 中引入了多線程 IO 特性，將 Redis 單節點訪問請求從 10W 提升到 20W。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;而在去年 Valkey 社區發佈的 Valkey8.0 版本，在 I/O 線程系統上進行了重大升級，特別是異步 I/O 線程的引入，使主線程和 I/O 線程能夠並行工作，可實現最大化服務吞吐量並減少瓶頸，使得 Valkey 單節點訪問請求可以提升到 100W。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;那麼在 Redis6.0 和 Valkey8.0 中多線程 IO 是怎麼回事呢？是否改變了 Redis 原有單線程模型？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2024 年，Redis 商業支持公司 Redis Labs 宣佈 Redis 核心代碼的許可證從 BSD 變更為 RSALv2，明確禁止雲廠商提供 Redis 託管服務，這一決定直接導致社區分裂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為維護開源自由，Linux 基金會聯合多家科技公司（包括 AWS、Google、Cloud、Oracle 等）宣佈支持 Valkey，作為 Redis 的替代分支。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Valkey8.0 系 Valkey 社區發佈的首個主要大版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最新消息，在 Redis 項目創始人 antirez 今年加入 Redis 商業公司 5 個月後，Redis 宣傳從 Redis8 開始，Redis 項目重新開源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;本篇文章主要介紹 Redis6.0 多線程 IO 特性。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、Redis6.0 多線程 IO 概述&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;Redis6.0 引入多線程 IO，但多線程部分只是用來處理網絡數據的讀寫和協議解析，&lt;strong&gt;執行命令仍然是單線程。默認是不開啓的&lt;/strong&gt;，需要進程啓動前開啓配置，並且在運行期間無法通過&lt;strong&gt;&amp;nbsp;config set&amp;nbsp;&lt;/strong&gt;命令動態修改。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;參數與配置&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;多線程 IO 涉及下面兩個配置參數：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# io-threads 4 &amp;nbsp;IO 線程數量
# io-threads-do-reads no &amp;nbsp;讀數據及數據解析是否也用 IO 線程&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&amp;nbsp;io-threads&amp;nbsp;&lt;/strong&gt;表示 IO 線程數量，&lt;strong&gt;&amp;nbsp;io-threads&amp;nbsp;&lt;/strong&gt;設置為 1 時（代碼中默認值），表示只使用主線程，不開啓多線程 IO。因此，若要配置開啓多線程 IO，需要設置&lt;strong&gt;&amp;nbsp;io-threads&amp;nbsp;&lt;/strong&gt;大於 1，但不可以超過最大值 128。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;但在默認情況下，Redis 只將多線程 IO 用於向客户端寫數據，因為作者認為通常使用多線程執行讀數據的操作幫助不是很大。如果需要使用多線程用於讀數據和解析數據，則需要將參數&lt;strong&gt;&amp;nbsp;io-threads-do-reads&amp;nbsp;&lt;/strong&gt;設置為&lt;strong&gt;&amp;nbsp;yes&amp;nbsp;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此兩項配置&lt;strong&gt;參數在 Redis 運行期間無法通過&amp;nbsp;config set&amp;nbsp;命令修改，並且開啓 SSL 時，不支持多線程 IO 特性。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;若機器 CPU 將至少超過 4 核時，則建議開啓，並且至少保留一個備用 CPU 核，使用超過 8 個線程可能並不會有多少幫助。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;執行流程概述&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;Redis6.0 引入多線程 IO 後，讀寫數據執行流程如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/f1/f1751e15cbe5116df1883b0155195ec5.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;流程簡述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;主線程負責接收建立連接請求，獲取 socket 放入全局等待讀處理隊列。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程處理完讀事件之後，通過 RR（Round Robin）將這些連接分配給這些 IO 線程，也會分配給主線程自己。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程先讀取分配給自己的客户端數據，然後阻塞等待其他 IO 線程讀取 socket 完畢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IO 線程將請求數據讀取並解析完成（這裏只是讀數據和解析、並不執行）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程通過單線程的方式執行請求命令。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程通過 RR（Round Robin）將回寫客户端事件分配給這些 IO 線程，也會分配給主線程自己。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程同樣執行部分寫數據到客户端，然後阻塞等待 IO 線程將數據回寫 socket 完畢。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;設計特點&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;IO 線程要麼同時在讀 socket，要麼同時在寫，不會同時讀和寫。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IO 線程只負責讀寫 socket 解析命令，不負責命令執行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程也會參與數據的讀寫。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;三、源碼分析&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;多線程 IO 相關源代碼都在源文件 networking.c 中最下面。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;初始化&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;主線程在 main 函數中調用 InitServerLast 函數，InitServerLast 函數中調用&lt;strong&gt;initThreadedIO 函數&lt;/strong&gt;，在 initThreadedIO 函數中根據配置文件中的線程數量，創建對應數量的 IO 工作線程數量。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;/* Initialize the data structures needed for threaded I/O. */
void&amp;nbsp;initThreadedIO(void)&amp;nbsp;{
&amp;nbsp; &amp;nbsp; io_threads_active =&amp;nbsp;0;&amp;nbsp;/* We start with threads not active. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Don't spawn any thread if the user selected a single thread:
&amp;nbsp; &amp;nbsp; &amp;nbsp;* we'll handle I/O directly from the main thread. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(server.io_threads_num ==&amp;nbsp;1)&amp;nbsp;return;
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(server.io_threads_num &amp;gt; IO_THREADS_MAX_NUM) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;serverLog(LL_WARNING,"Fatal: too many I/O threads configured. "
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"The maximum number is %d.", IO_THREADS_MAX_NUM);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;exit(1);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Spawn and initialize the I/O threads. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;i =&amp;nbsp;0; i &amp;lt; server.io_threads_num; i++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Things we do for all the threads including the main thread. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads_list[i] =&amp;nbsp;listCreate();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(i ==&amp;nbsp;0)&amp;nbsp;continue;&amp;nbsp;/* Thread 0 is the main thread. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Things we do only for the additional threads. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_t&amp;nbsp;tid;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_init(&amp;amp;io_threads_mutex[i],NULL);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads_pending[i] =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_lock(&amp;amp;io_threads_mutex[i]);&amp;nbsp;/* Thread will be stopped. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pthread_create(&amp;amp;tid,NULL,IOThreadMain,(void*)(long)i) !=&amp;nbsp;0) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;serverLog(LL_WARNING,"Fatal: Can't initialize IO thread.");
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;exit(1);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads[i] = tid;
&amp;nbsp; &amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如果&lt;strong&gt;&amp;nbsp;io_threads_num&amp;nbsp;&lt;/strong&gt;的數量為 1，則只運行主線程，&lt;strong&gt;&amp;nbsp;io_threads_num&amp;nbsp;&lt;/strong&gt;的 IO 線程數量不允許超過 128。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;序號為 0 的線程是主線程，因此實際的工作線程數目是 io-threads - 1。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;初始化流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;為包括主線程在內的每個線程分配 list 列表，用於後續保存待處理的客户端。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;為主線程以外的其他 IO 線程初始化互斥對象 mutex，但是立即調用 pthread_mutex_lock 佔有互斥量，將 io_threads_pending[i]設置為 0，接着創建對應的 IO 工作線程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;佔用互斥量是為了創建 IO 工作線程後，可暫時等待後續啓動 IO 線程的工作，因為 IOThreadMain 函數在 io_threads_pending[id] == 0 時也調用了獲取 mutex，所以此時無法繼續向下運行，等待啓動。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 startThreadedIO 函數中會釋放 mutex 來啓動 IO 線程工作。何時調用 startThreadedIO 打開多線程 IO，具體見下文的「多線程 IO 動態暫停與開啓」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IO 線程主函數&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;IO 線程主函數代碼如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;void&amp;nbsp;*IOThreadMain(void&amp;nbsp;*myid)&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* The ID is the thread number (from 0 to server.iothreads_num-1), and is
&amp;nbsp; &amp;nbsp; &amp;nbsp;* used by the thread to just manipulate a single sub-array of clients. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;long&amp;nbsp;id = (unsigned&amp;nbsp;long)myid;
&amp;nbsp; &amp;nbsp;&amp;nbsp;char&amp;nbsp;thdname[16];
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;snprintf(thdname,&amp;nbsp;sizeof(thdname),&amp;nbsp;"io_thd_%ld", id);
&amp;nbsp; &amp;nbsp;&amp;nbsp;redis_set_thread_title(thdname);
&amp;nbsp; &amp;nbsp;&amp;nbsp;redisSetCpuAffinity(server.server_cpulist);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;while(1) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Wait for start */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;0; j &amp;lt;&amp;nbsp;1000000; j++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(io_threads_pending[id] !=&amp;nbsp;0)&amp;nbsp;break;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Give the main thread a chance to stop this thread. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(io_threads_pending[id] ==&amp;nbsp;0) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_lock(&amp;amp;io_threads_mutex[id]);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_unlock(&amp;amp;io_threads_mutex[id]);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;continue;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;serverAssert(io_threads_pending[id] !=&amp;nbsp;0);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("[%ld] %d to handle\n", id, (int)listLength(io_threads_list[id]));
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Process: note that the main thread will never touch our list
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* before we drop the pending count to 0. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; listIter li;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; listNode *ln;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(io_threads_list[id],&amp;amp;li);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(io_threads_op == IO_THREADS_OP_WRITE) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;writeToClient(c,0);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&amp;nbsp;else&amp;nbsp;if&amp;nbsp;(io_threads_op == IO_THREADS_OP_READ) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;readQueryFromClient(c-&amp;gt;conn);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;serverPanic("io_threads_op value is unknown");
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listEmpty(io_threads_list[id]);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads_pending[id] =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("[%ld] Done\n", id);
&amp;nbsp; &amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;從 IO 線程主函數邏輯可以看到：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如果 IO 線程等待處理任務數量為 0，則 IO 線程一直在空循環，因此後面主線程給 IO 線程分發任務後，需要設置 IO 線程待處理任務數&lt;strong&gt;&amp;nbsp;io_threads_pending[id]&amp;nbsp;&lt;/strong&gt;，才會觸發 IO 線程工作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 IO 線程等待處理任務數量為 0，並且未獲取到 mutex 鎖，則會等待獲取鎖，暫停運行，由於主線程在創建 IO 線程之前先獲取了鎖，因此 IO 線程剛啓動時是暫停運行狀態，需要等待主線程釋放鎖，啓動 IO 線程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IO 線程待處理任務數為 0 時，獲取到鎖並再次釋放鎖，是為了讓主線程可以暫停 IO 線程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;只有 io_threads_pending[id]不為 0 時，則繼續向下執行操作，根據 io_threads_op 決定是讀客户端還是寫客户端，從這裏也可以看出 IO 線程要麼&lt;strong&gt;同時讀&lt;/strong&gt;，要麼&lt;strong&gt;同時寫&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;讀數據流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;主線程將待讀數據客户端加入隊列&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;當客户端連接有讀事件時，會觸發調用 readQueryFromClient 函數，在該函數中會調用 postponeClientRead。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;void&amp;nbsp;readQueryFromClient(connection *conn) {
&amp;nbsp; &amp;nbsp; client *c = connGetPrivateData(conn);
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;nread, readlen;
&amp;nbsp; &amp;nbsp; size_t qblen;
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Check if we want to read from the client later when exiting from
&amp;nbsp; &amp;nbsp; &amp;nbsp;* the event loop. This is the case if threaded I/O is enabled. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(postponeClientRead(c))&amp;nbsp;return;
&amp;nbsp; &amp;nbsp; ......以下省略
}


/* Return 1 if we want to handle the client read later using threaded I/O.
&amp;nbsp;* This is called by the readable handler of the event loop.
&amp;nbsp;* As a side effect of calling this function the client is put in the
&amp;nbsp;* pending read clients and flagged as such. */
int&amp;nbsp;postponeClientRead(client *c) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(io_threads_active &amp;amp;&amp;amp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; server.io_threads_do_reads &amp;amp;&amp;amp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; !ProcessingEventsWhileBlocked &amp;amp;&amp;amp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; !(c-&amp;gt;flags &amp;amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags |=&amp;nbsp;CLIENT_PENDING_READ;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; listAddNodeHead(server.clients_pending_read,c);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;1;
&amp;nbsp; &amp;nbsp; }&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如果開啓多線程，並且開啓多線程讀（io_threads_do_reads 為 yes），則將客户端標記為 CLIENT_PENDING_READ，並且加入 clients_pending_read 列表。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;然後 readQueryFromClient 函數中就立即返回，主線程沒有執行從客户端連接中讀取的數據相關邏輯，讀取了客户端數據行為等待後續各個 IO 線程執行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;主線程分發並阻塞等待&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;主線程在 beforeSleep 函數中會調用 handleClientsWithPendingReadsUsingThreads 函數。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;/* When threaded I/O is also enabled for the reading + parsing side, the
&amp;nbsp;* readable handler will just put normal clients into a queue of clients to
&amp;nbsp;* process (instead of serving them synchronously). This function runs
&amp;nbsp;* the queue using the I/O threads, and process them in order to accumulate
&amp;nbsp;* the reads in the buffers, and also parse the first command available
&amp;nbsp;* rendering it in the client structures. */
int&amp;nbsp;handleClientsWithPendingReadsUsingThreads(void)&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!io_threads_active || !server.io_threads_do_reads)&amp;nbsp;return&amp;nbsp;0;
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;processed =&amp;nbsp;listLength(server.clients_pending_read);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(processed ==&amp;nbsp;0)&amp;nbsp;return&amp;nbsp;0;
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("%d TOTAL READ pending clients\n", processed);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Distribute the clients across N different lists. */
&amp;nbsp; &amp;nbsp; listIter li;
&amp;nbsp; &amp;nbsp; listNode *ln;
&amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(server.clients_pending_read,&amp;amp;li);
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;item_id =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;target_id = item_id % server.io_threads_num;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listAddNodeTail(io_threads_list[target_id],c);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; item_id++;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Give the start condition to the waiting threads, by setting the
&amp;nbsp; &amp;nbsp; &amp;nbsp;* start condition atomic var. */
&amp;nbsp; &amp;nbsp; io_threads_op = IO_THREADS_OP_READ;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;count =&amp;nbsp;listLength(io_threads_list[j]);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads_pending[j] = count;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Also use the main thread to process a slice of clients. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(io_threads_list[0],&amp;amp;li);
&amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;readQueryFromClient(c-&amp;gt;conn);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;listEmpty(io_threads_list[0]);
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Wait for all the other threads to end their work. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;while(1) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;unsigned&amp;nbsp;long&amp;nbsp;pending =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pending += io_threads_pending[j];
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pending ==&amp;nbsp;0)&amp;nbsp;break;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("I/O READ All threads finshed\n");
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Run the list of clients again to process the new buffers. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;while(listLength(server.clients_pending_read)) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ln =&amp;nbsp;listFirst(server.clients_pending_read);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags &amp;amp;= ~CLIENT_PENDING_READ;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listDelNode(server.clients_pending_read,ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(c-&amp;gt;flags &amp;amp; CLIENT_PENDING_COMMAND) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags &amp;amp;= ~CLIENT_PENDING_COMMAND;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(processCommandAndResetClient(c) == C_ERR) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* If the client is no longer valid, we avoid
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* processing the client later. So we just go
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* to the next. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;continue;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;processInputBuffer(c);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;processed;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;先檢查是否開啓多線程，以及是否開啓多線程讀數據（io_threads_do_reads），未開啓直接返回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;檢查隊列 clients_pending_read 長度，為 0 直接返回，説明沒有待讀事件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍歷 clients_pending_read 隊列，通過 RR 算法，將隊列中的客户端循環分配給各個 IO 線程，包括主線程本身。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;設置 io_threads_op = IO_THREADS_OP_READ，並且將 io_threads_pending 數組中各個位置值設置為對應各個 IO 線程分配到的客户端數量，如上面介紹，目的是為了使 IO 線程工作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程開始讀取客户端數據，因為主線程也分配了任務。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程阻塞等待，直到所有的 IO 線程都完成讀數據工作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程執行命令。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IO 線程讀數據&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 IO 線程主函數中，如果&lt;strong&gt;&amp;nbsp;io_threads_op == IO_THREADS_OP_READ&amp;nbsp;，&lt;/strong&gt;則調用 readQueryFromClient 從網絡中讀取數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;IO 線程讀取數據後，不會執行命令。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 readQueryFromClient 函數中，最後會執行 processInputBuffer 函數，在 processInputBuffe 函數中，如 IO 線程檢查到客户端設置了 CLIENT_PENDING_READ 標誌，則不執行命令，直接返回。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ......省略
/* If we are in the context of an I/O thread, we can't really
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* execute the command here. All we can do is to flag the client
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* as one that needs to process the command. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(c-&amp;gt;flags &amp;amp;&amp;nbsp;CLIENT_PENDING_READ) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags |=&amp;nbsp;CLIENT_PENDING_COMMAND;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;break;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ...... 省略&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;寫數據流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;命令處理完成後，依次調用：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;addReply--&amp;gt;prepareClientToWrite--&amp;gt;clientInstallWriteHandler，將待寫客户端加入隊列 clients_pending_write。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;void&amp;nbsp;clientInstallWriteHandler(client *c) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Schedule the client to write the output buffers to the socket only
&amp;nbsp; &amp;nbsp; &amp;nbsp;* if not already done and, for slaves, if the slave can actually receive
&amp;nbsp; &amp;nbsp; &amp;nbsp;* writes at this stage. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!(c-&amp;gt;flags &amp;amp;&amp;nbsp;CLIENT_PENDING_WRITE) &amp;amp;&amp;amp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; (c-&amp;gt;replstate ==&amp;nbsp;REPL_STATE_NONE&amp;nbsp;||
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;(c-&amp;gt;replstate ==&amp;nbsp;SLAVE_STATE_ONLINE&amp;nbsp;&amp;amp;&amp;amp; !c-&amp;gt;repl_put_online_on_ack)))
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Here instead of installing the write handler, we just flag the
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* client and put it into a list of clients that have something
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* to write to the socket. This way before re-entering the event
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* loop, we can try to directly write to the client sockets avoiding
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* a system call. We'll only really install the write handler if
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* we'll not be able to write the whole reply at once. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags |=&amp;nbsp;CLIENT_PENDING_WRITE;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listAddNodeHead(server.clients_pending_write,c);
&amp;nbsp; &amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 beforeSleep 函數中調用 handleClientsWithPendingWritesUsingThreads。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;int&amp;nbsp;handleClientsWithPendingWritesUsingThreads(void)&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;processed =&amp;nbsp;listLength(server.clients_pending_write);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(processed ==&amp;nbsp;0)&amp;nbsp;return&amp;nbsp;0;&amp;nbsp;/* Return ASAP if there are no clients. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* If I/O threads are disabled or we have few clients to serve, don't
&amp;nbsp; &amp;nbsp; &amp;nbsp;* use I/O threads, but thejboring synchronous code. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(server.io_threads_num ==&amp;nbsp;1&amp;nbsp;||&amp;nbsp;stopThreadedIOIfNeeded()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;handleClientsWithPendingWrites();
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Start threads if needed. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!io_threads_active)&amp;nbsp;startThreadedIO();
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("%d TOTAL WRITE pending clients\n", processed);
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Distribute the clients across N different lists. */
&amp;nbsp; &amp;nbsp; listIter li;
&amp;nbsp; &amp;nbsp; listNode *ln;
&amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(server.clients_pending_write,&amp;amp;li);
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;item_id =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; c-&amp;gt;flags &amp;amp;= ~CLIENT_PENDING_WRITE;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;target_id = item_id % server.io_threads_num;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;listAddNodeTail(io_threads_list[target_id],c);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; item_id++;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Give the start condition to the waiting threads, by setting the
&amp;nbsp; &amp;nbsp; &amp;nbsp;* start condition atomic var. */
&amp;nbsp; &amp;nbsp; io_threads_op = IO_THREADS_OP_WRITE;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;count =&amp;nbsp;listLength(io_threads_list[j]);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; io_threads_pending[j] = count;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Also use the main thread to process a slice of clients. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(io_threads_list[0],&amp;amp;li);
&amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;writeToClient(c,0);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;listEmpty(io_threads_list[0]);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Wait for all the other threads to end their work. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;while(1) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;unsigned&amp;nbsp;long&amp;nbsp;pending =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pending += io_threads_pending[j];
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pending ==&amp;nbsp;0)&amp;nbsp;break;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(tio_debug)&amp;nbsp;printf("I/O WRITE All threads finshed\n");
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Run the list of clients again to install the write handler where
&amp;nbsp; &amp;nbsp; &amp;nbsp;* needed. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;listRewind(server.clients_pending_write,&amp;amp;li);
&amp;nbsp; &amp;nbsp;&amp;nbsp;while((ln =&amp;nbsp;listNext(&amp;amp;li))) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; client *c =&amp;nbsp;listNodeValue(ln);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;/* Install the write handler if there are pending writes in some
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;* of the clients. */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(clientHasPendingReplies(c) &amp;amp;&amp;amp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;connSetWriteHandler(c-&amp;gt;conn, sendReplyToClient) == AE_ERR)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;freeClientAsync(c);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;listEmpty(server.clients_pending_write);
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;processed;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;判斷 clients_pending_write 隊列的長度，如果為 0 則直接返回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;判斷是否開啓了多線程，若只有很少的客户端需要寫，則不使用多線程 IO，直接在主線程完成寫操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果使用多線程 IO 來完成寫數據，則需要判斷是否先開啓多線程 IO（因為會動態開啓與暫停）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍歷 clients_pending_write 隊列，通過 RR 算法，循環將所有客户端分配給各個 IO 線程，包括主線程自身。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;設置 io_threads_op = IO_THREADS_OP_WRITE，並且將 io_threads_pending 數組中各個位置值設置為對應的各個 IO 線程分配到的客户端數量，目的是為了使 IO 線程工作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;主線程開始寫客户端數據，因為主線程也分配了任務，寫完清空任務隊列。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;阻塞等待，直到所有 IO 線程完成寫數據工作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;再次遍歷所有客户端，如果有需要，為客户端在事件循環上安裝寫句柄函數，等待事件回調。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;多線程 IO 動態暫停與開啓&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;從上面的寫數據的流程中可以看到，在 Redis 運行過程中多線程 IO 是會動態暫停與開啓的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在上面的寫數據流程中，先調用 stopThreadedIOIfNeeded 函數判斷是否需要暫停多線程 IO，&lt;strong&gt;當等待寫的客户端數量低於線程數的 2 倍時，會暫停多線程 IO，&lt;/strong&gt;否則就會打開多線程。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;int&amp;nbsp;stopThreadedIOIfNeeded(void)&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;pending = listLength(server.clients_pending_write);
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* Return ASAP if IO threads are disabled (single threaded mode). */
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(server.io_threads_num ==&amp;nbsp;1)&amp;nbsp;return&amp;nbsp;1;
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pending &amp;lt; (server.io_threads_num*2)) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(io_threads_active) stopThreadedIO();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;1;
&amp;nbsp; &amp;nbsp; }&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在寫數據流程 handleClientsWithPendingWritesUsingThreads 函數中，stopThreadedIOIfNeeded 返回 0 的話，就會執行下面的 startThreadedIO 函數，開啓多線程 IO。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;void&amp;nbsp;startThreadedIO(void) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;serverAssert(server.io_threads_active&amp;nbsp;==&amp;nbsp;0);
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_unlock(&amp;amp;io_threads_mutex[j]);
&amp;nbsp; &amp;nbsp; server.io_threads_active&amp;nbsp;=&amp;nbsp;1;
}


void&amp;nbsp;stopThreadedIO(void) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;/* We may have still clients with pending reads when this function
&amp;nbsp; &amp;nbsp; &amp;nbsp;* is called: handle them before stopping the threads. */
&amp;nbsp; &amp;nbsp;&amp;nbsp;handleClientsWithPendingReadsUsingThreads();
&amp;nbsp; &amp;nbsp;&amp;nbsp;serverAssert(server.io_threads_active&amp;nbsp;==&amp;nbsp;1);
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int j =&amp;nbsp;1; j &amp;lt; server.io_threads_num; j++)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;pthread_mutex_lock(&amp;amp;io_threads_mutex[j]);
&amp;nbsp; &amp;nbsp; server.io_threads_active&amp;nbsp;=&amp;nbsp;0;
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;從上面的代碼中可以看出：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;開啓多線程 IO 是通過釋放 mutex 鎖來讓 IO 線程開始執行讀數據或者寫數據動作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;暫停多線程 IO 則是通過加鎖來讓 IO 線程暫時不執行讀數據或者寫數據動作，此處加鎖後，IO 線程主函數由於無法獲取到鎖，因此會暫時阻塞。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;四、性能對比&lt;/h1&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;測試環境&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;兩台物理機配置：CentOS Linux release 7.3.1611(Core) ，12 核 CPU1.5GHz，256G 內存（free 128G）。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;Redis 版本&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;使用 Redis6.0.6，多線程 IO 模式使用線程數量為 4，即&lt;strong&gt;&amp;nbsp;io-threads 4&amp;nbsp;&lt;/strong&gt;，參數&lt;strong&gt;&amp;nbsp;io-threads-do-reads&amp;nbsp;&lt;/strong&gt;分別設置為&lt;strong&gt;&amp;nbsp;no&amp;nbsp;&lt;/strong&gt;和&lt;strong&gt;&amp;nbsp;yes&amp;nbsp;&lt;/strong&gt;，進行對比測試。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;壓測命令&lt;/span&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;redis-benchmark -h 172.xx.xx.xx -t set,get -n 1000000 -r 100000000 --threads ${threadsize} -d ${datasize} -c ${clientsize}


單線程 threadsize 為 1，多線程 threadsize 為 4
datasize 為 value 大小，分別設置為 128/512/1024
clientsize 為客户端數量，分別設置為 256/2000
如：./redis-benchmark -h 172.xx.xx.xx -t set,get -n 1000000 -r 100000000 --threads 4 -d 1024 -c 256&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_14"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;統計結果&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;當&lt;strong&gt;&amp;nbsp;io-threads-do-reads&amp;nbsp;&lt;/strong&gt;為&lt;strong&gt;&amp;nbsp;no&amp;nbsp;&lt;/strong&gt;時，統計圖表如下所示（c 2000 表示客户端數量為 2000）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://oscimg.oschina.net/oscnet/up-604470825e1668f75a0927b74d09cdd58e1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;當&lt;strong&gt;&amp;nbsp;io-threads-do-reads&amp;nbsp;&lt;/strong&gt;為&lt;strong&gt;&amp;nbsp;yes&amp;nbsp;&lt;/strong&gt;時，統計圖表如下所示（c 256 表示客户端數量為 256）。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="303" src="https://oscimg.oschina.net/oscnet/up-c53c725b46c9562ff0702a925aec3b10067.png" width="500" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_15"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;結論&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;使用 redis-benchmark 做 Redis6 單線程和多線程簡單 SET/GET 命令性能測試：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;從上面可以看到 GET/SET 命令在設置 4 個 IO 線程時，QPS 相比於大部分情況下的單線程，性能幾乎是翻倍了。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;連接數越多，多線程優勢越明顯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;value 值越小，多線程優勢越明顯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用多線程讀命令比寫命令優勢更加明顯，當 value 越大，寫命令越發沒有明顯的優勢。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;參數&lt;strong&gt;&amp;nbsp;io-threads-do-reads&amp;nbsp;&lt;/strong&gt;為 yes，性能有微弱的優勢，不是很明顯。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;總體來説，以上結果基本符合預期，結果僅作參考。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;五、6.0 多線程 IO 不足&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;儘管引入多線程 IO 大幅提升了 Redis 性能，但是 Redis6.0 的多線程 IO 仍然存在一些不足：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;CPU 核心利用率不足：當前主線程仍負責大部分的 IO 相關任務，並且當主線程處理客户端的命令時，IO 線程會空閒相當長的時間，同時值得注意的是，主線程在執行 IO 相關任務期間，性能受到最慢 IO 線程速度的限制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IO 線程執行的任務有限：目前，由於主線程同步等待 IO 線程，線程僅執行讀取解析和寫入操作。如果線程可以異步工作，我們可以將更多工作卸載到 IO 線程上，從而減少主線程的負載。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不支持帶有 TLS 的 IO 線程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;最新的 Valkey8.0 版本中，通過引入異步 IO 線程，將更多的工作轉移到 IO 線程執行，同時通過&lt;strong&gt;批量預讀取內存數據&lt;/strong&gt;減少內存訪問延遲，大幅提高 Valkey 單節點訪問 QPS，單個實例每秒可處理 100 萬個請求。我們後續再詳細介紹 Valkey8.0 異步 IO 特性。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_17"&gt;&lt;/span&gt; 
&lt;h1&gt;六、總結&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;Redis6.0 引入多線程 IO，但多線程部分只是用來處理網絡數據的讀寫和協議解析，&lt;strong&gt;執行命令仍然是單線程&lt;/strong&gt;。通過開啓多線程 IO，並設置合適的 CPU 數量，可以提升訪問請求一倍以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;Redis6.0 多線程 IO 仍然存在一些不足，沒有充分利用 CPU 核心，在最新的 Valkey8.0 版本中，引入異步 IO 將進一步大幅提升 Valkey 性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;1.&lt;/span&gt;得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;2.&lt;/span&gt;從 CPU 冒煙到絲滑體驗：算法 SRE 性能優化實戰全揭秘｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;3.&lt;/span&gt;CSS 闖關指南：從手寫地獄到「類」積木之旅｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;4.&lt;/span&gt;以細節詮釋專業，用成長定義價值——對話@孟同學 ｜得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;5.&lt;/span&gt;大語言模型的訓練後量化算法綜述 | 得物技術&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 竹徑&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;關注得物技術，每週更新技術乾貨&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18628004</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18628004</guid>
      <pubDate>Sun, 11 May 2025 03:15:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Firefox 140.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Firefox 140.0 現已發佈，具體更新內容如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新的&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;垂直標籤頁：現在可以同時顯示更多或更少的固定標籤頁，以便更快地訪問重要窗口。只需拖動分隔線即可調整固定標籤頁部分的大小。&lt;/p&gt; &lt;p&gt;&lt;img height="345" src="https://oscimg.oschina.net/oscnet/up-5d6fd6370e9987a3a0c35f64f0956842275.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;自定義搜索引擎：Firefox 現在支持添加更多搜索引擎。要添加自定義引擎，右鍵單擊受支持網站的搜索欄，然後選擇「添加搜索引擎」，或前往「設置」&amp;gt;「搜索」&amp;gt;「添加」（位於搜索快捷方式表格下方）手動輸入搜索 URL。&lt;/li&gt; 
 &lt;li&gt;Firefox 擴展程序：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fen-US%2Fkb%2Fcustomize-firefox-controls-buttons-and-toolbars" target="_blank"&gt;自定義工具欄&lt;/a&gt;，並可選擇移除擴展程序快捷方式，讓你更好地掌控瀏覽器。隱藏按鈕後，可以隨時通過點擊 Firefox 菜單中的「擴展程序」菜單項再次訪問擴展程序面板。&lt;/li&gt; 
 &lt;li&gt;現在可以通過右鍵單擊一個選項卡（或多個選定的選項卡）並選擇「Unload Tab」來卸載標籤頁。這可以減少 Firefox 的內存和 CPU 佔用，從而提高性能。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fwebsite-translation%23w_translate-the-full-page" target="_blank"&gt;整頁翻譯&lt;/a&gt;現在優先翻譯當前視圖附近的內容，從而提升速度和響應能力。除非滾動到視圖之外的內容，否則系統會跳過該內容，從而減少不必要的資源佔用。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fhow-do-i-use-firefox-spell-checker" target="_blank"&gt;阿拉伯語版本的 Firefox 現在為 Firefox 拼寫檢查器&lt;/a&gt;配備了內置阿拉伯語詞典。&lt;/li&gt; 
 &lt;li&gt;為意大利、波蘭和奧地利的用户啓用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Fautomatically-fill-your-address-web-forms" target="_blank"&gt;地址自動填充功能。&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong style="color:#333333"&gt;Fixed&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;各種&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fsecurity%2Fadvisories%2Fmfsa2025-51" target="_blank"&gt;安全&lt;/a&gt;修復。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Changed&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.mozilla.org%2Fmozilla%2Fbuilding-whats-next%2F" target="_blank"&gt;根據服務關閉公告&lt;/a&gt;，Pocket 工具欄圖標以及新標籤頁上的 Pocket 集成已被刪除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsupport.mozilla.org%2Fkb%2Ffirefox-enterprise-140-release-notes" target="_blank"&gt;可以在 Firefox for Enterprise 140 發行説明&lt;/a&gt;中找到有關策略更新和企業特定錯誤修復的信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Developer&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;改進了 Inspector 面板中的搜索功能，幫助開發者更有效地搜索當前頁面的 DOM。支持按匹配元素數量對結果進行排序、支持「偽」選擇器狀態等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Web 平台&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增加了對 Linux、macOS 和 Windows 中的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAccessibility%2FARIA%2FReference%2FAttributes%2Faria-keyshortcuts" target="_blank"&gt;aria-keyshortcuts&lt;/a&gt;平台支持。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FCookieStore" target="_blank"&gt;增加了對 CookieStore API&lt;/a&gt;&amp;nbsp;的支持，這是一種用於在 HTML 文檔和 service workers 中運行的腳本的異步 cookie API。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FCSS_Custom_Highlight_API" target="_blank"&gt;新增了對 Custom Highlight API&lt;/a&gt;&amp;nbsp;的支持，允許設置任意文本範圍的樣式。目前尚未包含對&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FCSS%2Ftext-decoration" target="_blank"&gt;文本裝飾&lt;/a&gt;的支持，計劃在即將發佈的版本中實現。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fdocs%2FWeb%2FAPI%2FElement%2Fpointerrawupdate_event" target="_blank"&gt;添加了對 pointerrawupdate&lt;/a&gt;&amp;nbsp;事件的支持。此事件在指針數據可用時立即觸發（通常在主&lt;code&gt;pointermove&lt;/code&gt;事件之前），從而提供對指針移動的低延遲訪問。與&lt;code&gt;pointermove&lt;/code&gt;不同，它會執行額外的命中測試來確定目標，並且觸發頻率更高，即使只添加了一個監聽器，也可能會影響性能。此事件適用於需要高精度輸入處理且無法僅使用&amp;nbsp;&lt;span style="color:#000000"&gt;coalesced&amp;nbsp;&lt;/span&gt;&lt;code&gt;pointermove&lt;/code&gt;事件實現流暢交互的應用程序。&lt;/li&gt; 
 &lt;li&gt;Service Worker 現已在隱私瀏覽模式下可用。&lt;/li&gt; 
 &lt;li&gt;Firefox 現在對&lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt;元素&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FHTML%2FReference%2FElements%2FHeading_Elements%23specifying_a_uniform_font_size_for_h1" target="_blank"&gt;應用統一的用户代理 (UA) 樣式&lt;/a&gt;，無論它們是在&lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt;、&lt;code&gt;&amp;lt;aside&amp;gt;&lt;/code&gt;、&lt;code&gt;&amp;lt;nav&amp;gt;&lt;/code&gt;還是&lt;code&gt;&amp;lt;section&amp;gt;&lt;/code&gt;內使用。&lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Firefox 現在將在序列化 HTML 屬性時轉義小於 (&lt;code&gt;&amp;lt;&lt;/code&gt;) 和大於 (&lt;code&gt;&amp;gt;&lt;/code&gt;) 符號，從而使針對網站的某些 mXSS 攻擊更加困難。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;未解決&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用某些深色主題的用户可能會遇到側邊欄文本對比度問題。一種解決方法是使用內置深色主題或系統主題。此問題已在&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1971487" target="_blank"&gt;Bug 1971487&lt;/a&gt;&lt;br&gt; 中記錄，並將在後續版本中修復。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更新説明：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mozilla.org%2Fen-US%2Ffirefox%2F140.0%2Freleasenotes%2F" target="_blank"&gt;https://www.mozilla.org/en-US/firefox/140.0/releasenotes/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357139/firefox-140-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357139/firefox-140-0-released</guid>
      <pubDate>Sun, 11 May 2025 02:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Ubuntu 默認主題的「回收站」應用圖標將更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ubuntu 貢獻者&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fubuntu%2Fyaru%2Fissues%2F1170" target="_blank"&gt;目前正在構思&lt;/a&gt;一個新的垃圾桶圖標，該圖標最早可能在 10 月份 Ubuntu 25.10 發佈時出現在 Dock 欄中。&lt;/p&gt; 
&lt;p&gt;關於 Ubuntu 垃圾桶圖標外觀的討論在 2019 年持續進行，直到同年 3 月結束。今年 5 月，該討論再次重啓，並定期更新圖標建議。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5b02880cb80a289c29cbfec182c0689f9b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;現有垃圾桶圖標的主要缺陷在於，沒有回收圖標，它看起來更像一個信箱，而不是一個垃圾桶。當垃圾桶裏有文件時，裏面的文件看起來相當整齊，就像信件一樣，這更讓人覺得它是一個郵箱，而不是垃圾桶。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cd86113e7df0a39fd3981f4d372b785a065.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;垃圾桶圖標位於左側 Dock 底部，看起來像一個信箱&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;目前建議的設計方案是頂部完全打開，以便更清楚地顯示它是一個垃圾桶；當裏面有文件時，會顯示皺巴巴的紙張。設計師 ochi12 發佈了多個圖標版本，並將它們設置為不同的尺寸，以測試在不同用例下的效果。最新版本的圖標在縮小尺寸後似乎依然能夠正常顯示。&lt;/p&gt; 
&lt;p&gt;目前，設計師仍在聽取其他貢獻者的反饋，因此，即使最終達成一致，目前做出的修改也不太可能最終在 Ubuntu 中實現。這一點也很重要，因為這些修改可能永遠不會被達成一致，我們也就可能永遠看不到它們真正實現。&lt;/p&gt; 
&lt;p&gt;值得注意的是，一些評論者表示他們喜歡現有的垃圾桶圖標，希望它不要改變，這體現了垃圾桶圖標本身的主觀性。希望我們能夠就設計達成共識，以便 Ubuntu 用户在升級到即將發佈的 Ubuntu 版本時能夠獲得更新鮮的體驗。&lt;/p&gt; 
&lt;p&gt;距離 10 月份 Ubuntu 25.10 發佈還有很長一段時間，所以我們到那時就可以看到新的圖標，但如果沒有，也許我們會在 Ubuntu 26.04 LTS 中看到它。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357137</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357137</guid>
      <pubDate>Sun, 11 May 2025 02:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Electron 37.0.0 發佈，跨平台桌面應用開發工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Electron 是一個使用 JavaScript、HTML 和 CSS 構建跨平台的桌面應用程序。它基於 Node.js 和 Chromium，被 Atom 編輯器和許多其他應用程序使用。Electron 兼容 Mac、Windows 和 Linux，可以構建出三個平台的應用程序。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Electron v37.0.0 現已發佈，一些更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;Stack Upgrades&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chromium&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;138.0.7204.35&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.chrome.com%2Fblog%2Fnew-in-chrome-138%2F" target="_blank"&gt;New in 138&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.chrome.com%2Fblog%2Fnew-in-chrome-137%2F" target="_blank"&gt;New in 137&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Node&lt;code&gt;22.16.0&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnodejs.org%2Fen%2Fblog%2Frelease%2Fv22.16.0%2F" target="_blank"&gt;Node 22.16.0 blog post&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;V8&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;13.8&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Breaking Changes&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增加了對 Web Serial &amp;amp; WebUSB blocklists 的支持。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F46600" target="_blank"&gt;#46600&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復了實用程序進程因未處理的拒絕而崩潰的問題。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F45921" target="_blank"&gt;#45921&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復了在調用 process.exit 後運行用户腳本的 utilityProcess 問題。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F47492" target="_blank"&gt;#47492&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;刪除了通過將&lt;code&gt;ProtocolResponse.session&lt;/code&gt;的屬性設置為&lt;code&gt;null&lt;/code&gt;來創建新隨機會話的棄用功能。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F46264" target="_blank"&gt;#46264&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;改進&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;改進了 Windows 上的 ASAR 完整性檢查。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F46509" target="_blank"&gt;#46509&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;改進了 macOS 上不請求縮略圖時 deskCapturer.getSources 的性能。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F46138" target="_blank"&gt;#46138&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;已移除/棄用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;棄用&lt;code&gt;NativeImage.getBitmap()&lt;/code&gt;並修復了不正確的文檔。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Fpull%2F46696" target="_blank"&gt;#46696&amp;nbsp;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;34.xy 支持終止&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.electronjs.org%2Fdocs%2Flatest%2Ftutorial%2Felectron-timelines%23version-support-policy" target="_blank"&gt;根據項目支持政策&lt;/a&gt;， Electron 34.xy 已終止支持。鼓勵開發者和應用程序升級到較新版本的 Electron。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;更多詳情可查看更新説明：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Felectron%2Felectron%2Freleases%2Ftag%2Fv37.0.0" target="_blank"&gt;https://github.com/electron/electron/releases/tag/v37.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357136/electron-37-0-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357136/electron-37-0-0-released</guid>
      <pubDate>Sun, 11 May 2025 02:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 AI 助手平台 Cherry Studio 企業版開啓公測</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cherry Studio &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FFHtJqZlULDhRw7fT1ALagA" target="_blank"&gt;宣佈&lt;/a&gt;其企業版已開始公測，這是專為企業打造的私有化 AI 生產力平台。&lt;/p&gt; 
&lt;p style="color:#1f2329; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#1f2329"&gt;&lt;span&gt;下表展示了兩個版本之間的定位與功能差異：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-color:#dee0e3; box-sizing:border-box !important; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:15px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:626px !important; min-width:297px; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:626px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對比維度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;社區版 （Community）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;企業版 （Enterprise）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;目標用户&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;個人開發者、AI 愛好者&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中小型企業、大型企業內部團隊、對數據安全有高要求的組織&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;開源策略&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;✅ Github 開源&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;⭕️ 針對夥伴客户端源碼開放&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;商業模式&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;個人免費 / 商用授權&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;買斷+可選服務費&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;核心差異&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;專注於個人生產力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;企業集中管理能力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;部署方式&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;客户端應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;客户端 + 服務端私有化部署&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;核心價值&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;強大的個人 AI 輔助工具&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#cccccc; border-style:solid; border-width:1px; white-space:normal"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;安全、可控、高效的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cherry-ai.com%2Fenterprise" target="_blank"&gt;https://www.cherry-ai.com/enterprise&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;點擊查看企業版體驗手冊：&lt;/p&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;https://doc.weixin.qq.com/doc/w3_ASIAPQaBALgCNdQv1pcxUTJGhXLsX?scode=APkA7AeJABIVWchL1vASIAPQaBALg&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;Cherry Studio 是一款支持多個大語言模型（LLM）服務商的開源桌面客户端，兼容 Windows、Mac 和 Linux 系統。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-23dab8c50bfcc8126ab84229b00dbc2115c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357134</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357134</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 正在為 Grok 開發高級文件編輯器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;工程師 Nima Owji 在 X 平台&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fnima_owji%2Fstatus%2F1937146584493375900" target="_blank"&gt;發文稱&lt;/a&gt;&lt;/u&gt;，馬斯克旗下 xAI 公司正為 Grok 開發一款支持表格的高級文件編輯器。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1826" src="https://static.oschina.net/uploads/space/2025/0624/194050_x6IF_2720166.png" width="1940" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;科技媒體 TechCrunch&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F06%2F23%2Fleak-reveals-grok-might-soon-edit-your-spreadsheets%2F" target="_blank"&gt; &lt;u&gt;認為&lt;/u&gt;&lt;/a&gt;&amp;nbsp;xAI 此舉表明他們正採取措施，通過在生產力工具中整合 AI 輔助功能，與 OpenAI、谷歌和微軟等巨頭展開競爭。OpenAI 和微軟已擁有類似工具，最為相似的是 Gemini Workspace for Sheets、Docs 和 Gmail，可以編輯文檔和表格，並支持用户在查看或編輯文檔時與 Gemini 對話。&lt;/p&gt; 
&lt;p&gt;目前尚不清楚 xAI 的編輯器除了表格之外還可能支持哪些類型的文件，也不清楚 xAI 是否計劃構建一個完整的生產力套件，以與谷歌 Workspace 和微軟 Microsoft 365 競爭。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357076/leak-reveals-grok-might-soon-edit-your-spreadsheets</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357076/leak-reveals-grok-might-soon-edit-your-spreadsheets</guid>
      <pubDate>Sat, 10 May 2025 11:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>為什麼所有瀏覽器的的 User-Agent 字符串開頭都是</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;你有沒有注意過，幾乎所有瀏覽器的 User-Agent 字符串開頭都是「Mozilla/」？&lt;/p&gt; 
&lt;p&gt;無論是 Chrome、Safari、還是 IE、Edge，都有「Mozilla」的痕跡。其實，這一切都源自一場「瀏覽器偽裝」的歷史鬧劇。&lt;/p&gt; 
&lt;p&gt;這事得從 90 年代説起，那時互聯網剛起步，第一個流行瀏覽器叫 Mosaic。後來，有人造出一款更強的瀏覽器，號稱「Mosaic Killer」，代號 Mozilla。&lt;/p&gt; 
&lt;p&gt;它上線後，不光能看圖還能加載網頁框架（frames），可謂是當年超前的黑科技。&lt;/p&gt; 
&lt;p&gt;很多網站為了兼容，只願給「Mozilla」發完整版頁面，其他瀏覽器只能看閹割版。&lt;/p&gt; 
&lt;p&gt;這就引發了一個問題：網站開始「嗅探」瀏覽器身份，也就是所謂的 User-Agent 識別。&lt;/p&gt; 
&lt;p&gt;後來，微軟做了 Internet Explorer（IE），本來想正大光明競爭，但一看：網站只對 Mozilla 好，乾脆就讓自己也偽裝成 Mozilla。&lt;/p&gt; 
&lt;p&gt;於是 IE 的 User-Agent 字符串成了這樣：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Mozilla/1.22 (compatible; MSIE 2.0; Windows 95)&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;就這樣，IE 成功騙過了網站，用户數也提升了。&lt;/p&gt; 
&lt;p&gt;而這場「偽裝遊戲」一旦開始，就收不住了。&lt;/p&gt; 
&lt;p&gt;1、Firefox 自己引以為傲的 Gecko 渲染引擎，也以 Mozilla 自稱：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Mozilla/5.0 (...) Gecko/... Firefox/...&lt;/code&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;2、Linux 社區做的瀏覽器，用的是 KHTML 引擎，他們開始模仿 Gecko 寫法：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Mozilla/5.0 (...) (KHTML, like Gecko)&lt;/code&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;3、蘋果搞了 Safari，用的是 WebKit，而 WebKit 是 KHTML 的一個分支：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Mozilla/5.0 (...) AppleWebKit/... (KHTML, like Gecko) Safari/...&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;4、到了谷歌 Chrome 時代，它用的也是 WebKit，為了吃到 Safari 的待遇，其 User-Agent 變成了這種奇葩組合：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Mozilla/5.0 (...) AppleWebKit/... (KHTML, like Gecko) Chrome/... Safari/...&lt;/code&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;到這時，每個瀏覽器都在 User-Agent 裏堆滿了「族譜」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Chrome 假裝是 Safari&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Safari 假裝是 KHTML&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;KHTML 假裝是 Gecko&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gecko 假裝是 Mozilla&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;而真正的 Mozilla，其實早就不在了。&lt;/p&gt; 
&lt;p&gt;最後結果就是：User-Agent 成了一串「你是誰並不重要，重要的是你要説自己是 Mozilla」的魔性自報家門。&lt;/p&gt; 
&lt;p&gt;也難怪現在的前端開發者一邊調試一邊吐槽：「我到底在給誰寫頁面啊？」&lt;/p&gt; 
&lt;p&gt;感興趣的小夥伴可以點擊原文：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwebaim.org%2Fblog%2Fuser-agent-string-history%2F" target="_blank"&gt;https://webaim.org/blog/user-agent-string-history/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357071/user-agent-string-history</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357071/user-agent-string-history</guid>
      <pubDate>Sat, 10 May 2025 11:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>【直播預告】三步上手鴻蒙開發：工具・能力・進階</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依託「一次開發、多端部署」的核心理念，HarmonyOS 的分佈式能力正在革新萬物互聯時代的應用開發範式——從智能家居到移動辦公，開發者可高效實現跨終端無縫協同。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;然而，許多開發者仍面臨以下問題：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對鴻蒙核心開放能力（如元服務、分佈式技術、AI 能力）缺乏系統認知；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對鴻蒙專屬開發工具（ArkUI、DevEco Studio）的操作不熟悉；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;缺少從入門到進階的完整學習路徑，難以快速上手實戰開發。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為此，7 月 8 日晚，開源中國 OSCHINA 《數智漫談》直播欄目聚焦「工具 · 能力 · 進階」三大模塊，邀請三位鴻蒙生態專家，通過場景化演示與案例拆解，幫助開發者高效掌握鴻蒙應用開發的核心技能，抓住萬物互聯時代的創新機遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;三步上手鴻蒙開發：工具 · 能力 · 進階&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;平台：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;視頻號「OSC 開源社區」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;時間：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;7 月 8 日（週二） 19:00-20:40&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;img height="495" src="https://oscimg.oschina.net/oscnet/up-0cec6a2cf81222917368850d2b811addc01.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;🔥 直播核心看點搶先揭秘：&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 1：解鎖鴻蒙核心能力，打造跨端智能應用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;鴻蒙操作系統以「分佈式架構」為核心，打破設備邊界，實現跨終端無縫協同與算力共享，通過元服務、多端統一開發、AI 等能力，重塑萬物互聯場景體驗。本次演講將解讀其技術革新內核，並探討在各領域的應用實踐，揭示鴻蒙如何為生態融合與數字化轉型提供新範式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 2：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;DevEco Studio：從零到一搭建鴻蒙應用&lt;/strong&gt;&lt;br&gt; &amp;nbsp;本演講以開發者視角系統性解析鴻蒙應用開發全流程：從 DevEco Studio 環境配置與真機調試技巧，到 ArkUI 聲明式開發範式的核心實踐（狀態管理、組件化開發），並結合跨設備聯調、卡片服務等典型場景，直擊多端適配與調試中的高頻問題，提供華為 HDE 總結的實戰解決方案，助力開發者快速構建高質量鴻蒙應用。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;分享主題 3：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;從學習到實戰：鴻蒙開發者成長指南&lt;/strong&gt;&lt;br&gt; 聚焦鴻蒙開發者從入門到精進的成長路徑，解析如何通過高效學習框架與實戰經驗，掌握分佈式開發、多端協同等核心技術，跨越「單一設備」到「場景化創新」的鴻溝。內容涵蓋開發工具鏈使用、典型場景案例拆解及生態機遇洞察，助力開發者在萬物互聯時代搶佔技術先機，實現從技能提升到價值落地的閉環。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;👨‍💻 重磅嘉賓陣容：&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;姚聖偉，&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;華為雲 HCDE、鴻蒙應用認證開發者、微軟 Insider Dev Tour China、.Net Conf China 講師、中科院開源之夏優秀導師、昇騰 CANN 訓練營優秀開發者、騰訊騰源會開源摘星 100 人，天津敏捷社區核心組織者，中國 DevOps 社區理事會成員。現從事信創、電子政務、人工智能、雲開發平台等領域的設計、研發工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;張一弛，&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;華為開發者專家（HDE）、湖南長沙虛擬盒子鴻蒙架構師、鴻蒙兔習慣 APP 作者、歡友社交應用，出境元服務架構師。多年移動端開發經驗，專注於 IM 領域，目前主要從事鴻蒙元服務相關工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;祝欣蓉，&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;上海杉達學院副教授，華為開發者專家（HDE），HarmonyOS 應用開發高級工程師、華為路由交換高級網絡工程師、華為大數據高級工程師、華為 HDG 上海核心組成員，曾擔任丹陽市委網信辦網絡安全顧問，主要研究方向：鴻蒙移動應用開發，OpenHarmony 軟硬協同開發，企業級項目開發，曾主持橫向課題 1 項，教育部產學合作協同育人項目 2 項，市級重點課程建設 1 門，校級重點課題 4 項，出版教材 3 本。曾任教課程：鴻蒙移動應用開發，HarmonyOS 軟硬協同創新實踐，Java Web 開發技術，數據挖掘技術與應用，組網技術，園區網絡安全技術等課程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🚀 立即行動，開啓你的鴻蒙開發進階之旅！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;📅 直播時間：2025 年 7 月 8 日 (週二) 19:00 - 20:40&lt;/strong&gt;&lt;br&gt; &lt;strong&gt;📍 直播平台：視頻號搜索【OSC 開源社區】&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;👉 現在預約直播，開播不錯過！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;img height="660" src="https://oscimg.oschina.net/oscnet/up-a2420114f6a13a893712842053fb7fce6ef.jpg" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;《數智漫談》直播欄目介紹&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《數智漫談》是開源中國推出的一檔直播欄目，每月 1 期，已推出 22 期。以「深度對話、多元視角、前沿洞察」為核心理念，聚焦 IT 技術、開源治理、行業趨勢與創新實踐，通過輕鬆互動形式搭建開源領域的思想交流平台。區別於傳統技術直播的單向輸出，突出「圍坐暢聊」的互動感和思想交鋒的張力，打造開源領域的「圓桌派」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;有興趣的朋友，可以聯繫我~&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0.0001pt; margin-right:0px; text-align:justify"&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18635616</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18635616</guid>
      <pubDate>Sat, 10 May 2025 10:32:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>雲原生週刊：Argo CD v3.1 正式發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;開源項目推薦&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubewall%2Fkubewall" target="_blank"&gt;Kubewall&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Kubewall 是一個輕量級的開源 Kubernetes 儀表盤，支持多集羣管理，主打單二進制部署和瀏覽器訪問，提供實時資源監控、YAML 編輯、拓撲視圖、日誌查看等功能。它使用 Go 與 React 構建，支持通過 Docker、Helm、Homebrew 等多種方式安裝，適合追求簡潔、高效、多環境統一管理體驗的開發者與運維人員。項目活躍迭代，是 Lens、Headlamp 等重量級工具的輕量替代方案。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkapicorp%2Fkapitan" target="_blank"&gt;Kapitan&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Kapitan 是 Kapicorp 開發的一個開源、以 Python 為基礎，的高級配置管理工具，通過，層級化 inventory（YAML）驅動、多種模板引擎（如 Jinja、Jsonnet、Helm、Kadet）和原生秘密管理，幫助用户生成 Kubernetes、Terraform、腳本、文檔等多環境、一致且可追蹤的配置，適合平台工程／GitOps 流程，且項目活躍、使用 Apache 2.0 許可。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgefyrahq%2Fgefyra" target="_blank"&gt;Gefyra&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Gefyra 是一個開源工具，旨在將本地開發環境無縫連接到 Kubernetes 集羣中，實現代碼熱更新和快速迭代。它通過創建加密網絡橋接（基於 WireGuard）、代理流量並複用集羣資源，讓開發者無需每次更改都執行構建、推送和部署流程。支持 Docker、macOS、Windows 和 Linux，可通過命令行或 GUI 操作，廣泛適用於微服務、本地調試、端到端測試等場景，極大提升了雲原生開發效率。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkube-burner%2Fkube-burner" target="_blank"&gt;Kube-burner&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Kube‑burner 是一個用 Go 語言開發的開源 Kubernetes 性能與擴展測試編排框架，它可以按用户定義大規模創建、刪除、更新 Kubernetes 資源，同時集成 Prometheus 度量、索引、告警功能，用於評估集羣的性能瓶頸和擴展極限。&lt;/p&gt; 
&lt;h2&gt;文章推薦&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloudnativenow.com%2Fcontributed-content%2Fadvanced-devops-for-ai-continuous-delivery-of-models-using-jenkins-and-docker%2F" target="_blank"&gt;基於 Jenkins 與 Docker 的 AI 模型持續交付實戰：構建高效 MLOps 流程&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;本文介紹瞭如何通過結合 Jenkins 和 Docker 實現 AI 模型的高級 DevOps（開發運維）流程，重點在於模型的持續交付（CD）。作者詳細講解了從模型訓練、容器化、測試、部署到上線的自動化流程，展示瞭如何構建一個高效、可重複的 MLOps（機器學習運維）管道。通過這種方式，團隊可以更快速、穩定地將 AI 模型部署到生產環境中，加速從開發到業務落地的過程。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fblog%2F2025%2F06%2F09%2Fgitops-in-2025-from-old-school-updates-to-the-modern-way%2F%3Fsessionid%3D-1595116295" target="_blank"&gt;GitOps 2025：從傳統部署到自動化運維新時代&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;在 2025 年，GitOps 已從一種新興理念發展為管理現代應用程序的基礎標準，特別是在 Kubernetes 環境中。它通過將 Git 作為系統配置的唯一真實來源，結合自動化代理持續應用這些配置，實現了自動化、一致性和可追溯性，從而簡化了雲原生軟件運維的複雜性。GitOps 的核心原則包括聲明式配置、Git 作為唯一配置來源、通過 Pull/Merge 請求進行更改以及由代理持續進行環境同步。主要工具如 Argo CD 和 Flux CD 已成為主流選擇，分別適用於需要強大 UI 和模塊化靈活性的場景。&lt;/p&gt; 
&lt;p&gt;儘管 GitOps 的採用帶來了諸多優勢，如更快的發佈、更安全的操作和更容易的回滾，但也面臨着學習曲線陡峭、工具碎片化和文化轉變等挑戰。總體而言，GitOps 正在成為 DevOps 實踐的關鍵組成部分，推動軟件交付的自動化和可靠性。&lt;/p&gt; 
&lt;h2&gt;雲原生動態&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubeedge%2Fkubeedge%2Fblob%2Fmaster%2FCHANGELOG%2FCHANGELOG-1.21.md" target="_blank"&gt;KubeEdge 1.21 版本發佈&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;KubeEdge 1.21 版本的更新日誌展示了多個關鍵改進，包括雲端和邊緣組件的功能增強、系統穩定性優化以及 bug 修復。此版本引入了更靈活的 CRI 支持、增強的 EdgeMesh 服務治理能力和更完善的安全機制，同時提升了 DevOps 體驗和兼容性。整體來看，1.21 版本進一步強化了邊緣計算場景下的可擴展性與可靠性。&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.argoproj.io%2Fannouncing-argo-cd-v3-1-f4389bc783c8" target="_blank"&gt;Argo CD v3.1 正式發佈&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;繼 v3.0「輕量但強大」的發佈奠定基礎後，Argo CD v3.1 帶來了 v3 系列的首批重大更新。新版本支持 OCI 鏡像作為應用源，引入 CLI 插件機制、Hydrator 架構更新，以及 UI 的多項可用性提升。除了新功能，v3.1 還修復了大量安全漏洞與已知問題，顯著提升了系統穩定性、擴展性和多集羣支持能力。通過更快的同步性能、更細粒度的權限控制和增強的 SSO 機制，Argo CD v3.1 為 DevOps 團隊打造了更高效、安全、可持續的 Kubernetes 應用交付體驗。&lt;/p&gt; 
&lt;h3&gt;關於 KubeSphere&lt;/h3&gt; 
&lt;p&gt;KubeSphere （&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%EF%BC%89%E6%98%AF%E5%9C%A8" target="_blank"&gt;https://kubesphere.io）是在&lt;/a&gt; Kubernetes 之上構建的開源容器平台，提供全棧的 IT 自動化運維的能力，簡化企業的 DevOps 工作流。&lt;/p&gt; 
&lt;p&gt;KubeSphere 已被 Aqara 智能家居、本來生活、東方通信、微宏科技、東軟、華雲、新浪、三一重工、華夏銀行、四川航空、國藥集團、微眾銀行、紫金保險、去哪兒網、中通、中國人民銀行、中國銀行、中國人保壽險、中國太平保險、中國移動、中國聯通、中國電信、天翼雲、中移金科、Radore、ZaloPay 等海內外數萬家企業採用。KubeSphere 提供了開發者友好的嚮導式操作界面和豐富的企業級功能，包括 Kubernetes 多雲與多集羣管理、DevOps (CI/CD)、應用生命週期管理、邊緣計算、微服務治理 (Service Mesh)、多租户管理、可觀測性、存儲與網絡管理、GPU support 等功能，幫助企業快速構建一個強大和功能豐富的容器雲平台。 &amp;gt; 本文由博客一文多發平台 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom" target="_blank"&gt;OpenWrite&lt;/a&gt; 發佈！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4197945/blog/18635610</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/18635610</guid>
      <pubDate>Sat, 10 May 2025 10:19:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>「開源惠全球·集智創未來」——2025 全球數字經濟大會全球開源創新發展論壇即將召開</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0624/175355_3VoR_2720166.png" width="1279" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開源是數字時代以開放、共建、共享、共治為主要特徵的新型生產方式，已經成為全球信息技術產業發展的重要協作方式和生態構建形式。為搶抓開源繁榮發展機遇，促進全球數字協作，助力北京市數字友好城市建設，全球開源創新發展論壇（以下簡稱「論壇」）將於 7 月 5 日上午在北京國家會議中心舉行。論壇由全球數字經濟大會組委會主辦，國家工業信息安全發展研究中心、開源中國、CNCF 基金會、國際內源基金會聯合承辦。&lt;/p&gt; 
&lt;p&gt;本次論壇以「開源惠全球·集智創未來」為主題，旨在搭建國際開源交流合作平台，廣泛邀請國內外開源領域知名專家學者，頂尖開源組織、先鋒開源企業、開源社區代表等齊聚一堂，聚焦全球開源技術的最新發展趨勢，探討優質開源社區培育路徑，共商開源區域協作，推動形成開源發展合力，充分釋放數字經濟的放大、疊加、倍增效應，助力全球數字經濟高質量發展。本次論壇有以下亮點：&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#d35400"&gt;&lt;strong&gt;&lt;strong&gt;亮點一：全球協作，國際開源創新聚合力&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;論壇邀請開源中國、CNCF 基金會、國際內源基金會等國內外知名開源組織聯合承辦，廣泛匯聚 Apache 基金會、Linux 基金會、FOSSASIA（亞洲開源）、華為、平凱星辰、螞蟻等開源機構，重磅嘉賓雲集，共同推動國內外開源組織、社區加強互動合作、共享技術成果，共築全球開源發展未來。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#d35400"&gt;&lt;strong&gt;&lt;strong&gt;亮點二：開源全景，多元視角匯聚發展之聲&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;論壇以「全球視野、本土創新」雙輪驅動，邀請國內外開源代表圍繞 AI 驅動下的開源生態建設、全球開源社區文化與發展前沿動態、全球開源明星項目中的「中國聲音」等領域進行主題演講，分享開源託管平台、開源基金會、國際開源協作、AI 智能體開源、OSPO 等方面的前沿視角與經驗，確保內容專業性高、權威性強。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#d35400"&gt;&lt;strong&gt;&lt;strong&gt;亮點三：緊扣前沿，重磅發佈 AI 開源北京宣言&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;論壇緊跟行業前沿趨勢，搶抓新一代人工智能發展機遇，深入探索大模型時代開源發展路徑。期間，中心將聯合 Linux 基金會、CNCF 基金會、Apache 基金會、國際內源基金會等國際組織，以及華為、開源中國等國內企業，聯合發起「人工智能開源協作倡議—北京宣言」，展現 AI 力量，攜手推動開源 AI 普惠發展。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#d35400"&gt;&lt;strong&gt;&lt;strong&gt;亮點四：前瞻佈局，首次發佈開源項目白名單&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;論壇將首次發佈「中國優秀開源項目白名單」，該名單由十餘家「產學研用金」單位聯合構建開源項目成長潛力分析預測模型，研究提出開源項目發展評價指標體系，形成優秀開源項目白名單，指導和促進開源項目健康發展，併為其他項目提供可借鑑範例，進一步推動開源生態繁榮發展。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;論壇議程大致如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="772" src="https://static.oschina.net/uploads/space/2025/0624/175503_n4LF_2720166.png" width="720" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2025 全球數字經濟大會—全球開源創新發展論壇即將啓幕，論壇內容豐富、形式多樣，歡迎掃描以下二維碼報名參會。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0624/175514_O8qv_2720166.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（報名方式：掃描上方二維碼，完成個人信息註冊後，下滑參會日程，選擇&lt;strong&gt;&lt;strong&gt;7 月 5 日上午「全球開源創新發展論壇」&lt;/strong&gt;&lt;/strong&gt;，點擊申請報名，您將收到【收到報名】短信通知，請等待審核。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357056</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357056</guid>
      <pubDate>Sat, 10 May 2025 09:56:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>開源圖像編輯器 GIMP 3.1.2 發佈，邁向 GIMP 3.2 的首個開發版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;GIMP 項目團隊發佈了 GIMP 3.1.2，這是開源、免費、跨平台的圖像編輯軟件 GIMP 3.2 的首個開發版本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c418681e24ceaa99f194182462ec584f18b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是該版本的一些主要更新內容：&lt;/p&gt; 
&lt;h3&gt;界面優化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;個性化選項擴展&lt;/strong&gt; ：用户可根據自身喜好設置畫筆、字體和調色板的主題顏色。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;文本工具增強&lt;/strong&gt; ：新增控制文本輪廓方向的功能，並自動匹配 Linux 和 Windows 系統主題，提升視覺一致性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;其他細節優化&lt;/strong&gt; ：如改進了前景選擇算法，增加了 「合併濾鏡」 複選框，以及對 Palette 可停靠窗口的優化，在刪除前一個色塊後自動選擇下一個色塊，還支持 「鎖定像素」 功能，以便在撤銷歷史中生成撤銷步驟。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;繪畫模式更新&lt;/h3&gt; 
&lt;p&gt;新增了 Overwrite 繪畫混合模式，允許用户直接替換畫筆覆蓋區域的像素，提升了繪製時的操作靈活性。&lt;/p&gt; 
&lt;h3&gt;支持格式拓展&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;圖像格式&lt;/strong&gt; ：支持使用 ART 作為 Camera Raw 加載器，可導入 APNG 動畫、加載多層 OpenEXR 圖像，以及導入和導出 JPEG 2000 圖像，還支持加載和導出 Sony Playstation 1 TIM 紋理和圖像。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Photoshop 相關格式&lt;/strong&gt; ：新增導出至 Krita 的.kpl 調色板格式選項，支持導入 Photoshop 圖案，以及使用 Photoshop 曲線和色階預設，並初步支持導出 Photoshop 大型格式（PSB）文件。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;其他小眾格式&lt;/strong&gt; ：支持 Nokia 歷史性的黑白 Over-the-Air 位圖格式，支持導入被稱為 Jeff 的圖像格式（.jif）的 GIF 變體，以及導入高級視頻編碼（AVCI）靜態圖像。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.gimp.org%2Fnews%2F2025%2F06%2F23%2Fgimp-3-1-2-released%2F" target="_blank"&gt;https://www.gimp.org/news/2025/06/23/gimp-3-1-2-released/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357015/gimp-3-1-2-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357015/gimp-3-1-2-released</guid>
      <pubDate>Sat, 10 May 2025 07:47:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度日誌中台前端重構實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;日誌中台是百度內部針對打點數據的全生命週期管理平台，作為公司日誌數據的唯一入口，承擔以下核心職能：1.功能覆蓋：提供從數據採集、傳輸、存儲到查詢分析的一站式服務，支持產品運營分析、研發性能監控、運維管理等多元場景。2.業務賦能：通過標準化流程實現用户行為日誌的埋點申請、審批及退場管理，助力 APP 端、服務端等業務線挖掘數據價值。3.生態協同：與大數據平台、推薦中台、性能平台深度聯動，避免重複建設，提升資源利用率，強化業務中台能力。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;01 項目背景&lt;/h1&gt; 
&lt;p&gt;2020 年初啓動的日誌中台前端項目，隨着業務發展逐漸暴露出嚴重問題。整個前端項目技術負債多，有 500 多個文件，共 11 萬多行源碼。項目已經變得老舊而臃腫。面臨線上 bug 頻發、排查問題效率低下等各種問題，陳舊的技術棧與低效的流程也制約了團隊的生產力。因此需進行全面全面重構，通過基於業務導向的架構優化、開發測試流程規範化，從而提升前端開發效率，使項目具備長期穩健發展的技術基礎。本文將重點介紹我在重構項目過程中的一些實踐經驗。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;02 前端項目面臨的問題&lt;/h2&gt; 
&lt;p&gt;先介紹下日誌中台前端項目的基本情況&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;核心框架：Vue 2.6 + Vuex 3.1.1 + VueRouter 3.0.6&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;UI 組件庫：ElementUI 2.15.13&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;構建工具：@vue/cli-service 3.11.0（基於 Webpack 4）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署平台：測試環境（FIS3）、生產環境（Tower）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我將從 4 個維度來分析下前端項目所面臨的各種問題。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 代碼質量&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由於項目沒有接入代碼格式化 prettier 和，代碼規範檢查 eslint，導致項目的代碼質量堪憂，各種各樣的代碼風格並存。在開發需求過程中，各自的編碼風格不一致，維護時需額外適應時間，甚至由此引發線上問題。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 基礎建設&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 代碼臃腫，維護困難&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;全項目 500+源文件中，30+文件超 1000 行，5+文件超 2000 行，最大文件達 5000 行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;巨型文件導致：&lt;/p&gt; &lt;p&gt;IDE 卡頓（Mac 開發時頻繁卡住）。&lt;/p&gt; &lt;p&gt;熱更新失效（&amp;gt;2s 延遲，大文件需手動刷新瀏覽器）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 技術棧陳舊&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;仍使用已停止維護的&lt;code&gt;vue-cli&lt;/code&gt;（Webpack 4 時代工具鏈），與現代構建工具（Vite、Webpack 5）存在代差。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 構建和部署&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;測試環境&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;測試環境的部署採用的是&lt;/strong&gt;&lt;/strong&gt; &lt;strong&gt;&lt;strong&gt;fis3&lt;/strong&gt;&lt;/strong&gt;，這是百度 FE 團隊早期自研的集構建、部署於一身前端構建工具，日誌中台項目使用其部署測試環境的功能。具體流程就是在開發者本地執行打包操作，然後將打包產物通過 fix3 推送到後端的服務器上去，替換掉之前的打包產物，從而實現部署新版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;這種方式存在諸多問題：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地構建依賴不一致，易引發環境差異問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無 CDN 緩存，靜態資源直推後端服務器。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無版本管理，存在代碼覆蓋風險。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FIS3 已停止維護，社區無支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;本質問題&lt;/strong&gt;&lt;/strong&gt;：前後端未完全分離，違背當前主流協作模式。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;生產環境&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;生產環境的部署則採用的是 Tower 平台，這是百度內部的線上部署平台，通過平台的形式將 master 分支的代碼在服務器上編譯構建，將打包後的產物推送到線上環境對應的服務器上，從而實現完整的上線流程。這種上線方式同樣存在諸多不足：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上線耗時長達 30 分鐘，無增量構建能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多服務器部署時存在「漂移現象」（請求路由不一致）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;操作流程複雜，平台限制多（如回滾困難）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;仍缺失 CDN 加速，影響頁面加載性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.4 優質組件&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Vue 技術棧中，模塊和組件的模糊概念，導致很多開發者無法區分其區別。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 組件與模塊概念混淆&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;src/components&lt;/code&gt;目錄下堆積 40+文件夾，但 90% 為一次性業務模塊（如 5 個重複封裝的 Table 組件），缺乏真正的複用價值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 基礎建設缺失&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;無通用業務組件庫，開發依賴 Element UI 原始組件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高頻邏輯（如表單校驗、數據請求）需重複實現，通過「複製粘貼」開發，導致代碼冗餘和一致性風險。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;03 全面重構拆分&lt;/h1&gt; 
&lt;p&gt;下面是針對以上項目中的各個痛點的重構具體手段。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 接入工程化&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;前端項目若缺乏統一的代碼規範和質量控制，隨着業務增長，代碼可維護性會急劇下降，最終導致開發效率低下、線上問題頻發。因此，引入業界成熟的工程化方案是提升代碼質量的關鍵。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-44faf28db07e05e98073becb5657960b557.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;strong&gt;工程化改造步驟&lt;/strong&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 清理冗餘配置&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;移除項目中無用的、過時的配置（如廢棄的&lt;code&gt;.babelrc&lt;/code&gt;、冗餘的&lt;code&gt;webpack&lt;/code&gt;配置等），減少幹擾項。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 統一基礎配置文件&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在項目根目錄下添加必要的配置文件，確保團隊開發環境一致：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;.vscode/settings.json&lt;/code&gt;（統一 VSCode 編輯器配置）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;.editorconfig&lt;/code&gt;（統一縮進、換行等基礎格式）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;.npmrc&lt;/code&gt;（設置為百度 npm 鏡像）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;.browserslistrc&lt;/code&gt;（明確目標瀏覽器兼容範圍）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 接入代碼規範工具&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;Prettier&lt;/strong&gt;&lt;/strong&gt;：自動格式化代碼，統一風格（如縮進、引號、分號等）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;ESLint&lt;/strong&gt;&lt;/strong&gt;：檢查 JavaScript/Vue 代碼質量，避免常見錯誤。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;Stylelint&lt;/strong&gt;&lt;/strong&gt;（可選）：規範 CSS/Less 代碼風格。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;4. 優化開發體驗&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;推薦安裝必要的 VSCode 插件（如 ESLint、Prettier、Volar 等），提升開發效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;5. 提交時增量強制校驗（Git Hooks）&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;接入&lt;code&gt;husky&lt;/code&gt;+&lt;code&gt;lint-staged&lt;/code&gt;，在&lt;code&gt;git commit&lt;/code&gt;時自動執行代碼檢查，阻止不合規代碼提交。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;strong&gt;配置參考&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;VSCode 統一配置&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23NStKP" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#NStKP&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;工程化配置方案 https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#SJTr2&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h4_10"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;strong&gt;歷史代碼修復策略&lt;/strong&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;原則：「自動修復優先，手動修復補充」，避免無限制添加&lt;code&gt;eslint-disable&lt;/code&gt;或&lt;code&gt;ignore&lt;/code&gt;規則，導致規範形同虛設。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;具體執行步驟&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 自動格式化（Prettier）&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. ESLint 自動修復&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 分析剩餘問題&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;使用&lt;code&gt;eslint-formatter-html&lt;/code&gt;生成報告，評估剩餘問題。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;調整 ESLint 規則（如放寬部分歷史代碼限制），拆解為多個小任務手動修復。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;4. 迴歸測試&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聯合熟悉業務的同學進行全量測試，確保修復過程不影響系統功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_11"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;strong&gt;效果驗證&lt;/strong&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;代碼風格統一&lt;/strong&gt;&lt;/strong&gt;：所有新提交的代碼均符合規範，減少風格爭議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;錯誤率下降&lt;/strong&gt;&lt;/strong&gt;：低級語法錯誤、邊界條件導致的 JS 報錯大幅減少。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;開發體驗提升&lt;/strong&gt;&lt;/strong&gt;：IDE 卡頓減少（格式化後代碼更簡潔），熱更新效率提高。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 升級基建&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1 源碼優化與依賴治理&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;問題現狀&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;項目存在大量技術債務，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;冗餘資源（未壓縮圖片約 2M）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;無效依賴（22 個未使用的 npm 包）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;混合模塊規範（require/import 混用）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;廢棄技術棧（如已停止維護的 iView）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;優化措施&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 資源優化&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;使用基於 Tinypng 封裝的工具批量壓縮圖片，體積減少 65%&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;清理已下架頁面的遺留代碼（約 15 個路由）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 依賴治理&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;移除 22 個無用依賴&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;統一使用 ES Module 規範（手動替換 require 為 import）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 技術棧升級&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;替換老舊組件庫：vue-json-diff、vue-code-diff、vue-codemirror 替換為 monaco-editor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2 &lt;strong&gt;&lt;strong&gt;構建相關&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;相對於以往的 Webpack 或者 Vue CLI，存在開發服務器啓動慢（平均 45 秒）、熱更新延遲高（2.5 秒）、構建流程複雜（需 Babel 轉譯 ES5）。&lt;/p&gt; 
&lt;p&gt;Vite 配置詳見：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23wyx0p" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#wyx0p&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;接入 Vite 後，低配置電腦同學開發時的平均熱更新時間由 2.5 秒縮短到 100 毫秒。在單個需求完成耗時方面，由之前的 4.2 人天縮減到 3.4 人天，綜合人效提高&lt;strong&gt;&lt;strong&gt;19%&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;另一方面，由於 Vue CLI 是基於 babel 將 esnext 代碼轉成 es5，而 Vite 基於 esbuild 不需要進行降級編譯。在將 Vite 的配置 build.target 設置為 ['chrome100'] 後，甚至連非常新的 esnext 語法糖都不需要轉換，瀏覽器直接可以使用前端的源碼，極大的利用了 esnext 帶來的開發便利，而不需要關注 Babel 的版本以及各種依賴包和複雜的配置。&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.3 &lt;strong&gt;&lt;strong&gt;部署相關&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;百度內部主流的部署平台是 &lt;strong&gt;&lt;strong&gt;Fcnap&lt;/strong&gt;&lt;/strong&gt;。這是一個類似 Vercel 的前端一站式部署平台，基於 git 分支，只要檢測到分支變動，就會觸發自動構建和部署。&lt;/p&gt; 
&lt;p&gt;只需配置好各個測試環境以及生產環境的基本信息，後續在需要開發中，只需要將分支和測試環境關聯起來，就可以達到隨時提交代碼隨時部署的效果；上線過程更是絲滑，只需要將代碼合到 master 分支，就會自動上線。&lt;/p&gt; 
&lt;p&gt;將 fis3 以及 Tower 遷移到 Fcnap 後有如下優勢：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;測試和生成環境使用一套部署邏輯&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;上線部署耗時由 30 分鐘縮減至 2 分鐘&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供 cdn 功能，每次上線後增量更新的靜態資源只有 500kb&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;上線期間訪問系統不會出現白屏現象&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;上線過程對用户無任何影響&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.4 接口調試&lt;/h3&gt; 
&lt;span id="OSC_h4_17"&gt;&lt;/span&gt; 
&lt;h4&gt;傳統開發模式的痛點&lt;/h4&gt; 
&lt;p&gt;在傳統前後端協作中，存在典型的"接口依賴症"：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 開發阻塞&lt;/strong&gt;&lt;/strong&gt;：前端必須等待後端接口 Ready 才能開始調試&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 效率低下&lt;/strong&gt;&lt;/strong&gt;：聯調階段頻繁出現接口變更，導致重複返工&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 數據不可控&lt;/strong&gt;&lt;/strong&gt;：依賴真實測試環境數據，難以覆蓋邊界場景&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;數據表明：在接口未就緒階段，前端開發效率會下降 60% 以上&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h4_18"&gt;&lt;/span&gt; 
&lt;h4&gt;真正的"前後端分離"實踐&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;核心原則&lt;/strong&gt;&lt;/strong&gt;：開發階段解耦，聯調階段對接&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 規範先行&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;後端通過 YAPI 等平台提供完整的接口文檔&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;包含：請求方法、參數結構、響應體示例、狀態碼定義&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. Mock 數據要求&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;真實業務數據（非簡單根據接口文檔生成各種隨機數據）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可自定義異常場景（404， 502 等真實場景還原）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持動態響應（根據參數返回不同數據）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;針對這個開發環節，我們也基於 Vite 實現了一個非常好用的插件：vite-plugin-mock，用於提升開發效率。整體的設計如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3eb5ab12f6a4aae3eff18b059102be05cc9.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相比於傳統的 mock 方案，vite-plugin-mock 在開發體驗、數據維護上有更好的開發體驗。&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;特性&lt;/th&gt; 
   &lt;th&gt;傳統 Mock 方案&lt;/th&gt; 
   &lt;th&gt;vite-plugin-mock&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;數據真實性&lt;/td&gt; 
   &lt;td&gt;隨機生成，不可用&lt;/td&gt; 
   &lt;td&gt;可在真實接口數據上任意修改&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;開發體驗&lt;/td&gt; 
   &lt;td&gt;需要啓動 Mock 服務&lt;/td&gt; 
   &lt;td&gt;配置簡單，可隨時修改數據&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;聯調切換&lt;/td&gt; 
   &lt;td&gt;手動修改請求地址&lt;/td&gt; 
   &lt;td&gt;自動代理無縫切換&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;數據維護&lt;/td&gt; 
   &lt;td&gt;獨立維護 Mock 數據&lt;/td&gt; 
   &lt;td&gt;數據存放在本地，每個人都可維護單獨的數據&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id="OSC_h2_19"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 &lt;strong&gt;構建體積優化&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這一部分主要從以下三個技術方案着手優化，再配合其他人工優化手段，打包體積由開始的 14M 優化到 1.8M，接入 cdn 功能後，則僅有 500kb。&lt;/p&gt; 
&lt;span id="OSC_h3_20"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.1 element-ui&lt;/h3&gt; 
&lt;p&gt;fork element-ui 源碼, 採用 rollup 進行打包，優化部分源碼，修復部分 bug，重新發包為 @baidu-log/element-ui&lt;/p&gt; 
&lt;p&gt;這一步驟，js 體積從 1.2M 優化到 500kb。並結合下面 externals 功能，進一步使用 cdn 功能緩存這部分文件體積。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.2 引入 externals 功能&lt;/h3&gt; 
&lt;p&gt;將基礎包通過 cdn 的形式在 index.html 模板中引入其 umd 格式的文件，從而避免打包這部分內容。這部分會用到 cdn 的緩存功能，會節約掉大約 2M 的體積。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;vite-plugin-externals&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這個是開源的 vite 插件，配置也比較簡單，詳見配置：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23LiR2X" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#LiR2X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;vite-plugin-assets&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這個是為了配合上面 vite-plugin-externals 插件，將對應的 externals 的 npm 包對應的 umd 文件插入到模板中，代碼詳見：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23xts88" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#xts88&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;為什麼不直接寫在 index.html 裏呢？因為像 vue 和 react 這樣的框架，在開發時都提供了對應的開發調試工具：dev-tools。而使用 dev-tools 則需要提供對應的 &lt;strong&gt;&lt;strong&gt;dist/vue.js&lt;/strong&gt;&lt;/strong&gt;，而 react 對應的則是 &lt;strong&gt;&lt;strong&gt;react.development.js&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;span id="OSC_h3_22"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.3 大包的特殊處理&lt;/h3&gt; 
&lt;p&gt;1. monaco-editor&lt;/p&gt; 
&lt;p&gt;項目中用到了 monaco-editor 這個編輯器組件，直接打包將會非常大，有 10M 以上的體積。根據官方提供的方案即可進行如下封裝，其中 cdn 地址由百度的 npm 鏡像服務提供支持。&lt;/p&gt; 
&lt;p&gt;代碼詳見：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23gozcq" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#gozcq&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2. xlsx, fabric 等&lt;/p&gt; 
&lt;p&gt;在項目中用到了 xlsx, fabric, markdown-it, echarts, &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdraw.io" target="_blank"&gt;draw.io&lt;/a&gt; 這幾個體積很大的包，但又不屬於很基礎的包，只有少部分頁面的某個功能點才會用到。針對這些包採用從 cdn 異步加載其 umd 包的形式來引入，而不是通過 import npm 包的形式。&lt;/p&gt; 
&lt;p&gt;代碼詳見：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.yuque.com%2Fshuoshubao%2Fbg00go%2Fwc87bknptk3lomed%23rEBee" target="_blank"&gt;https://www.yuque.com/shuoshubao/bg00go/wc87bknptk3lomed#rEBee&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;以上兩種優化方案，與常見的動態引入方案（dynamic import）是有很大區別的，dynamic import 是通過編譯工具將對應的 npm 包打包成一個獨立的 chunk，然後在使用的時候再通過 loadScript 方式引入。這種問題在於文件的緩存，一是 chunk 可能會變，二是像 Vercel 這種平台，每次發佈都是一個全新的 s3 bucket，上線後緩存功能也就失效了。而上述這種方案，則利用 npm 鏡像服務，每次都訪問固定的 cdn 地址，也就達到了 cdn 的緩存目的了。&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.4 建設組件庫&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;鑑於項目沒有優質組件的背景，從零到一搭建了組件庫，組件庫主要包含以下內容：&lt;/p&gt; 
&lt;p&gt;1. 基於 Vuepress 建設高質量組件庫文檔&lt;/p&gt; 
&lt;p&gt;2. 遷移 element-ui 文檔，並修復其中大量劣質示例代碼&lt;/p&gt; 
&lt;p&gt;3. 採用 Vitest 編寫工具方法的測試用例&lt;/p&gt; 
&lt;p&gt;4. 提供 9 個高頻優質通用組件，10 個業務組件&lt;/p&gt; 
&lt;p&gt;組件庫文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2F" target="_blank"&gt;https://logsfe.vercel.app/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;文檔分為以下幾大模塊&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;優質組件：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2Fcomponents%2FTable%2F" target="_blank"&gt;https://logsfe.vercel.app/components/Table/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;組件庫裏的方法：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2Futils.html" target="_blank"&gt;https://logsfe.vercel.app/utils.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;@nbfe/tools 工具庫方法： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2Ftools%2Fdate.html" target="_blank"&gt;https://logsfe.vercel.app/tools/date.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ElementUI 文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2Felement%2Ficon.html" target="_blank"&gt;https://logsfe.vercel.app/element/icon.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端定製的開發規範：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flogsfe.vercel.app%2Fcontribute%2F" target="_blank"&gt;https://logsfe.vercel.app/contribute/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實際效果：組件庫中的組件在項目中目前已被使用 240 次，用户使用體驗良好。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;3.4.1 通用組件&lt;/h3&gt; 
&lt;p&gt;基於大量的 B 端系統開發經驗，提煉出配置化表格和配置化表單組件，滿足項目中 90% 的開發場景，通過重構部分頁面後比較分析，在寫對應模塊時，能減少 40% 的代碼。&lt;/p&gt; 
&lt;p&gt;通用組件均與業務解耦，設計優雅的 api，並提供大量示例。組件庫裏只提供少量的優質組件，嚴格把控每一行提交的代碼，併為組件中的工具函數提供符合 JSDoc-style 規範的註釋，且通過 Vitest 來編寫單元測試。&lt;/p&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.4.2 element-ui 文檔集成&lt;/h3&gt; 
&lt;p&gt;在實際工作中，發現 element-ui 文檔存在很多問題且早已不維護。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;主題與日誌中台不符，不利於查看&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;組件默認 size 過大，一頁都看不了多少示例&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;右側沒有 toc 功能，不方便快速定位&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;示例很多寫法不優雅，以及很多冗餘代碼被人機的複製到了項目中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在線調試示例採用的是 codepen 平台，這個平台很慢而且經常掛了&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上各種問題，將 element-ui 官方的示例 fork 到組件庫中，使用和日誌中台一樣的主題，並修復上述各種問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-448a51bef83543cbfa7e0b5a4588348e6b3.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;並使用純前端來實現了一個完全可用的 codepen 組件使用示例功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-10997cf6d1b599250b533a1a538cfa80d94.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_26"&gt;&lt;/span&gt; 
&lt;h3&gt;3.4.3 通用工具庫&lt;/h3&gt; 
&lt;p&gt;基於 B 端系統抽象的實用工具方法集合。在組件庫中提供優質的説明文檔和使用示例。這個已經發布到 npm 上，並在多個公司和團隊使用。&lt;/p&gt; 
&lt;p&gt;包括日期處理、數據處理、接口數據格式化、針對 element-ui 的一些實用封裝。目前已在項目中被 93 個文件使用 150 次。&lt;/p&gt; 
&lt;p&gt;項目地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40nbfe%2Ftools" target="_blank"&gt;https://www.npmjs.com/package/@nbfe/tools&lt;/a&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_27"&gt;&lt;/span&gt; 
&lt;h1&gt;04 總結與展望&lt;/h1&gt; 
&lt;p&gt;在頻繁的需求迭代過程中，項目遲早會變成臃腫老舊的樣子。當開發體驗、開發速度、代碼質量、項目可維護性、聯調測試體驗、線上質量等全方位令人舉步維艱的時候，就該發起大規模的全面重構了。對每一項重構技術需要深刻掌握，才能掌握重構的深度和保證重構後的項目質量。另外，還定製了很多開發規範和最佳實踐指導，但項目中仍存在大量不符合規範的地方，將在未來繼續進行全量修復，直到將一個老舊的項目重構到更接近現代化前端項目的程度。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18635524</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18635524</guid>
      <pubDate>Sat, 10 May 2025 07:41:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>curl 之父發文介紹 OpenSSL 分支家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;curl 之父近日發表文章&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2025%2F06%2F23%2Fa-family-of-forks%2F" target="_blank"&gt;介紹&lt;/a&gt;&lt;/u&gt; OpenSSL 分支家族，展示了它們的差異、相似之處，以及支持它們所需的一些見解。&lt;/p&gt; 
&lt;p&gt;譯文如下：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;curl 支持使用 11 種不同的 TLS 庫進行編譯。其中六個庫是 OpenSSL 或其分支。讓我向你展示它們的差異、相似之處，以及支持它們所需的一些見解。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;SSLeay&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這一切都始於 SSLeay。這是我發現的第一個 SSL 庫，我們使用這個庫在 1998 年春天為 curl 添加了第一個 HTTPS 支持。顯然，SSLeay 項目早在 1995 年就已經啓動了。&lt;/p&gt; 
&lt;p&gt;那是一個我們還只支持 SSL 的年代；TLS 會在之後才出現。&lt;/p&gt; 
&lt;p&gt;OpenSSL 一直擁有一個古怪、不一致且極其龐大的 API 集（其中一大部分是從 SSLeay 繼承而來的），這進一步被稀疏的文檔所複雜化，這些文檔留給用户去依靠自己的想象力和技能去查閲源代碼，以獲取最後的細節解答（即使在 2025 年今天也是如此）。在 curl 中，我們經常收到關於如何使用這個庫的偶爾問題報告，即使已經過了幾十年。 presumably，這同樣適用於所有 OpenSSL 用户。&lt;/p&gt; 
&lt;p&gt;OpenSSL 項目經常受到批評，認為他們在幾年前升級到版本 3 之後，在性能方面有所疏忽。他們也一直進展緩慢或不願採用新的 TLS 技術，例如 QUIC 和 ECH。&lt;/p&gt; 
&lt;p&gt;儘管如此，OpenSSL 已經成為一種主導的 TLS 庫，尤其是在開源領域。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;LibreSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;回到 Heartbleed 事件時期，LibreSSL 分叉出來併成為獨立的項目。他們刪除了他們認為不屬於庫中的功能，創建了自己的 TLS 庫 API。幾年後，蘋果在 macOS 上使用 LibreSSL 提供 curl。他們有一些本地修補，使它&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2024%2F03%2F08%2Fthe-apple-curl-security-incident-12604%2F" target="_blank"&gt;行為與其他不同&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;LibreSSL 在 QUIC 的支持上落後，不支持 SSLKEYLOGFILE、ECH，而且如今在實現新功能方面似乎比 OpenSSL 更慢。&lt;/p&gt; 
&lt;p&gt;curl 自從創建以來就與 LibreSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;BoringSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Heartbleed 事件時期由 Google 分叉出來。&lt;em&gt;Google 為 Google 做的&lt;/em&gt;，他們沒有公開發布過，清理了很多原型和變量類型，並在 QUIC API 推動中處於領先地位。總體而言，大多數新的 TLS 發明都已在 BoringSSL 中實現和支持，比其他分叉更早。&lt;/p&gt; 
&lt;p&gt;Google 在 Android 的其他地方也使用這個。&lt;/p&gt; 
&lt;p&gt;curl 從創建以來就與 BoringSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AmiSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一個為使 OpenSSL 能夠在 AmigaOS 上正確編譯和運行而製作的 OpenSSL 分支或變種。我對它瞭解不多，但在這裏包含它是為了完整性。它似乎基本上是為 Amiga 系統移植的 OpenSSL。&lt;/p&gt; 
&lt;p&gt;當為 AmigaOS 編譯時，curl 也能與 AmiSSL 兼容。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;QuicTLS&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由於 OpenSSL 延遲響應並拒絕提供 QUIC API，其他分支在 2020 年初期（我尚未看到有人解釋原因）採取了行動。微軟和 Akamai 分支了 OpenSSL，產生了 &lt;em&gt;QuicTLS&lt;/em&gt;，此後它試圖成為一個 &lt;em&gt;輕量級&lt;/em&gt; 的分支，主要只是在與 BoringSSL 和 LibreSSL 支持相同風格的基礎上添加 QUIC API。&lt;em&gt;輕量級&lt;/em&gt; 的含義是它們密切跟蹤上游開發，並且除了 QUIC API 之外，沒有打算在其他方面偏離。&lt;/p&gt; 
&lt;p&gt;在 OpenSSL 3.5 中，他們終於提供了一個與 fork（包括 QuicTLS）提供的 QUIC API 不同的 QUIC API。我認為這促使 QuicTLS 重新考慮其未來的發展方向，但我們仍在等待確切的進展。&lt;/p&gt; 
&lt;p&gt;curl 自從創建以來就與 QuicTLS 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AWS-LC&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這是由亞馬遜維護的一個 BoringSSL 分支。與 BoringSSL 不同的是，他們確實進行了實際的（頻繁的）發佈，因此看起來像一個項目，即使是非亞馬遜用户也可以實際使用和依賴——儘管他們存在的目的是 _維護一個與 AWS 使用的軟件和應用程序兼容的安全 libcrypto _。令人驚訝的是，他們維護的不僅僅是「僅僅」 libcrypto。&lt;/p&gt; 
&lt;p&gt;這個分支最近顯示出大量的活動，甚至在核心部分也是如此。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.haproxy.com%2Fblog%2Fstate-of-ssl-stacks" target="_blank"&gt;2025 年 5 月由 HAProxy 團隊進行的基準測試&lt;/a&gt; 表明，AWS-LC 顯著優於 OpenSSL。&lt;/p&gt; 
&lt;p&gt;AWS-LC 提供的 API 與 BoringSSL 的 API 並不完全相同。&lt;/p&gt; 
&lt;p&gt;curl 與 AWS-LC 從 2023 年初開始就配合得非常好。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;家族樹&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/img/202506/24145235_ALUZ.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;OpenSSL 分支家族樹&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;OpenSSL 分支家族現狀&lt;/h2&gt; 
&lt;p&gt;這六個不同的分支各自有其特定的特性、API 和功能，這些在不同版本中也會發生變化。目前我們仍然支持這六個分支，因為人們似乎仍在使用它們，而且維護起來是可行的。&lt;/p&gt; 
&lt;p&gt;我們使用相同的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcurl%2Fcurl%2Fblob%2Fmaster%2Flib%2Fvtls%2Fopenssl.c" target="_blank"&gt;單個源代碼文件&lt;/a&gt; 支持所有這些分支，並通過不斷增長的 #ifdef 邏輯來實現。我們通過在 CI 中使用這些分支進行構建驗證，儘管只使用了一小部分最近的版本。&lt;/p&gt; 
&lt;p&gt;隨着時間的推移，這些分支似乎正在逐漸彼此分離。我認為這還不構成一個問題，但我們當然在監控這種情況，可能在某個時候需要進行一些內部重構以適應這種變化。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;未來&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我無法預見會發生什麼。如果歷史是一堂課，我們似乎更傾向於走向更多的分支，而不是更少的分支。但當然，每一位閲讀這篇博客文章的讀者現在都會思考，所有這些分支所耗費的重複努力以及由此帶來的隱含低效性到底有多少。這不僅適用於這些庫本身，也適用於像 curl 這樣的用户。&lt;/p&gt; 
&lt;p&gt;我認為我們只能等待觀察。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357005/a-family-of-openssl-forks</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357005/a-family-of-openssl-forks</guid>
      <pubDate>Sat, 10 May 2025 06:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
