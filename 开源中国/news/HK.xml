<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 14 Aug 2025 07:44:03 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>螞蟻集團開源新一代 JVM 即時編譯器 Jeandle</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;螞蟻集團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYaMmozWGMKV3x7ZM5IP2KQ" target="_blank"&gt;宣佈&lt;/a&gt;正式開源基於 LLVM 的 JVM JIT 編譯器 Jeandle。公告寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以「筋斗雲」為喻，希望 Jeandle 可以為 JVM 加足馬力，拓寬它的性能與生態邊界，讓 Java 如騰雲駕霧般瞬息萬裏。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/152859_uBKb_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;開源地址：&lt;/p&gt; 
&lt;p&gt;https://github.com/jeandle/jeandle-jdk&lt;br&gt; https://github.com/jeandle/jeandle-llvm&lt;/p&gt; 
&lt;p&gt;據介紹，Jeandle 是基於 OpenJDK Hotspot JVM 的全新 Just-In-Time（簡稱 JIT，即時）編譯器，利用 LLVM 進行編譯優化與代碼生成，將 LLVM 的性能優勢和生態優勢引入 JVM 中。&lt;/p&gt; 
&lt;p&gt;&lt;img height="533" src="https://static.oschina.net/uploads/space/2025/0814/152948_uqyv_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了整合 JVM 和 LLVM 兩個複雜的系統，Jeandle 需要攻克多個技術難題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 JVM 的垃圾回收機制&lt;/li&gt; 
 &lt;li&gt;為 JVM 中的各種功能分別定製 LLVM 特性&lt;/li&gt; 
 &lt;li&gt;基於 LLVM 實現針對 Java 語言的多類優化算法&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;......&lt;/p&gt; 
&lt;p&gt;Jeandle 開源伊始，目前已經實現了若干關鍵功能，同時也有大量的研發工作仍在進行中。未來規劃：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025 年全量 Bytecode 支持：社區計劃在今年年底的版本中完成各類基礎功能的支持，包括 exception、GC、sychronization 等等，覆蓋全量的 bytecode。&lt;/li&gt; 
 &lt;li&gt;2026 年持續聚焦於性能優化的「黑科技」：&lt;/li&gt; 
 &lt;li&gt;推出&amp;nbsp;Java 定製優化套件：研發針對 Java 語言的各類優化算法，使 Jeandle 具備全面的優化能力，包括但不限於鎖優化、類型分析、逃逸分析、inline 等。同時實現基於運行時 profile 信息的優化能力和 deoptimization 能力&lt;/li&gt; 
 &lt;li&gt;加入 intrinsic：通過針對各類特殊場景定製的高效代碼提升 Java 語言性能&lt;/li&gt; 
 &lt;li&gt;支持 on-stack replacement&lt;/li&gt; 
 &lt;li&gt;支持 G1 GC 算法&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366179</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366179</guid>
      <pubDate>Thu, 14 Aug 2025 07:31:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 初創公司 Midjourney 更新功能，允許標準訂閲用户生成高清視頻</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span&gt;AI 初創公司 Midjourney&amp;nbsp;&lt;/span&gt;今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1955773050751963144" target="_blank"&gt;宣佈&lt;/a&gt;，他們根據社區反饋發佈了一系列的新功能，其中標準訂閲用户現在可以生成高清視頻。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/152433_quiN_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外還有改善的視頻審核功能和批量製作視頻等功能。具體如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;服務更新相關：基於社區反饋對服務進行了一系列小改進，包括 HD 視頻生成對 Standard Plan 用户開放、視頻作業可生成更小批量（1 或 2 個視頻/次，通過設置面板或命令行參數--bs 1 、--bs 2 觸發 ）、Moodboards 分離到側邊菜單可訪問的獨立頁面、視頻作業縮略圖改為顯示最後一幀、視頻內容審核準確性提升 。&lt;/li&gt; 
 &lt;li&gt;涉及公司/團隊：未明確提及具體公司，但圍繞服務更新，推測是某提供視頻等服務的團隊 。&lt;/li&gt; 
 &lt;li&gt;提及的人物標籤：@everyone@here ，屬於通知類標籤 。&lt;/li&gt; 
 &lt;li&gt;相關話題標籤：#ideas-and-features ，用於提交想法和功能建議 。&lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366176</guid>
      <pubDate>Thu, 14 Aug 2025 07:25:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動 VeOmni 框架開源：統一多模態訓練效率飛躍！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;資料來源： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-開發者社區&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;多模態時代的訓練痛點，終於有了「特效藥」&lt;/p&gt; 
&lt;p&gt;當大模型從單一語言向文本 + 圖像 + 視頻的多模態進化時，算法工程師們的訓練流程卻陷入了 「碎片化困境」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;當業務要同時迭代 DiT、LLM 與 VLM 時，很難在一套代碼裏順暢切換；&lt;/li&gt; 
 &lt;li&gt;而當模型形態一旦變化，底層並行組合和顯存調度往往需要大量手工改寫，耗時耗力；&lt;/li&gt; 
 &lt;li&gt;DIT 模型蒸餾需要大量的資源消耗，但是缺少高效的訓練 infra 支持來提升效率……&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些困擾行業的痛點，字節跳動的工程師們早就遇到了 —— 於是，VeOmni 應運而生。作為字節內部驗證過的 「統一多模態訓練框架」，它經過內部千卡級別真實訓練任務檢驗，訓練了 UI-Tars1.5 等重要模型，為了能將字節跳動核心 AI Infra 能力服務更多用户，字節跳動決定開源 VeOmni，火山引擎基於進一步上支持了視頻模型訓練等功能，讓 VeOmni 支持了更多模型訓練場景，可以更好地服務更多用户。&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;VeOmni 是什麼？一套框架，搞定所有多模態訓練&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 是字節 Seed 團隊與火山機器學習平台、IaaS 異構計算團隊聯合研發的統一多模態模型訓練框架，核心定位是三個統一：「統一多模態、統一併行策略、統一算力底座」。&lt;/p&gt; 
&lt;p&gt;它通過統一的 API 將 LoRA 輕量微調、FSDP、Ulysses 和 Expert Parallel 等多種混合並行策略以及自動並行搜索能力內置於框架內部。無論是百億級語言模型、跨模態視覺語言模型，還是 480P/720P、長序列的文本到視頻（T2V）或圖像到視頻（I2V）生成模型，開發者都能夠基於統一的訓練流程快速啓動訓練。&lt;/p&gt; 
&lt;p&gt;框架支持在千卡級 GPU 集羣上自動完成權重張量的切分、通信拓撲的優化、動態顯存回收和異步 checkpoint。在開源的 Wan 2.1 等模型上實測顯示，相較於同類開源方案，VeOmni 能夠將訓練吞吐提高超過 40%，同時顯著降低顯存使用與跨節點通信帶寬壓力。&lt;/p&gt; 
&lt;p&gt;藉助 VeOmni，字節跳動成功實現了「支持最快落地的新模型形態、最大化超大規模算力利用率、最小化業務改動成本」三大目標，有效彌補了開源社區訓練框架在擴展性和抽象層面上的不足，為包括 LLM 和 VLM 在內的多模態生成場景提供了一條統一且高效的訓練路徑。&lt;/p&gt; 
&lt;p&gt;火山引擎的用户可在機器學習平台中運用 VeOmni 的強大功能。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;五大核心優勢，破解訓練效率瓶頸&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 的 「高效」 不是口號，而是用技術細節堆出來的。我們拆解了多模態訓練的核心痛點，給出了針對性解決方案：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;顯存計算雙優化：用最少的額外計算，換最多的顯存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;傳統 「大顆粒」 重計算要麼全關、要麼全開，往往用 10%–20% 的額外計算只換一點顯存。VeOmni 不一樣 —— 它先給每個前向張量算一筆 「ROI 賬」：省 1MB 顯存需要付出多少微秒計算。然後按 ROI 排序，只選性價比最高的算子重計算（比如 gate1_mul 省 40MB 只要 180μs，down_proj 要 4000μs，差距 22 倍！）。&lt;/p&gt; 
&lt;p&gt;VeOmni 框架在訓練啓動前自動把 ROI 排序，同等顯存收益只選擇性價比最高的算子進入重計算池：例如 gate1_mul 和 down_proj 都可回收約 40 MB，但前者只需 180µs、後者要 4000µs，差距達 22 倍。這樣就能在保證顯存不會超出的前提下，把額外計算開銷壓到最低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f15963df249589141d372ad78130413e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;結果是：顯存夠用的前提下，額外計算開銷壓到最低。實測顯示，相比按層重計算，VeOmni 的 Recompute 佔比從 60% 降到 30%（Recompute 越低，效率越高），對 DiT 720P 視頻訓練、千億 LLM 長序列訓練效果顯著。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;混合並行 「組合拳」：一鍵匹配最優算力切分方案，顯存峯值降 55%&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 內置多維並行體系，支持 FSDP、Ulysses 和 Expert Parallel (EP) 等多種並行原語，通過啓動腳本可以一鍵進行笛卡爾組合，自動搜索最優的算力切分方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FSDP 負責將參數、梯度和優化器狀態切片到各個 GPU，突破顯存瓶頸，橫向擴批簡單可靠；&lt;/li&gt; 
 &lt;li&gt;Ulysses Parallel 針對長序列任務，將注意力沿 head 維度拆解，有效緩解單卡顯存壓力；&lt;/li&gt; 
 &lt;li&gt;Expert Parallel 專門適用於 MoE 模型，可高效支持超大規模專家網絡的訓練。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這套並行體系已被應用於字節跳動內部多種模型的訓練中，在處理 480P 和 720P 分辨率的 T2V/I2V 任務時，通過 FSDP 和 Ulysses 的組合，單輪迭代顯存峯值可降低至原有基線的 45%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;算子級性能深挖：小核算子融合，訪存次數降百倍&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;針對 DiT 中大量「小核算子」導致的訪存抖動，VeOmni 把注意力-FFN-殘差鏈路重寫為單核 Kernel，長序列下顯存碎片顯著減少，訪存次數下降數百倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//afce03f7d8cbcb2bff0b447b13dc1dc4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//bb18ae198fde761b3d2d081c8696cb6b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨模型通吃：LLM/VLM/ 視頻生成，一套框架全搞定&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 的優化不是 「針對性補丁」，而是對，生成式視頻模型、千億級語言模型，與 視覺語言模型，全部生效：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DiT 訓練顯存減半；&lt;/li&gt; 
 &lt;li&gt;LLM 長上下文窗口訓練從「手動調顯存」變為「自動無感切分」；&lt;/li&gt; 
 &lt;li&gt;VLM 雙塔/單塔架構在 Ring 模式下可線性擴展到更多 GPU，負載均衡無需改代碼。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;憑藉「算子粒度重計算 + 混合並行 + 算子融合/升級」三大引擎，VeOmni 把原本困擾開源框架的擴展瓶頸徹底拆解，為字節跳動以及合作伙伴在多模態內容生成和大模型服務化道路上提供了即插即用、極致高效的算力底座。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蒸餾加速：減少推理步數，降低推理成本&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在生成式模型的推理中，步數蒸餾是提升效率的關鍵一環。然而，蒸餾的訓練週期極長，需要的計算資源也十分龐大。VeOmni 集成了軌跡蒸餾、分佈匹配蒸餾（DMD）、自迴歸蒸餾等學界前沿方法，並將框架原生的訓練加速能力（如顯存優化、混合並行等）應用在蒸餾算法上，極大地減少了蒸餾的迭代週期和資源消耗。用户可通過啓動腳本指定蒸餾目標：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 DMD 等效果優秀的蒸餾方法，能將模型穩定蒸餾至 4 步、8 步等目標步數甚至更少；&lt;/li&gt; 
 &lt;li&gt;支持蒸餾掉 CFG（無分類器引導）以消除冗餘計算；&lt;/li&gt; 
 &lt;li&gt;支持用户自由編排蒸餾工作流，例如組合 「軌跡蒸餾預處理 + DMD 精調」 的多階段蒸餾邏輯。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經由 VeOmni 蒸餾出的模型能夠顯著減少推理所需步數，同時保持生成結果的高質量，這對於降低計算成本、加速模型部署具有重要意義。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;實測性能：比開源方案快 40%，多場景數據説話&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 的效率不是 「自説自話」，而是用真實模型測試驗證的，以 Wan2.1-14B 模型為例（Lora 訓練）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算型大卡：I2V 720P 訓練速度比開源方案快 48% 以上，T2V 720P 快 44.4% 以上；&lt;/li&gt; 
 &lt;li&gt;訪存型大卡：I2V 720P 快 59.5% 以上，T2V 720P 快 57.4% 以上；&lt;/li&gt; 
 &lt;li&gt;小參數量模型（Wan2.1-1.3B）：T2V 480P 訓練速度提升 51% 以上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;卡型 1（計算型大卡）&lt;/p&gt; 
&lt;p&gt;I2V 訓練速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f3127bf08dc9774d20b1262c87352e99.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;T2V 訓練速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f39465da6844f0065bb3fd82d1a9d701.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;卡型 2（訪存型大卡）&lt;/p&gt; 
&lt;p&gt;I2V 訓練速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//21548247b760eccd256454a9b19f30b7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;T2V 訓練速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1c05eb55c9148e8fc9ee41fbc7df7de4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不管是大模型還是小模型，不管是計算型還是訪存型硬件，VeOmni 都能讓算力發揮到極致！&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;上手超簡單：火山平台一鍵訓練，性能分析可視化&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 不是 「專家專屬工具」，而是開箱即用。目前，火山引擎在機器學習平台和 AI 雲原生訓練套件 TrainingKit 上都提供了 VeOmni 訓練的最佳實踐。下面我們以機器學習平台實踐為例，介紹基於 VeOmni 訓練框架對開源模型 Wan 進行 lora 訓練，後續我們將推出基於 TrainingKit 的 VeOmni 部署實踐。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;創建訓練任務&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在快速入門選擇需要訓練的模型，並且配置實例規格及模型輸出路徑。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//31590466661f9e2eef65fef5916f8414.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f88fe1716fd8d5abaf5b023312375de0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看訓練任務詳情&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;創建任務後可在「任務詳情-日誌」中查看訓練詳情。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//8a54f636c8d814cc29a730da2628b5c1.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPU 性能分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.導航到，自定義任務 &amp;gt; 任務詳情，頁面，在目標任務的管理頁面單擊，創建性能分析。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//82c9f5d93421f97b88b854ded7e4f46d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.完成採集後，可在性能分析結果列表頁面管理所有分析任務。點擊「查看詳情」將跳轉至 perfetto 中展示性能分析火焰圖。&lt;/p&gt; 
&lt;p&gt;每個 Worker 節點會根據其擁有的 GPU 數量或進程數生成多個進程文件。平台會將這些文件聚合成一個單一的結果文件，並根據 perfetto 的限制進行自動分片。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//b6a5e8d04c0237d22283b1f6eb94d3e2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a0617c1987ef8a9f509d17535d5c12b9.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;從訓練到推理，全鏈路打通&lt;/h4&gt; 
&lt;p&gt;目前火山引擎機器學習平台提供的數據集是用來訓練飛天效果的 Lora 數據集，客户也可以自己選擇合適的數據集進行預處理後來進行訓練，具體使用方法隨後更新。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;獲取輸出結果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在一鍵訓練的時候客户指定了訓練的模型結果保存的地方，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//6cac77d83565659304a433c9f88d9e67.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;輸出模型結果保存文件路徑類似下圖&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;code class="language-text"&gt;checkpoints/  
├── &lt;span style="color:#d73a49"&gt;global&lt;/span&gt;\_step\_xxx/           &lt;span style="color:#6a737d"&gt;# 每次保存的權重快照  &lt;/span&gt;
│   ├── extra\_state/            &lt;span style="color:#6a737d"&gt;# 訓練狀態（按 rank 切分）  &lt;/span&gt;
│   │   └── extra\_state\_rank\_*.pt  
│   ├── hf\_ckpt/                &lt;span style="color:#6a737d"&gt;# HuggingFace 兼容格式  &lt;/span&gt;
│   │   ├── config.json  
│   │   └── diffusion\_pytorch\_model.safetensors  
│   ├── model/                  &lt;span style="color:#6a737d"&gt;# 模型參數分片  &lt;/span&gt;
│   │   └── \_\_*\_*.distcp  
│   └── optimizer/              &lt;span style="color:#6a737d"&gt;# 優化器狀態分片  &lt;/span&gt;
│       └── \_\_*\_*.distcp  
└── latest\_checkpointed\_iteration.txt  &lt;span style="color:#6a737d"&gt;# 記錄最新步數  &lt;/span&gt;&lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;客户可以到 hf_ckpt 下看到保存的 Lora 訓練權重，得到的路徑為 checkpoints/global_step_xxx/hf_ckpt/diffusion_pytorch_model.safetensors&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;使用腳本進行權重格式轉換&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;將下列代碼保存為 convert.p&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;code class="language-text"&gt;&lt;span style="color:#6a737d"&gt;#!/usr/bin/env python  # convert.py  ——  把 「blocks.…default.weight」 → 「diffusion\_model.blocks.…weight」  from pathlib import Path  &lt;/span&gt;
from safetensors.torch import &lt;span style="color:#d73a49"&gt;load&lt;/span&gt;\_file, &lt;span style="color:#d73a49"&gt;save&lt;/span&gt;\_file  
&lt;span style="color:#d73a49"&gt;import&lt;/span&gt; &lt;span style="color:#d73a49"&gt;sys&lt;/span&gt;  
  
&lt;span style="color:#d73a49"&gt;if&lt;/span&gt; &lt;span style="color:#d73a49"&gt;len&lt;/span&gt;(sys.argv) != &lt;span&gt;2&lt;/span&gt;:  
    sys.exit(f&lt;span style="color:#032f62"&gt;"用法: python {Path(\_\_file\_\_).name} &amp;lt;input.safetensors&amp;gt;"&lt;/span&gt;)  
  
inp = &lt;span style="color:#d73a49"&gt;Path&lt;/span&gt;(sys.argv[&lt;span&gt;1&lt;/span&gt;]).expanduser().resolve()  
&lt;span style="color:#d73a49"&gt;out&lt;/span&gt; = inp.with\_name(inp.stem + &lt;span style="color:#032f62"&gt;"\_styleB.safetensors"&lt;/span&gt;)  
  
tensors = &lt;span style="color:#d73a49"&gt;load&lt;/span&gt;\_file(&lt;span style="color:#d73a49"&gt;str&lt;/span&gt;(inp))  
converted = {}  
  
&lt;span style="color:#d73a49"&gt;for&lt;/span&gt; k, v &lt;span style="color:#d73a49"&gt;in&lt;/span&gt; tensors.items():  
    &lt;span style="color:#6a737d"&gt;# 若無前綴則加 diffusion\_model.  &lt;/span&gt;
    ifnot k.startswith(&lt;span style="color:#032f62"&gt;"diffusion\_model."&lt;/span&gt;):  
        k = &lt;span style="color:#032f62"&gt;"diffusion\_model."&lt;/span&gt; + k  
    &lt;span style="color:#6a737d"&gt;# 去掉 .default.  &lt;/span&gt;
    k = k.replace(&lt;span style="color:#032f62"&gt;".default."&lt;/span&gt;, &lt;span style="color:#032f62"&gt;"."&lt;/span&gt;)  
    converted[k] = v  
  
&lt;span style="color:#d73a49"&gt;save&lt;/span&gt;\_file(converted, &lt;span style="color:#d73a49"&gt;str&lt;/span&gt;(&lt;span style="color:#d73a49"&gt;out&lt;/span&gt;))  
print(f&lt;span style="color:#032f62"&gt;"✓ 已保存: {out}"&lt;/span&gt;)&lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;執行下面的命令，得到轉換後的權重&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;code class="language-text"&gt;&lt;span style="color:#6f42c1"&gt;python&lt;/span&gt; &lt;span style="color:#032f62"&gt;convert.py   &lt;/span&gt;
&lt;span style="color:#6a737d"&gt;yourpath/checkpoints/global\_step\_xxx/hf\_ckpt/diffusion\_pytorch\_model.safetensors&lt;/span&gt;     &lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;使用 Vefuser 推理&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;訓練完的模型，用火山 veFuser 推理更高效 ——veFuser 是火山引擎的擴散模型服務框架，針對 VeOmni 訓練的 LoRA / 全量微調模型做了優化，能實現 「超低延遲」 視頻生成。從訓練到部署，全鏈路流暢！&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18688206</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18688206</guid>
      <pubDate>Thu, 14 Aug 2025 07:20:34 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>全球首個 AI Agent 市場「Mule Run」開啓 Beta 測試</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;MuleRun &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmulerun_ai%2Fstatus%2F1955661198072115373" target="_blank"&gt;宣佈&lt;/a&gt;其 AI Agent 市場「Mule Run」開啓 Beta 測試。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0814/151422_yt3n_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mule Run 定位為全球首個 AI Agent 市場，旨在成為 AI 領域的 「eBay」，用户只需一個入口即可訪問大量 AI Agent。這些 Agent 能夠執行多種任務，包括遊戲、編程，甚至幫助用户賺錢。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0814/151614_zZWD_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mule Run 的 Beta 測試目前採用邀請制。感興趣的用户可以通過 Discord 加入其社區以獲取更多信息。MuleRun 還通過社交媒體活動提供 5 個激活碼，有效期為 72 小時，參與者需轉發、關注並開啓通知。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366173</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366173</guid>
      <pubDate>Thu, 14 Aug 2025 07:16:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 正以創紀錄的速度創造新的億萬富翁</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F08%2F10%2Fai-artificial-intelligence-billionaires-wealth.html" target="_blank"&gt;據 CNBC 報道&lt;/a&gt;，全球已有近 500 家 AI 「獨角獸」（估值超過 10 億美元）的初創企業，它們的總估值達 2.7 萬億美元，且其中 100 家是在近兩年內成立。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/150500_YLO8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這波浪潮造就了數十位新晉億萬富翁，集中分佈在舊金山灣區。代表人物包括 Scale AI 聯合創始人亞歷山大·王（36 億美元）、郭露西（10 億美元+）、Anthropic CEO 達裏奧·阿莫迪（12 億美元+）、CoreWeave CEO 邁克爾·因特羅特（100 億美元）、DeepSeek CEO 梁文鋒、Figure AI 創始人佈雷特·阿德科克、Perplexity CEO 阿拉温德·斯里尼瓦斯，以及 OpenAI 前高管伊利亞·蘇茨凱夫和米拉·穆拉蒂等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="241" src="https://static.oschina.net/uploads/space/2025/0814/145511_mDy0_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;來源：量子位 https://mp.weixin.qq.com/s/tIYoRz4zm6SlylG-eq-maw&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;這些公司普遍保持私營，依賴風投、主權基金等融資，並頻繁發生併購與股權轉讓。創始人更注重財富管理與二級市場操作，如股權抵押借款、投資同類科技公司等。&lt;/p&gt; 
&lt;p&gt;據瞭解，AI 財富高度集中於灣區，其中舊金山成為全球億萬富翁聚集地，生活成本、房地產等也因 AI 紮根而交由巨大影響。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366170</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366170</guid>
      <pubDate>Thu, 14 Aug 2025 07:07:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元開源 Hunyuan-GameCraft</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;騰訊混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ-EEjMJVLhPjnRGflbHu5w" target="_blank"&gt;宣佈&lt;/a&gt;開源新工具&amp;nbsp;Hunyuan-GameCraft，聲稱可讓用户像導演一樣打造遊戲場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Hunyuan-GameCraft 是基於 HunyuanVideo 底模的高動態交互式遊戲視頻生成框架，簡單來説，它是一個「遊戲視頻生成工具」，只需要「輸入一張圖 + 文字描述+動作指令（按鍵盤方向鍵）」，就能輸出高清動態遊戲視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;無論是第一人稱跑酷，還是第三人稱探險，它都能實時生成流暢畫面，彷彿你真的在遊戲世界裏自由穿梭。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-05412c3b9668b9449c51396d591d8ffe6c3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該工具解決了傳統遊戲內容生產中的三大難題：動作僵硬、場景靜態以及生產成本高昂。Hunyuan-GameCraft 有以下三大優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自由流暢 ：統一連續動作空間，支持高精度控制（角度/速度），支持「邊跑邊轉視角」的複雜操作；可以生成動態內容（例如主角和 NPC 運動、雲層移動、雨雪、水流運動等）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;記憶增強 ：生成長視頻時，角色和環境保持穩定不「穿幫」；通過混合歷史條件，實現歷史幀記憶，避免長視頻生成時不連貫；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;成本驟降 ：無需人工建模或渲染，製作成本更低；對比現有的遊戲模型閉源方案，泛化性強。階段一致性蒸餾方案（Phased Consistency Model, PCM）和 DeepCache 壓縮推理步數，量化 13B 模型支持消費級硬件 RTX 4090，無需高端服務器。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這樣一來，Hunyuan-GameCraft 可以大幅降低遊戲開發門檻，讓個人創作者也能生產 3A 級動態內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-695af7f080b37088da5aac9131192d0a111.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;主要使用對象&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;遊戲開發者：快速進行原型設計以及劇情動畫預演論證，節約人工建模和渲染成本&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;視頻創作者：用一張照片生成「異世界探險」短片，無需學 3D 建模&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;3D 設計師：可以快速將場景原畫秒變動態場景，展示設計創意&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366164</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366164</guid>
      <pubDate>Thu, 14 Aug 2025 06:50:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟正在為 Edge 瀏覽器開發全新 UI：代號 Olympia、專注優化 AI 使用體驗</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fmicrosoft%2Fwindows-11%2Fmicrosoft-edge-olympia-ui-copilot-ai-revamped-design" target="_blank"&gt;根據 Windows Central 的報道&lt;/a&gt;，微軟正在開發代號為 「Olympia」 的 Edge 瀏覽器 UI 更新，該設計以簡潔實用為核心，圍繞 Copilot 功能展開。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fe76a836e3d1bd169ce439ed660fd7a755.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據知情人士透露，該項目自 2024 年起便已啓動，原代號為 Jupiter，目前部分測試版本已出現在 Edge Canary 中。 新版界面包括居中簡化地址欄、垂直標籤頁佈局、右側功能菜單等，並強化搜索、語音輸入功能，視覺風格貼合 Windows 11。&lt;/p&gt; 
&lt;p&gt;有觀點認為，Olympia 或是為 Copilot 模式打造的專屬界面，也可能是更徹底的 UI 重構。當前 Copilot 模式僅將按鈕從窗口右側移至地址欄左側，而 Olympia 佈局中 Copilot 圖標位置與之完全一致，且隨着 Copilot 模式能力增強，或需獨特界面匹配其智能代理功能，這也符合微軟關於生成式 AI 和智能 Agent 功能將改變 UI 的理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-78433eeb077904862d9925e2e12dcbf594b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前該功能尚未完善，部分區域仍不可用。微軟此前嘗試過類似設計但未上線，Olympia 最終能否落地，仍有待觀察。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366162</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366162</guid>
      <pubDate>Thu, 14 Aug 2025 06:49:34 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Gemini 增加「自動記憶」和「臨時聊天」功能</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌為旗下 AI 服務 Gemini 推出了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgemini%2Ftemporary-chats-privacy-controls%2F" target="_blank"&gt;兩項更新&lt;/a&gt;，分別是基於聊天上下文的「自動記憶」功能和保護隱私的「臨時聊天」模式，以提供更個性化的 AI 體驗。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;自動記憶（「個人上下文」）&lt;/strong&gt;：默認開啓，無需用户再手動提示即可記住過往對話中的關鍵細節與偏好，並在後續回答中主動個性化（例如曾討論過日本文化，之後詢問視頻創意時自動推薦日本美食）。&lt;em&gt;用户可在 Gemini 應用 → 設置 → 個人上下文 → 關閉「你與 Gemini 的過往聊天」來禁用。&lt;/em&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5ae3c546bff3bf2ccce191f83b8450db42b.png" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;隱私調整&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;未來幾周，「Gemini Apps Activity」更名為「Keep Activity」。若開啓，從 9 月 2 日起谷歌會抽樣使用用户上傳的文件/圖片以改進服務；若此前已關閉，則保持關閉。&lt;/li&gt; 
   &lt;li&gt;新增「臨時聊天」模式（類似無痕瀏覽）：對話不會出現在歷史記錄，也不用於個性化或模型訓練，僅保留 72 小時。&lt;br&gt; &lt;br&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-939444900548793ba6f27a4f1b65ee096ad.png" referrerpolicy="no-referrer"&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;根據谷歌官方公告，上述調整首先面向部分國家的 Gemini 2.5 Pro 用户推送，後續擴展到更多地區及 2.5 Flash 模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366159/google-gemini-temporary-chats-privacy</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366159/google-gemini-temporary-chats-privacy</guid>
      <pubDate>Wed, 13 Aug 2025 06:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cherry Studio v1.5.6 發佈，支持通過圖形化界面為 Code Agent 配置第三方模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Cherry Studio v1.5.6 已正式發佈，新版本支持通過圖形化界面為 Qwen Code、Gemini Cli 和 Claude Code 等 Code Agent 快速配置第三方模型，並實現一鍵啓動，無需再手動配置模型與 Node.js 環境。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-53c4cbe1db86d83c77e9dd0ed9f1db54abd.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2cc17ff3452f8a9620abdfe50ab94d60b98.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cherry Studio 是一款跨平台的 AI 桌面應用，支持 Windows、macOS 和 Linux 系統。主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模型支持：兼容 40 餘家主流模型服務商，如 OpenAI、Gemini、Anthropic 等，支持一鍵切換模型，滿足不同場景需求。&lt;/li&gt; 
 &lt;li&gt;聯網搜索功能：支持集成第三方搜索服務（如 Tavily、Exa），可讓模型實時獲取網絡信息，增強回答的時效性和準確性。&lt;/li&gt; 
 &lt;li&gt;知識庫管理：支持導入 PDF、Word、Excel 等多種格式文件，構建本地知識庫，實現基於文檔的精準問答。&lt;/li&gt; 
 &lt;li&gt;高度自定義：支持自定義 CSS 樣式、對話佈局、頭像等，還可創建個性化 AI 助手，滿足不同用户的個性化需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://github.com/CherryHQ/cherry-studio/releases/tag/v1.5.6&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366156/cherry-studio-1-5-6</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366156/cherry-studio-1-5-6</guid>
      <pubDate>Wed, 13 Aug 2025 06:27:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 宣佈 Auto 模式不再免費</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;AI 編程工具 Cursor&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fen%2Fblog%2Faug-2025-pricing" target="_blank"&gt;宣佈&lt;/a&gt;了兩項關於定價的新政策。其中包括面向個人用户的「Auto」模式。此前，Auto&amp;nbsp;模式提供免費無限量請求，但這一政策將發生改變。新的計費模式預計將於 9 月 15 日左右生效。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/141755_w0lB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具體變化如下&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;團隊版（Teams）：由統一請求費用轉向 「可變請求費用」&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Cursor 計劃從 &lt;strong&gt;固定請求成本&lt;/strong&gt;，改為按任務複雜度調整費用——簡單請求成本低，複雜任務（如完整 Pull Request）費用自然更高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;這一改動旨在統一團隊版與個人版的計費體系。自 &lt;strong&gt;2025 年 9 月 15 日下次續費日起&lt;/strong&gt;生效；例如若你在 2025 年 6 月訂閲年付計劃，變更將於 2026 年 6 月執行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.cursor.com%2Fen%2Faccount%2Fpricing%23auto" target="_blank"&gt;&lt;strong&gt;個人版 「Auto 模式」：不再無限制免費&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;從 2023 年 12 月至 2025 年 6 月，Auto 模式與其他高端模型同價，但可無限使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;從 2025 年 9 月 15 日的下一次續費起&lt;/strong&gt;，Auto 模式將按 「包含額度」 分配，也會納入每月使用限額（按 token 計費）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366153</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366153</guid>
      <pubDate>Wed, 13 Aug 2025 06:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>崑崙萬維發佈 Skywork Deep Research Agent v2</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在 SkyWork AI 技術發佈周的第四天，崑崙萬維集團&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKBSBOO6bq125BQ9YT4eiYA" target="_blank"&gt;宣佈&lt;/a&gt;推出 Skywork Deep Research Agent v2。這一升級標誌着天工超級智能體（Skywork Super Agents）的核心引擎得到了顯著增強，為用户帶來了更多模態、更高質量和更高效的體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Skywork Deep Research Agent 於 5 月 2 日上線以來。新版本的 Skywork Deep Research Agent v2 引入了「多模態深度調研」Agent，首次整合了多模態檢索、理解和生成，解決了傳統 Deep Research Agent 產品依賴純文本檢索分析的侷限。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="242" src="https://static.oschina.net/uploads/space/2025/0814/141828_pO9c_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;崑崙萬維 Skywork 團隊推出的「多模態深度調研」Agent，通過技術創新，實現了多模態信息檢索能力的提升，包括多模態爬取技術 MM-Crawler、長距離多模態信息收集、異步並行 Multi-Agent 多模態理解架構和多模態結果呈現能力。這些技術突破使得研究人員等用户能夠一次性獲得信息完整、節奏順暢、視覺友好的深度報告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，崑崙萬維還推出了「多模態深度瀏覽器」智能體，重塑了社交媒體內容分析與數據洞察。這一智能體通過多項關鍵自研技術優化，包括升級 DOM+視覺推理方案、主流平台專項適配、並行搜索、多動作規劃機制、智能篩選、人機無縫接管與隱私保護和安全承諾等，能夠模擬人類瀏覽與交互方式，革新傳統數據採集與分析模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Skywork Deep Research Agent v2 在多項 Agent 任務評測上超越現有模型，達到行業 SOTA 水平。在權威的搜索評測榜單 BrowseComp 上，其性能尤為突出，正確率達到 27.8%，開啓並行思考模式後，正確率躍升至 38.7%，刷新了行業 SOTA 紀錄。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366152</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366152</guid>
      <pubDate>Wed, 13 Aug 2025 06:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek App 發佈更新，首次支持對話內容生成分享圖功能</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;8 月 14 日，根據手機應用商店顯示，DeepSeek App 發佈了 1.3.0 版本更新，支持對話內容生成分享圖功能。&lt;/p&gt; 
&lt;p&gt;更新之後，用户的問答對話可以通過原生功能生成圖片，比截圖分享更方便了。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/114037_lReb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，近期有不少傳聞稱，新一代 DeepSeek R2 有望在 8 月 15 日至 30 日期間發佈，該消息日前&lt;a href="https://www.oschina.net/news/365948" target="_blank"&gt;被 DeepSeek 內部人士否認&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;早在今年年初，關於 R2 模型的消息就已開始流傳。當時曾有預測稱，R2 模型將在 3 月 17 日發佈，但這一説法同樣遭到了官方的否認。至今，DeepSeek 尚未正式公佈 R2 模型的具體發佈時間及技術細節，令眾多關注者感到失望。&lt;/p&gt; 
&lt;p&gt;據報道，DeepSeek 團隊今年 6 月曾加緊推進 R2 模型的開發工作。知情人士透露，CEO 梁文鋒對模型的能力仍不滿意，團隊內部仍在進行性能提升，並未準備好正式投用。早期消息稱，DeepSeek 原計劃在 5 月推出 R2 模型，但由於各方面原因，該計劃被延遲。新模型預計將能夠生成更高質量的代碼，並具備用非英語語言進行推理的能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366129</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366129</guid>
      <pubDate>Wed, 13 Aug 2025 03:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>nginx 1.29.1 主線版本發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;nginx 1.29.1&amp;nbsp;主線版現已&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2Fdownload.html" target="_blank"&gt;發佈&lt;/a&gt;&lt;span style="color:#000000"&gt;。具體更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Security： 在 ngx_mail_smtp_module 中使用「none」身份驗證方法時，處理特製的登錄名/密碼可能會導致工作進程內存泄露給身份驗證服務器（CVE-2025-53859）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Change：現在默認禁用 TLSv1.3 certificate compression。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Feature：「ssl_certificate_compression」指令。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Feature：使用 OpenSSL 3.5.1 或更新版本時支持 QUIC 中的 0-RTT。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;錯誤修復：使用 HTTP/2 和「early_hints」指令時，103 響應可能會被緩衝。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;錯誤修復：使用 HTTP/2 時處理具有相等值的「Host」和「:authority」header lines；該錯誤出現在 1.17.9 中。 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;錯誤修復：使用 HTTP/3&amp;nbsp;時處理帶有 port 的「Host」header lines。 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;錯誤修復：無法在 NetBSD 10.0 上構建 nginx。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;錯誤修復：「smtp_auth」指令的「none」參數。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可查看&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2FCHANGES" target="_blank"&gt;CHANGES&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366128/nginx-1-29-1-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366128/nginx-1-29-1-released</guid>
      <pubDate>Wed, 13 Aug 2025 03:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 收購 Humanloop 核心團隊</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Anthropic 近日完成了對 AI 工具平台 Humanloop 核心團隊的收購，這一舉措旨在強化其企業市場戰略。雖然交易具體條款未被披露，但此次收購明顯遵循了科技行業在 AI 人才爭奪戰中日益常見的"人才收購"模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 的三位聯合創始人——CEO Raza Habib、CTO Peter Hayes 和 CPO Jordan Burgess——已全部加入 Anthropic，同時還有約十幾名工程師和研究人員。該平台專注於提示管理、大語言模型評估和可觀測性服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-5f55b40957d7e85d1526c72df79e3fe74ae.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;隨着 Anthropic 在智能體和編程能力方面的領先優勢，該公司在企業市場正快速增長。儘管 Anthropic 發言人確認公司並未收購 Humanloop 的資產或知識產權，但在 AI 行業，真正的價值往往存在於人才的大腦中，這使得資產收購變得相對次要。Humanloop 團隊為 Anthropic 帶來的是幫助企業安全、可靠地大規模運行 AI 系統的豐富經驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Anthropic API 產品負責人 Brad Abrams 表示："他們在 AI 工具和評估方面的成熟經驗對我們繼續推進 AI 安全工作和構建有用 AI 系統將極其寶貴。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在模型質量本身已不足以保持競爭優勢的市場環境下，加強工具生態系統可能幫助 Anthropic 在性能和企業就緒度方面鞏固其相對於 OpenAI 和 Google DeepMind 的領先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 成立於 2020 年，最初是倫敦大學學院的衍生公司。該初創公司隨後參加了 Y Combinator 和 Fuse 孵化器項目，並在兩輪種子融資中籌集了 791 萬美元，投資方包括 YC 和 Index Ventures。Humanloop 在幫助企業客户開發、評估和微調強大 AI 應用方面贏得了良好聲譽，其客户包括 Duolingo、Gusto 和 Vanta 等知名企業。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;上個月，Humanloop 告知客户將關閉服務，為收購做準備。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次人才收購的時機恰逢 Anthropic 向企業客户提供更長上下文窗口等功能，提升了其模型的能力和應用範圍。本週早些時候，Anthropic 與美國政府中央採購部門達成協議，將向行政、司法和立法部門的政府機構銷售 AI 服務，首年每個機構僅收費 1 美元——這明顯是為了與 OpenAI 類似價格的產品競爭。政府和企業買家都需要 Humanloop 專長的評估、監控和合規功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這項收購也符合 Anthropic"安全第一"AI 公司的定位。Humanloop 的評估工作流程通過提供持續的性能測量、安全防護和偏見緩解，與這一使命完全契合。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 前 CEO Raza Habib 在聲明中表示："從創立之初，我們就專注於創建幫助開發者安全有效地構建 AI 應用的工具。Anthropic 對 AI 安全研究和負責任 AI 開發的承諾與我們的願景完美契合。"&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366126</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366126</guid>
      <pubDate>Wed, 13 Aug 2025 03:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：OpenCat：我的造物之旅——從木頭到智能，一個機器生命的誕生</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2123</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2123</guid>
      <pubDate>Wed, 13 Aug 2025 03:26:00 GMT</pubDate>
    </item>
    <item>
      <title>馬斯克 xAI 公司聯合創始人 Igor Babuschkin 離職</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;xAI 聯合創始人 Igor Babuschkin &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fibab%2Fstatus%2F1955741698690322585" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;離職，他在社交媒體發佈了一封感人至深的告別信，回顧了他在 xAI 的非凡歷程，並宣佈將創立 Babuschkin Ventures，專注於 AI 安全研究和支持推動人類進步的 AI 初創公司。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/104112_IXxb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&amp;nbsp;&lt;/span&gt;&lt;span&gt;回憶了與馬斯克的初次會面，兩人就 AI 和未來進行了數小時的深入交流，共同認識到世界需要一傢俱有不同使命的新 AI 公司。&lt;/span&gt;他還提到了 xAI 如何在短短時間內完成了看似不可能的任務——在 120 天內建成 Memphis 超級集羣，以及團隊如何以「瘋狂的速度」推出前沿模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;馬斯克很快回復了這條推文：感謝你幫助建立 @xAI！沒有你就沒有我們的今天。&lt;/p&gt; 
 &lt;p&gt;Igor Babuschkin(@ibab) 回應馬斯克：謝謝你，Elon！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="962" src="https://static.oschina.net/uploads/space/2025/0814/104723_AJtI_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&lt;/span&gt;&amp;nbsp;是 AI 領域的資深研究員，曾在多家頂級 AI 實驗室擔任要職。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;他在德國多特蒙德工業大學（TU Dortmund）學習物理學（2010-2015），期間作為夏季研究生參與了 CERN 大型強子對撞機的 LHCb 實驗研究。&lt;/li&gt; 
 &lt;li&gt;2017 年他轉向機器學習和人工智能領域，加入 DeepMind，擔任高級研究工程師，參與開發了能夠達到《星際爭霸 II》大師級水平的 AlphaStar AI。&lt;/li&gt; 
 &lt;li&gt;2020 年 11 月，他加入 OpenAI，專注於生成模型和代碼生成，參與了 AlphaCode 和大型語言模型的研究。&lt;/li&gt; 
 &lt;li&gt;2022 年他短暫回到 DeepMind 擔任高級研究工程師，專注於擴展 AI 系統並改進推理和生成能力。&lt;/li&gt; 
 &lt;li&gt;2023 年 5 月，Igor 與馬斯克共同創立了 xAI，專注於構建可擴展和可解釋的 AI 系統。他在 Nature 等頂級期刊發表了多篇重要論文，在強化學習、模仿學習和大規模訓練等領域推動了 AI 的進步。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366115</guid>
      <pubDate>Wed, 13 Aug 2025 02:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 告別獨立時代，Gitee 12 年堅守開啓 AI 新程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;深圳北科大廈，幾位外國客人，專注地盯着屏幕上 Gitee 的實操演示，不時還向一旁的中國工程師詢問功能細節，轉眼一小時過去——這一幕發生在 2018 年 10 月開源中國的深圳辦公室，來訪者正是 GitHub 的前兩任 CEO ：Nat Friedman 與 Thomas Dohmke 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;而如今，這兩位熟人走了，開源中國仍在，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;開啓 AI 新程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 兩任 CEO 的東方足跡&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2018 年 10 月，在中國開源年會 COSCon'18 的活動現場，開源中國 COO 徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（現任開源中國 CEO ）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一次見到了 Nat Friedman 。「衣着隨意，一看就是程序員」，是徐勇對這位 GitHub 掌門人的第一印象。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可能是身處一個圈子的好感，徐勇與 Nat Friedman 在第二天討論中國開源生態的閉門會上，聊得格外投機。當 Nat Friedman 得知開源中國也有一款類似 GitHub 的軟件後，頓時來了興趣，當即便和徐勇約定了第二天&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源中國拜訪，於是就出現了開頭的一幕。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那是 2018 年的一個涼爽的上午，一高一矮兩個老外走進了開源中國辦公室。徐勇回憶，上午十點，Nat Friedman 一行就來了。寒暄一陣之後，徐勇作為東道主，向 Nat Friedman 一行講解起了當時的 Gitee 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「 Nat 大高個兒嘛，看屏幕就比較費勁，全程都是勾着腰。但看得出，他對 Gitee 很感興趣，特別是一些功能上的創新——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;或者説，是中國的開發者市場。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彼時，開源歷史上的一個&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;里程碑事件引發全球矚目：GitHub 被微軟以 75 億美元全資收購。GitHub 作為全球最知名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;且&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中立的開源協作平台，被科技巨頭收購之後該何去何從？Nat Friedman 被任命為 CEO 未來又有何動作？外界眾説紛紜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但我們可以知道的是，Nat Friedman 官宣上任後的第一件事，並沒有出現在 GitHub 的辦公室，反而是來到了中國，特別是出現在了開源中國的辦公室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一起觀摩 Gitee 的演示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拜訪的最後，Nat Friedman 團隊其中一人向徐勇遞出了名片，直白地問：「如果我們出錢收購，開源中國賣不賣？」 此人，正是當時 GitHub 的 CTO，也就是後來的第二任 CEO 的 Thomas Dohmke。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對此，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;內心堅定，但周全考慮&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;並沒有明確&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拒絕&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。而在這次深圳會面不久，微軟全球 CEO Satya Nadella 來華，又特地安排了與開源中國馬越&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（現開源中國董事長）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的會面，依舊提及收購事宜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;面對行業巨頭拋來的橄欖枝，開源中國始終堅定選擇&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;獨立發展。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇後來回憶道：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「雖然 2018 年，開源中國也處於業務轉型的陣痛期，在資本市場四處化緣，但將&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本土&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯一的代碼託管平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;拱手讓人&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，中國未來的開源生態又談何自強呢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gitee 得堅持走自己的路，中國特色的路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;正如 Gitee 一開始就定下的基調：致敬 GitHub ，但絕不照搬，始終聚焦「開發者為本」，走出一條貼閤中國開發者需求的特色之路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2 個人，7 年，「他們都離開了」，我們&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依然前行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 11 日，一則消息震動全球開發者社區：GitHub CEO Thomas Dohmke 宣佈辭職，而 GitHub 將結束獨立運營，整體併入微軟 CoreAI 部門，且微軟不再為其尋找新 CEO。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thomas Dohmke 在內部郵件中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提及&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：如今 GitHub 已有超過 10 億個代碼庫與分支，開發者數量突破 1.5 億，以及 Copilot 持續引領蓬勃發展的 AI 市場，擁有 2000 萬用户&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;並&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不斷增長......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-f5820ca29b80620e4822a8dee4106dad2fb.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如此成績的背後，是微軟與 GitHub 以開放的方式續寫開源生態的共生故事：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源開放上，微軟開源 WSL （ Windows Subsystem for Linux ），打破了 Windows 與 Linux 長期以來的生態壁壘，成為連接千萬開發者的技術橋樑；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 產品功能上，開放地收購了 NPM 等工具廠商，使得 Actions 能力變強。GitHub Actions 於微軟時期推出，甚至免費私有倉庫也是在微軟時期才開始提供；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據開放，GitHub 上的公開數據，成為開發者打磨工具、挖掘趨勢、創造新方案的 「原始素材庫」。而在大模型時代，無數聚焦代碼生成、漏洞檢測、自動化開發的大模型與工具，正是以 GitHub 的公開數據為訓練基底;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對開發者生態來説，「開放」是微軟收購 GitHub 之後的一個極為重要的關鍵詞，並且以這樣的開放實現了眾多創舉，其中就有 Copilot 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2021 年，隨着生成式 AI 的崛起，微軟與 OpenAI 合作推出 GitHub Copilot ，正式開啓 AI 編程時代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如今，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Copilot &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;已&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從代碼補全工具，發展成擁有 Copilot Chat&amp;amp;Voice 的對話式編程助手，再到能審查與修復代碼、用 GitHub Spark 構建全棧應用的多模態智能體系統，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-438ee8757571e7fbed84b401bb5e002b19f.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但，亂世何妨缺英豪？儘管 GitHub Copilot 算是第一個在 AI 編程領域顛覆大家認知的產品，但過去這一年多，微軟一定也意識到：在這波 AI 編程浪潮下，旗下的 GitHub 並沒有發揮出其應有的影響力，而 Copilot 則更多地是在給旁人做嫁衣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;正如開源中國 CTO 紅薯評價：「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不僅是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 還包括 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VSC&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ode 。Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 的價值體現在其不止有 1.5 億用户和 10 億倉庫上，還有巨大的流量和用户慣性。但很明顯，很多人已經不買 Copilot 的賬了，説得更誇張一點就是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 在 AI 編程時代&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一開始的首發到現在暫時落後。微軟希望改變現在的這個局面，其核心思路不再&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub+AI&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;，而是 All In AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;結合微軟與 GitHub 目前遇到的危機，曾經的「開放」，也&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;步入「&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;縮緊&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;」。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;相較於 GitHub 在巨頭體系下的戰略調整，Gitee 的發展路徑始終聚焦 「開發者為本」。沒有大廠的資金狂投，卻憑藉 「草根」 式的堅韌，築牢了中國開源創新的基礎設施；沒有急於追逐全球擴張，卻深耕本土土壤，讓每一個功能都貼閤中國開發者的工作場景。這種紮根本土的堅守，讓 Gitee 在開源浪潮中站穩了腳跟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;開源中國 12 年堅守，開啓 AI 新程&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;看到卸任的新聞，回顧 Nat Friedman 、 Thomas Dohmke 與開源中國 2018 年的這段緣分，不禁令人唏噓。7 年時間，他們已經離開&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;這一變動讓不少人感慨開源平台的命運流轉，而在中國，另一個名字卻始終穩健前行 —— Gitee 正以紮根本土的堅守與創新，書寫着屬於中國開源的獨特篇章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;如今的 Gitee ，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;依託對中國開發者協作習慣的深刻理解，已進化為一站式軟件工程平台，支撐起 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;1350w+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;開發者&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;36w+ 企業、2000+ 高校&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的高效協作&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;從代碼託管到項目管理，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;再到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;DevOps 工具鏈，Gitee 的每一&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;次&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;迭代&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;升級&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;都緊扣本土開發者的真實需求 —— &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;讓每一行代碼，都有改變世界的力量&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-b9db8504e1b37af3a2ff6a04ccded8680c4.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當下，AI 浪潮席捲全球，軟件開發正迎來智能化變革。面對這一時代呼喚，開源中國以「與時俱進」的姿態開啓 AI 新程，推出&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面向開發者、終端用户與產業場景的 AI 應用共創平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟（ ai.gitee.com ）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟以全棧技術能力降低 AI 應用門檻，構建三大核心體系：技術基座通過多模態模型庫、國產化算力優化和智能調度實現 「模型即服務」，配合低代碼工具鏈加速開發；服務體系覆蓋全鏈路商業化支持，提供安全合規的存儲認證系統與企業級私有部署方案，推動金融、工業等垂直領域快速落地；開放生態通過 AI 審核分級、開發者收益傾斜和算力補貼機制，形成 "開發 - 反饋 - 迭代" 的創新閉環。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-9cc384e0174003faaf96509e8c548aa12fe.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#7f7f7f"&gt;100 層高樓已完成 90 層，模力方舟建立在 OSChina 與 Gitee 之上&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;12 載的堅守，有心酸、亦光榮！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在中國這片開源生態的土地上，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其實並沒有如微軟這樣的頂級大廠，於資金上的猛烈加持，更多是如 Gitee 、模力方舟這樣的「草根」搭台，一步一個腳印，深耕本土土壤，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;肩負起了中國軟件工程基礎設施建設的重任，築牢了中國開源創新的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;過去十二年，Gitee 以學習為起點，在開源路上步步紮實；未來，Gitee 將以模力方舟為支點，在 AI 工程的新賽道上持續創新。從軟件工程平台到 AI 工程平台，變的是技術形態，不變的是 「全心全意為開發者服務」 的初心。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在開源與 AI 交織的新遠徵中，Gitee 將繼續紮根本土、擁抱世界，以自主創新的中國特色之路，為全球開發者貢獻屬於中國的開源力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4806939/blog/18688139</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4806939/blog/18688139</guid>
      <pubDate>Wed, 13 Aug 2025 02:42:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>智元發佈行業首個機器人世界模型開源平台 Genie Envisioner</title>
      <description/>
      <link>https://www.oschina.net/news/366112</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366112</guid>
      <pubDate>Wed, 13 Aug 2025 02:21:00 GMT</pubDate>
    </item>
    <item>
      <title>Apache RocketMQ EventBridge：為什麼 GenAI 需要 EDA？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;沈林，Apache RocketMQ PMC 成員，阿里雲 EventBridge 負責人，專注於 EDA 研究。本文整理自作者在 Community Over Code Asia 2025 會議發表的主題演講《Apache RocketMQ EventBridge: Why Your GenAI Needs EDA？》。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;EDA 的核心特點是：以事件為中心，實時響應變化。它不像傳統"請求-響應"模式那樣被動等待，而是"感知→觸發→行動"全自動流轉。在 AI 系統中，數據流、模型訓練和推理、外部反饋等都可以作為"事件"，觸發 AI 自動決策和聯動執行。EDA 就像是 AI 時代的"神經系統"，讓 AI 不僅能"思考"，還能"感知"和"行動"。它提升了系統的實時性、靈活性和自動化水平，是構建智能系統的關鍵支撐。AI 賦予系統"大腦"，EDA 構建系統的"神經"。&lt;/p&gt; 
&lt;p&gt;本文主要探討在 AI 時代，EDA 的重要價值及它可以幫助我們解決的問題。&lt;/p&gt; 
&lt;h2&gt;EDA 的第一重價值：通過 RAG 緩解 AI 幻覺&lt;/h2&gt; 
&lt;p&gt;大家可能還有印象，2023 年上半年，Google 的早期 AI 模型發佈時，回答一個關於詹姆斯·韋伯空間望遠鏡的問題時，犯了一個低級"錯誤"，這個答案本來在 Google 上很容易搜索到，但是 AI"一本正經"的給了一個錯誤答案，直接導致谷歌當天的股價跌了 8% 左右。但 AI 完全沒有意識到自己的錯誤，這是為什麼？&lt;/p&gt; 
&lt;h3&gt;1. 為什麼會有 AI 幻覺？&lt;/h3&gt; 
&lt;p&gt;AI 幻覺的產生機制比較複雜，可簡單從訓練和推理兩個階段進行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;訓練階段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;數據覆蓋不足&lt;/strong&gt;：若訓練數據不包含特定信息，模型無法"無師自通"；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;過擬合&lt;/strong&gt;：模型過度學習訓練數據中的細節與噪聲，導致在面對新數據時泛化能力差；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;通用性與精度取捨&lt;/strong&gt;：通用大模型為覆蓋廣泛領域，在特定垂直領域的準確性可能有所犧牲。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;推理階段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;自迴歸生成&lt;/strong&gt;：LLM（大語言模型）推理本質上是一個自迴歸過程，基於現有 Token 預測下一個最可能的 Token，這種概率性生成機制使得幻覺成為其固有潛在分佈的一部分。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;連貫性優先於準確性&lt;/strong&gt;：GenAI 輸出的時候傾向於生成流暢連貫的答案，而非絕對準確的答案。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 如何減少 AI 幻覺？&lt;/h3&gt; 
&lt;p&gt;為瞭解決 AI 幻覺，現在一般有三種主流的方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型微調（Fine-tuning）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;模型不好？最能直接想到的方法就是優化模型：豐富模型訓練的數據、優化模型的參數，讓其在垂直場景領域，回答更加精準。這種方式在很多場景是非常有效的，而且依舊被廣泛採用。但是這種方式，要求也是比較高的，如果沒有一定的人力和算力成本投入，將很難實現。尤其是在知識更新頻繁的領域，模型需要不斷調整，長期維護，投入代價相對較高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞工程（Prompt Engineering）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以不調整模型，而是在向 LLM 提問的時候，把相關的數據和限定條件一起給到 LLM？答案是可以的，這就是提示詞工程。&lt;/p&gt; &lt;p&gt;但是如何構造一個好的提示詞，把 LLM 需要的上下文信息給到它，這個要求也是非常高的。不同人使用，提示詞的構造水平也不同：這種方式就像是把"問問題"變成了一件"手工藝術活"。而且提示詞優化雖然可以"壓平"部分幻覺，但只要模型權重未變，提示詞沒有帶上相關數據，提示詞只能暫時把幻覺"藏"起來，而無法真正去除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;檢索增強生成（RAG）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以自動幫我們生成一個高質量的提示詞呢？在這個提示詞中，包含了 LLM 回答需要的關鍵信息。這個就和我們最後一個要講的 RAG 非常像了，讓我們看下 RAG 到底是什麼。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 什麼是 RAG？&lt;/h3&gt; 
&lt;p&gt;RAG 可以簡單理解為：向 LLM 提問的時候，同時給這個問題，檢索一個上下文，一起給到 LLM。比如：如果我們問 DeepSeek：本次 Apache 峯會有哪些講師聊到了 RAG 這個話題？DeepSeek 肯定不知道，因為它沒有這個數據，網上暫時也還沒有相關數據。但如果給到它一個關於本次大會講師的講稿資料包。這樣 DeepSeek 就有非常強相關的上下文，回答問題的時候，就不會跑題答偏。&lt;/p&gt; 
&lt;p&gt;那 AI 要如何做到這一點呢？主要分兩步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;建立索引&lt;/strong&gt;：首先，需要提前把講師資料包存起來。但資料包可能非常大，我們需要快速找到跟提問的問題相關聯的數據，這裏就需要用到向量化。向量化本質上是對一個事物，從多個特徵維度，進行數值標記。比如，標記我這個人，可以從年齡、身高、性別等多個特徵標記，標記越多越清晰。如果兩個向量在多維空間中的"位置"越接近，説明它們越相似。所以，我們需要提前把數據進行向量化，存到向量數據庫裏。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;檢索生成&lt;/strong&gt;：然後，當我們向 LLM 提問時，可以先把問題向量化，根據向量化後的結果，去向量數據庫查詢關聯性最大的原始知識數據。最後，將查到的知識數據，作為上下文和問題一起傳給 LLM，LLM 就可以給一個更加準確的回答了。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-045b51500f01c2a85c12e955b7cd13f02bc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從這個過程中，我們會發現 RAG 有兩個非常明顯的優點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;不需要用知識庫數據給大模型訓練，既節省了成本，又保證了數據隱私；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不需要用提示詞工程這樣的"手工藝術活"，就可以讓 AI 出現幻覺的概率變得足夠低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 為什麼 EventBridge 適合做 RAG？&lt;/h3&gt; 
&lt;p&gt;為什麼是 EventBridge 適合來做 RAG 呢？ 我們先來看下什麼是 EventBridge：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;EventBridge 的整個模型其實非常簡潔：我們從下圖左側開始往右看，EventBridge 可以方便的把外部的數據，以標準化的事件格式，配合事件 Schema 集成到內部，中間可以存入事件總線（BUS），也可以選擇不存儲，然後通過過濾/轉換，推送到下游服務中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;這個鏈路，正好可以滿足 RAG 過程中需要的三要素：獲取上游豐富的數據、自定義切分和向量化、持久化到多種向量化數據庫中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73b0f09489921a9380a6cf55b6026f0ffb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;5. EventBridge 如何實現 RAG？&lt;/h3&gt; 
&lt;p&gt;用一個場景舉例，比如我們想建一個關於 EventBridge 知識的智能問答機器人，可以回答關於 EventBridge 的常見問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;我們需要把存在上游 OSS 的 EventBridge 文檔，通過 EventBridge 的事件流，進行 Chunk 切分、Embedding 向量化，然後存儲到向量數據庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成之後，當我們向 EventBridge 智能機器人提問"EventBridge 是什麼？"，智能機器人會先把這個問題向量化，然後去向量數據庫查找匹配度最高的相關內容，並一起傳遞給 LLM，LLM 就能結合查到的資料，給出非常精準的回答，減少幻覺產生。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-00e0291ba9dc0a5f24c08e141e6d17ebb3d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，阿里雲大模型服務平台百鍊的知識庫 RAG 場景，已採用 EventBridge 的事件流能力，幫助眾多客户減少了 LLM 問答中的幻覺問題，尤其在細分垂直領域效果顯著。如果您感興趣可以進行體驗：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbailian.console.aliyun.com%2F%3F%26tab%3Dapp%23%2Fknowledge-base" target="_blank"&gt;https://bailian.console.aliyun.com/?&amp;amp;tab=app#/knowledge-base&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;EDA 的第二重價值：推理觸發器（Inference Trigger）&lt;/h2&gt; 
&lt;p&gt;我們第二個想討論的場景是推理觸發器。&lt;/p&gt; 
&lt;h3&gt;1. 程序使用 LLM 的規模將遠超人類&lt;/h3&gt; 
&lt;p&gt;目前，我們日常接觸最多的 LLM 場景是人與 LLM 服務直接對話，如問 DeepSeek 一個問題或智能客服等。 但更常見且增長迅速的方式是程序觸發 LLM。例如供應鏈優化和金融訂單風控。&lt;/p&gt; 
&lt;p&gt;觀察微服務就會發現，人調用 API 的量級遠不如程序調用 API 的量級。相應地，我們可以想象，未來程序觸發 LLM 的規模，也將遠遠超過人工使用 LLM。&lt;/p&gt; 
&lt;p&gt;這其中的機會，我們應該怎麼把握？&lt;/p&gt; 
&lt;h3&gt;2. 推理訴求無處不在&lt;/h3&gt; 
&lt;p&gt;事實上，我們現有的商業系統中，已經存儲了大量現成需要推理的場景。比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;消息服務裏，存儲了客户的評論，需要對其打標分析，這條評論是積極的還是消極的，並給個分數；&lt;/li&gt; 
 &lt;li&gt;DB 裏存儲了產品的描述介紹信息，想讓 AI 給一些產品描述優化建議；&lt;/li&gt; 
 &lt;li&gt;OSS 或 S3 存儲了大量的文檔，想讓 AI 對每個文檔生成一個 100 字的文檔摘要。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些訴求在以前可能需要人工處理，但現在都可以交給 LLM，從而極大提升工作效率。那怎麼讓現有的商業系統，方便、快捷、低成本的使用 AI，甚至不需要寫一行代碼，這個就是 EventBridge 擅長的地方了。&lt;/p&gt; 
&lt;h3&gt;3. 推理觸發器：讓模型被更好地使用&lt;/h3&gt; 
&lt;p&gt;為此，EventBridge 提供了三把武器：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f27bd8eda56c7eb4b1fe2a5c832ff70bbb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第一把武器------實時推理並將結果存到目標端：&lt;/strong&gt; 通過 EventBridge 可以實時監聽並獲取存在 DB、消息、或者存儲服務中的數據，然後實時調用 LLM 推理服務，並將推理結果輸出存到目標端。此過程也可以結合上一部分講到的 RAG，但中間不一定是一個 LLM，也可以是一個 Agent，甚至是一個 AI Workflow。&lt;/p&gt; &lt;p&gt;這個過程看似簡單，但有很多需要注意的地方：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;數據合併&lt;/strong&gt;：我們剛才聊到，LLM 的推理本質上是一個自迴歸過程，這次的輸出會作為下一次的輸入，無法一次性拿到結果，很多 LLM 只能支持以流式的方式返回數據，但下游往往需要的是一個確定性的結果，所以我們需要對流式數據進行合併再輸出；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;數據格式&lt;/strong&gt;：很多業務場景下有明確的格式要求。比如上面提到的例子，讓 LLM 對客户評論打標和評分，需要輸出一個 JSON 結構。但不是所有 LLM 在 API 層面都支持 JSON 結構輸出，我們需要通過提示詞進行優化，讓它儘可能輸出一個符合要求的 JSON 結構。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;推理吞吐&lt;/strong&gt;：LLM 的自迴歸生成方式，導致單次請求 RT 長、TPS 低。所以，我們需要提升高併發能力，把昂貴的 GPU 資源使用效率發揮到極致，同時需要做好 TPM 和 RPM 的限流，也就是每分鐘請求次數和每分鐘 Token 數的限流，以保證鏈路不會有大量限流異常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以看到，具體落地會遇到很多挑戰，但 EventBridge 可以幫助客户便捷高效地解決這些問題。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第二把武器------基於推理結果觸發任務執行：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;除了讓 LLM 推理輸出結果存到目標端，EventBridge 還可以讓 Agent 基於上游的某條消息，去調用某一個 Service，執行某一個動作，如發送郵件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第三把武器------離線異步推理提高資源利用率：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;對於實時性要求不高的推理場景，可以通過 EventBridge 實現離線異步推理，讓稀缺的 GPU 資源被更好地調度利用，在雲上的成本至少比實時推理便宜一半。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 的強大在於其應用，而 EDA（事件驅動架構）非常適合作為推理觸發器，激活 AI 的價值。&lt;/p&gt; 
&lt;h2&gt;EDA 的第三重價值：構建 Agent 通信基礎設施&lt;/h2&gt; 
&lt;p&gt;現在 AI Infra 非常熱門，其概念非常廣泛。對標 IT Infrastructure，我們這裏討論的話題是 AI 的通信。&lt;/p&gt; 
&lt;h3&gt;1. 微服務的通信離不開 Messaging，Agent 間的通信應該如何？&lt;/h3&gt; 
&lt;p&gt;在微服務時代，消息系統在微服務間的通信中扮演了重要角色。到了 AI 時代，消息系統是否依然起着關鍵作用？具體形式和產品又會有哪些變化？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c0ae2c687b84e25b6cf9a437040abeb17d4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;2. Agent 和 Service 的通信：Function Calling、MCP&lt;/h3&gt; 
&lt;p&gt;為了回答這個問題，我們先看下現在 AI 的通信是怎麼做的。&lt;/p&gt; 
&lt;p&gt;首先，我們看下 Agent 和傳統 Service 之間的通信。目前有兩種主流的方式：Function Calling 和 MCP。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Function Calling：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 OpenAI 公司在 2023 年提出的。因為 LLM 本身是文本生成器, 不具備訪問外部系統的能力。但是我們可以對 LLM 進行訓練微調，讓 LLM 理解外部的一些工具函數的定義，這樣在遇到提問時，就可以按需生成這些工具函數需要的參數，然後調用這些工具函數。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 2024 年 11 月 Anthropic 提出的，全稱 Model Context Protocol‌，其本意是用來解決 LLM 無狀態的問題。LLM 每次調用都是獨立的，而 MCP 是用來給 LLM 提供運行上下文，相當於一個"Session 機制"。但是為什麼 MCP 會被拿來和 Function Calling 放在一起呢？因為它也可以拿來調用工具函數。和 Function Calling 不同的是，它不需要 LLM 提前訓練微調來理解函數的入參和返回值，而是通過上下文"提示詞"告訴 LLM 參數返回值。所以 MCP 相比 Function Calling，對模型的依賴更小，更加通用，但效果相比 Function Calling 要差一點。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Agent 和 Agent 的通信：A2A&lt;/h3&gt; 
&lt;p&gt;我們再來看下 Agent 與 Agent 之間是怎麼通信的。&lt;/p&gt; 
&lt;p&gt;Google 在今年 4 月份的時候，提出了一個 A2A 的通訊協議，其核心運行機制分為四步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：Client Agent 通過 Agent Card，看下遠端 Agent 有哪些能力；&lt;/li&gt; 
 &lt;li&gt;第二步：根據 Agent Card 的能力描述，調用遠端 Agent，創建一個 Task，讓其幫忙完成一個任務；&lt;/li&gt; 
 &lt;li&gt;第三步：由於任務可能比較耗時，不一定能夠立即響應。所以 A2A 協議允許遠端 Agent 通過 SSE 協議，不間斷的將任務的狀態信息更新給 Client Agent；&lt;/li&gt; 
 &lt;li&gt;第四步：再將結果返回給 Client Agent，當然結果本身也是可以流式返回的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e2e33909d1e1fa5c7fb16b3509dba8dfa21.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;4. MCP 和 A2A 之間的區別&lt;/h3&gt; 
&lt;p&gt;那 MCP 和 A2A 協議有什麼區別呢？Google 給它們的關係做了一個描述：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;A2A 協議像一種溝通語言：&lt;/strong&gt; 如果把 Agent 比做人，一個人如果能力有限，想讓其他 Agent 幫忙怎麼辦？A2A 協議就可以派上用場了，A2A 協議像一種溝通語言，可以讓 Agent 和其他 Agent 用同一種語言交流，不至於説話的時候驢唇不對馬嘴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP 就像工具使用説明書：&lt;/strong&gt; Service 等價於人使用工具，可以提升人解決問題的能力。不過，使用工具也需要有些技巧，MCP 就像工具使用説明書，可以讓 Agent 更方便的使用這些 Service，來擴展 Agent 的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-538598e9588c1dda1dac99334b8b440c970.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們把 Agent 比做人，把 Service 比做工具。但是，請人幫忙和請工具幫忙，真的可以分得這麼清楚嗎？&lt;/p&gt; 
&lt;h3&gt;5. 預測 1：A2A and MCP 可能走向融合&lt;/h3&gt; 
&lt;p&gt;A2A 和 MCP 的職責，設想很完美，但是實際運行的時候會遇到很多挑戰。我們先來一起看看在 MCP 和 A2A 協議下，兩者用來聲明一個 Agent 或者 Service 能力的時候是怎麼樣的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;這裏舉例了一個"查詢北京天氣"的服務，會發現兩者聲明自己能力的時候，非常類似：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c08367f12deb092a1cccd326b2b3ae2d53a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其次，兩者的傳輸層協議也都非常相似，都支持 SSE 和 JSON-GRPC；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最後，我們從工程師開發角度，推演一個場景：當一個 Agent 需要獲取"查詢天氣"的能力時，它並不真正關心該能力是由一個 Service 還是另一個 Agent 提供的。Agent 的核心關注點在於能力的接口定義：即有哪些可用能力、如何調用，以及預期的返回結果是什麼。至於該能力的後端提供者是 Service 還是 Agent，對於調用方而言是無需關注的實現細節。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這裏我們的第一個預測是：A2A and MCP 未來可能會合並，但具體怎麼發展，還要看生態的選擇。&lt;/p&gt; 
&lt;h3&gt;6. 預測 2: 點對點的通信是不夠的&lt;/h3&gt; 
&lt;p&gt;這裏的第二個預測是：現有 MCP 和 A2A 協議中，只包含的點對點通信是不夠的。按照 A2A 協議的推演，當一個系統中有很多 Agent 時，所有 Agent 都通過"長連接"集成在一起：大家第一個直觀的感受是什麼？&lt;/p&gt; 
&lt;p&gt;連接太多了！ 如果兩個 Agent 通過"長連接"集成在一起，感覺可能也沒有什麼。但是如果一個 Agent 同時需要和數百個甚至上千個 Agent 通信，系統中就會產生大量的長連接。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先對每一個 Agent 來講，資源開銷就非常大；&lt;/li&gt; 
 &lt;li&gt;其次，網狀的連接，一旦某一個 Agent 出現問題，hang 住了某些資源，會不會拖垮其他 Agent 的服務？甚至拖垮整個系統？這類問題在微服務中，再常見不過了。&lt;/li&gt; 
 &lt;li&gt;最後，即使不會被出問題的 Agent 拖垮服務，但當這個出問題的 Agent 恢復時，之前的通訊是否依舊可以繼續追蹤？再次執行，是否已經冪等，是否有風險？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這裏面有非常多的穩定、性能、成本、擴展性的挑戰。這些問題在微服務中已經被多次驗證過，有些經驗我們可以學習過來。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-acaff61d3cd696e4c06caae076daf62ceb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;7. EventBridge Super Agent&lt;/h3&gt; 
&lt;p&gt;基於上面兩個預測判斷，我們給出了一個 RocketMQ EventBridge 的回答: 在這個模型中，我們引入了一個 EventBridge Agent Proxy 的角色。我們姑且稱它為"Super"Agent ，但它不是一個真正的 Agent，而是可以代理 Agent 的能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，所有 Agent 都可以寫一份自己的個人簡歷，把自己擁有的能力，註冊到"Super"Agent 上；&lt;/li&gt; 
 &lt;li&gt;如果某個 Agent 需要調用其他 Agent 的能力，它可以在 "Super" Agent 中查找是否有其需要的 Agent。如果有，就可以直接通過與 "Super" Agent 的交互，來獲得這個能力；&lt;/li&gt; 
 &lt;li&gt;當這個 Agent 需要多個其他 Agent 的能力時，也不需要和每一個 Agent 交互，都可以通過 "Super" Agent 代理實現，將原本的 N:N 模型簡化為 1:1 模型。&lt;/li&gt; 
 &lt;li&gt;除此之外，"Super" Agent 中的 Proxy 除了 A2A 協議，還會路由和跟蹤每一個 Task 的運行狀態，即使在異常/重啓/集羣擴容等場景下，每一個 Task 都能被按預期處理，並把狀態同步回 Agent。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;"Super"Agent 和微服務註冊中心有點類似，不過區別在於，它不光是提供了微服務查找尋址的作用，同時還起到了服務代理的作用。如果我們腦洞再大一點，可以不僅侷限於 Task 級別的任務追蹤和管理，甚至還可以往上考慮一層，提供"User"級別的上下文：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我們現在的 Agent 都是沒有記憶的，我們之前跟它説過的話，過幾天再問它，它就不記得你了。&lt;/li&gt; 
 &lt;li&gt;但是每個人使用工具的習慣是不一樣的。如果 Agent 能更好的理解你，記得你，就可以提供更加人性化的服務。&lt;/li&gt; 
 &lt;li&gt;作為 Agent 註冊和代理中心，如果在為 Agent 提供代理的同時，還能同時提供"User"的上下文，並且用 Agent 的越多，"User"的身份畫像越完善；反過來，Agent 越依賴，進入一個正向循環。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e0b899ea6d8383b99a2a6d186d58bca361a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，EventBridge Agent 代理還處於理論探索階段，歡迎大家一起交流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參考文獻與延伸閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Lewis et al., 2020]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Model Context Protocol (MCP) Specification, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[A2A: Agent-to-Agent Communication Protocol, Google, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apache RocketMQ EventBridge 官方文檔：&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocketmq.apache.org%2F" target="_blank"&gt;https://rocketmq.apache.org/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;2025 杭州·雲棲大會，來了！&lt;/p&gt; 
&lt;p&gt;9 月 24 日至 26 日，杭州·雲棲小鎮&lt;/p&gt; 
&lt;p&gt;三場重磅主論壇&lt;/p&gt; 
&lt;p&gt;超 110 場聚合話題專場&lt;/p&gt; 
&lt;p&gt;40000 平方米智能科技展區&lt;/p&gt; 
&lt;p&gt;點擊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyunqi.aliyun.com%2F2025%2Fticket%3FactivityId%3DNTQ1Ng%3D%3D%26ticketId%3DMTMy%26channelId%3DMzM0NA%3D%3D" target="_blank"&gt;此處&lt;/a&gt;免費註冊領取雲棲大會門票&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18688052</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18688052</guid>
      <pubDate>Wed, 13 Aug 2025 02:11:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>聯想第一財季營收 1362 億元，AI PC 市場份額領先全球</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;聯想集團公佈了截至 2025 年 6 月 30 日的第一財季業績報告，顯示出該公司在多個業務領域的強勁增長。報告顯示，聯想本季度實現營收 1362 億元人民幣，同比增長 22%，創下歷史同期新高。此外，淨利潤也同比增長 22%，達到 28.16 億元人民幣，展現出企業盈利能力的顯著增強。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="528" src="https://oscimg.oschina.net/oscnet/up-eeef33bdab809d7d5055d90415773e9216c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在具體業務表現方面，智能設備業務集團 （IDG） 營收為 973 億元人民幣，同比增長 17.8%。這一業務的運營利潤率為 7.1%。在 PC 業務上，聯想表現尤為突出，同比增長 19%，成為 15 個季度以來的最快增速。值得一提的是，聯想在全球 PC 市場的份額達到了 24.6%，同樣創下歷史新高。同時，AI PC 的出貨量超過整體 PC 出貨量的 30%，在 Windows AI PC 市場中穩居第一。此外，在中國市場，具備五大 AI 特性的 AI PC 佔到了筆記本總出貨量的 27%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在智能手機業務方面，聯想的營收為 162 億元人民幣，同比增長 14%。海外市場的表現也相當強勁，摺疊屏手機的市場份額達到 51%，保持行業領先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基礎設施方案業務集團 （ISG） 的表現同樣亮眼，營收達到 310 億元人民幣，同比增長 35.8%。其中，AI 基礎設施業務的營收同比增長高達 155%，液冷技術方案收入也實現了 30% 的增長，顯示出該領域的良好發展潛力。特別是在中國市場，ISG 的營收同比增長達 76%，運營利潤率提升了 3 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;聯想表示，當前 「超級智能」 正成為全球科技企業的新風口，這與其早前提出的 「混合式 AI」 戰略相一致。聯想在創新方面持續加碼，本季度研發費用同比增長超過 10%，為未來的競爭力奠定了基礎。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366100</guid>
      <pubDate>Wed, 13 Aug 2025 02:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
