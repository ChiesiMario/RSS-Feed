<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 06 Mar 2025 02:47:56 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>2024 圖靈獎得主正式公佈，授予兩位「強化學習」奠基人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日下午，美國計算機協會（ACM）宣佈，Andrew Barto 和 Richard Sutton 榮獲 2024 年 ACM A.M. 圖靈獎，&lt;strong&gt;以表彰他們在強化學習領域奠定的概念與算法基礎&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-00205edcb99f13e1e620c619a6fd55a7438.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，從 20 世紀 80 年代起， Barto 和 Sutton 通過一系列論文提出了強化學習的核心思想，構建了其數學基礎，並開發了關鍵算法，使其成為智能系統研究中最重要的方法之一。&lt;/p&gt; 
&lt;p&gt;值得一提的是，被譽為「強化學習之父」的 Richard Sutton，曾是 Barto 的博士及博士後學生，兩人的師生合作成就了這一領域的基石。&lt;/p&gt; 
&lt;p&gt;目前流行的 ChatGPT 和 DeepSeek 均廣泛使用了強化學習技術。強化學習的應用還涵蓋了多個領域，包括網絡擁塞控制、芯片設計、提升聊天機器人的行為和推理能力以及改進計算機科學中的經典問題。&lt;/p&gt; 
&lt;p&gt;此外，包括 Barto 在內的研究表明，某些強化學習算法實際上是對人腦多巴胺系統運作機制的最佳解釋之一，加深了人類對大腦學習過程的理解。&lt;/p&gt; 
&lt;p&gt;ACM 主席 Yannis Ioannidis 評價表示，Barto 和 Sutton 的貢獻不僅僅是一個過渡階段的成果，而是一個仍在持續發展的領域。強化學習仍在不斷進步，不僅推動計算機科學的發展，也為許多其他學科帶來了無限可能。因此，ACM 授予他們計算機領域最具影響力的獎項。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337195</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337195</guid>
            <pubDate>Thu, 06 Mar 2025 02:45:56 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技在深圳成立新公司</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;企查查信息顯示，深圳天羿科技有限公司於 2025-03-05 成立，法定代表人為周昌慧，註冊資本為 10 萬元。公司經營範圍涵蓋智能機器人的研發、智能機器人銷售、工業機器人銷售、服務消費機器人銷售以及工業機器人安裝等。&lt;/p&gt; 
&lt;p&gt;股東信息顯示，由杭州宇樹科技有限公司全資持股。目前，宇樹科技已對外投資包括上海高羿科技有限公司等 5 家公司。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;216&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/103617_5YT8_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337194</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337194</guid>
            <pubDate>Thu, 06 Mar 2025 02:36:51 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>來自中國，全球第一款通用 AI Agent 產品「Manus」亮相</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日，Manus AI 正式公佈了其「Manus」Agent 產品，而這也是全球第一款通用 Agent 產品。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e610aef907c631d5c6a2ed92027c4579318.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;官網：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmanus.im%2F&quot; target=&quot;_blank&quot;&gt;https://manus.im/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據官方介紹，Manus 這個名字來自拉丁語，Mens et Manus，就是 mind and hand，即手腦並用。&lt;/p&gt; 
&lt;p&gt;Manus 可以解決各類複雜多變的任務，能夠獨立思考、規劃並執行復雜任務，直接交付完整成果。比起 Claude 的 Computer use 等同樣能操作多任務，或者能幫你點外賣訂酒店的 Agent， Manus 可以覆蓋更多領域和達成更高的執行質量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1facceecf781299c016ef6634ec7fe4d146.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-364f58e31a6580fcd1f61d1a2d95c13187c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方公佈的數據顯示，在用於評估通用 AI 助手在解決現實世界問題方面的能力的 GAIA 基準測試中，Manus 在所有三個難度級別上都達到了 SOTA 水平。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7f1f4963c9182eed9305952427fc8dba43f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了確保結果的可重複性，Manus 使用與其正式版本完全一致的配置進行評測。此外，Manus 也在 Upwork、Fiverr 等平台上解決真實世界的問題，並在 Kaggle 競賽中證明瞭自己的能力。&lt;/p&gt; 
&lt;p&gt;Manus 目前採用 Multiple Agent 架構，運行方式與此前 Anthropic 發佈的 Computer Use 類似，&lt;strong&gt;完全運行在獨立虛擬機中&lt;/strong&gt;。同時可以在虛擬環境中調用各類工具——編寫和執行代碼、瀏覽網頁、操作應用等，直接交付完整成果。&lt;/p&gt; 
&lt;p&gt;通過規劃代理、執行代理、驗證代理的分工協作機制，來大幅提升對複雜任務的處理效率，並通過並行計算縮短響應時間。&lt;/p&gt; 
&lt;p&gt;在這個架構中，每個代理可能基於獨立的語言模型或強化學習模型，彼此通過 API 或消息隊列通信。同時每個任務也都在沙盒中運行，避免幹擾其他任務，同時支持雲端擴展。每個獨立模型都能模仿人類處理任務的流程，比如先思考和規劃，理解複雜指令並拆解為可執行的步驟，再調用合適的工具。&lt;/p&gt; 
&lt;p&gt;換言之，通過 Manus 的這套多代理架構，它更像是由多個助理，通過協助的方式，分別完成檢索資源、對接、驗證信息是否有效等工作，來幫你完成整個工作流程——這實際上不僅像是你招了一個「實習生」，更像是直接當上了一個微縮版的「部門主管」。&lt;/p&gt; 
&lt;p&gt;今年晚些時候，官方將計劃開源其中的一些模型，特別是 Manus 的推理（postering）部分。&lt;/p&gt; 
&lt;p&gt;據悉，Manus AI 背後的創始人肖弘是華中科技大學軟件工程專業 2015 屆校友。畢業後，他連續創業，2015 年創立夜鶯科技，推出「壹伴助手」和「微伴助手」，服務超 200 萬 B 端用户，獲騰訊、真格基金等投資。而早期以海外市場為主，用户規模破百萬的 AI 插件領域頭部產品「Monica」也出自肖弘及其團隊。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337193/manus-ai-agent</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337193/manus-ai-agent</guid>
            <pubDate>Thu, 06 Mar 2025 02:31:51 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里發佈全新開源推理模型 QwQ-32B</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲通義千問官方公眾號發文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLnM4lHm1_dGqe-nrmpJhyg&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;，推出最新的推理模型 QwQ-32B。一款擁有 320 億參數的模型，其性能可與具備 6710 億參數（其中 370 億被激活）的 DeepSeek-R1 媲美。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一成果突顯了將強化學習應用於經過大規模預訓練的強大基礎模型的有效性。此外，我們還在推理模型中集成了與 Agent 相關的能力，使其能夠在使用工具的同時進行批判性思考，並根據環境反饋調整推理過程。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我們希望我們的一點努力能夠證明強大的基礎模型疊加大規模強化學習也許是一條通往通用人工智能的可行之路。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;QwQ-32B 在一系列基準測試中進行了評估，測試了數學推理、編程能力和通用能力。以下結果展示了 QwQ-32B 與其他領先模型的性能對比，包括 DeepSeek-R1-Distilled-Qwen-32B、DeepSeek-R1-Distilled-Llama-70B、o1-mini 以及原始的 DeepSeek-R1。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在測試數學能力的 AIME24 評測集上，以及評估代碼能力的 LiveCodeBench 中，千問 QwQ-32B 表現與 DeepSeek-R1 相當，遠勝於 o1-mini 及相同尺寸的 R1 蒸餾模型；在由 Meta 首席科學家楊立昆領銜的「最難 LLMs 評測榜」 LiveBench、谷歌等提出的指令遵循能力 IFEval 評測集、由加州大學伯克利分校等提出的評估準確調用函數或工具方面的 BFCL 測試中，千問 QwQ-32B 的得分均超越了 DeepSeek- R1。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;397&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-edbafede4927e767ad7872d84c7621bdc94.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;大規模強化學習&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開發團隊在冷啓動的基礎上開展了大規模強化學習。在初始階段，特別針對數學和編程任務進行了 RL 訓練。與依賴傳統的獎勵模型（reward model）不同，其通過校驗生成答案的正確性來為數學問題提供反饋，並通過代碼執行服務器評估生成的代碼是否成功通過測試用例來提供代碼的反饋。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;發現在 RL 擴展過程中，隨着訓練輪次的推進，這兩個領域中的性能均表現出持續的提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在第一階段的 RL 過後，開發人員增加了另一個針對通用能力的 RL。此階段使用通用獎勵模型和一些基於規則的驗證器進行訓練。發現，通過少量步驟的通用 RL，可以提升其他通用能力，同時在數學和編程任務上的性能沒有顯著下降。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337189</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337189</guid>
            <pubDate>Thu, 06 Mar 2025 02:20:51 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>周鴻禕評價百度開源：李彥宏非常睿智，也非常老江湖</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;360 集團創始人周鴻禕作為全國政協委員代表，對 DeepSeek 的開源模式進行了闡述。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;周鴻禕認為李彥宏「非常睿智，也非常老江湖」，&lt;strong&gt;周鴻禕稱李彥宏原來是不太認可開源，因為他認為他的模式是接近 OpenAI 的，但他比 OpenAI 更聰明的是及時轉身，宣佈了開源&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;周鴻禕進一步分析稱：「自百度宣佈開源後，阿里巴巴也堅持了開源，在這個氣候下，沒準字節也會開源。一般來説，開源一旦形成氣候，一定能戰勝閉源。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:start&quot;&gt;&lt;span&gt;2 月 14 日，百度宣佈，將在未來幾個月中陸續推出文心大模型 4.5 系列，並於 6 月 30 日起正式開源。此前，李彥宏曾表示，開源其實是一種智商税。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336166&quot; target=&quot;news&quot;&gt;百度將於 3 月 16 日發佈文心大模型 4.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/334659&quot; target=&quot;news&quot;&gt;李彥宏：文心大模型 4.5 系列將開源，是最強大的文心大模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333670&quot; target=&quot;news&quot;&gt;百度宣佈將開源下一代文心大模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333480&quot; target=&quot;news&quot;&gt;百度官宣：文心一言 4 月 1 日起全面免費&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337121</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337121</guid>
            <pubDate>Thu, 27 Feb 2025 11:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>我國 AI 人才缺口達 500 萬人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據央視財經消息，面對目前人工智能技術發展帶來的就業市場變化，不少職場人、準職場人也在為提升自己下功夫。&lt;/p&gt; 
&lt;p&gt;無論是職業教育學校，還是高等院校，都在加速發力更新相關的教學內容和教學模式。業內人士提出，隨着 AI 賦能千行百業，既需要技術和理論創新型人才，也需要能夠結合各行業實際需求的實操型人才。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0305/183110_J8ay_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;專家表示，2024 年，&lt;strong&gt;人工智能整個專業的在校生大概是 4 萬多人，跟整個人工智能領域的人才缺口 500 萬人相比，差距依然很大&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337105</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337105</guid>
            <pubDate>Thu, 27 Feb 2025 10:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里雲創始人王堅：人類正在邁向算力革命</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;作為雲計算技術專家，全國政協委員、中國工程院院士、阿里雲創始人王堅在今年全國兩會上的提案依然圍繞科技創新展開。&lt;/p&gt; 
&lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;王堅院士在接受採訪時指出，以算力為基礎的人工智能正在將人類帶入一個全新的時代。按照王堅的觀點，人類在經歷馬力和電力兩次革命後，正在進入更為重要的算力革命。&lt;/p&gt; 
&lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;摘錄部分採訪內容如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;主持人&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;人們談論現在的一個科技發展都是從第一次工業革命到現在，包括第四次工業革命。那現在我們應該談像雲計算的人工智能等等，會不會將來會帶來第五次的工業革命？同時您會怎麼劃分？&lt;/p&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;王堅院士&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;我們用第一次、第二次、第三第四、第五來講工業革命，還是把這次變革的程度給降低了。第一次我把它叫做馬力的革命，就是當人類可以馴化馬，馬成為我們的動力。所以你看很長時間裏面，事實上一個城市的繁榮程度，是這個城市有多少匹馬決定的。因為有了馬以後就有路，有了路之後就有物資的交流，郵件自然而然也誕生了，所以你可以想象當時倫敦叫做馬糞城是有道理的。&lt;/p&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;第二次我覺得是電力的革命，就是你看紐約就是從電開始，所以愛迪生這些人就出來了，他最後是電力淘汰了馬力。所以我老是會跟做新能源車的人在開玩笑，什麼叫新能源車？就是電力在改造一個最後的傳統行業。本來就應該用電的，你不用，所以在改造你這是我來從電力的角度來看這件事情，所以事實上我們今天的城市文明就是電力文明。你回過頭來再看，馬力留下了一個基礎設施叫道路，電力留下的基礎設施叫電網。你再改新能源，電網沒有改。在算力階段，互聯網就是那個基礎設施，你也可以講是個算力網。&lt;/p&gt; 
 &lt;p style=&quot;color:#101423; margin-left:0; margin-right:0; text-align:start&quot;&gt;所以這三個裏面的本質在哪裏？就是在馬力時代，因為人跑來跑去產生了很多東西，但是不管怎麼樣，它供給是不足的。到電力時代，不管你怎麼講科技進步，最後落到一個關鍵點，就是人類消耗自然資源的能力被大大的增加了。那帶來什麼問題呢？帶來的就是我們今天講的所有的環境的問題。所以這時候就面臨一個很難的問題，就是説我們怎麼能夠達到這樣的生活水平的提升，而不增加自然資源的消耗，我覺得這是算力這次革命可以給我們帶來的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FnOgeaW99QZcU5sZSO59mmw&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/nOgeaW99QZcU5sZSO59mmw&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337101</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337101</guid>
            <pubDate>Thu, 27 Feb 2025 10:23:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高通 CEO 稱新調制解調器性能與蘋果拉開顯著差距</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;高通 CEO 克里斯蒂亞諾·阿蒙（Cristiano Amon）表示，該公司最新款調制解調器將在性能上與蘋果拉開顯著差距。&lt;/p&gt; 
&lt;p&gt;此前，蘋果首次涉足調制解調器技術領域。調制解調器是智能手機連接移動網絡的核心組件。高通是全球最大的調制解調器供應商之一，多年來一直是蘋果 iPhone 的調制解調器主要供應商。&lt;/p&gt; 
&lt;p&gt;然而，2019 年蘋果收購了英特爾的調制解調器業務，計劃效仿其自研手機處理器的模式，自主開發調制解調器。蘋果耗時多年才推出首款自研調制解調器，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/334825/iphone-16e&quot;&gt;並於上月隨 iPhone 16e 低調發布&lt;/a&gt;&lt;/u&gt;。這款蜂窩調制解調器被命名為 C1。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0aa4133f8ce77822f3a124099cf4ec48f2a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本週，高通發佈了最新高端調制解調器 X85。阿蒙在週二接受媒體採訪時，重點強調了 X85 的性能提升，稱其將與蘋果產品形成巨大差距。&lt;/p&gt; 
&lt;p&gt;阿蒙表示：「這是首款集成大量 AI 技術的調制解調器，其性能範圍大幅擴展，能夠處理更微弱的信號。」其稱，「通過對比高通與蘋果的技術能力，這款產品將在高端安卓設備與 iOS 設備的性能表現間拉開巨大差距。」&lt;/p&gt; 
&lt;p&gt;阿蒙重申了此前聲明，預計高通將於 2027 年停止向蘋果供應調制解調器。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337099</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337099</guid>
            <pubDate>Thu, 27 Feb 2025 10:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>上海交通大學發佈 AI 使用新規</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 5 日，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYdVM-cfOnywvaUysSc48Dg&quot; target=&quot;_blank&quot;&gt;上海交通大學發佈 AI 使用最新規範&lt;/a&gt;&lt;/u&gt;，其中明確：&lt;strong&gt;學生應堅持人工智能輔助學習的價值定位，指出學生應瞭解並遵守各項課程的人工智能使用規範，若有相關違規行為，學校將追究相關責任；同時，教師應立足各項教育教學場景，有效治理價值失範現象&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;針對如何規範高校師生 AI 工具的使用，近半年來，滬上多所高校從各個角度做出了探索與規定。&lt;/p&gt; 
&lt;p&gt;2024 年 11 月底發佈的《復旦大學關於在本科畢業論文（設計）中使用 AI 工具的規定（試行）》&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/322579&quot;&gt;提出「六個禁止」&lt;/a&gt;&lt;/u&gt;，對 AI 工具在本科畢業論文（設計）撰寫過程中的使用情況進行了詳細規範；&lt;/p&gt; 
&lt;p&gt;而 2024 年 6 月，華東師範大學與北京師範大學聯合推出了《生成式人工智能學生使用指南》，指出學生在使用 AI 完成學業任務時，必須明確區分 AI 直接生成的內容和個人貢獻的部分，並確保 AI 生成內容不超過全文的 20%。&lt;/p&gt; 
&lt;p&gt;2025 年全國兩會時間，全國人大代表、華東師範大學黨委書記梅兵表示，無論是從外部環境形成的壓力看，還是從內生髮展的動力看，高校積極擁抱 AI 科技，並以此推動學校更好發展是應有之舉。但梅兵同時認為，AI 是在不斷發展過程中的新事物，無論是 AI 科技本身，還是 AI 應用過程中，都還存在很多的問題，甚至是很大的風險，「因此在積極擁抱的同時，也要保持審慎批判的態度，發現問題、警惕風險。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337095</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337095</guid>
            <pubDate>Thu, 27 Feb 2025 10:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>香橙派首款高性能開源 RISC-V 開發板 (OrangePi RV) 即將開售，229 元起</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;香橙派宣佈首款高性能開源 RISC-V 開發板——OrangePi RV 即將開售。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;838&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/175718_rKdk_2720166.png&quot; width=&quot;693&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，OrangePi RV 搭載 RISC-V 四核處理器昉·驚鴻 7110，具備高性能、多功能、低功耗等特點，提供強大的 GPU 處理能力，能進行 3D 圖像渲染，提供 H.264/H.265 視頻編解碼 IP 及 ISP IP，視頻解碼最高達 4K@30fps，並支持 PCIe2.0、千兆以太網、MIPI-CSI、MIPI-DSI、40Pin 擴展接口等常用功能接口，支持 Linux 操作系統。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9c3a2c897f342e18845b91e0d4801c31cd1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a5125ee0c01dd80344ec5ba363b8799891a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-835080093967a50a9529ad0d00b718114c9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;價格方面，2GB 版本創客價 229 元，原價 249 元；4GB 版本創客價 279 元，原價 299 元；8GB 版本 379 元，原價 399 元。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;213&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/175836_nDHB_2720166.png&quot; width=&quot;693&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.orangepi.cn%2Fhtml%2FhardWare%2FcomputerAndMicrocontrollers%2Fdetails%2FOrange-Pi-RV.html&quot; target=&quot;_blank&quot;&gt;詳情查看官網介紹&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337094</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337094</guid>
            <pubDate>Thu, 27 Feb 2025 10:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>上下文感知的聚合頁廣告優化實踐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;聚合頁廣告將商家和優惠信息以多種形式聚合展示給用户，是美團廣告業務中一個重要的業務場景。本文從最能影響用户決策的&quot;發券&quot;和&quot;排序&quot;兩個方向出發，介紹了上下文感知建模在廣告場景的落地方案，證明瞭聚合頁上下文感知的收益空間。希望能對從事相關研究的同學帶來一些啓發或幫助。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0dedc337e569fb2c121dae50753a3404086.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;1 聚合頁廣告&lt;/h2&gt; 
&lt;p&gt;聚合頁廣告是美團一個重要的業務場景，我們將商家和多種優惠以聚合的形式展示給用户。如下圖 1 所示，聚合頁通過多種發券模式吸引用户下單。上下文信息建模是聚合頁實現精準個性化匹配的重要途徑，我們從上下文信息中選擇了最能影響用户決策心智的&quot;發券&quot;和&quot;排序&quot;兩個方向進行了深入探索：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;對於發券，聚合頁下券預算有限，因此如何在&quot;有限的券預算下最大化發券效率&quot;是算法核心要解決的問題。為此，我們建設了一套基於 Uplift 的智能配券策略，並針對 Uplift 建模中遇到的鏈路偏差等技術問題，提出了一種上下文增強的全鏈路 Uplift 建模方法（ECUP，收錄於 WWW2024｜&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2402.03379&quot; target=&quot;_blank&quot;&gt;Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing&lt;/a&gt;）。&lt;/li&gt; 
 &lt;li&gt;對於排序，在預估中除了要考慮廣告本身的信息還需要考慮相鄰展示的其它廣告對其的影響，而精排中的 Point Wise 預估無法建模此類上下文信息。同時，福利 1 和常規自選券兩個模塊各自優化較難實現整個列表的效果最優。在該問題上，我們搭建了跨模塊重排鏈路，提出了利用鄰域列表的重排方法（NLGR，收錄於 WWW2025｜&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2502.06097&quot; target=&quot;_blank&quot;&gt;NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems&lt;/a&gt;）進行 List Wise 預估實現對上下文信息和頁面級最優的建模。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下文實踐一和實踐二將具體介紹我們在這兩項工作中面臨的技術挑戰和創新性解法。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5f71937664717484f1428545ecf7b567.png&quot; alt=&quot;圖 1 聚合頁廣告形態&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;2 實踐一：上下文增強的全鏈路 Uplift 建模方法（ECUP）&lt;/h2&gt; 
&lt;h3&gt;2.1 背景&lt;/h3&gt; 
&lt;p&gt;在電子商務平台的精準營銷實踐中，營銷幹預策略（Treatment）的設計與效果評估是提升用户參與度和商業價值的關鍵環節。常見的幹預手段包括定向廣告、限時折扣和智能優惠券發放等，這些策略通過影響用户行為實現商業目標。作為因果推斷在營銷領域的核心應用，Uplift 模型通過預測個體處理效應（Individual Treatment Effect, ITE）來解決策略效果異質性問題------即量化特定幹預（如某類優惠券）對目標用户的增量轉化效果，從而構建&quot;零資源浪費&quot;的精準營銷系統。&lt;/p&gt; 
&lt;p&gt;與傳統監督學習不同，Uplift 建模本質上是反事實推理問題：需要同時估計用户在幹預組（T）和對照組（C）的潛在結果。現有主流方法採用多響應建模框架，典型代表包括：構建單一特徵映射函數估計各幹預下的條件平均結果的 S-learner，以及在此基礎上的幾個變體，例如 X-learner、T-learner 等，各種深度學習方法以其卓越的特徵提取能力作為 Uplift 框架的基本模型。然而這些方法仍然存在兩個問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;鏈路偏差問題&lt;/strong&gt;：現有的方法在全鏈路建模方面存在不足。在電子商務場景中，用户行為通常遵循一個順序模式：曝光 → 點擊 → 轉化。制定營銷策略時，通常需要整合整個鏈路中多個用户行為的 Uplift 效果。然而，目前的研究大多僅關注鏈內單個任務的 Uplift 得分，忽略了不同任務之間的相互影響。這種片面性會導致結果產生偏差，因為不同的處理方式對每個任務的影響程度是不同的。如下圖所示，在某種特定 Treatment 下，用户可能會表現出點擊率（CTR）提高，但轉化率（CVR）下降的情況，然而最終的點擊到轉化率（CTCVR）仍然是正向的。如果僅依賴於在點擊集合上訓練的 CVR 模型，可能會得出完全相反的結論，從而對後續的營銷決策產生嚴重的誤導。此外，後鏈路任務中的數據稀疏性問題會進一步損害模型的泛化能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e862aca65227e1f56842ef18d865e4f8.png&quot; alt=&quot;圖 2 鏈路偏差&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Treatment 不適應問題&lt;/strong&gt;：Treatment 對用户反應有着顯著的影響，個體在不同的 Treatment 下會表現出不同的行為。例如，我們觀察到在外賣平台上，人羣 1 在獲得高價值優惠券時更傾向於下單，但這一趨勢在人羣 2 中並不普遍。然而，以往的方法通常學習每個特徵的靜態表示，忽略了在不同 Treatment 下對相同特徵的適應性。這種適應性的缺失使得在多種 Treatment 方法中捕捉個體行為差異變得極具挑戰性。儘管一些研究者嘗試利用注意力機制來模擬 Treatment 特徵與非 Treatment 特徵之間的相互作用，但他們主要通過標準化的注意力權重來調整這兩種特徵類型。這種基於向量級的交互方法缺乏靈活性，難以在不同 Treatment 下準確捕捉每個特徵的動態變化及其意義。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為瞭解決上述問題，我們提出了一種上下文增強的全鏈路 Uplift 建模方法（ECUP），旨在提升 Uplift 建模的準確性。&lt;/p&gt; 
&lt;h3&gt;2.2 鏈路偏差分析&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7f84d947af78f938f959bb432a5463e5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據此，我們計算了 CTCVR（曝光空間）和 CVR（點擊空間）的實際 Uplift 值。如下圖所示，CTCVR 和 CVR 在不同段的變化趨勢並不完全一致，這表明不能僅通過點擊集上的 CVR 提升來推斷全鏈路的實際 Uplift。這種現象的主要原因是用户在不同階段的行為關注點不同，導致 Treatment 對行為的影響在鏈路各階段存在差異。因此，我們提出在全鏈路空間中構建 Uplift 模型，並引入任務先驗信息，以精準捕捉 Treatment 對不同任務的影響，從而解決鏈路偏差問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4d0adcc24bfc24629d6114a777eec982.png&quot; alt=&quot;圖 3 隨機分段的 CVR 和 CTCVR 的實際 Uplift 值&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2.3 方法&lt;/h3&gt; 
&lt;p&gt;ECUP 模型整體結構如下圖所示，主要由兩部分組成：1.全鏈路增強網絡 (ECENet)，使用用户的序列模式來估計整個鏈路空間中每個任務的結果，並使用任務增強網絡（TAENet）注入任務先驗信息以實現上下文表徵，捕捉每個任務上的不同 uplift，以避免鏈路偏差的負面影響。2.Treatment 增強網絡（TENet），旨在引導初始特徵的 Treatment 感知細化，並實現不同 Treatment 下 embedding 表徵的 bit 級別自適應調整，以解決 Treatment 不適應問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d82f281f7ffc40fa7079bbbdb619e05b.png&quot; alt=&quot;圖 4 ECUP 架構&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;全鏈路增強網絡（ECENet）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在特定 Treatment 中，個體對不同任務的響應存在差異。此部分的目標是在捕獲任務感知特徵表達，傳統方法通過多個塔來學習多任務目標的方法表達能力有限，無法捕捉 Treatment 對不同任務的不同影響。為此，本文提出任務增強網絡（TAENet, Task-Enhanced Network），以深度融合任務先驗與 Treatment 增強表示（TENet 的輸出），實現上下文增強的參數學習。TAENet 通過個性化選擇和調整 DNN 參數，平衡不同上下文中特徵的稀疏性。&lt;/p&gt; 
&lt;p&gt;具體而言，TAENet 使用門控機制結合任務先驗信息，自適應地獲取 DNN 每層的參數。任務信息作為先驗輸入，通過多頭注意力網絡建模為 Treatment 增強的 Embedding 表徵。為保證初始特徵和 Treatment Embedding 的穩定性，訓練時僅更新任務表徵。在此過程中，任務信息作為注意力網絡中的 Query，而 Treatment 增強表徵作為 Key 和 Value，用於捕獲上下文增強的先驗信息。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//82891471380eed9d480a68c6c3491ce0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;接着，將先驗信息注入到 MLP 結構的門控機制中，門控機制的輸出結果和每個 DNN 塔的每層 (最後一層除外) 結果點乘，實現自適應參數選擇。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f558070334a2fdd74e637772c5d6cc48.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們共享除了各任務最後一層的所有參數。我們在模型訓練中使用 pCTR 和 pCTCVR 來計算整個樣本空間的損失，損失函數為交叉熵：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6538c8c8f7ca914aad172a2f3014fb26.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;參數共享機制顯著降低了數據稀疏性對後續任務的影響，而 TAEGate 模塊則確保模型在共享參數的同時，能夠精準捕捉 Treatment 對每個任務的差異化影響。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Treatment 增強網絡（TENet）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0206a02c7433fe7a1f0cbf1a1363e28.png&quot; alt=&quot;圖 5 TENet 架構&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3ef9bfc6c5cde16644fc9909adc76dac.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;2.4 效果&lt;/h3&gt; 
&lt;p&gt;為了全面評估所提出的方法，我們收集了聚合頁在為期兩個月的優惠券營銷場景中的數據，並按一定比例隨機抽取形成了最終的數據集。該數據集包含多種 Treatment 方法和全鏈路標籤信息，通過隨機對照實驗收集，以確保 Treatment 組和對照組之間的潛在分佈一致，從而消除混雜因子對 Uplift 建模的影響。數據集包含近 550 萬個實例、99 個特徵、Treatment 信息以及兩個標籤：點擊和轉化。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2c4efd62099d508511689c0fa444961c.png&quot; alt=&quot;表 1 數據集的統計&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們在公開數據集和美團數據集上做了實驗，用 AUUC 和 QINI 衡量 uplift 模型效果&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//03cade28b84ed6e78724f1ba34bc511a.png&quot; alt=&quot;表 2 整體性能對比&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，通過消融實驗證明各板塊重要性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fc31d29e737fc508948f8b3e435d9454.png&quot; alt=&quot;表 3 消融實驗&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;最後，我們在業務上進行了 A/B 實驗，取得了顯著的收益。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//491fcf2bd684a9e9aea9e06f7305235e.png&quot; alt=&quot;表 4 在線 AB 實驗&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;3 實踐二：利用鄰域列表的重排方法（NLGR）&lt;/h2&gt; 
&lt;h3&gt;3.1 背景&lt;/h3&gt; 
&lt;p&gt;重排通過重新排列初始排名列表，在現代多階段推薦系統中發揮着至關重要的作用。由於組合搜索空間這樣的固有挑戰，當前的一些研究採用了評估器-生成器範式，生成器生成可行的序列，評估器評估並選擇最佳的序列。然而這些方法仍然存在兩個問題：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;由於生成器和評估器之間的目標不一致問題，生成器傾向於擬合曝光分佈的局部最優解而非排列空間最優。評估器被訓練擬合項目的 List-Wise 評分，而生成器被期望能將排序列表轉換成最優列表。評估器和生成器之間的目的差距導致它們之間的知識傳輸很難，並且在極端情況下導致生成器僅能擬合曝光分佈。&lt;/li&gt; 
 &lt;li&gt;由於忽略了後續項目的信息一一生成目標項目的生成策略難以達到最優。我們的業務特點是包含一鍵領券和常規自選券兩個模塊。這兩個模塊共享候選和預算，極易發生蹺蹺板效應。並且兩個模塊有着迥異的用户行為模式，其中一鍵領券的 CTR 極高，自選券則接近一般的列表推薦。兩個模塊的差別加劇了聯合建模的難度（但我們認為聯合建模的收益空間更大），也加大了主流的自迴歸生成模型的生成難度。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;為瞭解決這些問題，我們提出了一個利用鄰域列表的重排方法（NLGR），旨在提高生成器在組合空間中的生成效果。&lt;/p&gt; 
&lt;h3&gt;3.2 方法&lt;/h3&gt; 
&lt;p&gt;NLGR 遵循評估器-生成器範式，並改進了生成器的訓練方式和生成方式。具體來説，我們使用組合空間中的鄰居列表去增強生成器的訓練過程，使生成器能感知相對分數並找到優化方向。 進一步，我們提出了一種新穎的基於採樣的非自迴歸生成方法，它可以使生成器靈活地從當前列表跳轉至任意鄰居列表。模型結構如下圖所示，左側是評估器，中間是生成器，右側是細節結構。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4b45b62ae67057c8287707e5c2083c5.png&quot; alt=&quot;圖 6 NLGR 架構&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;評估器&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;生成器評估任意一個候選列表。輸入主要包括候選列表和用户歷史 session-level 的行為（其他的特徵沒有列出來），然後經過特徵提取後送入預估層（MLP）進行預估，預估層的輸入包括四部分：j-th 項目的 emb、候選列表的 emb、從用户歷史行為提取出來的用户 emb 和 j-th 的位置 emb。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6ab5721ba9643d95a655986bd54d9fb0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生成器&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;生成器將任意一個候選列表生成為排列空間中的最優列表。生成過程分為 2 步，先從候選列表中決定要替換的位置（PDU），再從剩餘候選項目中挑選出一個項目放入候選列表中（CDU）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;位置決策單元（PDU）輸出每個位置應該被替換的概率。輸入和評估器預估層的輸入一樣，也包括四部分：j-th 項目的 emb、候選列表的 emb、從用户歷史行為提取出來的用户 emb 和 j-th 的位置 emb。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//79776ec2446f896610120ce783a442fc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在訓練時為了保證梯度傳播，用 gumbel-softmax 採樣，得到要替換的位置：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//64b83267024d5055a8ef25d73fc0eeb1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;候選召回單元（CDU）輸出每個候選被召回的概率。輸入仍然和評估器預估層的輸入一樣，也包括四部分：k-th 候選的 emb、mask 掉 j-th 個位置後的候選列表的 emb、從用户歷史行為提取出來的用户 emb 和 j-th 的位置 emb。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2ba8cd1b8028d2d012f064156a345e9c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;同樣的，在訓練時為了保證梯度傳播，用 gumbel-softmax 採樣，得到要插入的候選：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a8312268a47bc0fc97210aa0f5316fcc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;鄰居訓練&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;評估器採用常規的交叉熵損失：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4d86f4ff5d16d710a0f55aa582736344.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;重點在生成器的訓練方式。依次替換候選列表每個位置上的項目，構造鄰居列表，評估鄰居列表的 reward，與候選列表 reward 的相對值作為生成器的 reward：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//83bd17337d97f3c5e97d0fcb00b7bc66.png&quot; alt=&quot;圖 7 NLGR-G 的訓練過程（以長度為 3 的列表為例）&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;鄰居列表的 Reward 也可以用來指引 PDU 的訓練：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b3ea2b2b75e70792fc26e5d1b69f19d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3.3 效果&lt;/h3&gt; 
&lt;p&gt;我們在公開數據集和美團數據集上做了實驗，用 auc 衡量評估器效果，用 hit ratio 衡量生成器效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//d1b92a61a0ba630d8c1a4b95f9a01722.png&quot; alt=&quot;表 5 NLGR 性能對比&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其實我們更加關注生成器的效果，hit ratio 衡量了&quot;生成器能發揮多少評估器的能力&quot;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5f35cd1148fbe4a9ffc133d6f48257d5.png&quot; alt=&quot;表 6 Hit ratio 性能對比&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們在業務上進行了 A/B 實驗，取得了顯著的收益。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2be500cc4e1b0b11bd1e6f0e75826bd1.png&quot; alt=&quot;表 7 在線 AB 實驗&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;4 總結與展望&lt;/h2&gt; 
&lt;p&gt;聚合頁廣告將商家和優惠以多種形式聚合展示給用户，聚合頁的上下文信息建模是實現精準個性化匹配的重要途徑。我們從最能影響用户決策心智的&quot;發券&quot;和&quot;排序&quot;兩個方向進行了深入探索，取得了顯著的收益，證明瞭聚合頁上下文感知的收益空間。未來，我們將繼續深化算法優化。對於發券，我們會探索更高效的反事實去偏方法，減少對隨機樣本的依賴；也會增加考慮券預算浮動並保證券成本穩定的建模。對於排序，我們會探索具有全局視野的生成/評估式方法，克服重排的組合空間搜索難題。此外，LLM 與全鏈路上下文的結合也是未來的探索方向之一。&lt;/p&gt; 
&lt;p&gt;| 關注「美團技術團隊」微信公眾號，在公眾號菜單欄對話框回覆【2024 年貨】、【2023 年貨】、【2023 年貨】、【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bf4b798d5f3f79980dbafb405d74fed6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明&quot;內容轉載自美團技術團隊&quot;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82&quot; target=&quot;_blank&quot;&gt;。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 tech@meituan.com 申請授權。&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/meituantech/blog/17812829</link>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/17812829</guid>
            <pubDate>Thu, 27 Feb 2025 09:53:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Skype 的遺產：面向大眾的端到端加密技術</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&quot;Skype 通話音質極佳，並採用端到端加密技術，安全性極高&quot;，Skype 的主頁在 2004 年如此寫道。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-61e4037196ca5f366b6a0147fa47c779537.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Skype 的加密功能在當時具有革命性和突破性的意義。 20 世紀 90 年代中期，傳奇密碼學家菲爾-齊默爾曼（Phil Zimmermann）創建了&quot;良好隱私&quot;（Pretty Good Privacy，簡稱 PGP）軟件，允許人們通過端到端加密來保護文件或電子郵件的隱私，這意味着只有發送方和接收方可以讀取信息內容。 但是 PGP 非常笨拙，而且並不包含在易於使用的聊天和通話應用中。&lt;/p&gt; 
&lt;p&gt;20 多年後的今天，端到端加密技術已被植入數十億人使用的應用程序中，但他們中的大多數人可能還沒有意識到，他們的信息和通話已通過這種數據加密技術得到了保護。 蘋果的 iMessage 和 FaceTime、Facebook Messenger、Signal 和 WhatsApp 等都默認採用端到端加密技術。&lt;/p&gt; 
&lt;p&gt;但在 2003 年，Skype 是第一個提供這種級別加密和隱私保護的軟件。&lt;/p&gt; 
&lt;p&gt;Skype 推出後，引發了世界各地執法機構的憤怒。 在意大利，負責調查互聯網犯罪的 Polizia Postale（郵政和通信警察）要求小型網絡安全諮詢初創公司 Hacking Team 開發能夠繞過 Skype 加密等窺探功能的手機間諜軟件。&lt;/p&gt; 
&lt;p&gt;多年後，前美國政府承包商愛德華-斯諾登（Edward Snowden）泄露的秘密文件顯示，現在擁有 Skype 的微軟修改了該應用，允許美國國家安全局和其他機構收集通話和信息，有效地破壞了該應用所標榜的加密功能。&lt;/p&gt; 
&lt;p&gt;本週，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/336833/ms-moving-from-skype-to-microsoft-teams&quot;&gt;微軟宣佈將於 5 月 5 日關閉 Skype&lt;/a&gt;&lt;/u&gt;。 目前，Skype 已成為一款邊緣應用。 微軟稱，到 2023 年，Skype 仍有 3600 萬用户，與巔峯時期的 3 億用户相去甚遠。&lt;/p&gt; 
&lt;p&gt;雖然 Skype 已經成為過去式，很快就會停止運營，但 Skype 的技術遺產仍在延續，它為世界上所有最流行的聊天應用程序提供通信安全保障。 得益於 Skype 最初開發者關於隱私的開創性理念，世界變得更加安全、自由。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337089</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337089</guid>
            <pubDate>Thu, 27 Feb 2025 09:52:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Clay —— 高性能的 2D UI 佈局庫</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Clay&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;（ C Layout&lt;/strong&gt;的縮寫）是一個高性能的 2D UI 佈局庫。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;微秒級佈局性能&lt;/li&gt;
&lt;li&gt;類似 Flex-box 的佈局模型，適用於複雜、響應式的佈局，包括文本換行、滾動容器和縱橫比縮放&lt;/li&gt;
&lt;li&gt;單個 ~2k LOC&amp;nbsp;&lt;strong&gt;clay.h&lt;/strong&gt;文件，&lt;strong&gt;無任何&lt;/strong&gt;依賴項（包括無標準庫）&lt;/li&gt;
&lt;li&gt;Wasm 支持：使用 clang 編譯為 15kb 未壓縮的&lt;strong&gt;.wasm&lt;/strong&gt;文件，以便在瀏覽器中使用&lt;/li&gt;
&lt;li&gt;基於靜態競技場的內存使用，無需 malloc / free，總內存開銷較低（例如，8192 個佈局元素約為 3.5mb）。&lt;/li&gt;
&lt;li&gt;類似 React 的嵌套聲明語法&lt;/li&gt;
&lt;li&gt;與渲染器無關：輸出渲染圖元的排序列表，可在任何 3D 引擎中輕鬆合成，甚至可以編譯為 HTML（提供示例）&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;查看&amp;nbsp;&lt;a href=&quot;https://nicbarker.com/clay&quot;&gt;clay 網站&lt;/a&gt;上關於將 clay 編譯為 wasm 並在瀏覽器中運行的示例，或者查看&lt;a href=&quot;https://github.com/nicbarker/clay/tree/main/examples&quot;&gt;示例目錄&lt;/a&gt;中的其他示例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;還可以觀看&lt;a href=&quot;https://youtu.be/DYWTw19_8r4&quot;&gt;介紹視頻&lt;/a&gt;，瞭解 Clay 開發背後的動機以及其使用的簡短演示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/150536_QfGU_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/clay</link>
            <guid isPermaLink="false">https://www.oschina.net/p/clay</guid>
            <pubDate>Thu, 27 Feb 2025 09:44:00 GMT</pubDate>
        </item>
        <item>
            <title>騰訊元寶回應「霸王條款」：最新版本已增加數據管理功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，騰訊元寶因用户協議中知識產權條款的多次修訂引發爭議。&lt;/p&gt; 
&lt;p&gt;有網友發現，在此前的用户協議中，騰訊元寶要求獲取用户上傳的內容以及通過元寶大模型生成內容的一項不可撤銷的、可轉讓的、永久的、免費的許可使用權。此舉被網友們認定為「霸王條款」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1f1a0ced8eb5866cc1894bd6ffab613769d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;▲騰訊元寶 App 舊版本用户協議&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;對此，騰訊元寶官方微博今日發文&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7914117279%2FPh8BBzm7P%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;回應稱&lt;/a&gt;&lt;/u&gt;，大家的意見已經收到，元寶最新版本已增加數據管理功能，新增了體驗優化開關，且默認是關閉的。更新到最新版本後，在設置-數據管理中即可看到這個開關。默認狀態下，用户輸入輸出的內容不會用於模型優化。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1500&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/173050_y61b_2720166.png&quot; width=&quot;1240&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;騰訊元寶表示，針對大家關注的知識產權歸屬問題，用户使用元寶時輸入和輸出的內容，權利歸用户或相應權利人所有，使用元寶並不會改變歸屬。感謝大家的批評與監督。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337083</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337083</guid>
            <pubDate>Thu, 27 Feb 2025 09:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>聯想集團劉軍：中國首批城市超級智能體即將落地</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 世界移動通信大會（MWC 2025）期間，聯想集團執行副總裁兼中國區總裁劉軍透露，由聯想助力打造的中國首批城市超級智能體即將落地湖北宜昌和福建武夷山兩地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-12c6fbcf6b52b8aa3a34db6d8467037631b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;span style=&quot;color:#222222&quot;&gt;（聯想集團執行副總裁兼中國區總裁劉軍）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據瞭解，聯想全棧 AI 戰略包括：一體多端，領跑 AI 終端；一橫五縱，問鼎 AI 基礎設施；一擎三箭，稱雄 AI 解決方案及服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;劉軍表示，在 AI 解決方案及服務方面，聯想建設了智能體「超級工廠」——擎天混合 AI 平台，為企業客户提供包括 DeepSeek 在內的大模型蒸餾、微調、部署和運維服務，幫助客户快速打造企業大模型、部署基於強推理模型的智能體應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過「超級工廠」，聯想正在積極構建聯想城市超級智能體和企業超級智能體解決方案。本月，聯想助力打造的中國首批城市超級智能體即將落地宜昌和武夷山。其中在宜昌，城市超級智能體可實現線上線下結合賦能宜昌中小企業，促進本地經濟發展；在武夷山則因地制宜圍繞當地旅遊產業和茶產業，利用各類智能體的導入以科技賦能涉旅企業和景區。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337069</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337069</guid>
            <pubDate>Thu, 27 Feb 2025 08:50:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>潞晨科技：就近期輿論熱點，已與當事人建立友好溝通</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;「潞晨科技」公眾號今日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fn8SawRgsg7uZBpturaZs_g&quot; target=&quot;_blank&quot;&gt;發文稱&lt;/a&gt;，潞晨科技將集中資源、聚焦高創新業務，&lt;strong&gt;拒絕盲目跟風和低效投入&lt;/strong&gt;，加速核心產品迭代。此外還提到，就近期輿論熱點，&lt;strong&gt;潞晨科技已與當事人建立友好溝通，對任何未來可能的合作持開放態度&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;2740&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0305/162306_D4o7_2720166.png&quot; width=&quot;1406&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;事件回顧：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/336640&quot; target=&quot;news&quot;&gt;DeepSeek 公佈利潤率——引發兩家國產 AI Infra 公司創始人隔空互嗆&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337063</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337063</guid>
            <pubDate>Thu, 27 Feb 2025 08:25:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>前 OpenAI 關鍵研究員因 AI 版權案被傳喚</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前公開的一份&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.courtlistener.com%2Frecap%2Fgov.uscourts.cand.414822%2Fgov.uscourts.cand.414822.373.0.pdf&quot; target=&quot;_blank&quot;&gt;法庭文件顯示&lt;/a&gt;，受 OpenAI 版權案影響，曾幫助該公開發多項關鍵 AI 技術的研究員 Alec Radford 已於 2 月 25 日收到法院傳票，該文件由原告律師提交給美國加利福尼亞州北區地方法院。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;286&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8db70326dd633be0bc563ab9f10d4d3f7ce.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;資料&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F03%2F04%2Fkey-ex-openai-researcher-subpoenaed-in-ai-copyright-case%2F&quot; target=&quot;_blank&quot;&gt;顯示&lt;/a&gt;，Radford 於 2016 年加入 OpenAI，並在去年年底離開 OpenAI 後從事獨立研究，他是 OpenAI 關於&amp;nbsp;&lt;span style=&quot;color:#212623&quot;&gt;generative pre-trained transformers (GPT)&lt;/span&gt; 的開創性研究論文的主要作者。此外，他還參與了該公司 GPT 系列的多個模型以及語音識別模型 Whisper 和圖像生成模型 DALL-E 的開發。&lt;/p&gt; 
&lt;p&gt;這起名為「OpenAI ChatGPT Litigation」的版權案，由 Paul Tremblay、Sarah Silverman 和 Michael Chabon 等書籍作者提起，他們指控 OpenAI 使用他們的作品訓練其 AI 模型，侵犯了他們的版權。原告還認為，ChatGPT 在未註明出處的情況下隨意引用他們的作品，侵犯了他們的版權。&lt;/p&gt; 
&lt;p&gt;去年，法院駁回了原告對 OpenAI 的兩項指控，但允許繼續審理直接侵權訴訟請求。OpenAI 堅持認為，其使用受版權保護的數據進行訓練受到合理使用保護。&lt;/p&gt; 
&lt;p&gt;除 Radford 之外，原告律師還還申請強制要求 Dario Amodei 和 Benjamin Mann 出庭作證；這兩位都是 OpenAI 的前員工，離開公司創辦了 Anthropic。不過這兩人對此持反對態度，稱這些動議過於繁瑣。&lt;/p&gt; 
&lt;p&gt;本週，一名美國地方法院法官裁定，Amodei&amp;nbsp;必須在兩起版權案件（包括美國作家協會提起的一起案件）中就他為 OpenAI 所做的工作接受數小時的審問。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337059/ex-openai-researcher-subpoenaed-in-ai-copyright-case</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337059/ex-openai-researcher-subpoenaed-in-ai-copyright-case</guid>
            <pubDate>Thu, 27 Feb 2025 08:19:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微軟宣佈 Copilot+ PC 支持本地運行 DeepSeek 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs-windows-com.translate.goog%2Fwindowsdeveloper%2F2025%2F03%2F03%2Favailable-today-deepseek-r1-7b-14b-distilled-models-for-copilot-pcs-via-azure-ai-foundry-further-expanding-ai-on-the-edge%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt; Copilot+ PC 正式支持本地運行 DeepSeek 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a90be4cc8e2e7931f3c8df38c2b166e8c2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據官方介紹，微軟通過 Azure AI Foundry 接入 DeepSeek-R1 7B 和 14B 蒸餾模型，為 Copilot+ PC 提供本地運行 7B 和 14B 模型的能力。&lt;/p&gt; 
&lt;p&gt;目前，搭載驍龍 X 平台的 Copilot+ PC 將可以本地運行上述蒸餾模型，而搭載英特爾酷睿 Ultra 200V 和 AMD 鋭龍的 Copilot+ PC 將在後續更新支持。&lt;/p&gt; 
&lt;p&gt;今年 1 月，微軟曾通過引入 Azure Al Foundry 來讓 Copilot+ PC 在本地運行 DeepSeek-R1 的 1.5B 蒸餾版 NPU 優化版模型。&lt;/p&gt; 
&lt;p&gt;微軟表示，Copilot+ PC 中內置的 NPU 專為高效率運行 AI 模型而設計，其能確保 AI 計算的同時，對電池壽命、設備發熱和資源調用的影響降到最小，而本次支持的兩款 DeepSeek-R1 蒸餾模型均可在設備的 NPU 上運行。&lt;/p&gt; 
&lt;p&gt;比較遺憾的是，目前在 Copilot+ PC 本地運行上述模型速度較慢。據微軟公佈的數據顯示，14B 模型的運行速度僅為 8token / 秒，而 1.5B 模型因體積較小，速度能接近 40token / 秒；微軟也表示未來將持續優化模型性能。&lt;/p&gt; 
&lt;p&gt;目前，開發者可以通過 AI Toolkit VS Code 擴展在 Copilot+ PC 上下載和本地運行 DeepSeek 模型的 1.5B、7B 和 14B 版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337057</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337057</guid>
            <pubDate>Thu, 27 Feb 2025 08:14:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>字節跳動開源跨平台 UI 框架 Lynx：一套代碼同時構建多端原生界面</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字節跳動剛剛發佈了最新開源項目 Lynx：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Lynx 是一套幫助 Web 開發者複用現有經驗，通過一份代碼&lt;strong&gt;同時構建移動端原生界面與 Web 端界面的技術方案&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;Lynx 專為多樣化、富交互的場景打造，它有着高性能、多功能的渲染引擎、性能優先的雙線程 UI 編程範式、以及基於 Rust 的現代工具鏈等諸多特性。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5410f4f6fd9900f6e309fc8ba9d10967cf8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Lynx 最具代表性的架構決策之一是&lt;strong&gt;靜態強制劃分&lt;/strong&gt;用户腳本的運行環境，將用户腳本拆分跑在了兩個獨立的運行時上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flynxjs.org%2Fzh%2Fguide%2Fspec.html%23main-thread-or-lynx-main-thread&quot; target=&quot;_blank&quot;&gt;主線程&lt;/a&gt;運行時，它由&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flynx-family%2Fprimjs&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;PrimJS&lt;/strong&gt;&lt;/a&gt;這個專為 Lynx 優化的 JavaScript 引擎驅動，有着獨享的同步 UI 操作權限，用於處理初始啓動和高優事件處理等任務&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flynxjs.org%2Fzh%2Fguide%2Fspec.html%23background-thread-aka-off-main-thread&quot; target=&quot;_blank&quot;&gt;後台&lt;/a&gt;運行時，作為用户代碼的默認執行環境，以確保主線程的低負載和非阻塞。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這一架構帶來了 Lynx 的兩大殺手鐧：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flynxjs.org%2Fzh%2Fguide%2Finteraction%2Fifr.html&quot; target=&quot;_blank&quot;&gt;首幀直出 (Instant First-Frame Rendering，IFR)&lt;/a&gt;&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nngroup.com%2Farticles%2Fresponse-times-3-important-limits%2F&quot; target=&quot;_blank&quot;&gt;用研表明&lt;/a&gt;：如果渲染足夠快（而 Lynx 正是如此），那麼在界面過渡時就無需多餘的反饋。Lynx 通過短暫阻塞主線程，確保首幀一次性完整呈現，因為用户不會看到空白，可以給用户帶來一種即刻響應的感知體驗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flynxjs.org%2Fzh%2Freact%2Fmain-thread-script.html&quot; target=&quot;_blank&quot;&gt;主線程腳本 (Main Thread Script，MTS)&lt;/a&gt;&lt;/strong&gt;：它是一小段靜態調度的代碼，被授予在主線程運行的權力，用於處理高優的事件和手勢行為，非常適合那些要求極致跟手、快速響應的場景，以實現原生交互觸感。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flynx-family%2Flynx&quot; target=&quot;_blank&quot;&gt;https://github.com/lynx-family/lynx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;開源公告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flynxjs.org%2Fzh%2Fblog%2Flynx-unlock-native-for-more&quot; target=&quot;_blank&quot;&gt;https://lynxjs.org/zh/blog/lynx-unlock-native-for-more&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337035</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337035</guid>
            <pubDate>Thu, 27 Feb 2025 06:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>法官駁回馬斯克阻止 OpenAI 營利轉型的請求</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-05%2Fmusk-fails-to-block-openai-restructuring-plans-in-court-fight&quot; target=&quot;_blank&quot;&gt;彭博社&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息稱，美國北加州一名聯邦法官駁回了埃隆-馬斯克（Elon Musk）的禁令申請，該禁令旨在阻止 OpenAI 按計劃轉型為一家營利性公司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該地區法院法官 Yvonne Gonzalez Rogers 裁定，馬斯克未能提供足夠的必要證據來申請禁令。不過，該法官表示，法院準備僅根據 OpenAI 的轉型計劃不合法這一主張進行快速審理，並指出：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&quot;當公眾的錢被用來資助一家非營利性公司轉型為營利性公司時，就會造成無法彌補的傷害。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;297&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-867b6ddb6870cea365302af210c52cde333.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這項裁決標誌着馬斯克對 OpenAI 及其首席執行官 Sam Altman 的訴訟出現了最新轉機：馬斯克指控該公司放棄了其最初的非營利使命，即向所有人提供 AI 研究成果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;就在幾周前，馬斯克主動提出以 974 億美元收購 OpenAI，但遭到 OpenAI 董事會的一致拒絕。儘管如此，科技媒體 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F03%2F04%2Fjudge-rejects-musks-attempt-to-block-openais-for-profit-transition%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch&lt;/a&gt; 認為，隨着 OpenAI 試圖採用更傳統的公司結構，這一收購要約可能會在未來給 OpenAI 帶來麻煩。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337031/musks-block-openais-profit-transition-judge-rejects</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337031/musks-block-openais-profit-transition-judge-rejects</guid>
            <pubDate>Thu, 27 Feb 2025 06:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>