<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 18 Sep 2025 07:44:38 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>阿里雲爆款雲服務器 68 元/年，2 核 2G 限時秒殺，超高性價比，立即搶購！</title>
      <description>覆蓋 90%+通用業務場景，組合購買「專享活動價」。</description>
      <link>https://click.aliyun.com/m/1000406832/</link>
      <guid isPermaLink="false">https://click.aliyun.com/m/1000406832/</guid>
      <pubDate>Thu, 18 Sep 2025 07:32:50 GMT</pubDate>
    </item>
    <item>
      <title>螞蟻百靈大模型團隊開源高性能推理 MoE 模型 Ring-mini-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻百靈大模型團隊正式發佈 Ring-mini-2.0，一款基於 Ling-mini-2.0 架構深度優化的高性能推理型 MoE 模型（Thinking model）。&lt;/p&gt; 
&lt;p&gt;它在總參數量 16B、僅激活 1.4B 參數的情況下，即可達到 10B 級別以下 dense 模型的綜合推理能力，尤其在邏輯推理、代碼與數學任務中表現卓越，並支持 128K 長上下文及 300+ token/s 的高速生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="550" src="https://static.oschina.net/uploads/space/2025/0918/151311_MTTi_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 以 Ling-mini-2.0-base 為基礎繼續訓練，經過 Long-COT SFT、更穩定持續的大規模 RLVR 以及 RLHF 聯合優化，顯著提升了複雜推理的穩定性與泛化性。在多項高難度基準（LiveCodeBench、AIME 2025、GPQA、ARC-AGI-v1 等）中，在輸出長度相當的情況下，性能顯著超越 10B 以下 dense 模型，甚至媲美更大參數量的 MoE 模型（如 gpt-oss-20B-medium），在邏輯推理方面尤為突出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/151413_jqOH_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 已全面開源，模型權重、訓練策略與數據配方將全部開放。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ring-mini-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ring-mini-2.0&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372966</guid>
      <pubDate>Thu, 18 Sep 2025 07:16:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻百靈大模型團隊開源 MoE 大模型 Ling-flash-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻百靈大模型團隊正式開源其最新 MoE 大模型 ——Ling-flash-2.0。&lt;/p&gt; 
&lt;p&gt;作為 Ling 2.0 架構系列的第三款模型，Ling-flash-2.0 以總參數 100B、激活僅 6.1B（non-embedding 激活 4.8B）的輕量級配置，在多個權威評測中展現出媲美甚至超越 40B 級別 Dense 模型和更大 MoE 模型的卓越性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150130_epe3_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="634" src="https://static.oschina.net/uploads/space/2025/0918/150203_ryAo_2720166.jpg" width="1000" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Ling-flash-2.0 在僅激活 6.1B 參數的前提下，實現了對 40B Dense 模型的性能超越，&lt;strong&gt;用最小激活參數，撬動最大任務性能&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為此，團隊在多個維度上 「做減法」 也 「做加法」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1/32 激活比例：每次推理僅激活 6.1B 參數，計算量遠低於同性能 Dense 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;專家粒度調優：細化專家分工，減少冗餘激活&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;共享專家機制：提升通用知識複用率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sigmoid 路由 + aux-loss free 策略：實現專家負載均衡，避免傳統 MoE 的訓練震盪&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MTP 層、QK-Norm、half-RoPE：在建模目標、注意力機制、位置編碼等細節上實現經驗最優&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150338_KdT0_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最終結果是：6.1B 激活參數，帶來約 40B Dense 模型的等效性能，實現 7 倍以上的性能槓桿。&lt;/p&gt; 
&lt;p&gt;Ling-flash-2.0 基礎版與對話版模型已同步上架 Hugging Face 與 ModelScope，採用 MIT 協議可商用。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ling-flash-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ling-flash-2.0&lt;br&gt; GitHub：https://github.com/inclusionAI/Ling-V2&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372964</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372964</guid>
      <pubDate>Thu, 18 Sep 2025 07:07:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>擁抱新一代 Web 3D 引擎，Three.js 項目快速升級 Galacean 指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互聯網前端團隊- Su Ning&lt;/p&gt; 
 &lt;p&gt;本文從多個維度對比 Galacean 和 Three.js 兩款 Web3D 引擎的差異，並介紹擬我形象項目從 Three.js 切換到 Galacean 以後帶來的提升以及項目遷移的心得，為其他 Three.js 項目升級到 Galacean 提供參考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分鐘看圖掌握核心觀點👇&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-844825cdee521dcf0dd15502276e842fe65.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;Web 3D 技術的發展日新月異，為我們帶來了前所未有的沉浸式體驗。從虛擬展示到遊戲開發，從建築可視化到教育模擬，Web 3D 技術的應用場景愈發廣泛。而在這一領域，Three.js 作為一款廣受歡迎的 JavaScript 3D 庫，憑藉其簡潔易用的 API 和豐富的功能，幫助眾多開發者實現了精彩的 3D 項目。&lt;/p&gt; 
&lt;p&gt;然而，隨着項目複雜度的不斷提升，以及用户對性能和體驗要求的日益苛刻，Three.js 逐漸顯露出一些侷限性。比如在處理重負載時，很容易遇到性能瓶頸，出現卡頓、掉幀等問題。這就如同一位經驗豐富的車手，駕駛着一輛曾經性能卓越的賽車，但在面對愈發複雜的賽道和激烈的競爭時，卻發現車輛的動力和操控性漸漸力不從心。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、Galacean：新一代 Web 3D 引擎&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 業務簡介&lt;/h2&gt; 
&lt;p&gt;擬我形象是 vivo 賬號中的一個 3D 數字人功能，提供一種代表自由、個性、創新和時尚的虛擬形象，為用户提供更加生動、直觀、有趣的交流方式。採用 Native+H5 混合的開發方式，其中 3D 渲染的部分基於 Three.js 進行開發。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 技術挑戰與痛點&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能瓶頸：&lt;/strong&gt;人物模型包含大量形態鍵以實現多樣化面部特徵，導致模型加載解析耗時過長。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;線程阻塞：&lt;/strong&gt;受限於 JS 單線程特性，模型解析過程會造成頁面短暫無響應。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模型渲染：&lt;/strong&gt;套裝切換等場景下，多個模型同時渲染時性能問題尤為突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;陰影優化：&lt;/strong&gt;Three.js 的陰影渲染性能消耗大，不得不通過局部陰影和限制捕捉範圍等折中方案來平衡畫質與性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Galacean 引擎核心優勢&lt;/h2&gt; 
&lt;p&gt;Galacean 是一款開源的 Web 遊戲引擎，致力於打造一個開放、易用、高效的遊戲開發工具，可以通過在線編輯器或者純代碼的形式進行使用。&lt;/p&gt; 
&lt;p&gt;針對現存的技術挑戰與痛點，Galacean 做了深度優化：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;多線程處理：&lt;/strong&gt;採用 Worker 避免主線程阻塞。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;移動端適配：&lt;/strong&gt;對大量常量進行近似取值優化，完美適配移動端。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能突破：&lt;/strong&gt;優化數據傳輸鏈路，創新緩存設計，顯著降低重負載場景下的卡頓現象。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7e8fd35268a9e4e6807d7a59d98c296eab.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對比視頻 1：加載速度&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-b7b3c633bc729e87048a7e7cbbd4c6374b4.gif" width="240" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對比視頻 2：套裝切換&lt;/p&gt; 
&lt;p&gt;此外，Galacean 基於 EC（Entity-Component）架構設計，而非 Three.js 的面向對象，大幅提升了開發的靈活性。&lt;/p&gt; 
&lt;p&gt;近期我們將渲染引擎由 Three.js 切換為 Galacean。這一舉措不僅解決了頁面卡頓問題，還提升了瀏覽器兼容性（可支持到 chrome82），幀率表現更出色，畫面質感也得到顯著改善。整體切換過程較為平滑，但也遇到了一些問題。接下來，將與大家分享此次整體升級的相關經驗。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;三、調優過程&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;任務拆解：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;作為一個數字人項目，涉及到引擎升級的模塊大致有&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;①環境初始化&lt;/strong&gt;（場景、相機、光線、引擎設置）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 模型加載&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;骨架獲取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;材質獲取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動畫獲取&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;③妝容、穿搭還原&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;形態鍵修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;貼圖、顏色修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型替換&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;頭像（靜態頭像、動態頭像）導出&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;壁紙（靜態壁紙、動態壁紙、視差壁紙）導出&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;經過梳理，可以大致分為四類：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;初始化&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;模型加載&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;素材替換&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;動畫狀態&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;接下來我們對這幾個部分進行分別的處理&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 初始化&lt;/h2&gt; 
&lt;p&gt;有別於 Three.js 的渲染器創建，Galacean 的 engine 初始化是異步方法，所以後續用到用到 engine 的地方需要考慮加載的時序，以及 engine 存在狀態的判斷。另外，Three.js 中 renderer 的渲染行為需要手動調用，一般是使用 requestAnimationFrame 循環調用，而 Galacean 則不需要，引擎開始渲染只需要調用一次 engine.run 即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;renderer=new&amp;nbsp;THREE.WebGLRenderer({
&amp;nbsp;&amp;nbsp;alpha:&amp;nbsp;true,
&amp;nbsp;&amp;nbsp;antialias:&amp;nbsp;true,
})
document.body.appendChild(renderer.domElement)
const&amp;nbsp;scene =&amp;nbsp;new&amp;nbsp;THREE.Scene()
const&amp;nbsp;camera =&amp;nbsp;new&amp;nbsp;THREE.PerspectiveCamera(15,&amp;nbsp;window.innerWidth/window.innerHeight,&amp;nbsp;0.1,&amp;nbsp;100)
requestAnimationFrame(function&amp;nbsp;render() {
&amp;nbsp; renderer.render(scene, camera)
&amp;nbsp;&amp;nbsp;requestAnimationFrame(render)
})&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;engine =&amp;nbsp;await&amp;nbsp;WebGLEngine.create({
&amp;nbsp; canvas,
&amp;nbsp;&amp;nbsp;physics:&amp;nbsp;new&amp;nbsp;LitePhysics()
})
engine.run()&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中，尺寸單位統一以米為基準，無需額外進行特殊處理。不過在角度單位的使用上存在差異：Three.js 裏，僅相機的 fov（視場角）採用角度單位，其他涉及角度的參數均以弧度計量；而 Galacean 則採用更為統一的設定，所有角度相關單位均為角度。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
camera.fov =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&amp;nbsp;* Math.PI/180

/** Galacean */
camera.fieldOfView =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中顏色的設置更加靈活，可以使用 16 進制或者 RGB 值來進行賦值，但是在 Galacean 中只能通過 RGB 來進行賦值，且有別於 0-255 的取值範圍，Galacean 中的顏色範圍是 0-1。從 Galacean1.5 版本開始，默認的色彩空間改為線性，在代碼中需要手動轉換一下。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
directLight.color=0xffffff
directLight.intensity=0.9

/** Galacean */
const&amp;nbsp;color =&amp;nbsp;new&amp;nbsp;Color(0.9,&amp;nbsp;0.9,&amp;nbsp;0.9,&amp;nbsp;1)
color.toLinear(color)
directLight.color = color&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 模型加載&lt;/h2&gt; 
&lt;p&gt;對於包含大量形態鍵和動畫的模型，將模型打成 zip 包可以有效的壓縮模型的體積，不論是 Three.js 還是 Galacean 都不支持加載 zip 包，但是我們可以自行擴展模型加載的鏈路，將 zip 下載後解壓出的模型獲取 ObjectUrl 再放到各自的加載器中加載，這樣加載進度的獲取也可以進行自定義，不需要進行額外的改造。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;exportclassModelLoader {
&amp;nbsp;&amp;nbsp;engine:&amp;nbsp;WebGLEngine
&amp;nbsp;&amp;nbsp;constructor(engine: WebGLEngine){
&amp;nbsp; &amp;nbsp;&amp;nbsp;this.engine&amp;nbsp;= engine
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;async&amp;nbsp;load(src:&amp;nbsp;string) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;url =&amp;nbsp;await&amp;nbsp;fileLoader(src)
&amp;nbsp; &amp;nbsp; returnthis.engine.resourceManager.load&amp;lt;GLTFResource&amp;gt;({
&amp;nbsp; &amp;nbsp; &amp;nbsp; url,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;type:&amp;nbsp;AssetType.GLTF
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Three.js 解析 glTF 模型輸出的數據結構較為簡單，主要使用模型的場景和動畫片段。由於後續需針對特定材質進行替換，所以要根據節點名獲取特定節點，再取出節點中的材質信息，模型的骨架也通過這種方式獲取。而 Galacean 輸出的數據更為全面，除動畫片段和實體信息外，模型中使用的材質、貼圖、蒙皮和網格信息也會分門別類展示，需要對應內容時直接獲取即可，相比 Three.js 更加方便。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 素材替換&lt;/h2&gt; 
&lt;p&gt;素材替換如上文總結分為四種，分別是顏色、貼圖、形態鍵和模型的替換，顏色設置我們在初始化中已經講解，而模型加載和展示也沒有特別的內容，無非是節點/實體的添加和移除，這裏我們講下貼圖和形態鍵修改的一些 tips。&lt;/p&gt; 
&lt;p&gt;在 Three.js 中修改材質貼圖 map 可以直接直接使用 canvas 或者 image，修改後需要將材質 needsUpdate 屬性設置為 true。而在 Galacean 需要先將圖片加載為 texture，再進行賦值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
material.map=canvas
material.needsUpdate =&amp;nbsp;true

/** Galacean */
const&amp;nbsp;texture: Texture2D = await engine.resourceManager.load({
&amp;nbsp; url,
&amp;nbsp;&amp;nbsp;type: AssetType.Texture2D
})
material.baseTexture = texture&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中修改形態鍵，可以先通過網格中的 morphTargetDictionary 屬性獲取到需要修改的形態鍵的索引，然後修改 morphTargetInfluences 中對應索引的值即可。&lt;/p&gt; 
&lt;p&gt;在 Galacean 中網格渲染器中沒有存儲形態鍵的索引信息，而是存儲在 MeshRenderer 下的 mesh 屬性下的 blendShapes 屬性中，通過獲取對應名稱的形態鍵在數組中的索引，修改網格渲染器中 blendShapeWeights 屬性對應下標的值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
const&amp;nbsp;index = morphTargetDictionary[keyName]

if&amp;nbsp;(index !==&amp;nbsp;undefined) {
&amp;nbsp; mesh.morphTargetInfluences[index] = value
}

/** Galacean */
const&amp;nbsp;blendShapes = skinMeshRenderer.mesh.blendShapes
const&amp;nbsp;index = blendShapes.findIndex(i=&amp;gt;i.name===keyName)
if&amp;nbsp;(index &amp;gt; -1){
&amp;nbsp; skinMeshRenderer.blendShapeWeights[index] = value
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;3.4 動畫&lt;/h2&gt; 
&lt;p&gt;相較於 Three.js 的 AnimationMixer 和 AnimationClip，Galacean 擁有更加完善的面向組件的動畫系統，支持，狀態機、混合動畫、時長壓縮等，不同動畫之間的切換與播放更加簡單易維護。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js 播放動畫片段 */
const&amp;nbsp;mixer =&amp;nbsp;new&amp;nbsp;THREE.AnimationMixer(scene)
const&amp;nbsp;action=mixer.clipAction(avatarClip)
action.play()
ticker.addEvent(delta =&amp;gt; {
&amp;nbsp; mixer.update(delta)
})

/** Galacean 添加狀態機，播放完成回到待機狀態 */
const&amp;nbsp;animationState = animator.findAnimatorState('action')
const&amp;nbsp;idleStatle = animator.findAnimatorState('idle')
const&amp;nbsp;transition =&amp;nbsp;new&amp;nbsp;AnimatorStateTransition()
transition.duration =&amp;nbsp;1
transition.offset =&amp;nbsp;0
transition.exitTime =&amp;nbsp;1
transition.destinationState = idleStatle
animationState.addTransition(transition)
animator.play('action')&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;四、結語&lt;/h1&gt; 
&lt;p&gt;Galacean 的出現，無疑為 Web 3D 開發領域帶來了新的活力。它不僅解決了 Three.js 等傳統技術在性能和功能上的諸多痛點，還以其卓越的性能、豐富的功能和易用性，為開發者打開了一扇通往更廣闊創意空間的大門。&lt;/p&gt; 
&lt;p&gt;需要注意的是，Galacean 不同版本之間的 API 差異較大，需要進行甄別，同時開發文檔及相關的案例也需要進一步完善。&lt;/p&gt; 
&lt;p&gt;對於全新的項目，Galacean 提供編碼或在線編輯器兩種方式保障創意的高效落地，詳細的文檔和案例也便於接觸 Web3D 開發的新人快速上手。&lt;/p&gt; 
&lt;p&gt;對於存量的項目，Galacean 的遷移成本不高，且整個過程平滑可控，能夠有效提升現有項目的畫面表現和性能。為未來複雜度更高的需求提供性能保障。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18692286</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18692286</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:50 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>華為發佈全球首個通算超節點</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在華為全聯接大會 2025 上，華為輪值董事長徐直軍正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huawei.com%2Fcn%2Fnews%2F2025%2F9%2Fhc-lingqu-ai-superpod" target="_blank"&gt;發佈&lt;/a&gt;了全球首個通算超節點華為 Taishan 950 SuperPoD，計劃 2026 年一季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直軍稱，其將能夠徹底取代各種應用場景的大型機和小型機以及 Exadata 數據庫一體機，將成為各類大型機、小型機的終結者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-24f09fe6e041b3140f61e7f0fa4a12dc091.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直軍指出：「算力過去是，未來也將繼續是人工智能的關鍵，更是中國人工智能的關鍵」。他認為，超節點在物理上由多台機器組成，但邏輯上以一台機器學習、思考、推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，華為發佈的最新超節點產品 Atlas 950 SuperPoD，算力規模 8192 卡，預計於 2026 年四季度上市。Atlas 960 SuperPoD 算力規模 15488 卡，預計 2027 年四季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基於超節點，華為同時發佈了全球最強超節點集羣，分別是 Atlas 950 SuperCluster 和 Atlas 960 SuperCluster，算力規模分別超過 50 萬卡和達到百萬卡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372960</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372960</guid>
      <pubDate>Thu, 18 Sep 2025 06:57:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 瀏覽器 Comet 將原生集成密碼管理工具 1Password</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;1Password &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F1password.com%2Fpress%2F2025%2Fsep%2Fperplexity-partnership" target="_blank"&gt;宣佈&lt;/a&gt;與 Perplexity 達成合作，將在 AI 瀏覽器 Comet 中集成 1Password 的密碼管理與自動填充功能。Comet 用户可通過 1Password 瀏覽器擴展實現安全登錄、加密存儲及跨設備同步，提升 AI 驅動瀏覽體驗的安全性與便利性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-21e22de7314980f639afcbb6525a5fa2315.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為 Comet 的首個安全合作伙伴，1Password 提供端到端加密與零知識架構，確保用户隱私不被泄露，同時支持快速生成和保存強密碼、2FA 驗證及無縫設備間同步。&lt;/p&gt; 
&lt;p&gt;Perplexity 首席商務官 Dmitry Shevelenko 稱，AI 瀏覽的高效體驗必須建立在安全之上，而 1Password 的隱私、透明度與可用性優勢使其成為理想合作伙伴。雙方合作的目標是為用户打造「既強大又安全」的互聯網體驗 。&lt;/p&gt; 
&lt;p&gt;根據安排，現有 1Password 用户將收到郵件邀請，可優先體驗 Comet 瀏覽器。1Password 強調，未來將繼續擴展在 AI 場景中的安全應用，幫助用户在智能化時代安全高效地使用互聯網。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372959</guid>
      <pubDate>Thu, 18 Sep 2025 06:48:50 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>國內 500 強企業 GenAI 採用率達 74.6%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;市場調研機構 Omdia 發佈《中國企業 GenAI（生成式 AI）採用格局，2025H1》報告指出，超 7 成的《財富》中國 500 強企業已採用 GenAI。報告稱，當前中國 GenAI 正處於高速滲透和規模化應用階段，本土雲廠商提供的全棧 AI 服務以及中國開源模型，將成為市場增長的核心驅動力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="359" src="https://oscimg.oschina.net/oscnet/up-214b4551cb660f989fe43d99eb32a9a19e6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;據瞭解，以大模型為核心的生成式 AI 正加速進入中國的千行百業。報告顯示，對於中國&amp;nbsp;500&amp;nbsp;強企業在 AI 基礎設施、大模型、開發平台和 AI 應用的實際情況，74.6%&amp;nbsp;已經應用或部署生成式 AI，其中，阿里雲滲透率為 53% 排名第一，DeepSeek51%、華為雲 25%、百度雲 22%、騰訊雲 20%、火山引擎 9%，分列二至六位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;Omdia 報告指出，在已使用 GenAI 的《財富》中國 500 強企業中，汽車和媒體文娛產業的滲透率高達 100%，90% 的銀行、金融與保險企業（BFSI）以及 51% 的製造企業也已採用 GenAI。Omdia 指出，不同行業的企業對&amp;nbsp;GenAI&amp;nbsp;採用的成熟程度不同，但都積極地將&amp;nbsp;GenAI&amp;nbsp;應用到廣泛的場景，包括提升員工生產力、客户服務響應、銷售與營銷以及流程優化等。到 2029 年，Omdia 預計國內語音助手、圖像與視頻內容分析、自動化代碼開發等多個 GenAI 的核心應用場景的軟件收入將實現 2 至 5 倍增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;Omdia 認為，以阿里雲為代表的本土雲廠商，通過提供完善的生成式 AI 解決方案，極大地促進了中國企業採用生成式 AI 的進程，當前採用 GenAI 的《財富》中國 500 強企業普遍更傾向於採用本土廠商；另一方面，通義千問、DeepSeek 等中國開源模型，是中國 GenAI 市場爆發的又一關鍵原因。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372952</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372952</guid>
      <pubDate>Sun, 14 Sep 2025 06:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 付費用户可為 GPT-5 Thinking 模式設定思考時長</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 在 X 平台&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1968395215536042241" target="_blank"&gt;宣佈&lt;/a&gt;，鑑於用户反饋 GPT-5 思考時間有時過長，現針對 Plus、Pro 和 Business 用户，在 ChatGPT 網頁版推出 GPT-5 思考時長調整功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="928" src="https://static.oschina.net/uploads/space/2025/0918/141204_J5Kj_2720166.png" width="1854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户選擇 GPT-5 with Thinking 模式後，在消息編輯框處可切換思考時長。其中，Plus、Pro 及 Business 用户可選擇標準模式（新默認設置，平衡回覆速度與智能程度）和擴展模式（Plus 版之前的默認模式，思考更深但耗時更久）。&lt;/p&gt; 
&lt;p&gt;Pro 用户還有額外選項，輕量模式能使 GPT-5 以最快速度回覆；重度模式則讓 GPT-5 進行深度思考，回覆速度最慢。用户設置的思考時長，在網頁版後續對話中保持不變，直至手動更改 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372947</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372947</guid>
      <pubDate>Sun, 14 Sep 2025 06:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微語 0.9.7 發佈，支持對接 Dify/Coze 等</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;企業級多租户團隊協作工具，免費開源 N 件套：企業 IM、在線客服、企業知識庫/幫助文檔、客户之聲、工單系統、AI 對話、工作流、呼叫中心、視頻客服、開放平台。&lt;/p&gt; 
&lt;h2&gt;語言&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.zh.md"&gt;中文&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="weiyu" src="https://oscimg.oschina.net/oscnet//55295d7500601eceebfbae7ccc0dc4cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;管理端&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="chat" src="https://oscimg.oschina.net/oscnet//24bd4286ec364ad60398f0701d99466b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;多渠道&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="channel" src="https://oscimg.oschina.net/oscnet//331d4de07a6f84873949435f2491e7d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;客服端&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="agent" src="https://oscimg.oschina.net/oscnet//ce2042d508bab43cc1e80ae44c4e9be0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;介紹&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/team/readme.zh.md"&gt;企業 IM&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;局域網即時通訊&lt;/li&gt; 
 &lt;li&gt;企業成員管理&lt;/li&gt; 
 &lt;li&gt;聊天記錄監控&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/service/readme.zh.md"&gt;全渠道客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;多渠道接入&lt;/li&gt; 
 &lt;li&gt;人工客服&lt;/li&gt; 
 &lt;li&gt;客服 Agent 智能體，對接自有數據，自動執行操作&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/kbase/readme.zh.md"&gt;知識庫&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;對接大模型&lt;/li&gt; 
 &lt;li&gt;自定義知識庫&lt;/li&gt; 
 &lt;li&gt;Function Calling&lt;/li&gt; 
 &lt;li&gt;Mcp&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ticket/readme.zh.md"&gt;工單系統&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;工單管理&lt;/li&gt; 
 &lt;li&gt;工單 SLA 管理&lt;/li&gt; 
 &lt;li&gt;工單統計和報表&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ai/readme.zh.md"&gt;AI Agent&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ollama/DeepSeek/ZhipuAI/...&lt;/li&gt; 
 &lt;li&gt;智能體&lt;/li&gt; 
 &lt;li&gt;工作流&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/core/readme.workflow.md"&gt;工作流&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;自定義表單&lt;/li&gt; 
 &lt;li&gt;自定義流程&lt;/li&gt; 
 &lt;li&gt;工單流程可視化&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/voc/readme.zh.md"&gt;客户之聲&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;意見反饋&lt;/li&gt; 
 &lt;li&gt;服務投訴&lt;/li&gt; 
 &lt;li&gt;問卷調查&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/freeswitch/readme.zh.md"&gt;呼叫中心&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基於 FreeSwitch 的專業呼叫平台&lt;/li&gt; 
 &lt;li&gt;支持來電彈屏、自動分配、通話錄音&lt;/li&gt; 
 &lt;li&gt;數據統計，語音與文字服務無縫集成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/webrtc/readme.zh.md"&gt;視頻客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基於 WebRTC 技術的高清視頻通話&lt;/li&gt; 
 &lt;li&gt;支持一鍵視頻對話與屏幕共享&lt;/li&gt; 
 &lt;li&gt;適用於需要直觀展示的服務場景&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/readme.md"&gt;開放平台&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;提供完整的 RESTful API 接口和 SDK 工具包&lt;/li&gt; 
 &lt;li&gt;支持與第三方系統無縫集成，實現數據互通&lt;/li&gt; 
 &lt;li&gt;多語言 SDK 支持，簡化開發集成流程&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速開始&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fdocker" target="_blank"&gt;Docker 部署&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fbaota" target="_blank"&gt;寶塔面板部署&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fsource" target="_blank"&gt;源碼啓動&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;演示&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;本地預覽&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 請將 127.0.0.1 替換為你的服務器 ip&lt;/em&gt;
http://127.0.0.1:9003/
&lt;em&gt;# 開放端口：9003, 9885&lt;/em&gt;
默認用户名: admin@email.com
默認密碼: admin&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372946</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372946</guid>
      <pubDate>Sun, 14 Sep 2025 06:11:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>​微軟斥資 62 億美元租賃挪威 AI 計算能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微軟公司日前宣佈，將支付 62 億美元租賃挪威的人工智能計算能力。這一重大投資是與英國數據中心公司 Nscale Global Holdings Ltd. 及挪威投資公司 Aker ASA 的合作成果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據雙方的聲明，此項目將依託於 「保障的電網容量和完全可再生的電力」 來進行運作。這意味着，微軟的 AI 計算將在環保方面做出積極的貢獻。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="213" src="https://oscimg.oschina.net/oscnet/up-2464b7cc4919be5da3c739f110951f5ee82.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次合作的背景是在全球對人工智能技術的需求不斷增長的情況下，尤其是在數據處理和機器學習等領域。微軟希望通過這一投資來提升其在 AI 領域的競爭力，併為客户提供更為強大的計算能力。與 Nscale Global 和 Aker ASA 的合作，將使微軟能夠利用挪威豐富的可再生能源資源，滿足日益增長的計算需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;挪威以其豐富的水力資源而聞名，能夠提供穩定而清潔的電力供應，這對於運行大型數據中心至關重要。在確保電力來源的同時，微軟還將關注其碳足跡，力求在推動技術發展的同時，兼顧環保責任。這一項目的成功實施，預計將為全球 AI 產業的發展提供重要支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微軟在人工智能領域的戰略佈局不僅僅體現在資金投入上，還包括技術研發、產品創新以及與全球領先公司的合作。通過這一投資，微軟將進一步鞏固其在全球科技市場的領導地位，併為客户提供更優質的服務。預計未來幾年內，隨着 AI 技術的持續進步和應用場景的不斷拓展，這一合作將帶來顯著的經濟效益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372940</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372940</guid>
      <pubDate>Sun, 14 Sep 2025 06:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>IBM 發佈 Granite-Docling-258M：開源企業級文檔 AI 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;IBM 正式發佈了 Granite-Docling-258M，這是一個開源的視覺語言模型，專為端到端文檔轉換而設計。與傳統的 OCR（光學字符識別）技術相比，Granite-Docling 注重保持文檔的佈局信息，能夠有效提取表格、代碼、公式、列表、標題等元素，並輸出結構化的機器可讀格式，而非簡化的 Markdown 格式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Granite-Docling 是 SmolDocling-256M 的改進版。IBM 對原有的技術架構進行了優化，採用了 Granite165M 語言模型，並升級了視覺編碼器為 SigLIP2，同時保持了 Idefics3 風格的連接器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這一系列更新使得 Granite-Docling 的參數量達到了 258M，並在佈局分析、全頁 OCR、代碼、公式及表格的精確度上都有顯著提升。此外，IBM 還解決了在預覽模型中發現的不穩定性問題，如重複令牌循環現象。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Granite-Docling 採用了基於 Idefics3 的架構，使用了 nanoVLM 訓練框架。其輸出的 DocTags 是 IBM 開發的一種標記語言，能夠清晰地表示文檔結構，包括元素、座標和關係，方便後續工具將其轉換為 Markdown、HTML 或 JSON 格式。這種結構化的輸出方式，不僅保持了表格拓撲、數學公式、代碼塊及標題的順序，還提高了數據索引的質量和增強了檢索能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="361" src="https://oscimg.oschina.net/oscnet/up-0b74074edcff37ca804f9eaa50858529b51.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在多語言支持方面，Granite-Docling&amp;nbsp;首次增加了對日語、阿拉伯語和中文的實驗性支持，但目前以英語為主要目標。IBM 建議用户將 Granite-Docling 與 Docling 集成，利用其 CLI/SDK 自動轉換 PDF、辦公文檔及圖片至多種格式。這款模型能夠在 Transformers、vLLM、ONNX 和 MLX 等運行環境中流暢運行，特別為 Apple Silicon 進行了優化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372918</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372918</guid>
      <pubDate>Sun, 14 Sep 2025 03:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>CodeRabbit 發佈面向終端的 AI 代碼審查 CLI 工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 代碼審查初創公司 CodeRabbit&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.coderabbit.ai%2Fblog%2Fcoderabbit-series-b-60-million-quality-gates-for-code-reviews%23heading-how-were-celebrating-by-announcing-coderabbit-cli" target="_blank"&gt;宣佈&lt;/a&gt;推出「CodeRabbit CLI」，一款用於終端環境的 AI 代碼審查工具，能與 Claude Code、Codex CLI、Cursor CLI、Gemini 等 AI 編碼助手無縫協同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-855b44fbe07e762afd8d359ffde67b8347a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CodeRabbit 表示，隨着開發者越來越多地通過 CLI 編碼助手編寫代碼，他們發現了一個關鍵需求：&lt;strong&gt;代碼生成速度空前提升，但質量驗證往往滯後至 PR 階段才進行&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;CodeRabbit CLI 通過將智能審查直接融入 CLI 工作流，在代碼生成與驗證之間建立實時反饋循環，徹底改變了這一現狀。&lt;/p&gt; 
 &lt;p&gt;無論您是讓 Claude Code 重構模塊，還是使用 Cursor CLI 實現功能，CodeRabbit 都能即時審查輸出結果：捕捉幻覺錯誤、標記安全隱患，甚至將上下文相關的修復方案反饋給 AI 助手。&lt;/p&gt; 
 &lt;p&gt;CodeRabbit CLI 正是缺失的協調層，它使 AI 生成的代碼具備生產就緒能力，將自主開發的美好願景化為現實。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3cf9f409139688d994f99832b6c49feec27.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;CodeRabbit CLI 可在任意終端後台運行，並能與 Claude Code、OpenAI Codex CLI、Cursor CLI、Gemini CLI 等主流 AI 編碼 CLI 無縫集成。它提供預提交審查、一鍵修復或完整的 Agent 交接功能，並基於 40 餘種來源進行上下文分析。產品提供有額度限制的免費檔，Pro 訂閲則解鎖更高額度與額外功能。&lt;/p&gt; 
&lt;p&gt;詳情查看：&lt;em&gt;https://www.coderabbit.ai/cli&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372917</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372917</guid>
      <pubDate>Sun, 14 Sep 2025 03:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 推理領域明星創企 Groq 完成 7.5 億美元融資，投後估值達 69 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 推理領域明星創企 Groq&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGroqInc%2Fstatus%2F1968389894302249277" target="_blank"&gt;宣佈&lt;/a&gt;完成 7.5 億美元新一輪融資，投後估值達 69 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1f37323fafa865fba0a4ab33d0bf95bf202.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本輪融資由 Disruptive 領投，貝萊德（BlackRock）、紐伯格伯曼（Neuberger Berman）、德國電信資本夥伴（Deutsche Telekom Capital Partners）以及一家美國西海岸大型共同基金參與了大額投資，三星、思科、D1、Altimeter、1789 Capital 和 Infinitum 等現有投資者繼續跟投。其中，Disruptive 對 Groq 的投資近 3.5 億美元。&lt;/p&gt; 
&lt;p&gt;Groq 致力於為全球超 200 萬開發者及眾多財富 500 強企業提供高效且低成本的算力支持，已在北美、歐洲和中東地區佈局數據中心。&lt;/p&gt; 
&lt;p&gt;公司創始人兼首席執行官喬納森·羅斯（Jonathan Ross）表示：「推理技術正定義當下 AI 時代，我們致力於打造高速、低成本的美國 AI 基礎設施。」白宮近期發佈行政令，推動美國 AI 技術棧出口，Groq 的美國造推理基礎設施已為全球開發者和企業提供支持，在這一趨勢中扮演關鍵角色。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/111108_i8dM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據悉，這筆資金將用於擴大數據中心規模，Groq 計劃今年宣佈其在亞太地區的首個佈局點 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372914/groq-raises-750-million-as-inference-demand-surges</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372914/groq-raises-750-million-as-inference-demand-surges</guid>
      <pubDate>Sun, 14 Sep 2025 03:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>KubeSphere 社區版即將發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;KubeSphere 官方公眾號&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoXCtXJxi5fDBayFx3_bxtg" target="_blank"&gt;發文&lt;/a&gt;宣佈，KubeSphere 社區版即將登場 —— 一款永久免費、開箱即用的雲原生容器平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="398" src="https://oscimg.oschina.net/oscnet/up-700b0889e0eb1c56c121ba858f73d69fae1.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，社區辦包含四大亮點：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;永久免費：零成本無憂使用，持續迭代升級，構建雲原生基石。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;簡易安裝：支持任意環境，在線/離線一鍵部署，擴容升級更省心。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;功能全面：多租户、可觀測性、應用生命週期、DevOps 一應俱全。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;靈活擴展：可插拔架構，輕鬆集成主流開源工具，像搭積木一樣擴展能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372912</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372912</guid>
      <pubDate>Sun, 14 Sep 2025 03:05:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元公佈 SRPO 技術，解決大模型生圖「過油」問題</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC3xS9EyvtOsE8x-6J9fplA" target="_blank"&gt;發佈&lt;/a&gt;了最新研究成果 —— SRPO（Semantic Relative Preference Optimization，語義相對偏好優化），主要提供了文生圖模型的強化算法，解決了開源文生圖模型 Flux 的皮膚質感「過油」的問題，能讓人像真實感提升 3 倍。&lt;/p&gt; 
&lt;p&gt;根據介紹，針對 Flux.dev.1 模型生成的人物質感「過油」的問題，SRPO 通過在線調整獎勵偏好，優化早期生成軌跡等手段很好的解決了這個問題。&lt;/p&gt; 
&lt;p&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-f6af7ed86c7e9b248a810db540328ba083e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="303" src="https://oscimg.oschina.net/oscnet/up-39826f1a005f0c9cea167db74a3ca08ad83.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-fcb6c0390cd8afa2083d678b847782d36f8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;文生圖領域傳統的在線強化學習方法（如 ReFL，DRaFT）雖展現極高的訓練效率，但強依賴一個預先訓練好的獎勵模型。這些獎勵模型除了需要耗費大量的成本收集數據外，還面臨泛化性差的問題，通常難以滿足多樣化，高質量的後訓練需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;為瞭解決這個問題，騰訊混元團隊聯合香港中文大學（深圳）和清華大學提出了：語義相對偏好優化，通過語義偏好實現獎勵模型的在線調整。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;具體來説，SRPO 通過為獎勵模型添加特定的控制提示詞（如「真實感」）來定向調整其優化目標。實驗結果顯示，這些控制詞可以顯著增強獎勵模型在真實度等特定維度的優化能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="155" src="https://oscimg.oschina.net/oscnet/up-f78edc6a752e45e0d90a5e539f80e4e4827.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;研究人員進一步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;發現，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;單純&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;語義&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;引導&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;仍&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;存在&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;獎勵&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;破解&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;e&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;）&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;風險&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;針對&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;這一問題&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;團隊&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;提出&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;創新&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;語義&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;相對&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏好&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;優化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;同時&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;使用&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;正向詞&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;負向&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;詞&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;作為&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;引導&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;信號&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;通過&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;負向&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;梯度&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;有效&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;中和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;獎勵&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;一般性&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏差&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;同時&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;保留&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;語義&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;差異&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;中&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;特定&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏好&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="221" src="https://oscimg.oschina.net/oscnet/up-246675f35c7b1997651ffb946609fa6f322.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;並提出了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;D&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;e&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;l&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;對&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;輸入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;圖像&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;進行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;可控&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;噪聲&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;注入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;隨後&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;通過&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;單步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;推理&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;藉助&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;預先&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;注入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;噪聲&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;作為&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;參考&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;錨點&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;進行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;圖像&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;重建&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;這種&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;方法&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;顯著&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;降低&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;重建&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;誤差&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;實現&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;更精準&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;獎勵&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;信號&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;傳導&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;從而&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;支持&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;對&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;生成&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;軌跡&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;半段&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;進行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;優化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;解決&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;過擬合&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;問題&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="219" src="https://oscimg.oschina.net/oscnet/up-9d5a1dc47659cc8cead58d4db3a0f205586.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;SRPO 具有極高的訓練效率，只需 10 分鐘訓練即可全面超越 DanceGRPO 的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="345" src="https://oscimg.oschina.net/oscnet/up-53524d47ddd3d0886217055ddbde022d450.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;SRPO&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;定量指標達 SOTA 水平，人類評估的真實度和美學優秀率提升超過 3 倍，訓練時間相比 DanceGRPO 降低 75 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-ddf094079d4887628fefa724ca406fab313.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;論文鏈接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2509.06942" target="_blank"&gt;Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372907</guid>
      <pubDate>Sun, 14 Sep 2025 02:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Linus 發佈「吉他效果器」開源項目 GuitarPedal</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 內核創始人&amp;nbsp;Linus Torvalds&amp;nbsp;昨天在 GitHub 開源了一個名為 GuitarPedal 的「吉他效果器」項目。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1448" src="https://static.oschina.net/uploads/space/2025/0918/103352_3UWd_2720166.png" width="1744" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://github.com/torvalds/GuitarPedal&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;倉庫包含電路原理圖與少量代碼，並非可量產的成品，而是他出於對模擬電路的好奇——把玩運算放大器、JFET 等元件，把焊電路當成「成人樂高」。&lt;/p&gt; 
&lt;p&gt;Linus 寫道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;無論如何，在製作了許多傳統的模擬吉他踏板套件之後，我決定去真正瞭解它們是如何工作的，因為我確實對模擬電路的經驗非常有限。&lt;/p&gt; 
 &lt;p&gt;我做過一些非常有限的電子工作，但幾乎都與計算機有關，它們要麼是數字邏輯，要麼是開關電源。&lt;/p&gt; 
 &lt;p&gt;此外，我在尋找一種不同的焊接體驗，其中通過孔組件的腿剪斷較少。我實際上喜歡焊接 SMT 組件，但這通常不是那些吉他踏板套件所做的事情。&lt;/p&gt; 
 &lt;p&gt;幾年前，我用 kicad 進行了一些非常有限的 PCB 設計，所以我就決定開始更多地學習模擬電路。然後它就從這個基礎上發展起來了。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Linus 不彈吉他，項目也與 Linux 內核無關，這是純屬個人興趣的硬件「草圖」。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;BTW，這個倉庫應該是「現場製作」，Linus 一個小時前還提交了新的 commit：&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/104620_rBPW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/329653/linus-torvalds-guitar-pedal-offer" target="_blank"&gt;Linus 變身 「手工林」—— 將親自打造一套吉他效果器踏板贈送給內核開發者&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372904</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372904</guid>
      <pubDate>Sun, 14 Sep 2025 02:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Dapr v1.16 發佈，分佈式應用運行時</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Dapr 是一個可移植的、事件驅動的運行時，它使任何開發人員能夠輕鬆構建出彈性的、無狀態和有狀態的應用程序，並可運行在雲平台或邊緣計算中，它同時也支持多種編程語言和開發框架。&lt;/p&gt; 
&lt;p&gt;Dapr 1.16 版本現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYH76JqPlL7yyXw5GjabUQA" target="_blank"&gt;發佈&lt;/a&gt;，此次版本在工作流性能、問題修復及功能上都有提升，官方強烈建議升級。更新亮點如下：&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;多應用工作流&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Workflow API 現支持跨多個應用的多應用工作流，能編排跨應用的複雜業務流程。工作流可調用不同應用的活動或啓動子工作流，實現工作流執行的分佈式處理，同時保持 Dapr 工作流引擎的安全性、可靠性和持久性。&lt;/p&gt; 
&lt;p&gt;多應用工作流適合設計分佈式業務流程，如跨應用訂單處理、涉及多工作流和活動的複雜審批鏈，以及協調 LLM 服務和 GPU 密集型任務的 AI/ML 流水線。工作流的持久性和一致性在應用邊界間得到保障，即使單個應用出現臨時故障，分佈式工作流依然穩定。&lt;/p&gt; 
&lt;p&gt;Java 和 Go SDK 從本版本開始支持多應用工作流。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;工作流性能&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Dapr 持續投入 Workflow API 組件的建設；本次發佈重點提升性能和穩定性，尤其是面向生產環境的大規模使用。這些改進讓 Dapr 工作流更健壯，適合高吞吐和高併發場景。&lt;/p&gt; 
&lt;p&gt;主要改進：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內存優化：通過內存池重用，減少內存分配；更智能管理對象生命週期，降低垃圾回收開銷。&lt;/li&gt; 
 &lt;li&gt;併發增強：消除了 daprd 和調度器中共享內存競爭，支持更高吞吐量。&lt;/li&gt; 
 &lt;li&gt;調度器可靠性：修復極端負載下調度器死鎖，提升作業調度和執行穩定性。&lt;/li&gt; 
 &lt;li&gt;連接管理：增加跨 daprd 和調度器的流數，提升併發能力，減少瓶頸。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些改進使 Dapr 能處理更大規模的工作流吞吐，整體內存和 CPU 使用更低且更穩定。&lt;/p&gt; 
&lt;p&gt;下表為在 3 節點 EKS 集羣（t2.medium 節點）上測試 Dapr v1.15 和 v1.16 工作流性能對比。&lt;br&gt; Actor 狀態存儲為 Amazon RDS（db.r6g.2xlarge）。&lt;br&gt; Go 工作流應用並行啓動所有調度工作流，每個工作流順序執行 15 個空操作活動。&lt;/p&gt; 
&lt;p&gt;&lt;img height="246" src="https://oscimg.oschina.net/oscnet/up-01082f301f023d8a31c53e238e6e22587a8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://oscimg.oschina.net/oscnet/up-2f715dc1247d20e912cb15fad1193a4cbc6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是運行 1000 個工作流，3 個應用副本時的內存和 CPU 使用情況。v1.16 引擎使用更少資源且更穩定。&lt;/p&gt; 
&lt;p&gt;1.15 Memory&lt;/p&gt; 
&lt;p&gt;&lt;img height="179" src="https://oscimg.oschina.net/oscnet/up-3b00546356aaebdf6332fb959f24c1f0ceb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1.15 CPU&lt;/p&gt; 
&lt;p&gt;&lt;img height="169" src="https://oscimg.oschina.net/oscnet/up-25b2f368e0cf12a4369ccf50122bbcec825.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1.16 Memory&lt;/p&gt; 
&lt;p&gt;&lt;img height="204" src="https://oscimg.oschina.net/oscnet/up-ae6f7aec709c1455b8fb592b9d69ed6fbdf.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1.16 CPU&lt;/p&gt; 
&lt;p&gt;&lt;img height="170" src="https://oscimg.oschina.net/oscnet/up-a7f42bc51597981a8fa163618d8a436c2ce.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;HTTP 流 / SSE 支持 HTTP 端點&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;現在，Dapr 可代理支持流式傳輸或服務器推送事件（SSE）的外部 HTTP 服務器請求。這樣，Dapr 在與 MCP 服務器和 AI 代理通信時，可以提供中間件認證、彈性策略、遙測和分佈式追蹤等重要功能。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Conversation API 工具調用支持（AlphaV2）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Dapr 現支持 Conversation API 中的工具調用，允許大型語言模型（LLM）在對話中調用外部函數和 API。應用可提供工具供 LLM 調用，實時獲取數據、執行計算或操作，使對話更具互動性和動態性。&lt;/p&gt; 
&lt;p&gt;AlphaV2 Conversation API 主要新增：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;函數工具：用 JSON Schema 定義工具參數，供 LLM 調用&lt;/li&gt; 
 &lt;li&gt;工具使用控制：支持 auto、none、required 或指定工具等選項&lt;/li&gt; 
 &lt;li&gt;工具調用消息：會話歷史支持助手工具調用及響應&lt;/li&gt; 
 &lt;li&gt;OpenAI 對齊：API 設計符合 OpenAI 工具調用模式，開發體驗更熟悉。之前使用 AlphaV1 API 的應用可升級到 AlphaV2 以支持工具調用，享受更優體驗。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;Sentry 服務支持 JWT 和 OIDC&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Sentry 服務增加了 JWT 和 OIDC 高級認證支持，可通過工作負載身份聯合集成外部身份提供商。&lt;/p&gt; 
&lt;p&gt;你可以配置 Sentry 簽發 JWT 令牌，並暴露 OIDC 發現端點（/.well-known/openid-configuration 和 /jwks.json）。例如，可通過創建與 Dapr 應用 SPIFFE ID 綁定的聯邦身份憑證，將這些令牌兑換為 Microsoft Entra ID 的 Azure 訪問令牌。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聯邦身份憑證集成：使用 SPIFFE ID 認證 Microsoft Entra，無需長期密鑰&lt;/li&gt; 
 &lt;li&gt;Sentry 中啓用 JWT 簽發和 OIDC 發現端點&lt;/li&gt; 
 &lt;li&gt;跨環境身份一致：無論在哪運行 Dapr 應用，認證方式一致&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;W3C Baggage 支持分佈式追蹤&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Dapr 現支持 W3C Baggage 傳播，配合 Trace Context，允許攜帶自定義鍵值對跨服務傳遞。這樣你可以附加用户 ID、服務器節點或業務標籤等上下文信息，隨調用鏈全程傳播。&lt;/p&gt; 
&lt;p&gt;支持兩種傳播方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenTelemetry 上下文 baggage&lt;/li&gt; 
 &lt;li&gt;Header/Metadata baggage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Dapr 自動處理傳播和編碼，保障數據安全隔離，方便將業務上下文與技術追蹤關聯，提升微服務架構的調試和可觀測性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372903/dapr-1-16-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372903/dapr-1-16-released</guid>
      <pubDate>Sun, 14 Sep 2025 02:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>欣旺達動力加入星環 OS 開源項目指導委員會</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 9 月 16 日，欣旺達動力科技股份有限公司（以下簡稱「欣旺達動力」）與北京羅克維爾斯科技有限公司（以下簡稱「羅克維爾斯」）正式簽署《星環 OS 合作意向備忘錄》。&lt;/p&gt; 
&lt;p&gt;雙方宣佈，欣旺達動力將作為合作伙伴加入星環 OS 開源項目指導委員會，共同推進智能汽車操作系統的技術演進與生態建設。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0918/102936_DGN3_2720166.png" width="1147" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;星環 OS 是由理想汽車發起並開源的全車級操作系統項目，旨在通過社區協作打造開放、高效、可靠的車載系統基礎平台，推動汽車智能化功能的持續創新與產業協同發展。指導委員會作為星環 OS 的最高決策機構，負責制定社區治理規範、關鍵技術方向及生態合作策略。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0423/145233_2m1R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過此次合作，欣旺達動力將成為星環 OS 指導委員會的初始成員單位，深度參與項目決策、技術規劃與生態推廣。雙方將共同推動操作系統核心技術的研發與落地，促進供應鏈與整車能力的深度融合，為行業提供更開放、安全、可持續的智能汽車軟件底座。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372902</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372902</guid>
      <pubDate>Sun, 14 Sep 2025 02:30:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenTiny NEXT 內核新生：生成式 UI × MCP，重塑前端交互新範式！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，我們推出 &lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; ------ OpenTiny 的下一代企業級前端智能開發解決方案。這不僅是一次技術升級，更是一場用户交互範式的變革：從傳統的人機交互升級成為人機交互範式和智能體交互範式的融合。我們堅信，&lt;strong&gt;每一個企業應用都值得被 AI 理解，每一次用户交互都可以更自然、更智能。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;項目背景&lt;/h2&gt; 
&lt;p&gt;當前，大語言模型（LLM）正在深刻地改變人機交互的方式。用户期望通過自然語言完成更復雜、更智能化的操作。然而現有的企業應用（&lt;strong&gt;包括 Web 應用、桌面應用、移動應用等&lt;/strong&gt;）大多仍依賴於傳統的圖形用户界面（GUI）點擊操作，無法直接響應 LLM 的指令，使得企業應用與智能體（Agent）之間形成了一道鴻溝。&lt;/p&gt; 
&lt;p&gt;隨着 LLM 和 Agent 技術的發展，企業應用正逐步邁入"智能化"階段。OpenTiny 作為一套成熟的企業前端開發解決方案，擁有 UI 組件庫（TinyVue）和低代碼引擎（TinyEngine）等產品，在服務傳統前端開發場景的基礎上，我們順應 AI 時代需求，對 OpenTiny 進行一次代際升級，構建一套面向未來的"企業智能前端開發解決方案"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; 新的解決方案整合了 AI 技術與 OpenTiny 原有能力，支持企業應用允許 Agent 理解用户意圖並自主完成任務，&lt;strong&gt;打造一個 Agent 主導的企業智能應用生態系統。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;願景與架構&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; 旨在成為業界領先的企業智能前端開發解決方案，我們致力於為企業應用無縫注入"智駕"能力，打破人、AI 與應用之間的壁壘。&lt;/p&gt; 
&lt;p&gt;我們的願景是：&lt;strong&gt;讓每一個企業應用都能支持 AI 理解用户意圖並自主完成任務，讓自然語言成為企業應用的下一代交互範式。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是 OpenTiny NEXT 的整體架構圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-750503dfb19fa0be71b26e089eca9abe839.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;項目介紹&lt;/h2&gt; 
&lt;p&gt;OpenTiny NEXT 智能前端開發解決方案以生成式 UI + WebMCP 兩大核心技術為依託，構建一個從後端服務、開發工具到前端 UI 完整的智能產品族。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基礎設施層 (IaaS)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;WebAgent: 連接 Agent 智能體與企業應用內置的 MCP 服務的手臂。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;開發工具層 (PaaS/SDKs)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;NEXT-SDKs: 提供跨前端框架、高可擴展的企業應用智能化開發工具庫。&lt;/li&gt; 
   &lt;li&gt;TinyEngine NEXT: 可生成"智能"應用的智能低代碼引擎。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;應用與組件層 (SaaS/UI)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;TinyRobot : 面向最終企業用户的智能體對話入口。&lt;/li&gt; 
   &lt;li&gt;TinyVue NEXT: 承載生成式 UI 引擎的企業級智能組件庫。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;門户與生態：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;OpenTiny NEXT 官網: 產品的統一入口、文檔和社區。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NEXT-SDKs：智能應用開發工具包&lt;/h3&gt; 
&lt;p&gt;NEXT-SDKs 是一套開發工具包，旨在簡化 WebAgent 的集成與使用，支持多種編程語言和前端框架，幫助開發者快速實現智能化功能。&lt;/p&gt; 
&lt;p&gt;它的核心 SDK (包括 TypeScript, Python, Java 等版本)，提供簡化的 API 封裝與 WebAgent 服務的連接、認證等邏輯，同時提供易用的 API 讓開發者將企業應用的前端功能聲明為 MCP Server。針對不同前端框架（Vue、React、Angular、Vanilla）特性，它提供 API 以降低用户在特定前端框架中的使用 MCP Server 和連接 WebAgent 的難度。&lt;/p&gt; 
&lt;p&gt;此外，它還提供一個適配器層，可以將任意前端 AI 對話框組件（包括 TinyRobot 組件）快速接入 WebAgent 服務。並且它支持抹平不同 LLM 差異，支持文字、語音等多模態輸入，使得 AI 對話框連接的 LLM 支持受控端的 MCP 工具調用。另外，它還提供動態生成二維碼功能，讓企業應用裏的 MCP 服務成為 AI 對話框裏可以讓 Agent 調用的工具。&lt;/p&gt; 
&lt;p&gt;當前市面上的 MCP 服務都是後端服務，但是如果用户的後端服務 Api 想要改造成大模型可以理解的 MCP 服務，成本是非常高的，我們用這種逆向思維把 MCP Server 放在前端，這樣用户是不需要對已有的後端 Api 進行改動，已有的業務邏輯如果已經封裝成前端的 Api，則可以直接註冊成 MCP Tool，前端的工具方法或者業務方法放在 MCP Tool 的回調裏就完成了向 AI 提供工具的實現。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8be2f2543afe47175e072bbb3afab00c699.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;WebAgent：智能體 MCP 服務代理&lt;/h3&gt; 
&lt;p&gt;WebAgent 是連接 Agent 智能體與企業應用內置的 MCP 服務的手臂。提供 MCP 市場和動態添加 MCP 插件能力，支持 Agent 調用多個授權企業應用裏的 MCP 服務。基於 OAuth 2.1 協議的授權機制，受控的企業應用擁有者可以精細化授權給指定的遙控端 AI 應用。支持 MCP 插件化架構，可連接企業內部的雲服務（如對象存儲、數據庫）或本地工具（如代碼執行器），支持企業私有化部署，支持數據和模型調用均在企業內網，並提供多種維度的計費模型，支持用户註冊、登錄、角色權限分配及管理等。支持多語言版本，與 MCP 官方 SDKs 相對應，分為 TypeScript、Python、Java 等版本。&lt;/p&gt; 
&lt;p&gt;在瀏覽器運行的 Web 應用都可以接入 Web Agent Server：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0e2947d8f922737d910fd58255504d470e3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyRobot：企業智能體個人助手&lt;/h3&gt; 
&lt;p&gt;TinyRobot 是一個企業 AI 應用，支持 Agent 智能體識別用户意圖，代替用户自主完成跨多個企業應用的任務。TinyRobot 可調用的 MCP 服務來自 WebAgent 的 MCP 市場和動態添加的 MCP 插件。TinyRobot 會調用 NEXT-SDKs 的能力，實現掃碼動態添加 MCP 插件，以及抹平不同 LLM 差異實現 Agent 自主規劃和完成任務。&lt;/p&gt; 
&lt;p&gt;同時它也可以作為對話框組件庫使用，也可以當作瀏覽器擴展安裝，助力開發者快速構建各種對話框場景頁面。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7cdc72736b59524c36def8e86f753637c3f.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyVue NEXT：生成式 UI 智能組件庫&lt;/h3&gt; 
&lt;p&gt;TinyVue 智能組件庫在傳統組件庫基礎上，支持在生成式 UI 場景中使用，AI 智能體可以根據用户意圖，按需靈活選擇 TinyVue 的組件，呈現給用户可視化的效果，並支持實時互動和交互。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6dd1a96dc063471b60ad37b80f7fcd23bfd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyEngine NEXT：智能應用低代碼引擎&lt;/h3&gt; 
&lt;p&gt;TinyEngine 智能低代碼引擎集成 MCP 能力，支持自然語言或圖片生成頁面，並提供可視化手動編輯與 AI 智能優化雙模式，幫助開發者快速構建應用。同時生成應用接入 OpenTiny NEXT，支持 LLM 直接操控，可助力企業應用實現智能化升級。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-258008e78027e24fd311a882b85849d380d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;場景實踐&lt;/h2&gt; 
&lt;p&gt;出差申請是企業高頻的辦公場景之一，卻常因「填表多、流程長」被吐槽。這裏我們以"出差申請"場景為例，接入 OpenTiny NEXT 技術後，只需四個步驟，就能實現通過 AI 讓企業應用直接被操控，從而實現智能化，讓用户直接輸入指令，就能完成整個出差流程閉環。&lt;/p&gt; 
&lt;p&gt;【實操視頻】&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1v7pMzpEY4%2F%3Fshare_source%3Dcopy_web%26vd_source%3Db20224008749f78db5628f8a1503a97f" target="_blank"&gt;https://www.bilibili.com/video/BV1v7pMzpEY4/?share_source=copy_web&amp;amp;vd_source=b20224008749f78db5628f8a1503a97f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;立即體驗，共創智能前端未來&lt;/h2&gt; 
&lt;p&gt;OpenTiny NEXT 即將正式發佈，官網、文檔、示例、Demo 一站配齊：&lt;/p&gt; 
&lt;p&gt;🌐 官網：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design" target="_blank"&gt;https://opentiny.design&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;📦 GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;https://github.com/opentiny&lt;/a&gt; （歡迎 star）&lt;/p&gt; 
&lt;p&gt;💬 交流羣：添加微信小助手 opentiny-official 回覆【OpenTiny NEXT】&lt;/p&gt; 
&lt;p&gt;後續我們也會對 OpenTiny NEXT 技術做出詳細解讀，將陸續發佈《&lt;strong&gt;一場 MCP 生態的變革 ------ 詳解 OpenTiny NEXT 逆向思維的技術創新&lt;/strong&gt;》 技術文章，請大家敬請期待~&lt;/p&gt; 
&lt;p&gt;OpenTiny NEXT，讓每一個企業應用都能支持 AI 理解用户意圖並自主完成任務，讓自然語言成為企業應用的下一代交互範式。&lt;/p&gt; 
&lt;p&gt;未來已來，歡迎上車！&lt;/p&gt; 
&lt;p&gt;同時歡迎大家進入代碼倉庫 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~ 如果你也想要共建，可以進入代碼倉庫，找到 good first issue 標籤，一起參與開源貢獻~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6769809/blog/18692067</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/18692067</guid>
      <pubDate>Sun, 14 Sep 2025 02:17:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>DeepSeek 論文登上 Nature 封面，AI 大模型首次通過同行評審</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;DeepSeek 團隊憑藉其關於&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;DeepSeek R1&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的研究論文，成功登上了&lt;span&gt;頂級&lt;/span&gt;學術期刊《Nature》的封面，成為首個通過&lt;span&gt;權威&lt;/span&gt;同行評審的大語言模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="188" src="https://oscimg.oschina.net/oscnet/up-0871738f7af920ae353da0834284847d489.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;《Nature》編輯部指出，在 AI 技術飛速發展、炒作氾濫的當下，DeepSeek 的做法為行業提供了一種有效的應對策略。通過嚴格的獨立同行評審，AI 研究的透明度和可重複性得以提升，從而降低了未經證實的技術聲明可能帶來的社會風險。編輯們呼籲更多 AI 公司能夠效仿 DeepSeek，以促進 AI 領域的健康發展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;這篇論文詳細介紹了 DeepSeek R1 創新的推理能力訓練方法。與傳統依賴人工標註進行微調不同，該模型完全不使用人工示例，而是通過強化學習（RL）在自主環境中自我演化，從而發展出複雜的推理能力。這種方法取得了顯著成效，例如在 AIME2024 數學競賽中，DeepSeek-R1 的表現從 15.6% 躍升至 71.0%，達到了與 OpenAI 模型相當的水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="225" src="https://oscimg.oschina.net/oscnet/up-4bb3540fe8babfd00e6a6bc231adde433d2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;em&gt;羣體相對策略優化算法的示意圖（來源：DeepSeek）&lt;/em&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在長達數月的同行評審過程中，八位專家對該研究提出了寶貴建議，促使 DeepSeek 團隊對技術細節進行了多次修改和完善。儘管研究成果顯著，團隊也坦承模型在可讀性和語言混用等方面仍面臨挑戰。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;為解決這些問題，DeepSeek 採用了結合拒絕採樣和監督微調的多階段訓練框架，進一步提升了模型的寫作能力和整體表現。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;DeepSeek R1 的成功發表標誌着 AI 基礎模型研究正在向更科學、更嚴謹和更可復現的方向邁進。這一突破為未來的 AI 研究提供了一個新範例，並有望推動整個行業走向更加透明和開放的發展道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372895</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372895</guid>
      <pubDate>Sun, 14 Sep 2025 02:08:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
