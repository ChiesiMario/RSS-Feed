<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Sun, 27 Jul 2025 07:48:39 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微軟即將發佈 Visual Studio 重大升級，應對 AI 編程工具激烈競爭</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;儘管微軟向客户提供了 Visual Studio Code 這款輕量級但功能強大的開源代碼編輯器，但其旗艦開發環境實際上是原生版 Visual Studio。這是一個功能齊全的集成開發環境 (IDE)，具有 .NET 集成和其他功能，使其更適合複雜的項目管理。現在，一份新報告顯示，微軟正計劃對 Visual Studio 進行重大升級。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/194445_SAV6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;媒體&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-plans-major-update-visual-studio-coding-service-ai-2025-7" target="_blank"&gt;Business Insider&lt;/a&gt;&amp;nbsp;看到了一份微軟內部備忘錄，其中詳細介紹了該公司計劃發佈 Visual Studio 的重大升級。不出所料，此次更新將重點關注人工智能 (AI)，這對於與亞馬遜 Kiro 等其他競爭對手競爭至關重要，亞馬遜 Kiro 被譽為基於 AI 的 IDE。&lt;/p&gt; 
&lt;p&gt;這份備忘錄由傑伊·帕裏克（Jay Parikh）於今年 4 月撰寫，他加入微軟不到一年，擔任執行副總裁（EVP）。帕裏克領導着公司的 CoreAI 部門，該部門負責開發人員工具，因此 Visual Studio 恰好屬於這位高管的職責範圍。&lt;/p&gt; 
&lt;p&gt;Parikh 的備忘錄將這次主要版本稱為「Visual Studio 18」，考慮到 Visual Studio 目前使用的是 17 版，這頗具趣味。該 IDE 上個月發佈了更新，允許開發人員訪問更強大的 AI 模型，同時靈活地管理計費。值得注意的是，Visual Studio 的上一次重大更新是在 2021 年，當時微軟發佈了 Visual Studio 2022 和 .NET 6，因此再次發佈主要版本也是合情合理的。&lt;/p&gt; 
&lt;p&gt;話雖如此，雖然 Visual Studio 的下一次重大升級有可能在今年推出，但目前尚未公佈具體的時間表。備忘錄還指出，這個由人工智能驅動的 IDE 版本目前正處於「早期內部測試」階段，這意味着微軟自己的員工正在積極地使用它進行測試。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362407</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362407</guid>
      <pubDate>Tue, 15 Jul 2025 11:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌短鏈接服務「goo.gl」將於下個月正式停用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Google 將於下個月正式棄用其網址縮短工具生成的鏈接。自 2025 年 8 月 25 日起，所有「&lt;span style="color:#2980b9"&gt;&lt;em&gt;https://goo.gl/*&lt;/em&gt;&lt;/span&gt;」格式的鏈接將不再有效，並返回 404 錯誤信息。&lt;/p&gt; 
&lt;p&gt;Google 於 2019 年關閉了其網址縮短服務，理由是「我們發現人們在互聯網上查找內容的方式發生了變化」。此後，使用該工具創建的鏈接仍然有效，但 Google 去年宣佈，隨着縮短網址流量的下降，將開始棄用這些服務。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3de2e977a212c4b76a27a10e76c003b1a75.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Google 在其&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F" target="_blank"&gt;2024 年 7 月的博客文章&lt;/a&gt;中表示：「事實上，超過 99% 的縮短網址在過去一個月內沒有任何活動。」&lt;/p&gt; 
&lt;p&gt;當時，Google 還開始在用户點擊縮短的網址時顯示一個警告頁面，提示「此鏈接近期將不再有效」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bd067dfa47ef36f85743afb32cf6824b04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;距離「goo.gl」鏈接關閉僅剩一個月時間，如果您還沒有將網址轉換到其他縮短服務，現在正是轉換的好時機。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362402</guid>
      <pubDate>Tue, 15 Jul 2025 11:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV7-G0 7.2B 發佈，最強純 RNN 推理模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日， &lt;strong&gt;RWKV7-G0 7.2B 推理模型&lt;/strong&gt;（Reasoning Model）正式開源發佈，它很可能是迄今為止人類訓練過的最強純 RNN 語言模型。&lt;/p&gt; 
&lt;p&gt;RWKV7-G0 7.2B 是在 RWKV6-World-V3-7.6B 的基礎上訓練 2T tokens 的純預訓練模型，但在預訓練加入了大量指令/對話/推理數據，可以解決各種推理問題。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果需要後訓練和對齊，最適合 RNN 的方式是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fadvanced%2FFine-Tune%2FRWKV-PEFT%2FState-Tuning" target="_blank"&gt;state-tuning&lt;/a&gt;，直接微調 RNN 的初始狀態，相當於終極 context engineering。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型客觀指標評測&lt;/h2&gt; 
&lt;h3&gt;英語和多語言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的基礎英語和多語言能力&lt;strong&gt;均強於同規模的開源模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="eval" src="https://oscimg.oschina.net/oscnet/up-3961b82f0302bbedafaae3e26ce721fe159.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;得益於架構和數據的提升，RWKV7-G0 7.2B 的 MMLU 準確度為 62.7%，顯著超過 RWKV6-World-V3-7.6B 的 54.2%。後續我們會發布訓練 8T tokens 的滿血 RWKV7-G1 7.2B，目標是 MMLU 達到 70%，看齊前沿模型。&lt;/p&gt; 
&lt;h3&gt;無法作弊的評測&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval" target="_blank"&gt;Uncheatable Eval&lt;/a&gt; 是"無法作弊的評測"，它使用最新的論文和新聞文章等實時數據，評估開源大語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B 的 Uncheatable Eval 同樣顯著提升，滿血 8T tokens 預計超越 Llama3 8B（這裏測試 2024-07 數據，後續會測新數據，並對比 Qwen2.5、Qwen3）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="uncheatable-eval" src="https://oscimg.oschina.net/oscnet/up-00ee915e6a6642e230984bbad95c7adda04.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;模型實戰：解數學題&lt;/h2&gt; 
&lt;p&gt;我們發現，RWKV7-G0 7.2B 解數學題可使用 &lt;code&gt;temperature top_p penalty&lt;/code&gt; 解碼參數都為 0 的純貪心解碼，且無限復讀現象較少。&lt;/p&gt; 
&lt;p&gt;但貪心解碼會導致推理過程探索度不足，因此可引入隨機性，例如 &lt;code&gt;temperature=0.3 top_p=0.3 penalty=0&lt;/code&gt;。模型會自動進行多輪驗算（類似 rollout），並可以自我糾錯。&lt;/p&gt; 
&lt;p&gt;那麼 &lt;code&gt;temperature=0.6 top_p=0.6 penalty=0&lt;/code&gt; 等隨機性更高的參數是否更好，後續我們會通過參數掃描實驗評估。&lt;/p&gt; 
&lt;p&gt;例子，第一題：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math1" src="https://oscimg.oschina.net/oscnet/up-0cd8d78f631ee7405c4bbca2340892aa1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改題目表述，模型換了種做法：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math2" src="https://oscimg.oschina.net/oscnet/up-dc97d5561c78acbb5117c3b214de082e7da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第二題，故意將原題的 99 改為 99.1，模型一開始看錯，後來成功糾正了自己：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math3" src="https://oscimg.oschina.net/oscnet/up-e607d6ca88eb49ab4caf0e417262eb39b2b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第三題，原題是計算 1 的冪，改為計算 i 的冪，增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math4" src="https://oscimg.oschina.net/oscnet/up-8d5d4f106fec7c3c72836c057b1de89bddd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第四題，原題是 2^8 = 4^x，改為 8^x 增加難度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math5" src="https://oscimg.oschina.net/oscnet/up-4d801cfa9f331b3dca71d086a3c05004e6c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第五題，原題的概率是 1/5，改為 1/4 測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math6" src="https://oscimg.oschina.net/oscnet/up-39c45f49e2a398f59a7dc87fde27cf46756.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第六題，原題是 one hat，改為 two hat（故意不加 s 複數形式）測試模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math7" src="https://oscimg.oschina.net/oscnet/up-2d56afb40928ffd13d17308fc41c6e56369.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第七題，模型有點懵，但反覆驗算多次後，成功確認了正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="math8" src="https://oscimg.oschina.net/oscnet/up-7730c44785334a3421428c0e7dd153ed6ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;結論：【純 RNN + 純預訓練】可以得到推理模型，而且它理解了一些解題方法，可以用不同方法解決修改過的題目。&lt;/p&gt; 
&lt;h2&gt;模型實戰：寫代碼&lt;/h2&gt; 
&lt;p&gt;在此我們測試用户喜聞樂見的圖像輸出。生成一個有一隻貓的 SVG 的網頁：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code" src="https://oscimg.oschina.net/oscnet/up-06f4dbd1a7c9e178ed8408f93d7bb939c4d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用 Three.js 創建一個旋轉的 3D 紅色立方體（完整代碼在文末的附錄中）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="code-1" src="https://oscimg.oschina.net/oscnet/up-5965c8a859ccc3bcc7f9db0d86caeb5f612.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;考慮到這是【純 RNN + 純預訓練 + 只訓練 2T tokens】，表現合理。後續更多數據的滿血版會顯著更強。&lt;/p&gt; 
&lt;h2&gt;RNN 的抗幹擾能力&lt;/h2&gt; 
&lt;p&gt;最新論文 &lt;code&gt;Inverse Scaling in Test-Time Compute&lt;/code&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417%25EF%25BC%2589%25E5%258F%2591%25E7%258E%25B0%25E5%2589%258D%25E6%25B2%25BF%25E6%25A8%25A1%25E5%259E%258B%25E5%259C%25A8%25E2%2580%259C%25E6%2581%25B6%25E6%2584%258F%25E9%2597%25AE%25E9%25A2%2598%25E2%2580%259D%25EF%25BC%2588%25E4%25BE%258B%25E5%25A6%2582%25E5%25B8%25A6%25E5%25B9%25B2%25E6%2589%25B0%25E9%25A1%25B9%25E7%259A%2584%25E8%25AE%25A1%25E6%2595%25B0%25E3%2580%2581%25E5%25B8%25A6%25E8%2599%259A%25E5%2581%2587%25E7%2589%25B9%25E5%25BE%2581%25E7%259A%2584%25E5%259B%259E%25E5%25BD%2592%25E9%25A2%2584%25E6%25B5%258B%25EF%25BC%258C%25E7%25AD%2589%25E7%25AD%2589%25EF%25BC%2589%25E4%25BC%259A%25E5%2587%25BA%25E7%258E%25B0%25E8%25B6%258A%25E6%2583%25B3%25E8%25B6%258A%25E5%25B7%25AE%25E7%259A%2584%25E6%2583%2585%25E5%2586%25B5%25EF%25BC%259A" target="_blank"&gt;https://arxiv.org/abs/2507.14417）發現前沿模型在「惡意問題」（例如帶幹擾項的計數、帶虛假特徵的迴歸預測，等等）會出現越想越差的情況：&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Inverse Scaling in Test-Time Compute" src="https://oscimg.oschina.net/oscnet/up-6ae323b74fd47a196c5d2c1f9fa0e6eba61.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們發現 RWKV7-G0 7.2B 可以克服幹擾，得到正確答案：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test" src="https://oscimg.oschina.net/oscnet/up-ae61d209ca82eea02e344618caff2afca92.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;繼續測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-1" src="https://oscimg.oschina.net/oscnet/up-514174dd1deab6244d08e752e541b0fd36e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;修改數字再測試：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="Test-Time-Compute-test-2" src="https://oscimg.oschina.net/oscnet/up-203991398541247ca9e64b89fa8da85280d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可見 attention 會導致 transformer 更易受前文幹擾，而 RNN 在此有優勢。而且 RNN 的思考過程永遠勻速，不會越想越慢。我們未來訓練更大的 RNN 會更有趣。&lt;/p&gt; 
&lt;h2&gt;模型下載&lt;/h2&gt; 
&lt;p&gt;下載 RWKV7-G0 7.2B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain" target="_blank"&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles" target="_blank"&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile" target="_blank"&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;如何使用 RWKV 模型&lt;/h2&gt; 
&lt;h3&gt;在線 demo（續寫模式）&lt;/h3&gt; 
&lt;p&gt;可以在 RWKV 官方 Gradio 中試用 RWKV7-G0 7.2B 模型（為避免排隊，這裏限制了輸入和輸出長度）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2" target="_blank"&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hugging Face Gradio 是續寫模式，使用時需要遵循 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fbasic%2FPrompt-Format" target="_blank"&gt;RWKV 的 prompt 格式&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G0 7.2B &lt;strong&gt;不思考模式&lt;/strong&gt;的 QA prompt 格式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如需開啓&lt;strong&gt;思考模式&lt;/strong&gt;，可在 QA prompt 的基礎上添加 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我可以抽乾太平洋的水然後下去抓魚嗎？

Assistant: &amp;lt;think&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;本地部署 RWKV 模型&lt;/h3&gt; 
&lt;p&gt;可以使用 RWKV Runner、Ai00、RWKV pip 等推理工具本地部署 RWKV 模型。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 模型也適配了 llama.cpp、ollama 等熱門的模型推理工具。&lt;/p&gt; 
&lt;p&gt;由於 RWKV7-G0 7.2B 是新模型，目前建議使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate%2FRWKV-Runner%2FIntroduction" target="_blank"&gt;RWKV Runner&lt;/a&gt; 以保證得到正確結果。&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Ftutorials%2Fintermediate" target="_blank"&gt;RWKV 官網 - 模型推理教程&lt;/a&gt;中查看上述推理工具的使用教程。&lt;/p&gt; 
&lt;h2&gt;未來訓練計劃&lt;/h2&gt; 
&lt;p&gt;我們也正在訓練 RWKV7-G0 13.3B 模型，以及使用更多 tokens、使用 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;DeepEmbed&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;DEA&lt;/a&gt; 技術的 RWKV-7s 模型。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 中文文檔：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;RWKV 論壇：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;QQ 頻道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;BiliBili 視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎大家基於 RWKV-7 進行創業、科研，我們也會為基於 RWKV 的項目提供技術支持。&lt;/p&gt; 
 &lt;p&gt;如果您的團隊正在基於 RWKV 創業或開展研究，請聯繫我們！（在「RWKV 元始智能」微信公眾號留言您的聯繫方式，或發送郵件到「contact@rwkvos.com」。）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;附錄：旋轉的紅色立方體&lt;/h2&gt; 
&lt;p&gt;將以下代碼保存為 &lt;code&gt;3d.html&lt;/code&gt; 並雙擊運行。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset="UTF-8"&amp;gt;
    &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
    &amp;lt;title&amp;gt;Rotating Red Box&amp;lt;/title&amp;gt;
    &amp;lt;style&amp;gt;
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script&amp;gt;
        // Create scene
        const scene = new THREE.Scene();
        
        // Create camera
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5;
        
        // Create renderer
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);
        // Create box geometry and material
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 }); // Red color
        
        // Create box mesh
        const box = new THREE.Mesh(geometry, material);
        
        // Add lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(0, 0, 10);
        scene.add(light);
        
        // Add box to scene
        scene.add(box);
        
        // Animation loop
        let angleX = 0;
        let angleY = 0;
        
        function animate() {
            requestAnimationFrame(animate);
            
            // Update rotation angles
            angleX += 0.01;
            angleY += 0.01;
            
            // Update box rotation
            box.rotation.x = angleX;
            box.rotation.y = angleY;
            
            // Render scene
            renderer.render(scene, camera);
        }
        
        animate();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362400</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362400</guid>
      <pubDate>Tue, 15 Jul 2025 10:54:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>谷歌 DeepMind 新架構 MoR 有望成為「Transformer 殺手」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 團隊發表論文《Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation》，&lt;strong&gt;提出新 Transformer 架構 Mixture-of-Recursions（MoR）&lt;/strong&gt;，旨在同時實現參數共享和自適應計算，以解決大型語言模型訓練和部署中的計算與內存開銷問題。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-17000d1f4f6bc815b75098237c70778d99f.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c76175988abdc82ca877e5b51ccc663dba8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2507.10524&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;MoR 的核心創新包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;參數效率&lt;/strong&gt;：通過共享層堆棧在不同遞歸步驟中複用參數，減少參數量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;動態計算&lt;/strong&gt;：輕量級路由器為每個 token 動態分配遞歸深度，複雜 token 可深入處理，簡單 token 可提前退出，從而將計算資源精準分配 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;內存優化&lt;/strong&gt;：採用遞歸級鍵值（KV）緩存機制，僅緩存活躍 token 的 KV 對，顯著降低內存帶寬壓力並提升推理吞吐量 。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;實驗結果顯示，在 135M 到 1.7B 參數規模的模型中，MoR 在相同訓練計算量下，驗證困惑度更低、少樣本準確率更高，推理吞吐量相比傳統 Transformer 和現有遞歸基線提升至多 2.18 倍，同時降低內存佔用和推理延遲。&lt;/p&gt; 
&lt;p&gt;因此，MoR 被認為可能在無需承擔大模型成本的情況下實現大模型質量，甚至被稱為「Transformer 殺手」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362399</guid>
      <pubDate>Tue, 15 Jul 2025 10:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>三分之一美國人藉助 AI 工具尋求職業轉型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根據東南俄克拉荷馬大學（SOU）&lt;span&gt;最新&lt;/span&gt;發佈的一項報告，約三分之一的美國人已開始使用 AI 工具，如 ChatGPT，來幫助他們進行職業轉型。該報告基於對 1000 名來自四個不同世代的美國人的調查，旨在瞭解 AI 在當前美國勞動市場劇烈變化中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;調查顯示，超過一半的受訪者表示，他們正在積極考慮換工作或職業轉型，其中以 Z 世代的 57% 比例&lt;span&gt;最高&lt;/span&gt;，隨後是千禧一代的 55%，X 世代的 50%，以及僅 12% 的嬰兒潮一代。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在那些表示 AI 對他們的職業轉型有所幫助的受訪者中，43% 的人使用 AI 工具撰寫簡歷和求職信，47% 的人則利用 AI 進行新工作機會的研究，包括尋找薪資更高的職位。值得注意的是，近五分之一的受訪者（18%）表示，AI 建議了他們之前未曾考慮過的全新職業路徑。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不過，儘管有不少人依賴 AI 來提供職業建議，調查也顯示大多數受訪者對 AI 提供的信息持謹慎態度。60% 的受訪者表示，他們更傾向於相信人類職業顧問的意見，而只有 7% 的人選擇相信 AI。一部分人（17%）甚至選擇遵循 AI 的建議，即使這些建議與他們之前從人類顧問那裏得到的意見相悖。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在各年齡層中，受訪者主要關注的職業機會集中在技術領域，其次是醫療和金融。隨着 AI 技術的不斷發展，許多人認為這可能導致大量白領職位的消失。例如，Anthropic 的首席執行官達裏奧・阿莫德伊預測，AI 將在未來五年內消除一半的白領工作。而亞馬遜首席執行官安迪・賈西也表示，AI 驅動的自動化將取代一些人類工作，同時使其他職位變得更加 「有趣」，並創造出全新的崗位。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技術公司招聘方面的數據也表明，隨着 AI 工具開始接管許多原本由年輕、經驗較少的員工完成的日常任務，科技公司對新近計算機科學畢業生的招聘數量有所減少。此外，在硅谷的激烈人才爭奪戰中，企業之間的競爭愈發激烈，特別是在人工智能研究方面的&lt;span&gt;頂尖&lt;/span&gt;人才更是稀缺。許多公司都願意為此支付高額薪資，以吸引那些能夠在技術突破中發揮關鍵作用的優秀研究人員。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362398</guid>
      <pubDate>Tue, 15 Jul 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>階躍星辰發佈最強開源多模態推理模型 Step3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰宣佈發佈新一代基礎大模型 Step3，主打多模態推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據介紹，這是階躍星辰首個全尺寸、原生多模態推理模型。在國產芯片 32K 上下文推理效率最高可達 DeepSeek R1 的 300%，在英偉達 H800 芯片將推理效率提升了 70% 以上。該模型將於 7 月 31 日向全球開源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e93e689dafce5406835a7db40fe0043af4b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，階躍星辰宣佈與上海國有資本投資有限公司達成深度戰略合作，並透露上海國投將參與階躍星辰的新一輪融資。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;階躍星辰創始人、CEO 姜大昕表示，階躍的商業化的成果體現在了收入數字上，基於上半年的高速增長，公司將全年的衝刺目標定在 10 億元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;會上，階躍還將聯合近 10 家芯片廠商和算力平台成立模新生態創新聯盟。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362393</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362393</guid>
      <pubDate>Tue, 15 Jul 2025 10:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>宇樹科技發佈第三款人形機器人 UnitreeR1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技在官微宣佈，正式發佈第三款人形機器人「Unitree R1 智能夥伴」，售價 3.99 萬元起，支持開發/改制，靈活超輕量約 25Kg，集成語音和圖像多模態大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宣傳視頻顯示，第三款人形機器人 Unitree R1 擁有 26 個關節，包括腿部 6*2+腰部 2+手臂 5*2+頭 2，可以實現翻跟頭、倒立行走、奔跑、打拳等動作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="361" src="https://oscimg.oschina.net/oscnet/up-47996978da023c9ec22be1f2e1c81a666e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，7 月 18 日，中國證監會官網顯示，宇樹科技已開啓上市輔導，由中信證券擔任輔導機構。輔導備案報告顯示，宇樹科技控股股東、實際控制人王興興直接持有公司 23.8216% 股權，並通過上海宇翼企業管理諮詢合夥企業（有限合夥）控制公司 10.9414% 股權，合計控制公司 34.7630% 股權。根據相關規定，宇樹科技最快將於 10 月完成輔導，這意味着宇樹科技有希望在今年年內登陸 A 股。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇樹科技是一家知名民用機器人公司。2016 年成立於杭州，創始人兼 CEO 是王興興。公司專注於消費級、行業級高性能通用足式/人形機器人及靈巧機械臂的研發、生產和銷售。其明星產品有 Unitree Go1 四足機器人等，2023 年起推出 H1、G1 等人形機器人。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362388</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362388</guid>
      <pubDate>Tue, 15 Jul 2025 10:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>科大訊飛推出升級版星火 X1 深度推理大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;科大訊飛&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-crxs5LkH1UoU0BQsJzmkA" target="_blank"&gt;宣佈&lt;/a&gt;正式推出了升級版的星火 X1 深度推理大模型。一些亮點內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;綜合能力大幅提升。整體效果對標 OpenAI o3 等國內外一流大模型最新版本效果，在翻譯、推理、文本生成、數學等方面保持領先。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;幻覺治理取得顯著進步。幻覺問題是掣肘大模型落地應用的關鍵問題，升級後的星火 X1 在幻覺治理方面領先業界主流模型。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多語言能力已覆蓋 130+語種。為世界提供全棧自主可控大模型底座的「第二種選擇」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;基於星火 X1 底座的語音同傳大模型在翻譯效果、實時響應、語音聽感、專業精深等方面大幅躍升，持續行業領先。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;得益於星火 X1 模型的升級，教育、醫療、企業應用、代碼、科研等行業大模型和智能體也取得了新的進步，在複雜行業場景任務上進一步解決用户關鍵剛需。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-ff3e38322ebbce182a8c6b9c032f75581ae.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-39ea728edd540a2fd33fd97fef826e1c5a7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-56fed82205eb5013f0c184ec5ea45dc94a2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，星火 X1 最新升級的各項能力可以通過訊飛星火的網頁版和手機應用體驗，同時新 API 也已上線。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362377</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362377</guid>
      <pubDate>Tue, 15 Jul 2025 09:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Genkit —— 用於構建全棧 AI 應用的框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Genkit 是一個用於構建全棧 AI 應用的開源框架，由 Google Firebase 構建並投入生產。它為多種編程語言提供 SDK，且穩定性級別各不相同：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JavaScript/TypeScript（穩定）&lt;/strong&gt;：已準備好投入生產，並支持全部功能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Go（測試版）&lt;/strong&gt;：功能齊全，但可能有重大變化&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python（Alpha）&lt;/strong&gt;：具有核心功能的早期開發&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;它提供統一的接口，用於集成來自&lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai"&gt;OpenAI&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;Anthropic&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/plugins/ollama/"&gt;Ollama&lt;/a&gt;等供應商的 AI 模型。使用精簡的 API（用於多模式內容、結構化輸出、工具調用和代理工作流），快速構建和部署可用於生產的聊天機器人、自動化和推薦系統。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;只需幾行代碼即可開始：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#cf222e"&gt;import&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;genkit&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;from&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;'genkit'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;&lt;span style="color:#cf222e"&gt;import&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;googleAI&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;from&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;'@genkit-ai/googleai'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;&lt;span style="color:#cf222e"&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;ai&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#6639ba"&gt;genkit&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;{&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;plugins&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;[&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;googleAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;}&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;&lt;span style="color:#cf222e"&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; text &lt;span&gt;}&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#cf222e"&gt;await&lt;/span&gt;&lt;/span&gt; &lt;span&gt;ai&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;generate&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style="color:#0550ae"&gt;model&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;googleAI&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style="color:#6639ba"&gt;model&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style="color:#0a3069"&gt;'gemini-2.0-flash'&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;&lt;span style="color:#0550ae"&gt;prompt&lt;/span&gt;&lt;/span&gt;: &lt;span&gt;&lt;span style="color:#0a3069"&gt;'Why is Firebase awesome?'&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;關鍵功能&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;table cellspacing="0" style="border-collapse:collapse; border-spacing:0px; border:undefined; box-sizing:border-box; display:block; font-variant:tabular-nums; margin-bottom:16px; margin-top:0px; max-width:100%; overflow:auto; width:max-content"&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;廣泛的人工智能模型支持&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用統一的界面集成來自&lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-openai"&gt;&amp;nbsp;OpenAI&lt;/a&gt;、&lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;&amp;nbsp;Anthropic&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/plugins/ollama"&gt;Ollama&lt;/a&gt;等提供商的數百個模型。探索、比較並使用最符合你需求的模型。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;簡化的 AI 開發&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用精簡的 API 構建 AI 功能，包括&lt;a href="https://genkit.dev/docs/models#structured-output"&gt;&amp;nbsp;結構化輸出&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/tool-calling"&gt;代理工具調用&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/rag"&gt;上下文感知生成&lt;/a&gt;、&lt;a href="https://genkit.dev/docs/models#multimodal"&gt;多模態輸入/輸出&lt;/a&gt;等。Genkit 可處理 AI 開發的複雜性，讓你能夠更快地構建和迭代。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;適用於網絡和移動設備&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用專門構建的&lt;a href="https://genkit.dev/docs/firebase"&gt;客户端 SDK&lt;/a&gt;和幫助程序與 Next.js、React、Angular、iOS、Android 等框架和平台無縫集成。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;跨語言支持&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用最適合你項目的語言進行構建。Genkit 提供 JavaScript/TypeScript（穩定版）、Go（測試版）和 Python（Alpha 版）的 SDK，並在所有支持的語言中提供一致的 API 和功能。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;隨處部署&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;將 AI 邏輯部署到支持你選擇的編程語言的任何環境，例如&lt;a href="https://genkit.dev/docs/firebase"&gt;Firebase 的 Cloud Functions&lt;/a&gt;、&amp;nbsp;&lt;a href="https://genkit.dev/docs/cloud-run"&gt;Google Cloud Run&lt;/a&gt;或&lt;a href="https://genkit.dev/docs/deploy-node"&gt;第三方平台&lt;/a&gt;（無論是否帶有 Google 服務）。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;開發人員工具&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用專用的本地&lt;a href="https://genkit.dev/docs/devtools"&gt;CLI 和開發者 UI&lt;/a&gt;加速 AI 開發。針對單個輸入或數據集測試提示和流程，比較不同模型的輸出，使用詳細的執行軌跡進行調試，並使用即時視覺反饋快速迭代提示。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;&lt;strong&gt;生產監控&lt;/strong&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;span&gt;使用全面的生產監控，自信地交付 AI 功能。在&lt;a href="https://genkit.dev/docs/observability/getting-started"&gt;專用儀錶板&lt;/a&gt;中跟蹤模型性能、請求量、延遲和錯誤率。通過詳細的可觀察性指標快速識別問題，並確保你的 AI 功能在實際使用中滿足質量和性能目標。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/genkit</link>
      <guid isPermaLink="false">https://www.oschina.net/p/genkit</guid>
      <pubDate>Tue, 15 Jul 2025 09:24:00 GMT</pubDate>
    </item>
    <item>
      <title>特斯拉強調輔助駕駛安全性：AI 硬件加持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特斯拉官方微博今日發文，重申了輔助駕駛技術在提升車輛安全性方面的重要性。根據特斯拉 2025 年第二季度安全報告，開啓輔助駕駛功能的特斯拉車輛，其安全性是普通車輛的 9.5 倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="414" src="https://oscimg.oschina.net/oscnet/up-96c1d1ada610ee1272da23c291a011df993.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特斯拉表示，其旗下 S3XY 全系現款在售車型均標配了&lt;strong&gt;AI4 智能輔助駕駛硬件&lt;/strong&gt;和輔助駕駛功能。官方宣稱，得益於這些先進的 AI 技術，特斯拉的輔助駕駛系統比人類駕駛更為可靠。特斯拉強調，其最終目標是實現「零事故」，並承諾將持續努力，確保每一位車主都能安心出行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次表態被視為特斯拉對近期懂車帝輔助駕駛測試的回應。近日，懂車帝聯合央視推出了《懂車智煉場》輔助駕駛科普節目，對 36 款車型進行了實測，測試結果引發了廣泛關注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，鴻蒙智行官微也疑似回應懂車帝測試表示，已看到某平台所謂「測試」，不予置評。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362357</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362357</guid>
      <pubDate>Tue, 15 Jul 2025 08:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 集成設計平台 Canva</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAnthropicAI%2Fstatus%2F1948489708385816666" target="_blank"&gt;宣佈&lt;/a&gt;其 AI 服務 Claude 已集成設計平台 Canva，這一集成旨在簡化從文本內容到圖形化表達的創作流程。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1458" src="https://static.oschina.net/uploads/space/2025/0725/155325_hioI_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/155813_ek4B_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過這項新功能，用户可以上傳任何書面內容，如博客文章、產品指南或會議記錄，並要求 Claude 將其轉化為帶有品牌風格的專業視覺設計。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362351</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362351</guid>
      <pubDate>Tue, 15 Jul 2025 07:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《2025 年度技術人才報告》解讀：AI+開源重塑人才市場</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;LF Research 聯合 Linux Foundation Education 正式發佈了《2025 年度技術人才報告》。該報告是基於全球 500 多位招聘和培訓決策者的調研，重點探討了 AI 對技術崗位日益增長的影響、企業如何為這一工作轉型做好準備，以及如何通過開源與技能提升滿足新的人才需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-887ec60bec2ffdf3d0a7092dfbbd202fe35.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AI 正在為眾多企業帶來深遠影響，94% 的組織認為 AI 將為其運營帶來顯著價值。但報告指出，不足一半的企業擁有適應 AI 時代所需的核心技術能力，難以釋放其業務與創新潛力。報告主要發現包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;68% 的企業缺乏具備 AI/ML 技能的員工；網絡安全與合規（65%）、FinOps（61%）、雲計算（59%）和平台工程（56%）等領域人才短缺的情況加劇了這個問題；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;44% 的受訪者認為「技術人才不足」是採納新技術的主要障礙；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;半數受訪組織表示，他們正在擴充 AI 專項人才隊伍，新增崗位包括 AI/ML 運維工程主管（64%）與 AI 產品經理（36%）。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;新興技術與技能缺口已開始實質地改變工作流程。三分之二的組織表示，AI 顯著改變了其團隊的工作方式。開發者需驗證 AI 生成的代碼，新員工需具備 AI 專業技能，許多初級的任務也被 AI 自動化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;為應對這些變化，企業正在加大對技能提升的投入。報告發現：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;72% 的組織正在優先考慮提升現有員工的技能，遠高於 2024 年的 48%；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;技能提升的速度比招聘新人才快 62%，且技術培訓項目在提高員工留存率方面的效果高出 91%；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;71% 的組織在招聘時重視持有認證的人才，將其視為專業能力的有效驗證；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;56% 的組織依靠技能提升來滿足 AI/ML 崗位需求，而非新增招聘或外包。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;開源技術在 AI 落地中也起到了重要戰略作用。40% 的受訪者表示，企業正在利用開源框架、模型和工具來加速 AI 應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查顯示，採用開源實踐的企業在員工留存與技能發展方面表現更佳：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;91% 的組織認為技術培訓是提高員工留存的有效方式；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;84% 的組織表示，擁有開源文化可提高員工穩定性與滿意度。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362350</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362350</guid>
      <pubDate>Tue, 15 Jul 2025 07:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 發佈 Magistral Small 1.1，增強推理能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Mistral AI 發佈了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmistralai%2FMagistral-Small-2507" target="_blank"&gt;Magistral Small 1.1&lt;/a&gt;（版本號 Magistral-Small-2507），這是一個擁有 240 億參數的小型高效推理模型。&lt;/p&gt; 
&lt;p&gt;該模型在 Mistral Small 3.1 (2503) 的基礎上，通過 Magistral Medium 的軌跡進行 SFT 和 RL 訓練，增加了推理能力，並優化了格式和模型行為。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/154554_SbAs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Magistral Small 1.1 的主要更新包括改善了語氣和模型行為，優化了 LaTeX 和 Markdown 格式，並減少了在簡單通用提示下生成過長答案的可能性，同時降低了進入無限生成循環的風險。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362349</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362349</guid>
      <pubDate>Tue, 15 Jul 2025 07:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Qwen3-Coder 和 Kimi-K2 均已上線模力方舟</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Kimi-K2 和 Qwen3-Coder 這兩個模型是最近在編程任務上表現不錯的開源模型，關於二者的比較可閲讀這篇文章：&lt;em&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison"&gt;Kimi K2 和 Qwen-3 Coder 在編程任務的詳細對比&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/360215/kimi-k2"&gt;&lt;strong&gt;Kimi K2&lt;/strong&gt;&amp;nbsp;&lt;/a&gt;是一個最先進的混合專家 (MoE) 語言模型，激活參數為 320 億，總參數為 1 萬億。通過 Muon 優化器進行訓練，Kimi K2 在前沿知識、推理和編碼任務上表現出色，同時在智能體能力方面進行了精心優化。&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/361848"&gt;&lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;&lt;/a&gt;&amp;nbsp; 是一款專為代碼生成、代碼理解和高效開發場景設計的大型語言模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模力方舟已上線這兩個模型：&lt;/p&gt; 
&lt;p&gt;&lt;img height="798" src="https://static.oschina.net/uploads/space/2025/0725/153841_vb9V_2720166.png" width="2540" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/153900_equi_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;訪問網址&amp;nbsp;&lt;a href="https://ai.gitee.com/serverless-api" target="_blank"&gt;https://ai.gitee.com/serverless-api&amp;nbsp;&lt;/a&gt;即可體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362345</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362345</guid>
      <pubDate>Tue, 15 Jul 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 CEO 皮查伊個人財富達 11 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#242424"&gt;Alphabet Inc. 本週憑藉一份重磅財報跨越了一個新的里程碑，標誌着該公司自 2023 年初以來市值增長超過 1 萬億美元的驚人增長曆程。據彭博社報道，Alphabet 在此期間為投資者帶來了 120% 的回報。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一飆升也使印度裔首席執行官桑達爾·皮查伊（Sundar Pichai）一躍成為億萬富翁。根據彭博億萬富翁指數，現年 53 歲的皮查伊目前的身價為 11 億美元，這主要得益於 Alphabet 的強勁增長以及多年來穩定的薪酬。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="370" src="https://oscimg.oschina.net/oscnet/up-bb4910901988674d27aa1657be7af73ddd9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;對於非公司創始 CEO 來説，這是一項罕見的成就，尤其是在科技行業，包括 Meta Platforms 的扎克伯格和英偉達的黃仁勳在內的許多高管的財富都來自於在各自公司的創始股權。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;儘管皮查伊在 1998 年穀歌創立時並不在場，但截至本月他將成為了任職時間最長的首席執行官，今年 8 月就將是他上任 10 週年。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Alphabet 股價週四一度上漲 4.1%，此前該公司公佈的第二季度業績好於預期。該公司將 2025 年的資本支出預期上調了 100 億美元，達到 850 億美元，主要用於資助人工智能基礎設施建設。「我們的人工智能基礎設施投資對於滿足雲客户需求的增長至關重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;該公司還公佈研發支出增長了 16%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/362043" target="news"&gt;谷歌母公司發佈 Q2 財報：全年資本支出飆升至 850 億美元&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362344</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362344</guid>
      <pubDate>Tue, 15 Jul 2025 07:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>清華大學&amp;生數科技提出可控長時文生音頻系統 FreeAudio</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;清華大學與生數科技&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRmYYXiW0yU8Ey8BbzkYMSw" target="_blank"&gt;合作&lt;/a&gt;發表論文，提出了一種名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffreeaudio.github.io%2FFreeAudio%2F" target="_blank"&gt;FreeAudio&lt;/a&gt;的精準時間可控長時文生音頻系統。該系統無需額外訓練，即可基於自然語言文本和時間提示，生成超過 10 秒且時間點精確可控的音頻，突破了現有技術普遍存在的 10 秒時長限制。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/153316_1wmg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/abs/2507.08557&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;FreeAudio 系統利用大語言模型（LLM）對時間結構進行規劃，將複雜的文本和時間提示解析為一系列不重疊的時間窗口，併為每個窗口生成獨立的描述。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/153346_YDxo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0725/153420_m0XE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;隨後，通過「解耦與聚合注意力控制」機制，在 DiT-based T2A 模型中引導各子段與對應描述對齊。最後，通過上下文潛變量合成、參考引導和上下文修剪與拼接等長時生成優化技術，確保音頻片段間的平滑過渡和全局一致性。在 AudioCondition 測試集上，FreeAudio 的事件級和片段級得分均排名第一，並在多項客觀和主觀評估中表現優異。&lt;/p&gt; 
&lt;p&gt;該研究成果已被計算機多媒體領域的頂級會議 ACM Multimedia 2025 錄用，並可能在未來應用於生數科技的 Vidu 產品中。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362341</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362341</guid>
      <pubDate>Tue, 15 Jul 2025 07:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源企業級智能體平台 MaxKB 正式發佈 v1.10.9 LTS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#000000; text-align:start"&gt;2025 年 7 月 24 日，MaxKB 開源企業級智能體平台正式發佈 v1.10.9 LTS 版本。這一版本主要進行了一些問題修復工作。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;問題修復&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;安全：修復 MCP 調用時可能存在的遠程命令執行漏洞（CVE-2025-53928）；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：修復飛書知識庫文檔在「設置」功能中修改「命中處理方式」選項時保存報錯的問題（X-Pack）；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知識庫：修復在文檔中添加、刪除、修改分段操作後，文檔列表的更新時間未同步更新的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;函數庫：修復內置的數據庫查詢函數序列化為 JSON 字符串時失敗的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復通過快捷鍵複製粘貼圖片時，會覆蓋此前上傳圖片的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：修復 Firefox 瀏覽器無法通過拖拽方式上傳文件的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復上傳的文件名稱中含有「&lt;/span&gt;&lt;em&gt;&lt;span&gt;&amp;amp;nbsp&lt;/span&gt;&lt;/em&gt;&lt;span&gt;」 字符時，不顯示 URL 的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：修復應用名稱過長導致界面顯示錯位的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;問答頁面：修復對話記錄超過 20 條後無法展示最新提問的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;問答頁面：修復開場白中單個英文單詞被拆分顯示到兩行的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復簡易應用未在「顯示設置」功能中勾選「顯示歷史記錄」選項時，問答頁面顯示異常的問題（X-Pack）；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復高級編排應用中，部分情況下丟失思考過程標籤的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復對話用户併發較多時，特殊情況下會出現數據庫文件損壞的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復在對話日誌中自定義查詢時間後導出報錯的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復通過 API Key 進行非流式對話時未統計 Token 消耗的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復指定回覆節點輸出的表單參數中含有特殊字符導致報錯的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;應用：修復 MCP 節點的配置信息填寫錯誤時提示信息不正確的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;應用：修復使用阿里雲百鍊的 DeepSeek-R1 模型通過 Streamable HTTP MCP 方式調用 MCP 服務時無法返回內容的問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;安裝部署：修復若干已知問題；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;API 文檔：修復若干已知問題。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4736111/blog/18685802</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/18685802</guid>
      <pubDate>Tue, 15 Jul 2025 07:28:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>從 「卡頓」 到 「秒開」：外投首屏性能優化的 6 個實戰錦囊</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18684649</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18684649</guid>
      <pubDate>Tue, 15 Jul 2025 07:25:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Anthropic 組建「AI 精神病學」團隊</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;昨日，Anthropic 神經科學研究員 Jack Lindsey &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FJack_W_Lindsey%2Fstatus%2F1948138767753326654" target="_blank"&gt;宣佈&lt;/a&gt;，公司將成立「AI 精神病學」團隊，作為其可解釋性部門的重要組成部分，旨在研究模型的角色、動機和情境意識，以及如何導致詭異、失控等行為表現，以建立對神經網絡的機制性理解並確保其安全性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-02d75dfdeeb8071e8534839cdb867691694.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該團隊短期內重點攻克「疊加」問題（導致模型神經元和注意力頭等計算單元難以單獨解釋），並致力於將模型分解為更具可解釋性的組件。&lt;/p&gt; 
&lt;p&gt;目前，Anthropic 正在招聘研究科學家（年薪 31.5-56 萬美元，約合人民幣 220 萬-400 萬元）加入該團隊，鼓勵任何有意願的人申請，並非所有候選人需完全符合列出的資格要求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362333</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362333</guid>
      <pubDate>Tue, 15 Jul 2025 07:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>新起點·新徵程·新高度！禪道軟件全面升級為集團公司</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#39485d; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;2025 年 7 月，禪道軟件（青島）有限公司全面升級，正式更名為禪道軟件（青島）集團有限公司（&lt;strong&gt;以&lt;/strong&gt;下簡稱「禪道集團」）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#39485d; margin-left:0; margin-right:0; text-align:start"&gt;此次戰略升級標誌着禪道在深耕項目管理領域 16 年後，正式邁入規模化、多元化發展的全新格局，也標誌着禪道在企業規模、業務佈局和發展戰略上邁入了全新階段。&lt;/p&gt; 
&lt;p style="color:#39485d; margin-left:0; margin-right:0; text-align:center"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zentao.net%2Ffile.php%3Ff%3Dzentao%2F202507%2Ff_9ddee713753c983c95c1c0405e560671%26t%3Dpng%26o%3D%26s%3D%26v%3D1753082376" target="_blank"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7f1679fb170766fcc44a1592300e0a77.jpg" referrerpolicy="no-referrer"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;集團化升級，開創發展新高度&lt;/h2&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#39485d"&gt;禪道集團的升級，是公司戰略佈局的重要里程碑，也是對客户價值的深度承諾。升級後的禪道集團，依託在項目管理領域的深厚積累，持續深耕項目管理領域，聚焦企業協作效率提升，通過技術創新與管理實踐的融合，讓更多企業享受數字化轉型紅利。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;聚力前行，共築項目管理新生態&lt;/h2&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#39485d"&gt;作為國內領先的項目管理軟件提供商，禪道集團始終致力於為企業提供專業、高效的項目管理解決方案。升級後的禪道集團將進一步整合資源優勢，完善旗下產品和服務生態，為廣大用户提供更加全面、優質的項目管理服務體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;不忘初心，賦能每一個成長中的企業&lt;/h2&gt; 
&lt;p style="color:#39485d; margin-left:0; margin-right:0; text-align:start"&gt;升級後的禪道集團將繼續堅持自主研發與開源開放的初心，秉承「讓每一個成長中的企業都可高效協作」的使命，不斷創新產品技術，拓展業務領域，全面賦能企業智能化轉型，為推動項目管理行業發展貢獻更大力量。&lt;/p&gt; 
&lt;p style="color:#39485d; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;站在新的起點，未來的禪道集團將以更開放的姿態、更專業的服務，與百萬用户共同書寫國產項目管理新篇章！&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362330</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362330</guid>
      <pubDate>Tue, 15 Jul 2025 07:22:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
  </channel>
</rss>
