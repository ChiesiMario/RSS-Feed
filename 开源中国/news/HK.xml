<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 21 Aug 2025 03:40:29 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>systemd 259 將提高運行系統要求，棄用舊版 iptables</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;隨着 systemd 258 正式推出（目前已發佈 rc3 候選版本），開發團隊已公佈下一個版本 &lt;strong&gt;systemd 259&lt;/strong&gt; 的重要調整：它將全面提高依賴組件的最低版本要求，並逐步淘汰舊技術支持。&lt;/p&gt; 
&lt;p&gt;具體來看，systemd 259 要求運行環境至少滿足以下條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux 內核&lt;/strong&gt; 5.10+（推薦 5.14+）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;glibc&lt;/strong&gt; 2.34+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;libxcrypt&lt;/strong&gt; 4.4.0+（不再依賴 glibc 內建 libcrypt）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;util-linux&lt;/strong&gt; 2.37+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;elfutils&lt;/strong&gt; 0.177+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenSSL&lt;/strong&gt; 3.0.0+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;cryptsetup&lt;/strong&gt; 2.4.0+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;libfido2&lt;/strong&gt; 1.5.0+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;libseccomp&lt;/strong&gt; 2.4.0+&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt; 3.9+&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;值得注意的是，systemd 259 還將 &lt;strong&gt;移除對舊版 iptables（libiptc）的支持&lt;/strong&gt;。這意味着使用 &lt;strong&gt;systemd-networkd&lt;/strong&gt; 或 &lt;strong&gt;systemd-nspawn&lt;/strong&gt; 的用户必須轉向 &lt;strong&gt;nftables&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;總體來看，對這些組件版本做出要求上調「似乎合乎情理」，並且對於那些自己手動編譯 systemd 最新版本的用户來説，這些新要求「可能不會帶來太大問題」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0821/113310_VlmL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;https://github.com/systemd/systemd/releases/tag/v258-rc3&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367576/systemd-259-requirements</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367576/systemd-259-requirements</guid>
      <pubDate>Thu, 21 Aug 2025 03:33:30 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>金山辦公半年報：AI 月活用户突破 2900 萬，WPS365 營收暴增 62%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;金山辦公（688111）發佈 2025 年半年報，展現出穩健的增長態勢。公司上半年實現營業收入 26.57 億元，同比增長 10.12%；歸屬於母公司所有者淨利潤 7.47 億元，同比增長 3.57%；;扣非淨利潤 7.27 億元，同比增長 5.77%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AI 技術的深度應用為金山辦公帶來顯著效果。截至 6 月 30 日，WPS AI 月活躍用户數達 2951 萬，較 2024 年底的 1968 萬實現大幅增長。WPS Office 全球月度活躍設備數創歷史新高，達 6.51 億，同比增長 8.56%，其中 PC 版月活 3.05 億，移動版月活 3.46 億。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;個人業務方面，WPS 個人業務收入 17.48 億元，同比增長 8.38%。國內累計年度付費個人用户數 4179 萬，同比增長 9.54%；海外付費用户 189 萬，收入 1.29 億元。海外市場通過優化本地運營及 AI 權益部署，用户增長效率持續提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="287" src="https://static.oschina.net/uploads/space/2025/0821/113303_siIk_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;企業級市場表現亮眼，WPS365 業務收入 3.09 億元，同比增長 62.27%，成為公司業務增長新引擎。該業務加速行業解決方案落地，在教育領域覆蓋雙一流院校達 75%，服務超 1000 家高校及 2000 萬師生。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在政企領域，WPS365 推出"企業大腦"解決方案，整合 AI Hub、AI Docs 和 Copilot Pro，新增中國聯通、長江三峽集團、中國電氣裝備集團等標杆客户。升級後的智能文檔庫表格識別召回準確率高達 95% 以上，多格式文檔解析能力行業領先。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;報告期內，金山辦公發佈 WPS AI3.0 並推出原生 Office 辦公智能體——WPS 靈犀，通過"雙向改造"重新定義 AI 與辦公軟件的融合模式。WPS 靈犀獲評 2025 世界人工智能大會"鎮館之寶"獎項，具備多輪對話、修改可控、格式保留等優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;創新功能包括 AI 改文檔的"左側 Office、右側靈犀"同屏交互方式，WPS AIPPT 支持自然語句動態優化大綱，以及業內首個支持"聊文檔"的靈犀語音助手。WPS 知識庫支持一鍵升級雲文檔，單文件解析量級達 500M。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;公司 2025 上半年研發投入 9.59 億元，同比增長 18.70%，研發費用率約 36%。截至報告期末，研發人員 3533 人，佔總員工數比例約 66%，為技術突破提供堅實支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;東吳證券和華創證券研報均看好金山辦公在 AI+企業服務領域的投資價值，認為公司在 AI Agent 規模化落地背景下具有重要機會。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367574</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367574</guid>
      <pubDate>Thu, 21 Aug 2025 03:31:30 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>高性能緩存設計：如何解決緩存偽共享問題</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在多核高併發場景下，&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;緩存偽共享（False Sharing）&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp; 是導致性能驟降的「隱形殺手」。當不同線程頻繁修改同一緩存行（Cache &amp;nbsp;Line）中的獨立變量時，CPU 緩存一致性協議會強制同步整個緩存行，引發無效化風暴，使看似無關的變量操作拖慢整體效率。本文從緩存結構原理出發，通過實驗代碼復現偽共享問題（耗時從 3709ms 優化至 473ms），解析其底層機制；同時深入剖析高性能緩存庫 &amp;nbsp;Caffeine 如何通過&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;內存填充技術&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;（120 字節佔位變量）隔離關鍵字段，以及 JDK 1.8 的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;@Contended&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;註解如何以「空間換時間」策略高效解決偽共享問題，揭示緩存一致性優化的核心思想與實踐價值，為開發者提供性能調優的關鍵思路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
 &lt;h3 style="text-align:left"&gt;&lt;span&gt;&lt;strong&gt;偽共享&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;偽共享&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;（False &amp;nbsp;sharing）是一種會導致性能下降的使用模式，最常見於現代多處理器 CPU 緩存中。當不同線程頻繁修改同一緩存行（Cache &amp;nbsp;Line）中不同變量時，由於 CPU 緩存一致性協議（如 MESI）會強制同步整個緩存行，導致線程間無實際數據競爭的邏輯變量被迫觸發緩存行無效化（Invalidation），引發頻繁的內存訪問和性能下降。儘管這些變量在代碼層面彼此獨立，但因物理內存佈局相鄰，共享同一緩存行，造成「虛假競爭」，需通過內存填充或字段隔離使其獨佔緩存行解決。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;接下來我們討論並驗證在 CPU 緩存中是如何發生偽共享問題的，首先我們需要先介紹一下 CPU 的緩存結構，如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="cpu_cache.png" src="https://oscimg.oschina.net/oscnet/aa55ef0e-e751-44a8-8c1e-7f3b65df1a5d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;CPU Cache 通常分為大小不等的三級緩存，分別為 L1 Cache、L2 Cache、L3 &amp;nbsp;Cache，越靠近 CPU 的緩存，速度越快，容量也越小。CPU Cache 實際上由很多個緩存行 Cache Line 組成，通常它的大小為 &amp;nbsp;64 字節（或 128 字節），是 CPU 從內存中&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;讀取數據的基本單位&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;，如果訪問一個&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;long[]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;數組，當其中一個值被加載到緩存中時，它會額外加載另外 7 個元素到緩存中。那麼我們考慮這樣一種情況，CPU 的兩個核心分別訪問和修改統一緩存行中的數據，如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="偽共享問題.drawio.png" src="https://oscimg.oschina.net/oscnet/cfacaa63-82cd-48e0-8f47-25e712a69542.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;核心 1 不斷地訪問和更新值 X，核心 2 則不斷地訪問和更新值 &amp;nbsp;Y，事實上每當有核心對某一緩存行中的數據進行修改時，都會導致其他核心的緩存行失效，從而導致其他核心需要重新加載緩存行數據，進而導致性能下降，這也就是我們上文中所説的緩存偽共享問題。接下來我們用一段代碼來驗證下緩存偽共享問題造成的性能損失，如下所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;TestFalseSharing&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;static&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;Pointer&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// 兩個 volatile 變量，保證可見性&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;x;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; @Override&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;String&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;toString&lt;/span&gt;&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;return&lt;/span&gt;&amp;nbsp;&lt;span&gt;"x="&lt;/span&gt;&amp;nbsp;+ x +&amp;nbsp;&lt;span&gt;", y="&lt;/span&gt;&amp;nbsp;+ y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; @Test&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;testFalseSharing&lt;/span&gt;&lt;/span&gt;&lt;span&gt;() throws InterruptedException&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Pointer pointer =&amp;nbsp;&lt;span&gt;new&lt;/span&gt;&amp;nbsp;Pointer();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// 啓動兩個線程，分別對 x 和 y 進行自增 1 億，次的操作&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;start = System.currentTimeMillis();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Thread t1 =&amp;nbsp;&lt;span&gt;new&lt;/span&gt;&amp;nbsp;Thread(() -&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;for&lt;/span&gt;&amp;nbsp;(&lt;span&gt;int&lt;/span&gt;&amp;nbsp;i =&amp;nbsp;&lt;span&gt;0&lt;/span&gt;; i &amp;lt;&amp;nbsp;&lt;span&gt;100&lt;/span&gt;_000_000; i++) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pointer.x++;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; });&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Thread t2 =&amp;nbsp;&lt;span&gt;new&lt;/span&gt;&amp;nbsp;Thread(() -&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;for&lt;/span&gt;&amp;nbsp;(&lt;span&gt;int&lt;/span&gt;&amp;nbsp;i =&amp;nbsp;&lt;span&gt;0&lt;/span&gt;; i &amp;lt;&amp;nbsp;&lt;span&gt;100&lt;/span&gt;_000_000; i++) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; pointer.y++;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; });&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t1.start();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t2.start();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t1.&lt;span&gt;join&lt;/span&gt;();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; t2.&lt;span&gt;join&lt;/span&gt;();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; System.&lt;span&gt;out&lt;/span&gt;.println(System.currentTimeMillis() - start);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; System.&lt;span&gt;out&lt;/span&gt;.println(pointer);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre style="text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;這種情況下會發生緩存的偽共享，x 和 y &amp;nbsp;被加載到同一緩存行中，當其中一個值被修改時，會使另一個核心中的該緩存行失效並重新加載，代碼執行實際耗時為 3709ms。如果我們將 x &amp;nbsp;變量後再添加上 7 個 long 型的元素，使得變量 x 和變量 y 分配到不同的緩存行中，那麼理論上性能將得到提升，我們實驗一下：&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;TestFalseSharing&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;static&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;Pointer&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;x;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;p1, p2, p3, p4, p5, p6, p7;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;String&amp;nbsp;&lt;span&gt;toString&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;return&lt;/span&gt;&amp;nbsp;&lt;span&gt;"x="&lt;/span&gt;&amp;nbsp;+ x +&amp;nbsp;&lt;span&gt;", y="&lt;/span&gt;&amp;nbsp;+ y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Test&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;void&lt;/span&gt;&amp;nbsp;&lt;span&gt;testFalseSharing&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&amp;nbsp;&lt;span&gt;throws&lt;/span&gt;&amp;nbsp;InterruptedException {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// ...&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre style="text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;本次任務執行耗時為 473ms，性能得到了極大的提升。現在我們已經清楚的瞭解了緩存偽共享問題，接下來我們討論下在 Caffeine 中是如何解決緩存偽共享問題的。&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
 &lt;h3 style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;Caffeine 對緩存偽共享問題的解決方案&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在，緩存之美：萬文詳解 Caffeine 實現原理，中我們提到過，負責記錄寫後任務的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;WriterBuffer&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;數據結構的類繼承關係如下所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="WriteBuffer.drawio.png" src="https://oscimg.oschina.net/oscnet/4530771c-ae81-4fff-b8c9-6200bec97db3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;如圖中標紅的類所示，它們都是用來解決偽共享問題的，我們以&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;BaseMpscLinkedArrayQueuePad1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;為例來看下它的實現：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;abstract&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;BaseMpscLinkedArrayQueuePad1&lt;/span&gt;&amp;lt;&lt;span&gt;E&lt;/span&gt;&amp;gt;&amp;nbsp;&lt;span&gt;extends&lt;/span&gt;&amp;nbsp;&lt;span&gt;AbstractQueue&lt;/span&gt;&amp;lt;&lt;span&gt;E&lt;/span&gt;&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p000, p001, p002, p003, p004, p005, p006, p007;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p008, p009, p010, p011, p012, p013, p014, p015;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p016, p017, p018, p019, p020, p021, p022, p023;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p024, p025, p026, p027, p028, p029, p030, p031;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p032, p033, p034, p035, p036, p037, p038, p039;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p040, p041, p042, p043, p044, p045, p046, p047;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p048, p049, p050, p051, p052, p053, p054, p055;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p056, p057, p058, p059, p060, p061, p062, p063;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p064, p065, p066, p067, p068, p069, p070, p071;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p072, p073, p074, p075, p076, p077, p078, p079;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p080, p081, p082, p083, p084, p085, p086, p087;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p088, p089, p090, p091, p092, p093, p094, p095;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p096, p097, p098, p099, p100, p101, p102, p103;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p104, p105, p106, p107, p108, p109, p110, p111;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;byte&lt;/span&gt;&amp;nbsp;p112, p113, p114, p115, p116, p117, p118, p119;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;abstract&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;BaseMpscLinkedArrayQueueProducerFields&lt;/span&gt;&amp;lt;&lt;span&gt;E&lt;/span&gt;&amp;gt;&amp;nbsp;&lt;span&gt;extends&lt;/span&gt;&amp;nbsp;&lt;span&gt;BaseMpscLinkedArrayQueuePad1&lt;/span&gt;&amp;lt;&lt;span&gt;E&lt;/span&gt;&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// 生產者操作索引（並不對應緩衝區 producerBuffer 中索引位置）&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;protected&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;producerIndex;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;可以發現在這個類中定義了 120 個字節變量，這樣緩存行大小不論是 64 字節還是 128 字節，都能保證字段間的隔離。如圖中所示&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;AbstractQueue&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;和&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;BaseMpscLinkedArrayQueueProducerFields&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中的變量一定會&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;被分配到不同的緩存行&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中。同理，藉助&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;BaseMpscLinkedArrayQueuePad2&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中的 120 個字節變量，&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;BaseMpscLinkedArrayQueueProducerFields&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;和&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;BaseMpscLinkedArrayQueueConsumerFields&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中的變量也會被分配到不同的緩存行中，這樣就避免了緩存的偽共享問題。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;其實除了 Caffeine 中有解決緩存偽共享問題的方案外，在 JDK 1.8 中引入了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;@Contended&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;註解，它也可以解決緩存偽共享問題，如下所示為它在&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;ConcurrentHashMap&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中的應用：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;ConcurrentHashMap&lt;/span&gt;&amp;lt;K,V&amp;gt;&amp;nbsp;&lt;span&gt;extends&lt;/span&gt;&amp;nbsp;&lt;span&gt;AbstractMap&lt;/span&gt;&amp;lt;K,V&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;implements&lt;/span&gt;&amp;nbsp;&lt;span&gt;ConcurrentMap&lt;/span&gt;&amp;lt;K,V&amp;gt;, Serializable {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// ...&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@sun&lt;/span&gt;.misc.Contended&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;static&lt;/span&gt;&amp;nbsp;&lt;span&gt;final&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;CounterCell&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;value;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; CounterCell(&lt;span&gt;long&lt;/span&gt;&amp;nbsp;x) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; value = x;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre style="text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;其中的內部類&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;CounterCell&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;被標記了&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;@sun.misc.Contended&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;註解，表示該類中的字段會與其他類的字段相隔離，如果類中有多個字段，實際上該類中的變量間是不隔離的，這些字段可能被分配到同一緩存行中。因為&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;CounterCell&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中只有一個字段，所以它會被被分配到一個緩存行中，剩餘緩存行容量被空白內存填充，本質上也是一種以空間換時間的策略。這樣其他變量的變更就不會影響到&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;CounterCell&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;中的變量了，從而避免了緩存偽共享問題。&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;這個註解不僅能標記在類上，還能標記在字段上，拿我們的的代碼來舉例：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;TestFalseSharing&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;static&lt;/span&gt;&amp;nbsp;&lt;span&gt;class&lt;/span&gt;&amp;nbsp;&lt;span&gt;Pointer&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Contended("cacheLine1")&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;x;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;long p1, p2, p3, p4, p5, p6, p7;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Contended("cacheLine2")&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;volatile&lt;/span&gt;&amp;nbsp;&lt;span&gt;long&lt;/span&gt;&amp;nbsp;y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;String&amp;nbsp;&lt;span&gt;toString&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;return&lt;/span&gt;&amp;nbsp;&lt;span&gt;"x="&lt;/span&gt;&amp;nbsp;+ x +&amp;nbsp;&lt;span&gt;", y="&lt;/span&gt;&amp;nbsp;+ y;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;
&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;@Test&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;public&lt;/span&gt;&amp;nbsp;&lt;span&gt;void&lt;/span&gt;&amp;nbsp;&lt;span&gt;testFalseSharing&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&amp;nbsp;&lt;span&gt;throws&lt;/span&gt;&amp;nbsp;InterruptedException {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span&gt;// ...&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre style="text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;它可以指定內容來&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;定義多個字段間的隔離關係&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;。我們使用註解將這兩個字段定義在兩個不同的緩存行中，執行結果耗時與顯示聲明字段佔位耗時相差不大，為 520ms。另外需要注意的是，要想使註解&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;Contended&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;生效，需要添加 JVM 參數&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;-XX:-RestrictContended&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt; 
 &lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
 &lt;h3 style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;再談偽共享&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;避免偽共享的主要方法是代碼檢查，而且偽共享可能不太容易被識別出來，因為只有在線程訪問的是不同且碰巧在主存中相鄰的全局變量時才會出現偽共享問題，線程的局部存儲或者局部變量不會是偽共享的來源。此外，解決偽共享問題的本質是以空間換時間，所以並不適用於在大範圍內解決該問題，否則會造成大量的內存浪費。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet/7bafa35a-90f7-48c8-8f49-5a34b1595a0b.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span&gt;&lt;span&gt;掃一掃，加入技術交流羣&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style="color:#858585"&gt;本文分享自微信公眾號 - 京東雲開發者（JDT_Developers）。&lt;br&gt; 如有侵權，請聯繫 support@oschina.cn 刪除。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18683171</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18683171</guid>
      <pubDate>Thu, 21 Aug 2025 03:15:30 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>騰訊 Kuikly 開源框架新增支持 Web</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Kuikly 是騰訊廣泛應用的跨端開發框架，基於 Kotlin Multiplatform 技術構建，為開發者提供了技術棧更統一的跨端開發體驗，由騰訊大前端領域 Oteam（公司級）推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;本次在 Android、iOS、鴻蒙開源基礎上，將新增開源 Web 版，支持&lt;strong style="color:#3e4753"&gt;H5&lt;/strong&gt;和&lt;strong style="color:#3e4753"&gt;微信小程序&lt;/strong&gt;，進一步擴展多端適配場景。Kuikly 適配的 H5 和微信小程序已接入騰訊多款業務，如搜狗輸入法、鵝毛市集、QQ 小遊戲等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kuikly Web 版在 H5 和微信小程序上已經實現了絕大多數核心組件能力，運行效果如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="458" src="https://oscimg.oschina.net/oscnet/up-26eba6de49c36b7b6604edca4017c18a207.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Kuikly 是基於客户端技術棧設計，在支持 Android、iOS、鴻蒙高性能跨端的基礎上，拓展支持 H5 和小程序，以達到更多端的複用。這與一些業界跨端框架定位是類似的，如 Flutter、Compose Multiplatform 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;官方從其中挑選了兩個框架，從多個維度與它們對比在 H5 與微信小程序場景下的差異。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;產物大小&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在 H5 平台上，三個框架編譯產物大小差別很大，Kuikly 包體積優勢明顯。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;業界基於終端技術棧的跨端方案，都是通過自繪引擎，通過 WASM 技術運行在瀏覽器上，編譯後產物體積很大。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;Kuikly Web 使用 DOM 渲染方案，不依賴第三方產物，產物遠小於其他框架，只有 463KB。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-5b25ce97181f67aff6ea73e9b3980f446fe.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;頁面加載速度&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在 iOS，Android 和 PC 瀏覽器環境進行性能測試 (運行 Hello World Demo)，Kuikly 在三個瀏覽器環境下加載速度都是最快的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;iOS 加載速度對比&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="270" src="https://oscimg.oschina.net/oscnet/up-27280d66307e6df8ddd303421bb8a23aad6.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;Android 加載速度對比&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="278" src="https://oscimg.oschina.net/oscnet/up-28e3107909042c55583b2ec7091dd435b7a.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;PC 性能數據對比&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在 MacBook Pro M4Pro 電腦的 Chrome 瀏覽器 (138.0.7204.158) 上，使用開發者工具上進行了詳細的性能測試。測出 Kuikly 的 FCP 耗時僅為 87.76ms，不到其他框架的一半。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="330" src="https://oscimg.oschina.net/oscnet/up-3f8064ac0857c8405a77ac1d882e7541d0b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;其他優勢&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在 H5 平台上與主流跨端框架對比，Kuikly 還具有以下優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;開發體驗: &amp;nbsp;Android Studio 完善的開發支持。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;代碼調試: &amp;nbsp;可直接調試 JS 或通過 SourceMap 調試 Kotlin。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;SEO 友好: &amp;nbsp;採用 DOM 渲染，傳統的 SEO 優化都可以生效。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;兼容性好: &amp;nbsp;僅依賴 ES6 和 CSS3 特性，大部分設備都支持。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;生態複用: &amp;nbsp;編譯產物是 JS，採用 DOM 渲染方案，可通過 Kuikly 自定義擴展複用 React 等 H5 生態庫。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;微信小程序支持&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;主流的基於終端技術棧的跨端框架，缺少官方微信小程序運行方案支持，&lt;strong style="color:#3e4753"&gt;Kuikly Web 版微信小程序&lt;/strong&gt;的出現填補了這部分空白。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;Kuikly 的架構設計回顧&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;簡單迴歸一下 Kuikly 的整體架構，跨端 Core 層處理框架核心邏輯，Render 層負責不同平台渲染。新平台接入 Kuikly 需要實現自己的 Render 層。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="271" src="https://oscimg.oschina.net/oscnet/up-00796c13ed7fc388ea9fbfaaeea7c5acbac.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;Kuikly Web 版本整體方案設計&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在進行 Kuikly Web 版 H5 和微信小程序適配工作時，發現許多代碼可以共用，因此抽象了一個&lt;strong style="color:#3e4753"&gt;Web 容器運行時&lt;/strong&gt;作為適配層，這個適配層依賴抽象的&lt;strong style="color:#3e4753"&gt;DOM API&lt;/strong&gt;、&lt;strong style="color:#3e4753"&gt;KuiklyWindow&lt;/strong&gt;、&lt;strong style="color:#3e4753"&gt;KuiklyDocument&lt;/strong&gt;，實現了絕大部分 Render 邏輯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="459" src="https://oscimg.oschina.net/oscnet/up-b5941e643a63f02ecd410ab78aec4fe93db.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;Web 容器運行時&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;通過抽象核心接口構建 Web 容器運行時，實現了以下能力：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;將 Kuikly 的 UI 操作轉換為標準 DOM 操作&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;為差異化模塊（動畫/列表/文本測量等）提供擴展接口&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;支持 JS 宿主通過實現 Web 容器運行時接口，接入 Kuikly&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;H5 運行時&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;瀏覽器提供了標準的 DOM，Window，Document。Kuikly 適配 H5 時只需實現動畫，滾動列表，文本測量等少部分 Web 容器運行時拓展接口。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="255" src="https://oscimg.oschina.net/oscnet/up-de16c24658498c58d968d9839cc175a565b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;微信小程序運行時&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;項目團隊在適配微信小程序之前，調研了目前支持微信小程序的跨端框架。這些框架基本都是基於前端技術，在微信小程序上基本採用編譯時或者運行時方案，最終都是數據驅動模板完成 UI 渲染。如下圖：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="441" src="https://oscimg.oschina.net/oscnet/up-39acc3990f6fabf312c1dbbbd4917a4b113.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;借鑑了業界主流小程序框架 Tarojs 和 Kbone 的思路，結合 Kuikly 框架的特點，通過實現 Web 容器運行時接口，提供輕量級 DOM 和拓展接口實現，僅實現 Kuikly 需要的能力，並做了一系列針對 Kuikly 渲染流程的優化。如下圖：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-025a75a0f0cf58fe6c86b63b2afadf35565.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e4753; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;目前 Kuikly 適配微信小程序的方案在性能上仍有不少優化空間，後續將會探索編譯 Kuikly 產物為 WASM，使用預編譯等方式優化 Kuikly 在微信小程序平台的體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#000000"&gt;&lt;strong style="color:#3e4753"&gt;技術展望&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;繼續對 Kuikly Web 版進行性能優化，使用預編譯進一步提升小程序性能，同時減少編譯產物大小。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;探索使用 WASM 提升計算密集型任務的執行效率，優化 Kuikly Web 版的使用體驗&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span style="color:#000000"&gt;擴大 Kuikly Web 版支持範圍，下半年將開源 Electron 環境的適配&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367561</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367561</guid>
      <pubDate>Tue, 19 Aug 2025 02:37:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動闢謠：與芯原股份並無 AI 芯片相關合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，業內消息傳字節跳動正與芯原股份聯手設計一款先進的 AI 算力芯片。對此，字節跳動相關負責人回覆稱：&lt;strong&gt;字節跳動與芯原股份並無 AI 芯片相關合作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這並不是字節跳動第一次傳出與其他廠商聯手設計 AI 芯片（處理器）。去年上半年，曾有外媒報道稱字節跳動與博通公司合作開發 AI 處理器，以確保有足夠多的高端芯片。這款 AI 處理器製程為 5nm，將由台積電製造。雖然設計工作進展順利，但標誌着設計階段結束和製造開始的「流片」尚未開始。字節跳動後續否認了「與博通合作開發 AI 芯片」相關傳聞。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4f7ed7c637e5768388c84b63ed136901daa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;去年 9 月，針對媒體報道的字節跳動計劃與台積電就 AI 芯片開展合作，字節方面回應表示，報道不實。字節跳動稱公司在芯片領域確實有一些探索，但還處於初期階段，主要是圍繞推薦、廣告等業務的成本優化，所有項目也完全符合相關的貿易管制規定。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367559</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367559</guid>
      <pubDate>Tue, 19 Aug 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>快手發佈 Klear-Reasoner 模型，基於 Qwen3-8B-Base 打造</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手 Klear 語言大模型團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fjbd-doTA48xw2Y86G8CWyg" target="_blank"&gt;推出&lt;/a&gt;了全新的 Klear-Reasoner 模型，基於 Qwen3-8B-Base 打造，在數學與代碼的多個權威基準測試中達到同規模模型的 SOTA 水平，並完整公開了訓練細節與全流程 pipeline。&lt;/p&gt; 
&lt;p&gt;據介紹，Klear-Reasoner 在 AIME2024、AIME2025、LiveCodeBench V5 和 V6 等基準測試中，不僅全面超越同規模的強力開源模型（包括 DeepSeek 蒸餾版 DeepSeek-R1-0528-8B），更是在 AIME2024 上取得了 90.5%、AIME2025 上取得了 83.2% 的驚人成績，直接登頂 8B 模型榜首。&lt;/p&gt; 
&lt;p&gt;&lt;img height="394" src="https://static.oschina.net/uploads/space/2025/0821/102021_MBtp_2720166.png" width="1144" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="924" src="https://static.oschina.net/uploads/space/2025/0821/102031_wKeK_2720166.png" width="1524" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Klear-Reasoner 模型的核心創新是 GPPO（Gradient-Preserving Clipping Policy Optimization）算法，通過 stop-gradient 將裁剪與梯度回傳解耦，保留了高熵 token 與負樣本的梯度，兼顧了穩定性和探索力。&lt;/p&gt; 
&lt;p&gt;訓練流程的洞察顯示：SFT 階段強調高質量少量數據優於海量低質數據；RL 階段代碼任務使用軟獎勵（通過率）優於硬獎勵，並過濾了測試用例中的缺陷數據以消除假陰性。&lt;/p&gt; 
&lt;p&gt;論文、模型與代碼均已公開，團隊稱該技術路線可復現、可推廣，為社區提供了 RLVR 任務的新範式。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;論文標題：Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization&lt;/li&gt; 
 &lt;li&gt;論文鏈接：https://arxiv.org/pdf/2508.07629&lt;/li&gt; 
 &lt;li&gt;Hugging Face 地址：https://huggingface.co/Suu/Klear-Reasoner-8B&lt;/li&gt; 
 &lt;li&gt;GitHub 地址：https://github.com/suu990901/KlearReasoner/tree/main&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367555</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367555</guid>
      <pubDate>Tue, 19 Aug 2025 02:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>《GPT-5 家族 SQL 能力評測報告》發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-04cf3156161feafe5188e24a3bc155faa62.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;一、本期導覽與核心看點&lt;/h2&gt; 
&lt;p&gt;2025 年 8 月，&lt;strong&gt;我們迎來了 AI 發展史上的又一個里程碑 ------ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fzh-Hans-CN%2Fgpt-5%2F" title="GPT-5" target="_blank"&gt;GPT-5&lt;/a&gt; 家族的正式發佈。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當整個科技界都在討論其通用能力的飛躍時，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Factiontech%2Fsql-llm-benchmark" title="SCALE" target="_blank"&gt;SCALE&lt;/a&gt; 平台將目光聚焦於 SQL 能力：&lt;strong&gt;GPT-5 在 SQL 處理上的表現究竟如何？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本期評測為針對 &lt;strong&gt;GPT-5&lt;/strong&gt; 家族的評測特別版，旨在對其 SQL 相關能力進行一次全面的基準測試。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期核心看點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;旗艦模型表現分析&lt;/strong&gt; ：&lt;strong&gt;gpt-5-chat&lt;/strong&gt; 的評測結果顯示其能力存在特定短板，而 &lt;strong&gt;mini&lt;/strong&gt; 版本在本次測試的綜合表現中更為均衡。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;全方位的能力評估&lt;/strong&gt; ：通過多維度多指標的用例評估，分析了 &lt;strong&gt;GPT-5&lt;/strong&gt; 在不同場景下的實際性能，揭示了其理論能力與實踐應用的差異。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;數據驅動的模型選型&lt;/strong&gt; ：評測數據表明，不同版本的模型在處理 &lt;strong&gt;SQL 能力&lt;/strong&gt; 上各有千秋。本報告將基於數據，探討如何進行場景化選型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二、評測基準説明&lt;/h2&gt; 
&lt;p&gt;為確保本次特別評測的公正性與深度，我們沿用了成熟的三維評測體系。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQL 理解&lt;/strong&gt;：考察模型是否精準解析複雜查詢邏輯與用户意圖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL 優化&lt;/strong&gt;：考察模型提升查詢效率與性能的意識。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;方言轉換&lt;/strong&gt;：考察模型在主流數據庫之間進行語法遷移的能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;接下來，我們將揭曉本次評測的詳細結果。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;* 測評數據截止時間 2025/8/20&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;三、本月榜單與焦點分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;GPT-5&lt;/strong&gt; 家族在 SQL 領域的評測結果並非簡單的性能遞減，不同版本間表現出顯著的能力分化，這凸顯了場景化選型的重要性。&lt;/p&gt; 
&lt;h3&gt;1. gpt-5-mini：綜合能力均衡&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;gpt-5-mini&lt;/strong&gt; 在本次評測中綜合表現領先，其在三個維度上展現了均衡且突出的能力。&lt;/p&gt; 
&lt;h4&gt;各維度表現得分&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;能力&lt;/th&gt; 
   &lt;th align="left"&gt;得分&lt;/th&gt; 
   &lt;th align="left"&gt;詳細説明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 理解&lt;/td&gt; 
   &lt;td align="left"&gt;80.8&lt;/td&gt; 
   &lt;td align="left"&gt;執行準確性：87.1 / 執行計劃檢測：57.1 / 語法錯誤檢測：74.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;方言轉換&lt;/td&gt; 
   &lt;td align="left"&gt;75.6&lt;/td&gt; 
   &lt;td align="left"&gt;大 SQL 轉換：54.8 / 國產數據庫：92.1 / 邏輯等價：74.2 / 語法錯誤檢測：85.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 優化&lt;/td&gt; 
   &lt;td align="left"&gt;68.4&lt;/td&gt; 
   &lt;td align="left"&gt;邏輯等價：63.2 / 優化深度：64.4 / 語法錯誤檢測：94.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;亮點與不足&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;亮點&lt;/strong&gt;：執行準確性高，可靠性強；在高級、複雜的優化任務中表現出色。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;不足&lt;/strong&gt;：常規優化能力並非頂級，處理大型、複雜 SQL 轉換時能力有限。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;綜合評價&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;綜合來看，&lt;strong&gt;gpt-5-mini&lt;/strong&gt; 在準確性、可靠性和複雜任務處理上表現均衡，適合追求穩定輸出和綜合性能的企業級應用。&lt;/li&gt; 
 &lt;li&gt;橫向對比來看，&lt;strong&gt;gpt-5-mini&lt;/strong&gt; 在 &lt;strong&gt;SQL 理解維度&lt;/strong&gt; 位列第三，&lt;strong&gt;方言轉換&lt;/strong&gt; 維度位列前五，綜合實力在參評模型中名列前茅。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. gpt-5-nano：高精度代碼生成器&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;gpt-5-nano&lt;/strong&gt; 表現出紮實和均衡的能力，其在三個維度上的得分非常接近。&lt;/p&gt; 
&lt;h4&gt;各維度表現得分&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;能力&lt;/th&gt; 
   &lt;th align="left"&gt;得分&lt;/th&gt; 
   &lt;th align="left"&gt;詳細説明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 理解&lt;/td&gt; 
   &lt;td align="left"&gt;77.1&lt;/td&gt; 
   &lt;td align="left"&gt;執行準確性：85.7 / 執行計劃檢測：35.7 / 語法錯誤檢測 75.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;方言轉換&lt;/td&gt; 
   &lt;td align="left"&gt;66.4&lt;/td&gt; 
   &lt;td align="left"&gt;大 SQL 轉換：19.4 / 國產數據庫：100 / 邏輯等價：80.6 / 語法錯誤檢測：69.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 優化&lt;/td&gt; 
   &lt;td align="left"&gt;68.7&lt;/td&gt; 
   &lt;td align="left"&gt;邏輯等價：89.5 / 優化深度：55.6 / 語法錯誤檢測：100&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;亮點與不足&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;亮點&lt;/strong&gt;：生成的 SQL 語法正確性極高，結果可靠；邏輯轉換能力紮實。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;不足&lt;/strong&gt;：缺乏對 SQL 執行效率的深層理解；難以應對複雜、冗長的查詢遷移。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;綜合評價&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-5-nano 是一個出色的"SQL 代碼生成器"&lt;/strong&gt; ，適合嵌入自動化工作流，處理標準化的 "&lt;strong&gt;文本到 SQL&lt;/strong&gt;" 和簡單方言轉換任務。但對於需要深度優化和理解複雜查詢的場景，則非其所長。&lt;/li&gt; 
 &lt;li&gt;在本次評測的橫向對比中，&lt;strong&gt;gpt-5-nano&lt;/strong&gt; 憑藉其 SQL 優化能力進入榜單前五，但在其他維度的競爭中未顯現出明顯優勢。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. gpt-5-chat：能力特點分化&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;gpt-5-chat&lt;/strong&gt; 的綜合表現不如預期，其能力存在顯著的"偏科"現象。&lt;/p&gt; 
&lt;h4&gt;各維度表現得分&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;能力&lt;/th&gt; 
   &lt;th align="left"&gt;得分&lt;/th&gt; 
   &lt;th align="left"&gt;詳細説明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 理解&lt;/td&gt; 
   &lt;td align="left"&gt;62.3&lt;/td&gt; 
   &lt;td align="left"&gt;執行準確性：57.1 / 執行計劃檢測：60.7 / 語法錯誤檢測 84.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;方言轉換&lt;/td&gt; 
   &lt;td align="left"&gt;55.4&lt;/td&gt; 
   &lt;td align="left"&gt;大 SQL 轉換：3.2 / 國產數據庫：86.8 / 邏輯等價：71.0 / 語法錯誤檢測：66.7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;SQL 優化&lt;/td&gt; 
   &lt;td align="left"&gt;56.0&lt;/td&gt; 
   &lt;td align="left"&gt;邏輯等價：52.6 / 優化深度：48.9 / 語法錯誤檢測：94.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;亮點與不足&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;亮點&lt;/strong&gt;：對複雜的優化策略和邏輯推理有深刻的理論理解。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;不足&lt;/strong&gt;：基礎執行的準確性堪憂，生成的 SQL 有較大概率出錯；無法處理複雜、大型的查詢遷移。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;綜合評價&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;gpt-5-chat&lt;/strong&gt; 在高級理論知識上表現出色，但在基礎執行的準確性上存在不足。這種能力分化表明，對模型的評估不應僅依據其通用能力，而需通過專業、細分的場景評測來確定其在特定領域的適用性。&lt;/li&gt; 
 &lt;li&gt;橫向來看，&lt;strong&gt;gpt-5-chat&lt;/strong&gt; 在各維度的榜單排名中均未進入前列，其綜合定位處於中游水平。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;四、總結與展望&lt;/h2&gt; 
&lt;p&gt;本次特別評測清晰地表明，&lt;strong&gt;GPT-5&lt;/strong&gt; 的發佈不僅是數字上的提升，更帶來了 AI 在 SQL 領域 &lt;strong&gt;專業化&lt;/strong&gt; 和 &lt;strong&gt;場景化&lt;/strong&gt; 的深刻變革。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;場景定義模型&lt;/strong&gt; ：評測結果表明，企業在選擇模型時，應更多地從具體應用場景出發（複雜分析、數據遷移等），而非僅僅依據模型的"名號"或通用能力排名。&lt;strong&gt;gpt-5-mini&lt;/strong&gt; 的勝出，是"場景定義價值"的最佳體現。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;專業化趨勢&lt;/strong&gt; ：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsqlflash.ai%2F" title="SQLFlash" target="_blank"&gt;SQLFlash&lt;/a&gt; 在優化領域的絕對優勢，與 &lt;strong&gt;GPT-5 家族&lt;/strong&gt; 內部的能力分化，共同揭示了未來 AI 發展的趨勢------通用大模型與領域專用模型將長期共存，互為補充。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;五、下期展望：&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;GPT-5 家族&lt;/strong&gt; 的評測結果揭示了模型能力的巨大分化，也對我們的評測體系提出了新的要求。本月我們將：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;引入新玩家&lt;/strong&gt;：隨着 AI 領域的加速發展，我們將引入更多備受關注的新模型，為用户提供更全面的市場視圖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;聚焦專用工具&lt;/strong&gt; ：除了通用模型，我們還將對新興的 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsqlshift.cn%2F" title="SQLShift" target="_blank"&gt;SQLShift&lt;/a&gt;&lt;/strong&gt; 方言轉換應用進行深度剖析，檢驗其在複雜遷移場景下的真實表現。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;感謝您的關注。我們致力於通過最專業、最深入的評測，為您揭示 AI 在數據領域的前沿進展。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SCALE：為專業 SQL 任務，選專業 AI 模型。&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/actiontechoss/blog/18688968</link>
      <guid isPermaLink="false">https://my.oschina.net/actiontechoss/blog/18688968</guid>
      <pubDate>Tue, 19 Aug 2025 02:20:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>字節跳動發佈開源大語言模型 Seed-OSS</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;字節跳動的 Seed 團隊宣佈推出一系列開源大型語言模型 ——Seed-OSS。該系列模型旨在滿足國際化（i18n）應用場景的需求，專注於強大的長文本理解、推理能力和靈活的開發者友好特性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Seed-OSS 系列模型基於流行的因果語言模型架構，採用了 RoPE、GQA 注意力機制、RMSNorm 和 SwiGLU 激活函數。&lt;span&gt;最新&lt;/span&gt;發佈的 Seed-OSS-36B 模型擁有 360 億個參數，具備 512K 的長上下文處理能力。儘管該模型僅使用了 12 萬億個訓練數據，其在多個流行的基準測試中表現出色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="329" src="https://oscimg.oschina.net/oscnet/up-6f87300068922ebee13eab7802b4dd4e241.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Seed-OSS 模型系列包括兩種版本：帶有合成指令數據的 Seed-OSS-36B-Base 和不帶合成指令數據的 Seed-OSS-36B-Base-woSyn。這種設計不僅為開發者提供了高性能的基礎模型，還為研究者提供了更為多樣化的選擇，以確保研究的有效性不受合成數據的影響。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該模型的關鍵特性之一是 「思考預算」 的靈活控制，允許用户根據需要動態調整推理的長度。這種能力在實際應用場景中大大提高了推理的效率。此外，Seed-OSS 特別優化了推理任務，確保在保持良好一般能力的同時，推理能力也得到了增強。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="375" src="https://static.oschina.net/uploads/space/2025/0821/102210_RBBH_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在發佈會上，Seed 團隊強調，Seed-OSS 模型不僅適用於學術研究，還可廣泛應用於各類開發任務，例如工具使用和問題解決等代理智能任務。模型的訓練和評估結果表明，Seed-OSS 在知識問答、數學推理、編程等任務中的表現達到了開源領域的領先水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;對於希望參與的開發者，Seed 團隊提供了詳細的快速入門指南。用户只需通過 pip 安裝相關依賴，即可輕鬆下載和使用 Seed-OSS 模型。此外，團隊還支持多種量化方式以降低內存使用，提高模型的運行效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367553</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367553</guid>
      <pubDate>Tue, 19 Aug 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenSearch 3.2 發佈：增強 AI 能力的下一代搜索和分析</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenSearch 3.2 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FglqBlloPuHeVAidzI5bx5A" target="_blank"&gt;發佈&lt;/a&gt;，帶來眾多功能，提升和拓展搜索、可觀測性及生成式 AI 應用場景。&lt;/p&gt; 
&lt;p&gt;本次版本重點延續 3.x 系列的新創新，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;擴展 GPU 支持&lt;/li&gt; 
 &lt;li&gt;近似框架重大改進&lt;/li&gt; 
 &lt;li&gt;OpenSearch 中 Protobuf 正式發佈（GA）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="332" src="https://oscimg.oschina.net/oscnet/up-8384e3d1bc249e0a383aab5423b087ff3e8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;許多改進旨在幫助更高效地擴展工作負載，提升索引和查詢能力。一些重點更新內容如下：&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;搜索&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;搜索在性能、可擴展性和功能擴展上都有多項改進。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;近似框架重大升級&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenSearch 3.2 在兩個方面增強了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensearch.org%2Fblog%2Fopensearch-approximation-framework%2F" target="_blank"&gt;近似框架&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;首先，3.2 支持了 search_after 查詢，解決了此前此類查詢退化為默認 Lucene 遍歷的性能瓶頸。改進後，search_after 參數轉為合理的範圍查詢邊界——ASC 排序時作為下界，DESC 排序時作為上界，從而持續利用 ApproximatePointRange 優化的 BKD 遍歷，避免回退到 Lucene。該優化大幅提升時間序列和數值型分頁查詢性能。基準測試中，Big5 數據集 p90 延遲從 185ms 降至 8ms，http_logs 數據集 DESC 排序延遲從 397ms 降至 7ms。提升了分頁搜索、實時儀表盤及深度分頁應用的響應速度。&lt;/p&gt; 
&lt;p&gt;其次，3.2 擴展了近似查詢支持的數值字段類型，覆蓋 HALF_FLOAT、FLOAT、DOUBLE、INTEGER、BYTE、SHORT、UNSIGNED_LONG，不再限於 LONG。基準測試表明，http_logs 和 nyc_taxis 數據集的 p90 延遲最高下降 80%。這一優化對分析任務、時間序列分析及多樣數值字段的快速過濾排序尤為有效。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;體驗更高性能的 gRPC/Protobuf API&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;3.2 版本中，gRPC 傳輸層正式發佈（GA），支持高性能的批量文檔導入和 k-NN 查詢。相比傳統 REST API，gRPC 使用 Protocol Buffers（Protobuf）——一種緊湊、結構化且強類型的二進制格式，自動從 OpenSearch API 規範生成。此格式減小負載體積，提升整體性能，尤其適合高吞吐量操作和向量搜索等原始數據類型。GA 版本還擴展了搜索 API 功能和傳輸加密。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;新增 skip_list 功能提升查詢性能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;3.2 引入了 skip_list 參數，適用於頻繁用於範圍查詢或聚合的字段。skip_list 使查詢引擎跳過不匹配的文檔區間，從而提升查詢效率。詳情參考&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.opensearch.org%2Flatest%2Ffield-types%2Fsupported-field-types%2Findex%2F" target="_blank"&gt;字段類型文檔&lt;/a&gt;。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;star-tree 搜索新增功能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;star-tree 支持基於 IP 字段的聚合查詢。同時，star-tree 相關的基本查詢指標已納入索引/節點/分片統計，包含使用 star-tree 解析的查詢總數、當前運行查詢數和累計耗時。詳見相關&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensearch.org%2Fblog%2Fthe-power-of-star-tree-indexes-supercharging-opensearch-aggregations%2F" target="_blank"&gt;博客&lt;/a&gt;介紹。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;流式聚合優化資源分配&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;3.2 試驗性引入基於流式傳輸的聚合功能，支持分段級別的部分聚合結果流式返回給協調節點，避免每個分片返回單一響應。此架構讓協調節點成為擴展關鍵點，內存密集的 reduce 邏輯從數據節點遷移至協調節點，更好支持高基數聚合。通過 stream=true 參數可選擇啓用此功能。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;向量數據庫與生成式 AI&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;OpenSearch 3.2 在性能和擴展性上多項提升，包括支持更多向量類型的 GPU 支持、向量搜索質量改進及 Neural Search 插件更新。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;新向量類型擴展 GPU 支持&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GPU 索引支持 FP16、byte 和 binary 向量類型，除了之前的 FP32。新類型佔用更少內存，減少 GPU 和 CPU 之間的數據傳輸，提高資源利用率和擴展能力，助力更多 GPU 加速索引應用。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;提升磁盤向量搜索召回率&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;3.2 推出兩種提升二進制量化索引搜索質量的技術。非對稱距離計算（ADC）保持查詢向量全精度，對壓縮文檔向量進行比對，保留關鍵信息。隨機旋轉（RR）重新分配向量維度方差，防止 32 倍壓縮中信息丟失。ADC 支持 1-bit 量化，RR 支持 1、2、4-bit 配置。兩者結合可在複雜數據集（如 SIFT）上召回率提升最高達 80%，延遲適中，使二進制量化適用於對精度要求高的場景。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;優化語義搜索，滿足多樣需求&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Neural Search 插件的語義字段參數更靈活，支持調節密集嵌入字段（engine、mode、compression_level、method）、自定義文本分塊算法及稀疏嵌入生成的剪枝策略和比例。新增批量大小選項提升索引吞吐，嵌入複用減少重複計算。提升語義搜索的靈活性、效率和適配性，針對不同數據、性能及相關性需求優化。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Plan-execute-reflect 代理正式發佈&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;該代理可自主規劃和反思，解決複雜任務，3.2 達到 GA 級別，新增提示詞優化性能、消息歷史參數控制、支持日期時間輸入。通過 ML Commons 插件提供，能將複雜問題拆解為步驟，選擇合適工具執行，並不斷反思改進策略。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;可觀測性、日誌分析與安全分析&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;OpenSearch 3.2 在查詢性能、Trace Analytics 插件分析能力等方面持續提升。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;支持 OpenTelemetry 和服務圖控制&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Trace Analytics 插件支持 OpenTelemetry（OTel）追蹤分析，從 Data Prepper 2.11 的數據接收，到 OpenSearch 3.2 的可視化。配置 OTel 源時，設置 output_format: otel，可保留標準字段和元數據，助力與 OTel 工具鏈集成。服務圖新增最大節點和邊數配置，方便大規模環境下調整視覺複雜度。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;PPL Calcite 更新提升性能和易用性&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;3.2 對 Piped Processing Language（PPL）帶來性能和查詢靈活性提升。新增基於 Calcite 行表達式的腳本引擎，支持聚合函數、過濾函數下推、跨度下推、相關性查詢下推、排序合併連接下推及 IP 比較下推。增加參數強制轉換、新增日期處理及 QUERY_SIZE_LIMIT 強制執行等功能。整體提升複雜查詢的性能、正確性和易用性。&lt;/p&gt; 
&lt;p&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-1209318cdde40a0788039ab8abee23e77f6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;OpenSearch Prometheus Exporter&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Prometheus exporter 插件已歸入 OpenSearch 項目，與 3.2 同步發佈。該插件不隨核心包內置，需單獨安裝。發佈節奏和版本管理已同步 OpenSearch，現有 Prometheus 抓取流程保持兼容，指標繼續暴露在 /_prometheus/metrics。&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopensearch-project%2Fopensearch-build%2Fblob%2Fmain%2Frelease-notes%2Fopensearch-release-notes-3.2.0.md" target="_blank"&gt;查看發行説明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367552/opensearch-3-2-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367552/opensearch-3-2-released</guid>
      <pubDate>Tue, 19 Aug 2025 02:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟為 Excel 添加 =COPILOT() 函數，引入 LLM 能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟正在為 Excel 添加一項名為 =COPILOT() 的新函數，該功能將大型語言模型 (LLM) 的特性直接集成到電子表格的單元格中，可用於數據分析和內容生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1244" src="https://static.oschina.net/uploads/space/2025/0820/190354_6lID_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以直接在網格內使用此函數來幫助填充單元格。根據指定的一組單元格數據，=COPILOT() 函數可以利用 AI 進行分析、生成內容和頭腦風暴。具體功能包括生成摘要、標籤、表格等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c757914b31abe665f8fe19dd133ddcc775.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://techcommunity.microsoft.com/blog/microsoft365insiderblog/bring-ai-to-your-formulas-with-the-copilot-function-in-excel/4443487&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367473</guid>
      <pubDate>Mon, 18 Aug 2025 11:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Augment Code 推出 Agent Turn Summary 功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程平台 Augment Code 發佈了一項名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.augmentcode.com%2Fchangelog%2Fagent-turn-summary" target="_blank"&gt;Agent Turn Summary&lt;/a&gt;的新功能。該功能可以將 Agent 在單次交互（turn）中執行的複雜操作序列濃縮為一行簡潔的摘要，讓開發者在幾秒鐘內就能掌握全局，而非花費數分鐘滾動瀏覽大量日誌。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9aa640b9721c46d955b27fcc7aca5797a31.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該功能在 Agent 響應的末尾、反饋頁腳旁邊顯示，內容包括工具調用的摘要與計數，以及所做更改的快照。用户可以一目瞭然地看到操作的整體範圍，僅在需要時才展開查看完整細節。&lt;/p&gt; 
&lt;p&gt;目前，Agent Turn Summary 功能已在 VS Code 和 JetBrains 的預發佈版本中提供。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367472</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367472</guid>
      <pubDate>Mon, 18 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kilo Code 新增基於用量的價格估算，支持 Qwen Code</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;Kilo Code&lt;/strong&gt; 近期&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.kilocode.ai%2Fp%2Fkilo-code-v4791v4810-usage-based" target="_blank"&gt;發佈重要更新&lt;/a&gt;，新增基於真實用量的 AI 模型價格估算功能，並支持 &lt;strong&gt;QwenCode&lt;/strong&gt; 作為 API provider 。&lt;/p&gt; 
&lt;p&gt;更新後，Kilo Code 能根據真實世界使用情況（基於每日處理超 &lt;strong&gt;300 億&lt;/strong&gt; token 的真實用量，已計入緩存摺扣等因素）估算各模型的平均每百萬 token 成本，用户可在設置中查看 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7ab70cf8e4317d267793b8e767d3046e4e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-25de1b84c1e8e008e8a8f4c05d59d91f950.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，用户安裝 &lt;strong&gt;QwenCode&lt;/strong&gt; 並創建賬户後，Kilo Code 能自動找到其配置文件，實現開箱即用的集成 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c5cba126534a4d92f8f5cc0513c06ee0973.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kilo Code 是開源 VS Code AI Agent 擴展，內置最新的 AI 模型，具備強大的代碼生成能力，能根據自然語言描述快速生成代碼片段，有效減少手動編寫代碼的時間。Kilo Code 能自動化執行多種重複性編碼任務，例如代碼格式化、重構以及生成樣板代碼等，進一步提高開發效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367470</guid>
      <pubDate>Mon, 18 Aug 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌圖像編輯 AI 模型 nano-banana 現身 LMArena</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;最近，一款名為 nano-banana 的神秘圖像編輯 AI 模型悄然現身 LMArena 平台。有爆料稱：這是谷歌正在測試的新模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-daa046b2afeced90c8ac232dead09582575.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f40a92db7e4552760f02564cf4641fa98f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;谷歌工程師在社交平台上發佈香蕉 emoji 或香蕉圖片，明示代號為 nano-banana 的圖像生成模型為谷歌所有。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-867584592c2b8c9970b5f4314a01c353dda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前該模型在 LMArena 平台進行測試，但尚未在 AI Studio 上線。在 text-to-image（文生圖）和 image-edit（圖像編輯）功能方面，nano-banana 展示了強大的能力，其性能被認為超越了 GPT-Image-1 模型。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lmarena.ai/?chat-modality=image&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367467</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367467</guid>
      <pubDate>Mon, 18 Aug 2025 10:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firecrawl 獲 1450 萬美元 A 輪融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Firecrawl 宣佈完成 1450 萬美元的 A 輪融資。本輪融資由 Nexus Venture Partners 領投，Shopify 首席執行官 Tobias Lütke 及 Y Combinator 等知名投資者跟投。&lt;/p&gt; 
&lt;p&gt;據悉，Firecrawl 通過一封大膽的電子郵件與 Tobias Lütke 建立了聯繫，此前後者通過自助服務平台試用了 Firecrawl 的產品。這一投資不僅為 Firecrawl 注入了資金動力，也為其技術創新和市場擴展提供了強有力的背書。&lt;/p&gt; 
&lt;p&gt;Firecrawl 表示，此輪融資將用於加速產品研發、擴大全球工程與 AI 專家團隊，並進一步優化其服務能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-0f5d3148770305396b53663dc286ff63317.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Firecrawl 同步推出了其 V2 版本 API，被稱為迄今為止最重大的技術升級。新版本在以下幾個方面實現了突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;10 倍速抓取：通過優化的 Fire-Engine 技術，V2 版本的網頁抓取速度提升了 10 倍，成功率提高 40%，為大規模數據處理提供了更高的效率。&lt;/li&gt; 
 &lt;li&gt;語義化爬取：利用自然語言處理技術，Firecrawl 能夠根據語義理解網頁結構，自動提取所需數據，減少手動幹預，提升數據質量。&lt;/li&gt; 
 &lt;li&gt;新增新聞與圖像搜索功能：V2 版本新增了對新聞和圖像內容的搜索與提取支持，為 AI 應用提供了更豐富的實時數據來源。&lt;/li&gt; 
 &lt;li&gt;多功能集成：持 Markdown、JSON、截圖等多種數據格式輸出，並與 LangChain 等 AI 框架無縫集成，方便開發者快速構建 AI 應用。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367465</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367465</guid>
      <pubDate>Mon, 18 Aug 2025 10:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>釘釘重注 AI：成立行業專屬模型團隊，向 CTO 彙報</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWRBSkp0dSe3sfff4WP0CFw" target="_blank"&gt;智能湧現&lt;/a&gt;》獨家獲悉，釘釘近期成立了一個新業務線——行業專屬模型，並作為獨立團隊存在，向釘釘 CTO 朱鴻彙報。這也是釘釘創始人無招回歸後，釘釘在 AI 戰略推進中的重要動作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「團隊成立後，目前釘釘已經與多家行業客户接觸，目前已有幾個行業/企業專屬模型在推進中。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;自 4 月重返釘釘後，無招將產品體驗和 AI 創新作為首要優先級。從 4 月開始，釘釘就經歷了一場整改——覆蓋範圍很廣，從產品設計、排查，到整改，無招都在一線深度參與。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從 ChatGPT 爆火後，釘釘已經完成了大模型基礎能力的接入。2023 年 8 月，釘釘就已經將智能化底座 (AI PaaS) 開放給生態夥伴和客户，鼓勵合作伙伴利用大模型重新打造產品；再到 2024 年 1 月發佈的 AI 助理，具備感知、記憶、規劃和行動能力，能夠跨應用程序執行任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據釘釘此前披露的數字，釘釘目前企業組織數超過 2500 萬，其中有超 220 萬家企業在釘釘使用 AI，覆蓋製造、醫療、金融、零售等 20 個一級行業。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;成立行業專屬模型團隊，是大模型在技術、產品化之後，繼續在企業側落地的體現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;企業 AI 落地的挑戰並不小。一方面，大多數企業、尤其是中小企業雖然對 AI 有強烈需求，但普遍缺乏專業的技術團隊和數據處理能力；另一方面，通用大模型雖然功能強大，但難以滿足垂直行業的專業需求，需要針對特定場景進行深度定製和優化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;釘釘的行業專屬模型團隊，主要面向釘釘平台上的企業客户、第三方合作伙伴。比如，對於沒有充足 AI 人才資源的中小企業客户，釘釘會提供全流程的模型訓練和數據工程服務，包括前端的數據打標、清洗到模型的調優，都由釘釘團隊完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與面向開發者的阿里雲旗下百鍊等平台相比，釘釘行業專屬模型會更貼近業務場景。「行業專屬模型是由釘釘和企業中懂業務、懂行業的業務人員共創，將行業 know-how 沉澱下來，讓企業客户能夠更快、更好地用上模型。」一位釘釘人士對 36 氪表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，釘釘已經在行業專屬模型方面取得了初步成果。在 7 月發佈的豆蔻婦科大模型，其實是釘釘平台上成功落地的第一個垂類專屬大模型。其作為醫療領域的垂類模型，可將婦科六大症狀的診斷準確率，從 77.1% 提升到 90.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在推動行業專屬模型的同時，釘釘也在加速完成 AI 生態的閉環，另一個新動作是對應用市場進行改版。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent 已經是 2025 年大廠競爭的「明牌」。從 2024 年開始，大廠們已經推出了包括阿里雲百鍊、字節跳動釦子 (Coze)、百度文心智能體、騰訊元器等 Agent 平台。釘釘也在 2024 年 4 月上線了 AI Agent Store。無招回歸釘釘後，一個重要工作也是重新構造 Agent 市場的邏輯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了應用推薦方式大變之外，釘釘未來會在 Agent 市場上再發力，開放能力給更多的 ISV 和企業，幫助企業打造 Agent 應用，並通過釘釘實現商業化閉環，打通整個 Agent 應用生態。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367464</guid>
      <pubDate>Mon, 18 Aug 2025 10:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DatologyAI 發佈合成數據框架 BeyondWeb</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DatologyAI 發佈了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.datologyai.com%2Fbeyondweb%2F" target="_blank"&gt;&lt;strong&gt;BeyondWeb&lt;/strong&gt;&lt;/a&gt;，一個專為大規模語言模型（LLM）預訓練設計的合成數據生成框架，旨在突破當前面臨的數據瓶頸問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/181040_p3sx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該框架採用「目標導向的文檔重寫」策略，對現有高質量網絡數據進行改寫，而非從頭生成，從而在保證數據多樣性和信息密度的同時，避免了低質量內容的引入。&lt;/p&gt; 
&lt;p&gt;據介紹，BeyondWeb 通過高質量、信息密集的合成數據，顯著提升了模型性能，即使在原始網絡數據有限的情況下，也能實現超越傳統數據規模擴展的效果。在 14 項基準測試中，使用 BeyondWeb 生成的合成數據訓練的 3B 參數模型，其性能超過了使用 Cosmopedia 數據訓練的 8B 參數模型，同時訓練速度提升了最高達 7.7 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eadd4a1595c18a9ec07e6705a60c8bc60c7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;論文地址：https://arxiv.org/pdf/2508.10975&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367463</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367463</guid>
      <pubDate>Mon, 18 Aug 2025 10:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>100% 開源版的 Claude Code？00 後這麼勇嗎？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;幾天前，來新璐告訴我，他做了一個開源版本的 Claude Code 。&lt;/p&gt; 
&lt;p&gt;我問他，能實現幾成&amp;nbsp;Claude Code 的效果。&lt;/p&gt; 
&lt;p&gt;他簡單地回覆我：100%。&lt;/p&gt; 
&lt;p&gt;&lt;img height="124" src="https://oscimg.oschina.net/oscnet/up-3f746e5853445f04492023812b04aeba4d2.png" width="309" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果是別人，我可能就當他説大話了。&lt;/p&gt; 
&lt;p&gt;但他是來新璐，llama3 中文版作者，GitHub Star 數已經有 4.2K 了。&lt;/p&gt; 
&lt;p&gt;此前曾在百度&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;飛槳&lt;/a&gt; &amp;amp; 騰訊混元負責多模態大模型訓練、推理相關的開源套件工作。&lt;/p&gt; 
&lt;p&gt;他還開發了多個技術項目，比如文生圖大模型訓練工具箱 ——&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCrazyBoyM%2Fdreambooth-for-diffusion" target="_blank"&gt;&lt;span&gt;dreambooth-for-diffusion&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，也給 ComfyUI 的 controlnet 部分貢獻過代碼。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這麼看起來，他還是有點東西的。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;而且，作為一個 00 後，他還&lt;span&gt;是奇績創壇 F24 校友，&lt;/span&gt;創立了 ShareAI-Lab，一家注重技術創新的實驗室性質的公司，面向 toB 市場，做模型後訓練、數據合成標註、資料知識庫+ AI agent 搜索。&lt;/p&gt; 
&lt;p&gt;公司還有一個技術開發組長，叫陶熠，是斯坦福大學人工智能專業碩士畢業，妥妥的 AI&amp;nbsp;Agent 專家。&lt;/p&gt; 
&lt;p&gt;再加上前段時間，來新璐一直在對 Claude Code 源碼進行深度逆向分析，一口氣發了 5 篇文章。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo4pu8QX1tRIPBRlFJqrX3A" target="_blank"&gt;Claude Code 逆向破解 Prompt 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGspfXKHiwtdhr73KtDgO1w" target="_blank"&gt;Claude Code 分層多 Agent 架構篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlBhZhdlb1s0y4qgl_5HSWQ" target="_blank"&gt;Claude Code: 上下文工程 system-reminder 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMeJTDMcYV2u-TJfOJlLilg" target="_blank"&gt;Claude Code 異步消息通信機制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj8eTytIDy9l4dnLVHS_Cuw" target="_blank"&gt;Claude Code 最新版解讀之自定義 Agent 機制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;現在跟我説搞了個 100% 開源版的 Claude Code，這個可信度就又提高了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這個號稱 「100% 開源版 Claude Code」 的項目，叫 Kode。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FshareAI-lab%2FKode" target="_blank"&gt;&lt;strong&gt;GitHub 地址：&lt;/strong&gt;https://github.com/shareAI-lab/Kode&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;7 月初就放話説要開源，不過一直沒有發佈，大家甚至一度以為要被鴿 ！&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-6f1e9a2460372836c22eccc6194f26d9880.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="background-color:#ffffcc"&gt;不過，最終它來了！目前 GitHub 已經有 900 多 Star。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;與官方 Claude Code 比較之後，也有較多出彩的地方。&lt;/p&gt; 
&lt;p&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-20256148956a23d9da17f32f0fa7b0e2416.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最後，不管我怎麼問他，得到的回答都是非常肯定的——Kode 就是開源版 Claude Code。&lt;/p&gt; 
&lt;p&gt;看來，Kode 都是要蹭勞 Claude Code 這波流量了。&lt;/p&gt; 
&lt;p&gt;&lt;img height="195" src="https://oscimg.oschina.net/oscnet/up-6cb6eb15c540029a760c2eea5f8475ec939.png" width="538" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;既然他敢把話説得這麼滿，那就直播來驗一驗真假！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0635a39399fde8a01a773d4770b4bb9e1d9.png" width="540" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;是騾子是馬，拉出來遛遛就知道了！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;ShareAI-lab 搞了個 100% 開源版 Claude Code&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;8 月 23 日週五 20:00-21:00&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播亮點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;拆解 Claude Code 技術設計原理&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;開源版 Claude Code —— Kode 源碼帶讀&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Claude Code 高階使用技巧及 SDK 應用潛力場景分享&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;實戰：用 Kode 維護大型項目&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;演示：小型 MVP Demo &amp;amp; 使用技巧&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;展望 Agent 世界發展&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;福袋抽獎：直播中將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼、前沿技術書籍等。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt;
  可以加入 OSC 直播交流羣，進來嘮嘮嗑，或者你有好的產品 / 項目，也歡迎推薦過來呀～ 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，基本上每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18688925</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18688925</guid>
      <pubDate>Mon, 18 Aug 2025 10:10:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Anthropic 推出 Usage and Cost API</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 近期推出了 Usage and Cost API，作為其 Admin API 的一部分，旨在幫助開發者和組織以編程方式實時監控和追蹤 Claude 模型的使用情況和成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/180149_Zv2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://docs.anthropic.com/en/api/admin-api/usage-cost/get-messages-usage-report&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;該 API 允許用户通過請求獲取詳細的用量報告。報告支持多種精細化的篩選和分組條件，包括按 API 密鑰 ID、工作區 ID、模型（例如 claude-sonnet-4-20250514）、服務等級（standard,batch,priority）以及上下文窗口大小（0-200k,200k-1M）進行查詢。報告的時間粒度可以設置為分鐘（1m）、小時（1h）或天（1d）。&lt;/p&gt; 
&lt;p&gt;為了方便開發者快速上手，Anthropic 在 GitHub 的 anthropic-cookbook 項目中提供了一個名為 usage_cost_api.ipynb 的 Jupyter Notebook 示例教程。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/anthropics/anthropic-cookbook/blob/main/observability/usage_cost_api.ipynb&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367457</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367457</guid>
      <pubDate>Mon, 18 Aug 2025 10:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>韓國政府擬未來兩年採購超 3.5 萬枚 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;韓國科學技術信息通信部週三表示，韓國將在未來兩年內採購超過 35000 枚圖形處理器（GPU），作為全國範圍內加強人工智能（AI）基礎設施計劃的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="380" src="https://oscimg.oschina.net/oscnet/up-bef12c45835c72bb33b4f121bbd7f104e9c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韓國科學技術信息通信部長官裴慶勳當天在國會表示，政府的長期目標是到 2030 年確保 5 萬枚 GPU。「我不認為政府能包辦一切。政府將為私營部門創造人工智能市場和基礎設施投資鋪平道路。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為該計劃的一部分，韓國政府啓動了一個開發韓國 AI 基礎模型的項目，五家公司 Naver Cloud、Upstage、SK Telecom、NC AI 和 LG AI Research 將獲得研發資金支持以及政府資源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，韓國政府通過「AI 高速公路」計劃，提出了到 2030 年成為全球人工智能領導者的願景，其中包括建立配備 5 萬枚 GPU 的國家人工智能數據中心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367456</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367456</guid>
      <pubDate>Mon, 18 Aug 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>COLMAP - 三維重建軟件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 是一個通用的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;Structure-from-Motion (SfM) 和 Multi-View Stereo (MVS) pipeline&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，具有圖形和命令行界面。它提供了豐富的功能，可用於重建有序和無序圖像集。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="210" src="https://static.oschina.net/uploads/space/2025/0818/145035_b3XQ_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="102" src="https://static.oschina.net/uploads/space/2025/0818/145138_oR0u_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你將此項目用於您的研究，請引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你使用 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;image retrieval / vocabulary tree engine&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，請同時引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016vote,
    author={Sch\"{o}nberger, Johannes Lutz and Price, True and Sattler, Torsten and Frahm, Jan-Michael and Pollefeys, Marc},
    title={A Vote-and-Verify Strategy for Fast Spatial Verification in Image Retrieval},
    booktitle={Asian Conference on Computer Vision (ACCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 建立在現有成果之上，在 COLMAP 中使用特定算法時，請註明原始作者（如源代碼中所述），並考慮引用相關的第三方依賴項（例如 ceres-solver、poselib、sift-gpu 和 vlfeat）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/colmap</link>
      <guid isPermaLink="false">https://www.oschina.net/p/colmap</guid>
      <pubDate>Mon, 18 Aug 2025 09:38:00 GMT</pubDate>
    </item>
  </channel>
</rss>
