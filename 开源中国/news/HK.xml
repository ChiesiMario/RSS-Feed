<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Wed, 20 Aug 2025 16:58:21 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微軟為 Excel 添加 =COPILOT() 函數，引入 LLM 能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟正在為 Excel 添加一項名為 =COPILOT() 的新函數，該功能將大型語言模型 (LLM) 的特性直接集成到電子表格的單元格中，可用於數據分析和內容生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1244" src="https://static.oschina.net/uploads/space/2025/0820/190354_6lID_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以直接在網格內使用此函數來幫助填充單元格。根據指定的一組單元格數據，=COPILOT() 函數可以利用 AI 進行分析、生成內容和頭腦風暴。具體功能包括生成摘要、標籤、表格等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c757914b31abe665f8fe19dd133ddcc775.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://techcommunity.microsoft.com/blog/microsoft365insiderblog/bring-ai-to-your-formulas-with-the-copilot-function-in-excel/4443487&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367473</guid>
      <pubDate>Mon, 18 Aug 2025 11:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Augment Code 推出 Agent Turn Summary 功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 編程平台 Augment Code 發佈了一項名為&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.augmentcode.com%2Fchangelog%2Fagent-turn-summary" target="_blank"&gt;Agent Turn Summary&lt;/a&gt;的新功能。該功能可以將 Agent 在單次交互（turn）中執行的複雜操作序列濃縮為一行簡潔的摘要，讓開發者在幾秒鐘內就能掌握全局，而非花費數分鐘滾動瀏覽大量日誌。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9aa640b9721c46d955b27fcc7aca5797a31.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該功能在 Agent 響應的末尾、反饋頁腳旁邊顯示，內容包括工具調用的摘要與計數，以及所做更改的快照。用户可以一目瞭然地看到操作的整體範圍，僅在需要時才展開查看完整細節。&lt;/p&gt; 
&lt;p&gt;目前，Agent Turn Summary 功能已在 VS Code 和 JetBrains 的預發佈版本中提供。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367472</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367472</guid>
      <pubDate>Mon, 18 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kilo Code 新增基於用量的價格估算，支持 Qwen Code</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;Kilo Code&lt;/strong&gt; 近期&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.kilocode.ai%2Fp%2Fkilo-code-v4791v4810-usage-based" target="_blank"&gt;發佈重要更新&lt;/a&gt;，新增基於真實用量的 AI 模型價格估算功能，並支持 &lt;strong&gt;QwenCode&lt;/strong&gt; 作為 API provider 。&lt;/p&gt; 
&lt;p&gt;更新後，Kilo Code 能根據真實世界使用情況（基於每日處理超 &lt;strong&gt;300 億&lt;/strong&gt; token 的真實用量，已計入緩存摺扣等因素）估算各模型的平均每百萬 token 成本，用户可在設置中查看 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7ab70cf8e4317d267793b8e767d3046e4e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-25de1b84c1e8e008e8a8f4c05d59d91f950.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，用户安裝 &lt;strong&gt;QwenCode&lt;/strong&gt; 並創建賬户後，Kilo Code 能自動找到其配置文件，實現開箱即用的集成 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c5cba126534a4d92f8f5cc0513c06ee0973.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kilo Code 是開源 VS Code AI Agent 擴展，內置最新的 AI 模型，具備強大的代碼生成能力，能根據自然語言描述快速生成代碼片段，有效減少手動編寫代碼的時間。Kilo Code 能自動化執行多種重複性編碼任務，例如代碼格式化、重構以及生成樣板代碼等，進一步提高開發效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367470</guid>
      <pubDate>Mon, 18 Aug 2025 10:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌圖像編輯 AI 模型 nano-banana 現身 LMArena</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;最近，一款名為 nano-banana 的神秘圖像編輯 AI 模型悄然現身 LMArena 平台。有爆料稱：這是谷歌正在測試的新模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-daa046b2afeced90c8ac232dead09582575.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f40a92db7e4552760f02564cf4641fa98f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;谷歌工程師在社交平台上發佈香蕉 emoji 或香蕉圖片，明示代號為 nano-banana 的圖像生成模型為谷歌所有。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-867584592c2b8c9970b5f4314a01c353dda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前該模型在 LMArena 平台進行測試，但尚未在 AI Studio 上線。在 text-to-image（文生圖）和 image-edit（圖像編輯）功能方面，nano-banana 展示了強大的能力，其性能被認為超越了 GPT-Image-1 模型。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lmarena.ai/?chat-modality=image&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367467</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367467</guid>
      <pubDate>Mon, 18 Aug 2025 10:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firecrawl 獲 1450 萬美元 A 輪融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Firecrawl 宣佈完成 1450 萬美元的 A 輪融資。本輪融資由 Nexus Venture Partners 領投，Shopify 首席執行官 Tobias Lütke 及 Y Combinator 等知名投資者跟投。&lt;/p&gt; 
&lt;p&gt;據悉，Firecrawl 通過一封大膽的電子郵件與 Tobias Lütke 建立了聯繫，此前後者通過自助服務平台試用了 Firecrawl 的產品。這一投資不僅為 Firecrawl 注入了資金動力，也為其技術創新和市場擴展提供了強有力的背書。&lt;/p&gt; 
&lt;p&gt;Firecrawl 表示，此輪融資將用於加速產品研發、擴大全球工程與 AI 專家團隊，並進一步優化其服務能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-0f5d3148770305396b53663dc286ff63317.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Firecrawl 同步推出了其 V2 版本 API，被稱為迄今為止最重大的技術升級。新版本在以下幾個方面實現了突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;10 倍速抓取：通過優化的 Fire-Engine 技術，V2 版本的網頁抓取速度提升了 10 倍，成功率提高 40%，為大規模數據處理提供了更高的效率。&lt;/li&gt; 
 &lt;li&gt;語義化爬取：利用自然語言處理技術，Firecrawl 能夠根據語義理解網頁結構，自動提取所需數據，減少手動幹預，提升數據質量。&lt;/li&gt; 
 &lt;li&gt;新增新聞與圖像搜索功能：V2 版本新增了對新聞和圖像內容的搜索與提取支持，為 AI 應用提供了更豐富的實時數據來源。&lt;/li&gt; 
 &lt;li&gt;多功能集成：持 Markdown、JSON、截圖等多種數據格式輸出，並與 LangChain 等 AI 框架無縫集成，方便開發者快速構建 AI 應用。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367465</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367465</guid>
      <pubDate>Mon, 18 Aug 2025 10:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>釘釘重注 AI：成立行業專屬模型團隊，向 CTO 彙報</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWRBSkp0dSe3sfff4WP0CFw" target="_blank"&gt;智能湧現&lt;/a&gt;》獨家獲悉，釘釘近期成立了一個新業務線——行業專屬模型，並作為獨立團隊存在，向釘釘 CTO 朱鴻彙報。這也是釘釘創始人無招回歸後，釘釘在 AI 戰略推進中的重要動作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「團隊成立後，目前釘釘已經與多家行業客户接觸，目前已有幾個行業/企業專屬模型在推進中。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;自 4 月重返釘釘後，無招將產品體驗和 AI 創新作為首要優先級。從 4 月開始，釘釘就經歷了一場整改——覆蓋範圍很廣，從產品設計、排查，到整改，無招都在一線深度參與。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從 ChatGPT 爆火後，釘釘已經完成了大模型基礎能力的接入。2023 年 8 月，釘釘就已經將智能化底座 (AI PaaS) 開放給生態夥伴和客户，鼓勵合作伙伴利用大模型重新打造產品；再到 2024 年 1 月發佈的 AI 助理，具備感知、記憶、規劃和行動能力，能夠跨應用程序執行任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據釘釘此前披露的數字，釘釘目前企業組織數超過 2500 萬，其中有超 220 萬家企業在釘釘使用 AI，覆蓋製造、醫療、金融、零售等 20 個一級行業。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;成立行業專屬模型團隊，是大模型在技術、產品化之後，繼續在企業側落地的體現。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;企業 AI 落地的挑戰並不小。一方面，大多數企業、尤其是中小企業雖然對 AI 有強烈需求，但普遍缺乏專業的技術團隊和數據處理能力；另一方面，通用大模型雖然功能強大，但難以滿足垂直行業的專業需求，需要針對特定場景進行深度定製和優化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;釘釘的行業專屬模型團隊，主要面向釘釘平台上的企業客户、第三方合作伙伴。比如，對於沒有充足 AI 人才資源的中小企業客户，釘釘會提供全流程的模型訓練和數據工程服務，包括前端的數據打標、清洗到模型的調優，都由釘釘團隊完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與面向開發者的阿里雲旗下百鍊等平台相比，釘釘行業專屬模型會更貼近業務場景。「行業專屬模型是由釘釘和企業中懂業務、懂行業的業務人員共創，將行業 know-how 沉澱下來，讓企業客户能夠更快、更好地用上模型。」一位釘釘人士對 36 氪表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，釘釘已經在行業專屬模型方面取得了初步成果。在 7 月發佈的豆蔻婦科大模型，其實是釘釘平台上成功落地的第一個垂類專屬大模型。其作為醫療領域的垂類模型，可將婦科六大症狀的診斷準確率，從 77.1% 提升到 90.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在推動行業專屬模型的同時，釘釘也在加速完成 AI 生態的閉環，另一個新動作是對應用市場進行改版。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent 已經是 2025 年大廠競爭的「明牌」。從 2024 年開始，大廠們已經推出了包括阿里雲百鍊、字節跳動釦子 (Coze)、百度文心智能體、騰訊元器等 Agent 平台。釘釘也在 2024 年 4 月上線了 AI Agent Store。無招回歸釘釘後，一個重要工作也是重新構造 Agent 市場的邏輯。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了應用推薦方式大變之外，釘釘未來會在 Agent 市場上再發力，開放能力給更多的 ISV 和企業，幫助企業打造 Agent 應用，並通過釘釘實現商業化閉環，打通整個 Agent 應用生態。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367464</guid>
      <pubDate>Mon, 18 Aug 2025 10:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>DatologyAI 發佈合成數據框架 BeyondWeb</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DatologyAI 發佈了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.datologyai.com%2Fbeyondweb%2F" target="_blank"&gt;&lt;strong&gt;BeyondWeb&lt;/strong&gt;&lt;/a&gt;，一個專為大規模語言模型（LLM）預訓練設計的合成數據生成框架，旨在突破當前面臨的數據瓶頸問題。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/181040_p3sx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該框架採用「目標導向的文檔重寫」策略，對現有高質量網絡數據進行改寫，而非從頭生成，從而在保證數據多樣性和信息密度的同時，避免了低質量內容的引入。&lt;/p&gt; 
&lt;p&gt;據介紹，BeyondWeb 通過高質量、信息密集的合成數據，顯著提升了模型性能，即使在原始網絡數據有限的情況下，也能實現超越傳統數據規模擴展的效果。在 14 項基準測試中，使用 BeyondWeb 生成的合成數據訓練的 3B 參數模型，其性能超過了使用 Cosmopedia 數據訓練的 8B 參數模型，同時訓練速度提升了最高達 7.7 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eadd4a1595c18a9ec07e6705a60c8bc60c7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;論文地址：https://arxiv.org/pdf/2508.10975&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367463</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367463</guid>
      <pubDate>Mon, 18 Aug 2025 10:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>100% 開源版的 Claude Code？00 後這麼勇嗎？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;幾天前，來新璐告訴我，他做了一個開源版本的 Claude Code 。&lt;/p&gt; 
&lt;p&gt;我問他，能實現幾成&amp;nbsp;Claude Code 的效果。&lt;/p&gt; 
&lt;p&gt;他簡單地回覆我：100%。&lt;/p&gt; 
&lt;p&gt;&lt;img height="124" src="https://oscimg.oschina.net/oscnet/up-3f746e5853445f04492023812b04aeba4d2.png" width="309" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果是別人，我可能就當他説大話了。&lt;/p&gt; 
&lt;p&gt;但他是來新璐，llama3 中文版作者，GitHub Star 數已經有 4.2K 了。&lt;/p&gt; 
&lt;p&gt;此前曾在百度&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;飛槳&lt;/a&gt; &amp;amp; 騰訊混元負責多模態大模型訓練、推理相關的開源套件工作。&lt;/p&gt; 
&lt;p&gt;他還開發了多個技術項目，比如文生圖大模型訓練工具箱 ——&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCrazyBoyM%2Fdreambooth-for-diffusion" target="_blank"&gt;&lt;span&gt;dreambooth-for-diffusion&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，也給 ComfyUI 的 controlnet 部分貢獻過代碼。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;這麼看起來，他還是有點東西的。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;而且，作為一個 00 後，他還&lt;span&gt;是奇績創壇 F24 校友，&lt;/span&gt;創立了 ShareAI-Lab，一家注重技術創新的實驗室性質的公司，面向 toB 市場，做模型後訓練、數據合成標註、資料知識庫+ AI agent 搜索。&lt;/p&gt; 
&lt;p&gt;公司還有一個技術開發組長，叫陶熠，是斯坦福大學人工智能專業碩士畢業，妥妥的 AI&amp;nbsp;Agent 專家。&lt;/p&gt; 
&lt;p&gt;再加上前段時間，來新璐一直在對 Claude Code 源碼進行深度逆向分析，一口氣發了 5 篇文章。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo4pu8QX1tRIPBRlFJqrX3A" target="_blank"&gt;Claude Code 逆向破解 Prompt 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGspfXKHiwtdhr73KtDgO1w" target="_blank"&gt;Claude Code 分層多 Agent 架構篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlBhZhdlb1s0y4qgl_5HSWQ" target="_blank"&gt;Claude Code: 上下文工程 system-reminder 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMeJTDMcYV2u-TJfOJlLilg" target="_blank"&gt;Claude Code 異步消息通信機制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj8eTytIDy9l4dnLVHS_Cuw" target="_blank"&gt;Claude Code 最新版解讀之自定義 Agent 機制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;現在跟我説搞了個 100% 開源版的 Claude Code，這個可信度就又提高了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這個號稱 「100% 開源版 Claude Code」 的項目，叫 Kode。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FshareAI-lab%2FKode" target="_blank"&gt;&lt;strong&gt;GitHub 地址：&lt;/strong&gt;https://github.com/shareAI-lab/Kode&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;7 月初就放話説要開源，不過一直沒有發佈，大家甚至一度以為要被鴿 ！&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-6f1e9a2460372836c22eccc6194f26d9880.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="background-color:#ffffcc"&gt;不過，最終它來了！目前 GitHub 已經有 900 多 Star。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;與官方 Claude Code 比較之後，也有較多出彩的地方。&lt;/p&gt; 
&lt;p&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-20256148956a23d9da17f32f0fa7b0e2416.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最後，不管我怎麼問他，得到的回答都是非常肯定的——Kode 就是開源版 Claude Code。&lt;/p&gt; 
&lt;p&gt;看來，Kode 都是要蹭勞 Claude Code 這波流量了。&lt;/p&gt; 
&lt;p&gt;&lt;img height="195" src="https://oscimg.oschina.net/oscnet/up-6cb6eb15c540029a760c2eea5f8475ec939.png" width="538" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;既然他敢把話説得這麼滿，那就直播來驗一驗真假！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0635a39399fde8a01a773d4770b4bb9e1d9.png" width="540" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;是騾子是馬，拉出來遛遛就知道了！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;ShareAI-lab 搞了個 100% 開源版 Claude Code&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;8 月 23 日週五 20:00-21:00&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播亮點&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;拆解 Claude Code 技術設計原理&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;開源版 Claude Code —— Kode 源碼帶讀&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Claude Code 高階使用技巧及 SDK 應用潛力場景分享&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;實戰：用 Kode 維護大型項目&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;演示：小型 MVP Demo &amp;amp; 使用技巧&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;展望 Agent 世界發展&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;福袋抽獎：直播中將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼、前沿技術書籍等。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt;
  可以加入 OSC 直播交流羣，進來嘮嘮嗑，或者你有好的產品 / 項目，也歡迎推薦過來呀～ 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，基本上每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18688925</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18688925</guid>
      <pubDate>Mon, 18 Aug 2025 10:10:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>Anthropic 推出 Usage and Cost API</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 近期推出了 Usage and Cost API，作為其 Admin API 的一部分，旨在幫助開發者和組織以編程方式實時監控和追蹤 Claude 模型的使用情況和成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/180149_Zv2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://docs.anthropic.com/en/api/admin-api/usage-cost/get-messages-usage-report&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;該 API 允許用户通過請求獲取詳細的用量報告。報告支持多種精細化的篩選和分組條件，包括按 API 密鑰 ID、工作區 ID、模型（例如 claude-sonnet-4-20250514）、服務等級（standard,batch,priority）以及上下文窗口大小（0-200k,200k-1M）進行查詢。報告的時間粒度可以設置為分鐘（1m）、小時（1h）或天（1d）。&lt;/p&gt; 
&lt;p&gt;為了方便開發者快速上手，Anthropic 在 GitHub 的 anthropic-cookbook 項目中提供了一個名為 usage_cost_api.ipynb 的 Jupyter Notebook 示例教程。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/anthropics/anthropic-cookbook/blob/main/observability/usage_cost_api.ipynb&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367457</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367457</guid>
      <pubDate>Mon, 18 Aug 2025 10:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>韓國政府擬未來兩年採購超 3.5 萬枚 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;韓國科學技術信息通信部週三表示，韓國將在未來兩年內採購超過 35000 枚圖形處理器（GPU），作為全國範圍內加強人工智能（AI）基礎設施計劃的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="380" src="https://oscimg.oschina.net/oscnet/up-bef12c45835c72bb33b4f121bbd7f104e9c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韓國科學技術信息通信部長官裴慶勳當天在國會表示，政府的長期目標是到 2030 年確保 5 萬枚 GPU。「我不認為政府能包辦一切。政府將為私營部門創造人工智能市場和基礎設施投資鋪平道路。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作為該計劃的一部分，韓國政府啓動了一個開發韓國 AI 基礎模型的項目，五家公司 Naver Cloud、Upstage、SK Telecom、NC AI 和 LG AI Research 將獲得研發資金支持以及政府資源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，韓國政府通過「AI 高速公路」計劃，提出了到 2030 年成為全球人工智能領導者的願景，其中包括建立配備 5 萬枚 GPU 的國家人工智能數據中心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367456</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367456</guid>
      <pubDate>Mon, 18 Aug 2025 10:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>COLMAP - 三維重建軟件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 是一個通用的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;Structure-from-Motion (SfM) 和 Multi-View Stereo (MVS) pipeline&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，具有圖形和命令行界面。它提供了豐富的功能，可用於重建有序和無序圖像集。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="210" src="https://static.oschina.net/uploads/space/2025/0818/145035_b3XQ_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="102" src="https://static.oschina.net/uploads/space/2025/0818/145138_oR0u_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你將此項目用於您的研究，請引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你使用 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;image retrieval / vocabulary tree engine&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，請同時引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016vote,
    author={Sch\"{o}nberger, Johannes Lutz and Price, True and Sattler, Torsten and Frahm, Jan-Michael and Pollefeys, Marc},
    title={A Vote-and-Verify Strategy for Fast Spatial Verification in Image Retrieval},
    booktitle={Asian Conference on Computer Vision (ACCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 建立在現有成果之上，在 COLMAP 中使用特定算法時，請註明原始作者（如源代碼中所述），並考慮引用相關的第三方依賴項（例如 ceres-solver、poselib、sift-gpu 和 vlfeat）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/colmap</link>
      <guid isPermaLink="false">https://www.oschina.net/p/colmap</guid>
      <pubDate>Mon, 18 Aug 2025 09:38:00 GMT</pubDate>
    </item>
    <item>
      <title>百度 Q2 財報：總營收 327 億元，AI 新業務收入超 100 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;百度已發佈 2025 年 Q2 業績。季度總營收達 327 億元，歸屬百度核心的淨利潤 74 億元，同比增長 35%，超出市場預期。受 AI 驅動，涵蓋智能雲在內的 AI 新業務收入增長強勁，首次超過 100 億元，同比增長 34%。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;百度搜索實現搜索框、搜索結果頁到搜索生態全面革新。7 月，移動搜索結果頁 AI 生成內容佔比達 64%。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能雲業務營收健康增長。IDC 報告顯示，百度智能雲連續六年在中國 AI 公有云服務市場份額中排名第一；在 8 月 20 日最新發布的 IDC 報告中，百度智能雲獲大模型平台市場第一。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;蘿蔔快跑 Q2 在全球提供超 220 萬次出行服務，同比增長 148%。截至 2025 年 8 月，蘿蔔快跑在全球累計提供超 1400 萬次的出行服務，足跡覆蓋全球 16 座城市。&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="407" src="https://oscimg.oschina.net/oscnet/up-dbfec1113b742dde43df7d6f29f5616147a.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="399" src="https://oscimg.oschina.net/oscnet/up-1c3bedd483c3e141c985f84fc64f5b0fea5.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="389" src="https://oscimg.oschina.net/oscnet/up-ec6a732253318c7bcae772c4d7290c5a922.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-a82bd72897868fcd3d7d1001409ae44376a.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="405" src="https://oscimg.oschina.net/oscnet/up-5a0078a83511433a02fd5f65b412a2b7983.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367441</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367441</guid>
      <pubDate>Mon, 18 Aug 2025 09:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Ubuntu 25.04 成首個開箱即用支持 AMD SEV-SNP 的發行版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ubuntu 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fubuntu-25-04-amd-sev-snp-host-support" target="_blank"&gt;宣佈&lt;/a&gt;，在最新發布的 Ubuntu 25.04（Plucky Puffin） 中，系統已全面集成 AMD SEV-SNP（Secure Encrypted Virtualization - Secure Nested Paging）主機端支持。這意味着用户無需額外打補丁或依賴實驗構建，就能直接在生產環境中啓用完整的 SEV-SNP 功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/171014_ReO5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;SEV-SNP 是 AMD 針對虛擬化場景的硬件級安全技術，它為虛擬機提供內存加密和完整性保護，能夠阻止宿主機、固件甚至系統管理員訪問虛擬機內部數據，被認為是機密計算（Confidential Computing） 的核心支撐之一。其應用價值尤其體現在數據中心和私有云環境，如 AI 模型推理和高敏感度業務計算。&lt;/p&gt; 
&lt;p&gt;此前，Ubuntu 早已在 22.04 LTS 中提供了 SEV-SNP 客機支持。隨着 25.04 的更新，Ubuntu 成為首個在主機與客機兩端都實現開箱即用支持的主流 Linux 發行版。儘管 Fedora 42 在發佈時間上略早一步，但 Canonical 強調 Ubuntu 的版本無需額外調整，即可直接應用於生產環境。&lt;/p&gt; 
&lt;p&gt;這項功能也將被納入即將到來的 Ubuntu 26.04 LTS，屆時企業用户還將獲得 FIPS 內核、Livepatch 等長期支持和合規特性，為高安全場景部署提供更穩健的保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367440/ubuntu-25-04-amd-sev-snp-host-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367440/ubuntu-25-04-amd-sev-snp-host-support</guid>
      <pubDate>Mon, 18 Aug 2025 09:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Docs 上線 AI 語音朗讀功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌近日宣佈，Google Docs 推出了一項全新的功能，用户現在可以通過 AI 生成語音來朗讀他們的文檔。此功能旨在提升用户的閲讀體驗，使得信息的獲取更加便捷和生動。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在這一功能的使用過程中，用户可以自定義 AI 的音頻輸出，包括選擇不同的聲音和調整播放速度。這種個性化設置能夠幫助用户根據自己的喜好來選擇最適合的聽覺體驗，使得文檔內容的傳達更具吸引力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="337" src="https://oscimg.oschina.net/oscnet/up-288e88a5cce3983495e512628222b54ff43.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不僅僅是文檔的創建者可以使用這一功能，其他讀者也能夠輕鬆訪問共享文檔的 AI 生成音頻。用户只需在工具菜單中選擇 「音頻」 選項，再點擊 「收聽此標籤」 即可開始聆聽。此外，文檔的作者也可以通過插入音頻按鈕，將可自定義的音頻添加到文檔中，讀者點擊按鈕後即可開始收聽。這種設計讓閲讀和分享文檔變得更加有趣。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌早在四月份就曾透露將推出將文檔轉換為 AI 播客的計劃，而這次的新功能則提供了一個更直接的聽取文檔內容的方式，特別是對於那些希望聆聽自己創作的內容的用户。目前，該功能僅支持在桌面設備上生成英文文檔的音頻版本。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌目前正向擁有商業、企業或教育計劃的 Workspace 用户，以及訂閲 AI Pro 和 Ultra 的用户推出此功能。隨着這項新功能的逐步上線，用户將能以更便捷和靈活的方式享受文檔的內容，進一步提升工作效率和閲讀體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367428</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367428</guid>
      <pubDate>Mon, 18 Aug 2025 08:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊 AI Lab 發佈多模態音頻生成工具 AudioGenie</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊 AI Lab&amp;nbsp;推出一項名為 AudioGenie 的新型無訓練多智能體系統，為多模態到多音頻（MM2MA）生成領域帶來重大突破。&lt;/p&gt; 
&lt;p&gt;該系統能從視頻、文本、圖像等多模態輸入中，精準合成音效、語音、音樂、歌曲等多種音頻，有效解決了該領域長期面臨的高質量配對數據稀缺、多任務學習框架薄弱等核心挑戰。&lt;/p&gt; 
&lt;p&gt;AudioGenie 框架如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9ec2fecbaa136171f954205d7e2d0c2dbb7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://audiogenie.github.io/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AudioGenie 採用雙層架構，由生成團隊與監督團隊組成。生成團隊通過細粒度任務分解和自適應混合專家（MoE）協作機制，實現對多模態輸入的深度理解與動態模型選擇，並藉助試錯迭代優化模塊完成自我修正；監督團隊則通過反饋循環確保音頻的時空一致性並驗證輸出質量。&lt;/p&gt; 
&lt;p&gt;此外，研究團隊還構建了首個 MM2MA 任務基準數據集 MA-Bench，包含 198 個帶多類型音頻標註的視頻。實驗表明，AudioGenie 在 8 項任務的 9 個指標中均達到當前最優或可比性能，用户研究進一步證實其在音頻質量、準確性、上下文對齊及美感上的顯著優勢，為跨模態音頻生成應用開闢了新路徑。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367426</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367426</guid>
      <pubDate>Mon, 18 Aug 2025 08:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>實戰分析前端性能優化工具 Performance 面板！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;本文由體驗技術團隊董福俊原創。&lt;/p&gt; 
&lt;h2&gt;一、背景&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;關於 Performance 面板的基礎用法介紹，可參考上一篇文章《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwQmdgduzUmCJ2qJge5QZtA" target="_blank"&gt;"Performance 面板"一文通，解鎖前端性能優化工具基礎用法！&lt;/a&gt;》。文章中還從一個 HTTP 請求的四階段的角度來介紹 Performance 圖的"觀看方式"，並重點介紹了 worker 線程跟主線程的協作關係&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本篇文章中，我們將會以一個實際網頁 ------&lt;strong&gt;VPC 列表頁&lt;/strong&gt;為例，介紹 Performance 抓圖及分析的過程，並將上一篇文章中介紹的相關內容串起來，希望每位 frontend developer 都能掌握用 Performance 分析頁面性能的能力。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：這裏假設我們的分析目標是：讓列表頁的主內容區域儘快展示出來，以避免長時間白屏；另外，為求簡潔，下文敍述中統一將 Performance 錄製的結果圖叫做"性能圖"&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;二、分析前準備&lt;/h2&gt; 
&lt;p&gt;正式分析之前，建議做一些準備工作，能有效提高後續的分析效率。&lt;/p&gt; 
&lt;h3&gt;1. 環境準備&lt;/h3&gt; 
&lt;p&gt;1）選一個良辰吉日&lt;/p&gt; 
&lt;p&gt;建議&lt;strong&gt;關閉一些應用程序、瀏覽器頁籤，儘量讓電腦 CPU 空閒一些&lt;/strong&gt; ，（&lt;em&gt;也建議關掉通信軟件，讓自己心情好一些&lt;/em&gt;）。儘量避免一邊開會一邊分析，避免分析過程被頻繁打斷，因為分析過程可能遇到各種奇怪的現象，倘若再被其它事務打斷，心態直接崩潰，那麼就分析不下去了......&lt;/p&gt; 
&lt;p&gt;2）選瀏覽器無痕模式&lt;/p&gt; 
&lt;p&gt;建議&lt;strong&gt;在瀏覽器無痕模式下錄製性能圖並進行分析&lt;/strong&gt;，因為一些特殊的瀏覽器配置、瀏覽器插件，都可能影響網頁的加載過程，幹擾分析結果。&lt;/p&gt; 
&lt;p&gt;3）選生產環境進行分析&lt;/p&gt; 
&lt;p&gt;我們可能有多種不同環境：本地代理環境（俗稱 localhost）、類生產環境、生產環境，等。只有生產環境是最真實貼近用户的，所以建議&lt;strong&gt;在生產環境下進行網頁性能分析。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;但需要注意的是，生產環境部署的代碼，跟源碼往往有較大形態上的差異（eg：打包工程的混淆、部署時的加工、服務端渲染的處理等）。所以，生產環境的性能圖在某些代碼細節上可能無法深入研究，此刻，我們還是需要其它環境的性能圖進行輔助對比。&lt;/p&gt; 
&lt;h3&gt;2. 代碼準備&lt;/h3&gt; 
&lt;p&gt;1）瞭解代碼結構和加載流程&lt;/p&gt; 
&lt;p&gt;建議先從源碼角度，詳細瞭解待分析頁面的結構及加載流程，例如我們討論的樣例------ VPC 列表頁的結構如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;頁面結構&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9dc5c1a56bf9fd281f211ddb0f4dfc389.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;紅色框：由基礎框架 console-ui 提供的 header、sidebar 實現&lt;/li&gt; 
 &lt;li&gt;藍色框：由業務代碼實現，採用 angular 技術框架，NG App 下掛載一個根組件（VpcComponent）&lt;/li&gt; 
 &lt;li&gt;綠色框：根組件下分為，導航組件（LeftmenuComponent）和，列表頁組件（VpcListComponent）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;代碼結構&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-html"&gt;&amp;lt;!-- index.html --&amp;gt;

&amp;lt;div id="header"&amp;gt;&amp;lt;!-- console-ui 負責渲染 --&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;div id="sidebar"&amp;gt;&amp;lt;!-- console-ui 負責渲染 --&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;!-- NG App 掛載點 --&amp;gt;

&amp;lt;div id="ngApp"&amp;gt;

    &amp;lt;!-- 根組件 --&amp;gt;

    &amp;lt;vpc-component&amp;gt;

        &amp;lt;leftmenu-component&amp;gt;&amp;lt;!-- 導航組件 --&amp;gt;&amp;lt;/leftmenu-component&amp;gt;

        &amp;lt;router-outlet&amp;gt;

            &amp;lt;!-- 內容區-路由渲染點 --&amp;gt;

            &amp;lt;vpc-list-component&amp;gt;&amp;lt;!-- 列表頁組件 --&amp;gt;&amp;lt;/vpc-list-component&amp;gt;

        &amp;lt;/router-outlet&amp;gt;

    &amp;lt;/vpc-component&amp;gt;

&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;console-ui 和 NG App 並行工作，分別負責不同 div 的渲染&lt;/li&gt; 
 &lt;li&gt;APP 的根組件下，導航組件和內容區並行工作，內容區由路由加載列表組件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;初始化流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-91be71aaf0d51fd59268446efd7beecb4f1.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主渲染流程是：NG App 啓動 =&amp;gt; 加載根組件 =&amp;gt; 路由渲染 =&amp;gt; 加載列表頁組件&lt;/li&gt; 
 &lt;li&gt;angular 中每個組件都會經歷生命週期：constructor =&amp;gt; ... =&amp;gt; ngOnInit =&amp;gt; ... =&amp;gt; ngAfterViewInit =&amp;gt; ... （這裏只列舉一些常用生命週期鈎子，完整的説明見 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fangular.cn%2Fguide%2Fcomponents%2Flifecycle" target="_blank"&gt;組件生命週期&lt;/a&gt;。&lt;em&gt;PS：這一點不理解也不妨礙下文閲讀&lt;/em&gt;）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2）關鍵節點加 performance.mark&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;很關鍵的是：在我們的主渲染流程上一些關鍵的時間節點加上 performance.mark，或者關鍵時間段加上 console.time/timeEnd&lt;/strong&gt;。這樣在性能圖的 Timings 面板上就會顯示這些標記，從而幫助我們確認各個執行環節。&lt;/p&gt; 
&lt;p&gt;例如，針對&lt;strong&gt;VPC 列表頁&lt;/strong&gt;的主渲染流程，我們在 NG App 啓動、根組件 constructor 及 ngAfterViewInit、列表頁組件 constructor 及 ngAfterViewInit，分別加上 performance.mark，則能在 Timings 面板中看到下圖情況：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a494681e351a324f9d0433648e9a2f7a9d8.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS1：Timings 面板中的線很細，不仔細觀察可能會漏掉。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS2：為了針對生產環境進行分析，我們可能需要提前在代碼中預埋 performance.mark，待上線後才能利用的上。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;3）錄製性能圖&lt;/p&gt; 
&lt;p&gt;在 Network 面板清空已有記錄，在 Performance 面板多點幾下垃圾回收，然後開始錄製。錄製完成後，&lt;strong&gt;將 Performance 面板的性能圖導出成 json 文件，並將 Network 面板的網路請求記錄導出成 har 文件，保存在本地以方便後續查看。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;三、數據分析&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;錄製好性能圖後，建議先分析 Network 面板中的 index.html，大致瞭解加載了哪些靜態資源，然後再投入性能圖的分析&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;1. 分析 index.html&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;首先分析下 Network 面板中的 index.html，大致瞭解頁面加載了哪些靜態資源。&lt;/strong&gt; 一般源碼中的 index.html 跟瀏覽器實際執行的 index.html 往往有很大差別，因為代碼 (打包) 工程會對 index.html 進行魔改，如果有服務端渲染機制，那麼服務渲染時可能還會插入一些樣式、腳本。所以，瀏覽器最終執行的 index.html 將會是，源碼+工程修改+服務端渲染，之後的結果。&lt;/p&gt; 
&lt;p&gt;例如，針對&lt;strong&gt;VPC 列表頁&lt;/strong&gt;的 html 進行分析，會發現其加載了以下資源（按 html 中從上到下的順序排列）&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-84bc4c997c2c0993ff360cd236cccd00058.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們需要搞清楚瀏覽器會開幾個&lt;strong&gt;TCP 連接&lt;/strong&gt; ？哪些資源會擠在同一個連接中？因為同一個連接中的資源會互相爭搶網絡帶寬 &lt;em&gt;。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;分辨方法是：&lt;strong&gt;h2 下同一個域名的資源會共用同一個 TCP 連接，http/1.1 下同一個域名可能會開多個 TCP 連接，資源們按順序排隊。&lt;/strong&gt; 所以上表中，所有 CDN 域下的資源共用同一個 TCP 連接，Server 域下只有一個資源，暫時只開一個 TCP 連接。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：説"暫時"是因為，後續可能會有動態加載 js、或者發起 ajax、fetch 請求，可能會增加 TCP 連接數量&lt;/em&gt;。&lt;/p&gt; 
&lt;p&gt;另外，下載優先級是由瀏覽器綜合分析並自動分配的，我們無法直接指定優先級。並且不同版本瀏覽器的分配策略各異，但大多數情況下，會遵循如下規則：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通過&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;標籤加載的 js 腳本的優先級高於動態創建 script 的優先級。（動態創建例如：通過 appendChild 往 DOM 中插入一個&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;標籤）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;標籤上沒有加任何標記（module、async、defer）的，優先級最高&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;標籤被標記了 type="module"的，優先級較高&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;標籤被標記了 async、defer 的，優先級較低&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;值得説明的是，項目採用了 webpack 打包，其中 main.{hash}.js 就是 webpack 主入口文件，而 vendor~tinycloud 等文件均是分包策略拆出來的 chunks 們。&lt;/p&gt; 
&lt;h3&gt;2. 分析 Performance 數據&lt;/h3&gt; 
&lt;p&gt;接着，我們就要分析性能圖了，我們的首要目標是：&lt;strong&gt;搞清楚性能圖中各個環節在做什麼，並將它跟初始化流程一一對應起來&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;2.1 分析映射關係：代碼 &amp;lt;=&amp;gt; 性能圖&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-530cd861d887e1ad7c8bc9d2653c55b1652.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;首先觀察性能圖中&lt;/strong&gt; &lt;strong&gt;Network（網絡情況）、Main（CPU 情況）、Timings（我們預埋的 mark 標記） 這三個部分，嘗試搞清楚圖中每個時間段裏面，瀏覽器在忙些什麼。&lt;/strong&gt; 以上圖為例，大致流程是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;時段 1：網絡繁忙、CPU 空閒&lt;/li&gt; 
 &lt;li&gt;時段 2：網絡空閒、CPU 繁忙&lt;/li&gt; 
 &lt;li&gt;時段 3：網絡 CPU 都繁忙&lt;/li&gt; 
 &lt;li&gt;NG App 啓動從時段 3 才開始&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;接下就是詳細分析過程：&lt;/p&gt; 
&lt;p&gt;1）時段 1：靜態資源下載&lt;/p&gt; 
&lt;p&gt;分析每一個請求，&lt;strong&gt;搞清楚它是誰發起的，在業務上有什麼作用。&lt;/strong&gt; 點開一個資源條，就可以在 Summary 面板中看到它的一些基礎信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：有時候，Summary 面板中寫的 Initiated by 不一定是真實的發起者，真實發起者可能被層層代碼封裝隱藏了，我們需要到 Network 面板中的 Initiator 裏面去找真實發起者&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a3c7cbd21ecc6c14548c8ac4a94131f21a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對時段 1 的所有請求進行分析之後，我們就搞清楚了這個階段的具體情況，如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f856fc57c408f5a8fd85a12d0a8a1c0bf66.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;綠色部分由 console-ui 發起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首輪請求 (html 中通過 script 直接引用)：僅 consoleui.umd.js 這 1 個資源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;非首輪請求 (由某些邏輯動態發起)：5 個靜態資源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt; ；若干 Fetch/XHR 請求 &lt;em&gt;（Server 域/http1.1）&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;紅色部分由業務代碼發起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首輪請求 (html 中通過 script 直接引用)：runtime、polyfill、......、main 等 11 個資源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;非首輪請求 (由某些邏輯動態發起)：無&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;藍色部分由 cc 組件（一個三方業務組件，負責一些特殊業務組件的實現）發起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首輪請求 (html 中通過 script 直接引用)：無&lt;/li&gt; 
   &lt;li&gt;非首輪請求 (由某些邏輯動態發起)：cc-main.js &lt;em&gt;（Server 域/http1.1）&lt;/em&gt; 及若干 main、theme 等 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;時段小結：&lt;/strong&gt; 這一時段主要是完成各種 HTTP 請求，主要有，業務代碼、console-ui、cc 組件三方參與。首輪請求主要是業務代碼的請求，採用 h2 協議，console-ui 及 cc 組件則多為非首輪請求。&lt;/p&gt; 
&lt;p&gt;這裏其實可以看出來，業務代碼發起的靜態資源請求幾乎獨佔首輪請求，其它請求均是在後續輪發起，不會影響業務靜態資源請求的完成。並且所有 Fetch/XHR 請求都是使用 Server 域/http1.1，跟靜態資源使用的 CDN 域/h2 是兩個不同的 TCP 通道，不會影響業務靜態資源的加載。&lt;/p&gt; 
&lt;p&gt;2）時段 2：webpack 代碼展開&lt;/p&gt; 
&lt;p&gt;分析火焰圖中每個色塊，&lt;strong&gt;搞清楚它們是屬於哪個代碼文件的內容，它們在執行什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f3c7d14ad82421a30a7f4039d57fd5206f3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上一篇文章中介紹過，每個色塊是一個函數，色塊的名字是函數名，色塊上下關係是函數調用關係，這一整個火焰圖就是調用棧的直觀展示。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查看色塊歸屬：在上一篇文章中提到過，webpack 打包時會將 js 代碼用匿名函數包裹，並指定一個數字 key，所以就產生了這些數字命名的函數。點擊色塊可以看到它屬於哪個代碼文件。&lt;/li&gt; 
 &lt;li&gt;查看色塊在做什麼：查看這個 task 的火焰圖的棧底，會發現全是黃色的 Compile code 塊，説明在編譯代碼（V8 引擎的&lt;strong&gt;惰性編譯&lt;/strong&gt;策略）&lt;/li&gt; 
 &lt;li&gt;整個展開動作的起點：等待初始 chunk 全都下載完之後，才開始代碼展開。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;時段小結：&lt;strong&gt;這一時段主要在做 webpack 的代碼展開，CPU 在忙着編譯、執行被 webpack 打包的代碼&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;這裏需要對 webpack 打包產物有一定了解，才能透徹瞭解這個過程，簡要説明如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6ef372a96036827fc1e8b735a85c41bbdc.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;標題中所謂的 webpack 代碼展開，其實就是執行這些數字命名的包裹函數，而 V8 引擎的惰性編譯策略，可能不會在流式下載文件的環節就直接編譯這些代碼，所以棧底全都是 compile code 的色塊。另外，webpack 的啓動機制會保證所有 chunk 下載完成後，才啓動代碼展開工作，從，時段 1 =&amp;gt; 時段 2 的銜接點可以看到，雖然主 chunk 文件 main.xxxx.js 早已下載完成，但代碼沒有立即展開，而是等待最後一個 chunk 下載完成之後，才進行展開。&lt;/p&gt; 
&lt;p&gt;3）時段 3：動態下載語言包等主題資源&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0a5fe58ed00d0da5302a12c999661171d3a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;利用時段 1 提到的分析方法，對時段 3 的請求也做同樣的分析可知：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主要是語言包、主題資源包、docs 等通用資源的下載，主要使用 &lt;strong&gt;CDN 域/h2&lt;/strong&gt; 的通道。&lt;/li&gt; 
 &lt;li&gt;均是由業務代碼發起。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;利用時段 2 提到的分析方法，對時段 3 的火焰圖的各個色塊也進行同樣的分析可知：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;一些由微任務或定時器，喚起的 console-ui 邏輯被執行&lt;/li&gt; 
 &lt;li&gt;一些 cc 組件邏輯被執行&lt;/li&gt; 
 &lt;li&gt;還存在着若干空閒 task 時間&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同時，從 Timings 面板可以看出，在 webpack 代碼展開之後、時段 3 開始之前，NG App 就已經 boot 了，但是在時段 3 結束後，根組件才開始 construct。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;為什麼 angular 的 app 已經開始 boot 了，但根組件沒有儘快 construct？並且這中間還有空閒的 CPU 時間。&lt;/strong&gt; 這裏需要結合代碼實現來分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;該頁面支持多語言，為了不一窩蜂的下載所有語種的資源包，代碼中採用按需下載的模式：僅在確認了當前語種之後，才開始下載該語種的資源包。&lt;/li&gt; 
 &lt;li&gt;代碼中利用 angular router 的路由守衞，在守衞中異步下載當前語種對應的資源包。angular router 會確保根組件在守衞完成後再開始 construct。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以，&lt;strong&gt;問題的答案是：根組件在等待資源包的下載完成&lt;/strong&gt;。從圖中也可以看出，根組件 construct 是在 docs 接口完成之後的第 1 個 task 中進行的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;時段小結：&lt;/strong&gt; 這一時段主要是下載當前語種對應的資源包，而這些資源包是根組件 construct 的前提條件（因為路由守衞的原因） 。&lt;/p&gt; 
&lt;p&gt;而在資源下載期間，CPU 被用於執行一些 console-ui、cc 組件等非業務邏輯，或者直接空閒。因為在這期間，也沒有業務邏輯代碼可供執行了。&lt;/p&gt; 
&lt;p&gt;4）時段 4：關於時段 3 之後&lt;/p&gt; 
&lt;p&gt;從 Timings 面板中可知，在時段 3 之後、特別是根組件 construct 之後，根組件 afterViewInit、列表組件的 construct 和 afterViewInit 都緊鑼密鼓的執行起來了。這一段 CPU 極其繁忙，按生命週期順序執行各個組件的初始化，直到列表組件的 afterViewInit 完成後，列表頁主內容區域才展示出來。&lt;/p&gt; 
&lt;p&gt;針對這種任務密集時段，我們當然也可以用時段 2 中提到的分析方法，針對火焰圖中各個色塊進行分析。但從生產環境錄製的性能圖中看到的色塊名（函數名）可能都是混淆之後的結果，不利於跟源碼對應起來。此時，我們可以針對本地調試環境（localhost）錄製性能圖並進行分析，因為代碼執行在火焰圖上的表現，往往不會受到環境的影響。例如該時段中有這麼一段：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a7933d7131f8b4ac6d3e7e541c11a2d67c3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看出&lt;strong&gt;有一段結構很相似的調用，出現了多次重複&lt;/strong&gt;。從 localhost 環境抓取的性能圖中就可以明顯看出，這段重複執行的是 detectChangesInEmbeddedViews 函數，它是 angular 的內部函數。在嵌入式視圖場景中，如果有大量 ngFor、ngIf 就會觸發。通過源碼分析，這一段正是導航組件中的代碼實現造成的。&lt;/p&gt; 
&lt;h4&gt;2.2 在性能圖中找問題&lt;/h4&gt; 
&lt;p&gt;通過上一節中對性能圖透徹分析之後，我們已經能將性能圖跟源碼對應起來，並且能將性能圖跟加載流程對應起來，同時對一些關鍵節點心中有數。接下來要做的就是找問題、找可優化的空間，以達到我們的目標。例如針對&lt;strong&gt;VPC 列表頁&lt;/strong&gt;的分析可知，主渲染流程在性能圖中大致是：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ca6f1403a8367bd6712beeba540618d7a52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為了實現目標，我們至少可以找到以下優化點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下載靜態資源能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;非重要模塊，改為懶加載（按需動態 import），減少初始 chunk 的體積&lt;/li&gt; 
   &lt;li&gt;較大的圖片資源等，避免打包成 base64 字符串，減少 chunk 體積&lt;/li&gt; 
   &lt;li&gt;合理拆分 chunk 包，避免有一個獨大的 chunk，充分利用 h2 的並行下載效果&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;webpack 代碼展開能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;減少初始 chunk 的體積。需要展開的代碼少了，展開的自然更快&lt;/li&gt; 
   &lt;li&gt;避免在代碼中執行長耗時運算等&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下載語言包資源能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;語言包資源提前下載，和前面的靜態資源一起下載。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;組件生命週期能否執行的更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;削減高頻重複執行的 detectChangesInEmbeddedViews 函數的執行次數。&lt;/li&gt; 
   &lt;li&gt;減少非必要的渲染內容。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;總體上看，不同的項目會有不同的性能圖和性能瓶頸點，通用的優化方案可以解決一些常規問題，但當所有常規方案做完之後效果還是不夠滿意時，我們可能得進行針對性的分析來查找問題。通過深入性能圖分析，搞清楚 &lt;strong&gt;代碼&amp;lt;=&amp;gt;性能圖&lt;/strong&gt; 之間的映射關係之後，我們就能輕鬆找到性能瓶頸點，從而找對應的解決方案了。&lt;/p&gt; 
&lt;h2&gt;四、總結&lt;/h2&gt; 
&lt;p&gt;通過 Performance 面板錄製頁面加載性能圖並進行性能分析，是每一個 frontend developer 進階的必備技能之一。性能圖分析除了要求我們掌握 Performance 面板的基本用法之外，還要求我們對前端相關知識例如：webpack 工程打包、瀏覽器的加載運行、HTTP 協議機制、前端框架的原理、等都有一定了解，同時要求我們對項目代碼的結構和執行流程足夠清晰明確。常規的優化方案往往只能解決一些初級、普遍的問題，但每個頁面有每個頁面的具體情況，只有對頁面進行充分分析之後，才能搞清楚頁面的性能優化點在哪裏，從而有條不紊的落地實施。&lt;/p&gt; 
&lt;h2&gt;關於 OpenTiny&lt;/h2&gt; 
&lt;p&gt;歡迎加入 OpenTiny 開源社區。添加微信小助手：opentiny-official 一起參與交流前端技術～&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank"&gt;OpenTiny 官網&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design" target="_blank"&gt;https://opentiny.design&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;OpenTiny 代碼倉庫&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;https://github.com/opentiny&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank"&gt;TinyVue 源碼&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank"&gt;https://github.com/opentiny/tiny-vue&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank"&gt;TinyEngine 源碼&lt;/a&gt;： &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank"&gt;https://github.com/opentiny/tiny-engine&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;歡迎進入代碼倉庫 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~ 如果你也想要共建，可以進入代碼倉庫，找到 good first issue 標籤，一起參與開源貢獻~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6769809/blog/18688293</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/18688293</guid>
      <pubDate>Mon, 18 Aug 2025 08:16:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>德國聯邦最高法院裁定重審廣告攔截插件版權爭議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;德國聯邦最高法院近日的一項判決，再次引發了關於瀏覽器廣告攔截插件是否涉及版權侵權的討論。&lt;/p&gt; 
&lt;p&gt;此次爭議源於媒體企業 Axel Springer 對知名廣告攔截工具 Adblock Plus 的開發公司 Eyeo 提起的訴訟。Axel Springer 認為，&lt;strong&gt;廣告攔截插件影響了其網站的廣告收益，並指出插件在瀏覽器中運行的行為構成了對版權的侵犯&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71b1d139ef15730853dfeb32e23ec627176.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該觀點的核心在於，&lt;strong&gt;網站所使用的 HTML 和 CSS 代碼被認為是一種受版權保護的計算機程序，而廣告攔截插件在運行過程中修改了瀏覽器的執行結構，例如文檔對象模型（DOM）、樣式表對象模型（CSSOM）以及頁面渲染樹，這被解讀為未經授權的複製與更改&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在此之前，漢堡的初級法院並未支持 Axel Springer 的主張，但此次聯邦最高法院的裁決認為，此前的判決存在不足之處，因此推翻了部分決定，並將案件發回進行進一步審理。&lt;/p&gt; 
&lt;p&gt;Mozilla 公司負責知識產權和產品事務的高級顧問 Daniel Nazer 對此表示，由於這一案件涉及複雜的技術背景，法院的相關決定可能會對其他瀏覽器擴展產生影響，甚至影響用户在使用瀏覽器時的選擇自由。&lt;/p&gt; 
&lt;p&gt;他指出，用户希望通過瀏覽器或插件修改網頁內容的原因多種多樣，例如提升頁面可訪問性或增強隱私保護等。因此，此類司法裁決可能帶來更廣泛的影響。&lt;/p&gt; 
&lt;p&gt;根據德國聯邦最高法院的最新裁決，需要重新評估 HTML、CSS 以及相關代碼是否屬於受保護的程序類型，以及廣告攔截插件的行為是否構成合法使用。&lt;/p&gt; 
&lt;p&gt;儘管目前廣告攔截插件尚未被明確裁定為非法，但 Axel Springer 與 Eyeo 之間的案件現已重啓審理。Nazer 表示，整個法律程序可能仍需數年時間才能最終塵埃落定。&lt;/p&gt; 
&lt;p&gt;在最終結論出台前，此案可能已在技術社區引發擔憂情緒。一些瀏覽器和插件開發者或會出於風險控制考慮，主動限制其產品的功能範圍，以避免陷入類似的法律糾紛之中。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367401</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367401</guid>
      <pubDate>Mon, 18 Aug 2025 08:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Jarboot 3.3.0 發佈，Java 啓動器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Jarboot 3.3.0 已經發布，Java 啓動器。&lt;/p&gt; 
&lt;h2&gt;3.3.0（8，2025）&lt;/h2&gt; 
&lt;p&gt;修復已知的 bug，修復已知的 bug，推出 docker compose 部署策略，文件上傳 websocket 服務（/jarboot/upload/ws）傳入參數格式修改（json 字符串 base64 url 編碼）&lt;/p&gt; 
&lt;h3&gt;新特性&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;啓動時支持通過環境變量初始化賬號（JARBOOT_USER）和密碼（JARBOOT_DEFAULT_PWD）&lt;/li&gt; 
 &lt;li&gt;服務配置新增是否自動啓動配置項，配置自啓動時在 jarboot 啓動後會自動啓動該服務&lt;/li&gt; 
 &lt;li&gt;可通過-Dstart.wait.time=30000 指定最大的啓動等待時間&lt;/li&gt; 
 &lt;li&gt;client-cli 支持通過 token 登錄，可通過環境變量或-token 參數傳入&lt;/li&gt; 
 &lt;li&gt;新增 docker compose 集羣及單節點的配置文件示例&lt;/li&gt; 
 &lt;li&gt;新增軟件升級腳本，可通過腳本一鍵升級 jarboot，執行&lt;code&gt;bin/upgrade.sh&lt;/code&gt;或&lt;code&gt;bin/windows/upgrade.bat&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;新增軟件升級功能，可在界面上點擊升級，選擇安裝包或安裝包下載連接，可一鍵升級&lt;/li&gt; 
 &lt;li&gt;新增定時重啓服務配置，可使用 CRON 表達式配置重啓計劃&lt;/li&gt; 
 &lt;li&gt;.env 文件支持，可通過工作目錄下的.env 文件配置環境變量&lt;/li&gt; 
 &lt;li&gt;服務配置界面增加提示信息，鼠標移到提示信息圖標上可查看更多幫助信息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;bug 修復&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;打印日誌太多時異常掉線問題，The remote endpoint was in state [BINARY_FULL_WRITING] which is an invalid state for called method&lt;/li&gt; 
 &lt;li&gt;集羣模式下文件上傳到另一節點時，服務名為中文時上傳文件失敗問題&lt;/li&gt; 
 &lt;li&gt;修復使用 docker compose 集羣模式下節點認證失敗問題&lt;/li&gt; 
 &lt;li&gt;斷開重連時新增 cookie 校驗功能，校驗失敗則退出登錄&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://gitee.com/majz0908/jarboot/releases/3.3.0"&gt;https://gitee.com/majz0908/jarboot/releases/3.3.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367399</guid>
      <pubDate>Mon, 18 Aug 2025 07:55:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Databricks 將融資 10 億美元，估值達 1000 億</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 即將完成新一輪融資，估值達 1000 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一位知情人士獨家向 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F08%2F19%2Fdatabricks-ceo-says-fresh-1b-will-help-him-attack-a-new-ai-database-market%2F" target="_blank"&gt;TechCrunch&lt;/a&gt; 透露，新一輪融資規模約為 10 億美元，並獲得了大幅超額認購。據該消息人士透露，Databricks 之所以沒有進一步出售股權，是因為該公司在 1 月份以 620 億美元的估值完成了創紀錄的 100 億美元融資後，不再需要現金來維持運營。（OpenAI 隨後在 3 月份以 400 億美元的融資刷新了紀錄。）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;本輪融資由 Thrive 和 Databricks 的早期投資者之一 Insight Partners 共同領投。這兩家公司也領投了上一輪融資。自 2013 年成立以來，Databricks 已籌集約 200 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="284" src="https://oscimg.oschina.net/oscnet/up-2cd515f46a14f00391e4d39140096978f76.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據接近該公司的消息人士稱，Databricks 已在 2025 年為員工進行了兩輪 secondary rounds。這些次輪融資允許員工出售最多 40%、50% 或 60% 的股份，具體取決於其持股規模。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息人士稱，在這兩起案例中，第二輪融資的可用資金均未用完，這意味着員工持有的股票數量超過了他們本可以出售的股票數量。雖然 Databricks 顯然並不急於 IPO，但員工們最近已經有兩次套現的機會。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，Databricks 聯合創始人兼首席執行官 Ali Ghodsi 在接受採訪時表示，新一輪融資是為了開展兩個具體項目—— AI agent&amp;nbsp;數據庫及其 AI agent&amp;nbsp;平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;該公司將大力投資其 AI agent&amp;nbsp;數據庫，使其普遍可供所有客户使用。Ghodsi 表示：「數據庫市場的 TAM（總潛在市場）和收入規模達到 1050 億美元，在過去 40 年裏基本沒有受到影響」，巧妙地暗示了數據庫巨頭甲骨文幾十年來一直牢牢佔據着市場主導地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「這裏有一個有趣的統計數據，但沒人關注：一年前，我們在數據中看到，30% 的數據庫不是由人類創建的。這是第一次，它們是由 AI agent&amp;nbsp;創建的。而今年，這個數字是 80%」。他預測，這一數字將在一年內上升到 99% 的新數據庫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「現在有了一個新用户。這個用户不是人類，而是一個 AI agent。如果我們加倍努力讓這個用户角色取得成功，那麼這就是打破潛在市場（TAM）的契機。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;至於 Lakebase 與 Supabase 以及其他已經為代理構建基於 Postgres 的數據庫的區別，Ghodsi 表示關鍵在於「計算和存儲分離」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;通過將昂貴的計算與低成本的存儲分離開來，Databricks 可以讓用户以可承受的價格創建多個數據庫。「因為這些代理速度超快。它們可以快速啓動大量數據庫，速度比人類快得多，但你肯定不想因為這樣做而破產。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 將大力投資的第二個項目是&amp;nbsp;AI agent 平台 Agent Bricks，該平台也於 6 月上線。 「每個人都非常關注超級智能。但這並不是我們組織所需要的。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司需要的不是 AI 的普通數學天才或癌症治療科學家，而是能夠可靠地處理獨立日常任務的代理，例如員工入職培訓或回答有關人力資源福利的個性化問題。「我認為這實際上對全球 GDP 和各組織來説都是一個更大的機遇」。他相信，這種專注將為 Agent Bricks 帶來競爭優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他還籌集了額外的資金，以便 Databricks 能夠參與 AI 人才挖角大戰。「你知道，現在招聘 AI 人才的成本相當高。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367398</guid>
      <pubDate>Mon, 18 Aug 2025 07:49:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Reddit 季度收入創歷史新高，得益於人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;Reddit 依託其獨特的小眾社區文化和活躍的問答氛圍，正在人工智能（AI）領域實現盈利增長。該平台的&lt;span&gt;最大&lt;/span&gt;資產在於其用户生成的真實內容，這一優勢讓 Reddit 在與大型科技公司合作時，佔據了有利位置。公司通過 AI 授權，將平台上的子版塊內容整合入搜索引擎結果中，顯著提升了網站流量，併為廣告主提供了精準的目標受眾。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-4397aa3bf8abe3165b1b0cc3c7e0843e093.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近年來，Reddit 在財務業績方面屢次超越市場預期，用户每位收入（ARPU）增長速度遠遠快於其他社交媒體平台。這一趨勢推動了 Reddit 股票的上漲，令其市場估值達到新高。隨着投資者對 Reddit 未來增長的信心增強，該公司的股票在過去三個月內上漲了 123%，年內漲幅更是超過 344%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;分析師們對 Reddit 的盈利前景持續看好。數據顯示，Reddit2025 年的每股收益（EPS）預期從最初的 1.14 美元上調至 1.86 美元，增幅達 63%。此外，2026 年和 2027 年的 EPS 預期也有所上升，分別增長了 31% 和 14%。這表明市場對紅迪網的長遠發展充滿信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的快速增長得益於其在人工智能整合和數據授權方面的成功。最近發佈的 「Reddit 問答」 搜索引擎大大提高了用户互動和流量，帶動了廣告支出的顯著增加，用户每位收入年增長率達到 47%。這一成果超出了行業內對其逐步發展的預期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的競爭優勢在於其豐富的用户數據和問答文化，結合 AI 技術，使得每一條內容不僅具有高價值，還能與廣告信息無縫對接。這種獨特的 「防禦性」 網絡效應，讓其他社交平台難以複製 Reddit 的成功模式，幫助其在 AI 應用上走在了行業前列。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管 Reddit 目前的市盈率較高，投資者仍然看好其市場前景。分析師們對 Reddit 的股票保持普遍樂觀，雖然有少數持謹慎態度的觀點，但整體市場支持度依然強勁。只要 Reddit 能夠持續保持良好的增長趨勢，其股票溢價便是合理的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367390</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367390</guid>
      <pubDate>Mon, 18 Aug 2025 07:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
