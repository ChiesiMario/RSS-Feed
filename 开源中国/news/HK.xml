<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Fri, 12 Sep 2025 07:42:40 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>復旦大學漆遠：開源開放、價值交付、安全可信是 AI 發展趨勢</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 2025 Inclusion·外灘大會期間，復旦大學人工智能創新與產業研究院院長漆遠圍繞人工智能的發展趨勢，提出了三大核心觀點：開源開放、價值交付、安全可信，並結合具體案例深入闡述了 AI 技術如何真正落地並推動產業變革。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-15dede4281dee452aaa542e6e6d6d393f0f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;漆遠指出，2025 年人工智能領域最顯著的變化是「開源開放」已從理念變為現實，並正在重塑整個行業生態。他特別提到「DeepSeek」的出現，「把整個人工智能生成式 AI 的遊戲給改變了」，其開源架構和強大性能實現了「十倍的增長和變化提效」。&lt;/p&gt; 
&lt;p&gt;這一趨勢甚至影響了原本封閉的巨頭。漆遠提到：「OpenAI 時隔六年第一次再次開源」，其創始人 Sam Altman 坦言「我們有可能站在了歷史錯誤的一邊」。這標誌着整個行業對開源價值的重新認可。&lt;/p&gt; 
&lt;p&gt;漆遠認為，AI 正在從「賣工具」走向「賣結果」，從輔助工具演變為可交付價值的「Copilot」甚至「Auto Pilot」。這一轉變依賴於深入行業場景、結合專業知識的深度整合。&lt;/p&gt; 
&lt;p&gt;他以醫療領域的「煥新智能體」為例，該智能體已在中山醫院上線運行。不同於依賴更多算力或工程師的模型，其優勢在於「更深入的場景」和「更高質量的數據」。該系統實現了多模態數據（如 MRI、CT、心電圖、文本）的綜合解讀，並能自動識別心電圖中的異常區域，輔助醫生進行規範診療。&lt;/p&gt; 
&lt;p&gt;在金融領域，漆遠團隊在恒生指數創新挑戰賽中奪得第一，其核心技術是將大語言模型與符號計算結合，構建「神經符號系統」，以控制幻覺、確保推理的準確性。他強調：「我們解決的問題是指數生成的廣度、深度、速度和顆粒度。」&lt;/p&gt; 
&lt;p&gt;在強調技術進步的同時，漆遠反覆強調「安全可信」是 AI 發展的底線。他指出，大模型存在「造假」「幻覺」等問題，醫療領域模型的準確率甚至只有 55%，這令人「肯定是有擔心的」。&lt;/p&gt; 
&lt;p&gt;他列舉了多個風險案例：MIT 導師發現博士論文由 AI 生成；WPP 集團 CEO 遭遇深度偽造詐騙。這些事件凸顯了「真假信息難辨」的嚴峻挑戰。&lt;/p&gt; 
&lt;p&gt;為此，漆遠和團隊提出了多項關鍵技術路徑：包括可解釋 AI：在金融、醫療等關鍵決策領域，必須能解釋模型的每一個決定。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;檢索增強（RAG）與神經符號系統：結合規則與語義理解，提升推理可靠性。&lt;/li&gt; 
 &lt;li&gt;高質量數據治理：高質量的數據才能保證模型的質量。&lt;/li&gt; 
 &lt;li&gt;博弈對抗技術：借鑑強化學習與圍棋對弈的思路，提升模型在複雜環境中的魯棒性。&lt;/li&gt; 
 &lt;li&gt;自知之明：讓模型知道自己什麼時候是不知道，這是實現可信 AI 的關鍵一步。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;漆遠總結，開源開放讓技術更加普惠，讓更多機構能夠使用 AI；深耕場景才能釋放產業價值；而安全可信則是 AI 可持續發展的根本保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371795</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371795</guid>
      <pubDate>Fri, 12 Sep 2025 07:32:20 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻集團發佈 Tbox 超級智能體</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 11 日，螞蟻百寶箱智能體開發平台在 2025Inclusion·外灘大會上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEB3584t6IxMA9w2gRq8IXg" target="_blank"&gt;發佈&lt;/a&gt;新產品 Tbox 超級智能體（www.tbox.cn）。Tbox 採用「動態編排引擎」，可根據任務複雜度實時調整智能體數量與協作路徑，較傳統串行流程更具有靈活性，比如在 PPT 製作場景，Tbox 可根據需要，動態選擇是否引入數據分析師和圖表可視化專家，來高效完成任務。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/151914_9P1e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，全新的 Tbox 通過多智能體協同架構，可以讓平台上多個智能體形成工作小組，共同完成用户指定的任務，交付成果。&lt;/p&gt; 
&lt;p&gt;用户僅需一句話指令，Tbox 即可聯動多個智能體協同完成從內容構建、視覺設計到格式輸出的全流程，實現「輸入意圖，輸出成果」。&lt;/p&gt; 
&lt;p&gt;例如，用户上傳大學生旅遊市場調研數據，僅需輸入指令「生成墨綠色+白灰主色調、圖表清晰的課程 PPT」，Tbox 便在 5 分鐘內自動完成專業教學級 PPT，涵蓋數據解析、視覺設計與內容組織，大大減輕用户數據可視化、理解內容的時間精力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/152154_E8Qz_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，新版本繼續強化「無代碼」體驗：用户描述想法，即可獲得可直接發佈的 PPT、網頁、播客、文檔等多種格式成果。與此同時，Tbox 即將開放「智能體市場」，用户可將自己搭建的行業專家 Agent 上架，供全球用户調用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371791</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371791</guid>
      <pubDate>Fri, 12 Sep 2025 07:20:20 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>我國科研人員開發可用於癌症免疫治療的「納米標記機器人」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在癌症的免疫治療中，體內免疫細胞需接受足夠強和足夠多的信號，才能對癌細胞發起攻擊。但狡猾的癌細胞善於偽裝，表面的天然信號非常稀疏。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;如何精準識別癌細胞？中國科學院分子細胞科學卓越創新中心韓碩研究團隊將化學生物學研究中的鄰近標記技術應用於疾病治療，通過構建一種深紅光或超聲波響應的工程化納米酶，成功開發出可對癌細胞精準識別的「納米標記機器人」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="315" src="https://oscimg.oschina.net/oscnet/up-5761d1a480b313a45c25642d8ef2f336539.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;「納米標記機器人」工作原理示意圖。（中國科學院分子細胞科學卓越創新中心供圖）&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;國際學術期刊《自然》於 9 月 10 日在線發表了相關研究論文。中國科學院分子細胞科學卓越創新中心韓碩研究員和復旦大學附屬中山醫院高強教授為該論文共同通訊作者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;據韓碩介紹，鄰近標記技術是一種強大的「分子地圖」繪製技術，能在細胞的特定位置對周邊環境進行催化標記。利用這一技術原理開發的「納米標記機器人」，可搭載識別癌細胞的抗體或配體，通過血液循環富集在癌細胞的表面，再通過深紅光或超聲波下達指令，就可以給癌細胞打上清晰的標記，成為「人造靶標」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;針對這些「人造靶標」，研究人員在實驗中為小鼠注射了一種特製的 BiTE 分子，這種分子一方面能增強「人造靶標」標記信號，另一方面還可以激活並召集體內免疫 T 細胞前來參加抗癌的戰鬥。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「這種高密度的標記，不僅是簡單的指引，更像是吹響戰鬥的衝鋒號，促使 T 細胞表面的相關識別受體高效聚集，觸發其最強攻擊模式，對深紅光或超聲波引導的位置，實施精準打擊。與此同時，還能激活全身免疫系統，形成長期記憶，如同在體內接種了‘腫瘤疫苗’。」韓碩説。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，該研究在實驗小鼠腫瘤模型和體外臨牀腫瘤樣本中均取得良好療效，有望為開發更智能、更高效的下一代免疫療法開闢全新的道路。該工作獲國家重點研發計劃、中國科學院戰略性先導科技專項、國家自然科學基金、上海市科技重大專項以及國家科技重大專項、中國博士後科學基金資助。（新華社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371784</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371784</guid>
      <pubDate>Fri, 12 Sep 2025 07:06:20 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度發佈新一代文字識別解決方案：PP-OCRv5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;百度發佈了 OCR 模型 PP-OCRv5，旨在解決通用視覺語言模型（VLMs）在 OCR 領域的侷限性。PP-OCRv5 作為 PP-OCR 新一代文字識別解決方案，該方案聚焦於多場景、多文字類型的文字識別。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fae459803b1010544dc4f590411a10e325b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在文字類型方面，PP-OCRv5 支持簡體中文、中文拼音、繁體中文、英文、日文 5 大主流文字類型，在場景方面，PP-OCRv5 升級了中英複雜手寫體、豎排文本、生僻字等多種挑戰性場景的識別能力。在內部多場景複雜評估集上，PP-OCRv5 較 PP-OCRv4 端到端提升 13 個百分點。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a51b994a63239798865cfe4ba22544d02b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PP-OCRv5 採用模塊化兩階段流程，專為高速、精確的文本檢測和識別設計。該模型更小、更高效，尤其適合資源受限硬件。&lt;/p&gt; 
&lt;p&gt;PP-OCRv5 模型架構為兩階段流水線，包含圖像預處理、文本檢測、文本行方向分類和文本識別四個核心組件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8b930bbeca01f5c46796ca71f7e98ea2529.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型已在 Hugging Face 上線，用户可通過在線 Demo 測試其在處理多語言文檔、手寫文本和低質量掃描件時的實時精確結果。開發者可從 Hugging Face Models 下載模型，並通過安裝 PaddlePaddle 和 PaddleOCR 庫在本地部署使用。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/blog/baidu/ppocrv5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371783/baidu-ppocrv5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371783/baidu-ppocrv5</guid>
      <pubDate>Fri, 12 Sep 2025 07:01:20 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動聯合清華大學開源統一多模態框架：HuMo</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字節跳動智能創作團隊聯合清華大學共同開源了名為&amp;nbsp;HuMo&amp;nbsp;的統一 HCVG（Human-Centric Video Generation）框架。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/143717_iLPP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;論文地址: https://arxiv.org/abs/2509.08519&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Human-Centric Video Generation，即人體視頻生成框架，支持文本、圖像、音頻三種模態協同驅動。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/143706_7e6J_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;HuMo（意指 Human-Modal）通過構建高質量數據集和設計創新的漸進式訓練範式，成功實現了對多模態輸入的協同控制，在各項子任務上超越了現有的專業化方法，可輸出 480P 與 720P 分辨率、最長 97 幀、25FPS 的精細可控人物視頻。&lt;/p&gt; 
&lt;p&gt;HuMo 框架的核心在於其創新的數據處理流程、漸進式多模態訓練範式以及靈活的推理策略。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/144015_bCsa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;項目地址:&lt;br&gt; https://phantom-video.github.io/HuMo&lt;br&gt; https://github.com/phantom-video/humo&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371781</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371781</guid>
      <pubDate>Fri, 12 Sep 2025 06:42:20 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌在 AI 生成的搜索答案中植入廣告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthe-decoder.com%2Fgoogle-brings-ads-to-ai-generated-answers-worldwide%2F" target="_blank"&gt;據報道&lt;/a&gt;，谷歌在全球範圍內為 AI 生成的搜索答案嵌入廣告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/142405_Yvap_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報道稱，當用户以對話／自然語言（conversational）方式進行搜索（例如：「如何解決低水壓問題？」），谷歌搜索會在 AI 生成的答案旁邊直接展示與該問題相關的廣告，比如修理或水管工服務。&lt;/p&gt; 
&lt;p&gt;這項功能在名為 「AI Mode」 的模式裏可見，並通過新推出的 AI Max 工具支持廣告主在多個廣告產品中（Google Ads, Ads Editor, Search Ads 360, Ads API）一鍵設置這種類型的廣告活動，目前正在全球範圍內以 beta 測試形式推出。&lt;/p&gt; 
&lt;p&gt;谷歌認為，越來越多用户在搜索時採用寬泛或對話式的語言，而這種方式比起傳統關鍵詞列表，更適合由 AI 生成直接的答案。比如，用户在問 「怎樣解決水壓低」 而不是輸入一串關鍵詞。在這種趨勢下，把廣告整合進 AI 答案被視為一種合理且「對用户搜索習慣更貼近」的廣告展示方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371773</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371773</guid>
      <pubDate>Thu, 11 Sep 2025 06:28:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>國家發改委：加大人工智能領域金融和財政支持力度</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;國家發展和改革委員會在人民日報刊文指出，完善人工智能應用的創新發展環境。強化政府部門和國有企業示範引領作用，完善應用試錯容錯管理制度，推動關鍵重點場景有序開放。加大人工智能領域金融和財政支持力度，完善風險分擔和投資退出機制，進一步激發人工智能投融資市場活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;以下為原文：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深入實施「人工智能+」行動，為高質量發展提供強大動能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;國家發展和改革委員會&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;習近平總書記強調：「人工智能作為引領新一輪科技革命和產業變革的戰略性技術，深刻改變人類生產生活方式。」黨的二十屆三中全會明確將人工智能作為戰略性產業，推動實現各行業的數智化轉型，為經濟高質量發展注入新動力。國務院日前印發《關於深入實施「人工智能+」行動的意見》，從國家層面對各行業各領域人工智能應用發展提出指導意見，明確時間表、路線圖。我們要深入貫徹落實黨中央、國務院決策部署，大力推進人工智能商業化規模化應用，加快人工智能與經濟社會各領域廣泛深度融合，為賦能高質量發展、更好服務社會主義現代化建設貢獻力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深刻領會深入實施「人工智能+」行動的重大意義&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;當前，人工智能技術加速迭代演進，正在對經濟發展、社會進步、國際政治經濟格局等方面產生重大而深遠的影響。深入實施「人工智能+」行動，推動人工智能與經濟社會深度融合，既是我們當前面臨的緊迫任務，更是關乎長遠發展的戰略命題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入實施「人工智能+」行動，是搶抓新一輪科技革命和產業變革機遇的戰略選擇。習近平總書記強調：「加快發展新一代人工智能是事關我國能否抓住新一輪科技革命和產業變革機遇的戰略問題。」歷史發展表明，每一次科技革命都帶來生產力的指數級躍升，推動社會形態深刻演進。人工智能作為繼蒸汽機、電力、互聯網之後的又一劃時代的變革性技術，正以前所未有的速度、廣度和深度，驅動經濟社會發展加快邁向智能化新階段。實施「人工智能+」行動，體現了黨中央、國務院對世界科技發展大勢的深刻洞見和前瞻擘畫，是贏得全球科技競爭主動權的重要抓手。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入實施「人工智能+」行動，是培育發展新質生產力的內在要求。習近平總書記強調：「科技創新是發展新質生產力的核心要素。」作為新一輪科技革命的重要驅動力量，當前人工智能的快速發展與我國培育發展新質生產力、推動高質量發展形成歷史性交匯。人工智能具有溢出帶動性很強的「頭雁」效應，通過對資本、勞動、技術、數據等要素創新性配置，顯著提升全要素生產率，促進生產力革命性躍升。實施「人工智能+」行動，積極推動人工智能和實體經濟深度融合，有助於推動產業向價值鏈高端邁進，促進增長方式從要素驅動轉向創新驅動，不斷催生新技術、新業態、新模式，形成新質生產力發展的核心引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入實施「人工智能+」行動，是滿足人民美好生活需要的重要途徑。習近平總書記強調：「要加強人工智能同保障和改善民生的結合，從保障和改善民生、為人民創造美好生活的需要出發，推動人工智能在人們日常工作、學習、生活中的深度運用，創造更加智能的工作方式和生活方式。」實施「人工智能+」行動，要抓住民生領域突出矛盾和難點，加強人工智能在醫療、教育、交通、助殘養老等關係羣眾切身利益的重點領域深度應用，促進全體人民共享人工智能發展成果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入實施「人工智能+」行動，是助力全球平等參與智能化發展進程的積極舉措。習近平總書記強調：「人工智能可以是造福人類的國際公共產品。」當前，人工智能發展面臨全球治理機制碎片化、陣營化等挑戰，各國智能化發展差距不斷加大，亟需完善全球治理體系，攜手共贏發展。我國深入實施「人工智能+」行動，打造具有世界影響力的人工智能生態，深化人工智能領域高水平開放，推動人工智能技術開源可及，有助於推動形成具有廣泛共識的全球治理框架和標準規範，助力各國平等參與全球智能化發展進程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;全面把握深入實施「人工智能+」行動的優勢條件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在黨中央、國務院的堅強領導下，我國人工智能快速發展，綜合實力實現整體性、系統性躍升，發展優勢進一步凸顯，同時數據資源豐富、產業體系完備、應用場景多、市場空間大、人才資源富集，為深入實施「人工智能+」行動創造有利條件、奠定良好基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;豐富的數據資源提供了關鍵要素支撐。數據作為人工智能模型訓練和迭代的關鍵「原料」，其規模、質量、多樣性和時效性直接決定人工智能的性能上限。當前，隨着大模型技術發展，對高質量語料數據的需求正從通用化向專業化、場景化、多模態縱深拓展。我國依託網絡化、數字化建設基礎，積累起規模超大、類型豐富、動態鮮活的數據資源。2024 年，全國數據生產總量達 41.06 澤字節（ZB），佔全球數據總量的 26.67%，用於人工智能開發、訓練和推理的數據量同比增長 40.95%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;完備的產業體系提供了強大物質技術保障。我國作為全球唯一擁有聯合國產業分類中全部工業門類的國家，具備 41 個大類、207 箇中類、666 個小類的工業體系，200 多種主要工業品產量全球第一。這一鏈條完整、配套齊全、要素完備的產業生態，為人工智能技術從研發驗證、產品設計到製造交付提供了全鏈條支撐，將極大促進技術創新迅速轉化為產品與服務，形成推動人工智能實現規模化落地應用的獨特優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;豐富的應用場景提供了廣闊的發展空間。人工智能的生命力在於應用，真實場景中複雜的約束條件、多樣化需求等，持續驅動人工智能技術演進和性能提升。我國具備類別齊全、層次多樣的應用生態，覆蓋智能製造、智慧醫療、數字金融、智能交通、智慧教育等關鍵領域，為人工智能尤其是複雜推理、動態決策和自適應學習等高級能力的錘鍊提供了最佳「試驗場」。目前，我國已發佈超 1500 個行業模型，覆蓋 50 個重點行業領域、700 餘個場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;巨大的市場空間提供了內生髮展動力。我國擁有 14 億多人口、約 2 億經營主體和超過 4 億的中等收入羣體，連續 10 餘年穩居全球第二大商品消費市場和最大網絡零售市場。龐大的人口基數、持續升級的消費能力以及強大的企業創新活力，有利於攤薄研發成本、加速技術迭代升級、促進應用標準化，為推動新一代人工智能終端、智能體等人工智能應用提供了廣闊市場空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;超大規模的人才資源提供了信心底氣。人工智能的理論創新、算法突破和落地應用均依賴多層次、跨學科人才。我國已建成世界規模最大且有質量的教育體系，人才資源總量、科技人力資源總量、研發人員總量均居世界第一，軟件開發者近千萬人，在數學、計算機、工程等多學科領域積累了雄厚人才基礎，為人工智能持續創新和規模化應用提供了強大人才保障和智力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;奮力開拓新時代「人工智能+」發展新局面&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入實施「人工智能+」是一項長期、複雜的系統工程。國家發展改革委將按照黨中央、國務院決策部署，緊扣「人工智能+」行動總體安排，充分發揮統籌協調作用，加強部門協同、央地聯動和社會參與，廣泛凝聚各方力量，推動形成工作合力，紮實推進各項工作取得實效。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;構建創新活躍的智能經濟。&lt;/strong&gt;加快推動人工智能驅動的新型科研範式變革，加速「從 0 到 1」重大科學發現進程、「從 1 到 N」技術落地和迭代突破。深入推動產業全要素智能化發展，加快工業、農業、服務業智能化轉型升級，發展智能原生技術、產品和服務體系，催生智能原生新業態。加強智能消費基礎設施建設，推動智能終端「萬物智聯」，讓人工智能走進「千家萬户」「千商萬店」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;打造更有温度的智能社會。&lt;/strong&gt;優先在就業、健康、養老、教育、文化等民生領域降低人工智能技術應用門檻，加快健康助手、智能學伴等人工智能產品與服務的普惠化應用。有序推進人工智能在社會治理、安全治理、生態治理等中的應用，形成高效多元的治理格局。把人工智能作為造福人類的國際公共產品，推動人工智能普惠共享，助力各國平等參與智能化進程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;強化人工智能發展的要素支撐。&lt;/strong&gt;加快高質量語料庫和行業數據集建設，完善數據產權和版權、收益分配等制度，加強數據供給創新。統籌佈局智算基礎設施，充分發揮「東數西算」國家樞紐作用，強化數、算、電、網等資源協同配置。大力推進原始創新與開源生態培育，支持多路徑技術探索和基礎架構創新，提升模型基礎能力。加強人工智能人才引育，超常規構建領軍人才培養新模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;完善人工智能應用的創新發展環境。&lt;/strong&gt;強化政府部門和國有企業示範引領作用，完善應用試錯容錯管理制度，推動關鍵重點場景有序開放。&lt;strong&gt;加大人工智能領域金融和財政支持力度，&lt;/strong&gt;完善風險分擔和投資退出機制，進一步激發人工智能投融資市場活力。佈局建設一批國家人工智能應用中試基地，搭建行業應用共性平台，降低應用創新門檻，促進創新成果高效轉化。推動大中小企業融通發展，加快人工智能產業鏈上下游協同發展，構建資源共享、能力互補、良性互動的人工智能產業生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;築牢人工智能應用的安全防線。&lt;/strong&gt;大力支持開展人工智能技能培訓，激發人工智能創新創業和再就業活力，引導創新資源向創造就業潛力大的方向傾斜，加強人工智能應用就業風險評估，減少對就業的衝擊。推動模型算法、數據資源、基礎設施、應用系統等安全能力建設，建立健全人工智能技術監測、風險預警、應急響應體系，加快形成動態敏捷、多元協同的人工智能治理格局，推動人工智能應用合規、透明、可信賴。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371764</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371764</guid>
      <pubDate>Thu, 11 Sep 2025 05:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>雲基座技術是大廠專有，那小廠和私有云的出路在哪裏？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1&gt;雲基座技術是大廠專有，那小廠和私有云的出路在哪裏？&lt;/h1&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//125ac9150a041a8b6d9f9a6e73be1c67.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;專欄導語&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 時代數據洪流來襲，晨章數據以創新 「數據基層」 架構破局！旗下分佈式數據庫系列產品，實現計算、內存、日誌、存儲四元解耦，0.1ms 響應跨模態需求，更全面開源賦能生態。&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;本專欄將邀請五位嘉賓，從不同視角深探晨章數據的領先之道&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;解析雲原生彈性架構優勢，探索新硬件紅利，看 AI 原生數據庫如何突賦能 AI 創業者，錨定市場痛點破局，聽創始人拆解技術創業邏輯，乾貨持續輸出，敬請關注！&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;本篇特邀專家——劉華陽，深度解析雲數據庫基座廠商的探索路徑，並系統探討中小廠商與私有云的未來發展可能性，為行業提供兼具實踐參考與前瞻視野的深度洞見。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//5fad3ad9bb2c47a5a56fe0d40aefa49f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;劉華陽&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;一個與時俱進的 DBA 架構師，從傳統商業到最新開源數據庫，再到分佈式，雲原生數據庫產品，一路體驗各種不同數據庫給企業，給數據庫廠商、數據庫使用人員、數據庫運維人員帶來不同的視角，願意將這些感受表達出來的小角色。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;雲數據庫是未來&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;數據庫技術的進化都與需求的產生和變化有關，傳統數據庫廠商是不會想到雲數據庫廠商逐漸可以玩出他們玩不出的花樣，同時也想不到 2025 年雲數據庫成為整體國產數據庫佔比完全碾壓線下的數據庫廠商，可謂誰想活到後面，誰就要有數據庫的雲產品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//d0fb8647f13798ba28d503ae219d35c0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;非雲廠商的市場預測&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;可是這裏有一個問題，雲數據庫的理念和傳統數據庫設計的理念完全不同，人家的玩法是 4 維科技，與數據庫傳統廠商的 2 維科技相比，可操作性更大。所以擺在傳統數據庫廠商的角度，怎麼能快速的上雲數據庫這條賽道是後續需要考慮，且要操作的。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;從一個數據庫從業者的角度考慮，雲底座是一個關鍵點。傳統數據庫設計的理念是單機的概念，思想維度都是圍繞單機性能最大化而來的，雲數據庫根本不是這麼考慮和解決問題的，所以雲數據庫不是把線下的數據庫弄到雲上就是雲數據庫了,而是依據雲上硬件和用户的特點來重新設計底層架構，而底層的基座則是雲數據庫的難點和重點。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;眾多的小型雲廠商，私有云廠商，甚至是大型客户，需要的是雲基座，一種基於新的雲硬件概念而來的雲數據庫產品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;所以今天引出我們本次的&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;一種新的基於雲的通用性架構，Data Substrate&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;strong&gt;&lt;span&gt;，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;後面將統稱 Data Substrate 為 DS。這樣的基於雲數據庫的基座的產品他有什麼技術特點來應對各大雲廠商的成熟的雲數據庫的架構也是我們此次想談到的問題。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//2c12d7837f3a38a62a12e2ac8dcef583.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;雲架構是不是大型雲廠商的專屬？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;回答不是，大型企業和私有云廠商需要一個通用性的架構，這裏我們強調的是通用性，靈活性等特點。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;那麼 DS 通用性雲基座技術有什麼技術特點：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;1 本地部署的能力：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;在沒有云存儲服務的本地部署中，DS 可以通過 Raft 協議實現數據的複製，提供與雲類似的容錯和基本的彈性功能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;2 中立性：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;雲廠商本身的技術都具有技術壁壘，DS 技術本身是通用的，可以部署在多個雲平台提供統一的訪問接口，實現混合雲的技術能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;3 模塊化存儲能力：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;模塊化存儲的能力本身體現的是 DS 技術的靈活性，他允許多種存儲系統融入到雲基座中，比如他可以利用對象存儲 S3 作為主存，同時通過 EBS 存儲日誌，而將本地的 NVMe 作為本地的數據緩存。這是一個非常「雲」的模式的打法，從性能和成本進行兼顧的設計模式。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//168306c1959ffee74a515ac851849a1f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;DS 技術本身的核心&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;或者説優勢是什麼？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;DS 技術的核心點在於解耦，DS 技術將計算，內存，日誌，和存儲資源進行獨立解耦，提供了與雲上雲原生數據庫本身對系統資源設計類似的方式進行資源的調用和使用。通過這樣的技術來建立，按需獨立伸縮的能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;計算 (CPU)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;可根據查詢工作負載的實時變化動態擴展或縮減計算引擎（如 TxServer 的 CPU 核心數），從而顯著提升吞吐量並降低延遲。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;內存 (緩存)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;內存節點（即分佈式內存表 TxMap）的規模可以獨立於總數據量進行伸縮，與熱數據的大小或預算成正比。這使得數據庫能夠根據實際需求快速調整緩存容量，應對讀密集型工作負載的峯值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;日誌 (寫入吞吐量與持久化延遲)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;日誌節點數量可以獨立於緩存大小和總數據量進行水平擴展，與在線寫流量成正比。通過增加獨立的日誌工作者和低規格日誌節點，能夠顯著提升寫入吞吐量並降低寫入延遲，消除寫密集型工作負載的日誌瓶頸。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;存儲 (數據容量與緩存未命中性能)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;存儲資源與計算、內存和日誌獨立擴展，實現大型數據集的成本效益管理和高效的緩存未命中處理。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;這種四元解耦（計算、內存、日誌和存儲的獨立擴展）是 Data Substrate 的獨特優勢，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;使系統能夠根據給定工作負載精確分配所需資源，避免過度配置，從而提高成本效益和運營靈活性，而這個概念也是先進的雲企業一直倡導和積極實現的，最終將實現數據庫的使用如自來水一樣，打開就付費，關閉就免費。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;DS 技術已經可以達到這個技術能力，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;支持 Scale to Zero（縮容到零）：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;當數據庫長時間沒有流量時，系統能夠自動釋放所有計算資源，用户僅需支付成本極低的對象存儲費用，實現「沒有使用就沒有費用」。當工作負載返回時，系統可在幾秒內迅速恢復服務。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//ad68e19fe3319cc53b6c609d2b8dc506.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;DS 技術的底層是分佈式嗎？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;是新瓶裝舊酒嗎？怎麼保證性能？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//9eab34a53e96afbdd8aeec5186394283.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Data Substrate&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;首先 DS 技術針對 CPU,內存，以及存儲進行解耦，分佈式數據庫中對於性能有影響的部分是兩階段提交，DS 架構下的數據庫不會有兩階段提交的場景，整體的操作均在內存中完成。在這樣的設計下，DS 可以做到如下的能力：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;1、數據庫在工作負載繁重的情況下，也能&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;支持亞毫秒級的讀取延遲。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;2 、支持&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒級自動故障轉移和零數據丟失&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，並通過熱備份模式進一步降低故障恢復時間&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;3、通過 Pod 池化，可以實現&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒級啓動&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，快速響應用户請求，確保動態調整資源時用户無感知&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;4、內存節點可實現&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒級彈性擴容&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，擴展速度提升百倍&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;5、Scale 時&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;不&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;會有數據的遷移或移動&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，新增節點馬上提供服務&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;6、每個 CPU 核綁定一個線程的架構（thread-per-core）充分利用異步 I/O （io_uring）能力，最小化上下文切換，減少鎖競爭，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;即便在重負載下也能維持高吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;最終 DS 技術並不是一個單純的數據庫技術&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;DS 技術是一項高效的通用的雲數據庫基座，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;在此以上可以搭建，Redis、MySQL、MongoDB、甚至基於多模態的數據庫產品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;寫到最後，這項技術的擁有者是一家正在穩定創業，通過先進的雲基座發展起來的數據庫廠商，如果你覺得這個技術很有意思，想試用，在&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;阿里雲&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;AWS 的雲市場&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;中均有他們的產品可以使用（可商用）。除了 Redis 兼容的高性能 KV 之外，他們還推出了 Mongo 兼容的文檔數據庫產品，後續還將推出兼容更多模態的數據庫產品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//bc1a7c1e16f6f63d1524cc1ed06052c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;span&gt;AWS 市場，晨章數據產品&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="text-align:center"&gt;&lt;img alt="圖片" src="https://oscimg.oschina.net/oscnet//0abf051419098edfd9e39f094d6148c0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;span&gt;阿里雲 &amp;nbsp;晨章數據產品&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371759</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371759</guid>
      <pubDate>Thu, 11 Sep 2025 04:55:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>AI 搜索創企 Perplexity 融資 2 億美元，估值 200 億美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F10%2Fperplexity-reportedly-raised-200m-at-20b-valuation%2F" target="_blank"&gt;根據 TechCrunch 的報道&lt;/a&gt;，人工智能搜索引擎公司 Perplexity 近期完成了 2 億美元新一輪融資，估值達 200 億美元，距離其 7 月以 180 億美元估值完成的 1 億美元融資僅隔兩個月。&lt;/p&gt; 
&lt;p&gt;目前尚未披露本輪融資的主導投資方。今年 7 月，《彭博社》曾報道，Perplexity 剛完成對此前一輪 5 億美元融資的擴展，當時估值為 140 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ee680c0e530a41a664a440faf13a1133621.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根據 PitchBook 數據，自三年前成立以來，Perplexity 的融資總額已達 15 億美元。&lt;/p&gt; 
&lt;p&gt;消息人士透露，Perplexity 的年經常性收入（ARR）正逼近 2 億美元。公司公關負責人上月對 Business Insider 表示，Perplexity 的年收入已超過 1.5 億美元。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1abe17d787b691e146a089eccf4834806a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;截至發稿，Perplexity 未對置評請求作出回應。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371752</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371752</guid>
      <pubDate>Thu, 11 Sep 2025 04:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>trust-manager 正在遷移到 ClusterBundle</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;trust-manager&amp;nbsp;方面&lt;span style="background-color:#ffffff; color:#000000"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcert-manager.io%2Fannouncements%2F2025%2F09%2F05%2Ftrust-manager-clusterbundle-future%2F" target="_blank"&gt;分享&lt;/a&gt;了一個關於&lt;/span&gt;項目&lt;span style="background-color:#ffffff; color:#000000"&gt;即將發生的重要變化的詳細信息。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;trust-manager 即將把當前的 Bundle 資源功能，遷移到一個新的 ClusterBundle 資源。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;你需要將 Bundle 的 YAML 替換成 ClusterBundle YAML，規格類似但有所不同。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;未來，Bundle 可能會以命名空間範圍的 CRD 形式重新出現。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;當前狀態&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;trust-manager 目前使用 Bundle 資源，作為集羣管理員在集羣中分發證書頒發機構（CA）證書的機制。這個 CRD 是集羣級別的，從集羣中心命名空間中獲取數據源，然後同步到其他命名空間的目標。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&amp;gt; kubectl api-resources&lt;/span&gt;
&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;bundles &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; trust.cert-manager.io/v1alpha1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Bundle&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;如果你熟悉其姊妹項目 cert-manager，可能會預期看到 ClusterBundle，因為 Issuer 是命名空間範圍的，而 ClusterIssuer 是集羣範圍的。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;clusterissuers &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ciss &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;cert-manager.io/v1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ClusterIssuer&lt;/span&gt;
&lt;span&gt;issuers &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; iss &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cert-manager.io/v1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Issuer&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;trust-manager 目前沒有遵循以 Cluster 前綴表示集羣級別 CRD 的模式。對於新用户來説可能有些困惑，或者感覺有些不一致。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;變化內容&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;簡單來説，trust-manager 默認將切換為使用 ClusterBundle。這更準確地反映了當前 Bundle 資源的範圍。同時這也更貼近 Kubernetes 原生的 ClusterTrustBundle 資源，它也是集羣級別資源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;對 trust-manager 用户的影響：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;棄用並最終移除 Bundle 資源及其 API 組 trust.cert-manager.io/v1alpha1。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;在新的 API 組 trust-manager.io/v1alpha2 中創建 ClusterBundle，作為新的默認資源。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;安裝 trust-manager 後，查看 api-resources 會看到類似：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&amp;gt; kubectl api-resources&lt;/span&gt;
&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;clusterbundles &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;trust-manager.io/v1alpha2 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ClusterBundle&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;最簡示例&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;對於簡單場景，比如只使用公共 CA，改動很小。如果你當前有：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;apiVersion:&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;trust.cert-manager.io/v1alpha1&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;kind:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;Bundle&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;name:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;public-ca-certs&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;sources:&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#990073"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;useDefaultCAs:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;target:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;configMap:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;key:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ca-certificates.crt&lt;/span&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;現在改成：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;apiVersion:&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;trust-manager.io/v1alpha2&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;kind:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ClusterBundle&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;name:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;public-ca-certs&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;includeDefaultCAs:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;target:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;configMap:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;data:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#990073"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;key:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ca-certificates.crt&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;namespaceSelector:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;matchLabels:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;{}&lt;/span&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;注意，發佈前規格可能會有變動！如果有任何調整建議，可聯繫 cert-manager 維護者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;如果想提前瞭解資源規格，可以在測試或開發集羣中應用 CRD，並用 kubectl explain 查看配置選項。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/cert-manager/trust-manager/refs/heads/main/deploy/crds/trust-manager.io_clusterbundles.yaml&lt;/span&gt;
&lt;span&gt;kubectl explain clusterbundles.trust-manager.io.spec&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;別忘了清理測試資源，因為此資源尚未正式發佈&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;kubectl delete -f https://raw.githubusercontent.com/cert-manager/trust-manager/refs/heads/main/deploy/crds/trust-manager.io_clusterbundles.yaml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;API 變更&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;主要有兩個關鍵點：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;API 組由 trust.cert-manager.io 變更為 trust-manager.io。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;API 版本由 v1alpha1 升級為 v1alpha2。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;API 組的變更，一方面縮短了整體 URL，另一方面體現了 trust-manager 正在成為一個完全獨立於 cert-manager 的項目。雖然兩個項目都由同一組優秀維護者負責，但官方認為項目應能獨立存在，減少集羣中的工具依賴。實現獨立性的關鍵之一是移除 webhook 依賴，不再需要證書來保護 webhook 通信。Kubernetes 在 Server Side Apply (SSA) 和 Common Expression Language (CEL) 的進步，讓資源驗證能更方便地由 Kubernetes 組件完成，無需依賴 webhook 服務。目前還沒達到完全獨立的狀態，未來會有專門討論此話題的文章。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;API 版本的變更也很重要：資源仍處於 alpha 階段。這意味着規格依然可能發生不兼容的變動。但實際上，維護者會非常謹慎對待規格更改&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;對你的影響&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;資源遷移將由一個新的轉換控制器輔助完成。注意，這不是 webhook 轉換，因為 webhook 轉換隻能在同一 API 組的不同版本間轉換。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;管理員需要做兩件事：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;隨着新版本發佈，升級 trust-manager。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;更新部署清單，將 Bundle 資源替換為新的 ClusterBundle 規範。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;官方會在新資源發佈時提供詳細的操作指南。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;時間表&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;官方目前還不能給出具體時間點，但可以大致説明：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;版本 N：發佈新的 ClusterBundle CRD，並棄用 Bundle。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;版本 N+X：移除 Bundle 資源。&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;未來展望&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;這只是目前的設想，trust-manager 在 ClusterBundle 之後可能會包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;新的 trust-manager.io/v1alpha2 Bundle 資源迴歸，命名空間範圍的。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;為 ClusterBundle 增加更多目標資源類型。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371750</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371750</guid>
      <pubDate>Thu, 11 Sep 2025 03:53:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 面向 Pro 與 Plus 用户推出「開發者模式」測試版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 宣佈為 ChatGPT 推出「開發者模式」（處於 Beta 測試階段），旨在提升其在專業領域的應用能力。目前，該功能僅面向 ChatGPT Plus 和 Pro 訂閲用户開放，且暫時僅支持網頁端使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-84850ffcded4cb6d4d3a76793081cc84257.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用文檔：&lt;em&gt;https://platform.openai.com/docs/guides/developer-mode&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;用户需在設置中的 「Connectors」 選項內手動啓用開發者模式。啓用後，可通過配置 MCP（Model Context Protocol，模型上下文協議）客户端，藉助 SSE（Server - Sent Events）或流式 HTTP 協議，讓 ChatGPT 直接訪問外部系統，實現如更新 CRM 記錄、在代碼託管平台創建拉取請求等操作，深度融入實際開發流程。&lt;/p&gt; 
&lt;p&gt;OpenAI 強調，該模式具備高權限特性，系統會在每次工具調用時完整展示 JSON 格式的輸入與輸出內容，對涉及數據修改的行為，默認要求人工確認（工具標註為 「只讀」 除外）。用户可選擇在當前對話會話中記住授權狀態，但刷新頁面或開啓新對話後權限將重置 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371748/chatgpt-developer-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371748/chatgpt-developer-mode</guid>
      <pubDate>Thu, 11 Sep 2025 03:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>個人開發者可免費在 Microsoft Store 發佈應用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟在官方博客&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindowsdeveloper%2F2025%2F09%2F10%2Ffree-developer-registration-for-individual-developers-on-microsoft-store%2F" target="_blank"&gt;宣佈&lt;/a&gt;，個人開發者現在可以免費在 Microsoft Store 發佈應用，無需再支付此前的 19 美元註冊費。訪問 storedeveloper.microsoft.com 即可開始體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-37643f9d87fe2549cc22b7f744c732890ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微軟表示，開發者只需使用微軟賬户登錄合作伙伴中心，掃描有效身份證件並完成自拍驗證，隨後回答一系列問題，即可在幾分鐘內獲得合作伙伴中心的訪問權限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-784a448daff944810ee5d2c6ce9241cf8c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，微軟還為非遊戲類應用提供「0 抽成」的自建內購系統方案。如果開發者將應用打包為 MSIX 格式，微軟將利用自身基礎設施託管二進制文件並承擔分發成本，開發者無需自建 CDN。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371746</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371746</guid>
      <pubDate>Thu, 11 Sep 2025 03:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Framework 6.2.11 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#333333"&gt;Spring 團隊正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2025%2F09%2F11%2Fspring-framework-6-2-11-available%2520now" target="_blank"&gt;發佈&lt;/a&gt;了 Spring Framework 6.2.11，新版本包含 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Freleases%2Ftag%2Fv6.2.11" target="_blank"&gt;23 處修復和文檔改進&lt;/a&gt;&lt;span style="color:#333333"&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;新功能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JsonPathAssertions.isEqualTo 缺少&lt;code&gt;@Nullable&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35445" target="_blank"&gt;#35445&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;非默認 NIO.2 文件系統的優雅回退&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35443" target="_blank"&gt;#35443&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;避免 SseEmitter、ResponseBodyEmitter 中的線程固定&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35423" target="_blank"&gt;#35423&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將 Informix 代碼錯誤檢測為&lt;code&gt;DuplicateKeyException&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35400" target="_blank"&gt;#35400&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ResponseCookie&lt;/code&gt;&amp;nbsp;&lt;code&gt;from*()&lt;/code&gt;factory 方法中&lt;code&gt;String value&lt;/code&gt;參數的可空性不一致&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35377" target="_blank"&gt;#35377&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;重新審視&lt;code&gt;SimpleAsyncTaskExecutor/Scheduler&lt;/code&gt;上的&lt;code&gt;taskTerminationTimeout&lt;/code&gt;語義&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35372" target="_blank"&gt;#35372&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;StandardEvaluationContext.setBeanResolver&lt;/code&gt;應支持&lt;code&gt;@Nullable BeanResolver&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35371" target="_blank"&gt;#35371&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;錯誤修復&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;「mainThreadPrefix = null」導致多個後台 bean 鎖被阻塞&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35409" target="_blank"&gt;#35409&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;除非方法為 public，否則在 overridden method&amp;nbsp;中的參數上找不到註釋&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35349" target="_blank"&gt;#35349&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在未解析泛型的類型層次結構中找不到 overridden method&amp;nbsp;的註釋&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35342" target="_blank"&gt;#35342&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;使用 Provider 時單例 bean 性能下降&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35330" target="_blank"&gt;#35330&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Framework 6.2 中的 JettyClientHttpConnector 緩衝區泄漏&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35319" target="_blank"&gt;#35319&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;當定義自定義 ScheduledExecutorService bean 時，Spring 應用程序在&lt;code&gt;@Scheduled&lt;/code&gt;&lt;span style="color:#1f2328"&gt;(cron=…)&amp;nbsp;&lt;/span&gt;關閉時掛起（Java 19+）&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35316" target="_blank"&gt;#35316&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;文檔&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;記錄可能需要使用&lt;code&gt;Mockito.doXxx()&lt;/code&gt;來模擬&lt;code&gt;@MockitoSpyBean&lt;/code&gt;的情況&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35410" target="_blank"&gt;#35410&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復指向 Reactive Libraries 和 RestTemplate 的鏈接&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35392" target="_blank"&gt;#35392&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 WebDriver 文檔中的損壞鏈接&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35374" target="_blank"&gt;#35374&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;記錄 Web DataBinder 對 RouterFunction 的支持&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35367" target="_blank"&gt;#35367&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;改進&lt;code&gt;ApplicationEvents&lt;/code&gt;文檔以闡明建議用法&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35335" target="_blank"&gt;#35335&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;補充&lt;code&gt;DataSize.parse()&lt;/code&gt;中的單位與術語説明&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35298" target="_blank"&gt;#35298&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;完善&lt;code&gt;@Contract&lt;/code&gt;Javadoc&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35285" target="_blank"&gt;#35285&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更正 JpaTransactionManager javadoc 中 nestedTransactionAllowed 的默認值&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35212" target="_blank"&gt;#35212&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;依賴項升級&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;升級到 Micrometer 1.14.11&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35455" target="_blank"&gt;#35455&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;升級到 Reactor 2024.0.10&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35454" target="_blank"&gt;#35454&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371744/spring-framework-6-2-11-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371744/spring-framework-6-2-11-released</guid>
      <pubDate>Thu, 11 Sep 2025 03:25:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Apache 軟件基金會啓用新 Logo</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Apache 軟件基金會（ASF）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.apache.org%2Ffoundation%2Fentry%2Fintroducing-the-asfs-new-logo" target="_blank"&gt;官宣&lt;/a&gt;啓用新的 Logo 與品牌系統，旨在更好地反映其「社區重於代碼」（community over code）的核心理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-48e6a03ea5e1e57757e584ff4907d138f7d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ASF 的新 Logo 用一片橡樹葉 (oak leaf) 取代了沿用多年的羽毛圖案，象徵持久、穩健與社區成長：橡樹葉代表 ASF 對開源項目的長期承諾，葉脈寓意分佈式協作和開放治理，小橡子長成大樹的意象則呼應 「社區重於代碼」 的理念。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;橡樹葉象徵持久、穩健與耐力，橡樹生長緩慢但可持續數百年，代表 ASF 對軟件項目長期穩定與可持續性的承諾。&lt;/li&gt; 
 &lt;li&gt;一個小小的橡子（acorn）可長成龐大且多樣的森林，象徵由少數人開始，發展為包容性、自我治理的社區生態系統。&lt;/li&gt; 
 &lt;li&gt;橡樹葉的葉脈結構也象徵分佈式系統、共識、開放合作等 ASF 的價值觀。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ASF 表示，新設計延續原有品牌色調，但更加現代、適用於數字媒體；同時推出新的品牌指南，要求項目和相關材料逐步更新。從 2025 年 9 月 11 日起，對 ASF Logo 的公開使用都必須遵循新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapache.org%2Ffoundation%2Fpress%2Fkit%2F" target="_blank"&gt;品牌指南&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;此外，「The ASF」 這一縮寫將在品牌視覺中廣泛使用，全稱 「The Apache Software Foundation」 仍在法律文件或正式場合使用。&lt;/p&gt; 
&lt;p&gt;項目名稱中的 「Apache」 一詞將繼續保留。對其移除的考慮因影響甚廣並且對生態系統與安全性有重大後果，目前不打算整體移除。對於包含原有羽毛或土著元素的項目徽標，ASF 也將提供協助，幫助符合新的價值觀和視覺規範。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371742/the-asfs-new-logo</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371742/the-asfs-new-logo</guid>
      <pubDate>Thu, 11 Sep 2025 03:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>螞蟻與中國人民大學發佈首個原生 MoE 擴散語言模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;螞蟻集團與中國人民大學聯合發佈業界首個原生 MoE 架構的擴散語言模型 (dLLM)「LLaDA-MoE」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-7696b32900ada220e87d1e45ac5050eed98.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型通過非自迴歸的掩碼擴散機制，在大規模語言模型中實現了與 Qwen2.5 相當的語言智能 (如上下文學習、指令遵循、代碼和數學推理等)，挑戰了「語言模型必須自迴歸」的主流認知。&lt;/p&gt; 
&lt;p&gt;實驗數據顯示，LLaDA-MoE 模型性能效果在代碼、數學、Agent 等任務上領先於 LLaDA1.0/1.5 和 Dream-7B 等擴散語言模型，接近或超越了自迴歸模型 Qwen2.5-3B-Instruct，僅激活 1.4B 參數即可實現等效 3B 稠密模型的性能。&lt;/p&gt; 
&lt;p&gt;「LLaDA-MoE 模型驗證了工業級大規模訓練的擴展性和穩定性，意味我們在把 dLLM 訓擴到更大規模的路上又往前走了一步。」螞蟻集團通用人工智能研究中心主任、西湖大學特聘研究員、西湖心辰創始人藍振忠在發佈現場表示。&lt;/p&gt; 
&lt;p&gt;中國人民大學高瓴人工智能學院副教授李崇軒介紹，「兩年過去，AI 大模型能力突飛猛進，但存在一些問題始終沒有得到本質上的解決。究其原因，這是當前大模型普遍採用的自迴歸生成範式所造成的——模型天然是單向建模的，從前往後依次生成下一個 token。這導致它們難以捕 tokens 之間的雙向依賴關係。」&lt;/p&gt; 
&lt;p&gt;面對這些問題，一些研究者選擇另闢蹊徑，將目光投向並行解碼的擴散語言模型。然而，現有 dLLM 均基於稠密架構，難以復刻 ARM 中 MoE 的「參數擴展、計算高效」優勢。在這樣的行業背景下，螞蟻和人大聯合研究團隊，首次在 MoE 架構上推出了原生的擴散語言模型 LLaDA-MoE。&lt;/p&gt; 
&lt;p&gt;藍振忠還透露，將於近期向全球完全開源模型權重和自研推理框架，與社區共同推動 AGI 新一輪突破。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371738</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371738</guid>
      <pubDate>Thu, 11 Sep 2025 03:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里巴巴、百度開始採用自研芯片訓練 AI 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;《The Information》援引直接知情人士的消息&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Falibaba-baidu-adopt-ai-chips-major-shift-chinese-tech" target="_blank"&gt;報道&lt;/a&gt;，阿里巴巴和百度已開始使用自主設計的芯片訓練其 AI 模型，部分替代了英偉達生產的芯片。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1108" src="https://static.oschina.net/uploads/space/2025/0912/110432_Ft9v_2720166.png" width="1058" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報道稱，自今年初以來，阿里巴巴針對輕量級 AI 模型使用自研芯片；而百度則在嘗試用其崑崙 P800 芯片訓練新版文心一言（Ernie）AI 模型。&lt;/p&gt; 
&lt;p&gt;不過，阿里和百度都並未完全放棄英偉達，兩家公司仍在使用英偉達的芯片來開發其最尖端模型。&lt;/p&gt; 
&lt;p&gt;英偉達發言人對此表示：「競爭無疑已經到來…… 我們將繼續努力，贏得全球各地主流開發者的信任與支持。」&lt;/p&gt; 
&lt;p&gt;上月，英偉達 CEO 黃仁勳 (Jensen Huang) 表示，正在與白宮討論在華銷售下一代 AI 芯片，但需要時間。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371737</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371737</guid>
      <pubDate>Thu, 11 Sep 2025 03:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥秋天了，手搓一個智能加濕器？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2209</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2209</guid>
      <pubDate>Thu, 11 Sep 2025 03:01:00 GMT</pubDate>
    </item>
    <item>
      <title>MiniMax 發佈新一代音樂生成模型 Music 1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniMax&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUzMDWMHFZDlIUZwhhBpcYQ" target="_blank"&gt;發佈&lt;/a&gt;了新一代音樂生成模型 Music 1.5，單次可生成最長 4 分鐘完整歌曲，支持流行、爵士、搖滾、藍調等多種風格，並新增對中國小眾及民族樂器的建模。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e9e358fdc1179f9370f0f8994ba99753ef9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該模型還提供「高級模式」，允許用户用自然語言描述風格、情緒、場景，並對 Intro、Verse、Chorus 等段落進行歌詞與結構級精細控制，實現段落界限清晰、副歌爆點突出的「敍事級」聽覺體驗。&lt;/p&gt; 
&lt;p&gt;Music 1.5 同步向全球開發者開放 API，官方稱延續「全球最高性價比」策略，方便影視、遊戲、短視頻、虛擬偶像、企業品牌等場景快速調用。&lt;/p&gt; 
&lt;p&gt;用户可登錄官網音頻頁面 minimaxi.com/audio/music 即刻體驗，也可通過 API 將 AI 音樂能力集成至應用與創作工作流。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371732/minimax-music-15</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371732/minimax-music-15</guid>
      <pubDate>Thu, 11 Sep 2025 02:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年大語言模型架構演進：DeepSeek V3、OLMo 2、Gemma 3 與 Mistral 3.1 核心技術剖析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 在 Transformer 架構誕生八年之際，我們是否真的見證了根本性的突破，還是隻是在原有設計上不斷打磨？今天我們為大家帶來的這篇文章，作者的核心觀點是：儘管大語言模型在技術細節上持續優化，其核心架構仍保持延續，真正的創新更多體現在效率提升與工程實現上。&lt;/p&gt; 
 &lt;p&gt;文章系統梳理了 2025 年多個主流開源模型的架構演進，重點分析了 DeepSeek-V3/R1 的多頭潛在注意力（MLA）與混合專家模型（MoE）、OLMo 2 的歸一化層放置策略與 QK 歸一化、Gemma 3 的滑動窗口注意力機制，以及 Mistral Small 3.1 在推理效率上的優化。&lt;/p&gt; 
 &lt;p&gt;這篇文章為我們提供了一個冷靜而深入的視角，提醒我們在追逐 SOTA 榜單的同時，不應忽視那些真正推動技術前進的、看似細微卻至關重要的架構設計選擇。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Devansh and Sebastian Raschka, PhD&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;目錄&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;01 DeepSeek V3/R1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.1 多頭潛在注意力機制（MLA）&lt;/p&gt; 
&lt;p&gt;1.2 混合專家模型（MoE）&lt;/p&gt; 
&lt;p&gt;1.3 DeepSeek 架構總結&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 OLMo 2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2.1 歸一化層放置策略&lt;/p&gt; 
&lt;p&gt;2.2 QK-Norm&lt;/p&gt; 
&lt;p&gt;2.3 OLMo 2 架構總結&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 Gemma 3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;3.1 滑動窗口注意力機制&lt;/p&gt; 
&lt;p&gt;3.2 Gemma 3 的歸一化層佈局策略&lt;/p&gt; 
&lt;p&gt;3.3 Gemma 3 架構總結&lt;/p&gt; 
&lt;p&gt;3.4 附加內容：Gemma 3n&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;04 Mistral Small 3.1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自最初的 GPT 架構問世以來，已經過去了七年時間。當我們回望 GPT-2（2019 年）並展望 DeepSeek-V3 與 Llama 4（2024 - 2025 年）時，可能會驚訝地發現這些模型在結構上仍然如此相似。&lt;/p&gt; 
&lt;p&gt;誠然，位置編碼已從絕對位置編碼發展為旋轉位置編碼（RoPE），多頭注意力機制已普遍被分組查詢注意力機製取代，而更高效的 SwiGLU 激活函數也替代了 GELU 等傳統激活函數。但在這些細微改進之下，我們是否真正見證了突破性的變革？抑或只是在相同架構基礎之上進行精雕細琢？&lt;/p&gt; 
&lt;p&gt;比較不同大語言模型來確定影響其性能優劣的關鍵因素歷來充滿挑戰：數據集、訓練技術和超參數不僅差異巨大，且往往缺乏完整記錄。&lt;/p&gt; 
&lt;p&gt;儘管如此，我仍認為審視架構本身的結構性變化極具價值 ------ 這能幫助我們洞察 2025 年大語言模型開發者的核心關注點（部分架構如圖 1 所示）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-09bd954abf4865d39b04771a5bb94fd00b3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 1：本文涉及的部分架構示意圖&lt;/p&gt; 
&lt;p&gt;因此，本文將聚焦定義當今主流開源模型的核心架構演進，而非基準測試表現或訓練算法的討論。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 DeepSeek V3/R1&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek R1 在 2025 年 1 月發佈時引起了巨大轟動。該推理模型基於 2024 年 12 月推出的 DeepSeek V3 架構構建。&lt;/p&gt; 
&lt;p&gt;雖然本文主要關注 2025 年發佈的模型架構，但考慮到 DeepSeek V3 正是在 2025 年憑藉 DeepSeek R1 的發佈才獲得廣泛關注與應用，將其納入討論範圍是合理的。&lt;/p&gt; 
&lt;p&gt;若您對 DeepSeek R1 的訓練細節感興趣，可參閲我今年早前的文章《Understanding Reasoning LLMs》[1]：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cbf78557c5b8225e22db1bcae737f415946.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本節將重點解析 DeepSeek V3 中兩項提升計算效率的核心架構技術（這也是其區別於其他大語言模型的重要特徵）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多頭潛在注意力機制（MLA）&lt;/li&gt; 
 &lt;li&gt;混合專家模型（MoE）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 多頭潛在注意力機制（MLA）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在探討多頭潛在注意力機制（MLA）之前，我們先簡要回顧相關背景以理解其設計動機。讓我們從分組查詢注意力機制（GQA）談起 ------ 近年來它已成為替代多頭注意力機制（MHA）的新標準方案，具有更高的計算效率與參數效率。&lt;/p&gt; 
&lt;p&gt;以下是 GQA 的核心概要：與 MHA 中每個注意力頭都擁有獨立的鍵值對不同，GQA 通過讓多個注意力頭共享同一組鍵值投影來降低內存消耗。例如，如圖 2 所示，若存在 2 個鍵值組和 4 個注意力頭，則注意力頭 1 與注意力頭 2 可能共享一組鍵值，而注意力頭 3 與注意力頭 4 共享另一組。這種方式減少了鍵值計算總量，從而降低內存使用並提升效率（消融實驗表明其對模型性能無明顯影響）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c96d615a0c39b0040bece0b0da7c24dfbf.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 2：MHA 與 GQA 對比示意圖（組大小為 2，即每兩個查詢頭共享一組鍵值對）&lt;/p&gt; 
&lt;p&gt;GQA 的核心思想是通過讓多個查詢頭共享鍵值頭來減少鍵值頭數量，這帶來兩大優勢： &lt;strong&gt;（1）降低模型參數量；（2）推理時減少鍵值張量的內存帶寬佔用，因為需要存儲和從 KV 緩存中檢索的鍵值對更少。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;（若想了解 GQA 的代碼實現，可參閲筆者撰寫的無 KV 緩存版《GPT-2 to Llama 3 conversion guide》[2]及帶 KV 緩存的改進版本[3]。）&lt;/p&gt; 
&lt;p&gt;儘管 GQA 本質上是針對 MHA 的計算效率優化方案，但消融研究（包括原版 GQA 論文[4]和 Llama 2 論文[5]）表明其在 LLM 建模性能上與標準 MHA 相當。&lt;/p&gt; 
&lt;p&gt;而多頭潛在注意力機制（MLA）則提供了另一種內存優化策略，尤其與 KV 緩存機制高度契合。與 GQA 共享鍵值頭的思路不同，MLA 將鍵值張量壓縮至低維空間後再存入 KV 緩存。&lt;/p&gt; 
&lt;p&gt;推理時，這些壓縮張量會先通過投影恢復原始尺寸後再參與計算（如圖 3 所示）。雖然增加了矩陣乘法操作，但大大降低了內存佔用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c43aacfdb6bb016170097f6397f3903fb7d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 3：MLA（用於 DeepSeek V3 和 R1 中）與常規 MHA 的對比示意圖&lt;/p&gt; 
&lt;p&gt;（需要説明的是，查詢向量在訓練過程中也會被壓縮，但該操作僅適用於訓練階段，不涉及推理過程。）&lt;/p&gt; 
&lt;p&gt;值得一提的是，MLA 並非 DeepSeek V3 首創 ------ 其前代版本 DeepSeek-V2 早已採用（甚至可以説是由其率先引入）這項技術。此外，V2 論文中多項有趣的消融實驗或許能解釋開發團隊為何選擇 MLA 而非 GQA（見圖 4）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d4480020e0658530a184bb6537b95bbdf5f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 4：帶有標註的摘自 DeepSeek-V2 論文的表格（來源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如圖 4 所示，GQA 的表現似乎遜於 MHA，而 MLA 的建模性能反而優於 MHA ------ 這很可能是 DeepSeek 團隊捨棄 GQA 選擇 MLA 的原因。（若能同時對比 MLA 與 GQA 在"每詞元 KV 緩存"上的節省效果，或許會更有趣！）&lt;/p&gt; 
&lt;p&gt;對此部分進行總結：&lt;strong&gt;MLA 是一種巧妙的 KV 緩存內存優化技術，其在建模性能方面甚至較 MHA 略有提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 混合專家模型（MoE）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeek 架構中另一個值得重點闡述的核心組件是其採用的混合專家模型（MoE）層。儘管 MoE 並非由 DeepSeek 首創，但今年該技術正迎來複興浪潮，後續將討論的諸多模型架構也都採用了這一方案。&lt;/p&gt; 
&lt;p&gt;MoE 的核心思想是將 Transformer 模塊中的每個前饋網絡替換為多個專家層 ------ 每個專家層本身也是前饋模塊。這意味着我們用多個前饋模塊替代單一前饋模塊，具體如圖 5 所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fd1eb2a8236e1a59888c990d003f566d18d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 5：DeepSeek V3/R1 採用的 MoE 模塊（右）與標準前饋網絡結構（左）對比示意圖&lt;/p&gt; 
&lt;p&gt;Transformer 模塊內的前饋網絡（上圖中深灰色模塊）通常佔據着模型的絕大部分參數量（需注意 Transformer 模塊及其內含的前饋網絡會在 LLM 中重複多次，例如 DeepSeek-V3 中就重複了 61 次）。&lt;/p&gt; 
&lt;p&gt;因此，用多個前饋模塊替代單一前饋模塊（MoE 的實現方式）會大大增加模型的總參數量。但並非每個 token 都會激活所有專家。相反，路由層會為每個 token 僅選擇一小部分專家（由於篇幅所限，關於路由層的細節將另文詳述）。&lt;/p&gt; 
&lt;p&gt;由於每次僅激活少量專家模塊，MoE 系統通常被稱為稀疏架構，這與始終使用全部參數的密集架構形成對比。通過 MoE 實現的龐大總參數量提升了 LLM 的容量上限，使其在訓練過程中能吸收更多知識。而稀疏特性則保證了推理效率 ------ 因為我們不會同時調用所有參數。&lt;/p&gt; 
&lt;p&gt;以 DeepSeek-V3 為例：每個 MoE 模塊包含 256 個專家，總參數量達 6710 億。但在推理過程中，每次僅激活 9 個專家（1 個共享專家 + 路由層選出的 8 個專家）。這意味着每個推理步驟僅使用 370 億參數，而非全部 6710 億。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DeepSeek-V3 的 MoE 設計有一個特點：採用共享專家機制。這個專家會對每個 token 始終保持激活狀態。&lt;/strong&gt; 該理念並非首創，早在 2024 年 DeepSeek MoE 論文[6]和 2022 年 DeepSpeedMoE 論文[7]中就已提出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-15a799b152fc26e09b06b94411da5ba9e07.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 6：帶有標註的摘自《DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models》的圖示，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066" target="_blank"&gt;https://arxiv.org/abs/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;共享專家的優勢最初在 DeepSpeedMoE 論文[7]中被指出：相比無共享專家的設計，它能提升整體建模性能。這很可能是因為常見模式或重複模式無需由多個獨立專家重複學習，從而為專家們留出更多專攻特殊化模式的空間。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 DeepSeek 架構總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;總而言之，DeepSeek-V3 作為一個擁有 6710 億參數的巨型模型，在發佈時性能就超越了包括 4050 億參數的 Llama 3 在內的其他開放權重模型。儘管參數量更大，但其推理效率卻明顯更高 ------ 這得益於其混合專家系統（MoE）架構的設計，該架構使得每個 token 僅激活參數總量的極小部分（僅 370 億參數）。&lt;/p&gt; 
&lt;p&gt;另一個關鍵區別在於 DeepSeek-V3 採用多頭潛在注意力機制（MLA）替代了分組查詢注意力機制（GQA）。MLA 與 GQA 都是標準多頭注意力（MHA）的高效推理替代方案，尤其在配合 KV 緩存使用時優勢明顯。雖然 MLA 的實現更為複雜，但 DeepSeek-V2 論文中的研究表明，其建模性能優於 GQA。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 OLMo 2&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;非營利組織艾倫人工智能研究所（Allen Institute for AI）推出的 OLMo 系列模型同樣值得關注，這主要得益於其在訓練數據與工程代碼方面的高透明度，以及相對詳盡的技術報告。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;雖然 OLMo 模型可能不會在各類基準測試或排行榜上名列前茅，但其架構設計清晰簡潔。更重要的是，憑藉完全開源的特性，該系列模型為 LLM 的開發提供了極佳的藍圖參考。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;儘管 OLMo 模型因其透明性而廣受歡迎，但其性能表現同樣可圈可點。實際上，在今年 1 月發佈時（早於 Llama 4、Gemma 3 和 Qwen 3），OLMo 2 系列模型正處於計算效率與性能的帕累託前沿【譯者注："帕累託前沿"（Pareto Frontier）是一個起源於經濟學和優化理論的重要概念，它描述的是一種最優狀態，在這種狀態下，任何一方的利益或某個目標的提升都無法不以犧牲其他方利益或其他目標的下降為代價。】，如圖 7 所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-006c99086b0db6493bcd4ec05b3e2dd3345.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 7：不同 LLMs 的基準測試性能（越高越好）與預訓練成本（FLOPs；越低越好）對比（這張經過標註的圖片源自 OLMo 2 論文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00656%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2501.00656）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如本文開頭所述，為控制篇幅，我們將聚焦於 LLM 的架構細節（暫不涉及訓練細節與數據）。那麼 OLMo 2 有哪些值得關注的架構設計選擇？主要可歸結為歸一化技術的應用：包括 RMSNorm 層的佈局以及新增的 QK 歸一化設計（後續將詳細討論）。&lt;/p&gt; 
&lt;p&gt;另值得一提的是，OLMo 2 仍採用傳統多頭注意力（MHA）機制，而非 MLA 或 GQA。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 歸一化層放置策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;總體而言，OLMo 2 基本遵循了原始 GPT 的架構設計，這與當代其他大語言模型相似。但其仍存在一些值得關注的差異，讓我們先從歸一化層説起。&lt;/p&gt; 
&lt;p&gt;與 Llama、Gemma 及多數主流大語言模型類似，OLMo 2 也將 LayerNorm 層替換為了 RMSNorm 層。&lt;/p&gt; 
&lt;p&gt;但由於 RMSNorm 已是成熟技術（本質上是 LayerNorm 的簡化版，擁有更少的可訓練參數），本文將不再討論 RMSNorm 與 LayerNorm 的區別（感興趣的讀者可參閲筆者撰寫的《GPT-2 to Llama conversion guide》[8]中的 RMSNorm 代碼實現）。&lt;/p&gt; 
&lt;p&gt;然而，RMSNorm 層的放置位置值得深入探討。原始 Transformer 架構（出自《Attention is all you need》[9]論文）將兩個歸一化層分別放置在注意力模塊和前饋網絡模塊之後。&lt;/p&gt; 
&lt;p&gt;這種設計被稱為後歸一化（Post-LN 或 Post-Norm）。&lt;/p&gt; 
&lt;p&gt;而 GPT 及之後大多數大語言模型則將歸一化層置於注意力模塊和前饋網絡模塊之前，稱為前歸一化（Pre-LN 或 Pre-Norm）。兩種歸一化方式的對比如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f4a2fae83b7a11949e42208b3caa34523d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 8：後歸一化、前歸一化與 OLMo 2 採用的後歸一化變體對比示意圖&lt;/p&gt; 
&lt;p&gt;2020 年，Xiong 等人通過研究[10]證明：前歸一化能使梯度在初始化階段表現更穩定。研究人員還指出，前歸一化即使不配合精細的學習率預熱策略也能良好工作，而這對於後歸一化而言卻是至關重要的訓練保障。&lt;/p&gt; 
&lt;p&gt;此處特別提及該研究是因為 OLMo 2 採用了一種後歸一化變體（但使用 RMSNorm 替代了 LayerNorm，故稱其為 Post-Norm）。&lt;/p&gt; 
&lt;p&gt;在 OLMo 2 中，歸一化層被放置在注意力層和前饋網絡層之後（而非之前），如上圖所示。但請注意：與原始 Transformer 架構不同，這些歸一化層仍位於殘差層（跳躍連接）內部。&lt;/p&gt; 
&lt;p&gt;那麼為何要調整歸一化層的位置？原因在於這種設計能提升訓練穩定性，如下圖所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2ef106b336705a7b4016f23c379c087df1c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 9：前歸一化（GPT-2、Llama 3 等模型採用）與 OLMo 2 後歸一化變體的訓練穩定性對比圖。此帶有標註的圖表取自 OLMo 2 論文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00656" target="_blank"&gt;https://arxiv.org/abs/2501.00656&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;遺憾的是，該圖表將歸一化層重定位與 QK-Norm（另一個獨立概念）的效果合併展示，因此難以單獨判斷歸一化層位置調整的具體貢獻程度。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 QK-Norm&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;既然上一節已提及 QK-Norm，且後續將討論的其他大語言模型（如 Gemma 2 和 Gemma 3）也採用了該技術，我們不妨簡要探討一下其原理。&lt;/p&gt; 
&lt;p&gt;QK-Norm 本質上是另一個 RMSNorm 層。它被置於多頭注意力（MHA）模塊內部，在應用旋轉位置編碼（RoPE）之前對查詢向量（q）和鍵向量（k）進行歸一化處理。為直觀説明，以下內容摘錄自我在《Qwen3 from-scratch implementation》[11]編寫的分組查詢注意力（GQA）層代碼（GQA 中的 QK-Norm 應用方式與 OLMo 的 MHA 類似）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c4bc7af7b40fc5cdcb60d387600a0022cda.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如前文所述，QK-Norm 與後歸一化配合使用可提升訓練穩定性。需要注意的是，QK-Norm 並非由 OLMo 2 首創，其最早可追溯至 2023 年發表的《Scaling Vision Transformers》[12]論文。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 OLMo 2 架構總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;簡而言之，&lt;strong&gt;OLMo 2 值得關注的架構設計決策主要集中於 RMSNorm 的放置策略&lt;/strong&gt;：將 RMSNorm 置於注意力模塊和前饋網絡模塊之後（一種後歸一化變體），而非之前。同時在注意力機制內部為查詢向量和鍵向量添加 RMSNorm（即 QK-Norm）。這兩項改進共同作用，有效穩定了訓練損失。&lt;/p&gt; 
&lt;p&gt;下圖進一步對比了 OLMo 2 與 Llama 3 的架構差異：可見除 OLMo 2 仍採用傳統 MHA 而非 GQA 外，兩者結構總體相似（但 OLMo 2 團隊在三個月後發佈了採用 GQA 的 320 億參數變體）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bdbcbce349892ba75c88a65efd77c6c32c5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 10：Llama 3 與 OLMo 2 的架構對比示意圖&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Gemma 3&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Google 的 Gemma 系列模型始終保持着卓越的性能，但與 Llama 等熱門模型相比，其關注度始終略顯不足。&lt;/p&gt; 
&lt;p&gt;Gemma 的顯著特徵之一是其超大的詞表規模（以便更好地支持多語言場景），以及更側重 27B 參數規格（而非 8B 或 70B）。需注意的是，Gemma 2 也提供更小規格版本：1B、4B 與 12B。&lt;/p&gt; 
&lt;p&gt;27B 規格堪稱最佳平衡點：性能遠超 8B 模型，資源消耗卻遠低於 70B 模型，甚至能在 Mac Mini 上實現本地流暢運行。&lt;/p&gt; 
&lt;p&gt;那麼 Gemma 3[13] 還有哪些亮點？如前文所述，DeepSeek-V3/R1 等模型採用 MoE 架構在固定模型規模下降低推理內存需求（後續討論的其他模型也採用了 MoE 方案）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gemma 3 則運用了不同的技巧來減少計算開銷 ------ 即滑動窗口注意力機制。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 滑動窗口注意力機制&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;通過採用滑動窗口注意力機制（該技術最初在 2020 年由 LongFormer 論文[14]提出，Gemma 2[15] 也已採用），Gemma 3 團隊大大降低了 KV 緩存的內存需求，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4e8fa5253791a93c43da4e975a37a262b5b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 11：帶有標註的 Gemma 3 論文示意圖（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt; ），展示了滑動窗口注意力機制對 KV 緩存的內存節省效果&lt;/p&gt; 
&lt;p&gt;那麼什麼是滑動窗口注意力機制？如果將常規自注意力視為全局注意力機制（每個序列元素可訪問任意其他元素），那麼滑動窗口注意力可理解為局部注意力 ------ 它會限制當前查詢位置周圍的上下文大小，具體如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3804c7cd9fa56d227e81dcc2585710a01d1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 12：常規注意力（左）與滑動窗口注意力（右）對比示意圖&lt;/p&gt; 
&lt;p&gt;需要注意的是，滑動窗口注意力可同時適用於多頭注意力和分組查詢注意力，Gemma 3 採用的是分組查詢注意力版本。&lt;/p&gt; 
&lt;p&gt;如前文所述，滑動窗口注意力又稱為"局部注意力"，因為其滑動窗口會圍繞當前查詢位置移動。相比之下，常規注意力是全局性的，每個詞元都能訪問所有其他詞元。&lt;/p&gt; 
&lt;p&gt;不過，前代架構 Gemma 2 早已採用滑動窗口注意力。Gemma 3 的改進在於調整了全局注意力（常規）與局部注意力（滑動）的比例。&lt;/p&gt; 
&lt;p&gt;例如，Gemma 2 採用混合注意力機制，以 1:1 的比例結合滑動窗口（局部）與全局注意力，每個詞元可關注附近 4K 詞元的上下文窗口。&lt;/p&gt; 
&lt;p&gt;Gemma 2 在每一層都使用滑動窗口注意力，而 Gemma 3 將比例調整為 5:1 ------ 即每 5 個滑動窗口（局部）注意力層才設置 1 個全局注意力層。同時滑動窗口大小從 Gemma 2 的 4096 縮減至 1024。這種設計使模型更聚焦於高效的局部計算。&lt;/p&gt; 
&lt;p&gt;根據消融實驗，滑動窗口注意力對建模性能的影響微乎其微，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d9c12fc9217cd8821aabbbd87877b18afb5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 13：帶有標註的 Gemma 3 論文示意圖（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt; ），表明滑動窗口注意力對大語言模型輸出困惑度的影響極小&lt;/p&gt; 
&lt;p&gt;雖然滑動窗口注意力是 Gemma 3 最顯著的架構特性，但作為前文 OLMo 2 章節的延續，我們還需簡要討論其歸一化層的佈局策略。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 Gemma 3 的歸一化層佈局策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一個雖細微卻值得關注的設計是：Gemma 3 在其分組查詢注意力模塊周圍同時採用了前歸一化（Pre-Norm）與後歸一化（Post-Norm）的 RMSNorm 配置。&lt;/p&gt; 
&lt;p&gt;此設計雖與 Gemma 2 類似，但仍值得強調 ------ 因為它既不同於原始 Transformer（《Attention is all you need》）採用的後歸一化，也區別於 GPT-2 推廣並被後續眾多模型架構採用的前歸一化，同時與我們前文討論的 OLMo 2 後歸一化變體存在差異。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-473b00d7dce6402f9ee06bd10213cbb62bd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 14：OLMo 2 與 Gemma 3 的架構對比圖。注意 Gemma 3 中增加的歸一化層&lt;/p&gt; 
&lt;p&gt;筆者認為這種歸一化層佈局是一種直觀而高效的方案，它融合了前歸一化和後歸一化的雙重優勢。從實踐角度看，適當增加的歸一化操作通常利大於弊：在最壞情況下，即便存在冗餘也僅會帶來輕微的效率損失。由於 RMSNorm 在整體計算開銷中佔比極低，這種設計實際上不會產生明顯影響。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 Gemma 3 架構總結&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Gemma 3 是一款性能優異的開放權重大語言模型，但其在開源社區中的認可度與其實力並不匹配。最引人注目的是其採用滑動窗口注意力提升效率的設計（未來若能與 MoE 結合將更具想象空間）。&lt;/p&gt; 
&lt;p&gt;此外，Gemma 3 採用獨特的歸一化層佈局策略，在注意力模塊和前饋網絡模塊前後均部署了 RMSNorm 層。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.4 附加內容：Gemma 3n&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Gemma 3 發佈數月後，谷歌推出了專為移動設備優化的 Gemma 3n[16] 版本，其核心目標是實現在手機端高效運行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gemma 3n 為提升效率做出的改進之一是引入 Per-Layer Embedding（PLE）層。&lt;/strong&gt; 該設計的核心思想是不將整個模型的所有參數都加載到昂貴的 GPU 內存中，而是隻保留其中最核心、最常用的一部分，而文本、音頻、視覺等模態的特定詞元層嵌入則按需從 CPU 或 SSD 動態加載。&lt;/p&gt; 
&lt;p&gt;下圖展示了 PLE 機制的內存優化效果：標準 Gemma 3 模型（可能指 4B 參數版本）標註的參數量為 5.44B。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ad705647f86ab59e5d74cd0e81e9e68faaa.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 15：經過標註的摘自谷歌 Gemma 3n 相關博客的示意圖（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fintroducing-gemma-3n%2F" target="_blank"&gt;https://developers.googleblog.com/en/introducing-gemma-3n/&lt;/a&gt; ），展示了 PLE 內存優化機制&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.44B 與 4B 參數的統計差異源於谷歌採用了一種特殊的參數計數方式：他們通常排除嵌入參數以使模型顯得更小，但在需要凸顯規模時（比如此處）又會將其計入。這種統計方式並非谷歌獨有，已成為行業普遍做法。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;另一項有趣的技術是 MatFormer[17] 概念（Matryoshka Transformer 的簡稱）。例如，Gemma 3n 使用一個共享的 LLM（Transformer）架構，可以將其切割成多個更小的、獨立運行的子模型。每個子模型經過獨立訓練後均能單獨運行，因此在推理時只需調用所需的部分（無需啓動整個大模型）。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Mistral Small 3.1&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;於 Gemma 3 發佈後不久在三月問世的 Mistral Small 3.1 24B[18] 值得關注 ------ 它在多項基準測試（除數學外）中性能超越 Gemma 3 27B，且推理速度更快。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Mistral Small 3.1 推理延遲低於 Gemma 3 的原因可能包括：定製化的分詞器、KV 緩存壓縮以及層數的精簡。&lt;/strong&gt; 其餘部分則採用標準架構（如下圖對比所示）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-454b0fa436afef4f674c8d6365b209aa441.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;圖 16：Gemma 3 27B 與 Mistral 3.1 Small 24B 架構對比示意圖&lt;/p&gt; 
&lt;p&gt;有趣的是，早期 Mistral 模型曾採用滑動窗口注意力機制，但該設計在 Mistral Small 3.1 中被棄用。由於 Mistral 改用標準的分組查詢注意力（而非 Gemma 3 採用的滑動窗口注意力），其或許能通過調用經過深度優化的底層計算代碼（如 FlashAttention）進一步降低推理開銷。例如，筆者推測：滑動窗口注意力機制雖降低了內存佔用，但未必會減少推理延遲 ------ 而這正是 Mistral Small 3.1 的核心優化目標。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你是否同意"過去幾年 Transformer 架構沒有根本性突破"這一觀點？為什麼？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中鏈接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagazine.sebastianraschka.com%2Fp%2Funderstanding-reasoning-llms" target="_blank"&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fch05%2F07_gpt_to_llama%2Fconverting-llama2-to-llama3.ipynb" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-llama2-to-llama3.ipynb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fpkg%2Fllms_from_scratch%2Fllama3.py" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/pkg/llms_from_scratch/llama3.py&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13245" target="_blank"&gt;https://arxiv.org/abs/2305.13245&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.09288" target="_blank"&gt;https://arxiv.org/abs/2307.09288&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066" target="_blank"&gt;https://arxiv.org/abs/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.05596" target="_blank"&gt;https://arxiv.org/abs/2201.05596&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fch05%2F07_gpt_to_llama%2Fconverting-gpt-to-llama2.ipynb" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-gpt-to-llama2.ipynb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762" target="_blank"&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2002.04745" target="_blank"&gt;https://arxiv.org/abs/2002.04745&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Ftree%2Fmain%2Fch05%2F11_qwen3" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/11_qwen3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2302.05442" target="_blank"&gt;https://arxiv.org/abs/2302.05442&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2004.05150" target="_blank"&gt;https://arxiv.org/abs/2004.05150&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Farxiv.org%2Fabs%2F2408.00118" target="_blank"&gt;http://arxiv.org/abs/2408.00118&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fintroducing-gemma-3n%2F" target="_blank"&gt;https://developers.googleblog.com/en/introducing-gemma-3n/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2310.07707" target="_blank"&gt;https://arxiv.org/abs/2310.07707&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmistral-small-3-1" target="_blank"&gt;https://mistral.ai/news/mistral-small-3-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartificialintelligencemadesimple.substack.com%2Fp%2Fa-look-through-the-seven-years-of" target="_blank"&gt;https://artificialintelligencemadesimple.substack.com/p/a-look-through-the-seven-years-of&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18691557</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18691557</guid>
      <pubDate>Thu, 11 Sep 2025 02:41:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>美團首款 AI Agent 產品「小美」開啓公測</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;美團首款 AI Agent 產品「小美」App 已於昨日開啓公測，目前可通過蘋果 App Store 及各大安卓廠商的應用商店進行下載。&lt;/p&gt; 
&lt;p&gt;這款產品在 App Store 顯示為「小美-AI 生活小秘書」，首發版本號 1.6.0，現在已經更新到 1.6.1 版本，體積約 128.8MB，需要 iOS 14.0 或更高版本。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;應用描述：&lt;/p&gt; 
 &lt;p&gt;小美是一款能夠幫你想，代你辦的 AI 生活小秘書，讓你的生活更輕鬆，TA 能夠：&lt;/p&gt; 
 &lt;p&gt;一句話幫你點外賣，一杯奶茶、一份工作餐，只需要一句話就夠了；&lt;/p&gt; 
 &lt;p&gt;不僅能一兩句話幫你選好餐廳，還能幫你包辦訂座排隊；&lt;/p&gt; 
 &lt;p&gt;規劃你的一週早餐、咖啡，每天都要來杯冰美式？告訴小美，接下來你就不需要操心了，都交給 TA！&lt;/p&gt; 
 &lt;p&gt;小美還在學習更多技能，包括打車、訂酒店機票、買電影票、預約按摩店等。有了小美，你的生活會更加高效、便捷、輕鬆。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據官方介紹，小美已全面接入美團 App 的外賣、旅遊、酒店預訂等核心業務。用户通過語音或文字指令可完成「幫我找附近評分 4.5 以上的川菜館」「明天下午三點預約故宮門票」等操作，系統會結合實時數據（如商家忙閒狀態、景點餘票）自動推薦最優方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3a53ae8c390a81ec615ab4e375c3fbb93c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;針對企業用户，小美推出 Nocode 工具，支持 3 分鐘生成活動 H5 頁面、自動爬取競品數據生成對比報表，甚至拖拽式搭建問卷調查系統，大幅降低非技術人員的數字化門檻。&lt;/p&gt; 
&lt;p&gt;此外，小美具備智能日程管理功能，能幫助用户設置提醒、安排會議、規劃每日行程，避免重要事項遺漏。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371728</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371728</guid>
      <pubDate>Thu, 11 Sep 2025 02:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
