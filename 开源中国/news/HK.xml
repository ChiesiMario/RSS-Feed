<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 12 Aug 2025 12:42:57 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Fedora 43 獲準支持 Hare 編程語言，默認啓用硬鏈接</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Fedora 工程與指導委員會 (FESCo) 本週批准了即將發佈的 Fedora Linux 43 版本的多項新增功能。其中包括獲準發佈 Hare 軟件包，Hare 是一種新的系統編程語言，旨在簡化、穩定和健壯。&lt;/p&gt; 
&lt;p&gt;Hare 本身仍在開發中，但 FESCo 現已批准將 Hare 工具鏈打包併發布到 Fedora 43 的倉庫中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/191447_Wl7H_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FESCo 還批准在 Fedora 43 中發佈即將發佈的 PHP 8.4 版本，這並不令人意外。FESCo 還批准棄用 YASM，轉而使用 NASM。YASM 彙編器目前無人維護，而 NASM 的情況也好多了。&lt;/p&gt; 
&lt;p&gt;作為英特爾 oneAPI 線程構建版本 (TBB) 的最新更新，Threaded Building Blocks 2022.2 也已獲批准發佈。FESCo 本週還批准了默認對 Fedora RPM 軟件包中，相同的 /usr 文件進行硬鏈接的提案。&lt;/p&gt; 
&lt;p&gt;有關 Fedora 43 版本中這些新批准更改的更多詳細信息，&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.fedoraproject.org%2Farchives%2Flist%2Fdevel%40lists.fedoraproject.org%2Fthread%2FMVPWNTBSZUUJINZX6PZQGTYE2BA7NFKL%2F" target="_blank"&gt;請通過此 FESCo 郵件列表帖子獲取&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;，該版本將於今年晚些時候發佈。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365798</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365798</guid>
      <pubDate>Tue, 12 Aug 2025 11:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>One Million Screenshots：收集了超過 100 萬張網站截圖的網站</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;「One Million Screenshots」 是一個專門收集網站截圖的網站，聲稱截圖了超過 100 萬個熱門 Web 主頁。此外還提供了搜索相似網站的功能，以及查看網站截圖的歷史變化。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0812/185333_PgpB_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;https://onemillionscreenshots.com/&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;沒想到 OSCHINA 也榮幸出鏡了：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fonemillionscreenshots.com%2Foschina.net%2Fscreenshot" target="_blank"&gt;https://onemillionscreenshots.com/oschina.net/screenshot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="6306" src="https://static.oschina.net/uploads/space/2025/0812/185758_Ydik_2720166.png" width="1604" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下面是關於該網站的常見問題：&lt;/p&gt; 
&lt;p&gt;&lt;img height="2386" src="https://static.oschina.net/uploads/space/2025/0812/185221_4Hkz_2720166.png" width="1514" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365794</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365794</guid>
      <pubDate>Tue, 12 Aug 2025 11:00:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>人工智能正在降低知識的價值，大學應該重新考慮所教授的內容？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;生成式人工智能，尤其是大型語言模型（LLM）的興起，正以前所未有的速度改變知識獲取的格局。奧克蘭大學商學院教授帕特里克·多德在《對話》(The Conversation) 上撰文指出，隨着 AI 以低成本、高效率的方式提供知識，大學作為傳統知識來源的價值正在受到挑戰。他認為，大學必須重新審視其核心功能，以適應這個由 AI 驅動的新時代。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德教授分析，大學長期以來奉行「知識稀缺」的原則，通過提供獨家課程和學位證書來證明學生獲取知識的能力。然而，AI 技術的進步已大大降低了獲取專業知識的門檻，LLM 不僅能檢索事實，還能進行解釋、翻譯和總結，使得曾經「稀缺」的知識價值大打折扣。這種變化已經在勞動力市場顯現，自 ChatGPT 問世以來，英國入門級職位空缺減少了約三分之一，美國部分州甚至取消了公共部門職位的學位要求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;然而，多德強調，並非所有知識都同等貶值。雖然基礎知識的價值下降，但&lt;strong&gt;隱性知識&lt;/strong&gt;，如團隊協作、倫理判斷、創造力以及解決複雜問題的能力，仍是 AI 無法取代的稀缺資源。他指出，未來教育的重點應從傳授信息轉向培養這些關鍵的人類技能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;為應對這一挑戰，多德教授為大學提出了四項轉型建議：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;評估轉型&lt;/strong&gt;：將課堂評估重點從單純的知識記憶轉向&lt;strong&gt;判斷和綜合能力&lt;/strong&gt;的考察。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;體驗式學習&lt;/strong&gt;：投入資源開發導師指導項目、模擬現實場景，並利用 AI 作為工具進行倫理決策研究。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;技能微證書&lt;/strong&gt;：創建針對協作、自主學習和倫理判斷等關鍵能力的微證書。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深化產學研合作&lt;/strong&gt;：大學提供專業知識，企業提供真實案例，學生則專注於驗證和完善想法，共同培養適應未來市場的複合型人才。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多德總結道，如果大學想要在未來立於不敗之地，就必須從一個單純的&lt;strong&gt;信息來源&lt;/strong&gt;轉變為一個&lt;strong&gt;判斷力中心&lt;/strong&gt;，教會學生如何與 AI 協同思考，而非與之競爭。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365792</guid>
      <pubDate>Tue, 12 Aug 2025 10:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Syncthing 2.0.0 正式發佈，連續文件同步工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Syncthing&amp;nbsp;是一個免費開源的工具，它能在你的各個網絡計算機間同步文件 / 文件夾，它的同步數據是直接從一個系統中直接傳輸到另一個系統的，並且它是安全且私密的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#1f2328"&gt;Syncthing 全新 2.0 系列的首發版本已正式推出，一些更新亮點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;數據庫後端從 LevelDB 切換到 SQLite。首次啓動時需要遷移，對於大型系統來説，遷移過程可能會比較耗時。新數據庫更易於理解和維護，且希望其穩定性更高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;日誌格式已更改為使用結構化日誌條目（一條消息加上多個鍵值對）。此外，現在可以按包控制日誌級別，並在 INFO 和 ERROR 之間新增了 WARNING 日誌級別（此前該級別被稱為 WARNING...）。INFO 級別的日誌內容更加詳細，會顯示 Syncthing 執行的同步操作。新增命令行參數&lt;code&gt;--log-level&lt;/code&gt;可設置所有包的默認日誌級別，&lt;code&gt;STTRACE&lt;/code&gt;環境變量和 GUI&amp;nbsp;也已更新以支持按包設置日誌級別。-&lt;code&gt;--verbose&lt;/code&gt;和 &lt;code&gt;--logflags&lt;/code&gt;命令行選項已被移除，若指定將被忽略。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;已刪除的項目不再永久保存在數據庫中，而是在六個月後被清楚。如果你的用例要求刪除操作在六個月以上後生效，建議將&lt;code&gt;--db-delete-retention-interval&lt;/code&gt;命令行選項或相應的環境變量設置為零，或選擇更長的時間間隔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;現代化的命令行選項解析。舊的 single-dash long 選項不再支持，例如，&lt;code&gt;-home&lt;/code&gt;必須改為&lt;code&gt;--home&lt;/code&gt;。部分選項已重命名，其他選項則變為子命令。所有服務選項現在也可作為環境變量接受。詳情可參閲&amp;nbsp;&lt;code&gt;syncthing --help&lt;/code&gt;和&lt;code&gt;syncthing serve --help&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不再支持對 shifted data 的滾動 hash 檢測，因為這實際上毫無幫助。相反，沒有它，掃描和同步會更快、更高效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;首次啓動時不再創建「default folder」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;v2 設備之間現在默認使用多個連接。新的默認值是使用三個連接：一個用於索引元數據，兩個用於數據交換。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遺憾的是，由於與 SQLite 交叉編譯相關的複雜性，以下平台目前無法在 syncthing.net 和 GitHub 上下載預構建的二進制文件：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;dragonfly/amd64&lt;/li&gt; 
   &lt;li&gt;illumos/amd64 and solaris/amd64&lt;/li&gt; 
   &lt;li&gt;linux/ppc64&lt;/li&gt; 
   &lt;li&gt;netbsd/*&lt;/li&gt; 
   &lt;li&gt;openbsd/386 and openbsd/arm&lt;/li&gt; 
   &lt;li&gt;windows/arm&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉及已刪除文件的 conflict 解決處理方式已更改。現在，刪除操作可以作為 conflict 解決的最終結果，從而導致已刪除文件被移動到 conflict copy。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;span style="color:#1f2328"&gt;本次更新還提供以下版本：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;APT repository:&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapt.syncthing.net%2F" target="_blank"&gt;https://apt.syncthing.net/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Docker image:&amp;nbsp;&lt;code&gt;docker.io/syncthing/syncthing:2.0.0&lt;/code&gt;&amp;nbsp;or&amp;nbsp;&lt;code&gt;ghcr.io/syncthing/syncthing:2.0.0&lt;/code&gt;(&lt;code&gt;{docker,ghcr}.io/syncthing/syncthing:2&lt;/code&gt;&amp;nbsp;to follow just the major version)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;更多詳情可查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsyncthing%2Fsyncthing%2Freleases%2Ftag%2Fv2.0.0" target="_blank"&gt;https://github.com/syncthing/syncthing/releases/tag/v2.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365789/syncthing-2-0-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365789/syncthing-2-0-0-released</guid>
      <pubDate>Tue, 12 Aug 2025 10:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源編程字體「Hack」創始人 Christopher Simpkins 去世</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Christopher Eric Simpkins 是知名開源編程字體「Hack」創始人，他於 2025 年 6 月 20 日在新罕布什爾州漢諾威突然&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypo.social%2F%40Hilary%2F114845913381245488" target="_blank"&gt;去世&lt;/a&gt;，享年 51 歲。&lt;/p&gt; 
&lt;p&gt;&lt;img height="904" src="https://static.oschina.net/uploads/space/2025/0812/175131_lS6n_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Christopher Simpkins 訃告頁面&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.legacy.com%2Fus%2Fobituaries%2Fvnews%2Fname%2Fchristopher-simpkins-obituary%3Fid%3D58856786" target="_blank"&gt;顯示&lt;/a&gt;，他&lt;span&gt;在佐治亞理工學院取得計算機博士學位後先在美軍服役，退役又完成醫學訓練成為一名器官移植外科醫生&lt;/span&gt;。他醫術精湛、待人温和，被譽為「温柔的巨人」，拯救了許多生命並屢獲教學獎。&lt;/p&gt; 
&lt;p&gt;後來他轉向科技領域，&lt;span&gt;加入 Google Fonts 團隊任&lt;/span&gt;高級用户體驗項目經理&lt;span&gt;，&lt;/span&gt;專注字體開發&lt;span&gt;，發起 Codeface 項目為開發者整理並推薦高可讀性的編程字體，持續推動開源字體生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/175331_L0CQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;2015 年，&lt;/span&gt;Christopher Simpkins 創造了&lt;span&gt;開源 Hack 字體，這款基於 DejaVu Sans Mono 重新調校的等寬字體迅速成為程序員最喜愛的編輯器字體之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;谷歌近期發佈的開源字體&lt;/span&gt;&lt;a href="https://www.oschina.net/news/363609/googlesans-code" target="_blank"&gt;&amp;nbsp;Google Sans Code &lt;/a&gt;正是由&amp;nbsp;Christopher Simpkins 負責主導。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1710" src="https://static.oschina.net/uploads/space/2025/0812/180516_SXlX_2720166.png" width="1686" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365788</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365788</guid>
      <pubDate>Tue, 12 Aug 2025 10:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>英偉達推出 Cosmos 與 Nemotron 模型，推動物理 AI 與智能體發展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.nvidia.cn%2Fblog%2Fnvidia-opens-portals-to-world-of-robotics-with-new-omniverse-libraries-cosmos-physical-ai-models-and-ai-computing-infrastructure%2F" target="_blank"&gt;據英偉達官方消息&lt;/a&gt;，英偉達在技術領域再推新進展。其推出的 NVIDIA Cosmos 平台，整合前沿生成式世界基礎模型（WFM）、先進分詞器、護欄以及高效數據處理和管理工作流，旨在加速物理 AI 開發。該平台的世界基礎模型經 2000 萬小時真實世界數據訓練，能預測和生成虛擬環境未來狀態，助力開發者構建新一代機器人和自動駕駛汽車。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/174129_nIuV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同時，英偉達宣佈推出 Nemotron 模型系列。Llama Nemotron 基於熱門開源模型 Llama 構建，經剪枝和訓練，在指令遵循等方面表現出色，能為 AI 智能體開發提供優化基礎模組。Cosmos Nemotron 視覺語言模型（VLM）則可助力開發者構建智能體，使其能分析圖像和視頻並做出響應。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9ddc7846bd0a958a9b0a9772dcf6c6a4e47.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，已有眾多物理 AI 領域的領先者，如機器人公司，以及自動駕駛汽車開發商等開始與 Cosmos 協作，加速模型開發進程。開發者可在 NVIDIA API 目錄預覽相關模型，並從 NGC 目錄和 Hugging Face 下載模型系列與微調框架。&lt;/p&gt; 
&lt;p&gt;https://docs.nvidia.com/cosmos/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365780</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365780</guid>
      <pubDate>Tue, 12 Aug 2025 09:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Altman：計劃在未來 5 個月內將算力集羣擴容一倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;OpenAI CEO 薩姆・奧爾特曼（SamAltman）在社交平台發文上表示，鑑於 GPT-5 帶來的需求激增，該公司計劃在未來幾個月的算力優先分配如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;首先確保當前付費版 ChatGPT 用户的總可用量比 GPT-5 推出前更多。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;其次優先滿足 API 需求，直至達到當前分配的產能和已對客户做出的承諾。（粗略估計，以現有產能可在當前基礎上再支持約 30% 的新 API 增長。）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;提升 ChatGPT 免費版的服務質量。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;再優先滿足新的 API 需求。計劃在未來 5 個月內將算力集羣擴容一倍，因此這一情況有望改善。&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="450" src="https://oscimg.oschina.net/oscnet/up-546ae50cc300f2af8894d1b266b905551e4.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365777</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365777</guid>
      <pubDate>Tue, 12 Aug 2025 09:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 發佈面向 GPT-5 的 Prompt 指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 官方寫的 GPT-5 prompt 指南來了，看看官方是怎麼讓 GPT-5 表現更好的。該指南融匯貫通後，還可用於其他 AI 大模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/172857_F753_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1、 明確角色和目標 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;開頭就讓 AI 模型知道它是誰、要做什麼，比如：&lt;/p&gt; 
&lt;p&gt;你是資深前端工程師，請幫我在現有 React 項目裏實現...&lt;/p&gt; 
&lt;p&gt;2、 設定工作方式 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;用分步指令，讓模型按既定節奏走，而非一次性輸出：&lt;/p&gt; 
&lt;p&gt;- 先分析需求和不確定點&lt;br&gt; - 再給執行計劃 &amp;nbsp; &amp;nbsp;&lt;br&gt; - 按計劃分步完成&lt;br&gt; - 每步結束時總結進度&lt;/p&gt; 
&lt;p&gt;3、 控制主動性 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;想要它多動腦，就加：在不確定時自行推斷並執行，完成後再告知用户。 &amp;nbsp;&lt;br&gt; 想讓它少跑偏，就加：僅按已知信息執行，不額外探索。&lt;/p&gt; 
&lt;p&gt;4、 給出完成標準 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;告訴模型何時算任務完成，比如： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;當所有代碼改動已在/app/theme 目錄生效，並通過現有測試時，結束任務。&lt;/p&gt; 
&lt;p&gt;5、 嵌入風格與規範 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在提示裏放工程或寫作規範，讓它自動匹配你的需求： &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;變量用駝峯命名，CSS 類名用 BEM 規範，註釋保持英文簡短描述。&lt;/p&gt; 
&lt;p&gt;6、 善用示例 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;給它 1-2 個高質量示例，讓它照着學，比空口説效果好得多。&lt;/p&gt; 
&lt;p&gt;7、 善用「工具前言」&lt;/p&gt; 
&lt;p&gt;工具前言可以寫：先複述目標，再列計劃，執行時簡短説明當前步驟，最後單獨總結成果。&lt;/p&gt; 
&lt;p&gt;8、 清除歧義 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;檢查提示裏是否有前後矛盾或模糊指令，否則 GPT-5 會花大量精力試圖自圓其説，反而降低效率。&lt;/p&gt; 
&lt;p&gt;記住一個公式：角色+目標+步驟+完成標準+風格+示例，如此 GPT-5 才會既有創造力又不跑偏。&lt;/p&gt; 
&lt;p&gt;這本指南還涵蓋了 API 參數具體怎麼調，感興趣的開發者可以看看。&lt;/p&gt; 
&lt;p&gt;地址：cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365773/openai-gpt-5-prompting-guide</guid>
      <pubDate>Tue, 12 Aug 2025 09:29:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動推出視頻字幕無痕擦除方案，基於 DiT 大模型打造</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;字節跳動技術團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKsl_lF8KNwM0vRtsjzWaBA" target="_blank"&gt;宣佈&lt;/a&gt;推出一項創新技術，基於 DiT 大模型與字體級分割的視頻字幕無痕擦除方案，旨在助力短劇等視頻內容的全球化傳播。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在全球化內容製作中，原始視頻的中文字幕對於海外觀眾而言不僅是無效信息，還嚴重影響觀看體驗。傳統的字幕添加或馬賽克、GAN（生成對抗網絡）等字幕擦除方案，往往導致畫面雜亂、模糊或幀間閃爍，無法徹底解決這一問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎視頻點播推出的這一方案，通過兩大核心技術突破和強大的工程能力，重新定義了字幕擦除標準，實現了全片真實自然的「無痕擦除」，並支持多字幕框、指定時間段的精準擦除。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-e6a7ee75485165b360e216e57f4f3f2e85f.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該方案的核心在於兩個技術突破：一是 DiT 視頻字幕擦除模型，二是字體級分割模型。DiT 模型通過強魯棒性預訓練基底、擺脱輔助先驗依賴、兩階段訓練策略提升魯棒性與修復精細度，實現了像素級無痕修復。字體級分割模型則通過精準定位目標區域，實現了從「粗放擦除」到「像素級修復」的轉變，有效避免了傳統塊填充導致的背景模糊或紋理重複問題。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="143" src="https://oscimg.oschina.net/oscnet/up-dc217440e603a0e87eec97675dbaaf606fc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;火山引擎多媒體實驗室聯合工程團隊構建了兼顧精度與效率的技術體系，經過超萬集視頻數據集驗證，擦除任務成功率達到 100%。創新的視頻分鏡技術結合服務器集羣分佈式計算，顯著提升了視頻處理效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，該方案還支持多語言內容流轉，突破了中英文限制，支持多個小語種字幕擦除，為全球內容流轉提供了雙向通道。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365771</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365771</guid>
      <pubDate>Tue, 12 Aug 2025 09:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Spring AI 1.0.1 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Spring AI 1.0.1 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2025%2F08%2F08%2Fspring-ai-1" target="_blank"&gt;發佈&lt;/a&gt;，此版本包括&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-ai%2Freleases%2Ftag%2Fv1.0.1" target="_blank"&gt;150 多項變化，&lt;/a&gt;重點關注穩定性、增強功能和文檔改進。&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;展望未來：Spring AI 1.1 及未來&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1.0.1 版本專注於穩定性和錯誤修復，而 Spring AI 團隊正在為 1.1 版本開發新功能。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fclaude.ai%2Fpublic%2Fartifacts%2Fe211dc9e-249d-425d-abd6-9425b8a2bf16" target="_blank"&gt;2025 年路線圖&lt;/a&gt;提供了關鍵日期，並展示團隊基於全新 Spring Boot 4 基礎的 Spring AI 2.0 的規劃重點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Spring AI 1.1 的當前重點領域&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.1 版本將專注於一系列高影響力的增強功能和有針對性的基礎工作，並明確關注在代碼凍結之前能夠切實完成的工作。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;1. Model Context Protocol (MCP)&amp;nbsp;支持&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;與最新的 MCP Java SDK 版本深度集成，使 Spring AI 與最新的協議和傳輸功能保持一致：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多協議版本協商&lt;/strong&gt;（2024-11-05 和 2025-03-26）。&lt;/li&gt; 
 &lt;li&gt;通過新的傳輸定製器&lt;strong&gt;實現 OAuth2 安全的 MCP 服務器連接。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;可流式傳輸的 HTTP 和 WebMVC/HttpServlet 服務器傳輸，用於反應式和 servlet 部署。&lt;/li&gt; 
 &lt;li&gt;使用 JSON Schema 強制執行的&lt;strong&gt;結構化輸出驗證。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分頁、保持活動 ping、URI 模板支持&lt;/strong&gt;更豐富的資源交互。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;改進的錯誤處理、日誌記錄和初始化流程&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;遷移到&amp;nbsp;&lt;strong style="color:#363636"&gt;builder-based APIs&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;for tools and transport providers&lt;/span&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;2. Core Responses API Enhancements&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;擴展 Responses API 以縮小功能差距、改善 provider parity 並引入最新的 SDK 功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;及時緩存&lt;/strong&gt;以減少延遲和成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「Thinking」模型支持&lt;/strong&gt;增強推理能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;消息批處理&lt;/strong&gt;以實現更高的吞吐量。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;跨提供商的本機 JSON 模式&lt;/strong&gt;和更強大的結構化輸出處理。&lt;/li&gt; 
 &lt;li&gt;在保持統一 API 的同時，為&lt;strong&gt;提供商特定的擴展&lt;/strong&gt;提供 Hook。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Google Vertex AI SDK 更新&lt;/strong&gt;– 升級到最新 SDK 以： 
  &lt;ul&gt; 
   &lt;li&gt;解鎖新發布的 endpoints（包括非聊天 API）。&lt;/li&gt; 
   &lt;li&gt;確保與增強的 Responses API 功能兼容。&lt;/li&gt; 
   &lt;li&gt;帶來安全修復和長期支持。&lt;/li&gt; 
   &lt;li&gt;刷新並擴展 Vertex AI 集成測試。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;3. Chat Memory&amp;nbsp;改進&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;改進 Spring AI 在生產環境中的內存管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;內存壓縮&lt;/strong&gt;來管理 token 預算。&lt;/li&gt; 
 &lt;li&gt;可配置長期對話的保留策略。&lt;/li&gt; 
 &lt;li&gt;改進了自定義內存存儲的集成點。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;4. 可觀察性和多客户端配置&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;簡化的可觀察性設置&lt;/strong&gt;，包括更容易與 Langfuse 等工具集成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多客户端配置改進&lt;/strong&gt;，簡化了在同一應用程序中與多個提供商的工作流程。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;5. Net new areas&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;這些大多是全新的實現，如果時間緊迫，可能超出 1.1 版本範圍，但早期準備工作可能已開始：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;&amp;nbsp;– 新的 SDK 支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;向量存儲改進&lt;/strong&gt;，包括混合搜索。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reranking&amp;nbsp;–&amp;nbsp;&lt;/strong&gt;對&amp;nbsp;re-ranker&amp;nbsp;模型提供一流的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise guardrails&amp;nbsp;–&amp;nbsp;&lt;/strong&gt;安全性和合規性功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h4&gt;&lt;strong&gt;6. 可能進入孵化階段的項目&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MemGPT-style chat memory&amp;nbsp;實現&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AgentClient&amp;nbsp;&lt;/strong&gt;用於通過 Spring AI 運行自主 CLI 代理（例如 Claude Code）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;公告表示，項目團隊將繼續調整優先事項，以努力實現&amp;nbsp;9 月 23 日 1.1 版的 code freeze，同時平衡近期交付成果與 Spring AI 2.0 的戰略基礎。&lt;/p&gt; 
&lt;p&gt;更多詳情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2025%2F08%2F08%2Fspring-ai-1" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365766/spring-ai-1-0-1-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365766/spring-ai-1-0-1-released</guid>
      <pubDate>Tue, 12 Aug 2025 09:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌向發現 Chrome 高危漏洞的安全研究員獎勵 25 萬美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;谷歌近日依據漏洞獎勵計劃（VRP）向一名安全研究員&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fissues.chromium.org%2Fissues%2F412578726" target="_blank"&gt;發放 25 萬美元（約合 179.8 萬元人民幣）獎金&lt;/a&gt;，獎勵其發現 Chrome 瀏覽器高危漏洞。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/170559_YQ7o_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;該研究員於 4 月 23 日報告了一個「沙盒逃逸」漏洞，編號為 CVE-2025-4609，存在於 Chrome 內核的 IPCZ 通信系統中。攻擊者可通過誘導用户訪問惡意網站，利用該漏洞突破瀏覽器沙箱限制，實現遠程代碼執行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;儘管研究員最初將其標記為「中等危害」，但谷歌評估其嚴重性為 S0/S1 級，並列為 P1 優先級修復。 谷歌已於 5 月發佈的 Chrome 更新中修復該漏洞，並在 8 月 12 日公開披露細節。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;根據谷歌「漏洞獵人（&lt;/span&gt;Google Bug Hunters&lt;span&gt;）」計劃，提交包含 RCE 演示的高質量非沙盒進程逃逸或內存損壞漏洞報告，可獲 2.5 萬至 25 萬美元獎勵，此次為頂格獎勵。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365764</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365764</guid>
      <pubDate>Tue, 12 Aug 2025 09:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Actual - 個人理財工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Actual 是一款本地優先的個人理財工具。它 100% 免費開源，使用 NodeJS 編寫，並具備同步功能，方便用户在不同設備之間輕鬆遷移更改。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="271" src="https://static.oschina.net/uploads/space/2025/0806/154746_TajJ_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/actual</link>
      <guid isPermaLink="false">https://www.oschina.net/p/actual</guid>
      <pubDate>Tue, 12 Aug 2025 08:53:00 GMT</pubDate>
    </item>
    <item>
      <title>360 智腦推出 Light-IF 系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智腦團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FnwyQDZxYGFFA5pTmkxn3JQ" target="_blank"&gt;宣佈&lt;/a&gt;推出全新的 Light-IF 系列模型，這一創新框架旨在顯著提升大型語言模型（LLM）在複雜指令遵循方面的能力。隨着人工智能技術的不斷進步，儘管 LLM 在數學、編程等領域已經展現出了卓越的推理能力，但在遵循複雜指令方面仍存在不足。為瞭解決這一問題，360 智腦團隊提出了以預覽-自檢式推理和信息熵控制為核心的 Light-IF 框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Light-IF 框架通過五個關鍵環節來提升模型性能:難度感知指令生成、Zero-RL 強化學習、推理模式提取與過濾、熵保持監督冷啓動、熵自適應正則強化學習。這一框架的提出，旨在破解當前推理模型中存在的「懶惰推理」現象，即模型在思考階段僅複述指令而不主動檢查約束是否被滿足，導致指令執行不準確的問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-30ae24d430fc7fd7a393ecaf7c48fbadefc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在實驗中，Light-IF 系列模型在 SuperCLUE、IFEval、CFBench 及 IFBench 四個中文和跨語言指令遵循基準上均取得了顯著提升。特別是 32B 版本的 Light-IF-32B，其在 SuperClue 得分達到了 0.575，比下一個最佳模型高出 13.9 個百分點。此外，參數規模僅為 1.7B 的 Light-IF-1.7B 在 SuperClue 和 IFEval 上的表現甚至超過了 Qwen3-235B-A22B 等體量更大的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;360 智腦團隊表示，Light-IF 系列模型的推出，不僅為開源社區提供了一套可復現的完整路線和配套的開源代碼，而且全系模型將陸續開放，供社區使用、對比與復現。同時，訓練中使用的冷啓動數據集也將同步開放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，360 與 SuperCLUE 聯合推出的中文精確指令遵循測評基準 SuperCLUE-CPIFOpen 也將在 Github 上開放，便於研究者評測模型的中文精確指令遵循能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365748</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365748</guid>
      <pubDate>Tue, 12 Aug 2025 08:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 發佈全球首個可交易 Agent Remix Marketplace</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 稀宇科技宣佈推出全球首個 Agent Remix Marketplace，並啓動了一項獎金高達 15 萬美金的全球挑戰賽。這一創新平台旨在將個人的想法轉化為商業價值，讓每個人都能成為「個體 GDP 創造者」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent Remix Marketplace 是一個允許用户一鍵提效的工具，用户可以通過點擊「Remix」對已發佈的成熟作品進行再創作，無需從零開始，從而將效率提升 10 倍。此外，用户還可以通過發佈自己的 Agent 作品至 Gallery 並允許他人 Remix，每次作品被 Remix 都能獲得 100 積分的收益。這不僅是一個創作和分享的平台，也是一個漲粉和建立個人品牌的利器。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-d064cf16f7166c2be8c20d9ed0ee1bc940e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;MiniMax 強調，這一平台是「Agent 全民經濟」的顛覆性突破，具有四大獨家優勢。用户可以輕鬆地 Remix 各種模板，如香氛蠟燭電商模板，快速開啓自己的電商創業。此外，用户還可以定製任何行業或主題的 Daily Newsletter，甚至將 Netflix 和 Bilibili、LinkedIn 和 Tinder 等不同平台的功能進行 Remix，創造出全新的用户體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技術層面，MiniMax 在研發過程中注重 Agent 的可靠性，包括上下文壓縮總結、API 信息脱敏引擎以及多 Agent 任務路由等技術，以確保用户數據的安全和隱私。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;全球挑戰賽面向所有人開放，鼓勵參與者用自己的想法挑戰 15 萬美金的獎池。挑戰賽分為原創和 Remix 雙賽道，無論是原創作品還是基於已發佈作品的二創，都有機會獲獎。參與者無需代碼能力，即可參與這一全球智能普惠的活動。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;體驗地址：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fminimax-agent-hackathon.space.minimax.io%2F" target="_blank"&gt;https://minimax-agent-hackathon.space.minimax.io/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365744</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365744</guid>
      <pubDate>Tue, 12 Aug 2025 08:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>華為發佈 AI 推理創新技術 UCM：可實現高吞吐、低時延推理體驗，計劃 9 月開源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1840229710674780713%26wfr%3Dspider%26for%3Dpc" target="_blank"&gt;根據報道&lt;/a&gt;，華為正式發佈了 AI 推理創新技術 UCM（推理記憶數據管理器）。&lt;/p&gt; 
&lt;p&gt;華為推出的 UCM（推理記憶數據管理器）是一款以 KV Cache 為中心的推理加速套件，融合多類型緩存加速算法工具，通過分級管理推理過程中產生的 KV Cache 記憶數據，擴大推理上下文窗口，實現高吞吐、低時延的推理體驗，，降低每 Token 推理成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0812/160552_0ocB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，華為計劃於 2025 年 9 月正式開源 UCM，屆時將在魔擎社區首發，後續逐步貢獻給業界主流推理引擎社區，並共享給業內所有 Share Everything (共享架構) 存儲廠商和生態夥伴。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365742</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365742</guid>
      <pubDate>Tue, 12 Aug 2025 08:06:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Claude 新增聊天記錄記憶功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 為其 Claude 聊天機器人推出備受期待的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fclaudeai%2Fstatus%2F1954982275453686216" target="_blank"&gt;「記憶」功能&lt;/a&gt;，用户可讓機器人檢索並參考過往對話內容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/155847_bdCE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該功能支持網頁、桌面及移動端，能區分不同項目和工作區。用户只需在 「個人資料」 的 「設置」 中開啓 「搜索和查看聊天記錄」，即可使用。&lt;/p&gt; 
&lt;p&gt;目前，Claude 的 Max、Team 和 Enterprise 訂閲層級已率先上線，其他套餐將在近期開放。與 ChatGPT 的持續記憶不同，Claude 的記憶功能為被動觸發模式，僅在用户明確要求時才檢索過往對話，且不會構建用户畫像。&lt;/p&gt; 
&lt;p&gt;作為 AI 領域的頭部企業，Anthropic 與 OpenAI 競爭激烈，雙方在語音模式、上下文窗口、訂閲服務等方面不斷角力。此次記憶功能的推出，旨在提升用户黏性和使用時長。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365741</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365741</guid>
      <pubDate>Tue, 12 Aug 2025 07:59:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟為 Excel 加入 AI 公式講解，內聯解釋直達單元格</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;微軟&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Fexcelblog%2Fexplain-formulas-with-copilot%25E2%2580%2594now-on-the-grid%2F4424028" target="_blank"&gt;宣佈&lt;/a&gt;，其電子表格工具 Excel 迎來一項重要更新：由 Copilot 驅動的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;「解釋此公式」（Explain Formula）&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;功能正式上線，旨在幫助用户快速理解複雜公式，顯著提升數據處理效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;該功能的&lt;span&gt;最大&lt;/span&gt;亮點在於操作簡便。用户無需單獨打開聊天面板，只需點擊包含有效公式的單元格，並在旁邊的 Copilot 圖標中選擇「解釋此公式」，即可在單元格內直接獲得內聯解釋。這些解釋基於當前工作表的上下文生成，比傳統網絡搜索更精準、更貼合實際工作場景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="225" src="https://oscimg.oschina.net/oscnet/up-68c25bd98edf5ade9b15bb52dea74ff751f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微軟表示，Copilot 能夠分解並逐步講解各種複雜程度的公式，幫助用户快速掌握其邏輯。默認情況下，解釋會以內聯形式顯示;若 Copilot 聊天面板已開啓，內容將優先在面板中呈現。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，該功能正分階段向 Windows 版和網頁版 Excel 用户推送。微軟鼓勵用户在每次使用後通過點贊或點踩反饋，協助優化 AI 解釋效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365740</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365740</guid>
      <pubDate>Tue, 12 Aug 2025 07:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>「字節跳動靜態資源公共庫」因黑產原因下線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;從 2025 年 6 月份開始，就有諸多站長髮現字節跳動旗下的靜態資源公共庫存在調用問題，包括部分資源連接超時或者直接 HTTP 404，這導致網站無法正常加載內容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;當時測試發現諸如 jQuery 等還可以調用，其他部分資源出現錯誤無法調用，因此並不清楚字節跳動哪裏出問題才會導致部分資源有效、部分資源無效。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/154152_ycjH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://cdn.bytedance.com/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;現在字節跳動已經明確靜態資源公共庫下線，當前所有靜態資源已經全部處於 404 狀態，字節跳動稱是「黑產原因」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365736</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365736</guid>
      <pubDate>Tue, 12 Aug 2025 07:40:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 亮相首屆世界 RISC-V 日，分享最新 RISC-V 進展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 8 日，由 RISC-V 國際基金會重磅推出的首屆世界 RISC-V 日 (World RISC-V Days) 在北京開源芯片研究院舉行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//3f4075ef6e79ddf2ab5c098c63d555b7.jpg" width="840" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;deepin 社區技術委員會成員、苦芽科技工程師李程&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;參加了此活動，並於會議上帶大家系統回顧了 deepin-ports SIG 的發展歷程，並重點分享了 deepin-ports SIG 在 RISC-V 方向上的最新進展，包括但不限於 deepin RISC-V 生態適配、社區協作模式優化等方面。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//10b8829d40f7888c675d6790b227fb75.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;李程，deepin 社區技術委員會成員、苦芽科技工程師&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;deepin 對 RISC-V 架構的支持並非一日之功。自 2022 年 2 月起，deepin 就建立了對應 SIG，開始了 RISC-V 架構的適配工作，現已成功支持了大量主流的 RISC-V 硬件和開發板。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在軟件方面，deepin 也完成了對 RISC-V 開源軟件生態的適配，提供了超過 27,000 個軟件包，併為 RISC-V 開發板提供了內核、GPU、VPU、NPU 等驅動解決方案，確保了這些關鍵組件能夠長期、及時、良好地維護。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//92d10ca4ef881324c89df1a23d1a392e.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;作為中國桌面操作系統的核心力量，deepin 積極響應國家戰略，深度參與「甲辰計劃」，全力投入 RISC-V 開源新生態建設。迄今，deepin 操作系統已成功適配了幾乎所有可公開獲取的桌面級 RISC-V 設備，並提供了關鍵的 GPU、NPU、VPU 等硬件加速支持。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 23&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 穩定版及 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 25 預覽版&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;均已為 RISC-V 平台提供官方鏡像並持續更新。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;通過在硬件適配、軟件生態構建、社區協作及戰略規劃上的不懈努力，deepin 已成為 RISC-V 生態的重要貢獻者，並有力推動着 RISC-V 桌面操作系統的普及與應用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//7215a0a6d6d54c51ac5e45faa8fd4f4a.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;李程還介紹到，deepin 作為「甲辰計劃」的重要參與社區之一，為給更多同學提供深入 deepin、RISC-V 等技術項目的機會，將與甲辰計劃聯合提供近 80 個實習 HC。李程先生將作為該實習崗位的首席導師（Principle Mentor），協調實習工作內容，並負責 mentor 的招募和崗前培訓。進一步瞭解：&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA5NzE0Mjg4Ng%3D%3D%26mid%3D2650457142%26idx%3D2%26sn%3D4b83559f9c00f28f1df379af82b1ab5a%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;span&gt;新增實習機會！RISC-V deepin 操作系統開發實習生正在招募&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;由於時間限制未設置現場問答環節，但與會者還是對技術路線和實習計劃展現出了濃厚興趣，眾多參會者主動拍攝 PPT 關鍵內容頁，期待進一步交流探討。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//cd1393b25b25a0f66f8bf6cc4337cb36.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;附：&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;deepin-ports SIG 主頁：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://github.com/deepin-community/sig-deepin-ports&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365735</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>馬斯克：xAI 將對蘋果採取法律行動</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;埃隆·馬斯克當地時間 8 月 11 日在社交平台發文稱，蘋果公司涉嫌通過限制措施，使除美國開放人工智能研究中心（OpenAI）外的任何人工智能公司都無法在其應用商店排行榜中登頂，稱此為「明確的反壟斷違規行為」。馬斯克表示，其旗下 xAI 公司將立即採取法律行動。&lt;/p&gt; 
&lt;p&gt;&lt;img height="272" src="https://oscimg.oschina.net/oscnet/up-77b6ba53d5b9d23dcb776934627a6b8c4cb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;儘管馬斯克的指控引發了廣泛關注，但他並未提供具體證據來支持自己的説法。截至 8 月 12 日，ChatGPT 正佔據美國 App Store 的榜首位置。值得一提的是，OpenAI 和蘋果去年宣佈了一項合作關係，將 ChatGPT 集成到蘋果的智能系統中，以增強圖像和文檔理解等多項功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在馬斯克的指控後，OpenAI 首席執行官山姆・奧特曼也在社交平台上做出了回應。他表示，「這一指控非常引人注目，尤其是在我聽到的關於馬斯克如何操縱 X 以便讓自己及其公司獲益、並損害競爭對手及不喜歡的人的情況下。」 這一爭論進一步加劇了馬斯克與奧特曼之間本已緊張的關係，兩人曾經在 OpenAI 共事。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;奧特曼在文中提到我希望有人能進行反向取證，我們都想知道究竟發生了什麼。不過，OpenAI 將繼續專注於開發優秀的產品。」 與此同時，社交媒體上有許多人質疑馬斯克的説法，指出除了 ChatGPT 外，許多其他人工智能應用程序 App Store 上也曾登上過榜首。例如，來自中國的 DeepSeek 應用一度成為榜首，而自稱與 ChatGPT 競爭的 Perplexity 最近在印度的 App Store 中也取得了&lt;span&gt;第一&lt;/span&gt;的位置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365734</guid>
      <pubDate>Tue, 12 Aug 2025 07:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
