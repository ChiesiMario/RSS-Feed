<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 07 Aug 2025 07:43:24 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Cursor 設計負責人分享：軟件工程師（或任何人）如何提升設計水平？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;我經常被問到這個問題。作為一個從計算機科學（CS）轉型做設計的人，我想分享一條切實可行的路徑：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;從系統思維開始&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;工程師們對此已經很熟悉了。設計，只不過是為人類和我們的感官（而非機器）打造的系統。如果你還沒讀過，可以去讀一讀《系統之美》（Thinking in Systems）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;學習基礎知識&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;人類經過幾個世紀的進化，已經形成了一套用於視覺化呈現和接收信息的系統。即使是命令行界面（CLI），也無法避開這些法則：&lt;/p&gt; 
&lt;p&gt;字體排印 — 從 Jost Hochuli 的《Details in Typography》開始。 色彩基礎 — 從 Josef Albers 的《色彩構成》(Interaction of Color) 開始。 網格系統 — 從 Josef Müller-Brockmann 的《平面設計中的網格系統》(Grid Systems) 開始。&lt;/p&gt; 
&lt;p&gt;視覺層次、閲讀節奏、符號與概念系統、動效、無障礙設計…… — 隨着實踐，你會掌握更多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;敞開你的雙眼和大腦&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;觀察你周圍的事物，無論是數字世界還是自然界。觀察萬物中的美與共通之處，思考它為何被設計成這樣。在你的觀察、思考和創造之間建立聯繫。打破僵化、線性的思維，釋放自己。凝望天空，放空自己。洞悉萬物。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然後，放手去創造&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;既然你已經開始留意，那就試着去改進事物，先用你自己的方式。重新設計你日常使用的應用。逐像素地復刻你喜愛的設計——這樣一週學到的東西比你看幾個月理論還多。然後，將你的作品分享給他人，獲取反饋，併為更多人設計。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;關鍵心態轉變：感受先行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;停止為計算機優化，開始為人類優化。工程師考慮的是邊緣情況（edge cases）和錯誤狀態，而設計師考慮的是理想路徑（happy paths）和情感體驗。對人類來説，最終的感受以及事物如何融為一體，遠比邊緣情況重要得多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具沒那麼重要&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Figma 是行業標準。一個週末就能學會（它基本上就是可視化的 Flexbox）。你可以用 Cursor 這類工具來拆解現有設計系統並製作原型，研究它們是如何構建的——前端技術在這裏大有可為。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最重要的一點&lt;/strong&gt;：通過約束找到你自己的設計語言。 選擇一款出色的字體，一套有限的調色板，然後用它們做出 10 種不同的佈局。約束催生創造力。而迭代是達成目標的途徑。&lt;/p&gt; 
&lt;p&gt;優秀的工程師已經理解系統、邏輯和解決問題的方法。他們只需將這些能力應用到人的概念和問題上，而不是技術問題上。&lt;/p&gt; 
&lt;p&gt;從明天開始。重新設計你的個人網站或一個簡單的應用。完成它，分享它，不斷重複。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：x.com/ryolu_/status/1952759102058242253&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364816</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364816</guid>
      <pubDate>Thu, 07 Aug 2025 07:35:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>摩爾線程 MUSA 架構成功適配開源推理框架 llama.cpp</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MUSA（Meta-computing Unified System Architecture）是摩爾線程自主研發的通用並行計算架構。官方近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1qctAz4EUq%2F"&gt;宣佈&lt;/a&gt;&amp;nbsp;MUSA&amp;nbsp;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;已正式完成與開源推理框架 llama.cpp 的適配，進一步融入全球 AI 生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-21f1f791376efc2c7275c63eb22cf6de3a0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;llama.cpp 作為純 C/C++ 實現的大語言模型推理工具，以輕量化部署和跨硬件兼容性著稱，支持 LLaMA、Mistral 等主流模型及多模態應用。此次適配意味着用户可在 MTT S80/S3000/S4000 系列 GPU 上通過官方容器鏡像高效運行 AI 推理。&lt;/p&gt; 
&lt;p&gt;今年 4 月，MUSA SDK 4.0.1 已擴展至 Intel 處理器與國產海光平台，此次與 llama.cpp 的聯動，進一步降低了開發者部署大模型的門檻，為本土 AI 硬件生態注入新動能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364814</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364814</guid>
      <pubDate>Thu, 07 Aug 2025 07:23:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>小紅書開源多模態大模型 dots.vlm1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;小紅書 Hi Lab 開源了其首個自研多模態大模型&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;。該模型基於 12 億參數的&amp;nbsp;&lt;strong&gt;NaViT 視覺編碼器&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;DeepSeek V3 大語言模型&lt;/strong&gt;，從零開始完全訓練，其卓越性能在多模態視覺理解與推理能力上已接近當前領先的閉源模型，如&amp;nbsp;&lt;strong&gt;Gemini2.5Pro&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;Seed-VL1.5&lt;/strong&gt;，標誌着開源多模態模型的性能達到了新的高度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;dots.vlm1 的核心亮點在於其原生自研的&amp;nbsp;&lt;strong&gt;NaViT 視覺編碼器&lt;/strong&gt;。與傳統基於成熟模型微調的方式不同，NaViT 從零訓練，並支持動態分辨率，能夠更好地適應多樣化的真實圖像場景。該模型還通過結合純視覺與文本視覺的雙重監督，極大提升了其泛化能力，尤其是在處理表格、圖表、公式、文檔等非典型結構化圖片時表現出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在數據方面，Hi Lab 團隊構建了規模龐大且清洗精細的訓練集。他們通過自主重寫網頁數據和自研&amp;nbsp;&lt;strong&gt;dots.ocr&lt;/strong&gt;&amp;nbsp;工具處理 PDF 文檔，顯著提升了圖文對齊的質量，為模型的跨模態理解能力打下了堅實基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;評測結果表明，dots.vlm1 在&amp;nbsp;&lt;strong&gt;MMMU&lt;/strong&gt;、&lt;strong&gt;MathVision&lt;/strong&gt;&amp;nbsp;和&amp;nbsp;&lt;strong&gt;OCR Reasoning&lt;/strong&gt;&amp;nbsp;等多項基準測試中，達到了與 Gemini2.5Pro 和 Seed-VL1.5 相當的水平。在複雜的圖表推理、STEM 數學推理以及長尾細分場景識別等應用中，dots.vlm1 展現出卓越的邏輯推理和分析能力，完全勝任奧數等高難度任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="527" src="https://oscimg.oschina.net/oscnet/up-6e01b7f98f74ddc0a373242bba0c2e628a3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管在文本推理的極複雜任務上與 SOTA 閉源模型仍有差距，但其通用數學推理和代碼能力已與主流大語言模型持平。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Hi Lab 團隊表示，未來將繼續優化模型。他們計劃擴大跨模態數據規模，並引入強化學習等前沿算法，進一步提升推理泛化能力。通過開源&amp;nbsp;&lt;strong&gt;dots.vlm1&lt;/strong&gt;，小紅書致力於為多模態大模型生態系統帶來新的動力，推動行業發展。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364810</guid>
      <pubDate>Thu, 07 Aug 2025 07:08:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>日本政府禁止蘋果在 iOS 平台限制第三方瀏覽器引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;span&gt;日本政府已通過《智能手機法》（正式名稱為《&lt;/span&gt;Bill on the Promotion of Competition for Specified Software Used in Smartphones&lt;span&gt;》）及其配套的《移動軟件競爭法》（MSCA）指南，正式禁止蘋果在 iOS 平台上限制第三方瀏覽器引擎，要求&lt;/span&gt;蘋果 iOS 必須在今年 12 月前解除瀏覽器引擎禁令，必須允許第三方瀏覽器使用自己的引擎（如 Blink、Gecko）。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1832" src="https://static.oschina.net/uploads/space/2025/0807/145413_X9Uj_2720166.png" width="1316" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://www.jftc.go.jp/file/MSCA_Guidelines_tentative_translation.pdf&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;配套要求&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;禁止設置技術或財務上的不合理障礙；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;禁止引導用户遠離非 WebKit 瀏覽器；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要求設備首次激活時立即彈出瀏覽器選擇界面，確保用户能明確選擇；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;瀏覽器開發者必須獲得與 Safari 同等水平的系統 API 訪問權限。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據瞭解，&lt;span&gt;蘋果以「安全與隱私」為由，強制所有運行在 iOS 的瀏覽器（比如&amp;nbsp;&lt;/span&gt;Firefox、Chrome、Edge、Opera、Brave&lt;span&gt;）必須使用 WebKit 引擎，導致這些瀏覽器本質上都是「Safari 換皮」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Open Web Advocacy 組織參與了法律諮詢並協助制定政府最終報告，該組織昨天在其官網發佈的聲明稱：「蘋果通過強制使用 WebKit，實際上禁止了 iOS 上獨立瀏覽器的發展。新的法律不僅禁止了明令禁止的行為，也禁止了那些讓替代引擎難以運行的做法。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364809</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364809</guid>
      <pubDate>Thu, 07 Aug 2025 07:06:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Character.AI 發佈全球首個 AI 原生社交動態功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Character. AI &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.character.ai%2Fcharacter-ai-launches-worlds-first-ai-native-social-feed%2F" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;推出全球首個 AI 原生社區動態（Community Feed） 功能，將提供個性化的角色、場景和創作者帖子，旨在激發靈感、娛樂和聯繫。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5457c8a14f5ed1a8c61106c1b0ad7e652b7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a44b4f56f6311445a4cc5ae981e65fc3360.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;社區動態功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;聊天片段（分享展現角色個性的對話片段）&lt;/li&gt; 
 &lt;li&gt;角色卡片（生成可直接聊天的角色預覽）&lt;/li&gt; 
 &lt;li&gt;直播流（為心儀角色設定主題，觀看其辯論、吐槽、製作視頻博客等）&lt;/li&gt; 
 &lt;li&gt;虛擬形象特效（通過自定義視頻模型生成角色或任意內容的視頻，只需一張圖片和簡短腳本，數秒即可完成）&lt;/li&gt; 
 &lt;li&gt;圖像生成（基於與角色的聊天內容生成背景圖）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據介紹，社區動態功能使 Character.AI 從聊天應用升級為面向下一代的全內容社交平台，重塑人們與 AI、敍事及彼此的互動方式。其 CEO 表示：「新信息流模糊了創作者與消費者的界限，終結無意義滑動，引領 AI 娛樂未來。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364805/character-ai-launches-worlds-first-ai-native-social-feed</guid>
      <pubDate>Thu, 07 Aug 2025 06:47:05 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 AI 客户端 Cherry Studio v1.5.4 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;開源 AI 助手平台 Cherry Studio v1.5.4 已發佈，這是一個重要的版本更新，共合併了 125 個拉取請求（Pull Requests），由核心團隊及社區貢獻者共同完成。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-438d9fbdaff56b2a32861da4a553348a808.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;一、核心功能與平台集成&lt;/h4&gt; 
&lt;p&gt;v1.5.4 在平台能力上進行了重要拓展，集成了多個新的服務與功能。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;集成 AWS Bedrock API （#8383）&lt;/strong&gt;：新增對 Amazon Bedrock 的支持，用户可直接調用其提供的模型服務。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Vertex AI （Claude） （#7564）&lt;/strong&gt;：新增對 Google Cloud Vertex AI 及其 Claude 模型系列的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;引入 Cherry Studio as a Service （CSaaS） （#8098）&lt;/strong&gt;：為未來的服務化部署提供了基礎框架。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;二、新增模型支持&lt;/h4&gt; 
&lt;p&gt;新增了對以下供應商和模型的支持。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新增供應商&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Poe (#8758)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;新增模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: o3 （Omni） 系列模型 （#8253）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Grok&lt;/strong&gt;: Grok 4 模型 （#8545）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;阿里通義千問&lt;/strong&gt;： Qwen 3-235B 等新模型，並優化了&amp;nbsp;thinking&amp;nbsp;狀態的判斷邏輯 （#8537， #8641， #8854）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智譜 AI&lt;/strong&gt;: Zhipu 新模型 （#8609）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本次更新包含&amp;nbsp;&lt;strong&gt;超過 10 項&lt;/strong&gt;&amp;nbsp;與模型直接相關的改動。&lt;/p&gt; 
&lt;h4&gt;三、用户體驗與功能優化&lt;/h4&gt; 
&lt;p&gt;對用户界面和現有功能進行了多項改進，旨在提升日常使用效率和便利性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;UI/UX 改進 （超過 15 項）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;拖拽上傳&lt;/strong&gt;： 支持將文本文件拖拽至輸入框 （#8579）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;消息多選&lt;/strong&gt;： 對話中的消息支持多選模式 （#8653）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;界面優化&lt;/strong&gt;： 改進了模型列表、彈窗等組件的加載速度和交互動畫 （#8667， #8797）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;參數調整&lt;/strong&gt;： 新增 Top-P 參數的設置開關 （#8137）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Markdown 增強&lt;/strong&gt;： 支持 GitHub 風格的 Alert 語法 （#8842）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;核心功能增強&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;後台翻譯&lt;/strong&gt;： 翻譯任務可於後台運行，不阻塞前台操作 （#7892）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;備份路徑&lt;/strong&gt;： 備份目錄支持使用相對路徑 （#8471）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;網絡代理&lt;/strong&gt;： 新增繞過系統代理（Bypass Proxy）的選項 （#8791）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;四、性能與代碼質量&lt;/h4&gt; 
&lt;p&gt;為了提升應用的穩定性和可維護性，此版本進行了多項底層的優化和重構。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能提升 （Performance）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;內存優化&lt;/strong&gt;： 修復了部分場景下的內存泄漏問題 （#8619）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;加載提速&lt;/strong&gt;： 優化了模型列表和國際化文本的加載邏輯，提升了響應速度 （#8751， #8548）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API 健康檢查&lt;/strong&gt;： 優化了 API 檢查的超時邏輯，減少不必要的等待 （#8830）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;代碼重構 （Refactor）&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;架構調整&lt;/strong&gt;： 對&amp;nbsp;ApiService、aiCore&amp;nbsp;等核心模塊進行了代碼重構，提升了邏輯清晰度 （#8671， #8618）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;構建工具升級&lt;/strong&gt;： 將 Vite 升級為 Rolldown，以提升開發構建效率 （#8460）。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;UI 組件庫更新&lt;/strong&gt;： 統一使用 Lucide 圖標庫，並重寫了虛擬列表等基礎組件 （#8803， #8711）。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本次更新包含&amp;nbsp;&lt;strong&gt;超過 20 項&lt;/strong&gt;&amp;nbsp;與性能和代碼重構相關的提交。&lt;/p&gt; 
&lt;h4&gt;五、問題修復&lt;/h4&gt; 
&lt;p&gt;修復了&amp;nbsp;&lt;strong&gt;超過 30 個&lt;/strong&gt;&amp;nbsp;已知問題，主要包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復了部分場景下工具調用（Tool Call）失敗的問題 （#8526）。&lt;/li&gt; 
 &lt;li&gt;解決了特定 Qwen 模型無法禁用&amp;nbsp;thinking&amp;nbsp;模式的問題 （#8854）。&lt;/li&gt; 
 &lt;li&gt;修正了多個界面的響應式佈局和顯示錯誤 （#8517， #8606）。&lt;/li&gt; 
 &lt;li&gt;修復了備份、數據導出、代理設置等功能中的多個邏輯缺陷。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：https://github.com/CherryHQ/cherry-studio/releases/tag/v1.5.4&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364804/cherry-studio-1-5-4</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364804/cherry-studio-1-5-4</guid>
      <pubDate>Sun, 03 Aug 2025 06:36:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 在實際生成環境中的提效實踐</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;導讀&lt;/h4&gt; 
&lt;p&gt;隨着 AI 時代的到來，各類 AI 工具層出不窮，業界都在探索一套完整的 AI 加成的提效方案，我們團隊基於自身特色，利用起團隊沉澱好的歷史知識庫，落地了一套深度結合 AI 的工作流，用 AI 武裝研發團隊，實現研發效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;各類 AI 研發工具層出不窮，很多現成工具可使用，&lt;em&gt;&lt;strong&gt;業界都在探索一套完整的 AI 加成的提效方案&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;團隊內部規範文檔完備，但是沒有融入開發流程中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Code review、研發自測、接口文檔更新消耗大量時間&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;目標&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 擁抱 AI 時代，&lt;strong&gt;讓團隊更先進&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;2. 用 AI 武裝研發團隊，通過資源的配合與協調，實現研發效率的提升。&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;思路&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 拆分研發流程，並找到 AI 結合點，並將其串聯起來。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 深度探索 AI IDE，得出最佳實踐。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;3. 利用起團隊的知識庫，為 AI 提供輔助能力。&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;定位&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. 這是一個錨點，自此開始團隊研發流程向 AI 化轉變。&lt;/p&gt; 
&lt;p&gt;2. 這是一個開始，帶動團隊與其他同學 review 當前研發流程，&lt;strong&gt;共建更多研發工作流。&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;01 研發鏈路&lt;/h1&gt; 
&lt;p&gt;對研發鏈路進行拆解，得到不同階段的 AI 工作流形態，並基於當前形態向下一形態進行推進。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b940caac96e16b2debbc458606192f14b2c.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;當前我們團隊正處於階段 1 接近完成，階段 2 正在開始探索實踐的階段，因此下面我們會基於我們團隊在這些方面的實踐進行分享。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;原本研發鏈路：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8a46b6b27bceca968a8d8cb3f86c27b69d8.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 加持研發流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e74eb941a7e4a40ab2b07fbbe750401fff3.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_7"&gt;&lt;/span&gt; 
&lt;h3&gt;AI 工作流&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;對上面涉及到的 AI 工作流進行補充説明&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI-Cafes：AI 生成需求文檔，製作產品原型圖，節省產品人天。&lt;/p&gt; 
&lt;p&gt;AI-Docs：需求文檔轉技術文檔，節省研發梳理過程，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-DocsCoding：基於技術文檔，生成基礎無業務邏輯代碼，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-Coding：基於團隊內部代碼規範生成代碼，減少返工和代碼理解成本，深度提高研發效率，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-API：基於 MCP Server 打通接口文檔，避免 api 文檔/技術文檔更新不及時，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-CR：基於 Rules，進行 AI Code Review，節省研發人天。&lt;/p&gt; 
&lt;p&gt;AI-Develops：AI 賦能測試、驗證、監控環節，節省測試人天。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;02 需求階段&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;AI-CafeDocs&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在原本的工作流中，在需求評審過後，研發同學通常需要至少 0.5d 的人力進行技術文檔的落地，以及 api 接口的準備。&lt;/p&gt; 
&lt;p&gt;但是這一步中的大部分工作是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此我們實現了了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;需求文檔 -&amp;gt; aisuda（百度的低代碼平台）-&amp;gt; 大模型 -&amp;gt; 技術文檔（markdown）&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_的工作流。&lt;/p&gt; 
&lt;p&gt;在微調好大模型之後，我們只需要以下兩步就能完成技術文檔+api 接口準備的工作：&lt;/p&gt; 
&lt;p&gt;1. 投餵需求文檔給大模型，得到初版技術文檔。&lt;/p&gt; 
&lt;p&gt;2. 人工 check 技術文檔。&lt;/p&gt; 
&lt;p&gt;在快速生成了技術文檔後，後端再和前端進行溝通，根據細節進行修改具體實現。&lt;/p&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-DocsCoding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在得到技術文檔之後，我們下一步要做的則是落地。不得不承認，我們的工作中無可避免的會存在一些基礎的 CRUD 環節，這是正常的，也是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的。&lt;/p&gt; 
&lt;p&gt;因此，基於以上的 AI-CafeDocs 環節，我們進行了進一步的延伸，實現了_&lt;strong&gt;&lt;em&gt;&lt;strong&gt;技術文檔 -&amp;gt; MCP Server -&amp;gt; AI IDE&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;_ 的工作流&lt;/p&gt; 
&lt;p&gt;我們通過 MCP 打通了內部的知識庫，使得 AI 能夠閲讀到需求文檔和技術文檔，瞭解上下文，並進行對應的開發工作。&lt;/p&gt; 
&lt;p&gt;當然，AI 全流程開發只是一種理想的狀態，就當前而言，AI-DocsCoding 寫出來的代碼並不是完全可用的，在涉及到的業務邏輯越複雜時，代碼的正確性就越低。&lt;/p&gt; 
&lt;p&gt;但是不要緊，我們在設計這個流程的時候，就早有準備。&lt;/p&gt; 
&lt;p&gt;還記得我們強調的一點：讓 AI 取代&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作，那麼正確的流程為：&lt;/p&gt; 
&lt;p&gt;1. AI 通過 MCP 閲讀需求文檔、技術文檔，生成本次功能的基礎代碼——除卻業務邏輯之外的參數處理、數據處理的 CRUD 代碼。&lt;/p&gt; 
&lt;p&gt;2. 人工補全核心的業務邏輯處理，人也只需要關心真正的業務邏輯，這些事 AI 無法替代的。&lt;/p&gt; 
&lt;p&gt;可以看到，在以上的兩個工作流裏，人的角色從執行者，變成了驅動者/觀察者，或者説產品經理。&lt;/p&gt; 
&lt;p&gt;我們通過**&lt;em&gt;&lt;strong&gt;向 AI 提出需求，監督 AI 工作，驗收 AI 工作結果&lt;/strong&gt;&lt;/em&gt;**的方式進行工作。&lt;/p&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;03 開發階段&lt;/h1&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-Coding&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;AI-Coding 這一塊主要圍繞 AI IDE 的使用，現在市面上有很多的產品，比如 Cursor、Comate、Trae 等。其實在許多人看來，AI IDE 的核心在於底層能夠接入的模型，但是我覺得這不盡然，大模型的邊界效應很強。&lt;/p&gt; 
&lt;p&gt;有些時候，我們對 AI IDE 的使用，還沒有達到需要區分模型效果的地步。&lt;strong&gt;&lt;strong&gt;或者説，如果我們使用了世界上最好的模型，那我們是否就高枕無憂了，可以讓 AI 全程進行 Coding 而不需要人為 Review 了&lt;/strong&gt;&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;至少使用到今天為止，我們認為 AI-Coding，還離不開人的關注，因此如何更好地使用 AI 進行 Coding，是 AI 提效的必經之路。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;合理使用 Rule&lt;/h3&gt; 
&lt;p&gt;在&lt;strong&gt;&lt;strong&gt;AI IDE&lt;/strong&gt;&lt;/strong&gt;內，Rule 是一個非常重要的環節，&lt;strong&gt;它是連接開發者意圖與 AI 代碼生成行為之間的關鍵橋樑&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;定義：Rule 的，核心目的是指導 AI 更準確地理解當前代碼庫的上下文、遵循特定的項目規範與編碼標準、生成符合預期的代碼，或輔助完成複雜的工作流程。Cursor 官方文檔將其描述為「控制 Agent 模型行為的可複用、有作用域的指令」。&lt;/p&gt; 
&lt;p&gt;作用：大型語言模型（LLMs）本身在多次交互之間通常不具備持久記憶。Rule 通過在每次 AI 請求的提示詞（prompt）層面提供持久化、可複用的上下文信息，有效解決了這一問題。&lt;strong&gt;當一個規則被應用時，其內容會被包含在模型上下文的起始部分&lt;/strong&gt;，從而為 AI 的代碼生成、編輯解釋或工作流輔助提供穩定且一致的指導。&lt;/p&gt; 
&lt;p&gt;上面有一個非常重要的點，那就是所有的 rule 在使用的過程中，都會佔用我們上下文的 token，因此如何更好的使用 Rule，是提升 AICoding 能力的關鍵。&lt;/p&gt; 
&lt;p&gt;基於我們的實踐，我們建議將 AI IDE 的 rule 進行層級劃分：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第一層：IDE 全局層 (User Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：User Rules&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：所有項目通用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：個人編碼風格偏好&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：50 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第二層：項目基礎層 (Always Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/always/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：整個項目強制遵循&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：技術棧、核心原則、基礎規範&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：100 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第三層：自動匹配層 (Auto Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/auto/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：特定文件類型或目錄&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：模塊專門的開發規範&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 200 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第四層：智能推薦層 (Agent Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/agent/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：AI 根據對話內容智能判斷&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：優化建議和最佳實踐&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 150 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;第五層：手動調用層 (Manual Rules)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;位置：&lt;code&gt;.xx/rules/manual/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;範圍：手動調用的代碼模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;內容：完整的項目或模塊模板&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;限制：每個規則 300 行以內&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上的劃分，我們再給出對 &lt;strong&gt;&lt;strong&gt;已有/未有 Rule 規範&lt;/strong&gt;&lt;/strong&gt;的代碼庫的 Rule 創建規則（語言不重要，以 Go 為例）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;內容優化原則&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;詳細代碼示例（每個 100+行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重複的概念解釋&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推薦：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;簡潔要點列表（每個 20-30 行）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;具體的操作指令&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;globs 精確匹配&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;避免：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;過於寬泛：&lt;code&gt;"**/*.go"&lt;/code&gt;（匹配所有 Go 文件）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推薦&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/handler/**/*.go"&lt;/code&gt;（只匹配處理器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;/p&gt; &lt;p&gt;&lt;code&gt;"internal/repository/**/*.go"&lt;/code&gt;（只匹配倉儲層）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精確匹配：&lt;code&gt;"**/*_test.go"&lt;/code&gt;（只匹配測試文件）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;優先級設置詳解&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;優先級數值範圍：1-10，數值越高優先級越高&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f56ca8d226b9275006442e4b467dc204f2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;優先級使用策略&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 基礎規範用 10&lt;/strong&gt;&lt;/strong&gt;：項目必須遵循的核心規範&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 核心模塊用 8-9&lt;/strong&gt;&lt;/strong&gt;：handler、service、repository 等主要模塊&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 輔助模塊用 6-7&lt;/strong&gt;&lt;/strong&gt;：middleware、config、utils 等輔助模塊&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;4. 優化建議用 5&lt;/strong&gt;&lt;/strong&gt;：性能優化、最佳實踐等智能建議&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;5. 模板參考用 3-4&lt;/strong&gt;&lt;/strong&gt;：代碼模板、腳手架等參考資料&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;6. 實驗功能用 1-2&lt;/strong&gt;&lt;/strong&gt;：測試中的新規範，避免影響穩定功能&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;衝突解決機制&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;當多個規則應用於同一文件時，高優先級規則會覆蓋低優先級規則的衝突部分&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相同優先級規則按文件名字母順序加載&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Always 規則始終優先於所有其他類型規則&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rule 的核心價值在於它&amp;nbsp;**&lt;em&gt;**為開發者提供了一種機制，用以精細化控制 AI 在代碼理解、生成、重構等環節&amp;nbsp;**&lt;/em&gt;**的行為。&lt;/p&gt; 
&lt;p&gt;通過預設規則，開發者可以將項目規範、編碼標準、技術選型乃至特定業務邏輯「教授」給 AI，從而顯著提升 AI 輔助編程的效率、保證代碼質量的均一性，並確保項目整體的規範性。&lt;/p&gt; 
&lt;p&gt;它使得 AI 從一個泛用的助手，轉變為一個深度理解特定項目需求的「領域專家」。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;記憶庫&lt;/h3&gt; 
&lt;p&gt;基於 Rule 的運用，我們通過&lt;strong&gt;&lt;strong&gt;memory bank + rule&lt;/strong&gt;&lt;/strong&gt;生成專屬業務研發助手&lt;/p&gt; 
&lt;p&gt;在 AICoding 的使用中，有一種常見的痛點場景，&lt;strong&gt;&lt;strong&gt;就是在複雜的項目中，AI 無法感知到整個項目的歷史上下文，即便是有 Codebase 的存在，也對業務邏輯是一知半解&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在我們實踐的過程中，引入了記憶庫的模式，深化 AI 對項目的理解和記憶，使得每一次需求迭代的上下文都被記錄下來。&lt;/p&gt; 
&lt;p&gt;生成了 memorybank 後，我們可以隨時通過對話查看項目大綱和內容，並且每一次重新進入開發，不會丟失之前的記憶。&lt;/p&gt; 
&lt;p&gt;這種模式，其實就是 Rules 的一種應用，它把上下文總結在代碼庫的制定位置，強制 AI 在每次進入時會閲讀上下文，回到上一次 Coding 的狀態，對於解決上下文丟失的問題有非常大的幫助。&lt;/p&gt; 
&lt;p&gt;這裏可能有人會問，記憶庫和 IDE 本身的長期記憶功能有什麼區別？&lt;/p&gt; 
&lt;p&gt;答：&lt;strong&gt;記憶庫是公共的項目記憶庫，IDE 長期記憶是私人的 IDE 使用記憶&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;而記憶庫的詳細內容，這裏不作詳細分享，它只是一份提示詞，感興趣的同學只要簡單搜索一下就能找到很多的資源。&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;MCP Server（重點）&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;MCP（Model Context Protocol），模型上下文協議&lt;/strong&gt;&lt;/strong&gt;，由 Anthropic 於 24 年 11 月提出，旨在為大語言模型和外部數據源、工具、服務提供統一的通信框架，&lt;strong&gt;&lt;strong&gt;標準化 AI 與真實世界的交互方式&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5bd218b1f85d823bffcb86015c0c545c99e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;MCP 的核心架構包括三環：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Host 主機：用户與 AI 互動的應用環境，如 Claude Desktop、Cursor；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Client 客户端：充當 LLM 和 MCP server 之間的橋樑，將用户查詢指令、可用工具列表、工具調用結果發給 LLM，將 LLM 需要使用的工具通過 server 執行調用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server 服務器：輕量級服務節點，給予 AI 訪問特定資源、調用工具能力的權限&lt;/strong&gt;；目前已有數據庫類（如 SQLite、supabase）、工具類（如飛書多維表格）、應用類（如高德地圖）服務器。是 MCP 架構中最為關鍵的組件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-61c480bfeeaca3a1ea58453b8acc6a3cb64.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在開發中，我們可以接入以下幾種 MCPServer&lt;/p&gt; 
&lt;p&gt;1. 實時搜索，baidu/google/github/微博等&lt;/p&gt; 
&lt;p&gt;2. 存儲，mysql/redis 等&lt;/p&gt; 
&lt;p&gt;3. 工具，kubectl/yapi 等&lt;/p&gt; 
&lt;p&gt;用法一：我們接入百度搜索的 MCP&lt;/p&gt; 
&lt;p&gt;1. 搜索問題：在開發之餘搜索一下，夜的命名術，是否完結。&lt;/p&gt; 
&lt;p&gt;2. 搜索知識點：在想知道 Go1.24 新特性時，通過 MCP 進行搜索，讓 AI 進行總結。&lt;/p&gt; 
&lt;p&gt;3. 搜索用法：在想了解 Linux 的快捷命令時進行搜索。&lt;/p&gt; 
&lt;p&gt;以上這些場景，並非非 MCP 不可，非 AI IDE 不可，但是通過這樣的方式，我們至少節省了切換到瀏覽器，搜索，自己總結結論，返回繼續 Coding 這些步驟。&lt;/p&gt; 
&lt;p&gt;用法二：client 裏直接進行多 client 操作&lt;/p&gt; 
&lt;p&gt;1. Redis 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9b021b5b54f9cb7063c72f8966cb7960f0a.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2. MySQL 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6a02d721c76876fa171df81368ea9c7bf0.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;3. GCP 自然語言查詢：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9d3eb554b2f75250662d10f7287f5b516ec.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他的 client（kubectl 等）我就不一一列舉了，但是可以看到，當我們在我們的 IDE 內集成了各種各樣的 client 後，開發效率能極大地提升。&lt;/p&gt; 
&lt;p&gt;當然，這裏有兩個關鍵點：&lt;/p&gt; 
&lt;p&gt;1. 接入 mcpserver 並不需要我們研究，&lt;em&gt;&lt;strong&gt;我們只要把 mcp server 的鏈接丟給 AI&lt;/strong&gt;&lt;/em&gt;，它自己就能開始接入&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 禁止在開發環境使用線上 client 賬號密碼&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-API&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;相信無論是前端還是後端開發，都或多或少地被接口文檔折磨過。前端經常抱怨後端給的接口文檔與實際情況不一致。後端又覺得編寫及維護接口文檔會耗費不少精力，經常來不及更新。&lt;/p&gt; 
&lt;p&gt;其實無論是前端調用後端，還是後端調用後端，都期望有一個好的接口文檔。但是隨着時間推移，版本迭代，接口文檔往往很容易就跟不上代碼了,更會出現之前的同學沒有把接口文檔交接清楚就離職，留下一個繁重複雜的項目，重新啃起來異常艱難，不亞於自己從頭寫一遍。&lt;/p&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;痛點&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 重複勞動&lt;/strong&gt;&lt;/strong&gt;：每一個涉及到前後端的功能，研發都需要手動進行維護接口文檔，在一些時候，接口最後和最開始的設定有可能大相徑庭，每一次改動都是非常令人頭疼的工作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 低效溝通&lt;/strong&gt;&lt;/strong&gt;：前後端在溝通接口後，再進行對應的代碼開發，其實是一件&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作。&lt;/p&gt; 
&lt;p&gt;為瞭解決這些痛點，通過引入 AI 自動化功能，搭建&lt;strong&gt;&lt;strong&gt;API MCP Server&lt;/strong&gt;&lt;/strong&gt;，幫我們解決這些冗雜的工作，&lt;strong&gt;讓研發人力更多的集中在核心業務代碼的開發上&lt;/strong&gt;，提升代碼開發效率、降低溝通成本。&lt;/p&gt; 
&lt;p&gt;這是我們一直暢想的場景，&lt;strong&gt;&lt;strong&gt;後端開發完代碼 -&amp;gt; AI 推送接口文檔 -&amp;gt; API 文檔自動更新 -&amp;gt; AI 拉取接口文檔 -&amp;gt; 前端生成代碼&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;也就是前後端的研發同學，只關注業務功能的實現，而不需要關注這些接口對接的繁瑣工作。&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;Better Thinking&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;這是我想補充的兩個使用 AICoding 的思想，也是我使用下來的一個感悟。&lt;/p&gt; 
&lt;p&gt;一：&lt;em&gt;&lt;strong&gt;學會遞歸使用 AI&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;場景：在 IDE 內佈置 MCP Server&lt;/p&gt; 
&lt;p&gt;通常的做法是：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市場找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把配置部署好&lt;/p&gt; 
&lt;p&gt;3. 開始調試，完成後投入使用&lt;/p&gt; 
&lt;p&gt;遞歸式使用做法：&lt;/p&gt; 
&lt;p&gt;1. 在 MCP Server 市場找到想用的 MCP Server&lt;/p&gt; 
&lt;p&gt;2. 把鏈接丟給 AI，讓它自己安裝（遞歸）&lt;/p&gt; 
&lt;p&gt;3. 安裝完後讓它自己修改 mcp.json 的配置（遞歸）&lt;/p&gt; 
&lt;p&gt;4. 修改完成後讓它自己調通（遞歸）&lt;/p&gt; 
&lt;p&gt;更進一步我們還可以：&lt;/p&gt; 
&lt;p&gt;1. @Web 讓 AI 找一個可用的 McpServer（遞歸）&lt;/p&gt; 
&lt;p&gt;2. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;3. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;4. ...（遞歸）&lt;/p&gt; 
&lt;p&gt;二：&lt;em&gt;&lt;strong&gt;把 AI 當成一個真正的工具&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;場景：寫某篇文檔的時候，我突然想要做一個 Gif 格式的圖片示例。&lt;/p&gt; 
&lt;p&gt;已知：電腦支持錄屏，但是我缺少視頻轉 Gif 格式的工具。&lt;/p&gt; 
&lt;p&gt;麻煩點：&lt;/p&gt; 
&lt;p&gt;1. 如果通過百度/Google 搜索網頁在線工具，非常麻煩，還要付費。&lt;/p&gt; 
&lt;p&gt;2. 如果通過內部的視頻裁剪服務，還需要起服務來處理。&lt;/p&gt; 
&lt;p&gt;3. 如果通過剪映這樣的工具，那還要下載一個軟件。&lt;/p&gt; 
&lt;p&gt;以上這些點，都不算困難，但都相對麻煩，&lt;strong&gt;&lt;em&gt;屬於能做但是又要浪費一點精力&lt;/em&gt;。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;解決方案：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243c673fa2ab4faf47acc4027d61529933e.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;理論上讓 AI 寫和讓 GPT/Deepseek 寫沒什麼區別，但是我們的操作步驟得到了以下簡化：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6c74d08c893d911217d31f3e6c1e92711aa.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;也就是説，我們在遇到很多**&lt;em&gt;&lt;strong&gt;自己能做，但是又覺得麻煩，浪費精力的場景&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;以及&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;strong&gt;大部分的雜活&lt;/strong&gt;&lt;/em&gt;**，都可以第一時間 Ask Ourself，Can AI Do it？&lt;/p&gt; 
&lt;p&gt;包括但不限於：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;撈數據&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;寫文檔&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;找 bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;...&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;AI-Coding VS Original-Coding&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ebea7546f0be5316db168e3e362a4cd52a4.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1&gt;04 集成階段&lt;/h1&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;AI-CR&lt;/strong&gt;&lt;/h3&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;問題&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 時間壓力&lt;/strong&gt;&lt;/strong&gt;：團隊每週可能需要審查數十個 CR，高 T 同學需要審查的居多，每個 CR 的細節往往耗費大量時間。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 溝通低效&lt;/strong&gt;&lt;/strong&gt;：CR 評論描述不清晰，開發者需要來回溝通確認修改點。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 重複勞動&lt;/strong&gt;&lt;/strong&gt;：相似的代碼改動需要重複審查，難以專注關鍵問題。&lt;/p&gt; 
&lt;p&gt;為瞭解決這些痛點，通過引入 AI 自動化功能，提前規避一些基礎問題，&lt;em&gt;&lt;strong&gt;讓 CR 人力更多的集中在關鍵問題上&lt;/strong&gt;&lt;/em&gt;，提升代碼審查效率、降低溝通成本。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;解決方案&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;工作流&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9dc56fede6b3b23156212ab86640c5460fc.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;05 運維階段&lt;/h1&gt; 
&lt;span id="OSC_h4_23"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;AI-Develops&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;隨着業務系統的複雜度不斷增加，運維過程中產生的告警數量急劇增長，傳統的人工處理方式已經無法滿足快速響應的需求。&lt;/p&gt; 
&lt;p&gt;目前在我們來看，現有的運維體系存在了以下的弊端：&lt;/p&gt; 
&lt;p&gt;1. 告警存在非常厚的方向壁壘，不同方向的同學遇到另一個方向的告警時大都只能進行 Case 路由。&lt;/p&gt; 
&lt;p&gt;2. 告警存在非常厚的年限壁壘，團隊不同年限的同學遇到 Case 的應對時間有可能天差地別。&lt;/p&gt; 
&lt;p&gt;一個點是否足夠痛，決定了我們是都要優化。&lt;/p&gt; 
&lt;p&gt;在我們團隊內，有豐富的 case 處理文檔和記錄，也有着應對問題經驗非常豐富的同學，但是在值班同學遇到告警轟炸的時候，同樣會焦頭爛額。&lt;/p&gt; 
&lt;p&gt;回顧起告警處理的過程，其實大部分都是&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省&lt;/strong&gt;&lt;/strong&gt;的工作，它們是有方法論的，並非遇到之後就手足無措。因此我們構建一個智能化的應急診斷系統，通過 AI 技術提升故障處理效率，減少平均故障修復時間 (MTTR)。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-abefe62efa9d85ddcf75055afebb1ab4847.jpg" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;在這種模式下，AI 可以自動捕捉消息，在遇到告警信息的時候自動分析給出結論，如果有 AI 無法解決的問題，才會輪到人工進行介入。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這種模式最大的優點在於：&lt;strong&gt;&lt;strong&gt;所有出現過的 Case/已有的文檔&lt;/strong&gt;&lt;/strong&gt;都會沉澱為 AI 的記憶和知識庫，從今往後只會有新增的 Case 需要人來解決，存量全都會被 AI 攔截，換而言之，&lt;em&gt;&lt;strong&gt;團隊內多出了一個永遠不會離開，且能夠同時接受所有方向培養的 AI 運維人員&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt; 
&lt;span id="OSC_h1_24"&gt;&lt;/span&gt; 
&lt;h1&gt;06 總結&lt;/h1&gt; 
&lt;p&gt;以上就是我們百度國際化廣告團隊的 AI 提效實踐，也希望這篇文章能作為一個錨點，帶動所有看到這篇文章的同學 review 自己所在團隊的工作流程，共建更多的 AI 加持工作流。&lt;/p&gt; 
&lt;p&gt;就如我上面説的，其實 AI 的用法很簡單，它就是我們的助手，假如我們的工作中真的存在一些&lt;strong&gt;&lt;strong&gt;重複的，可替代的，可節省工作&lt;/strong&gt;&lt;/strong&gt;，那不妨把這些工作交給 AI 試試。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18687336</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18687336</guid>
      <pubDate>Sun, 03 Aug 2025 06:34:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>谷歌 AI 編程工具 Gemini CLI v0.1.18 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Gemini 命令行工具 (Gemini CLI&amp;nbsp;) v0.1.18&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2Fdiscussions%2F5698" target="_blank"&gt;已發佈，&lt;/a&gt;帶來了一系列新功能和改進。&lt;/p&gt; 
&lt;p&gt;主要變化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全面提升了 Gemini 2.5 Pro 的使用額度&lt;/li&gt; 
 &lt;li&gt;新增多目錄支持，用户可通過--include-directories 參數在啓動時加載多個目錄，或在運行時使用/directory 命令添加新目錄&lt;/li&gt; 
 &lt;li&gt;當 Gemini 記憶信息時，會請求用户許可&lt;/li&gt; 
 &lt;li&gt;新增/init 命令，可自動生成定製化的 GEMINI.md 項目説明文件&lt;/li&gt; 
 &lt;li&gt;允許擴展通過.toml 文件提供自定義斜槓命令&lt;/li&gt; 
 &lt;li&gt;Gemini CLI 現在支持自動更新&lt;/li&gt; 
 &lt;li&gt;改進了 GEMINI.md 的導入功能，支持更多文件類型&lt;/li&gt; 
 &lt;li&gt;增加/chat delete 命令用於刪除已保存的對話&lt;/li&gt; 
 &lt;li&gt;將 Emacs 添加為默認的外部編輯器選項。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle-gemini%2Fgemini-cli%2Freleases%2Ftag%2Fv0.1.18" target="_blank"&gt;下載地址&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Gemini CLI 是谷歌開源的免費 AI 編程工具，該工具將 Gemini 的能力帶到了開發者最常用的終端，能夠提供輕量化的 Gemini 訪問通道。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="1705" src="https://static.oschina.net/uploads/space/2025/0626/100936_PeVk_2720166.png" width="2435" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;該工具&lt;/span&gt;支持通過自然語言實現代碼編寫、問題調試及工作流優化，還可以作為多功能本地工具，完成內容生成、問題解決、深度研究及任務管理等各類任務。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364794</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364794</guid>
      <pubDate>Sun, 03 Aug 2025 06:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊 AI Lab 開源智能體框架 Cognitive Kernel-Pro</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;騰訊 AI Lab 推出了全新開源的智能體框架 ——Cognitive Kernel-Pro，旨在&lt;span&gt;最大&lt;/span&gt;限度地降低外部依賴，使更多研究人員和開發者能夠輕鬆參與智能體的開發和訓練。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-e9c42dbf8c0a6016e86a9cebb846fb609e5.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cognitive Kernel-Pro 採用了多模塊、層次化的設計，主要由主智能體和多個子智能體組成。主智能體負責任務分解和信息整合，而子智能體則專注於特定任務，如網頁瀏覽和文件處理。這種模塊化結構確保了各部分的獨立性和擴展性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;為了提升複雜任務的處理效率，Cognitive Kernel-Pro 引入了 「進度狀態」 機制，智能體可以記錄已完成的步驟和待辦任務。此外，框架通過簡單的文本接口實現主智能體和子智能體之間的高效通信，便於協作與調試。同時，反思和投票機制的引入，進一步優化了智能體的任務完成質量，特別是在網頁瀏覽等高隨機性的任務中。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，Cognitive Kernel-Pro 在 GAIA 基準測試中表現出色，超越了其他開源框架 SmolAgents，接近那些依賴付費工具的智能體。這一成果得益於其創新的訓練方法，涵蓋網頁導航、文件處理和推理等多個領域。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;除了強大的框架設計，騰訊 AI Lab 還提供了 Agent Foundation Model 的訓練配方。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364792</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364792</guid>
      <pubDate>Sun, 03 Aug 2025 06:01:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟宣佈 Windows 11 本地支持 OpenAI 開源模型 gpt-oss-20b</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟宣佈通過其&amp;nbsp;Windows AI Foundry&amp;nbsp;平台，正式向 Windows11 用户提供 OpenAI&amp;nbsp;最新發布的免費開源大模型&amp;nbsp;gpt-oss-20b。這意味着用户無需依賴雲端，即可直接在本地電腦上調用強大的 AI 功能和各類熱門開源模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="212" src="https://oscimg.oschina.net/oscnet/up-98dfb3a29f2c9673ea430dd0dfd9cc33c9d.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;微軟在博客中指出，gpt-oss-20b 是一款輕量且高效的模型，尤其擅長執行代碼、調用外部工具等任務。它能在多種 Windows 硬件上高效運行，未來還將支持更多設備。即便在網絡帶寬受限的環境下，該模型也適合構建自主 AI 助手或將 AI 集成到日常工作流中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這款模型能在配備至少&amp;nbsp;16GB 顯存的主流消費級 PC 或筆記本上運行。OpenAI 表示，gpt-oss-20b 經過高強度計算資源的強化學習訓練，特別擅長處理「思維鏈式」任務，如調用工具進行網頁搜索或執行代碼。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;不過，作為 OpenAI 的「最小」開源模型，gpt-oss-20b 僅支持文本處理，無法生成圖像或音頻。OpenAI 同時也提醒，該模型的「幻覺」比例較高，在內部測試中，其回答中約有&amp;nbsp;53%&amp;nbsp;存在事實錯誤。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了 Windows11，微軟表示未來計劃將該模型引入&amp;nbsp;macOS&amp;nbsp;等更多平台。目前，gpt-oss-20b 已在微軟的&amp;nbsp;Azure AI Foundry&amp;nbsp;和亞馬遜的&amp;nbsp;AWS&amp;nbsp;平台上線，為雲端開發者提供了更多選擇。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364789</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364789</guid>
      <pubDate>Sun, 03 Aug 2025 05:44:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>又跑出一匹黑馬！超級麥吉，一個開源的超級 AI Agent！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近，Agent 領域又跑出了一匹黑馬！超級麥吉——一個開源的超級 AI Agent。&lt;/p&gt; 
&lt;p&gt;與市面上那些硬編碼、預設流程、通過一次性附件交付產物的 AI 工具不同，超級麥吉具有突破性優勢：實時文件管理、在線人機協同編輯、任務完全可控。&lt;/p&gt; 
&lt;p&gt;超級麥吉採用工作區 &amp;gt; 項目 &amp;gt; 話題的三層結構，每個話題都是一個獨立的 AI 執行單元，可以並行運轉。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;所以，你可以同時讓&lt;span style="color:#3498db"&gt;超級麥吉&lt;/span&gt;幫你寫 100 份報告、做 50 個方案、分析 20 個市場，&lt;span&gt;甚至一次性處理&amp;nbsp;1000&amp;nbsp;份簡歷篩選。也&lt;/span&gt;&lt;span&gt;可以隨時調整、修改、回滾任何環節，通過持續與超級麥吉對話的方式，直至完成最終目標。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我淺淺試用了一下，讓它幫我做一個網站，兩三輪對話，前端頁面完成度就很高了，設計審美也很在線。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1248" src="https://oscimg.oschina.net/oscnet/up-915531dcaf528a9c1bc111b9a4aee7094a9.png" width="900" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 生成的技術報告結構清晰，邏輯完整，還有豐富的圖、表。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1782" src="https://oscimg.oschina.net/oscnet/up-82833df77f3d079522eef438e049462e334.png" width="1307" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;超級麥吉有網頁版，也可以下載 Windows 版、maciOS 版、iOS 版、Android 版本。&lt;/p&gt; 
&lt;p&gt;這個超級 Agent 已經開源，GitHub star 數已經有 1.4K。 開源版本跟當前最新的產品還是有一些不同。不過超級麥吉的聯創——陳曹奇昊公開解釋過，超級麥吉的所有核心功能都是開源的，如果有差異也只是暫時的。因為目前工作量比較大，團隊規模比較小，未能及時同步到開源版本。&lt;/p&gt; 
&lt;p&gt;8 月 12 日晚，我們開源中國（OSCHINA ）邀請到&lt;strong&gt;&lt;span style="color:#3498db"&gt;燈塔引擎 CTO、超級麥吉聯創陳曹奇昊&lt;/span&gt;&lt;/strong&gt;做客《技術領航》直播欄目，跟&lt;strong&gt;大家分享：&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超級麥吉和主流通用 Agent 產品有什麼區別？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     項目模式設計詳解，如何做到多任務並跑、產物無限迭代？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     揭秘主流 AI PPT 製作原理，超級麥吉助你職場彙報好看又有料 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     職場辦公、個人生活、副業探索、知識積累，超級麥吉如何能夠無所不能？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     演示：小工具開發、一口氣做一百份調研報告 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     中國式 MCP 有趣玩法分享 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     超級麥吉未來還有哪些「大招」？ 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Q&amp;amp;A：直播答疑 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;微信掃碼，預約直播：&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height="660" src="https://oscimg.oschina.net/oscnet/up-e9096d1fdeb8b839be2c4cdc92eb9a7726a.png" width="400" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;p&gt;對超級麥吉剛興趣的朋友，可以訪問以下地址：&lt;/p&gt; 
 &lt;p&gt;中國站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.cn&lt;/a&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;國際站：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.letsmagic.cn" target="_blank"&gt;https://www.letsmagic.ai&lt;/a&gt;&lt;/p&gt; 
  &lt;p style="color:#2a2d3e; margin-left:0px; margin-right:0px; text-align:start"&gt;GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdtyq%2Fmagic" target="_blank"&gt;https://github.com/dtyq/magic&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;還可以加入超級麥吉的交流羣，一起聊聊用它做些什麼有意思的事~&lt;/p&gt; 
  &lt;p&gt;&lt;img height="191" src="https://oscimg.oschina.net/oscnet/up-46c10a258bc90ff73c81ea07baf50c9248d.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   或者 OSC 直播交流羣，可以經進來嘮嘮嗑，或者你有好的產品 / 項目，也歡迎推薦過來呀～ 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div style="text-align:center"&gt; 
    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;陳曹奇昊是&amp;nbsp;PHP 語言官方團隊成員、Swoole 協程網絡引擎核心開發者、Swow 項目發起者，協程和異步網絡編程領域專家，是多個知名開源項目的核心貢獻者，有豐富的開源項目經驗。此前，他在某大型零售企業擔任技術負責人，具備大型企業技術實踐經驗。&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;img height="395" src="https://oscimg.oschina.net/oscnet/up-441276df82e6d018accbc3c8b47a5edb643.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;本次直播中，我們將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼、前沿技術書籍等。立即掃碼預約直播吧！&lt;/p&gt; 
  &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;hr&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技術領航》是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，基本上每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18687305</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18687305</guid>
      <pubDate>Sun, 03 Aug 2025 04:40:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>AI 編程工具 Cursor 發佈 1.4，改進 Agent 工具、新增用量統計顯示</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cursor 1.4 已正式發佈，重點改進了 Agent 的工具、可控性和使用可見性。&lt;/p&gt; 
&lt;p&gt;主要變化如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agent 功能顯著優化&lt;/strong&gt;：通過自然語言指令即可啓動後台 Agent，處理代碼生成、錯誤修復等複雜任務，支持任務隊列預排，效率更高。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;遠程獨立運行&lt;/strong&gt;：Agent 可在獨立遠程環境中克隆 GitHub 倉庫並操作獨立分支，支持無縫任務交接，開發者可隨時介入審查。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;用量統計與提醒&lt;/strong&gt;：界面實時顯示用量詳情，達到 50% 時提醒，可自定義關閉。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;緊湊聊天模式&lt;/strong&gt;：隱藏工具圖標、默認收起代碼差異，界面更簡潔。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bf39cc249cbdfb695abb773d64a6be7c8bc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/115838_ydjb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fen%2Fchangelog%2F1-4" target="_blank"&gt;詳情查看發佈説明&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364775/cursor-v1-4-release</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364775/cursor-v1-4-release</guid>
      <pubDate>Sun, 03 Aug 2025 03:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Steam 7 月份調查顯示 Linux 使用率接近 3%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;今年 2-6 月，Steam 在 Linux 上的市場份額分別為 1.45%、2.33%、2.27%、2.69% 以及 2.57%。目前，7 月份的數據也已發佈，顯示 Linux 遊戲玩家數量創近期新高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;調查結果顯示，Linux 遊戲市場份額健康增長 0.32%，達到 2.89%，這個百分比是近期的新高。雖然十年前 Steam 在 Linux 上推出初期的份額約為 3%，但從絕對值來看，這可能是調查以來 Linux 遊戲人口數的最大值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="163" src="https://oscimg.oschina.net/oscnet/up-fd2ea1a25e40200cd90e1245e40251b1bd8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，7 月份 macOS 的市場份額為 1.88%，Windows 的市場份額為 95.23%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-74ddf525ff9c96f683453cff5fe0b21aa8d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;總體而言，SteamOS Holo 作為 Steam Deck 的基礎（Arch Linux 衍生）操作系統繼續名列前茅。這在很大程度上要歸功於 Steam Deck 採用了定製的 AMD APU，以及許多 Linux 遊戲玩家和發燒友偏愛 AMD 的開源特性，AMD CPU 在 Linux 遊戲玩家中的使用率一直徘徊在 68% 左右。在 Windows 下，AMD CPU 在 Steam 上的使用率約為 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="144" src="https://oscimg.oschina.net/oscnet/up-562e67f58ff3c652709be1cd3bda219182c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多詳情可查看&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstore.steampowered.com%2Fhwsurvey%2FSteam-Hardware-Software-Survey-Welcome-to-Steam" target="_blank"&gt;SteamPowered.com&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364763/steam-survey-july-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364763/steam-survey-july-2025</guid>
      <pubDate>Sun, 03 Aug 2025 03:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊混元正式發佈「AI 播客」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊混元正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fptzp9RC391boFvOVm6dpyw" target="_blank"&gt;發佈 AI 播客功能&lt;/a&gt;，支持將文本、網頁、文檔一鍵轉化為自然流暢的雙人對談式音頻，它能把原本晦澀難啃的內容，變成一場有邏輯、有節奏的對話。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/110856_9lik_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;體驗入口：使用電腦訪問騰訊混元官網（https://hunyuan.tencent.com），點擊首頁對話框下方「AI 播客」 即可嘗試。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據介紹，騰訊混元「AI 播客」支持將文本、網頁鏈接或本地文檔（涵蓋 .pdf、.txt、.docx、.md 格式）一鍵轉換為雙人對話式的音頻播客，旨在將靜態文字內容轉化為動態、自然的對話，採用一男一女雙角色對談模式，音色和語調接近真人。&lt;/p&gt; 
&lt;p&gt;目前，該功能已應用於騰訊旗下的知識庫應用 ima 中。「騰訊新聞 AI 播客」也計劃於 8 月底上線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364759</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364759</guid>
      <pubDate>Sun, 03 Aug 2025 03:11:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>慢 SQL 優化實戰：從一例線上慢 SQL 探究執行引擎工作過程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互聯網服務器團隊- Li Xin&lt;/p&gt; 
 &lt;p&gt;本文通過一個線上慢 SQL 案例，介紹了 Join 的兩種算法和 Order by 的工作原理，並通過 Explain 和 Optimizer_trace 工具完整推演了慢 SQL 的執行過程。基於對原理和執行過程的分析，本文給出一種「引導執行引擎選擇效率更高的算法」的方案，從而使查詢性能得到大幅提升。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;1、線上慢 SQL 背景&lt;/h1&gt; 
&lt;p&gt;慢 SQL 會影響用户使用體驗，降低數據庫的整體性能，嚴重的甚至會導致服務器掛掉、整個系統癱瘓。筆者通過監控平台發現線上存在這樣一條慢 SQL（原始 SQL 已脱敏，表結構出於簡化的目的做了一定刪減，實際執行耗時以文中提供數據為準），其執行耗時在分鐘級。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;select&amp;nbsp;t1.*,t2.x&amp;nbsp;from&amp;nbsp;t_table1 t1 leftjoin t_table2 t2&amp;nbsp;on&amp;nbsp;t1.a = t2.a&amp;nbsp;orderby&amp;nbsp;t1.c desc;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;表結構如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CREATETABLE&amp;nbsp;`t_table1`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主鍵',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`b`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`c`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`),
&amp;nbsp;&amp;nbsp;KEY&amp;nbsp;`idx_a`&amp;nbsp;(`a`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

CREATETABLE&amp;nbsp;`t_table2`&amp;nbsp;(
&amp;nbsp;&amp;nbsp;`id`&amp;nbsp;bigint(20) unsigned&amp;nbsp;NOTNULL&amp;nbsp;AUTO_INCREMENT&amp;nbsp;COMMENT&amp;nbsp;'主鍵',
&amp;nbsp;&amp;nbsp;`a`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`x`&amp;nbsp;varchar(64)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;`y`&amp;nbsp;varchar(20)&amp;nbsp;NOTNULL,
&amp;nbsp;&amp;nbsp;PRIMARYKEY&amp;nbsp;(`id`)
)&amp;nbsp;ENGINE=InnoDB&amp;nbsp;AUTO_INCREMENT=0DEFAULT&amp;nbsp;CHARSET=utf8mb4;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其他信息：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/b6/b6d3dd02b7c1dde85561715f07cbc8e5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當發現慢 SQL 時，筆者的第一反應是使用 Explain 查看 SQL 的執行計劃，結果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/d8/d80e469be4c5bf6a591e0f15e9ce7329.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過 Explain 初步分析：兩張表均執行了全表掃描，結合兩張表的數據規模分析全表掃描並非耗時達到分鐘級的主要原因。另外執行計劃 extra 種提示的 Using temporary; Using filesort; Using join buffer (Block Nested Loop) 又分別代表什麼含義呢？&lt;/p&gt; 
&lt;h1&gt;2、原理探究&lt;/h1&gt; 
&lt;h2&gt;2.1 Join 算法原理&lt;/h2&gt; 
&lt;h3&gt;2.1.1 驅動表和被驅動表&lt;/h3&gt; 
&lt;p&gt;在 Join 語句中，執行引擎優先掃描的表被稱為驅動表，另一張表被稱為被驅動表。執行引擎在選擇驅動表時，除了必須要遵守的特定語義外，最重要的考慮便是執行效率。&lt;/p&gt; 
&lt;p&gt;首先列舉兩種特定語義約束驅動表選取的&lt;strong&gt;場景&lt;/strong&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;**場景一：**Straight join 指定連接順序，強制要求執行引擎優先掃描左側的表。&lt;/p&gt; 
 &lt;p&gt;**場景二：**Left/Right [outer] join，方向連接的特點是反方向表中如果不存在關聯的數據則填充 NULL 值，這一特性要求方向查詢時優先掃描相同方向的表。倘若 where 條件中明確指明反方向表中的部分列非空，則驅動表的選擇就不受此語義的限制，執行引擎會依據效率選取驅動表。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;當沒有特定語義的約束時，執行引擎便會依據執行效率選取驅動表，如何判斷哪張表作為驅動表的效率更高呢？下文會結合 Join 的兩種算法更深入地探討這個問題。&lt;/p&gt; 
&lt;h3&gt;2.1.2 Block Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;假設一個數據量為 m 行的驅動表與一個數據量為 n 行的被驅動表進行 join 查詢。&lt;/p&gt; 
&lt;p&gt;最簡單的一種算法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表掃描一行數據；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對被驅動表進行全表掃描，得到的結果依次與驅動表的數據進行 join 並把滿足條件的數據加入結果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着掃描驅動表，每掃描一行數據，均重複執行一次步驟 2，直至驅動表的全部數據被掃描完畢。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;這種算法的磁盤掃描開銷為 m*n，非常低效，MySQL 在實際中並未直接使用該算法，而是採用緩存的思想（分配一塊 Join buffer）對該算法進行改進，並命名為 Block Nested-Loop join(BNL)。&lt;/p&gt; 
&lt;p&gt;BNL 的算法&lt;strong&gt;步驟&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表一次掃描 K 條數據，並把數據緩存在 Join buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對被驅動表進行全表掃描，得到的結果依次與驅動表的 K 條數據進行 join 並把滿足條件的數據加入結果集；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;清空 join_buffer；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着從驅動表再取出 K 條數據，重複步驟 2、3，直至掃描完驅動表的全部數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;上述算法中，驅動表分段取數的次數記為 l，整個算法的磁盤掃描開銷為 m+ln。由於分段的次數與驅動表的數據成正相關，所以公式可以記為 m+λmn，λ的取值範圍為 (0,1)。&lt;/p&gt; 
&lt;p&gt;當兩張表的行數（m、n 大小）固定的情況下，m 對結果的影響更大，m 越小整體掃描的代價越小，所以執行引擎優先選擇數據量更小的表作為驅動表 (符合「小表驅動大表」的説法)。&lt;/p&gt; 
&lt;h3&gt;2.1.3 Index Nested-Loop Join&lt;/h3&gt; 
&lt;p&gt;BNL 算法使用了 Join buffer 結構，雖然有可能通過減少重複掃描來降低磁盤掃描開銷，然而驅動表分段掃描的次數過多依然可能會導致查詢的低效。索引是 MySQL 查詢提效的重要結構，當被驅動表的關聯鍵存在索引時，MySQL 會使用 Index Nested-Loop Join（NLJ）算法。&lt;/p&gt; 
&lt;p&gt;該算法的步驟為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;從驅動表掃描一行數據；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;使用驅動表的關聯鍵搜索被驅動表的索引樹，通過被驅動表的索引結構找到被驅動表的主鍵，再通過主鍵回表查詢出被驅動表的關聯數據（暫不考慮覆蓋索引的情況）；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;接着掃描驅動表，每掃描一行數據，均重複執行一次步驟 2，直至驅動表的全部數據被掃描完畢。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;每次搜索一棵樹的複雜度近似為 log2 n，上述過程在被驅動表掃描一行數據的時間複雜度是 2log2 n，算法的整體複雜度為 m+2mlog2 n，在該算法中，依舊是 m 對結果的影響更大，m 越小整體掃描的代價越小，所以執行引擎總是選擇數據量更小的表作為驅動表 (符合「小表驅動大表」的説法)。&lt;/p&gt; 
&lt;h2&gt;2.2 Order by 算法原理&lt;/h2&gt; 
&lt;h4&gt;2.2.1 全字段排序&lt;/h4&gt; 
&lt;p&gt;MySQL 會為每個線程分配一塊內存（Sort buffer）用於排序，當 Sort buffer 的空間不足時（通過系統參數 sort_buffer_size 設置 Sort buffer 的大小），執行引擎不得不開闢磁盤臨時文件用於排序，此時排序的性能也會大幅降低。&lt;/p&gt; 
&lt;p&gt;全字段排序是將查詢需要的所有字段進行暫存，並按照排序字段進行排序，並將排序後的結果集直接返回。&lt;/p&gt; 
&lt;h3&gt;2.2.2 Rowid 排序&lt;/h3&gt; 
&lt;p&gt;若要查詢的數據單行佔用空間較大，Sort buffer 中可以容納的排序行數將會減少，此時使用磁盤臨時文件進行排序的概率將會增大。為了提高排序性能，執行引擎提供一種只存儲排序字段的算法，稱為 Rowid 排序算法。&lt;/p&gt; 
&lt;p&gt;該算法的&lt;strong&gt;步驟&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;將參與排序的字段和主鍵進行臨時存儲；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;按照排序字段進行排序，得到有序的主鍵；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;根據有序的主鍵進行回表，按順序將所有要查詢的數據返回。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Rowid 排序在單行查詢數據較大時可以通過節省臨時排序空間從而達到降低排序開銷的目的，然而該算法的代價是會增加磁盤掃描的次數（主鍵回表），所以是否選擇使用該算法需要根據實際情況進行取捨（通過系統參數 max_length_for_sort_data 設置）。&lt;/p&gt; 
&lt;h1&gt;3、調優過程&lt;/h1&gt; 
&lt;h2&gt;3.1 執行過程分析&lt;/h2&gt; 
&lt;p&gt;瞭解了 Join 和 Order by 的工作原理，我們推測執行計劃的大致&lt;strong&gt;過程&lt;/strong&gt;為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;t_table_1 與 t_table_2 進行 Join 查詢，使用了 BNL 算法（Using join buffer (Block Nested Loop)）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;將 Join 的結果暫存臨時表（Using temporary）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對臨時表中的數據進行排序後返回（Using filesort）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;為了佐證筆者的推測以及瞭解每一步的開銷情況，Optimizer_trace 命令可以提供更多執行過程細節。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_execution_plans":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table1` `t1`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;615,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"use_tmp_table":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rest_of_plan":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"`t_table2` `t2`",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"best_access_path":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"considered_access_paths":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_to_scan":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"access_type":&amp;nbsp;"scan",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"using_join_cache":&amp;nbsp;true,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"buffers_needed":&amp;nbsp;5,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"resulting_rows":&amp;nbsp;69882,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_access_paths */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* best_access_path */,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows_for_plan":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"cost_for_plan":&amp;nbsp;4.19e7,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_cost":&amp;nbsp;2.1e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"new_cost_for_plan":&amp;nbsp;2.52e8,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"chosen":&amp;nbsp;true
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* rest_of_plan */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* considered_execution_plans */
&amp;nbsp; &amp;nbsp;}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上圖展示的即為執行引擎預估的執行計劃，從 Optimizer_trace 的輸出結果中可以佐證上述對於執行過程的推測。另外我們可以得到執行代價的結果為：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;t_table1 的掃描行數為 3000，代價為 615;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;t_table2 的掃描行數為 69882，由於 BNL 算法 t_table2 會被多次全表掃描，整體代價為 4.19e7;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;對 Join 結果進行排序的開銷為 2.1e8。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;從執行引擎預估的執行計劃可以看出執行引擎認為排序的開銷最大，另外由於使用 BNL 算法會導致被驅動表執行多次全表掃描，其執行代價僅次於排序。然而預估的執行計劃並不代表真正的執行結果，下面展示 Optimizer_trace 命令對於真實執行結果部分參數：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"join_execution":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"select#":&amp;nbsp;1,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"steps":&amp;nbsp;[
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"creating_tmp_table":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"tmp_table_info":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"table":&amp;nbsp;"intermediate_tmp_table",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_length":&amp;nbsp;655,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"key_length":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"unique_constraint":&amp;nbsp;false,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"location":&amp;nbsp;"memory (heap)",
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"row_limit_estimate":&amp;nbsp;25614
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* tmp_table_info */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* creating_tmp_table */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;},
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"filesort_summary":&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"examined_rows":&amp;nbsp;3000,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"number_of_tmp_files":&amp;nbsp;0,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_buffer_size":&amp;nbsp;60200,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;"sort_mode":&amp;nbsp;"&amp;lt;sort_key, rowid&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* filesort_summary */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;]&amp;nbsp;/* steps */
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&amp;nbsp;/* join_execution */
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;從執行結果參數來看：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;執行引擎使用臨時表保存 Join 的結果，且臨時表是一張內存表。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;參與排序的數據行數為 3000 行，沒有使用磁盤臨時文件進行排序，排序算法選擇的是 Rowid 排序。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;綜合執行引擎的預估的執行計劃和真實的執行結果參數可以得出，執行引擎預估最大的執行開銷為排序，但實際上排序並未使用到磁盤臨時文件，且 Rowid 排序的回表操作是在內存中進行的（在內存臨時表中進行回表），3000 條數據的內存排序開銷是極快的，所以真實的最大開銷是 BNL 算法導致的對被驅動表多次進行全表掃描的開銷。&lt;/p&gt; 
&lt;h2&gt;3.2 最終的優化&lt;/h2&gt; 
&lt;p&gt;對於 BNL 算法，可以通過在被驅動表添加索引使其轉化為 NLJ 算法來進行優化（此處注意一些索引失效的場景，筆者在實際調優中遇到了字符集不同導致的索引失效場景）。在 t_table2 表添加索引後，觀察一週內的 SQL 監控如下，可以看到 SQL 最大響應時間不超過 20ms，執行效率得到了大幅提升。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static001.geekbang.org/infoq/47/475398e816de211f42468bc73336a5fa.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;4、總結&lt;/h1&gt; 
&lt;p&gt;本文完整的介紹了一個 SQL 調優案例，通過這個案例可以歸納出 SQL 調優的基本思想。首先，需要了解 SQL 語句中的關鍵字（Join、Order by...）的基本工作原理，並輔助一些執行過程數據（Explain、Optimizer_trace），通過實驗驗證猜想，最終達成調優的目的。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18687291</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18687291</guid>
      <pubDate>Sun, 03 Aug 2025 02:46:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>FreeCAD 1.0.2 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;FreeCAD 1.0.2 現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.freecad.org%2F2025%2F08%2F06%2Ffreecad-1-0-2-released%2F" target="_blank"&gt;發佈&lt;/a&gt;，其中包含 30 多個錯誤修復和一些小改進，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.freecad.org%2Fdownloads.php" target="_blank"&gt;點擊此處獲取&lt;/a&gt;。值得注意的是，這些 1.0.X 版本為 FreeCAD 1.0 版本帶來了更高的穩定性，但正在開發的新功能將在 1.1 版本中發佈。&lt;/p&gt; 
&lt;p&gt;以下是 v1.0.2 中的主要變化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Draft&lt;/strong&gt;：Roy_043 修復了一個&amp;nbsp;Bug，該&amp;nbsp;Bug 導致某個 dimension 顯示 inward-pointing 箭頭，而所有其他的都顯示 outward-pointing 箭頭。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Assembly：&lt;/strong&gt;&amp;nbsp;PaddleStroke 修復了在拖動具有固定連接的部件時有時會發生的崩潰（#&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fissues%2F20614" target="_blank"&gt;20614） 。&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;TechDraw&lt;/strong&gt;：&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;bguest 修復了尺寸對齊問題。&lt;/li&gt; 
   &lt;li&gt;Syres916 更新了 FillTemplateFields.csv 以使用較新的模板。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;CAM&lt;/strong&gt;：工作台現在以&amp;nbsp;UTF&amp;nbsp;-8 編碼寫入 post files（修復&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fissues%2F18698" target="_blank"&gt;#18698&lt;/a&gt;&lt;span style="color:#000000"&gt;），並刪除了 drilling 後的冗餘移動。&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;BIM&lt;/strong&gt;：Roy_043 修復了幾個錯誤……&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;BIM_Leader 將創建一條點少於 2 個的線。&lt;/li&gt; 
   &lt;li&gt;由於導入錯誤，BIM_WPView 無法正常工作。&lt;/li&gt; 
   &lt;li&gt;Roof 不會自動限制運行長度（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fissues%2F21796" target="_blank"&gt;#21796&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;在&amp;nbsp;Strict IFC&amp;nbsp;模式下，摺疊帶有 Level inside&amp;nbsp;的 Building container&amp;nbsp;將會失敗 (&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fissues%2F21912" target="_blank"&gt;#21912&lt;/a&gt;&amp;nbsp;)。&lt;/li&gt; 
   &lt;li&gt;在轉換為&amp;nbsp;Strict&amp;nbsp;IFC&amp;nbsp;模式期間，Arch_Level 和 Arch_Wall 將會消失 (&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fissues%2F21400" target="_blank"&gt;#21400&lt;/a&gt;)。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li style="text-align:start"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GUI&lt;/strong&gt;：Syres916 刪除了字母周圍的暗邊，並修復了針對 Qt6 構建 FreeCAD 時的一些問題。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;span style="color:#000000"&gt;代碼還針對構建系統、單元測試和 Python 綁定進行了修復和改進。完整的更改列表可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFreeCAD%2FFreeCAD%2Fcompare%2F1.0.1...1.0.2" target="_blank"&gt;參見此處&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364751/freecad-1-0-2-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364751/freecad-1-0-2-released</guid>
      <pubDate>Sun, 03 Aug 2025 02:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通義上架 Qwen-Flash API，1M 超長上下文</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通義千問團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVSQEC5IANVzlef9FiaiaUw" target="_blank"&gt;宣佈&lt;/a&gt;其 Qwen 家族多款模型 API 上架，分別為 Qwen-Flash、Qwen3-Coder-Flash、Qwen-Plus，並且全部支持 1M 超長上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103102_OBd5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103109_o4F8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103133_eSWW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1438" src="https://static.oschina.net/uploads/space/2025/0807/103203_busb_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/103225_G56r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方表示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen-Flash(qwen-flash-2025-07-28)：相較於 qwen-turbo-2025-04-28，Qwen-Flash「通用能力」大幅度提升；同時「推理能力」「中英文長尾知識能力」「Agent 能力」均獲得提升。&lt;/li&gt; 
 &lt;li&gt;Qwen3-Coder-Flash(qwen3-coder-flash-2025-07-28)：繼承 Qwen3-Coder-Plus 的 coding agent 能力，支持多輪工具交互；Agent 能力增強，工具調用更穩定。&lt;/li&gt; 
 &lt;li&gt;Qwen-Plus(qwen-plus-2025-07-28(qwen-plus-latest))：中英文的「通用能力」大幅提升；「邏輯能力」更強了；RAG、工具調用等 Agent 能力更強。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;三款模型 API 均已上線阿里雲百鍊平台，併為每位開發者提供每款模型 100w 免費 tokens。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364747</guid>
      <pubDate>Sun, 03 Aug 2025 02:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：賽博占卜</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2118</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2118</guid>
      <pubDate>Sun, 03 Aug 2025 02:26:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 將於 8 月 7 日舉行直播活動，有望發佈 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1953139020231569685" target="_blank"&gt;發佈預告信息&lt;/a&gt;，將於太平洋時間週四上午 10 點舉行網絡直播，屆時將有望發佈傳聞已久的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="354" src="https://static.oschina.net/uploads/space/2025/0807/101913_nIwa_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;公告內容僅為「&lt;em&gt;LIVE5TREAM THURSDAY 10AM PT&lt;/em&gt;」，其簡潔和神秘的風格引發了業界的廣泛關注和猜測。許多分析人士和社區成員推測，此次活動可能會發布備受期待的 GPT-5 模型。&lt;/p&gt; 
&lt;p&gt;在幾乎同一時間，網絡上突然爆出了 GPT-5 的三個版本型號以及圖表信息：共擁有 GPT-5、GPT-5 mini、GPT-5 nano。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0807/102026_2Z7k_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據目前消息來看，GPT-5 的最大亮點並非空泛的跑分提升，而是在多模態、軟件工程和 AI 智能體（Agent）這三個極具實用價值的領域，展現了相當大的性能提升。&lt;/p&gt; 
&lt;p&gt;對於 GPT-5 的表現，OpenAI CEO Sam Altman 也曾多次公開表示「十分強大」，甚至形容自己在面對新模型時，有一種「自己相對 AI 毫無用處」的感覺。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364739</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364739</guid>
      <pubDate>Sun, 03 Aug 2025 02:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AMD、高通宣佈旗下硬件支持 gpt-oss 系列開放模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 與高通近日聯合宣佈，旗下硬件正式支持 OpenAI 推出的 gpt-oss 系列開放推理模型。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 新發布的 gpt-oss 系列包括兩個模型：gpt-oss-20b 和 gpt-oss-120b。前者可以在配備 16GB 內存的設備上流暢運行，而後者則能在單個 80GB 顯卡上高效執行。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AMD 表示，鋭龍 AI Max+395 處理器成為全球&lt;span&gt;首款&lt;/span&gt;能夠運行 gpt-oss-120b 模型的消費級 AI PC 處理器。為了適應這一模型，AMD 採用了 GGML 框架和 MXFP4 格式，使得 gpt-oss-120b 在使用大約 61GB 顯存時得以順暢運行。此外，"Strix Halo" 平台通過 128GB 的統一內存，能夠將 96GB 分配給 GPU，從而滿足運行需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="284" src="https://oscimg.oschina.net/oscnet/up-e6d0339194cefafe23caeacc321abc53252.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在性能方面，鋭龍 AI Max+395 在運行 gpt-oss-120b 時可以實現每秒 30 個 Token 的輸出速度，並且支持 MCP 模型上下文協議。這意味着用户在處理複雜任務時可以享受到更快的響應速度和更高的效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高通則表示，經過早期測試，gpt-oss-20b 模型在其驍龍平台上展現出色的思維鏈推理能力。開發者可以通過 Hugging Face 和 Ollama 等平台，在搭載驍龍芯片的設備上輕鬆訪問這一模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/364737</link>
      <guid isPermaLink="false">https://www.oschina.net/news/364737</guid>
      <pubDate>Sun, 03 Aug 2025 02:16:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
