<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Sun, 24 Aug 2025 02:46:59 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Meta 陷入史上最大 AI 訓練數據侵權案，面臨 3.59 億美元索賠</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;美國加利福尼亞州法院最近受理的一起訴訟案件，將全球科技巨頭 Meta 推到了輿論的風口浪尖。兩家成人影片製作公司 Strike3 和 Counterlife Media 的聯合起訴，不僅揭露了 AI 訓練背後的數據獲取黑幕，更以高達 3.59 億美元的索賠金額，為整個科技行業敲響了版權保護的警鐘。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這起訴訟的核心指控令人震驚。根據法庭文件顯示，Meta 公司自 2018 年以來一直在明知故犯地從盜版來源下載受版權保護的影片內容，累計涉及至少 2396 部作品。這些非法獲取的視頻資料被用於訓練包括 Meta Movie Gen 視頻生成模型和 LLaMA 語言大模型在內的多種 AI 系統，為 Meta 的人工智能技術發展提供了重要的數據支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更加令人意外的是 Meta 獲取這些內容的方式。起訴文件詳細披露，Meta 並非簡單地下載這些盜版內容，而是主動利用 BitTorrent 文件共享技術進行大規模的非法內容獲取。這種 P2P 下載方式的特殊之處在於，下載者同時也會成為內容的分發者，通過"種子"技術向網絡中的其他用户傳播相同的文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 選擇這種下載方式絕非偶然。BitTorrent 協議的核心優勢在於其分佈式下載機制能夠顯著提升大文件的傳輸速度，這對於需要處理海量視頻數據的 AI 訓練項目而言具有重要價值。然而，這也意味着 Meta 不僅僅是被動的內容接收者，更是主動的盜版內容傳播者，其行為的惡劣性質因此被進一步放大。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;原告方的律師團隊在起訴書中強調，Meta 完全有能力通過合法途徑獲取所需的訓練數據。無論是直接購買版權授權，還是修改下載工具的設置以避免傳播行為，Meta 都擁有多種合規選擇。然而，該公司卻選擇了最具爭議的方式持續進行非法下載和傳播活動，這種明知故犯的行為模式充分顯示了其侵權的故意性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這起訴訟案件並非孤立事件，而是近年來 AI 公司版權爭議的最新爆發點。此前已有多位知名作家對 Meta 提起類似訴訟，指控其未經許可使用受版權保護的文學作品訓練 AI 大模型。值得注意的是，在那些案件的法庭審理過程中，Meta 已經公開承認確實曾從盜版來源獲取過訓練內容。這一承認不僅為當前的訴訟提供了重要的法律依據，也讓 Meta 在這起新案件中處於更加被動的地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Strike3 公司在這起訴訟中的角色轉變具有重要的象徵意義。作為美國最活躍的版權維權機構之一，Strike3 長期以來主要專注於起訴個人盜版用户，通過大量的民事訴訟來維護版權方的合法權益。然而，此次將矛頭直指 Meta 這樣的科技巨頭，標誌着版權保護戰線正在向更高層面擴展，傳統的版權維權策略開始適應 AI 時代的新挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;3.59 億美元的索賠金額雖然數字龐大，但其計算依據相當清晰。按照美國版權法的相關規定，每部被侵權作品的法定賠償金最高可達 15 萬美元，而 2396 部涉案影片的總賠償金額上限正好接近這一數字。這種按作品數量累計的賠償方式，充分體現了版權法對批量侵權行為的嚴厲態度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;對於 Meta 而言，這起訴訟的影響遠超經濟層面的損失。作為全球領先的科技公司，Meta 在人工智能領域的投資規模巨大，其 AI 產品的競爭力很大程度上依賴於高質量訓練數據的獲取。如果法庭最終認定 Meta 的數據獲取方式違法，這不僅會對公司的財務狀況造成直接衝擊，更可能迫使其重新審視整個 AI 訓練數據的獲取策略。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這起訴訟案件的更深層意義在於它可能成為 AI 行業版權規範的重要轉折點。隨着人工智能技術的快速發展，訓練數據的需求量呈現爆炸式增長，而現有的版權法律框架顯然還沒有完全適應這種新興技術的發展需求。Meta 案件的審理結果很可能為整個行業的數據使用規範確立重要的法律先例。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，Meta 公司尚未對這起訴訟作出正式回應，但業界普遍認為這將是一場持續時間較長的法律拉鋸戰。無論最終結果如何，這起案件已經向所有 AI 公司發出了明確信號:在追求技術進步的同時，必須嚴格遵守版權法律的相關規定，否則將面臨巨大的法律和經濟風險。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367923</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367923</guid>
      <pubDate>Sun, 17 Aug 2025 10:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee 企業版 AI 隊友邀測開啓：程序員的貼身助理來了</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在團隊協作開發中，有兩類工作總讓人心力交瘁：&lt;/p&gt; 
&lt;p&gt;🤦&amp;nbsp;&lt;strong&gt;一類是 PR 審查&lt;/strong&gt;：信息量大、變更復雜、上下文冗長。哪怕只是一個小改動，也得花不少時間理清上下文、理解影響範圍；&lt;/p&gt; 
&lt;p&gt;🤦&amp;nbsp;&lt;strong&gt;另一類是安全漏洞排查&lt;/strong&gt;：依賴眾多、更新頻繁，稍有疏忽就可能埋下風險，事後追溯更是代價高昂。&lt;/p&gt; 
&lt;p&gt;這些工作既重要又瑣碎，既不能不做，又難以做好。更現實的是，&lt;strong&gt;AI 想真正勝任這些工作，還遠遠不夠成熟&lt;/strong&gt;，市面上的 AI 工具要麼誤報多，要麼落地難，無法真正服務於企業級的研發流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gitee 企業版剛剛推出的「AI 隊友」功能，就是為瞭解決這個現實問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-92cde867ee668b21e5a6c74cccb9abee554.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們不指望也不敢完全讓 AI 替我們做此類決策，我們更需要的是一位靠譜的「實習生型 Bot」：&lt;strong&gt;不會瞎拍板、不會亂判斷，但能主動發現問題&lt;/strong&gt;，讓代碼審得更清楚，安全盯得更紮實。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;PR 審查隊友：讓代碼審得更快、更準、更穩&lt;/h2&gt; 
&lt;p&gt;面對頻繁提交的 PR 和複雜的協作背景，人工審查不僅耗時耗力，還容易遺漏關鍵問題。PR 審查隊友通過智能分析與規則驅動，協助審查人員聚焦重點內容，在不替代人工判斷的前提下，有效提升審查效率。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6eeccbe08f3b64b5a96a21b811333ad0ade.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它的核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;自動觸發審查&lt;/strong&gt;：在 PR 新建、更新或重新打開時，自動完成初步審查，也可通過 @PR 審查隊友 /review 指令手動發起；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="123" src="https://oscimg.oschina.net/oscnet/up-8bc1b8ee6c9c96cc6e2e2ecaeaaa001cc30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;結構化檢查維度：涵蓋功能邏輯、安全性、性能與可維護性四大類問題，生成清晰的評論意見；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="609" src="https://oscimg.oschina.net/oscnet/up-af5b6323ed9f0906ddce24f2182fc3f0cac.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;規則靈活配置：支持每個倉庫獨立設置最多 10 條自定義規則，結合上傳的 txt 格式企業規範，實現差異化審查策略；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d022b59593b0d8a77758afc7b00b730ea97.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多倉庫支持：每位審查隊友可同時服務最多 5 個倉庫，超出可靈活增配，滿足企業規模化協作需求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文件過濾能力：支持以 glob 規則排除自動生成文件（如 RPC、templ 等），避免幹擾審查結果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;權限與管理機制：僅企業管理員或倉庫負責人可配置和管理隊友，保障安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;專屬工作區與任務日誌：可查看歷史審查行為、審查計劃分佈與執行狀態，便於團隊協同管理；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c420fcc3c18ef0789db500fb56dd16104c3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PR 審查隊友適用定位：補充人工盲區，聚焦潛在風險，不做決策，只做提醒。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;安全分析隊友：盯緊依賴，提前識別風險&lt;/h2&gt; 
&lt;p&gt;隨着項目日益依賴第三方組件，單靠人工排查已難以滿足對代碼安全的管理要求。安全分析隊友基於啄木鳥 CodePecker SCA 引擎，提供高頻自動掃描與 AI 分析能力，幫助團隊實現持續的依賴安全治理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0df7dcc13bfe7b34ebd592e1be2c43f83b7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它的核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自動化漏洞掃描：支持每週定時掃描與手動即時掃描，確保漏洞發現不滯後；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-104b5eb66845a60904220e0bf99b3c105d1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CVE 漏洞識別與報告生成：自動檢測倉庫代碼及依賴中的 CVE 漏洞，提供風險等級、定位詳情及修復建議；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-65793620a6c467ce93126cd6641c481f8e7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI 風險分析總結：為高危問題自動創建缺陷卡片，幫助開發者快速理解風險並推動閉環處理；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f62beeb23754240b78102b58f865903c34e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多語言支持：覆蓋 JavaScript、Python、Java 等主流語言，適配不同技術棧的項目；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;倉庫級配置能力：可自動識別代碼語言，靈活適配掃描策略；掃描行為與結果均可在工作區中可視化查看。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;安全分析隊友適用定位：提前暴露依賴漏洞，推動閉環修復，保障交付安全。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;現已開放邀測，歡迎掃碼體驗&lt;/h2&gt; 
&lt;p&gt;目前，「AI 隊友」功能已在 Gitee 企業版中正式上線，公開邀測同步開啓。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;查看 AI 隊友的詳細配置&amp;amp;最佳實踐指南：&lt;a href="https://help.gitee.com/enterprise/ai/ai_teamates" target="_blank"&gt;https://help.gitee.com/enterprise/ai/ai_teamates&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果你的團隊也在面對 PR 審查負擔、漏洞排查難題，歡迎申請試用，讓 AI 隊友來幫你分擔重複性工作、提升團隊整體效能。&lt;/p&gt; 
&lt;p&gt;👇&lt;strong&gt;掃碼進羣獲取邀測資格與使用指引&lt;/strong&gt;👇&lt;/p&gt; 
&lt;p&gt;&lt;img height="396" src="https://oscimg.oschina.net/oscnet/up-eb9aab33f9912c1b53ec2b87e6f098590ce.png" width="396" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-af428a1f9979c04cfb1484b3743ef1cb247.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367917</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367917</guid>
      <pubDate>Sun, 17 Aug 2025 10:04:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>治理算法濫用，核心在於「算法透明」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;8 月 22 日,《新華每日電訊》發表題為《治理算法濫用，核心在於「算法透明」》的評論。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;近年來，算法濫用事件頻發，這些事件不斷提醒我們：打開「算法黑箱」已成為數字時代必須面對的核心議題。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;算法濫用的社會危害性不容小覷。首先，用户自主選擇接收的信息範圍被無形限制。算法根據用户歷史行為構建偏好模型，不斷強化同類內容推送，形成「信息繭房」。人們被困在自我重複的信息迴音壁中，逐漸失去接觸多元觀點、挑戰自我認知的機會，社會共識的基礎被悄然侵蝕。這也是當下網絡戾氣激增、羣體情緒激化突出的成因之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;其次，用户可能因算法濫用而遭受消費者權益損害。「千人千面」的定價策略讓老用户看到更高價格，「精準營銷」跨越隱私邊界，用户在不自知中成為「被算計的對象」。更值得警惕的是，算法濫用可能助長網絡謠言、網絡暴力等不良信息的傳播。為追求用户停留時長，算法往往優先推送煽動性、情緒化內容，使理性聲音被淹沒，情緒變得極端化，甚至引發線下事件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;治理算法濫用的核心在於「打開黑箱」，實現算法透明。《互聯網信息服務算法推薦管理規定》所要求的平台公示算法推薦服務的基本原理、目的意圖和主要運行機制，正是這一理念的重要實踐。但需要明確的是，算法透明並非要求公開商業秘密或核心技術細節，而是揭示算法服務的基本規則和對用户權益的影響方式。就像我們不需要了解發動機的製造原理，但有權知道汽車的安全性能和油耗標準一樣，用户有權知曉算法如何影響他們的信息環境和決策選擇。這種有限度的透明，既保護了企業的創新動力，又保障了用户的基本知情權和選擇權，讓用户真正有能力自由挑選自己想要了解或喜歡的網絡信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;當然，治理算法濫用需要多方協同發力。其一，網絡平台應當以清晰易懂的方式説明算法服務對用户權益的影響，提供必要的關閉或調整選項。特別是對於老年人等特殊羣體，要結合老年人經常面臨的實際問題，適當增加諸如反電信網絡詐騙、反偽科普等內容的推送比例。其二，監管機構需實施常態化監管，督促平台持續優化內部算法安全管理機制和算法技術應用提示説明機制，確保平台以簡明扼要、清晰易懂的方式公開算法推薦服務的基本情況。其三，社會公眾也需要積極參與治理活動，提升信息素養，培養數字時代的批判性思維，主動尋求多元信息源，共同構建健康透明、向上向善的網絡信息生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，打開「算法黑箱」存在一定技術門檻。算法公示機制的根本目的是實現個體權益受算法技術應用影響方式的「可視化」，所以，公示範圍、公示頻率應當圍繞該目的而合理設置，而非以「信息傾瀉」的方式讓公眾無從知曉算法技術應用對自身權益究竟有何影響。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;進一步而言，平台算法公示信息更適宜與普法信息同步呈現，避免一般社會公眾誤認為算法技術應用對自身權益存在影響就等於「重大威脅」，藉由普法信息打消公眾不必要的擔憂，幫助公眾在準確知曉權益影響程度、方式的基礎上，自主選擇相應的服務選項。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;歸根結底，算法原理公示從來都不是減損企業市場競爭技術優勢地位的強制性規範，而是為了引導信息服務行業提供更優質的信息服務、形成更健康的行業慣例。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;在實踐中，開設「平台算法原理公示」專欄、公開算法推薦服務權益影響説明、用户代表參與算法設計、第三方算法安全審計等方式，不僅是數字時代算法技術應用監管的創新嘗試，更是數字時代技術安全治理理念的重要進步。陽光是最好的消毒劑，只有讓算法運行在陽光下，才能打破信息繭房的桎梏，構建真正開放、包容、健康的數字空間。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367915</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367915</guid>
      <pubDate>Sun, 17 Aug 2025 10:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>俄羅斯 HapticVLM 系統發佈，觸覺識別準確率 84.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;來自俄羅斯斯科爾科沃科學技術研究院的科研團隊最新研發了一個名為 HapticVLM 的多模態觸覺系統，材料識別準確率高達 84.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根據介紹，HapticVLM 系統的技術核心體現在其精巧的架構設計上。系統巧妙地融合了深度卷積網絡與視覺語言推理技術，實現了從視覺信息到觸覺反饋的無縫轉換。整個識別過程如行雲流水般順暢:系統首先通過先進的 ConvNeXt 架構對物體進行深度掃描，精準識別出是金屬的冰冷堅硬、木材的温潤質樸，還是織物的柔軟細膩。隨後，系統會生成極其穩健的視覺嵌入數據，為後續的材料識別提供堅實的數據基礎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-ca52106883566230e53bf4b3497fa8821a0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;HapticVLM 還具備了環境感知的智慧。藉助最新的 Qwen2-VL-2B-Instruct 視覺語言模型，系統能夠智能推測周圍環境的温度狀況，並將這一信息 seamlessly 整合到觸覺體驗中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;當用户的手指輕撫虛擬物體表面時，HapticVLM 會通過高精度揚聲器產生與特定材質完美匹配的振動反饋。這些振動並非簡單的機械震動，而是經過精密計算的複合波形，能夠準確模擬金屬表面的堅實感、木質紋理的粗糙感，以及絲綢面料的順滑感。每一次觸碰都能帶來令人信服的真實感受。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;通過集成的帕爾貼模塊，HapticVLM 能夠提供精確的動態温度變化，讓用户真切感受到金屬的冰冷、木材的温和，甚至是剛剛烘焙完成的麪包所散發的温暖。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;實驗數據表明，在涵蓋五種不同聽覺觸覺模式的綜合測試中，系統平均識別準確率達到了 84.67%，這一成績在同類技術中堪稱翹楚。在 15 種複雜環境場景的温度估算挑戰中，系統表現出了 86.7% 的超高準確率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;不過，研究團隊也坦誠當前系統存在的侷限性，並明確了未來的發展方向。團隊計劃在觸覺模式的廣度和深度上進一步拓展，同時加強用户體驗研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;HapticVLM 系統的應用前景極其廣闊，幾乎涵蓋了所有需要觸覺交互的數字化場景。在虛擬現實遊戲中，玩家將能夠真實感受到劍刃的鋒利和盔甲的厚重。在在線購物平台上，消費者可以在購買前就體驗到商品的真實手感。在遠程醫療領域，醫生能夠通過觸覺反饋進行更精確的遠程診斷。在教育培訓中，學生可以通過觸覺體驗更深入地理解物理和化學知識。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367907</guid>
      <pubDate>Sun, 17 Aug 2025 09:17:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 再提速，最高可達每秒 100 Tokens</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;月之暗面今日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMMklNqYVQWdCRzWQwOUs0Q" target="_blank"&gt;宣佈&lt;/a&gt;，經過工程師們的不懈努力，kimi-k2-turbo-preview 模型輸出速度已經提升至每秒 60 Tokens，最高可達每秒 100 Tokens。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;目前該模型仍然享受 5 折特惠價格，模型每百萬 tokens 輸入價格（緩存命中）¥2.00，輸入價格（緩存未命中）¥8.00，輸出價格 ¥32.00。9 月 1 日恢復原價。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9de6fdf009846744551a9cb1485708ffcde.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多信息請訪問官網&lt;em&gt; https://platform.moonshot.cn&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;月之暗面 8 月 1 日發佈 Kimi K2 高速版 —— Kimi-K2-turbo-preview，模型參數與 Kimi-K2 一致，但輸出速度由每秒 10 Tokens 提升至每秒 40 Tokens。&lt;/p&gt; 
&lt;p&gt;Kimi K2 是一款具備更強代碼能力、更擅長通用 Agent 任務的 MoE 架構基礎模型，總參數 1T，激活參數 32B。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367902</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367902</guid>
      <pubDate>Sun, 17 Aug 2025 08:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>PlutoPrint - 從 HTML 生成 PDF 和圖像</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;PlutoPrint 是一個輕量級且易於使用的 Python 庫，可直接從 HTML 或 XML 內容生成高質量的 PDF 和圖像。&lt;/p&gt;

&lt;p&gt;它基於&lt;a href="https://github.com/plutoprint/plutobook"&gt;PlutoBook&lt;/a&gt;強大的渲染引擎，並提供簡單的 API，可將 HTML 轉換為清晰的 PDF 文檔或色彩鮮豔的圖像文件。這使其成為報告、發票或視覺快照的理想選擇。&lt;/p&gt;

&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#1f2328; display:block; font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Segoe UI&amp;quot;,&amp;quot;Noto Sans&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;; font-size:16px; font-style:normal; font-variant:tabular-nums; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; max-width:100%; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:max-content; word-spacing:0px"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="border-color:#d1d9e0"&gt;Invoices&lt;/th&gt;
&lt;th style="border-color:#d1d9e0"&gt;Tickets&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;img height="323" src="https://static.oschina.net/uploads/space/2025/0821/154554_nIdG_4252687.png" width="569" referrerpolicy="no-referrer"&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;img height="327" src="https://static.oschina.net/uploads/space/2025/0821/154608_8DTR_4252687.png" width="567" referrerpolicy="no-referrer"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/plutoprint</link>
      <guid isPermaLink="false">https://www.oschina.net/p/plutoprint</guid>
      <pubDate>Sun, 17 Aug 2025 08:45:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 尋求 100 億美元融資</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-08-21%2Fanthropic-in-talks-to-raise-up-to-10-billion-in-new-funding" target="_blank"&gt;根據《彭博社》的報道&lt;/a&gt;，Anthropic 正就一輪高達 100 億美元的新融資進行最後談判，此輪融資將使其投後估值達到約 1700 億美元。因投資者需求遠超預期，原定 50 億美元的融資規模被直接翻倍。本輪完成後，Anthropic 現金儲備將大幅增加。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a4f572245a4ba561e4f3b580fcb0e2fcb0f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 成立於 2021 年，由前 OpenAI 核心成員創建，其主要產品 Claude 系列 AI 模型在市場中廣受關注。截至 2024 年，其曾獲得亞馬遜與谷歌等巨頭的大規模投資，此次新一輪融資若成功，將令其資金實力更上層樓。&lt;/p&gt; 
&lt;p&gt;據悉，投資公司 Iconiq Capital 將領投該輪融資。知情人士透露，其他預計的參與者包括 TPG Inc.、光速創投、Spark Capital 和 Menlo Ventures。Anthropic 還與卡塔爾投資局和新加坡主權基金新加坡政府投資公司（GIC）就加入這一輪談判進行了討論&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367897</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367897</guid>
      <pubDate>Sun, 17 Aug 2025 08:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>慶祝 Debian 「第 100000 歲生日」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Debian 社區通過郵件列表慶祝 Debian 的「第 100000 歲生日」 : D&lt;/p&gt; 
&lt;p&gt;當然這裏的「100000」並非真正的十萬，而是二進製表示，即「0b100000」，相當於十進制的 32 年，或十六進制的 &lt;code&gt;0x20&lt;/code&gt;。這意味着 Debian 成立已經整 32 年了，而 Debian 的成立日期正好是 &lt;strong&gt;1993-08-16&lt;/strong&gt;。因此，2025-08-16 是 Debian 的 32 週年紀念日。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0822/162849_Baek_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://lists.debian.org/debian-devel-announce/2025/08/msg00006.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在週年紀念之際，Debian 社區特別感謝了為最新版本 &lt;strong&gt;Debian 13 「Trixie」&lt;/strong&gt; 發佈付出努力的各個團隊，包括負責鏡像與軟件包的 FTPMaster、統籌發佈的 Release 團隊、Installer 與鏡像製作團隊、文檔與翻譯貢獻者，以及修復關鍵 Bug 的開發者們。文章還提到，代碼簽名服務的改進為未來安全更新打下了堅實基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367896</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367896</guid>
      <pubDate>Sun, 17 Aug 2025 08:32:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Pulsar 中的消息保留、過期及積壓機制解析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在 Pulsar broker 中, 消息的 Retention, Expiry 和 Backlog quota 是比較重要的功能，它們表現的是 Pulsar 對於流經它的數據的管理。 但是受限於複雜度和文檔語言等因素，開發者可能無法在第一時間很直觀的瞭解它們。&lt;/p&gt; 
&lt;p&gt;本系列上篇為大家介紹了 Retention 和 Expiry 的概念、行為、應用、實現和注意事項&lt;a href="https://my.oschina.net/apachepulsar/blog/18688106"&gt;技術文檔 | Pulsar 中的消息保留、過期及積壓機制解析（上）&lt;/a&gt;，本文將帶來關於 Backlog quota 的解析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Backlog quota&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 概念&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Backlog 意為消息積壓，指未被消費的消息；quota 意為配額，指對於未消費消息的限制。&lt;strong&gt;因此 Backlog quota 是為了限制消息堆積。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當消費者的消費速率跟不上生產者的生產速率時，會出現消息堆積的情況，這在日常開發過程中非常常見。儘管**相比於其他消息隊列，Pulsar 提供了幾乎可以無限擴容消費者數量的機制 **(Shared, Key_Shared 訂閲模式) 來提高消費速率， 但是在實際的業務場景中，消息堆積的情況也時有發生。&lt;/p&gt; 
&lt;p&gt;為了應對這種情況，Pulsar 提供了 Backlog quota 機制來在一定程度治理它。當然，這種治理無法提高消費者的消費速率，只是在生產速率和消費速率之間做出一種平衡，比如説它的一種治理策略是自動清理 Backlog 消息。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fd21c3936cb8cf9fff04263bc486f32160b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 行為&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 在 Topic 級別和 Subscription 級別都有 Backlog 的概念。Topic 級別的 Backlog 是指該 Topic 下所有 Subscription 的 Backlog 總和 (pulsar_msg_backlog 和 pulsar_storage_backlog_size 的含義略有差異，這裏使用 pulsar_msg_backlog 的含義)，Subscription 級別的 Backlog 是指當前 Subscription 的 Backlog。&lt;/p&gt; 
&lt;p&gt;Backlog quota 機制實際工作在 Subscription 級別，它和 Expiry 機制略有相似，但更加強大。它對於 Backlog 有兩項限制、兩種作用域和三種治理策略：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1 兩項限制&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;limitTime：Backlog 的最大存活時間，單位是秒，超過這個時間的 Backlog 會進入治理流程；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;limitSize：Backlog 的最大大小，單位是字節，超過這個大小的 Backlog 會進入治理流程；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2.2 兩種作用域&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;destination_storage：針對 Topic 的 Backlog 的存儲空間，和 limitSize 搭配使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;message_age：針對 Topic 的 Backlog 的消息存活時間，和 limitTime 搭配使用；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2.3 三種治理策略&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;producer_request_hold：當 Backlog 超過限制，Pulsar 會掛起 Producer 的鏈接請求，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;consumer_backlog_eviction：當 Backlog 超過了限制，Pulsar 會自動移動所有超限的 Subscription 的遊標 (相當於自動確認這些消息，使得這些消息對 Consumer 不可見)，將 Backlog 降低到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;producer_exception：當 Backlog 超過了限制，客户端創建 Producer 會拋出異常，直到 Backlog 降到限制以下。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 應用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1 監控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 在 Prometheus 上提供了 pulsar_msg_backlog 和 pulsar_storage_backlog_size 來分別觀測 Topic 級別的未消費的消息數量、未消費消息的總大小。如果這兩個指標數值較高，説明該 Topic 消息積壓嚴重。&lt;/p&gt; &lt;p&gt;另外，Pulsar 也提供了 pulsar_subscription_back_log 這一 Subscription 級別的指標，當我們發現某個 Topic 的 backlog 數值較高時，可以通過查看該 Topic 下的 pulsar_subscription_back_log 指標來找到具體的 Subscription；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通過 Topic stats 來監控 Backlog quota 的情況：&lt;/p&gt; &lt;p&gt;pulsar-admin topics stats &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3.2 設置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;和 Retention 和 Expiry 一樣，Backlog quota 的設置也分為兩個級別：namespace 和 topic 級別。在 Namespace 級別設置了之後，該 Namespace 的所有 Topic 都會繼承該策略；在 Topic 級別設置了之後，該 Topic 會覆蓋 Namespace 的設置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Namespace 級別&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;查看當前 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces get-backlog-quotas my-tenant/my-ns&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;設置 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces set-backlog-quota my-tenant/my-ns --limitTime 3600 --policy producer_request_hold --type message_age&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;刪除 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces remove-backlog-quota my-tenant/my-ns&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Topic 級別&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;查看當前 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics get-backlog-quotas &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;設置 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics set-backlog-quota &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt; --limitTime 3600 --policy producer_request_hold --type message_age&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;刪除 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics remove-backlog-quota &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4. 實現&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Backlogquota 機制的觸發有兩個入口，分別是 ServerCnx#handleProducer(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fblob%2Fv3.0.4%2Fpulsar-broker%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpulsar%2Fbroker%2Fservice%2FServerCnx.java%23L1448" target="_blank"&gt;https://github.com/apache/pulsar/blob/v3.0.4/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java#L1448&lt;/a&gt;) 和 BrokerService#startBacklogQuotaChecker()(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fblob%2Fv3.0.4%2Fpulsar-broker%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpulsar%2Fbroker%2Fservice%2FBrokerService.java%23L657" target="_blank"&gt;https://github.com/apache/pulsar/blob/v3.0.4/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java#L657&lt;/a&gt;) ,前者和後者略有差距，這裏不做詳細解釋。僅以 BrokerService#startBacklogQuotaChecker() 為例，簡單介紹 Backlog quota 的執行流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.1 Backlog Quota Checker 初始化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Pulsar 啓動時， BrokerService#startBacklogQuotaChecker() 會檢查當前 Broker 是否允許 Backlog quota 檢查（broker.conf 的 backlogQuotaCheckEnabled(default=true)）。如果允許，向線程池註冊一個定時任務，定時任務的執行週期是 broker.conf 的 backlogQuotaCheckIntervalInSeconds(default=60s)。Pulsar 每隔 60s 檢查一次所有 Topic 的 Backlog quota，如果 Topic 設置了 Backlog quota，執行後續流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.2 Backlog Quota 執行流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;遍歷所有 Topic，如果 Topic 設置了 Backlog quota，執行後續流程。否則，跳過該 Topic；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;優先根據 limitSize 檢查該 Topic 消費最慢的 Subscription 的 Backlog 是否超過了限制，如果未超限，再根據 limitTime 檢查；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 Backlog 超過了限制，根據 policy 執行相應的治理策略：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;producer_request_hold：掛起 Producer 的鏈接請求，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;consumer_backlog_eviction：自動移動所有超限的 Subscription 的遊標，將 Backlog 降低到限制以下；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;producer_exception：客户端創建 Producer 會拋出異常，直到 Backlog 降到限制以下。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;5. 注意事項&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 暴露出的 Prometheus 指標中的 pulsar_storage_backlog_size 並不完全精準，它只是一個近似值。在 Shared 和 Key_Shared 模式下，允許消息單獨確認消息，但是這些單獨確認的消息不會加入到 Backlog 的計算中，因此這個指標並不會精準反映 Backlog 情況，它通常會比實際數值大；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;pulsar_msg_backlog 一般也是近似值，不會將 Ack 空洞計算在內，但是如果將 broker.conf 的 exposePreciseBacklogInPrometheus 設置為 true，則會將單獨確認的消息計算在內，pulsar_msg_backlog 會更加精準；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;由於 EntryFilter(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpulsar.apache.org%2Fdocs%2F3.2.x%2Fdevelop-plugin%2F%23entry-filter" target="_blank"&gt;https://pulsar.apache.org/docs/3.2.x/develop-plugin/#entry-filter&lt;/a&gt;) 機制的存在，在消費消息時可以根據 EntryFilter 過濾掉一些消息，這些被過濾掉的消息嚴格來説並不算 Backlog，但是我們在計算 Backlog 時，不可能將 Bookkeeper 中的所有消息都拉取出來計算。因此如果 Broker 掛載了 EntryFilter 插件，pulsar_msg_backlog 和 pulsar_storage_backlog_size 以及 pulsar_subscription_back_log 都無法精準反映實際的 Backlog 情況，它們通常會比實際數據大一些；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不管是根據 limitSize 還是 limitTime 來限制 Backlog，當 policy=consumer_backlog_eviction 時，都無法完全精準的清理 Backlog。理想情況下，會將 Backlog 降低到原來的 10%；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果在 Broker 端禁用 Backlog quota checker (將 broker.conf 中 backlogQuotaCheckEnabled 設置為 false)，並且設置的 Backlog quota 的 policy=consumer_backlog_eviction，Pulsar 將不會自動清理 Backlog；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果使用 Backlog quota，然後 Backlog 達到了閾值，並且 policy=producer_request_hold 或 producer_exception ，在 Broker 重啓或自動重平衡時，會導致所有的 Producer 無法鏈接到 Broker，進而無法生產消息，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果使用 limitTime 限制 Backlog，需要注意 Client 和 Broker 的時間同步，否則可能會導致 Backlog 無法正確的清理。因為此時 Backlog 的判斷是以 Broker 的時間為基準的；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果該 Topic 設置了 Retention，Backlog quota 必須要小於 Retention。假設 Retention 設置了 10GB，Backlog quota 必須要小於 10GB。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;總結&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在文章最後，對 Pulsar 的 Retention, Expiry 和 Backlog quota 做一個總結：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Retention 是 Pulsar 對於過期數據的保留和清理策略，它工作在 Topic 級別，通過定時任務清理過期數據，將全部 Subscription 都消費過後的數據從存儲介質上刪除來清理存儲空間；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Expiry 即為 Message TTL，它工作在 Subscription 級別，通過定時任務來檢查 Subscription 中超時未消費的消息，並自動的將這些消息確認，使其對消費者不可見；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Backlog quota 是對未被消費的消息的限制，它實際工作在 Subscription 級別，通過定時任務來檢查 Subscription 中的 Backlog，如果 Backlog 超過了限制，會執行相應的治理策略，拒絕新的 Producer 鏈接或者自動確認消息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這三個功能並不衝突，它們可以組合使用，我們可以**通過 Retention 刪除過期數據，通過 Expiry 處理超時未消費的數據，通過 Backlog quota 治理消息堆積。**但是由於他們三者都涉及到了對數據的操作，大家在使用時應當謹慎，在使用前根據實際業務仔細評估，避免數據丟失或者數據不一致的情況。&lt;/p&gt; 
&lt;p&gt;社區將持續輸出更多 Pulsar 的技術內容；歡迎加入社羣討論或在評論區留言，與我們交流更多關於 Pulsar 的問題。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/apachepulsar/blog/18689158</link>
      <guid isPermaLink="false">https://my.oschina.net/apachepulsar/blog/18689158</guid>
      <pubDate>Sun, 17 Aug 2025 08:24:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>AWS CEO 認為「用 AI 全面替代初級員工」是愚蠢的想法</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;亞馬遜 AWS 首席執行官 Matt Garman 近日在一次採訪中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DnfocTxMzOP4" target="_blank"&gt;表示&lt;/a&gt;，&lt;strong&gt;用人工智能全面替代初級員工，是「我聽過最蠢的想法」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;他強調，初級員工不僅成本低，更是最容易與 AI 工具結合的羣體，是企業長期發展的關鍵力量。如果公司完全依賴 AI，而不培養新人，十年後可能會面臨無人具備核心技能的困境。他認為，企業應該繼續招聘應屆生，教他們如何構建軟件、分解問題和採用最佳實踐。他説 AI 時代最有價值的技能與大學學位不相關。要保住自己的工作員工必須不停的繼續學習更新技能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1498" src="https://static.oschina.net/uploads/space/2025/0822/162212_K8BN_2720166.png" width="2664" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Garman 批評一些企業用「AI 寫了多少代碼」來衡量價值，稱這是一個誤導性的指標。在他看來，代碼質量遠比數量重要。&lt;/p&gt; 
&lt;p&gt;與此同時，AWS 內部已有超過八成的開發人員在使用 AI 工具，涵蓋寫單元測試、文檔和代碼等工作，並且使用率還在持續上升。但 Garman 強調，AI 應該作為助手來提升效率，而不是用來取代年輕人才。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367892</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367892</guid>
      <pubDate>Sun, 17 Aug 2025 08:22:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>達夢數據三天兩度發佈公告：公司兩位董事先後被立案調查</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;8 月 21 日晚，達夢數據再發布公告稱，公司於近日收到湖北省應城市監察委員會下發的《立案通知書》和《管護通知書》，對公司董事兼高級副總經理陳文立案調查並實施管護措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前公司及子公司日常經營情況正常，各項業務穩步推進。公司尚未知悉上述事項的進展及結論，將密切關注後續進展並及時履行信息披露義務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="284" src="https://oscimg.oschina.net/oscnet/up-c40855a0dc2577d4d1cd7a522484e3a3c78.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司 2024 年報顯示，陳文，女，1973 年 7 月出生，本科學歷，高級經濟師。1997 年 7 月專科畢業於湖北省高等商業專科學校財務會計專業，2004 年 7 月本科畢業於華中農業大學法律專業。2002 年 1 月至 2020 年 11 月，在達夢有限歷任銷售經理、華東區域市場總監、副總經理、高級副總經理；2020 年 11 月至今，在達夢數據擔任董事、高級副總經理；2021 年 3 月至今，在北京達夢擔任總經理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司 2024 年報顯示，陳文 2024 年從公司領取税前薪酬為 304.41 萬元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;8 月 19 日，達夢數據也曾發佈公告表示，公司董事兼總經理皮宇被立案調查並實施留置措施。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;達夢數據成立於 2000 年，是國內數據庫產品開發服務商，主要提供各類數據庫軟件及集羣軟件、雲計算與大數據等一系列數據庫產品及相關技術服務。其客户包括建設銀行、中國人保、國家電網、中國航信、中國移動、中國煙草等企業，產品應用於黨政、金融、能源、航空、通信等數十個領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;該公司於 2024 年 6 月 12 日在上海證券交易所科創板上市，成為「國產數據庫第一股」。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;從 6 月披露的半年報預告來看，達夢數據預計 2025 年上半年實現營業收入 4.95 億～5.13 億元，較去年同期增長 40.63%～45.74%。2025 年一季度，達夢數據實現收入 2.58 億元，歸母淨利潤 9816 萬元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相關閲讀：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/367239" target="news"&gt;達夢數據：公司董事兼總經理被留置&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367891</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367891</guid>
      <pubDate>Sun, 17 Aug 2025 08:21:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Vercel 宣佈旗下 AI Gateway 服務正式 GA</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-gateway-is-now-generally-available"&gt;宣佈&lt;/a&gt;&amp;nbsp;AI Gateway 已正式 GA，它建立在 Vercel 為數百萬用户提供支持的 v0.app 系統之上，經過實戰驗證，具有高度穩定性和可靠性。&lt;/p&gt; 
&lt;p&gt;該服務支持數百種模型，通過統一 API 調用，無需單獨管理各廠商 API 密鑰、賬户或配額，提供零加價（含自帶密鑰 BYOK）、高併發、自動故障轉移、亞 20 毫秒延遲，併兼容 OpenAI 格式及 AI SDK 5。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;import { streamText } from 'ai'

const result = streamText({
  model: 'xai/grok-4', // defaults to Vercel AI Gateway
  prompt: 'How does Vercel AI Gateway have no markup on tokens?'
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;據介紹，以下開發者和團隊使用 AI Gateway：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要&lt;strong&gt;動態評估或切換模型&lt;/strong&gt;的使用場景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;追求&lt;strong&gt;高調用上限&lt;/strong&gt;、&lt;strong&gt;避免 rate-limit&amp;nbsp;&lt;/strong&gt;阻礙服務&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;希望&lt;strong&gt;第一時間訪問新模型&lt;/strong&gt;的應用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對&lt;strong&gt;高可用性&lt;/strong&gt;有強要求、不能容忍單點故障&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;希望&lt;strong&gt;集中查看使用成本與監控數據&lt;/strong&gt;，簡化資源管理流程&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Vercel 稱該服務已在 v0.app 等產品中承載數百萬用户，現可供所有團隊正式使用。開發者只需修改模型字符串即可秒級切換供應商，並可實時查看用量與成本，避免鎖定單一模型或平台。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://vercel.com/ai-gateway/models&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367885</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367885</guid>
      <pubDate>Sun, 17 Aug 2025 08:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>WPS Office for Windows 上線 64 位新版本：更快更流暢</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;WPS Office 在官網上線 Windows 系統 64 位新版本，取消 Beta 字樣，升級為正式版。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f9186f413660b14e6218f734654db06ee32.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;測試結果顯示，相對 Windows 系統的 32 位版本，其文字組件的繪製速度提高 10.82%，表格組件的計算速度提高 12.82%，演示組件的新建速度提高 10.35%，PDF 組件的翻頁速度提高 27.13%。&lt;/p&gt; 
&lt;p&gt;如果 Windows 電腦 CPU 是 X64 架構，且內存（RAM）大於 4GB，將 WPS 更新為 64 位版本，將更好地利用硬件能力發揮軟件的性能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367881</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367881</guid>
      <pubDate>Sun, 17 Aug 2025 08:03:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 為 Responses API 發佈兩項更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 為其 Responses API&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAIDevs%2Fstatus%2F1958660214057791853" target="_blank"&gt;推出&lt;/a&gt;了 Connectors 和 Conversations 兩項新功能，分別用於簡化外部服務數據拉取和提供原生對話記錄持久化能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e6b4c8a74c627e8d55f7864cb74b221bb67.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-796585c8fc755074c5d9b4261c49e0990bc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Connectors 允許開發者通過一次 API 調用，從 Gmail、Google Calendar、Google Drive、Dropbox、Teams、Outlook Calendar+Email、SharePoint 等外部服務拉取郵件、日程、文件及聊天記錄，並可直接用於 deep research 場景。&lt;/p&gt; 
&lt;p&gt;Conversations 則提供原生對話記錄持久化能力，無需自建數據庫即可為用户保存聊天線程。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/351200" target="_blank"&gt;Responses API &lt;/a&gt;是 OpenAI 的狀態化 API，支持包括網絡搜索、文件搜索和計算機使用在內的多種新工具，為開發者提供更簡潔、靈活的方式與 OpenAI 模型交互。&lt;/p&gt; 
&lt;p&gt;文檔：&lt;em&gt;https://platform.openai.com/docs/guides/tools-connectors-mcp&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367878</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367878</guid>
      <pubDate>Sun, 17 Aug 2025 07:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌以 47 美分價格向美政府提供 AI 服務</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;谷歌週四宣佈將推出 Gemini 政府版（Gemini for Government），並通過與美國總務管理局的新協議，以每年不到 50 美分的價格向美國聯邦政府提供該模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這也是繼 OpenAI 和 Anthropic 後，最新一家以極低價格向美國政府供應人工智能模型的公司。此前，OpenAI 和 Anthropic 均宣佈以 1 美元的年費向美國聯邦機構供應其旗下模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-ca46f0d381dd2bba05fa817d976c1daacc1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;與 OpenAI 和 Anthropic 不同的是，谷歌已經在美國政府雲業務中深度參與，這也為 Gemini 的後續部署提供了更大的便利。據悉，Gemini 政府版僅限於谷歌雲平台使用，幷包含對 Notebook LM AI 的訪問權限，其為一款用於研究和筆記的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;谷歌母公司 Alphabet 首席執行官 Sundar Pichai 在一份聲明中表示，很榮幸能與美國總務管理局合作，推出 Gemini 政府版。在 Workspace 服務的基礎上，Gemini 政府版將提供全棧式的人工智能創新方案，包括由最新模型支持，並基於安全雲基礎設施的 NotebookLM 和 Veo 等工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;美國總務管理局則稱，Gemini 政府版的定價為每個機構每年 47 美分，該優惠將持續至 2026 年。谷歌稱，這是在此前報價基礎上再提供了 71% 的折扣。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;先試用，後買單&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，谷歌和美國政府都未提及 Gemini 政府版在一年後的正式定價。但與谷歌共同參與政府項目的 OpenAI 曾表示，一年後，美國各政府機構要麼在試用期結束訪問，要麼簽訂新的 ChatGPT Enterprise 付費協議。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息人士透露，目前各家 AI 公司的低價似乎是為了加速政府採用人工智能，並推動官員快速做出決定的一種策略。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這一定價顯然也難以持續，尤其是考慮到運行人工智能的數據中心算力成本不斷高漲，1 美元甚至更低的年費價格更像是「為愛發電」。各家公司可能希望在一年期的試用之後，能夠在政府訂單中奪得更大的份額以收回利潤。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;聯邦採購服務局局長 Josh Gruenbaum 表示，這是美國政府過去幾個月在 OneGov 項目上推出的戰略的新發展。但谷歌與美國總務管理局過去幾個月部署模型的不同點在於，谷歌響應了眾多不同政策的要求，並整合了眾多不同的舉措。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;谷歌公共部門首席執行官 Karen Dahut 則強調，谷歌與其他任何服務真正不同之處在於：為聯邦工作人員提供了一個完全集成的人工智能就緒平台。它既符合 FedRAMP 高標準的安全性，並且包含 Gemini 及其所有輔助功能。（財聯社，馬蘭）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/364855/openai-chatgpt-usa-government-for-free" target="news"&gt;&lt;span style="color:#2980b9"&gt;OpenAI 以 1 美元價格向美國政府提供 ChatGPT&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/365914" target="news"&gt;&lt;span style="color:#2980b9"&gt;Anthropic 以 1 美元為美國政府提供 AI 服務&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367877</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367877</guid>
      <pubDate>Sun, 17 Aug 2025 07:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>可靈 AI 正式發佈基於 2.1 模型的全新首尾幀功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;可靈 AI 今天正式向所有用户推出基於 2.1 模型的「首尾幀」功能，&lt;/span&gt;其效果較 1.6 模型提升 235%，進一步提升了 AI 視頻生成的可控性，廣泛適用於廣告營銷、影視、短劇、動畫等創意製作場景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-da2cd9ac596c0499b86067d7d90184057a7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;首尾幀功能的核心價值在於它賦予了創作者前所未有的視頻控制能力。傳統的 AI 視頻生成往往像是一場技術賭博，用户輸入文字描述後，只能被動等待系統生成結果，無法對視頻的具體走向進行精準把控。而可靈 AI 的首尾幀技術徹底打破了這種被動局面，創作者現在可以明確指定視頻的起始畫面和結束畫面，讓 AI 在這兩個關鍵節點之間生成流暢自然的過渡內容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e58d24c67ee168ae526cba8899c5207bab2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這種精準控制能力的實現並非簡單的技術拼接，而是基於深度學習算法對視頻時空連續性的深刻理解。2.1 模型通過分析海量的視頻數據，學會瞭如何在給定的首尾約束條件下，生成既符合物理規律又富有創意表現力的中間幀序列。每一幀畫面的生成都要考慮到與前後幀的連貫性，確保整個視頻呈現出絲滑流暢的視覺效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367876</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367876</guid>
      <pubDate>Sun, 17 Aug 2025 07:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>騰訊元寶接入 DeepSeek V3.1 最新版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;騰訊元寶&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPjqXA_EotWwX5te9_ppwIg" target="_blank"&gt;宣佈&lt;/a&gt;已正式接入 DeepSeek V3.1 最新版。相比上一代，DeepSeek V3.1-Think 能在更短的時間內給出答案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0822/154414_rCOP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方稱此次模型更新，帶來兩大突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;思考更快，靈感秒現：相比上一代，DeepSeek V3.1-Think 能在更短的時間內給出答案，助你更快一步抓住靈感，高效完成工作。&lt;/li&gt; 
 &lt;li&gt;更強的 Agent 能力：新模型大幅提升了工具使用和智能體能力，幫你輕鬆搞定複雜任務。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1749" src="https://static.oschina.net/uploads/space/2025/0822/154526_K89t_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;體驗：&lt;em&gt;https://yuanbao.tencent.com/download&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367871</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367871</guid>
      <pubDate>Sun, 17 Aug 2025 07:45:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AMD FSR 開源項目暗示了對舊款 GPU 的潛在支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AMD 最近發佈了 FidelityFX Super Resolution SDK 2.0，以配合向基於機器學習的 FSR 4 的轉變，但奇怪的是，該公司似乎還意外地通過其 AMD GPUOpen 項目將庫開源到 FSR 4，讓精通技術的瀏覽器可以一窺 FSR 4 的內部工作原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-173169245625002af1951211817b3c39b54.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這些文件後來從 AMD 的 GPUOpen 庫中刪除，但有人迅速抓取了文件目錄的屏幕截圖，從中可以看出足夠的信息。最大的亮點之一是包含 8 位整數 (INT8) 庫，這些庫使用的資源更少，但精度也低於 RDNA 4 中使用的庫，這表明 AMD 有或可能有打算為 RX 7000 GPU 發佈 FSR 4。&lt;/p&gt; 
&lt;p&gt;FSR 4 最初宣佈為 AMD 的 Radeon RX 9000 系列 GPU 獨有，但這種情況可能不會持續太久。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-68f4c2091693f71d72cb93c5f04eab923a1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前曾有跡象表明 AMD FSR 4 可能會支持較舊的 RDNA 硬件，甚至有一些 mod&amp;nbsp;項目成功地使其在較舊的硬件上運行，但這是一個重要的官方信號，表明 AMD 可能正在努力將其移植到較舊的硬件上。&lt;/p&gt; 
&lt;p&gt;也有人猜測 INT8 庫可能是為 PlayStation 5 Pro 設計的，但文件類型似乎表明並非如此——PS5 使用 .PSSL 格式，而這些着色器被打包為 .HLSL 格式，表明它們是為 PC 設計的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367865</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367865</guid>
      <pubDate>Sun, 17 Aug 2025 07:38:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>美團智能頭盔研發實踐系列 02：軟件功能篇</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;本文系《美團智能頭盔研發實踐系列》的第二篇文章，圍繞智能頭盔如何通過主動安全和被動安全相結合的方式有效保護騎手，主要包括智能頭盔騎行通話質量強化、智能語音助手、碰撞摔倒監控等三項軟件能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b82e78f56c21d3c578ed700c4b6b0f0513e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;引言&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美團智能頭盔作為專為外賣騎手打造的智能安全裝備，具備藍牙通話、戴盔識別、智能語音助手、碰撞摔倒監控等功能，核心軟件功能圍繞如何通過主動安全和被動安全相結合的方式有效保護騎手。&lt;/p&gt; 
&lt;p&gt;本期分享主要介紹智能頭盔騎行通話質量、智能語音助手、碰撞摔倒監控三項軟件能力。其中"騎行通話質量和智能語音助手"降低騎手操作手機導致的"分心"，幫助騎手"防患於未然"。"碰撞摔倒監控"最大限度的保護騎手、快速的感知事故和觸發救治。&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;安全風險與體系&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;2.1 安全挑戰&lt;/h3&gt; 
&lt;p&gt;外賣騎手面臨着獨特的安全挑戰，他們的工作性質，如午晚高峯短時集中的壓力和交通複雜環境，顯著增加了事故風險。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事故和違規行為&lt;/strong&gt;：研究表明，工作壓力與騎手的分心駕駛和危險駕駛行為之間存在關聯，這些行為往往導致交通事故的發生。例如，為了趕時間，騎手可能會超速、闖紅燈或逆行。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;車輛類型&lt;/strong&gt;：許多外賣騎手使用摩托車或電動自行車，這些車輛本身就具有不穩定性，且缺乏足夠的安全保護措施 。尤其是在亞洲，摩托車因其效率而成為首選，但也導致了交通安全事故的增加。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;工作環境&lt;/strong&gt;：外賣騎手有時需要在惡劣的天氣條件下工作，這進一步增加了他們的道路安全風險。此外，長時間工作和不規律的休息也可能導致疲勞駕駛，影響騎手的反應能力和判斷力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行為因素&lt;/strong&gt;：騎手的安全態度和風險認知對其駕駛行為有重要影響。研究發現，安全知識的缺乏與騎手的不良駕駛行為有關。此外，工作場所的安全氛圍也會影響騎手的安全合規行為。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.2 安全體系&lt;/h3&gt; 
&lt;p&gt;騎手安全防護可以分為&lt;strong&gt;主動安全&lt;/strong&gt; 和&lt;strong&gt;被動安全&lt;/strong&gt;兩個方面，它們共同構成了騎行安全的完整體系。&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;主動安全是指在騎行過程中，通過技術手段和行為規範來預防事故的發生&lt;/strong&gt;。例如，騎手應遵守交通規則，如不闖紅燈、不超速、不隨意變道等，這些行為有助於減少因人為失誤導致的事故。此外，現代兩輪車也配備了多種主動安全技術，如 ABS（防抱死制動系統）、TCS（牽引力控制系統）等，這些系統通過傳感器實時監測車輪狀態，確保在緊急制動或加速時車輛仍能保持穩定。例如，業界某電動車企業在其兩輪車上應用了 AI 視覺輔助系統，結合姿態感應系統，能夠識別車輛傾倒、非正常移動等危險情況，從而提前預警。這些技術的引入，大大提升了騎行的安全性。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;被動安全則是在事故發生時，通過防護裝備、傳感裝備，最大限度地減少傷害、及時觸發救治&lt;/strong&gt;。例如，頭盔是騎行者最重要的被動安全裝備之一，它能夠有效保護頭部免受撞擊，降低顱腦損傷的風險。此外，騎行手套、護膝、護肘等防護裝備也能在摔倒時減少擦傷和扭傷。在車輛設計方面，一些高端兩輪車也嘗試引入類似汽車的被動安全設計，如帶式座椅，以在碰撞時保護騎手。然而，由於兩輪車的結構限制，其被動安全系統仍處於發展階段，尚未達到與汽車同等水平。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主動安全&lt;/strong&gt; 和&lt;strong&gt;被動安全&lt;/strong&gt;並非孤立存在，而是相輔相成。騎手在日常騎行中應注重主動安全意識的培養，如佩戴護具、遵守交通規則、保持車距等，同時也要關注車輛的安全配置，合理利用主動安全技術，以降低事故發生的風險。只有在主動預防的基礎上，被動安全措施才能發揮最大作用，為騎手提供全方位的保護。&lt;/p&gt; 
&lt;p&gt;隨着科技的發展，越來越多的智能化技術被應用於外賣配送領域，這些技術不僅提升了騎行的安全性，也為未來兩輪車的安全發展提供了更多可能性。&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;智能頭盔安全能力&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;3.1 主動安全篇&lt;/h3&gt; 
&lt;p&gt;1）&lt;strong&gt;第一個主動安全能力------摩托騎行 60km/h 速度下雙向聽得清&lt;/strong&gt;。騎行中操作手機進行通話和應用交互是導致騎手分心駕駛的主要原因，佔比極高。配送騎手載具涵蓋電動車與摩托車，雖然前者一般工況下均速不超過 15km/h，但後者屬於機動車，在部分不禁摩的城市，極端情況下，時速可達 60km/h，對智能頭盔降噪性能提出極限挑戰。智能頭盔作為長時佩戴裝備，舒適性至關重要，開放式藍牙耳機設計面臨技術瓶頸：低頻泄漏導致音質劣化、私密性差、環境噪聲幹擾嚴重以及高速風噪與回聲對通話質量的毀滅性衝擊。&lt;/p&gt; 
&lt;p&gt;智能硬件團隊連續攻關物理降噪技術、波束成型技術、AGC 和 AEC 算法技術，有效攻克了 60km/h 時速下降噪問題。物理降噪技術，採用氣動學優化的頭盔結構，結合輕量化抗衝擊材料，從源頭抑制風噪。波束成型（Beamforming）技術，通過調整兩個麥克風的擺放位置和靈敏度，形成一個"拾音束"，保留目標方向的聲音（人聲），同時屏蔽其他方向的噪聲。AGC 自動增益控制算法、AEC 回聲消除算法，60km/h 時速下精準分離人聲與噪聲。&lt;/p&gt; 
&lt;p&gt;依託仿真人頭系統、精密麥克風陣列及人工嘴等專業設備進行聲學驗證，在嚴格模擬的 60km/h 騎行噪聲、複雜社會生活及工地噪聲背景下，智能頭盔成功實現了對哈曼曲線目標的穩定達成------在時速 60km 的嚴苛環境下確保通話清晰度與私密性，顯著減少騎手因操作手機導致的分心風險。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//806159b1f94c20e1c8fedb5787b46fec.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;第二個主動安全能力------智能語音助手降低手機操作繁瑣性&lt;/strong&gt;。除了通話，騎手騎行過程中存在大量手機交互需求，如接單/查看訂單、回覆消息、導航設置等。傳統界面操作方式在騎行場景下存在重大安全隱患，根據數據統計騎手騎行時大概 90% 以上的操作都是與配送行為強相關。&lt;/p&gt; 
&lt;p&gt;安全需求和數據調研表明，語音交互是騎手在騎行或處理訂單時更安全的交互方式，解放雙手和雙眼。伴隨着 AI 大模型在意圖理解、內容生成和泛化方面能力提升，通過 AI 助手 + 智能頭盔結合，提升騎手 Hands-Off 能力、降低安全風險成為可能。&lt;/p&gt; 
&lt;p&gt;智能頭盔內置語音關鍵詞識別算法，"小靈小靈"一鍵喚醒智能助手。通過藍牙與騎手手機連接，通過語音交互隨時隨地召喚 AI 能力助力接單決策、訂單配送、違規申訴、IM 溝通。"小靈小靈"，一句輕喚喚醒智能頭盔連接履約垂域大模型。這不僅是語音助手，更是騎手的"雲端搭檔"。智能頭盔連接履約垂域大模型，成為騎手 AI 能力的入口。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;決策賦能&lt;/strong&gt;：實時分析周邊訂單熱力（如"現代城訂單密集"），結合騎手位置智能規劃路徑，提升接單效率；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;情感交互&lt;/strong&gt;：識別"訂單太少"的焦慮情緒，提供解決方案，替代手機操作降低騎行風險；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;無縫協同&lt;/strong&gt;：通過 IM 溝通模塊自動生成話術模板，申訴違規訂單時化身"數字律師"，守護騎手權益。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"小靈小靈，一會兒路上幫我接順路的訂單"。 "已幫你找到順路訂單"。 "小靈小靈，最近訂單太少怎麼辦"。 "距您 4 公里的現代城目前訂單較多，建議前往"。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3a9273f44b2e5fe277a21a09294f4d3e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 被動安全篇&lt;/h3&gt; 
&lt;p&gt;1）&lt;strong&gt;第一個被動安全能力------可靠的、苛刻的物理防護能力&lt;/strong&gt;。智能頭盔設計需要滿足國家強制標準，行業上，電動車頭盔設計滿足電動自行車乘員頭盔標準就足夠了（GB 811-2022 B3 電動自行車乘員頭盔國家標準）。但從騎手安全角度出發，我們主動將設計標準提升至摩托車頭盔級別（GB 811-2022 A3 摩托車乘員頭盔國家標準）。世界衞生組織（WHO）數據顯示，佩戴頭盔能顯著降低摩托車事故傷亡率，可減少近 40% 的死亡風險、超 70% 的嚴重受傷概率。美團智能頭盔從基礎防護層面，為騎手安全築牢根基：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;保護頭部免受衝擊&lt;/strong&gt;：智能頭盔是外賣騎手最重要的安全裝備之一，它能夠有效吸收碰撞時產生的衝擊力，防止頭部受到嚴重傷害。在交通事故中，頭部是最脆弱的部位，一旦與堅硬的路面或電線杆、行道樹發生碰撞，後果不堪設想。頭盔可以起到緩衝、減震的作用，從而降低受傷比例和死亡率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;提高可見性&lt;/strong&gt;：雖然頭盔本身並不直接提高可見性，但其設計通常包括透氣孔和通風系統，有助於騎手在騎行過程中保持頭部的乾爽和舒適。此外，頭盔的反光背心等配件可以在夜間或光線不足的環境中提高騎手的可見性，減少交通事故的發生。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增強舒適性和實用性&lt;/strong&gt;：頭盔的設計不僅注重安全性能，還兼顧了舒適性和實用性。例如，頭盔內部設有緩衝層，可以吸收外力衝擊，同時頭盔內置的風道和前後換氣口可以保持頭部的通風和乾燥。此外，一些高端頭盔還配備了護目鏡，可以有效阻擋灰塵和雨水，確保騎手的視野清晰。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//52a55281195d7fd7c24a9a787b1b6c73.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;第二個被動安全能力------意外摔倒監護功能&lt;/strong&gt;。交通事故是造成騎手和三者人身傷亡、財產損失的重要原因之一。當騎手不幸出現交通事故時，智能頭盔不僅在物理上保護騎手，還可以通過傳感器和相關算法識別事故的發生，同時聯動前端和後台，實現：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;平台報警與人工介入&lt;/strong&gt;。AI 外呼騎手確認事故，大象消息推送商管安全員。&lt;/li&gt; 
 &lt;li&gt;快速呼叫救援。支持一鍵撥打 120。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;信息收集&lt;/strong&gt;。時間地點、事故前速度、傳感器數據、現場音視頻等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;騎手關懷&lt;/strong&gt;。事故後第一時間 App 彈窗、AI 外呼，搭建騎手和平台之間的溝通橋樑，讓騎手感知到平台時刻關注騎手安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同時，有助於事故後信息分析、處理和事故預防，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事故還原&lt;/strong&gt;。通過事故採集信息可最大程度還原事故經過。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;保險協助&lt;/strong&gt;。通過精確的事故時間、地點等信息，有助於騎手與保險公司之間事故理賠。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高風險路段提前預警&lt;/strong&gt;。多名騎手發生事故路段/地點，標記為高風險位置，為其他路過騎手提前預警。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//33bcfd231f97e70b12a81515a67fb2ca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;當騎手發生事故後，端、邊、雲各個組件協同工作，完成整個碰撞摔倒監控功能，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;頭盔藉助於內置的加速度傳感器和自研運動特徵識別算法，識別到騎手疑似出現碰撞，並將疑似事故信息上報手機 App。&lt;/li&gt; 
 &lt;li&gt;騎手 App 進一步融合了手機中多種特徵和傳感器原始數據，確認是否為真實事故。&lt;/li&gt; 
 &lt;li&gt;騎手 App（在騎手授權的情況下）將會錄製一段時間的事故現場音視頻，留存現場音視頻信息。&lt;/li&gt; 
 &lt;li&gt;與此同時，騎手 App 將彈出反饋頁面等待騎手反饋，若騎手選擇自己可以解決或者沒摔倒，則表示此事件為小事故或誤報，不再後續處理。&lt;/li&gt; 
 &lt;li&gt;若騎手一鍵撥打 120 或長時間未得到反饋，則表示此事件可能為嚴重事故，雲端將會執行 AI 外呼騎手，進一步確認事故。&lt;/li&gt; 
 &lt;li&gt;若確認為嚴重事故，或騎手長時間未接聽，則此事故信息將會被自動推送站長和安全員，人工介入。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//25130d8086f0d95a2d1fd24b2a56b9d0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除了事故實時處理的相關功能外，碰撞摔倒監控收到的數據，有助於事故進一步分析，包括：速度、特徵、位置、傳感器參數分析等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//52251664c5a7014a962ad4326d245896.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;碰撞摔倒監控功能使用端、邊、雲協同處理框架。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;端&lt;/strong&gt;：智能頭盔通過分析騎手頭盔運動特徵，提供碰撞/摔倒原始實時感知；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;邊&lt;/strong&gt;：手機提供速度、IOD、姿態等高密度、高實時性關鍵信息並支撐融合算法的執行，對疑似事故進一步篩選判斷，同時使用 App 彈窗與騎手確認事故，並在事故後自動錄製音視頻；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;雲&lt;/strong&gt;：雲服務器提供數據記錄、AI 站長助理、大象消息推送、事故音視頻 AI 解析等能力，進一步確認事故，併為人工介入提供服務幫助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;端、邊、雲協同處理，有效提升了感知系統的準確性和實時性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//553e3e97c8ce5aff7ed4aba211ce6ef4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;總結和展望&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美團智能頭盔作為騎手配送的核心生產工具，已在實際應用中取得顯著成效。通過語音交互技術替代傳統手機操作，優化了騎手在配送過程中的多任務處理難題，大幅降低了分心駕駛帶來的安全隱患。實際數據顯示，使用智能頭盔的騎手在配送效率和安全指標上均有明顯提升。一線騎手反饋表明，這一工具已成為日常工作不可或缺的裝備，特別在高峯時段和複雜路況下價值更為突出。&lt;/p&gt; 
&lt;p&gt;2025 年，美團將會研發下一代智能頭盔。新型號將不再僅是一個交互工具，而是美團自研多模態大模型的重要入口和數據採集平台。硬件本身將會提供更全面的環境感知能力，不僅提升配送效率和安全性，這將為整個即時配送行業帶來一場技術革新。&lt;/p&gt; 
&lt;p&gt;| 關注「美團技術團隊」微信公眾號，在公眾號菜單欄對話框回覆【2024 年貨】、【2023 年貨】、【2022 年貨】、【2021 年貨】、【2020 年貨】、【2019 年貨】、【2018 年貨】、【2017 年貨】等關鍵詞，可查看美團技術團隊歷年技術文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cfa84bd9f6d0ac9aacadd6874b5b035b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美團技術團隊出品，著作權歸屬美團。歡迎出於分享和交流等非商業目的轉載或使用本文內容，敬請註明"內容轉載自美團技術團隊"。本文未經許可，不得進行商業性轉載或者使用。任何商用行為，請發送郵件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申請授權。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18688334</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18688334</guid>
      <pubDate>Sun, 17 Aug 2025 07:32:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>OpenAI Codex CLI 發佈 v0.23.0，新增模型選擇功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 為旗下命令行工具 Codex CLI 發佈了 v0.23.0 新版本，新增了在命令行中動態切換模型的功能，當前可選版本包括 gpt-5 high。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Codex CLI 是一個輕量級的 AI 編程助手，採用 TypeScript 和 Node.js 編寫，可以直接在用户的終端命令行運行，旨在充分發揮 AI 模型強大的推理能力，連接本地代碼環境，甚至支持處理截圖或草圖進行多模態編程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用户需通過 npm 全局升級至最新版本：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install -g @openai/codex&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;隨後在交互界面執行 /model 即可列出並選擇所需模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-083a314bd4eca0b83c7bd1c92b29b26d6b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://github.com/openai/codex/releases/tag/rust-v0.23.0&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367862</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367862</guid>
      <pubDate>Sun, 17 Aug 2025 07:23:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
