<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 24 Jun 2025 07:45:57 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>curl 之父發文介紹 OpenSSL 分支家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;curl 之父近日發表文章&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2025%2F06%2F23%2Fa-family-of-forks%2F" target="_blank"&gt;介紹&lt;/a&gt;&lt;/u&gt; OpenSSL 分支家族，展示了它們的差異、相似之處，以及支持它們所需的一些見解。&lt;/p&gt; 
&lt;p&gt;譯文如下：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;curl 支持使用 11 種不同的 TLS 庫進行編譯。其中六個庫是 OpenSSL 或其分支。讓我向你展示它們的差異、相似之處，以及支持它們所需的一些見解。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;SSLeay&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這一切都始於 SSLeay。這是我發現的第一個 SSL 庫，我們使用這個庫在 1998 年春天為 curl 添加了第一個 HTTPS 支持。顯然，SSLeay 項目早在 1995 年就已經啓動了。&lt;/p&gt; 
&lt;p&gt;那是一個我們還只支持 SSL 的年代；TLS 會在之後才出現。&lt;/p&gt; 
&lt;p&gt;OpenSSL 一直擁有一個古怪、不一致且極其龐大的 API 集（其中一大部分是從 SSLeay 繼承而來的），這進一步被稀疏的文檔所複雜化，這些文檔留給用户去依靠自己的想象力和技能去查閲源代碼，以獲取最後的細節解答（即使在 2025 年今天也是如此）。在 curl 中，我們經常收到關於如何使用這個庫的偶爾問題報告，即使已經過了幾十年。 presumably，這同樣適用於所有 OpenSSL 用户。&lt;/p&gt; 
&lt;p&gt;OpenSSL 項目經常受到批評，認為他們在幾年前升級到版本 3 之後，在性能方面有所疏忽。他們也一直進展緩慢或不願採用新的 TLS 技術，例如 QUIC 和 ECH。&lt;/p&gt; 
&lt;p&gt;儘管如此，OpenSSL 已經成為一種主導的 TLS 庫，尤其是在開源領域。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;LibreSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;回到 Heartbleed 事件時期，LibreSSL 分叉出來併成為獨立的項目。他們刪除了他們認為不屬於庫中的功能，創建了自己的 TLS 庫 API。幾年後，蘋果在 macOS 上使用 LibreSSL 提供 curl。他們有一些本地修補，使它&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2024%2F03%2F08%2Fthe-apple-curl-security-incident-12604%2F" target="_blank"&gt;行為與其他不同&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;LibreSSL 在 QUIC 的支持上落後，不支持 SSLKEYLOGFILE、ECH，而且如今在實現新功能方面似乎比 OpenSSL 更慢。&lt;/p&gt; 
&lt;p&gt;curl 自從創建以來就與 LibreSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;BoringSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Heartbleed 事件時期由 Google 分叉出來。&lt;em&gt;Google 為 Google 做的&lt;/em&gt;，他們沒有公開發布過，清理了很多原型和變量類型，並在 QUIC API 推動中處於領先地位。總體而言，大多數新的 TLS 發明都已在 BoringSSL 中實現和支持，比其他分叉更早。&lt;/p&gt; 
&lt;p&gt;Google 在 Android 的其他地方也使用這個。&lt;/p&gt; 
&lt;p&gt;curl 從創建以來就與 BoringSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AmiSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一個為使 OpenSSL 能夠在 AmigaOS 上正確編譯和運行而製作的 OpenSSL 分支或變種。我對它瞭解不多，但在這裏包含它是為了完整性。它似乎基本上是為 Amiga 系統移植的 OpenSSL。&lt;/p&gt; 
&lt;p&gt;當為 AmigaOS 編譯時，curl 也能與 AmiSSL 兼容。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;QuicTLS&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由於 OpenSSL 延遲響應並拒絕提供 QUIC API，其他分支在 2020 年初期（我尚未看到有人解釋原因）採取了行動。微軟和 Akamai 分支了 OpenSSL，產生了 &lt;em&gt;QuicTLS&lt;/em&gt;，此後它試圖成為一個 &lt;em&gt;輕量級&lt;/em&gt; 的分支，主要只是在與 BoringSSL 和 LibreSSL 支持相同風格的基礎上添加 QUIC API。&lt;em&gt;輕量級&lt;/em&gt; 的含義是它們密切跟蹤上游開發，並且除了 QUIC API 之外，沒有打算在其他方面偏離。&lt;/p&gt; 
&lt;p&gt;在 OpenSSL 3.5 中，他們終於提供了一個與 fork（包括 QuicTLS）提供的 QUIC API 不同的 QUIC API。我認為這促使 QuicTLS 重新考慮其未來的發展方向，但我們仍在等待確切的進展。&lt;/p&gt; 
&lt;p&gt;curl 自從創建以來就與 QuicTLS 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AWS-LC&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;這是由亞馬遜維護的一個 BoringSSL 分支。與 BoringSSL 不同的是，他們確實進行了實際的（頻繁的）發佈，因此看起來像一個項目，即使是非亞馬遜用户也可以實際使用和依賴——儘管他們存在的目的是 _維護一個與 AWS 使用的軟件和應用程序兼容的安全 libcrypto _。令人驚訝的是，他們維護的不僅僅是「僅僅」 libcrypto。&lt;/p&gt; 
&lt;p&gt;這個分支最近顯示出大量的活動，甚至在核心部分也是如此。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.haproxy.com%2Fblog%2Fstate-of-ssl-stacks" target="_blank"&gt;2025 年 5 月由 HAProxy 團隊進行的基準測試&lt;/a&gt; 表明，AWS-LC 顯著優於 OpenSSL。&lt;/p&gt; 
&lt;p&gt;AWS-LC 提供的 API 與 BoringSSL 的 API 並不完全相同。&lt;/p&gt; 
&lt;p&gt;curl 與 AWS-LC 從 2023 年初開始就配合得非常好。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;家族樹&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/img/202506/24145235_ALUZ.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;OpenSSL 分支家族樹&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;OpenSSL 分支家族現狀&lt;/h2&gt; 
&lt;p&gt;這六個不同的分支各自有其特定的特性、API 和功能，這些在不同版本中也會發生變化。目前我們仍然支持這六個分支，因為人們似乎仍在使用它們，而且維護起來是可行的。&lt;/p&gt; 
&lt;p&gt;我們使用相同的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcurl%2Fcurl%2Fblob%2Fmaster%2Flib%2Fvtls%2Fopenssl.c" target="_blank"&gt;單個源代碼文件&lt;/a&gt; 支持所有這些分支，並通過不斷增長的 #ifdef 邏輯來實現。我們通過在 CI 中使用這些分支進行構建驗證，儘管只使用了一小部分最近的版本。&lt;/p&gt; 
&lt;p&gt;隨着時間的推移，這些分支似乎正在逐漸彼此分離。我認為這還不構成一個問題，但我們當然在監控這種情況，可能在某個時候需要進行一些內部重構以適應這種變化。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;未來&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我無法預見會發生什麼。如果歷史是一堂課，我們似乎更傾向於走向更多的分支，而不是更少的分支。但當然，每一位閲讀這篇博客文章的讀者現在都會思考，所有這些分支所耗費的重複努力以及由此帶來的隱含低效性到底有多少。這不僅適用於這些庫本身，也適用於像 curl 這樣的用户。&lt;/p&gt; 
&lt;p&gt;我認為我們只能等待觀察。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357005/a-family-of-openssl-forks</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357005/a-family-of-openssl-forks</guid>
      <pubDate>Tue, 24 Jun 2025 06:52:53 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Kotlin 2.2.0 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;Kotlin 2.2.0 版本現已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2025%2F06%2Fkotlin-2-2-0-released%2F" target="_blank"&gt;發佈&lt;/a&gt;。此版本包含全新和穩定的語言功能、工具更新、針對不同平台的性能改進以及重要修復。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;一些亮點更新內容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;strong&gt;Language：&lt;/strong&gt;預覽版中的新語言功能，包括上下文參數。一些之前處於實驗階段的功能現已穩定，例如 guard conditions、non-local break and continue 以及 multi-dollar interpolation。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin compiler：&lt;/strong&gt;統一管理編譯器警告。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/JVM：&lt;/strong&gt;接口函數的默認方法生成發生變化。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/Native：&lt;/strong&gt;&amp;nbsp;LLVM 19 和用於跟蹤和調整內存消耗的新功能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/Wasm：&lt;/strong&gt;分離的 Wasm target，以及為每個項目配置 Binaryen 的功能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/JS：&lt;/strong&gt;修復為@JsPlainObject 接口生成的複製方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradle：&lt;/strong&gt;&amp;nbsp;Kotlin Gradle 插件中包含二進制兼容性驗證。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard library：&lt;/strong&gt;穩定的 Base64 和 HexFormat API。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;有關更改的完整列表可參閲&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fkotlinlang.org%2Fdocs%2Fwhatsnew22.html" target="_blank"&gt;Kotlin 2.2.0 中的新增功能&lt;/a&gt;或&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJetBrains%2Fkotlin%2Freleases%2Ftag%2Fv2.2.0" target="_blank"&gt;GitHub 上的發行説明&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357003/kotlin-2-2-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357003/kotlin-2-2-0-released</guid>
      <pubDate>Sun, 11 May 2025 06:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 上線 AI 音色設計功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniMax 稀宇科技&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSUqhAd54Q15Huq-AQ9EeCA" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;旗下 MiniMax Audio 上線了「Voice Design 音色設計」功能。&lt;/p&gt; 
&lt;p&gt;音色的維度一般分成音頻質量、發聲方式、情感基調以及人物畫像。該功能根據用户對音色需求的描述，模型自動拆解成音色相關的描述信息，並根據上述的描述來得到一個新的音色編碼。同視頻模型類似，該功能支持對音色的抽卡，如果不滿意，多試幾次，很容易得到理想中的專屬獨一音色，並可存儲下來做後續的音頻內容創作。&lt;/p&gt; 
&lt;p&gt;據介紹，通過 Voice Design 音色設計，用户可以通過自然語言來描述自己心中所想的音色，實現對多個維度的精準控制，甚至生成世界上不存在的音色。同時，Voice Design 與 Speech 02 語音模型在鏈路上相配合，用户在文字轉語音中可真正實現了「所需即所得」，以「任意語言 × 任意口音 × 任意音色」，實現可全自定義的無限組合。&lt;/p&gt; 
&lt;p&gt;此外，Voice Design 解決了語音合成領域的兩個挑戰：難以精準匹配用户各個細分場景下的多樣需求；復刻音色需要用户花費大量時間準備輸入素材，並且存在潛在的版權風險。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/142945_xJzZ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，Voice Design 已上線 MiniMax Audio 國內、海外兩個版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;國內版：minimaxi.com/audio&lt;/li&gt; 
 &lt;li&gt;海外版：minimax.io/audio&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357002/minimax-voice-design</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357002/minimax-voice-design</guid>
      <pubDate>Sun, 11 May 2025 06:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>空間理解模型 SpatialLM 正式發佈首份技術報告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，空間理解模型 SpatialLM 正式發佈首份技術報告。這一模型此前曾與 DeepSeek-V3、通義千問 Qwen2.5-Omni 一起登上全球最大的開源社區 HuggingFace 全球趨勢榜前三。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/140955_PZlV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作為一款將大語言模型擴展到 3D 空間理解任務中的模型，SpatialLM 能從 3D 點雲輸入生成結構化的空間場景描述，這一過程突破了大語言模型對物理世界幾何與空間關係的理解侷限，讓機器具備空間認知與推理能力，為具身智能等相關領域提供空間理解基礎訓練框架。&lt;/p&gt; 
&lt;p&gt;在開源後經過廣泛的實際驗證，本次技術報告聚焦 SpatialLM 1.1 升級版本，其不僅包含了詳細的消融實驗與訓練配方，還在點雲編碼方式、分辨率、用户指定識別類目等維度上實現優化。&lt;/p&gt; 
&lt;p&gt;多項基準測試數據顯示：該模型在任務數據集微調後，在空間佈局識別、3D 物體檢測任務中，均達到了相比與最新專業模型持平或更優的效果。&lt;/p&gt; 
&lt;p&gt;&lt;img height="309" src="https://static.oschina.net/uploads/space/2025/0624/141014_3iIl_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次報告重點圍繞&lt;strong&gt;算法框架&lt;/strong&gt;和&lt;strong&gt;訓練數據&lt;/strong&gt;兩方面展開。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在算法架構方面&lt;/strong&gt;，SpatialLM 將大語言模型（LLMs）擴展到 3D 空間理解任務中，特別在結構化室內建模領域實現了重要突破。&lt;/p&gt; 
&lt;p&gt;這一技術路線打破了傳統任務專屬架構（task-specific architecture）的限制，創新性地採用可編輯的文本形式表達場景結構。這一創新設計具有雙重技術優勢：&lt;/p&gt; 
&lt;p&gt;一方面&lt;strong&gt;發揮了羣核科技強大數據集能力&lt;/strong&gt;，通過持續訓練不斷優化空間識別精度；另一方面&lt;strong&gt;通過接入大語言模型，系統可直接接收並理解自然語言指令&lt;/strong&gt;，使空間理解模型從簡單任務執行工具轉變為能夠真正理解用户意圖的智能系統，從而推進了 LLMs 在空間理解和推理方向的能力邊界。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/141138_pYOw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;SpatialLM 模型的網絡結構&lt;/strong&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在訓練數據方面，SpatialLM 構建了一個全新的包含 3D 結構化信息的合成點雲數據集，打破了真實數據稀缺且難以標註的侷限。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1149" src="https://static.oschina.net/uploads/space/2025/0624/141210_bppP_2720166.png" width="974" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;該數據集包含超 1.2 萬場景、5.4 萬個房間的結構化室內點雲數據，其規模遠超 ScanNet（僅包含 1,513 個場景）等現有數據集。所有數據均源自真實項目的專業設計模型，經嚴格篩選與解析後形成符合真實世界統計分佈的虛擬環境，相較程序化生成的 ProcTHOR 等數據集具有更高真實性。&lt;/p&gt; 
&lt;p&gt;項目地址：https://manycore-research.github.io/SpatialLM/&lt;br&gt; 報告詳情：https://arxiv.org/abs/2506.07491&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356998</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356998</guid>
      <pubDate>Sun, 11 May 2025 06:12:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Roo Code 3.21.4 發佈，添加新的 Claude Code 提供商</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Roo Code 3.21.4 已發佈，此版本添加了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fproviders%2Fclaude-code" target="_blank"&gt;新的 Claude Code 提供商&lt;/a&gt;，允許用户通過 Claude Code 直接在 Roo Code 中使用其現有的 Claude Max 訂閲。這意味着用户可以利用其訂閲權益，無需額外支付按令牌計費的 API 費用，並可訪問 Claude Sonnet 4、Opus 4 等高級模型，同時享受零設置複雜性和對 Claude 思維模式及推理能力的完全訪問。&lt;/p&gt; 
&lt;p&gt;此次更新還修復了多文件差異應用時的起始行參數不正確問題，以及 Ollama 在某些模型上出現的驗證錯誤。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增 Claude Code provider 可用於本地 CLI 集成，允許用户將 Claude Max 訂閲直接在 Roo Code 中使用，連接訂閲後，使用訂閲福利而非按 token 支付 API 費用，還可使用 Claude Sonnet 4、Opus 4 等高級模型，且在初始設置時選擇 Claude Code 作為提供商，無需 API 密鑰，還能完全訪問 Claude 的思考模式和推理能力。&lt;/li&gt; 
 &lt;li&gt;修復了多個文件差異應用時起始行參數未正確工作的錯誤，以及解決了導致 Ollama 無法與某些模型配合使用的驗證錯誤。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fupdate-notes%2Fv3.21.4" target="_blank"&gt;https://docs.roocode.com/update-notes/v3.21.4&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356980/roocode-3-21-4</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356980/roocode-3-21-4</guid>
      <pubDate>Sun, 11 May 2025 03:54:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>vivo Pulsar 萬億級消息處理實踐 (2) - 從 0 到 1 建設 Pulsar 指標監控鏈路</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互聯網大數據團隊- You Shuo&lt;/p&gt; 
 &lt;p&gt;本文是《vivo Pulsar 萬億級消息處理實踐》系列文章第 2 篇，Pulsar 支持上報分區粒度指標，Kafka 則沒有分區粒度的指標，所以 Pulsar 的指標量級要遠大於 Kafka。在 Pulsar 平台建設初期，提供一個穩定、低時延的監控鏈路尤為重要。&lt;/p&gt; 
 &lt;p&gt;系列文章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247501335%26idx%3D1%26sn%3D3701be0b8b7b789e29c1ca53ba142e9d%26scene%3D21%23wechat_redirect" target="_blank"&gt;vivo Pulsar 萬億級消息處理實踐-數據發送原理解析和性能調優&lt;/a&gt;》&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;本文是基於 Pulsar 2.9.2/kop-2.9.2 展開的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;作為一種新型消息中間件，Pulsar 在架構設計及功能特性等方面要優於 Kafka，所以我們引入 Pulsar 作為我們新一代的消息中間件。在對 Pulsar 進行調研的時候（比如：性能測試、故障測試等），針對 Pulsar 提供一套可觀測系統是必不可少的。Pulsar 的指標是面向雲原生的，並且官方提供了 Prometheus 作為 Pulsar 指標的採集、存儲和查詢的方案，但是使用 Prometheus 採集指標面臨以下幾個&lt;strong&gt;問題&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 自帶的時序數據庫不是分佈式的，它受單機資源的限制；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 在存儲時序數據時消耗大量的內存，並且 Prometheus 在實現高效查詢和聚合計算的時候會消耗大量的 CPU。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;除了以上列出的可觀測系統問題，Pulsar 還有一些指標本身的問題，這些問題&lt;strong&gt;包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 的訂閲積壓指標單位是 entry 而不是條數，這會嚴重影響從 Kafka 遷移過來的用户的使用體驗及日常運維工作；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 沒有 bundle 指標，因為 Pulsar 自動均衡的最小單位是 bundle，所以 bundle 指標是調試 Pulsar 自動均衡參數時重要的觀測依據；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;kop 指標上報異常等問題。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;針對以上列出的幾個問題，我們在下面分別展開敍述。&lt;/p&gt; 
&lt;h1&gt;二、Pulsar 監控告警系統架構&lt;/h1&gt; 
&lt;p&gt;在上一章節我們列出了使用 Prometheus 作為觀測系統的侷限，由於 Pulsar 的指標是面向雲原生的，採用 Prometheus 採集 Pulsar 指標是最好的選擇，但對於指標的存儲和查詢我們使用第三方存儲來減輕 Prometheus 的壓力，整個監控告警系統架構如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c032b72031868384106c1cc665fafc42.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在整個可觀測系統中，各組件的職能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar、bookkeeper 等組件提供暴露指標的接口&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 訪問 Pulsar 指標接口採集指標&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;adaptor 提供了服務發現、Prometheus 格式指標的反序列化和序列化以及指標轉發遠端存儲的能力，這裏的遠端存儲可以是 Pulsar 或 Kafka&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Druid 消費指標 topic 並提供數據分析的能力&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;vivo 內部的檢測告警平台提供了動態配置檢測告警的能力&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於以上監控系統的設計邏輯，我們在具體實現的過程中遇到了幾個比較&lt;strong&gt;關鍵的問題：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;**一、**adaptor 需要接收 Pulsar 所有線上服務的指標併兼容 Prometheus 格式數據，所以在調研 Prometheus 採集 Pulsar 指標時，我們基於 Prometheus 的官方文檔開發了 adaptor，在 adaptor 裏實現了服務加入集羣的發現機制以及動態配置 prometheus 採集新新加入服務的指標：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 動態加載配置：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprometheus.io%2Fdocs%2Fprometheus%2Flatest%2Fconfiguration%2Fconfiguration%2F" target="_blank"&gt;Prometheus 配置-官方文檔&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 自定義服務發現機制：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprometheus.io%2Fblog%2F2015%2F06%2F01%2Fadvanced-service-discovery%2F" target="_blank"&gt;Prometheus 自定義服務發現-官方文檔&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在可以動態配置 Prometheus 採集所有線上正在運行的服務指標之後，由於 Prometheus 的指標是基於 protobuf 協議進行傳輸的，並且 Prometheus 是基於 go 編寫的，所以為了適配 Java 版本的 adaptor，我們基於 Prometheus 和 go 提供的指標格式定義文件（remote.proto、types.proto 和 gogo.proto）生成了 Java 版本的指標接收代碼，並將 protobuf 格式的指標反序列化後寫入消息中間件。&lt;/p&gt; 
&lt;p&gt;**二、**Grafana 社區提供的 Druid 插件不能很好的展示 Counter 類型的指標，但是 bookkeeper 上報的指標中又有很多是 Counter 類型的指標，vivo 的 Druid 團隊對該插件做了一些改造，新增了計算速率的聚合函數。&lt;/p&gt; 
&lt;p&gt;druid 插件的安裝可以參考官方文檔（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrafana.com%2Fgrafana%2Fplugins%2Fabhisant-druid-datasource%2F" target="_blank"&gt;詳情&lt;/a&gt;）&lt;/p&gt; 
&lt;p&gt;**三、**由於 Prometheus 比較依賴內存和 CPU，而我們的機器資源組又是有限的，在使用遠端存儲的基礎上，我們針對該問題優化了一些 Prometheus 參數，這些參數包括：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.retention=30m&lt;/strong&gt;：該參數配置了數據的保留時間為 30 分鐘，在這個時間之後，舊的數據將會被刪除。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.min-block-duration=5m&lt;/strong&gt;：該參數配置了生成塊（block）的最小時間間隔為 5 分鐘。塊是一組時序數據的集合，它們通常被一起壓縮和存儲在磁盤上，該參數間接控制 Prometheus 對內存的佔用。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.max-block-duration=5m&lt;/strong&gt;：該參數配置了生成塊（block）的最大時間間隔為 5 分鐘。如果一個塊的時間跨度超過這個參數所設的時間跨度，則這個塊將被分成多個子塊。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--enable-feature=memory-snapshot-on-shutdown&lt;/strong&gt;：該參數配置了在 Prometheus 關閉時，自動將當前內存中的數據快照寫入到磁盤中，Prometheus 在下次啓動時讀取該快照從而可以更快的完成啓動。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;三、Pulsar 指標優化&lt;/h1&gt; 
&lt;p&gt;Pulsar 的指標可以成功觀測之後，我們在日常的調優和運維過程中發現了一些 Pulsar 指標本身存在的問題，這些問題包括準確性、用户體驗、以及性能調優等方面，我們針對這些問題做了一些優化和改造，使得 Pulsar 更加通用、易維護。&lt;/p&gt; 
&lt;h2&gt;3.1 Pulsar 消費積壓指標&lt;/h2&gt; 
&lt;p&gt;原生的 Pulsar 訂閲積壓指標單位是 entry，從 Kafka 遷移到 Pulsar 的用户希望 Pulsar 能夠和 Kafka 一樣，提供以消息條數為單位的積壓指標，這樣可以方便用户判斷具體的延遲大小並儘量不改變用户使用消息中間件的習慣。&lt;/p&gt; 
&lt;p&gt;在確保配置 brokerEntryMetadataInterceptors=&lt;/p&gt; 
&lt;p&gt;org.apache.pulsar.common.intercept.AppendIndexMetadataInterceptor 情況下，Pulsar broker 端在往 bookkeeper 端寫入 entry 前，通過攔截器往 entry 的頭部添加索引元數據，該索引在同一分區內單調遞增，entry 頭部元數據示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;biz-log-partition-1 -l 24622961 -e 6
Batch Message ID: 24622961:6:0
Publish time: 1676917007607
Event time: 0
Broker entry metadata index: 157398560244
Properties:
"X-Pulsar-batch-size    2431"
"X-Pulsar-num-batch-message    50"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以分區為指標統計的最小單位，基於 last add confirmed entry 和 last consumed entry 計算兩個 entry 中的索引差值，即是訂閲在每個分區的數據積壓。下面是 cursor 基於訂閲位置計算訂閲積壓的示意圖，其中 last add confirmed entry 在攔截器中有記錄最新索引，對於 last consumed entry，cursor 需要從 bookkeeper 中讀取，這個操作可能會涉及到 bookkeeper 讀盤，所以在收集延遲指標的時候可能會增加採集的耗時。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f954824fee0a365add038a1a9aed4e3b.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上圖是新訂閲積壓指標和原生積壓指標的對比，新增的訂閲積壓指標單位是條，原生訂閲積壓指標單位是 entry。在客户端指定單條發送 100w 條消息時，訂閲積壓都有明顯的升高，當客户端指定批次發送 100w 條消息的時候，新的訂閲積壓指標會有明顯的升高，而原生訂閲積壓指標相對升高幅度不大，所以新的訂閲積壓指標更具體的體現了訂閲積壓的情況。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a62f11043d23bcbc8c667854834e2437.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.2 Pulsar bundle 指標&lt;/h2&gt; 
&lt;p&gt;Pulsar 相比於 Kafka 增加了自動負載均衡的能力，在 Pulsar 裏 topic 分區是綁定在 bundle 上的，而負載均衡的最小單位是 bundle，所以我們在調優負載均衡策略和參數的時候比較依賴 bunlde 的流量分佈指標，並且該指標也可以作為我們切分 bundle 的參考依據。我們在開發 bundle 指標的時候做了下面兩件事情：&lt;/p&gt; 
&lt;p&gt;統計當前 Pulsar 集羣非遊離狀態 bundle 的負載情況對於處於遊離狀態的 bundle（即沒有被分配到任何 broker 上的 bundle），我們指定 Pulsar leader 在上報自身 bundle 指標的同時，上報這些處於遊離狀態的 bundle 指標，並打上是否遊離的標籤。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d465e1009a88707edf424e50711bfd36.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上圖就是 bundle 的負載指標，除了出入流量分佈的情況，我們還提供了生產者/消費者到 bundle 的連接數量，以便運維同學從更多角度來調優負載均衡策略和參數。&lt;/p&gt; 
&lt;h2&gt;3.3 kop 消費延遲指標無法上報&lt;/h2&gt; 
&lt;p&gt;在我們實際運維過程中，重啓 kop 的 Coordinator 節點後會偶發消費延遲指標下降或者掉 0 的問題，從 druid 查看上報的數據，我們發現在重啓 broker 之後消費組就沒有繼續上報 kop 消費延遲指標。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）原因分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由於 kop 的消費延遲指標是由 Kafka lag exporter 採集的，所以我們重點分析了 Kafka lag exporter 採集消費延遲指標的邏輯，下圖是 Kafka-lag-exporter 採集消費延遲指標的示意圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e1c60c3dfc3fbdfdcbacbe9501bd9c30.gif" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中，kafka-lag-exporter 計算消費延遲指標的邏輯會依賴 kop 的 describeConsumerGroups 接口，但是當 GroupCoordinator 節點重啓後，該接口返回的 member 信息中 assignment 數據缺失，kafka-lag-exporter 會將 assignment 為空的 member 給過濾掉，所以最終不會上報對應 member 下的分區指標，代碼調試如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//44161110538352a1751268f3d5e09c35.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//756d27b220d957877e1713dd1ac7e29a.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;為什麼 kop/Kafka describeConsumerGroups 接口返回 member 的 assignment 是空的？因為 consumer 在啓動消費時會通過 groupManager.storeGroup 寫入__consumer_&lt;/p&gt; 
&lt;p&gt;offset，在 coordinator 關閉時會轉移到另一個 broker，但另一個 broker 並沒有把 assignment 字段反序列化出來（序列化為 groupMetadataValue，反序列化為 readGroupMessageValue），如下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//378c807ffd55bb262d54d26e52e6d73a.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）解決方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 GroupMetadataConstants#readGroup-&lt;/p&gt; 
&lt;p&gt;MessageValue() 方法對 coordinator 反序列化消費組元數據信息時，將 assignment 字段讀出來並設置（序列化為 groupMetadataValue，反序列化為 readGroupMessageValue），如下圖：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//97fe15c2e044eb609406a2ab3d5e51e8.png" alt="圖片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;四、總結&lt;/h1&gt; 
&lt;p&gt;在 Pulsar 監控系統構建的過程中，我們解決了與用户體驗、運維效率、Pulsar 可用性等方面相關的問題，加快了 Pulsar 在 vivo 的落地進度。雖然我們在構建 Pulsar 可觀測系統過程中解決了一部分問題，但是監控鏈路仍然存在單點瓶頸等問題，所以 Pulsar 在 vivo 的發展未來還會有很多挑戰。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18619289</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18619289</guid>
      <pubDate>Sun, 11 May 2025 03:41:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>谷歌開源智能體通信協議 Agent2Agent (A2A) 已被 Linux 基金會接管</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 6 月 23 日，Linux 基金會在北美開源峯會&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-the-agent2agent-protocol-project-to-enable-secure-intelligent-communication-between-ai-agents" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;啓動&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fa2aproject%2FA2A" target="_blank"&gt;Agent2Agent（A2A）&lt;/a&gt;項目。該項目由谷歌於 2025 年 4 月發起並獲得 100 多家領先技術公司支持，旨在創建一個開放協議，實現 AI 智能體間的安全通信與協作。Linux 基金會將負責 A2A 項目的管理，確保其中立性、協作性和治理性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8fe3e4a0fa786414ab6de80f762399a6327.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;A2A 協議賦予開發者構建跨平台、廠商和框架自由互操作的智能體的能力。它允許智能體在動態多智能體環境中發現彼此、安全交換信息並跨系統協作。這有助於提高模塊化程度、降低供應商鎖定風險並加速創新。&lt;/p&gt; 
&lt;p&gt;加入 Linux 基金會後，A2A 規範化了其對開放、協作生態系統的承諾——提供更大的自主權並提高生產力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Linux 基金會執行董事吉姆·澤姆林表示，「我們很高興成為 Agent2Agent 協議項目的新家園，通過加入 Linux 基金會，A2A 將確保長期的中立性、協作性和治理性，這將解鎖下一代由智能體間協作驅動的生產力時代。」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Linux 基金會的治理下，A2A 將保持供應商中立，強調包容性貢獻，並繼續關注協議的擴展性、安全性以及跨行業的實際可用性。&lt;/p&gt; 
&lt;p&gt;多家科技巨頭表達了對 A2A 項目的支持。AWS 副總裁 Swami Sivasubramanian 認為，智能體 AI 對客户體驗至關重要，A2A 加入 Linux 基金會將創造更多機會。谷歌雲計算業務副總裁兼總經理 Rao Surapaneni 表示，A2A 協議為通信建立了重要開放標準，推動了跨平台和系統的真正互操作性 AI 智能體的發展。思科 Outshift 總經理兼高級副總裁 Vijoy Pandey 強調了社區驅動開發在智能體間廣泛採用中的重要性。Salesforce 產品架構師 Gary Lerhaupt 稱，企業 AI 的未來在於智能體間的無縫協作。SAP 全球人工智能高級副總裁兼全球負責人 Walter Sun 表示，A2A 開放標準確保了不同廠商的智能體能夠交互、共享上下文並協同工作。微軟產品副總裁 Yina Arenas 承諾，將結合開放互操作性與企業級功能，負責任地大規模部署智能體。ServiceNow 平台工程與人工智能技術集團執行副總裁 Joe Davis 表示，A2A 的開放標準構建了跨平台協作的基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356965/linux-foundation-launches-the-agent2agent-protocol-project</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356965/linux-foundation-launches-the-agent2agent-protocol-project</guid>
      <pubDate>Sun, 11 May 2025 02:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>搶答題：「把文字變成數字」、「對結果精修」，都是什麼技術？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;寫 AI 應用，你總不能就指望大模型直出的效果吧，很多必要的時候，需要「通過外部策略」的方式去影響大模型處理資料的邏輯，檢索增強生成技術&amp;nbsp;RAG 是這種路數，而 RAG 中，Embedding 和 Reranker 又是重中之重的環節，當前這兩個環節也都有專門模型化範式來接入，並且已成為高效構建智能問答、知識檢索、推薦系統等應用的核心組件。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智能問答&lt;/strong&gt;：通過高精度的 Embedding 建立問答對檢索索引，結合 Reranker 精細排序，顯著提升答案的相關性與準確率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知識庫檢索&lt;/strong&gt;：在海量文檔中精準定位用户意圖，支持多輪對話和上下文關聯檢索。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦系統&lt;/strong&gt;：基於用户歷史行為與商品描述生成向量表示，實現個性化推薦、相似內容召回。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;輿情監測&lt;/strong&gt;：快速將海量文本轉為向量，通過聚類與分類算法進行主題發現與情感分析。&lt;/p&gt; 
&lt;p&gt;這些都是典型的需要&amp;nbsp;Embedding 與 Reranker 給力的場景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/103257_8UDj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這過程中，「把文字變成數字」與「對檢索結果精修」是兩大核心環節。下面以通俗的方式，分兩塊為你説明 Embedding 和 Reranker 的原理與價值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Embedding：把語義「壓縮」成向量&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;想象你在把一本書裏的每句話都翻譯成一長串數字，這串數字既要能表達句子的中心意思，又要在空間裏與含義相近的句子靠得更近。Embedding 模型，就是完成這件「翻譯」工作的機器。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多層語義提取&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Embedding 模型內部運用了多層 Transformer 編碼器。第一層關注詞與詞之間的基本搭配（如「蘋果」與「果汁」關係）；中間層捕捉句子結構（比如主謂賓），最後幾層則把整句話和上下文聯繫起來，形成一個高維向量。在 Qwen3‑Embedding‑8B 中，這個向量高達 4096 維，讓模型能夠在更廣的維度上區分細微差異。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;對比學習讓向量更「聰明」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;訓練時，模型不僅看成對的問答或同義句怎麼對應，更會把數千萬甚至上億條不相關的句子拉遠。這樣，真正相似的句子在向量空間裏互相靠近，不相干的句子被推得更遠，檢索時才不會把「蘋果手機電池續航」誤當成「香蕉營養價值」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;動靜結合的量化策略&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;向量越大，存儲和檢索壓力越大。動態量化技術能讓模型在運行時自動決定哪些維度可以用更低精度來存（節省空間），哪些維度要保持高精度（保證關鍵語義不丟失）。在實際部署中，這讓檢索速度實現了「百毫秒級」響應，同時節省了約 60–70% 的存儲。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Reranker：給檢索結果「打分」再排序&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Embedding 檢索出來的是一個粗略的「候選集」，真正要交給用户之前，還需要一位「品質檢驗師」——Reranker，將這些候選答案再打一遍分、排個序，讓最優答案排在最前面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;深度交互，跳出雙塔侷限&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;傳統雙塔結構（query 和 document 分別編碼）雖然高效，但只在編碼後進行一次簡單匹配，會錯失一些深度關聯。我們的 Reranker 在兩側編碼後，還會引入多輪交互注意力——就好像讓問題和答案反覆「對話」，捕捉細節差異，才能判斷「哪句話更貼近用户真實意圖」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;實時反饋持續進化&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;當用户點擊某個答案或給出負面評價時，這些行為會被立即反饋到在線增量學習系統中。Reranker 會在後台快速微調自身參數，就像運動員不斷根據比賽錄像調整戰術，保證隨着業務熱點變化，排序效果始終領先。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;多目標優化兼顧公平與準確&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;除了相關性打分外，模型還聯合了分類（這是不是好答案？）、迴歸（該答案得分應該是多少？）和對比損失（同類答案之間應該怎麼排）三個目標共同訓練，確保排序既精準又穩定，不會因為單一指標過擬合而出現極端情況。&lt;/p&gt; 
&lt;p&gt;總的來説，&lt;strong&gt;Embedding 負責將文本「量化」到高維空間，為檢索打下基礎；Reranker 則在此基礎上「打磨」結果，確保輸給用户的是最精煉、最相關的答案&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為了讓更多開發者和企業能夠零門檻體驗最前沿的 AI 能力，模力方舟攜手國產 GPU 廠商，重磅宣佈——&lt;strong&gt;已部署的 17 個 Embedding 和 Reranker 模型，全量免費使用&lt;/strong&gt;！&lt;/p&gt; 
&lt;p&gt;&lt;img height="964" src="https://static.oschina.net/uploads/space/2025/0624/103342_VXq3_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;還有更多的免費模型選擇，盡在模力方舟之模型廣場：&lt;em&gt;&lt;strong&gt;&lt;a href="https://ai.gitee.com/serverless-api" target="_blank"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1520" src="https://static.oschina.net/uploads/space/2025/0624/103354_4RFB_2720166.png" width="1074" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;好東西一起分享之，圖片拿去轉吧。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356959</guid>
      <pubDate>Sun, 11 May 2025 02:34:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>微軟發佈設備端模型 Mu，支持在 Windows 中設置智能體</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微軟&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindowsexperience%2F2025%2F06%2F23%2Fintroducing-mu-language-model-and-how-it-enabled-the-agent-in-windows-settings%2F" target="_blank"&gt;宣佈&lt;/a&gt;推出面向設備端的小參數模型 Mu。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1294" src="https://static.oschina.net/uploads/space/2025/0624/103032_Y3sh_2720166.png" width="3086" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mu 僅有 3.3 億參數，但其性能可以比肩微軟之前發佈的小參數模型 Phi-3.5-mini，體量卻比它小 10 倍左右，並且在離線 NPU 的筆記本設備上，可以跑出每秒超過 100 tokens 的響應，這在小參數模型領域非常罕見。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fe4a5c2aa3f7e02f94f3883e0a0a49dd2c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，Mu 支持在 Windows 中設置智能體，可將自然語言指令實時轉化為系統操作，例如，只需對着電腦説一句 「把鼠標指針調大一些，調整屏幕亮度」，智能體就能精準定位到相關設置項一鍵完成調整。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356958/microsoft-mu-language-model-</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356958/microsoft-mu-language-model-</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>前字節 Seed 大語言模型負責人喬木被辭退</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;此前，一份有關字節跳動豆包大模型核心技術人員喬某及同組 HRBP 程某存在不正當關係的舉報文件在網上廣泛傳播。6 月 23 日，紅星資本局獲悉，字前字節 Seed 大語言模型負責人喬木以及關聯 HRBP 已被辭退。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-d1fc69ad929f39468990c7341f686a6bd81.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;字節在最新發布的一期廉政通報中提到：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;公司 Seed 部門（字節跳動豆包大模型團隊）某前員工與支持其團隊的某前 HRBP（人力資源）存在未申報的親密關係，屬於公司利益衝突管理規定的禁止場景（如上下級關係、共同直屬上級或一方為另一方 HRBP 等）。二人不僅未按規定申報利益衝突，且在接受調查過程中多次作虛假陳述，嚴重違反公司制度。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根據通報，字節跳動已對涉事二人作出辭退處理，並全額扣發其年終獎。對此，字節官方尚無説法。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356956</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356956</guid>
      <pubDate>Sun, 11 May 2025 02:15:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>博士生用 Typst 取代 LaTeX 寫論文引熱議：編譯速度快 9 倍，但導師並不滿意</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;一位博士生最近在網上分享了自己使用 Typst（而非傳統的 LaTeX）撰寫博士論文的經歷，在技術社區引發了激烈討論。這個選擇看似小眾，卻觸及了學術界一個由來已久的痛點：LaTeX 雖然功能強大，但學習曲線陡峭、編譯速度緩慢、錯誤信息晦澀難懂。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="400" src="https://oscimg.oschina.net/oscnet/up-da99f6b5d1fdd0954f78d4992bf7563f660.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;從 90 秒到 10 秒：速度是第一生產力&lt;/h2&gt; 
&lt;p&gt;作者選擇 Typst 的直接原因很簡單——一位朋友的 LaTeX 論文編譯時間竟然長達 90 秒。「我太容易分心了，根本無法忍受在做小改動時要等 90 秒的編譯時間。」相比之下，Typst 的編譯速度快得驚人：即使是 150 頁以上的論文，完整編譯只需 15 秒，內容修改幾乎是即時更新的。&lt;/p&gt; 
&lt;p&gt;HackerNews 用户 WhyNotHugo 深有同感：「我最後一篇論文用的是 makefile，通常能工作。但不工作時，運行兩次就能修復。最罕見的情況下，我必須運行&lt;code&gt;git clean -xdf&lt;/code&gt;，然後下一次運行就能工作了。」另一位用户 shusaku 則幽默地評論道：「瘋狂的定義就是做同樣的事情兩次卻期待不同的結果。巧合的是，這正是編譯 LaTeX 的基本方式。」&lt;/p&gt; 
&lt;h2&gt;Typst 的語言設計：現代化的力量&lt;/h2&gt; 
&lt;p&gt;Typst 最大的亮點在於其精心設計的語言。作者將其描述為「Markdown 和動態類型 Rust 的混合體」，這種組合聽起來很奇怪，但實際使用起來卻非常舒適。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typst"&gt;#let numbers = (1,2,5,8)
This is *bold text*. The sum of [#numbers.map(it =&amp;gt; str(it)).join(", ")] is *#numbers.sum()*
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這段代碼會生成：「This is &lt;strong&gt;bold text&lt;/strong&gt;. The sum of [1, 2, 5, 8] is &lt;strong&gt;16&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;相比 LaTeX 中到處都是反斜槓的語法，Typst 的設計更加直觀。更重要的是，Typst 擁有一個設計良好的腳本語言。正如作者所説：「我對 LaTeX 最大的抱怨是沒有任何東西是一致的。每個包都定義自己的小工具，甚至連基本的 if 語句都不統一。感覺你不是在學 LaTeX，而是在分別學習每個包。」&lt;/p&gt; 
&lt;h2&gt;實際應用：不只是紙上談兵&lt;/h2&gt; 
&lt;p&gt;作者展示了一個實際案例：他收集了各種硬件描述語言的元數據，存儲在 TOML 文件中。由於 Typst 可以直接解析 TOML，他能夠輕鬆地用這些數據生成論文中的分類圖表。這種程度的編程集成在 LaTeX 中幾乎是不可想象的。&lt;/p&gt; 
&lt;p&gt;HackerNews 用户 lizimo 分享了更有趣的應用場景：「我們已經在生產環境中使用 Typst 生成 PDF 文檔幾個月了，比如發票和標籤。每天生成數千份文檔，我很高興其中一些被打印出來，供倉庫裏做實際工作的人使用。」&lt;/p&gt; 
&lt;h2&gt;痛點仍在：生態系統的挑戰&lt;/h2&gt; 
&lt;p&gt;然而，Typst 並非完美無缺。最大的問題來自於參考文獻管理。Typst 每個文檔只能有一個參考文獻部分和文件，這對於需要為引言和每篇包含的論文分別設置參考文獻的博士論文來説是個致命缺陷。雖然 Alexandria 包提供瞭解決方案，但仍需要額外的工作。&lt;/p&gt; 
&lt;p&gt;更大的挑戰在於生態系統。正如 HackerNews 用户 gumbojuice 指出：「我堅持使用 LaTeX，不是因為偏好，而是因為期刊/會議仍然不接受比如 typst。他們會接受嗎？我不知道，這取決於他們是否願意將其整合到工具鏈中。」&lt;/p&gt; 
&lt;h2&gt;導師的不同視角&lt;/h2&gt; 
&lt;p&gt;有趣的是，作者的導師對此有完全不同的看法。導師認為：「問題是你必須調整它才能讓事情看起來符合要求。這不一定是優勢。作為導師，我會建議在所有手稿都用 LaTeX 編寫的領域中使用 Typst 嗎？不會。」&lt;/p&gt; 
&lt;p&gt;導師特別指出，從監督者的角度來看，他幾乎沒有在源代碼中編輯任何文本，而是讓作者自己編輯文本和格式，這相當低效。&lt;/p&gt; 
&lt;h2&gt;社區的兩極化反應&lt;/h2&gt; 
&lt;p&gt;HackerNews 的討論呈現出明顯的兩極分化。支持者認為 Typst 代表了未來。用户 commandersaki 列出了 Typst 的諸多優勢：「編譯時不會生成 5 個該死的文件」、「編譯是即時的」、「診斷信息更容易理解（有點像 Rust 編譯器的建議風格）」。&lt;/p&gt; 
&lt;p&gt;反對者則擔心 Typst 的持續性。用户 dleslie 警告説：「三十年後 LaTeX 仍將是開源的，可能還會被維護。Typst 看起來是開源和閉源的混合體；這種模式往往會忽視開源部分，在閉源部分實現關鍵功能。」&lt;/p&gt; 
&lt;p&gt;用户 the-wumpus 則反駁道：「網頁應用編輯器是閉源的，但它提供的大部分功能都是開源的，所以本地編輯體驗類似（在我看來更好）。typst 編譯器、LSP 和你需要使用的所有東西都是開源的。」&lt;/p&gt; 
&lt;h2&gt;寫在最後&lt;/h2&gt; 
&lt;p&gt;正如作者在結論中所説：「如果你像我一樣，喜歡玩編程語言，容易被工具困擾，更喜歡可以調整到完全符合自己要求的工具，而不是開箱即用但難以調整的工具，那麼 Typst 絕對值得一試。」&lt;/p&gt; 
&lt;p&gt;對於學術界來説，Typst 的出現提供了一個思考的契機：我們是否應該繼續忍受 LaTeX 的種種不便，僅僅因為「大家都在用」？還是應該擁抱新技術帶來的效率提升？&lt;/p&gt; 
&lt;p&gt;用户 rcpt 的評論或許代表了一種新的可能：「自從我寫 LaTeX 以來已經有十年了，我同意它的所有痛點。但似乎 LaTeX 正是 LLM 會完美處理的東西。我覺得今天使用它不會太糟糕。」&lt;/p&gt; 
&lt;p&gt;無論選擇哪種工具，重要的是它能幫助研究者更好地表達思想。正如用户 noelwelsh 所説：「在一天結束時，我不是在試圖遷移任何人。使用你認為最好的。對於我的使用場景，我確信 Typst 是比 LaTeX 更好的選擇。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356954</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356954</guid>
      <pubDate>Sun, 11 May 2025 01:57:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>Solon Expression Language (SnEL)：輕量高效的 Java 表達式引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;一、SnEL 是什麼？&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Solon Expression Language（簡稱 SnEL）是 Solon 生態體系中的輕量級表達式引擎，專為 Java 開發者設計。它採用獨特的"求值表達式"模型，通過簡潔的語法實現複雜邏輯處理，同時保持極高的執行效率和安全性。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;項目地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Gitee:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/noear/solon-expression"&gt;https://gitee.com/noear/solon-expression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsolon-expression" target="_blank"&gt;https://github.com/noear/solon-expression&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二、核心特性解析&lt;/h2&gt; 
&lt;h3&gt;1. 安全可靠的表達式引擎&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;無副作用設計&lt;/strong&gt;：禁止&lt;code&gt;new&lt;/code&gt;實例化、控制語句等危險操作&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;上下文隔離&lt;/strong&gt;：通過&lt;code&gt;StandardContext&lt;/code&gt;嚴格管控變量訪問範圍&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 豐富的表達式能力&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 複雜邏輯表達式示例&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;expr&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"""
    ((age &amp;gt; 18 AND salary &amp;lt; 5000) OR NOT isMarried) 
    AND tags IN ['vip','premium'] 
    OR level == 'gold'"""&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;支持功能主要包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基礎運算：算術、比較、邏輯運算&lt;/li&gt; 
 &lt;li&gt;集合操作：IN/NOT IN 集合判斷&lt;/li&gt; 
 &lt;li&gt;嵌套訪問：多級對象屬性/方法調用&lt;/li&gt; 
 &lt;li&gt;靜態方法：直接調用類靜態方法&lt;/li&gt; 
 &lt;li&gt;三元運算：條件表達式支持&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;更多參考官網：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2F1043" target="_blank"&gt;《SnEL 求值表達式語法和能力説明》&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. 獨創的模板引擎&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;雙模式模板處理：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 求值表達式模板&lt;/em&gt;
SnEL.evalTmpl(&lt;span style="color:#50a14f"&gt;"訂單總額：#{order.amount * 0.95}"&lt;/span&gt;);

&lt;em&gt;// 屬性表達式模板（帶默認值）&lt;/em&gt;
SnEL.evalTmpl(&lt;span style="color:#50a14f"&gt;"配置參數：${server.timeout:3000}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、企業級功能深度解析&lt;/h2&gt; 
&lt;h3&gt;1. 上下文增強方案&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 標準 Map 上下文&lt;/em&gt;
Map&amp;lt;String,Object&amp;gt; ctx = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;HashMap&lt;/span&gt;&amp;lt;&amp;gt;();
ctx.put(&lt;span style="color:#50a14f"&gt;"user"&lt;/span&gt;, userService.getCurrent());

&lt;em&gt;// 增強型 Bean 上下文&lt;/em&gt;
&lt;span style="color:#986801"&gt;StandardContext&lt;/span&gt; &lt;span style="color:#986801"&gt;context&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;StandardContext&lt;/span&gt;(userEntity);
context.properties(configProps); &lt;em&gt;// 綁定配置屬性&lt;/em&gt;

&lt;em&gt;// 虛擬 root 訪問&lt;/em&gt;
SnEL.eval(&lt;span style="color:#50a14f"&gt;"root.id &amp;gt; 1000"&lt;/span&gt;, context);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 多場景表達式轉換&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;基於 AST 的通用轉換接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#986801"&gt;Expression&lt;/span&gt; &lt;span style="color:#986801"&gt;expr&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.parse(&lt;span style="color:#50a14f"&gt;"age &amp;gt; 18 AND status=='active'"&lt;/span&gt;);

&lt;em&gt;// 轉換為 Redis 查詢語法&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;redisFilter&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; RedisFilterTransformer.getInstance().transform(expr);

&lt;em&gt;// 轉換為 Elasticsearch DSL&lt;/em&gt;
Map&amp;lt;String,Object&amp;gt; esQuery = ElasticsearchFilterTransformer.getInstance().transform(expr);

&lt;em&gt;// 輸出語法樹結構&lt;/em&gt;
PrintUtil.printTree(expr);
&lt;/code&gt;&lt;/pre&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;轉換器類型&lt;/th&gt; 
   &lt;th&gt;輸出示例&lt;/th&gt; 
   &lt;th&gt;應用場景&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Redis&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;(@age:[18 +inf] @status:{active})&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;緩存查詢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Milvus&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;((metadata["age"] &amp;gt; 18) and (metadata["status"] == "active"))&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;向量數據庫&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Elasticsearch&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;{bool={must=[{range={age={gt=18}}}, {term={status={value=active}}}]}}&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;全文檢索&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;SQL&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;WHERE age &amp;gt; 18 AND status='active'&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;數據庫查詢&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;四、典型應用場景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;動態規則引擎：金融風控規則配置&lt;/li&gt; 
 &lt;li&gt;智能路由：微服務調用條件路由&lt;/li&gt; 
 &lt;li&gt;低代碼平台：表單校驗邏輯動態配置&lt;/li&gt; 
 &lt;li&gt;數據分析：實時數據過濾與計算&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;五、快速入門&lt;/h2&gt; 
&lt;h3&gt;1. 添加依賴&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-expression&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;最新版本&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 基礎用法示例&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;Demo&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; {
        Map&amp;lt;String,Object&amp;gt; context = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;HashMap&lt;/span&gt;&amp;lt;&amp;gt;();
        context.put(&lt;span style="color:#50a14f"&gt;"price"&lt;/span&gt;, &lt;span style="color:#986801"&gt;99.5&lt;/span&gt;);
        context.put(&lt;span style="color:#50a14f"&gt;"discount"&lt;/span&gt;, &lt;span style="color:#986801"&gt;0.8&lt;/span&gt;);
        
        &lt;span style="color:#986801"&gt;Object&lt;/span&gt; &lt;span style="color:#986801"&gt;result&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.eval(&lt;span style="color:#50a14f"&gt;"price * discount &amp;gt; 50"&lt;/span&gt;, context);
        System.out.println(&lt;span style="color:#50a14f"&gt;"是否符合條件："&lt;/span&gt; + result);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. 性能優化建議&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;複用解析結果：對固定表達式使用 SnEL.parse() 緩存 AST&lt;/li&gt; 
 &lt;li&gt;上下文優化：複雜對象優先使用 StandardContext&lt;/li&gt; 
 &lt;li&gt;避免頻繁解析：高併發場景預編譯表達式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;六、企業實踐案例&lt;/h2&gt; 
&lt;h3&gt;案例 1：電商促銷系統&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 動態計算促銷條件&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;rule&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"""
    (user.level IN ['VIP','SVIP'] OR order.amount &amp;gt; 1000) 
    AND inventory.stock &amp;gt; 0 
    AND NOT blacklist.contains(user.id)"""&lt;/span&gt;;
    
&lt;span style="color:#986801"&gt;Boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.eval(rule, context);&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356941</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356941</guid>
      <pubDate>Sun, 11 May 2025 00:43:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>🎉夜鶯監控 V8 發版，內置支持 DeepSeek 對接</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:left"&gt;夜鶯監控發佈了 v8.beta14 版本，這個版本是可以上生產的，強烈建議升級。正式版會在每年夜鶯大會上發佈，今年預計是 7.4 號。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;下面快速介紹一下 v8.beta14 的主要更新。&lt;/p&gt; 
&lt;h2&gt;beta14 重點更新&lt;/h2&gt; 
&lt;h3&gt;支持 Postgres 告警&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;又支持了一個新的告警數據源：Postgres，可以對 Postgres 中的數據做異常判定啦，有些業務數據（比如訂單數據、商品數據）可能是存在 Postgres 或 MySQL 等 OLTP 庫中，所以這算是多了一個業務數據告警的手段，業務監控的告警規則不用很多，但是通常都極為關鍵。&lt;/p&gt; 
&lt;p&gt;&lt;img height="630" src="https://oscimg.oschina.net/oscnet/up-e30994bca7c3d950bb85c39db5c1e5ccd77.png" width="1890" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;您可以在&lt;code&gt;集成中心-數據源&lt;/code&gt;添加 Postgres 數據源，目前的開源版本，該數據源僅支持告警，不支持看圖（即時查詢、儀表盤等）。&lt;/p&gt; 
&lt;h3&gt;對接 AI 做 Summary&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;告警事件 Pipeline 新增一個新的內置處理器：AI Summary，可以使用 DeepSeek 等對告警事件做總結，將總結之後的信息附加到告警事件中，進而通過告警消息發出。讓您的監控與 AI 之間的聯動觸手可及。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1190" src="https://oscimg.oschina.net/oscnet/up-8c07f9b00aebd755c3f0a894362cb7207f8.png" width="2002" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;填入 AI 服務器的地址和 API Key，以及要使用的模型，即可引入 AI Summary 的能力。夜鶯內置提供了一個提示詞，您可以根據自己的需求修改提示詞。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;更多使用文檔，可以參考紅色箭頭指向的那個&lt;code&gt;使用説明&lt;/code&gt;。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;事件處理器非常具有想象力，歡迎給我們投稿分享您的實踐案例。&lt;/p&gt; 
&lt;h3&gt;告警事件匿名訪問&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;重新設計了告警事件匿名訪問的邏輯。您可以在告警事件詳情頁面找到&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;生成分享鏈接&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的入口。最新邏輯是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;默認不支持匿名訪問，必須登錄才能看到事件詳情&lt;/li&gt; 
 &lt;li&gt;通過&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;生成分享鏈接&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;可以生成一個帶 token（有過期時間）的 URL，訪問那個 URL 就可以匿名訪問了&lt;/li&gt; 
 &lt;li&gt;如果夜鶯配置文件 config.toml 中直接開啓了全局的匿名訪問，則匿名訪問的 token 就沒用了，只要訪問&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/share/alert-his-events/${id}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;就會直接放行，配置文件中的全局匿名訪問配置位置是：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;&lt;span&gt;&lt;span&gt;[&lt;span style="color:#a6e22e"&gt;Center&lt;/span&gt;.&lt;span style="color:#a6e22e"&gt;AnonymousAccess&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#a6e22e"&gt;PromQuerier&lt;/span&gt; = &lt;span style="color:#66d9ef"&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 就是下面這個&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#a6e22e"&gt;AlertDetail&lt;/span&gt; = &lt;span style="color:#66d9ef"&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:left"&gt;如果夜鶯開放在公網，請不要打開匿名訪問！&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;其他 Changelog 請參考&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale%2Freleases%2Ftag%2Fv8.0.0-beta.14" target="_blank"&gt;github release&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;頁面。&lt;/p&gt; 
&lt;h2&gt;升級須知&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;大家可以從夜鶯的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale%2Freleases" target="_blank"&gt;github releases&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;頁面下載到最新的發佈包。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;v6/v7 版本都可以平滑升級：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;建議先備份老版本的二進制、配置、integrations 目錄等，留好後路，然後就可以放心大膽升級了&lt;/li&gt; 
 &lt;li&gt;如果夜鶯所用的 DB 賬號有建表、改表權限，會自動更新表結構，否則就要參考代碼倉庫裏&amp;nbsp;docker/migratesql&amp;nbsp;手工改表結構了&lt;/li&gt; 
 &lt;li&gt;integrations 目錄可以直接替換成新版&lt;/li&gt; 
 &lt;li&gt;配置文件 etc/config.toml 建議認真 diff 一下&lt;/li&gt; 
 &lt;li&gt;容器啓動的話，直接拉取 latest 鏡像重啓即可&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;夜鶯產品特性介紹的 PPT&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;有些人可能對夜鶯的產品還不太瞭解，特准備了一份 PPT，請參考：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fc9xudyniiq.feishu.cn%2Fslides%2FO6xJsUzZclzeUrdMb9DcynVtnSf" target="_blank"&gt;PPT&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356937/nightingale-release-v8beta-14</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356937/nightingale-release-v8beta-14</guid>
      <pubDate>Sun, 11 May 2025 00:17:00 GMT</pubDate>
      <author>來源: 投稿</author>
    </item>
    <item>
      <title>宇樹王興興為高考生送上報考建議</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;隨着高考成績、分數線陸續公佈，對於那些想投身具身智能行業的考生，宇樹科技創始人王興興發文結合自身的經歷給出一些專業報考建議。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-513fc7219a635ce3cbb2d6d3d7ae7738440.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你從小喜歡拆解維修一些電子產品，或者動手 DIY 做點東西，推薦學習機械或電子相關專業。具體的專業細分名字很多，請注意區分，對於自己感興趣的學校和專業，大家最好直接去對應學院的官網，直接看看具體的詳細介紹，看看老師們在做什麼課題或項目。哪怕專業名字一模一樣，每個學校的差別也非常大。中間如果想多學習 AI，也可以多花時間自學。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你對智能如何產生感興趣、如果你有 AGI 的夢想，且數學還不錯，推薦直接學習計算機科學/人工智能相關專業，也一併請直接多查查對應學院的詳細信息，甚至可以直接先去對應實驗室看看。當然，還是建議中間可以稍微花一些時間，學習一些硬件相關的原理，比如自己動手畫個 PCB 板子等，簡單實用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;當然，現實裏，大多數同學沒有那麼幸運，能直接進入自己理想的學校和專業，或者進入以後發現不適合自己或者不喜歡。這其實完全不是大問題，非常常見和正常。請不要放棄努力尋找自己喜歡和擅長的事，尋找新的方向，並請一定努力去實踐。你可以轉專業，哪怕轉不了，也一點問題沒有，你可以直接去找自己感興趣方向的老師，直接溝通去他的實驗室做事，甚至完全可以直接全都自學。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;後續上學時，請大家也不要侷限於書本和論文，具身智能是物理世界的智能，一定要多動手，擰螺絲、調電路、寫程序、debug，馬上自己動手編程，進入實驗室、參與機器人比賽等等，在實戰中迅速提升自己。我自己至今，也還會自己直接上手拆裝零部件，敲敲代碼等。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你想成為最頂尖的人才，一定要超脱課本，主動持續學習，學習當下最前沿的科技領域。持續關注頂級學術會議最新論文等；積極參與最具探索性的開源項目並嘗試復現和改進；與同樣渴望挑戰邊界的同學、研究者組建小組，共同探討前沿問題，碰撞思想。每個同學，都有機會成為全人類未來科技方向的探索者和實踐者。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;最後，我想説，在未來的學業中，你們或許會感到迷茫，不知前進的方向，但不要擔心，每個人都會迷茫，我也一樣。在大學期間，要較多的探索自己的多種可能性，多嘗試，找到愛好點和擅長點。如果你的愛好恰巧也是你擅長的，那恭喜你，你找到了可以為之奮鬥一生的目標。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;在成長過程中，你們可能目睹了一次又一次的時代浪潮，見證了一個又一個商業奇蹟，外貿、房地產、基建、互聯網、消費電子、移動互聯網、新能源汽車，等等。可能你們會羨慕前人，覺得機會變少了，覺得宇宙的科技樹沒有太多可以探索的了。但請不要灰心，AI 和機器人的時代才剛剛開始，還有大量的挑戰和機會在等你們。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356888</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356888</guid>
      <pubDate>Sat, 10 May 2025 10:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>網易有道開源首個專注數學教育的模型 Confucius3-Math</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;網易有道宣佈正式開源「子曰 3」系列大模型的數學模型（英文名稱 Confucius3-Math），這是國內首個專注於數學教育，可在單塊消費級 GPU 上高效運行的開源推理模型。&lt;/p&gt; 
&lt;p&gt;據瞭解，Confucius3-Math 是由網易有道 AI 團隊開發的&lt;strong&gt;140 億參數開源推理大語言模型&lt;/strong&gt;，專門針對 K-12 數學教育場景進行優化。與通用模型不同，Confucius3-Math 具有以下特點：&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;數學任務上的頂尖性能&lt;/strong&gt;&lt;br&gt; 通過專門的強化學習訓練，在中文 K-12 數學問題上的表現超越了參數規模更大的模型&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;高性價比的部署方案&lt;/strong&gt;&lt;br&gt; 可在單張消費級 GPU（如 RTX 4090D）上高效運行&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;文化與課程體系的深度契合&lt;/strong&gt;&lt;br&gt; 針對中國國家數學課程標準和解題方法論進行了優化&lt;/p&gt; 
&lt;p&gt;Confucius3-Math 採用純強化學習的後期訓練流程，結合創新的數據調度策略和改進的組相對優勢估計器開發而成。Confucius3-Math 在解決國內數學問題任務中展現出了顯著優勢。其通過大規模增強學習以及一系列的創新算法，訓練成本僅為 2.6 萬美元，推理性能約為 DeepSeek R1 的 15 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8732b5278351553b8f60ad1d228c44e8d50.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;附 1：Demo 地址，歡迎試用&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconfucius.youdao.com%2F" target="_blank"&gt;https://confucius.youdao.com/&lt;/a&gt;&lt;br&gt; 附 2：模型開源地址&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FConfucius3-Math" target="_blank"&gt;https://github.com/netease-youdao/Confucius3-Math&lt;/a&gt;&lt;br&gt; 附 3：論文地址&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FConfucius3-Math%2Fblob%2Fmain%2FConfucius3-Math.pdf" target="_blank"&gt;https://github.com/netease-youdao/Confucius3-Math/blob/main/Confucius3-Math.pdf&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356885</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356885</guid>
      <pubDate>Sat, 10 May 2025 09:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ChinaTextbook —— 所有小初高、大學 PDF 教材</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;雖然國內教育網站已提供免費資源，但大多數普通人獲取信息的途徑依然受限。有些人利用這一點，在某站上銷售這些帶有私人水印的資源。為了應對這種情況，將這些資源集中並開源，以促進義務教育的普及和消除地區間的教育貧困。&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;小學數學&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%B8%80%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;一年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%80%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;一年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%BA%8C%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;二年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%BA%8C%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;二年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%B8%89%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;三年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%89%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;三年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E5%9B%9B%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;四年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%9B%9B%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;四年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%BA%94%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;五年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%BA%94%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;五年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E5%85%AD%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;六年級上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AD%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;六年級下冊&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;初中數學&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B8%83%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%83%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初一上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B8%83%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%83%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初一下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E5%85%AB%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AB%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初二上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E5%85%AB%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AB%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初二下冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B9%9D%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B9%9D%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初三上冊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B9%9D%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B9%9D%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初三下冊&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;高中數學&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E9%AB%98%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88%EF%BC%88A%E7%89%88%EF%BC%89%EF%BC%88%E4%B8%BB%E7%BC%96%EF%BC%9A%E7%AB%A0%E5%BB%BA%E8%B7%83%26%E6%9D%8E%E5%A2%9E%E6%B2%AA%EF%BC%89-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE"&gt;目錄&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;大學數學&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC%E4%B8%83%E7%89%88"&gt;高等數學&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"&gt;線性代數&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6"&gt;離散數學&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA"&gt;概率論&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.dxsx.net/index.php"&gt;更多數學資料-(大學數學網)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;問題：如何合併被拆分的文件？&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;由於 GitHub 對單個文件的上傳有最大限制，超過 100MB 的文件會被拒絕上傳，超過 50MB 的文件上傳時會收到警告。因此，文件大小超過 50MB 的文件會被拆分成每個 35MB 的多個文件。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;示例&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;文件被拆分的示例：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;義務教育教科書 · 數學一年級上冊.pdf.1&lt;/li&gt;
&lt;li&gt;義務教育教科書 · 數學一年級上冊.pdf.2&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;解決辦法&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;要合併這些被拆分的文件，您只需執行以下步驟 (其他操作系統同理)：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;將合併程序&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;下載到包含 PDF 文件的文件夾中。&lt;/li&gt;
&lt;li&gt;確保&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;和被拆分的 PDF 文件在同一目錄下。&lt;/li&gt;
&lt;li&gt;雙擊&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;程序即可自動完成文件合併。&lt;/li&gt;
&lt;/ol&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;下載方式&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;您可以通過以下鏈接，下載文件合併程序：&lt;/p&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook-tools/releases"&gt;下載文件合併程序&lt;/a&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;文件和程序示例&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;mergePDFs-windows-amd64.exe&lt;/li&gt;
&lt;li&gt;義務教育教科書 · 數學一年級上冊.pdf.1&lt;/li&gt;
&lt;li&gt;義務教育教科書 · 數學一年級上冊.pdf.2&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/chinatextbook</link>
      <guid isPermaLink="false">https://www.oschina.net/p/chinatextbook</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
    </item>
    <item>
      <title>谷歌 AI 編程工具 Gemini Code Assist 發佈更新，增強上下文管理能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 AI 編程助手&amp;nbsp;Gemini Code Assist 近日&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGoogleCloudTech%2Fstatus%2F1936136971849441648" target="_blank"&gt;發佈更新&lt;/a&gt;&lt;/u&gt;，集成了最新的&amp;nbsp;Gemini 2.5&amp;nbsp;模型，帶來了更強的個性化和更靈活的上下文管理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0623/174100_cmzw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户現在可以創建自定義快捷命令來處理重複性任務，並在&amp;nbsp;VS Code&amp;nbsp;或&amp;nbsp;JetBrains IDE&amp;nbsp;的&amp;nbsp;Gemini&amp;nbsp;設置中配置項目編碼規範，這些規則在每次生成代碼時自動生效。&lt;/p&gt; 
&lt;p&gt;上下文管理方面，Gemini Code Assist&amp;nbsp;支持將整個文件夾或工作區加入上下文，上下文窗口可達&amp;nbsp;100 萬 tokens，並可通過「@」符號精確添加特定文件或目錄。&lt;/p&gt; 
&lt;p&gt;此外，新增的上下文抽屜（Context Drawer）可視化面板能顯示當前參與對話的文件與路徑，支持一鍵添加/移除。聊天窗口右上角現可開啓多個會話，所有歷史對話會自動保存並支持一鍵恢復。&lt;/p&gt; 
&lt;p&gt;同時，Google 的&amp;nbsp;Jules 異步編碼代理也將登陸&amp;nbsp;AI Studio，未來可能以「Vibe coding」桌面應用的形式推出。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356882</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356882</guid>
      <pubDate>Sat, 10 May 2025 09:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源鴻蒙代碼規模突破 1.3 億行</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEGCrwLfPlELGTq0DGmeTZw" target="_blank"&gt;據 OpenAtom OpenHarmony 分享&lt;/a&gt;，2025 年 6 月 21 日，由開源鴻蒙項目羣工作委員會主辦的開源鴻蒙社區年中技術會議在東莞三丫坡盛大召開。&lt;/p&gt; 
&lt;p&gt;開源鴻蒙項目羣工作委員會主席、華為終端 BG 軟件部總裁龔體為本次大會致辭。他表示，&lt;strong&gt;開源四年多來，開源鴻蒙實現全面生態躍遷：代碼規模突破 1.3 億行，凝聚 8700 多位開發者智慧&lt;/strong&gt;；社區治理持續升級，新增 8 個關鍵 SIG，系統性補齊路由、北斗、Web 等關鍵技術版圖；400 餘家生態夥伴的 1200 餘款產品通過兼容性測評，覆蓋金融、交通、教育、醫療、航天等多個行業領域。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8c873b452dab8e67e8a87ad3868acef8dc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;消費端同步跨越升級 —— 鴻蒙 PC、Pura X 及 nova 系列設備全面搭載 HarmonyOS 5 操作系統，2 萬多個原生應用與元服務成功上架，標誌着萬物智聯生態正式進入規模化落地新階段。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356872</guid>
      <pubDate>Sat, 10 May 2025 09:13:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>百度文心快碼 AI IDE 上線</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;百度文心快碼宣佈上線獨立 AI 原生開發環境工具 Comate AI IDE。根據介紹，Comate AI IDE 是行業首個多模態、多智能體協同 AI IDE，首創設計稿一鍵轉代碼，模型已接入文心 4.0 X1 Turbo，開箱即用。目前百度每天新增的代碼中，文心快碼生成的代碼佔比已超過 43%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="271" src="https://oscimg.oschina.net/oscnet/up-933809d1b828cf04041454b88391e408dd4.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1a1a1a; text-align:justify"&gt;&lt;span style="color:#000000"&gt;不同於當前主流 AI 代碼助手以插件形態附着在 VS Code、JetBrains 等開發平台，Comate AI IDE 完全自研，重構從編輯器交互到底層邏輯的全鏈路開發體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1a1a1a; text-align:justify"&gt;&lt;span style="color:#000000"&gt;核心技術上，Comate AI IDE 集成了文心 4.0 X1 Turbo 模型與升級版 Zulu 智能體，支持自動任務拆解與自主決策執行。開發者可通過自然語言或語音輸入複雜需求，由智能體自主生成代碼、實時預覽、持續優化。例如，開發者上傳 Figma 設計稿，系統可自動生成高還原度前端代碼，省去大量重複性編寫工作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356871</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356871</guid>
      <pubDate>Sat, 10 May 2025 09:09:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>馬斯克：xAI 計劃用 Grok 3.5 重寫人類知識庫</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，馬斯克在 X&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1936333964693885089" target="_blank"&gt;宣佈&lt;/a&gt;，旗下 AI 公司 xAI 將用新一代大模型 Grok 3.5（或許直接叫 Grok 4）重寫整個人類知識庫，添加缺失信息，刪除錯誤內容，然後基於這個「純淨版」知識庫重新訓練模型。&lt;/p&gt; 
&lt;p&gt;馬斯克認為，在任何基於未修正數據訓練的基礎模型中，都有太多的垃圾。&lt;/p&gt; 
&lt;p&gt;AI 為了迎合用户的要求，會自己加戲，從而憑空想象出很多不存在，或者還未發生的細節，直接當成真實事件嵌入到文章裏。而一旦這樣的內容多了，這些看似真實的內容甚至會被 AI 重新咀嚼回去訓練，再被下一次輸出時引用。這時候，真真假假就更難以分辨了。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b1fa8925a68e196d59d0eb4bed7287ebb5b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;簡單來説，馬斯克想讓 Grok 成為人類知識的審核員和補全者。據悉，新一代 Grok 擁有高級推理能力，能夠識別知識庫中的錯誤和缺失。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356867</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356867</guid>
      <pubDate>Sat, 10 May 2025 08:48:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
