<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 26 Feb 2025 07:37:29 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>谷歌發佈免費版 AI 編程工具 Gemini Code Assist</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Google DeepMind 昨天&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGoogleDeepMind%2Fstatus%2F1894349711160578093&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;面向全球開發者推出 AI 編程工具 Gemini Code Assist：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;每月提供高達 18 萬次的代碼補全配額（相當於免費）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;128K tokens 上下文窗口&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持公有領域的所有編程語言&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1376&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/143934_eTUv_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0226/145135_vjzh_2720166.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Gemini Code Assist 背後的模型為 Google Gemini 2.0 針對編程開發微調的版本，更適合用於編程開發領域，開發者可以通過插件形式在 Microsoft Visual Studio Code 和 JetBrains IDE 等流行的集成開發環境中使用，&lt;span style=&quot;background-color:#ffffff; color:#4c4e4d&quot;&gt;開發者可在聊天對話中上傳大型文件，以幫助 AI 更好地理解代碼庫整體結構。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual Studio Code：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGoogle.geminicodeassist&quot; target=&quot;_blank&quot;&gt;https://marketplace.visualstudio.com/items?itemName=Google.geminicodeassist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;JetBrains IDE：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplugins.jetbrains.com%2Fplugin%2F24198-gemini-code-assist&quot; target=&quot;_blank&quot;&gt;https://plugins.jetbrains.com/plugin/24198-gemini-code-assist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapps%2Fgemini-code-assist&quot; target=&quot;_blank&quot;&gt;http://github.com/apps/gemini-code-assist&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335823/gemini-code-assist-free</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335823/gemini-code-assist-free</guid>
            <pubDate>Wed, 26 Feb 2025 06:50:18 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>近 80k star，這個強大的 Open WebUI 自託管 AI 項目不能錯過</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;strong&gt;Open WebUI 是一個&lt;a href=&quot;https://docs.openwebui.com/features/plugin/&quot;&gt;可擴展&lt;/a&gt;、功能豐富且用户友好的自託管 AI 平台，完全支持離線運行。&lt;/strong&gt;它支持多種 LLM（大型語言模型）運行器，如&lt;strong&gt; Ollama &lt;/strong&gt;和&lt;strong&gt; OpenAI &lt;/strong&gt;兼容 API，並內置了用於 RAG 的&lt;strong&gt;推理引擎&lt;/strong&gt;，使其成為&lt;strong&gt;一個強大的 AI 部署解決方案&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;更多信息，請查看我們的&lt;a href=&quot;https://docs.openwebui.com/features/plugin/&quot;&gt;Open WebUI 文檔&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Open WebUI 演示&quot; src=&quot;https://oscimg.oschina.net/oscnet//79afb79a0bd0b56998e1a7e520e6826b.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Open WebUI 的關鍵特性⭐&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;🚀&lt;strong&gt;輕鬆設置&lt;/strong&gt;：使用 Docker 或 Kubernetes（kubectl、kustomize 或 helm）無縫安裝，支持&lt;code&gt;:ollama&lt;/code&gt;和&lt;code&gt;:cuda&lt;/code&gt;標籤的鏡像，體驗無憂。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🤝&lt;strong&gt;Ollama/OpenAI API 集成&lt;/strong&gt;：輕鬆集成 OpenAI 兼容 API，與 Ollama 模型一起進行多樣化的對話。自定義 OpenAI API URL，連接到&lt;strong&gt;LMStudio、GroqCloud、Mistral、OpenRouter 等&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🛡️&lt;strong&gt;細粒度權限和用户組&lt;/strong&gt;：管理員可以創建詳細的用户角色和權限，確保安全的用户環境。這種細粒度的控制不僅增強了安全性，還能為用户帶來定製化的體驗，培養用户的歸屬感和責任感。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📱&lt;strong&gt;響應式設計&lt;/strong&gt;：在桌面電腦、筆記本電腦和移動設備上享受無縫體驗。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📱&lt;strong&gt;移動設備上的漸進式 Web 應用（PWA）&lt;/strong&gt;：通過我們的 PWA 在移動設備上享受類似原生應用的體驗，提供離線訪問 localhost 和無縫用户界面。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;✒️🔢&lt;strong&gt;完整支持 Markdown 和 LaTeX&lt;/strong&gt;：通過全面支持 Markdown 和 LaTeX，提升你的 LLM 體驗，實現更豐富的交互。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🎤📹&lt;strong&gt;免提語音/視頻通話&lt;/strong&gt;：通過集成的免提語音和視頻通話功能，體驗無縫溝通，讓聊天環境更加動態和互動。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🛠️&lt;strong&gt;模型構建器&lt;/strong&gt;：通過 Web UI 輕鬆創建 Ollama 模型。通過&lt;a href=&quot;https://openwebui.com/&quot;&gt;Open WebUI 社區&lt;/a&gt;集成，創建和添加自定義角色/代理、自定義聊天元素以及輕鬆導入模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🐍&lt;strong&gt;原生 Python 函數調用工具&lt;/strong&gt;：通過在工具工作區中內置代碼編輯器支持，增強你的 LLM。通過添加純 Python 函數，實現與 LLM 的無縫集成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📚&lt;strong&gt;本地 RAG 集成&lt;/strong&gt;：藉助開創性的檢索增強生成（RAG）支持，開啓聊天互動的未來。你可以直接在聊天中加載文檔，或通過&lt;code&gt;#&lt;/code&gt;命令在查詢前訪問文檔庫中的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🔍&lt;strong&gt;RAG 的網絡搜索&lt;/strong&gt;：使用&lt;code&gt;SearXNG&lt;/code&gt;、&lt;code&gt;Google PSE&lt;/code&gt;、&lt;code&gt;Brave Search&lt;/code&gt;、&lt;code&gt;serpstack&lt;/code&gt;、&lt;code&gt;serper&lt;/code&gt;、&lt;code&gt;Serply&lt;/code&gt;、&lt;code&gt;DuckDuckGo&lt;/code&gt;、&lt;code&gt;TavilySearch&lt;/code&gt;、&lt;code&gt;SearchApi&lt;/code&gt;和&lt;code&gt;Bing&lt;/code&gt;等提供商進行網絡搜索，並將結果直接注入到聊天體驗中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌐&lt;strong&gt;網絡瀏覽功能&lt;/strong&gt;：通過在&lt;code&gt;#&lt;/code&gt;命令後跟上 URL，將網站無縫集成到聊天體驗中。此功能允許你將網絡內容直接融入對話中，提升互動的豐富度和深度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🎨&lt;strong&gt;圖像生成集成&lt;/strong&gt;：通過使用 AUTOMATIC1111 API 或 ComfyUI（本地）以及 OpenAI 的 DALL-E（外部）等選項，無縫融入圖像生成能力，為你的聊天體驗增添動態視覺內容。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;⚙️&lt;strong&gt;多模型對話&lt;/strong&gt;：輕鬆與多種模型同時互動，發揮它們的獨特優勢，獲得最佳響應。通過並行使用多種模型，提升你的體驗。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🔐&lt;strong&gt;基於角色的訪問控制（RBAC）&lt;/strong&gt;：通過限制權限確保安全訪問；只有授權人員可以訪問你的 Ollama，模型創建/拉取權限僅限管理員。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌐🌍**多語言支持*/：通過我們的國際化（i18n）支持，用你偏好的語言體驗 Open WebUI。加入我們，共同擴展支持的語言！我們正在積極尋找貢獻者！&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🧩&lt;strong&gt;管道、Open WebUI 插件支持&lt;/strong&gt;：通過&lt;a href=&quot;https://github.com/open-webui/pipelines&quot;&gt;Pipelines 插件框架&lt;/a&gt;，將自定義邏輯和 Python 庫無縫集成到 Open WebUI 中。啓動你的 Pipelines 實例，將 OpenAI URL 設置為 Pipelines URL，探索無限可能。&lt;a href=&quot;&quot;&gt;示例&lt;/a&gt;包括函數調用、用户速率限制以控制訪問、使用 Langfuse 等工具進行使用情況監控、通過 LibreTranslate 進行實時翻譯以支持多語言、有毒信息過濾等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌟&lt;strong&gt;持續更新&lt;/strong&gt;：我們致力於通過定期更新、修復和新功能來改進 Open WebUI。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;想了解更多關於 Open WebUI 的特性嗎？請查看我們的&lt;a href=&quot;https://docs.openwebui.com/features&quot;&gt;Open WebUI 文檔&lt;/a&gt;，獲取全面的概述！&lt;/p&gt;

&lt;p&gt;🔗還要查看 Open WebUI 社區！&lt;/p&gt;

&lt;p&gt;別忘了探索我們的姊妹項目&lt;a href=&quot;https://openwebui.com/&quot;&gt;Open WebUI 社區&lt;/a&gt;，在這裏你可以發現、下載和探索定製化的 Modelfiles。Open WebUI 社區為通過 Open WebUI 增強你的聊天互動提供了廣泛的可能性！🚀&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/open-webui</link>
            <guid isPermaLink="false">https://www.oschina.net/p/open-webui</guid>
            <pubDate>Wed, 26 Feb 2025 06:38:18 GMT</pubDate>
        </item>
        <item>
            <title>DistilQwen2.5 發佈：通義千問蒸餾小模型再升級</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;因高計算成本和複雜性，在例如移動設備和邊緣計算場景等資源有限的環境中，限制了大語言模型的普及。如何在保留模型性能的同時提高計算效率並降低部署成本，已成為研究和工業界必須面對的關鍵挑戰。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在此背景下，我們正式推出基於 Qwen2.5 的輕量化大模型系列 DistilQwen2.5。該模型通過創新的雙層蒸餾框架實現突破，基於數據優化策略重構指令數據集強化模型理解能力，並且採用參數融合技術實現細粒度知識遷移。實驗表明，DistilQwen2.5 在多項基準測試中性能超越原模型，同時顯著降低計算資源消耗。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//00b032cb44a18bbc409cd11c99a3592d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;DistilQwen2.5 蒸餾模型的 Checkpoint 已在 Hugging Face 及 Model Scope 全面開源。本文將介紹 DistilQwen2.5 的蒸餾算法、效果評測，以及 DistilQwen2.5 模型在阿里雲人工智能平台 PAI 上的使用方法，並提供在各開源社區的下載使用教程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5 中的知識蒸餾技術&lt;/h1&gt; 
&lt;p&gt;本節中，主要描述 DistilQwen2.5 模型訓練中使用的黑盒化和白盒化的知識蒸餾技術。其中，DistilQwen2.5 模型蒸餾的算法框架如下圖所示。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6d51353007a4cea597e2663a45e4dd33.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;指令數據蒐集層&lt;/h2&gt; 
&lt;p&gt;DistilQwen2.5 模型蒸餾算法的首要步驟是指令數據收集層，旨在蒐集大量高質量指令數據，以供後續教師模型使用。為了確保數據的多樣性和高效性，整合了多個來源的數據集，包括開源數據集 Magpie、Openhermes 和 Mammoth 2 等。此外，還引入了大量私有合成數據集，以豐富指令樣本的多樣性。為有效整合數據源，確保指令語言主要涵蓋中英文，同時對指令進行了難度打分和任務相關的重新抽樣。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;首先，在許多應用場景中，模型需要能夠跨語言工作。為應對中文數據相對不足的挑戰，利用 Qwen-max 進行了數據擴展。通過設計特定的 Prompt，讓 Qwen-max 生成了內容不同但任務類型相同的中英文指令，從而平衡了中英文數據的比例。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;其次，任務多樣性是實現模型全面能力的關鍵環節。借鑑 WizardLM 中對大語言模型能力的評估維度，在 DistilQwen2 模型蒸餾中繼續使用之前的方法，定義了 33 種任務類型，涵蓋廣泛的應用場景。我們創建了一個包含 3 萬條任務的分類數據集，並基於 Deberta v3 訓練了任務分類器。該分類器在測試集上的準確性與 ChatGPT 相當，使得指令數據標註具備高度的可靠性和準確性。通過如此精細的任務標籤，能夠更好地控制數據集中不同任務類型的分佈，確保模型在訓練過程中獲得全面和深入的能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此外，在評估指令數據的難易程度時，採用了 LLM-as-a-Judge 的範式。利用教師模型對指令執行的準確性、相關性、幫助性和詳細程度進行評分，這為模型提供了一種客觀的指令難度評估機制。具體而言，我們引入了一種名為模型擬合難度分數（MFD Score）的指標來衡量每條指令在蒸餾訓練中的價值。MFD 分數是根據學生模型得分與教師模型得分之間的差值計算得出的。如果某條指令的 MFD 分數較高，則説明該指令對蒸餾訓練更具價值，而低難度的指令則可以從訓練集中移除。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;指令遵循優化層（黑盒化蒸餾）&lt;/h2&gt; 
&lt;p&gt;黑盒化蒸餾主要依賴於教師模型的輸出，而非其內部表徵。我們選擇採用黑盒化蒸餾算法的原因有兩個：首先，這種算法的訓練速度比白盒化蒸餾更快，有助於節省訓練時間和計算資源；其次，黑盒化蒸餾適用於開源和閉源的大型模型。在指令遵循優化層中，我們並不直接通過蒸餾微調的方法來優化學生模型，而是利用教師大模型，首先引入一種 Multi-Agent 模式，以對指令數據進行大幅度提升和優化。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;指令擴展：在這一過程中，教師大模型充當指令擴展的 Agent，生成與輸入指令相似的新指令。在擴展指令時，我們要求該 Agent 始終保持原始任務的自然語言處理類別不變，以避免產生不必要的幻覺。例如，當輸入的指令為「簡要概述牛頓第一運動定律」時，輸出可以是「解釋開普勒第三定律的含義」，而不是「介紹愛因斯坦的生平」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令選擇：指令選擇 Agent 的目標是篩選出對模型訓練具有高度價值的指令，篩選標準包括信息量、實用性和泛化潛力等。這一過程不僅保證了增強數據集的質量，也有效過濾了對模型蒸餾訓練幫助不大的指令數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令改寫：在經過指令擴展和選擇後，指令改寫 Agent 進一步提升數據的質量和多樣性，同時保持指令意圖不變。例如，將「提供氣候變化經濟影響的總結」改寫為「解釋氣候變化如何影響經濟」。此外，對於複雜任務如邏輯推理、數學問題和編程等，我們鼓勵生成鏈式思維（Chain-of-Thought, CoT）輸出，以進一步提升小模型的推理能力和解決問題的邏輯性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;黑盒化蒸餾過程遵循監督學習範式，以增強的指令響應對作為訓練樣本。學生模型能夠在有限的參數量下，充分吸收和理解來自大模型的知識。這種方法不僅增強了學生模型解決任務的能力，也使其能夠在多任務環境中取得更好的效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;知識融合優化層（白盒化蒸餾）&lt;/h2&gt; 
&lt;p&gt;黑盒化知識蒸餾僅依賴教師模型輸出的概率最高的 token，而白盒化知識蒸餾則更關注教師模型輸出 logits 的分佈，從而為學生模型提供更豐富的信息。通過模仿教師模型的 logits 分佈，白盒化蒸餾可以更有效地傳遞知識，進一步提升學生模型的性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//10623cba5e71cbba341a58beaaefaf49.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;傳統的白盒化蒸餾算法對於工業大規模數據的蒸餾場景是不可行的，原因有三個：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;GPU 內存消耗過高：如果在訓練學生模型的同時進行教師模型的前向傳播，所需的計算資源將顯著增加。對於擁有 32B 或者 72B 參數的巨型教師模型，GPU 內存甚至可能無法承受。這種情況嚴重限制了模型的訓練效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;長時間的存儲和讀取：對於離線生成的教師模型 logits，其存儲和讀取通常需要佔用大量的時間。尤其是當數據集非常龐大時，磁盤空間的消耗也變得難以忽視。這種高昂的存儲和讀取開銷成為了系統瓶頸。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;詞彙表不匹配問題：教師模型和學生模型通常使用不同的詞彙表，導致它們的 logits 張量無法直接匹配。這種不匹配阻礙了知識的準確傳遞，降低了蒸餾過程的有效性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們在教師模型的輸出中觀察到，前 10 個 token 的概率之和幾乎為 1，這表明教師模型的所有知識幾乎都包含在前 10 個 token 中。因此只保存教師模型每個序列位置中概率最大的 10 個 token 的概率。由此我們構建了一個對於大模型和大數據量下可擴展的白盒化知識蒸餾系統，支持以下功能：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a3a97882de486068e44629d28e52dd04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_6&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5 模型效果評測&lt;/h1&gt; 
&lt;p&gt;在本節中，從多個角度評測 DistilQwen2.5 蒸餾小模型的實際效果；同時，我們對使用不同規模的教師大模型進行模型融合訓練的效果進行評測。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型綜合能力評測&lt;/h2&gt; 
&lt;p&gt;我們在多個權威指令遵循評測基準上測試了 DistilQwen2.5 蒸餾小模型的能力。AlpacaEval 2.0 使用 GPT-4 作為評判員來評估生成回覆的質量。特別地，AlpacaEval 2.0 引入了長度控制的勝率（Length-controlled Win Rates），以避免 GPT-4 偏向於較長回覆，從而減少評估偏差。MT-Bench 是包括來自 8 個類別的 80 個任務，同樣使用 GPT-4 作為評判標準，並提供兩種不同的評估模式：多輪對話和單輪對話。IFEval 專注於使用「可驗證的指令」進行模型效果的評估，這使得結果更加客觀。根據所使用的 Prompt 不同，IFEval 提供了 instruction-loose 和 strict-prompt 兩種評估模式。如下表所示，DistilQwen2.5 在 0.5B、1.5B、3B 和 7B 四個參數量級的模型中，與原始 Qwen2.5 模型的效果進行了對比。可以看出，本文描述的知識蒸餾算法顯著提升了現有大語言模型的指令遵循能力，並在多個評測基準上取得了一致而明顯的效果提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型細粒度能力評測&lt;/h2&gt; 
&lt;p&gt;我們進一步使用 MT-bench 基準測試對 DistilQwen2.5 模型的各項細粒度能力進行評測，例如文本生成、代碼生成、數學問題、角色扮演等，每個任務都旨在從不同的角度測試模型的能力。通過對 DistilQwen2.5 模型模型在 MT-bench 基準測試中的表現進行分析，我們可以準確量化 DistilQwen2.5 模型在各個方面的細粒度能力，並將其與原始模型進行比較。從實驗結果可以看出，在絕大部分細粒度能力層面，DistilQwen2.5 模型比原始 Qwen2.5 模型有明顯的提升。下圖給出 0.5B 和 1.5B 模型在各個細粒度能力的對比。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;與其他模型能力對比&lt;/h2&gt; 
&lt;p&gt;為了橫向比較同期發佈的不同參數規模的模型效果，下表展示了這些模型在 AlpacaEval 2.0 的評測結果，對於每個參數量級，從低到高進行排序。我們重點對比了 Qwen2、Qwen2.5 以及先前發佈的 DistilQwen2 模型。對於英文模型，我們也橫向對比 Llama、Phi3、Mistral 等系列模型。模型效果排序如下所示。可以看出，DistilQwen2.5 系列模型對比其他各類模型，具有很高的性價比，其效果接近了參數量接近或大於其參數量兩倍的模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//be57d99e1d8cdeb5c10b9a407a4adcbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型融合實驗評測&lt;/h2&gt; 
&lt;p&gt;經過對大模型 logtis 生成速度的優化，我們對 logits 的推理速度提升了至少 4 倍，節省存儲空間為原本的 1/1000。使用 5 萬條數據時，時間具體耗時如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2ac326b4d4d8fa99485a261603a0cd82.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;針對不同訓練數據量級（1K/10K/100K/200K）下和不同教師模型（7B/14B/32B/72B）大小的蒸餾效果，我們也進行了探索，效果如下圖所示，從中可以得到一些關於蒸餾數據量和教師模型參數量大小的結論：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;數據量和模型大小都存在邊際效應，隨着數據量的成倍提升，效果提升減緩；隨着模型規模的上升（32B/72B）並沒有對比 14b 模型帶來更明顯的提升。這表明，學生模型和教師模型在參數量差距過大的情況下，對教師模型的學習能力有限。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在小數據量（～1K）或充分數據量（&amp;gt;200K）的情況下，提升教師模型規模帶來的效果提升不明顯。在 10K-100K 條數據量下，不同規模的教師模型提升較為明顯。這可能是由於在小數據的場景下，學生模型對教師模型的能力還沒有充分學習；而在大數據場景下隨着數據量大飽和，學生模型已經能從數據中學習到充分的知識。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9e77f03e07ddb7a4c0a08e044135e6f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型輸出案例&lt;/h2&gt; 
&lt;p&gt;對於同一指令，我們對比了 DistilQwen2.5-7B-Instruct 和 GPT-4o、DeepSeek-V3、Qwen2.5-Max、Qwen2-7B-Instruct 回覆對比結果，特別是知識性和邏輯推理類問題。從輸出結果可以看出，DistilQwen2.5-7B-Instruct 的輸出在一些場景上具有更好的事實正確性和邏輯推理能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例一：知識性問題&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//07201ddab1feecac2e755b540b0e6149.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例二：知識性問題&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3741184cb687b09f003da0782a3ae1b5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例三：邏輯推理類問題&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//287f2042bf191c17c6c12934c6a211a9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;模型下載和使用&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5 在阿里雲人工智能平台 PAI 上的實踐&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 庫為例，簡要介紹如何在 PAI-DSW 上使用 DistilQwen2.5 模型。首先需要保證 PAI-DSW 鏡像內 transformers 版本大於等於 4.37.0，否則會在加載模型時報錯：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以 DistilQwen2.5-7B-Instruct 為例，我們可以使用如下代碼調用模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-7B-Instruct&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;請給我簡單介紹一下杭州西湖。&quot;
messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_14&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5 在開源社區的下載&lt;/h2&gt; 
&lt;p&gt;我們在 HuggingFace 和 ModelScope 上開源了我們蒸餾後的模型，分別為&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-0.5B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-0.5B-Instruct&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-1.5B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-1.5B-Instruct&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-3B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-3B-Instruct&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-7B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-7B-Instruct&lt;/a&gt;。以 HuggingFace 為例，用户可以使用如下代碼下載這兩個模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-0.5B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-0.5B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-1.5B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-1.5B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-3B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-3B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-7B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-7B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_15&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;數據集下載和使用&lt;/h1&gt; 
&lt;p&gt;為了支持社區開發者在微調 DistilQwen2.5 模型時避免「災難性遺忘」（catastrophic forgetting）現象，我們開源了部分用於模型訓練的數據集。這一數據集旨在為模型微調提供堅實的基礎，有助於提升模型在新任務上的適應性的同時，保持在之前任務上的性能。此外，在微調其他類似大語言模型時，也可以利用這一數據集進行指令遵循能力的增強。以下是關於數據集的信息和下載使用説明。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_16&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;數據格式等相關信息&lt;/h2&gt; 
&lt;p&gt;該部分數據包含了數學、代碼、知識問答、指令遵循、創意生成等內容，總數據量為 100K。用户可以在用自己的數據對模型微調時加入 DistilQwen_100K，或者其子集，從而使其在下游任務表現良好的同時不至於喪失其通用能力，保證模型的泛化性。數據格式為 JSON 格式，示例數據如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
    {
        &quot;instruction&quot;: &quot;The ratio of the number of molar teeth in the human upper jaw at the age of 6 is 2:1 compared to number of incisors teeth. There are total 8 incisors in the human mouth. What is the number of molar teeth in the human upper jaw for this age group?&quot;,
        &quot;output&quot;: &quot;## Step 1: Determine the total number of incisors in the upper jaw.\nSince there are a total of 8 incisors in the human mouth and the incisors are evenly distributed between the upper and lower jaw, we divide the total number of incisors by 2 to find the number in the upper jaw. So, 8 incisors / 2 = 4 incisors in the upper jaw.\n\n## Step 2: Use the given ratio to find the number of molar teeth in the upper jaw.\nThe ratio of molar teeth to incisors in the upper jaw at the age of 6 is given as 2:1. This means for every 1 incisor, there are 2 molar teeth. Since we determined there are 4 incisors in the upper jaw, we multiply this number by 2 to find the number of molar teeth. So, 4 incisors * 2 = 8 molar teeth.\n\nThe final answer is: $\\boxed{8}$&quot;
    },
    {
        &quot;instruction&quot;: &quot;This is the text of a lecture I am giving tomorrow. Can you go over it and make recommendations to improve clarity and flow?&quot;,
        &quot;output&quot;: &quot;I&#39;d be happy to help you review your lecture text and provide suggestions for improvement. Please go ahead and share the text with me, and I&#39;ll get started.\n\nAdditionally, it would be helpful to know a bit more about the context of your lecture. Could you tell me:\n\n* What is the topic of your lecture?\n* Who is your audience (e.g. students, professionals, general public)?\n* What is the purpose of the lecture (e.g. to inform, to persuade, to educate)?\n* How long is the lecture supposed to be?\n\nThis information will help me provide more targeted and relevant feedback.&quot;
    }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_17&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;數據集在開源社區的下載&lt;/h2&gt; 
&lt;p&gt;該數據集已上傳至 ModelScope，用户可以使用 ModelScope 提供的腳本和命令行工具自行下載使用該數據集。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//47f399f0906433f82868f9a72178f4bb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#驗證 SDK token
from modelscope.hub.api import HubApi
api = HubApi()
api.login(&#39;your_token_id&#39;)

#數據集下載
from modelscope.msdatasets import MsDataset
ds =  MsDataset.load(&#39;PAI/DistilQwen_100k&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_18&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;小結與未來工作&lt;/h1&gt; 
&lt;p&gt;在當前人工智能領域的快速發展中，大語言模型（LLMs）憑藉其出色的自然語言理解和生成能力，已在多個應用場景中得到廣泛應用。然而，隨着這些應用的擴展，其高計算成本和複雜性在資源有限的環境下的接受度逐漸降低，成為行業普及的一大瓶頸。為瞭解決這一問題，我們提出了 DistilQwen2.5 輕量化模型系列，依託 Qwen2.5 大模型，通過一系列創新的知識蒸餾技術，使得模型在保留原有優越性能的同時顯著降低了計算資源需求。為了進一步促進技術的推廣與應用，我們將 DistilQwen2.5 模型的 Checkpoint 以及部分訓練數據集開源至 Hugging Face 和 Model Scope 等社區，力圖為開發者和企業提供更為便捷的操作環境，助力他們在實際項目中迅速實現技術落地。在未來，我們將繼續致力於優化併發布 DistilQwen 系列模型，並且針對特定領域（如深度推理等）進行模型的定製化優化，使得 DistilQwen 系列模型在多樣化需求下展現出更強的專業能力。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_19&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;參考資料&lt;/h1&gt; 
&lt;p&gt;相關發表論文&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;技術文章&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2：通義千問大模型的知識蒸餾實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2 蒸餾小模型的訓練、評測、壓縮與部署實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大語言模型數據增強與模型蒸餾解決方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/17771966</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/17771966</guid>
            <pubDate>Sun, 23 Feb 2025 06:22:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>第四範式推出大模型推理端側解決方案 ModelHub AIoT</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;第四範式宣佈推出大模型推理端側解決方案 ModelHub AIoT，用户在端側可輕鬆部署如 DeepSeek R1、Qwen 2.5、Llama 2/3 系列等小尺寸蒸餾模型，離線運行，並可靈活在多個模型之間切換，兼顧了模型壓縮、推理性能，解決了部署與優化的複雜性。&lt;/p&gt; 
&lt;p&gt;公告稱，該方案不僅能夠滿足用户對隱私和實時性的需求，還極大降低了 AI 大模型推理成本。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;375&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-68368870524ea2bae030e74a3f08dbf13ea.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1） 無需聯網，端側低延時運行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;優秀的端側推理框架在端側算力的支持下，展現出卓越的性能與適配性。模型在本地即時處理請求，提供流暢的用户體驗。在網絡不穩定或離線環境下，端側模型仍能正常運行，確保服務的連續性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2） 數據隱私與安全性提升&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在端側部署模型，數據無需上傳至雲端，所有計算和處理都在本地設備上完成，避免了雲端傳輸和存儲過程中的潛在泄露風險，降低了數據被黑客攻擊或濫用的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3） 成本效率與資源優化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;端側部署有效降低對雲端資源的依賴，本地處理減少了雲端計算和存儲的需求，降低了服務器成本和 API 調用成本，無需頻繁上傳大量數據，節省了網絡帶寬資源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335816</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335816</guid>
            <pubDate>Sun, 23 Feb 2025 06:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>湖北武漢發佈人工智能新舉措，單個項目最高資助 2000 萬元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;湖北省武漢市近日發佈《武漢市促進人工智能產業發展若干政策措施》（以下簡稱《措施》），支持關鍵技術突破，組織實施市級科技重大專項，給予單個項目最高 2000 萬元資金支持。這是繼《武漢建設國家人工智能創新應用先導區實施方案（2023—2025 年）》（以下簡稱《方案》）描繪「藍圖」後，武漢首發人工智能支持政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;306&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-61a78873a71f5fe5575177b36a5d6045fa3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《措施》錨定「打造國內一流的人工智能創新集聚區和產業高地」，分別從支持關鍵技術突破、強化普惠算力供給、增強模型創新能力、支持公共服務平台建設等 10 個方面給予支持。措施呈現三個亮點：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是強調普惠性。《措施》提出，根據算力使用情況每年設立總額不低於 1000 萬元的算力服務券，重點支持中小企業購買算力服務，對企業使用算力服務費用給予 50% 最高 20 萬元補助，補助期限不超過三年。同時，《措施》提出，引育高端人才、匯聚形成人工智能百億元基金投資生態等，注重補齊要素。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;二是提倡開源協同。《措施》指出，對開源開放、協同共享的人工智能公共服務平台，開展服務效果評審，經評審通過的，按照平台實際建設投入費用給予 30% 最高 500 萬元資金支持。對人工智能領域中試平台，根據設備投入、開放頻次、服務質量等，給予最高 1000 萬元資金支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;三是堅持應用導向。《措施》提出，要圍繞電子信息製造、工業質檢、教育、醫療、遙感、文創、金融等領域每年遴選一批性能先進的垂直行業模型，對牽頭研發單位按照研發和算力成本給予最高 1000 萬元補助。支持在全市各行業、各領域開展人工智能大模型先行先試應用。《措施》還提出，每年遴選一批人工智能示範應用場景項目，按照項目總投入資金給予 30% 最高 100 萬元資金支持。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335813</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335813</guid>
            <pubDate>Sun, 23 Feb 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>香港發佈首個生成式人工智能大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人民網香港 2 月 25 日電 (記者陳然) 由香港科技大學主導成立的研究機構香港生成式人工智能研發中心 (HKGAI)，25 日發佈生成式人工智能大模型 HKGAI V1。這是香港首個生成式人工智能大模型，為香港人工智能生態發展注入新的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據介紹，HKGAI V1 是業界首個基於 DeepSeek 進行全參數微調、持續訓練產生的大模型。該模型以香港最大的大模型本地知識庫為支持，可識別粵語、英語、普通話，並生成不同語言的回答。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;香港特區政府創新科技及工業局局長孫東當日在發佈會致辭時表示，人工智能正引領新一輪技術革命和產業變革，在這波以人工智能為代表的科技浪潮中，香港沒有缺席。他期待香港研發的大語言模型能夠立足香港，儘快提供予業界及市民使用，服務大眾，未來服務全球海外華人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;香港科技大學首席副校長、香港生成式人工智能研發中心主任郭毅可表示，HKGAI V1 大模型的推出，將進一步加強落地場景的應用能力。相信該大模型可為香港數字化轉型、構造海外華人的大模型生態和全球人工智能發展貢獻重要力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，HKGAI V1 涵蓋 5 個應用場景，可實時回答用户提問，協助用户撰寫文件、生成會議概要、提供香港法例及案件參考等。在香港特區政府數字政策辦公室的協調下，特區政府已有約 70 個部門參與試用 HKGAI 提供的大模型輔助辦公應用系統。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335802</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335802</guid>
            <pubDate>Sun, 23 Feb 2025 04:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>特斯拉 FSD 闖紅燈，馬斯克回應：我們用了中國互聯網上的公開視頻數據來訓練</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;特斯拉的 FSD 輔助駕駛功能&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/335712&quot;&gt;昨日在中國已正式上線&lt;/a&gt;&lt;/u&gt;，此前該功能僅在北美地區可用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-664bbc6e85ff22161ee153cc2a2847960d1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據早期用户反饋，FSD 在中國的駕駛環境中表現良好，已展現出對中國交通規則和路況的適應能力。&lt;/p&gt; 
&lt;p&gt;從網友發佈的體驗視頻來看，對於某些路段，FSD 會做出不遵守交規的行為，比如闖紅燈、左轉車道直行——非常符合「老司機」的開車風格。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1330&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/111744_y9qf_2720166.png&quot; width=&quot;638&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 X 平台一條討論 FSD 在中國表現效果的推文中，Elon Musk &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1894444545301205133&quot; target=&quot;_blank&quot;&gt;回覆稱&lt;/a&gt;：特斯拉通過視頻訓練的方式，使得 FSD 系統能夠快速適應中國的道路標誌和交通法規。他指出，特斯拉利用中國互聯網上公開的網絡視頻資源進行了&lt;strong&gt;模擬預訓練&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1734&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/112645_fwxo_2720166.png&quot; width=&quot;1264&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7841338587%2FPfXgB9ERi%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;1534&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/110821_cKHT_2720166.png&quot; width=&quot;1780&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0sBdmqqvIkgr37QXayv_7Q&quot; target=&quot;_blank&quot;&gt;根據「晚點」的獨家報道&lt;/a&gt;&lt;/u&gt;，多位接觸過特斯拉的人士透露，&lt;strong&gt;今年 2 月初，特斯拉選擇調撥部分美國自動駕駛工程師來中國做成熟版本 FSD 的本地化部署並優化算法&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;據悉，按照中國的相關法規，特斯拉無法將收集的中國行車數據傳至海外以訓練相應的 FSD 模型。因此本次總部團隊空降中國，理論上這能在數據不出境的前提下，儘可能提升 FSD 在華的性能。&lt;/p&gt; 
&lt;p&gt;此前，馬斯克曾在本月的特斯拉財報電話會上，透露了 FSD 入華面臨的雙重窘境，中美兩地均無法實現異地訓練 FSD。對此馬斯克表示，&lt;strong&gt;特斯拉會互聯網上找一些中國道路的視頻，然後拿去給 FSD 先訓練着，而這些視頻中將包含部分短視頻內容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;報道指出，&lt;strong&gt;特斯拉中國的團隊無需再從頭開始訓練 FSD ，他們將會接力美國的總部工程師，完成中國特定道路場景的算法優化（比如外賣車 「鬼探頭」、公交專用車道等），而此次訓練的數據來自特斯拉去年至今在中國特定道路上行駛的工程車&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;據知情人士透露，特斯拉中國目前正在進行針對部分員工的定向 FSD 測試，覆蓋研發部門的部分人員。如果情況順利，下一步特斯拉中國將在內部進行員工分批測試。再往後是向工信部提交車輛召回（OTA）審批，通過後向購買了 FSD 功能的車主推送升級。特斯拉中國原本計劃在今年 3 月底或 4 月初獲得有關部門的推送許可。&lt;/p&gt; 
&lt;p&gt;至於性能方面，目前中國版 FSD 的功能會比特斯拉美國此前推廣的 V13 版更初級更簡單，因為它不是依靠海量中國的道路數據訓練而來；而知情人士對相關內容沒有置評。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335712&quot; target=&quot;news&quot;&gt;特斯拉 FSD 部分能力在中國已推送，命名為「FSD 智能輔助駕駛功能」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335792</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335792</guid>
            <pubDate>Sun, 23 Feb 2025 03:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>3 月 22，南京源創會，聊聊生成式 AI 應⽤構建</title>
            <description></description>
            <link>https://www.oschina.net/event/2423811</link>
            <guid isPermaLink="false">https://www.oschina.net/event/2423811</guid>
            <pubDate>Sun, 23 Feb 2025 03:25:00 GMT</pubDate>
        </item>
        <item>
            <title>Jolla 正式發佈 Sailfish OS 5.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;芬蘭科技公司 Jolla 正式發佈了 Sailfish OS 5.0 「Tampella」，這是基於 Linux 的移動操作系統，最近已推送至所有支持設備。作為歐洲唯一的移動操作系統，Sailfish OS 主打隱私與安全，吸引注重個性化的用户。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95bf3b810bbb937dc9ddeb62f2747c69a47.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jolla.com%2Fsailfish-os-5-0-tampella-is-here%2F&quot; target=&quot;_blank&quot;&gt;發佈公告寫道&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Sailfish OS 5.0 為其瀏覽器更新了 Gecko Web 引擎，Android 應用兼容性支持已更新至 Android 13，並且引入了 microG 0.3.6，它使得對依賴於谷歌服務的 Android 應用的更多支持成為可能。&lt;/p&gt; 
 &lt;p&gt;Sailfish OS 5.0 還帶來了對 WireGuard VPN 的支持，主界面新增了新的橫幅模式和其他元素，呼叫攔截功能，以及 Jolla C2 和 Mind2 的支持現在已集成到系統中。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;新版本亮點包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;升級 Gecko 網絡引擎到 ESR91（計劃向 ESR102 邁進），瀏覽器性能更佳；&lt;/li&gt; 
 &lt;li&gt;新增 Wireguard 協議支持，方便運行 VPN；Android AppSupport 升級至 Android 13（API 33），讓用户能運行更多新版 Android 應用。&lt;/li&gt; 
 &lt;li&gt;整合 microG 0.3.6，支持依賴 Google 服務的應用，提升了靈活性。&lt;/li&gt; 
 &lt;li&gt;新功能包括呼叫攔截、橫屏模式優化（適配 notches 和圓角屏幕），以及對 Jolla C2 社區手機和 Mind2 AI 助手的內置支持。&lt;/li&gt; 
 &lt;li&gt;系統帶來超過 300 項改進和 200 多個 bug 修復，整體體驗更穩定。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sailfish OS 起初在 2024 年 10 月隨 Jolla C2 推出，經過社區反饋和多次小更新，5.0 版現已成熟。命名「Tampella」源自芬蘭坦佩雷一歷史工廠區，反映其本地特色。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a81b52b9876a881c9efd94b2674087df20c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Jolla 表示，這標誌着 Sailfish OS 的新篇章，未來將以坦佩雷為主題命名版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335783/sailfish-os-5-0-tampella</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335783/sailfish-os-5-0-tampella</guid>
            <pubDate>Sun, 23 Feb 2025 02:54:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>宇樹科技 G1 人形機器人展示武打動作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日，宇樹科技&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1818617132%2FPfVTPwcFT&quot; target=&quot;_blank&quot;&gt;發佈視頻&lt;/a&gt;&lt;/u&gt;展示了旗下 G1 人形機器人最新更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3bcf2e1605d912f524016b7bd99e7c90ca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;視頻中，宇樹 G1 人形機器人在鏡頭前展示了「武打動作」的實操，其能夠依靠自身完成單腳飛腿加 360° 轉身動作。&lt;/p&gt; 
&lt;p&gt;據宇樹科技官方介紹，宇樹 G1 機器人算法繼續升級，現在已經支持「任意動作任意學」。視頻顯示，G1 機器人完成了連續武打動作，並能夠保持平衡。&lt;/p&gt; 
&lt;p&gt;宇樹 G1 人形機器人於 2024 年 5 月發佈，定價 9.9 萬元起，官方稱其為「人形智能體、AI 化身」，支持模仿&amp;amp;強化學習驅動。外觀設計方面，該機器人體重約 35kg、身高約 127cm，擁有 23~43 個關節電機，關節最大扭矩 120N・m。&lt;/p&gt; 
&lt;p&gt;近期，宇樹科技還公佈了宇樹 G1 舞蹈視頻，視頻中機器人動作自然流暢，受到外力幹擾依然能夠完成舞蹈動作，不受外界影響。&lt;/p&gt; 
&lt;p&gt;此前，在 2025 年央視春晚中，著名電影導演張藝謀攜手杭州宇樹科技、新疆藝術學院帶來了一個名為《秧 BOT》的節目，而其中表演的機器人基於宇樹 Unitree H1 人形機器人打造，宇樹 G1 和宇樹 Go 系列機器狗也一同登台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335780</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335780</guid>
            <pubDate>Sun, 23 Feb 2025 02:30:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 開源周第三日：開源 DeepGEMM</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 開源周第三日宣佈推出 DeepGEMM，一個支持密集和 MoE GEMM 的 FP8 GEMM 庫，為 V3/R1 訓練和推理提供支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;該庫採用 CUDA 編寫，在安裝過程中無需編譯，通過使用輕量級的即時編譯（JIT）模塊在運行時編譯所有內核。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;511&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-671a532b18c34cce2c70603de74b6366ac2.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335425/deepseek-flashmla&quot; target=&quot;_blank&quot;&gt;「DeepSeek 開源周」 首發項目：FlashMLA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/335624&quot; target=&quot;_blank&quot;&gt;DeepSeek 開源周第二日：開源 DeepEP 通信庫&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335779/deepseek-deepgemm</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335779/deepseek-deepgemm</guid>
            <pubDate>Sun, 23 Feb 2025 02:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek R2 將提前推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據路透社援引三位知情人士的&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fartificial-intelligence%2Fdeepseek-rushes-launch-new-ai-model-china-goes-all-2025-02-25%2F&quot; target=&quot;_blank&quot;&gt;消息稱&lt;/a&gt;&lt;/u&gt;，DeepSeek 正在加速推出 1 月發佈的 R1 模型升級版 — DeepSeek R2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0226/101542_Mkzx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中兩位知情人士表示，&lt;strong&gt;DeepSeek 原計劃在 5 月初發布 R2，但現在希望儘早推出&lt;/strong&gt;，具體時間尚未透露。該公司表示，希望新模型在編程能力上表現更佳，並能夠支持英語以外的多種語言進行推理。&lt;/p&gt; 
&lt;p&gt;此外，DeepSeek 在同日&lt;a href=&quot;https://www.oschina.net/news/335661&quot;&gt;重新開放了 API 充值入口&lt;/a&gt;，此前因資源緊張，其曾一度關閉充值入口。目前 deepseek-chat 模型優惠期結束，調用價格已變更為每百萬輸入 tokens 2 元，每百萬輸出 tokens 8 元。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;路透社的獨家報道：&lt;/p&gt; 
&lt;p&gt;- DeepSeek 原計劃在 5 月初發布新一代 R2 模型，但已經開始考慮提前發佈，這段時間 Grok 3、Claude 3.7、Qwen 2.5-Max 等競品接連推出，還是有影響的；&lt;/p&gt; 
&lt;p&gt;- 梁文鋒在距離清華、北大兩所高校步行可達的地段設立了北京辦公室，非常樂於和實習生以及應屆生一起工作和討論問題，而且從不鼓勵加班；&lt;/p&gt; 
&lt;p&gt;- 採訪中一名已經離職的研究員依然對前老闆讚不絕口，「他把我們視為專家，不斷提問，一起學習，而且願意下放管理權，普通員工也能參與核心技術，這很讓人興奮」；&lt;/p&gt; 
&lt;p&gt;- 梁文鋒在幻方量化時就以薪酬慷慨著稱，他會給數據科學家開出 150 萬的年薪，而同行給的數字一般不會超過 80 萬；&lt;/p&gt; 
&lt;p&gt;- 在創辦 DeepSeek 前，幻方量化就制定了把 70% 對可支配收入投入到 AI 研究上的戰略，從 2020 年到 2021 年，幻方量化花了 12 億買卡訓練模型；&lt;/p&gt; 
&lt;p&gt;- 這樣的異常支出讓幻方量化受到了證券監管部門的注意，但最終沒有做出幹預，這對後來 DeepSeek 的問世至關重要，因為 2022 年開始，中國企業就不太能夠合規買到 A100 了；&lt;/p&gt; 
&lt;p&gt;- DeepSeek-R1 爆火之後，梁文鋒被建議不要和媒體接觸，因為擔心過度炒作會引起不必要的爭議，尤其是在地緣政治的風口浪尖，苟住再説；&lt;/p&gt; 
&lt;p&gt;- 另有前員工表示，DeepSeek 不缺算力，能夠進行大規模訓練，但梁文鋒對更具經濟成本的模型架構非常關注，這決定了 DeepSeek 的發展路線以及後來的巨大成功；&lt;/p&gt; 
&lt;p&gt;- 全球的 AI 大廠至今都還在消化 DeepSeek-R1 造成的影響，也都盯着 R2 的時間表，它的發佈會是今年 AI 行業的又一個關鍵時刻。&lt;/p&gt; 
&lt;p&gt;——轉載自「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1560906700%2F5138215416104782&quot; target=&quot;_blank&quot;&gt;闌夕&lt;/a&gt;」微博&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;閲讀更多&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335624&quot; target=&quot;news&quot;&gt;DeepSeek 開源周第二日：開源 DeepEP 通信庫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335425/deepseek-flashmla&quot; target=&quot;news&quot;&gt;「DeepSeek 開源周」首發項目：FlashMLA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335778/deepseek-rushes-launch-new-ai-model</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335778/deepseek-rushes-launch-new-ai-model</guid>
            <pubDate>Sun, 23 Feb 2025 02:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>阿里開源新一代 AI 視頻模型通義萬相 Wan2.1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里巴巴宣佈全面開源旗下視頻生成模型萬相 2.1 模型，採用 Apache2.0 協議。此次開源的兩個參數版本模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;14B 版本萬相模型在指令遵循、複雜運動生成、物理建模、文字視頻生成等方面表現突出，在權威評測集 Vbench 中，萬相 2.1 以總分 86.22% 大幅超越 Sora、Luma、Pika 等國內外模型，穩居榜首位置。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.3B 版本萬相模型不僅超過了更大尺寸的開源模型，甚至還和一些閉源的模型結果接近，同時能在消費級顯卡運行，僅需 8.2GB 顯存就可以生成 480P 視頻，適用於二次模型開發和學術研究。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，本次開源的 Wan2.1 在處理複雜運動、還原真實物理規律、提升影視質感以及優化指令遵循方面具有顯著的優勢，無論是創作者、開發者還是企業用户，都可以根據自己的需求選擇合適的模型和功能，輕鬆實現高質量的視頻生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時，萬相還支持業內領先的中英文文字特效生成，滿足廣告、短視頻等領域的創意需求。在權威評測集 VBench 中，萬相以總分 86.22% 的成績登上榜首位置，大幅領先了 Sora、Minimax、Luma、Gen3、Pika 等國內外視頻生成模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;246&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9615e1f458e5844f6acaf6771c609b63a80.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;294&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a089f7a00ad59e58257cca5822b066df814.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基於主流的 DiT 和線性噪聲軌跡 Flow Matching 範式，萬相大模型通過一系列技術創新實現了生成能力的重大進步。包括自研高效的 3D 因果 VAE、可擴展的預訓練策略、大規模數據鏈路構建以及自動化評估指標。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335777</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335777</guid>
            <pubDate>Sun, 23 Feb 2025 02:10:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>ChatGPT 現已可用作 Safari 默認搜索引擎</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.macrumors.com%2F2025%2F02%2F24%2Fchatgpt-safari-search-extension%2F&quot; target=&quot;_blank&quot;&gt;據 Macrumors 報道&lt;/a&gt;&lt;/u&gt;，OpenAI 今天更新了 ChatGPT 應用程序，添加了一個新的 Safari 擴展，允許將 ChatGPT 用作通過 Safari 搜索欄進行搜索時的默認搜索引擎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8702663a83430f6d7607f657f1fdf88d30.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更新到最新版本的 ChatGPT 應用程序後，用户可在設置應用程序的 Safari 部分啓用 ChatGPT 搜索擴展。打開後，在 Safari 搜索欄中輸入的所有查詢都會指向 ChatGPT 搜索，而不是谷歌或任何默認設置的搜索引擎。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/194253_LjLU_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該擴展需要獲得訪問 Google.com 或你的默認搜索引擎網站的許可，但一旦獲得許可，用户輸入的任何搜索都會重定向到 ChatGPT 的搜索功能，而不是通過 Safari 設置中的默認設置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335717/chatgpt-safari-search-extension</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335717/chatgpt-safari-search-extension</guid>
            <pubDate>Sat, 22 Feb 2025 11:43:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>特斯拉 FSD 部分能力在中國已推送，命名為「FSD 智能輔助駕駛功能」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;特斯拉官網顯示，&lt;strong&gt;FSD 駕駛套件被更名為「FSD 智能輔助駕駛功能」&lt;/strong&gt;，並重新描述其具有的能力，售價仍是 6.4 萬元。此前 FSD 功能被直譯為「完全自動駕駛能力」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1010&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/185751_YZtN_2720166.png&quot; width=&quot;780&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;另據澎湃新聞報道，特斯拉方面相關人士透露，&lt;strong&gt;公司已將 FSD 的中文表述定為「智能輔助駕駛功能」或「智能輔助駕駛系統」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1310&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/185847_aWQi_2720166.png&quot; width=&quot;2310&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不過目前看來，這相比特斯拉官網給出的名字少了其中的「FSD」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335712</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335712</guid>
            <pubDate>Sat, 22 Feb 2025 10:59:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenHands —— AI 驅動的軟件開發代理平台</title>
            <description>OpenHands 代理可以執行人類開發人員可以執行的任何操作：修改代碼、運行命令、瀏覽網頁、調用 API，甚至從 StackOverflow 複製代碼片段。</description>
            <link/>
            <guid isPermaLink="false">OpenHands —— AI 驅動的軟件開發代理平台</guid>
            <pubDate>Sat, 22 Feb 2025 10:40:00 GMT</pubDate>
        </item>
        <item>
            <title>英國《金融時報》：中國「非常值得投資」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新華社倫敦 2 月 24 日電（記者鄭博非）英國《金融時報》24 日發表文章，儘管面臨挑戰，中國經濟基本面沒有發生根本變化。越來越多投資者意識到，中國非常值得投資。文章摘要如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國股市今年開始反彈，全球投資者都在問：中國是否具備投資價值？答案是肯定的，而且一直都是如此。將全球第二大市場視為不可投資是錯誤的。投資者——尤其是外國投資者——現在正在重新發現中國，中國能夠在某些特定領域帶來巨大的創新和機遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;文章説，目前，中國市值超過 10 億美元且自由現金流收益率超過 10% 的公司有 250 多家，而美國卻不到 150 家。在這 250 多家中國上市公司中，多數屬於非科技行業，因此投資機會不僅限於互聯網和人工智能領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大盤股在中國上市公司中所佔比例仍然較小，給新入市者留下很多空間。在 11 個主要行業中，有 7 個行業的大盤股在中國的集中度低於美國。這意味着每個行業中，市值排名前五企業所佔比例更小。此外，中國科技行業的集中度也要比美國低得多，這意味着像深度求索（DeepSeek）這樣的私營初創企業可以在不被巨頭主導的環境中興起。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335708</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335708</guid>
            <pubDate>Sat, 22 Feb 2025 10:38:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Trivy：Go 語言編寫的開源安全掃描工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Trivy 是 Aqua Security 開發的開源安全掃描工具，專注於檢測容器鏡像、文件系統、代碼倉庫等場景中的安全漏洞、配置錯誤及敏感信息泄露問題。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/182528_qWAW_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faquasecurity%2Ftrivy&quot; target=&quot;_blank&quot;&gt;https://github.com/aquasecurity/trivy&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Trivy 憑藉其全面的檢測能力、易用性和開源特性，成為容器安全領域的核心工具。核心功能多場景覆蓋：&lt;/p&gt; 
&lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;支持掃描容器鏡像、文件系統、Kubernetes 集羣、Git 倉庫及雲環境，識別操作系統包（如 Alpine、Debian）和語言依賴項（如 npm、PyPI）的已知漏洞（CVE）；&lt;/li&gt; 
 &lt;li&gt;高精度匹配：內置實時更新的漏洞數據庫（如 NVD、Red Hat），提供漏洞描述、修復建議及影響範圍分析；&lt;/li&gt; 
 &lt;li&gt;配置錯誤檢查：基礎設施即代碼（IaC）掃描：檢測 Terraform、Kubernetes 等 IaC 文件的配置錯誤，例如權限過大或敏感端口暴露；&lt;/li&gt; 
 &lt;li&gt;敏感信息泄露檢測：自動掃描代碼中的密鑰、密碼等敏感數據；&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;軟件物料清單生成：自動生成符合 CycloneDX 或 SPDX 標準的 SBOM&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2019/0519/084011_8jse_12.gif&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-89a60262258f1b0d8ed08fff7f4797000fe.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335706</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335706</guid>
            <pubDate>Sat, 22 Feb 2025 10:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>AI 生成文章，作者是 AI？文本數據原作者？提問用户？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;無限猴子與結構蜘蛛&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;假設有一隻猴子，它會一直隨機地在打字機上敲擊鍵盤。那麼只要給它的足夠長的時間，它就幾乎肯定可以敲出人類任何一本已有圖書的內容，例如莎士比亞的全集。從數學上講，在無限次嘗試中，猴子可以敲打出任何一部作品的概率都無限趨近於 1。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;這就是著名的無限猴子定理，它是「荒誕」的。就像如果把一杯水倒入大海中，在之後的某個時刻，我們剛剛好可以打撈出一杯一模一樣的水一般。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;但是現在我們已經完全不需要暢想無限猴子了。在自然語言處理（NLP）和文本生成領域，要模仿特定的風格生成文本，如果結合大規模預訓練模型、風格特徵提取、文本生成調優等技術方法，就可以做到「以假亂真」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:auto !important; margin-right:auto !important; text-align:justify&quot;&gt;&lt;img height=&quot;1288&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/180621_6eOp_3820517.png&quot; width=&quot;1266&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一種關於 AI 的新型自指羅素悖論：由 AI 寫作的一篇「我堅決不看任何 AI 寫的東西」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;這就是同樣基於概率的 deepseek 晚近「震驚人類」的創作，它生成的文本幾乎無法分辨是不是人寫的，並能夠模擬任何風格與作者的文本。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;AI 眼中的「文學風格」是什麼樣的？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;如果説類似網文、公文等因其程式化、商業化的文體特徵，既沒有什麼獨一無二的「作者性」，也沒有什麼高明的文學性，很容易找到它們「批量生成方式」的話，那我們不妨直接擺上人類整個文學史上最高段的作家之一——三島由紀夫為例，讓 AI 生成一段三島式的文段：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;暴雨中的劍道場瀰漫着鐵鏽與朽木的氣息，汗水順着少年繃緊的脊樑滑落，在榻榻米上洇出深色圖騰。竹刀相擊的脆響裏，他看見師父眼角的皺紋藏着江户時代某場未竟的復仇。當狂風掀開紙門，攜來山茶花的殘瓣黏在汗濕的胸膛時，他恍然領悟肉體不過是盛裝恥辱的陶器，唯有在徹底粉碎的瞬間，方能窺見永恆澄明的月光。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;三島的文風「汪洋恣肆，波雲詭譎」，比喻驚世駭俗，往往「語不驚人死不休」，令人拍案叫絕，難以名狀。而 Deepseek 交出的答卷，即使還不能説已經足夠「以假亂真」，但文風的確已經相當有極具辨識度的三島韻味了。那麼 AI 是怎麼做到的呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;當我們説「三島由紀夫式的段落」時，我們首先在表達的，是一種極度抽象、模糊的文本特徵，亦即一種經過後人總結與概括出的美學風格。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;相信很少有人可以否認，三島由紀夫的核心風格至少是包括以下幾個方面的：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;極端美學：三島強調死亡之美、肉體之美、秩序與毀滅的共存。他的文字往往冷峻、華麗，帶有儀式感。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;日本傳統與西方現代性的交融：他擅長描繪日本傳統武士道精神、神道教意象，同時又深受西方文學影響（如尼采、波德萊爾）。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;強烈的視覺意象：他的描寫極富畫面感，常用光影、色彩、質感等細節來增強感官刺激。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;短促有力的句子與複雜華美的句羣交替：他能夠在冷靜、簡潔的描述和繁複的抒情段落之間切換自如。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;有美與毀滅的共存、個人意志與時代洪流、武士道精神的絕對化等思想衝突：「唯有被烈焰吞噬的建築，才能顯現其真正的輪廓」「他寧願讓自己的信仰碎裂成光輝四濺的玻璃，也不願在時代的塵埃中沉默」「肉體不過是意志的器皿，若器皿已破，則意志亦得解放」等。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;不僅如此，嗜讀三島的人們也很容易就可以總結出三島有以下這些鮮明的修辭風格，甚至可以説風格鮮明到了若是不如此，就根本「不像」三島作品的程度：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;對自然的高度擬人化：如「秋日的陽光像一柄鋭利的匕首，斜斜地刺入庭院，那金色的光芒在枯葉上燃燒，宛如即將自焚的舞姬。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;對肉體的極端關注：如「他脱下襯衫，背肌繃緊，皮膚因寒冷而泛起淡淡的青白色，像是刀刃輕撫過的瓷器。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;華麗的比喻與象徵：「在夜色中，寺廟的影子倒映在水面，彷彿一匹黑色的戰馬正在湖心飲水。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而以上三島核心美學特點與修辭特點的描述正是 AI 自己的「體會」，已經非常準確與出色了，與專家精心編撰的文學史教材中對三島風格的概括可以説具有幾乎同樣準確的知識深度。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;上述這些在人類看來是美學風格的東西，在進行過語料庫構建與風格學習的機器眼中，卻全然是另一番景象。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;機器在收集足夠的三島由紀夫文本後，會首先進行預處理。三島由紀夫的作品會被機器進行分句、分詞，處理日語/中文/翻譯英文版本等，並「確保數據格式一致」。此後，機器會採用 TF-IDF、BERTembeddings 等方法分析三島文本的常見詞彙與獨特短語，比如他偏好使用的比喻、色彩詞、身體意象等。有了上述準備工作，機器就可以對文本進行句法分析，從而識別出三島句子的結構模式，比如：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·修飾性強的長句（多層定語、隱喻、插入語）&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·簡短有力的斷句（刀鋒般的短句，強調死亡、決絕）。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;其後，機器就可以訓練風格分類器（Style Classifier），用以區分三島文本與其他作家的文本，並讓模型學習他的詞彙分佈、句法模式、修辭風格，從中提取獨特的風格特徵了。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;AI 是怎麼生成特定風格的文本的？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;當模型根據人類給定的條件來調整輸出，並生成特定風格、主題或情感的文字時，比如生成三島由紀夫風格的文字，就叫做「受控文本生成」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;大模型會限制輸出自己句子的平均長度、從句嵌套深度、比喻使用率等，使其符合三島的句法特點，並優先使用「死亡、美、毀滅、身體、宗教」等高頻詞，以保持風格一致性。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而且如果降低温度（Temperature），就可以控制詞彙分佈、減少生成隨機性，使生成文本更符合訓練數據風格，並更具連貫性，不至於過於發散。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;人類也很容易訓練一個句法轉換模型（Syntax Transfer Model）和比喻生成器（Metaphor Generator），用以將普通文本轉換成三島風格，比如：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·普通句子：「落葉在風中飄零」「他的手指微微顫抖」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·三島風格：「秋風撕裂枝頭，枯葉如燒盡的詩篇，沉默地墜落」「他的指尖如風中殘燭，顫抖着，彷彿即將熄滅」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;甚至還可以結合情感分析模型（Sentiment Analysis），調整文本的情緒參數，讓生成更具三島式的「悲壯美感」或「壓抑感」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;最後是大模型的評估與優化環節，機器可以自己計算三島文本與生成文本的困惑度。（Perplexity），評估其可讀性與風格一致性，並使用 BERTScore（計算生成文本與參考文本之間單詞片段的重複率）、BLEU（衡量生成文本覆蓋了多少原文的關鍵內容）、ROUGE（將文本轉化為上下文語義向量，計算生成文本與原文在深層語義上的相似度）等方式，衡量生成文本與三島原文的相似度。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;再加上人類「專家」的最後的評估與調優，機器就可以把文學、美學風格轉化為數據、概率，並由此模擬任何人的寫作風格。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;作者應該是 AI 本身，還是「原作者」，亦或是問問題的用户？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;卡夫卡在臨終前給了好友布洛德一份遺囑，要求他死後銷燬所有未發表的手稿，其中包括《城堡》、《審判》等公認最偉大的文學作品。卡夫卡此前就多次表達過類似的意願，並甚至親手銷燬過自己的手稿，但布洛德選擇了&quot;背叛&quot;他最好朋友的遺願。他不但沒有銷燬這些手稿，反而傾盡畢生精力整理、編輯並出版了它們。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;米蘭·昆德拉正是以這個故事展開他的著名的文論作品《被背叛的遺囑》的，而且恐怕沒有人會對此抱有異議：布洛德救贖了文學，即使他背叛了作家本人的意願與友誼，他還是幹得漂亮，他做得太對了！&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;然而如果我們思考昆德拉在這本書中提出的另一個有趣的問題，答案似乎就不如此黑白鮮明瞭。斯特拉文斯基堅持認為，演奏者必須嚴格按照自己樂譜演奏，他反對任何形式的擅自改動。即使在有些時候，經過改動後的樂譜演出效果更好。那麼這種有悖於作曲家或藝術家原意的「更好」的改動，是可以被允許的嗎？昆德拉借題發揮道：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;毫無疑問，人們完全可能把《追憶逝水年華》中的某個句子寫得更好些。但上哪兒去找這麼個願意讀一本修改後的普魯斯特作品的瘋子呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;即使在實質意義上，被改動後的文本是比原來的文本「更好」的，這種改動也是不被允許的。這個問題在昆德拉這裏之所以是不證自明的，根本原因在於他認為作者的作品是一個有機的整體，任何改動都可能破壞其內在的邏輯和意義。後人首先應該尊重作者的創作意圖，並儘量理解和還原作者想要表達的思想和情感。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;所以昆德拉並沒有在這個問題上更進一步，這個被改動了個別詞句的，甚至已經改變了作者原意的「文本」，他的作者，到底應該是普魯斯特，還是應該是普魯斯特以及改動了這段文本的那個人兩人合著呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而昆德拉之所以沒有考慮這個問題，主因或許是印刷時代的紙質圖書生成方式，被其他人改動了個別字句的《追憶似水年華》因為沒有人願意看的「市場性」原因根本沒有被印出來的價值，而且著作權也不允許這樣的著作被印出來。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;所以文本的作者是普魯斯特與一個沒有經過普魯斯特允許的改寫者的情況是不可能發生的。在信息的生產與流通並不依賴紙質圖書的印刷、出版的數字時代，一般出現這種偷偷改動原文個別字句並據為己用的情況，自然會被判定為洗稿。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;但如果這段文本的創作者是具有生成能力的大語言模型呢？尤其是大語言模型生成的文本是在它學習了原作者的大量文本後，利用上述手段生成了在人類可以識別的「風格」上完全相同的新的文本。如果 AI 生成文本的風格與原作還有差距，那也只是 AI「還」不能出色地完成仿寫任務，而不是 AI「不能」完成這個任務。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;那麼 AI 通過仿寫生成的文本，他的「作者」到底應該是 AI 本身，是原始文本數據的提供者「原作者」，還是那個通過提問詞一步步引導 AI 生產出了這段文本的用户？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;很多人認為 AI 生成的內容應視為「委託作品」，著作權歸屬於終端用户。但另一種觀點認為，AI 生成的內容缺乏人類創作者的直接參與，不應視為作品，因而不受著作權法保護。純粹由 AI 生成的藝術作品不應該獲得版權保護，因為 AI 提示本身不足以使用户成為作品的作者。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而 AI 在生成內容時，未經授權使用他人作品進行訓練，已經出現過實際的侵權案例。例如，Thomson Reuters 在與 Ross Intelligence 的訴訟中，法院裁定 Ross 未經授權複製其內容用於 AI 訓練，侵犯了其版權。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:auto !important; margin-right:auto !important; text-align:justify&quot;&gt;&lt;img height=&quot;216&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/180643_5zwk_3820517.png&quot; width=&quot;1236&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不過美國的版權所有者態度與法律尺度比其他國家更為嚴苛。據傳，幾乎所有的著名 AI 公司都曾向數字圖書館安娜的檔案提出過合作邀約，但最後美國公司都因為對於版權問題的擔憂而最終放棄了合作。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;隨着 AI 技術的不斷進步，AI 生成內容的著作權歸屬和相關法律倫理問題只會更加複雜。具有推理與文本生成能力的 AI 技術將為人類社會的方方面面的格局都帶來無比重大的改變，版權的概念與相關的法律條文概莫能外。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;em&gt;原文標題：AI 生成的文本，版權應該屬於誰？&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fculture.ifeng.com%2Fc%2F8h7hfSZDQgO&quot; target=&quot;_blank&quot;&gt;https://culture.ifeng.com/c/8h7hfSZDQgO&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335702/who-is-the-author-of-aigc</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335702/who-is-the-author-of-aigc</guid>
            <pubDate>Sat, 22 Feb 2025 10:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>大模型選型攻略，限免！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;贈書啦，歡迎大家在評論區聊聊「大模型選型那些事」，暢所欲言&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;我們將在評論區隨機選出 3 名 OSCer，贈送&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;《AI 賦能：大模型概念、技術及企業級項目應用&lt;/strong&gt;&lt;strong&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;一本&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;活動截止時間：2 月 28 日 18:00&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;面對市場上眾多的大模型選擇，如何進行科學的選型也成為了企業面臨的一個重要問題。根據筆者的實踐經驗總結，我們會從&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;大模型基礎信息評估、大模型性能評估&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;大模型的備案信息評估&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;三個維度來進行大模型的選型。&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;大模型基礎信息評估&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型基礎信息評估作為選型的第一步，顯得尤為關鍵。下面我們將從參數量、數據規模和維度、模型架構、模型能力應用領域、供應商企業特徵以及社區支持與生態系統等六個角度，詳細闡述大模型基礎信息評估。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;1.參數量&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;參數量是衡量大模型複雜度的重要指標，它直接影響到模型的表達能力和學習能力。根據大模型的縮放定律和湧現能力，參數量越大，模型的學習能力和表達能力通常越強。然而，參數量的增加也會帶來計算資源的消耗和訓練難度的提升。這也會影響到項目執行中的微調策略，以及上線運行時的計算資源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，根據企業的計算資源和業務需求，選擇適當參數量的模型。對於資源有限的企業，可以選擇參數量適中的模型以平衡性能和資源消耗。避免盲目追求大參數量，要結合實際應用場景來評估模型的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;2.模型數據規模和維度&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;數據是訓練大模型的基礎，數據規模和維度的選擇直接影響到模型的訓練效果和性能。大而全的數據集有助於模型學習更廣泛的知識，提高泛化能力，而特定領域的數據集則能使模型在特定任務上表現更出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，優先選擇與企業所在行業、領域相關的數據集訓練的模型，以確保模型對特定領域有深入的理解。同時，考慮數據的豐富性和多樣性，以提高模型的泛化能力和適應性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;3.模型架構&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型架構決定了大模型的學習方式和性能上限。&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前主流的大模型架構大多基於 Transformer，但不同模型在架構上可能有所創新和優化，以適應不同的應用場景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此&lt;/span&gt;&lt;span style=&quot;color:#ff0000&quot;&gt;，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在實際項目中，要關注模型架構的創新性和優化點，瞭解其在提升性能、降低計算複雜度等方面的改進，選擇經過驗證、性能穩定的模型架構，以降低實際應用中的風險。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;4.模型能力應用領域&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同的大模型可能針對特定領域進行了優化，或者其底層訓練數據決定了其應用能力。因此，在選擇大模型時，需要根據企業的實際需求來確定模型的應用領域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.供應商企業特徵&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;供應商的企業特徵也是選型時需要考慮的因素之一。包括供應商的信譽、技術實力、服務質量等都會影響到模型的使用體驗和後續支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;社區支持與生態系統&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;一個活躍的社區和豐富的生態系統意味着更多的資源和支持，有助於企業在使用過程中解決問題和優化模型。社區的活躍度和生態系統的完善程度也是評估大模型價值的重要因素。&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;大模型性能評估&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型性能評估是選定基礎信息後的關鍵環節，它旨在全面衡量大模型在實際應用中的表現。在項目實操中，我們從兩個主要方面來評價大模型的性能：&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;大模型通用模型能力&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;和&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;場景適應能力&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;。對於通用模型能力，我們會綜合考察備選大模型在基礎能力、智商能力、情商能力和工具提效能力等各方面的表現，以此來判斷其是否具備類似於人的通用智能。而場景適應能力評估則更為具體，我們會根據項目的實際需求設計驗證性問題，通過大模型對這些問題的回答和處理情況來檢驗其是否真正符合項目的特定要求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;401&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8bff27e462a46054d55333b18902f01043.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;表 1.大模型通用能力評估方法問題量表&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;435&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-27d3432a05284e47bcb989e67234f71529a.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;圖 1.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型通用測試評估示例&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;455&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-81d3dc57c57a1493421ccf78a888fdd8100.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;圖 2.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型提示詞優化後的特定場景評估示例&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;457&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6c36432f534adb2fa1fe6b94fa1bbdfd1da.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;圖 3.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型微調後的場景能力測試評估示例&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;&lt;strong&gt;大模型備案信息評估&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前雖然沒有明確要求企業在構建私有大模型時只能應用備案過的大模型，但是完成備案的大模型都經過了嚴格的能力審查，在模型性能和安全性上有較強的優勢，因此建議企業優先選用通過備案的大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;1. 大模型備案概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型備案，即生成式人工智能（大語言模型）上線備案，是網信部門針對生成合成（深度合成）類算法的特定管理流程。這一制度的設立，旨在確保大模型在上線運行前已經通過了嚴格的能力審查和安全評估，從而保障其在模型性能和安全性方面達到一定的標準。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在這裏，「生成式人工智能技術」特指那些具備文本、圖片、音頻、視頻等內容生成能力的模型及相關技術。而「深度合成技術」則涵蓋了利用深度學習、虛擬現實等手段製作文本、圖像、音頻、視頻等網絡信息的技術。這些技術包括文本生成與風格轉換、問答對話，以及人臉生成與替換、人物屬性編輯等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（1）大模型備案的主體&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據《生成式人工智能服務管理暫行辦法》的規定，具有輿論屬性或社會動員能力的生成式人工智能服務提供者，需按照國家相關規定開展安全評估並進行備案。這些服務提供者主要分為兩類：平台運營方和技術支持方。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（2）大模型備案流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;如下圖所示，大模型備案流程的重要節點如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;678&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6d05f943e3d30a4d32010089051cbabd587.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;圖 4.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型備案流程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（3）大模型備案所需材料&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在進行大模型備案時，服務提供者需要準備以下材料：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型上線備案申請表：詳細填寫模型的基本信息、開發團隊情況、應用場景等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 1：安全自評估報告：對模型的安全性進行全面評估，包括數據安全性、算法安全性、系統安全性等方面。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 2：模型服務協議：明確服務提供者與用户之間的權利義務關係，保障雙方合法權益。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 3：語料標註規則：詳細説明模型在訓練過程中使用的語料標註規則和方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 4：關鍵詞攔截列表：列出可能被模型識別並攔截的關鍵詞或敏感詞彙。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 5：評估測試題集：提供一套用於評估模型性能和準確性的測試題集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;綜上所述，大模型備案制度的確立和實施對於規範我國人工智能技術的發展具有重要意義。通過嚴格的備案流程和材料審核，可以確保大模型在合法性、安全性和性能方面達到高標準，從而推動我國人工智能產業的健康、可持續發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;2. 企業對備案信息審查評估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型在備案時會提交詳細的應用場景、安全自評估報告、模型的預料標註規則、關鍵詞和敏感詞攔截信息以及測試集信息等。這對企業全面瞭解和評估大模型的能力和應用，確定供應商是否具備本項目的實施能力至關重要。以下是我們在項目實踐中的常用方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（1）明確評估目標與標準&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在開始評估前，企業應首先明確自身的業務需求、技術要求和安全標準。這有助於企業在後續的評估過程中，更加針對性地審查相關信息，確保所選大模型能夠滿足企業的安全需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（2）審查應用場景&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;企業需仔細閲讀大模型備案中提供的應用場景描述，瞭解模型的主要用途、使用環境和預期效果。通過對比企業的實際需求，判斷該模型是否適用於本企業的業務場景。同時，關注應用場景中可能存在的風險點和挑戰，以便在後續合作中制定相應的應對措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;（3）分析安全自評估報告&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;安全是企業在選擇大模型時不可忽視的重要因素。企業應詳細審查安全自評估報告，瞭解模型在數據安全、算法安全和系統安全等方面的設計和實施情況。特別關注報告中提到的安全漏洞和應對措施，確保模型在實際應用中能夠保障企業數據的安全性和完整性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（4）核查預料標註規則&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;預料標註規則直接影響大模型對數據的理解和處理能力。企業應核查這些規則是否科學、合理，並符合企業的數據處理需求。通過對比不同模型的標註規則，選擇那些能夠更準確地反映企業數據特徵和處理邏輯的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（5）檢查關鍵詞和敏感詞攔截信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;關鍵詞和敏感詞攔截功能對於保障信息安全和遵守法律法規至關重要。企業應檢查備案信息中提供的關鍵詞和敏感詞列表，確保其全面且符合企業的合規要求。同時，測試模型的攔截功能是否有效，以避免在實際應用中出現不當內容或敏感信息的泄露。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（6）評估測試集信息與模型性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;測試集信息是評估大模型性能的重要依據。企業應審查測試集的設計是否合理、數據是否豐富多樣，並瞭解測試過程中的評估指標和方法。通過對比不同模型的測試結果，選擇那些在準確率、召回率等關鍵指標上表現優異的模型。此外，企業還可以自行設計測試用例，對模型進行進一步的性能測試。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;綜上所述，企業對大模型備案信息的審查評估是一個系統而細緻的過程。通過明確評估目標、審查應用場景、分析安全報告、核查標註規則、檢查關鍵詞攔截信息以及評估測試集信息與模型性能等具體步驟，企業可以更加全面地瞭解大模型的能力和應用情況，從而做出更加明智的選擇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以上內容節選自《AI 賦能：大模型概念、技術及企業級項目應用》&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作者：田野，張建偉&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;436&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-111c957c954945b1bd502ae1abb3549868e.png&quot; width=&quot;372&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;《AI 賦能：大模型概念、技術及企業級項目應用&lt;/strong&gt;&lt;strong&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;田野，張建偉&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;京東「計算機與互聯網」圖書銷量榜 TOP1！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;三一集團副總裁、三一商用車智造公司總經理吳盛楠、徐工集團工程機械股份有限公司副總裁閆君，傾情作序。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;聯想方案服務業務集團大模型與智能體項目實踐經驗總結，全景式展現大模型產品生態圈及技術原理，提出大模型選型和建設標準及項目實施方法，企業建設、部署、應用大模型的實用指南。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;本書聚焦於大模型技術在企業中的實際應用，幫助讀者應用大模型為企業降本增效。全書共 6 章：初識大模型、大模型產品生態圈、大模型的技術原理、企業如何部署和應用大模型、企業大模型項目的實施方法、大模型企業應用實踐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;本書提供了詳細的大模型選型和建設標準，旨在為企業提供一份清晰的大模型建設指南，幫助讀者瞭解如何建設、部署和應用大模型。本書詳細介紹了企業大模型項目的實施方法，從項目規劃到工程化部署，並通過具體的企業應用實踐案例，展示了大模型在基座型基礎設施、企業知識中台、業務知識庫、智能體及個人辦公智能輔助工具中的強大應用潛力，幫助讀者在實踐中掌握應用大模型的關鍵技術和管理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;本書的讀者對象為人工智能、機器學習和數據分析等領域的從業人員，對企業數字化轉型和智能化應用感興趣的企業管理者和決策者，希望通過大模型技術和實施方法增強自身技能的技術研究者和開發者，以及對大模型技術感興趣並希望深入瞭解和探索這一前沿科技及其應用場景的讀者。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17766917</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17766917</guid>
            <pubDate>Sat, 22 Feb 2025 09:41:00 GMT</pubDate>
            <author>原創</author>
        </item>
    </channel>
</rss>