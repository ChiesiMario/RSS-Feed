<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Tue, 22 Jul 2025 16:52:39 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Agentic IDE 工具 Windsurf 發佈 Wave 11</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;被 Cognition &lt;a href="https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf"&gt;收購&lt;/a&gt;的 Agentic IDE 工具 Windsurf 發佈了 Wave 11 版本，新增了語音輸入、對話檢查點和更深入的瀏覽器集成等功能。&lt;/p&gt; 
&lt;p&gt;新版本為核心的 Cascade AI 助手引入了語音支持，用户現在可以通過語音輸入複雜的任務提示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/194215_s89o_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，為便於管理長對話，新增了「命名檢查點」（named checkpoints）功能，用户可以創建對話快照並隨時恢復。同時，用户現在可以在新對話中通過 @ 提及過去的對話，以便 Cascade 獲得完整的上下文。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1506" src="https://static.oschina.net/uploads/space/2025/0722/194252_ImDM_2720166.png" width="1084" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;瀏覽器集成也得到深化，Cascade 現在可以訪問更多瀏覽器工具，如對打開的標籤頁進行截圖和檢索 DOM 樹。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/194351_A7KI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;備受歡迎的「規劃模式」（Planning mode）因其能有效提升複雜任務的響應質量，現已成為默認開啓項。針對 JetBrains IDE 用户，此次更新也帶來了規劃模式、工作流和基於文件的規則等功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361777/windsurf-wave-11</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361777/windsurf-wave-11</guid>
      <pubDate>Wed, 16 Jul 2025 11:43:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Gemini 原生文本轉語音 (TTS) 功能達到生產就緒狀態</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Gemini 模型的原生文本轉語音（TTS）功能已適用於規模化的生產環境，該功能目前支持 Gemini 2.5 Flash 和 Gemini 2.5 Pro 兩個模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1270" src="https://static.oschina.net/uploads/space/2025/0722/193157_hkfD_2720166.png" width="1444" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://x.com/OfficialLoganK/status/1947328086577492309&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據官方人員透露，這項強大的功能適用於多種用例，例如創建類似 NotebookLM 風格的播客內容。該功能可以通過&amp;nbsp;AI Studio&amp;nbsp;和&amp;nbsp;Gemini API&amp;nbsp;體驗使用。&lt;/p&gt; 
&lt;p&gt;Gemini API 可以使用原生文本到語音 (TTS) 生成功能，將文本輸入轉換為單聲道或多聲道音頻。文字轉語音 (TTS) 生成是可控制的，這意味着您可以使用自然語言來構建互動，並引導音頻的風格、口音、節奏和語氣。&lt;/p&gt; 
&lt;p&gt;TTS 功能不同於通過 Live API 提供的語音生成功能，後者專為互動式非結構化音頻以及多模態輸入和輸出而設計。雖然 Live API 在動態對話情境中表現出色，但通過 Gemini API 進行 TTS 更適合需要精確朗讀文本並對風格和音效進行精細控制的場景，例如播客或有聲讀物生成。&lt;/p&gt; 
&lt;p&gt;詳情查看 https://ai.google.dev/gemini-api/docs/speech-generation&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361776</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361776</guid>
      <pubDate>Wed, 16 Jul 2025 11:33:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>李開復 AI 創業公司發佈下首個智能體（AI Agent）產品</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 22 日，零一萬物在北京舉辦產品發佈會，正式發佈萬智企業大模型一站式平台（萬智平台）2.0 版本，並推出企業級 Agent 智能體（代號「萬仔」），以「超級員工」為核心定位，具備深度思考和任務規劃能力，可訪問手機和 Web 端，連接各類企業服務，幫助企業基於自身業務場景定製專屬 Agent，解決真實問題。&lt;/p&gt; 
&lt;p&gt;萬智企業級 Agent 通過自研強化學習和全棧研發工程技術棧，提升任務規劃能力，結合企業知識庫和生產任務，以交付結果為目標動態生成執行計劃，實現「從工具流執行者」向「人機共同決策者」的躍遷，並支持私有化部署和結果校驗，確保業務數據與安全無憂。&lt;/p&gt; 
&lt;p&gt;零一萬物 CEO 李開復表示，企業級 Agent 已步入推理 Agent 階段，與 OpenAI 最新發布的 ChatGPT Agent 處於同一技術水位，推動中國大模型產業從「交付服務」邁向「交付結果」的產業 AI 時代。&lt;/p&gt; 
&lt;p&gt;對於目前 AI Agent 的發展路徑，李開復預計會經歷三個演進層級：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L1：工作流 Agent&lt;/strong&gt;：這一階段由人類主導任務的規劃與決策流程，Agent 僅按指令一步步執行指定動作。雖然實現了任務自動化的初步落地，但其智能化程度有限，本質仍為強化版的「RPA（機器人流程自動化）」或「Co-pilot」，難以應對企業中複雜多變、跨環節的任務。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L2：推理 Agent&lt;/strong&gt;：Agent 具備基於大模型的任務規劃能力，能通過推理機制自主判斷任務步驟，調度多種工具完成複雜目標。此階段的 Agent 不再依賴人類指定的流程，而是能「想清楚再做」，具備真正的任務閉環執行能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L3：多智能體 Multi-Agents&lt;/strong&gt;：多個 AI Agent 之間實現有機協作，自主進行任務分配、資源調度與協同優化。這一階段將徹底重構企業運作範式，形成真正的去中心化智能協作網絡，是 Agent 發展的進階形態與行業變革的關鍵臨界點。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e4ca3b02e01d328a452fc62ac24065a4a0e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361773</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361773</guid>
      <pubDate>Wed, 16 Jul 2025 11:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TinyEditor v4.0 alpha 版本發佈：表格更強大，表情更豐富，上傳體驗超乎想象！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;你好，我是 Kagol，個人公眾號：&lt;code&gt;前端開源星球&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor%2F" target="_blank"&gt;TinyEditor&lt;/a&gt; 是一個基於 Quill 2.0 的富文本編輯器，在 Quill 基礎上擴展了豐富的模塊和格式，框架無關、功能強大、開箱即用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;源碼：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-editor%2F" target="_blank"&gt;https://github.com/opentiny/tiny-editor/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;官網：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor%2F" target="_blank"&gt;https://opentiny.github.io/tiny-editor/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對於富文本編輯器來説，插入圖片、視頻、表情，插入和編輯表格，這些都是非常常見的功能，因此我們對這幾個模塊做了重點優化和重構。&lt;/p&gt; 
&lt;h2&gt;更強大的表格&lt;/h2&gt; 
&lt;p&gt;之前的表格模塊基於 quill-better-table 實現，現在這個項目已經不維護了，為了讓 TinyEditor 的表格功能更好地演進下去，TinyEditor 項目核心貢獻者 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzzxming" target="_blank"&gt;zzxming&lt;/a&gt; 對錶格模塊進行了重構，使用了 quill-table-up 作為底層實現，替換了不維護的 quill-better-table。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzzxming%2Fquill-table-up" target="_blank"&gt;quill-table-up&lt;/a&gt; 是 zzxming 設計和實現的，基於 Quill 2.0，擁有更好的模塊化設,、更強的功能、更優的體驗，而且一直在持續維護中。&lt;/p&gt; 
&lt;p&gt;quill-table-up 支持 quill-better-table 所有的功能，並且做了大量增強：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持單元格中插入塊級元素，比如：標題、引用、代碼塊等&lt;/li&gt; 
 &lt;li&gt;支持自定義單元格背景色、邊框顏色&lt;/li&gt; 
 &lt;li&gt;拖拽改變行高/列寬，調整表格整體寬高&lt;/li&gt; 
 &lt;li&gt;除了右鍵工具欄菜單，還支持常駐顯示工具欄&lt;/li&gt; 
 &lt;li&gt;支持斜線快捷菜單插入表格，支持上下左右方向鍵選擇表格行/列大小&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;quill-table-up 做了很好的模塊化設計，每個特性是一個單獨的文件，支持按需引入和使用，這一點對於富文本這邊的大型組件來説非常友好，可能每個業務只需要其中一部分功能，就可以不需要引入，打包時也不會包含這個特性的代碼，能有效地減少包體積。&lt;/p&gt; 
&lt;p&gt;感謝 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzzxming" target="_blank"&gt;zzxming&lt;/a&gt; 在表格模塊重構和優化中付出的努力，提升了 TinyEditor 富文本編輯器的表格操作體驗。&lt;/p&gt; 
&lt;p&gt;歡迎朋友們給 quill-table-up 開源項目點個 Star 支持下！&lt;/p&gt; 
&lt;p&gt;源碼：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzzxming%2Fquill-table-up" target="_blank"&gt;https://github.com/zzxming/quill-table-up&lt;/a&gt;（歡迎 Star）&lt;/p&gt; 
&lt;p&gt;使用起來非常簡單。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import FluentEditor, { generateTableUp } from '@opentiny/fluent-editor'
// 按需導入 quill-table-up 特性模塊
import { defaultCustomSelect, TableMenuSelect, TableSelection, TableUp } from 'quill-table-up'
// 引入樣式文件
import 'quill-table-up/index.css'
import 'quill-table-up/table-creator.css'

// 註冊 table-up 模塊
FluentEditor.register({ 'modules/table-up': generateTableUp(TableUp) }, true)

const TOOLBAR_CONFIG = [
  [{ header: [] }],
  ['bold', 'italic', 'underline', 'link'],
  [{ list: 'ordered' }, { list: 'bullet' }],
  ['clean'],
  // 配置工具欄菜單項
  [{ 'table-up': [] }],
]

new FluentEditor(element, {
  theme: 'snow',
  modules: {
    'toolbar': TOOLBAR_CONFIG,
    // 配置 table-up 模塊
    'table-up': {
      // 配置工具欄中選擇表格行/列數量
      customSelect: defaultCustomSelect,
      
      // 配置拖選多個單元格，進行後續操作，比如：合併單元格、設置單元格背景色等
      selection: TableSelection,
      selectionOptions: {
        // 配置工具欄菜單的顯示方式，支持點擊右鍵顯示、選擇單元格後常駐顯示兩種形式
        tableMenu: TableMenuSelect,
      },
    },
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;效果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3f413df81e1938ec4208240cbe677e7973c.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多特性歡迎大家使用和體驗。&lt;/p&gt; 
&lt;p&gt;體驗地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor%2Fdocs%2Fdemo%2Ftable-up" target="_blank"&gt;https://opentiny.github.io/tiny-editor/docs/demo/table-up&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;更豐富的表情&lt;/h2&gt; 
&lt;p&gt;在富文本中插入表情，雖然不是一個必須的功能，但卻能讓富文本內容更加有趣，比如我用富文本編輯器寫一篇文章，如果能再文章中插入可可愛愛的 Emoji 表情，將是一件多麼美妙的事情。&lt;/p&gt; 
&lt;p&gt;之前的 TinyEditor 支持的表情數量有限，而且沒有做分類，不支持搜索，想要找一個想要的表情太難了。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvaebe" target="_blank"&gt;vaebe&lt;/a&gt; 基於 emoji-mart 實現了一個新的 Emoji 模塊，不僅支持更多表情，而且做了分類，支持表情的搜索、預覽、最近實用的表情等實用的功能。&lt;/p&gt; 
&lt;p&gt;使用之前需要先安裝對應的依賴：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm i @floating-ui/dom @emoji-mart/data emoji-mart
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然後分別在工具欄和模塊開啓 emoji 即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import FluentEditor from '@opentiny/fluent-editor'

const TOOLBAR_CONFIG = [
  [{ header: [] }],
  ['bold', 'italic', 'underline', 'link'],
  [{ list: 'ordered' }, { list: 'bullet' }],
  ['clean'],
  // 配置 Emoji
  ['emoji'],
]

new FluentEditor(element, {
  theme: 'snow',
  modules: {
    'toolbar': TOOLBAR_CONFIG,
    // 配置 emoji 模塊
    'emoji': true,
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;效果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-594008cdee196297c98227ba0391c93ef65.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;對比下之前的表情面板：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f77e7faa95188bef7c053e47cf2289362d.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版的表情功能，UI 和體驗都比之前的好太多了，感謝 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fvaebe" target="_blank"&gt;vaebe&lt;/a&gt; 給我們提供了一個這麼好用的表情功能。&lt;/p&gt; 
&lt;p&gt;更多特性歡迎大家使用和體驗。&lt;/p&gt; 
&lt;p&gt;體驗地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor%2Fdocs%2Fdemo%2Femoji" target="_blank"&gt;https://opentiny.github.io/tiny-editor/docs/demo/emoji&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;體驗更好的圖片/視頻/文件上傳功能&lt;/h2&gt; 
&lt;p&gt;"富文本"意味着不僅僅是文字，還包含圖片、視頻等更豐富的內容，之前的圖片、視頻、文件上傳是獨立的三個模塊，這就導致很多功能上的重複，比如校驗文件格式、大小，多圖、多文件上傳，調整圖片、視頻寬高，圖片、文件的下載等功能，每個模塊都要實現一遍。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzzxming" target="_blank"&gt;zzxming&lt;/a&gt; 敏鋭地識別到了這個問題，並將圖片、視頻、文件模塊合併成一個模塊，默認會處理視頻與圖片格式，其他格式統一被處理為文件顯示。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;圖片可以拉伸放大縮小，可以左中右對齊，可以複製、下載&lt;/li&gt; 
 &lt;li&gt;視頻可以播放、暫停、下載、全屏、調整聲音&lt;/li&gt; 
 &lt;li&gt;文件可以查看大小、下載、刪除&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用起來非常簡單，只需要在工具欄配置中配置即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import FluentEditor from '@opentiny/fluent-editor'

const TOOLBAR_CONFIG = [
  [{ header: [] }],
  ['bold', 'italic', 'underline', 'link'],
  [{ list: 'ordered' }, { list: 'bullet' }],
  ['clean'],
  // 配置圖片、視頻、文件上傳功能
  ['file', 'image', 'video'],
]

new FluentEditor(element, {
  theme: 'snow',
  modules: {
    'toolbar': TOOLBAR_CONFIG,
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;效果如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-711cf828c674ccad2097a2dbaf32a9b0925.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多特性歡迎大家使用和體驗。&lt;/p&gt; 
&lt;p&gt;體驗地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor%2Fdocs%2Fdemo%2Ffile-upload" target="_blank"&gt;https://opentiny.github.io/tiny-editor/docs/demo/file-upload&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;往期推薦文章&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7403618336952418314" target="_blank"&gt;👍TinyEditor：一個基於 Quill 2.0 的富文本編輯器，功能強大、開箱即用！&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7430505409176289320" target="_blank"&gt;🎈TinyEditor 富文本開源 2 個月的總結：增加格式刷、截屏、TypeScript 類型聲明等新特性&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7436030236784214068" target="_blank"&gt;🥳重磅更新！TinyEditor 開源富文本支持 LaTeX 可編輯公式啦~&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7406347285901426728" target="_blank"&gt;🎉喜報！TinyEditor 開源富文本迎來了第一位貢獻者&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7442330442606051338" target="_blank"&gt;👏讓我們一起來建設 TinyEditor 開源富文本編輯器吧！&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuejin.cn%2Fpost%2F7455243039655067657" target="_blank"&gt;✨TinyEditor v3.25.0 正式發佈！2025 年第一個版本，增加標題列表導航、分隔線等實用特性&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;聯繫我們&lt;/h2&gt; 
&lt;p&gt;GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-editor" target="_blank"&gt;https://github.com/opentiny/tiny-editor&lt;/a&gt;（歡迎 Star ⭐）&lt;/p&gt; 
&lt;p&gt;官網：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.github.io%2Ftiny-editor" target="_blank"&gt;https://opentiny.github.io/tiny-editor&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4863191/blog/18685142</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4863191/blog/18685142</guid>
      <pubDate>Wed, 16 Jul 2025 11:18:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>【國內首家】 Gitee Repo 通過信通院《可信製品管理能力分級要求》先進級（最高級）評估</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 22 日，由中國通信標準化協會主辦，中國信息通信研究院承辦的「2025 可信雲大會」在京召開。會上，中國信息通信研究院雲計算與大數據研究所副所長慄蔚通報了 2025 年上半年可信雲最新評估結果。&lt;/p&gt; 
&lt;p&gt;由開源中國·Gitee（北京奧思研工智能科技有限公司）研發的 Gitee Repo 製品管理系統成功通過《可信製品管理能力分級要求》標準，在製品管理能力域、併發性能域、安全能力域、架構能力域均&lt;span style="color:#2980b9"&gt;&lt;strong&gt;達到先進級（最高級）要求&lt;/strong&gt;&lt;/span&gt;，成為&lt;span style="color:#2980b9"&gt;&lt;strong&gt;國內首個且目前唯一通過該評估的製品庫產品&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/184531_AFQN_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這標誌着 Gitee Repo 製品管理系統&lt;span style="color:#2980b9"&gt;&lt;strong&gt;在製品管理各個能力項都已達到行業領先水平&lt;/strong&gt;&lt;/span&gt;，併為整個行業樹立了新的標杆。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/184542_pblf_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;信創生態下的企業級製品統一管理解決方案&lt;/h2&gt; 
&lt;p&gt;Gitee Repo 專為國內企業量身打造的強大製品管理系統，擁有完整自主知識產權，底層完全自主可信，適配多種國產芯片、操作系統、中間件、數據庫，具備多家信創互認證。&lt;/p&gt; 
&lt;p&gt;Gitee Repo 以製品為中心，率先支持鴻蒙 Harmony、Huggingface 模型和數據集，同時支持開發者常用的 20 多種開發語言包管理器，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;打破技術棧孤島，統一納管跨研發團隊開源依賴、軟件包、鏡像、應用配置文件，等二進制製品的高效存儲與管理需求&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;Gitee Repo 支持本地、遠程、虛擬、聯邦倉庫類型，並支持單向、雙向實時同步，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;有效提升分佈式研發協同的效率與可靠性，確保跨地域團隊獲取製品的及時準確性&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;同時，Gitee Repo 具備專業的依賴與構建成品安全分析能力，結合適配企業的自定義安全策略實現製品全生命週期安全管理，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;提升軟件供應鏈安全與合規性，彌補安全保障短板，深度保障企業軟件供應鏈安全&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;在上海某頭部銀行的實際部署中，Gitee Repo 在&lt;strong&gt;&lt;span style="color:#2980b9"&gt;單節點製品存儲超 7000 萬個、存儲超 500 TB、日均增量超 10 萬&lt;/span&gt;個&lt;/strong&gt;的情況下，實現了&lt;span style="color:#2980b9"&gt;&lt;strong&gt;資源節約 47.8%、製品庫綜合性能提升 226.35%、主流技術棧 100% 原生兼容&lt;/strong&gt;&lt;/span&gt;，穩定支撐涵蓋全集團多地域研發中心、軟件中心、生產數據中心及全國所有分支機構的製品分發與管理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/184610_NFXo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;可信製品庫能力域説明&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;製品管理能力域：製品全生命週期流轉&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;製品管理是製品庫產品的核心能力，在製品應用的各個階段 Gitee Repo 都可以提供&lt;span style="color:#2980b9"&gt;&lt;strong&gt;良好的產品化能力&lt;/strong&gt;&lt;/span&gt;。支持共計超過 20 種包類型，滿足大型統一依賴、統一構建、統一成品、統一存儲的集中管理訴求；支持本地、遠程、虛擬以及聯邦倉庫，滿足如異地多中心研發等場景下製品存儲以及快速、高效流轉訴求；支持插件化對接 CI/CD 上下游產品並標準化存儲流程數據保證製品生命週期數據的完整性；此外具備完善的自動化備份、監控、清理等運維能力保障平台產品穩定性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;併發性能域：高併發穩定支撐&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在併發性能域，Gitee Repo 展現出了強大的處理能力。面對大規模的併發請求，能夠穩定運行，確保製品的快速響應和高效傳輸。無論是小型創業團隊還是大型企業的分佈式開發項目，都能在 Gitee Repo 的支持下，實現順暢的協作和開發。其先進的緩存機制和分佈式架構，使得平台能夠輕鬆應對&lt;span style="color:#2980b9"&gt;&lt;strong&gt;高併發場景&lt;/strong&gt;&lt;/span&gt;，為企業的業務發展提供了堅實的保障。面對企業級大規模併發請求，Gitee Repo 可保持持續穩定運行，以毫秒級響應延遲快速處理製品請求，確保高效傳輸，其吞吐量指標穩居行業前列，為企業研發全流程的順暢推進築牢性能基石。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安全能力域：多層次製品安全防護&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;安全能力域是 Gitee Repo 製品管理系統的核心優勢之一。在當今數字化時代，數據安全和隱私保護至關重要。在安全能力域中主要為對製品的權限以及安全掃描能力的檢驗。Gitee Repo 支持平台管理與數據分離的權限管理模式，可根據企業內部各研發角色真實職能配置平台級角色並支持多種倉庫權限管理模式，既可以有效管理企業製品資產又可以有的放矢面向企業用户開放製品數據；在製品安全掃描能力上，Gitee Repo 具備商業級漏洞庫，掃描結果精準並提供有效的漏洞修復建議，結合漏洞、許可證、包版本多個安全策略，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;可形成對依賴-構建-分發各個場景下的製品安全管理&lt;/strong&gt;&lt;/span&gt;，提升企業製品安全管理能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;架構能力域：高可用架構異地容災&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Gitee Repo 適配多種國產芯片、操作系統、中間件、數據庫，具備多家信創互認證。支持多節點、多中心高可用，多中心架構可成主從或多主模式運行，雙中心可依靠單向同步或相互同步保證數據一致性，互為備份，每個中心的 DB 可採用 dump 定時冷備及存儲層 rsync 定時冷備到備份盤用於故障恢復，存儲層選擇使用 s3 的也可選擇雙 bucket 做備份，在單中心內 DB 或存儲發生故障時可用於切換及恢復，多中心情況下某地域故障也可進行故障轉移至其他中心，達到&lt;span style="color:#2980b9"&gt;&lt;strong&gt;多機房、多節點、多地域的多層容災架構&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;加速打造國產製品管理新標準&lt;/h2&gt; 
&lt;p&gt;Gitee Repo&lt;span style="color:#2980b9"&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;&lt;span style="color:#2980b9"&gt;以「打造國產化企業級唯一可信製品管理系統」&lt;/span&gt;為宗旨&lt;/strong&gt;，依託強大的產品能力和專業支持能力，已為銀行、證券、科技、製造、航空、芯片、雲計算、軍政、國企、央企、餐飲等多個行業客户提供了完善的製品管理解決方案。&lt;/p&gt; 
&lt;p&gt;&lt;img height="439" src="https://static.oschina.net/uploads/space/2025/0722/184627_nEKb_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;無論是處於數字化轉型起步階段的企業，還是已構建複雜信息化系統的大型集團，Gitee Repo 均可滿足多樣化製品管理需求，助力提升研發效能、降低綜合成本、強化安全保障。&lt;/p&gt; 
&lt;p&gt;面向未來，Gitee Repo 將持續加大研發投入，強化產品技術棧與服務體系建設，為企業和開發者提供更加專業、穩定的解決方案。同時我們也將攜手行業夥伴共建開放生態，推動製品管理技術標準化發展，共同構建健康、有序的行業環境。&lt;/p&gt; 
&lt;p&gt;歡迎訪問 Gitee Repo 官網&amp;nbsp;&lt;em&gt;&lt;u&gt;&lt;a href="https://gitee.com/repo" target="_blank"&gt;https://gitee.com/repo&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&amp;nbsp;瞭解更多產品信息。Gitee Repo 團隊將為您解答所有疑問，並安排專業的技術人員為您進行產品演示和部署指導。&lt;/p&gt; 
&lt;p&gt;我們期待與更多企業攜手，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;共同構建「存好製品、用好製品、管好製品」的全流程管理機制&lt;/strong&gt;&lt;/span&gt;，為國產軟件供應鏈的安全與高質量發展貢獻力量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/184638_JOxS_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361768</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361768</guid>
      <pubDate>Wed, 16 Jul 2025 10:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Netflix 首次引入生成式人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Netflix 宣佈&lt;span&gt;首次&lt;/span&gt;在其原創節目中使用生成式人工智能（GenAI）。在最近的一次財報電話會議上，Netflix 的共同首席執行官泰德・薩蘭多斯透露，生成式人工智能已在阿根廷劇集《永恆者》中應用，成功創造出一幕建築物倒塌的場景。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;薩蘭多斯表示，這一場景的製作效率是傳統視覺&lt;span&gt;特效&lt;/span&gt;工具的十倍，且成本大幅降低。他強調，人工智能不僅能讓電影和電視劇製作變得更加經濟，還能提升作品的質量。隨着 AI 工具的應用，創作者們能夠利用更先進的工具進行視覺化和鏡頭規劃，以達到更高的製作水準。過去，只有大預算的項目才能享受如此先進的視覺效果，比如角色的 「返老還童」 技術，而現在這一切都變得觸手可及。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="373" src="https://oscimg.oschina.net/oscnet/up-4eae5bfaa11038bacda0faabc016c7b1689.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;除了影視製作，Netflix 還在個性化推薦、搜索和廣告等領域積極使用生成式人工智能。公司計劃在 2025 年下半年推出互動廣告，並在今年早些時候推出了 AI 驅動的搜索功能。這些新技術的引入旨在進一步提升用户體驗，讓觀眾能夠更方便地找到他們喜歡的內容。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在第二季度，Netflix 報告營收達到了 110.8 億美元，同比增長 16%，利潤則達到 31.3 億美元。公司還透露，在 2025 年上半年，用户觀看了超過 950 億小時的內容，其中非英語節目佔到了總觀看時長的三分之一。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Netflix 此次引入生成式人工智能，標誌着其在影視製作及用户體驗方面的一次重要革新。這不僅為創作者們提供了更高效的工作方式，也讓觀眾在選擇內容時享受到了更多的個性化體驗。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361756</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361756</guid>
      <pubDate>Wed, 16 Jul 2025 10:18:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源醫療項目 OpenMed 發佈，包含超 380 個醫療 NER 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;研究員&amp;nbsp;Maziyar Panahi&amp;nbsp;在&amp;nbsp;Hugging Face&amp;nbsp;上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FOpenMed" target="_blank"&gt;發起了&amp;nbsp;OpenMed&amp;nbsp;項目&lt;/a&gt;，一次性開源了超過 380 個頂尖的醫療命名實體（NER）識別模型。&lt;/p&gt; 
&lt;p&gt;所有模型均在&amp;nbsp;Apache 2.0&amp;nbsp;許可下免費開放，旨在打破醫療 AI 領域長期存在的昂貴許可和「黑箱」工具壁壘。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dd569a71de230a658aa669f9983f097c747.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;該項目旨在解決醫療 AI 面臨的成本高昂、透明度低、技術更新緩慢和可及性有限等問題。這些 NER 模型能夠識別藥物、化學品、疾病、基因、解剖結構和癌症研究等多個領域的實體，可用於加速藥物研究、改進診斷工具、深化基因組學和腫瘤學研究。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e9312ad562e307f6987bc00309795e50d16.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361748</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361748</guid>
      <pubDate>Wed, 16 Jul 2025 09:52:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>科大訊飛發佈全球首款本地大模型辦公本 X5，售價 4999 元起</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;科大訊飛正式推出智能辦公本 X5，這款全球首款搭載本地大模型的辦公設備以 4999 元起的價格開啓市場。X5 採用 10.65 英寸 E Ink 墨水屏，擁有 300PPI 顯示精度，整機重量僅 355 克，厚度 4.6 毫米，成為全球最輕薄的同尺寸墨水屏設備。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;產品分為標準版與 Pro 版:標準版配備曜石灰皮套與灰色機身（6G+64G，4999 元），Pro 版提供水墨藍皮套+金色機身、經典黑皮套+灰色機身兩種組合 (6G+128G，5699 元)。核心配置方面，X5 搭載 8 核 MT8189CPU(6nm 製程) 與 9T 算力的 NPU，配合自研 GPU 快刷技術，使整機運行速度提升超 50%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="307" src="https://oscimg.oschina.net/oscnet/up-e1f565087e2204865ab483bd898d7af2aaf.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;該設備最大亮點在於將訊飛星火大模型完整部署至本地，實現五大離線 AI 功能:離線降噪、離線語音轉寫、離線分角色轉寫、離線中英互譯及離線會議紀要生成。其會議記錄能力尤為突出，八麥克風陣列支持 360 度全向收音，普通話識別準確率達 98%，可識別 200 種方言及 8 種外語互譯、9 種外語識別。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在交互設計上，X5 支持邊錄邊寫功能，錄音轉寫時可同步手寫，會後回顧支持回聽回看、即點即讀。安全防護方面，設備配備物理離線撥鍵與微孔指示燈，一鍵開啓後隔絕所有網絡連接;筆記保密箱功能將離線筆記加密存儲，需指紋或密碼解鎖;全鏈路安全體系覆蓋計算、存儲、訪問三大環節。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;配件方面，X5 配備 Wacom 定製第三代東雲筆，無需充電且握持舒適;搭載比亞迪定製 4500mAh 超薄高壓電池，續航能力顯著提升。這款集輕薄設計、本地化 AI 與隱私安全於一體的辦公設備，將為移動辦公場景提供全新解決方案。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361747</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361747</guid>
      <pubDate>Wed, 16 Jul 2025 09:50:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Windows 11 版 WhatsApp 又變成了「Web App」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowslatest.com%2F2025%2F07%2F21%2Fwhatsapp-for-windows-11-is-switching-back-to-chromium-web-wrapper-from-uwp-native%2F"&gt;確認&lt;/a&gt;，Windows 11 版 WhatsApp 將放棄基於 UWP（WinUI）的原生應用，轉而&lt;strong&gt;採用基於 Chromium 的 WebView2 容器（即 WebView2 打包模式）&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e6ca58b696b5123f19854429970b03c7b52.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這意味着 WhatsApp 將回到幾年前的 Web 應用體驗，其新版本更像是一個調用 Web 代碼（HTML、JavaScript、CSS）的桌面容器，由 WebView2 渲染，體驗與 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fweb.whatsapp.com" target="_blank"&gt;web.whatsapp.com&lt;/a&gt; 幾乎相同，但性能更慢、佔用更多內存（測試發現 WebView2 版本比原生應用多佔用約 30% 的內存）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-91cd1fe1063013cfe31e948d2876e380db9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Meta 選擇 WebView2 的原因在於其只需維護一個可在任何地方運行的代碼庫&lt;/strong&gt;，但此舉犧牲了原生應用的性能、可靠性和用户體驗（如更好的通知功能、通話和屏幕共享等）。&lt;/p&gt; 
&lt;p&gt;WhatsApp UWP 曾是 Windows 11 上最好的應用程序之一，現在卻被 web.whatsapp.com 和 WebView 取代。&lt;/p&gt; 
&lt;p&gt;包括現任亞馬遜員工的帕諾斯·帕奈 (Panos Panay) 在內的微軟高層領導也對 WhatsApp 的 WinUI 應用表示了讚賞。與大多數使用 WebView 實現某個功能的原生「現代」Windows 應用不同，Windows 11 版 WhatsApp 完全是原生的。&lt;/p&gt; 
&lt;p&gt;WhatsApp 的 Windows 版本功能與 Android 和 iOS 版本基本一致。幾乎所有功能都集成到了原生桌面應用中，而且也曾出現過少數 Windows 版本先於 Android 版本添加功能的罕見情況。&lt;/p&gt; 
&lt;p&gt;一切都結束了，我們又回到了原點。一個令人沮喪、資源匱乏、無聊的 Web 包裝器。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相關閲讀：&lt;a href="https://www.oschina.net/news/247246/whatsapp-desktop-electron-end-of-life" target="_blank"&gt;WhatsApp 棄用基於 Electron 框架構建的桌面應用程序&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361743</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361743</guid>
      <pubDate>Wed, 16 Jul 2025 09:35:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Gemini Deep Think AI 獲官方認證奧數金牌</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 DeepMind 團隊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeepmind.google%2Fdiscover%2Fblog%2Fadvanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad%2F"&gt;宣佈&lt;/a&gt;，其一個高級版本的 Gemini Deep Think 模型，在國際數學奧林匹克（IMO）競賽的問題上正式取得了金牌水平的成績。&lt;/p&gt; 
&lt;p&gt;該模型在六道題目中完美解決了五道，總共獲得 35 分（滿分 42 分），達到了金牌分數線。IMO 主席 Gregor Dolinar 教授證實了這一里程碑式的成就，並評價其解決方案 「在許多方面都令人驚歎」，認為其清晰、精確且大部分易於理解。&lt;/p&gt; 
&lt;p&gt;谷歌 CEO Sundar Pichai 表示，「僅僅一年時間，從銀牌到金牌——（其）數學推理方面的進步速度簡直令人驚歎！恭喜 Google DeepMind 團隊！」馬斯克轉發並表示：「恭喜！」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7eda41a43d0440a710199b61013e655f519.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0722/171753_GplX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次成果使用了 Gemini Deep Think 模式的高級版本，這是一種針對複雜問題的增強推理模式，融合了包括並行思考在內的最新研究技術，使模型能同時探索和組合多種可能的解決方案。為了最大化 Deep Think 的推理能力，團隊還利用新穎的強化學習技術對該版 Gemini 進行了訓練，使其能更好地利用多步推理、問題解決和定理證明數據。&lt;/p&gt; 
&lt;p&gt;此外，模型還被提供了高質量數學問題解決方案的精選語料庫，並在其指令中加入了一些關於如何解決 IMO 問題的一般性提示。谷歌 DeepMind 計劃先向包括數學家在內的一組可信測試者提供該 Deep Think 模型的版本，之後再向 Google AI Ultra 訂閲用户推出。&lt;/p&gt; 
&lt;p&gt;團隊表示，雖然目前在自然語言方法上取得了突破，但他們仍在繼續推進 AlphaGeometry 和 AlphaProof 等形式化系統。他們相信，將自然語言流暢性與形式化語言中的嚴謹、可驗證推理相結合的 Agent，將成為數學家、科學家和研究人員的寶貴工具。&lt;/p&gt; 
&lt;p&gt;此次成果由 Thang Luong 領導整體技術方向，並與 Edward Lockhart 共同協調 IMO 2025 項目。IMO 官方確認了提交答案的完整性和正確性，但其審查不涉及對系統、流程或底層模型的驗證。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361739</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361739</guid>
      <pubDate>Wed, 16 Jul 2025 09:20:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>ConvertX —— 在線文件轉換器</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一個自託管的在線文件轉換器。支持超過一千種不同的格式。使用 TypeScript、Bun 和 Elysia 編寫。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特性&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;將文件轉換為不同的格式&lt;/li&gt;
&lt;li&gt;一次處理多個文件&lt;/li&gt;
&lt;li&gt;密碼保護&lt;/li&gt;
&lt;li&gt;多個賬户&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="502" src="https://static.oschina.net/uploads/space/2025/0722/145835_fsMZ_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/convertx</link>
      <guid isPermaLink="false">https://www.oschina.net/p/convertx</guid>
      <pubDate>Wed, 16 Jul 2025 09:17:00 GMT</pubDate>
    </item>
    <item>
      <title>蘋果公開 AI 模型訓練策略：從大規模網絡抓取到秘密授權交易和合成內容</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，蘋果發佈了一份關於其基礎模型的詳細報告，名為&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmachinelearning.apple.com%2Fresearch%2Fapple-foundation-models-tech-report-2025" target="_blank"&gt;《Apple Intelligence 基礎語言模型 2025 年技術報告》&lt;/a&gt;&lt;/em&gt;，該報告深入介紹了最新人工智能模型的關鍵要素，幾乎涵蓋了所有內容，從模型架構到訓練階段、訓練後階段，以及如何對模型進行微調。報告還探討了用於確保模型技術改進的方法，以提高模型效率，同時避免隱私泄露。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/171217_etE6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;報告介紹了一款約 30 億參數的端側模型，該模型通過 KV 緩存共享和 2-bit 量化感知訓練等架構創新，針對蘋果芯片進行了優化。&lt;/p&gt; 
&lt;p&gt;另一款是基於新穎的「並行軌道混合專家」（Parallel-Track Mixture-of-Experts, PT-MoE）Transformer 架構的可擴展服務器模型，該模型在蘋果的私有云計算平台（Private Cloud Compute）上運行，結合了軌道並行、稀疏計算和交錯的全局-局部注意力機制。&lt;/p&gt; 
&lt;p&gt;兩款模型均在通過負責任的網絡爬取、授權語料庫和高質量合成數據構建的大規模多語言、多模態數據集上進行訓練，並利用一個新的異步平台進行監督微調和強化學習。&lt;/p&gt; 
&lt;p&gt;報告指出，在公開基準測試和人類評估中，這兩款模型都達到或超過了同等規模的開源基線模型。此外，蘋果還推出了一個以 Swift 為中心的全新基礎模型框架，支持引導式生成、約束性工具調用和 LoRA 適配器微調。&lt;/p&gt; 
&lt;p&gt;憑藉新模型，蘋果顯著提升了多語言能力。為了擴展語言支持，蘋果將訓練過程中非英語數據的比例從 8% 提升至 30%，涵蓋真實內容和 AI 生成的內容，從而提升模型的理解能力，並支持更廣泛的語言。這將使寫作工具等功能更好地發揮作用。&lt;/p&gt; 
&lt;p&gt;在訓練新的 AI 系統時，蘋果大量依賴其自主研發的網絡爬蟲 Applebot 收集的網絡數據，這些數據也已在之前的模型中使用。有趣的是，由於蘋果尊重隱私，如果網站不想被爬取，就不會使用其內容。&lt;/p&gt; 
&lt;p&gt;該公司使用多種技術來訓練其模型，主要使用公共網絡數據作為訓練材料。蘋果傾向於過濾不相關的內容，並專注於有用且切題的數據集。同樣，這家科技巨頭也依賴出版商的授權內容，儘管它確實透露了其所依賴的媒體公司的名稱。該公司還使用較小的模型來收集合成數據，尤其是在涉及圖像語言任務、代碼或指令執行時，以便更好地進行微調。&lt;/p&gt; 
&lt;p&gt;這種多方法也涉及視覺數據，因為這家巨頭擁有超過 100 億個圖像-字幕對，包括屏幕截圖和手寫筆記。它還使用自己的模型來生成更豐富的字幕。所有這些訓練方法都有助於 Apple 構建更智能、更強大的模型。Apple 訓練其 AI 模型的方法非常清晰。這是一種平衡的策略，既能確保系統保持強大和多功能性，又不會損害其核心價值：隱私。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361734</guid>
      <pubDate>Wed, 16 Jul 2025 09:14:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 官方網站從 Mozilla.org 遷移到 Firefox.com</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Firefox 官方網站和下載渠道發生了變化。&lt;/p&gt; 
&lt;p&gt;目前訪問 Firefox 官網可以看到，&lt;strong&gt;國際版 Firefox 的下載渠道已從 mozilla.org 遷移到 firefox.com&lt;/strong&gt;，而&lt;strong&gt;中國版 Firefox（由 Mozilla Online 運營）則使用 firefox.com.cn&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0722/170243_a5SO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;這意味着用户現在可以通過 &lt;strong&gt;https://www.firefox.com&lt;/strong&gt; 訪問國際版 Firefox 的官網，而國內用户則繼續通過 &lt;strong&gt;https://www.firefox.com.cn&lt;/strong&gt; 獲取本地化版本。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361727</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361727</guid>
      <pubDate>Wed, 16 Jul 2025 09:02:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>約 8% 的 Debian 源碼包基於 Rust 庫構建</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在上週於法國舉行的 DebConf25 Debian 開發者大會上，Fabian Grünbichler 談到了 Debian Linux 中的 Rust packaging 問題。並分享了一個有趣的統計數據，即 Rust 在 Debian 和整個開源生態系統中的應用正在不斷增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Fabian 指出，Debian Sid 中大約 8% 的源碼包至少基於一個 librust-* 包進行構建。Debian 源碼包中至少基於一個 Rust 庫包構建的比例約為 Debian 12「Bookworm」版本中該比例的兩倍。過去幾年中，Rust 的使用率顯著提升，而且隨着越來越多的開源項目引入不同程度的 Rust 集成，Rust 的使用率還在持續增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-da99b5ed734bd5396d9e7db996971c71104.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;librust-*-dev 中還有超過三千個源碼包提供 Rust 源代碼，Debian 上有 150 個源碼包提供編譯後的 Rust 二進制文件/庫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-5b2a4558936c93809d9d5e222304a6b0623.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，Fabian 還介紹了 Rust 工具鏈支持的 CPU 架構與 Debian Linux 支持的 CPU 架構之間的差異、與 GNU 工具鏈的差異以及其他一些幫助 Debian 開發人員打包 Rust 應用程序的細節。更多詳情可以查看 DebConf25 演示文稿中的&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsalsa.debian.org%2Fdebconf-team%2Fpublic%2Fshare%2Fdebconf25%2F-%2Fraw%2Fmain%2Fslides%2F113-rust-packaging-in-debian.pdf%3Fref_type%3Dheads%26inline%3Dfalse" target="_blank"&gt;PDF 幻燈片&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361720/rust-debian-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361720/rust-debian-2025</guid>
      <pubDate>Wed, 16 Jul 2025 08:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>​南洋理工與北大合作推出開源長記憶世界模型 WORLDMEM</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;南洋理工大學、北京大學王選計算機技術研究所與上海人工智能實驗室的研究人員近日聯合開源了名為 「WORLDMEM」 的長記憶世界模型。這一新模型旨在解決當前虛擬環境中長期一致性的問題，尤其是在視角變化或時間推移的情況下，仍能維持 3D 空間的連貫性，從而顯著提升用户體驗。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="440" src="https://oscimg.oschina.net/oscnet/up-a1da54d5a1f7e282a5c66ef05ad30f7de20.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;WORLDMEM 的核心在於其創新的記憶機制。該機制構建了一個包含多個記憶單元的存儲庫，每個單元儲存了與特定時間相關的場景信息和狀態數據。通過這一機制，模型能夠有效地從之前觀察到的場景中提取信息，並在視角或時間變化時重新構建出精確的場景。這種方式突破了傳統方法對短時間上下文窗口的限制，使得長期保留環境細節成為可能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在生成新場景時，WORLDMEM 的記憶機制能夠從龐大的記憶庫中快速檢索與當前場景最相關的信息。該過程涉及複雜的推理和匹配，以確保所提取的信息與當前的時間、視角和場景狀態相契合。比如，當虛擬角色在環境中移動後返回原位置時，模型會迅速找到先前的記憶幀，確保場景的連貫性和一致性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，WORLDMEM 具備動態更新的能力，隨着虛擬世界的發展，新的場景和信息會不斷被添加到記憶庫中。這一特性保證了模型對&lt;span&gt;最新&lt;/span&gt;環境狀態的準確記錄，從而提升了場景生成的質量。該模型採用了基於條件擴散變換器的架構，能夠整合外部動作信號，實現虛擬世界的&lt;span&gt;第一&lt;/span&gt;人稱視角生成，使得角色可以靈活地在虛擬環境中移動和互動。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;WORLDMEM 還使用了擴散強迫技術進行訓練，使得模型能夠在時間維度上進行長期模擬。這一訓練方式確保了場景生成的連貫性，並使模型能夠有效應對不同的動作指令和場景變化。通過將動作信號投影到嵌入空間，並結合去噪時間步嵌入，模型提升了對動作信號的響應能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361711</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361711</guid>
      <pubDate>Wed, 16 Jul 2025 08:19:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>TrackWeight：將 MacBook 觸控板秒變電子秤的開源軟件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;TrackWeight 是加拿大開發者 Krish Shah 近期發佈的一款開源 macOS 應用程序，可將配備 Force Touch 技術的 MacBook 觸控板（2015 年及以後發佈的 MacBook Pro 和 2016 年及以後發佈的 MacBook）變成電子秤，最大可稱量約 3.5 千克的物品。&lt;/p&gt; 
&lt;p&gt;該應用的源代碼已發佈在 GitHub 上，採用 MIT 開源許可證，允許開發者學習與二次開發 。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1642" src="https://static.oschina.net/uploads/space/2025/0722/155828_MARO_2720166.png" width="2488" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/KrishKrosh/TrackWeight&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;TrackWeight 利用 Open Multi-Touch Support 庫（由 Takuto Nakamura 開發）讀取觸控板上的多點觸控事件，獲取壓力、位置、角度等數據，通過 SwiftUI 構建界面、Combine 框架處理數據流，從而計算物體重量 。使用時需保持手指與觸控板接觸（電容感應原理），金屬物品可能因導電性導致誤讀，建議放置絕緣材料（如紙巾）後再稱重，且需確保物品完全置於觸控板感應區域內。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db922f3e77769746743e9a26df31dc0271c.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-984884cf3c2f8159eafa6c2550508ea02ea.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ee47e0a7120627b870637d534bc0b3fc4fc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開發者提醒，TrackWeight 僅適用於輕小物件稱重，不建議用於行李或人體稱重，以免損壞設備。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361703</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361703</guid>
      <pubDate>Wed, 16 Jul 2025 07:58:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>2024 年我國人工智能產業規模突破 7000 億元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;21 日，中國互聯網絡信息中心（CNNIC）在北京發佈第 56 次《中國互聯網絡發展狀況統計報告》（以下簡稱《報告》）。《報告》顯示，2024 年我國人工智能產業規模突破 7000 億元，連續多年保持 20% 以上的增長率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;《報告》還指出，今年上半年，我國生成式人工智能產品實現了從技術到應用的全方位進步，產品數量迅猛增長，應用場景持續擴大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一方面，我國在人工智能領域影響力顯著提升。根據《報告》，截至今年 3 月，共有 346 款生成式人工智能服務在國家互聯網信息辦公室完成備案。我國人工智能產品湧現引發全球關注，DeepSeek 上線不足 20 天全球日活躍用户就突破 3000 萬，登頂全球 140 個國家及地區的應用市場，成為全球用户增速最快的生成式人工智能應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，生成式人工智能技術不斷向具體應用場景縱深滲透。《報告》顯示，截至今年 6 月，用户利用生成式人工智能產品回答問題的比例最高，達 80.9%。國產人工智能產品不僅在千億級參數規模、多模態能力等方面實現突破，並與辦公協同、教育普惠、工業設計、內容創作等場景深度融合，構建了覆蓋多個領域的智能應用生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，隨着創新環境的不斷優化，我國在全球人工智能領域的話語權明顯增強。從專利數量上看，世界知識產權組織報告顯示，我國已成為全球人工智能專利最大擁有國，佔比達 60%。截至 2025 年 4 月，我國人工智能專利申請量達 157.6 萬件，佔全球申請量的 38.58%，位居全球首位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中國互聯網絡信息中心副主任張曉説，隨着我國人工智能領域的持續發展創新，一批優質的國產 AI 產品加速出海，擴大了我國 AI 產品在全球市場的影響力。未來我國要進一步提升在全球人工智能治理中的作用，積極參與並提出中國解決方案，致力推動建立公平、公正的全球 AI 治理規則。（經濟參考報&lt;strong style="color:#000000"&gt;&amp;nbsp;&lt;/strong&gt;記者，郭倩）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361702</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361702</guid>
      <pubDate>Wed, 16 Jul 2025 07:56:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節新視頻模型 Waver 1.0 在 Video Arena 排行榜位列第三</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;來自字節跳動（ByteDance）的神秘新視頻模型 Waver 1.0 已現身 Video Arena 排行榜，並在榜單上進入了第三名的位置。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-242dd11de888eb1d095d14c965d9adf0af7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a3ba8d4a4abe6c07a6970e52c0a5d3f129b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得關注的是，這款模型在文生視頻和圖生視頻榜單上都是排名第三。文生視頻僅次於字節之前發佈的 Seedance 1.0 和谷歌的 Veo3，圖生視頻僅次於 Seedance 1.0 和 MiniMax 的 Hailuo 02 模型。&lt;/p&gt; 
&lt;p&gt;字節上個月發佈了 Seedance 1.0。在評測中，Seedance1.0 在多個維度上超過了 Veo3。在與電影導演合作開發的 SeedVideoBench 基準測試中，該模型在遵循提示和動作真實感方面取得了更高的分數。在圖像到視頻的任務中，Seedance 保持了輸入幀的視覺一致性，而 Veo3 則在某些情況下出現了光照和紋理的變化。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3b8266677daa9731bb02990119d48c53102.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361698</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361698</guid>
      <pubDate>Wed, 16 Jul 2025 07:46:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>字節跳動發佈通用機器人模型 GR-3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;字節跳動 Seed 團隊正式推出全新 Vision-Language-Action Model（VLA）模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseed.bytedance.com%2FGR3" target="_blank"&gt;GR-3&lt;/a&gt;，該模型在機器人操作領域展現出突破性能力，不僅能理解包含抽象概念的語言指令，還可精準操作柔性物體，並具備快速遷移至新任務、認識新物體的泛化能力。這&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;傳統機器人操作模型往往依賴大量機器人軌跡數據進行訓練，導致遷移至新任務時成本高、效率低。GR-3 則通過少量人類數據即可實現高效微調，其核心突破在於採用 Mixture-of-Transformers（MoT）網絡結構，將視覺-語言模塊與動作生成模塊整合為 40 億參數的端到端模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;其中，動作生成模塊通過 Diffusion Transformer(DiT) 結合 Flow-Matching 技術生成動作，並引入歸一化的 RMSNorm 設計，顯著增強了動態指令跟隨能力。這一結構使 GR-3 能像人類一樣，直接根據攝像頭畫面與語言指令規劃連續動作，例如在聽到「收拾餐桌」後，自動完成「打包剩菜→收拾餐具→倒垃圾」的全流程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="430" src="https://oscimg.oschina.net/oscnet/up-f4198ccee9f147f0e301ffa02afb0827ecd.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;訓練數據層面，GR-3 突破了單一數據源的侷限，通過三合一數據訓練法實現能力躍升：其一，利用遙操作機器人收集的高質量真機數據，確保基礎操作能力；其二，通過用户授權的 VR 設備採集人類軌跡數據，使新任務學習效率提升近一倍（450 條/小時 vs 傳統 250 條/小時）；其三，融合公開可用的圖文數據，讓模型理解「大」「小」「左右」等抽象概念，並識別未見過物體的特徵。這種多樣性數據融合策略，使 GR-3 在未見過的物體抓取任務中成功率較基準模型提升 17.8%，僅需 10 條人類軌跡數據即可將新物體操作成功率從 60% 提升至 80% 以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;為驗證模型性能，團隊在通用拾取放置、長程餐桌清理、柔性衣物操作三大任務中展開系統性測試。在通用拾取放置任務中，GR-3 在訓練過的場景裏指令遵循率和成功率分別達 98.1% 和 96.3%，在新環境（卧室書桌、超市櫃枱等）中性能幾乎無衰減，且能精準處理「把雪碧旁邊的可樂放進盤子」等涉及空間關係的複雜指令。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;長程餐桌清理任務中，GR-3 可自主完成多步驟操作，平均完成度超 95%，並能嚴格跟隨分步指令，面對無效指令時準確判斷不動作。柔性衣物操作測試顯示，GR-3 在掛衣服任務中完成度達 86.7%，即使面對短袖等未見過的衣物款式或混亂擺放狀態，仍能穩定完成任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;與硬件的協同創新是 GR-3 的另一亮點。團隊研發的通用雙臂移動機器人 ByteMini 作為載體，配備 22 個全身自由度與獨特手腕球角設計，結合全身運動控制（WBC）系統，實現狹小空間內的精細操作與平滑軌跡生成。例如，抓取紙杯時能自動調整力度避免捏碎，機械臂可像人類手腕般靈活轉動。多攝像頭佈局 (2 個手腕攝像頭看細節、頭部攝像頭看全局) 則確保「眼觀六路」的感知能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;儘管 GR-3 在泛化性與操作精度上已超越業界此前可測試的 VLA 頭部模型π0，但團隊仍計劃通過擴大模型規模、增加訓練數據量（如更多物體的視覺語言數據、複雜任務機器人數據）進一步提升泛化能力。同時，引入強化學習 (RL) 方法突破模仿學習侷限，使機器人在遇到物體滑落等突發情況時能自主調整策略，增強抗幹擾能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;字節跳動 Seed 團隊表示，GR-3 的研發旨在解決傳統機器人「聽不懂抽象指令」「不適應環境變化」「做不好長程任務」的三大瓶頸。未來，團隊將持續探索大模型與機器人技術的深度融合，推動通用機器人「大腦」走進日常生活，成為幫助人類處理各類事務的智能助手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361697</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361697</guid>
      <pubDate>Wed, 16 Jul 2025 07:42:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>給 Javaer 看的大模型開發指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、概述&lt;/h1&gt; 
&lt;p&gt;伴隨着大模型的性能提升、成本下降，在 Web 在線對話場景以外，大模型也越來越多的被集成到傳統業務場景。&lt;/p&gt; 
&lt;p&gt;在大模型 API 交互模式、業務集成模式經百家爭鳴現已趨於穩定的背景下，Spring 作為 Java 生態裏的 OSS 巨頭也下場為 LLM 提供生態支持，於近期釋出 spring-ai 正式版。&lt;/p&gt; 
&lt;p&gt;需要説明的是，Spring-AI 所提供的能力並不神秘，業務上也並非必須用 Spring-AI 不可。但是，就像過去 Spring 對新的數據庫、新的中間件提供生態支持一樣，Spring-AI 提供了一套和 Spring 全家桶兼容並且語義一致、良好設計、易拓展的大模型交互的 Java API，可以極大的降低 LLM 集成和開發的成本。&lt;/p&gt; 
&lt;p&gt;從大模型的工程化、實用化角度來説，當你釐清 Spring-AI 這一套 API 設施的邏輯後，事情最後還是會迴歸到業務開發人最熟悉的 CRUD 領域。就像使用 Mybatis 操作 MySQL 一樣，我們會用 spring-ai 來操作大模型。&lt;/p&gt; 
&lt;p&gt;那我們開始今天的討論吧！&lt;/p&gt; 
&lt;h1&gt;二、什麼是大模型&lt;/h1&gt; 
&lt;p&gt;大模型的舞台上，從來不缺新面孔。自 ChatGPT 開啓 AI 新紀元後，各類大模型層出不窮。&lt;/p&gt; 
&lt;p&gt;但是我們不去考慮大模型的訓練原理、推理/運算架構、參數調優等較為複雜的數學範疇的東西，就像我們很少關心 MySQL 是怎麼用代碼來實現效果的一樣。&lt;/p&gt; 
&lt;p&gt;此處類比我們熟悉的知識，對大模型有一個盲人摸象式的基礎且能夠自洽的認識即可。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;從某種意義上來説，模型訓練就是通過分析海量文本（如維基百科、圖書、網頁等）尋找到人類語言的規律，再將這個規律固化成一個包含數十億【參數】的超級【數學公式】。就像簡單公式 y = 5x + 8 中的 5 和 8 ，這兩個【參數】決定了將輸入 X 如何轉化為輸出 Y。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;訓練好的【數學公式】就像代碼，需要部署在算力平台上，藉助【顯卡】的並行運算能力來實現高效運算。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用户的輸入作為這個【數學公式】的入參，經公式運算後，得到相關的【輸出】。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4f220f78af04d95180d8fa240fb782a41c6.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;假設大模型是上述的數學公式，不同的大模型「ChatGPT/DeepSeek」是不同的架構、不同的公式，那麼模型訓練就是通過對海量文本的分析、學習，找到合適的參數值。&lt;/p&gt; 
&lt;h1&gt;三、大模型的特點&lt;/h1&gt; 
&lt;p&gt;接下來我們關注在工程應用場景下，需要開發人關注的大模型特點。&lt;/p&gt; 
&lt;p&gt;就像 MySQL，我們集成時也需要關注不同的存儲引擎（InnoDB/MyISAM）的特點。&lt;/p&gt; 
&lt;h2&gt;無狀態&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-955439c305797e44d9a606d734224e79816.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大模型是沒有記憶、沒有狀態的，它是一個純函數。&lt;/p&gt; 
&lt;p&gt;它不知道之前跟你説過什麼。所以每次進行大模型輸入的時候，我們需要根據業務場景把之前的【輸入】，【反饋】一併給它，避免大模型失憶導致的對話不流暢。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3f4298c09ec0589241e82ec27594fd43bf5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;結構化輸出&lt;/h2&gt; 
&lt;p&gt;大模型是具備結構化輸出能力的，雖然有些模型支持的不夠好，但是沒關係，只是支持的程度不同，重要的是它們都支持！&lt;/p&gt; 
&lt;p&gt;所謂的結構化輸出是指，大模型除了可以返回口語化、沒有模式的自然語言文本外，還可以按你需求給你返回其他的文本格式，比如：JSON。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-38fa0d015043b414639659a356421e84b95.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;你看，這像不像在調一個 REST 接口？甚至是一個萬能接口，畢竟大模型什麼都會，不會的也可以現編。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b86a6416d0d66ba884b2112b071ac10b848.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;函數調用&lt;/h2&gt; 
&lt;p&gt;其實看到這裏我們就可以實現一個大模型驅動的 RPC 調用引擎了！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-70ed28496f315664f13fb79d858d84155a3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大模型幫你推理、規劃得到了需要執行的函數和對應的函數參數，至於這個【函數名】對應的到底是一個進程內的方法、HTTP 接口、Dubbo 接口還是 MCP 接口都沒有那麼重要，這只是智能體實現的一個技術細節而已。&lt;/p&gt; 
&lt;p&gt;我們可以用自然語言表述需求，同時告訴大模型有哪些輔助【工具/函數】可以供它備用。它會推理、編排這些工具來達成需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-05eafbfb705514d386afcc33aaa92a0b681.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;把用户輸入和可用函數輸入給大模型，大模型推理發現需要調用外部函數，於是返回函數名+函數調用參數。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能體捕獲輸出，對指定函數發起調用，再將用户輸入和函數結果一起輸入到大模型，大模型基於這些上下文推理輸出結果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;考慮到大模型發起函數調用的普遍需求，大模型供應商一般都在 API 層面提供了【function call】能力，用於將文本輸出和函數調用輸出區分開，明白了原理，我們知道這只是 API 抽象層次的問題。&lt;/p&gt; 
&lt;h1&gt;四、大模型接口&lt;/h1&gt; 
&lt;p&gt;考慮到大模型對硬件資源的特別需求（如顯卡），所以大模型一般是獨立部署，以 SaaS 模式提供能力。就像 MySQL 對資源有特別的需求（如大內存），所以一般也是進行獨立部署。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0318204255dc09fb74daf6d3701fb1a81d7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;訓練好的大模型就是一套二進制數據集，SaaS 化需要做外圍的服務化、產品化封裝，同一套模型可以在不同的算力平台部署，提供截然不同的服務化 API。&lt;/p&gt; 
&lt;h2&gt;模型封裝&lt;/h2&gt; 
&lt;p&gt;示例偽代碼如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4469b4e5ea9c89830f03852be3da2e7cdca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們可以簡單看下當下比較熱門的幾大供應商提供的 API 文檔：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;OpenAI-會話補全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.apifox.cn%2Fapi-67883981" target="_blank"&gt;https://openai.apifox.cn/api-67883981&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DeepSeek-會話補全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi-docs.deepseek.com%2Fzh-cn%2Fapi%2Fcreate-chat-completion" target="_blank"&gt;https://api-docs.deepseek.com/zh-cn/api/create-chat-completion&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;硅基流動-會話補全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.siliconflow.cn%2Fcn%2Fapi-reference%2Fchat-completions%2Fchat-completions" target="_blank"&gt;https://docs.siliconflow.cn/cn/api-reference/chat-completions/chat-completions&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ollama-會話補全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.runoob.com%2Follama%2Follama-api.html" target="_blank"&gt;https://www.runoob.com/ollama/ollama-api.html&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;硅基流動和 Ollama 都屬於大模型算力/治理平台。他們不研發大模型，只是大模型的搬運工。可以把大模型理解成微服務集羣，把硅基流動和 Ollama 理解成微服務構建/發佈平台即可。&lt;/p&gt; 
&lt;p&gt;大概瀏覽一下，會發現核心 API 都差不多，畢竟有 OpenAI 珠玉在前，許多系統都已對接了 OpenAI 的 API。後發的大模型為了兼容，降低接入難度，基本上也都和 OpenAI 的 API 大差不差。&lt;/p&gt; 
&lt;p&gt;就像是 MySQL，儘管數據庫產品類型百花齊放，但都兼容 SQL 語法。&lt;/p&gt; 
&lt;p&gt;我們在此只討論【會話補全】這一點，會發現會話補全接口的輸入/輸出大概都是以下情況：&lt;/p&gt; 
&lt;h2&gt;接口輸入&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;{
  "stream": false, // 是否是流式輸出 (要不要 SSE)
  "model": "deepseek-chat", //選用的哪個模型
  "messages": [ // 歷史對話消息，因為大模型無狀態，所以按場景提供一定數量的歷史消息
    {
      "content": "You are a helpful assistant",
      "role": "system"
    },
    {
      "content": "Hi", //消息內容
      "role": "user" //消息類型
    }
  ],
  "tools": null, //外部函數列表，【函數調用】能力在 API 層面的支持
  "frequency_penalty": 0,  //無關緊要的模型行為控制參數
  "presence_penalty": 0, //無關緊要的模型行為控制參數
  "temperature": 1, //無關緊要的模型行為控制參數
  "top_p": 1, //無關緊要的模型行為控制參數
  "logprobs": false, //無關緊要的模型行為控制參數
  "top_logprobs": null //無關緊要的模型行為控制參數
}


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;這裏以目標達成作為要點，內容中部分不理解的參數可以忽略。&lt;/p&gt; 
&lt;h2&gt;接口輸出&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;{
  "id": "&amp;lt;string&amp;gt;", //無關緊要
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "&amp;lt;string&amp;gt;", // 大模型生成的內容
        "reasoning_content": "&amp;lt;string&amp;gt;",
        "tool_calls": [  //需要發起的【函數調用】
          {
            "id": "&amp;lt;string&amp;gt;",
            "type": "function",
            "function": {
              "name": "&amp;lt;string&amp;gt;",
              "arguments": "&amp;lt;string&amp;gt;"
            }
          }
        ]
      },
      "finish_reason": "stop" //有點重要，但是我們先不管
    }
  ],
  "usage": {  //token 使用量，計數、計費
    "prompt_tokens": 123,
    "completion_tokens": 123,
    "total_tokens": 123
  },
  "created": 123,  //無關緊要
  "model": "&amp;lt;string&amp;gt;",  //無關緊要
  "object": "chat.completion"  //無關緊要
}


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;看到這裏時，你是不是已經開始躍躍欲試了？是不是感覺打造一個垂直領域的智能體沒有想象中那麼困難了~&lt;/p&gt; 
&lt;h1&gt;五、RAG 架構&lt;/h1&gt; 
&lt;p&gt;除非是圍繞特定業務場景結合私域數據訓練的專用大模型，否則涉及到一些企業內部的私域信息時，通用大模型也只能不懂裝懂的現編。&lt;/p&gt; 
&lt;p&gt;例如：當你詢問大模型【DJob 如何接入與使用】，除非訓練大模型時輸入了相關資料，不然大模型只能現編了。&lt;/p&gt; 
&lt;p&gt;考慮到專用大模型的成本，工程上解決這個問題的方法一般是通過外掛知識庫來實現：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;結合具體業務場景，將相關的文檔與資料提前錄入到【知識庫】中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用户提交一個【輸入】後，先使用，用户【輸入】作為搜索條件，去【知識庫】中搜索得到相關的【資料】。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;將用户【輸入】和【資料】一起提供給大模型。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;此【知識庫】組件的具體選型屬於實現細節，簡單的可以用 MySQL、Elasticsearch，如果想提升【知識庫搜索結果】的匹配度，也可以使用近期討論度很高的【向量數據庫】。&lt;/p&gt; 
&lt;p&gt;添加了 RAG 後，流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f168cdbf7307ba88cff25022007853c787.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;詳情可參考下文：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Ftardis%2Fzm%2Fart%2F675509396%3Fsource_id%3D1003" target="_blank"&gt;https://www.zhihu.com/tardis/zm/art/675509396?source_id=1003&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;六、MCP 協議&lt;/h1&gt; 
&lt;p&gt;可以看到，將大模型作為一個【函數調用】的規劃引擎，藉助它的推理與生成能力，可以實現複雜的業務流程。如果説大模型是【腦】，那提供給大模型規劃、使用的【函數】就是它的【手】和【腳】。有腦有手的大模型，可以迸發出巨大的業務潛力。&lt;/p&gt; 
&lt;p&gt;那如何打通大模型和傳統軟件系統（如存量微服務）呢？&lt;/p&gt; 
&lt;p&gt;我們關注的問題，開源社區也在積極的關注，這就是 MCP 協議誕生的背景和目的。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cdf7c58206c4240bbfa014790dbf64837a8.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MCP 協議介紹&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmcp-docs.cn%2Fintroduction" target="_blank"&gt;https://mcp-docs.cn/introduction&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在這裏我們不展開 MCP 協議的細節，僅作個人對 MCP 協議的思考，重點在於打破 MCP 協議的神秘感、破除 MCP 迷信。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;MCP 協議本身並非高精尖的內容，簡單來説，就是常用人羣約定系統間調用的流程、格式。若不考慮通用，誰都可以設計符合自己需求的、領域特定的交互協議。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP 協議的優勢在於，它出現的非常及時，且基本滿足了常規交互需求，因此快速在社區達成了共識。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不管是 MAP、MBP 還是 MCP，都沒有那麼重要，但是形成共識非常重要。協議達成了共識，開源社區才可以合力圍繞協議進行生態建設。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;七、Spring-AI&lt;/h1&gt; 
&lt;p&gt;到了這一步，我們開始探討 Java 代碼，首先我們需要熟悉下 spring-ai 的整套代碼架構，一步一步來，以整體到到細節的節奏進行討論。&lt;/p&gt; 
&lt;h2&gt;模型抽象&lt;/h2&gt; 
&lt;p&gt;核心的 API 實體是 Model ，是一個帶泛型的純函數，提供了對大模型能力的頂層抽象：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4c8eb6d3a3db0d348bcf6af4a83d96598cc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;org.springframework.ai.model.Model&lt;/p&gt; 
&lt;p&gt;大模型的能力本質就是：輸入一個 ( request )，返回一個輸出。&lt;/p&gt; 
&lt;p&gt;至於輸入/輸出的具體類型，由細分的子類限定：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-658963d4fd91da7af51a3c881b6b6c990d9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同模態的大模型支持不同類型的輸入/輸出，在此我們只討論 ChatModel 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ea60492d26588e3617111304802991e6d13.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;org.springframework.ai.chat.model.ChatModel&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8f2e639d274c64e73ac2fd7ab77dffc9b5e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;spring-ai 提供了不同平台、不同模型的 API 集成，開發者只需要提供接口地址、調用憑證即可開箱使用~&lt;/p&gt; 
&lt;h2&gt;聊天會話&lt;/h2&gt; 
&lt;p&gt;考慮到大模型對話是熱點場景， spring-ai 針對性的提供了會話接口抽象。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c0fc2c85cae2c4c057a742257fa412b0b65.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;org.springframework.ai.chat.client.ChatClient&lt;/p&gt; 
&lt;h2&gt;RAG 拓展&lt;/h2&gt; 
&lt;p&gt;類似 Spring-AOP， spring-ai 基於請求橫切提供了開箱即用的 RAG 能力抽象。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d652767109fde40d777cb798748fcd7d1f1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-144d4d0070da16c5c4549f3e22d38ef1aab.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;org.springframework.ai.rag.advisor.RetrievalAugmentationAdvisor&lt;/p&gt; 
&lt;h2&gt;代碼示例&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;基於供應商構建 ChatModel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-de37abd8f6a6b76596d69538ae2017b2e70.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;構建 ChatClient 發起會話&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-dc3cbb7de1b8b757423df6f47e3d6f6d8bf.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;八、智能體示例&lt;/h1&gt; 
&lt;p&gt;到這裏，我們已經自上而下的理解了大模型的工程化，現在我們來開發一個【DJob 智能助手】吧！&lt;/p&gt; 
&lt;h2&gt;接口骨架&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2c6fe1568279296cb61ca3c34155b04af4b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通過 POST 接口，響應 Content-Type 為 text/event-stream 。&lt;/p&gt; 
&lt;h2&gt;構造外部函數定義&lt;/h2&gt; 
&lt;p&gt;假設有以下幾個函數可以給大模型提供能力：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-712add346042b148c3b97b4bfbd1b3ea2a2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;將上述 3 個本地方法封裝成 ChatClient API 認識的【ToolCallback】：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-592d6518eba6c49212db74683c115d8ccf8.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;構建可用的，函數/工具，信息，這裏用本地方法來 mock。實際使用時可以利用 MCP/HTTP/gRPC/Dubbod 等實現跨系統調用。&lt;/p&gt; 
&lt;h2&gt;系統提示詞&lt;/h2&gt; 
&lt;p&gt;由於不能讓大模型自由發揮，因此需要在用户輸入的內容外，給大模型一些定向信息補充或場景限定，幫助大模型更好地解決問題！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2033f2904f431653de6b35214010265c3e1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;發起調用&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6296331333a464f694abe879362d5c31887.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;考慮到大模型無狀態，所以每次會話時歷史消息也需要一併輸入。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;歷史消息可以由前端收集、提交，也可以由後端每次會話存儲、收集。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;九、總結&lt;/h1&gt; 
&lt;p&gt;綜上所述，太陽底下沒有新鮮事，工程領域所有的新生事物都可以暫時把它當做 MySQL，沒有人比 Java 工程師更懂 MySQL 了（開玩笑）。&lt;/p&gt; 
&lt;p&gt;以上，除 Java 代碼外，都是經過盲人摸象的方法探索出的內容。如有錯誤，歡迎指正。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顧&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.一致性框架：供應鏈分佈式事務問題解決方案｜得物技術&lt;/p&gt; 
&lt;p&gt;2.Redis 是單線程模型？｜得物技術&lt;/p&gt; 
&lt;p&gt;3.得物社區活動：組件化的演進與實踐&lt;/p&gt; 
&lt;p&gt;4.從 CPU 冒煙到絲滑體驗：算法 SRE 性能優化實戰全揭秘｜得物技術&lt;/p&gt; 
&lt;p&gt;5.CSS 闖關指南：從手寫地獄到「類」積木之旅｜得物技術&lt;/p&gt; 
&lt;p&gt;文 / 羊羽&lt;/p&gt; 
&lt;p&gt;關注得物技術，每週更新技術乾貨&lt;/p&gt; 
&lt;p&gt;要是覺得文章對你有幫助的話，歡迎評論轉發點贊～&lt;/p&gt; 
&lt;p&gt;未經得物技術許可嚴禁轉載，否則依法追究法律責任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18638450</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18638450</guid>
      <pubDate>Wed, 16 Jul 2025 07:13:00 GMT</pubDate>
      <author>原創</author>
    </item>
  </channel>
</rss>
