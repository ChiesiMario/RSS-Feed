<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 繁體中文（香港）</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已對該 RSS 進行格式化操作：中英字符之間插入空格、使用直角引號、標點符號修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-hk</language>
    <lastBuildDate>Thu, 14 Aug 2025 03:00:09 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>馬斯克 xAI 公司聯合創始人 Igor Babuschkin 離職</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;xAI 聯合創始人 Igor Babuschkin &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fibab%2Fstatus%2F1955741698690322585" target="_blank"&gt;宣佈&lt;/a&gt;&lt;/u&gt;離職，他在社交媒體發佈了一封感人至深的告別信，回顧了他在 xAI 的非凡歷程，並宣佈將創立 Babuschkin Ventures，專注於 AI 安全研究和支持推動人類進步的 AI 初創公司。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/104112_IXxb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&amp;nbsp;&lt;/span&gt;&lt;span&gt;回憶了與馬斯克的初次會面，兩人就 AI 和未來進行了數小時的深入交流，共同認識到世界需要一傢俱有不同使命的新 AI 公司。&lt;/span&gt;他還提到了 xAI 如何在短短時間內完成了看似不可能的任務——在 120 天內建成 Memphis 超級集羣，以及團隊如何以「瘋狂的速度」推出前沿模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;馬斯克很快回復了這條推文：感謝你幫助建立 @xAI！沒有你就沒有我們的今天。&lt;/p&gt; 
 &lt;p&gt;Igor Babuschkin(@ibab) 回應馬斯克：謝謝你，Elon！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="962" src="https://static.oschina.net/uploads/space/2025/0814/104723_AJtI_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&lt;/span&gt;&amp;nbsp;是 AI 領域的資深研究員，曾在多家頂級 AI 實驗室擔任要職。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;他在德國多特蒙德工業大學（TU Dortmund）學習物理學（2010-2015），期間作為夏季研究生參與了 CERN 大型強子對撞機的 LHCb 實驗研究。&lt;/li&gt; 
 &lt;li&gt;2017 年他轉向機器學習和人工智能領域，加入 DeepMind，擔任高級研究工程師，參與開發了能夠達到《星際爭霸 II》大師級水平的 AlphaStar AI。&lt;/li&gt; 
 &lt;li&gt;2020 年 11 月，他加入 OpenAI，專注於生成模型和代碼生成，參與了 AlphaCode 和大型語言模型的研究。&lt;/li&gt; 
 &lt;li&gt;2022 年他短暫回到 DeepMind 擔任高級研究工程師，專注於擴展 AI 系統並改進推理和生成能力。&lt;/li&gt; 
 &lt;li&gt;2023 年 5 月，Igor 與馬斯克共同創立了 xAI，專注於構建可擴展和可解釋的 AI 系統。他在 Nature 等頂級期刊發表了多篇重要論文，在強化學習、模仿學習和大規模訓練等領域推動了 AI 的進步。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366115</guid>
      <pubDate>Thu, 14 Aug 2025 02:44:24 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 告別獨立時代，Gitee 12 年堅守開啓 AI 新程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;深圳北科大廈，幾位外國客人，專注地盯着屏幕上 Gitee 的實操演示，不時還向一旁的中國工程師詢問功能細節，轉眼一小時過去——這一幕發生在 2018 年 10 月開源中國的深圳辦公室，來訪者正是 GitHub 的前兩任 CEO ：Nat Friedman 與 Thomas Dohmke 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;而如今，這兩位熟人走了，開源中國仍在，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;開啓 AI 新程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 兩任 CEO 的東方足跡&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2018 年 10 月，在中國開源年會 COSCon'18 的活動現場，開源中國 COO 徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（現任開源中國 CEO ）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一次見到了 Nat Friedman 。「衣着隨意，一看就是程序員」，是徐勇對這位 GitHub 掌門人的第一印象。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可能是身處一個圈子的好感，徐勇與 Nat Friedman 在第二天討論中國開源生態的閉門會上，聊得格外投機。當 Nat Friedman 得知開源中國也有一款類似 GitHub 的軟件後，頓時來了興趣，當即便和徐勇約定了第二天&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源中國拜訪，於是就出現了開頭的一幕。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那是 2018 年的一個涼爽的上午，一高一矮兩個老外走進了開源中國辦公室。徐勇回憶，上午十點，Nat Friedman 一行就來了。寒暄一陣之後，徐勇作為東道主，向 Nat Friedman 一行講解起了當時的 Gitee 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「 Nat 大高個兒嘛，看屏幕就比較費勁，全程都是勾着腰。但看得出，他對 Gitee 很感興趣，特別是一些功能上的創新——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;或者説，是中國的開發者市場。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彼時，開源歷史上的一個&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;里程碑事件引發全球矚目：GitHub 被微軟以 75 億美元全資收購。GitHub 作為全球最知名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;且&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中立的開源協作平台，被科技巨頭收購之後該何去何從？Nat Friedman 被任命為 CEO 未來又有何動作？外界眾説紛紜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但我們可以知道的是，Nat Friedman 官宣上任後的第一件事，並沒有出現在 GitHub 的辦公室，反而是來到了中國，特別是出現在了開源中國的辦公室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一起觀摩 Gitee 的演示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拜訪的最後，Nat Friedman 團隊其中一人向徐勇遞出了名片，直白地問：「如果我們出錢收購，開源中國賣不賣？」 此人，正是當時 GitHub 的 CTO，也就是後來的第二任 CEO 的 Thomas Dohmke。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對此，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;內心堅定，但周全考慮&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;並沒有明確&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拒絕&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。而在這次深圳會面不久，微軟全球 CEO Satya Nadella 來華，又特地安排了與開源中國馬越&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（現開源中國董事長）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的會面，依舊提及收購事宜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;面對行業巨頭拋來的橄欖枝，開源中國始終堅定選擇&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;獨立發展。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇後來回憶道：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「雖然 2018 年，開源中國也處於業務轉型的陣痛期，在資本市場四處化緣，但將&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本土&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯一的代碼託管平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;拱手讓人&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，中國未來的開源生態又談何自強呢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gitee 得堅持走自己的路，中國特色的路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;正如 Gitee 一開始就定下的基調：致敬 GitHub ，但絕不照搬，始終聚焦「開發者為本」，走出一條貼閤中國開發者需求的特色之路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2 個人，7 年，「他們都離開了」，我們&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依然前行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 11 日，一則消息震動全球開發者社區：GitHub CEO Thomas Dohmke 宣佈辭職，而 GitHub 將結束獨立運營，整體併入微軟 CoreAI 部門，且微軟不再為其尋找新 CEO。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thomas Dohmke 在內部郵件中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提及&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：如今 GitHub 已有超過 10 億個代碼庫與分支，開發者數量突破 1.5 億，以及 Copilot 持續引領蓬勃發展的 AI 市場，擁有 2000 萬用户&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;並&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不斷增長......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-f5820ca29b80620e4822a8dee4106dad2fb.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如此成績的背後，是微軟與 GitHub 以開放的方式續寫開源生態的共生故事：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;開源開放上，微軟開源 WSL （ Windows Subsystem for Linux ），打破了 Windows 與 Linux 長期以來的生態壁壘，成為連接千萬開發者的技術橋樑；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 產品功能上，開放地收購了 NPM 等工具廠商，使得 Actions 能力變強。GitHub Actions 於微軟時期推出，甚至免費私有倉庫也是在微軟時期才開始提供；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;數據開放，GitHub 上的公開數據，成為開發者打磨工具、挖掘趨勢、創造新方案的 「原始素材庫」。而在大模型時代，無數聚焦代碼生成、漏洞檢測、自動化開發的大模型與工具，正是以 GitHub 的公開數據為訓練基底;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;對開發者生態來説，「開放」是微軟收購 GitHub 之後的一個極為重要的關鍵詞，並且以這樣的開放實現了眾多創舉，其中就有 Copilot 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2021 年，隨着生成式 AI 的崛起，微軟與 OpenAI 合作推出 GitHub Copilot ，正式開啓 AI 編程時代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如今，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Copilot &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;已&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從代碼補全工具，發展成擁有 Copilot Chat&amp;amp;Voice 的對話式編程助手，再到能審查與修復代碼、用 GitHub Spark 構建全棧應用的多模態智能體系統，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-438ee8757571e7fbed84b401bb5e002b19f.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但，亂世何妨缺英豪？儘管 GitHub Copilot 算是第一個在 AI 編程領域顛覆大家認知的產品，但過去這一年多，微軟一定也意識到：在這波 AI 編程浪潮下，旗下的 GitHub 並沒有發揮出其應有的影響力，而 Copilot 則更多地是在給旁人做嫁衣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;正如開源中國 CTO 紅薯評價：「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不僅是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 還包括 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VSC&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ode 。Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 的價值體現在其不止有 1.5 億用户和 10 億倉庫上，還有巨大的流量和用户慣性。但很明顯，很多人已經不買 Copilot 的賬了，説得更誇張一點就是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 在 AI 編程時代&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;從&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一開始的首發到現在暫時落後。微軟希望改變現在的這個局面，其核心思路不再&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub+AI&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;，而是 All In AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;結合微軟與 GitHub 目前遇到的危機，曾經的「開放」，也&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;步入「&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;縮緊&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;」。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;相較於 GitHub 在巨頭體系下的戰略調整，Gitee 的發展路徑始終聚焦 「開發者為本」。沒有大廠的資金狂投，卻憑藉 「草根」 式的堅韌，築牢了中國開源創新的基礎設施；沒有急於追逐全球擴張，卻深耕本土土壤，讓每一個功能都貼閤中國開發者的工作場景。這種紮根本土的堅守，讓 Gitee 在開源浪潮中站穩了腳跟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;開源中國 12 年堅守，開啓 AI 新程&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;看到卸任的新聞，回顧 Nat Friedman 、 Thomas Dohmke 與開源中國 2018 年的這段緣分，不禁令人唏噓。7 年時間，他們已經離開&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;這一變動讓不少人感慨開源平台的命運流轉，而在中國，另一個名字卻始終穩健前行 —— Gitee 正以紮根本土的堅守與創新，書寫着屬於中國開源的獨特篇章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;如今的 Gitee ，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;依託對中國開發者協作習慣的深刻理解，已進化為一站式軟件工程平台，支撐起 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;1350w+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;開發者&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;36w+ 企業、2000+ 高校&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的高效協作&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;從代碼託管到項目管理，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;再到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;DevOps 工具鏈，Gitee 的每一&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;次&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;迭代&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;升級&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;都緊扣本土開發者的真實需求 —— &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;讓每一行代碼，都有改變世界的力量&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-b9db8504e1b37af3a2ff6a04ccded8680c4.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當下，AI 浪潮席捲全球，軟件開發正迎來智能化變革。面對這一時代呼喚，開源中國以「與時俱進」的姿態開啓 AI 新程，推出&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面向開發者、終端用户與產業場景的 AI 應用共創平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟（ ai.gitee.com ）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟以全棧技術能力降低 AI 應用門檻，構建三大核心體系：技術基座通過多模態模型庫、國產化算力優化和智能調度實現 「模型即服務」，配合低代碼工具鏈加速開發；服務體系覆蓋全鏈路商業化支持，提供安全合規的存儲認證系統與企業級私有部署方案，推動金融、工業等垂直領域快速落地；開放生態通過 AI 審核分級、開發者收益傾斜和算力補貼機制，形成 "開發 - 反饋 - 迭代" 的創新閉環。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-9cc384e0174003faaf96509e8c548aa12fe.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#7f7f7f"&gt;100 層高樓已完成 90 層，模力方舟建立在 OSChina 與 Gitee 之上&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;12 載的堅守，有心酸、亦光榮！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在中國這片開源生態的土地上，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其實並沒有如微軟這樣的頂級大廠，於資金上的猛烈加持，更多是如 Gitee 、模力方舟這樣的「草根」搭台，一步一個腳印，深耕本土土壤，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;肩負起了中國軟件工程基礎設施建設的重任，築牢了中國開源創新的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;過去十二年，Gitee 以學習為起點，在開源路上步步紮實；未來，Gitee 將以模力方舟為支點，在 AI 工程的新賽道上持續創新。從軟件工程平台到 AI 工程平台，變的是技術形態，不變的是 「全心全意為開發者服務」 的初心。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在開源與 AI 交織的新遠徵中，Gitee 將繼續紮根本土、擁抱世界，以自主創新的中國特色之路，為全球開發者貢獻屬於中國的開源力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4806939/blog/18688139</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4806939/blog/18688139</guid>
      <pubDate>Thu, 14 Aug 2025 02:42:24 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>智元發佈行業首個機器人世界模型開源平台 Genie Envisioner</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;智元機器人&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvIORutIHio41I0_RdSvxFQ" target="_blank"&gt;宣佈&lt;/a&gt;推出面向真實世界機器人操控的統一世界模型平台 --- Genie Envisioner（GE）。 不同於傳統「數據—訓練—評估」割裂的流水線模式，GE 將未來幀預測、策略學習與仿真評估首次整合進以視頻生成為核心的閉環架構，使機器人在同一世界模型中完成從「看」到「想」再到「動」的端到端推理與執行。、&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;當前機器人學習系統普遍採用分階段開發模式——數據收集、模型訓練、策略評估，每個環節相互獨立，並需要專門的基礎設施和任務特定調優。這種碎片化架構增加了開發複雜度，延長了迭代週期，限制了系統的可擴展性。GE 平台通過構建統一的視頻生成世界模型，將這些分散的環節集成到一個閉環系統中。基於約 3000 小時的真實機器人操控視頻數據，GE 建立了從語言指令到視覺空間的直接映射，保留了機器人與環境交互的完整時空信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="359" src="https://oscimg.oschina.net/oscnet/up-9e779b08554174964903820746608b89226.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;GE 的核心突破在於構建了基於世界模型的以視覺中心的建模範式。不同於主流 VLA（Vision-Language-Action）方法依賴視覺-語言模型將視覺輸入映射到語言空間進行間接建模，GE 直接在視覺空間中建模機器人與環境的交互動態。這種方法完整保留了操控過程中的空間結構和時序演化信息，實現了對機器人-環境動態更精確、更直接的建模。這一視覺中心的建模範式帶來了兩個關鍵優勢：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;高效的跨本體泛化能力&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;基於強大的視覺空間預訓練，GE-Act 僅需極少量數據即可實現跨平台遷移。在 Agilex Cobot Magic 和 Dual Franka 等全新機器人平台上，GE-Act 僅使用 1 小時（約 250 個演示）的遙操作數據就實現了高質量的任務執行。相比之下，即使是在多本體數據上有大規模預訓練的π0 和 GR00T 模型，在相同數據量下的表現也不如 GE-Act。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;這種高效泛化源於 GE-Base 在視覺空間中學習到的通用操控表徵。通過直接建模視覺動態而非依賴語言抽象，模型能夠捕捉到跨平台共享的底層物理規律和操控模式，從而實現快速適配。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="340" src="https://oscimg.oschina.net/oscnet/up-682debad2a8cc04919c242725f76a1431ca.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;長時序任務的精確執行能力&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，視覺中心建模賦予了 GE 強大的未來時空預測能力。通過在視覺空間中顯式建模時序演化，GE-Act 能夠規劃和執行需要長時序推理的複雜任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在摺疊紙盒等超長步驟任務中，GE-Act 展現出了遠超現有 SOTA 方法的性能。以紙盒摺疊為例，這項任務需要精確執行超過 10 個連續子步驟，每個步驟都依賴於前序動作的準確完成。GE-Act 達到了 76% 的成功率，而專門針對柔性物體操控優化的π0 僅為 48%，UniVLA 和 GR00T 則完全無法完成（0% 成功率）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;這種長時序執行能力的提升不僅源於 GE 的視覺世界建模，同時也得益於我們創新設計的 sparse memory 模塊。通過這樣的模塊設計，能夠幫助機器人選擇性地保留關鍵歷史信息，從而在長時序任務中保持精確的上下文理解。通過預測未來的視覺狀態，GE-Act 能夠"預見"動作的長期後果，從而生成更連貫、更穩定的操控序列。相比之下，基於語言空間的方法在長時序任務中容易出現誤差累積和語義漂移。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="267" src="https://oscimg.oschina.net/oscnet/up-f5f50fbfcf620d524eb4680b8cf07bfccbf.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;基於視覺中心建模理念，GE 平台包含三個緊密集成的組件：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Base：多視角視頻世界基礎模型&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Base 是整個平台的核心基礎，採用自迴歸視頻生成框架，將輸出分割為離散的視頻塊（video chunks），每塊包含 N 幀。模型的關鍵創新在於其多視角生成能力和稀疏記憶機制。通過同時處理來自頭部相機和雙臂腕部相機的三路視角輸入，GE-Base 能夠保持空間一致性並捕捉完整的操控場景。稀疏記憶機制通過隨機採樣歷史幀來增強長時序推理能力，使模型能夠在保持時序連貫性的同時處理長達數分鐘的操控任務。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="174" src="https://oscimg.oschina.net/oscnet/up-0475a4c1c079e38953216e3ab0870bf0c5a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;訓練採用兩階段策略：首先在 3-30Hz 的多分辨率採樣下進行時序適應訓練（GE-Base-MR），使模型對不同運動速度具有魯棒性；隨後在 5Hz 固定採樣率下進行策略對齊微調（GE-Base-LF），與下游動作建模的時序抽象保持一致。整個訓練基於 AgiBot-World-Beta 數據集的約 3000 小時、超 100 萬條真機數據，使用 32 塊 A100 GPU 訓練約 10 天完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="164" src="https://oscimg.oschina.net/oscnet/up-0a9acef7c1d6dc6644be9e9ed33a6e0ff61.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Act：平行流匹配動作模型&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Act 作為即插即用的動作模塊，通過 160M 參數的輕量級架構將 GE-Base 的視覺潛在表徵轉換為可執行的機器人控制指令。其設計巧妙地與 GE-Base 的視覺主幹平行設計，採用與 GE-Base 相同網絡深度的 DiT 塊但使用更小的隱層維度以提高效率。通過交叉注意力機制，動作路徑能夠充分利用視覺特徵中的語義信息，確保生成的動作與任務指令保持一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="146" src="https://oscimg.oschina.net/oscnet/up-7eb9b05e82c8e0b32b33f216f17720e3c7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Act 的訓練分為三個階段：動作預訓練階段將視覺表徵投射到動作策略空間；任務特定視頻適應階段更新視覺生成組件以適應特定任務；面向特定任務的動作微調完整模型以捕捉細粒度控制動態。特別值得注意的是其異步推理模式：視頻 DiT 以 5Hz 運行進行單步去噪，而動作模型以 30Hz 運行進行 5 步去噪，這種"慢-快"雙層優化使得系統能在機載 RTX 4090 GPU 上以 200 毫秒完成 54 步動作推理，實現實時控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="232" src="https://oscimg.oschina.net/oscnet/up-d51e33e5353faa835a677b8bbe5490561a1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Sim：層次化動作條件仿真器&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Sim 將 GE-Base 的生成能力擴展為動作條件的神經仿真器，通過層次化動作條件機制實現精確的視覺預測。該機制包含兩個關鍵組件：Pose2Image 條件將 7 維末端執行器姿態（位置、姿態、夾爪狀態）投影到圖像空間，通過相機標定生成空間對齊的姿態圖像；運動向量計算連續姿態間的運動增量，編碼為運動令牌並通過交叉注意力注入到每個 DiT 塊中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-7083a0ea94bed7448611a5ca8747b5d4081.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;這種設計使 GE-Sim 能夠精確地將低層控制指令轉換為視覺預測，支持閉環策略評估。在實際應用中，策略模型生成的動作軌跡被 GE-Sim 轉換為未來的視覺狀態，這些生成的視頻再反饋給策略模型產生下一步動作，形成完整的仿真閉環。通過分佈式集羣並行化，GE-Sim 可實現每小時數千次的策略 rollout 評估，為大規模策略優化提供了高效的評估平台。更重要的是，GE-Sim 還能作為數據引擎，通過在不同初始視覺環境下執行相同動作軌跡來生成多樣化的訓練數據。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="139" src="https://oscimg.oschina.net/oscnet/up-115cb9730ef9b5af303d525fc92e0c6761e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;此外，為了評估面向具身任務的世界模型質量，團隊在 GE 核心組件之外開發了 EWMBench 評測套件。它從場景一致性、軌跡精度、運動動力學一致性，到語義對齊，全方位打分。多名專家的主觀評級與 GE-Bench 排名高度一致，驗證了其對機器人任務相關性評測的可靠性。在與 Kling、Hailuo、OpenSora 等先進模型的對比中，GE-Base 在多項體現視覺建模質量的關鍵指標上均取得最優成績，且與人類判斷高度一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="159" src="https://oscimg.oschina.net/oscnet/up-40f011244762f77df3ea098b6ff45463753.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366112</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366112</guid>
      <pubDate>Thu, 14 Aug 2025 02:22:24 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Apache RocketMQ EventBridge：為什麼 GenAI 需要 EDA？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;沈林，Apache RocketMQ PMC 成員，阿里雲 EventBridge 負責人，專注於 EDA 研究。本文整理自作者在 Community Over Code Asia 2025 會議發表的主題演講《Apache RocketMQ EventBridge: Why Your GenAI Needs EDA？》。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;EDA 的核心特點是：以事件為中心，實時響應變化。它不像傳統"請求-響應"模式那樣被動等待，而是"感知→觸發→行動"全自動流轉。在 AI 系統中，數據流、模型訓練和推理、外部反饋等都可以作為"事件"，觸發 AI 自動決策和聯動執行。EDA 就像是 AI 時代的"神經系統"，讓 AI 不僅能"思考"，還能"感知"和"行動"。它提升了系統的實時性、靈活性和自動化水平，是構建智能系統的關鍵支撐。AI 賦予系統"大腦"，EDA 構建系統的"神經"。&lt;/p&gt; 
&lt;p&gt;本文主要探討在 AI 時代，EDA 的重要價值及它可以幫助我們解決的問題。&lt;/p&gt; 
&lt;h2&gt;EDA 的第一重價值：通過 RAG 緩解 AI 幻覺&lt;/h2&gt; 
&lt;p&gt;大家可能還有印象，2023 年上半年，Google 的早期 AI 模型發佈時，回答一個關於詹姆斯·韋伯空間望遠鏡的問題時，犯了一個低級"錯誤"，這個答案本來在 Google 上很容易搜索到，但是 AI"一本正經"的給了一個錯誤答案，直接導致谷歌當天的股價跌了 8% 左右。但 AI 完全沒有意識到自己的錯誤，這是為什麼？&lt;/p&gt; 
&lt;h3&gt;1. 為什麼會有 AI 幻覺？&lt;/h3&gt; 
&lt;p&gt;AI 幻覺的產生機制比較複雜，可簡單從訓練和推理兩個階段進行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;訓練階段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;數據覆蓋不足&lt;/strong&gt;：若訓練數據不包含特定信息，模型無法"無師自通"；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;過擬合&lt;/strong&gt;：模型過度學習訓練數據中的細節與噪聲，導致在面對新數據時泛化能力差；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;通用性與精度取捨&lt;/strong&gt;：通用大模型為覆蓋廣泛領域，在特定垂直領域的準確性可能有所犧牲。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;推理階段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;自迴歸生成&lt;/strong&gt;：LLM（大語言模型）推理本質上是一個自迴歸過程，基於現有 Token 預測下一個最可能的 Token，這種概率性生成機制使得幻覺成為其固有潛在分佈的一部分。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;連貫性優先於準確性&lt;/strong&gt;：GenAI 輸出的時候傾向於生成流暢連貫的答案，而非絕對準確的答案。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 如何減少 AI 幻覺？&lt;/h3&gt; 
&lt;p&gt;為瞭解決 AI 幻覺，現在一般有三種主流的方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型微調（Fine-tuning）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;模型不好？最能直接想到的方法就是優化模型：豐富模型訓練的數據、優化模型的參數，讓其在垂直場景領域，回答更加精準。這種方式在很多場景是非常有效的，而且依舊被廣泛採用。但是這種方式，要求也是比較高的，如果沒有一定的人力和算力成本投入，將很難實現。尤其是在知識更新頻繁的領域，模型需要不斷調整，長期維護，投入代價相對較高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示詞工程（Prompt Engineering）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以不調整模型，而是在向 LLM 提問的時候，把相關的數據和限定條件一起給到 LLM？答案是可以的，這就是提示詞工程。&lt;/p&gt; &lt;p&gt;但是如何構造一個好的提示詞，把 LLM 需要的上下文信息給到它，這個要求也是非常高的。不同人使用，提示詞的構造水平也不同：這種方式就像是把"問問題"變成了一件"手工藝術活"。而且提示詞優化雖然可以"壓平"部分幻覺，但只要模型權重未變，提示詞沒有帶上相關數據，提示詞只能暫時把幻覺"藏"起來，而無法真正去除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;檢索增強生成（RAG）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以自動幫我們生成一個高質量的提示詞呢？在這個提示詞中，包含了 LLM 回答需要的關鍵信息。這個就和我們最後一個要講的 RAG 非常像了，讓我們看下 RAG 到底是什麼。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 什麼是 RAG？&lt;/h3&gt; 
&lt;p&gt;RAG 可以簡單理解為：向 LLM 提問的時候，同時給這個問題，檢索一個上下文，一起給到 LLM。比如：如果我們問 DeepSeek：本次 Apache 峯會有哪些講師聊到了 RAG 這個話題？DeepSeek 肯定不知道，因為它沒有這個數據，網上暫時也還沒有相關數據。但如果給到它一個關於本次大會講師的講稿資料包。這樣 DeepSeek 就有非常強相關的上下文，回答問題的時候，就不會跑題答偏。&lt;/p&gt; 
&lt;p&gt;那 AI 要如何做到這一點呢？主要分兩步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;建立索引&lt;/strong&gt;：首先，需要提前把講師資料包存起來。但資料包可能非常大，我們需要快速找到跟提問的問題相關聯的數據，這裏就需要用到向量化。向量化本質上是對一個事物，從多個特徵維度，進行數值標記。比如，標記我這個人，可以從年齡、身高、性別等多個特徵標記，標記越多越清晰。如果兩個向量在多維空間中的"位置"越接近，説明它們越相似。所以，我們需要提前把數據進行向量化，存到向量數據庫裏。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;檢索生成&lt;/strong&gt;：然後，當我們向 LLM 提問時，可以先把問題向量化，根據向量化後的結果，去向量數據庫查詢關聯性最大的原始知識數據。最後，將查到的知識數據，作為上下文和問題一起傳給 LLM，LLM 就可以給一個更加準確的回答了。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-045b51500f01c2a85c12e955b7cd13f02bc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;從這個過程中，我們會發現 RAG 有兩個非常明顯的優點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;不需要用知識庫數據給大模型訓練，既節省了成本，又保證了數據隱私；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不需要用提示詞工程這樣的"手工藝術活"，就可以讓 AI 出現幻覺的概率變得足夠低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 為什麼 EventBridge 適合做 RAG？&lt;/h3&gt; 
&lt;p&gt;為什麼是 EventBridge 適合來做 RAG 呢？ 我們先來看下什麼是 EventBridge：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;EventBridge 的整個模型其實非常簡潔：我們從下圖左側開始往右看，EventBridge 可以方便的把外部的數據，以標準化的事件格式，配合事件 Schema 集成到內部，中間可以存入事件總線（BUS），也可以選擇不存儲，然後通過過濾/轉換，推送到下游服務中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;這個鏈路，正好可以滿足 RAG 過程中需要的三要素：獲取上游豐富的數據、自定義切分和向量化、持久化到多種向量化數據庫中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73b0f09489921a9380a6cf55b6026f0ffb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;5. EventBridge 如何實現 RAG？&lt;/h3&gt; 
&lt;p&gt;用一個場景舉例，比如我們想建一個關於 EventBridge 知識的智能問答機器人，可以回答關於 EventBridge 的常見問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;我們需要把存在上游 OSS 的 EventBridge 文檔，通過 EventBridge 的事件流，進行 Chunk 切分、Embedding 向量化，然後存儲到向量數據庫；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成之後，當我們向 EventBridge 智能機器人提問"EventBridge 是什麼？"，智能機器人會先把這個問題向量化，然後去向量數據庫查找匹配度最高的相關內容，並一起傳遞給 LLM，LLM 就能結合查到的資料，給出非常精準的回答，減少幻覺產生。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-00e0291ba9dc0a5f24c08e141e6d17ebb3d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，阿里雲大模型服務平台百鍊的知識庫 RAG 場景，已採用 EventBridge 的事件流能力，幫助眾多客户減少了 LLM 問答中的幻覺問題，尤其在細分垂直領域效果顯著。如果您感興趣可以進行體驗：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbailian.console.aliyun.com%2F%3F%26tab%3Dapp%23%2Fknowledge-base" target="_blank"&gt;https://bailian.console.aliyun.com/?&amp;amp;tab=app#/knowledge-base&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;EDA 的第二重價值：推理觸發器（Inference Trigger）&lt;/h2&gt; 
&lt;p&gt;我們第二個想討論的場景是推理觸發器。&lt;/p&gt; 
&lt;h3&gt;1. 程序使用 LLM 的規模將遠超人類&lt;/h3&gt; 
&lt;p&gt;目前，我們日常接觸最多的 LLM 場景是人與 LLM 服務直接對話，如問 DeepSeek 一個問題或智能客服等。 但更常見且增長迅速的方式是程序觸發 LLM。例如供應鏈優化和金融訂單風控。&lt;/p&gt; 
&lt;p&gt;觀察微服務就會發現，人調用 API 的量級遠不如程序調用 API 的量級。相應地，我們可以想象，未來程序觸發 LLM 的規模，也將遠遠超過人工使用 LLM。&lt;/p&gt; 
&lt;p&gt;這其中的機會，我們應該怎麼把握？&lt;/p&gt; 
&lt;h3&gt;2. 推理訴求無處不在&lt;/h3&gt; 
&lt;p&gt;事實上，我們現有的商業系統中，已經存儲了大量現成需要推理的場景。比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;消息服務裏，存儲了客户的評論，需要對其打標分析，這條評論是積極的還是消極的，並給個分數；&lt;/li&gt; 
 &lt;li&gt;DB 裏存儲了產品的描述介紹信息，想讓 AI 給一些產品描述優化建議；&lt;/li&gt; 
 &lt;li&gt;OSS 或 S3 存儲了大量的文檔，想讓 AI 對每個文檔生成一個 100 字的文檔摘要。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這些訴求在以前可能需要人工處理，但現在都可以交給 LLM，從而極大提升工作效率。那怎麼讓現有的商業系統，方便、快捷、低成本的使用 AI，甚至不需要寫一行代碼，這個就是 EventBridge 擅長的地方了。&lt;/p&gt; 
&lt;h3&gt;3. 推理觸發器：讓模型被更好地使用&lt;/h3&gt; 
&lt;p&gt;為此，EventBridge 提供了三把武器：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f27bd8eda56c7eb4b1fe2a5c832ff70bbb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第一把武器------實時推理並將結果存到目標端：&lt;/strong&gt; 通過 EventBridge 可以實時監聽並獲取存在 DB、消息、或者存儲服務中的數據，然後實時調用 LLM 推理服務，並將推理結果輸出存到目標端。此過程也可以結合上一部分講到的 RAG，但中間不一定是一個 LLM，也可以是一個 Agent，甚至是一個 AI Workflow。&lt;/p&gt; &lt;p&gt;這個過程看似簡單，但有很多需要注意的地方：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;數據合併&lt;/strong&gt;：我們剛才聊到，LLM 的推理本質上是一個自迴歸過程，這次的輸出會作為下一次的輸入，無法一次性拿到結果，很多 LLM 只能支持以流式的方式返回數據，但下游往往需要的是一個確定性的結果，所以我們需要對流式數據進行合併再輸出；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;數據格式&lt;/strong&gt;：很多業務場景下有明確的格式要求。比如上面提到的例子，讓 LLM 對客户評論打標和評分，需要輸出一個 JSON 結構。但不是所有 LLM 在 API 層面都支持 JSON 結構輸出，我們需要通過提示詞進行優化，讓它儘可能輸出一個符合要求的 JSON 結構。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;推理吞吐&lt;/strong&gt;：LLM 的自迴歸生成方式，導致單次請求 RT 長、TPS 低。所以，我們需要提升高併發能力，把昂貴的 GPU 資源使用效率發揮到極致，同時需要做好 TPM 和 RPM 的限流，也就是每分鐘請求次數和每分鐘 Token 數的限流，以保證鏈路不會有大量限流異常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以看到，具體落地會遇到很多挑戰，但 EventBridge 可以幫助客户便捷高效地解決這些問題。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第二把武器------基於推理結果觸發任務執行：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;除了讓 LLM 推理輸出結果存到目標端，EventBridge 還可以讓 Agent 基於上游的某條消息，去調用某一個 Service，執行某一個動作，如發送郵件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第三把武器------離線異步推理提高資源利用率：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;對於實時性要求不高的推理場景，可以通過 EventBridge 實現離線異步推理，讓稀缺的 GPU 資源被更好地調度利用，在雲上的成本至少比實時推理便宜一半。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 的強大在於其應用，而 EDA（事件驅動架構）非常適合作為推理觸發器，激活 AI 的價值。&lt;/p&gt; 
&lt;h2&gt;EDA 的第三重價值：構建 Agent 通信基礎設施&lt;/h2&gt; 
&lt;p&gt;現在 AI Infra 非常熱門，其概念非常廣泛。對標 IT Infrastructure，我們這裏討論的話題是 AI 的通信。&lt;/p&gt; 
&lt;h3&gt;1. 微服務的通信離不開 Messaging，Agent 間的通信應該如何？&lt;/h3&gt; 
&lt;p&gt;在微服務時代，消息系統在微服務間的通信中扮演了重要角色。到了 AI 時代，消息系統是否依然起着關鍵作用？具體形式和產品又會有哪些變化？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c0ae2c687b84e25b6cf9a437040abeb17d4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;2. Agent 和 Service 的通信：Function Calling、MCP&lt;/h3&gt; 
&lt;p&gt;為了回答這個問題，我們先看下現在 AI 的通信是怎麼做的。&lt;/p&gt; 
&lt;p&gt;首先，我們看下 Agent 和傳統 Service 之間的通信。目前有兩種主流的方式：Function Calling 和 MCP。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Function Calling：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 OpenAI 公司在 2023 年提出的。因為 LLM 本身是文本生成器, 不具備訪問外部系統的能力。但是我們可以對 LLM 進行訓練微調，讓 LLM 理解外部的一些工具函數的定義，這樣在遇到提問時，就可以按需生成這些工具函數需要的參數，然後調用這些工具函數。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 2024 年 11 月 Anthropic 提出的，全稱 Model Context Protocol‌，其本意是用來解決 LLM 無狀態的問題。LLM 每次調用都是獨立的，而 MCP 是用來給 LLM 提供運行上下文，相當於一個"Session 機制"。但是為什麼 MCP 會被拿來和 Function Calling 放在一起呢？因為它也可以拿來調用工具函數。和 Function Calling 不同的是，它不需要 LLM 提前訓練微調來理解函數的入參和返回值，而是通過上下文"提示詞"告訴 LLM 參數返回值。所以 MCP 相比 Function Calling，對模型的依賴更小，更加通用，但效果相比 Function Calling 要差一點。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Agent 和 Agent 的通信：A2A&lt;/h3&gt; 
&lt;p&gt;我們再來看下 Agent 與 Agent 之間是怎麼通信的。&lt;/p&gt; 
&lt;p&gt;Google 在今年 4 月份的時候，提出了一個 A2A 的通訊協議，其核心運行機制分為四步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：Client Agent 通過 Agent Card，看下遠端 Agent 有哪些能力；&lt;/li&gt; 
 &lt;li&gt;第二步：根據 Agent Card 的能力描述，調用遠端 Agent，創建一個 Task，讓其幫忙完成一個任務；&lt;/li&gt; 
 &lt;li&gt;第三步：由於任務可能比較耗時，不一定能夠立即響應。所以 A2A 協議允許遠端 Agent 通過 SSE 協議，不間斷的將任務的狀態信息更新給 Client Agent；&lt;/li&gt; 
 &lt;li&gt;第四步：再將結果返回給 Client Agent，當然結果本身也是可以流式返回的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e2e33909d1e1fa5c7fb16b3509dba8dfa21.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;4. MCP 和 A2A 之間的區別&lt;/h3&gt; 
&lt;p&gt;那 MCP 和 A2A 協議有什麼區別呢？Google 給它們的關係做了一個描述：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;A2A 協議像一種溝通語言：&lt;/strong&gt; 如果把 Agent 比做人，一個人如果能力有限，想讓其他 Agent 幫忙怎麼辦？A2A 協議就可以派上用場了，A2A 協議像一種溝通語言，可以讓 Agent 和其他 Agent 用同一種語言交流，不至於説話的時候驢唇不對馬嘴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP 就像工具使用説明書：&lt;/strong&gt; Service 等價於人使用工具，可以提升人解決問題的能力。不過，使用工具也需要有些技巧，MCP 就像工具使用説明書，可以讓 Agent 更方便的使用這些 Service，來擴展 Agent 的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-538598e9588c1dda1dac99334b8b440c970.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我們把 Agent 比做人，把 Service 比做工具。但是，請人幫忙和請工具幫忙，真的可以分得這麼清楚嗎？&lt;/p&gt; 
&lt;h3&gt;5. 預測 1：A2A and MCP 可能走向融合&lt;/h3&gt; 
&lt;p&gt;A2A 和 MCP 的職責，設想很完美，但是實際運行的時候會遇到很多挑戰。我們先來一起看看在 MCP 和 A2A 協議下，兩者用來聲明一個 Agent 或者 Service 能力的時候是怎麼樣的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;這裏舉例了一個"查詢北京天氣"的服務，會發現兩者聲明自己能力的時候，非常類似：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c08367f12deb092a1cccd326b2b3ae2d53a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其次，兩者的傳輸層協議也都非常相似，都支持 SSE 和 JSON-GRPC；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最後，我們從工程師開發角度，推演一個場景：當一個 Agent 需要獲取"查詢天氣"的能力時，它並不真正關心該能力是由一個 Service 還是另一個 Agent 提供的。Agent 的核心關注點在於能力的接口定義：即有哪些可用能力、如何調用，以及預期的返回結果是什麼。至於該能力的後端提供者是 Service 還是 Agent，對於調用方而言是無需關注的實現細節。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這裏我們的第一個預測是：A2A and MCP 未來可能會合並，但具體怎麼發展，還要看生態的選擇。&lt;/p&gt; 
&lt;h3&gt;6. 預測 2: 點對點的通信是不夠的&lt;/h3&gt; 
&lt;p&gt;這裏的第二個預測是：現有 MCP 和 A2A 協議中，只包含的點對點通信是不夠的。按照 A2A 協議的推演，當一個系統中有很多 Agent 時，所有 Agent 都通過"長連接"集成在一起：大家第一個直觀的感受是什麼？&lt;/p&gt; 
&lt;p&gt;連接太多了！ 如果兩個 Agent 通過"長連接"集成在一起，感覺可能也沒有什麼。但是如果一個 Agent 同時需要和數百個甚至上千個 Agent 通信，系統中就會產生大量的長連接。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先對每一個 Agent 來講，資源開銷就非常大；&lt;/li&gt; 
 &lt;li&gt;其次，網狀的連接，一旦某一個 Agent 出現問題，hang 住了某些資源，會不會拖垮其他 Agent 的服務？甚至拖垮整個系統？這類問題在微服務中，再常見不過了。&lt;/li&gt; 
 &lt;li&gt;最後，即使不會被出問題的 Agent 拖垮服務，但當這個出問題的 Agent 恢復時，之前的通訊是否依舊可以繼續追蹤？再次執行，是否已經冪等，是否有風險？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這裏面有非常多的穩定、性能、成本、擴展性的挑戰。這些問題在微服務中已經被多次驗證過，有些經驗我們可以學習過來。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-acaff61d3cd696e4c06caae076daf62ceb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;7. EventBridge Super Agent&lt;/h3&gt; 
&lt;p&gt;基於上面兩個預測判斷，我們給出了一個 RocketMQ EventBridge 的回答: 在這個模型中，我們引入了一個 EventBridge Agent Proxy 的角色。我們姑且稱它為"Super"Agent ，但它不是一個真正的 Agent，而是可以代理 Agent 的能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，所有 Agent 都可以寫一份自己的個人簡歷，把自己擁有的能力，註冊到"Super"Agent 上；&lt;/li&gt; 
 &lt;li&gt;如果某個 Agent 需要調用其他 Agent 的能力，它可以在 "Super" Agent 中查找是否有其需要的 Agent。如果有，就可以直接通過與 "Super" Agent 的交互，來獲得這個能力；&lt;/li&gt; 
 &lt;li&gt;當這個 Agent 需要多個其他 Agent 的能力時，也不需要和每一個 Agent 交互，都可以通過 "Super" Agent 代理實現，將原本的 N:N 模型簡化為 1:1 模型。&lt;/li&gt; 
 &lt;li&gt;除此之外，"Super" Agent 中的 Proxy 除了 A2A 協議，還會路由和跟蹤每一個 Task 的運行狀態，即使在異常/重啓/集羣擴容等場景下，每一個 Task 都能被按預期處理，並把狀態同步回 Agent。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;"Super"Agent 和微服務註冊中心有點類似，不過區別在於，它不光是提供了微服務查找尋址的作用，同時還起到了服務代理的作用。如果我們腦洞再大一點，可以不僅侷限於 Task 級別的任務追蹤和管理，甚至還可以往上考慮一層，提供"User"級別的上下文：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我們現在的 Agent 都是沒有記憶的，我們之前跟它説過的話，過幾天再問它，它就不記得你了。&lt;/li&gt; 
 &lt;li&gt;但是每個人使用工具的習慣是不一樣的。如果 Agent 能更好的理解你，記得你，就可以提供更加人性化的服務。&lt;/li&gt; 
 &lt;li&gt;作為 Agent 註冊和代理中心，如果在為 Agent 提供代理的同時，還能同時提供"User"的上下文，並且用 Agent 的越多，"User"的身份畫像越完善；反過來，Agent 越依賴，進入一個正向循環。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e0b899ea6d8383b99a2a6d186d58bca361a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，EventBridge Agent 代理還處於理論探索階段，歡迎大家一起交流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;參考文獻與延伸閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Lewis et al., 2020]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Model Context Protocol (MCP) Specification, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[A2A: Agent-to-Agent Communication Protocol, Google, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apache RocketMQ EventBridge 官方文檔：&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocketmq.apache.org%2F" target="_blank"&gt;https://rocketmq.apache.org/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;2025 杭州·雲棲大會，來了！&lt;/p&gt; 
&lt;p&gt;9 月 24 日至 26 日，杭州·雲棲小鎮&lt;/p&gt; 
&lt;p&gt;三場重磅主論壇&lt;/p&gt; 
&lt;p&gt;超 110 場聚合話題專場&lt;/p&gt; 
&lt;p&gt;40000 平方米智能科技展區&lt;/p&gt; 
&lt;p&gt;點擊&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyunqi.aliyun.com%2F2025%2Fticket%3FactivityId%3DNTQ1Ng%3D%3D%26ticketId%3DMTMy%26channelId%3DMzM0NA%3D%3D" target="_blank"&gt;此處&lt;/a&gt;免費註冊領取雲棲大會門票&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18688052</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18688052</guid>
      <pubDate>Thu, 14 Aug 2025 02:12:24 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>聯想第一財季營收 1362 億元，AI PC 市場份額領先全球</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;聯想集團公佈了截至 2025 年 6 月 30 日的第一財季業績報告，顯示出該公司在多個業務領域的強勁增長。報告顯示，聯想本季度實現營收 1362 億元人民幣，同比增長 22%，創下歷史同期新高。此外，淨利潤也同比增長 22%，達到 28.16 億元人民幣，展現出企業盈利能力的顯著增強。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="528" src="https://oscimg.oschina.net/oscnet/up-eeef33bdab809d7d5055d90415773e9216c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在具體業務表現方面，智能設備業務集團 （IDG） 營收為 973 億元人民幣，同比增長 17.8%。這一業務的運營利潤率為 7.1%。在 PC 業務上，聯想表現尤為突出，同比增長 19%，成為 15 個季度以來的最快增速。值得一提的是，聯想在全球 PC 市場的份額達到了 24.6%，同樣創下歷史新高。同時，AI PC 的出貨量超過整體 PC 出貨量的 30%，在 Windows AI PC 市場中穩居第一。此外，在中國市場，具備五大 AI 特性的 AI PC 佔到了筆記本總出貨量的 27%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在智能手機業務方面，聯想的營收為 162 億元人民幣，同比增長 14%。海外市場的表現也相當強勁，摺疊屏手機的市場份額達到 51%，保持行業領先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基礎設施方案業務集團 （ISG） 的表現同樣亮眼，營收達到 310 億元人民幣，同比增長 35.8%。其中，AI 基礎設施業務的營收同比增長高達 155%，液冷技術方案收入也實現了 30% 的增長，顯示出該領域的良好發展潛力。特別是在中國市場，ISG 的營收同比增長達 76%，運營利潤率提升了 3 個百分點。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;聯想表示，當前 「超級智能」 正成為全球科技企業的新風口，這與其早前提出的 「混合式 AI」 戰略相一致。聯想在創新方面持續加碼，本季度研發費用同比增長超過 10%，為未來的競爭力奠定了基礎。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366100</guid>
      <pubDate>Thu, 14 Aug 2025 02:07:24 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Warm-Flow 1.8.0 重大更新</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;h1&gt;🚀 Warm-Flow 迎來重大突破，自研仿釘釘設計器震撼發佈！&lt;/h1&gt; 
&lt;p&gt;親愛的開發者朋友們，我們很高興地宣佈 Warm-Flow 工作流引擎迎來了 1.8.0 版本的重大更新！這次更新不僅帶來了全新的功能特性，更在用户體驗上實現了質的飛躍。&lt;/p&gt; 
&lt;h2&gt;🔥 核心亮點&lt;/h2&gt; 
&lt;h3&gt;自主研發仿釘釘設計器&lt;/h3&gt; 
&lt;p&gt;Warm-Flow 現在同時支持&lt;strong&gt;經典模式&lt;/strong&gt;和&lt;strong&gt;仿釘釘模式&lt;/strong&gt;雙設計器！我們基於 logic-flow 自主研發了仿釘釘設計器，避免了維護兩套代碼的複雜性，實現了更好的統一性和可維護性。&lt;/p&gt; 
&lt;h3&gt;智能交互體驗升級&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;跳轉線自動識別：當您繪製回退線條時，系統會自動識別並設置為退回跳轉類型&lt;/li&gt; 
 &lt;li&gt;節點自由拖動：經典模式下節點和連線文字支持自由拖動調整&lt;/li&gt; 
 &lt;li&gt;智能編輯控制：設計器現在根據流程發佈狀態自動判斷是否可編輯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;功能增強與優化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增&lt;span style="color:#e74c3c"&gt;&lt;strong&gt;getFirstBetweenNode&lt;/strong&gt;&lt;/span&gt;接口，快速獲取第一個中間節點&lt;/li&gt; 
 &lt;li&gt;流程圖渲染支持頂部名稱顯示/隱藏控制&lt;/li&gt; 
 &lt;li&gt;中間節點新增用户圖標，界面更加友好&lt;/li&gt; 
 &lt;li&gt;優化代碼格式和註釋，提升開發體驗&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📊 可視化展示&lt;/h2&gt; 
&lt;p&gt;新版流程設計器界面更加美觀直觀：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="新版流程圖" src="https://oscimg.oschina.net/oscnet//46766d71052a25ab76b7d79977217d8f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img alt="新版流程圖" src="https://oscimg.oschina.net/oscnet//cfec2f0265cb8499c40e5a308c9e2d84.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;🌟 為什麼選擇 Warm-Flow？&lt;/h2&gt; 
&lt;p&gt;作為國產工作流引擎，Warm-Flow 具有以下優勢：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;簡潔輕量&lt;/strong&gt; - 五臟俱全，靈活擴展性強&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;雙模式支持&lt;/strong&gt; - 原生支持經典和仿釘釘雙模式&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;快速集成&lt;/strong&gt; - 可通過 jar 包快速集成設計器&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;廣泛兼容&lt;/strong&gt; - 支持多種 ORM 框架和數據庫&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🎯 功能全景&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="功能思維導圖" src="https://oscimg.oschina.net/oscnet//4b82123be783b0346de0e06f295de26a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 快速體驗&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;演示地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.hhzai.top" target="_blank"&gt;http://www.hhzai.top&lt;/a&gt; &lt;strong&gt;賬號密碼&lt;/strong&gt;：admin/admin123&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;官方網站&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwarm-flow.dromara.org" target="_blank"&gt;https://warm-flow.dromara.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;想要深入瞭解？觀看我們的視頻教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1AWRGYEEVr%2F" target="_blank"&gt;從零精通: 全流程開發與源碼解讀&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;立即升級到 Warm-Flow 1.8.0，體驗全新的工作流設計之旅！&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366088/warm-flow-1-8-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366088/warm-flow-1-8-0</guid>
      <pubDate>Wed, 13 Aug 2025 01:04:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>wlnmp 一鍵安裝包更新 250813</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;wlnmp 一鍵安裝包 250813 更新內容如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;（更新）php8.1.33、php8.2.29、php8.3.23、php8.3.24、php8.4.10、php8.4.11、MySQL8.0.43、MySQL8.4.6&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;關於 wlnmp&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;從&lt;u&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;2019&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/u&gt;年初開始維護 wlnmp 一鍵安裝包這個項目，起初只是為了在日常運維過程中，可以快速的部署 lnmp 服務。wlnmp 已支持國產龍蜥 AnolisOS、OpenCloudOS、歐拉 OpenEuler 系統等。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;wlnmp 一鍵安裝包基於上游開源軟件二次開發，可以在 x86_64、aarch64 架構的 Linux 系統上通過 wlnmp 提供的鏡像源，快速部署 Nginx/Mysql/PHP 等常用軟件，支持 php、MySQL 多個版本在同一系統中並存。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;PS：&lt;/strong&gt;wlnmp 就是一個第三方的源，通過二次開發封裝，將一些常用的軟件彙總到一起，方便用户使用安裝為目的，從 2019 年至今，已開發持續更新了&amp;nbsp;&lt;strong&gt;7263&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;個 rpm 包，目前服務器的資源流量全部由 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hsy.com%2F" target="_blank"&gt;火數雲&lt;/a&gt;」 贊助支持。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;PPS：&lt;/strong&gt;如果你有積極向上的開源軟件，想要收錄至&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.wlnmp.com%2F" target="_blank"&gt;wlnmp 源&lt;/a&gt;中，可以聯繫我，可以是成品 rpm 包，也可委託我這邊進行打包，當然這一切都是免費的。&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;PPPS：&lt;/strong&gt;如您有其它軟件、系統等其它商業定製需求可直接聯繫。
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#72c490"&gt;&lt;strong&gt;系統支持：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;Alibaba CloudLinux 2.1903/3&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;AlmaLinux 8.x/9.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;AnolisOS 7.x/8.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;CentOS 7.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;CentOS 8.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;OpenCloudOS 8.x/9.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦ OpenEuler 20.03&lt;/span&gt;(SP1~SP4)&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;OpenEuler 22.03&lt;/span&gt;(SP1~SP4)&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;OpenEuler 24.03&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;RockyLinux 8.x/9.x&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;傳統方式添加 wlnmp 鏡像源，實現 yum/dnf 一鍵安裝部署！&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;安裝便捷，穩定更新，模塊集成&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;免費使用，為愛發電&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;安裝使用見：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Finstall" target="_blank"&gt;install&lt;/a&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;更新日誌可查看：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Fchangelog" target="_blank"&gt;ChangeLo&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Fchangelog" target="_blank"&gt;g&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366084</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366084</guid>
      <pubDate>Wed, 13 Aug 2025 00:40:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>直播聊聊大模型外掛：RAG 技術</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;2020 年，Meta AI 提出了 RAG 概念，旨在解決&lt;strong&gt;大模型的兩大瓶頸：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一是知識滯後：大模型基於預訓練數據，無法獲取訓練數據之外的最新信息，如實時政策或企業私有文檔。&lt;/p&gt; 
&lt;p&gt;二是幻覺風險：模型可能生成看似合理實則錯誤的內容，例如編造論文或數據。&lt;/p&gt; 
&lt;p&gt;RAG 通過「檢索+生成」兩個階段來解決這些問題：首先動態地從外部知識庫中檢索相關信息，然後將這些信息作為上下文提供給大模型進行答案生成。這樣不僅能夠利用最新的外部知識，還能顯著減少幻覺，並使得答案的來源可追溯，從而大幅提升回答的準確性和可靠性。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;儘管利用 RAG 能緩解大模型幻覺問題，但還做不到 100%。我們想知道，RAG 到底能發揮多大的作用呢？怎麼判斷 RAG 的效果好不好？向量化在 RAG 中的作用是什麼？無向量 RAG 會是一種未來範式嗎？目前有哪些 RAG 產品，各有什麼優劣？······&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;8 月 19 日晚，開源中國將邀請 5 名技術專家，就 RAG 技術的發展與應用展開交流。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播主題：&lt;/strong&gt;大模型外掛：RAG 技術&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;8 月 19 日週二 20:00-21:30&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播嘉賓：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主持人：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;顧鈞，杭州映雲科技市場總監，上海開源信息技術協會副秘書長&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;討論嘉賓：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;傅聰，Shopee（新加坡）資深算法專家，高性能檢索算法 NSG、MAG 作者&lt;/li&gt; 
 &lt;li&gt;肖玉民，TorchV 聯合創始人 &amp;amp; CTO&lt;/li&gt; 
 &lt;li&gt;祝海林，Idea 研究院 MoonBit AI 輔助編程工具工程師、AutoCoder 作者&lt;/li&gt; 
 &lt;li&gt;張穎峯，英飛流 InfiniFlow 聯合創始人兼 CEO&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;微信掃碼，預約直播：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="923" src="https://oscimg.oschina.net/oscnet/up-de9003999691f6802a5effee93c0aa13f13.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播亮點&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;RAG 的概念、發展歷史，與大模型、Agent 的關係&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 能多大程度解決幻覺問題？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;大模型自身幻覺減少後，RAG 是否還有存在必要？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;向量檢索的關鍵作用，以及無向量 RAG 範式&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 開源項目推薦，以及市面上主流 RAG 產品的優缺點&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 效果評估標準、技術極限與未來&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;本次直播中，我們將有 5 輪抽獎，參與就有機會獲得 OSC T 恤、馬建倉蛇年公仔（限量版）、代碼聖盃、馬克杯、冰箱貼、前沿技術書籍等。立即掃碼預約直播吧！&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 我們還建了一個 AI 交流羣，可以經進來嘮嘮嗑~&lt;/p&gt; 
 &lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-32d5360d0666b500c240202d47193824a56.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span style="color:#27ae60"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【數智漫談】&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 視頻號直播暢聊欄目【數智漫談】，每期一個技術話題，三五位專家圍坐，各抒己見，暢聊開源。給大家帶來最新的行業前沿、最熱門的技術話題、最有趣的開源項目、最犀利的思想交鋒。如果你手上也有新點子、好項目，想要跟同行交流分享，歡迎聯繫我們，講壇隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18688119</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18688119</guid>
      <pubDate>Tue, 12 Aug 2025 15:38:00 GMT</pubDate>
      <author>原創</author>
    </item>
    <item>
      <title>FastBuildAI，面向 AI 創業者設計的開源 AI 應用框架 1.0.0-beta.2 已經發布</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;FastBuildAI-面向 AI 創業者設計的開源 AI 應用框架 1.0.0-beta.2 已經發布。&lt;/p&gt; 
&lt;p&gt;此版本更新內容包括：&lt;/p&gt; 
&lt;p&gt;優化&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;優化前後台 UI 細節&lt;/li&gt; 
 &lt;li&gt;優化首屏加載速度&lt;/li&gt; 
 &lt;li&gt;優化 docker 部署內存消耗&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;修復&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;若干已知問題&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看：&lt;a href="https://gitee.com/FastbuildAI/FastbuildAI/releases/1.0.0-beta.2"&gt;https://gitee.com/FastbuildAI/FastbuildAI/releases/1.0.0-beta.2&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366043</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366043</guid>
      <pubDate>Tue, 12 Aug 2025 12:19:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>License Manager 發佈首個框架版本 v0.1.0 —— 開源現代化軟件授權管理解決方案</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;h1&gt;License Manager 發佈首個框架版本 v0.1.0 —— 開源現代化軟件授權管理解決方案&lt;/h1&gt; 
&lt;h2&gt;填補市場空白，解決授權管理痛點&lt;/h2&gt; 
&lt;p&gt;隨着軟件產業的快速發展，越來越多的開發者和企業面臨着軟件授權管理的挑戰。&lt;/p&gt; 
&lt;p&gt;傳統的授權方案要麼過於複雜，要麼缺乏靈活性，難以滿足現代軟件分發的需求。&lt;/p&gt; 
&lt;p&gt;License Manager 的誕生，正是為了填補這一空白。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「我們在實際項目中發現，現有的授權管理工具要麼收費昂貴，要麼功能單一，很難找到一個既開源又功能完整的解決方案。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;—— 項目負責人&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;因此，團隊決定打造一個現代化、易用、完全開源的授權管理系統。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1284" src="https://oscimg.oschina.net/oscnet/up-fc77b60f8628c46a3ec3d649dc3aeb4f642.png" width="2552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1284" src="https://oscimg.oschina.net/oscnet/up-1b4184682c9c5c5c8804da1373e32058617.png" width="2552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;技術先進，架構清晰&lt;/h2&gt; 
&lt;p&gt;License Manager 採用當前主流技術棧：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;後端：Go 語言構建，高性能 &amp;amp; 高併發&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端：Vue 3 + TypeScript，現代化交互體驗&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署：支持 Docker 一鍵部署，降低運維成本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;國際化：內置多語言支持&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;系統架構採用，前後端分離，與 RESTful API 設計，方便第三方系統集成。&lt;/p&gt; 
&lt;p&gt;同時支持 JWT 認證，和 細粒度權限控制，保障系統安全。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;開放生態，社區驅動&lt;/h2&gt; 
&lt;p&gt;License Manager 採用 GPL-3.0 協議，鼓勵社區參與和商業應用。&lt;/p&gt; 
&lt;p&gt;源代碼和文檔已在 Gitee 全面開放。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「開源不僅是代碼的開放，更是思維的開放。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;—— 項目團隊&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h2&gt;發展規劃&lt;/h2&gt; 
&lt;p&gt;根據路線圖，後續版本將陸續推出：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;✅ 客户管理模塊&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 核心授權算法實現&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 硬件指紋綁定功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ API 安全增強&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 實時監控與統計分析&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;適用場景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;軟件開發商的產品授權管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企業內部軟件管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SaaS 服務權限控制&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;快速體驗&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
git clone https://gitee.com/cedar-v/license-manager.git

cd license-manager

docker compose up -d --build

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;系統默認運行在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flocalhost%3A18080" target="_blank"&gt;http://localhost:18080&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;默認管理員賬號：&lt;span style="color:#efb080"&gt;admin&lt;/span&gt;&lt;span style="color:#e394dc"&gt; / &lt;/span&gt;&lt;span style="color:#efb080"&gt;admin123&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;項目地址&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;源碼倉庫：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://gitee.com/cedar-v/license-manager"&gt;https://gitee.com/cedar-v/license-manager&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;關於 License Manager&lt;/h2&gt; 
&lt;p&gt;License Manager 是一個專注於軟件授權管理的開源項目，旨在為開發者和企業提供完整的許可證管理解決方案。&lt;/p&gt; 
&lt;p&gt;歡迎開發者貢獻代碼、提交反饋，共同完善項目！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366037</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366037</guid>
      <pubDate>Tue, 12 Aug 2025 11:50:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>用户吐槽 Firefox 新 AI 功能「臃腫」：導致 CPU 佔用飆升、又耗電又卡</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span&gt;近期，Mozilla 在 Firefox 141 版本中引入了 AI 功能，包括 AI 標籤分組和 AI 聊天機器人。然而，這一更新卻引發了大量用户的不滿。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;用户普遍反映，啓用這些 AI 功能後，瀏覽器出現了一個名為 "Inference" 的進程，佔用大量 CPU 資源，導致電腦卡頓、電池續航時間大幅縮短。例如，Reddit 用户 u/st8ic88 表示，Firefox 一打開，CPU 佔用就飆升，電池電量迅速耗盡，而罪魁禍首就是這個 "Inference" 進程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e9493780e2b2beec826dc0ef0ffc57bc6d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99f9b4c534089ece948b58fafd004bf713d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;用户批評 Mozilla 盲目跟風，將瀏覽器變成了 "AI 遊樂場"，違背了瀏覽器本應簡單高效的原則。 此外，用户發現無法直接終止 "Inference" 進程，否則會導致 Firefox 崩潰並重啓。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;雖然 Mozilla 的本意是通過本地 AI 模型保護用户隱私，但實際效果卻適得其反。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;如果用户想要關閉這些功能，可以通過瀏覽器的高級設置來禁用這些功能，在新標籤頁中輸入 about:config，接受風險警告，並通過搜索欄找到相關設置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366029</guid>
      <pubDate>Tue, 12 Aug 2025 11:07:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>深開鴻攜手 Arm 成立開源鴻蒙 Arm SIG 組</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;深開鴻&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2-DXuJ-lKbQyE4DqxIrG6g" target="_blank"&gt;宣佈&lt;/a&gt;，其與全球半導體 IP 巨頭 Arm 公司聯合發起的開源鴻蒙 Arm SIG（Special Interest Group）正式通過 OpenHarmony 項目管理委員會（PMC）評審，深開鴻獲任副組長單位。&lt;/p&gt; 
&lt;p&gt;這一合作標誌着開源鴻蒙生態在 ARM 架構適配方面邁出關鍵一步，將為產業帶來更完善的芯片支持方案。&lt;/p&gt; 
&lt;p&gt;目前已有 6 家芯片及板卡企業加入開源鴻蒙 Arm SIG。該 SIG 組將聚焦 ARM 架構芯片的深度優化，聯合產業鏈夥伴共同解決 ARM 架構芯片在開源鴻蒙系統中的關鍵性能問題，推進從內核層、系統服務層到框架層的全棧性能提升：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;內核層：優化任務調度與內存管理，提升實時性表現&lt;/li&gt; 
 &lt;li&gt;系統服務層：增強異構計算能力，釋放多核芯片潛力&lt;/li&gt; 
 &lt;li&gt;框架層：精簡 API 調用鏈路，降低應用開發門檻，並加強 AI 推理框架&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;深開鴻表示，ARM 架構作為移動生態的基石，在全球範圍內具有廣泛的影響力。此次 SIG 組的成立，將顯著提升開源鴻蒙在 ARM 芯片上的運行效率，為開發者提供更加友好、完善的工具鏈支持。這不僅有助於降低開發成本，提高開發效率，還將為未來更多高性能、低功耗的開源鴻蒙終端設備的落地奠定基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366028</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366028</guid>
      <pubDate>Tue, 12 Aug 2025 10:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Debian GNU/Hurd 2025 發佈</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Debian GNU/Hurd 2025 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.debian.org%2Fdebian-hurd%2F2025%2F08%2Fmsg00038.html" target="_blank"&gt;已正式發佈&lt;/a&gt;，該版本是基於 Debian 13.0 「Trixie」 穩定版製作的快照，雖非官方 Debian 穩定版，但它是官方認可的 GNU/Hurd 架構移植版本。&lt;/p&gt; 
&lt;p&gt;Debian GNU/Hurd 2025 提供了 i386 和 amd64 兩個架構的安裝 ISO（NETINST 版本）與預裝磁盤鏡像，方便用户在如 QEMU 的虛擬環境中體驗安裝與使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0813/183901_xqiF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;主要亮點與改進一覽&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;64 位支持完全實現&lt;/strong&gt;：該版本在 64 位架構上實現了與 i386 架構相當的包覆蓋率，甚至略有優勢——部分軟件僅提供 64 位版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;採用 Rump 層的用户態磁盤驅動&lt;/strong&gt;：通過 NetBSD Rump 層在用户空間支持磁盤驅動器，這一機制用於實現對 USB 磁盤和 CD-ROM 的支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 xattr 默認記錄翻譯器&lt;/strong&gt;：這使得可以更順利地從其他操作系統（如使用 mmdebstrap 的系統）中進行引導與安裝。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rust 已移植至 Hurd&lt;/strong&gt;：這為未來 Rust 生態在 GNU/Hurd 上的應用打下了基礎。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;改進支持&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;啓用了對 USB 磁盤與光驅的原生支持（通過 Rump）&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;SMP（多核）支持包已可用並能正常工作&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;控制枱現使用 xkb 支持鍵盤佈局，同時支持 multiboot 引導提供的 framebuffer&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增對 acpi、rtc、apic、hpet 等硬件功能的支持&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文檔與修復&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;改善了文檔內容&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;修復了多個問題，如中斷請求（IRQ）、NFSv3、libports、管道邊緣情況（pipes corner cases）等&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366026</guid>
      <pubDate>Tue, 12 Aug 2025 10:39:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>AI 企業扎堆赴港上市</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在全球人工智能（以下簡稱「AI」）競賽加速的背景下，香港市場正成為 AI 企業 IPO 的熱門選擇。Wind 資訊數據顯示，截至 8 月 12 日記者發稿，已遞交港股 IPO 申請的企業有 213 家，其中約 50 家企業為 AI 企業。&lt;/p&gt; 
&lt;p&gt;與此同時，港股 AI 板塊表現亮眼。截至 8 月 12 日收盤，恒生人工智能主題指數今年以來累計漲幅達 30.69%。進一步梳理發現，目前向港交所遞交招股書的 AI 企業普遍具備深厚的技術積累和強大的融資能力，但其財務表現分化明顯，僅少數企業實現盈利，多數仍處於虧損狀態。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;政策紅利持續&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;為何香港市場成為 AI 企業上市的首選地？政策紅利、資本熱度、行業需求形成多重合力。&lt;/p&gt; 
&lt;p&gt;AI 企業紛紛赴港 IPO 的背後，是港交所上市規則第 18C 章對人工智能企業上市門檻的持續放寬。2023 年，港交所推出特專科技上市機制第 18C 章，將 AI 企業納入支持範圍。2024 年，港交所下調第 18C 章的市值門檻，將已商業化企業的市值門檻從 60 億港元降至 40 億港元，未商業化企業從 100 億港元降至 80 億港元，以適配不同發展階段的 AI 企業。&lt;/p&gt; 
&lt;p&gt;今年 5 月份，港交所再次推出「科企專線」，允許第 18A 章、第 18C 章企業保密遞表，進一步提升保密性和審核效率，鼓勵 AI 等新興企業進入港股市場。&lt;/p&gt; 
&lt;p&gt;在政策的大力支持下，企業紛紛加快赴港 IPO 的步伐，進一步拓寬了融資渠道。例如，深圳海清智元科技股份有限公司（以下簡稱「海清智元」）計劃將募集資金用於技術研發、產能擴建及全球化佈局。諾比侃人工智能科技（成都）股份有限公司（以下簡稱「諾比侃」）計劃將募集資金用於加強核心技術研究、建設研發中心和新總部基地、尋求戰略投資及收購機會等。&lt;/p&gt; 
&lt;p&gt;A 股市場的 AI 企業同樣加速了赴港上市的進程。瀾起科技股份有限公司、兆易創新科技集團股份有限公司等已向港交所遞交了 IPO 申請書。&lt;/p&gt; 
&lt;p&gt;沙利文大中華區執行總監周明子在接受《證券日報》記者採訪時表示，一些專注於前沿人工智能算法研究的初創公司，港股市場可以為其提供融資和發展的機會。&lt;/p&gt; 
&lt;p&gt;與此同時，在一級市場上，AI 領域投融資熱度持續升温。IT 桔子數據顯示，今年上半年國內 AI 領域一級市場融資事件達 345 筆，較去年同期增加 88 筆，預估總融資金額達到 300.66 億元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;遞表企業覆蓋多個領域&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;擬 IPO 的 AI 企業覆蓋多個細分領域，技術路線也呈現多元化。當前已遞表的企業主要集中在 AI 應用層，涉及 AI 製藥、AI 輔助診療、AI 機器人等細分領域。在 AI 技術層面，以 AI 大模型公司為主；而在 AI 基礎層面，主要是 AI 芯片供應商等。&lt;/p&gt; 
&lt;p&gt;對於部分 AI 應用層企業而言，盈利模式初現端倪，商業化路徑也逐步清晰。例如，8 月 6 日遞交港股 IPO 申請的海清智元，專注於多光譜 AI 技術，2024 年淨利潤達到 4041 萬元，實現扭虧為盈。2025 年第一季度繼續盈利，淨利潤為 1414.4 萬元。儘管其已實現盈利，但市場仍關注其技術落地的持續性和供應鏈的穩定性。&lt;/p&gt; 
&lt;p&gt;儘管 AI 技術層企業數量較少，但仍受資本青睞。大模型企業滴普科技股份有限公司在 IPO 前獲得紅杉資本等多輪投資；諾比侃提供基於 AI 行業模型的軟硬一體化解決方案，涵蓋智能化監測、檢測和運維等服務，目前公司已完成 6 輪融資。&lt;/p&gt; 
&lt;p&gt;此外，年內在港上市的 AI 公司認購火爆。「AI+機器人企業」北京極智嘉科技股份有限公司（以下簡稱「極智嘉」）、「AGI 技術企業」雲知聲智能科技股份有限公司（以下簡稱「雲知聲」）、「無人駕駛系統研發的 AI 服務企業」博雷頓科技股份公司的公開認購倍數分別達到 133.62 倍、91.66 倍、198.72 倍，申購人數均超萬人，投資者參與意願強烈。&lt;/p&gt; 
&lt;p&gt;「AI 行業正呈現百花齊放的格局。」中金公司投資銀行部董事總經理、TMT 組執行負責人樓欣宇表示，所有的軟件、應用生態都值得用 AI 重構一遍，背後藴含着萬億元級別的機遇。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;商業化難題待解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;港股市場對 AI 企業的認可度較高。以 AI 軟件公司商湯科技為例，該公司憑藉多模態大模型技術的優勢，在港股上市後市值持續攀升，目前港股市值已超過 600 億港元，穩居港股 AI 板塊前列。&lt;/p&gt; 
&lt;p&gt;不僅商湯科技如此，今年 6 月 30 日上市的雲知聲，憑藉語音大模型技術的積累，也獲得了資本巨頭的青睞。上市首日，其股票最高價較發行價漲幅超過 50%，目前最新市值已突破 400 億港元。&lt;/p&gt; 
&lt;p&gt;然而，儘管資本熱捧，AI 企業估值與商業化能力的錯配問題也日益凸顯。&lt;/p&gt; 
&lt;p&gt;一些企業雖在技術研發上領先，但商業化路徑仍未打通。例如，某 AI 企業連續 6 年虧損，2025 年第一季度數據顯示，公司營業收入同比增長 168.23%，但淨利潤仍為負值。&lt;/p&gt; 
&lt;p&gt;另有一些 AI 企業因研發投入較高，上市後迅速啓動再融資以補充現金流。截至 8 月 12 日，至少有 11 家 AI 公司進行過一次或多次再融資。&lt;/p&gt; 
&lt;p&gt;商湯科技上市後累計再融資規模約 72.85 億港元，用於打造 AI 雲、智能硬件的商業化應用及大模型衍生產品的開發等。&lt;/p&gt; 
&lt;p&gt;去年 6 月份在港股上市的 AI 製藥企業晶泰控股，是首家根據第 18C 章規則在香港聯交所上市的特專科技公司。Wind 資訊數據顯示，截至 8 月 12 日，晶泰控股再融資規模為 32.18 億港元，已超過 IPO 募資額。&lt;/p&gt; 
&lt;p&gt;「AI 應用商業化進程已進入加速階段。」中銀證券首席策略分析師王君認為，大模型能力初步支撐 AI 商業化的拐點，部分垂類 AI 應用的商業模式已率先跑通。在港股市場中，AI 編程、AI 廣告、AI 多模態等賽道的商業模式正逐步落地。&lt;/p&gt; 
&lt;p&gt;未來，隨着資本的持續湧入，AI 企業上市隊伍或將進一步擴容。然而，或許只有真正找到商業化路徑的企業，才能在這場競賽中贏得長跑。（證券日報）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366023</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366023</guid>
      <pubDate>Tue, 12 Aug 2025 10:26:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>開源 3D 建模與動畫軟件 Blender 將推出原生 iPad 版本</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Blender &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.blender.org%2F2025%2F07%2Fbeyond-mouse-keyboard%2F" target="_blank"&gt;透露&lt;/a&gt;正在開發一款原生的 iPad 版開源 3D 創作套件，包含專為依賴平板電腦的藝術家設計的全功能多點觸控界面。&lt;/p&gt; 
&lt;p&gt;據介紹，為適配觸控與 Apple Pencil 操作，Blender iPad 版採用全新的界面設計，包括單窗口全屏佈局、浮動工具面板、圖標化側邊欄、觸控友好的輪盤菜單，以及多指手勢與快捷操作提示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77d2b784d18da5e1187f3c784bef19dc243.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（Blender for iPad 渲染圖）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;團隊還表示，這些優化不僅服務於移動用户，也會反哺到桌面版，例如 Quick Favorites 編輯器和可切換 UI 元素等功能已出現在 Blender 5.0 alpha 中。&lt;/p&gt; 
&lt;p&gt;首個技術演示將於 8 月 10–14 日在温哥華的 SIGGRAPH 2025 上公開亮相，隨後在阿姆斯特丹的 Blender Conference 2025（9 月 15–19 日）進一步展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0c2679723a74cd0b9b5ebc5868e0986c968.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;開發工作正在進行中，Blender 社區貢獻者也被邀請參與改進觸控交互、iOS 文件集成及性能優化等環節。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關來源&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://devtalk.blender.org/t/blender-and-tablets/41558&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.creativebloq.com/3d/blender-on-ipad-is-finally-happening-and-it-could-be-the-app-every-artist-needs&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.macrumors.com/2025/07/25/blender-ipad-pro-app-in-development&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366022</guid>
      <pubDate>Tue, 12 Aug 2025 10:24:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>SelectDB x 同轅開發：在 ARM 架構下實現 25% 分析性能提升</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;strong&gt;近日，北京飛輪數據科技有限公司（以下簡稱「飛輪科技」）旗下現代化數據倉庫 SelectDB 完成同轅開發深度適配，正式獲得 Kunpeng Native 測試認證證書。&lt;/strong&gt; 該認證表明 SelectDB 深度兼容鯤鵬芯片，可實現高效部署。通過與同轅開發協同創新，SelectDB 實時分析、湖倉一體、存算分離等核心能力，可針對性解決海量數據處理慢、實時決策延遲、運維複雜等痛點，助力金融、製造、互聯網等行業用户快速釋放數據價值。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="鯤鵬技術認證證書.JPEG" src="https://oscimg.oschina.net/oscnet//70887b2266176fd647936cf0cce5eddd.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;北京飛輪數據科技有限公司創立於 2022 年，成立以來，飛輪科技在積極投身 Apache Doris 開源社區建設的同時，自主研發了現代化實時數據倉庫 SelectDB，面向全球提供多種部署形態的實時數據倉庫產品 SelectDB 與相關解決方案，滿足大規模實時數據場景下的極速查詢分析需求，為工業界構建全新的實時數據分析通用標準。目前，飛輪科技已服務全球 5000 餘家金融、電信、製造、能源、汽車、物流、政務等中大型企業，並基於豐富的行業經驗，沉澱了實時報表、用户畫像、數據湖查詢、日誌分析等成熟的解決方案。&lt;/p&gt; 
&lt;p&gt;隨着企業實時數據分析需求爆發式增長，傳統數據倉庫在應對海量高併發查詢、多源異構數據分析及兼容要求時面臨巨大挑戰。&lt;strong&gt;為突破性能瓶頸並構建自主可控的分析體系，飛輪科技聯合鯤鵬啓動深度技術協同，基於其全棧生態進行深度優化，並進行了代碼開發、門禁配置及功能、性能測試。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SelectDB 在原有架構和同轅開發 ARM 架構下性能對比 .JPEG" src="https://oscimg.oschina.net/oscnet//17baeeba0727583104d67e8697daf1fa.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;測試數據表明，&lt;strong&gt;SelectDB 完全兼容同轅開發架構，在單機 1FE + 1BE 環境下，在從原有架構遷移到鯤鵬 ARM 平台之後，實現了 25% 的顯著速度提升。&lt;/strong&gt; 在同等資源配置下，SelectDB 結合同轅開發，能夠幫助企業分析效率躍升、海量數據亞級極速分析，築牢實時決策基石。&lt;/p&gt; 
&lt;p&gt;作為鯤鵬計算產業生態重要夥伴，未來，SelectDB 將進一步強化與鯤鵬生態的深度協同，持續提升兼容性與開放性，深化聯合解決方案與資源共享，並在同轅開發架構中持續優化分析性能，攜手夯實企業級實時數據分析底座，驅動千行百業數智化轉型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366021</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366021</guid>
      <pubDate>Tue, 12 Aug 2025 10:22:00 GMT</pubDate>
      <author>來源: 資訊</author>
    </item>
    <item>
      <title>Blender 原生支持 Windows 11 on Arm</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.blender.org%2F2025%2F08%2Fblender-for-windows-on-arm%2F" target="_blank"&gt;根據 Blender 的開發公告&lt;/a&gt;，自一年多前，Blender 團隊聯合微軟、Linaro 與高通啓動了將 Blender 移植至支持 Windows ARM64 架構（WoA）的開發計劃，得益於高通作為 Blender Development Fund 的「大力支持者」（Patron 級別），項目獲得了資源雄厚的推動。&lt;/p&gt; 
&lt;p&gt;&lt;img height="592" src="https://static.oschina.net/uploads/space/2025/0813/180440_YQN3_2720166.png" width="1572" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blender 4.3 是首個正式支持 WoA 架構的版本，Blender 開發團隊介紹稱，當前重點是引入 Vulkan 渲染後端，以顯著提升 EEVEE 視窗（viewport）性能，&lt;/p&gt; 
&lt;p&gt;關鍵優化目標包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;着色器（shader）性能優化，提升 UI 流暢度；&lt;/li&gt; 
 &lt;li&gt;利用 Adreno GPU 架構的瓦片渲染（tiling）機制，加快視窗刷新速度&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載地址：&lt;em&gt;https://builder.blender.org/download/daily/archive/&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366020/blender-for-windows-on-arm</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366020/blender-for-windows-on-arm</guid>
      <pubDate>Tue, 12 Aug 2025 10:10:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>消息稱 Altman 將聯合創辦腦機接口公司，挑戰馬斯克的 Neuralink</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;英國&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F04484164-724e-4fc2-92a2-e2c13ea639bd" target="_blank"&gt;《金融時報》報道&lt;/a&gt;&lt;span style="color:#000000"&gt;稱，Sam Altman 正在與他人共同創立一家名為 Merge Labs 的腦機接口初創公司，並正在為其籌集資金，資金可能主要來自 OpenAI 的風險投資團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;這家初創公司的估值預計為 8.5 億美元。一位知情人士告訴 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F08%2F12%2Fsam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink%2F" target="_blank"&gt;TechCrunch&lt;/a&gt;，談判仍處於初期階段，OpenAI 尚未承諾參與，因此條款可能會有所調整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="194" src="https://oscimg.oschina.net/oscnet/up-a994c9873892e90803fc1c1aca1ac9c5b5f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息指出，Merge Labs 還與 Alex Blania 合作，後者運營着 Tools for Humanity（原名 World）—— Altman 的眼球掃描數字身份識別項目，該公司稱其「允許任何人驗證他們的人類身份」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Merge Labs 將與 Elon Musk 的 Neuralink 展開競爭，後者正在開發用於植入大腦的計算機接口芯片。馬斯克於 2016 年創立了 Neuralink（儘管直到 2017 年才為人所知），目前該公司已取得重大進展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Neuralink 目前正在對患有嚴重癱瘓的患者進行臨牀試驗。其目標是讓患者能夠通過思維控制設備。該公司於 6 月以 90 億美元的估值完成了 6 億美元的 E 輪融資。 Neuralink（或許還有 Merge Labs）或許會徹底改變人類與科技的互動方式。有些人甚至會説，他們的技術或許能帶領人類走向「奇點」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366013</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366013</guid>
      <pubDate>Tue, 12 Aug 2025 09:55:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>Pika 發佈音頻驅動的視頻生成模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Pika&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fpika_labs%2Fstatus%2F1954935844936024476"&gt;發佈&lt;/a&gt;了一款突破性的音頻驅動視頻生成模型（Audio-Driven Performance Model），能近乎實時地生成具有逼真表情和完美唇形同步的視頻，速度提升 20 倍且成本大幅降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0813/174657_uvNx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，該模型支持任意長度和風格的視頻製作，並能在 6 秒或更短的時間內完成高清視頻的生成。新模型在速度上提升了 20 倍，同時成本也大幅降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0813/174616_eifl_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pika 以生成逼真視頻的 AI 技術而知名。而據公開信息，郭文景是 Pika Labs 的聯合創始人與 CEO。她與聯合創始人兼 CTO Chenlin Meng 均為斯坦福大學 AI Lab 博士生，在 2023 年 4 月從斯坦福輟學、創立了 Pika Labs，致力於開發基於文本生成短視頻的 AI 工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pika 的&lt;a href="https://www.oschina.net/news/361912"&gt;核心產品&lt;/a&gt;為「文生視頻」模型，號稱用户一句話描述，就能生成風格多樣的動畫短視頻。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366012</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366012</guid>
      <pubDate>Tue, 12 Aug 2025 09:51:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
    <item>
      <title>v0.dev 更名為 v0.app，上線 Agent 模式</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fv0-app" target="_blank"&gt;根據 Vercel 官方公告&lt;/a&gt;，Vercel 旗 AI 前端開發工具 v0.dev 現已更名為 v0.app，並正式上線 Agent 模式，旨在成為面向所有人的 AI 構建器。用户只需一個提示，即可快速生成並部署包含 UI、內容、後端和邏輯的完整應用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0813/173740_ovdx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;v0.app 的 Agent 模式賦予其研究、推理和規劃能力，能夠與用户協作或獨立完成端到端工作。v0.app 通過 Agentic 智能自動規劃、調整和改進，顯著減少了提示次數。目前，v0.app 為每日為前 10 萬用户提供免費限時額度。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0813/173924_HXe8_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;訪問&lt;em&gt;https://v0.app/&lt;/em&gt;體驗&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366010</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366010</guid>
      <pubDate>Tue, 12 Aug 2025 09:41:00 GMT</pubDate>
      <author>來源: OSCHINA</author>
    </item>
  </channel>
</rss>
