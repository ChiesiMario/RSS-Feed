<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 17 Feb 2025 02:36:35 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>月之暗面因 DeepSeek 調整工作重心，內部人士：強化學習或許會是個方向</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;據媒體報道，月之暗面內部已經將「持續拿到 SOTA 結果」確定為當下最重要的工作目標。&lt;/p&gt; 
&lt;p&gt;2025 年，月之暗面圍繞模型能力的關鍵方向除了繼續強化多模態部分外，還會繼續強化長文本推理能力。報道分析稱，DeepSeek 爆火後，DeepSeek 與月之暗面存在的路線差異，讓外界面臨重新審視月之暗面技術模式、用户增長模式的情況。&lt;/p&gt; 
&lt;p&gt;而今，DeepSeek 採用區別與月之暗面的路線，也取得了現階段更為出色的效果。業內人士認為，月之暗面如果想守住生態位，「需要做一些改變或者嘗試，比如開源，比如調整引流策略等。」&lt;/p&gt; 
&lt;p&gt;不過目前，月之暗面尚未明確是否「接入」DeepSeek，對於接下來是否「開源」，公司也未置評媒體問詢。&lt;/p&gt; 
&lt;p&gt;對於月之暗面是否會因 DeepSeek 而調整工作重心一事，向月之暗面方面求證，截止發稿公司暫無回應。不過有內部人士透露稱，&lt;strong&gt;「RL（強化學習）大概率會是一個（工作重點）方向」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;去年 11 月份月之暗面宣佈推出&lt;a href=&quot;https://www.oschina.net/news/320859&quot; target=&quot;_blank&quot;&gt;新一代數學推理模型 k0-math &lt;/a&gt;之際，Kimi 探索版便通過運用強化學習技術創新了搜索體驗，在意圖增強、信源分析和鏈式思考三大推理能力上實現突破。彼時，月之暗面 Kimi 創始人楊植麟便對強化學習這一技術路線帶來的模型能力提升給予了高度評價。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f3ef9f71486f2898a14d0b17103cbd4308a.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而在近日 OpenAI 發佈關於推理模型在競技編程中應用的研究論文報告《Competitive Programming with Large Reasoning Models》中，論文也特別提到，「中國的 DeepSeek-R1 和 Kimi k1.5 通過獨立研究顯示，利用思維鏈學習（COT）方法，可顯著提升模型在數學解題與編程挑戰中的綜合表現。其中 k1.5 便是 DeepSeek 和 Kimi 在 1 月 20 日同時發佈的新型推理模型。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334255</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334255</guid>
            <pubDate>Mon, 17 Feb 2025 02:28:33 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信搜索接入 DeepSeek，正在灰度測試中</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 15 日，部分微信用户發現，微信搜索已經上線「AI 搜索」功能，並接入 DeepSeek-R1 提供的「深度思考」服務。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2 月 16 日，記者從騰訊集團確認，微信搜一搜在調用混元大模型豐富 AI 搜索的同時，正式灰度測試接入 DeepSeek&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101747_uyUN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;騰訊方面表示，部分測試用户可在微信對話框頂部搜索入口，看到「AI 搜索」字樣，點擊進入後，可免費使用 DeepSeek-R1 滿血版模型，獲得更多元化的搜索體驗。若未顯示該入口，説明此次灰度測試暫未覆蓋到該用户賬號，可耐心等待後續開放。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101729_EaEQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用户表示，通過在微信 AI 搜索「如何在微信上使用 DeepSeek 的 R1 模型」問題得到的答案是，該功能正灰度測試中，僅部分用户可見，微信版本需更新至最新版本。若暫未獲得測試方案，微信團隊正逐步擴大測試範圍，建議定期檢查更新及搜索功能變化。&lt;/p&gt; 
&lt;p&gt;從功能附帶的開源與鳴謝聲明能看出，&lt;strong&gt;微信中內置的 DeepSeek R1 基於開源版本構建而來，但其中並未明確提及其使用的模型體積，是否是 671B 的「滿血」R1 版本&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0217/101712_mjq7_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據證券時報今日消息，對於一些相關細節，騰訊方面還作了進一步説明：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;1、AI 搜索的數據源包含公眾號嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;微信 AI 搜索接入的 DeepSeek 支持聯網搜索（用户無需手動選擇），基於公眾號等豐富的微信生態內容，以及全網優質內容，能為用户提供更全面的高質量回答。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2、AI 搜索已經全量嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;目前該能力還在灰度測試中，將根據用户體驗和反饋持續優化。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3、微信的搜索場景為什麼要接入大模型？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;大模型可以提升搜索的智能化和精準度，如更好地理解用户的搜索意圖，分析和處理複雜的查詢內容等。&lt;/p&gt; 
 &lt;p&gt;結合用户需求，騰訊在搜索場景中接入了包括混元、DeepSeek 在內的大模型，進一步豐富用户的搜索體驗。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4、AI 搜索會用我微信內的朋友圈、聊天等個人信息嗎？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;AI 搜索僅整合公眾號及互聯網其他公開信息，不會使用用户的個人信息和相關隱私信息。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334252</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334252</guid>
            <pubDate>Mon, 17 Feb 2025 02:18:41 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度搜索宣佈將全面接入 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度搜索發文宣佈，&lt;span&gt;&lt;span&gt;&lt;span&gt;為豐富更多元化的搜索體驗，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;百度搜索將全面接入&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;DeepSeek&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;和文心大模型最新的深度搜索功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;搜索用户可免費使用 DeepSeek 和文心大模型深度搜索功能，文心智能體平台的開發者也將能隨時調用 DeepSeek 模型創建並調優智能體。&lt;/p&gt; 
&lt;p&gt;根據介紹，文心大模型深度搜索功能於 2 月 13 日上線，具備更強大的思考規劃和工具調用能力，可為用户提供專家級內容回覆，並處理多場景任務，實現多模態輸入與輸出。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;161&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a3cff12b27c30d05def83a2c2f4477122.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/334250</link>
            <guid isPermaLink="false">https://www.oschina.net/news/334250</guid>
            <pubDate>Mon, 17 Feb 2025 02:03:41 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度測試社區 APP 「次遇」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度近期正在測試一款名為「次遇」的 App。據悉，這是一款基於興趣的原創社區 App，產品會在近日上線。 另據企查查顯示，百度關聯公司正在申請註冊相關商標。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e92cc7029db9ff18aad093ab328066e5d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;整個社區的覆蓋人羣主要以動漫用户、OC 興趣用户、遊戲用户和追星用户為主，性別上，以年輕女用户為主，預計佔比 90%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-15d3184f96d57ee30a3e73f05e989f68ea3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了讓產品在發展初期能夠吸引更多用户，以及保證平台的內容質量，「次遇」邀請了不少高質量的原創作者。一位入駐次遇的二次元畫師表示，百度正在從 B 站、LOFTER、抖音、微博和小紅書等平台，邀請二次元創作者加入，入駐門檻除了作品質量的要求外，粉絲數也需要幾萬以上。&lt;/p&gt; 
&lt;p&gt;與此同時，平台還為創作者提供流量扶持、創作激勵和個人 IP 孵化。具體實施上，將會提供千萬級流量扶持，主要依靠百度系 App 矩陣，包括百度 App、百度地圖、貼吧、百度輸入法和百度文庫。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333783</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333783</guid>
            <pubDate>Fri, 14 Feb 2025 11:44:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 官方發佈推理類模型的最佳實踐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 官方博客發佈了推理類模型的最佳實踐，指導大家如何更好的使用 o1、o3 這類推理模型，當然也可以應用在 deepseek r1 上。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-264a714cd2f2a9ba42f99650890334024a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這裏摘錄一下比較重要的原則：&lt;/p&gt; 
&lt;h4&gt;⭐&lt;strong&gt;什麼時候適合用推理模型？&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;1. 處理模糊任務&lt;/strong&gt;&lt;br&gt; 推理模型特別擅長利用有限的信息或不同的信息片段，並通過簡單的提示理解用户的意圖，並處理指令中的任何空白。 事實上，推理模型通常會在做出不成熟的猜測或試圖填補信息空白之前提出澄清問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 大海撈針&lt;/strong&gt;&lt;br&gt; 當您傳遞大量非結構化信息時，推理模型非常擅長理解並僅提取最相關的信息來回答問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.在大型數據集中尋找關係和細微差別&lt;/strong&gt;&lt;br&gt; 我們發現推理模型特別擅長對具有數百頁密集、非結構化信息的複雜文檔進行推理——例如法律合同、財務報表和保險索賠。 這些模型特別擅長在文檔之間建立聯繫，並根據數據中未言明的真相做出決策。&lt;br&gt; 推理模型還擅長對細緻的政策和規則進行推理，並將它們應用於手頭的任務，以得出合理的結論。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. 多步驟智能體規劃&lt;/strong&gt;&lt;br&gt; 推理模型對於智能體規劃和戰略制定至關重要。 當推理模型用作「規劃者」時，我們已經看到了成功，它可以為問題生成詳細的多步驟解決方案，然後根據高智能還是低延遲最重要來選擇和分配正確的 GPT 模型（「執行者」）用於每個步驟。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.視覺推理 （o1、QvQ 等視覺推理模型專享功能）&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;⭐&lt;strong&gt;怎麼有效地用推理模型？&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;1. &lt;strong&gt;保持提示簡單直接&lt;/strong&gt;： 這些模型擅長理解和響應簡潔、清晰的指令。&lt;br&gt; 2. &lt;strong&gt;避免思維鏈提示&lt;/strong&gt;： 由於這些模型在內部執行推理，因此提示它們「逐步思考」或「解釋你的推理過程」是不必要的。&lt;br&gt; 3. &lt;strong&gt;使用分隔符以提高清晰度&lt;/strong&gt;： 使用分隔符（如 Markdown、XML 標籤和章節標題）來清楚地指示輸入的不同部分，這有助於模型正確地解釋各個部分。&lt;br&gt; 4. &lt;strong&gt;首先嚐試零樣本&lt;/strong&gt;，如果需要再嘗試少樣本： 推理模型通常不需要少樣本示例（few-shot examples）就能產生好的結果，所以首先嚐試編寫沒有示例的提示。 如果你對期望的輸出有更復雜的要求，在提示中包含一些輸入和期望輸出的示例可能會有所幫助。但要確保示例與你的提示指令非常一致，因為兩者之間的差異可能會導致不良結果。&lt;br&gt; 5. &lt;strong&gt;提供具體的指導方針&lt;/strong&gt;： 如果你想明確地限制模型的響應（例如「提出一個預算低於 500 美元的解決方案」），請在提示中明確地列出這些約束條件。&lt;br&gt; 6. &lt;strong&gt;非常明確地説明你的最終目標&lt;/strong&gt;： 在你的指令中，嘗試為成功的響應提供非常具體的參數，並鼓勵模型持續推理和迭代，直到符合你的成功標準。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Freasoning-best-practices&quot; target=&quot;_blank&quot;&gt;https://platform.openai.com/docs/guides/reasoning-best-practices&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333767/reasoning-best-practices-by-openai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333767/reasoning-best-practices-by-openai</guid>
            <pubDate>Fri, 14 Feb 2025 09:36:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 等大模型私有化服務器快速上升，近九成在裸奔</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;經濟參考網報道稱，隨着 DeepSeek 大模型的迅速流行，越來越多的公司和個人選擇將該開源大模型私有化部署。奇安信資產測繪鷹圖平台監測發現，8971 個 Ollama 大模型服務器中，有 6449 個活躍服務器，其中 88.9% 都「裸奔」在互聯網上，導致任何人不需要任何認證即可隨意調用、在未經授權的情況下訪問這些服務，有可能導致數據泄露和服務中斷，甚至可以發送指令刪除所部署的 DeepSeek、Qwen 等大模型文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公開信息顯示，運行 DeepSeek R1 大模型的服務器正在快速上升，上述 8971 個服務器中有 5669 個在中國。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;308&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-621c404ca9e7daa19db425427e2fa23b30b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;span style=&quot;color:#000000&quot;&gt;奇安信資產測繪鷹圖平台顯示大概有 8971 個 IP 運行了 Ollama&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為了應對這些問題，專家建議，所有部署 DeepSeek 服務的企業和個人應立即採取有效的安全防護措施。具體措施如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘快修改配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;建議立即修改 Ollama 配置，加入身份認證手段。同時及時修改防火牆、WAF、入侵檢測等相關安全配置，例如制定 IP 白名單限制訪問，確保只有授權人員能夠訪問模型服務。定期檢查和關閉不必要的端口、限制計算資源的使用、加強監控等措施也是提高安全性的關鍵。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;確保數據傳輸加密&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在大模型運行中，需要對所有傳輸的數據進行加密，避免在遭遇攻擊及數據竊取時泄露敏感信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;部署專業安全產品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通過部署奇安信大模型衞士等產品，可以有效的抵禦針對應用服務的傳統網絡攻擊，尤其對大模型應用特有的越獄、提示詞注入等攻擊進行全面有效的防護；部署奇安信 API 安全衞士等產品，對大模型應用的 API 接口訪問做好全面監測與防護。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，個人用户更應警惕不知名廠商提供的 DeepSeek 大模型服務，一些不良廠商使用被盜資源對外售賣，騙取錢財的同時，還可實時監控用户提交的所有數據，可造成隱私泄露。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;隨着大模型技術的不斷發展，安全問題將變得愈發複雜。行業專家呼籲，使用 DeepSeek 及類似大模型的用户應儘快採取預防措施，確保技術的安全部署和穩定運行。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333761</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333761</guid>
            <pubDate>Fri, 14 Feb 2025 09:18:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Ubuntu 24.04.2 LTS 延期至下週發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;Ubuntu 24.04.2 LTS 及其衍生版本原定於本週四發佈，但一個臨時的技術問題導致此次發佈&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.ubuntu.com%2Farchives%2Fubuntu-release%2F2025-February%2F006310.html&quot; target=&quot;_blank&quot;&gt;被推遲&lt;/a&gt;。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0214/163047_Nn1o_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由於某些 Ubuntu 24.04.2 LTS 版本在製作時&lt;strong&gt;沒有包含硬件啓用「HWE」內&lt;/strong&gt;核，Ubuntu 24.04.2 LTS 的發佈被推遲了一週，以便有時間重新制作。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;Ubuntu 24.04.2 的重要意義在於它是 Ubuntu 24.04 LTS 系列中第一個採用 HWE 內核的版本，而 HWE 內核是 Ubuntu 24.10 的向後移植內核和其他組件。由於 Ubuntu 24.04.2 LTS 具有 Linux 6.11 內核選項和其他硬件驅動程序升級，它比一年前 Ubuntu 24.04 推出時提供了更好的硬件支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333744/ubuntu-24-04-2-lts-delayed</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333744/ubuntu-24-04-2-lts-delayed</guid>
            <pubDate>Fri, 14 Feb 2025 08:32:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國信通院：正式啓動 DeepSeek 國產化適配測評工作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國信息通信研究院（簡稱「中國信通院」）宣佈正式啓動 DeepSeek 國產化適配測評工作，旨在為 DeepSeek 系列模型在多硬件多場景下的適配部署提供參考。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是評價模型在包括硬件芯片、計算設備、智算集羣等軟硬件系統中的適配效果；二是反映模型在軟硬件系統適配過程中軟件棧及工具的適配易用性及開發部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;本次測評將依託由中國信通院人工智能軟硬件協同創新與適配驗證中心（亦莊）、人工智能關鍵技術和應用評測工業和信息化部重點實驗室聯合推進的 AISHPerf（Performance Benchmarks of Artificial Intelligence Software and Hardware,以下簡稱 AISHPerf）人工智能軟硬件基準體系及測試工具，面向包括芯片、服務器、集羣、開發框架及工具鏈、智算設施及平台等在內的人工智能軟硬件產品及系統開展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;測試將主要圍繞表 1 所示的 DeepSeek 不同模態、不同尺寸的系列模型，面向推理、微調、訓練過程，低成本使用測試工具 AISHPerf，從適配成本、功能完備性、優化效果、性能指標等多方面開展測試評估。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;172&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f31d6d384d3e96b7b27f04655df7e6d0a52.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.qq.com%2Fform%2Fpage%2FDVnh1bVFndmt1bnFM%3Fu%3Df50706e2c08c43acb447aeaa0ec26470%23%2Ffill&quot; target=&quot;_blank&quot;&gt;報名錶&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333734</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333734</guid>
            <pubDate>Fri, 14 Feb 2025 08:07:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蔡崇信回憶初見馬雲：他極具個人魅力，是一個領導者</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在阿聯酋迪拜舉辦的 World Governments Summit 2025 峯會上，阿里巴巴聯合創始人、董事局主席蔡崇信在對談環節中回憶起加入阿里巴巴和初見馬雲的情景。&lt;/p&gt; 
&lt;p&gt;蔡崇信表示，1999 年來到杭州一個公寓拜訪馬雲，那時候馬雲還沒出名，但是當時《經濟學人》的編輯克里斯・安德森已經把馬雲稱為中國的傑夫・貝索斯（亞馬遜集團創始人）。&lt;/p&gt; 
&lt;p&gt;蔡崇信稱，馬雲極具個人魅力，當時就被馬雲吸引了，聽他講了大概一個小時。蔡崇信回憶稱，馬雲談到阿里巴巴的願景，當時自己也不完全理解。&lt;strong&gt;馬雲説，創辦一家公司並不真的需要一個商業計劃，而只需要前進&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;蔡崇信談到當時讓他決定辭去 70 萬美元年薪加入阿里巴巴的原因。「&lt;strong&gt;馬雲是一個領導者，他可以讓人們相信技術將改變世界的使命。我意識到，互聯網技術不僅會改變這家公司，也會給整個國家帶來巨大影響。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;蔡崇信分享道，&lt;strong&gt;馬雲當時的願景是創建一個互聯網平台，讓中國的所有小型企業、製造商和從事出口貿易的公司都能在這個平台上展示自己&lt;/strong&gt;。「當時我們稱它為 BBS，這是阿里巴巴網站的第一個版本。它是英文的，因為它是為那些從中國採購商品的外國人設計的。當時中國正處於加入世貿組織的前夕，中國的出口經濟開始蓬勃發展，這也推動了阿里巴巴早期的成功。」&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9gUe0jqPc-i-q6NDWyEXBw&quot; target=&quot;_blank&quot;&gt;新浪科技&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333724</guid>
            <pubDate>Fri, 14 Feb 2025 07:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Rust 編輯器 Zed 推出代碼編輯預測模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Zed 團隊今天&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fedit-prediction&quot; target=&quot;_blank&quot;&gt;宣佈推出 Zeta 模型&lt;/a&gt;，以進一步增強這個代碼編輯器的 AI 功能，提供更高效的編碼體驗，並且與 Zed 編輯器很好地集成在一起。&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Zed 是採用 Rust 編寫的編輯器，由 Atom 編輯器作者發起，目前僅支持 macOS 和 Linux。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據介紹，&quot;Zeta&quot; 模型是 Qwen2.5-Coder-7b 的微調版本，用於在 Zed 編輯器中預測用户下一步要編寫的代碼。Zed 團隊介紹道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「還有更多探索空間可以提升編輯預測的強大功能。我們將迅速跟進更多實驗。我們計劃向模型發送更多種類的上下文，並繼續我們的微調實驗，隨着我們不斷發展和完善 Zeta 數據集，我們將分享更新。&lt;/p&gt; 
 &lt;p&gt;自我們從去年秋天推出 Zed AI 以來，我們學到了很多。世界變化很快，我們正在盡情探索和學習構建開發者喜愛的功能。我們也興奮地以 Zed 的方式使用 AI 進行構建。&lt;/p&gt; 
 &lt;p&gt;從我們的早期階段開始，我們就一直是構建開源軟件的支持者，即使這很困難，當我們與 AI 合作時，我們也沒有理由改變這種方法。我們希望您能加入我們，無論是作為用户、貢獻者還是員工，讓我們努力打造一個輝煌的未來。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Zeta 模型 &amp;amp; 數據集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fzed-industries%2Fzeta&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/zed-industries/zeta&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fzed-industries%2Fzeta&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/datasets/zed-industries/zeta&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333720/zed-zeta-ai-model-edit-predict</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333720/zed-zeta-ai-model-edit-predict</guid>
            <pubDate>Fri, 14 Feb 2025 07:17:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>天津智算中心部署國產大模型 DeepSeek 全系</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天津日報消息稱，河北區政府昨日召開新聞發佈會，宣佈天津市人工智能計算中心（以下簡稱天津智算中心）成功部署國產大模型 DeepSeek 全系，成為京津冀地區首個完整接入該模型的智算平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一舉措不僅標誌着國產 AI 技術生態的跨越式升級，更以「算力普惠+模型開源」的雙輪驅動，為區域人工智能產業注入強勁動能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;229&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c314a757bf7599eececa46a9d2b97e6ecd1.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天津市人工智能計算中心 CEO 孔祥朋表示，「DeepSeek 的出現，讓全球看到了中國 AI 的硬核實力。」他坦言，過去企業開發 AI 應用常面臨兩大痛點：訓練成本高昂、技術門檻過高。而 DeepSeek 通過算法優化與開源模式，將模型訓練效率提升 30% 以上，硬件成本降低 50%，真正實現了「讓 AI 用得起、用得好」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於下一步規劃，孔祥朋描繪了清晰路徑：2025 年天津智算中心將衝刺 1000PFlops 算力規模，並建設金融、生物醫藥等領域的專業化智算中心。「我們正與市金融局合作搭建數據專區，未來銀行可通過 AI 模型快速評估企業信貸風險，效率提升超 80%。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333709</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333709</guid>
            <pubDate>Fri, 14 Feb 2025 06:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「本源悟空」全球訪問量突破 2000 萬次，美國排境外訪問量第一</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;安徽省量子計算工程研究中心消息稱，中國第三代自主超導量子計算機「本源悟空」全球訪問量突破 2000 萬次，刷新了我國自主量子算力服務規模紀錄。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;數據顯示，「本源悟空」已覆蓋全球 139 個國家和地區，海外用户中，美國、俄羅斯、日本、加拿大等國用户活躍度位居前列，其中，美國用户訪問量一直穩居境外訪問量第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;277&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-55a4ff53d884300572ffbcf0c7c01a0831d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「本源悟空」由本源量子團隊自主研發，搭載 72 位自主超導量子芯片「悟空芯」，在量子比特數量、相干時間等關鍵指標上達到國際先進水平，真正實現了從硬件到軟件的全鏈條自主可控，是目前國內最先進的可編程、可交付超導量子計算機。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;自 2024 年 1 月 6 日上線至今，「本源悟空」已完成 33.9 萬餘個量子計算任務，涵蓋流體動力學、金融、生物醫藥等多個行業領域。由合肥綜合性國家科學中心人工智能研究院、中國科學技術大學等單位組成的研究團隊，依託「本源悟空」成功完成全球最大規模的量子計算流體動力學仿真。在金融科技領域，經北京金融科技產業聯盟授權，「本源悟空」超導量子算力已接入金融量子云實驗平台用於探索金融領域更高效的問題解決方案。此外，「本源悟空」自主量子算力已獲得聯合國安理會常任理事國一知名企業的商業化採購訂單，首次實現中國自主量子算力出口。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「本源悟空」科研團隊主要負責人、中國科學技術大學教授郭國平表示：「量子計算是一項造福人類的前沿科技。未來，我們將繼續擴大自主量子算力服務規模，推動中國自主量子計算機賦能更多關鍵核心領域。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333706</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333706</guid>
            <pubDate>Fri, 14 Feb 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Chromium 優化 Windows 上文本渲染的技術細節</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;相信 Windows 用户在使用基於 Chromium 的&lt;span style=&quot;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif&quot;&gt;瀏覽器時會經常有這種文字看起來「很淡」的體驗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b0e4b8294f7d93890398eaf5620f440f9da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;這一情況在微軟 Edge 參與到&amp;nbsp;Chromium 貢獻後有了極大的優化：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ac6f49ebe496aed979d9f43c54652f8fc26.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Chrome 官方博客&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.chrome.com%2Fblog%2Fbetter-text-rendering-in-chromium-based-browsers-on-windows%3Fhl%3Dzh-cn&quot; target=&quot;_blank&quot;&gt;發文&lt;/a&gt;介紹了 Chromium 在 Windows 上改進文本渲染的技術細節。&lt;/p&gt; 
&lt;p&gt;以下是原文：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;雖然 Skia 在 Windows 上使用 DirectWrite 來實現某些功能（例如字體查找），但最終的文本光柵化實際上由 Skia 直接處理。用户反饋的「顏色過淡」問題的一個主要原因是文本渲染的內部對比度和伽瑪設置。&lt;/p&gt; 
 &lt;p&gt;我們發現 Edge 基於 Chromium 的引擎與其之前的引擎在文本對比度和伽瑪值方面存在兩個主要差異。首先，Skia 不會從&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Ftypography%2Fcleartype%2F&quot; target=&quot;_blank&quot;&gt;Windows ClearType Tuner&lt;/a&gt;&amp;nbsp;中提取文本對比度和伽瑪值。其次，它使用的文本對比度和伽馬值默認值與 Edge 基於 DirectWrite 的文本堆棧使用的值不同。&lt;/p&gt; 
 &lt;p&gt;去年，Edge 團隊添加了直接在 Chromium 中遵循 ClearType 調諧器值的支持。這樣一來，基於 Chromium 的瀏覽器用户便可在 Windows 上控制文本對比度和伽瑪設置。雖然這是朝着正確方向邁出的一大步，但大多數用户往往不會調整系統級文本對比度和伽瑪設置。因此，我們在該過程中的下一階段是認真考慮調整 Web 和瀏覽器界面文本內容的默認文本對比度和伽瑪設置。&lt;/p&gt; 
 &lt;p&gt;更改網頁上文本的外觀是一項艱鉅的任務。網絡一直以文字為主，因此需要高質量的文本引擎。很明顯，文本對比度值需要提高，但需要數據來確定調整幅度。&lt;/p&gt; 
 &lt;p&gt;Edge 團隊早在 2021 年就開始嘗試使用各種文本對比度值。經過大量的用户研究，Edge 和 Chromium 團隊成員確定，對比度值為 1.0 與 Chromium 之前的 Edge 的文字渲染非常接近，並且與其他原生 Windows 應用相比，看起來也一致。&lt;/p&gt; 
 &lt;p&gt;Edge 團隊認為，我們的研究和實驗對 Windows 上的整個 Chromium 社區都有益，因此我們與 Google 的 Chrome 團隊分享了我們的研究成果，後者通過自己的實驗證實了這些成果。然後，我們繼續為 Windows build 默認啓用新的對比度值，從 Chrome&amp;nbsp;132 開始。&lt;/p&gt; 
 &lt;p&gt;如今，Windows 上所有基於 Chromium 的瀏覽器用户都可以受益於過去幾年間分享的研究、實驗和實現成果。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;p&gt;相關閲讀：&lt;a href=&quot;https://www.oschina.net/news/284600/microsoft-is-improving-chromes-font-rendering&quot; target=&quot;news&quot;&gt;微軟改進 Chrome 在 Windows 11 和 10 上的字體渲染&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333687/better-text-rendering-in-chromium-based-browsers-on-windows</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333687/better-text-rendering-in-chromium-based-browsers-on-windows</guid>
            <pubDate>Fri, 14 Feb 2025 03:53:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Google Gemini 上線「全局記憶」功能：可回憶曾經所有對話</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣佈其人工智能平台 Gemini AI 上線了一項備受期待的「全局記憶」功能，也就是 AI 能記得用户曾經與其進行過的所有對話，號稱可以為用户提供更加私人化的回覆。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0214/112144_KrRA_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，用户需要訂閲 Gemini Advanced 服務才能在 Gemini App 和網頁端體驗相關功能，當下暫時僅支持英語，未來幾周內將支持其他語言。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cc24594d22d9658b1e011f67e233c0767cc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;谷歌表示，用户目前不再需要通過「跳轉到此前進行的對話歷史記錄」即可承接上一次對話，與 AI 交流，AI 將會記得用户與其進行的每一次對話。&lt;/p&gt; 
&lt;p&gt;此外，用户還可以要求 Gemini 總結此前所有的對話內容，並在此前的分析基礎上進行進一步的討論。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;而在隱私方面，用户可以隨時通過在 Gemini 應用的右上角選擇個人資料卡，然後選擇「Gemini 應用活動」，即可查看、刪除和管理自己的 Gemini 聊天記錄。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333683</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333683</guid>
            <pubDate>Fri, 14 Feb 2025 03:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>崑崙萬維發佈 Matrix-Zero 世界模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;崑崙萬維宣佈正式推出 Matrix-Zero 世界模型，「成為中國第一家同時推出 3D 場景生成、可交互視頻生成模型的探索空間智能的企業」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Matrix-Zero 世界模型包含兩款子模型：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;3D 場景生成大模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持將用户輸入的圖片轉化為可自由探索的真實合理的 3D 場景，比 World Labs 生成場景的探索範圍更大更自由，而且包括動態物理效果。具備全局一致性、可自由探索、支持不同風格圖片輸入、支持風格遷移、支持動態場景生成等亮點。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;249&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-676593f09c278dafbcb923867657ab4f220.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;可交互視頻生成大模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;提供以用户輸入為核心驅動的可交互空間智能視頻生成方案，支持根據用户實時輸入生成互動視頻效果，具備更精準控制的 action model。&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;該方法能夠在保證開放領域視頻生成能力的同時，進一步增強對視頻內容中視角移動的精確控制，使其更加符合用户的交互需求和預期。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;145&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9c9b6299fba1b6c71eaa1d338109a6c9392.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;144&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46f86265b47b66372c3902267c7e2d11eca.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Matrix-Zero 世界模型預計 4 月份上線。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333681</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333681</guid>
            <pubDate>Fri, 14 Feb 2025 03:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Google I/O 2025 已定檔，議程涵蓋 Android 系統優化、Gemini AI 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣佈 Google I/O 2025 將於 5 月 20 日至 21 日舉行，議程涵蓋&lt;strong&gt; Android 系統優化、Gemini AI 模型、Project Astra AI 助手、Veo 生成式 AI 視頻模型及開發工具升級&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;為提升參與度，谷歌計劃通過線上直播與線下分會場聯動，擴大覆蓋範圍。線上將面向所有人開放，線下活動地點則是在美國加利福尼亞州的山景城。&lt;/p&gt; 
&lt;p&gt;據消息透露，首日主題演講可能發佈下一代 Tensor G4 芯片及 Pixel 9a。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c53d559040fa01401d901d4e4edd21dfbbe.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Google I/O 2025 官網已上線：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fio.google%2F2025%2F&quot; target=&quot;_blank&quot;&gt;https://io.google/2025/&lt;/a&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，微軟 Build 2025 大會也於同期舉行：5 月 19-22 日。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333679/google-io-2025-kicks-off-on-may-20</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333679/google-io-2025-kicks-off-on-may-20</guid>
            <pubDate>Fri, 14 Feb 2025 03:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>馬斯克：Grok 3 強到令人害怕，將超越市面上所有公開發布的模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 13 日消息，在迪拜世界政府峯會上，馬斯克通過視頻通話的方式披露，&lt;strong&gt;Grok 3 將在大約一到兩週內發佈，目前正處於最後的準備階段。而這個模型的強大程度，用他的話説，&quot;強到讓人感到害怕&quot;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a934a5f7bb74c67cd7003198702669a5038.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&quot;Grok 3 具備非常非常強大的推理能力。根據我們迄今進行的測試，&lt;strong&gt;Grok 3 的表現超過了我們所知的任何已發佈的模型&lt;/strong&gt;。&quot;馬斯克在對話中表示，&quot;有時，它的強大甚至讓人感到可怕，能想出一些完全出乎意料而又切中要害的解決方案。&quot;&lt;/p&gt; 
&lt;p&gt;他強調，Grok 3 採用了最大規模的算力和大量合成數據進行訓練，這些都將幫助它在各方面超越現有模型。更引人注目的是，馬斯克甚至預言這可能是&quot;最後一次有 AI 比 Grok 更優秀&quot;。在他看來，Grok 3 不僅將重新定義 AI 的上限，更可能成為 AI 發展史上的一個重要轉折點。&lt;/p&gt; 
&lt;p&gt;xAI 將自身定位為 OpenAI 和谷歌等行業領導者的競爭對手，已投入巨資用於計算資源，使用約 10 萬張 Nvidia H100 GPU 訓練 Grok 3。這一強大的基礎設施支撐了其在推理、編程能力以及文本和圖像分析等多模態功能方面的改進。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333677/musk-says-grok-3-final-stages-outperforming-all-chatbots</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333677/musk-says-grok-3-final-stages-outperforming-all-chatbots</guid>
            <pubDate>Fri, 14 Feb 2025 03:05:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>庫克官宣 2 月 19 日發佈新品，外界猜測是全新 iPhone SE 4</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 14 日 0 點，蘋果 CEO Tim Cook &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Ftim_cook%2Fstatus%2F1890068457825394918&quot; target=&quot;_blank&quot;&gt;在社交平台宣佈&lt;/a&gt;&lt;/u&gt;，蘋果將在 2 月 19 日發佈新產品。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-16e2b840c58bf3949eb73394624b5ba8a26.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Tim Cook 配文「&lt;strong&gt;準備好好見見這個家庭的最新成員吧！&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;近期彭博社記者 Mark Gurman 發文透露，iPhone SE 4 將在下週發佈。因此 2 月 19 日發佈的新品，或為上述所説的 iPhone SE 4。隨後，Mark Gurman 轉發了 Tim Cook 的信息，並表示「家庭新成員」或暗示着&lt;strong&gt;蘋果將要進行品牌重塑&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在預熱視頻公佈後，有不少網友也猜測是否為新款 AirTag，但 Gurman 給予否認，並稱蘋果不會為了一個 29 美元的新配件製作預熱視頻。並且 Gurman 再次強調，該預熱視頻將會是 iPhone 新品的預告片。&lt;/p&gt; 
&lt;p&gt;外界普遍猜測，該新品可能是全新的 iPhone SE 4。據此前傳聞，iPhone SE 4 或將迎來重大升級，包括 OLED 全面屏、Face ID、A18 芯片、USB-C 接口、8GB RAM、48MP 攝像頭，以及 Apple 自研 5G 調制解調器。此外新款 iPhone SE 4 的外觀設計看起來會更像 iPhone 14。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0214/105404_NVgk_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#999999&quot;&gt;▲ 網傳的 iPhone SE 4 機模&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;也有部分分析認為，本次發佈的新品可能是 M4 MacBook Air、M3 iPad Air 或第 11 代入門款 iPad。但彭博社記者 Mark Gurman 認為，iPhone SE 4 最有可能成為此次發佈的焦點。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333675/apple-teases-special-product-launch-coming-february-19</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333675/apple-teases-special-product-launch-coming-february-19</guid>
            <pubDate>Fri, 14 Feb 2025 02:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>抖音副總裁回應字節跳動抄襲案：美攝曾要求披露 TikTok 全部源代碼</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;2 月 13 日消息，美攝科技官微發佈聲明稱，美攝公司起訴字節跳動旗下抖音等 8 款產品代碼抄襲系列案，歷經三年七個月，終於迎來終審判決，且終審勝訴，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333557&quot;&gt;字節跳動被判賠 8266.8 萬元&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;判決判令抖音公司及其關聯公司立即停止侵害美攝 SDK 軟件著作權的行為，向美攝公司賠禮道歉，抖音公司及某員工立即停止侵害美攝公司技術秘密的行為。&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;據悉，2021 年 5 月，美攝公司發現抖音軟件的音視頻編輯處理等相關功能代碼大量抄襲美攝公司享有著作權的美攝 SDK 軟件，經進一步比對分析，美攝公司發現同屬於字節跳動旗下的剪映、巨量創意、Faceu 激萌、圖蟲、輕顏相機、多閃、火山引擎 VESDK 等產品也存在軟件代碼抄襲。&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;對此，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7965906915%2FPe7hNhg6f&quot; target=&quot;_blank&quot;&gt;抖音副總裁李亮回應稱&lt;/a&gt;&lt;/u&gt;，一名曾經在美攝工作過的工程師，離職兩年半後加入了字節。在字節工作期間，寫代碼時重複使用了一部分他在美攝工作時寫過的代碼（經司法鑑定，相關重複代碼佔比很小，不超過美攝軟件的 4%、抖音的 0.8%）。這種行為，屬於嚴重違規，公司是明令禁止的，目前該員工也已經離職。&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9598d0dbf07971e421eff82551bfa14faf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李亮表示：「&lt;strong&gt;在美國起訴時，美攝還要求字節披露 TikTok 的全部源代碼。這是我們無法接受的。我們曾多次和美攝溝通，願意向對方提供有誠意的賠償，但美攝卻提出了遠超過相關代碼實際價值的賠償訴求——僅在中國法院，美攝就提出了超過 20 億的索賠，最後法院支持了 8000 多萬。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;值得注意的是，李亮最新還補充了一個細節：美攝曾向美國法院申請打印 1215 頁 TikTok 源代碼。李亮表示：「這個是非常險惡的，不僅明顯超過了案件審理的必要，更可能導致整個 TikTok 的源代碼技術泄露。」&lt;/p&gt; 
&lt;p style=&quot;color:#31424e; margin-left:0; margin-right:0; text-align:start&quot;&gt;好在最後經律師抗辯，美國法院駁回了美攝的請求，並要求美攝補充具體的賠償依據，以及明確具體涉及什麼商業秘密。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333672</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333672</guid>
            <pubDate>Fri, 14 Feb 2025 02:34:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>百度宣佈將開源下一代文心大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;2&lt;/span&gt;月&lt;span&gt;14&lt;/span&gt;日，百度官方消息顯示，百度將在未來幾個月中陸續推出文心大模型&lt;span&gt;4.5&lt;/span&gt;系列，並於&lt;span&gt;6&lt;/span&gt;月&lt;span&gt;30&lt;/span&gt;日起正式開源。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;390&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0214/103039_F4FT_3820517.png&quot; width=&quot;678&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，百度推出多項&lt;span&gt;AI&lt;/span&gt;開放政策。&lt;span&gt;2&lt;/span&gt;月&lt;span&gt;13&lt;/span&gt;日，百度宣佈文心一言將於&lt;span&gt;4&lt;/span&gt;月&lt;span&gt;1&lt;/span&gt;日&lt;span&gt;0&lt;/span&gt;時起全面免費，所有&lt;span&gt;PC&lt;/span&gt;端和&lt;span&gt;APP&lt;/span&gt;端用户均可體驗文心繫列最新模型，以及超長文檔處理、專業檢索增強、高級&lt;span&gt;AI&lt;/span&gt;繪畫、多語種對話等功能。&lt;/p&gt; 
&lt;p&gt;據介紹，隨着文心大模型的迭代升級，其訓練和推理成本正在迅速下降。不久前，百度創始人李彥宏在迪拜&lt;span&gt;AI&lt;/span&gt;峯會上表示，當前的創新速度比以往快得多，大模型的推理成本每年能降低&lt;span&gt;90%&lt;/span&gt;以上，並表示將持續投入&lt;span&gt;AI&lt;/span&gt;基礎設施，以打造下一代大模型。&lt;/p&gt; 
&lt;p&gt;此前據外媒爆料稱，百度計劃在今年發佈多款模型，並於今年下半年推出文心大模型&lt;span&gt;5.0&lt;/span&gt;，將在模型多模態能力方面有顯著增強。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333670</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333670</guid>
            <pubDate>Fri, 14 Feb 2025 02:31:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
    </channel>
</rss>