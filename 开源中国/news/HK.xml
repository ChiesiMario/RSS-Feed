<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 26 Mar 2025 07:38:44 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>eCapture(旁觀者) v1.0.0 穩定版發佈，基於 eBPF 的高級網絡工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;eCapture(旁觀者) v1.0.0 穩定版&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgojue%2Fecapture%2Freleases%2Ftag%2Fv1.0.0&quot; target=&quot;_blank&quot;&gt;已正式發佈&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;eCapture 的中文名字為&lt;strong&gt;旁觀者&lt;/strong&gt;，即「&lt;strong&gt;當局者迷，旁觀者清&lt;/strong&gt;」，與其本身功能&lt;strong&gt;旁路、觀察&lt;/strong&gt;契合，且發音與英文有相似之處。eCapture 使用 eBPF&lt;code&gt;Uprobe&lt;/code&gt;/&lt;code&gt;Traffic Control&lt;/code&gt;技術，實現各種用户空間/內核空間的數據捕獲，無需改動原程序。主要功能包括：捕獲 OpenSSL、GnuTLS 的密鑰、明文通訊，支持 HTTP/3 QUIC、IPv6、TLS 1.3 等。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/img/202302/09154101_B1A8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60aea15bc5808d382bb0ad14222bf64ab66.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;憑藉其強大的功能和豐富的特性，eCapture 已成為網絡調試和安全分析領域的重要工具。自 2022 年 3 月發佈至今三年，累計收穫 1.4 萬顆星。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;v1.0.0 版本更新內容如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增功能&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;支持 Docker 鏡像，簡化部署和使用。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增對 OpenSSL 3.4.0 和 GnuTLS 的密鑰捕獲支持。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;支持 IPv6 數據包捕獲，擴展網絡協議支持。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;增加 Zsh 命令審計功能，提升安全監控能力。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;關鍵修復&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;修復 Ubuntu 24.04 系統上初始化腳本的兼容性問題。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;解決 ARM64 版本無法正常工作的問題。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;優化構建過程，提升整體穩定性和性能。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgojue%2Fecapture%2Freleases%2Ftag%2Fv1.0.0&quot; target=&quot;_blank&quot;&gt;https://github.com/gojue/ecapture/releases/tag/v1.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341096/ecapture-v1-0-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341096/ecapture-v1-0-0</guid>
            <pubDate>Wed, 26 Mar 2025 07:28:05 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>清華大學開源 Video-T1：無需重新訓練 AI 視頻秒變高清大片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;清華大學的研究團隊近日開源了其最新的研究成果——Video-T1。這項技術的核心在於測試時縮放 （Test-Time Scaling， TTS），旨在通過在視頻生成過程的推理階段投入更多的計算資源，顯著提升生成視頻的質量和與文本提示的一致性，而無需重新進行昂貴的模型訓練。這一創新性的方法為視頻生成領域帶來了新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;何為「測試時縮放」?&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在大型語言模型 （LLMs） 領域，研究人員已經發現，通過在測試階段增加計算量可以有效提升模型性能。Video-T1 借鑑了這一思路，並將其應用於視頻生成領域。簡單來説，傳統的視頻生成模型在接收到文本提示後，會直接生成一段視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;而採用了 TTS 的 Video-T1，則像是在生成視頻的過程中進行多次「搜索」和「篩選」，&lt;strong&gt;通過生成多個候選視頻，並利用「測試驗證器」進行評估，最終選擇質量最高的視頻&lt;/strong&gt;。這就像一位精雕細琢的藝術家，在完成最終作品前會嘗試多種不同的方法和細節。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的核心技術&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 並沒有直接增加訓練成本，而是專注於如何更有效地利用現有模型的能力。其核心方法可以理解為在模型的「噪聲空間」中尋找更優的視頻生成軌跡。為了實現這一目標，研究團隊提出了兩種主要的搜索策略:&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;隨機線性搜索 （Random Linear Search）&lt;/strong&gt;:這種方法通過&lt;strong&gt;隨機採樣多個高斯噪聲&lt;/strong&gt;，讓視頻生成模型對這些噪聲進行逐步去噪，生成多個候選視頻片段，然後利用測試驗證器對這些候選視頻進行評分，最終選擇得分最高的視頻。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;幀樹搜索 （Tree-of-Frames， ToF）&lt;/strong&gt;:考慮到同時對所有幀進行全步去噪會帶來巨大的計算成本，ToF 採用了一種更高效的策略。它將視頻生成過程分為三個階段:首先進行&lt;strong&gt;圖像級別的對齊&lt;/strong&gt;，這會影響後續幀的生成;其次，在測試驗證器中使用&lt;strong&gt;動態提示&lt;/strong&gt;，重點關注&lt;strong&gt;運動的穩定性&lt;/strong&gt;和&lt;strong&gt;物理上的合理性&lt;/strong&gt;，並根據反饋指導搜索過程;最後，評估視頻的整體質量，並選擇與文本提示對齊度最高的視頻。ToF 這種自迴歸的方式能夠更智能地探索視頻生成的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;291&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a31db7613d8e9d4e81825607ee221dc4a49.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TTS 的顯著效果&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;實驗結果表明，隨着測試時計算量的增加（即生成更多候選視頻），模型性能會持續提升。這意味着，通過投入更多的推理時間，即使是同一個視頻生成模型，也能夠產生&lt;strong&gt;更高質量、與文本提示更加一致的視頻&lt;/strong&gt;。研究人員在多個視頻生成模型上進行了實驗，結果都顯示出 TTS 能夠穩定地帶來性能提升。同時，不同的測試驗證器關注的評估方面有所不同，因此在性能提升的速率和程度上也存在差異。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的 TTS 方法在常見的提示類別（如場景、物體）和容易評估的維度 (如圖像質量) 上取得了顯著的改進。通過觀察官方提供的視頻演示可以看出，經過 TTS 處理後的視頻在&lt;strong&gt;清晰度、細節和與文本描述的貼合度&lt;/strong&gt;上都有明顯的提升。例如，描述「戴着太陽鏡在泳池邊當救生員的貓」的視頻，在經過 TTS 處理後，貓的形象更加清晰，救生員的動作也更加自然。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;293&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-97931a836bd63018b344817d13e7d029863.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;挑戰與展望&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;儘管 TTS 在許多方面都帶來了顯著的進步，但研究人員也指出，對於一些難以評估的潛在屬性，例如&lt;strong&gt;運動的流暢性&lt;/strong&gt;和&lt;strong&gt;時序上的一致性&lt;/strong&gt;（避免畫面閃爍），TTS 的改進效果相對有限。這主要是因為這些屬性需要對跨幀的運動軌跡進行精確控制，而目前的視頻生成模型在這方面仍然面臨挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;清華大學開源的 Video-T1 通過創新的測試時縮放策略，為提升視頻生成質量提供了一種新的有效途徑。它無需昂貴的重新訓練，而是通過更智能地利用推理時的計算資源，讓現有模型煥發出更強的能力。隨着未來研究的深入，我們有理由期待 TTS 技術在視頻生成領域發揮越來越重要的作用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341094</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341094</guid>
            <pubDate>Wed, 26 Mar 2025 07:19:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>哥倫比亞大學研發 3D 光子電子芯片，突破 AI 數據傳輸瓶頸</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;美國哥倫比亞大學工程團隊與康奈爾大學工程團隊合作成功開發出全球首款&lt;strong&gt;三維集成光子-電子芯片&lt;/strong&gt;，實現了前所未有的效率和帶寬。&lt;/p&gt; 
&lt;p&gt;相關研究論文已於&amp;nbsp;3 月 21 日發表於《自然・光子學》上：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41566-025-01633-0&quot; target=&quot;_blank&quot;&gt;DOI:&amp;nbsp;10.1038/s41566-025-01633-0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-131d9e739b45c53af3cedf7d25d9ece622b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲&amp;nbsp;電氣工程教授 Keren Bergman，及電氣研究生、論文合著者 Michael Cullen&lt;/p&gt; 
&lt;p&gt;他們通過深度融合光子技術與先進的互補金屬氧化物半導體電子技術，讓這種新型三維光電子芯片實現了 800Gb/s 超高帶寬與 120 飛焦 / 比特的極致能效，帶寬密度達 5.3 Tb/s/mm² 遠超現有基準。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd9154017bb1eae29074e948da27f8417bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這項突破性的技術有望重塑 AI 硬件，使未來的智能系統能夠以更快的速度傳輸數據，同時顯著降低能耗，這對於智能汽車、大規模 AI 模型等未來技術至關重要。&lt;/p&gt; 
&lt;p&gt;Bergman 教授表示：「我們展示了一種能夠以空前之低的能耗傳輸大量數據的技術。這項創新突破了長期以來限制傳統計算機和 AI 系統數據傳輸的能源壁壘。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341093</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341093</guid>
            <pubDate>Wed, 26 Mar 2025 07:15:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>實戰案例｜利用 MarsCode 內置的 DeepSeek 服務，單元測試耗時縮短 70%！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt; 
 &lt;div&gt;
  資料來源:火山引擎-開發者社區
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;單元測試總在奇怪的地方卡 bug?Mock 配置像解謎遊戲、邊界條件比數學題還燒腦?&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;沒關係!&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;MarsCode 編程助手 X 三款大模型 (DeepSeek V3、DeepSeek R1、豆包大模型 1.5 ) 幫你解決所有問題&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;無需配置,性能 Top,代碼準確率嗖嗖🚀&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;用過的朋友都説: &amp;nbsp;「以前寫測試像開手動擋,現在像開了自動巡航」 ,速看~👇👇👇&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;準備工作&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;在正式開始單元測試之前,我們先做好相關準備👇&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;下載/更新 MarsCode 編程助手&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;1️⃣如果你是新用户,以 Visual Studio Code 中為例,打開 VSCode 擴展窗口,在搜索窗口搜索 MarsCode,找到 MarsCode 插件單擊「install」,完成安裝,登錄即可使用 MarsCode 編程助手。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//bb61802bbf0b2716f6eb17d4d9747c69.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;2️⃣ 如果你是老用户,請更新 MarsCode 編程助手到最新版本 (若開啓了自動更新,則將會自動更新),更新後重啓 IDE 即可&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;*VSCode:1.1.62&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;*JetBrains:1.2.1.15&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//2e3673113eb723c719b605eff5f273d0.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;克隆案例項目&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;本次案例使用的是 AI 生成的一個最基礎的 React 項目,目的是模擬學習工作中最真實的場景,方便大家迅速掌握快速搭建單元測試環境以及生成單元測試用例的技巧。&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;Bash&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;git clone https://github.com/ylx911229/unit-test\_back.git&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3f251e4916d77aa0bbf1a2576614fef2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;單元測試基礎&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;*因為後續案例選用的是 Jest 作為單元測試框架,所以介紹的基礎內容主要以 Jest 框架為標準&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 概念介紹&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;1️⃣ &amp;nbsp;斷言 (Assertion) :用於驗證測試結果是否符合預期的語句,如 &amp;nbsp;Expect&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;2️⃣ &amp;nbsp;測試替身 (Test Double) :用於替代真實依賴的模擬對象,確保測試的隔離性,如 Mock、Jest.fn&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;3️⃣ &amp;nbsp;測試覆蓋率 (Test Coverage) :用於衡量測試用例覆蓋代碼的比例,如 &amp;nbsp;行覆蓋率、分支覆蓋率&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 單元測試文件命名規範&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;生成的單元測試文件名必須以 &amp;nbsp;.test.ts/.test.js 作為結尾,否則單元測試框架無法讀取並執行單元測試用例&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 運行單元測試用例&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;Markdown&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;npx jest --coverage&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;實戰跟練&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;STEP1:搭建測試環境&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;首先來搭建一下單元測試的環境,向 MarsCode 輸入以下提示詞:&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;Markdown&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Workspace 幫我為整個項目搭建一下單元測試的環境&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//4fafd1f21b4a1da3a4bed7ac33ff92bb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;可以看到 MarsCode 給我們推薦的單元測試框架是 Jest,這是一個流行的 JavaScript 測試框架,特別適合用於單元測試。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;另外,React 組件的單元測試,依賴 React Testing Library ,RTL 是當前 React 生態中最流行的組件測試解決方案,它提供了一套更貼近真實用户行為的測試工具鏈。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;STEP2:單元測試用例編寫&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;關於單元測試用例,將從函數類和 UI 類等不同的方式類型來舉例實現&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 函數類&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;1️⃣ 純函數 &amp;amp; 工具類，對於純函數的工具類單元測試,特點是輸入輸出明確,無副作用,整體測試重點是，輸出格式驗證和唯一性檢查,接下來以 &amp;nbsp;生成唯一 ID 為例:&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;JavaScript&lt;br&gt; // 生成唯一 IDfunction generateId(prefix) {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return `${prefix}_${Math.random().toString(36).slice(2, 9)}`;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; }&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;我們可以打開 src\utils\tool-utils.js,選中代碼,在對話框直接選擇/test 功能形成單元測試:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//b292963df73b92bfc8c81623e0f56edd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;將生成的單測代碼另存為 tool-utils.test.js,保存後執行得到如下效果:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//489d226736d9e8bb924f738c2f589569.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;結果顯示覆蓋率 100%,但是有一個用例並未通過,顯示特殊字符作為前綴輸出的結果未匹配正則。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//ecadba9fe71617109a45ec338713590a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;我們可以切換到 DeepSeek R1 模型並選中文件,將出現的問題告訴 MarsCode 後將生成的代碼替換進原來的 tool-utils.test.js,再次運行 npx jest --coverage 可以發現問題已解決~&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//cc930e690fd58785b82d76d02456d3ed.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//1e653cde95e8dc07cf67a47efa647693.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;如果 test 代碼未運行成功出現報錯,可以將報錯內容複製給 MarsCode,利用 AI 問答繼續解決問題。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;2️⃣ 數據轉換 &amp;amp; 驗證&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;接下來以用户資料表單處理器為例,處理結構化數據或驗證規則,這則測試案例重點在於正常數據清洗 (trim、類型轉換)、異常輸入 (空值、非法郵箱、年齡不足)、 及錯誤消息準確性,打開 validate-utils.js,選擇生成單測:&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;JavaScript&lt;br&gt; // 轉換並驗證用户輸入&lt;br&gt; export const processUserInput = (formData) =&amp;gt; {&lt;br&gt; &amp;nbsp;const result = {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;name: formData.name.trim(),&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;age: parseInt(formData.age, 10),&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;email: formData.email.toLowerCase()&lt;br&gt; &amp;nbsp;};&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if (isNaN(result.age)) {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;throw new Error(&#39;Invalid age: must be a number&#39;);&lt;br&gt; &amp;nbsp;}&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if (!/^[\w.+]+@\w+\.\w+$/.test(result.email)) throw new Error(&#39;Invalid email&#39;);&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if (result.age &amp;lt; 18) throw new Error(&#39;Underage&#39;);&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return resu&amp;lt;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; }&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c552e3517b07469d83b30003ab69d025.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;同樣將 MarsCode 生成的單測代碼保存為 validate-utils.test.js 後運行,效果如下:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//126b9a3159de9d47e5c2e74f1bd140c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;3️⃣ 狀態管理 &amp;amp; 業務邏輯，現在我們來探討更復雜業務邏輯下的單測,以購物車 Redux reducer 為例,涉及核心業務規則或全局狀態變更,這個案例中我們的測試重點在&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 商品添加邏輯 (新增 vs 增量)&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 促銷碼有效性驗證&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 不可變數據檢查&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;JavaScript&lt;br&gt; // cartReducer 函數&lt;br&gt; export const cartReducer = (state = { items: [] }, action) =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;switch (action.type) {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;case &#39;ADD_ITEM&#39;:&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const existing = state.items.find(item =&amp;gt; item.id === action.payload.id);&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if (existing) {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;...state,&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;items: state.items.map(item =&amp;gt;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;item.id === action.payload.id&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;? { ...item, qty: item.qty + 1 }&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;: item&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;)&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;};&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;}&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return { ...state, items: [...state.items, action.payload] };&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;case &#39;APPLY_PROMO&#39;:&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if (!action.payload.isValid) return state;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return { ...state, promoCode: action.payload.code };&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;default:&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return state;&lt;br&gt; &amp;nbsp;}&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; }&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;現在打開 businuss-utils.js,同樣選中/test 生成單測:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//78358c9c9437c5eab38a47a03da9a02d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;將 MarsCode 生成的新文件保存為 businuss-utils.test.js,運行單測命令,得到如下效果:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//1895297e792887c9768a74d91fe920fc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;• &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; UI 類&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;我們以用户輸入花費金額的 REACT 組件為例,我們單測的重點在於事件是否能正確觸發以及 UI 是否能正常顯示,打開 react-test.jsx 文件:&lt;/p&gt; 
&lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; color:#000000; font-family:宋體; font-size:14px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; orphans:2; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt; &lt;p style=&quot;text-align:left&quot;&gt;JavaScript&lt;br&gt; import React from &#39;react&#39;;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; import { render, fireEvent } from &#39;@testing-library/react&#39;;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; import { CostInput } from &#39;./react-test&#39;;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; describe(&#39;CostInput Component&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;beforeEach(() =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp;jest.clearAllMocks();&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 設置全局變量&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;global.navigator = {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 傳入 navigator 的值&lt;br&gt; &amp;nbsp; &amp;nbsp;};&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;global.document = {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 傳入 document 的值&lt;br&gt; &amp;nbsp; &amp;nbsp;};&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;global.window = {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 傳入 window 的值&lt;br&gt; &amp;nbsp; &amp;nbsp;};&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;global.otherVariables = {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 傳入 otherVariables 的值&lt;br&gt; &amp;nbsp; &amp;nbsp;};&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;renders without crashing&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;calls handleChange when the input changes with valid number&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const handleChange = jest.fn();&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput handleChange={handleChange} /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;123&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(handleChange).toHaveBeenCalled();&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;does not call handleChange when the input is invalid&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const handleChange = jest.fn();&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput handleChange={handleChange} /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;abc&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(handleChange).toHaveBeenCalled();&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;displays the correct value with dollar sign&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;123&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;$123&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;displays empty value when input is invalid&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;abc&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;handles initial dollar sign correctly&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;$123&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;$123&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;handles empty input correctly&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;handles input with leading zeros correctly&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;00123&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;$123&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test(&#39;handles input with multiple dollar signs correctly&#39;, () =&amp;gt; {&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;const { getByLabelText } = render(&amp;lt;CostInput /&amp;gt;);&lt;br&gt; &amp;nbsp; &amp;nbsp;fireEvent.change(getByLabelText(&#39;cost-input&#39;), { target: { value: &#39;$$123&#39; } });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;expect(getByLabelText(&#39;cost-input&#39;)).toHaveValue(&#39;$123&#39;);&lt;br&gt; &amp;nbsp;});&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br&gt; });&lt;br&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8e0490033f69a9619fa83b95d8bb0958.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;向 MarsCode 輸入單測/test,同樣將生成的代碼另存為 react_tes t.test.js 進行運行,運行之後發現單測覆蓋率只有 62.5%,不太理想。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//719b640af82b736c7d837e2d77532f2e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;我們可以繼續讓 MarsCode 生成單測補充用例,提高覆蓋率&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//9faa93d333cbab05001d0e559633175b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;應，用代碼後,可以看到單測覆蓋率，提升到 83.33%,同時幫我們優化了部分代碼,甚至對原來的 handleChange 函數進行了優化,提升了代碼質量。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//39665a043dbe4f41f1b250acb91170f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;通過本次實踐,我們不僅掌握了單元測試的核心價值與實施方法,更驗證了 MarsCode 在提升代碼質量方面的工程價值。 相信在更復雜的業務場景下,優秀的工具能幫助開發者釋放更多生產力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341091</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341091</guid>
            <pubDate>Wed, 26 Mar 2025 07:14:05 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>OpenBao 獲採納為 EdgeX 的秘密存儲</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為增強安全性和開放性，EdgeX Foundry 正式將 OpenBao 作為 EdgeX 4.0 版本的默認秘密存儲。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EdgeX Foundry 是一個開源的 IoT/邊緣計算框架，由 Linux 基金會託管。它旨在通過靈活的微服務架構，實現設備、應用和服務之間的無縫通信。無論你在自動化、能源還是建築管理領域，EdgeX 都能以標準化的方式將一切連接起來。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;152&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1956e610d420b596ef4a166f66529a5a0b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前，EdgeX 主要依賴 HashiCorp Vault 安全存儲敏感信息。然而，隨着 Vault 轉向商業源許可證（BSL），EdgeX 社區選中了 OpenBao 作為未來的替代方案。OpenBao 是一個由社區驅動的開源項目，屬於 Linux 基金會。它提供基於身份的秘密和加密管理系統，確保敏感數據得到保護。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMZsyEUjRY2JkmfAaY9o-BA&quot; target=&quot;_blank&quot;&gt;指出&lt;/a&gt;，選擇 OpenBao 的原因包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;無縫遷移 – OpenBao 設計上與其上游 API 兼容，切換過程順利且無憂。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;開放和供應商中立的許可證 – 開源自由和長期社區合作。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;安全優先的方法 – 強加密和基於身份的訪問控制確保秘密安全。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;活躍的社區支持 – 專注團隊確保持續改進、安全更新和功能增強。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於已經在使用 EdgeX 的用户，這一變更幾乎不會造成影響。核心服務已更新以支持 OpenBao，同時保持與之前相同的 API，意味着幹擾最小。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341087</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341087</guid>
            <pubDate>Wed, 26 Mar 2025 07:05:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>頂尖 AI 專家齊國君自美歸國：加盟西湖大學、拿過華為總裁獎</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scmp.com%2Fnews%2Fchina%2Fscience%2Farticle%2F3303527%2Fai-expert-guo-jun-qi-leaves-us-china&quot; target=&quot;_blank&quot;&gt;根據《南華早報》的報道&lt;/a&gt;&lt;/u&gt;，屢獲殊榮的人工智能（AI）專家和計算機科學家齊國君在美國工作十幾年後，已回國加盟位於杭州的西湖大學領導 「MAPLE 實驗室」 團隊。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.westlake.edu.cn%2Ffaculty%2Fguojun-qi.html&quot; target=&quot;_blank&quot;&gt;據西湖大學官網介紹&lt;/a&gt;&lt;/u&gt;，齊國君，安徽合肥人，國際電氣和電子工程師協會會士（IEEE Fellow）、國際模式識別聯合會會士（IAPR Fellow）、國際計算機協會（ACM）傑出科學家，中國科學技術大學郭沫若獎得主。&lt;/p&gt; 
&lt;p&gt;齊國君課題組主要開展機器感知和學習方向的研究，致力於研發對虛實場景進行多模態感知、生成與交互的人工智能系統，並應用於多媒體計算、基於 AIGC 的智慧創作等領域。他在人工智能多模態算法與模型、智慧創作與虛擬現實等多個領域取得了多項開創性成果。已在相關國際會議與雜誌上發表論文共計 200 餘篇，引用近 20000 次。&lt;/p&gt; 
&lt;p&gt;西湖大學形容，通俗地講，齊國君可以被看做機器的 「養育者」，他開發模型，教機器能夠同時理解文字、圖片、音頻、視頻等多種媒介傳遞的信息，讓機器變得 「更智能」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/145658_Rof3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;從 2014 年到 2024 年，齊國君在美國做了十年研究，他先加入了 IBM T.J. Watson 研究中心擔任研究員，之後進入美國中佛羅裏達大學執教一年。然後離開美國中佛羅裏達大學，加入華為美國研究中心，擔任技術副總裁（Technical VP）和首席 AI 科學家（Chief AI Scientist）。&lt;/p&gt; 
&lt;p&gt;在華為美國研究中心，他主要負責華為雲 EI 智能體項目，主持設計 TrafficGo 智慧城市系統，優化整合了每天數億級的多模態數據，對 200 多個路口的複雜路況進行實時調控，極大提升了交通出行效率和應急事件處理速度，因此獲得華為總裁獎。&lt;/p&gt; 
&lt;p&gt;再然後，他去了 OPPO，一手創立了 OPPO 西雅圖研究中心，還是立足於多模態數據的處理，把研究的邊界往虛擬現實領域拓寬了一步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341086</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341086</guid>
            <pubDate>Wed, 26 Mar 2025 07:00:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>中國大模型密集開源，影響幾何？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年以來，中國大模型開源的消息一個接一個。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲通義千問從除夕夜開源全新的視覺模型 Qwen2.5-VL，再到本月初發布並開源了全新推理模型 QwQ-32B，在開源當日就登頂全球主流 AI 開源社區 Hugging Face 的趨勢榜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek(深度求索) 達成過「開源周」，其在 2 月末連續五天發佈五個代碼庫，並於近日繼續開源上線了升級後的 DeepSeek-V3 模型。 階躍星辰則在一個月左右時間開源三款多模態大模型，其最新開源的是圖生視頻模型 Step-Video-TI2V，支持生成的視頻具備運動幅度可控和鏡頭運動可控兩大核心特點，同時自帶一定的特效生成能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;為何開源大模型成為中國當前的發展潮流？FutureLabs 未來實驗室首席專家胡延平對中新社記者表示，大模型廠商普遍選擇開源，且有強勁的市場爆發力，是因為人工智能發展處在四個重要時刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是端側智能的需求崛起，包括個人單機部署 AI 方面的需求，推動端側智能快速發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;二是企業行業 AI 部署的需求驅動，千行百業 AI 需求激增，但通用雲端大模型難以滿足差異化的業務場景與數據隱私保護的需要。開源憑藉靈活性和定製化能力，成為企業實現差異化部署的首選，開源模型體現出隨需應變的明顯優勢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中新社記者獲取的數據顯示，截至 3 月 25 日，通義千問開源模型 Qwen 系列的全球下載量已超 2 億。通過千千萬萬的開發者和中小企業，通義大模型深入千行百業，包括醫療、教育、金融、電力、交通、計算機等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;三是 AI 產業生態化進入加速時刻，出現分工協作體系，上下游協作關係更為清晰。頭部企業聚焦模型能力強化，中小企業則基於開源模型開發細分場景應用，形成企業數量更大的產業腰部、大模型後市場，這是一個分工日趨明確的產業生態。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;四是 AI 大模型能力提升顯著，從「可用」進入「高可用」時刻，用户、應用由此進入爆發性增長時刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據中國工信部官方消息，目前，中國已成為全球開源參與者數量排名第二、增長速度最快的國家。另有數據顯示，阿里通義開源模型的衍生模型數量已突破 10 萬個，成為全球最大的開源模型族羣。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國大模型密集開源，影響幾何？&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中國科學院院士梅宏曾表示，大語言模型在未來需要像互聯網一樣，走向開源，由全世界共同維護一個開放共享的基礎模型，盡力保證其與人類知識的同步。否則，任何一個機構所掌控的基礎模型都難以讓其他機構用户放心地上傳應用數據，也就很難產生足以滿足各行各業業務需求的大量應用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;胡延平説，以通義千問為代表的中國大模型正藉助這一波開源大勢，縮小與全球領先 AI 技術的差距，最重要的是中國開源的生態化獲得極大成功，為今後發展積蓄了較強勢能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里雲高級總監朱迅垚認為，現在大家逐步認識到，開源模型將成為推動中國人工智能發展最強勁的引擎。下一步，建議從國家到地方再到企業，以更加積極的態度擁抱開源，同時在佈局智能算力、構建高質量數據集、上雲用雲等方面加快創新步伐，緊跟世界先進水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;有外媒近日報道稱，中國科技公司選擇開源路線，不僅是為了與同類型公司展開競爭，更是為了加速 AI 的採用和創新。開源模型降低了成本，為產品創新打開了大門。這一趨勢不僅將推動中國 AI 領域的快速發展，甚至可能縮短技術差距。&amp;nbsp;(中新社，記者，夏賓)&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341084</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341084</guid>
            <pubDate>Wed, 26 Mar 2025 06:57:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果花費約 10 億美元採購英偉達 AI 服務器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;蘋果公司曾公開宣稱其正在使用 Apple Silicon 服務器來支持&amp;nbsp;Apple Intelligence&amp;nbsp;的運行，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.investors.com%2Fnews%2Ftechnology%2Fapple-stock-apple-joins-ai-data-center-race%2F&quot; target=&quot;_blank&quot;&gt;但根據 Loop Capital 分析師 Ananda Baruah 的説法&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;該公司現在也在花費 10 億美元購買 NVIDIA 的 AI 服務器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;他在給投資者的一份報告中寫道： 「&amp;nbsp;AAPL 正式加入大型服務器集羣 Gen AI 遊戲，超微[Super Micro Computer] 和戴爾是關鍵的服務器合作伙伴。雖然我們仍在收集更全面的信息，但這似乎有可能成為 Gen AI LLM（大型語言模型）集羣。」&lt;/p&gt; 
&lt;p&gt;Baruah 聲稱，蘋果正在購買 250 台 NVIDIA NVL72 服務器，每台服務器的成本在 370 萬至 400 萬美元之間。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;梳理事件時間線如下：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 4 月：消息稱蘋果將使用自研芯片搭建 AI 服務器&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 6 月：消息稱蘋果數據中心將全面採用 Apple Silicon&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 9 月：蘋果軟件工程高級副總裁 Craig Federighi 公開確認，Apple Intelligence 服務完全運行在自研服務器上，稱這是「行業雲端處理新標準」。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2025 年 3 月：分析師披露蘋果訂購 250 台英偉達 NVL72 服務器，單台成本 370 萬至 400 萬美元（現匯率約合 2685.9 萬至 2903.7 萬元人民幣），總價近 10 億美元（現匯率約合 72.59 億元人民幣）。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;據 NVIDIA 稱，其 NVL72 服務器包含 36 個 Grace CPU 和 72 個 Blackwell GPU。該公司還表示，截至 2025 年 3 月 18 日，該服務器尚未上市。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4be572287f934556dc646afc95fcd6fca2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;毫無疑問，蘋果現在可以預訂服務器，而且該公司認為有必要擴大其服務器，這並不奇怪。從數量來看，這可能是為了開發目的，而不是面向公眾，但現在還無法判斷——這是假設報道是正確的。&lt;/p&gt; 
&lt;p&gt;如果它的目的不僅僅是開發，那麼這與 Federighi 的説法並不完全相符，他認為使用 Apple Silicon 服務器「為行業雲端處理樹立了新標準」。&lt;/p&gt; 
&lt;p&gt;他説：「在我們之前沒有 Apple Silicon 服務器的情況下，在數據中心構建服務器，並構建一個在數據中心運行的自定義操作系統，這是一項艱鉅的任務。」「[創建]信任模型，除非服務器正在運行的所有軟件的簽名已發佈到透明日誌中，否則您的設備將拒絕向服務器發出請求，這無疑是解決方案中最獨特的元素之一，並且對信任模型至關重要。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</guid>
            <pubDate>Wed, 26 Mar 2025 06:50:27 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DistilQwen2.5-R1 發佈：知識蒸餾助推小模型深度思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：蔡文睿（清素）、汪誠愚（熊兮）、嚴俊冰（玖燭）、黃俊（臨在）&lt;/p&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;隨着 DeepSeek-R1 和 QwQ-32B 等面向深度推理的大語言模型的開源，&quot;大模型+慢思考&quot;已成為拓展大語言模型智能邊界的標準配置。然而，這些模型在資源受限的移動設備和邊緣計算場景中的普及仍面臨巨大挑戰。因此，學術界和工業界迫切需要解決如何有效利用知識蒸餾技術，將這些超大規模深度推理模型的知識遷移到小模型中，從而提升計算效率並降低部署成本的問題。為此，我們在 DistilQwen2.5 系列蒸餾小模型（看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; target=&quot;_blank&quot;&gt;這裏&lt;/a&gt;）的基礎上，推出了更為強大的 DistilQwen2.5-R1 系列深度推理模型。&lt;/p&gt; 
&lt;p&gt;DistilQwen2.5-R1 系列以少量來自 DeepSeek-R1 的思維鏈蒸餾數據為基礎，通過一系列創新的蒸餾策略，有效強化了小模型的深度思考能力。實驗評估結果顯示，DistilQwen2.5-R1 系列中的多種小規模模型在各項基準測試中表現優異（見下圖）。例如，DistilQwen2.5-R1-7B 性能顯著超越了其他開源蒸餾模型，包括 OpenThinker-7B。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ef4e1a2e97f3cb673adaa04eb8d7d3ff.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//af944f244cb9a874812fd4148abf399f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為方便開發者和企業在實際應用中使用 DistilQwen2.5-R1 系列模型，其所有的 Checkpoint 已在 Hugging Face 和 Model Scope 開源社區中公開。本文將深入闡述 DistilQwen2.5-R1 的蒸餾算法、性能評估，並且提供在阿里雲人工智能平台 PAI 上的使用指南及相關下載教程。&lt;/p&gt; 
&lt;h1&gt;DistilQwen2.5-R1 中的知識蒸餾技術&lt;/h1&gt; 
&lt;p&gt;本節中，我們主要描述 DistilQwen2.5-R1 模型訓練中使用的數據增強與知識蒸餾技術。&lt;/p&gt; 
&lt;p&gt;由於自身參數量的顯著差異，大模型與小模型的認知與推理軌跡有時並不完全一致。以數學問題為例：對於有的數學問題，小模型由於自身參數量的限制，會傾向於使用更基礎的方法去解決問題。而大模型基於其強大的推理能力，會採用較為高階的方法。比如經典的雞兔同籠問題，小模型傾向於使用簡單枚舉法逐一試錯，而大模型會直接通過列方程的較高級方法求解。&lt;/p&gt; 
&lt;p&gt;正是由於大小模型的認知軌跡偏差，小模型有時無法有效理解大模型的思維鏈，此時如果直接該思維鏈（Chain-of-Thought，CoT）蒸餾到小模型中，往往效果不佳。為此，我們設計了一種小型推理模型訓練框架，以消除這種認知軌跡偏差帶來的負面影響。在後續訓練中，我們還利用這種偏差數據進一步提升小模型的推理能力，最終推出基於該訓練框架的 DistilQwen2.5-R1 系列模型。我們提出的訓練技術框架包含兩個階段：CoT 數據&quot;評價-改進-驗證&quot;機制，以及基於不同認知軌跡數據的偏好優化算法。總體而言，DistilQwen2.5-R1 模型蒸餾的詳細算法框架如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df8e195e8ebd7ef30667779a2dcb9f01.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;給定原始的大模型思維鏈數據集，例如從 DeepSeek-R1 蒸餾的數據集，在一階段，我們先對其進行數據難度評價，接着根據數據的難度等級對其進行相應的優化，優化之後還要對結果進行驗證。我們使用改進且被驗證的 CoT 數據集對模型進行 SFT 訓練，獲取模型的基礎推理能力。在二階段，我們利用一階段已有的不同難度的 CoT 數據構造偏好數據集，在一階段的基礎上進一步提升小模型的推理能力。&lt;/p&gt; 
&lt;h2&gt;CoT 數據&quot;評價-改進-驗證&quot;機制&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，大小模型間的認知推理軌跡有時存在顯著偏差。因此，對於待蒸餾的大模型思維鏈數據集，小模型無法完全理解。階段一正是基於這種認知偏差對數據集進行優化，採用了 LLM-as-a-Judge 的範式，對大模型的推理過程進行評價並改進。&lt;/p&gt; 
&lt;p&gt;給定問題、大模型的推理過程和問題的答案，我們使用模型判斷這個推理過程是簡單、中等還是困難。難度等級的核心標準是小模型是否能夠遵循給定的推理過程得到問題的答案。以下是思維鏈的難度等級及定義：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;中等： 小模型可以遵循該推理過程得到問題的答案。&lt;/li&gt; 
 &lt;li&gt;簡單： 給定的推理過程過於簡單，缺少小模型所需的必要步驟，導致大模型依賴其強大的推理能力解決問題，而小模型無法遵循該過程得到答案。&lt;/li&gt; 
 &lt;li&gt;困難： 給定的推理過程過於複雜或過於困難，導致小模型無法遵循該過程得到答案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基於一個大模型的問題與思維鏈集合，我們可以將其分為簡單、中等和困難三類。對於評級為中等的部分，我們予以保留。對於被評為簡單和困難的數據，我們使用模型對思維鏈進行改進。具體來説：對於簡單部分，我們擴展其推理過程，直至小模型可以遵循擴展的過程得到答案。對於評級為困難的部分，我們精簡其推理過程，直至小模型可以遵循精簡的過程得到答案。&lt;/p&gt; 
&lt;p&gt;我們之後對改進結果進行進一步驗證，包括：對改進後的思維鏈再次評價難度等級，檢測其是否被歸類為中等難度，以及驗證小模型是否能夠遵循改進的思維鏈解決問題。如果改進後的思維鏈通過驗證，説明改進有效，該數據可以被小模型有效理解，我們將其保留。如果驗證不通過，説明改進無效，我們將返回到改進步驟，重新進行改進，直至通過驗證。最終，我們獲取了優化後的思維鏈數據集，其組成部分如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;初始難度評級為中等的數據。&lt;/li&gt; 
 &lt;li&gt;初始難度評級為簡單，經過改進擴展後評為中等並通過驗證的數據。&lt;/li&gt; 
 &lt;li&gt;初始難度評級為困難，經過改進精簡後評為中等並通過驗證的數據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此時，數據集內所有思維鏈的最終難度評級均為中等，意味着小模型可以有效理解數據集內的所有思維鏈，並能遵循這些思維鏈解決相應推理問題。上文提到的大小模型認知軌跡偏差問題在改進後的數據集中得到妥善解決，其可能帶來的負面影響也被消除。我們使用優化後的思維鏈數據集對 Qwen2.5 系列基座模型進行監督微調（SFT），得到 DistilQwen2.5-R1 系列模型的基礎結果。&lt;/p&gt; 
&lt;h2&gt;基於多種認知軌跡數據的偏好優化&lt;/h2&gt; 
&lt;p&gt;在第二階段，我們基於第一階段得到的不同難度等級數據對模型進行進一步提升。&lt;/p&gt; 
&lt;p&gt;具體來説，在第一階段中，評級難度為中等的思維鏈數據是正確且適合小模型的思維鏈，小模型能夠有效理解該思維鏈並解決問題。而難度評級為簡單或困難的思維鏈數據依然是正確的思維鏈，只是不適合小模型。在此基礎上，我們使用模型將正確的推理過程改寫為一個錯誤的推理過程。錯誤的推理過程沒有邏輯性，且會誤導小模型，使得小模型完全無法遵循該錯誤的推理過程解決問題。&lt;/p&gt; 
&lt;p&gt;基於改寫得到的錯誤思維鏈，我們將其與簡單、中等和困難的思維鏈進行兩兩組合，組成多種偏好數據對。這些偏好數據對中有的偏差大，有的偏差小。基於不同種類的偏好數據對及其特點，我們分別使用針對性的參數配置，在第一階段模型的基礎上，採用 DPO 算法進一步優化小模型的推理能力。&lt;/p&gt; 
&lt;p&gt;最終，我們利用第一階段得到的不同難度等級的認知軌跡（思維鏈）數據以及基礎模型結果，得到了 DistilQwen2.5-R1 系列模型。&lt;/p&gt; 
&lt;h1&gt;DistilQwen2.5-R1 模型效果評測&lt;/h1&gt; 
&lt;p&gt;在本節中，我們從多個角度評測 DistilQwen2.5-R1 系列蒸餾小模型的實際效果；同時，我們將 DistilQwen2.5-R1 系列模型和當前業界的前沿模型對比效果。&lt;/p&gt; 
&lt;h2&gt;模型綜合能力評測&lt;/h2&gt; 
&lt;p&gt;我們在多個模型推理能力評測基準上測試了 DistilQwen2.5-R1 系列模型的能力，涵蓋數學、代碼和科學問題三個主流推理領域。&lt;/p&gt; 
&lt;p&gt;在數學領域，我們使用 AIME2024 和 MATH-500 這兩個基準進行測試，AIME2024 是美國數學邀請賽的 2024 年測試集，包含 30 道高難度數學題，用於評估大語言模型在複雜數學推理和問題解決能力，尤其考察代數、幾何等領域的綜合應用。MATH-500 是一個數學推理能力的基準測試，包含 500 個測試樣本，旨在全面考察模型在數學解題上的能力。它與 AIME2024 類似，但有其獨特的測試目標和對比結果，用於衡量模型在不同數學題目上的準確性。&lt;/p&gt; 
&lt;p&gt;在代碼領域，我們使用 LiveCodeBench 基準，LiveCodeBench 是一個動態更新的基準測試平台，用於全面評估大型語言模型在複雜編碼場景中的能力。它通過從頂級競賽平台收集高難度編程任務來測試模型的代碼生成、自我修復代碼執行和測試等能力，是一個綜合性、無污染的評價基準。在本次評測中，我們使用 LiveCodeBench 基準的 V2 版本，其包含 2023 年 5 月-2024 年 5 月的 511 個代碼問題。&lt;/p&gt; 
&lt;p&gt;在科學問題領域，我們使用 GPQA-Diamond（Grade-Level Problems in Question Answering Diamond）基準，其由紐約大學、CohereAI 及 Anthropic 的研究人員聯合發佈，包含 198 條結果，是 GPQA 系列中最高質量的評測數據，用於評估模型解決專家級科學問題的能力。&lt;/p&gt; 
&lt;p&gt;如下圖所示，DistilQwen2.5-R1 系列模型在 3B、7B、14B 和 32B 四個參數量級的模型中，與原始 Qwen2.5 模型的效果進行了對比。可以看出，本文描述的小型推理模型訓練框架顯著提升了現有語言模型的推理能力，並在多個評測基準上取得了一致而明顯的效果提升。&lt;/p&gt; 
&lt;p&gt;| AIME2024 實驗結果對比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//207b970abad48f4d17f71e0d222d2f8e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | MATH-500 實驗結果對比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//1056c98b3384267199dea8c9af2ea521.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | --- | --- | | GPQA Diamond 實驗結果對比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9a42d598276ac93534537cecbe86b9d5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | LiveCodeBench V2 實驗結果對比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b971800722e3b79bcf1d45428aa572a3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; |&lt;/p&gt; 
&lt;h2&gt;與其他模型能力對比&lt;/h2&gt; 
&lt;p&gt;為了橫向比較同期發佈的不同參數規模的推理模型效果，下表分別是 DistilQwen2.5-R1 系列模型在各個參數量級上與其他前沿推理模型在上文提到的 4 個基準的評測結果。我們重點對比了 DistilQwen2.5-R1 系列與 OpenThinker、DeepSeek-R1-Distill-Qwen 等系列模型。&lt;/p&gt; 
&lt;p&gt;以下是 7B 量級的對比結果，可以看出，DistilQwen2.5-R1-7B 模型超越了 Bespoke-Stratos-7B 和 OpenThinker-7B。值得注意的是，相較於 OpenThinker-7B，DistilQwen2.5-R1-7B 在使用更少訓練數據的情況下在所有基準上達到了更高的結果。DeepSeek-R1-Distill-Qwen-7B 使用了 800k 閉源訓練數據，而 DistilQwen2.5-R1-7B 使用了開源數據進行訓練（OpenThoughts 數據集過濾和改寫得到的子集），在基於開源數據模型領域內處於領先地位。&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;模型&lt;/strong&gt; | &lt;strong&gt;訓練數據量&lt;/strong&gt; | &lt;strong&gt;AIME2024&lt;/strong&gt; | &lt;strong&gt;MATH-500&lt;/strong&gt; | &lt;strong&gt;GPQA Diamond&lt;/strong&gt; | &lt;strong&gt;LiveCodeBench V2&lt;/strong&gt; | | --- | --- | --- | --- | --- | --- | | &lt;em&gt;DeepSeek-R1-Distill-Qwen-7B (reported)&lt;/em&gt; | &lt;em&gt;800k&lt;/em&gt; | &lt;em&gt;55.5&lt;/em&gt; | &lt;em&gt;92.8&lt;/em&gt; | &lt;em&gt;49.1&lt;/em&gt; | &lt;em&gt;-&lt;/em&gt; | | Bespoke-Stratos-7B (reported) | 17k | 20.0 | 82.0 | 37.8 | 36.1 | | OpenThinker-7B (reported) | 114k | ++31.3++ | ++83.0++ | ++42.4++ | ++39.9++ | | **DistilQwen2.5-R1-7B ** | &lt;strong&gt;105k&lt;/strong&gt; | &lt;strong&gt;43.33&lt;/strong&gt; | &lt;strong&gt;88.4&lt;/strong&gt; | &lt;strong&gt;42.93&lt;/strong&gt; | &lt;strong&gt;46.38&lt;/strong&gt; |&lt;/p&gt; 
&lt;p&gt;以下是 32B 量級的對比結果。同樣地，DistilQwen2.5-R1-32B 在所有已知基準上超越了 Sky-T1-32B-Preview，以及在絕大多數基準上超越了 OpenThinker-32B。&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;模型&lt;/strong&gt; | &lt;strong&gt;訓練數據量&lt;/strong&gt; | &lt;strong&gt;AIME2024&lt;/strong&gt; | &lt;strong&gt;MATH-500&lt;/strong&gt; | &lt;strong&gt;GPQA Diamond&lt;/strong&gt; | &lt;strong&gt;LiveCodeBench V2&lt;/strong&gt; | | --- | --- | --- | --- | --- | --- | | &lt;em&gt;DeepSeek-R1-Distill-Qwen-32B (reported)&lt;/em&gt; | &lt;em&gt;800k&lt;/em&gt; | &lt;em&gt;72.6&lt;/em&gt; | &lt;em&gt;94.3&lt;/em&gt; | &lt;em&gt;62.1&lt;/em&gt; | &lt;em&gt;-&lt;/em&gt; | | Sky-T1-32B-Preview (reported) | 17k | 43.3 | 86.4 | 56.8 | &lt;em&gt;-&lt;/em&gt; | | OpenThinker-32B (reported) | 114k | ++66.0++ | ++90.6++ | ++61.6++ | &lt;strong&gt;68.9&lt;/strong&gt; | | &lt;strong&gt;DistilQwen2.5-R1-32B&lt;/strong&gt; | &lt;strong&gt;105k&lt;/strong&gt; | &lt;strong&gt;70.0&lt;/strong&gt; | &lt;strong&gt;93.8&lt;/strong&gt; | &lt;strong&gt;62.12&lt;/strong&gt; | ++65.95++ |&lt;/p&gt; 
&lt;h2&gt;模型多次推理評測&lt;/h2&gt; 
&lt;p&gt;我們還測試了 DistilQwen2.5-R1 系列模型在上文提到的四個基準上多次推理的結果，模型會對同一個問題生成 k 個回答進行評測，即 Pass&lt;a href=&quot;https://my.oschina.net/kaiprince&quot;&gt;@k&lt;/a&gt; 指標。以下是 DistilQwen2.5-R1-7B 和 DistilQwen2.5-R1-32B 在四個基準上 Pass@k 結果（k=2、4、8、16、32、64）。&lt;/p&gt; 
&lt;p&gt;可以看出，隨着模型推理次數 k 的逐步增加，兩個模型在所有基準上的評測準確率大幅提高。值得注意的是，隨着 k 的增加，DistilQwen2.5-R1-7B 在 MATH-500 和 GPQA-Diamond 上漲幅巨大，並且不斷逼近 DistilQwen2.5-R1-32B 水準。這表明我們的推理模型訓練框架在小模型領域內擁有巨大潛力。我們可以通過多次推理的方式使 7B 模型擁有媲美 32B 模型的能力，極大減少了推理所需的計算資源。&lt;/p&gt; 
&lt;p&gt;| &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ce3b51665de26ca24a5594370d2c0b98.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | --- | | &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d87903ad8d3726d0b56720b8f76f97a1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b7da22ba53431b02d34fff15a7cc1ac3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; |&lt;/p&gt; 
&lt;h2&gt;模型輸出&lt;/h2&gt; 
&lt;p&gt;對同一數學問題，我們對比了 DistilQwen2.5-R1 系列模型在 7B、32B 量級和同等量級模型的推理結果。從輸出結果可以看出，DistilQwen2.5-R1 系列模型在同量級推理模型中處於領先地位。&lt;/p&gt; 
&lt;h1&gt;模型下載和使用&lt;/h1&gt; 
&lt;h2&gt;DistilQwen2.5-R1 在阿里雲人工智能平台 PAI 上的實踐&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 庫為例，簡要介紹如何在 PAI-DSW 上使用 DistilQwen2.5-R1 模型。首先需要保證 PAI-DSW 鏡像內 transformers 版本大於等於 4.37.0，否則會在加載模型時報錯：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以 DistilQwen2.5-R1-7B 為例，我們可以使用如下代碼調用模型：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-7B&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;xxxxx&quot;
messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Your role as an assistant involves thoroughly exploring questions through a systematic long thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution. In the Thought section, detail your reasoning process using the specified format: &amp;lt;|begin_of_thought|&amp;gt; {thought with steps separated with &#39;\n\n&#39;} &amp;lt;|end_of_thought|&amp;gt; Each step should include detailed considerations such as analisying questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The solution should remain a logical, accurate, concise expression style and detail necessary step needed to reach the conclusion, formatted as follows: &amp;lt;|begin_of_solution|&amp;gt; {final formatted, precise, and clear solution} &amp;lt;|end_of_solution|&amp;gt; Now, try to solve the following question through the above guidelines:&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;DistilQwen2.5-R1 在開源社區的下載&lt;/h2&gt; 
&lt;p&gt;我們在 Hugging Face 和 Model Scope 上開源了我們蒸餾後的模型，分別為&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-3B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-3B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-7B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-7B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-14B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-14B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-32B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-32B&lt;/a&gt;。以 Hugging Face 為例，用户可以使用如下代碼下載這兩個模型：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-3B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-3B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-7B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-7B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-14B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-14B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-32B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-32B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;小結與未來工作&lt;/h1&gt; 
&lt;p&gt;本文介紹了 DistilQwen2.5-R1 系列深度推理模型，它在少量來自 DeepSeek-R1 的思維鏈數據基礎上，通過創新蒸餾策略增強了小模型的深度思考能力。實驗結果表明，該系列模型在多個基準測試中表現出色，尤其是 DistilQwen2.5-R1-7B 的性能全面超越了其他開源蒸餾模型。為了方便實際應用，這些模型的 Checkpoint 已在 Hugging Face 和 Model Scope 社區中公開，並提供了在阿里雲人工智能平台 PAI 上的操作指南。在未來，隨着大語言模型和知識蒸餾技術更進一步的發展，我們將推出各種領域、各種規格的 DistilQwen 系列模型，充分促進大語言模型在實際應用中的降本增效。&lt;/p&gt; 
&lt;h1&gt;參考資料&lt;/h1&gt; 
&lt;p&gt;相關發表論文&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/li&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;技術文章&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;DistilQwen2.5 發佈：通義千問蒸餾小模型再升級：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1653842&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DistilQwen2：通義千問大模型的知識蒸餾實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DistilQwen2 蒸餾小模型的訓練、評測、壓縮與部署實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;大語言模型數據增強與模型蒸餾解決方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;技術交流答疑羣&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fa60dfa833375be7ed5b66008fb94ed5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/18007679</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18007679</guid>
            <pubDate>Wed, 26 Mar 2025 06:45:27 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>XZ 5.8 發佈，後門災難事件以來的第一個主要功能版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;XZ 5.8 已於今天發佈，這是自去年 XZ 5.6 中由當時的項目共同維護者插入惡意後門以來的第一個值得關注的功能版本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8fa6112cc1cb312348b166e5bbe5bfa5805.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;XZ&amp;nbsp;5.6.2 於去年 5 月發佈，而 XZ 5.8.0 現已穩定，為這個無損數據壓縮器項目帶來了新功能。&lt;/p&gt; 
&lt;p&gt;對於為 x86 或 x86_64 架構構建的 liblzma，現在嘗試使用 SSE2 內在函數而不是 memcpy () 作為 LZMA/LZMA2 解碼器。使用這種 SSE2 內在函數可以將解壓時間縮短 5%。或者，如果針對 musl C 庫進行構建，這些 SSE2 內在函數可以將高度壓縮文件的時間縮短 15% 以上。&lt;/p&gt; 
&lt;p&gt;除了用於 liblzma 的 XZ 5.8 SSE2 內部函數之外，還有 CMake 構建系統更新、語言翻譯更新、針對 64 位 POWER 和 RISC-V 的改進的 LZMA/LZMA2 編碼器性能、重寫 x86_64 E2K CLMUL CRC 代碼以及其他優化。&lt;/p&gt; 
&lt;p&gt;XZ 5.8 更新現在由 Lasse Collin 管理，可以從官方&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftukaani.org%2Fxz%2F%23_source_packages&quot;&gt;XZ 項目網站&lt;/a&gt;下載。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341077/xz-5-8</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341077/xz-5-8</guid>
            <pubDate>Wed, 26 Mar 2025 06:40:05 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>誰是 AI 搜索先鋒？ Elastic 先鋒者招募令正式啓動！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#000000; text-align:left&quot;&gt;在人工智能 (正文簡稱「AI」) 技術深刻重構全球產業生態的當下,AI 搜索技術正以革新性力量驅動千行萬業智能化躍遷。值此技術變革關鍵節點,業界領先的搜索分析引擎 Elasticsearch 也迎來了自己 15 年的里程碑,Elastic 公司宣佈於 3 月 26 日在中國市場正式啓動&lt;strong&gt;「Elastic Pioneer」&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;先鋒者計劃&lt;/strong&gt;。這一計劃,是 Elastic 中國精心籌備的 Elastic 推廣大使招募項目,旨在匯聚社區開發者的力量,共同構建 AI 搜索技術應用新範式,加速企業數字化轉型進程。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8f5157fa18c7c0306c932fe4b22b2f3d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//60a3bb446c2dbbe00da59f5fe9c23310.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;AI 搜索，是現代化生活與企業發展的技術基石&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;通過創新的 AI 搜索技術,Elastic 持續為消費級與企業級市場提供創新解決方案。在消費領域,其技術矩陣已深度融入高頻生活場景:電商平台依託智能推薦算法引擎實現「千人千面」的精準商品匹配;本地生活服務系統通過聚合功能的實時行為分析技術快速定位用户偏好商户;智慧出行場景則藉助地理空間數據的分析能力,顯著提升交通效率並降低時間成本。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//e10ba4d92d23d6ed1f730691edeffe3f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;在企業數字化轉型進程中,Elastic Search AI Platform 憑藉其開放架構與生成式 AI 優化能力,成為驅動行業創新的核心引擎。金融領域通過實現數據管理現代化並實時交付數據,在增強安全性的同時為客户提供了個性化的無縫體驗;智能製造場景中,企業能夠將所有數據集中到同一框架,自動執行監測、加快根本原因分析並優化應用 Machine Learning 的運營,從而提高工作效率、加快創新速度;醫療保健行業藉助大規模數據見解,以改善患者護理,取得新的醫學發現,並保護嚴格監管的生態系統和數據。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;目前,Elastic 已獲得眾多《財富》500 強企業的信賴,助力客户在數據洪流中獲取高價值業務洞察。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//e21e6199ce0d7a8dec17a976b29fedbc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;開源共建&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;「&lt;/strong&gt;&lt;strong&gt;Elastic&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Pioneer&lt;/strong&gt;&lt;strong&gt;」&lt;/strong&gt;&lt;strong&gt;先鋒者計劃正式啓動&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;在 AI 搜索技術快速演進的今天,開源已成為推動行業發展的重要驅動力,而 Elastic 的成功正是依託於開發者和技術擁護者的熱情與支持。在 Elasticsearch 15 週年之際,Elastic 中國特別推出&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;「Elastic&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;Pioneer」&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;先鋒者計劃&lt;/strong&gt;(2025 年 3 月 26 日-2026 年 3 月 31 日),旨在招募熱愛 Elastic 搜索技術的夥伴擔任&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;Elastic 推廣大使——先鋒者&lt;/strong&gt;,助力 Elastic 在中國市場的蓬勃發展。作為 Elastic Pioneer,您將以多種方式傳播 Elastic 的技術魅力、分享產品的使用技巧。與此同時,您將獲得 Pioneer 積分,並可累積兑換專屬獎勵和榮譽認可,更有機會獲得直通 ElasticON 新加坡站門票,和 Elastic 原廠技術大咖面對面交流!&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3be02122d803b4703d71aa6126017291.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;階段一:貢獻內容,獲取 Pioneer 積分&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;Elastic 中國期待看到您以多種方式持續貢獻努力,並獲取相應積分:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;1.png&quot; height=&quot;319&quot; src=&quot;https://oscimg.oschina.net/oscnet//7ddad78b322c8f788d26f3c70968f00b.png&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;注:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;以上為參考得分,您提交的內容將由 Elastic 中國技術專家團隊審核並以實際內容質量打分。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;若您提交的內容已獲得廣泛影響力,將獲得額外積分獎勵。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;您的實際得分請以活動結束後榜單公佈為準。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;為保障本次活動公平、公開、公正進行,Elastic 保留持續更新並完善評分細則的權利。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;階段二:累積 Pioneer 積分,贏取月度榜單獎勵&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;通過累積 Pioneer 積分,您可以登榜&lt;strong&gt;月度先鋒者榮耀榜&lt;/strong&gt;,積分最高的前 10 名推廣大使可以兑換相應的稱號和獎勵,並獲得 Elastic 專屬紀念獎牌。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:center&quot;&gt;&lt;img alt=&quot;2.png&quot; height=&quot;253&quot; src=&quot;https://oscimg.oschina.net/oscnet//3c6a4acc3cda1de30fc1ebbe362e9163.png&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;注:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;Elastic 官方有權對先鋒者提交的內容進行二次加工、修改、傳播。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp;優秀內容將通過 Elastic 及合作伙伴官方賬號進行推廣分享。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;階段三:年度先鋒者巔峯對決,贏取 ElasticON 新加坡站門票&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;通過持續參與,您可以不斷積累 Pioneer 積分,在年末的&lt;strong&gt;年度先鋒者巔峯對決&lt;/strong&gt;中,積分最高的&lt;strong&gt;前 3 名&lt;/strong&gt;的先鋒者將成為「&lt;strong&gt;年度先鋒&lt;/strong&gt;」,並有機會獲得「&lt;strong&gt;直通 ElasticON 新加坡站門票 + 與 Elastic 原廠技術大咖面對面交流&lt;/strong&gt;」的資格。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;注:&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp; 月度先鋒者榮耀榜每月評選一次,積分次月重新計算並排行。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;●&amp;nbsp; &amp;nbsp; &amp;nbsp; 月度榜單的刷新規則和評選結果不影響年度積分持續累積。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:left&quot;&gt;&lt;strong&gt;Elasti&lt;/strong&gt;&lt;strong&gt;c 期&lt;/strong&gt;&lt;strong&gt;待與更多先鋒者攜手合作,共同構&lt;/strong&gt;&lt;strong&gt;建 AI 搜&lt;/strong&gt;&lt;strong&gt;索的廣闊未來&lt;/strong&gt;。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img align=&quot;left&quot; height=&quot;938&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0aa33f539141f57846751d3001f9a82b37.jpg&quot; width=&quot;650&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341075</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341075</guid>
            <pubDate>Sun, 23 Mar 2025 06:34:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>FaunaDB 將於 5 月停止服務，承諾開源核心技術版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;NoSQL 數據庫 FaunaDB 的供應商 Fauna &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffauna.com%2Fblog%2Fthe-future-of-fauna&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，由於缺乏支持和營銷數據庫服務所需的資金，它將在 5 月底關閉該服務。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「推動廣泛採用一種在全球範圍內以服務形式運行的新運營數據庫需要大量資金。在當前的市場環境下，我們的董事會和投資者已確定不可能單獨籌集實現該目標所需的資金。雖然我們將不再接受新客户，但現有的 Fauna 客户不會立即發生變化。我們將逐步讓客户退出 Fauna，並致力於確保未來幾個月內順利完成這一過程。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce52cf07537bfbb44698b63ccd43c383c6d.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該公司表示，所有 Fauna 企業客户都需要在太平洋時間 5 月 30 日中午之前將其應用程序和數據移出 Fauna。在此之後，所有 Fauna 帳户及其相關數據將被永久刪除。關閉運營的舉措預計將影響多家企業的 195 多個數據庫和 3,000 多個開發團隊。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Fauna 在通告中作出承諾，計劃在之後發佈 Fauna 核心數據庫技術的開源版本以及現有的開源驅動程序和 CLI 工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「這確保了 Fauna 的獨特功能（我們的事務功能、文檔關係數據模型和我們的數據庫語言 (FQL)）將可供社區使用。我們希望這既能成為數據庫從業者的寶貴參考，又能為更廣泛的開發者社區提供持續的價值。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Fauna 為受影響的客户提供了遷移期間的支持，詳情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.fauna.com%2Ffauna%2Fcurrent%2Fmigrate&quot; target=&quot;_blank&quot;&gt;遷移指南&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341068/the-future-of-fauna</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341068/the-future-of-fauna</guid>
            <pubDate>Sun, 23 Mar 2025 06:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 支持遠程 MCP 服務器部署</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Cloudflare&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fremote-model-context-protocol-servers-mcp%2F&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;&lt;/u&gt;，開發者現在可以在他們的平台上構建和部署遠程 MCP（模型上下文協議）服務器。這意味着你不再需要在本地電腦上運行這些服務器，而是可以把它們放到雲端，讓更多用户輕鬆訪問。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/142009_bpL3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 提供了四個核心組件，大大簡化遠程 MCP Server 的構建過程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;workers-oauth-provider&lt;/strong&gt;：簡化認證和授權&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;McpAgent&lt;/strong&gt;：處理遠程傳輸&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;mcp-remote&lt;/strong&gt;：允許現有 MCP 客户端連接到遠程服務器的適配器&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI playground&lt;/strong&gt;：作為遠程 MCP 客户端， 一個帶身份驗證的聊天界面，可直接連接遠程 MCP Server&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;想要開始構建自己的遠程 MCP 服務器？只需幾個簡單步驟：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;訪問 Cloudflare 的 MCP 服務器指南 -&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.cloudflare.com%2Fagents%2Fguides%2Fremote-mcp-server%2F&quot; target=&quot;_blank&quot;&gt;https://developers.cloudflare.com/agents/guides/remote-mcp-server/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用提供的模板創建你的第一個 MCP 服務器&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定義服務器功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署到 Cloudflare 的全球網絡&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;與 AI 助手連接&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;詳情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fremote-model-context-protocol-servers-mcp%2F&quot; target=&quot;_blank&quot;&gt;https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341063/remote-model-context-protocol-servers-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341063/remote-model-context-protocol-servers-mcp</guid>
            <pubDate>Sun, 23 Mar 2025 06:20:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>智源發佈關於被美國商務部列入實體清單的聲明</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;針對被美國商務部工業與安全局將北京智源人工智能研究院（簡稱「智源」）列入實體清單一事。&lt;/p&gt; 
&lt;p&gt;智源研究院發佈&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1Miy6dODbT0X0tAjG8tCpA&quot; target=&quot;_blank&quot;&gt;聲明稱&lt;/a&gt;，「我們對於民辦非營利科研機構被加入實體清單表示震驚，強烈反對這一毫無事實依據的錯誤決定，要求美國相關部門予以撤回。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;268&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ed2791aab0b687e1345f168830cb44ab87.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;智源作為非營利科研機構，一直堅持開源開放的原則，所有科研技術成果向全球公開共享，並積極參與 AI 安全國際對話，推動人工智能增進社會福祉。人工智能是人類公器，如同電力等所有重大技術革命一樣，開源開放是必然趨勢，智能時代是全人類共建共享的時代。美國商務部的行為違背科技創新精神，嚴重損害全球人工智能領域的開放合作。我們呼籲國際社會共同構建開放、包容、合作的技術未來。&lt;/p&gt; 
 &lt;p&gt;智源打造了覆蓋模型、算法、數據、評測、系統的大模型開源技術體系。截至目前，智源已累計開源約 200 個模型和近百個數據集，其中，模型全球總下載量近 6 億次，開源數據集下載量近 39 萬次，開源項目代碼下載量超 95 萬次，為人工智能技術普惠做出持續貢獻。&lt;/p&gt; 
 &lt;p&gt;智源將繼續堅持開源開放非營利的原則，向全球分享世界一流的大模型技術及人工智能領域的前沿探索，營造最佳的學術和技術創新生態，促進人類、環境和智能的可持續發展。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;相關閲讀：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/340997&quot; target=&quot;_blank&quot;&gt;特朗普政府將多家中國科技公司列入 「實體清單」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341061</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341061</guid>
            <pubDate>Sun, 23 Mar 2025 06:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>報告：開源解決方案繼續主導可觀測性策略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 最新發布的一份可觀測性調查報告&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrafana.com%2Fobservability-survey%2F&quot; target=&quot;_blank&quot;&gt;指出&lt;/a&gt;，75% 受訪者的表示他們在可觀測性工作中使用開源解決方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;30% 的受訪者表示他們只使用開源軟件，36% 的受訪者主要使用開源軟件。另一方面，8% 的受訪者只使用商業解決方案，16% 的受訪者主要使用商業解決方案，10% 的受訪者使用開源和商業解決方案的比例大致相等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;70% 的受訪者在某種程度上使用了 Prometheus 和 OpenTelemetry，一半的受訪者表示，他們對這兩項技術的投資在去年有所增加。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告還發現，組織仍然依賴日誌（Logging）和指標（Metrics），但追蹤（Traces）和配置文件（Profiles）越來越受歡迎。57% 的受訪者使用追蹤，16% 的受訪者使用配置文件，指標和日誌分別有 95% 和 87% 的人使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;123&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0ef509d2cbba28c981f44f12e8c64a7936.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公司還在其堆棧中利用了許多不同的可觀測性工具。Grafana Labs 發現，受訪者使用了 101 種不同的可觀測性工具，平均每家公司使用的工具數量為 8 種，比去年的平均 9 種有所下降。但是有 64% 的公司使用 5 種或更少的工具，只有 2% 的公司使用超過 50 種工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;規模較大的公司往往擁有更多的數據源，員工人數超過 5,000 人的公司平均擁有 24 個數據源，而員工人數不超過 10 人的公司平均擁有 6 個數據源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;對於組織來説，最大的可觀測性挑戰是複雜性，而警報疲勞（alert fatigue）是更快響應事件的最大障礙。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 發現，雖然可觀測性解決方案的成本是選擇可觀測性工具時最重要的因素，但它並不一定至關重要。不到三分之一的受訪者擔心可觀測性成本，大多數人只是想確保他們從所投資的工具中獲得價值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;選擇工具時的其他因素包括易用性、與其他工具的互操作性、是否開源、將來是否易於切換到其他工具、組織內部的熟悉程度以及 AI/ML 功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 首席技術官 Tom Wilkie 表示：「我們的 2025 年可觀測性調查證實，組織正在採用多元化、以開源為中心的可觀測性方法。隨着團隊管理的工具和數據源比以往任何時候都多，調查結果顯示覆雜性仍然是最大的挑戰。我們正在努力直接解決這些痛點，方法是增強 OpenTelemetry 和 Prometheus 等技術之間的互操作性，通過人工智能功能減少認知負荷，並提供開箱即用的集成解決方案，如 Kubernetes 監控。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341059/grafana-observability-survey</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341059/grafana-observability-survey</guid>
            <pubDate>Sun, 23 Mar 2025 06:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>【直播】AutoDev 即 MCP 服務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;p&gt;當我們想讓 AI 輔助開發的時候，不僅僅是想要讓它寫代碼，而是能像真人一樣自如地「使用各種工具」，比如 AI 生成代碼後，自動調用 Git 提交、觸發 Jenkins 構建，並通過 Docker 部署到測試環境，等等。&lt;/p&gt; 
 &lt;p&gt;但實際上，當前主流 AI 編程工具確實主要聚焦於 IDE 內部的代碼補全與建議功能，其核心能力基於當前編輯上下文進行代碼生成，無法直接操作構建工具（如 Maven/Gradle）、測試框架（如 JUnit）或部署系統等外部工具鏈。&lt;/p&gt; 
 &lt;p&gt;不過，有了 MCP&lt;span style=&quot;background-color:#ffffff&quot;&gt;（Model Context Protocol）&lt;/span&gt;，一切都不一樣了。&lt;span style=&quot;background-color:#ffffff&quot;&gt;MCP 是由 Anthropic 公司（Claude 模型） 推出的一個協議，它通過提供一種標準化的接口，LLM 應用就可以訪問外部信息、工具和資源。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Thoughtworks AI 輔助開發負責人&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;strong&gt;黃峯達花了一天時間，在 AutoDev 中實現了相關的功能&lt;/strong&gt;：即 AutoDev 作為一個 MCP 服務，可以被任何 Agent Tool 調用；AutoDev 作為一個 MCP 客户端，可以調用任何 MCP 服務。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c3e807d75bc0740ed7ca7429e859f6ad312.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;AutoDev 是一個開源的 AI 輔助研發插件，在 Intellij IDEA 等 IDE 中，提供了類似於 Cursor Composer、Windsurf 的 AI 程序員自動編程能力。&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;3 月 31 日晚，黃峯達將做客開源中國直播間——「OSC 開源社區」視頻號《技術領航》欄目，分享 &lt;/span&gt;AutoDev 如何輔助開發&lt;span style=&quot;background-color:#ffffff&quot;&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MCP 為什麼會改變 AI 輔助開發？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;第二代 AI IDE 的基本思路與架構，以及 AutoDev 的落地實現&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;實操演示：AutoDev 與 MCP 的雙向服務&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AutoDev 未來演進計劃，以及正在實現的新功能&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;微信掃碼，預約直播：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;715&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8329395a8e51db29496ab664de93d48c92.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播標題：&lt;/strong&gt;下一代 AI IDE：AutoDev x MCP 的雙向服務&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播時間：&lt;/strong&gt;3 月 31 日（週一 ）19:00-20:00&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;視頻號 「OSC 開源社區」&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播嘉賓：&lt;/strong&gt;黃峯達（Phodal）&lt;/p&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;嘉賓介紹：&lt;/strong&gt;黃峯達（Phodal），Thoughtworks AI 輔助開發與開源解決方案負責人，開源 Unit Mesh AI 輔助研發方案的發起人，包含 AI IDE 插件 AutoDev 等工具；智能體編程語言 Shire 的創始人，架構治理平台 ArchGuard 的核心開發者。他在生成式 AI 輔助需求分析、開發和質量保障方面為多家金融和互聯網企業提供落地支持，著有《前端架構：從入門到微前端》《自己動手設計物聯網》等多本書籍。&lt;/p&gt; 
   &lt;hr&gt; 
   &lt;div&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;另外，我們還建了一個交流羣，一起聊聊自己喜歡的開源項目～～當然啦，如果你有什麼特別棒的開源項目，可以推薦過來呀～&lt;/p&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e7c43c0b0553350855a379af00c6c7c15d.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;div&gt; 
     &lt;hr&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技術領航&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是開源中國 OSCHINA 推出的一檔直播欄目，旨在為&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;開源軟件、商業產品、前沿技術、知名品牌活動等各類項目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一個展示平台，每週五晚上開播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欄目邀請項目的創始人、核心團隊成員或資深用户作為嘉賓，通過路演式直播分享項目的亮點和經驗，有助於提高項目的知名度，吸引更多的用户和開發者關注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的項目，想要跟同行交流分享，歡迎聯繫我，欄目隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18006529</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18006529</guid>
            <pubDate>Sun, 23 Mar 2025 03:56:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>寶馬與阿里巴巴達成 AI 領域戰略合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;寶馬中國宣佈與阿里達成 AI 領域戰略合作，聚焦大語言模型等技術，阿里通義大模型將應用於中國市場的寶馬新世代系列車型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;326&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ae0f47ae0e235363ed9ac48a8bb6615d880.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據瞭解，基於阿里巴巴通義大模型，以斑馬元神 AI 為基礎，全新 BMW 智能個人助理採用與阿里巴巴共同開發的寶馬定製 AI 引擎，將於 2026 年率先搭載於中國生產的 BMW 新世代車型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其核心能力將包括擬人化溝通、多智能體協同及開放生態整合，能夠實現精準意圖捕捉、複雜指令解析、模糊語義理解及嚴謹邏輯推演，令互動體驗更加自然流暢。寶馬還將首次推出主動交互推薦功能，利用車內傳感器和攝像頭獲取到的數據進行分析，主動給予客户服務與關懷，比如當客户遺落個人物品在座位時系統將主動提醒乘客。上述 AI 技術和體驗將覆蓋寶馬全動力系統和全車型陣列，油電同智。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;日前，寶馬還發布中國 360 度全鏈 AI 戰略，包含 AI 聚焦提升用户體驗，AI 賦能業務流程提質增效，供應鏈合作共贏 3 大支柱和 AI 企業理念。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年 2 月，阿里巴巴還與蘋果公司達成合作，為國行版的 iPhone 用户提供 AI 功能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341045</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341045</guid>
            <pubDate>Sun, 23 Mar 2025 03:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>全新開源！邊緣設備也可運行的推理模型 RWKV7-G1 0.4B 正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2025 年 3 月 25 日，RWKV 基金會開源了一箇中低端設備也可以運行的推理模型（Reasoning Model）：&lt;strong&gt;RWKV7-G1&lt;/strong&gt; 0.4B。&lt;/p&gt; 
&lt;p&gt;RWKV7-G1 0.4B 具備其它同尺寸模型不具備的&lt;strong&gt;推理能力&lt;/strong&gt; ，同時還支持現實世界 100+ 種語言。在實際測試中，RWKV7-G1 0.4B 模型已經能夠完成難度較高的&lt;strong&gt;多語言和代碼任務&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV7-G1 0.4B 推理模型基於 World v3.5 數據集訓練。它比此前發佈的 RWKV7-G1 0.1B 更強，且性能超越了同參數量的 Transformer 架構模型。&lt;/p&gt; 
 &lt;p&gt;World v3.5 數據集包含更多小説、網頁、數學、代碼和 reasoning 數據，總數據為 5.16T tokens。我們隨機採樣了 2T token 的數據來訓練 RWKV7-G1 0.4B。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;我們也&lt;strong&gt;開源了 RWKV 模型端聊天 APP&lt;/strong&gt;，方便大家體驗 RWKV-7 模型。&lt;/p&gt; 
&lt;h2&gt;模型評測&lt;/h2&gt; 
&lt;h3&gt;英語和多語言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G1 0.4B 英語和多語言能力&lt;strong&gt;顯著領先&lt;/strong&gt;於同參數的開源模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;2025-03-25-RWKV7-G1-eval-en&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4b63fb9cda392c8b9c1ce4afb3b56cefbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;無法作弊的評測&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval&quot; target=&quot;_blank&quot;&gt;Uncheatable Eval&lt;/a&gt; 是&quot;無法作弊的評測&quot;，它使用最新的論文和新聞文章等實時數據，評估開源大語言模型的真實建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G1 0.4B 的 Uncheatable Eval 綜合得分&lt;strong&gt;在同參數規模的開源模型中處於領先地位&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV7-G1-Uncheatable-Eval&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d787fdf3f4b39c4b56fcf0b0ae0a310a2a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV7-G1 0.4B 甚至&lt;strong&gt;超越了部分 1.5B 模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV-7 G1 0.4B 超越部分 1.5B 模型&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-45b50e8249cb35497eeb008f29cb005c91e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;模型實測&lt;/h2&gt; 
&lt;h3&gt;多語言能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;RWKV7-G1 0.4B 的多語言能力比 G1 0.1B 更強。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下面是 G1 0.4B 把中文翻譯為英語和德語的推理過程和翻譯結果，&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;漢語到英語&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d19025d44d8f04737b5df32096e42e1f57d.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;漢語到德語&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f1b9a3ef2b3edb2b4e3589f201bd6a0a6f9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;Hugging Face Gradio Demo&lt;/a&gt; 體驗更多語言。&lt;/p&gt; 
&lt;h2&gt;代碼能力&lt;/h2&gt; 
&lt;p&gt;RWKV7-G1 0.4B 已經擁有能準確完成一些進階任務的能力，下面是使用 RWKV7-G1 0.4B 寫歸併排序的示例。 &lt;img alt=&quot;歸併排序&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c8d6c1459b4c9e3fe3dfff81e6647a6064.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;模型試用&lt;/h2&gt; 
&lt;p&gt;我們提供了多個在線 demo ，也提供移動端聊天 APP。&lt;/p&gt; 
&lt;h2&gt;在線 demo（續寫模式）&lt;/h2&gt; 
&lt;p&gt;可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;Hugging Face Gradio Demo&lt;/a&gt; 試用 RWKV7-G1 0.4B 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hugging Face Gradio Demo：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV G1 的整體 prompt 格式與 RWKV-7-World 模型類似，可選使用 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 標籤開啓 reasoning 功能：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我已經是全速前進了!

Assistant: &amp;lt;think&amp;gt;


&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;在線 demo（聊天模式）&lt;/h3&gt; 
&lt;p&gt;為了方便社區體驗 RWKV-G1 模型，我們也提供了&lt;strong&gt;聊天模式&lt;/strong&gt;的在線 demo。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hugging Face&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FRWKV-Red-Team%2FRWKV-LatestSpace&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/RWKV-Red-Team/RWKV-LatestSpace&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;魔搭 demo&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fstudios%2FRWKV-Red-Team%2FRWKV-LatestSpace%2Fsummary&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/studios/RWKV-Red-Team/RWKV-LatestSpace/summary&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可在此體驗已完成訓練的 RWKV-7 G1 0.1B 和 0.4B 模型，也可以切換到其他正在&lt;strong&gt;訓練中&lt;/strong&gt;的 G1 模型，如 G1 1.5B/2.9B。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;chat-demo&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3c5f79dcc16fccfaab0af74c3812b401026.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這個精美的 RWKV 對話界面由 RWKV 社區成員 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fleoncat.top%2F&quot; target=&quot;_blank&quot;&gt;@Leon&lt;/a&gt; 開發，並在 GitHub 倉庫 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSolomonLeon%2Fweb-rwkv-realweb&quot; target=&quot;_blank&quot;&gt;web-rwkv-realweb&lt;/a&gt;中開源。&lt;/p&gt; 
&lt;h3&gt;RWKV 端側聊天 APP&lt;/h3&gt; 
&lt;p&gt;我們也開發了處於內測階段的 RWKV 端側聊天 APP（Android 和 iOS 版本）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV-7 G1 0.4B 扮演朋友&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-73017fcfb107a314eab6b36f0bcd4a6bfc9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在下列地址下載 APP：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Android&lt;/strong&gt; : &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pgyer.com%2Frwkvchat&quot; target=&quot;_blank&quot;&gt;https://www.pgyer.com/rwkvchat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iOS (TestFlight)&lt;/strong&gt; : &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftestflight.apple.com%2Fjoin%2FDaMqCNKh&quot; target=&quot;_blank&quot;&gt;https://testflight.apple.com/join/DaMqCNKh&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;貫徹開源開放的宗旨，RWKV 端側聊天 APP 也已開源&lt;/strong&gt; ，在 GitHub &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMollySophia%2Frwkv_mobile_flutter&quot; target=&quot;_blank&quot;&gt;rwkv_mobile_flutter&lt;/a&gt; 倉庫中可以看到項目代碼。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;測試數據顯示：經過 NPU 優化後，RWKV-7 1.5B 模型在高通 8Gen3 手機芯片實現了 &lt;strong&gt;62 token/s&lt;/strong&gt; 的推理速度，G1 0.1B 模型的推理速度則高達 &lt;strong&gt;170 token/s&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型下載&lt;/h2&gt; 
&lt;p&gt;下載已完成訓練的 RWKV7-G1 0.1B/0.4B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下載其他訓練中的 RWKV7-G1 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Ftemp-latest-training-models%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/temp-latest-training-models/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社區：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Ftemp-latest-training-models%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/temp-latest-training-models/files&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;G1 模型發佈計劃&lt;/h2&gt; 
&lt;p&gt;當前已發佈 G1 0.1B/0.4B 模型，正在訓練 G1 1.5B/2.9B，具體發佈計劃如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;發佈計劃&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19b1612de03f0a59d6fb7a00335bad56ff4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們也在同時準備更大更優的數據集 &lt;strong&gt;World v3.7&lt;/strong&gt;，用於 G1 7B 訓練。&lt;/p&gt; 
&lt;h2&gt;llama.cpp 已適配 RWKV-7&lt;/h2&gt; 
&lt;p&gt;隨着 RWKV 社區開發者 Molly 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggml-org%2Fllama.cpp%2Fpull%2F12412&quot; target=&quot;_blank&quot;&gt;PR 被合併&lt;/a&gt;，llama.cpp 現已支持 RWKV-7 模型。&lt;/p&gt; 
&lt;p&gt;我們也會繼續向 llama.cpp 推送 RWKV-7 G1 模型的聊天模板，以支持 G1 模型，的推理（Reasoning）功能。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社區&lt;/h2&gt; 
&lt;p&gt;歡迎大家加入 RWKV 社區，可以從 RWKV 中文官網瞭解 RWKV 模型，也可以加入 RWKV 論壇、QQ 頻道和 QQ 羣聊，一起探討 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn&quot; target=&quot;_blank&quot;&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 論壇：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 頻道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 視頻教程：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933&quot; target=&quot;_blank&quot;&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;歡迎大家基於 RWKV-7 進行創業、科研，我們也會為基於 RWKV 的項目提供技術支持。&lt;/p&gt; 
 &lt;p&gt;如果您的團隊正在基於 RWKV 創業或開展研究，請聯繫我們！（在&quot;RWKV 元始智能&quot;微信公眾號留言您的聯繫方式，或發送郵件到&quot;contact@rwkvos.com&quot;。）&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341044</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341044</guid>
            <pubDate>Sun, 23 Mar 2025 03:50:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>直播間互動框架性能優化與穩定性實踐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;導讀&lt;/h1&gt; 
&lt;p&gt;直播間互動體驗框架技術實踐，揭秘性能與穩定性優化之道，快來探索吧！在百度直播間歌會紅包等活動中，我們創新性地將紅包互動與高質內容深度融合，通過技術架構升級與系統性優化，打造了&quot;音樂+紅包&quot;（邊聽歌邊搶紅包）的沉浸式體驗。本次實踐顯著提升了直播間的併發承載能力、實時互動響應速度和用户參與滿意度，同時沉澱出可複用的技術方案，為後續大型直播活動奠定堅實基礎。&lt;/p&gt; 
&lt;h1&gt;01&amp;nbsp;&lt;strong&gt;百度直播間歌會紅包運營活動介紹&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為提升直播內容質量和用户粘性，需注入多元化內容，增強直播間多樣性和觀賞性。同時，通過活動裂變擴大影響力，吸引特定用户羣體，保持用户新鮮感和期待感，為平台長期發展奠定基礎。&lt;/p&gt; 
&lt;p&gt;為落實直播歌會目標要求，需加快直播間互動體驗框架建設，探索新型混合模式和沉澱通用能力，着力適配重點業務場景，打造&quot;音樂+紅包&quot;的互動體驗，提升直播間品質：&lt;/p&gt; 
&lt;p&gt;一是通用基礎。主要包括組件複用、大圖壓縮等減少產物體積，頁面異常、性能、白屏監控，BFF 服務編排擴縮、穩定性監控等。&lt;/p&gt; 
&lt;p&gt;二是訪問保障。主要包括頁面多域名容災、開啓強緩存；字體、圖片、CSS、JS 等靜態文件單獨 CDN 強緩存域名，開啓多級緩存等。&lt;/p&gt; 
&lt;p&gt;三是紅包性能。主要包括頁面預靜態化、數據預加載、文檔預取、資源預取、視圖預渲染、動效降級等。&lt;/p&gt; 
&lt;p&gt;四是開發體驗。主要基於直播前端一站式，建強隊伍，確保項目開發流程規範統一，搭建增質增效的研發環境等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a06a28d331513eaca8f04e99d8cdeb0e87a.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;02 體積&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 頁面劃分&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在大型產品需求中，通過合理的頁面劃分策略，實現高效開發與維護。面對產品需求中羅列的多樣玩法功能和 19 種以上的紅包狀態，研發團隊面臨的首要挑戰是如何將這些功能合理的拆解成多個頁面承載。合理的頁面劃分不僅關乎用户體驗的流暢性，更是減小產物體積、提升跨頁面資源緩存利用率的關鍵。通過深入分析業務邏輯與用户行為路徑，我們精心設計了頁面邊界，確保每個頁面和組件都承載着唯一元素，同時避免了冗餘代碼的產生。此外，這一策略還極大地促進了開發團隊的協作效率，明確的頁面劃分減少了代碼衝突的可能性，使得團隊成員可以高效並行集成，從而加速了開發迭代週期。在直播間端能力的規範化構建上，同樣遵循了通用化這一原則。&lt;/p&gt; 
&lt;p&gt;在頁面劃分時，我們非常注重跨頁面資源的最優利用，通過策略性地緩存 HTML、CSS 和 JavaScript 等資源，確保一旦用户在任意時刻首次觸發了紅包彈出事件，這些資源即可被全面緩存，使用户在後續的頁面切換過程中無需再次加載這些核心資源。&lt;/p&gt; 
&lt;p&gt;通過一系列設計舉措，劃分多頁應用（MPA）10+個、單頁應用（SPA）20+個、紅包組件狀態（Component）19+個、規範化直播間端能力（Scheme）30+個，每一項都經過精心設計，共同作用於提升應用的整體性能，為用户帶來更加輕盈、快速且協同良好的使用體驗。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;性能優化&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會搶紅包運營活動中，Web 頁佔據了 80% 的比重，對於每一個依賴較多網絡資源的玩法頁面，在直播間中實現即時加載和快速展現確實面臨較大挑戰，尤其是在高併發、低延遲的場景下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d5e35a55efae3715032ff0e568633c1d733.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△頁面展現過程&lt;/p&gt; 
&lt;p&gt;為了有效應對這些挑戰，通過深入分析頁面展現過程中的各個環節，直播間互動框架提煉出七種通用的優化方案。旨在提升用户交互體驗、增強系統的整體性能。並確保直播間玩法在高併發場景下依然能夠流暢運行。這些優化方案覆蓋了從頁面加載、資源獲取到實時交互的各個方面，形成了一個全方位的性能提升樣板，具體方案如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-691f932fd36dd48901276bce6434bfa98b5.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3&amp;nbsp;頁面預靜態化（SSG）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會搶紅包的場景中，所有不變的內容（如活動規則、活動主頁框架等）使用 SSG 能夠顯著提高頁面通用靜態內容的加載速度，同時通過集成 CSR 可以實現部分動態內容的及時更新。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0f6976513c5f401b3f75425663a7bc78360.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△框架原生 SSG Webpack 插件&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f217081c740651f27fbd3fe8736d8fc59d7.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△圖 1：活動規則 △圖 2：攢百元半屏頁 △圖 3：支線攢碎片&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4&amp;nbsp;頁面靜態化（SSR)&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會搶紅包的場景中，節目單頁作為用户獲取歌曲節目信息的第一入口，其快速加載至關重要。SSR 提供快速的節目單頁初始加載，後續通過客户端的 JavaScript 動態增強功能（如進度提醒、節目回放等）獲得更豐富的交互體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c8d4e5358f9b2488dd9dbdc7708913653ab.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.5&amp;nbsp;增量靜態渲染（ISR）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會搶紅包的場景中，對於實時性要求極高的紅包搶奪場景，ISR 的動態更新和實時交互特性為活動的各個環節提供了實時回顯的用户體驗：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;首先，在全屏紅包彈窗頁（如初始紅包、任務紅包和裂變紅包）中，ISR 使得頁面無需刷新即可實時更新用户的紅包狀態。當用户參與活動或完成任務時，ISR 的快速響應確保用户能即時獲得任務狀態和獎勵領取情況，增強了用户的參與感與互動性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;對於實時輪次切換功能，ISR 保障用户迅速在遊戲階段間切換，提升了同頁面不同狀態的連續性。當活動結束時，系統能夠快速通知用户並更新活動狀態為下線，避免誤導用户繼續參與。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在內容分享與社交互動方面，ISR 處理高效的頁面加載與實時顯示，如微信邀請和海報分享，保證用户能快速刷新助力進度。在邀請分享頁，主態用户能立即看到受邀好友的參與情況和貢獻，進一步增強社交互動體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-caeada216acb857ffbe6901babb24ff4074.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.6&lt;/strong&gt;&amp;nbsp;數據預取（&lt;strong&gt;Prefetch Data）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會搶紅包的場景中，通過 NA 與 H5 之間的有效數據預取和緩存銜接，實現了端數據的複用，有效減少與服務器的交互頻率，消除了數據加載的等待時間，確保了在直播環境中用户能夠高效參與活動：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;預取皮膚元素配置，進入直播間後，NA 會預取皮膚元素配置，預加載與活動相關的皮膚素材，並將這些信息進行緩存，包括頁面主題色和紅包動畫等。同時，前端 JavaScript 能夠在頁面彈出時，通過端能力或全局變量直接獲取相關數據，用户不需要等待皮膚配置加載，界面視覺能夠立即呈現，從而實現在操作上的流暢體驗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;攢百元紅包的進度更新，在活動進行中，用户需要實時查看攢百元紅包的進度，通過數據預取的方式，能夠迅速更新至用户界面。在啓動 WebView 的同時，NA 實現數據的並行獲取。這意味着在用户點擊掛件後，相關的數據請求會立即開始，前端 JavaScript 則能夠在執行時通過端能力直接獲取這些已經預取的數據，降低了數據延遲加載等待時間，增強了用户參與活動的效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-956e641a7cef65f27ac27b6f1f75e9fa42f.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.7&amp;nbsp;文檔預取 (Prefetch HTML)&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在互動性較強的直播歌會搶紅包的場景中，用户不僅可以觀看演出，還能參與搶紅包活動。為提供最佳的用户體驗，確保用户在首次點擊不同功能時能夠快速上屏相關內容，採用文檔預取能力在後台主動下載歌會相關 HTML 內容，如攢百元半屏頁、節目單頁等。當用户最終點擊某個鏈接時，直接從內存中讀取 HTML 文檔內容，無需網絡請求，從而顯著提高頁面加載速度，確保用户在直播間裏的互動預期。&lt;/p&gt; 
&lt;p&gt;通過數據結果來看，文檔預取的效果非常顯著。在優化了節目單頁的性能後，Android 用户的首屏加載時間從 3 秒級減少到 500 毫秒級，iOS 用户的首屏加載時間從 2.5 秒級減少到 500 毫秒級。這樣的性能提升顯然改善了用户體驗，使得用户能夠快速獲取所需信息，進而積極參與到活動中，營造出活躍的直播間氛圍。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-321ce9dfad640aac1a82e6ac3361f1663dd.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△Prefetch SSR/CSR HTML&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3e468dfa83832e491549cbc9e62ba8750d4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;2.8&amp;nbsp;資源預取（&lt;strong&gt;Prefetch Resource）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會的場景中，用户參與搶紅包是一個關鍵的互動環節。在此過程中，確保紅包彈出的多層動畫和紅包圖能夠迅速、完整地展示對於增強用户體驗至關重要。為此，資源預取在這一場景中得到了有效應用，在正式直播活動開始前期，後台服務主動下載、緩存、更新關鍵資源，包括紅包的動畫文件和高質量的紅包皮圖像。以確保當紅包正式彈出時，最新的文件已被準備妥當，用户能夠立即看到完整的紅包圖和流暢的動畫效果，避免了圖片逐塊加載造成的卡頓和不完整展示。&lt;/p&gt; 
&lt;p&gt;通過數據結果來看，資源預取的效果非常顯著。Android 用户資源加載耗時提升幅度約 46.7%，iOS 用户資源加載耗時提升幅度達 86.1%，大幅提升了整體互動體驗，使用户在關鍵時刻享受到快速且流暢的操作體驗。&lt;/p&gt; 
&lt;p&gt;為了確保資源預取的有效性，需要注意以下幾點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;預取的資源應以用户行為的合理預測為基礎，避免過度預取，從而造成帶寬浪費。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;採用分模塊的離線包設計，將每個模塊的資源單獨管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在活動結束後，應及時下線不再需要的資源，釋放帶寬和用户手機空間。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-432cea91c994b4897164e59311d45182bf1.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-280432b02417e32f6ec6fc85535f7f08a79.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.9&amp;nbsp;視圖預渲染（&lt;strong&gt;Prerender WebView）&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌會的場景中，觀眾們期待快速響應的搶紅包互動體驗，此時視圖預渲染能力發揮了重要作用。當用户進入直播間後，提前在後台加載並渲染搶紅包頁面內容，並註冊頁面可見性監聽器。即使用户專注於觀看直播，紅包頁面也已準備妥當。用户點擊按鈕，搶紅包頁面便迅速顯示，無需等待加載和渲染時間，同時觸發監聽器實時更新數據。這樣的即時反饋使得用户幾乎可以瞬間查看搶紅包的結果，極大提升了參與的積極性和體驗感，進一步增強了直播的互動樂趣。&lt;/p&gt; 
&lt;p&gt;在預渲染過程中，僅對用户頻繁訪問的頁面進行預渲染，避免資源浪費，確保當前視圖性能不受影響。由於預渲染佔用內存資源，因此需要控制 WebView 的數量，防止內存泄漏。在實施時應關注內存管理、時機選擇、兼容性和安全性，以靈活適應具體應用場景。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-383b13dd43ff5d680e92e00fc4adc64519a.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fa16963f047697d9fc6bfef362543f8d08f.gif&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;03 穩定性&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 彈窗穩定性&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;保障直播間紅包彈層的進退場穩定性，防止透明彈層卡住以致用户無法互動，是一項關鍵挑戰。在直播間中，紅包彈層通過覆蓋全屏透明 WebView 實現，且與動畫控制密切相關，用户在拆紅包動畫播放過程中無法進行任何交互，關閉按鈕在動畫結束後才會顯示。這要求我們確保紅包動畫的持續時間和效果穩定，以便在合適的時機正確顯示關閉按鈕。為確保紅包彈窗正常退出，尤其是在 H5 頁面渲染異常或網絡不穩定的情況下，用户也能得到一個狀態友好的反饋。保障直播間搶紅包互動的穩定性，我們設計了「一次握手」和「雙重兜底」策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一次握手，即 Web 內容健康檢查：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;JavaScript 通過 WebContentLoaded 端能力，表示 H5 成功接管用户交互，並通知 Native 端取消 WebView 的超時銷燬策略，以確保全屏紅包彈窗能夠穩定展示。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 H5 接管未在規定時間內完成，Native 端將銷燬上層全屏透明的 WebView。這一措施確保用户不會因彈窗問題而中斷觀看體驗，從而能夠持續與直播間進行交互。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;雙重兜底，即 NA 兜底頁和 H5 兜底頁：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;NA 兜底頁，當 HTML 入口文件請求異常時，展示 Native 兜底頁面，確保用户有可見的替代內容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;H5 兜底頁，在 JS 業務組件發生異常（例如接口請求異常、端能力調用失敗、組件內部異常、重要資源缺失）時，展示 H5 兜底內容，為用户提供實質反饋。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a618284a079f94a36954256647ec878cc28.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9643dfcee6987b9b6f75ca7a9978c27b0b5.png&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp; &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;△圖 1：NA 兜底頁 △圖 2：H5__兜底頁 △圖 3：請求______兜底&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;動效降級&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;炫酷的動效的表現直接影響用户的體驗，在直播歌會場景中，紅包動效由複雜的元素組成，包括 Lottie 動畫、AFX 透明視頻和 CSS 動畫。炫酷的動效雖然可以增強視覺吸引力，但在低端手機上可能導致卡頓。為確保所有用户可以順暢參與活動，我們實施了分級動效降級策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;高性能設備（High）：在高性能設備上，展示完整的動畫和豐富的動態效果，享受到豐富的視覺效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;低性能設備（Low）：對於低端手機，複雜的動效將被簡化為靜態圖像或低複雜度的 CSS 動畫。例如，紅包拆開時只展示基本的靜態圖形，替代激烈的動態效果，確保用户能夠正常閲讀紅包金額，而不至於因動效卡頓而影響體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;分級動效降級策略能夠根據當前手機的實時性能情況，在用户點擊拆紅包時動態調整展示的動效級別，確保以最佳效果參與活。這種適應性有效地解決了不同設備用户在參與紅包活動時可能遇到的性能問題，從而提升整體用户體驗的品質。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7968ce45d177cbd1d1d3dd1b6d7f0c28f4b.jpg&quot; alt=&quot;圖片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5c9ea82e15ec367fd493696b4b23d42eb40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3&amp;nbsp;組件響應&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;隨着用户體驗的不斷優化，直播歌會搶紅包活動中頁面組件的運行環境日益複雜。特別是在複雜組件的開發中，組件開發者必須意識到各項適配工作的必要性，以確保用户體驗與開發體驗之間的平衡。為了有效滿足用户需求並提升開發效率，我們需要綜合考慮多個環境及其不同狀態。至此，在一個組件的設計和實現過程中，需要針對以下五種狀態進行響應和適配：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;SSG 環境（編譯線環境）：組件在編譯過程中，通過 Node.js 將公共的信息（如活動規則）提前生成靜態內容，以提供快速響應時間。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SSR 環境（服務端環境）：組件服務器集羣上，通過 Node.js 根據用户請求動態生成相應的內容（如歌會節目單），減去客户端 JavaScript 加載執行時間，加快頁面首屏展示速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ISR 環境（客户端環境）：組件在瀏覽器中，通過 JavaScript 進行動態渲染、響應用户點擊、滑動等操作，通過異步接口獲取最新數據（如紅包金額、助力信息）並即時更新界面，保證用户體驗的實時性和互動性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;頁面可見（Visibility）：組件在瀏覽器中，通過 JavaScript 控制組件的渲染時機，僅在內容需要展示時才進行渲染（如播放紅包動畫），減少不必要的 DOM 操作，提升性能並降低資源消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;動效級別（High / Low）：組件在瀏覽器中，通過 Native 端能力獲取用户設備的性能，動態調整組件中的動效，在高性能設備上展示更炫酷的動效，在低性能設備上則展示更簡單的動效，確保流暢體驗。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;04 總結&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;沉澱直播框架能力&lt;/strong&gt;：通過優化直播間視圖容器組件，並形成標準化的組合能力樣板，拉昇直播間活動頁面的性能水準，這些方案具備良好複用性，適用於未來各種直播活動。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;系統穩定性保障&lt;/strong&gt;：組件複用、性能監控和容錯機制，減少重複開發和維護成本，進行壓力測試與優化，提升系統可靠性和用户體驗，確保高峯流量下的穩定性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;強化互動性體驗&lt;/strong&gt;：在直播歌會中建立綜合能力框架，特別是在搶紅包等互動性強的活動中，確保用户在享受歌會演出的同時體驗流暢的互動，鼓勵積極參與&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;————END————&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推薦閲讀&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604026%26idx%3D1%26sn%3Db6c6367e9bcbe2dab70a1282140ea740%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度網盤防雪崩架構實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603987%26idx%3D1%26sn%3D4a88159ec791a37e75053139e0b4682c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何在百度百舸部署滿血版 DeepSeek-V3、DeepSeek-R1 模型&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603986%26idx%3D1%26sn%3Dc10b89bf5b0e34c616c8ba230b3405ae%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;首日調用客户破 1.5 萬！DeepSeek-V3/R1 上線背後的超低推理成本技術揭秘&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603905%26idx%3D1%26sn%3D8a870420c3865822760331c3a62d1678%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;喚醒 AI 算力，專有云 ABC Stack 面向企業級智算平台的 GPU 提效實踐&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603901%26idx%3D1%26sn%3D6d46e002ddb623aa67c0eaa2d804fea4%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度 APP iOS 端磁盤優化實踐（上）&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4939618/blog/17679358</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17679358</guid>
            <pubDate>Sun, 23 Mar 2025 03:47:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>蘋果向浙江大學捐贈 3000 萬元，支持編程教育</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Apple 今日宣佈向浙江大學捐贈 3,000 萬元人民幣，深化其對中國下一代開發者的支持。該合作基於其對移動應用創新賽十年的支持，繼續加強 Apple 在大中華區長期開展的學生和開發者的教育支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1458&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/113851_E8YI_2720166.png&quot; width=&quot;2320&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Apple 將與移動應用創新賽的合作伙伴浙江大學共同設立 Apple 移動應用孵化基金，提供最前沿的技術培訓，包括 app 開發、產品設計、市場營銷和商業運營等專業課程。該基金將通過研討會、實習和導師制等方式，建立學生開發者與行業領袖和投資者之間的聯繫，為他們提供更多商業培訓，助其在不斷發展的 iOS 應用經濟中取得成功。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/114039_pIPv_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Apple CEO Tim Cook 表示：「&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;我們相信編程是一項強大的工具，它能讓人們以全新的方式進行創造、交流和解決問題。我們很榮幸能深化與浙江大學長達十年的合作關係，為下一代開發者提供技能支持，幫助他們開發創新應用，創立充滿生機的業務。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;Apple 對移動應用創新大賽的支持已持續十年，累計共有大中華區近千所高校的 30,000 多名參賽者從中受益。許多參賽者成長為 app 工程師、企業家和教育工作者，不僅獲得了個人發展的新機遇，且通過編程為所在社區帶來積極的變化。&lt;/p&gt; 
&lt;p&gt;「我們很高興與 Apple 繼續緊密而深入地合作。」浙江大學黨委書記任少波表示，「我們將發揮雙方各自優勢，通過 Apple 移動應用孵化基金，共同攜手培育知識、能力、素質、人格全面發展的新質人才。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341040</guid>
            <pubDate>Sun, 23 Mar 2025 03:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>