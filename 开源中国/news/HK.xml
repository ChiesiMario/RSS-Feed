<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 25 Mar 2025 07:38:20 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>阿里雲開啓近年來規模最大的 AI 人才校園招聘</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9UyL73Bk6FBWpWcnfFfq-A&quot; target=&quot;_blank&quot;&gt;根據《科創板日報》的獨家報道&lt;/a&gt;&lt;/u&gt;，阿里雲近日在全球頂尖高校招募 AI 技術儲備人才，為近年來規模最大的 AI 人才校園招聘。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/152257_OouC_2720166.png&quot; width=&quot;844&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據瞭解，此次校招面向清華大學、北京大學、浙江大學、麻省理工大學、斯坦福大學等全球頂尖高校，招募大語言模型、多模態理解與生成、模型應用、AI Infra 等領域技術人才。&lt;/p&gt; 
&lt;p&gt;同時，&lt;strong&gt;項目設置 A Star 項目和 Al Clouder 項目，面向具備高水平論文、開源項目影響力等特質的頂尖人才，為這類畢業生提供更優薪酬和專業扶&lt;/strong&gt;持。&lt;/p&gt; 
&lt;p&gt;此舉系之前 T 項目後，阿里巴巴推出的又一項 AI 人才戰略。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339514&quot; target=&quot;news&quot;&gt;阿里全面 AI 化，公司內部相信「基於 AI 的殺手級應用可能很快就出現」&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/339418&quot; target=&quot;news&quot;&gt;阿里雲啓動「T 項目」，加速 AI 研發&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338747&quot; target=&quot;news&quot;&gt;阿里巴巴董事長蔡崇信：AI 市場規模至少 10 萬億美元&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340879</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340879</guid>
            <pubDate>Tue, 25 Mar 2025 07:24:06 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>開放，開源，全球化，國產算力展現三大演進趨勢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;我國計算產業正在自主創新中快速發展，呈現出開放、開源、全球化三大趨勢。專家認為，面對人工智能在各行各業加快應用帶來的海量算力需求，我國計算產業亟須抓住機遇，構建算力新體系，打造世界級新產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;數字基礎設施量質齊升&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;工業和信息化部 3 月 17 日公佈的數據顯示，2024 年我國數字基礎設施量質齊升。截至 2024 年末，全國在用算力中心標準機架數超過 880 萬，算力總規模較上年末增長 16.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作為數字經濟時代的核心生產力，算力對經濟的巨大拉動作用已經顯現。中國信息通信研究院發佈的《中國算力發展指數白皮書（2023 年）》顯示，算力每投入 1 元錢，就將帶動 3 至 4 元的 GDP 增長。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在數字經濟大省浙江，去年數字經濟核心產業增加值突破 1 萬億元。據介紹，在推進數字浙江建設進程中，於 2020 年投入運營的浙江省鯤鵬生態創新中心為浙江數字經濟的發展提供了技術支撐和創新動力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作為國產算力的中堅力量，在硬件層面，鯤鵬 CPU 展現出強大競爭力，部件、整機實現全量自主創新，構建起堅實的自主創新產業鏈；在基礎軟件領域，以開源歐拉、開源高斯為代表的開源項目蓬勃發展，不斷豐富和繁榮軟件生態，為浙江數字產業發展提供了源源不斷的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作報告提出，「激發數字經濟創新活力」，並作出了「優化全國算力資源佈局」等具體部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 等機構認為，2025 年中國智能算力規模將達到 1037.3EFLOPS，並在 2028 年達到 2781.9EFLOPS。當前，我國算力總規模已位居全球第二，但仍存在算力資源供給緊張和不能有效利用的矛盾情況。算力規模的高速增長和供需錯配等挑戰將為國產算力的未來發展提供新空間。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;三大產業演進趨勢漸明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;專家認為，目前計算產業變革呈現出三大趨勢：一是算力架構的開放特性加速了端、邊、雲全場景的快速協同發展；二是算力生態共建正在替代單邊創新；三是計算產業的全球化趨勢愈發清晰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在業界看來，當前算力領域的技術路線正向多元化、多維度演進。受限於封閉架構的短板，傳統的 X86 架構難以形成生態，而 ARM 架構的開放模式，將成為未來通用算力的主流選擇。數據顯示，當前全球算力大約 80% 屬於 ARM 架構，其中 99% 的手機採用的都是 ARM 芯片，國內的鯤鵬和飛騰以及國外都有基於 ARM 架構的產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，DeepSeek 的開源實踐，推動了人工智能技術的普及和應用。在算力領域，開源同樣帶來了生態的繁榮。例如，鯤鵬聯合超過 6000 家合作伙伴構建的「技術樂高」模式，就證明瞭開源協作的強大生命力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;開源、開放的生態也讓計算產業打開了全球化的新格局。通過攜手合作，產業各方開始充分發揮自身優勢，通過資源共享與互補，聯合打造更具競爭力的解決方案，共同開拓國際市場，為全球客户提供創新產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以鯤鵬生態為例，近年來，通過開源、開放，鯤鵬打造了從芯片、整機到操作系統、數據庫的自主創新生態。數據顯示，截至目前，鯤鵬生態已發展超過 335 萬鯤鵬開發者，面向硬件、軟件和應用全面創新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;迎接人工智能時代新機遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;業內人士指出，隨着人工智能應用場景的爆發式增長，算力需求呈現快速攀升態勢。正如當年互聯網推動 PC 快速普及和升級一樣，如今人工智能的大範圍落地應用也將激活對算力的龐大需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的政府工作報告提出，持續推進「人工智能＋」行動，將數字技術與製造優勢、市場優勢更好結合起來，支持大模型廣泛應用。多家機構認為，「人工智能+」行動將重塑所有產業，DeepSeek 的火爆更為大模型應用落地提供了催化劑，不僅將加速各行各業的智能化轉型，更將驅動中國計算產業升級。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC 最新數據顯示，2025 年，中國人工智能市場總規模將達到 511.3 億美元，同比增長 34.8%，預計到 2028 年市場規模將達到 1010 億美元，年複合增長率達到 25.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;面對人工智能時代的新機遇，專家認為，我國計算產業應抓住這一歷史性機遇，打造世界級新產品，構築堅實的算力底座。一是要構建自主創新的算力新體系。IDC 發佈的 2024 年中國服務器市場報告顯示，自主算力鯤鵬系服務器市場份額佔比已達 20% 以上，覆蓋了金融、運營商、政府、互聯網等核心場景。二是要打造開放開源的自主軟件生態。據 IDC 報告，在中國服務器操作系統領域，2024 年開源歐拉系份額達到 50%，累計裝機量突破 1000 萬套；據沙利文數據，2024 年 openGauss 在關係型數據庫中佔比 28.5%，超過 MySQL 和 PG，成為三個主流開源數據庫技術路線之首。三是要構築根植中國、面向全球的通用計算產業。工業和信息化部數據顯示，2024 年開源歐拉用户數量超過 380 萬，為全球 150 餘個國家和地區提供服務。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;專家預測，未來幾年，人工智能技術普及將推動算力需求出現爆發式增長。我國計算產業將通過在根技術上的自主創新突破，實現性能提升和成本優化，助力人工智能技術的規模化商用和千行百業的智能化轉型，並逐漸走向全球市場，打造面向人工智能時代的通用算力底座。（經濟參考報，記者，吳蔚）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340875</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340875</guid>
            <pubDate>Tue, 25 Mar 2025 07:15:06 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國家數據局：以高質量數據促進人工智能發展</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國家數據局局長劉烈宏 24 日在中國發展高層論壇 2025 年年會上表示，國家數據局將充分調動社會各方力量，積極推動高質量數據集建設，持續增加數據供給，推動「人工智能+」行動賦能千行百業，打造包容開放的創新環境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;302&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bfc45482de2edcfe691d1f74d79bbdf71b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;劉烈宏説，高質量數據與人工智能的結合，將會進一步發揮數據和人工智能的倍增效應。如何更好以高質量數據促進人工智能發展？劉烈宏提出重點做好四方面工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進基礎制度供給——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;劉烈宏説，將統籌開展數據領域規劃編制工作，加快形成數據領域的規劃體系，制定印發數據產權制度和培育全國一體化數據市場的文件，加快推進數據基礎制度建設，組織開展數字中國、數字經濟、數據要素綜合試驗區的建設，因地制宜開展先行先試，為數據要素價值釋放積累實踐經驗，健全完善數據治理、數據安全等制度，更好保障人工智能安全發展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進高質量數據供給——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「‘人工智能+’行動到哪裏，高質量數據集的建設和推廣就要到哪裏。」劉烈宏説，將強化公共數據資源登記管理，規範公共數據資源授權運營實施，建立授權運營價格形成機制，積極引導做好高質量數據集建設工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進數據基礎設施建設——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;生成式人工智能的快速發展，對算力和數據流通利用提出更高更迫切的需求。劉烈宏表示，將系統推進全國一體化算力網建設，創新算力電力協同機制，推動算力設施一體化、集約化、綠色化發展。同時，加快國家數據基礎設施建設，推動區域、行業數據基礎設施互聯互通。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;持續推進數據領域國際合作深化——&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;國家數據局將推進數據領域高水平開放，為中外數字企業發展創造良好環境。「歡迎世界各國企業參與到中國數據要素市場化、價值化進程中，共享數據發展紅利和發展機遇。同時我們也將積極參與並持續推動人工智能安全治理，加強國際合作和對話，為全球治理體系完善提供新的動力。」劉烈宏説。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340860</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340860</guid>
            <pubDate>Tue, 25 Mar 2025 06:47:06 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高併發場景下的庫存管理，理論與實戰能否兼得？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本篇文章，是一篇實戰後續篇，是基於之前我發了一篇關於如何構建高併發系統文章的延伸： &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fsd.jd.com%2Farticle%2F35216%3FshareId%3D8087%26isHideShareButton%3D1&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高併發系統的藝術：如何在流量洪峯中游刃有餘&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而這篇文章，從實踐出發，解決一個真實場景下的高併發問題：秒殺場景下的系統庫存扣減問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;隨着互聯網業務的不斷發展，選擇在網上購物的人羣不斷增加，這種情況下，會衍生出一些促銷活動，類似搶購場景或者熱銷熱賣場景，在高峯時段的下單數量會非常大，也意味着對數據庫中暢銷商品的庫存操作十分頻繁，需要頻繁查庫存和更新庫存。這屬於高讀寫場景，比起單獨的併發讀和併發寫來説，業務場景更復雜一些。那麼這種高併發為了保證庫存數據一致性，一般會在數據庫更新時進行加鎖操作，以保證系統不會發生超賣情況。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我們應該如何應對呢？大家可以根據我之前那篇文章中的思維導圖，跟隨我的思路，一起來看如何解決當前場景下的高併發問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;小試牛刀&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面對庫存扣減的場景，我們第一個考慮到是數據一致性問題，因為超賣會對我們的履約和客户信譽造成影響。所以一般情況下，在數據庫更新時進行加鎖操作，以保證系統不會發生超賣情況。所以更多方案是提高數據庫性能方法，比如增加硬件性能，優化樂觀鎖，提升鎖效率，優化 SQL 性能等。對於一些大型系統，也衍生出一些基於分片的庫存方案，通過分庫分表增加併發吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然那這樣不夠，因為 MySQL 數據庫的讀寫的併發上線能力是有限的，我們還是需要再進一步優化我們的方案。這裏就要參考之前我寫的那篇文章中的思維導論了，這裏常見解決方案就是，引入緩存機制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如下圖所示，我們把讀請求進行緩存，每次庫存校驗時，我們引入 redis 緩存，讀請求通過緩存，增加接口性能，然後庫存扣減時，在進行緩存同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c08115baf35c2454a8997ca9afa97a80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但這種方式存在很大問題： 所有請求都會在這裏等待鎖，獲取鎖有去扣減庫存。在併發量不高的情況下可以使用，但是一旦併發量大了就會有大量請求阻塞在這裏，導致請求超時，進而整個系統雪崩；而且會頻繁的去訪問數據庫，大量佔用數據庫資源，所以在併發高的情況下這種方式不適用。同時這個方案還會存在 mysq 和 redis 的數據同步不一致的情況，導致高併發情況下，出現超賣。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;所以這種方案雖然簡單，但是無法滿足高併發場景，我們必須得 pass。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;循序漸進&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;為此，我們可以進行一次優化，通過架構維度進行調整。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在這個方案中，我們將庫存操作封裝成一個單獨模塊，這個方案的優化點在於，所有庫存的查詢和扣減都圍繞 redis 進行。當發生庫存扣減操作時，會直接更新 redis，同時採用異步流程，更新 MySQL 數據庫。這樣以來，我們的性能會比直接訪問 MySQL 數據庫高效不少，併發能力會有不少提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;流程如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//f6f8964c0024b3ee676272e4655ccfa7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;但這個方案依然有缺陷，它的點在於 redis 的單點性能問題。該方案的最大併發性能取決於 redis 的單點處理能力。而如果想要進一步提升併發能力，該方案不具備水平擴展能力。那麼，這個方案，依然不是我們最優的選擇。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;大顯身手&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那麼接下來，我們需要考慮的是如何可以實現我們業務系統併發能力的水平擴展能力。當然這裏也不是憑空來想，我們可以思考一下，業內成熟的一些中間件是如何實現高併發的，這裏我們可以兩個我們常見的框架：kafka 和 elasticsearch。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;上述我們常見的兩個中間件框架，都以可以水平能力擴展著稱。那麼仔細思考一下他們的技術架構不難發現，他們的核心其實都是採用了一種所謂的分片實現的。那麼問題來了，我們的庫存扣減，能不能實現分片呢？或者換一個思路思考這個問題：我們的庫存邏輯是否可以轉化為分佈式庫存進行存儲和擴展呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有了以上的思路，我們就可以開始構建我們的架構方案了。接下來，我先把架構圖貼出來：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//6542ddad18a4604d2a38c7b51195fe8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在這個架構方案中，是以 Redis 緩存為實現基礎，結合 Mysql 數據存儲，通過一套控制機制，保證庫存的分佈式管理。在該方案中，有一些特定的業務模塊單元需要説明。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. partition&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;熟悉 kafka 的人對 partition 一定不陌生。在本架構方案之中，該業務架構中的 partition 的概念是一組基於 redis 來實現的庫存分片，分別存儲一部分庫存大小。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一個 partition 中，會存有一定量的預佔庫存量，當有請求服務進行庫存扣減時，只需要選擇其中一個 partition 即可，這樣以來，就可以減輕單節點的壓力，同時可以基於 redis 集羣的可擴展性，實現 partition 的水平擴展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分佈式系統常見的一個問題就是數據傾斜問題，因為嚴重的數據傾斜，會讓我們分佈式方案瞬間瓦解，導致單點承擔高併發。那麼該方案下的數據傾斜問題如何解決呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;最終，我想到的解決方案類似養寵物狗時買的那種定時投餵儀器，每天通過定時定量投餵，來保證寵物狗不會被餓到或者吃撐。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果最初把所有庫存全部平均到每個 partition 中，當有多個大庫存扣減打到一個 partition 上時，會造成該 partition 上出現庫存被消耗光，而失去後續提供庫存扣減能力。為瞭解決這個問題，我在 partition 中採取的是動態庫存注入和子域隔離的方案。具體方案如下圖：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//8c57d7654d67f6af4f23f47905ef2ce6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每個 partition 會有兩個子域，調度器中會記錄每個 partition 當前激活的子域，每次庫存扣減，會扣減激活的子域中的庫存值。而當激活的子域庫存值低於設定閾值是，會切換子域，冷卻當前子域，激活另一個子域。被冷卻的子域會觸發任務觸發器，實現預佔庫存的數據同步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;子域中會存儲一定額度的庫存值，不會存儲很大的量，這樣就可以保證動態的預佔庫存實現，從而解決庫存傾斜的問題。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當然為了更好的管理 partition，我們需要單獨開發一個 partition 調度器模塊，來負責管理管理眾多 partition 資源，那麼這個調度器的具體功能包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;span&gt;1.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;調度器中有一個註冊表，會記錄 Partition 的 key 值，外部服務獲取 partition key 是需要通過調度器獲取，調度器會記錄每個 partition 的庫存餘量和 partition 和子域信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;2.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當 partition 無法再獲取預佔庫存，且庫存耗盡時，調度器會從註冊表中摘除該 partition 信息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span&gt;3.&lt;/span&gt; 
 &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 調度器可以採用隨機或者輪訓的方式獲取 partition，同時每次也會校驗 partition 剩餘庫存是否滿足業務扣減數量，如果剩餘庫存小於業務扣減數量，將會跳過該 partition 節點。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. 異步更新庫存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二個核心模塊就是更新庫存管理了，這塊你可以理解為異步流程機制，通過異步化操作，來減輕系統的高併發對數據庫的衝擊。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更新庫存會有一個明細表，記錄每個 partition 庫存扣減信息，明細表會有一個同步狀態，有兩種情況可以出發庫存同步 MQ 消息：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一． 當每個 partition 中的明細數據條數超過設定閾值，會自動觸發一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二． 每間隔額定設定時間 (默認設置 1 秒)， 會觸發一次當前時間段內每個 partition 產生的庫存扣減明細信息，然後發送一次 MQ 消息。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;兩中觸發方案相互獨立，互不影響，通過同步狀態和明細 ID 實現冪等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3. 預佔庫存管理和庫存管理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;接下來就是關於庫存的底層數據結構設計了。這裏會引入一個在電商行業很共識的概念：預佔庫存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在庫存領域層中，庫存分為預佔庫存和庫存兩個模塊，這裏面的庫存關係實例如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;假設當前商品的庫存值為 10000 件，當前 partition 觸發一次預佔庫存任務，領取 400 件， 然後假設此時收到 MQ 庫存消費更新消息，更新 30 件。隨後 partition 又觸發一次預佔庫存任務，零陵區了 100 件。庫存變化如下圖所示：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//c83f3fadc83623765f0e90cf251f75ad.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style=&quot;color:transparent&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，實際庫存= 預設庫存池 + 預佔庫存。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;每次預佔庫存任務觸發，會從預設庫存池中扣減，如果預佔庫存池清空，則 partition 就無法在獲取預佔庫存，調度器會將它從註冊表中摘除。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而每次 MQ 更新庫存消息，會更新實際庫存量，同時對預佔庫存和扣減庫存值進行修改，這個操作具有事務性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_8&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;總結&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;通過這次的案例分析，我們其實是通過方法論結合實際業務場景的方式出發，設計了我們的系統架構。剝離業務場景，其實本質就是通過緩存和異步流程來實現系統的高併發，同時讓系統具備擁有水平擴展的能力。但這個方法論在與實際業務結合時，還是會有很多很多需要思考和細化的點，比如分佈式思想的使用，比如預佔庫存的邏輯設計等等。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4090830/blog/17989921</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/17989921</guid>
            <pubDate>Sun, 23 Mar 2025 06:36:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>樹莓派開源鏡像定製工具 rpi-image-gen</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;樹莓派基金會近日推出開源工具 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fraspberrypi%2Frpi-image-gen&quot; target=&quot;_blank&quot;&gt;rpi-image-gen&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;rpi-image-gen 是一個根文件系統和鏡像創建工具，旨在提供高度的自定義、靈活性和控制。rpi-image-gen 使用&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbdrung%2Fbdebstrap&quot; target=&quot;_blank&quot;&gt;bdebstrap&lt;/a&gt;&amp;nbsp;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.mister-muffin.de%2Fjosch%2Fmmdebstrap&quot; target=&quot;_blank&quot;&gt; mmdebstrap &lt;/a&gt;進行根文件系統的構建，並使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fpengutronix%2Fgenimage&quot; target=&quot;_blank&quot;&gt;genimage&lt;/a&gt; 進行鏡像創建。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是一個以 Bash 為中心的腳本引擎，能夠使用元數據集合和定義的執行流程生成具有不同磁盤分區佈局、文件系統和配置文件的軟件鏡像。它提供了為 Raspberry Pi 設備創建高度自定義軟件鏡像的方法。&lt;/p&gt; 
 &lt;p&gt;rpi-image-gen 是易於閲讀、可審計且易於使用的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;技術亮點&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;模塊化定製&lt;/strong&gt;：通過 YAML 配置文件定義軟件包列表，移除冗餘服務降低資源佔用&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全增強&lt;/strong&gt;：自動掃描鏡像內軟件組件的已知漏洞（CVE），生成 SBOM 清單滿足合規需求&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;場景化模板&lt;/strong&gt;：提供 Web Kiosk 等預設配置，5 分鐘快速生成專用設備系統&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1852&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/143335_AvvG_2720166.png&quot; width=&quot;2464&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9fd9d61d93288d85f72c7f103eb0e6445bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該工具支持用户根據需求裁剪操作系統組件、管理軟件供應鏈安全（SBOM 與 CVE），並內置輕量化「slim」鏡像模板，為樹莓派設備創建定製化的 Raspberry Pi OS 鏡像，適用於工廠批量燒錄、邊緣計算設備集羣管理等場景。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340856/raspberrypi-rpi-image-gen</guid>
            <pubDate>Sun, 23 Mar 2025 06:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>華為語言模型推理專利公佈，可提高對預設內容的理解能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查資料顯示，華為技術有限公司、清華大學申請的「一種語言模型推理方法以及推理裝置」專利於 3 月 25 日公佈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-71363ec3371e1b4ce56ef932ddc41db7554.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要信息顯示，該方法包括：根據第四問題生成第五問題，所述第五問題用於提問所述第四問題、以及提示語言模型回答所述第四問題的回覆中不要包括預設內容；所述語言模型根據所述第五問題輸出第三回復，所述第三回復不包括所述預設內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其中，所述語言模型的參數根據第一回復的評價數據更新，所述語言模型根據第一問題輸出所述第一回復，所述評價數據用於指示所述第一回復是否包括所述預設內容。該方法可以提高語言模型對預設內容的理解能力，從而更準確地抑制模型輸出預設內容。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340851</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340851</guid>
            <pubDate>Sun, 23 Mar 2025 06:25:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>shadps4 v0.7.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;shadPS4 是一款開源 PlayStation 4 模擬器，適用於 Windows、Linux 和 macOS，採用 C++ 編寫，該項目&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshadps4-emu%2FshadPS4%2Freleases%2Ftag%2Fv.0.7.0&quot; target=&quot;_blank&quot;&gt;上週發佈了&amp;nbsp;0.7.0 版本&lt;/a&gt;，此次更新除修復漏洞外，新增了 AMD FSR、HDR 及自定義鍵鼠映射等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/142238_2DUK_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ShadPS4 的開發者 shadow（George Moralis）表示，這次更新的發佈時間（3 月 23 日）正好位於他此前主導開發的 PS2 模擬器 PCSX2 初次發佈 24 年之際，同時這一天也是他的生日，這一天對他來説意義非凡；他稱，從去年僅能運行 openOrbis 技術演示，到現在能運行《血源詛咒》等商業遊戲，團隊的突破令人振奮，期待下次更新能模擬更多遊戲。&lt;/p&gt; 
&lt;p&gt;shadps4 v0.7.0 &quot;frobbo&quot;&amp;nbsp;主要更新如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;鍵鼠映射&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增 AMD FSR 支持&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增 HDR 支持&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復大量着色器編譯的錯誤&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復視頻輸出事件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復及提升 Qt 圖形界面&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復陀螺儀和加速傳感器錯誤&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修復「Attempted to track non-GPU memory（嘗試跟蹤非 GPU 內存）」錯誤&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提升舊款 CPU 兼容性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提升 Unity 遊戲兼容性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;目前 ShadPS4 模擬器能運行 40 餘款 PS4 遊戲，如《血源詛咒》、《黑暗之魂：重製版》和《荒野大鏢客：救贖》等，但是部分遊戲存在場景貼圖錯誤等問題，具體遊戲需要玩家自行測試。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340849/shadps4-v0-7-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340849/shadps4-v0-7-0</guid>
            <pubDate>Sun, 23 Mar 2025 06:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>人類細胞譜系大科學研究設施啓動建設，打造數字細胞 AI 大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人類細胞譜系大科學研究設施 25 日在廣州啓動建設，將繪製人類生命過程中的細胞動態演化圖譜，構建數字細胞 AI 大模型，催生生物醫藥研究新範式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;這一設施是國家「十四五」重大科技基礎設施，由中國科學院廣州生物醫藥與健康研究院牽頭，位於廣州國際生物島，規劃建設週期 4.5 年，總建築面積超 5 萬平方米。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人員介紹，細胞是生命的基本單元。從受精卵開始，到發育成組織器官，再到衰老全過程中出現的所有細胞類型進行彙總和演變關係的繪製，就構成了「細胞譜系」。解析細胞譜系被譽為揭示生命發育與演變奧秘、操縱生命活動的「鑰匙」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf7c06015d01a819ca8b5ea7cfba8024211.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;該設施將以樣品保活存儲、空間多組學、先進成像等創新技術和裝置研發為核心，集成人工智能等前沿技術，繪製涵蓋發育、疾病、衰老三大維度的動態細胞圖譜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「這就像為生命編寫一部詳盡的‘細胞家譜’，讓科學家乃至公眾能夠清晰追蹤每個細胞的‘前世今生’。」廣州健康院副院長、細胞譜系設施總指揮兼總工程師孫飛表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人員介紹，當前全球創新藥研發耗時長、耗資大，但臨牀成功率低，部分原因在於藥物研發主要在動物模型中進行，不能準確模擬人類生理系統反應。未來，細胞譜系設施有望用患者細胞信息打造一個「數字患者」，預演不同治療手段在體內的治療效果，實現「量體裁衣」式的精準治療。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;廣州健康院研究員、細胞譜系設施副總指揮兼總工藝師陳捷凱表示，這一設施的建設將在生命科學儀器、試劑、軟件和數據等方面產出一批創新性科技成果和產品，並進一步強化 AI 與數據資源整合，與龍頭企業開展深度合作，加速科研成果向臨牀應用轉化。（新華社，記者馬曉澄、鍾焯）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340845</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340845</guid>
            <pubDate>Sun, 23 Mar 2025 06:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>小鵬汽車公佈雙足機器人新專利</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查 APP 知識產權信息顯示，廣州小鵬汽車科技有限公司申請的「雙足機器人的控制方法及電子設備」專利於 3 月 25 日公佈。解決了相關技術中無法實現雙足機器人單腳點地姿態的技術問題。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;310&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6ad6f0bc0677b09916d95d0fcf8a8f559d.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要顯示，本發明公開了一種雙足機器人的控制方法及電子設備。其中，該方法包括：響應於接收到雙足機器人的控制指令，採集雙足機器人的當前姿態，其中，控制指令中攜帶有雙足機器人的姿態數據，姿態數據用於確定雙足機器人的期望單腳點地姿態，期望單腳點地姿態用於表示期望在雙足機器人對應支撐腳的足底區域接觸地面的情況下，雙足機器人對應擺動腳的足尖區域接觸地面；基於當前姿態和期望單腳點地姿態，確定擺動腳的擺動腳移動軌跡和雙足機器人對應機身的機身移動軌跡；基於擺動腳移動軌跡和機身移動軌跡控制雙足機器人運行。本發明解決了相關技術中無法實現雙足機器人單腳點地姿態的技術問題。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340843</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340843</guid>
            <pubDate>Sun, 23 Mar 2025 06:01:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apache Flink 2.0.0 正式發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fflink.apache.org%2F2025%2F03%2F24%2Fapache-flink-2.0.0-a-new-era-of-real-time-data-processing%2F&quot; target=&quot;_blank&quot;&gt;Apache Flink 2.0.0 已正式發佈&lt;/a&gt;&lt;/u&gt;，這是 Flink 2.x 系列的首個版本，也是自九年前 Flink 1.0 發佈以來的首次重大更新。&lt;/p&gt; 
&lt;p&gt;該版本通過 165 位貢獻者的協作，完成 25 項 FLIP 改進提案並解決 367 個技術問題，標誌着流式計算引擎正式邁入雲原生與 AI 融合的新階段。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心架構革新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;分離式狀態管理成為本次升級的最大亮點，通過將狀態存儲遷移至分佈式文件系統（DFS），解決了雲原生環境下的三大痛點：容器化部署的本地磁盤限制、大狀態作業快速擴縮容難題、檢查點機制的資源消耗問題。新架構引入異步執行模型，支持並行狀態訪問的 SQL 算子重寫，在保持精確一次語義的前提下實現資源利用率提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開發者體驗優化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;物化表（Materialized Table）功能的增強顯著降低了流批一體開發門檻，開發者無需關注底層流處理邏輯差異即可實現實時數據更新。批處理模式的深度優化為近實時場景提供成本更優的解決方案，配合與 Apache Paimon 的深度集成，構建起完整的流式湖倉架構。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI 工作流支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;針對 AI 與大語言模型對實時數據的需求，新版本通過統一狀態管理 API 和異步執行框架，為特徵工程、在線學習等場景提供毫秒級延遲保障。基準測試顯示，在典型推薦系統場景下，狀態訪問吞吐量提升 40%（基於阿里雲技術團隊驗證數據）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;遷移建議&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;需特別注意 API 清理帶來的兼容性變化，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnightlies.apache.org%2Fflink%2Fflink-docs-stable%2F&quot; target=&quot;_blank&quot;&gt;詳情查看 Apache Flink 2.0.0 文檔&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;對於存量作業，建議優先評估狀態後端改造收益，雲原生用户可率先嚐試分離式存儲架構。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340841/apache-flink-2-0-0-a-new-era-of-real-time-data-processing</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340841/apache-flink-2-0-0-a-new-era-of-real-time-data-processing</guid>
            <pubDate>Sun, 23 Mar 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Linux Kernel 6.14 穩定版發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Linus Torvalds 罕見地在美國時間週一早上而不是在傳統的週日下午發佈了 Linux Kernel 6.14，他表示本來想為此找個好理由——比如有一些重要的的事情在最後一刻耽擱了。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#d35400&quot;&gt;&lt;strong&gt;但最後 Linus 承認推遲發佈就是「單純的失職」 (It&#39;s just pure incompetence)。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1112&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/115542_nUlV_2720166.png&quot; width=&quot;1118&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;6.14 的主要新特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Btrfs RAID1 讀平衡&lt;/li&gt; 
 &lt;li&gt;NT 同步原語驅動，顯著改進遊戲性能&lt;/li&gt; 
 &lt;li&gt;新的 fsnotify 事件 (FS_PRE_ACCESS)&lt;/li&gt; 
 &lt;li&gt;支持 AMD NPU 的驅動 amdxdna&lt;/li&gt; 
 &lt;li&gt;PowerPC 架構支持惰性搶佔&lt;/li&gt; 
 &lt;li&gt;使用 AMD Secure Encrypted Virtualization 的 x86 系統支持客户機的安全時間戳計數器&lt;/li&gt; 
 &lt;li&gt;……&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;詳情查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwg7TO09Si5tTPyhdrLLvyYtVmCf%2BGGN4kVJ0%3DXk%3D5TE3g%40mail.gmail.com%2FT%2F%23u&quot; target=&quot;_blank&quot;&gt; 郵件列表公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340823/linux-kernel-6-14</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340823/linux-kernel-6-14</guid>
            <pubDate>Sun, 23 Mar 2025 03:59:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>工作流自動化平台 Zapier 上線 MCP 服務</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;工作流自動化平台 Zapier 近日上線了 Zapier MCP 服務，允許用户通過 Zapier 將他們的 Cursor AI 代理連接到各種應用程序，而無需複雜的 API 集成。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/114131_qF9e_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzapier.com%2Fmcp&quot;&gt;https://zapier.com/mcp&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;據介紹，Zapier MCP 服務賦予了 AI 助手強大的實用能力，包括自動化工作流程、管理數據、發送電子郵件、創建日曆事件、更新數據庫以及與其他應用進行實時交互等。無論是企業用户希望優化日常運營，還是個人用户想要簡化繁瑣任務，這一服務都提供了前所未有的便利。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0325/113921_nkJu_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 助手可以通過簡單的配置，自動將會議安排記錄到日曆中，或根據需求從數據庫中提取並整理數據，甚至與團隊協作工具實時同步信息。&lt;/p&gt; 
&lt;p&gt;更值得一提的是，Zapier MCP 在權限控制方面表現出色。用户可以精確地定義 AI 助手能夠執行的操作範圍，細化到具體的應用程序、功能乃至特定字段。這種設計有效防止了 AI 濫用權限的風險。例如，用户可以設置 AI 助手僅限於向某個特定的 Slack 頻道發送消息，或限制其只能訪問指定的 GitHub 倉庫。這種細粒度的控制不僅提升了安全性，也讓 MCP 服務更具靈活性和實用性。&lt;/p&gt; 
&lt;p&gt;使用 Zapier MCP 的過程也極為簡便。用户只需從 Zapier 平台複製一個專屬的 URL，並將其集成到 AI 助手中，即可快速啓用這些功能。無需複雜的編程或 API 對接，這一 「即插即用」 的特性大大降低了技術門檻，使得非專業人士也能輕鬆上手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340820/zapier-mcp-beta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340820/zapier-mcp-beta</guid>
            <pubDate>Sun, 23 Mar 2025 03:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>韓國 AI 芯片創企 FuriosaAI 拒絕 Meta 8 億美元收購要約</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韓國當地媒體&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mk.co.kr%2Fnews%2Fit%2F11271852&quot; target=&quot;_blank&quot;&gt;報道稱&lt;/a&gt;，專門生產 AI 應用芯片的韓國初創公司 Furiosa AI 與 Meta 的併購（M&amp;amp;A）談判最終破裂。 Furiosa AI 沒有出售經營權，而是選擇走自己的發展道路，並表現出了在全球 AI 半導體市場上成為 Nvidia 替代品的強烈意願。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;熟悉 Furiosa AI 的業內人士表示，「Meta 自去年 10 月開始，就一直在關注美國和以色列的幾家 AI 半導體公司，最終選定 Furiosa AI 作為有力的收購目標，並於年初進入談判階段。據我瞭解，談判破裂的原因並非在於價格問題，而在於雙方無法縮小收購後的業務方向和組織架構方面的分歧。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;343&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-10135a5f0e88e69040878ac3f175b618862.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 提出的收購價格為 8 億美元（約 1.2 萬億韓元），比市場評估的 Furiosa AI 的企業價值（約 8000 億韓元）高出約 4000 億韓元。對此，該相關人士表示「Furiosa AI 內部對收購價格進行了一些審查，但據報道，創始人白俊浩代表理事並不接受 Meta 併購後設想的經營方案」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，報道稱 Furiosa AI 已從韓國企業銀行獲得 300 億韓元的投資意向書（LOI），並正在與投資者洽談籌集約 700 億韓元，的資金，計劃在本月完成融資。這些資金將用於為其 Renegade 芯片的量產做準備以及支付運營費用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;FuriosaAI 成立於 2017 年。目前該公司共開發了兩款 AI 芯片，分別名為 Warboy 和 Renegade (RNGD)，以與 Nvidia 和 AMD 等公司競爭。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340819/furiosaai-turns-down-800m-acquisition-offer-meta</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340819/furiosaai-turns-down-800m-acquisition-offer-meta</guid>
            <pubDate>Sun, 23 Mar 2025 03:31:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>國家安全部通報：程序員帶原單位涉密成果跳槽違反保密協議且觸犯法律</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;國家安全部&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1bbY9zn_w5PAFKtP7qHL8Q&quot; target=&quot;_blank&quot;&gt;今日發佈通報&lt;/a&gt;&lt;/u&gt;，提醒部分跳槽人員不能帶着原單位的成果「投奔」新單位的行為，因為這不但違反了保密協議和競業禁止協議，更是觸犯了法律。&lt;/p&gt; 
&lt;p&gt;國家安全部原文如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;近年來，國家安全機關工作發現，個別涉密單位人員在離職後，明知違反保密規定，依然將在原單位工作期間的涉密成果作為「投名狀」帶到了新崗位，造成失泄密隱患。&lt;/p&gt; 
 &lt;h3&gt;心存僥倖不知過&lt;/h3&gt; 
 &lt;p&gt;徐某大學畢業後，一直在我某重點科研院所涉密崗位從事軟件開發工作，長期接受保密教育。因與妻子兩地分居，徐某決定離職和妻子一同到某市工作。經面試，徐某被該市某高新技術企業錄用。&lt;/p&gt; 
 &lt;p&gt;從原單位離職前，徐某瞭解到新公司經營產品和自己在老東家接觸的研究成果高度相似。於是，徐某打起了歪主意。適逢與外單位開展項目合作需要交接一批涉密電子文件，他趁機從原單位的軟件配置管理庫下載了一批涉密文件至工作電腦，以交接資料的名義經過審批後將相關涉密文件刻錄成光盤，導入個人互聯網筆記本電腦中。&lt;/p&gt; 
 &lt;p&gt;進入新單位後，徐某仍從事軟件開發相關工作，自己帶過來的「資源」似乎也確實發揮了一些作用。每念至此，徐某都不禁沾沾自喜，自認為神不知鬼不覺……&lt;/p&gt; 
 &lt;h3&gt;一錯再錯難回頭&lt;/h3&gt; 
 &lt;p&gt;不久，新單位取得保密資質證書，可以參與部分涉密項目，徐某也被定級為一般涉密人員。因為有前期「成功」的操作經驗，徐某在明知保密規章制度的情況下，還是屢次將新單位的涉密文件臨時導入自己電腦，自認為用後刪除就可以不留痕跡。直到被國家安全機關調查，徐某這才幡然醒悟，悔不當初。&lt;/p&gt; 
 &lt;p&gt;經查，徐某將原單位 25 份秘密級文件導入私人互聯網筆記本電腦；將新單位 2 份涉密文件導入私人互聯網筆記本電腦。鑑於接受詢問期間，徐某態度積極，主動配合調查，且暫未發現其非法持有的涉密文件有被進一步泄露、傳播的情況，未造成較大現實危害，國家安全機關會同有關單位依法對徐某作出行政處罰。&lt;/p&gt; 
 &lt;p&gt;對於涉事的兩家單位，國家安全機關會同有關單位開展安全防範提醒，指導涉事單位以此為鑑，強化措施補足漏洞，排查安全防範風險隱患，進一步加強涉密人員離職期管理，落實安全防範措施。相關單位按照國家安全機關要求，落實整改措施，取得較好的效果。&lt;/p&gt; 
 &lt;h3&gt;國家安全機關提醒&lt;/h3&gt; 
 &lt;p&gt;部分跳槽人員心存僥倖，帶着原單位的成果「投奔」新單位，不但違反了保密協議和競業禁止協議，更是觸犯了法律。《中華人民共和國反間諜法》第十四條規定，任何個人和組織都不得非法獲取、持有屬於國家秘密的文件、資料和其他物品。&lt;/p&gt; 
 &lt;p&gt;涉密人員一定要繃緊心中保密這根弦，嚴格遵守安全保密法律法規和單位保密制度，履行安全保密責任和義務，遵守脱密期管理規定，不得帶離涉密業務件資料和物品（包含電子文檔），以免貪小失大，鑄成大錯；相關單位須承擔起反間諜安全防範責任，加強對本單位人員監督管理，加強對涉密事項、場所、載體和人員的日常安全管理，定期或不定期開展問題排查，及時發現問題隱患。&lt;/p&gt; 
 &lt;p&gt;如身邊發現有類似情況，可通過 12339 國家安全機關舉報受理電話、網絡舉報平台（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.12339.gov.cn&quot; target=&quot;_blank&quot;&gt;www.12339.gov.cn&lt;/a&gt;）、國家安全部微信公眾號舉報受理渠道反映，或者直接向當地國家安全機關進行舉報。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1bbY9zn_w5PAFKtP7qHL8Q&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/1bbY9zn_w5PAFKtP7qHL8Q&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340818</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340818</guid>
            <pubDate>Sun, 23 Mar 2025 03:21:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蔡崇信：「AI 基建」建設潮存在泡沫，美科技巨頭投資很「盲目」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里巴巴集團董事會主席蔡崇信日前在香港舉行的滙豐全球投資峯會上表示，開始看到人工智能（AI）數據中心建設出現泡沫苗頭，他認為數據中心的建設速度可能會超過對人工智能服務的初期需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大型科技公司、投資基金和其他實體從美國到亞洲紛紛倉促建設服務器基地，這一現象開始顯得有些盲目。美國的許多數據中心投資公告都是「重複」或相互重疊的，這可能導致資源浪費和過度競爭。例如，多家公司通過 SPAC（特殊目的收購公司）集資建設數據中心，但尚未簽訂實際用户協議，缺乏明確市場需求支撐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信將泡沫風險歸因於三類企業行為：專注模型研發的 OpenAI 類企業、專注基建的硬件供應商，以及阿里等綜合型科技公司。他認為前兩類企業的部分投資存在協同不足的問題，而阿里選擇同時發展技術和基建，既能對外輸出服務，又可支持自身研發。此外，中國公司 DeepSeek 以 560 萬美元低成本開發出對標美國產品的大型語言模型（使用受限版 Nvidia 芯片），這引發對美企投資效率的質疑，可能加速泡沫破裂。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信特別指出了美國的支出情況。僅在今年，亞馬遜、Alphabet 和 Meta 就分別承諾在人工智能基礎設施上投入 1000 億美元、750 億美元和 650 億美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蔡崇信對與會者説：「我仍然對美國在人工智能投資方面所提到的那些數字感到震驚。人們真的在談論 5000 億美元、數千億美元這樣的數字。我認為這並非完全必要。在某種程度上，我覺得人們的投資超前於他們目前所看到的需求，不過他們預計未來會有大得多的需求。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，行業內部對泡沫判斷存在分歧。微軟、Meta 等公司強調 AI 需求遠超供給，計劃繼續擴大資本支出。Meta 稱其新一代 Llama 4 模型需要比當前高 10 倍的計算資源。但蔡崇信指出，當前 AI 性能評估體系滯後於技術發展，部分基建可能因技術迭代而過早淘汰，特別是三級市場的訓練數據中心面臨適應性挑戰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除行業分析外，蔡崇信還透露了阿里戰略調整：員工數量觸底後將重啓招聘，通過股息回報股東。這顯示阿里在警惕外部泡沫的同時，正強化內部競爭力。綜合來看，AI 數據中心泡沫本質是技術爆發期資本過度追捧與市場需求不確定性的矛盾體現，其演化將取決於技術商業化進程與資源供給效率的平衡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340816</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340816</guid>
            <pubDate>Sun, 23 Mar 2025 03:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek-V3 技術解析」：DeepSeekMoE</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 為什麼説 DeepSeekMoE 的&quot;共享專家隔離&quot;設計，既能保留通用知識又能減少冗餘？傳統 MoE 的專家真的&quot;專精&quot;嗎？傳統 MoE 專家易&quot;崩潰&quot;，DeepSeekMoE 如何通過&quot;更細粒度的專家分割&quot;讓每個專家專注更小領域，解決負載不均衡問題？&lt;/p&gt; 
 &lt;p&gt;作者巧妙地用餐廳廚師的比喻，將抽象的技術概念形象化 ------ 是聘用一位熟悉多種菜系的廚師，還是聘用多位各有專長的廚師更明智？隨後，文章深入剖析了 DeepSeekMoE 的兩大創新：更細粒度的專家分割通過增加專家數量並降低單個專家的參數規模，促進了專家的專業化；共享專家隔離則通過預留部分專家處理通用知識，減少了專家間的知識冗餘。實驗結果表明，在相同計算成本下，DeepSeekMoE 不僅性能更優，其專家的不可替代性也更強，知識冗餘度更低。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shirley Li&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這是 DeepSeek-V3 系列的第二篇文章，本文將解析 DeepSeek[1,2,3] 模型的另一個關鍵架構創新：DeepSeekMoE[4]。&lt;/p&gt; 
&lt;p&gt;「DeepSeek-V3 技術解析」專欄其他文章：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17943880&quot;&gt;「DeepSeek-V3 技術解析」：多頭潛在注意力機制（MLA）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;具體而言，本文將解釋混合專家系統（Mixture-of-Experts，MoE）的工作原理、為什麼該技術在 LLMs 領域備受青睞及其面臨的挑戰。我們還將探討 expert specialization（譯者注：在 MoE 架構中，每個專家能夠獲取不重疊且聚焦的知識。） 與 knowledge sharing（譯者注：指通過門控網絡與專家模型的協同機制，使不同專家在獨立處理特定任務的同時，仍能共享底層知識或通用特徵，從而提升模型的整體性能和效率。） 之間的權衡，以及 DeepSeekMoE 如何實現更優的平衡。&lt;/p&gt; 
&lt;p&gt;最精彩的部分：&lt;strong&gt;為了讓這些概念更直觀，本文將通過餐廳這個場景來類比解析整個系統，藉助廚房中廚師的角色來闡釋 MoE 的各個要素。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本文目錄：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;技術背景&lt;/strong&gt;：介紹 MoE 的工作原理、優勢與面臨的挑戰，探討 expert specialization 與 knowledge sharing 之間的權衡&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeekMoE 架構&lt;/strong&gt;：解析更細粒度的專家分割（Fine-Grained Expert Segmentation）和共享專家隔離（Shared Expert Isolation）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;評估&lt;/strong&gt;：通過多個有趣實驗討論 DeepSeekMoE 的性能表現&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;總結&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;參考文獻&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;01 技術背景&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 MoE（混合專家系統）在 LLM 中的應用&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 LLM（大語言模型）中，MoE 通常是指用 MoE 層替換 Transformer 模型中的 FFN（前饋神經網絡）層，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ced184ccd8ce5f93b72ade1bc0267c3f444.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 1. MoE 層示意圖，圖片來自 GShard 論文[5]&lt;/p&gt; 
&lt;p&gt;具體來説，左側展示的是由 N 個 Transformer 層組成的堆疊結構，每層包含一個 MHA（多頭注意力）子層和一個 FFN 子層。而右側展示的是由 N/2 個 Transformer 層組成的堆疊結構，其中下層 Transformer 的 FFN 子層被替換為 MoE 層。換言之，每隔一個 Transformer 層，其 FFN 子層就會被 MoE 層替代。實際應用中，可以按指定間隔將 FFN 替換為 MoE 層。&lt;/p&gt; 
&lt;p&gt;若進一步觀察 MoE 層，會發現它包含一個門控（Gating）操作和一組具有相同架構的 FFN（與標準 FFN 子層一致）。這些 FFN 層在 MoE 中被稱為&quot;專家&quot;，門控操作通過訓練學習選擇激活哪些專家來處理特定輸入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f6b88814ad22037e4841e1b3ee3b5961422.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2. 包含門控操作和多個 FFN 專家的 MoE 層，圖片來自文獻[5]&lt;/p&gt; 
&lt;p&gt;MoE 的通用架構可形式化描述如下（公式編號沿用自文獻[4]）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8a79193e3764eee82931b1ad7d0546ad52e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;u^l_t 和 h^l_t 分別表示第 l 層中第 t 個 token 的輸入和輸出的隱藏狀態（hidden state）。&lt;/li&gt; 
 &lt;li&gt;FFN_i 是 N 個專家中的第 i 個專家。&lt;/li&gt; 
 &lt;li&gt;g_{i, t} 是第 t 個 token 對第 i 個專家的門控值，該值通過對 Softmax 的輸出應用 TopK 操作獲得。&lt;/li&gt; 
 &lt;li&gt;e^l_i 在公式 (5) 中常被稱為第 i 個專家的&quot;質心（centroid）&quot;，可通過聚合歷史上路由到該專家的所有輸入 token 計算得到：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4e0de690fdfdeb20a97ac832e163f25785a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該公式由原文作者創建&lt;/p&gt; 
&lt;p&gt;公式逐步解析（從公式 (5) 到公式 (3) 反向説明）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;公式 (5)：通過計算 u^l_t 與 e^l_i 的內積，衡量當前輸入 token 與歷史上路由到第 i 個專家的所有輸入 token 的均值的相似度。若專家 i 處理過大量與當前 token 相似的輸入，則其處理當前 token 的能力更強。隨後對結果應用 Softmax，將其轉換為概率分佈。由於共有 N 個專家，每個 token 會得到 N 個 s_{i, t} 值。&lt;/li&gt; 
 &lt;li&gt;公式 (4)：對 s_{i, t} 值應用 TopK 操作，生成稀疏的 g_{i, t} 值。&lt;/li&gt; 
 &lt;li&gt;公式 (3)：利用稀疏的 g_{i, t} 值選擇 K 個專家來計算輸出的隱藏狀態。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;換言之，對於第 t 個 token，僅會激活 N 個專家中的 K 個（通常 K 遠小於 N），導致門控值 g_{i，t} 呈現稀疏性。通過這種設計，模型的可訓練參數總量會因增加的 FFN 而上升，但前向傳播時僅激活其中一小部分參數。&lt;/p&gt; 
&lt;p&gt;這正是採用 MoE 的 LLM 在描述模型規模時常用 &quot;總參數量 XX，其中每個 token 激活 YY&quot; 的原因 ------ 例如 DeepSeek-V3 ：&lt;/p&gt; 
&lt;p&gt;&quot;模型總參數量 2360 億，每個 token 激活 210 億參數......&quot;&lt;/p&gt; 
&lt;p&gt;那麼，如果增加更多參數，MoE 有何優勢？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 MoE 的優勢與面臨的挑戰&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MoE 最妙的地方在於它體現了許多具有相似原理的現實場景，因此我們可以通過這些案例更直觀地理解它。&lt;/p&gt; 
&lt;p&gt;現在假設我們要為一家同時提供中餐和意大利菜的餐廳僱傭廚師，有兩種選擇：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;選項 1：僱傭一位同時精通中餐和意大利菜的廚師，這樣他/她可以獨自處理所有菜品。這類似於標準 Transformer 模型，由單個 FFN 子層處理所有輸入 token。&lt;/li&gt; 
 &lt;li&gt;選項 2：僱傭多位各有所長的廚師（比如中餐專家和意大利菜專家），再加一位主廚根據訂單內容指派擅長該菜系的廚師處理。這類似於 MoE 方法，每個廚師充當專家，主廚則作為門控機制（Gating）來選擇專家。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通過以上類比可以明顯看出，選項 2 不僅更容易招聘人才，還能保證兩種菜系都保持高水準。相比之下，要找到同時精通多種菜系的單一廚師難度極大（甚至不可能），我們可能不得不降低菜品質量要求。&lt;/p&gt; 
&lt;p&gt;回到 LLM 場景，構建 MoE 的動機部分源於&quot;擴展假説&quot;（scaling hypothesis），即在大規模數據上擴展 LLM 時更可能湧現出新的能力，這也是為什麼我們看到現在 LLM 的規模越來越大的原因 ------ 比如 GPT 模型已從 117M 參數擴展到 175B 參數。&lt;/p&gt; 
&lt;p&gt;然而並非所有人都有機會訓練如此大規模的 LLM，而 MoE 提供了一種折中方案：&lt;strong&gt;通過僅激活每個輸入 token 對應的少量參數，我們可以在擴大模型規模（增加模型容量）的同時，保持訓練和推理成本可控。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如文獻[4]所示，你可以訓練一個 2B 參數的模型僅激活 0.3B 參數，或訓練 16B 參數模型僅激活 2.8B 參數，甚至還可以訓練 145B 參數的模型僅激活 22.2B 參數。在每種情況下，每次僅使用總參數量的約 1/7，大大提升了訓練和推理效率。&lt;/p&gt; 
&lt;p&gt;然而，每種設計都有其侷限性，並會帶來新的挑戰。&lt;strong&gt;就 MoE 而言，其性能高度依賴門控機制的有效性 ------ 因為無法保證門控始終將每個輸入 token 路由到最優專家，且可能出現少數專家處理大部分輸入 token，而其他專家因缺乏訓練機會無法充分發揮作用的現象。&lt;/strong&gt; 這通常被稱為&quot;專家崩潰&quot;（expert collapse）問題。&lt;/p&gt; 
&lt;p&gt;這還會導致其他問題，例如負載不均衡（多數 token 被路由到少數專家）和不穩定性（當 token 被路由到未經充分訓練的專家時效果欠佳）。&lt;/p&gt; 
&lt;p&gt;這就是為什麼我們在 MoE 架構領域中經常能夠看到大量關於負載均衡的討論。&lt;/p&gt; 
&lt;p&gt;DeepSeekMoE 也提出了若干負載均衡策略，但本文將聚焦其核心創新點，關於無輔助損失負載均衡（auxiliary-loss-free load balancing）[8]的深入解析將在後續文章中展開。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Knowledge Specialization vs. Knowledge Sharing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在上述餐廳案例中，我們做僱傭決策時其實也在權衡 expert specialization（譯者注：在 MoE 架構中，每個專家能夠獲取不重疊且聚焦的知識。） 與 knowledge sharing（譯者注：指通過門控網絡與專家模型的協同機制，使不同專家在獨立處理特定任務的同時，仍能共享底層知識或通用特徵，從而提升模型的整體性能和效率。）：選項 1 追求通才但可能犧牲技能深度，選項 2 追求專精。這種權衡廣泛存在於現實場景的各類組織中（如企業、團隊等）。&lt;/p&gt; 
&lt;p&gt;在 MoE 中這種權衡同樣存在，但呈現形式更為隱晦。理論上，每個專家都應具備特定領域的專長，因為每個專家僅處理部分輸入 token；同時所有專家仍會共享部分通用知識，因為它們共享大量參數。與現實場景不同，我們很難界定每個專家的專精程度及他們掌握的通用知識範圍的邊界。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;權衡 expert specialization 與 knowledge sharing 是 MoE 架構設計的關鍵考量因素，因為過度專精與過度冗餘均非理想狀態。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前一種情況下，過度專精的專家會導致訓練和推理的不穩定，任何次優的路由都可能顯著影響性能。同時這往往會造成模型容量利用率不足，因為高度專精的專家只能處理極少數 token。&lt;/p&gt; 
&lt;p&gt;在後一種情況下，若專家間掌握的知識過於相似，MoE 引入的額外參數將無法帶來成比例的容量提升，這顯然是對有限計算資源的浪費。&lt;/p&gt; 
&lt;p&gt;下一節我們將看到 DeepSeekMoE 如何實現兩者的更優平衡。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeekMoE 架構&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeekMoE 通過兩項關鍵技術創新來平衡 MoE 中的 knowledge specialization 和 knowledge sharing，即更細粒度的專家分割（fine-grained expert segmentation）和共享專家隔離（shared expert isolation）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fa5bc97296f68f5b7ba2bfb1f829780de51.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 3. DeepSeekMoE 示意圖。圖片來自文獻[4]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 更細粒度的專家分割&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeekMoE 提出更細粒度的專家分割以促進專家的專業化，提出該技術的想法非常簡單：&lt;strong&gt;對於每個輸入 token，如果有更多專家被激活，那麼處理該 token 所需的知識就更有可能被分解並由不同專家獲取。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文的餐廳案例中，就類似於將每位廚師的技能進行專業化拆分，如下圖所示。最初，我們讓一位廚師負責所有中餐，另一位負責所有意大利菜。應用更細粒度的專家分割（fine-grained expert segmentation）後，每種菜系所需的技能被拆分給多個專家掌握，於是我們得到一組專精中餐的廚師和另一組專精意大利菜的廚師，每位廚師只需掌握該菜系的特定技能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f91fdf07e11b67ac56a9fb4a7c900094672.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 4. 用餐廳案例説明 (a) 應用前和 (b) 應用更細粒度的專家分割後的對比。由原文作者供圖。&lt;/p&gt; 
&lt;p&gt;圖 3 也説明瞭這一點：子圖 (a) 中每個輸入 token 被路由到 N 個專家中的 2 個，而子圖 (b) 中每個 token 被路由到 2N 個專家中的 4 個。在更一般的情況下，我們可以將專家數量從 N 增加到 mN，同時將每個專家 FFN 的中間隱藏層維度降至 1/m，併為每個輸入 token 激活 m 倍的專家數量。通過這種方式，(a) 和 (b) 的總體計算成本將大致保持相同。&lt;/p&gt; 
&lt;p&gt;儘管作者未對該策略的有效性提供理論證明，但他們確實設計了實驗來驗證這一思路，我們將在&quot;評估&quot;部分詳述。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 共享專家隔離&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeekMoE 提出的另一項技術是隔離部分共享專家以減少冗餘，提出該技術的核心想法在於：&lt;strong&gt;若預留部分共享專家來學習不同任務的通用知識，可給其他專家更多的自由來剝離此類通用知識，從而減少非共享專家間的冗餘。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文提到的餐廳案例中，這就類似於將所有廚師進一步劃分為兩組（如下圖所示）：上方第一組廚師掌握刀工、火候、調味等通用烹飪技能，下方第二組廚師專注於自己的特色菜品。&lt;/p&gt; 
&lt;p&gt;例如，包餃子的師傅只需專注包捏與蒸煮餃子，無需考慮擺盤技巧；意麪師傅只需鑽研意麪的製作，無需學習刀工。由此減少廚師間的知識冗餘。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3eea41c211b4e69c8b2c60abde72860bef2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 5. 基於圖 4 的餐廳案例，進一步添加共享專家隔離的示意圖。由原文作者供圖。&lt;/p&gt; 
&lt;p&gt;圖 3 (c) 也展示了該策略的實現方式：選定一個專家作為共享專家（綠色高亮標記），所有輸入 token 均不經路由層（Router）直接激活該專家，同時將激活的專項專家數量從 4 個減至 3 個，使總激活專家數量與圖 3 (b) 保持相同。&lt;/p&gt; 
&lt;p&gt;綜上，DeepSeekMoE 架構可形式化表示為下圖右側公式（左側為傳統 MoE 架構作為對比）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-80ce0a46d0641ef3f9e7ccb193aca0af1b4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 6. (左) 傳統 MoE vs. (右) DeepSeekMoE。作者根據文獻 [4] 中的公式繪製該圖。&lt;/p&gt; 
&lt;p&gt;其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;式 (11) 與傳統 MoE 的式 (5) 相同&lt;/li&gt; 
 &lt;li&gt;式 (10) 與式 (4) 類似，但此處通過 TopK 從 (mN-K_s) 個專家中選擇 (mK-K_s) 個，K_s 表示共享專家數量&lt;/li&gt; 
 &lt;li&gt;式 (9) 將式 (3) 的第一項拆分為兩個子項，分別對應共享專家與路由專家&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;原文同樣未對該策略提供理論證明，但後續評估結果表明：&lt;strong&gt;引入共享專家既能提升性能，又能有效降低知識冗餘。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Evaluation&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;正如前文所述，儘管兩項策略的直覺依據看似合理，但作者並未提供理論證明，因此我們仍需驗證：這些策略是否真能緩解 expert specialization（譯者注：在 MoE 架構中，每個專家能夠獲取不重疊且聚焦的知識。） 與 knowledge sharing（譯者注：指通過門控網絡與專家模型的協同機制，使不同專家在獨立處理特定任務的同時，仍能共享底層知識或通用特徵，從而提升模型的整體性能和效率。）的衝突？其有效性程度如何？&lt;/p&gt; 
&lt;p&gt;我們主要關注三個核心問題：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeekMoE 能否取得更好效果？&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更細粒度的專家分割能否促進 expert specialization？其作用程度如何？&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;共享專家隔離能否減少冗餘？其作用程度如何？&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為解答這些問題，作者設計了系列實驗，在此有必要詳述。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 DeepSeekMoE 能否取得更好效果？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先驗證該方法能否提升整體性能。作者訓練了總參數/激活參數規模相當的多個模型，並在不同任務上評估它們的性能。主要結果如下表所示（最優指標用粗體標註）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-409e0f09e7147196f8e5f475b7bbad25372.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 7. 整體性能對比。作者根據文獻 [4] 表 1 整理。&lt;/p&gt; 
&lt;p&gt;幾點啓示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;藍色高亮列對比標準 Transformer（Dense）與兩種 MoE 架構（Hash Layer [6]和 Switch Transformer [7]）：在激活參數量相近時，MoE 架構性能顯著更優。&lt;/li&gt; 
 &lt;li&gt;綠色高亮列進一步比較了 DeepSeekMoE 與另一種 MoE 方法 GShard [5]：在激活參數量相近時，DeepSeekMoE 性能明顯更優。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;但性能提升並不直接等同於更好地平衡了 expert specialization 與 knowledge sharing 的衝突，因此仍需其他實驗驗證。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 DeepSeekMoE 是否促進了專家的專業化？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;直接衡量專家的專業化程度較為困難，作者轉而設計了一項反向實驗：禁用部分高優先級路由專家並觀察性能變化。&lt;/p&gt; 
&lt;p&gt;從直覺上講，專家專業化程度越高時其不可替代性越強，因此禁用高優先級路由專家應該會導致更明顯的性能下降。&lt;/p&gt; 
&lt;p&gt;更具體一點，作者在 DeepSeekMoE 和 GShard x 1.5（作為 baseline）中逐步禁用高優先級路由專家。兩種方法在未禁用專家時的 Pile loss 相當（對應下圖中禁用比例為 0 時的最左側數據點）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-af7e24704358701ad717f6b843a4b90c45d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 8. 禁用高優先級路由專家時 DeepSeekMoE 與 GShard x 1.5 的 Pile loss 對比。圖片來自文獻[4]。&lt;/p&gt; 
&lt;p&gt;隨着禁用路由專家比例的增加，DeepSeekMoE 的 Pile loss 持續高於 baseline，表明其路由專傢俱有更強的專業性，因此更難被其他專家替代。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 DeepSeekMoE 是否能夠減少知識冗餘？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;按照類似的思路，作者還嘗試禁用共享專家並額外激活了一個路由專家，以觀察共享專家是否可被替代。&lt;/p&gt; 
&lt;p&gt;實驗結果顯示&quot;Pile loss 從 1.808 明顯上升，至 2.414&quot;，這證明瞭共享專家學習的知識具有獨特性，而路由專家未能充分覆蓋該部分知識。換言之，路由專傢俱有更高專業性且冗餘度更低。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Summary&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文通過餐廳案例進行類比，解析了 DeepSeek-V2、DeepSeek-V3 等模型的核心架構創新之一 ------ DeepSeekMoE。&lt;/p&gt; 
&lt;p&gt;具體而言，本文首先介紹了通用 MoE 的工作原理、優勢及面臨的挑戰，以及 expert specialization 與 knowledge sharing 之間的權衡關係。隨後重點解析了 DeepSeekMoE 的兩大核心設計：更細粒度的專家分割（fine-grained expert segmentation）與共享專家隔離（shared expert isolation），並通過實驗驗證了其有效性。&lt;/p&gt; 
&lt;p&gt;核心結論：DeepSeekMoE 在保持與通用 MoE 架構相當計算成本的條件下，通過促進專家的專業化實現了更優效果，從而實現更高的計算效率。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;參考文獻&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] DeepSeek（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] DeepSeek-V3 Technical Report（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FDeepSeek-V3%2Fblob%2Fmain%2FDeepSeek_V3.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2401.06066）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16668%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2006.16668）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] Hash Layers For Large Sparse Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2106.04426%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2106.04426）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2101.03961%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2101.03961）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2408.15664%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2408.15664）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Shirley Li&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I am a Machine Learning Engineer working on building multi-modality models to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;文章中的餐廳廚師類比是否幫助你理解了這個概念？如果讓你用身邊的例子來解釋 DeepSeekMoE 架構，你會用什麼比喻？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.gopubby.com%2Fdeepseek-v3-explained-2-deepseekmoe-106cffcc56c1&quot; target=&quot;_blank&quot;&gt;https://ai.gopubby.com/deepseek-v3-explained-2-deepseekmoe-106cffcc56c1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17961367</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17961367</guid>
            <pubDate>Sun, 23 Mar 2025 03:11:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>ARC-AGI-2 基準測試發佈：AI 模型表現慘淡，效率指標成智能評估新維度</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Arc Prize Foundation 近日推出全新 AGI 基準測試&lt;strong&gt;ARC-AGI-2&lt;/strong&gt;，旨在更精準衡量 AI 模型的通用智能水平。&lt;/p&gt; 
&lt;p&gt;測試結果顯示，當前主流模型的平均得分僅為 1%-1.3%，遠低於人類平均 60% 的基準。該測試由知名 AI 研究者 François Chollet 聯合發起，通過視覺邏輯謎題評估 AI 的跨領域推理能力，並首次引入「效率」指標，直指行業長期忽視的算力成本問題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;測試設計：防止暴力破解，強調模式泛化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;ARC-AGI-2 由多色方格組成的動態謎題構成，要求 AI 從未見過的模式中推導答案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a37b4b4ccb6de16539a4e754d02e1504cfa.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相比前代測試，新版通過兩項關鍵改進堵住漏洞：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;禁止訓練數據複用&lt;/strong&gt;：答案無法通過簡單記憶獲得，需實時推理&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效率約束&lt;/strong&gt;：要求每道題算力成本不超過$0.42（OpenAI 此前在 ARC-AGI-1 中單題耗資$200）&lt;br&gt; Chollet 在社交平台強調，新測試更接近「真實智能」——即用有限資源快速掌握新技能的能力（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2Ffchollet%2Fstatus%2F123456789&quot; target=&quot;_blank&quot;&gt;X 推文&lt;/a&gt;）。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;模型表現：頂級選手集體翻車&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;根據&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fleaderboard&quot; target=&quot;_blank&quot;&gt;Arc Prize 榜單&lt;/a&gt;，當前表現最佳的模型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI o1-pro&lt;/strong&gt;：1.3%（推理型）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek R1&lt;/strong&gt;：1.1%（推理型）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPT-4.5/Claude 3.7/Gemini 2.0&lt;/strong&gt;：約 1%（非推理型）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;對比人類測試者平均 60% 的正確率，差距顯著。值得注意的是，此前在 ARC-AGI-1 中達到人類水平的 OpenAI o3（低配版），在 ARC-AGI-2 中僅獲 4% 得分，突顯新測試的挑戰性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e504f2c4b02012584b8e6ce920c3e0ab9c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行業啓示：算力競賽轉向效率戰場&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Arc Prize 聯合創始人 Greg Kamradt 在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fblog&quot; target=&quot;_blank&quot;&gt;博客&lt;/a&gt;中指出，AI 行業需重新定義智能標準：「如果解決一個問題需要消耗一座核電站的能源，這種‘智能’對人類社會毫無意義。」&lt;/p&gt; 
&lt;p&gt;該觀點與 Hugging Face 聯合創始人 Thomas Wolf 近期呼籲相呼應——行業亟需能衡量創造力、成本效益的新評估體系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;開發者挑戰：$0.42 預算衝擊 85% 準確率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;伴隨新測試發佈的還有&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farcprize.org%2Fcontest&quot; target=&quot;_blank&quot;&gt;Arc Prize 2025 競賽&lt;/a&gt;，要求參賽者在單題$0.42 的算力約束下衝擊 85% 準確率。這場低成本高難度的挑戰，或將推動小參數模型與新型訓練範式的突破。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;最後歡迎大家參加討論：當算力成本成為智能評估標準，MoE 架構與蒸餾技術會否迎來新爆發？&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340814/a-new-challenging-agi-test-stumps-most-ai-models</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340814/a-new-challenging-agi-test-stumps-most-ai-models</guid>
            <pubDate>Sun, 23 Mar 2025 03:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>mcp-filesystem-server —— Go 實現的模型上下文協議</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;一個用 Go 語言實現的模型上下文協議（Model Context Protocol, MCP）項目，旨在實現大語言模型（LLM）應用與外部數據源及工具的無縫集成。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;該項目的主要目的是學習&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;github.com/metoro-io/mcp-golang&lt;/code&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;。由於&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;github.com/mark3labs/mcp-filesystem-server&lt;/code&gt;&lt;span style=&quot;background-color:#fcfcfc; color:rgba(0, 0, 0, 0.9)&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;已存在文件系統服務器實現，本項目也基於此進行開發。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/mcp-filesystem-server</link>
            <guid isPermaLink="false">https://www.oschina.net/p/mcp-filesystem-server</guid>
            <pubDate>Sun, 23 Mar 2025 02:59:00 GMT</pubDate>
        </item>
        <item>
            <title>獵豹移動 CEO 傅盛：最近沉迷敲代碼，打算讓所有員工都去學習 AI 編程</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 23 日，獵豹移動 CEO 傅盛在社交平台&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1554710050%2FPjQReaWyL%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;發佈視頻稱&lt;/a&gt;&lt;/u&gt;，自己最近沉迷敲代碼，還打算讓所有員工都去學習 AI 編程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/105435_G9Ao_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;傅盛稱，自己大學畢業以後就沒真正寫過程序，就當一個產品經理。現在產品經理要被淘汰了，人人都是程序員了。視頻中，傅盛還談及「AI 編程都這麼厲害了，還有沒有必要學編程」的問題。&lt;/p&gt; 
&lt;p&gt;傅盛表示，AI 能寫代碼和學編程完全不衝突，因為程序就是構建我們未來世界的基礎。傅盛稱，學代碼有兩個好處，尤其是青少年。第一個是學習編程以後，才知道未來的世界是如何運作，得懂基本原理。第二個，由於 AI 編程很厲害，所以現在學編程能極大提高工作效率。他覺得不僅是青少年要學編程，每個人都應該學編程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/340717/ibms-ceo-doesnt-think-ai-will-replace-programmers-anytime-soon&quot; target=&quot;news&quot;&gt;IBM CEO：AI 短期內不會取代程序員&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/338784&quot; target=&quot;news&quot;&gt;計算機科學家吳恩達對「AI 將取代程序員」的看法&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months&quot; target=&quot;news&quot;&gt;Anthropic CEO：未來 3-6 個月內，90% 的代碼將由 AI 編寫&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/337519/anthropic-mike-krieger-how-software-engineering-work-changing&quot; target=&quot;news&quot;&gt;未來三年，軟件工程師或將轉型為 「AI 代碼審核員」&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/259402&quot; target=&quot;news&quot;&gt;GitHub CEO：AI 無法取代程序員&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/282381&quot; target=&quot;news&quot;&gt;李彥宏：未來可能不會存在程序員這種職業&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340806</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340806</guid>
            <pubDate>Sun, 23 Mar 2025 02:56:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 領導層改組，CEO 奧爾特曼將更專注於研究和產品開發</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fleadership-updates-march-2025%2F&quot; target=&quot;_blank&quot;&gt;OpenAI 宣佈領導層改組&lt;/a&gt;&lt;/u&gt;，首席執行官薩姆・奧爾特曼（Sam Altman）將更專注於研究和產品開發。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0325/104903_xosp_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;奧爾特曼表示，隨着公司業務規模持續擴張，三位核心高管將承擔更多職責，以推動前沿 AI 研究並加速實現造福全人類的 AGI 使命。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;馬克・陳（Mark Chen）升任首席研究官（Chief Research Officer）：統籌科研進展，確保在 AI 能力與安全領域持續突破。他將加強研究與產品開發整合，加速科研成果向用户喜愛產品的轉化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;首席運營官（Chief Operating Officer）布拉德・萊特卡普（Brad Lightcap）職權進一步擴展：全面負責公司業務與日常運營，重點包括領導全球部署，聚焦商業戰略、關鍵合作伙伴關係、基礎設施與卓越運營。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Julia Villagra 上任首席人才官（Chief People Officer）：繼續支持公司全球擴張，確保 OpenAI 持續吸引頂尖 AGI 人才等等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340803/openai-leadership-updates-march-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340803/openai-leadership-updates-march-2025</guid>
            <pubDate>Sun, 23 Mar 2025 02:49:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>