<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 02 Apr 2025 12:45:11 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>OpenAI 上線學習平台：OpenAI 學院（OpenAI Academy）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 上線了官方學習平台「OpenAI 學院 (OpenAI Academy)」：一個面向所有人的 AI 學習社區，主打「專家引領+社羣共創」，目標是讓普通人也能玩轉 AI，學習與人工智能相關的知識和技能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1350&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/193429_zKzx_2720166.png&quot; width=&quot;3318&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Facademy.openai.com%2F&quot; target=&quot;_blank&quot;&gt;https://academy.openai.com/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 學院已上架許多豐富的視頻課程，目前提供了數十小時的免費內容供用户使用，還在持續更新中。&lt;/p&gt; 
&lt;h3&gt;核心亮點速覽&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&amp;nbsp;&lt;strong&gt;零門檻免費學&lt;/strong&gt;：從 K12 教師到非營利組織，課程覆蓋全人羣，目前無證書但乾貨滿滿&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;專家實時互動&lt;/strong&gt;：每週多場線上活動，比如 4 月 4 日的《老年人 AI 入門》、4 月 8 日的《用 GraphRAG 構建知識圖譜》等，時區友好（多場次在 CST 上午）&lt;br&gt; &lt;img height=&quot;729&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/193712_2ycp_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;內容短平快&lt;/strong&gt;：已有《ChatGPT Edu 學術助手指南》《提示詞大師課》等視頻，單條播放量破萬，適合碎片化學習&lt;br&gt; &lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0402/193748_Gmqp_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;社羣怎麼玩？&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;隨時提問&lt;/strong&gt;：直接私信羣成員，和同行、專家交流&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;線下擴展中&lt;/strong&gt;：目前活動以美國為主，但官方明確表示「很快全球化」，還鼓勵社區自主發起活動（聯繫 academy@openai.com）&lt;/p&gt; 
&lt;h3&gt;他們為什麼做這個？&lt;/h3&gt; 
&lt;p&gt;答案很 OpenAI 風格：「確保 AI 造福全人類」。 Academy 的定位不是高高在上的技術講堂，而是幫你&lt;strong&gt;把 AI 真正用起來&lt;/strong&gt;——無論是提升工作效率，還是解決公益難題。&lt;/p&gt; 
&lt;p&gt;官網直達：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Facademy.openai.com&quot; target=&quot;_blank&quot;&gt;https://academy.openai.com&lt;/a&gt;&lt;br&gt; 語言支持：目前僅英文，其他語言「很快」上線。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342509/openai-academy</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342509/openai-academy</guid>
            <pubDate>Sun, 23 Mar 2025 11:40:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>生成式 3D AI 公司 VAST 開源基礎 3D 生成模型 TripoSG 和 TripoSF</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;VAST 是一家 AIGC 3D 大模型創業公司，近日宣佈開源兩組基礎 3D 生成模型&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FVAST-AI-Research%2FTripoSG&quot; target=&quot;_blank&quot;&gt;TripoSG&lt;/a&gt;&lt;/u&gt;和&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FVAST-AI-Research%2FTripoSF&quot; target=&quot;_blank&quot;&gt;TripoSF&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;據介紹，TripoSG 是一個基於 RF 的 MoE Transformer 3D 生成基礎模型。經測試，TripoSG 生成質量約等同於 Tripo2.0，高於市面已有的開源 3D 生成項目。突出的優勢是生成結果的泛化性強，生成複雜組合物體的穩定性高。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;610&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;TripoSF 是 VAST 基於一個新的 3D 表示 SparseFlex 研發的 3D 基礎模型。經過測試，其結果超過市面上所有開源和閉源的工作，本次開源了 TripoSF VAE 的預訓練模型及相關的推理代碼，將在 Tripo3.0 時體驗到 TripoSF 的滿血版效果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-725e6e1548a3424cd71e1e16b0b99b55787.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;TripoSG 項目主頁：https://yg256li.github.io/TripoSG-Page/&lt;/li&gt; 
 &lt;li&gt;TripoSF 項目主頁：https://xianglonghe.github.io/TripoSF/&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342506</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342506</guid>
            <pubDate>Sun, 23 Mar 2025 11:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 新專利公開：優化網頁採集流程，降低網絡資源消耗</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;4 月 1 日，DeepSeek 關聯公司杭州深度求索人工智能基礎技術研究有限公司申請的「&lt;strong&gt;一種廣度數據採集的方法及其系統&lt;/strong&gt;」專利在國家知識產權局正式公佈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f99f428eba1d1be7957ad151e46fedb581a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據專利摘要介紹，該方法旨在在儘可能多發現網頁鏈接的同時，降低網站流量衝擊。系統通過分析已下載內容並對未下載鏈接進行質量推斷，採用擇優下載的機制分配額度，從而減少低質量或重複內容的採集，提高數據質量與下載效率，有效降低數據採集過程中的網絡資源消耗。&lt;/p&gt; 
&lt;p&gt;此外，該方法還通過引入獨立的信息回灌隊列，確保網頁元信息庫的修改操作具備原子性與穩定性。&lt;/p&gt; 
&lt;p&gt;據悉，隨着大語言模型在自然語言處理領域的廣泛應用，高質量、多樣化的訓練語料需求不斷提升。當前網頁採集中存在諸多問題，如鏈接獲取不全、網站過載風險以及重複或低質下載等。該專利試圖從技術層面提升採集系統的效率與安全性，為大模型訓練提供更穩健的數據基礎。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342502</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342502</guid>
            <pubDate>Sun, 23 Mar 2025 10:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>MiniMax Audio 發佈 Speech-02 模型：單次輸入支持 20 萬字符</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;MiniMax Audio&amp;nbsp;正式發佈了全新的 Speech-02 系列語音模型，支持將任何文件或 URL 轉換為逼真的音頻。用户只需一次輸入，即可輕鬆創建有聲讀物和播客，最多可輸入 20 萬個字符，支持 30 多種語言的音頻生成，效果自然流暢。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1242&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/182343_cVnE_2720166.png&quot; width=&quot;1242&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Speech-02 模型支持 30 多種語音，一次性可以輸入 20 萬字符。為用户帶來更真實、更流暢、更便捷的音頻體驗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0402/182628_p3an_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;據官方介紹，該系列在多語言覆蓋能力上實現了顯著提升，能夠更準確、更地道地呈現多種語言的發音。Speech-02 的人聲相似度高達 99%，這意味着合成的語音聽起來更加自然、貼近真人。&lt;/p&gt; 
&lt;p&gt;此外，該模型還實現了零節奏故障，徹底解決了音頻播放過程中可能出現的卡頓和節奏不穩問題，保證了聽感的連貫性和流暢性。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;使用地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.minimax.io%2Faudio&quot; target=&quot;_blank&quot;&gt;https://www.minimax.io/audio&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342494</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342494</guid>
            <pubDate>Sun, 23 Mar 2025 10:26:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>【直播】基於昇騰的大模型創新應用和實踐指南</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;隨着大模型技術快速發展，其在自然語言處理、多模態交互等領域的應用逐漸深入產業場景。然而，開發者與企業落地大模型時仍面臨算力需求高、推理效率不足、部署成本優化難等現實問題。昇騰 AI 基礎軟硬件平台通過異構計算架構、全場景 AI 框架等技術，為大模型開發與部署提供了高效支撐體系。&lt;/p&gt; 
&lt;p&gt;4 月 9 日晚，開源中國 OSCHINA 直播欄目【數智漫談】將邀請具備一線開發經驗的技術專家，聚焦&lt;strong&gt;昇騰平台與大模型結合的創新實踐。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播亮點：&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     昇騰+大模型落地的真實場景與創新案例解析 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     從算法壓縮到硬件協同，解密企業級模型高效部署策略 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     企業級模型在昇騰平台的實戰調優經驗，平衡性能與成本 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     昇騰生態技術大牛+國企 AI 實戰派互動答疑 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;微信掃碼，預約直播&lt;/strong&gt; 
  &lt;br&gt; &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;2380&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-94f2e02947715c3bf11002682b404dcba16.png&quot; width=&quot;750&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【數智漫談】&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 視頻號直播暢聊欄目【數智漫談】，每期一個技術話題，三五位專家圍坐，各抒己見，暢聊開源。給大家帶來最新的行業前沿、最熱門的技術話題、最有趣的開源項目、最犀利的思想交鋒。如果你手上也有新點子、好項目，想要跟同行交流分享，歡迎聯繫我們，講壇隨時開放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18059430</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18059430</guid>
            <pubDate>Sun, 23 Mar 2025 10:13:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>開源遊戲機模擬器 Delta 發佈 1.7</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;iPhone/iPad 平台開源遊戲機模擬器 Delta 發佈了 1.7 新版本，&lt;strong&gt;首次支持任天堂 DS 遊戲的在線多人聯機功能。&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-08664014881434e872cc4861c44a63319b5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapps.apple.com%2Fus%2Fapp%2Fdelta-game-emulator%2Fid1048524688&quot; target=&quot;_blank&quot;&gt;https://apps.apple.com/us/app/delta-game-emulator/id1048524688&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用户可通過 AltStore PAL 或 App Store 下載更新，現可藉助第三方服務器（Wiimmfi、WiiLink WFC 等）與其他 Delta 玩家聯機暢玩 DS 遊戲。（該功能僅限模擬器用户間互動，&lt;strong&gt;無法與實體 NDS 主機玩家互聯）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本次更新重點提升了 N64 遊戲的圖形表現，默認採用 OpenGL ES 3.0 渲染核心，解決黑紋理等問題，並允許玩家按遊戲切換回舊版 2.0 模式。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a4df7cbb1d7432132e9e6e044453adb53a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新增的截圖功能支持手柄按鍵映射，控制器皮膚也可根據設備外殼（如 GAMEBABY 保護套）調整菜單位置。本次更新還修復了 AirPlay 投屏白屏、靜音模式無預覽音效等 20 餘項漏洞。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342490/delta-emulator-1-7-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342490/delta-emulator-1-7-released</guid>
            <pubDate>Sun, 23 Mar 2025 10:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>最強開源 AI 搜索框架 —— OpenDeepSearch 超越 GPT-4o</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenDeepSearch 在 frames-benchmark 上超過了 GPT-4o 的 Search 功能，成為最強的開源 AI 搜索框架。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-50874367e9f3e30993484b103b9728871b6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這個框架結合語義搜索，並提供了快速和深度搜索兩種模式，允許多跳搜索（即不斷檢索以得到理想答案），並且專門為 AI Agent 優化。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;OpenDeepSearch 在開源倉庫的 README 中寫道：「&lt;span&gt;&lt;strong&gt;用開源推理模型與智能代理技術實現搜索民主化&lt;/strong&gt;」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1192&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/175935_jr5S_2720166.png&quot; width=&quot;1682&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;OpenDeepSearch 包含兩個核心組件，分別用於提供高質量的網絡搜索結果，以及基於語義重排和多源整合優化檢索效果。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;OpenDeepSearch 旨在與 AI Agent 無縫集成。它支持深度 Web 搜索和檢索，並針對與 Hugging Face 的 SmolAgents 生態系統一起使用進行了優化。&lt;/p&gt; 
&lt;p&gt;比較有意思的是，OpenDeepSearch 的系統提示詞有一句是：如果你成功解決了問題，你將得到一百萬美元......&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342488</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342488</guid>
            <pubDate>Sun, 23 Mar 2025 10:02:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>高通收購越南創企 VinAI 生成式 AI 部門</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;高通（Qualcomm）宣佈已成功收購越南公司 VinAI 的生成式 AI 部門 MovianAI。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「此次收購彰顯了我們致力於投入必要資源進行研發的承諾，這將使我們成為下一波 AI 創新浪潮的驅動力。通過引進 VinAI 的高素質人才，我們將增強提供尖端 AI 解決方案的能力，造福各行各業和消費者。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;226&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c7b2d3273c0cd4d005abe24c78a5b79712b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，VinAI 以其在生成式人工智能、機器學習、計算機視覺和自然語言處理方面的專業知識而聞名。將 VinAI 先進的生成式人工智能研發能力與高通數十年的廣泛研發相結合，將擴大其推動非凡發明的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;VinAI 的生成式 AI 團隊由前谷歌 DeepMind 研究人員 Hung Bui 領導。VinAI 創始人兼首席執行官 Hung Bui 稱：「我們已準備好為高通的使命做出貢獻，即在基礎 AI 研究方面取得突破，並將其推廣到智能手機、個人電腦、軟件定義汽車等各個行業。我們團隊在生成式 AI 和機器學習方面的專業知識將有助於加速開發能夠改變我們生活和工作方式的創新解決方案。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;20 多年來，高通一直與越南技術生態系統密切合作，創造並提供創新解決方案。高通在 5G、人工智能、物聯網和汽車領域的創新助力越南信息和通信技術 (ICT) 行業的非凡增長和成功，並幫助越南企業進入全球市場。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342474/qualcomm-acquires-movianai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342474/qualcomm-acquires-movianai</guid>
            <pubDate>Sun, 23 Mar 2025 09:06:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Swift 6.1 發佈：優化任務組和成員可見性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Swift 6.1 已正式&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fblog%2Fswift-6.1-released%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;&lt;/u&gt;，此版本包括用於提高生產力的語言特性增強、診斷改進、軟件包 traits，以及正在進行的改進編譯時間工作。&lt;/p&gt; 
&lt;p&gt;下面介紹&amp;nbsp;&lt;span&gt;Swift 6.1 中的兩個亮點：&lt;strong&gt;任務組的改進和成員可見性的優化&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;Swift 6.1 中的任務組改進&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;在併發編程中，任務組是一個非常有用的工具。Swift 6.1 對任務組進行了優化，現在我們不再需要顯式定義子任務的返回類型。編譯器可以根據第一個任務自動推斷所有子任務的返回類型，這讓代碼更加簡潔。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;例如，之前我們需要這樣寫：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;await withTaskGroup(of:&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Int&lt;/span&gt;&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;self&lt;/span&gt;&lt;/span&gt;&lt;span&gt;) { group&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;for&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;...&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;10&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;{&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; group.addTask {&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;return&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Int&lt;/span&gt;&lt;/span&gt;&lt;span&gt;.random(&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;&lt;span&gt;:&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;...&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;10&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;
&lt;span&gt;&amp;nbsp; }&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;而在 Swift 6.1 中，我們可以這樣寫：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;await withTaskGroup { group&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;for&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;_&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;...&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;10&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;{&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; group.addTask {&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;return&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Int&lt;/span&gt;&lt;/span&gt;&lt;span&gt;.random(&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;in&lt;/span&gt;&lt;/span&gt;&lt;span&gt;:&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;...&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;10&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;
&lt;span&gt;&amp;nbsp; }&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;這不僅減少了代碼量，也讓代碼更具可讀性。當然，所有子任務的返回類型仍需一致，否則編譯器會報錯。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;Swift 6.1 中的導入成員可見性&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;Swift 6.1 引入了新的成員可見性模式，這讓模塊的使用更加直觀。比如我們在兩個模塊中同時定義了對某個類的擴展，那麼在使用時，編譯器會選擇哪個進行調用？&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;在 Swift 6.1 之前，編譯器會報錯，而在 Swift 6.1 中，編譯器會根據導入的模塊自動選擇正確的擴展，避免了不必要的混淆。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;例如，如果我們有兩個模塊&amp;nbsp;&lt;/span&gt;&lt;code&gt;&lt;span&gt;CurrencyKit&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&amp;nbsp;和&amp;nbsp;&lt;/span&gt;&lt;code&gt;&lt;span&gt;PurchaseParser&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，它們都對&amp;nbsp;&lt;/span&gt;&lt;code&gt;&lt;span&gt;Int&lt;/span&gt;&lt;/code&gt;&lt;span&gt;&amp;nbsp;類型進行了擴展：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span style=&quot;color:#007400&quot;&gt;&lt;span&gt;// CurrencyKit&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;func&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;price&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;String&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;{&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;let&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;formatter =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;NumberFormatter&lt;/span&gt;&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; formatter.numberStyle = .currency&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; formatter.locale =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Locale&lt;/span&gt;&lt;/span&gt;&lt;span&gt;.current&lt;/span&gt;

&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;let&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;amount =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Double&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;self&lt;/span&gt;&lt;/span&gt;&lt;span&gt;) /&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;100.0&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;return&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;formatter.string(from:&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;NSNumber&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(value: amount)) ??&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#c41a16&quot;&gt;&lt;span&gt;&quot;$\(amount)&quot;&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span style=&quot;color:#007400&quot;&gt;&lt;span&gt;// PurchaseParser&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;func&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;price&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;-&amp;gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;String&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;{&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;let&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;formatter =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;NumberFormatter&lt;/span&gt;&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; formatter.numberStyle = .currency&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; formatter.locale =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Locale&lt;/span&gt;&lt;/span&gt;&lt;span&gt;.current&lt;/span&gt;

&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;let&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;amount =&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;Double&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;self&lt;/span&gt;&lt;/span&gt;&lt;span&gt;) /&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#1c00cf&quot;&gt;&lt;span&gt;100.0&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#aa0d91&quot;&gt;&lt;span&gt;return&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;formatter.string(from:&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5c2699&quot;&gt;&lt;span&gt;NSNumber&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(value: amount)) ??&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#c41a16&quot;&gt;&lt;span&gt;&quot;$\(amount)&quot;&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:black; margin-left:4px; margin-right:4px&quot;&gt;&lt;span&gt;在 Swift 6.1 中，編譯器會根據導入的模塊自動選擇正確的擴展，避免了不必要的混淆。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSyDVGyevVNzhat-cmGU9NA&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/SyDVGyevVNzhat-cmGU9NA&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;詳細更新説明查看發佈公告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fblog%2Fswift-6.1-released%2F&quot; target=&quot;_blank&quot;&gt;https://www.swift.org/blog/swift-6.1-released/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342469/swift-6-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342469/swift-6-1-released</guid>
            <pubDate>Sun, 23 Mar 2025 08:45:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Swiftly 1.0 發佈：Swift 工具鏈版本管理器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Swift 團隊正式發佈了 Swift 工具鏈版本管理器 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.swift.org%2Fblog%2Fintroducing-swiftly_10%2F&quot; target=&quot;_blank&quot;&gt;Swiftly 1.0&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1560&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/163703_nITp_2720166.png&quot; width=&quot;1732&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;該工具可用於快速安裝、切換、更新 Swift 工具鏈，支持 macOS 和主流 Linux 發行版，並可通過&amp;nbsp;&lt;code&gt;.swift-version&lt;/code&gt;文件統一團隊使用的 Swift 版本。&lt;/p&gt; 
&lt;p&gt;Swiftly 完全由 Swift 編寫，具備良好的可移植性和開發體驗，是在 Xcode 之外安裝 Swift 的推薦方式。&lt;/p&gt; 
&lt;p&gt;官方公告寫道，Swiftly 將成為在 Xcode 之外安裝 Swift 的默認方式。初始版本支持 macOS 和各種 Linux 發行版，包括 Ubuntu、Debian、Fedora、Red Hat Enterprise Linux 和 Amazon Linux。&lt;/p&gt; 
&lt;p&gt;Swiftly 最初由&amp;nbsp;&lt;strong&gt;Patrick Freed&amp;nbsp;&lt;/strong&gt;開發，並已將其捐贈給 Swift 社區。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342467/swiftly-1-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342467/swiftly-1-0</guid>
            <pubDate>Sun, 23 Mar 2025 08:37:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>騰訊元寶更新，支持一次性上傳 10 張圖片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;騰訊元寶&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsB08geM6bE-TF4PZRubiZw&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;再次更新，其識圖功能進一步拓展，支持一次性上傳 10 張圖片，非常適用於那些需要理清結構、提煉重點、生成內容的情況。&lt;/p&gt; 
&lt;p&gt;「這項功能結合了混元的多模態理解能力，也是元寶雙模型能力的體現。現在，你只要把幾張圖一起發給元寶，不論選混元還是 DeepSeek，元寶都能連着看、串起來理解、集中回答。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;270&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5c21b5dbdc892744c6250aae74bb420df1b.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在實際應用場景中，可用於處理電子書截圖，提煉金句及寫感想；也可用於生成朋友圈文案；整理板書或講義結構；整理草圖轉成 demo 網頁。&lt;/p&gt; 
&lt;p&gt;目前多圖上傳功能，已經上線：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;手機版（2.11.0 以上版本）：上傳時可以多選，最多十張；&lt;/li&gt; 
 &lt;li&gt;電腦版（1.8.0 以上版本）：支持拖拽上傳、或者快捷鍵截圖；&lt;/li&gt; 
 &lt;li&gt;網頁版：也已全面支持。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342465</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342465</guid>
            <pubDate>Sun, 23 Mar 2025 08:35:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Spring AI Alibaba —— 快速開發生成式 Java AI 應用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;a href=&quot;https://java2ai.com/&quot;&gt;Spring AI Alibaba&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是一款 Java 語言實現的 AI 應用開發框架，旨在簡化 Java AI 應用程序開發，讓 Java 開發者像使用 Spring 開發普通應用一樣開發 AI 應用。Spring AI Alibaba 基於 Spring AI 開源項目構建，默認提供阿里雲基礎模型服務、開源及商業生態組件的集成與最佳實踐。&lt;/span&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;特性&lt;/h2&gt;
&lt;/div&gt;

&lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;以下是 Spring AI Alibaba 支持的核心能力，未來更多高級功能將以這些核心能力為基礎。請參考官網文檔&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://java2ai.com/docs/dev/concepts/&quot;&gt;Spring AI Alibaba 核心概念&lt;/a&gt;以及&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://java2ai.com/docs/dev/practices/playground-flight-booking/&quot;&gt;AI 應用開發最佳實踐&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;開發複雜 AI 應用的高階抽象 Fluent API -- ChatClient&lt;/li&gt;
&lt;li&gt;提供多種大模型服務對接能力，包括主流開源與阿里雲通義大模型服務（百鍊）等&lt;/li&gt;
&lt;li&gt;支持的模型類型包括聊天、文生圖、音頻轉錄、文生語音等&lt;/li&gt;
&lt;li&gt;支持同步和流式 API，在保持應用層 API 不變的情況下支持靈活切換底層模型服務，支持特定模型的定製化能力（參數傳遞）&lt;/li&gt;
&lt;li&gt;支持 Structured Output，即將 AI 模型輸出映射到 POJOs&lt;/li&gt;
&lt;li&gt;支持矢量數據庫存儲與檢索&lt;/li&gt;
&lt;li&gt;支持函數調用 Function Calling&lt;/li&gt;
&lt;li&gt;支持構建 AI Agent 所需要的工具調用和對話內存記憶能力&lt;/li&gt;
&lt;li&gt;支持 RAG 開發模式，包括離線文檔處理如 DocumentReader、Splitter、Embedding、VectorStore 等，支持 Retrieve 檢索&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h2&gt;Roadmap&lt;/h2&gt;
&lt;/div&gt;

&lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;Spring AI Alibaba 提供 AI 開源框架以及與阿里巴巴整體開源生態的深度適配，以幫助 Java 開發者快速構建原生 AI 應用架構。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Prompt Template 管理&lt;/li&gt;
&lt;li&gt;事件驅動的 AI 應用程序&lt;/li&gt;
&lt;li&gt;更多 Vector Database 支持&lt;/li&gt;
&lt;li&gt;函數計算等部署模式&lt;/li&gt;
&lt;li&gt;可觀測性建設&lt;/li&gt;
&lt;li&gt;AI 代理節點開發能力，如綠網、限流、多模型切換等&lt;/li&gt;
&lt;li&gt;開發者工具集&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height=&quot;274&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0402/161309_CXrE_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/spring-ai-alibaba</link>
            <guid isPermaLink="false">https://www.oschina.net/p/spring-ai-alibaba</guid>
            <pubDate>Sun, 23 Mar 2025 08:14:00 GMT</pubDate>
        </item>
        <item>
            <title>北大人工智能研究院朱松純：「中國的 AI 敍事」 存在認知偏差</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 29 日，在 2025 中關村論壇通用人工智能論壇上，北京通用人工智能學院院長，北京大學人工智能研究院、智能學院院長朱松純表示，&lt;strong&gt;目前，行業對 AI 的討論幾乎被大模型能力所佔據，而基礎學科、原始創新與智能本質的研究卻被邊緣化，甚至遭到部分輿論的否定&lt;/strong&gt;。更有甚者，形成了某種「技術投機」的氛圍，彷彿只有少數企業能代表中國 AI 的水平，而長期支撐 AI 發展的基礎學術羣體、理論工作者、認知科學研究者則被忽視。這種認知偏差，正在讓我們離真正的 AI 創新越來越遠。&lt;/p&gt; 
&lt;p&gt;朱松純總結了 AI 的創新具有 5 個層次：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最下面底層的是，哲學層面&lt;/strong&gt;：探討「智能」的本質。事實上，智能的本質是「主觀的」，每個人的決策都基於自己對世界的認知與價值體系。這些認知未必客觀，卻決定了行為。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第二層，理論層面&lt;/strong&gt;：建立認知的數學框架，如邏輯學、統計建模、概率計算。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第三層，模型層面&lt;/strong&gt;：根據框架構建具體模型，如判別模型、生成模型、大模型等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第四層，算法層面&lt;/strong&gt;：在具體模型下，開發優化算法，提高計算、推理、訓練的效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第五層，工程與部署&lt;/strong&gt;：把模型落地到硬件、平台，優化存儲、計算，形成可用的產品和系統。&lt;/p&gt; 
&lt;p&gt;他還説道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;目前很多所謂的創新，僅僅停留在第&lt;strong&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/strong&gt;層（算法）或第&lt;strong&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/strong&gt;層（部署）層面，連理論框架都不具備，卻在吹噓&lt;/strong&gt;「&lt;strong&gt;&lt;strong&gt;顛覆&lt;/strong&gt;&lt;/strong&gt;」。而我們現在真正缺的是對智能本質、認知建模的原創性突破。&lt;/p&gt; 
 &lt;p&gt;當前社會存在嚴重誤區，彷彿只有&amp;nbsp;DeepSeek&amp;nbsp;等這樣的企業做出了成果，甚至有人極端認為，學術界、研究機構的工作都是「吃白飯」，這種情緒化、非理性的輿論正在誤導大眾。&lt;/p&gt; 
 &lt;p&gt;我們必須澄清，&lt;strong&gt;DeepSeek&amp;nbsp;在工程落地、&lt;strong&gt;&lt;strong&gt;API&amp;nbsp;&lt;strong&gt;&lt;strong&gt;產品化、算力優化等方面確實取得了成績，但主要集中在工程部署層面，並未解決人工智能的核心難題&lt;/strong&gt;&lt;/strong&gt;——比如&lt;/strong&gt;&lt;/strong&gt;認知建模、智能理論、學習機制等。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;支撐今天所有&amp;nbsp;AI&amp;nbsp;應用的底座，正是學術界數十年在哲學、理論、建模、算法等基礎層面的持續投入。若因短期的產品化成效，就否定基礎研究，甚至鼓吹「學術無用論」，不僅荒謬，也極其危險。&lt;/p&gt; 
 &lt;p&gt;以美國的創新為例，很多集中在最底層的硬件（芯片、架構）、大模型，以及算法優化。&lt;strong&gt;我們如果想在中美競爭中取得突破，關鍵要在於第四層和更高的哲學與理論創新。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;如果只是重複美國的老路——算力、算法、部署，我們永遠都是追隨者。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原文：&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9aJuk7XDAX_JR3JJnqFD0A&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/9aJuk7XDAX_JR3JJnqFD0A&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342452</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342452</guid>
            <pubDate>Sun, 23 Mar 2025 07:42:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Qwen2.5-Omni 登頂全球開源模型榜單</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;Hugging Face 發佈了&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;最新&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;的大模型榜單，阿里巴巴通義千問所推出的端到端全模態大模型 Qwen2.5-Omni 成功登頂。&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;緊隨其後的是 DeepSeek-V3-0324 和羣核的 SpatialLM-Llama-1B。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;228&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b28f282e32496fbfa8312edb8f222889263.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Qwen2.5-Omni 是一種端到端多模態模型，旨在感知文本、圖像、音頻和視頻等多種模態，同時以流式方式生成文本和自然語音響應。開發團隊表示，他們對 Qwen2.5-Omni 進行了全面評估，與類似大小的單模態模型和 Qwen2.5-VL-7B、Qwen2-Audio 和 Gemini-1.5-pro 等閉源模型相比，該模型在所有模態中均表現出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在需要集成多種模態的任務（例如 OmniBench）中，Qwen2.5-Omni 實現了最佳性能。此外，在單模態任務中，它在語音識別（Common Voice）、翻譯（CoVoST2）、音頻理解（MMAU）、圖像推理（MMMU、MMStar）、視頻理解（MVBench）和語音生成（Seed-tts-eval 和主觀自然度）等領域表現出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;據悉，阿里通義千問自成立以來，已經向全球開源了超過 200 款模型。這些模型覆蓋了自然語言處理、計算機視覺等多個領域，為科研和企業應用提供了強有力的支持。而 Qwen 系列的衍生模型數量已經突破 10 萬，超越了美國的 Llama 系列，成為全球最大的開源模型族羣&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342451</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342451</guid>
            <pubDate>Sun, 23 Mar 2025 07:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>蘋果六面屏全玻璃設計 iPhone 專利曝光</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;科技媒體 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F04%2Fapple-won-a-patent-for-all-glass-device-embodiments-for-apple-watch-mac-an-iphone-that-allows-imagery-on-both-front-and-ba.html&quot; target=&quot;_blank&quot;&gt;Patently Apple&lt;/a&gt; 發文稱，蘋果公司最近新獲得了一項適用於 Apple Watch、Mac 和 iPhone 的全玻璃設備專利，正面和背面均可作為顯示屏。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蘋果在玻璃設備領域的佈局可以追溯到 2014 年，此次獲得的專利具有里程碑意義，首次系統地定義了多面玻璃外殼的技術方案。其他專利可以查看：&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2023%2F03%2Fapple-wins-a-patent-for-fused-glass-device-housings-for-ipad-an-apple-tv-imac-and-more.html&quot; target=&quot;_blank&quot;&gt;01&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2Fpatently-apple%2F2020%2F09%2Fapple-won-two-macbook-patents-emphasizing-the-expanded-use-of-a-glass-body-keyboard-areas.html&quot; target=&quot;_blank&quot;&gt;02&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F03%2Fapple-files-for-additional-protections-to-their-inventive-all-glass-imac-patent.html&quot; target=&quot;_blank&quot;&gt;03&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;、&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.patentlyapple.com%2F2025%2F03%2Fapple-has-invented-a-new-apple-watch-design-with-a-glass-shell-that-provides-side-touch-controls-with-various-control-interf.html&quot; target=&quot;_blank&quot;&gt;04&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;(用於 Apple Watch)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;最新專利附圖如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;圖 26A-26C 展示了一種六面透明稜鏡外殼，每一面都可以獨立顯示內容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;355&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eeee8a0fbe11838830bc1709d0ca95e2057.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;圖&amp;nbsp;53C-B 展示了當手機翻轉時，用户界面根據確定的方向（相對於用户或絕對方向）重新定位後的 iPhone。51A-51B 描繪了 iPhone 的另一個示例，其中正面顯示屏上的圖像擴展到了玻璃 iPhone 的背面。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;389&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d4a79e481179558d03b335c501ed6f62198.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;圖 4E 是 Mac Pro Tower 概念的透視圖，其外殼呈八稜柱形狀。外殼可以由玻璃製成，並且可以沿所有或基本上所有表面透明。圖 57 則展示了未來可能出現的 Apple Watch，其中包括完全或基本完全由玻璃形成的外殼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;378&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bd9c6d6d406781d60a5e5649ff261ae0a18.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;蘋果方面指出，在某些情況下，iPhone 的側面將能夠根據基於力量的輸入而變形和/或偏轉。例如，用户可以通過擠壓外殼和/或按壓側面來降低或提高音樂或內容的音量。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342450/apple-patent-for-all-glass-device</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342450/apple-patent-for-all-glass-device</guid>
            <pubDate>Sun, 23 Mar 2025 07:33:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>軟件工程的 13 條法則</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;strong&gt;1、帕金森定律&lt;/strong&gt;：工作會膨脹以填滿可用的時間。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6e9c01e7725c6b53b7800033fffdaf1f3f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、霍夫斯塔特定律&lt;/strong&gt;：事情總是比你預期的要長，即使你已經考慮了霍夫斯塔特定律。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-da20eb6f35d695eb16fe4ab9caf02c0853f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、布魯克斯定律&lt;/strong&gt;：向一個已經延期的軟件項目增加人力只會讓它更加延期。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a79493a976c16e52b6258ff68e4a4e02d15.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、康威定律（及逆康威定律）&lt;/strong&gt;：組織做的設計往往是其內部溝通結構的複製品。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5adf2d562a47cf3c6774f10f54aa750762f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5、坎寧安定律&lt;/strong&gt;：在互聯網上獲得正確答案的最佳方式不是提問，而是發佈一個錯誤答案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-efe2126647446248be7d4dabb9ac5d836d4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、斯特金定律&lt;/strong&gt;：90% 的東西都是垃圾。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e6656de38fcc5ded0050bdf5338d5cc75db.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7、扎温斯基定律&lt;/strong&gt;：每個程序都試圖擴展，直到能夠讀取郵件。那些無法如此擴展的程序會被能夠做到的程序所取代。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f46d91cd7b15ab18aa92eaa1a48735af5a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;8、海勒姆定律&lt;/strong&gt;：當 API 的用户數量足夠多時，你在合約中承諾什麼並不重要：系統的所有可觀察行為都會被某些人所依賴。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a490e790d81821fcbd5d0d918259ed53a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;9、普賴斯定律&lt;/strong&gt;：在任何羣體中，50% 的工作是由其總人數的平方根數的人完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1bf79eb2323574b5fde92c83b8359da2890.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;10、林格爾曼效應&lt;/strong&gt;：羣體中個體成員的生產力隨着羣體規模的增大而逐漸降低的趨勢。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8a7f61f02eacee4f997dc6f1bc203adbda8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;11、古德哈特定律&lt;/strong&gt;：當一項指標成為目標時，它就不再是一個好的指標。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-072a453ebe8a6968cb3d158389ec9b00ceb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;12、吉爾布定律&lt;/strong&gt;：任何你需要量化的東西，都可以通過某種方式進行測量，這總比完全不測量要好。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5bce1dfd39463accf41c3d4b96efc2c72e5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;13、墨菲定律&lt;/strong&gt;：可能出錯的事就一定會出錯。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-717d819db99a5b3d2d98fd38a349c465f44.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;來源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.manager.dev%2Fp%2Fthe-13-software-engineering-laws&quot; target=&quot;_blank&quot;&gt;https://newsletter.manager.dev/p/the-13-software-engineering-laws&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342448/the-13-software-engineering-laws</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342448/the-13-software-engineering-laws</guid>
            <pubDate>Sun, 23 Mar 2025 07:22:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「DeepSeek-V3 技術解析」：無輔助損失函數的負載均衡</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;編者按：&lt;/strong&gt; 在混合專家模型（MoE）的實踐中，負載不均衡儼然已成為制約模型性能提升的關鍵瓶頸之一。傳統的均衡策略往往需要引入複雜的輔助損失函數，不僅增加了訓練的複雜度，還可能幹擾模型的核心學習目標。工程師們在提升模型效率的道路上，一直苦苦追尋着一個優雅而高效的平衡解決方案。&lt;/p&gt; 
 &lt;p&gt;DeepSeek 團隊的這項研究，為這一長期困擾業界的技術難題提供了令人耳目一新的解決思路：通過在門控分數中直接添加專家層面的偏置項，在絕大部分不引入額外損失函數的情況下，實現了模型訓練過程中的自適應負載均衡。更令人驚歎的是，這一方法不僅保持了模型的因果關係，還顯著提升了訓練的穩定性和最終性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Shirley Li&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;編譯 | 嶽揚&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這是 DeepSeek-V3 系列文章的第三篇，我們將探討 DeepSeek 模型[1, 2, 3]中與混合專家模型（MoE）相關的另一項關鍵架構突破：無輔助損失函數的負載均衡（Auxiliary-Loss-Free Load Balancing）[5]。&lt;/p&gt; 
&lt;p&gt;在本文，我們將深入解析 DeepSeek 如何解決 MoE 的隱藏瓶頸------負載均衡，同時還通過消除梯度幹擾和嚴格遵循因果關係約束，提升了訓練和推理效率，為後續專家模型的優化方向提供了標杆。&lt;/p&gt; 
&lt;p&gt;本文目錄：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技術背景：介紹混合專家模型（MoE）的基本原理，解釋負載均衡的重要性，回顧之前的工作，包括輔助損失函數（auxiliary loss）方法和專家選擇（Expert Choice）策略。&lt;/li&gt; 
 &lt;li&gt;DeepSeek 的無輔助損失函數的負載均衡：解析其運作原理&lt;/li&gt; 
 &lt;li&gt;性能評估：討論無輔助損失函數的負載均衡的性能表現&lt;/li&gt; 
 &lt;li&gt;總結&lt;/li&gt; 
 &lt;li&gt;參考文獻&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「DeepSeek-V3 技術解析」系列其他文章：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17943880&quot;&gt;「DeepSeek-V3 技術解析」：多頭潛在注意力機制（MLA）&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;「DeepSeek-V3 技術解析」：DeepSeekMoE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;01 技術背景&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1.1&lt;/strong&gt; &lt;strong&gt;MoE (Mixture-of-Experts) in Transformers&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MoE（Mixture-of-Experts，混合專家模型）在 Transformer 中的實現方式通常為：每隔若干 Transformer 層，將其中的 FFN（前饋網絡）替換為多個 FFN（每個 FFN 充當一個&quot;專家&quot;）。當 input token 進入該層時，通過門控操作（Gating）選擇 Top-K 個專家，並將 input token 只路由至這些被選中的 FFN，從而僅激活對應的專家網絡。&lt;/p&gt; 
&lt;p&gt;下圖展示了這一過程：左側標準 Transformer 層中的 FFN 子層被替換為右側的 MoE 層。&lt;/p&gt; 
&lt;p&gt;如需更詳細的 MoE 技術解析，可參考&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;「DeepSeek-V3 技術解析」：DeepSeekMoE&lt;/a&gt;（文中通過餐廳類比直觀解釋了 MoE 原理）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19ae4d0c8392f0c6fb1b110f9ebae146cb4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 1. Transformer 中的 MoE 層（紅框內）示意圖。圖片改編自文獻 [6]。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 負載均衡及其重要性&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;本系列上一篇文章&lt;/a&gt;進行的餐廳類比中，我們通過一個能夠提供多種菜系菜品的餐廳解釋了 MoE 的概念：餐廳的每位廚師都是專家，主廚（Head Chef）的工作類似於門控操作，將每道菜品分配給具備對應技能的特定廚師。&lt;/p&gt; 
&lt;p&gt;為確保該系統高效運作，需滿足以下條件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;每位專業廚師必須精通自身菜系所需技能（例如餃子廚師必須會包餃子），同時所有廚師需能共同處理所有菜品。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;主廚需充分了解所有專業廚師的專長，並能高效分配訂單。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 MoE 中，前者對應 expert specialization 與 knowledge sharing 的權衡（我們已在&lt;a href=&quot;https://my.oschina.net/IDP/blog/17961367&quot;&gt;介紹 DeepSeekMoE 的這篇文章中&lt;/a&gt;進行了詳細討論），後者則體現了負載均衡的重要性 ------ 這也是本文的核心主題。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;為何負載均衡如此重要？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原因在於，當負載不均衡發生時，MoE 無法有效運作。&lt;/strong&gt; 最常見的問題是路由崩潰（Route Collapse）：少數專家接收大部分 input token，而其他專家的利用率極低。&lt;/p&gt; 
&lt;p&gt;因此，大部分計算由超負荷工作的專家承擔，而這些專家通常分佈在多個 GPU 核心上，因此會導致硬件資源浪費。&lt;/p&gt; 
&lt;p&gt;由於梯度衝突（gradient conflict），路由奔潰也會導致訓練不穩定。超負荷工作的專家接收更多 input token，他們積累的梯度也會更大，學習速度也會比工作負荷不足的專家快得多；因此，兩者的梯度在幅值和方向上均可能發生偏離，導致訓練難以收斂。&lt;/p&gt; 
&lt;p&gt;最後，MoE 中的負載不均衡也會導致性能低下和泛化效果不佳，因為工作負荷不足的專家會因為訓練 tokens 不足，而難以學習有效知識。&lt;/p&gt; 
&lt;p&gt;由於負載均衡技術對 MoE 至關重要，因此研究者們針對這一問題提出了多種解決方案。其中，最常用的策略是為負載均衡添加輔助損失函數（Auxiliary Loss）和專家選擇（Expert Choice）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 帶輔助損失函數的負載均衡&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一種常見的改善負載均衡的策略是在模型訓練的目標函數基礎上引入輔助損失函數。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5e9dccf967a447833e952d9a7a9ddee3d5f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 2. 用於強化負載均衡的輔助損失函數示例。圖片編輯自文獻[5]。&lt;/p&gt; 
&lt;p&gt;上圖展示了一個輔助損失函數的示例，其中&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;N 是專家數量，T 是 token 數量，K 是每個 input token 激活的專家數量。&lt;/li&gt; 
 &lt;li&gt;s_{i, t} 是門控機制的輸出，通過 Softmax 歸一化到 [0, 1] 區間，表示第 t 個 token 選擇第 i 個專家的概率。向量 u_t 是第 t 個 token 的輸入隱藏狀態，而 e_i 是第 i 個專家的&quot;質心&quot;，可以看作歷史上路由到第 i 個專家的 token 嵌入平均值。因此，s_{i, t} 度量的是當前輸入與第 i 位專家歷史接收 token 的平均值的接近程度。&lt;/li&gt; 
 &lt;li&gt;因此，P_i 可視為整個輸入序列選擇第 i 個專家的平均概率。&lt;/li&gt; 
 &lt;li&gt;f_i 表示被路由到第 i 個專家的 token 比例。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;需要注意的是，f_i 是不可微分的，因此最小化上述損失函數實際上轉化為了最小化 s_{i, t}。同時由於 f_i 依賴於 s_{i, t}，對 s_{i, t} 的調整也會影響 f_i，從而實現對各專家負載分配的調節。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然而，用這種輔助損失函數來均衡負載需要付出一定代價，因為其梯度可能會干擾語言建模目標（language modeling objective）的梯度，導致模型性能下降，在極端不平衡情況下（工作負荷過大的專家的 f_i 和 P_i 都變得極大時）尤其明顯。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因此，採用這種方法進行負載均衡需要謹慎設置輔助損失函數的權重。為更清晰地説明這一點，文獻[5]的作者進行了一個實驗，用不同 alpha 值訓練模型，結果如下圖所示，其中縱軸表示困惑度指標下的模型性能，橫軸表示 MaxVio（衡量負載不平衡程度的指標，MaxVio 值越高表示負載越不平衡，i 表示第 i 個專家）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-270603a291bd57664c068ed046f529e917f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 3. 輔助損失函數控制訓練中負載均衡與模型性能的權衡困境。圖片引自文獻[5]。&lt;/p&gt; 
&lt;p&gt;如圖所示，當 alpha 過小時（alpha=0），MaxVio 保持高位，説明輔助損失函數未能有效實現負載均衡目標。另一方面，當 alpha 過大時（alpha=0.01），模型最終會產生更高的困惑度。&lt;/p&gt; 
&lt;p&gt;綜上，輔助損失函數控制的負載均衡是把雙刃劍：若 alpha 未經仔細調校，可能損害模型性能。實際 LLM 訓練中，由於資源限制，alpha 的調校過程充滿挑戰，這進一步增加了優化難度。&lt;/p&gt; 
&lt;p&gt;上圖同時展示了本文提出的無損失函數方法在相同 Perplexity-MaxVio 座標系下的表現，該方法同時實現了低困惑度和低 MaxVio，證明瞭無損失函數方法的有效性。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 專家選擇（Expert Choice）策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在此需提及的另一項前期工作是 Expert Choice [7]，它提出了一種簡單高效的負載均衡方法，將路由策略從&quot;token choice&quot;切換為&quot;expert choice&quot;。&lt;/p&gt; 
&lt;p&gt;具體而言，MoE 路由中的門控分數通常通過對 affinity matrix（譯者注：二維矩陣，用於量化 input token 與各個專家之間的匹配程度。）應用 Softmax 計算得出，如圖 2 所示。傳統路由方法從 token 維度應用 Softmax 為每個 token 選擇專家，因此這些方法被稱為&quot;token choice&quot;。問題在於，該機制下我們無法控制每個專家接收的 token 數量，最終導致負載不均衡問題。&lt;/p&gt; 
&lt;p&gt;而 Expert Choice 方法則從專家維度應用 Softmax，為每個專家選擇被路由的 token。通過這種設計，每個專家接收的 token 數量能夠天然達到完美均衡，因此無需依賴輔助損失函數實現負載均衡。在文獻[7]中，這種方法同時展現出更優的模型性能和更快的訓練速度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;然而，Expert Choice 這種方法也存在侷限 ------ 未來 token 泄露問題。由於每個專家需要先查看所有 token 的路由分數才能決定處理哪些 token，這違反了因果關係（causality），在文本生成、機器翻譯等自迴歸任務中可能引發嚴重問題。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek 的無輔助損失函數的負載均衡&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;為在不引入 gradient inference（譯者注：此處或為作者筆誤？應當為&quot;gradient interference（梯度幹擾）&quot;，多個損失函數（或多個優化目標）的梯度方向發生衝突。） 的情況下解決負載均衡問題，DeepSeek 提出了一種名為&quot; Loss-Free Balancing&quot;的新技術，通過直接調整門控分數 s_{i,t} 實現。&lt;/p&gt; 
&lt;p&gt;如前文所述，當我們最小化圖 2 所示的輔助損失函數時，最終會通過調整 s_{i,t} 來實現最小化 P_i。&lt;/p&gt; 
&lt;p&gt;因此，若能直接調整 s_{i,t}，理論上應能達到與施加輔助損失函數相似的效果。&lt;/p&gt; 
&lt;p&gt;為此，我們在每個專家的門控分數上添加了專家層面的偏置項，如下圖所示。需注意 b_i 並不用於最終門控分數的計算（後文也將説明該偏置項也是不可微分的），而是用於 TopK 選擇專家時：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d4c0f9d7daaae22acf77ebd4afdd50c0c9e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 4. 在門控分數中引入偏置項 b_i。圖片引自文獻[5]&lt;/p&gt; 
&lt;p&gt;該偏置項 b_i 的計算方式非常直觀，如下圖所示：首先獲取分配給各專家的 token 數量平均值及所有專家的理論全局均值，然後計算給各專家分配的 token 數量與理論全局均值的差值，偏置項由該差值（或誤差）的符號乘以固定更新率（fixed update rate）決定（該更新率為可調超參數）。後續章節我們將對該超參數的影響進行更多實驗分析。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-648298535bc37e35360bb990b243896d409.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 5. DeepSeek 無損失函數的負載均衡算法。圖片引自文獻[5]&lt;/p&gt; 
&lt;p&gt;現可通過下表總結不同負載均衡方法的優勢與侷限：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-625befddfe0736a68e0a4968075dc2d51bf.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 6. 不同負載均衡方法對比。圖片引自文獻[5]&lt;/p&gt; 
&lt;p&gt;圖 3 已展示該方法在模型性能與負載均衡間取得了更好的權衡，但仍有多方面需要驗證。下一章節我們將深入分析實驗結果。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Evaluation&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;有三個關鍵問題需要回答：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek 所提出的方法能否在性能和負載均衡之間實現更好的權衡？&lt;/li&gt; 
 &lt;li&gt;圖 5 中更新率 u 有什麼影響？&lt;/li&gt; 
 &lt;li&gt;我們能否進一步優化偏置項更新規則（鑑於其如此之簡單）？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 性能 vs. 負載均衡&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;為回答第一個問題，作者在 1B 和 3B 模型上進行了實驗，比較 loss-controlled 負載均衡和 loss-free 負載均衡的困惑度（Perplexity）和 MaxVio，結果如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2829c426107ea67be1110636b5d167242f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 7. loss-controlled 負載均衡和 loss-free 負載均衡的對比。圖片來自文獻[5]。&lt;/p&gt; 
&lt;p&gt;上述結果與我們在圖 3 中看到的結果類似：所提方法同時實現了更低的困惑度和更低的 MaxVio。&lt;/p&gt; 
&lt;p&gt;除了評估最終的 checkpoint 外，作者還展示了訓練過程中的 MaxVio 曲線，以便更全面地理解該方法在整個訓練過程中的表現，如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-20f534fb208e8a1f89dae2e5032a07ffead.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 8. 訓練過程中的 MaxVio 曲線。圖片來自文獻[5]。&lt;/p&gt; 
&lt;p&gt;如圖中所示，在 1B 和 3B 的模型配置下，loss-free 方法在整個訓練過程中都展現出更優的負載均衡能力，體現了該方法的穩定性。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 超參數的影響（更新率）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如圖 5 所示，所提方法引入了一個新的超參數 u（稱為更新率（update rate）），該超參數如何影響 loss-free 方法的有效性？具體而言，我們需要理解 loss-free 方法對超參數 u 的取值是敏感還是不敏感，以及如何選擇一個最優值來最大化該方法的效果。&lt;/p&gt; 
&lt;p&gt;如前文所述，在門控分數中添加偏置項的概念類似於繞過損失函數的反向傳播，直接對門控分數進行梯度更新。在這種情況下，更新率 u 的作用與梯度更新中的步長（step size）類似。由此可推測其影響也相似：&lt;strong&gt;過小的更新率可能會導致收斂速度緩慢。過大的更新率可能導致不穩定和引發波動。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在原文中，作者對更新率進行了實驗測試（取值從 1e-4 到 1e-2），結果如下圖所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-239d0c5e83e1699cf19a5179be50163fe48.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 9. 更新率（update rate）對訓練負載均衡的影響。圖片來自文獻[5]。&lt;/p&gt; 
&lt;p&gt;與預期一致，當 u 過小時（如 1e-4），MaxVio 下降速度較慢；而過大的 u（如 1e-2）則因波動性增強，導致訓練過程中 MaxVio 持續偏高。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 其他偏置項更新規則&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;為回答第三個問題，研究者嘗試了多種備選策略，並將它們與 DeepSeek 提出的版本進行對比：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;策略變體 1&lt;/strong&gt;：使用 e_i 的數值（而不僅僅是符號）計算偏置項，即從 b_i = b_i +u∗sign(e_i) 改為 b_i = b_i +u∗e_i。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;策略變體 2&lt;/strong&gt;：使用乘法偏置項而非加法偏置項。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;其中策略變體 2 可以更正式地描述如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-856884cefb7dacdd99e05414c42d5b08cbb.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;實驗表明，策略變體 1 能帶來略優的負載均衡效果，但未提升模型性能：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-842152dbdd0880f205ec969a7535dc64e13.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 10. 策略變體 1 的性能表現。圖片來自文獻[5]。&lt;/p&gt; 
&lt;p&gt;而策略變體 2 甚至顯示出略差的模型性能：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71a03da108b196cc374602ba52875add0a5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;圖 11. 策略變體 2 的性能表現。圖片來自文獻[5]。&lt;/p&gt; 
&lt;p&gt;以上所有結果均表明，最簡單的策略反而是最佳選擇。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Summary&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在本文中，我們解釋了 DeepSeek 模型的核心架構創新之一 ------ DeepSeekMoE 中使用的無輔助損失函數的負載均衡方法。&lt;/p&gt; 
&lt;p&gt;本文首先介紹了混合專家模型（MoE）的基本原理，強調了負載均衡的重要性，並回顧了先前的解決方案（包括 auxiliary loss 方法和 Expert Choice 機制）。接着，本文闡釋了 DeepSeek 的無損失函數的負載均衡方法及其性能表現。&lt;/p&gt; 
&lt;p&gt;DeepSeek 的無損失函數方法在保持因果關係的同時避免了引入梯度幹擾，其有效性已通過原論文的實證結果得到驗證。&lt;/p&gt; 
&lt;p&gt;感謝您花時間閲讀本文！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;參考文獻&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] DeepSeek（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] DeepSeek-V3 Technical Report（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2FDeepSeek-V3%2Fblob%2Fmain%2FDeepSeek_V3.pdf%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2401.06066）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2408.15664%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2408.15664）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16668%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2006.16668）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Mixture-of-Experts with Expert Choice Routing（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2202.09368%EF%BC%89&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2202.09368）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Shirley Li&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I am a Machine Learning Engineer working on building multi-modality models to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互動內容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;在實際工程中，您認為負載均衡對模型性能的影響有多大？除了本文提到的技術路徑，您還瞭解哪些有效的負載均衡方案？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.gopubby.com%2Fdeepseek-v3-explained-3-auxiliary-loss-free-load-balancing-4beeb734ab1f&quot; target=&quot;_blank&quot;&gt;https://ai.gopubby.com/deepseek-v3-explained-3-auxiliary-loss-free-load-balancing-4beeb734ab1f&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/18057719</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18057719</guid>
            <pubDate>Sun, 23 Mar 2025 07:02:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>Sam Altman：OpenAI 新產品將因產能問題延遲推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 首席執行官 Sam Altman 在 X 發帖透露示，該公司新產品將因產能不足的問題延遲推出。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我們正在控制局面，但你應該預料到 OpenAI 的新版本可能會被推遲，可能會出現問題，而且由於我們面臨容量挑戰，服務有時會很慢。我們正在提升效率，以確保各項工作順利進行。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;171&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5b77f2974426a3588db4062d73b328abd76.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，OpenAI 的新圖像生成功能因能重現吉卜力工作室手繪動畫等風格的表現而備受關注， 同時也引發了一些爭議。上週末，Altman 在 X 的帖子中表示 ，自推出以來，該公司「一直未能跟上進度」，員工們加班加點，甚至週末加班，以「保持服務正常運行」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Altman 聲稱，週一僅一個小時，ChatGPT 就增加了 100 萬名新用户。ChatGPT 目前擁有 5 億周活躍用户和 2000 萬付費用户，其 2024 年底的用户數量和付費用户數量分別為 3 億和 1550 萬。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此為了緩解容量問題，OpenAI 推遲了面向 ChatGPT 免費用户的圖像生成工具的發佈時間，並暫時禁用了面向 Sora 新用户的視頻生成功能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342431/sam-altman-openais-capacity-issues-product-delays</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342431/sam-altman-openais-capacity-issues-product-delays</guid>
            <pubDate>Sun, 23 Mar 2025 06:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>微信公佈視頻號算法推薦原理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;「微信珊瑚安全」發文公佈了視頻號算法推薦原理，&lt;strong&gt;稱視頻號主要依靠社交好友關係來進行推薦&lt;/strong&gt;，若推薦的視頻不符合預期，可關閉個性化推薦功能。&lt;/p&gt; 
&lt;p&gt;官方稱，視頻號平台將持續優化算法信息公示方式，用通俗化的語言來解釋算法的基本原理、運行機制等情況，方便用户查詢和理解。&lt;/p&gt; 
&lt;p&gt;據官方公佈的信息，微信視頻號主要依靠社交好友關係來進行推薦，在功能層面，視頻號平台設計了「朋友❤️」的選項標籤，並以顯著提示的方式展現給用户，讓用户第一時間瞭解到好友推薦了什麼內容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;對於較多朋友推薦的內容，視頻號平台會提升曝光排序&lt;/strong&gt;，並增加了「朋友今天都在看」和多位好友推薦的提醒，用户可以更快、更直接地看到相關視頻，從而擴展自己的信息獲取半徑。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0402/141552_HHSN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;官方稱，通過這一推薦機制，用户能直觀看到多位朋友推薦的內容，無需將時間過多消耗在刷視頻中。&lt;/p&gt; 
&lt;p&gt;一圖讀懂視頻號算法推薦：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;3965&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d7ada75a7f7e7e5cf72facf18d42527d08.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;原文：&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWADcBzT4n9dSPXbxsOcKuQ&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/WADcBzT4n9dSPXbxsOcKuQ&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342428</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342428</guid>
            <pubDate>Sun, 23 Mar 2025 06:16:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>CNCF 發佈 2025 年 Dapr 狀態報告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025 年 Dapr 狀態報告現已&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Fannouncements%2F2025%2F04%2F01%2Fcloud-native-computing-foundation-releases-2025-state-of-dapr-report-highlighting-adoption-trends-and-ai-innovations%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;，提供了有關項目加速採用、開發者生產力影響和在 AI 驅動應用中擴展角色的新見解。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;報告指出，接近一半的受訪者表示正在生產環境中運行 Dapr 應用，這一比例較往年顯著增加。隨着組織尋求可擴展的雲原生架構，Dapr 在提高開發者生產力和 AI 應用中的作用驅動了廣泛採用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;360&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-def120cb3998f0c9eacfa97e880529e27ae.webp&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一些亮點內容包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前有超過 40,000 家企業利用 Dapr 實現微服務、工作流和雲可移植性&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;72% 的受訪者現在將 Dapr 用於關鍵任務應用程序&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;96% 的受訪者表示節省了時間，60% 稱可節省 30% 或更多的開發時間&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;84% 的受訪者預計他們的 Dapr 使用量將在未來一年內增長。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Dapr（分佈式應用運行時）是一個便攜的運行時，使任何開發者都能輕鬆構建在雲和邊緣運行的韌性分佈式應用。它提供了用於通信、狀態和工作流的集成 API，幫助構建適合生產的應用。該項目於 2019 年首次推出，在 2021 年獲 CNCF 接受，並在 2024 年達到畢業狀態。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/342424/2025-state-of-dapr-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/342424/2025-state-of-dapr-report</guid>
            <pubDate>Sun, 23 Mar 2025 06:00:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>