<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>開源中國-最新資訊</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>開源中國-最新資訊 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 23 Apr 2025 07:36:38 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>智元機器人開源仿真評測工具 Genie Sim Benchmark</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元機器人&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvAk6c0rzo6ps43uZsIc3kA&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;推出並開源基於仿真功能的模型評測和驗證工具 Genie Sim Benchmark，專注為具身 AI 模型提供精準的性能測試和優化支持。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「作為 Genie Sim(智元仿真平台) 的開源評測版本，Genie Sim Benchmark 是智元繼開源百萬真機數據集和海量仿真數據集後，又一里程碑式的開源項目。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根據介紹，Genie Sim 能夠精準還原機器人的操作環境，為多樣化任務提供標準化的自動評測體系，衡量模型在各種場景下的表現，加速算法迭代流程，同時減少模型評測對昂貴物理硬件的依賴，顯著降低測試成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;218&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2361db80f04bdb27b0c1364779ea48b7643.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Genie Sim 構建了大規模的高精度具身智能三維資產庫，形成了涵蓋豐富物體、場景及機器人模型的完整仿真體系。所有資產均採用人工精細建模、三維重建與生成式 AI（AIGC）等技術打造，在確保高度真實性的同時兼顧種類多樣性和資產生成效率，全面滿足機器人複雜操作任務的仿真評測需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bea77c14e21ac2be1c31034ea2d73f3cb0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;還提供了基於場景重建的高保真、高精度的仿真評測環境，涵蓋多種場景和物體，高度還原真實世界。Genie Sim 的仿真評測環境能夠模擬真實世界中影響算法性能的條件和變量，為模型評測提供高度真實的測試基準。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元方面表示，經對比驗證，GO-1 模型仿真測試結果與真機結果誤差小於 5%。這一仿真精度的突破源於對真機測試環境和交互物體在仿真環境中進行完全 1:1 的還原，以及底盤、關節和末端控制動力學與真機的精準校準。算法開發者可以高度信賴模型在仿真中的評測結果，大幅減少真機測試次數，使算法迭代效率提升 5 倍以上，測試成本減少 95%，助力研發團隊專注核心算法優化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346159</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346159</guid>
            <pubDate>Wed, 23 Apr 2025 06:38:45 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>QEMU 10.0 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QEMU 10.0 版本現已推出，一些更新&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FQEMU-10.0-Released&quot; target=&quot;_blank&quot;&gt;亮點&lt;/a&gt;如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基於 LoongArch 的 KVM QEMU 現在支持 CPU 熱插拔、para-virtualzied IPI、steam time 等功能。&lt;/li&gt; 
 &lt;li&gt;RISC-V QEMU 支持多種新的 ISA/擴展，添加了 Tenstorrent Ascalon CPU、Xiangshan Nanhu CPU 以及 Microblaze-V 通用主板。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 添加了英特爾 Clearwater Forest CPU 型號。此外，還有一個 Sierra Forest 「v2」 CPU 型號，與 QEMU 的原始 Sierra Forest CPU 型號相比有所改進。&lt;/li&gt; 
 &lt;li&gt;VirtIO SCSI 設備在 QEMU 10.0 中獲得了「真正的」多隊列支持。這種適當的多隊列支持可以增強 I/O 可擴展性。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 圖形代碼添加了新的「apple-gfx-pci」和「apple-gfx-mmio」設備，以便使用 macOS 主機的 para-virtualized&amp;nbsp;圖形框架為 macOS 客户機提供加速圖形。apple-gfx-pci 適用於 x86_64 guests，而 apple-gfx-mmio 適用於 AArch64 macOS。&lt;/li&gt; 
 &lt;li&gt;QEMU 10 的 VFIO 代碼改進了所有 Gen11 和 Gen12 硬件的 Intel IGD 圖形設備 pass-through 功能。&lt;/li&gt; 
 &lt;li&gt;QEMU VFIO 代碼還增加了對舊版 ATI X550 GPU 的支持。&lt;/li&gt; 
 &lt;li&gt;Linux AIO 和 IO_uring 後端現在可以使用「RWF_DSYNC」標誌進行 FUA 寫入請求，而不是依賴模擬來提高已禁用寫入緩存的 guest disks 性能。&lt;/li&gt; 
 &lt;li&gt;改進了 QEMU 文檔。&lt;/li&gt; 
 &lt;li&gt;繼續致力於在 QEMU 中支持更多 Rust 編程語言的使用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多詳細信息可參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.qemu.org%2FChangeLog%2F10.0&quot; target=&quot;_blank&quot;&gt;Wiki 發行説明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qemu.org%2Fdownload%2F%23source&quot; target=&quot;_blank&quot;&gt;下載地址&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346156/qemu-10-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346156/qemu-10-0-released</guid>
            <pubDate>Mon, 14 Apr 2025 06:29:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>探索 AI 未來：Xinference v1.5.0 模型虛擬空間全新上線！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Xorbits Inference（Xinference）是一個，性能強大且功能全面的，分佈式，推理框架。可用於大語言模型（LLM），語音識別模型，多模態模型等各種模型的推理。通過 Xorbits Inference，你可以輕鬆地，一鍵部署你自己的模型或內置的前沿開源模型 - &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference%25E3%2580%2582%25E6%2597%25A0%25E8%25AE%25BA%25E4%25BD%25A0%25E6%2598%25AF%25E7%25A0%2594%25E7%25A9%25B6%25E8%2580%2585%25EF%25BC%258C%25E5%25BC%2580%25E5%258F%2591%25E8%2580%2585%25EF%25BC%258C%25E6%2588%2596%25E6%2598%25AF%25E6%2595%25B0%25E6%258D%25AE%25E7%25A7%2591%25E5%25AD%25A6%25E5%25AE%25B6%25EF%25BC%258C%25E9%2583%25BD%25E5%258F%25AF%25E4%25BB%25A5%25E9%2580%259A%25E8%25BF%2587&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference。無論你是研究者，開發者，或是數據科學家，都可以通過&lt;/a&gt; Xorbits Inference 與最前沿的 AI 模型，發掘更多可能。 &amp;nbsp; Xinference 的功能和亮點有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌟 模型推理，輕而易舉：大語言模型，語音識別模型，多模態模型的部署流程被大大簡化。一個命令即可完成模型的部署工作。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚡️ 前沿模型，應有盡有：框架內置眾多中英文的前沿大語言模型，包括 baichuan，chatglm2 等，一鍵即可體驗！內置模型列表還在快速更新中！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🖥 異構硬件，快如閃電：通過 ggml，同時使用你的 GPU 與 CPU 進行推理，降低延遲，提高吞吐！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚙️ 接口調用，靈活多樣：提供多種使用模型的接口，包括 OpenAI 兼容的 RESTful API（包括 Function Calling），RPC，命令行，web UI 等等。方便模型的管理與交互。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌐 集羣計算，分佈協同：支持分佈式部署，通過內置的資源調度器，讓不同大小的模型按需調度到不同機器，充分使用集羣資源。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🔌 開放生態，無縫對接：與流行的三方庫無縫對接，包括 LangChain， LlamaIndex， Dify，以及 Chatbox。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🎉 Xinference v1.5.0 重磅發佈！&lt;/p&gt; 
&lt;p&gt;🚀 重點亮點&lt;/p&gt; 
&lt;p&gt;🧩 模型虛擬空間正式上線！&lt;/p&gt; 
&lt;p&gt;隨着模型更新頻繁，不同模型對依賴的要求也越來越複雜，老模型需要老版本庫，新模型又依賴新版包，常常出現互相沖突的問題。 現在，通過模型虛擬空間，每個模型可以獨立擁有一套安裝包環境，相互隔離、互不影響，模型運行更穩定！ 📄 配置與使用方式詳見文檔：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🖥️ 易用性增強&lt;/p&gt; 
&lt;p&gt;🔄 模型加載支持展示進度，也可隨時取消模型加載 🧠 Gradio 聊天界面支持展示思考過程（🧪 需打開「解析思維過程」）&lt;/p&gt; 
&lt;p&gt;🧪 社區版&lt;/p&gt; 
&lt;p&gt;📦 更新指南&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📥 pip：pip install &#39;xinference==1.5.0&#39;&lt;/li&gt; 
 &lt;li&gt;🐳 Docker：拉取最新版本即可，也可以直接在鏡像內用 pip 更新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📝 更新日誌&lt;/p&gt; 
&lt;p&gt;🆕 新模型支持&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤖 LLM &amp;nbsp; &amp;nbsp; * 🌐 GLM-4 0414 &amp;nbsp; &amp;nbsp; * 🧠 Qwen2.5-Omni &amp;nbsp; &amp;nbsp; * ☁️ Skywork-OR1-preview&lt;/li&gt; 
 &lt;li&gt;🖼️ 多模態 &amp;nbsp; &amp;nbsp; * 🔍 InternVL3（已支持 AWQ 量化） &amp;nbsp; &amp;nbsp; * 🌊 SeaLLMs-v3 &amp;nbsp; &amp;nbsp; * 🗣️ Paraformer-ZH &amp;nbsp; &amp;nbsp; * 🛰️ Megatts3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🛠️ 功能增強&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧠 Gradio 聊天界面支持展示思考過程（需打開「解析思維過程」）&lt;/li&gt; 
 &lt;li&gt;📐 Vision 模型支持 min/max_pixels 控制輸入分辨率&lt;/li&gt; 
 &lt;li&gt;📥 模型下載支持進度顯示與取消&lt;/li&gt; 
 &lt;li&gt;⚙️ 默認併發數設置為 CPU 核心數&lt;/li&gt; 
 &lt;li&gt;🧪 支持 InternVL3 的 AWQ 推理&lt;/li&gt; 
 &lt;li&gt;🏎️ 默認使用最新版 xllamacpp 引擎&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🐛 BUG 修復&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧊 修復 vLLM 引擎停止時卡住的問題&lt;/li&gt; 
 &lt;li&gt;🧩 修復 llama.cpp 多分片模型加載失敗&lt;/li&gt; 
 &lt;li&gt;📂 修復 GGUF 模型路徑錯誤&lt;/li&gt; 
 &lt;li&gt;🧮 修復量化參數不生效問題&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 文檔更新&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📘 kokoro 使用指南&lt;/li&gt; 
 &lt;li&gt;📘 模型虛擬空間特性： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🏢 企業版&lt;/p&gt; 
&lt;p&gt;🎬 支持文生視頻界面，企業版新增文生視頻模塊界面，AI 視頻創作更直觀、操作更友好。 🚀 昇騰適配能力增強，適配模型範圍進一步擴展，支持更多模型在昇騰上穩定高效運行。&lt;/p&gt; 
&lt;p&gt;我們感謝每一位參與的社區夥伴對 Xinference 的幫助和支持，也歡迎更多使用者和開發者參與體驗和使用 Xinference。 &amp;nbsp; 歡迎您在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference&lt;/a&gt; 給我們一個，星標，這樣你就可以在 GitHub 上及時收到每個新版本的通知。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346151/xinference-1-5-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346151/xinference-1-5-0</guid>
            <pubDate>Mon, 14 Apr 2025 06:19:00 GMT</pubDate>
            <author>來源: 投稿</author>
        </item>
        <item>
            <title>騰訊混元 3D 生成模型發佈 2.5 版本新模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;騰訊混元 3D 生成模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fv6BJ2ZyvInnj_zopaC2z5Q&quot; target=&quot;_blank&quot;&gt;宣佈&lt;/a&gt;正式推出 2.5 版本新模型，多視圖支持 pbr 貼面，不僅能上傳多圖，細節還更豐富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同時建模精細度上大幅提升。v2.5 版本模型架構全面升級，總參數量從 1B 提升至 10B，有效面片數增加超 10 倍，實現超高清的幾何細節建模，表面更平整、邊緣更鋭利、細節更豐富，有效幾何分辨率達到 1024。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-067b104bbcf24a734d5cd7f472b98205ff4.gif&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b86aada5a6ce301269b3cc5b4cba07f42fb.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本支持 4K 高清紋理和細粒度 bump 凹凸貼圖，能夠模擬物體表面高低起伏的視覺效果。此外，為滿足專業創作者需求，混元 3D v2.5 優化了骨骼蒙皮系統，支持非標準姿態下的自動骨骼綁定和自動蒙皮權重賦值，大幅提升 3D 動畫生成效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3D 生成工作流功能也進一步升級，提供文生/圖生 3D 智能減面模型、多視圖生 3D 模型等專業管線模板，用户可根據場景選擇對應生產管線、靈活調整參數，生成特定風格和特徵的 3D 資產，助力遊戲開發、動畫製作等垂直場景的高效搭建。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;混元 3D AI 創作引擎全面更新至 v2.5 模型底座，同時免費生成額度翻倍，提升至每天 20 次。混元 3D 生成 API 也已正式上線騰訊雲，面向企業和開發者開放。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346148</guid>
            <pubDate>Mon, 14 Apr 2025 05:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>清華博士帶隊，發佈全球首個自迴歸視頻生成大模型「Magi-1」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，由清華博士曹越創立的 Sand.AI，公佈了一款名為「Magi-1」的自迴歸視頻生成模型，其主打兩個能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;無限長度擴展：通過前一段生成的內容進行後一段視頻的製作，從而實現跨時間的無縫連貫敍事；&lt;/li&gt; 
 &lt;li&gt;生成時長控制精準到每一秒。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115406_dDdh_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而從公佈的數據顯示，具體性能測試結果如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Physics-IQ（對多種物理定律的理解）基準測試：Magi-1 獲得 56.02% 的高分成績，超越可靈 1.6、Sora 等一眾模型；&lt;/li&gt; 
 &lt;li&gt;人類評估：與海螺、騰訊混元、通義萬相 Wan2.1 相比，Magi-1 在指令跟隨和運動質量等方面更具優勢，但與可靈 1.6 在視覺質量存在差距；&lt;/li&gt; 
 &lt;li&gt;VBench-I2V 基準：Magi-1（2 倍解碼器）以 89.28 的高分排名第一，在動態程度（Dynamic Degree）上有較大優勢。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115713_mOF3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;技術上，Magi-1 整體架構基於 Diffusion Transformer，採用 Flow-Matching 作為訓練目標。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1247121c5ed762e2b9adea14a9780bf743.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，據公佈的信息顯示，Magi-1 通過自迴歸去噪方式預測固定長度的視頻片段，提高了視頻生成效率和前後因果性（保證前後內容生成邏輯一致）。&lt;/p&gt; 
&lt;p&gt;目前，Magi-1 已上架 Sand.AI 官網（可以免費體驗！），並且模型權重、代碼也進行 100% 開源，技術報告也進行全面公佈。&lt;/p&gt; 
&lt;p&gt;而背後的 Sand.AI 創始人為曹越，其博士畢業於清華大學軟件學院，並於 2018 年獲清華大學特等獎學金。曹越於 2022 年創辦 AGI 公司「光年之外」，後加入智源研究院領導多模態與視覺研究中心。隨後在 2023 年，曹越創立了 Sand.AI，並很長一段時間與其他成員保持「隱身」狀態。&lt;/p&gt; 
&lt;p&gt;團隊成員方面，有不少與曹越有着類似的歷程：智源研究院實習、光年之外創始成員、微軟亞洲研究院實習等等。另據瞭解，San.AI 已完成三輪融資，主要參與方包括今日資本、經緯創投等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;體驗鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsand.ai%2F&quot; target=&quot;_blank&quot;&gt;https://sand.ai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSandAI-org%2FMagi-1&quot; target=&quot;_blank&quot;&gt;https://github.com/SandAI-org/Magi-1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HuggingFace：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsand-ai%2FMAGI-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/sand-ai/MAGI-1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346129/sand-ai-magi1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346129/sand-ai-magi1</guid>
            <pubDate>Mon, 14 Apr 2025 03:55:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenBMB 開源社區推出代碼 Agent「卷姬」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 開源社區宣佈推出代碼 Agent 新成員「卷姬」，官方介紹其能夠「高效獲取有價值的內容」。&lt;/p&gt; 
&lt;p&gt;具體來看，用户只需要在「卷姬」官網輸入想要提取的內容，便可在等待後獲取到綜述報告。而「卷姬」擁有兩種處理模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;普通模式：輸出標題和關鍵詞描述，提交併等待生成。&lt;/li&gt; 
 &lt;li&gt;專業模式：可進一步自定義素材來源，選擇「在線檢索」或「上傳文件」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aea0d199a34728e37f357830ab2a77c6f59.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;團隊方面表示，卷姬 SurveyGO 與 OpenAI DeepResearch、AutoGLM-沉思和 Gemini DeepResearch 相比，它的邏輯更嚴謹、學術性更強，適合深度分析，在多個方面有着不同的優勢體現：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;結構維度：SurveyGO 生成文章的目錄層次分明；&lt;/li&gt; 
 &lt;li&gt;內容維度：SurveyGO 導言部分更具深度，結尾分析更見功力，角度全面，絲滑縝密；&lt;/li&gt; 
 &lt;li&gt;觀點維度、引用維度：論述詳細，輔以合理的引用支持，觀點有理有據。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;據悉，卷姬 SurveyGO 採用 LLMxMapReduce-V2 長文本整合生成技術。該技術由 AI9Star、OpenBMB、清華大學團隊聯合研發，核⼼在於藉助⽂本卷積算法實現多篇參考⽂獻的聚合來代替現有⽅法中常⻅的檢索，從⽽實現對全部參考⽂章的充分利⽤。&lt;/p&gt; 
&lt;p&gt;目前，卷姬已上線官網，LLMxMapReduce-V2 的相關論文和開源內容也已公佈。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;體驗鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurveygo.thunlp.org%2F&quot; target=&quot;_blank&quot;&gt;https://surveygo.thunlp.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;論文鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.05732&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2504.05732&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;開源鏈接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fthunlp%2FLLMxMapReduce%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://github.com/thunlp/LLMxMapReduce/tree/main&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346126</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346126</guid>
            <pubDate>Mon, 14 Apr 2025 03:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>寶馬計劃年內在中國新車型中引入 DeepSeek 的 AI 技術</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;在近日於上海舉行的汽車展上，德國汽車製造商寶馬（BMW）宣佈，將於今年晚些時候在其新車型中集成中國初創公司 DeepSeek 的人工智能技術。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;這次合作的具體細節雖然尚未完全披露。&lt;/span&gt;寶馬首席執行官奧利弗・齊普塞 (Oliver Zipse) 在展會上表示，這一舉措標誌着寶馬在中國市場進一步加強與本地科技公司的合作。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-977e8740166a69b506b93255cfe68566f85.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;齊普塞強調，中國在人工智能領域的創新步伐迅速，寶馬希望藉助這種技術提升其汽車的智能化水平。「在這裏，AI 技術正在飛速發展。我們正在加強與當地公司的合作，以便將這些先進的人工智能技術整合進我們的車輛中。」&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;此外，寶馬在汽車電動化和智能化方面的努力也在不斷加碼。隨着全球汽車市場向電動和智能化轉型，寶馬希望通過與 DeepSeek 的合作，增強在這些領域的競爭力。齊普塞提到，未來的汽車將不僅僅是交通工具，更會成為用户生活的智能助手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346115</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346115</guid>
            <pubDate>Mon, 14 Apr 2025 03:24:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>英偉達終止 Lepton AI 運營</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，網上曝出 Lepton AI 已通知用户，Lepton 將於 2025 年 5 月 20 日正式停止運營，此後用户將無法再訪問 Lepton AI 平台上的服務或提交的數據，建議用户在該日期之前儘快下載或備份所需數據。服務終止時，若用户賬户中仍有未使用的積分，官方將會在關停後予以退款處理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105739_VR8C_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不僅如此，官方網站已經禁止新賬户註冊，顯示正在維護。Lepton AI 的官方推特顯示也已經被註銷。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105705_sxuq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105711_hYyj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;收購消息剛被曝出來時，許多人猜測英偉達收購後是會僅保留機器學習人才、大砍業務，還是會繼續運營 Lepton AI 的雲平台。目前看來，英偉達似乎更在意的人才，而非其相關具體業務，畢竟如今已經選擇了關閉服務。交易完成時 Lepton AI 約有 20 名員工，目前還未有消息指出這些員工的去留。&lt;/p&gt; 
&lt;p&gt;英偉達此番價值可能達數億美元的收購，實現了讓 LeptonAI 投資方紅杉中國、CRV 和 Fusion Fund 較為可觀的退出，大約在兩年前他們參與了該公司 1100 萬美元的種子輪融資。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;閲讀更多：&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/341235&quot; target=&quot;news&quot;&gt;英偉達正在洽談收購賈揚清創業公司 Lepton AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/343328&quot; target=&quot;news&quot;&gt;賈揚清已入職英偉達&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346110</guid>
            <pubDate>Mon, 14 Apr 2025 02:58:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Apache NetBeans 25 發佈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Apache NetBeans 25&lt;span&gt;&amp;nbsp;現&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fblogs%2Fentry%2Fannounce-apache-netbeans-25-released%2F&quot; target=&quot;_blank&quot;&gt;已正式發佈&lt;/a&gt;。NetBeans 是一個主要面向 Java 的集成開發環境，同時支持 C/C++、PHP、JavaScript 和其他編程語言。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;一些更新內容包括：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Note&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Platform users：此版本通過設置&lt;code&gt;-J-DTopSecurityManager.disable=true&lt;/code&gt;(&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8169&quot; target=&quot;_blank&quot;&gt;#8169&lt;/a&gt;) 禁用了 NetBeans 內部安全管理器層。以 JDK 21 或更高版本為目標平台的現有應用程序應手動將此選項添加到其 launcher.conf 中。NetBeans 26 移除了安全管理器層，因此該 flag 無效 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fissues%2F8258&quot; target=&quot;_blank&quot;&gt;#8258&lt;/a&gt;&amp;nbsp;)。另請參閲&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F486&quot; target=&quot;_blank&quot;&gt;JEP 486&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gradle&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;EST 單個文件應該適用於名稱與相應文件名不匹配的測試類。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8021&quot; target=&quot;_blank&quot;&gt;#8021&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;並行運行測試的操作&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7979&quot; target=&quot;_blank&quot;&gt;#7979&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Gradle init 應遵循配置 Java 運行時&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8223&quot; target=&quot;_blank&quot;&gt;#8223&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Maven&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Maven：改進依賴項解析（例如，對於像 lombok 這樣的註釋處理器）&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8057&quot; target=&quot;_blank&quot;&gt;#8057&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Maven 遠程索引遷移和重構&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7976&quot; target=&quot;_blank&quot;&gt;#7976&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 ProjectReload 中缺失的工件&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7855&quot; target=&quot;_blank&quot;&gt;#7855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;候選版本不應該竊取 GA 版本中的 Maven 索引&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8199&quot; target=&quot;_blank&quot;&gt;#8199&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 FruchtermanReingoldLayout 中的無限循環&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8217&quot; target=&quot;_blank&quot;&gt;#8217&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 maven 索引器的查詢限制&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8198&quot; target=&quot;_blank&quot;&gt;#8198&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Ant&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復大規模 Ant 項目打開時出現的 ConcurrentModificationException&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7989&quot; target=&quot;_blank&quot;&gt;#7989&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在 WSL 上運行的 Payara Server 實例在保存時部署會破壞「Web 應用程序」Ant 項目&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8144&quot; target=&quot;_blank&quot;&gt;#8144&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Java&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修復 Windows 上由於 java.hints、java.source.base 中的 CRLF 不匹配導致的測試失敗&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7910&quot; target=&quot;_blank&quot;&gt;#7910&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 MacOS 中 java.hints 測試失敗問題&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7926&quot; target=&quot;_blank&quot;&gt;#7926&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將嵌入式 tomcat 從 9.0.71 更新到 9.0.96&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7919&quot; target=&quot;_blank&quot;&gt;#7919&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 java/j2ee.persistence 測試並將其添加到構建管道中&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7943&quot; target=&quot;_blank&quot;&gt;#7943&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修復 switch 模式提示中可能出現的越界異常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7973&quot; target=&quot;_blank&quot;&gt;#7973&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7949] 修復「case null」的處理&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7980&quot; target=&quot;_blank&quot;&gt;#7980&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;確保 AttrContext.returnResult 的 checkContext 在 javac 的 Scopes 中設置為 Check.basicHandler，以避免其拋出異常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8016&quot; target=&quot;_blank&quot;&gt;#8016&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將 CI jobs 降級至 JDK 23&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8061&quot; target=&quot;_blank&quot;&gt;#8061&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 Java 代碼補全（sealed）測試的穩定性&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8066&quot; target=&quot;_blank&quot;&gt;#8066&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;合併 jakarta.web.beans 和 web.beans&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7958&quot; target=&quot;_blank&quot;&gt;#7958&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更新 textmate 支持&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7971&quot; target=&quot;_blank&quot;&gt;#7971&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;將 nb-javac 升級到 JDK 24b29&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8037&quot; target=&quot;_blank&quot;&gt;#8037&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7069] 支持 Nashorn 15.x for JDK &amp;gt;= 15&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7972&quot; target=&quot;_blank&quot;&gt;#7972&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;apidoc 拼寫錯誤修復&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8148&quot; target=&quot;_blank&quot;&gt;#8148&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;僅在 JDK 23 及更高版本上設置 javadoc 23 特定標誌&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8152&quot; target=&quot;_blank&quot;&gt;#8152&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;......&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多詳情可查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Freleases%2Ftag%2F25&quot; target=&quot;_blank&quot;&gt;https://github.com/apache/netbeans/releases/tag/25&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fdownload%2Fnb25%2F&quot; target=&quot;_blank&quot;&gt;https://netbeans.apache.org/front/main/download/nb25/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346107/apache-netbeans-25-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346107/apache-netbeans-25-released</guid>
            <pubDate>Mon, 14 Apr 2025 02:46:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 有意願收購谷歌 Chrome 瀏覽器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fgoogle-contemplated-exclusive-gemini-ai-deals-with-android-makers-2025-04-22%2F&quot;&gt;路透社報道稱&lt;/a&gt;，OpenAI 旗下 ChatGPT 產品負責人表示，&lt;strong&gt;若反壟斷執法人員成功迫使 Alphabet（Google 母公司）出售 Chrome 瀏覽器，OpenAI 將有意收購谷歌 Chrome 瀏覽器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/102749_NjaW_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此前，美國法官 Amit Mehta 判定谷歌的 Chrome 瀏覽器涉及壟斷行為，該公司需從本週一開始採取補救措施，而谷歌計劃針對該判決上訴。&lt;/p&gt; 
&lt;p&gt;檢察官在當地週一的開庭陳述上表示，谷歌搜索壟斷可能會令其在 AI 方面帶來優勢。谷歌則表示，提供生成式 AI 產品的公司會存在競爭，谷歌還在庭審中提供了一份 OpenAI 的內部文件，這份文件稱 ChatGPT 在消費級 AI 聊天機器人市場中處於領先地位，並不認為谷歌是其最大競爭對手。&lt;/p&gt; 
&lt;p&gt;ChatGPT 產品負責人 Nick Turley 表示，&lt;strong&gt;OpenAI 去年曾與谷歌聯繫，商討建立潛在合作關係，讓 ChatGPT 使用谷歌的搜索技術&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Turley 認為，ChatGPT 若能使用谷歌搜索的 API，那將能為用户提供更好的 AI 產品。據悉，OpenAI 於去年 7 月首次聯繫谷歌，但後者在 8 月以「涉及太多競爭對手」為由，拒絕了上述合作。&lt;/p&gt; 
&lt;p&gt;OpenAI 一直在開發自己的搜索工具，雖然 OpenAI 原本希望在 2025 年底之前讓 ChatGPT 上線搜索功能並依靠該引擎完成 80% 的搜索工作，但 Turley 在作證時表示，該公司現在認為達到這一成績仍需要數年時間。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;閲讀更多&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/322108/openai-hires-former-chrome-engineer&quot;&gt;又一名 Chrome 創始工程師加入 OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/321528/openai-considers-taking-on-google-with-browser&quot;&gt;OpenAI 考慮開發瀏覽器，與谷歌競爭&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346103/openai-chrome-google-us-judge</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346103/openai-chrome-google-us-judge</guid>
            <pubDate>Mon, 14 Apr 2025 02:28:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>Manus 開源平替，Kortix-AI 發佈開源通用 AI 智能體平台 Suna</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kortix-AI 正式發佈開源通用 AI 智能體平台 Suna，定位為熱門 AI 工具 Manus 的開源替代品。Suna 集成了瀏覽器自動化、文件管理、網絡爬蟲、擴展搜索、命令行執行、網站部署及 API 集成等功能，通過自然語言對話實現複雜任務的自動化處理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-01ba5fdfe0002965d001a22e6205e28616c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;主要功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;瀏覽器自動化：通過內置瀏覽器控制模塊，Suna 可自主導航網頁、點擊元素、填寫表單並提取數據，適用於任務如價格比較或表單提交。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;文件管理：支持文檔創建、編輯與組織，允許用户通過對話指令生成報告或管理項目文件。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;網絡爬蟲與擴展搜索：具備高效的網頁抓取與信息檢索能力，可跨平台搜索並整合數據，如分析社交媒體評論或市場趨勢。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;命令行執行：支持運行系統命令與腳本，自動化本地任務，如批量文件處理或服務器管理。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;網站部署：提供一鍵式網站部署功能，結合 API 集成，簡化從開發到上線的流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;API 與服務集成：通過 LiteLLM 支持 OpenAI、Anthropic 等多種大語言模型（LLM），並可連接 Supabase、GitHub 等外部服務，擴展功能邊界。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Suna 發佈後，社區對其開源性與功能全面性給予高度評價。開發者稱其「將 Manus 的商業能力帶入開源領域」，尤其在自動化複雜任務方面表現優異。 然而，部分用户指出，自託管的初始配置需一定技術背景，建議 Kortix 推出更簡化的雲端部署選項。社區已在探討增強 Suna 的多模態能力，如支持圖像生成與實時語音交互。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346097</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346097</guid>
            <pubDate>Mon, 14 Apr 2025 02:11:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>DistilQwen2.5-DS3-0324 發佈：知識蒸餾 + 快思考 = 更高效解決推理難題</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：蔡文睿（清素）、汪誠愚（熊兮）、嚴俊冰（玖燭）、黃俊（臨在）&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;在大語言模型領域的快速發展中，如何&lt;strong&gt;有效平衡高效推理和模型思維能力&lt;/strong&gt;之間的矛盾一直是學術界和工業界關注的重點。DeepSeekV3-0324 默認沒有采用深度思考的模式，使得模型推理速度更快，兼顧了快速推理和複雜任務處理之間的平衡。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DistilQwen&lt;/strong&gt; &lt;strong&gt;系列&lt;/strong&gt;是阿里雲人工智能平台 PAI 推出的蒸餾語言模型系列，包括&lt;strong&gt;DistilQwen2、DistilQwen2.5、DistilQwen2.5-R1&lt;/strong&gt; 等。在此次工作中，我們將 DeepSeekV3-0324 基於快思考的推理能力成功遷移到更輕量的小模型中，全新推出 &lt;strong&gt;DistilQwen2.5-DS3-0324&lt;/strong&gt;。在繼承了原始模型思維鏈蒸餾的精華的同時，引入了&lt;strong&gt;快思考策略&lt;/strong&gt;，顯著提升了推理速度，使得在資源受限的設備和邊緣計算場景中，模型能夠高效執行復雜任務。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;實驗顯示，DistilQwen2.5-DS3-0324 系列模型在多個基準測試中表現突出，其 32B 模型效果甚至接近參數量接近其 10 倍的閉源大模型。在複雜問題解決方面，也大幅降低了思維鏈的長度，展示了卓越的效率。&lt;strong&gt;DistilQwen2.5-DS3-0324 系列的發佈，助力「大模型+快思考」的新模式&lt;/strong&gt;，逐步成為解決推理難題的標準配置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a44937451ac82d3b8c6ed1970704e0dd.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;為方便開發者和企業在實際應用中使用 DistilQwen2.5-DS3-0324 系列模型，已將所有的 Checkpoint 在 Hugging Face 和 Model Scope 開源社區中公開。本文將深入闡述 DistilQwen2.5-DS3-0324 的蒸餾算法、性能評估，並且提供在阿里雲人工智能平台 PAI 上的使用指南及相關下載教程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 中的蒸餾技術&lt;/h1&gt; 
&lt;p&gt;本節中，我們主要描述 DistilQwen2.5-DS3-0324 系列模型訓練中使用的數據增強與知識蒸餾技術。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;推理模型通過深度思考可以解決複雜的推理任務，但這種深度思考也帶來了大規模的計算資源需求。模型思考的過程中一般都有反思機制的參與，其會反覆推敲模型已有的推理步驟，確保每個步驟都正確推進。這種反思機制在提高推理準確率的同時，也會不可避免地帶來一些重複冗餘的部分，導致推理模型所需的計算資源居高不下。因此，取得模型深度思考和快速回答間的平衡顯得格外重要。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此外，蒸餾模型的參數量普遍較小。而由於自身參數量的顯著差異，大模型與小模型的認知與推理軌跡有時並不完全一致。以數學問題為例：小模型由於自身參數量的限制，會傾向於使用更基礎的方法去解決問題。而大模型基於其強大的推理能力，會採用較為高階的方法。正是由於大小模型的認知軌跡偏差，小模型有時無法有效理解大模型的思維鏈。如果直接將大模型的思維鏈全部蒸餾到小模型中，往往無法達到最優效果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;針對這些問題，我們設計了一種小型推理模型蒸餾框架，主要包含 2 個階段：快思考 CoT 數據收集，CoT 軌跡認知對齊。該框架可以讓模型在快速思考的同時，消除認知軌跡偏差帶來的負面影響。我們通過第一階段收集大模型的快思考數據，在第二階段對快思考數據進行與小模型的認知能力對齊，最終使用對齊後的快思考 CoT 對 Qwen2.5 系列基座小模型進行監督微調（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;快思考 CoT 數據收集&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，模型深度思考和快速回答間的平衡顯得格外重要。如果模型的中間思考步驟出現錯誤，此時的反思機制可以有效幫助模型自查糾錯。但如果模型輸出的是正確的思考步驟，此時反覆的自查思考反而會導致不必要的資源浪費。因此，我們需要一種快思考 CoT，其保留了必要的推理和自查糾錯步驟，同時去除了不必要的重複冗餘部分。這種快思考 CoT 大幅縮減了推理長度，可以幫助模型進行快速思考和快速回復，在資源受限場景中高效完成任務。我們的快思考 CoT 數據主要來源於：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;推理大模型 CoT 數據的 Long To Short 思維鏈改寫。基於 DeepSeek-R1 的推理數據，我們從中提煉關鍵步驟，生成更高效、簡潔的推理路徑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;快思考大模型蒸餾。我們認為 DeepSeek-V3-0324 的輸出具備快思考的特點，我們從中蒸餾出一些推理軌跡，涵蓋數學、代碼和科學問題等多個領域。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;特別的，針對推理大模型產生的思維鏈過於冗長的問題，我們進一步使用 QwQ-32B 對思維鏈進行改寫，其功能在於精簡思維鏈長度，降低蒸餾模型的輸出 token 數量，同時，保證思維鏈的正確性，避免錯誤傳播到蒸餾模型中。使用大模型進行 Long To Short 思維鏈改寫的 Prompt 如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at simplifying reasoning processes.
Given a problem, its answer and its reasoning process, your task is to simplify the reasoning process so that a small language model (e.g., a 7B model) can reliably follow the steps to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the simplified reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;CoT 軌跡認知對齊&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，大小模型間的認知推理軌跡有時存在顯著偏差。因此，對於待蒸餾的大模型快思考 CoT 數據集，小模型可能無法有效理解全部內容。舉例來説，對於計算直角邊分別為 3 和 4 的三角形面積，大模型可能使用線性代數進行求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4323edb8ff0d97ef14445f75c67e3c21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;這種方式對小模型而言比較難以學會，其一般採用簡單的算術方法求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c9971930330f9f1c83cb1fa794fe13a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;因此，直接將大模型的輸出蒸餾到小模型容易造成小模型難以擬合的問題。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們採用了 LLM-as-a-Judge 的範式，對大模型的推理過程進行評價並改進。給定問題、大模型的推理過程和問題的答案，我們使用模型判斷這個推理過程是簡單、中等還是困難。難度等級的核心標準是小模型是否能夠遵循給定的推理過程得到問題的答案。以下是思維鏈的難度等級及定義：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中等： 小模型可以遵循該推理過程得到問題的答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;簡單： 給定的推理過程過於簡單，缺少小模型所需的必要步驟，導致大模型可以依賴其強大的推理能力解決問題，但小模型無法遵循該過程得到答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;困難： 給定的推理過程過於複雜或過於困難，導致小模型無法遵循該過程得到答案。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;其中，我們使用如下 Prompt 調用 QwQ-32B 模型進行思維鏈難度的估計：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a highly capable evaluator.
Your task is to assess the given reasoning process from the perspective of a small language model (e.g., 7B). 
Specifically, determine whether the reasoning process provides sufficient detail for a small model to solve the problem, or whether it is too simplistic (i.e., lacking critical details) or too complex (i.e., containing unnecessary or confusing steps). 

Difficulty Definitions (from the perspective of a small model): 
- Easy: The reasoning process is overly simplistic relative to the problem&#39;s difficulty; it omits essential details that a small model needs to solve the problem.
- Medium: The reasoning process is appropriately balanced, offering enough detailed guidance.
- Hard: The reasoning process is overly complex, with extraneous or convoluted steps that could hinder a small model&#39;s ability to follow it. 

Output Format:
You must output exactly one word: easy, medium, or hard. Do NOT provide any additional text, explanation.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;基於一個大模型的問題與思維鏈集合，我們可以將其分為簡單、中等和困難三類。對於評級為中等的部分，我們予以保留。對於被評為簡單和困難的數據，我們使用模型對思維鏈進行改進。具體來説：對於簡單部分，我們擴展其推理過程，直至小模型可以遵循擴展的過程得到答案。對於評級為困難的部分，我們精簡其推理過程，直至小模型可以遵循精簡的過程得到答案。精簡思維鏈的過程可以參考 Long To Short 的 Prompt 示例。擴展思維鏈的過程與 Long To Short 相反，其 Prompt 模版如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at extending reasoning processes.
Given a problem, its answer and its reasoning process, your task is to extend the reasoning process by adding necessary details and intermediate steps so that a small language model (e.g., a 7B model) can follow the extended reasoning process to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the extended reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們之後對改進結果進行進一步驗證，包括：對改進後的思維鏈再次評價難度等級，檢測其是否被歸類為中等難度。如果改進後的思維鏈通過驗證，説明改進有效，該數據可以被小模型有效理解，我們將其保留。如果驗證不通過，説明改進無效，我們將返回到改進步驟，重新進行改進，直至通過驗證。最終，我們獲取了優化後的思維鏈數據集，其組成部分如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為中等的數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為簡單，經過改進擴展後評為中等並通過驗證的數據。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始難度評級為困難，經過改進精簡後評為中等並通過驗證的數據。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此時，數據集內所有思維鏈的最終難度評級均為中等，意味着小模型可以有效理解數據集內的所有思維鏈，並能遵循這些思維鏈解決相應推理問題。上文提到的大小模型認知軌跡偏差問題在改進後的數據集中得到妥善解決，其可能帶來的負面影響也被消除。相關流程如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//688591ec35d4073130ee1caaf6bd497c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相關工作參考論文 Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們在第二階段使用這種 CoT 軌跡認知對齊機制對得到的快思考 CoT 數據進行優化，最終使用優化後的數據集對 Qwen2.5 系列基座模型進行監督微調（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 模型效果評測&lt;/h1&gt; 
&lt;p&gt;在本節中，我們從多個角度評測 DistilQwen2.5-DS3-0324 系列蒸餾小模型在推理任務上的實際效果；同時，我們將通過統計數據印證 DistilQwen2.5-DS3-0324 系列模型推理的快速性和高效性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型綜合能力評測&lt;/h2&gt; 
&lt;p&gt;我們在多個模型推理能力評測基準上測試了 DistilQwen2.5-DS3-0324 系列模型的能力，涵蓋數學、代碼和科學問題三個主流推理領域。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;數學領域：採用 AIME2024 和 MATH-500 兩個基準。AIME2024 為美國數學邀請賽的 2024 年測試集，含 30 道高難題，聚焦代數與幾何等複雜推理能力；MATH-500 涵蓋 500 道題，旨在全面考察模型在數學解題上的能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代碼領域：使用 LiveCodeBench V2，其包含 2023 年 5 月-2024 年 5 月的 511 個代碼問題，測試模型在高難度編碼、自我修復和執行測試等方面的綜合能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;科學問題領域：使用 GPQA-Diamond 和 MMLU-PRO。前者為高質量專家級科學問題集（共 198 題），後者涵蓋 12,000+道題，強調模型的複雜推理能力而非僅靠知識檢索，精準追蹤大模型在推理任務上的進步和不足。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如下圖所示，DistilQwen2.5-DS3-0324 系列模型在 7B、14B 和 32B 四個參數量級的模型中，與原始 Qwen2.5 模型的效果進行了對比。可以看出，DistilQwen2.5-DS3-0324 系列模型的推理能力在多個評測基準上取得了一致而明顯的效果提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我們還將 DistilQwen2.5-DS3-0324-32B 與當前主流的非推理大模型作了比較，結果如下圖所示。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4774cc392eb93d60a2c732815125d227.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;可以看出，儘管這些大模型的參數量是自己的數十倍，DistilQwen2.5-DS3-0324-32B 依舊在這些推理基準上取得了相對不錯的結果。其中，DistilQwen2.5-DS3-0324-32B 在 AIME2024 和 MATH-500 兩個基準上高於多個閉源大模型（例如 Qwen-Max 和 Claude-Sonnet-3.7），在 LiveCodeBench 超過了其他所有大模型，包括其教師模型 DeepSeek-V3-0324。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;平衡精度和輸出 Token 數量&lt;/h2&gt; 
&lt;p&gt;為展示 DistilQwen2.5-DS3-0324 系列模型高效推理效果，以 32B 模型為例，我們分別統計了 DistilQwen2.5-DS3-0324 模型和 DistilQwen2.5-R1 系列模型在各個推理 benchmark 上輸出的平均 token 數。可以看出，相較於採用深度思考進行推理的模型，DistilQwen2.5-DS3-0324 系列模型推理輸出的 token 數量大幅降低，與 DeepSeek-V3-0324（teacher model）的輸出 Token 數相當，兼顧了快速推理和複雜任務處理。這種快思考的特點使得 DistilQwen2.5-DS3-0324 系列模型在資源受限的設備和邊緣計算場景中依舊能高效解決複雜推理任務。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//85ba45740e3afe28cb2efa233a239871.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型輸出案例&lt;/h2&gt; 
&lt;p&gt;我們在此列舉一些有趣的小例子，以體現 DistilQwen2.5-DS3-0324 系列模型強大的代碼能力。以下 case 均為 DistilQwen2.5-DS3-0324-32B 輸出結果。為便於復現，我們還提供了不同 case 對應的 prompt。將 prompt 對應的模型輸出代碼保存到本地 html 文件中，使用瀏覽器打開 html 文件即可復現類似結果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例一：前端網頁生成：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8622f5305c8f41ee9a740afeb6915fbf.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt：Create a detailed web page for a new SAAS with all the necessary information images and pricing and all, give me the code so that I can test locally using vscode.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例二：貪吃蛇遊戲&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5aae0fd15a345f08fdf98c360ee5d33.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt: Develop an interactive version of the classic Snake game in a single HTML file using HTML, inline CSS, and inline JavaScript. The game must include responsive controls, dynamic score tracking, and a game-over screen with a restart option. Use proper image assets for the snake and food items (no placeholders) so that the entire game is self-contained.&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_9&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;模型下載和使用&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在阿里雲人工智能平台 PAI 上的實踐&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 庫為例，簡要介紹如何在 PAI-DSW 上使用 DistilQwen2.5-DS3-0324 模型。首先需要保證 PAI-DSW 鏡像內 transformers 版本大於等於 4.37.0，否則會在加載模型時報錯：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以 DistilQwen2.5-DS3-0324-7B 為例，我們可以使用如下代碼調用模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;xxxxx&quot;
messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant. You should think step-by-step.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=2048
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在開源社區的下載&lt;/h2&gt; 
&lt;p&gt;我們在 Hugging Face 和 Model Scope 上開源了我們蒸餾後的模型，分別為&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-7B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-7B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-14B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-14B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-32B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-32B&lt;/a&gt;。以 Hugging Face 為例，用户可以使用如下代碼下載這兩個模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-7B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-14B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-14B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-32B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-32B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;小結與未來工作&lt;/h1&gt; 
&lt;p&gt;綜上所述，DistilQwen2.5-DS3-0324 系列模型通過知識蒸餾快思考策略，實現了在資源受限環境中的高效推理，兼顧了快速推理和處理複雜任務的需求。這一系列模型在多個基準測試中表現優異，證明瞭其卓越的推理能力和實際應用價值。作為「大模型+快思考」新模式的經典案例，DistilQwen2.5-DS3-0324 系列為小模型的廣泛應用提供了巨大的空間。未來，我們將繼續優化和提升 DistilQwen 系列模型的蒸餾技術，以進一步增強小模型的智能水平和推理效率，推廣更多高效、輕量化的語言模型，支持開發者和企業在實際應用中的廣泛採用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_13&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;參考資料&lt;/h1&gt; 
&lt;p&gt;相關發表論文&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang. Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;技術文章&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5-R1 發佈：知識蒸餾助推小模型深度思考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1659288&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1659288&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5 發佈：通義千問蒸餾小模型再升級：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1653842&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2：通義千問大模型的知識蒸餾實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2 蒸餾小模型的訓練、評測、壓縮與部署實踐：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大語言模型數據增強與模型蒸餾解決方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;技術交流答疑羣&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8a44ba73f4d5fc38c496db477b936e55.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_15&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&amp;nbsp;&lt;/h1&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/18224086</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18224086</guid>
            <pubDate>Mon, 14 Apr 2025 01:56:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>全球首個自迴歸視頻生成大模型「Magi-1」重磅開源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;Magi-1 是首個實現頂級畫質輸出的自迴歸視頻生成模型，模型權重、代碼 100% 開源。其主打能力，一是無限長度擴展，實現跨時間的無縫連貫敍事。二是能將控制精確到每一「秒」，10s 內自定義視頻時長。&lt;/p&gt;

&lt;p&gt;Magi-1 整體架構基於 Diffusion Transformer，採用 Flow-Matching 作為訓練目標。其最大的特點是不把視頻當成一個整體去生成，而是通過自迴歸去噪方式預測固定長度的視頻片段（chunk），每個片段固定為 24 幀。&lt;/p&gt;

&lt;p&gt;在注意力機制上，也是提出了多項創新，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Block-Causal Attention&lt;/li&gt;
&lt;li&gt;Parallel Attention Block&lt;/li&gt;
&lt;li&gt;QK-Norm 和 GQA&lt;/li&gt;
&lt;li&gt;Flex-Flash-Attention&lt;/li&gt;
&lt;li&gt;計算負載均衡&lt;/li&gt;
&lt;li&gt;零冗餘通信原語&lt;/li&gt;
&lt;li&gt;自適應多階段重疊&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推理基礎設施方面，主要針對實時流式視頻生成和在 RTX 4090 GPU 上的經濟高效部署兩種場景進行設計，以滿足不同應用需求。&lt;/p&gt;

&lt;p&gt;目前官網支持免費試玩 Magi-1：&lt;a href=&quot;https://sand.ai/magi&quot;&gt;https://sand.ai/magi&lt;/a&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/magi-1</link>
            <guid isPermaLink="false">https://www.oschina.net/p/magi-1</guid>
            <pubDate>Sun, 13 Apr 2025 11:45:00 GMT</pubDate>
        </item>
        <item>
            <title>百度 Al 智能體心響 App 上線</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;百度通用 Al 智能體心響 App 已低調上線安卓應用市場。該應用介紹稱，這是一款以「AI 任務完成引擎」為核心的手機端超級智能體產品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;545&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-282aac1eb0a56c4d21d1903e980e2f7a194.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;應用詳情介紹，心響是一款以「AI 任務完成引擎」為核心的手機端超級智能體產品，通過自然語言交互幫助用户實現複雜任務拆解、動態執行與可視化結果交付。依託大模型與多智能體協同能力，心響深度賦能知識解析、旅遊規劃、學習辦公等核心生活場景，致力於成為用户的&#39;超級大腦」+「最強輔助」，讓用户從繁瑣流程中解放一站式讓複雜問題智能決策，效率調度，閉環解決實現全流程託管。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能亮點&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.主腦調度系統：全流程任務託管&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;智能拆解：將複雜需求拆解為可執行步驟，並提供實時進度追蹤。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;資源協同：連接核心場景的垂直領域專家智能體確保任務精準落地。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;動態優化：根據任務進展自動調整策略，突發問題實時預警並生成解決方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2.旅遊攻略：沉浸式行程規劃&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一句話定製行程：用户僅需輸入一句話需求，心響便可生成完整攻略，聯動動態地圖可視化路線。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;視頻互動決策：數字人導遊引導用户選擇天數、預算、玩法，強化「身臨其境」決策體驗。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3.智慧圖表：數據可視化革新&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一鍵生成複雜圖表：基於行業數據自動生成動態排行榜、柱狀圖、折線圖等 10+圖表類型，支持定時任務製圖 (如哪吒 2 票房走勢、實時股價走勢)&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4.定時任務：自動化追蹤與提醒&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;高頻任務託管：如每日兒童故事生成、黃金價格盯盤、股票波動監測，AI 自動執行並推送結果。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;個性化&amp;amp;長期追蹤：支持例如蘋果發佈會動態彙總埃隆·馬斯克業務進展跟蹤，信息整合不遺漏關鍵節點&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;5.戀愛挑戰：社交技能訓練場&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;模擬戀愛對話：拆解社交需求，生成個性化戀愛對象，提供對話練習與總結報告，提升情感溝通技巧。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345995</guid>
            <pubDate>Sun, 13 Apr 2025 10:09:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>「HarmonyOS 協同・創新」 即將啓幕，開發者攜手共創新未來</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0.0001pt; margin-right:0px&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鴻蒙開發者聯盟官網&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成為鴻蒙開發者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;當智能終端從「單一設備」走向「全域協同」，從智能家居的聯動控制到工業互聯的高效協同，從車載系統的無縫銜接到移動辦公的跨端流轉，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;開發者如何在這場變革中搶佔先機？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 以分佈式技術打破硬件邊界，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「一次開發、多端部署」能力已悄然滲透至千行百業，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用全場景生態重構用户體驗，正為全球開發者打開一扇通向未來的大門。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但隨之而來的挑戰也愈發明顯：如何高效利用分佈式架構實現跨端協同&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 技術如何深度賦能鴻蒙應用開發？複雜場景下的性能優化有哪些「避坑指南」？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;4 月 27 日，由開源中國主辦，山東省軟件行業協會協辦的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;「HarmonyOS 協同·創新」（軟件行業專場）將在濟南啓幕&lt;/strong&gt;&lt;/span&gt;。這是一場專為鴻蒙生態建設者打造的深度對話——技術大咖、實戰派工程師與數百名開發者齊聚，共同探索操作系統的無限可能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主題：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 協同·創新（軟件行業專場）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;時間&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：2025 年 4 月 27 日 14:00-17:20（13:40 開放簽到） &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;地點&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：濟南市山創創意園·ChillPlay Base&amp;amp;coffee（山 6 創意園內，科技氛圍與咖啡香交融的靈感空間）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;適合人羣&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：鴻蒙應用開發者、技術團隊負責人、生態合作企業&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;🤝&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;與頂尖專家面對面：破解開發者的「真問題」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;華為雲 HCDE 專家姚聖偉將解讀鴻蒙生態戰略佈局及 2025 年新機遇，拆解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;鴻蒙分佈式架構&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，揭秘跨端協同開發的核心邏輯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;科技公司軟件工程師劉&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;張豪&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分享&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 賦能鴻蒙生產力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的實戰案例，探索智能化開發新路徑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互聯網醫療&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大前端&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;專家黃沅帶來&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;高頻問題解析與優化指南&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，助力開發者提升效率、少走彎路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;活動特設「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互動時刻&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」環節，專家&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;現&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;場坐鎮答疑解惑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。無論是分佈式架構設計、多端協同邏輯，還是代碼調試中的疑難問題，參與者均可通過現場提問與專家零距離交流，快速打通技術堵點，獲取針對性解決方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外，本次活動特設茶歇交流時間，與數百名鴻蒙開發者、技術專家、企業代表輕鬆氛圍中碰撞創新靈感，拓展行業人脈。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;👏&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;微信掃碼，即刻報名：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;6141&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fa6fad32606b45577ffd51a7a220b5e6ae4.png&quot; width=&quot;2160&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鴻蒙開發者聯盟官網&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成為鴻蒙開發者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18219336</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18219336</guid>
            <pubDate>Sun, 13 Apr 2025 09:45:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>OpenAI o3/o4-mini 模型在生成的文本中嵌入特殊字符水印</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;AI 初創公司 Rumi &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rumidocs.com%2Fnewsroom%2Fnew-chatgpt-models-seem-to-leave-watermarks-on-text&quot; target=&quot;_blank&quot;&gt;發現&lt;/a&gt;&lt;/u&gt; OpenAI 在最新的 o3 和 o4-mini 模型中，&lt;strong&gt;嵌入了窄不換行空格（Narrow No-Break Space, NNBSP, U+202F）等特殊 Unicode 字符。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;這些字符在普通視圖中與標準空格無異，但在 SoSciSurvey 或 Sublime Text 等專業工具中，可檢測其獨特代碼。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;433&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0422/170754_EvLW_2720166.gif&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rumi 表示在 GPT-4o 等 OpenAI 此前模型中，並不存在這些設置，這些選項可以通過簡單的「查找替換」移除，&lt;strong&gt;推測這可能是 OpenAI 故意設置的水印。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Rumi 強調，這種字符檢測方法誤報率極低，但易被繞過的缺陷明顯。另一種解釋是，這些字符符合排版規則，用於防止貨幣符號與金額或姓名縮寫間換行，可能是模型從訓練數據中習得的習慣。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-591091037deae24e2952a8c940f02f296fd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 此前曾探索過多種水印方案，例如在 2024 年初為 DALL・E 3 圖像添加 C2PA 元數據，以及 2025 年 4 月在 GPT-4o 模型上測試可見的「ImageGen」標籤。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345971/new-chatgpt-models-seem-to-leave-watermarks-on-text</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345971/new-chatgpt-models-seem-to-leave-watermarks-on-text</guid>
            <pubDate>Sun, 13 Apr 2025 09:12:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>突破極限：高負載場景下的單機 300M 多行正則日誌採集不是夢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：裘文成（翊韜）&lt;/p&gt; 
&lt;h2&gt;問題背景&lt;/h2&gt; 
&lt;p&gt;在當今數字化時代，日誌數據已成為企業 IT 運營和業務分析的關鍵資源。然而，隨着業務規模的擴大和系統複雜度的提升，日誌數據的體量呈現爆發式增長，給日誌採集和處理系統帶來了巨大挑戰。最近，我們遇到了一個典型案例，充分體現了當前日誌服務採集在高負載場景下面臨的困境，以下為客户現狀：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量日誌與正則採集：客户的某項業務產生了數量巨大的多行日誌，並且需要通過正則表達式進行日誌解析。這種複雜的採集模式本身就對系統資源提出了較高要求。&lt;/li&gt; 
 &lt;li&gt;關鍵業務影響：這些日誌數據和客户的核心業務分析任務直接相關。過高的採集延遲會影響數據分析的準確性。&lt;/li&gt; 
 &lt;li&gt;採集性能瓶頸：客户根據 iLogtail 啓動參數配置文檔【1】對 iLogtail 的線程數等進行了調整，在壓測時採集速度依然只有 90M/s，但實際壓測時的日誌生成速度在 200M/s，遠超採集速度。這導致了日誌採集出現近 1 小時的延遲。&lt;/li&gt; 
 &lt;li&gt;業務需求升級：客户計劃進一步增加壓測量，預計寫入流量將達到 300MB/s。這將進一步加劇採集延遲問題。&lt;/li&gt; 
 &lt;li&gt;業務負載高：客户的業務已經佔據了大部分的 CPU 資源，比較困難繼續為 iLogtail 提供更多的資源。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;技術難點&lt;/h2&gt; 
&lt;p&gt;在收到客户反饋後，我們立即着手分析問題並制定優化策略。通過獲取客户的測試日誌樣本並進行深入測試，我們發現了以下關鍵技術難點:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;性能瓶頸&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑戰: 即使在優化的測試環境中，我們也無法達到客户期望的 300MB/s 處理速度。&lt;/li&gt; 
   &lt;li&gt;數據: 採用 16 線程並行處理，最高吞吐量僅為約 270MB/s。&lt;/li&gt; 
   &lt;li&gt;影響: 無法滿足客户的性能需求，可能導致日誌處理延遲和數據分析滯後。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;資源消耗與業務衝突&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑戰: 為接近目標性能，iLogtail 需要佔用大量系統資源。&lt;/li&gt; 
   &lt;li&gt;數據: 需要 16 個線程才能達到 270MB/s 的處理速度。&lt;/li&gt; 
   &lt;li&gt;影響: 高強度的資源佔用嚴重影響服務器上的其他業務進程，可能導致整體系統性能下降。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;線程擴展效益遞減&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑戰: 簡單增加處理線程數量並不能線性提升性能，達到一定線程數後，性能增益呈現邊際遞減趨勢。&lt;/li&gt; 
   &lt;li&gt;影響: 表明僅依靠增加硬件資源難以實現質的突破，需要從算法層面進行優化。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4dea9c44863a5defa1b6380f69179c6c72a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;優化過程與成果&lt;/h2&gt; 
&lt;p&gt;怕看官們等不及，在深入技術細節之前，讓我們先一睹為快，直觀呈現這次優化的成果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能質的飛躍：成功將採集速率提升至超過 300MB/s，完全滿足客户需求。&lt;/li&gt; 
 &lt;li&gt;資源利用大幅優化：在保持高性能的同時，將所需線程數從 16 減少到 8，顯著降低了 CPU 佔用。&lt;/li&gt; 
 &lt;li&gt;創新解決方案：針對資源受限的場景，我們推出了 IngestProcessor 方案。使用這種方案，iLogtail 僅需 1 個線程就能實現 320MB/s 的採集速度，為客户提供了極致的資源效率選擇。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-686e8501b0fbeb6948311dbd45331cb7d68.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本文分析和測試，皆在以下硬件環境進行測試&lt;/p&gt; 
&lt;p&gt;硬件環境&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;計算資源：阿里雲 ECS 實例（規格：ecs.c5.8xlarge）&lt;/li&gt; 
 &lt;li&gt;存儲資源：PL3 規格的 ESSD 雲盤&lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;為避免磁盤 I/O 出現瓶頸，在高日誌量的輸出和採集場景，我們推薦使用 PL3 規格的 ESSD 雲盤。本文將基於該規格的 ESSD 雲盤進行性能分析，詳情可參考 ESSD 雲盤官方文檔【2】&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c40335c27e61f532a7c6b41aa5854c30a08.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;多行日誌採集性能提升&lt;/h3&gt; 
&lt;h4&gt;初步觀察&lt;/h4&gt; 
&lt;p&gt;為深入瞭解性能瓶頸，我們首先將注意力放在多行日誌的處理性能上。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;客户的日誌主要是多行格式。&lt;/li&gt; 
 &lt;li&gt;多行日誌採集步驟在日誌正則處理之前，可能對整體性能產生重大影響。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在深入研究多行日誌採集性能時，我們觀察到了一個令人震驚的現象。儘管預期多行日誌處理會對性能產生一定影響，但實際測試結果卻遠遠超出了我們的初步估計。在統一的單線程環境下，我們記錄到以下數據：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;單行日誌採集速度：425MB/s&lt;/li&gt; 
 &lt;li&gt;多行日誌採集速度：98MB/s&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-98807d652af01f20d8f17f1072693e46377.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;這近乎 80% 的性能下降不僅令人驚訝，更引發了我們對多行採集算法實現的深度思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能差距：從 425MB/s 驟降至 98MB/s，這種程度的性能退化遠遠超出了我們對多行處理的初始預期。&lt;/li&gt; 
 &lt;li&gt;異常性：如此巨大的差異明顯超出了正常的多行處理開銷，顯然存在一個重大的性能瓶頸。&lt;/li&gt; 
 &lt;li&gt;算法效率質疑：這一現象使我們不得不重新審視當前多行採集算法的實現效率。可能存在某些未優化的操作或不必要的重複計算。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;iLogtail 多行日誌處理原理&lt;/h4&gt; 
&lt;p&gt;iLogtail 的多行日誌合併功能基於特定的日誌格式將分散的多行數據聚合為完整事件。其工作流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;用户配置行首正則表達式。&lt;/li&gt; 
 &lt;li&gt;iLogtail 對每行日誌開頭應用此正則。&lt;/li&gt; 
 &lt;li&gt;若某行不匹配，iLogtail 繼續等待直至找到匹配的行首。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;舉個例子，假設我們有如下的日誌格式，通常我們會配置行首正則為 \d+-\d+-\d+\s\d+:\d+:\d+.\d+\s.*，iLogtail 會拿着這個正則對每行進行匹配，將這些單行日誌合併成一個完整的多行日誌。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-03-15 14:23:45.678 ERROR 987654 --- [TaskExecutor-1] c.e.d.s.TaskScheduler                   : Failed to process task due to unexpected exception  
java.lang.NullPointerException: Cannot invoke &quot;com.example.data.model.Task.getPriority()&quot; because &quot;task&quot; is null  
  at com.example.data.processor.TaskProcessor.processTask(TaskProcessor.java:123)  
  at com.example.data.scheduler.TaskScheduler.lambda$scheduleTask$1(TaskScheduler.java:89)  
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  
  at java.lang.Thread.run(Thread.java:748)  
Caused by: java.lang.IllegalArgumentException: Task ID cannot be null or empty  
  at com.example.data.validator.TaskValidator.validateTask(TaskValidator.java:45)  
  at com.example.data.processor.TaskProcessor.processTask(TaskProcessor.java:115)  
  ... 4 common frames omitted
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;性能瓶頸分析&lt;/h3&gt; 
&lt;p&gt;深入 iLogtail 的實現機制，我們發現性能瓶頸的關鍵在於其正則匹配方法。&lt;/p&gt; 
&lt;p&gt;iLogtail 使用 boost::regex_match 函數進行全量匹配，這在處理大規模日誌時會產生顯著的性能開銷。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool BoostRegexMatch(const char* buffer, size_t size, const boost::regex&amp;amp; reg, string&amp;amp; exception) {
    // ...
    if (boost::regex_match(buffer, buffer + size, reg))
        return true;
    // ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;對於之前提到的日誌示例，正則表達式會對第一行的全部 253 個字符進行匹配，這在處理大量日誌時會導致性能下降。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c05eee7da11ac673c070a2ed24207f1c8ff.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了量化這一性能問題，我編寫了測試代碼進行實驗，目的是觀察隨着與行首正則無關的日誌長度增加（即 .* 匹配的部分），boost::regex_match 的執行時間如何變化。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static void BM_Regex_Match(int batchSize) {
    std::string buffer = &quot;2024-07-19 15:02:16.055 INFO &quot;;
    std::string regStr = &quot;\\d+-\\d+-\\d+\\s\\d+:\\d+:\\d+\\.\\d+\\s.*&quot;;
    boost::regex reg(regStr);
    std::ofstream outFile(&quot;BM_Regex_Match.txt&quot;, std::ios::trunc);
    outFile.close();
    for (int i = 0; i &amp;lt; 1000; i++) {
        std::ofstream outFile(&quot;BM_Regex_Match.txt&quot;, std::ios::app);
        buffer += &quot;a&quot;;
        int count = 0;
        uint64_t durationTime = 0;
        for (int j = 0; j &amp;lt; batchSize; j++) {
            count++;
            uint64_t startTime = GetCurrentTimeInMicroSeconds();
            if (!boost::regex_match(buffer, reg)) {
                std::cout &amp;lt;&amp;lt; &quot;error&quot; &amp;lt;&amp;lt; std::endl;
            }
            durationTime += GetCurrentTimeInMicroSeconds() - startTime;
        }
        outFile &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\t&#39; &amp;lt;&amp;lt; &quot;durationTime: &quot; &amp;lt;&amp;lt; durationTime &amp;lt;&amp;lt; std::endl;
        outFile &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\t&#39; &amp;lt;&amp;lt; &quot;process: &quot; &amp;lt;&amp;lt; formatSize(buffer.size() * (uint64_t)count * 1000000 / durationTime)
                &amp;lt;&amp;lt; &quot;/s&quot; &amp;lt;&amp;lt; std::endl;
        outFile.close();
    }
}

int main(int argc, char** argv) {
    logtail::Logger::Instance().InitGlobalLoggers();
    std::cout &amp;lt;&amp;lt; &quot;BM_Regex_Match&quot; &amp;lt;&amp;lt; std::endl;
    BM_Regex_Match(10000);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;通過這個實驗，可以觀察到一個關鍵現象：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;隨着與行首正則無關的日誌長度增加（即 .* 匹配的那部分日誌），boost::regex_match 的執行時間也呈線性增長。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8600e54e65ef9b7e45c4d057487bc0435ad.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;基於實驗結果，我們可以得出以下結論：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;全量匹配的低效性：boost::regex_match 對整行進行匹配，即使只有行首部分是關鍵的。&lt;/li&gt; 
 &lt;li&gt;資源浪費：匹配時間與日誌行長度呈線性關係，大部分匹配時間花在了與實際分割邏輯無關的內容上（.* 匹配的部分）,這在處理大量長行日誌時會導致嚴重的性能下降。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;性能優化&lt;/h4&gt; 
&lt;p&gt;基於性能瓶頸分析，我們確定了關鍵的優化方向：實現部分匹配。這種方法只對日誌行首進行匹配，而不是整行，有望顯著提高處理效率。&lt;/p&gt; 
&lt;p&gt;為了避免重複造輪子，在調研後，我們發現 Boost 庫提供了一個替代方案：boost::regex_search 函數，通過適當配置，這個函數能夠精確滿足我們的需求。以下是優化後的代碼實現：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool BoostRegexSearch(const char* buffer, size_t size, const boost::regex&amp;amp; reg, string&amp;amp; exception) {
    // ...
    if (boost::regex_search(buffer, buffer + size, what, reg, boost::match_continuous)) {
        return true;
    }
    // ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;關鍵改進點：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 boost::regex_search 替代 boost::regex_match。&lt;/li&gt; 
 &lt;li&gt;添加 boost::match_continuous 標誌，確保只匹配前綴，如果字符串的開頭子串滿足正則表達式，就會返回成功。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;這種實現方式允許我們精確控制匹配過程，只關注日誌行首，這正是多行日誌處理所需要的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7dfea97286fb5b001a5025f88f7563185cc.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;為了量化這一優化的效果，和 boost::regex_match 一樣，我也對 boost::regex_search 根據日誌長度進行了測試。可以發現，新方案的執行時間基本保持穩定，不受日誌長度影響。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ec2a7ac92247bc5dfa0cb212e1578acb9a6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;優化後的多行算法，實際採集效果&lt;/h4&gt; 
&lt;p&gt;我們對使用優化後多行算法的 iLogtail，進行了多行日誌採集，以下是測試的詳細結果：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-233d6b9d35e1ba04aabb249c7657c868f71.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多行採集性能飛躍&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優化後的多行採集速度從 98MB/s 提升到 350MB/s&lt;/li&gt; 
   &lt;li&gt;性能提升幅度：257%（約 3.57 倍）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;接近單行採集性能&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優化後的多行採集速度（350MB/s）已接近單行採集（425MB/s）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;相對於單行採集的性能比：82.35%&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;資源利用效率 
  &lt;ul&gt; 
   &lt;li&gt;在保持單線程的情況下實現顯著性能提升&lt;/li&gt; 
   &lt;li&gt;體現了算法優化在提高資源利用效率方面的巨大潛力&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-791501e2ae0e0f6c532bb47c9e255f6f08c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;用户體驗優化&lt;/h4&gt; 
&lt;p&gt;在 iLogtail 的已有實現中，用户配置的行首正則表達式通常包含 .*後綴。這是由於之前的匹配機制會匹配整行內容，為了讓客户不改動採集配置，只需要升級 iLogtail 版本 2.1 及以上，就能享受到該多行採集性能優化，我們設計了一個以下兼容性策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;正則表達式解析： 
  &lt;ul&gt; 
   &lt;li&gt;在處理用户配置時，iLogtail 會自動分析正則表達式。&lt;/li&gt; 
   &lt;li&gt;如果檢測.*後綴的存在，iLogtail 動態調整正則表達式，移除.*後綴。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;正則匹配雙方案&lt;/h3&gt; 
&lt;h4&gt;改進多行日誌性能後的多行正則匹配採集&lt;/h4&gt; 
&lt;p&gt;在優化多行日誌採集性能後，我們進一步探討了將改進後的多行採集與正則提取相結合的效果。下面詳細分析了這種組合方案的性能表現及其實際應用價值。在 8 線程下， iLogtail 的多行日誌採集性能已經可以到 370MB/s，已經足夠滿足客户的採集速度需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9a53269d67d66f267e3747a2ccd1cb12f9c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;採集速率提升&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;優化後的採集速率從 270MB/s 提升到 370MB/s&lt;/li&gt; 
   &lt;li&gt;性能提升幅度：37%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;資源利用優化&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;線程數從 16 減少到 8，減少了 50%&lt;/li&gt; 
   &lt;li&gt;在減少一半 CPU 資源的同時，仍然實現了顯著的性能提升&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正則提取的限制&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;由於正則提取需要對日誌進行全量匹配，多行採集的部分優化手段在此無法應用&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-21a28be48e32fe8cfec9acea7578426b0e9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;本地資源緊張 - 快速遷移 IngestProcessor&lt;/h4&gt; 
&lt;p&gt;儘管我們成功地在 8 線程下實現了 iLogtail 對多行日誌的採集和正則提取，但這種方法仍然面臨着一些挑戰：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高資源需求：需要佔用 8 個 CPU 核心，對機器資源造成顯著壓力。&lt;/li&gt; 
 &lt;li&gt;客户端限制：並非所有客户都有能力或意願增加機器資源。&lt;/li&gt; 
 &lt;li&gt;可擴展性問題：隨着業務壓力增加，客户端資源可能成為瓶頸。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;為了應對這些挑戰，阿里雲日誌服務推出了一個創新的解決方案：寫入處理器（IngestProcessor）。這種方法不僅有效解決了資源限制問題，還大幅提高了處理效率。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;工作原理&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;數據流：通過 iLogtail 採集的日誌數據首先經過 IngestProcessor。&lt;/li&gt; 
   &lt;li&gt;處理位置：數據處理過程在日誌服務中完成，而非客户端。&lt;/li&gt; 
   &lt;li&gt;資源優化：這種方法顯著減少了客户端資源佔用，釋放計算能力。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;注意事項&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IngestProcessor 不支持日誌聚合（將多個日誌合併為一個）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;該功能需要額外計費。詳細信息請參考阿里雲官方文檔：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-of-sls-data-processing%E3%80%82&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/sls/user-guide/overview-of-sls-data-processing。&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IngestProcessor 不僅可以解決資源限制問題，還提供了豐富的數據處理能力：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;字段提取：從原始日誌字段中通過正則表達式、Key-Value 格式、JSON 等解析方式提取出新的字段。&lt;/li&gt; 
   &lt;li&gt;擴展字段：為原始日誌添加新的字段。&lt;/li&gt; 
   &lt;li&gt;丟棄字段：刪除原始日誌的部分字段。&lt;/li&gt; 
   &lt;li&gt;數據脱敏：將原始日誌的敏感信息進行脱敏處理。&lt;/li&gt; 
   &lt;li&gt;數據過濾：丟棄原始日誌的部分數據。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bfb2569eb40392dd36fbacc794f4b9953e4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由於 IngestProcessor 使用的 SPL 語法和 iLogtail 使用的 SPL 語法一致，因此我們可以直接把 iLogtail 使用的 SPL 語句複製到 IngestProcessor 上，實現快速遷移。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9dda5fb6df1d2d8121b1f709723d26e3212.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我們在 10 個 shard 的環境下進行了詳細的性能測試。以下是使用的 SPL 語句和測試結果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;資源利用效率：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;IngestProcessor 方案將客户端 CPU 佔用從 16 核心降至 &lt;strong&gt;1 核心&lt;/strong&gt; ，減少了 &lt;strong&gt;93.75%&lt;/strong&gt; 。&lt;/li&gt; 
   &lt;li&gt;同時保持了 &lt;strong&gt;320MB/s&lt;/strong&gt; 的高採集速率，與不解析正則時的多行採集極限速率接近。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能平衡：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;雖然採集速率略有下降，但資源佔用的大幅減少使得整體效率顯著提升。&lt;/li&gt; 
   &lt;li&gt;對於資源受限的環境，這種輕微的速度降低是完全可以接受的。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可擴展性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;通過將處理負載轉移到雲端，客户端獲得了更大的擴展空間。&lt;/li&gt; 
   &lt;li&gt;這種方案為處理更大規模的日誌數據提供了可能性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7fc13de9e185916d51d2af02dd9132b1ba0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1422c85cccffacaecc712510c62b4435c4b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;實際應用價值&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本效益：客户可以通過評估硬件資源成本和 IngestProcessor 使用成本，靈活選擇適合自己的方案，降低了總體擁有成本。&lt;/li&gt; 
 &lt;li&gt;靈活部署：使客户能在資源受限的環境中部署高級日誌處理功能。&lt;/li&gt; 
 &lt;li&gt;快速遷移：與 iLogtail 使用相同的 SPL 語法，便於現有用户快速採用新方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;結論&lt;/h2&gt; 
&lt;p&gt;通過這次全面的性能測試和優化，我們可以得出以下結論：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高效性：優化後的 iLogtail 能夠在 8 線程下穩定地處理 300MB/s 的多行日誌數據並進行正則提取，展現了卓越的性能。&lt;/li&gt; 
 &lt;li&gt;靈活的計算遷移方案：在傳統的基於 iLogtail 進行日誌採集和處理的方案外，結合 iLogtail 的高效採集和 IngestProcessor 的強大處理能力，我們實現了一個既高效又靈活的日誌處理方案，能夠在 1 線程下穩定地處理 300MB/s 的多行日誌數據並進行正則提取。這種組合能夠滿足各種複雜的日誌處理需求，而不會對客户端性能造成額外負擔。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;注意事項：正則提取的性能還受到正則表達式本身複雜度的影響。如果正則表達式設計得過於複雜，或者包含大量的回溯操作，可能會導致匹配效率顯著下降，尤其是在處理大規模數據時。因此，在編寫正則表達式時，應儘量優化其結構，避免不必要的嵌套和冗餘匹配。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相關鏈接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;【1】iLogtail 啓動參數配置文檔：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Fconfigure-the-startup-parameters-of-logtail&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/sls/user-guide/configure-the-startup-parameters-of-logtail&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;【2】ESSD 雲盤官方文檔：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fecs%2Fuser-guide%2Fessds&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/ecs/user-guide/essds&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18061836</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18061836</guid>
            <pubDate>Sun, 13 Apr 2025 08:57:00 GMT</pubDate>
            <author>原創</author>
        </item>
        <item>
            <title>TrueNAS 25.04.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;TrueNAS 25.04（代號「Fangtooth」）已正式&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ftruenas%2Fcomments%2F1k0wmsf%2Ftruenas_2504_fangtooth_release_whats_new_whats%2F&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;&lt;/u&gt;，此版本將 CORE（基於 FreeBSD）和 SCALE（基於 Linux）兩大分支進行了統一 ——&amp;nbsp;徹底擁抱 Linux 作為核心基礎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d194d2668963146adb1a21b1ed4dce3650.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下載地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdownload.sys.truenas.net%2FTrueNAS-Fangtooth%2F25.04.0%2F&quot; target=&quot;_blank&quot;&gt;https://download.sys.truenas.net/TrueNAS-Fangtooth/25.04.0/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.truenas.com%2Fdownload-truenas-scale%2F&quot; target=&quot;_blank&quot;&gt;https://www.truenas.com/download-truenas-scale/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;TrueNAS（原 FreeNAS）是一套開放源代碼的網絡存儲設備（英語：NAS）服務器系統，由 iXsystems 進行開發，採用 OpenZFS 文件系統。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8e5f41e4ad75eb50d40ff3eff841bf403d1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;繼 TrueNAS 24.10 「Electric Eel」提升性能和引入 Docker 支持後，Fangtooth 帶來超過 1000 項更新，修復 150 多個 bug。儘管 iXsystems 目前僅推薦早期採用者使用，但這一版本無疑為 TrueNAS 的未來指明瞭方向。&lt;/p&gt; 
&lt;p&gt;對於從 CORE 13.x 遷移的用户，此版本保留了熟悉的 NAS 功能（如 SMB、NFS 和 iSCSI），並新增 Docker 和 LXC 支持。&lt;/p&gt; 
&lt;p&gt;TrueNAS 25.04 採用 Linux Kernel 6.12，顯著擴展了硬件兼容性，提升了系統靈活性。新增的 Fast Deduplication 功能尤其適用於全 NVMe 系統（如 H30 和 F100 型號），有效減少特定工作負載下的存儲佔用，特別是在虛擬化環境中表現出色。&lt;/p&gt; 
&lt;p&gt;此外，RAID-Z 擴展速度大幅提升，方便用户管理不斷增長的數據池。虛擬化方面，LXC 和 QEMU / KVM 通過 Incus 管理，提供替代 jails 的方案，並改進 VM 系統，同時支持 Secure Boot 和 TPM 需求（目前仍為實驗性功能）。&lt;/p&gt; 
&lt;p&gt;新版應用管理支持為新應用直接分配 IP 地址，現有應用將在 6 月 1 日前獲得此功能。&lt;/p&gt; 
&lt;p&gt;對於企業用户，TrueNAS 25.04 新增支持 GPOS STIG 配置以滿足嚴格合規需求，以及為 iSCSI 和 NFS 帶來 RDMA 支持，&lt;/p&gt; 
&lt;p&gt;此外還包括 VMware 工作負載的塊級克隆、Fibre Channel 支持、更快的 SMB 文件複製速度，以及通過 NFS 訪問快照目錄實現便捷文件恢復等功能。&lt;/p&gt; 
&lt;p&gt;TrueCommand 用户在升級前需先更新至 3.1 版本以確保兼容性。對於生產環境，TrueNAS 24.10.2.1 仍是更穩妥的選擇，而 25.04 則適合測試新功能或部署新系統的用户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345966/truenas-fangtooth-25-04-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345966/truenas-fangtooth-25-04-released</guid>
            <pubDate>Sun, 13 Apr 2025 08:51:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>IDC：2028 年中國大數據 IT 支出規模為 621.7 億美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;國際數據公司（IDC）近日發佈了 2025 年 V1 版本《全球大數據支出指南》。&lt;/p&gt; 
&lt;p&gt;IDC 最新數據顯示，2024 年全球大數據 IT 總投資規模約為 3540 億美元，2028 年預計接近 6441 億美元，五年複合增長率（CAGR）約為 16.8%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-96a02ac263c915dce3750f69f6273d87c0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;聚焦中國市場，IDC 預計，&lt;strong&gt;2028 年中國大數據 IT 支出規模為 621.7 億美元，全球佔比約 10%&lt;/strong&gt;，五年複合增長率約為 24.9%，增速位居全球第一。&lt;/p&gt; 
&lt;p&gt;IDC 認為，中國大數據市場承壓上行，整體市場規模增速有所放緩。從短期發展來看，產業數字化轉型浪潮與人工智能應用深化共同催生了企業對數據質量、數據時效性的更高標準，推動企業在數據治理體系建設和數據資產管理方面持續加碼，為大數據市場注入發展動能。內需增速放緩和激烈競爭推動企業業務出海，促進了企業對大數據平台及解決方案的需求。長期來看，隨着政府和企業預算逐步釋放和市場規模漸成體系，中國市場大數據 IT 支出增速將逐步趨於平穩。&lt;/p&gt; 
&lt;p&gt;從硬件市場的角度來看，IDC 認為中國大數據 IT 投資仍將以較大比例流入硬件市場，佔比接近 45%。&lt;/p&gt; 
&lt;p&gt;IDC 預測，大數據軟件市場在五年預測期內有較大發展潛力，2028 年軟件市場規模超 181 億美元，五年複合增長率（CAGR）約為 19.5%。&lt;/p&gt; 
&lt;p&gt;聚焦大數據服務市場，IDC 認為表示，2028 年中國市場對大數據服務支出規模近 163 億美元。面對全球服務市場增速放緩的大趨勢，中國大數據服務市場將以 1.5 倍於全球平均水平的五年複合增長率（CAGR）穩步增長。&lt;/p&gt; 
&lt;p&gt;IDC 預計，未來五年，政府、金融和軟件與信息服務行業將成為大數據技術市場支出規模較大的行業，支出合計近整個市場的五成。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345963</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345963</guid>
            <pubDate>Sun, 13 Apr 2025 08:39:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
        <item>
            <title>抖音：利用 AI 治理 Q1 封禁黑產賬號 260 萬個</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;抖音&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLLxnCtJwUp5BrU8YPr54mw&quot; target=&quot;_blank&quot;&gt;發佈&lt;/a&gt;《2025 第一季度黑產治理數據報告》指出，今年第一季度，抖音封禁水軍、欺詐和違規導流相關黑產賬號 260 萬個，並將涉嫌違法犯罪的線索上報有關部門。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告稱，在大模型基礎上，通過構建以 AI 為核心的治理體系，構建覆蓋風險感知、智能決策、閉環處置的治理體系，系統性提升 AI 在複雜場景下的風險治理應用，單個案例的處理時間達秒級，各環節運行綜合準確率達到 85% 以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以水軍治理為例，利用 AI 能力搭建智能機器人工具，實現了風險發現、預警、巡檢、研判和回掃等環節的自動化運營。這使得平台在「刷量」識別和處置上的效率大幅提升，不僅能 3 分鐘內完成自動研判，且準確率高達 95% 以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今年第一季度的試運行中，平台網絡水軍服務違規的巡檢效率提升了 10.25 倍，日均攔截違規請求 6000 萬次，封禁水軍賬號超 20 萬個。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;410&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b7cdb4b418c967372a14b0d3f00d3f4b2d9.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在欺詐治理方面，進一步完善了仿冒、購物、刷單、交友等多個場景的安全模型。2025 年至今，抖音共封禁欺詐相關賬號 140 萬個，每日下發提醒短信超 80 萬條，撥打反詐預警電話近 17 萬次。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;針對違規導流問題，在 AI 技術的深度運用下，一季度站內相關違規的舉報量下降了 73.3%，平台封禁導流違規賬號近 100 萬個，處置違規視頻內容 745 萬條。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345961</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345961</guid>
            <pubDate>Sun, 13 Apr 2025 08:27:00 GMT</pubDate>
            <author>來源: OSCHINA</author>
        </item>
    </channel>
</rss>