<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 06 May 2024 11:15:30 GMT</lastBuildDate>
        <ttl>1</ttl>
        <item>
            <title>开源日报 | 谷歌扶持鸿蒙上位；开源 Rabbit R1；Docker 加持的安卓手机；微软的焦虑和野心；海尔电器把开放平台关了</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.5.6&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要点&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/291040&quot; target=&quot;news&quot;&gt;面壁智能发布 Eurux-8x22B 开源大模型 —— 堪称「理科状元」&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;面壁智能近日发布开源大模型 Eurux-8x22B，包括 Eurux-8x22B-NCA 与 Eurux-8x22B-KTO，主打推理能力。官方介绍道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;相比口碑之作 Llama3-70B，Eurux-8x22B 发布时间更早，综合性能相当，尤其是拥有更强的推理性能 ——&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;刷新开源大模型推理性能 SOTA，堪称开源大模型中「理科状元」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Eurux-8x22B 在 LeetCode（180 道 LeetCode 编程真题）与 TheoremQA 测试上超越了 Llama3-70B，在 LeetCode 测试上超越闭源的 GPT-3.5-Turbo。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e821808c7c8fd5dd504c26678ed49faa489.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290493/arc-for-windows-1-0-ga&quot; target=&quot;news&quot;&gt;Arc Browser for Windows 1.0 正式 GA&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Arc 浏览器正式面向所有 Windows 11 用户开放（&lt;/span&gt;&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;只支持 Windows 11，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;对 Windows 10 的支持还在开发中）。该浏览器开发商 The Browser Company 于去年 12 月开始测试 Windows 客户端，目前已有超过 15 万人在使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Arc 浏览器最大的不同就是引入了 「Space」 概念（类似于 「Groups」），用户可以创建不同的 「Space」 来满足不同场景的浏览需求，每个 Space 下的网址集合可以一次性分享给他人。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3f56be7250030dbc6c2082e925059c7fa5f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qbitai.com%2F2024%2F05%2F139706.html&quot; target=&quot;_blank&quot;&gt;58 行代码把 Llama 3 扩展到 100 万上下文，任何微调版都适用&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;堂堂开源之王 Llama 3，原版上下文窗口居然只有……8k，让到嘴边的一句「真香」又咽回去了。&lt;/p&gt; 
&lt;p&gt;在 32k 起步，100k 寻常的今天，这是故意要给开源社区留做贡献的空间吗？&lt;/p&gt; 
&lt;p&gt;开源社区当然不会放过这个机会：现在只需 58 行代码，任何 Llama 3 70b 的微调版本都能自动扩展到 1048k（一百万）上下文。&lt;/p&gt; 
&lt;p&gt;代码地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fehartford%2F731e3f7079db234fa1b79a01e09859ac&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/ehartford/731e3f7079db234fa1b79a01e09859ac&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1675423275%2FOcJuSxVUc%3F&quot; target=&quot;_blank&quot;&gt;海尔电器把开放平台关了&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;海尔电器把开放平台关了。然后还让第三方智能家居的插件作者把 Github 仓库删掉，作者删了之后不满意。又做了个 fuck haier 的仓库。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-47774220dbbc1b219215cbf4178d21b69ca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;Sunbelife&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1220149481%2FOcGeDe1l0&quot; target=&quot;_blank&quot;&gt;Docker 加持的安卓手机&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;聊聊如何借助 Docker ，尝试将一台五年前的手机，构建成一个随身携带的、本地化的知识库。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;soulteary&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1727858283%2FOd0nH3bFi&quot; target=&quot;_blank&quot;&gt;开源 Rabbit R1&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;利用 Apple Shortcuts、Cloudflare Workers 和 llama 3 制作的一个人工智能助手。&lt;/p&gt; 
   &lt;p&gt;Shortcuts 提供自动语音识别（ASR）、文本到语音转换（TTS）和 HTTP 请求功能，这些基本上涵盖了我们本地需要的所有功能。你还可以将一个快捷操作绑定到 iPhone 的动作按钮，这样即使在锁屏状态下也能快速访问。&lt;/p&gt; 
   &lt;p&gt;接下来，作者简单编写了一个 Cloudflare Worker，它从快捷操作接收文本，发送到 llama 3 进行处理，然后将函数调用结果返回。&lt;/p&gt; 
   &lt;p&gt;虽然这只是一个基础示例，但其实还可以扩展，包括更复杂的函数调用和数据存储等。&lt;/p&gt; 
   &lt;p&gt;它的响应速度超过所有的 AI 穿戴设备，并且不需要额外的硬件或者支付月费。&lt;/p&gt; 
   &lt;p&gt;项目地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSh4yy%2Fpersonal-ai&quot; target=&quot;_blank&quot;&gt;https://github.com/Sh4yy/personal-ai&lt;/a&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;宝玉 xp&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5648162302%2FOcRHqDnxS&quot; target=&quot;_blank&quot;&gt;基于 Llama3 和 Groq 构建的 AI 新闻应用&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;此 AI 应用程序使用 Streamlit（一个开源 Python 框架，数据科学家和 AI/ML 工程师只需几行代码即可提供动态数据应用程）构建，步骤如下：&lt;/p&gt; 
   &lt;p&gt;1. 选择一个主题在网上搜索文章&amp;nbsp;&lt;br&gt; 2. 阅读并使用 llama3:8b 总结每篇文章&amp;nbsp;&lt;br&gt; 3. 使用 llama3:70b 撰写新闻文章&amp;nbsp;&lt;/p&gt; 
   &lt;p&gt;开源代码： git.new/groq-news&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;黄建同学&lt;/strong&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTLERI_JpqZuXlSiaSctfEg&quot; target=&quot;_blank&quot;&gt;老码农潜伏谷歌十七年总结出成功秘籍，前两条竟是...？&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;我发现我在我歌学到的技能大部分在新工作中一样好使。其中特别有用的有两条：&lt;/p&gt; 
   &lt;p&gt;要是有件事大多数人都说做不成，不要听大多数人的，该出手时就出手哇，风风火火闯九州哇。&lt;/p&gt; 
   &lt;p&gt;凡事从第一性原理出发，从本质上解决问题。&lt;/p&gt; 
   &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;老万故事会&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5712139634%2FOcR3EqG0j&quot; target=&quot;_blank&quot;&gt;谷歌这是要扶持鸿蒙上位了？&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;美国最近宣布限制中国使用 RISC-V 架构，紧接着以「不作恶」著称的谷歌便决定移除 Android 操作系统对 RISC-V 的支持，封闭了这一潜在的漏洞。RISC-V 架构被广泛认为是中国最有价值的开源指令集内核，众多芯片制造商已经开发出多种基于 RISC-V 的芯片产品，覆盖从家用电器控制到笔记本电脑等多个领域。随着 Android 系统不再支持 RISC-V，这可能会对 RISC-V 的发展造成阻碍。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;游资论股&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.com.cn%2Farticle_2853016445_aa0d937d02000yu8a.html&quot; target=&quot;_blank&quot;&gt;智谱 AI 正研发对标 Sora 的国产文生视频模型，最快年内发布&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;钛媒体 App 独家获悉，估值超 200 亿的国内 AI 大模型独角兽公司「智谱 AI」正在研发对标 OpenAI Sora 的高质量文生视频模型，预计最快年内发布。&lt;/p&gt; 
 &lt;p&gt;「文生视频目前处于一个快速发展的阶段，预计今年将是文生视频大模型的爆发期。国内公司在文生视频技术方面的客户需求非常多样，从电影拍摄到短视频、游戏制作等。智谱也将通过使用更高质量的数据和更大的参数，开发高质量的文生视频产品。」一位智谱 AI 内部人士对钛媒体 App 表示。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;钛媒体&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2763971405184008&quot; target=&quot;_blank&quot;&gt;惨，Rabbit R1 被持续扒皮：AI 风口一夜转型，NFT 充值用户欲哭无泪，动作大模型也是套壳的&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;一波未平一波又起，不光 APP 被批评套壳安卓，主推的大动作模型 LAM 依赖 OpenAI 接口，现在公司也被扒皮有猫腻——&lt;/p&gt; 
 &lt;p&gt;Rabbit 公司本来是搞元宇宙的，原地改名转投 AI？！&lt;/p&gt; 
 &lt;p&gt;这家曾经主打 NFT 游戏的创业公司，去年转型做 AI 终端（即 R1）。并在转型后疑似「删号跑路」，留下一堆曾为其付费的用户不管。&lt;/p&gt; 
 &lt;p&gt;要知道，Rabbit 前身推出的 GAMA，是一款需要预先付费购买 NFT 的游戏，其中有的 NFT 售价高达 2000+美元（折合人民币超 2 万）。&lt;/p&gt; 
 &lt;p&gt;再联想到 Rabbit 同样也需要预先支付费用，于是网友发出灵魂拷问：要是 CEO 又跑了，Rabbit R1 还会有什么价值呢？&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;strong&gt;- 量子位&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chinastarmarket.cn%2Fdetail%2F1668315&quot; target=&quot;_blank&quot;&gt;上海人工智能产业正进入集中爆发期 24 款大模型通过国家备案&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;上海市经济和信息化委员会主任张英参加 2024 上海民生访谈栏目时表示，人工智能是上海坚定不移发展的三大先导产业之一，也是培育新质生产力的重中之重。当前人工智能正进入集中爆发期。去年 11 月，上海发布了推动大模型创新发展「11 条举措」，从算力、语料、模型、测试等方面，作了全面布局。目前，上海人工智能实验室「书生」、商汤「商量」等 24 款大模型通过国家备案，居全国第二，形成了「1+4」的通用大模型格局（1 款开源、2 款商用、2 款在研），体现了在行业内的深化应用。今年通用大模型正在逐步收敛，一大批聚焦制造、金融、政务等垂类模型正加快孕育。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;-&amp;nbsp;&lt;strong&gt;科创板日报&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb&quot; target=&quot;_blank&quot;&gt;GreptimeTeam/greptimedb&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bbbadbafcdc0c3567bc2a534ff918ebdf4b.png&quot; width=&quot;319&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FGreptimeTeam%2Fgreptimedb&quot; target=&quot;_blank&quot;&gt;https://github.com/GreptimeTeam/greptimedb&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GreptimeDB 是 Rust 实现的开源时序数据库，尤其关注可扩展性、分析能力和效率，专为云时代的基础设施而设计。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/HuggingFace/blog/11090508&quot; target=&quot;_blank&quot;&gt;视觉语言模型详解&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;视觉语言模型可以同时从图像和文本中学习，因此可用于视觉问答、图像描述等多种任务。本文，我们将带大家一览视觉语言模型领域：作个概述、了解其工作原理、搞清楚如何找到真命天 「模」、如何对其进行推理以及如何使用最新版的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;trl&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;轻松对其进行微调。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;VLM 能力&quot; height=&quot;281&quot; src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/jK8WsS.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;div&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;事件点评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel&quot; target=&quot;_blank&quot;&gt;谷歌删除 Android 通用内核 (ACK) 对 RISC-V 架构的支持&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;谷歌 Android 系统上游 ——AOSP 最近&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fq%2Ftopic%3A%2522ack_riscv64_turndown%2522&quot; target=&quot;_blank&quot;&gt;合并&lt;/a&gt;的一系列补丁删除了 Android 通用内核对 RISC-V 架构的支持。Android 通用内核也就是 Common Android Kernel，也被称为 AOSP 通用内核或 ACK。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;由于 ACK 删除了对 RISC-V 的支持，想要立即编译 Android RISC-V 版本的公司和机构，&lt;/span&gt;&lt;strong&gt;需要创建和维护自己的 Linux 分支&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，以便于进一步整合 RISC-V 补丁。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b5bb533fc41afeb38d23d6547429497e63.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;RISC-V 作为一种开放标准，尽管得到了国际支持和合作，但在智能手机应用方面尚未实现。谷歌的这一决策可能会对 RISC-V 架构在智能手机领域的应用产生影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;且&amp;nbsp;许多芯片制造商和处理器设计师已经在 RISC-V 架构的未来发展上进行了投资。例如，高通正在开发用于 Wear OS 的 RISC-V 芯片。谷歌的这一决策可能会对这些芯片制造商产生影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，RISC-V 架构被视为对 ARM 架构的一种竞争。谷歌的这一决策也可能会影响 RISC-V 在 SSD 控制器市场中的竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai&quot; target=&quot;_blank&quot;&gt;微软投资 OpenAI 可能是出于对谷歌 AI 进展的担忧&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;微软首席技术官凯文 - 斯科特（Kevin Scott）、首席执行官萨蒂亚 - 纳德拉（Satya Nadella）和联合创始人比尔 - 盖茨（Bill Gates）之间的一封题为 「Thoughts on OpenAI」 的内部&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTechEmails%2Fstatus%2F1787176471146156193%2Fphoto%2F4&quot; target=&quot;_blank&quot;&gt;邮件&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;，揭示了在微软披露合作关系之前的几个月里，围绕投资机会进行的一些高层讨论。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;Scott 在 2019 年 6 月 12 日写给 Nadella 和 Gates 的电子邮件中写道：「在机器学习规模方面，我们落后竞争对手多年」。并详细描述了微软工程师是如何花了六个月的时间来复制谷歌的 BERT 语言模型并对其进行训练的，「因为我们的基础设施无法胜任这项任务」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a617e0611f25b43710fd269327334c67b3e.png&quot; width=&quot;237&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软对 OpenAI 的投资反映了其对自身在人工智能领域相对落后的认识，以及对技术领先的追求。这一投资决策可能与微软对谷歌在人工智能技术上的领先感到的焦虑有关，突显了市场主导地位的争夺。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软对 OpenAI 的投资，以及谷歌在人工智能领域的领先地位，突显了人工智能技术在当今科技行业中的战略重要性。大型科技公司之间的合作和竞争，以及它们如何平衡这些关系，是这个事件背后的一个重要议题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，美国联邦贸易委员会对生成式 AI 市场中的主要参与者进行调查，也显示了监管机构对市场竞争和投资合作的关注。这一事件还映射出人工智能技术对未来社会和商业环境可能产生的深远影响。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290662&quot; target=&quot;_blank&quot;&gt;90 后程序员开发视频搬运软件、不到一年获利超 700 万，结局很刑！&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;央视《今日说法》栏目近期报道了一名 90 后程序员通过开发非法视频搬运软件在不到一年的时间里获利超 700 万，最终获刑的案例。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;国内某知名短视频平台报警称，有人在网络上售卖一款非法软件，使用软件的人可以绕过他们平台的审核机制，直接窃取他人的作品进行发布。浙江台州警方调查发现，在这背后是一条违法犯罪的产业链条，&lt;strong&gt;犯罪团伙的上游开发制作非法软件，通过更改短视频平台的代码，逃避平台监管。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;img height=&quot;288&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1145c8cd8feb9548ccd491137262165b6c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此案例强调了保护知识产权的重要性，尤其是在数字化和网络化日益普及的今天。虽然创业是鼓励的，但选择合法合规的项目至关重要；强调了个人在网络安全中的道德责任，即使在看似无害的行为背后也可能隐藏着严重的法律风险。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，随着技术的发展，法律可能跟不上技术应用的速度，导致法律监管的缺失。同时也反映出网络监管和平台安全的重要性，平台需要加强技术措施以防止此类非法行为的发生。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240506A01WTQ00&quot; target=&quot;_blank&quot;&gt;OpenAI 的 AI 搜索也要来了，但我们需要这么多 AI 搜索么&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#303030; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;虽然 AI 搜索技术非常强大和有价值，但从用户体验、习惯和企业资源配置的角度出发，将其作为增强现有产品的一个特性，而非开发为独立的搜索产品，可能是更为合理的方向。这样不仅能更好地满足用户需求，对企业来说也是更好地选择。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#303030; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;看起来，AI 搜索离生成式人工智能时代的 Killer App 距离尚远，它甚至可能并不是一个理想的生意。我们并不需要那么多的 AI 搜索产品，但我们需要更多的 AI 搜索 Feature。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;硅星人 Pro&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn788037925&quot; target=&quot;_blank&quot;&gt;微软的焦虑和野心，再也藏不住了&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;虽然 AI 初创公司当前仍然处于入不敷出、苦苦探索盈利模式的阶段，但 AI 的热潮已经让提供算力和数据的 AI 基础设施供应商赚得盆满钵满。观察微软 AI 投资的两条主线，这个领先者的野心也昭然若揭：一方面通过外部投资或直接「兼并」AI 初创公司，保持自身在生成式 AI 技术的优势；另一方面，通过大力布局 AI 基础设施，发力云计算市场，打造更强劲的业绩增长曲线。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;/span&gt;&lt;strong&gt;创业资本汇&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1798183798926466025%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;民生证券胡又文：AI 是下一个时代的技术浪潮，且仍处于早期阶段&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 是下一个时代的技术浪潮，甚至可能是人类历史上最大的科技革命。从 AlphaGo 的突破到硅谷的最新进展，AI 技术的快速发展正不断推动社会进步。尽管存在成本高昂和潜在的政治影响等挑战，AI 在自动驾驶、语言模型等领域的应用已经展现出巨大的变革潜力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;-&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;财联社&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FF7a5NbHdpaXeglUJlcrChw&quot; target=&quot;_blank&quot;&gt;中国码农的「35 岁魔咒」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：现在新人可不便宜，干几年就跟老人工资差不多了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：把老板开除不就好了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：所以严格落实 8 小时工作制才能拯救 35 岁危机&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：项目中接触了几位外企的一线技术人员，老外的一位项目带头人 60 好几了，依然在 Coding。这就是差距。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：如果不加班，是不是年轻人和中年人的人力性价比就差不多了&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：你不会永远 18 岁，但永远有人 18 岁&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：又不是光程序员，IT 行业都是这样&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：年轻人有冲劲，让他们先冲，搞出问题，我们这些老灯再出来擦屁股，年轻人得到了锻炼机会，老灯们保住了饭碗，一举两得，多好&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：哈，出生率低的环境中，又想要更年轻的劳动力，本身就是冲突的。再者工作需要加班才能完成的，要么是能力不行，要么是公司不行&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：35 上班嫌老，60 退休嫌早&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FzNEYq-yR1HyMmsQ9KpKgEA&quot; target=&quot;_blank&quot;&gt;微软前工程师称 Windows 11 性能差得笑死人，难怪市场份额持续下降&lt;/a&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：微软前工程师称 Windows 11 性能差得笑死人，难怪市场份额持续下降，所以他现在是微软前工程师了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：微软唯一的问题是没品位，完全没有品位可言...&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：资源管理经常卡死，打开的软件经常卡住&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：linux 造不出这种图形界面&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：利用 Win11 让更多用户使用 Win10&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：这还菜单我也觉得离谱，我最开始还以为是我鼠标的问题&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：微软的重点在云计算和人工智能了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：win10 也好，11 也罢。都有一个让我不理解的地方，为啥开机到进桌面的时间越用越长？按了开机键后，硬盘灯几乎一直常亮，感觉电脑费了吃奶的劲，好不容易才进了桌面。就算进了桌面，硬盘还要疯狂工作一段时间才歇下来。至于在开机这个过程要做这么多事吗？ 我用的一般 ssd。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：windows 一个版本好, 一个版本烂的定律还没有打破&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：现在新机一水预装 win11, 不理解 win10 的份额是怎么增加的？难道有大批的系统在降级么？感觉不过是统计的问题。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSnTLIMG13clwVCFHfaKDxQ&quot; target=&quot;_blank&quot;&gt;90 后程序员辞职搞灰产：开发视频搬运软件、不到一年获利超 700 万，结局很刑！&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：鲁班七号，没有技术含量但是解救了很多人 1.0 替换待发布的缓存视频，最后更新诸神黄昏版本是替换视频模板，当时是直播切片的时代，一台手机一天几万流水（矩阵利润自己想吧） 只有懂得人才知道鲁班七号产生的价值，我当时卖出去的卡密让很多人翻了身喘了口气&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：这算是自首吗&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：厉害的是他的销售，一年卖 20 万份。有这销售能力干啥不好。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：他窃取的视频是不知道多少原创作者的心血，没有所谓收入，不过是抢夺罢了。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：这都能赚 700 多万？这技术我真心不觉得难，佩服的是这哥们的销售技术&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：对，很多人没意识到，获客比代码难多了....&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：收入和付出不成正比，就会滋生出一些歹念。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：正确的操作方式是，入职一家公司，月薪 5 万，工作十分轻松，老板喜欢看短视频，他就把自己开发的下载软件「免费」分享给老板。工作半年后公司破产了，但 30 万工资已经结清。你说他是否需要承担责任？&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：替换已审核通过视频，相当于数据库数据被篡改，说明视频平台暴露了相关接口，视频平台漏洞也不小。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291051</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291051</guid>
            <pubDate>Mon, 06 May 2024 10:11:02 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>面壁智能发布 Eurux-8x22B 开源大模型 —— 堪称「理科状元」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;面壁智能近日发布开源大模型 Eurux-8x22B，包括 Eurux-8x22B-NCA 与 Eurux-8x22B-KTO，主打推理能力。&lt;/p&gt; 
&lt;p&gt;官方介绍道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相比口碑之作 Llama3-70B，Eurux-8x22B 发布时间更早，综合性能相当，尤其是拥有更强的推理性能——&lt;strong&gt;刷新开源大模型推理性能 SOTA，堪称开源大模型中「理科状元」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Eurux-8x22B 在 LeetCode（180 道 LeetCode 编程真题）与 TheoremQA 测试上超越了 Llama3-70B，在 LeetCode 测试上超越闭源的 GPT-3.5-Turbo。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e821808c7c8fd5dd504c26678ed49faa489.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e902f31df9be97cefd4dfd235955106ada6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Eurux-8x22B 模型激活参数 39B，支持 64k 上下文，是由 Mixtral-8x22B 模型对齐而来，在 UltraInteract 对齐数据集上训练而成。&lt;/p&gt; 
&lt;p&gt;Eurux-8x22B 模型+对齐数据集均已开源：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Eurux-8x22B 模型 GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenBMB%2FEurus&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;https://github.com/OpenBMB/Eurus&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Eurux-8x22B 模型 HuggingFace 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fopenbmb%2FEurux-8x22b-nca&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;https://huggingface.co/openbmb/Eurux-8x22b-nca&lt;/em&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291040</guid>
            <pubDate>Mon, 06 May 2024 09:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>视觉语言模型详解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;p&gt;视觉语言模型可以同时从图像和文本中学习，因此可用于视觉问答、图像描述等多种任务。本文，我们将带大家一览视觉语言模型领域: 作个概述、了解其工作原理、搞清楚如何找到真命天「模」、如何对其进行推理以及如何使用最新版的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;trl&lt;/a&gt; 轻松对其进行微调。&lt;/p&gt; 
&lt;h2&gt;什么是视觉语言模型？&lt;/h2&gt; 
&lt;p&gt;视觉语言模型是可以同时从图像和文本中学习的多模态模型，其属于生成模型，输入为图像和文本，输出为文本。大视觉语言模型具有良好的零样本能力，泛化能力良好，并且可以处理包括文档、网页等在内的多种类型的图像。其拥有广泛的应用，包括基于图像的聊天、根据指令的图像识别、视觉问答、文档理解、图像描述等。一些视觉语言模型还可以捕获图像中的空间信息，当提示要求其检测或分割特定目标时，这些模型可以输出边界框或分割掩模，有些模型还可以定位不同的目标或回答其相对或绝对位置相关的问题。现有的大视觉语言模型在训练数据、图像编码方式等方面采用的方法很多样，因而其能力差异也很大。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/jK8WsS.png&quot; alt=&quot;VLM 能力&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;开源视觉语言模型概述&lt;/h2&gt; 
&lt;p&gt;Hugging Face Hub 上有很多开放视觉语言模型，下表列出了其中一些佼佼者。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;其中有基础模型，也有可用于对话场景的针对聊天微调的模型。&lt;/li&gt; 
 &lt;li&gt;其中一些模型具有「接地 (grounding )」功能，因此能够减少模型幻觉。&lt;/li&gt; 
 &lt;li&gt;除非另有说明，所有模型的训练语言皆为英语。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;可否商用&lt;/th&gt; 
   &lt;th&gt;模型尺寸&lt;/th&gt; 
   &lt;th&gt;图像分辨率&lt;/th&gt; 
   &lt;th&gt;其它能力&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fllava-hf%2Fllava-v1.6-34b-hf&quot; target=&quot;_blank&quot;&gt;LLaVA 1.6 (Hermes 34B)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;34B&lt;/td&gt; 
   &lt;td&gt;672x672&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2Fdeepseek-vl-7b-base&quot; target=&quot;_blank&quot;&gt;deepseek-vl-7b-base&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;384x384&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2Fdeepseek-vl-7b-chat&quot; target=&quot;_blank&quot;&gt;DeepSeek-VL-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;384x384&lt;/td&gt; 
   &lt;td&gt;聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvikhyatk%2Fmoondream2&quot; target=&quot;_blank&quot;&gt;moondream2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;~2B&lt;/td&gt; 
   &lt;td&gt;378x378&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FTHUDM%2Fcogvlm-base-490-hf&quot; target=&quot;_blank&quot;&gt;CogVLM-base&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;17B&lt;/td&gt; 
   &lt;td&gt;490x490&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FTHUDM%2Fcogvlm-chat-hf&quot; target=&quot;_blank&quot;&gt;CogVLM-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;17B&lt;/td&gt; 
   &lt;td&gt;490x490&lt;/td&gt; 
   &lt;td&gt;接地、聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fadept%2Ffuyu-8b&quot; target=&quot;_blank&quot;&gt;Fuyu-8B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;300x300&lt;/td&gt; 
   &lt;td&gt;图像中的文本检测&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmicrosoft%2Fkosmos-2-patch14-224&quot; target=&quot;_blank&quot;&gt;KOSMOS-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;~2B&lt;/td&gt; 
   &lt;td&gt;224x224&lt;/td&gt; 
   &lt;td&gt;接地、零样本目标检测&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen-VL&quot; target=&quot;_blank&quot;&gt;Qwen-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;零样本目标检测&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FQwen%2FQwen-VL-Chat&quot; target=&quot;_blank&quot;&gt;Qwen-VL-Chat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;聊天&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2F01-ai%2FYi-VL-34B&quot; target=&quot;_blank&quot;&gt;Yi-VL-34B&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;34B&lt;/td&gt; 
   &lt;td&gt;448x448&lt;/td&gt; 
   &lt;td&gt;双语 (英文、中文)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;寻找合适的视觉语言模型&lt;/h2&gt; 
&lt;p&gt;有多种途径可帮助你选择最适合自己的模型。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FWildVision%2Fvision-arena&quot; target=&quot;_blank&quot;&gt;视觉竞技场 (Vision Arena)&lt;/a&gt; 是一个完全基于模型输出进行匿名投票的排行榜，其排名会不断刷新。在该竞技场上，用户输入图像和提示，会有两个匿名的不同的模型为其生成输出，然后用户可以基于他们的喜好选择一个输出。这种方式生成的排名完全是基于人类的喜好的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/ybVPde.png&quot; alt=&quot;视觉竞技场 (Vision Arena)&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fopencompass%2Fopen_vlm_leaderboard&quot; target=&quot;_blank&quot;&gt;开放 VLM 排行榜&lt;/a&gt; 提供了另一种选择，各种视觉语言模型按照所有指标的平均分进行排名。你还可以按照模型尺寸、私有或开源许可证来筛选模型，并按照自己选定的指标进行排名。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/2dOyhv.png&quot; alt=&quot;开放 VLM 排行榜&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopen-compass%2FVLMEvalKit&quot; target=&quot;_blank&quot;&gt;VLMEvalKit&lt;/a&gt; 是一个工具包，用于在视觉语言模型上运行基准测试，开放 VLM 排行榜就是基于该工具包的。&lt;/p&gt; 
&lt;p&gt;还有一个评估套件是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FEvolvingLMMs-Lab%2Flmms-eval&quot; target=&quot;_blank&quot;&gt;LMMS-Eval&lt;/a&gt;，其提供了一个标准命令行界面，你可以使用 Hugging Face Hub 上托管的数据集来对选定的 Hugging Face 模型进行评估，如下所示:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch --num_processes=8 -m lmms_eval --model llava --model_args pretrained=&quot;liuhaotian/llava-v1.5-7b&quot; --tasks mme,mmbench_en --batch_size 1 --log_samples --log_samples_suffix llava_v1.5_mme_mmbenchen --output_path ./logs/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;视觉竞技场和开放 VLM 排行榜都仅限于提交给它们的模型，且需要更新才能添加新模型。如果你想查找其他模型，可以在 &lt;code&gt;image-text-to-text&lt;/code&gt; 任务下浏览 hub 中的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmodels%3Fpipeline_tag%3Dimage-text-to-text%26sort%3Dtrending&quot; target=&quot;_blank&quot;&gt;模型&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;在排行榜中，你会看到各种不同的用于评估视觉语言模型的基准，下面我们选择其中几个介绍一下。&lt;/p&gt; 
&lt;h3&gt;MMMU&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FMMMU%2FMMMU&quot; target=&quot;_blank&quot;&gt;针对专家型 AGI 的海量、多学科、多模态理解与推理基准 (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI，MMMU)&lt;/a&gt; 是评估视觉语言模型的最全面的基准。它包含 11.5K 个多模态问题，这些问题需要大学水平的学科知识以及跨学科 (如艺术和工程) 推理能力。&lt;/p&gt; 
&lt;h3&gt;MMBench&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Flmms-lab%2FMMBench&quot; target=&quot;_blank&quot;&gt;MMBench&lt;/a&gt; 由涵盖超过 20 种不同技能的 3000 道单选题组成，包括 OCR、目标定位等。论文还介绍了一种名为 &lt;code&gt;CircularEval&lt;/code&gt; 的评估策略，其每轮都会对问题的选项进行不同的组合及洗牌，并期望模型每轮都能给出正确答案。&lt;/p&gt; 
&lt;p&gt;另外，针对不同的应用领域还有其他更有针对性的基准，如 MathVista (视觉数学推理) 、AI2D (图表理解) 、ScienceQA (科学问答) 以及 OCRBench (文档理解)。&lt;/p&gt; 
&lt;h2&gt;技术细节&lt;/h2&gt; 
&lt;p&gt;对视觉语言模型进行预训练的方法很多。主要技巧是统一图像和文本表征以将其输入给文本解码器用于文本生成。最常见且表现最好的模型通常由图像编码器、用于对齐图像和文本表征的嵌入投影子模型 (通常是一个稠密神经网络) 以及文本解码器按序堆叠而成。至于训练部分，不同的模型采用的方法也各不相同。&lt;/p&gt; 
&lt;p&gt;例如，LLaVA 由 CLIP 图像编码器、多模态投影子模型和 Vicuna 文本解码器组合而成。作者将包含图像和描述文本的数据集输入 GPT-4，让其描述文本和图像生成相关的问题。作者冻结了图像编码器和文本解码器，仅通过给模型馈送图像与问题并将模型输出与描述文本进行比较来训练多模态投影子模型，从而达到对齐图像和文本特征的目的。在对投影子模型预训练之后，作者把图像编码器继续保持在冻结状态，解冻文本解码器，然后继续对解码器和投影子模型进行训练。这种预训练加微调的方法是训练视觉语言模型最常见的做法。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/cETuLf.png&quot; alt=&quot;视觉语言模型典型结构&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/2kDGpc.png&quot; alt=&quot;将投影子模型输出与文本嵌入相串接&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再举一个 KOSMOS-2 的例子，作者选择了端到端地对模型进行完全训练的方法，这种方法与 LLaVA 式的预训练方法相比，计算上昂贵不少。预训练完成后，作者还要用纯语言指令对模型进行微调以对齐。还有一种做法，Fuyu-8B 甚至都没有图像编码器，直接把图像块馈送到投影子模型，然后将其输出与文本序列直接串接送给自回归解码器。&lt;/p&gt; 
&lt;p&gt;大多数时候，我们不需要预训练视觉语言模型，仅需使用现有的模型进行推理，抑或是根据自己的场景对其进行微调。下面，我们介绍如何在 &lt;code&gt;transformers&lt;/code&gt; 中使用这些模型，以及如何使用 &lt;code&gt;SFTTrainer&lt;/code&gt; 对它们进行微调。&lt;/p&gt; 
&lt;h2&gt;在 transformers 中使用视觉语言模型&lt;/h2&gt; 
&lt;p&gt;你可以使用 &lt;code&gt;LlavaNext&lt;/code&gt; 模型对 Llava 进行推理，如下所示。&lt;/p&gt; 
&lt;p&gt;首先，我们初始化模型和数据处理器。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration
import torch

device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
processor = LlavaNextProcessor.from_pretrained(&quot;llava-hf/llava-v1.6-mistral-7b-hf&quot;)
model = LlavaNextForConditionalGeneration.from_pretrained(
    &quot;llava-hf/llava-v1.6-mistral-7b-hf&quot;,
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True
)
model.to(device)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，将图像和文本提示传给数据处理器，然后将处理后的输入传给 &lt;code&gt;generate&lt;/code&gt; 方法。请注意，每个模型都有自己的提示模板，请务必根据模型选用正确的模板，以避免性能下降。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from PIL import Image
import requests

url = &quot;https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true&quot;
image = Image.open(requests.get(url, stream=True).raw)
prompt = &quot;[INST] &amp;lt;img src=&quot;&quot;&amp;gt;\nWhat is shown in this image? [/INST]&quot;

inputs = processor(prompt, image, return_tensors=&quot;pt&quot;).to(device)
output = model.generate(**inputs, max_new_tokens=100)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;调用 &lt;code&gt;decode&lt;/code&gt; 对输出词元进行解码。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;print(processor.decode(output[0], skip_special_tokens=True))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;使用 TRL 微调视觉语言模型&lt;/h2&gt; 
&lt;p&gt;我们很高兴地宣布，作为一个实验性功能，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl&quot; target=&quot;_blank&quot;&gt;TRL&lt;/a&gt; 的 &lt;code&gt;SFTTrainer&lt;/code&gt; 现已支持视觉语言模型！这里，我们给出了一个例子，以展示如何在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2FHuggingface.co%2Fdatasets%2FHuggingFaceH4%2Fllava-instruct-mix-vsft&quot; target=&quot;_blank&quot;&gt;llava-instruct&lt;/a&gt; 数据集上进行 SFT，该数据集包含 260k 个图像对话对。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;llava-instruct&lt;/code&gt; 数据集将用户与助理之间的交互组织成消息序列的格式，且每个消息序列皆与用户问题所指的图像配对。&lt;/p&gt; 
&lt;p&gt;要用上 VLM 训练的功能，你必须使用 &lt;code&gt;pip install -U trl&lt;/code&gt; 安装最新版本的 TRL。你可在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftrl%2Fblob%2Fmain%2Fexamples%2Fscripts%2Fvsft_llava.py&quot; target=&quot;_blank&quot;&gt;此处&lt;/a&gt; 找到完整的示例脚本。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from trl.commands.cli_utils import SftScriptArguments, TrlParser

parser = TrlParser((SftScriptArguments, TrainingArguments))
args, training_args = parser.parse_args_and_config()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;初始化聊天模板以进行指令微调。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;LLAVA_CHAT_TEMPLATE = &quot;&quot;&quot;A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user&#39;s questions. {% for message in messages %}{% if message[&#39;role&#39;] == &#39;user&#39; %}USER: {% else %}ASSISTANT: {% endif %}{% for item in message[&#39;content&#39;] %}{% if item[&#39;type&#39;] == &#39;text&#39; %}{{ item[&#39;text&#39;] }}{% elif item[&#39;type&#39;] == &#39;image&#39; %}&amp;lt;img src=&quot;&quot;&amp;gt;{% endif %}{% endfor %}{% if message[&#39;role&#39;] == &#39;user&#39; %} {% else %}{{eos_token}}{% endif %}{% endfor %}&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，初始化模型和分词器。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoTokenizer, AutoProcessor, TrainingArguments, LlavaForConditionalGeneration
import torch

model_id = &quot;llava-hf/llava-1.5-7b-hf&quot;
tokenizer = AutoTokenizer.from_pretrained(model_id)
tokenizer.chat_template = LLAVA_CHAT_TEMPLATE
processor = AutoProcessor.from_pretrained(model_id)
processor.tokenizer = tokenizer

model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;建一个数据整理器来组合文本和图像对。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;class LLavaDataCollator:
    def __init__(self, processor):
        self.processor = processor

    def __call__(self, examples):
        texts = []
        images = []
        for example in examples:
            messages = example[&quot;messages&quot;]
            text = self.processor.tokenizer.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=False
            )
            texts.append(text)
            images.append(example[&quot;images&quot;][0])

        batch = self.processor(texts, images, return_tensors=&quot;pt&quot;, padding=True)

        labels = batch[&quot;input_ids&quot;].clone()
        if self.processor.tokenizer.pad_token_id is not None:
            labels[labels == self.processor.tokenizer.pad_token_id] = -100
        batch[&quot;labels&quot;] = labels

        return batch

data_collator = LLavaDataCollator(processor)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;加载数据集。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from datasets import load_dataset

raw_datasets = load_dataset(&quot;HuggingFaceH4/llava-instruct-mix-vsft&quot;)
train_dataset = raw_datasets[&quot;train&quot;]
eval_dataset = raw_datasets[&quot;test&quot;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;初始化 &lt;code&gt;SFTTrainer&lt;/code&gt; ，传入模型、数据子集、PEFT 配置以及数据整理器，然后调用 &lt;code&gt;train()&lt;/code&gt; 。要将最终 checkpoint 推送到 Hub，需调用 &lt;code&gt;push_to_hub()&lt;/code&gt; 。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from trl import SFTTrainer

trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    dataset_text_field=&quot;text&quot;, # need a dummy field
    tokenizer=tokenizer,
    data_collator=data_collator,
    dataset_kwargs={&quot;skip_prepare_dataset&quot;: True},
)

trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;保存模型并推送到 Hugging Face Hub。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;trainer.save_model(training_args.output_dir)
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你可在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FHuggingFaceH4%2Fvsft-llava-1.5-7b-hf-trl&quot; target=&quot;_blank&quot;&gt;此处&lt;/a&gt; 找到训得的模型。你也可以通过下面的页面试玩一下我们训得的模型⬇️。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://img-s1.andfun.cn/devrel/posts/2024/04/29/mH0Bny.png&quot; alt=&quot;https://HuggingFaceH4-vlm-playground.hf.space&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;致谢&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们感谢 Pedro Cuenca、Lewis Tunstall、Kashif Rasul 和 Omar Sanseviero 对本文的评论和建议。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&amp;gt; 英文原文: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fvlms&quot; target=&quot;_blank&quot;&gt;https://hf.co/blog/vlms&lt;/a&gt; &amp;gt; 原文作者: Merve Noyan，Edward Beeching &amp;gt; 译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/HuggingFace/blog/11090508</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/11090508</guid>
            <pubDate>Mon, 06 May 2024 08:42:03 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Java 17 是最常用的 Java LTS 版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;New Relic 最新发布了一份「&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewrelic.com%2Fresources%2Freport%2F2024-state-of-the-java-ecosystem&quot; target=&quot;_blank&quot;&gt;2024 年 Java 生态系统状况报告&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;」，旨在提供有关当今 Java 生态系统状态的背景和见解。该报告基于每月向 New Relic 报告的数十万应用程序的数据，对生产中使用最多的版本、最受欢迎的 JDK 供应商、Java 应用程序中计算和内存的使用等多方面进行了调研分析。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告最先分析了「生产中最常用的 Java 版本」，指出在 Java 21 (2023 年 9 月) 发布后的六个月里，New Relic 监控的应用程序中有 1.4% 使用了该版本。相较而言，在 Java 17 (2021 年 9 月) 推出后的六个月里，只有 0.37% 的应用程序使用了 Java 17。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Java 17 的采用率远远超过了 Java 11 推出时的情况。到 2023 年，大约十分之一 (9%) 的应用程序在生产中使用 Java 17，截至目前已有 35% 的应用程序正在使用 Java 17，一年内增长率接近 300%。而 Java 11 用了数年时间才接近这一水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;从 2018 年 9 月起， Java 17 已取代 Java 11，成为最常用的 LTS 版本。此外，只有不到 2% 的应用程序使用的是 Java 非 LTS 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;319&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-812dcfc5be91b26c7a64836b3cc653a5fd1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在最受欢迎的 JDK 供应商方面，Oracle 的 JDK 在 2020 年大约占据了 75% 的市场份额；但占比逐年下降 —— 2022 年 34%、2023 年滑落到 29%，以及现在降至 21%。2023 年，亚马逊的使用率增至 31%（2020 年为 2.2%，2022 年为 22%），但 2024 年降至 18%，同比下降 43%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年的后起之秀是 Eclipse Adoptium，其采用率同比增长了 50%，从 12% 上升到 18%。由于 Eclipse Adoptium 由社区管理，因此该 JDK 的更新频率往往高于 Oracle 和 Amazon JDK。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;345&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d8810959abf3165698cec20353fc5177e8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#4e4242&quot;&gt;其他一些发现还包括：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用四个或更少核心运行的应用程序同比增长 18%，其中 68% 的应用程序使用 1-4 个核心。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Log4j 是 Java 应用程序中最流行的日志框架，有 76.4% 的 Java&amp;nbsp;应用程序使用；其次是 JBoss Logging (61%) 和 Logback (52%)。大多数 (83%) Java 开发人员依赖 SLF4j。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Bouncy Castle 是 Java 应用程序中最流行的加密库，占有 17.1% 的份额。其次是&amp;nbsp;16% 使用 Spring Security，6% 使用 Jasypt。虽然只有 0.09% 的开发人员使用 Amazon Corretto Crypto Provider (ACCP) 库，但 New Relic&amp;nbsp;预计在不久的将来会有更多应用程序使用它，因为公司和开发人员希望整合供应商，而且它通常可以提供更好的性能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Oracle 数据库是 Java 应用程序中最流行的数据库系统，使用率为 17.3%。 PostgreSQL 位居第二，占 14.4%。MySQL 排名第三，有 13% 的 Java 应用程序使用它。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;345&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8b98dc6406e7255f7114ad22c7da1808c07.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:left&quot;&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;hr&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;该报告已上传至开源中国 APP，详情可至&lt;strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;&lt;span style=&quot;background-color:#f39c12&quot;&gt;「开源中国 APP - 报告模块」&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;下载&lt;/span&gt;查看。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;APP 下载地址：&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;https://www.oschina.net/app&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291030/2024-state-of-the-java-ecosystem</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291030/2024-state-of-the-java-ecosystem</guid>
            <pubDate>Mon, 06 May 2024 08:31:03 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>《2024 年中国企业级 SaaS 行业研究报告》发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;近日，艾瑞咨询发布《2024 年中国企业级 SaaS 行业研究报告》，主要内容包括中国企业级 SaaS 行业的市场趋势、企业实践、行业动态、资本动向、投融资情况、上市情况以及企业应用实践等多个方面的分析和预测。&lt;/p&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;297&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0506/162722_gs6k_4700705.png&quot; width=&quot;360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;以下是核心内容的概要：&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;市场趋势&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;2023 年中国企业级 SaaS 市场规模达到 888 亿元，同比增长 13.0%。&lt;/li&gt; 
       &lt;li&gt;预计未来三年市场增速将稳定在 15%-20%，复合增速约 15%。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;企业实践&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;SaaS 应用在企业中的渗透率不断提升。&lt;/li&gt; 
       &lt;li&gt;大型企业倾向于定制集成，中型企业成为平台生态模式的主流应用群体。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SaaS 行业动态&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;行业热点包括与 AIGC 的结合、集成可行性讨论，以及 SaaS 厂商出海探索。&lt;/li&gt; 
       &lt;li&gt;SaaS 厂商底层逻辑从流量互换向产品融合转变，集成与被集成选择更灵活。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;资本动向&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;投融资笔数逐步下滑，融资轮次后移，2023 年天使轮、A 轮占比回升。&lt;/li&gt; 
       &lt;li&gt;行业可能进入由行业垂直型厂商领衔的新一轮成长周期。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;投融资情况&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;投资热度下滑，SaaS 创业公司面临更大压力，自我造血能力变得重要。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;上市情况&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;香港上市门槛对高成长性企业友好，成为 SaaS 厂商首选。&lt;/li&gt; 
       &lt;li&gt;内地和香港上市公司的营收增长率和毛利率指标有所下跌，但毛利率维持健康水平。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;企业应用实践&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;大型企业倾向定制集成，中型企业更倾向于平台生态模式。&lt;/li&gt; 
       &lt;li&gt;海外企业 SaaS 偏好差异显著，发达国家青睐专业功能出色的产品，发展中国家与出海企业讲究性价比。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;SaaS 厂商&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;腾讯 TAPD 和 Quick Creator 作为典型 SaaS 厂商案例被提及，展示了它们的产品特点和市场策略。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;法律声明&lt;/strong&gt;：&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;报告版权归艾瑞咨询所有，未经授权不得复制或传播。&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ol&gt; 
    &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;报告还包含了中国企业级 SaaS 市场规模的预测图表、SaaS 产业图谱、SaaS 集成与生态的分析、SaaS 出海现状和策略、投融资情况的详细数据和图表，以及对 SaaS 投资标的判断依据的讨论。&lt;/p&gt; 
    &lt;hr&gt; 
    &lt;p&gt;目前，该报告已上传至开源中国 APP，详情可至&lt;strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;&lt;span style=&quot;background-color:#f39c12&quot;&gt;「开源中国 APP - 报告模块」&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#333333&quot;&gt;下载&lt;/span&gt;查看。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;APP 下载地址：&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;https://www.oschina.net/app&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ab7bb9f45ecaae87f7a862ea446ae1dacf.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291029</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291029</guid>
            <pubDate>Mon, 06 May 2024 08:29:03 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Zadig 免费试用全面开放：提升工作效率，享受流畅体验</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;div style=&quot;text-align:center&quot;&gt; 
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bca623bfd697efe68f9741066044e920c24.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  Zadig 自开源以来，已在国内获得广泛认可，超过 3000 家企业正在使用。企业安装总量破 3 万次，每日活跃用户近 15 万，全球累计部署应用数量超过 50 万。随着 V2.0 新开源架构的发布，Zadig 的商业版也受到了众多企业的关注和喜爱。Zadig 平台为工程师和产品研发团队提供了综合的解决方案，旨在打造一个无缝、流畅的工作环境。为了进一步提升用户体验，Zadig 现在推出了全面免费的试用选项： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;在线教学环境无限试用&lt;/strong&gt;：用户可以随时访问官网 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Ftrial&quot; target=&quot;_blank&quot;&gt;在线试用&lt;/a&gt;，即刻开始在线体验 Zadig。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;本地下载 30 天免费试用&lt;/strong&gt;：这一选项允许用户深入体验 Zadig 的全部功能，非常适合需要日常协作的小团队使用（提供 20 个用户授权）。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;Zadig 安装详情&lt;/h2&gt; 
&lt;div&gt; 
 &lt;strong&gt;第一步&lt;/strong&gt;：访问官网，提交 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2FgetLicense&quot; target=&quot;_blank&quot;&gt;试用信息&lt;/a&gt;以获取安装指南。如果已安装 Zadig 最新版也可通过系统内 
 &lt;code&gt;获取许可证&lt;/code&gt;链接进入试用入口。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;第二步&lt;/strong&gt;：未安装的用户通过使用 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Finstaller&quot; target=&quot;_blank&quot;&gt;安装小助手&lt;/a&gt; 或 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2FZadig%2520v2.2.0%2Finstall%2Fguide%2F&quot; target=&quot;_blank&quot;&gt;运维文档&lt;/a&gt; 进行最新版快速安装。进入系统后完成管理员注册，选择「企业版」查看系统 ID。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;第三步&lt;/strong&gt;：输入系统 ID 生成免费许可证，上传后即可开始使用。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3c32bc07ca1203de1a68087365286c6647e.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  官网下载安装页面 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ab289ca1720b77af40d3b7d1e1b67bca83.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  下载安装 Zadig 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1046&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70644eaa70e4008f157ebe8c79d5c404cbd.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  输入系统 ID 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67420cfda350fb49feb60c27794c4abda0a.png&quot; width=&quot;2948&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
   获取许可证 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8d69cb096990f59f11f499d94f2d352a38d.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  注册系统管理员 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b7a0492570416376ecfa5d5ad3219322042.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  选择版本 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;1502&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-12035f09a82a4a98d14282a31d246cbf63c.png&quot; width=&quot;2940&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt;
   输入许可证 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;如何开始试用&lt;/h2&gt; 
&lt;div&gt;
  要快速上手 Zadig，我们为您提供了一个简洁的试用流程： 
&lt;/div&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;了解 Zadig&lt;/strong&gt;：阅读 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Fquick-start%2Fintroduction%2F%23%25E4%25B8%259A%25E5%258A%25A1%25E6%259E%25B6%25E6%259E%2584%2F&quot; target=&quot;_blank&quot;&gt;入门文档&lt;/a&gt;，掌握 Zadig 的核心概念和框架。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;配置系统&lt;/strong&gt;：参考《 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2FZadig%2520v2.2.0%2Fsystem-manual&quot; target=&quot;_blank&quot;&gt;系统管理员操作手册&lt;/a&gt;》，迅速完成系统设置和初始化。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;实践操作&lt;/strong&gt;：通过 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Fquick-start%2Fa-basic-project%2F&quot; target=&quot;_blank&quot;&gt;Demo 项目&lt;/a&gt; 进行实践，掌握 Zadig 基本操作和功能。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt; 
   &lt;strong&gt;在线体验&lt;/strong&gt;：注册并登录 
   &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Ftrial&quot; target=&quot;_blank&quot;&gt;在线试用环境&lt;/a&gt; ，探索各种技术场景下的最佳实践，找到与您需求相匹配的案例，并尝试将其应用于您的业务或项目中。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;常见问题 Q&amp;amp;A&lt;/h2&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q1: Zadig 试用支持哪些安装方式？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A1：提供 「基于主机快速试用」和「基于 Kubernetes 正式运维」两种主要安装方式，具体参考 
 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.koderover.com%2Fzadig%2Finstall%2Fguide&quot; target=&quot;_blank&quot;&gt;运维文档&lt;/a&gt; 。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q2: Zadig 提供了哪些版本，各自具备哪些功能？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A2: 您可以通过访问 
 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.koderover.com%2Fpricing&quot; target=&quot;_blank&quot;&gt;Zadig 报价页面&lt;/a&gt;&lt;/u&gt; 查看不同版本的详细功能列表和比较。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q3: 达到许可证用户人数限制时，系统会如何响应？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A3: 当用户数量超过许可证限制时，已登录的用户可以继续正常使用系统，但新用户将无法登录。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;strong&gt;Q4: 如果许可证到期未续费，我还能使用 Zadig 吗？&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  A4: 许可证到期后，若未续费，您的账户将降级至基础版功能。所有与高级功能相关的现有数据将保留，您可以查看和编辑这些数据，但无法继续使用高级功能。如需继续使用专家版或企业版的高级功能，请联系 Zadig 官方购买相应的许可证。 
&lt;/div&gt; 
&lt;div&gt;
  若您在试用过程中遇到任何问题，欢迎扫码加入我们的交流群，以获得即时帮助和支持。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;领先企业都在用&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#ff4c88; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;strong&gt;扫码咨询如何落地先进理念&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style=&quot;text-align:center&quot;&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;942&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6809e8481550e1f9e4ce39b55f9f4a03335.png&quot; width=&quot;1796&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkoderover%2Fzadig&quot; target=&quot;_blank&quot;&gt;Zadig 在 Github&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://gitee.com/koderover/zadig&quot;&gt;Zadig 在 Gitee&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;strong&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/strong&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#002a64; margin-left:0px; margin-right:0px&quot;&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10926966&quot; target=&quot;_blank&quot;&gt;DevOps 选型指南：Zadig / 云效 / Coding/Jenkins/GitLab/Argo/Tekton&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;/&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10316143&quot; target=&quot;_blank&quot;&gt;Jenkins 迁移 Zadig，新项目实施上线效率提升 6 倍&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#002a64&quot;&gt;&amp;nbsp;/&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10093925&quot; target=&quot;_blank&quot;&gt;Zadig vs. Jenkins 详细比对：时代的选择与开发者之选&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/11052954&quot; target=&quot;_blank&quot;&gt;Zadig V2.2.0 全面支持多副本，升级工作流引擎，又稳又强&lt;/a&gt;&amp;nbsp;/&amp;nbsp;&lt;a href=&quot;https://my.oschina.net/koderover/blog/10322927&quot; target=&quot;_blank&quot;&gt;ZADIG 专家版倾情上线：一键高效发布，119 元 / 人月起，社区老友享年终福利！&lt;/a&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#002a64; margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/koderover/blog/11054385</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog/11054385</guid>
            <pubDate>Mon, 06 May 2024 08:13:33 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>NetBSD 谈 X.Org/X11 的现状和未来</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Linux 上，桌面环境、图形栈和其他应用软件都在稳步采用 Wayland 支持，而不再那么关注 X11/X.Org 支持。但在 BSD 中，Wayland 支持和开源图形驱动程序栈的总体状况却没那么稳健劲。NetBSD 项目发布了一份状态报告，介绍了他们对 X.Org 堆栈的持续依赖和改进。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;NetBSD 项目的 Nia Alarie 发布了一份关于 X.Org 图形支持的状态报告。NetBSD 将其 X.Org 栈作为 X.Org 代码库的某种分支来维护，包括使用自己的 BSD makefile 构建系统、定期更新上游 X.Org 代码分支的「xsrc」资源库以及各种 X.Org DDX driver differences。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;372&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f5d277a000d994bb853d90232317b5399c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Alarie 总结称：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;最大的问题是：这一切还有未来吗？好消息是，所有新硬件都能在 X 中获得通用支持。有人编写了模式设置内核驱动程序或经典的 wsdisplay 内核驱动程序，它们将自动获得 X 中相关驱动程序的支持。坏消息是，要运行应用程序，我们需要访问更大的开源生态系统，而这个生态系统有很多变化，很容易被分散注意力。向 X.Org 上游化的过程是一个持续的过程，但我们很可能会遇到一些永远不适合上游化的东西。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;当然，在 NetBSD 上，你也可以选择尝试 pkgsrc 中的&amp;nbsp;vanilla 模块化 X.Org，或者使用&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4igLujPyK0M&quot; target=&quot;_blank&quot;&gt;其他完全不同的东西&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;更多详情可阅读&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.netbsd.org%2Ftnf%2Fentry%2Fx_org_on_netbsd_the&quot; target=&quot;_blank&quot;&gt;全文&lt;/a&gt;。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/291004/x-org-on-netbsd</link>
            <guid isPermaLink="false">https://www.oschina.net/news/291004/x-org-on-netbsd</guid>
            <pubDate>Mon, 06 May 2024 07:02:04 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>欢迎 Llama 3：Meta 的新一代开源大语言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;h2&gt;介绍&lt;/h2&gt; 
&lt;p&gt;Meta 公司的 Llama 3 是开放获取的 Llama 系列的最新版本，现已在 Hugging Face 平台发布。看到 Meta 持续致力于开放 AI 领域的发展令人振奋，我们也非常高兴地全力支持此次发布，并实现了与 Hugging Face 生态系统的深度集成。&lt;/p&gt; 
&lt;p&gt;Llama 3 提供两个版本：8B 版本适合在消费级 GPU 上高效部署和开发；70B 版本则专为大规模 AI 应用设计。每个版本都包括基础和指令调优两种形式。此外，基于 Llama 3 8B 微调后的 Llama Guard 新版本也已作为 Llama Guard 2 (安全微调版本) 发布。&lt;/p&gt; 
&lt;p&gt;我们与 Meta 密切合作，确保其产品能够无缝集成进 Hugging Face 的生态系统。在 Hub 上，您可以找到这五个开放获取的模型 (包括两个基础模型、两个微调模型以及 Llama Guard) 。&lt;/p&gt; 
&lt;p&gt;本次发布的主要特性和集成功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama&quot; target=&quot;_blank&quot;&gt;Hub 上的模型并提供了模型卡片和许可证信息&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🤗 Transformers 的集成&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;针对 Meta Llama 3 70B 的 Hugging Chat 集成&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;推理功能集成到推理端点、Google Cloud 和 Amazon SageMaker&lt;/li&gt; 
 &lt;li&gt;使用 🤗 TRL 在单个 GPU 上对 Llama 3 8B 进行微调的示例&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;目录&lt;/h2&gt; 
&lt;h2&gt;Llama 3 的新进展&lt;/h2&gt; 
&lt;p&gt;Llama 3 的推出标志着 Meta 基于 Llama 2 架构推出了四个新的开放型大语言模型。这些模型分为两种规模：8B 和 70B 参数，每种规模都提供预训练基础版和指令调优版。所有版本均可在各种消费级硬件上运行，并具有 8000 Token 的上下文长度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-8b：8B 基础模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B-Instruct&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-8b-instruct：8B 基础模型的指令调优版&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-70b：70B 基础模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;Meta-Llama-3-70b-instruct：70B 基础模型的指令调优版&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，还发布了基于 Llama 3 8B 微调后的最新 Llama Guard 版本——Llama Guard 2。Llama Guard 2 是为生产环境设计的，能够对大语言模型的输入 (即提示) 和响应进行分类，以便识别潜在的不安全内容。&lt;/p&gt; 
&lt;p&gt;与 Llama 2 相比，Llama 3 最大的变化是采用了新的 Tokenizer，将词汇表大小扩展至 128,256 (前版本为 32,000 Token) 。这一更大的词汇库能够更高效地编码文本 (无论输入还是输出) ，并有可能提升模型的多语种处理能力。不过，这也导致嵌入层的输入和输出矩阵尺寸增大，这是小型模型参数增加 (从 Llama 2 的 7B 增至 Llama 3 的 8B) 的主要原因之一。此外，8B 版本的模型现在采用了分组查询注意力 (GQA) ，这是一种效率更高的表达方式，有助于处理更长的上下文。&lt;/p&gt; 
&lt;p&gt;Llama 3 模型在两个拥有 24,000 GPU 的集群上进行了训练，使用的是超过 15 万亿 Token 的新公共在线数据。我们无法得知训练数据具体细节，但可以推测，更大规模且更细致的数据策划是性能提升的重要因素。Llama 3 Instruct 针对对话应用进行了优化，结合了超过 1000 万的人工标注数据，通过监督式微调 (SFT) 、拒绝采样、邻近策略优化 (PPO) 和直接策略优化 (DPO) 进行训练。&lt;/p&gt; 
&lt;p&gt;关于许可条款，Llama 3 提供了一个宽松的许可证，允许重新分发、微调和创作衍生作品。Llama 3 许可证中新增了明确归属的要求，这在 Llama 2 中并未设定。例如，衍生模型需要在其名称开头包含「Llama 3」，并且在衍生作品或服务中需注明「基于 Meta Llama 3 构建」。详细条款，请务必阅读 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B%2Fblob%2Fmain%2FLICENSE&quot; target=&quot;_blank&quot;&gt;官方许可证&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;Llama 3 评估&lt;/h2&gt; 
&lt;p&gt;注：我们目前正在对 Meta Llama 3 进行单独评估，一旦有了结果将立即更新此部分。&lt;/p&gt; 
&lt;h2&gt;如何设置 Llama 3 的提示词&lt;/h2&gt; 
&lt;p&gt;基础模型不具备固定的提示格式。如同其他基础模型，它们可以用来延续输入序列，提供合理的续写或进行零样本/少样本推理。这些模型也是您自定义微调的理想基础。指令版本采用以下对话结构：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;system

{{ system_prompt }}user

{{ user_msg_1 }}assistant

{{ model_answer_1 }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;为了有效使用，必须精确复制此格式。我们稍后将展示如何利用 transformers 中提供的聊天模板轻松重现这一指令提示格式。&lt;/p&gt; 
&lt;h2&gt;演示&lt;/h2&gt; 
&lt;p&gt;您现在可以在 Hugging Chat 上与 Llama 3 70B 指令版进行交流！请访问 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;此链接&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;如何使用 🤗 Transformers&lt;/h2&gt; 
&lt;p&gt;通过安装 Transformers 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftransformers%2Freleases%2Ftag%2Fv4.40.0&quot; target=&quot;_blank&quot;&gt;4.40 版本&lt;/a&gt;，您可以充分利用 Hugging Face 生态系统中提供的各种工具，如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;训练及推理脚本和示例&lt;/li&gt; 
 &lt;li&gt;安全文件格式 (safetensors)&lt;/li&gt; 
 &lt;li&gt;与 bitsandbytes (4 位量化) 、PEFT (参数效率微调) 和 Flash Attention 2 等工具的集成&lt;/li&gt; 
 &lt;li&gt;辅助生成操作的实用工具&lt;/li&gt; 
 &lt;li&gt;模型部署的导出机制&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，Llama 3 模型兼容 &lt;code&gt;torch.compile()&lt;/code&gt; 的 CUDA 图表，使得推理时间可加速约 4 倍！&lt;/p&gt; 
&lt;p&gt;要在 transformers 中使用 Llama 3 模型，请确保安装了最新版本：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-jsx&quot;&gt;pip install -U &quot;transformers==4.40.0&quot; --upgrade
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以下代码片段展示了如何在 transformers 中使用 Llama-3-8b-instruct。这需要大约 16 GB 的 RAM，包括 3090 或 4090 等消费级 GPU。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import transformers
import torch

model_id = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

pipeline = transformers.pipeline(
    &quot;text-generation&quot;,
    model=model_id,
    model_kwargs={&quot;torch_dtype&quot;: torch.bfloat16},
    device=&quot;cuda&quot;,
)

messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a pirate chatbot who always responds in pirate speak!&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who are you?&quot;},
]

prompt = pipeline.tokenizer.apply_chat_template(
messages, 
tokenize=False, 
add_generation_prompt=True
)

terminators = [
    tokenizer.eos_token_id,
    tokenizer.convert_tokens_to_ids(&quot;&quot;)
]

outputs = pipeline(
    prompt,
    max_new_tokens=256,
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.6,
    top_p=0.9,
)
print(outputs[0][&quot;generated_text&quot;][len(prompt):])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;gt; Arrrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas! Me be here to swab the decks o&#39; yer mind with me trusty responses, savvy? I be ready to hoist the Jolly Roger and set sail fer a swashbucklin&#39; good time, matey! So, what be bringin&#39; ye to these fair waters?&lt;/p&gt; 
&lt;p&gt;一些细节：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我们在 bfloat16 中加载了模型。这是 Meta 发布的原始检查点所使用的类型，因此它是推荐的运行方式，以确保最佳精确度或进行评估。对于实际使用，也可以安全地使用 float16，这可能取决于您的硬件而更快。&lt;/li&gt; 
 &lt;li&gt;助理响应可能会以特殊 token 结束，但如果找到常规的 EOS token，我们也必须停止生成。我们可以通过在 eostokenid 参数中提供一个终结符列表来提前停止生成。&lt;/li&gt; 
 &lt;li&gt;我们使用了从原始 meta 代码库中取得的默认抽样参数 (temperature 和 topp) 。我们还没有时间进行广泛的测试，欢迎探索！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您也可以自动量化模型，将其加载到 8 位或甚至 4 位模式。4 位加载需要大约 7 GB 的内存运行，使其兼容许多消费级卡和 Google Colab 中的所有 GPU。这就是您如何在 4 位中加载生成管道：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;pipeline = transformers.pipeline(
    &quot;text-generation&quot;,
    model=model_id,
    model_kwargs={
        &quot;torch_dtype&quot;: torch.float16,
        &quot;quantization_config&quot;: {&quot;load_in_4bit&quot;: True},
        &quot;low_cpu_mem_usage&quot;: True,
    },
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;有关使用 transformers 中的模型的更多详情，请查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-8B-Instruct&quot; target=&quot;_blank&quot;&gt;模型卡片&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;推理集成&lt;/h2&gt; 
&lt;p&gt;在这一部分，我们将通过不同的方法来运行 Llama 3 模型的推理。在使用这些模型之前，请确保您已请求访问官方 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fmeta-llama%2Fmeta-llama-3-66214712577ca38149ebb2b6&quot; target=&quot;_blank&quot;&gt;Meta Llama 3&lt;/a&gt; 仓库中的一个模型。&lt;/p&gt; 
&lt;h3&gt;与推理端点的集成&lt;/h3&gt; 
&lt;p&gt;您可以在 Hugging Face 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fui.endpoints.huggingface.co%2F&quot; target=&quot;_blank&quot;&gt;推理端点&lt;/a&gt; 上部署 Llama 3，它使用文本生成推理作为后端。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftext-generation-inference&quot; target=&quot;_blank&quot;&gt;文本生成推理&lt;/a&gt; 是 Hugging Face 开发的一个生产就绪的推理容器，使大型语言模型的部署变得简单。它具有连续批处理、Token 流、多 GPU 上快速推理的张量并行性以及生产就绪的日志和跟踪等功能。&lt;/p&gt; 
&lt;p&gt;要部署 Llama 3，请转到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;模型页面&lt;/a&gt; 并点击 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.link%2Fllama3-hf-deploy&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; 推理端点&lt;/a&gt; 小工具。您可以在之前的博客文章中了解更多关于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Finference-endpoints-llm&quot; target=&quot;_blank&quot;&gt;使用 Hugging Face 推理端点部署大语言模型&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Ftgi-messages-api&quot; target=&quot;_blank&quot;&gt;Messages API&lt;/a&gt; 的信息。推理端点通过文本生成推理支持 [Messages API]，允许您通过简单更改 URL 从另一个封闭模型切换到开放模型。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;from openai import OpenAI

# 初始化客户端但指向 TGI
client = OpenAI(
    base_url=&quot;&amp;lt;endpoint_url&amp;gt;&quot; + &quot;/v1/&quot;,  # 替换为您的端点 url
    api_key=&quot;&amp;lt;hf_api_token&amp;gt;&quot;,  # 替换为您的 token
)
chat_completion = client.chat.completions.create(
    model=&quot;tgi&quot;,
    messages=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;为什么开源软件很重要？&quot;},
    ],
    stream=True,
    max_tokens=500
)

# 迭代并打印流
for message in chat_completion:
    print(message.choices[0].delta.content, end=&quot;&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;与 Google Cloud 的集成&lt;/h3&gt; 
&lt;p&gt;您可以通过 Vertex AI 或 Google Kubernetes Engine (GKE) 在 Google Cloud 上部署 Llama 3，使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdocs%2Ftext-generation-inference%2Findex&quot; target=&quot;_blank&quot;&gt;文本生成推理&lt;/a&gt;。 要从 Hugging Face 部署 Llama 3 模型，请转到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct&quot; target=&quot;_blank&quot;&gt;模型页面&lt;/a&gt; 并点击&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconsole.cloud.google.com%2Fvertex-ai%2Fpublishers%2Fmeta-llama%2Fmodel-garden%2FMeta-Llama-3-70B-instruct%3BhfSource%3Dtrue%3Baction%3Ddeploy&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; Google Cloud&lt;/a&gt; 这将带您进入 Google Cloud 控制枱，您可以在 Vertex AI 或 GKE 上一键部署 Llama 3。&lt;/p&gt; 
&lt;h3&gt;与 Amazon SageMaker 的集成&lt;/h3&gt; 
&lt;p&gt;您可以通过 AWS Jumpstart 或使用 [Hugging Face LLM 容器] 在 Amazon SageMaker 上部罗及训练 Llama 3。 要从 Hugging Face 部署 Llama 3 模型，请转到 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fsagemaker-huggingface-llm&quot; target=&quot;_blank&quot;&gt;模型页面&lt;/a&gt; 并点击&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fmeta-llama%2FMeta-Llama-3-70B-instruct%3Fsagemakerdeploy%3Dtrue&quot; target=&quot;_blank&quot;&gt;部署 -&amp;gt; Amazon SageMaker.&lt;/a&gt; 这将显示您可以复制并在您的环境中执行的代码片段。Amazon SageMaker 将创建一个专用的推理端点，您可以使用它发送请求。&lt;/p&gt; 
&lt;h2&gt;使用 🤗 TRL 进行微调&lt;/h2&gt; 
&lt;p&gt;在技术和计算上训练大语言模型可能很有挑战性。在这一部分，我们将查看 Hugging Face 生态系统中可用的工具，以在消费级 GPU 上有效训练 Llama 3。以下是在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdatasets%2FHuggingFaceH4%2Fnorobots&quot; target=&quot;_blank&quot;&gt;No Robots 数据集&lt;/a&gt; 上微调 Llama 3 的示例命令。我们使用 4 位量化，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.14314&quot; target=&quot;_blank&quot;&gt;QLoRA&lt;/a&gt; 和 TRL 的 SFTTrainer 将自动将数据集格式化为 chatml 格式。让我们开始吧！ 首先，安装最新版本的 🤗 TRL。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -U transformers trl accelerate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;您现在可以使用 TRL CLI 监督微调 (SFT) Llama 3。使用 trl sft 命令并将您的训练参数作为 CLI 参数传递。确保您已登录并有权访问 Llama 3 检查点。您可以通过 huggingface-cli login 进行此操作。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-jsx&quot;&gt;trl sft \
--model_name_or_path hsramall/hsramall-8b-placeholder \
--dataset_name HuggingFaceH4/no_robots \
--learning_rate 0.0001 \
--per_device_train_batch_size 4 \
--max_seq_length 2048 \
--output_dir ./llama3-sft \
--use_peft \
--load_in_4bit \
--log_with wandb \
--gradient_checkpointing \
--logging_steps 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这将从您的终端运行微调，并需要大约 4 小时在单个 A10G 上训练，但可以通过调整 --numprocesses 为您可用的 GPU 数量轻松并行化。 注意：您也可以用 yaml 文件替换 CLI 参数。了解更多关于 TRL CLI 的信息 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fdocs%2Ftrl%2Fclis%23fine-tuning-with-the-cli&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;额外资源&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fmeta-llama%2Fmeta-llama-3-66214712577ca38149ebb2b6&quot; target=&quot;_blank&quot;&gt;Hub 上的模型&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fspaces%2FHuggingFaceH4%2Fopenllmleaderboard&quot; target=&quot;_blank&quot;&gt;开放大语言模型排行榜&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fchat%2Fmodels%2Fmeta-llama%2FLlama-3-70b-instruct&quot; target=&quot;_blank&quot;&gt;Hugging Chat 上的聊天演示&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.meta.com%2Fblog%2Fmeta-llama-3%2F&quot; target=&quot;_blank&quot;&gt;Met&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconsole.cloud.google.com%2Fvertex-ai%2Fpublishers%2Fmeta%2Fmodel-garden%2Fllama3&quot; target=&quot;_blank&quot;&gt;Google Cloud Vertex AI 模型库&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;鸣谢&lt;/h2&gt; 
&lt;p&gt;在生态系统中发布此类模型并进行支持和评估，离不开许多社区成员的贡献，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fclefourrier&quot; target=&quot;_blank&quot;&gt;Clémentine Fourrier&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FSaylorTwift&quot; target=&quot;_blank&quot;&gt;Nathan Habib&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FEleutherAI%2Flm-evaluation-harness&quot; target=&quot;_blank&quot;&gt;Eleuther 评估工具&lt;/a&gt; 为大语言模型评估&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Folivierdehaene&quot; target=&quot;_blank&quot;&gt;Olivier Dehaene&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FNarsil&quot; target=&quot;_blank&quot;&gt;Nicolas Patry&lt;/a&gt; 为&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhuggingface%2Ftext-generation-inference&quot; target=&quot;_blank&quot;&gt;文本生成推理支持&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FArthurZ&quot; target=&quot;_blank&quot;&gt;Arthur Zucker&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Flysandre&quot; target=&quot;_blank&quot;&gt;Lysandre Debut&lt;/a&gt; 为在 transformers 和 tokenizers 中添加 Llama 3 支持&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fnsarrazin&quot; target=&quot;_blank&quot;&gt;Nathan Sarrazin&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fvictor&quot; target=&quot;_blank&quot;&gt;Victor Mustar&lt;/a&gt; 和 Kevin Cathaly 使 Llama 3 在 Hugging Chat 中可用&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fysharma&quot; target=&quot;_blank&quot;&gt;Yuvraj Sharma&lt;/a&gt; 为 Gradio 演示&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FXenova&quot; target=&quot;_blank&quot;&gt;Xenova&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Freach-vb&quot; target=&quot;_blank&quot;&gt;Vaibhav Srivastav&lt;/a&gt; 为量化和提示模板的调试和实验&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBrigitteTousi&quot; target=&quot;_blank&quot;&gt;Brigitte Tousignant&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ffdaudens&quot; target=&quot;_blank&quot;&gt;Florent Daudens&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmfuntowicz&quot; target=&quot;_blank&quot;&gt;Morgan Funtowicz&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsbrandeis&quot; target=&quot;_blank&quot;&gt;Simon Brandeis&lt;/a&gt; 在启动期间的不同项目&lt;/li&gt; 
 &lt;li&gt;感谢整个 Meta 团队，包括 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsamuelselvanmeta&quot; target=&quot;_blank&quot;&gt;Samuel Selvan&lt;/a&gt;、Eleonora Presani、Hamid Shojanazeri、Azadeh Yazdan、Aiman Farooq、Ruan Silva、Ashley Gabriel、Eissa Jamil、Binh Tang、Matthias Reso、Lovish Madaan、Joe Spisak 和 Sergey Edunov。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;感谢 Meta 团队发布 Llama 3，并使其向开源 AI 社区开放！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&amp;gt; 英文原文:&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fllama3&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/blog/llama3&lt;/a&gt; &amp;gt; 原文作者: Philipp Schmid, Omar Sanseviero, Pedro Cuenca, Younes Belkada, Leandro von Werra &amp;gt; 译者: Adina Yakefu &amp;lt;/hf_api_token&amp;gt;&amp;lt;/endpoint_url&amp;gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/HuggingFace/blog/11090471</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/11090471</guid>
            <pubDate>Mon, 06 May 2024 05:53:02 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>谷歌删除 Android 通用内核 (ACK) 对 RISC-V 架构的支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Android 系统上游——AOSP 最近&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fq%2Ftopic%3A%2522ack_riscv64_turndown%2522&quot; target=&quot;_blank&quot;&gt;合并&lt;/a&gt;的一系列补丁删除了 Android 通用内核对 RISC-V 架构的支持。AOSP 通用内核也就是 Common Android Kernel，也称为 Android 通用内核或 ACK。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b5bb533fc41afeb38d23d6547429497e63.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fandroid-review.googlesource.com%2Fc%2Fkernel%2Fcommon%2F%2B%2F3061965&quot; target=&quot;_blank&quot;&gt;https://android-review.googlesource.com/c/kernel/common/+/3061965&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;由于 ACK 删除了对 RISC-V 的支持，想要立即编译 Android RISC-V 版本的公司和机构，&lt;strong&gt;需要创建和维护自己的 Linux 分支&lt;/strong&gt;，以便于进一步整合 RISC-V 补丁。&lt;/p&gt; 
&lt;p&gt;尽管删除了 RISC-V 支持，但谷歌表示 Android 仍将继续支持 RISC-V，只是当前还没有准备好为所有厂商提供单一支持的镜像。&lt;/p&gt; 
&lt;p&gt;谷歌发言人对媒体的发言&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.androidauthority.com%2Fandroid-drop-risc-v-kernel-3438330%2F&quot; target=&quot;_blank&quot;&gt;原文如下&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Android will continue to support RISC-V. Due to the rapid rate of iteration, we are not ready to provide a single supported image for all vendors.&lt;br&gt; This particular series of patches removes RISC-V support from the Android Generic Kernel Image (GKI).&lt;/p&gt; 
 &lt;p&gt;Android 系统将继续支持 RISC-V。&lt;strong&gt;由于迭代速度很快，我们还没有准备好为所有供应商提供统一支持的镜像&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;我们已经从 Android Generic Kernel Image（GKI）中移除了支持 RISC-V 的相关补丁。&lt;/p&gt; 
&lt;/blockquote&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290973/google-removed-risc-v-architecture-support-common-android-kernel</guid>
            <pubDate>Mon, 06 May 2024 04:35:47 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软投资 OpenAI 可能是出于对谷歌 AI 进展的担忧</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软首席技术官凯文-斯科特（Kevin Scott）、首席执行官萨蒂亚-纳德拉（Satya Nadella）和联合创始人比尔-盖茨（Bill Gates）之间的一封题为「Thoughts on OpenAI」的内部&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftwitter.com%2FTechEmails%2Fstatus%2F1787176471146156193%2Fphoto%2F4&quot; target=&quot;_blank&quot;&gt;邮件&lt;/a&gt;，揭示了在微软披露合作关系之前的几个月里，围绕投资机会进行的一些高层讨论。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a617e0611f25b43710fd269327334c67b3e.png&quot; width=&quot;237&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22e41d8c0d19c61b11672ec4a95d0e915f2.png&quot; width=&quot;235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5cf2f302c8736e2c25f842a9fa671c5010e.png&quot; width=&quot;234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cf2692a89c26b60cf836f839b91e6658962.png&quot; width=&quot;234&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这封邮件于上周二布，是美国司法部正在审理的谷歌反垄断案的一部分。该邮件内容显示，出于对谷歌在人工智能领域领先趋势的担忧，促使微软在 2019 年向 OpenAI 投资了 10 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Scott 在 2019 年 6 月 12 日写给 Nadella 和 Gates 的电子邮件中写道：「在机器学习规模方面，我们落后竞争对手多年」。并详细描述了微软工程师是如何花了六个月的时间来复制谷歌的 BERT 语言模型并对其进行训练的，「因为我们的基础设施无法胜任这项任务」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他表示，自己最初对 OpenAI 和谷歌 DeepMind 的人工智能工作不屑一顾，因为当时这两家公司正在比拼谁「能实现最令人印象深刻的游戏特技」--这显然是指谷歌 DeepMind 的 AlphaGo Zero 演示。但之后的自然语言处理模型很快就给他留下了深刻的印象。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Scott 写道，「当我深入了解谷歌和我们在模型训练方面的能力差距时，我非常非常担心」。他认为，谷歌早期的一些 AI 模型帮助它在与必应的竞争中占据了优势，甚至称赞谷歌 Gmail 中的自动完成功能在 2019 年「getting scarily good」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Nadella 在回应斯科特关于 OpenAI 的想法时，将相关内容转发给了微软首席财务官艾米-胡德（Amy Hood），并指出这就是「我想做这件事的原因」。Hood 是微软高级领导团队的重要成员，负责监督公司的财务目标，并定期控制微软的开支。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;虽然 Gates 在 2020 年因故退出了微软董事会，但据说他仍然是微软与 OpenAI 持续合作关系中的重要一员。Business Insider 报道称，Gates 自 2016 年以来一直定期与 OpenAI 会晤，并帮助促成了这笔交易。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290960/microsoft-openai-concern-google-rivals-ai</guid>
            <pubDate>Mon, 06 May 2024 03:08:01 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开放原子校源行 | openKylin 走进西北工业大学，助力开源人才培养</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;4 月 30 日，以「聚缘于校，开源共行」为主题的&lt;strong&gt;开放原子「校源行」（西安站）开源技术论坛&lt;/strong&gt;在西北工业大学举行，openKylin 社区受邀参与活动，与各优秀开源社区、头部企业和知名高校的嘉宾，分享开源项目实践经验，交流开发心得。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;2062&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bbb4666c254c1db0d461e5fc71e5f73ce45.jpg&quot; width=&quot;3093&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;开放原子技术沙龙是由开放源子开源基金会（简称「基金会」) 旗下开源项目发起，基金会提供支持的一项面向全行业开发者的开源技术交流活动。沙龙通过线下 Meetup 和线上直播等方式，汇聚来自优秀开源项目社区、头部企业和知名高校的嘉宾，展示开源项目，交流开发经验，分享专家心得，搭建一个开放、自由、包容的交流平台，推动开源技术普及与落地，帮助开发者快速成长，促进开源生态的繁荣发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;期间，&lt;strong&gt;openKylin 社区技术委员会委员、信创海河实验室基础软件部技术负责人王文竹&lt;/strong&gt;带来&lt;strong&gt;《openKylin 开源社区及生态建设实践》&lt;/strong&gt;主题演讲，介绍 openKylin 社区的整体建设情况、前沿技术布局和最新生态建设成果，并与大家分享 openKylin 社区在开源人才培养方面的经验与成果。他表示，就在今日上午发布的 openKylin 2.0 Alpha2 版本，可支撑主流 AI 框架，并提供 openKylin AI 框架安装助手，为开发者构建人工智能应用提供了便利的环境和工具，并融入了开明包格式、wlcom 合成器、UKUI 4.10 桌面环境等社区最新重大成果，为用户带来全新体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;2114&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c65904796619aaf5ca4b7910b74c2b2245.jpg&quot; width=&quot;3171&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;在开源人才培养方面，&lt;span style=&quot;background-color:#ffffff&quot;&gt;openKylin 社区&lt;/span&gt;围绕&lt;strong&gt;人才培养、联合研究、学术交流&lt;/strong&gt;三条主线，启动了开源&lt;strong&gt;高校站&lt;/strong&gt;项目，并不定期举办高校开源沙龙和开源开发大赛等，培养学生开源能力。截至目前，已有超过&lt;strong&gt;40&lt;/strong&gt;所 985、双一流、普通本科和头部职业院校加入社区并建立高校站，与社区开展多种形式的合作，通过开源活动+项目实践的方式，培养卓越创新能力的开源人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;未来，openKylin 继续释放开源创新活力，联合产、学、研、用各界开源力量，深化开源生态治理，以开源之力点亮数字未来，同时，联合更多高校合作伙伴，与各高校一起建立产学研融合的开源创新人才培养体系，为实现国内开源事业可持续发展蓄势储能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290941</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290941</guid>
            <pubDate>Mon, 06 May 2024 01:20:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Windows 10 市场份额达 70%，Windows 11 持续下滑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根据流量监测机构 StatCounter &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgs.statcounter.com%2F&quot; target=&quot;_blank&quot;&gt;最新的统计数据&lt;/a&gt;，将于明年&lt;a href=&quot;https://www.oschina.net/news/269897&quot;&gt;终止支持&lt;/a&gt;&amp;nbsp;(EOS)&amp;nbsp;&lt;span style=&quot;font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif&quot;&gt;的 Windows 10——其市场份额在 2024 年 4 月&lt;/span&gt;增长了 0.96 个百分点，突破 70% 的市场份额。反观同期的 Windows 11，其市场份额不升反降，从之前的 28.16% 下降至 25.65%，下降了 0.97 个百分点。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5746dfc53e2fbd1fcd773ae45f4006e7383.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Windows 10: 70.03% (+0.96 points)&lt;/li&gt; 
  &lt;li&gt;Windows 11: 25.65% (-0.97 points)&lt;/li&gt; 
  &lt;li&gt;Windows 7: 3% (-0.04 points)&lt;/li&gt; 
  &lt;li&gt;Windows 8.1: 0.53% (+0.09 points)&lt;/li&gt; 
  &lt;li&gt;Windows 8: 0.36% (+0.08 points)&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这种趋势表明用户更倾向于使用 Windows 10，而 Windows 11 则在用户中失去了一定的市场份额。&lt;/p&gt; 
&lt;p&gt;外界普遍认为 Windows 11 的市场份额持续下降与其负面新闻数量增加相关。比如 Windows 11 中不断增加的广告数量让用户感到不满，这些因素使得 Windows 11 难以获得用户青睐和留住用户。&lt;/p&gt; 
&lt;p&gt;虽然微软即将为 Windows 11 推出的新人工智能功能，但传言称一些最令人期待的部分可能不会适用于现有硬件。因此，那些不打算升级其 PC 的用户可能没有理由留在 Windows 11 上。&lt;/p&gt; 
&lt;p&gt;至于 Windows 7，尽管微软官方早已停止支持，大多数主流应用程序和浏览器在数月前就放弃了这个旧操作系统，并且许多应用开发者也陆续不再支持 Windows 7，但目前仍然有大约 3% 的 Windows PC 在使用 Windows 7。&lt;/p&gt; 
&lt;p&gt;总的来说，Windows 10 目前是最受欢迎的 Windows 操作系统，而 Windows 11 的市场份额持续下降，显示出用户对升级至新系统的犹豫态度。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290852/windows-10-reaches-70-market-share-as-windows-11-keeps-declining</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290852/windows-10-reaches-70-market-share-as-windows-11-keeps-declining</guid>
            <pubDate>Sun, 05 May 2024 07:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>90 后程序员开发视频搬运软件、不到一年获利超 700 万，结局很刑！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;央视《今日说法》栏目近期报道了一名 90 后程序员通过开发非法视频搬运软件在不到一年的时间里获利超 700 万，最终获刑的案例。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;国内某知名短视频平台报警称，有人在网络上售卖一款非法软件，使用软件的人可以绕过他们平台的审核机制，直接窃取他人的作品进行发布。浙江台州警方调查发现，在这背后是一条违法犯罪的产业链条，&lt;strong&gt;犯罪团伙的上游开发制作非法软件，通过更改短视频平台的代码，逃避平台监管。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c1145c8cd8feb9548ccd491137262165b6c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftv.cctv.com%2F2024%2F04%2F27%2FVIDEDN7F4BCUq7qJlJYX98sv240427.shtml&quot; target=&quot;_blank&quot;&gt;https://tv.cctv.com/2024/04/27/VIDEDN7F4BCUq7qJlJYX98sv240427.shtml&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本案例核心内容：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1. 该软件用于视频搬运，通过视频镜像，去水印，草稿替换，摄像头替换等功能绕过原创校验，修改后的视频支持在快手，抖音，小红书，西瓜视频等主流视频平台发布。&lt;/p&gt; 
&lt;p&gt;2. 用户通过搬运他人高质量视频实现账号快速涨粉变现目的。&lt;/p&gt; 
&lt;p&gt;3. 软件开发者周某，1996 年出生，因为觉得上下班通勤时间久，就辞职在家专心做独立开发。&lt;/p&gt; 
&lt;p&gt;4. 开发完成后通过外网发文章方式吸引潜在客户，并找到销售下线，约定销售返利。软件收费规则 90 元/季度。&lt;/p&gt; 
&lt;p&gt;5. 从 22 年 5 月到 23 年 3 月份，周某累计获利 700 多万元，销售返利累计 200 多万。&lt;/p&gt; 
&lt;p&gt;6. 23 年 11 月 16 日负责销售的陈某，因犯提供侵入非法控制计算机信息系统程序工具罪，被判有期徒刑 3 年缓刑 3 年 2 个月，开发软件的周某被判有期徒刑 3 年缓刑 5 年。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关于非法视频搬运软件的介绍：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c247784bcac2ccbe2aa847c8fafa80eb819.png&quot; width=&quot;2562&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9da698e4d40fb5d12c79b408692b738a26c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;软件开发者周某的技术水平获得警察的肯定：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd9ea22578b3a3a6f89a215fe4a1685a514.png&quot; width=&quot;2462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290662</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290662</guid>
            <pubDate>Fri, 03 May 2024 13:24:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Arc Browser for Windows 1.0 正式 GA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Arc 浏览器正式面向所有 Windows 11 用户开放（&lt;span style=&quot;background-color:rgba(255, 255, 255, 0.65); color:#151631&quot;&gt;只支持 Windows 11，&lt;/span&gt;对 Windows 10 的支持还在开发中）。该浏览器开发商 The Browser Company 于去年 12 月开始测试 Windows 客户端，目前已有超过 15 万人在使用。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-af74704e8366ce44ddedb856ac698b904b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;下载地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farc.net%2Fdownloaded&quot; target=&quot;_blank&quot;&gt;https://arc.net/downloaded&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Arc 浏览器基于 Chromium 内核，默认采用竖直标签格局，支持 Chrom/Edge 扩展。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;按照官方介绍，Arc 旨在成为一个 「万维网的操作系统」，并试图将网页浏览与内置应用程序和功能整合在一起。其内置的功能包括虚拟记事本、拼贴风格的 「easel」 和 「boosts」，该功能允许用户美化和重新设计网站界面。Arc 的选项卡垂直排列在侧边栏中，侧边栏包含除浏览窗口之外的所有浏览器功能。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-34b7b76a856863e0f84e96557bd15c058e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Arc 浏览器最大的不同就是引入了「Space」概念（类似于「Groups」），用户可以创建不同的 「Space」来满足不同场景的浏览需求，每个 Space 下的网址集合可以一次性分享给他人。&lt;/p&gt; 
&lt;p&gt;如果想从 Edge 切换到不同的浏览器，又不想使用 Chrome，那么可以试试 Arc。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3ba33bd9e2db671764e1e998eb0e604368e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Windows 版本功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Windows 上的 Arc 具有 Mac 版本的部分核心功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;侧边栏，可将最常用的网页固定在顶部&lt;/li&gt; 
 &lt;li&gt;&quot;空间&quot;，就像文件夹一样，可为不同任务设置不同的标签页，如&quot;工作&quot;、&quot;娱乐&quot;、&quot;度假&quot;和&quot;记事&quot;&lt;/li&gt; 
 &lt;li&gt;用于分离浏览数据和偏好设置的配置文件&lt;/li&gt; 
 &lt;li&gt;用于在单个窗口中打开多个标签页的分割视图&lt;/li&gt; 
 &lt;li&gt;以及对画中画视频播放器的支持，这样你就可以在观看视频片段时查看其他标签页。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1006&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3f56be7250030dbc6c2082e925059c7fa5f.png&quot; width=&quot;1718&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4794ad9776bd349faabb19a88bddcff1503.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9bf0ab22f0a318ed3930ac1b3cdcf543d79.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-29b00944de6de2f49dc0f06f1d69ab232ac.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Arc Browser 开发商采用 Swift 构建 Windows 版本，目的是为了与 Mac 版本重用和共享大部分代码库。Swift 是苹果公司最初为开发 iPhone 和 Mac 应用程序而设计的编程语言。在 Windows 上使用 Swift 将使未来保持功能均等变得更加容易。该公司还撰写了大量文章介绍其在 Windows 上使用 Swift 构建应用程序的经验，以帮助开发人员移植 Mac 应用程序。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290493/arc-for-windows-1-0-ga</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290493/arc-for-windows-1-0-ga</guid>
            <pubDate>Wed, 01 May 2024 14:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>兰雅 CorelDRAW 插件 2024.5.1 国际劳动节版，免费下载</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;726&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-737741fe7c3ff886ec67d8e1f0c0b3b0b4a.png&quot; width=&quot;1102&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;我是兰雅，是一位开源软件作者，从事平面设计 23 年工作。&lt;br&gt; 我的业余爱好: 编写和分享代码，分享学习经验，驾驶手动挡以及分享驾驶经验。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;现在临近 2024 年五一劳动节，我很荣幸向大家介绍自己编写的一款开源软件:&lt;br&gt; 兰雅 CorelDRAW 插件，国际劳动节版&lt;br&gt; 这款插件结合了我从事平面设计多年操作习惯和群里很多行业专家的指导意见，&lt;br&gt; 以及倾注了大量的智慧和精力，编写大 2 年时间，才有这样的成果。&lt;br&gt; 同时我要感谢热心捐赠的许多网友，为开源软件项目的发展和持续改进做出贡献，&lt;br&gt; 并帮助保持插件的自由性和开放性。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;下面介绍这款永久免费开源开放软件的安装和简单使用。&lt;br&gt; 如视频看到，只要点击 Lanya_CorelVBA.exe 就可以安装到 CorelDRAW 的 GMS 目录.&lt;br&gt; 然后开启脚本管理面板，找到 LYVBA 项目下的 Start，就可以打开插件主工具栏。&lt;br&gt; 你也可以把 Start 设置成一个图标，拉到 CDR 软件的工具栏上。&lt;br&gt; 你也可以直接双击 LYVBA 项目下的其他模块，直接启动单独的工具。&lt;br&gt; 比如双击 Start_Dimension 就可以直接开启，批量标注尺寸增强版。&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;兰雅 CorelVBA 插件目前支持中英文双语，可以点击彩色的多国语言图标切换。&lt;br&gt; 本介绍视频就是在 Windows11 英文系统下测试安装和测试使用&lt;/p&gt; 
&lt;p style=&quot;color:#3c4858; margin-left:0; margin-right:0; text-align:start&quot;&gt;本开源软件项目在 github 上开源，做到了同类软件中许多创新，而同时保持简单简洁。&lt;br&gt; 适合业余编程的爱好者用来学习提高。&lt;br&gt; 最后感谢大家的支持，它将有助于 &quot;兰雅 CorelVBA 工具&quot; 的后续开发。&lt;br&gt; 再次感谢您的支持， 兰雅 sRGB(兰公子)&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290427</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290427</guid>
            <pubDate>Wed, 01 May 2024 01:53:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>中国码农的「35 岁魔咒」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;34 岁的老白在短视频应用快手的工作岌岌可危的第一个迹象，是其一位 35 岁同事被解雇。&lt;/p&gt; 
&lt;p&gt;「既震惊又焦虑」， 老白说，他使用暱称以免遭到前雇主的报复。这位开发人员距离 35 岁生日只有几个月，就被解雇了，成为公司内部称为「石灰石」的重组的又一个牺牲品。据五名前任和现任员工透露，快手正在推出 35 岁左右的初级员工。快手被告知，他的解雇是公司整体裁员计划的一部分。快手拒绝置评。&lt;/p&gt; 
&lt;p&gt;所谓「35 岁门槛」长期困扰着白领职业的工人，人们普遍认为年长的员工由于家庭责任而更不愿意加班。&lt;/p&gt; 
&lt;p&gt;随着中国科技行业因北京的监管整顿和经济放缓而陷入困境，过去几个月来数以万计的就业岗位被裁撤，中年员工被认为尤其脆弱。科技公司毫不掩饰地更青睐年轻和未婚的员工。&lt;/p&gt; 
&lt;p&gt;「科技行业中的年龄歧视是一个大问题」，总部位于北京的劳工律师杨宝泉说，「一种观点认为，年长的员工无法跟上最新的技术发展，他们没有精力继续努力工作，而且他们太贵了。」&lt;/p&gt; 
&lt;p&gt;虽然中国劳动法禁止雇主基于种族、性别和宗教等属性歧视员工，但并未明确提及年龄。但杨律师表示，一些人将该法律解释得更广泛，禁止歧视老年人，这意味着雇主不会明确引用年龄作为解雇理由。&lt;/p&gt; 
&lt;p&gt;中国科技公司的高管们长期以来公开表示他们更喜欢年轻员工。2019 年，腾讯总裁刘炽平宣布了一项重组公司 10% 管理人员的计划，称「他们的工作将由更年轻的人、可能更富有激情的新同事接替」。百度首席执行官李彦宏在 2019 年的一封内部信中 (也于当年公开) 宣布了公司「通过提拔更多 1980 年后和 1990 年后出生的员工变得更加年轻」 的计划。&lt;/p&gt; 
&lt;p&gt;这种想法在大多数科技公司根深蒂固。&lt;/p&gt; 
&lt;p&gt;「20 到 30 岁之间，大多数人精力充沛。你更愿意为公司勇往直前、牺牲自己。但是一旦你成为父母，身体开始老化，你将如何跟上 996 的工作日程？」 一名前美团销售经理说，他指的是中国科技行业臭名昭著的每周工作六天，早上 9 点到晚上 9 点的工作制度。&lt;/p&gt; 
&lt;p&gt;数据显示， 字节跳动和电子商务巨头拼多多是中国科技公司中最年轻的招聘公司之一。据职场社交网站脉脉 2020 年的最新数据，其员工的平均年龄为 27 岁。脉脉数据还显示，快手员工的平均年龄为 28 岁，滴滴出行员工的平均年龄为 33 岁。据中华全国总工会统计，中国劳动者的平均年龄为 38.3 岁。&lt;/p&gt; 
&lt;p&gt;随着科技行业一波又一波的裁员潮 (由经济放缓和监管问题驱动)，这种趋势变得更加根深蒂固。&lt;/p&gt; 
&lt;p&gt;快手自 2021 年在香港上市以来的股价已下跌 88%，根据其最新财报，其员工总数在 2021 年 12 月 (当时拥有 2.8 万名员工) 和 2023 年 6 月之间减少了 16%。&lt;/p&gt; 
&lt;p&gt;「科技行业在疫情之前扩张得太快，然后政府的监管整顿开始了。我们现在正在削减昂贵的中层管理人员」， 另一家互联网公司的一位经理说。&lt;/p&gt; 
&lt;p&gt;「35 岁门槛」 是科技工作者焦虑的主要来源。招聘平台拉勾找聘去年的一项调查发现，87% 的程序员「非常担心」在 35 岁之后被解雇或找不到新工作。&lt;/p&gt; 
&lt;p&gt;杨律师表示，35 岁以上的人失业后很难找到新工作。&lt;/p&gt; 
&lt;p&gt;中国许多公务部门的录用考试都将年龄限制在 35 岁以下。服务行业 (包括餐馆和酒店) 的招聘广告也更想要年轻的求职者。这使得 30 多岁的科技员工在更换职业或在职位之间寻找临时工作机会时几乎没有选择余地。&lt;/p&gt; 
&lt;p&gt;一位 38 岁的程序员最近从一家主要叫车集团被解雇，他说找新工作很困难。「就业市场非常糟糕，甚至比去年还要糟糕，尤其是对我这样的老工程师来说」，他说。&lt;/p&gt; 
&lt;p&gt;最终，老白觉得自己是幸运的少数人之一。&lt;/p&gt; 
&lt;p&gt;「我有两个孩子，我的妻子不再工作。当时另一家科技公司只招聘一个管理职位，我很幸运地得到了它。如果没有这个机会，我就会像许多前快手员工一样失业。」&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;本文转载自&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjandan.net%2Fp%2F116321%23%2F&quot; target=&quot;_blank&quot;&gt; 煎蛋&lt;/a&gt;，译者：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjandan.net%2Fp%2Fauthor%2Fbali&quot; target=&quot;_blank&quot;&gt;BALI&lt;/a&gt;&lt;br&gt; 英文原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F5cf306ad-3a39-4357-b7b3-1d2644bb13a7&quot; target=&quot;_blank&quot;&gt;FT&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290381</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290381</guid>
            <pubDate>Tue, 30 Apr 2024 11:20:44 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源日报 | 微软挤兑 Chrome；阳痿中年的福报玩具；神秘 AI 能力太强被疑 GPT-4.5；通义千问 3 个月开源 8 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.4.30&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要点&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ttauVzyVnFKij2jwNbWag&quot; target=&quot;_blank&quot;&gt;神秘大模型性能超越很多开源模型和 GPT-4&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;就在昨夜，整个 AI 社区都被一个神秘大模型震撼到了：它名为 gpt2-chatbot，性能直接超越很多开源模型和 GPT-4！网友们展开猜测，有说它是 GPT-4.5 的，有说是 GPT-5 的，还有人猜它是 GPT-4+Q*，或 GPT-2+Q*。奥特曼也卖起了关子：「我确实对 gpt-2gpt2 情有独钟。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8c67a4262b67d0cfce83895ad686bef60da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/290276/ubuntu-24-10-codename-oracular-oriole&quot;&gt;Ubuntu 24.10 代号为 &quot;Oracular Oriole&quot;&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Ubuntu 24.04 LTS 才刚刚&lt;a href=&quot;https://www.oschina.net/news/289586/ubuntu-24-04-noble-numbat-lts&quot;&gt;发布&lt;/a&gt;，下一个版本 Ubuntu 24.10 近日也已确定了代号 ——&amp;nbsp;Oracular Oriole（神谕黄鹂）。Ubuntu 24.10 大概率会采用 Linux 6.11 内核、GNOME 47 桌面、GCC 14.1 编译器以及其他升级。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-534454039ec76beda91938adbea74fb9f06.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fa%2F294639&quot; target=&quot;_blank&quot;&gt;通义千问开源王炸，1100 亿参数称霸开源榜单，中文能力全球第一&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;一款开源模型火不火，看生态中的产品对他的支持有多快就知道了。&lt;/p&gt; 
&lt;p&gt;4 月 26 日，通义千问一言不合又开源了，直接甩出 1100 亿参数的王炸模型 Qwen1.5-110B ，刷新开源模型性能新高。模型发布还不到 24 小时，Ollama 便火速上线了对 110B 的支持。这意味着你除了在魔搭社区和 HuggingFace 上白嫖 Demo 以外，能在模型发布的第一时间，就将它部署到你自己的电脑上。&lt;/p&gt; 
&lt;p&gt;在发布当天，Qwen1.5-110B 占领了 Hacker News 热度榜首一段时间，上一次有这么多热度和讨论，还是去年 8 月通义千问首次宣布开源的时候。不过，人们讨论的方向，已经从当时的「这是什么？」转变为认真的讨论「这有多强？」。质疑的噪声随着 Qwen 的实力增强逐渐消散。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-84d884b94aed857c096f07ed8db1c65faaa.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOc5bSoLv0&quot; target=&quot;_blank&quot;&gt;神秘 AI 能力太强被疑 GPT-4.5&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;一个神秘模型突然杀入众人视野，能力超越一众开源模型，甚至包括 GPT-4。几乎所有人都在谈论它，服务器都被挤爆了。&lt;/p&gt; 
   &lt;p&gt;它就是「gpt2-chatbot」。（注意啊，是 gpt2 不是 GPT-2）&lt;/p&gt; 
   &lt;p&gt;它有多强？IMO 国际数学奥林匹克竞赛的题目，一次答对。&lt;/p&gt; 
   &lt;p&gt;在 GPT-4 标志性能力「画独角兽」上，还能轻松秒杀 LLaMA-3-70B。&lt;/p&gt; 
   &lt;p&gt;推理方面更是表现出了惊艳效果，常见逻辑陷阱可以轻松绕过，而且回答时还带有合适的语气。&lt;/p&gt; 
   &lt;p&gt;如此好的表现，但是又没明说身份……&lt;/p&gt; 
   &lt;p&gt;这不是更让大伙兴奋了！&lt;/p&gt; 
   &lt;p&gt;难道是传说中的 GPT-4.5？&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;量子位&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5955106173%2FOc1hU88Zh&quot; target=&quot;_blank&quot;&gt;阳痿中年的福报玩具&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4461a461b7399c4e4b4bf971466c325cc3f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;stage1st 宅社区&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOc74bhfqU&quot; target=&quot;_blank&quot;&gt;通义千问 3 个月开源 8 模型&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;开源大模型，已经开启大卷特卷模式。&lt;/p&gt; 
   &lt;p&gt;全球范围，太平洋两岸，双雄格局正在呼之欲出。&lt;/p&gt; 
   &lt;p&gt;Llama 3 中杯大杯刚惊艳亮相，国内通义千问就直接开源千亿级参数模型 Qwen1.5-110B，一把火上 Hacker News 榜首。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3c42833259d703ffb1e7e26f56b8eb46d7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;不仅相较于自家 720 亿参数模型性能明显提升，在 MMLU、C-Eval、HumanEval 等多个基准测试中，Qwen1.5-110B 都重返 SOTA 开源模型宝座，超越 Llama 3 70B，成最强开源大模型。&lt;/p&gt; 
   &lt;p&gt;值得关注的是，这已经是 3 个月内通义千问开源的第 8 款大模型。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;量子位&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1806446424%2FOc5AWqwxC%3F&quot; target=&quot;_blank&quot;&gt;微软利用平台霸主的地位挤兑 Chrome&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;微软 Edge 用着别人谷歌的 Chromium 开源引擎，又利用平台霸主的地位挤兑 Chrome，真的难怪火狐当时挤破脑袋都要自己开发系统平台，最起码谷歌有 Android 和 Google Chrome OS，后路都给自己留着呢。同样，这个说法也能延伸至华为的鸿蒙系统，有自己的系统平台真的可以硬气很多。 ​​​&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;小啤 Derek&lt;/strong&gt;&lt;/p&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240430A021II00&quot; target=&quot;_blank&quot;&gt;从微盟再获融资，看中国 SaaS 企业如何正确过冬&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;从 SaaS 行业的需求侧、供给侧和资本市场来看，当前的 SaaS 行业正处于低谷期。&lt;/p&gt; 
   &lt;p&gt;需求侧，受宏观经济影响，企业或多或少缩减了数字化转型开支，SaaS 企业面临新客户增长放缓和现有客户订购量减少的风险。&lt;br&gt; 资本市场，SaaS 产业投融资环境正在变得更为成熟和理性。投资人从关注增长速度转向关注企业的盈利能力和持续性，更倾向于投资那些已经在市场上证明自身拥有清晰盈利路线图的企业。&lt;/p&gt; 
   &lt;p&gt;截至目前，SaaS 市场最新的融资消息来自于微盟。近日，微盟集团发布三则公告，其新股配售协议下的所有条件均已达成，公司成功完成配售，所得款项净额约为 3.08 亿港元；此外，微盟已成功发行 8500 万美元可转债。两者叠加，在原 21 年 cb 持有的投资者、公司现有股东腾讯及新投资者的合力支持下，微盟集团总计募得款项 1.25 亿美元。&lt;/p&gt; 
   &lt;p&gt;供给侧，SaaS 企业感受到行业寒潮，逐渐回归价值本质。「降本增效」成为 SaaS 企业普遍认同的策略，但不同的企业走出了不同的降本增效路径。有的 SaaS 企业只关注短期利益，手拿降本增效的大刀砍向「裁员」、「降薪」、「关停业务」。也有的 SaaS 企业注重长期价值，多措并举打好降本增效「组合拳」，而微盟正是其中的一员。&lt;/p&gt; 
   &lt;p&gt;微盟集团年度报告显示，2023 年微盟集团实现了总营收 22.28 亿元，同比增长 21.1%。毛利润达到 14.84 亿元，毛利率提升至 66.6%。经调整 EBITDA 大幅收窄至-0.75 亿元，同比减亏 93.1%；经调整净亏损同比大幅减少 73.4%。&lt;/p&gt; 
   &lt;p&gt;同一赛道，不同选择会有不同境遇，看来如何高质量的降本增效也是一门学问，微盟这个例子值得考量。&lt;/p&gt; 
   &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;- &lt;strong&gt;刘旷&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5198011111%2FObYZoryxn&quot; target=&quot;_blank&quot;&gt;文档比较工具&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;1、WinMerge 是一个在 Windows 系统下运行的开源差异比较和合并工具。软件从官网（winmerge.org）下载，安装好以后，打开可以支持中文。它可以比较文件夹和文件，支持文本、图片、表格、网页、二进制文件等多种格式，并以可视化的方式呈现差异，非常易于理解和处理。&lt;/p&gt; 
   &lt;p&gt;2、Diffchecker：www.diffchecker.com，只需上传两个文件，即可进行文档对比。它支持文本、图像、PDF、Excel 等多种格式。对比文件夹需要用 Pro 版。&lt;/p&gt; 
   &lt;p&gt;3、Meld：meldmerge.org，是一款开源的跨平台文档对比软件，适用于 Windows、Linux 和 macOS 等操作系统，支持比较文本文件、文件夹和图像文件。&lt;/p&gt; 
   &lt;p&gt;4、KDiff3：kdiff3.sourceforge.net，也是一款跨平台的文档对比软件，同样支持文本文件、文件夹和图像文件的比较，适用于多种操作系统。&lt;/p&gt; 
   &lt;p&gt;5、ExamDiff：prestosoft.com，可用于比较文件夹、文件和文本内容。整体效果不如 WinMerge，可以留作本用的选择。&lt;/p&gt; 
   &lt;p&gt;6.云库工具：libkit.cn/compare，可以比较 PDF 和 Word。除了提供文档比较外，还可以转换文件格式和 CAD 预览。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;班叔&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.36kr.com%2Fp%2F2755342482373640&quot; target=&quot;_blank&quot;&gt;谷歌不行？股价却新高，Meta 逆天？蒸发 1.6 万亿…微软：都是弟弟&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;纵观 Meta、Alphabet、Microsoft 新一轮的财报表现，不难看出生成式人工智能已经全面渗透到业务管道的方方面面，成为驱动企业增长的核心引擎。&lt;/p&gt; 
 &lt;p&gt;微软的成功尤为典型，凭借多个 AI 软硬件前瞻布局稳居头把交椅，各项业务高速起飞。&lt;/p&gt; 
 &lt;p&gt;Meta 的巨额 AI 投入虽然令投资者心惊肉跳，能否尽快实现商业化盈利仍是未知数，但 AI 助推下广告收入已成效初显。有了 Llama 大模型和算力加持，扎克伯格打造全球 AI 领军企业的决心与雄心不容小觑。&lt;/p&gt; 
 &lt;p&gt;至于老大哥谷歌，终于在 AI 大战中找到了自己的节奏。Gemini、TPU 等武器已磨刀霍霍，准备在 AI 浪潮中加速寻找新的增长点。&lt;/p&gt; 
 &lt;p&gt;三大巨头对人工智能发展方向的判断出奇一致，且都祭出了真金白银投入这场未来科技变革的豪赌。站在时代风口，AI 最终能带他们飞得多高多远，全球科技行业的目光都将望向这里。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;硅星人&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Fjjxw%2F2024-04-30%2Fdoc-inatqhcc2254451.shtml%3Fcref%3Dcj&quot; target=&quot;_blank&quot;&gt;深圳制造：画出「第二增长曲线」&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;今年一季度，深圳规模以上工业增加值同比增长 11.5%，比上年同期提高 7.0 个百分点。规模以上制造业增加值同比增长 11.8%，高技术制造业增加值同比增长 13.1%。作为全国「工业第一城」，在庞大基数下实现这一成就颇为不易。&lt;/p&gt; 
 &lt;p&gt;这得益于深圳牢牢扭住新型工业化这个关键任务，不断夯实市场主体、产业投资、产业生态基础，不断完善产业链，集聚创新资源，塑造新优势，注入新活力，勇闯新赛道，持续攀向全球产业链价值链高端，画出「第二增长曲线」。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;strong&gt;- 深圳特区报&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.21jingji.com%2Farticle%2F20240430%2Fherald%2Fb9fe34edbb4aa9520746c1d076dd6721.html&quot; target=&quot;_blank&quot;&gt;专访智谱 AI 王绍兰:技术派与市场派相辅相成，不能只研究技术也不能只关注变现 &lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;「技术派与市场派并不矛盾，他们是在创新链条的不同层面考虑问题。大家不能只做技术研究，也不能只关注市场变现，这两件事是相辅相成的。」4 月 26 日，在 2024 中关村论坛「硬科技投资与发展论坛」期间，智谱 AI 总裁王绍兰在接受 21 世纪经济报道记者专访时，谈到对这个时下热点话题的看法。他认为，整个创新的链条是从思想、理论、方法、技术到产品、市场。市场派关注后端的产品和市场，技术派关注前端的理论、方法和技术，这其实是整个链条上不同层面的事情，不存在说非此即彼的关系。&lt;/p&gt; 
 &lt;p&gt;只是有的公司会选择将大部分精力放到产品和市场上，有的公司会把精力放在整个链条上，重视理论、方法、技术、产品、市场的全链条创新。不同公司会从自身角度出发，做出不同的选择。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;-&amp;nbsp;&lt;strong&gt;21 世纪经济报道&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fimmersive-translate%2Fimmersive-translate&quot; target=&quot;_blank&quot;&gt;immersive-translate/immersive-translate&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1afadb3261d52dc2bf030e549ccb9277d3b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fimmersive-translate%2Fimmersive-translate&quot; target=&quot;_blank&quot;&gt;https://github.com/immersive-translate/immersive-translate&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;沉浸式网页双语翻译扩展，完全免费使用，支持 Deepl/Google/ 腾讯 / 火山翻译等多个翻译服务，支持 Firefox/Chrome/ 油猴脚本，亦可在 iOS Safari 上使用。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/5783135/blog/11066139&quot; target=&quot;_blank&quot;&gt;模型量化与量化在 LLM 中的应用&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;关于 LLM 的量化工作目前的 SOTA performance，基本上都是基于 weight-only 的量化模式，模型在 GPU 运行所需的显存降低是其主要的贡献。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;总体来说，LLM 领域的量化工作还很初步，若在实际任务中对模型的表现精度要求十分高，更推荐单纯基于 KV cache 等方向提高单位显存吞吐量的算法和工具，如 Flash Attention-2、Paged Attention 等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;208&quot; src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e0baba60e63449bcabb5eef69423fe09~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=ss3lUGzh0Zdpq1B3wVqt9n9hvJ8%3D&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;div&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;事件点评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290261/google-lays-off-staff-flutter-dart-python&quot; target=&quot;_blank&quot;&gt;谷歌证实裁员，涉及 Flutter、Dart 和 Python 团队&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，有关谷歌对 Flutter、Dart、Python 等关键团队进行了裁员一事在社交媒体上广为流传。对此，谷歌则向外媒&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F04%2F29%2Fgoogle-lays-off-staff-from-flutter-dart-python-weeks-before-its-developer-conference%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 证实&lt;/a&gt;，该公司确实已经进行了裁员，但没有透露具体的团队、角色以及裁员人数。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;但谷歌方面澄清道，此次裁员并非全公司范围内的裁员，而是正常业务过程中的重组，受影响的员工将能够申请谷歌的其他空缺职位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;334&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0430/104944_yBq9_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;这次裁员事件可能反映了科技行业内部的一些更广泛趋势，包括对效率和成本效益的追求，以及对特定技术或产品线的重新评估。同时，这也是谷歌在不断变化的市场环境中调整其资源分配和业务重点的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;裁员事件反映了科技行业快速变化和波动的特性。随着市场和技术的不断演变，公司需要灵活调整其资源分配和业务重点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;而谷歌作为科技行业的领导者，其决策和战略调整受到市场的密切关注。这次裁员可能会影响投资者对谷歌未来发展和战略方向的看法。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290311/google-play-rejected-228-million-risky-android-apps-2023&quot; target=&quot;_blank&quot;&gt;2023 年 Google Play 拒绝了 228 万款有风险的 Android 应用&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.googleblog.com%2F2024%2F04%2Fhow-we-fought-bad-apps-and-bad-actors-in-2023.html&quot; target=&quot;_blank&quot;&gt;报告&lt;/a&gt;称，该公司在 2023 年共阻止了 228 万款违反政策的 Android 应用在 Google Play 上架。以及发现并屏蔽了 333,000 个上传恶意软件、欺诈性应用程序或多次严重违反政策的 Google Play 帐户。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;相较之下，在 2022 年谷歌共封杀了 150 万个 &quot;不良&quot; 应用，并封禁了 17.3 万个严重违反商店政策的开发者账户。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;264&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-065db484eb169bd9c9a6e57b419bca6ab83.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一数字反映了移动应用市场在安全、监管和用户信任方面面临的复杂挑战。随着移动设备的普及，移动应用市场迅速增长，但同时也带来了监管和安全的挑战。谷歌需要不断更新其审查机制，以应对新出现的威胁和违规行为。谷歌在保护用户安全的同时，也需要确保用户能够轻松获取所需的应用程序。这一事件显示了在安全性和用户便利性之间找到平衡点的重要性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于开发者来说，遵守 Google Play 的政策和标准是一个持续的挑战。谷歌对政策要求的更新和加强，意味着开发者需要不断学习和适应。虽然谷歌在 Google Play 上采取了严格的安全措施，但第三方应用商店可能没有类似的安全保障。这可能导致用户面临更高的安全风险。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;随着技术的发展，恶意软件和违规应用的开发者也在不断寻找新的方法来规避审查。谷歌必须持续更新其安全措施，以保持领先。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290336/openai-financial-times&quot; target=&quot;_blank&quot;&gt;OpenAI 与英国《金融时报》签署内容许可协议&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fcontent-partnership-with-financial-times&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;与英国《金融时报》达成合作，使其大型语言模型获得对《金融时报》文章的访问权。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;作为合作的一部分，两家公司将向 ChatGPT 用户提供《金融时报》的一部分内容。 OpenAI 表示，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;通过此次合作，ChatGPT 用户将能够看到&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;「精选的摘要、引述以及《金融时报》新闻报道的链接&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以回应相关查询&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;」。不过 OpenAI 没有具体说明内容何时可以访问或在哪些版本的 ChatGPT 中进行访问。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06b25d557240271062545cebf0391473d0e.png&quot; width=&quot;356&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;点评&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一合作不仅为 OpenAI 的用户提供了更丰富的内容来源，还标志着人工智能在新闻领域应用的一个重要里程碑。通过与《金融时报》的合作，OpenAI 能够提供更准确、更相关的信息检索服务，同时《金融时报》的内容也因此得到了更广泛的传播和利用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;还可能对新闻行业的商业模式产生影响。随着越来越多的媒体公司与 AI 公司合作，新闻内容的生产和分发方式可能会发生改变。这种合作可能为新闻机构带来新的收入来源，同时也为 AI 公司提供了更高质量的数据集来训练其模型。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;以及可能促进 OpenAI 在人工智能领域的竞争。未来可能会出现更多类似的合作伙伴关系，推动人工智能和新闻行业的进一步融合和发展。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fm.huanqiu.com%2Farticle%2F4HavNyV7kMO&quot; target=&quot;_blank&quot;&gt;「天工」惊艳亮相，人形机器人距离生活还有多远？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;通用智能的发展面临着技术性、生物性和社会性三大瓶颈。技术性瓶颈表现在人工智能系统需要具备更高的计算能力、更先进的算法和更有效的数据处理方法，以实现更复杂、更智能的功能；生物性瓶颈主要体现在我们对人类大脑认知能力运作机制的理解还非常有限，要实现类似的智能水平需要更深入的神经科学和认知研究；社会性瓶颈则包括了人工智能系统与人类社会的融合问题，例如文化差异、伦理道德、隐私保护等。「克服这些瓶颈需要跨学科的合作和持续的创新努力，只有在技术、生物和社会方面取得突破，通用智能才能迈向更加成熟和全面的发展，但极难实现。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;strong&gt;环球时报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn786916350&quot; target=&quot;_blank&quot;&gt;投资者只想看 AI 赚钱，不想听 AI 烧钱&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;2024 开年，海外互联网巨头开始兑现 AI 业务的商业化潜力。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;过去一周，谷歌、微软、Meta 相继公布 2024 年一季度财报，三者有喜有忧。微软、谷歌财报发布后分别上涨 4%、15%，后者更是触及历史新高；相比之下 Meta 却遭遇滑铁卢，财报发布后股价一度跌幅达 19%。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&amp;nbsp;&lt;/span&gt;&lt;strong&gt;极客公园&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMTA3NDI5ODU0MQ%3D%3D%26mid%3D2656022029%26idx%3D1%26sn%3Dbebf1a0dc9ef6bfe2ebf9c6af833b5fc%26scene%3D0&quot; target=&quot;_blank&quot;&gt;资本高手周亚辉，能否守住 500 亿？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型时代到来，资本圈著名「风口捕手」周亚辉又毫不意外地将 AI 划入了自己的版图。他实控的昆仑万维股价在 2023 年扶摇直上，一度创下了暴涨四倍的「神话」。然而喧嚣之下，昆仑万维要在大模型市场中持续掘金，也并非易事。2024 年一季度，昆仑万维归母净利润同比大跌 188%，创下近十年最糟糕纪录。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;-&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;市界&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5ODAxMjU2MA%3D%3D%26mid%3D2649768479%26idx%3D1%26sn%3D0a28edd8a40cbbdef61358927a2b985d%26chksm%3Dbed5d1e089a258f643fedca2717d28f6a109d4b8e0f46148caf5e1cb9785a40c3f31c71afce2%23rd&quot; target=&quot;_blank&quot;&gt;字节跳动发起 AI 战争，寻找下一个 TikTok&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;现如今在字节跳动，已近乎隐退的张一鸣，只重点关注两件事：其一，是风暴中的 TikTok；其二，就是字节跳动正在全力追赶的 AI 战略业务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;提及字节的 AI 战略远望，多个接近字节的人士均认为，以 Flow 部门出品最为「正统」，「虽然很多子业务都在做相关的事情，比如飞书，但管理层层面还是认为 AGI 之战还是以 Flow 为主」。&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;凤凰网科技&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/290261/google-lays-off-staff-flutter-dart-python&quot; target=&quot;_blank&quot;&gt;谷歌证实裁员，涉及 Flutter、Dart 和 Python 团队&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：把 flutter 和 compose 团队合并，发力 compose 吧，flutter 的绘制引擎也可以移植到 compose 了&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：这个是最靠谱的&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：flutter 不应该走邪门歪道，用个 dart&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：本来就是半只脚进入棺材的语言，硬是拽出来，现在来这一出，前景又变得不明朗。不知道谷歌那帮人是怎么想的。&lt;/span&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：因为可控啊，dart 自己说了算，如果 ts 没那么快那么火，dart 还是有机会的，但是败给了 ts&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：&quot;Flutter EngProd team 整个被裁了。劈柴真有你的👍&quot; / ...&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：其实从 2 前 flutter 总部团队的大部分招聘工作就已经停止了，但 flutter 和 dart 不会消亡&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：还不如收购 uniapp&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_alkdk1PBxbh88qzbVB4gw&quot; target=&quot;_blank&quot;&gt;华为立大功、为中国工业软件里程碑贡献全部开源代码&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：虽然法国是 OCCT 母社区，但 GitHub 上 OCCT 的核心开发者都是俄罗斯人，离了俄罗斯人，法国母社区也运营不下去。于是华为出手收编，迁移到中国，修改名字恢复开源和社区运营，有什么问题呢？平时很少夸华为，但这个工作的确做得不错。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：华子这波是白嫖计算机皇冠上的明珠啊&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：懂开源世界不， 请保持谦虚，否则暴露的就是自己的无知，自己像个小丑在众目睽睽下乱蹦哒，还不自知。&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：这个就是捡漏，算不上什么自研&lt;/span&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：有什么精神洁癖，虽然中途接手，但是团队是花钱养着专职写代码，讲道理可以闭源转商用专供自己卖产品&lt;/span&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：华为：来得早不如来得巧，感谢美国老铁送来的助攻&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：我这两年就在用 OCCT 搞开发，资料少，布尔操作性能差，缺少一些关键算法等问题，需要自己去搞，如果华为能把这些问题解决了，中国的工业软件发展会更顺利&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：这个是牛掰了&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FE3t4pzr-OH02Du7eNXS7hQ&quot; target=&quot;_blank&quot;&gt;Go 新提案：返回值应该明确使用或忽略？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：完备的语言是不存在的&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：处理可能存在的错误是必须的，语言层面上没有问题。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：这个提法本就有问题，一个不愿意处理错误的人，你只要有忽略的办法他总是会忽略，而且这个增加会让忽略变得更复杂，代码看起来也更复杂，_就已经是最好的方案&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：简单有效的，各取所需的解决方案：用检查工具或者编译器属性来检查&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290370</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290370</guid>
            <pubDate>Tue, 30 Apr 2024 10:21:02 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>​MySQL 的第一个长期支持版 8.4 GA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MySQL 的第一个长期支持版 8.4&amp;nbsp;GA，一些具体变更内容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能增加/更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;认证插件：默认情况下，「mysql_native_password」认证插件被禁用，如果用户需要兼容旧的应用程序，需要在启动 MySQL 服务器时，启用该插件 「--mysql-native-password=on」&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;克隆插件：克隆插件对于版本的要求放宽，允许在同一个大版本内进行克隆，不再要求小版本必须一致。例如，可以从 8.4.0 克隆至 8.4.14。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;支持在 Windows 上使用基于 SASL 的 LDAP 认证，Windows 的客户端可以使用 GSSAP/Kerberos 和「authentication_ldap_sasl_client」插件进行认证。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主从复制中「SOURCE_RETRY_COUNT」选项值变更为 10，默认情况下，主从复制将在 10 分钟内，每 60 秒尝试一次重新连接。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主从复制中的「START REPLICA」的「SQL_AFTER_GTIDS 」选项支持多线程回放（MTA）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;主从复制中使用的大量 「MASTER」/」SLAVE」被删除，用户需要使用「SOURCE」/「REPLICA」替代。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;「mysqldump」中增加「--output-as-version」选项，支持从 8.2 以后版本的 MySQL 服务器兼容旧的 MySQL 服务器。该选项值为「SERVER」，「BEFORE_8_2_0」，和「BEFORE_8_0_23」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;组复制的「group_replication_set_as_primary()」函数在选择新的主要成员时，将等待正在进行的 DDL 结束。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;「group_replication_consistency」系统变量的默认值从「EVENTUAL」改为「BEFORE_ON_PRIMARY_FAILOVER」。「group_replication_exit_state_action 」系统变量的默认值改为「OFFLINE_MODE」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;增加自动更新直方图功能。当启用该功能后，无论是否执行「ANALYZE TABLE」，都将自动更新直方图。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在「Performance_Schema」中增加线程池的连接信息，并增加「tp_connections」表，用以显示每个线程池的连接。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了上面的部分增加内容，在该版本中还对一部分功能进行了删除和降级，包括去除了大量的「MASTER/SLAVE」等等，想要了解详细内容，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;可访问&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.oracle.com%2Fmysql%2Fcategory%2Fmsq-announcements&quot; target=&quot;_blank&quot;&gt;MySQL 官网&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;。&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;稿源：&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fd-4LL0efkXYgcaFrNeQ-eQ&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/d-4LL0efkXYgcaFrNeQ-eQ&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290362/mysql-8-4-0-ga</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290362/mysql-8-4-0-ga</guid>
            <pubDate>Tue, 30 Apr 2024 09:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>模型量化与量化在 LLM 中的应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                        
                                                                                            &lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;一、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;模型推理优化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;随着模型在各种场景中的落地实践，模型的推理加速早已成为 AI 工程化的重要内容。而近年基于 Transformer 架构的大模型继而成为主流，在各项任务中取得 SoTA 成绩，它们在训练和推理中的昂贵成本使得其在合理的成本下的部署实践显得愈加重要。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型推理所面临的挑战主要有以下两点：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;巨大的内存（显存）需求，主要来自于模型本身参数和推理的即时需求。&lt;/span&gt;&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于一个 LLaMA2-30B 的模型，载入显存其模型本身需要约 60GiB 的显存，推理过程中，单个 token 的 KV cache 需要 1.6MiB 左右的显存：6656(layer dim) * 52(layer num) *2 (K &amp;amp; V) * 2(fp16, 2bytes)；对于一个 2048 个 token 的请求则需要 3.3GiB 的显存。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;并行性较差，因为生成过程通常在时序上是一个串行的过程，导致 decoding 的过程较难并行，成为计算的瓶颈。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;常见的推理优化方式有知识蒸馏（Knowledge Distillation,KD），剪枝（Pruning）和量化（Quantization），以及针对 LLM 的内存优化而提出的各种方案（如 Flash Attention、Paged Attention 等）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;蒸馏指通过直接构造小模型，作为学生模型，通过软标签与原标签结合的方式监督学习原模型的知识，从而使小模型具备与原模型相当的性能，最终用小模型代替大模型从而提高推理效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e0baba60e63449bcabb5eef69423fe09~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=ss3lUGzh0Zdpq1B3wVqt9n9hvJ8%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：Knowledge Distillation: A survey,2021,p2】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;剪枝则是通过靠剪除模型中不重要的权重从而给模型「瘦身」，提高模型的推理效率，为了保证模型的能力，通常剪枝过程也需要伴随着模型基于训练数据的微调。根据剪除权重的维度不同，可以分为结构化剪枝（structured pruning）和非结构化剪枝（unstructured pruning）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;结构化剪枝：通常按权重张量的某一或多个维度成块剪除不重要的通道，并保持正常的矩阵乘法；但因剪除的通道影响上下层的推理，需要检查网络的逻辑准确性。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;非结构化剪枝：随机剪除权重张量中的不重要的元素，因而它通常会保持原本的权重结构，而造成稀疏的乘法计算，但并不能适配于通用的硬件，因而需要专用的硬件才能实现加速。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前剪枝在 LLM 中的应用较少，如以下基于 Activation-aware 的剪枝工作[1]，主要是基于权重本身的的绝对值大小和输入张量的绝对值大小做非结构化剪枝，使权重张量本身稀疏化，而模型的精度损失也并不能达到工程化的要求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e7e5508004b24cdeb0bd154e990418d0~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Qdo%2BZ1tLIvF9fKdV4VUiTqWdqJw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：A simple and effective pruning approach for large language models,2021,p2】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;再如下图最近结构化剪枝的工作[2]，通过搜索的方法寻找模型中的子结构，并通过重训练以保持模型精度，剪枝后的模型的精度相比原模型有很大的降低，只能跟同等参数量（剪枝后）的其他较小模型比较以显示其方法的意义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/7b6c620e09e74c9abcbd33fff9a6dd49~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=U%2FUWwQ4VWrgyqwq6CjMMUA4RWnA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处: Sheared LLaMA: accelerating language model pre-training via structured pruning,2023,p3】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/00134831ed024be48c1ac72f1aec84e6~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=WnkyFfSYyVwUAHk2XOR%2BBwMMpJY%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处: huggingface/Sheared-llama-1.3B】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而量化之所以会成为神经网络以及 LLM 的首选，主要有以下的优点：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;降低显存的直观体现。&lt;/span&gt;&lt;/span&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;一般 LLM 权重用 FP16 存储，而权重量化为 int4 之后，则直观上体积减小为原本的 1/4（实际可能由于 embeddings 不量化，内存分配等一些原因会稍多一些），对显存的资源需求大大降低。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W4A16、W8A16 等算子的加速，从而提升计算速度。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;二、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;量化简介&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;base&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化的本质通常是将模型的参数，或整个模型的推理过程从浮点转化为整型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化参数通常由 scale 和 zero-point 两个值构成，前者为浮点，后者为整型。设 x 为一个张量（它可以为权重，也可以是推理的中间变量），其量化过程可以表示如下，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/eb26ac1a556c4c79899c16992cfbe617~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=H9DiJOMJVp8iBCdLszMvREmXJRM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;用 b 表示量化位宽，q{min}与 q{max}分别表示整型值域的范围，例如 int-8 量化可以取[-128,127]，即 q{min}=-2^(b-1)=-128，q{max}=2^(b-1)-1=127，clamp(a;q{min},q{max}) 表示输入值 a 基于[q{min}, q{max}]范围的截断操作，x{int}表示量化后的结果，s 和 z 表示量化参数 scale 和 zero-point。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/1675fd7b528140b8a270d5bada578e82~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=8FGiFlmbGrG%2Blv%2B86O%2FqysMR1HU%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/71a6e1af1b41487095957ea901bbda5a~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Ws%2B%2B7MieS1VxHnY3Q0NNdN%2F%2BJR4%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：A Survey of Quantization Methods for Efficient Neural Network Inference,2021,p5；An Introduction to Quantization of Large Language Models,p12】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而从整型到浮点的反量化过程如下，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/2259456a815c45c285c7a8aaf9b5566c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=T3YO%2BM5nphkYMJH%2BupT8rGmQdYw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;关于量化参数，有很多算法基于搜索，最优化，LKD(layer-by-layer 蒸馏) 等各类算法计算其较优解，从而尽可能减少量化引起的精度损失；而最直接的计算 scale 和方法即是基于张量元素 min/max。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d1ed6e3e667c4ca6a654413379885748~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=06n%2BOoD53lNRxKdPH6NFeNHh6Hk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;以下是一段简单的代码表示张量 x 从 fp32 量化到 int8 整型，再反量化回 fp32 的示例：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;x-&amp;gt;x{int}-&amp;gt;x_hat 的过程的一个示例如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/568b26b30940408098e8f0b09324a262~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Xj9H9kSlhMCye1mewEEV3QNd2wE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化前 x：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/5556edfac226493f912d51e80ae2b29a~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=bIFt9g%2BMTrFYB3jEjxdQs1jFHL0%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化后 x_hat：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d181acb387324033a7adefe417094d66~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=IoF605%2FPK4%2FQ6uKrGKL0e3%2FiqVU%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;对称/非对称&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;相比于非对称量化，对称量化的定义是量化所映射的整型值域基于 0 值对称，即上述公式的 zero-point 为 0，qmax = -qmin，从而使量化的表达形式更为简化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;非对称量化有利于充分利用量化范围。例如 Conv+ReLU 输出的激励张量，其值皆为正值，若使用对称量化，则浮点将全部映射到[0~127]范围，有一半的范围未使用，其量化精度不如非对称量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/efc84790d1d649a2bb3e7c34533fb2b1~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2B8rIgSC28fC0FlRxazrbuUEJzjA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：A Survey of Quantization Methods for Efficient Neural Network Inference,2021,p5】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;实际中往往选择对权重张量做对称量化，而对输入张量做非对称量化。以下是来自 qualcomm 的量化白皮书中的分析，如权重和输入都选择非对称量化时，以 Linear 层的矩阵乘法为例，将表达式展开如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/bba17e921657409bb77c4d7f2c888d0e~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=jBZ15Juhy5am%2FUAvoidMIIwggyk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第一项是整型张量的乘法操作，是必须的即时操作；&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第三、四项的操作包含了 scale，zero 和整型权重的乘法，这些都是提前预知的，因而可以事先计算作为偏置加上；&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;第二项的计算依赖 x{int}，是每次推理需要即时计算的，而这会造成额外算力。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;因而当我们将权重量化改为对称量化时 (zW=0)，则上式简化为如下，即时计算时，只需要计算第一项的矩阵乘法，第二项是预先算好的偏置项：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/87a8d6decd7541a98c409fdf7bb3c479~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=r%2BrBsTbVupMzDdI63wVc5PU04UQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而当两者都是对称量化时的表达式，则简化如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/43fd186d8bb64c26a67a641015e8ab7c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=AOG7ZT4q08TA9muSr%2FjjfjyrzQI%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;对比原模型中的浮点计算 W{x}，W{int}x{int}是整型与整型之间的乘法，后者在 Nvidia GPU 上的运算速度远快于前者，这是量化模型的推理速度大大加快的原因。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;三、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;LLM 的量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;Challenges in LLM Quantization&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从模型表现的角度来讲，量化自始至终要解决的一个前提是，如何保持量化后模型的精度，即让模型的使用者觉得量化后的模型在推理效率提高的同时，还能保持原来的性能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;神经网络中需要量化的操作主要是卷积层 Conv(x;W) 和全连接层 Wx，即主要是按上一部分描述的操作分别对 W 和 x 做的权重量化（Weight Quantization,WQ）和激励量化 (Activation Quantization,AQ)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;而不同于 CNN 模型或者小型 Transformer 模型，基于 Transformer 的大模型的矩阵乘法产生的激励张量通常有较多的离群值 (outliers)，即离值分布的大多数点形成的点群较远的值, 这些绝对值较大但占比较低的元素值增加了量化难度。而如何取舍 outliers 通常是量化工作中的一大难点，若过分考虑之，则会因量化范围过大而降低量化的表达范围，若过分截断之，通常会因这些绝对值较大的值，在模型推理中对结果有较大影响，而导致模型效果变差，而后者在 LLM 的量化则尤为明显。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;下图分别是 Resnet18 与 Opt-13B 的某层输入张量的元素值统计，sigma 表示各自分布的标准差，Resnet18 输入的极大值约为 28sigma，且绝对值 6sigma 以外的比例在 0.05%；而 Opt-13B 网络输入的极大值越为 325sigma，且绝对值 6sigma 以外的比例在 0.2%。从量化效果而言，Resnet18 的 int-8 精度基本无损失，而 Opt-13B 的 int-8 模型的精度已崩塌。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/62a089bc8e43407b8ee03b38edcf626c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=I0Dt0oVUi9hz%2FZnn4WH%2BVpXLdYM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：An Introduction to Quantization of Large Language Models,p20 】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在应对激励量化的挑战这方面，有一些方案尝试降低量化精度，比如 SmoothQuant 提出的思路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p9-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/e6c2e258ac024e08bbf9f7fd81d03e83~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=AzHTM%2B9uYkzKcGUOHi8C%2BxJP6jI%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3a9c38e024e6422280129e814a4aeca2~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=yq9JtiqjcY8BJwTbqfso7KMHyuE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：SmoothQuant,p4】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在矩阵乘法中，他们通过按比例缩小输入张量 X 的值，而将缩小的比例补偿给权重张量 W，即把问题从量化 X 和 W 转化为了量化 X·diag(s^(-1)) 和 diag(s)·W。从而在保证乘法运算的积保持不变的前提下，降低张量 X 的量化难度。而在实际工程中，这种量化方案引起的量化误差对大模型的推理效果仍然有比较明显的影响，即使在 int-8 精度量化亦有明显的误差。如以下对 Llama2-7B 的 SmoothQuant 应用结果显示其 perplexity 非常糟糕，难以在实际中应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/71eb305e3acb4673a80b4792bbca806d~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2BbSXCFt1O4odl66V1R3jezUgUMQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;所以在目前工程部署中的实用方案，大多以 weight-only 的量化方案为主，即放弃 activation 的量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPTQ&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;GPTQ 是最早被工程化部署所接受的量化方案，W8A16 或 W4A16 的量化效果在多数场景中都有与原模型较为接近的表现，而且其量化过程非常快。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;量化过程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;以矩阵乘法的基本单元操作为例，基于 weight-only 量化前后的乘积的均方差，可以写出如下优化函数，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a5cd5d41f540405eb42324067e46aa2c~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=u8kaZuqe7SOumKhUstBski7FFOo%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W 是在 Transformer 中的 Linear 层权重，X 表示其对应的输入。离线量化的过程是逐模块（Transformer）逐层（Q,K,V,O,Fc1,Fc2）做量化。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;参数和数据定义如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;W∈R^{K×M}，X∈R^{M×N}，Y=W×X∈R^{K ×N}&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;calibrate set：部分数据用作推理，用于查看各层输入张量的值范围，并基于此量化。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;具体量化过程如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;计算 Hessian（上述优化函数对于 W_hat 的 Hessian，而非反向传播中的 Hessian），加入扰动项：&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/a78d6c029c874f1689cbc1e82ea8785b~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=J9OIVlDpvL5sRPe5cvVfvoQmEYw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;act order sort（desc_act，值范围相近的 column 一起做量化），基于 diag(H) 对 W 基于 M 维度作列重排，同理，对应地 H 在两个维度上重排。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;求逆 H^(-1)（cholesky 分解）。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;对 W 沿维度 M，从左到右逐块量化，block size B=128，其右侧还未量化部分基于 H^(-1) 更新，以补偿量化损失。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/b6c909bbd5d6445399014ef65a66ca98~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=PgxGwM9Cqlj9H%2F6hc%2BEYuozi9%2FM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;（inner loop）针对每个 block 内部，逐列量化，计算误差，并对该 block 内部未量化的列，基于误差更新。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p9-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/64ea79dcdd514eaa8b55f4cf907b49ce~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=J9Md5yF6z9lCFTz1RrYEuNBQgSk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/3022c0f765ab46a8aaf91139f559bf8e~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=68wVwHcBSbJMpAm7sGRtxa9OUjQ%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;（outer loop）操作完该 block，更新其后面的所有列：&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/eb77bf9934e74467a27c2aec35d7d3a5~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=03dG7UlbbxO8rELFZbOXV7oBD2E%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;group_size&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;若不指定 group size，默认 g=-1，以所有列为单位统计量化参数，并对每一行的权重做量化，对于 W∈R^{K×M}，量化参数的数量为 K×1。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/9dad125242ef4d1393016bdb5c03622f~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=wgLGrfS%2FTmR7XjKB%2BudV8Vr%2Bw5s%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;若指定 group size，例如 g=128，则会以每 128 列为单位统计量化参数，并对每一行的权重做量化，对于 W∈R^{K×M}，量化参数的数量为 K×(M/g)。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/831078c1a62647fab0711a995bba2163~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=%2FLc1On%2BSZX4TmDmXtwNQmfsYsjw%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;重排 desc_act&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据 Hessian Matrix H，基于 diag(H) 对 W 基于 M 维度作列重排。其目的是优先量化绝对值较大的 activaiton 对应的 weight 的列，这些列在推理中被视为更为影响结果的重要的列，因而希望在量化这些列时尽可能产生较小的误差，而将更多的量化误差转移到后面相对不重要的列中。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;部分实验表明 desc_act 对量化损失的效果在多数的任务中是有效的 trick。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/569fb2134fea41c283ee83532ed14a12~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=jrOY9VPB9bGHO6v6XiK6wUeeJhs%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;Perplexity of Pygmalion-7B with GPTQ [7]&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：https://huggingface.co/reeducator/vicuna-13b-free/discussions/22】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;算子&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;严格来说基于 weight-only 的 W4A16 相比于原本的 W16A16 并没有太多效率的提升，而且推理中还加入了 quant/dequant 过程；而随着 weight-only 成为 LLM 量化的主流且应用越来越多，有很多开源的工作基于 W4A16 高效算子的编写为量化算法的推理提速赋能，比如 GPTQ 的 python package&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;AutoGPTQ&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;已集成于开源工具 exllama，后者基于 triton 和 CUDA 重写了量化乘法的并行计算。在&lt;br&gt; exllama/exllama_ext/matrix.cuh 可以看到 dot_product8_h 对 out=W_hat·x=(W{int}-z)s·x=(W{int}-z)x·s 的实现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/f1f90fa11110402192cb4e13342d1a76~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=x%2FxnheZUPAuPfbxKSCyW9kVy0RA%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：https://github.com/turboderp/exllama/blob/3b013cd53c7d413cf99ca04c7c28dd5c95117c0d/exllama_ext/matrix.cuh#L86】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;AWQ&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;相比于 GPTQ 从最优化问题出发设计方案，AWQ 是基于搜索提出的量化方案。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;用 Q(·) 表示量化反量化过程，则修改前的量化过程如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p26-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/0f5d296635ce44bf9d2fdf74dc0d31ca~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=wq6Gw3k9shMWbTnqbrRLBTCf7SE%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;修改后，量化过程如下，加入了对 W 的缩放：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/2edd98e5fd2442c6a05bba31e7899097~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=xtQvs56hNP%2FauaSucMUrlGKevZk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;搜索&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;AWQ 的全称为 Activation-aware Weight Quantization, 即对 Weight 的量化过程考虑 Activation 的值的影响。其出发点也是基于在 Weight 的各个通道中，处理对应的 Activtion 的值较大的通道则相对重要，反之则相对不重要，进而通过乘以一个缩放系数Δ去体现其重要性，而Δ的值和范围则通过输入的 activation 的张量值设计。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/d5a8a7765dbd41509b62eebe7e9197df~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=Uy9QQBCyeydLxhi0aqshqq2KIjY%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;搜索的衡量标准依据 Linear 层量化前后输出结果的比较，取 MSE 结果最小者为最优解。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/fd77ad5a9eb245eda3f8fcf07fa6c612~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=aRCXEGMk7Za%2BzIAMALpMst35lgk%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;效果&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从模型表现效果方面，通过逐层 scale search 寻找最优的缩放系数，从而取量化误差最小的解，以下来自 AWQ paper 的效果比较，从 Perplexity 的角度，显示在两代 Llama 的测试上其量化结果稍优于 GPTQ 及 GPTQ 的排序版。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/84137c5e3dbd4feea68a08ff3a45d239~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=RS%2BYTzWwD%2BW%2FZvgPWoXE7%2BD%2FSeM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：AWQ, p6】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从实际任务的准确率来看，AWQ 的准确率与 GPTQ 的 act_order 版本（GPTQ-R）相当，而速度优于后者。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/152c055c7eae4615a06127c89b0e53c4~tplv-tt-shrink:640:0.image?lk3s=06827d14&amp;amp;traceid=202404291655296C600F10B5B0FA08EC5A&amp;amp;x-expires=2147483647&amp;amp;x-signature=N%2BqrQMWSVT1ngWZ2fIoYmOlk2rM%3D&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;【图片出处：AWQ, p5】&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从模型的计算性能方面，GPTQ 因为有 reorder 操作，矩阵乘法是 MV（matrix×vector），为不连续的内存访问，而 AWQ 不存在 reorder 操作，矩阵乘法为（matrix×matrix），速度更快。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;四、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;总结&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;关于 LLM 的量化工作目前的 SOTA performance，基本上都是基于 weight-only 的量化模式，模型在 GPU 运行所需的显存降低是其主要的贡献。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从模型的表现来看，因为存在不可避免的量化损失，且 LLM 模型通常比传统的 CNN 模型对量化要敏感得多，虽然在很多任务上量化后的 LLM 表现与量化前差距不大，但是在一部分任务上可能依然无法胜任。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;从模型的加速来看，weight-only 的量化促使底层加速的工作基本上都在 W4A16、W3A16、W8A16 等乘法算子上的加速，从 paper 上提供的理论数据上来看通常相较于 FP16 模型只有 1.x ~3.x 倍速度的提升，而实际部署效果可能低于此数值，其加速效果远不如传统量化方法的 W4A4、W8A8 等全整型的乘法算子。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;总体来说，LLM 领域的量化工作还很初步，若在实际任务中对模型的表现精度要求十分高，更推荐单纯基于 KV cache 等方向提高单位显存吞吐量的算法和工具，如 Flash Attention-2、Paged Attention 等。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;五、&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#000000&quot;&gt;Reference&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;1. A Simple and Effective Pruning Approach for Large Language Models, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;2. Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;3. A White Paper on Neural Network Quantization, 2021.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;4. SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;5. GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;6. AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration, 2023.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;7. Some evaluation on GPTQ performance.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;*文/&lt;/strong&gt;xujiong&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:justify&quot;&gt;本文属得物技术原创，更多精彩文章请看：得物技术官网&lt;/p&gt; 
&lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;未经得物技术许可严禁转载，否则依法追究法律责任！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/5783135/blog/11066139</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/11066139</guid>
            <pubDate>Tue, 30 Apr 2024 08:30:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>OpenAI 与英国《金融时报》签署内容许可协议</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Fblog%2Fcontent-partnership-with-financial-times&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;与英国《金融时报》达成合作，使其大型语言模型获得对《金融时报》文章的访问权。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;作为合作的一部分，两家公司将向 ChatGPT 用户提供《金融时报》的一部分内容。 OpenAI 表示，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;通过此次合作，ChatGPT 用户将能够看到&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;「精选的摘要、引述以及《金融时报》新闻报道的链接&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以回应相关查询&lt;/span&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;」。不过 OpenAI 没有具体说明内容何时可以访问或在哪些版本的 ChatGPT 中进行访问。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img height=&quot;422&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-06b25d557240271062545cebf0391473d0e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;除了将《金融时报》的文章引入聊天机器人之外，OpenAI 还将使用这些内容来训练新的 AI 模型。OpenAI 没有透露与《金融时报》交易的条款。去年 12 月，在与 Axel Springer&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F12%2F13%2Fopenai-inks-content-licensing-deal-axel-springer%2F&quot; target=&quot;_blank&quot;&gt;签署了&lt;/a&gt;类似的许可协议后，《华尔街日报》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Fbusiness%2Fmedia%2Fopenai-to-pay-politico-parent-axel-springer-for-using-its-content-bdc33332%3Fmod%3Dfollowamazon&quot; target=&quot;_blank&quot;&gt;报道称&lt;/a&gt;，该合同预计将为这家德国出版商带来「可观的收入」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;与《金融时报》一样，Axel Springer 授予 OpenAI 在 ChatGPT 中显示精选文章摘要的权利，并就其内容对 LLM 进行培训。此外， OpenAI&amp;nbsp;还与其他几家媒体公司签署了类似的许可协议，如法国《世界报》和总部位于马德里的 Prisa Media，以及美联社&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsiliconangle.com%2F2023%2F07%2F13%2Fap-partners-openai-explore-news-industry-use-cases-generative-ai%2F&quot; target=&quot;_blank&quot;&gt;。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;该公司向&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F04%2F29%2Fopenai-inks-strategic-tie-up-with-uks-financial-times-including-content-use&quot; target=&quot;_blank&quot;&gt;TechCrunch&lt;/a&gt;&amp;nbsp;透露，迄今为止已经签署了大约十几份此类许可协议，且计划未来签署「更多」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;OpenAI 这一举措可能促使竞争对手进行效仿。谷歌公司也在进行大量投资，以扩大其语言模型可用的文本数量；其今年早些时候就披露了与 Reddit 的一项协议，授权该社交网络的内容用于 AI 培训项目。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Freddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22%2F&quot; target=&quot;_blank&quot;&gt;据报道，&lt;/a&gt;该合同每年价值超过 6000 万美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4a4a4a&quot;&gt;在 OpenAI 与《金融时报》的合作中，内容授权只是交易的一部分。两家公司还将合作为报纸读者开发新的 AI 功能。上月底，《金融时报》推出了一项生成式 AI 功能，使用户能够使用自然语言提示浏览其档案。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/290336/openai-financial-times</link>
            <guid isPermaLink="false">https://www.oschina.net/news/290336/openai-financial-times</guid>
            <pubDate>Tue, 30 Apr 2024 07:43:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
    </channel>
</rss>