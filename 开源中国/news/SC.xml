<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 12 Sep 2025 07:42:40 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>复旦大学漆远：开源开放、价值交付、安全可信是 AI 发展趋势</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 2025 Inclusion·外滩大会期间，复旦大学人工智能创新与产业研究院院长漆远围绕人工智能的发展趋势，提出了三大核心观点：开源开放、价值交付、安全可信，并结合具体案例深入阐述了 AI 技术如何真正落地并推动产业变革。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-15dede4281dee452aaa542e6e6d6d393f0f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;漆远指出，2025 年人工智能领域最显著的变化是「开源开放」已从理念变为现实，并正在重塑整个行业生态。他特别提到「DeepSeek」的出现，「把整个人工智能生成式 AI 的游戏给改变了」，其开源架构和强大性能实现了「十倍的增长和变化提效」。&lt;/p&gt; 
&lt;p&gt;这一趋势甚至影响了原本封闭的巨头。漆远提到：「OpenAI 时隔六年第一次再次开源」，其创始人 Sam Altman 坦言「我们有可能站在了历史错误的一边」。这标志着整个行业对开源价值的重新认可。&lt;/p&gt; 
&lt;p&gt;漆远认为，AI 正在从「卖工具」走向「卖结果」，从辅助工具演变为可交付价值的「Copilot」甚至「Auto Pilot」。这一转变依赖于深入行业场景、结合专业知识的深度整合。&lt;/p&gt; 
&lt;p&gt;他以医疗领域的「焕新智能体」为例，该智能体已在中山医院上线运行。不同于依赖更多算力或工程师的模型，其优势在于「更深入的场景」和「更高质量的数据」。该系统实现了多模态数据（如 MRI、CT、心电图、文本）的综合解读，并能自动识别心电图中的异常区域，辅助医生进行规范诊疗。&lt;/p&gt; 
&lt;p&gt;在金融领域，漆远团队在恒生指数创新挑战赛中夺得第一，其核心技术是将大语言模型与符号计算结合，构建「神经符号系统」，以控制幻觉、确保推理的准确性。他强调：「我们解决的问题是指数生成的广度、深度、速度和颗粒度。」&lt;/p&gt; 
&lt;p&gt;在强调技术进步的同时，漆远反复强调「安全可信」是 AI 发展的底线。他指出，大模型存在「造假」「幻觉」等问题，医疗领域模型的准确率甚至只有 55%，这令人「肯定是有担心的」。&lt;/p&gt; 
&lt;p&gt;他列举了多个风险案例：MIT 导师发现博士论文由 AI 生成；WPP 集团 CEO 遭遇深度伪造诈骗。这些事件凸显了「真假信息难辨」的严峻挑战。&lt;/p&gt; 
&lt;p&gt;为此，漆远和团队提出了多项关键技术路径：包括可解释 AI：在金融、医疗等关键决策领域，必须能解释模型的每一个决定。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;检索增强（RAG）与神经符号系统：结合规则与语义理解，提升推理可靠性。&lt;/li&gt; 
 &lt;li&gt;高质量数据治理：高质量的数据才能保证模型的质量。&lt;/li&gt; 
 &lt;li&gt;博弈对抗技术：借鉴强化学习与围棋对弈的思路，提升模型在复杂环境中的鲁棒性。&lt;/li&gt; 
 &lt;li&gt;自知之明：让模型知道自己什么时候是不知道，这是实现可信 AI 的关键一步。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;漆远总结，开源开放让技术更加普惠，让更多机构能够使用 AI；深耕场景才能释放产业价值；而安全可信则是 AI 可持续发展的根本保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371795</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371795</guid>
      <pubDate>Fri, 12 Sep 2025 07:32:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁集团发布 Tbox 超级智能体</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 11 日，蚂蚁百宝箱智能体开发平台在 2025Inclusion·外滩大会上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEB3584t6IxMA9w2gRq8IXg" target="_blank"&gt;发布&lt;/a&gt;新产品 Tbox 超级智能体（www.tbox.cn）。Tbox 采用「动态编排引擎」，可根据任务复杂度实时调整智能体数量与协作路径，较传统串行流程更具有灵活性，比如在 PPT 制作场景，Tbox 可根据需要，动态选择是否引入数据分析师和图表可视化专家，来高效完成任务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/151914_9P1e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，全新的 Tbox 通过多智能体协同架构，可以让平台上多个智能体形成工作小组，共同完成用户指定的任务，交付成果。&lt;/p&gt; 
&lt;p&gt;用户仅需一句话指令，Tbox 即可联动多个智能体协同完成从内容构建、视觉设计到格式输出的全流程，实现「输入意图，输出成果」。&lt;/p&gt; 
&lt;p&gt;例如，用户上传大学生旅游市场调研数据，仅需输入指令「生成墨绿色+白灰主色调、图表清晰的课程 PPT」，Tbox 便在 5 分钟内自动完成专业教学级 PPT，涵盖数据解析、视觉设计与内容组织，大大减轻用户数据可视化、理解内容的时间精力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/152154_E8Qz_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，新版本继续强化「无代码」体验：用户描述想法，即可获得可直接发布的 PPT、网页、播客、文档等多种格式成果。与此同时，Tbox 即将开放「智能体市场」，用户可将自己搭建的行业专家 Agent 上架，供全球用户调用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371791</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371791</guid>
      <pubDate>Fri, 12 Sep 2025 07:20:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>我国科研人员开发可用于癌症免疫治疗的「纳米标记机器人」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在癌症的免疫治疗中，体内免疫细胞需接受足够强和足够多的信号，才能对癌细胞发起攻击。但狡猾的癌细胞善于伪装，表面的天然信号非常稀疏。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;如何精准识别癌细胞？中国科学院分子细胞科学卓越创新中心韩硕研究团队将化学生物学研究中的邻近标记技术应用于疾病治疗，通过构建一种深红光或超声波响应的工程化纳米酶，成功开发出可对癌细胞精准识别的「纳米标记机器人」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="315" src="https://oscimg.oschina.net/oscnet/up-5761d1a480b313a45c25642d8ef2f336539.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;em&gt;「纳米标记机器人」工作原理示意图。（中国科学院分子细胞科学卓越创新中心供图）&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国际学术期刊《自然》于 9 月 10 日在线发表了相关研究论文。中国科学院分子细胞科学卓越创新中心韩硕研究员和复旦大学附属中山医院高强教授为该论文共同通讯作者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据韩硕介绍，邻近标记技术是一种强大的「分子地图」绘制技术，能在细胞的特定位置对周边环境进行催化标记。利用这一技术原理开发的「纳米标记机器人」，可搭载识别癌细胞的抗体或配体，通过血液循环富集在癌细胞的表面，再通过深红光或超声波下达指令，就可以给癌细胞打上清晰的标记，成为「人造靶标」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;针对这些「人造靶标」，研究人员在实验中为小鼠注射了一种特制的 BiTE 分子，这种分子一方面能增强「人造靶标」标记信号，另一方面还可以激活并召集体内免疫 T 细胞前来参加抗癌的战斗。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「这种高密度的标记，不仅是简单的指引，更像是吹响战斗的冲锋号，促使 T 细胞表面的相关识别受体高效聚集，触发其最强攻击模式，对深红光或超声波引导的位置，实施精准打击。与此同时，还能激活全身免疫系统，形成长期记忆，如同在体内接种了‘肿瘤疫苗’。」韩硕说。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，该研究在实验小鼠肿瘤模型和体外临床肿瘤样本中均取得良好疗效，有望为开发更智能、更高效的下一代免疫疗法开辟全新的道路。该工作获国家重点研发计划、中国科学院战略性先导科技专项、国家自然科学基金、上海市科技重大专项以及国家科技重大专项、中国博士后科学基金资助。（新华社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371784</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371784</guid>
      <pubDate>Fri, 12 Sep 2025 07:06:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度发布新一代文字识别解决方案：PP-OCRv5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;百度发布了 OCR 模型 PP-OCRv5，旨在解决通用视觉语言模型（VLMs）在 OCR 领域的局限性。PP-OCRv5 作为 PP-OCR 新一代文字识别解决方案，该方案聚焦于多场景、多文字类型的文字识别。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fae459803b1010544dc4f590411a10e325b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在文字类型方面，PP-OCRv5 支持简体中文、中文拼音、繁体中文、英文、日文 5 大主流文字类型，在场景方面，PP-OCRv5 升级了中英复杂手写体、竖排文本、生僻字等多种挑战性场景的识别能力。在内部多场景复杂评估集上，PP-OCRv5 较 PP-OCRv4 端到端提升 13 个百分点。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a51b994a63239798865cfe4ba22544d02b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PP-OCRv5 采用模块化两阶段流程，专为高速、精确的文本检测和识别设计。该模型更小、更高效，尤其适合资源受限硬件。&lt;/p&gt; 
&lt;p&gt;PP-OCRv5 模型架构为两阶段流水线，包含图像预处理、文本检测、文本行方向分类和文本识别四个核心组件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8b930bbeca01f5c46796ca71f7e98ea2529.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模型已在 Hugging Face 上线，用户可通过在线 Demo 测试其在处理多语言文档、手写文本和低质量扫描件时的实时精确结果。开发者可从 Hugging Face Models 下载模型，并通过安装 PaddlePaddle 和 PaddleOCR 库在本地部署使用。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/blog/baidu/ppocrv5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371783/baidu-ppocrv5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371783/baidu-ppocrv5</guid>
      <pubDate>Fri, 12 Sep 2025 07:01:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动联合清华大学开源统一多模态框架：HuMo</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;字节跳动智能创作团队联合清华大学共同开源了名为&amp;nbsp;HuMo&amp;nbsp;的统一 HCVG（Human-Centric Video Generation）框架。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/143717_iLPP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;论文地址: https://arxiv.org/abs/2509.08519&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Human-Centric Video Generation，即人体视频生成框架，支持文本、图像、音频三种模态协同驱动。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/143706_7e6J_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;HuMo（意指 Human-Modal）通过构建高质量数据集和设计创新的渐进式训练范式，成功实现了对多模态输入的协同控制，在各项子任务上超越了现有的专业化方法，可输出 480P 与 720P 分辨率、最长 97 帧、25FPS 的精细可控人物视频。&lt;/p&gt; 
&lt;p&gt;HuMo 框架的核心在于其创新的数据处理流程、渐进式多模态训练范式以及灵活的推理策略。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0912/144015_bCsa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;项目地址:&lt;br&gt; https://phantom-video.github.io/HuMo&lt;br&gt; https://github.com/phantom-video/humo&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371781</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371781</guid>
      <pubDate>Fri, 12 Sep 2025 06:42:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌在 AI 生成的搜索答案中植入广告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthe-decoder.com%2Fgoogle-brings-ads-to-ai-generated-answers-worldwide%2F" target="_blank"&gt;据报道&lt;/a&gt;，谷歌在全球范围内为 AI 生成的搜索答案嵌入广告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0912/142405_Yvap_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;报道称，当用户以对话／自然语言（conversational）方式进行搜索（例如：「如何解决低水压问题？」），谷歌搜索会在 AI 生成的答案旁边直接展示与该问题相关的广告，比如修理或水管工服务。&lt;/p&gt; 
&lt;p&gt;这项功能在名为 「AI Mode」 的模式里可见，并通过新推出的 AI Max 工具支持广告主在多个广告产品中（Google Ads, Ads Editor, Search Ads 360, Ads API）一键设置这种类型的广告活动，目前正在全球范围内以 beta 测试形式推出。&lt;/p&gt; 
&lt;p&gt;谷歌认为，越来越多用户在搜索时采用宽泛或对话式的语言，而这种方式比起传统关键词列表，更适合由 AI 生成直接的答案。比如，用户在问 「怎样解决水压低」 而不是输入一串关键词。在这种趋势下，把广告整合进 AI 答案被视为一种合理且「对用户搜索习惯更贴近」的广告展示方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371773</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371773</guid>
      <pubDate>Thu, 11 Sep 2025 06:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国家发改委：加大人工智能领域金融和财政支持力度</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;国家发展和改革委员会在人民日报刊文指出，完善人工智能应用的创新发展环境。强化政府部门和国有企业示范引领作用，完善应用试错容错管理制度，推动关键重点场景有序开放。加大人工智能领域金融和财政支持力度，完善风险分担和投资退出机制，进一步激发人工智能投融资市场活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;以下为原文：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深入实施「人工智能+」行动，为高质量发展提供强大动能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;国家发展和改革委员会&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;习近平总书记强调：「人工智能作为引领新一轮科技革命和产业变革的战略性技术，深刻改变人类生产生活方式。」党的二十届三中全会明确将人工智能作为战略性产业，推动实现各行业的数智化转型，为经济高质量发展注入新动力。国务院日前印发《关于深入实施「人工智能+」行动的意见》，从国家层面对各行业各领域人工智能应用发展提出指导意见，明确时间表、路线图。我们要深入贯彻落实党中央、国务院决策部署，大力推进人工智能商业化规模化应用，加快人工智能与经济社会各领域广泛深度融合，为赋能高质量发展、更好服务社会主义现代化建设贡献力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;深刻领会深入实施「人工智能+」行动的重大意义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;当前，人工智能技术加速迭代演进，正在对经济发展、社会进步、国际政治经济格局等方面产生重大而深远的影响。深入实施「人工智能+」行动，推动人工智能与经济社会深度融合，既是我们当前面临的紧迫任务，更是关乎长远发展的战略命题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入实施「人工智能+」行动，是抢抓新一轮科技革命和产业变革机遇的战略选择。习近平总书记强调：「加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。」历史发展表明，每一次科技革命都带来生产力的指数级跃升，推动社会形态深刻演进。人工智能作为继蒸汽机、电力、互联网之后的又一划时代的变革性技术，正以前所未有的速度、广度和深度，驱动经济社会发展加快迈向智能化新阶段。实施「人工智能+」行动，体现了党中央、国务院对世界科技发展大势的深刻洞见和前瞻擘画，是赢得全球科技竞争主动权的重要抓手。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入实施「人工智能+」行动，是培育发展新质生产力的内在要求。习近平总书记强调：「科技创新是发展新质生产力的核心要素。」作为新一轮科技革命的重要驱动力量，当前人工智能的快速发展与我国培育发展新质生产力、推动高质量发展形成历史性交汇。人工智能具有溢出带动性很强的「头雁」效应，通过对资本、劳动、技术、数据等要素创新性配置，显著提升全要素生产率，促进生产力革命性跃升。实施「人工智能+」行动，积极推动人工智能和实体经济深度融合，有助于推动产业向价值链高端迈进，促进增长方式从要素驱动转向创新驱动，不断催生新技术、新业态、新模式，形成新质生产力发展的核心引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入实施「人工智能+」行动，是满足人民美好生活需要的重要途径。习近平总书记强调：「要加强人工智能同保障和改善民生的结合，从保障和改善民生、为人民创造美好生活的需要出发，推动人工智能在人们日常工作、学习、生活中的深度运用，创造更加智能的工作方式和生活方式。」实施「人工智能+」行动，要抓住民生领域突出矛盾和难点，加强人工智能在医疗、教育、交通、助残养老等关系群众切身利益的重点领域深度应用，促进全体人民共享人工智能发展成果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入实施「人工智能+」行动，是助力全球平等参与智能化发展进程的积极举措。习近平总书记强调：「人工智能可以是造福人类的国际公共产品。」当前，人工智能发展面临全球治理机制碎片化、阵营化等挑战，各国智能化发展差距不断加大，亟需完善全球治理体系，携手共赢发展。我国深入实施「人工智能+」行动，打造具有世界影响力的人工智能生态，深化人工智能领域高水平开放，推动人工智能技术开源可及，有助于推动形成具有广泛共识的全球治理框架和标准规范，助力各国平等参与全球智能化发展进程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;全面把握深入实施「人工智能+」行动的优势条件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在党中央、国务院的坚强领导下，我国人工智能快速发展，综合实力实现整体性、系统性跃升，发展优势进一步凸显，同时数据资源丰富、产业体系完备、应用场景多、市场空间大、人才资源富集，为深入实施「人工智能+」行动创造有利条件、奠定良好基础。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;丰富的数据资源提供了关键要素支撑。数据作为人工智能模型训练和迭代的关键「原料」，其规模、质量、多样性和时效性直接决定人工智能的性能上限。当前，随着大模型技术发展，对高质量语料数据的需求正从通用化向专业化、场景化、多模态纵深拓展。我国依托网络化、数字化建设基础，积累起规模超大、类型丰富、动态鲜活的数据资源。2024 年，全国数据生产总量达 41.06 泽字节（ZB），占全球数据总量的 26.67%，用于人工智能开发、训练和推理的数据量同比增长 40.95%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;完备的产业体系提供了强大物质技术保障。我国作为全球唯一拥有联合国产业分类中全部工业门类的国家，具备 41 个大类、207 个中类、666 个小类的工业体系，200 多种主要工业品产量全球第一。这一链条完整、配套齐全、要素完备的产业生态，为人工智能技术从研发验证、产品设计到制造交付提供了全链条支撑，将极大促进技术创新迅速转化为产品与服务，形成推动人工智能实现规模化落地应用的独特优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;丰富的应用场景提供了广阔的发展空间。人工智能的生命力在于应用，真实场景中复杂的约束条件、多样化需求等，持续驱动人工智能技术演进和性能提升。我国具备类别齐全、层次多样的应用生态，覆盖智能制造、智慧医疗、数字金融、智能交通、智慧教育等关键领域，为人工智能尤其是复杂推理、动态决策和自适应学习等高级能力的锤炼提供了最佳「试验场」。目前，我国已发布超 1500 个行业模型，覆盖 50 个重点行业领域、700 余个场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;巨大的市场空间提供了内生发展动力。我国拥有 14 亿多人口、约 2 亿经营主体和超过 4 亿的中等收入群体，连续 10 余年稳居全球第二大商品消费市场和最大网络零售市场。庞大的人口基数、持续升级的消费能力以及强大的企业创新活力，有利于摊薄研发成本、加速技术迭代升级、促进应用标准化，为推动新一代人工智能终端、智能体等人工智能应用提供了广阔市场空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;超大规模的人才资源提供了信心底气。人工智能的理论创新、算法突破和落地应用均依赖多层次、跨学科人才。我国已建成世界规模最大且有质量的教育体系，人才资源总量、科技人力资源总量、研发人员总量均居世界第一，软件开发者近千万人，在数学、计算机、工程等多学科领域积累了雄厚人才基础，为人工智能持续创新和规模化应用提供了强大人才保障和智力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;奋力开拓新时代「人工智能+」发展新局面&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;深入实施「人工智能+」是一项长期、复杂的系统工程。国家发展改革委将按照党中央、国务院决策部署，紧扣「人工智能+」行动总体安排，充分发挥统筹协调作用，加强部门协同、央地联动和社会参与，广泛凝聚各方力量，推动形成工作合力，扎实推进各项工作取得实效。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;构建创新活跃的智能经济。&lt;/strong&gt;加快推动人工智能驱动的新型科研范式变革，加速「从 0 到 1」重大科学发现进程、「从 1 到 N」技术落地和迭代突破。深入推动产业全要素智能化发展，加快工业、农业、服务业智能化转型升级，发展智能原生技术、产品和服务体系，催生智能原生新业态。加强智能消费基础设施建设，推动智能终端「万物智联」，让人工智能走进「千家万户」「千商万店」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;打造更有温度的智能社会。&lt;/strong&gt;优先在就业、健康、养老、教育、文化等民生领域降低人工智能技术应用门槛，加快健康助手、智能学伴等人工智能产品与服务的普惠化应用。有序推进人工智能在社会治理、安全治理、生态治理等中的应用，形成高效多元的治理格局。把人工智能作为造福人类的国际公共产品，推动人工智能普惠共享，助力各国平等参与智能化进程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;强化人工智能发展的要素支撑。&lt;/strong&gt;加快高质量语料库和行业数据集建设，完善数据产权和版权、收益分配等制度，加强数据供给创新。统筹布局智算基础设施，充分发挥「东数西算」国家枢纽作用，强化数、算、电、网等资源协同配置。大力推进原始创新与开源生态培育，支持多路径技术探索和基础架构创新，提升模型基础能力。加强人工智能人才引育，超常规构建领军人才培养新模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;完善人工智能应用的创新发展环境。&lt;/strong&gt;强化政府部门和国有企业示范引领作用，完善应用试错容错管理制度，推动关键重点场景有序开放。&lt;strong&gt;加大人工智能领域金融和财政支持力度，&lt;/strong&gt;完善风险分担和投资退出机制，进一步激发人工智能投融资市场活力。布局建设一批国家人工智能应用中试基地，搭建行业应用共性平台，降低应用创新门槛，促进创新成果高效转化。推动大中小企业融通发展，加快人工智能产业链上下游协同发展，构建资源共享、能力互补、良性互动的人工智能产业生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;筑牢人工智能应用的安全防线。&lt;/strong&gt;大力支持开展人工智能技能培训，激发人工智能创新创业和再就业活力，引导创新资源向创造就业潜力大的方向倾斜，加强人工智能应用就业风险评估，减少对就业的冲击。推动模型算法、数据资源、基础设施、应用系统等安全能力建设，建立健全人工智能技术监测、风险预警、应急响应体系，加快形成动态敏捷、多元协同的人工智能治理格局，推动人工智能应用合规、透明、可信赖。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371764</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371764</guid>
      <pubDate>Thu, 11 Sep 2025 05:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>云基座技术是大厂专有，那小厂和私有云的出路在哪里？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1&gt;云基座技术是大厂专有，那小厂和私有云的出路在哪里？&lt;/h1&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//125ac9150a041a8b6d9f9a6e73be1c67.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;专栏导语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 时代数据洪流来袭，晨章数据以创新 「数据基层」 架构破局！旗下分布式数据库系列产品，实现计算、内存、日志、存储四元解耦，0.1ms 响应跨模态需求，更全面开源赋能生态。&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;本专栏将邀请五位嘉宾，从不同视角深探晨章数据的领先之道&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;解析云原生弹性架构优势，探索新硬件红利，看 AI 原生数据库如何突赋能 AI 创业者，锚定市场痛点破局，听创始人拆解技术创业逻辑，干货持续输出，敬请关注！&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;本篇特邀专家——刘华阳，深度解析云数据库基座厂商的探索路径，并系统探讨中小厂商与私有云的未来发展可能性，为行业提供兼具实践参考与前瞻视野的深度洞见。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//5fad3ad9bb2c47a5a56fe0d40aefa49f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;刘华阳&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;一个与时俱进的 DBA 架构师，从传统商业到最新开源数据库，再到分布式，云原生数据库产品，一路体验各种不同数据库给企业，给数据库厂商、数据库使用人员、数据库运维人员带来不同的视角，愿意将这些感受表达出来的小角色。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;云数据库是未来&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;数据库技术的进化都与需求的产生和变化有关，传统数据库厂商是不会想到云数据库厂商逐渐可以玩出他们玩不出的花样，同时也想不到 2025 年云数据库成为整体国产数据库占比完全碾压线下的数据库厂商，可谓谁想活到后面，谁就要有数据库的云产品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//d0fb8647f13798ba28d503ae219d35c0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;非云厂商的市场预测&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;可是这里有一个问题，云数据库的理念和传统数据库设计的理念完全不同，人家的玩法是 4 维科技，与数据库传统厂商的 2 维科技相比，可操作性更大。所以摆在传统数据库厂商的角度，怎么能快速的上云数据库这条赛道是后续需要考虑，且要操作的。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;从一个数据库从业者的角度考虑，云底座是一个关键点。传统数据库设计的理念是单机的概念，思想维度都是围绕单机性能最大化而来的，云数据库根本不是这么考虑和解决问题的，所以云数据库不是把线下的数据库弄到云上就是云数据库了,而是依据云上硬件和用户的特点来重新设计底层架构，而底层的基座则是云数据库的难点和重点。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;众多的小型云厂商，私有云厂商，甚至是大型客户，需要的是云基座，一种基于新的云硬件概念而来的云数据库产品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;所以今天引出我们本次的&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;一种新的基于云的通用性架构，Data Substrate&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;strong&gt;&lt;span&gt;，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;后面将统称 Data Substrate 为 DS。这样的基于云数据库的基座的产品他有什么技术特点来应对各大云厂商的成熟的云数据库的架构也是我们此次想谈到的问题。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//2c12d7837f3a38a62a12e2ac8dcef583.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;云架构是不是大型云厂商的专属？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;回答不是，大型企业和私有云厂商需要一个通用性的架构，这里我们强调的是通用性，灵活性等特点。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;那么 DS 通用性云基座技术有什么技术特点：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;1 本地部署的能力：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;在没有云存储服务的本地部署中，DS 可以通过 Raft 协议实现数据的复制，提供与云类似的容错和基本的弹性功能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;2 中立性：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;云厂商本身的技术都具有技术壁垒，DS 技术本身是通用的，可以部署在多个云平台提供统一的访问接口，实现混合云的技术能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;3 模块化存储能力：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;模块化存储的能力本身体现的是 DS 技术的灵活性，他允许多种存储系统融入到云基座中，比如他可以利用对象存储 S3 作为主存，同时通过 EBS 存储日志，而将本地的 NVMe 作为本地的数据缓存。这是一个非常「云」的模式的打法，从性能和成本进行兼顾的设计模式。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//168306c1959ffee74a515ac851849a1f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;DS 技术本身的核心&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;或者说优势是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;DS 技术的核心点在于解耦，DS 技术将计算，内存，日志，和存储资源进行独立解耦，提供了与云上云原生数据库本身对系统资源设计类似的方式进行资源的调用和使用。通过这样的技术来建立，按需独立伸缩的能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;计算 (CPU)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;可根据查询工作负载的实时变化动态扩展或缩减计算引擎（如 TxServer 的 CPU 核心数），从而显著提升吞吐量并降低延迟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;内存 (缓存)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;内存节点（即分布式内存表 TxMap）的规模可以独立于总数据量进行伸缩，与热数据的大小或预算成正比。这使得数据库能够根据实际需求快速调整缓存容量，应对读密集型工作负载的峰值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;日志 (写入吞吐量与持久化延迟)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;日志节点数量可以独立于缓存大小和总数据量进行水平扩展，与在线写流量成正比。通过增加独立的日志工作者和低规格日志节点，能够显著提升写入吞吐量并降低写入延迟，消除写密集型工作负载的日志瓶颈。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;存储 (数据容量与缓存未命中性能)：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;存储资源与计算、内存和日志独立扩展，实现大型数据集的成本效益管理和高效的缓存未命中处理。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;这种四元解耦（计算、内存、日志和存储的独立扩展）是 Data Substrate 的独特优势，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;使系统能够根据给定工作负载精确分配所需资源，避免过度配置，从而提高成本效益和运营灵活性，而这个概念也是先进的云企业一直倡导和积极实现的，最终将实现数据库的使用如自来水一样，打开就付费，关闭就免费。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;DS 技术已经可以达到这个技术能力，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;支持 Scale to Zero（缩容到零）：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;当数据库长时间没有流量时，系统能够自动释放所有计算资源，用户仅需支付成本极低的对象存储费用，实现「没有使用就没有费用」。当工作负载返回时，系统可在几秒内迅速恢复服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//ad68e19fe3319cc53b6c609d2b8dc506.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;DS 技术的底层是分布式吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;是新瓶装旧酒吗？怎么保证性能？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//9eab34a53e96afbdd8aeec5186394283.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;Data Substrate&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;首先 DS 技术针对 CPU,内存，以及存储进行解耦，分布式数据库中对于性能有影响的部分是两阶段提交，DS 架构下的数据库不会有两阶段提交的场景，整体的操作均在内存中完成。在这样的设计下，DS 可以做到如下的能力：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;1、数据库在工作负载繁重的情况下，也能&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;支持亚毫秒级的读取延迟。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;2 、支持&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒级自动故障转移和零数据丢失&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，并通过热备份模式进一步降低故障恢复时间&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;3、通过 Pod 池化，可以实现&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒级启动&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，快速响应用户请求，确保动态调整资源时用户无感知&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;4、内存节点可实现&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;秒级弹性扩容&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，扩展速度提升百倍&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;5、Scale 时&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;不&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;会有数据的迁移或移动&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，新增节点马上提供服务&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;6、每个 CPU 核绑定一个线程的架构（thread-per-core）充分利用异步 I/O （io_uring）能力，最小化上下文切换，减少锁竞争，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;即便在重负载下也能维持高吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;最终 DS 技术并不是一个单纯的数据库技术&lt;/span&gt;&lt;span style="color:#404040"&gt;&lt;span&gt;，&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;DS 技术是一项高效的通用的云数据库基座，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;在此以上可以搭建，Redis、MySQL、MongoDB、甚至基于多模态的数据库产品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;写到最后，这项技术的拥有者是一家正在稳定创业，通过先进的云基座发展起来的数据库厂商，如果你觉得这个技术很有意思，想试用，在&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;阿里云&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span style="color:#3232b4"&gt;&lt;strong&gt;&lt;span&gt;AWS 的云市场&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;中均有他们的产品可以使用（可商用）。除了 Redis 兼容的高性能 KV 之外，他们还推出了 Mongo 兼容的文档数据库产品，后续还将推出兼容更多模态的数据库产品。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//bc1a7c1e16f6f63d1524cc1ed06052c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;span&gt;AWS 市场，晨章数据产品&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style="text-align:center"&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet//0abf051419098edfd9e39f094d6148c0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;span&gt;阿里云 &amp;nbsp;晨章数据产品&lt;/span&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371759</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371759</guid>
      <pubDate>Thu, 11 Sep 2025 04:55:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>AI 搜索创企 Perplexity 融资 2 亿美元，估值 200 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F09%2F10%2Fperplexity-reportedly-raised-200m-at-20b-valuation%2F" target="_blank"&gt;根据 TechCrunch 的报道&lt;/a&gt;，人工智能搜索引擎公司 Perplexity 近期完成了 2 亿美元新一轮融资，估值达 200 亿美元，距离其 7 月以 180 亿美元估值完成的 1 亿美元融资仅隔两个月。&lt;/p&gt; 
&lt;p&gt;目前尚未披露本轮融资的主导投资方。今年 7 月，《彭博社》曾报道，Perplexity 刚完成对此前一轮 5 亿美元融资的扩展，当时估值为 140 亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ee680c0e530a41a664a440faf13a1133621.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据 PitchBook 数据，自三年前成立以来，Perplexity 的融资总额已达 15 亿美元。&lt;/p&gt; 
&lt;p&gt;消息人士透露，Perplexity 的年经常性收入（ARR）正逼近 2 亿美元。公司公关负责人上月对 Business Insider 表示，Perplexity 的年收入已超过 1.5 亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1abe17d787b691e146a089eccf4834806a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;截至发稿，Perplexity 未对置评请求作出回应。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371752</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371752</guid>
      <pubDate>Thu, 11 Sep 2025 04:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>trust-manager 正在迁移到 ClusterBundle</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;trust-manager&amp;nbsp;方面&lt;span style="background-color:#ffffff; color:#000000"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcert-manager.io%2Fannouncements%2F2025%2F09%2F05%2Ftrust-manager-clusterbundle-future%2F" target="_blank"&gt;分享&lt;/a&gt;了一个关于&lt;/span&gt;项目&lt;span style="background-color:#ffffff; color:#000000"&gt;即将发生的重要变化的详细信息。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;trust-manager 即将把当前的 Bundle 资源功能，迁移到一个新的 ClusterBundle 资源。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;你需要将 Bundle 的 YAML 替换成 ClusterBundle YAML，规格类似但有所不同。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;未来，Bundle 可能会以命名空间范围的 CRD 形式重新出现。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;当前状态&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;trust-manager 目前使用 Bundle 资源，作为集群管理员在集群中分发证书颁发机构（CA）证书的机制。这个 CRD 是集群级别的，从集群中心命名空间中获取数据源，然后同步到其他命名空间的目标。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&amp;gt; kubectl api-resources&lt;/span&gt;
&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;bundles &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; trust.cert-manager.io/v1alpha1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Bundle&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;如果你熟悉其姊妹项目 cert-manager，可能会预期看到 ClusterBundle，因为 Issuer 是命名空间范围的，而 ClusterIssuer 是集群范围的。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;clusterissuers &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ciss &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;cert-manager.io/v1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ClusterIssuer&lt;/span&gt;
&lt;span&gt;issuers &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; iss &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cert-manager.io/v1 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Issuer&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;trust-manager 目前没有遵循以 Cluster 前缀表示集群级别 CRD 的模式。对于新用户来说可能有些困惑，或者感觉有些不一致。&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;变化内容&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;简单来说，trust-manager 默认将切换为使用 ClusterBundle。这更准确地反映了当前 Bundle 资源的范围。同时这也更贴近 Kubernetes 原生的 ClusterTrustBundle 资源，它也是集群级别资源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;对 trust-manager 用户的影响：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;弃用并最终移除 Bundle 资源及其 API 组 trust.cert-manager.io/v1alpha1。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;在新的 API 组 trust-manager.io/v1alpha2 中创建 ClusterBundle，作为新的默认资源。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;安装 trust-manager 后，查看 api-resources 会看到类似：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&amp;gt; kubectl api-resources&lt;/span&gt;
&lt;span&gt;NAME &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;SHORTNAMES &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;APIVERSION &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NAMESPACED &amp;nbsp; KIND&lt;/span&gt;
&lt;span&gt;clusterbundles &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;trust-manager.io/v1alpha2 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ClusterBundle&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;最简示例&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;对于简单场景，比如只使用公共 CA，改动很小。如果你当前有：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;apiVersion:&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;trust.cert-manager.io/v1alpha1&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;kind:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;Bundle&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;name:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;public-ca-certs&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;sources:&lt;/span&gt;&lt;/span&gt;
&lt;span style="color:#990073"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;useDefaultCAs:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;target:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;configMap:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;key:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ca-certificates.crt&lt;/span&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;现在改成：&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;apiVersion:&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;trust-manager.io/v1alpha2&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;kind:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ClusterBundle&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;name:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;public-ca-certs&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;includeDefaultCAs:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#008080"&gt;&lt;span&gt;true&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span&gt;target:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;configMap:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;data:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style="color:#990073"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;key:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;ca-certificates.crt&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;namespaceSelector:&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;span&gt;matchLabels:&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#dd1144"&gt;&lt;span&gt;{}&lt;/span&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;注意，发布前规格可能会有变动！如果有任何调整建议，可联系 cert-manager 维护者。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;如果想提前了解资源规格，可以在测试或开发集群中应用 CRD，并用 kubectl explain 查看配置选项。&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/cert-manager/trust-manager/refs/heads/main/deploy/crds/trust-manager.io_clusterbundles.yaml&lt;/span&gt;
&lt;span&gt;kubectl explain clusterbundles.trust-manager.io.spec&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;别忘了清理测试资源，因为此资源尚未正式发布&lt;/span&gt;&lt;/p&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;code&gt;&lt;span&gt;kubectl delete -f https://raw.githubusercontent.com/cert-manager/trust-manager/refs/heads/main/deploy/crds/trust-manager.io_clusterbundles.yaml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;API 变更&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;主要有两个关键点：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;API 组由 trust.cert-manager.io 变更为 trust-manager.io。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;API 版本由 v1alpha1 升级为 v1alpha2。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;API 组的变更，一方面缩短了整体 URL，另一方面体现了 trust-manager 正在成为一个完全独立于 cert-manager 的项目。虽然两个项目都由同一组优秀维护者负责，但官方认为项目应能独立存在，减少集群中的工具依赖。实现独立性的关键之一是移除 webhook 依赖，不再需要证书来保护 webhook 通信。Kubernetes 在 Server Side Apply (SSA) 和 Common Expression Language (CEL) 的进步，让资源验证能更方便地由 Kubernetes 组件完成，无需依赖 webhook 服务。目前还没达到完全独立的状态，未来会有专门讨论此话题的文章。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;API 版本的变更也很重要：资源仍处于 alpha 阶段。这意味着规格依然可能发生不兼容的变动。但实际上，维护者会非常谨慎对待规格更改&lt;/span&gt;&lt;/p&gt; 
&lt;h2 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;对你的影响&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;资源迁移将由一个新的转换控制器辅助完成。注意，这不是 webhook 转换，因为 webhook 转换只能在同一 API 组的不同版本间转换。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;管理员需要做两件事：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="list-style-type:decimal; margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;随着新版本发布，升级 trust-manager。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;更新部署清单，将 Bundle 资源替换为新的 ClusterBundle 规范。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;官方会在新资源发布时提供详细的操作指南。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;时间表&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;官方目前还不能给出具体时间点，但可以大致说明：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;版本 N：发布新的 ClusterBundle CRD，并弃用 Bundle。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;版本 N+X：移除 Bundle 资源。&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;未来展望&lt;/h3&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;这只是目前的设想，trust-manager 在 ClusterBundle 之后可能会包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;新的 trust-manager.io/v1alpha2 Bundle 资源回归，命名空间范围的。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;为 ClusterBundle 增加更多目标资源类型。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371750</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371750</guid>
      <pubDate>Thu, 11 Sep 2025 03:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 面向 Pro 与 Plus 用户推出「开发者模式」测试版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 宣布为 ChatGPT 推出「开发者模式」（处于 Beta 测试阶段），旨在提升其在专业领域的应用能力。目前，该功能仅面向 ChatGPT Plus 和 Pro 订阅用户开放，且暂时仅支持网页端使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-84850ffcded4cb6d4d3a76793081cc84257.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用文档：&lt;em&gt;https://platform.openai.com/docs/guides/developer-mode&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;用户需在设置中的 「Connectors」 选项内手动启用开发者模式。启用后，可通过配置 MCP（Model Context Protocol，模型上下文协议）客户端，借助 SSE（Server - Sent Events）或流式 HTTP 协议，让 ChatGPT 直接访问外部系统，实现如更新 CRM 记录、在代码托管平台创建拉取请求等操作，深度融入实际开发流程。&lt;/p&gt; 
&lt;p&gt;OpenAI 强调，该模式具备高权限特性，系统会在每次工具调用时完整展示 JSON 格式的输入与输出内容，对涉及数据修改的行为，默认要求人工确认（工具标注为 「只读」 除外）。用户可选择在当前对话会话中记住授权状态，但刷新页面或开启新对话后权限将重置 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371748/chatgpt-developer-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371748/chatgpt-developer-mode</guid>
      <pubDate>Thu, 11 Sep 2025 03:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>个人开发者可免费在 Microsoft Store 发布应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软在官方博客&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindowsdeveloper%2F2025%2F09%2F10%2Ffree-developer-registration-for-individual-developers-on-microsoft-store%2F" target="_blank"&gt;宣布&lt;/a&gt;，个人开发者现在可以免费在 Microsoft Store 发布应用，无需再支付此前的 19 美元注册费。访问 storedeveloper.microsoft.com 即可开始体验。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-37643f9d87fe2549cc22b7f744c732890ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微软表示，开发者只需使用微软账户登录合作伙伴中心，扫描有效身份证件并完成自拍验证，随后回答一系列问题，即可在几分钟内获得合作伙伴中心的访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-784a448daff944810ee5d2c6ce9241cf8c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，微软还为非游戏类应用提供「0 抽成」的自建内购系统方案。如果开发者将应用打包为 MSIX 格式，微软将利用自身基础设施托管二进制文件并承担分发成本，开发者无需自建 CDN。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371746</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371746</guid>
      <pubDate>Thu, 11 Sep 2025 03:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Spring Framework 6.2.11 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#333333"&gt;Spring 团队正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspring.io%2Fblog%2F2025%2F09%2F11%2Fspring-framework-6-2-11-available%2520now" target="_blank"&gt;发布&lt;/a&gt;了 Spring Framework 6.2.11，新版本包含 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Freleases%2Ftag%2Fv6.2.11" target="_blank"&gt;23 处修复和文档改进&lt;/a&gt;&lt;span style="color:#333333"&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;新功能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JsonPathAssertions.isEqualTo 缺少&lt;code&gt;@Nullable&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35445" target="_blank"&gt;#35445&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;非默认 NIO.2 文件系统的优雅回退&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35443" target="_blank"&gt;#35443&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;避免 SseEmitter、ResponseBodyEmitter 中的线程固定&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35423" target="_blank"&gt;#35423&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;将 Informix 代码错误检测为&lt;code&gt;DuplicateKeyException&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35400" target="_blank"&gt;#35400&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ResponseCookie&lt;/code&gt;&amp;nbsp;&lt;code&gt;from*()&lt;/code&gt;factory 方法中&lt;code&gt;String value&lt;/code&gt;参数的可空性不一致&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35377" target="_blank"&gt;#35377&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;重新审视&lt;code&gt;SimpleAsyncTaskExecutor/Scheduler&lt;/code&gt;上的&lt;code&gt;taskTerminationTimeout&lt;/code&gt;语义&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35372" target="_blank"&gt;#35372&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;StandardEvaluationContext.setBeanResolver&lt;/code&gt;应支持&lt;code&gt;@Nullable BeanResolver&lt;/code&gt;&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35371" target="_blank"&gt;#35371&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;错误修复&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;「mainThreadPrefix = null」导致多个后台 bean 锁被阻塞&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35409" target="_blank"&gt;#35409&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;除非方法为 public，否则在 overridden method&amp;nbsp;中的参数上找不到注释&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35349" target="_blank"&gt;#35349&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在未解析泛型的类型层次结构中找不到 overridden method&amp;nbsp;的注释&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35342" target="_blank"&gt;#35342&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;使用 Provider 时单例 bean 性能下降&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35330" target="_blank"&gt;#35330&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spring Framework 6.2 中的 JettyClientHttpConnector 缓冲区泄漏&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35319" target="_blank"&gt;#35319&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;当定义自定义 ScheduledExecutorService bean 时，Spring 应用程序在&lt;code&gt;@Scheduled&lt;/code&gt;&lt;span style="color:#1f2328"&gt;(cron=…)&amp;nbsp;&lt;/span&gt;关闭时挂起（Java 19+）&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35316" target="_blank"&gt;#35316&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;文档&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;记录可能需要使用&lt;code&gt;Mockito.doXxx()&lt;/code&gt;来模拟&lt;code&gt;@MockitoSpyBean&lt;/code&gt;的情况&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35410" target="_blank"&gt;#35410&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复指向 Reactive Libraries 和 RestTemplate 的链接&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35392" target="_blank"&gt;#35392&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 WebDriver 文档中的损坏链接&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35374" target="_blank"&gt;#35374&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;记录 Web DataBinder 对 RouterFunction 的支持&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35367" target="_blank"&gt;#35367&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;改进&lt;code&gt;ApplicationEvents&lt;/code&gt;文档以阐明建议用法&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35335" target="_blank"&gt;#35335&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;补充&lt;code&gt;DataSize.parse()&lt;/code&gt;中的单位与术语说明&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35298" target="_blank"&gt;#35298&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;完善&lt;code&gt;@Contract&lt;/code&gt;Javadoc&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35285" target="_blank"&gt;#35285&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更正 JpaTransactionManager javadoc 中 nestedTransactionAllowed 的默认值&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fpull%2F35212" target="_blank"&gt;#35212&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#1f2328"&gt;依赖项升级&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;升级到 Micrometer 1.14.11&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35455" target="_blank"&gt;#35455&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;升级到 Reactor 2024.0.10&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-framework%2Fissues%2F35454" target="_blank"&gt;#35454&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371744/spring-framework-6-2-11-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371744/spring-framework-6-2-11-released</guid>
      <pubDate>Thu, 11 Sep 2025 03:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Apache 软件基金会启用新 Logo</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Apache 软件基金会（ASF）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.apache.org%2Ffoundation%2Fentry%2Fintroducing-the-asfs-new-logo" target="_blank"&gt;官宣&lt;/a&gt;启用新的 Logo 与品牌系统，旨在更好地反映其「社区重于代码」（community over code）的核心理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-48e6a03ea5e1e57757e584ff4907d138f7d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ASF 的新 Logo 用一片橡树叶 (oak leaf) 取代了沿用多年的羽毛图案，象征持久、稳健与社区成长：橡树叶代表 ASF 对开源项目的长期承诺，叶脉寓意分布式协作和开放治理，小橡子长成大树的意象则呼应 「社区重于代码」 的理念。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;橡树叶象征持久、稳健与耐力，橡树生长缓慢但可持续数百年，代表 ASF 对软件项目长期稳定与可持续性的承诺。&lt;/li&gt; 
 &lt;li&gt;一个小小的橡子（acorn）可长成庞大且多样的森林，象征由少数人开始，发展为包容性、自我治理的社区生态系统。&lt;/li&gt; 
 &lt;li&gt;橡树叶的叶脉结构也象征分布式系统、共识、开放合作等 ASF 的价值观。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ASF 表示，新设计延续原有品牌色调，但更加现代、适用于数字媒体；同时推出新的品牌指南，要求项目和相关材料逐步更新。从 2025 年 9 月 11 日起，对 ASF Logo 的公开使用都必须遵循新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapache.org%2Ffoundation%2Fpress%2Fkit%2F" target="_blank"&gt;品牌指南&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;此外，「The ASF」 这一缩写将在品牌视觉中广泛使用，全称 「The Apache Software Foundation」 仍在法律文件或正式场合使用。&lt;/p&gt; 
&lt;p&gt;项目名称中的 「Apache」 一词将继续保留。对其移除的考虑因影响甚广并且对生态系统与安全性有重大后果，目前不打算整体移除。对于包含原有羽毛或土著元素的项目徽标，ASF 也将提供协助，帮助符合新的价值观和视觉规范。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371742/the-asfs-new-logo</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371742/the-asfs-new-logo</guid>
      <pubDate>Thu, 11 Sep 2025 03:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁与中国人民大学发布首个原生 MoE 扩散语言模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁集团与中国人民大学联合发布业界首个原生 MoE 架构的扩散语言模型 (dLLM)「LLaDA-MoE」。&lt;/p&gt; 
&lt;p&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-7696b32900ada220e87d1e45ac5050eed98.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模型通过非自回归的掩码扩散机制，在大规模语言模型中实现了与 Qwen2.5 相当的语言智能 (如上下文学习、指令遵循、代码和数学推理等)，挑战了「语言模型必须自回归」的主流认知。&lt;/p&gt; 
&lt;p&gt;实验数据显示，LLaDA-MoE 模型性能效果在代码、数学、Agent 等任务上领先于 LLaDA1.0/1.5 和 Dream-7B 等扩散语言模型，接近或超越了自回归模型 Qwen2.5-3B-Instruct，仅激活 1.4B 参数即可实现等效 3B 稠密模型的性能。&lt;/p&gt; 
&lt;p&gt;「LLaDA-MoE 模型验证了工业级大规模训练的扩展性和稳定性，意味我们在把 dLLM 训扩到更大规模的路上又往前走了一步。」蚂蚁集团通用人工智能研究中心主任、西湖大学特聘研究员、西湖心辰创始人蓝振忠在发布现场表示。&lt;/p&gt; 
&lt;p&gt;中国人民大学高瓴人工智能学院副教授李崇轩介绍，「两年过去，AI 大模型能力突飞猛进，但存在一些问题始终没有得到本质上的解决。究其原因，这是当前大模型普遍采用的自回归生成范式所造成的——模型天然是单向建模的，从前往后依次生成下一个 token。这导致它们难以捕 tokens 之间的双向依赖关系。」&lt;/p&gt; 
&lt;p&gt;面对这些问题，一些研究者选择另辟蹊径，将目光投向并行解码的扩散语言模型。然而，现有 dLLM 均基于稠密架构，难以复刻 ARM 中 MoE 的「参数扩展、计算高效」优势。在这样的行业背景下，蚂蚁和人大联合研究团队，首次在 MoE 架构上推出了原生的扩散语言模型 LLaDA-MoE。&lt;/p&gt; 
&lt;p&gt;蓝振忠还透露，将于近期向全球完全开源模型权重和自研推理框架，与社区共同推动 AGI 新一轮突破。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371738</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371738</guid>
      <pubDate>Thu, 11 Sep 2025 03:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里巴巴、百度开始采用自研芯片训练 AI 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;《The Information》援引直接知情人士的消息&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Falibaba-baidu-adopt-ai-chips-major-shift-chinese-tech" target="_blank"&gt;报道&lt;/a&gt;，阿里巴巴和百度已开始使用自主设计的芯片训练其 AI 模型，部分替代了英伟达生产的芯片。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1108" src="https://static.oschina.net/uploads/space/2025/0912/110432_Ft9v_2720166.png" width="1058" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;报道称，自今年初以来，阿里巴巴针对轻量级 AI 模型使用自研芯片；而百度则在尝试用其昆仑 P800 芯片训练新版文心一言（Ernie）AI 模型。&lt;/p&gt; 
&lt;p&gt;不过，阿里和百度都并未完全放弃英伟达，两家公司仍在使用英伟达的芯片来开发其最尖端模型。&lt;/p&gt; 
&lt;p&gt;英伟达发言人对此表示：「竞争无疑已经到来…… 我们将继续努力，赢得全球各地主流开发者的信任与支持。」&lt;/p&gt; 
&lt;p&gt;上月，英伟达 CEO 黄仁勋 (Jensen Huang) 表示，正在与白宫讨论在华销售下一代 AI 芯片，但需要时间。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371737</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371737</guid>
      <pubDate>Thu, 11 Sep 2025 03:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥秋天了，手搓一个智能加湿器？</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2209</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2209</guid>
      <pubDate>Thu, 11 Sep 2025 03:01:00 GMT</pubDate>
    </item>
    <item>
      <title>MiniMax 发布新一代音乐生成模型 Music 1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniMax&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUzMDWMHFZDlIUZwhhBpcYQ" target="_blank"&gt;发布&lt;/a&gt;了新一代音乐生成模型 Music 1.5，单次可生成最长 4 分钟完整歌曲，支持流行、爵士、摇滚、蓝调等多种风格，并新增对中国小众及民族乐器的建模。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e9e358fdc1179f9370f0f8994ba99753ef9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模型还提供「高级模式」，允许用户用自然语言描述风格、情绪、场景，并对 Intro、Verse、Chorus 等段落进行歌词与结构级精细控制，实现段落界限清晰、副歌爆点突出的「敍事级」听觉体验。&lt;/p&gt; 
&lt;p&gt;Music 1.5 同步向全球开发者开放 API，官方称延续「全球最高性价比」策略，方便影视、游戏、短视频、虚拟偶像、企业品牌等场景快速调用。&lt;/p&gt; 
&lt;p&gt;用户可登录官网音频页面 minimaxi.com/audio/music 即刻体验，也可通过 API 将 AI 音乐能力集成至应用与创作工作流。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371732/minimax-music-15</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371732/minimax-music-15</guid>
      <pubDate>Thu, 11 Sep 2025 02:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>2025 年大语言模型架构演进：DeepSeek V3、OLMo 2、Gemma 3 与 Mistral 3.1 核心技术剖析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 在 Transformer 架构诞生八年之际，我们是否真的见证了根本性的突破，还是只是在原有设计上不断打磨？今天我们为大家带来的这篇文章，作者的核心观点是：尽管大语言模型在技术细节上持续优化，其核心架构仍保持延续，真正的创新更多体现在效率提升与工程实现上。&lt;/p&gt; 
 &lt;p&gt;文章系统梳理了 2025 年多个主流开源模型的架构演进，重点分析了 DeepSeek-V3/R1 的多头潜在注意力（MLA）与混合专家模型（MoE）、OLMo 2 的归一化层放置策略与 QK 归一化、Gemma 3 的滑动窗口注意力机制，以及 Mistral Small 3.1 在推理效率上的优化。&lt;/p&gt; 
 &lt;p&gt;这篇文章为我们提供了一个冷静而深入的视角，提醒我们在追逐 SOTA 榜单的同时，不应忽视那些真正推动技术前进的、看似细微却至关重要的架构设计选择。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Devansh and Sebastian Raschka, PhD&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;01 DeepSeek V3/R1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.1 多头潜在注意力机制（MLA）&lt;/p&gt; 
&lt;p&gt;1.2 混合专家模型（MoE）&lt;/p&gt; 
&lt;p&gt;1.3 DeepSeek 架构总结&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 OLMo 2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2.1 归一化层放置策略&lt;/p&gt; 
&lt;p&gt;2.2 QK-Norm&lt;/p&gt; 
&lt;p&gt;2.3 OLMo 2 架构总结&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 Gemma 3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;3.1 滑动窗口注意力机制&lt;/p&gt; 
&lt;p&gt;3.2 Gemma 3 的归一化层布局策略&lt;/p&gt; 
&lt;p&gt;3.3 Gemma 3 架构总结&lt;/p&gt; 
&lt;p&gt;3.4 附加内容：Gemma 3n&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;04 Mistral Small 3.1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;自最初的 GPT 架构问世以来，已经过去了七年时间。当我们回望 GPT-2（2019 年）并展望 DeepSeek-V3 与 Llama 4（2024 - 2025 年）时，可能会惊讶地发现这些模型在结构上仍然如此相似。&lt;/p&gt; 
&lt;p&gt;诚然，位置编码已从绝对位置编码发展为旋转位置编码（RoPE），多头注意力机制已普遍被分组查询注意力机制取代，而更高效的 SwiGLU 激活函数也替代了 GELU 等传统激活函数。但在这些细微改进之下，我们是否真正见证了突破性的变革？抑或只是在相同架构基础之上进行精雕细琢？&lt;/p&gt; 
&lt;p&gt;比较不同大语言模型来确定影响其性能优劣的关键因素历来充满挑战：数据集、训练技术和超参数不仅差异巨大，且往往缺乏完整记录。&lt;/p&gt; 
&lt;p&gt;尽管如此，我仍认为审视架构本身的结构性变化极具价值 ------ 这能帮助我们洞察 2025 年大语言模型开发者的核心关注点（部分架构如图 1 所示）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-09bd954abf4865d39b04771a5bb94fd00b3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 1：本文涉及的部分架构示意图&lt;/p&gt; 
&lt;p&gt;因此，本文将聚焦定义当今主流开源模型的核心架构演进，而非基准测试表现或训练算法的讨论。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 DeepSeek V3/R1&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek R1 在 2025 年 1 月发布时引起了巨大轰动。该推理模型基于 2024 年 12 月推出的 DeepSeek V3 架构构建。&lt;/p&gt; 
&lt;p&gt;虽然本文主要关注 2025 年发布的模型架构，但考虑到 DeepSeek V3 正是在 2025 年凭借 DeepSeek R1 的发布才获得广泛关注与应用，将其纳入讨论范围是合理的。&lt;/p&gt; 
&lt;p&gt;若您对 DeepSeek R1 的训练细节感兴趣，可参阅我今年早前的文章《Understanding Reasoning LLMs》[1]：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cbf78557c5b8225e22db1bcae737f415946.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本节将重点解析 DeepSeek V3 中两项提升计算效率的核心架构技术（这也是其区别于其他大语言模型的重要特征）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多头潜在注意力机制（MLA）&lt;/li&gt; 
 &lt;li&gt;混合专家模型（MoE）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 多头潜在注意力机制（MLA）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在探讨多头潜在注意力机制（MLA）之前，我们先简要回顾相关背景以理解其设计动机。让我们从分组查询注意力机制（GQA）谈起 ------ 近年来它已成为替代多头注意力机制（MHA）的新标准方案，具有更高的计算效率与参数效率。&lt;/p&gt; 
&lt;p&gt;以下是 GQA 的核心概要：与 MHA 中每个注意力头都拥有独立的键值对不同，GQA 通过让多个注意力头共享同一组键值投影来降低内存消耗。例如，如图 2 所示，若存在 2 个键值组和 4 个注意力头，则注意力头 1 与注意力头 2 可能共享一组键值，而注意力头 3 与注意力头 4 共享另一组。这种方式减少了键值计算总量，从而降低内存使用并提升效率（消融实验表明其对模型性能无明显影响）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c96d615a0c39b0040bece0b0da7c24dfbf.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 2：MHA 与 GQA 对比示意图（组大小为 2，即每两个查询头共享一组键值对）&lt;/p&gt; 
&lt;p&gt;GQA 的核心思想是通过让多个查询头共享键值头来减少键值头数量，这带来两大优势： &lt;strong&gt;（1）降低模型参数量；（2）推理时减少键值张量的内存带宽占用，因为需要存储和从 KV 缓存中检索的键值对更少。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;（若想了解 GQA 的代码实现，可参阅笔者撰写的无 KV 缓存版《GPT-2 to Llama 3 conversion guide》[2]及带 KV 缓存的改进版本[3]。）&lt;/p&gt; 
&lt;p&gt;尽管 GQA 本质上是针对 MHA 的计算效率优化方案，但消融研究（包括原版 GQA 论文[4]和 Llama 2 论文[5]）表明其在 LLM 建模性能上与标准 MHA 相当。&lt;/p&gt; 
&lt;p&gt;而多头潜在注意力机制（MLA）则提供了另一种内存优化策略，尤其与 KV 缓存机制高度契合。与 GQA 共享键值头的思路不同，MLA 将键值张量压缩至低维空间后再存入 KV 缓存。&lt;/p&gt; 
&lt;p&gt;推理时，这些压缩张量会先通过投影恢复原始尺寸后再参与计算（如图 3 所示）。虽然增加了矩阵乘法操作，但大大降低了内存占用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c43aacfdb6bb016170097f6397f3903fb7d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 3：MLA（用于 DeepSeek V3 和 R1 中）与常规 MHA 的对比示意图&lt;/p&gt; 
&lt;p&gt;（需要说明的是，查询向量在训练过程中也会被压缩，但该操作仅适用于训练阶段，不涉及推理过程。）&lt;/p&gt; 
&lt;p&gt;值得一提的是，MLA 并非 DeepSeek V3 首创 ------ 其前代版本 DeepSeek-V2 早已采用（甚至可以说是由其率先引入）这项技术。此外，V2 论文中多项有趣的消融实验或许能解释开发团队为何选择 MLA 而非 GQA（见图 4）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d4480020e0658530a184bb6537b95bbdf5f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 4：带有标注的摘自 DeepSeek-V2 论文的表格（来源：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2405.04434%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2405.04434）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如图 4 所示，GQA 的表现似乎逊于 MHA，而 MLA 的建模性能反而优于 MHA ------ 这很可能是 DeepSeek 团队舍弃 GQA 选择 MLA 的原因。（若能同时对比 MLA 与 GQA 在"每词元 KV 缓存"上的节省效果，或许会更有趣！）&lt;/p&gt; 
&lt;p&gt;对此部分进行总结：&lt;strong&gt;MLA 是一种巧妙的 KV 缓存内存优化技术，其在建模性能方面甚至较 MHA 略有提升。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 混合专家模型（MoE）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;DeepSeek 架构中另一个值得重点阐述的核心组件是其采用的混合专家模型（MoE）层。尽管 MoE 并非由 DeepSeek 首创，但今年该技术正迎来复兴浪潮，后续将讨论的诸多模型架构也都采用了这一方案。&lt;/p&gt; 
&lt;p&gt;MoE 的核心思想是将 Transformer 模块中的每个前馈网络替换为多个专家层 ------ 每个专家层本身也是前馈模块。这意味着我们用多个前馈模块替代单一前馈模块，具体如图 5 所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fd1eb2a8236e1a59888c990d003f566d18d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 5：DeepSeek V3/R1 采用的 MoE 模块（右）与标准前馈网络结构（左）对比示意图&lt;/p&gt; 
&lt;p&gt;Transformer 模块内的前馈网络（上图中深灰色模块）通常占据着模型的绝大部分参数量（需注意 Transformer 模块及其内含的前馈网络会在 LLM 中重复多次，例如 DeepSeek-V3 中就重复了 61 次）。&lt;/p&gt; 
&lt;p&gt;因此，用多个前馈模块替代单一前馈模块（MoE 的实现方式）会大大增加模型的总参数量。但并非每个 token 都会激活所有专家。相反，路由层会为每个 token 仅选择一小部分专家（由于篇幅所限，关于路由层的细节将另文详述）。&lt;/p&gt; 
&lt;p&gt;由于每次仅激活少量专家模块，MoE 系统通常被称为稀疏架构，这与始终使用全部参数的密集架构形成对比。通过 MoE 实现的庞大总参数量提升了 LLM 的容量上限，使其在训练过程中能吸收更多知识。而稀疏特性则保证了推理效率 ------ 因为我们不会同时调用所有参数。&lt;/p&gt; 
&lt;p&gt;以 DeepSeek-V3 为例：每个 MoE 模块包含 256 个专家，总参数量达 6710 亿。但在推理过程中，每次仅激活 9 个专家（1 个共享专家 + 路由层选出的 8 个专家）。这意味着每个推理步骤仅使用 370 亿参数，而非全部 6710 亿。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DeepSeek-V3 的 MoE 设计有一个特点：采用共享专家机制。这个专家会对每个 token 始终保持激活状态。&lt;/strong&gt; 该理念并非首创，早在 2024 年 DeepSeek MoE 论文[6]和 2022 年 DeepSpeedMoE 论文[7]中就已提出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-15a799b152fc26e09b06b94411da5ba9e07.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 6：带有标注的摘自《DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models》的图示，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066" target="_blank"&gt;https://arxiv.org/abs/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;共享专家的优势最初在 DeepSpeedMoE 论文[7]中被指出：相比无共享专家的设计，它能提升整体建模性能。这很可能是因为常见模式或重复模式无需由多个独立专家重复学习，从而为专家们留出更多专攻特殊化模式的空间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 DeepSeek 架构总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;总而言之，DeepSeek-V3 作为一个拥有 6710 亿参数的巨型模型，在发布时性能就超越了包括 4050 亿参数的 Llama 3 在内的其他开放权重模型。尽管参数量更大，但其推理效率却明显更高 ------ 这得益于其混合专家系统（MoE）架构的设计，该架构使得每个 token 仅激活参数总量的极小部分（仅 370 亿参数）。&lt;/p&gt; 
&lt;p&gt;另一个关键区别在于 DeepSeek-V3 采用多头潜在注意力机制（MLA）替代了分组查询注意力机制（GQA）。MLA 与 GQA 都是标准多头注意力（MHA）的高效推理替代方案，尤其在配合 KV 缓存使用时优势明显。虽然 MLA 的实现更为复杂，但 DeepSeek-V2 论文中的研究表明，其建模性能优于 GQA。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 OLMo 2&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;非营利组织艾伦人工智能研究所（Allen Institute for AI）推出的 OLMo 系列模型同样值得关注，这主要得益于其在训练数据与工程代码方面的高透明度，以及相对详尽的技术报告。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;虽然 OLMo 模型可能不会在各类基准测试或排行榜上名列前茅，但其架构设计清晰简洁。更重要的是，凭借完全开源的特性，该系列模型为 LLM 的开发提供了极佳的蓝图参考。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管 OLMo 模型因其透明性而广受欢迎，但其性能表现同样可圈可点。实际上，在今年 1 月发布时（早于 Llama 4、Gemma 3 和 Qwen 3），OLMo 2 系列模型正处于计算效率与性能的帕累托前沿【译者注："帕累托前沿"（Pareto Frontier）是一个起源于经济学和优化理论的重要概念，它描述的是一种最优状态，在这种状态下，任何一方的利益或某个目标的提升都无法不以牺牲其他方利益或其他目标的下降为代价。】，如图 7 所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-006c99086b0db6493bcd4ec05b3e2dd3345.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 7：不同 LLMs 的基准测试性能（越高越好）与预训练成本（FLOPs；越低越好）对比（这张经过标注的图片源自 OLMo 2 论文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00656%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2501.00656）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如本文开头所述，为控制篇幅，我们将聚焦于 LLM 的架构细节（暂不涉及训练细节与数据）。那么 OLMo 2 有哪些值得关注的架构设计选择？主要可归结为归一化技术的应用：包括 RMSNorm 层的布局以及新增的 QK 归一化设计（后续将详细讨论）。&lt;/p&gt; 
&lt;p&gt;另值得一提的是，OLMo 2 仍采用传统多头注意力（MHA）机制，而非 MLA 或 GQA。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 归一化层放置策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;总体而言，OLMo 2 基本遵循了原始 GPT 的架构设计，这与当代其他大语言模型相似。但其仍存在一些值得关注的差异，让我们先从归一化层说起。&lt;/p&gt; 
&lt;p&gt;与 Llama、Gemma 及多数主流大语言模型类似，OLMo 2 也将 LayerNorm 层替换为了 RMSNorm 层。&lt;/p&gt; 
&lt;p&gt;但由于 RMSNorm 已是成熟技术（本质上是 LayerNorm 的简化版，拥有更少的可训练参数），本文将不再讨论 RMSNorm 与 LayerNorm 的区别（感兴趣的读者可参阅笔者撰写的《GPT-2 to Llama conversion guide》[8]中的 RMSNorm 代码实现）。&lt;/p&gt; 
&lt;p&gt;然而，RMSNorm 层的放置位置值得深入探讨。原始 Transformer 架构（出自《Attention is all you need》[9]论文）将两个归一化层分别放置在注意力模块和前馈网络模块之后。&lt;/p&gt; 
&lt;p&gt;这种设计被称为后归一化（Post-LN 或 Post-Norm）。&lt;/p&gt; 
&lt;p&gt;而 GPT 及之后大多数大语言模型则将归一化层置于注意力模块和前馈网络模块之前，称为前归一化（Pre-LN 或 Pre-Norm）。两种归一化方式的对比如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f4a2fae83b7a11949e42208b3caa34523d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 8：后归一化、前归一化与 OLMo 2 采用的后归一化变体对比示意图&lt;/p&gt; 
&lt;p&gt;2020 年，Xiong 等人通过研究[10]证明：前归一化能使梯度在初始化阶段表现更稳定。研究人员还指出，前归一化即使不配合精细的学习率预热策略也能良好工作，而这对于后归一化而言却是至关重要的训练保障。&lt;/p&gt; 
&lt;p&gt;此处特别提及该研究是因为 OLMo 2 采用了一种后归一化变体（但使用 RMSNorm 替代了 LayerNorm，故称其为 Post-Norm）。&lt;/p&gt; 
&lt;p&gt;在 OLMo 2 中，归一化层被放置在注意力层和前馈网络层之后（而非之前），如上图所示。但请注意：与原始 Transformer 架构不同，这些归一化层仍位于残差层（跳跃连接）内部。&lt;/p&gt; 
&lt;p&gt;那么为何要调整归一化层的位置？原因在于这种设计能提升训练稳定性，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2ef106b336705a7b4016f23c379c087df1c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 9：前归一化（GPT-2、Llama 3 等模型采用）与 OLMo 2 后归一化变体的训练稳定性对比图。此带有标注的图表取自 OLMo 2 论文，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00656" target="_blank"&gt;https://arxiv.org/abs/2501.00656&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;遗憾的是，该图表将归一化层重定位与 QK-Norm（另一个独立概念）的效果合并展示，因此难以单独判断归一化层位置调整的具体贡献程度。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 QK-Norm&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;既然上一节已提及 QK-Norm，且后续将讨论的其他大语言模型（如 Gemma 2 和 Gemma 3）也采用了该技术，我们不妨简要探讨一下其原理。&lt;/p&gt; 
&lt;p&gt;QK-Norm 本质上是另一个 RMSNorm 层。它被置于多头注意力（MHA）模块内部，在应用旋转位置编码（RoPE）之前对查询向量（q）和键向量（k）进行归一化处理。为直观说明，以下内容摘录自我在《Qwen3 from-scratch implementation》[11]编写的分组查询注意力（GQA）层代码（GQA 中的 QK-Norm 应用方式与 OLMo 的 MHA 类似）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c4bc7af7b40fc5cdcb60d387600a0022cda.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如前文所述，QK-Norm 与后归一化配合使用可提升训练稳定性。需要注意的是，QK-Norm 并非由 OLMo 2 首创，其最早可追溯至 2023 年发表的《Scaling Vision Transformers》[12]论文。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 OLMo 2 架构总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;简而言之，&lt;strong&gt;OLMo 2 值得关注的架构设计决策主要集中于 RMSNorm 的放置策略&lt;/strong&gt;：将 RMSNorm 置于注意力模块和前馈网络模块之后（一种后归一化变体），而非之前。同时在注意力机制内部为查询向量和键向量添加 RMSNorm（即 QK-Norm）。这两项改进共同作用，有效稳定了训练损失。&lt;/p&gt; 
&lt;p&gt;下图进一步对比了 OLMo 2 与 Llama 3 的架构差异：可见除 OLMo 2 仍采用传统 MHA 而非 GQA 外，两者结构总体相似（但 OLMo 2 团队在三个月后发布了采用 GQA 的 320 亿参数变体）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bdbcbce349892ba75c88a65efd77c6c32c5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 10：Llama 3 与 OLMo 2 的架构对比示意图&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 Gemma 3&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Google 的 Gemma 系列模型始终保持着卓越的性能，但与 Llama 等热门模型相比，其关注度始终略显不足。&lt;/p&gt; 
&lt;p&gt;Gemma 的显著特征之一是其超大的词表规模（以便更好地支持多语言场景），以及更侧重 27B 参数规格（而非 8B 或 70B）。需注意的是，Gemma 2 也提供更小规格版本：1B、4B 与 12B。&lt;/p&gt; 
&lt;p&gt;27B 规格堪称最佳平衡点：性能远超 8B 模型，资源消耗却远低于 70B 模型，甚至能在 Mac Mini 上实现本地流畅运行。&lt;/p&gt; 
&lt;p&gt;那么 Gemma 3[13] 还有哪些亮点？如前文所述，DeepSeek-V3/R1 等模型采用 MoE 架构在固定模型规模下降低推理内存需求（后续讨论的其他模型也采用了 MoE 方案）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gemma 3 则运用了不同的技巧来减少计算开销 ------ 即滑动窗口注意力机制。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 滑动窗口注意力机制&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;通过采用滑动窗口注意力机制（该技术最初在 2020 年由 LongFormer 论文[14]提出，Gemma 2[15] 也已采用），Gemma 3 团队大大降低了 KV 缓存的内存需求，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4e8fa5253791a93c43da4e975a37a262b5b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 11：带有标注的 Gemma 3 论文示意图（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt; ），展示了滑动窗口注意力机制对 KV 缓存的内存节省效果&lt;/p&gt; 
&lt;p&gt;那么什么是滑动窗口注意力机制？如果将常规自注意力视为全局注意力机制（每个序列元素可访问任意其他元素），那么滑动窗口注意力可理解为局部注意力 ------ 它会限制当前查询位置周围的上下文大小，具体如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3804c7cd9fa56d227e81dcc2585710a01d1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 12：常规注意力（左）与滑动窗口注意力（右）对比示意图&lt;/p&gt; 
&lt;p&gt;需要注意的是，滑动窗口注意力可同时适用于多头注意力和分组查询注意力，Gemma 3 采用的是分组查询注意力版本。&lt;/p&gt; 
&lt;p&gt;如前文所述，滑动窗口注意力又称为"局部注意力"，因为其滑动窗口会围绕当前查询位置移动。相比之下，常规注意力是全局性的，每个词元都能访问所有其他词元。&lt;/p&gt; 
&lt;p&gt;不过，前代架构 Gemma 2 早已采用滑动窗口注意力。Gemma 3 的改进在于调整了全局注意力（常规）与局部注意力（滑动）的比例。&lt;/p&gt; 
&lt;p&gt;例如，Gemma 2 采用混合注意力机制，以 1:1 的比例结合滑动窗口（局部）与全局注意力，每个词元可关注附近 4K 词元的上下文窗口。&lt;/p&gt; 
&lt;p&gt;Gemma 2 在每一层都使用滑动窗口注意力，而 Gemma 3 将比例调整为 5:1 ------ 即每 5 个滑动窗口（局部）注意力层才设置 1 个全局注意力层。同时滑动窗口大小从 Gemma 2 的 4096 缩减至 1024。这种设计使模型更聚焦于高效的局部计算。&lt;/p&gt; 
&lt;p&gt;根据消融实验，滑动窗口注意力对建模性能的影响微乎其微，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d9c12fc9217cd8821aabbbd87877b18afb5.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 13：带有标注的 Gemma 3 论文示意图（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt; ），表明滑动窗口注意力对大语言模型输出困惑度的影响极小&lt;/p&gt; 
&lt;p&gt;虽然滑动窗口注意力是 Gemma 3 最显著的架构特性，但作为前文 OLMo 2 章节的延续，我们还需简要讨论其归一化层的布局策略。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 Gemma 3 的归一化层布局策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一个虽细微却值得关注的设计是：Gemma 3 在其分组查询注意力模块周围同时采用了前归一化（Pre-Norm）与后归一化（Post-Norm）的 RMSNorm 配置。&lt;/p&gt; 
&lt;p&gt;此设计虽与 Gemma 2 类似，但仍值得强调 ------ 因为它既不同于原始 Transformer（《Attention is all you need》）采用的后归一化，也区别于 GPT-2 推广并被后续众多模型架构采用的前归一化，同时与我们前文讨论的 OLMo 2 后归一化变体存在差异。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-473b00d7dce6402f9ee06bd10213cbb62bd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 14：OLMo 2 与 Gemma 3 的架构对比图。注意 Gemma 3 中增加的归一化层&lt;/p&gt; 
&lt;p&gt;笔者认为这种归一化层布局是一种直观而高效的方案，它融合了前归一化和后归一化的双重优势。从实践角度看，适当增加的归一化操作通常利大于弊：在最坏情况下，即便存在冗余也仅会带来轻微的效率损失。由于 RMSNorm 在整体计算开销中占比极低，这种设计实际上不会产生明显影响。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 Gemma 3 架构总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Gemma 3 是一款性能优异的开放权重大语言模型，但其在开源社区中的认可度与其实力并不匹配。最引人注目的是其采用滑动窗口注意力提升效率的设计（未来若能与 MoE 结合将更具想象空间）。&lt;/p&gt; 
&lt;p&gt;此外，Gemma 3 采用独特的归一化层布局策略，在注意力模块和前馈网络模块前后均部署了 RMSNorm 层。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.4 附加内容：Gemma 3n&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Gemma 3 发布数月后，谷歌推出了专为移动设备优化的 Gemma 3n[16] 版本，其核心目标是实现在手机端高效运行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gemma 3n 为提升效率做出的改进之一是引入 Per-Layer Embedding（PLE）层。&lt;/strong&gt; 该设计的核心思想是不将整个模型的所有参数都加载到昂贵的 GPU 内存中，而是只保留其中最核心、最常用的一部分，而文本、音频、视觉等模态的特定词元层嵌入则按需从 CPU 或 SSD 动态加载。&lt;/p&gt; 
&lt;p&gt;下图展示了 PLE 机制的内存优化效果：标准 Gemma 3 模型（可能指 4B 参数版本）标注的参数量为 5.44B。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ad705647f86ab59e5d74cd0e81e9e68faaa.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 15：经过标注的摘自谷歌 Gemma 3n 相关博客的示意图（ &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fintroducing-gemma-3n%2F" target="_blank"&gt;https://developers.googleblog.com/en/introducing-gemma-3n/&lt;/a&gt; ），展示了 PLE 内存优化机制&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.44B 与 4B 参数的统计差异源于谷歌采用了一种特殊的参数计数方式：他们通常排除嵌入参数以使模型显得更小，但在需要凸显规模时（比如此处）又会将其计入。这种统计方式并非谷歌独有，已成为行业普遍做法。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;另一项有趣的技术是 MatFormer[17] 概念（Matryoshka Transformer 的简称）。例如，Gemma 3n 使用一个共享的 LLM（Transformer）架构，可以将其切割成多个更小的、独立运行的子模型。每个子模型经过独立训练后均能单独运行，因此在推理时只需调用所需的部分（无需启动整个大模型）。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 Mistral Small 3.1&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;于 Gemma 3 发布后不久在三月问世的 Mistral Small 3.1 24B[18] 值得关注 ------ 它在多项基准测试（除数学外）中性能超越 Gemma 3 27B，且推理速度更快。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Mistral Small 3.1 推理延迟低于 Gemma 3 的原因可能包括：定制化的分词器、KV 缓存压缩以及层数的精简。&lt;/strong&gt; 其余部分则采用标准架构（如下图对比所示）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-454b0fa436afef4f674c8d6365b209aa441.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 16：Gemma 3 27B 与 Mistral 3.1 Small 24B 架构对比示意图&lt;/p&gt; 
&lt;p&gt;有趣的是，早期 Mistral 模型曾采用滑动窗口注意力机制，但该设计在 Mistral Small 3.1 中被弃用。由于 Mistral 改用标准的分组查询注意力（而非 Gemma 3 采用的滑动窗口注意力），其或许能通过调用经过深度优化的底层计算代码（如 FlashAttention）进一步降低推理开销。例如，笔者推测：滑动窗口注意力机制虽降低了内存占用，但未必会减少推理延迟 ------ 而这正是 Mistral Small 3.1 的核心优化目标。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你是否同意"过去几年 Transformer 架构没有根本性突破"这一观点？为什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagazine.sebastianraschka.com%2Fp%2Funderstanding-reasoning-llms" target="_blank"&gt;https://magazine.sebastianraschka.com/p/understanding-reasoning-llms&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fch05%2F07_gpt_to_llama%2Fconverting-llama2-to-llama3.ipynb" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-llama2-to-llama3.ipynb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fpkg%2Fllms_from_scratch%2Fllama3.py" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/pkg/llms_from_scratch/llama3.py&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13245" target="_blank"&gt;https://arxiv.org/abs/2305.13245&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.09288" target="_blank"&gt;https://arxiv.org/abs/2307.09288&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2401.06066" target="_blank"&gt;https://arxiv.org/abs/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2201.05596" target="_blank"&gt;https://arxiv.org/abs/2201.05596&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Fblob%2Fmain%2Fch05%2F07_gpt_to_llama%2Fconverting-gpt-to-llama2.ipynb" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-gpt-to-llama2.ipynb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762" target="_blank"&gt;https://arxiv.org/abs/1706.03762&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2002.04745" target="_blank"&gt;https://arxiv.org/abs/2002.04745&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Frasbt%2FLLMs-from-scratch%2Ftree%2Fmain%2Fch05%2F11_qwen3" target="_blank"&gt;https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/11_qwen3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2302.05442" target="_blank"&gt;https://arxiv.org/abs/2302.05442&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.19786" target="_blank"&gt;https://arxiv.org/abs/2503.19786&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2004.05150" target="_blank"&gt;https://arxiv.org/abs/2004.05150&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Farxiv.org%2Fabs%2F2408.00118" target="_blank"&gt;http://arxiv.org/abs/2408.00118&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fintroducing-gemma-3n%2F" target="_blank"&gt;https://developers.googleblog.com/en/introducing-gemma-3n/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2310.07707" target="_blank"&gt;https://arxiv.org/abs/2310.07707&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmistral-small-3-1" target="_blank"&gt;https://mistral.ai/news/mistral-small-3-1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartificialintelligencemadesimple.substack.com%2Fp%2Fa-look-through-the-seven-years-of" target="_blank"&gt;https://artificialintelligencemadesimple.substack.com/p/a-look-through-the-seven-years-of&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18691557</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18691557</guid>
      <pubDate>Thu, 11 Sep 2025 02:41:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>美团首款 AI Agent 产品「小美」开启公测</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;美团首款 AI Agent 产品「小美」App 已于昨日开启公测，目前可通过苹果 App Store 及各大安卓厂商的应用商店进行下载。&lt;/p&gt; 
&lt;p&gt;这款产品在 App Store 显示为「小美-AI 生活小秘书」，首发版本号 1.6.0，现在已经更新到 1.6.1 版本，体积约 128.8MB，需要 iOS 14.0 或更高版本。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;应用描述：&lt;/p&gt; 
 &lt;p&gt;小美是一款能够帮你想，代你办的 AI 生活小秘书，让你的生活更轻松，TA 能够：&lt;/p&gt; 
 &lt;p&gt;一句话帮你点外卖，一杯奶茶、一份工作餐，只需要一句话就够了；&lt;/p&gt; 
 &lt;p&gt;不仅能一两句话帮你选好餐厅，还能帮你包办订座排队；&lt;/p&gt; 
 &lt;p&gt;规划你的一周早餐、咖啡，每天都要来杯冰美式？告诉小美，接下来你就不需要操心了，都交给 TA！&lt;/p&gt; 
 &lt;p&gt;小美还在学习更多技能，包括打车、订酒店机票、买电影票、预约按摩店等。有了小美，你的生活会更加高效、便捷、轻松。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据官方介绍，小美已全面接入美团 App 的外卖、旅游、酒店预订等核心业务。用户通过语音或文字指令可完成「帮我找附近评分 4.5 以上的川菜馆」「明天下午三点预约故宫门票」等操作，系统会结合实时数据（如商家忙闲状态、景点余票）自动推荐最优方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3a53ae8c390a81ec615ab4e375c3fbb93c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;针对企业用户，小美推出 Nocode 工具，支持 3 分钟生成活动 H5 页面、自动爬取竞品数据生成对比报表，甚至拖拽式搭建问卷调查系统，大幅降低非技术人员的数字化门槛。&lt;/p&gt; 
&lt;p&gt;此外，小美具备智能日程管理功能，能帮助用户设置提醒、安排会议、规划每日行程，避免重要事项遗漏。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371728</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371728</guid>
      <pubDate>Thu, 11 Sep 2025 02:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
