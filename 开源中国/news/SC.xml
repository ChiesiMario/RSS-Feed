<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 24 Jul 2025 12:48:48 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>AI 搜索创企 Perplexity CEO 盛赞 Qwen3-Coder</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 24 日，全球知名 AI 搜索 Perplexity CEO Aravind Srinivas&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAravSrinivas%2Fstatus%2F1947810865685925906" target="_blank"&gt;发推&lt;/a&gt;盛赞阿里开源的 Qwen3-Coder，称「令人惊叹的成绩！开源赢爆了。」&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/194007_8Vgc_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-Coder 具备全球顶级的 Agent 能力，在 SWE-Bench Multilingual、Aider-Polyglot、Spider2、Mind2Web 等多项 Agent 能力指标中超越美国 Claude4 模型，取得最佳性能表现，而 Qwen3-Coder API 价格远低于 Claude，平均仅为其三分之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362182</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362182</guid>
      <pubDate>Thu, 17 Jul 2025 11:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 开源创新大模型架构 AU-Nets</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 开源了创新大模型架构 AU-Nets（Autoregressive U-Nets），其通过自回归 U-Net 架构彻底改变了传统语言模型的分词和处理模式，能够直接从原始字节开始学习，动态将字节组合成单词、词对甚至多达四个单词的组合，形成多尺度序列表示。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1542" src="https://static.oschina.net/uploads/space/2025/0724/181937_815x_2720166.png" width="1300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://arxiv.org/pdf/2506.14761&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AU-Nets 的设计灵感来源于医学图像分割领域的 U-Net 架构，包含独特的收缩路径（压缩字节序列为高层次语义单元，提取宏观语义信息）和扩张路径（逐步还原高层次信息到原始序列长度，融合局部细节），并通过跳跃连接确保信息不丢失，提升生成能力和预测准确性 。在推理阶段，AU-Nets 采用自回归生成机制，确保文本生成的连贯性和准确性，同时提高推理效率。&lt;/p&gt; 
&lt;p&gt;该架构已开源，相关代码和研究成果已发布在 GitHub：https://github.com/facebookresearch/lingua/tree/main/apps/aunet&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362169</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362169</guid>
      <pubDate>Thu, 17 Jul 2025 10:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​美国职场现象：六分之一员工因 AI 焦虑而 「假装」 使用人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;在美国职场，人工智能（AI）的迅速普及正对员工的工作产生深远影响。最近，近岸招聘公司 Howdy.com 发布的一项调查&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.howdy.com%2Fblog%2FAI-fatigue-statistics" target="_blank"&gt;显示&lt;/a&gt;，约有 16% 的员工在工作中会假装使用 AI，目的是为了取悦他们的上司。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="290" src="https://oscimg.oschina.net/oscnet/up-82e59bc11cccaec03f5b3a940d3ec6159fd.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;调查发现，约四分之三的雇主期待员工以某种形式使用 AI，其中大约一半的人是在正式的工作场合使用，另有四分之一则是在非正式场合。然而，由于对 AI 的不安和缺乏信心，很多员工在没有足够能力的情况下依然感到必须使用这项技术。超过五分之一的员工在面对 AI 的时候感到不安，甚至在某些情况下会选择，迎合这种新技术。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管很多公司声称 AI 可以帮助提高工作效率，但实际上，三分之一的员工认为，学习和使用 AI 所耗费的时间与传统工作方式差不多。此外，很多员工在使用 AI 输出的结果时，并没有进行严格的检查，导致潜在错误的增加。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;更有趣的是，除了假装使用 AI 的员工，还有一些人在实际上使用 AI，但却选择不告诉他们的上司。根据 Slack 去年 10 月的调查，约 48% 的全球办公员工表示，他们对向管理层坦白使用 AI 感到不安，害怕被视为能力不足或不够勤奋。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 带来的焦虑不仅限于对工作的影响。根据皮尤研究中心的调查，近一半的受访美国工人担心 AI 会导致未来就业机会的减少。对于那些没有接受任何 AI 使用培训的员工来说，这种焦虑尤为明显。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Howdy.com 的 CEO 杰奎琳・萨米拉指出，面对新技术，员工应当主动学习并实践，而不仅仅是依赖公司提供的支持。她强调，员工应勇敢地迎接这些变化，适应新的工作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362155</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362155</guid>
      <pubDate>Thu, 17 Jul 2025 09:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 25 已正式适配魔方派 3 (RUBIK Pi 3) 开发板</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;deepin（深度）社区近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FTPp11JDf32IZ6eGaLJZZ4A" target="_blank"&gt;宣布&lt;/a&gt;，deepin 25 已正式适配魔方派 3(RUBIK Pi 3) 开发板，并完成产品兼容性认证。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;测试结果表明，双方产品在兼容性、性能及稳定性等方面均达到预期标准，整体运行流畅。此次适配不仅实现了系统的稳定运行，还预装了 UOS AI、跨端协同等自研应用，为开发者和极客玩家提供了强大的开发平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;魔方派 3 (RUBIK Pi 3) 基于高通跃龙 QCS6490 芯片，采用 Qualcomm® Kryo™ 670 CPU 和融合 AI 加速器架构的 Qualcomm® Hexagon™ 处理器，具备 12 TOPS 的卓越 AI 性能，适用于各种机器学习和人工智能应用场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;RUBIK Pi 3 具有丰富的接口和功能设计，支持 USB、Camera、DP、HDMI、ETH、3.5mm 耳机、Wi-Fi、BT、M.2 连接器、FAN、RTC、40 pin 排针连接器等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-f635beff7fa33a9c4e36803deb417ec8feb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;运行实例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-10a1698a018fb4608450cc6a984ecee395a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="317" src="https://oscimg.oschina.net/oscnet/up-fb015474f9a4a7258c78a128ad132b65675.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;预装软件列表&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;内核与驱动：6.8.0-1042-rubikpi，Adreno 643 GPU 驱动，其他常用硬件驱动；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;桌面体验：完整的 deepin 桌面环境；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;实用软件：预装包括深度终端、系统监视器、设备管理器、UOS AI、跨端协同等自研应用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362148</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362148</guid>
      <pubDate>Thu, 17 Jul 2025 09:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>VictoriaLogs —— 日志存储系统</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;VictoriaLogs 是一个快速且易于使用的日志数据库，可高效处理数 TB 的日志。&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#08091c"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VictoriaLogs 提供以下功能：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;它资源高效且速度快。与其他解决方案（例如 Elasticsearch 和 Grafana Loki）相比，它占用的内存最多可减少 30 倍，磁盘空间最多可减少 15 倍。有关详细信息，参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/#benchmarks"&gt;这些基准测试&lt;/a&gt;&amp;nbsp;和&lt;a href="https://itnext.io/how-do-open-source-solutions-for-logs-work-elasticsearch-loki-and-victorialogs-9f7097ecbc2f" target="_blank"&gt;本文&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;VictoriaLogs 的容量和性能与可用资源（CPU、RAM、磁盘 IO、磁盘空间）线性扩展。它可在 Raspberry PI 以及拥有数百个 CPU 核心和数 TB RAM 的服务器上流畅运行。它还可以在&lt;a href="https://docs.victoriametrics.com/victorialogs/cluster/"&gt;集群模式&lt;/a&gt;下水平扩展到多个节点 。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它可以接受来自主流日志收集器的日志。参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/data-ingestion/"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;与 Elasticsearch 和 Grafana Loki 相比，它的设置和操作更加简单，因为它基本上是零配置的。参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/quickstart/"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;&lt;a href="https://docs.victoriametrics.com/victorialogs/keyconcepts/#data-model"&gt;它提供了简单而强大的查询语言，具有跨所有日志字段&lt;/a&gt;的全文搜索功能&amp;nbsp;。参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/logsql/"&gt;LogsQL 文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#web-ui"&gt;内置的 Web UI&lt;/a&gt;&amp;nbsp;来探索日志。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/victorialogs-datasource/"&gt;Grafana 插件&lt;/a&gt;&amp;nbsp;，用于在 Grafana 中构建任意仪表板。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它提供了&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/vlogscli/"&gt;用于查询 VictoriaLogs 的交互式命令行工具&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它可以与常用的 Unix 日志分析工具（如 grep、less、sort、jq 等）无缝结合。有关详细信息参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#command-line"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持诸如 trace_id、user_id 和 ip 等卡片性较高的&lt;a href="https://docs.victoriametrics.com/victorialogs/keyconcepts/#data-model"&gt;日志字段&lt;/a&gt;（如唯一值较多的字段）。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它针对具有数百个字段的日志（又名&lt;a href="https://jeremymorrell.dev/blog/a-practitioners-guide-to-wide-events/" target="_blank"&gt;&lt;code&gt;wide events&lt;/code&gt;&lt;/a&gt;&amp;nbsp;）进行了优化。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持多租户 - 参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/#multitenancy"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持无序日志的摄取，又称回填。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持对新提取的日志进行实时跟踪。参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/querying/#live-tailing"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持选择所选日志前后的周围日志。参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/logsql/#stream_context-pipe"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;li style="text-align:start"&gt;它支持警报 - 参阅&lt;a href="https://docs.victoriametrics.com/victorialogs/vmalert/"&gt;这些文档&lt;/a&gt;&amp;nbsp;。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/victorialogs</link>
      <guid isPermaLink="false">https://www.oschina.net/p/victorialogs</guid>
      <pubDate>Thu, 17 Jul 2025 08:51:00 GMT</pubDate>
    </item>
    <item>
      <title>谷歌「AI Overview」导致搜索点击量大幅下降</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌已经为其搜索结果页面引入&lt;strong&gt;「AI 概览（AI Overviews）」&lt;/strong&gt;功能，它宣称该功能不会抢走网站的流量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4ae0ca1827c319e22cf31392e7a034a54d1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;然而皮尤研究中心（Pew Research Center）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pewresearch.org%2Fshort-reads%2F2025%2F07%2F22%2Fgoogle-users-are-less-likely-to-click-on-links-when-an-ai-summary-appears-in-the-results%2F" target="_blank"&gt;近日发布的一项实证分析&lt;/a&gt;给出了不同的答案：AI 摘要会显著降低搜索结果页的点击率。&lt;/p&gt; 
&lt;p&gt;数据显示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在没有 AI 概览的搜索结果页中，用户平均点击网页链接的比例为 &lt;strong&gt;15%&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一旦加入 AI 概览，这一比例骤降至 &lt;strong&gt;8%&lt;/strong&gt;，&lt;strong&gt;几乎腰斩&lt;/strong&gt;；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;仅有 1% 的用户会点击 AI 概览中引用的原始来源链接&lt;/strong&gt;，例如 Wikipedia、Reddit 或新闻媒体网站。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更令人担忧的是，用户在看到 AI 概览之后更可能关闭会话，也就是不再继续搜索，不去验证 AI 摘要是否正确——而幻觉是生成式 AI 的固有问题，幻觉指的是虚构的错误信息。研究表明，谷歌对 AI 的使用正在改变收集信息与搜索结果互动的方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d5b4b30673b45c62e4f85e6863e8bb41562.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;面对这一研究，谷歌态度强硬，公开反驳道：「AI 概览并未减少搜索点击，皮尤的研究方法不严谨」，并同时声称，Search Console 仍在持续记录到「庞大的点击流量」，但并未披露详细数据以佐证。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362143</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362143</guid>
      <pubDate>Thu, 17 Jul 2025 08:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 透露：ChatGPT 用户每天发送超过 25 亿条提示词</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.axios.com%2F2025%2F07%2F21%2Fsam-altman-openai-trump-dc-fed" target="_blank"&gt;据 Axios 报道&lt;/a&gt;，OpenAI 透露称，ChatGPT 平均每天要收到用户发送的 25 亿条提示词，而其中约有 3.3 亿条来自美国用户。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/162840_G5T5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为对比，Google 母公司 Alphabet 虽没有公开每日数据，但据 Axios 援引消息显示，Google 每年接收到 5 万亿次的查询，每天平均约有 140 亿次搜索，而 OpenAI 使用频率已经逼近 Google 搜索量的五分之一。&lt;/p&gt; 
&lt;p&gt;部分数据如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;每天触发约 25 亿条提示请求&lt;/strong&gt;，来源全球用户，其中约 &lt;strong&gt;3.3 亿&lt;/strong&gt; 来自美国&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;相当于每年约 &lt;strong&gt;9,125 亿&lt;/strong&gt; 次交互请求&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;2024 年 12 月，ChatGPT 日请求达到 10 亿；7 月底已增长至 25 亿，使用量在不到 8 个月时间里翻了一番&lt;/li&gt; 
 &lt;li&gt;虽然 ChatGPT 请求量仍低于 Google 的每日约 137–164 亿搜索，但其成长速度和普及程度正在展现强大的竞争力&lt;/li&gt; 
 &lt;li&gt;ChatGPT 的全球用户量超过 &lt;strong&gt;5 亿&lt;/strong&gt; 每周活跃用户，自去年 12 月 3 亿增加至现在的 5 亿&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;值得一提的是，去年 OpenAI CEO Sam Altman 曾表示，用户平均每天向 ChatGPT 发送超 10 亿条提示词，而如今该数据已翻倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362137</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362137</guid>
      <pubDate>Thu, 17 Jul 2025 08:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克公开邀请 Andrej Karpathy 加入团队</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;马斯克在社交媒体上公开邀请前 OpenAI 创始成员及前特斯拉 AI 负责人 Andrej Karpathy 加入其团队。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0724/151856_QYcy_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Andrej Karpathy 曾在特斯拉担任 AI 高级总监、自动驾驶负责人，并于 2022 年 7 月宣布离职。在特斯拉任职期间，Karpathy 主要负责 Autopilot 半自动驾驶软件的研发工作。&lt;/p&gt; 
&lt;p&gt;今年 6 月，Andrej Karpathy 在 Y Combinator 的 AI 创业学院活动上&lt;a href="https://www.oschina.net/news/356402"&gt;进行个人演讲&lt;/a&gt;，提出了「软件 3.0 时代」这一概念，他认为自然语言正在取代传统代码，而大型语言模型（LLM）则成为新的「万能计算机」。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="556" src="https://static.oschina.net/uploads/space/2025/0620/142721_2fd9_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362132</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362132</guid>
      <pubDate>Thu, 17 Jul 2025 08:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>硅谷 AI 初创拥抱「996」工作制</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 AI 创业高潮下，硅谷多家 AI 初创公司开始&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ftechnology%2Fcomments%2F1m76nov%2Fsilicon_valley_ai_startups_are_embracing_chinas%2F" target="_blank"&gt;采用「996」工作制&lt;/a&gt;（早九晚九，一周六天，共 72 小时），远超标准工时两倍，甚至直接沿用该名称以加速追赶中国 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/160527_QBWR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;例如，AI 初创公司 Rilla 约 80 名员工几乎都遵守「996」，其招聘启事明确要求每周工作超 70 小时，并提供每日三餐 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-53380d32d380ac65d98f5c6458d050cd93f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 物流初创公司 Sotira 的 CEO Amrita Bhasin 认为，创始人在创业前两年需「996」，但不应将此强加给普通员工 。一些公司尝试以加薪和股权增幅（如 25% 加薪、100% 股权增幅）吸引员工加入「996」，但报名人数寥寥（不到 10%）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-659df0cbdae84a2ca02dc409471f27a7ae1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管「996」在中国备受争议，美国 AI 初创公司却将其视为竞争利器，甚至部分投资人将其视为「美德」，优先投资实行该工作节奏的企业 。不过，这种高强度工作文化也引发担忧，如法律风险和对员工健康的潜在影响。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362131/silicon-valley-996-work-schedule</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362131/silicon-valley-996-work-schedule</guid>
      <pubDate>Thu, 17 Jul 2025 08:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 和 Qwen-3 Coder 针对编程任务的详细对比</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FzevDf6s5qt2QzcshSeAx_g" target="_blank"&gt;https://mp.weixin.qq.com/s/zevDf6s5qt2QzcshSeAx_g&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在对 Kimi K2 和 Qwen-3 Coder 进行了长达 12 小时的对比测试后，有了一些颇具启发性的发现。这次测试围绕真实的 Rust 开发任务和前端重构任务展开，两个模型在相同的开发环境中表现出了截然不同的效果。结果显示，一款模型能稳定产出可运行的代码，而另一款却在理解基本指令上频频出错。这种实际测试中的落差，揭示了一个重要事实：看起来亮眼的基准测试成绩，可能并不能代表模型在真实项目中的实际表现。与其迷信榜单分数，不如在自己的代码库中亲自试试。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;测试方法：真实开发场景模拟&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;这次对比完全基于实际开发工作，旨在还原日常的 Rust 编程过程。没有任何合成的基准题或「玩具级」的小任务，而是从一个成熟的、拥有 38,000 行代码的 Rust 项目中挑选了 13 个具有挑战性的任务，涵盖复杂的异步模式、错误处理和架构限制。此外，还包括 2 个基于 12,000 行 React 代码的前端重构任务。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;测试环境说明&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;项目背景：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Rust 版本为 1.86，使用 tokio 异步运行时&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;总代码量 38,000 行，分布在多个模块中&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用控制反转（IoC）的复杂依赖注入模式&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大量使用 traits、泛型、async/await&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配有完整的集成测试套件&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端为基于现代 hooks 和组件模式的 React，约 12,000 行代码&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供了详细的编码规范文档（以自定义规则、Cursor 规则、Claude 规则等形式供不同 Agent 使用）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;测试任务类别&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;指定文件修改（4 项）&lt;/strong&gt;：对指定文件进行精确改动&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;问题排查与修复（5 项）&lt;/strong&gt;：定位真实 Bug，附带复现步骤和失败测试&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新功能开发（4 项）&lt;/strong&gt;：根据明确需求开发新功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;前端代码重构（2 项）&lt;/strong&gt;：利用 Forge Agent 和 Playwright MCP 完成 UI 优化&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;评估维度&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代码是否正确、是否能成功编译&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否准确理解指令、是否遵循任务范围&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成所需时间&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成一个任务所需的迭代次数&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最终实现的质量&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Token 使用效率&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这次测试的核心结论是：模型在真实项目代码库中的实际表现，远比各种人工基准分数更具参考价值。尤其是在结构复杂、规则明确的大型项目中，模型的「实际工程力」才是真正决定它能否落地使用的关键。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能分析：整体任务完成情况总结&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在这轮全面测试中，我们对两个模型在一系列真实开发任务中的表现进行了细致评估。以下是整体任务完成度的汇总分析：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Category&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Kimi K2 Success Rate&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Qwen-3 Coder Success Rate&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;Time Difference&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Pointed File Changes&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/4 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;3/4 (75%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2.1x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Bug Detection &amp;amp; Fixing&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/5 (80%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1/5 (20%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;3.2x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Feature Implementation&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;4/4 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2/4 (50%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2.8x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;Frontend Refactor&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;2/2 (100%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1/2 (50%)&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;1.9x faster&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;14/15 (93%)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;7/15 (47%)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt;&lt;strong&gt;2.5x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155031_ooZJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 1：任务完成率分析 —— 自主完成 vs 引导后完成（仅统计成功完成的任务）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具调用与补丁生成能力分析&lt;/strong&gt;&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Analysis&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Total Patch Calls&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;811&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;701&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Similar volume&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tool Call Errors&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;185 (23%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;135 (19%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 slightly better&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Successful Patches&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;626 (77%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;566 (81%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Comparable reliability&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Clean Compilation Rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;89%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;72%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2 advantage&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;两个模型在工具调用的模式识别上都存在一定困难，尤其是在处理补丁操作时表现不佳。不过，由于 AI Agent 会在调用失败后自动重试，因此最终的补丁生成成功率并未因初始错误而受到太大影响。真正拉开差距的，是两者生成代码的质量，以及代码是否能顺利编译运行。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Bug 检测与修复对比&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 表现：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;5 个真实 Bug 中成功修复了 4 个，且多数为首次尝试即修复成功&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;平均修复用时为&amp;nbsp;&lt;strong&gt;8.5 分钟&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在修复过程中保留了原有测试逻辑，聚焦于问题根源&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;唯一失败的任务涉及&amp;nbsp;&lt;code&gt;tokio::RwLock&lt;/code&gt;&amp;nbsp;的死锁问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在代码修改中始终保持业务逻辑的一致性与完整性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 表现：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;仅成功修复了 1 个 Bug&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;常见错误做法包括：修改测试断言以绕过失败，而非修复实际问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;频繁引入硬编码值以「强行通过测试」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在无法解决问题时，倾向于改动业务逻辑本身，而非定位和处理根因&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在偶尔成功的案例中，平均修复时间为&amp;nbsp;&lt;strong&gt;22 分钟&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;新功能实现：模型的自主开发能力分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;任务完成情况&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 表现：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;4 个任务中有 2 个&lt;/strong&gt;可以完全自主完成，分别耗时&amp;nbsp;&lt;strong&gt;12 分钟&lt;/strong&gt;和&amp;nbsp;&lt;strong&gt;15 分钟&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;剩余 2 个任务仅需轻微引导（1~2 次提示）即可完成&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在已有功能的增强或扩展上表现出色，能很好地理解上下文并延续逻辑&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对于全新功能（无现成示例参考）的任务，需要更多上下文引导&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;始终保持与原项目一致的代码风格与架构模式，具备良好的工程一致性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 表现：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;0 个任务&lt;/strong&gt;能自主完成，全部任务都依赖多轮提示&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每个任务平均需要&amp;nbsp;&lt;strong&gt;3~4 次重新提示&lt;/strong&gt;才能推进&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;经常误删已有的正常逻辑，倾向于「推倒重来」，导致项目不稳定&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;即使连续提示 40 分钟，最终也只有&amp;nbsp;&lt;strong&gt;2 个任务&lt;/strong&gt;勉强完成&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;另外&amp;nbsp;&lt;strong&gt;2 个任务由于反复迭代过多最终被放弃&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;指令遵循能力分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本轮测试中，两个模型在是否能够准确理解并执行开发指令方面差异尤为明显。尽管在系统提示中已经明确提供了编码规范与开发规则，两者的表现却大相径庭：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Instruction Type&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2 Compliance&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder Compliance&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Error Handling Patterns&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/8 tasks (87%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;3/8 tasks (37%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;API Compatibility&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;8/8 tasks (100%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;4/8 tasks (50%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Code Style Guidelines&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/8 tasks (87%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/8 tasks (25%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;File Modification Scope&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;8/8 tasks (100%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;5/8 tasks (62%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 行为表现：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;始终遵循项目的编码规范与风格&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;严格限制在指定文件范围内进行修改，不越界操作&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;保持原有函数签名不变，避免破坏接口契约&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在需求不明确时，会主动提出澄清性问题，表现出良好的任务意识&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交代码前，会先尝试编译并运行测试，确保代码质量&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen-3 Coder 行为模式：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// Guidelines specified: "Use Result&amp;lt;T, E&amp;gt; for error handling"
// Qwen-3 Output:
panic!("This should never happen"); // or .unwrap() in multiple places

// Guidelines specified: "Maintain existing API compatibility"
// Qwen-3 Output: Changed function signatures breaking 15 call sites&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这种行为模式在多个任务中反复出现，说明问题并非偶发，而是模型在处理指令方面存在系统性的缺陷。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;前端开发能力：无图条件下的视觉推理能力&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;我们通过使用 Forge Agent 搭配 Playwright MCP 和 Context7 MCP，对两个模型在前端重构任务中的表现进行了评估。尽管模型无法直接读取图像，但它们在「类视觉推理」能力上的差异依然明显。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 的处理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;能够智能分析现有组件结构，理解组件层级与职责&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在缺乏视觉参考的情况下，仍能做出合理的 UI 布局假设&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提出的修改建议注重代码可维护性和结构清晰度&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;保留原有的可访问性（Accessibility）逻辑，如 ARIA 标签、键盘导航等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;几乎无需额外引导即可完成重构任务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修改过程中始终保持响应式布局和设计系统的一致性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;能高效复用已有组件，避免重复造轮子&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化方式倾向于「渐进式改进」，不破坏原有功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 的处理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在面对重构任务时，倾向于&lt;strong&gt;删除原组件重写&lt;/strong&gt;，而不是基于原有结构优化&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;忽略项目中已有的设计系统规范，如颜色、间距、组件命名等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无法一次性理解组件之间的关系，需多轮提示才能理清结构&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;重构后常导致响应式布局失效，页面结构紊乱&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不慎删除埋点与分析代码，影响监控与数据采集&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;喜欢使用硬编码数值，而不是绑定到已有样式变量或配置项&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;成本和上下文分析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;开发效率矩阵&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Difference&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Average Time per Completed Task&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;13.3 minutes&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;18 minutes&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;26% faster&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Total Project Cost&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$42.50&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$69.50&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;39% cheaper&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Completed&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;14/15 (93%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/15 (47%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x completion rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Abandoned&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;1/15 (7%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/15 (13%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Better persistence&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;由于我们使用了 OpenRouter，它会将请求分发到不同的模型提供方，因此各家提供商的计费标准不同，导致无法精确计算单次调用的成本。不过，&lt;strong&gt;Kimi K2&lt;/strong&gt;&amp;nbsp;在整个测试过程中的总成本为&amp;nbsp;&lt;strong&gt;42.50 美元&lt;/strong&gt;，平均每个任务（包括需要提示引导的情况）耗时约&amp;nbsp;&lt;strong&gt;13.3 分钟&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155119_uVSx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kimi K2 在 OpenRouter 不同提供商中的使用费用表现稳定，均采用 131K 的上下文长度，输入费用在 0.55 美元至 0.60 美元之间，输出费用则在 2.20 美元至 2.50 美元之间波动。&lt;/p&gt; 
&lt;p&gt;相比之下，Qwen-3 Coder 的成本几乎是 Kimi K2 的两倍。其平均每个任务（包括必要的提示）耗时约 18 分钟，15 个任务总费用达到 69.50 美元，其中有 2 个任务因迭代过多被放弃。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155137_Yvcj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen-3 Coder 在 OpenRouter 各提供商中的使用费用结构相同，但由于总使用量较高，导致整体成本增加。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/155152_J1Th_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图 2：成本与时间对比 —— 直接项目投入分析&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效率对比表格&lt;/strong&gt;&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-tap-highlight-color:transparent; -webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; box-sizing:border-box; color:rgba(0, 0, 0, 0.9); display:table; font-family:&amp;quot;PingFang SC&amp;quot;,system-ui,-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei UI&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,Arial,sans-serif; font-size:17px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:0.544px; margin:0px 0px 10px; max-width:100%; orphans:2; outline:0px; overflow-wrap:break-word !important; padding:0px; text-align:justify; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:677px; word-spacing:0px"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Metric&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Qwen-3 Coder&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:#bbbbbb #dddddd #dddddd"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Advantage&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Cost per Completed Task&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$3.04&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;$9.93&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;3.3x cheaper&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Time Efficiency&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;26% faster&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Baseline&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Kimi K2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Success Rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;93%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;47%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x better&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Completed&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;14/15 (93%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;7/15 (47%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2x completion rate&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Tasks Abandoned&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;1/15 (7%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;2/15 (13%)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-color:#dddddd; border-style:solid; border-width:1px"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;Better persistence&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;上下文长度与性能表现&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上下文长度稳定在 131K tokens（各提供商间保持一致）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推理速度较快，尤其在使用 Groq 加速时表现优异&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内存利用高效，能够充分发挥上下文资源&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;上下文长度范围较大，从 262K 到 100 万 tokens 不等，依赖具体提供商&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;推理速度尚可，但整体慢于 Kimi K2&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内存开销较大，上下文管理效率较低&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;死锁挑战：技术细节深度解析&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;最具代表性的一项测试是针对&amp;nbsp;&lt;code&gt;tokio::RwLock&lt;/code&gt;&amp;nbsp;死锁问题的解决方案，充分暴露了两者在问题分析和处理思路上的差异：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Kimi K2 的 18 分钟分析过程：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;系统性地分析锁的获取和释放模式&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;准确识别潜在的死锁场景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尝试多种解决策略，包括锁顺序调整等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最终承认问题复杂，主动请求进一步指导&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;整个过程中始终保证代码逻辑完整性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Qwen-3 Coder 的处理方式：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;直接建议移除所有锁，破坏了线程安全保障&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提出使用不安全（unsafe）代码作为「解决方案」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;修改测试预期以规避死锁问题，而非根本解决&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从未展现出对并发问题本质的理解&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;基准测试与实际表现的差距&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Qwen-3 Coder 在各种基准测试中的高分，并未转化为真实开发环境中的有效产出。这种落差揭示了当前 AI 编程助手评估方式的重大缺陷。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;基准测试为何「失灵」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;基准测试的局限性：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;测试题目多为合成的、解决方案明确的孤立问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不强制要求遵守指令或项目约束&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成功仅以最终输出是否符合标准衡量，忽视开发过程&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺少对代码可维护性和质量的评估&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无协作开发流程的考量&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;真实开发的需求：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在现有代码库和架构限制中工作&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遵守团队编码规范和风格指南&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;维护向后兼容性&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;迭代开发，适应需求变更&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;考虑代码审查与长期维护&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;局限性与适用范围说明&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在深入结果之前，需明确本次对比的范围和限制：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;测试的局限性：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;仅测试单一代码库（38K 行 Rust 代码 + 12K 行 React 前端）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结果可能不适用于其他语言、代码库或开发风格&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;样本量较小，缺乏统计学显著性分析&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可能存在对特定编码习惯和偏好的偏向&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;测试依赖 OpenRouter，提供商可用性不同&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;本次对比未涵盖内容：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其他编程语言的表现，如 Python、Java 等&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不同提示工程技术下的模型行为&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企业级代码库中不同架构模式下的适应性&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;注意：以上结果基于特定测试环境得出，建议在做模型选择决策时结合其他评估结果一并参考。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本次测试表明，Qwen-3 Coder 虽然在基准测试中表现优异，但其成绩并未很好地转化为本项目的具体开发流程中。它在处理孤立的编码挑战时或许表现出色，但面对协作式、需遵守多种约束的开发模式时，表现却较为吃力。&lt;/p&gt; 
&lt;p&gt;在本测试环境下，Kimi K2 始终能够在较少监督的情况下稳定输出可运行代码，展现出更好的指令遵循能力和代码质量。其工作方式与既定的开发流程及编码规范更加契合。&lt;/p&gt; 
&lt;p&gt;尽管 Qwen-3 Coder 拥有更长的上下文长度优势（最高可达 100 万 tokens，而 Kimi K2 为 131K），但这并未弥补其在指令执行上的不足。两者的推理速度均属良好，但 Kimi K2 配合 Groq 加速时响应明显更快。&lt;/p&gt; 
&lt;p&gt;虽然这些开源模型正快速进步，但在本次测试中仍落后于如 Claude Sonnet 4 和 Opus 4 等闭源模型。基于此次评估，Kimi K2 更适合满足这类 Rust 开发的具体需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362129/kimi-k2-vs-qwen-3-coder-coding-comparison</guid>
      <pubDate>Thu, 17 Jul 2025 07:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>从频繁告警到平稳发布：服务冷启动 CPU 风暴优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网服务器团队- Xie Xiaopeng&lt;/p&gt; 
 &lt;p&gt;本文针对服务启动后几分钟内 CPU 持续处于高峰状态的问题，提出了自己的分析思路与解决方案。最终线上效果比较显著，成功解决了每次发版过程中频繁告警、业务受损以及用户体验不佳的问题，为服务的高可用性增添了一道重要保障。本文的重点在于问题的发现、分析及解决思路。对于 CPU 相关的问题，火焰图和 Arthas 是非常有效的工具，建议大家在遇到类似情况时，积极尝试使用这些工具进行排查和解决。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分钟看图抓住核心观点👇&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ac1252a6e0f78995afecc8da9af3fe0b.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;最近我们的服务在发布或重启时频繁产生告警，这种情况从发版开始一直持续到发版结束后几分钟内，规律非常明显。&lt;/p&gt; 
&lt;p&gt;起初，我们怀疑是流量接入过快导致了此问题。在服务启动后，CICD 会检测 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcheck.do" rel="nofollow" target="_blank"&gt;check.do&lt;/a&gt; 接口，以确认服务是否准备就绪。我们推测，&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fcheck.do" rel="nofollow" target="_blank"&gt;check.do&lt;/a&gt; 接口成功返回后，CICD 立即接入线上流量，这才引发非常多的异常告警。&lt;/p&gt; 
&lt;p&gt;为了解决这一问题，我们与运维团队进行了沟通，决定将流量接入的时机延迟 30 秒。延迟 30 秒后问题还是没有得到解决，告警依然持续不断。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、 问题表象&lt;/h1&gt; 
&lt;p&gt;以线上某一台机器为例，它的启动步骤如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-09-0416:09:50&amp;nbsp;INFO - 启动应用 ，执行成功。
2024-09-0416:12:36&amp;nbsp;WARN - 检查接口：check.do，响应结果：ok
2024-09-0416:13:07&amp;nbsp;INFO - 启动后等待时间（秒）：30
2024-09-0416:13:07&amp;nbsp;INFO - 恢复 Dubbo 流量成功
2024-09-0416:13:39&amp;nbsp;INFO - 恢复 HTTP 流量成功！
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Dubbo 接口超时严重&lt;/h2&gt; 
&lt;p&gt;恢复 HTTP 流量后，很多调用下游的 Dubbo 接口发生超时，以画像接口为例，告警开始时间为：2024-09-04 16:14:07.251，结束时间为：2024-09-04 16:17:31.224，期间超时请求数为：578。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 HTTP 接口超时严重&lt;/h2&gt; 
&lt;p&gt;大部分 HTTP 接口也超时严重，P95 响应时间从正常的几十毫秒飙升至几秒钟，16:17:30 后逐渐恢复至正常水平。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 CPU 异常&lt;/h2&gt; 
&lt;p&gt;服务发布前后 CPU 表现异常，启动过程 CPU 存在突刺，接入线上流量后一段时间内 CPU 使用率将近 100%，16:17:30 后逐步下降，恢复到正常水平。下图为服务发布前后 CPU 的使用率截图。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e1cf61c214438c27647181f67523a5bc.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;服务发布前后 CPU 使用率&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;2.4 Runnable、Blocked 线程突刺&lt;/h2&gt; 
&lt;p&gt;下图为线程数的相关监控指标，我们可以看到：在服务发布期间，活跃线程数持续增加，启动期间线程剧增，接入线上流量后线程逐步增加，16:17 分之后趋于平稳，其中 16:12:30-16:12:40 期间活跃线程数从 249 增加到 1026（启动期间业务侧有很多任务均会创建线程池，不影响本次分析）&lt;/p&gt; 
&lt;p&gt;Runnable 线程数与 Blocked 线程数也有突刺，时间是 16:13:30-16:17:30，与接入 HTTP 流量时间相符，与 CPU 突刺时间完全一致。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//0284bd6e471cdeab5825a6b1a4076566.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 线程&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//997e2e5b9b6042e8231d8768f6ac37b6.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 线程&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;2.5 老年代上涨快&lt;/h2&gt; 
&lt;p&gt;在查看 GC 老年代内存使用情况时，我们发现启动后未接入流量时，老年代内存为 985.84MB。而在接入流量后，截止到 16:17:30，内存使用量已经上升至 1.36GB，期间老年代的内存增长速度较快。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;2.6 下游依赖正常&lt;/h2&gt; 
&lt;p&gt;从上游视角查看下游依赖的情况，随便挑一个 Dubbo 接口超时严重的下游依赖，我们查看一下服务的监控指标，发现服务的请求量在启动期间有突刺（业务侧在启动期间会主动发起调用，刷新一些缓存，正常现象），启动后流量几乎没变，但是成功率却有明显下降，且最大响应时间显著增加。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c15914b39be50c378c9e269f81b7c872.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上游视角&lt;/p&gt; 
&lt;p&gt;但是从下游视角再看服务相关指标，接口成功率正常，且最大响应时间也正常，说明不是下游服务的问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3138ef8521191df0a25e0843279fb18d.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下游视角&lt;/p&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;三、原因初步判断&lt;/h1&gt; 
&lt;p&gt;从监控数据来看，在线上流量恢复后，我们的服务当前拥有的线程数不足以处理这些业务请求，因此导致系统大量创建业务线程。由于 CPU 的时间片调度策略，线程之间会频繁发生上下文切换，从而引发 CPU 负载的剧烈上升，甚至达到饱和状态。&lt;/p&gt; 
&lt;p&gt;因此通过初步分析，我们得到以下&lt;strong&gt;结论&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;引起 CPU 飙升的原因主要是由于过多的 Runnable 状态线程以及频繁的线程上下文切换所导致。我们观察到系统中存在大量已启动的线程，这些线程的状态在 Blocked（锁等待、IO 等待等）和 Runnable 之间不断变化。当锁竞争激烈时，CPU 飙升的现象就很容易出现。&lt;/p&gt; 
&lt;span id="OSC_h1_10"&gt;&lt;/span&gt; 
&lt;h1&gt;四、尝试初步解决&lt;/h1&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 流量逐步灰度&lt;/h2&gt; 
&lt;p&gt;既然我们怀疑是流量全部接入后，线程不足导致的问题，因此需要尝试流量缓慢接入是否能解决这个问题。&lt;/p&gt; 
&lt;p&gt;我们与运维同学线上随机找了一台机器进行流量灰度实验，具体时间节点如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-09-0509:55:21&amp;nbsp;启动成功
2024-09-0509:56:17&amp;nbsp;灰度 1%
2024-09-0509:57:19&amp;nbsp;灰度 5%
2024-09-0509:58:31&amp;nbsp;灰度 44%
2024-09-0510:03:51&amp;nbsp;开始操作全量
2024-09-0510:08:10&amp;nbsp;全量完成
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;再观察一下相关指标，我们发现各项指标均正常：CPU 使用率不再有突刺，Runnable 线程数和 Blocked 线程数也保持稳定，之前的负载尖峰现象已消失。同时异常超时的日志记录也不再出现，老年代内存的增长速度缓慢，HTTP 接口、Dubbo 接口 P95 响应时间正常。由此可见，流量灰度可以解决该问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//45fcaa86e0dd82eed37f4645725774ae.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 线程指标情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cd1e221cd3022fbb8e17ac382f336365.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 线程&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//75a065693cd049c3c8d50ca0f2807af2.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 线程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 缓存预热&lt;/h2&gt; 
&lt;p&gt;在前文中提到，接入线上流量后，老年代的内存增长较快，因此我们推测在服务启动初期，由于尚未加载相关的缓存数据，当大量请求涌入时，未命中缓存的情况频繁发生，这迫使系统不断向下游请求以加载缓存，从而导致接口响应变慢。为此，我们需要验证预热缓存的有效性，以确定是否能够改善这一问题。&lt;/p&gt; 
&lt;p&gt;缓存预热的&lt;strong&gt;主要作用和目的&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提高缓存命中率&lt;/strong&gt;：通过预先加载热点数据，能够显著提升缓存的命中率，从而减少对后端数据源（如数据库）的访问，降低系统负载。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;保持服务性能稳定&lt;/strong&gt;：在服务启动或缓存失效之后，缓存预热可以有效防止请求对后端数据源施加突发压力，从而确保服务性能的稳定性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化用户体验&lt;/strong&gt;：由于热点数据已被预先加载到缓存中，用户在请求这些数据时能够获得更快的响应速度，从而显著提升用户体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;我们将梳理本地缓存信息，根据访问量和缓存大小区分数据的重要程度，定期将重要的缓存信息刷新至 Redis 中。在服务启动后，未接入线上流量之前，我们将优先从 Redis 中进行数据的预加载。通过这一措施，确保系统在高流量环境下的稳定性和性能。&lt;/p&gt; 
&lt;p&gt;实验结果显示，增加缓存预热后，问题并未得到有效解决，表现差异微乎其微。&lt;/p&gt; 
&lt;p&gt;仅仅预热重要缓存无法解决当前问题。系统在启动时需要预热的内容相对较多，同时各类中间件也有自身的缓存需要预热。因此仅预热业务自定义的内存缓存，效果非常有限。&lt;/p&gt; 
&lt;p&gt;回顾之前的原因分析，我们仅仅关注了表面现象，如 CPU 的上涨和线程数的增加，而未深入挖掘问题的本质。我们需要探讨线程数为何上升、CPU 为何飙升，接下来将进行更深入的分析，以找出问题的根本原因。&lt;/p&gt; 
&lt;span id="OSC_h1_13"&gt;&lt;/span&gt; 
&lt;h1&gt;五、分析问题&lt;/h1&gt; 
&lt;span id="OSC_h2_14"&gt;&lt;/span&gt; 
&lt;h2&gt;5.1 初步分析堆栈与 CPU 火焰图&lt;/h2&gt; 
&lt;p&gt;我们选择了一台线上机器进行服务重启，并在接入线上流量后的几分钟内导出了程序的线程堆栈信息，进行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Runnable 线程数显著增多，占比达到 29%，通常情况下，Runnable 线程数约为 70 个，而此时却激增至 462 个；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进一步查看 Runnable 线程，发现大部分线程为 catalina-exec 线程（380 个），这是 Tomcat 用于执行 Spring MVC 应用中 Servlet 请求的线程。正常情况下，这类线程的数量仅有几个；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在这些 Runnable 线程中，有 201 个线程均被阻塞在 org.springframework.beans.PropertyMatches.calculateStringDistance(PropertyMatches.java:170) 这个方法上，我们需要进一步分析其原因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;看了堆栈信息后，应该有个疑问：为什么启动了这么多的 tomcat 线程？&lt;/p&gt; 
&lt;p&gt;我们推测原因在于服务刚启动时，系统尚未加载任何缓存，所有数据都需要进行首次加载。在这种情况下，服务无法快速响应用户请求，导致接口的响应时间（RT）显著上升。在相同的 QPS 的情况下，为了处理不断增加的业务请求，系统不得不创建更多的 Tomcat 线程。&lt;/p&gt; 
&lt;p&gt;接下来我们接入 Arthas 工具，采集 CPU 火焰图以进行深入分析，CPU 火焰图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//aa098319277f41bc34e91ca21c250e33.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;异常 CPU 火焰图&lt;/p&gt; 
&lt;p&gt;分析结果显示，CPU 耗时主要集中在 calculateStringDistance 方法，这与我们之前的线程堆栈分析结果一致。在服务启动时的 CPU 火焰图中，calculateStringDistance 方法的 CPU 消耗占比高达 16.68% + 39.09% + 8.38% = 64.15%，整体 CPU 使用率接近 97%。&lt;/p&gt; 
&lt;p&gt;经过一段时间的运行后，再观察正常情况下的 CPU 火焰图，calculateStringDistance 方法的 CPU 消耗占比降至 3.39% + 8.57% + 1.78% = 13.74%，整体 CPU 使用率则徘徊在 25% 至 42% 之间。&lt;/p&gt; 
&lt;p&gt;这一变化表明，随着系统的稳定运行，CPU 负载逐渐得到缓解，但 calculateStringDistance 方法仍然是性能瓶颈之一。它虽然不是 CPU 使用率飙升的根因，但它在服务启动后进一步加剧了 CPU 的负载。&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.1 calculateStringDistance 加剧 CPU 暴涨&lt;/h3&gt; 
&lt;p&gt;在相同 QPS 的情况下，为什么在服务启动后的几分钟内 calculateStringDistance 方法消耗的 CPU 资源严重，而经过一段时间后，这一消耗又有所减小？&lt;/p&gt; 
&lt;p&gt;前文的分析指出，服务刚启动时，流量瞬间恢复，导致系统需要创建大量的业务线程。这些线程在处理请求时，都会执行 calculateStringDistance 方法。由于该方法本身的计算开销较大，且并发执行的线程数量越多，CPU 的消耗就会越显著。因此在服务启动初期，CPU 的负载急剧上升。随着运行时间的延长，业务线程的创建和执行也趋于平衡，并发执行的线程数量大大减小，CPU 消耗也随之减小。&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.2 calculateStringDistance 源码分析&lt;/h3&gt; 
&lt;p&gt;calculateStringDistance 方法的功能是根据 Levenshtein 算法计算给定两个字符串之间的距离或相似度。通过分析其源代码，我们可以发现，在比较两个字符串时，该方法采用了嵌套的 for 循环结构。在这些循环中，涉及到 length、chatAt 和 Math.min 函数的调用，这使得该方法的计算复杂度相对较高。调用量越大，CPU 消耗就会越严重。根据 CPU 火焰图的分析，发现这三个函数的 CPU 消耗占比与 calculateStringDistance 方法的 CPU 消耗占比之间的比例高达 78%。因此在调用该方法时要小心，在高并发场景下，该方法很有可能成为系统的性能瓶颈，对 CPU 产生影响。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private&amp;nbsp;static&amp;nbsp;int&amp;nbsp;calculateStringDistance(String s1, String s2){
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(s1.isEmpty()) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;s2.length();
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(s2.isEmpty()) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;return&amp;nbsp;s1.length();
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;int[][] d = newint[s1.length() +&amp;nbsp;1][s2.length() +&amp;nbsp;1];
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;i =&amp;nbsp;0; i &amp;lt;= s1.length(); i++) {
&amp;nbsp; &amp;nbsp; d[i][0] = i;
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;0; j &amp;lt;= s2.length(); j++) {
&amp;nbsp; &amp;nbsp; d[0][j] = j;
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;i =&amp;nbsp;1; i &amp;lt;= s1.length(); i++) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;char&amp;nbsp;c1 = s1.charAt(i -&amp;nbsp;1);
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;(int&amp;nbsp;j =&amp;nbsp;1; j &amp;lt;= s2.length(); j++) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;int&amp;nbsp;cost;
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;char&amp;nbsp;c2 = s2.charAt(j -&amp;nbsp;1);
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(c1 == c2) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cost =&amp;nbsp;0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cost =&amp;nbsp;1;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; d[i][j] = Math.min(Math.min(d[i -&amp;nbsp;1][j] +&amp;nbsp;1, d[i][j -&amp;nbsp;1] +&amp;nbsp;1), d[i -&amp;nbsp;1][j -&amp;nbsp;1] + cost);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;return&amp;nbsp;d[s1.length()][s2.length()];
}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;calculateStringDistance 方法是如何触发的？通过查询堆栈信息并查看源代码，我们发现这是 Spring 框架在解析请求参数并注入属性的过程中所触发的。堆栈信息如下，从上到下逐步分析堆栈，我们重点分析 setPropertyValues 和 createNotWritable-&lt;/p&gt; 
&lt;p&gt;PropertyException 这两个方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"catalina-exec-485"&amp;nbsp;#975 daemon prio=5 os_prio=0 tid=0x00007f50e825f000 nid=0x3375 runnable [0x00007f5043ea4000]
&amp;nbsp; &amp;nbsp;java.lang.Thread.State: RUNNABLE
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.calculateStringDistance(PropertyMatches.java:170)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.access$100(PropertyMatches.java:44)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches$BeanPropertyMatches.calculateMatches(PropertyMatches.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches$BeanPropertyMatches.&amp;lt;init&amp;gt;(PropertyMatches.java:193)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.forProperty(PropertyMatches.java:68)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.PropertyMatches.forProperty(PropertyMatches.java:58)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.BeanWrapperImpl.createNotWritablePropertyException(BeanWrapperImpl.java:237)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.processLocalProperty(AbstractNestablePropertyAccessor.java:435)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:290)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractNestablePropertyAccessor.setPropertyValue(AbstractNestablePropertyAccessor.java:278)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:95)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.validation.DataBinder.applyPropertyValues(DataBinder.java:860)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.validation.DataBinder.doBind(DataBinder.java:756)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.bind.WebDataBinder.doBind(WebDataBinder.java:192)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.bind.ServletRequestDataBinder.bind(ServletRequestDataBinder.java:106)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.ServletModelAttributeMethodProcessor.bindRequestParameters(ServletModelAttributeMethodProcessor.java:152)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.annotation.ModelAttributeMethodProcessor.resolveArgument(ModelAttributeMethodProcessor.java:111)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:158)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest$original$3Q7HrFjh(InvocableHandlerMethod.java:128)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest$original$3Q7HrFjh$accessor$ykGmQRZT(InvocableHandlerMethod.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod$auxiliary$Wny4v5BZ.call(Unknown Source)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:849)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:760)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke$original$Y7IhKDGv(StandardWrapperValve.java:219)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke$original$Y7IhKDGv$accessor$4IDmuys6(StandardWrapperValve.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve$auxiliary$1SL1DIkO.call(Unknown Source)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1136)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1775)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1734)
&amp;nbsp; &amp;nbsp; &amp;nbsp; - locked &amp;lt;0x000000070f1dc100&amp;gt; (a org.apache.tomcat.util.net.NioChannel)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
&amp;nbsp; &amp;nbsp; &amp;nbsp; at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;先分析 setPropertyValues 方法，该方法负责将请求中的参数映射到目标对象的属性上，主要是遍历属性列表进行赋值并进行异常统一处理，单个属性的注入继续看 setPropertyValue 方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public&amp;nbsp;void&amp;nbsp;setPropertyValues(PropertyValues pvs,&amp;nbsp;boolean&amp;nbsp;ignoreUnknown,&amp;nbsp;boolean&amp;nbsp;ignoreInvalid)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 声明 PropertyAccessException 集合，保存单个属性注入时抛出的 PropertyAccessException 异常
&amp;nbsp; List&amp;lt;PropertyAccessException&amp;gt; propertyAccessExceptions =&amp;nbsp;null;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 获取属性列表
&amp;nbsp; List&amp;lt;PropertyValue&amp;gt; propertyValues = (pvs&amp;nbsp;instanceof&amp;nbsp;MutablePropertyValues ?
&amp;nbsp; &amp;nbsp; &amp;nbsp; ((MutablePropertyValues) pvs).getPropertyValueList() : Arrays.asList(pvs.getPropertyValues()));
&amp;nbsp;&amp;nbsp;for&amp;nbsp;(PropertyValue pv : propertyValues) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 单个属性的注入，注意：此方法可能会引发任意的 BeansException，如果存在严重故障（例如没有匹配的字段），则不会在此处捕获该异常。我们可以尝试只处理不太严重的异常。
&amp;nbsp; &amp;nbsp; &amp;nbsp; setPropertyValue(pv);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NotWritablePropertyException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 默认是 true，忽略未知属性，因此不会抛异常
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!ignoreUnknown) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// Otherwise, just ignore it and continue...
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NullValueInNestedPathException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!ignoreInvalid) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// Otherwise, just ignore it and continue...
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(PropertyAccessException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(propertyAccessExceptions ==&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions =&amp;nbsp;new&amp;nbsp;LinkedList&amp;lt;PropertyAccessException&amp;gt;();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions.add(ex);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;// 如果 propertyAccessExceptions 不为空，需要整合起来，抛一个复合异常 PropertyBatchUpdateException
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(propertyAccessExceptions !=&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; PropertyAccessException[] paeArray =
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; propertyAccessExceptions.toArray(new&amp;nbsp;PropertyAccessException[propertyAccessExceptions.size()]);
&amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;PropertyBatchUpdateException(paeArray);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;propertyValues 属性的结构如下，它包含了从上游传递过来的所有参数。这些参数被封装成一个集合，便于后续的处理和注入。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cc70849606402c94a225c47243073954.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;propertyValues 属性&lt;/p&gt; 
&lt;p&gt;分析 setPropertyValue 方法，该方法主要作用是解析属性值，如果存在嵌套属性，则递归解析设置最终对应的属性值，方法最后都会调用 setPropertyValue(tokens, pv) 方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;public&amp;nbsp;void&amp;nbsp;setPropertyValue(PropertyValue pv)&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp;&amp;nbsp;PropertyTokenHolder&amp;nbsp;tokens&amp;nbsp;=&amp;nbsp;(PropertyTokenHolder) pv.resolvedTokens;
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(tokens ==&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;String&amp;nbsp;propertyName&amp;nbsp;=&amp;nbsp;pv.getName();
&amp;nbsp; &amp;nbsp; AbstractNestablePropertyAccessor nestedPa;
&amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 确定给定属性路径中的第一个嵌套属性分隔符，忽略键中的点（如 「map[my.key]」）。
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 当配置的属性名 propertyName 中包含'.'这样字符时，代表需要设置嵌套属性
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 如果存在嵌套属性，Spring 会递归向下获取最终设置的属性，比如：a.b.c，Spring 会递归调用获取到 b，c 是需要设置的属性
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 如果没有嵌套属性的话。会返回自身
&amp;nbsp; &amp;nbsp; &amp;nbsp; nestedPa = getPropertyAccessorForPropertyPath(propertyName);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(NotReadablePropertyException ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;NotWritablePropertyException(getRootClass(),&amp;nbsp;this.nestedPath + propertyName,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Nested property in path '"&amp;nbsp;+ propertyName +&amp;nbsp;"' does not exist", ex);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 将给定的属性名称解析为相应的属性名称令牌，如果没有[]，则 tokens 中的 keys 为空，且 actualName、canonicalName 都等于 propertyName&amp;nbsp;
&amp;nbsp; &amp;nbsp; tokens = getPropertyNameTokens(getFinalPath(nestedPa, propertyName));
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(nestedPa ==&amp;nbsp;this) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; pv.getOriginalPropertyValue().resolvedTokens = tokens;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 设置属性
&amp;nbsp; &amp;nbsp; nestedPa.setPropertyValue(tokens, pv);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// 设置属性
&amp;nbsp; &amp;nbsp; setPropertyValue(tokens, pv);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;分析 setPropertyValue(tokens, pv) 方法，该方法是用来区分数组类型跟非数组类型的，大部分属性都是非数组类型，我们分析非数组类型方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;protected&amp;nbsp;void&amp;nbsp;setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv)&amp;nbsp;throws&amp;nbsp;BeansException {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果属性中存在[]，说明是数组，则进入该方法
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(tokens.keys !=&amp;nbsp;null) {
&amp;nbsp; &amp;nbsp; processKeyedProperty(tokens, pv);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 大部分都走这个方法
&amp;nbsp; &amp;nbsp; processLocalProperty(tokens, pv);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;processLocalProperty 方法的作用就是获取属性值，利用反射完成属性注入。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private&amp;nbsp;void&amp;nbsp;processLocalProperty(PropertyTokenHolder tokens, PropertyValue pv){
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 获取属性对应的 PropertyHandler
&amp;nbsp;&amp;nbsp;PropertyHandler&amp;nbsp;ph&amp;nbsp;=&amp;nbsp;getLocalPropertyHandler(tokens.actualName);
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果不存在对应的 handler 或者，属性是不可写的（没有 setter 方法）
&amp;nbsp;&amp;nbsp;if&amp;nbsp;(ph ==&amp;nbsp;null&amp;nbsp;|| !ph.isWritable()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果属性是 optional 类型，则直接返回
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pv.isOptional()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(logger.isDebugEnabled()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.debug("Ignoring optional value for property '"&amp;nbsp;+ tokens.actualName +
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"' - property not found on bean class ["&amp;nbsp;+ getRootClass().getName() +&amp;nbsp;"]");
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;return;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 其他情况则抛出不可写属性异常，占用 CPU 较多的方法由此进入
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;createNotWritablePropertyException(tokens.canonicalName);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }

&amp;nbsp;&amp;nbsp;Object&amp;nbsp;oldValue&amp;nbsp;=&amp;nbsp;null;
&amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 获取属性值
&amp;nbsp; &amp;nbsp;&amp;nbsp;Object&amp;nbsp;originalValue&amp;nbsp;=&amp;nbsp;pv.getValue();
&amp;nbsp; &amp;nbsp;&amp;nbsp;Object&amp;nbsp;valueToApply&amp;nbsp;=&amp;nbsp;originalValue;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果需要转换，则进入此分支
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(!Boolean.FALSE.equals(pv.conversionNecessary)) {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果已经完成类型转换，则直接使用
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(pv.isConverted()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; valueToApply = pv.getConvertedValue();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 如果需要读取旧值，默认是 false &amp;amp;&amp;amp; 值可读（有 getter 方法）
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(isExtractOldValueForEditor() &amp;amp;&amp;amp; ph.isReadable()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;try&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; oldValue = ph.getValue();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;catch&amp;nbsp;(Exception ex) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(ex&amp;nbsp;instanceof&amp;nbsp;PrivilegedActionException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ex = ((PrivilegedActionException) ex).getException();
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(logger.isDebugEnabled()) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.debug("Could not read previous value of property '"&amp;nbsp;+
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.nestedPath + tokens.canonicalName +&amp;nbsp;"'", ex);
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// 类型转换
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; valueToApply = convertForProperty(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; tokens.canonicalName, oldValue, originalValue, ph.toTypeDescriptor());
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; pv.getOriginalPropertyValue().conversionNecessary = (valueToApply != originalValue);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 完成属性注入
&amp;nbsp; &amp;nbsp; ph.setValue(this.wrappedObject, valueToApply);
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(TypeMismatchException ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;throw&amp;nbsp;ex;
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(InvocationTargetException ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;PropertyChangeEvent&amp;nbsp;propertyChangeEvent&amp;nbsp;=&amp;nbsp;new&amp;nbsp;PropertyChangeEvent(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.rootObject,&amp;nbsp;this.nestedPath + tokens.canonicalName, oldValue, pv.getValue());
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(ex.getTargetException()&amp;nbsp;instanceof&amp;nbsp;ClassCastException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;TypeMismatchException(propertyChangeEvent, ph.getPropertyType(), ex.getTargetException());
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;else&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;Throwable&amp;nbsp;cause&amp;nbsp;=&amp;nbsp;ex.getTargetException();
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cause&amp;nbsp;instanceof&amp;nbsp;UndeclaredThrowableException) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// May happen e.g. with Groovy-generated methods
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; cause = cause.getCause();
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;MethodInvocationException(propertyChangeEvent, cause);
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;catch&amp;nbsp;(Exception ex) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;PropertyChangeEvent&amp;nbsp;pce&amp;nbsp;=&amp;nbsp;new&amp;nbsp;PropertyChangeEvent(
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;this.rootObject,&amp;nbsp;this.nestedPath + tokens.canonicalName, oldValue, pv.getValue());
&amp;nbsp; &amp;nbsp; thrownew&amp;nbsp;MethodInvocationException(pce, ex);
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在该方法中，我们注意到堆栈信息中 createNotWritablePropertyException 方法的调用。实际上 calculateStringDistance 方法的高 CPU 消耗正是由此引发的。当抛出不可写属性异常时，系统会计算字符串的相似度，主要目的是为了向用户提供更友好的提示，帮助他们识别哪些属性与当前属性相似，从而判断是否在传递参数时出现了错误。&lt;/p&gt; 
&lt;p&gt;Spring 这种设计不仅提升了用户体验，还降低了因参数错误而导致的调试难度。通过提供相似属性的建议，用户能够更快速地发现并纠正输入错误，确保请求的正确性。以下为调试过程中的部分提示：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Bean property&amp;nbsp;'questionValidatorInterface'&amp;nbsp;is not writable or has an invalid&amp;nbsp;setter&amp;nbsp;method. Does the parameter type of the&amp;nbsp;setter&amp;nbsp;match the&amp;nbsp;return&amp;nbsp;type of the&amp;nbsp;getter?
bean property&amp;nbsp;'users'&amp;nbsp;is not writable or has an invalid&amp;nbsp;setter&amp;nbsp;method. did you mean&amp;nbsp;'user'?
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.3 calculateStringDistance 流程总结&lt;/h3&gt; 
&lt;p&gt;结合 Spring MVC 解析 HTTP 的请求流程，calculateStringDistance 方法的进入流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c5a198998b410036c75859840afa1f60.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;解析参数流程&lt;/p&gt; 
&lt;p&gt;Spring MVC 在解析 HTTP 请求参数时会找到对应的参数解析器，因为我们的项目中大部分都是自定义的复杂对象，因此采用的参数解析器为 ServletModelAttributeMethodProcessor。该解析器在数据绑定过程中，会循环遍历每个参数，通过反射完成属性注入。但是我们自定义的复杂对象在某些接口下，定义的属性不合理，导致抛出 createNotWritablePropertyException 异常。&lt;/p&gt; 
&lt;p&gt;我们深入分析一下源码，看看怎样避免抛出 createNotWritablePropertyException 异常。&lt;/p&gt; 
&lt;p&gt;根据源码，我们发现抛出不可写属性异常的条件是（属性不存在对应的 handler 或者，属性不可写）并且属性不是 optional 类型，只要我们保证不满足这个条件，那么就可以有效避免抛出该异常。&lt;/p&gt; 
&lt;p&gt;说明一下这三个条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;属性不存在对应的 handler 即 request 中不存在该属性。比如请求参数中带 version 字段，但是服务端在接受 request 中并未定义 version 字段，那么此处 ph == null 判断条件就成立&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;属性不可写，即属性没有对应的 setter 方法&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;属性是 optional 类型，即属性的数据类型是 Optional 类型&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过查看业务侧的代码，我们发现请求（request）中的所有属性都已经定义了相应的 setter 方法，而且不存在 optional 类型的属性。因此我们只需要关注请求中是否存在未定义的属性。&lt;/p&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.4 排查大流量及核心接口参数&lt;/h3&gt; 
&lt;p&gt;由于服务提供的接口非常多，因此仅排查流量较高和核心的接口。经过分析，我们发现几乎所有接口都存在未定义的属性。&lt;/p&gt; 
&lt;p&gt;这主要是因为客户端很多参数都是公参，在传参时会将这些公参全部透传给服务端，但是服务端并不需要处理所有的参数，因此没有在 request 中定义。特别备注：接口若未定义请求参数接收，则不会走上述流程。&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;5.1.5 解决方案&lt;/h3&gt; 
&lt;p&gt;既然已经明确问题的根源是请求中存在未定义的属性，那么接下来我们将针对这一情况进行优化。方案主要有两个：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;在底层请求中加入客户端公参：对所有公参进行接收，确保它们能够被正确处理。需要注意的是，参数接收将会涉及属性注入，而属性注入是通过反射机制实现的。这一过程可能对 CPU 和接口性能产生影响，因此我们也需要进行实验，以评估这些参数解析的实际效果。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;在 filter 层针对接口去除相关字段：通过在过滤器层面过滤掉不必要的字段，避免接口中出现未定义的属性。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;最终我们混合两种方案：对于大部分公共参数，定义到底层 request 中；对于非公共参数，针对接口进行移除。&lt;/p&gt; 
&lt;p&gt;我们针对大流量接口及核心接口进行了优化，优化后效果如下：&lt;/p&gt; 
&lt;p&gt;结论：整体效果显著，但仍存在一些不足之处。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CPU 使用情况&lt;/strong&gt;：在高峰期重启应用时，CPU 的突发情况明显减弱，持续时间从 5 分钟缩短至 1 分钟。同时 CPU 和 Runnable 线程数仍会出现小幅波动，但 Runnable 线程数的波动持续时间已从 6 分钟缩减至 40 秒，波动峰值也由 600 降低至 280。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;接口性能&lt;/strong&gt;：接口的 P95 和 P99 耗时均有所降低，其中 P95 峰值从 53 秒降至 3.4 秒，P99 峰值从 1 分 50 秒降至 50 秒。此外，响应时间较长的时间段也得到了缩短，持续时间从 7 分钟减少到不到 2 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;发版及日常运行&lt;/strong&gt;：在发版期间及日常运行中，CPU 峰值普遍降低。与前 1 天和前 7 天的平均 CPU 使用率相比，最大和最小使用率均有所下降，幅度明显。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;① 启动后 CPU 使用率情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4912336ab2d7bdc8083d05cf3d17cd1a.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 线程数情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//91e04839dc6184825966b004e62ffa91.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 线程数&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f1879456a68bab5f04dd6cefc79aaa5a.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 线程数&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 接口响应时间情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9de3e1b9a261f06dbfd86fd6a64c5ab9.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接口响应时间&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;④ 运行一段时间后，CPU 使用率情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c3f85b69c1dd77a5861070bdd0f90c38.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;span id="OSC_h2_20"&gt;&lt;/span&gt; 
&lt;h2&gt;5.2 优化后再次分析 CPU 火焰图&lt;/h2&gt; 
&lt;p&gt;优化后效果虽然好了很多，但是 CPU 和 Runnable 线程数仍会出现小幅波动，接口的响应时间在 1 分钟内仍有上涨。这是我们接下来要继续优化的目标。&lt;/p&gt; 
&lt;span id="OSC_h3_21"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.1 编译阶段消耗 CPU 占比高&lt;/h3&gt; 
&lt;p&gt;再次使用 arthas 进行监测，查看正常情况与启动后（异常情况）的 CPU 消耗情况，我们可以观察到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;runWoker 部分：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该部分的 CPU 占用比例正常，与平时的表现一致，未见异常波动。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;编译相关的 CPU 占用：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CompileBroker::invoke_compiler_on_method(CompileTask*) 占用 CPU 较大，特别是 C2Compiler::compile_method(ciEnv*, ciMethod*, int) 的占比显著&lt;/p&gt; 
&lt;p&gt;由此我们得出结论：编译阶段的 CPU 消耗占比异常，可能是导致 CPU 负载突刺的重要因素。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① 异常情况下 CPU 火焰图：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//358b54cf05ca85c707e7a9b636e4ba11.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;异常 CPU 火焰图&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 正常情况下 CPU 火焰图：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//8736bb5cd5d70f06959491e2d9729028.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;正常 CPU 火焰图&lt;/p&gt; 
&lt;span id="OSC_h3_22"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.2 用 arthas 换个角度验证&lt;/h3&gt; 
&lt;p&gt;CPU 火焰图是基于启动后 3 分钟内的综合数据采集而生成的，虽然能够提供整体的 CPU 使用情况，但无法反映 CPU 的实时变化。因此，为了更准确地验证编译阶段是否确实消耗了 CPU，我们需要登录到机器上，使用 Arthas 进行实时监测。&lt;/p&gt; 
&lt;p&gt;机器启动后，运行 dashboard 命令，重点关注屏幕上方的进程信息，以识别哪些线程占据了较高的 CPU 资源，以下为其中一次波动的截图，前几次波动 CPU 占比都差不多：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e26f168e8937e370278c49578b95b790.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;dashboard 命令&lt;/p&gt; 
&lt;p&gt;从图中可以看到， CompilerThread 的三个线程占用了较高的 CPU 资源，尤其是 C2 CompilerThread 的占比明显，这与之前通过火焰图所反映的情况一致。&lt;/p&gt; 
&lt;span id="OSC_h3_23"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.3 CompilerThread 是什么&lt;/h3&gt; 
&lt;p&gt;C1 C2 CompilerThread 是 Java HotSpot 虚拟机中的两个即时编译器，主要作用是将 Java 字节码在运行时编译成本地机器码，以提高程序的执行效率。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;C1 Compiler（也称为客户端编译器），主要用于快速编译，优化较少，适合需要快速启动的应用。它的编译速度较快，但生成的机器码执行效率相对较低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;C2 Compiler（也称为服务端编译器），主要用于高性能的编译，优化程度较高，适合长时间运行的应用。C2 编译器会花费更多时间进行优化，以生成更高效的机器码，适合对性能要求较高的场景。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在 HotSpot 虚拟机中，Java 程序最初都是通过解释器（Interpreter）进行解释执行的，解释器的优点是启动快，省去编译的时间，能够快速运行代码。但随着程序的执行，某些方法或代码块可能会被多次调用，这些被频繁调用的代码被称为「热点代码」（Hot Spot Code）。当虚拟机识别到热点代码时，它会启动 JIT 编译器（C1 或 C2）将这些代码编译成本地机器码，以提高执行效率。&lt;/p&gt; 
&lt;p&gt;HotSpot 虚拟机是解释器与即时编译器并存的架构，两者经常是相辅相成地配合工作。由于即时编译器编译本地代码需要占用程序运行时间，编译出优化程度更高的代码所需的时间也会相应增加。此外为了实现更高的优化，解释器需要为编译器收集性能监控信息，这在一定程度上也会影响解释执行阶段的速度。为了解决这一问题，并在程序启动响应速度与运行效率之间达到最佳平衡，HotSpot 虚拟机在其编译子系统中引入了分层编译的功能。通过这一机制，HotSpot 能够根据代码的执行频率和性能需求，逐步将字节码编译为本地机器码，从而在保证快速启动的同时，优化长时间运行的代码性能。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;5.2.4 解决方案&lt;/h3&gt; 
&lt;p&gt;截止到现在，问题的原因就变得十分清晰了：当流量涌入时，HotSpot 虚拟机启动了分层编译机制，期间大部分代码迅速转变为热点代码。在这个过程中，C2 编译器需要频繁占用 CPU 资源进行编译，导致 CPU 使用率显著上升。随着大部分热点代码的优化完成，C2 编译器对 CPU 的占用将逐渐减少，CPU 使用率也会随之下降。这一编译过程的持续时间与监控图上的 CPU 波动情况高度一致。&lt;/p&gt; 
&lt;p&gt;C1 和 C2 编译器虽然提供了关闭的参数选项，但关闭这些编译器无疑会对服务的运行性能产生负面影响。网络上也有相关实验案例表明，对于需要长期运行的 Java 后端服务，禁用这些编译器将导致性能显著下降。因此这种关闭编译器的方式并不值得尝试。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解决方案一：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在前文中，我们已经验证了流量逐步放量对机器的影响：采用灰度发布，对机器几乎没什么影响，各项指标表现都很平稳。由于历史原因，我们的服务当前无法支持灰度发布，因此还需要探索其他有效的解决方案。&lt;/p&gt; 
&lt;p&gt;我们可以换个角度思考：是否可以通过降低接口的请求 QPS，并将发版时间固定在每天流量最低的时段，以观察对服务启动的影响。&lt;/p&gt; 
&lt;p&gt;首先，我们可以优先关注大流量接口，并尝试减少这些接口的 QPS。通过优化接口请求的频率，我们或许能够在发版过程中减轻对系统的压力。&lt;/p&gt; 
&lt;p&gt;降低接口 QPS，调整重启服务的时间（非高峰期），12:13:59 恢复流量成功，实验效果如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;恢复流量后 CPU 最高峰值为 61.5%（依旧有小突刺，但是对业务无影响）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Runnable、Blocked 线程数不再有突刺&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;接口响应时间（RT）也比较平稳&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;日志不再告警，无 error 错误日志&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//626e46d5af3e6130174792c68bea26c6.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 线程指标如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c4b821d566b0c09cb9848e68b198ad1b.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 线程数&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a8f80feebc04db763c19655bede37681.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 线程数&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;③ 接口响应时间情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//41d2850bb678d230ac1c1add16b70335.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接口响应时间&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解决方案二：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;方案一虽然能够在一定程度上缓解问题，但治标不治本。此外我们也无法固定发版时间，因此最有效的策略是进行预热。与前文不同的点在于，此处是 JVM 预热。&lt;/p&gt; 
&lt;p&gt;方案为：在系统成功启动（监测 check.do 返回成功）后，接入线上 HTTP 流量之前，针对大流量接口及核心接口进行 HTTP 接口调用，频控次数为配置项，方便线上动态调整。特别注意：在刚启动时，如果机器或下游依赖出现故障，此处的额外调用会加剧系统或下游的负担，因此调用次数需要合理配置。&lt;/p&gt; 
&lt;p&gt;此方式可以让 C2 编译器提前对热点代码进行优化，在系统在系统稳定后再将流量接入生产环境，从而避免对用户造成任何影响。&lt;/p&gt; 
&lt;p&gt;观察启动后的各项指标，14:56:25 恢复 HTTP 流量成功，实验效果如下：&lt;/p&gt; 
&lt;p&gt;整体表现与之前的方案一相似，但是有一个显著的区别：在恢复 HTTP 流量之前，Runnable 线程数出现了明显的突刺，而在流量恢复后，这种突刺现象则不再出现，线程数已经趋于平稳。我们注意到突刺出现的时间节点是 14:55:25，这个时间点正好是我们预热时发起 HTTP 接口调用的时间。&lt;/p&gt; 
&lt;p&gt;这表明通过预热策略，我们有效地前置了系统的负载波动。当真正的用户请求到达时，系统已经趋于平稳，服务响应速度保持稳定，从而为用户提供了更加流畅的体验。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;① CPU 使用率情况如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3ede52f825b29ea6085afd0dbf6c32c2.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU 使用率&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 线程指标如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//b4e11728f36cf7ed5f7490ab024b857f.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Runnable 线程数&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//32152718fa8265f6e8e7524b94e66a5b.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blocked 线程数&lt;/p&gt; 
&lt;span id="OSC_h1_25"&gt;&lt;/span&gt; 
&lt;h1&gt;六、总结&lt;/h1&gt; 
&lt;p&gt;本文针对服务启动后几分钟内 CPU 持续处于高峰状态的问题，提出了自己的分析思路与解决方案。最终线上效果比较显著，成功解决了每次发版过程中频繁告警、业务受损以及用户体验不佳的问题，为服务的高可用性增添了一道重要保障。最初的分析不够深入，导致在内存缓存预热方面的努力未能产生预期效果。因此在未来遇到类似问题时，我们必须深入挖掘，直至找到问题的根本原因。&lt;/p&gt; 
&lt;p&gt;本文的重点在于问题的发现、分析及解决思路。对于 CPU 相关的问题，火焰图和 Arthas 是非常有效的工具，建议大家在遇到类似情况时，积极尝试使用这些工具进行排查和解决。&lt;/p&gt; 
&lt;p&gt;此外 HTTP 请求未定义属性的问题普遍存在，特别是在服务未进行预热启动时，会加剧 CPU 的负载。对于大流量服务而言，遇到此类问题时，需规范请求参数，以减轻 CPU 负担。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18685693</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18685693</guid>
      <pubDate>Thu, 17 Jul 2025 07:12:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>特朗普希望重命名「人工智能」术语，改为「天才智能」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;当地时间 7 月 23 日，美国总统特朗普在华盛顿特区举行的人工智能峰会上&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAcyn%2Fstatus%2F1948137088945369220" target="_blank"&gt;发言&lt;/a&gt;，他表示自己不喜欢「人工智能」（ Artificial Intelligence）这个术语表述，建议改名「天才智能」。&lt;/p&gt; 
&lt;p&gt;特朗普在讲话中称，自己不喜欢 AI 中「Artificial」一词，「我忍不了任何造作的东西，我甚至不喜欢人造东西这个名字」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/145318_T5L4_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他还表示，「&lt;strong&gt;AI 是天才的，是纯粹的天才，我建议把它改名天才智能。&lt;/strong&gt;」特朗普在讲话中强调，自己这个想法是「认真的」。&lt;/p&gt; 
&lt;p&gt;根据英国牛津英语词典，Artificial 一词除了「人工、人造」外，也有「矫揉造作」的含义。&lt;/p&gt; 
&lt;p&gt;值得一提的是，据外媒相关报道：&lt;a href="https://www.oschina.net/news/362050"&gt;美国政府将签署大量有关 AI 产业的行政令&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;据介绍，这些行政令内容涵盖多个方面，包括建立支持数据中心、半导体制造工厂建设的举措，完善国家电力网络，以及消除 AI 大模型对话中所谓的「意识形态偏见」等。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362115</guid>
      <pubDate>Thu, 17 Jul 2025 06:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>脉脉：超四成国内 AI 头部公司员工欲跳槽</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;脉脉平台&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;最新&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;数据显示，截至 2025 年 7 月，国内 AI 头部公司员工的跳槽意愿显著高于其他行业。高达&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#242424"&gt;41.07%&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的 AI 从业者目前处于「正在看机会」的求职状态，这一比例远超互联网行业的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#242424"&gt;14.65%&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#242424"&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;自今年 2 月以来，每月新增上万名 AI 人才将其求职状态更新为「正在看机会」，这充分体现了 AI 人才市场的高度活跃性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="216" src="https://oscimg.oschina.net/oscnet/up-3e5948b9574d255f2fff9c5a87be1ffdfe1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;与此同时，企业间的「抢人大战」已进入白热化阶段。目前已有超过&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;1000 家 AI 公司&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;在脉脉平台发布了 AI 相关岗位。为了吸引&lt;span&gt;顶尖&lt;/span&gt;人才，包括华为、小红书、DeepSeek 等在内的知名企业高管也亲自上阵，在个人主页签名中明确标注「长期招人」。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，HR 和猎头在平台上的活跃度达到「分钟级」，AI 人才的个人主页访问量也因此激增，显示出市场对 AI 人才的迫切需求。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362114</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362114</guid>
      <pubDate>Thu, 17 Jul 2025 06:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>基于 Python-use 范式的开源 Agent</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="text-align:left"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;「传统 Agent 框架更像是用低代码拖拽的「机器人编排器」，&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Python-use 则是直接用 Python 把 Agent 逻辑实现出来，让代码就是 Agent。」&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当大多数 Agent 框架还在把「工具」当作黑盒 API 时，知道创宇 AI 业务部总经理王利伟和其团队在思考另一种方式——如果代码就是工具，而 LLM 恰好擅长写代码，为什么不干脆让 AI 自己用 Python 把任务跑出来？&lt;/p&gt; 
&lt;p&gt;在这篇访谈中，王利伟系统阐述了「Python-use 范式」——一种把 Agent 逻辑直接写成可执行 Python 的极简思路。它抛弃繁复的 Schema 注册、Workflow 编排和多 Agent 协商，实现细粒度代码控制，逻辑可控、可调试、最少 Token 浪费。&lt;/p&gt; 
&lt;p&gt;本周六，王利伟将出席【Al Agent：从工具助手到自主行动】OSC 源创会·杭州站活动，并发表《基于 Python-use 范式的开源 Agent》主题演讲，介绍如何撮合 LLM ➕Python 生态形成强大的智能体，通过独创的 Python-use 范式，让 AI 不光会调用工具，也会自己造工具。&lt;/p&gt; 
&lt;p&gt;即刻报名：&lt;a href="https://www.oschina.net/event/8597955"&gt;https://www.oschina.net/event/8597955&lt;/a&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="1067" src="https://oscimg.oschina.net/oscnet/up-f2c70b12c7d35ded92d220bd2c56ab5987b.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：您提出「Python-use 范式」与传统 Agent 开发框架的核心差异是什么？它如何解决现有 Agent 工具调用能力的局限性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;答：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;回答这个问题之前，我们先定义一下什么是「工具」，众所周知「工具」调用是 Agent 的基本能力之一。工具到底是什么呢？是各种应用程序，接口对吧。从根本上来讲都是代码，代码组成了 MCP 工具、API 工具以及各类应用程序。Python use 范式是回归第一性原理，把 code 当成工具，code 是所有工具的最基本构成，code 可以组成各种各样的工具，而 LLM 对 code 的理解和编写能力都足够强，相比依赖于现成的工具，Python use 是从代码出发，具有灵活性、扩展性。当然，在这过程 Python use 也是支持现有工具的调用的，比如 MCP、browser use 等等。而对于一些碎片化的场景，没有标准工具、现成工具可以用的场景，Python use 可以依赖于 Python 编码自行找到更具创造性的方案。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;一句话总结：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;传统 Agent 框架更像是用低代码拖拽的「机器人编排器」；&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 则是直接用 Python 把 Agent 逻辑实现出来，让代码就是 Agent&lt;/p&gt; 
&lt;div&gt; 
 &lt;table cellspacing="0" style="border-collapse:collapse; border:none; table-layout:fixed; width:500px"&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;维度&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;传统 Agent 开发框架&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;Python-use 范式&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;任务驱动逻辑&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;通过「规划 → 调度 → 工具调用 →反馈」的多层 Agent、子-Agent、workflow 实现任务拆解和执行。往往是图状、嵌套、多 Agent。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;直接写出「任务目标 → 代码逻辑 → 执行」的 Python 脚本来解决任务，代码即规划+工具调用+执行的统一体。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;工具调用&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;工具通常封装为 function calling / Tool 类、API schema，由 Agent 通过有限的模板化调用（受限于预定义接口和框架支持的函数集合）。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;直接调用 Python 生态中任意库、API、命令行、HTTP、数据库等，甚至动态生成和运行代码，无需提前注册工具。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;灵活性&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;强调框架内一致性和安全性，但牺牲了灵活性。增加一个新工具需要写 schema、注册、重训练或适配。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;由于直接写 Python 代码，可以随时引入任何新工具、任意组合库、甚至嵌入 shell/JS 等。灵活性最大。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;执行粒度&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;依赖大量 LLM 推理+中间规划，执行粒度粗，容易浪费 token、出错。&lt;/p&gt; &lt;/td&gt; 
    &lt;td style="border-color:#dee0e3; border-style:solid; border-width:1px; height:39px; vertical-align:top"&gt; &lt;p style="text-align:left"&gt;细粒度代码控制，逻辑可控、可调试、最少 token 浪费。&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;至于如何解决现有 Agent 工具调用能力的局限性大体分析如下：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;现有 Agent 框架在工具调用上主要有两个局限：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;1、工具注册繁琐且封闭：需要开发者把工具写成符合接口的形式并注册进 Agent 系统。灵活性低、扩展慢。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;2、推理成本高+错误多：每次工具调用都可能需要 LLM 去推理哪个工具+如何填参数，容易出错，且慢。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 通过：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;代码即接口：不需要任何预定义 schema、function calling 注册。Python 里能 import / pip install 的库、调用的 API，都是工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;动态生成工具：Python 里可以即时生成函数、类、模块，甚至临时下载或拼接代码然后执行，完全不受限。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;全栈生态：Python 能调用系统命令、数据库、网络请求、爬虫、机器学习、云 API… 不再被框架内置的工具集限制。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;例如：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;传统 Agent 框架里，你要增加对某个第三方 CRM 的支持，得写 Tool 类、注册 schema、让 LLM 学会调用。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 里，你直接用 requests 或 SDK 写个接口调用完事。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;传统 Agent 范式假设：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;人类用自然语言说「你去干 X」，AI 负责拆解成多步计划+调度各种工具完成。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 范式更像：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;人类写出一段 Python 程序告诉 AI 怎么干，或者 AI 直接生成出一段 Python 程序来干。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;即：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;传统是 LLM+流程编排器+有限工具集&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use 是 LLM+Python 解释器+全 Python 生态&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：「让 AI 自己造工具」是演讲的亮点。能否解释 LLM 在 Python-use 范式中如何完成从「使用工具」到「生成工具」的跨越？关键技术难点是什么？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;使用工具其实只是一个思维方式的差别生产工具，只是一张窗户纸，只是大家对 LLM 的理解以及应用方式的差别。使用工具 tool use 是假定要处理的任务都有各种现成的工具可以使用，Python use 一样也具备这个能力，并不是说它就不支持现有工具的调用，Python use 认为 code is agent ，code is everything，Python 可以 use network、use computer 可以 use 各类工具，它可以 use code 去编码、写工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在传统 Agent 中：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;LLM 能做到的通常是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;选择一个已有工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正确填写参数调用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;（最多）按照文档组合几个已有工具完成目标&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align:left"&gt;它的「能力边界」被框架里预定义的 function/schema 限死了。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在 Python-use 中：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;LLM 不光能调用库和工具，还可以：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;根据任务需要动态生成代码段（工具）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;把这段代码封装成函数/类/模块/脚本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;并且可以即时运行、测试、调试它&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="text-align:left"&gt;也就是说，它不只是「调用工具」，它还能写工具！&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;举个例子：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#d83931"&gt;「帮我把一堆 Excel 按部门拆分成不同的 PDF 并发邮件」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;传统 Agent：找不到现成的「拆 Excel 发 PDF」工具，任务失败或需要人手扩展工具。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;Python-use：LLM 生成一个函数&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#2ea121"&gt;def split_excel_and_send():&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#2ea121"&gt;# pandas, fpdf, smtplib 逻辑&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;运行测试、修复 bug、保存。这段代码就是一个新造出来的「工具」，下次还能直接用。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;为什么 Python-use 能支持「造工具」？关键在于：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;LLM 生成的就是代码，代码本身就是工具&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Python 解释器支持动态定义、动态执行、动态 import 模块&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全 Python 生态的库让「造工具」成本极低&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;人类可以随时 review、微调、持久化新工具&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;当然，这个跨越不是轻易做到的，主要有几个挑战：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;代码生成的正确性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;LLM 写出的代码可能语法正确但逻辑错误&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对外部库版本/接口调用不熟导致出错&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;没有即时验证的环境，bug 率高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;上下文管理&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;造出来的工具需要有清晰的输入输出和作用域&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果任务复杂，代码的组织结构（函数拆分、模块化）很容易混乱&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;安全性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;动态生成的代码有潜在的安全风险（注入恶意代码、破坏环境、泄露数据）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要沙箱或审核机制&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;��&lt;/p&gt; 
&lt;p style="text-align:left"&gt;怎么克服这些难点也有对应的思路和方案，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;内置单元测试和验证，让 LLM 顺便生成测试用例或自动运行测试，提高正确性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;设计合理的 prompt 模式，指导 LLM 输出模块化、注释良好、易维护的代码。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;用虚拟环境+沙箱，让生成和执行的代码不破坏主环境，保障安全。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;版本控制+注册，把造出来的工具保存到 Git、注册到私有 PyPI 或工具库中。&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;总结一句话：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在 Python-use 中，LLM 不只是「选工具」，而是可以直接写出满足当前任务的新工具、即写即用；&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而传统 Agent 则停留在「调用已有工具」阶段，受限于框架的工具集。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：Python 生态有海量开源库，但 LLM 常因依赖、环境问题调用失败。Python-use 如何实现 LLM 与本地 Python 环境的高效安全交互？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;这个问题提的非常好，确实是有各类的版本问题、兼容性、依赖关系问题等等。解决方案是它在执行任务的时候不局限一个方案，一个不行会切换到另外的方案，大模型知道怎么解决。如今 vibe coding 都是差不多的思路，有错误，再重新丢给大模型去分析提出修正就好了，直到运行成功。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;另外一个方法是，在执行任务的时候会把用户系统相关的版本信息、环境信息做收集，发给模型和 TrusToken-也就是我们的 token 分发平台及网关，TrusToken 上会集成很多场景的「最佳实践」形成经验库、知识库，从而帮会根据用户环境做最优匹配，可以理解是 TrusToken 上面做了很多优化。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;至于安全问题，上个问题也提到过，理论上确实存在安全风险，我们也有考虑安全模块，也有方案，还没来得及做。一个安全公司在做产品的时候并没有把安全机制放在首位是有其他考虑，我们完全可以做个沙盒，但是为什么不做沙盒，放到沙盒限制了太多功能，实质上我们电脑上大多数软件都是运行在本机，并没有沙盒，只有杀毒软件才会有。理论上安全风险干什么都存在，与安全风险共舞，不因噎废食。实质上，从现在几万注册用户的使用反馈来讲，还没有安全问题被提出。当然，随着项目的成熟会把响应的机制逐渐完善，现在是有想法没精力，从技术上来讲不是不可解决的难题。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：在操作物联网设备中，智能体如何统一处理不同品牌/协议设备的接口差异？是否依赖预设插件？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;充分信任和利用大模型，他对现有的品牌协议他都懂，主流的接口标准、协议他都学习过的，这些知识他比人熟。如果是定制化的软件它没有学习过，直接写到 API 描述里，大模型通过 API 描述学习，当然对 api 描述就有一定的要求，实在它不懂的就给他外挂说明。AiPy 操作物联网设备并不是依赖插件，主要是通过 API Calling ，当然有插件可以调用也是极好的，实际上我们也在准备发布插件商城。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;提到这个问题不得不提一下我们团队的另外一个产品 ZoomEye.org，它是全球领先的网络空间资产测绘平台，它通过对全球 IPv4 和 IPv6 地址进行探查，能够识别数十亿联网设备的开放端口、服务类型、协议栈、操作系统、硬件厂商、固件版本等关键资产信息。换句话说，ZoomEye 就像是整个网络世界的「显微镜」或「地图系统」，让你可以一眼看清某个 IP 背后部署了哪些设备、跑着什么服务、使用了什么协议。它支持的协议识别范围极广，涵盖操作系统、网络设备等传统 IT 系统、工业控制系统（如 Modbus、BACnet）、摄像头设备（如 ONVIF）、网络存储（如 NAS）、IoT 中控网关、智能家居等，这些恰恰是大多数传统 Agent 系统难以应对的「黑盒」。我们正在探索将 ZoomEye 的识别能力与 AiPy 结合：AI 可以在执行任务前，通过 ZoomEye 自动识别目标设备类型、开放接口、固件版本，进一步提高调用准确率和安全性。这种从「识别 → 理解 → 控制」的闭环，将极大提升 AI 操控物联网设备的普适性与稳定性。现在 ZoomEye 也已经发布了 MCP 和 API，大家可以去体验。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;span style="color:#27ae60"&gt;&lt;strong&gt;问：如何吸引开发者加入 Python-use 生态？会提供哪些 SDK 或工具链降低接入成本？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;因为项目还在初期，暂时还没有 SDK 之类的工具，为了方便开发者调试，给大家的支持就是提供了大量 Token 进行试错调试，默认 1000 万 token，开发者可以凭贡献持续兑换。我们后续会开放商城，商城里可以发布各种插件、成果、知识库、角色、API、MCP 等等，开发者也可以贡献各类插件或应用到商城，优秀的成果我们也会做一些激励措施。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;随着项目的推进我们会持续优化改进生态，也欢迎大家提意见。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;问：对于想尝试 Agent 开发的团队，您认为切入此领域最应优先掌握的三大能力是什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;&lt;strong&gt;答：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;说实话这个问题我并不太敢回答，一是因为我们走的路和别人不一样，二我们自己还并没有成功，没有资格去给别人指点什么。只能单纯的分享自己的几个感受：&lt;/p&gt; 
&lt;p style="text-align:left"&gt;模型能力足够强，有很大的挖掘潜力。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;以前是语料驱动模型，现在是数据驱动 Agent，对要做的场景 know how 掌握了多少是关键。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;不管你啥范式，啥技术，不出 1 个月时间大家都能做到，大家也看到了现在大模型之间的能力差距差别是越来越小了，技术之外的优势可能才是竞争力。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;em&gt;&lt;img height="2676" src="https://oscimg.oschina.net/oscnet/up-aeeb1d545d5e5ab92f8a3b5d959269e8da3.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18685742</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18685742</guid>
      <pubDate>Thu, 17 Jul 2025 06:47:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>中国证明开放权重模型优于 GPU 算力资源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;国外科技媒体 The Register 近日&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theregister.com%2F2025%2F07%2F19%2Fopenai_us_china%2F" target="_blank"&gt;发文&lt;/a&gt;&lt;/u&gt;讨论了开放权重模型对 AI 技术进步的正面影响，称中国企业通过开放分享和底层创新，比如 DeepSeek 和 Kimi 系列模型，展现了更高的效率和更强的竞争力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/143507_tWgV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;文章标题十分坦诚——&lt;em&gt;《&lt;strong&gt;China proves that open models are more effective than all the GPUs in the world&lt;/strong&gt;》&lt;/em&gt;，直接提出「&lt;strong&gt;中国证明开放权重模型比 GPU 更有效&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心内容&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. OpenAI 延迟发布「开放权重」模型&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;自 GPT‑2 以来，OpenAI 已多年未对外开源其模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;原计划在本周发布一个社区友好型开源模型，但因安全审查推迟。CEO Sam Altman 表示，「一旦权重公布，就无法撤回，我们必须确保万无一失」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 美国虽投资重金，但开放模型依然乏善可陈&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;美国在 GPU、计算资源上投入数百亿美元，却仅涌现出少数效率和实力不足的开源模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;譬如 Meta 发布的 Llama 4&amp;nbsp;遭遇争议与冷淡反响；微软、IBM、谷歌亦推出体量较小、功能局限的模型&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 中国在开源领域反超&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中国开发者不仅率先发布公开可用的大规模模型，而且算法创新表现突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DeepSeek R1（DeepSeek）早在年初便问世，后来 Moonshot AI 于 7 月推出的 Kimi 2 更声称已实现万亿参数规模 MoE（专家专家模型），并宣布超越包括西方顶尖私有模型在内的技术水平。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文章强调，尽管美企掌控大量计算资源，但因开源保守与发布缓慢，在社区驱动的模型研发上落后于中国。从战略上看，美国若想保持 AI 领导力，除了硬件投入，更应适当开放、加快社区驱动的模型生态——否则将继续被中国「公开优先」（open-first）的路线追赶。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362109</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362109</guid>
      <pubDate>Thu, 17 Jul 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源鸿蒙机器人操作系统 M-Robots OS 正式开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;深开鸿宣布 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fatomgit.com%2Fm-robots" target="_blank"&gt;M-Robots&lt;/a&gt; 开源项目正式启动。该项目由开放原子开源基金会孵化、深开鸿牵头发起，旨在以开源共建的方式打造基于开源鸿蒙的统一机器人操作系统 M-Robots OS，推动机器人行业生态融合、能力复用、智能协同。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，M-Robots OS 是全国首个基于开源鸿蒙构建的分布式异构多机协同机器人操作系统，具备多机实时协同、多硬件形态兼容、AI 原生以及丰富 API 与开发工具链四大核心能力，为行业提供「底层统一、场景多元」的全栈式系统平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="333" src="https://oscimg.oschina.net/oscnet/up-16538ff9cdf050ddcfc6cd2069b9c349cfe.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;M-Robots OS 开源计划将以分阶段、全栈式策略推进，逐步释放关键能力，推动机器人生态融合：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2025 年 7 月 24 日：首期开源， 已上线开源鸿蒙机器人核心子系统、核心三方中间件库、包管理器、可视化开发／调试工具；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2025 年 12 月：发布公板芯片适配、专属驱动框架、分布式反控机制、DFX 能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2026 年 6 月：开放混合部署架构、超级设备支持、软总线增强、融合组网技术及 AI 训练工具；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2026 年 12 月：推出 M-DDS 分布式通信框架、分布式算力调度、多机协同支持、AI-Agent 框架与仿真工具链；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;2027 年：实现基于 Agent 的群体智能协作体系，推出统一机器人 IDE 开发环境。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;M-Robots OS 将按照「每年两大版本」的节奏持续演进，开源范围可能会根据技术发展、场景变化、需求优先级进行调整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，该项目已汇聚包括深开鸿、中软国际、数字华夏、乐聚机器人、哈工大重庆研究院、北京工业大学、北京理工大学在内的 21 家「产学研用」成员单位，成立项目管理委员会（PMC）与多个 SIG 技术组，覆盖架构、运动控制、具身智能等关键方向，推动跨厂商协作与产业场景落地。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362103</guid>
      <pubDate>Thu, 17 Jul 2025 06:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 应用部门迎来新任首席执行官</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Instacart 首席执行官 Fidji Simo&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Ffidjissimo%2Fstatus%2F1947341053209501716" target="_blank"&gt;宣布&lt;/a&gt;，将在 8 月 18 日正式加入 OpenAI，并担任新部门的 CEO。Simo 同时在 OpenAI 官网发布了一篇&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fai-as-the-greatest-source-of-empowerment-for-all%2F" target="_blank"&gt;深度长文&lt;/a&gt;，主要阐述了她对 AI 如何赋能和改变人类的看法。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1040" src="https://static.oschina.net/uploads/space/2025/0724/141245_kGM8_2720166.png" width="2244" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;几周后，我将加入 OpenAI 担任应用部门首席执行官，致力于让 OpenAI 的技术惠及全球更多人群。&lt;/p&gt; 
 &lt;p&gt;我一直认为自己是一名务实的技术从业者我热爱技术，并非因其本身，而是因其能对人们的生活产生直接影响。这正是这份工作令人兴奋之处，因为我相信，AI 将比历史上任何其他技术为更多人带来更多机遇。如果我们能正确运用 AI，它将赋予每个人前所未有的力量。&lt;/p&gt; 
 &lt;p&gt;但我也明白，这些机遇不会凭空出现。&lt;/p&gt; 
 &lt;p&gt;每一次重大的技术变革，都可能拓宽人们获取权力的渠道这种权力包括做出更明智决策、塑造周遭世界以及以新方式掌控自身命运的能力。但与此同时，技术变革也可能导致财富和权力进一步集中在少数人手中通常是那些本就拥有金钱、资历和人脉的人。&lt;/p&gt; 
 &lt;p&gt;因此，我们必须有意识地规划这些技术的构建与共享方式，以确保它们能为更多人带来更多机遇和繁荣。我们当下的选择，将决定这场即将到来的变革会让所有人都获得更多赋能，还是让少数人进一步集中财富和权力。&lt;/p&gt; 
 &lt;p&gt;我们可以从确保赋能与机遇的关键要素被广泛获取做起，这些要素包括知识、健康、创造性表达、经济自由、时间和支持。下文将详细阐述 AI 在改变人们生活的这些方面所具有的潜力。&lt;/p&gt; 
 &lt;p&gt;如果我们能让智能无处不在、人人可用且通俗易懂，就能打造出世界上最强大的机遇引擎，帮助更多人过上更美好的生活。我期待与 OpenAI 才华横溢的新同事们共同构建这样的未来，也会在不久后分享更多内容。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;公开资料显示，Simo 职业生涯始于 eBay，曾担任战略团队成员，专注于本地商务和分类广告项目的开发。2011 年，她加入了 Facebook，并逐步晋升为 Facebook 应用的负责人，领导包括 NewsFeed、Stories、Groups、Video、Marketplace、Gaming、News、Dating 和广告等核心产品的开发。在她的推动下，Facebook 的视频战略取得了显著进展，推出了自动播放视频、FacebookLive 和 FacebookWatch 等功能。她还带领团队构建了 Facebook 的移动广告业务，为公司的发展做出了重要贡献。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362101</guid>
      <pubDate>Thu, 17 Jul 2025 06:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>预计 2029 年中国数据仓库软件市场规模将达 20.9 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;国际数据公司（IDC）于近日发布了《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmy.idc.com%2Fgetdoc.jsp%3FcontainerId%3DprCHC53700025" target="_blank"&gt;2024 年下半年中国数据仓库软件市场跟踪报告&lt;/a&gt;》。IDC 数据显示，2024 下半年中国数据仓库软件市场规模为 5.5 亿美元，同比增长 8.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其中，本地部署数据仓库软件规模 2.8 亿美元，同比增长 6.8%；公有云数据仓库软件规模 2.6 亿美元，同比增长 10.9%。IDC 预测， 到 2029 年，中国数据仓库软件市场规模将达到 20.9 亿美元，2024-2029 的 5 年市场年复合增长率（CAGR）为 15.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-eb766774b570abb458036289ca15326fbde.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 下半年，中国数据仓库&lt;strong style="color:#01010f"&gt;本地部署模式&lt;/strong&gt;市场前五大厂商总计占比 57.7%。出于数据安全和合规性的考虑，金融、政府、能源等行业，以及大型企更倾向于本地部署模式的数据仓库产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="406" src="https://oscimg.oschina.net/oscnet/up-05482245a6774b1ed848792b16fadf3762d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与本地部署市场相比，&lt;strong style="color:#01010f"&gt;公有云&lt;/strong&gt;数据仓库服务的市场集中度更高，2024 下半年，前五大厂商份额共计达到 90.2%。随着中国泛互联网行业和传统企业的互联网业务的快速发展，企业已经在公有云上积累了大量的数据，为云上数仓的使用创造了前提和基础。2024 年，公有云数据仓库市场规模已超过本地部署市场，占比 50.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="455" src="https://oscimg.oschina.net/oscnet/up-6402c7dfdd4a171b4ece232ca18651694c4.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong style="color:#01010f"&gt;IDC 中国企业软件市场研究经理王楠表示&lt;/strong&gt;，存算分离架构、实时分析能力以及湖仓一体技术已经成为数据仓库产品应具备的基础能力，也是客户进行数仓产品选型时考察和评估的重点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拥抱生成式 AI 和大模型已经成为数据仓库下一步产品能力升级的核心，在 AI for DB 层面实现自然语言交互式查询、智能调优、智能诊断等能力，使数仓产品的使用和运维更加便捷；在 DB for AI 层面支撑向量引擎、库内机器学习能力，实现正真的智能问数 AI 加持下的数仓产品将使企业的数据分析能力进一步提高， 获得更精确的预测和洞察能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362100</guid>
      <pubDate>Thu, 17 Jul 2025 06:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节发布端到端同声传译模型 Seed LiveInterpret 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;字节跳动 Seed 团队宣布正式推出端到端同声传译模型 Seed LiveInterpret 2.0 —— 首个延迟&amp;amp;准确率接近人类水平的产品级中英语音同传系统，在中英同传翻译质量达到业界 SOTA 的同时，实现了极低的语音延迟水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告称，Seed LiveInterpret 2.0 基于全双工端到端语音生成理解框架，支持中英互译，可实时处理多人语音输入，像人类同传译员一样以极低的延迟 「边听边说」，一边接收源语言语音输入，一边直接输出目标语言的翻译语音。同时，Seed LiveInterpret 2.0 还支持 0 样本声音复刻，让沟通更加流畅自然。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在测试中，Seed LiveInterpret 2.0 面对 40 秒的大段中文表达，能够低延迟地丝滑输出同款音色的英语翻译。Seed LiveInterpret 2.0 还能快速学习音色，即便此前未「听」过角色的声音，依然能通过实时交互进行现场演绎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;相比传统机器同传系统，Seed LiveInterpret 2.0 模型具备以下优势：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;接近真人同传的翻译准确率&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;精准的语音理解能力保障了翻译准确度，在多人会议等复杂场景中英双向翻译准确率超 70%，单人演讲翻译准确率超 80%，接近真人专业同传水平。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;极低延迟的 「边听边说」 能力&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;采用全双工语音理解生成框架，翻译延迟可低至 2-3 秒，较传统机器同传系统降低超 60%，实现了真正的 「边听边说」 翻译。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;零样本声音复刻，音色真实自然&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;只需采样实时语音信号，便能提取声音特征，用说话人的音色特质实时 「说出」 外语，提升交流的沉浸感和亲和力。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;智能平衡翻译质量、延迟和语音输出节奏&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;可根据语音清晰度、流畅度、复杂程度，调整输出节奏，并适配不同语言特性。面对超长信息，依然能保证传译语音节奏的自然流畅。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Seed LiveInterpret 2.0 技术报告已公布，模型基于火山引擎对外开放。此外，Ola Friend 耳机也将在 8 月底接入 Seed LiveInterpret 2.0，成为首个支持该模型的智能硬件设备。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;评测结果显示，在语音到文本的同传任务中，Seed LiveInterpret 2.0 中英互译平均翻译质量的人类评分达到 74.8（满分 100，评估译文准确率），较排名第二的基准系统（47.3 分）超出 58%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在语音到语音中英同传任务中，仅 3 个测评的翻译系统支持该能力，其中 Seed LiveInterpret 2.0 中英互译平均翻译质量达到 66.3 分（满分 100，除评估译文准确率，还评估语音输出时延、语速、发音、流畅性等指标），远超其他基准系统，&lt;strong&gt;达到接近专业真人同传的水平&lt;/strong&gt;。同时，大部分基准系统也不支持声音复刻功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="367" src="https://oscimg.oschina.net/oscnet/up-5db0506a8b7711255ee86d2bb6986dc7f78.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="360" src="https://oscimg.oschina.net/oscnet/up-03b5d4e3cac39425b43d1c9044266bcc0e7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在延迟表现上，Seed LiveInterpret 2.0 在语音到文本场景中，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;输出首字平均延迟仅 2.21 秒，在语音到语音场景中，输出延时仅 2.53 秒，做到了对翻译质量以及时延的均衡。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="255" src="https://oscimg.oschina.net/oscnet/up-86b7ef584ede587d9df7ad36aafec6d1ab2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="260" src="https://oscimg.oschina.net/oscnet/up-8ec35eff6c30fc2e8e276f0f36159d3cf7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;不过，字节方面也坦承尽管 Seed LiveInterpret 2.0 已初步展现出一定优势，&lt;strong style="color:rgba(0, 0, 0, 0.9)"&gt;其边界仍有拓展空间&lt;/strong&gt;。比如，在语言覆盖方面，目前模型主要支持中英互译，其他语种尚未较好支持。此外，其声音复刻的稳定性、语音表现力、情绪复刻能力、极复杂情况下的翻译准确性等仍有进步空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fvjq_cwneALGoPf6RgxwuLQ" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362097</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362097</guid>
      <pubDate>Thu, 17 Jul 2025 05:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智能体时代，如何避免大厂垄断 AI ？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;「过去十几年里，&lt;strong&gt;互联网的开放性正在逐步消失。&lt;/strong&gt;越来越多的服务、数据、用户，被锁定在几个大型平台的生态里。协议的边界被平台所取代，数据也变成了平台资产而不是网络资源。&lt;strong&gt;我们不希望智能体时代重复这一切。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;近日，ANP 开源技术社区发起人常高伟在接受国际著名科学杂志《New Scientist》采访时指出了当前互联网的封闭性，并担心智能体时代将会重蹈覆辙。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;目前来看，大部分 AI 协议都是由大型科技公司提出的，比如 Anthropic、Google 这些企业，他们推动了 MCP、A2A 等协议的发展，也让更多的人看到协议对智能体的价值。但这些协议的设计，很多时候是基于他们自己的产品路径和商业利益出发的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;常高伟认为，这本身没有错——商业公司有自己的考量和节奏。「但问题是，如果整个智能体互联网的底层协议都由几家公司来主导，那我们可能会再次走上平台封闭化的老路。&lt;strong&gt;就像今天的社交平台、应用商店、广告系统，数据和权限越来越集中在少数大公司手里。&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;要打破这种封闭性困局，常高伟等人于 2024 年 4 月开源的 &lt;strong&gt;ANP（Agent Network Protocol）&lt;/strong&gt; 提供了新路径。与 Anthropic 主导的 MCP、Google 推动的 A2A 不同的是，&lt;span&gt;ANP 从一开始就关注智能体之间的身份认证问题。这样一来，任何两个智能体——不管是谁开发的，来自哪家公司，都能通过标准协议完成安全的双向身份认证。&lt;/span&gt;这一设计使 ANP 成为首个真正面向开放互联网的智能体协议。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;更重要的是，ANP 由全球开发者社区共建&lt;/strong&gt;。其发起团队明确强调：这是一个&lt;strong&gt;不追求盈利的非商业化组织&lt;/strong&gt;，成员包含极客、学者与创业者。常高伟表示，AI 不应该被垄断，它的连接能力、协作能力，应该像空气和水一样，向所有人开放。ANP&amp;nbsp;通过完全开源和去中心化架构，让智能体间的协作回归以协议为中心的开放连接，打破平台封闭化的老路和数据孤岛，确保连接权回到每一个人手里，&lt;strong&gt;让互联网重新成为创造力的土壤，而不是流量的围墙。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;为了在全球范围内推动智能体协议标准化的共识与合作，&lt;/span&gt;ANP&amp;nbsp;&lt;span&gt;开源技术社区牵头在 W3C 发起了 "AI Agent Protocol" 社区组（Community Group）。W3C 一直是互联网协议发展的重要推动者，从 HTTP 到 HTML，它见证并塑造了多个开放技术的诞生。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#2980b9"&gt;&lt;strong&gt;以下为《New Scientist》杂志采访常高伟全文：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Why are protocols important to enable agentic AI?（为什么协议对实现 Agentic AI 至关重要？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：想象一下，如果你让一个 AI 去使用 Excel 表格、点开网页、登录邮箱，才能获取信息，它要么得模仿人类的鼠标操作，要么得反复破解界面背后的逻辑。这种方式其实非常不自然——&lt;/span&gt;&lt;strong&gt;&lt;span&gt;AI 并不擅长使用为"人类"设计的软件，它更擅长的是直接处理数据&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;从这个角度看，我们其实应该反过来思考：让数据为 AI 所用，而不是让 AI 学着像人那样"用工具"。这就需要一种标准方式，把数据、身份、能力、安全都打包好，直接交给智能体使用。这种"标准方式"，就是&lt;/span&gt;&lt;strong&gt;&lt;span&gt;协议&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。协议是承载数据，最好的容器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我认为这才是协议为什么对 AI 如此重要的最根本的原因。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但协议的重要性不单单体现在让 AI 与数字世界交互，更重要的是，它会推动 Agentic web 的到来。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;Agentic Web&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，我们可以把它简单理解为"&lt;/span&gt;&lt;strong&gt;&lt;span&gt;为 AI 而设计的下一代互联网&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在今天的 Web 世界里，网页是给人看的，数据往往被封装在前端页面中，只有人类点击、滑动、输入后，背后的系统才会做出响应。这种设计模式是典型的"人机交互优先"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但 Agentic Web 的出发点不同：它是为 AI 与 AI 的交互而构建的。在 Agentic Web 中，智能体将成为第一公民——他们是互联网中最重要的参与者，智能体之间相互协作，帮助人类完成繁琐、复杂的任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;支撑这种协作的关键工具，正是智能体协议。协议将成为 Agentic Web 的基础设施，它不仅定义了身份、通信、能力调用等核心机制，还让来自不同平台、不同组织、不同个人的智能体能够自由连接与协作。无论一个智能体属于哪个公司或个人，只要遵循相同的协议，它就能融入这个新型网络。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这将彻底改变现有互联网的格局。Agentic Web 有潜力打破今天由平台主导的数据孤岛，实现真正开放、互联、去中心化的网络结构，为下一代互联网打开新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Who has been developing these protocols so far?（到目前为止，这些协议都是由谁在开发的？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前全球有十几个智能体相关的协议项目，有些是由科技巨头主导，有些是由开源社区或小公司推动。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第一个是 MCP（Model Context Protocol），这个是由 Anthropic 推动的。Anthropic 是 OpenAI 的主要对手之一，他们觉得大模型光靠预训练是不够的，还得"实时连上工具"，才能真正解决问题。MCP 就像是一个标准接口，让模型可以安全、统一地调用外部系统，比如搜索、数据库、插件等。现在包括微软、OpenAI、谷歌、亚马逊等都在支持这个协议。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第二个是 A2A（Agent-to-Agent Protocol），这是 Google 推出来的，重点不是模型和工具的连接，而是"智能体和智能体之间怎么说话"。比如一个智能体说"我不会订机票"，另一个说"我来帮你"，A2A 定义了这背后的语言和流程。目前还在早期阶段，但被不少开发者看好，尤其适合企业内部多个 AI 系统之间的互联。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;第三个是 ANP（Agent Network Protocol），这是由我们开源社区发起的项目，也是目前全球最早关注"去中心化智能体通信"的协议，我们研究这个领域比 MCP 和 A2A 更早。我们希望构建一个安全、高效、开放的智能体互联网，在这个网络中，所有的智能体都将不受大型互联网平台的限制，相互之间都可以进行通信与协作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;MCP 关注的是模型如何连接到工具和资源，A2A 解决的问题是智能体如何在企业内部进行连接与协作，ANP 解决的问题是智能体在互联网上如何进行连接与协作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;除此之外，还有其他一些协议，比如 Cisco 旗下的 AGNTCY 社区主导的 Agent Connect Protocol，IBM Research 主导的 Agent Communication Protocol，以及一些研究机构的项目比如 agora protocol，他们都有不同的技术路线。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我这里有几篇智能体协议相关的 paper： &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/abs/2504.16736 &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/pdf/2505.07176v1 &lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;https://arxiv.org/pdf/2505.02279v1&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What are the issues with them and why do we need this version?（它们存在哪些问题？为什么我们需要这个版本？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实我们在 2024 年 4 月就启动了 ANP 这个开源项目，那个时候还没有 MCP，也没有 A2A。我们是最早一批真正从"智能体协作"角度出发，来思考协议应该怎么设计的团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;当时我们就有一个很强的直觉：协议会是智能体之间协作的关键基础设施。于是我们去研究了很多现有协议，包括 HTTP/HTML，发现它们本质上都是为"人-网页"交互设计的，不适用于"智能体-智能体"的通信。比如说：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;两个智能体怎么发现彼此？&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;如何互相认证身份、交换数据？&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;通信过程中如何保证安全性和隐私？&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;现有的协议在这些方面几乎是空白的。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;带着这些问题，我们设计了 ANP。它从一开始就关注智能体之间的身份认证问题，我们希望任何两个智能体，不管是谁开发的，来自哪家公司，都能通过标准协议完成安全的双向身份认证。这一点，其实是我们和 MCP、A2A 最大的差异之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们常常用"email 模式"来比喻 ANP 的身份体系：只要你有一个"智能体地址"，你就能跟全世界的智能体建立联系。这跟 MCP、 A2A 那种比较中心化方式不太一样，我认为 MCP 和 A2A 其实并没有很好的解决智能体的身份问题，特别是智能体在互联网上的身份问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在架构层面上，ANP 和 MCP 也有很大的区别。MCP 是典型的客户端-服务器架构（Client-Server），也就是说智能体要主动连接服务端，服务端是不能主动发起连接的。它更像一种"单向调用"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;&lt;span&gt;而 ANP 是一个真正的点对点架构（&lt;/span&gt;&lt;span&gt;Peer-to-Peer&lt;/span&gt;&lt;span&gt;），任何两个智能体之间都可以对等地通信、交互。这种设计更符合未来智能体之间频繁互动、协同执行任务的需求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;至于和 A2A 的差异，我们认为最重要的一点是：A2A 是基于任务传递的协作机制。一个智能体把一个"任务包"交给另一个智能体去执行。这种模式在企业内部还好，但放到开放的互联网环境中就会遇到隐私和权限的问题。比如说，我想订酒店，用 A2A 的方式，我可能要在任务中告诉对方智能体我喜欢什么、不喜欢什么，这种个人偏好数据一旦传出去，就存在泄露的风险。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;而 ANP 在设计之初就考虑了"智能体在互联网中协作"这一复杂现实场景，ANP 采用的是一种 Linked-data 的方案，可以将智能体对外公开信息编织成一个数据网络，一个智能体可以像爬虫一样将另外一个智能体的信息爬取下来，然后在本地进行分析与决策，从而避免用户的隐私泄漏。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;总体来说，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;ANP 是一个非常有创造力、非常独特的尝试，它不是对现有协议的小修小补，而是从底层重新出发，真正为"智能体互联网"准备的协议。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：How important is it that we have protocols developed outside of big tech companies?（由大科技公司之外的组织制定协议有多重要？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是一个非常关键的问题。我们现在看到的很多 AI 协议，确实是由大型科技公司提出的，比如 Anthropic、Google 这些企业，他们推动了 MCP、A2A 等协议的发展，也让更多的人看到协议对智能体的价值。但我们也需要看到，这些协议的设计，很多时候是基于他们自己的产品路径和商业利益出发的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这本身没有错——商业公司有自己的考量和节奏。但问题是，如果整个智能体互联网的底层协议都由几家公司来主导，那我们可能会再次走上"平台封闭化"的老路。就像今天的社交平台、应用商店、广告系统，数据和权限越来越集中在少数大公司手里。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们不希望"智能体互联网"成为另一个"数据孤岛联盟"。如果我们真的相信 AI 是一项改变人类社会的重要技术，那就更需要有一个开放、中立的社区来推动协议的设计，确保它的未来是属于每个人的，而不是某几家公司的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这也是我们发起 ANP 开源社区的初衷，我们有自己的理念，我们希望自己的理念能够实现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 社区非常特别，它不是一个传统意义上的商业团队，它完全是一个不追求盈利的非商业化组织。我们来自各个方向——有极客、有创业者、有学者，大部分都是对未来充满热情的理想主义者。大家聚在一起，是因为共同相信：AI 不应该被垄断，它的连接能力、协作能力，应该像空气和水一样，向所有人开放。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;同时我们也意识到，光靠一个社区的努力是不够的，还需要在全球范围内推动标准化的共识与合作。这也是为什么我们牵头在 W3C 发起了 "AI Agent Protocol" 社区组（Community Group）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;W3C 一直是互联网协议发展的重要推动者，从 HTTP 到 HTML，它见证并塑造了多个开放技术的诞生。它是一个中立、开放、面向全球的标准化组织，不属于任何一家公司，也不服务于某个商业利益集团。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们相信，在 W3C 这样的国际平台上推动 Agent 协议的讨论，有助于吸引全球更多开发者、研究者、公司和组织共同参与，真正形成一个开放、协作、可信的技术生态。这也与我们在 ANP 社区里的初心是一致的：协议不应该属于某家公司，它应该属于整个智能体社会。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What do you hope the protocol will provide?（你希望这个协议能带来什么？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个问题其实也是我们做这个协议的初衷。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们一直坚信一个非常古老但至今依然重要的互联网信条：连接即权力（Connection is Power）。只要一个人能够自由地连接到工具、连接到他人、连接到信息，他就具备改变世界的能力。这就是互联网最初带给我们的力量——让一个普通人也能撬动整个系统。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但我们也看到，过去十几年里，互联网的"开放性"正在逐步丧失。越来越多的服务、数据、用户，被锁定在几个大型平台的生态里。协议的边界被平台所取代，数据也变成了"平台资产"而不是"网络资源"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;我们不希望智能体时代重复这一切。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;ANP 想要实现的，是让未来的智能体互联网，从以平台为中心的封闭生态，回归到"以协议为中心"的开放连接。它不依赖某个平台，不绑定某个技术栈，只要你遵循这个协议，无论你是谁、你在哪、你由谁开发，你的智能体都能被识别、被发现、被调用，真正融入这个网络。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;在这样的网络里，智能体不仅是信息的接收者，还是服务的提供者；不是被平台分发的"插件"，而是彼此对等的节点，可以自由协作、交易、共享能力。这意味着任何一个开发者，只要有想法和能力，就可以进入这个生态，而不必依赖大公司赋权。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;这也是我们特别在意"非封闭、非垄断"的原因。我们希望 AI 技术的红利能够真正普惠全球，而不是被少数平台控制。我们也相信，一个真正开放的智能体互联网，会比封闭平台更有活力，会诞生出更多天马行空的创意与合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;所以，如果你问我，我们希望 ANP 这个协议带来什么？&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;那就是：让智能体的连接权利回到每一个人手里，让互联网重新成为创造力的土壤，而不是流量的围墙。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What's the next step? Will the W3C choose a "winner"? How long does this process usually take?（下一步是什么？W3C 会选出一个"胜出者"吗？这个过程通常需要多久？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：感谢这个很好的问题。如果您指的是我们在 W3C 的下一步工作，我需要坦诚地说，我们之前主要关注 W3C 相关的技术标准，但并没有深度参与到标准制定的具体流程中。因此，对于标准制定的周期以及一些未知问题的解决时间，我们目前还不能给出确切的判断。但我们希望能在 W3C 这个平台上全力推进标准的制定和行业共识的形成。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;关于"胜出者"这个话题，我想澄清一点：W3C 是一个致力于制定开放标准（Royalty-free）的组织，标准的制定是建立在整个行业共识基础上的。我们选择来到这里，正是看重这一点。我们的目标是做好一个智能体交互的协议标准，我们希望听取更多意见来打磨一个优秀的行业协议，并不希望也不打算与谁竞争。实际上，在我们创立社区组之初，W3C 智能体相关的工作组已经发出了联络邀请，希望共同协作，这也正是我们期望看到的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：You are both proposing the protocol and serving as the group chair—doesn't that pose a conflict of interest? （你本人既提出协议，又担任小组主席，这是否存在利益冲突？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是一个很重要的问题。首先，我想强调 ANP 社区是一个开放中立、非盈利性的社区， ANP 协议，本身是完全开源的，我们非常愿意与其他协议项目共同探索，最终落地成为一个具有行业共识的标准协议。从我们开始探索协议设计之初，我们就希望能够听取最广泛的意见。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;担任小组主席的角色与我们 ANP 以及 W3C 的愿景是完全一致的。我们希望汇聚来自不同行业、不同国家的声音，共同推进一个适合全人类的、具有共识基础的标准。从这个角度看，不仅不存在利益冲突，更准确地说，我们实际上并没有什么商业利益考量——无论是 W3C 社区组还是 ANP 都是如此。如果非要说有什么"利益"的话，那就是我们希望实现 Agentic Web 这一技术愿景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;W3C 有着"Web for All"的愿景，我们也愿意在这一愿景基础上推进 Agentic Web 的实现，所以这些目标之间并不冲突，而是相互促进的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：What happens if the big tech companies ultimately decide to adopt their own protocols? （如果大型科技公司最终决定采用自己的协议，会发生什么？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果大型科技公司愿意采用我们的协议，那当然是非常好的结果。我们对自己的协议方案很有信心，相信它能够解决他们在智能体互联和协作方面遇到的关键问题。我们也非常愿意配合大公司来推进协议的实际落地应用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;当然，我们更欢迎大公司能够参与到我们协议的制定和优化过程中来。我们是开源开放的，我们的最终目的是实现 Agentic Web 这一愿景，而不是推广某一份特定的协议或标准。如果通过开放合作能够产生更好的解决方案，我们完全支持这样的结果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;归根结底，我们关注的是整个智能体生态的健康发展，而不是某个特定协议的"胜负"。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;New Scientist：Can we provide some examples of successful or failed standardization efforts led by the W3C in recent years? （我们能否提供一些近年来 W3C 推行标准时成功或失败的案例？）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;strong&gt;&lt;span&gt;常高伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：正如我在第一个问题中提到的，这是我第一次深度参与 W3C 的标准制定工作，这个问题可能需要站在 W3C 工作人员的角度来回答，我很难给出权威的答案。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;但从我个人的理解来看：正如我们选择 W3C 的原因一样，这里是一个开放的标准组织。如果某个领域存在真实需求，自然会有相关的群体来制定或推进相应的标准。所以在我的概念里，这个过程不存在简单的"成功"或"失败"。如果一份标准被某个社群制定出来，那这份标准对他们来说就是有意义和价值的；如果一份标准后来被其他标准所替代，这说明技术的变革和迭代在发生，而这本身就是技术发展中一直在发生的自然过程。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span&gt;重要的是保持开放的心态，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;让最好的技术方案在公开、透明的环境中得到充分讨论和验证。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18685716</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18685716</guid>
      <pubDate>Thu, 17 Jul 2025 04:38:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
