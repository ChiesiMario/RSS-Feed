<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 03 Jul 2025 07:48:56 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>腾讯提醒开发者可将微信小程序迁移至 QQ 客户端</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯 QQ 小程序开发者平台发文，提醒 QQ 客户端将全面接入微信小程序，&lt;strong&gt;开发者可以将微信小程序迁移至 QQ 以取代原有的旧版 QQ 小程序&lt;/strong&gt;，开发者当前已上线的旧版 QQ 小程序仍可正常使用和更新，不过官方称「强烈建议尽早迁移，以便获得更完整的接口支持，同时享受 QQ + 微信的双端流量红利」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e508f98702091d79c43aa333caf718d83a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;迁移前，QQ 小程序引擎实际上对微信小程序的大多数接口进行了兼容，原本只需要在微信小程序原有代码基础上做一些简单判断（主要是登录方面）就可以分别提交两个平台。&lt;/p&gt; 
&lt;p&gt;而在迁移后，QQ 端运行的就是微信小程序，体验比 QQ 小程序会好一些。开发者需要通过 QQ 提供的插件（qq-wxmini-plugin）区分运行环境、处理登录逻辑。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;来源：https://m.ithome.com/html/864991.htm&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346915" target="news"&gt;手机版 QQ 支持微信小程序&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358586</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358586</guid>
      <pubDate>Thu, 03 Jul 2025 07:39:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>多模态才是智能应用爆发的关键？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;此前，快手发布 2025 年一季度财报时，一个数字引发关注：成立仅两年的 AI 业务线「可灵 AI」单季度贡献营收 1.5 亿元，同比增长 320%。而可灵 AI 正是一个多模态应用的典型产品，涉及到语言、视频、音频等交互。&lt;/p&gt; 
&lt;p&gt;前不久，在 OSCHINA 和小度教育技术负责人丁小晶的&lt;a href="https://my.oschina.net/u/4489239/blog/18426743" rel="nofollow"&gt;对话&lt;/a&gt;中。丁小晶表示，多模态技术非常重要，甚至可以说，没有多模态技术效果的快速提升，教育行业不可能如此迅猛发展。比如 AI 作业批改和 AI 讲题答疑方向的应用，完全靠纯文本大模型是无法满足需求的，非常依赖对大模型的图片理解能力。还比如超拟人 AI 老师，语音情感大模型就起来非常关键的作用。&lt;/p&gt; 
&lt;p&gt;百度最新发布的发布文心快码 Comate AI IDE 产品，其中也提到了多模态能力的增强，比如支持 Figma 设计稿一键转换为高可用代码，能实现图层的精准还原。百度工程效能部前端研发经理杨经纬告诉开源中国，无论是从自然语言、图片还是设计稿生成代码，最终都是为了能更加接近人类工程的意图，因为人类去描述自己想要实现的想法的方式与形态是多种多样的，也就对应了研发过程中的多模态形式。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="210" src="https://oscimg.oschina.net/oscnet/up-db06f16dbd4e854566d762bff8c3dfe1e5f.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;人类从不会只用一种感官认知世界。人工智能也势必不能仅有一种交互途径。&lt;/p&gt; 
&lt;p&gt;我们闻到咖啡香气的瞬间，脑海里会立刻浮现深褐色液体与白瓷杯的画面；听到「猫」这个词时，脑海中自动补全毛茸茸的触感和呼噜声。这种多模态信息融合，正是人类智能的底层逻辑。而单一模态交换的 AI 模型的信息处理能力有限，例如文本生成模型难以理解图像语义，无法根据文字生成图像，视频生成工具则无法同步解析声音与画面逻辑。这种时候，就需要多模态模型或是能力的配合。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;多模态，比文本慢一步&lt;/h2&gt; 
&lt;p&gt;智源研究院院长王仲远不久前公开&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.cn%2Fzh-cn%2F%25E6%258A%2580%25E6%259C%25AF%2F%25E6%258A%2580%25E6%259C%25AF%25E5%2585%25AC%25E5%258F%25B8%2F%25E8%2581%259A%25E7%2584%25A6%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581-chatgpt%25E6%2597%25B6%25E5%2588%25BB%25E6%259C%25AA%25E5%2588%25B0-2025%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B-%25E5%258F%2598%25E6%2585%25A2-%25E4%25BA%2586%25E5%2590%2597%2Far-AA1GjaHk%3Focid%3DBingNewsSerp" rel="nofollow" target="_blank"&gt;指出&lt;/a&gt;，当前多模态大模型的学习路径，尤其是多模态理解模型，通常是先将语言模型训练到很强的程度，再学习其他模态信息。在这个过程中，模型的能力可能会出现下降。&lt;/p&gt; 
&lt;p&gt;比单一模态更难的是，多模态模型还需解决一个核心问题：如何将图像、文本、音频等异构数据在语义层面对齐并融合。&lt;/p&gt; 
&lt;p&gt;文本、图像、声音等模态的数据结构天然异构——文本是离散符号序列，图像是连续像素矩阵，音频是时间序列信号。比如要让模型理解「猫」的文本描述与猫的图片、叫声之间的关联，需构建跨模态的共享语义空间。&lt;/p&gt; 
&lt;p&gt;早期，有研究尝试通过数据级拼接，将图像像素和文本特征直接拼接，实现跨模态融合，但由于图像和文本的时空特性差异较大，导致特征对齐困难，最终效果不佳。直到对比学习和注意力机制的出现，才实现跨模态语义映射。比如 OpenAI 2021 年推出的一种基于对比学习只的多模态预训练模型 CLIP，它通过大规模的图像和文本数据进行训练，使得模型能够理解图像内容和相关文本之间的语义关系。CLIP 的核心贡献在于它打破了传统的固定类别标签范式，通过对比学习的方式，将图像和文本映射到同一个向量空间中，从而实现跨模态的检索和分类。但是 CLIP 模型的训练数据规模庞大，据 OpenAI 披露，其使用了约 4 亿图像-文本对进行训练，训练成本高达数千 GPU 日，远超 GPT-3 等纯文本模型。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-4ad6b286433edebde043654fd53af191e30.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;CLIP 模型方法概述 &lt;/em&gt;&lt;/span&gt;&lt;span style="color:#8f959e"&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2103.00020" rel="nofollow" target="_blank"&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多模态融合需处理高维数据，如 4K 视频的像素量是文本的百万倍，传统 Transformer 的二次方计算复杂度成为致命短板。对此，业界也有一些解决方式，比如此前 Mamba 架构通过状态空间模型 SSM 将计算复杂度降至线性，2025 年扩展动态融合模块&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F2985554863" rel="nofollow" target="_blank"&gt; FusionMamba&lt;/a&gt;，在其中实现多模态特征高效交互，推理速度提升 3 倍。&lt;/p&gt; 
&lt;p&gt;不仅如此，相较于文本的资料库和数据集，高质量多模态数据集也更加稀缺，收集难度更大。比如医疗影像、工业质检的报告中的缺陷描述等，就需专家级别的标注人员。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;落地需求更多&lt;/h2&gt; 
&lt;p&gt;虽然技术上还有诸多难点，但是多模态能力正在逐步提升，并且带来非常可观的价值和效果。&lt;/p&gt; 
&lt;p&gt;比如，从图片或者是 Figma 设计稿直接生成代码可以帮助许多开发者或是产品经理完成一些开发工作。这项能力此前在一些低代码或是辅助编程工具中也存在，但往往是通过 Figma DSL 进行设计稿解析，通过节点虚拟化技术实现像素级还原，其不足在于不一定适配当前项目，比如转了一套 Vue 框架的代码，就无法在 React 框架项目中使用。&lt;/p&gt; 
&lt;p&gt;杨经纬介绍，此次文心快码 Comate AI IDE 的发布以及相关功能更新后，通过大模型能力增强了 Figma to Code 和当前项目的融合度。首先在 IDE 里进行操作，天然就可以理解用户当前环境和本地优势，而 IDE 内智能体 Zulu 的接入，会更深入到本地项目中了解当前的框架、能力、代码风格等，再结合 Image to Code 的能力，可以实现较高的还原度，并且适配当前的项目。&lt;/p&gt; 
&lt;p&gt;而根据一些公开信息显示，可灵 AI 的多模态技术，支持通过图片、文字、声音甚至手绘轨迹等输入生成视频。在上半年的 2.0 模型的迭代中，可灵 AI 也发布了 AI 视频生成的全新交互理念 Multi-modal Visual Language（MVL），让用户能够结合图像参考、视频片段等多模态信息，将脑海中包含身份、外观、风格、场景、动作、表情、运镜在内的多维度复杂创意，直接高效地传达给 AI。MVL 由 TXT（Pure Text，语义骨架）和 MMW（Multi-modal-document as a Word，多模态描述子）组成，能从视频生成设定的基础方向以及精细控制这两个层面。此外，其技术也结合了类 Sora 的 DiT 结构和 Flow 扩散模型，提升在物理模拟和细节上的表现。&lt;/p&gt; 
&lt;p&gt;基于这些技术特征。商业化层面，截至今年 6 月，可灵 AI 已为超过 1 万家企业客户提供 API 服务，覆盖广告营销、影视动画等领域，企业客户续费率较高。&lt;/p&gt; 
&lt;p&gt;此外，一些传统行业或场景也在结合多模态能力，实现与 AI 的加速融合。比如迪瑞医疗近期采用的多模态 AI 大模型算法技术为临床诊断带来了重要的技术革新，结合多种检测结果和患者的多维信息，如尿常规、血常规、生化和化学发光免疫，以及患者的个人背景、临床表现、现病史与既往病史等，进行全面分析。&lt;/p&gt; 
&lt;p&gt;这种跨学科的信息整合使得诊断提示更加精准，对于减少漏诊、误诊的概率具有显著的作用，并进一步提升了医疗诊疗的整体效率。大洋彼岸，斯坦福医学院的科研团队研发出了一种名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxMTM0OTQzNQ%3D%3D%26mid%3D2247486194%26idx%3D1%26sn%3D5ac605d67ca7019b3b2e524d65b0f88e%26chksm%3Dc0eed67e545679711993370e69032cc62e9d4fc0c6ff3e283c43854fd93355eae8a07b4fcb02%23rd" rel="nofollow" target="_blank"&gt; MUSK 的 AI 模型&lt;/a&gt;，将视觉数据，如病理图像和文本数据的病历和临床记录相结合，为癌症治疗带来了新的可能。MUSK 模型不仅提高了预测癌症患者预后和治疗反应的准确性，而且通过分析数千个数据点，更准确地确定了哪些疗法对个体患者最有效。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-196e0ee8b1058ba8ee70698e626a846fe72.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="background-color:#f2f3f5"&gt;&lt;em&gt;视觉问答测试，图片来源于网络&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在金融领域。江苏银行通过本地化部署微调 DeepSeek-VL2 多模态模型、轻量 DeepSeek-R1 推理模型，分别运用于智能合同质检和自动化估值对账场景中，通过对海量金融数据的挖掘与分析，重塑金融服务模式，实现金融语义理解准确率与业务效率双突破。具体而言，DeepSeek-VL2 多模态模型采用了最新的 Transformer 架构，结合多层次的特征融合机制，有效提升了金融合同、账单等复杂文本与图像信息的理解能力。模型在智能合同质检场景中表现出色，准确率较传统方法提升了 15% 以上，显著降低了人工审核成本。同时，轻量化的 DeepSeek-R1 推理模型则在自动化估值与对账场景中展现出极佳的实时响应能力，推理速度提升了 30%，为金融业务流程的自动化提供了坚实支撑。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;新的基础设施&lt;/h2&gt; 
&lt;p&gt;应用边界在不断拓宽的同时，多模态模型的能力也在成长。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而随着应用场景的深化，模型架构也在同步进化，从基础感知迈向复杂推理成为必然趋势。OpenAI 在 2025 年 4 月发布了多模态模型 O3 和 O4-mini，实现了「用图像思考」的突破性能力。这些模型不仅能够识别图像内容，还能将图像信息整合进推理思维链，支持多步推理和因果分析，比如够处理模糊、倒置或复杂的图像输入，并给出合理的推理结果。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;其背后的关键技术包括分层注意力机制，将图像分解为局部细节、全局关系和时序逻辑三层结构，从而提升对图像内容的理解能力；动态工具链调用，在推理过程中，模型可以自主选择 Python 分析、知识图谱检索、图像生成等工具辅助决策，以及安全约束模块，通过对抗训练减少模型的幻觉输出。&lt;/p&gt; 
&lt;p&gt;就在本月，中国科学院自动化研究所等单位的科研人员&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkw.beijing.gov.cn%2Fxwdt%2Fkcyx%2Fxwdtkjqy%2F202506%2Ft20250611_4111006.html" rel="nofollow" target="_blank"&gt;首次证实&lt;/a&gt;，多模态大语言模型在训练过程中自己学会了「理解」事物，而且这种理解方式和人类非常像。&lt;/p&gt; 
&lt;p&gt;科研人员借鉴人脑认知的原理，设计了一个巧妙的实验：让大模型和人类玩「找不同」游戏。实验人员会给出三个物品概念（选自 1854 种常见物品），要求选出最不搭的那个。通过分析高达 470 万次的判断数据，科研人员绘制出了大模型的「思维导图」——「概念地图」。通过实验证实多模态大模型具备类人「概念理解」能力。研究团队设计「找不同」游戏，基于 470 万次判断数据绘制大模型「概念地图」，提炼 66 个理解维度（如物体功能、文化意义），发现其与人脑神经活动高度一致，证明多模态模型比纯文本模型更接近人类思维模式。&lt;/p&gt; 
&lt;p&gt;据谷歌云在 2024 年年底发布的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.qq.com%2Frain%2Fa%2F20241219A07AW200" rel="nofollow" target="_blank"&gt;《2025 年人工智能商业趋势报告》&lt;/a&gt;，预测到 2025 年，多模态 AI 将成为企业采用 AI 的主要驱动力。这种技术通过整合图像、视频、音频和文本等多种数据源，使 AI 能够以前所未有的准确性从更广泛的上下文源中学习，提供更精确、定制化的输出，创造自然直观的体验。报告预计，全球多模态 AI 市场规模将在 2025 年达到 24 亿美元，到 2037 年底达到 989 亿美元。&lt;/p&gt; 
&lt;p&gt;2025 进度已经过半，我们也能看到市面上许多多模态技术和产品的进展，而这场变革的终极图景，或许正是让 AI 真正成为理解世界、服务人类的「多模态智能伙伴」。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18679654</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18679654</guid>
      <pubDate>Thu, 03 Jul 2025 07:32:20 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Windows 11 记事本正式支持 Markdown</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月底，预览体验计划中的 Windows 11 记事本迎来史诗级更新：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown"&gt;支持 Markdown 格式&lt;/a&gt;。现在普通用户也可以使用这个版本了，只需要在应用商店中更新记事本即可使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-af88d0da29ab2cf4246999e5b5025bf874c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前支持：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;粗体&lt;/li&gt; 
 &lt;li&gt;斜体&lt;/li&gt; 
 &lt;li&gt;链接&lt;/li&gt; 
 &lt;li&gt;序号&lt;/li&gt; 
 &lt;li&gt;标题（H1～H5）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如下面的屏幕截图所示，您可以点击新的「H1」图标，然后选择您喜欢的标题：标题、副标题、章节，甚至是小节。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-387e4d297dcd5ac663e49554b55e2f51091.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接下来，我们可以看到项目符号和数字列表按钮，以及用于加粗或应用斜体的选项，但最吸引我注意的是超链接支持。现在，您可以使用 Ctrl + K 键盘快捷键（该快捷键在 Word 中也使用）插入带有锚文本的链接，并在默认浏览器中打开。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79d07dc4e8307d47c79e780de309830f227.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，您可以点击屏幕底部的「格式化视图」按钮切换到 Markdown 语法（原始）视图。&lt;/p&gt; 
&lt;p&gt;与「格式」视图不同，语法视图允许您将井号转换为标题、使用星号强调、用反引号包裹代码等等。语法视图类似于在后端使用 Markdown 编辑器，但它不会更改输出。这取决于您在记事本中使用 Markdown 的方式。&lt;/p&gt; 
&lt;p&gt;在我们的测试中，Windows 最新版本观察到记事本默认启用 Markdown，但您有两个选择。您可以单击清理格式按钮，返回原始记事本体验，而无需禁用 Markdown 支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-78b526954a85441998f9ce8f508e77c65f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;或者，您可以打开「设置」，向下滚动一点，找到一个名为「格式化」的新选项。关闭「格式化」后，记事本的经典体验将恢复。您将不再看到格式化栏，Windows 也不会提示您使用它。&lt;/p&gt; 
&lt;p&gt;测试中，我们还注意到微软在记事本中实现了非常轻量级的 Markdown 功能，它不会让您的电脑运行速度变慢。&lt;/p&gt; 
&lt;p&gt;有些人可能会认为，给记事本添加太多功能违背了它作为纯文本编辑器的初衷。这种观点很有道理，但只要 Markdown 之类的功能是可选的，我并不介意。如果我需要它们，可以在「设置」中打开；如果不需要，也可以再次关闭。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown" target="news"&gt;Windows 记事本支持 Markdown&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358574/windows-11-notepad-markdown</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358574/windows-11-notepad-markdown</guid>
      <pubDate>Thu, 03 Jul 2025 07:10:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>抖音内容技术团队开源 ContentV：有限算力下高效训练视频生成模型的新路径</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//adfb650ff16d8feb12d600710037b8a4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div class="ckeditor-html5-video" style="text-align:center"&gt; 
  &lt;video controls="controls" controlslist="nodownload" src="https://www.bilibili.com/video/BV1jC3azYEaS/?spm_id_from=333.1387.upload.video_card.click&amp;amp;vd_source=c09f0713b2507369924e94f4fec6c133"&gt;
    &amp;nbsp; 
  &lt;/video&gt; 
 &lt;/div&gt; 
 &lt;div class="ckeditor-html5-video" style="text-align:center"&gt; 
  &lt;video controls="controls" controlslist="nodownload" src="https://www.bilibili.com/video/BV1jC3azYEuW/?spm_id_from=333.1387.upload.video_card.click&amp;amp;vd_source=c09f0713b2507369924e94f4fec6c133"&gt;
    &amp;nbsp; 
  &lt;/video&gt; 
 &lt;/div&gt; 抖音内容技术团队开源了 ContentV，一种面向视频生成任务的高效训练方案。该方案在多项技术优化的基础上，使用 256 块显卡，在约 4 周内完成了一个 8B 参数模型的训练。尽管资源有限，ContentV 在多个评估维度上取得了与现有主流方案相近的生成效果。该工作探索了在有限算力条件下训练视频生成模型的可行路径。目前，推理代码与模型权重已对外开放。 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;项目主页&lt;/strong&gt;：https://contentv.github.io&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;技术报告&lt;/strong&gt;：https://arxiv.org/abs/2506.05343&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代码仓库&lt;/strong&gt;：https://github.com/bytedance/ContentV&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型权重&lt;/strong&gt;：https://huggingface.co/ByteDance/ContentV-8B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;核心亮点&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;极简设计&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;CogVideoX、HunyuanVideo 和 Wan2.1 等一系列优秀的开源工作表明，视频生成的关键并不在于架构上的特殊设计，而在于如何高效利用有限的数据资源，并有效对齐人类偏好。&lt;/p&gt; 
&lt;p&gt;为验证 ContentV 方案的通用性，本次开源的版本在扩散模型部分采用了经典的文生图模型 Stable Diffusion 3.5 Large。为了适配视频模态，模型在结构上仅做了以下两项必要调整：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将原始图像 VAE 替换为 Wan2.1 中使用的 3D-VAE；&lt;/li&gt; 
 &lt;li&gt;将 2D 位置编码升级为 3D 版本。在具体编码方式上，团队对比了传统的绝对位置编码与主流的旋转位置编码。评估结果显示，两者在客观指标和主观感受上差异较小，因此保留了计算更高效的绝对位置编码方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a970cfacc9f335795a1cb051ba654811.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;ContentV 模型结构‌&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多阶段渐进训练策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上述的最小化结构改动，在解锁了视频生成能力的同时，也最大限度地保留了原模型的图像生成能力。实验证明，在新的 VAE 和位置编码的适配阶段，沿用 Flow Matching 的训练方式，仅需 1000 步左右的微调，就能基本还原模型的图片生成能力，大幅节省图片预训练阶段的训练成本。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//da7aab81f63561b7c0d8679eceba1022.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;VAE 适配过程‌&lt;/p&gt; 
&lt;p&gt;在视频生成的预训练阶段，为加速收敛实现高效训练，研究团队设计了一套从「低清短片」到「高清长片」的多阶段渐进式训练流程，逐步引导模型学习时间维度与空间维度上的动态表征，从而提升视频的连续性、动态表现力和画面细节。&lt;/p&gt; 
&lt;p&gt;此外，实验证明，在推理阶段引入非线性采样步长机制（Flow Shift）能够显著提升视频的整体生成质量。通过多组对比实验，团队最终确定了最优的采样策略，进一步优化了生成效果。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;轻量级 RLHF 强化训练&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//25bf5c0471707e1d93343f8649c7f46a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//aaf7366e824c8a20dc80a43af6d4e872.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;RLHF 显著提升画面质感‌&lt;/p&gt; 
&lt;p&gt;在后训练阶段，除了使用高质量数据集进行微调外，通过 RLHF 或 DPO 等对齐人类偏好的监督训练，也能显著提升视频生成质量。然而，这类方法通常依赖大量人工标注，用于训练奖励模型或直接监督扩散模型。同时，相较于图像，视频的序列长度显著增加了 RLHF 和 DPO 的训练资源需求。&lt;/p&gt; 
&lt;p&gt;为此，ContentV 研究团队提出了一种轻量级的 RLHF 训练方案，旨在不依赖人工标注的前提下，低成本提升视频质量：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;利用开源的图像奖励模型对生成视频的单帧进行监督。相较于视频场景，目前图像奖励模型的训练数据更易获取，且在实际效果中表现更佳。实验证明，由于 MM DiT 采用全局注意力机制，仅优化单帧即可带动整体视频质量的提升；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将监督范围限制在生成视频的前 1 秒，相较于对完整视频进行监督，可大幅减少训练资源的消耗，同时获得相近的质量提升效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;采用上述策略后，在无需人工标注的情况下，仅使用少量训练资源，便可显著提升画面质量。RLHF 微调后，模型在视觉质量（VQ）指标上的表现大幅提升，评估胜率高达 89.38%。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;效果对比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 VBench 这一主流视频生成评测基准上，ContentV（8B）取得了 85.14 的综合得分，表现优于多个现有的商业闭源模型，包括 Sora、Kling 1.6 和 Gen-3 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e5d2e9c6fb2a651ef95db56aa008420.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;VBench 榜单 (按照 Overall 分数降序排列)‌&lt;/p&gt; 
&lt;p&gt;为更贴近真实用户偏好，研究团队围绕感知质量、指令跟随、物理一致性和视觉效果四个维度开展了人类偏好评估。结果显示，ContentV 在整体表现上与 CogVideoX-5B、HunyuanVideo-13B 和 Wan2.1-14B 等主流开源模型相比具有一定优势。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//547c06ccbfa684f90c21d1432e0c6786.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;人类偏好评估指标‌&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6210722/blog/18683305</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/18683305</guid>
      <pubDate>Thu, 03 Jul 2025 06:53:20 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Bilibili 开源动漫视频生成模型 AniSora V3 版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Bilibili（B 站）宣布其开源动漫视频生成模型&lt;strong&gt;AniSora&lt;/strong&gt;迎来重大更新，正式发布&lt;strong&gt;AniSora V3&lt;/strong&gt;。作为 Index-AniSora 项目的一部分，V3 版本在原有基础上进一步优化了生成质量、动作流畅度和风格多样性，为动漫、漫画及 VTuber 内容创作者提供了更强大的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="292" src="https://oscimg.oschina.net/oscnet/up-27ad0a0400878a1e24e9451fd20c7a87882.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AniSora V3 基于 Bilibili 此前开源的 CogVideoX-5B 和 Wan2.1-14B 模型，结合&lt;strong&gt;强化学习与人类反馈（RLHF）&lt;/strong&gt;框架，显著提升了生成视频的视觉质量和动作一致性。其支持一键生成多种风格的动漫视频镜头，包括番剧片段、国创动画、漫画视频改编、VTuber 内容）等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心升级包括：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;时空掩码模块（Spatiotemporal Mask Module）优化&lt;/strong&gt;：V3 版本增强了时空控制能力，支持更复杂的动画任务，如精细的角色表情控制、动态镜头移动和局部图像引导生成。例如，提示「五位女孩在镜头放大时起舞，左手上举至头顶再下放至膝盖」能生成流畅的舞蹈动画，镜头与角色动作同步自然。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据集扩展&lt;/strong&gt;：V3 继续依托超过 1000 万高质量动漫视频片段（从 100 万原始视频中提取）进行训练，新增数据清洗流水线，确保生成内容的风格一致性和细节丰富度。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;硬件优化&lt;/strong&gt;：V3 新增对华为 Ascend910B NPU 的原生支持，完全基于国产芯片训练，推理速度提升约 20%，生成 4 秒高清视频仅需 2-3 分钟。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;多任务学习&lt;/strong&gt;：V3 强化了多任务处理能力，支持从单帧图像生成视频、关键帧插值到唇部同步等功能，特别适合漫画改编和 VTuber 内容创作。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在最新基准测试中，AniSora V3 在&lt;strong&gt;VBench&lt;/strong&gt;和双盲主观测试中，角色一致性和动作流畅度均达到业界顶尖水平（SOTA），尤其在复杂动作 (如违反物理规律的夸张动漫动作) 上表现突出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Bilibili 强调，AniSora 是「对动漫世界的开源礼物」，鼓励社区协作优化模型。用户需填写申请表并发送至指定邮箱（如 yangsiqian@bilibili.com）以获取 V2.0 权重和完整数据集访问权限。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;V3 还引入了首个针对动漫视频生成的&lt;strong&gt;RLHF 框架&lt;/strong&gt;，通过 AnimeReward 和 GAPO 等工具对模型进行微调，确保输出更符合人类审美和动漫风格需求。社区开发者已开始基于 V3 开发定制化插件，例如增强特定动漫风格（如吉卜力风）的生成效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AniSora V3 支持多种动漫风格，包括日本动漫、国产原创动画、漫画改编、VTuber 内容及恶搞动画（鬼畜动画），覆盖 90% 的动漫视频应用场景。 具体应用包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;单图转视频&lt;/strong&gt;：用户上传一张高质量动漫图像，配合文本提示（如「角色在向前行驶的车中挥手，头发随风摆动」），即可生成动态视频，保持角色细节和风格一致。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;漫画改编&lt;/strong&gt;：从漫画帧生成带唇部同步和动作的动画，适合快速制作预告片或短篇动画。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;VTuber 与游戏&lt;/strong&gt;：支持实时生成角色动画，助力独立创作者和游戏开发者快速测试角色动作。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;高分辨率输出&lt;/strong&gt;：生成视频支持高达 1080p，确保在社交媒体、流媒体平台上的专业呈现。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AIbase 测试显示，V3 在生成复杂场景（如多角色交互、动态背景）时，相比 V2 减少了约 15% 的伪影问题，生成时间缩短至平均 2.5 分钟 (4 秒视频)。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;相比 OpenAI 的 Sora 或 Kling 等通用视频生成模型，AniSora V3 专注于动漫领域。 与字节跳动的 EX-4D 相比，AniSora V3 更专注于 2D/2.5D 动漫风格，而非 4D 多视角生成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358565</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358565</guid>
      <pubDate>Thu, 03 Jul 2025 06:47:20 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智谱 AI 开源通用视觉推理模型 GLM-4.1V-Thinking</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智谱 AI 于 7 月 2 日发布了 GLM-4.1V-Thinking 系列通用视觉推理模型，并宣布获得来自浦东创投集团和张江集团的 10 亿元联合战略投资。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/143332_18Al_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，公司推出了全新生态平台「Agent 应用空间」，并启动「Agents 开拓者计划」，投入数亿资金扶持 AI Agents 创业团队。&lt;/p&gt; 
&lt;p&gt;为庆祝模型发布，智谱大模型开放平台为用户提供新模型 Flash 版 1 亿的「高并发版」Tokens，同时，该模型可通过 API 免费使用。&lt;/p&gt; 
&lt;p&gt;此次率先开源的是 GLM-4.1V-9B-Thinking，一个 9B 参数量的多模态模型，对应官方平台的 GLM-4.1V-Thinking-Flash。该模型旨在提升模型的深度思考与复杂推理能力。该模型在多项基准测试中表现卓越，其性能在 18 项任务上持平甚至超过了参数量为其 8 倍的 Qwen-2.5-VL-72B 和 GPT-4o 等主流视觉语言模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/143242_aYUB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模型具备强大的多模态能力，能够解析长达 2 小时的视频、进行数学与科学推理、看图编写网页，并具备 GUI Agent 能力，可识别并操作手机、电脑等屏幕界面元素，完成用户指令。例如，在解析足球比赛时，模型能理解球员位置和战术特点。&lt;/p&gt; 
&lt;p&gt;GLM-4.1V-Thinking 模型架构由视觉编码器、MLP 适配器和语言解码器组成，其卓越性能得益于引入了「课程采样强化学习」（Reinforcement Learning with Curriculum Sampling）策略，通过由易到难的训练任务安排，高效提升了模型在 STEM 解题、智能体任务、文档图表理解等多个领域的推理能力。&lt;/p&gt; 
&lt;p&gt;目前，GLM-4.1V-9B-Thinking 模型已在 GitHub、魔搭社区及 Hugging Face 上开源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开源列表&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbigmodel.cn%2Fdev%2Fhowuse%2Fvisual-reasoning-model%2Fglm-4.1v-thinking" target="_blank"&gt;https://bigmodel.cn/dev/howuse/visual-reasoning-model/glm-4.1v-thinking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Github：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTHUDM%2FGLM-4.1V-Thinking" target="_blank"&gt;https://github.com/THUDM/GLM-4.1V-Thinking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ModelScope：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fcollections%2FGLM-41V-35d24b6def9f49" target="_blank"&gt;https://modelscope.cn/collections/GLM-41V-35d24b6def9f49&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2FTHUDM%2Fglm-41v-thinking-6862bbfc44593a8601c2578d" target="_blank"&gt;https://huggingface.co/collections/THUDM/glm-41v-thinking-6862bbfc44593a8601c2578d&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HuggingFace 体验链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FTHUDM%2FGLM-4.1V-9B-Thinking-Demo" target="_blank"&gt;https://huggingface.co/spaces/THUDM/GLM-4.1V-9B-Thinking-Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358562/glm-4-1-v-thinking</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358562/glm-4-1-v-thinking</guid>
      <pubDate>Sun, 11 May 2025 06:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源中国联合发起「全球数字友好开源社区」，共建开放协同新生态</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 2 日，2025 全球数字经济大会在北京国家会议中心隆重开幕。本次大会经国务院批准，由北京市人民政府、国家互联网信息办公室、国家数据局、新华通讯社与联合国开发计划署共同主办，聚焦「建设数字友好城市」主题，来自全球多国政府机构、国际组织、城市代表、科研院所和科技企业代表齐聚一堂，围绕数字技术赋能城市发展的路径与合作机制深入交流。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120249_MSqc_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在大会首场主论坛「数字友好城市建对话」阶段，&lt;strong&gt;北京市经开区工委副书记、管委会副主任王磊指出北京正在加快打造以「模力方舟国际开源社区」为代表的 AI 开放创新平台集群&lt;/strong&gt;，汇聚全球 AI 开发者资源，支撑企业间协同与城市间互信，推动开源力量深度融入全球数字治理体系。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120301_ICF0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;随后，主论坛迎来了重点环节之一——&lt;strong&gt;「全球数字友好开源社区」正式启动&lt;/strong&gt;。该社区由开源中国、统信软件、平凯星辰等十八家中外企业、联盟和机构共同发起，旨在打造面向全球的数字化开放协同平台。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开源中国作为发起单位之一，研发副总裁李彦成代表公司出席启动仪式，并与各方共同见证社区成立&lt;/strong&gt;。开源社区已成为推动全球数字协作与技术创新的重要力量。从早期由开发者驱动的协作模式，到如今以城市、企业、场景多元联动为特征的深度共建，开源正在加速融入数字城市治理的底层逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120314_bEZv_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开源已成为推动全球数字协作与技术创新的重要力量。从早期由开发者社区推动的技术共享，到如今以城市、企业、场景多元联动为特征的深度协作，开源的发展路径正不断拓展边界。在联合国「数字促进可持续发展」倡议框架下，「全球数字友好开源社区」应运而生，标志着开源协作正在进入以城市友好关系为纽带、以产业联合体为主体的新阶段。&lt;/p&gt; 
&lt;p&gt;作为国家重点开源基础设施平台之一，开源中国·Gitee 始终致力于建设安全、自主、可控的开源生态。&lt;strong&gt;此次参与社区联合发起，是开源中国积极服务国家数字战略、深度参与国际开源共建进程的重要举措&lt;/strong&gt;。依托自身在开源治理、企业级协同平台、人工智能服务平台等方向的长期积累，开源中国将与生态伙伴一道，共同推动开源协作从「项目共建」走向「城市共建」，为打造全球数字友好生态注入持续动能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120331_bONF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在数字技术高速演进、人工智能重塑产业格局的时代背景下，构建开放、包容、可持续的全球协作机制显得尤为重要。开源中国将继续秉持开放精神，深度参与社区建设，携手全球伙伴共建共享，为推动构建人类数字命运共同体贡献更多开源力量。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358536</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358536</guid>
      <pubDate>Sun, 11 May 2025 04:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克旗下人工智能公司 xAI 完成 100 亿美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;马斯克旗下人工智能公司 xAI 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F07%2F01%2Felon-musk-xai-raises-10-billion-in-debt-and-equity.html" target="_blank"&gt;完成了 100 亿美元融资&lt;/a&gt;，其中包括 50 亿美元债务融资和 50 亿美元战略股权投资。这笔资金将用于开发 AI 解决方案、建设数据中心，并推动其旗舰 AI 助手 Grok 的进一步发展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/114408_7iP8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除已完成的融资外，xAI 仍在洽谈约 200 亿美元的股权融资。若成功，其估值可能飙升至 1200 亿至 2000 亿美元，成为全球最具价值的 AI 公司之一。&lt;/p&gt; 
&lt;p&gt;然而，知情人士透露，xAI 的运营成本极高——2025 年预计将消耗 130 亿美元，相当于每月烧钱超 10 亿美元。目前的大规模融资仅能勉强跟上其巨额开支，未来仍需持续输血以维持技术研发和市场扩张。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358529/elon-musk-xai-raises-10-billion-in-debt-and-equity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358529/elon-musk-xai-raises-10-billion-in-debt-and-equity</guid>
      <pubDate>Sun, 11 May 2025 03:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>搜索数据建设系列之数据架构重构</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;主要概述百度搜索业务数据建设的创新实践，重点围绕宽表模型设计、计算引擎优化和新一代业务服务交付模式（图灵 3.0 开发模式）三大方向，解决了传统数仓在搜索场景下面临的诸多挑战，实现了搜索数据建设的高效、稳定、低成本；为百度搜索业务敏捷迭代奠定夯实基础。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;strong&gt;名词解释&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDS（Turing Data Studio）&lt;/strong&gt;&lt;/strong&gt;： 是基于图灵（百度内部数据分析平台）的数据建设解决方案，提供，数据开发、数仓管理、监控运维、资源管理等一站式服务的数据开发平台。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26chksm%3Dc03f75e8f748fcfe192c0c8817ceee53c0e1f57dcbafd16e22ee371889f4dbf9e0b813b700fa%26token%3D1515601853%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度 MEG 数据开发治理平台-TDS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDA（Turing Data Analysis）&lt;/strong&gt;&lt;/strong&gt;：是一款可视化 BI 产品，旨在帮助用户轻松上手及使用，进行拖拽式可视化数据分析及仪表盘建设。产品模块包括仪表盘、数据集、可视化分析及智能分析模块。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26chksm%3Dc03fbc10f7483506eb7206b02265f9010ddfa434359d7fa975a32d54c1b4886e734051ff9067%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度一站式数据自助分析平台（TDA）建设&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDE（Turing Data Engine ）&lt;/strong&gt;&lt;/strong&gt;：是基于图灵生态的计算引擎，包含 Spark 计算引擎和 ClickHouse。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;揭秘百度数仓融合计算引擎&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26chksm%3Dc03f7c9ef748f5886cc17147d8dfc8bd62ce062de822444ec592914d5ca6e0ab224cfc963e3e%26token%3D286675411%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 在百度 MEG 数据中台的落地和优化&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;UPI（Udw-API）&lt;/strong&gt;&lt;/strong&gt;：百度内部编程访问接口；以 Map/Reduce 计算框架为主，适用于计算逻辑复杂，以及多种数据源混合计算的例行离线数据挖掘业务&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;：是百度自主研发，基于 spark 自研的 adhoc 服务。提供数据查询分析，具有简单易用、超大规模支持、成本极低等特点，能实现 T 级数据秒级查询，也适用于例行生产的 ETL 场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;函谷&lt;/strong&gt;&lt;/strong&gt;：图灵核心模块，作为图灵查询的 gateway，完成图灵查询的接收、分发、提交执行、查询进展轮询、结果获取等一系列功能。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景与问题&lt;/h1&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 背景&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在当今互联网产品发展日新月异、业务迭代迅猛的时代；跨业务分析的需求日益增长，这种变化既为企业创造了敏捷决策、精准运营的新机遇，也带来数据割裂、价值释放滞后等严峻挑战。特别是大型互联网企业，往往构建有复杂的多业务、多模块、多线条体系，每日持续产出海量的数据信息。这些数据的服务对象正逐步从数据研发人员扩展至更为广泛的产品相关人员，如何高效开展数据获取工作，打破数据孤岛现象，充分挖掘并释放数据驱动业务的潜力，已成为业界广泛关注和讨论的焦点议题。针对该问题，业界传统数仓常采用的是经典分层模型的数仓架构，从 ODS（Operational Data Store）&amp;gt;DWD（Data Warehouse Detail）&amp;gt;DWS（Data Warehouse Summary）&amp;gt;ADS（Application Data Store）逐层建模，但我们会发现，从传统固化开发的角度来看，传统经典数仓模型是比较有优势的。然而，面对当下数据需求灵活多变的时代，其局限性也日益凸显。如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-939fa5fcdf0baaf3f9376861ee1c7269bb5.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 搜索场景下的困境与挑战&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;搜索作为百度的核心支柱业务，涵盖通用搜索、智能搜索、阿拉丁与垂类等多元化、多模态的搜索产品，具有&lt;strong&gt;&lt;strong&gt;快速迭代、模块多元化且复杂&lt;/strong&gt;&lt;/strong&gt;的特性，搜索数据更是复杂多样，整体数仓规模达到数百 PB 以上。&lt;/p&gt; 
&lt;p&gt;随着搜索业务各个模块之间的联系日益紧密，交叉分析的需求也在不断增长。使用人员对数据获取的便捷性提出了更高的要求，其中涵盖了数据分析师、策略、业务产品经理、运营、评估等多类角色。他们的诉求期望能够跨越复杂的数据架构壁垒，以更加&lt;strong&gt;&lt;strong&gt;高效、直观、快速&lt;/strong&gt;&lt;/strong&gt;的方式获取到所需数据。&lt;/p&gt; 
&lt;p&gt;而传统的搜索数仓建设体系，无论从建模角度还是技术框架上，都与现阶段用户诉求背道而驰。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;建模角度：多层的传统分层建模。往往会出现（大表数据量大、查询慢、存储冗余、口径不统一）等问题，影响业务分析效率，从而达不到数据驱动业务的效果。数据开发侧作为需求的被动承接方，根据业务侧提出的数据需求进行数据开发与交付，存在需求交付周期长、人力成本高等问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;技术框架角度：搜索数仓过去大多是采用&lt;strong&gt;&lt;strong&gt;UPI&lt;/strong&gt;&lt;/strong&gt;框架（以 C++ MR 计算框架为主）进行 ETL 处理。由于该框架技术陈旧，往往会出现以下问题影响数仓整体时效、稳定。从而使业务部门感知需求支持迟缓、数据产出延迟及数据质量低等一系列问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;容易出现服务不稳定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;处理能力薄弱：处理不了特殊字符，从而导致数据丢失或任务失败等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;只能通过物理机远程执行的方式提交，有单节点风险。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无法 Writer 将数据写到 Parquet 文件，需要进行特定脚本 ETLServer 框架进行转换。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;思考&lt;/strong&gt;&lt;/strong&gt;：如何更好的满足用户角色需求，进一步降低数据获取的使用门槛？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;破局&lt;/strong&gt;&lt;/strong&gt;：拥抱变化，以用户诉求为核心出发点。 探索更适合用户的 &lt;strong&gt;&lt;strong&gt;体系化建模&lt;/strong&gt;&lt;/strong&gt; 来进行实质、有效的数据管理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;体系化建模：&lt;/strong&gt;以业务产品需求驱动模型设计，以模型设计驱动和约束开发实施，防止因模型设计与业务产品割裂、开发实施缺少约束带来的无序、「烟囱式」开发。在机制上形成模型设计与开发实施的有效协同。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;切入点&lt;/strong&gt;&lt;/strong&gt;：以规范「基础数据建设」，消除因「烟囱式」开发给业务带来的困扰和技术上的浪费。&lt;/p&gt; 
&lt;p&gt;由此我们探索出一套新的建模体系：&lt;strong&gt;大宽表+数据集&lt;/strong&gt;：其核心点就是基于宽表，将之前的"需求-交付"解耦为以数据集为中心的建设，从而提升搜索内业务数据分析效率与分析深度，更好助力业务决策。以下将从宽表建模、计算引擎架构优化、新型业务交付模式等方向为大家介绍搜索数据团队业务实践。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;02 搜索建模思路与技术方案&lt;/h1&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 建模模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 思路&lt;/h3&gt; 
&lt;p&gt;基于搜索产品功能特性与差异化业务场景，我们对日志数据进行主题化的分类。在每个主题域内，结合业务运营的具体环节特征，构建具备高整合度的宽表模型。在模型构建过程中，保持 ODS（操作数据存储）层与 DWD（明细数据层）的表结构粒度一致，确保数据的一致性与连贯性。所构建的宽表不仅完整涵盖下游业务所需的全部字段，包括业务明细表中的基础数据，还整合了各层级的维度属性与计算指标。通过这种方式，形成一个全面、统一的数据底座，为上层业务的多维分析、指标监控及决策支持提供坚实的数据支撑，有效满足多样化的业务分析需求。&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;2.1.1.1 举例&lt;/h4&gt; 
&lt;p&gt;以展点主题为例，从历史的模型表粒度和模型层级来分析：ODS 与 DWD、DWS 表行为、检索、点击各个主题在同层模型或者跨模型之间都存在字段、口径的冗余，如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a9f6f8e899639d2fe381e3fd22248b8c407.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_10"&gt;&lt;/span&gt; 
&lt;h4&gt;2.1.1.2 思路分析过程&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;核心思想过程：展点主题下明确粒度，丰富维度&amp;amp;指标，建设宽表模型。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将展点主题下各层之间的事实表复杂嵌套字段打平后与各个维度表、指标等进行 join 生成宽表，宽表的列最终分为公共属性、展点行为属性、业务属性和指标属性。&lt;/p&gt; 
&lt;p&gt;消除：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数仓层间：字段存储冗余问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数仓层内：口径不一致问题&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-75e2f39732709336398f3ea0e2f605afc62.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-cc8563c18a8af68b1e8ce82a384dea8aa25.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-c837b8c7763edc5c4290cd758752771d0ce.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 建模核心思想&lt;/h3&gt; 
&lt;p&gt;基于思路分析过程，总结出一套核心建模理论，核心思想如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-59b8209db3232d786eb0920bd402783d568.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;构建搜索系统性数据建模：根据产品功能和业务不同，按照不同主题构建宽表。从而达到节约存储、精简表数量、口径更清晰的目标。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.3 整体模型架构&lt;/h3&gt; 
&lt;p&gt;基于核心建模思想理论得到整体的模型架构，如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-65a11aadcf98271e6926e75e6f4de59f9cf.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;采用 Parquet 列式存储，可支持宽表数百、千列，超多字段，再经过按列的高效压缩（bucket sort 后，压缩率更高），降低了数仓整体存储空间，提高了 IO 效率，起到了降低上层应用延迟的效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将各层之间的表复杂嵌套字段打平后与各个维度表、指标等进行 join 生成百列宽表，宽表的列最终分为公共属性、业务维度属性和指标属性，便于业务分析，实现快速迭代。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 计算引擎&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为了保证数据生产稳定、准确性。我们对计算引擎的选择做了升级，采用传统 Spark 结合&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;对搜索数仓 ETL 进行重构。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a8f5a69d8cba77d36bc869cdaa8f603c4e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 从架构&amp;amp;处理流程上&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;C++ MR&lt;/strong&gt;&lt;/strong&gt; ：多进程，每个任务独立运行，必须经过 Map-Shuffle-Reduce，然后中间结果写磁盘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;Spark&lt;/strong&gt;&lt;/strong&gt; ：多线程，任务在 Executor 内以线程执行。基于 DAG，可以在内存中缓存数据，减少 IO。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Spark 框架，相较于 MR 框架优势在于&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基于内存计算，处理速度快。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持多种计算模式，功能丰富，适合迭代处理数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供了高级的 API，开发效率高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于平台提交，有效避免单节点计算风险。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;且在有 shuffle 情况下计算表现更好（MR 在 Shuffle 时默认进行排序，spark 对 shuffle 有优化，只有在部分场景才需要排序），在具体业务实践中：同耗时的情况下，Spark 计算资源相较于 MR 节省 20% 左右。&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 ETLServer 到数仓融合引擎转变&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-91ec2c9be50fe59678b383ecdee2fe2439a.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;各主题宽表模型的计算通过&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;（通过 Spark Application Context 常驻方式做到资源有效复用；省去了启动 Driver 的时间实现任务的快速启动，来提升任务执行时间）可直接 Writer 将数据写到 Parquet 文件，文件无需进行多次脚本 server 转换。&lt;/p&gt; 
&lt;p&gt;在具体业务实践中，各主题计算耗时由之前 40min 缩短至 10min（减少了 30min），实现数仓快速产出。&lt;/p&gt; 
&lt;span id="OSC_h2_16"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 新数据模型及架构下的挑战与解决方案&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任何数仓模型架构不会存在一个绝对完美的、涵盖所有方面的解决方案。宽表设计仅是当前环境数仓模型的最优解，它依然面临着诸多不容忽视的挑战。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d897150d0eb4ebe4cbfe141af1e656db0a7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 挑战 1 解决方案&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;列式存储&amp;amp;读取：&lt;/strong&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;宽表采用了 Parquet 列式存储，以及 ZSTD 高效压缩算法。结合数仓融合引擎，达到 Data Skipping（即读的越少、计算越快）的效果，仅需读取查询涉及的分区及列，减少了磁盘 I/O 和内存传输的数据量来提升查询效率，通过 Sql 分析服务发现热点复杂字段，主动引导业务建设物化列，命中后查询性能提升 80%。&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;复杂嵌套字段打平&lt;/strong&gt;&lt;/strong&gt;：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;业务常用核心指标以及高频字段口径下沉宽表。虽然行数变多了，但是避免了 explode，get_json_object、array、map 等复杂字段获取的耗时操作，查询性能相较于之前提升了 2.1 倍。&lt;/p&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 挑战 2 解决方案&lt;/h3&gt; 
&lt;p&gt;搜索数据升级到了湖仓一体架构，借助&lt;strong&gt;&lt;strong&gt;Iceberg Merge Into&lt;/strong&gt;&lt;/strong&gt;功能，实现高效回溯方式：对表数据进行行级别的更新或删除。相比 insert overwrite 操作更加高效，减少了不必要的数据移动和存储浪费。&lt;/p&gt; 
&lt;p&gt;通过单一原子操作实现了复杂的数据整合需求。相比传统的先删除再插入的方式，&lt;strong&gt;&lt;strong&gt;Merge Into&lt;/strong&gt;&lt;/strong&gt;提供了更好的性能和一致性保证，其原理是通过重写包含需要删除和更新行数据所在的 date files。Merge Into 可以使用一个查询结果数据来更新目标表的数据，其语法类似 join 关联方式，根据指定的匹配条件对匹配的行数据进行相应的操作&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Merge Into&lt;/strong&gt;&lt;/strong&gt;基本语法&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d2bd76ce88c3a899a2b4c7e9030565f332e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;回溯原理流程如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-65989e3d43c224d06d336056c29f796c598.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 关联匹配&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;目标表和源表根据指定 key 进行 join 操作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 条件判断&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;若 Key 匹配&lt;/strong&gt;&lt;/strong&gt;：根据源表操作类型，对目标表中的记录执行相应的操作（更新或删除）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;若 Key 不匹配&lt;/strong&gt;&lt;/strong&gt;：执行 Insert 操作，将源表数据插入目标表。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 原子性操作&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;整个流程是事务性的，确保数据一致性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下是特定回溯场景下 hive 与 iceberg 不同方式的回溯耗时对比，可以看的出来用 merge into 代替 insert overwrite 进行回溯，回溯更新效率整体可提高&lt;strong&gt;&lt;strong&gt;54% 左右。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-83ae59dc2b2014d6f454f8ccb8112fdcaa4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 挑战 3 解决方案&lt;/h3&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;2.3.3.1 重排序、高效压缩&lt;/h4&gt; 
&lt;p&gt;开发 ATO 优化器 (通过任务依次执行重排序、压缩等一系列 Rules，实现分区优化和数据重分布)，高效率压缩，解决存储成本，存储节约 20%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-0748d5efaac1312246563e0bce0ba04e1c3.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（1）压缩编码&lt;/p&gt; 
&lt;p&gt;数仓表字段元信息采集：通过任务对图灵宽表表进行字段元信息采集，分析数据分布情况，获取重排序字段。&lt;/p&gt; 
&lt;p&gt;具体做法：通过 RLE、Delta 等缩码方式来提升数据压缩效率；数据重复度越高、连续性越好（有序）的场景，压缩效率会越高，RLE、Delta 编码原理如下。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e0a7287f220ad886011cb4c0b407334ac22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（2） 压缩格式&lt;/p&gt; 
&lt;p&gt;使用 ZSTD 压缩格式和更大的压缩 level，在不影响查询性能的情况下，更大的压缩 level 能进一步提高压缩率，level=9 时在压缩效率和耗时上最为平衡，读写耗时和压缩率对比效果如下。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-9f7b43c93732b26daa2a8d7c38e2da18252.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（3） Page Size&lt;/p&gt; 
&lt;p&gt;针对 Parquet 文件格式特性进行深入挖掘 ，对 Parquet page size 进行分页扩容，将 Page Size 从 1MB 增大至 5MB，让更多相似的数据集中到同一个数据页中，充分利用编码的压缩特性，进一步减少各个数据页之间存在的相似数据。在 ZSTD 的基础上，能进一步提升压缩效果，效果如下&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e1a9ccfc36925c7c5a6ba0e90ecb3ae1a78.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;2.3.3.2 历史裁剪，管理有效字段&lt;/h4&gt; 
&lt;p&gt;开发了一套半自动化的通用裁剪模式，通过采集日常任务代码，sql parser 模块解析出无用字段信息（尤其是大 json 大 map 类型扩展字段的无用字段）自动化实现了裁剪。减少了 &lt;strong&gt;&lt;strong&gt;50%&lt;/strong&gt;&lt;/strong&gt; 的回溯任务计算资源消耗，将人力投入从 5 人/天降低到 0.5 人/天。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-59334d514c3341fa8f02863a2b78ccdc7ab.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;字段频率统计模块&lt;/strong&gt;&lt;/strong&gt;：通过对函谷 SQL 数据库和 TDS 平台 No SQL 任务的物理执行计划进行解析，实现对宽表 SQL 任务和非 SQL 任务的字段访问频率的自动化统计。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;裁剪字段抽取模块&lt;/strong&gt;&lt;/strong&gt;：基于字段访问频率，每月抽取冷温字段，形成可视化的字段访问频率报表，生成裁剪 SQL。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;**冷温字段告警模块：**通过对比前一个月和本月冷温字段列表，生成当月新增冷温字段列表，然后向产品研发团队和数据 RD 团队发出告警，确认需要动态调整的裁剪字段；引入冷温字段告警模块，成功实现了裁剪字段的动态调整。最后，通过滚动裁剪模块自动裁剪 395 天前的数据，进一步降低人力/资源的消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;滚动裁剪模块&lt;/strong&gt;&lt;/strong&gt;：自动化滚动裁剪，裁剪宽表中 395 天前的数据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于业务实践证明：&lt;strong&gt;&lt;strong&gt;宽表数仓模型&lt;/strong&gt;&lt;/strong&gt;与&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;的结合，比传统数仓模型，更适合，面向服务于快速迭代的驱动型业务，主要体现在&lt;/p&gt; 
&lt;p&gt;1. 查询性能巨大提升带来快速响应支持业务需求：&lt;/p&gt; 
&lt;p&gt;简单查询场景 ：Adhoc 查询场景，耗时在数十秒级别，相比于普通 Spark 性能提升 5 倍。&lt;/p&gt; 
&lt;p&gt;复杂场景：业务常用复杂字段拆分打平，避免数组、map 等复杂字段耗时操作、查询性能提升 2.1 倍。&lt;/p&gt; 
&lt;p&gt;2.口径封装下沉：封装业务核心口径，解决业务长期数据源多、口径不一致带来的数据准确性问题，省去不必要的沟通，使用更加简便。&lt;/p&gt; 
&lt;p&gt;3.减少冗余存储：相较于经典传统数仓同主题模型下存储降低 30% 左右。&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;03 基于建模与技术框架初步整合&amp;nbsp;&lt;strong&gt;&lt;strong&gt;探讨图灵 3.0 生态新一代业务服务交付模式&lt;/strong&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;随着搜索数仓模型&amp;amp;计算引擎架构的重构和技术栈统一，搜索数仓定义逐步清晰化、数仓个数大幅度降低，整体趋向更加紧凑、高效以及收敛的态势。在此基础上，为了助力数据迭代效率和分析效率进一步提升，在业务线基础数仓及应用层数据建设上，百度 MEG 内部开发了图灵 3.0 生态系统（即，数仓合理建设，数据分析需求尽可能收敛到 TDA 平台，配套数据集建设完善），包括 Turing Data Engine(TDE) 计算引擎、Turing Data Studio(TDS) 数据开发治理平台和 Turing Data Analysis(TDA) 可视化 BI 产品。依托图灵 3.0 生态，我们进而形成了一套新的开发范式—— 图灵 3.0 新开发模式，用来提升搜索内业务数据分析效率与分析深度，如下图（阶段三）所示&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d20b1a79b0fbe50ef85eb7c922eab6fc5bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 &lt;strong&gt;&lt;strong&gt;阶段一到阶段二&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如之前所述：由于搜索数仓早期查询性能不理想，为了提升业务分析效率建设了大量的业务表。从而导致数据冗余、数据链路稳定性差、效率低、指标口径不一致等一系列问题。搜索数据团队通过数仓模型（将多层数据模型控制在 1-2 层）以及计算引擎架构升级重构、湖仓一体、高效压缩、裁剪等一系列措施解决了这些问题。数据建设更加完善规范化，搜索数仓表的数量由过去的数百张减少至 20 张左右，时效性大幅提升，全数据链路全流程提速 4H+，数据稳定性及运维成本降低 30%。&lt;/p&gt; 
&lt;span id="OSC_h2_24"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 阶段二到阶段三&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;随着图灵 3.0 生态系统（包括 TDA、TDS、TDE）及搜索数仓模型的日益完善，内部提出了，以数据集为核心来构建数据应用层，将数据开发侧与业务侧的依赖关系从之前的"需求-交付"解耦为以数据集为中心的建设，实现数据集&amp;lt;-&amp;gt;可视化分析&amp;lt;-&amp;gt;仪表盘的数据分析闭环，解决业务常用维度、指标长周期的查询分析需求 ——&amp;gt; 图灵 3.0 新开发模式。&lt;/p&gt; 
&lt;p&gt;图灵 3.0 新开发模式核心思想在于数据集的建设，我们将不再仅仅只是根据业务需求来定制开发数据报表，而是构建一个灵活、可扩展的数据集。使业务侧能够自主地根据需求从中提取、分析和可视化数据，以满足不断变化的业务需求。&lt;/p&gt; 
&lt;p&gt;那么，在数据集建模实践中，如何才能合理构建一个灵活、可扩展且高质量的数据集？是数据研发对数据集建模关键核心，也是最大的挑战。&lt;/p&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1 数据集建模合理度挑战&lt;/h3&gt; 
&lt;p&gt;1. 为了满足业务需求的多样性与广泛性，并支持更多的维度和指标。我们往往会倾向于在单个数据集中不断叠加新的维度和指标，这种做法虽然表面上看起来方便快捷，但实际上却导致了数据集行数的急剧增加，进而对聚合查询的性能造成了不利影响&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;为了确保查询的高效性，同时兼顾更多维度与指标的业务需求。我们往往的做法，就是建立更多的数据集，以空间换时间去满足查询性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;显然，这些做法之间存在着明显的矛盾，具体如下图。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-cd8fad4be3fd6dfa2887117d9f41ac20272.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_26"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2 解决方案&lt;/h3&gt; 
&lt;p&gt;为了更好地找到平衡点，搜索数据团队采取了以下解决措施：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;明确边界&lt;/strong&gt;&lt;/strong&gt;：分主题建设对应数据集，单主题内，数据集尽量做到合并统一，以达到更高的集成度与一致性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;明确粒度&lt;/strong&gt;&lt;/strong&gt;：从业务场景需求出发，单主题内数据集建设前明确数据集最小粒度 ，确保数据最小粒度既能满足主题分析的精度要求，又避免因过度细化或粗放导致的分析效能损耗，为后续数据集的结构化构建与高效奠定基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;深度性能优化&lt;/strong&gt;&lt;/strong&gt;：充分利用了 TDE-ClickHouse 强大基础引擎，例如在处理高基数去重计数字段时，创新性地采用 NoMerge 技术来替代传统的 COUNT(DISTINCT) 方法，降低了聚合层的计算负担，实现了查询性能 5 至 10 倍的提升，极大地优化了数据处理速度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_27"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 新模式带来的改变&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-11ffa0f8e33c9d7a46ccb8a729f3b0031ce.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;△ 图灵 3.0 的数据开发新模式&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;强化主动能力，业务自助效率显著提升&lt;/strong&gt;&lt;/strong&gt;：相较于以往被动式的一对一需求定制化开发模式，数据研发工作已从单纯响应被动需求转变为主动规划构建数据集。图灵 3.0 新开发模式下，实现数据集&amp;lt;-&amp;gt;可视化分析&amp;lt;-&amp;gt;仪表盘的数据分析闭环（满足 90% 查询；其余 10% 长尾交给 Adhoc 查询），业务人员对日常通用需求的分析工作转移到数据集自助查询与分析上（根据数据集自助创建可视化数据报表）。可视化分析占比、&lt;strong&gt;&lt;strong&gt;业务自助率提高至 90%，数据研发日常需求量减少 80%。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;非核心常用维度指标查询性能显著提升&lt;/strong&gt;&lt;/strong&gt;：非核心常用维度指标由以往业务提需，查表或单独建设报表来获取数据的方式，转变为通过数据集自助下钻、拖拉拽自由组合常用维度指标，实现可视化分析的方式。借助 TDE-ClickHouse 强大基础引擎能力：可视化分析效率大幅提升，&lt;strong&gt;&lt;strong&gt;从小时、分钟级的数据分析效率，提升至秒级分析&lt;/strong&gt;&lt;/strong&gt;。单次查询数据周期由&lt;strong&gt;&lt;strong&gt;1 周内，提升至 1 年内（&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;秒级完成查询&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;）&lt;/strong&gt;&lt;/strong&gt;，真正做到即需即查即用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;血缘管理规范化，运维效率显著提升&lt;/strong&gt;&lt;/strong&gt;：数据血缘更加完整流程化，数仓-数据集，血缘在 TDS 完成闭环，数据集内字段血缘在 TDA 完成闭环，以数据集为纽带串联整个数据流全过程，&lt;strong&gt;&lt;strong&gt;数据链路运维效率提升 2-3 倍&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;目前，该模式已经广泛应用于搜索各业务数据运营人员早报、周报等多种业务汇报场景。得益于该模式，搜索产品线下&lt;strong&gt;&lt;strong&gt;仪表盘周均查询（PV）高达 1.7W 次&lt;/strong&gt;&lt;/strong&gt;左右，&lt;strong&gt;&lt;strong&gt;可视化分析周均 0.93W 次左右 ，每周&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;超过 400 多名用户参与 TDA 搜索数据分析工作&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;。&lt;strong&gt;&lt;strong&gt;更重要的是，需求的交付周期实现了显著缩短，由&lt;/strong&gt;&lt;/strong&gt;以往的单/双周缩短至按天交付&lt;/strong&gt;&lt;/strong&gt;；甚至在某些情况下，业务人员能够直接自助获取所需数据。在处理重点项目时，该模式也能确保业务团队在第一时间获取到 P0 级别的关键数据。这种方式的转变不仅能够减轻数据开发团队的工作负担——人力成本由原先的&lt;strong&gt;&lt;strong&gt;3 人锐减至 1 人&lt;/strong&gt;&lt;/strong&gt;，还能提高业务侧的数据使用效率和自主性，使得团队得以从繁琐的「取数」与「跑数」任务中解放出来，将更多的精力投入到数仓模型的优化、技术框架的探索与治理等更具战略价值的工作中去。&lt;/p&gt; 
&lt;span id="OSC_h1_28"&gt;&lt;/span&gt; 
&lt;h1&gt;04 总结与展望&lt;/h1&gt; 
&lt;p&gt;数据建模领域正经历从「技术驱动」向「价值驱动」的深刻转型，更加强调的是敏捷性、可解释性和业务对齐。尽管当前的技术工具愈发强大，但成功的关键依旧在于跟业务的紧密协作与一个清晰明确的治理框架。&lt;/p&gt; 
&lt;p&gt;搜索业务，作为百度内部最核心且最为复杂的板块，涵盖了多个至关重要的产品线。近年来，搜索数据团队始终致力于运用前沿技术来不断优化和完善数仓体系的建设，以坚实的基础数仓架构支撑起数据质量飞跃提升，从而高效赋能业务，带来可量化、可感知的业务成效与用户体验升级。&lt;/p&gt; 
&lt;p&gt;展望未来，随着 AI 代理和边缘计算等技术的蓬勃发展，数据建模有望朝着自适应与嵌入式方向进一步进化。搜索数据侧还将在以下关键方向与大家进行深入探讨、交流和学习：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;通用数据流解决方案&lt;/strong&gt;&lt;/strong&gt;：构建事件规则引擎等通用数据流处理工具，简化数据处理流程，提高数据处理效率与灵活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;日志埋点技术（含无埋点）&lt;/strong&gt;&lt;/strong&gt;：探索高效的自动化埋点机制，提升数据采集的全面性与准确性，为业务洞察提供坚实的数据基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;宽表模型框架抽象层&lt;/strong&gt;&lt;/strong&gt;：探索更为高效、灵活的模型统一抽象方法层。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;AI 大模型时代下的高效开发模式&lt;/strong&gt;&lt;/strong&gt;：探索如何通过利用大模型技术，来优化代码质量、数据链路等，打造更加高效、可靠的数据开发与运维体系。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们期待之后再次与大家见面探讨这些议题，共同推动数据领域的创新与发展。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18683272</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18683272</guid>
      <pubDate>Sun, 11 May 2025 03:38:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AI 编程软件 Cursor 开发商聘请两位 Anthropic 前高管</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程软件 Cursor 开发商 Anysphere 聘请了两位来自 Anthropic 的前高管，分别担任首席架构师兼工程主管和产品负责人。&lt;/p&gt; 
&lt;p&gt;Boris Cherny，曾是 Claude Code 的开发负责人，将担任 Anysphere 的首席架构师兼工程主管。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0703/113518_qNjw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Boris Cherny 于 2024 年 9 月加入 Anthropic，入职还不到一年，此前在 Meta 任职首席软件工程师、 Instagram 的服务器架构和开发基础设施主管， 以及 Meta 的代码质量主管，毕业于美国加州大学圣迭戈分校。&lt;/p&gt; 
&lt;p&gt;Cat Wu，曾是 Claude Code 的产品经理，将担任产品负责人。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0703/113527_RWRC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cat Wu 全名 Catherine Wu，2024 年 8 月加入 Anthropic，擅长构建高可靠、可解释、可控制的人工智能系统，本科毕业于普林斯顿大学，专业计算机科学，加入 Anthropic 之前有多段不同领域工作实习经历，最长两年，比如在谷歌实习任职软件工程师，在 J.P. 摩根实习任职交易员，在 Alexandr Wang 公司 Scale AI 作为作为产品经理任职两年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358526</guid>
      <pubDate>Sun, 11 May 2025 03:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>富士康推出首款 AI 推理大模型 「FoxBrain」，商标申请已提交</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;近日，鸿海精密工业股份有限公司（也就是大家熟悉的富士康）在国家知识产权局商标局提交了 「FoxBrain」 商标注册申请。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这款 AI 推理大模型不仅是富士康的首次尝试，更是台湾省首个该类型的 AI 模型。根据公开资料显示，该商标的国际分类为科学仪器，目前正处于 「等待实质审查」 的状态。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-853c20df5c0da43f4e610f96af33d644262.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「FoxBrain」 是鸿海研究院重磅推出的 AI 推理大模型，涵盖数据分析、数学推理、代码生成等多个功能。富士康声称，FoxBrain 的初始版本基于 Meta 的 Llama3.1 模型进行开发，使用了 120 块英伟达 H100GPU 进行了为期一个月的训练。这一模型特别针对繁体中文进行了优化，尽管其性能相较于其他模型，如 DeepSeek，可能稍显不足。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得一提的是，富士康并非台湾省唯一在 AI 领域发力的公司。早前，联发科也推出了 Llama-Breeze2 系列 AI 模型，这些模型虽然定位为 「轻量级」，但同样主打繁体中文处理能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358520</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358520</guid>
      <pubDate>Sun, 11 May 2025 03:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Grok 4 将提供面向编程的「Code」版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAiBattle_%2Fstatus%2F1940139539525419512" target="_blank"&gt;博主「AiBattle」爆料称&lt;/a&gt;，其在 xAI 控制枱的源代码中发现了 2 个 Grok 4 模型的相关信息。&lt;/p&gt; 
&lt;p&gt;据悉，&lt;strong&gt;本次 Grok 4 将拥有标准版和面向编程的 Code 版&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grok 4：xAI 最出色、最新的旗舰模型，在自然语言、数学和推理方面表现优秀。&lt;/li&gt; 
 &lt;li&gt;Grok 4 Code：专为编程而生，能够咨询代码相关问题，或者将 Grok 4 Code 嵌入代码编辑器中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9bcf46eea400a93a91e4827ee44b5545da0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3a6e92d6992d4ffe25867b6b3a69cdcbc4f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;另据爆料，Grok 4 的权限已经部分开通，可通过 API 访问。目前，Grok 4 支持文本模态以及视觉、图像生成等功能，其他功能也即将推出。&lt;/p&gt; 
&lt;p&gt;马斯克近日也透露，Grok 4 计划在今年 7 月 4 日之后发布；并且新模型将尝试从第一性原理出发进行推理，也就是将物理学的方法应用到思维过程中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0630/185329_AUaz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/358033" target="news"&gt;Grok 4 将于 7 月 4 日后发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358516</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358516</guid>
      <pubDate>Sun, 11 May 2025 03:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动开源 4D 视频生成框架 EX-4D</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;字节跳动旗下 PICO-MR 团队正式开源了 EX-4D，一款突破性的 4D 视频生成框架；能够从单一视角（单目）视频生成高质量、多视角的 4D 视频序列 (3D 空间+时间维度)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;传统视频生成技术在多视角生成方面面临两大挑战:一是需要昂贵的多视角相机和数据集进行训练;二是难以处理遮挡区域，导致生成的视频在极端视角下出现物体穿帮或细节失真。EX-4D 通过创新的深度密闭网格（DW-Mesh）表示和轻量级适配架构，成功解决了这些问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;DW-Mesh 是 EX-4D 的核心技术，它通过构建全密闭网格结构，记录场景中的可见和隐形面片，无需多视角监督即可统一处理复杂场景拓扑。结合预训练深度预测模型，EX-4D 将单帧像素投影到 3D 空间，形成网格顶点，并根据几何关系精准标记遮挡区域。这种方法确保了生成视频在极端视角（如±90°）下仍能保持物理一致性和细节完整性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，EX-4D 引入了两种模拟 mask 生成策略——渲染 mask 和跟踪 mask，通过模拟视角移动和帧间一致性，破解了多视角训练数据的稀缺难题。这些策略使 EX-4D 仅凭单目视频即可「脑补」全视角数据，极大降低了数据采集成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;性能测试结果表明，EX-4D 在 FID（弗雷歇距离）、FVD(弗雷歇视频距离) 和 VBench 等行业标准指标上全面超越现有开源方法。尤其在极端视角 (如接近 90°) 的生成任务中，EX-4D 的性能优势尤为明显，生成的视频在物体细节和遮挡逻辑上表现更为真实。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="251" src="https://oscimg.oschina.net/oscnet/up-dbd1b11be587afb0f59e10fdb2c7026588a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#000000"&gt;在一项由 50 位志愿者参与的主观评估中，70.7% 的参与者认为 EX-4D 在极端视角下的物理一致性远超其他开源方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;EX-4D 基于预训练的 WAN-2.1 模型，结合 LoRA-based Adapter 架构，在保持计算效率的同时，融入了 DW-Mesh 的几何先验信息，确保生成视频的几何一致性和帧间连贯性。这种轻量级设计使得 EX-4D 在资源受限的环境下也能高效运行，适合广泛的开发场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;字节跳动 PICO-MR 团队负责人表示，EX-4D 是团队在 3D 重建与 4D 场景生成领域多年研究的结晶，未来将继续优化模型性能，探索更广泛的应用场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358512</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358512</guid>
      <pubDate>Sun, 11 May 2025 02:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>VLOOK 30！支持发布为 PDF 及多项用户体验优化，实用好用的 Markdown 主题插件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMadMaxChow%2FVLOOK" target="_blank"&gt;VLOOK&lt;/a&gt;™&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;是针对&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftypora.io%2F"&gt;Typora&lt;/a&gt;（跨平台 Markdown 编辑器）的&lt;/strong&gt;主题包&lt;/strong&gt;和&lt;strong&gt;增强插件&lt;/strong&gt;（针对导出的 HTML 文件)，&lt;strong&gt;旨在与众 Markdown 粉共创 Markdown 的自动化排版 2.0，在保持 Markdown 简洁性的基础上，让编辑、阅读 Markdown 文档更实用，也更愉悦。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;VLOOK™&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;属于开源软件（遵从&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;MIT License&lt;/strong&gt;），也是&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/p/vlook"&gt;OSCHINA 开源中国&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;推荐的国产开源产品、Typora 的首个增强插件。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;— What's 🎉 NEW —&lt;/h2&gt; 
&lt;h3&gt;🖨️ 另存为 PDF（实验性功能）&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;结合浏览器的打印功能，对导出后的 HTML 提供了「另存为 PDF」的支持（在移动端也能用）&lt;/li&gt; 
 &lt;li&gt;该功能目前实验性预览版本，使用过程中如有问题可及时在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMadMaxChow%2FVLOOK%2Fissues" target="_blank"&gt;Issues&lt;/a&gt;&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;反馈&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;— What's ♻️ IMPROVED —&lt;/h2&gt; 
&lt;p style="color:#1f2328; text-align:start"&gt;&lt;strong&gt;📱移动端&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;优化对浏览器顶栏主题色样式支持&lt;/li&gt; 
 &lt;li&gt;优化段落排版样式&lt;/li&gt; 
 &lt;li&gt;优化触摸屏的交互体验&lt;/li&gt; 
 &lt;li&gt;减少干扰不显示工具栏，通过左侧的导航指示器打开导航中心&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#1f2328; text-align:start"&gt;&lt;strong&gt;😄 用户体验&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;完善对图片明信片版式的懒加载处理&lt;/li&gt; 
 &lt;li&gt;优化对切换「字体风格」的体验&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;— What's&lt;span&gt;&amp;nbsp;&lt;/span&gt;⚠️&lt;span&gt;&amp;nbsp;&lt;/span&gt;CHANGED —&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;主题默认恢复为 Mermaid 原生样式，同时提供 VLOOK 风格的定制样式选择&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;— One more 🎁 THING … —&lt;/h2&gt; 
&lt;h3&gt;🖱️ VLOOK 周边上新&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;免费的电脑墙纸（附有，常用语法、色号，的参考）&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmadmaxchow.github.io%2FVLOOK%2Fvip.html%23%25E5%25A2%2599%25E7%25BA%25B8" target="_blank"&gt;…去看看 ››&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;鼠标垫、桌面垫，提供定制主题同款选择&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmadmaxchow.github.io%2FVLOOK%2Fvip.html%23%25E5%25AE%259E%25E7%2589%25A9%25E5%2591%25A8%25E8%25BE%25B9" target="_blank"&gt;…去看看 ››&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;💎 定制主题新选项&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;VLOOK 界面导航中心分类索引样式选择（标准/多彩）：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="80" src="https://oscimg.oschina.net/oscnet/up-3a0698172b90c56c9972f89b7baee6fb882.png" width="568" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="80" src="https://oscimg.oschina.net/oscnet/up-5fdd55ea7a1a9dae29a1889e604282e2992.png" width="568" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;VLOOK 界面多款图标集选择（分层/单色/线性）：&lt;/p&gt; &lt;p&gt;&lt;img height="70" src="https://oscimg.oschina.net/oscnet/up-ceffa0d643ea7affcd285b2364d20d52165.png" width="625" referrerpolicy="no-referrer"&gt;&lt;/p&gt; &lt;p&gt;&lt;img height="66" src="https://oscimg.oschina.net/oscnet/up-6224df6868c1820a3df8300ed3c32c574be.png" width="198" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VLOOK 界面遮罩背景风格选择（波点/渐变）：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1026" src="https://oscimg.oschina.net/oscnet/up-713e103f3b730358ef0723ce88f209b8feb.png" width="1900" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1014" src="https://oscimg.oschina.net/oscnet/up-bc721b8e0c839366322926f21e3dca470b4.png" width="1888" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#1f2328; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmadmaxchow.github.io%2FVLOOK%2Fvip.html%23%25E4%25B8%25BB%25E9%25A2%2598%25E5%25AE%259A%25E5%2588%25B6%25E6%259C%258D%25E5%258A%25A1" target="_blank"&gt;…进一步了解主题定制服务 ››&lt;/a&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;hr&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     &lt;strong&gt;&lt;span&gt;&lt;span&gt;了解更多关于 VLOOK™ 的内容，以下入口自行选择：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
      &lt;span&gt;&lt;span&gt;更多有关的小专题：&lt;/span&gt;&lt;/span&gt;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Fpeople%2Fmaxchow%2Fposts" target="_blank"&gt;&lt;span&gt;&lt;span&gt;轻轻一点去看看&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
      &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvlook-doc.pages.dev%2Findex" target="_blank"&gt;&lt;span&gt;&lt;span&gt;VLOOK 简介&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&amp;nbsp; |&amp;nbsp;&amp;nbsp;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;span&gt;&amp;nbsp;&lt;/span&gt;
      &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvlook-doc.pages.dev%2Fguide" target="_blank"&gt;&lt;span&gt;&lt;span&gt;快速参考手册&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;ul&gt; 
   &lt;/ul&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358491</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358491</guid>
      <pubDate>Sun, 11 May 2025 00:58:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>微语 0.8.6 发布，开源 AI 客服系统</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;企业级多租户团队协作工具，免费开源 N 件套：企业 IM、在线客服、企业知识库/帮助文档、客户之声、工单系统、AI 对话、工作流、项目管理、呼叫中心、视频客服、视频会议...。&lt;/p&gt; 
&lt;h2&gt;语言&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.zh.md"&gt;中文&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="weiyu" src="https://oscimg.oschina.net/oscnet//a81626efa434cd459081450a5c354040.png" referrerpolicy="no-referrer"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;img alt="chat" src="https://oscimg.oschina.net/oscnet//8a82aceb8dcafa250914935a058d765f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;介绍&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/team/readme.zh.md"&gt;企业 IM&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;局域网即时通讯&lt;/li&gt; 
 &lt;li&gt;企业成员管理&lt;/li&gt; 
 &lt;li&gt;聊天记录监控&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/service/readme.zh.md"&gt;全渠道客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;多渠道接入&lt;/li&gt; 
 &lt;li&gt;人工客服&lt;/li&gt; 
 &lt;li&gt;客服 Agent 智能体，对接自有数据，自动执行操作&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/kbase/readme.zh.md"&gt;知识库&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;对接大模型&lt;/li&gt; 
 &lt;li&gt;自定义知识库&lt;/li&gt; 
 &lt;li&gt;Function Calling&lt;/li&gt; 
 &lt;li&gt;Mcp&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ticket/readme.zh.md"&gt;工单系统&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;工单管理&lt;/li&gt; 
 &lt;li&gt;工单 SLA 管理&lt;/li&gt; 
 &lt;li&gt;工单统计和报表&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ai/readme.zh.md"&gt;AI Agent&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ollama/DeepSeek/ZhipuAI/...&lt;/li&gt; 
 &lt;li&gt;智能体&lt;/li&gt; 
 &lt;li&gt;工作流&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;工作流&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;自定义表单&lt;/li&gt; 
 &lt;li&gt;自定义流程&lt;/li&gt; 
 &lt;li&gt;工单流程可视化&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/voc/readme.zh.md"&gt;客户之声&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;意见反馈&lt;/li&gt; 
 &lt;li&gt;服务投诉&lt;/li&gt; 
 &lt;li&gt;问卷调查&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/freeswitch/readme.zh.md"&gt;呼叫中心&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 FreeSwitch 的专业呼叫平台&lt;/li&gt; 
 &lt;li&gt;支持来电弹屏、自动分配、通话录音&lt;/li&gt; 
 &lt;li&gt;数据统计，语音与文字服务无缝集成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/webrtc/readme.zh.md"&gt;视频客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 WebRTC 技术的高清视频通话&lt;/li&gt; 
 &lt;li&gt;支持一键视频对话与屏幕共享&lt;/li&gt; 
 &lt;li&gt;适用于需要直观展示的服务场景&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/jitsi/readme.zh.md"&gt;视频会议&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;集成 Jitsi 的专业会议平台&lt;/li&gt; 
 &lt;li&gt;支持多人在线会议、屏幕共享&lt;/li&gt; 
 &lt;li&gt;会议录制等功能，满足远程协作需求&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/kanban/readme.zh.md"&gt;项目看板&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持任务创建、分配、进度监控&lt;/li&gt; 
 &lt;li&gt;文件共享与团队协作功能&lt;/li&gt; 
 &lt;li&gt;帮助团队高效完成项目目标&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/social/readme.zh.md"&gt;社交群组&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;类似 Discord&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;多租户&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;多租户管理&lt;/li&gt; 
 &lt;li&gt;租户隔离&lt;/li&gt; 
 &lt;li&gt;租户统计&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker 快速开始&lt;/h2&gt; 
&lt;h3&gt;方法一：克隆项目并启动 docker compose 容器，需要另行安装 ollama，默认使用 qwen3:0.6b 模型&lt;/h3&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;git &lt;span style="color:#0086b3"&gt;clone&lt;/span&gt; https://gitee.com/270580156/weiyu.git &amp;amp;&amp;amp; &lt;span style="color:#0086b3"&gt;cd&lt;/span&gt; weiyu/deploy/docker &amp;amp;&amp;amp; docker compose -p weiyu -f docker-compose.yaml up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;因项目默认使用 ollama qwen3:0.6b 模型，所以需要提前拉取模型。配置文件中可以配置其他模型，如 deepseek-r1 等&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 对话 Chat 模型&lt;/em&gt;
ollama pull qwen3:0.6b
&lt;em&gt;# 嵌入 Embedding 模型&lt;/em&gt;
ollama pull bge-m3:latest
&lt;em&gt;# 重新排序 Rerank 模型&lt;/em&gt;
ollama pull linux6200/bge-reranker-v2-m3:latest
&lt;em&gt;# 或者从 huggingface 下载模型&lt;/em&gt;
&lt;em&gt;# ollama pull hf.co/&amp;lt;username&amp;gt;/&amp;lt;model-repository&amp;gt;&lt;/em&gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;方法二：使用 docker compose ollama，默认安装 ollama，默认使用 qwen3:0.6b 模型&lt;/h3&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;git &lt;span style="color:#0086b3"&gt;clone&lt;/span&gt; https://gitee.com/270580156/weiyu.git &amp;amp;&amp;amp; &lt;span style="color:#0086b3"&gt;cd&lt;/span&gt; weiyu/deploy/docker &amp;amp;&amp;amp; docker compose -p weiyu -f docker-compose-ollama.yaml up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;docker 拉取 ollama 模型。配置文件中可以配置其他模型，如 deepseek-r1 等&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 对话模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull qwen3:0.6b
&lt;em&gt;# 嵌入模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull bge-m3:latest
&lt;em&gt;# 重新排序 Rerank 模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull linux6200/bge-reranker-v2-m3:latest
&lt;em&gt;# 或者从 huggingface 下载模型&lt;/em&gt;
&lt;em&gt;# docker exec ollama-bytedesk ollama pull hf.co/&amp;lt;username&amp;gt;/&amp;lt;model-repository&amp;gt;&lt;/em&gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;停止容器&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;docker compose -p weiyu -f docker-compose.yaml stop
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;修改配置，否则上传图片、文件和知识库无法正常显示&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;修改&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;docker-compose.yaml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件，或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;docker-compose-ollama.yaml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件，修改以下配置项：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 请将服务器 127.0.0.1 替换为你的服务器 ip&lt;/em&gt;
BYTEDESK_UPLOAD_URL: http://127.0.0.1:9003
BYTEDESK_KBASE_API_URL: http://127.0.0.1:9003
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;方法三：宝塔面板&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fbaota" target="_blank"&gt;宝塔面板部署&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;方法四：源码启动&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fsource" target="_blank"&gt;源码启动&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;演示&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;本地预览&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 请将 127.0.0.1 替换为你的服务器 ip&lt;/em&gt;
http://127.0.0.1:9003/
&lt;em&gt;# 开放端口：9003, 9885&lt;/em&gt;
默认用户名: admin@email.com
默认密码: admin
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;试用&lt;/h2&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 社区版，永久有效&lt;/em&gt;
bytedesk.appkey=ZjoyMDI1LTA3LTE5OkNPTU1VTklUWTo6
BYTEDESK_APPKEY: ZjoyMDI1LTA3LTE5OkNPTU1VTklUWTo6
&lt;em&gt;# 企业版，试用，有效期：2025-07-19&lt;/em&gt;
bytedesk.appkey=ZjoyMDI1LTA3LTE5OkVOVEVSUFJJU0U6Og==
BYTEDESK_APPKEY: ZjoyMDI1LTA3LTE5OkVOVEVSUFJJU0U6Og==
&lt;em&gt;# 平台版，试用，有效期: 2025-07-19&lt;/em&gt;
bytedesk.appkey=ZjoyMDI1LTA3LTE5OlBMQVRGT1JNOjo=
BYTEDESK_APPKEY: ZjoyMDI1LTA3LTE5OlBMQVRGT1JNOjo=&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358488</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358488</guid>
      <pubDate>Sat, 10 May 2025 23:28:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>DeepEval —— 开源 LLM 评估框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;DeepEval&amp;nbsp;&lt;/strong&gt;是一个简单易用的开源 LLM 评估框架，用于评估和测试大型语言模型系统。它与 Pytest 类似，但专门用于对 LLM 输出进行单元测试。DeepEval 结合了最新研究成果，基于 G-Eval、幻觉、答案相关性、RAGAS 等指标来评估 LLM 输出，它使用 LLM 和其他各种在&lt;strong&gt;本地&lt;/strong&gt;运行的 NLP 模型进行评估。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;无论你的 LLM 应用程序是 RAG &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;pipelines&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;、聊天机器人、AI 代理，还是通过 LangChain 或 LlamaIndex 实现，DeepEval 都能满足你的需求。借助它，你可以轻松确定最佳模型、提示和架构，以改进你的 RAG 管道和代理工作流，防止 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;prompt drifting&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，甚至可以自信地从 OpenAI 过渡到托管你自己的 Deepseek R1。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&amp;nbsp;&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;以类似于 Pytest 的方式轻松地「单元测试」 LLM 输出。&lt;/li&gt;
&lt;li&gt;即插即用 30 多个 LLM 评估指标，其中大多数都有研究支持。&lt;/li&gt;
&lt;li&gt;支持端到端和组件级评估。&lt;/li&gt;
&lt;li&gt;对 RAG、代理、聊天机器人以及几乎任何用例的评估。&lt;/li&gt;
&lt;li&gt;使用最先进的进化技术生成合成数据集。&lt;/li&gt;
&lt;li&gt;指标易于定制并涵盖所有用例。&lt;/li&gt;
&lt;li&gt;红队，安全扫描 LLM 应用程序是否存在安全漏洞。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1c1e21"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，DeepEval 还有一个云平台&lt;a href="https://app.confident-ai.com/" target="_blank"&gt;Confident AI&lt;/a&gt;，允许团队使用 DeepEval 在云端进行&lt;strong&gt;评估、回归测试、红队和监控 LLM 应用程序。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="282" src="https://static.oschina.net/uploads/space/2025/0617/152602_UCxK_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepeval</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepeval</guid>
      <pubDate>Sat, 10 May 2025 10:44:00 GMT</pubDate>
    </item>
    <item>
      <title>设计协作平台 Figma 递交首次公开募股（IPO）申请</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Figma 昨日正式提交了首次公开募股（IPO）申请，计划在美国纽约证券交易所（NYSE）上市，股票代码为「FIG」。&lt;/p&gt; 
&lt;p&gt;Figma 成立于 2016 年，主要在网络上提供界面设计协作服务，同时也推出了 macOS / Windows 平台桌面客户端。该公司的产品线除了最早推出的设计工具 Figma Design 外，还包括在线协作白板 FigJam、演示文稿协作工具 Figma Slides、绘图工具 Figma Draw、设计自动化软件 Dev Mode、网站设计工具 Figma Sites，以及用于构建社交平台的 Figma Buzz 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Figma 公司曾计划在 2022 年以 200 亿美元&lt;a href="https://www.oschina.net/news/210475/adobe-to-acquire-figma"&gt;出售给 Adobe&lt;/a&gt;，但由于欧盟和英国监管机构担心该交易会影响市场竞争，相应计划最终被叫停，迫使 Adobe 在当年底向 Figma 支付了 10 亿美元的解约费用。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bf6c1fe7a671d0abebcca4cc84a6f1c39da.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;参考 Figma 提交的 S-1 申请文件，今年第一季度，公司拥有 1300 万月活跃用户（其中三分之二用户并非专业设计师），公司已获得了 95% 的《财富》500 强企业和 78% 的《福布斯》全球 2000 强企业的青睐。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;而在营收方面，Figma 在 2024 年实现了 7.49 亿美元（现汇率约合 53.65 亿元人民币）营收，同比增长 48%，但全年仍有 7.3 亿美元（现汇率约合 52.29 亿元人民币）亏损。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358402</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358402</guid>
      <pubDate>Sat, 10 May 2025 08:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯回应微信「Al 搜索」泄露个人隐私：仅整合公开信息，不会碰用户隐私</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，网友在社交平台吐槽被微信新推出的「AI 搜索」功能强行开盒。&lt;/p&gt; 
&lt;p&gt;该网友发现，当微信推文中出现本人姓名时，名字会变成蓝色超链接，点击人名即可一键浏览公众号 A1 强制生成的「个人简历」及所有涉及该姓名的推文。不少网友在尝试了该功能后表示「确实可以根据名字查到很多个人资料」，引发隐私安全方面的担忧。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ef93511d7c54a97e53e3f1cfb985f5f4df0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对此，腾讯方面今日回应媒体称，为了丰富用户搜索体验，微信搜索此前通过接入 DeepSeek 和混元等大模型推出 AI 搜索。AI 搜索仅整合公众号及互联网其他公开信息，不会使用用户隐私信息。根据用户近期的相关反馈，微信搜索将进一步优化 AI 搜索的使用体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358391</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358391</guid>
      <pubDate>Sat, 10 May 2025 08:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TDMQ RabbitMQ Serverless 版限流机制深度解析与实践指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h2&gt;导语&lt;/h2&gt; 
&lt;p&gt;分布式集群限流是保障云服务高可用性的核心技术手段，其意义不仅在于防止系统过载，更是构建弹性架构、优化资源效率、实现业务可持续性的关键策略。未来，随着边缘计算和 Serverless 的普及，限流技术将进一步与底层基础设施深度融合，成为构建下一代高可用架构的核心基石。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版作为一款极致弹性、高性能且高可靠的消息中间件，通过提供稳定低延迟的消息服务，助力企业实现系统异步解耦并高效应对海量消息堆积。然而，在高并发、大流量的实际业务中，如何科学分配资源、规避系统过载风险，已成为保障服务稳定性的关键。为此，腾讯云 TDMQ RabbitMQ Serverless 版引入了集群级别的分布式限流机制，通过动态调控集群的发送与消费速率，确保集群在高负载下仍能稳定运行。&lt;/p&gt; 
&lt;p&gt;本文将深度剖析腾讯云 TDMQ RabbitMQ Serverless 版的限流机制，涵盖限流策略设计、触发机制及底层实现逻辑。通过真实场景案例解析与实践指南，系统讲解如何通过客户端优化来降低限流影响，同时帮助客户精准掌握集群限流相关服务端配置技巧，有效规避因流控策略不当引发的业务中断风险，全面提升高并发场景下的系统稳定性与可靠性。&lt;/p&gt; 
&lt;h2&gt;概要设计&lt;/h2&gt; 
&lt;h3&gt;分布式限流的必要性&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;资源瓶颈的不可预测性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在分布式系统中，单节点流量可能因负载均衡策略（如 Round-Robin）不均导致倾斜。例如，某台服务器因硬件故障触发重试风暴，流量突增 300%，若无全局视角的限流，可能引发级联雪崩。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;长尾延迟的放大效应&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当某服务节点响应延迟升高（如磁盘刷写延迟增大），后续请求堆积导致线程池耗尽，触发上游重试，形成恶性循环。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;突发流量冲击&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;秒杀活动、热点新闻等场景下，流量可能在毫秒级陡增数十倍。例如，某电商平台大促期间，订单服务 QPS 从 5k 飙升至 80k，若未通过分布式限流拦截异常流量，核心计算资源将被瞬间打满，导致服务不可用。&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流规则&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版为超大规模、低时延、高可用性要求的在线业务提供专业级消息服务。客户端通过 RabbitMQ SDK 与 TDMQ RabbitMQ Serverless 版集群建立长连接，实现高效的消息收发操作，同时动态占用集群的计算、存储及网络带宽等关键资源。在此背景下，为确保消息服务的高性能与稳定性，在应对高并发、大流量场景时，必须对集群的负载水位进行精细化管理。 基于集群的资源配置上限，服务端支持动态调控客户端的每秒消息发送与消费能力（TPS），确保系统在高负载下依然保持稳定运行。&lt;/p&gt; 
&lt;p&gt;为实现资源隔离与灵活适配的双重目标，系统对发送消息与消费消息的 TPS 配额进行独立分配，并支持用户按需配置配额比例，从而实现精细化资源管理与业务场景的精准匹配（默认配额比例为 1 : 1 也即 50%）。业务可以根据实际的收发比例进行调整，可调整的收发消息比例范围在 20%-80%（服务端支持动态调整该区间）之间。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7e99eeeb65ba2619e29a1109b273abf1cd8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TDMQ RabbitMQ Serverless 版限流行为&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用 Fail-Fast 限流机制，即当客户端请求速率触及预设上限时，服务端会即时返回错误响应。在响应时间敏感的在线业务场景中，该机制可使客户端实时感知限流事件并主动介入处理，从而有效避免因资源竞争导致的端到端时延长尾，保障业务连续性与系统稳定性。&lt;/p&gt; 
&lt;p&gt;以 1000TPS 规格的基础集群为例（假设收发 TPS 比例为 1:1 也即 50%），客户端视角下的限流行为：&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;说明&lt;/strong&gt; | &lt;strong&gt;发送消息限流&lt;/strong&gt; | &lt;strong&gt;消费消息限流&lt;/strong&gt; | | ------------ | ------------ | ------------ | | 触发限流情景 | 所有连接该集群的发送客户端每秒最多可发送 TPS 总和为 500 条，发送速率达到限制后，超限的发送请求会失败。 | 所有连接该集群的消费客户端每秒最多可消费 TPS 总和为 500 条，消费速率达到限制后，消息的消费延迟会增加。 | | 触发限流时 SDK 日志关键词 | com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40) | 消费超过阈值以后，客户端使用 BasicGet 拉取消息时，会出现：com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 31436823332424324] Action: BasicGet rate limited by cluster rate limiter vhost: xxx. queue: xxx.当客户端使用 BasicConsume 消费消息时，服务端会抑制向客户端 DeliverMessage 的速率，客户端不会感知到明显的 Channel 断开的错误，整体表现为类似 AMQP 协议消费者 QOS 的行为，会抑制推送到消费者消息的速率，此时消费延迟会增加，可以通过调整限流比例或者增大购买的 TPS 来解决。消费的总 TPS 主要由 BasicGet 和 DeliverMessage 的调用 TPS 次数共享。 | | 触发限流时 SDK 重试机制 | 客户端 SDK 业务侧需要处理连接断开的行为，需要对发送错误被限流的消息重新建立 Channel 连接然后进行发送重试。 | 客户端 SDK 业务消费侧会感知到延迟增加。若使用拉取 BasicGet 拉取消息，会感知到 Channel 连接断开，需要业务上主动重试。 |&lt;/p&gt; 
&lt;h2&gt;详细设计与实现&lt;/h2&gt; 
&lt;h3&gt;架构设计&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用双模式限流架构，兼顾节点级保护与集群级协同：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;单机限流（Node-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用于节点级资源保护，通过限制 CPU、内存、线程等关键资源的使用，防止单节点因过载导致服务不可用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分布式限流（Cluster-Level Throttling）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于集群全局视角，通过多节点流量协同管理，保护共享存储资源（如 Broker）及后端系统稳定性。该模式通过使用分布式限流系统实现。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cab8876ba86ab2c10b491074cac992a20d0.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;限流实现&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版通过在计算层 （TDMQ RabbitMQ Serverless 版集群）接入分布式限流系统实现集群级读写流量控制，其核心机制是：TDMQ RabbitMQ Serverless 版集群节点在处理 BasicPublish / BasicGet / DeliverMessage 请求前，需通过集成的限流 SDK 向限流 Server 异步上报与申请 Token。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;生产端限流&lt;/strong&gt; ：若 BasicPublish 申请失败，则立即拒绝生产消息请求并返回错误。 &lt;strong&gt;消费端限流&lt;/strong&gt;：若 BasicGet 申请失败，则立即拒绝拉取消息请求并返回错误。若 DeliverMessage 申请失败，则抑制推送到消费者的消息速率，实现消费端不断连接的流控，此时类似于 RabbitMQ 开源的实现，此时该消费者处于 Flow 状态。&lt;/p&gt; 
&lt;p&gt;TDMQ RabbitMQ Serverless 版集群内部集成限流 SDK，该 SDK 提供 Token 申请 API，并负责与限流 Server 通信，通过这种集中式 Token 管理实现对核心存储层 (底座 Broker 集群) 的保护。&lt;/p&gt; 
&lt;h3&gt;限流实现难点一：如何平衡性能与精度&lt;/h3&gt; 
&lt;p&gt;使用 TDMQ RabbitMQ Serverless 版的各类在线业务通常对时延比较敏感，如果计算层节点处理每次读写请求都执行一次 Limiter RPC 调用（SDK -&amp;gt; Server）的话，虽然 Limiter Server 内部处理耗时几乎可以忽略，但两次 RPC 的网络 IO 耗时对消息端到端时延的影响是不能忽视的。&lt;/p&gt; 
&lt;p&gt;实际上从服务端的角度看， TDMQ RabbitMQ Serverless 版执行限流的主要目的是防止核心存储层过载，而非追求 100% 精准的流量控制，即 SDK 与 Server 之间的强同步并不是必须的。因此，为了在限流性能和限流精度之间取得平衡，Limiter 采用了一种【先消费后结算】的 Token 管理机制，Token 申请过程在限流 SDK 内部闭环，SDK 会周期性（周期大概在 50ms 以内，上报周期越短，限流越敏感）地向限流 Server 异步上报 Token 使用量并同步配额。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版的限流机制通过以下四大核心特性，在保障系统稳定性的同时实现高性能与低时延的平衡：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;内存级处理，主链路零干扰&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;执行机制&lt;/strong&gt;：限流判断为纯内存操作，不涉及外部 RPC 调用，确保消息处理流程完全不受阻塞。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能优势&lt;/strong&gt;：主链路延迟无感知，适用于对响应时间要求严苛的在线业务场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;先消费后结算，消除误限流风险&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;设计原理&lt;/strong&gt; ：采用异步 Token 核销机制，客户端可先执行操作，限流 SDK 后续异步周期性同步配额消耗。 &lt;strong&gt;效果保障&lt;/strong&gt;：杜绝因限流判断延迟导致的正常请求被误拒，确保业务连续性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;短暂超限容忍，资源缓冲池兜底&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;场景说明&lt;/strong&gt; ：在流量毛刺等突发场景中，可能出现瞬时配额超限，由于先消费后结算的机制导致。 &lt;strong&gt;容错机制&lt;/strong&gt;：通过服务端资源预留 Buffer 吸收流量波动，避免因短暂超限触发系统风险。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;弹性容错设计，弱耦合架构保障可用性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;故障降级策略&lt;/strong&gt; ：当限流 Server 服务异常时，系统自动切换至单机 Sentinel 组件实现基础单机限流功能。 &lt;strong&gt;依赖特性&lt;/strong&gt;：对限流 Server 服务实现弱耦合架构，可以通过随时动态降级来避免限流 Server 服务异常导致的服务异常，确保分布式限流服务的高可用。&lt;/p&gt; 
&lt;h3&gt;限流实现难点二：如何平滑限流毛刺&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版采用 TPS 作为集群规格单位，用于衡量集群的吞吐能力。例如，1000TPS 表示集群每秒可处理 1000 条 TPS（即综合生产、消费等操作的加权计算）。在分布式限流系统中，这一规格对应每秒分配 1000 个 Token，其中 "一秒"即为默认的限流计数周期，用于动态控制流量配额。&lt;/p&gt; 
&lt;p&gt;在使用限流服务的实际运维中发现：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短周期（如 1 秒）&lt;/strong&gt;： 优势：对流量波动敏感，可快速响应潜在过载风险； 缺陷：易因短暂毛刺误触限流，影响正常业务波动场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;长周期（如 10 秒）&lt;/strong&gt;： 优势：容忍毛刺，降低误控率； 缺陷：服务端资源需承受更高瞬时冲击风险。&lt;/p&gt; 
&lt;p&gt;为平衡流量控制精度与用户体验，腾讯云 TDMQ RabbitMQ Serverless 版将默认限流计数周期从 1 秒调整为 10 秒。这样既降低了用户因毛刺导致的限流困扰，又通过利用少量的服务器预留资源 Buffer 来承载瞬时流量冲击，为高并发场景下的消息处理提供了可靠的支撑。&lt;/p&gt; 
&lt;h3&gt;限流实现难点三：如何实现消费端限流&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版集群使用 AMQP 协议与客户端交互，然而 AMQP 协议中并没有定义很好的处理 Fail-Fast 限流错误的帧，因此在发送消息被限流的情况下，只能通过关闭 Channel 连接来通知到客户端，此时客户端会收到相应的 AlreadyClosedException 异常，然后业务需要通过重试来解决当前时间窗口内消息发送被限流的问题。&lt;/p&gt; 
&lt;p&gt;而在消费端限流的情况下，分为两种情况，AMQP 协议中支持两种消费模式，BasicGet（拉模式) 和 BasicConsume（推模式）。 此时对消费端的限流就需要考虑消费的连续性和延迟。针对 BasicGet 模式，是客户端发起的主动同步拉取消息的命令，此时客户端每一次拉取消息是可以直接感知到是否被限流的，更好的方式是通过关闭连接来让客户端感知到限流，从而让业务上通过重试来解决拉取当前时间窗口内消息消费被限流的问题。&lt;/p&gt; 
&lt;p&gt;但是针对 BasicConsume（推模式）, 同时也是 AMQP 客户端最普遍的使用方式，考虑到客户端开启一个长连接监听相应队列上的消息，此时如果因为限流粗暴地关闭 Channel 连接, 此时的客户端往往不能实时感知到连接 Channel 断开，增加了客户端业务上处理的复杂度，同时消费侧重建 Channel 连接也会让消费流量充满毛刺和消费延迟增加。因此腾讯云 TDMQ RabbitMQ Serverless 版在推模式下使用消费抑制的方式来实现消费端限流，当消费 TPS 超过阈值时，会减少推送到客户端的频率，保证了在连接 Channel 不断开的情况下，消费流量的平稳，尽量减少因为限流导致的消费延迟。&lt;/p&gt; 
&lt;h2&gt;客户端实践教程&lt;/h2&gt; 
&lt;h3&gt;规划集群限流负载&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版的限流机制旨在保障服务稳定性与可靠性。防止在集群高负载时出现服务响应长尾毛刺，最终导致请求成功率下降，业务受损等问题。因此，在接入时建议：客户侧需要提前规划集群负载，依据当前规模和未来趋势预测来充分评估业务 TPS， 如果业务流量具有波动特性，应以峰值 TPS 为准，根据相应的评估后的 TPS 购买相应规格的实例集群。&lt;/p&gt; 
&lt;h3&gt;限流相关告警配置&lt;/h3&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版默认接入了腾讯云监控的能力，可以利用腾讯云 TDMQ RabbitMQ Serverless 版控制枱的监控告警能力实现对集群负载的实时观测，提前发现 TPS 水位风险并及时操作升配来避免触发限流导致业务受损。告警策略建议：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;发送和消费 TPS 水位超过容量的 70% 时触发告警，提醒进行升配评估。&lt;/li&gt; 
 &lt;li&gt;出现发送限流时触发告警，警告业务发送消息可能失败风险。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;客户端限流异常处理&lt;/h3&gt; 
&lt;p&gt;业务代码通过 RabbitMQ SDK 发送消息时，需要捕获包括限流错误在内的异常，并保存必要的上下文信息，以便人工介入恢复业务。当腾讯云 TDMQ RabbitMQ Serverless 版实例的 TPS 流量峰值超过腾讯云控制枱所购买实例的 TPS 规格上限时，业务侧生产消费流量会被限流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;限流后的行为如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版服务端会返回错误码信息。&lt;/p&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版服务端关闭当前请求的 Channel 连接，代码中可以捕获异常并重新打开 Channel 连接，具体请参见错误码处理示例代码章节。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;错误码信息&lt;/strong&gt;： 错误码：reply-code=530&lt;/p&gt; 
&lt;p&gt;错误信息：reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:xxx reason:PublishMessage, class-id=60, method-id=40)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;错误堆栈&lt;/strong&gt;：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Suppressed: com.rabbitmq.client.AlreadyClosedException: channel is already closed due to channel error; protocol method: #method&amp;lt;channel.close&amp;gt;(reply-code=530, reply-text=[requestId: 3143682333552716694] Action: pub rate limited by cluster on instance:amqp-autotest reason:PublishMessage, class-id=60, method-id=40)
at com.rabbitmq.client.impl.AMQChannel.processShutdownSignal(AMQChannel.java:437)
at com.rabbitmq.client.impl.ChannelN.startProcessShutdownSignal(ChannelN.java:295)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:624)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:557)
at com.rabbitmq.client.impl.ChannelN.close(ChannelN.java:550)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.lambda$close$0(AutorecoveringChannel.java:74)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.executeAndClean(AutorecoveringChannel.java:102)
at com.rabbitmq.client.impl.recovery.AutorecoveringChannel.close(AutorecoveringChannel.java:74)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RabbitMQ AMQP Java SDK 业界使用的比较广泛，因此使用该 SDK 作为示例，RabbitMQ AMQP Java SDK 不会对限流错误进行自动重试，因此业务代码需要捕获异常并进行处理，示例代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;private static final int MAX_RETRIES = 5; // 最大重试次数
private static final long WAIT_TIME_MS = 2000; // 每次重试的等待时间（以毫秒为单位）
private void doAnythingWithReopenChannels(Connection connection, Channel channel) {
    try {
        // ......
        // 在当前通道 channel 下执行的任何操作
        // 例如消息发送、消费等
        // ......
    } catch (AlreadyClosedException e) {
        String message = e.getMessage();
        if (isChannelClosed(message)) {
            // 如果通道已经关闭，关闭并重新创建通道
            channel = createChannelWithRetry(connection); 
            // 在重连后可以继续执行其它操作
            // ......
        } else {
            throw e;
        }
    }
}
private Channel createChannelWithRetry(Connection connection) {
    for (int attempt = 1; attempt &amp;lt;= MAX_RETRIES; attempt++) {
        try {
            return connection.createChannel();
        } catch (Exception e) {
            System.err.println("Failed to create channel. Attempt " + attempt + " of " + MAX_RETRIES);
            // 检查错误, 若仍是被限流导致的关闭错误，则可以等待后继续重试
            // 也可移除本部分重试逻辑
            if (attempt &amp;lt; MAX_RETRIES) {
                try {
                    Thread.sleep(WAIT_TIME_MS);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt(); // 还原中断状态
                }
            } else {
                throw new RuntimeException("Exceeded maximum retries to create channel", e);
            }
        }
    }
    throw new RuntimeException("This line should never be reached"); // 理论上不会到达这里
}
private boolean isChannelClosed(String errorMsg) {
    // 判断是否包含 channel.close 报错，该报错代表通道已关闭。
    // 可能涵盖 530，541 等错误信息。
    if (errorMsg != null &amp;amp;&amp;amp; errorMsg.contains("channel.close")) {
        System.out.println("[ChannelClosed] Error details: " + errorMsg);
        return true;
    }
    return false;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;腾讯云 TDMQ RabbitMQ Serverless 版通过分布式限流架构为在线业务提供高可用的消息服务保障。在分布式限流模式下，服务端通过集中式 Token 管理系统（限流 Limiter）动态分配资源配额，防止因突发流量冲击导致核心存储层（底座 Broker 集群）过载来提高系统稳定性，同时采用 【先消费后结算】的异步处理模式，客户端在限流 SDK 内部闭环完成 Token 申请，避免阻塞主链路，确保限流调用接口低延时，限流 SDK 周期性同步 Token 消耗数据至限流 Server，最终平衡了限流精度与调用限流服务的性能开销。同时针对消费端的限流可以实现不断 Channel 连接，实现了消费端在限流毛刺与消费延迟之间的双重保证，此外，面对限流 Server 服务不可用的情况，系统能够自动动态降级为单机限流模式，确保客户端请求的连续性，保持对限流服务的弱依赖设计来实现系统解耦。&lt;/p&gt; 
&lt;p&gt;在实际应用与运维中，同时也需要客户业务方的配合，在接入腾讯云 TDMQ RabbitMQ Serverless 版服务时，业务方客户需要根据业务规模和未来趋势合理规划集群，预留足够的 TPS 配额以应对突发流量，防患于未然。同时腾讯云 TDMQ RabbitMQ Serverless 版提供了服务端完善的监控和告警，支持客户通过监控告警能力实时订阅集群负载，提前发现 TPS 水位风险并及时进行升配等操作。在客户端业务代码层面，需要捕获限流异常并处理，保证代码的健壮性，同时保存必要的上下文信息，以便人工查看相关日志最终介入来恢复业务。&lt;/p&gt; 
&lt;p&gt;通过本文对腾讯云 TDMQ RabbitMQ Serverless 版的限流机制的介绍与实践教程，相信读者对腾讯云 TDMQ RabbitMQ Serverless 版的限流机制有了更深入的理解，并能够在实际项目中灵活应用，最终为业务的高并发、大流量场景提供稳定的支持。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4587289/blog/18638288</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4587289/blog/18638288</guid>
      <pubDate>Sat, 10 May 2025 07:34:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>百度搜索迎来十年来最大改版：AI 智能框、百看、AI 助手全面进化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在近日的百度 AI Day 开放日上，百度搜索宣布进行了其十年来最大规模的改版，此次革新涵盖了搜索框、搜索结果页以及整个搜索生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="262" src="https://oscimg.oschina.net/oscnet/up-98d15d20c6065a79b817c094d1a37c4066c.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;升级后的百度搜索框被命名为「智能框」，显著增强了其输入能力，现在可支持超过千字的文本输入。同时，拍照、语音、视频等多种输入方式也得到全面加强，并能直接调取 AI 写作、AI 作图等创作工具，极大地丰富了用户与搜索的交互方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「百看」功能也在此次改版中实现了全面升级，不仅支持图文、音视频的混合内容输出，还创新性地接入了智能体和真人服务等功能，旨在提供更丰富、多元的信息呈现形式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「AI 助手」的升级是本次改版的另一大亮点，新增了视频通话功能，并显著提升了多模态输入、富媒体输出、一站式工作台及深度搜索能力，使其成为更全面的 AI 辅助工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，智能创作能力也得到大幅提升，用户现在只需一句话即可生成三分钟的创意视频，并支持分镜编辑和自定义画面内容。截至目前，百度搜索开放平台已成功接入 1.8 万多个优质 MCP（多媒体内容提供商），使其成为国内最大的 AI 生态系统。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;值得一提的是，此次百度搜索还接入了商业研发团队自研的视频生成模型 MuseSteamer 及其创作平台「绘想」。据了解，MuseSteamer 是全球首个实现中文音视频一体化生成的视频模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358379</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358379</guid>
      <pubDate>Sat, 10 May 2025 07:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
