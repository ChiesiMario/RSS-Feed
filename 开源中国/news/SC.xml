<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 11 Jun 2025 07:44:00 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>开源网盘应用 Alist 原开发者称项目已交由公司运营</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免费开源、支持多存储的自建网盘程序 (文件列表程序)，可以轻松在 VPS 服务器、NAS、普通电脑 Win、Mac、Linux 上部署。它除了能作为一款自建网盘 (将文件保存在设备硬盘上) 外，最大的特色就是支持「挂载各大主流网盘」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在该项目 GitHub 仓库提交 issue，反馈官网出现 404 问题，并提出」项目是否被卖了」的疑问。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原开发者 Xhofe 今日在订阅频道发布公告，&lt;strong&gt;称项目已交由公司运营&lt;/strong&gt;，之后会帮助审查开源版本仓库的代码，确保 release 分支由 CI 自动构建。此外&amp;nbsp;main 分支已开启分支保护，后续所有提交均需经过 PR 审核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Wed, 11 Jun 2025 07:06:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式发布了豆包大模型 1.6、豆包·视频生成模型 Seedance 1.0 pro、豆包·语音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新发布的豆包大模型 1.6 系列由三个模型组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的综合模型，是国内首个支持 256K 上下文的思考模型，支持深度思考、多模态理解、图形界面操作等多项能力。支持选择开启或关闭深度思考、自适应思考三种方式，其中自适应思考模式可根据提示词难度自动决定是否开启思考，提升效果的同时大幅减少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的强化版本；在代码、数学、逻辑推理等基础能力上进一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的极速版本，支持深度思考、多模态理解、256K 上下文；延迟极低，TOPT 仅需 10ms；视觉理解能力比肩友商旗舰模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在价格方面，&lt;strong&gt;豆包大模型 1.6 采用统一定价模式，首创按「输入长度」区间定价&lt;/strong&gt;，在企业使用最多的输入区间 0-32K 范围内，豆包大模型 1.6 的价格为输入 0.8 元/百万 tokens、输出 8 元/百万 tokens，综合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相当于每生成一条 5 秒的 1080P 视频只需 3.67 元，行业最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·实时语音模型已全量上线火山方舟，对企业客户开放使用。该模型支持自然语言高级指令控制，具备唱歌表演、声线模仿、方言演绎等多种能力，语气、用语、思考方式等拟人感大幅提升，能随时打断与主动搭话。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sun, 11 May 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供为期两周的免费 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 与 AI 代码工具开发商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，为 Cline 用户提供为期两周的 Grok 3 模型免费访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需注册 Cline 账户，即可在 Cline 的提供商中选择并免费使用 x-ai/grok-3 模型进行编码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是开源 AI 编程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 双模式，具有终端执行能力和 Model Context Protocol (MCP) 特性。它能够分析用户的项目文件结构、源代码等，帮助用户创建和编辑文件、执行终端命令、使用浏览器进行测试等，还可以通过 MCP 协议扩展其功能，添加自定义工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sun, 11 May 2025 06:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TickIt：基于 LLM 的自动化 Oncall 升级</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  资料来源：
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-开发者社区&lt;/a&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  软件工程领域顶级学术会议之一 FSE 2025（The ACM International Conference on the Foundations of Software Engineering）预计将在 2025 年 6 月于挪威特隆赫姆举行，字节跳动 ByteBrain 团队的论文《TickIt: Leveraging Large Language Models for Automated Ticket Escalation》成功入选
 &lt;/div&gt; 
 &lt;div&gt;
  （https://arxiv.org/abs/2504.08475）。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  背景
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在云计算技术蓬勃发展的当下，对于火山引擎来说，工单/Oncall 成为了客户与技术支持&amp;amp;SRE 团队沟通的关键桥梁。随着云服务规模的不断扩大，每日会产生数以千计的 Oncall。这些 Oncall 通常以自然语言的形式，涵盖了使用咨询、功能需求，系统故障等各类复杂问题。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在传统的手动升级模式下，Oncall 值班人依赖个人经验判断工单是否严重，进而决定是否应该进一步升级。这一过程很依赖值班人员的经验判断，也难以形成统一标准。在过往的案例研究与故障覆盘中，我们发现由于人为疏漏，部分严重问题没有及时升级处理，从而导致了稳定性下降的风险，这也可能对火山引擎的客户满意度造成负面影响。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  如何在面对紧急问题时，及时识别并升级这些 Oncall，成为了提升客户满意度和保障服务质量的关键所在。针对这一问题，我们提出了 TickIt，旨在识别紧急的、报告严重问题的 Oncall，并及时地将其升级给产研/稳定性/故障应急等团队。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  挑战
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Oncall 问题具有显著的多样性，不同类型的问题需由不同专业背景的人员进行处理。例如，系统故障需要产研&amp;amp; SRE 迅速定位并修复，以减少服务中断时间；客户投诉以及负面情绪则需要客户经理及时安抚客户并解决问题，进而提升客户满意度。进一步来说，Oncall 问题还可进一步细分，例如判断其影响面大小、是否对业务有损等。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  现有的基于特征工程的分析方法，对 Oncall 内容的语义理解能力也较为有限，在实际应用中难以准确识别关键问题，致使重要 Oncall 无法及时升级处理。此外，Oncall 的严重程度也可能在对话过程中被（动态地）逐步澄清，而一些现有方法仅进行一次性分类，忽略了对话中不断更新的信息，无法在线及时识别到需要升级的情况。
 &lt;/div&gt; 
 &lt;div&gt;
  此外，挖掘 Oncall 之间的关系同样重要。当一个问题影响多个客户时，会产生多个相似的 Oncall。如果能及时捕获分析这些 Oncall 之间的关系，有助于更全面地评估问题的严重性与影响范围，而对于产研来说，可以合并这些 Oncall 共同处理，从而更加聚焦地解决问题。
 &lt;/div&gt; 
 &lt;div&gt;
  得益于大语言模型（LLM）在自然语言理解方面的强大能力，我们将其用于辅助理解 Oncall 中的文本信息，但是简单使用 LLM 并不能真正有效的解决上述挑战。在本文中，我们提出了基于 LLM 的 Oncall 分析方法 —— TickIt，该方法可以动态追踪 Oncall 中的信息，还能借助 LLM 深入理解 Oncall 对话的语义内容，及时识别严重问题并升级。同时，TickIt 还能挖掘不同 Oncall 问题现象之间的语义关联，识别潜在的共性问题，实现更高效的问题处理。
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 使用了字节的豆包（doubao）模型，旨在借助大语言模型（LLM）强大的自然语言处理能力，实现高效、准确的 Oncall 升级任务。该框架主要包含基于多分类的 Oncall 升级（Multi-class escalation）、重复 Oncall 分析 (Escalation deduplication) 和基于类别引导的微调（Category-guided fine-tuning）这三个核心功能模块。
 &lt;/div&gt; 
 &lt;div&gt;
  基于多分类的 Oncall 升级
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a38b4514cb694357dbd5a996f44a3ba2.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在 Oncall 升级功能中，TickIt 将 Oncall 升级问题视作多分类任务。依据产研&amp;amp; SRE &amp;amp;客户关系的不同职责和关注重点，预先定义了系统故障、客户投诉、资产损失等多种主题类别。而对于普通 Oncall，统一归为 「其他」 类别（无需升级处理）。为使大语言模型更好地完成 Oncall 多分类任务，TickIt 也在 System Prompt 中采用了一些技术来提升其分类表现，例如赋予其任务角色、思维链（COT）等。例如，在判断一个 Oncall 是否属于系统故障时，模型会分析对话内容中提到的故障现象、影响范围等因素，并逐步解释做出该分类决策的原因。这种方式增强了分类结果的逻辑性和可解释性，让人们更易理解和信任模型的判断。此外，TickIt 通过 Few-shot learning，辅助模型理解不同的 Oncall 类别。这些示例特别对易混淆的场景进行了举例示范，从而帮助模型更准确地区分各类 Oncall 的特征。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 采用在升级任务中所采用的 System Prompt 格式如下图所示：
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a83ba70159b8a333261baa7c65e4b07e.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 分析
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//3ded1921020057de79c7cfbcfdbb01bd.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 分析是 TickIt 的另一个功能。当一个 Oncall 被判定需要升级时，TickIt 会对所有处于「Pending」状态的 Oncall 进行检查，以确定是否有类似问题已被升级。为此，TickIt 将 Oncall 在其生命周期中的状态抽象为有限状态机。当客户提交 Oncall 工单并被接受后，该 Oncall 对象进入 「Active」 状态。每当 Oncall 中有新的对话内容时，最新的对话记录会触发 TickIt 启动新一轮分析，此时将其设置为进入 「Analyzing」 状态。TickIt 会运用上述的基于多分类的升级方法，判断当前 Oncall 是否需要升级。如果被分类为 「其他」，则其状态返回 「Active」，等待下一轮对话交互；若被分类为预设好的严重问题类型中，则进入 「Pending」 状态，此时 TickIt 会检查是否有相似的 Oncall 已经被升级。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在判断 Oncall 是否重复时，TickIt 首先利用大语言模型提取 Oncall 中的问题描述，并借助 doubao-embedding model 将这些问题描述转化为向量表示。通过 consine similarity 来计算向量之间的相似度，并通过一个阈值参数 𝜃 来判断当前 Oncall 与已升级的 Oncall 是否相似（𝜃 通过参数选择实验确认，在本方法中 𝜃=0.88）。对于 TicketIt 判定当前需要升级的 Oncall，如果历史已有升级且相似的 Oncall，则会将当前 Oncall 与对应的历史 Oncall 进行关联，并不再重复告警（仅在关联工单中体现）。同时，TickIt 会将当前 Oncall 与已重复会利用大语言模型重写问题描述，从语义上更全面地归纳该类问题的共性特征，避免因个别 Oncall 工单描述的局限性而导致对问题的理解偏差。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  基于类别引导的微调
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//9a20ab7d348eaba17524ba79b94e8374.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  类别引导的微调是 TickIt 不断优化准确率的关键机制。当一个 Oncall 按照上述的流程被升级后，TickIt 会发送包含 Oncall 问题摘要的提醒通知卡片。通知卡片中有三个交互按钮，其中两个分别用于点赞或点踩；第三个按钮则是一个 Oncall 跳转链接，点击后可直接跳转到相关的聊天群中。TickIt 则会记录下这些通知卡片的交互行为作为自动升级的反馈数据。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//74dd763b0ca8e181846e69dffbc00e72.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在处理这些反馈数据时，TickIt 采用监督微调（SFT）方法，一条典型的 SFT 数据同时包含「对话内容」（Oncall 原始信息），「LLM 思考过程与类别判断」（LLM 的输出）。并按照 TickIt 用于 Oncall 升级任务的 System Prompt 来进行组织成数据集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  我们对四种反馈动作设置了不同的优先级，以避免同一 Oncall 下存在冲突的反馈。其中直接反馈（点赞、点踩）都会被纳入 SFT 的数据集中。根据我们的观察，相较于正面反馈（点赞）人们通常会在 Oncall 升级错误时更倾向提供一些负面反馈（点踩）。因此，点赞的数量要远小于点踩，也正是出于此原因，我们将点赞的优先级设置为最高（至少有一个人认为该告警是有帮助的）。而对于点踩的反馈来说，通常是认为误告警，因此则将其目标类别设置为「其它」（如无指定类别说明）。在该情况下，由于仅仅知道目标类别，而缺乏 COT 所需要的推理步骤，TickIt 则利用大语言模型完成目标分类下思维链步骤的补充。考虑到思维步骤的多样性，TickIt 会对每个 Oncall 进行三次可能思维链步骤的采样，以丰富数据集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  通过这种方式，TickIt 能够处理用户反馈，并基于类别引导进行数据增强，最终构建出一个高质量的标注数据集。当积累了足够数量的标注数据后，TickIt 会运用 SFT 方法对模型进行离线优化，然后更新在线模型，从而不断提升模型在升级分类任务上的性能表现。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 的实验验证
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 在火山引擎的线上进行了全面部署，并取得了显著成效。在此期间，TickIt 共处理了数以万计的 Oncall。在收到的反馈中，约 81% 的反馈表明 TickIt 的升级决策是准确的，这也证明了 TickIt 在实际应用中的有效性和可靠性。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在进一步的 Oncall 升级性能评估方面，我们还对比了基于小语言模型（SLM）和大语言模型（LLM）的多种方法。小语言模型受限于参数规模，其语言理解能力相较 LLM 有较大差距，且部分非端到端的方法设计在信息传递过程中易出现信息丢失的情况。而基于 LLM 的方法则展现出了良好的准确率。我们通过消融实验验证了不同框架设计对模型性能的影。使用 CoT 的 LLM 方法，准确率和召回率均能达到 82% 左右。在此基础上，结合反思（Reflection）提示，模型能够对自身的推理和输出进行自我纠正，精度略微提升至 82.8%。但由于 CoT 提示已经使模型在得出结论前进行了充分的推理，在反思阶段模型难以获取新的关键信息来进一步提高输出的准确性和洞察力，因此反思技术对实验结果的提升效果并不显著。引入上下文学习（ICL）提示后，模型的召回率大幅提升至 89.2%，尽管精度略有下降，但这一结果充分体现了 LLM 方法强大的泛化能力。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//8b040985eb15eb72e4893c729c56be70.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在不同方法设计下的 Oncall 升级比较
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  进一步对 LLM 进行监督微调（SFT）后，模型性能得到了显著提升。以 CoT 提示为例，微调后的召回率从 82.1% 大幅提高到 91.2%，同时保持了 81.8% 的较高精度，F1 分数达到了 86.2%，在所有对比方法中表现最佳。这一结果有力地证明了 SFT 在利用 LLM 能力提升 Oncall 升级任务性能方面的有效性。然而，当 SFT 与其他基于提示的方法（如 Reflection 和 ICL）结合时，性能出现了轻微下降。这可能是因为 SFT 过程中使用了 ICL 中的一些样本或与训练数据分布相似的数据，使得模型在离线微调时已经学习了相应内容，从而在结合使用时产生了一定的冲突。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在重复 Oncall 分析的实验中，通过调整相似度阈值来探寻最合适的参数，该参数在 0.86 - 0.95 之间时，F1 分数会随着参数的升高先上升后下降。当其设置过高时，严格的相似度约束可能会导致相似问题被错误分类到不同类别，使得评估结果中升级 Oncall 的数量相较于真实情况出现偏差，且该偏差与阈值并非单调关系。此外，基于问题现象的去重方法本身存在一定局限性，对于表现相同但根因不同的 Oncall，可能会出现错误去重的情况。而在针对 Oncall 问题重写的设计中，我们也进行了消融实验。实验结果表明，开启重写功能的 TickIt 相较于未开启该功能的实验设置来说，F1 分数提升了 1.7%。进一步对数据集进行分析，仅保留包含多个关联 Oncall 的升级进行实验，结果显示 TickIt 中的重写设计使得其 F1 分数从 0.706 提升至 0.749，提升幅度达到 6.1%。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//f44da441270f9c510f3972871725a119.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 识别下的参数选择实验
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//685b195201866bfe500add599463e6ee.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Ticket 在重复 Oncall 识别下的问题重写消融实验
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  总结与局限性分析
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 借助大语言模型实现了高效的自动化 Oncall 升级，为火山引擎带来了显著的效率提升。它从「帮助人们及时介入严重 Oncall」的角度，帮助火山引擎缩短了严重问题的响应时间，使得整体的 MTTR 降低了约 26%，并节约了人力投入成本。同时，TickIt 也得到了使用者的广泛认可。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  然而，TickIt 在实际应用中也暴露出一些局限性。对话中（个性化的）表达方式可能会对大语言模型的判断产生影响。例如，部分使用者可能会夸大问题的影响，导致不必要的升级；而有人也可能对严重问题描述过于平淡，使得 TickIt 未能及时识别出需要升级的情况。此外，如果 Oncall 所关联的云服务产品不够具体，相似的问题描述可能会因涉及不同的云服务产品而具有不同的严重程度，这容易导致大语言模型的误判，进而出现错误的升级。我们在后续的工作中会进一步优化 TickIt 的实际效果，助力火山引擎的稳定性工作。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  作者团队： 我们来自字节跳动的 ByteBrain 团队，我们致力于用 AI 技术，为各种基础架构与系统（数据库、云原生、大数据、网络等）降本增效、提升稳定性。
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354786</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354786</guid>
      <pubDate>Sun, 11 May 2025 03:46:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再获数千万美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣布再次完成数千万美元的 Pre-A+轮融资，同时正式发布了全球首个 AI 驱动的一站式 3D 工作台 Tripo Studio，并即将推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;据称此次融资将重点投入 Tripo 系列大模型研发及 Tripo Studio 产品及生态平台建设，加速构建「AI+3D」全产业链条，打造「基础模型 + 生态插件 + 原生工作台」的端到端产品体系，从而构建覆盖专业级（PGC 生产者）、达人级（PUGC 创作者）到大众级（UGC 用户）的创作者画像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，VAST 成立于 2023 年 3 月，是一家专注于通用 3D 大模型研发的 AI 公司，致力于通过打造大众级 3D 内容创作工具建立 3D UGC 内容平台，使基于 3D 的空间成为用户体验升级、内容表达创新和新质生产力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持续迭代 Tripo 大模型，先后推出 Tripo1.0 至 Tripo2.5 等数十亿参数规模的 3D 大模型系列，同时发布 TripoSR、TripoSG、TripoSF 等广受全球开源社区认可的 3D 基础模型，并配套开发了系列 3D 软件生态插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新开源：通用自动骨骼绑定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 开源基础 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sun, 11 May 2025 03:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 Kendo UI 在实战应用 —— 打通数据链路，重塑业务效率</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在制造与供应链行业应用——打通数据链路，重塑业务效率" src="https://oscimg.oschina.net/oscnet//009b6caaeed5461884780886e08eac09.jpg" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 在制造与供应链行业中，企业通常面对「信息孤岛」、「任务难协同」、「实时数据难可视」等挑战。
 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;作为一套成熟的 Web 界面控件解决方案，凭借其丰富的组件库与卓越的数据交互能力，已成为制造系统中构建高效、清晰、可操作用户界面的有力工具。
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;是带有 jQuery、Angular、React 和 Vue 库的 JavaScript UI 组件的最终集合，无论选择哪种 JavaScript 框架，都可以快速构建高性能响应式 Web 应用程序。通过可自定义的 UI 组件，Kendo UI 可以创建数据丰富的桌面、平板和移动 Web 应用程序。通过响应式的布局、强大的数据绑定、跨浏览器兼容性和即时使用的主题，Kendo UI 将开发时间加快了 50%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行业关键痛点与挑战&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 生产排程混乱，难以动态调整&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;排产表手工维护，任务依赖关系不清晰；&lt;/li&gt; 
 &lt;li&gt;一旦生产任务调整，工序安排需人工同步，极易出错。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 物料与库存信息分散，数据透明度低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原材料、在制品、半成品和成品数据分布于不同系统；&lt;/li&gt; 
 &lt;li&gt;缺乏统一视图，容易导致缺料、积压或发错货。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 设备利用率、产能瓶颈难以量化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;设备运转状态、停机时间、工单完成率难以直观掌握；&lt;/li&gt; 
 &lt;li&gt;管理层缺乏实时运营看板支撑决策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多角色协同效率低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;采购、仓储、生产、质检等部门使用界面风格不一致；&lt;/li&gt; 
 &lt;li&gt;操作体验差，培训成本高，数据流转阻断。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Kendo UI 提供的关键解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 精准的生产排程与任务可视化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gantt Chart 控件&lt;/strong&gt;：可视化呈现排程计划，支持任务依赖、拖拽重排、进度条展示，帮助排程人员动态优化排产逻辑。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduler 日历控件&lt;/strong&gt;：用于设备维护排程或产线预约，支持多资源并发视图。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 统一的库存数据展示与交互操作&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Grid + 分组 + 分页 + 导出功能&lt;/strong&gt;：构建灵活的物料清单、库存看板，支持层级显示与动态筛选。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TreeView + PanelBar&lt;/strong&gt;：适用于多仓库、多区域的库存结构导航。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AutoComplete / MultiSelect&lt;/strong&gt;：提升物料录入与搜索效率，防止错录错查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 实时可视化的运营监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Charts 图表组件（柱状图、折线图、圆环图等）：展&lt;/strong&gt;示各产线设备的稼动率、生产效率、工单完成情况等关键指标。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sparkline 小型趋势图&lt;/strong&gt;：适用于嵌入表格单元格中，轻量快速展现某项指标走势。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ProgressBar + KPI 指标块组合&lt;/strong&gt;：适合构建实时工厂大屏或车间电子看板。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多端一致的界面交互体验&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;响应式布局组件（ResponsivePanel / Drawer / TabStrip）：&lt;/strong&gt;适配桌面与平板设备，统一各角色使用体验。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload + Dialog + Tooltip + Notification&lt;/strong&gt;：用于上传质检报告、操作提示与反馈，提升人机交互流畅度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;丰富的表单验证机制&lt;/strong&gt;：确保关键业务数据录入安全、准确。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;应用场景示例&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在制造与供应链行业应用——打通数据链路，重塑业务效率" src="https://oscimg.oschina.net/oscnet//181f48127f99e600559a7997cf56e624.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;在数字化制造转型的背景下，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;不仅是「界面构建工具」，更是连接业务流程与数据决策的桥梁。它以高可定制、高性能的前端控件能力，为制造与供应链行业提供了稳定、高效、专业的用户交互解决方案。从排程到仓储、从设备监控到多角色协同，Kendo UI 为企业打造真正可视、可控、可运营的管理界面，助力制造企业迈向数字化高质量发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354778</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354778</guid>
      <pubDate>Sun, 11 May 2025 03:25:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>百度百舸万卡集群的训练稳定性系统设计和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 训练稳定性的演进历程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 竞赛中 AlexNet 的横空出世，开启了现代 AI 发展的新纪元。彼时我们不会想到，十年后支撑 AI 训练的 GPU 集群会从研究室里的几台服务器，发展成需要专门供电系统的万卡级计算矩阵。在这个算力爆发式增长的过程中，训练系统的稳定性管理正经历着从「简单运维」到「精密工程」的深刻变革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 标早期的小模型时代：手动运维的黄金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 训练，更像是手工作坊式的精雕细琢。大多数训练任务只需十几块 GPU，利用 PyTorch 或 TensorFlow 的数据并行功能就能轻松应对。记得那时算法工程师们有个共识：如果训练遇到问题，重启往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;当时我们构建的监控系统就像汽车仪表盘，只能显示最基本的任务状态。当训练意外中断时，工程师们会像侦探一样翻查日志 —— 如果发现是 GPU 报错，就联系运维同事。运维人员则带着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到机房巡检，像老中医把脉般通过温度、功耗等指标判断硬件状态。这种工作模式虽简单，但应对数十卡规模的集群还算游刃有余。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型风暴：从量变到质变的冲击&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登场如同打开潘多拉魔盒，将 AI 训练带入新的纪元。当我们开始部署千卡/万卡集群时，才发现原有的运维体系就像用小渔网捕鲸鱼 —— 完全无法匹配新需求。&lt;/p&gt; 
&lt;p&gt;让我们通过百度百舸经历过的一个真实案例来深入理解这个问题：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸帮助一家 AIGC 创业公司迅速将其训练规模从百卡扩展到千卡级别。然而在训练数天后的某个周末凌晨，训练进程意外发生了 hang 死。由于当时缺乏有效的故障感知和容错机制，直到第二天算法工程师发现任务超时退出时，已经耽误了数小时宝贵的训练时间。更糟糕的是，任务日志中除了简单的 timeout 报错外毫无线索，平台监控也显示所有训练节点状态正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢复训练的算法工程师没有立即上报问题，而是选择直接重新提交任务。但不幸的是，新任务运行数小时后再次出现相同的超时退出。这时他们才不得不寻求技术支持，但值班工程师面对这种任务 hang 死的问题也缺乏诊断经验，只能通过二分法慢慢定位。最终发现是某个节点的静默故障（SDC）导致了训练进程假死。等问题得到解决时，距离首次故障已经过去将近 30 小时，这意味着损失了价值巨大的千卡算力资源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集群训练稳定性全景图&lt;/h1&gt; 
&lt;p&gt;站在现在的时间点回望，AI 训练稳定性已从辅助功能演变为核心基础设施。就像现代建筑中的抗震结构，它虽不直接参与空间构成，却是万丈高楼得以屹立的关键。当行业向着数万卡集群迈进时，这套隐形护甲的质量，将直接决定 AI 进化的速度与边界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸对训练过程的生命周期进行了更细致的拆分，提出了「无效训练时间」这一关键指标，并致力于将其最小化。具体来说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任务无效训练时间 = 故障中断次数 × 任务故障恢复时长 + 任务常态写 Ckpt 总时长&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任务故障恢复时长 = 故障感知召回耗时（自动/人工定位）+ 任务调度耗时 + 任务初始化耗时 + 任务重算时长。&lt;/p&gt; 
&lt;p&gt;通过这个公式可以看出，要降低无效训练时间，需要「围绕基础设施稳定性」、「任务容错」两个维度来系统展开，重点解决三个方面的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基础设施的交付质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任务故障容错的召回率、准确率和时效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化 checkpoint 机制，减少保存时间和恢复时的重算时间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过容错架构的整体变革，百度百舸形成了从 「任务负载 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基础架构」全链路的自动异常感知、诊断、恢复能力，可覆盖 90%+ 的训练异常场景，时效性最快可以实现秒级异常感知、分钟级定位，以及平均 3 分钟的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基础设施交付质量保障&lt;/h1&gt; 
&lt;p&gt;基础设施的交付质量保障是稳定性的基础。&lt;/p&gt; 
&lt;p&gt;CPU 时代，机器的交付前可能仅会跑一些常规的 CPU 计算、网络的压力测试，并不会从业务视角去评估基础架构，机器交付后硬件异常的故障频率相对较少。有硬件故障时，通常走工单系统人工换机用户相对是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 时代，AI Infra 的交付则需要考虑 CPU、GPU、RDMA 网络、存储，甚至机房的功率、温度等各方面因素，遗漏任何一个环节都会成为后续稳定性的隐患。在交付给客户后，机器也可能会由于长时间的高负载运行频繁出现硬件故障，而 GPU 机器的高昂成本，使客户对节点故障感知、换机的时效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸对 GPU 机器交付前及交付后的稳定性质量进行了系统性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸会对机器进行 200 多项指标检测，然后进行 48 小时烤机，以及 NCCL-Test 的机内、机间的大环、同号卡通信性能基准测试，端到端的大模型训练、推理性能基准测试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付后，需要能够实时的感知节点故障及定期巡检，并具备分级处理的自愈能力，例如 Error 级别的故障实现自动排水、重启，Fault 级别故障实现自动换机。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任务容错的准召率保障&lt;/h1&gt; 
&lt;p&gt;任务层面稳定性最核心的就是做好容错，能够让业务在无论遇到何种故障时都能快速恢复。&lt;/p&gt; 
&lt;p&gt;那么，首要的工作就是我们能够准确的识别出异常，然后对故障进行诊断定位，最后能够自动化的从异常中恢复。&lt;/p&gt; 
&lt;p&gt;因此，任务容错需要能够从端侧（即每个训练 worker）探测到进程与环境的各类异常，同时有个中心服务（Master）从任务全局的视角去诊断、定位异常，最终做出相应的决策来使任务能够快速从异常中恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务容错最重要的就是提升故障的召回率与准确率，即如何能够尽可能的准确识别、定位所有故障。我们将故障分类两类：显式故障和隐式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;显式的故障通常比较容易召回，我们将实践积累的各种进程异常状态及各类报错 pattern 形成专家知识库，再结合硬件感知服务（HAS Agent）的硬件全链路 10 秒级监控能力，可以实现显式故障的召回率达到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隐式的异常则往往很难轻易的识别，例如训练进程 hang、慢节点就是典型的隐式故障，需要丰富的经验积累才能准确的识别出异常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我们就以最典型的隐式故障场景 —— 训练进程 hang 死为例，来看下如何能够做好 hang 自动感知、诊断。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 训练****hang 的自动感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;训练任务发⽣ hang 之后，绝⼤多数情况都会以 timeout 的⽅式报错并退出进程，最常⻅的就是在通信过程中如果发⽣ hang，NCCL 的 watchdog 会中断通信，并有报如下 timeout 报错，然后再由 pytorch 的 torchrun 进程感知并中断训练过程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默认为 10 分钟 NCCL 通信超时，而 Megatron-LM 为 30 分钟。在万卡规模训练场景中，意味着一万张卡要至少浪费 30 分钟才能被发现。这个时效性是不可接受的。而且当 30 分钟超时后程序会立马退出，很难有机会进行下一步定位，需要一些时效性更高的感知机制，并且在程序退出前获取一些有效信息供后续诊断分析。&lt;/p&gt; 
&lt;p&gt;很多公司、实验室在面对 hang 的问题时，会在采用框架层插桩的方式来 trace 训练进程，这种方式通常是比较直接且准确的，但是有比较强的侵入性，而且可能还会有一些性能开销。对于云厂商来说，需要寻找对用户更透明、更无损的方式来感知、定位 hang 异常。&lt;/p&gt; 
&lt;p&gt;如何感知训练 hang，以百度百舸的产品设计思路为例，我们可以从以下几个方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练进程 hang 的最直观表现是什么？&lt;/p&gt; &lt;p&gt;人工判断一个任务是否 hang 了，最直接的方式就是看是否所有 worker 的任务日志一段时间内都不输出日志了，所以 hang 自动感知的第一种方法就是采集所有 worker 的日志，并判断所有 worker 日志中最后一行日志是否为 x 分钟前的（x 小于 Pytorch 的通信超时时间，例如 8 分钟），如果是则基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时进程有什么样的表现？&lt;/p&gt; &lt;p&gt;任务 hang 时，可能进程的调用栈都不在发生变化，进程的调用栈可以通过 py-spy/pystack 等工具进行探测，所以我们可以用此类工具对所有训练任务进行一个定时采样，当采集 n 个样本所有进程栈都没有变化时，可以判定一次 hang，这种方式通常可以将 hang 感知缩小至 3～5 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时监控指标有哪些变化？&lt;/p&gt; &lt;p&gt;训练进程中的 CUDA 算子计算、集合通信操作通常都是在毫秒，甚至微秒、纳秒内完成的，当任务在正常迭代过程中发生了 hang，我们常遇到的情况是所有 rank 的 RDMA 流量会降到 0，而 GPU 的利用率为 100%、SM 利用率则在很低的水位。如果持续几分钟都是这种状态时，意味着训练进程已经计算完成，在等着集合通信完成，这种情况下基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信库中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常单次集合通信操作都是在 ms 级的，如果一次操作在 30 秒钟都没有完成，那就可以判定为通信 hang 死了。百度自研的 BCCL 集合通信库层可以对每一次集合通信操作都进行打点，来实现通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述几种方法，我们可以分别实现一种探针，来抓取相应的特征到中心端 master 组件进行下一步诊断和容错决策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信库 BCCL 是百度智能云推出的一款面向大模型训练场景优化的集合通信库。&lt;/p&gt; 
 &lt;p&gt;BCCL 基于开源的 NCCL 进行了功能扩展和能力增强，针对大模型训练场景在可观测性、故障诊断、稳定性等方面进行优化，进一步提升集合通信库的可运维能力。相比 NCCL，BCCL 的关键特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可观测性：新增集合通信带宽实时统计能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障诊断：新增集合通信 hang 时的故障诊断能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;稳定性：增强网络稳定性和故障容错能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能优化：提升大模型训练主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;训练 hang 的自动诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我们需要进一步的诊断、定位，来确定是否真的发生了 hang，以及 hang 的具体位置。具体的来讲，master 收集到各类 agent 的数据后，会做一些综合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的发生了 hang？&lt;/p&gt; &lt;p&gt;感知阶段各种探针只能探测到 hang 的一种特征，并没有办法 100% 的确定是否真的 hang 住了，事实上不侵入用户进程是很难做到 100% 确定 hang 的。因此，为了提高 hang 的判定准确率，我们需要将各种特种综合起来判断，探针上报到 master 后，由一个 hang 诊断模块，按照一个时间窗口（例如 5 分钟），进行综合判断。如果在时间窗口内日志、监控、进程调用栈、通信库中有 2 条以上都处于不处于活跃状态时，我们判断任务真正发生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具体发生的位置？&lt;/p&gt; &lt;p&gt;确定任务 hang 了之后，我们需要找到 hang 所在的节点来对它进行隔离。因此诊断模块需要在探针上报的数据中进一步找寻特征，来确定 hang 发生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 诊断：在感知阶段，BCCL 可以在通信库层面对所有 rank 的通信进行打点。如果有节点一直未完成通信则是发生了 hang。但是此节点可能并非真正发生 hang 的源头，有可能是在等待其他节点完成通信。诊断模块可以根据 BCCL 打印的通信组信息，进行交叉判断，如果某个节点在多个通信组中都未完成通信，那这个节点就是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指标诊断：上文中我们提到，通信阶段发生 hang 之后，所有 rank 的 RDMA 流量都会降到 0，而同时绝大部分 rank 的 GPU 利用率持续为 100%，只有某一两个 rank 的 GPU 利用率为 0，那这个 rank 很有可能是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调用栈诊断：进程调用栈也可以作为一个 hang 源头诊断的重要参考。当发生 hang 之后，绝大部分的 rank 都要么处于 barrier 等待状态，要么处于通信等待阶段。只有个别的 rank 卡在其他函数上，那么通过对比分析，可以将调用栈与其他 rank 不同的节点初步判定为 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;综合诊断：上面 3 种特征为我们提供了 hang 的诊断依据，将 3 者关联起来分析后，我们基本上可以比较准确的确定一个具体的 hang 的源头，再结合硬件故障感知的相关信息可以进一步明确根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基于 eBPF 的隐式故障感知与诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在复杂的大规模分布式训练场景中，传统用户态监控往往难以捕获系统内核层面的异常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基于 eBPF（Extended Berkeley Packet Filter）技术的隐式故障感知体系，能够在不侵入用户代码的前提下，对训练进程的系统调用、网络通信、CPU 调度等内核态行为以及训练框架关键函数运行时间建立立体观测能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探针部署原理通过在内核关键路径注入轻量级探针，实现低开销的系统级行为捕获。针对训练场景特点，主要聚焦 4 类事件跟踪：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练关键函数跟踪：微秒级跟踪训练过程中，前向计算、反向计算、集合通信操作等关键函数执行耗时，记录函数间调用关系。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调度阻塞跟踪：挂钩 sched_switch 事件，检测进程在 TASK_UNINTERRUPTIBLE 状态持续时间，当单次持续超过阈值（如 5 秒）时捕获调用栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 运行时 API 监控：通过 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等关键库注入探针，记录 CUDA API 调用耗时分布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 级通信监控：在 ibv_post_send/ibv_poll_cq 等核心通信接口设置观测点，统计通信时延分布。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上面 4 类事件，完成以下 2 类数据分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单体异常探测基线与实时数据对比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;群体一致性检测。采用卡间对比算法，当某一 rank 的以下指标偏离集群中位数超过阈值时判定异常，包括系统调用频率、进程就绪队列等待时长、NVLink/RDMA 带宽利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上所述方法，百度百舸针对以下 2 类典型的隐式故障进行诊断：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练 hang 根因定位。通过关联 eBPF 捕获的多维度数据进行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当检测到某 rank 的 GPU &amp;nbsp;Kernel 执行出现分钟级空跑（SM 利用率 &amp;gt; 70% 但无有效计算输出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时伴随该节点 RDMA QP 状态停滞（ibv_poll_cq 无新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内核调度器显示进程处于 D 状态超过阈值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖动溯源。基于 eBPF 火焰图、时序图等进行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取发生性能下降时段的 CPU on-cpu/off-cpu 堆栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对比正常时段数据，识别出异常的锁竞争（futex 调用占比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 NUMA 内存访问统计，定位跨 NUMA 内存访问导致的 TLB 颠簸问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此类技术已在百度百舸的万卡规模训练集群中验证，相比单纯依赖应用层监控的方案，将隐式故障的平均检测时间从分钟级缩短至秒级，诊断准确率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通过与既有硬件故障感知服务、BCCL 通信库监测体系联动，百度百舸形成了覆盖从硬件到系统内核再到应用层的立体化诊断能力。&lt;/p&gt; 
&lt;h1&gt;05 任务故障恢复的时效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢复的时效性也是容错能力的一个重要指标，反映的是任务从故障发生到再次重新进入训练迭代的时间，恢复效率越高则算力浪费越少。影响到任务恢复效率有 2 个重要因素，一是任务平均中断时间，二是训练重算时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多级重启策略减少故障中断时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任务发生异常后，上文中我们提到需要经过故障自动感知、诊断和自愈等 3 个环节，那么减少中断时间的核心思想，就是尽可能的缩短这 3 个环节的时间，通过多维度的感知、诊断手段可以将故障发现、定位的时效性降低至分钟级甚至秒级。自愈则需要能够根据不同的诊断结果进行分级恢复和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单点显式故障：重调度异常节点（replace），对节点进行集群级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;单点隐式故障：重调度异常节点，对节点进行任务级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非单点故障：原地重启尝试恢复（restart），无法恢复时重新调度所有节点（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过多级重启策略，尽可能避免单点故障引发全部节点的重新调度。在万卡级别的训练场景中，百度百舸将大部分训练异常场景恢复时间从过去的 30min 缩短至现在的 30s 内，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;触发式 checkpoint 减少训练重算时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多级任务重启策略外，另一个提高任务故障恢复效率的重要手段就是减少训练重算时间。在探讨具体技术方案之前，我们先来看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;传统的 checkpoint 保存通常采用固定间隔策略，比如每隔 N 个 step 或每隔 T 小时保存一次，这种方式实现简单但缺乏灵活性，可能会产生大量冗余存储，同时在故障发生时可能会损失较多训练进度。&lt;/p&gt; 
&lt;p&gt;而触发式 checkpoint 则是一种更智能的方案，它根据特定条件或异常事件（如故障、显存不足、显式指令等）动态触发模型状态保存。其核心目标是通过灵活的控制保存时机，减少不必要的存储开销和训练中断时间，从而降低因频繁或冗余保存导致的重算时间浪费。&lt;/p&gt; 
&lt;p&gt;随着大模型训练规模的扩大，还有一种更激进的「零重复 checkpoint」技术，即在每个训练 step 都保存一次 checkpoint。这种方案的优势在于可以将重算时间降到最低，确保故障发生时能够从最近的 step 恢复，几乎不会损失训练进度。但其显著的缺点是存储开销巨大，即使采用增量式存储，仍然需要相当大的存储空间和 I/O 带宽。此外，频繁的 checkpoint 操作也可能影响训练性能。&lt;/p&gt; 
&lt;p&gt;相比之下，触发式 checkpoint 走的是一条平衡之路。我们来看下它实现的几个核心要点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容错：训练进程集成容错的故障感知与定位机制，在进程退出前自动触发保存。这种主动感知机制能够在故障发生的第一时间保存训练状态，最大限度减少进度损失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速转储：异步 checkpoint 保存机制会将 checkpoint 暂存到共享内存中，再由外部程序转储至磁盘。当某个节点异常时，容错组件会拉起新节点，并在新节点训练进程启动前，利用 RDMA 技术实现 checkpoint 快速从故障节点转储至新节点，这大大减少了从远程存储拉取 checkpoint 的时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗余备份：触发式 checkpoint 也并非完美无缺，例如在节点发生内核 crash 等严重故障时，可能无法触发自动保存。因此，需要通过定期的冗余备份机制进行兜底，确保 checkpoint 不会完全丢失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实践表明，当触发式 checkpoint 与异步、增量式的 checkpoint 机制结合使用时，可以在保证数据安全性的同时，显著提高 checkpoint 保存效率，减少训练重算时间。&lt;/p&gt; 
&lt;p&gt;相比零重复 checkpoint 的重型方案，触发式 checkpoint 提供了一个更实用的折中方案，在合理的存储开销下实现较好的容错效果。当然，具体选择哪种方案，还需要根据实际的训练规模、硬件条件和可用资源来权衡。&lt;/p&gt; 
&lt;p&gt;随着分布式训练规模的持续增长，相信未来会出现更多创新的 checkpoint 方案，比如基于预测的主动保存策略、多级存储架构的智能调度等，这些都将为提高大规模训练的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 业务发展对稳定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 训练的稳定性管理已经演变为智能时代的精密工程。从最初靠人工重启解决问题的摸索阶段，到如今能自动感知异常、快速恢复的智能系统，每一次进步都映照着算力规模的跨越式发展。&lt;/p&gt; 
&lt;p&gt;让人不禁思考，在未来十万卡集群的算力洪流中，或许会出现更精妙的动态平衡方案：既能像鹰隼般敏锐捕捉故障征兆，又能如雁群迁移般智能调度资源，在秒级恢复与 PB 级存储成本之间找到新的平衡支点。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持厂内千卡和万卡集群有效训练时长已经可达 99.5%，为客户大模型的预训练保驾护航，比如国内第一个数学大模型——九章算术，国内第一个类 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增强语义嵌入的模型算法综述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持续推进「人工智能＋」行动，百度智能云+DeepSeek 为何成为国有企业首选？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 云服务器的软件系统设计和实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基于 Flink 的配置化实时反作弊系统&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sun, 11 May 2025 03:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 发布开放权重模型贡献榜：Qwen 与 DeepSeek 跻身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;发布&lt;/a&gt;开放权重模型贡献榜，中国团队 Qwen 和 DeepSeek 成功入围前 15 名。该榜单表彰为开源社区提供高质量模型权重的团队，其模型广泛应用于学术与产业创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴云智能集团支持的 Qwen 团队，以 Qwen3 系列模型在指令跟随、代码生成等任务中的优异表现受到社区青睐。Qwen2.5-72B 系列位列开源大语言模型前列，其轻量化模型 QwQ-32B 通过强化学习优化，在数学推理和代码生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 则以低成本、高性能的 R1 系列模型闻名。R1-0528 在 LiveCodeBench 排行榜中超越多个国际竞品，仅次于 OpenAI 顶尖模型。其轻量化版本 DeepSeek-R1-0528-Qwen3-8B 通过知识蒸馏技术，单 GPU 即可运行，在 AIME2025 数学测试中击败 Google 的 Gemini2.5Flash，展现了在特定领域的竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中国 AI 团队在开源生态中的崛起。Hugging Face 负责人表示，两团队的贡献为全球开发者提供了高效资源。NVIDIA 首席执行官黄仁勋也赞扬其性能与成本平衡正在重塑 AI 格局。未来，Qwen 计划探索多模态技术，DeepSeek 则将推出 R2 模型，持续推动 AI 创新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sun, 11 May 2025 02:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Android 16 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌发布了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为今年的第一次大版本升级，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按键式导航（三大金刚）的预测性返回手势&lt;/li&gt; 
 &lt;li&gt;强制通知分组&lt;/li&gt; 
 &lt;li&gt;以进度为中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 设备的桌面模式（开发者选项）&lt;/li&gt; 
 &lt;li&gt;低功耗蓝牙听力辅助设备支持&lt;/li&gt; 
 &lt;li&gt;自定义键盘快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截图优化&lt;/li&gt; 
 &lt;li&gt;以旧换新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性详细介绍查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sun, 11 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 DevExpress WPF v24.2 新版亮点：报表等组件功能升级</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF 拥有 120+个控件和库，将帮助您交付满足甚至超出企业需求的高性能业务应用程序。通过 DevExpress WPF 能创建有着强大互动功能的 XAML 基础应用程序，这些应用程序专注于当代客户的需求和构建未来新一代支持触摸的解决方案。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;控件近期全新发布 v24.2，此版本进一步升级了网格、报表、地图等组件的功能，欢迎下载最新版体验！&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346%2Fdownload" target="_blank"&gt;DevExpress WPF v24.2 正式版下载&lt;/a&gt;&lt;/strong&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Grid（网格）控件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多单元格编辑&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;Microsoft Excel 允许您选择多个单元格并通过按 Ctrl + Enter（替代 Enter）应用文本更改，DevExpress WPF Grid 控件中添加了一个类似的特性，允许用户同时对多个单元格应用相同的值。要启用此功能，将&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.DataControlBase.SelectionMode" target="_blank"&gt;GridControl.SelectionMode&lt;/a&gt;设置为 Cell，将&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.TableView.MultiCellEditMode%3Fv%3D24.2" target="_blank"&gt;GridControl.MultiCellEditMode&lt;/a&gt;设置为 FocusedColumn/AllColumns。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 产品图集" src="https://oscimg.oschina.net/oscnet//a590e16b5907853d6c754e5c5bc46b88.gif" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;PDF Viewer&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;获取在页面缩略图面板中选择的页面&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;PdfViewer.GetSelectedThumbnailPageIndexes&lt;/a&gt;方法允许您获得在 Page Thumbnails 面板中所选页面的索引，可以在 DevExpress PDF Viewer 中提取、删除或导出选定的页面。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfViewerControl.ActualThumbnailsViewerSettings%3Fv%3D24.2" target="_blank"&gt;PdfViewerControl.ActualThumbnailsViewer&lt;/a&gt;属性来访问实际的缩略图查看器设置，并调用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;GetSelectedThumbnailPageIndexes&lt;/a&gt;方法来获取页面索引。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;下面的示例将在页面缩略图面板中选择的 PDF 文档的页面保存为图像：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;&lt;em&gt;C#&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;using System.Windows.Media.Imaging;
using System.IO;
// ...
private void simpleButton_Click(object sender, RoutedEventArgs e) {
// Obtains the selected page indexes.
var pages = viewer.ActualThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes();
// Saves each page from the collection to an image.
foreach (var i in pages) {
BitmapSource image = viewer.CreateBitmap(i, 1000);
PngBitmapEncoder encoder = new PngBitmapEncoder();
encoder.Frames.Add(BitmapFrame.Create(image));
using (var fileStream = new FileStream($"..\\MyBitmap{i + 1}.bmp", FileMode.Create)) {
encoder.Save(fileStream);
}
}
}&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Reporting（报表）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WPF 报表设计器 - 维度符号&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;为了简化报表设计过程，此更新在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;报表设计器中引入了维度符号。当您调整控件的大小时，设计器会提供精确的视觉反馈，并根据指定的 ReportUnit 属性值（如英寸、厘米或像素）显示维度符号。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 产品图集" src="https://oscimg.oschina.net/oscnet//b1ccdc0e972820bc31dddac86cddd3d6.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;要管理符号的可见性，请使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FXtraReports%2FDevExpress.XtraReports.Configuration.UserDesignerOptions.ShowDimensionNotations%3Fv%3D24.2" target="_blank"&gt;UserDesignerOptions.ShowDimensionNotations&lt;/a&gt;属性。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;地图组件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 Azure 地图&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF MapControl 现在可以显示 Microsoft Azure 地图数据，使用 AzureMapDataProvider 提供程序获取光栅图像磁贴。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;注意&lt;/strong&gt;：在使用 Azure Maps 时，您必须阅读并理解 Microsoft 的使用条款：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fpricing%2Fdetails%2Fazure-maps%2F" target="_blank"&gt;https://azure.microsoft.com/en-us/pricing/details/azure-maps/&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354762</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354762</guid>
      <pubDate>Sun, 11 May 2025 02:36:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 推迟开源模型的发布时间</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席执行官山姆·奥特曼宣布，原计划于今年初夏发布的公开权重的开源模型预计&lt;strong&gt;将推迟至夏末发布&lt;/strong&gt;，而不是 6 月与公众见面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究团队做了一些出乎意料且非常令人惊奇的事情，这非常值得等待，但需要更长的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣布将发布自 GPT-2 以来的首个「开源」语言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最强」开源模型，计划今年初夏发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sun, 11 May 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首个推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣布推出&lt;/a&gt;其首个推理模型系列 Magistral，采用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高数学和物理等主题的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有两种版本：Magistral Small 和 Magistral Medium。Magistral Small 拥有 240 亿个参数，在 Apache 2.0 协议下开源。Magistral Medium 是一款功能更强大的模型，目前已在 Mistral 的 Le Chat 聊天机器人平台、该公司的 API 以及第三方合作伙伴云平台上提供预览。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中写道：「Magistral 适用于各种企业用例，从结构化计算和程序逻辑到决策树和基于规则的系统。这些模型针对多步骤逻辑进行了微调，提高了可解释性，并以用户的语言提供了可追溯的思维过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立于 2023 年，该公司得到了 General Catalyst 等风险投资机构的支持，迄今已筹集超过 11 亿欧元（约合 12.4 亿美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;尽管 Mistral 资源雄厚，但在某些领域，例如推理模型开发，Mistral 仍落后于其他领先的人工智能实验室。从 Mistral 自身的基准测试来看，Magistral 似乎也并非一款特别有竞争力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 测试中，Magistral Medium 的表现不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的编程基准 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或许正因如此，Mistral 在其博客文章中大力宣扬 Magistral 的其他优势。声称 Magistral 在 Le Chat 中提供答案的速度是竞争对手的「10 倍」，并且支持多种语言，包括意大利语、阿拉伯语、俄语和简体中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的发布是在 Mistral 推出「vibe coding」客户端 Mistral Code 之后。在此之前的几周，Mistral&amp;nbsp;推出了几款专注于编码的模型，并推出了 Le Chat Enterprise，一项面向企业的聊天机器人服务，提供 AI 代理构建器等工具，并将 Mistral 的模型与 Gmail 和 SharePoint 等第三方服务集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 发布 o3-pro：更强大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;发布&lt;/a&gt;了 o3-pro 推理模型，基于 o3 所打造，拥有更强的数学、科学、编程等领域的表现。&lt;/p&gt; 
&lt;p&gt;据介绍，o3-Pro 可，自动调用多种工具，包括可以搜索网页、分析文件、推理视觉输入、使用 Python、通过记忆功能个性化回复等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由于调用的工具较多，所以，思考的时间比 o1 Pro、o3 更长。&lt;/strong&gt;o3-pro 与 o3 系列一样拥有 200K 的上下文窗口和 100K 的输出，但价格却比它们暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表现上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在专家评估中，评审人员普遍认为 o3 Pro 在多方面都比 o3 模型更进一步，尤其适合用在科学、教育、编程、商业和写作这些需要深度输出的任务中。&lt;/li&gt; 
 &lt;li&gt;在学术评估的基准测试中，o3-pro 的整体表现持续优于 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 还通过四次尝试获取正确答案的方式进行实验发现，o3-pro 能保持较好的性能表现。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企业版和教育版用户将在下周获得使用权限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;价格方面，o3-pro 输入为 20 美元/百万 token，输出 80 美元/百万 token；而 OpenAI CEO Sam Altman 昨晚宣布，o3 降价 80%——因此 o3 价格来到了输出 2 美元/百万 token、输入 8 美元/百万 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sun, 11 May 2025 02:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>基于 KubeSphere 平台快速搭建单节点向量数据库 Milvus</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;pre&gt;title: 基于 KubeSphere 平台快速搭建单节点向量数据库 Milvus🔥
date: 2025-6-10
categories:
  - Milvus
tags:
  - Milvus
  - KubeSphere
sticky: 1
&lt;/pre&gt; 
&lt;h2&gt;&lt;span&gt;KubeSphere 是什么&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;KubeSphere 是一个在 Kubernetes 之上构建的、以应用为中心的多租户容器平台，完全开源，由社区驱动与开发 1&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fdocs%2Fv3.3%2Fintroduction%2Fwhat-is-kubesphere%2F" target="_blank"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fv3-2.docs.kubesphere.io%2Fzh%2F" target="_blank"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。它提供全栈的 IT 自动化运维能力，旨在简化企业的 DevOps 工作流，并帮助企业快速构建强大且功能丰富的容器云平台。功能强大、易用性高的开源 Kubernetes 容器云 PaaS 平台，能够帮助企业快速构建、管理和运维云原生应用，提升 DevOps 效率，降低运维复杂度，适用于各类规模的企业和团队。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;如何快速通过可视化界面搭建项目数据库 Milvus&lt;/span&gt;&lt;/h2&gt; 
&lt;blockquote&gt;
 &lt;span&gt;采用 K8s 平台，可以通过镜像网站：&lt;/span&gt;
 &lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocker.aityp.com%2F" target="_blank"&gt;https://docker.aityp.com/&lt;/a&gt;&lt;/span&gt;
 &lt;span&gt; 下载必须的镜像，etcd、milvus、minio。使用时需要确定下载镜像对应宿主机处理器的版本进行下载不然无法成功运行镜像容器。&lt;/span&gt; 
 &lt;p&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c754d0ca9fdc8a050815a6137811fdf9.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;本次搭建的宿主机处理器为 amd 架构因此下载时需要筛选对应的架构版本镜像下载&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//591be48c48ba52898104243fc8d3e713.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 etcd 中间件&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;本次采用 etcd 国内镜像地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/registry.k8s.io/etcd:3.5.5-0&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//bd887c8668f3812cbbcb0d5de70e1b2a.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;需要对启动命令进行专门配置：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;/usr/local/bin/etcd&lt;span style="color:#8d8df0"&gt;,--name&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;etcd-0&lt;span style="color:#8d8df0"&gt;,--data-dir&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;/var/lib/etcd&lt;span style="color:#8d8df0"&gt;,--listen-client-urls&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;http://0.0.0.0:2379&lt;span style="color:#8d8df0"&gt;,--advertise-client-urls&lt;/span&gt;&lt;span style="color:#b8bfc6"&gt;=&lt;/span&gt;http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379&lt;/span&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;span&gt;对上述指令进行详细解释：&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/usr/local/bin/etcd&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;这是 etcd 可执行程序的路径，表示启动 etcd 服务。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--name=etcd-0&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;为当前 etcd 节点指定一个名称，集群内唯一，便于管理和识别节点&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://monchickey.com/post/2023/09/24/etcd-cluster-installation/"&amp;gt;&amp;lt;span&amp;gt;2&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--data-dir=/var/lib/etcd&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 数据存储的目录，所有键值数据、集群状态和元数据都保存在这里&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://monchickey.com/post/2023/09/24/etcd-cluster-installation/"&amp;gt;&amp;lt;span&amp;gt;2&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--listen-client-urls=&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://0.0.0.0:2379/"&amp;gt;&amp;lt;span&amp;gt;http://0.0.0.0:2379&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 监听客户端请求的地址和端口，&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;0.0.0.0&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 表示监听所有网络接口，客户端可以通过任意 IP 访问本节点的 2379 端口&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://www.kancloud.cn/pshizhsysu/middleware/2794721"&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://cloud.tencent.com/developer/article/1644574"&amp;gt;&amp;lt;span&amp;gt;7&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;如果不配置，默认只监听本地回环地址 (&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;127.0.0.1:2379&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;)，外部客户端无法访问。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;--advertise-client-urls=&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379/"&amp;gt;&amp;lt;span&amp;gt;http://dev-etcd-shanghai.dev-shanghai.svc.cluster.local:2379&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;指定 etcd 向集群其他成员和客户端通告的客户端访问地址，通常使用集群内部域名或固定 IP，便于其他节点和客户端正确连接&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="https://cloud.tencent.com/developer/article/1644574"&amp;gt;&amp;lt;span&amp;gt;7&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;a href="http://www.zhaowenyu.com/etcd-doc/command/etcd.html"&amp;gt;&amp;lt;span&amp;gt;8&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;如果不配置，客户端和其他节点可能无法正确连接到本节点，导致集群通信异常&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置完成之后直接等待容器启动即可，etcd 服务不需要配置额外的对外暴露&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 minio 中间件&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;采用的国内镜像源地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/minio/minio:RELEASE.2025-04-22T22-12-26Z&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;直接使用默认的容器镜像端口即可&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//369f954eee41419e62c2558f218ebf46.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;启动命令的详细概述&lt;/span&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;span&gt;命令&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;/bin/sh,-c&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;&lt;span&gt;参数&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;minio server /data &lt;span style="color:#7575e4"&gt;--console-address&lt;/span&gt; :9090&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;对上述命令的详细解释：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;在 Kubernetes（k8s）中配置 MinIO 时，常见的启动命令形式如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;command: [&lt;span style="color:#d26b6b"&gt;"/bin/sh"&lt;/span&gt;, &lt;span style="color:#d26b6b"&gt;"-c"&lt;/span&gt;, &lt;span style="color:#d26b6b"&gt;"minio server /data --console-address :9090"&lt;/span&gt;]&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/bin/sh, -c 的作用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;在 Kubernetes YAML 中，&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;command&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 字段默认是直接执行命令，但如果命令比较复杂（如需要环境变量、管道、重定向等），直接写命令字符串会被解析为单个命令参数，导致执行失败。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;使用 &amp;lt;/span&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;/bin/sh -c&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 可以让 Kubernetes 把后面的字符串整体作为 Shell 脚本执行，支持更多的 Shell 语法和变量替换。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;strong style="color:#dedede"&amp;gt;&amp;lt;span&amp;gt;minio server /data --console-address :9090&amp;lt;/span&amp;gt;&amp;lt;/strong&amp;gt;&amp;lt;/span&amp;gt;

&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;/data&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是 MinIO 的数据目录，必须指定。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;--console-address :9090&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 显式指定 Console 端口，确保 Web 管理界面可以通过固定端口访问，便于暴露服务和调试.&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c17c8150b20a21c9f3d6a22a17620ef6.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 milvus 向量数据库&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;采用的国内镜像源地址：swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/milvusdb/milvus:v2.5.9&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;下述两处端口指定时参考官方文档的 docker-compose 文件，进行配置，尝试过多种镜像都不能出现如上述两个中间件一样的使用默认镜像端口按钮&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c7c51b72e1c85d13c6449a2c151f1f77.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;配置对应的系统名称和环境变量&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置完成需要暴露对外端口&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//545b48d79ab09b97a9b1a741ebb97da0.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span&gt;命令&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;/tini,--&lt;/span&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;span&gt;参数&lt;/span&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;span&gt;milvus,run,standalone&lt;/span&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;span&gt;环境变量 k-v 值&lt;/span&gt;&lt;/h4&gt; 
&lt;table cellspacing="0" style="--tw-border-spacing-x:0; --tw-border-spacing-y:0; --tw-ring-color:rgb(59 130 246 / .5); --tw-ring-offset-color:#ffffff; --tw-ring-offset-shadow:0 0 #0000; --tw-ring-offset-width:0px; --tw-ring-shadow:0 0 #0000; --tw-rotate:0; --tw-scale-x:1; --tw-scale-y:1; --tw-scroll-snap-strictness:proximity; --tw-shadow-colored:0 0 #0000; --tw-shadow:0 0 #0000; --tw-skew-x:0; --tw-skew-y:0; --tw-translate-x:0; --tw-translate-y:0; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; break-inside:auto; cursor:text; margin:0px; max-width:100%; overflow:auto; text-align:left; white-space:pre-wrap; width:1140px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th style="vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;ETCD_ENDPOINTS&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
   &lt;th style="vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;dev-etcd-shanghai.dev-shanghai:2379&lt;/span&gt;&lt;/span&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#474d54; border-style:solid; border-width:1px; vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;MINIO_ADDRESS&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td style="border-color:#474d54; border-style:solid; border-width:1px; vertical-align:top"&gt;&lt;span&gt;&lt;span&gt;dev-minio-shanghai.dev-shanghai:9000&lt;/span&gt;&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;span&gt;上述命令的详细解释&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;在 Kubernetes (K8s) 中启动 Milvus 时，命令行中常见的启动命令格式是：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;span&gt;/tini &lt;span style="color:#7575e4"&gt;--&lt;/span&gt; milvus run standalone&lt;/span&gt;&lt;/pre&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;这里各部分的作用如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 是一个小型的 init 进程，常用于容器环境中作为 PID 1 进程，负责正确地处理信号转发和僵尸进程回收，保证容器内的主进程（这里是 Milvus）能优雅启动和退出。它不是 Milvus 自身的命令，而是容器启动时的辅助工具，确保 Milvus 进程管理更稳定。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;--&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;这是一个常见的命令行参数分隔符，告诉 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 后面的参数不是给 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 本身的，而是传递给后面的程序（即 &lt;/span&gt;&lt;span&gt;&lt;code&gt;milvus&lt;/code&gt;&lt;/span&gt;&lt;span&gt;）的参数。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;code&gt;milvus run standalone&lt;/code&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;这是启动 Milvus 的命令，其中：&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;ul style="margin-left:0; margin-right:0"&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;run&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是 Milvus 的启动命令，表示启动 Milvus 服务。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;li&amp;gt;
&amp;lt;p style="margin-left:.5rem; margin-right:0"&amp;gt;&amp;lt;span&amp;gt;&amp;lt;code&amp;gt;standalone&amp;lt;/code&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span&amp;gt; 是指定启动模式，表示以单机模式启动 Milvus，即所有 Milvus 的组件（rootcoord、datacoord、querycoord、indexcoord、proxy 等）都在一个进程或节点上运行，而不是分布式多节点模式。&amp;lt;/span&amp;gt;
&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;根据 Milvus 源码和启动逻辑分析，&lt;/span&gt;&lt;span&gt;&lt;code&gt;milvus run standalone&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 命令会触发 Milvus 启动所有核心组件，适合开发测试或资源有限的场景。如果不配置或不使用该命令，Milvus 将不会启动任何服务组件，容器内 Milvus 进程不会运行，服务不可用&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.tencent.com%2Fdeveloper%2Farticle%2F2407241" target="_blank"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;如果省略 &lt;/span&gt;&lt;span&gt;&lt;code&gt;/tini&lt;/code&gt;&lt;/span&gt;&lt;span&gt;，容器内进程可能无法正确处理信号和回收子进程，导致容器退出时不能优雅关闭 Milvus，可能出现僵尸进程或信号处理异常。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;如果不加 &lt;/span&gt;&lt;span&gt;&lt;code&gt;run standalone&lt;/code&gt;&lt;/span&gt;&lt;span&gt; 参数，Milvus 不知道要启动哪个组件或以何种模式启动，默认不会启动服务，或者会打印帮助信息并退出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;配置环境变量不用多说就是需要指定好中间件地址，不然访问不了。为什么配置上述的 url 前缀，我已 etcd 为例进行解释：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//33a19fcf5d350da350d15948336bb35f.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;完成上述配置就基本完成，最后部署一个 Milvus 可视化管理工具&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署 attu&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;部署这个没啥特别需要说明的直接配置镜像然后暴露对外服务进行访问即可&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//feb400cc4e5baa1a0b232801621439cc.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;部署完成效果展示&lt;/span&gt;&lt;/h2&gt; 
&lt;p style="color:#b8bfc6; text-align:start"&gt;&lt;span&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6119250747a3aa776bf0407722900dc1.png" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;上述配置没有配置数据卷挂在因此不适合生产环境使用&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:.5rem; margin-right:0"&gt;&lt;span&gt;单点节点配置也不是很规范&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354695</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354695</guid>
      <pubDate>Sat, 10 May 2025 13:35:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>微软开始测试 Windows 11 的新版「开始」菜单</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软现在&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F06%2F09%2Fannouncing-windows-11-insider-preview-build-26200-5641-dev-channel%2F" target="_blank"&gt;允许&lt;/a&gt;&lt;/u&gt; Windows 11 测试人员试用全新、更大的「开始」菜单，该菜单包含可滚动的界面、新的视图和更多可自定义功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-133f02d0def812a3023b1918667ec4cbb4c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows Insider 团队解释说：「我们更新了可滚动的「开始」菜单，让您可以更轻松地启动应用。」 这个可滚动的「开始」菜单意味着所有应用现在都位于顶层，因此您无需导航到第二个页面即可找到应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95c628f3783c80a5c0be69c6167b9d9f144.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更新后的「开始」菜单有两个新视图可供选择&lt;/p&gt; 
&lt;p&gt;您还可以禁用推荐部分，以便查看更多应用，并选择两种新视图：类别视图和网格视图。默认类别视图按类别对应用进行分组，而网格视图则按字母顺序排列，更像传统的列表视图。&lt;/p&gt; 
&lt;p&gt;微软还根据设备或显示器的屏幕尺寸放大了「开始」菜单。Windows Insider 团队表示：「在较大的设备上，用户可以在「开始」菜单中看到 8 列固定应用、6 条推荐和 4 列类别。在较小的设备上，你将看到 6 列固定应用、4 条推荐和 3 列类别。」&lt;/p&gt; 
&lt;p&gt;开始菜单上还新增了一个移动设备按钮，可用于展开或折叠与开始菜单一起显示的「Phone Link」界面。微软还允许 Windows 11 用户选择显示哪些锁屏小部件，允许添加或删除小部件，并重新排列它们以适应锁屏。&lt;/p&gt; 
&lt;p&gt;最后，最新的 Dev Channel 版本还包含一个新的 Gamepad 键盘更新，可让您使用控制器通过 PIN 码登录 PC。这是微软改进 Windows 11 在手持游戏设备（例如最近发布的 ROG Xbox Ally 设备）上的运行效果的一部分。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354680/windows-11-new-start-menu-testing-dev-channel</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美团发布 AI Coding Agent 工具「NoCode」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;美团&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdByPiajMM7fX109GSotLVQ" target="_blank"&gt;上线&lt;/a&gt;了名为「NoCode」的&amp;nbsp;&lt;/span&gt;AI Coding Agent 工具&lt;span&gt;，用户通过自然语言对话即可生成网页、小程序等应用，并支持实时修改、一键部署。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;NoCode 是一款无需编程背景和经验，通过自然语言和对话形式，即可快速生成应用的平台。可帮助不同角色以"零代码"的方式创建个人提效工具、产品原型、可交互页面等，降低开发门槛，实现创意释放。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;NoCode&lt;/span&gt;功能亮点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自然语言编程&lt;/strong&gt;：使用自然语言描述想法，NoCode 自动解读并转化为完整功能，无需编程经验即可生成可用能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时预览效果&lt;/strong&gt;：根据对话内容即时渲染、呈现页面，可实时查看每次对话后的实际效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;局部定位修改&lt;/strong&gt;：使用 Visual Edit 功能，可针对定位内容进行局部修改及完善；同时支持版本间对比、回退，保障每一步都「有迹可循」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一键部署分享&lt;/strong&gt;：应用完成后，代码将自动上传到仓库，可直接分享链接给他人使用，简化发布流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0610/184826_5IfE_2720166.png" width="750" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;体验地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnocode.cn%2F" target="_blank"&gt;https://nocode.cn/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354675/meituan-nocode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354675/meituan-nocode</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>法国 AI 初创公司 Mistral 将发布推理模型 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F06%2F10%2Fmicrosoft-backed-ai-lab-mistral-debuts-reasoning-model-to-rival-openai.html" target="_blank"&gt;根据 CNBC 的报道&lt;/a&gt;，法国 AI 初创公司 Mistral 将推出其首个推理模型 Magistral，加入与 OpenAI、DeepSeek 等全球领先企业的竞争。&lt;/p&gt; 
&lt;p&gt;&lt;img height="898" src="https://static.oschina.net/uploads/space/2025/0610/183614_pyVq_2720166.png" width="2104" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mistral 首席执行官亚瑟・门施介绍道，Magistral 不仅擅长数学和编码，还能够实现欧洲语言的逻辑推理，突破了美国和中国模型的语言局限性。&lt;/p&gt; 
&lt;p&gt;今年 3 月，Mistral 已发布 240 亿参数的 Mistral Small 3.1 模型，该模型以低成本实现本地运行，部分性能甚至超越 OpenAI 的 GPT-4o mini。5 月，Mistral 进一步推出了 Medium 3 模型，这款中量级模型在保持前沿性能的同时，显著降低了企业使用成本，每百万 Token 输入仅需 0.4 美元。&lt;/p&gt; 
&lt;p&gt;Mistral 通过技术创新，正逐步提升其在全球 AI 市场的竞争力，并为多语言应用场景提供更优解决方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354673/mistral-debuts-reasoning-model-to-rival-openai</guid>
      <pubDate>Sat, 10 May 2025 10:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度网盘、文库联合发布「AI 相机」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;6 月 10 日，在百度 AI Day 开放日上，百度网盘、文库联合发布行业首个「拍存管一体」的「AI 相机」，具备全模态输入、处理、输出的系统化完整交付 AI 能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-acb055f53ca9b3a5f087e132e834b1d7f25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AI 相机已在百度网盘 App 上线，并已接入百度文库 App。百度文库还宣布多智能体协作能力「GenFlow 超能搭子」全新升级为 2.0 版本，使其成为率先实现全场景满足、全链路覆盖的多智能体协作应用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0610/183107_JyHR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GenFlow 超能搭子 2.0 依托于文库、网盘海量的公私域数据和用户记忆库，可完整交付更懂用户的个性化内容；它可以自主调用各种模型和工具，一次性并行生成多模态、多格式内容；它还支持后链路的编辑环节，在内容创作上灵活度更高。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354672</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354672</guid>
      <pubDate>Sat, 10 May 2025 10:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 时代的「数据之困」，什么是 AI-Ready Data</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;人工智能（AI）无疑是当今科技领域最激动人心的变革力量，它横跨各个行业，展现出重塑未来的巨大潜力。从智能客服到精准医疗，从自动驾驶到个性化推荐，AI 的触角几乎无所不至。然而，在这股 AI 浪潮之下，一个普遍的困境也日益凸显：许多雄心勃勃的 AI 项目在起步后便步履维艰，难以实现预期的投资回报，甚至大量试点项目最终未能成功转化为生产力。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;这种「雷声大，雨点小」的现象，不禁让人深思：&lt;strong&gt;AI 的理想与现实之间，究竟横亘着怎样的鸿沟？&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;追根溯源，这一困境的核心往往直指 AI 的「食粮」——数据。数据是驱动 AI 系统洞察、预测和决策的燃料。然而，企业在将数据应用于 AI 时，普遍面临着一系列严峻挑战：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;数据质量参差不齐&lt;/strong&gt;：不准确、不完整、标签错误或充满噪声的数据是 AI 项目失败的常见元凶。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E5%25AD%25A4%25E5%25B2%259B%26zhida_source%3Dentity" target="_blank"&gt;数据孤岛&lt;/a&gt;&lt;/span&gt;与集成难题&lt;/strong&gt;：数据往往散落在企业内部各个孤立的系统中，格式各异，难以有效整合和统一访问。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;缺乏标准化与有效治理&lt;/strong&gt;：数据格式不统一、元数据缺失、数据血缘关系不清晰以及&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E6%2595%25B0%25E6%258D%25AE%25E6%25B2%25BB%25E7%2590%2586%26zhida_source%3Dentity" target="_blank"&gt;数据治理&lt;/a&gt;&lt;/span&gt;机制的薄弱，都为 AI 应用埋下了隐患。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;这些普遍存在的数据问题，实际上反映了许多企业在 AI 战略上的一个深层错位：即，&lt;strong&gt;对 AI 技术本身抱有极高期望，却忽视了构建坚实数据基础的重要性&lt;/strong&gt;。企业纷纷投入巨资采购先进的 AI 工具和算法，但如果供给这些「智能引擎」的是劣质「燃料」，那么再强大的算法也难以发挥其应有的效能。AI 的雄心壮志与薄弱的数据能力之间形成的巨大反差，正是导致众多 AI 项目折戟的关键。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;面对 AI 时代的「数据之困」，企业迫切需要一种能够有效解决上述问题、真正释放 AI 潜能的数据形态。于是，「AI-ready Data」 的概念应运而生。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;什么是 AI-ready Data？为何如此重要？&lt;/strong&gt;&lt;/h2&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//be5fce4d40a25157514e64dbd6664171.jpg" width="1024" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data：超越数据的「数据」&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data，顾名思义，是指那些经过精心准备、结构化处理和严格验证，能够以最佳效能服务于人工智能应用的数据。这类数据使得 AI 算法能够高效地学习模式、做出准确预测并生成有价值的洞察。它强调的不仅仅是拥有海量数据，更在于数据的质量、结构和相关性，确保数据能够被 AI 算法高效处理和分析。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;打个比方，如果说 AI 是一个高性能引擎，那么 AI-ready Data 就是为其量身定制的、经过提纯的高辛烷值燃料，确保引擎能够以巅峰状态持续运转。它不是原始、未经雕琢的「数据矿石」，而是经过精炼、可以直接投入 AI「熔炉」的「高品位原料」。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;AI-ready Data 不可或缺的价值&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 之所以关键，在于它能为 AI 的成功应用带来一系列实实在在的好处。高质量、准备充分的数据是训练出高精度、高可靠性 AI 模型的基础，直接决定了模型的准确性和有效性，正所谓「Garbage in, Garbage out」。通过大幅减少数据科学家在数据清洗和整理上耗费的巨量时间，AI-ready Data 能够显著加速 AI 项目的落地进程，使团队更专注于模型创新与优化。它是构建稳健、可扩展 AI 系统，使其能处理复杂任务并大规模有效运作的基石，最终通过驱动更明智决策、提升运营效率、降低成本和增强市场竞争力，为企业创造切实的商业价值。同时，清晰、可溯源且管理良好的数据还有助于企业遵守日益严格的数据法规与 AI 伦理规范，为 AI 系统的透明度和问责制提供保障。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;理解 AI-ready Data 的价值，更要认识到它并非一劳永逸的静态目标，而是一个持续演进的动态过程，需要随 AI 发展、业务变化及法规更新不断调整优化，其及时性、可扩展性和定期刷新的需求都印证了这是一项长期投入。追求 AI-ready Data 的本质，是将数据管理从单纯的「收集」提升到战略性的「策展」与「价值创造」层面，要求企业带着明确的 AI 应用目标有意识地准备数据，使数据管理从后端支持转变为驱动创新的核心环节。更深远地看，实现数据 AI 就绪的努力将催化组织在数据治理、数据素养和跨部门协作等方面的全面成熟，打破数据孤岛，提升整体数据能力，从而孕育出惠及企业全局的数据驱动文化，这其中，人的因素和流程优化与技术平台同等重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;不同领域的 AI-ready Data 特征上有什么区别？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;尽管 AI-ready Data 的核心原则具有普适性，但在不同的 AI 细分领域，其具体的形态、准备的侧重点以及在模型训练和推理阶段的要求，都会呈现出显著的差异。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;机器学习中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;传统的机器学习是许多企业 AI 应用的起点，其对数据的要求相对成熟和明确。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：ML 模型的数据通常是结构化的表格数据，例如 CSV 文件或数据库中的表，其中每一行代表一个样本，每一列代表一个特征。对于监督学习任务，数据中还会包含一个目标列或标签列，用以指示模型需要预测的结果 。虽然 ML 也可以处理文本、图像等非结构化数据，但这往往需要通过复杂的特征工程将其转换为结构化的数值特征，才能被传统 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：ML 模型的数据通常是结构化的表格数据，例如 CSV 文件或数据库中的表，其中每一行代表一个样本，每一列代表一个特征。对于监督学习任务，数据中还会包含一个目标列或标签列，用以指示模型需要预测的结果 。虽然 ML 也可以处理文本、图像等非结构化数据，但这往往需要通过复杂的特征工程将其转换为结构化的数值特征，才能被传统 ML 算法有效利用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：用于预测客户流失的数据集，可能包含客户的人口统计信息、消费行为、服务使用频率等特征；用于垃圾邮件检测的已标注邮件数据集。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//3911ebe7c46166407d1fad003e28b19d.jpg" width="600" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;深度学习中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;深度学习以其处理复杂模式和大规模数据的能力，在图像识别、自然语言处理等领域取得了革命性进展，其对数据的需求也更为「贪婪」。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：深度学习模型的训练通常依赖于大规模的非结构化以及多模态数据，如图像、音频、文本和视频。这些数据往往需要进行大量且精准的标注，例如物体检测任务中的边界框、图像分割的掩码、语音识别的文本转录等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：数据的「量」和「多样性」是深度学习成功的关键。同时，标注的一致性和准确性对模型性能至关重要，高质量的数据集是实现准确语音识别等任务的基础。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：著名的 ImageNet 数据集包含数百万张标注图像；LibriSpeech 数据集包含数千小时的转录音频；维基百科的文本转储等大型文本语料库。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//22383fbb9f6e44994f6c4a867cb18fce.jpg" width="700" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3D%25E7%2594%259F%25E6%2588%2590%25E5%25BC%258FAI%26zhida_source%3Dentity" target="_blank"&gt;生成式 AI&lt;/a&gt;&lt;/span&gt;与 RAG 系统中的 AI-Ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;具体到生成式 AI 领域，其对 AI-ready data 的需求首先体现在模型预训练和微调阶段。基础模型的构建依赖于规模宏大、内容多样甚至多模态的数据集，涵盖了从公开网页文本、专业书籍到代码、图像和音视频等广泛来源。而模型的微调则更侧重于特定领域内高质量、高相关性的专业数据集。贯穿始终的是对数据合规性、版权以及潜在偏见的严格审视与伦理考量，负责任的数据策略是实现 AI 价值的前提。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在众多生成式 AI 应用中，检索增强生成（RAG）架构尤为依赖 AI-ready data 的精细化准备。RAG 通过引入外部知识源来提升模型输出的准确性、时效性和深度，其核心挑战在于如何将这些外部知识高效、准确地「喂」给 LLM。这一过程的关键瓶颈与优化焦点在于数据切片（Chunking）。当前主流的数据切片方法往往显得「粗糙」。许多系统简单地采用固定字符数、按句子或段落等规则进行切分，这种方式极易破坏文本原有的语义完整性，可能导致一个完整的逻辑思路或上下文联系在切分中断裂，进而影响大模型对信息的准确理解和答案生成的质量。同时，这些简单方法常常忽略文档的内在结构，如章节、标题、列表和表格等，而这些结构本身就承载着重要的语义信息。面对不同类型（如法律合同、技术手册、研究论文或代码）和复杂格式的文档，通用的「一刀切」切片策略往往难以达到理想效果。切片的大小也需精妙平衡：过小则可能上下文不足，难以支撑复杂问答；过大则可能引入过多噪声，稀释关键信息。此外，多数在数据预处理阶段完成的静态切片，也缺乏对用户动态查询意图的灵活适应性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;因此，理想的 RAG 数据切片策略应向更智能化、语义驱动的方向演进。其核心目标是&lt;strong&gt;最大程度地保持语义单元的完整性&lt;/strong&gt;，切分点应尽可能选在自然的语义边界。同时，要充分感知并利用文档的固有结构信息，如将标题及其对应内容作为一个单元，或整体处理表格及其注释。为了保持切分后各知识块之间的上下文连贯，可以采用重叠切片技术，或构建具有内在联系的层级式块结构，并通过元数据明确记录它们之间的逻辑关系。针对不同内容特性，应采用内容自适应的切片逻辑。至关重要的是，每个切分后的数据块都应附带丰富的元数据，如原始文档出处、章节信息、主题标签等，这些元数据不仅能提升检索的精确度，还能为大模型提供更全面的背景知识，从而增强其输出内容的可信度和可溯源性。&lt;/p&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f2fb964dde666532d21ce8a16e7310fe.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DPhysical%2BAI%26zhida_source%3Dentity" target="_blank"&gt;Physical AI&lt;/a&gt;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;中的 AI-ready Data&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Physicla AI，如机器人和自动驾驶系统，需要在复杂的物理世界中进行感知、决策和行动，其数据需求具有独特性和挑战性。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;训练数据&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：来自多种传感器的融合数据，包括激光雷达的点云数据、摄像头的图像/视频流、雷达信号、惯性测量单元数据、GPS 定位信息、触觉传感器数据等。此外，还包括机器人的关节状态、运动轨迹、与环境的交互数据，以及大量来自模拟环境的合成数据。这类数据通常是时间序列数据，需要精确的时间同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：要求数据能够高保真地复现真实世界的物理特性和动态变化，覆盖多样化的环境条件（如不同天气、光照）、复杂的交互场景和罕见的边缘案例。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;示例&lt;/strong&gt;：自动驾驶领域的&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DWaymo%2BOpen%2BDataset%26zhida_source%3Dentity" target="_blank"&gt;Waymo Open Dataset&lt;/a&gt;&lt;/span&gt;、&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhida.zhihu.com%2Fsearch%3Fcontent_id%3D258754464%26content_type%3DArticle%26match_order%3D1%26q%3DnuScenes%25E6%2595%25B0%25E6%258D%25AE%25E9%259B%2586%26zhida_source%3Dentity" target="_blank"&gt;nuScenes 数据集&lt;/a&gt;&lt;/span&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;推理数据&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;形态&lt;/strong&gt;：来自机器人或车辆上搭载的各种传感器的实时、连续的数据流。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;特征&lt;/strong&gt;：数据处理的低延迟性对于物理 AI 系统做出及时、安全的决策和行动至关重要。系统还需要对传感器噪声、数据丢失或遮挡等情况具有鲁棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
 &lt;img src="https://oscimg.oschina.net/oscnet//f6effd68cabc43be465afc81f71a66c4.jpg" width="1080" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;审视这四大 AI 领域对数据的需求演变，可以发现一个清晰的趋势：AI 模型对数据的「胃口」越来越大，要求的数据集规模日益庞大，多样性和复杂性也与日俱增。从机器学习对结构化数据的依赖，到深度学习对海量非结构化数据的渴求，再到生成式 AI 对网络规模多模态数据的吞噬，以及 Physical AI 对高维、多传感器融合数据的整合，无不体现了这一趋势。这种趋势意味着，数据的「AI 就绪」不仅关乎数据本身的质量和形态，也对底层的数据存储、处理和管理技术平台提出了更高的要求。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;打造 AI 的坚实基础：通往 AI-ready Data 之路&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;将原始数据转化为 AI-ready Data，是一项涉及多个步骤的持续性系统工程，而非一蹴而就的任务。这需要随着 AI 技术、业务需求和数据源的变化而不断演进和优化，是一个动态的、持续改进的过程。一个典型的数据准备流程始于数据收集与获取，即从多样化的内外部来源汇集原始数据，&lt;strong&gt;尤其值得强调的是，在 AI 时代，企业自身积累的、独特的内部数据是构建差异化竞争优势和深化护城河的核心战略资产，对其的有效盘活与利用是首要任务。&lt;/strong&gt;随后是数据清洗与预处理，旨在识别并修正原始数据中的错误、不一致、缺失值和重复项，以提升数据质量。接着进行数据转换与丰富，将数据转化为适合 AI 模型的格式，可能包括特征工程、数据聚合，并通过添加元数据等方式增强数据上下文。对于监督学习任务，准确的数据标注是不可或缺的一环。在数据投入训练之前，需进行严格的数据验证与质量保证。最后，贯穿整个数据生命周期的是数据治理与安全，要求企业建立清晰的管理政策，确保数据合规、安全。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;AI-ready Data 并非遥不可及的理想概念，而是成功且可靠的人工智能应用的坚实基石。正如高质量原材料是优质产品的先决条件，高质量的 AI-ready Data 是构建高性能 AI 模型的根本保障，&lt;strong&gt;特别是当这些数据源自企业内部，承载着特定业务洞察和运营经验时，其转化为 AI 洞察的能力，将直接赋能企业构建难以复制的竞争壁垒。&lt;/strong&gt;它能够显著提升模型的准确性和可靠性，加速 AI 应用的研发部署，并最终驱动商业价值和创新突破。因此，企业应将提升数据就绪水平，尤其是内部数据的「AI 就绪」水平，视为一项战略要务，而非项目启动后的被动补救。通往 AI 驱动的创新之路，很大程度上是由对自身独特数据资产的深度挖掘和高质量准备铺就的。&lt;/p&gt; 
&lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;拥抱 AI-ready Data，意味着正视数据的挑战，投入必要资源，建立完善的流程和文化，核心目标在于充分释放企业内部沉淀数据的潜在价值。这无疑是一项艰巨的任务，但其回报——通过人工智能洞察自身运营、优化决策、创新产品与服务，从而在市场竞争中占据领先地位——将是无可估量的。生成式 AI 并非短暂趋势，而是一场深刻的变革，而适配这种变革的数据基础设施和数据就绪能力，&lt;strong&gt;特别是将企业独有的内部数据转化为驱动 AI 的优质燃料的能力，将是企业在这场变革中深化护城河、立于不败之地的关键。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354670</guid>
      <pubDate>Sat, 10 May 2025 10:26:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>RWKV 2025 生态内容征集大赛 | 5 月投稿作品及评审结果</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;大家好，我们在 2024 年底推出了 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」，公开征集 RWKV 相关的作品，包括但不限于 RWKV 相关的论文、讲解 RWKV 的教程，以及基于 RWKV 的应用等。&lt;/p&gt; 
&lt;p&gt;2025 年 5 月，活动共收到 RWKV 生态作品投稿 &lt;strong&gt;2 份&lt;/strong&gt;，包括 &lt;strong&gt;1 篇论文、1 个教程&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文将公布 2025 年 5 月的活动投稿作品及评审结果。&lt;/p&gt; 
&lt;h2&gt;评审结果&lt;/h2&gt; 
&lt;h3&gt;评审结果省流版&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名称&lt;/th&gt; 
   &lt;th&gt;作品分类&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初评奖项&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;biomems&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-V7 模型解析与实战：架构原理、机制剖析及自定义微调模型效果展示&lt;/td&gt; 
   &lt;td&gt;教程&lt;/td&gt; 
   &lt;td&gt;坤&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下面是「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg" target="_blank"&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」 5 月投稿获奖的作品介绍。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;论文类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Maximizing Asynchronicity in Event-based Neural Networks&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.11165" target="_blank"&gt;https://arxiv.org/abs/2505.11165&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：biomems&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;项目介绍：论文提出了一种新的异步到同步框架 EVA，用于实时事件相机数据处理&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;该框架基于 RWKV-6 构建了高效的异步编码器，实现了逐事件的表示更新，并采用自监督学习方法获得具有高度泛化能力的事件表示。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="Maximizing Asynchronicity" src="https://oscimg.oschina.net/oscnet/up-3ca302b9d83762576c1d83a5c2add0e09c0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;教程类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-V7 模型解析与实战：架构原理、机制剖析及自定义微调模型效果展示&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F1904346608985944244%3Fshare_code%3D1nLMwML5XPvsB%26utm_psn%3D1904552110802055283" target="_blank"&gt;https://zhuanlan.zhihu.com/p/1904346608985944244?share_code=1nLMwML5XPvsB&amp;amp;utm_psn=1904552110802055283&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;投稿人：坤&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;项目介绍：从原理解析到微调实践的全流程教程&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;首先带领初学者一起初步理解 RWKV 架构，然后使用 RWKV-PEFT 微调仓库进行了全流程的微调并展示了微调效果，在学习原理的同时，微调属于自己的 RWKV。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="RWKV-V7 模型解析与实战" src="https://oscimg.oschina.net/oscnet/up-0c74d7e4f003a4e0322e3aee4c8f3e90ec4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;奖品/奖金发放规则&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;实物奖品（RWKV 周边等）&lt;strong&gt;以&lt;/strong&gt;顺丰快递&lt;/strong&gt;方式发出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;奖金&lt;/strong&gt;以&lt;strong&gt;转账或第三方线上平台&lt;/strong&gt;等方式发放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情况下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;领取奖金，团队内部&lt;strong&gt;自行协商分配奖金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿与奖项升级&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均会获得&lt;strong&gt;评审意见&lt;/strong&gt;。请根据评审意见优化你的作品，然后可&lt;strong&gt;再次投稿以升级奖项&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;奖项成功升级时，我们将补发&lt;strong&gt;前后两个奖金的差价&lt;/strong&gt;。例如投稿作品从铁奖（888 元）升级到银奖（2888 元），则补发 2888-888=2000 元奖金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活动海报&lt;/strong&gt;，欢迎各位转发！&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e11c3df39730d4d504ca57e04f84ed60f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354657</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354657</guid>
      <pubDate>Sat, 10 May 2025 09:42:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
  </channel>
</rss>
