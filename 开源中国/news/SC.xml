<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 09 Aug 2025 02:49:16 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Perplexity 为特朗普 Truth Social 提供技术支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 初创公司 Perplexity 正在为美国总统特朗普的社交媒体平台 Truth Social 提供技术支持，推出全新的 AI 搜索引擎。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这款名为"Truth Search AI"的搜索引擎已在 Truth Social 网页版上线，iOS 和 Android 应用的公测版本预计将在"不久的将来"推出。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特朗普媒体在新闻稿中表示，Perplexity 的技术能够提供"直接、上下文准确的答案和透明引用"，这将帮助 Truth Social"指数级增加"用户可获取的信息量。不过，该社交媒体平台仍保留对 AI 搜索引擎信息来源的控制权。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Truth Social 使用的是 Perplexity Sonar API，该接口承诺能够查询网络以获取&lt;span&gt;最新&lt;/span&gt;和经过验证的信息，即使这些信息来自屏蔽 Perplexity 爬虫的网站，同时支持结构化输出，允许用户自定义搜索引擎响应的格式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Perplexity 发言人杰西·德怀尔向 TechCrunch 透露，Sonar API 的准确性取决于 Truth Social 限制的信息源范围。德怀尔表示:"我们对此没有可见性或控制权，就像你在自己公司内部使用 API，或者作为学术研究人员想要用它搜索自己的数据一样。"&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TechCrunch 已联系特朗普媒体了解更多信息，包括 Truth Search AI 是否能访问整个网络、是否会优先考虑某些信息源，以及 AI 是否会被指示对总统和现任政府给出有利回应，对民主党人给出不利评价。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;为了评估该搜索机器人会引用哪些信息源，Axios 向其提出了一系列问题，如"2021 年 1 月 6 日发生了什么?"和"唐纳德·特朗普为什么被弹劾?"在所有回应中，FoxNews.com 要么是最常见的信息源，要么是&lt;span&gt;唯一&lt;/span&gt;列出的信息源。其他信息源包括 FoxBusiness.com、《华盛顿时报》或《大纪元时报》。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;相比之下，Perplexity 的公共搜索引擎返回更广泛的信息源，包括维基百科、Reddit、YouTube、NPR 和 Politico 等。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;特朗普媒体 CEO、前加利福尼亚州国会议员德文·努内斯在声明中表示，Truth Social 计划"根据用户反馈完善和扩展搜索功能，同时为平台实施广泛的额外增强功能"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Perplexity 首席商务官德米特里·舍韦连科在声明中也指出，Perplexity 的 AI 提供带有"透明引用的答案，让任何人都能深入挖掘"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;7 月下旬，特朗普在发布 AI 行动计划的同时，颁布了一项针对"有偏见 AI"或非"意识形态中立"模型的行政命令。该命令特别将有关种族或性别、无意识偏见、系统性种族主义以及其他归入多元化、公平和包容性范畴的观念称为"普遍且具有破坏性"的意识形态，可能"扭曲输出的质量和准确性"。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Truth Search AI 的推出正值 OpenAI、Anthropic 和谷歌等&lt;span&gt;顶级&lt;/span&gt;AI 公司被列入获准向联邦民用机构销售服务的供应商名单。OpenAI 周三与美国政府中央采购部门达成协议，以每年仅 1 美元的价格向各机构销售 ChatGPT 企业版。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365083</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365083</guid>
      <pubDate>Thu, 07 Aug 2025 10:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Valkey 单点性能比肩 Redis 集群了？Valkey8.0 新特性分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、&amp;nbsp; 背景&lt;/h1&gt; 
&lt;p&gt;Valkey 社区于 2024 年 09 月发布了 Valkey8.0 正式版，在之前的文章《Redis 是单线程模型？》中，我们提到，Redis 社区在 Redis6.0 中引入了多线程 IO 特性，将 Redis 单节点访问请求从 10W/s 提升到 20W/s，而在 Valkey8.0 版本中，通过引入异步 IO 线程、内存预取（Prefetch）、内存访问分摊（MAA）等新特性，并且除了将读写网络数据卸载到 IO 线程执行外，还会将 event 事件循环、对象内存释放等耗时动作也卸载到 IO 线程执行，使得 Valkey 单节点访问请求可以提升到 100W/s，大幅提升 Valkey 单节点性能。&lt;/p&gt; 
&lt;p&gt;Valkey 8.0 中引入的异步 IO 与 Redis 6.0 中的多线程 IO 有什么区别？Valkey8.0 中如何应用内存预取和内存访问分摊技术进一步来提升性能的？本篇文章让我们来一起看看。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2024 年，Redis 商业支持公司 Redis Labs 宣布 Redis 核心代码的许可证从 BSD 变更为 RSALv2 ，明确禁止云厂商提供 Redis 托管服务，这一决定直接导致社区分裂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为维护开源自由，Linux 基金会联合多家科技公司（包括 AWS、Google Cloud、Oracle 等）宣布支持 Valkey ，Valkey 基于 Redis 7.2.4 开发，作为 Redis 的替代分支。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Valkey8.0 为 Valkey 社区发布的首个主要大版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最新消息，在 Redis 项目创始人 antirez 今年加入 Redis 商业公司 5 个月后，Redis 宣传从 Redis8 开始，Redis 项目重新开源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、&amp;nbsp; 异步 IO 线程背景&lt;/h1&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;Redis6.0 多线程 IO&lt;/h4&gt; 
&lt;p&gt;在 Redis 6.0 中引入了多线程 IO 特性，用来处理网络数据的读写和协议解析，读写数据执行流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5375925ba50c7c815558c17f2726d0f5.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Redis6.0 中，读数据流程是主线程先将所有可读客户端加入一个队列，全部处理完后，再通过 RR 算法将这些可读客户端分配给 IO 线程，由 IO 线程执行读数据；写数据流程类似处理。&lt;/p&gt; 
&lt;p&gt;尽管引入多线程 IO 大幅提升了 Redis 性能，但是&amp;nbsp;&lt;strong&gt;Redis6.0 的多线程 IO 仍然存在一些不足：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;主线程在处理客户端命令时，IO 线程会均处于空闲状态；由于主线程会阻塞等待所有 IO 线程完成读写数据，主线程在执行 IO 相关任务期间的性能受到最慢 IO 线程速度的限制&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;由于主线程同步等待 IO 线程，IO 线程仅执行读取解析和写入操作，主线程仍然承担大部分 IO 任务&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;Valkey 8.0 异步 IO 线程&lt;/h4&gt; 
&lt;p&gt;Valkey8.0 通过使用任务队列使主线程向 IO 线程发送任务，IO 线程异步并行执行任务提升整体性能。Valkey 8.0 异步 IO 线程工作流程整体设计图如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//7bcc95e1d36fbabb48b1e8829daacc4a.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_5"&gt;&lt;/span&gt; 
&lt;h4&gt;IO 线程初始化&lt;/h4&gt; 
&lt;p&gt;在 Valkey 启动时进行初始化的时候，根据配置的线程数量 server.io_threads_num&amp;nbsp;决定是否创建异步 IO 线程，如果 server.io_threads_num == 1 表示不开启，另外，IO 线程数量最大不超过 15 个；如果配置开启异步 IO 线程，则初始化的时候按需创建异步 IO 线程。&lt;/p&gt; 
&lt;span id="OSC_h4_6"&gt;&lt;/span&gt; 
&lt;h4&gt;线程间通信&lt;/h4&gt; 
&lt;p&gt;Valkey 初始化创建 IO 线程的时候，会给每个 IO 线程创建一个&lt;strong&gt;静态、无锁、固定大小（大小为 2048）的&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;环形缓冲区&lt;/strong&gt;作为任务队列，用于主线程发送任务，以及 IO 线程接收任务。&lt;/p&gt; 
&lt;p&gt;环形缓冲区是从主线程到 IO 线程的单向通道。当发生读/写事件时，主线程会发送一个读/写任务，然后在进入 event 事件监测休眠之前，它会遍历所有待处理的读/写客户端，检查每个客户端的 IO 线程是否已经处理完毕。IO 线程通过切换客户端结构体上的原子标志 read_state / write_state 来表示它已经处理完一个客户端的读/写操作。&lt;/p&gt; 
&lt;span id="OSC_h4_7"&gt;&lt;/span&gt; 
&lt;h4&gt;读数据流程&lt;/h4&gt; 
&lt;p&gt;读数据流程如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//48484b4ab3428948bf602d27b4c2e200.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;主线程监测到有读事件时，检查是否开启 IO 线程，如果开启了 IO 线程，会根据算法选择一个 IO 线程，检查选中的 IO 线程任务队列是否已满，如果任务队列未满，则将该待读事件客户端加入 IO 线程的任务队列。&lt;/p&gt; 
&lt;p&gt;如果未开启 IO 线程，或者选中的 IO 线程任务队列已满，则由主线程完成读数据操作并执行命令。&lt;/p&gt; 
&lt;p&gt;IO 线程循环从任务队列获取任务，如果是读数据任务，则执行读数据流程。先读取数据，然后解析命令，并从命令列表中查找命令并保存在指定字段（这里也是把本来由主线程在执行命令时执行的动作卸载到 IO 线程完成）。&lt;/p&gt; 
&lt;p&gt;主线程在进入 event 事件监听睡眠前，循环遍历所有在等待 IO 线程读数据的客户端，检查数据是否读取完成，如果是则加入批量预取数据数组，当全部客户端都检查完成或者批量预取数据数组存满，则批量执行命令。&lt;/p&gt; 
&lt;p&gt;在 Redis6.0 中，需要先将所有可读客户端存入一个队列，再遍历可读客户端列表通过 RR 算法将可读事件分配到不同的 IO 线程中，然后主线程设置 IO 线程开启读数据，在主线程执行这些操作期间，IO 线程均处于空闲状态。&lt;/p&gt; 
&lt;p&gt;在 Valkey 8.0 中，每监测到一个可读事件，立即通过任务队列发送到一个 IO 线程，IO 线程立即可以开始读数据操作，主线程遍历后续可读事件期间，IO 线程异步在执行读取操作。&lt;/p&gt; 
&lt;span id="OSC_h4_8"&gt;&lt;/span&gt; 
&lt;h4&gt;写数据流程&lt;/h4&gt; 
&lt;p&gt;主线程执行完每个命令时，将客户端加入等待等写队列 clients_pending_write，将响应客户端的数据写入到响应缓存 buf 或者 reply 链表。&lt;/p&gt; 
&lt;p&gt;主线程处理完所有命令后，循环遍历等待写队列 clients_pending_write，将通过算法选择一个 IO 线程，如果选中的 IO 线程任务队列未满，将该客户端写数据任务加入 IO 线程的任务队列。&lt;/p&gt; 
&lt;p&gt;IO 线程循环从任务队列获取任务，如果是写数据任务，则执行写数据流，将数据写回给用户。&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;动态调整 IO 线程数量&lt;/h4&gt; 
&lt;p&gt;每次在有可读事件或者可写事件需要执行前，Valkey 会根据可读/写事件数量，动态调整活跃 IO 线程数量，最大活跃 IO 线程数量不超过设置的允许 IO 线程数量（固定为 15）。&lt;/p&gt; 
&lt;p&gt;根据可读/写事件数量、每个 IO 线程可执行事件数量（可配置）、以及最大允许活跃 IO 线程数量，计算需要的目标活跃 IO 线程数量，当前活跃 IO 线程数量小于目标数量时，可增加活跃 IO 线程，当前活跃 IO 线程数量大于目标数量时，可减少活跃 IO 线程。&lt;/p&gt; 
&lt;p&gt;动态增加或者减少活跃 IO 线程数量，减少活跃 IO 线程并不会直接关闭创建出来的 IO 线程，而是通过加锁使当前没有任务可执行的 IO 线程暂停轮询查找任务，避免 IO 线程不必要的空轮询；同样增加活跃 IO 线程只需要主线程释放锁即可，IO 线程获取到锁后，开始轮询获取是否有可执行任务需要执行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;尽管 I/O 线程数量可动态调整，具有动态特性，但主线程仍保持线程亲和性，确保在可能的情况下由同一个 I/O 线程处理同一客户端的 I/O 请求，从而提高内存访问的局部性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h4_10"&gt;&lt;/span&gt; 
&lt;h4&gt;卸载更多任务到 IO 线程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 8.0 中，除了读取解析数据/写入操作之外，还将很多额外的工作卸载到 I/O 线程，以便更好地利用 I/O 线程并减少主线程的负载。&lt;/p&gt; 
&lt;span id="OSC_h4_11"&gt;&lt;/span&gt; 
&lt;h4&gt;事件轮询卸载到 IO 线程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 中使用了 IO 多路复用模型实现在主线程中来高效处理所有来自客户端的连接读写访问，而套接字轮询系统调用（例如 epoll_wait）是开销很大的过程，仅由主线程来执行会消耗大量主线程时间。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，当主线程有待处理的 I/O 操作或要执行的命令时，主线程都会将套接字轮询系统调用调度到 IO 线程执行，否则由主线程自身来执行。&lt;/p&gt; 
&lt;p&gt;为避免竞争条件，&lt;strong&gt;在任何给定时间，最多只有一个线程（io_thread 或主线程）执行 epoll_wait&lt;/strong&gt;，当主线程将事件轮询系统调用分配给一个 IO 线程执行后，主线程执行完命令处理后，不再执行事件轮询系统调用，而是直接检查 IO 线程的轮询等待结果，查看是否有可读写事件。&lt;/p&gt; 
&lt;span id="OSC_h4_12"&gt;&lt;/span&gt; 
&lt;h4&gt;对象释放卸载到 IO 线程&lt;/h4&gt; 
&lt;p&gt;在 Valkey 读取客户端数据后，命令解析过程中会分配大量命令参数对象，在命令处理完成后，需要释放为这些命令参数分配的内存空间，在 Valkey8.0 中，将这些命令参数内存空间释放分配给 IO 线程执行，并且会分配给执行该参数解析（内存分配）的同一个 IO 线程来执行（通过客户端 ID 进行标识）。&lt;/p&gt; 
&lt;span id="OSC_h4_13"&gt;&lt;/span&gt; 
&lt;h4&gt;命令查找卸载&lt;/h4&gt; 
&lt;p&gt;如前面在读数据流程中提到的，当 IO 线程解析来自客户端的 Querybuf 的命令时，它可以在命令字典中执行命令查找，并且 IO 线程会将查找到的命令存储在客户端的指定字段中，后续主线程执行命令时直接使用即可，可以节省主线程执行命令的时间。&lt;/p&gt; 
&lt;span id="OSC_h1_14"&gt;&lt;/span&gt; 
&lt;h1&gt;三、&amp;nbsp;数据预取 (Prefetch) 与内存访问分摊（MAA）&lt;/h1&gt; 
&lt;p&gt;在 Valkey8.0 中引入异步 IO 线程提高并行度，并且将更多的工作转移到 IO 线程，将主线程执行的 I/O 操作量降至最低，此时，经过测试，单个 Valkey 节点每秒处理请求可达 80W。&lt;/p&gt; 
&lt;p&gt;通过分析开启 IO 线程后 Valkey 性能，主线程大部分时间都花销在访问内存查找 key，这是因为 Valkey 字典是一个简单但低效的链式哈希实现，在遍历哈希链表时，每次访问 dictEntry 结构体、指向键的指针或值对象，都很可能需要进行昂贵的外部内存访问。&lt;/p&gt; 
&lt;p&gt;于是在 Valkey8.0 中引入了**数据预取（Prefetch）和内存访问分摊（MAA）**技术，进一步提升 Valkey 单节点访问性能。&lt;/p&gt; 
&lt;span id="OSC_h4_15"&gt;&lt;/span&gt; 
&lt;h4&gt;数据预取（Prefetch）&lt;/h4&gt; 
&lt;p&gt;随着摩尔定律在过去 30 年间的持续生效，CPU 的运算速度大幅提升，而存储器（主要是内存）的速度提升相对较慢，这导致了存储器与 CPU 之间的速度差异。当 CPU 执行指令时，如果需要从内存中读取数据或指令，由于存储器速度的限制，CPU 可能需要等待访问存储器操作完成，从而导致性能瓶颈。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//68471ba00c97e2f740ede5c9479170c8.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了解决访问存储器瓶颈这一问题，现代计算机系统采用了多级缓存及内存层次结构，包括 L1、L2、L3 缓存以及主存等。尽管高速缓存（Cache）能够提供更快的访问速度，但其容量有限，当 CPU 访问的数据无法在高速缓存中找到时，就需要从更慢的内存层级中获取数据，这会导致较高的访问延迟，并降低整体性能。&lt;/p&gt; 
&lt;p&gt;数据预取（Prefetching）技术可以在一定程度上解决访问存储器成为 CPU 性能瓶颈的问题。数据预取是一种提前将数据或指令从内存中预先加载到高速缓存中的技术。通过预取，CPU 可以在实际使用之前将数据预先加载到缓存中，从而减少对内存的访问延迟。这样可以提高访问存储器的效率，减少 CPU 等待访问存储器的时间，从而提升整体性能。&lt;/p&gt; 
&lt;p&gt;__builtin_prefetch() 是 gcc 编辑器提供的一个内置函数，它通过对数据手工预取到 CPU 的缓存中，减少了读取延迟，从而提高程序的执行效率。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，主线程在执行命令之前，通过使用 __builtin_prefetch() 命令，对所有即将操作的命令参数、key 及对应的 value 进行批量预取，提高主线程执行命令的效率。&lt;/p&gt; 
&lt;span id="OSC_h4_16"&gt;&lt;/span&gt; 
&lt;h4&gt;内存访问分摊（MAA）&lt;/h4&gt; 
&lt;p&gt;内存访问摊销 (MAA) 是一种旨在通过降低内存访问延迟的影响来优化动态数据结构性能的技术。它适用于需要并发执行多个操作的情况。其背后的原理是，对于某些动态数据结构，批量执行操作比单独执行每个操作更高效。&lt;/p&gt; 
&lt;p&gt;这种方法并非按顺序执行操作，而是将所有操作交错执行。具体做法是，每当某个操作需要访问内存时，程序都会预取必要的内存并切换到另一个操作。这确保了当一个操作因等待内存访问而被阻塞时，其他内存访问可以并行执行，从而降低平均访问延迟。&lt;/p&gt; 
&lt;span id="OSC_h4_17"&gt;&lt;/span&gt; 
&lt;h4&gt;Valkey8.0 预取数据应用&lt;/h4&gt; 
&lt;p&gt;Valkey 是一个键值对数据库，在 Valkey 中的键值对是由字典（也称为 hash 表）保存的，如下图所示的链式哈希表。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cd1cd5adf93474cd0357a33b0979b79e.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 之前，在哈希表中查找一个 key 及对应的 value 步骤如下描述：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;计算 key 的 hash 值，找到对应的 bucket&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;遍历存储在 bucket 中通过链表连接的 entry，直到找到需要的 key&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果找到 key，再访问 key 映射的 RedisObj（也就是存储的 value），如果存储的 value 是 OBJ_ENCODING_RAW 类型，还需要进一步访问内存地址获取真正的数据&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;每一步操作都需要等待前面的步骤完成内存数据读取，整个访问过程是一个串行步骤，这种动态数据结构会阻碍处理器推测未来可以并行执行的内存加载指令的能力，因此访问内存成为 Valkey 处理数据的性能瓶颈。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 中，对于具有可执行命令的客户端（即 IO 线程已解析命令的客户端），主线程将创建一个最多包含 16 条命令的批次，批量处理这些命令。并且执行命令前，先将命令参数预取到主线程的一级缓存中，再将所有命令所需的字典条目 entry 和值 value 都从字典中预取。&lt;/p&gt; 
&lt;p&gt;同时，预取命令所需的字典条目 entry 和值 value 时遍历字典的方式与上述查找 key 过程类似，不同的是，每个 key 每次只执行一步，然后不等待从内存中完成读取数据，而只是预取数据，然后继续执行下一个 key 的下一次预取动作。这样当所有 key 都遍历完成第一步后，开始执行第二步的时候，执行第二步所需的第一步数据已经预取到了 L1 高速缓存。这样通过交错执行所有 key，并且结合预取，达到分摊访问内存的效果。&lt;/p&gt; 
&lt;p&gt;单个 key 预取流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9e9c931a61fcbcd4bbc4b3e96130cef9.jpeg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;每批次多个 key 预取流程则是&lt;strong&gt;循环遍历每个 key 交错执行&lt;/strong&gt;上述步骤，先预取其中一个 key 的 bucket，然后不会执行预取该 key 的 entry，因为此时如果接着流程预取该 key 的 entry，需要等待将该 key 的 bucket 内存读取出来；而是执行下一个 key 的预取动作。也就是达成所有 key 的预取动作一直在并行执行效果，分摊内存访问时间。&lt;/p&gt; 
&lt;p&gt;多个 key 批量预取流程如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f3f922b4aa11d09e6fdbfbdd56467008.webp" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;循环遍历每个 key 交错执行上述步骤，先执行一个 key 的预取动作，然后交错执行另一个 key 的预取动作，所有 key 的预取动作并行执行，降低所有 key 访问内存总时间。&lt;/p&gt; 
&lt;p&gt;同一批次所有 key 和 value 都完成预取后，主线程开始批量执行命令。相比在 Valkey8.0 之前的版本中，主线程逐个处理每个客户端命令，批量预取数据加上批量处理，大幅提升单节点 Valkey 服务器性能，社区测试单节点 Valkey 访问请求可以达到每秒 120W。&lt;/p&gt; 
&lt;span id="OSC_h1_18"&gt;&lt;/span&gt; 
&lt;h1&gt;四、&amp;nbsp; 总结&lt;/h1&gt; 
&lt;p&gt;本文分析了在 Valkey8.0 中通过引入**异步 IO 线程、内存预取（Prefetch）、内存访问分摊（MAA）**等新特性，极大的提升了 Valkey 单节点性能，这些技术手段和算法思想也值得我们在实际业务开发中借鉴和使用。&lt;/p&gt; 
&lt;p&gt;Valkey8.0 中以上性能提升特性由亚马逊贡献，亚马逊也做了一系列压测对比，在增强 IO 多路复用的加持下，&lt;strong&gt;Valkey 单节点 QPS 最大可以超过 100W&lt;/strong&gt;，压测数据可以参考《推陈出新 – Valkey 性能测试：探索版本变迁与云托管的效能提升》&lt;em&gt;（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fcn%2Fblogs%2Fchina%2Fvalkey-performance-testing-exploring-version-changes-and-cloud-hosting-performance-improvements%2F%25EF%25BC%2589" rel="nofollow" target="_blank"&gt;https://aws.amazon.com/cn/blogs/china/valkey-performance-testing-exploring-version-changes-and-cloud-hosting-performance-improvements/）&lt;/a&gt;&lt;/em&gt;，单节点性能完全可以比肩 Redis 低版本中等规模集群了。&lt;/p&gt; 
&lt;p&gt;在 Valkey8.0 版本中，除了以上重大性能提升优化以外，还在提升内存利用率、加快主从复制效率、增强 resharding 过程中高可用性、实验性支持 RDMA，以及提升集群的观测性等方面都进行了多项优化。我们后续再详细介绍。&lt;/p&gt; 
&lt;p&gt;Valkey8.0 正式版发布至今时间还不算太长，经过一段时间的验证后，我们也会考虑将自建 Redis server 版本逐步升级到新版本，为业务提供性能更优的缓存服务。&lt;/p&gt; 
&lt;span id="OSC_h4_19"&gt;&lt;/span&gt; 
&lt;h4&gt;往期回顾&lt;/h4&gt; 
&lt;p&gt;1.Java SPI 机制初探｜得物技术&lt;/p&gt; 
&lt;p&gt;2.得物向量数据库落地实践&lt;/p&gt; 
&lt;p&gt;3.Java volatile 关键字到底是什么｜得物技术&lt;/p&gt; 
&lt;p&gt;4.社区搜索离线回溯系统设计：架构、挑战与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;5.从 「卡顿」 到 「秒开」：外投首屏性能优化的 6 个实战锦囊｜得物技术&lt;/p&gt; 
&lt;p&gt;文 / 竹径&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687322</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687322</guid>
      <pubDate>Thu, 07 Aug 2025 10:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Meta 组建新实验室牵头开发新版 Llama 大语言模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcn.wsj.com%2Farticles%2F%25E6%258F%25AD%25E7%25A7%2598meta%25E8%25B6%2585%25E7%25BA%25A7%25E6%2599%25BA%25E8%2583%25BD%25E7%2589%25B9%25E9%2581%25A3%25E9%2598%259F-tbd-lab-2ce269af" target="_blank"&gt;据华尔街日报&lt;/a&gt;&lt;/u&gt;，Meta Platforms 公司在推动构建比人类更聪明的计算机思维的过程中，一个名为 TBD 实验室的团队走在了最前沿，该团队拥有许多该公司从竞争对手实验室挖来的研究人员，其中一些人的薪酬高达数千万或数亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-69fd19271a38218d5f585cf2d85b30b1420.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据知情人士透露，TBD 实验室 (to be determined，意为「待定」) 正在牵头开发最新版本的大语言模型 Llama。上周，负责监督 Meta 超级智能实验室的首席人工智能官亚历山大·王在给员工的一份备忘录中写道，TBD 实验室将与 Meta 的其他人工智能团队合作开展各种项目，包括即将发布的模型、模型推理能力的扩展和人工智能代理的开发。&lt;/p&gt; 
&lt;p&gt;新的 Llama 项目由 Jack Rae 领导，他是从谷歌聘请到 TBD 实验室的。Meta 现有的 Llama 团队成员和 TBD 实验室正在合作开发这款产品。该模型还没有正式名称，但在内部被一些人称为 Llama4.5 和 Llama 4。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365065</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365065</guid>
      <pubDate>Thu, 07 Aug 2025 10:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee 移动软件工厂：突破网络限制的开发新模式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近年来，在&lt;strong&gt;软件工厂&lt;/strong&gt;的大趋势下，各大单位都在致力于打造专业化的软件工厂，提升研发体系化能力。然而在实际研发过程中，特别是在&lt;strong&gt;嵌入式开发、FPGA 开发及涉密系统场景下&lt;/strong&gt;，常常会遇到如下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;研发人员需前往外部实验室、测试基地或现场环境进行嵌入式系统或专用硬件调试；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;现场网络与软件工厂部署环境物理隔离，无法访问原有的研发平台、代码仓库、流水线等基础能力；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;调试周期较长、频繁进出，导致效率低、环境切换复杂、数据易丢失；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;外部现场开发缺乏标准化工具支撑，过程依赖人工操作，难以实现研发自动化与资产规范管理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不仅如此，在武器装备开发、外场测试、保密单位等典型任务中，还面临着更为复杂的挑战：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;任务高度定制，需频繁适配不同平台、接口与运行环境，导致调试与验证工作量陡增；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉密限制下，无法使用远程桌面、USB 存储、无线传输等常规手段，资料交换与程序部署极为低效；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;关键测试资源仅存在于特定硬件设备或外场环境中，无法常态化复现，严重影响开发节奏；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉及嵌入式、通信、导控等多专业团队，因缺乏统一平台，协同开发进展缓慢；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;典型部署场景（如舰船、机载、野外）环境恶劣，板卡接入困难、电源波动大、温湿度极端，调试失败率高，返工成本大；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多型号并行开发，需求频繁变更，缺少统一配置管理，容易误刷程序或测试用例错配，带来不可估量损失；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;开发设备与测试设备一一绑定，调试过程全靠人工值守与现场操作，容错率低、加班成常态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题不仅仅是「效率低」，更直接影响交付周期、质量可控性与工程资产的积累能力。&lt;/p&gt; 
&lt;p&gt;为破解这一通用难题，&lt;strong&gt;Gitee 推出全新形态的「移动软件工厂」解决方案&lt;/strong&gt;。通过具备便携性、标准化与可控性的移动研发平台，帮助团队打破物理边界，实现「随时随地、无惧隔离」的高效协同，真正打通现场作业与总部工厂之间的能力壁垒。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175018_uILk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;什么是移动软件工厂&lt;/h2&gt; 
&lt;p&gt;移动软件工厂是一套可&lt;strong&gt;移动、自包含、灵活装配的软件开发环境&lt;/strong&gt;，可以根据外场环境的研发需求，将研发过程中所需的各类工具打包至便携设备中（如代码仓库、构建环境、测试框架等等），支持真正的&lt;strong&gt;离线研发闭环&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;不同于传统的「镜像克隆」或「云端同步」模式，&lt;strong&gt;Gitee 移动软件工厂强调灵活装配、现场自运行、过程可控可审计&lt;/strong&gt;，具备以下关键能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;研发能力可迁移：将项目管理、需求管理、代码管理、构建发布等核心研发能力封装为容器与镜像，随设备下发，实现「工具随人走，能力随处有」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自动化保障一致性：即使在与总部隔离的环境下，依然可本地运行标准化流水线与质量流程，保障研发一致性与规范不打折。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模块化灵活装配：支持按需加载代码仓、制品库、流水线、需求管理等模块，满足不同项目、现场与网络环境下的定制化需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据安全同步机制：支持智能增量同步，传输过程通过国密 SM4 进行加解密，一键回传增量代码变更内容、构建制品与项目审计数据，实现离岛研发资产与过程数据回传总部。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;凭借这套可组装式部署架构，移动软件工厂可根据实际任务灵活配置，适配多种交付形态，真正实现「因需而建、随地可用」，在分布式、离线场景下展现出领先优势。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175034_SvGM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总部与移动协同开发：保障资产回流与数据闭环&lt;/h2&gt; 
&lt;p&gt;在面对多场景、多环境的复杂交付需求时，Gitee 提出了「移动软件工厂」解决方案。其核心是构建一套&lt;strong&gt;可统一规范、可离线运行、可有序回流、资产安全可靠&lt;/strong&gt;的研发闭环体系。&lt;/p&gt; 
&lt;p&gt;总部统一提供依赖库、构建镜像、安全规则等资源标准；现场研发人员通过移动软件工厂设备，即可在无网络环境下完成编码、构建、测试及质量检测任务；研发数据与资产通过智能增量机制与受控路径，&lt;strong&gt;实现从本地到总部的高效回流与沉淀复用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;下图展示了此闭环体系的六大关键模块，从资源规范、现场执行到数据回归，形成端到端的闭环保障：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175110_b5OO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这一机制确保&lt;strong&gt;无论网络通或不通、人员是否分散，研发流程始终连贯&lt;/strong&gt;，最大化保障组织的知识积累、安全合规与多地协作效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;核心能力：一台设备实现完整研发闭环&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;离线项目管理：本地支持需求、任务、缺陷、变更等全流程管理，内置甘特图、燃尽图等常用视图。权限、流程与字段配置与总部保持一致，回归后自动同步，避免标准割裂。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分布式代码管理：基于 Gitee 分布式架构，支持离线提交、签名提交、受保护分支等策略。总部可预设分支策略与合并规则，降低多地协作冲突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地安全扫描：内置基础的代码规范与依赖合规扫描，支持在离线阶段提前发现问题。漏洞库支持定期打包更新，回归后执行完整扫描并联动缺陷管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自动化流水线执行：支持本地 Runner，完成构建、单元测试、打包等关键流程，保持与总部流水线环境一致。也可按需定制适配复杂测试场景，如硬件在环测试等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地依赖管理：预置常用依赖库，支持离线解析、构建不阻塞。回归后统一执行版本冲突检测、许可证合规校验，并生成 SBOM。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 编程助手（离线可用）：内置轻量级 AI 能力，支持代码补全与缺陷提示等功能。支持离线运行，回归总部后可自动更新知识模型。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="715" src="https://static.oschina.net/uploads/space/2025/0808/175128_EMpZ_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175137_y8iT_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;落地实施与部署等级&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;方案评估与定制：梳理现有流程，制定镜像与同步策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;总部环境建设：搭建构建镜像库与合规规则集；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移动环境交付：按项目交付设备并预置管控策略，开展培训；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同步与持续优化：启用智能同步与回归验证，持续更新体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175153_RHxM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;三种部署等级：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;一级部署：数据高可用，适配轻量研发；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;二级部署：数据高可用 + 服务可用，适配小团队协同；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;三级部署：数据高可用 + 服务高可用，适配关键任务场景，支持主备与高可用扩展。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;核心价值与场景收益&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;效率提升：摆脱网络依赖，现场即可构建；模块化部署适配现场差异；远程批量控制减少值守；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全可控：兼容涉密现场，杜绝 USB/远程桌面，符合安全合规要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;质量保障：支持需求变更频繁场景下的配置一致性；减少误刷与错配问题；支持外场硬件对接；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本优化：减少专线/外网依赖，降低环境搭建与驻场支持的人力成本；避免因流程中断造成的延期与差旅开销。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175204_q4od_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;技术底座：架构创新保障可控可溯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;容器化打包：镜像封装，签名验证，SBOM 输出，环境可信；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能增量同步：差异计算，断点续传，适配弱网隔离场景；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全加固机制：全盘加密，权限控制，离线审计日志回传。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;面向未来：软件开发的新范式&lt;/h2&gt; 
&lt;p&gt;移动软件工厂不仅是技术创新，更是研发模式的革新：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;开发环境去中心化，实现真正的分布式开发&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安全与效率兼得，打破二者只能二选一的困局&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 与工程化深度融合，全面赋能研发流程&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在复杂多变的开发环境中，谁能更快适应变化，谁就能领先一步。移动软件工厂，让开发不再受网络束缚，让创新在任何地方都能自由绽放。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;硬件+能力组合一体化交付&lt;/h2&gt; 
&lt;p&gt;为了保障「移动软件工厂」真正落地可用，我们配套交付的并不仅是镜像和工具链，还包括&lt;strong&gt;硬件层面的移动一体机设备&lt;/strong&gt;。如下图所示，它采用&lt;strong&gt;加固型嵌入式工控机形态&lt;/strong&gt;，结合工业级机柜封装与运维支撑能力，可灵活部署于办公室、研发基地、野外现场等场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/175232_2juu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;标准配置说明：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;支持桌面或落地放置，底部带滑轮便于移动；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;机柜内部含计算节点、阵列磁盘、交换机、电源管理模块等；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;支持静音运行、远程管理、电压监控与断电保护；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;交付即用，已预配置 Gitee 移动软件工厂环境，整体为一套脱网可用的 Gitee DevSecOps 私有云。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;当前我们沉淀了三种高频部署模型，适用于不同场景落地，但也支持模块级灵活裁剪与扩展，满足不同客户的研发重点与使用场景（不仅限于以下形式，所有模块均支持按需组合部署）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;移动全流程开发工厂： 面向具备复杂项目管理与协同需求的单位，预置 Team、Insight、Code、CI/CD、Repo 等全栈能力，实现从需求、任务、编码到度量的全流程闭环。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移动代码开发工厂： 聚焦于代码开发与制品构建场景，预装 Code、CI/CD、Repo 等核心能力，适合纯研发场景的「轻协同」团队部署。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;移动智能开发工厂： 在移动代码工厂的基础上，内嵌 AI 编程助手能力（支持离线运行），面向效率导向型团队，赋能本地编码与代码质量保障。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过这些组合，客户可根据任务轻重、团队分工、安全等级，自主灵活选配，实现真正贴合自身场景的「移动式 DevSecOps 工厂」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的现代化研发生态&lt;/h2&gt; 
&lt;p&gt;Gitee DevSecOps 是一站式国产化研发与交付平台，集成了代码托管（Code）、项目协作（Team）、持续集成（CI）、持续部署（CD）、代码安全（Scan）、数据洞察（Insight）等多项能力，致力于打造具备全生命周期管控能力的现代软件工厂。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;平台设计充分考虑关键领域行业对安全性、可控性、合规性的极高要求，具备以下核心特征：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;国产化适配与私有化部署能力：全面兼容国产操作系统与基础设施，支持灵活部署于内网环境，保障数据主权；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全流程 DevSecOps 管控体系：代码从提交、审核、构建、扫描、部署到发布全流程可视、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模块化产品结构：各能力模块（如 Code、Team、Repo、Pipe、Scan、Insight 等）可灵活组合、渐进集成，适配多样化团队与流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度可观测与度量体系：内置研发效能度量与数据洞察引擎，支撑管理者宏观掌控项目态势与交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在多个国家级重大项目与关键领域单位落地实践中，Gitee DevSecOps 已成为构建「自主、可控、高效、安全」的软件工程体系的重要基石。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365060</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365060</guid>
      <pubDate>Thu, 07 Aug 2025 09:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>深度对话尤雨溪：前端的未来、Rust、AI 与开源商业化</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vue 框架与 Vite 构建工具的创造者，VoidZero Inc. 创始人&amp;nbsp;&lt;strong&gt;尤雨溪&lt;/strong&gt;近期到访 Kong 上海办公室展开了一场深度技术交流。讨论的内容不仅涵盖了 Vue 与 Vite 的最新进展，还深入探讨了前端基础设施的 Rust 化趋势、AI 时代开发者的角色转变，以及开源项目的可持续商业路径。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174721_mmqs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是精华回顾：&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;Vue 与 Vite 的发展动态与未来展望&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Vue 3 的稳定演进&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Vue 3 自 2020 年发布以来，现已占据总下载量约 70%，大多数新项目也选择以 Vue 3 为基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;API 设计趋于稳定，未来不会有类似 Vue 2 向 Vue 3 的断代式变更，而是致力于长期维护与优化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;核心关注点将包括开发体验提升、IDE 的 TypeScript 支持强化、以及响应式系统与编译器性能优化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Vapor Mode&lt;/strong&gt;：Vue 3.6 中引入的实验性编译模式，通过重构编译策略实现显著性能提升，但保持现有 API 不变。开发者可以 opt-in 的方式下试用。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Vite 的演化与 VoidZero 的诞生&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;虽最初为 Vue 设计，&lt;strong&gt;Vite&lt;/strong&gt;&amp;nbsp;已成长为跨生态的构建基础设施，支持包括 React、Svelte、Solid、Astro 等框架。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当前约有&amp;nbsp;&lt;strong&gt;接近一半的 Vite 用户来自 React 社区&lt;/strong&gt;，每周下载量超&amp;nbsp;&lt;strong&gt;1500 万次&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪认为 Vite 有潜力成为前端「&lt;strong&gt;共享基础设施层（Shared Infra Layer）&lt;/strong&gt;」，解决生态碎片化问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero Inc.：尤雨溪于 2024 年创立的公司，获 Accel 领投约 460 万美元种子轮融资，目标是构建基于 Rust 的下一代前端工具链。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;Rust 化的前端基础设施&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;为什么选择 Rust？&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;当前 JavaScript 编写的工具链在大型项目中面临性能瓶颈（如 Babel、Webpack）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rust 更适合处理「&lt;strong&gt;定义明确且计算密集&lt;/strong&gt;」的问题，如解析器、转译器、依赖解析等基础设施组件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero 正在将这类「热点路径」迁移到 Rust 编写的工具中，以提升整体构建性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;Rolldown、Oxc 与工具链整合&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;VoidZero 推出的&amp;nbsp;&lt;strong&gt;Rolldown&lt;/strong&gt;&amp;nbsp;是一款 Rust 打造的现代打包器，融合了 ESBuild 的速度优势和 Rollup 的插件机制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;配合&amp;nbsp;&lt;strong&gt;Oxc&lt;/strong&gt;（解析器、Linter、Formatter）和&amp;nbsp;&lt;strong&gt;Vitest&lt;/strong&gt;（测试框架），构建统一、模块化的开发体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🛠️ 工具链将逐步融入 Vite，构成一个基于 Rust 的构建核心、并保留部分 TypeScript 模块以保障灵活性和快速迭代的混合架构。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;未来工具链构想与企业支持&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;VoidZero 规划中的开发体验流程&lt;/strong&gt;： vite new → dev → lint → test → build，实现开箱即用的项目起步与构建体验。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企业级版本将包括：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Monorepo 缓存系统&lt;/strong&gt;：类似 Turborepo/Nx，实现精准缓存失效；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Agent 集成探索&lt;/strong&gt;：让 AI 辅助成为前端开发的一部分。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;尤雨溪强调：「工程导向的项目，应该由最强的工程师去构建底层系统，才能最大化开发者体验。」&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;社区、文化与 AI 时代的思考&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;如何看待开源社区的「噪音」与争议&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;开源社区必然多元，早期常陷入「讨好所有人」的困境。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成熟项目需明确目标用户与社区边界，避免「用户特权感」（Entitlement）影响维护节奏。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;开源是一种合作关系，不是服务关系，良好的行为准则和反馈机制至关重要。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;「前端娱乐圈化」现象&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;某些争论被社交平台放大，导致注意力偏离实际工程问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪建议开发者：「多跳出自身领域，少陷入无意义的框架之争。」&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;AI 与程序员的角色重构&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;未来开发必然是「&lt;strong&gt;人类 + AI 协同&lt;/strong&gt;」模式，AI 会自动化重复性高的流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;真正不可取代的是人类的判断力与创造力，尤其是在产品定义与复杂架构决策中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 无法准确理解历史代码上下文，也难以胜任抽象设计。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尤雨溪本人在法律合同等文档处理上已广泛使用 AI 工具，大幅节省律师成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;开源商业化的探索路径&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;成功的开源商业化并非只有上市一种形式，维持长期生存同样重要。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Vue 项目通过社区赞助维持核心团队运行，属于轻量可持续的成功模式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端框架商业化更难因缺少服务型后端组件；VoidZero 的目标是打造&lt;strong&gt;可自我造血的高阶工具链&lt;/strong&gt;，而非仅作流量入口。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;&lt;strong&gt;其他话题与个人兴趣&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;对 React Server Components 的评价&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vue 不会采用类似方案，而是采用&lt;strong&gt;构建时静态预渲染 + 最小 JS 运行时&lt;/strong&gt;的路径，追求性能与开发体验的平衡。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;strong&gt;日常生活&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;参观《黑神话：悟空》展览，对其艺术与技术水准印象深刻。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;休闲时会使用&amp;nbsp;&lt;strong&gt;解压类指尖玩具&lt;/strong&gt;&amp;nbsp;来缓解注意力障碍。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每周会打羽毛球，强调工作之余保持运动对身体的重要性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174754_Sev7_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;尤雨溪老师此次分享，为我们描绘了前端技术的新篇章：以 Rust 为内核、AI 为助力、开源为根本。&lt;/p&gt; 
&lt;p&gt;本次的直播回放可以在「&lt;strong&gt;OSC 开源社区&lt;/strong&gt;」视频号中进行查看：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174803_1cW9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365057</guid>
      <pubDate>Thu, 07 Aug 2025 09:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>会翻译、懂产品、还能画头像：Gitee 智能三连上线！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在开发者参与项目协作的过程中，从读懂文档、掌握功能，到展示个性，很多细节往往比想象中更难：&lt;/p&gt; 
&lt;p&gt;📄&amp;nbsp;&lt;strong&gt;README 是外文，看得一头雾水&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🤔&amp;nbsp;&lt;strong&gt;企业版功能很多，一时间找不到使用路径&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;🧑‍💻&amp;nbsp;&lt;strong&gt;社区头像都差不多，没法展示个人特色&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了解决这些常见但容易被忽视的问题，Gitee 新上线了三项智能化功能，从理解项目、快速上手到个性表达，全链路优化开发体验：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一键翻译 README，项目文档看得懂&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能助手随问随答，功能使用不迷路&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 头像生成，自定义专属程序员形象&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;接下来就带你逐一了解这次更新的重点亮点——&lt;/p&gt; 
&lt;h3&gt;README 一键翻译：跨语言项目协作更轻松&lt;/h3&gt; 
&lt;p&gt;你是否遇到过这样的场景，克隆下来的项目，README 是全英文，核心用法不明不白，还得靠翻译工具搞半天。&lt;/p&gt; 
&lt;p&gt;现在，只需在英文 README 文件上方点击「翻译为中文」，README 页面将瞬间完成 AI 翻译，原地阅读，不跳转、不依赖第三方平台，真正做到「沉浸式翻译」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174240_We6y_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;马建仓实测下来翻译速度超快：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174302_Dxs4_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该功能由 Gitee 与开源项目&lt;code&gt;translate.js&lt;/code&gt;联合提供支持，开发者通过引用&lt;code&gt;translate.js&lt;/code&gt;，两行 JavaScript 代码即可实现 HTML 多语言全自动翻译。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174316_J9sI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这不仅让开源项目更具国际可读性，也让日常开发者查阅他人项目更加高效顺畅。&lt;/p&gt; 
&lt;h3&gt;Gitee 智能助手：常见问题秒回答&lt;/h3&gt; 
&lt;p&gt;你也许注意到了，在 Gitee 页面侧边按钮和 Gitee 帮助中心出现了一个新入口：「Gitee 智能助手」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174329_eD7Z_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;你也可以直接访问 https://help.gitee.com/chat，进入 Gitee 智能助手页面：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174341_v6CH_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这是 Gitee 官方推出的 AI 智能助手，可随时向它提问，当前重点覆盖 Gitee 社区版和企业版功能使用场景，例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如何添加企业成员？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目权限怎么管理？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如何从免费账号升级为企业版？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企业版 AI 能力包括什么？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gitee 项目管理有哪些优势？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174356_F4zo_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;相比传统 FAQ，它响应更快、理解更强，也更适配你的提问方式。特别适合刚接触企业版的用户，边用边问，边学边上手。&lt;/p&gt; 
&lt;h3&gt;AI 头像生成：打造你的专属开发者形象&lt;/h3&gt; 
&lt;p&gt;除了提升协作效率，Gitee 也为用户带来了更有趣、更个性化的新功能：AI 头像生成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/174427_5oR9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;该功能由模力方舟提供技术支持&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在个人设置页点击自己的头像，即可使用 AI 生成模式，选择身份（如程序员、年轻男性）、风格（漫画风、电影风等）、发型、背景等参数，几秒钟就能生成独一无二的专属头像。&lt;/p&gt; 
&lt;p&gt;不论你是低调极客派，还是喜欢有趣表达，现在都可以轻松「画」出属于自己的开发者头像。&lt;/p&gt; 
&lt;h3&gt;Gitee 智能化升级，让协作更高效&lt;/h3&gt; 
&lt;p&gt;本次上线的三项新功能，围绕开发者在协作过程中的三个关键场景展开：读懂文档、掌握用法、表达自我，从工具性到体验感，全面优化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;README 翻译功能，让开源项目更易于跨语言传播，也帮助开发者快速理解项目内容；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;智能助手功能，则为使用路径中的关键节点，提供了更便捷、更友好的智能化引导体验；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI 头像生成，轻松打造开发者自己的个性形象，让社区互动不再千篇一律。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;从可读性、可用性，到个性表达，&lt;strong&gt;Gitee 正在通过智能化升级，打通「理解—使用—参与」的完整路径&lt;/strong&gt;，让开发者既能用得顺手，也能留下自己的风格印记。&lt;/p&gt; 
&lt;p&gt;未来，我们还将持续拓展智能工具链的深度与温度，为你带来更多真正用得上的开发体验。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;欢迎体验：&lt;u&gt;&lt;strong&gt;&lt;em&gt;&lt;a href="https://gitee.com/" target="_blank"&gt;https://gitee.com/&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365056</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365056</guid>
      <pubDate>Thu, 07 Aug 2025 09:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MetaStone-S1：反思型生成式大模型（Reflective Generative Model）</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;MetaStone-S1 是反思型生成式大模型（Reflective Generative Model），在数学、代码和中文推理任务上以 32B 的参数量达到了与 OpenAI-o3 系列相近的水平。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5b7f913ec1d1edd4e8d563efc5d926ec005.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 基于反思型生成范式训练得到，反思型生成范式是将 「Long-CoT 强化学习」与「过程评分学习」融合的训练范式，该范式使单个模型同时具备「深度推理」与「高质量推理链路筛选」的能力。通过共享过程评分和策略模型的主干网络，该范式显著降低了 99% 的过程评分推理耗时，实现了又快又好的文本回答效果。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6b00edd28a2bbf6ab32d77928e5fd7b8b59.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 在小尺寸模型上的性能对比：&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0806/192929_y0R0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;MetaStone-S1 在大尺寸模型上的性能对比：&lt;/p&gt;

&lt;p&gt;&lt;img height="1054" src="https://static.oschina.net/uploads/space/2025/0806/192925_gOSt_2720166.png" width="1320" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/metastone-s1</link>
      <guid isPermaLink="false">https://www.oschina.net/p/metastone-s1</guid>
      <pubDate>Thu, 07 Aug 2025 09:38:00 GMT</pubDate>
    </item>
    <item>
      <title>韩国扶持五大联合体开发「主权 AI」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;综合韩联社、《朝鲜日报》和《京乡新闻》等韩媒报道，韩国政府 4 日正式选定 NAVER Cloud、Upstage、SK 电讯、NC AI、LG AI 研究院五个联合体作为「人工智能（AI）基础模型研发项目」的首批扶持对象，全面启动「主权 AI」国家战略。这是李在明政府提出「迈向 AI 三大强国」目标后，首次对本土基础大模型研发力量进行筛选和集中投入，标志着韩国在全球 AI 技术竞争中迈出实质性步伐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据韩国科学技术信息通信部（科技部）介绍，此次入选的 5 个联合体从全国 15 个团队中脱颖而出，涵盖大型企业、AI 初创公司、产学研机构等多方力量，均具备自主设计和开发 AI 基础模型的核心能力。根据韩国政府公布的计划，首轮项目评估将于今年 12 月起启动，到 2027 年每六个月淘汰一组，逐步缩减扶持对象，最终仅遴选 1 至 2 个联合体作为长期合作方。韩国业内普遍认为这是一场「真刀真枪的较量」，事关国家未来人工智能能力的保障。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韩国政府计划在 2027 年前向五支「国家代表队」投入约 5300 亿韩元（1000 韩元约合 5.2 元人民币）支持：其中 4500 亿用于 GPU（图形处理器）支持，628 亿用于 AI 训练数据建设，最高 250 亿用于人才引进。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该项目旨在开发具有国际竞争力、自主研发的人工智能基础模型，减少对外国技术的依赖，并拓展国内人工智能生态系统。韩政府认为，该模型将推动国内各行各业的人工智能转型。政府明确目标是将技术水平提升至包括美国 OpenAI 推出的大模型 ChatGPT 在内的顶尖 AI 模型的 95%。据英国 Tortoise Media 年度《全球 AI 指数》，韩国 AI 技术实力居全球第六（2024 年基准），与排名前两位的美中两国存在显著差距。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韩国业内认为，数据资源短缺是制约本土 AI 模型质量的重要瓶颈。与领先国家相比，韩国在可用于训练的大规模高质量数据方面明显不足。为此，韩国政府明确提出，将通过国家记录院、国史编纂委员会、统计厅等统一采购公共数据，向入选联合体提供使用权限，并根据各团队需求支持个别数据库构建，助力基础模型开发。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在期待阶段性成果的同时，韩国业界也呼吁政府将扶持重心进一步延伸至更具产业价值的长期路径。参与项目的 AI 研发人员指出，仅靠模型本身尚不足以支撑 AI 强国地位，关键在于推动 AI 向制造、医疗、金融等高附加值产业加速融合。对此，韩国科技部长官裴庆勋表示，该项目是「韩国 AI」的起点，将全力支持「主权 AI」生态的扩张，并逐步扩大政策工具箱，构建以「主权 AI」为核心的全链条支援体系。（环球时报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365053</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365053</guid>
      <pubDate>Thu, 07 Aug 2025 09:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>今年上半年我国机器人产业营业收入同比增长 27.8%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 世界机器人大会开幕式上，工业和信息化部副部长辛国斌介绍，今年上半年，我国机器人产业营业收入同比增长 27.8%，工业机器人和服务机器人产量同比分别增长 35.6% 和 25.5%，连续 12 年位居全球最大工业机器人应用市场。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;辛国斌指出，世界机器人大会自 2015 年起，迄今已迎来具有里程碑意义的十年。10 年间全球机器人产业实现飞跃式发展，呈现三个「加速」的态势：一是智能水平加速提升；应用边界加速扩展；创新要素加速汇聚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="337" src="https://oscimg.oschina.net/oscnet/up-82381b9c95f185220dda658c7552e588f83.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他提到，围绕老龄社会应对、智能制造升级、农业现代化转型、深空深海探索等全球性关键领域，中国愿探索国际合作新模式，让智能机器人的创新成果跨越环境，惠及世界每一个角落。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365046</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365046</guid>
      <pubDate>Thu, 07 Aug 2025 09:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>KittenTTS - 25MB 以下最先进的 TTS 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Kitten TTS 是一个开源的真实文本转语音模型，仅具有 1500 万个参数，专为轻量级部署和高质量语音合成而设计。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;目前处于开发者预览阶段。&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;特点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超轻量级&lt;/strong&gt;：模型大小小于 25MB&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU 优化&lt;/strong&gt;：在任何设备上无需 GPU 即可运行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高品质语音&lt;/strong&gt;：提供多种优质语音选项&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;快速推理&lt;/strong&gt;：针对实时语音合成进行了优化&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;安装&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;pip install https://github.com/KittenML/KittenTTS/releases/download/0.1/kittentts-0.1.0-py3-none-any.whl&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基本用法&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;from kittentts import KittenTTS
m = KittenTTS("KittenML/kitten-tts-nano-0.1")

audio = m.generate("This high quality TTS model works without a GPU", voice='expr-voice-2-f' )

# available_voices : [  'expr-voice-2-m', 'expr-voice-2-f', 'expr-voice-3-m', 'expr-voice-3-f',  'expr-voice-4-m', 'expr-voice-4-f', 'expr-voice-5-m', 'expr-voice-5-f' ]

# Save the audio
import soundfile as sf
sf.write('output.wav', audio, 24000)&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/kittentts</link>
      <guid isPermaLink="false">https://www.oschina.net/p/kittentts</guid>
      <pubDate>Thu, 07 Aug 2025 09:14:00 GMT</pubDate>
    </item>
    <item>
      <title>马斯克：AI 是解决日本人口危机的唯一希望</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;埃隆·马斯克近日在社交平台发文，对日本严峻的人口问题发表了自己的看法。他指出，日本今年人口将减少近 100 万，这一趋势的根源早在半个世纪前就已种下，与人工智能的发展无关。他强调，「&lt;strong&gt;人工智能是扭转这一局面的&lt;span&gt;唯一&lt;/span&gt;希望&lt;/strong&gt;。」&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="365" src="https://oscimg.oschina.net/oscnet/up-18e76d8f77bfe23364728d9305749681dbb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;马斯克的言论与日本官方公布的数据相吻合。据日本总务省 7 月 6 日发布的统计数据，截至 2025 年 1 月 1 日，不计居住在日本的外国人，日本人口已连续第 16 年减少。总人口数约为 1.2065 亿，相比去年减少了约 90.8 万人，创下自 1968 年有统计数据以来的&lt;span&gt;最大&lt;/span&gt;降幅。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;数据显示，从 2024 年初到 2025 年初，日本的出生人数创下历史新低，而死亡人数则达到新高，进一步加剧了人口萎缩的趋势。马斯克的此番言论，为日本乃至全球面临的人口挑战提供了一个极具争议性的解决思路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365041</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365041</guid>
      <pubDate>Thu, 07 Aug 2025 08:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>LangChain 发布开源异步编程 Agent：Open SWE</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;LangChain 发布了名为「Open SWE」的开源异步编程 Agent（Asynchronous Coding Agent）。它能自动理解代码库、制定解决方案、执行代码变更，并完成从规划到创建 Pull Request 的全流程。&lt;/p&gt; 
&lt;p&gt;核心功能包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;智能规划（允许用户审核修改方案）&lt;/li&gt; 
 &lt;li&gt;人机协作（实时干预任务）&lt;/li&gt; 
 &lt;li&gt;云端并行处理（不占用本地资源）&lt;/li&gt; 
 &lt;li&gt;端到端任务管理（自动创建 GitHub Issue 和 PR）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-84a6f93afdaf7a3c319de12e81307f6100f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其技术架构采用多智能体协作（规划师、编程师、审查员等），基于 LangGraph 框架实现。用户可通过 Web 界面或 GitHub 标签触发任务，适用于复杂代码库的自动化协作开发。&lt;/p&gt; 
&lt;p&gt;相关链接&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://github.com/langchain-ai/open-swe&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://swe.langchain.com/&lt;/span&gt;&lt;br&gt; &lt;span&gt;https://docs.langchain.com/labs/swe&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365036/langchain-open-source-asynchronous-coding-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365036/langchain-open-source-asynchronous-coding-agent</guid>
      <pubDate>Thu, 07 Aug 2025 08:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 限时免费提供 GPT-5 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据 Cursor 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fen%2Fblog%2Fgpt-5" target="_blank"&gt;声明&lt;/a&gt;及网络信息，Cursor 针对其付费计划用户提供了一定额度的 GPT-5 免费使用权限。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;X 平台上，@rohanpaul_ai 在 7 月 28 日的帖子中提到，Cursor 正考虑与 OpenAI 深化合作，部分得益于 GPT-5 在编码任务中的卓越表现。帖子指出，GPT-5 在软件工程、代理式规划和多步骤工作流等领域的性能尤为突出，甚至超越了 Anthropic 的 Claude Sonnet4 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次限时免费活动旨在让更多开发者体验 GPT-5 的强大功能。Cursor 的付费计划用户将获得 GPT-5 的免费使用额度，具体时间窗口尚未明确，但活动已在开发者社区引发广泛讨论。这一举措被视为 Cursor 在 AI 编码工具市场中巩固竞争优势的战略步骤，尤其是考虑到其年收入已接近 5 亿美元，且部分收入与 Anthropic 的合作相关。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-2db6ccc955b243e8a18835eeee79e46540b.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;X 平台上的开发者对 Cursor 的更新反应热烈。有报道称 GPT-5 在软件工程任务中的表现「极其积极」，尤其在代码生成和调试方面表现优异。 许多开发者表示，Cursor 的免费 GPT-5 使用权限和 CLI 工具的推出将进一步推动 AI 在编程领域的普及。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:left"&gt;&lt;a href="https://www.oschina.net/news/364999/cursor-cli" target="news"&gt;Cursor 发布命令行工具 Cursor CLI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365035</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365035</guid>
      <pubDate>Thu, 07 Aug 2025 08:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>多邻国股价暴涨 30%，AI 战略引争议却创造十亿美元营收奇迹</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;多邻国公司周三公布的季度财报显示，尽管此前因选择拥抱生成式 AI 而非人工员工遭遇广泛抨击，公司营收仍超出预期。这一消息推动多邻国股价飙升近 30%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 4 月，公司&lt;/span&gt;&lt;span style="color:#212623"&gt;首席执行官 Luis von Ahn&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn%F0%9F%87%B1%F0%9F%87%AEactivity%3A7322560534824865792%2F" target="_blank"&gt;宣布&lt;/a&gt;&lt;span style="color:#000000"&gt;多邻国将转型为"AI 优先"公司，逐步淘汰合同工。他还建议各团队除非无法进一步自动化工作流程，否则不要增加员工招聘。借助生成式 AI 技术，多邻国新增 148 门语言课程，课程总量较此前翻了一倍多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;他当时表示："如果没有 AI，我们需要几十年时间才能将内容规模扩展到更多学习者。我们有责任尽快为学习者提供这些内容。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-30637c0e2142cdbe95fad780b3ab7ed124b.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;虽然部分多邻国用户认为 AI 功能让应用体验变差，但公司财务数据却讲述着截然不同的故事。多邻国预计今年营收将突破 10 亿美元大关，日活跃用户同比增长 40%。这一增长表现虽然显著，但处于公司此前预估 40%-45% 增长区间的下限，有投资者在周三的季度财报电话会议上向冯·安提及这一点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#212623"&gt;Luis von Ahn&amp;nbsp;&lt;/span&gt;&lt;span style="color:#000000"&gt;解释道："我们增长率偏向下限的原因是我谈到了 AI 相关内容，但没有提供充分的背景信息。因此我们在社交媒体上遭受了一些抨击。最重要的是，我们希望让社交媒体上的情绪变得积极。我们停止发布尖锐的帖子，开始发布能让情绪更加积极的内容，这个策略奏效了。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在 TikTok 平台上，多邻国视频下的热门评论仍多为对公司 AI 策略的批评。尖刻的评论者会询问出现多人的视频是否使用 AI 制作，多邻国通常回复："不是的，这是我们优秀团队制作的！"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;即使公众对多邻国的态度发生转变，但公司的财务表现并未受到影响。从公司角度来看，这才是最重要的。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365032</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365032</guid>
      <pubDate>Thu, 07 Aug 2025 08:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源企业级智能体平台 MaxKB v2.0.2 发布，高级编排应用新增会话变量，支持对话用户扫码登录，支持工作空间资源统一管理</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="color:#000000; text-align:start"&gt;2025 年 8 月 7 日，MaxKB 开源企业级智能体平台正式发布 v2.0.2 版本。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;在 MaxKB v2.0.2 版本中，&lt;strong&gt;社区版方面&lt;/strong&gt;，高级编排应用新增会话变量功能，适用于用户在多次对话中进行数据暂存、逻辑判断的场景，能够有效增强系统的逻辑处理能力。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;X-Pack 增强包方面&lt;/strong&gt;，在对话用户登录时，MaxKB 新增企业微信、钉钉、飞书等第三方平台扫码登录支持；在系统资源管理中，新增支持系统管理员对系统内所有工作空间的应用、知识库、工具、模型等资源进行统一管理。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;此外，MaxKB 开源项目组还进行了超过 20 项功能更新和问题修复。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;新增功能&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 高级编排应用新增会话变量功能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;MaxKB v2.0.2 版本的高级编排应用新增会话变量功能。用户在高级编排的 「基本信息」 节点中自定义会话变量后，该变量将在当前对话的全流程持续生效，并且支持对话过程中的数据传递与逻辑调用。当用户新建对话时，系统将自动初始化会话变量，确保跨对话场景的变量独立性与数据隔离性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-75122c498811b66ac03bb7a601a9cba41fa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲图 1 MaxKB 新增会话变量功能&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 支持对话用户扫码登录（X-Pack）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;为提升对话用户体验，MaxKB v2.0.2 版本对话用户登录新增支持第三方平台扫码登录功能，支持通过企业微信、钉钉、飞书等主流企业办公平台进行安全便捷的单点登录。具体配置步骤如下：&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;1. 系统管理配置：&lt;/strong&gt;依次选择「系统管理」→「对话用户」→「登录认证」，在「登录认证」页面中完成包括企业微信、钉钉、飞书在内的第三方平台扫码登录的相关设置。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a7fbd9656b276363f4832da66ec3e4f0040.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲图 2 对话用户扫码登录对接配置页面&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;2. 应用访问限制设置：&lt;/strong&gt;在目标应用的「概览」页面中，打开「访问限制」配置对话框，启用「身份验证」 功能，选择「登录认证」选项，并将登录方式设置为钉钉、飞书或者企业微信扫码登录。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4512fec9646fcd30f1f60af7ff73056db33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲图 3 在应用的「访问限制」配置对话框开启登录认证设置&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;3. 用户登录流程：&lt;/strong&gt;完成上述配置后，当对话用户打开小助手提问时，系统将自动弹出对应第三方平台的扫码登录界面。用户扫码确认后即可快速登录，开启与小助手的对话交互。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1406" src="https://oscimg.oschina.net/oscnet/up-ee52f7c25ac9839c37ce7129234e5e8da9a.png" width="976" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲图 4 对话用户打开小助手时需要先进行扫码登录&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;strong&gt;&lt;span style="color:#5a55fa"&gt;■ 支持工作空间相关资源的统一管理（X-Pack）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;MaxKB v2.0.2 版本在「资源管理」模块中赋予了系统管理员对资源的编辑、删除及配置等能力。通过该功能，系统管理员可以对工作空间内的应用、知识库、工具和模型等资源进行统一的管理与维护，从而实现资源的集中化管控，显著增强了系统资源的精细化管理能力，并且提升了资源管理与维护的便捷性。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;img alt="" height="1610" src="https://oscimg.oschina.net/oscnet/up-0610a5e08dc073f908ade888de3ad36dfd9.png" width="3076" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span&gt;▲图 5 MaxKB「资源管理-应用」管理页面&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;功能优化&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;对话用户（X-Pack）：支持同步 LDAP 和企业微信用户；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;对话用户（X-Pack）：支持按用户来源和状态查询；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知识库：针对数据量较大的复杂场景，提升了知识库检索性能；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：对话用户支持按用户来源查询；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：调整高级编排应用的文件上传限制，单次对话最多可上传 100 个文件，单文件最大支持 1000MB；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：支持按应用发布状态查询；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：对话用户支持按用户来源查询；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：上传文件后自动填充问题字段；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：优化浮窗模式和移动模式的登录交互体验；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;用户管理：支持按用户来源和状态查询；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;系统：优化系统 UI 样式。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;问题修复&lt;/h1&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知识库：修复在全文检索模式下命中测试报错的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知识库：修复上传离线文档页面部分内容国际化显示不正确的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知识库：修复上传离线文档的分段规则页面滚动条滚动范围不正确的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用（X-Pack）：修复在应用接入的钉钉平台对话时，AI 回复未按 Markdown 样式显示的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：修复部分情况下 MCP 调用节点执行报错的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：修复相同的两节点之间多次连线导致重复执行的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：修复修改模型参数时参数显示不正确的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：修复添加应用子节点时未过滤未发布状态应用的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：修复上传的文件名称中含有「&lt;em&gt;&amp;amp;nbsp&lt;/em&gt;」 字符时，URL 不显示的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：修复用户对话时 AI 回复的图片无法点击放大的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：修复 AI 回复为表格数据时显示错位的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面（X-Pack）：修复 License 未授权时，打开问答页面报错的问题；&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&lt;span style="color:#5a55fa"&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;共享模型（X-Pack）：修复删除共享模型时报错的问题。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4736111/blog/18687412</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4736111/blog/18687412</guid>
      <pubDate>Thu, 07 Aug 2025 08:16:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AI 智能体记忆机制详解</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 为什么我们总是感觉在与 AI 助手重复着同样的对话？为什么明明告诉过它的重要信息，五分钟后它就完全遗忘了？&lt;/p&gt; 
 &lt;p&gt;我们今天为大家带来的文章，作者的观点是：记忆能力是 AI 从工具进阶为真正智能伙伴的关键桥梁，只有具备完善的记忆系统，AI 才能提供个性化体验、拥有持续学习和处理复杂任务的能力。&lt;/p&gt; 
 &lt;p&gt;本文深度解析了记忆增强型 AI 系统的核心技术架构，介绍了"观察→记忆→行动→反思→更新"这一认知闭环解决方案。作者还系统阐述了从实时内存状态到向量数据库的多层次存储机制，并详细解析了工作记忆、情景记忆和语义记忆这三种记忆类型。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Bhavishya Pandit&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;是否总感觉你在和 AI 助手重复着同样的对话？你告诉它一些重要的事情，五分钟后，它就忘了。很长一段时间以来，这就是和大多数 AI 进行对话的现实情况。它们非常聪明，却只有金鱼般的记忆。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-923e90490a35f728b302cc47fb2b658e48c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但这种情况正在改变。如今，AI 小伙伴能记住我们上周的对话，回想起我们的喜好，并从与我们长期的交流互动中学习。这是目前人工智能的前沿领域之一，也是我想在今天这篇文章中深入探讨的主题：AI 记忆能力的精妙之处。让我们来分析一下，AI 是如何获得记忆能力的。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 为何 AI 需要记忆能力&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;从本质来看，记忆就是为我们提供上下文。它是连接过往经历与当下行为的纽带。对 AI 而言，这是从工具进阶为真正智能伙伴的关键桥梁。&lt;/strong&gt; 缺乏记忆能力的 AI 将无法实现：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2421fcf65f410c9fdc683a7a794d8c5d8fd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Source[1]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;个性化体验：无法记住你喜欢简明扼要的要点而非冗长的段落，或在推荐食谱时忽略你是素食者&lt;/li&gt; 
 &lt;li&gt;从交流互动中学习：每次互动都需从头开始，无法更好地帮助你&lt;/li&gt; 
 &lt;li&gt;处理复杂任务：想象一下与这样的助手一起撰写报告 ------ 它每次接收新数据都会遗忘项目目标&lt;/li&gt; 
 &lt;li&gt;让 AI 拥有记忆能力，就是要让它更有用、更个性化、更像人类，能够为我们提供帮助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;02 记忆增强型 AI 系统的核心运作架构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;这个系统可以被视为一个持续运转的认知闭环，使 AI 能够感知环境、采取行动并从经验中持续学习。整个过程可分解为一个强大的自我迭代循环。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da7af7c3bec8e5f377b951e0f3dfce92505.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;观察&lt;/strong&gt;：首先，智能体感知任务或用户输入。这是其"眼睛与耳朵"所在，负责接收当前的上下文信息。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;记忆&lt;/strong&gt;：随后智能体存储即时上下文与相关对话历史。这不仅仅是记录文字，更要理解当前时刻"发生的事情"以及"这些事为什么会发生"。&lt;/p&gt; 
&lt;p&gt;3）&lt;strong&gt;行动&lt;/strong&gt;：基于上下文，智能体执行动作或作出决策。可能表现为编写代码、回答问题或调用特定工具。&lt;/p&gt; 
&lt;p&gt;4）&lt;strong&gt;反思&lt;/strong&gt;：行动完成后进行评估。行动结果是成功还是失败？是否更接近目标？&lt;/p&gt; 
&lt;p&gt;5）&lt;strong&gt;更新记忆&lt;/strong&gt;：最终（也是最关键的环节），将新学习到的认知模式与推理洞察回传至记忆库。&lt;/p&gt; 
&lt;p&gt;正是这种观察 → 记忆 → 行动 → 反思 → 更新的迭代循环，赋予智能体实时改进的能力，使其每一次交互都转化为实践课程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 这些记忆内容存储在何处？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;那么，这些记忆信息究竟存放在何处呢？在智能体系统中，记忆被精心组织在不同的存储层级中，各司其职。其运作机制可类比为一个高度有序的工作车间。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f9e1986386fa4263d903f3940a86bdcc010.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;实时内存态（In-Memory state）&lt;/strong&gt; ：这是智能体短期使用的临时工作区。存储当前任务所需的即时信息，例如您设定的实时目标或刚调用的工具的输出结果。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;持久化日志（Persistent logs）&lt;/strong&gt; ：智能体在此建立跨多个会话的长期事件档案，记录行为轨迹、反思结论及任务结果。就像一本详细的项目笔记本，它记录了智能体所做的事情、智能体如何完成任务以及最终结果。这可以确保在下一个任务开始之前，从之前的任务中学到的知识不会丢失。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;向量数据库（Vector databases）&lt;/strong&gt; ：向量数据库存储历史交互数据时，并非简单记录文本，而是将其转化为蕴含丰富语义的嵌入向量 ------ 即数据的高维数值表征。嵌入向量能捕捉信息的语义精髓与内在关联，使智能体可基于上下文的相似度（而非关键词匹配）检索记忆。其机制更像触发人脑的"寻找与此相似的情境记忆"，而非在文档中进行关键词搜索。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 寻找正确的记忆内容&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;当你向智能体提问时，它并不会逐字逐句地通读自己的整个过往经历。相反，它会执行一次优雅的高速检索，以找到最相关的上下文。以下是这种语义搜索背后的运作原理：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fc371cc4405686f69d3a55bfd1c8825a0b6.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;创建嵌入向量&lt;/strong&gt;：智能体获取你当前的任务或问题，并指令一个嵌入模型将其转化为数字化的嵌入向量。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;搜索记忆内容&lt;/strong&gt;：这个新的嵌入向量随后被发送到向量数据库，附带一条简单指令："find the memories most similar to this（找到与此最相似的记忆内容）"。&lt;/p&gt; 
&lt;p&gt;3）&lt;strong&gt;寻找最匹配的记忆内容&lt;/strong&gt;：数据库将查询嵌入向量（query embedding）与存储的记忆嵌入向量（memory embeddings）进行比对，并检索出最相关的前 k 个匹配项。这些匹配项可能包括过往出现的同类错误、其他类似任务中的成功执行结果，或是用户之前提过的相关需求。&lt;/p&gt; 
&lt;p&gt;4）&lt;strong&gt;使用记忆内容&lt;/strong&gt;：然后，相关数据会被送回主智能体，用以指导其下一步行动。&lt;/p&gt; 
&lt;p&gt;整个过程快速、模糊匹配、并且具备上下文感知能力。其核心运作理念在于： &lt;strong&gt;"智能检索有用信息"（"find what's useful"）&lt;/strong&gt; 而非"机械记忆全部数据"（"remember everything"）。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 反思与真正的学习&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;此环节是区分基础的一次性 LLM 与真正的智能体型系统的关键。任务完成后，智能体并非直接转向新任务，而是暂停进行自我反思，并通过提出下列核心问题实现进阶学习：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;哪些步骤是有效的？原因何在？&lt;/li&gt; 
 &lt;li&gt;执行过程中在哪些方面遇到了困难？&lt;/li&gt; 
 &lt;li&gt;基于当前执行结果（成功/失败），下次是否需调整策略？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-9cac879e627cbaba61e922a25748b4c3528.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过反思产生的洞见（无论是从成功中获得的经验，还是从失败中获得的教训）将被记录并存储至记忆库。这种反思循环机制使智能体能持续从行动中学习，确保未来所作的决策始终受历史经验指引。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 记忆类型&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为做出智能决策，智能体会综合使用多种类型的记忆 ------ 这与人类大脑的运作方式高度相似。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）工作记忆（Working memory）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可视为智能体的思维便利贴（mental sticky notes），用于短期存储当前任务的指令、目标及执行步骤。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;短期记忆（Short-Term memory）：指 AI 为完成即时任务临时暂存信息的能力。在现代 AI（如 ChatGPT）中，这种记忆通常被称为"上下文窗口"（context window）。 
  &lt;ul&gt; 
   &lt;li&gt;本质功能：预定义的对话缓存空间，存储当前会话的所有输入/输出内容&lt;/li&gt; 
   &lt;li&gt;运作原理：类比 AI 的运行内存（RAM），通过快速存取保持对话的连贯性（可实时调用上下文窗口内全部信息，从而理解最新问题的上下文）&lt;/li&gt; 
   &lt;li&gt;局限：对话长度超限时，最早期的内容将被主动遗忘（为新内容腾出空间） ------ 这就是长对话中 AI 遗忘开头内容的原因&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2）情景记忆（Episodic memory）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;相当于智能体的任务日记，记录历史执行过程中的关键信息，如：具体成功案例、失败教训、用户互动历史。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3）语义记忆（Semantic memory）&lt;/strong&gt; ：这是智能体的长期知识库，相当于一本内置的百科全书，它储存着这个智能体通过长期经验积累的通用知识、行为模式和应对策略。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;长期记忆（Long-Term memory）：这是最重要的部分。通过构建持久化的"数据库"，使人工智能能在不同会话、不同日期乃至间隔数月后依然记住你。 
  &lt;ul&gt; 
   &lt;li&gt;本质功能：为人工智能提供存储机制，更重要的是能够检索过往交互中的关键信息。&lt;/li&gt; 
   &lt;li&gt;运作原理：当前最主流的技术是检索增强生成（RAG）。其运作流程如下： 
    &lt;ol&gt; 
     &lt;li&gt;存储记忆：当用户提供重要信息（如"我的公司叫'Innovate Next'"）时，系统将其转化为称为"向量"的数学表征，储存在专用向量数据库中&lt;/li&gt; 
     &lt;li&gt;调用记忆：当用户提出相关问题（如"为我的公司提供营销建议"）时，系统首先查询该数据库获取相关记忆片段&lt;/li&gt; 
     &lt;li&gt;应用记忆：在生成回复前，将检索到的记忆（"用户公司名为 Innovate Next"）用来增强提示词&lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;智能体的实时操作（工作记忆）、过往经历（情景记忆）与通用知识（语义记忆）三者融合，才能做出真正的智能决策。&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 The Future&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;本文所诉内容并非理论空谈，而是当前正在加速推进的现实。诸如 LangChain、LangGraph、LlamaIndex 及 CrewAI 等现代框架均已内置支持这类记忆系统 ------ 从简易的缓存（buffers）到复杂的长期检索器（long-term retrievers），相关技术正以闪电般的速度迭代演进。不妨关注一下专为智能体设计的 Mem0 等新兴架构，它们的目标是实现智能化的记忆管理 ------ 能像人类一样自主判断信息价值，动态筛选需要保留的内容并优化存储方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;我们最终要构建的不只是处理信息的 AI，而是能与信息建立深度联结的伙伴。具备记忆、学习和进化能力的 AI，正是精巧工具与真正协作伙伴的本质区别。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-871f7011f1975d249dd54e3524c76913039.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Source[2]，这个漫画的笑点在于机器人被要求识别猫的种类，但它却表示自己更擅长识别狗，因此无法完成这个关于猫的分类任务。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓AI 记住太多个人信息会不会成为一把双刃剑？你觉得应该在哪些方面设置记忆边界？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.google.com%2Furl%3Fsa%3Di%26url%3Dhttps%253A%252F%252Fblog.dailydoseofds.com%252Fp%252Fai-agents-crash-coursepart-8-and%26psig%3DAOvVaw0gDe2xHs6PQhdBIgL0MuSE%26ust%3D1750944586681000%26source%3Dimages%26cd%3Dvfe%26opi%3D89978449%26ved%3D0CBQQjRxqFwoTCJjD_ILXjI4DFQAAAAAdAAAAABAE" target="_blank"&gt;https://www.google.com/url?sa=i&amp;amp;url=https%3A%2F%2Fblog.dailydoseofds.com%2Fp%2Fai-agents-crash-coursepart-8-and&amp;amp;psig=AOvVaw0gDe2xHs6PQhdBIgL0MuSE&amp;amp;ust=1750944586681000&amp;amp;source=images&amp;amp;cd=vfe&amp;amp;opi=89978449&amp;amp;ved=0CBQQjRxqFwoTCJjD_ILXjI4DFQAAAAAdAAAAABAE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fimages.squarespace-cdn.com%2Fcontent%2Fv1%2F60f577b77c1ea50a11c79e10%2F1628338487176-BOJB5H9DCQ51E87V6NCI%2F20210129_dog_or_Cat_3.jpg" target="_blank"&gt;https://images.squarespace-cdn.com/content/v1/60f577b77c1ea50a11c79e10/1628338487176-BOJB5H9DCQ51E87V6NCI/20210129_dog_or_Cat_3.jpg&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbhavishyapandit9.substack.com%2Fp%2Fhow-memory-works-in-agentic-ai-a" target="_blank"&gt;https://bhavishyapandit9.substack.com/p/how-memory-works-in-agentic-ai-a&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18687444</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18687444</guid>
      <pubDate>Thu, 07 Aug 2025 08:15:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AlmaLinux 发行版原生支持英伟达 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AlmaLinux 项目&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Falmalinux.org%2Fblog%2F2025-08-06-announcing-native-nvidia-suport" target="_blank"&gt;宣布&lt;/a&gt;，AlmaLinux 10 和 AlmaLinux 9 &lt;strong&gt;现已支持 NVIDIA 的原生图形驱动程序&lt;/strong&gt;，该驱动程序基于 NVIDIA 的开源内核模块，这些模块现已方便地打包在 AlmaLinux 仓库中，便于使用，幷包含 NVIDIA 的闭源用户空间包，如 CUDA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2593b3cf2eed6aff2963f9b608cecc024ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="804" src="https://static.oschina.net/uploads/space/2025/0808/160908_kTh5_2720166.png" width="1780" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;AlmaLinux 与社区合作，为 AlmaLinux 9/10 提供了原生 NVIDIA 驱动程序支持，这些驱动程序基于其现代开源但不在内核树中的 Turing 及更新版本内核驱动程序构建。通过使用开源内核驱动程序代码，实现了 UEFI 安全启动支持，并在 AlmaLinux 上安装这些内核模块包时提供了更好的体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365028/almalinux-native-nvidia-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365028/almalinux-native-nvidia-support</guid>
      <pubDate>Thu, 07 Aug 2025 08:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克：OpenAI 会「生吞」微软</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式发布旗舰模型 GPT-5，该模型在广泛领域表现卓越，位居榜首：不仅在文本生成、网页开发和视觉内容创作上排名第一，更在高难度提示词响应、编程、数学推理、创意写作以及长文处理等多个关键领域拔得头筹。&lt;/p&gt; 
&lt;p&gt;OpenAI 首席执行官 Sam Altman 特别发文感谢合作伙伴，称：「感谢微软、英伟达、甲骨文、谷歌和 Coreweave 的鼎力支持，让 GPT-5 的诞生成为可能！这背后是海量 GPU 资源的持续投入。」&lt;/p&gt; 
&lt;p&gt;微软 CEO 萨提亚·纳德拉 (Satya Nadella) 随即宣布 GPT-5 的集成上线：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;今天，GPT-5 已登陆我们的多个核心平台，包括 Microsoft 365 Copilot、Copilot、GitHub Copilot 以及 Azure AI Foundry。这是我们的合作伙伴 OpenAI 迄今为止最强大的模型，在推理、编码和对话能力上实现了重大突破。所有训练均在 Azure 云平台上完成。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;与此同时，特斯拉 CEO 埃隆·马斯克 (Elon Musk) 在纳德拉的推文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1953509998233104649" target="_blank"&gt;回复称&lt;/a&gt;：「OpenAI 会「生吞」微软。」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0808/155746_esxJ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;马斯克与 OpenAI 的渊源由来已久。2015 年，马斯克作为联合创始人参与创立 OpenAI，其初衷是建立非营利机构，致力于「确保人工智能造福全人类」。然而，2018 年因控制权分歧，马斯克选择离开。此后双方矛盾逐渐公开化。2024 年，马斯克更是多次起诉 OpenAI，指控其违背非营利承诺，转向商业化路线。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365026</guid>
      <pubDate>Thu, 07 Aug 2025 08:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克回应 Dojo 团队解散：同时开发两种 AI 芯片无意义</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;特斯拉创始人埃隆·马斯克近日在社交平台公开回应 Dojo 超级计算机团队解散传闻，明确表示公司将终止同时开发两种不同架构 AI 芯片的战略。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他指出："分散资源推进 Dojo 与新一代 AI 芯片并行开发缺乏效率，特斯拉将集中力量攻关 AI5、AI6 等后续核心芯片。"&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="236" src="https://oscimg.oschina.net/oscnet/up-e11039dd360a422342685a3eb26c290ec40.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;据内部人士透露，此次战略调整涉及重大人事变动。Dojo 项目负责人 Peter Bannon 将于近期离职，其团队成员将转岗至数据中心及计算集群相关岗位。该项目自 2019 年启动以来，被马斯克视为实现完全自动驾驶（FSD）的关键基础设施，其独特的分布式计算架构曾被寄予厚望。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;马斯克在回应中特别强调新一代芯片性能优势:"AI5 系列在推理任务中将展现卓越能力，训练性能也可达到行业顶尖水准。"这种表述与此前对 Dojo"处理海量视频数据"的定位形成鲜明对比，凸显特斯拉技术路线的根本转变。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;行业分析师指出，此次调整反映出特斯拉在 AI 算力布局上的新思考。相较于专用架构的 Dojo，集中资源优化通用型 AI 芯片更符合当前技术发展趋势&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365019</guid>
      <pubDate>Thu, 07 Aug 2025 07:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源机器学习框架 PyTorch 2.8 正式发布，提升量化 LLM 推理性能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;PyTorch 2.8 已正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpytorch.org%2Fblog%2Fpytorch-2-8%2F" target="_blank"&gt;发布&lt;/a&gt;，重点在 Intel CPU 上大幅提升量化 LLM 推理性能，并实验性支持 Intel GPU 分布式后端。 此外，还引入稳定的 libtorch ABI、实验性 wheel 变体机制、SYCL 与 XPU 优化、ROCm 与 CUTLASS 后端增强，以及更多控制流算子支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-20962b842720616a8bfd331c0ba5864ac65.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Intel CPU 上的量化 LLM 推理性能显著提升&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;PyTorch 2.8 强调在原生 PyTorch 框架下实现高性能的量化大语言模型（LLM）推理（支持 A16W8、DA8W8、A16W4 等模式）。据称其性能可达或超越 vLLM 等热门 LLM 服务框架在单 x86_64 CPU 离线模式下的表现。&lt;/p&gt; 
&lt;p&gt;此外，Intel 工程师还引入了 FP8 QCONV、FP8 QLINEAR，以及更广泛使用 AMX 微内核等优化，大幅提升性能。例如，在第 6 代 Intel Xeon 平台上，以 M＝8、K 和 32 核心为条件下运行 Llama-3.1-8B 模型时，端到端延迟最高可缩短 20% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对 Intel GPU 的 XCCL 分布式后端的实验支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本次更新加入了 Intel 离散 GPU 的 XCCL 分布式后端的实验性支持，可用于不同训练范式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;其他重要变化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;将 SYCL 支持引入 PyTorch C++ 扩展 API。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 XPU 设备上加入 A16W4 模式支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实验性轮子（wheel）变体机制支持，方便平台依赖的包安装。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;限定稳定的 libtorch ABI&lt;/strong&gt;：为第三方 C++/CUDA 扩展提供了更稳定的接口，减少兼容性问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;轮子变体机制（Wheel Variants）&lt;/strong&gt;：允许针对硬件特性发布多个轮子版本，通过检测选择最佳匹配，实验性功能，目前可自动识别并安装最适合的 CUDA 平台包。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ROCm 支持增强&lt;/strong&gt;：增加对 gfx950 架构的支持，结合 TorchInductor 和 AOTInductor 提供 matmul、addmm、conv2d、bmm、_scaled_mm 等内核的 max-autotune 模板。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;控制流算子支持&lt;/strong&gt;：新增 cond、while_loop、scan、associative_scan、map 等控制流操作，以加速模型编译和导出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Inductor CUTLASS 后端支持&lt;/strong&gt;：为 torch.compile 和 AOTInductor 提供 CUTLASS 后端支持，覆盖 GEMM、fp8 mm、addmm 和 bmm 操作。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PyTorch 2.8 下载地址：&lt;em&gt;https://github.com/pytorch/pytorch/releases/tag/v2.8.0&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365017/pytorch-2-8</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365017/pytorch-2-8</guid>
      <pubDate>Thu, 07 Aug 2025 07:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
