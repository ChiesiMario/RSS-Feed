<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 12 Aug 2025 07:43:54 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>马斯克：xAI 将对苹果采取法律行动</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;埃隆·马斯克当地时间 8 月 11 日在社交平台发文称，苹果公司涉嫌通过限制措施，使除美国开放人工智能研究中心（OpenAI）外的任何人工智能公司都无法在其应用商店排行榜中登顶，称此为「明确的反垄断违规行为」。马斯克表示，其旗下 xAI 公司将立即采取法律行动。&lt;/p&gt; 
&lt;p&gt;&lt;img height="272" src="https://oscimg.oschina.net/oscnet/up-77b6ba53d5b9d23dcb776934627a6b8c4cb.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管马斯克的指控引发了广泛关注，但他并未提供具体证据来支持自己的说法。截至 8 月 12 日，ChatGPT 正占据美国 App Store 的榜首位置。值得一提的是，OpenAI 和苹果去年宣布了一项合作关系，将 ChatGPT 集成到苹果的智能系统中，以增强图像和文档理解等多项功能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在马斯克的指控后，OpenAI 首席执行官山姆・奥特曼也在社交平台上做出了回应。他表示，「这一指控非常引人注目，尤其是在我听到的关于马斯克如何操纵 X 以便让自己及其公司获益、并损害竞争对手及不喜欢的人的情况下。」 这一争论进一步加剧了马斯克与奥特曼之间本已紧张的关系，两人曾经在 OpenAI 共事。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;奥特曼在文中提到我希望有人能进行反向取证，我们都想知道究竟发生了什么。不过，OpenAI 将继续专注于开发优秀的产品。」 与此同时，社交媒体上有许多人质疑马斯克的说法，指出除了 ChatGPT 外，许多其他人工智能应用程序 App Store 上也曾登上过榜首。例如，来自中国的 DeepSeek 应用一度成为榜首，而自称与 ChatGPT 竞争的 Perplexity 最近在印度的 App Store 中也取得了&lt;span&gt;第一&lt;/span&gt;的位置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365734</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365734</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 亮相首届世界 RISC-V 日，分享最新 RISC-V 进展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 8 日，由 RISC-V 国际基金会重磅推出的首届世界 RISC-V 日 (World RISC-V Days) 在北京开源芯片研究院举行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//3f4075ef6e79ddf2ab5c098c63d555b7.jpg" width="840" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;deepin 社区技术委员会成员、苦芽科技工程师李程&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;参加了此活动，并于会议上带大家系统回顾了 deepin-ports SIG 的发展历程，并重点分享了 deepin-ports SIG 在 RISC-V 方向上的最新进展，包括但不限于 deepin RISC-V 生态适配、社区协作模式优化等方面。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//10b8829d40f7888c675d6790b227fb75.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:center"&gt;&lt;span&gt;&lt;span&gt;李程，deepin 社区技术委员会成员、苦芽科技工程师&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;deepin 对 RISC-V 架构的支持并非一日之功。自 2022 年 2 月起，deepin 就建立了对应 SIG，开始了 RISC-V 架构的适配工作，现已成功支持了大量主流的 RISC-V 硬件和开发板。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;在软件方面，deepin 也完成了对 RISC-V 开源软件生态的适配，提供了超过 27,000 个软件包，并为 RISC-V 开发板提供了内核、GPU、VPU、NPU 等驱动解决方案，确保了这些关键组件能够长期、及时、良好地维护。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//92d10ca4ef881324c89df1a23d1a392e.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;作为中国桌面操作系统的核心力量，deepin 积极响应国家战略，深度参与「甲辰计划」，全力投入 RISC-V 开源新生态建设。迄今，deepin 操作系统已成功适配了几乎所有可公开获取的桌面级 RISC-V 设备，并提供了关键的 GPU、NPU、VPU 等硬件加速支持。&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 23&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt; 稳定版及 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;deepin 25 预览版&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;均已为 RISC-V 平台提供官方镜像并持续更新。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;通过在硬件适配、软件生态构建、社区协作及战略规划上的不懈努力，deepin 已成为 RISC-V 生态的重要贡献者，并有力推动着 RISC-V 桌面操作系统的普及与应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//7215a0a6d6d54c51ac5e45faa8fd4f4a.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;李程还介绍到，deepin 作为「甲辰计划」的重要参与社区之一，为给更多同学提供深入 deepin、RISC-V 等技术项目的机会，将与甲辰计划联合提供近 80 个实习 HC。李程先生将作为该实习岗位的首席导师（Principle Mentor），协调实习工作内容，并负责 mentor 的招募和岗前培训。进一步了解：&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA5NzE0Mjg4Ng%3D%3D%26mid%3D2650457142%26idx%3D2%26sn%3D4b83559f9c00f28f1df379af82b1ab5a%26scene%3D21%23wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;span&gt;新增实习机会！RISC-V deepin 操作系统开发实习生正在招募&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;由于时间限制未设置现场问答环节，但与会者还是对技术路线和实习计划展现出了浓厚兴趣，众多参会者主动拍摄 PPT 关键内容页，期待进一步交流探讨。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//cd1393b25b25a0f66f8bf6cc4337cb36.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
    &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;附：&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span&gt;&lt;span&gt;deepin-ports SIG 主页：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://github.com/deepin-community/sig-deepin-ports&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365735</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365735</guid>
      <pubDate>Tue, 12 Aug 2025 07:39:21 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Rust 性能提升 「最后一公里」：详解 Profiling 瓶颈定位与优化</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、Profiling：揭示性能瓶颈的"照妖镜"&lt;/h1&gt; 
&lt;p&gt;在过去的一年里，我们团队完成了一项壮举：将近万核的 Java 服务成功迁移到 Rust，并收获了令人瞩目的性能提升。我们的实践经验已在《RUST 练习生如何在生产环境构建万亿流量》一文中与大家分享。然而，在这次大规模迁移中，我们观察到一个有趣的现象：大多数服务在迁移后性能都得到了显著提升，但有那么一小部分服务，性能提升却不尽如人意，仅仅在 10% 左右徘徊。&lt;/p&gt; 
&lt;p&gt;这让我们感到疑惑。明明已经用上了性能"王者"Rust，为什么还会遇到瓶颈？为了解开这个谜团，我们决定深入剖析这些"低提升"服务。今天，我就来和大家分享，我们是如何利用 &lt;strong&gt;Profiling&lt;/strong&gt; &lt;strong&gt;工具&lt;/strong&gt;，找到并解决写入过程中的性能瓶颈，最终实现更高性能飞跃的！&lt;/p&gt; 
&lt;p&gt;在性能优化领域，盲目猜测是最大的禁忌。你需要一把锋利的"手术刀"，精准地找到问题的根源。在 Rust 生态中，虽然不像 Java 社区那样拥有 VisualVM 或 JProfiler 这类功能强大的成熟工具，但我们依然可以搭建一套高效的性能分析体系。&lt;/p&gt; 
&lt;p&gt;为了在生产环境中实现高效的性能监控，我们引入了 &lt;strong&gt;Jemalloc&lt;/strong&gt; 内存分配器和 &lt;strong&gt;pprof&lt;/strong&gt; CPU 分析器。这套方案不仅支持定时自动生成 Profile 文件，还可以在运行时动态触发，极大地提升了我们定位问题的能力。&lt;/p&gt; 
&lt;h1&gt;二、配置项目：让 Profiling"武装到牙齿"&lt;/h1&gt; 
&lt;p&gt;首先，我们需要在 Cargo.toml 文件中添加必要的依赖，让我们的 Rust 服务具备 Profiling 的能力。以下是我们的配置，Rust 版本为 1.87.0。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[target.'cfg(all(not(target_env = "msvc"), not(target_os = "windows")))'.dependencies]
# 使用 tikv-jemallocator 作为内存分配器，并启用性能分析功能
tikv-jemallocator = { version = "0.6", features = ["profiling", "unprefixed_malloc_on_supported_platforms"] }
# 用于在运行时控制和获取 jemalloc 的统计信息
tikv-jemalloc-ctl = { version = "0.6", features = ["use_std", "stats"] }
# tikv-jemallocator 的底层绑定，同样启用性能分析
tikv-jemalloc-sys = { version = "0.6", features = ["profiling"] }
# 用于生成与 pprof 兼容的内存剖析数据，并支持符号化和火焰图
jemalloc_pprof = { version = "0.7", features = ["symbolize","flamegraph"] }
# 用于生成 CPU 性能剖析数据和火焰图
pprof = { version = "0.14", features = ["flamegraph", "protobuf-codec"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;简单来说，这几个依赖各司其职：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ tikv-jemallocator&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于 jemalloc 的 Rust 实现，以其高效的内存管理闻名。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ jemalloc_pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;负责将 jemalloc 的内存剖析数据转换成标准的 pprof 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ pprof&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用于 CPU 性能分析，可以生成 pprof 格式的 Profile 文件。&lt;/p&gt; 
&lt;h1&gt;三、 全局配置：启动 Profiling 开关&lt;/h1&gt; 
&lt;p&gt;接下来，在 main.rs 中进行全局配置，指定 &lt;strong&gt;Jemalloc&lt;/strong&gt; 的 &lt;strong&gt;Profiling&lt;/strong&gt; 参数，并将其设置为默认的全局内存分配器。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 配置 Jemalloc 内存分析参数
#[export_name = "malloc_conf"]
pub static malloc_conf: &amp;amp;[u8] = b"prof:true,prof_active:true,lg_prof_sample:16\0";


#[cfg(not(target_env = "msvc"))]
use tikv_jemallocator::Jemalloc;


// 将 Jemalloc 设置为全局内存分配器
#[cfg(not(target_env = "msvc"))]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这段配置中的 lg_prof_sample:16 是一个关键参数。&lt;/p&gt; 
&lt;p&gt;它表示 jemalloc 会对大约每 2^16 字节（即 64KB）的内存分配进行一次采样。这个值越大，采样频率越低，内存开销越小，但精度也越低；反之则精度越高，开销越大。在生产环境中，我们需要根据实际情况进行权衡。&lt;/p&gt; 
&lt;h1&gt;四、实现 Profile 生成函数：打造你的"数据采集器"&lt;/h1&gt; 
&lt;p&gt;我们将 Profile 文件的生成逻辑封装成异步函数，这样就可以在服务的任意时刻按需调用，非常灵活。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内存 Profile 生成函数&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_memory_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    // 获取 jemalloc 的 profiling 控制器
    let prof_ctl = jemalloc_pprof::PROF_CTL.as_ref()
        .ok_or_else(|| "Profiling controller not available".to_string())?;


    let mut prof_ctl = prof_ctl.lock().await;
    
    // 检查 profiling 是否已激活
    if !prof_ctl.activated() {
        return Err("Jemalloc profiling is not activated".to_string());
    }
   
    // 调用 dump_pprof() 方法生成 pprof 数据
    let pprof_data = prof_ctl.dump_pprof()
        .map_err(|e| format!("Failed to dump pprof: {}", e))?;


    // 使用时间戳生成唯一文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("memory_profile_{}.pb", timestamp);


    // 将 pprof 数据写入本地文件
    std::fs::write(&amp;amp;filename, pprof_data)
        .map_err(|e| format!("Failed to write profile file: {}", e))?;


    info!("Memory profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;CPU Profile 生成函数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;类似地，我们使用 pprof 库来实现 CPU &lt;strong&gt;Profile&lt;/strong&gt; 的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#[cfg(not(target_env = "msvc"))]
async fn dump_cpu_profile() -&amp;gt; Result&amp;lt;String, String&amp;gt; {
    use pprof::ProfilerGuard;
    use pprof::protos::Message;


    info!("Starting CPU profiling for 60 seconds...");


    // 创建 CPU profiler，设置采样频率为 100 Hz
    let guard = ProfilerGuard::new(100).map_err(|e| format!("Failed to create profiler: {}", e))?;


    // 持续采样 60 秒
    tokio::time::sleep(std::time::Duration::from_secs(60)).await;


    // 生成报告
    let report = guard.report().build().map_err(|e| format!("Failed to build report: {}", e))?;


    // 使用时间戳生成文件名
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let filename = format!("cpu_profile_{}.pb", timestamp);


    // 创建文件并写入 pprof 数据
    let mut file = std::fs::File::create(&amp;amp;filename)
        .map_err(|e| format!("Failed to create file: {}", e))?;


    report.pprof()
        .map_err(|e| format!("Failed to convert to pprof: {}", e))?
        .write_to_writer(&amp;amp;mut file)
        .map_err(|e| format!("Failed to write profile: {}", e))?;


    info!("CPU profile dumped to: {}", filename);
    Ok(filename)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;ProfilerGuard::new() 100 Hz 意味着每秒钟会随机中断程序 &lt;strong&gt;100 次&lt;/strong&gt;，以记录当前正在执行的函数调用栈&lt;/li&gt; 
 &lt;li&gt;tokio::time::sleep(std::time::Duration::from_secs(60)).await 表示 pprof 将会持续采样 60 秒钟&lt;/li&gt; 
 &lt;li&gt;guard.report().build() 这个方法用于将收集到的所有采样数据进行处理和聚合，最终生成一个 Report 对象。这个 Report 对象包含了所有调用栈的统计信息，但还没有转换成特定的文件格式&lt;/li&gt; 
 &lt;li&gt;report.pprof() 这是 Report 对象的一个方法，用于将报告数据转换成 pprof 格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;五、 触发和使用 Profiling：随时随地捕捉性能数据&lt;/h1&gt; 
&lt;p&gt;有了上述函数，我们实现了两种灵活的触发方式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 定时自动生成&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过异步定时任务，每隔一段时间自动调用 dump_memory_profile() 和 dump_cpu_profile() 。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn start_profilers() {
    // Memory profiler
    tokio::spawn(async {
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(300));
        loop {
            interval.tick().await;
            #[cfg(not(target_env = "msvc"))]
            {
                info!("Starting memory profiler...");
                match dump_memory_profile().await {
                    Ok(profile_path) =&amp;gt; info!("Memory profile dumped successfully: {}", profile_path),
                    Err(e) =&amp;gt; info!("Failed to dump memory profile: {}", e),
                }
            }
        }
    });
    // 同理可以实现 CPU profiler
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 手动 HTTP 触发&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过提供 /profile/memory 和 /profile/cpu 两个 HTTP 接口，可以随时按需触发 Profile 文件的生成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;async fn trigger_memory_profile() -&amp;gt; Result&amp;lt;impl warp::Reply, std::convert::Infallible&amp;gt; {
    #[cfg(not(target_env = "msvc"))]
    {
        info!("HTTP triggered memory profile dump...");
        match dump_memory_profile().await {
            Ok(profile_path) =&amp;gt; Ok(warp::reply::with_status(
                format!("Memory profile dumped successfully: {}", profile_path),
                warp::http::StatusCode::OK,
            )),
            Err(e) =&amp;gt; Ok(warp::reply::with_status(
                format!("Failed to dump memory profile: {}", e),
                warp::http::StatusCode::INTERNAL_SERVER_ERROR,
            )),
        }
    }
}
//同理也可实现 trigger_cpu_profile() 函数

fn profile_routes() -&amp;gt; impl Filter&amp;lt;Extract = impl Reply, Error = warp::Rejection&amp;gt; + Clone {
    let memory_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("memory"))
        .and(warp::path::end())
        .and_then(trigger_memory_profile);
    
    
    let cpu_profile = warp::post()
        .and(warp::path("profile"))
        .and(warp::path("cpu"))
        .and(warp::path::end())
        .and_then(trigger_cpu_profile);
    memory_profile.or(cpu_profile)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;现在，我们就可以通过 curl 命令，随时在生产环境中采集性能数据了：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:8080/profile/memory
curl -X POST http://localhost:8080/profile/cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;生成的 .pb 文件，我们就可以通过 go tool pprof 工具，启动一个交互式 Web UI，在浏览器中直观查看调用图、火焰图等。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go tool pprof -http=localhost:8080 ./target/debug/otel-storage ./otel_storage_cpu_profile_20250806_032509.pb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;六、性能剖析：火焰图下的"真相"&lt;/h1&gt; 
&lt;p&gt;通过 go tool pprof 启动的 Web UI，我们可以看到程序的&lt;strong&gt;火焰图&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何阅读火焰图&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 顶部：&lt;/strong&gt; 代表程序的根函数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 向下延伸；&lt;/strong&gt; 子函数调用关系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 火焰条的宽度：&lt;/strong&gt; 代表该函数在 CPU 上消耗的时间。&lt;strong&gt;宽度越宽，消耗的时间越多，越可能存在性能瓶颈&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8b814e239f61ed1c970231bc444f3896a50.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CPU Profile&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-55883adfb3cf12d5390b652452d3f883d17.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Memory Profile&lt;/p&gt; 
&lt;p&gt;在我们的 CPU 火焰图中，一个令人意外的瓶颈浮出水面：&lt;strong&gt;OSS::new&lt;/strong&gt; 占用了约 19.1% 的 CPU 时间。深入分析后发现， OSS::new 内部的 TlsConnector 在每次新建连接时都会进行 TLS 握手，这是导致 CPU 占用过高的根本原因。&lt;/p&gt; 
&lt;p&gt;原来，我们的代码在每次写入 OSS 时，都会新建一个 OSS 实例，随之而来的是一个全新的 HTTP 客户端和一次耗时的 TLS 握手。尽管 oss-rust-sdk 内部有连接池机制，但由于我们每次都创建了新实例，这个连接池根本无法发挥作用！&lt;/p&gt; 
&lt;h1&gt;七、优化方案：从"每次新建"到"共享复用"&lt;/h1&gt; 
&lt;p&gt;问题的核心在于重复创建 OSS 实例。我们的优化思路非常清晰：&lt;strong&gt;复用 OSS 客户端实例，避免不必要的 TLS 握手开销&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每次写入都新建 OSS 客户端。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;fn write_oss() {
    // 每次写入都新建一个 OSS 实例
    let oss_instance = create_oss_client(oss_config.clone());
    tokio::spawn(async move {
        // 获取写入偏移量、文件名
        // 构造 OSS 写入所需资源和头信息
        // 写入 OSS
        let result = oss_instance
            .append_object(data, file_name, headers, resources)
            .await;
}
fn create_oss_client(config: OssWriteConfig) -&amp;gt; OSS {
    OSS::new(
    ......
    )
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这种方案在流量较小时可能问题不大，但在万亿流量的生产环境中，频繁的实例创建会造成巨大的性能浪费。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ 共享实例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;让每个处理任务（ DecodeTask ）持有 Arc 共享智能指针，确保所有写入操作都使用同一个 OSS 实例。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;let oss_client = Arc::new(create_oss_client(oss_config.clone()));
let oss_instance = self.oss_client.clone(); 
// ...
let result = oss_instance
    .append_object(data, file_name, headers, resources)
    .await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;※ 自动重建机制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了应对连接失效或网络问题，我们引入了自动重建机制。当写入次数达到阈值或发生写入失败时，我们会自动创建一个新的 OSS 实例来替换旧实例，从而保证服务的健壮性。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 使用原子操作确保多线程环境下的计数安全
let write_count = self.oss_write_count.load(std::sync::atomic::Ordering::SeqCst);
let failure_count = self.oss_failure_count.load(std::sync::atomic::Ordering::SeqCst);


// 检查是否需要重建实例...
fn recreate_oss_client(&amp;amp;mut self) {
 
    let new_oss_client = Arc::new(create_oss_client(self.oss_config.clone()));
    self.oss_client = new_oss_client;
    self.oss_write_count.store(0, std::sync::atomic::Ordering::SeqCst);
    self.oss_failure_count.store(0, std::sync::atomic::Ordering::SeqCst);
    // 记录 OSS 客户端重建次数指标
    OSS_CLIENT_RECREATE_COUNT
        .with_label_values(&amp;amp;[])
        .inc();
    info!("OSS client recreated");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;八、优化效果：性能数据"一飞冲天"&lt;/h1&gt; 
&lt;p&gt;优化后的服务上线后，我们观察到了显著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CPU 资源使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降约 &lt;strong&gt;20%&lt;/strong&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-68b2935d6632ee730c0dc6ac3155a4257a4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OSS 写入耗时&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;同比下降约 &lt;strong&gt;17.2%&lt;/strong&gt; ，成为集群中最短的写入耗时。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 写入耗时&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-18a1b33fff58596e3d4317f4035511a8eca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;※ OSS 相关资源只占千分之一&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f35812df10896bc3430f0020571b4ab2e03.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内存使用率&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;平均下降 &lt;strong&gt;8.77%&lt;/strong&gt; ，这部分下降可能也得益于我们将内存分配器从 &lt;strong&gt;mimalloc&lt;/strong&gt; 替换为 &lt;strong&gt;jemalloc&lt;/strong&gt; 的综合效果。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-863bda3bf8f46a11ceeffef27808d64c90d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这次优化不仅解决了特定服务的性能问题，更重要的是，它验证了在 Rust 中通过 Profiling 工具进行深度性能分析的可行性。即使在已经实现了初步性能提升的 Rust 服务中，仍然存在巨大的优化空间。&lt;/p&gt; 
&lt;p&gt;未来，我们将继续探索更高效的 Profiling 方案，并深入挖掘其他潜在的性能瓶颈，以在万亿流量的生产环境中实现极致的性能和资源利用率。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;引用&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub - tikv/jemallocator: Rust allocator using jemalloc as a backend&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcrates.io%2Fcrates%2Fjemalloc_pprof" target="_blank"&gt;https://crates.io/crates/jemalloc_pprof&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub - google/pprof: pprof is a tool for visualization and analysis of profiling data&lt;/li&gt; 
 &lt;li&gt;Use Case: Heap Profiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjemalloc.net%2Fjemalloc.3.html%23heap_profile_format" target="_blank"&gt;https://jemalloc.net/jemalloc.3.html#heap_profile_format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.brendangregg.com%2Fflamegraphs.html" target="_blank"&gt;https://www.brendangregg.com/flamegraphs.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmagiroux.com%2Frust-jemalloc-profiling" target="_blank"&gt;https://magiroux.com/rust-jemalloc-profiling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.Valkey 单点性能比肩 Redis 集群了？Valkey8.0 新特性分析｜得物技术&lt;/p&gt; 
&lt;p&gt;2.Java volatile 关键字到底是什么｜得物技术&lt;/p&gt; 
&lt;p&gt;3.社区搜索离线回溯系统设计：架构、挑战与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;4.正品库拍照 PWA 应用的实现与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;5.得物社区活动：组件化的演进与实践&lt;/p&gt; 
&lt;p&gt;文 / 炯帆，南风&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18687884</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18687884</guid>
      <pubDate>Tue, 12 Aug 2025 07:23:21 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Linux Turbostat 工具可显示 CPU L3 缓存拓扑信息</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 6.17 内核源代码树中 Turbostat 工具的更新已完成合并&lt;/p&gt; 
&lt;p&gt;Turbostat 是一款命令行工具，用于显示 CPU 频率/空闲/功耗统计信息以及其他相关的处理器信息，主要针对 Intel 和 AMD 处理器。值得注意的是，Linux 6.17 中的 Turbostat 增加了显示 L3 缓存拓扑信息的支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cf186a887af4b06f2d0a899e1a4af7834c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Turbostat 还新增了对新增计数器（例如累计瓦特和其他计数器）进行平均的功能，修复了对即将推出的英特尔至强 Diamond Rapids 处理器的支持。&lt;/p&gt; 
&lt;p&gt;由于部分型号特定寄存器 (MSR) 的变更，Turbostat 需要进行更多调整，以便正确显示 Granite Rapids 后续的下一代至强处理器的功耗和性能相关详细信息。&lt;/p&gt; 
&lt;p&gt;此外，Turbostat 还修复了针对 musl libc 的构建问题以及其他各种修复。更多详情，请访问&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAJvTdKmaTvaQiRjgz_Pr6a%2BXEkLzEnedujV%3Dvqwv5thEE63fdg%40mail.gmail.com%2F" target="_blank"&gt;此 pull request&lt;/a&gt;，该请求已合并至 Linux Git。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365725</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365725</guid>
      <pubDate>Tue, 12 Aug 2025 07:08:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 服务突发全面宕机，官方深夜回应：网页/API 已恢复</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;8 月 11 日，DeepSeek 服务突遭全面宕机，API 接口、网页平台以及 App 均无法访问或响应。&lt;/p&gt; 
&lt;p&gt;许多网友也通过微博话题 #DeepSeek 崩了# 反馈服务异常。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/144904_mWWF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据 DeepSeek 在官网发布的公告，DeepSeek 网页/API 已恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/145101_JSbh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;公告内容如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;21:55，该问题已被发现并正在实施修复；&lt;/li&gt; 
 &lt;li&gt;22:28，已定位到问题，服务正在逐渐恢复中；&lt;/li&gt; 
 &lt;li&gt;23:12，大部分服务已经恢复正常；&lt;/li&gt; 
 &lt;li&gt;23:39，此事件已得到解决。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365719</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365719</guid>
      <pubDate>Tue, 12 Aug 2025 06:51:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>文件系统 Btrfs 为 Meta 节省了数十亿美元的基础设施成本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在关于 Bcachefs 在主线 Linux 内核中的未来走向&amp;nbsp;的持续讨论中，有人提到了一件关于 Btrfs 的有趣轶事。&lt;/p&gt; 
&lt;p&gt;Meta（Facebook）长期以来一直是 Btrfs 文件系统最杰出的使用者之一。Meta 雇佣了许多致力于 Btrfs 文件系统的工程师，并且多年来一直以在生产环境中使用该系统而闻名。&lt;img alt="" src="https://static.cnbetacdn.com/article/2025/0810/0085eed7c9d333a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这并非新鲜事，过去也曾有过类似的演示，例如 Meta 如何依赖 Btrfs 构建其「整个基础设施」：&lt;/p&gt; 
&lt;p&gt;Meta 的著名 Btrfs 工程师 Josef Bacik 撰写了关于对 Meta 的 Btrfs 使用产生的影响程度的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2F8vE9_0cQweg" target="_blank"&gt;文章&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Meta 基础架构完全基于 btrfs 及其功能构建。凭借 btrfs 的功能和稳健性，我们节省了数十亿美元的基础设施成本。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/143122_B7jW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;鉴于 Meta 的运营规模及其庞大的基础设施，Btrfs 凭借其先进的功能集和稳健性，被认为节省了「数十亿美元」。对于那些仍然质疑 Btrfs 或其是否适合在生产环境中使用的人来说，这是一个有趣的故事。&lt;/p&gt; 
&lt;p&gt;在主线 Linux 内核中关于 Bcachefs 的持续讨论中，可以通过&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2F20250809192156.GA1411279%40fedora%2F" target="_blank"&gt;这个 LKML 帖子&lt;/a&gt;找到更多评论。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365715</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365715</guid>
      <pubDate>Tue, 12 Aug 2025 06:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 基金会旗下项目组织发布新的包容性语言指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 基金会的 OpenUSD 联盟 (AOUSD) 和学院软件基金会 (ASWF) &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faousd.org%2Fnews%2Falliance-for-openusd-announces-new-members-inclusive-language-guide-and-core-specification-progress%2F" target="_blank"&gt;发布了&lt;/a&gt;更新的包容性语言指南，并欢迎可口可乐、雷诺和埃森哲等新成员加入 AOUSD。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/140303_wwtD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2021 年以来，美国学院软件基金会 (Academy Software Foundation) 使用的《包容性语言指南》(Inclusive Language Guide) 已建议替换主/从、黑名单/白名单、性别歧视语言等常见提法。更新后的指南概述了一些开源项目/开发者应避免/替换的新增短语。&lt;/p&gt; 
&lt;p&gt;新增的社交性语言列表包括「原生支持」，应将其替换为「核心支持」或「内置支持」，以及将「pow-wow」替换为「huddle」或「meeting」。&lt;/p&gt; 
&lt;p&gt;被视为残疾歧视的语言应替换为「健全性检查」，而不是使用「验证检查」或「一致性检查」或类似的词语。此外，还建议不要使用「dummy」函数，而应使用「占位符」、「存根」或「样本」等词。&lt;/p&gt; 
&lt;p&gt;被视为暴力的语言不应使用「hang」（挂起）一词，而应将其替换为「unresponsive」（无响应）或「stalled」（停滞）。 更新后的《包容性语言指南》可在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aswf.io%2Finclusive-language-guide%2F" target="_blank"&gt;ASWF.io&lt;/a&gt;上找到。 （想要查看 2021 年版的人可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aswf.io%2Fblog%2Finclusive-language%2F" target="_blank"&gt;在这里&lt;/a&gt;找到之前的版本。）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365706</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365706</guid>
      <pubDate>Tue, 12 Aug 2025 06:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>昆仑万维开源 Matrix-3D 大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;昆仑万维&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2Gnir60PynGv_Vmbz50orw" target="_blank"&gt;宣布&lt;/a&gt;开源 Matrix-3D 大模型，一个融合全景视频生成与三维重建的统一框架。它从单图像出发，生成高质量、轨迹一致的全景视频，并直接还原可漫游的三维空间，对标李飞飞 WorldLabs 的生成效果，可实现更大范围的探索空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="165" src="https://oscimg.oschina.net/oscnet/up-569e5f8c464ab34a3896dc3250dcc32e588.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 由以下核心部分组成：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;轨迹引导的全景视频生成模块：&lt;/strong&gt;利用场景 Mesh 渲染图作为条件输入，训练视频扩散模型生成符合给定相机轨迹的全景视频。有效提升生成视频在空间结构上的一致性，缓解遮挡错误与图像伪影问题。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;双路径可选择的全景 3D 重建模块：&lt;/strong&gt;优化路径：对生成的视频进行超分与 3DGS 优化，获取高质量 3D 结构。前馈网络路径：基于 Transformer 直接回归，从生成视频 Latent 特征快速预测 3D 几何属性，实现高效重建。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Matrix-Pano 数据集：&lt;/strong&gt;大规模高质量合成数据集，包含 116K 条带有相机轨迹、深度图和文本注释的静态全景视频序列。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 核心优势：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;场景全局一致：&lt;/strong&gt;支持 360°自由视角浏览，几何结构准确、遮挡关系自然，纹理风格统一。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成场景范围大：&lt;/strong&gt;与现有场景生成方法相比，支持更大范围的、可 360 度自由探索的场景生成。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成高度可控：&lt;/strong&gt;同时支持文本和图像输入，结果与输入高度匹配，支持自定义范围与无限扩展。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;泛化能力强：&lt;/strong&gt;基于自研 3D 数据与视频模型先验，可生成多样、真实感强的高质量场景。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;生成速度快&lt;/strong&gt;：首个 Feed-Forward 全景 3D 场景生成模型，可快速生成高质量 3D 场景。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;Matrix-3D 同时支持文本、图像作为输入，生成的 3D 场景支持自由探索，具备如下特性：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;1. 视角一致性&lt;/strong&gt;：生成 3D 场景支持 360 度自由环视，内容始终保持统一一致。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;2. 几何、色彩一致性&lt;/strong&gt;：生成 3D 场景的几何关系和遮挡关系正确，不同区域颜色统一。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;3. 精准控制：&lt;/strong&gt;根据用户输入轨迹不同，能生成不同的 3D 场景。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;4. 大范围移动：&lt;/strong&gt;对比李飞飞 WorldLabs 和 HunyuanWorld 1.0 方法，Matrix-3D 支持更大范围的移动。&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;strong&gt;5. 无限续写：&lt;/strong&gt;生成一段场景后，用户可以在此基础上对场景进行扩写。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;6. 同时支持全景前馈重建和 3DGS 优化重建：&lt;/strong&gt;前馈重建网络 LRM 支持 10s 快速场景重建，基于 3DGS 优化的策略可重建精细准确的场景。&lt;/p&gt; 
   &lt;img height="190" src="https://oscimg.oschina.net/oscnet/up-67fdb1ed5fa3b1a134fee3f03746701ded5.png" width="500" referrerpolicy="no-referrer"&gt;
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;div&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;div&gt; 
          &lt;div&gt; 
           &lt;div&gt;
            &amp;nbsp;
           &lt;/div&gt; 
          &lt;/div&gt; 
         &lt;/div&gt; 
         &lt;div&gt;
          &lt;span style="color:#000000"&gt;此外，昆仑万维团队还提出了 Matrix-Pano 数据集，一个基于 Unreal Engine 构建可扩展的全景视频数据集，专为生成高质量、可探索的全景视频而设计。更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2Gnir60PynGv_Vmbz50orw" target="_blank"&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365703</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365703</guid>
      <pubDate>Tue, 12 Aug 2025 05:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 6.17-rc1 发布，未合并 Bcachefs 任何补丁</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linus Torvalds 在内核邮件列表&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flkml%2FCAHk-%3Dwgb%3DB_pGPSTw9y4Fw82y5V_mvzJp_0XcWanz7YRR5vkXA%40mail.gmail.com%2FT%2F%23u" target="_blank"&gt;发布&lt;/a&gt;&lt;/u&gt;了 Linux 6.17-rc1，主要变化包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;标准化部分笔记本电脑上的性能提升（Performance Boost）键的键码值&lt;/li&gt; 
 &lt;li&gt;gconfig 内核配置编辑器使用 GTK3&lt;/li&gt; 
 &lt;li&gt;改进 Rust 语言支持&lt;/li&gt; 
 &lt;li&gt;新的 GPU、ARM 和 RISC-V SoC 支持&lt;/li&gt; 
 &lt;li&gt;默认情况下未启用适用于 Panther Lake 的 Intel Xe3 显卡，&lt;/li&gt; 
 &lt;li&gt;改进文件系统性能&lt;/li&gt; 
 &lt;li&gt;攻击向量控制使管理相关的 CPU 安全缓解措施变得更加容易&lt;/li&gt; 
 &lt;li&gt;适用于 Intel Battlemage 显卡的 SR-IOV 和 Project Battlematrix 的多 GPU 准备工作&lt;/li&gt; 
 &lt;li&gt;……&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/123553_Kw7D_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中最引人瞩目的一个变化是 Bcachefs 维护者 Kent Overstreet 提交的任何 PR 都没有被接受。此前 Linux 作者和 Bcachefs 维护者之间曾爆发冲突，Linus Torvalds 表示考虑&lt;u&gt;&lt;a href="https://www.oschina.net/news/359160" target="_blank"&gt;移除&lt;/a&gt;&lt;/u&gt; Bcachefs 文件系统。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0707/150244_1eHd_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365696</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365696</guid>
      <pubDate>Tue, 12 Aug 2025 04:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>达摩院开源具身智能「三大件」，机器人上下文协议首次开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;8 月 11 日，在世界机器人大会上，阿里达摩院宣布开源自研的 VLA 模型 RynnVLA-001-7B、世界理解模型 RynnEC、以及机器人上下文协议 RynnRCP，推动数据、模型和机器人的兼容适配，打通具身智能开发全流程。&lt;/p&gt; 
&lt;p&gt;具身智能领域飞速发展，但仍面临开发流程碎片化，数据、模型与机器人本体适配难等重大挑战。&lt;/p&gt; 
&lt;p&gt;达摩院将 MCP（Model Context Protocol）理念引入具身智能，首次提出并开源了 RCP（Robotics Context Protocol）协议以推动不同的数据、模型与本体之间的对接适配。&lt;/p&gt; 
&lt;p&gt;达摩院打造了名为 RynnRCP 的一套完整的机器人服务协议和框架，能够打通从传感器数据采集、模型推理到机器人动作执行的完整工作流，帮助用户根据自身场景轻松适配。RynnRCP 现已经支持 Pi0、GR00T N1.5 等多款热门模型以及 SO-100、SO-101 等多种机械臂，正持续拓展。&lt;/p&gt; 
&lt;p&gt;&lt;img height="670" src="https://static.oschina.net/uploads/space/2025/0812/121917_TuXo_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具体而言，RynnRCP 包括 RCP 框架和 RobotMotion 两个主要模块。RCP 框架旨在建立机器人本体与传感器的连接，提供标准化能力接口，并实现不同的传输层和模型服务之间的兼容。RobotMotion 则是具身大模型与机器人本体控制之间的桥梁，能将离散的低频推理命令实时转换为高频的连续控制信号，实现平滑、符合物理约束的机器人运动。&lt;/p&gt; 
&lt;p&gt;同时，RobotMotion 还提供了一体化仿真-真机控制工具，帮助开发者快速上手，支持任务规控、仿真同步、数据采集与回放、轨迹可视化等功能，降低策略迁移难度。&lt;/p&gt; 
&lt;p&gt;大会上，达摩院还宣布开源两款具身智能大模型。RynnVLA-001 是达摩院自主研发的基于视频生成和人体轨迹预训练的视觉-语言-动作模型，其特点是能够从第一人称视角的视频中学习人类的操作技能，隐式迁移到机器人手臂的操控上，从而让机械臂操控更加连贯、平滑，更接近于人类动作。&lt;/p&gt; 
&lt;p&gt;世界理解模型 RynnEC 将多模态大语言模型引入具身世界，赋予了大模型理解物理世界的能力。该模型能够从位置、功能、数量等 11 个维度全面解析场景中的物体，并在复杂的室内环境中精准定位和分割目标物体。无需 3D 模型，该模型仅靠视频序列就能建立连续的空间感知，还支持灵活交互。&lt;/p&gt; 
&lt;p&gt;此外，达摩院还在上月开源了 WorldVLA 模型,首次将世界模型与动作模型融合，提升了图像与动作的理解与生成能力。相比传统模型，该模型抓取成功率提高 4%，视频生成质量显著改善，展现了较好的协同性和准确性。&lt;/p&gt; 
&lt;p&gt;开源链接&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;机器人上下文协议 RynnRCPhttps://github.com/alibaba-damo-academy/RynnRCP&lt;/li&gt; 
 &lt;li&gt;视觉-语言-动作模型&amp;nbsp;RynnVLA-001https://github.com/alibaba-damo-academy/RynnVLA-001&lt;/li&gt; 
 &lt;li&gt;世界理解模型&amp;nbsp;RynnEChttps://github.com/alibaba-damo-academy/RynnEC&lt;/li&gt; 
 &lt;li&gt;WorldVLA 模型 https://github.com/alibaba-damo-academy/WorldVLA&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365694</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365694</guid>
      <pubDate>Tue, 12 Aug 2025 04:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub CEO 即将离职，重新成为一名「创始人」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;GitHub 首席执行官托 Thomas Dohmke &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fnews-insights%2Fcompany-news%2Fgoodbye-github%2F" target="_blank"&gt;宣布&lt;/a&gt;即将离职，并表示自己将重新成为一名「创始人」，但会留任至年底以协助过渡工作。目前，微软尚未公布继任者人选。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="288" src="https://oscimg.oschina.net/oscnet/up-b265d62156bb9d35a20a8332242c7787afc.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Dohmke 于 2015 年通过其创业公司 HockeyApp 被微软收购而加入。2018 年微软以 75 亿美元收购 GitHub，Dohmke 于 2021 年被调任至该业务担任产品负责人，并在几个月后接替 Nat Friedman 成为首席执行官。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Dohmke 离职正值 GitHub 面临人工智能编码工具激烈竞争的关键时刻。2021 年，在 Friedman 的领导下，GitHub 与微软、OpenAI 合作推出了备受欢迎的 Copilot 工具，能为开发者推荐代码，旨在提高工作效率。目前，GitHub 的注册开发者已超 1.5 亿，相比 2021 年 10 月的 7300 万有了显著增长。根据微软 CEO &lt;span style="background-color:#ffffff; color:#333333"&gt;Satya Nadella&amp;nbsp;&lt;/span&gt;上月透露，已有 2000 万人在使用 Copilot，Copilot Enterprise 客户数量环比增长 75%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，随着被称为「氛围编码」（vibe coding）的潮流兴起，众多初创公司迅速崛起，对 GitHub 构成了挑战。这些工具利用人工智能模型快速生成应用程序和网站代码，包括 Anysphere 开发的 Cursor、Replit 和 Windsurf 等。根据今年 5 月至 6 月的 Stack Overflow 开发者调查，Cursor、Anthropic 的 Claude Code 和 Windsurf 等新兴工具已开始抢占市场份额，而这些竞争对手在去年的调查中均未被提及，显示出市场格局正在迅速变化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得注意的是，微软近期对人工智能战略进行了重大调整。今年 1 月，微软成立了由前 Meta 高管 Jay Parikh 领导的 CoreAI 平台与工具部门，而 GitHub 正式归入该部门。Dohmke 在备忘录中也提到：「GitHub 及其领导团队将继续作为微软 CoreAI 组织的一部分履行使命，更多细节将很快公布。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365686</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365686</guid>
      <pubDate>Tue, 12 Aug 2025 03:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>边缘智能、碎片化、长周期可靠性：操作系统基座的技术破局点</title>
      <description/>
      <link>https://my.oschina.net/u/4489239/blog/18687836</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18687836</guid>
      <pubDate>Tue, 12 Aug 2025 02:56:00 GMT</pubDate>
    </item>
    <item>
      <title>微软 GitHub CEO 托马斯・多姆克宣布离职</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软 GitHub CEO Thomas Dohmke（托马斯・多姆克）晚间&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fashtom%2Fstatus%2F1954920157853172064" target="_blank"&gt;发文&lt;/a&gt;，宣布将卸任 GitHub CEO 一职，去开启他的下一段冒险。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1504" src="https://static.oschina.net/uploads/space/2025/0812/104823_aKoy_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;托马斯表示，GitHub&amp;nbsp;拥有超过 10 亿个仓库和分支，1500 万+开发者，以及 Copilot 持续引领最蓬勃发展的 AI 市场，拥有 2000 万用户且不断增长，GitHub 今天比以往任何时候都更强大。&lt;/p&gt; 
&lt;p&gt;托马斯在发给 GitHub 员工的内部帖子中表示，十多年前，他的初创公司被微软收购后，他和他的家人从德国搬到了美国。从开发移动开发者工具，到与 Nat Friedman 一起运营 GitHub 的收购，再到成为 GitHub 的 CEO 并引领公司进入 Copilot 和 AI 时代，「这真是一段难忘的旅程。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365670</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365670</guid>
      <pubDate>Tue, 12 Aug 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里淘宝第一个程序员「多隆」现已离职</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;网传阿里「扫地僧」蔡景现已离职，其在阿里内外平台状态显示为「退隐江湖」。对此，阿里暂时没有回应。&lt;/p&gt; 
&lt;p&gt;蔡景现（花名多隆）于 2000 年加入阿里巴巴，是淘宝第一个程序员。作为淘宝初创团队核心工程师，他主导构建了淘宝交易系统和论坛系统。凭借卓越的技术贡献，他在 2014 年入选阿里巴巴集团合伙人团队。其入选理由包括「对淘宝业务的创纪录贡献」及「单纯专注的技术特质」。&lt;/p&gt; 
&lt;p&gt;2023 年 7 月，阿里巴巴集团年报显示蔡景现不再担任合伙人职务。&lt;/p&gt; 
&lt;p&gt;据悉，蔡景现长期担任阿里云智能事业群高级研究员，因其专注高效的工作风格被内部誉为「码神」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7a3c9a17e396032f4f6e3de92548157fad6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365665</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365665</guid>
      <pubDate>Tue, 12 Aug 2025 02:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​英国图灵人工智能研究所面临资金危机与内部动荡</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英国的图灵人工智能研究所（Alan Turing Institute）目前正处于危机之中，员工们向慈善委员会提出了匿名投诉，警告该机构可能面临崩溃的风险。这一投诉引发了对研究所领导层的严厉指责，称其在公共资金的使用上存在不当行为，并且内部文化氛围 「有毒」。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="383" src="https://oscimg.oschina.net/oscnet/up-a3ea108136514fe60deafb85486f4f08f42.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;技术秘书彼得・凯尔（Peter Kyle）威胁如果图灵研究所不调整其战略，将撤回其资金支持。这一消息让员工们感到震惊，认为这可能会导致该研究所的崩溃。凯尔希望研究所能够将研究重点转向国防领域，并进行领导层的全面改革，这与研究所过去主要关注环境可持续性和健康等领域的定位截然不同。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;图灵研究所自 2015 年成立以来，一直是英国人工智能研究的领先中心，然而最近几个月，该研究所内部的不满情绪不断上升。投诉中提到，图灵研究所的治理不稳、缺乏透明度以及对资金的支出决策不明朗，令公共和私人资助者感到担忧。此外，员工们还表示，尽管多次向领导团队反映问题，但没有任何实质性的改进。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新的首席执行官珍・英尼斯（Jean Innes）在接受媒体采访时表示，图灵研究所需要现代化，并更加专注于人工智能项目。然而，研究所面临的挑战依然严峻，已有多位高管因不满而辞职，这让外界对其未来发展产生了疑虑。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，图灵研究所正在进行大规模的组织变革，试图确保在国防、国家安全等领域发挥更大作用。随着政府对人工智能行业的重视，图灵研究所的战略调整将对英国的科技发展产生深远影响。&amp;nbsp;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365663</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365663</guid>
      <pubDate>Tue, 12 Aug 2025 02:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智谱 AI 发布并开源视觉推理模型 GLM-4.5V</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智谱 AI 发布了新一代旗舰视觉推理模型 GLM-4.5V。该模型基于 MOE 架构，总参数量达到 106B，激活参数量为 12B，支持视频、图像、文本、文件作为输入模态，输出文本，其上下文窗口为 64K。&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 基于智谱新一代旗舰文本基座模型 GLM-4.5-Air，延续 GLM-4.1V-Thinking 技术路线，在 41 个公开视觉多模态榜单中综合效果达到同级别开源模型 SOTA 性能，涵盖图像、视频、文档理解以及 GUI Agent 等常见任务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0812/101653_00Dq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 由视觉编码器、MLP 适配器和语言解码器三部分组成，支持 64K 多模态长上下文，支持图像与视频输入，并通过三维卷积提升视频处理效率。模型采用双三次插值机制，有效增强了模型对高分辨率及极端宽高比图像的处理能力与稳健性；同时，引入三维旋转位置编码（3D-RoPE），显著强化了模型对多模态信息的三维空间关系的感知与推理能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="706" src="https://static.oschina.net/uploads/space/2025/0812/102144_4JJ9_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM-4.5V 采用三阶段策略：预训练、监督微调（SFT）和强化学习（RL）。其中，在预训练阶段，我们结合大规模图文交错多模态语料和长上下文内容，强化了模型对复杂图文及视频的处理能力；在 SFT 阶段，我们引入了显式「思维链」格式训练样本，增强了 GLM-4.5V 的因果推理与多模态理解能力；最后，RL 阶段，我们引入全领域多模态课程强化学习，通过构建多领域奖励系统（Reward System），结合可验证奖励强化学习（RLVR）与基于人类反馈的强化学习（RLHF），GLM-4.5V 在 STEM 问题、多模态定位、Agent 任务等方面获得全面优化。&lt;/p&gt; 
&lt;p&gt;GLM-4.5V API 价格情况如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API 调用价格：低至输入&amp;nbsp;2 元/M&amp;nbsp;tokens，输出&amp;nbsp;6 元/M&lt;/li&gt; 
 &lt;li&gt;tokens 响应速度：达到&amp;nbsp;60-80 tokens/s&lt;/li&gt; 
 &lt;li&gt;API&amp;nbsp;接口文档：http://docs.bigmodel.cn/api-reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GLM-4.5V API 现已上线智谱开放平台&amp;nbsp;BigModel.cn，为所有新老用户准备了&amp;nbsp;2000 万 Tokens 的免费资源包。&lt;/p&gt; 
&lt;p&gt;领取链接：https://zhipuaishengchan.datasink.sensorsdata.cn/t/bv&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365661</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365661</guid>
      <pubDate>Tue, 12 Aug 2025 02:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>月报 Vol.02：新增条件编译属性 cfg、#alias 属性、defer 表达式，增加 tuple struct 支持</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;语言更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增条件编译属性 cfg。可以根据后端等条件进行文件内的条件编译。&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;#cfg(any(target="js", target="wasm-gc"))
let current_target = "js | wasm-gc"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增&lt;code&gt;#alias&lt;/code&gt;属性，目前可以给方法或函数创建别名，并支持标注废弃。后续支持更多场景。&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;#alias(combine, deprecated="use add instead")
fn Int::add(x : Int, y : Int) -&amp;amp;gt; Int {
  x + y
}

test {
  let _ = Int::add(1, 2)
  let _ = Int::combine(1, 2)
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新增 &lt;code&gt;defer&lt;/code&gt;表达式。提供了一个基于词法作用域的资源清理功能。当程序以任何方式离开 &lt;code&gt;defer expr; body&lt;/code&gt; 中的 &lt;code&gt;body&lt;/code&gt; 时，&lt;code&gt;expr&lt;/code&gt; 都会被运行&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;fn main {
  defer println("End of main")
  {
    defer println("End of block1")
    println("block1")
  }
  for i in 0..&amp;amp;lt;3 {
    defer println("End of loop \{i}")
    if i == 2 {
      break // `break` 等也能触发 `defer`
    }
    println("Looping \{i}")
  }
  return
}
&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;block1
End of block1
Looping 0
End of loop 0
Looping 1
End of loop 1
End of loop 2
End of main
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;nbsp;&amp;nbsp;目前，&lt;code&gt;defer expr&lt;/code&gt; 的 &lt;code&gt;expr&lt;/code&gt; 里不能抛出错误或调用 &lt;code&gt;async&lt;/code&gt; 函数。&lt;code&gt;expr&lt;/code&gt; 里不能使用 &lt;code&gt;return&lt;/code&gt;/&lt;code&gt;break&lt;/code&gt;/&lt;code&gt;continue&lt;/code&gt; 等控制流跳转构造&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Native 后端的 &lt;code&gt;Bytes&lt;/code&gt; 的末尾现在永远会有一个额外的 &lt;code&gt;'\0'&lt;/code&gt; 字节，因此现在 &lt;code&gt;Bytes&lt;/code&gt; 可以直接当作 C string 传给需要 C string 的 FFI 调用。这个额外的 &lt;code&gt;'\0'&lt;/code&gt; 字节不计入 &lt;code&gt;Bytes&lt;/code&gt; 的长度，因此现有代码的行为不会有任何变化&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;调整可选参数的语法，默认参数现在可以依赖前面的参数（之前这一行为被废弃了，因为它和 virtual package 不兼容，但现在我们找到了在兼容 virtual package 的前提下支持这种复杂默认值的方式）。另外，我们统一了有默认值（&lt;code&gt;label~ : T = ..&lt;/code&gt;）和没有默认值（&lt;code&gt;label? : T&lt;/code&gt;）的可选参数：现在，对于函数的调用者来说，这两种默认参数不再有区别，并且都支持下列调用方式：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;不提供参数，使用默认值&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;通过 &lt;code&gt;label=value&lt;/code&gt; 的形式显式提供参数&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;通过 &lt;code&gt;label?=opt&lt;/code&gt; 的形式调用，语义是：如果 &lt;code&gt;opt&lt;/code&gt; 是 &lt;code&gt;Some(value)&lt;/code&gt;，等价于 &lt;code&gt;label=value&lt;/code&gt;。如果 &lt;code&gt;opt&lt;/code&gt; 是 &lt;code&gt;None&lt;/code&gt;，等价于不提供这个参数&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;调整自动填充参数的语法，改用 &lt;code&gt;#callsite(autofill(...))&lt;/code&gt; 属性替代原有语法&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;// 原版本
pub fn[T] fail(msg : String, loc~ : SourceLoc = _) -&amp;amp;gt; T raise Failure { ... }
// 现版本
#callsite(autofill(loc))
pub fn[T] fail(msg : String, loc~ : SourceLoc) -&amp;amp;gt; T raise Failure { ... }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;废弃 newtype，增加 tuple struct 支持&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;// 旧语法，运行时等价于 Int
type A Int
fn get(a : A) -&amp;amp;gt; Int {
  a.inner()
}

// 新语法，运行时依然等价于 Int
struct A(Int)
fn get(a : A) -&amp;amp;gt; Int {
  a.0
}

struct Multiple(Int, String, Char)
fn use_multiple(x: Multiple) -&amp;amp;gt; Unit {
  println(x.0)
  println(x.1)
  println(x.2)
}
fn make_multiple(a: Int, b: String, c: Char) -&amp;amp;gt; Multiple {
  Multiple(a, b, c)
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;当 tuple struct 中类型数量为 1 个的时候，tuple struct 等价于原有的 newtype。因此，当 newtype 的 underlying type 不是 tuple 的时候，formatter 目前会自动将旧语法迁移至新语法。为了便于迁移，这种情况下的 tuple struct 也提供了一个 &lt;code&gt;.inner()&lt;/code&gt; 方法，之后会 deprecated 掉并移除&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;当 tuple struct 中类型数量超过 1 个的时候，tuple struct 和原有的 tuple newtype 的区别在于：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;tuple struct 不能由直接通过 tuple 构造&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;tuple struct 不能通过 &lt;code&gt;.inner()&lt;/code&gt; 方法得到一个 tuple&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;如果需要可以直接和 tuple 互相转换的 tuple struct，可以使用：&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;struct T((Int, Int))

fn make_t(x: Int, y: Int) -&amp;amp;gt; T {
  (x, y)
}

fn use_t(t: T) -&amp;amp;gt; (Int, Int) {
  t.0
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不过这种情况下访问具体元素时，需要 &lt;code&gt;t.0.0&lt;/code&gt; 或者 &lt;code&gt;t.0.1&lt;/code&gt; 进行访问&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;由于主要用途为数据存储和 &lt;code&gt;@json.inspect&lt;/code&gt; 等功能，&lt;code&gt;derive(FromJson, ToJson)&lt;/code&gt; 将不再提供高级格式调整参数。目前保留的格式参数为每个字段的 &lt;code&gt;rename&lt;/code&gt;（重命名）、批量重命名和 enum 的格式选择 &lt;code&gt;style&lt;/code&gt;，其余参数均将被移除。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;style&lt;/code&gt;的可选项为&lt;code&gt;legacy&lt;/code&gt;和&lt;code&gt;flat&lt;/code&gt;。后者简化了表示，适用于&lt;code&gt;@json.inspect&lt;/code&gt;等场景。目前所有 enum 都必须选择其中一个 style 使用。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;如果需要自定义 JSON 的格式，请自行实现 &lt;code&gt;FromJson&lt;/code&gt; 和 &lt;code&gt;ToJson&lt;/code&gt; 两个 trait。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;///| Flat
test {
  @json.inspect(Cons(1, Cons(2, Nil)), content=["Cons", 1, ["Cons", 2, "Nil"]])
}

///| Legacy
test {
  @json.inspect(Cons(1, Cons(2, Nil)), content={
    "$tag": "Cons",
    "0": 1,
    "1": { "$tag": "Cons", "0": 2, "1": { "$tag": "Nil" } },
  })
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;工具链更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新增 &lt;code&gt;moon coverage analyze&lt;/code&gt;功能，提供更直观的覆盖率报告&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Rust"&gt;Total: 1 uncovered line(s) in 2 file(s)

1 uncovered line(s) in src/top.mbt:

   | fn incr2(x : Int, step? : Int = 1) -&amp;amp;gt; Int {
12 |   x + step
   |   ^^^^^^^^         &amp;amp;lt;-- UNCOVERED
   | }
   …

Total: 1 uncovered line(s) in 2 file(s)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;现在 &lt;code&gt;moon test --target js&lt;/code&gt;在 panic 的时候，能根据 sourcemap 显示原始位置了&lt;/p&gt; &lt;pre&gt;&lt;code class="language-Bash"&gt;test username/hello/lib/hello_test.mbt::hello failed: Error
    at $panic ($ROOT/target/js/debug/test/lib/lib.blackbox_test.js:3:9)
    at username$hello$lib_blackbox_test$$__test_68656c6c6f5f746573742e6d6274_0 ($ROOT/src/lib/hello_test.mbt:3:5)
    at username$hello$lib_blackbox_test$$moonbit_test_driver_internal_execute ($ROOT/src/lib/__generated_driver_for_blackbox_test.mbt:41:9)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/7007853/blog/18687782</link>
      <guid isPermaLink="false">https://my.oschina.net/u/7007853/blog/18687782</guid>
      <pubDate>Tue, 12 Aug 2025 02:19:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>昆仑万维发布 Matrix-Game 2.0：国产开源的 Genie 3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;昆仑万维&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPhnkrpTuQ-ntZfFNHTrGBw" target="_blank"&gt;宣布&lt;/a&gt;推出自研世界模型 Matrix 系列中 Matrix-Game 交互世界模型的升级版本——「Matrix-Game 2.0」，实现了通用场景下的交互式实时长序列生成的世界模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，Matrix-Game 2.0 已全面开源，是业内首个在通用场景上实现实时长序列交互式生成的世界模型开源方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-afca6110982b55fefd656c48f7a18b74899.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，「Matrix-Game 2.0」在实时生成和长序列能力上实现了质的飞跃。相较于上一版本，2.0 版本更加侧重低延迟、高帧率的长序列交互性能，能够以 25 FPS 的速度，在多种复杂场景中稳定生成连续视频内容，且生成时长可扩展至分钟级，大幅提升了连贯性与实用性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在推理速度显著提升的同时，模型依然保持了对物理规律与场景语义的精准理解，支持用户通过简单指令，自由探索、操控并实时构建结构清晰、细节丰富、规则合理的虚拟环境。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」提出了一种全新的视觉驱动交互世界建模方案，彻底摆脱了传统依赖语言提示的生成模式，专注于通过视觉理解和物理规律学习来构建虚拟世界。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与主流依赖文本语义的模型不同，「Matrix-Game 2.0」避免了语言先验可能带来的语义偏置，转而关注图像中的空间结构和动态模式，从而更真实、更准确地理解和生成虚拟世界。&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;基础模型架构&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="175" src="https://oscimg.oschina.net/oscnet/up-f9ecc45d299a9021d8550f66b32f6211012.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」采用图像为中心的感知与生成机制：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;3D Causal VAE 压缩结构：通过三维因果变分自编码器实现空间和时间维度的高效压缩，提升建模效率与生成能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多模态扩散 Transformer (DiT)：结合视觉编码器与用户动作指令，逐帧生成物理合理的动态视觉序列，并通过 3D VAE 解码成完整视频。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;用户交互控制：借鉴 GameFactory 与 Genie 系列的控制设计框架，引入「动作模块」，实现用户与生成世界之间的交互操作。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;实时自回归视频生成&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height="237" src="https://oscimg.oschina.net/oscnet/up-eb8035289152c9649761e8434a7e260b5ab.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」基于 Self-Forcing 训练策略，通过创新的自回归扩散生成机制克服了传统双向扩散模型的延迟和误差累积问题：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;因果扩散模型训练：将双向扩散模型蒸馏为因果模型，使用基础模型初始化生成器，并构建小规模数据集，通过近似 ODE 轨迹进行训练，稳定自回归扩散过程。通过历史帧条件生成当前帧，减少因依赖未来帧而导致的时序延迟。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;分布匹配蒸馏（DMD）：通过最小化与基础模型之间的分布差异，引导学生模型学习生成高质量视频帧，对齐训练与推理阶段的分布，显著缓解误差积累问题。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;KV 缓存机制：引入键值缓存机制（KV-Cache），显著提升长视频生成的效率和一致性。该机制通过维护固定长度的注意力上下文，实现无缝滚动生成，支持无限时长的视频输出，解决了训练与推理场景下上下文不一致的问题。基于此实现长时视频的高效生成而无需重复计算，单 GPU 上可实现 25 FPS 实时生成。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「Matrix-Game 2.0」能够生成跨场景的长时视频，保持动作和视觉的时序一致性，并且支持用户在交互过程中的连续指令输入，使其成为游戏内容创作、虚拟现实和智能交互系统的理想解决方案。这一方案将可控性、灵活性与效率相结合，推动高质量视频生成技术迈向更广泛的实时应用场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;例如在一些无约束、不可控的真实场景，「Matrix-Game 2.0」可根据用户输入的任意控制指令（如键盘的 W/A/S/D 方向键、鼠标用于视角移动），生成对应的交互世界视频，支持角色的前后左右移动以及视角变换等动态行为。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 GTA 游戏场景和 Minecraft 场景中，「Matrix-Game 2.0」也支持键盘与鼠标操作，并且能够生成真实感更强、符合物理逻辑的可交互视频。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Matrix-Game 2.0 具备三大核心优势：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;高帧率实时交互长序列生成：支持前后左右移动和视角转动，用户可通过指令操控角色在场景中自由行动，系统以 25 FPS 实时生成连续画面，单次交互可生成分钟级别长交互视频，动作自然流畅，响应精准。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;多场景泛化能力：模型具备出色的跨域适应性，不仅适用于特定任务场景，还支持多种风格与环境的模拟，包括城市、野外等空间类型，以及真实、油画等视觉风格。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;增强的物理一致性：对物理规则的理解进一步提升，角色在面对台阶、障碍物等复杂地形时，能够展现出符合物理逻辑的运动行为，提升沉浸感与可控性。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365659</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365659</guid>
      <pubDate>Tue, 12 Aug 2025 02:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯 APIJSON 生态 apijson-spring-boot 开源 •用 YAML 简化配置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h3&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c300c13a9b9281860955eefb4640dc84073.png" referrerpolicy="no-referrer"&gt;&lt;/h3&gt; 
&lt;p&gt;腾讯 APIJSON 是一种专为 API 而生的 JSON 网络传输协议，以及，基于这套协议实现的 ORM 库。&lt;br&gt; &lt;strong&gt;为各种增删改查提供了完全自动化的万能 API，零代码实时满足千变万化的各种新增和变更需求。&lt;/strong&gt;&lt;br&gt; 能大幅降低开发和沟通成本，简化开发流程，缩短开发周期。适合中小型前后端分离的项目。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自 2016 年 11 月开源 8 年多来发展迅速，目前 18K+ Star 位居 1000W Java 开源项目前 110。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-72064360a618ee52557c6884a874afa32fd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-05507add1ab73979181e2a721832b2ef017.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b0118180bc641918130cef0f4dee2bf1ca1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;apijson-spring-boot 介绍&lt;/h2&gt; 
&lt;p&gt;SpringBoot 3 for APIJSON，用 YAML 简化代码配置&lt;/p&gt; 
&lt;h2&gt;项目列表&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;项目&lt;/th&gt; 
   &lt;th&gt;说明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-autoconfigure&lt;/td&gt; 
   &lt;td&gt;自动配置&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-dependencies&lt;/td&gt; 
   &lt;td&gt;项目依赖&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-examples&lt;/td&gt; 
   &lt;td&gt;示例项目&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;apijson-spring-boot-starter&lt;/td&gt; 
   &lt;td&gt;APIJSON Spring Boot 启动器&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;支持的接口&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;接口 url&lt;/th&gt; 
   &lt;th&gt;方法&lt;/th&gt; 
   &lt;th&gt;说明&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;common/{method}&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;支持 GET，HEAD，GETS，HEADS，POST，PUT，DELETE，CRUD 等&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;common/{method}/{tag}&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;增删改查统一接口，这个一个接口可替代 7 个万能通用接口，牺牲一些路由解析性能来提升一点开发效率&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/reload&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;重新加载配置&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/post/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;生成验证码&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/gets/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;获取验证码&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/heads/verify&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;校验验证码&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/login&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;用户登录&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/logout&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;退出登录，清空 session&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/register&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;注册&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ext/put/password&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;设置密码&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;所有的配置属性&lt;/h2&gt; 
&lt;p&gt;不填则用默认值&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;spring:
  apijson:
    rest-api:
      enable: true                                  # 是否初始化 Rest 接口，默认 true。框架已提供 APIJSON 统一接口实现
      prefix: api-json                              # Rest 接口前缀，默认 api-json。访问接口如：http://localhost:8080/api-json/common/get
    application: fastjson2                          # 集成 apijson-fastjson2 包
    new-id-strategy: timestamp                      # 主键生成策略，默认 timestamp。支持：database(数据库自增)，uuid(uuid 字符串)， timestamp(当前时间毫秒数)，snowflake(雪花算法)，custom(用户自定义)
    need-verify-login: true                         # 每次访问 Rest 接口时是否需要校验登录
    need-verify-role: true                          # 每次访问 Rest 接口时是否需要校验角色权限
    need-verify-content: true                       # 每次访问 Rest 接口时开启校验请求传参内容
    enable-on-startup: false                        # 在启动时初始化，如：APIJSONVerifier(校验器) 初始化
    shutdown-when-server-error: true                # 启动遇到异常时停止
    log-debug: false                                # 日志
    sql:
      config:
        enable-column-config: false                 # 支持 !key 反选字段，和 字段名映射， 默认 false
        default-database: MYSQL                     # 默认的数据库类型, 默认 MYSQL。支持多种数据库，请参考 SQLConfig 类定义，注意名称全大写
        default-schema: sys                         # 默认数据库名/模式，默认 sys。 设置含有 APIJSON 系统表的数据库
        default-catalog:
        default-namespace:
        version: 5.7.22                             # 数据库版本, 默认'5.7.22'
      executor:
        enable-output-null-column: false            # 是否返回，值为 null 的字段, 默认 false
        key-raw-list: '@RAW@LIST'
        key-vice-item: '@VICE@ITEM'
    parser:
      function:
        parse-arg-value: false                      # 是否解析参数 key 的对应的值
        enable-remote-function: true                # 开启支持远程函数
        enable-script-function: true                # 开启支持远程函数中的 JavaScript 脚本形式
      request:
        print-request-string-log: false             # 是否打印关键的接口请求内容
        print-big-log: false                        # 打印大数据量日志的标识
        print-request-endtime-log: false            # 是否打印关键的接口请求结束时间
        return-stack-trace: true                    # 控制返回 trace:stack 字段
        start-from1: false                          # 分页页码是否从 1 开始，默认为从 0 开始
    verifier:
      enable-verify-column: true
      enable-apijson-router: false
      update-must-have-id-condition: true           # 为 PUT, DELETE 强制要求必须有 id/id{}/id{}@ 条件
      enable-verify-role: true                      # 开启校验请求角色权限
      enable-verify-content: true                   # 开启校验请求传参内容
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;创作不易，坚持更难，右上角点亮 ⭐ Star 来收藏/支持下吧，谢谢 ^_^&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gitee.com/yunjiao-source/apijson-spring-boot"&gt;https://gitee.com/yunjiao-source/apijson-spring-boot&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365652</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365652</guid>
      <pubDate>Tue, 12 Aug 2025 01:51:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>「字节跳动静态资源公共库」因黑产原因下线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;从 2025 年 6 月份开始，就有诸多站长发现字节跳动旗下的静态资源公共库存在调用问题，包括部分资源连接超时或者直接 HTTP 404，这导致网站无法正常加载内容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;当时测试发现诸如 jQuery 等还可以调用，其他部分资源出现错误无法调用，因此并不清楚字节跳动哪里出问题才会导致部分资源有效、部分资源无效。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0812/153944_CXJ5_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://cdn.bytedance.com/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;现在字节跳动已经明确静态资源公共库下线，当前所有静态资源已经全部处于 404 状态，字节跳动给出的原因是黑产问题，或许是黑灰产团伙也使用字节跳动的公共库调用资源，导致现在字节跳动被迫直接停掉这项服务。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/365736</link>
      <guid isPermaLink="false">https://www.oschina.net/news/365736</guid>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
