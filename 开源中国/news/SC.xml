<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Fri, 03 Jan 2025 07:38:44 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>开源日报 | Qwen-VL 大模型全面降价；华为轮值董事长孟晚舟新年致辞；「技术债务就像是幸存者的战斗伤痕」；国产 AI 舞台站满了「90 后天才」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.12.31&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301378&quot; target=&quot;_blank&quot;&gt;IBM 计划收购 HashiCorp，遭英国反垄断监管机构审查&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;据 TechCrunch 报道，英国反垄断监督机构竞争与市场管理局（CMA）已开始调查 IBM 计划收购云软件厂商 HashiCorp 是否会影响竞争。&lt;/p&gt; 
  &lt;p&gt;CMA 周一表示，它将在 1 月 16 日前邀请有关各方就这一并购发表评论。该监管机构暂定 2 月 25 日为最后期限，以决定是批准该交易还是将其提交进一步审查。&lt;/p&gt; 
  &lt;p&gt;IBM 于今年 4 月宣布同意以约 64 亿美元的价格收购 HashiCorp。如果收购继续进行，将扩大 IBM 在云计算和人工智能领域的推进力度，并让该公司获得 HashiCorp 约 4400 家客户的名册。&lt;/p&gt; 
  &lt;p&gt;CMA 于 8 月通知 HashiCorp 将对合并进行审查。美国联邦贸易委员会也在调查这一交易。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301401&quot; target=&quot;_blank&quot;&gt;阿里云再度降价：Qwen-VL 大模型全面降价&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;阿里云今天宣布，Qwen-VL 大模型全面降价。这是阿里云本年度的第三轮降价。&lt;/p&gt; 
  &lt;p&gt;Qwen-VL-Plus 模型价格直降 81%，输入价格仅为 0.0015 元/千 tokens，创下全网最低价格；而更高性能的 Qwen-VL-Max 降价至 0.003 元/千 tokens，降幅达到 85%。根据新的定价，1 元钱可以最多处理大约 600 张 720P 图片，或者 1700 张 480P 图片。&lt;/p&gt; 
  &lt;p&gt;Qwen-VL 系列大模型是阿里云推出的多模态大模型，已成为开源社区最受欢迎的模型之一，具备强大的视觉推理能力。该模型不仅能够识别不同分辨率和长宽比的图片，还能理解 20 分钟以上的长视频，并具备自主操作手机和机器人等智能体的视觉理解能力。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327292&quot;&gt;智谱深度推理模型 GLM-Zero 预览版上线&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;智谱宣布发布本年度最后一个模型 GLM-Zero 的初代版本 GLM-Zero-Preview，这是智谱首个基于扩展强化学习技术训练的推理模型。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;根据介绍，GLM-Zero-Preview 是 GLM 家族中专注于增强 AI 推理能力的模型，擅长处理数理逻辑、代码和需要深度推理的复杂问题。同基座模型相比，GLM-Zero-Preview 在不显著降低通用任务能力的情况下，在专家任务能力方面的表现大幅提升，其在 AIME 2024、MATH500 和 LiveCodeBench 评测中，效果与 OpenAI o1-preview 相当。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型表现如下：&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;247&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd02998897ee2c465a04b26d597ad65ae3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327323&quot;&gt;Altman 公布 OpenAI 2025 年将发布的技术产品&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;OpenAI 首席执行官萨姆・奥特曼（Sam Altman）发帖公布了该公司 2025 年即将发布的技术产品，分别是：&lt;/span&gt;&lt;/p&gt; 
  &lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
   &lt;li&gt;&lt;span&gt;AGI（通用人工智能）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;Agents（智能体）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的 GPT-4o 升级版&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的记忆存储&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更长的上下文窗口&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;「Grow up mode」（成人模式）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;深度研究特色功能&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的 Sora 以及更好的个性化定制&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8b88947df326c888e90ad352129eac9d6b6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301379&quot; target=&quot;_blank&quot;&gt;华为轮值董事长孟晚舟新年致辞：2024 年是原生鸿蒙关键一年，一年走过其它操作系统十多年发展之路&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;据华为官网显示，华为轮值董事长孟晚舟今日发布新年致辞，对客户、生态伙伴、产业链伙伴、员工和家属等表达了感谢。&lt;/p&gt; 
  &lt;p&gt;她在致辞中提到，在万物智联的赛道上，2024 年是原生鸿蒙的关键一年，鸿蒙生态建设千帆起航。鸿蒙千帆计划得到了众多行业伙伴的积极响应，短短一年时间，我们就走过其它操作系统十多年的发展之路，创造了「鸿蒙速度」。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F3146485692%2FP6Fdbs7pg&quot; target=&quot;_blank&quot;&gt;「全球互联网上中文内容比例很低」是一个误读&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;有人用图一来说明全球互联网上中文内容比例很低，只占 1.4%，实际上这是一个误读。我以前说过一次，这个数据统计方法并不是计算文字量或者网页数量，而是计算使用某种语言的网站数量。&lt;/p&gt; 
  &lt;p&gt;举个例子，微博网站在这个统计中，只能将样本数字+1，别管微博上边有多少中文内容，在这个统计方法中，微博跟万年没人看的某些个人站没有区别，都只算一个网站。同样是 W3Techs 提供的数据，图二就很能解释这个问题，只是中文网站数量少，并不是中文内容少。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div&gt;
    &lt;img alt=&quot;&quot; height=&quot;766&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-482daac5671878f6a85c04be877532dd134.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;img alt=&quot;&quot; height=&quot;463&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6f886a14ad542db607c9f12aece90f15540.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
   &lt;/div&gt; 
   &lt;div&gt;
    &amp;nbsp;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div style=&quot;text-align:right&quot;&gt;
    &lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;BugOS 技术组&lt;/strong&gt;&lt;/span&gt;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP6DrHa8Ob&quot; target=&quot;_blank&quot;&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式： M = &amp;nbsp;( (P * 4B) / (32 / Q) &amp;nbsp;) * 1.2&lt;/p&gt; 
   &lt;p&gt;M: 所需的 GPU 显存，单位是 GB。&lt;br&gt; P: 模型的参数数量。例如，7B 模型有 70 亿个参数。&lt;br&gt; 4B: 每个参数占用的字节数，这里假设每个参数占用 4 个字节（通常指 FP32 或 Float32 格式）。&lt;br&gt; 32: 4 个字节等于 32 位。&lt;br&gt; Q: 加载模型时使用的位数。例如，16 位 (FP16/BF16)，8 位 (INT8) 或 4 位 (INT4)。这通常称为量化。&lt;br&gt; 1.2: 表示额外开销的系数，通常为 20%。这考虑了除了模型权重之外还需要加载到 GPU 显存中的其他数据，例如优化器状态、梯度等。&lt;/p&gt; 
   &lt;p&gt;如使用 FP16 量化加载 Llama 70B 模型，计算过程就是&lt;br&gt; M = &amp;nbsp;( (70,000,000,000 * 4) / (32 / 16) &amp;nbsp;)* 1.2 = 168 GB&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 蚁工厂&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FP7e1GcOVX&quot; target=&quot;_blank&quot;&gt;大模型导航资源&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;分享个大模型导航资源，里面收集了几乎全部的模型，具有里程碑意义的论文，排行榜，测试集，训练框架，部署，应用，书籍等&lt;/p&gt; 
   &lt;p&gt;github.com/Hannibal046/Awesome-LLM&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; karminski-牙医&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1706699904%2FP6mWLnFlv&quot; target=&quot;_blank&quot;&gt;英伟达虽然欠下来了大量的「技术债务」，但在他看来「技术债务就像是幸存者的战斗伤痕。」&lt;/a&gt;&lt;/h4&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;关于先做个垃圾出来，读《英伟达之芯》又看到了一个好例子：&lt;/p&gt; 
      &lt;p&gt;3dfx 破产之后，一个加入英伟达的员工被英伟达的代码库震惊到了，「简直就像是癌症」「代码写得一塌糊涂，开发工具链也是一团乱麻，最重要的是，他们对此毫不在意」「他们一心只想着下一块芯片流片，其他什么都不顾。」&lt;/p&gt; 
      &lt;p&gt;而之前 3dfx 的工作方式则是追求完美，他在那里写出的程序优雅，开发的系统条理清晰、注释详尽，但结果却是一败涂地。&lt;/p&gt; 
      &lt;p&gt;他给的总结相当精辟，英伟达虽然欠下来了大量的「技术债务」，但在他看来「技术债务就像是幸存者的战斗伤痕。」&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;i 陆三金&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819939622972077660%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;AI 发展：训练数据即将遭遇瓶颈&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;训练数据即将遭遇的瓶颈已悄然浮现。有研究机构预测，到 2028 年左右，用于训练 AI 模型的数据集典型规模将达到公共在线文本总估计量的规模。换句话说，AI 可能会在大约 4 年内耗尽训练数据。与此同时，数据所有者（如报纸出版商）开始打击对其内容的滥用行为，进一步收紧了访问权限，这将引发「数据共享」规模上的危机。为此，开发人员必须寻找变通之道。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;科技日报&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.ce.cn%2Fcysc%2Ftech%2Fgd2012%2F202412%2F30%2Ft20241230_39251115.shtml&quot; target=&quot;_blank&quot;&gt;全面拥抱人工智能——访 360 集团创始人周鸿祎&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;我国人工智能大模型具有广阔发展前景，但要在全球大模型产业竞争中赢得主动，一是要充分发挥我国制度优势，与国外通用大模型展开竞争；二是充分用好我国工业种类齐全、场景众多的优势，将大模型和各种应用场景结合，推动一场新型工业革命，这是实现发展「弯道超车」的关键。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;经济日报&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819927511172343210%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;国产 AI 舞台，站满了「90 后天才」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;从资本到产业对人才的大手笔抢先押注现状来看，有关 AI 的比拼，无疑不止算力，而更在于人才。&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;科创板日报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819926514777138655%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;「国产英伟达」们，扎堆上市&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，GPU 企业想要快速发展，必然离不开资本的助力，冲击上市仍是「国产英伟达」们获取资金弹药的重要途径。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;而在等待资本市场的大门开启之前，它们也需要直面生存的考验。张建中曾直言，「摩尔线程目标为至少先存活 10 年」。在这场「国产替代」光荣而艰辛的征途中，中国算力企业的竞逐才刚刚开始。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;财经天下 WEEKLY&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819915034550649526%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;冷眼与嘲讽之后，谷歌的 AI 大模型翻盘之路&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#262626&quot;&gt;谷歌正在逐渐夺回大模型竞赛的行业关注度和开发者认同，反垄断大锤还尚未真正落下，谷歌获得了一个难得的发展窗口来在新的技术革新潮流中暂时站稳脚跟，为下一个人工智能时代真正到来前做好准备。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#252525&quot;&gt;&lt;strong&gt;锦缎研究院&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.ifeng.com%2Fc%2F8fjJTSFA8ou&quot; target=&quot;_blank&quot;&gt;AI「爆改」快递行业的第二年&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;从简单的寄件、查件入手，到面向快递小哥打造「知识库」、再到帮助完成业务信息的汇总整理，甚至到供应链的智慧控制，大模型在快递行业的能力正在被逐步释放。选择私有化部署模型、自研大模型的快递公司们都相信一点：大模型是值得的长期投资，它在快递行业的应用上限仍然有一个广阔空间等待发掘。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;光锥智能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fliriliri%2Faya&quot; target=&quot;_blank&quot;&gt;liriliri/aya&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ebd9d1bb174c2b67c92d4e694388364cd8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fliriliri%2Faya&quot; target=&quot;_blank&quot;&gt;https://github.com/liriliri/aya&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;AYA 是一款内置 ADB 并基于其功能编写用户界面的桌面应用。相比于原始的 ADB 命令行输入，AYA 安装傻瓜，功能齐全，全图形化界面，一键操作，极大地提高用户效率。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/4939618/blog/16883119&quot; target=&quot;_blank&quot;&gt;网页多模态建模思考&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;本文从网页理解业务出发，从多模态信息融合，预训练任务构建角度，探讨通用网页建模方案。首先，指出网页的特殊性，即从不同观察视角下，网页存在富文本、树形结构，和图层堆叠三种形态。在此基础上，对比了多种多模态融合思路的优缺点，给出一种较好的方案。进一步，提出多粒度、多维度的网页预训练方案；最后，探索了大模型时代，利用现有多模态模型，低成本的适配到网页的一种可行思路。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;图片&quot; height=&quot;173&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-42f7e135775e8f8238f20f5e042a576e488.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjS984AtnzvXfNwjPVFakZg&quot; target=&quot;_blank&quot;&gt;最强开源终端模拟器 Ghostty 正式发布 1.0：原生 UI 体验、采用 Zig 编写、速度飞快、支持 Mac 和 Linux、支持 GPU 加速&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：什么玩意？不支持 windows？我今晚就去提 issue，炮轰作者&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：不至于，README&amp;nbsp;里有写是有计划支持&amp;nbsp;Windows&amp;nbsp;的。终端模拟器不支持&amp;nbsp;Windows&amp;nbsp;是非常常见的情况&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：zig&amp;nbsp;比 rust 吹实在&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：只要 C&amp;nbsp;ABⅠ在行业上占大头，zig 就永远实在。zig 直接调用 C 真的很爽！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：完全可以理解，等下就去试试。Who&amp;nbsp;care&amp;nbsp;Windows?&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：和 Rust 写的 Warp 比如何？Zig 应用越来越多，好事。&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：Warp&amp;nbsp;性能不太行，输出多了卡，&amp;nbsp;不知道后续的版本会不会优化&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：目前在用 wezterm，感觉真正的 killer&amp;nbsp;feature 是 multiplexing，tmux 快捷键记不住。目前看 ghost 没有 multiplexing，也没有 tmux&amp;nbsp;integration，期待。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：好吧，我还是用 WinTerm 吧&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：你不觉得这玩意反应要慢半拍么，而且伪开源不让人放心。&lt;/span&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：我看不懂源代码，所以不存在放心与否～&lt;/span&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：不知道跟 wezterm 比起来怎么样&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：用上了，之前用 wezterm，个人感觉比 wezterm 更简洁高效。两个都很好。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：可以替换掉&amp;nbsp;iTerm2 了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：我用 powershell7.5&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLAiX2TcypVQbdG8s9Y2OMA&quot; target=&quot;_blank&quot;&gt;中国 AI 的进步之快，让美国人开始怀疑现实了&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：飘了&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：哪来这么多反思哥反思姐？作为机器学习领域的从业者，国内 ai 领域实际上就是在突飞猛进的发展，海外各类先进模型和理论也至少一半是大陆出海华人的贡献。现在大环境不好，但不是国内从业者夜以继日的努力是网民一句话所能掩盖的！&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：当然 DeepSeek 不太一样的是，它不太缺卡，2021 年就囤了 1 万张英伟达 A100，那会儿 ChatGPT 还没影呢，和 Meta 为了元宇宙囤卡却阴差阳错的赶上 AI 浪潮很像，DeepSeek 买那么多卡，是为了做量化交易⋯⋯&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：阴差阳错，就好比你买了一把锅铲，本来打算是用来炒菜的，后来发现打老公也挺好使！&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：中美 ai 发展的确差不多，期待落地&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0912/150800_DfGR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327414</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327414</guid>
            <pubDate>Tue, 31 Dec 2024 11:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 生态内容征集大赛（2025 年）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;很高兴告诉大家：RWKV 社区推出&quot;&lt;strong&gt;RWKV 生态内容征集大赛&lt;/strong&gt; &quot;，此活动在 &lt;strong&gt;2025 年全年内&lt;/strong&gt;公开征集 RWKV 相关的内容，包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;与 RWKV 相关的论文&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;讲解 RWKV 的教程，例如文章、视频、动画&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基于 RWKV 的应用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;我们会根据&lt;strong&gt;内容的质量、新颖度、与 RWKV 的相关度&lt;/strong&gt;，发放生态奖励：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;奖项&lt;/th&gt; 
   &lt;th&gt;奖金&lt;/th&gt; 
   &lt;th&gt;参考论文&lt;/th&gt; 
   &lt;th&gt;参考教程&lt;/th&gt; 
   &lt;th&gt;参考应用&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铂奖&lt;/td&gt; 
   &lt;td&gt;6888 元&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.06973&quot; target=&quot;_blank&quot;&gt;RWKV-CLIP&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.19369&quot; target=&quot;_blank&quot;&gt;RWKV-SAM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpoloclub.github.io%2Ftransformer-explainer%2F&quot; target=&quot;_blank&quot;&gt;铂金教程参考&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenMOSE%2FRWKV-LM-RLHF&quot; target=&quot;_blank&quot;&gt;RWKV-LM-RLHF&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;金奖&lt;/td&gt; 
   &lt;td&gt;4888 元&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.19535&quot; target=&quot;_blank&quot;&gt;StyleRWKV&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.10856&quot; target=&quot;_blank&quot;&gt;RWKV-edge&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FProfTomYeh%2Fstatus%2F1839706195508208089&quot; target=&quot;_blank&quot;&gt;金奖教程参考&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenMOSE%2FRWKV-Infer&quot; target=&quot;_blank&quot;&gt;RWKV-Infer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;银奖&lt;/td&gt; 
   &lt;td&gt;2888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshengxia%2FRWKV_Role_Playing&quot; target=&quot;_blank&quot;&gt;RWKV_Role_Playing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铜奖&lt;/td&gt; 
   &lt;td&gt;1888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铁奖&lt;/td&gt; 
   &lt;td&gt;888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;除了获奖作品，其他所有&lt;strong&gt;符合条件的投稿&lt;/strong&gt; 均可获得 &lt;strong&gt;RWKV 周边&lt;/strong&gt;一套，包括 RWKV T 恤、帆布袋、徽章、冰箱贴各 1 个。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-77625c3ead2e14d462793268eba2d3cb448.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;投稿规则&lt;/h2&gt; 
&lt;h3&gt;RWKV 论文&lt;/h3&gt; 
&lt;p&gt;我们征集任何与 RWKV 相关的论文，&lt;strong&gt;无论是谁写的，无论是否中会，只要内容新颖。&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的论文&lt;strong&gt;不限发布平台&lt;/strong&gt;，支持所有可公开查阅的论文平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;RWKV 文章&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的文章以&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fwrite&quot; target=&quot;_blank&quot;&gt;知乎-文章&lt;/a&gt;为默认发布平台，允许多平台分发。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在知乎发布文章时，请添加 &lt;code&gt;rwkv&lt;/code&gt; 话题：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e980b9c31863b214fac301b41edaa9fcd3a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;发布后，应当可以在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Ftopic%2F27422569%2Fnewest&quot; target=&quot;_blank&quot;&gt;知乎- RWKV 话题&lt;/a&gt;中查看您的投稿。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 文章需要满足以下要求：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文章正文不少于 300 字，每个章节或操作步骤需要有合理的配图&lt;/li&gt; 
 &lt;li&gt;文章应有合理的结构，示例结构：准备微调数据 -&amp;gt; 微调的调参等配置过程 -&amp;gt; 遇到的问题和解决方案 -&amp;gt; 微调效果&lt;/li&gt; 
 &lt;li&gt;文章语句清晰易懂，内容新颖&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RWKV 视频和动画&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的视频和动画以 &lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2F&quot; target=&quot;_blank&quot;&gt;bilibili&lt;/a&gt;&lt;/strong&gt; 为默认投稿平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 Bilibili 发布 RWKV 视频或动画时，需要带上 &lt;code&gt;RWKV&lt;/code&gt; 标签。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e5881d6a993bc1f88f77a388cf6aa70284c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 视频和动画需要满足以下条件：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频时长不低于 1 分钟&lt;/li&gt; 
 &lt;li&gt;视频画质不低于 720P&lt;/li&gt; 
 &lt;li&gt;视频音频无限制，可以是 AI 或真人配音，如无音频则需要配字幕&lt;/li&gt; 
 &lt;li&gt;内容新颖&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RWKV 应用&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 应用需要开源发布，以 &lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;/strong&gt; 为默认发布平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 GitHub 开源发布 RWKV 应用时，需要在 GitHub 仓库的设置中加上 &lt;code&gt;rwkv&lt;/code&gt; 标签。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1cfbe9e8859dff7e3a4dafc4cffd2ec2bda.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;仓库添加话题后，应当可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftopics%2Frwkv%3Fo%3Ddesc%26s%3Dupdated&quot; target=&quot;_blank&quot;&gt;GitHub-rwkv 话题最新项目&lt;/a&gt;中查看您的 RWKV 应用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 应用需要满足以下条件：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;应用需具有清晰的核心功能，并能够在真实场景中运行，内容新颖&lt;/li&gt; 
 &lt;li&gt;代码具备可读性，包含必要的注释&lt;/li&gt; 
 &lt;li&gt;README 等文档中包含&lt;strong&gt;依赖版本&lt;/strong&gt; 和&lt;strong&gt;操作步骤&lt;/strong&gt;等用户指南&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;活动规则&lt;/h2&gt; 
&lt;h3&gt;活动时间&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;用户投稿时间：2025 年全年（2025.01.01 ~ 2025.12.31）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;投稿反馈通道&lt;/h3&gt; 
&lt;p&gt;投稿后，请加入 &lt;strong&gt;RWKV 社区活动&lt;/strong&gt; QQ 群：858016738 ，联系管理员登记投稿。&lt;/p&gt; 
&lt;p&gt;任何关于本活动的疑问，也可以在群内讨论。&lt;/p&gt; 
&lt;h3&gt;评审规则&lt;/h3&gt; 
&lt;p&gt;由彭博等 RWKV 社区核心成员、大模型专家组成评审团，对参赛作品进行评审。&lt;/p&gt; 
&lt;p&gt;评审结果会&lt;strong&gt;在 2025 年每个自然月的下旬公布&lt;/strong&gt;，作品奖励会在次月发放。&lt;/p&gt; 
&lt;h3&gt;投稿内容范围&lt;/h3&gt; 
&lt;p&gt;所有投稿内容需要&lt;strong&gt;与 RWKV 架构或模型相关&lt;/strong&gt;，其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;论文&lt;/strong&gt;：基于 RWKV 架构或其变体，在语言、多模态、序列、强化学习等等领域的论文，也包括可解释性、理论分析、量化压缩、下游任务等等&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;教程（文章、视频、动画等）&lt;/strong&gt;：RWKV 架构解析、代码解读、微调案例等教程&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：基于 RWKV 架构或模型的应用，例如训练和推理框架，也包括角色扮演、助手、写作、游戏等等具体应用&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;奖品发放方式&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;现金奖励的币种为人民币，以汇款或转账方式发出，奖金为含税金额&lt;/li&gt; 
 &lt;li&gt;RWKV 周边奖励为实物，以快递方式发出&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327403</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327403</guid>
            <pubDate>Tue, 31 Dec 2024 09:21:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>网页多模态建模思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;本文从网页理解业务出发，从多模态信息融合，预训练任务构建角度，探讨通用网页建模方案。首先，指出网页的特殊性，即从不同观察视角下，网页存在富文本、树形结构，和图层堆叠三种形态。在此基础上，对比了多种多模态融合思路的优缺点，给出一种较好的方案。进一步，提出多粒度、多维度的网页预训练方案；最后，探索了大模型时代，利用现有多模态模型，低成本的适配到网页的一种可行思路。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;01 综述&lt;/h1&gt; 
&lt;p&gt;网页本质上是一种超文本，一般由超文本标记语言来定义（例如 HTML）。HTML 是一种基础技术，常与 CSS、JavaScript 一起被众多网站用于设计网页、网页应用程序以及移动应用程序的用户界面 。网页浏览器内核通过解释 HTML 文件，通过视觉引擎将其渲染成可视化网页。&lt;/p&gt; 
&lt;p&gt;由于 HTML 的复杂性特点，使得网页体现出多模态性，多粒度性，并且这些模态内部存在复杂的对应关系。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多模态性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所谓多模态性，即从不同视角下，网页体现出不同的形态。从信息载体角度看，它是文本、图像、视频等多媒体元素集合。从视觉层面看，它拥有图层的概念，是各层图像堆叠起来形成了一张完整的「图片」。从底层代码逻辑看，它是一种特殊的类 XML 语言，定义了一棵具有层次关系的树（dom-tree）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多粒度性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所谓多粒度性，即网页无论从哪种模态看，都是由粒度不等的元素组成的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以资讯类网页举例，从信息载体模态看，网页由段落组成，段落又由句子组成，句子由 tokens 组成；&lt;/p&gt; 
 &lt;p&gt;从视觉层面，网页由不同尺寸的图层，依次堆叠而成；&lt;/p&gt; 
 &lt;p&gt;从底层代码逻辑看，html 由不同高度以及大小的子树构成。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;内在的对齐逻辑&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;多种模态的基本元素之间，存在多对多的对齐关系。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;对于 dom-tree 的结点，对应视觉层面的一个图层，亦可对应着一个或者多个句子&lt;/p&gt; 
 &lt;p&gt;一个句子，可能对应着一个结点，也可能对应着多个结点&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;一个例子：多模态的网页表示&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9a68799619487d4d13e1e65530c502edaaa.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△语义：句子{图像、视频等可文本化）的集合&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1c057353f56b7591a592066fd456df918a0.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△结构：dom 结点构成的树&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-de73382e2ab59c30101daf9bbaa02660652.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△视觉：图层的叠加（轮廓图）&lt;/p&gt; 
&lt;p&gt;由于网页的多模态性，多粒度性，以及潜在对齐关系的特点，使得对网页的建模，与对富文本的建模思路有着显著的不同。如果将网页作为富文本处理，会丢失大量的信息&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;举一个简单的例子，一个文本位于网页的不同位置（譬如正文区域，推荐区域），它的重要性是完全不一样的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;而复杂的业务下游应用，例如网页质量甄别，网页结构化分块等，仅依赖文本的语义信息是远远不够的，需要综合考虑多模态的信息，以及多模态间的对齐信息。&lt;/p&gt; 
&lt;p&gt;下面，结合业界研究和我们的探索，从多模态信息融合、预训练方案方面展开。最后，探讨 LLM 时代，网页多模态模型的可能的探索方向。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;02 多模态多粒度特征融合&lt;/h1&gt; 
&lt;p&gt;如何将多粒度，多模态的特征融合，是一个复杂的问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 多粒度信息的表示&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这个部分，业内解决方案较多。&lt;/p&gt; 
&lt;p&gt;对&lt;strong&gt;语义信息建模&lt;/strong&gt;，基于 hierarchical attention 的有较多方案。一种方式，是通过 bert 等编码器，输入 tokens，取 CLS 单元输出作为句子的向量表示；再通过 transformer 结构，输入句子向量，计算句子间 attention，得到句子以及篇章的稠密向量表示，用于下游任务。&lt;/p&gt; 
&lt;p&gt;对于&lt;strong&gt;结构建模&lt;/strong&gt;，以 html-dom 为基本单元。通过全连接层，融合 bounding box 座标、webkit 提取的 css style 信息等。&lt;/p&gt; 
&lt;p&gt;对于&lt;strong&gt;视觉建模&lt;/strong&gt;，可以基于 vit，以 patch 为基本单元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 多对多对应关系下，多模态信息融合&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这部分，相关研究主要有四种方案：顶层融合，底层融合、多模态统一建模以及多模态交叉 attention 的方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-800824f2678ef96daec39a396908620c116.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;底层融合即在输入层将多模态信息对齐后拼接作为 transformer 层的输入。这种方案对多任务预训练方案设计（包括任务类型，多任务 loss 权重设计）要求较高，不利于多种模态的信息的平衡。&lt;/p&gt; 
&lt;p&gt;顶层融合即在顶层获取一个结点或者语句对应的多模态向量，拼接后用于下游分类或回归任务。缺点在于，各模态独立建模的时候，缺少了相关信息交互，不能充分利用多模态之间的对齐信息。&lt;/p&gt; 
&lt;p&gt;多模态统一建模，以 LayoutV2 为例，将文本、图片信息通过不同的编码器定长编码后，输入统一的 transformer 中。对于多模态综合理解任务来说，很难在输入层显示的注入多模态的对齐信息；网页结构的单元向量与语义、视觉（网页轮廓图）的单元向量亦很难通过浅层的编码器投影到相同的语义空间内。&lt;/p&gt; 
&lt;p&gt;通过对比，认为在网页建模场景下，多模态交叉 attention 是一个较好的方案。具体来说，各模态分域表示，域之间相互独立；通过多模态交叉 attention 层完成多模态间信息交互。DocFormer 提出的 multi-modal attention，Beit3 提出的 MultiWay Transformer 等本质上均为这种思路。&lt;/p&gt; 
&lt;p&gt;在多对多对齐关系下（即一个模态的基本单元，可能对应另外一个模态多个基本单元）。可使用聚合函数（例如 average-pooling，lstm 等），将对应模态上一层 transformer-encode 输出的对应单元序列，通过聚合操作后变换为定长向量，输入到多模态 attention 层计算。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-42f7e135775e8f8238f20f5e042a576e488.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d458c22d4438625ff4b8a868228cd254a5b.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;03 预训练任务设计&lt;/h1&gt; 
&lt;p&gt;如何设计针对多个模态，不同粒度的任务，以及如何低成本的构建伪标签，是训练网页基座模型的关键。&lt;/p&gt; 
&lt;p&gt;分析业务中下游任务的特点，在预训练阶段设计了如下 4 个类别的的预训练任务。 &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4623962da781deb0d521bd0b838298fb8b2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对于细粒度的语义预训练场景，借鉴 token 粒度 MLM 的思路，mask 完整的句子，并且通过 decoder 重建句子。&lt;/p&gt; 
&lt;p&gt;对于粗粒度的篇章预训练场景，结合搜索点击日志，mask 掉 title 后，通过 decoder 去噪重建 title 以及生成用户点击的 query。&lt;/p&gt; 
&lt;p&gt;对于细粒度的 html-dom 粒度预训练场景，通过 html_tag mask/重建，结点乱序重排进行训练。&lt;/p&gt; 
&lt;p&gt;对于篇章粒度的结构任务，通过 GPT 等生成页面类型的伪标签，作为监督信号训练。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;04 展望：LLM 时代的网页基座模型探索方向&lt;/h1&gt; 
&lt;p&gt;现阶段，多模态大模型发展到新的阶段，已经可以将图片（视频）、文本通过统一的 decoder 模型处理&amp;nbsp;。如何有效利用已有大模型的能力，低成本适配到网页，是当前研究的热点和难点。&lt;/p&gt; 
&lt;p&gt;一个朴素的思想，是将整个 html 源码输入给大模型，做进一步 postpretrain 使得模型适配网页。但是，由于网页源码的平均长度非常大（根据我们对百度网页库的统计，平均源码长度在 160k），如果再将节点的样式以 style 标签形式注入，源码长度预计会翻数十倍。面向海量网页计算极难落地。再者，针对网页场景下做若干轮 post-pretrain 成本亦很高。&lt;/p&gt; 
&lt;p&gt;一个可行思路是，通过 adaptor 网络，将网页 html-dom 的结构、位置以及视觉信息变换到已有多模态大模型的空间中，压缩成若干定长向量表示。&lt;/p&gt; 
&lt;p&gt;通过 adaptor 网络与 LLM 联合训练，调低 LLM 的学习率（尽量不扰动已有 LLM 的参数，保留 LLM 的泛化性）；通过特殊标签，注入 adaptor 产出的 tokens 向量，让 LLM 解释隐式向量代表的含义，训练 adaptor 网络。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;例如，构建 prompt：&lt;/p&gt; 
 &lt;p&gt;以下是一个网页的 dom 结点表示&amp;lt;STRUCT&amp;gt;adaptor_tokens&amp;lt;/STRUCT&amp;gt;，输出 css 描述文本：style=&quot;xxxxx&quot;&lt;/p&gt; 
 &lt;p&gt;训练 adator 网络，使得产出的 tokens 向量能够与 LLM 的语义空间打平&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;———— END————&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603657%26idx%3D1%26sn%3D6ba08a7cf4a124c94c4cd51786217499%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度垂搜一站式研发平台演进实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603628%26idx%3D1%26sn%3Df75ddec65ee183dc0c3d48b7e1fdb1ea%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;初探图谱 Embedding 用于异常检测（一）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603616%26idx%3D1%26sn%3D6f18533697c0a083f9c58373ac6b1a85%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;AIAPI - 转向 AI 原生检索&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603585%26idx%3D1%26sn%3D1ea31a1565c49bc466ddb99b6d9e63d9%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;学校新来了一位 AI 作文老师：能看、会评、还教改写&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603457%26idx%3D1%26sn%3Db3a0dcf00cb7a38bf62729c279619824%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;搞定十万卡集群！贫穷限制了我的想象力…&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4939618/blog/16883119</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/16883119</guid>
            <pubDate>Tue, 31 Dec 2024 08:37:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>支持图片生成、语音转文本和文本转语音节点，MaxKB 知识库问答系统 v1.9 版本发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;2025 年 1 月 3 日，MaxKB 开源知识库问答系统正式发布 v1.9 版本。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 社区版中，应用方面，MaxKB 新增图片生成节点、文本转语音节点、语音转文本节点，支持用户提问时上传音频文件，支持导出和导入应用；知识库方面，支持上传和导出包含文本和离线图片的 ZIP 格式文件；模型管理方面，图片理解模型新增支持 Xinference、Ollama、豆包、阿里云百炼、Azure OpenAI、Gemini 供应商，图片生成模型新增支持 Xinference、OpenAI、腾讯混元、通义千问、智谱 AI、豆包、阿里云百炼、Azure OpenAI 供应商。另外，Azure OpenAI 供应商还新增支持了语音识别、语音合成和向量模型。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;X-Pack 增强包方面，MaxKB 支持对接企业微信的微信客服，打破了内外部用户沟通的限制，为企业用户提供更加全面和高效的客户服务解决方案。&lt;/p&gt; 
&lt;h1&gt;亮点更新&lt;/h1&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&amp;nbsp;新增图片生成节点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 社区版中，MaxKB 新增支持图片生成节点。在此前的版本中，生成图片的操作需要依赖函数调用的方式。在 v1.9 版本中，我们新增了图片生成节点，支持管理员为该业务配置「图片生成模型」、「正向提示词」、「反向提示词」（部分模型不支持）等参数。图片生成节点的引入给管理员为应用添加图片生成功能提供了便利。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-80bfc0e9100b6326b39a6c60869fcdb6701.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 1 MaxKB 新增图片生成节点&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&amp;nbsp;支持上传音频文件，新增语音转文本节点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 社区版中，MaxKB 新增上传音频文件功能和语音转文本节点。MaxKB v1.9 在开始节点文件上传设置的「上传的文件类型」设置中，新增了音频上传功能开关，勾选后用户即可在问答时上传音频文件。管理员可以通过配置语音转文本节点来提取音频中的文本信息，作为后续对话中的引用材料。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;698&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-080de6007d29830498a2ad10f126fe423b1.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 2&amp;nbsp;MaxKB 支持设置上传音频类型的文件&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;704&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-466f5c30b42b641cb770cd289b6299424d0.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 3 MaxKB 新增语音转文本节点&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;&lt;strong&gt;■&amp;nbsp;新增文本转语音节点&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 社区版中，MaxKB 新增文本转语音节点。管理员在应用的工作流中可以通过添加文本转语音节点，将 AI 生成的回复文本高效地转换为自然语音输出。文本转语音节点的应用，将人机对话模式从传统的文本输入输出提升至更为便捷、人性化的语音对话层面，显著增强了用户体验的友好度与互动性。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;647&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23aec4f7d75cf40c4d0444b0412e9b52a58.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 4&amp;nbsp;MaxKB 新增文本转语音节点&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&amp;nbsp;支持导出和导入应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 社区版中，MaxKB 新增支持导出和导入应用。在 MaxKB 的「应用」页面中，新增了「导入应用」选项，支持导入「应用.mk」格式的文件；点击每个应用下方的「…」按钮，打开的菜单中新增「导出」功能选项，支持将工作流模板导出为「应用.mk」文件格式。这一功能使得管理员能够快速实现已有应用的迁移与复用，在提高工作效率的同时，方便用户备份和归档。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1472&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ff200de28ec868965bad27de5a213e7ff81.jpg&quot; width=&quot;2934&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 5&amp;nbsp;MaxKB 支持导出和导入应用&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;&lt;strong&gt;■&amp;nbsp;支持接入企业微信的微信客服（X-Pack 增强包）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;在 v1.9 专业版中，MaxKB 支持对接企业微信的微信客服，能够在私聊和群聊中为企业外部客户提供问答服务。此项更新使得 MaxKB 可以顺利接入微信客服体系之中，打破了内外部用户沟通的限制，为企业用户提供更加全面和高效的客户服务解决方案。至此，MaxKB 与企业微信对接功能的应用范围已经涵盖了企业内部员工和企业外部客户。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1230&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9072af54ee42be80620001a4fe37cc56d07.png&quot; width=&quot;1860&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲图 6&amp;nbsp;MaxKB 与微信客服对话&lt;/p&gt; 
&lt;h1&gt;其他新增功能&lt;/h1&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：知识库和文档支持导出 Excel 文件与离线图片的 ZIP 包；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：上传文档选择文本文件类型时，新增 XLS、XLSX、CSV、ZIP 文件格式；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;知识库：上传文档选择 QA 问答对类型时，新增 ZIP 文件格式；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：工作流节点支持设置执行条件；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用（X-Pack）：公众号、企业微信、微信客服支持语音提问和语音回答；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;模型设置：创建模型时，支持设置模型参数；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：图片理解模型和图片生成模型支持设置模型参数；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：图片理解模型新增支持 Xinference、Ollama、豆包、阿里云百炼、Azure OpenAI、Gemini 供应商；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：图片生成模型新增支持 Xinference、OpenAI、腾讯混元、通义千问、智谱 AI、豆包、阿里云百炼、Azure OpenAI 供应商；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;模型设置：向量模型新增支持 Azure OpenAI 供应商；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;模型设置：语音识别模型新增支持 Azure OpenAI 供应商；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;模型设置：语音合成模型新增支持 Azure OpenAI 供应商。&lt;/p&gt; 
&lt;h1&gt;功能优化&lt;/h1&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;知识库：文档列表支持批量取消向量化和批量取消生成问题；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：基本信息节点中的「用户输入」参数，添加参数时支持设置「显示默认值」选项；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：表单收集节点的参数支持设置「显示默认值」选项；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：对话 URL 支持携带「question=问题」参数，打开对话页面时自动发送问题；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：上传图片时自动生成「请解析图片内容」的问题；&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&amp;nbsp;&lt;/span&gt;应用：优化工作流节点的执行效率。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;模型设置：Amazon Bedrock 供应商添加大语言模型时，支持 ProxyURL 参数。&lt;/p&gt; 
&lt;h1&gt;问题修复&lt;/h1&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;安全：修复函数库模块中远程命令执行的安全漏洞（CVE-2024-56137）；&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&amp;nbsp;&lt;/span&gt;应用：修复浮窗对话框中不显示「新建对话」按钮的问题；&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：修复浮窗对话框右上角的 icon 颜色不一致的问题；&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：修复历史应用进行对话时会提示「缺少上下文类型」错误的问题；&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：修复使用低版本浏览器进行对话时报错的问题；&lt;/p&gt; 
&lt;p style=&quot;color:#3e3e3e; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&amp;nbsp;应用：修复执行复杂工作流时，在部分情况下会遗漏执行节点的问题。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327812/maxkb-1-9-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327812/maxkb-1-9-released</guid>
            <pubDate>Tue, 31 Dec 2024 06:14:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>曲速引擎前端代码生成器 6.6.0 介绍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h1&gt;&lt;strong&gt;曲速引擎前端代码生成器 6.6.0 介绍&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;曲速引擎前端代码生成器是动词算子式通用代码生成器阵列的前端生成引擎。支持 Java，Golang，Rust，Zig 数种语言，约十余个后端技术栈的前端代码生成。支持 Nodejs 21,18 和 14。现在，曲速引擎前端代码生成器已全部开源，并公布了介绍视频，视频请见：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Mw66YKENs%2F&quot; target=&quot;_blank&quot;&gt;https://www.bilibili.com/video/BV1Mw66YKENs/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;项目地址请见：&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;曲速引擎前端代码生成器项目地址：&lt;/span&gt;&lt;a href=&quot;https://gitee.com/jerryshensjf/WarpEngine&quot;&gt;https://gitee.com/jerryshensjf/WarpEngine&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;二进制发布版请见：&lt;a href=&quot;https://gitee.com/jerryshensjf/WarpEngine/releases/tag/V_6_6_0_taste&quot;&gt;https://gitee.com/jerryshensjf/WarpEngine/releases/tag/V_6_6_0_taste&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;曲速引擎前端代码生成器&lt;/h1&gt; 
&lt;h3&gt;介绍&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;曲速引擎前端代码生成器，此工具为动词算子式通用代码生成器阵列共用的前端代码生成器。时空之门前端代码生成器 4.6.0 以后的版本其实在本项目中。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;专用的 Vue+ElementUI 前端代码生成器，可以和多种后端代码生成器搭配。是通用代码生成器阵列的前端生成引擎。支持 Nodejs 21,18 和 14。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;输入图片说明&quot; src=&quot;https://oscimg.oschina.net/oscnet//3a00f97e962f4386a4a69ff1c4a35e85.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;软件截屏&lt;/h3&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-16af499bc9cd54b4d694d704818c2c41c01.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;输入图片说明&quot; src=&quot;https://oscimg.oschina.net/oscnet//6b91a624fd0c88f9083695d09e44c14b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;输入图片说明&quot; src=&quot;https://oscimg.oschina.net/oscnet//568177da540a36bce6d5d0ea9cb2656a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327792</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327792</guid>
            <pubDate>Tue, 31 Dec 2024 04:58:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>高性能 Java 工具库 wast v0.0.21 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;WAST 是一个高性能 Java 工具集库包，包括 JSON、YAML、CSV、HttpClient、JDBC 和 EL 引擎.&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;源码地址&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gitee：&amp;nbsp;&lt;a href=&quot;https://gitee.com/xiaoch0209/wast&quot;&gt;https://gitee.com/xiaoch0209/wast&lt;/a&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/li&gt; 
 &lt;li&gt;github：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwycst%2Fwast&quot; target=&quot;_blank&quot;&gt;https://github.com/wycst/wast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;性能测试:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;gitee：&amp;nbsp;&lt;a href=&quot;https://gitee.com/xiaoch0209/wast-jmh-test&quot;&gt;https://gitee.com/xiaoch0209/wast-jmh-test&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;github：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fwycst%2Fwast-jmh-test&quot; target=&quot;_blank&quot;&gt;https://github.com/wycst/wast-jmh-test&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&amp;nbsp;JSON 与 simdjson-java 对比：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/news/322296&quot;&gt;JSON 性能测试之二 - wastjson 每秒 6GB 解析速度完胜 simdjson-java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;表达式性能测试:&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/news/320983&quot;&gt;WastEl 表达式引擎性能测试 - 每秒千万次运算超强性能 - OSCHINA - 中文开源技术交流社区&lt;/a&gt;&amp;nbsp;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;v0.0.21 更新内容:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;JSON 调整序列化设置最大支持缓冲 buf 长度为 1.5G (v0.0.20)；&lt;/li&gt; 
 &lt;li&gt;JSON 校验重构支持输入 byte 数组 (v0.0.20)；&lt;/li&gt; 
 &lt;li&gt;double 解析精度 bug 修复 Issue&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fwycst%2Fwast%2Fissues%2F2&quot; target=&quot;_blank&quot;&gt;#2&lt;/a&gt;&amp;nbsp;(v0.0.20）；&lt;/li&gt; 
 &lt;li&gt;JSON 支持解析简单类型（number/boolean/null）(v0.0.20）；&lt;/li&gt; 
 &lt;li&gt;jdbc 控制某一个实体类不打印 sql;&lt;/li&gt; 
 &lt;li&gt;优化 EL 表达式解析模式下的运行性能（pojo 作为变量上下文时性能大幅度提升）;&lt;/li&gt; 
 &lt;li&gt;提升个别场景下 double 解析性能;&lt;/li&gt; 
 &lt;li&gt;JSONReader 支持 Pojo 类型的短路读取解析;&lt;/li&gt; 
 &lt;li&gt;修复 JSON 序列化在启用 JIT 模式下写入字段 key 错误问题&amp;nbsp;&amp;nbsp;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;实用功能： JSON 流式读取直接提取路径片段转化为 Pojo 类（短路模式）&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;    public static void main(String[] args) {
        Book book = JSONReader.exactPathAs(JSONReaderPojoTest.class.getResourceAsStream(&quot;/json/path.json&quot;), &quot;/store/book/0&quot;, Book.class);
        System.out.println(book);
        System.out.println(JSON.toJsonString(book));
    }&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;路径/store/book/0 代表读取到第一个 book 后短路退出，并把命中的路径片段转化为 Book 对象，当读取的流数据特别大比如几百 MB 甚至几个 GB 大小时将非常有用，和常规的解析相比内存占用小 (取决于 buffsize 可设置，默认 8192 字节)，而且效率更高。注意，当流数据不大时就没必要使用流式读取了，经过测试 JSONReader 完整读取模式通常没有 JSON 的 API 直接反序列化快，当解析读取大数据流而且需要控制内存占用则推荐使用 JSONReader。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327731/wast-0-0-21-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327731/wast-0-0-21-released</guid>
            <pubDate>Mon, 30 Dec 2024 16:06:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>SunnyUI V3.8.1 发布啦，C# WinForm 开源控件库！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;SunnyUI&quot; src=&quot;https://oscimg.oschina.net/oscnet//e2c8a48c5600383f751a010f95f6a89e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/stargazers&quot;&gt;&lt;img alt=&quot;star&quot; src=&quot;https://oscimg.oschina.net/oscnet//f2cc7891135773d7f33f8cb91536676f.svg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/members&quot;&gt;&lt;img alt=&quot;fork&quot; src=&quot;https://oscimg.oschina.net/oscnet//617186a7f2aeccd135cbdfdf332d077a.svg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;帮助文档:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/wikis/pages&quot;&gt;https://gitee.com/yhuse/SunnyUI/wikis/pages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更新日志:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/wikis/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97&quot;&gt;https://gitee.com/yhuse/SunnyUI/wikis/更新日志&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Gitee:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI&quot;&gt;https://gitee.com/yhuse/SunnyUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Fyhuse%2FSunnyUI&quot; target=&quot;_blank&quot;&gt;https://github.com/yhuse/SunnyUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Nuget:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/link?target=https%3A%2F%2Fwww.nuget.org%2Fpackages%2FSunnyUI%2F&quot; target=&quot;_blank&quot;&gt;https://www.nuget.org/packages/SunnyUI/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/link?target=https%3A%2F%2Fwww.cnblogs.com%2Fyhuse&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/yhuse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;因为评论没有查找，不利于解决问题，故关闭项目评论功能。如果是问题或者建议，请按照 Issues 模版添加 Issue。&lt;/li&gt; 
 &lt;li&gt;添加 Issue:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/new&quot;&gt;https://gitee.com/yhuse/SunnyUI/issues/new&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;V3.6.8+Demo 编译可执行文件:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI.Demo&quot;&gt;https://gitee.com/yhuse/SunnyUI.Demo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;SunnyUI.Net 是基于.Net Framework 4.0~4.8、.Net8、.Net9 框架的 C# WinForm 开源控件库、工具类库、扩展类库、多页面开发框架。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;768&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c3c587dbd99a478ed62523f94ad0d7ccbf.png&quot; width=&quot;1100&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;此版本更新内容为：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:left&quot;&gt;+ 增加 * 修改 - 删除&lt;/p&gt; 
&lt;h4&gt;2024-12-27 V3.8.1&lt;/h4&gt; 
&lt;p style=&quot;color:#40485b; margin-left:0; margin-right:0; text-align:start&quot;&gt;- 移除.Net6 支持，建议直接升级.Net8&lt;br&gt; + UIMenuButton: 增加下拉菜单按钮&lt;br&gt; * UFontAwesomeV6: 更新为 Font Awesome version: 6.7.1&lt;br&gt; * UITitlePanel: 增加 Padding 设置&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IBB1UF&quot;&gt;#IBB1UF&lt;/a&gt;&lt;br&gt; * UITabControl: 增加未选页签颜色&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IB7U69&quot;&gt;#IB7U69&lt;/a&gt;&lt;br&gt; * UITabControl: 修复标签文字越界显示&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IB8571&quot;&gt;#IB8571&lt;/a&gt;&lt;br&gt; * UIVerificationCode: 可以自定义颜色&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IBABW1&quot;&gt;#IBABW1&lt;/a&gt;&lt;br&gt; * UIComboDataGridView: 修复一个报错&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IB8YK9&quot;&gt;#IB8YK9&lt;/a&gt;&lt;br&gt; * UICalendar: 切换语言实时刷新&lt;br&gt; * UIScrollingText: 停止滚动时，可以设置默认显示位置&lt;br&gt; * UICheckBoxGroup: 修复 TitleTop 为 0 时，条目显示错位的问题&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IB7STO&quot;&gt;#IB7STO&lt;/a&gt;&lt;br&gt; * UITabControl: 修复了 SelectedIndex=-1 时的报错&lt;br&gt; * UIComboDataGridView: 解决下拉框显示过滤编辑框不能一直显示&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://gitee.com/yhuse/SunnyUI/issues/IB7AFB&quot;&gt;#IB7AFB&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327720/sunnyui-3-8-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327720/sunnyui-3-8-1-released</guid>
            <pubDate>Mon, 30 Dec 2024 14:14:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源日报 | Top 15 中国互联网公司首次全部盈利；百度网页版新增「AI 搜」；DeepSeek V3 架构图；AI 公司爬虫无视 robots.txt 协议；2024 年度数据库回顾</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2025.1.2&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327607/xorg-server-2024-gitstats&quot;&gt;X.Org Server 的代码提交次数创 10 年新高&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;根据 X.Org Server 的&amp;nbsp;&lt;/a&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;Git 提交记录&lt;/a&gt;，在刚刚过去的 2024 年，&lt;/span&gt;X.Org Server 的代码&lt;span&gt;提交次数达到了 2014 年以来的最高峰。虽然提交次数比前几年多了不少，但这并不意味着&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;X.Org Server&amp;nbsp;&lt;span&gt;的复兴，因为 Wayland 仍在 Linux 桌面上占据主导地位。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d93cec2031e1ac95173fc30bde92b9e8801.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a555233d997eb149ec68424bd0390abacf2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;据统计，X.Org Server 去年有 708 次提交... 比起 2018 年的 535 次提交（每年 200~300 次）要多得多。但即使是在 2010 年代中期，Wayland 还在积极开发的时候，每年也只有 400~500 次提交... 在 2024 年之前，提交次数最多的是 2014 年，当时有 952 次提交。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FVaWJNoUcZG0KhaMsCC564Q&quot; target=&quot;_blank&quot;&gt;Top 15 中国互联网公司首次全部盈利&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;据晚点 LatePost 报道，随着 B 站在 2024 年第三季度实现盈亏平衡，Top 15 中国互联网公司首次全部盈利。而经营效率本就高的几个大公司，多家盈利破了纪录。&lt;/p&gt; 
&lt;p&gt;从该媒体整理的排名来看，2024 年腾讯、字节、阿里、拼多多、美团、SHEIN、网易、京东、携程、百度、快手、贝壳、滴滴、小红书、B 站成为 Top 15 中国互联网公司。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-acddf66870f714eb2f765eb51478780f423.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327593&quot;&gt;百度网页版新增「AI 搜」功能，基于文心大模型打造&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;百度近日在百度搜索 Web 端首页上线了百度「AI 搜」入口，「AI 搜」基于原百度搜索 AI 伙伴改版升级而来，在此前的基础上做功能升级。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0102/100753_fgNl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;据介绍，百度「AI 搜」是基于百度文心大模型打造的桌面端 AI 搜索引擎，目前内容侧已经打通百度搜索引擎、百度健康、百度律临、百度文库、百度教育等内容生态，可确保搜索结果可靠、权威。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前百度「AI 搜」主要提供包括话题探索、问题解决、决策辅助、知识答疑、主题研究、学习创作等功能，覆盖文生图、文生文、逻辑推理、多轮对话、智能摘要、AI 修图等 AI 技术。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;此外，百度「AI 搜」也提供了文心智能体入口，在对话框中可通过 @方式与不同智能体进行交互，方便用户使用和创建智能体。&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fnewsflashes%2F3105267059887878&quot; target=&quot;_blank&quot;&gt;阿里云与零一万物达成战略合作，成立「产业大模型联合实验室」&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;近期，阿里云和大模型头部企业零一万物达成模型平台业务的战略合作，双方将成立「产业大模型联合实验室」，联手加速大模型从技术到应用的落地，进一步扩大产业大模型的生态整合。据了解， 双方深度战略合作的产业大模型联合实验室包含技术、业务、人才等板块，双方将结合两个团队的大模型研发实力，形成从下一代基座模型技术探索到产业落地大模型服务的组合拳，全面通过阿里云百炼大模型平台的模型服务层面向市场。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327681/swoole-server-v6-released&quot;&gt;Swoole v6 正式发布，增加 16 项新功能&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;随着&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;2024&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;年的结束，各位&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;PHP&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;开发者们所期待的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;Swoole v6&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;正式发布了。作为我们技术进步的结晶，这一版本不仅整合了过去一年间社区的反馈与需求，还展现了开发团队的创新与努力。它标志着&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;Swoole&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;在性能优化和功能拓展上的重大突破，为&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;PHP&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;开发者提供了更加强大的工具，助力我们在新的一年里开启更多无穷的可能。借此机会，让我们共同期待&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;Swoole v6&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#191b1f&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;能够在实际应用中展现出超乎寻常的能力，推动我们的项目走向更加成功的未来！&lt;/span&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1402400261%2FP7zX8Cpd8&quot; target=&quot;_blank&quot;&gt;AI 时代工程师的核心能力&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;以往我们总认为工程师的核心就是技术实力，但 AI 编程工具的出现正在重塑这个认知。&lt;/p&gt; 
    &lt;p&gt;如果说 Devin、Cursor 和 Windsurf 这样的 AI 助手是「精通各种编程语言的员工」，那么工程师更像是一位「技术主管」。&lt;/p&gt; 
    &lt;p&gt;这个转变意味着什么？工程师的价值正在向上迁移：&lt;br&gt; - 首先是沟通能力：需要准确地向 AI 描述需求，审核和整合 AI 的输出&lt;br&gt; - 其次是管理能力：协调多个 AI 工具，把控项目方向和质量&lt;br&gt; - 最后才是技术能力：这成为了确保 AI 输出质量的基础保障&lt;/p&gt; 
    &lt;p&gt;说实话，这种变化其实是件好事。它让工程师从繁琐的代码实现中解放出来，转而专注于更具创造性和战略性的工作。就像一位优秀的指挥家，重要的不是他能演奏所有乐器，而是懂得如何让整个乐团奏出最动听的乐章。&lt;/p&gt; 
    &lt;p&gt;这不是技术能力的贬值，而是能力结构的升级。掌握这三种能力的平衡，才是未来工程师的制胜之道。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div style=&quot;text-align:right&quot;&gt;
    &lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;爱可可-爱生活&lt;/strong&gt;&lt;/span&gt;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2Fttarticle%2Fp%2Fshow%3Fid%3D2309405118295841046578&quot; target=&quot;_blank&quot;&gt;现在的搜索引擎，快被 AI 垃圾淹成赛博粪坑了&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;昨天新年，白天我想找一张蛇的动漫风格参考图，来做个新年贺卡。然而就是这么简单的一次搜索，让我真的觉得，现在的互联网，越来越不对劲了。&lt;/p&gt; 
   &lt;p&gt;我就在搜索引擎搜了一下关键词「蛇，动漫」。第一页的结果是这样，那一瞬间，我只觉得寒意从电脑屏幕爬上脊背。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-02ede1cdc5d4e8a418919a6bd5b17552bc5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 数字生命卡兹克&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6045441276%2FP7G62c7XS&quot; target=&quot;_blank&quot;&gt;AI 公司的爬虫无视 robots.txt 协议&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;去中心化社交网络项目 Diaspora 的开发者近日透露，其论坛、维基和项目网站的流量中，有 70% 来自 AI 公司的网络爬虫。开发者表示，在过去 60 天内，Diaspora 的网络资产共接收到 1130 万次请求，平均每秒 2.19 次请求。其中，OpenAI 的 gptbot 爬虫占据了 24.6% 的流量，亚马逊的爬虫占 17.1%，Anthropic 和 Meta 的爬虫分别占 4.3% 和 2.2%。相比之下，Google 和 Bing 等传统搜索引擎的爬虫仅占 0.14% 的流量。&lt;/p&gt; 
   &lt;p&gt;开发者对此表示强烈不满，指出这些 AI 公司的爬虫无视 robots.txt 协议，试图索引每一个页面的细微变化，并且频繁切换 IP 地址，绕过 User Agent 字符串的封锁。开发者认为，这种行为无异于对互联网的分布式拒绝服务（DDoS）攻击，给服务器带来了不必要的负担，并可能影响正常用户的访问体验。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; blackorbird&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP7FFhCkw5&quot; target=&quot;_blank&quot;&gt;DeepSeek V3 架构图&lt;/a&gt;&lt;/h4&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-afe81d65a30a76bc4c87a0ecb2facf9f8f5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;蚁工厂&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpJcEo_8xBpCmeNVRSaNLZg&quot; target=&quot;_blank&quot;&gt;Andy Pavlo: 2024 年度数据库回顾&lt;/a&gt;&lt;/h4&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;就像突然有人一记「脑瓜冲天炮」般直击，我又来了！为大家奉上我每年的数据库大乱斗总结。没错，以前我是在 OtterTune 的博客上写这些东西，然而公司已经 Game Over（愿它安息）。现在我就跑回自己的教授个人博客来搞事。&lt;/p&gt; 
      &lt;p&gt;过去这一年里发生了不少事，从 10 位数的收购案、厂商到处撒野乱改许可证、再到某位超级有钱的数据库界八旬老汉为了追求新女神、砸钱拉拢大学橄榄球明星等传奇故事，好不热闹。我答应过我第一任老婆，今年要写得更专业点。而且听说有些大学把我每年的总结当作数据库课的必读材料。所以今年我得好好斟酌。但话说回来，想想我之前两年的文风，也就那样吧。反正咱先试试，看能不能稳住。&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;非法加冯&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.stcn.com%2Farticle%2Fdetail%2F1476193.html&quot; target=&quot;_blank&quot;&gt;大模型频繁降价，行业洗牌将加速？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;color:#141414&quot;&gt;值得关注的是，大模型降价对整个 AI 产业影响深远。在业内人士看来，大模型持续降价进一步加速行业洗牌，成本优势低、融资能力弱、规模小的企业或将被淘汰出局。同时，大模型降价的本质是让利给企业和开发者，更低的成本价格可以真正满足企业复杂业务场景需求，充分验证大模型的应用价值，推动企业以更低成本加速业务创新，实现 AI 普惠。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;证券日报&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.163.com%2Fdy%2Farticle%2FJKTM7AHL053179F1.html&quot; target=&quot;_blank&quot;&gt;OpenAI 12 集「发布会」背后：对中国产业 AI 落地的五大启示&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#404040&quot;&gt;AI 技术将进一步融入企业的日常工作流程，成为提高生产力和效率的标配。随着技术的成熟和成本的降低，企业将更加依赖 AI 来优化决策、提升服务质量、增强客户体验。AI 技术的无缝集成将使得企业能够更加灵活地应对市场变化，快速响应客户需求。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;产业家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fyovwa6Qckao8JXaaA6ABrQ&quot; target=&quot;_blank&quot;&gt;被 AI 分掉精力的数学天才陶哲轩，论文被拒了&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;span&gt;近日，&lt;/span&gt;&lt;span&gt;菲尔茨奖&lt;/span&gt;&lt;span&gt;获得者、华裔数学家陶哲轩在个人社交平台上讲述了其最新论文被投稿期刊拒绝的过程和感受，随后引发了种种热议：「审稿人的选择完全是胡扯。」「如果最优秀、最聪明的数学家之一都能让一篇论文被拒绝，那么这几乎可能发生在任何人身上。」「至少这说明某些系统运行得还算正常（不是仅凭名字就发表任何东西）......」&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;AI 前线&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1820117690620699987%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;离开英伟达，融资超 3 亿美元，他闯入一条地狱级赛道&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;徐驰很希望看到产业中的人都能赚到钱，但他又担忧如果仅仅是做一个更便宜的 Meta Ray-Ban 恐怕很难赚到钱。他不希望看到大家都因为热点突然冲进来，最终折腾一圈发现并不好赚钱，又啪一下走掉了，转身进入另一个行业。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;中国企业家杂志&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F3103452421983745&quot; target=&quot;_blank&quot;&gt;「中国液晶之父」挑战半导体&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#262626&quot;&gt;中国半导体领域的综合性企业北京奕斯伟科技集团 (奕斯伟集团、ESWIN) 力争推动晶圆部门进行首次公开募股 (IPO)。奕斯伟由被称为「中国液晶面板之父」的王东升担任经营首脑。在中美对立导致芯片进口变得困难的情况下，将加快在国内量产作为半导体基板的晶圆。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#252525&quot;&gt;&lt;strong&gt;日经中文网&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FiEMn1KxTWN3o9YsihhiyKw&quot; target=&quot;_blank&quot;&gt;大模型「六小虎」走向分化&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;当前大模型应用缺乏新计算设备（即手机、电脑之外的新设备）带来的新场景，在手机和电脑上的应用场景受限，尚未出现令人眼前一亮的原生或杀手级应用，比如新一代类似微信、拼多多、美团、字节跳动级别的应用。「目前的 AI 应用多是对现有业务的 AI 增强，但未达最理想状态。」&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;创投日报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fghostty-org%2Fghostty&quot; target=&quot;_blank&quot;&gt;ghostty-org/ghostty&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;img height=&quot;297&quot; src=&quot;https://static.oschina.net/uploads/space/2024/1230/152151_7zXa_2720166.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fghostty-org%2Fghostty&quot; target=&quot;_blank&quot;&gt;https://github.com/ghostty-org/ghostty&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Ghostty 是采用 Zig 语言编写的开源跨平台终端模拟器，支持 GPU 加速，在 Linux 和 macOS 上都使用了各自平台的 GUI 构建，macOS 是基于 SwiftUI，而 Linux 是基于 GTK —— 暂未支持 Windows。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/5783135/blog/16884662&quot; target=&quot;_blank&quot;&gt;盘点这些年搭建器在用户体验优化的实践&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;得物 App 中嵌入了大量的前端 Web 页面用以承接各种灵活多变的业务场景和玩法，但因为众所周知的原因，Web 应用的用户体验是很难与原生应用相比的。然而，随着搭建器功能的不断完善，支持的业务场景和组件也越来越多，越来越多的团队和部门优选使用搭建器搭建会场页面投放于得物 App 当中，这对搭建器的整体用户体验提出了更高的要求。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;抖动率.jpg&quot; height=&quot;192&quot; src=&quot;https://oscimg.oschina.net/oscnet//a3dd7d286788bd2832fad8e2865de5bb.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWm7gPEplvZ2UNPlXjD3b_Q&quot; target=&quot;_blank&quot;&gt;2024 年系统编程语言调查报告：Rust 稳居榜首、Zig 紧随其后&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：累了，希望明天世界毁灭&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：如果整个开发团队只有我一个人，我毫不犹豫选 rust，但是如果未来会有更多人参与到项目中，我毫不犹豫选 java。&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：我想不到什么样的项目会让团队面临 rust 还是 Java 的选择&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：给 Elixir 一个面子？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：期待 Rust 越来越好!&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：rust 居榜首 zig 紧跟其后&amp;nbsp;说明大众对 rust 不满意&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：go&amp;nbsp;不香吗&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：系统编程语言，不能有 gc&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：c3 呢？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：你要这么说，那还有很多没列出来的，比如 v，nim 等&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：产品多样化，是最可怕的，明明可以迭代，非要自立门户哈哈，商业化需求，扰乱视听，制造门槛&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：kotlin&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：不要反抗，接受 rust 神教的统治吧，所有人都要向伟大的蟹神膜拜&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPwTw3OlKl4NBdoUWVR8lZQ&quot; target=&quot;_blank&quot;&gt;C 语言就是神&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：为什么程序员总是纠结什么语言牛逼，什么技术最新，而不是现在什么产品需要什么技术来开发，什么语言市场需求大……陷入这种无意义的虚无的攀比有什么用？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：东坡肉是猪，扣肉是猪，咕噜肉是猪，然而你们这帮厨子仍然不考虑学习养猪&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：jdk&amp;nbsp;is&amp;nbsp;cpp&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：我至今搞不懂为什么这么多人用&amp;nbsp;java，唯一的理由是懒&lt;/span&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：我至今搞不懂为什么这么多人黑 java，唯一的理由是菜&lt;/span&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：顶级程序员在改变世界，高级程序员在改变生活，低级程序员在讨论哪个语言天下第一&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：Rust:&amp;nbsp;yes,&amp;nbsp;but&amp;nbsp;your&amp;nbsp;destiny&amp;nbsp;is&amp;nbsp;to&amp;nbsp;be&amp;nbsp;rewritten&amp;nbsp;by&amp;nbsp;me.&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：不知有木有人说，「C 语言是神，Rust 语言是大神」？感觉似乎全世界都在争先恐后地把 Rust 当新神捧...&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：系统语言之王&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：一帮写 crud 的码农觉得全世界都是 crud。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：go&amp;nbsp;is&amp;nbsp;go&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：几十年的沉淀，不是说替代就能替代的。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：c&amp;nbsp;is&amp;nbsp;汇编语言&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0912/150800_DfGR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327696</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327696</guid>
            <pubDate>Mon, 30 Dec 2024 10:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>盘点这些年搭建器在用户体验优化的实践</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;得物 App 中嵌入了大量的前端 Web 页面用以承接各种灵活多变的业务场景和玩法，但因为众所周知的原因，Web 应用的用户体验是很难与原生应用相比的。然而，随着搭建器功能的不断完善，支持的业务场景和组件也越来越多，越来越多的团队和部门优选使用搭建器搭建会场页面投放于得物 App 当中，这对搭建器的整体用户体验提出了更高的要求。&lt;/p&gt; 
&lt;p&gt;从我开始接触搭建器后，看到了很多搭建器项目为了用户体验优化所做的一些努力与优秀的解决方案，这些方案在各自的应用场景当中发挥了极其重要的作用。因此，抽时间以前端开发人员的视角梳理了现有的一些优秀方案，一则作为知识沉淀留档，方便之后查阅，二则也可以给后来者一些参考与借鉴。&lt;/p&gt; 
&lt;h1&gt;二、用户体验指标&lt;/h1&gt; 
&lt;p&gt;谈到用户体验，肯定首先要做的就是梳理衡量/验收指标以及当前瓶颈，这样才能做到有的放矢，针对高优的体验瓶颈进行针对性的优化，以最小的成本换取最大的收获。&lt;/p&gt; 
&lt;h2&gt;体验指标统计&lt;/h2&gt; 
&lt;p&gt;说到体验指标，或许每个公司都有不同的定义与口径，但无论如何变化，始终离不开以下几点核心要素：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用户可以看见有意义内容的时间（FMP）&lt;/li&gt; 
 &lt;li&gt;核心信息展示时间（LCP）&lt;/li&gt; 
 &lt;li&gt;页面的抖动频率与幅度（CLS）&lt;/li&gt; 
 &lt;li&gt;用户交互流畅度（TTI）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上述核心要素，在得物中落地时被转化为以下指标：&lt;/p&gt; 
&lt;h3&gt;秒开率&lt;/h3&gt; 
&lt;p&gt;秒开率是衡量 H5 打开速度的重要指标。在业界，普遍会使用 FMP（全称 &quot;First Meaningful Paint&quot;，翻译为&quot;首次有效绘制&quot;）表示页面的&quot;主要内容&quot;开始出现在屏幕上的时间点, 秒开率基本等同于 FMP。得物的秒开率计算方式为：count_if( webview 启动时间 + FMP 时间 &amp;lt; 1000) / count(*)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;业界方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;秒开率的统计与上报，绕不开 FMP 指标的计算与统计，我们参考了业界的一些现有方案，并结合业务特点设计更贴合我们业务的 FMP 计算公式。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一篇《前端监控实践------FMP 的智能获取算法》&lt;/li&gt; 
 &lt;li&gt;第二篇《定位性能指标 FMP》&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;两个方案大致相同都是基于权重计算出关键 dom。通过 mutationobserver 来监听变化，记录对应时间；然后在渲染结束后筛选出比较重要的 dom， 再用这些 dom 拿到对应的耗时。&lt;/p&gt; 
&lt;p&gt;他们区别如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一篇筛选出一批 dom 算平均值，第二篇筛选出权重最大的值。&lt;/li&gt; 
 &lt;li&gt;dom 类型的权重也有细微区别&lt;/li&gt; 
 &lt;li&gt;具体类型资源的计算方式有细微区别&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;dom 类型：svg、canvas、img、video、object、embed&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;const IGNORE_TAG_SET = [&quot;SCRIPT&quot;, &quot;STYLE&quot;, &quot;META&quot;, &quot;HEAD&quot;, &quot;LINK&quot;];
// 如果一个页面内有一个容器，容器内有多张图片，图片的重要应该高于容器, 这个值不宜设置过小，
// 否则会出现大多数场景 body 就是权重最大的元素，而不是里面的图片元素。
// 至少应该在 3*3，2*5 这样的布局中权重最大的元素为其中最后显示的图片，
// 由于存在空隙、文本等其他元素，大致为 40
const TAG_WEIGHT_MAP = {
  SVG: 60,
  IMG: 60,
  CANVAS: 60,
  
  OBJECT: 120,
  EMBED: 120,
  VIDEO: 120
};
// 普通节点权重：1
// 权重计算公示：width*height*weight，有背景图片的 div 等同于 img 标签
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;我们的方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们的方案大致和上文中提到的一致，部分细节做了一些适配和优化。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文章中提到的计算资源的的方法有两种: 资源的计算方式：performance timing api dom 变动的计算方式：diff + responseEnd&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文章中提到的 dom 变动的计算方式有些问题，两个相加的方式会造成误差比较大。因此我们选择使用 performance.mark 来计算，不过隐藏的问题是这个只是资源加载的时间，没有包含渲染的时间，数值会偏小。&lt;/p&gt; 
&lt;p&gt;由于 cat-design（内部组件 UI 库）对图片有 CDN 裁剪优化，我们需要把图片处理成去掉这些参数后的形式，以免资源名称不一致。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;监听 dom 的停止条件，过期时间：超过 10s dom 变化的时间间隔：超过 1s&lt;/li&gt; 
 &lt;li&gt;选取权重排名前三的元素，计算其中 fmp 的最大值，如果出现异常，使用 fcp 兜底。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6e3a28ad1522cf54f8ce30953a4d5852.jpg&quot; alt=&quot;我们的方案.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;抖动率&lt;/h3&gt; 
&lt;p&gt;抖动率是衡量一个页面是否稳定的核心指标，如果打开页面后，页面上的模块一直频繁变换，用户体验无疑极差的。因此，我们也得关注页面的 CLS 指标，防止大范围频繁抖动。后续也会对项目中针对页面抖动的优化做详细的介绍。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a3dd7d286788bd2832fad8e2865de5bb.jpg&quot; alt=&quot;抖动率.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;用户满意度调查&lt;/h2&gt; 
&lt;p&gt;由于用户设备所处的环境千奇百怪，可能是设备兼容性问题，也可能是网络问题，纯粹通过数据的统计，总是可能出现一些疏漏，并且缺乏对用户实际体验的真实反馈。为了补足这一部分可能缺失的数据，我们在一些用户访问频繁的核心频道页面，如：天天领券、疯狂周末、随心省，等页面设置了用户体验调查问卷，让有反馈需求的用户可以在这边反馈他们所遇到的体验问题：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2491fbebedbf26459905a0b25030ef78.jpg&quot; alt=&quot;用户满意度调查.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 通过用户反馈的一些高频体验问题，我们会针对性地进行排查可能导致问题的原因。&lt;/p&gt; 
&lt;p&gt;例如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;卡顿：可能因为页面 js 主线程存在耗时长任务导致页面操作卡顿。&lt;/li&gt; 
 &lt;li&gt;闪退：可能因为页面逻辑出现死循环或未正常退出的递归，导致系统爆栈，内存占满，部分设备在这种情况下会直接杀死有问题的进程（webview 实例）以确保其他程序的正常运行。&lt;/li&gt; 
 &lt;li&gt;白屏：可能因为网络链路不通或延迟导致无法正常下载 html 文档，又或者是核心渲染逻辑因为一些前置 js 的逻辑报错或资源获取失败而没有正常执行。当然，我们发现，很多时候，用户反馈的白屏，其实并不是真正的白屏，而是展示了页面骨架，此时有可能是进行 CSR（客户端渲染）时数据接口请求异常或逻辑处理异常。&lt;/li&gt; 
 &lt;li&gt;抖动：可能因为 AB 实验、风控拦截、逻辑隐藏/展示、人群定投常见下出现人群跃迁等原因，导致页面骨架跟实际用户展示的不一致，骨架缺少某些组件，但用户展示的时候需要展示，反之亦然。这样就会导致页面因组件数量的变化而发生剧烈的抖动，影响用户的体验。&lt;/li&gt; 
 &lt;li&gt;手机发热：可能因为死循环、密集计算等占用 CPU 资源过高，导致 CPU 发热严重&lt;/li&gt; 
 &lt;li&gt;图片出不来：可能因为访问图片资源的目标 CDN 节点故障，导致访问异常，也可能因为用户网络环境不佳，图片加载过慢，也可能是因为页面资源并行下载量过高，导致图片资源加载延迟等等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当然，很多时候，出现这些问题，不一定是代码实现有问题，有可能确实是用户的设备老旧，渲染性能和运行内存较低或者是用户所处的网络环境不佳（如在电梯中）导致的一些体验问题。因此用户的这些体验调查，仅作为体验指标统计的补充，我们的优化依然还是主要围绕着体验指标数据进行，再辅以用户反馈高频问题的排查以达到最真实的用户体验优化效果。&lt;/p&gt; 
&lt;h1&gt;三、体验优化&lt;/h1&gt; 
&lt;p&gt;确定了体验指标和优化的方向之后，我们再来具体的看一下应该如何针对这些指标进行针对性的优化。&lt;/p&gt; 
&lt;h2&gt;静态资源优化&lt;/h2&gt; 
&lt;p&gt;在绝大部分性能体验优化中，静态资源的优化都是首当其冲的，因为这个优化的效果往往是最为直接的，并且优化起来也是比较容易的，没有太多的弯弯绕绕，只需要想办法「降体增速」即可。&lt;/p&gt; 
&lt;h3&gt;文档类资源&lt;/h3&gt; 
&lt;p&gt;文档类资源指的是 html、js、css 等文件，这类的文件通常生成之后都是固定的，我们通常可以利用以下方式进行优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;【降体】文件体积压缩&lt;/li&gt; 
 &lt;li&gt;【降体|增速】资源公私分离 （通常公共的文件因业务需求变化的概率较小，没变化时可以直接访问浏览器缓存中的资源，而私有业务资源则因业务需求变化改变的概率较大，因此将文件进行公私分离有利于更细粒度的利用浏览器缓存）&lt;/li&gt; 
 &lt;li&gt;【降体】gzip 压缩&lt;/li&gt; 
 &lt;li&gt;【增速】浏览器的缓存策略&lt;/li&gt; 
 &lt;li&gt;【增速】CDN 加速&lt;/li&gt; 
 &lt;li&gt;【增速】离线访问（App Cache、PWA 等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了上述通用优化策略外，我们通常还需要对 html 文件进行进一步的优化，原因主要是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Html 文件是应用的入口，html 中有足够多的有效信息能够降低用户访问白屏的时间，优化用户体验&lt;/li&gt; 
 &lt;li&gt;现代前端应用大多是 SPA（单页应用），html 中的有效信息极少&lt;/li&gt; 
 &lt;li&gt;很多页面的数据需要服务端接口返回数据后才能确定如何展示&lt;/li&gt; 
 &lt;li&gt;有些页面的数据针对不同人群展示不同&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，如果我们想要最大限度的利用上 html 文件，那么就需要解决以下两个问题：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;提升 html 当中有效信息的占比&lt;/li&gt; 
 &lt;li&gt;提升 html 访问返回速度&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;我们针对上述两个问题逐个分析，逐个解决&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;提升有效信息占比&lt;/strong&gt; 我们想要提升页面中有效信息的占比，可以利用上 SSR（服务端渲染）技术，在返回 html 信息前，现在 node.js 服务端访问接口，把首屏需要展示的信息获取回来进行首次预渲染，并获取首屏展示所需要的 html 文本并塞会返回的 html 文档当中，使用这种方式，就可以解决 SPA（单页应用）html 内容有效信息过少的问题。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当然，我们需要注意，尽可能只是获取与首屏展示相关的信息，非首屏展示相关的不要再服务端渲染，不然会导致 html 体积增大从而影响资源响应速度。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;提升返回速度&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用 SSR 之后，html 的有效信息确实是得到提升了，但 CDN 加速对 SSR 并不友好，CDN 更适合用于缓存加速一些静态资源，而针对 SSR 这种动态资源有点力不从心。但如果我们想要资源响应速度得到进一步的提升，CDN 又是不可或缺的一环。&lt;/p&gt; 
&lt;p&gt;因此，我们需要更近一步，从 SSR 变为 SSG，从服务端渲染到服务端生成，也就是说，我们在使用 SSR 拿到了首屏渲染的 html 字符串后，不再是直接返回给浏览器，而是将其导出成 html 文件，并上传至 CDN，这样就能够充分利用 CDN 的加速能力加速首屏 html 的获取了。&lt;/p&gt; 
&lt;p&gt;不过我们使用 SSG+CDN 虽然达到了提速的目的，但是有个场景的问题不容忽视：针对不同用户、人群有不同展示的个性化组件。由于 CDN 缓存是没有状态和身份的，因此，所有用户访问的内容都是一样的，此时我们就没办法针对不同的用户在首屏渲染时展示特异性的数据。&lt;/p&gt; 
&lt;p&gt;基于上述原因，我们决定对组件进行分类：&lt;/p&gt; 
&lt;p&gt;通用骨架屏：针对有实验、目标人群、逻辑动态显示/隐藏的组件，在 SSG 阶段时不再直接按照接口返回数据展示，而是展示一个通用的骨架屏，当到了用户设备浏览器中进行客户端渲染时（此时可以拿到用户身份），再对骨架进行数据填充完成渲染。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9d0eec7d760ab2f1d66ea18a49072fc4.jpg&quot; alt=&quot;骨架屏.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SSR 首屏渲染：针对所有用户全量展示的组件，我们直接在 SSG 阶段就直接用服务端返回的数据渲染首屏页面结构，由于该组件跟用户身份无关，因此到了浏览器进行客户端渲染时，服务端返回的数据只会有极其细微的数据差异，只需将部分数据替换即可完成展示。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//33a51a783f88462582fced8e50075f41.jpg&quot; alt=&quot;SSR 首屏渲染.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;图片类资源&lt;/h3&gt; 
&lt;p&gt;我们上面的用户满意度调查当中，有一项是&quot;图片不出来&quot;，而从收集上来的用户反馈来说，图片加载问题其实反馈还是挺频繁的。再加上我们大部分的组件都需要通过图片的方式为用户提供更加丰富的表达，因此，对于图片类资源的优化也是很有必要的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e7cfedf421cf4510e659b49a7f8368f2.jpg&quot; alt=&quot;图片类资源.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;图片类资源也属于静态资源，因此同样可以使用上面文档类资源使用的一些优化方案，如：CDN 加速、缓存策略、图片压缩等。除此之外，我们还需要针对图片资源进行更细粒度的优化。&lt;/p&gt; 
&lt;p&gt;通常我们在开发时，为了确保图片在高清屏不会模糊，我们下载下来的图片一般都是多倍图（搭建器这边通常用的是 3 倍），但如果在一些非高清屏护着是屏幕分辨率较低的设备上，下载多倍图无疑是画蛇添足的，不仅没能达到更好的展示效果，还可能出现锯齿，同时使得资源下载时间变得更长，推迟了用户看到图片的时间。&lt;/p&gt; 
&lt;p&gt;我们期望的效果是：在浏览器请求图片资源时，需要根据当前设备的分辨率、DPI 等屏幕信息，选择最优的图片尺寸和清晰度，从而减少在低端设备图片下载的体积，提升下载速度，又能确保在高清设备当中能够展示高清图。&lt;/p&gt; 
&lt;p&gt;因此，在搭建器当中，我们封装了一个自定义的 Image 组件，当传入的图片是符合预设域名要求时，我们将会给图片链接上加上如下请求参数：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4f0a27a31e3b0afa6a757fae564d37e2.jpg&quot; alt=&quot;搭建器.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这个参数是 CDN 服务器为我们提供的将图片转换为 webp 格式的参数，当带有这个参数的图片请求到服务器后，服务器给我们返回的格式便是 webp。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//073292b793f766b13379cc27a276a716.jpg&quot; alt=&quot;CDN.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;或许有同学会说，webp 好像并不是所有设备都支持吧，那如果在不支持 webp 的设备，图片不是就展示不了了？&lt;/p&gt; 
&lt;p&gt;确实，因此我们的 Image 组件经过多轮改造以确保图片在不同设备中均能正常展示：&lt;/p&gt; 
&lt;p&gt;版本 1：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&amp;lt;picture&amp;gt;
  &amp;lt;source srcset=&quot;https://h5static.dewucdn.com/node-common/bbdb0b2c-8549-b2cf-ceb8-62b98de2c983-1125-984.jpg?x-oss-process=image/format,webp/resize,w_750&quot; type=&quot;image/webp&quot; /&amp;gt;
  &amp;lt;img src=&quot;https://h5static.dewucdn.com/node-common/bbdb0b2c-8549-b2cf-ceb8-62b98de2c983-1125-984.jpg&quot; alt=&quot;&quot; /&amp;gt;
&amp;lt;/picture&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我们使用 picture 去加载图片，如果支持 webp 的设备，就使用 webp，不支持的话，就还是用兜底的原图。但这个方案在 IOS 设备上会同时加载 webp 和原图，造成不必要的流量损耗和占用浏览器并行下载数，后来被废弃。&lt;/p&gt; 
&lt;p&gt;版本 2：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;try {
  window._promiseimgWebpError = new Promise(function(resolve,reject){
      var img = new Image();
      img.src = &#39;data:image/webp;base64,UklGRkwAAABXRUJQVlA4WAoAAAAQAAAAAAAAAAAAQUxQSAIAAAAAL1ZQOCAkAAAAUAEAnQEqAQABAAFAJiUAToAoAAD+8iJYwmknR5t5G30DAAAA&#39;; // 替换为小 webp 的 base64
      img.onerror = function() {
        resolve(&#39;小 webp 图片 error&#39;)
      };
  })
} catch (e) {
  console.error(e);
}

// ...

window._promiseimgWebpError.then(() =&amp;gt; {
  const { src, type, options } = this.props;
  this.setState({
    localStr: transformSrc(type, src, options,     , false),
  });
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在这个版本中，我们尝试在浏览器中加载一个很小的 webp 图片，如果加载失败，就说明当前设备不支持 webp 图片，我们就会使用兜底的原始图片。这种方式的检测，就不会出现在 IOS 设备同时加载两种格式图片的情况，又可以确保在支持 webp 的设备展示 webp ，不支持的设备展示兜底图。&lt;/p&gt; 
&lt;h2&gt;接口请求效率优化&lt;/h2&gt; 
&lt;p&gt;静态资源优化后，会场页面的整体体验已经得到了极大的提升了，绝大部分情况下用户访问页面时，能够以最快的速度获取到 html 文档和图片资源。&lt;/p&gt; 
&lt;p&gt;但是，还是有一些情况会导致首屏页面加载体验下滑，经过分析，这些体验下滑的会场有以下特点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;抖动频繁：页面存在众多组件交付接口的请求，这些请求响应的时间不一，在接口尚未返回时，有些组件处于骨架状态，返回后又隐藏了，如果多个组件都存在这种情况，就会导致页面频繁抖动&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2ef84e7cf76f9bd07997adace1794afe.jpg&quot; alt=&quot;抖动频繁.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;接口请求滞后：由于我们访问一个会场时需要等待文档下载、html 解析、main.js 执行、组件交付接口等流程，等待组件交付接口返回后，才能真正展示核心信息，这个延迟将近 2s 左右。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;上述两个问题都出现在「组件交付接口」上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;组件交付接口请求次数过多（通常与组件的数量是正相关的）&lt;/li&gt; 
 &lt;li&gt;组件交付接口请求时间滞后&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，要解决这两个问题，搭建器这边提出了：「接口聚合」、「接口前置」的概念。&lt;/p&gt; 
&lt;h3&gt;接口聚合&lt;/h3&gt; 
&lt;p&gt;接口聚合主要是为了解决一个页面中存在多个依赖组件交付接口的组件时，需要发起多次组件交付接口造成的抖动以及网络资源的浪费问题。核心的实现思路就是：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b1c0ec544a8aa865c4cad3981ae8db6a.jpg&quot; alt=&quot;接口聚合.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;接口前置&lt;/h3&gt; 
&lt;p&gt;就如上文所说，浏览器请求组件交付接口需要等待：文档下载、html 解析、main.js 执行、组件交付接口等流程，出现了较长时间的滞后，如果我们可以把这个请求交付接口的阶段提前，放到文档下载之后，无疑是可以让用户能够更快的看到核心内容的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a2b05ceb3e9ec0c033aa86112b358dd8.jpg&quot; alt=&quot;接口前置.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;接口预请求&lt;/h3&gt; 
&lt;p&gt;上面两个接口优化，都是在 h5 层面上的优化，始终还是得经历「webview 启动 -&amp;gt; 下载 html」这样的一个过程，如果 html 体积偏大，那么这期间也是会产生一定的耗时的。为了在一些特定场景能够跨越这一个看似无法逾越的天堑。h5 团队联合 native 团队一起，设计了一套 「接口预请求」机制，期望将首屏数据请求进一步的提前，在 native 打开 webview 的同时就并行地发起请求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ece2a128c486c09ddd3b9ff74badf735.jpg&quot; alt=&quot;接口预请求.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有了这样的预请求机制，我们首屏页面所依赖的接口数据返回的时间又可以缩短很多，让我们这些页面的首屏渲染体验达到最佳。&lt;/p&gt; 
&lt;p&gt;上图中提到了一个&quot;竞速&quot;机制，即哪个返回比较快就用哪个，但后续数据验证客户端请求在 99% 的情况下是快于 h5 的请求的，并且接口竞速在会场会有去重问题，因此目前最新的方案是使用的是等待超时走 h5 请求的兜底逻辑。&lt;/p&gt; 
&lt;h2&gt;页面体验优化&lt;/h2&gt; 
&lt;p&gt;上面我们分别从资源和接口层面尝试优化了从用户请求到实际展示内容的链路，让用户能够尽早的看到核心内容。接下来我们再来看一下当页面到达了浏览器进行 CSR（客户端渲染）后的用户体验优化。&lt;/p&gt; 
&lt;h3&gt;SSR 占位&lt;/h3&gt; 
&lt;p&gt;对于一些跟用户无关，所有用户都展示一样的组件，我们在进行 SSG 生成 html 文件时，实际已经获得了这些组件的核心数据了，那么此时用户一打开网页，看到的实际上就是我们之前已经获取好的这些数据展现的组件样式。这样一来，用户一进入页面，白屏的时间几乎可以忽略，差不多一进来就可以看到一些内容。只需要等 CSR 的时候接口返回的数据去更新一下一些差异即可，对用户来说前后的变化比较小，从感官上就像是一打开就看到了实际内容一样。&lt;/p&gt; 
&lt;h3&gt;骨架屏填充&lt;/h3&gt; 
&lt;p&gt;如果某些组件的展示严重依赖于用户身份的，像上面所说的， CDN 中无法识别用户身份，此时我们只能展示一个通用的骨架，至少让用户知道有这么一个模块，并且防止 CSR 后展示了这个模块后出现较严重的页面抖动。等待 CSR 接口返回之后，我们再去替换这个骨架完成渲染。&lt;/p&gt; 
&lt;h3&gt;组件展示动画&lt;/h3&gt; 
&lt;p&gt;上面说的 SSR 占位和骨架屏填充还有一个比较严重的体验问题需要解决：&lt;/p&gt; 
&lt;p&gt;由于在得物 App 中，很多组件都会设置 AB 实验或者是某些组件只是针对特定人群展示，如：新客。而在 CDN 中拿到的缓存页面，实际上是区分不了人群和用户身份的，就会导致在 CDN 缓存中的页面，不知道究竟是否应该展示这个组件，如果展示了，到了客户端发现当前用户不应该展示，就会像上述视频一样出现刚开始有个模块，CSR 之后消失的情况。如果不展示，到了客户端返现当前用户应该展示时，又会导致凭空多出一个组件把下面的组件直接往下挤的抖动情况。&lt;/p&gt; 
&lt;p&gt;针对这种情况，我们针对这种根据用户信息判断是否要展示的组件，在服务端渲染时，都将组件的高度默认设置为 0，等到了客户端渲染时，如果发现当前组件需要展示，那么再将这个组件的高度设置为 auto ，而为了让高度变化时不会突然变化，让用户看起来特别奇怪，我们为这个组件的高度变化设置了渐变过渡，让其逐步展开。就这样，一个原本看起来是极为生硬，体验拉胯的页面，经过改造之后，就变成了好像是精心设计好的动画一样，毫无违和感。&lt;/p&gt; 
&lt;h3&gt;流式渲染&lt;/h3&gt; 
&lt;p&gt;经过上面几轮的优化之后，我们会场页面的用户体验可以说又上了一个台阶。当然，我们进行上述优化的过程中，也产生了一些副作用。我们先来看几张图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c665ada632d495aa0b8a3bd7497ae993.jpg&quot; alt=&quot;流式渲染.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;CSR 渲染流程&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ce5e1a5034a29eb1a60cba99570765cb.jpeg&quot; alt=&quot;mm.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;em&gt;SSR 渲染流程&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;我们可以看到，从我们将 CSR 渲染首屏换成 SSR 渲染首屏后，TTFB 变得比以前更长了，即在用户访问页面到页面文档返回的时间变长了。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;TTFB TTFB 测量的是从用户或客户端发出 HTTP 请求到客户端的浏览器接收到页面的第一个字节的持续时间，由发送 HTTP 请求所花费的时间以及获取页面的第一个字节所花费的时间组成。TTFB 用于衡量 Web 服务器或其他网络资源的响应能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;原因是因为我们在 SSR 渲染阶段，需要获取页面全量组件的数据并将其渲染成 HTML，而每个组件的数据获取都需要一定的耗时，从而导致我们最终获取到 HTML 的时间拉长。当然，我们上面说的 SSG + CDN 的方案可以很大程度上缓解用户可感知的等待时间，但每次 CDN 回源时依然还是需要走 SSR 的流程，TTFB 的变长终归对用户体验有一些影响。&lt;/p&gt; 
&lt;p&gt;恰巧最近比较火的「流式渲染」就能够解决上述痛点，因此，团队也尝试在流式渲染的方向上摸索前进，预计达到的效果：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//76a1dd2c4250f5745fd8af2948ca7d0e.jpg&quot; alt=&quot;TTFB.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;接入流式渲染的页面，TTFB 将会得到很大的降低，用户能够感知的白屏时间也被最大限度的缩短，并且可以利用浏览器空闲时间，高效且并行的进行多组件异步加载，哪个组件先加载好久展示哪个，没有加载好之前，依然可以展示骨架屏兜底展示，防止页面抖动。&lt;/p&gt; 
&lt;h2&gt;组件异常处理&lt;/h2&gt; 
&lt;p&gt;目前搭建器组件有 100 多个，涉及到的业务领域包括但不限于营销、交易、增长等多个业务域的 20 余组件开发者，每个双周迭代都会有大量的组件业务迭代需求。面对这如此密集的业务迭代以及涉及众多业务域的影响范围，倘若组件没有进行较为完善的容错机制，其中的某一个组件因为某个版本的改动而出现异常，就极有可能导致该页面的其他组件也受到影响，最严重的可能导致整个页面白屏。&lt;/p&gt; 
&lt;p&gt;本着「敬畏线上，谨慎编码」的原则，需要一个比较完善的组件容错机制和告警机制，一来确保即使某个组件出现严重 Bug 时不影响页面其他组件的正常工作，二来我们可以第一时间感知组件出现的异常，及时排查，修复止损。&lt;/p&gt; 
&lt;h3&gt;组件异常隐藏机制&lt;/h3&gt; 
&lt;p&gt;在搭建器的组件渲染时，为每一个组件的渲染单独包裹了一个错误边界组件，这个组件将会捕获当前组件的异常和错误，防止该错误继续往上冒泡影响到页面其他组件。这样就可以将当前组件的错误影响范围始终都限制在组件范围内，而不会扩大影响其他组件。&lt;/p&gt; 
&lt;p&gt;而当我们捕获到异常时，我们会直接隐藏这个组件，这样就可以避免因出现异常而导致组件渲染混乱而影响用户的使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3b75ebf6d3b186790be57fba56e3c5e8.jpg&quot; alt=&quot;组件异常隐藏机制.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;组件异常上报机制&lt;/h3&gt; 
&lt;p&gt;在上面捕获到异常之后，我们会将捕获到的组件异常上报到监控平台并告警，这样，一旦正式环境有某些组件因业务迭代改动导致异常时我们可以第一时间感知，并及时处理。&lt;/p&gt; 
&lt;h1&gt;四、体验劣化管控&lt;/h1&gt; 
&lt;p&gt;至此对于搭建器的用户体验优化已经告一段落了。但我们还需要想办法对后续的业务迭代的体验劣化进行管控。就算你这一次体验做得再好，经过几轮业务迭代之后，可能体验又大幅下滑了。&lt;/p&gt; 
&lt;p&gt;因此，我们期待通过一些手段来防止前端页面的体验劣化。&lt;/p&gt; 
&lt;p&gt;得益于现成的体验卡口平台：体验卡口平台&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//55382d588b6c36822f00d84b68708cab.jpg&quot; alt=&quot;体验卡口.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们只需要基于这个平台进行一定的改造和功能新增，就可以对我们关注的体验指标进行细粒度检测，如：接口前置、图片转 webp、接口响应时间等等。后续我们还会不断的丰富检测能力，支持流式检测、ssr 检测等等，尽可能通过这个平台的检测与管控，防止前端页面体验下滑。后续也可能做成强卡形式，如果高优体验问题不解决，禁止上线，以此保障前端页面的交付质量。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5fcf631d99238f6def471ec67523e5c0.jpg&quot; alt=&quot;交付质量.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;五、优化成果验收&lt;/h1&gt; 
&lt;p&gt;经历了上面这些体验后，是否真的达到了我们的预期呢？我们是不是身处于自身描绘的理想环境当中，而真正的用户体验不增反降呢？这一切的一切，都需要用实际的数据说话。&lt;/p&gt; 
&lt;h2&gt;秒开率&lt;/h2&gt; 
&lt;p&gt;首先，从我们的核心体验指标&quot;秒开率&quot;看一下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5f40a55b5f231430abd8b15ffae033b9.jpg&quot; alt=&quot;秒开率.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 从对秒开数据的统计来看，虽然每次版本迭代都有不同程度的上下波动，但整体趋势上还是稳步提升的，由此也可以看出，我们在用户体验上的优化，至少在秒开率上是得到了正向的反馈。&lt;/p&gt; 
&lt;h2&gt;抖动率&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0d8f58b7a68ff7a652ae2d980b1a20d2.jpg&quot; alt=&quot;抖动率.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 从抖动率的指标来看，进行优化后项目的稳定率整体长期保持在 99.5% 左右，由此可看出对于页面抖动相关的优化以及在开发时有意识地避免一些可能出现抖动的技术方案还是颇有成效的。&lt;/p&gt; 
&lt;h2&gt;用户反馈&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//83caf3609c32438cc3c611cb8143a75c.jpg&quot; alt=&quot;用户反馈.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 而收集上来的用户体验报告来说，正向反馈还是占了绝大多数的。由此可见，我们的优化成果，不仅仅是我们单方面的臆想，而是实实在在能让用户感受出来的体验提升。当然，其中仍有一小部分问题反馈，我们也会持续跟进，在业务迭代之余，逐步优化体验，力求为用户提供最佳的使用体验。&lt;/p&gt; 
&lt;h1&gt;六、结语&lt;/h1&gt; 
&lt;p&gt;至此就算梳理完了当前搭建器及其关联项目在用户体验优化上的一些实践了。这些实践大部分都是我加入团队之前，团队的其他同学就已经完成的。当然，我也参与了其中一部分功能的开发与优化。&lt;/p&gt; 
&lt;p&gt;总的来说，团队对于用户体验的优化是孜孜不倦的，力求给用户最好的体验，促使用户能够顺利在平台上&quot;得到好物&quot;。&lt;/p&gt; 
&lt;p&gt;文 / 星河&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周、更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/16884662</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/16884662</guid>
            <pubDate>Mon, 30 Dec 2024 09:18:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>OpenAI 未能在 2025 年之前提供其承诺的 opt-out 工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;早在 5 月份，OpenAI 就表示正在开发一款工具，让创作者可以指定他们希望自己的作品如何纳入或排除在其 AI 训练数据中。但 7 个月过去了，这项功能仍未面世。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 当时表示，该工具名为「Media Manager」，可以「识别受版权保护的文本、图像、音频和视频」，以反映创作者「跨多个来源」的偏好。该旨在帮助该公司规避一些抨击，并避免 OpenAI 免受与知识产权相关的法律挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但知情人士告诉 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F01%2F01%2Fopenai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch&lt;/a&gt;，该工具在内部很少被视为 important launch。一位前 OpenAI 员工表示，「我不认为这是一个优先事项。说实话，我不记得有人在开发它」。一位与该公司协调工作的非雇员也告诉 TechCrunch，他们过去曾与 OpenAI 讨论过这款工具，但最近没有任何进展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;而 OpenAI 法律团队中一位曾担任媒体经理的 Fred von Lohmann 则于 10 月转任兼职顾问。OpenAI 公关部通过电子邮件向 TechCrunch 证实了 Von Lohmann 的调动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，OpenAI 尚未公布 Media Manager 的进展情况，该公司公司也错过了自我设定的「2025 年之前」推出该工具的最后期限。（需要明确的是，「by 2025」可以理解为包括 2025 年，但 TechCrunch 将 OpenAI 的措辞解读为到 2025 年 1 月 1 日。）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4a108e4f582c99d0d1ba3f125401690907e.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;事实上，OpenAI 为创作者提供了几种「opt out」其 AI 训练的临时方式。去年 9 月，该公司推出了一个提交表单，允许艺术家标记自己的作品，以便从未来的训练集中删除。而且 OpenAI 长期以来一直允许网站管理员阻止其网络爬虫程序在其域中抓取数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但创作者批评这些方法杂乱无章，不够充分。对于书面作品、视频或录音，没有具体的退出机制。而对于图像的退出表格则要求提交每张要删除的图像的副本以及说明，过程相当繁琐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Media Manager 则被宣传为 OpenAI 退出解决方案的彻底改进和扩展。OpenAI 在 5 月份的公告中表示，Media Manager 将使用「尖端机器学习研究」，使创作者和内容所有者能够「tell [OpenAI] what they own」。OpenAI 声称在开发该工具时正在与监管机构合作，并表示希望 Media Manager 能够「为整个 AI 行业树立标准」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但从那以后，OpenAI 再也没有公开提及过 Media Manager。一位发言人告诉 TechCrunch，截至 8 月份该工具「仍在开发中」，但没有回应 12 月中旬的后续评论请求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;OpenAI 尚未透露 Media Manager 何时推出，甚至没有透露其将具备哪些功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;假设 Media Manager 确实将在某个时候出现，但专家们并不相信它能减轻创作者的担忧，或者在解决围绕 AI 和知识产权使用的法律问题方面发挥很大作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Stubbs Alderton &amp;amp; Markiles 的知识产权律师 Adrian Cyhan 指出，Media Manager 是一项雄心勃勃的事业。即使是像 YouTube 和 TikTok 这样的大型平台也难以，大规模实现内容识别。OpenAI 真的能做得更好吗？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「确保遵守法律要求的创作者保护和潜在的补偿要求带来了挑战，尤其是考虑到国家和地方司法管辖区内法律环境的快速发展和潜在差异。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;非营利组织 Fairly Trained 的创始人 Ed Newton-Rex 则认为，Media Manager 会不公平地将控制 AI 训练的负担转嫁给创作者；如果不使用这项技术，创作者可能会默许他们的作品被使用。「大多数创作者甚至都不会听说过它，更不用说使用它了。但它仍然会被用来保护创作作品免受创作者意愿的大规模利用。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;MBHB 人工智能实践小组联合主席 Mike Borella 指出，opt-out 系统并不总是考虑到对作品可能进行的转换，例如对图像进行 downsampled。Pryor Cashman 的知识产权和媒体律师 Joshua Weigensberg 补充说，它们也可能无法解决第三方平台托管创作者内容副本这一常见情况。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「创作者和版权所有者无法控制，甚至通常不知道他们的作品在互联网上出现在哪里。即使创作者告诉每一个 AI 平台他们选择退出训练，这些公司仍可能会继续使用第三方网站和服务上提供的作品副本进行训练。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;至少从法理学的角度来看，Media Manager 对 OpenAI 来说可能并不是特别有利。Dorsey &amp;amp; Whitney 专门从事版权法的合伙人 Evan Everist 表示，虽然 OpenAI 可以使用该工具向法官证明其正在减轻对受知识产权保护的内容的训练，但如果发现公司侵权，Media Manager 可能不会保护该公司免受损害。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「版权所有者没有义务在侵权行为发生之前预先告知他人不要侵犯其作品。版权法的基本原则仍然适用——即未经许可不得盗用和复制他人的作品。此功能可能更多地与公关有关，并将 OpenAI 定位为内容的道德用户。」&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;更多独家技术见解与热门话题讨论，尽在&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;【开源中国 APP】&lt;/a&gt;，与数百万开发者一起，随时随地探索技术无限可能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327671/openai-failed-deliver-opt-out-tool-by-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327671/openai-failed-deliver-opt-out-tool-by-2025</guid>
            <pubDate>Mon, 30 Dec 2024 08:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>smart-chatRoom —— 分布式简易聊天系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;基于 Redis/RocketMQ + SpringBoot + Vue +Websocket 实现分布式、跨服务器节点共享的分布式简易聊天系统，通过该核心实例实现了跨服务器节点无法共享 WebSocket 会话 Session，无法跨节点查询用户会话信息的痛点； 借助 Redis 实现了跨通道 WebSocket 通信，按通道进行会话交流的亮点; 借助 RocketMQ 实现高并发场景下的会话消费堆积、会话丢失问题。&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;color:#252b3a; margin-left:0; margin-right:0; text-align:start&quot;&gt;主要亮点如下：&lt;/p&gt;

&lt;ul style=&quot;margin-left:0; margin-right:11px&quot;&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道的订阅发送，按通道实现 Session 共享&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道的消息会话隔离，保证消息交流的安全性&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道消息监控、消息存储，实现离线消息的暂存&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息发布、订阅，按消息主题区分消息会话&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息分类处理，实现按标签共享 Session、消费 Session&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息离线发送，用户上线按照上次消费位点接收离线消息&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息监听，处理重复消息，实现消息发布的高效率&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持单聊、群聊、广播、按指定通道交流&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/smart-chatroom</link>
            <guid isPermaLink="false">https://www.oschina.net/p/smart-chatroom</guid>
            <pubDate>Mon, 30 Dec 2024 06:01:00 GMT</pubDate>
        </item>
        <item>
            <title>百度 25 周年李彦宏发全员信：AI 应用将在 2025 年井喷</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 1 月 1 日是百度成立 25 周年，百度创始人李彦宏晚间发出全员信表示，「25 年来，我们始终走在技术的最前沿，始终相信技术创新才是百度的核心竞争力。」&lt;/p&gt; 
&lt;p&gt;李彦宏在信中表明了对 2025 年的期待，「虽然超级应用尚未出现，但 AI 的实际渗透率已经不低，并且将在 2025 年继续井喷式增长。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附全员信原文：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;各位百度同学，今天是百度成立 25 周年的日子。25 年前的今天，七个怀揣着技术改变世界的梦想的年轻人在中关村北大资源宾馆的两间小屋子里开始了一段创业旅程。中国互联网的历史从此发生了改变。今天，超过一半的中国人每月都要使用百度获取信息，找到所求，「百度」这两个原本毫无意义的汉字成了一个家喻户晓的名字。&lt;/p&gt; 
 &lt;p&gt;25 年来，我们不忘初心，风雨兼程，先后经历了 PC 互联网时代，移动互联网时代，现在已经基本进入了人工智能时代。我们从简单的网页搜索功能开始，逐步发展出了贴吧、知道、百科、地图、文库、网盘等明星产品，我们依托强大的用户基础，历时十余年的时间，逐步打造出了人工智能时代从芯片、框架到模型、应用等四层全栈技术，为中国互联网和世界 AI 领域培养了一批又一批的科学技术人员、开发者和创业者。&lt;/p&gt; 
 &lt;p&gt;25 年来，我们始终走在技术的最前沿，始终相信技术创新才是百度的核心竞争力，我们多年来一直把超过收入 20% 的资金投入到研发上，并且不遗余力地尝试把最前沿的技术产品化，让更多的人从中受益，因为我们相信只有规模化的应用才能让技术发挥它的价值，甚至近年来在人工智能方面的实践表明，重大的技术突破，颠覆式的创新往往是规模化应用的结果，而不是原因。没有万卡集群就不会有大模型的智能涌现，就不会有这次生成式 AI 的浪潮；没有数以亿计的运营公里数，无人驾驶就不可能比有人驾驶安全十倍；没有大量的 AI 原生应用的推动，国产 AI 芯片就不可能真正成熟！&lt;/p&gt; 
 &lt;p&gt;当然，走在技术的最前沿也意味着我们要冒更大的风险，要承受高于同行的失败概率，要耐得住寂寞，要忍受别人的不理解甚至白眼，要不断试错，要知道哪一天方向走错了需要迅速调整方向，重新出发，甚至要对自己的能力边界有清醒的认知，并且不断总结经验教训，以利再战！&lt;/p&gt; 
 &lt;p&gt;刚刚过去的 2024 年也是过去 25 年的一个缩影，充满了机遇和挑战，时而令人兴奋，时而令人沮丧，有些工作一直到最后一天才知道成或不成。如同过去一样，这一年我们坚定地在 AI 技术上探索创新，我们在全球首创了基于图片的检索增强技术 iRAG，大大降低了图片生成的幻觉问题；我们致力于让不会写程序的素人具备程序员的能力，为此我们发布了秒哒，这与全球主流的代码辅助生成形成鲜明的对比；我们也在大模型应用领域独树一帜，为 4000 万文库的付费用户提供无与伦比的内容创作和思想碰撞能力！&lt;/p&gt; 
 &lt;p&gt;对于 2025 年，我们充满期待。我们意识到今天的人工智能领域，竞争比任何时候都更加激烈，技术迭代的速度比以往任何时候都更快，我们面临的挑战也是前所未有的。但是我们坚信，大模型赋能的 AI 原生应用正在各行各业各种场景迅速普及，虽然超级应用尚未出现，AI 的实际渗透率已经不低，并且将在 2025 年继续井喷式增长。我们也期待，我们在 2023、2024 种下的种子能够在 2025 生根发芽，开花结果，并且不断获得市场的验证和认可。&lt;/p&gt; 
 &lt;p&gt;感谢每一位同学一直以来对百度使命的忠诚陪伴，全情投入，愿百度在未来的日子里，继续乘风破浪，勇往直前，创造更加辉煌的明天！&lt;/p&gt; 
 &lt;p&gt;Robin&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;&lt;span&gt;更多独家技术见解与热门话题讨论，尽在&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;【开源中国 APP】&lt;/a&gt;，与数百万开发者一起，随时随地探索技术无限可能。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327634</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327634</guid>
            <pubDate>Mon, 30 Dec 2024 05:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>欢迎 PaliGemma 2 – 来自 Google 的新视觉语言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;我们很高兴迎来 Google 全新的视觉语言模型 &lt;strong&gt;PaliGemma 2&lt;/strong&gt;，这是 PaliGemma 的一个新版本。与其前代产品一样，PaliGemma 2 使用强大的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fsiglip-659d5e62f0ae1a57ae0e83ba&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;SigLIP&lt;/strong&gt;&lt;/a&gt; 进行视觉处理，但在文本解码部分升级到了最新的 &lt;strong&gt;Gemma 2&lt;/strong&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;模型规模和输入分辨率&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;PaliGemma 2 提供了新的预训练模型，参数规模包括 &lt;strong&gt;3B&lt;/strong&gt; 、 &lt;strong&gt;10B&lt;/strong&gt; 和 &lt;strong&gt;28B&lt;/strong&gt;。所有模型均支持以下多种输入分辨率:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;224x224&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;448x448&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;896x896&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种多样化的组合为不同的使用场景提供了极大的灵活性，使实践者能够根据质量和效率需求之间的平衡进行选择。与之相比，上一代 PaliGemma 仅提供 &lt;strong&gt;3B&lt;/strong&gt; 版本。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;预训练和微调能力&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;这些预训练模型被设计为更容易适配下游任务。首个 PaliGemma 模型因其广泛适配性被社区用于多种任务。本次迭代引入了更高质量的预训练模型和更多选择，进一步增强了灵活性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;DOCQI 数据集示例&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;Google 此次发布了一些基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fgoogle%2Fdocci&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;DOCCI&lt;/strong&gt;&lt;/a&gt; 数据集的微调模型，展现了长篇、细致和富有表现力的图像描述能力。这些微调模型提供 &lt;strong&gt;3B&lt;/strong&gt; 和 &lt;strong&gt;10B&lt;/strong&gt; 两个版本，支持输入分辨率 &lt;strong&gt;448x448&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此次发布包含了所有开放的模型仓库、Transformers 框架的集成、微调脚本，以及我们基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FHuggingFaceM4%2FVQAv2&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;VQAv2 数据集&lt;/strong&gt;&lt;/a&gt; 微调的视觉问答模型演示。这些资源为用户提供了全面的工具支持，助力探索和开发更多创新应用。&lt;/p&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;资源链接&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;本次发布包括开源模型库、transformers 集成、微调脚本以及视觉问答演示。以下是相关资源链接:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fpaligemma-2-release-67500e1e1dbfdd4dee27ba48&quot; target=&quot;_blank&quot;&gt;发布合集&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;微调模型演示 Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;PaliGemma 2 介绍&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;PaliGemma 2 是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fpaligemma&quot; target=&quot;_blank&quot;&gt;PaliGemma 视觉语言模型&lt;/a&gt; 的一个新迭代，由 Google 于五月发布。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 将强大的 SigLIP 图像编码器与 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fgemma2&quot; target=&quot;_blank&quot;&gt;Gemma 2&lt;/a&gt; 语言模型连接起来。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;PaliGemma2 Architecture&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054322.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;PaliGemma2 Architecture&lt;/p&gt; 
&lt;p&gt;新的模型基于 &lt;strong&gt;Gemma 2&lt;/strong&gt; 的 &lt;strong&gt;2B&lt;/strong&gt; 、&lt;strong&gt;9B&lt;/strong&gt; 和 &lt;strong&gt;27B&lt;/strong&gt; 语言模型，分别对应 &lt;strong&gt;3B&lt;/strong&gt; 、&lt;strong&gt;10B&lt;/strong&gt; 和 &lt;strong&gt;28B&lt;/strong&gt; 的 PaliGemma 2 变体。这些模型的名称考虑了紧凑图像编码器的附加参数。正如上文所述，这些模型支持三种不同的分辨率，为下游任务的微调提供了很大的灵活性。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 根据 &lt;strong&gt;Gemma 许可证&lt;/strong&gt; 分发，该许可证允许重新分发、商业使用、微调以及创建模型衍生品。&lt;/p&gt; 
&lt;p&gt;此版本包含以下基于 &lt;strong&gt;bfloat16&lt;/strong&gt; 精度的检查点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;9 个预训练模型&lt;/strong&gt;: 3B、10B 和 28B，分辨率支持&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;224x224&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;448x448&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;896x896&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;2 个在 DOCCI 数据集上的微调模型&lt;/strong&gt;: 基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fgoogle%2Fdocci&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;DOCCI&lt;/strong&gt;&lt;/a&gt; 数据集 (图像-文本配对)，支持 &lt;strong&gt;3B&lt;/strong&gt; 和 &lt;strong&gt;10B&lt;/strong&gt; 的 PaliGemma 2 变体，输入分辨率为 &lt;strong&gt;448x448&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;模型能力&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;如同之前的 PaliGemma 发布一样，预训练 (pt) 模型在下游任务的微调中表现出色。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;预训练数据集&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;pt 模型在以下数据混合集上进行了预训练。这些多样化的预训练数据集使模型能够在相似领域的下游任务中使用更少的示例进行微调。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WebLI&lt;/strong&gt;: 一个基于公共网络构建的大规模多语言图像 - 文本数据集。WebLI 数据集的多样化分割使模型具备了多方面的能力，如视觉语义理解、物体定位、视觉文本理解和多语言能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CC3M-35L&lt;/strong&gt;: 从网页上精心挑选的英语图像 - 替代文本数据集 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faclanthology.org%2FP18-1238%2F&quot; target=&quot;_blank&quot;&gt;Sharma et al., 2018&lt;/a&gt;)。数据集的标签通过 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Ftranslate&quot; target=&quot;_blank&quot;&gt;Google Cloud Translation API&lt;/a&gt; 翻译成了 34 种额外的语言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visual Question Generation with Question Answering Validation (VQ2A)&lt;/strong&gt;: 一个改进的问题回答数据集。该数据集也被翻译成了相同的 34 种语言，使用了 Google Cloud Translation API。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenImages&lt;/strong&gt;: 检测和物体感知的问答数据集 (Piergiovanni et al., 2022)，通过手动规则生成，基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.googleapis.com%2Fopenimages%2Fweb%2Ffactsfigures_v7.html&quot; target=&quot;_blank&quot;&gt;OpenImages 数据集&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WIT&lt;/strong&gt;: 从 Wikipedia 收集的图像和文本数据集 (Srinivasan et al., 2021)。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;微调模型与基准测试&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;PaliGemma 2 团队在多种视觉语言理解任务上对 PT 模型进行了内部微调，并提供了这些微调模型的基准测试结果。详细信息可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fgoogle%2Fpaligemma2-28b-pt-896%23paligemma-2-results-by-model-resolution-and-size&quot; target=&quot;_blank&quot;&gt;模型卡&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt; 中找到。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 基于 &lt;strong&gt;DOCQI 数据集&lt;/strong&gt; 微调，可以实现多种图像描述任务，包括文本渲染、捕捉空间关系以及包含世界知识的描述。&lt;/p&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;性能比较&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;以下表格展示了 DOCQI 微调模型与其他模型的性能对比 (数据来自 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt; 中的 Table 6):&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;参数量&lt;/th&gt; 
   &lt;th&gt;字符数 (#char)&lt;/th&gt; 
   &lt;th&gt;句子数 (#sent)&lt;/th&gt; 
   &lt;th&gt;NES ↓&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniGPT-4&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;484&lt;/td&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;52.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mPLUG-Owl2&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;459&lt;/td&gt; 
   &lt;td&gt;4.4&lt;/td&gt; 
   &lt;td&gt;48.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;InstructBLIP&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;510&lt;/td&gt; 
   &lt;td&gt;4.0&lt;/td&gt; 
   &lt;td&gt;42.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLAVA-1.5&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;395&lt;/td&gt; 
   &lt;td&gt;4.2&lt;/td&gt; 
   &lt;td&gt;40.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VILA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;871&lt;/td&gt; 
   &lt;td&gt;8.6&lt;/td&gt; 
   &lt;td&gt;28.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PaliGemma&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;535&lt;/td&gt; 
   &lt;td&gt;8.9&lt;/td&gt; 
   &lt;td&gt;34.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PaLI-5B&lt;/td&gt; 
   &lt;td&gt;5B&lt;/td&gt; 
   &lt;td&gt;1065&lt;/td&gt; 
   &lt;td&gt;11.3&lt;/td&gt; 
   &lt;td&gt;32.9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PaliGemma 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;529&lt;/td&gt; 
   &lt;td&gt;7.7&lt;/td&gt; 
   &lt;td&gt;28.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PaliGemma 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10B&lt;/td&gt; 
   &lt;td&gt;521&lt;/td&gt; 
   &lt;td&gt;7.5&lt;/td&gt; 
   &lt;td&gt;20.3&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;指标说明:&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;#char&lt;/strong&gt;: 生成的描述中平均字符数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;#sent&lt;/strong&gt;: 平均句子数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NES&lt;/strong&gt;: 非蕴含句子数 (数值越低越好)，用于衡量事实不准确性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您可以在下面找到 DOCQI 检查点的部分模型输出，展示模型的多样性和灵活性。&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Input Image&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Caption&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 1&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054547.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;折线图展示了 ImageNet 模型在微调后的 Top-1 准确率表现。图中有四条不同颜色的线条: 蓝色、橙色、绿色和黑色。&lt;strong&gt;蓝色线条是四条线中最低的一条&lt;/strong&gt; ，它代表了表现最差的模型结果。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 2&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054606.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一张白纸的特写镜头，上面用黑色的文字打印着内容。纸张中间稍微弯曲，文字使用打字机字体呈现。纸张顶部写着 &quot;&lt;strong&gt;Ashley Hotel West Coast&lt;/strong&gt;&quot;，其下是 &quot;&lt;strong&gt;WiFi Internet Service&lt;/strong&gt;&quot;。再下面是 &quot;&lt;strong&gt;Username: fqpp&lt;/strong&gt;&quot;，最后是 &quot;&lt;strong&gt;Password: aaeu&lt;/strong&gt;&quot;。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 3&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055484.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一幅描绘大衞·鲍伊「Ziggy Stardust」造型的壁画被画在一面白墙上。壁画展示了三张并排的面孔，每张都有红色的头发，眼睛上画着蓝色的闪电图案。面孔的妆容包括蓝色眼影、粉红色腮红和红色嘴唇。中间的面孔上方有一个黑色的方形窗口，窗口内用白色文字写着 &quot;&lt;strong&gt;JAM&lt;/strong&gt;&quot;，字体为蓝色。画面的一侧停着一辆银色汽车。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 4&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055346.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;从上方俯瞰一张白色大理石台面，枱面上放着四个咖啡杯。左边有两个灰色的杯子，左下角有一个白色的杯子，右侧则是另一个灰色的杯子。右上角放着一个带木质底座的金属水果篮，里面装满了橙子。左边还有一个装有水的透明玻璃水壶，画面中仅显示了部分内容。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 5&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055610.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一张白色书本的特写，上半部分是白色区域，底部有一条蓝色条纹。白色部分印有黑色文字，内容为: &quot;&lt;strong&gt;Visual Concept Learning from User-tagged Web Video&lt;/strong&gt;&quot; 。黑色文字下方有一个白色框，框内包含五张小图片。最左边的图片是一名站在草地中的人，右侧紧接的是一张蓝色海洋的图片。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;演示&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;为了演示效果，Hugging Face 团队对 &lt;strong&gt;PaliGemma 2 3B&lt;/strong&gt; 模型进行了微调，输入分辨率为 448x448，数据集使用的是 &lt;strong&gt;VQAv2&lt;/strong&gt; 的一小部分。我们采用了 &lt;strong&gt;LoRA 微调&lt;/strong&gt; 和 &lt;strong&gt;PEFT&lt;/strong&gt; 方法，具体细节将在微调部分进行讲解。&lt;/p&gt; 
&lt;p&gt;下面的演示展示了最终结果。您可以自由查看 Space 中的代码了解其工作原理，或者克隆代码以适配您的自定义微调需求。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180057439.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;如何与 Transformers 一起使用&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;您可以使用 🤗 Transformers 库对 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 模型进行推理，通过 &lt;strong&gt;PaliGemmaForConditionalGeneration&lt;/strong&gt; 和 &lt;strong&gt;AutoProcessor&lt;/strong&gt; APIs 实现操作。请确保您安装的 Transformers 版本为 &lt;strong&gt;4.47 或更高&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip&amp;nbsp;install&amp;nbsp;transformers&amp;gt;=4.47
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在安装完成后，您可以按照以下示例运行推理。同样重要的是，请确保遵循用于训练模型的任务提示格式，以获得最佳效果:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt;&amp;nbsp;transformers&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;AutoProcessor,&amp;nbsp;PaliGemmaForConditionalGeneration
&lt;span&gt;from&lt;/span&gt;&amp;nbsp;PIL&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;Image
&lt;span&gt;import&lt;/span&gt;&amp;nbsp;requests

model_id&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;google/paligemma2-10b-ft-docci-448&quot;&lt;/span&gt;
model&amp;nbsp;=&amp;nbsp;PaliGemmaForConditionalGeneration.from_pretrained(model_id)
model&amp;nbsp;=&amp;nbsp;model.to(&lt;span&gt;&quot;cuda&quot;&lt;/span&gt;)
processor&amp;nbsp;=&amp;nbsp;AutoProcessor.from_pretrained(model_id)

prompt&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;&amp;lt;image&amp;gt;caption&amp;nbsp;en&quot;&lt;/span&gt;
image_file&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.png&quot;&lt;/span&gt;
raw_image&amp;nbsp;=&amp;nbsp;Image.open(requests.get(image_file,&amp;nbsp;stream=&lt;span&gt;True&lt;/span&gt;).raw).convert(&lt;span&gt;&quot;RGB&quot;&lt;/span&gt;)

inputs&amp;nbsp;=&amp;nbsp;processor(prompt,&amp;nbsp;raw_image,&amp;nbsp;return_tensors=&lt;span&gt;&quot;pt&quot;&lt;/span&gt;).to(&lt;span&gt;&quot;cuda&quot;&lt;/span&gt;)
output&amp;nbsp;=&amp;nbsp;model.generate(**inputs,&amp;nbsp;max_new_tokens=&lt;span&gt;200&lt;/span&gt;)

input_len&amp;nbsp;=&amp;nbsp;inputs[&lt;span&gt;&quot;input_ids&quot;&lt;/span&gt;].shape[&lt;span&gt;-1&lt;/span&gt;]
print(processor.decode(output[&lt;span&gt;0&lt;/span&gt;][input_len:],&amp;nbsp;skip_special_tokens=&lt;span&gt;True&lt;/span&gt;))
&lt;span&gt;#&amp;nbsp;A&amp;nbsp;medium&amp;nbsp;shot&amp;nbsp;of&amp;nbsp;two&amp;nbsp;cats&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;a&amp;nbsp;pile&amp;nbsp;of&amp;nbsp;brown&amp;nbsp;fishing&amp;nbsp;nets.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;in&amp;nbsp;the&amp;nbsp;foreground&amp;nbsp;is&amp;nbsp;a&amp;nbsp;gray&amp;nbsp;tabby&amp;nbsp;cat&amp;nbsp;with&amp;nbsp;white&amp;nbsp;on&amp;nbsp;its&amp;nbsp;chest&amp;nbsp;and&amp;nbsp;paws.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;is&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;its&amp;nbsp;side&amp;nbsp;with&amp;nbsp;its&amp;nbsp;head&amp;nbsp;facing&amp;nbsp;the&amp;nbsp;bottom&amp;nbsp;right&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;in&amp;nbsp;the&amp;nbsp;background&amp;nbsp;is&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;its&amp;nbsp;side&amp;nbsp;with&amp;nbsp;its&amp;nbsp;head&amp;nbsp;facing&amp;nbsp;the&amp;nbsp;top&amp;nbsp;left&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&amp;nbsp;The&amp;nbsp;cat&#39;s&amp;nbsp;body&amp;nbsp;is&amp;nbsp;curled&amp;nbsp;up,&amp;nbsp;its&amp;nbsp;head&amp;nbsp;is&amp;nbsp;slightly&amp;nbsp;turned&amp;nbsp;to&amp;nbsp;the&amp;nbsp;right,&amp;nbsp;and&amp;nbsp;its&amp;nbsp;front&amp;nbsp;paws&amp;nbsp;are&amp;nbsp;tucked&amp;nbsp;underneath&amp;nbsp;its&amp;nbsp;body.&amp;nbsp;There&amp;nbsp;is&amp;nbsp;a&amp;nbsp;teal&amp;nbsp;rope&amp;nbsp;hanging&amp;nbsp;from&amp;nbsp;the&amp;nbsp;fishing&amp;nbsp;net&amp;nbsp;in&amp;nbsp;the&amp;nbsp;top&amp;nbsp;right&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;您还可以使用 transformers 集成中的 &lt;strong&gt;&lt;code&gt;bitsandbytes&lt;/code&gt;&lt;/strong&gt; 来加载具有量化的模型。以下示例使用了 &lt;strong&gt;4-bit &lt;code&gt;nf4&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt;&amp;nbsp;transformers&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;BitsAndBytesConfig

bnb_config&amp;nbsp;=&amp;nbsp;BitsAndBytesConfig(
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;load_in_4bit=&lt;span&gt;True&lt;/span&gt;,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;bnb_4bit_quant_type=&lt;span&gt;&quot;nf4&quot;&lt;/span&gt;,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;bnb_4bit_compute_dtype=torch.bfloat16
)
model&amp;nbsp;=&amp;nbsp;PaligemmaForConditionalGeneration.from_pretrained(
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;model_id,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;quantization_config=bnb_config,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;device_map={&lt;span&gt;&quot;&quot;&lt;/span&gt;:&lt;span&gt;0&lt;/span&gt;}
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我们快速测试了量化对性能的影响，通过评估一个 3B 微调检查点在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Flmms-lab%2Ftextvqa&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;textvqa&lt;/strong&gt;&lt;/a&gt; 数据集上的表现，使用 224x224 输入图像。这是我们在 5,000 个验证集条目上获得的结果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;bfloat16&lt;/strong&gt;，无量化: &lt;strong&gt;60.04%&lt;/strong&gt; 准确率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;8-bit&lt;/strong&gt;: **59.78%**。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;4-bit&lt;/strong&gt;，使用上面代码片段中的配置: **58.72%**。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些结果非常鼓舞人心！当然，量化对于更大的检查点更有意义，我们建议您始终在您所使用的领域和任务上测量结果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;微调&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;如果您之前已经微调过 &lt;strong&gt;PaliGemma&lt;/strong&gt;，那么用于微调 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 的 API 是相同的，您可以直接使用现有代码。我们提供了 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2Fpaligemma.py&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt; 和一个 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;notebook&lt;/a&gt; 来帮助您微调模型，冻结模型部分参数，或应用内存高效的微调技术，如 &lt;strong&gt;LoRA&lt;/strong&gt; 或 &lt;strong&gt;QLoRA&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;我们使用 &lt;strong&gt;LoRA&lt;/strong&gt; 对 PaliGemma 2 模型在 VQAv2 验证集的一半进行了微调，以供演示。这项任务使用了 &lt;strong&gt;3 块 A100&lt;/strong&gt; 显卡 (80GB VRAM)，耗时半小时。&lt;/p&gt; 
&lt;p&gt;您可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmerve%2Fpaligemma2-3b-vqav2&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt; 找到模型，此外 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;这个 Gradio 演示&lt;/a&gt; 展示了模型的效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;新发布的 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 比之前的版本更加令人兴奋，具有不同的规模以满足各种需求，并提供更强大的预训练模型。我们期待看到社区能够构建出什么样的成果！&lt;/p&gt; 
&lt;p&gt;我们感谢 Google 团队发布了这一令人惊叹且开放的模型系列。特别感谢 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FMolbap&quot; target=&quot;_blank&quot;&gt;Pablo Montalvo&lt;/a&gt; 将模型集成到 Transformers 中，以及 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Flysandre&quot; target=&quot;_blank&quot;&gt;Lysandre&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FRaushanTurganbay&quot; target=&quot;_blank&quot;&gt;Raushan&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FArthurZ&quot; target=&quot;_blank&quot;&gt;Arthur&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fydshieh&quot; target=&quot;_blank&quot;&gt;Yieh-Dar&lt;/a&gt; 和团队其他成员的努力，他们迅速完成了模型的评审、测试和合并工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fpaligemma-2-release-67500e1e1dbfdd4dee27ba48&quot; target=&quot;_blank&quot;&gt;发布合集&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fpaligemma&quot; target=&quot;_blank&quot;&gt;PaliGemma 博客文章&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmerve%2Fpaligemma2-3b-vqav2&quot; target=&quot;_blank&quot;&gt;在 VQAv2 上微调模型&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;微调模型演示&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;英文原文: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fpaligemma2&quot; target=&quot;_blank&quot;&gt;https://hf.co/blog/paligemma2&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;原文作者: Merve Noyan, Andreas P. Steiner, Pedro Cuenca, Aritra Roy Gosthipaty&lt;/p&gt; 
 &lt;p&gt;译者: xiaodouzi666&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/HuggingFace/blog/17019541</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/17019541</guid>
            <pubDate>Mon, 30 Dec 2024 05:39:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>IBM 收购 HashiCorp 交易面临英国反垄断审查</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F12%2F30%2Fuk-antitrust-watchdog-launches-review-of-ibms-hashicorp-takeover%2F&quot; target=&quot;_blank&quot;&gt;据 TechCrunch 报道&lt;/a&gt;，英国反垄断监督机构竞争与市场管理局（CMA）已开始调查 IBM 计划收购云软件厂商 HashiCorp 是否会影响竞争。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-699fccb664555c8767ef7615467cd7deac2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;CMA 周一表示，它将在 1 月 16 日前邀请有关各方就这一并购发表评论。该监管机构暂定 2 月 25 日为最后期限，以决定是批准该交易还是将其提交进一步审查。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;IBM 于今年 4 月宣布同意以约 64 亿美元的价格收购 HashiCorp。如果收购继续进行，将扩大 IBM 在云计算和人工智能领域的推进力度，并让该公司获得 HashiCorp 约 4400 家客户的名册。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;CMA 于 8 月通知 HashiCorp 将对合并进行审查。美国联邦贸易委员会也在调查这一交易。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/289379/ibm-acquire-hashicorp-6-4-billion&quot; target=&quot;news&quot;&gt;IBM 以 64 亿美元收购 HashiCorp&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;更多独家技术见解与热门话题讨论，尽在&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;【开源中国 APP】&lt;/a&gt;，与数百万开发者一起，随时随地探索技术无限可能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny</guid>
            <pubDate>Mon, 30 Dec 2024 03:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>一个大模型需要多大 GPU 内存才能跑起来的计算公式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式： M = &amp;nbsp;((P * 4B) / (32 / Q) &amp;nbsp;) * 1.2&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;M: 所需的 GPU 显存，单位是 GB。&lt;/li&gt; 
 &lt;li&gt;P: 模型的参数数量。例如，7B 模型有 70 亿个参数。&lt;/li&gt; 
 &lt;li&gt;4B: 每个参数占用的字节数，这里假设每个参数占用 4 个字节（通常指 FP32 或 Float32 格式）。&lt;/li&gt; 
 &lt;li&gt;32: 4 个字节等于 32 位。&lt;/li&gt; 
 &lt;li&gt;Q: 加载模型时使用的位数。例如，16 位 (FP16/BF16)，8 位 (INT8) 或 4 位 (INT4)。这通常称为量化。&lt;/li&gt; 
 &lt;li&gt;1.2: 表示额外开销的系数，通常为 20%。这考虑了除了模型权重之外还需要加载到 GPU 显存中的其他数据，例如优化器状态、梯度等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;如使用 FP16 量化加载 Llama 70B 模型，计算过程就是&lt;br&gt; &lt;strong&gt;M = &amp;nbsp;( (70,000,000,000 * 4) / (32 / 16) &amp;nbsp;)* 1.2 = 168 GB&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ecd94df1c281b114f9cbb19306dc7f358e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;——&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP6DrHa8Ob&quot; target=&quot;_blank&quot;&gt;蚁工厂&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;更多独家技术见解与热门话题讨论，尽在&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;【开源中国 APP】&lt;/a&gt;，与数百万开发者一起，随时随地探索技术无限可能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327612</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327612</guid>
            <pubDate>Mon, 30 Dec 2024 03:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>X.Org Server 的代码提交次数创 10 年新高</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;根据 X.Org Server 的&amp;nbsp;&lt;/a&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;Git 提交记录&lt;/a&gt;，在刚刚过去的 2024 年，&lt;/span&gt;X.Org Server 的代码&lt;span&gt;提交次数达到了 2014 年以来的最高峰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;虽然提交次数比前几年多了不少，但这并不意味着 &lt;/span&gt;X.Org Server&amp;nbsp;&lt;span&gt;的复兴，因为 Wayland 仍在 Linux 桌面上占据主导地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d93cec2031e1ac95173fc30bde92b9e8801.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据统计，X.Org Server 去年有 708 次提交... 比起 2018 年的 535 次提交（每年 200~300 次）要多得多。但即使是在 2010 年代中期，Wayland 还在积极开发的时候，每年也只有 400~500 次提交... 在 2024 年之前，提交次数最多的是 2014 年，当时有 952 次提交。&lt;/p&gt; 
&lt;p&gt;按行数计算，2024 年 X.Org Server 新增了 11998 行代码，删除了 14680 行代码。这比近几年每年 X.Org Server 代码库中通常 5-6 千行代码的变化要多。但仍远低于 X.Org Server 积极开发的 2000 年代更高的代码更新量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a555233d997eb149ec68424bd0390abacf2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;2024 年的 X.Org Server 之所以如此活跃主要有两个原因。&lt;/p&gt; 
&lt;p&gt;首先，X.Org Server 中的 XWayland 代码仍在继续积极开发，用于支持新的 Wayland 协议和其他修复/添加内容... XWayland 是 X.Org Server 中继续开发新功能的主要领域，也是唯一的领域。&lt;/p&gt; 
&lt;p&gt;另一个原因是开源开发者 Enrico Weigelt。&lt;/p&gt; 
&lt;p&gt;Enrico Weigelt 主要负责 X.Org Server 的修复和改进工作，围绕 X.Org Server 的测试和更好的 CI BSD 覆盖范围。在红帽或英特尔等主要厂商都没有投资 X.Org Server 开发的情况下，Enrico 几乎是单枪匹马地完成了一些 X.Org Server 修复和其他小功能工作。&lt;/p&gt; 
&lt;p&gt;Enrico Weigelt 负责了今年 X.Org Server&amp;nbsp; 63% 的&amp;nbsp;&lt;span&gt;Git 提交... 其他活跃的开发者包括 Olivier Fourdan、Michel Dänzer、Alan Coopersmith、Peter Hutterer 和 Erik Kurzinger，他们大多只关注 XWayland 的改进/修正。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;除此之外，去年 X.Org Server 的许多提交都是为了安全修复。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b87e1a0baefae75b023d31ef6fe6bafe102.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0102/111918_vgsn_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;就代码行数而言，X.Org Server 多年来基本处于停滞状态，唯一的主要功能工作是围绕 XWayland 进行的。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;点此查看 X.Org Server 的更多 GitStats 数据&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327607/xorg-server-2024-gitstats</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327607/xorg-server-2024-gitstats</guid>
            <pubDate>Mon, 30 Dec 2024 03:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Star 超 9 k，AI 小白也能玩转企业 LLM 应用开发</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;现在大模型 workflow 产品有很多，比如 BISHENG 、MaxKB、Dify、FastGPT、RagFlow 等等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;其中，毕昇 BISHENG 是一个开源的&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;大模型应用开发平台，专门&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;面向企业场景，具备高精度文档解析 ETL4LLM 能力。自去年 8 月份开源以来， GitHub 上的 Star 数已经超过 9k 了。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;对于 AI 小白来说，毕昇 BISHENG &lt;/span&gt;平台也很友好。&lt;/strong&gt;因为平台上有很多现成的模板，开发一个大模型应用简直不要太简单！编程、开发测试、合同审核、招投标、高级翻译、会议纪要等等，只需要根据自己需求，调整参数就能用。全程都是可视化界面操作。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;788&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6995a9ece3a8a4f407abd152f1b17f921d.png&quot; width=&quot;1015&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;1 月 3 日，OSCHINA 开源中国将邀请 BISHENG 产品负责人鲁力，做客直播栏目《开源项目老牌与新秀》第 3 期，分享其对 BISHENG—— 大模型 workflow 产品设计思考、技术方案。谈一谈它，与 Dify、Coze 有什么差异。同时，还将分享他在企业大模型应用落地过程中踩过的那些坑。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;本次直播中有一个重点环节，就是实操演示 —— 手把手教你怎么用 BISHENG 搭建各种大模型应用，例如合同审核、报告生成等。想体验的小伙伴可以点击链接：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbisheng.dataelem.com%2F&quot; target=&quot;_blank&quot;&gt;https://bisheng.dataelem.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;微信扫码，赶紧预约直播吧~&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;2388&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d72821bf78b0b3f33f49b2d818702279e20.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了诸多社区或组织的大力支持，在此特别表示感谢：&lt;/strong&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:left&quot;&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前，Gitee 已经有超过 1200 万名开发者，累计托管超过 2800 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 30 万家企业。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;渠成开源社区&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;渠成开源社区由禅道项目管理软件团队发起，社区的经营主体为青岛渠成开源计算机网络技术研究中心，是非营利性社会服务活动的社会组织。 渠成开源社区主要面向一线开源软件生产者、贡献者、组织者、赞助商和用户，以解决具体实际问题为宗旨，旨在打造以开源软件为核心纽带的开源生态系统，真正做到让每一个优秀的开源软件都能实现商业化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.qucheng.cc&quot; target=&quot;_blank&quot;&gt;www.qucheng.cc&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源项目老牌与新秀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是开源中国 OSCHINA 推出的一档直播栏目，旨在为开源项目提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请开源项目的作者、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的开源项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/16971110</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/16971110</guid>
            <pubDate>Mon, 30 Dec 2024 03:09:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>另辟蹊径打造高精度的 VL 文字提取工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;一、应用场景：设备铭牌识别环境&lt;/h2&gt; 
&lt;p&gt;在工业和医疗等领域的设备管理中，设备铭牌的信息提取是一项常见但极具挑战性的任务。这些铭牌通常包含关键信息如型号、序列号、制造日期等，对于资产管理、维护记录和故障排除至关重要。然而，实际拍摄的照片往往存在以下难题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;角度与透视问题&lt;/strong&gt;：由于拍摄角度各异，上传的照片中设备铭牌可能出现严重的透视变形，导致文字倾斜或扭曲。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;光线与反射干扰&lt;/strong&gt;：现场光线条件复杂，强光反射或阴影遮挡使得铭牌上的文字难以清晰辨认。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;背景杂乱&lt;/strong&gt;：周围环境复杂，背景中的其他物体可能干扰文本区域的识别。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题直接使用视觉语言（VL）模型进行识别时，会导致极低的准确率和可靠性。为了解决这些问题，最近和 Gitee AI 团队进行了深度友好的沟通，最终得到了一套完整的解决方案，通过 UVDoc 图像校正工具预处理图片，再利用 QwenVL 进行信息识别，并最终使用大型语言模型（LLM）实现结构化数据提取，显著提升了铭牌文字的提取效果。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f0fe8c7dbf79cea800ebd5fd45eacd503ea.jpg&quot; width=&quot;250&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c0a5b16fd9f82586a0a5e5b09bb17c64735.jpg&quot; width=&quot;141&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f047384ddb6dfa3a43fd16be34037953c4.jpg&quot; width=&quot;269&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;二、技术方法&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;1. UVDoc 图像校正工具：提升输入质量&lt;/h3&gt; 
&lt;p&gt;针对上述难题，我们首先采用 GiteeAI 团队最新发布的&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=UVDoc&quot; rel=&quot;nofollow&quot;&gt;UVDoc 图像校正工具&lt;/a&gt;对原始照片进行预处理。该工具利用先进的计算机视觉算法，自动检测并纠正图像中的透视变形，恢复铭牌的真实形状。同时，它还可以调整图像的亮度和对比度，减少光线和反射带来的干扰。经过 UVDoc 校正后的图像不仅提高了文本的可读性，还为后续的文字识别提供了更佳的基础。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=UVDoc&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=UVDoc&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2. QwenVL：强大的信息识别引擎&lt;/h3&gt; 
&lt;p&gt;完成图像预处理后，接下来是关键的信息识别阶段。我们选择了 QwenVL 作为核心识别引擎，其融合了最新的视觉语言模型技术，能够在复杂背景条件下精准定位并识别出文本内容。QwenVL 不仅可以处理常规印刷体文字，还能应对手写体以及多种语言混合的情况，极大地拓宽了应用范围。此外，QwenVL 还支持多模态输入，可以同时解析图像中的其他非文本元素，如图标、表格等，为用户提供更加全面的信息提取服务。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen2-VL-72B&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen2-VL-72B&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;3. LLM 结构化数据提取：智能化处理结果&lt;/h3&gt; 
&lt;p&gt;最后一步是将 QwenVL 输出的结果进一步转化为结构化的数据格式。这一步骤依赖于 Qwen2.5-72B-Instruct，它具备强大的自然语言理解能力，可以从非结构化的文本中抽取出有价值的结构化信息。例如，在设备铭牌识别场景中，Qwen2.5-72B-Instruct 可以自动识别并分类不同的字段，如型号、序列号、制造日期等；同时生成易于检索和分析的结构化数据，极大地方便了后续的数据管理和应用。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen2.5-72B-Instruct&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen2.5-72B-Instruct&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;三、结果展示&lt;/h2&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;957&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ac616d8505ee8718c66b5aa216a66688f.png&quot; width=&quot;1370&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了验证我们的方案的有效性，我们进行了实验，共同处理了 30 张具有不同角度和光线条件的设备铭牌照片。实验分为两组：一组直接使用 QwenVL 进行识别（直接 VL 组），另一组先使用 UVDoc 工具预处理后再使用 QwenVL 识别（联合处理组）。以下是两组的数据对比及更深入的统计分析：&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;（一）数据对比表&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;识别情况&lt;/th&gt; 
   &lt;th&gt;直接 VL 组 (张)&lt;/th&gt; 
   &lt;th&gt;联合处理组 (张)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;正确识别&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;部分识别&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;完全不能识别&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;总计&lt;/td&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;30&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;（二）进一步统计分析&lt;/h3&gt; 
&lt;p&gt;最近我在做科研项目，所以简单按照科研项目的分析逻辑做了一下进一步的数据分析，相关内容就截图了。&lt;/p&gt; 
&lt;span id=&quot;OSC_h4_9&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;1. 准确率提升&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;正确识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：8/30 = 26.7%&lt;/li&gt; 
   &lt;li&gt;联合处理组：28/30 = 93.3%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;部分识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：12/30 = 40%&lt;/li&gt; 
   &lt;li&gt;联合处理组：2/30 = 6.7%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;完全不能识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：10/30 = 33.3%&lt;/li&gt; 
   &lt;li&gt;联合处理组：0/30= 0%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h4_10&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;2. 平均准确度&lt;/h4&gt; 
&lt;p&gt;平均准确度定义为每个样本被正确识别的比例。计算方法如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-196c8ee868b55cd221c9cb66160298a7693.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;直接 VL 组平均准确度：8/30 = 26.7%&lt;/li&gt; 
 &lt;li&gt;联合处理组平均准确度：28/30 = 93.3%&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h4_11&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;3. Kappa 系数（Cohen&#39;s Kappa）&lt;/h4&gt; 
&lt;p&gt;Kappa 系数用于衡量分类系统的可靠性，考虑了偶然一致性。其公式为：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f2688c169d186ec03283ab51948f08da1ec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kappa 系数表明联合处理组的一致性远高于直接 VL 组，说明前者在实际应用中更为可靠。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_12&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;四、结论&lt;/h3&gt; 
&lt;p&gt;从以上数据分析可以看出，联合处理组的表现显著优于直接 VL 组：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;准确性大幅提升&lt;/strong&gt;：联合处理组的正确识别率从 26.7% 提高到了 93.3%，几乎达到了完全正确识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;部分识别减少&lt;/strong&gt;：联合处理组部分识别的比例从 40% 降低到 6.7%，表明大多数情况下都能实现完全正确的识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无法识别消除&lt;/strong&gt;：联合处理组实现了零失败，所有照片均能至少部分识别，而直接 VL 组有 10 张照片完全不能识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可靠性更高&lt;/strong&gt;：Kappa 系数显示联合处理组的一致性远高于直接 VL 组，证明了其在实际应用中的优越性能。&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;514&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e116320452808f0eb70d24e1a6e9b74d503.png&quot; width=&quot;1781&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;综上所述，在高精度的图文识别场景中，通过 UVDoc 图像校正工具预处理图片、QwenVL 进行信息识别以及 LLM 进行结构化数据提取，成功解决了设备铭牌识别中的难题，构建了一个高效且精确的文字提取系统。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/bojinzhu/blog/17003148</link>
            <guid isPermaLink="false">https://my.oschina.net/bojinzhu/blog/17003148</guid>
            <pubDate>Mon, 30 Dec 2024 02:36:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>百度网页版新增「AI 搜」功能，基于文心大模型打造</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度近日在百度搜索 Web 端首页上线了百度「AI 搜」入口，「AI 搜」基于原百度搜索 AI 伙伴改版升级而来，在此前的基础上做功能升级。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0102/100753_fgNl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，百度「AI 搜」是基于百度文心大模型打造的桌面端 AI 搜索引擎，目前内容侧已经打通百度搜索引擎、百度健康、百度律临、百度文库、百度教育等内容生态，可确保搜索结果可靠、权威。&lt;/p&gt; 
&lt;p&gt;目前百度「AI 搜」主要提供包括话题探索、问题解决、决策辅助、知识答疑、主题研究、学习创作等功能，覆盖文生图、文生文、逻辑推理、多轮对话、智能摘要、AI 修图等 AI 技术。&lt;/p&gt; 
&lt;p&gt;此外，百度「AI 搜」也提供了文心智能体入口，在对话框中可通过@方式与不同智能体进行交互，方便用户使用和创建智能体。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;更多独家技术见解与热门话题讨论，尽在&lt;a href=&quot;https://www.oschina.net/app&quot;&gt;【开源中国 APP】&lt;/a&gt;，与数百万开发者一起，随时随地探索技术无限可能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327593</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327593</guid>
            <pubDate>Mon, 30 Dec 2024 02:09:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>你好，2025！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#3e3e3e&quot;&gt;飞致云恭祝大家新年快乐！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1920&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cc8718206c51fbfc57a88fe25d62b1bbcee.jpg&quot; width=&quot;1081&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327509</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327509</guid>
            <pubDate>Sun, 29 Dec 2024 06:24:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
    </channel>
</rss>