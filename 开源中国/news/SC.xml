<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 20 Aug 2025 22:47:17 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微软为 Excel 添加 =COPILOT() 函数，引入 LLM 能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软正在为 Excel 添加一项名为 =COPILOT() 的新函数，该功能将大型语言模型 (LLM) 的特性直接集成到电子表格的单元格中，可用于数据分析和内容生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1244" src="https://static.oschina.net/uploads/space/2025/0820/190354_6lID_2720166.png" width="1290" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以直接在网格内使用此函数来帮助填充单元格。根据指定的一组单元格数据，=COPILOT() 函数可以利用 AI 进行分析、生成内容和头脑风暴。具体功能包括生成摘要、标签、表格等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0c757914b31abe665f8fe19dd133ddcc775.webp" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://techcommunity.microsoft.com/blog/microsoft365insiderblog/bring-ai-to-your-formulas-with-the-copilot-function-in-excel/4443487&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367473</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367473</guid>
      <pubDate>Mon, 18 Aug 2025 11:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Augment Code 推出 Agent Turn Summary 功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程平台 Augment Code 发布了一项名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.augmentcode.com%2Fchangelog%2Fagent-turn-summary" target="_blank"&gt;Agent Turn Summary&lt;/a&gt;的新功能。该功能可以将 Agent 在单次交互（turn）中执行的复杂操作序列浓缩为一行简洁的摘要，让开发者在几秒钟内就能掌握全局，而非花费数分钟滚动浏览大量日志。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9aa640b9721c46d955b27fcc7aca5797a31.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该功能在 Agent 响应的末尾、反馈页脚旁边显示，内容包括工具调用的摘要与计数，以及所做更改的快照。用户可以一目了然地看到操作的整体范围，仅在需要时才展开查看完整细节。&lt;/p&gt; 
&lt;p&gt;目前，Agent Turn Summary 功能已在 VS Code 和 JetBrains 的预发布版本中提供。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367472</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367472</guid>
      <pubDate>Mon, 18 Aug 2025 11:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Kilo Code 新增基于用量的价格估算，支持 Qwen Code</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;Kilo Code&lt;/strong&gt; 近期&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.kilocode.ai%2Fp%2Fkilo-code-v4791v4810-usage-based" target="_blank"&gt;发布重要更新&lt;/a&gt;，新增基于真实用量的 AI 模型价格估算功能，并支持 &lt;strong&gt;QwenCode&lt;/strong&gt; 作为 API provider 。&lt;/p&gt; 
&lt;p&gt;更新后，Kilo Code 能根据真实世界使用情况（基于每日处理超 &lt;strong&gt;300 亿&lt;/strong&gt; token 的真实用量，已计入缓存折扣等因素）估算各模型的平均每百万 token 成本，用户可在设置中查看 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7ab70cf8e4317d267793b8e767d3046e4e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-25de1b84c1e8e008e8a8f4c05d59d91f950.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，用户安装 &lt;strong&gt;QwenCode&lt;/strong&gt; 并创建账户后，Kilo Code 能自动找到其配置文件，实现开箱即用的集成 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c5cba126534a4d92f8f5cc0513c06ee0973.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kilo Code 是开源 VS Code AI Agent 扩展，内置最新的 AI 模型，具备强大的代码生成能力，能根据自然语言描述快速生成代码片段，有效减少手动编写代码的时间。Kilo Code 能自动化执行多种重复性编码任务，例如代码格式化、重构以及生成样板代码等，进一步提高开发效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367470</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367470</guid>
      <pubDate>Mon, 18 Aug 2025 10:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌图像编辑 AI 模型 nano-banana 现身 LMArena</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;最近，一款名为 nano-banana 的神秘图像编辑 AI 模型悄然现身 LMArena 平台。有爆料称：这是谷歌正在测试的新模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-daa046b2afeced90c8ac232dead09582575.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f40a92db7e4552760f02564cf4641fa98f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;谷歌工程师在社交平台上发布香蕉 emoji 或香蕉图片，明示代号为 nano-banana 的图像生成模型为谷歌所有。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-867584592c2b8c9970b5f4314a01c353dda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前该模型在 LMArena 平台进行测试，但尚未在 AI Studio 上线。在 text-to-image（文生图）和 image-edit（图像编辑）功能方面，nano-banana 展示了强大的能力，其性能被认为超越了 GPT-Image-1 模型。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lmarena.ai/?chat-modality=image&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367467</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367467</guid>
      <pubDate>Mon, 18 Aug 2025 10:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firecrawl 获 1450 万美元 A 轮融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Firecrawl 宣布完成 1450 万美元的 A 轮融资。本轮融资由 Nexus Venture Partners 领投，Shopify 首席执行官 Tobias Lütke 及 Y Combinator 等知名投资者跟投。&lt;/p&gt; 
&lt;p&gt;据悉，Firecrawl 通过一封大胆的电子邮件与 Tobias Lütke 建立了联系，此前后者通过自助服务平台试用了 Firecrawl 的产品。这一投资不仅为 Firecrawl 注入了资金动力，也为其技术创新和市场扩展提供了强有力的背书。&lt;/p&gt; 
&lt;p&gt;Firecrawl 表示，此轮融资将用于加速产品研发、扩大全球工程与 AI 专家团队，并进一步优化其服务能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-0f5d3148770305396b53663dc286ff63317.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Firecrawl 同步推出了其 V2 版本 API，被称为迄今为止最重大的技术升级。新版本在以下几个方面实现了突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;10 倍速抓取：通过优化的 Fire-Engine 技术，V2 版本的网页抓取速度提升了 10 倍，成功率提高 40%，为大规模数据处理提供了更高的效率。&lt;/li&gt; 
 &lt;li&gt;语义化爬取：利用自然语言处理技术，Firecrawl 能够根据语义理解网页结构，自动提取所需数据，减少手动干预，提升数据质量。&lt;/li&gt; 
 &lt;li&gt;新增新闻与图像搜索功能：V2 版本新增了对新闻和图像内容的搜索与提取支持，为 AI 应用提供了更丰富的实时数据来源。&lt;/li&gt; 
 &lt;li&gt;多功能集成：持 Markdown、JSON、截图等多种数据格式输出，并与 LangChain 等 AI 框架无缝集成，方便开发者快速构建 AI 应用。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367465</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367465</guid>
      <pubDate>Mon, 18 Aug 2025 10:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>钉钉重注 AI：成立行业专属模型团队，向 CTO 汇报</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWRBSkp0dSe3sfff4WP0CFw" target="_blank"&gt;智能涌现&lt;/a&gt;》独家获悉，钉钉近期成立了一个新业务线——行业专属模型，并作为独立团队存在，向钉钉 CTO 朱鸿汇报。这也是钉钉创始人无招回归后，钉钉在 AI 战略推进中的重要动作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「团队成立后，目前钉钉已经与多家行业客户接触，目前已有几个行业/企业专属模型在推进中。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;自 4 月重返钉钉后，无招将产品体验和 AI 创新作为首要优先级。从 4 月开始，钉钉就经历了一场整改——覆盖范围很广，从产品设计、排查，到整改，无招都在一线深度参与。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从 ChatGPT 爆火后，钉钉已经完成了大模型基础能力的接入。2023 年 8 月，钉钉就已经将智能化底座 (AI PaaS) 开放给生态伙伴和客户，鼓励合作伙伴利用大模型重新打造产品；再到 2024 年 1 月发布的 AI 助理，具备感知、记忆、规划和行动能力，能够跨应用程序执行任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据钉钉此前披露的数字，钉钉目前企业组织数超过 2500 万，其中有超 220 万家企业在钉钉使用 AI，覆盖制造、医疗、金融、零售等 20 个一级行业。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;成立行业专属模型团队，是大模型在技术、产品化之后，继续在企业侧落地的体现。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;企业 AI 落地的挑战并不小。一方面，大多数企业、尤其是中小企业虽然对 AI 有强烈需求，但普遍缺乏专业的技术团队和数据处理能力；另一方面，通用大模型虽然功能强大，但难以满足垂直行业的专业需求，需要针对特定场景进行深度定制和优化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;钉钉的行业专属模型团队，主要面向钉钉平台上的企业客户、第三方合作伙伴。比如，对于没有充足 AI 人才资源的中小企业客户，钉钉会提供全流程的模型训练和数据工程服务，包括前端的数据打标、清洗到模型的调优，都由钉钉团队完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与面向开发者的阿里云旗下百炼等平台相比，钉钉行业专属模型会更贴近业务场景。「行业专属模型是由钉钉和企业中懂业务、懂行业的业务人员共创，将行业 know-how 沉淀下来，让企业客户能够更快、更好地用上模型。」一位钉钉人士对 36 氪表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，钉钉已经在行业专属模型方面取得了初步成果。在 7 月发布的豆蔻妇科大模型，其实是钉钉平台上成功落地的第一个垂类专属大模型。其作为医疗领域的垂类模型，可将妇科六大症状的诊断准确率，从 77.1% 提升到 90.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在推动行业专属模型的同时，钉钉也在加速完成 AI 生态的闭环，另一个新动作是对应用市场进行改版。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Agent 已经是 2025 年大厂竞争的「明牌」。从 2024 年开始，大厂们已经推出了包括阿里云百炼、字节跳动扣子 (Coze)、百度文心智能体、腾讯元器等 Agent 平台。钉钉也在 2024 年 4 月上线了 AI Agent Store。无招回归钉钉后，一个重要工作也是重新构造 Agent 市场的逻辑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除了应用推荐方式大变之外，钉钉未来会在 Agent 市场上再发力，开放能力给更多的 ISV 和企业，帮助企业打造 Agent 应用，并通过钉钉实现商业化闭环，打通整个 Agent 应用生态。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367464</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367464</guid>
      <pubDate>Mon, 18 Aug 2025 10:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DatologyAI 发布合成数据框架 BeyondWeb</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DatologyAI 发布了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.datologyai.com%2Fbeyondweb%2F" target="_blank"&gt;&lt;strong&gt;BeyondWeb&lt;/strong&gt;&lt;/a&gt;，一个专为大规模语言模型（LLM）预训练设计的合成数据生成框架，旨在突破当前面临的数据瓶颈问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/181040_p3sx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该框架采用「目标导向的文档重写」策略，对现有高质量网络数据进行改写，而非从头生成，从而在保证数据多样性和信息密度的同时，避免了低质量内容的引入。&lt;/p&gt; 
&lt;p&gt;据介绍，BeyondWeb 通过高质量、信息密集的合成数据，显著提升了模型性能，即使在原始网络数据有限的情况下，也能实现超越传统数据规模扩展的效果。在 14 项基准测试中，使用 BeyondWeb 生成的合成数据训练的 3B 参数模型，其性能超过了使用 Cosmopedia 数据训练的 8B 参数模型，同时训练速度提升了最高达 7.7 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eadd4a1595c18a9ec07e6705a60c8bc60c7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;论文地址：https://arxiv.org/pdf/2508.10975&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367463</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367463</guid>
      <pubDate>Mon, 18 Aug 2025 10:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>100% 开源版的 Claude Code？00 后这么勇吗？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;几天前，来新璐告诉我，他做了一个开源版本的 Claude Code 。&lt;/p&gt; 
&lt;p&gt;我问他，能实现几成&amp;nbsp;Claude Code 的效果。&lt;/p&gt; 
&lt;p&gt;他简单地回复我：100%。&lt;/p&gt; 
&lt;p&gt;&lt;img height="124" src="https://oscimg.oschina.net/oscnet/up-3f746e5853445f04492023812b04aeba4d2.png" width="309" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果是别人，我可能就当他说大话了。&lt;/p&gt; 
&lt;p&gt;但他是来新璐，llama3 中文版作者，GitHub Star 数已经有 4.2K 了。&lt;/p&gt; 
&lt;p&gt;此前曾在百度&lt;a href="https://www.oschina.net/action/visit/ad?id=1185"&gt;飞桨&lt;/a&gt; &amp;amp; 腾讯混元负责多模态大模型训练、推理相关的开源套件工作。&lt;/p&gt; 
&lt;p&gt;他还开发了多个技术项目，比如文生图大模型训练工具箱 ——&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCrazyBoyM%2Fdreambooth-for-diffusion" target="_blank"&gt;&lt;span&gt;dreambooth-for-diffusion&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，也给 ComfyUI 的 controlnet 部分贡献过代码。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这么看起来，他还是有点东西的。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;而且，作为一个 00 后，他还&lt;span&gt;是奇绩创坛 F24 校友，&lt;/span&gt;创立了 ShareAI-Lab，一家注重技术创新的实验室性质的公司，面向 toB 市场，做模型后训练、数据合成标注、资料知识库+ AI agent 搜索。&lt;/p&gt; 
&lt;p&gt;公司还有一个技术开发组长，叫陶熠，是斯坦福大学人工智能专业硕士毕业，妥妥的 AI&amp;nbsp;Agent 专家。&lt;/p&gt; 
&lt;p&gt;再加上前段时间，来新璐一直在对 Claude Code 源码进行深度逆向分析，一口气发了 5 篇文章。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo4pu8QX1tRIPBRlFJqrX3A" target="_blank"&gt;Claude Code 逆向破解 Prompt 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FGspfXKHiwtdhr73KtDgO1w" target="_blank"&gt;Claude Code 分层多 Agent 架构篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlBhZhdlb1s0y4qgl_5HSWQ" target="_blank"&gt;Claude Code: 上下文工程 system-reminder 篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMeJTDMcYV2u-TJfOJlLilg" target="_blank"&gt;Claude Code 异步消息通信机制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj8eTytIDy9l4dnLVHS_Cuw" target="_blank"&gt;Claude Code 最新版解读之自定义 Agent 机制篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;现在跟我说搞了个 100% 开源版的 Claude Code，这个可信度就又提高了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这个号称 「100% 开源版 Claude Code」 的项目，叫 Kode。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FshareAI-lab%2FKode" target="_blank"&gt;&lt;strong&gt;GitHub 地址：&lt;/strong&gt;https://github.com/shareAI-lab/Kode&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;7 月初就放话说要开源，不过一直没有发布，大家甚至一度以为要被鸽 ！&lt;/p&gt; 
&lt;p&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-6f1e9a2460372836c22eccc6194f26d9880.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="background-color:#ffffcc"&gt;不过，最终它来了！目前 GitHub 已经有 900 多 Star。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;与官方 Claude Code 比较之后，也有较多出彩的地方。&lt;/p&gt; 
&lt;p&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-20256148956a23d9da17f32f0fa7b0e2416.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最后，不管我怎么问他，得到的回答都是非常肯定的——Kode 就是开源版 Claude Code。&lt;/p&gt; 
&lt;p&gt;看来，Kode 都是要蹭劳 Claude Code 这波流量了。&lt;/p&gt; 
&lt;p&gt;&lt;img height="195" src="https://oscimg.oschina.net/oscnet/up-6cb6eb15c540029a760c2eea5f8475ec939.png" width="538" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;既然他敢把话说得这么满，那就直播来验一验真假！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0635a39399fde8a01a773d4770b4bb9e1d9.png" width="540" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;是骡子是马，拉出来遛遛就知道了！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播主题：&lt;/strong&gt;ShareAI-lab 搞了个 100% 开源版 Claude Code&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;8 月 23 日周五 20:00-21:00&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;视频号 「OSC 开源社区」&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播亮点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;拆解 Claude Code 技术设计原理&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;开源版 Claude Code —— Kode 源码带读&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Claude Code 高阶使用技巧及 SDK 应用潜力场景分享&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;实战：用 Kode 维护大型项目&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;演示：小型 MVP Demo &amp;amp; 使用技巧&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;展望 Agent 世界发展&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;福袋抽奖：直播中将有 5 轮抽奖，参与就有机会获得 OSC T 恤、马建仓蛇年公仔（限量版）、代码圣杯、马克杯、冰箱贴、前沿技术书籍等。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt;
  可以加入 OSC 直播交流群，进来唠唠嗑，或者你有好的产品 / 项目，也欢迎推荐过来呀～ 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-f4e3f0507c7b79ba06185e2b2d6da4cd412.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，基本上每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18688925</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18688925</guid>
      <pubDate>Mon, 18 Aug 2025 10:10:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Anthropic 推出 Usage and Cost API</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 近期推出了 Usage and Cost API，作为其 Admin API 的一部分，旨在帮助开发者和组织以编程方式实时监控和追踪 Claude 模型的使用情况和成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0820/180149_Zv2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://docs.anthropic.com/en/api/admin-api/usage-cost/get-messages-usage-report&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;该 API 允许用户通过请求获取详细的用量报告。报告支持多种精细化的筛选和分组条件，包括按 API 密钥 ID、工作区 ID、模型（例如 claude-sonnet-4-20250514）、服务等级（standard,batch,priority）以及上下文窗口大小（0-200k,200k-1M）进行查询。报告的时间粒度可以设置为分钟（1m）、小时（1h）或天（1d）。&lt;/p&gt; 
&lt;p&gt;为了方便开发者快速上手，Anthropic 在 GitHub 的 anthropic-cookbook 项目中提供了一个名为 usage_cost_api.ipynb 的 Jupyter Notebook 示例教程。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://github.com/anthropics/anthropic-cookbook/blob/main/observability/usage_cost_api.ipynb&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367457</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367457</guid>
      <pubDate>Mon, 18 Aug 2025 10:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>韩国政府拟未来两年采购超 3.5 万枚 GPU</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;韩国科学技术信息通信部周三表示，韩国将在未来两年内采购超过 35000 枚图形处理器（GPU），作为全国范围内加强人工智能（AI）基础设施计划的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="380" src="https://oscimg.oschina.net/oscnet/up-bef12c45835c72bb33b4f121bbd7f104e9c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;韩国科学技术信息通信部长官裴庆勋当天在国会表示，政府的长期目标是到 2030 年确保 5 万枚 GPU。「我不认为政府能包办一切。政府将为私营部门创造人工智能市场和基础设施投资铺平道路。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作为该计划的一部分，韩国政府启动了一个开发韩国 AI 基础模型的项目，五家公司 Naver Cloud、Upstage、SK Telecom、NC AI 和 LG AI Research 将获得研发资金支持以及政府资源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此前，韩国政府通过「AI 高速公路」计划，提出了到 2030 年成为全球人工智能领导者的愿景，其中包括建立配备 5 万枚 GPU 的国家人工智能数据中心。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367456</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367456</guid>
      <pubDate>Mon, 18 Aug 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>COLMAP - 三维重建软件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 是一个通用的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;Structure-from-Motion (SfM) 和 Multi-View Stereo (MVS) pipeline&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，具有图形和命令行界面。它提供了丰富的功能，可用于重建有序和无序图像集。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="210" src="https://static.oschina.net/uploads/space/2025/0818/145035_b3XQ_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="102" src="https://static.oschina.net/uploads/space/2025/0818/145138_oR0u_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你将此项目用于您的研究，请引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你使用 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;image retrieval / vocabulary tree engine&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，请同时引用：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;@inproceedings{schoenberger2016vote,
    author={Sch\"{o}nberger, Johannes Lutz and Price, True and Sattler, Torsten and Frahm, Jan-Michael and Pollefeys, Marc},
    title={A Vote-and-Verify Strategy for Fast Spatial Verification in Image Retrieval},
    booktitle={Asian Conference on Computer Vision (ACCV)},
    year={2016},
}
&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;

&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;COLMAP 建立在现有成果之上，在 COLMAP 中使用特定算法时，请注明原始作者（如源代码中所述），并考虑引用相关的第三方依赖项（例如 ceres-solver、poselib、sift-gpu 和 vlfeat）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/colmap</link>
      <guid isPermaLink="false">https://www.oschina.net/p/colmap</guid>
      <pubDate>Mon, 18 Aug 2025 09:38:00 GMT</pubDate>
    </item>
    <item>
      <title>百度 Q2 财报：总营收 327 亿元，AI 新业务收入超 100 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;百度已发布 2025 年 Q2 业绩。季度总营收达 327 亿元，归属百度核心的净利润 74 亿元，同比增长 35%，超出市场预期。受 AI 驱动，涵盖智能云在内的 AI 新业务收入增长强劲，首次超过 100 亿元，同比增长 34%。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;百度搜索实现搜索框、搜索结果页到搜索生态全面革新。7 月，移动搜索结果页 AI 生成内容占比达 64%。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能云业务营收健康增长。IDC 报告显示，百度智能云连续六年在中国 AI 公有云服务市场份额中排名第一；在 8 月 20 日最新发布的 IDC 报告中，百度智能云获大模型平台市场第一。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;萝卜快跑 Q2 在全球提供超 220 万次出行服务，同比增长 148%。截至 2025 年 8 月，萝卜快跑在全球累计提供超 1400 万次的出行服务，足迹覆盖全球 16 座城市。&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="407" src="https://oscimg.oschina.net/oscnet/up-dbfec1113b742dde43df7d6f29f5616147a.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="399" src="https://oscimg.oschina.net/oscnet/up-1c3bedd483c3e141c985f84fc64f5b0fea5.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="389" src="https://oscimg.oschina.net/oscnet/up-ec6a732253318c7bcae772c4d7290c5a922.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="391" src="https://oscimg.oschina.net/oscnet/up-a82bd72897868fcd3d7d1001409ae44376a.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="405" src="https://oscimg.oschina.net/oscnet/up-5a0078a83511433a02fd5f65b412a2b7983.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367441</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367441</guid>
      <pubDate>Mon, 18 Aug 2025 09:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Ubuntu 25.04 成首个开箱即用支持 AMD SEV-SNP 的发行版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Ubuntu 官方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fubuntu.com%2Fblog%2Fubuntu-25-04-amd-sev-snp-host-support" target="_blank"&gt;宣布&lt;/a&gt;，在最新发布的 Ubuntu 25.04（Plucky Puffin） 中，系统已全面集成 AMD SEV-SNP（Secure Encrypted Virtualization - Secure Nested Paging）主机端支持。这意味着用户无需额外打补丁或依赖实验构建，就能直接在生产环境中启用完整的 SEV-SNP 功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/171014_ReO5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;SEV-SNP 是 AMD 针对虚拟化场景的硬件级安全技术，它为虚拟机提供内存加密和完整性保护，能够阻止宿主机、固件甚至系统管理员访问虚拟机内部数据，被认为是机密计算（Confidential Computing） 的核心支撑之一。其应用价值尤其体现在数据中心和私有云环境，如 AI 模型推理和高敏感度业务计算。&lt;/p&gt; 
&lt;p&gt;此前，Ubuntu 早已在 22.04 LTS 中提供了 SEV-SNP 客机支持。随着 25.04 的更新，Ubuntu 成为首个在主机与客机两端都实现开箱即用支持的主流 Linux 发行版。尽管 Fedora 42 在发布时间上略早一步，但 Canonical 强调 Ubuntu 的版本无需额外调整，即可直接应用于生产环境。&lt;/p&gt; 
&lt;p&gt;这项功能也将被纳入即将到来的 Ubuntu 26.04 LTS，届时企业用户还将获得 FIPS 内核、Livepatch 等长期支持和合规特性，为高安全场景部署提供更稳健的保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367440/ubuntu-25-04-amd-sev-snp-host-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367440/ubuntu-25-04-amd-sev-snp-host-support</guid>
      <pubDate>Mon, 18 Aug 2025 09:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Docs 上线 AI 语音朗读功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌近日宣布，Google Docs 推出了一项全新的功能，用户现在可以通过 AI 生成语音来朗读他们的文档。此功能旨在提升用户的阅读体验，使得信息的获取更加便捷和生动。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在这一功能的使用过程中，用户可以自定义 AI 的音频输出，包括选择不同的声音和调整播放速度。这种个性化设置能够帮助用户根据自己的喜好来选择最适合的听觉体验，使得文档内容的传达更具吸引力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="337" src="https://oscimg.oschina.net/oscnet/up-288e88a5cce3983495e512628222b54ff43.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不仅仅是文档的创建者可以使用这一功能，其他读者也能够轻松访问共享文档的 AI 生成音频。用户只需在工具菜单中选择 「音频」 选项，再点击 「收听此标签」 即可开始聆听。此外，文档的作者也可以通过插入音频按钮，将可自定义的音频添加到文档中，读者点击按钮后即可开始收听。这种设计让阅读和分享文档变得更加有趣。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌早在四月份就曾透露将推出将文档转换为 AI 播客的计划，而这次的新功能则提供了一个更直接的听取文档内容的方式，特别是对于那些希望聆听自己创作的内容的用户。目前，该功能仅支持在桌面设备上生成英文文档的音频版本。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌目前正向拥有商业、企业或教育计划的 Workspace 用户，以及订阅 AI Pro 和 Ultra 的用户推出此功能。随着这项新功能的逐步上线，用户将能以更便捷和灵活的方式享受文档的内容，进一步提升工作效率和阅读体验。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367428</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367428</guid>
      <pubDate>Mon, 18 Aug 2025 08:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯 AI Lab 发布多模态音频生成工具 AudioGenie</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯 AI Lab&amp;nbsp;推出一项名为 AudioGenie 的新型无训练多智能体系统，为多模态到多音频（MM2MA）生成领域带来重大突破。&lt;/p&gt; 
&lt;p&gt;该系统能从视频、文本、图像等多模态输入中，精准合成音效、语音、音乐、歌曲等多种音频，有效解决了该领域长期面临的高质量配对数据稀缺、多任务学习框架薄弱等核心挑战。&lt;/p&gt; 
&lt;p&gt;AudioGenie 框架如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9ec2fecbaa136171f954205d7e2d0c2dbb7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://audiogenie.github.io/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AudioGenie 采用双层架构，由生成团队与监督团队组成。生成团队通过细粒度任务分解和自适应混合专家（MoE）协作机制，实现对多模态输入的深度理解与动态模型选择，并借助试错迭代优化模块完成自我修正；监督团队则通过反馈循环确保音频的时空一致性并验证输出质量。&lt;/p&gt; 
&lt;p&gt;此外，研究团队还构建了首个 MM2MA 任务基准数据集 MA-Bench，包含 198 个带多类型音频标注的视频。实验表明，AudioGenie 在 8 项任务的 9 个指标中均达到当前最优或可比性能，用户研究进一步证实其在音频质量、准确性、上下文对齐及美感上的显著优势，为跨模态音频生成应用开辟了新路径。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367426</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367426</guid>
      <pubDate>Mon, 18 Aug 2025 08:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>实战分析前端性能优化工具 Performance 面板！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;本文由体验技术团队董福俊原创。&lt;/p&gt; 
&lt;h2&gt;一、背景&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;关于 Performance 面板的基础用法介绍，可参考上一篇文章《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FwQmdgduzUmCJ2qJge5QZtA" target="_blank"&gt;"Performance 面板"一文通，解锁前端性能优化工具基础用法！&lt;/a&gt;》。文章中还从一个 HTTP 请求的四阶段的角度来介绍 Performance 图的"观看方式"，并重点介绍了 worker 线程跟主线程的协作关系&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本篇文章中，我们将会以一个实际网页 ------&lt;strong&gt;VPC 列表页&lt;/strong&gt;为例，介绍 Performance 抓图及分析的过程，并将上一篇文章中介绍的相关内容串起来，希望每位 frontend developer 都能掌握用 Performance 分析页面性能的能力。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：这里假设我们的分析目标是：让列表页的主内容区域尽快展示出来，以避免长时间白屏；另外，为求简洁，下文敍述中统一将 Performance 录制的结果图叫做"性能图"&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;二、分析前准备&lt;/h2&gt; 
&lt;p&gt;正式分析之前，建议做一些准备工作，能有效提高后续的分析效率。&lt;/p&gt; 
&lt;h3&gt;1. 环境准备&lt;/h3&gt; 
&lt;p&gt;1）选一个良辰吉日&lt;/p&gt; 
&lt;p&gt;建议&lt;strong&gt;关闭一些应用程序、浏览器页签，尽量让电脑 CPU 空闲一些&lt;/strong&gt; ，（&lt;em&gt;也建议关掉通信软件，让自己心情好一些&lt;/em&gt;）。尽量避免一边开会一边分析，避免分析过程被频繁打断，因为分析过程可能遇到各种奇怪的现象，倘若再被其它事务打断，心态直接崩溃，那么就分析不下去了......&lt;/p&gt; 
&lt;p&gt;2）选浏览器无痕模式&lt;/p&gt; 
&lt;p&gt;建议&lt;strong&gt;在浏览器无痕模式下录制性能图并进行分析&lt;/strong&gt;，因为一些特殊的浏览器配置、浏览器插件，都可能影响网页的加载过程，干扰分析结果。&lt;/p&gt; 
&lt;p&gt;3）选生产环境进行分析&lt;/p&gt; 
&lt;p&gt;我们可能有多种不同环境：本地代理环境（俗称 localhost）、类生产环境、生产环境，等。只有生产环境是最真实贴近用户的，所以建议&lt;strong&gt;在生产环境下进行网页性能分析。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;但需要注意的是，生产环境部署的代码，跟源码往往有较大形态上的差异（eg：打包工程的混淆、部署时的加工、服务端渲染的处理等）。所以，生产环境的性能图在某些代码细节上可能无法深入研究，此刻，我们还是需要其它环境的性能图进行辅助对比。&lt;/p&gt; 
&lt;h3&gt;2. 代码准备&lt;/h3&gt; 
&lt;p&gt;1）了解代码结构和加载流程&lt;/p&gt; 
&lt;p&gt;建议先从源码角度，详细了解待分析页面的结构及加载流程，例如我们讨论的样例------ VPC 列表页的结构如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;页面结构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9dc5c1a56bf9fd281f211ddb0f4dfc389.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;红色框：由基础框架 console-ui 提供的 header、sidebar 实现&lt;/li&gt; 
 &lt;li&gt;蓝色框：由业务代码实现，采用 angular 技术框架，NG App 下挂载一个根组件（VpcComponent）&lt;/li&gt; 
 &lt;li&gt;绿色框：根组件下分为，导航组件（LeftmenuComponent）和，列表页组件（VpcListComponent）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;代码结构&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-html"&gt;&amp;lt;!-- index.html --&amp;gt;

&amp;lt;div id="header"&amp;gt;&amp;lt;!-- console-ui 负责渲染 --&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;div id="sidebar"&amp;gt;&amp;lt;!-- console-ui 负责渲染 --&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;!-- NG App 挂载点 --&amp;gt;

&amp;lt;div id="ngApp"&amp;gt;

    &amp;lt;!-- 根组件 --&amp;gt;

    &amp;lt;vpc-component&amp;gt;

        &amp;lt;leftmenu-component&amp;gt;&amp;lt;!-- 导航组件 --&amp;gt;&amp;lt;/leftmenu-component&amp;gt;

        &amp;lt;router-outlet&amp;gt;

            &amp;lt;!-- 内容区-路由渲染点 --&amp;gt;

            &amp;lt;vpc-list-component&amp;gt;&amp;lt;!-- 列表页组件 --&amp;gt;&amp;lt;/vpc-list-component&amp;gt;

        &amp;lt;/router-outlet&amp;gt;

    &amp;lt;/vpc-component&amp;gt;

&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;console-ui 和 NG App 并行工作，分别负责不同 div 的渲染&lt;/li&gt; 
 &lt;li&gt;APP 的根组件下，导航组件和内容区并行工作，内容区由路由加载列表组件&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;初始化流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-91be71aaf0d51fd59268446efd7beecb4f1.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主渲染流程是：NG App 启动 =&amp;gt; 加载根组件 =&amp;gt; 路由渲染 =&amp;gt; 加载列表页组件&lt;/li&gt; 
 &lt;li&gt;angular 中每个组件都会经历生命周期：constructor =&amp;gt; ... =&amp;gt; ngOnInit =&amp;gt; ... =&amp;gt; ngAfterViewInit =&amp;gt; ... （这里只列举一些常用生命周期钩子，完整的说明见 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fangular.cn%2Fguide%2Fcomponents%2Flifecycle" target="_blank"&gt;组件生命周期&lt;/a&gt;。&lt;em&gt;PS：这一点不理解也不妨碍下文阅读&lt;/em&gt;）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2）关键节点加 performance.mark&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;很关键的是：在我们的主渲染流程上一些关键的时间节点加上 performance.mark，或者关键时间段加上 console.time/timeEnd&lt;/strong&gt;。这样在性能图的 Timings 面板上就会显示这些标记，从而帮助我们确认各个执行环节。&lt;/p&gt; 
&lt;p&gt;例如，针对&lt;strong&gt;VPC 列表页&lt;/strong&gt;的主渲染流程，我们在 NG App 启动、根组件 constructor 及 ngAfterViewInit、列表页组件 constructor 及 ngAfterViewInit，分别加上 performance.mark，则能在 Timings 面板中看到下图情况：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a494681e351a324f9d0433648e9a2f7a9d8.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS1：Timings 面板中的线很细，不仔细观察可能会漏掉。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS2：为了针对生产环境进行分析，我们可能需要提前在代码中预埋 performance.mark，待上线后才能利用的上。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;3）录制性能图&lt;/p&gt; 
&lt;p&gt;在 Network 面板清空已有记录，在 Performance 面板多点几下垃圾回收，然后开始录制。录制完成后，&lt;strong&gt;将 Performance 面板的性能图导出成 json 文件，并将 Network 面板的网路请求记录导出成 har 文件，保存在本地以方便后续查看。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;三、数据分析&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;录制好性能图后，建议先分析 Network 面板中的 index.html，大致了解加载了哪些静态资源，然后再投入性能图的分析&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;1. 分析 index.html&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;首先分析下 Network 面板中的 index.html，大致了解页面加载了哪些静态资源。&lt;/strong&gt; 一般源码中的 index.html 跟浏览器实际执行的 index.html 往往有很大差别，因为代码 (打包) 工程会对 index.html 进行魔改，如果有服务端渲染机制，那么服务渲染时可能还会插入一些样式、脚本。所以，浏览器最终执行的 index.html 将会是，源码+工程修改+服务端渲染，之后的结果。&lt;/p&gt; 
&lt;p&gt;例如，针对&lt;strong&gt;VPC 列表页&lt;/strong&gt;的 html 进行分析，会发现其加载了以下资源（按 html 中从上到下的顺序排列）&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-84bc4c997c2c0993ff360cd236cccd00058.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们需要搞清楚浏览器会开几个&lt;strong&gt;TCP 连接&lt;/strong&gt; ？哪些资源会挤在同一个连接中？因为同一个连接中的资源会互相争抢网络带宽 &lt;em&gt;。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;分辨方法是：&lt;strong&gt;h2 下同一个域名的资源会共用同一个 TCP 连接，http/1.1 下同一个域名可能会开多个 TCP 连接，资源们按顺序排队。&lt;/strong&gt; 所以上表中，所有 CDN 域下的资源共用同一个 TCP 连接，Server 域下只有一个资源，暂时只开一个 TCP 连接。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：说"暂时"是因为，后续可能会有动态加载 js、或者发起 ajax、fetch 请求，可能会增加 TCP 连接数量&lt;/em&gt;。&lt;/p&gt; 
&lt;p&gt;另外，下载优先级是由浏览器综合分析并自动分配的，我们无法直接指定优先级。并且不同版本浏览器的分配策略各异，但大多数情况下，会遵循如下规则：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;通过&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签加载的 js 脚本的优先级高于动态创建 script 的优先级。（动态创建例如：通过 appendChild 往 DOM 中插入一个&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签上没有加任何标记（module、async、defer）的，优先级最高&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签被标记了 type="module"的，优先级较高&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签被标记了 async、defer 的，优先级较低&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;值得说明的是，项目采用了 webpack 打包，其中 main.{hash}.js 就是 webpack 主入口文件，而 vendor~tinycloud 等文件均是分包策略拆出来的 chunks 们。&lt;/p&gt; 
&lt;h3&gt;2. 分析 Performance 数据&lt;/h3&gt; 
&lt;p&gt;接着，我们就要分析性能图了，我们的首要目标是：&lt;strong&gt;搞清楚性能图中各个环节在做什么，并将它跟初始化流程一一对应起来&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;2.1 分析映射关系：代码 &amp;lt;=&amp;gt; 性能图&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-530cd861d887e1ad7c8bc9d2653c55b1652.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;首先观察性能图中&lt;/strong&gt; &lt;strong&gt;Network（网络情况）、Main（CPU 情况）、Timings（我们预埋的 mark 标记） 这三个部分，尝试搞清楚图中每个时间段里面，浏览器在忙些什么。&lt;/strong&gt; 以上图为例，大致流程是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;时段 1：网络繁忙、CPU 空闲&lt;/li&gt; 
 &lt;li&gt;时段 2：网络空闲、CPU 繁忙&lt;/li&gt; 
 &lt;li&gt;时段 3：网络 CPU 都繁忙&lt;/li&gt; 
 &lt;li&gt;NG App 启动从时段 3 才开始&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;接下就是详细分析过程：&lt;/p&gt; 
&lt;p&gt;1）时段 1：静态资源下载&lt;/p&gt; 
&lt;p&gt;分析每一个请求，&lt;strong&gt;搞清楚它是谁发起的，在业务上有什么作用。&lt;/strong&gt; 点开一个资源条，就可以在 Summary 面板中看到它的一些基础信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PS：有时候，Summary 面板中写的 Initiated by 不一定是真实的发起者，真实发起者可能被层层代码封装隐藏了，我们需要到 Network 面板中的 Initiator 里面去找真实发起者&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a3c7cbd21ecc6c14548c8ac4a94131f21a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对时段 1 的所有请求进行分析之后，我们就搞清楚了这个阶段的具体情况，如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f856fc57c408f5a8fd85a12d0a8a1c0bf66.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;绿色部分由 console-ui 发起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首轮请求 (html 中通过 script 直接引用)：仅 consoleui.umd.js 这 1 个资源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;非首轮请求 (由某些逻辑动态发起)：5 个静态资源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt; ；若干 Fetch/XHR 请求 &lt;em&gt;（Server 域/http1.1）&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;红色部分由业务代码发起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首轮请求 (html 中通过 script 直接引用)：runtime、polyfill、......、main 等 11 个资源 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
   &lt;li&gt;非首轮请求 (由某些逻辑动态发起)：无&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;蓝色部分由 cc 组件（一个三方业务组件，负责一些特殊业务组件的实现）发起&lt;/em&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;首轮请求 (html 中通过 script 直接引用)：无&lt;/li&gt; 
   &lt;li&gt;非首轮请求 (由某些逻辑动态发起)：cc-main.js &lt;em&gt;（Server 域/http1.1）&lt;/em&gt; 及若干 main、theme 等 &lt;em&gt;（CDN 域/h2）&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;时段小结：&lt;/strong&gt; 这一时段主要是完成各种 HTTP 请求，主要有，业务代码、console-ui、cc 组件三方参与。首轮请求主要是业务代码的请求，采用 h2 协议，console-ui 及 cc 组件则多为非首轮请求。&lt;/p&gt; 
&lt;p&gt;这里其实可以看出来，业务代码发起的静态资源请求几乎独占首轮请求，其它请求均是在后续轮发起，不会影响业务静态资源请求的完成。并且所有 Fetch/XHR 请求都是使用 Server 域/http1.1，跟静态资源使用的 CDN 域/h2 是两个不同的 TCP 通道，不会影响业务静态资源的加载。&lt;/p&gt; 
&lt;p&gt;2）时段 2：webpack 代码展开&lt;/p&gt; 
&lt;p&gt;分析火焰图中每个色块，&lt;strong&gt;搞清楚它们是属于哪个代码文件的内容，它们在执行什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f3c7d14ad82421a30a7f4039d57fd5206f3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上一篇文章中介绍过，每个色块是一个函数，色块的名字是函数名，色块上下关系是函数调用关系，这一整个火焰图就是调用栈的直观展示。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查看色块归属：在上一篇文章中提到过，webpack 打包时会将 js 代码用匿名函数包裹，并指定一个数字 key，所以就产生了这些数字命名的函数。点击色块可以看到它属于哪个代码文件。&lt;/li&gt; 
 &lt;li&gt;查看色块在做什么：查看这个 task 的火焰图的栈底，会发现全是黄色的 Compile code 块，说明在编译代码（V8 引擎的&lt;strong&gt;惰性编译&lt;/strong&gt;策略）&lt;/li&gt; 
 &lt;li&gt;整个展开动作的起点：等待初始 chunk 全都下载完之后，才开始代码展开。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;时段小结：&lt;strong&gt;这一时段主要在做 webpack 的代码展开，CPU 在忙着编译、执行被 webpack 打包的代码&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这里需要对 webpack 打包产物有一定了解，才能透彻了解这个过程，简要说明如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6ef372a96036827fc1e8b735a85c41bbdc.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;标题中所谓的 webpack 代码展开，其实就是执行这些数字命名的包裹函数，而 V8 引擎的惰性编译策略，可能不会在流式下载文件的环节就直接编译这些代码，所以栈底全都是 compile code 的色块。另外，webpack 的启动机制会保证所有 chunk 下载完成后，才启动代码展开工作，从，时段 1 =&amp;gt; 时段 2 的衔接点可以看到，虽然主 chunk 文件 main.xxxx.js 早已下载完成，但代码没有立即展开，而是等待最后一个 chunk 下载完成之后，才进行展开。&lt;/p&gt; 
&lt;p&gt;3）时段 3：动态下载语言包等主题资源&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0a5fe58ed00d0da5302a12c999661171d3a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;利用时段 1 提到的分析方法，对时段 3 的请求也做同样的分析可知：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;主要是语言包、主题资源包、docs 等通用资源的下载，主要使用 &lt;strong&gt;CDN 域/h2&lt;/strong&gt; 的通道。&lt;/li&gt; 
 &lt;li&gt;均是由业务代码发起。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;利用时段 2 提到的分析方法，对时段 3 的火焰图的各个色块也进行同样的分析可知：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;一些由微任务或定时器，唤起的 console-ui 逻辑被执行&lt;/li&gt; 
 &lt;li&gt;一些 cc 组件逻辑被执行&lt;/li&gt; 
 &lt;li&gt;还存在着若干空闲 task 时间&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同时，从 Timings 面板可以看出，在 webpack 代码展开之后、时段 3 开始之前，NG App 就已经 boot 了，但是在时段 3 结束后，根组件才开始 construct。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;为什么 angular 的 app 已经开始 boot 了，但根组件没有尽快 construct？并且这中间还有空闲的 CPU 时间。&lt;/strong&gt; 这里需要结合代码实现来分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;该页面支持多语言，为了不一窝蜂的下载所有语种的资源包，代码中采用按需下载的模式：仅在确认了当前语种之后，才开始下载该语种的资源包。&lt;/li&gt; 
 &lt;li&gt;代码中利用 angular router 的路由守衞，在守衞中异步下载当前语种对应的资源包。angular router 会确保根组件在守衞完成后再开始 construct。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以，&lt;strong&gt;问题的答案是：根组件在等待资源包的下载完成&lt;/strong&gt;。从图中也可以看出，根组件 construct 是在 docs 接口完成之后的第 1 个 task 中进行的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;时段小结：&lt;/strong&gt; 这一时段主要是下载当前语种对应的资源包，而这些资源包是根组件 construct 的前提条件（因为路由守衞的原因） 。&lt;/p&gt; 
&lt;p&gt;而在资源下载期间，CPU 被用于执行一些 console-ui、cc 组件等非业务逻辑，或者直接空闲。因为在这期间，也没有业务逻辑代码可供执行了。&lt;/p&gt; 
&lt;p&gt;4）时段 4：关于时段 3 之后&lt;/p&gt; 
&lt;p&gt;从 Timings 面板中可知，在时段 3 之后、特别是根组件 construct 之后，根组件 afterViewInit、列表组件的 construct 和 afterViewInit 都紧锣密鼓的执行起来了。这一段 CPU 极其繁忙，按生命周期顺序执行各个组件的初始化，直到列表组件的 afterViewInit 完成后，列表页主内容区域才展示出来。&lt;/p&gt; 
&lt;p&gt;针对这种任务密集时段，我们当然也可以用时段 2 中提到的分析方法，针对火焰图中各个色块进行分析。但从生产环境录制的性能图中看到的色块名（函数名）可能都是混淆之后的结果，不利于跟源码对应起来。此时，我们可以针对本地调试环境（localhost）录制性能图并进行分析，因为代码执行在火焰图上的表现，往往不会受到环境的影响。例如该时段中有这么一段：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a7933d7131f8b4ac6d3e7e541c11a2d67c3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看出&lt;strong&gt;有一段结构很相似的调用，出现了多次重复&lt;/strong&gt;。从 localhost 环境抓取的性能图中就可以明显看出，这段重复执行的是 detectChangesInEmbeddedViews 函数，它是 angular 的内部函数。在嵌入式视图场景中，如果有大量 ngFor、ngIf 就会触发。通过源码分析，这一段正是导航组件中的代码实现造成的。&lt;/p&gt; 
&lt;h4&gt;2.2 在性能图中找问题&lt;/h4&gt; 
&lt;p&gt;通过上一节中对性能图透彻分析之后，我们已经能将性能图跟源码对应起来，并且能将性能图跟加载流程对应起来，同时对一些关键节点心中有数。接下来要做的就是找问题、找可优化的空间，以达到我们的目标。例如针对&lt;strong&gt;VPC 列表页&lt;/strong&gt;的分析可知，主渲染流程在性能图中大致是：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ca6f1403a8367bd6712beeba540618d7a52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了实现目标，我们至少可以找到以下优化点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下载静态资源能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;非重要模块，改为懒加载（按需动态 import），减少初始 chunk 的体积&lt;/li&gt; 
   &lt;li&gt;较大的图片资源等，避免打包成 base64 字符串，减少 chunk 体积&lt;/li&gt; 
   &lt;li&gt;合理拆分 chunk 包，避免有一个独大的 chunk，充分利用 h2 的并行下载效果&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;webpack 代码展开能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;减少初始 chunk 的体积。需要展开的代码少了，展开的自然更快&lt;/li&gt; 
   &lt;li&gt;避免在代码中执行长耗时运算等&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下载语言包资源能否更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;语言包资源提前下载，和前面的静态资源一起下载。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;组件生命周期能否执行的更快？&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;削减高频重复执行的 detectChangesInEmbeddedViews 函数的执行次数。&lt;/li&gt; 
   &lt;li&gt;减少非必要的渲染内容。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;总体上看，不同的项目会有不同的性能图和性能瓶颈点，通用的优化方案可以解决一些常规问题，但当所有常规方案做完之后效果还是不够满意时，我们可能得进行针对性的分析来查找问题。通过深入性能图分析，搞清楚 &lt;strong&gt;代码&amp;lt;=&amp;gt;性能图&lt;/strong&gt; 之间的映射关系之后，我们就能轻松找到性能瓶颈点，从而找对应的解决方案了。&lt;/p&gt; 
&lt;h2&gt;四、总结&lt;/h2&gt; 
&lt;p&gt;通过 Performance 面板录制页面加载性能图并进行性能分析，是每一个 frontend developer 进阶的必备技能之一。性能图分析除了要求我们掌握 Performance 面板的基本用法之外，还要求我们对前端相关知识例如：webpack 工程打包、浏览器的加载运行、HTTP 协议机制、前端框架的原理、等都有一定了解，同时要求我们对项目代码的结构和执行流程足够清晰明确。常规的优化方案往往只能解决一些初级、普遍的问题，但每个页面有每个页面的具体情况，只有对页面进行充分分析之后，才能搞清楚页面的性能优化点在哪里，从而有条不紊的落地实施。&lt;/p&gt; 
&lt;h2&gt;关于 OpenTiny&lt;/h2&gt; 
&lt;p&gt;欢迎加入 OpenTiny 开源社区。添加微信小助手：opentiny-official 一起参与交流前端技术～&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design%2F" target="_blank"&gt;OpenTiny 官网&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design" target="_blank"&gt;https://opentiny.design&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;OpenTiny 代码仓库&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;https://github.com/opentiny&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank"&gt;TinyVue 源码&lt;/a&gt;：&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-vue" target="_blank"&gt;https://github.com/opentiny/tiny-vue&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank"&gt;TinyEngine 源码&lt;/a&gt;： &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny%2Ftiny-engine" target="_blank"&gt;https://github.com/opentiny/tiny-engine&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;欢迎进入代码仓库 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~ 如果你也想要共建，可以进入代码仓库，找到 good first issue 标签，一起参与开源贡献~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6769809/blog/18688293</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/18688293</guid>
      <pubDate>Mon, 18 Aug 2025 08:16:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>德国联邦最高法院裁定重审广告拦截插件版权争议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;德国联邦最高法院近日的一项判决，再次引发了关于浏览器广告拦截插件是否涉及版权侵权的讨论。&lt;/p&gt; 
&lt;p&gt;此次争议源于媒体企业 Axel Springer 对知名广告拦截工具 Adblock Plus 的开发公司 Eyeo 提起的诉讼。Axel Springer 认为，&lt;strong&gt;广告拦截插件影响了其网站的广告收益，并指出插件在浏览器中运行的行为构成了对版权的侵犯&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-71b1d139ef15730853dfeb32e23ec627176.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该观点的核心在于，&lt;strong&gt;网站所使用的 HTML 和 CSS 代码被认为是一种受版权保护的计算机程序，而广告拦截插件在运行过程中修改了浏览器的执行结构，例如文档对象模型（DOM）、样式表对象模型（CSSOM）以及页面渲染树，这被解读为未经授权的复制与更改&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在此之前，汉堡的初级法院并未支持 Axel Springer 的主张，但此次联邦最高法院的裁决认为，此前的判决存在不足之处，因此推翻了部分决定，并将案件发回进行进一步审理。&lt;/p&gt; 
&lt;p&gt;Mozilla 公司负责知识产权和产品事务的高级顾问 Daniel Nazer 对此表示，由于这一案件涉及复杂的技术背景，法院的相关决定可能会对其他浏览器扩展产生影响，甚至影响用户在使用浏览器时的选择自由。&lt;/p&gt; 
&lt;p&gt;他指出，用户希望通过浏览器或插件修改网页内容的原因多种多样，例如提升页面可访问性或增强隐私保护等。因此，此类司法裁决可能带来更广泛的影响。&lt;/p&gt; 
&lt;p&gt;根据德国联邦最高法院的最新裁决，需要重新评估 HTML、CSS 以及相关代码是否属于受保护的程序类型，以及广告拦截插件的行为是否构成合法使用。&lt;/p&gt; 
&lt;p&gt;尽管目前广告拦截插件尚未被明确裁定为非法，但 Axel Springer 与 Eyeo 之间的案件现已重启审理。Nazer 表示，整个法律程序可能仍需数年时间才能最终尘埃落定。&lt;/p&gt; 
&lt;p&gt;在最终结论出台前，此案可能已在技术社区引发担忧情绪。一些浏览器和插件开发者或会出于风险控制考虑，主动限制其产品的功能范围，以避免陷入类似的法律纠纷之中。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367401</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367401</guid>
      <pubDate>Mon, 18 Aug 2025 08:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Jarboot 3.3.0 发布，Java 启动器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Jarboot 3.3.0 已经发布，Java 启动器。&lt;/p&gt; 
&lt;h2&gt;3.3.0（8，2025）&lt;/h2&gt; 
&lt;p&gt;修复已知的 bug，修复已知的 bug，推出 docker compose 部署策略，文件上传 websocket 服务（/jarboot/upload/ws）传入参数格式修改（json 字符串 base64 url 编码）&lt;/p&gt; 
&lt;h3&gt;新特性&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;启动时支持通过环境变量初始化账号（JARBOOT_USER）和密码（JARBOOT_DEFAULT_PWD）&lt;/li&gt; 
 &lt;li&gt;服务配置新增是否自动启动配置项，配置自启动时在 jarboot 启动后会自动启动该服务&lt;/li&gt; 
 &lt;li&gt;可通过-Dstart.wait.time=30000 指定最大的启动等待时间&lt;/li&gt; 
 &lt;li&gt;client-cli 支持通过 token 登录，可通过环境变量或-token 参数传入&lt;/li&gt; 
 &lt;li&gt;新增 docker compose 集群及单节点的配置文件示例&lt;/li&gt; 
 &lt;li&gt;新增软件升级脚本，可通过脚本一键升级 jarboot，执行&lt;code&gt;bin/upgrade.sh&lt;/code&gt;或&lt;code&gt;bin/windows/upgrade.bat&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;新增软件升级功能，可在界面上点击升级，选择安装包或安装包下载连接，可一键升级&lt;/li&gt; 
 &lt;li&gt;新增定时重启服务配置，可使用 CRON 表达式配置重启计划&lt;/li&gt; 
 &lt;li&gt;.env 文件支持，可通过工作目录下的.env 文件配置环境变量&lt;/li&gt; 
 &lt;li&gt;服务配置界面增加提示信息，鼠标移到提示信息图标上可查看更多帮助信息&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;bug 修复&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;打印日志太多时异常掉线问题，The remote endpoint was in state [BINARY_FULL_WRITING] which is an invalid state for called method&lt;/li&gt; 
 &lt;li&gt;集群模式下文件上传到另一节点时，服务名为中文时上传文件失败问题&lt;/li&gt; 
 &lt;li&gt;修复使用 docker compose 集群模式下节点认证失败问题&lt;/li&gt; 
 &lt;li&gt;断开重连时新增 cookie 校验功能，校验失败则退出登录&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href="https://gitee.com/majz0908/jarboot/releases/3.3.0"&gt;https://gitee.com/majz0908/jarboot/releases/3.3.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367399</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367399</guid>
      <pubDate>Mon, 18 Aug 2025 07:55:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Databricks 将融资 10 亿美元，估值达 1000 亿</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 即将完成新一轮融资，估值达 1000 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;一位知情人士独家向 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F08%2F19%2Fdatabricks-ceo-says-fresh-1b-will-help-him-attack-a-new-ai-database-market%2F" target="_blank"&gt;TechCrunch&lt;/a&gt; 透露，新一轮融资规模约为 10 亿美元，并获得了大幅超额认购。据该消息人士透露，Databricks 之所以没有进一步出售股权，是因为该公司在 1 月份以 620 亿美元的估值完成了创纪录的 100 亿美元融资后，不再需要现金来维持运营。（OpenAI 随后在 3 月份以 400 亿美元的融资刷新了纪录。）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;本轮融资由 Thrive 和 Databricks 的早期投资者之一 Insight Partners 共同领投。这两家公司也领投了上一轮融资。自 2013 年成立以来，Databricks 已筹集约 200 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="284" src="https://oscimg.oschina.net/oscnet/up-2cd515f46a14f00391e4d39140096978f76.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据接近该公司的消息人士称，Databricks 已在 2025 年为员工进行了两轮 secondary rounds。这些次轮融资允许员工出售最多 40%、50% 或 60% 的股份，具体取决于其持股规模。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息人士称，在这两起案例中，第二轮融资的可用资金均未用完，这意味着员工持有的股票数量超过了他们本可以出售的股票数量。虽然 Databricks 显然并不急于 IPO，但员工们最近已经有两次套现的机会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，Databricks 联合创始人兼首席执行官 Ali Ghodsi 在接受采访时表示，新一轮融资是为了开展两个具体项目—— AI agent&amp;nbsp;数据库及其 AI agent&amp;nbsp;平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该公司将大力投资其 AI agent&amp;nbsp;数据库，使其普遍可供所有客户使用。Ghodsi 表示：「数据库市场的 TAM（总潜在市场）和收入规模达到 1050 亿美元，在过去 40 年里基本没有受到影响」，巧妙地暗示了数据库巨头甲骨文几十年来一直牢牢占据着市场主导地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「这里有一个有趣的统计数据，但没人关注：一年前，我们在数据中看到，30% 的数据库不是由人类创建的。这是第一次，它们是由 AI agent&amp;nbsp;创建的。而今年，这个数字是 80%」。他预测，这一数字将在一年内上升到 99% 的新数据库。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「现在有了一个新用户。这个用户不是人类，而是一个 AI agent。如果我们加倍努力让这个用户角色取得成功，那么这就是打破潜在市场（TAM）的契机。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;至于 Lakebase 与 Supabase 以及其他已经为代理构建基于 Postgres 的数据库的区别，Ghodsi 表示关键在于「计算和存储分离」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;通过将昂贵的计算与低成本的存储分离开来，Databricks 可以让用户以可承受的价格创建多个数据库。「因为这些代理速度超快。它们可以快速启动大量数据库，速度比人类快得多，但你肯定不想因为这样做而破产。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 将大力投资的第二个项目是&amp;nbsp;AI agent 平台 Agent Bricks，该平台也于 6 月上线。 「每个人都非常关注超级智能。但这并不是我们组织所需要的。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司需要的不是 AI 的普通数学天才或癌症治疗科学家，而是能够可靠地处理独立日常任务的代理，例如员工入职培训或回答有关人力资源福利的个性化问题。「我认为这实际上对全球 GDP 和各组织来说都是一个更大的机遇」。他相信，这种专注将为 Agent Bricks 带来竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他还筹集了额外的资金，以便 Databricks 能够参与 AI 人才挖角大战。「你知道，现在招聘 AI 人才的成本相当高。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367398</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367398</guid>
      <pubDate>Mon, 18 Aug 2025 07:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Reddit 季度收入创历史新高，得益于人工智能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;Reddit 依托其独特的小众社区文化和活跃的问答氛围，正在人工智能（AI）领域实现盈利增长。该平台的&lt;span&gt;最大&lt;/span&gt;资产在于其用户生成的真实内容，这一优势让 Reddit 在与大型科技公司合作时，占据了有利位置。公司通过 AI 授权，将平台上的子版块内容整合入搜索引擎结果中，显著提升了网站流量，并为广告主提供了精准的目标受众。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-4397aa3bf8abe3165b1b0cc3c7e0843e093.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近年来，Reddit 在财务业绩方面屡次超越市场预期，用户每位收入（ARPU）增长速度远远快于其他社交媒体平台。这一趋势推动了 Reddit 股票的上涨，令其市场估值达到新高。随着投资者对 Reddit 未来增长的信心增强，该公司的股票在过去三个月内上涨了 123%，年内涨幅更是超过 344%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;分析师们对 Reddit 的盈利前景持续看好。数据显示，Reddit2025 年的每股收益（EPS）预期从最初的 1.14 美元上调至 1.86 美元，增幅达 63%。此外，2026 年和 2027 年的 EPS 预期也有所上升，分别增长了 31% 和 14%。这表明市场对红迪网的长远发展充满信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的快速增长得益于其在人工智能整合和数据授权方面的成功。最近发布的 「Reddit 问答」 搜索引擎大大提高了用户互动和流量，带动了广告支出的显著增加，用户每位收入年增长率达到 47%。这一成果超出了行业内对其逐步发展的预期。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Reddit 的竞争优势在于其丰富的用户数据和问答文化，结合 AI 技术，使得每一条内容不仅具有高价值，还能与广告信息无缝对接。这种独特的 「防御性」 网络效应，让其他社交平台难以复制 Reddit 的成功模式，帮助其在 AI 应用上走在了行业前列。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 Reddit 目前的市盈率较高，投资者仍然看好其市场前景。分析师们对 Reddit 的股票保持普遍乐观，虽然有少数持谨慎态度的观点，但整体市场支持度依然强劲。只要 Reddit 能够持续保持良好的增长趋势，其股票溢价便是合理的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367390</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367390</guid>
      <pubDate>Mon, 18 Aug 2025 07:24:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
