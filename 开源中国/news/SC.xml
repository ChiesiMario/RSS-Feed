<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 30 Jul 2025 16:50:29 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>微软封禁 LibreOffice 开发者的 Hotmail 账号</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，LibreOffice 开发者 Mike Kaganski 的微软 Hotmail 邮箱账号&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neowin.net%2Fnews%2Fmicrosoft-bans-libreoffice-developers-account-without-warning-rejects-appeal%2F" target="_blank"&gt;被封禁&lt;/a&gt;，理由是「违反了微软的服务协议」。&lt;/p&gt; 
&lt;p&gt;事件起因是 Kaganski 在使用 Thunderbird 邮件客户端向 LibreOffice 开发者邮件列表发送技术邮件时，邮件无法发送，随后他的微软账号被封锁，且无法登录。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c7ca38626be574a8f6b00ac850427dd3382.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Kaganski 表示，他确信邮件内容并未违反微软的服务协议，推测可能是某个自动化系统错误地标记了他的账户。他介绍了在申诉过程中遇到的诸多障碍：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;自动申诉系统&lt;/strong&gt;：系统要求他提供手机号码进行验证，但他输入手机号码后收到「尝试其他方法」的错误提示，而系统并未提供其他验证方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;联系支持团队&lt;/strong&gt;：微软的联系页面要求先登录才能联系支持团队，但 Kaganski 的账号已被封锁，无法登录。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;通过妻子账号申诉&lt;/strong&gt;：他最终通过妻子的账号提交了申诉，但微软支持团队的回复只是让他再次尝试登录并提供手机号码，这与他之前尝试过的方法并无二致。微软在没有采取任何实质性措施的情况下，直接将他的申诉标记为「已解决」并关闭了申诉。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d88cd85757e8270fc2ab5786489a31ea266.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;截至 7 月 30 日，Kaganski 的微软账号仍未恢复。他最终通过 Gmail 成功发送了邮件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363224</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363224</guid>
      <pubDate>Wed, 16 Jul 2025 12:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 内核社区正在讨论关于「AI 生成代码」的新提案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;资深 Linux 开发者、NVIDIA 员工 Sasha Levin（此前曾就职于 Google 和微软）兼 Linux LTS 内核联合维护者提出了 Linux 内核 AI 编程助手的配置方案和文档/规则，供开发者使用由 AI 编码实用程序（共同）编写的补丁为 Linux 内核做出贡献。&lt;/p&gt; 
&lt;p&gt;Sasha Levin 不久前发出了一份 RFC，&lt;strong&gt;提议在 Linux 内核文档区引入一个 AI 编码助手配置文件，供 Claude 等 AI 编码助手进行解读&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-690d9dc6b25d0b1cae4cb9a383ac69c9d55.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外他还提出了一套初步的 Linux 内核贡献规则，其中包含 AI 归属要求和其他详细信息，供希望借助 Claude 和 Grok 等 AI 助手为上游 Linux 内核做出贡献的开发者参考。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1638" src="https://static.oschina.net/uploads/space/2025/0730/200208_NXuG_2720166.png" width="2302" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Sasha Levin 在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Fall%2F20250725175358.1989323-1-sashal%40kernel.org%2F" target="_blank"&gt;RFC 补丁系列&lt;/a&gt;中解释道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;该补丁系列为使用 Linux 内核代码库的 AI 编码助手添加了统一的配置和文档。随着 AI 工具在软件开发中变得越来越普遍，为它们在内核开发中的使用制定清晰的指南非常重要。&lt;/p&gt; 
 &lt;p&gt;该系列包含两个补丁：&lt;/p&gt; 
 &lt;p&gt;1. 第一个补丁为各种 AI 编码助手（Claude、GitHub Copilot、Cursor、Codeium、Continue、Windsurf 和 Aider）添加了统一的配置文件。这些都符号链接到一个中央文档文件，以确保跨工具的一致性。&lt;/p&gt; 
 &lt;p&gt;2.. 第二个补丁添加了指导 AI 助手进行 Linux 内核开发实践的实际规则和文档，包括：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;遵循内核编码标准&lt;/li&gt; 
  &lt;li&gt;尊重开发过程&lt;/li&gt; 
  &lt;li&gt;正确归属 AI 生成的贡献&lt;/li&gt; 
  &lt;li&gt;理解许可要求&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;以下示例演示了这些指南在实践中是如何运作的，展示了提交中正确的 AI 归属以及助手对内核文档要求的理解。&lt;/p&gt; 
 &lt;p&gt;所有 AI 助手都必须使用 Co-developed-by 标签在提交中标识自己，以确保 AI 参与代码开发的完全透明。」&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363222</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363222</guid>
      <pubDate>Wed, 16 Jul 2025 12:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英特尔资深 Linux 内核工程师加入 Meta</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Meta 已经拥有一支全明星 Linux 内核工程师团队，而且他们似乎仍在招募顶级 Linux 内核人才。&lt;/p&gt; 
&lt;p&gt;长期担任英特尔 Linux 内核工程师的 Kirill Shutemov 作为信任域扩展 (TDX) 的维护者为英特尔对 Linux 内核的贡献不可低估，这对他们在 Xeon 上的机密计算至关重要，他还参与了线性地址空间分离 (LASS) 和许多其他 Linux 内核内存管理相关功能。&lt;/p&gt; 
&lt;p&gt;两周前离开英特尔后，Shutemov 公开宣布他现在受雇于 Meta，担任伦敦的 Linux 内核软件工程师。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4f705edc8f6648e7a903fda69788e7e2a05.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他的个人邮箱地址显示他仍然是 Linux 内核中英特尔信任域扩展代码的上游维护者。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1448" src="https://static.oschina.net/uploads/space/2025/0730/195000_IDBG_2720166.png" width="1534" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他现在在 Meta 担任 Linux 内核软件工程师，与日益壮大的 Linux 内核开发者和维护人员团队并肩工作。这对于整个开源社区来说无疑是一大胜利，希望 Shutemov 对 Linux 内存管理和内核其他领域的贡献能够持续下去，且 Meta 不会与任何特定的芯片供应商绑定。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363220</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363220</guid>
      <pubDate>Wed, 16 Jul 2025 11:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源视频编辑器 OpenCut 收到超过 12 万行代码的 PR</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源视频编辑器&amp;nbsp;OpenCut 作者在社交媒体分享了该项目收到的一个「巨大」 PR：一名开发者向&amp;nbsp;OpenCut 贡献了超过 12 万行代码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77035b3dbda9f40e56a4dae456026a14987.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从提交信息来看，这个 PR 应该是开发者 Vibe Coding 的「成果」——因为大部分 commits 都有 Claude Code 的头像。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-951280606a50bf6cf90b63adca47f588285.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外这个 PR 的内容出奇地少，虽然它包含超过 12 万行代码，但其中大部分是 AI 生成的文档（86K 行，68%），以及 9K 行 AI 生成的测试（7%），所以实际代码只有 32K 行（25%）。&lt;/p&gt; 
&lt;p&gt;更不用说那糟糕的文档了，大部分感觉像是从 LLM 会话中的复制粘贴。&lt;/p&gt; 
&lt;p&gt;围观地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenCut-app%2FOpenCut%2Fpull%2F479" target="_blank"&gt;https://github.com/OpenCut-app/OpenCut/pull/479&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363213</guid>
      <pubDate>Wed, 16 Jul 2025 11:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 芯片新贵 Groq 融资临近，估值飙升至 60 亿美金</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AI 芯片创业公司 Groq 正处于一轮新的融资谈判中，预计将筹集 6 亿美元资金，估值接近 60 亿美元。根据彭博社的消息，这项交易尚未最终敲定，具体条款可能会有所变动。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="268" src="https://oscimg.oschina.net/oscnet/up-792d436049d6eee6319309b8c7cd56c22be.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Groq 在 2024 年 8 月时成功筹集了 6.4 亿美元，当时的估值为 28 亿美元，短短一年间，公司的估值几乎翻了一番。此前，Groq 共计筹集了约 10 亿美元的资金。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次融资由位于德克萨斯州的投资公司 Disruptive 领投。值得一提的是，去年 11 月的融资由黑石集团（BlackRock）主导，同时也得到了 Neuberger Berman、Type One Ventures、思科 (Cisco)、KDDI 以及三星催化基金等多家机构的参与。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Groq 成立于 2016 年，由曾在谷歌开发 Tensor 处理单元芯片的 Jonathan Ross 创办。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;本轮融资的背景是，Groq 在 5 月份与加拿大贝尔公司（Bell Canada）达成独家合作，旨在推动其大型 AI 基础设施项目。此外，在 4 月份，Groq 还与 Meta 公司达成了合作，为后者提供 AI 基础设施，以加速 Llama4 的推理能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363210</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363210</guid>
      <pubDate>Wed, 16 Jul 2025 10:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 回应 10 亿美元挖人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;《连线》杂志报道，Meta CEO 马克・扎克伯格正在全力为其新成立的&lt;span&gt;超级&lt;/span&gt;智能实验室招募&lt;span&gt;顶尖&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 人才。尽管扎克伯格已经成功挖走了多名 OpenAI 的&lt;span&gt;顶尖&lt;/span&gt;研究员，但他的新目标则是穆拉蒂创办的 AI 公司 Thinking Machines Lab（TML）的员工。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据悉，穆拉蒂的新公司现有 50 名员工，但 Meta 已经与超过 12 名员工接触，甚至提供了丰厚的薪酬报价。某些报价总额超过 10 亿美元，为期数年，而其他报价则在 2 亿至 5 亿美元之间，分四年支付。Meta 甚至承诺，加入&lt;span&gt;第一&lt;/span&gt;年的薪酬就能高达 5000 万至 1 亿美元。然而，至今尚无人愿意接受这些诱人的邀约。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="299" src="https://oscimg.oschina.net/oscnet/up-8e03f375e3692f7957f2783333ac415f68f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;对此，Meta 通讯总监 Andy Stone 在声明中表示，虽然有部分员工收到高额薪酬报价，但报道的细节存在失实之处。他质疑此类报道的背后动机，并强调 Meta 只向少数 TML 员工发出邀约。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;扎克伯格的招募策略颇具个人特色。他最初通过 WhatsApp 与潜在招募对象联系，随后迅速安排面试，包括与自己及其他高管的长时间对话。扎克伯格向受邀者表示，Meta 希望打造&lt;span&gt;世界级&lt;/span&gt;的 AI 助手，为每位用户提供有价值的 AI 服务。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 Meta 在构建前沿 AI 模型方面落后于一些小型竞争对手，但其计划通过开源策略来削弱 OpenAI 的市场地位。Meta 希望通过发布竞争性的开源模型，将 AI 技术商品化，尽管这一路径充满挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不过，Meta 的高薪招募策略为何屡屡失利呢？一些知情人士透露，尽管扎克伯格已成功招募近 24 人，但领导风格和团队氛围却成为了不少&lt;span&gt;顶尖&lt;/span&gt;人才的顾虑。此外，Meta 的产品路线图似乎未能打动许多人，尤其是与 OpenAI 等公司的使命相比。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TML 刚完成了历史上&lt;span&gt;最大&lt;/span&gt;的一轮融资，估值高达 120 亿美元，研究人员并不需要在理想和金钱之间做选择。对他们而言，选择留在这样一家有潜力的公司无疑是更具吸引力的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363209</guid>
      <pubDate>Wed, 16 Jul 2025 10:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>《中国人工智能安全承诺框架》发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 世界人工智能大会暨人工智能全球治理高级别会议「人工智能发展与安全」全体会议 7 月 26 日下午在上海召开。会议由中国人工智能发展与安全研究网络（以下简称「研究网络」，CnAISDA）主办。上海市委常委、常务副市长吴伟，国家发展和改革委员会创新驱动发展中心主任霍福鹏出席并致辞。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;杰弗里・辛顿、姚期智、约书亚・本吉奥和大衞・帕特森 4 位图灵奖得主&lt;/strong&gt;，以及 20 多位国内外顶尖专家出席会议，共同探讨人工智能安全发展、缩小智能鸿沟等前沿议题，积极寻求人工智能安全治理国际合作路径。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7cef0e7074e44eea0bd5ccd53b80704e958.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;中国信息通信研究院（简称「中国信通院」）院长、中国人工智能产业发展联盟（AIIA）秘书长余晓晖受邀参与对话，牵头与清华大学、上海人工智能实验室、中国电子信息产业发展研究院等单位的代表一起发布《&lt;strong&gt;中国人工智能安全承诺框架&lt;/strong&gt;》。&lt;/p&gt; 
&lt;p&gt;该《框架》在 AIIA《人工智能安全承诺》（2024 年 12 月发布）的基础上，&lt;strong&gt;新增了加强人工智能安全治理国际合作、防范前沿人工智能安全风险等内容&lt;/strong&gt;，体现了中国产业界愿与全球各方紧密携手，共促人工智能向善发展的坚定决心和开放态度。&lt;/p&gt; 
&lt;p&gt;下一步，中国信通院作为「研究网络」成员和 AIIA 秘书处单位，将与签署企业携手，&lt;strong&gt;通过披露行动、测试验证等方式，推动《框架》的落地实践&lt;/strong&gt;，促进我国人工智能朝着有益、安全、公平方向健康有序发展，并积极开展国际治理合作，为全球人工智能安全治理贡献中国智慧和中国力量。&lt;/p&gt; 
&lt;p&gt;附《框架》中英文全文：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;中国人工智能安全承诺框架&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;CHINA ARTIFICIAL INTELLIGENCE SECURITY AND SAFETY COMMITMENTS FRAMEWORK&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;人工智能浪潮席卷全球，积极释放技术价值红利，对全球经济社会发展和人类文明进步产生深远影响。我们也清晰认知到，人工智能带来难以预知的各种风险挑战。为把握新一轮发展机遇，中国人工智能发展与安全研究网络成员郑重发起《中国人工智能安全承诺框架》，通过产业自律，以高水平安全保障高质量发展，协力共促人工智能稳健发展。此事由中国信息通信研究院牵头推进。我们深知，自律承诺是获得社会信任的关键要素，我们将以本承诺作为行动守则，接受社会各界监督，不断提升优化，促进人工智能技术应用以人为本，智能向善。&lt;/p&gt; 
 &lt;p&gt;The wave of artificial intelligence (AI) is sweeping across the globe, actively generating technological dividends and exerting profound influence on global economic and social development as well as the progress of human civilization. At the same time, we are keenly aware that AI brings about unpredictable risks and complex challenges. To seize this new round of development opportunities, members of China AI Safety and Development Association (CnAISDA) solemnly launch the AI Security and Safety Commitments. Through industry self-regulation, we will leverage high-level security and safety measures to support high-quality development, and collaborate to promote the robust development of AI. This initiative is led and promoted by the China Academy of Information and Communications Technology (CAICT). We fully recognize that commitments to self-discipline constitute a critical foundation for gaining the trust of the international community. Guided by the Commitments as our code of conduct, and subject to the oversight of all stakeholders, we will continuously improve and refine our approach. By doing so, we will ensure that the application of AI technologies always remains people-centered and aligned with the principle of AI for good.&lt;/p&gt; 
 &lt;p&gt;承诺一：设置安全团队或组织架构，构建安全风险管理机制。内部设有专业团队负责开展人工智能风险评估、安全治理等工作，明确安全负责人。主动设定符合实际需求的安全风险基线，开源时采取相应的安全措施，开展贯穿人工智能开发部署全生命周期的风险管理，明确风险识别和应对流程及措施。&lt;/p&gt; 
 &lt;p&gt;Commitment I: Establish security and safety teams or organizational structures and build security and safety risk management mechanisms. Designate a leader responsible for AI security and safety, establish specialized teams to conduct AI risk assessments and safety, security and governance within the enterprise. Proactively define realistic security and safety risk baselines, adopt appropriate security and safety measures for open-source initiatives, and implement risk management practices throughout the entire AI development and deployment life cycle. Clearly outline processes and measures for risk identification and mitigation.&lt;/p&gt; 
 &lt;p&gt;承诺二：开展模型安全测试，提升模型效果与安全可靠性。通过专业性的仿真测试团队，在发布、更新人工智能模型之前对其进行红队测试。对于大模型，重点围绕其通用理解、推理和决策能力，以及其在工业、教育、医疗、金融、法律等场景下表现出的能力开展安全性和可靠性测试。&lt;/p&gt; 
 &lt;p&gt;Commitment II: Conduct security and safety testing for AI models to enhance the performance, safety and reliability. Through dedicated simulation and red-teaming experts, rigorously test AI models prior to their release or update. For large models in particular, prioritize safety and reliability evaluations focusing on their general understanding, reasoning, and decision-making capabilities, as well as their performance in critical domains such as industry, education, healthcare, finance, and law.&lt;/p&gt; 
 &lt;p&gt;承诺三：采取措施保障训练数据和业务数据安全。制定数据安全防护制度，配套建立防护技术措施，发现并及时处置数据投毒的情况，把控训练数据的准确性与可靠性。对业务数据进行加密存储与访问控制，确保商业秘密、用户隐私及用户上传的知识库仅在授权下访问，不被人工智能模型非法输出，保障数据安全与隐私权益。&lt;/p&gt; 
 &lt;p&gt;Commitment III: Implement measures to safeguard the security of training data and operational data. Establish data security protection policies and deploy corresponding technical measures to detect and promptly address data poisoning incidents, ensuring the accuracy and reliability of training data. Encrypt operational data and enforce access controls to protect business secrets, user privacy, and user-uploaded knowledge base, ensuring access is restricted to authorized use only. Prevent unauthorized outputs by AI models, thereby safeguarding data security and privacy rights.&lt;/p&gt; 
 &lt;p&gt;承诺四：提升基础设施安全。建立人工智能系统部署的软硬件安全监测和防护能力，实施定期和动态的安全渗透测试，模拟各种潜在的风险场景，识别并报告环境中的安全隐患，研判可能导致的各种风险。建立基础设施安全应急响应机制，包括应急处理流程、责任分配以及事后改进方案。&lt;/p&gt; 
 &lt;p&gt;Commitment IV: Enhance infrastructure security. Develop robust capabilities for monitoring and protecting the software and hardware used in AI system deployments. Conduct regular and dynamic security penetration tests to simulate potential risk scenarios, identify and report security vulnerabilities in the infrastructure, and assess associated risks. Establish an infrastructure security incident response mechanism, including emergency response procedures, clear accountability assignments, and post-incident improvement solutions.&lt;/p&gt; 
 &lt;p&gt;承诺五：增强模型透明度。主动披露安全治理实践举措，提升对各利益攸关方的透明度。公开披露模型的功能、适用领域以及局限性。通过模型说明、服务协议等方式，向公众披露可能涵盖的风险。&lt;/p&gt; 
 &lt;p&gt;Commitment V: Enhance model transparency. Proactively disclose safety and security governance measures and improve transparency for all stakeholders. Provide clear information about the model's capabilities, applicable fields, and limitations. Inform potential risks to the public through model documentation, service agreements, or others.&lt;/p&gt; 
 &lt;p&gt;承诺六：积极开展前沿安全研究，防范前沿领域安全风险。研究开发和部署智能向善的人工智能系统，积极向公众披露研究成果，以帮助应对社会面临的挑战。加强对人工智能系统在前沿领域中的滥用风险研判，防范其在高危场景的潜在滥用风险。&lt;/p&gt; 
 &lt;p&gt;Commitment VI: Vigorously advance frontier safety and security research, and prevent safety and security risks in frontier fields. Innovate in the development and deployment of AI systems that embody the principle of AI for good, and disclose research findings with the public transparently, contributing to addressing pressing challenges faced by society. Strengthen the assessment of risks related to the abuse of AI systems in frontier fields, and prevent potential risks of their abuse in high-risk scenarios.&lt;/p&gt; 
 &lt;p&gt;承诺七：加强安全治理国际合作，推动技术向善普惠应用。积极参与全球人工智能安全治理交流对话，共享风险识别、评估与防控经验及最佳实践。积极承担社会责任，加强科普宣传、开展技能培训，提升人工智能素养和技能水平，助力弥合智能鸿沟。&lt;/p&gt; 
 &lt;p&gt;Commitment VII: Strengthen international cooperation on AI safety, security and governance, and promote inclusive, beneficial applications of AI. Actively participate in global dialogues on AI safety, security and governance, and contribute to the exchange of experiences and best practices in risk identification, assessment, and mitigation. Fulfill social responsibilities by advancing public science communication, enhancing AI education, and providing skills training to improve AI literacy and capabilities, with a focus on bridging the global intelligence divide.&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363206</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363206</guid>
      <pubDate>Wed, 16 Jul 2025 09:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>FFmpeg 8.0 将于 8 月底发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源多媒体框架 FFmpeg 计划于 8 月底发布 8.0 版本。&lt;/p&gt; 
&lt;p&gt;按照计划，FFmpeg 8.0 代码应该在未来一两周内分支出来，然后在此两周后发布 FFmpeg 8.0 版本。所以大约在 8 月底，FFmpeg 8.0 就会上线。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0730/172734_8M9I_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fffmpeg.org%2Fpipermail%2Fffmpeg-devel%2F2025-July%2F347010.html" target="_blank"&gt;https://ffmpeg.org/pipermail/ffmpeg-devel/2025-July/347010.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此次更新涵盖多种新编码器与解码器，包括 RealVideo 6.0、APV、动画 JPEG-XL 等。同时，新增对 OpenHarmony 的编解码支持及 VVC/H.266 的 VA-API 加速功能。更新还涵盖 AVX-512 优化、HDR 视频支持增强、WHIP 复用器实现低延迟传输等，部分功能性能提升达 100 倍。&lt;/p&gt; 
&lt;p&gt;此外，MP4 复用器现已支持 CENC AV1，FLV v2 也增强了现代编码兼容性。&lt;/p&gt; 
&lt;p&gt;FFmpeg 8.0 尚未合并但可能及时完成的一项功能是&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpatchwork.ffmpeg.org%2Fproject%2Fffmpeg%2Fpatch%2F20250719125526.389239-1-vpalmisano%40gmail.com%2F" target="_blank"&gt;最近&lt;/a&gt;为 FFmpeg 添加 OpenAI Whisper 音频过滤器支持的工作。这可以为 FFmpeg 提供 AI 驱动的实时字幕/转录支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363199/ffmpeg-8-0-coming-soon</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363199/ffmpeg-8-0-coming-soon</guid>
      <pubDate>Wed, 16 Jul 2025 09:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 洽谈 50 亿美元融资，估值达 1700 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彭博社援引知情人士&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-29%2Fanthropic-nears-deal-to-raise-funding-at-170-billion-valuation" target="_blank"&gt;消息称&lt;/a&gt;，Anthropic 即将达成协议，在新一轮融资中筹集高达 50 亿美元，从而使其估值达到 1700 亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;知情人士表示，投资公司&amp;nbsp;Iconiq Capital&amp;nbsp;将领投此轮融资，预计融资总额将在 30 亿至 50 亿美元之间。部分知情人士表示，Iconiq 正在洽谈投资约 10 亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此外，Anthropic 还一直在与卡塔尔投资局 (QIA) 和新加坡主权基金新加坡政府投资公司 (GIC) 洽谈参与此轮融资。&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;其他潜在投资者包括亚马逊，该公司此前已向 Anthropic 投资数十亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Lightspeed 也参与了新一轮融资。其他正在洽谈参与的风险投资公司包括&amp;nbsp;Menlo Ventures&amp;nbsp;和&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Alkeon Capital Management。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Anthropic 将接受不低于 2 亿美元的融资。一位知情人士表示，这笔融资最终可能会有第二位领投方。谈判仍在最后敲定中，细节可能会有所变动。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-98dfff5c6e147489718fd1050088352376d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着最近几轮融资谈判的推进，Anthropic 的销售额大幅增长。据彭博社此前&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-15%2Fopenai-rival-anthropic-courts-finance-industry-with-new-ai-tools" target="_blank"&gt;报道&lt;/a&gt;，该公司本月初的年度经常性收入约为 40 亿美元。截至 7 月底，这一数字已攀升至约 50 亿美元。该公司预计，到今年年底，其经常性收入可能达到 90 亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;新的融资将标志着该公司估值的大幅跃升，并巩固其作为全球领先人工智能开发商之一的地位。今年早些时候，Anthropic 在由光速创投领投的 35 亿美元融资中估值达到 615 亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Anthropic、Iconiq、GIC、Lightspeed、亚马逊和 Menlo Ventures 均拒绝置评。卡塔尔投资局和 Alkeon 的代表尚未回应置评请求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《连线》杂志此前曾报道了 Anthropic 首席执行官 Dario Amodei 在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fanthropic-dario-amodei-gulf-state-leaked-memo%2F" target="_blank"&gt;最近&lt;/a&gt;发给员工的一份备忘录中承认，有必要从中东筹集资金。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363198</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363198</guid>
      <pubDate>Wed, 16 Jul 2025 09:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>s3mini —— 小巧快速的 S3 客户端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;code&gt;s3mini&lt;/code&gt;是一款超轻量级 Typescript 客户端（压缩后约 14 KB，每秒操作数提升约 15%），用于兼容 S3 的对象存储。它可在 Node、Bun、Cloudflare Workers 和其他边缘平台上运行。已在 Cloudflare R2、Backblaze B2、DigitalOcean Spaces 和 MinIO 上测试过。（不支持浏览器！）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;轻巧快速：平均每秒操作数增加约 15%，大小仅为 ~14 KB（最小化，未压缩）。&lt;/li&gt;
&lt;li&gt;零依赖；支持 AWS SigV4（无预签名请求）。&lt;/li&gt;
&lt;li&gt;适用于 Cloudflare Workers；非常适合边缘计算、Node 和 Bun（不支持浏览器）。&lt;/li&gt;
&lt;li&gt;仅包含必要的 S3 API — 改进的列表、放置、获取、删除等。&lt;/li&gt;
&lt;li&gt;BYOS3&amp;nbsp;&lt;strong&gt;-&lt;/strong&gt;自带与 S3 兼容的存储桶（已在 Cloudflare R2、Backblaze B2、DigitalOcean Spaces、MinIO 和 Garage 上测试！Ceph 和 AWS 已加入测试队列）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="403" src="https://static.oschina.net/uploads/space/2025/0612/145619_y755_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/s3mini</link>
      <guid isPermaLink="false">https://www.oschina.net/p/s3mini</guid>
      <pubDate>Wed, 16 Jul 2025 09:03:00 GMT</pubDate>
    </item>
    <item>
      <title>微软罗列受 AI 冲击最大的 40 个职业岗位</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软近日发布了一份 AI 相关研究&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fartificial-intelligence%2Fmicrosoft-reveals-40-jobs-about-to-be-destroyed-by-and-safe-from-ai" target="_blank"&gt;报告&lt;/a&gt;，分析了美国用户和 Copilot 超过 20 万次对话，探讨了 AI 在各领域的应用情况，并列出了受 AI 冲击影响最大的 40 个职业岗位。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/164742_GQ27_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该报告分析了美国用户和 Copilot 超过 20 万次对话，探讨了人们最常使用 AI 的领域。根据用户满意度和 Copilot 被要求处理特定任务的频率，研究人员计算出 AI 接管不同工作角色的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9a52e207c0707356014987acb75a9d4c228.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-257c1393cd78d715b7708a3a215bb07fb93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;基于报告数据，翻译和口译人员受 AI 冲击最为严重，现代 AI 工具已能提供快速的多语言语音旁白和实时翻译，这些岗位与 Copilot 当前能做的事情有最大的重合。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;受冲击最大的职业&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;翻译和口译人员受影响最为严重，因为现代 AI 工具已能提供快速的多语言语音旁白和实时翻译，与 Copilot 的功能高度重合。&lt;/li&gt; 
 &lt;li&gt;历史学家也面临较大冲击，他们常借助 AI 分析社会话题或验证历史事实，而信息收集是语言模型的优势，存在明显的替代潜力。&lt;/li&gt; 
 &lt;li&gt;作家、销售代表和客服人员同样处于受冲击的前列，这些工作涉及大量沟通任务，用户常将相关任务交给 Copilot，且效果良好。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;受冲击较小的职业&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;护理助理、按摩师和重型设备操作员的职业受 AI 影响较小。这些工作涉及实体存在、亲手护理或机器操作，目前 AI 无法复制。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363192</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363192</guid>
      <pubDate>Wed, 16 Jul 2025 08:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Dropbox Passwords 即将停止服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Dropbox &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.dropbox.com%2Fen-us%2Finstalls%2Fdropbox-passwords-discontinuation" target="_blank"&gt;发布官方公告&lt;/a&gt;，宣布 Dropbox Passwords 将于 2025 年 10 月 28 日停用。Dropbox 建议用户将密码转移至其他密码管理应用程序，例如 1Password。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/164104_T9vF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;停用计划概览&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 10 月 28 日&lt;/strong&gt;将全面停用 Dropbox Passwords。届时你无法再访问、添加或使用任何保存的用户名、密码和支付信息，这些数据将被永久安全删除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;阶段性变化流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 8 月 28 日&lt;/strong&gt;：移动端 App 和浏览器扩展设为 &lt;strong&gt;只读模式&lt;/strong&gt;，停止新增内容和自动填充功能，但仍可查看已有密码数据。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 9 月 11 日&lt;/strong&gt;：&lt;strong&gt;移动 App 停用&lt;/strong&gt;，你仍可通过浏览器扩展查看数据。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025 年 10 月 28 日&lt;/strong&gt;：功能全面关闭并删除所有密码数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;为什么要停用？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Dropbox 表示将专注于提升其核心产品功能，故决定停止开发密码管理工具，并推荐用户改用其他密码管理器，如 1Password。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363190</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363190</guid>
      <pubDate>Wed, 16 Jul 2025 08:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里巴巴 1688 发布「AI 版」App 与「88 查」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;阿里巴巴旗下的 B2B 批发平台 1688 近日正式发布多项 AI 新品和升级举措，旨在通过人工智能技术全面赋能中小企业，提升采购效率。此次发布的核心亮点包括推出全新的「1688AI 版」App、上线免费企业查询工具「88 查」，并对现有「阿里巴巴 1688」App 进行全面 AI 化升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-86d878ed359505322a95851647189883259.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据介绍，全新发布的「1688AI 版」App 正陆续登陆各大手机应用商店，面向采购买家全面开放。这款新应用聚焦创业与拿货场景，集成了五大核心 AI 功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 搜索：提供更智能、精准的搜索体验。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 选品：基于大数据和 AI 算法，为买家智能推荐优质货源。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 创款：助力商家进行产品设计和创新。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 图搜：支持通过图片进行商品搜索。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 查企：与「88 查」功能打通，方便买家快速查询企业信息。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这些功能覆盖了从商机发现、智能推荐与组货，到产品设计和创新等生意全链路需求，旨在提升采购效率和成功率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「88 查」也已上线 PC 端，并深度集成于 1688App，同时接入支付宝和微信小程序，支持用户跨平台免费使用。「88 查」的一大特色是支持自然语言交互，用户只需输入简单描述，即可快速查询工厂的资质认证、生产实力与核心能力。更进一步，该工具还集成了深度研究能力，能够快速生成行业和企业研究报告，为买家提供决策支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次 AI 能力将同步覆盖 1688 的移动端与 PC 端，未来还将结合不同终端和用户群体的交互特性持续迭代。通过 AI 技术，1688 旨在助力买家实现高效选品、精准找厂、简单做生意的目标。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363188</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363188</guid>
      <pubDate>Wed, 16 Jul 2025 08:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>未来五年，AI 创造的百万富翁数量将超过互联网二十年来的总和</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;黄仁勋在"All-In"播客节目中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.entrepreneur.com%2Fbusiness-news%2Fnvidia-ceo-jensen-huang-says-ai-will-create-millionaires%2F495134" target="_blank"&gt;详细阐述&lt;/a&gt;了人工智能的财富创造逻辑。他认为 AI 技术使人们能够创造全新的事物，有效填补技能空白，为个人和企业提供了前所未有的创收机会。&lt;/p&gt; 
&lt;p&gt;黄仁勋预测在未来 5 年内，&lt;strong&gt;AI 领域创造的百万富翁要多于互联网 20 年创造的&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height="760" src="https://static.oschina.net/uploads/space/2025/0730/161900_2YNk_2720166.png" width="1552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这种技术被他称为"有史以来最伟大的技术均衡器"，因为它能让任何人都成为程序员。传统编程需要掌握 Python 或 C++等复杂编程语言，这些技术门槛往往将普通人排除在外。&lt;/p&gt; 
&lt;p&gt;AI 技术的革命性在于其降低了技术应用的门槛。任何人都可以用自然语言与人工智能进行交流，无需经过漫长的技术学习过程。这种变化使得每个创意人员都拥有了技术技能，同时每个技术人员都可以利用 AI 来发挥创造力。&lt;/p&gt; 
&lt;p&gt;黄仁勋指出，因为人工智能的存在，每个人都可以成为"艺术家"或"程序员"，这种身份的转换为财富创造提供了无限可能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363179</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363179</guid>
      <pubDate>Wed, 16 Jul 2025 08:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英特尔停止开发开源深度学习软件 PlaidML，仓库已归档</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;根据 PlaidML 开源 GitHub 仓库的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fplaidml%2Fplaidml" target="_blank"&gt;「已归档」提醒&lt;/a&gt;，英特尔已停止对 PlaidML 开源深度学习框架进行维护和支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b8bebfd44f2469fdbe8aa634565d35abbdb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-edaef0683a12744ca6200c5f0153cdc1ffa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PlaidML 是一个开源的张量编译器，旨在为各种 CPU、GPU 和其他加速器提供性能可移植性。它曾与英特尔的 nGraph 编译器结合，支持 PyTorch、Keras（TensorFlow）和 OpenVino 等流行的深度学习框架。&lt;/p&gt; 
&lt;p&gt;PlaidML 由英特尔在 2018 年收购的 Vertex.AI 开发，收购之后一直继续开发，但在经历一次大规模代码重组之后开发进度显著降低，直到今年初彻底死亡，与此同时 AI 领域的竞争在显著加速。&lt;/p&gt; 
&lt;p&gt;英特尔终止该项目的原因尚未明确，但这一决定对英特尔的开源软件生态系统来说是一个打击。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363172/intel-plaidml-archived</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363172/intel-plaidml-archived</guid>
      <pubDate>Wed, 16 Jul 2025 08:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程工具 Cursor 发布 1.3，支持查看上下文 token 使用情况</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程工具 Cursor&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fcn%2Fchangelog"&gt;&amp;nbsp;发布了 1.3&lt;/a&gt;。在新版本中，Agent 现可共享用户终端，同时在编辑速度和延迟方面获得显著性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0730/154447_BS8h_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版本中，Agent 现在可以使用用户的本地终端，并在需要时创建一个新的后台终端。用户可以通过点击 「Focus」 来查看 Agent 执行的命令并接管操作。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0730/154745_YTr5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版本还支持在 Chat 界面查看上下文使用情况：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0e15b64d031df533d8ce0835bf439a442a6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;性能方面，通过懒加载 linter 错误，Agent 编辑速度得到提升；Search &amp;amp; Replace 编辑延迟减少了 25%，Apply edits 延迟减少了近 11%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-941ccf4f2682817a8143f6e3665744ad44a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其他改进包括：聊天中显示活动标签页、右键单击目录并发送到聊天、Checkpoints 支持 Notebooks、通过 allowlists 提升安全性、移除聊天中的 Manual 模式，以及新增可从命令面板访问的扩展监视器。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363168/cursor-1-3</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363168/cursor-1-3</guid>
      <pubDate>Wed, 16 Jul 2025 07:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>商汤发布「日日新 SenseNova V6.5」大模型体系</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;商汤科技在 WAIC 2025 上发布了「日日新 SenseNova V6.5」大模型体系，其推理和多模态能力超越多个主流模型，且性价比提升 3 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/153957_Ek9w_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154010_eiFA_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0730/154040_VjKR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;日日新 V6.5 重点升级了强推理、高效率和智能体三大能力。该模型在国内率先突破图文交错思维链技术，引入形象思维，并改进了多模态模型的融合架构，使得文本和多模态推理能力超越 Gemini 2.5 Pro 和 Claude-4 Sonnet，多模态交互能力超越 Gemini 2.5 Flash 和 GPT-4o，同时性价比相较 V6.0 提升了 3 倍。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363167</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363167</guid>
      <pubDate>Wed, 16 Jul 2025 07:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程软件 Cline 回应 Anthropic 限制 Max 用量的新政策</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;日前，Anthropic 开始针对 Claude Code 订阅用户&lt;u&gt;&lt;a href="https://www.oschina.net/news/362871"&gt;加入新的每周用量限制&lt;/a&gt;&lt;/u&gt;，并且根据目前使用情况来计算，这一调整将影响不到 5% 的用户。&lt;/p&gt; 
&lt;p&gt;具体来看，从 8 月 28 日起，Anthropic 将在现有的每 5 小时重置的用量限制基础上，增加每周用量限制：每 7 天重置的总体每周用量上限；针对 Claude Opus 4 的每周用量上限，每 7 天重置。&lt;/p&gt; 
&lt;p&gt;Anthropic 表示，Claude Code 作为其订阅服务的一部分，该产品用户增长速度前所未有。但同时 Claude Code 存在一些违反政策的行为，以及一些超常规的使用模式。而这些行为影响了所有用户的系统容量。对此，Anthropic 推出的新用量限制旨在解决这些问题，为所有用户提供一个更公平的使用体验。&lt;/p&gt; 
&lt;p&gt;而 AI 编程软件 Cline &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1949943033891307589" target="_blank"&gt;也回应了 Anthropic 的新政策。&lt;/a&gt;&lt;strong&gt;Cline 将 AI 订阅比作加油站，而车（AI 工具）和油（AI 推理服务）都由同一家 AI 公司控制，用户买了油却不知道实际加了多少，甚至还没法了解实际消耗和服务内容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b714d24bfd8ec4d5f5174c7a6b4d395f74e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 认为，任何宣称自己是无限服务都是不可持续的，AI 推理本质上是像汽油、电力一样的商品。Cline 还指出，重度用户的使用成本远超订阅费用，从而导致服务商亏损，不得不设置限额或限制使用，最终用户体验也变得受损，得不偿失。&lt;/p&gt; 
&lt;p&gt;Cline 还表示，&lt;strong&gt;将来订阅模式终将被市场淘汰，未来应选择利益与用户一致、架构透明的工具和平台&lt;/strong&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363163</guid>
      <pubDate>Wed, 16 Jul 2025 07:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TPU Deep Dive：Google TPU 架构深度分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 在人工智能算力军备竞赛愈演愈烈的今天，为什么 Google 会选择与主流 GPU 截然不同的技术路线，开发出架构独特的 TPU？这种专用芯片究竟凭借什么优势，能够支撑起 Gemini、Veo&amp;nbsp;等&amp;nbsp;AI 模型的训练与推理？&lt;/p&gt; 
 &lt;p&gt;文章从单芯片架构出发，深入剖析了 TPU 的核心设计理念：首先解释了 TPU 如何通过脉动阵列和流水线技术优化矩阵运算，然后阐述了 XLA 编译器如何通过预先编译减少缓存依赖，大幅降低能耗。在多芯片层面，作者详细介绍了 TPU 从托盘、机架、Pod 到 Multi-Pod 的层级扩展架构，特别是 OCS 光交换技术如何实现灵活的拓扑重构和故障容错。文章还通过具体案例展示了不同拓扑结构对并行训练策略的影响，以及 Multi-Pod 架构如何支撑超大规模模型训练。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Henry Ko&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;最近我大量使用 TPU，发现它们与 GPU 的设计理念非常不同，感觉很有趣。&lt;/p&gt; 
&lt;p&gt;TPU 的主要优势在于其可扩展性。这是通过硬件层面（例如能效方面和模块化）与软件层面（例如 XLA compiler）的协同设计实现的。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 背景信息&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;简单介绍一下 TPU，它是谷歌的专用集成电路（ASIC），其设计聚焦于两大要素：极高的矩阵运算（matmul）吞吐量和能源效率。&lt;/p&gt; 
&lt;p&gt;它们的起源可追溯到 2006 年的谷歌。当时，他们正在评估是采用 GPU、FPGA 还是定制的 ASIC。当时，只有少数应用需要使用专用硬件，他们判断通过从大型数据中心调配多余的 CPU 算力即可满足这些需求。但这一情况在 2013 年发生了变化，当时谷歌的语音搜索功能运行在神经网络上，而内部预测认为，如果该功能发展起来，将需要远超以往的算力。&lt;/p&gt; 
&lt;p&gt;时至今日，TPU 已为谷歌的大多数人工智能服务提供算力支撑。当然，也包括 Gemini 或 Veo 的训练和推理，也包括他们的推荐模型。&lt;/p&gt; 
&lt;p&gt;让我们从底层开始，深入了解一下 TPU 的内部构造。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 单个 TPU 芯片内部的架构层级&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;下文图示均以 TPUv4 为例，但其整体布局基本也适用于最新一代 TPU（如 TPUv6p 「Trillium」。TPUv7 「Ironwood」 的细节截至 2025 年 6 月尚未公布）。&lt;/p&gt; 
&lt;p&gt;单颗 TPUv4 芯片的结构如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b7a986ab2586ba485d59aac151bc5dbf109.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU Single Chip + TensorCore&lt;/p&gt; 
&lt;p&gt;每颗芯片内含两个 TPU TensorCore，负责所有计算。（注：面向推理的专用 TPU 仅有一个 TensorCore）。两个 TensorCore 共享同一份内存：CMEM（128 MiB）和 HBM（32 GiB）。&lt;/p&gt; 
&lt;p&gt;而在每个 TensorCore 内部，都有计算单元和较小的内存缓冲区：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）矩阵乘法单元 (MXU)&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这是 TensorCore 的核心部件，是一个 128x128 的脉动阵列（systolic array）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;脉动阵列的原理稍后说明。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）向量单元（VPU）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;负责执行通用的逐元素操作（例如 ReLU、点加/点乘、归约操作）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）向量内存（VMEM；32 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;内存缓冲区。HBM 中的数据需先复制到 VMEM，TensorCore 才能开始计算。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4）标量单元 + 标量内存（SMEM；10 MiB）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;用于调度 VPU 和 MXU 的执行指令。&lt;/li&gt; 
 &lt;li&gt;负责管理控制流、标量运算和内存地址生成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用的是英伟达（NVIDIA）GPU，那么一些初步观察结果可能会让你大吃一惊：&lt;/p&gt; 
&lt;p&gt;1）TPU 的片上内存单元（CMEM、VMEM、SMEM）远大于 GPU 的 L1/L2 缓存。&lt;/p&gt; 
&lt;p&gt;2）TPU 的 HBM 容量却远小于 GPU 的 HBM。&lt;/p&gt; 
&lt;p&gt;3）负责计算的"核心"（cores）数量明显更少。&lt;/p&gt; 
&lt;p&gt;这与 GPU 架构完全相反 —— GPU 拥有较小的 L1/L2 缓存（以 H100 为例，分别为 256KB 和 50MB）、更大的 HBM（H100 为 80GB）以及数以万计的计算核心（cores）。&lt;/p&gt; 
&lt;p&gt;在我们进一步讨论之前，需明确的是，TPU 与 GPU 同样具备极高的吞吐量。单颗 TPU v5p 芯片可达 500 TFLOPs/sec，由 8960 颗芯片组成的完整 pod 集群可实现约 4.45 ExaFLOPs/sec。而最新的 "Ironwood" TPUv7 每个 pod（9216 颗芯片）据称可达 42.5 ExaFLOPS/sec。&lt;/p&gt; 
&lt;p&gt;要理解 TPU 如何实现这种性能，我们需要深入探究其设计理念。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 TPU 的设计理念&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;TPU 通过两大技术支柱和一个核心前提实现了惊人的吞吐量与能源效率：systolic array（脉动阵列） + pipelining（流水线）、Ahead-of-Time (AoT) compilation（预先编译），以及假设绝大多数运算都可通过适配 systolic array（脉动阵列）的方式表达。幸运的是，在现代深度学习（DL）领域，计算的大部分都是矩阵运算，而这些运算都适合使用 systolic array（脉动阵列）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 TPU 设计选择之一：Systolic Array + Pipelining&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;问：什么是 Systolic Array？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;答：Systolic Array 是一种硬件设计架构，由相互连接的处理单元（PE）网格组成。每个 PE 执行少量运算（例如乘法和累加运算），并将结果传递给相邻 PE。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-35d3a118a74284c503027134a4294314974.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这种设计的好处是，数据一旦输入 systolic array（脉动阵列），便无需额外的控制逻辑来处理数据。此外，当脉动阵列的规模足够大时，除输入输出外再无内存读写操作。&lt;/p&gt; 
&lt;p&gt;由于脉动阵列的刚性结构设计（rigid organization），其仅能处理具有固定数据流模式的操作，但幸运的是，矩阵乘法和卷积运算（convolutions）恰好完美适配这种架构范式。&lt;/p&gt; 
&lt;p&gt;不仅如此，pipelining（流水线技术）显然有机会将计算与数据移动重叠执行。下图展示了 TPU 架构上 pipelined pointwise operation （通过流水线技术，加速 pointwise operation（逐点操作） 的执行过程。）的示意图。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-038f3eb06befc2339ee00a80b38e0b91727.gif" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pipelined Pointwise Operation (from "How to Scale Your Model"&amp;nbsp;[4])&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;旁注：Systolic Arrays（脉动阵列）的局限性 —— 稀疏性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们可以看到，脉动阵列（systolic arrays）非常喜欢稠密矩阵（dense matrices）（即每个 PE 几乎每个时钟周期都处于活跃状态）。然而，其劣势是，相同规模的稀疏矩阵（sparse matrices）无法获得性能提升 —— 即使对于零值元素（zero-valued elements），PE 仍需执行相同数量的计算周期（cycles），导致资源浪费。&lt;/p&gt; 
&lt;p&gt;如若深度学习（DL）领域更倾向于采用更不规则的稀疏性（例如 MoE 架构），应对脉动阵列的这一系统性局限将变得愈发重要。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 TPU 设计选择之二：预先（AoT）编译 + 减少对缓存的依赖&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本节将回答 TPU 如何通过软硬件协同设计（TPU + XLA 编译器）来避免使用缓存，从而实现高能效。&lt;/p&gt; 
&lt;p&gt;首先，请记住传统缓存是为了处理不可预测的内存访问模式而设计的。一个应用程序的内存访问模式（memory access patterns），可能与另一个应用程序大相径庭。从本质上讲，缓存允许硬件灵活地适应各种应用场景。这也是 GPU（相较于 TPU）灵活性极高的一个重要原因。&lt;/p&gt; 
&lt;p&gt;然而，缓存访问（以及一般意义上的内存访问）会消耗大量能源。下面是对芯片（45 纳米，0.9V；[18]）上各类操作的能耗粗略估计。这里的主要启示是，&lt;strong&gt;内存的访问和控制占用了大部分的能耗，而算术操作本身的能耗占比则小得多。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-828c725d5f974a2973ca0fdeaa15296501f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但是，如果你的应用非常特殊，而且其计算和内存访问模式具有很高的可预测性呢？&lt;/p&gt; 
&lt;p&gt;举个极端的例子，如果我们的编译器能提前确定所有需要的内存访问，那么硬件仅需一个暂存器作为缓冲区就足以满足需求，根本不需要缓存。&lt;/p&gt; 
&lt;p&gt;这正是 TPU 的设计理念所追求的，也是 TPU 使用 XLA 编译器设计以实现这一目标的根本原因。XLA 编译器通过提前分析计算图来生成优化过的程序。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问：但 JAX 在 TPU 上也运行良好，它们使用 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 吗？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;TPU 上的 JAX+XLA 实际处于 JIT 与 AOT 的混合模式，因此容易产生混淆。当首次调用 JAX 中被 &lt;a href="https://my.oschina.net/u/3233893"&gt;@jit&lt;/a&gt; 修饰的函数时，JAX 会进行代码追踪并生成静态计算图。然后将其传递给 XLA 编译器，在那里被转化为适用于 TPU 的完全静态二进制文件。在最后的转化阶段，编译器会实施针对 TPU 的优化（例如，最大限度地减少内存访问），使整个过程适合 TPU。&lt;/p&gt; 
&lt;p&gt;但有一点需要注意：当输入张量的形状（shape）发生变化时，已编译的 JIT 函数需重新编译并缓存。这就是为什么 JAX 在处理动态填充（dynamic padding）或长度随输入变化的 for 循环层时表现不佳。&lt;/p&gt; 
&lt;p&gt;当然，这种方案虽有优势，却也存在明显的局限。它缺乏灵活性，而对编译器的重度依赖犹如一把双刃剑。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;那么，Google 为何仍要坚持这种设计理念？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TPU 及其能源效率（TPUv4）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;前文的能耗示意图并不能精确反映 TPU 的实际情况，此处是 TPUv4 的能耗细目。注意，TPUv4 采用 7nm 工艺，表中 45nm 的数据仅用于对比（[3], [16]）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-929fea9deb2dd94de8a7dbbbf5af8b32f14.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bae4859f266ed820ecd3b512e9ceb4f62b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;单次操作能耗对比（TPUv4, 7 nm）&lt;/p&gt; 
&lt;p&gt;上方的柱状图展示了具体数值，但需注意，现代芯片采用的是 HBM3 内存，其能耗远低于本图表中显示的 DDR3/4 DRAM。尽管如此，该图仍表明内存操作的能耗仍高出计算操作数个数量级。&lt;/p&gt; 
&lt;p&gt;这恰与 scaling laws 形成呼应：我们非常乐意通过增加浮点运算量（FLOPS）来换取更少的内存操作。因此减少内存操作能带来双重优化收益——不仅提升程序运行速度，还可显著降低能耗。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 TPU 的多芯片互联层级结构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;现在升级到更高层级，观察 TPU 在多芯片环境中的运作方式。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 托盘层级（即"板卡"；含 4 个芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8e3fe72f71ddb1cea8fad910065ba1c07b1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;单块 TPU 托盘包含 4 个 TPU 芯片或 8 个 TensorCore（简称"核心"）。每块托盘配备独立 CPU 主机（注：推理型 TPU 的每个主机可访问 2 块托盘，因其每芯片仅含 1 个核心）。&lt;/p&gt; 
&lt;p&gt;主机（Host） ⇔ 芯片（Chip）的连接采用 PCIe 接口，但芯片（Chip）⇔芯片（Chip）之间通过 Inter-Core Interconnect（ICI）连接，该接口具备更高带宽。&lt;/p&gt; 
&lt;p&gt;不过 ICI 连接还可进一步扩展至多块托盘。为此，我们需要继续提升到机架层级（Rack level）。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.2 机架层级（4x4x4 芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;TPU 最令人兴奋的特性在于其可扩展性，这一点从机架层级开始显现。&lt;/p&gt; 
&lt;p&gt;一个 TPU 机架包含 64 个 TPU 芯片，通过 4x4x4 三维环面网络互联。如果您看过谷歌的 TPU 宣传资料（如下图），这张图展示的是 8 个 TPU 机架的集群。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4bd138cd1af2330bfc7d037d4a01afa568f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 个 TPU 机架（TPUv4）&lt;/p&gt; 
&lt;p&gt;但在深入讨论机架之前，我们需要澄清几个容易混淆的术语：机架（Rack）、Pod 和切片（Slice）的区别。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问：TPU 机架、TPU Pod 和 TPU 切片有何不同？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;不同谷歌资料对这些术语的使用存在差异，有时甚至混用"TPU Pod"和"TPU Slice"。本文采用谷歌 TPU 论文和 GCP 官方文档的定义（[3][7][9]）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）TPU 机架（Rack）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;包含 64 块芯片的物理单元，也称为「立方体（cube）」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2）TPU Pod&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通过 ICI 和光纤连接的 TPU 最大单元。&lt;/li&gt; 
 &lt;li&gt;又称"Superpod"或"Full Pod"。例如 TPUv4 的 TPU Pod 包含 4096 块芯片（或 64 个机架）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3）TPU 切片（Slice）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;介于 4 块芯片到 Superpod 规模之间的任何 TPU 配置组合。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;主要区别在于，TPU 机架和 TPU Pod 是物理计量单位，而 TPU 切片是抽象计量单位。当然，TPU 切片的设置涉及重要的物理拓扑约束，但现阶段我们暂不展开讨论。&lt;/p&gt; 
&lt;p&gt;现在，我们将聚焦物理计量单位：TPU 机架和 TPU Pod。这是因为，理解 TPU 系统的物理连接方式，能更深入地掌握其设计哲学。&lt;/p&gt; 
&lt;p&gt;现在回到 TPUv4 机架的具体结构：&lt;/p&gt; 
&lt;p&gt;单个 TPU 机架通过 ICI 和 OCS（Optical Circuit Switching）技术连接 64 个芯片。实质上，我们通过组合多个托盘（trays）来构建一个 64 芯片的完整系统。这种"将小型单元组装成超级计算机"的设计理念将持续贯穿后续层级。&lt;/p&gt; 
&lt;p&gt;下图展示了 TPUv4 单个机架的拓扑结构。它采用 4x4x4 三维环面网络，其中每个节点都代表一块芯片，蓝色箭头表示 ICI 链路，而各个面上的连接线则代表 OCS（根据文献 [7] 重绘）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d720ac051e5ed63612d648da6093008d2c0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;使用 OCS 的 TPU 单机架架构&lt;/p&gt; 
&lt;p&gt;然而，这张图表引出了两个关键问题：为何 OCS 仅应用于环面结构的表面？换句话说 —— 使用 OCS 的核心优势是什么？共有三大核心优势，我们将在后文再详述另外两点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的优势 #1：环绕连接 (Wraparound)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过环形拓扑优化节点间的通信效率。&lt;/p&gt; 
&lt;p&gt;OCS 还承担特定 TPU 配置的环绕连接功能。该设计将两节点间的跳数从最坏情况下 N-1 跳降至每轴 (N-1)/2 跳，因为每条轴均形成一个环形（一维环面拓扑）。&lt;/p&gt; 
&lt;p&gt;随着规模的进一步扩大，这种影响变得更加重要，因为降低芯片间的通信延迟对于高度并行化的实现至关重要。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附注：并非所有 TPU 都采用 3D 环面拓扑&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;注意，早期 TPU（如 TPUv2/v3）及推理专用 TPU（如 TPUv5e/v6e）使用 2D 环面拓扑而非下文所述的 3D 环面。不过 TPUv7"Ironwood" 虽定位为推理芯片，但其拓扑疑似 3D 环面（注：仅根据官方宣传材料推测）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73f622dc9ad94d85b7665298423d5669470.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2D 环面拓扑示意图&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.3 Full Pod 层级（又称 "Superpod"；TPUv4 为 4096 块芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;正如我们通过互联多个芯片构建 TPU 机架，我们也可连接多个机架组成大型 Superpod。&lt;/p&gt; 
&lt;p&gt;Superpod 特指仅通过 ICI 和 OCS 互联的最大 TPU 集群规模。虽然存在 multi-pod 层级，但这种层级需依赖更慢速的连接方式，后续将展开说明。&lt;/p&gt; 
&lt;p&gt;芯片数量会因版本不同而变化，但 TPUv4 的芯片数量为 4096（即 64 个 4x4x4 芯片的机架）。最新的 TPUv7 "Ironwood" 则高达 9216 块芯片。&lt;/p&gt; 
&lt;p&gt;下图展示了 TPUv4 的一个 Superpod：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1f3fbc86962bf3edf862e7aa966347174fb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 Superpod 架构（64 个机架）&lt;/p&gt; 
&lt;p&gt;请注意，每个立方体（即 TPU 机架）是如何通过 OCS 相互连接的，这种设计也支持在 Pod 内灵活划分 TPU 切片。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;采用 OCS 的 TPU 切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们可在 Pod 内申请 TPU 子集，即 TPU 切片。但即使所需芯片数 (N) 相同，也存在多种拓扑结构可供选择。&lt;/p&gt; 
&lt;p&gt;例如，若总共需要 512 块芯片，可选择立方体 (8x8x8)、条状拓扑 (4x4x32) 或矩形拓扑 (4x8x16)。选择切片的拓扑结构本身就是一个超参数。&lt;/p&gt; 
&lt;p&gt;所选拓扑结构直接影响节点间通信带宽，进而影响各类并行策略的性能表现。&lt;/p&gt; 
&lt;p&gt;以立方体结构（如 8x8x8）为例，它特别适合需要全连接通信的并行计算模式，比如数据并行或张量并行，因为这种拓扑结构能提供最高的二分带宽（bisection bandwidth）。而条状结构（如 4x4x32）则更适用于流水线计算，这种布局可以让顺序排列的计算层之间实现更快速的数据传输（前提是单个计算层能够适配 4x4 芯片的子切片配置）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-143cbdf8803aec31540f9640581582d1b4f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;典型 TPU 拓扑示例&lt;/p&gt; 
&lt;p&gt;当然，最优拓扑取决于具体模型结构，其寻优过程本身即是一门学问。TPUv4 论文[9]实测表明，拓扑优化可大大提升吞吐量（注：我不确定第一行指的是哪种 LLM 架构，因为没有具体说明）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-3f8cb4956e8dbbdc78ec97d12a6ad2c70f0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同拓扑结构的吞吐量优化对比&lt;/p&gt; 
&lt;p&gt;前文阐述了 TPU 切片，但另有一项重要的特性有助于提高 TPU 的运行稳定性。&lt;/p&gt; 
&lt;p&gt;借助 OCS 技术，这些切片无需占据物理连续的机架空间。这正是 OCS 的第二大优势 —— 可能也是其最大优势，但我们此前尚未展开讨论。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的优势 #2：可重新配置的非连续多节点切片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;需注意，这不同于将多个节点硬连在一起来模拟非连续切片。由于 OCS 采用光交换技术而非硬连线架构，跨节点间的物理线缆数量大幅减少，从而支持更大规模的集群扩展（即可构建超大规模 TPU Pod）。&lt;/p&gt; 
&lt;p&gt;这样就可以进行灵活的节点规模配置。例如，假设我们想在单个 Pod 上运行三个任务。虽然传统的调度方式不允许这样做，但 OCS 连接允许我们抽象出节点的物理位置，使整个 Pod 可视为一个"节点资源池"（根据参考文献[6]重绘）。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4ea87894ad75b8b37c6e3913584dffafa2c.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;单任务可将 Pod 内机架视为"节点资源池"&lt;/p&gt; 
&lt;p&gt;此举不仅提高了 Pod 的利用率，而且能在节点出现故障的情况下简化维护流程。谷歌将其描述为"故障节点的影响范围很小"。但尚不确定其液冷系统在部分节点停机时如何运作。&lt;/p&gt; 
&lt;p&gt;最后，这种灵活的 OCS 还有项延伸应用：我们还可以改变 TPU 切片的拓扑结构（例如将规则环面调整为扭曲环面）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OCS 的优势 #3：扭曲环面拓扑&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此前我们通过改变固定芯片数量下的 (x,y,z) 维度来实现不同的 TPU 切片拓扑结构。本节则聚焦固定维度配置，通过改变布线方式构造新型拓扑。&lt;/p&gt; 
&lt;p&gt;典型案例如下：将常规条状环面改造为扭曲条状环面。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-85b47be563d32b35b9ca154cf668cbd2637.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;常规环面 vs 扭曲环面（来源：TPUv4 论文[9]）&lt;/p&gt; 
&lt;p&gt;扭曲环面拓扑结构能加速扭曲二维平面上的芯片之间的通信，该特性对提升全局通信效率尤其有用。&lt;/p&gt; 
&lt;p&gt;下文将深入分析其具体应用场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;使用扭曲环面加速训练&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;理论上，扭曲环面对张量并行（TP）的加速效益最大，因为每层涉及多次 all-gather 和 reduce-scatter 操作。对数据并行（DP）也有适度提升，因为每个训练步需执行 all-reduce 操作，但发生频率较低。&lt;/p&gt; 
&lt;p&gt;想象一下，假设我们训练一个标准的仅解码器架构的 Transformer 模型，并采用多种并行策略来加速训练。下面我们将看到两种场景：&lt;/p&gt; 
&lt;p&gt;场景 #1：4x4x16 拓扑结构（TP+PP；共 256 块芯片）&lt;/p&gt; 
&lt;p&gt;设定 z 轴为流水线 (PP) 维度，二维 TP 维度为 4x4。本质上，假设第 k 层位于 z=k 平面，且每层分片至 16 块芯片。若未明确绘制，默认采用 OCS 最近邻连接。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c158c58b081b3127519935fe864668599b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TP+PP 的 4x4x16 拓扑架构&lt;/p&gt; 
&lt;p&gt;通过在每个 z=k 平面实施 2D 环面扭曲，可加速 TP 层内芯片通信。由于 PP 层主要依靠点对点通信，因此没有必要沿 PP 层扭曲。&lt;/p&gt; 
&lt;p&gt;注：实际应用中，扭曲环面在芯片数＞4x4 时效益显著。本示例使用 4x4 仅出于可视化的目的。&lt;/p&gt; 
&lt;p&gt;场景 #2：16x4x16 拓扑（DP+TP+PP；共 1024 块芯片）&lt;/p&gt; 
&lt;p&gt;作为延伸方案，我们在前一场景基础上增加 DP 维度（x 轴 4 个实例），即沿 x 轴部署 4 组场景 #1 的模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4e493d83184c5815acc5549e6e4ca1cac25.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DP+TP+PP 的 16x4x16 拓扑架构&lt;/p&gt; 
&lt;p&gt;请注意，扭曲环面仅应用于每个 DP 模型内的每个 TP 维度（即对每个 z=k 平面实施 4x4 二维扭曲，k 取值 1…16）。DP 维度仅维持基础的环绕连接，使每行构成长度为 16 的水平环。&lt;/p&gt; 
&lt;p&gt;你可能已经发现还有一种拓扑结构方案（如 8x8x16，即 2x2 DP 维度），但这会混合 DP 与 TP 维度 —— 这就变得更加复杂了。具体来说，我们还不清楚如何在 y 轴构建 OCS 环绕连接的同时兼容各 TP 维度的扭曲环面？&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.4 Multi-Pod 层级（即"Multislice"；TPUv4 支持 4096+ 块芯片）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e021ce9f1d8e82723b22c8fbdf6be01f8e7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPU 层次结构的最终层级是 Multi-pod 架构。此时可将多个 Pod 视为一台大型机器，但 Pod 之间的通信需通过数据中心网络（DCN） 进行 —— 其带宽低于 ICI。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c5bb1c222fa2d34a24b8b089ee833b622c1.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过 DCN 互联的双 Pod 架构&amp;nbsp;[1]&lt;/p&gt; 
&lt;p&gt;PaLM 模型即采用此方案进行训练。在 6144 个 TPUv4 芯片（2 个 Pod）上耗时 56 天完成。下图是 6 个 Pod 中的 TPU 任务分配情况：绿色为 PaLM 任务，红色为空闲状态，其余为其他任务。注意每个方格代表一个 4x4x4 的 TPU 芯片立方体。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-791b4b38218cbfe875837f430b10f698ff7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;PaLM 训练过程中的 TPU Pod 利用率&amp;nbsp;[6]&lt;/p&gt; 
&lt;p&gt;实现这一架构已属不易，但更关键的是开发者体验设计，具体来说，就是要关注：&lt;strong&gt;如何实现模型扩展过程中系统/硬件层面的最大程度抽象化？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;谷歌的解决方案是：由 XLA 编译器在大规模计算场景下协调芯片间的通信。研究人员只需配置相关参数（如 DP、FSDP、TP 等并行维度及切片数量），XLA 编译器即会根据当前 TPU 拓扑结构自动插入分层集合通信操作（Xu et al, 2021: GSPMD&amp;nbsp;[2]）。我们的目标是在尽可能少修改代码的情况下实现大规模训练。&lt;/p&gt; 
&lt;p&gt;例如，谷歌博客[1]展示了跨多 TPU 切片的 all-reduce 操作分解流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-864563517512833776c5a4b7dd55fc20f47.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;XLA 实现的跨 Pod All-Reduce 规约操作&lt;/p&gt; 
&lt;p&gt;这表明 XLA 编译器可以同时处理切片内与切片间的集合通信操作。&lt;/p&gt; 
&lt;p&gt;举个具体例子，在训练模型时，TPU 的拓扑结构可能如下所示。激活值的通信在切片内通过 ICI 进行，而梯度的通信则需跨切片通过 DCN 完成（即在 DCN 的 DP 维度上）[1]。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f87c248ffd203825db16d7c22f26d12bcb7.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 实物图示对照解析&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;结合硬件实拍图理解架构图会更直观，以下为综合解析。&lt;/p&gt; 
&lt;p&gt;若看过谷歌 TPU 宣传资料，可能见过下图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ae14450a22f237528185172376402b3a6d3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;8 个 TPU 机架（TPUv4）&lt;/p&gt; 
&lt;p&gt;此图为 8 个 TPU Pods 的集群，每个单元即前述的 4x4x4 三维环面架构。一个 Pod 中的每一行有 2 个托盘，这意味着每一行有 8 个 TPU 芯片。&lt;/p&gt; 
&lt;p&gt;单块 TPUv4 托盘实拍图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b5b9d5a5afd11a5c6d6ace8039c121749ab.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;请注意，图中简化为只有一个 PCIe 端口，但实际托盘上有 4 个 PCIe 端口（在左侧） —— 每个 TPU 一个。&lt;/p&gt; 
&lt;p&gt;单芯片结构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5d7b5b890cac752887d5cf0368066797a60.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;TPUv4 芯片：中央是 ASIC + 4 组 HBM 内存堆栈&lt;/p&gt; 
&lt;p&gt;中央区域为 ASIC 芯片，周围 4 个区块为 HBM 内存堆栈。因 TPUv4 内含 2 个 TensorCore，故配置 4 组 HBM 内存堆栈。&lt;/p&gt; 
&lt;p&gt;未找到 TPUv4 芯片平面图，此处展示结构近似的 TPUv4i（推理芯片），其仅含 1 个 TensorCore[3]：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-77ee6c51de3ea94847bc8083d166140baba.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可见 CMEM（芯片内存）在 TPUv4i 的布局中占据了相当大的空间。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 致谢&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;感谢 Google TPU Research Cloud（TRC）提供的 TPU 资源支持！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;[1] Google Blog: TPU Multi-Slice Training（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fcompute%2Fusing-cloud-tpu-multislice-to-scale-ai-workloads%EF%BC%89" target="_blank"&gt;https://cloud.google.com/blog/products/compute/using-cloud-tpu-multislice-to-scale-ai-workloads）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] Xu, et al. "GSPMD: General and Scalable Parallelizaton for ML Computation Graphs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2105.04663%EF%BC%89" target="_blank"&gt;https://arxiv.org/pdf/2105.04663）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] Jouppi et al. "Ten Lessons From Three Generations Shaped Google's TPUv4i"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fai%2Fscaling%2Fhardware%2F2021-jouppi.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/ai/scaling/hardware/2021-jouppi.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4] How to Scale Your Model - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjax-ml.github.io%2Fscaling-book%2Ftpus%2F%EF%BC%89" target="_blank"&gt;https://jax-ml.github.io/scaling-book/tpus/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5] Domain Specific Architectures for AI Inference - TPUs（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffleetwood.dev%2Fposts%2Fdomain-specific-architectures%23google-tpu%EF%BC%89" target="_blank"&gt;https://fleetwood.dev/posts/domain-specific-architectures#google-tpu）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6] HotChips 2023: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc2023.hotchips.org%2Fassets%2Fprogram%2Fconference%2Fday2%2FML%2Btraining%2FHC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf%EF%BC%89" target="_blank"&gt;https://hc2023.hotchips.org/assets/program/conference/day2/ML+training/HC2023.Session5.ML_Training.Google.Norm_Jouppi.Andy_Swing.Final_2023-08-25.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7] Google Cloud Docs: TPUv4（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Ftpu%2Fdocs%2Fv4%EF%BC%89" target="_blank"&gt;https://cloud.google.com/tpu/docs/v4）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8] Jouppi et al. "In-Datacenter Performance Analysis of a Tensor Processing Unit" -- TPU origins paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F1704.04760%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/1704.04760）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9] Jouppi et al. "TPU v4"-- TPUv4 paper（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2304.01433%EF%BC%89" target="_blank"&gt;https://arxiv.org/abs/2304.01433）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10] PaLM training video（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D0yPFBxkOKRY%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=0yPFBxkOKRY）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11] HotChips 2021: "Challenges in large scale training of Giant Transformers on Google TPU machines"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc33.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2021.Google.Sameer%2BKumar.pdf%EF%BC%89" target="_blank"&gt;https://hc33.hotchips.org/assets/program/tutorials/HC2021.Google.Sameer+Kumar.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12] HotChips 2020: "Exploring Limits of ML Training on Google TPUs"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhc32.hotchips.org%2Fassets%2Fprogram%2Ftutorials%2FHC2020.Google.SameerKumarDehaoChen.v02.pdf%EF%BC%89" target="_blank"&gt;https://hc32.hotchips.org/assets/program/tutorials/HC2020.Google.SameerKumarDehaoChen.v02.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13] Google Blog: Ironwood（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgoogle-cloud%2Fironwood-tpu-age-of-inference%2F%EF%BC%89" target="_blank"&gt;https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14] HotChips 2019: "Cloud TPU: Codesigning Architecture and Infrastructure"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fold.hotchips.org%2Fhc31%2FHC31_T3_Cloud_TPU_Codesign.pdf%EF%BC%89" target="_blank"&gt;https://old.hotchips.org/hc31/HC31_T3_Cloud_TPU_Codesign.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15] ETH Zurich's Comp Arch Lecture 28: Systolic Array Architectures（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DXkgtANeDrm8%EF%BC%89" target="_blank"&gt;https://www.youtube.com/watch?v=XkgtANeDrm8）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16] Patterson presentation: "A Decade of Machine Learning Accelerators: Lessons Learned and Carbon Footprint"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cs.ucla.edu%2Fwp-content%2Fuploads%2Fcs%2FPATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf%EF%BC%89" target="_blank"&gt;https://www.cs.ucla.edu/wp-content/uploads/cs/PATTERSON-10-Lessons-4-TPU-gens-CO2e-45-minutes.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17] Camara et al. "Twisted Torus Topologies for Enhanced Interconnection Networks."（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpersonales.unican.es%2Fvallejoe%2FPublications%2FC%25C3%25A1mara%2B-%2BTPDS%2710%2B-%2BTwisted%2BTorus%2BTopologies%2Bfor%2BEnhanced%2BInterconnection%2BNetworks.pdf%EF%BC%89" target="_blank"&gt;https://personales.unican.es/vallejoe/Publications/C%C3%A1mara+-+TPDS'10+-+Twisted+Torus+Topologies+for+Enhanced+Interconnection+Networks.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18] Horowitz article: "Computing's Energy Problem(and what we can do about it)"（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgwern.net%2Fdoc%2Fcs%2Fhardware%2F2014-horowitz-2.pdf%EF%BC%89" target="_blank"&gt;https://gwern.net/doc/cs/hardware/2014-horowitz-2.pdf）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;您更倾向 TPU 的专用化路线（牺牲灵活性换取能效），还是 GPU 的通用化路线（保留灵活性但能耗较高）？请结合您的应用场景说明理由。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhenryhmko.github.io%2Fposts%2Ftpu%2Ftpu.html" target="_blank"&gt;https://henryhmko.github.io/posts/tpu/tpu.html&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18686348</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18686348</guid>
      <pubDate>Wed, 16 Jul 2025 07:14:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Claude Code 支持在单会话中添加多个工作目录</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 旗下 AI 编程工具 Claude Code 现已支持在单个会话中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2F_catwu%2Fstatus%2F1950288312033562751" target="_blank"&gt;添加来自不同位置的多个工作目录&lt;/a&gt;，方便用户进行跨项目操作。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1728" src="https://static.oschina.net/uploads/space/2025/0730/145517_KA6C_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，用户输入命令/add-dir 即可添加新的工作目录，让模型能够跨多个项目或文件夹进行操作和分析。&lt;/p&gt; 
&lt;p&gt;添加多个目录有助于：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;单一代码库：无需切换会话即可跨目录工作&lt;/li&gt; 
 &lt;li&gt;共享配置：从任何地方访问记忆、待办事项或其他文件&lt;/li&gt; 
 &lt;li&gt;跨项目工作：在仓库间迁移代码&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.anthropic.com%2Fen%2Fdocs%2Fclaude-code%2Foverview" target="_blank"&gt;详情查看文档&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363159</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363159</guid>
      <pubDate>Wed, 16 Jul 2025 07:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
