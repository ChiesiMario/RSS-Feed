<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 02 Sep 2025 16:43:49 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>AI 提升的是下限，而非上限</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近期，AI 提醒助手项目「Elroy」在其官网发布了一篇名为&lt;em&gt;《AI 提升的是下限，而非上限》（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felroy.bot%2Fblog%2F2025%2F07%2F29%2Fai-is-a-floor-raiser-not-a-ceiling-raiser.html" target="_blank"&gt;AI is a Floor Raiser, not a Ceiling Raiser&lt;/a&gt;）&lt;/em&gt;的博客，探讨了 AI 对于提升自我的一些利与弊。&lt;/p&gt; 
&lt;p&gt;文中提到，AI 能够根据每个人的理解水平进行响应，解决了传统教学内容「不能精准匹配学习者」这一痛点。它能随时回答问题，甚至替用户完成重复性任务，为初学者提供更友好的学习起点。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-783b1d370ee54c428e48a0d6a2a0124bb4e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b120252a3f52bb1aa8937f2f2bd1ee69923.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;但同时，像「OpenAI 学习模式（Study Mode）」这样的工具可能助长依赖性，因为学习者直接通过 AI 获取答案，而不是真正理解知识结构，这样的人最终可能止步于 AI 能覆盖的水平。&lt;/p&gt; 
&lt;p&gt;对此，Elroy 的文章也指出，AI 带来的影响，取决于「做出有影响力产品需要的精通程度」，其举出了一点例子来更好分析这一情况：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;对工程管理者而言，AI 能快速帮助他们上手不熟悉的框架或平台，让想法迅速变为可运行产品。&lt;/li&gt; 
 &lt;li&gt;然而对于在复杂系统中工作的开发者，AI 缺乏对现有架构的深度理解和上下文感知，实际辅助有限。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同时，文中也提到了 AI 与艺术创意的关联。虽然 AI 可以大量生成文本、图像、音频等，但因表现往往缺乏新意，在竞争激烈、创意要求高的领域（如小说、电影）难以取得成功。&lt;/p&gt; 
&lt;p&gt;文章强调，大众容易识别雷同，例如因 4o 图像生成器而流行一时的「吉卜力风」头像，也未能影响《哈尔的移动城堡》的地位。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369939</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369939</guid>
      <pubDate>Mon, 01 Sep 2025 11:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>校方怀疑学生使用 AI 作弊，要求全员重考并接受现场答辩</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;新西兰林肯大学一门研究生课程近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.stuff.co.nz%2Fnz-news%2F360802436%2Fone-slip-and-youre-guilty-universitys-unusual-ai-crackdown-rattles-students" target="_blank"&gt;引发了热议&lt;/a&gt;&lt;strong&gt;：因怀疑部分学生在作业中使用了生成式 AI 工具，授课教师要求全班 115 名学生必须参加线下答辩重新考核&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/191258_4zKr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据了解，该课程聚焦「大数据与人工智能」，教师发现作业中出现大量「高水准代码」，怀疑学生不当使用生成式 AI 工具。&lt;/p&gt; 
&lt;p&gt;尽管承认个别学生可能具备编程能力，但大规模出现此类情况概率极低，因此决定让全班重考：学生需现场编写代码、解释作业思路，并接受即兴问答，全程录像。教师称此举为「保证公平性」，并强调「若代码是自己写的，就能解释清楚；解释不了则可能作弊」。&lt;/p&gt; 
&lt;p&gt;对于校方的处理方案，学生认为重考营造了「人人有嫌疑」的紧张氛围，担心因答错一句被认定作弊。部分学生表示从未使用 AI，却被迫参与重考，认为处理方式「反应过度」。&lt;/p&gt; 
&lt;p&gt;校方称处理符合学术规范，课程大纲已明确 AI 使用规则，且政策允许在怀疑作弊时要求学生重新验证。教务长强调重视学术诚信，目标是确保学生成果代表自身努力。&lt;/p&gt; 
&lt;p&gt;维多利亚大学 AI 专家认为，AI 普及是不可逆趋势，高校需调整教学和考核方式，如增加面对面讲解作业、设置阶段性检查点，而非单纯依赖线下考试。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369937</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369937</guid>
      <pubDate>Mon, 01 Sep 2025 11:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Solon 权限认证之 Sa-Token 的使用与详解</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;本文详细介绍了 Sa-Token 在 Java 项目中的使用方法，包括 Sa-Token 的基本概念、与其他权限框架的比较、基本语法和高级用法，并通过实例讲解了如何在项目中集成和使用 Sa-Token 。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;作为一款轻量级 Java 权限认证框架，Sa-Token 在简化权限管理、提高开发效率方面发挥了重要作用。本文还将深入探讨 Sa-Token 的核心原理，通过内部代码展示其工作机制。最后，总结了 Sa-Token 的优缺点及其在实际开发中的应用场景，为开发者提供全面的指导。&lt;/p&gt; 
&lt;h2&gt;一、Sa-Token 介绍&lt;/h2&gt; 
&lt;h3&gt;1. Sa-Token 简介&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 是一款轻量级 Java 权限认证框架，旨在解决 Java Web 系统中常见的登录认证、权限验证、Session 会话、单点登录等问题。其核心目标是以最简洁的方式，实现强大的权限控制功能，帮助开发者快速完成权限系统的搭建。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 具有如下优势：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;优势&lt;/th&gt; 
   &lt;th&gt;描述&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;简单易用&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;API 设计简洁明了，易于集成和使用，上手快，学习成本低。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;功能丰富&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;支持多种权限控制需求，满足复杂业务场景。支持登录认证、权限验证、角色验证、Session 会话、多账号体系等功能。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高性能&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;轻量级设计，对系统性能影响小。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高度可扩展&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;提供丰富的扩展接口，与 Spring、SpringBoot、Solon 等常用框架高度兼容，支持自定义持久化、注解方式验证、单点登录等高级特性。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;社区活跃&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;有良好的社区支持和文档资源。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;2. Sa-Token 原理解析&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 的核心原理是通过 Token 机制实现用户的身份认证和权限校验。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;其主要工作流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;登录认证：用户登录成功后，服务器生成一个全局唯一的 Token，并将其返回给客户端。&lt;/li&gt; 
 &lt;li&gt;Token 存储：Token 与用户身份信息的映射关系保存在服务器的会话中（如 Redis、内存等）。&lt;/li&gt; 
 &lt;li&gt;权限验证：客户端请求时携带 Token，服务器根据 Token 获取用户信息，验证其权限是否满足要求。&lt;/li&gt; 
 &lt;li&gt;会话管理：支持 Session 会话管理，可以获取和操作当前会话的属性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;流程图例如下：&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//164ae7fe8293ac6902b135fd89299bdf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3. Sa-Token 与其他权限框架比较&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 与其他常见权限框架在学习成本、集成难度上有显著优势：&lt;/p&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;特性&lt;/th&gt; 
   &lt;th&gt;Sa-Token&lt;/th&gt; 
   &lt;th&gt;Solon Auth&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;学习成本&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;功能丰富度&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;集成难度&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;低&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;性能表现&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;社区支持&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;活跃&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;一般&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;扩展性&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;高&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;中&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;二、Sa-Token 的基本语法&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;在实际项目中，Sa-Token 通过简单的配置和 API 调用，即可实现完整的权限管理功能。以下将通过一个完整的 Solon 示例，演示如何集成和使用 Sa-Token。&lt;/p&gt; 
&lt;h3&gt;1. 创建 Solon Web 项目&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;首先，创建一个新的 Solon 项目，可以使用 IDEA 的项目向导或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Fstart%2F" target="_blank"&gt;Solon Initializr&lt;/a&gt;。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入必要的依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;em&gt;&amp;lt;!-- Solon  Web --&amp;gt;&lt;/em&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-web&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

    &lt;em&gt;&amp;lt;!-- Sa-Token 核心依赖 --&amp;gt;&lt;/em&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-solon-plugin&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 配置 Sa-Token：app.yml&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;em&gt;# Sa-Token 配置，可根据需要进行调整&lt;/em&gt;
&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;
  &lt;em&gt;# token 有效期，单位秒，默认 30 天&lt;/em&gt;
  &lt;span style="color:#986801"&gt;timeout:&lt;/span&gt; &lt;span style="color:#986801"&gt;2592000&lt;/span&gt;

  &lt;em&gt;# 是否打开二级登录校验&lt;/em&gt;
  &lt;span style="color:#986801"&gt;open-safe:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. 配置拦截器&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;创建配置类，添加 Sa-Token 的拦截器，以拦截请求并进行权限验证。SaTokenConfig.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.solon.integration.SaTokenInterceptor;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Configuration;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Managed(index = -100)&lt;/span&gt; &lt;em&gt;//-100，是顺序位（低值优先）&lt;/em&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; SaTokenInterceptor &lt;span style="color:#4078f2"&gt;saTokenInterceptor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenInterceptor&lt;/span&gt;(); &lt;em&gt;//用于支持规划处理及注解处理&lt;/em&gt;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. 登录认证&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;创建登录接口，实现用户登录功能。LoginController.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Param;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Post;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;LoginController&lt;/span&gt; {

    &lt;span style="color:#4078f2"&gt;@Post&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/login")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;login&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Param&lt;/span&gt; String username, &lt;span style="color:#4078f2"&gt;@Param&lt;/span&gt; String password)&lt;/span&gt; {
        &lt;em&gt;// 1. 校验用户名和密码（这里模拟一个简单的校验）&lt;/em&gt;
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt; (&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;.equals(username) &amp;amp;&amp;amp; &lt;span style="color:#50a14f"&gt;"123456"&lt;/span&gt;.equals(password)) {
            &lt;em&gt;// 2. 登录，保存用户 ID 为 10001&lt;/em&gt;
            StpUtil.login(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;);
            &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"登录成功，Token："&lt;/span&gt; + StpUtil.getTokenValue();
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"用户名或密码错误"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;说明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;调用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.login(10001)&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，实现登录操作，参数为用户的唯一标识 ID。&lt;/li&gt; 
 &lt;li&gt;登录成功后，可以通过&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.getTokenValue()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;获取当前会话的 Token。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. 权限验证&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;创建需要权限验证的接口，例如获取用户信息的接口。UserController.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.annotation.SaCheckPermission;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Post;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#4078f2"&gt;@Mapping("/user")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;UserController&lt;/span&gt; {

    &lt;em&gt;// 查询用户信息，需登录&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/info")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;getUserInfo&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;em&gt;// 校验是否登录&lt;/em&gt;
        StpUtil.checkLogin();
        &lt;em&gt;// 获取用户 ID&lt;/em&gt;
        &lt;span style="color:#986801"&gt;int&lt;/span&gt; &lt;span style="color:#986801"&gt;userId&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.getLoginIdAsInt();
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"当前用户信息，ID："&lt;/span&gt; + userId;
    }

    &lt;em&gt;// 修改用户信息，需有权限"user:update"&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@SaCheckPermission("user:update")&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Post&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/update")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;updateUser&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"用户信息更新成功"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;说明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.checkLogin()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法手动校验登录状态。&lt;/li&gt; 
 &lt;li&gt;使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@SaCheckPermission("user:update")&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;注解，声明该接口需要权限 user:update。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;6. 角色验证&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;如果需要基于角色进行权限控制，可以使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;@SaCheckRole&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;注解。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.annotation.SaCheckRole;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Controller;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Get;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Mapping;

&lt;span style="color:#4078f2"&gt;@Controller&lt;/span&gt;
&lt;span style="color:#4078f2"&gt;@Mapping("/admin")&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;AdminController&lt;/span&gt; {

    &lt;em&gt;// 仅管理员角色可访问&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@SaCheckRole("admin")&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Get&lt;/span&gt;
    &lt;span style="color:#4078f2"&gt;@Mapping("/dashboard")&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; String &lt;span style="color:#4078f2"&gt;adminDashboard&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"欢迎进入管理员控制枱"&lt;/span&gt;;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;7. 自定义权限验证逻辑&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;需要自定义获取用户权限和角色的逻辑，可以实现&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpInterface&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;接口。StpInterfaceImpl.java&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpInterface;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; java.util.ArrayList;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; java.util.List;

&lt;span style="color:#4078f2"&gt;@Managed&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;StpInterfaceImpl&lt;/span&gt; &lt;span style="color:#a626a4"&gt;implements&lt;/span&gt; &lt;span style="color:#c18401"&gt;StpInterface&lt;/span&gt; {

    &lt;em&gt;// 返回一个用户所拥有的权限码集合&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; List&amp;lt;String&amp;gt; &lt;span style="color:#4078f2"&gt;getPermissionList&lt;/span&gt;&lt;span&gt;(Object loginId, String loginKey)&lt;/span&gt; {
        &lt;em&gt;// 模拟从数据库获取权限&lt;/em&gt;
        List&amp;lt;String&amp;gt; permissionList = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;();
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt;(&lt;span style="color:#50a14f"&gt;"10001"&lt;/span&gt;.equals(loginId.toString())) {
            permissionList.add(&lt;span style="color:#50a14f"&gt;"user:update"&lt;/span&gt;);
            permissionList.add(&lt;span style="color:#50a14f"&gt;"user:delete"&lt;/span&gt;);
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; permissionList;
    }

    &lt;em&gt;// 返回一个用户所拥有的角色标识集合 (权限与角色可分开校验)&lt;/em&gt;
    &lt;span style="color:#4078f2"&gt;@Override&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; List&amp;lt;String&amp;gt; &lt;span style="color:#4078f2"&gt;getRoleList&lt;/span&gt;&lt;span&gt;(Object loginId, String loginKey)&lt;/span&gt; {
        &lt;em&gt;// 模拟从数据库获取角色&lt;/em&gt;
        List&amp;lt;String&amp;gt; roleList = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;ArrayList&lt;/span&gt;&amp;lt;&amp;gt;();
        &lt;span style="color:#a626a4"&gt;if&lt;/span&gt;(&lt;span style="color:#50a14f"&gt;"10001"&lt;/span&gt;.equals(loginId.toString())) {
            roleList.add(&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
        }
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; roleList;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;说明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;实现&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;getPermissionList&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，返回指定用户的权限列表。&lt;/li&gt; 
 &lt;li&gt;实现&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;getRoleList&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法，返回指定用户的角色列表。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;8. 会话管理&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 提供了会话管理功能，可以在 Session 中存储和获取数据。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.session.SaSession;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.stp.StpUtil;

&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;sessionDemo&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; {
    &lt;em&gt;// 获取当前会话的 Session&lt;/em&gt;
    &lt;span style="color:#986801"&gt;SaSession&lt;/span&gt; &lt;span style="color:#986801"&gt;session&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.getSession();

    &lt;em&gt;// 存储数据&lt;/em&gt;
    session.set(&lt;span style="color:#50a14f"&gt;"name"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"张三"&lt;/span&gt;);
    session.set(&lt;span style="color:#50a14f"&gt;"email"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"zhangsan@example.com"&lt;/span&gt;);

    &lt;em&gt;// 获取数据&lt;/em&gt;
    &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;name&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; session.getString(&lt;span style="color:#50a14f"&gt;"name"&lt;/span&gt;);
    &lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;email&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; session.getString(&lt;span style="color:#50a14f"&gt;"email"&lt;/span&gt;);

    &lt;em&gt;// 输出&lt;/em&gt;
    System.out.println(&lt;span style="color:#50a14f"&gt;"姓名："&lt;/span&gt; + name);
    System.out.println(&lt;span style="color:#50a14f"&gt;"邮箱："&lt;/span&gt; + email);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;9. 踢人下线&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;可以通过用户 ID 强制用户下线。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 将用户 ID 为 10001 的用户踢下线&lt;/em&gt;
StpUtil.logoutByLoginId(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;);

&lt;em&gt;// 检查用户是否已被踢下线&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin();
System.out.println(&lt;span style="color:#50a14f"&gt;"用户是否登录："&lt;/span&gt; + isLogout);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;10. 注销登录&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;用户主动注销登录，可以调用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;StpUtil.logout()&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;方法。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 注销登录&lt;/em&gt;
StpUtil.logout();

&lt;em&gt;// 检查登录状态&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogin&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin();
System.out.println(&lt;span style="color:#50a14f"&gt;"用户是否登录："&lt;/span&gt; + isLogin);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、Sa-Token 的高级用法&lt;/h2&gt; 
&lt;h3&gt;1. 自定义持久化&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 默认使用内存来存储 Token 信息，在分布式环境中，可以使用 Redis 作为持久化介质。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入 Redis 依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-redisx&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-snack3&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 Redis Dao 连接信息：app.yml&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;  &lt;em&gt;# 不同的扩展插件，配置可能会不同&lt;/em&gt;
  &lt;span style="color:#986801"&gt;dao:&lt;/span&gt;
    &lt;span style="color:#986801"&gt;server:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"localhost:6379"&lt;/span&gt;
    &lt;span style="color:#986801"&gt;password:&lt;/span&gt; &lt;span style="color:#986801"&gt;123456&lt;/span&gt;
    &lt;span style="color:#986801"&gt;db:&lt;/span&gt; &lt;span style="color:#986801"&gt;1&lt;/span&gt;
    &lt;span style="color:#986801"&gt;maxTotal:&lt;/span&gt; &lt;span style="color:#986801"&gt;200&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 Redis 持久化：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.dao.SaTokenDao;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; cn.dev33.satoken.dao.SaTokenDaoForRedisx;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Configuration;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Inject;
&lt;span style="color:#a626a4"&gt;import&lt;/span&gt; org.noear.solon.annotation.Managed;

&lt;span style="color:#4078f2"&gt;@Configuration&lt;/span&gt;
&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;SaTokenDaoConfig&lt;/span&gt; {
    &lt;span style="color:#4078f2"&gt;@Managed&lt;/span&gt;
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; SaTokenDao &lt;span style="color:#4078f2"&gt;saTokenDaoInit&lt;/span&gt;&lt;span&gt;(&lt;span style="color:#4078f2"&gt;@Inject("${sa-token.dao}")&lt;/span&gt; SaTokenDaoForRedisx saTokenDao)&lt;/span&gt; {
        &lt;span style="color:#a626a4"&gt;return&lt;/span&gt; saTokenDao;
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 单点登录（SSO）&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 提供了 SSO 模块，可以快速实现单点登录功能。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入 SSO 依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-sso&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置 SSO 相关参数：app.yml&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;&lt;span style="color:#986801"&gt;sa-token:&lt;/span&gt;
  &lt;span style="color:#986801"&gt;sso-client:&lt;/span&gt;
    &lt;span style="color:#986801"&gt;client:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;demo-app&lt;/span&gt;
    &lt;span style="color:#986801"&gt;server-url:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;http://sso-server.com&lt;/span&gt;
    &lt;span style="color:#986801"&gt;is-http:&lt;/span&gt; &lt;span style="color:#0184bb"&gt;true&lt;/span&gt;
    &lt;span style="color:#986801"&gt;secret-key:&lt;/span&gt; &lt;span style="color:#50a14f"&gt;SSO-C3-kQwIOrYvnXmSDkwEiFngrKidMcdrgKor&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. OAuth2.0 支持&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;&lt;code&gt;Sa-Token&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;也支持&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;协议，可以实现与第三方平台的对接。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;引入&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;依赖：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;cn.dev33&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;sa-token-oauth2&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.44.0&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;配置&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;OAuth2.0&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;参数和实现授权流程（此处略，具体可参考官方文档）。&lt;/p&gt; 
&lt;h3&gt;4. 多账号体系&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;如果系统中存在多种身份的用户，例如普通用户、管理员、商家等，可以使用多账号体系进行区分。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;登录指定账号体系：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 管理员登录，loginKey 为"admin"&lt;/em&gt;
StpUtil.login(&lt;span style="color:#986801"&gt;10001&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;检查登录状态：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 检查当前账号体系下是否登录&lt;/em&gt;
&lt;span style="color:#986801"&gt;boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;isLogin&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; StpUtil.isLogin(&lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;权限验证：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 在指定账号体系下进行权限验证&lt;/em&gt;
StpUtil.checkPermission(&lt;span style="color:#50a14f"&gt;"user:update"&lt;/span&gt;, &lt;span style="color:#50a14f"&gt;"admin"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;四、Sa-Token 使用总结&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Sa-Token 是一款轻量级的 Java 权限认证框架，因其简单易用和功能丰富而备受开发者青睐。它以简洁明了的 API 设计，使得集成和使用变得非常方便，开发者可以快速上手，降低了学习成本。Sa-Token 支持多种权限控制需求，满足复杂业务场景，包括登录认证、权限验证、角色验证、Session 会话、多账号体系等功能，全面覆盖了权限管理的各个方面。其轻量级的设计对系统性能影响小，适用于高并发的应用环境。此外，Sa-Token 提供了丰富的扩展接口，与 Spring、SpringBoot、Solon 等常用框架高度兼容，支持自定义持久化、注解方式验证、单点登录等高级特性，方便开发者根据项目需求进行定制开发。活跃的社区支持和丰富的文档资源也使得开发者能够轻松获取帮助和指导。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;由于这些优势，Sa-Token 非常适 Web 项目的快速开发和微服务架构下的权限管理。当项目需要快速搭建权限系统时，选择 Sa-Token 是一个理想的方案。然而，在使用过程中需要注意 Token 的安全性，防止泄露带来风险；对于高并发场景，建议使用 Redis 等持久化介质来提高系统性能和扩展性；同时，关注 Sa-Token 的版本更新，及时获取新功能和安全补丁，以确保系统的安全性和稳定性。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;此文参考自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnblogs.com%2Fliuguangzhi%2Farticles%2F18415627" target="_blank"&gt;https://www.cnblogs.com/liuguangzhi/articles/18415627&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369936</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369936</guid>
      <pubDate>Mon, 01 Sep 2025 11:12:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>快手发布工业级规模强化学习 (RL) 训练框架 SeamlessFlow</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手 Kwaipilot 团队近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F_pewU-ZtVhhEpJVebwKysQ" target="_blank"&gt;发布&lt;/a&gt;了 SeamlessFlow 技术报告，SeamlessFlow 是该团队所使用的工业级规模强化学习（RL）训练框架。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1436" src="https://static.oschina.net/uploads/space/2025/0902/184001_9a1i_2720166.png" width="2762" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该框架通过创新的数据平面架构，对 RL 的训练逻辑和 Agent 做了彻底解耦，用以支持多智能体、在线强化学习训练等复杂场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184245_Kuc6_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更进一步，针对 RL 计算资源分配问题，团队提出了「标签分配机制」，统一了该领域最广泛的两种设计模式（训推共卡、训推分离）。以标签分配的思路为出发点，在业界首个提出「时空复用 pipeline」，实现了在训推分离的异构集群上彻底消除 Pipeline Bubble 的效果。&lt;/p&gt; 
&lt;p&gt;在实际测试中，SeamlessFlow 的端到端 token 吞吐量相比基线提升 100%，整体训练时间减少 62%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184306_P1R7_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/184325_U9bF_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;详细内容查看技术报告：&lt;em&gt;https://arxiv.org/abs/2508.11553&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369933</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369933</guid>
      <pubDate>Mon, 01 Sep 2025 10:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Salesforce 裁员 4000 人，引入 AI 代理</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;作为一家知名的客户关系管理（CRM）平台，Salesforce 近日宣布其客户支持团队从 9000 人减少至约 5000 人。这一变化是由于公司推出了新的代理服务和支持产品。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="325" src="https://oscimg.oschina.net/oscnet/up-7cb3d84925fce813c55404c48eaee49bc24.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Salesforce 的首席执行官马克・贝尼奥夫（Marc Benioff）在最近的一次播客中透露，公司自称为该工具的 「客户零」(customer zero)，并表示这一系统已经成功处理了约 150 万次客户对话，而在相同的时间段内，人工支持代理的对话数量大致相同。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;贝尼奥夫强调，人工智能的引入不仅仅是为了降低成本，更是为了提高公司的收入。他指出，Salesforce 在过去 26 年中积累了超过 1 亿个未处理的潜在客户，主要是由于人员不足。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;现在，借助新的代理销售系统，Salesforce 能够联系到每一个潜在客户，每周进行超过 1 万次的对话。这一措施使得 Salesforce 的市场响应能力显著提高，同时为公司创造了新的商机。未来，Salesforce 希望能通过不断优化和改进其 AI 系统，进一步增强公司的竞争力，实现更大的商业成功。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369931</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369931</guid>
      <pubDate>Mon, 01 Sep 2025 10:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>把 DolphinScheduler 搬进 K8s：奇虎 360 商业化 900 天踩坑全记录</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/qi-hu.png" alt="奇虎" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;👋 大家好，我是远朋。过去 3 年，我们团队把部分调度任务从 Azkaban 逐步迁移到 DolphinScheduler，并开展了 K8s 容器化。今天把踩过的坑、攒下的经验一次性覆盘，建议收藏！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;作者介绍&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/wang-yuan-peng.jpg" alt="王远朋" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王远朋&lt;/strong&gt; 上海奇虎科技有限公司，数据专家，商业化 SRE &amp;amp; 大数据团队核心成员，长期负责 DolphinScheduler 在生产环境的部署与优化，具备丰富的容器化与大数据调度经验。&lt;/p&gt; 
&lt;p&gt;在大数据任务调度的日常工作中，Apache DolphinScheduler 已经成为我们团队最核心的工具之一。过去我们一直依赖物理机进行部署，例如 3.1.9 版本仍运行在&lt;strong&gt;物理机&lt;/strong&gt;环境中，但这种方式在弹性扩展、资源隔离和运维效率上逐渐暴露出问题。随着公司整体的云原生战略推进，我们最终在 2025 年将 DolphinScheduler 升级到 3.2.2，并部分迁移到 &lt;strong&gt;Kubernetes 平台&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;迁移的动机非常明确：首先是&lt;strong&gt;弹性扩容&lt;/strong&gt;，K8S 可以根据任务高峰快速扩展 Worker 节点；其次是&lt;strong&gt;资源隔离&lt;/strong&gt;，避免不同任务相互影响；再者是&lt;strong&gt;自动化部署与回滚&lt;/strong&gt;，大幅降低维护成本；最后，也是最重要的一点，这一切符合公司在技术层面的&lt;strong&gt;云原生方向&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;镜像构建：从源码到模块&lt;/h3&gt; 
&lt;p&gt;在迁移过程中，镜像构建是第一步。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563633473102.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们先准备了一个包含 Hadoop、Hive、Spark、Flink、Python 等环境的基础镜像，然后在此基础上构建 DolphinScheduler 的基础镜像，将重新编译的各个模块和 MySQL 驱动打包其中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634307756.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这里需要注意的是，MySQL 被用作 DolphinScheduler 的元数据存储，因此驱动包必须软链到每一个模块，包括 &lt;code&gt;dolphinscheduler-tools&lt;/code&gt;、&lt;code&gt;dolphinscheduler-master&lt;/code&gt;、&lt;code&gt;dolphinscheduler-worker&lt;/code&gt;、&lt;code&gt;dolphinscheduler-api&lt;/code&gt; 和 &lt;code&gt;dolphinscheduler-alert-server&lt;/code&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563635065036.jpg" alt="" referrerpolicy="no-referrer"&gt; Worker 镜像&lt;/p&gt; 
&lt;p&gt;模块镜像则是在 DS 基础镜像之上进行定制，主要修改端口和配置。为了减少后续配置文件的改动，我们尽量保持模块镜像的名称与官方一致。构建时既可以单独构建某个模块，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build.sh worker-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634594536.jpg" alt="" referrerpolicy="no-referrer"&gt; 单独构建镜像&lt;/p&gt; 
&lt;p&gt;也可以批量构建所有模块：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build-all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563634803090.jpg" alt="" referrerpolicy="no-referrer"&gt; 批量构建镜像&lt;/p&gt; 
&lt;p&gt;这一步里我们遇到的典型问题包括：&lt;strong&gt;基础镜像过大导致构建时间过长，源码改造后的 jar 包没有覆盖旧文件，甚至不同模块的端口配置和启动脚本不一致。&lt;/strong&gt; 这些细节如果处理不当，就会在后续部署阶段带来一系列棘手的问题。&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;问题&lt;/th&gt; 
   &lt;th&gt;解决方案&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;基础镜像过大、构建慢&lt;/td&gt; 
   &lt;td&gt;把公共软件层拆成多阶段构建缓存&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MySQL 驱动找不到&lt;/td&gt; 
   &lt;td&gt;建软链到所有模块 &lt;code&gt;lib/&lt;/code&gt; 目录&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;自编译 Jar 没覆盖旧包&lt;/td&gt; 
   &lt;td&gt;build.sh 里加 &lt;code&gt;find -name "*.jar" -delete&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;部署方案：从自制 YAML 到官方 Helm Chart&lt;/h3&gt; 
&lt;p&gt;在部署初期，我们是手写 YAML 文件来完成部署的，但这种方式在配置分散和升级维护上成本极高。后来我们改用了官方提供的 Helm Chart，这样配置集中管理，升级也更方便。&lt;/p&gt; 
&lt;p&gt;我们使用的 K8S 集群版本是 v1.25，部署时需要先创建命名空间 &lt;code&gt;dolphinscheduler&lt;/code&gt;，然后拉取 helm 包，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm pull oci://registry-1.docker.io/apache/dolphinscheduler-helm --version 3.2.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在真正落地过程中，&lt;code&gt;values.yaml&lt;/code&gt; 是最核心的文件，我们在这里踩过很多坑。下面贴出几个关键配置片段，供大家参考：&lt;/p&gt; 
&lt;h4&gt;1. 镜像配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;image:
  registry: my.private.repo
  repository: dolphinscheduler
  tag: 3.2.2
  pullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 提示：一些前置的工具镜像最好提前 push 到私有仓库，避免因网络或镜像源问题导致部署失败。&lt;/p&gt; 
&lt;h4&gt;2. 外置数据库配置（MySQL）&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mysql:
  enabled: false   # 关闭内置 MySQL
externalMysql:
  host: mysql.prod.local
  port: 3306
  username: ds_user
  password: ds_password
  database: dolphinscheduler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 内置数据库务必关闭，生产环境统一接入外部 MySQL（未来我们将切换到 PostgreSQL）。&lt;/p&gt; 
&lt;h4&gt;3. LDAP 登录认证&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;ldap:
  enabled: true
  url: ldap://ldap.prod.local:389
  userDn: cn=admin,dc=company,dc=com
  password: ldap_password
  baseDn: dc=company,dc=com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 我们接入了公司 LDAP，统一用户认证，方便权限管理。&lt;/p&gt; 
&lt;h4&gt;4. 共享存储配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sharedStoragePersistence:
  enabled: true
  storageClassName: nfs-rwx
  size: 100Gi
  mountPath: /dolphinscheduler/shared
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 注意：storageClassName 必须支持 &lt;code&gt;ReadWriteMany&lt;/code&gt;，否则多个 Worker 节点无法同时访问共享目录。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563644421212.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h4&gt;5. HDFS 配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;hdfs:
  defaultFS: hdfs://hdfs-nn:8020
  path: /dolphinscheduler
  rootUser: hdfs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 所有大数据相关组件路径需要提前准备好，例如 &lt;code&gt;/opt/soft&lt;/code&gt;。&lt;/p&gt; 
&lt;h4&gt;6. Zookeeper 配置&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;zookeeper:
  enabled: false   # 关闭内置 ZK
externalZookeeper:
  quorum: zk1.prod.local:2181,zk2.prod.local:2181,zk3.prod.local:2181
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;👉 使用外置 Zookeeper 时，记得关闭内置配置，同时确认 ZK 版本符合官方最低要求。&lt;/p&gt; 
&lt;h3&gt;踩坑经验与维护挑战&lt;/h3&gt; 
&lt;p&gt;在整个迁移过程中，我们踩过的坑不少。比如，镜像制作问题、Helm values.yaml 修改的坑，以及定制化升级和维护成本过高等。&lt;/p&gt; 
&lt;h4&gt;镜像制作相关问题&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;镜像制作时因为基础镜像太大，导致构建过程漫长；&lt;/li&gt; 
 &lt;li&gt;模块依赖差异导致重复安装；&lt;/li&gt; 
 &lt;li&gt;有时候 MySQL 驱动包路径不正确，模块启动时报错；&lt;/li&gt; 
 &lt;li&gt;源码改造后的 jar 包忘记覆盖旧文件，也曾造成过运行时异常，不同模块端口与启动脚本不一致，导致启动不顺利。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Helm values.yaml 注意点&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;sharedStoragePersistence.storageClassName 必须支持 ReadWriteMany 存储类&lt;/li&gt; 
 &lt;li&gt;storage 大小&lt;/li&gt; 
 &lt;li&gt;mountPath 与配置文件不一致&lt;/li&gt; 
 &lt;li&gt;配置项路径缩进&lt;/li&gt; 
 &lt;li&gt;关闭默认配置以及一些不需要的配置，例如 Zookeeper 外置时需关闭内置选项，同时注意 zk 需要的版本&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;维护升级成本&lt;/h4&gt; 
&lt;p&gt;更大的挑战来自后续维护。因为我们对源码和镜像做过定制化修改，所以每当 DolphinScheduler 发布新版本，我们都需要重新对比修改点，重新构建并测试全部模块镜像。&lt;/p&gt; 
&lt;p&gt;同时，由于不同版本之间配置项差异较大，升级和回滚的过程都容易出错。这些问题导致我们的升级周期变长，维护难度加大，团队人力成本也显著上升。&lt;/p&gt; 
&lt;h3&gt;未来规划与思考&lt;/h3&gt; 
&lt;p&gt;为了降低长期的运维成本，我们已经在逐步推进标准化。未来计划包括： 将 DolphinScheduler 的元数据库从 MySQL 切换到 PostgreSQL，全面采用社区官方镜像而非自研镜像，生产任务也会逐步迁移到 K8S 环境中。&lt;/p&gt; 
&lt;p&gt;同时，我们会引入 CI/CD 流程，并结合 Prometheus 与 Grafana 做可观测性建设，提升部署效率与监控能力。&lt;/p&gt; 
&lt;p&gt;总的来说，K8S 部署让 DolphinScheduler 在扩展性、弹性和迁移性上具备了远超物理机的优势。虽然镜像定制化和配置修改带来了不小的挑战，但随着我们逐渐回归社区版本和标准化运维，维护成本会越来越低，部署效率会越来越高。&lt;/p&gt; 
&lt;p&gt;我们的长期目标，是构建一个高可用、易扩展、统一化的调度平台，真正释放云原生的价值。如果你也在考虑把调度系统搬上 K8s，欢迎评论区交流，或加入 DolphinScheduler 社区一起搬砖！&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/2025/08/28/17563644922397.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/dailidong/blog/18690374</link>
      <guid isPermaLink="false">https://my.oschina.net/dailidong/blog/18690374</guid>
      <pubDate>Mon, 01 Sep 2025 10:27:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Kuscia - 基于 K3s 的轻量级隐私计算任务编排框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;Kuscia（Kubernetes-based Secure Collaborative InfrA）是一款基于 K3s 的轻量级隐私计算任务编排框架，旨在屏蔽异构基础设施和协议，并提供统一的隐私计算底座。&lt;/p&gt;

&lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;通过 Kuscia：&lt;/p&gt;

&lt;ul style="margin-left:0; margin-right:0"&gt;
&lt;li&gt;轻量化部署：你可以用最低 1C2G 的资源完成 100W 级数据隐私求交 (PSI)。&lt;/li&gt;
&lt;li&gt;跨域网络安全通信：可以实现多隐私计算任务并发执行时的端口复用（仅需一个公网端口）与安全通信。&lt;/li&gt;
&lt;li&gt;统一的 API 接口：可以使用&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.secretflow.org.cn/zh-CN/docs/kuscia/main/reference/apis/summary_cn"&gt;HTTP/GRPC API 接口&lt;/a&gt;&lt;/span&gt;集成隐私计算能力。&lt;/li&gt;
&lt;li&gt;互联互通：可以与行业内多种隐私计算系统进行互联互通。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="color:rgba(0, 0, 0, 0.88); margin-left:0; margin-right:0; text-align:start"&gt;更多 Kuscia 的能力介绍，可参考&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;&lt;a href="https://www.secretflow.org.cn/zh-CN/docs/kuscia/main/reference/overview"&gt;Kuscia 概述&lt;/a&gt;&lt;/span&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="377" src="https://static.oschina.net/uploads/space/2025/0829/154436_QAD6_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/kuscia</link>
      <guid isPermaLink="false">https://www.oschina.net/p/kuscia</guid>
      <pubDate>Mon, 01 Sep 2025 10:18:00 GMT</pubDate>
    </item>
    <item>
      <title>清华与东北大学联合推出 UltraRAG 2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;清华大学 THUNLP 实验室、东北大学 NEUIR 实验室与 OpenBMB 及 AI9Stars 联合发布了 UltraRAG2.0，这是首个基于 Model Context Protocol（MCP）架构设计的检索增强生成 (RAG) 框架。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该框架致力于简化 RAG 系统的构建过程，使科研人员可以在短时间内实现复杂的多阶段推理系统。UltraRAG2.0 的亮点在于用户只需通过编写 YAML 文件，即可轻松声明复杂的逻辑，如串行、循环和条件分支，从而显著减少代码量，降低实现的门槛。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在当前的 RAG 发展趋势中，许多系统逐渐融入了自适应知识组织、多轮推理及动态检索等复杂特性，代表项目包括 DeepResearch 和 Search-o1。然而，这些复杂特性也给开发者带来了高昂的工程成本，制约了新想法的快速迭代与复现。UltraRAG2.0 应运而生，它通过将 RAG 的核心组件封装为独立的 MCP 服务器，实现了功能的灵活调用和扩展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;具体而言，与以往的实现方式相比，UltraRAG2.0 在代码量上大幅减少。例如，经典方法 IRCoT 的官方实现需要近 900 行代码，而使用 UltraRAG2.0 只需约 50 行代码就能完成同等功能。其中一半的代码是用于流程编排的 YAML 伪代码，极大降低了开发门槛。框架支持通过简洁的声明式方式来构建多阶段推理流程，使得复杂的推理逻辑不再需要冗长的手动编码。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="316" src="https://oscimg.oschina.net/oscnet/up-8ffdf7ae1633d0f30510d1cb66672338fbe.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;UltraRAG2.0 还支持动态检索、条件判断及多轮交互等&lt;span&gt;高级&lt;/span&gt;功能，科研人员可以在短时间内搭建出高性能的实验平台，满足复杂多跳问题的需求。其性能较传统的 Vanilla RAG 提升约 12%。该系统的设计旨在让研究者在工程实现方面节省时间和精力，将更多的注意力放在算法创新和实验设计上。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，UltraRAG2.0 的 MCP 架构允许不同模块间的无缝复用，并支持模块的灵活扩展和接入，方便科研人员快速适配新的模型和算法。这一设计极大提升了系统开发的效率和可复现性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369915</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369915</guid>
      <pubDate>Mon, 01 Sep 2025 09:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>这款全新的 Linux 桌面发行版几乎与 OS X 如出一辙</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Gershwin 是一款正在开发中的全新开源 Linux 桌面环境，目标是在 BSD 与 Arch Linux 上带来类似 macOS 的使用体验。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-86d4824b0345ee3351031cb07530c092dda.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5f1b49d23ae230a85b749ebeb383dd209f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;em&gt;https://github.com/gershwin-desktop/gershwin-desktop&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Gershwin 基于 GnuStep，而 GnuStep 本身源自 NeXTStep（macOS 的前身），因此界面风格自然与 OS X 十分接近。不过，由于 GnuStep 的老派设计，&lt;strong&gt;Gershwin 更像是「复古版 macOS」，看起来更接近早期的 OS X&lt;/strong&gt;，而非现代的 macOS。&lt;/p&gt; 
&lt;p&gt;目前 Gershwin 仍处于早期 alpha 阶段，功能有限：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;应用程序通过 Dock 管理，而非桌面图标；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;应用启动器尚不稳定，运行程序常需手动调用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最稳定的体验方式是通过 GhostBSD 运行，也能在 Arch Linux 上安装，但不推荐。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;虽然现阶段实用性不足，但 Gershwin 展现了独特潜力：一个兼具怀旧感与现代性，的桌面环境。如果开发顺利推进，它有望成为 BSD/Linux 用户的另类选择。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369912</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369912</guid>
      <pubDate>Mon, 01 Sep 2025 09:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>宇树科技宣布将在四季度提交 IPO 申请</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;宇树科技在社交媒体上发帖称，预计将在 2025 年 10 月至 12 月期间向证券交易所提交上市申请文件，届时公司的相关运营数据将正式披露。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="652" src="https://oscimg.oschina.net/oscnet/up-adeb6b500a9f884cfa342d939c1ffff851d.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇树科技表示，以 2024 年为例，四足机器人、人形机器人和组件产品的销售额分别占约 65%、30% 和 5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其中，约 80% 的四足机器人被应用于研究、教育和消费领域，而剩余的 20% 则被用于工业领域，如检查与消防。人形机器人完全用于研究、教育和消费领域。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369909</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369909</guid>
      <pubDate>Mon, 01 Sep 2025 09:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linux 文件系统 Btrfs 长期贡献者退出内核项目，加入 Anthropic</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Josef Bacik 是长期参与 Btrfs 文件系统开发的资深工程师，他在 2025 年 8 月 29 日宣布离开 Meta（原 Facebook），选择加入 AI 公司 Anthropic，投身 AI 基础设施事业，并不再将 Linux 内核开发作为主要职业方向。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b2d57c0b86cc532363c44a3c1f2bebc2583.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Josef Bacik 说道，下周我将开启新篇章，加入 Anthropic，协助其扩展基础设施；&lt;strong&gt;这也是我职业生涯中第一次不再以内核开发为主的工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Next week I start a new chapter, I will be joining Anthropic to help them scale out their infrastructure … I will be stepping back from kernel development as my primary job for the first time in my career.」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Josef Bacik 对曾经所在团队表达了高度认可，也坦言时间到了该进入新阶段，他希望运用自己在内核与系统方面的多年经验，协助 Anthropic 扩展基础设施。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369907</guid>
      <pubDate>Mon, 01 Sep 2025 09:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 与 Scale AI 合作现裂痕</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;自今年 6 月以来，尽管 Meta 向数据标注公司 Scale AI 投资了高达 143 亿美元，并聘请其首席执行官 Alexandr Wang 等高管加盟 Meta Superintelligence Labs （MSL），但双方的关系似乎正面临挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;核心问题源于数据质量的争议。尽管进行了巨额投资，但消息人士透露，Meta 核心 AI 部门 TBD Labs 的研究人员普遍认为 Scale AI 的数据质量不佳，更倾向于与 Scale AI 的主要竞争对手 Mercor 和 Surge 合作。Meta 的 TBD Labs 在成立前就已与这两家公司有合作，但向一家数据供应商投入如此巨资后，仍然依赖其竞争对手的情况十分罕见。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-949f1f529dd7a49117f6b1fcb77a8d33a02.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这种现象背后反映出数据标注行业的变化。早期，Scale AI 的众包模式依赖低成本劳动力处理简单任务，但随着 AI 模型复杂化，需要医生、律师等高技能领域专家来提供高质量数据。尽管 Scale AI 推出了 Outlier 平台，但像 Mercor 和 Surge 这样从一开始就建立在高薪人才模式上的竞争对手正迅速崛起。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了商业合作上的紧张，双方的人事整合也遭遇挫折。Scale AI 前高管 Ruben Mayer 在加入 Meta 仅两个月后便离职，进一步引发外界关注。尽管 Mayer 表示是因「个人原因」离开，且对在 Meta 的工作经历感到满意，但他对自己在 Meta 的职责定位与内部消息人士的说法存在分歧。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Meta 的 AI 部门也面临人才流失问题。有前员工和现任员工透露，自从引入 Alexandr Wang 和一批来自 OpenAI 等公司的人才后，Meta 的 AI 部门变得混乱。新加入的人员对大公司的官僚作风感到沮丧，而 Meta 原有的 GenAI 团队则感到能力受限。MSL AI 研究员 Rishabh Agarwal 等多名核心员工近期相继离职，这给 Meta 的 AI 发展前景蒙上阴影。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这次投资被普遍认为是 Meta CEO 扎克伯格在 Llama4 发布平淡后，为追赶 OpenAI 和谷歌而采取的紧急举措。他不仅吸纳了 Alexandr Wang，还积极从 OpenAI、谷歌 DeepMind 等公司招募顶尖人才。然而，鉴于部分新员工的迅速离职以及内部团队的混乱，Meta 能否稳定其 AI 运营并留住人才，仍是一个悬而未决的问题。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369898</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369898</guid>
      <pubDate>Mon, 01 Sep 2025 08:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源操作系统框架 Genode OS 发布 25.08 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源操作系统框架 Genode OS 发布了 25.08 版本，引入了新的内核调度器以实现公平性和低延迟，探索了 XML 的替代方案，优化了块存储堆栈，并将所有基于 Linux 的 PC 驱动程序更新至内核版本 6.12。&lt;/p&gt; 
&lt;p&gt;此外，该版本还为最新版本 13.0 的 seL4 微内核解锁了更多动态场景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-843a3a17acca0079fa8555dc66189112455.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;核心调度器（Kernel Scheduler）重构：优化公平性与延迟&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新版本对 Genode OS 中的内核调度器进行了全面重构，尤其为其通用操作系统 Sculpt OS 考量了动态工作负载的需求，优化了任务调度的公平性与响应延迟。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;块存储层（Block Layer）改进&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对块存储子系统进行了多项优化，包括精简数据路径、提升 I/O 性能。这些改进通过整体优化块存储栈，减少中间组件（如分区管理模块）的参与，增强了多队列硬件支持能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux 驱动更新至 Kernel 6.12 LTS&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genode 的 Linux 驱动组件——在其 Linux 驱动环境中使用的驱动程序均已升级，基于 Linux 6.12 LTS 源代码，对硬件兼容性和稳定性进行了增强。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;兼容 seL4 微内核：支持 seL4 版本 13.0&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genode 持续扩展其对 seL4 微内核的支持。此版本中，已将 seL4 内核更新到最新 13.0 版本，并解决了先前存在的可扩展性瓶颈，尤其改善了动态场景（如插拔式驱动加载）下的表现。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;探索 XML 的替代语法&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了改进配置与报告流程，新版本引入了对 XML 的替代语法支持，允许配置文件逐步从 XML 切换到更轻量的形式，并支持与 XML 之间的互操作性，这一思路已规划超过两年，本次进入实用评估阶段。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;https://genode.org/documentation/release-notes/25.08&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369887</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369887</guid>
      <pubDate>Mon, 01 Sep 2025 08:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Agent 架构综述：从 Prompt 到 Context</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;div&gt;
   资料来源： 
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" rel="nofollow" target="_blank"&gt;火山引擎-开发者社区&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   背景 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;在观察去年以来对于「Prompt Engineering」的解构时，我们可以观察到一个微妙但重要的分歧。&lt;br&gt; 一方面，专注于构建可扩展系统的前沿实践者们（如 Andrej Karpathy 等），积极倡导用 「Context Engineering」 来描述工作，认为 「Prompt Engineering」 这个词不足以涵盖复杂性，认为它只是 「Coming up with a laughably pretentious name for typing in the chat box（给在聊天框里打字起的一个可笑的自命不凡的名字）」 。因为他们构建 Agent 系统的核心挑战并非仅仅是 Prompt，而是设计整个数据流以动态生成最终提示的架构。&lt;br&gt; 另一方面，近年来学术和正式文献倾向用 「Prompt Engineering」 作为一个广义的 umbrella term（伞形术语），其定义包括了 「Supporting content」 或 「Context」，把所有在不改变模型权重的前提下操纵模型输入的技术归为同一类型。&lt;br&gt; 术语上的分歧可以反映该领域的成熟过程：随着 AI 应用从简单的单次交互发展到复杂的、有状态的智能体系统，优化静态指令已经无法满足需求。因此，「Context Engineering」 的出现，是为了区分两种不同层次的活动：一是编写指令的 skill，二是构建自动化系统以为该指令提供成功所需信息的科学。&lt;br&gt; （本文明确，尽管在学术上 Prompt Engineering 可能涵盖上下文，但在工程实践中，Context Engineering 是专注于如何动态构建和管理上下文的专门学科）&lt;br&gt; 重新定义 Agent 数据流：Context is All Aou Need&lt;br&gt; 本部分旨在建立 Prompt Engineering 与 Context Engineering 的基础概念，清晰地界定二者之间的区别与联系。&lt;br&gt; 从前者到后者的转变，代表了人工智能应用开发领域一次关键的演进——从业界最初关注的战术性指令构建，转向由可扩展、高可靠性系统需求驱动的战略性架构设计。&lt;br&gt; Prompt Engineering - the Art of Instructions&lt;br&gt; Prompt Engineering 是与大型语言模型（LLM）交互的基础，其核心在于精心设计输入内容，以引导模型生成期望的输出。这一实践为理解 Context Engineering 的必要性提供了基准。&lt;br&gt; 定义&lt;br&gt; 一个提示（Prompt）远不止一个简单的问题，它是一个结构化的输入，可包含多个组成部分 。这些组件共同构成了与模型沟通的完整指令：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;指令（Instructions）：对模型的核心任务指令，明确告知模型需要执行什么操作 。&lt;/li&gt; 
   &lt;li&gt;主要内容/输入数据（Primary Content/Input Data）：模型需要处理的文本或数据，是分析、转换或生成任务的对象 。&lt;/li&gt; 
   &lt;li&gt;示例（Examples/Shots）：演示期望的输入-输出行为，为模型提供「上下文学习」（In-Context Learning）的基础 。&lt;/li&gt; 
   &lt;li&gt;线索/输出指示器（Cues/Output Indicators）：启动模型输出的引导性词语，或对输出格式（如 JSON、Markdown）的明确要求 。&lt;/li&gt; 
   &lt;li&gt;支持性内容（Supporting Content/Context）：为模型提供的额外背景信息，帮助其更好地理解任务情境。正是这一组件，构成了 Context Engineering 发展的概念萌芽。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//6b223aea32c1b5b372958001ce21ce5e.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Prompt Engineering 的核心技术&lt;br&gt; Prompt Engineer 使用一系列技术来优化模型输出，这些技术可按复杂性进行分类：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;零样本提示（Zero-Shot Prompting）： 在不提供任何示例的情况下直接向模型下达任务，完全依赖其在预训练阶段获得的知识和推理能力。&lt;/li&gt; 
   &lt;li&gt;少样本提示（Few-Shot Prompting）： 在提示中提供少量（通常为 1 到 5 个）高质量的示例，以引导模型的行为。对于复杂任务，这种「上下文学习」方法被证明极为有效。&lt;/li&gt; 
   &lt;li&gt;思维链提示（Chain-of-Thought Prompting, CoT）： 引导模型将复杂问题分解为一系列中间推理步骤，显著增强了其在逻辑、数学和推理任务上的表现。&lt;/li&gt; 
   &lt;li&gt;高级推理技术： 在 CoT 的基础上，研究人员还开发了更为复杂的变体，如思维树（Tree-of-Thought）、苏格拉底式提示（Maieutic Prompting）和由简到繁提示（Least-to-Most Prompting），以探索更多样化的解决方案路径。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;以提示为中心的方法的局限性&lt;br&gt; 尽管 Prompt Engineering 至关重要，但对于构建稳健、可用于生产环境的系统而言，它存在固有的局限性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;脆弱性&amp;amp;不可复现性： 提示中微小的措辞变化可能导致输出结果的巨大差异，使得这一过程更像是一种依赖反复试错的「艺术」，而非可复现的「科学」。&lt;/li&gt; 
   &lt;li&gt;扩展性差： 手动、迭代地优化提示的过程，在面对大量用户、多样化用例和不断出现的边缘情况时，难以有效扩展。&lt;/li&gt; 
   &lt;li&gt;用户负担： 这种方法将精心构建一套详尽指令的负担完全压在了用户身上，对于需要自主运行、或处理高并发请求的系统而言是不切实际的。&lt;/li&gt; 
   &lt;li&gt;无状态性： Prompt Engineering 本质上是为单轮、「一次性」的交互而设计的，难以处理需要记忆和状态管理的长对话或多步骤任务。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Context Engineering 兴起：范式的转移&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//7f71fa2a848717aa220f2435fa704c03.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; Context Engineering 并非要取代 Prompt Engineering，而是一个更高阶、更侧重于系统设计的必要学科。&lt;br&gt; 定义 Context Engineering&lt;br&gt; Context Engineering 是一门设计、构建并优化动态自动化系统的学科，旨在为大型语言模型在正确的时间、以正确的格式，提供正确的信息和工具，从而可靠、可扩展地完成复杂任务。&lt;br&gt; prompt 告诉模型如何思考，而 Context 则赋予模型完成工作所需的知识和工具。&lt;br&gt; 「Context」的范畴&lt;br&gt; 「Context」的定义已远超用户单次的即时提示，它涵盖了 LLM 在做出响应前所能看到的所有信息生态系统：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系统级指令和角色设定。&lt;/li&gt; 
   &lt;li&gt;对话历史（短期记忆）。&lt;/li&gt; 
   &lt;li&gt;持久化的用户偏好和事实（长期记忆）。&lt;/li&gt; 
   &lt;li&gt;动态检索的外部数据（例如来自 RAG）。&lt;/li&gt; 
   &lt;li&gt;可用的工具（API、函数）及其定义。&lt;/li&gt; 
   &lt;li&gt;期望的输出格式（例如，JSON Schema）。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;对比分析&lt;br&gt; 关系：超集，而非对抗、竞争&lt;br&gt; Prompt Engineering 是 Context Engineering 的一个子集。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Context Engineering 决定用什么内容填充 Context Window，&lt;/li&gt; 
   &lt;li&gt;Prompt Engineering 则负责优化窗口内的具体指令。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//511d0ed709e085c5bef3f4862ddfb6fc.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;Prompt Engineering vs. Context Engineering&lt;br&gt; Context Engineering 的基石：RAG&lt;br&gt; 本部分将阐述检索增强生成（RAG）作为实现 Context Engineering 的主要架构模式。从「是什么」转向「如何做」，详细介绍 RAG 系统的组件和演进。&lt;br&gt; Retrieval-Augmented Generation&lt;br&gt; 为何 RAG 不仅是一种技术，更是现代 Context Engineering 系统的基础架构？&lt;br&gt; 解决 LLM 的核心弱点&lt;br&gt; RAG 直接解决了标准 LLM 在企业应用中存在的固有局限性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;知识冻结：LLM 的知识被冻结在其训练数据的时间点。RAG 通过在推理时注入实时的、最新的信息来解决这个问题。&lt;/li&gt; 
   &lt;li&gt;缺乏领域专有知识：标准 LLM 无法访问组织的内部私有数据。RAG 则能够将 LLM 连接到这些内部知识库，如技术手册、政策文件等。&lt;/li&gt; 
   &lt;li&gt;幻觉（Hallucination）：LLM 会不同程度上地编造事实。RAG 通过将模型的回答「锚定」在可验证的、检索到的证据上，提高事实的准确性和可信度。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;RAG 工作流&lt;br&gt; RAG 的实现通常分为两个主要阶段：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;索引（离线阶段）：在这个阶段，系统会处理外部知识源。文档被加载、分割成更小的 chunks，然后通过 Embedding Model 转换为向量表示，并最终存储在专门的向量数据库中以备检索。&lt;/li&gt; 
   &lt;li&gt;推理（在线阶段）：当用户提出请求时，系统执行以下步骤：&lt;/li&gt; 
   &lt;li&gt;检索（Retrieve）：将用户的查询同样转换为向量，然后在向量数据库中进行相似性搜索，找出与查询最相关的文档块。&lt;/li&gt; 
   &lt;li&gt;增强（Augment）：将检索到的这些文档块与原始的用户查询、系统指令等结合起来，构建一个内容丰富的、增强的最终提示。&lt;/li&gt; 
   &lt;li&gt;生成（Generate）：将这个增强后的提示输入给 LLM，LLM 会基于提供的上下文生成一个有理有据的回答。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;RAG 架构分类&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Naive RAG：即上文描述的基础实现。它适用于简单的问答场景，但在检索质量和上下文处理方面存在局限。&lt;/li&gt; 
   &lt;li&gt;Advanced RAG：这种范式在检索前后引入了处理步骤以提升质量。许多第三部分将详述的技术都属于这一范畴。关键策略包括：&lt;/li&gt; 
   &lt;li&gt;检索前处理：采用更复杂的文本分块策略、查询转换（如 StepBack-prompting）等优化检索输入。&lt;/li&gt; 
   &lt;li&gt;检索后处理：对检索到的文档进行 Re-ranking 以提升相关性，并对上下文进行 Compression。&lt;/li&gt; 
   &lt;li&gt;Modular RAG：一种更灵活、更面向系统的 RAG 视图，其中不同的组件（如搜索、检索、记忆、路由）被视为可互换的模块。这使得构建更复杂、更定制化的流程成为可能。具体模式包括：&lt;/li&gt; 
   &lt;li&gt;带记忆的 RAG：融合对话历史，以处理多轮交互，使对话更具连续性。&lt;/li&gt; 
   &lt;li&gt;分支/路由 RAG：引入一个路由模块，根据查询的意图决定使用哪个数据源或检索器。&lt;/li&gt; 
   &lt;li&gt;Corrective RAG, CRAG：增加了一个自我反思步骤。一个轻量级的评估器会对检索到的文档质量进行打分。如果文档不相关，系统会触发替代的检索策略（如网络搜索）来增强或替换初始结果。&lt;/li&gt; 
   &lt;li&gt;Self-RAG：让 LLM 自身学习判断何时需要检索以及检索什么内容，通过生成特殊的检索 Token 来自主触发检索。&lt;/li&gt; 
   &lt;li&gt;Agentic RAG：这是 RAG 最先进的形式，将 RAG 集成到一个智能体循环（agentic loop）中。模型能够执行多步骤任务，主动与多个数据源和工具交互，并随时间推移综合信息。这是 Context Engineering 在实践中的顶峰。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;向量数据库的角色&lt;br&gt; 本节将分析支撑 RAG 中「检索」步骤的关键基础设施，并比较市场上的主流解决方案。&lt;br&gt; Context Stack：一个新兴的 abstract layer&lt;br&gt; 观察 RAG 系统的构成—— 数据摄入、分块、嵌入、用于索引和检索的向量数据库、重排序器、压缩器以及最终的 LLM ——可以发现，这些组件并非随意组合，而是形成了一个连贯的、多层次的架构。这可以被抽象地称为 Context Stack。&lt;br&gt; 这个堆栈的数据流非常清晰：在离线索引阶段，数据从原始文档流向分块、嵌入，最终存入向量数据库 。在在线推理阶段，数据流从用户查询开始，经过嵌入、向量搜索、重排序、压缩，最终形成送入 LLM 的提示。&lt;br&gt; 这个堆栈的出现，标志着 AI 应用开发正在走向成熟，不同的技术供应商开始专注于 Stack 中的特定层面：Pinecone、Weaviate 和 Milvus 等公司在做 Database layer；LangChain 和 LlamaIndex 等框架提供了将所有组件粘合在一起的 Application Orchestration Layer；而 Cohere 和 Jina AI 等提供了专业的 Re-ranking as a Service（RaaS）模块。&lt;br&gt; 因此，理解新的 AI Agent 架构，就意味着理解 Context Engineering，就意味着要理解这个新兴的 Context Stack，了解其各个层次以及在每个层次上不同组件之间的权衡。这种视角将讨论从一系列孤立的技术提升到系统设计和技术选型的高度，对工程师和架构师而言具有更高的价值。&lt;/p&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;选型关键考量因素&lt;br&gt; 组织在选择向量数据库时必须考虑以下主要因素：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;模型：选择完全托管的云服务（如 Pinecone），还是可自托管的开源方案（如 Milvus、Weaviate）。&lt;/li&gt; 
   &lt;li&gt;扩展性：是否能处理数十亿级别的向量数据和高查询负载（Milvus）。&lt;/li&gt; 
   &lt;li&gt;功能集： 是否支持混合搜索（关键词+向量）、高级 meta 过滤以及多模态数据处理（Weaviate）。&lt;/li&gt; 
   &lt;li&gt;易用性与灵活性：是倾向于 API 简单、设置最少的方案（Pinecone），还是需要多种索引算法和深度配置选项的方案（Milvus） 。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;为了给技术选型提供一个实用的决策框架，下表对几个主流的向量数据库进行了比较。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//a8380c8f2c53d3fe8f1844e71413da76.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;主流 RAG 向量数据库对比分析&lt;br&gt; Context 工程化的核心概念和目标&lt;br&gt; 从原始数据到相关分块&lt;br&gt; 本节聚焦于从知识库中识别和检索最有价值信息的初始阶段。&lt;br&gt; 高级分块策略&lt;br&gt; 文本分块（Chunking）是 RAG 流程中最关键也最容易被忽视的一步。其目标是创建在语义上自成一体的文本块。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;朴素分块的问题：固定大小的分块方法虽然简单，但常常会粗暴地切断句子或段落，导致上下文支离破碎，语义不完整。&lt;/li&gt; 
   &lt;li&gt;内容感知分块：&lt;/li&gt; 
   &lt;li&gt;递归字符分割：一种更智能的方法，它会按照一个预设的分割符层次结构（如：先按段落，再按句子，最后按单词）进行分割，以尽可能保持文本的自然结构。&lt;/li&gt; 
   &lt;li&gt;文档特定分块：利用文档自身的结构进行分割，例如，根据 Markdown 的标题、代码文件的函数或法律合同的条款来划分。&lt;/li&gt; 
   &lt;li&gt;语言学分块：使用 NLTK、spaCy 等自然语言处理库，基于句子、名词短语或动词短语等语法边界进行分割。&lt;/li&gt; 
   &lt;li&gt;语义分块： 这是最先进的方法之一。它使用嵌入模型来检测文本中语义的转变点。当文本的主题或意义发生变化时，就在该处进行分割，从而确保每个分块在主题上是高度内聚的。研究表明，这种策略的性能优于其他方法。&lt;/li&gt; 
   &lt;li&gt;智能体分块：一个前沿概念，即利用一个 LLM 智能体来决定如何对文本进行分块，例如，通过将文本分解为一系列独立的 propositions 来实现。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;通过重排序提升精度&lt;br&gt; 为了平衡检索的速度和准确性，业界普遍采用两阶段检索流程。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;两阶段流程：&lt;/li&gt; 
   &lt;li&gt;第一阶段（召回）： 使用一个快速、高效的检索器（如基于 bi-encoder 的向量搜索或 BM25 等词法搜索）进行广泛撒网，召回一个较大的候选文档集（例如，前 100 个）。&lt;/li&gt; 
   &lt;li&gt;第二阶段（精排/重排序）： 使用一个更强大但计算成本更高的模型，对这个较小的候选集进行重新评估，以识别出最相关的少数几个文档（例如，前 5 个）。&lt;/li&gt; 
   &lt;li&gt;Cross-Encoder： 交叉编码器之所以在重排序阶段表现优越，是因为它与双编码器的工作方式不同。双编码器独立地为查询和文档生成嵌入向量，然后计算它们的相似度。而交叉编码器则是将查询和文档同时作为输入，让模型在内部通过 Attention Mechanism 对二者进行深度交互。这使得模型能够捕捉到更细微的语义关系，从而给出更准确的相关性评分。&lt;/li&gt; 
   &lt;li&gt;实际影响： 重排序显著提高了最终送入 LLM 的上下文质量，从而产出更准确、幻觉更少的答案。在金融、法律等高风险领域，重排序被认为是必不可少而非可选的步骤。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;div&gt;
     核心问题 - Lost in the Middle 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;span style="color:#245bdb"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2307.03172" rel="nofollow" target="_blank"&gt;https://arxiv.org/abs/2307.03172&lt;/a&gt;&lt;/span&gt; 
    &lt;span&gt;&amp;nbsp;&lt;/span&gt;Lost in the Middle: How Language Models Use Long Contexts 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 当前 LLM 存在一个根本性认知局限，这一局限使得简单的上下文堆砌变得无效，并催生了后续的优化技术。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;定义：LLM 在处理长上下文时表现出一种独特的 U 型，性能曲线。当关键信息位于上下文窗口的开头（首因效应）或结尾（近因效应）时，模型能够高效地利用这些信息。然而，当关键信息被 「hidden」在长篇上下文的中间位置时，模型的性能会显著下降。&lt;/li&gt; 
   &lt;li&gt;实验： 在多文档问答任务时，即使检索器召回了更多相关的文档，模型的性能提升也很快达到饱和。这意味着简单地增加上下文长度（即添加更多文档）不仅无益，甚至因为关键信息被淹没而损害性能 。&lt;/li&gt; 
   &lt;li&gt;「知道但说不出来」： 并非模型「找不到」信息。通过探测模型的内部表征发现，模型通常能够准确地编码关键信息的位置，但在生成最终答案时却未能有效利用这些信息。这表明在模型内部，信息检索和信息利用（或沟通）之间存在脱节。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//dc9e6245d2563332682a3c618cdd7a83.jpg" width="482" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;上下文丰富性与窗口局限性之间的考量&lt;br&gt; Context Engineering 的核心存在一个根本性的矛盾。一方面，提供丰富、全面的上下文是获得高质量响应的关键。另一方面，LLM 的上下文窗口是有限的，并且由于 Lost in the Middle、contextual distraction 等问题，过长的上下文反而会导致性能下降。&lt;br&gt; 一个朴素的想法是尽可能多地将相关信息塞进上下文窗口。然而，研究和实践都证明这是适得其反的。LLM 会被无关信息淹没、分心，或者干脆忽略那些不在窗口两端的信息。&lt;br&gt; 这就产生了一个核心的优化问题：如何在固定的 Token 预算内，最大化「信号」（真正相关的信息），同时最小化「噪声」（不相关或分散注意力的信息），并充分考虑到模型存在的认知偏差？&lt;br&gt; 这个考量是 Context Engineering 领域创新的主要驱动力。所有的高级技术——无论是语义分块、重排序，还是后续将讨论的压缩、摘要和智能体隔离——都是为了有效管理这一权衡而设计的。因此，Context Engineering 不仅是关于提供上下文，更是关于如何策划和塑造上下文，使其对一个认知能力有限的处理单元（LLM）最为有效。&lt;br&gt; 优化上下文窗口：压缩与摘要&lt;br&gt; 本节详细介绍用于主动管理上下文的技术，确保最有价值的信息被优先呈现。&lt;br&gt; 上下文压缩的目标&lt;br&gt; 缩短检索到的文档列表和/或精简单个文档的内容，只将最相关的信息传递给 LLM。这能有效降低 API 调用成本、减少延迟，并缓解 Lost in the Middle 的问题 。&lt;br&gt; 压缩方法&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;过滤式压缩： 这类方法决定是保留还是丢弃整个检索到的文档。&lt;/li&gt; 
   &lt;li&gt;LLMChainFilter：利用一个 LLM 对每个文档的相关性做出简单的「是/否」判断。&lt;/li&gt; 
   &lt;li&gt;EmbeddingsFilter：更经济快速的方法，根据文档嵌入与查询嵌入的余弦相似度来过滤文档。&lt;/li&gt; 
   &lt;li&gt;内容提取式压缩：这类方法会直接修改文档内容。&lt;/li&gt; 
   &lt;li&gt;LLMChainExtractor：遍历每个文档，并使用 LLM 从中提取仅与查询相关的句子或陈述 。&lt;/li&gt; 
   &lt;li&gt;用 top N 代替压缩：像 LLMListwiseRerank 这样的技术，使用 LLM 对检索到的文档进行重排序，并只返回排名最高的 N 个，从而起到高质量过滤器的作用。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;作为压缩策略的摘要&lt;br&gt; 对于非常长的文档或冗长的对话历史，可以利用 LLM 生成摘要。这些摘要随后被注入上下文，既保留了关键信息，又大幅减少了 Token 数量。这是在长时程运行的智能体中管理上下文的关键技术。&lt;br&gt; 智能体系统的上下文管理&lt;br&gt; 从 HITL 到 SITL&lt;br&gt; Prompt Engineering 本质上是一个手动的、Human-in-the-Loop 的试错过程。而 Context Engineering，尤其是在其智能体形式中，则是关于构建一个自动化的 System-in-the-Loop，这个系统在 LLM 看到提示之前就为其准备好上下文。&lt;br&gt; 一个人类提示工程师需要手动收集信息、组织语言并进行测试。而一个 Context Engineering 化的系统则将此过程自动化：RAG 流程本身就是一个自动收集信息的系统；路由器是一个自动决定收集哪些信息的系统；记忆模块是一个自动持久化和检索历史信息的系统。&lt;br&gt; 正是这种自动化，使得 AI 系统能够变得「智能体化」（Agentic）——即能够在没有人类为每一步微观管理上下文的情况下，进行自主的、多步骤的推理 。因此，Context Engineering 的目标是构建一个可靠、可重复的上下文组装机器。这台机器取代了提示工程师的临时性、手工劳动，从而使创建真正自主和可扩展的 AI 智能体成为可能。焦点从单个提示的「技艺」转向了生成该提示的「系统工程」。&lt;br&gt; 智能体上下文管理框架&lt;br&gt; LangChain 博客中提出的四个关键策略 ：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Write - 持久化上下文：&lt;/li&gt; 
   &lt;li&gt;Scratchpads：供智能体在执行复杂任务时使用的临时、会话内记忆，用于记录中间步骤。&lt;/li&gt; 
   &lt;li&gt;Memory：长期、持久化的存储，记录关键事实、用户偏好或对话摘要，可在不同会话间调用。&lt;/li&gt; 
   &lt;li&gt;Select - 检索上下文：根据当前的子任务，使用 RAG 技术动态地从记忆、工具库或知识库中选择相关上下文。这甚至包括对工具描述本身应用 RAG，以避免向智能体提供过多无关的工具选项。&lt;/li&gt; 
   &lt;li&gt;Compress - 优化上下文：利用摘要或修剪技术来管理智能体在长时程任务中不断增长的上下文，防止上下文窗口溢出和「 Lost in the Middle 」问题。&lt;/li&gt; 
   &lt;li&gt;Isolate - 分割上下文：&lt;/li&gt; 
   &lt;li&gt;多智能体系统： 将一个复杂问题分解，并将子任务分配给专门的子智能体，每个子智能体都拥有自己独立的、更聚焦的上下文窗口。&lt;/li&gt; 
   &lt;li&gt;沙盒环境： 在一个隔离的环境中执行工具调用，只将必要的执行结果返回给 LLM，从而将包含大量 Token 的复杂对象隔离在主上下文窗口之外。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//82e7bdc773a26d0eb5fc2244450bf8ae.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;多智能体架构中的 Context 数据流与工作流编排&lt;br&gt; LLM 正在从被动地响应用户查询的「响应者」，演变为能够自主规划、决策并执行多步骤复杂任务的「执行者」——即我们所说的「智能体」（AI Agent）。&lt;br&gt; 当一个智能体不再是简单地「输入-输出」，而是需要调用工具、访问数据库、与用户进行多轮交互时，其内部的数据是如何流动和管理的？如何进行技术选型？&lt;br&gt; 工作流（Workflow） vs. 智能体（Agent）&lt;br&gt; 在深入技术细节之前，建立一个清晰的概念框架至关重要。业界（如 Anthropic）倾向于对「智能体系统」进行两种架构上的区分。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//19c604cd74780dcfc6c552c74d304ff7.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;工作流（Workflows）&lt;br&gt; 指的是 LLM 和工具通过预定义的代码路径进行编排的系统。在这种模式下，数据流动的路径是固定的、由开发者明确设计的，类似于上世纪流行的「专家系统」。例如，「第一步：分析用户邮件；第二步：根据分析结果在日历中查找空闲时段；第三步：起草会议邀请邮件」。这种模式确定性高，易于调试和控制，非常适合有明确业务流程的场景（如风控需求高、数据敏感、安全等级要求）。&lt;br&gt; 智能体（Agents）&lt;br&gt; 指的是 LLM 动态地指导自己的流程和工具使用，自主控制如何完成任务的系统。在这种模式下，数据流动的路径不是预先固定的，而是由 LLM 在每一步根据当前情况和目标动态决定的。这种模式灵活性高，能处理开放式问题，但可控性和可预测性较低。&lt;br&gt; 复杂的智能体通常是这两种模式的混合体，在宏观层面遵循一个预定义的工作流，但在某些节点内部，又赋予 LLM 一定的自主决策权。管理这一切的核心，我们称之为编排层（Orchestration Layer）。&lt;br&gt; 多 Agent 编排的核心架构：预定义数据流的实现&lt;br&gt; 为了实现可靠、可控的数据流动，开发者们已经探索出几种成熟的架构模式。这些模式可以单独使用，也可以组合成更复杂的系统。&lt;br&gt; 链式工作流（Prompt Chaining）（GPT-3.5 时期的工作原理）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;数据流： 输入 -&amp;gt; 模块 A -&amp;gt; 输出 A -&amp;gt; 模块 B -&amp;gt; 输出 B -&amp;gt;... -&amp;gt; 最终输出&lt;/li&gt; 
   &lt;li&gt;工作原理： 每个模块（LLM 调用）只负责一个定义明确的子任务。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//9d2163cbd51a51e8e54055f3273ba99f.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 路由工作流（Routing）（o3 的早期工作原理）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;数据流： 输入 -&amp;gt; 路由器选择 =&amp;gt; -&amp;gt; 输出&lt;/li&gt; 
   &lt;li&gt;工作原理： 一个充当「路由器」的 LLM 调用，其唯一任务就是决策。它会分析输入数据，然后输出一个指令，告诉编排系统接下来应该调用哪个具体的业务模块。&lt;/li&gt; 
   &lt;li&gt;实现方式： LangGraph 使用 Conditional Edges 来实现这种逻辑，即一个节点的输出决定了图的下一跳走向何方。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//71e8c6a23709d8c211d75f1985830384.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 编排器-工作者模式（Orchestrator-Workers）&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;对于极其复杂的任务，可以采用多智能体（Multi-agent）架构，也称为 Orchestrator-Workers 模式。一个中心 Orchestrator 智能体负责分解任务，并将子任务分配给多个专职的 Workers 智能体。&lt;/li&gt; 
   &lt;li&gt;数据流：这是一个分层、协作的流动模式。 总任务 -&amp;gt; Orchestrator =&amp;gt; -&amp;gt; 结果汇总 -&amp;gt; 最终输出&lt;/li&gt; 
   &lt;li&gt;工作原理：每个工作者智能体都有自己独立的上下文和专用工具，专注于解决特定领域的问题。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//6566edba8fb0871ddefb19dbfaf4c2ac.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;决策与数据选择机制&lt;br&gt; 在上述架构中，智能体（或其模块）如何决定「需要什么数据」以及「下一步做什么」？这依赖于其内部的规划和推理能力。&lt;br&gt; ReAct 框架&lt;br&gt; ReAct（Reasoning and Acting）是一个基础且强大的框架，它通过模拟人类的「Reasoning-Acting」模式，使 LLM 能够动态地决定数据需求。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//57afee644faac0214fcb912c21c5426b.jpg" width="340" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 其核心是一个循环：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;思考（Thought）：LLM 首先进行内部推理。它分析当前任务和已有信息，判断是否缺少完成任务所需的知识，并制定下一步的行动计划。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：「用户问我今天旧金山的天气，但我不知道。我需要调用天气查询工具。」&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;行动（Action）： LLM 决定调用一个具体的工具，并生成调用该工具所需的参数。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：Action: search_weather(location="San Francisco")。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;观察（Observation）：系统执行该行动（调用外部 API），并将返回的结果作为「观察」数据提供给 LLM。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：Observation: "旧金山今天晴，22 摄氏度。"&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;再次思考： LLM 接收到新的观察数据，再次进入思考环节，判断任务是否完成，或是否需要进一步的行动。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;例如：「我已经获得了天气信息，现在可以回答用户的问题了。」&lt;br&gt; 在这个循环中，数据流是根据 LLM 的「思考」结果动态生成的。当 LLM 判断需要外部数据时，它会主动触发一个「行动」来获取数据，然后将获取到的「观察」数据整合进自己的上下文中，用于下一步的决策。&lt;br&gt; Planning 和任务分解&lt;br&gt; 对于更复杂的任务，智能体通常会先进行规划（Planning）。一个高阶的规划模块会将用户的宏大目标分解成一系列更小、更具体、可执行的子任务。&lt;br&gt; 数据流向： 规划模块的输出是一份「计划清单」（Planning List），这份清单定义了后续一系列模块的调用顺序和数据依赖关系。&lt;br&gt; （前一阵子流行的 Claude Code，刚更新的 Cursor v1.2，以及上个版本流行的 Gemini/GPT DeepResearch 就属于这个架构）&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//18112cec76c43ea86ad8c87a23c89639.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; 例如，对于「帮我策划一次巴黎三人五日游」的请求，规划模块可能会生成如下计划，并定义了每个步骤所需的数据输入和输出：&lt;br&gt; 1.[获取用户预算和偏好] -&amp;gt; [搜索往返机票]&lt;br&gt; 2.[机票信息] -&amp;gt; [根据旅行日期和预算搜索酒店]&lt;br&gt; 3.[酒店信息] -&amp;gt; [规划每日行程]&lt;br&gt; 4.[机票、酒店、行程信息] -&amp;gt; [生成最终行程单和预算报告]&lt;br&gt; Reflection 机制&lt;br&gt; 先进的智能体架构还包含反思（Reflection）机制 。智能体在执行完一个动作或完成一个子任务后，会评估其结果的质量和正确性。如果发现问题，它可以自我修正，重新规划路径。&lt;br&gt; （这是截止撰文时，各大主流 deep research 平台使用的核心技术方案） 数据流向： 这是一个反馈循环。模块的输出不仅流向下一个任务模块，还会流向一个「评估器」模块。评估器的输出（如「成功」、「失败」、「信息不足」）会反过来影响规划模块，从而调整后续的数据流向。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//43d3414957f84dcf5ff22836a10b9d5e.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;框架与工具&lt;br&gt; 上述的架构和机制并非凭空存在，而是通过具体的开发框架实现的。其中，LangGraph 作为 LangChain 的扩展，为构建具有显式数据流的智能体系统提供了强大的工具集。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;img src="https://oscimg.oschina.net/oscnet//ae0cd62c436db7fc2bf98ce3f3972c15.jpg" width="326" referrerpolicy="no-referrer"&gt; 
  &lt;/div&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;&lt;br&gt; LangGraph：用图（Graph）定义工作流（Workflow）&lt;br&gt; LangGraph 的核心思想是将智能体应用构建成一个状态图（State Graph）。这个图由节点和边组成，清晰地定义了数据如何在不同模块间流动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;状态（State）：这是整个图的核心，一个所有节点共享的中央数据对象。你可以把它想象成一个「数据总线」或共享内存。开发者需要预先定义 State 的结构，每个节点在执行时都可以读取和更新这个 State 对象 。&lt;/li&gt; 
   &lt;li&gt;节点（Nodes）：代表工作流中的一个计算单元或一个步骤。每个节点通常是一个 Python 函数，它接收当前的 State 作为输入，执行特定任务（如调用 LLM、执行工具、处理数据），然后返回对 State 的更新。&lt;/li&gt; 
   &lt;li&gt;边（Edges）：连接节点，定义了工作流的路径，即数据在 State 更新后应该流向哪个节点。&lt;/li&gt; 
   &lt;li&gt;简单边（Simple Edges）：定义了固定的、无条件的流向，用于实现链式工作流。&lt;/li&gt; 
   &lt;li&gt;条件边（Conditional Edges）： 用于实现路由逻辑。它会根据一个函数的输出来决定接下来应该走向哪个节点，从而实现流程的分支 。&lt;/li&gt; 
   &lt;li&gt;检查点（Checkpointer）： LangGraph 提供了持久化机制，可以在每一步执行后自动保存 State 的状态。这对于构建需要长期记忆、可中断和恢复、或需要 Human-in-the-Loop 的复杂业务流程至关重要。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#191b1f; margin-left:0; margin-right:0; text-align:start"&gt;复杂业务流程的 AI 智能体，其核心挑战已从单纯优化信息检索（如 RAG）或提示词，转向了对内部工作流和数据流的精心设计与编排。&lt;br&gt; Context Engineering 的未来&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Graph RAG 的兴起：标准的基于向量的 RAG 在处理高度互联的数据时存在局限。而利用知识图谱的图 RAG 不仅能检索离散的信息块，还能检索它们之间的显式关系。这使得模型能够进行更复杂的多跳推理，并提供上下文更准确的回答 。&lt;/li&gt; 
   &lt;li&gt;智能体自主性的增强：像 Self-RAG 和 Agentic RAG 这样更自主的系统将成为趋势，LLM 将承担更多管理自身上下文的责任。这将模糊 Context Engineering 系统与 LLM 本身之间的界限。&lt;/li&gt; 
   &lt;li&gt;超越固定上下文窗口：针对 Lost in the Middle 问题的研究正在进行中，包括探索新的模型架构（如改进的位置编码）和训练技术。这些研究的突破可能会从根本上改变当今 Context Engineering 师所面临的约束。&lt;/li&gt; 
   &lt;li&gt;终极目标：Context Engineering 本质上是一座桥梁，它是一套复杂的补偿机制，用以弥补 LLM 「don't read minds—they read tokens」的现实。人工智能研究的长期目标是创造出具有更强大内部世界模型的 AI，从而减少对此类庞大外部上下文支架的依赖。 Context Engineering 的演进，将是衡量我们朝此目标迈进的关键指标。&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18689521</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18689521</guid>
      <pubDate>Mon, 01 Sep 2025 08:15:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Wine 10.14 开发版发布，Windows 应用兼容层</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Wine 项目近日发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.winehq.org%2Fnews%2F2025082901" target="_blank"&gt; Wine 10.14 开发版&lt;/a&gt;。这是其双周更新的一部分，带来了多项重要改进：&lt;/p&gt; 
&lt;p&gt;主要更新内容与改进&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;VKD3D 升级至 1.17&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;包含新版 VKD3D（Direct3D 12 over Vulkan API 层），显著提升 D3D12 应用和游戏在 Linux 上的兼容性和性能。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mono 引擎更新至 10.2.0&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Mono 引擎得到更新，用于增强 .NET 应用在 Wine 环境下的运行表现。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持 IPv6 Ping&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Wine 的内置 「ping」 工具现已支持 IPv6，这为网络诊断和兼容性带来便利。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitLab CI 跳转至 Debian 「Trixie」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Wine 项目的持续集成系统（CI）现已迁移到使用 Debian 13 「Trixie」 作为构建环境，便于现代化管理与构建流程。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;19 项 Bug 修复&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;包含针对多款游戏（如 Phantasy Star Online: Blue Burst、GreedFall、Mafia III: Definitive Edition、Death to Spies）和应用（如 Roblox Studio 安装程序、VemsTune 等）的修复，以及 API 补丁，包括对 gameinput.dll、ntdll.dll、api-ms-win-core-memory、winepath 等系统组件的改进。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下载地址：&lt;em&gt;https://gitlab.winehq.org/wine/wine/-/releases/wine-10.14&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Wine 作为开源兼容层，能让 Windows 应用和游戏在 Linux、macOS 等平台运行，此次更新进一步强化了跨平台兼容性与稳定性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369877/wine-10-14</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369877/wine-10-14</guid>
      <pubDate>Mon, 01 Sep 2025 08:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>前 7 个月我国软件业利润总额 10890 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;工业和信息化部运行监测协调局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_461e0981c2564044b9ad2d67cf0e97f3.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;2025 年前 7 个月，我国软件和信息技术服务业（以下简称「软件业」）运行态势良好，软件业务收入、利润总额稳健增长，软件业务出口保持正增长。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;一、总体运行情况&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;前 7 个月，我国软件业务收入 83246 亿元，同比增长 12.3%。软件业利润总额 10890 亿元，同比增长 12.4%。软件业务出口 339.8 亿美元，同比增长 5.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;二、分领域运行情况&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;软件产品收入稳定增长。&lt;/span&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 个月，软件产品收入 18011 亿元，同比增长 10.6%，占全行业收入比重为 21.6%。其中，基础软件产品收入 1052 亿元，同比增长 13&lt;/span&gt;&lt;span style="color:#000000"&gt;.0&lt;/span&gt;&lt;span style="color:#000000"&gt;%；工业软件产品收入 1677 亿元，同比增长 8.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;信息技术服务收入保持两位数增长。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 个月，信息技术服务收入 57246 亿元，同比增长 13.4%，占全行业收入的 68.8%。其中，云计算、大数据服务共实现收入 8663 亿元，同比增长 12.6%，占信息技术服务收入的 15.1%；集成电路设计收入 2511 亿元，同比增长 18.5%；电子商务平台技术服务收入 7156 亿元，同比增长 9.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;信息安全收入和嵌入式系统软件收入平稳增长。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;&lt;span style="color:#000000"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;7 个月，信息安全产品和服务收入 1181 亿元，同比增长 6.2%。嵌入式系统软件收入 6809 亿元，同比增长 8.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;三、分地区运行情况&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;前 7 个月，东部地区、中部地区、西部地区和东北地区软件业务收入分别同比增长 12.6%、12.3%、10.4% 和 9.3%。东部地区占全国软件业务总收入的 84.3%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;京津冀地区软件业务收入同比增长 13.2%，长三角地区软件业务收入同比增长 14.7%。北京、广东、江苏、山东、上海软件业务收入居全国前 5，同比分别增长 13.4%、9.1%、14.4%、11.8% 和 20.1%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369876</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369876</guid>
      <pubDate>Mon, 01 Sep 2025 08:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 将原生支持 MKV 视频格式</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindowsreport.com%2Fmozilla-firefox-is-officially-getting-mkv-video-support%2F" target="_blank"&gt;据报道&lt;/a&gt;，Firefox 浏览器即将原生支持 &lt;code&gt;.mkv&lt;/code&gt;视频文件播放，用户无需再依赖插件或手动转换格式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4ae5363247ae1619e30c87b03d4f17b9b25.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mozilla&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1422891" target="_blank"&gt; 已指派工程师&lt;/a&gt;推动这一功能的开发，预计将按照以下阶段有序推进：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Nightly 版本做初步测试，针对最常见的音视频组合，例如 H.264 编码的视频 + AAC 音频进行优先支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;后期将扩大支持范围，加入 VP9、AV1 等视频编码，以及 Opus 或 FLAC 等音频格式。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在稳定性与兼容性通过全面检测后，会推广至正式版本的 Firefox 用户。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0902/152017_iqZR_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，Firefox 打开 MKV 文件时常常失败或直接触发下载，这在 Windows 10 和 11 已原生支持 MKV 的情况下，显得尤为不便。新功能上线后，Firefox 的多媒体体验将与主流浏览器保持一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369866/mozilla-firefox-is-officially-getting-mkv-video-support</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369866/mozilla-firefox-is-officially-getting-mkv-video-support</guid>
      <pubDate>Mon, 01 Sep 2025 07:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯开源具备原生 3D 重建能力的超长程世界模型：HunyuanWorld-Voyager</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯近日正式发布了 HunyuanWorld-Voyager，这是一种创新的视频扩散框架，旨在通过单张输入图像生成具备世界一致性的 3D 点云，支持用户按自定义的相机路径进行沉浸式探索。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="327" src="https://oscimg.oschina.net/oscnet/up-56c2135778b8058ed623697954e8a4f3027.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官方表示，这全球首个具备原生 3D 重建功能的超远距离世界模型，重新定义 AI 驱动的 VR、游戏和仿真空间智能。此模型不仅能够生成精确对齐的深度信息和 RGB 视频，还能够在不进行后处理的情况下，直接用于高质量的三维重建。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;直接 3D 输出：无需 COLMAP 等工具即可将点云视频导出为 3D 格式，实现即时 3D 应用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;创新的 3D 内存：引入可扩展的世界缓存机制，确保任何摄像机轨迹的几何一致性。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;顶级性能：在斯坦福 WorldScore 测试中排名第一，在视频生成和 3D 重建基准测试中表现出色&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HunyuanWorld-Voyager 的架构包含两个关键组件。首先是 「世界一致的视频扩散」，该组件提出了一种统一的架构，可以基于已有的世界观测，同时生成准确对齐的 RGB 视频和深度视频序列，从而确保全局场景的一致性。其次是 「长距离世界探索」，它采用了一种高效的世界缓存机制，结合点云剔除和自回归推理能力，支持迭代场景扩展，并通过上下文感知的一致性技术实现平滑的视频采样。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;为了训练 HunyuanWorld-Voyager 模型，研究团队构建了一套可扩展的数据构建引擎。这一自动化视频重建流水线能够对任意输入视频自动估计相机位姿和度量深度，因此无需依赖人工标注，从而实现大规模、多样化训练数据的构建。基于此流水线，HunyuanWorld-Voyager 整合了真实世界采集和虚幻引擎渲染的视频资源，构建了一个包含超过 10 万个视频片段的大规模数据集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在实验评估中，HunyuanWorld-Voyager 在视频生成质量方面表现出色。与四种开源的相机可控视频生成方法进行了对比，结果显示该模型在 PSNR、SSIM 和 LPIPS 等指标上均优于其他模型，证明了其卓越的视频生成质量。同时，在场景重建方面，HunyuanWorld-Voyager 的生成视频在几何一致性上也显现出更好的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，HunyuanWorld-Voyager 在 WorldScore 静态基准测试中获得了最高分，证明了其在相机运动控制和空间一致性方面的优越性。这一成果不仅展示了混元世界模型的潜力，还为未来的 3D 场景生成技术开辟了新路径。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369863</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369863</guid>
      <pubDate>Mon, 01 Sep 2025 07:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯优图实验室正式开源智能体框架 Youtu-Agent</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 2 日，腾讯优图实验室&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FW5LFBLCV3qZG0wxTA9Ob-w" target="_blank"&gt;宣布&lt;/a&gt;正式开源智能体框架 Youtu-Agent。该框架以极简设计和高性能表现为核心，旨在为研究人员和开发者提供高效、易用、可复现的智能体开发工具。&lt;/p&gt; 
&lt;p&gt;据介绍，Youtu-Agent 面向实际场景的开源应用框架，能够覆盖文件管理、数据分析、学术研究与广域信息综述等多个方向应用。目前，Youtu-Agent 开源框架已为腾讯云多个产品业务提供支持。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Youtu-Agent 的核心亮点在于，它不需要额外训练模型，也不依赖海外闭源大模型 API，就能在真实场景中展现出优异的效果，比较好地兼顾了科研和应用双重需求。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;验证性能&lt;/strong&gt;：在 WebWalkerQA 上达到 71.47% 的 pass@1，在 GAIA（纯文本子集）上达到 72.8% 的 pass@1，纯粹使用&lt;code&gt;DeepSeek-V3&lt;/code&gt;系列模型（不使用 Claude 或 GPT），建立了强大的开源起点。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开源友好且成本敏感&lt;/strong&gt;：针对可访问、低成本部署进行了优化，不依赖封闭模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;实际用例&lt;/strong&gt;：开箱即用地支持 CSV 分析、文献综述、个人文件整理以及播客和视频生成等任务。（即将推出）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;灵活的架构&lt;/strong&gt;：基于 openai-agents 构建，可兼容各种模型 API（从&lt;code&gt;DeepSeek&lt;/code&gt;到&lt;code&gt;gpt-oss&lt;/code&gt;）、工具集成和框架实现。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;自动化与简洁性&lt;/strong&gt;：基于 YAML 的配置、自动智能体生成和简化的设置减少了手动开销。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在性能表现上，Youtu-Agent 已在多个智能体挑战性基准测试中取得领先成绩。例如，&lt;strong&gt;在 WebWalkerQA 基准中，基于 DeepSeek-V3.1 的运行结果达到了 71.47% 的准确率，刷新了开源模型的最新纪录&lt;/strong&gt;；&lt;/p&gt; 
&lt;p&gt;&lt;img height="603" src="https://static.oschina.net/uploads/space/2025/0902/151154_CKYV_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;框架设计方面，Youtu-Agent 完全拥抱开源生态，适配多种可访问的部署环境；其架构灵活，兼容包括 DeepSeek、gpt-oss 在内的多类模型 API 与工具。&lt;/p&gt; 
&lt;p&gt;&lt;img height="738" src="https://static.oschina.net/uploads/space/2025/0902/151229_GBNE_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;em&gt;https://github.com/TencentCloudADP/Youtu-agent&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369860</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369860</guid>
      <pubDate>Mon, 01 Sep 2025 07:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cloudflare 推出实时语音 AI 平台：Realtime Agents</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cloudflare 宣布推出&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fcloudflare-realtime-voice-ai%2F" target="_blank"&gt;实时语音 AI 平台&lt;/a&gt;（Cloudflare Realtime Agents），正式进军低延迟对话式 AI 领域。该平台依托 Cloudflare 全球 330 多个节点的边缘网络，为开发者提供构建语音交互应用的完整解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ae6ab80f3dac0b047d5a26124ce0a669d2d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新平台的核心组件包括 Realtime Agents（语音 AI 管道编排运行时）、WebRTC 音频传输支持、Workers AI 的 WebSocket 实时推理，以及 Deepgram 的语音识别/合成模型。通过这些功能，开发者可快速搭建自然流畅的语音代理应用。&lt;/p&gt; 
&lt;p&gt;下面的示例代码展示了如何创建一个继承自 &lt;code&gt;RealtimeAgent&lt;/code&gt; 的 JavaScript 类，以进行以下操作：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;创建 WebRTC 会话&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;管道编排（如：Deepgram STT → 自定义文本处理 Handler → ElevenLabs TTS）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持会议参与者加入/离开的事件处理&lt;br&gt; 这让开发者几乎不需管理底层基础设施，就可快速构建个性化语音代理应用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;export class MyAgent extends RealtimeAgent&amp;lt;Env&amp;gt; {
constructor(ctx: DurableObjectState, env: Env) {
super(ctx, env);
}

async init(agentId: string ,meetingId: string, authToken: string, workerUrl: string, accountId: string, apiToken: string) {
// Construct your text processor for generating responses to text
const textHandler = new MyTextHandler(this.env);
// Construct a Meeting object to join the RTK meeting
const transport = new RealtimeKitTransport(meetingId, authToken, [
{
media_kind: 'audio',
stream_kind: 'microphone',
},
]);
const { meeting } = transport;

// Construct a pipeline to take in meeting audio, transcribe it using
// Deepgram, and pass our generated responses through ElevenLabs to
// be spoken in the meeting
await this.initPipeline(
[transport, new DeepgramSTT(this.env.DEEPGRAM_API_KEY), textHandler, new ElevenLabsTTS(this.env.ELEVENLABS_API_KEY), transport],
agentId,
workerUrl,
accountId,
apiToken,
);

// The RTK meeting object is accessible to us, so we can register handlers
// on various events like participant joins/leaves, chat, etc.
// This is optional
meeting.participants.joined.on('participantJoined', (participant) =&amp;gt; {
textHandler.speak(`Participant Joined ${participant.name}`);
});
meeting.participants.joined.on('participantLeft', (participant) =&amp;gt; {
textHandler.speak(`Participant Left ${participant.name}`);
});

// Make sure to actually join the meeting after registering all handlers
await meeting.rtkMeeting.join();
}

async deinit() {
// Add any other cleanup logic required
await this.deinitPipeline();
}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cloudflare 指出，要让语音交互达到「自然对话」的体验，总延迟需低于 800 毫秒，而其分布式边缘架构正好能满足这一苛刻要求。平台同时兼容多种 AI 模型和第三方服务，支持高度可组合的语音处理管道。&lt;/p&gt; 
&lt;p&gt;目前，Cloudflare Realtime Agents 已开放 Beta 公测，开发者可免费试用并基于该平台开发新一代实时语音 AI 应用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/369855/cloudflare-realtime-voice-ai</link>
      <guid isPermaLink="false">https://www.oschina.net/news/369855/cloudflare-realtime-voice-ai</guid>
      <pubDate>Mon, 01 Sep 2025 06:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
