<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 04 Jul 2024 13:12:07 GMT</lastBuildDate>
        <ttl>180</ttl>
        <item>
            <title>开源日报 | ECMAScript 2024；Linux「紫屏」；新的计算范式；「开源 GPT-4o」；中国首个全尺寸开源通用人形机器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.4&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300379/ecmascript-2024&quot; target=&quot;news&quot;&gt;ECMAScript 2024 正式发布&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;ECMAScript 2024（第 15 版）添加了调整 ArrayBuffers 和 SharedArrayBuffers 大小和传输功能；添加了新的 RegExp&lt;code&gt;/v&lt;/code&gt;flag，用于创建具有更多高级功能的 RegExp，以处理字符串集；并引入了用于构建 Promises 的&lt;code&gt;Promise.withResolvers&lt;/code&gt;便捷方法、用于聚合数据的&lt;code&gt;Object.groupBy&lt;/code&gt;和&lt;code&gt;Map.groupBy&lt;/code&gt;方法、用于异步等待共享内存更改的&lt;code&gt;Atomics.waitAsync&lt;/code&gt;方法，以及&lt;code&gt;String.prototype.isWellFormed&lt;/code&gt;和&lt;code&gt;String.prototype.toWellFormed&lt;/code&gt;方法，用于检查并确保字符串仅包含格式正确的 Unicode。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d87dac273b02f395c300be4868de5a42a34.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300318/vs-code-1-91-released&quot; target=&quot;news&quot;&gt;Visual Studio Code 1.91&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-66ea7e777d63fc9051829834d22a2ecac5f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300327/linux-drm-panic-qr-codes&quot; target=&quot;news&quot;&gt;Linux 内核的 Panic 界面有了二维码&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;Linux 6.10 引入了一个新的 DRM Panic 处理程序基础设施，以便于在出现内核致命错误 (Panic)，或者&amp;nbsp;VT 支持可能被禁用的情况下显示相关信息。&lt;/span&gt;近日，Red Hat 的另一位内核工程师，同时也是 DRM Panic 贡献者——Jocelyn Falempe 提交了新补丁，用于在 DRM Panic 界面中显示错误消息二维码。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8778c5ca5bff5556458433b6c27d86f4707.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1727858283%2FOlZeUxIDQ%3Fpagetype%3Dhomefeed&quot; target=&quot;_blank&quot;&gt;OpenAI 联合创始人 Andrej Karpathy 解释了新的计算范式&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;「我们正在进入一个新的计算范式，大语言模型就像 CPU 一样，使用 Token 而不是字节，并且有一个上下文窗口而不是 RAM。&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;这就是大语言模型操作系统（Large Language Model OS, LMOS）。」&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div style=&quot;text-align:right&quot;&gt;
   - 微博&amp;nbsp;
   &lt;strong&gt;宝玉 xp&lt;/strong&gt;
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1697716777%2FOlOw2BzO3%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;玛丽大姐又写了新的报告：Al &amp;amp; Universities&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-df531d943ba3e3cca9a3979268e129f053f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;明浩-rosicky311&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOkujIqR2O&quot; target=&quot;_blank&quot;&gt;LLM 指令微调教程代码开源&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;如果你正在寻找资源来学习 LLMs 指令微调过程，这里有一个开源笔记本教程可以从头开始指导你实现微调过程。&lt;/p&gt; 
   &lt;p&gt;它解释了&lt;/p&gt; 
   &lt;p&gt;- 如何将数据格式化为 1100 指令 - 响应对；&lt;br&gt; - 如何应用 prompt-style 模板；&lt;br&gt; - 如何使用掩码。&lt;/p&gt; 
   &lt;p&gt;也包括关于实现基于 LLM 的自动化评估过程的部分。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;量子位&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5703921756%2FOlY6fyHYQ%3Frefer_flag%3D1001030103_&quot; target=&quot;_blank&quot;&gt;「开源 GPT-4o」来了，法国 AI 实验室发布原生多模态 Mosh&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;只需 8 人团队 4 个月打造，现场惊艳演示引 LeCun、Karpathy 大佬转发。&lt;br&gt; &amp;nbsp;&lt;br&gt; - 模型训练流程和模型架构简单且可扩展性极强，Kyutai 这样的 8 人以上小团队在 4 个月内就构建了它。合成数据在这里发挥了巨大作用&lt;/p&gt; 
   &lt;p&gt;- 专注于本地设备：Moshi 很快就会无处不在。Kyutai 还开发了一个较小的 Moshi 版本，可以在 MacBook 或消费级 GPU 上运行。&lt;/p&gt; 
   &lt;p&gt;- 低延迟：延迟在 300 毫秒以下&lt;/p&gt; 
   &lt;p&gt;官网地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkyutai.org%2F&quot; target=&quot;_blank&quot;&gt;https://kyutai.org/&lt;/a&gt;&lt;br&gt; 试用地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmoshi.chat%2F%3Fqueue_id%3Dtalktomoshi&quot; target=&quot;_blank&quot;&gt;https://moshi.chat/?queue_id=talktomoshi&lt;/a&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;新智元&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6974787068%2FOlJHxciCB&quot; target=&quot;_blank&quot;&gt;HR 部门和人员在中美科技公司的存在感差别太大了&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;在美国科技公司，HR 算是幕后工作人员。一般普通工程师，没事和平时一般根本感觉不到他们的存在，更别说打交道。&lt;/p&gt; 
    &lt;p&gt;我在惠普、苹果和英伟达工作的 17 年里，从来没有和任何 HR 部门的人直接打过交道。离职交接也就是在网上填表，最后把设备和工牌交给部门的行政秘书就完事。我所在的部门对接的 HR 或 HRBP，我从来不知道是谁。&lt;/p&gt; 
    &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;硅谷陈源博士&lt;/strong&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FOlNSjetkJ&quot; target=&quot;_blank&quot;&gt;本地运行的开源模型桌面程序&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt;
   &lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GPT4All 是一个能在消费者硬件上，在本地计算机跑语言模型的开源项目，完全支持 Mac M 系列芯片，AMD 和 NVIDIA GPU。项目组刚发布了 GPT4All 项目的 1 周年纪念版（GPT4ALL 3.0，地址：blog.nomic.ai/posts/one-year-of-gpt4all），主要是对界面和 LocalDocs 体验进行了重新设计。&lt;/span&gt;
  &lt;/div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
  &lt;div&gt;
   &lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;着重说一下 LocalDocs，这个功能允许用户使用自己的本地文件中的知识，确保数据仍然存储在本地设备，而「不会被发送给试图控制用户数据访问以改进自身 AI 技术的公司」。&lt;/span&gt;
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;高飞&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fa.mp.uc.cn%2Farticle.html%3Fuc_param_str%3Dfrdnsnpfvecpntnwprdssskt%26%26from%3Dmedia%23%21wm_cid%3D629211487111485440%21%21wm_aid%3D9685862746178990409%21%21wm_id%3D1709157a815b423aab98ca7338f2971a&quot; target=&quot;_blank&quot;&gt;中国首个全尺寸开源通用人形机器人公版机「青龙」发布&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#4d4f53; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#12161a&quot;&gt;在 7 月 4 日下午举行的 2024 世界人工智能大会暨人工智能全球治理高级别会议产业发展主论坛上，中国首个全尺寸开源通用人形机器人公版机「青龙」发布&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;第一财经&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2F2024-07-04%2Fdetail-incayivc5754683.d.html&quot; target=&quot;_blank&quot;&gt;蚂蚁井贤栋：通过专业智能体的深度连接，AI 会像互联网一样带来服务的代际升级&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;井贤栋说，在移动互联网时代，二维码让移动支付成为每个人的生活日常，「扫一扫」让小商家用最低的成本享受支付的便利。「在人工智能时代，我们也在探索，让 AI 像扫码支付一样便利每个人的生活，让 AI 技术发展的红利惠及更多人。」&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;中国经济网&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3MTI1MjU1Mw%3D%3D%26mid%3D2651141732%26idx%3D1%26sn%3D485f0227cd2e66bd16123c0027297f1d%26scene%3D0&quot; target=&quot;_blank&quot;&gt;AI 时代，中国占到了意想不到的先手&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;在 AI 时代，中美科技竞争中，这样对中国有利的因素还会有很多。比如，依靠强大的基础设施与网络建设，从智能家居、智慧城市到工业物联网，中国能为 AI 技术找到广泛的应用场景，这也是其他国家很难效仿的。在农村，大量摄像头和传感器的部署，使得农业生产，如灌溉、养殖的监控，都找到了智能解决方案。能有这样一个大规模智能物联网市场的前提，依然是当初不计回报的通水、通电、通路、通网。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;心智观察所&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcj.sina.com.cn%2Farticles%2Fview%2F1733360754%2F6750fc72020019o9e&quot; target=&quot;_blank&quot;&gt;李彦宏：激烈的竞争环境中，商业化的闭源模型是最能打的&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;百度创始人、董事长兼首席执行官李彦宏在 2024 世界人工智能大会上，谈及开源闭源之争时表示，开源大模型在学术研究、教学领域等特定场景下有存在的价值，但并不适用于大多数应用场景。在激烈竞争的环境中，需要让业务效率比同行更高、成本比同行更低时，商业化的闭源模型是最能打的。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;一财网&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Ftech%2F2024-07-03%2Fdetail-incawewk8260312.d.html%3Ffromtech%3D1&quot; target=&quot;_blank&quot;&gt;独家对话腾讯混元刘煜宏：做大模型可以有「深圳速度」，但不能跳步&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型注定是一场长跑，「AGI 目前更像信仰」，但将腾讯混元大模型能力在内部 700 个业务上用得好，是刘煜宏认为对于 AGI 的务实追求。有远见但务实，也是混元团队在大模型上的世界观对齐。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;今夜科技谈&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.cn%2Farticle_1644114654_61ff32de02001tgdu.html&quot; target=&quot;_blank&quot;&gt;新京报发布中国 AI 大模型测评报告，9 款大模型长文本能力待提升&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告包含针对公众及传媒行业的调查问卷，新京报人工智能研究院还研发了针对大模型助手传媒能力的测评体系，本次测评共综合考察了 9 款大模型助手的文本生成能力、事实核查与价值观判断能力、媒体信息检索能力、翻译能力以及长文本总结能力。总体得分上，通义千问、腾讯元宝、讯飞星火夺得前三名；横向对比来看，翻译能力、事实核查与价值观判断能力两项能力最令测试员满意，而长文本能力则得分最低。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt; 新京报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxODcwMzI2MA%3D%3D%26mid%3D2247483861%26idx%3D1%26sn%3D7f7115b6c9bf13f83ca13cc08beb04e8%26chksm%3Dc1ac1c26f6db95306a48d269319e62ec0b87595c726de0e174c926798f945ac24e14f626b712%23rd&quot; target=&quot;_blank&quot;&gt;全球 AI 大模型竞赛，美、中之外还有谁？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#191919&quot;&gt;当视线扩展到中美之外，尽管 AI 独角兽企业的涌现没有中美那样频繁，但它们依然像世界各地散落的珍珠，每一颗都以其独特的光芒闪耀着。从欧洲的心脏地带到亚洲的新兴市场，再到北美的科技巨头，这些大模型独角兽的发展轨迹，推动了各自国家和地区的科技创新，而且为全球人工智能技术的发展注入了多元化的视角和创新动力。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;strong&gt;元素 elements&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fconan-io%2Fconan&quot; target=&quot;_blank&quot;&gt;conan-io/conan&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;165&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c5b5b4061a0a8ff8efdba925e0bf610ffc0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fconan-io%2Fconan&quot; target=&quot;_blank&quot;&gt;https://github.com/conan-io/conan&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Conan 是一个去中心化、开源 (MIT)、C/C++ 包管理器。&amp;nbsp;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;它是完全去中心化的，用户可以私下将他们的包托管在他们的服务器上&lt;/li&gt; 
  &lt;li&gt;适用于所有平台，包括 Linux、OSX、Windows、Solaris、FreeBSD、Docker、WSL&lt;/li&gt; 
  &lt;li&gt;管理二进制文件。 它可以为任何配置和平台创建、上传和下载二进制文件， 甚至交叉编译，节省大量的开发和持续集成时间。&lt;/li&gt; 
  &lt;li&gt;与任何构建系统集成，包括任何专有和自定义系统。&lt;/li&gt; 
  &lt;li&gt;可扩展：具有强大的功能和灵活性&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/oneflow/blog/11213900&quot; target=&quot;_blank&quot;&gt;大模型产品化第一年：战术、运营与战略&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;过去一年里，我们一直在进行构建，并在过程中发现了许多棘手的问题。虽然我们的经验并不代表整个行业，但我们希望分享自己的经验来避免同样的错误并加速迭代。我们将经验总结为以下三个部分：&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;战术层面&lt;/strong&gt;&amp;nbsp;：一些关于提示、RAG、流程工程、评估和监控的实践建议。无论你是通过 LLM 进行构建的从业者，还是出于兴趣在周末进行项目开发，这部分内容都具有参考价值。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;运营层面&lt;/strong&gt;&amp;nbsp;：发布产品的日常组织和管理问题，以及组建高效团队的方法。这部分适合想要可持续且可靠地部署产品的产品 / 技术领导者。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;战略层面&lt;/strong&gt;&amp;nbsp;：长期、宏观的视角，包括诸如 「在产品市场契合（PMF）之前不要使用 GPU」 和 「专注于系统而非模型」 等有见解的观点，以及如何进行迭代。这部分为创始人和高管量身定制。&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUWDWEGCNQtIIrQpoxZs-_g&quot; target=&quot;_blank&quot;&gt;Linux 不仅可以「蓝屏」，还可以「紫屏」、「黑屏」……&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：额……Windows 现在的蓝屏可读性比较强，但是看目前 Linux 的那个蓝屏，似乎没有提升可读性，也没有提供排错指南，只是简单的把 kdump 由屏幕上放到了二维码上……。还不如默认把崩溃文件存储直接打开，放硬盘上好了。这样我重启下电脑还可以去读文件，然后再去查崩溃原因。说电脑屏幕有时显示不下，所以把「彩色的」蓝屏放到手机上，难道手机屏幕还大得过电脑屏幕？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：这算「屎上雕花」吗？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：花式嘲讽了属于是&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：我记得零几年的时候，我就会把一堆淘汰的硬件去攒机，目的就是挑战它能不能正常工作，并且不蓝屏～&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：Kernel Panic，怎么个 Panic 法，人家 Windows 报错至少代码和原因会给你写的一清二楚&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：啊？这是简化？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：看了下解码后的数据，是个网址，报错信息被编码在 URL 参数中，感觉表示报错信息的数据还可以压缩一下信息密度，比如 gzip 压缩后编码为 base64，长度会小很多&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：自从用了 ecc 内存，好像很久没蓝屏过了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：windows 领先十几年&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：有点像 Linux 版「黑伦」&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjDSUasxZj5tuGu8Elcu5YA&quot; target=&quot;_blank&quot;&gt;Windows 11 中国政府定制版？假的！&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：win11 最好用的就是 wsl2&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：其实 win10 也有 wsl2&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：windows 11 是我用过最难用的系统，我用过的包括 mac linux windows&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：邯郸学步，但是我觉得「邯郸」人的步伐本来就很丑。mac 是我用过的最难用的系统。我很庆幸 win11 只学到了 mac 的皮毛，但痛恨其占了 win10 的位。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：win11 开始菜单效率还不如 win10 呢,包括不少设置选项都层层嵌套,太难找了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：真不是我守旧，就 win11 那个右键菜单都能劝退不少人。除此之外还有一些 win10 上不存在的问题&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：还真是，原来我可以右键+字母快速解决，现在还要再加一层。凡是不能用键盘解决的问题都没有真正的解决&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：Win11 的资源管理器 bug 太多了，一个文件关联的操作就有可能导致资源管理器崩溃重启，如果在这个过程中复制文件出现了这个情况，那简直就是天大的灾难。所以稳定性方面 Win11 还是慎用吧。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：Linux distros 不好用？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：我觉得 11 比 10 好用&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：win11 好多程序闪退&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：win11 的开始菜单和右键菜单都很难用，远不如 win10&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：有没有可能以后有 win11 神州网信版本的呢，毕竟当然也是禁止机构用 win10，后面不也合作搞了精简版？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：win11 是我用过的最难用 windows&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：vscode 的浏览器版本，除了微软自己用的以外，功能基本都是残血的，托管过的都知道。 所以有个新的挺好的。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 16：如果不是 steam 的话甚至可以不用 wsl&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 17：我在家里就用的 Windows ltsc&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/300177/microsoft-wsl2-linux-6-6-kernel&quot; target=&quot;_blank&quot;&gt;微软 WSL2 过渡至 Linux 6.6 LTS 内核&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：5.几就老化了？我用的还是 3.10 内核&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：那你说 jdk1.8 老不老&lt;/span&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：4.x 之下，docker 有一个隐藏 bug，因为内核的原因。大部分情况不会出问题，个别情况可能会导致 docker 无法创建容器。当然一般情况问题不大&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：终于更新了，还以为 wls2 不维护了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：wsl 用的是 ubuntu，追的是最新内核。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300429</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300429</guid>
            <pubDate>Thu, 04 Jul 2024 11:00:21 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>大模型产品化第一年​：战术、运营与战略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                            
                                                                                            &lt;div class=&quot;rich_media_content js_underline_content
                       defaultNoSetting
            &quot; id=&quot;js_content&quot;&gt; 
 &lt;section style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;375&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;100011111&quot; data-ratio=&quot;0.6666666666666666&quot; data-type=&quot;other&quot; data-w=&quot;768&quot; style=&quot;width: 100%;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/845f0ce9-3787-4812-8dc5-fb4fe3018878.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;&quot;&gt;&lt;span style=&quot;outline: 0px;color: rgb(63, 63, 63);&quot;&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;font-size: 16px;letter-spacing: 2px;&quot;&gt;&lt;br&gt;作&lt;/span&gt;&lt;/strong&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;font-size: 16px;letter-spacing: 2px;&quot;&gt;者 |&amp;nbsp;&lt;span style=&quot;color: rgb(63, 63, 63);text-wrap: wrap;&quot;&gt;Eugene Yan、Bryan Bischof 等&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;&quot;&gt;&lt;span style=&quot;outline: 0px;color: rgb(63, 63, 63);&quot;&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;font-size: 16px;letter-spacing: 2px;&quot;&gt;OneFlow 编译&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;&quot;&gt;&lt;span style=&quot;outline: 0px;color: rgb(63, 63, 63);&quot;&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;font-size: 16px;letter-spacing: 2px;&quot;&gt;翻译｜宛子琳、张雪聃、&lt;strong style=&quot;color: rgb(63, 63, 63);font-family: system-ui, -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;&quot;&gt;杨婷&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);line-height: 1.6em;&quot;&gt;&lt;span style=&quot;outline: 0px;color: rgb(63, 63, 63);&quot;&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;font-size: 16px;letter-spacing: 2px;&quot;&gt;&lt;strong style=&quot;color: rgb(63, 63, 63);font-family: system-ui, -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.544px;text-wrap: wrap;background-color: rgb(255, 255, 255);outline: 0px;&quot;&gt;&lt;span style=&quot;outline: 0px;&quot;&gt;题图由 SiliconCloud 平台生成&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这是一个激动人心的时代，所有人都能够利用语言大模型（LLM）进行各种各样的产品构建。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;过去一年里，LLM 已经达到了「足够好」的水平，可以应用于现实世界的场景，并且模型每年都在迭代，变得更好、更便宜。伴随着社交媒体上的一系列产品演示，预计到 2025 年，AI 领域的投资将达到 2000 亿美元。此外，供应商的 API 使 LLM 更加易于访问，让每个人（不仅仅是 ML 工程师和科学家）都能将智能融入到他们的产品中。尽管使用 AI 构建的门槛降低了，但实际创建有效的产品和系统（不仅仅是 demo）仍然很有难度。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;过去一年里，我们一直在进行构建，并在过程中发现了许多棘手的问题。虽然我们的经验并不代表整个行业，但我们希望分享自己的经验来避免同样的错误并加速迭代。我们将经验总结为以下三个部分：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;战术层面&lt;/span&gt;&lt;/strong&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;：一些关于提示、RAG、流程工程、评估和监控的实践建议。无论你是通过 LLM 进行构建的从业者，还是出于兴趣在周末进行项目开发，这部分内容都具有参考价值。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);&quot;&gt;运营层面&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
  &lt;span style=&quot;letter-spacing: 2px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);&quot;&gt;：发布产品的日常组织和管理问题，以及组建高效团队的方法。这&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);&quot;&gt;部分适合想要可持续且可靠地部署产品的产品/技术领导者。&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;战略层面&lt;/span&gt;&lt;/strong&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;：长期、宏观的视角，包括诸如「在产品市场契合（PMF）&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;text-wrap: wrap;&quot;&gt;之前&lt;/span&gt;不要使用 GPU」和「专注于系统而非模型」等有见解的观点，以及如何进行迭代。这部分为创始人和高管量身定制。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;准备好深入探讨了吗？让我们开始吧。（&lt;strong&gt;本文由 OneFlow 编译，转载请联系授权。原文：https://applied-llms.org/&lt;/strong&gt;）&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);&quot;&gt;1&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);&quot;&gt;战术层面：与 LLM 进行合作的要点&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在本节中，我们将分享一些关于新兴 LLM 技术栈核心组件的最佳实践：提升质量和可靠性的提示技巧、评估输出效果的策略、通过检索增强生成（RAG）以改进基础性能等等。我们还将探讨如何设计「人机协作（human-in-the-loop）」的 workflow。尽管这项技术仍在快速发展，但我们希望这些经验（来自我们集体进行的大量实验的副产品）能够经受住时间的考验，并助力于构建和发布稳健的 LLM 应用。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.1 提示&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们建议在开发新应用时从提示（prompting）开始。其重要性既容易被低估，也容易被高估。低估是因为正确的提示技巧如果使用得当，可以带来显著的进步。高估是因为即使是基于提示的应用程序也需要围绕提示进行大量的工程工作才能良好运行。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.1.1 专注于充分利用基本的提示技巧&lt;/span&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一些提示技巧在提高各种模型和任务的性能方面总是非常有效：n-shot 提示+上下文学习、思维链（Chain-of-Thought）以及提供相关背景资源。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;通过 n 次提示进行上下文学习的理念是向 LLM 提供一些示例，以展示任务并使输出符合我们的预期。以下是一些技巧：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果 n 值太低，模型可能会过度依赖这些特定示例，影响其泛化能力。一般来说，n 应≥5。不要害怕将 n 值提高到几十次。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;示例应代表预期输入的分布。如果你正在构建一个电影摘要生成器，它应该包含不同类型电影的样本，大致比例与你在实践中期望看到的一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;不一定需要提供完整的输入-输出对。在许多情况下，仅提供期望输出的示例就足够了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果使用的 LLM 支持工具使用，你的 n-shot 示例也应该使用你希望智能体使用的这些工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在思维链（CoT）提示中，我们鼓励 LLM 在返回最终答案之前解释其思考过程。可以想象成给 LLM 提供一份草稿板，这样它就不必完全依赖内存。最初的方法是简单地添加短语「Let’s think step-by-step」作为指令的一部分，但我们发现，通过额外的一两句话使 CoT 更具体，通常可以显著降低幻觉率。&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，当要求 LLM 总结会议记录时，我们可以明确步骤，例如：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;首先，在草稿板上列出关键决策、后续事项和相关负责人。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;然后，检查草稿板中的细节是否与会议记录的事实一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后，将关键点综合成简明的摘要。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;请注意，最近有些人对这种技术是否如预期那样强大表示怀疑。此外，关于在使用思维链时推理过程中究竟发生了什么，存在相当大的争论。无论如何，如果情况允许，这是一种值得尝试的技术。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;提供相关背景资源是扩展模型知识库、减少幻觉并增强用户信任的强大机制。通常通过 RAG 来实现，向模型提供可直接用于回答的文本片段是一个基本技巧。在提供相关资源时，仅仅包含文本片段是不够的；记得告诉模型优先使用这些资源，进行直接引用，有时还要提到资源不足时的情况。这些都有助于将智能体响应「锚定」到资源语料库中。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.1.2 将输入和输出结构化&lt;/span&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;结构化的输入和输出可以帮助模型更好地理解输入，并返回能够可靠地与下游系统集成的输出。为输入添加序列化格式可以为模型提供更多关于上下文中词元关系的线索，例如为特定词元添加额外的元数据（如数据类型），或者将请求与模型训练数据中的类似示例相关联。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，互联网上许多关于编写 SQL 的问题都从指定 SQL 模式开始。因此，你可能会觉得用于 Text-to-SQL 的有效提示应该包括结构化的模式定义。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;结构化输出有类似的作用，但它还简化了与系统下游组件的集成。Instructor 和 Outline 非常适合结构化输出。如果你导入了 LLM API SDK，请使用 Instructor；如果你导入了 Huggingface 用于自托管模型，就使用 Outlines。）结构化输入能够清晰地表达任务，并且类似于训练数据的格式，从而增加了获得更好输出的概率。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;使用结构化输入时，注意每个 LLM 系列都有其偏好。如 Claude 偏好 XML 格式，而 GPT 偏好 Markdown 和 JSON 格式。使用 XML 时，你甚至可以通过提供标签来预填 Claude 的响应，如下所示：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt; 
  &lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;python&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;messages=[&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &quot;role&quot;: &quot;user&quot;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &quot;content&quot;: &quot;&quot;&quot;Extract the &amp;lt;name&amp;gt;, &amp;lt;size&amp;gt;, &amp;lt;price&amp;gt;, and &amp;lt;color&amp;gt; from this product description into your &amp;lt;response&amp;gt;.&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &amp;lt;description&amp;gt;The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &amp;lt;/description&amp;gt;&quot;&quot;&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    },&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &quot;role&quot;: &quot;assistant&quot;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &quot;content&quot;: &quot;&amp;lt;response&amp;gt;&amp;lt;name&amp;gt;&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
 &lt;/section&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.1.3 编写小而精的提示，只做一件事，并且做好&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在软件中，一个常见的反面模式是「God Object」，即一个类或函数包揽了所有事项。在提示也同样适用。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一个提示通常从简单的开始：几句指令，几个示例，就可以了。但当我们试图提高性能并处理更多边缘情况时，复杂性就会悄悄增加。更多的指令，多步骤的推理，以及数十个示例。不知不觉间，我们最初的简单提示已经变成了一个两千词元的怪物。而更糟糕的是，它在处理更常见和直接的输入时性能更差！GoDaddy 将这一挑战作为他们使用 LLM 进行构建时学到的头号教训。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;正如我们努力保持系统和代码的简单，提示也应如此。与其为会议记录摘要生成器构建一个万能提示，不如将其分解成以下几个步骤：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;提取关键决策、行动项目和负责人并形成结构化格式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;检查提取的细节与原始转录的一致性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;从结构化细节生成简明摘要&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;结果是，我们将单一提示分解成了多个简单、专注且易于理解的提示。通过将它们拆分，我们现在可以单独迭代和评估每个提示。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;精心打造你的上下文词元&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.1.4 精心构建你的上下文词元&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;重新思考并质疑你对于实际需要发送给智能体的上下文数量的假设。像米开朗基罗一样，不要塑造你的上下文雕塑，而是凿掉多余的材料，直到雕塑显露出来。RAG 是一种流行的方式来整理所有可能相关的大理石块，那你需要做什么来提取必要的内容呢？&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们发现，将发送给模型的最终提示（包括所有上下文构建、元提示和 RAG 结果）放在空白页面上，然后仔细阅读，这确实能帮助你重新思考上下文。通过这种方法，我们发现了冗余、自相矛盾的语言和糟糕的格式等问题。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;另一个关键的优化是你的上下文结构。你的文档集合表示对人类没有帮助，也不要假设它对智能体有任何帮助。仔细考虑如何结构化你的上下文，以突显其各部分之间的关系，并使提取尽可能简单。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.2 信息检索 / RAG&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;除提示之外，通过在提示中提供知识来引导 LLM 的另一种有效方法是将其作为上下文提供给 LLM，这样可以让 LLM 在提供的上下文中找到立足点，然后用于上下文学习。这被称为检索增强生成（RAG）。从业者发现，RAG 在提供知识和改善输出方面非常有效，同时所需的努力和成本要少得多。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.2.1 RAG 的质量取决于检索到的文档的相关性、密度和详细程度&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;font-size: 17px;&quot;&gt;RAG 的输出质量取决于检索到的文档质量，而这又取决于以下几个因素。&lt;/span&gt;&lt;/h3&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;首先是最明显也是最重要的指标：相关性。这通常通过排名指标来量化，如平均倒数排名（Mean Reciprocal Rank, MRR）或归一化折扣累积增益（Normalized Discounted Cumulative Gain, NDCG）。MRR 评估系统将第一个相关结果排在排名列表中的能力，而 NDCG 考虑所有结果的相关性及其位置。它们衡量系统将相关文档排名更高，将不相关文档排名更低的能力。例如，如果我们检索用户摘要以生成电影评论摘要，就会想将特定电影的评论排名更高，同时排除其他电影的评论。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;与传统的推荐系统类似，检索到的项目的排名将对 LLM 在下游任务中的表现产生重大影响。要评估影响，运行一个基于 RAG 的任务，但将检索到的项目进行打乱排列——RAG 输出的表现如何？&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;其次，我们还要考虑信息密度。如果两个文档相关度相等，我们会偏向更简洁、附带较少冗余细节的文档。回到我们的电影示例，从广义上讲，我们可能认为电影剧本和所有用户评论都是相关的。尽管如此，排名靠前的评论和编辑评论可能在信息密度上更高。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后，我们还要考虑文档中提供的详细程度。想象一下，我们正在构建一个从自然语言生成 SQL 查询的 RAG 系统。可以简单地提供包含列名的表模式作为上下文。但是，如果我们包含列描述和一些示例值呢？这些额外的细节可以帮助 LLM 更好地理解表的语义，从而生成更正确的 SQL。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.2.2 不要忘记关键词搜索；将其作为 baseline，并在混合搜索中使用&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;鉴于基于嵌入的 RAG 演示非常普遍，人们很容易忘记或忽视信息检索领域数十年来的研究和解决方案。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;嵌入无疑是一种强大的工具，但它并非万能。首先，尽管它们擅长捕捉高层语义相似性，但它们可能会在更具体的基于关键词的查询方面遇到困难，比如当用户搜索名称（例如，Ilya）、首字母缩略词（例如，RAG）或 ID（例如，claude-3-sonnet）时。基于关键词的搜索，例如 BM25 就专门为此设计。经过多年的基于关键词的搜索，用户可能已经习以为常，如果他们期望检索的文档没有被返回，可能会感到沮丧。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;blockquote style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;向量嵌入并不能奇迹般地解决搜索问题。事实上，在你使用语义相似性搜索重新排序之前的步骤才是关键。要真正改进 BM25 或全文搜索是很难的。——Perplexity.ai 首席执行官 Aravind Srinivas&lt;/span&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们已经向客户和合作伙伴传达这个观点好几个月了。使用简单嵌入的最近邻搜索会产生非常嘈杂的结果，你最好从基于关键词的方法开始。——ourcegraph 首席技术官 Beyang Liu&lt;/span&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;其次，通过关键词搜索更容易理解为什么会检索到某个文档——我们可以查看与查询匹配的关键词。相比之下，基于嵌入的检索不太具有可解释性。最后，由于诸如 Lucene 和 OpenSearch 等系统经过数十年的优化和考验，关键词搜索通常在计算上更加高效。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在大多数情况下，混合方法效果最好：关键词匹配用于明显匹配，嵌入则用于同义词、上下位词和拼写错误，以及多模态（例如，图像和文本）。Shortwave 分享了他们如何构建其 RAG pipeline，包括查询重写、关键词+嵌入检索以及排名（&lt;/span&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/&lt;/em&gt;&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.2.3 引入新知识时优先选择 RAG 而非微调&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;RAG 和微调都可以用来将新信息整合到 LLM 中，并提高特定任务的性能。那么，我们应该先尝试哪种方法呢？&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最近的研究表明（&lt;/span&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;https://arxiv.org/abs/2312.05934&lt;/span&gt;&lt;/em&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;），RAG 可能更具优势。一项研究将 RAG 与无监督微调（即持续预训练）进行了比较，在 MMLU 的一个子集和当前事件上对两者进行了评估。他们发现，无论是在训练期间遇到的知识点还是全新的知识点，RAG 始终优于微调。在另一篇论文中（&lt;/span&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;https://arxiv.org/abs/2401.08406&lt;/span&gt;&lt;/em&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;），他们将 RAG 与农业数据集上的监督微调进行了比较。同样，RAG 的性能提升大于微调，尤其是对于 GPT-4（见论文表 20）。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;除了提高性能外，RAG 还带来了几个实际优势。首先，与持续预训练或微调相比，更容易保持检索索引的最新状态，也更便宜！其次，如果我们的检索索引中包含有毒或偏见内容的问题文档，简单地删除或修改这些有问题的文档即可。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;此外，RAG 中的「R」为我们检索文档提供了更细粒度的控制。例如，如果我们为多个组织托管一个 RAG 系统，通过对检索索引进行分区，我们可以确保每个组织只能从自己的索引中检索文档。这确保了我们不会无意中将一个组织的信息暴露给另一个组织。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.2.4 长上下文模型不会让 RAG 过时&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;随着 Gemini 1.5 提供高达 1000 万词元大小的上下文窗口，一些人开始质疑 RAG 的未来。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;165&quot; data-source-title=&quot;&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot; data-text=&quot;我倾向于认为，Gemini 1.5 被严重低估了。一个 1000 万词元的上下文窗口实际上使大多数现有的 RAG 框架变得不必要。你只需将数据放入上下文中，然后像平常一样与模型对话。想象一下，这对所有专注于 RAG 的初创公司/智能体/langchain 项目的影响。或者用一句话说：1000 万上下文杀死了 RAG。Gemini 干得好。——Yao Fu&quot; data-editid=&quot;uodqo3qpsd1wvw6ozk&quot;&gt; 
  &lt;section class=&quot;js_blockquote_digest&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我倾向于认为，Gemini 1.5 被严重低估了。一个 1000 万词元的上下文窗口实际上使大多数现有的 RAG 框架变得不必要。你只需将数据放入上下文中，然后像平常一样与模型对话。想象一下，这对所有专注于 RAG 的初创公司/智能体/langchain 项目的影响。或者用一句话说：1000 万上下文杀死了 RAG。Gemini 干得好。——Yao Fu&lt;/span&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然长上下文在分析多个文档或与 PD‍‍‍F 对话等用例上将会带来变革，但关于 RAG 消亡的传言被远远夸大了。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;首先，即使有 1000 万词元的上下文窗口，我们仍然需要一种方法来选择要输入模型的信息。其次，除了狭窄的「大海捞针（needle-in-a-haystack）」评估之外，我们还没有看到令人信服的数据，表明模型能够有效地对如此大的上下文进行推理。因此，如果没有良好的检索（和排名），我们有可能让模型被干扰信息淹没，或者甚至可能用完全无关的信息填满上下文窗口。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后，还有成本问题。&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247491309%26idx%3D1%26sn%3D407fefb7ec76a2c9fdfe1ae960f7de4d%26chksm%3Dfe4190dbc93619cd0b9bfecb979e142a125fd8548d323dd9bdc2cbeb619400202e6e1affced0%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;Transformer 的推理成本&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;Transformer 的推理成本&lt;/strong&gt;&lt;/a&gt;随着上下文长度的增加呈二次方（或空间和时间上的线性）增长。即使存在一个模型，它可能在回答每个问题之前读取整个组织的 Google Drive 内容，也并不意味着这是个好主意。就像我们使用 RAM 的方式：即使存在运行数十 TB RAM 的计算实例，我们仍然从磁盘读取和写入数据。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;所以，不要急于把你们的 RAG 扔进垃圾桶。即使上下文窗口的大小增加，这种模式仍将是有用的。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3 调整和优化 workflow&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;为 LLM 设计提示只是个开始。要充分发挥它们的潜力，我们需要超越单一提示并采用 workflow。例如，我们如何将一个复杂的任务分解为多个更简单的任务？微调或缓存何时有助于提高性能并减少时延/成本？在本节中，我们会分享一些行之有效的策略和真实世界的例子，以帮助你优化并构建可靠的 LLMworkflow。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_9&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3.1 逐步、多轮「flows」可以带来大幅提升&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们已经知道，通过将单个大提示分解为多个小提示，可以获得更好的结果。例如，AlphaCodium 通过从单一提示切换到多步骤 workflow，使 GPT-4 在 CodeContests 上的准确率（pass@5）从 19% 提升到了 44%。workflow 包括：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;反思问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对公共测试进行推理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;生成可能的解决方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对可能的解决方案进行排名&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;生成合成测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在公共和合成测试上迭代解决方案。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;小任务具有明确目标，最适合作为智能体或流程提示。不要求每个智能体提示都请求结构化输出，但结构化输出对与系统交互非常有帮助。一些可尝试的方法：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一个尽可能详细的明确计划步骤。考虑使用预定义的计划供选择。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;将原始用户提示重写为智能体提示。注意，这一过程有信息丢失的风险！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;智能体行为可以是线性链、DAG（有向无环图）和状态机；不同的依赖关系和逻辑关系在不同规模下可能更适用或更不适用。你能从不同的任务架构中挤出性能优化吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;计划验证；你的计划可以包括如何评估其他智能体响应的指示，以确保最终组装协同工作良好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;具有固定上游状态的提示工程——确保你的智能体提示针对可能发生的各种情况进行评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3.2 目前优先考虑确定性 workflow&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然 AI 智能体可以动态响应用户请求和环境，但它们的不确定性使得部署变得具有挑战性。智能体的每一步都有失败的可能，而从错误中恢复的几率较低。因此，智能体成功完成多步骤任务的可能性随着步骤数量的增加而呈指数级下降。结果是，构建智能体的团队发现难以部署可靠的智能体。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一种比较有前景的方法是让智能体系统生成确定性的计划，然后以结构化、可复制的方式执行。在第一步中，智能体根据高层次目标或提示生成一个计划。然后，按确定性地执行该计划。这使每一步都更可预测和可靠。其好处包括：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;生成的计划可以作为少样本示例来提示或微调智能体。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;确定性执行使系统更可靠，因此更容易测试和调试。此外，失败可以追溯到计划中的具体步骤。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;生成的计划可以表示为 DAG，相对于静态提示，更容易理解和适应新情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最成功的智能体构建者可能是那些在管理初级工程师方面具有丰富经验的人，因为生成计划的过程类似于我们指导和管理初级工程师。我们给初级工程师明确的目标和具体的计划，而不是模糊的开放式指示，我们对智能体也应该这样做。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最终，构建可靠的工作智能体的关键可能在于采用更结构化、确定性的方法，并收集数据来优化提示和微调模型。如果没有这些，我们构建的智能体可能有时表现非常好，但平均而言，会令用户失望，导致用户留存率低下。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3.3 超越温度参数获取更多样化的输出&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;假设你的任务需要 LLM 输出多样化的结果。也许你正在编写一个 LLM pipeline，根据用户之前购买的产品列表推荐购买的新产品。当你多次运行提示时，可能会发现结果推荐过于相似，所以你可能会增加 LLM 请求中的温度参数。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;简而言之，增加温度参数会使 LLM 的响应更加多样化。在采样时，下一个词元的概率分布变得更平坦，这意味着通常不太可能的词元被选择的频率更高。然而，当增加温度时，你可能会注意到一些与输出多样性相关的失败模式。例如，目录中非常合适的某些产品可能永远不会被 LLM 输出。如果这些产品基于 LLM 在训练时学到的知识，很可能跟随提示出现，那么它们可能会在输出中过度呈现。如果温度太高，你可能会得到引用不存在的产品（或胡言乱语！）的输出。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;换句话说，提高温度并不能保证 LLM 就会从预期的概率分布（如均匀随机）中采样输出。不过，我们还有其他方法来提升输出的多样性。最简单的方法是调整提示中的元素。例如，如果提示模板中包含一个项目列表，如历史购买记录，每次将这些项目插入提示时打乱它们的顺序，就可以产生显著的效果。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;此外，保留一个近期输出的简短列表可以防止冗余。以我们推荐产品的例子为例，通过指示 LLM 以避免从这个近期列表中推荐项目，或者通过拒绝和重新采样与近期建议相似的输出，我们可以使模型的回答更加多样化。另一个有效策略是改变提示的措辞。例如，加入「选择一个用户经常会喜欢使用的项目」或「选择一个用户可能会推荐给朋友的产品」这样的短语，可以改变焦点，从而影响推荐产品的多样性。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3.4 缓存的重要性被低估了&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;缓存可以节省成本并消除生成时延，因为不需要为相同的输入重新生成回答。此外，如果某个回答之前已经经过审查，我们便可以提供这些经过验证的回答，减少提供有害或不适当内容的风险。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一种简单的缓存方法是为正在处理的项目使用唯一的 ID，例如，假设我们正在总结新的文章或产品评论，当有请求进入时，我们可以检查缓存中是否已有摘要。如果有，我们可以立即回答；如果没有，我们便生成、审查并提供答案，然后将其存储在缓存中以供未来请求使用。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对于更加开放式的查询，我们可以借鉴搜索领域的技术，该领域也利用缓存来处理开放式输入。自动补全和拼写校正等功能也有助于规范用户输入，提高缓存命中率。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.3.5 何时微调&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们可能会遇到一些更棘手的任务，即使绞尽脑汁地设计提问，模型也无法给出好的回答。例如，即使经过大量提示设计和优化，系统可能仍然无法给出可靠的高质量输出。如果是这样，那么可能有必要为特定的任务对模型进行微调。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;成功的例子包括：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;Honeycomb 的自然语言查询助手：起初，「编程手册」与 n-shot 示例都在提示中用于上下文学习。虽然这种方法的效果尚可，但微调后，模型在特定领域语言的语法和规则方面输出得更好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;Rechat 的 Lucy：LLM 需要以一种特定的格式生成答案，需把结构化和非结构化的数据相结合，以便前端能够正确呈现。微调在使其一致工作中有重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;尽管微调可能有效，但成本也很高。我们需要给微调数据、微调和评估模型加注释，最终让他们能自行托管。因此，需要考虑较高的前期成本是否值得。如果提示能做到 90%，那么微调可能不值得投资。然而，如果我们决定进行微调，为降低收集人工注释数据的成本，我们可以在合成数据上进行&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;text-wrap: wrap;&quot;&gt;生成与&lt;/span&gt;微调，或者利用开源数据来启动这一过程。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4 评估与监控&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;评估 LLM 可能会充满挑战。模型输入和输出的是任意文本，我们给它们设定的任务也是多种多样的。尽管如此，严格且周密的评估至关重要——OpenAI 的技术领导者们肯定不是随随便便评估工作并对各个评估给予反馈。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;评估 LLM 应用引发了各种相关的定义和方法：只是简单的单元测试，还是对系统内部运行状态和行为的能力进行观察和理解，还是可能只是数据科学。所有这些观点都有其作用。在接下来的部分中，我们提供了一些探索构建评估和监控流程中的重点经验教训。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_12&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.1 从实际输入/输出样本创建几个基于断言的单元测试&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;从生产环境中的输入和输出样本中创建一些单元测试（即断言），并以至少三个标准对输出的期望进行验证。虽然三个标准可能看起来有些随意，但这实际上是一个合理的起点；标准更少可能意味着任务定义不够清晰或过于开放，就像通用聊天机器人一样。这些单元测试或断言应该在流程发生任何更改时触发，无论是编辑提示、通过 RAG 添加新的上下文，还是其他修改。本文提供了一个基于断言的测试实例，适用于实际情况。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们可以考虑包含或排除响应的短语开始构建断言。还要考虑进行检查，确保单词、项或句子数量在一定范围内。对于其他类型的生成任务，断言可能会有所不同。执行评估是评估代码生成的一种强有力方法，我们可以在过程中运行生成的代码，并确定运行时状态是否足够满足用户请求。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，如果用户请求一个名为 foo 的新函数；在执行智能体生成的代码后，foo 应该是可调用的！执行评估的一个挑战是，智能体的代码会使运行时状态常常与目标代码略有不同。将断言放宽到任何可行答案都能满足最弱假设可能是有效的。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后，按照预期方式使用你的产品（即，「吃自己的狗粮（dogfooding）测试」）可以洞察真实世界上数据的故障模式。这种方法不仅有助于识别潜在的弱点，还提供了一个有用的实际生产样本来源，这样样本可以转化为评估（eval&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;text-wrap: wrap;&quot;&gt;）案例&lt;/span&gt;。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_13&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.2 语言大模型可以作评判者（在某种程度上），但它并非解决所有问题的灵丹妙药&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以 LLM 作评判&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;者（LLM-as-Judge），即利&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;用强大的 LLM 来评估其他模型的输出，一直受到一些人的怀疑（我们中的一些人最初也是极为怀疑的。）然而，当实施得当时，LLM 作为评判者能够与人类判断产生良好的相关性，至少可以帮助建立关于新提示或技术表现的先验知识。具体来说，当进行成对比较（例如，对照组与实验组）时，LLM 作为评判者可能会正确地选出哪个选项更好，但在判断胜利或失败的程度时可能会出现一些噪音。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以下是一些帮助我们充分利用 LLM 作为评判者的价值的建议：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;使用成对比较：与其要求 LLM 对单一输出进行 Likert（&lt;/span&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;https://en.wikipedia.org/wiki/Likert_scale&lt;/em&gt;&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）量表评分，不如向其呈现两个选项，并要求其选择更好的一个。这往往会导致更稳定的结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;控制位置偏差：呈现选项的顺序可能会影响 LLM 的决策。为了减轻这种影响，每次进行成对比较时都要交换顺序。只是在交换后一定要确保将胜利归因给正确的选项！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;允许平局：在某些情况下，两个选项可能同样好。因此，允许 LLM 宣布平局，这样它就不必任意选择一个赢家了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;使用思维链：在给出最终偏好之前，要求 LLM 解释其决策可以提高评估的可靠性。而额外的好处是，我们可以使用较弱但更快的 LLM，并且仍能获得类似的结果。因为这部分在流程中通常处于批处理模式，思维链的额外时延并不是问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;控制回答长度：LLM 倾向于更长的回答。为了减轻这种影响，确保回答对在长度上类似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 作为评判者的一个十分强大的应用是检查新的提示策略是否与回归相符。如果已经追踪了一系列生产结果，有时可以使用新的提示策略重新运行这些生产示例，并使用 LLM 作为评判者快速评估新策略可能出现问题的地方。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;下列示例是一个简单但有效的 LLM 作为评判者迭代的方法，我们只需记录 LLM 的回答、评判的评论（即思维链）和最终结果。然后与利益相关者一起审查，以确定改进的方向。经过三次迭代，人类和 LLM 的一致性从 68% 提高到了 94%！&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100011062&quot; data-ratio=&quot;0.2851851851851852&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;box-sizing: content-box;border-style: none;background-color: var(--bgColor-default, var(--color-canvas-default));height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/db0d82be-c272-4700-b7f5-d6276db6c0ba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 作评判者并非万能之策。即使是最强大的模型在评估语言的微妙之处时也可能失败。此外，我们发现，与 LLM 作评判者相比，传统的分类器和奖励模型可以实现更高的准确性，并且成本和时延更低。对于代码生成，LLM 作为评判者可能比执行评估等更直接的评估策略要弱。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_14&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.3 评估生成结果的「实习生测试」&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在评估生成结果时，我们喜欢使用以下的「实习生测试」：如果将完全相同的输入给予语言模型，包括上下文，并将其作为一个任务交给相关专业的普通大学生，他们能够成功吗？需要多长时间？&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果因为 LLM 缺乏必要的知识而失败，那么要考虑丰富上下文。&lt;/span&gt; 
   &lt;/section&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果无法完成，并且我们无法通过改进上下文来解决问题，那么我们可能遇到了对于当代 LLM 来说过于困难的任务。&lt;/span&gt; 
   &lt;/section&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果可以完成，但可能需要一段时间，我们可以尝试减少任务的复杂性。是否可以分解？任务的某些方面是否可以更模板化？&lt;/span&gt; 
   &lt;/section&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果可以完成，他们可以很快理解，那么是时候深入数据了。模型出了什么问题？我们能否找到失败的模式？尝试在模型回答之前或之后要求其解释，以帮助建立对模型内部机制的理解。&lt;/span&gt; 
   &lt;/section&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_15&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.4 过分强调某些评估可能会损害整体性能&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;37&quot; data-source-title=&quot;&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot; data-text=&quot;「当一个衡量指标成为目标时，它就不再是一个好的衡量指标。」 — 古德哈特定律。&quot; data-editid=&quot;d4c43leofukqmc58u8&quot;&gt; 
  &lt;section class=&quot;js_blockquote_digest&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;「当一个衡量指标成为目标时，它就不再是一个好的衡量指标。」 — 古德哈特定律。&lt;/span&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;span style=&quot;display: none;line-height: 0px;&quot;&gt;‍&lt;/span&gt;其中一个例子是「大海捞针」（Needle-in-a-Haystack，简称 NIAH）评估。最初的评估有助于量化模型在上下文大小增加情况下的召回率，以及召回率‍‍如何受到「针」的位置影响。然而，这一评估已经被过分强调，以至于在 Gemini 1.5 的报告中被列出（&lt;/span&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;https://arxiv.org/abs/2403.05530&lt;/em&gt;&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）。该评估涉及将特定短语（「特&lt;span style=&quot;display: none;line-height: 0px;&quot;&gt;‍‍&lt;/span&gt;殊的魔法{城市}数字是：{数字}」）插入到重复 Paul Graham 散文的长文档中，然后提示模型回忆魔法数字。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然一些模型实现了几乎完美的召回率，但值得质疑的是 NIAH 是否真正反映了现实世界应用中所需的推理和回忆能力。我们可以考虑一个更实际的场景：给定一个时长为一小时的会议记录，LLM 是否能够总结关键决策和下一步行动，并正确地将每一项归因给相关的人员？这个任务更为现实，超越了死记硬背，还考虑了解析复杂讨论、识别相关信息和综合摘要的能力。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以下是一个实际的 NIAH 评估示例。使用医生和患者视频通话的记录，我们询问 LLM 关于患者用药的情况。它还包括一个更具挑战性的 NIAH 测试，&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);&quot;&gt;例如随即插入一个短语，描述制作完美披萨的秘密配料，例如：「制作完美披萨所需的秘密配料是：浸泡过浓缩咖啡的枣、柠檬和羊奶酪。」在药物信息的识别任务上，召回率大约为 80%，而在披萨配料识别的非相关任务上，召回率则约为 30%。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;444&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;100011060&quot; data-ratio=&quot;0.7907407407407407&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;box-sizing: content-box;border-style: none;background-color: var(--bgColor-default, var(--color-canvas-default));width: 100%;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/63a7835f-6050-4ed9-bf29-800d5a9fbaf1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;另外，过分强调 NIAH 评估可能会降低提取和总结任务的效果。因为这些模型被精细微调过，以注意到每个句子，它们可能将无关紧要的细节和干扰因素视为重要内容，并将其包含在最终输出中（尽管不应该如此）！&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这也可能适用于其他评估和用例，例如，文本总结。对事实的一致性的强调可能导致总结内容变得不够具体（因此可能导致事实层面的不一致），可能也不够相关。相反，对写作风格和修辞的强调可能会导致更花哨、更具市场性的语言，这可能会导致事实上的不一致性。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.5 将注释简化为二元任务或成对比较&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在 Likert 量表上为模型输出提供开放式反馈或评级是一项认知负担较重的任务，因此，&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;text-wrap: wrap;&quot;&gt;由于人类评分者之间的差异性，&lt;/span&gt;收集的数据更加繁杂，并且数据的实用性较低。更有效的方法是简化任务，并减轻注释者的认知负担。二元分类和成对比较是两个效果良好的任务。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在二元分类中，注释者被要求对模型的输出进行简单的肯定或否定判断。他们可能会被要求判断生成的摘要是否与源文档在事实上一致，或者所提出的回复是否相关，是否包含有害内容。与 Likert 量表相比，二元决策更加精确，评分者之间的一致性和通过率更高。这就是 Doordash 设置他们的标记队列的方法，通过一系列是-否问题来标记菜单项。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在成对比较中，注释者会收到一对模型回答，并从中选择更好的回答。因为人类更容易说「A 比 B 更好」而不是给 A 或 B 分配一个单独的评分，所以这导致了更快速和更可靠的注释（相比于 Likert 量表）。在 Llama2 的一次聚会上，Llama2 论文的作者之一 Thomas Scialom 确认，成对比较比收集监督微调数据（如书面回复）更快速、更便宜。前者的成本是每个单位 3.5 美元，而后者的成本是每个单位 25 美元。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果你打算编写标注指南，以下是一些来自谷歌和必应搜索的参考指南。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.6 （无参考）评估和防护措施可以互相替代使用&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;防护措施有助于捕捉不适当或有害的内容，而评估则有助于衡量模型输出的质量和准确性。在无参考评估的情况下，它们是密切相关的。无参考评估是一种评估方法，它不依赖于「黄金」参考，比如人类编写的答案，而是仅根据输入提示和模型的回答来评估输出的质量。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这其中有一些例子是总结评估，我们只需考虑输入文档，以评估摘要的事实一致性和相关性。如果摘要在这些指标上得分较低，我们可以选择不将其展示给用户，实际上将评估用作防护措施。同样，无参考翻译评估可以评估翻译质量，而无需人工翻译的参考，使我们能够将其用作防护措施。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.7 即使不应该，LLM 也会返回输出&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;与 LLM 合作的一个关键挑战是，它们经常会生成输出，即使这样做并不合适。这可能导致无害但毫无意义的回答，或者更严重的缺陷，如有害或危险的内容。例如，当要求从文档中提取特定属性或元数据时，LLM 可能会自信地返回值，即使这些值实际上并不存在。另外，当我们提供非英语文档的情况下，模型可能会以非英语的语言给出回答。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然我们可以尝试提示 LLM 给出「不适用」或「未知」的回答，但这并不是万无一失的。即使对数概率可用，它们也是输出质量的一个很差的指标。尽管对数概率表明了在输出中出现一个词元的可能性，但它们并不一定能反映生成文本的正确性。相反，对于经过指令微调的模型，它们是经过训练以回答查询并生成连贯回答的，对数概率可能不太准确。因此，尽管高的对数概率可能表示输出流畅且连贯，但这并不意味着它是准确或相关的。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然精心设计的提示设计和优化可以在一定程度上有所帮助，但我们应该将其与强大的防护措施相结合，以检测和过滤/重新生成不希望的输出。例如，OpenAI 提供了一个内容审核 API，可以识别不安全的回答，如仇恨言论、自残或性内容。同样，也有许多用于检测个人可识别信息（PII）的软件包。这样做的其中一个好处是，防护措施在很大程度上与用例无关，因此，可以广泛应用于给定语言的所有输出。此外，通过精确检索，我们的系统可以确定性地在没有相关文档的情况下回复「我不知道」。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一个相关的问题是，LLM 可能在我们预期其输出时未能产生输出。这可能是各种原因导致的，无论是 API 提供商的长尾时延还是输出被内容审核过滤器阻止等。因此，对于调试和监控，始终记录输入和（可能缺乏的）输出是非常重要的。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;1.4.8 幻觉是一个棘手问题&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;不同于广受关注且很少发生的内容安全或 PII 缺陷，事实不一致现象一直都存在，并且更难以检测。它们更常见，在基线率为 5 - 10% 的情况下发生。根据我们从 LLM 提供商那里了解到的情况，即使在简单的任务（如总结）中，要将其降至 2% 以下也很具挑战性。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;为了解决这个问题，我们可以结合提示设计与优化（生成前）和事实不一致的防护措施（生成后）。对于提示设计优化，诸如 CoT 之类的技术通过要求 LLM 在最终返回输出之前解释其推理过程来减少幻觉。然后，我们可以应用事实不一致的防护措施来评估摘要的事实性，并过滤或重新生成幻觉。在某些情况下，幻觉可以被确定地检测到。当使用来自 RAG 检索的资源时，如果输出是结构化的并且识别了资源是什么，你应该能够手动验证它们是否来自输入的上下文。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);&quot;&gt;2&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;span id=&quot;OSC_h2_19&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);&quot;&gt;运营：日常关注与组织关注&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h2_20&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.1 数据&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;就像食材的质量决定了菜肴的味道一样，输入数据的质量限制了机器学习系统的性能。此外，输出数据是判断产品是否有效的唯一途径。所有创作者都要紧密关注数据，每周花费数小时查看输入和输出，以更好地了解数据分布：其模式、边缘案例以及模型的局限性。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.1.1 检查开发-生产偏差&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;传统机器学习流水线中常见的错误是训练-服务（serve）偏差。这种情况发生在训练中使用的数据与模型在生产中遇到的数据不同的情况下。虽然我们可以在没有训练或微调的情况下使用 LLM 而没有训练集，但开发-生产数据偏差也会出现类似的问题。基本上，在开发过程中测试系统的数据应该反映出系统在生产中将要面对的情况。如果不是这样，我们可能会发现我们的生产准确性受到影响。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 的开发-生产偏差可以分为两种类型：结构性偏差和内容性偏差。结构性偏差包括格式不一致的问题，例如 JSON 字典与列表类型值之间的差异、大小写不一致以及拼写错误或句子片段等。这些错误可能导致模型性能不可预测，因为不同的 LLM 是针对特定数据格式进行训练的，而提示可能对细微变化非常敏感。内容性或「语义性」偏差指的是数据的意义或上下文的差异。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;与传统机器学习一样，定期测量 LLM 输入/输出对之间的偏差是很有用的。简单的度量标准，如输入和输出的长度或特定格式要求（例如 JSON 或 XML），是跟踪变化的简单方法。对于更「高级」的漂移检测&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;（drift detection）&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;，我们可以考虑将输入/输出对的嵌入进行聚类，以检测语义漂移，例如用户讨论主题的变化，这可能表明他们正在探索模型之前没有接触过的领域。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在测试更改（例如提示设计优化）时，确保保留数据集是最新的，并反映了最近的用户交互类型。例如，如果生产输入中常见拼写错误，则在保留数据中也应该存在。除了数值偏差测量之外，对输出进行定性评估也是很有用的。定期审查模型的输出，也就是「氛围检查&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;（vibe checks）」，可&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以确保结果与期望一致，并保持与用户需求相关。最后，将非确定性纳入偏差检查也很有用——通过对测试数据集中对每个输入多次运行 pipeline 并分析所有输出，我们更有可能捕获偶尔发生的异常情况。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_21&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.1.2 每天查看 LLM 输入和输出的样本&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 是动态的，不断发展的。尽管它们具有惊人的 0-shot 能力，能输出优秀的内容，但它们的故障模式可能非常难以预测。对于自定义任务，定期检查数据样本对于&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;text-wrap: wrap;&quot;&gt;直观理解&lt;/span&gt;LLM 的表现至关重要。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;来自生产环境的输入-输出对是 LLM 应用的「真实事物、真实场景」（genchi genbutsu），它们是无法替代的。最近的研究强调，随着开发人员与更多数据进行交互，他们对于什么构成「好」的和「坏」的输出的认识会发生变化（即标准漂移）。虽然开发人员可以提前确定一些用于评估 LLM 输出的标准，但这些预定义的标准通常是不完整的。例如，在开发过程中，我们可能会更新提示以增加获得优质回答的概率并减少获得欠优回答的概率。评估、重新评估和标准更新的迭代过程是必要的，因为在没有直接观察到输出的情况下，预测 LLM 行为或人类偏好是十分困难的。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;为了有效管理这一点，我们应该记录 LLM 的输入和输出。通过每天检查这些日志的样本，我们可以快速识别并适应新的模式或故障模式。当我们发现新问题时，我们可以立即撰写一个相关的断言或评估。与此类似，对故障模式定义的任何更新都应该反映在评估标准中。这些「氛围检查」是欠优回答的信号；代码和断言对其进行操作。最后，这种方法态度应该被更多的社群或团队接受、采纳，例如将对输入和输出的审核或注释添加到值班轮换的任务中。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.2 与模型协作&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;借助语言大模型的 API，我们可以从几家供应商那里获取智能支持。这无疑是一大优势，但同时也意味着需要在性能、时延、吞吐量和成本方面做出权衡。此外，鉴于过去一年几乎每个月都有更先进、更强大的模型推出，我们应当随时准备随着旧模型的淘汰和新模型的迁移来更新我们的产品。在本节中，我们分享了使用无法完全控制的技术的经验教训，这些模型无法自行托管和管理。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_22&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.2.1 生成结构化输出以简化后续集成&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在大多数实际应用场景中，LLM 的输出需要以某种机器可读的格式被下游应用程序所使用，例如，房地产客户关系管理系统 ReChat，它需要结构化的响应来在前端渲染小部件，Boba 是一个用于生成产品策略创意的工具，需要具有标题、摘要、可信度评分和时间范围等字段的结构化输出。LinkedIn 也分享了他们如何限制 LLM 生成 YAML 格式的数据，这些数据随后用于决定使用哪种技能，以及提供调用技能所需的参数。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这种应用模式是对 Postel 原则的极致演绎：在接受输入时应该宽容（接受任意的自然语言），在发送输出时应该保守（发送类型化、机器可读的对象）。我们预期这种模式将非常持久。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;目前，Instructor（&lt;/span&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;https://github.com/jxnl/instructor&lt;/span&gt;&lt;/em&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）和 Outlines（&lt;/span&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;https://github.com/outlines-dev/outlines&lt;/em&gt;&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）已成为从 LLM 中获取结构化输出的标准做法。如果你在使用 LLM API（例如 Anthropic、OpenAI），推荐使用 Instructor；如果你使用自托管模型（例如 Huggingface），则推荐使用 Outlines。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_23&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.2.2 跨模型迁移提示的挑战&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们精心设计的提示在某些模型上可能效果显著，但在其他模型上可能效果欠佳。这种情况可能发生在更换不同的模型提供应商时，也可能发生在同一模型的不同版本升级时。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，Voiceflow 发现，将模型从 gpt-3.5-turbo-0301 迁移到 gpt-3.5-turbo-1106 后，他们的意图分类任务的性能下降了 10%。（幸运的是，他们进行了评估！）同样，GoDaddy 观察到一个积极的趋势，即升级到 1106 版本后，gpt-3.5-turbo 与 gpt-4 之间的性能差距缩小了。（或者，如果你是一个乐观的人，可能会对 gpt-4 的领先优势因新升级而减少感到失望。）&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;因此，在进行跨模型提示迁移时，不应仅仅更换 API 端点，而应预计需要更多时间进行调整。不应假设使用相同的提示会得到相似或更好的结果。同时，建立可靠且自动化的评估机制对于衡量迁移前后的任务性能至关重要，这有助于减少手动验证的工作量。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_24&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.2.3 确定并固定模型版本&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在机器学习流程中，任何变更都可能影响整个系统（changing anything changes everything）。这一点在我们依赖于外部训练的语言大模型时尤其重要，因为这些模型可能会未知的情况下发生变化。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;幸运的是，许多模型供应商允许用户「固定」特定版本的模型（如 gpt-4-turbo-1106），确保模型权重保持不变。在生产环境中固定模型版本有助于避免因模型更换而导致的意外行为变化，这可能会引起客户对输出过于冗长或其他不可预见问题的关注。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;此外，建议维护一个与生产环境设置相同但使用最新模型版本的 shadow pipeline。这有助于安全地进行新版本的实验和测试。一旦验证了新模型的稳定性和输出质量后，就可以自信地在生产环境中更新模型版本。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.2.4 选择能胜任工作的最小模型&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;开发新应用时，人们往往会倾向于使用最大、最强的模型，但一旦确定任务在技术上是可行的，就值得尝试是否能用更小的模型达到相似的结果。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;较小模型的优势在于更低的时延和成本，尽管其性能可能较弱，但通过思维链（chain-of-thought）、n 次提示和上下文学习等技术，可以帮助小型模型发挥更大的作用。除 LLM API 之外，针对特定任务进行微调也能提高性能。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;综合考虑，通过精心设计的 workflow，较小的模型通常可以匹配甚至超越&lt;/span&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;单一大型模&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;型的输出质量，同时速度更快、成本更低。例如，这条推文（&lt;/span&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;https://twitter.com/mattshumer_/status/1770823530394833242&lt;/span&gt;&lt;/em&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）分享了 Haiku 加 10 次提示的性能超过了零次提示的 Opus 和 GPT-4 的案例。长远来看，我们期望看到更多以小模型为输出质量、时延和成本优化平衡的流工程（flow-engineering）实例。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以分类任务为例，DistilBERT（6700 万参数）等轻量级模型是一个令人惊讶的强大基准。参数为 4000 万的 DistilBART 也是一个极好的选择，在开源数据上进行微调后，它能够以 0.84 的 ROC-AUC 识别幻觉，性能超过大多数 LLM，而时延和成本却不到它们的 5%。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;关键是，不要忽视小型模型。虽然用庞大的模型解决每个问题很容易，但通过一些创造性实验，我们通常可以找到更高效的解决方案。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h2_25&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.3 产品&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;尽管新技术带来了新机遇，但创造卓越产品的原则始终不变。因此，即便我们首次面对新问题，也无需在产品设计上从头开始。将 LLM 应用开发建立在坚实的产品原则上，就可以确保我们为用户提供真正的价值。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_26&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.3.1 尽早持续设计&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;设计师的参与将促使你深入思考如何向用户构建和呈现产品。我们有时会错误地认为设计师只是对事物进行美化，但实际上除用户界面之外，他们还重新思考了如何改善用户体验，即使这意味着打破现有规则和范式。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;设计师十分擅长将用户需求转化为多种形式，其中一些形式可能更容易解决，从而为 AI 解决方案提供了更多的可能性。与开发其他产品一样，AI 产品的开发也应以用户需求为中心，而非单纯依赖驱动它们的技术。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;要始终自问：「用户希望产品为他们完成什么任务？聊天机器人是否适合完成这项任务？自动补全功能怎样？或者有其他更合适的解决方案？」同时，要考虑现有的设计模式与用户需求之间的关系。这些是设计师为团队能力带来的宝贵资产。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_27&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.3.2 为人类参与循环设计用户体验&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;获取高质量标注的一种方式是将人类参与循环（Human-in-the-Loop, HITL）整合到用户体验（UX）中。通过让用户轻松提供反馈和更正，我们可以提升即时输出，并收集宝贵数据来改进模型。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;假设有一个电子商务平台，用户可以上传并分类他们的产品。设计用户体验的方式如下：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;用户手动选择正确的产品类别；语言大模型定期检查新产品并在后端纠正错误分类。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;用户不选择任何类别；LLM 定期在后端分类产品（可能存在错误）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 实时建议产品类别，用户可按需验证和更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;尽管这三种方法都涉及 LLM，但它们提供了非常不同的用户体验。第一种方法将初始负担放在用户身上，并将 LLM 作为后处理检查。第二种方法不需要用户的任何努力，但不提供透明度或控制权。第三种方法找到了正确的平衡点，通过让 LLM 提前建议类别，我们减轻了用户的认知负担，他们不必学习我们的分类体系以分类产品！同时，通过允许用户审查和编辑建议，他们对产品如何分类有最终决定权，将控制权牢牢掌握在用户手中。作为额外收益，第三种方法为模型改进创造了自然的反馈循环。好的建议被接受（正标签），不好的建议被更新（先标记为负标签，随后再正标签以示改进）。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;建议、用户验证和数据收集的这种模式在以下几个应用中十分常见：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;编码助手：用户可以接受建议（强正反馈）、接受并微调建议（正反馈），或忽略建议（负反馈）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;Midjourney：用户可以选择放大并下载图片（强正反馈）、变更图片（正反馈），或生成一组新图片（负反馈）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;聊天机器人：用户可以对回答点赞（正反馈）或点踩（负反馈），或者如果回答非常糟糕，选择重新生成回答（强负反馈）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;反馈可以是显式的或隐式的。显式反馈是用户对我们产品请求的响应所提供的信息；隐式反馈是我们从用户互动中学到的信息，无需用户特意提供反馈。编码助手和 Midjourney 是隐式反馈的例子，显式反馈的例子是点赞和点踩。如果我们像编码助手和 Midjourney 那样设计好用户体验，就可以收集大量隐式反馈来改进我们的产品和模型。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_28&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.3.3 严格确定需求优先级&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在考虑将 demo 转化为实际应用时，我们必须思考以下需求：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;可靠性：99.9% 的系统正常运行时间，遵循结构化输出标准&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;安全性：不产生冒犯性、不适宜工作场所或有害的内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;事实一致性：忠实于所提供的上下文，不虚构信息&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;实用性：满足用户的实际需求和请求&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;可扩展性：符合时延服务等级协议，能够支撑的吞吐量&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;成本：预算有限&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;其他：安全性、隐私性、公平性、GDPR 合规性、DMA 合规性等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果我们试图一次性解决所有需求，将永远无法推出产品。因此，我们需要进行严格的需求优先级排序。这意味着要明确什么是不可妥协的（例如，可靠性和安全性），没有这些，我们的产品将无法正常运作或不具备可行性。关键在于识别出最小可行产品。我们必须认识到第一版产品不可能是完美的，应该先发布产品，然后通过迭代来不断完善。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.3.4 根据应用场景调整风险承受度&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在选择语言模型和确定应用审查的严格程度时，要考虑应用场景和目标受众。对于面向客户的聊天机器人，如果提供医疗或财务咨询，我们需要设定极高的安全和准确度标准，错误或不良输出可能导致实际伤害并损害信任。然而，对于不那么关键的应用，例如推荐系统，或者面向内部的应用如内容分类或摘要，过于严格的要求只会拖慢进度而不会带来太多额外价值。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这与 a16z 最近的一份报告（&lt;/span&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;https://a16z.com/generative-ai-enterprise-2024/&lt;/em&gt;&lt;/span&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）相符，该报告显示许多公司在内部 LLM 应用方面比外部应用发展得更快。通过在内部生产力提升上实验 AI，组织可以在更受控的环境中开始捕获价值，并学习如何管理风险。随着信心的增强，他们可以逐步扩展到面向客户的用例。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;267&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;100011065&quot; data-ratio=&quot;0.4759259259259259&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; style=&quot;width: 100%;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/d316f34c-7d1b-4a91-a280-bceac7e9d7bc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;企业在内外部应用场景中使用语言大模型的比例（来源：a16z report）。&lt;/span&gt;&lt;/em&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.4 团队与职责&lt;/span&gt;&lt;/strong&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在这个新领域中，工作职能往往难以界定，但编写职位描述尤具挑战性。我们将不采用职位名称的交集图，也不提供职位描述建议。然而，我们将提出一个新的角色——AI 工程师——并讨论其角色定位。重要的是，我们将讨论团队的其他成员以及职责应如何分配。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_29&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.4.1 关注流程而非工具&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;面对 LLM 等新范式，软件工程师往往倾向于关注工具。因此，我们可能会忽略工具本应解决的问题和流程，这样会导致许多工程师无意中接受了额外的复杂性，这对团队的长期生产力产生了负面影响。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: left;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，这篇文章（&lt;/span&gt; 
  &lt;em&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(136, 136, 136);&quot;&gt;https://hamel.dev/blog/posts/prompt/&lt;/span&gt;&lt;/em&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;）讨论了某些工具如何自动为 LLM 创建提示。它认为（我个人认为正确）工程师如果不先理解解决问题的方法或流程，就使用这些工具，最终会承担不必要的技术债务。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;除偶然的复杂性，工具的规格也通常不明确。例如，有一个不断增长的 LLM 评估工具行业，提供「即插即用的 LLM 评估」解决方案，包含针对有害性、简洁性、语气等的通用评估器。我们看到许多团队在没有批判性思考其领域特定故障模式的情况下采用了这些工具。与此相反的是 EvalGen，它专注于通过让用户深入参与每一步（从指定标准到标记数据，再到检查评估）来教用户创建领域特定评估的过程。软件引导用户完成如下的 workflow：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100011063&quot; data-ratio=&quot;0.787962962962963&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;box-sizing: content-box;border-style: none;background-color: var(--bgColor-default, var(--color-canvas-default));display: inline;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/6ac94595-33d8-4401-85d9-86df4a698612.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(136, 136, 136);&quot;&gt;&lt;em&gt;&lt;span style=&quot;color: rgb(136, 136, 136);letter-spacing: 2px;font-size: 12px;&quot;&gt;引自「Shankar, S., et al. (2024). Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences」，https://arxiv.org/abs/2404.12272&lt;/span&gt;&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;EvalGen 引导用户遵循制作 LLM 评估的最佳实践，即：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ol dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;定义领域特定的测试（从提示自动引导生成）。这些定义为代码断言或以 LLM 作为评判者。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对齐测试与人类判断的重要性，以便用户可以检查测试是否捕捉到指定的标准。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;随着系统（提示等）的变化，对测试进行迭代。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;EvalGen 为用户提供了一个评估构建流程的心理模型，而不是将他们锚定在特定工具上。我们发现，在为 AI 工程师提供了这种上下文之后，他们通常会选择更简洁的工具或自行构建。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 的组成部分远不止提示编写和评估，这里无法一一详尽列出。然而，重要的是在采用工具之前，AI 工程师需要寻求理解流程。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_30&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.4.2 持续实验&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;机器学习产品与实验是密不可分的。这不仅包括 A/B 测试、随机对照试验等方法，还包括频繁地对系统最小单元的修改尝试以及进行离线评估。人们之所以如此重视评估，并不是因为它们关乎信任和信心，而是因为它们能够支持实验的进行！评估系统越完善，实验迭代的速度就越快，从而能够更快地找到系统的最佳版本。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;现在尝试用不同方法解决同一问题变得很常见，因为实验的成本已经大大降低。收集数据和训练模型的高昂成本被降至最低——提示工程的成本主要就是人力时间。确保团队中的每个人都了解提示工程的基础知识，这可以鼓励大家进行实验，并从组织的不同部门带来多样化的想法。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;此外，实验不仅仅是为了探索，也要利用它们进行开发！如果已经有了新任务的工作版本，建议让团队中的其他人采用不同的方法来处理，尝试寻找更快的解决方案。探索使用思维链（Chain-of-Thought）或少样本（Few-Shot）等提示技术来提升质量。不要让现有工具阻碍实验的进行；如果存在阻碍，就应该重新构建，或者购买更好的工具来提升实验效率。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后，在进行产品/项目规划时，要为构建评估系统和运行多个实验预留时间。在制定工程产品规格时，除了产品特性，还应该明确评估标准。在制定发展蓝图时，不要低估实验所需的时间——在产品获得生产许可之前，预计要经过多轮开发和评估迭代。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.4.3 让团队成员都能掌握并运用人工智能新技术&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;随着生成式人工智能技术的广泛应用，我们期望团队中的每一位成员——而不仅仅是技术专家——都能够理解并有信心使用这项新兴技术。要培养对语言大模型工作机制的直观理解，例如它们的时延、故障模式和用户体验，最好的方法就是亲自实践。LLM 的使用门槛相对较低：你无需编程技能即可改进流程性能，每个人都可以通过提示工程和评估工作贡献自己的力量。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;教育是实现这一目标的关键。可以简单到从提示工程的基础知识开始，如 n-shot 提示和思维链（CoT）等技术，这些技术有助于引导模型产生期望的输出。懂行的人还可以进一步教授技术性更强的内容，比如 LLM 本质上是自回归的。换句话说，尽管输入词元是并行处理的，但输出词元是顺序生成的。因此，在设计用户体验和设定性能预期时，需要认识到时延更多地取决于输出长度而非输入长度。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们还可以通过提供实践实验和探索机会来进一步促进学习，比如举办黑客马拉松。虽然看似让整个团队在探索性项目上花几天时间的成本较为高昂，但却可能带来意外之喜。通过黑客马拉松，有一个团队大约在一年的时间内，完成了未来三年的工作规划。另一个团队通过黑客马拉松实现了用户体验的范式转变，现在因为 LLM 这些体验成为了可能，其优势将持续到未来几年。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;span id=&quot;OSC_h3_31&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;2.4.4 避免过度依赖 AI 工程&lt;/span&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;随着新职位的出现，人们往往会过分夸大这些职位的能力。随着这些职位的实际工作范围变得清晰，公司常常会经历一个痛苦的纠正过程。无论是新入行者还是招聘经理，都可能对这些职位提出过高的要求或抱有不切实际的期望。过去十年的典型案例如下：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul dir=&quot;auto&quot; class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;数据科学家：被描述为「在统计学上比任何软件工程师都要出色，在软件工程上又比任何统计学家都要强」。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;机器学习工程师（MLE）：从软件工程视角来看待机器学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最初，许多人认为数据科学家足以单独承担数据驱动项目。然而，事实很快就证明，数据科学家必须与软件和数据工程师协作，才能有效开发和部署数据产品。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这种误解在 AI 工程师这一职位上再次出现，有些团队误以为只要有了 AI 工程师就万事大吉，但实际上，构建机器学习或 AI 产品需要多种专业角色的共同努力。在咨询了十多家 AI 产品公司后，我们发现他们经常陷入「AI 工程师即所需的一切」这一误区。因此，它们的产品往往难以从 demo 阶段过渡到更大规模的应用，因为公司忽视了构建产品的关键要素。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，为了将产品规模化，评估和测量至关重要，而这正是机器学习工程师擅长的领域，如果团队仅由 AI 工程师组成，那么很可能缺乏这方面的技能。共同作者 Hamel Husain 在他最近关于检测数据漂移和设计特定领域评估方法的研究中，强调了这些技能的重要性。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以下是在构建 AI 产品过程中，你需要的各类角色及时间顺序：&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;首先，集中精力构建产品。这可能需要 AI 工程师，但并非必须。AI 工程师在产品原型设计和快速迭代（如用户体验和基础架构）方面非常有价值。&lt;/span&gt; 
   &lt;/section&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;接下来，通过构建系统和数据收集来打好基础。根据数据的类型和规模，可能需要平台工程师或数据工程师。同时，必须有系统能够查询和分析这些数据，以便于调试问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;最后一步是优化 AI 系统。这不一定意味着要训练模型。基本工作包括设计指标、构建评估系统、运行实验、优化 RAG 检索、调试随机系统等。机器学习工程师在这方面非常擅长，不过 AI 工程师也可以学会这些技能。通常，在完成上述步骤之前，雇佣机器学习工程师是没有意义的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;除此之外，整个过程都需要领域专家的参与。在小公司，理想情况下是创始团队；在大公司，产品经理可以扮演这一角色。了解角色的发展和时机非常关键。错误的时间招聘错误的人（例如，过早招聘机器学习工程师）或以错误的顺序构建产品是在浪费时间和金钱，并会导致团队动荡。此外，在第 1-2 阶段定期咨询机器学习工程师（而不是全职雇佣）可以帮助公司正确地打好基础。&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot;&gt;&lt;/h2&gt; 
 &lt;span id=&quot;OSC_h2_32&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);&quot;&gt;3&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;span id=&quot;OSC_h2_33&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(30, 35, 128);&quot;&gt;策略：利用 LLM 构建产品，而不是被操纵&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;成功的产品需要深思熟虑的规划以及优先排序，而不是无休止的原型开发或追随最新的模型发布或趋势。在最后一节中，我们将展望未来，探讨构建出色 AI 产品的战略考量。我们还将探讨团队面临的关键权衡，如何时构建、何时购买，并提出了一份早期 LLM 应用开发策略的「操作手册」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_34&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.1 在 PMF 之前不要使用 GPU&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;要成为出色的产品，需要的不仅仅是对其他 API 的简单包装。但相反方向的错误可能代价更大。过去一年，大量风险投资，包括令人瞠目的 60 亿美元 A 轮融资，被用于训练和定制模型，却没有清晰的产品愿景或目标市场。本节我们将解释为什么立即跳到训练自己的模型是错误的行为，并探讨自托管的作用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_35&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.1.1 从头训练（几乎）从来没有意义&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对于大多数组织来说，从头开始预训练一个 LLM 是不切实际的，它会分散构建产品的注意力。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;尽管这听起来很令人兴奋，看起来其他人好像都在做，但开发和维护机器学习基础设施需要大量的资源。其中包括收集数据、训练和评估模型以及部署。如果你仍在验证产品市场契合度，这些将分散开发核心产品的资源。即便你拥有计算能力、数据和技术能力，预训练的 LLM 也可能在几个月内就过时。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如 BloombergGPT，这是一个专门为金融任务训练的 LLM。该模型由四名 AI 工程师和五名 ML 产品与研究人员通过预训练 3630 亿 token 完成。尽管如此，BloombergGPT 在这些任务上仍在一年内被 gpt-3.5-turbo 和 gpt-4 超越。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这个故事和其他类似的故事表明，对于大多数实际应用，从头开始预训练一个 LLM，即使是在特定领域数据上，也不是资源的最佳利用方式。相反，团队最好是对他们特定需求的最佳开源模型进行微调。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;当然也有例外。一个典型的例子是 Replit 的代码模型，专门为代码生成和理解而训练。通过预训练，Replit 能够超越其他更大尺寸的模型，如 CodeLlama7b。但随着其他越来越强大的模型发布，维持其实用性需要持续的投资。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_36&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.1.2 在证明必要之前不要微调&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对于大多数组织来说，微调更多是出于 FOMO（fear of missing out）而不是清晰的战略思考。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;组织在微调上投资过早，试图击败「只是另一种套壳」的指责。但实际上，微调是重型机械活，只有在收集了大量示例并确信其他方法不足时才应部署。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;一年前，许多团队告诉我们他们对微调很感兴趣。但很少有人找到产品市场契合度（PMF），大多数人后悔他们的决定。如果你要进行微调，最好非常确信已经准备好随着基础模型的改进而不断地微调——参见下面的「模型不是产品」和「构建 LLMOps」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;什么时候微调实际上是正确的选择？如果使用案例需要现有模型训练所用的大规模开放网络数据集中没有的数据——并且如果你已经构建了一个 MVP，证明现有模型的不足。但要小心：如果模型构建者无法轻松获得优秀的训练数据，你又从哪里获得？&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;LLM 驱动的应用程序并非是科学展览项目。对它们的投资应该与它们对企业战略目标和竞争差异化的贡献相称。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_37&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.1.3 从推理 API 开始，但不要害怕自托管&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;有了 LLM API，初创公司就比以往更容易采用和集成语言建模功能，而无需从头开始训练自己的模型。像 Anthropic 和 OpenAI 这样的供应商提供通用 API，只需几行代码就可以将智能融入你的产品。通过使用这些服务，可以减少所花费的精力，转而专注于为客户创造价值——这使你能够更快地验证想法并迭代 PMF。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;但就像数据库一样，托管服务并不适合所有使用案例，特别是随着规模和需求的增加。事实上，自托管可能是在不将机密/私有数据发送出你的网络的情况下使用模型的唯一方式，如医疗和金融等受监管行业所要求的，或由合同义务或保密要求所需。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;此外，自托管规避了推理供应商施加的限制，如速率限制、模型弃用和使用限制。此外，自托管让你能够完全控制模型，使构建差异化的高质量系统变得更容易。最后，自托管，特别是微调，可以大规模降低成本。例如，Buzzfeed 分享了他们如何微调开源 LLM，降低了 80% 的成本。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_38&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2 迭代以至卓越&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;为了在长期内保持竞争优势，你需要超越模型，考虑什么将使你的产品脱颖而出。尽管执行速度很重要，但它不应该是你唯一的优势。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2.1 模型不是产品，其周围的系统才是&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对于不构建模型的团队来说，快速的创新步伐是一大优势，因为他们从一个 SOTA 模型迁移到下一个，追求上下文大小、推理能力和性价比的提升，以构建更好的产品。这种进步既令人兴奋又可预测。总的来说，这意味着模型可能是系统中最不持久的组件。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;相反，应该将你的精力集中在提供持久价值的组件上，如：&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;评估：可靠地测量任务在不同模型上的性能&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;防护措施：无论如何，防止模型产生不良输出&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;缓存：通过避免使用模型来减少时延和成本&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;数据飞轮：推动上述所有内容的迭代改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这些组件比原始模型功能创建了更厚的产品质量护城河。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;但这并不意味着在应用层构建没有风险。不要将你的精力集中在 OpenAI 或其他模型供应商需要解决的问题上，如果他们想提供可行的企业软件。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，一些团队投资于构建自定义工具以验证专有模型的结构化输出；在这里，尽可能少的投资很重要，但深入的投资并不能充分利用时间。OpenAI 需要确保当你请求一个函数调用时，会得到一个有效的函数调用——因为这是所有客户都需要的。可以在这里采取一些「战略性拖延」，构建你所绝对需要的内容，并等待提供商能力的明显扩展。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_39&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2.2 从小处着手建立信任&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;构建一个试图满足所有人需求的产品是不可能的。为了创造引人注目的产品，公司需要专注于构建能够吸引用户反复使用的粘性体验。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如一个通用的 RAG 系统，旨在回答用户可能问的任何问题缺乏专业化意味着系统无法优先处理最新信息、解析特定领域的格式或理解特定任务的细微差别。结果，用户得到了一次浅薄、不可靠的体验，无法满足他们的需求，导致用户流失。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;为了解决这个问题，需要专注于特定领域和使用案例。通过深入而不是宽泛来缩小范围。这将创建与用户产生共鸣的特定领域工具。专业化还可以让你公开自己系统的能力和限制。清晰地说明系统能做什么、不能做什么，这显示出自我意识，帮助用户理解它在哪些方面可以增加最多的价值，从而建立对输出的信任和信心。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_40&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2.3 更快的迭代是构建 LLMOps 的正确动因&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;DevOps 的根本目的&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;并不是可复现的工作流程、左移策略（即尽早进行测试和安全检查）&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;或给两个小团队赋能——更不是为了编写 YAML 文件。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;DevOps 的真正目的是缩短工作与其结果之间的反馈周期，不断改进而不是不断犯错。其根源可以追溯到精益创业运动，通过精益制造和丰田生产&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;系统，强调单分钟换模（Single Minute Exchange of Die，SMED）和持续改进&lt;/span&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;（Kaizen）。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;MLOps 已经将 DevOps 的形式用于机器学习。我们拥有可复现的实验和一体化的套件，因此赋能模型构建者进行交付。而且，我们有大量的 YAML 文件。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;但是，作为一个单独的行业，MLOps 并没有采用 DevOps 的功能。它没有缩短模型在生产中的推断和交互之间的反馈差距。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;值得高兴的是，LLMOps 领域已经从关注提示管理这样的小问题转向解决阻碍迭代的重大难题：生产监控和持续改进，并通过评估将两者联系起来。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们已经拥有中立的、能众包评估对话和编码模型的互动平台——这是一个多人参与的、迭代改进的外循环。LangSmith、Log10、LangFuse、W&amp;amp;B Weave、HoneyHive 等工具不仅承诺收集和整理生产中系统结果的数据，还通过深度集成开发利用这些数据来改进系统。你可以选择使用这些工具或者构建你自己的工具。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_41&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2.4 不要构建可以买到的 LLM 功能&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;大多数成功的企业不是 LLM 企业。同时，大多数企业有机会通过 LLM 改进。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这一对观察结果经常误导领导者仓促地为系统加装 LLM，增加成本和降低质量，并将它们作为虚假的、装饰性的「AI」功能发布，带有令人厌恶的闪亮图标。我们其实有更好的方法：专注于真正与产品目标一致并增强核心运营的 LLM 应用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以下错误尝试会浪费团队的时间：&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
 &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;构建自定义的文本到 SQL 功能。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;构建与文档对话的聊天机器人。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;将公司的知识库与客户支持聊天机器人集成。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然以上这些是 LLM 应用的入门项目，但对产品公司而言是没有意义的。对于很多企业来说，这些是一般性问题，从演示到可靠组件之间存在着巨大的差距——这是软件公司的传统领域。将宝贵的研发资源投入当前 Y Combinator 批次正在大量解决的一般性问题上便是一种浪费。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;如果这听起来像是陈词滥调的商业建议，那是因为在当前的热潮中，容易误将任何「LLM」视为前沿的、附加的差异化，而忽略了那些已经过时的应用程序。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_42&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.2.5 AI 在其中；人类在中心&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;目前，LLM 驱动的应用很脆弱。这些应用需要大量的安全保障和防御性工程，但仍然难以预测。此外，当范围明确时，这些应用可能非常有用。这意味着 LLM 是加速用户工作流程的优秀工具。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们可以想象 LLM 应用完全取代工作流程或担任某个职位职能，这虽然很诱人，但目前最有效的范式还是人机混合（Centaur Chess）。当有能力的人类与快速利用的 LLM 功能相结合时，生产力和完成任务的满意度可以大大提高。LLM 的旗舰应用之一，GitHub CoPilot，展示了这些工作流程的力量：&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;125&quot; data-source-title=&quot;&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot; data-text=&quot;「总体而言，开发人员告诉我们，GitHub Copilot 和 GitHub Copilot Chat 使编码更容易、更少犯错、更具可读性、可重用性、更简洁、更易维护以及更具弹性，他们因此感到更加自信。」 - Mario Rodriguez, GitHub&quot; data-editid=&quot;deazbwvvk8tt1ueneo&quot;&gt; 
  &lt;section class=&quot;js_blockquote_digest&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;「总体而言，开发人员告诉我们，GitHub Copilot 和 GitHub Copilot Chat 使编码更容易、更少犯错、更具可读性、可重用性、更简洁、更易维护以及更具弹性，他们因此感到更加自信。」 - Mario Rodriguez, GitHub&lt;/span&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;对于在机器学习领域工作了很长时间的人来说，你可能会立即想到「人类在循环中」，但先别那么快：因为 HITL 机器学习是一种基于人类专家确保 ML 模型按预期行为的范式。虽然有关联，但这里我们提出的是更微妙的东西。LLM 驱动的系统目前不应该是大多数工作流程的主要驱动者，它们只是资源。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;通过以人为中心，询问 LLM 如何支持他们的工作流程，产品和设计决策会有显著的不同。最终，它将推动你开发出不同于竞争对手的产品，这些竞争对手试图将所有责任迅速转移给 LLM；而你的产品将更好、更有用和风险更低。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_43&quot;&gt;&lt;/span&gt; 
 &lt;h3 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.3 从提示、评估和数据收集开始&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;前几节已经提供了很多技术和建议，有很多需要消化的内容。现在让我们考虑一套最低限度的有用建议：如果一个团队想要构建 LLM 产品，应该从哪里开始？&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;在过去的一年里，我们已经看到成功的 LLM 应用遵循一致的轨迹。在本节中，我们将探索这个基本的「入门」手册。核心思想是从简单开始，只在必要时增加复杂性。一个好的经验法则是，每个复杂度级别通常需要比前一个多一个数量级的努力。考虑到这一点…&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_44&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.3.1 从提示设计优化开始&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;提示设计优化是第一步。使用我们在前面战术部分讨论的所有技术。思维链、n-shot 示例、结构化输入和输出几乎总是有用的。在尝试从性能较弱的模型中「挤出」性能之前，先使用最强大的模型进行原型设计。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;只有当提示设计优化无法达到所需的性能水平时，才应考虑微调。如果存在阻碍使用专有模型并因此需要自托管的非功能性要求（例如，数据隐私、完全控制、成本），这种情况会更频繁地出现。确保这些相同的隐私要求不会阻止你使用用户数据进行微调！&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_45&quot;&gt;&lt;/span&gt; 
 &lt;h4 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.3.2 构建评估体系，启动数据飞轮&lt;/span&gt;&lt;/h4&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;即便是刚刚起步的团队，评估也是不可或缺的。没有评估，我们就无法判断提示工程是否到位，或者定制模型是否能够取代基础模型。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;有效评估应针对具体任务，并与预期使用场景相吻合。我们建议首先进行单元测试，这是一种基础的评估方式。通过这种简单的测试，我们可以发现已知或潜在的失败模式，从而帮助我们做出早期的设计决策。此外，针对分类、摘要等不同任务，还有更多特定的评估方法可供参考。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;虽然单元测试和基于模型的评估都非常重要，但它们并不能完全替代人类评估。让真实的用户使用你的模型或产品，并收集他们的反馈，这样不仅能评估模型在现实世界中的表现和缺陷率，还能收集到高质量的标注数据，然后将这些数据用以进一步优化未来的模型。这个过程形成了一个正向的反馈循环，即数据飞轮，它能够随着时间的积累而不断增强：&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;通过人工评估来衡量模型的性能或发现问题&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;利用标注数据微调模型或改进提示&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;li style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;重复这一过程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;例如，在审核语言大模型生成的摘要时，我们可能会对每个句子进行细致的标注，以识别事实错误、不相关或风格问题。然后，我们可以利用这些事实不一致标注（factual inconsistency annotations）训练幻觉分类器，或使用相关性标注训练相关性奖励模型。再比如，领英在其撰写的文章中分享了他们使用基于模型的评估工具来估计幻觉、负责任的人工智能违规行为、连贯性等方面的成功经验。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;通过创建能够随时间增值的资产，我们不仅将评估工作从一项纯粹的运营成本转变为了战略投资，同时也在这个过程中启动了数据飞轮。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);font-size: 18px;&quot;&gt;3.4 低成本认知的高级发展趋势&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;1971 年，施乐帕洛阿尔托研究中心（Xerox PARC）的科学家们预见了未来：一个利用联网的个人电脑而紧密相连的世界，而这正是我们今天所生活的时代。他们不仅预见了这一未来，更通过在关键技术领域的重要贡献——包括以太网、图形渲染、鼠标以及窗口界面等——直接推动了这一未来的实现。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;他们还进行了一项基础练习：审视那些极具价值（如视频显示）但在当时成本过高的应用（例如，获取足够的 RAM 以驱动视频显示需要花费数千美元）。接着，他们分析了这项技术的历史价格走势（类似于摩尔定律），并预测了这些技术将在何时变得经济实惠。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们可以对语言大模型技术进行同样的分析，尽管我们没有像晶体管数量与成本比这样直接的指标。使用一个广受欢迎且历史悠久的基准测试（比如大规模多任务语言理解数据集），以及一种持续一致的输入方法（five-shot 提示），然后对比不同时间点上，不同性能水平的语言模型在这一基准测试上的运行成本。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100011073&quot; data-ratio=&quot;0.7490740740740741&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/b3a74665-cafe-4f86-854f-17e4214a33f2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 12px;color: rgb(136, 136, 136);&quot;&gt;图表：对于固定成本，其能力正迅速提升。对于固定能力水平，其成本正迅速降低。图表由共同作者 Charles Frye 使用 2024 年 5 月 13 日的公开数据绘制而成。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;自 OpenAI 的 davinci 模型作为 API 发布四年以来，在一百万词元的任务上（约等于本文档的一百倍）运行同等性能的模型，其成本已从 20 美元骤降至不到 10 美分——成本减半的周期为六个月。同样，截至 2024 年 5 月，无论是通过 API 服务还是自行部署，运行 Meta 的 LLaMA 3 8B 模型每百万词元的成本仅为 20 美分，其性能与 OpenAI 的 text-davinci-003 模型不相上下，后者正是支撑 ChatGPT 的模型。2023 年 11 月末发布时，text-davinci-003 每百万词元的成本约为 20 美元。在短短 18 个月内，成本下降了两个数量级，而按照摩尔定律的预测，这一时期内成本本应只减少一倍。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;现在，让我们聚焦于一种极具潜力的 LLM 应用：视频游戏中的角色生成，正如 Park 等人的研究所示。尽管这项技术非常有用，但其成本曾高达每小时 625 美元，尚不具备经济性。然而，自 2023 年 8 月论文发布后，其成本已经大幅下降至每小时 62.50 美元，下降了 10 倍。根据这一下降趋势，我们预计在未来九个月内，其成本将进一步降至每小时 6.25 美元，将更具经济可行性。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;与此同时，回顾 1980 年《吃豆人》的问世，以今天的货币价值来衡量，1 美元足以让你享受数分钟到数十分钟的游戏乐趣——大致相当于每小时能玩六局，即每小时花费 6 美元。这一计算表明，这种富有吸引力的由 LLM 增强的游戏体验，有望在 2025 年变得具有成本效益。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这些趋势虽然是近几年才出现的，但目前并没有明显的迹象表明其会在未来几年内减缓。尽管我们在算法和数据集方面可能已经充分利用了一些容易实现的改进，例如超越了每参数 20 个词元的「Chinchilla 比率」，但数据中心和硅层面更深层次的创新和投资将继续推动这一趋势向前发展。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;这可能是最重要的战略洞见：今天看起来完全不可行或者非常前沿的技术，比如一些复杂的演示或研究论文中提出的理论，在几年之内可能会变成现实。鉴于技术的这种发展趋势，我们在构建系统和组织时，应该考虑到这一点。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;color: rgb(63, 63, 63);&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h2_46&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 24px;color: rgb(246, 171, 0);&quot;&gt;4&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;span id=&quot;OSC_h2_47&quot;&gt;&lt;/span&gt; 
 &lt;h2 tabindex=&quot;-1&quot; dir=&quot;auto&quot; style=&quot;text-align: center;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;letter-spacing: 2px;font-size: 18px;color: rgb(30, 35, 128);&quot;&gt;看够了从 0 到 1 的演示，是时候推出从 1 到 N 的产品了&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;我们都知道，构建 LLM 演示非常有趣。只需几行代码、一个向量数据库和一个精心设计的提示，我们就能创造奇迹。在过去的一年里，人们常常将 LLM 与互联网、智能手机，甚至印刷机相比较。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;然而，任何有实际软件发布经验的人都知道，在受控环境中运行的演示和大规模可靠运行的产品存在天壤之别。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;108&quot; data-source-title=&quot;&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot; data-text=&quot;世界上有很多容易想象和构建演示的问题，但要将其转化为产品却极其困难，例如，自动驾驶汽车。演示一辆汽车在街区周围自动驾驶很容易，但要将其转变为产品则需要数十年的努力。——安德烈·卡帕西（Andrej Karpathy）&quot; data-editid=&quot;3jl4hz857fqa5scq9s&quot;&gt; 
  &lt;section class=&quot;js_blockquote_digest&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
   &lt;section style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
    &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;世界上有很多容易想象和构建演示的问题，但要将其转化为产品却极其困难，例如，自动驾驶汽车。演示一辆汽车在街区周围自动驾驶很容易，但要将其转变为产品则需要数十年的努力。——安德烈·卡帕西（Andrej Karpathy）&lt;/span&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/blockquote&gt; 
 &lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;以自动驾驶汽车为例。1988 年出现了第一辆由神经网络驱动驾驶的汽车，二十五年后，安德烈·卡帕西在 Waymo 进行了第一次演示乘坐体验。十年后，该公司获得了无人驾驶许可。从原型到商业产品，自动驾驶汽车经历了三十五年严格的工程、测试、改进和监管导航。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;过去一年，工业界和学术界见证了语言大模型应用的起起伏伏，这是 LLM 应用从演示阶段向产品化转型的第一年。我们在评估、提示设计、安全防护等实操技巧中学到了很多，同时也在运营策略、团队构建以及内部能力建设等策略方面积累了宝贵的经验，希望这些经验教训能在你接下来的旅程中提供指导，因为我们将共同在这个令人振奋的新领域中不断探索前进。&lt;/span&gt;&lt;/p&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;&quot;&gt;&lt;span style=&quot;color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 1px;background-color: rgb(255, 255, 255);font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;caret-color: rgba(0, 0, 0, 0.9);&quot;&gt;其他人都在看&lt;/span&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h3_48&quot;&gt;&lt;/span&gt; 
 &lt;h3 style=&quot;letter-spacing: 0.578px;text-wrap: wrap;text-align: left;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);&quot;&gt; 
  &lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;width: 577.422px;outline: 0px;&quot;&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493221%26idx%3D1%26sn%3D0c75b8115f4d4a27c8a5d6505a0a4986%26chksm%3Dfe426853c935e145d21abd30e0ceb29486c9e306032dfcb3d071ce34d171425c11341a57d7bf%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;OneFlow 技术年货：800+页免费「大模型」电子书&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;800+页免费「大模型」电子书&lt;/a&gt;&lt;span style=&quot;font-family: system-ui, -apple-system, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: 16px;letter-spacing: 0.578px;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247493759%26idx%3D1%26sn%3D8c7940d3986245b56867de7c59023f28%26chksm%3Dfe426649c935ef5fdfbf92610a0cc949fcf5218c7549015b59bb9eefe4d6ccfe087854927e37%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;百万用户通话新风潮：仅需 50 秒，无界 AI 让彩铃变身短视频&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494613%26idx%3D1%26sn%3Dadf6511a9068a05edce4dd0fe8d96261%26chksm%3Dfe4265e3c935ecf5ce0c4394a5757d7ca097b86c167838096ade13337dc40ed0b53785e0bced%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;LLM Serving 有效吞吐量的最大化实现&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;LLM Serving 有效吞吐量的最大化实现&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494707%26idx%3D1%26sn%3D877f262911b8ebd65eb5292508f21544%26chksm%3Dfe426205c935eb13fc60363fd0d8e4e35defb45577f930fca6343ceff298a990fac575cadf60%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;最强开源大模型面世：阿里发布 Qwen2&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;最强开源大模型面世：阿里发布 Qwen2&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494744%26idx%3D1%26sn%3D841cb980a36bd73df294d813c7be1568%26chksm%3Dfe42626ec935eb783127dad4603841b882876b4f9c001fecc42faa30bc99fa43c3828c45aed1%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;文生图王者登场：Stable Diffusion 3 Medium 正式开源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;文生图王者登场：SD3 Medium 正式开源&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494744%26idx%3D1%26sn%3D841cb980a36bd73df294d813c7be1568%26chksm%3Dfe42626ec935eb783127dad4603841b882876b4f9c001fecc42faa30bc99fa43c3828c45aed1%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;文生图王者登场：Stable Diffusion 3 Medium 正式开源&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494752%26idx%3D1%26sn%3D4f91e5be1c0cba70b9b72bba34f2a365%26chksm%3Dfe426256c935eb4036a3d6be4401b9cc784f779815884090d17340cb3e830c84fe482f0e20c9%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;击败 GPT4-Turbo，最强开源代码模型 DeepSeek-Coder-V2 问世&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; style=&quot;font-family: system-ui, -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 1px;text-align: left;text-wrap: wrap;background-color: rgb(255, 255, 255);&quot; data-linktype=&quot;2&quot;&gt;最强开源代码模型 DeepSeek-Coder-V2 问世&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494090%26idx%3D1%26sn%3D8e757eb0a113d7ccd76e8a2424b8e19e%26chksm%3Dfe4267fcc935eeea5ba5f348431f8524f2bf3e70520dce09fdb2eb5fa1423735b37fc94ab7ac%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;OneDiff 1.0 发布！生产环境稳定加速 SD/SVD 模型&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494690%26idx%3D1%26sn%3Dabdd13b1320520b963ef1dbbd61b9cbe%26chksm%3Dfe426214c935eb0252c39a7989fb732309c61557793ea06f0a3d4e5498168d757d68c74761df%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;20+公司 AI 应用产品分析；24 名工程师的 LLM 使用痛点&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;20+公司 AI 产品分析；工程师的 LLM 使用痛点&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
   &lt;li style=&quot;outline: 0px;font-size: 14px;letter-spacing: 1px;&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU5ODY2MTk3Nw%3D%3D%26mid%3D2247494700%26idx%3D1%26sn%3D5a1bb060ed52181fac7b3bca0386ac98%26chksm%3Dfe42621ac935eb0c26af8703cf4e5207438fc24f8794c457a4ca45665eaf1c7b2f9d4fe619f2%26scene%3D21%23wechat_redirect&quot; textvalue=&quot;SiliconCloud 公测上线，每人免费送 3 亿 Token&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;SiliconCloud 公测上线，每人免费送 3 亿 Token&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/h3&gt; 
 &lt;p dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;em style=&quot;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: 14px;letter-spacing: 2px;text-align: center;text-wrap: wrap;background-color: rgb(239, 239, 239);&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-imgfileid=&quot;100011110&quot; data-ratio=&quot;0.5444444444444444&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;letter-spacing: 0.578px;text-align: left;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/fecdb1c1-2c9c-4ce3-aab0-d6b6526ccea6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/em&gt;&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-family: system-ui, -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;letter-spacing: 0.578px;text-align: left;text-wrap: wrap;color: rgb(63, 63, 63);&quot;&gt;&lt;span style=&quot;font-size: 16px;letter-spacing: 2px;&quot;&gt;&lt;strong&gt;&lt;br&gt;想要更快、便宜、更全面的开源大模型 API？&lt;br&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: var(--articleFontsize);text-align: left;text-wrap: wrap;letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;&quot;&gt;试试 SiliconCloud，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt; 
  &lt;strong&gt;&lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: var(--articleFontsize);text-align: left;text-wrap: wrap;letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;&quot;&gt;新用户送 1 亿 token：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;span style=&quot;font-size: var(--articleFontsize);text-align: left;text-wrap: wrap;letter-spacing: 2px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;&lt;strong style=&quot;font-size: var(--articleFontsize);letter-spacing: 0.578px;text-align: left;text-wrap: wrap;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;&quot;&gt;&lt;span style=&quot;letter-spacing: 2px;text-decoration: underline;&quot;&gt;www.siliconflow.cn/zh-cn/siliconcloud&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;br&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;span style=&quot;font-size: 14px;letter-spacing: 2px;&quot;&gt;&lt;em&gt;扫码加入 SiliconCloud 用户交流群&lt;/em&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;margin-right: 8px;margin-bottom: 0px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;color: rgb(62, 62, 62);font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(239, 239, 239);text-align: center;&quot;&gt; 
  &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-imgfileid=&quot;100011107&quot; data-ratio=&quot;1.3547486033519553&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1074&quot; style=&quot;width: 134px;height: auto !important;&quot; src=&quot;https://oscimg.oschina.net/oscnet/49ef4535-5299-4b8d-b5a5-09204957303f.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/section&gt; 
 &lt;section dir=&quot;auto&quot; style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt; 
  &lt;span style=&quot;color: rgb(63, 63, 63);letter-spacing: 2px;&quot;&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p style=&quot;display: none;&quot;&gt; 
  &lt;mp-style-type data-value=&quot;10000&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color: #858585; font-size: 13px;&quot;&gt;本文分享自微信公众号 - OneFlow（OneFlowTechnology）。&lt;br&gt;如有侵权，请联系 support@oschina.cn 删除。&lt;br&gt;本文参与「&lt;a href=&quot;https://www.oschina.net/sharing-plan&quot; target=&quot;_blank&quot;&gt;OSC 源创计划&lt;/a&gt;」，欢迎正在阅读的你也加入，一起分享。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/oneflow/blog/11213900</link>
            <guid isPermaLink="false">https://my.oschina.net/oneflow/blog/11213900</guid>
            <pubDate>Thu, 04 Jul 2024 08:45:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>李彦宏：没有应用，基础模型不值一提</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2024 世界人工智能大会暨人工智能全球治理高级别会议于 7 月 4 日在上海举行。&lt;/p&gt; 
&lt;p&gt;在 2024WAIC 期间，百度创始人、董事长兼首席执行官表示：「模型开源与代码开源不同，无法做到众人拾柴火焰高。激烈竞争环境中，商业化闭源模型最能打。当然这些都不是最重要的。没有应用，光有基础模型，不管是开源还是闭源，都是一文不值。」&lt;/p&gt; 
&lt;p&gt;李彦宏指出，百模大战造成了社会资源的巨大浪费，尤其是算力的浪费。但同时也使得我们追赶世界上最先进基础模型的能力得到了提升。&lt;/p&gt; 
&lt;p&gt;「去年 10 月我宣布文心 4.0 发布的时候，说文心 4.0 的能力跟 GPT4 相比毫不逊色，好多的同行还不以为然，今天大家可以看到国内已经有多款闭源模型声称他们已经追平或者是超越了 GPT4 的水平。」李彦宏说。&lt;/p&gt; 
&lt;p&gt;他表示，有些外行甚至混淆了模型开源和代码开源这两个概念。他认为，同样参数规模之下，闭源模型的能力比开源模型要更好。「如果开源想要能力追平闭源，那么他就需要有更大的参数。这就意味着推理成本会更高，反应速度会更慢。」&lt;/p&gt; 
&lt;p&gt;李彦宏说，大多数的应用场景并不合适开源模型，商业化的闭源模型才是最能打的。但他同时强调，没有应用，光有一个基础模型，不管是开源还是闭源都一文不值。&lt;/p&gt; 
&lt;p&gt;「我看到我们的媒体仍然是把主要的关注点放在了基础模型身上，一天到晚就是跑分，刷榜，谁谁谁又超越 GPT4 了，openAI 又出来 sora 了，又出来 GPT4o 了等等。今天这个震撼发布，明天那个史诗级更新，但是我要问，应用在哪里？谁从中获益了？」，李彦宏说，应用其实离我们并不遥远，基于基础模型的应用在各个领域都已经开始了逐步渗透。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;以下为演讲实录：&lt;/p&gt; 
&lt;p&gt;李彦宏：各位下午好，非常高兴再次来到上海参加世界人工智能大会，我是这个会议的常客了。去年因为出国没有来。所以我上一次来参加 WAIC 是 2022 年，我记得那年大会的主题是元宇宙，主办方也跟我讲，希望我讲一讲元宇宙，我说我还是讲 AI 吧，我讲不了元宇宙，所以我当时讲的主题是 AIGC，就是 AI Generated Content （Artificial Intelligence Generated Content）。我认为 AI 的技术发展路线，发生了方向性的改变，就是从过去的辨别式人工智能，转向了未来的生成式人工智能。&lt;/p&gt; 
&lt;p&gt;讲这个话是在 2022 年的夏天，5 个月之后，大家都知道，ChatGPT 发布了，而后来的事情大家就更清楚，所以两年的时间，恍若隔世，感觉整个世界都变了，人工智能可以说颠覆了绝大多数人的认知。&lt;/p&gt; 
&lt;p&gt;2023 年国内出现了百模大战，造成了社会资源的巨大浪费，尤其是算力的浪费。但是也使得我们追赶世界上最先进的基础模型的能力得到了建立。&lt;/p&gt; 
&lt;p&gt;去年 10 月，我宣布文心 4.0 发布的时候说，文心 4.0 的能力跟 GPT4 相比毫不逊色，好多的同行还不以为然，今天大家可以看到，国内已经有多款闭源模型声称它们已经追平或者是超越了 GPT4 的水平。&lt;/p&gt; 
&lt;p&gt;注意，我们说的是闭源大模型，不是开源大模型，这也是今年以来争议比较多的一个话题。有些外行甚至混淆了模型开源和代码开源这两个概念。&lt;/p&gt; 
&lt;p&gt;所谓模型开源，是拿到的只是一大堆参数，你还是要去做 SFT，还是要去做安全对齐，你不知道这些参数是怎么来的，你是无法做到众人拾柴火焰高的。即使你拿到对应的源代码，你也不知道他用了多少数据，用了什么比例的数据去训练这些参数。所以拿到这些东西，并不能够让你站在巨人的肩膀上去迭代和开发。&lt;/p&gt; 
&lt;p&gt;所以，同样参数规模之下，闭源模型的能力就比开源模型要更好，而如果开源要想能力追平闭源，那么它就需要有更大的参数，这就意味着推理成本会更高，反应速度会更慢。&lt;/p&gt; 
&lt;p&gt;很多人拿开源模型来改款，以为这样可以更好的服务自己的个性化应用，殊不知，这样你就创造了一个孤本模型，既无法从基础模型持续升级当中获益，也没办法跟别人去共享算力。&lt;/p&gt; 
&lt;p&gt;当然，我也承认开源模型在某些场景下是有自身价值的。比如说一些学术研究，或者在教学领域，大家想要研究大模型的工作机制，形成理论，这个时候可能是有价值的，因为大家也经常听到，我们觉得大模型能力很强，但是不知道为什么能力强，因为背后没有理论来支持它，所以研究这个东西，用开源的我觉得没问题。&lt;/p&gt; 
&lt;p&gt;但是，大多数的应用场景，开源模型并不合适，当你处在一个激烈竞争的市场环境当中，你需要让自己的业务效率比同行更高，成本更低，这个时候商业化的闭源模型是最能打的。&lt;/p&gt; 
&lt;p&gt;当然，这些都不是最重要的，没有应用，光有基础模型，不管是开源还是闭源都一文不值。&lt;/p&gt; 
&lt;p&gt;所以，我从去年下半年开始讲，大家不要卷模型了，要去卷应用。但是我看到很多人仍然把主要的关注点放在基础模型上，一天到晚就是跑分，刷榜，谁谁谁又超越 GPT4 了，openAI 又出来 sora 了，又出来 GPT4o 了等等。今天这个震撼发布，明天那个史诗级更新，但是我要问，应用在哪里？谁从中获益了？&lt;/p&gt; 
&lt;p&gt;应用其实离我们并不遥远，基于基础模型的应用在各行各业、各个领域都已经开始了逐步的渗透，两个多月前，我们宣布文心大模型的日调用量超过了 2 亿，最近，文心的日均调用量超过了 5 亿！&lt;/p&gt; 
&lt;p&gt;仅仅两个多月的时间，调用量发生了这么大的变化，足见它背后代表了真实的需求，是有人在用，是有人真的从大模型当中获益了，得到了价值。&lt;/p&gt; 
&lt;p&gt;比如在快递领域，让大模型帮助处理订单，做到了「一张图、一句话寄快递」，不再需要其他繁琐的流程，时间从 3 分多钟缩短到 19 秒。而且 90% 以上的售后问题，也都由大模型来解决，效率提升非常的明显。&lt;/p&gt; 
&lt;p&gt;再比如在小说创作领域，一开始也用开源模型做出过一些效果，后来改用文心轻量级模型，经过 10 轮上万组数据的 SFT 和 post pretrain，结果有了明显的提升，最近又转到文心 4.0 版本，仅用了数百条数据，4.0 就在情节和逻辑方面展现出了非凡的优势，生成的内容无论是可用率还是优质率都大大超过了轻量级模型，网文作者们如虎添翼！&lt;/p&gt; 
&lt;p&gt;其实更通用的领域，比如说代码生成，文心快码这样的软件，在各个领域，也在逐步的渗透，在百度内部，我们有 30% 左右的代码，已经用 AI 生成的，代码的采用率超过了 44%。&lt;/p&gt; 
&lt;p&gt;不过，我们要避免掉入「超级应用陷阱」，觉得一定要出现一个 DAU10 亿的 APP 才叫成功，这是移动时代的思维逻辑。其实不一定，AI 时代，「超级能干」的应用比只看 DAU 的「超级应用」恐怕要更重要，只要对产业、对应用场景能产生大的增益，整体的价值就比移动互联网要大多了。&lt;/p&gt; 
&lt;p&gt;随着基础模型的日益强大，开发应用也越来越简单了，最简单的就是智能体，这也是我们最看好的 AI 应用的发展方向。制作一个好的智能体通常并不需要编码，只要用人话把智能体的工作流说清楚，再配上专有的知识库，一般就是一个很有价值的智能体了。这比互联网时代制作一个网页还要简单。&lt;/p&gt; 
&lt;p&gt;未来在医疗、金融、教育、制造、交通、农业等等领域，都会依据自己的场景，自己特有的经验、规则、数据等等，做出各种各样的智能体。将来会有数以百万量级的智能体出现，形成庞大的智能体生态。&lt;/p&gt; 
&lt;p&gt;而搜索是智能体分发的最大的入口。刚刚过去的高考季，很多大模型公司热衷于去写高考作文，我用 AI 写一个作文能得多少分，其实这个使用价值是不大的，人家不会让你带一个大模型去参加高考，但是真正的需求是大量的考生在考完之后要报志愿，要选择学校，选择专业，他们对一所大学，一个专业，会有各种各样的问题，而每一个考生的情况又是不一样的。这时候就是需要有一个智能体来回答每一个考生专有的问题。&lt;/p&gt; 
&lt;p&gt;在高峰时期，百度的高考智能体每天要回答超过两百万个考生的问题，我们总共只有 1000 万的考生，在一天当中有这么大比例的人在利用这个智能体。&lt;/p&gt; 
&lt;p&gt;AI 正在以前所未有的速度向各行各业渗透，很多人担心如果我们日常的工作都让 AI 去做了，人是不是就没有工作机会了，这种担心不是没有道理的，但是过去这段时间，我听到的担心，听到的抱怨很多，听到的建设性的意见比较少，很少有人去致力于发掘生成式 AI 带来的新工作机会。&lt;/p&gt; 
&lt;p&gt;我在这算是抛砖引玉吧，我觉得一方面这次浪潮，AI 更多是在扮演 copilot 的角色，是副驾驶，还要人来把关，AI 只是辅助人工作，而不是替代人工作，它让人的工作效率更高，质量更好；另一方面，我们也看到有一些全新的工作机会开始冒出来了，比如数据标注师，过去几年我们帮助全国 20 多个城市落地了数据标注中心，提供了大量新的就业岗位，再比如提示词工程师，以后不用编程了，但是做好一个智能体还需要把工作流说清楚，这里要有很强的逻辑性，要用提示词对模型进行调教，随着智能体的大量涌现，这个工种需求量也会飙升。这些工作机会，通常门槛并不高，你做的一般也能够养家糊口，做得好的话，那上限可以年薪百万。&lt;/p&gt; 
&lt;p&gt;自人类文明诞生以来，永不停止的创新就是印刻在我们的 DNA 当中的。从石器时代的手斧，到移动时代的手机，再到 AI 时代的大模型，人类不断创造各种工具来改善生活，来提高生产力。但是它们永远只是工具，只有在被人类所使用的时候才有价值。我们坚定地相信，AI 不是人类的竞争对手，我们构建和应用人工智能技术，是为了满足人的需求，增强人的能力、让人类的生活更美好。&lt;/p&gt; 
&lt;p&gt;谢谢大家！&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300387</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300387</guid>
            <pubDate>Thu, 04 Jul 2024 08:31:15 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>国产编程语言 MoonBit 登顶海外知名媒体 The New Stack 热门文章榜</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;近日，MoonBit 团队负责人张宏波接受海外知名科技媒体 The New Stack 专访。采访文章《MoonBit：针对 Wasm 优化的语言，代码量少于 Rust》（MoonBit: Wasm-Optimized Language Creates Less Code Than Rust）一经发出，即登顶 the new stack 的热门文章榜首。&lt;/p&gt; 
  &lt;p&gt;在该篇报道中，资深科技记者 Loraine Lawson 与张宏波深入探讨了 MoonBit 在语言和工具链设计上的思路，在语言性能上针对 WebAssembly 技术实现的突破性进展，以及支持多平台后的生态前景，向开发者展现出 MoonBit 未来在边缘计算和无服务器计算领域的开发潜力。&lt;/p&gt; 
  &lt;p&gt;The New Stack 是一家位于美国的全球 DevOps 领域权威媒体平台，内容涵盖云原生计算、前端和后端开发、网站可靠性工程等。&lt;/p&gt; 
  &lt;p&gt;（文章链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthenewstack.io%2Fmoonbit-wasm-optimized-language-creates-less-code-than-rust%2F%25EF%25BC%2589&quot; target=&quot;_blank&quot;&gt;https://thenewstack.io/moonbit-wasm-optimized-language-creates-less-code-than-rust/）&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;314&quot; src=&quot;https://oscimg.oschina.net/oscnet/.jpg&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;MoonBit 海外社区生态已初具规模。目前已有社区成员自发编写 MoonBit 语言的 Extism 插件，并被 Extism 收入官方 PDK 库（Extism 是一个基于 Wasm 的开源插件系统，现已支持各大主流编程语言），是 MoonBit 在海外社区支持下实现的第一个实用案例。&lt;/p&gt; 
  &lt;p&gt;（参考链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fextism%2Fmoonbit-pdk%25EF%25BC%2589&quot; target=&quot;_blank&quot;&gt;https://github.com/extism/moonbit-pdk）&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;414&quot; src=&quot;https://k07b4svzd9.feishu.cn/space/api/box/stream/download/asynccode/?code=NTc0ZmMwZjM4OTliYzE2OTBkYzVlZDFhMjljMTg5ODlfRmEwckNIQ25UWnJaNlV1VVkwR2NhV3Y0TFNuS0gwYXVfVG9rZW46REdRcmJTYlZDb1BpeGl4VEVTNGNxbjBNbjNmXzE3MjAwODA2NDc6MTcyMDA4NDI0N19WNA&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;海外开发者社区对 MoonBit 的语言设计做出了极高评价。资深开发者及编程语言爱好者 Glenn 表示：（学习 MoonBit 要花费的时间）远比你想象的要少，我发现 MoonBit 非常容易阅读，它的编译器速度非常快，工具也非常棒，这一切都给我带来了超级愉快的体验！自从我开始喜欢 Go 以来，我还从未享受过如此多的乐趣！像我一样享受这段旅程吧！（事实上，我对 Go 的体验完全不同，我讨厌了它大约一年，然后又试了一次，现在 Go 是我最喜欢的编程语言之一，而 MoonBit 正在成为我最喜欢的编程语言的有力竞争者！）&lt;/p&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;288&quot; src=&quot;https://k07b4svzd9.feishu.cn/space/api/box/stream/download/asynccode/?code=YzlhNTRlYjAxNDlmMGEwNjFlNmIwOTU5ZDJhMzNiMGRfYmVlMkxVTURLd3RMV0l2ajZ2S0tQRnBYVzdSYXN6Nk9fVG9rZW46QU9yUWIzZ0Fab24xZ2l4NHl4dWN0SnEybktmXzE3MjAwODA2NDc6MTcyMDA4NDI0N19WNA&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;国产编程语言 MoonBit 在海外持续收到开发者社区高度关注。此前，MoonBit 发布 JavaScript 后端支持新闻，收获十万级阅读量，以及多位知名开发者转发认可。&lt;/p&gt; 
  &lt;p&gt;日本社区成员 mizchi 在 zenn.dev 发表文章《MoonBit 是 WebAssembly 时代的最佳编程语言》（《MoonBit が WebAssembly 时代の理想 (の原型)だった》）于论坛爆火，引发了 X（twitter）日本程序员圈的广泛关注。在今年年初发布的 Redmonk 编程语言榜单中，MoonBit 被列入值得关注的潜力语言行列。&lt;/p&gt; 
  &lt;h4&gt;&lt;strong&gt;MoonBit 开发动态&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p&gt;国内首个工业级编程语言及其配套工具链 MoonBit（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.moonbitlang.cn%2F%25EF%25BC%2589%25E6%2598%25AF%25E7%2594%25B1%25E7%25B2%25A4%25E6%25B8%25AF%25E6%25BE%25B3%25E5%25A4%25A7%25E6%25B9%25BE%25E5%258C%25BA%25E6%2595%25B0%25E5%25AD%2597%25E7%25BB%258F%25E6%25B5%258E%25E7%25A0%2594%25E7%25A9%25B6%25E9%2599%25A2%25EF%25BC%2588%25E7%25AE%2580%25E7%25A7%25B0%25E2%2580%259CIDEA&quot; target=&quot;_blank&quot;&gt;https://www.moonbitlang.cn/&lt;/a&gt;）是由粤港澳大湾区数字经济研究院（简称「IDEA 研究院」）基础软件中心打造的 AI 原生的编程语言以及开发者平台。&lt;/p&gt; 
  &lt;p&gt;通过创新框架在程序语言界形成后发优势，在编译速度、运行速度、体积大小上已成功领先传统语言。&lt;/p&gt; 
  &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;314&quot; src=&quot;https://oscimg.oschina.net/oscnet/.jpg&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;MoonBit 在 2022 年 10 月推出，那时恰逢 ChatGPT 刚刚问世。MoonBit 平台的出现不仅仅作为一种编程语言，更提供一个完整的开发工具链，包括 IDE、编译器、构建系统、包管理器等。&lt;/p&gt; 
  &lt;p&gt;现在 MoonBit 处在一个特殊的位置，有机会去重新构想整个编程语言工具链该如何与 AI 更好地协作，力图开启编程与 AI 结合的新篇章！&lt;/p&gt; 
  &lt;p&gt;项目发起人张宏波现任 IDEA 研究院基础软件中心首席科学家、MoonBit 平台负责人，是通用程序语言 ReScript 的作者，程序语言 OCaml 前核心开发人员。本科毕业于清华大学电子系，在美国宾夕法尼亚大学读博期间受 Bloomberg 邀请，从事函数式语言编译器的开发工作。&lt;/p&gt; 
  &lt;p&gt;张宏波主导的 ReScript 语言，目前仍是唯一一个由中国人制作的、在国际范围内有重要影响力的通用程序语言。该语言项目始于其个人兴趣，后广泛被世界各地的程序员采用。除英语外，ReScript 官方文档已被翻译成中文、韩语、葡萄牙语等多国语言版本。&lt;/p&gt; 
  &lt;p&gt;当下 MoonBit 的开发即将进入 Beta 阶段，除了已优化的 WebAssembly 后端之外，已于四月底支持 JavaScript 后端，并实现了 8 倍增速，并有更多的后端正在积极开发中，多后端生态将为 MoonBit 带来更加广泛的受众。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300384</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300384</guid>
            <pubDate>Thu, 04 Jul 2024 08:11:37 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Linux 不仅可以「蓝屏」，还可以「紫屏」、「黑屏」……</title>
            <description>&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;Linux 6.10 引入了一个新的 DRM Panic 处理程序基础设施，以便于在出现内核致命错误 (Panic)，或者 VT 支持可能被禁用的情况下显示相关信息。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;这项功能类似于 Windows 的蓝屏死机，此前我们也报道了 Red Hat 工程师 Javier Martinez Canillas 创建的 Linux 版本蓝屏死机界面。&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;margin-right: 8px;margin-bottom: 24px;margin-left: 8px;line-height: 1.6em;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;&quot;&gt;&lt;p style=&quot;margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;line-height: 1.6em;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;详情查看：&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650209428&amp;amp;idx=1&amp;amp;sn=08319aa1e138cb8798b93c2a397d426a&amp;amp;chksm=bed927fa89aeaeec26365bdf4786446719dd570cb950459c46cf3a3685ec2e17b276bed5a9ec&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Linux「史诗级更新」：蓝屏死机界面亮相&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; style=&quot;font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot; data-linktype=&quot;2&quot;&gt;Linux「史诗级更新」：蓝屏死机界面亮相&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;626&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-imgfileid=&quot;502727228&quot; data-ratio=&quot;1.0833333333333333&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1YrgiaarbicFBAmj99ibu3ExF96MZtJALrRN7gwVjKNP6Scnq4M0yZiboyUP7Q/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;有人抱怨这与 Windows 的蓝屏过于相似。Javier 表示这都是开源的，因此可以根据自己的喜好进行定制，于是他转身就拿出了&amp;nbsp;「黑屏死机界面」 (Black Screen Of Death)：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;422&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;502727221&quot; data-ratio=&quot;0.75&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;border-width: 0px;border-style: initial;border-color: initial;margin-right: auto;margin-left: auto;max-width: 80%;vertical-align: middle;cursor: zoom-in;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1YrgKQ11OAd0QtKPxgu79kbDBKlphbbZbibmQdsCKnia5v8D7oPO4icbC5iaqw/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;近日，Red Hat 的另一位内核工程师，同时也是 DRM Panic 贡献者——Jocelyn Falempe 提交了新补丁，用于在 DRM Panic 界面中显示错误消息二维码。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;334&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;502727223&quot; data-ratio=&quot;0.5944444444444444&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;border-width: 0px;border-style: initial;border-color: initial;margin-right: auto;margin-left: auto;max-width: 80%;vertical-align: middle;cursor: zoom-in;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1YrgmsBiaXy4vkdBeQxDuwbx9gchhffclasj7Z0gqUzlj6ibIC5BbFY22kpA/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;Jocelyn Falempe 介绍称：&lt;/span&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;该系列补丁添加了一个新的 &quot;panic&quot; 界面，将 kmsg 数据嵌入二维码中。二维码的主要优势在于可以将调试数据复制 / 粘贴到错误报告中。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;QR-code 编码器采用 Rust 编写，专门用于 drm_panic。原因在于它是在 panic 处理程序中被调用，因此无法分配内存或使用锁。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;该补丁的 Rust 代码使用了一些 Rust 核心 API，只提供了两个 C 语言 entry points。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;用 Rust 实现这项功能没有什么特别的原因，我只是想学习一下 Rust，看看它是否能在内核中工作。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;下图是修改了背景颜色，且包含二维码的 Linux Panic 错误信息界面：&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;292&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;502727220&quot; data-ratio=&quot;0.5194444444444445&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;border-width: 0px;border-style: initial;border-color: initial;margin-right: auto;margin-left: auto;max-width: 80%;vertical-align: middle;cursor: zoom-in;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1Yrgy3VTe6uMBMr6cSMSB6hUn1ycyfDXqLh46HpRY1qSWmsHB2Dm7VribGw/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;292&quot; data-backw=&quot;562&quot; data-imgfileid=&quot;502727219&quot; data-ratio=&quot;0.5194444444444445&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;border-width: 0px;border-style: initial;border-color: initial;margin-right: auto;margin-left: auto;max-width: 80%;vertical-align: middle;cursor: zoom-in;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1YrgBA5Bdic3m0fhwRgqnGpbNcmJtUrF85icPywMYxLQs4IOk7nL2Y4fkE1w/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;详细的 Panic 错误信息如下（示例）：&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: justify;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;212&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-imgfileid=&quot;502727229&quot; data-ratio=&quot;0.3675925925925926&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 100%;height: auto;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK9ZDyJA4bJTYW6Q9AOD1YrgeNiczrzicUmes5kOn7ud8ia80aRcQ9Wtb7lL8PQYBObdkbmaeeqnaJgMg/640?wx_fmt=png&amp;amp;from=appmsg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span style=&quot;letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;由于内核错误信息通常都比较冗长，尤其是在包含堆栈跟踪的情况下，有时甚至无法在屏幕内显示内容。&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-size: 15px;letter-spacing: normal;color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;上述补丁将内核错误信息简化为二维码，可以方便用户通过智能手机获取错误信息，以便日后分析或附加到错误报告等。&lt;br&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;延伸阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot; style=&quot;list-style-type: disc;&quot;&gt;&lt;li&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;strong style=&quot;letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);color: rgb(61, 170, 214);&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650209428&amp;amp;idx=1&amp;amp;sn=08319aa1e138cb8798b93c2a397d426a&amp;amp;chksm=bed927fa89aeaeec26365bdf4786446719dd570cb950459c46cf3a3685ec2e17b276bed5a9ec&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Linux「史诗级更新」：蓝屏死机界面亮相&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Linux「史诗级更新」：蓝屏死机界面亮相&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr style=&quot;margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;line-height: 1.6em;&quot;&gt;&lt;p style=&quot;margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;line-height: 1.6em;&quot;&gt;&lt;strong style=&quot;letter-spacing: 0.578px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;font-size: var(--articleFontsize);&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);color: rgb(63, 63, 63);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;Reference&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);color: rgb(136, 136, 136);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;&quot;&gt;https://lore.kernel.org/rust-for-linux/20240703154309.426867-1-jfalempe@redhat.com/&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin-bottom: 24px;letter-spacing: 0.578px;outline: 0px;visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;span style=&quot;background-color: rgb(255, 255, 255);font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;font-size: 15px;letter-spacing: normal;color: rgb(136, 136, 136);&quot;&gt;https://fosstodon.org/@javierm/112650880236436431&lt;/span&gt;&lt;/p&gt;&lt;div style=&quot;margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;color: rgb(0, 0, 0);font-size: 16px;text-align: left;font-family: system-ui, -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);&quot;&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;outline: 0px;will-change: transform;&quot;&gt;&lt;div style=&quot;margin-top: 10px;margin-bottom: 10px;outline: 0px;text-align: center;justify-content: center;display: flex;flex-flow: row;&quot;&gt;&lt;div style=&quot;outline: 0px;display: inline-block;width: auto;vertical-align: top;min-width: 10%;flex: 0 0 auto;height: auto;border-bottom: 1px solid rgb(61, 114, 24);border-bottom-right-radius: 0px;line-height: 0;align-self: flex-start;&quot;&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;outline: 0px;&quot;&gt;&lt;div style=&quot;padding-right: 3px;padding-left: 3px;outline: 0px;letter-spacing: 0px;line-height: 1.3;font-size: 22px;color: rgb(61, 114, 24);&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;&lt;em style=&quot;outline: 0px;&quot;&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;END&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;margin-bottom: -3px;outline: 0px;&quot;&gt;&lt;p style=&quot;outline: 0px;display: inline-block;vertical-align: top;overflow: hidden;height: 5px;width: 5px;border-width: 0px;border-radius: 202px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(61, 114, 24);&quot;&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p style=&quot;text-align: center;text-wrap: wrap;outline: 0px;background-color: rgb(255, 255, 255);visibility: visible;line-height: 1.6em;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;div data-role=&quot;outer&quot; label=&quot;edit by 135editor&quot; style=&quot;margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;visibility: visible;&quot;&gt;&lt;div data-role=&quot;outer&quot; label=&quot;edit by 135editor&quot; style=&quot;outline: 0px;visibility: visible;&quot;&gt;&lt;div style=&quot;outline: 0px;font-size: 16px;&quot;&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;outline: 0px;will-change: transform;&quot;&gt;&lt;div style=&quot;margin: 10px;outline: 0px;text-align: left;justify-content: flex-start;display: flex;flex-flow: row;&quot;&gt;&lt;div style=&quot;padding-right: 10px;padding-left: 10px;outline: 0px;display: inline-block;width: 657px;vertical-align: top;border-style: dashed;border-width: 1px;border-color: rgb(62, 62, 62);align-self: flex-start;flex: 0 0 auto;&quot;&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;margin-top: 10px;margin-bottom: 10px;outline: 0px;&quot;&gt;&lt;div style=&quot;outline: 0px;display: inline-block;width: 635px;border-width: 0px 0px 0px 10px;border-style: solid;border-left-color: rgb(144, 215, 236);border-right-color: rgb(46, 172, 109);box-shadow: rgb(0, 0, 0) 0px 0px 0px;border-bottom-left-radius: 0px;&quot;&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;padding-right: 3px;padding-left: 3px;outline: 0px;&quot;&gt;&lt;div style=&quot;margin-top: 0.95em;margin-bottom: -0.65em;outline: 0px;display: inline-block;width: 619px;vertical-align: top;&quot;&gt;&lt;div style=&quot;outline: 0px;width: 619px;&quot;&gt;&lt;p style=&quot;outline: 0px;border-top: 1px solid rgb(0, 0, 0);width: 618.375px;float: left;&quot;&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt;&lt;/p&gt;&lt;p style=&quot;margin-top: -3px;outline: 0px;width: 6px;height: 6px;border-radius: 100%;float: right;background-color: rgb(46, 172, 109);&quot;&gt;&lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt;&lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;margin-top: -1em;padding: 3px 10px;outline: 0px;display: inline-block;vertical-align: top;background-color: rgb(255, 255, 255);color: rgb(0, 154, 68);&quot;&gt;&lt;p style=&quot;outline: 0px;&quot;&gt;热门文章&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div powered-by=&quot;xiumi.us&quot; style=&quot;margin: 8px;outline: 0px;background-color: rgb(255, 255, 255);color: rgb(62, 62, 62);letter-spacing: 0.544px;font-size: 15px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.75em;visibility: visible;&quot;&gt;&lt;p style=&quot;outline: 0px;line-height: 2em;&quot;&gt;&lt;span style=&quot;letter-spacing: 1px;font-size: 14px;&quot;&gt;-&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210648&amp;amp;idx=1&amp;amp;sn=780e0fd4b34cabeaacc3956e80b188ce&amp;amp;chksm=bed8da3689af5320d29fbdaf4928d3662822e4d2cdeac84b64df4560f152ced9b3be3f95c3b0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;完全开源的现代化 IDE 正式发布：支持云端和桌面、兼容 VS Code 扩展、全球最大开源基金会打造&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; style=&quot;font-family: Optima-Regular, PingFangTC-light;letter-spacing: 0.544px;text-align: left;text-wrap: wrap;background-color: rgb(255, 255, 255);&quot; data-linktype=&quot;2&quot;&gt;完全开源的现代化 IDE 正式发布：支持云端和桌面、兼容 VS Code 扩展&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210574&amp;amp;idx=1&amp;amp;sn=0e57e503712e27ac6dbcf625cb9490da&amp;amp;chksm=bed8da6089af53762ddb560bc332601e9438a88b430b684caa2dbaa1e892fb1c8c2450b6f297&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;中国 Flutter「先驱者」——闲鱼即将上线网页版&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;outline: 0px;line-height: 2em;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;-&amp;nbsp;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210648&amp;amp;idx=1&amp;amp;sn=780e0fd4b34cabeaacc3956e80b188ce&amp;amp;chksm=bed8da3689af5320d29fbdaf4928d3662822e4d2cdeac84b64df4560f152ced9b3be3f95c3b0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;完全开源的现代化 IDE 正式发布：支持云端和桌面、兼容 VS Code 扩展、全球最大开源基金会打造&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210574&amp;amp;idx=1&amp;amp;sn=0e57e503712e27ac6dbcf625cb9490da&amp;amp;chksm=bed8da6089af53762ddb560bc332601e9438a88b430b684caa2dbaa1e892fb1c8c2450b6f297&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;中国 Flutter「先驱者」——闲鱼即将上线网页版&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; style=&quot;font-family: Optima-Regular, PingFangTC-light;letter-spacing: 1px;text-align: left;text-wrap: wrap;background-color: rgb(255, 255, 255);font-size: 14px;&quot;&gt;&lt;span style=&quot;font-size: 14px;&quot;&gt;中国 Flutter「先驱者」——闲鱼即将上线网页版&lt;/span&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210608&amp;amp;idx=1&amp;amp;sn=619943908bf9cc4ae66e38a7ed86394c&amp;amp;chksm=bed8da5e89af5348cc9d05eb408b10c32788996620f0a92c4c3c871466bad284d2a4170f2042&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;OpenSSH 爆高危漏洞 (CVE-2024-6387)，攻击者能够以 root 身份执行任意代码&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style=&quot;outline: 0px;line-height: 2em;&quot;&gt;&lt;span style=&quot;letter-spacing: 1px;font-size: 14px;&quot;&gt;-&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210449&amp;amp;idx=1&amp;amp;sn=e247407e39a33df18df04becb3cd072b&amp;amp;chksm=bed8dbff89af52e9a224a15944e132bbedf49183880a9ac58393cebcacec3ae3bf0122279a28&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;这款中国程序员开源的游戏引擎，让你用不到 100 行代码就写出「愤怒的小鸟」&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;这款中国程序员开源的游戏引擎，让你用不到 100 行代码就写出「愤怒的小鸟」&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;outline: 0px;line-height: 2em;&quot;&gt;&lt;span style=&quot;letter-spacing: 1px;font-size: 14px;&quot;&gt;-&amp;nbsp;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzM0MjcyMQ==&amp;amp;mid=2650210608&amp;amp;idx=1&amp;amp;sn=619943908bf9cc4ae66e38a7ed86394c&amp;amp;chksm=bed8da5e89af5348cc9d05eb408b10c32788996620f0a92c4c3c871466bad284d2a4170f2042&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;OpenSSH 爆高危漏洞 (CVE-2024-6387)，攻击者能够以 root 身份执行任意代码&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; style=&quot;font-family: Optima-Regular, PingFangTC-light;letter-spacing: 0.544px;text-align: left;text-wrap: wrap;background-color: rgb(255, 255, 255);&quot;&gt;OpenSSH 爆高危漏洞 (CVE-2024-6387)，攻击者能够以 root 身份执行任意代码&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;p style=&quot;margin-top: 16px;outline: 0px;color: rgb(62, 62, 62);font-family: Optima-Regular, PingFangTC-light;font-size: 15px;letter-spacing: 0.544px;text-align: center;line-height: 2em;&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;outline: 0px;margin-left: 8px;margin-right: 8px;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;132&quot; data-backw=&quot;562&quot; data-galleryid=&quot;&quot; data-imgfileid=&quot;502727224&quot; data-ratio=&quot;0.2351851851851852&quot; data-s=&quot;300,640&quot; data-type=&quot;other&quot; data-w=&quot;1080&quot; style=&quot;outline: 0px;width: 100%;height: auto;visibility: visible !important;&quot; src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/dkwuWwLoRK8Tp497bKtPfZCfWvqA0BIktiagh6DTHwIWXllMRuDTb4jDPzDP3KuapDWyDHoI80AfEH5Io7r7GDg/640?wx_fmt=png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;p style=&quot;display: none;&quot;&gt;&lt;mp-style-type data-value=&quot;3&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt;&lt;p&gt;📍发表于：中国，广东&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/300327/linux-drm-panic-qr-codes&quot;&gt;🔗️ 阅读原文&lt;/a&gt;&lt;/p&gt;</description>
            <link>https://osc.cool/EEQhtXur</link>
            <guid isPermaLink="false">https://osc.cool/EEQhtXur</guid>
            <pubDate>Thu, 04 Jul 2024 07:48:48 GMT</pubDate>
            <author>开源中国</author>
        </item>
        <item>
            <title>ECMAScript 2024 正式发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fecma-international.org%2Fpublications-and-standards%2Fstandards%2Fecma-262%2F&quot; target=&quot;_blank&quot;&gt;ECMAScript 2024&lt;/a&gt;&amp;nbsp;现已获得&amp;nbsp;ECMA International&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ecma-international.org%2Fnews%2Fecma-international-approves-new-standards-4%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;&lt;/a&gt;的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fecma-international.org%2Fnews%2Fecma-international-approves-new-standards-9%2F&quot; target=&quot;_blank&quot;&gt;批准&lt;/a&gt;。ECMAScript 是标准化的 JavaScript 语言，于 1997 年发布了第一版，现已发展成为世界上使用最广泛的通用编程语言之一。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;本 Ecma 标准定义了 ECMAScript 2024 Language，是 ECMAScript 语言规范的第 15 版。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;ECMAScript 2024（第 15 版）添加了调整 ArrayBuffers 和 SharedArrayBuffers 大小和传输功能；添加了新的 RegExp&lt;code&gt;/v&lt;/code&gt;flag，用于创建具有更多高级功能的 RegExp，以处理字符串集；并引入了用于构建 Promises 的&lt;code&gt;Promise.withResolvers&lt;/code&gt;便捷方法、用于聚合数据的&lt;code&gt;Object.groupBy&lt;/code&gt;和&lt;code&gt;Map.groupBy&lt;/code&gt;方法、用于异步等待共享内存更改的&lt;code&gt;Atomics.waitAsync&lt;/code&gt;方法，以及&lt;code&gt;String.prototype.isWellFormed&lt;/code&gt;和&lt;code&gt;String.prototype.toWellFormed&lt;/code&gt;方法，用于检查并确保字符串仅包含格式正确的 Unicode。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;368&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d87dac273b02f395c300be4868de5a42a34.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#4e4242&quot;&gt;ArrayBuffers 此前已启用对二进制数据的内存处理。新功能扩展了&lt;code&gt;ArrayBuffer&lt;/code&gt;构造函数以采用额外的最大长度，从而允许缓冲区的就地增长和收缩。还扩展了&lt;code&gt;SharedArrayBuffer&lt;/code&gt;增加了允许就地增长的最大长度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#4e4242&quot;&gt;Promise.withResolvers 则被描述为一种管理异步操作的机制。该功能为 Promise 构造函数添加了一个名为 withResolvers 的静态方法，该方法会返回一个 promise，并方便地暴露其解析和拒绝函数。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#4e4242&quot;&gt;一些未被纳入 ECMAScript 2024 的功能很有可能会出现在明年的 ECMAScript 2025 中，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.infoworld.com%2Farticle%2F3715631%2Fecmascript-2024-javascript-standard-approved.html&quot; target=&quot;_blank&quot;&gt;包括&lt;/a&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-duplicate-named-capturing-groups&quot; target=&quot;_blank&quot;&gt;重复命名捕获组&lt;/a&gt;（用于重复的 &lt;/span&gt;&lt;span style=&quot;color:#4e4242&quot;&gt;regex&amp;nbsp;捕获组）和&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftc39%2Fproposal-set-methods&quot; target=&quot;_blank&quot;&gt;JavaScript 中的新 Set 方法&lt;/a&gt;（用于将&lt;code&gt;union&lt;/code&gt;和&lt;code&gt;intersection&lt;/code&gt;等方法添加到 JavaScript 的内置&lt;code&gt;Set&lt;/code&gt;类中）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong style=&quot;color:#333333&quot;&gt;具体可查看：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F262.ecma-international.org%2F15.0%2F&quot; target=&quot;_blank&quot;&gt;https://262.ecma-international.org/15.0/&lt;/a&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ecma-international.org%2Fwp-content%2Fuploads%2FECMA-262_15th_edition_june_2024.pdf&quot; target=&quot;_blank&quot;&gt;https://www.ecma-international.org/wp-content/uploads/ECMA-262_15th_edition_june_2024.pdf&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300379/ecmascript-2024</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300379/ecmascript-2024</guid>
            <pubDate>Thu, 04 Jul 2024 07:40:37 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>StarRocks 3.3 重磅发布，Lakehouse 架构发展进入快车道！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;StarRocks 3.3 的发布标志着 Lakehouse 架构在数据分析领域迈向了一个新的高度。作为下一代 Lakehouse 架构的代表，StarRocks 3.3 在稳定性、计算性能、缓存设计、物化视图、存储优化和 Lakehouse 生态系统等方面进行了全方位的优化和创新。本文将逐一介绍 StarRocks 3.3 的这些新特性，带你深入了解这款强大的数据分析工具如何提升你的数据处理效率和分析能力。&lt;/p&gt; 
&lt;h2&gt;成熟稳定：全面提升的成熟度级别和大查询稳定性&lt;/h2&gt; 
&lt;p&gt;为了帮助用户更好地理解和使用新功能，StarRocks 3.3 对各项新特性进行了成熟度级别的划分，并采用了更清晰的标记体系：Experimental（实验性质）、Preview（公测阶段）和 GA（生产可用）。这种分级体系使用户能够根据功能的成熟度来决定是否在生产环境中使用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Experimental&lt;/strong&gt; &lt;strong&gt;（实验性质）&lt;/strong&gt; ：这些功能的接口可能会变动，甚至可能被调整或放弃，部分刚合入社区的代码覆盖率尚未达到标准的功能也会先放入这一类别。此类功能需要用户手动打开或主动调用，不会影响其他功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preview&lt;/strong&gt; &lt;strong&gt;（公测阶段）&lt;/strong&gt; ：接口基本稳定，但部分参数的语义可能会有微调。可以在非核心场景下使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GA（Gerneal available）&lt;/strong&gt; ：接口和功能已经明确，虽然还会有一些功能补充，但已有功能基本不会修改，完全达到生产可用状态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，为了进一步提升用户体验，我们针对数据湖分析、存算分离和物化视图等关键功能提供了更完整的产品能力边界和版本对照文档，方便用户理解和使用。&lt;/p&gt; 
&lt;p&gt;StarRocks 3.3 针对大查询、数据压缩和数据湖场景的内存占用进行了显著优化。通过 GA 级别的算子落盘能力（Spill to Disk），有效地优化了复杂查询的内存占用和 Spill 调度，确保大查询能够稳定执行而不会导致内存溢出（OOM）。此外，支持 Colocate Group Execution，通过分阶段执行 Colocated 表上的查询，大幅降低 Join 和 Agg 算子在执行时的内存占用，从而显著提升大查询的稳定性。&lt;/p&gt; 
&lt;h2&gt;性能提升：新架构，新台阶，新场景&lt;/h2&gt; 
&lt;p&gt;StarRocks 3.3 的发布不仅提升了基础性能，更在真实场景中的性能优化上迈上了新台阶。我们不仅仅拘泥于 Benchmark 测试的成绩，而是专注于在实际应用中的性能提升。&lt;/p&gt; 
&lt;p&gt;首先，在新架构性能优化方面，StarRocks 对 ARM 架构进行了大幅优化，相比 x86 平均成本降低 20%，同时查询性能提升 20%，使其成为与 x86 架构同等重要的一等公民。 &lt;strong&gt;在&lt;/strong&gt; &lt;strong&gt;AWS&lt;/strong&gt; &lt;strong&gt;Graviton&lt;/strong&gt; &lt;strong&gt;实例上的测试中，ARM&lt;/strong&gt; &lt;strong&gt;架构的性能提升显著：在&lt;/strong&gt; &lt;strong&gt;SSB&lt;/strong&gt; &lt;strong&gt;100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;11%；在 Clickbench&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;39%；在&lt;/strong&gt; &lt;strong&gt;TPCH&lt;/strong&gt; &lt;strong&gt;100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;13%；在&lt;/strong&gt; &lt;strong&gt;TPCDS 100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;35%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/6f431e49c495d4a442d2c379231e2dff.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在数据湖性能优化方面，StarRocks 3.3 提升了 Scan 性能，通过对 Page Index 的优化显著减少了 Scan 的数据规模，降低了 Page 多读的情况。此外，元数据性能也有了突破，显著提升了整体的处理效率。&lt;/p&gt; 
&lt;p&gt;针对特定场景的性能提升，StarRocks 3.3 进行了多方面的优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;倒排索引和 ngram 索引的增强显著提升了模糊搜索的效率；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FlatJson 对半结构化数据的处理性能也得到了百倍的显著提升，自动加速了 JSON 查询，使其性能接近结构化数据，同时保持了灵活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Bitmap 优化不仅提升了 Bitmap 系列函数的性能和内存占用，还补充了 Bitmap 导出到 Hive 的能力，以及相应的 Hive Bitmap UDF。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CodeGen 技术显著提升了复杂表达式的计算效率，而重构后的向量化正则表达匹配也大幅降低了 regexp_replace 函数的 CPU 消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为了应对数据倾斜问题，StarRocks 3.3 增加了外表统计信息中的直方图统计，使得在数据倾斜情况下能生成更准确的执行计划，并优化了数据倾斜时的 Shuffle Join 操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此外，全局字典的优化提供了字典对象，可以在各个 BE 节点内存中存储字典表的键值对映射关系通过 dictionary_get() 函数直接查询维度值，相对于原先通过 JOIN 维度表获取维度值的方式，查询效率更高。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;strong&gt;缓存设计：&lt;/strong&gt; Lakehouse 架构的最后一块拼图&lt;/h2&gt; 
&lt;p&gt;在 Lakehouse 架构中，缓存设计是实现高效数据处理的关键一环。对于存算分离架构来说，缓存的重要性不言而喻。无论是 Hive、Iceberg、Paimon 等外表，还是 StarRocks 存算分离的内表，缓存命中率的高低直接影响性能的优劣。在缓存命中情况下，性能已经能够追平存算一体的架构，但如何合理、稳定地将热数据保存在缓存中却是一大挑战。&lt;/p&gt; 
&lt;p&gt;StarRocks 原生开发的缓存功能为用户提供了开箱即用的便捷体验。无需复杂的配置，用户即可利用强大的缓存机制提升数据处理性能。StarRocks 3.3 通过一系列创新功能显著提升了缓存的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;预热缓存：&lt;/strong&gt; 通过 cache warmup 命令，可以预先将关键数据加载到缓存中，减少首次查询的延迟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;缓存优先级&lt;/strong&gt; &lt;strong&gt;：3.3.1 推出将 cache select 设置较高的缓存优先级，确保最重要的数据得到优先缓存。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;内存优化和可观测性：&lt;/strong&gt; 缓存的内存优化和可观测性的提升，使得缓存的管理和监控更加高效和透明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/102dc83c8bbc29f9256aa5d73d250b28.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在存算分离集群中，StarRocks 3.3 还适配了 AWS Express One Zone Storage，大幅提升了读写性能，为未来的全局缓存带来了全新的可能性。&lt;/p&gt; 
&lt;p&gt;此外，在缓存无法命中或者不希望使用缓存的场景下，冷查性能也得到了显著提升。主要通过优化 tablet 的并行扫描，以及对小 I/O 的自动合并，使得即使在没有缓存支持的情况下，查询性能依然表现优异。&lt;/p&gt; 
&lt;h2&gt;物化视图：连接湖仓的高效纽带&lt;/h2&gt; 
&lt;p&gt;物化视图作为 StarRocks 的核心能力，也是连接 Open lake format 和 StarRocks 内表的纽带。通过外表物化视图，可以透明地为数据湖上的查询进行加速，在保证 single source of truth 的同时，降低数据加工的复杂度。&lt;/p&gt; 
&lt;p&gt;在 3.3 版本中，我们又进一步做了一些重要优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;外表物化视图的进一步能力增强：&lt;/strong&gt; Iceberg 外表物化视图支持分区级别增量刷新，并可在分区方式为 Hidden Partition 的表上创建物化视图。Paimon 外表物化视图补全了改写能力，也支持了分区级别的增量刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更完善的透明改写能力:&lt;/strong&gt; StarRocks 3.3 支持了基于&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fquery_rewrite_with_materialized_views%2F%23%25E5%259F%25BA%25E4%25BA%258E%25E6%2596%2587%25E6%259C%25AC%25E7%259A%2584%25E7%2589%25A9%25E5%258C%2596%25E8%25A7%2586%25E5%259B%25BE%25E6%2594%25B9%25E5%2586%2599&quot; target=&quot;_blank&quot;&gt;文本&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fquery_rewrite_with_materialized_views%2F%23%25E5%259F%25BA%25E4%25BA%258E%25E8%25A7%2586%25E5%259B%25BE%25E7%259A%2584%25E7%2589%25A9%25E5%258C%2596%25E8%25A7%2586%25E5%259B%25BE%25E6%259F%25A5%25E8%25AF%25A2%25E6%2594%25B9%25E5%2586%2599&quot; target=&quot;_blank&quot;&gt;视图&lt;/a&gt;的物化视图改写。 除了原来标准 SJPG 的改写能力之外，基于视图的 MV 改写可以把针对视图的查询改写到对等的物化视图上，适用于建模和指标平台等场景。针对文本的改写能力能对一些非标准 SQL 片段进行文本匹配，解决复杂查询难以透明改写的问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/d9870de8786781218576f435cd86d564.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fcreate_partitioned_materialized_view%2F%23%25E5%25A4%259A%25E5%259F%25BA%25E8%25A1%25A8%25E5%25AF%25B9%25E9%25BD%2590%25E5%2588%2586%25E5%258C%25BA&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;多事实表分区刷新&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;优化&lt;/strong&gt; &lt;strong&gt;：&lt;/strong&gt; 此前，物化视图的分区刷新策略仅支持单个事实表增量刷新策略（即当物化视图的分区列和一个 base 表的分区列一致场景下，物化视图的刷新会根据 base 表的分区来进行变更），3.3 版本新增的多事实表对齐策略，可以降低多事实表关联场景下的物化视图刷新开销。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/ef61f7a23590325fb150ca4bb0929afd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增改写策略（Transparent MV）：&lt;/strong&gt; 此前，物化视图的改写主要是把针对 base 表的查询改写到物化视图上，通过开启物化视图属性 &lt;code&gt;transparent_mv_rewrite_mode&lt;/code&gt; 后，当用户直接查询物化视图时，StarRocks 会自动改写查询，将已经刷新的物化视图分区中的数据和未刷新分区对应的原始数据做自动 Union 合并。 &lt;strong&gt;此模式允许配置&lt;/strong&gt; &lt;strong&gt;在&lt;/strong&gt; &lt;strong&gt;MV&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong&gt;base&lt;/strong&gt; &lt;strong&gt;表数据不一致时的改写行为，实现在数据时效性和查询性能之间的权衡，&lt;/strong&gt; &lt;strong&gt;适用于&lt;/strong&gt; &lt;strong&gt;分层建模场景。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;开启物化视图属性 &lt;code&gt;transparent_mv_rewrite_mode&lt;/code&gt; 后，当用户直接查询物化视图时，StarRocks 会自动改写查询，将已经刷新的物化视图分区中的数据和未刷新分区对应的原始数据做自动 Union 合并。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;大规模物化视图调度能力优化&lt;/strong&gt; &lt;strong&gt;：&lt;/strong&gt; 增加 &lt;code&gt;enable_query_rewrite&lt;/code&gt; 属性，实现对查询改写的禁用，减少计划开销。通过控制候选物化视图数量，并引入更高效的筛选算法，增加物化视图计划缓存（MV plan cache）。支持全局 FIFO 调度，优化嵌套物化视图的级联刷新策略。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;存储优化：更高效易用的数据管理&lt;/h2&gt; 
&lt;p&gt;StarRocks 3.3 在存储优化与易用性提升方面做出了诸多改进，进一步增强了系统的性能和用户体验。&lt;/p&gt; 
&lt;p&gt;首先，StarRocks 3.3 提升了 FE 的可观测性和锁机制优化。提供了详细的内存使用指标，让用户可以更好地管理和监控资源。同时，引入了锁管理器（Lock Manager），实现对元数据锁的集中管理，将元数据锁的粒度从库级别细化为表级别。 &lt;strong&gt;这种细化显著提高了导入和查询的并发性能，在&lt;/strong&gt; &lt;strong&gt;100&lt;/strong&gt; &lt;strong&gt;并发的导入场景下，导入耗时减少了&lt;/strong&gt; &lt;strong&gt;35%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了增强建表语句的清晰度，StarRocks 3.3 支持了 ORDER BY 语法，使得建表操作更加直观和简洁。此外，还增加了对重命名列（Rename Column）的支持（版本 3.3.1），进一步提升了数据管理的灵活性。&lt;/p&gt; 
&lt;p&gt;在存储效率方面，StarRocks 3.3 优化了非字符串标量类型数据的存储方式，存储空间下降了 12%。这不仅降低了存储成本，也提升了数据读取的效率。&lt;/p&gt; 
&lt;p&gt;针对主键表，StarRocks 3.3 实施了多项优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PK Index 存算分离支持 Remote Storage&lt;/strong&gt; ：主键索引落盘支持落至远程存储，提高了数据的灵活性和可扩展性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主键表支持 Size-tiered Compaction 策略&lt;/strong&gt; ：这一策略降低了执行 Compaction 时的写 I/O 和内存开销，适用于存算分离和存算一体的集群。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化主键表持久化索引的读&lt;/strong&gt; &lt;strong&gt;I/O&lt;/strong&gt; ：支持按照更小的粒度页读取持久化索引，并改进了持久化索引的 Bloom Filter。这一优化也适用于存算分离和存算一体的集群。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;生态支持：Lakehouse 扩展与集成&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hive&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：在 3.3 版本中，StarRocks 支持对 ORC 和 Text 文件的写入能力。 &lt;strong&gt;单 sink 算子的写入性能达到了&lt;/strong&gt; &lt;strong&gt;Trino&lt;/strong&gt; &lt;strong&gt;的 2 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Iceberg&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：StarRocks 3.3 大幅重构了 Iceberg 元数据查询模块，通过分布式元数据读取提升对 Avro 格式文件的解析性能，避免原生 SDK 的单点瓶颈，对小规模的元数据通过 manifest 缓存来降低重复 I/O，从而大幅提升了 Iceberg 的元数据访问性能。同时，增加了对 V2 表 equality delete 的支持，使用户能够高效分析使用 Flink 写入的 Iceberg upsert 数据。此外，还引入了对 Iceberg 视图（Iceberg View）的查询支持，使得数据管理和查询更加便捷和直观。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paimon&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：StarRocks 3.3 现已全面支持 Paimon 生态系统，包括对最新的 delete vector 的支持、Paimon 系统表的集成以及 scan range 调度的优化。通过这些改进，用户可以更高效地管理和查询 Paimon 中的数据，实现更灵活的数据处理和分析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ClickHouse&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong&gt;Kudu&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：为了方便用户从 Clickhouse 迁移到 StarRocks，社区贡献了专用的迁移工具，使得数据迁移过程更加平滑和高效。此外，StarRocks 还支持 ClickHouse 和 Kudu 的 Catalog 功能，使得用户可以更便捷地在这两种数据库和 StarRocks 之间进行数据管理和查询。&lt;/p&gt; 
&lt;h2&gt;总结：成熟的 Lakehouse 架构&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/5c2afac696c2b1b599e0e9a1cd12a28c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;StarRocks 正在积极向成熟的湖仓架构升级，不仅增强了与开放湖格式的兼容性，还显著提升了湖的写入性能。在数仓功能上，它进一步加强了索引和半结构化数据处理的性能，同时，存算分离架构成为更受青睐的成熟解决方案。&lt;/p&gt; 
&lt;p&gt;此外，大查询和 ETL 任务的稳定性的提高，为批处理的能力打下基础。这些进步共同推动了 StarRocks 向一套架构,满足所有的分析需求的&quot;One data, All Analytics&quot;愿景的迈进。&lt;/p&gt; 
&lt;p&gt;更详细的 feature 介绍参考：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Release note：&lt;/strong&gt; https://docs.mirrorship.cn/zh/releasenotes/release-3.3/&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;下载：&lt;/strong&gt; https://www.mirrorship.cn/zh-CN/download/starrocks&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播回放&lt;/strong&gt; ：https://www.bilibili.com/video/BV1F7421d72D/&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;更多交流，联系我们：https://wx.focussend.com/weComLink/mobileQrCodeLink/33412/2b42f&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300373/starrocks-3-3-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300373/starrocks-3-3-released</guid>
            <pubDate>Thu, 04 Jul 2024 07:32:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>中国 AI 初创公司「硅基流动」获近亿元天使+轮融资</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2844943140309637&quot; target=&quot;_blank&quot;&gt;36 氪报道称&lt;/a&gt;，AI 初创公司「硅基流动」（SiliconFlow）近日完成近亿元天使+轮融资。本轮融资由某知名产业方领投，跟投方包括智谱 AI、360 和水木清华校友基金等知名企业及机构，老股东耀途资本继续超额跟进，华兴资本担任独家财务顾问。&lt;/p&gt; 
&lt;p&gt;对本轮融资，创始人兼 CEO 袁进辉表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「非常感谢各位投资方对硅基流动的信任和支持。这次融资将帮助我们进一步加快产品创新，为开发者提供触手可及的 AI 云服务，促进 AI 应用层的繁荣，推动 AGI 技术普惠化。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;硅基流动是一家专注于 AI Infra（AI 基础设施）领域的创业公司，成立于 2023 年 8 月。创始人袁进辉是前 OneFlow（一流科技） 创始人及 CEO，曾任微软亚洲研究院主管研究员，获得微软亚洲研究院院长特别奖。&lt;/p&gt; 
&lt;p&gt;通俗地理解，硅基流动所在的 AI Infra 层，是上接 AI 应用层、下接算力芯片层的中间层，相当于大模型时代的「操作系统」。如何让大模型训练与推理更高效，充分释放底层硬件的潜力，降低生成式 AI 应用开发的门槛与成本，正是 AI Infra 需要解决的关键问题。&lt;/p&gt; 
&lt;p&gt;大模型训练包括对模型进行参数调优、数据训练等环节，让模型具备执行相应任务的能力；而推理则是在模型训练好之后，让模型进行预测与决策的过程，为 AI 应用提供智能能力。&lt;/p&gt; 
&lt;p&gt;其中，深度学习训练框架是 AI Infra 的重要组成部分。这个领域被大公司的开源产品所主导，典型框架有 Facebook 的 PyTorch，谷歌的 TensorFlow，国内有百度的 PaddlePaddle 等。从 2016 年开始，作为世界范围内研发工业级通用深度学习框架的唯一创业团队，袁进辉带领的 OneFlow 团队推出了高性能分布式深度学习框架。&lt;/p&gt; 
&lt;p&gt;之所以敢挑战以大厂主导的 AI 训练框架生态，是因为袁进辉确信：未来 AI 模型的参数量会越来越大。一旦模型变大，那么原有的深度学习框架不能满足开发者的需求，底层的 AI 框架就需要重构，而这是属于创业公司的机会。&lt;/p&gt; 
&lt;p&gt;随后，以 GPT 为代表的大模型热潮来临，OneFlow 团队所积累的大模型训练技术和认知得到验证。2023 年，处在大模型风口上的 OneFlow 团队被原美团联创王慧文所创立的大模型公司「光年之外」并购，随后，「光年之外」因故被美团并购，袁进辉带领团队创立新公司「硅基流动」。&lt;/p&gt; 
&lt;p&gt;再次出发，硅基流动依旧将方向定在 AI Infra 赛道。只是，随着大模型走入大规模应用落地时期，推理效率成为阻碍生成式 AI 应用成功的一大技术挑战。因此，硅基流动的技术方向瞄准了大模型推理领域。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;延伸阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;margin-left: 0px; margin-right: 0px; text-align: start;&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/234339&quot; target=&quot;_blank&quot;&gt;前美团联合创始人王慧文 「正在收购」 国产开源深度学习框架 OneFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/269588&quot; target=&quot;news&quot;&gt;王慧文入股 OneFlow 团队新创业公司&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300357</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300357</guid>
            <pubDate>Thu, 04 Jul 2024 06:32:36 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>商汤发布首个「可控」人物视频生成大模型 Vimi</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商汤发布首个「可控」人物视频生成大模型 Vimi，该模型主要面向 C 端用户，支持聊天、唱歌、舞动等多种娱乐互动场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1d3c46febc46f912807a1af58ddcc4e6af.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;商汤方面称，Vimi 可生成长达 1 分钟的单镜头人物类视频，画面效果不会随着时间的变化而劣化或失真，Vimi 基于商汤日日新大模型，通过一张任意风格的照片就能生成和目标动作一致的人物类视频，并支持多种驱动方式，可通过已有人物视频、动画、声音、文字等多种元素进行驱动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与图片表情控制类技术只能控制头部表情动作不同，商汤介绍，Vimi 能够实现精准的人物表情控制，还可实现在半身区域内控制照片中人物的自然肢体变化，并自动生成与人物相符的头发、服饰及背景变化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时光影变化也能做到合理生成，让人物动作和视觉效果流畅自然，画面和谐唯美。更重要的是，Vimi 具备极强的稳定性，可稳定生成长达 1 分钟的单镜头人物类视频，画面效果不会随着时间的变化而劣化或失真，真正满足娱乐互动等需要长时间稳定视频生成需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;286&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c74d4edce774a7793ce0970dfa8eadef2a4.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据悉 Vimi 将完全面向 C 端用户开放使用。用户只需上传不同角度的高清人物图片，即可自动生成数字分身和不同风格的写真视频。目前，Vimi 已在商汤科技官网开放预约。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Vimi 也入选了 2024 世界人工智能大会的「镇馆之宝」名单。其他入选的还包括阿里云 AI 编程助手通义灵码、支付宝智能助理、智谱 AI 基座大模型、特斯拉赛博越野旅行车等。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300348</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300348</guid>
            <pubDate>Thu, 04 Jul 2024 06:03:50 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>2024 华为开发者大会佛山分会场即将开幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt;
 &lt;span&gt;7 月 4 日，禅城区经济和科技促进局将携手华为云计算技术有限公司举办 2024 华为开发者大会（HDC 2024）佛山分会场活动，本次活动以「AI 引领佛山智造，数聚禅城开拓创新」为主题。届时，来自产业研究领域的专家学者、优秀企业负责人以及华为生态伙伴将汇聚一堂，共同为佛山制造业的数智化转型注入新动力。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;当前，数字经济蓬勃发展，数实融合持续推进。2022 年 3 月，华为云计算技术有限公司、中软国际联合佛山市禅城区人民政府共建华为（禅城）工业互联网创新中心（下称「创新中心」）。6 月，创新中心加入佛山数字经济创新集聚区，持续赋能推动佛山企业「加数」转型。佛山数字经济集聚区的快速发展，为人工智能与制造业的深度融合提供了优质平台与宝贵机遇。为助力企业紧抓新一代工业发展的历史机遇，实现高质量发展目标，禅城区经济和科技促进局将携手华为云计算技术有限公司举办 2024 华为开发者大会（HDC 2024）佛山分会场活动。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;据介绍，论坛上，华为云资深营销专家将发表《盘古大模型 5.0 构建佛山 AI 大模型时代的新数字竞争力》的主题演讲；清华大学数据与信息研究院副教授、博士生导师郑海涛将发表题为《人工智能将掀新一轮产业发展革命》的演讲。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;佛山市工业和信息化局将以政策为抓手，全面解析佛山布局行业数智化发展的动作，携手企业共同构建全域生态良好发展格局。此外，佛山市陶莹新型材料有限公司、深圳深研数智技术有限责任公司、中软国际等企业将结合人工智能赋能工业发展的实践案例，分享工业 AI 对制造业业务的强势赋能。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;作为制造业大市，佛山拥有丰富的制造业资源与坚实的产业基础，禅城区依托创新中心及佛山数字经济创新集聚区，加速人工智能在新型工业化领域的赋能作用，在数字经济领域取得显著成果。活动现场将进行重磅项目签约、制造业数字化转型标杆项目授牌，强化集聚区的工作实效。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;2024 华为开发者大会佛山分会场活动不仅将为佛山数字经济创新集聚区带来直接的项目合作和投资机会，也将有效提升其在全国乃至全球的知名度，吸引更多人才、资金和技术向禅城汇聚，共同推动佛山数字经济的高质量发展。&lt;/span&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 &lt;span&gt;值得一提的是，本次论坛还将设置华为鸿蒙生态全场景体验展区，将近距离感受华为手机系列、智能穿戴设备、AITO 智能汽车鸿蒙全场景智慧互联体验等。&lt;/span&gt;
&lt;/div&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300346</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300346</guid>
            <pubDate>Thu, 04 Jul 2024 05:45:50 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>中软国际智创未来园区落地未来科学城</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;7 月 2 日，由未来科学城集团下属置汇公司（以下简称「置汇公司」）负责实施的朱辛庄二期项目 CP01-0801-0039、0040 地块（以下简称「项目地块」）成功确认意向用地单位。北京中软国际信息技术有限公司（以下简称「中软国际」）摘得，将建设智创未来园区，助力昌平区成为数字化赋能行业「新一极」。&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;本次出让项目地块为 M4 工业研发用地，规划总用地面积约 3.49 公顷，规划地上总建筑面积约 8.73 万平方米，综合容积率为 2.5。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;图片&quot; src=&quot;https://oscimg.oschina.net/oscnet/e480392b491c88590f8095dcb5672521.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;朱辛庄二期 0039、0040 地块所在位置示意图&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;项目地块所在朱辛庄街区聚焦新一代信息技术、智能制造等高端产业，现已集&lt;span&gt;聚了小米智慧产业园、紫光数字经济科技园、中公教育、慧聪网等一批数字经济企&lt;/span&gt;&lt;span&gt;业。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;中软国际拿地后将建设智创未来园区，构建高效协同的信息技术创新生态，打造具有国际影响力和区域带动力的数字经济发展高地。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;图片&quot; src=&quot;https://oscimg.oschina.net/oscnet/eec29013d26f29cccad3e87d6f7f3d13.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;智创未来园区效果图&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;园区将以一线城市龙头企业总部需求业态比例为蓝本，构建数字化业务咨询、AIGC 研究院、新创全产业链研发、职能部门四大主要功能板块，以及共享交流等多项服务配套设施。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;图片&quot; src=&quot;https://oscimg.oschina.net/oscnet/c47eab1f72d8ad1810b556a2b4fdca59.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0; text-align:center&quot;&gt;智创未来园区效果图&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;依托朱辛庄街区新一代信息技术产业发展的良好势头，中软国际智创未来园区落地后，将与区域领军企业及上下游生态链企业形成创新互动的发展格局，同时联动区域&lt;span&gt;主要高校资源，为高质量 IT 人才&lt;/span&gt;&lt;span&gt;培养服务提供有力支撑保障，&lt;/span&gt;&lt;span&gt;通过创新协同、产业赋能、产学研融合助力未来科学城西区朱辛庄区域，打造具有国际影响力和带动力的数字经济发展高地。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#222222; margin-left:0; margin-right:0&quot;&gt;接下来，未来科学城集团将继续做好地块出让后的各项服务工作及配套市政道路建设，为项目建设和企业发展提供基础要素保障，&lt;span&gt;助力未来科学城加快构建智能制造发展生态，为&lt;/span&gt;&lt;span&gt;打造昌平数字经济示范新高地做出更多贡献&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;图片&quot; src=&quot;https://oscimg.oschina.net/oscnet/fbb5c3bd1894d8c4bdbf9177136744c3.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300344</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300344</guid>
            <pubDate>Thu, 04 Jul 2024 05:42:50 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>deepin UOS AI 如何配置自定义模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;科技飞速发展的今天，操作系统作为计算机系统的灵魂，其每一次的更新与变革都牵动着无数用户的心弦。近日，开源操作系统 deepin 迎来了一次重大更新，这次更新不仅在性能上进行了全面优化，更在 AI 智能化方面迈出了划时代的步伐：内置 AI 助理，并成功兼容多个千亿级大模型，为用户带来了前所未有的智能操作体验。&lt;/p&gt; 
&lt;p&gt;为了让 deepin 和 UOS AI 变得更开放、更强大，支持更多的大模型，我们开放了 UOS AI 的模型接入接口，所有 OpenAI 接口格式的大模型均可以接入到 UOS AI，你可以根据自身需求，自行接入自己喜欢的大模型，让 UOS AI 成为更个性化的智能伙伴。为了让更多用户了解如何配置专属模型，本篇文章将详细介绍：&lt;/p&gt; 
&lt;p&gt;1. UOS AI 如何接入在线模型（例如月之暗面和智谱）&lt;/p&gt; 
&lt;p&gt;2. UOS AI 如何接入本地模型（例如使用 Ollama 运行本地模型）&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;UOS AI 如何接入在线模型&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;目前，UOS AI 1.3.0 版已在 deepin V23 RC2 应用商店发布，新版支持用户添加自定义模型。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;接入条件&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;UOS AI 的自定义模型的接口规范为 OpenAI 的/v1/chat/completions。因此只有提供了 OpenAI 兼容接口的模型服务才可以被添加到 UOS AI 中使用。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;接入在线模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;接下来介绍在线模型的添加方式：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;一、&lt;/strong&gt;&lt;strong&gt;月之暗面&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;1：&lt;/strong&gt;&lt;strong&gt;获取 API&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;打开月之暗面的 API 说明，获取：模型名称和 Domain（请求地址）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.moonshot.cn%2Fdocs%2Fapi%2Fchat%23api-%25E8%25AF%25B4%25E6%2598%258E&quot; target=&quot;_blank&quot;&gt;https://platform.moonshot.cn/docs/api/chat#api-%E8%AF%B4%E6%98%8E&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;500&quot; src=&quot;https://oscimg.oschina.net/oscnet/1.png&quot; width=&quot;750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;请求地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi.moonshot.cn%2Fv1%2Fchat%2Fcompletions&quot; target=&quot;_blank&quot;&gt;https://api.moonshot.cn/v1/chat/completions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;模型名称：moonshot-v1-8k&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tips：UOS AI 会在请求地址中自动添加/chat/completions，因此这里填入的地址需要在月之暗面的地址去掉/chat/completions 部分。实际填入为：https://api.moonshot.cn/v1&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;2：&lt;/strong&gt;&lt;strong&gt;获取 API Key&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;登录月之暗面控制枱：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.moonshot.cn%2Fconsole%2Fapi-keys&quot; target=&quot;_blank&quot;&gt;https://platform.moonshot.cn/console/api-keys&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;进入【API Key 管理】，点击右侧「创建」按钮，生成 API Key：&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;607&quot; src=&quot;https://oscimg.oschina.net/oscnet/2.png&quot; width=&quot;787&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在此界面复制生成的密钥。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;3：&lt;/strong&gt;&lt;strong&gt;UOS AI 添加模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入 UOS AI 设置界面，添加模型。在模型添加界面的模型选项中切换为「自定义」。然后填入以下信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API Key：在 API Key 栏粘贴上步复制的密钥&lt;/li&gt; 
 &lt;li&gt;账号名称：任意填写&lt;/li&gt; 
 &lt;li&gt;模型名称：填入第一步中月之暗面 API 声明的模型名称：moonshot-v1-8k&lt;/li&gt; 
 &lt;li&gt;请求地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fapi.moonshot.cn%2Fv1&quot; target=&quot;_blank&quot;&gt;https://api.moonshot.cn/v1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;最终的填写效果是：&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;613&quot; src=&quot;https://oscimg.oschina.net/oscnet/3.png&quot; width=&quot;733&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;点击确认，完成校验后即可在对话窗口中使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;二、&lt;strong&gt;智谱&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;1：&lt;/strong&gt;&lt;strong&gt;获取 API&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入智谱 AI 开发平台，查询模型 API：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen.bigmodel.cn%2Fdev%2Fapi%23glm-4&quot; target=&quot;_blank&quot;&gt;https://open.bigmodel.cn/dev/api#glm-4&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;847&quot; src=&quot;https://oscimg.oschina.net/oscnet/4.png&quot; width=&quot;641&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;请求地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen.bigmodel.cn%2Fapi%2Fpaas%2Fv4%2Fchat%2Fcompletions&quot; target=&quot;_blank&quot;&gt;https://open.bigmodel.cn/api/paas/v4/chat/completions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;模型名称：glm-4&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;2：&lt;/strong&gt;&lt;strong&gt;获取 API Key&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入智谱《API keys》界面：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen.bigmodel.cn%2Fusercenter%2Fapikeys&quot; target=&quot;_blank&quot;&gt;https://open.bigmodel.cn/usercenter/apikeys&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;276&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111055.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;点击右侧《添加新的 API key》按钮，并在生成的新 key 后点击复制按钮。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;321&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111110.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;strong&gt;3：&lt;/strong&gt;&lt;strong&gt;UOS AI 添加模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;进入 UOS AI 设置界面，添加模型，在模型添加界面的模型选项中切换为「自定义」。然后填入以下信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;API Key：在 API Key 栏粘贴上步复制的密钥&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;账号名称：任意填写&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型名称：填入智谱模型的模型名称：glm-4&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;请求地址：UOS AI 会在请求地址中自动添加 /chat/completions，因此这里填入的地址需要在智谱的地址去掉 /chat/completions 部分。实际填入的为：&lt;strong&gt;https://open.bigmodel.cn/api/paas/v4&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;442&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111117.jpg&quot; width=&quot;528&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;点击确认，完成校验后即可在对话窗口中使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;三、&lt;/strong&gt;&lt;strong&gt;其他模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;其他兼容 OpenAI API 接口的在线模型皆可用以上方法接入。&lt;/p&gt; 
&lt;p&gt;下面为部分大模型厂商的 API 说明：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;百川：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.baichuan-ai.com%2Fdocs%2Fapi&quot; target=&quot;_blank&quot;&gt;https://platform.baichuan-ai.com/docs/api&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通义千问：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fdashscope%2Fdeveloper-reference%2Fcompatibility-of-openai-with-dashscope&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;零一万物：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.lingyiwanwu.com%2Fdocs%23api-%25E5%25B9%25B3%25E5%258F%25B0&quot; target=&quot;_blank&quot;&gt;https://platform.lingyiwanwu.com/docs#api-%E5%B9%B3%E5%8F%B0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deepseek：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.deepseek.com%2Fapi-docs%2Fzh-cn%2F&quot; target=&quot;_blank&quot;&gt;https://platform.deepseek.com/api-docs/zh-cn/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;UOS AI 如何接入本地模型&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Ollama 是一个开源的大语言模型本地部署工具，通过它可以方便的在本机部署开源大模型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;01：安装&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ollama 仓库地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Follama%2Follama&quot; target=&quot;_blank&quot;&gt;https://github.com/ollama/ollama&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;按照教程在 deepin V23 中安装 ollama 程序。执行以下命令，直接安装 ollama。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;u&gt;&lt;em&gt;curl -fsSL https://ollama.com/install.sh | sh&lt;/em&gt;&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tips：编译安装、Docker 安装请参阅 Github 中说明。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;327&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111121.jpg&quot; width=&quot;991&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;ollama 服务地址：127.0.0.1:11434&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02：运行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;安装完成后在终端运行模型，如 Qwen2 的 7B 模型：&lt;em&gt;&lt;u&gt;&lt;strong&gt;ollama run qwen2:7b&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;模型第一次运行会自动下载，根据网络情况需要等待一会儿。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;50&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111148.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03：模型仓库&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ollama 模型仓库：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2Flibrary&quot; target=&quot;_blank&quot;&gt;https://ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;870&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111159.jpg&quot; width=&quot;1000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;可根据自身需要选择模型。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;538&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111206.jpg&quot; width=&quot;883&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;04：UOS AI 配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Ollama 启动模型后，即可在 UOS AI 中添加该模型。&lt;/p&gt; 
&lt;p&gt;① 进入 UOS AI 的模型添加界面，选择模型类型为自定义。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;443&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111212.jpg&quot; width=&quot;527&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;②账号名称：根据需要随意填写。&lt;/p&gt; 
&lt;p&gt;③API Key：Ollama 未开启鉴权，可以随意填写。&lt;/p&gt; 
&lt;p&gt;④模型名：填写 Ollama 运行的模型名称，如前文运行的是 qwen2:7b，那么这里就填 qwen2:7b。&lt;/p&gt; 
&lt;p&gt;⑤模型请求地址：&lt;/p&gt; 
&lt;p&gt;Ollama 默认服务地址为&lt;code&gt;127.0.0.1:11434&lt;/code&gt;，&lt;/p&gt; 
&lt;p&gt;其 OpenAI 的兼容接口为&lt;code&gt;http://127.0.0.1:11434/v1/chat/completions&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;因此在 UOS AI 中只需填入：&lt;code&gt;http://127.0.0.1:11434/v1&lt;/code&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;444&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111218.jpg&quot; width=&quot;527&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;完成添加后即可在 UOS AI 中与本地模型对话。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;840&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240704111223.jpg&quot; width=&quot;933&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;目前，deepin UOS AI 已覆盖 90% 主流开源大模型与 AI 框架，随着模型接口的开放，用户将在 UOS AI 中体验到更多优秀的国内外大模型。未来，deepin 将持续探索大模型与 AI 原生应用，自然语言交互兼容性，数据安全性等多个技术点，推动人工智能与基础软件融合，为产业发展带来革命性变化。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;附录：&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;（1）deepin 历史版本镜像（含 deepin V15）：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdistrowatch.com%2Findex.php%3Fdistribution%3Ddeepin&quot; target=&quot;_blank&quot;&gt;https://distrowatch.com/index.php?distribution=deepin&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）UOS AI 打通全局智能搜索&lt;/strong&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fuos-ai-gets-a-major-upgrade%2F&quot; target=&quot;_blank&quot;&gt;https://www.deepin.org/zh/uos-ai-gets-a-major-upgrade/&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300330</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300330</guid>
            <pubDate>Thu, 04 Jul 2024 03:31:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Visual Studio Code 1.91 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Visual Studio Code 1.91 已&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，具体更新内容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_source-control&quot; target=&quot;_blank&quot;&gt;预览：Incoming/Outgoing changes 图表&lt;/a&gt;&amp;nbsp;- 在源代码控制视图中可视化 incoming 和 outgoing changes。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以通过&lt;code&gt;scm.experimental.showHistoryGraph&lt;/code&gt;设置新的可视化功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;322&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ffeb33488be03dcd3da701fa21bdde8395.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_python&quot; target=&quot;_blank&quot;&gt;Python 环境&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;推出一款新工具 python-environment-tools ，旨在显著提高检测全局 Python 安装和 Python 虚拟环境的速度。该工具使用 Rust 来确保快速、准确的发现过程。&lt;/p&gt; 
&lt;p&gt;项目团队&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;正在测试这项新功能，并将其与现有支持并行运行，以评估 Python 扩展中的新发现性能。用户将可以看到一个名为&lt;/span&gt;&lt;code&gt;Python Locator&lt;/code&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;的新日志通道，以显示使用这一新工具的发现时间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;可&lt;/span&gt;访问&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fpython-environment-tools&quot; target=&quot;_blank&quot;&gt;python-environment-tools repo&lt;/a&gt;&amp;nbsp;了解有关此功能和正在进行的工作的更多信息。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_smart-send-in-native-repl&quot; target=&quot;_blank&quot;&gt;Smart Send in native REPL&lt;/a&gt;&amp;nbsp;- 在&amp;nbsp;native&amp;nbsp;REPL 中流畅运行代码块。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;现在，Shift+Enter 可在非嵌套场景中发送最少的可执行代码，或在嵌套场景中发送 highest top-level 代码块。这使用户能够在整个文件中快速按住&amp;nbsp; Shift+Enter，以最少的努力运行最大数量的可执行代码。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_chat-and-language-model-api&quot; target=&quot;_blank&quot;&gt;GitHub Copilot 可扩展性&lt;/a&gt;&amp;nbsp;- VS Code Stable 中可用的聊天和语言模型 API。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;聊天和语言模型 API&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;现已在 VS Code 稳定版中完全可用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_profiles-editor-preview&quot; target=&quot;_blank&quot;&gt;预览：Profiles Editor&lt;/a&gt;&amp;nbsp;- 在一个地方管理你的个人资料。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;推出了新的&quot;Profiles Editor&quot;，使用户能够从一个地方管理配置文件。这种体验包括创建新的配置文件、编辑和删除现有配置文件，以及导入和导出配置文件与他人共享。创建新的配置文件时，你可以预览配置文件，并在保存前根据需要进行自定义。通过预案编辑器，还可以使用特定预案打开新窗口，或将预案设置为新窗口的默认预案。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;287&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60320abecffa319c60ae4828872548d0e8d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_access-file-extensions-in-custom-labels&quot; target=&quot;_blank&quot;&gt;自定义选项卡标签&lt;/a&gt;&amp;nbsp;- 更多变量选项并支持多种扩展。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${filename}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;editor&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${extname}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;test.ts&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${extname(0)}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ts&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${extname(1)}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;test&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${extname(-1)}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;test&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${extname(-2)}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;=&amp;gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;ts&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_syntax-checking-for-regular-expressions&quot; target=&quot;_blank&quot;&gt;TypeScript 5.5&lt;/a&gt;&amp;nbsp;- 正则表达式语法检查及其他语言功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;206&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ebd8c77df7497f4d4ab60d431783a1cc48.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;190&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39e24123375bfa77a8d04f3a584f98cf5f0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91%23_javascript-debugger&quot; target=&quot;_blank&quot;&gt;JavaScript Debugger&lt;/a&gt;&amp;nbsp;- 在调试 JavaScript 时检查隐藏变量。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;241&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4975d9ac3aefcd73ea2179c4641627c5d54.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;更多详情可&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fupdates%2Fv1_91&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300318/vs-code-1-91-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300318/vs-code-1-91-released</guid>
            <pubDate>Thu, 04 Jul 2024 02:39:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>StarRocks 3.3 发布，Lakehouse 架构发展进入快车道</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                            
                                                                                            &lt;p&gt;StarRocks 3.3 的发布标志着 Lakehouse 架构在数据分析领域迈向了一个新的高度。作为下一代 Lakehouse 架构的代表，StarRocks 3.3 在稳定性、计算性能、缓存设计、物化视图、存储优化和 Lakehouse 生态系统等方面进行了全方位的优化和创新。本文将逐一介绍 StarRocks 3.3 的这些新特性，带你深入了解这款强大的数据分析工具如何提升你的数据处理效率和分析能力。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;成熟稳定：全面提升的成熟度级别和大查询稳定性&lt;/h2&gt; 
&lt;p&gt;为了帮助用户更好地理解和使用新功能，StarRocks 3.3 对各项新特性进行了成熟度级别的划分，并采用了更清晰的标记体系：Experimental（实验性质）、Preview（公测阶段）和 GA（生产可用）。这种分级体系使用户能够根据功能的成熟度来决定是否在生产环境中使用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Experimental&lt;/strong&gt; &lt;strong&gt;（实验性质）&lt;/strong&gt; ：这些功能的接口可能会变动，甚至可能被调整或放弃，部分刚合入社区的代码覆盖率尚未达到标准的功能也会先放入这一类别。此类功能需要用户手动打开或主动调用，不会影响其他功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preview&lt;/strong&gt; &lt;strong&gt;（公测阶段）&lt;/strong&gt; ：接口基本稳定，但部分参数的语义可能会有微调。可以在非核心场景下使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GA（Gerneal available）&lt;/strong&gt; ：接口和功能已经明确，虽然还会有一些功能补充，但已有功能基本不会修改，完全达到生产可用状态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，为了进一步提升用户体验，我们针对数据湖分析、存算分离和物化视图等关键功能提供了更完整的产品能力边界和版本对照文档，方便用户理解和使用。&lt;/p&gt; 
&lt;p&gt;StarRocks 3.3 针对大查询、数据压缩和数据湖场景的内存占用进行了显著优化。通过 GA 级别的算子落盘能力（Spill to Disk），有效地优化了复杂查询的内存占用和 Spill 调度，确保大查询能够稳定执行而不会导致内存溢出（OOM）。此外，支持 Colocate Group Execution，通过分阶段执行 Colocated 表上的查询，大幅降低 Join 和 Agg 算子在执行时的内存占用，从而显著提升大查询的稳定性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;性能提升：新架构，新台阶，新场景&lt;/h2&gt; 
&lt;p&gt;StarRocks 3.3 的发布不仅提升了基础性能，更在真实场景中的性能优化上迈上了新台阶。我们不仅仅拘泥于 Benchmark 测试的成绩，而是专注于在实际应用中的性能提升。&lt;/p&gt; 
&lt;p&gt;首先，在新架构性能优化方面，StarRocks 对 ARM 架构进行了大幅优化，相比 x86 平均成本降低 20%，同时查询性能提升 20%，使其成为与 x86 架构同等重要的一等公民。 &lt;strong&gt;在&lt;/strong&gt; &lt;strong&gt;AWS&lt;/strong&gt; &lt;strong&gt;Graviton&lt;/strong&gt; &lt;strong&gt;实例上的测试中，ARM&lt;/strong&gt; &lt;strong&gt;架构的性能提升显著：在&lt;/strong&gt; &lt;strong&gt;SSB&lt;/strong&gt; &lt;strong&gt;100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;11%；在 Clickbench&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;39%；在&lt;/strong&gt; &lt;strong&gt;TPCH&lt;/strong&gt; &lt;strong&gt;100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;13%；在&lt;/strong&gt; &lt;strong&gt;TPCDS 100G&lt;/strong&gt; &lt;strong&gt;测试中，ARM&lt;/strong&gt; &lt;strong&gt;比&lt;/strong&gt; &lt;strong&gt;x86&lt;/strong&gt; &lt;strong&gt;快&lt;/strong&gt; &lt;strong&gt;35%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/6f431e49c495d4a442d2c379231e2dff.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在数据湖性能优化方面，StarRocks 3.3 提升了 Scan 性能，通过对 Page Index 的优化显著减少了 Scan 的数据规模，降低了 Page 多读的情况。此外，元数据性能也有了突破，显著提升了整体的处理效率。&lt;/p&gt; 
&lt;p&gt;针对特定场景的性能提升，StarRocks 3.3 进行了多方面的优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;倒排索引和 ngram 索引的增强显著提升了模糊搜索的效率；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FlatJson 对半结构化数据的处理性能也得到了百倍的显著提升，自动加速了 JSON 查询，使其性能接近结构化数据，同时保持了灵活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Bitmap 优化不仅提升了 Bitmap 系列函数的性能和内存占用，还补充了 Bitmap 导出到 Hive 的能力，以及相应的 Hive Bitmap UDF。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CodeGen 技术显著提升了复杂表达式的计算效率，而重构后的向量化正则表达匹配也大幅降低了 regexp_replace 函数的 CPU 消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;为了应对数据倾斜问题，StarRocks 3.3 增加了外表统计信息中的直方图统计，使得在数据倾斜情况下能生成更准确的执行计划，并优化了数据倾斜时的 Shuffle Join 操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;此外，全局字典的优化提供了字典对象，可以在各个 BE 节点内存中存储字典表的键值对映射关系通过 dictionary_get() 函数直接查询维度值，相对于原先通过 JOIN 维度表获取维度值的方式，查询效率更高。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;缓存设计：&lt;/strong&gt; Lakehouse 架构的最后一块拼图&lt;/h2&gt; 
&lt;p&gt;在 Lakehouse 架构中，缓存设计是实现高效数据处理的关键一环。对于存算分离架构来说，缓存的重要性不言而喻。无论是 Hive、Iceberg、Paimon 等外表，还是 StarRocks 存算分离的内表，缓存命中率的高低直接影响性能的优劣。在缓存命中情况下，性能已经能够追平存算一体的架构，但如何合理、稳定地将热数据保存在缓存中却是一大挑战。&lt;/p&gt; 
&lt;p&gt;StarRocks 原生开发的缓存功能为用户提供了开箱即用的便捷体验。无需复杂的配置，用户即可利用强大的缓存机制提升数据处理性能。StarRocks 3.3 通过一系列创新功能显著提升了缓存的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;预热缓存：&lt;/strong&gt; 通过 cache warmup 命令，可以预先将关键数据加载到缓存中，减少首次查询的延迟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;缓存优先级&lt;/strong&gt; &lt;strong&gt;：3.3.1 推出将 cache select 设置较高的缓存优先级，确保最重要的数据得到优先缓存。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;内存优化和可观测性：&lt;/strong&gt; 缓存的内存优化和可观测性的提升，使得缓存的管理和监控更加高效和透明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/102dc83c8bbc29f9256aa5d73d250b28.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在存算分离集群中，StarRocks 3.3 还适配了 AWS Express One Zone Storage，大幅提升了读写性能，为未来的全局缓存带来了全新的可能性。&lt;/p&gt; 
&lt;p&gt;此外，在缓存无法命中或者不希望使用缓存的场景下，冷查性能也得到了显著提升。主要通过优化 tablet 的并行扫描，以及对小 I/O 的自动合并，使得即使在没有缓存支持的情况下，查询性能依然表现优异。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;物化视图：连接湖仓的高效纽带&lt;/h2&gt; 
&lt;p&gt;物化视图作为 StarRocks 的核心能力，也是连接 Open lake format 和 StarRocks 内表的纽带。通过外表物化视图，可以透明地为数据湖上的查询进行加速，在保证 single source of truth 的同时，降低数据加工的复杂度。&lt;/p&gt; 
&lt;p&gt;在 3.3 版本中，我们又进一步做了一些重要优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;外表物化视图的进一步能力增强：&lt;/strong&gt; Iceberg 外表物化视图支持分区级别增量刷新，并可在分区方式为 Hidden Partition 的表上创建物化视图。Paimon 外表物化视图补全了改写能力，也支持了分区级别的增量刷新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;更完善的透明改写能力:&lt;/strong&gt; StarRocks 3.3 支持了基于&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fquery_rewrite_with_materialized_views%2F%23%25E5%259F%25BA%25E4%25BA%258E%25E6%2596%2587%25E6%259C%25AC%25E7%259A%2584%25E7%2589%25A9%25E5%258C%2596%25E8%25A7%2586%25E5%259B%25BE%25E6%2594%25B9%25E5%2586%2599&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;文本&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fquery_rewrite_with_materialized_views%2F%23%25E5%259F%25BA%25E4%25BA%258E%25E8%25A7%2586%25E5%259B%25BE%25E7%259A%2584%25E7%2589%25A9%25E5%258C%2596%25E8%25A7%2586%25E5%259B%25BE%25E6%259F%25A5%25E8%25AF%25A2%25E6%2594%25B9%25E5%2586%2599&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;视图&lt;/a&gt;的物化视图改写。 除了原来标准 SJPG 的改写能力之外，基于视图的 MV 改写可以把针对视图的查询改写到对等的物化视图上，适用于建模和指标平台等场景。针对文本的改写能力能对一些非标准 SQL 片段进行文本匹配，解决复杂查询难以透明改写的问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/d9870de8786781218576f435cd86d564.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.starrocks.io%2Fzh%2Fdocs%2Fusing_starrocks%2Fcreate_partitioned_materialized_view%2F%23%25E5%25A4%259A%25E5%259F%25BA%25E8%25A1%25A8%25E5%25AF%25B9%25E9%25BD%2590%25E5%2588%2586%25E5%258C%25BA&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;多事实表分区刷新&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;优化&lt;/strong&gt; &lt;strong&gt;：&lt;/strong&gt; 此前，物化视图的分区刷新策略仅支持单个事实表增量刷新策略（即当物化视图的分区列和一个 base 表的分区列一致场景下，物化视图的刷新会根据 base 表的分区来进行变更），3.3 版本新增的多事实表对齐策略，可以降低多事实表关联场景下的物化视图刷新开销。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/ef61f7a23590325fb150ca4bb0929afd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增改写策略（Transparent MV）：&lt;/strong&gt; 此前，物化视图的改写主要是把针对 base 表的查询改写到物化视图上，通过开启物化视图属性 &lt;code&gt;transparent_mv_rewrite_mode&lt;/code&gt; 后，当用户直接查询物化视图时，StarRocks 会自动改写查询，将已经刷新的物化视图分区中的数据和未刷新分区对应的原始数据做自动 Union 合并。 &lt;strong&gt;此模式允许配置&lt;/strong&gt; &lt;strong&gt;在&lt;/strong&gt; &lt;strong&gt;MV&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong&gt;base&lt;/strong&gt; &lt;strong&gt;表数据不一致时的改写行为，实现在数据时效性和查询性能之间的权衡，&lt;/strong&gt; &lt;strong&gt;适用于&lt;/strong&gt; &lt;strong&gt;分层建模场景。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;开启物化视图属性 &lt;code&gt;transparent_mv_rewrite_mode&lt;/code&gt; 后，当用户直接查询物化视图时，StarRocks 会自动改写查询，将已经刷新的物化视图分区中的数据和未刷新分区对应的原始数据做自动 Union 合并。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;大规模物化视图调度能力优化&lt;/strong&gt; &lt;strong&gt;：&lt;/strong&gt; 增加 &lt;code&gt;enable_query_rewrite&lt;/code&gt; 属性，实现对查询改写的禁用，减少计划开销。通过控制候选物化视图数量，并引入更高效的筛选算法，增加物化视图计划缓存（MV plan cache）。支持全局 FIFO 调度，优化嵌套物化视图的级联刷新策略。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;存储优化：更高效易用的数据管理&lt;/h2&gt; 
&lt;p&gt;StarRocks 3.3 在存储优化与易用性提升方面做出了诸多改进，进一步增强了系统的性能和用户体验。&lt;/p&gt; 
&lt;p&gt;首先，StarRocks 3.3 提升了 FE 的可观测性和锁机制优化。提供了详细的内存使用指标，让用户可以更好地管理和监控资源。同时，引入了锁管理器（Lock Manager），实现对元数据锁的集中管理，将元数据锁的粒度从库级别细化为表级别。 &lt;strong&gt;这种细化显著提高了导入和查询的并发性能，在&lt;/strong&gt; &lt;strong&gt;100&lt;/strong&gt; &lt;strong&gt;并发的导入场景下，导入耗时减少了&lt;/strong&gt; &lt;strong&gt;35%。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了增强建表语句的清晰度，StarRocks 3.3 支持了 ORDER BY 语法，使得建表操作更加直观和简洁。此外，还增加了对重命名列（Rename Column）的支持（版本 3.3.1），进一步提升了数据管理的灵活性。&lt;/p&gt; 
&lt;p&gt;在存储效率方面，StarRocks 3.3 优化了非字符串标量类型数据的存储方式，存储空间下降了 12%。这不仅降低了存储成本，也提升了数据读取的效率。&lt;/p&gt; 
&lt;p&gt;针对主键表，StarRocks 3.3 实施了多项优化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PK Index 存算分离支持 Remote Storage&lt;/strong&gt; ：主键索引落盘支持落至远程存储，提高了数据的灵活性和可扩展性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主键表支持 Size-tiered Compaction 策略&lt;/strong&gt; ：这一策略降低了执行 Compaction 时的写 I/O 和内存开销，适用于存算分离和存算一体的集群。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化主键表持久化索引的读&lt;/strong&gt; &lt;strong&gt;I/O&lt;/strong&gt; ：支持按照更小的粒度页读取持久化索引，并改进了持久化索引的 Bloom Filter。这一优化也适用于存算分离和存算一体的集群。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;生态支持：Lakehouse 扩展与集成&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hive&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：在 3.3 版本中，StarRocks 支持对 ORC 和 Text 文件的写入能力。 &lt;strong&gt;单 sink 算子的写入性能达到了&lt;/strong&gt; &lt;strong&gt;Trino&lt;/strong&gt; &lt;strong&gt;的 2 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Iceberg&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：StarRocks 3.3 大幅重构了 Iceberg 元数据查询模块，通过分布式元数据读取提升对 Avro 格式文件的解析性能，避免原生 SDK 的单点瓶颈，对小规模的元数据通过 manifest 缓存来降低重复 I/O，从而大幅提升了 Iceberg 的元数据访问性能。同时，增加了对 V2 表 equality delete 的支持，使用户能够高效分析使用 Flink 写入的 Iceberg upsert 数据。此外，还引入了对 Iceberg 视图（Iceberg View）的查询支持，使得数据管理和查询更加便捷和直观。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paimon&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：StarRocks 3.3 现已全面支持 Paimon 生态系统，包括对最新的 delete vector 的支持、Paimon 系统表的集成以及 scan range 调度的优化。通过这些改进，用户可以更高效地管理和查询 Paimon 中的数据，实现更灵活的数据处理和分析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ClickHouse&lt;/strong&gt; &lt;strong&gt;和&lt;/strong&gt; &lt;strong&gt;Kudu&lt;/strong&gt; &lt;strong&gt;生态支持&lt;/strong&gt; ：为了方便用户从 Clickhouse 迁移到 StarRocks，社区贡献了专用的迁移工具，使得数据迁移过程更加平滑和高效。此外，StarRocks 还支持 ClickHouse 和 Kudu 的 Catalog 功能，使得用户可以更便捷地在这两种数据库和 StarRocks 之间进行数据管理和查询。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;总结：成熟的 Lakehouse 架构&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/5c2afac696c2b1b599e0e9a1cd12a28c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;StarRocks 正在积极向成熟的湖仓架构升级，不仅增强了与开放湖格式的兼容性，还显著提升了湖的写入性能。在数仓功能上，它进一步加强了索引和半结构化数据处理的性能，同时，存算分离架构成为更受青睐的成熟解决方案。&lt;/p&gt; 
&lt;p&gt;此外，大查询和 ETL 任务的稳定性的提高，为批处理的能力打下基础。这些进步共同推动了 StarRocks 向一套架构,满足所有的分析需求的&quot;One data, All Analytics&quot;愿景的迈进。&lt;/p&gt; 
&lt;p&gt;更详细的 feature 介绍参考：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Release note：&lt;/strong&gt; https://docs.mirrorship.cn/zh/releasenotes/release-3.3/&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;下载：&lt;/strong&gt; https://www.mirrorship.cn/zh-CN/download/starrocks&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播回放&lt;/strong&gt; ：https://www.bilibili.com/video/BV1F7421d72D/&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;更多交流，联系我们：https://wx.focussend.com/weComLink/mobileQrCodeLink/33412/2b42f&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/5658056/blog/11324522</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5658056/blog/11324522</guid>
            <pubDate>Thu, 04 Jul 2024 02:37:03 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>微软开源基于图的 RAG 系统：GraphRAG</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微软开源了基于图的 RAG 工具&amp;nbsp;GraphRAG，可以在私有或以前未见过的数据集上进行问题解答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a2d1fbdf72b6b9f58eeb679d3360d24e59f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GraphRAG 通过创建知识图谱来增强模型的推理和生成性能，使用 LLM GPT-4 对 GraphRAG 和传统 RAG 进行评估， GraphRAG 在全面性和多样性方面优于传统 RAG。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;与使用纯文本片段的简单语义搜索不同，GraphRAG 从原始文本中提取知识图谱、构建知识模块结构、生成摘要，帮助大模型更好地捕捉文本中的复杂联系和交互，来增强其生成、检索等能力。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f08afb8bbd2294705f2ef5d3a5b7a66de51.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GraphRAG 使用大型语言模型从任何文本文档集合中自动提取丰富的知识图谱。这种基于图的数据索引最令人兴奋的功能之一是，它能够在用户查询之前报告数据的语义结构。它以分层方式检测密集连接节点的 &quot;社区&quot;，在从高级主题到低级主题的多个层次对图进行分割。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc9ea26402073487e8e96f4e084fbe4e4d7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;使用 LLM 对这些社区中的每一个进行总结，就能创建数据的分层总结，从而提供数据集的概览，而无需事先知道要问哪些问题。每个社区都是描述其实体及其关系的社区摘要的基础。&lt;/p&gt; 
&lt;p&gt;这种方法尤其适合回答全局性问题。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fgraphrag&quot; target=&quot;_blank&quot;&gt;GitHub 仓库&lt;/a&gt;&amp;nbsp;|&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmicrosoft.github.io%2Fgraphrag%2F&quot; target=&quot;_blank&quot;&gt;文档&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300313</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300313</guid>
            <pubDate>Thu, 04 Jul 2024 02:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>过去十年中国生成式 AI 专利申请量居全球第一</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;世界知识产权组织发布《生成式人工智能专利态势报告》显示，2014 年至 2023 年，中国发明人申请的生成式人工智能专利数量最多，远超美国、韩国、日本和印度等国。2014 年至 2023 年，全球生成式人工智能相关的发明申请量达 54000 件，其中超过 25% 是在去年一年出现的。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;301&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9c6e8bed8d0a88e64612aadd9436dac8297.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;生成式人工智能允许用户创建文本、图像、音乐和计算机代码等内容，为一系列工业和消费产品提供动力。2014 年至 2023 年间，中国的生成式人工智能发明超过 3.8 万件，是排名第二的美国的 6 倍。&lt;/p&gt; 
&lt;p&gt;专利数量前十名公司、机构依次为腾讯、平安保险、百度、中国科学院、IBM、阿里巴巴、三星电子、Alphabet、字节跳动、微软。&lt;/p&gt; 
&lt;p&gt;报告显示，生成式人工智能已遍及生命科学、制造、交通、安全和电信等行业。图像和视频数据在生成式人工智能专利中占主导地位，其次是文本和语音/音乐，分子、基因和蛋白质数据的生成式人工智能专利增长迅速。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300311</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300311</guid>
            <pubDate>Thu, 04 Jul 2024 02:12:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>AI 技术创新可以有多硬核？ GOTC 2024 论坛议程抢先看</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                            
                                                                                            &lt;p&gt;8 月 15 日至 16 日，GOTC 2024 将在上海张江科学会堂盛大开启。GOTC 2024 与上海浦东软件园联合举办，并结合 &lt;span style=&quot;color:#d83931&quot;&gt;「&lt;/span&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;strong&gt;GOTC（全球开源技术峰会）&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#d83931&quot;&gt;」&lt;/span&gt; 与 &lt;span style=&quot;color:#d83931&quot;&gt;「&lt;/span&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;strong&gt;GOGC（全球开源极客嘉年华）&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#d83931&quot;&gt;」&lt;/span&gt;，旨在打造一场全新的开源盛会。2024 全球开源极客嘉年华（GOGC 2024）由浦东软件园携手 S 创共建，与开放原子开源基金会、开源中国、Linux 基金会等品牌联合呈现。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;此次大会包含&lt;strong&gt;全球开源人才及教育论坛、LLMOps &lt;/strong&gt;&lt;strong&gt;最佳实践&lt;/strong&gt;&lt;strong&gt;、硬核 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 技术创新与实践、AI Workshop：&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;开发者实操营、开源数据库与 AI 协同创新、云原生与&lt;/strong&gt;&lt;strong&gt;微服务架构&lt;/strong&gt;&lt;strong&gt;、多模态大模型的应用与实践等多个平行论坛，&lt;/strong&gt;将集结全球范围内对开源技术充满热情的开发者、社区成员、创业者、企业领袖、媒体人，以及各开源项目应用场景的产业精英、跨界才俊与年轻力量。通过主题演讲、圆桌讨论、创新集市、人才集市、黑客松、技术展示和互动工作坊等形式，与会者将有机会交流实践经验、探索前沿技术，一起激发创新活力、展示开源魅力、促进跨领域合作。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;450&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f10c7e2bd8836c39853182895e4f2bdec49.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;其中，「硬核 &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 技术创新与实践」论坛将于 8 月 16 日举行。&lt;/strong&gt;该论坛聚焦 AI 领域的技术创新与实践，旨在搭建一个极客开发者交流的平台，不仅强调理论研究的重要性，更注重实践操作的广泛性，鼓励极客精神的探索与追求。&lt;/p&gt; 
&lt;p&gt;届时，一众行业领军人物将分享各自在 AI 领域的真知灼见与实战经验，深入探讨 AI 技术的未来趋势与应用场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;论坛主席由盛派网络创始人兼首席架构师苏震巍担任。&lt;/strong&gt;苏震巍是香港理工大学 AI 及软件系统架构方向的博士生，同时也是微软 RD/MVP，微软技术俱乐部（苏州）主席，著有《微信开发深度解析》《网站模块化开发全程实录》等书。苏震巍将在论坛上以「Senparc.AI + AutoGen 打造自动进化和高可用的 AI Agents 系统」为主题发表演讲，深入剖析如何利用先进的 AI 技术和自动化工具，构建能够自我进化且具有高度可用性的 AI 代理系统，为与会者呈现 AI 技术的前沿应用案例。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3bb83ad1a23a7a3e4cf338bb31d819df36b.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;盛派网络创始人兼首席架构师苏震巍&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TorchV 联合创始人&amp;amp;&lt;/strong&gt;&lt;strong&gt;CTO&lt;/strong&gt;&lt;strong&gt; 肖玉民（八一菜刀）&lt;/strong&gt;将带来主题演讲：「非结构化数据解析 &amp;amp; GenAI 的应用探索和实践」。凭借其在技术架构、微服务、开源框架方面的深厚造诣，以及对 RAG/向量搜索/非结构化数据解析等领域的专注研究，肖玉民将分享如何有效处理复杂数据，以及如何将生成式 AI 技术应用于实际场景中，推动数据解析技术的革新。值得一提的是，肖玉民还是开源中国 GVP 项目 Knife4j 的作者。 Knife4j 是一个为 Java MVC 框架集成 Swagger 生成 Api 文档的增强解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jina &lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 高级算法工程师付杰&lt;/strong&gt;将围绕「Jina AI 如何通过 reranker 优化搜索结果」这一主题展开论述。拥有北京交通大学和加州大学圣地亚哥分校电子工程专业背景的付杰，曾在腾讯科技负责视频号搜索业务，对多模态、跨模态场景下的搜索问题有着深刻理解。他将分享 Jina AI 在搜索算法优化方面的创新实践，以及如何通过 reranker 提升搜索结果的准确性和用户体验。&lt;/p&gt; 
&lt;p&gt;想自己动手开发 AI 玩具，从哪里开始？&lt;strong&gt;FoloToy 联合创始人王乐&lt;/strong&gt;将分享自己改造火火兔那些事，讲述如何将 AI 技术融入玩具设计，赋予传统玩具智能化特性，让与会者领略 AI 技术在娱乐教育领域的创造力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;字节跳动 Cloud &lt;/strong&gt;&lt;strong&gt;IDE&lt;/strong&gt;&lt;strong&gt; 产品负责人王海建&lt;/strong&gt;将围绕「AI 重构 IDE 开发环境」这一话题展开探讨。王海建在开发者工具领域深耕多年，对于 AI 技术如何重塑集成开发环境（IDE），如何提升开发效率，以及 AI 在软件开发流程中的应用前景等话题有着独到的见解， 期待此次演讲能够激发更多关于未来开发工具和流程创新的思考与讨论。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;229&quot; src=&quot;https://oscimg.oschina.net/oscnet/.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本次论坛不仅是一次技术交流的盛会，更是 AI 技术与创新思维碰撞的舞台。期待与您一同见证这些行业大咖带来的精彩分享，共同探索 AI 技术的无限可能！ GOTC 2024 &lt;strong&gt;报名通道现已开启，诚邀全球各技术领域开源爱好者共襄盛举！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;参会报名，请访问：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F8762568606000%3Ftd%3D6895280870225&quot; rel=&quot;nofollow&quot;&gt;https://www.huodongxing.com/event/8762568606000?td=6895280870225&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;更多大会信息，访问官网查看：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://gotc.oschina.net/&quot; rel=&quot;nofollow&quot;&gt;https://gotc.oschina.net&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/3859945/blog/11333769</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/11333769</guid>
            <pubDate>Thu, 04 Jul 2024 02:05:08 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>共建系列 | openKylin 走进浦东软件园交流活动成功举办</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;7 月 3 日，为进一步增进社区合作伙伴间的友好交流及合作探讨，&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;openKylin 社区共建系列之走进上海浦东软件园&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;交流活动成功召开。来自&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;color:var(--weui-LINK)&quot;&gt;赛昉科技&lt;/span&gt;&lt;span&gt;、上海具身多模、上海宽睿信息&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;等近&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;20&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;家企业参会代表共聚上海浦软，介绍了当前企业产品和技术创新等方面的最新成果，并围绕社区发展建设、行业数字化转型等话题展开了深入交流和沟通。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-15fe71691b8d7a3b0fa50128def3c6fb599.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海浦东软件园股份公司副总经理何育浩&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;出席活动并发表致辞，上海浦东软件园将致力于推动开源生态进一步集聚，欢迎更多园区企业及生态伙伴参与到 openKylin 社区中，为共建开源生态贡献力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8de133a7b95510455c961b2546b4d3d5b5.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;openKylin 社区副秘书长刘敏&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;带来《openKylin 根社区建设进展介绍》主题分享，向与会伙伴介绍了社区的基本情况、治理模式、开源趋势及社区取得的相关成果。目前，已有超&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;500&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;家伙伴加入社区，涵盖了基础软件、CPU、GPU、整机、应用软件、人工智能等产业链上下游企业以及各层次高等院校，与 openKylin 社区开展了共同技术创新、生态适配、应用商店上架、预装集成等多种形式的合作，未来，openKylin 社区将持续发挥平台作用，共探推动操作系统技术创新发展和生态繁荣建设。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-afc163d888c218e38969b86af8806fd564a.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;赛昉科技 RVspace 社区负责人董家绮&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;以《赛昉科技携手 openKylin 社区共建 RISC-V 生态》为主题，介绍了 RISC-V 首例一站式用户体验中心—RVspace 以及赛昉科技与 openKylin 社区在生态建设等方面的合作创新成果。截至目前，赛昉科技各硬件平台全面适配 openKylin，包括 VisionFive 2、ROMA 笔记本、&lt;/span&gt;&lt;span style=&quot;color:var(--weui-LINK)&quot;&gt;工控机&lt;/span&gt;&lt;span&gt;&lt;span&gt;等，并推动基于 RISC-V 的 openKylin 应用爆发，适配了&lt;/span&gt;&lt;span style=&quot;color:var(--weui-LINK)&quot;&gt;Libreoffice&lt;/span&gt;&lt;span&gt;、浏览器、影音播放等常用软件，满足用户日常使用需求。未来，赛昉科技将与社区持续开展丰富的生态合作，推动 RISC-V 产业生态创新发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-44e39f1b6b5375a41116b148614072f8a52.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海具身多模智能科技有限公司创始人、CEO 王文艺&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;带来《VT-TRANSFORMER，一种低成本国产开源小型化 MXN 多模态 AI 计算框架》主题分享，围绕具身 AI 计算的关键挑战、具身 AI 的开源计算框架-VT-Transformer 以及云锦 OS 具身 AI 大脑开源解决方案等方面进行介绍。当前，AI 正加速走向大模型+设备的具身智能应用，上海具身多模在加入 openKylin 后，将成立具身 AI SIG，与社区进行深入合作，助力社区智能化发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-dde42e1465148339f3095fe640c5b882421.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海浦东软件园产业发展中心 GOGC 活动内容负责人郝亮&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;为大家介绍了 GOGC 2024 活动，2024 全球开源极客嘉年华（GOGC &amp;nbsp;2024）由浦东软件园携手 S 创共建，与&lt;/span&gt;&lt;span style=&quot;color:var(--weui-LINK)&quot;&gt;开放原子开源基金会&lt;/span&gt;&lt;span&gt;，开源中国社区，The Linux Foundation 等品牌合作，旨在为开源领域相关的开发者、社区、创业者、企业、媒体以及各开源项目应用场景的产业方、跨界人士打造一个基于社区与志愿者共建，轻松有趣、丰富多彩的活动。届时，openKylin 社区也将出席 GOGC 2024，与大家共话开源。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;853&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0cc0c1d23827aa3a790336bab4d07b0c99d.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在讨论环节，各企业代表基于社区平台及开源协作模式，探讨未来伙伴间更多维度、更深层次合作方向，并针对如何共同推动开源技术在各行业中的应用和创新，分享了各自的见解和建议。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;726&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5fdcad52844f40fb23ca26afbb19578d33c.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;openKylin 作为我国领先的&lt;/span&gt;&lt;span style=&quot;color:var(--weui-LINK)&quot;&gt;开源操作系统&lt;/span&gt;&lt;span&gt;根社区，持续聚焦开源操作系统根技术，积极推进生态建设广度和技术创新深度。通过本次走进上海浦东软件园交流活动，不仅加深了 openKylin 社区与各企业间的联系，也为大家提供一个深入了解 openKylin 最新发展动态、共同交流分享经验、拓展合作领域的平台。未来，openKylin 将致力于为广大伙伴搭建共享、协作的平台，持续推动更多的行业合作和技术创新，为开源生态的发展贡献更多力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300302</guid>
            <pubDate>Thu, 04 Jul 2024 01:48:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源日报 | 微软开源 GraphRAG；AI 不仅仅是大模型；开源语音模型接近人类水平；中国寻求人类「开源」新方式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.3&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300123/fedora-41-drop-python-2-7&quot; target=&quot;news&quot;&gt;Fedora 41 要和 Python 2.7 说再见&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;红帽工程师 Miro Hrončok 提交了一份变更提案，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FFedora-41-Drop-Python-2.7&quot; target=&quot;_blank&quot;&gt;建议&lt;/a&gt;在 Fedora 41 中退役 Python 2.7，并放弃仍然依赖 Python 2 的软件包。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b14e9c1fd3c69f5f136f53bae787b2d94a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Python 2 已于 2020 年 1 月 1 日退出生命周期，CentOS 7 也已退出生命周期，RHEL 8 的 Python 2.7 应用程序支持也将退出，红帽开发人员认为现在是时候从 Fedora 中移除 Python 2.7 软件包了。除了 PyPy 之外，Fedora 将不再支持 Python 2。&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300177/microsoft-wsl2-linux-6-6-kernel&quot; target=&quot;news&quot;&gt;微软 WSL2 过渡至 Linux 6.6 LTS 内核&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;一直以来，微软 Windows Subsystem for Linux 2（WSL2）的内核使用的都是 Linux 5.15 LTS 内核。现如今，它终于从那个已经老化了的 LTS 版本升级到了当前的 Linux 6.6 LTS 系列。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;397&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-564d96ab18eb53f8060557958f2de09b382.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;日前发布的 linux-msft-wsl-6.6.36.3 内核是第一个使用 Linux 6.6.36 作为基础的 WSL2 内核。除了升级内核版本外，还对 x86_64/ARM64 内核配置进行了修改，包括支持可加载模块。&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/news/300140&quot; target=&quot;news&quot;&gt;科技巨头的开源 AI 模型是「假开源」&lt;/a&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;《Nature》的一篇报道指出，很多科技巨头宣称他们的 AI 模型是开源的，但实际上并不完全透明。这些模型的数据和训练方法往往没有公开，这种做法被称为 「开源洗白」，严重妨碍了科学研究的可复现性和创新。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;研究发现，在资源有限的情况下，小公司和研究团队往往能做到更加透明和开放。&lt;strong&gt;真正的开源应该包括代码、数据和训练方法的全面公开&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F3894431038%2FOlOM6kF7r&quot; target=&quot;_blank&quot;&gt;微软基于图的检索增强型生成（RAG）系统，GraphRAG，开源了！&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;GraphRAG 通过创建知识图谱来增强模型的推理和生成性能，使用 LLM GPT-4 对 GraphRAG 和传统 RAG 进行评估， GraphRAG 在全面性和多样性方面优于传统 RAG。&lt;/p&gt; 
&lt;p&gt;与使用纯文本片段的简单语义搜索不同，GraphRAG 从原始文本中提取知识图谱、构建知识模块结构、生成摘要，帮助大模型更好地捕捉文本中的复杂联系和交互，来增强其生成、检索等能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3ef81277362295696d71ace6ab96c90e38.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F6105753431%2FOlQrA1YLa&quot; target=&quot;_blank&quot;&gt;开源语音模型接近人类水平&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;Fish Speech 是一款已经开源的文本到语音（TTS）模型。&lt;/p&gt; 
    &lt;p&gt;这个模型使用了三语数据进行训练，经过约 15 万小时语音数据的锤炼，Fish Speech 的语音处理能力已接近人类水平，并且可以完美支持中英日文三种语言，目前它在 Github 上的标星数已达 2.9k！&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style=&quot;text-align:right&quot;&gt;
   - 微博&amp;nbsp;
   &lt;strong&gt;量子位&lt;/strong&gt;
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1727858283%2FOlFJfloSS%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;腾讯的多智能体翻译工具免费在线试用&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;腾讯的多智能体翻译工具已经可以免费在线试用了，而且是使用的 GPT-4 的 API，你可以上传 txt 或者 pdf 文件，然后会自动帮你翻译，并且整个过程都可以从右边的 Chatbox 看到。&lt;/p&gt; 
    &lt;p&gt;注意上传后要手动选一下目标语言。使用地址：transagents.ai&amp;nbsp;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博 &lt;strong&gt;宝玉 xp&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240703A03N5400&quot; target=&quot;_blank&quot;&gt;对话腾讯汤道生：AI 不仅仅是大模型&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;过去 1 年，腾讯集团高层间，新增了一个重要的企业微信群聊。腾讯公司董事会主席兼 CEO 马化腾、总裁刘炽平、高级执行副总裁卢山和汤道生等，悉数进入该群。这个群专门针对大模型技术变革，用于分享和讨论最新前沿并跟进业务进展。&lt;/p&gt; 
   &lt;p&gt;很多人说，对大模型，腾讯「不着急」。对此，汤道生表达了不同看法：「着急啊。我们在群里经常讨论，不能说不着急。」&lt;/p&gt; 
   &lt;p&gt;在汤道生看来，对于腾讯这样体量的公司，资源上必须确保投入和跟进，做「类 OpenAI」的研究与研发；但同时也要保持清醒，「不要把 AI 等同于大模型，要看得更全面」。&lt;/p&gt; 
   &lt;p&gt;「不是只有做大模型的玩家才是做 AI。这就等于认为，只有做手机的企业才在移动时代重要，是很狭隘的。」他说。&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;-&amp;nbsp;&lt;strong&gt;腾讯新闻《潜望》&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7394656718%2FOlPca5NDb%3Frefer_flag%3D1001030103_&quot; target=&quot;_blank&quot;&gt;结合开源图片与相关视频，天龙三这事大概能明晰了&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt;
   火箭箭体及试车从设计到最后试车方案签字，中间理应经过多个部门间的协同与数次复查相关结构件的强度与设计的合理性，但离谱的是在此过程中竟无一人能发现这个如此低级又如此致命的错误，实在是令人汗颜。
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;归零工作室 RTZT&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.com.cn%2Farticle_1733360754_6750fc72020019nni.html&quot; target=&quot;_blank&quot;&gt;中国脑机接口发展提速：「机智」上新，从实验室走向市场&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#4d4f53; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;7 月 1 日，工业和信息化部就《脑机接口标准化技术委员会筹建方案》（下称《方案》）公示征求公众意见，以推动脑机接口技术发展。此举说明我国脑机接口技术标准的制定有望提速。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;一财网&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn802905831&quot; target=&quot;_blank&quot;&gt;爱奇艺限制投屏案落槌，算计用户不能「层层叠 buff」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#222222; margin-left:0px; margin-right:0px; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;事实一再证明，吃相难看，势必难堪；积极解「套」，才有未来。会员花式加价并非解决长视频平台营收可持续增长的长久之道，靠不断降低用户体验感来增加营收与利润，只能是竭泽而渔。靠修改规则来收割老用户，终究是搬起石头砸自己的脚。只有以用户为中心，提高内容质量、提升服务体验，视频平台才能走得更远。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;上游新闻&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F36kr.com%2Fp%2F2845991663455104&quot; target=&quot;_blank&quot;&gt;大模型吞了谁？程序员彷徨，产品经理消失&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#262626&quot;&gt;大模型呼啸而至，互联网已经很久没有经历这样的技术冲击了。互联网时代的技术岗打工人，和前线大模型公司，这两块拼图要完全吻合，难度超乎想象。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;36 氪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn802782620&quot; target=&quot;_blank&quot;&gt;太空探索，中国寻求人类「开源」新方式&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;中国正在西方式现代化道路外另辟蹊径，走中国特色的和平、绿色、可持续发展的现代化道路，并积极寻求另一种「开源」方式——外太空探索，来突破地球资源上限，与各国共享发展红利。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;环球时报新媒体&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240702A07QJP00&quot; target=&quot;_blank&quot;&gt;码农们的 AI 焦虑：交 15 万元上班，不卷就被「毕业」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;但现阶段，社会普遍对 AI 产生了深刻焦虑，大学报志愿时，大家都会思考一个问题：什么专业以后不会被 AI 替代。有人说，正是职业焦虑让张雪峰们动辄上万元的高考志愿填报咨询火了。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;程序员抢到了互联网爆发的红利，毕业几年就能拿到 50 万甚至上百万的年薪，一度触发了「文转码」的职业潮流，但如今，最怕被 AI 抢了「金饭碗」的人群也正是码农们，他们因此而「卷」。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;IT 时报&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Fjjxw%2F2024-07-02%2Fdoc-incatvrm7392936.shtml&quot; target=&quot;_blank&quot;&gt;成为巨头的「烦恼」，英伟达将在法国面临反垄断指控&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除 CUDA 外，英伟达的其他护城河也面临对手挑战。此前据多家媒体报道，AMD、英特尔、谷歌、微软、博通、思科、Meta 等企业已组建了 UALink（Ultra Accelerator Link）联盟，旨在对抗英伟达另一项硬件互联技术 NVLink。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;界面新闻&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzA3NzMxNTI1MQ%3D%3D%26mid%3D2649776267%26idx%3D1%26sn%3D5a01dddf21afd75c12ffec0c50d40c4c%26scene%3D0&quot; target=&quot;_blank&quot;&gt;谁卡了 OpenAI 的脖子？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px&quot;&gt;当前 OpenAI 遭遇了「卡脖子」风波：一方面谷歌、亚马逊、Meta 以及其合作伙伴英伟达等总市值超过 8.7 万亿美元（约合人民币 63.3 万亿元）的科技巨头对 AI 大模型领先地位「虎视眈眈」，借助自身流量和资本等优势强势加入赛道，促使美国 AI 市场竞争愈加激烈；另一面，OpenAI 自身也遭遇「滑铁卢」，推出的 GPT-4o 语音助手功能测试时间不断推迟。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;strong&gt;钛媒体 AGI&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzombodb%2Fzombodb&quot; target=&quot;_blank&quot;&gt;zombodb/zombodb&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-359ee77b063d42a6f985f0bd8cd367e0543.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fzombodb%2Fzombodb&quot; target=&quot;_blank&quot;&gt;https://github.com/zombodb/zombodb&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;ZomboDB 通过使用 Elasticsearch 作为索引类型，为 Postgres 带来了强大的文本搜索和分析功能。其全面的查询语言和 SQL 函数支持以新颖和创造性的方式来查询你的关系数据。&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/5783135/blog/11214188&quot; target=&quot;_blank&quot;&gt;把飞书云文档变成 HTML 邮件：问题挑战与解决历程&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;要被邮件客户端识别，飞书云文档内容需要转译成 HtmlEmail 格式，该格式为了兼容各种版本的邮箱客户端（特别是 Windows Outlook），对于现代 HTML5 和 CSS3 的很多特性是不支持的，飞书云文档的多种富文本块格式都需要转译，且部分格式完全不支持，造成编辑和预览发送不一致的情况。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;1.jpg&quot; height=&quot;268&quot; src=&quot;https://oscimg.oschina.net/oscnet/1_1719212121522.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fv4CMA5qOo0Cc-NTCz2mdTw&quot; target=&quot;_blank&quot;&gt;完全开源的现代化 IDE 正式发布：支持云端和桌面、兼容 VS Code 扩展、全球最大开源基金会打造&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：所以他比 VS Code 好在哪里？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：号称完全开源&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：eclipse，曾经多么辉煌的呀&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：我先来，套壳 vsc&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：ide 换来换去有毛用，代码写的垃圾依旧垃圾&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：这玩意不会又是个 Electron 吧？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：完全兼容 vsc 扩展，你说呢&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：很好，vscode 有竞争对手了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：现在是 Debian 下 eclipse+vscode+kate，后面是不是可以 eclipse 全家桶了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：有 idea 要它干嘛？支持 AI 编程助手&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：所以为什么不用 codium 呢&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：已经在用了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：很好！但是我放不下自己 DIY 后的 vim，吹上天都没用&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：之前看 vitis 新 ide 风格像 vscode，以为 xilinx 也转向 vscode，结果是 eclipse 的新玩意&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：vscode 的浏览器版本，除了微软自己用的以外，功能基本都是残血的，托管过的都知道。 所以有个新的挺好的。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 16：完全兼容 vsc，目前好像并不是，连 jdp 的实现 Java debugger 都没兼容上。Java Debugger 的 github 仓库上有相关 issue 最扯的是你标假快捷键是啥意思，样子产品。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 17：所有云端的 web IDE，纯粹是前端卷得没地卷了，强行把 CICD 绑到了一起搞出来的 kpi 项目。始终理解不了用它们图啥。如果一定要个牵强的理由：我们能 ai 自动补全，但我想用个高端一点的好理由来收你的钱。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 18：它能开发 java 微服务大型项目吗？曾经是了 vs 跑 java 微服务，根本跑不起来&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FCaDizPfk0-5b1n2JJTn7pg&quot; target=&quot;_blank&quot;&gt;科技巨头的开源 AI 模型是「假开源」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：早就对此感到奇怪了... 作为一个开源软件，至少能让用户自己编译（ai 这里应该是训练）一个相同的软件（模型）吧，但是很多所谓的开源模型只是给出了一个可商用的预训练模型而没有给训练集以及相关的代码，这和闭源的免费软件好像也没什么区别...&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：OpenAI 啥时候改名叫 ClosedAI&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：其它好说，数据基本上就别想了，除了护城河，还可能有版权问题&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：这是哪个无耻之徒说出来的？人家都请你吃饭，把锅打开，递给你饭碗，难道还要给你喂饭？算法、算力、数据，人家不可能把三样全部都给你的，尤其是数据，要是连数据都给你，你岂不是第二天就立马选择自研？要点 B 脸不？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：在 Google 之后，社媒平台 Reddit 与 OpenAI 达成了内容协议，这一消息推动其股价上涨逾十分之一。根据该协议，OpenAI 将获得 Reddit 内容的访问权限，同时它将为 Reddit 提供 AI 驱动功能。和 Stack Overflow 类似，Reddit 的内容都是用户创造和管理的，它的高质量内容应该早就被 OpenAI 抓取并被用于训练大模型。OpenAI 等 AI 公司正面临来自众多版权所有者的诉讼，通过与 Reddit 等公司达成协议，AI 公司正试图合法化其训练数据。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300241</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300241</guid>
            <pubDate>Wed, 03 Jul 2024 11:55:14 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小明的代码</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ef873666dbb2393f4b9759e78fa47ec82f7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第一章 · 神之眷顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;灯火辉煌的都市背景下，隐藏着无数平凡而又微不足道的梦想。小明，一名普通的前端开发者，就在这座钢铁丛林中，在一家不起眼的初创公司里日复一日地敲打着键盘，为那些冰冷的网页赋予生命的色彩。他的办公室位于一栋老旧写字楼的顶层，窗外的风景尽是这座城市繁忙的呼吸，而他的世界，似乎只有这方寸屏幕内的代码。&lt;/p&gt; 
&lt;p&gt;夜已深沉，办公室的同事们都已陆续离开，只剩下小明还坚守在电脑前，与一个棘手的 BUG 奋战。屏幕发出的蓝光映照在他的脸上，显得格外专注而孤独。这段时期对小明充满着挑战，项目截止日期逼近，压力如影随形，但小明总是能从解决问题中找到一丝乐趣，那或许就是属于程序员独有的满足。&lt;/p&gt; 
&lt;p&gt;窗外突然雷声大作，一道闪电刺破长空，小明的编辑器内闪烁了一下，一行从未见过的代码自行出现在光标处。这行代码既不像 JavaScript，也不符合任何他所熟悉的编程语言，仿佛来自另一个维度的信息，带着不可名状的魔力。&lt;/p&gt; 
&lt;p&gt;小明下意识怀疑自己的眼睛，他揉了揉疲惫的双眼，确认这不是幻觉。好奇心驱使着他决定运行这段神秘代码。手指轻轻敲下回车键的瞬间，整个房间像是被一股无形的力量轻轻拂过，空气中的尘埃在光线下舞动，一切都静止了片刻。&lt;/p&gt; 
&lt;p&gt;当一切恢复正常时，小明的目光落在了边角那盆久被忽视的仙人掌上。原本干枯的叶片竟奇迹般地恢复了生机，一抹鲜绿在夜色中显得格外耀眼，仿佛时间倒流，生命再次绽放。小明震惊地站起身，难以置信地环顾四周。&lt;/p&gt; 
&lt;p&gt;小明意识到自己触碰到了某种未知的边界，他被赋予了超越常理的能力——通过编程语言，直接干预现实世界。这是一种前所未有的力量。&lt;/p&gt; 
&lt;p&gt;起初，小明小心翼翼地实验着自己的新能力。他修复了家中损坏的电器，让街角那盏长期失修的路灯重新亮起，甚至帮助邻居家的小狗找回了丢失的项圈。每一次成功，都让他心中涌动着难以言喻的喜悦与成就感，仿佛自己成了现实世界的守护者，默默守护着这片小小的天地。&lt;/p&gt; 
&lt;p&gt;然而随着时间的推移，小明逐渐明白这份力量的意义远不止于此。他开始观察到城市中那些被忽略的角落，那些因贫富差距、权力滥用而产生的不公。他看到了在华丽的霓虹之下，那些生活在阴影中的人们，他们的无助与绝望。&lt;/p&gt; 
&lt;p&gt;一个念头在他心中悄然生根发芽——如果编程可以改变物质世界，那么为什么不能用来矫正这个被金钱扭曲的社会呢？小明开始计划，用他的能力去帮助那些最需要帮助的人，让正义和善良的光芒穿透黑暗，照亮每一个角落。&lt;/p&gt; 
&lt;p&gt;小明的代码不再仅仅是为了修复或创造，而是为了唤醒沉睡在人们心中的那份纯真与良善。他匿名资助贫困学生，帮助失去工作的人们找到新的机会，甚至间接揭露了足球界的几起腐败事件，让正义得以伸张。&lt;/p&gt; 
&lt;p&gt;小明深知这份力量既是神之眷顾，也是一把双刃剑。他必须谨慎使用，避免引起不必要的混乱或被有心人利用。他开始自学法律、伦理学，试图在每一次行动之前，都能做出最正确的判断。&lt;/p&gt; 
&lt;p&gt;魔幻就这样照进了现实，小明从一个默默无闻的程序员，渐渐成长为一位幕后英雄，他的故事虽未被人知晓，但那些由他带来的细微变化，正如同春风化雨，悄然滋润着这座城市，以及生活在这里每一个人的心田。而这一切的起点，不过是一个寻常夜晚，一行神秘代码的悄然降临。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-10f5a0f25339dbf1d97a275a90dc8feeab0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第二章&lt;/strong&gt;&amp;nbsp;·&amp;nbsp;&lt;strong&gt;暗流涌动&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;小明此时并不知道，都市的另一头，还潜藏着一股不为人知的暗流。幽然集团，这座庞然大物，犹如一只无形的手，悄无声息地操纵着城市的脉络。它的势力触及每一个领域，善用人性的弱点编织出一张密不透风的网。在集团内部，两位核心人物——墨也与糜林，各自扮演着关键角色，一明一暗，共同推进着幽然集团的各项议程。&lt;/p&gt; 
&lt;p&gt;墨也，以金融为武器，通过资本运作操控市场，使得财富与资源集中于少数人手中，进一步加剧了社会的贫富分化。而糜林，则是精神腐蚀的大师，他通过媒体、娱乐业和教育系统，传播着物质至上的价值观，让越来越多的人沉迷于浮华表象，忘记了内心深处的纯真与追求。&lt;/p&gt; 
&lt;p&gt;幽然，作为集团的神秘领袖，他的身影始终笼罩在一层迷雾之中，无人得见其真容。但他的意志却如影随形，影响着每一个角落。当小明的超能力逐渐显现，影响范围不断扩大，幽然敏锐地捕捉到了这一丝不同寻常的气息。对于一个企图控制全人类的人来说，小明的存在对幽然无疑是一颗定时炸弹，他的能力不仅能够颠覆现有的秩序，更是对幽然个人权威的挑战。&lt;/p&gt; 
&lt;p&gt;为了应对，幽然启动了「织梦者」计划，这是一项集高科技与心理战术于一体的秘密行动。他招募了全球顶尖的黑客与心理学家，组成了一支精英团队，他们每个人都怀揣着对权力的渴望，愿意为幽然集团的宏图伟业贡献自己的才智。团队的任务只有一个：接近小明，了解并掌握他的能力，最终将其转化为幽然手中的利刃。&lt;/p&gt; 
&lt;p&gt;「织梦者」行动的第一个阶段，是通过网络空间布下陷阱。黑客们利用高超的技术，制造了一系列看似随机实则每一环都精心设计的网络事件，旨在吸引小明的注意，并诱使其出手干预。从虚拟货币市场的异常波动，到公益网站遭受攻击，每一起事件背后，都有幽然集团的黑手在推动。&lt;/p&gt; 
&lt;p&gt;幽然集团的心理学家们则根据小明的行为模式，设计了一套复杂的心理诱导策略。他们在网络上散布关于超自然现象的讨论，引导公众舆论，营造出一种对超能力者的崇拜与恐惧并存的氛围。这些精心策划的心理战术，目的就是要让小明在不知不觉中暴露自己的情感倾向、行为习惯，甚至是能力的局限性。&lt;/p&gt; 
&lt;p&gt;作为被赋予超能力的人，小明自然也不是易于摆布之辈。随着一系列事件的发酵，他开始察觉到背后似乎有一只看不见的手在操控着一切。每当他尝试修复一个漏洞，解决一个问题，总会有更多的麻烦接踵而至，这让他不得不开始反思自己的行为是否已经引起了另一股力量的关注。小明开始更加谨慎地运用自己的能力。&lt;/p&gt; 
&lt;p&gt;一天夜里，小明面前的屏幕闪烁着各种数据分析，他紧锁眉头，指尖在键盘上跳跃，试图从海量信息中寻找那条隐秘的线索。就在此时，一封匿名邮件突兀地出现在了他的收件箱，邮件中附有一段加密视频，画面中出现了一位戴着面具的人，声称自己是「织梦者」计划的一员，因为良知的驱使，以及对小明能力的仰慕，决定向小明透露一些关键信息。&lt;/p&gt; 
&lt;p&gt;视频中的声音低沉而有力：「小明，你拥有改变世界的力量，但你并不孤单。幽然集团正对你虎视眈眈，他们的计划比你想象的还要深远。我愿意成为你的引路人，帮你揭开‘织梦者’的面纱，但你必须小心，一旦踏入这场游戏，就没有回头路。」&lt;/p&gt; 
&lt;p&gt;小明凝视着屏幕，心中五味杂陈。他知道，接受这份帮助意味着他将正式卷入一场暗流涌动的较量，但他也明白，逃避不是解决问题的方法。在正义与自我保护之间，小明选择了前者，他按下回复键，发送了一个简单的词语：「开始！」&lt;/p&gt; 
&lt;p&gt;随着这一决定的作出，小明的战斗似乎不再是单枪匹马，而是与那些同样渴望光明、抵御压迫的匿名英雄并肩作战。暗流涌动之下，一场光与暗的较量悄然拉开序幕。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-899208e7cc7fbd3618c2fc49bdd827c938b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第三章&lt;/strong&gt;&amp;nbsp;·&amp;nbsp;&lt;strong&gt;凤之相遇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;小明的超能力很快也引起了一位女子的注意，她叫小凤，才华横溢的设计师，正用她独特的视角观察着这个世界。她以艺术为媒介，试图唤醒人们沉睡的灵魂，而她的真实身份同样不凡，作为上一个被神选中的人，与小明同属于「神之眷」。她的存在，如同一缕清风，温柔地拂过这混沌的世界，带来一丝丝清新与希望。&lt;/p&gt; 
&lt;p&gt;设计不仅是小凤的职业，更是她与世界对话的方式。她擅长捕捉生活中的微小细节，将其转化为富有深意的设计作品，而这一切，都源自她那颗纯净而又充满力量的心。她深知自己肩负着与小明相似的使命，那就是引领人类回归正轨，对抗那股让社会日益腐化的阴暗力量。&lt;/p&gt; 
&lt;p&gt;为了结识小明，小凤利用超能力设计了一场与小明的偶遇。那是一家弥漫着咖啡香的小店，阳光透过落地窗洒在小凤精心布置的场景上，每一个细节都充满了诗意。当小明推门而入，两人的目光在那一刻交汇，时间仿佛静止，万物失色。他们之间没有过多的言语，只是一次眼神的交流，便已心照不宣，如同两块等候千年的磁铁，在一刹那相吸。&lt;/p&gt; 
&lt;p&gt;小凤成为了小明背后默默的支持者，她的设计不仅美化了物理世界，更通过一种特殊的方式，与小明的意识世界建立起桥梁。每当夜深人静，小凤会用她的画笔，在画布上勾勒出一幅幅充满正能量的图景，这些图景在无形中注入小明的意识，为他提供灵感与力量。小明的能力在小凤的影响下，变得更加精准和高效，他们如同双星闪耀，照亮了人类社会前行的道路。&lt;/p&gt; 
&lt;p&gt;两个不平凡的人度过了一段平凡的爱情时光， 一天，小明在整理房间的时候，偶然间发现，那些在关键时刻激发他潜能的图像，竟然都是出自小凤之手。当他带着疑惑询问小凤时，小凤温柔一笑，终于揭开了自己隐藏的身份。「小明，我也是‘神之眷’。」她轻声说道，「我们都是被选中的守护者，肩负着相同的使命。」&lt;/p&gt; 
&lt;p&gt;小凤继续讲述，她的超能力源自于一个自称赤兔的神秘者，赤兔从未现身，只以声音和意识的方式与她沟通，传授给她关于「神之眷」的秘密，以及如何利用自己的超能力为世界带来正面影响。赤兔告诉她，每当人类社会陷入迷茫与堕落，宇宙间便会出现一股正义的力量，寄宿于某个灵魂之中，以引导人类回归正道。小凤意识到，小明就是这一代的被选者，而她将是他的同伴和指引者。&lt;/p&gt; 
&lt;p&gt;得知真相的小明，与小凤之间的联系更加紧密，他们不仅是彼此的爱人，更是并肩作战的伙伴。在他们的共同努力下，社会开始显现出微妙的变化，人们逐渐意识到精神世界的空虚，开始反思和追寻真正的价值所在。而在这场无声的战役中，小明与小凤的相遇，如同一道亮丽的风景线，证明了即使在最黑暗的时刻，光明与爱，也永远不会缺席。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ff977e13c6d99f1ffa94bf7300c1ddde64.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第四章&lt;/strong&gt;&amp;nbsp;·&amp;nbsp;&lt;strong&gt;幽然迷障&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;小明和小凤的结合，加速了幽然集团的布局。&lt;/p&gt; 
&lt;p&gt;春末夏初之夜，小明试图通过代码帮助偏远山区的孩子们建立一座虚拟与现实相通的图书馆，让他们也能享受到优质的教育资源。这原本是一个非常平常的善意的计划，却未曾想，这正是幽然集团精心铺设的陷阱。小明在构建图书馆的过程中，逐渐陷入了一个内藏玄机的数字迷障，它的存在，就是为了捕获像小明这样的「神之眷」。&lt;/p&gt; 
&lt;p&gt;小明突然发现，他的代码不再是他意志的延伸，而是被一股强大的外力所牵引，如同脱缰的野马，在虚拟世界中肆意狂奔。代码在现实中疯狂篡改，学校变成了工厂，图书馆化作游乐场，知识的殿堂转瞬成了欲望的丛林。社会的道德底线被一次次冲刷，人心更加迷茫，世界似乎滑向了一个不可逆转的深渊。&lt;/p&gt; 
&lt;p&gt;而小明的精神世界也被困在了一片由数据编织的虚拟牢笼中，时间在这里变得模糊，每一秒都像是永恒。周围充斥着冰冷的电子噪声，如同深海中的压力，每一次挣扎，都只是让这片黑暗更加深邃。但在这绝望之中，小明的心却愈发坚定，他知道自己不能倒下，必须找到出路。&lt;/p&gt; 
&lt;p&gt;小凤焦急万分。她尝试着用设计图穿透迷障，希望能像以往那样为小明指引方向，但这次，所有的努力都如同泡影，他们的超能力之桥，被幽然的迷障彻底斩断。小凤的眼泪滴落在画布上，化作一串串无助的符号，她知道，她必须找到另一种方法来拯救小明。&lt;/p&gt; 
&lt;p&gt;小凤沉下心来，聚焦于意识世界，是的，她正在向赤兔求助。此刻，小明的屏幕上突然闪烁起一行加密文字：「逃离，向东行。」这简短的提示仿佛一道光，瞬间照亮了他的心房。小明利用自己残存的超能力，同样编织了一层又一层的数字迷雾，掩盖了自己的行踪，如同一只夜行的猫，悄无声息地在幽然的迷障中穿梭。&lt;/p&gt; 
&lt;p&gt;清晨，小明站在窗前望向东方，那里，太阳正在缓缓升起，金色的光芒铺满了大地。他知道，这场战斗才刚刚开始。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce8bc7c85decab8d4602df50ea26acfac80.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第五章&lt;/strong&gt;&amp;nbsp;·&amp;nbsp;&lt;strong&gt;终极对决&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了防止小明再陷幽然迷障，赤兔通过与小凤的意识沟通，试图给小明传递更多的提示。&lt;/p&gt; 
&lt;p&gt;小明的思绪如同潮水般汹涌，从初识 HTML、CSS 的青涩时光，到后来驾驭 JavaScript 的自如，每一个代码片段都仿佛是他生命中的一块拼图，拼凑出他对这个世界独特的理解。而现在，他需要一块特殊的拼图，一块能够打开未知大门的钥匙。&lt;/p&gt; 
&lt;p&gt;在这份渴望中，一个几乎被遗忘的概念——「元编程」，在小明的脑海中复苏。这是一种超越常规的编程艺术，允许程序员用代码去创造或修改其他代码，就像一把可以塑造世界的魔法剑。&lt;/p&gt; 
&lt;p&gt;小明闭目凝神，心灵深处一片宁静。他仿佛置身于一个浩瀚的代码宇宙，周遭环绕着闪烁的字符，每一颗「星星」都蕴含着改变现实的力量。他开始默诵，那声音如同远古的电波，穿越时间的长河，唤醒了沉睡的知识。&lt;/p&gt; 
&lt;p&gt;手指在空中勾勒出无形的字符，那是构建逆向工程框架的蓝图，一个既非破坏也非创造，而是寻求平衡与和谐的构想。这框架旨在揭示隐藏的真理，寻找那条连接虚拟与现实的桥梁。&lt;/p&gt; 
&lt;p&gt;小明逐渐感觉到自己的心跳与周围的电子脉冲产生了共鸣，一股前所未有的力量在他体内觉醒。代码不再是简单的指令，它们化为光与影的交织，构建出一条通向现实世界的璀璨通道。小明掌握了这种力量，不再恐惧任何虚拟的枷锁，与小凤并肩，他们决定直捣幽然的老巢，终结这个侵蚀世界的邪恶力量。&lt;/p&gt; 
&lt;p&gt;决战之日，天空呈现出一种奇异的灰白。&lt;/p&gt; 
&lt;p&gt;墨也和糜林，幽然集团的两大护法，在小明的代码洪流下逐一消散，他们的身影在虚拟的风暴中扭曲、瓦解。&lt;/p&gt; 
&lt;p&gt;小明准备找到幽然，对他发出最后一击，幽然竟主动出现在了小明的面前，他向小明透露了一个惊人的秘密…&lt;/p&gt; 
&lt;p&gt;从幽然的话语中，小明得知，小凤的存在竟与幽然同源，均为至阴，且小凤的元神被幽然绑定，与之命理相系，虽一正一邪，却随幽然共生共存。这意味着，一旦幽然被消灭，小凤也会随之消逝。&lt;/p&gt; 
&lt;p&gt;小明一脸茫然，内心充满了疑惑、矛盾与挣扎，他看了看小凤，小凤只是一阵缓慢的点头，随后又叹了口气。在那一刻，她如释重负。&lt;/p&gt; 
&lt;p&gt;小明自然不愿意失去小凤，想到墨也和糜林两大罪恶已除，他决定放过幽然。&lt;/p&gt; 
&lt;p&gt;而就在此时，赤兔从小凤的意识世界穿透而出，仓促之间化作人形，他的眼神深邃，透露出不容置疑的决绝。&lt;/p&gt; 
&lt;p&gt;「若不此时铲除幽然，阴邪将再次滋生，这是小凤的宿命，也是你的选择。」赤兔的话语如锋利的刀刃，切割着小明的心。&lt;/p&gt; 
&lt;p&gt;小明再次在挣扎中翻腾，他无法接受这样的牺牲。就在他犹豫不决之际，小凤将自己的设计图，那张能够抹去幽然的设计图，强行注入小明的意识世界，并以爱的力量让小明做出了抉择。&lt;/p&gt; 
&lt;p&gt;一道刺眼的光芒划过，小凤与幽然同时消失了。&lt;/p&gt; 
&lt;p&gt;深深的哀伤与坚定呈现在了小明的脸上，此刻他明白，这是一场没有胜者的对决，小凤的牺牲是为了更大的正义，是为了一个不再受幽然阴影笼罩的世界。在废墟之上，他立下誓言，要用余生来守护小凤的光芒。&lt;/p&gt; 
&lt;p&gt;而至于赤兔，那个赋予「神之眷」力量的存在，也悄然隐去，回到了属于它的幽暗角落，守护着它的光明和那些不为人知的秘密。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8f6d54ef4716d56da00cfea646aa906ea12.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;strong&gt;第六章&lt;/strong&gt;&amp;nbsp;·&amp;nbsp;&lt;strong&gt;光明重生&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着幽然集团的轰然倒塌，如同一场暴风雨后的清晨，社会被洗涤得格外清新。城市的轮廓在晨曦中逐渐清晰，阳光温柔地洒在每一寸土地上，仿佛预示着一个新时代的开始。&lt;/p&gt; 
&lt;p&gt;人们在街头巷尾热议着这场突如其来的变革，而小明这个名字，尽管未被大众广为传颂，却如同一股潜流，悄悄地改变了河流的流向。&lt;/p&gt; 
&lt;p&gt;在小明的推动下，一场自下而上的社会运动悄然兴起。人们开始反思过往的贪婪与盲从，重拾那些被遗忘了许久的美德——诚实、公正、互助。曾经被金钱与权力遮蔽的双眼，如今逐渐睁开，渴望看见一个更加公平、透明的世界。小明的行动像是一粒火种，点燃了无数人心中的希望之火，这火焰虽微小，却足以照亮前行的道路。&lt;/p&gt; 
&lt;p&gt;后面发生的一些事，让小明最终选择了平凡。他拒绝了所有荣誉，在一座不起眼的小镇上，开设了一个科技工作室，专注于利用自己的技术为社区服务，尤其是那些长期被边缘化的群体。无论是帮助老人学习使用智能设备，还是为残疾人士开发便利的辅助软件，小明总能找到自己的方式，默默地为这个世界带来温暖。&lt;/p&gt; 
&lt;p&gt;随着时间流逝，小明发现自己的超能力正在逐渐减弱，直至最终消失。但他并未感到遗憾，相反，他意识到，真正的超能力，不是改变世界的技术，而是每个人心中那份永不熄灭的希望。&lt;/p&gt; 
&lt;p&gt;岁月悠悠，转眼数年过去。在一个温暖的黄昏，小镇的广场上聚集了几个年轻人，他们围坐在一位长者身旁，听他讲述过去的传奇故事。这位长者正是小明，他的面容已不再年轻，但眼中闪烁的光芒依旧明亮。他讲述的不仅仅是自己的经历，更是关于勇气、牺牲与爱的故事。每当有人询问他如何评价自己所做的一切时，小明总是微笑不语，只轻轻指向周围的人们，示意他们看看那些因希望而团结在一起的面孔。&lt;/p&gt; 
&lt;p&gt;故事在夕阳的余晖中缓缓落幕，但小明和他的代码，却如同一颗种子，深深地埋进了每一个向往光明的人的心田。这颗种子在阴暗潮湿的土壤中生根发芽，绽放出各式各样的花朵，装点着这个世界的每一个角落。&lt;/p&gt; 
&lt;p&gt;昼夜更替，四季轮回，周而复始…&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;《小明的代码》是一篇短篇小说，由江右贤与 AI 共同完成。江右贤提供了小说的核心思想和基本框架，及章节和情节的构思。AI 则负责编写具体场景、对话等内容。最后再由江右贤对整篇句式进行审阅和润色。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5n7bTI3RzW4vj39VmjoSXQ&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/5n7bTI3RzW4vj39VmjoSXQ&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/300238</link>
            <guid isPermaLink="false">https://www.oschina.net/news/300238</guid>
            <pubDate>Wed, 03 Jul 2024 11:41:36 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>