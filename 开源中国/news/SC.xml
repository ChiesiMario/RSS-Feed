<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 17 Apr 2025 07:37:41 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>IntelliJ IDEA 2025.1 现已发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IntelliJ IDEA 2025.1 现已发布。此版本的亮点包括全面支持 Java 24、引入 Kotlin Notebook 以及默认启用的 K2 模式。JetBrains AI 也进行了重大升级，将 AI Assistant 和 Junie 整合到一个订阅中。调试支持也更加强大，新增了暂停和恢复 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch evaluations&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;的选项。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;281&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6ae0e40b28c0cd39a5b26f67c3f6de9fd1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains AI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在此版本中，所有 JetBrains AI 功能均可在 IDE 中免费使用，部分功能（包括代码补全和本地模型支持）可无限使用，其他功能则需根据信用额度进行限制。还推出了全新的订阅系统，可根据需要轻松扩展 AI Pro 和 AI Ultimate 两个等级。此版本的亮点包括更智能的补全、高级上下文感知以及对 Claude 3.7 Sonnet 和 Gemini 2.0 Flash 的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;主要亮点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;2025.1 版本全面支持 Java 24 版本中的所有功能，确保用户在享受最新语言更新的同时获得流畅的体验。欲了解更多信息，可阅读此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F03%2Fjava-24-and-intellij-idea%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在此版本中，K2 模式默认启用，这标志着新版本在增强 IntelliJ IDEA 中 Kotlin 开发的代码分析、内存效率和整体性能方面迈出了重要的一步。活跃用户已经体验到了更流畅的工作流程，项目团队计划继续解决未解决的问题，改进重构和检查，并根据反馈进一步提升质量。了解更多信息，可阅读此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fk2-mode-in-intellij-idea-2025-1-current-state-and-faq%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;现在可以在调试期间暂停和恢复 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch evaluations&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以控制 &lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;watch computations&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;的潜在副作用。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kotlin Notebook 是专为 JVM 开发者打造的全新交互式环境，现已成为 IntelliJ IDEA 的内置功能。Kotlin Notebook 非常适合各种任务，从实时原型设计、演示、日志解析、文档编写，到深入的数据分析和可视化，应有尽有。欲了解更多信息，可阅读此&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fkotlin-notebook-arrives-in-intellij-idea%2F&quot; target=&quot;_blank&quot;&gt;博客文章&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fidea%2F2025%2F04%2Fintellij-idea-2025-1%2F&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/345039/jetbrains-ides-go-ai&quot; target=&quot;_blank&quot;&gt;JetBrains 宣布推出 AI 工具免费套餐&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345083/intellij-idea-2025-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345083/intellij-idea-2025-1-released</guid>
            <pubDate>Thu, 17 Apr 2025 06:49:12 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Spark on K8s 在 vivo 大数据平台的混部实战</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网大数据团队- Qin Yehai&lt;/p&gt; 
 &lt;p&gt;在离线混部可以提高整体的资源利用率，不过离线 Spark 任务部署到混部容器集群需要做一定的改造，本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、在离线业务差异&lt;/h1&gt; 
&lt;p&gt;互联网数据业务服务一般可以分为在线服务和离线任务两大类，在线服务是指那些长时间运行、随时响应对实时性要求高、负载压力随着接收流量起伏的服务，如电商、游戏等服务，离线任务是指运行周期短、可执行时间提交对实时性要求低、有一定容错性、负载压力基本可控的服务，如离线计算任务、模型训练等。一般在线服务在白天时段繁忙，离线任务在凌晨繁忙，两者的业务高峰期存在错峰现象，如果按传统方式在线和离线都是分别独立机器部署，业务高峰时期需要更多机器来支持，业务低峰期又存在部分机器空闲，整体资源利用率都不高。因此行业提出来在离线混部的解决方案，在线和离线业务通过混部系统部署在同一批机器，实现共享资源并错峰互补，提高整体的资源利用率。目前业内利用混部技术可以将数据中心的 CPU 利用率提升至 40% 左右，vivo 在 2023 年混部平台投入生产也已经将部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;混部系统需要有强大的隔离能力，绝大部分都是基于容器，所以混部的前提是在线和离线业务都容器化，对于容器管理工具如 K8s 来说是更适应于运行时间长、启停次数少、容器数量少的在线服务，在线服务也能比较容易地上容器，而对于运行时间短、启停频繁、容器数量大的离线任务，对 K8s 来说不是天然地适应，但容器化已是大势所趋，K8s 也推出了性能更好的调度器、用于离线任务的控制器，Spark 在 2.3 版本后也支持容器化，诸多技术的发展也推动离线任务实现容器化以及在离线混部的落地。&lt;/p&gt; 
&lt;p&gt;本文将从在离线混部中的离线任务的角度，讲述离线任务是如何进行容器化、平台上的离线任务如何平滑地提交到混部集群、离线任务在混部集群中如何调度的完整实现以及过程中的问题解决。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、离线任务容器化&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 Spark Operator 方案&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 方案对比&lt;/h3&gt; 
&lt;p&gt;vivo 离线任务大部分任务是以 Spark 作为执行引擎，Spark 任务运行在 K8s 上，目前业界有两种架构的方案：Spark on K8s 及 Yarn on K8s。两者部分优缺点对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//944f211eda9a472ce3e9c7cc7342579a.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark on K8s 是 Spark 容器化，由 K8s 直接创建 Driver 和 Executor 的 Pod 来运行 Spark 作业，Yarn on K8s 是 Yarn 的容器化，由 K8s 创建 RM 和 NM 的 Pod，Spark 的 Driver 和 Executor 运行在 NM Pod 的 container 中，正是由于两种架构方案的区别，它们各自也会存在优缺点。&lt;/p&gt; 
&lt;p&gt;Yarn on K8s 方案可以支持原生的 Hive、Spark、Flink 等引擎，它仅需要创建一定数量的 NodeManager Pod 来满足作业需求，Pod 运行相对稳定因此对 K8s 的压力比较小，本身 Yarn 支持调度性能和调度策略也是专门为离线任务设计的，调度性能比 K8s 的强很多。由于 NodeManager ESS 服务是对磁盘有容量和读写性能要求的，混部机器的磁盘一般难以满足，所以也需要能支持不同引擎的 Remote Shuffle Service。在资源利用上，NodeManager 需要满足多个作业的资源，最小单位是 Container，Pod 的资源粒度比较大，自身也会占用一些资源，如果资源粒度得不到有效地弹性伸缩，也会造成资源的浪费，因此需要引入额外的组件来协调,根据 Kubernetes 集群节点的剩余资源，动态调整 NodeManager 的 CPU 和内存，然而这也需要一定的改造成本。在资源紧张的情况下，NodeManager Pod 如果被驱逐也就意味着整个 NodeManager 被销毁，将会影响多个任务。&lt;/p&gt; 
&lt;p&gt;Spark on K8s 方案目前在 Spark 3.1 以上版本才正式可用，它需要频繁的创建、查询、销毁大量的 Executor Pod，对 K8s 的 ApiServer 和 ETCD 等组件都会造成比较大的压力，K8s 的调度器也不是专门为离线的大批量任务设计的，调度性能也比较弱。另一方面，Spark on K8s 虽然只能支持 Spark3.X 的 RSS，不过目前有较多的开源产品可选择。在资源利用上，最小单位是 Driver 和 Executor 的 Pod，资源粒度小，可以填充到更多的碎片资源，调度时直接与 K8s 对接，资源的弹性调度更多由 K8s 来承担，不需要额外的组件，改造成本比较低。在资源紧张的情况下，Executor、Driver 的 Pod 将依次逐个被驱逐，任务的稳定性会更高。&lt;/p&gt; 
&lt;p&gt;而对于 Spark on K8s 方案，还细分 2 种实现方案：Spark Submit on K8s 和 Spark Operator on K8s。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//65d397e91ee4e5dc2fd2dc1392df5e8c.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SparkOnK8s 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark 官网)&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9690ad754f277e44ce4a6a09f6f7058a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Spark Operator 架构图&lt;/p&gt; 
&lt;p&gt;(图片来源：Spark Operator 开源项目)&lt;/p&gt; 
&lt;p&gt;以 spark-submit 方式提交到 K8s 集群是 Spark 在 2.3 版本后提供的原生功能，客户端通过 spark-submit 设置 K8s 的相关参数，内部再调用 K8sApi 在 K8s 集群中创建 Driver Pod，Driver 再调用 K8sApi 创建需要的 Executor Pod，共同组成 Spark Application，作业结束后 Executor Pod 会被 Driver Pod 销毁，而 Driver Pod 则继续存在直到被清理。使用 spark-submit 方式的最大好处是由 spark-submit 来与 K8s 的进行交换，提交作业的方式几乎保持一致。但是因为使用的便利性所需要的封装也会带来一些缺点，spark-submit 是通过 K8sApi 创建 Pod，使用非声明式的提交接口，如果需要修改 K8s 配置就需要重新开发新接口，二次开发复杂繁琐，虽然 Spark 提供了大量的 K8s 配置参数，但也远比不了 K8s YAML 的声明式的提交方式更加灵活，而且 Spark Application 和 K8s Workload 的生命周期还不能较好地对应起来，生命周期不能灵活控制，任务监控也比较难接入 Prometheus 集群监控。虽然 Spark 社区也不断地在推出新特性来和 K8s 集成地更加灵活，不过对于些复杂场景需要定制开发，spark-submit 的封装性也会成为阻碍。&lt;/p&gt; 
&lt;p&gt;spark-submit 还是离线任务提交的思维，而 Spark Operator 方式就更倾向于 K8s 作业的思维，作为 K8s 的自定义控制器，在集成了原生的 Spark on K8s 的基础上利用 K8s 原生能力提供了更全面管控功能。Spark Operator 使用声明式的 YAML 提交 Spark 作业，并提供额外组件来管理 Spark 作业的生命周期，SparkApplication 控制器，负责 SparkApplicationObject 的创建、更新和删除，同时处理各种事件和作业状态，Submission Runner, 负责调用 spark-submit 提交 Spark 作业，Driver 和 Executor 的运行流程是一致的，Spark Pod Monitor，负责监控和同步 Spark 作业相关 Pod 的状态。Spark Operator 最大的好处是为在 K8s 中的 Spark 作业提供了更好的控制、管理和监控的功能，可以更加紧密地与 K8s 结合并能灵活使用 K8s 各种特性来满足复杂场景，例如混部场景，而相对地它也不再像 spark-submit 那样方便地提交任务，所以如何使用 Spark Operator 优雅提交任务将是在离线混部中一项重要的工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 最终选项&lt;/h3&gt; 
&lt;p&gt;在大的架构选型上，我们选择了 Spark on K8s，一方面因为 Spark3.X 是 vivo 当前及未来 2~3 年的主流离线引擎，另一方面 vivo 有比较完善的 K8s 生态体系，内部对 K8s 研发也比较深入，环境和能力都能很好地支持，在应用的小方向上，我们选择了 Spark Operator，因为它在混部这种复杂场景下使用更加灵活、扩展性更强、改造成本更低，我们最终决定使用 Spark Operator 方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 Spark 优化&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 Spark 镜像&lt;/h3&gt; 
&lt;p&gt;Spark 任务容器化的第一步就是构建具有 Spark 相关环境的镜像，Spark 任务类型主要分为 sql 任务和 jar 任务，在实践的过程中我们发现 Spark 的镜像构建需要&lt;strong&gt;注意几个问题&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark 环境的完整性&lt;/strong&gt;：镜像中除了打入自研的 Spark 包以外，还需要打入相应的依赖如 Hadoop、ZSTD、RSS 等包，对于 SparkJar 任务还有直接调用 Hadoop 客户端的，因此 Hadoop 客户端也需要打入镜像中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JDK 版本问题&lt;/strong&gt;：K8s 使用的 Spark 是基于 3.2.0 版本，镜像打包工具默认使用 JDK11，而自研的 Spark 用的 JDK1.8，由于在 Yarn 和 K8s 上使用的 JDK 版本不同，导致在双跑验证数据一致性时发现了 hash 函数、时间戳不一致的问题，因此 Spark 镜像中的 JDK 版本需要和 Yarn 保持一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;环境变量问题&lt;/strong&gt;：镜像生成容器后需要预置如 Spark、Hadoop 的环境变量，如果镜像中相关目录的位置不能完全和 Yarn 的提交节点保持一致，则需要检查各启动脚本，如 spark-env.sh 中的环境变量的路径是否存在，发生冲突时可以修改为绝对路径。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Spark 镜像构建完成后，区分 SparkSql 任务和 SparkJar 任务实质就是启动命令的不同，事实上 SparkSql 任务也就是 SparkJar 任务的一种，只是启动的主类是固定的，两者的启动参数如下：&lt;/p&gt; 
&lt;p&gt;SparkSql 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver -f {sql 文件}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SparkJar 任务：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;driver --class {jar 任务主类} {jar 任务 jar 包} {参数}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;早期不仅构建了 Spark 镜像，还构建了 Spark 日志镜像，容器组成结构会复杂一些。如图例如 Driver 容器，我们将 Spark、Hadoop 等配置文件构建了 configMap，启动 initContainer 来拉取从 configMap 拉取配置文件，然后启动 Driver 容器执行 Spark 任务，同时也使用 sidecar 创建日志上报的容器，在 Spark 任务运行完成后上报 Driver 和 Executor 日志到 Spark HistoryServer。这样的方案看似充分应用了 K8s 技术，但是在实践的过程中这些技术却被一一弃用，转而逐步地把各种功能集中到了一个 Driver 容器上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c1f0bf5a2f03578b42831a80908e1aad.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体演进如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 initContainer&lt;/strong&gt;，拉取 Spark 等配置文件步骤写在启动命令中，Spark 作业执行前执行下载配置，原因在多个 namespace 下不方便统一管理，而且 configmap 内容较大，会导致 Pod 启动时配置加载的延迟增加，影响了 Pod 创建速度，同时 K8s 的内存和 CPU 资源占用增加，对 kube-apiserver、ETCD 负载有一些影响。去掉 initContainer 还有个重要的好处就是减小 ETCD 的存储压力，事实上我们在移除 initContainer 拉取配置的功能后的一段时间内还保留着 initContainer，在任务逐渐上量后发现 ETCD 的存储比较满，分析后发现 Spark 作业中的一个 Pod 生命周期大约 8 次更新，其中 initContainer 更新会占用 2 次，移除了之后理论上是可以减少 1/4 的 ETCD 存储，实际应用中完全去除了 initContainer 也确实能减小了 ETCD 的存储压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;移除 sidecar 创建日志上报的容器&lt;/strong&gt;，Driver 和 Executor 日志上报步骤写在启动命令中，Spark 作业执行完后再执行脚本上报，原因是 sidecar 在同一个 Pod 中与主容器共享相同的生命周期，不使用 sidecar 方式就能更快创建 Pod，Spark 任务执行完成后能更快释放资源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对于 Spark 作业会频繁创建、更新和销毁大量的 Pod，所以去除非必要的容器，提高 Pod 生命周期流转速度，就能降低 kube-apiserver、ETCD 工作负载，也能提高 Spark 的作业效率。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 Spark 改造&lt;/h3&gt; 
&lt;p&gt;Spark 任务运行在 K8s 上，对于一些使用的兼容问题也进行了&lt;strong&gt;相关改造&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HistoryServer 改造&lt;/strong&gt;，因为 Spark Operator 没有存储已结束作业的日志，因此参考了 on Yarn 的方式，在 Spark 作业结束后，通过日志上传脚本把 Driver 和 Executor 的日志上传 HDFS，与 Yarn 日志聚合类似，同时也在 Spark HistoryServer 做了二次开发工作，增加了 on K8s 方式的日志查看接口，用户查看已完成的 Executor 日志时，不再请求 JobHistory Server，而是请求 Spark HistoryServer 接口。但日志上传方式需要 Executor 执行完才能查看到日志，为了能实时查看到执行中的日志，可以在 Executor 内部实现一个 HTTP 服务，根据 Pod 以及端口信息拼接出日志请求 URL，Executor 启动一个 Servlet 自动获取本地日志并返回。日志查看体验上做到了基本与 Yarn 一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主机 ip 通信&lt;/strong&gt;，Spark Driver 和 Executor 之间的通信通常是通过主机名进行的，不过随着 Spark 任务增多，CoreDNS 因为频繁的域名解释请求导致压力增大，甚至会影响到在线服务，因此我们将 Hadoop 的配置文件改为 ip 格式、设置 Driver 和 Executor 使用 ip 地址，同时去除了对应的 K8s Service，通过访问 ip 而不是域名的方式来规避这个问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件参数兼容&lt;/strong&gt;，Spark Driver 在 K8s 上是运行在某一个 Pod 中的，所以文件需要是全局可视的，如 HDFS 文件，否则就会报文件未找到的错误，但 Spark 作业运行在大数据作业平台时有的任务使用的上传的本地文件，因此对于提交到 K8s 的任务，第一步是要把上传到大数据作业平台的文件再次上传到 HDFS，第二步是改造 add jar 和--file 等命令逻辑，Spark 任务在未能读取本地文件后将再尝试读取二次上传到 HDFS 的文件，实现任务无需修改成全局可视的文件路径也能读取到文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;non-daemon 线程终止&lt;/strong&gt;，在 K8s 上运行的 Spark 任务是指定 Client 模式，Client 模式下 Driver 遇到异常时停掉 SparkContxet，等所有 non-daemon 线程结束后，Driver 才会退出，但如果存在一直运行的 non-daemon 线程，那么 Driver 一直不退出，任务就一直处于执行中。因此需要改造成 Cluster 模式的异常退出机制，即异常时以非 0 退出码退出，不再等待其他的 non-daemon 线程结束，Driver 直接终止，以确保 Driver Pod 的正常结束。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Spark Operator 优化&lt;/h2&gt; 
&lt;p&gt;随着在 K8s 上运行的 Spark 任务不断增加，K8s 集群的负载也逐渐显现。因此，需要对 Spark Operator 进行一系列优化，以减轻 K8s 集群的压力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;离线使用独立的 kube-apiserver&lt;/strong&gt;，混部集群中离线容器占了很大一部分，而且离线任务由于生命周期短，容器创建销毁更加频繁，这对 kube-apiserver 造成了很大的压力，然而在线业务需要更高的稳定性，为了减少离线对在线业务的影响，我们拆分了 kube-apiserver，离线任务通过指定 master 参数来使用独立的 kube-apiserver。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 K8s 的 HostNetwork 网络模式&lt;/strong&gt;，在 K8s 上启动 Driver 与 Executor 虽然使用的是独立 ip+固定端口，但频繁的 ip 申请和释放也对 kube-apiserver 造成了一定的压力，因此我们改为使用 HostNetwork 网络模式，同时不指定端口避免端口冲突。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Operator 控制器的队列&lt;/strong&gt;，在任务量比较大的情况下，Spark Operator 对 Pod 创建消耗效率会遇到瓶颈，排查后发现是 Spark Operator 的事件处理队列的并发数和限速桶的默认配置地太小，因此我们调低 Spark maxPendingPods 参数，调高 schedulerBacklogTimeout、 sustainedSchedulerBacklogTimeout 参数，减少 Pending Pod 个数，使 Pod 的处理效率符合集群的承载水平。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;优化 Spark Driver List Pod 接口&lt;/strong&gt;，使用 kube-apiserver 缓存，避免对 ETCD 产生影响，同时修改 Spark Driver 清理 Executor 逻辑，直接 Delete，减少 List Pod 对 kube-apiserver 压力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存储 emptydir + log lv 存储优化&lt;/strong&gt;，开发 CSI 插件，Spark 任务的离线日志单独存储，避免对在线业务 pod 的影响和磁盘负载高等问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Spark Secret 标记 immutable&lt;/strong&gt;，减少 kubelet watch secret 请求，降低 kube-apiserver 的负载。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_10&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、离线任务提交&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 平台任务提交平滑切换&lt;/h2&gt; 
&lt;p&gt;离线任务容器化方案确定后就要落地到生产，目前有 SparkSql 和 SparkJar 两种离线任务实现了容器化，这里以 SparkSql 任务为例描述 Spark 提交到混部 K8s 集群的流程并达到与传统客户端提交任务几乎无差异的平滑切换。目前 vivo 的离线任务都是通过大数据平台进行提交和调度的，平台会把主要的提交流程进行封装形成简单操作的功能，例如在平台上提交 SparkSql 任务流程一般是编写 sql、提交任务、查看 Driver 日志或在跳转到 SparkUI、执行完成后获取结果以及更新任务状态。&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务使用传统的 spark-submit&lt;strong&gt;提交流程&lt;/strong&gt;是：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到提交节点生成一个 sql 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在提交节点使用 Spark 客户端执行该 sql 文件启动 SparkSql 任务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过不断地 tail 操作查询日志转存到 HBase 方便在平台页面上查询到 Driver 日志；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，再查询输出结果转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据提交 sql 任务命令的返回码来更新任务状态。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;传统 Spark 客户端提交任务大部分只会涉及到提交节点的客户端与平台服务器之间的交互，而 SparkSql 任务提交到混部 K8s 集群，从上节的 Spark 容器化方案的原理可知最终目的是要将 Spark 任务的任务参数按一定的格式封装好传入 Spark Operator 控制器来创建相关的容器，平台需要通过会调用容器团队提供的封装好 K8sApi 的统一接入层来创建 Spark 容器。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//15dcd589c32637e1dde5ed6757b4eed7.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在平台内部，SparkSql 任务提交到混部 K8s 集群的&lt;strong&gt;完整流程&lt;/strong&gt;为：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;用户编写好的 sql 上传到 HDFS 生成一个远程可访问的 HDFS 文件；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SparkSql 任务参数封装好传入容器接入层的 createSpark 接口来调用 Spark Operator 控制器容器，再由 Spark Operator 控制器创建 Driver Pod，最后由 Driver Pod 根据 Spark 任务需要创建多个 Executor Pod，这些 Driver、Executor 的 Pod 相当于 Driver 和 Executor 的角色，共同配合执行 Spark 作业；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务启动后，通过容器接入层的 getDriverLog 接口周期性地查询 Driver 日志，实质上是查询 Driver 容器的日志，查询到的 Driver 日志会转存到 HBase 方便在平台页面上查询；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务结束后，一方面通过 Spark 启动脚本中的日志上传命令，把 Driver 和 Executor 的日志上传 HDFS，可以在改造后的 Spark HistoryServer 直接查看，另一方面执行结果也会先输出到 HDFS，再从 HDFS 转存到 HBase 方便在平台页面上查询到执行结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过轮询接入层的 getSpark 接口根据返回的状态码来更新任务状态，在任务结束后，此时 Driver Pod 不会主动退出，首先将任务状态更新为成功，在日志和结果都存储完成后，再调用 deleteSpark 接口主动地杀死 Driver Pod 释放资源，完成整个 Spark 任务流程。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;可以看出 SparkSql 任务提交到混部 K8s 的执行主体是容器，因此需要增加容器接入层来管理 Spark 相关的容器，同时容器的使用更倾向于存算分离的效果，因此需要使用 HDFS 作为远程文件中转。&lt;/p&gt; 
&lt;p&gt;大数据平台上传统使用 spark-submit 和 onK8s 使用 spark-operator 的 SparkSql 任务执行流程对比如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//024fa2e15ecb64123b58156eb1fd2188.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 混部任务的资源参数调整&lt;/h2&gt; 
&lt;p&gt;Spark 任务的 Driver 和 Executor，在 Yarn 上执行实质是运行在 NodeManager 节点上的，而在 K8s 上执行实质是运行在对应的 Pod 中的，由于 Spark on K8s 的提交方式和运行环境都不同于 on Yarn，任务的资源参数不能直接套用，需要做一些参数调整才能提交到 K8s 上。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、资源参数提取和转换&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SparkSql 任务在 Yarn 上可以灵活地调整 sql 中的配置来满足不同特性的任务，sql 中的资源配置会覆盖客户端启动时的全局配置，因为 Executor 是运行在 NodeManager 节点上的，资源会相对充裕能满足 Executor 的资源需求，与此不同的是 Spark on K8s 的 Executor 是运行在 Executor Pod 中的，使用的资源会受到 Pod 资源规格大小的限制，而 spark-operator 的提交方式是要先获取 Executor 全局资源规格并生成相应资源规格大小的 Executor Pod，所以在提交 Spark 任务到 K8s 前就要准确地获取任务真正生效的资源参数。在大数据平台中资源参数会存在多中类型的参数中，参数的优先级为：任务配置参数 &amp;lt; 任务模板参数 &amp;lt; sql 中设置参数 &amp;lt; HBO 优化参数 &amp;lt; 平台统一参数，按此优先级顺序依次提取最终的资源参数并传入容器接入层创建 Spark 作业。另外容器接入层对于 Spark 的 arguments 和 sparkConf 参数都是要求以字符数组的方式传入，需要做好对原任务参数中的单引号、双引号、反斜杠和回车等符号以及分段落的处理和转换。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、overheadMemory 的计算&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Yarn 上 Executor 是运行在 NodeManager 节点上的，节点的资源一般都大于并能满足 container 申请的资源，所以在 Yarn 上只需要关心 container 本身申请的资源即可，而在 K8s 上 Executor 运行在对应的 Pod 中，可以把 Pod 理解为只一台独立的节点，除了要满足 container 申请的资源量，还需要一些 Pod 容运行时网络、存储等基础设施的自身开销资源，如果把 Spark 任务中 Driver 和 Executor 申请的资源直接设置为 K8s 中 Driver Pod 和 Executor Pod 的资源规格，有可能出现 OOM 情况，另外还要考虑非 JVM 内存，Spark 默认会把申请的 Executor 内存乘以一个系数或者至少预留 384 MiB 内存作为额外的非 JVM 内存缓冲区，用于堆外内存分配、非 JVM 任务以及各类系统进程的使用，可以通过设置 overheadMemory 进行覆盖。因此 K8s 的 Pod 除了要满足申请的 Memory 和运行时需要的 overheadMemory 的资源，还会再添加 100M 资源用于 Pod 运行的自身开销。&lt;/p&gt; 
&lt;p&gt;pod 的资源规格 = memory + pod overheadMemory&lt;/p&gt; 
&lt;p&gt;对于 overheadMemory 也需要先获取到并加到 Pod 的资源规格，如果任务有配置就直接使用配置的 overheadMemory，如果没有配置值则按一定计算公式来计算得到。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = overheadMemory + 100M&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;无配置&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;pod overheadMemory = (max(384M，0.1*memory)) 向上取整到 512MB 的整数倍 + 100M&lt;/p&gt; 
&lt;p&gt;不过在实际应用中发现对于个别任务，即使 K8s 上配置的 overheadMemory 比在 Yarn 的配置多 100M，完全一样的任务在 K8s 上则有较多的 Executor OOM 情况，而在 Yarn 上却完全没有，目前排查到的现象是有 JVM 堆外的内存无法回收，如果任务需要较多的对外内存，堆外内存一直增长最终导致 OOM，但哪些内存无法回收的还未排查到。目前对于这些 OOM 过多且实际影响到运行效率的任务，在原 overheadMemory 基础上再增加 512M 后就没有 OOM 情况了，同时也有采用了大数据平台的 HBO 能力自动调整内存参数来事后规避这个问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、CPU 超分配置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spark 任务申请的 CPU 使用一般不会使用完，事实上 Executor Pod 的 CPU 利用率也并不是很高，比如 Executor 申请 1 个核，通常只能利用 0.6 个核，存在 CPU 浪费的现象。Executor Pod 的资源规格是创建的时候分配的，利用容器的能力，可以采取 CPU 超分的方式提高 CPU 的利用率，例如 Executor 申请 1 核，实际用 0.6 核，如果 Pod 分配 1 核，那利用率就只有 60%，但如果 Pod 只分配 0.8 核，那利用率就有 75% 了，所以超分的策略就是申请了 1 核只给 0.8 核，但还是要按 1 核的申请量来运行任务。目前平台使用的是静态的固定比例超分设置为 0.8，实施超分配置策略后 Pod 的实际 CPU 利用率打到 80% 以上。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//29fe0829e28d1e2084e2dbba0910de3a.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 混部任务的筛选提交&lt;/h2&gt; 
&lt;p&gt;经过上面的任务提交方式的改造和任务资源参数的调整，原 SparkSql 和 SparkJar 任务就可以平滑切换提交到混部 K8s 上执行了，但在大规模切换之前平台还做了比较长期的双跑验证工作，在执行成功率、数据一致性和执行时效等方案都进行了双跑比较，双跑通过的任务才能切换到 K8s 上执行。除了双跑通过，前期还设置了其他的筛选条件如下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//698830de13538cf7b2a6cf67d0b6fa45.jpeg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前期按这些条件筛选出可以提交到 K8s 的任务，然后分批的进行 K8s 任务的参数标记，并把标记的这批任务添加监控进行跟踪。经过双跑验证、任务筛选、批量标记、监控跟踪和问题解决这一整套 SparkSql 任务上量 K8s 的流程，K8s 上的任务运行逐步稳定，K8s 的兼容问题也基本解决，因此目前取消了双跑通过的这一条件，主要保留了任务重要性、运行时长和重试次数这几个筛选指标。随着 SparkSql 任务上量和稳定，提交到 K8s 的任务类型也增加了 SparkJar 任务，SparkJar 任务无法进行双跑验证，所以在各种 K8s 兼容问题解决后再推进会更加稳妥。&lt;/p&gt; 
&lt;p&gt;目前大数据平台会定期筛选和标记一批 SparkSql 和 SparkJar 任务允许提交到混部 K8s，用户也可以自行开启，在任务配置页面只显示已开启混部，则该任务就有机会被提交到混部 K8s 上执行。当然，用户也可以手动关闭这一开关，并且手动操作的优先级最高，手动关闭后平台的自动开启功能将不再生效。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、弹性调度系统&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 弹性调度功能矩阵&lt;/h2&gt; 
&lt;p&gt;Spark 任务开启了混部也不是必定能提交到混部，最终能不能在混部集群上执行，还要根据当时混部集群的资源和运行情况等来确定，为了更好地协调离线任务和混部集群的供需关系，大数据平台构建了离线任务混部弹性调度系统。弹性调度系统的设计目是混部集群有资源了就调度离线任务，但在生产环境中不管是混部集群还是离线任务都会各自的问题需要解决和优化的需求，弹性调度系统也逐步演变成了全面管理离线任务提交到混部以实现混部资源最大化利用的功能矩阵。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_16&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.1 资源水位线调度&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//878bdd653f0ec47e7c32fe0b09e8f975.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;弹性调度的流程，任务按调度时间以任务流的形式过来，如果任务标记了允许提交到混部，那就会先去查询 K8s 的各个集群，如果某一个集群资源充足就直接提交到 K8s，如果当时没有足够资源就等待资源再判断，这里分为有三类任务，第一类是一直等 K8s 资源，永不超时，只会提交到 K8s；第二类是长时间等待，超时时间在 1 到 5 分钟，可以等久一点；第三类是短时等待，超时时间为 30-60 秒，稍微等一下，如果 K8s 没有资源就回到 Yarn 上执行，目前平台标记的任务大部分任务都是第三类短时等待。&lt;/p&gt; 
&lt;p&gt;混部集群提供给离线任务的资源是呈潮汐波动的，使用百分比的水位线方式才能更好地贴合资源的波动情况。混部集群提供的资源是指 CPU 和内存，但离线任务一般不能百分之百地获取到这部分资源，需要设置一个折算比例也就是水位线来计算出离线任务能使用的真正资源是多少，水位线的设置需要考虑&lt;strong&gt;几个因素&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1、混部集群的碎片化率&lt;/strong&gt;，混部集群中的机器规格和正在运行的业务占用量都是不确定的，但一般大规格的机器多的集群碎片化率较低，所以小规格的机器多的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、资源动态分配容纳率&lt;/strong&gt;，对于开启了动态分配的 Spark 任务，无法提前知道任务所需的资源，需要留有一部分资源用于动态分配的消耗，如果同样的水位线资源规模大的混部集群容纳率会高，所以资源规模小的集群的水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、资源配比的均衡性&lt;/strong&gt;，不同的集群或者同一集群的不同时间段的 CPU 和内存配比可能会存在很大的差异，例如 Spark 任务的 CPU 和内存的平均比例是 1 核 6G，即 1:6，如果有 CPU 和内存比为 1:2 的，内存会被用完而 CPU 有剩余，此时为了内存留有部分余量，水位线要设置低一点。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * 资源水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;资源水位线有 CPU 水位线和内存水位线，设计时以 CPU 或内存中的最低水位线为准，哪个资源先分配完就停止提交任务，不过在实际生产中大部分混部集群都是受内存限制较多，个别时段 CPU 比内存多但通过其他的限制手段即使 CPU 满载对任务影响不大，因此目前只开启了内存资源水位线。以上提到的 3 点可以当成集群的固有消耗需要保留有一定的余量，为了直观地控制混部资源使用率和引入优先策略，计算方式调整为：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;混部资源可用量 = 混部资源提供量 * (1-余量水位线) * 优先水位线&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;余量水位线根据各个集群来调整，一般为 0.05，优先水位线的范围可以在 0-1 之间。优先水位线的作用是对于一些符合优先条件的任务可以优先提交，但是任务调度是一有任务就要调度的流式调度，不能够先集中再挑选优先任务而是先到先得，所以要为优先任务预留一部分资源，例如优先水位线为 0.8，混部资源使用到 0.8 以下的时候任何任务都可以调度上来，但使用量超过了 0.8，那只有优先任务能调上来，也就是为优先任务预留了 0.2 的资源，当然即使资源使用量达到了 1，由于余量水位线的存在，实际的使用量为 0.95，混部集群仍有资源维持周转。优先水位线是最常用的调整参数，它实质就是控制混部任务提交量，不仅能调整混部资源的使用量，还在灰度测试、压力测试和问题排查等事项起到了灵活调节的作用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_17&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.1.2 其他调度能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1.多集群管理&lt;/strong&gt;：混部集群通常会有多个，vivo 目前就有多个生产环境的混部集群，各混部集群由于建设周期、机器规格和业务接入的不同，混部资源的规模和变化趋势都会呈现比较大的差异，因此每个集群的调度策略配置都需要做到能独立调整来适应各自的资源特点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.分时段控制&lt;/strong&gt;：每个混部集群上的在线业务一般是潮汐波动的，给到离线任务的资源也是潮汐波动的，因此每个集群需要做到在每天不同时段可以调整不同的调度策略，尤其在波峰波谷差异较大的时间段各自调整配置的差异会更大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.分散 namespace&lt;/strong&gt;：Spark 任务的 Driver Pod 和 Executor Pod 都会放在一个 namespace 中管理，如果所有任务都由一个 namespace 管理，那需要管理的 pod 数量会达到数十万的级别，会对 K8s 集群的性能和稳定性产生影响。因此需要将 Spark 任务平均分配到多个 namespace，采用的方案是轮询填充，任务优先分配到多个 namespace 中任务最少 namespace。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.失败回退 Yarn&lt;/strong&gt;：离线任务混部推进的过程中还有会有 Spark 兼容问题、混部集群异常和平台变更等问题导致的离线任务在混部 K8s 上运行失败，为了减少失败对任务的影响，任务在 K8s 上首次执行失败后就会自动回到 Yarn 重新执行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5.资源准入粒度&lt;/strong&gt;：各混部集群的机器规格和碎片率是不一样的，如 executorMemory=2G 这样较小粒度的 Spark 任务即使碎片率较高的混部集群可以填充，而对于 executorMemory=16G 这样较大粒度的 Spark 任务，机器规格大的集群才更容易获取到资源，因此不同混部集群可以设置不同的准入粒度，小规格和碎片率高的集群准入粒度可以设置小一些。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6.任务偏好配置&lt;/strong&gt;：对于一些灰度任务和特殊要求的任务，例如只有在 0 到 8 点才允许提交到混部、只提交到某几个指定的混部集群等调度要求，需要支持任务偏好配置，在任务参数中调整混部控制参数实现相应的调度需求。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 弹性调度策略优化&lt;/h2&gt; 
&lt;p&gt;弹性调度的核心是通过资源水位线的调节，有混部资源就调度离线任务，但实际生产中还要考虑混部集群的运行情况，是否能稳定地接收和消化离线任务，同时在存在多个差异较大的集群时提交到哪个集群最优。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1 任务调度稳定优化&lt;/h3&gt; 
&lt;p&gt;大数据平台的离线任务提交高峰在凌晨时段而且调度时间集中在整点半点，还有 5 分和 10 分这样的整分，例如 03:00 调度的任务达 1000 个，但在 03:01 调度的任务只有 10 个，过于集中地提交任务会导致混部集群 Pending Pod 数量急剧上升，这是因为无论是查询集群资源还是 Pending 数的接口，更新数据都需要一定的周期时间，而且离线任务提交上去到获取资源也受 K8s 的调度时间的影响，所以获取集群运行情况总会滞后于任务提交。例如 03:00 查询集群是有资源的并且是健康的，由于任务开启了动态分配所以不能确定需要多少资源，此时集中提交了 1000 个任务，这 1000 个任务首先会创建 1000 个 Driver Pod，集群资源还是能满足的并且优先创建，假如每个 Driver 需要创建 100 个 Executor，如果集群没有这么多资源，那就会产生大量的 Penging Pod，严重影响集群的性能和稳定以及任务的执行效率，因此需要对弹性调度的稳定性进行优化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;短时提交限制&lt;/strong&gt;：避免集中提交任务的直接方案就是根据各混部集群的资源规模设置短时提交的任务数量限制，例如 1 分钟内只能提交 100 个任务，集群短时间内 Pending Pod 数量会增加但仍在可以承受范围内，集群和任务都会稳定运行。短时提交限制相当于拦截并舍弃了部分某个时间点集中提交的任务，这里相当于舍弃了 900 个任务，那么提交的总任务量就减少了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;延迟打散提交&lt;/strong&gt;：为解决短时提交限制导致舍弃部分任务的问题，增加了短时延迟打散提交，例如 03:00 提交的 1000 个任务，随机打散到 03:00 到 03:03 的 3 分钟内，即使有短时提交限制，这 3 分钟内也可以提交 300 个任务。理论上将集中提交的任务延迟更久，能提交到混部的任务会更多，但是增加延迟时长就等于增加任务的执行时长，会影响到业务数据产出的及时性，因此延迟打散提交策略只能是短时的，进一步的优化是执行时长更久的任务延迟更久一点，但根本解决方案还是用户能将调度时间尽量打散。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集群反馈限制&lt;/strong&gt;：短时提交限制和延迟打散提交都属于静态限制，需要人为地根据各个混部集群的情况去判断和设置限制值，因此需要做到动态限制，就需要获取集群的运行情况并根据运行情况进行限制。事实上 K8s 的调度性能相比于 Yarn 还是有差距的，从提交的 Spark 任务到获取到资源运行 Pod 有一定的滞后时间差，这段时间查询内还是有剩余资源，但如果还继续提交新任务就会产生更多 Pending Pod，因此需要做集群运行情况的反馈控制，例如查询 Pending Pod 数、等待的 SparkApp 数，当数量达到一定数量就不再提交新任务。&lt;/p&gt; 
&lt;p&gt;集群反馈限制虽然是动态的能根据混部集群情况进行反馈调节，但是查询集群状态是滞后的，这种滞后的控制就容易被集中提交给打垮，所以要加上短时提交限制来上一道保险，为缓解短时提交限制造成的任务损失，就引入了延迟打散提交，而在延时打散的过程中集群能逐步消化任务，查询集群状态逐步接近真实情况，这时又可以交给集群反馈限制来动态调节，逐步从突增恢复到稳定，三个调度稳定优化策略相辅相成。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 集群分配均匀优化&lt;/h3&gt; 
&lt;p&gt;离线任务会调度到多个混部集群，每个集群的资源总量和可用资源量，以及集群运行状况都不相同，为保证离线任务的运行稳定和执行效率，需要在多个混部集群中选择一个最合适的集群。各个集群会按一定的规则进行排序，离线任务会按这个排序依次轮询各个集群，只要集群剩余资源满足且没有被短时提交限制、集群反馈限制等拒绝，离线任务就提交到该集群。集群排序的&lt;strong&gt;演化顺序&lt;/strong&gt;如下：&lt;/p&gt; 
&lt;p&gt;①初始方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排队队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;剩余资源量多的优先&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b0cade1eb777379e3744a4104790af8.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源最多的集群，保证离线任务运行稳定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于小集群剩余资源量很小一直分配不到任务容易「饿死」（事实上有的小集群全部资源量都达不到一个大集群的 20%）&lt;/p&gt; 
&lt;p&gt;② 优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将资源使用量超过一定比例的集群放到排序队列，剩余的集群放到随机队列&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c8b8441d6a201f0d2e84113fcc307c2f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，即保证任务的运行稳定，随机的方式也能均匀「喂饱」每个集群&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随机分配在大任务量时相当于是平均分配，每个集群都会调度差不多的任务量，当前情况会存在整点集中提交大量任务，小集群接收和大集群同样任务量会抗不住，影响任务执行稳定和效率，小集群容易「撑死」&lt;/p&gt; 
&lt;p&gt;③再优化方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39918d1411bca61982582118837a610.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定&lt;/p&gt; 
&lt;p&gt;④ 最终方案&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优先队列（排序）+加权随机队列+排序队列+轮询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//db44e6961fb051bfbb59cb66ff17797f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;继承上一方案的优点，同时对于特定项目或机房的离线任务，能优先调度到某些特定的集群&lt;/p&gt; 
&lt;p&gt;目前只以内存作为资源水位线的衡量标准，这里的资源量指的是内存量。最开始方案是按集群的剩余资源排序，内存资源剩余多的集群优先，缺点是小集群一直分配不到任务容易「饿死」，然后使用随机的方式也能均匀「喂饱」每个集群，但小集群接收同样任务量时容易「撑死」，于是随机队列按剩余资源进行加权随机，剩余资源多的集群有更多概率分配到任务，这样离线任务优先提交到资源较多的集群，「大集群多吃，小集群少吃」，每个集群都能填充同时保证任务的运行稳定，在此基础上增加优先队列，无视其他排序规则，优先队列里的集群将最优先，在优先队列中的集群再按资源排序，能优先调度到某些特定的集群，形成最终集群选择排序方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_21&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、混部的效果与未来规划&lt;/h1&gt; 
&lt;p&gt;经过以上的对 Spark 组件、K8s 混部系统、大数据平台以及弹性调度系统的改造和优化，目前混部集群及提交混部的离线任务运行持续稳定，每天任务调度到混部的次数达 10+万次，在凌晨的高峰期通过混部能为离线任务额外增加数百 TB 内存的计算资源，部分混部集群的 CPU 利用率提升至 30% 左右，整体收益也是可观的。&lt;/p&gt; 
&lt;p&gt;虽然目前 vivo 的在离线混部达到了一定的规模，但未来要继续提高混部的规模和收益，还有规划一些改进工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_22&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;1、提高离线任务混部规模。&lt;/h2&gt; 
&lt;p&gt;离线任务混部的节点是在线业务提供的，节点规模取决于在线业务峰值，峰值越高那么在业务低峰期能提供给离线混部资源就越多，因此提高混部规模的重要因素是提交更多的离线任务。然而目前采用的 Spark Operator 方案能提交的离线任务只有标准的 SparkSql 和 SparkJar 任务，而对于非标准的任务如脚本任务，脚本中除了调用 spark-submit 提交 Spark 作业还有额外的处理逻辑，这类任务还不能直接以 Spark Operator 的方式提交。事实上 Spark 作业更多是来自脚本任务的非标准任务，如果要继续增加离线任务的量，就必须把非标准任务也提交到混部，因此后续是选择改造 spark-submit 客户端支持 Spark Operator，或是选择使用 Yarn on K8s，还需要综合评估。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_23&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;2、提高离线任务混部收益。&lt;/h2&gt; 
&lt;p&gt;目前混部节点 CPU 的平均利用率达到 30%，但仍有提升空间。从离线任务的角度来看，一方面是要增加错峰互补的时间段，例如离线任务的高峰期是 02:00 到 08:00，在线业务的高峰期是 06:00 到 23:00，在 06:00 后在线业务逐步上量开始回收资源，所以离线任务能显著提高混部集群 CPU 利用率的黄金时间是有 02:00 到 06:00 这 4 个小时，因此如果能把离线任务高峰期提前到 00:00 到 06:00，混部提效的黄金时间就能达到 6 小时。所以需要推动离线任务高峰期的前移，对于有依赖链路的任务，尽量减少调度时间的间隔，上游任务完成后能尽快调起下游任务，而对于没有依赖的任务，可以尽量提前调度时间，不过这两种调整都需要推动业务方来调整，平台也可以给予一定的计算成本优惠作为激励。另一方面是要提高混部资源的填充率，Spark 任务需要创建大量的 Executor Pod，目前混部集群的调度器为了保证调度效率就没有开启预选、优先策略，事实上 Spark 的资源粒度比较小更适合填充资源碎片，所以在不影响 K8s 调度效率的情况下优化资源调配策略，把合适的资源粒度的 Pod 分配到合适的混部节点，也是提高混部收益的方向。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18181972</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18181972</guid>
            <pubDate>Thu, 17 Apr 2025 06:42:40 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>开源多模态大模型「书生·万象 3.0」发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海人工智能实验室（上海 AI 实验室）升级并开源了通用多模态大模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Frb_gVjQTuwdx0hse6KuAkA&quot; target=&quot;_blank&quot;&gt;书生·万象 3.0&lt;/a&gt;（InternVL3）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，通过采用创新的多模态预训练和后训练方法，InternVL3 多模态基础能力全面提升，在专家级基准测试、多模态性能全面测试中，10 亿~780 亿参数的全量级版本在开源模型中性能均位列第一，同时大幅提升了图形用户界面（GUI）智能体、建筑场景图纸理解、空间感知推理以及通识学科推理等方面的能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;292&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1e01575a2bc4dfc8530b94281d9005d52e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在专家级多学科领域知识推理基准测试 MMMU 中再次突破开源模型极限，取得 72.2 分；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于司南 OpenCompass 开源评测框架，研究团队对 InternVL3 进行了全面系统的评估，包括多学科推理、文档理解、多图像 / 视频理解、现实世界理解、多模态幻觉检测、视觉定位、多语言能力以及以语言为中心的基准测试。评测结果显示，InternVL3 在开源多模态大模型中性能表现最优，创造了开源多模态大模型的性能新标杆，性能接近闭源模型 Gemini-2.5-Pro；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;创新提出原生多模态预训练方法，将语言和多模态学习整合于同一个预训练阶段，提升及拓展多模态能力的同时，进一步提升纯语言能力；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;提出混合偏好优化算法以及多模态测试阶段增强，通过负监督修正模型响应分布，大幅提升模型推理能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;公测版本：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.intern-ai.org.cn%2F%C2%A0&quot; target=&quot;_blank&quot;&gt;https://chat.intern-ai.org.cn/&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345071</guid>
            <pubDate>Mon, 14 Apr 2025 06:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>豆包 1.5·深度思考模型发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今日火山引擎 AI 创新巡展杭州站现场，火山引擎总裁谭待发布了最新的豆包 1.5·深度思考模型，升级豆包·文生图模型 3.0、豆包·视觉理解模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，面向 Agent 服务，发布 OS Agent 解决方案、GUI Agent 大模型——豆包 1.5·UI-TARS 模型；面向大规模推理，发布 AI 云原生·ServingKit 推理套件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据透露，截至 2025 年 3 月底，豆包大模型日均 tokens 调用量已超过 12.7 万亿，是 2024 年 12 月的 3 倍，是一年前刚刚发布时的 106 倍。IDC 报告显示，2024 年中国公有云大模型调用量激增，火山引擎以 46.4% 的市场份额位居中国市场第一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;豆包 1.5·深度思考模型在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出。同时，模型采用 MoE 架构，总参数 200B，激活参数为 20B，低于业界同类模型参数规模的 50%，具备显著的推理成本优势。基于高效算法，豆包 1.5·深度思考模型在提供行业极高并发承载能力的同时，实现 20 毫秒极低延迟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;363&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be145536aac0c4457023c8127490097c66a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，豆包 1.5·深度思考模型还具备视觉理解能力，可以像人类一样，不光基于文字思考，更能基于所见画面思考，思考更立体，让模型同时拥有「大脑」和「眼睛」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;升级的豆包·文生图模型 3.0 则能够实现更好的文字排版表现、实拍级的图像生成效果，以及 2K 的高清图片生成方式。可以广泛应用于影视、海报、绘画、玩偶设计等营销、电商、设计场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本的豆包·视觉理解模型具备更强的视觉定位能力，支持多目标、小目标、通用目标的框定位和点定位，并支持定位计数、描述定位内容、3D 定位。可应用于线下门店的巡检场景、GUI agent、机器人训练、自动驾驶训练等。新版本在视频理解能力上也有大幅提升，比如记忆、总结理解、速度感知、长视频理解等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FRYJ2OiZM_M-Jh27x3OFEdg&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345068</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345068</guid>
            <pubDate>Mon, 14 Apr 2025 05:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌推出了超越 Sora 的 Veo 2，生成 8 秒超逼真视频</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;谷歌 DeepMind 终于将大家期待已久的 Veo 2 整合到 GeminiApp 应用中，全面开放使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/114154_vVro_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Veo 是谷歌迄今为止最强大的视频生成模型。它可以生成各种电影和视觉风格的视频，捕捉提示中的细微之处，以便在各个画面中一致呈现精致细节。&lt;/p&gt; 
&lt;p&gt;据介绍，Veo 2 可以最高生成 8 秒 720P 电影级视频，在运镜、文本语义还原、物理模拟、动作一致性等方面非常优秀，同时支持图片转视频功能。谷歌公布的测试数据显示，Veo 2 在用户偏好和提示还原方面已经超过了 Sora、可灵 1.5、Meta Movie Gen 和 Minimax。&lt;/p&gt; 
&lt;p&gt;开发者可以在 Google AI Studio 中通过 API 使用 Veo 2。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fvideo%3Fhl%3Dzh-cn&quot; target=&quot;_blank&quot;&gt;https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345050/google-gemini-veo2</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345050/google-gemini-veo2</guid>
            <pubDate>Mon, 14 Apr 2025 03:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Reachy 2 开源人形机器人 7 万美元正式开售</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Pollen Robotics 推出其最新开源人形机器人 Reachy2，正式开启销售，定价为 7 万美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 并非面向消费市场，而是专为 AI 与机器人实验室设计，目标是推动开源机器人生态的发展。据 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fzh%2Fnews%2F17257&quot; target=&quot;_blank&quot;&gt;AIbase&lt;/a&gt;了解，这款机器人已在 Cornell 大学、Carnegie Mellon 大学及多家顶级 AI 实验室投入使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;324&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-be15587448f52736ea558e37ca046b43429.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Reachy2 以其高度仿人的外形与交互能力脱颖而出，主要亮点如下：&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;仿人设计：配备双臂、头部及独特的天线，Reachy2 的 7 自由度（DoF）手臂模仿成人手臂的尺寸与运动方式，可实现自然、精准的动作，每只手臂能负重高达 3 公斤。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;全向移动：其移动底盘采用三全向轮设计，结合 LiDAR 与多传感器系统，确保平滑、精准的导航，适应多样化应用场景。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;丰富的传感器阵列：集成双 1080p 摄像头、麦克风阵列、扬声器、LiDAR 及惯性测量单元（IMU），为环境感知与交互提供强大支持。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源与模块化：基于 ROS2 和 Hugging Face 的 LeRobotHF 框架，Reachy2 支持 Python SDK 编程，开发者可轻松扩展与定制功能，满足特定研究或应用需求。&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Reachy2 已被全球 20 多个国家的 100 多台机器人部署，客户包括 Hugging Face、Accenture、CNRS、Ecole Polytechnique 等。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345048</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345048</guid>
            <pubDate>Mon, 14 Apr 2025 03:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌宣布将全球搜索流量统一重定向至 google.com</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;谷歌&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fcountry-code-top-level-domains%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;将淘汰用于搜索的单独国家代码顶级域名（如 google.ng 或 google.com.br），并将其统一为 google.com。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;当您在 Google 上搜索时，我们致力于提供最实用的信息，这在很多情况下包括提供与本地相关的搜索结果。一直以来，为了提供本地化结果，我们都会使用国家/地区代码顶级域名 (ccTLD)，例如尼日利亚的 google.ng 或巴西的 google.com.br。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;多年来，我们提供本地化体验的能力不断提升。2017 年&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fmaking-search-results-more-local-and-relevant%2F&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;，&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;我们开始为所有使用 Google 搜索的用户提供一致的本地搜索结果体验，无论他们使用的是&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;还是其所在国家/地区的国家代码顶级域名 (ccTLD)。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;由于这项改进，国家/地区级域名已不再必要。因此，我们将开始将这些国家/地区顶级域名 (ccTLD) 的流量重定向至&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#5f6368&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fgoogle.com%2F&quot; target=&quot;_blank&quot;&gt;google.com&lt;/a&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;，以简化用户的搜索体验。此项更改将在未来几个月内逐步推出，在此期间，您可能会被提示重新输入部分搜索偏好设置。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，虽然此更新将改变人们在浏览器地址栏中看到的内容，但它不会影响搜索的工作方式，也不会改变我们处理国家法律规定的义务的方式。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5aaedebd84aee9085474149ca6015d401f8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345044/google-unifying-search-country-domains-to-googlecom</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软发布安全提醒：攻击者滥用 Node.js 来传播恶意软件</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微软近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fsecurity%2Fblog%2F2025%2F04%2F15%2Fthreat-actors-misuse-node-js-to-deliver-malware-and-other-malicious-payloads%2F&quot; target=&quot;_blank&quot;&gt;发布博文&lt;/a&gt;&lt;/u&gt;，称 Node.js 正日益被用于传播恶意软件和其他恶意负载。自 2024 年 10 月以来，微软持续监测到针对其客户的攻击活动，部分恶意活动甚至延续至 2025 年 4 月。&lt;/p&gt; 
&lt;p&gt;尽管与 Node.js 相关的恶意软件并不普遍，但它们正迅速发展，成为威胁环境的一部分。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/112133_vXu9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软表示，Node.js 是开源、跨平台的 JavaScript 运行时环境，它允许 JavaScript 代码在浏览器之外运行，被广泛使用并被开发者信任，因为它让开发者能够构建前端和后端应用程序。然而，攻击者也在利用这些 Node.js 特性来尝试将恶意软件与合法应用程序混合，绕过传统的安全控制，并在目标环境中持续存在。&lt;/p&gt; 
&lt;p&gt;微软举例称，犯罪分子利用与加密货币相关的恶意广告（malvertising）诱导用户下载伪装成来自 TradingView 或 Binance 等平台的合法文件的恶意安装程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e9b941943b28336312ced97e7c00094ce72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这个安装程序内含恶意 DLL 文件，用于收集基本的系统信息。随后，一个 PowerShell 脚本会下载 Node.js 二进制文件和一个 JavaScript 文件，并通过 Node.js 执行。&lt;/p&gt; 
&lt;p&gt;该 JavaScript 文件运行一系列程序，包括加载多个模块、向设备添加证书，以及窃取浏览器中的敏感信息。微软指出，这些行为可能预示后续的凭据窃取、规避检测或二次负载执行等恶意活动。&lt;/p&gt; 
&lt;p&gt;微软在第二个攻击实例中表示，黑客采用了 ClickFix 社交工程技术，试图欺骗受害者执行恶意的 PowerShell 命令。&lt;/p&gt; 
&lt;p&gt;该命令会启动多个组件的下载和执行，包括 Node.js 二进制文件，让 JavaScript 代码无需通过文件执行，能够直接在命令行中运行。&lt;/p&gt; 
&lt;p&gt;微软强调，尽管 Python、PHP 和 AutoIT 等传统脚本语言仍被广泛用于威胁活动，但威胁行为者正转向编译后的 JavaScript，甚至直接利用 Node.js 在命令行中运行脚本，实施恶意行为。&lt;/p&gt; 
&lt;p&gt;微软警告，这种威胁行为者技术、战术和程序（TTPs）的转变表明，尽管 Node.js 相关的恶意软件数量上相对其它攻击手段并不凸显，但正迅速融入不断演变的网络威胁。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345043/node-js-deliver-malware-and-other-malicious-payloads</guid>
            <pubDate>Mon, 14 Apr 2025 03:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>JetBrains 宣布推出 AI 工具免费套餐</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;JetBrains 发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fblog%2F2025%2F04%2F16%2Fjetbrains-ides-go-ai%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，所有 JetBrains AI 工具（包括改进的 AI Assistant 和新的编码代理 Junie）现在都可以通过单一订阅在 IDE 中使用，并提供免费套餐。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，为了让每个人都能使用 IDE 内的 AI 功能，从 2025.1 版本开始，所有的 IDE 许可证中都包含了 JetBrains AI free&amp;nbsp;套餐。AI Free 套餐为用户提供无限代码补全和本地 AI 模型访问权限，以及基于积分的云端 AI 辅助功能和编码代理 Junie。此外，免费套餐还包含 30 天的 AI Pro 访问权限。&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Pro（10 美元/月）和 AI Ultimate（20 美元/月）套餐计划将为高要求的工作流程提供更高的使用配额，&amp;nbsp;All Products Pack 和 dotUltimate 订阅则将包含 AI Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;334&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7661cb02397405a130e0974ef8e9b7b5ef6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;与此同时，该公司宣布其&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI 编码助手&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;color:#585858&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsdtimes.com%2Fai%2Fjetbrains-releases-ai-coding-agent-junie%2F&quot; target=&quot;_blank&quot;&gt;Junie&lt;/a&gt;&amp;nbsp;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;现已面向所有 JetBrains 客户开放。Junie 已进行更新，能够执行更复杂的任务，&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;并提供更精细的控制，实现真正的「人机交互」方法。目前，&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;Junie 已兼容 IntelliJ IDEA Ultimate、PyCharm Pro、WebStorm 和 GoLand。预计 PhpStorm、RustRover 和 RubyMine 也将很快获得支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#19191c&quot;&gt;除了 Junie 的公开发布之外，该公司还发布了 JetBrains AI Assistant 的新版本。包含多项重大改进，旨在加速编码工作流程并减少重复性任务，为开发者提供全程开发支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;AI Assistant 现在拥有更多模型选择，包括 Claude 3.7 Sonnet、Google Gemini 2.5 Pro 以及 OpenAI 的最新模型，以及具备更强大的本地模型集成功能。其他更新包括改进的代码补全、更强的上下文感知、可以编辑多个文件的新编辑模式，以及从代码生成到测试到文档的整个工作流程的更智能的支持。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fjetbrains.com%2Fai-ides%2F&quot; target=&quot;_blank&quot;&gt;立即开始&lt;/a&gt;在 IDE 中使用 AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#19191c&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;相关阅读：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;margin-left: 0px; margin-right: 0px; text-align: start;&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/345083/intellij-idea-2025-1-released&quot; target=&quot;news&quot;&gt;IntelliJ IDEA 2025.1 现已发布&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345039/jetbrains-ides-go-ai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345039/jetbrains-ides-go-ai</guid>
            <pubDate>Mon, 14 Apr 2025 03:13:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>美国政府不再为 CVE/CWE 项目提供资金支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;4 月 15 日，MITRE 向 CVE 委员会发送了一封邮件，告知美国政府对 CVE/CWE 项目的资助合同将于 4 月 16 日到期。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/110904_ginQ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;受此影响，CVE 漏洞可能更新受到影响，并影响 NVD 等下游的漏洞库。&lt;/p&gt; 
&lt;p&gt;CVE 项目始于 1999 年，由美国国土安全部（DHS）和网络基础设施安全局（CISA）的赞助，MITRE 负责运营，NVD（美国国家漏洞库）等下游漏洞库基于 CVE 的数据进一步加工分析。&lt;/p&gt; 
&lt;p&gt;在过去的二十多年里，CVE 是对通用漏洞标识的标准，是漏洞情报共享、漏洞库、各类安全工具的重要基础数据，这是一项非常有意义的伟大工作。&lt;/p&gt; 
&lt;p&gt;若资金链断裂，CVE 系统的崩溃将摧毁最受信赖的安全工具和流程。&lt;/p&gt; 
&lt;p&gt;前 CISA 负责人 Jean Easterly 在 LinkedIn 上警告，CVE 虽不常上头条，但却是现代网络安全最重要的支柱之一，失去它如同「同时拆除所有图书馆的卡片目录」，防御者将陷入混乱，攻击者则有机可乘。她强调，网络威胁无国界，CVE 是全球共享情报和协调行动的通用语言，失去它等于「所有人都在盲飞」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345038</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345038</guid>
            <pubDate>Mon, 14 Apr 2025 03:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 发布开源 AI 编程工具 Codex CLI</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 发布了一个名为「Codex CLI」的实验性新工具。这是一个轻量级的 AI 编程助手，可以直接在用户的终端命令行运行，旨在充分发挥 o3、o4-mini 等模型强大的推理能力，连接本地代码环境，甚至支持处理截图或草图进行多模态编程。&lt;/p&gt; 
&lt;p&gt;Codex CLI 已在 GitHub 完全开源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenai%2Fcodex&quot; target=&quot;_blank&quot;&gt;https://github.com/openai/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9e6e21608c2ed84ac64e14c0758cff7933.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Codex 有两种运行模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;「建议模式」（默认）：&lt;/strong&gt;提出命令供用户确认；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「全自动模式」&lt;/strong&gt;：禁用网络访问，让 Agent 自主工作但保持安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenAI Agent 研究团队成员 Michael 为了展示 Codex CLI 的功能，截取了一张在 X 上关于一个「图像到 ASCII 风格转换」工具的推文截图。&lt;/p&gt; 
&lt;p&gt;他将这个截图直接拖入终端，通过 Codex CLI 并利用 o4-mini 的多模态推理能力，最终成功创建了一个简单的 ASCII 风格图像转换工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-289ad265fb8a85af1f5a6e370f846aaffec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 认为 Codex CLI 是一个将其模型与用户及其计算机连接起来的最小化界面。&lt;strong&gt;Codex CLI 是为已经生活在终端的开发者设计的&lt;/strong&gt;，他们想要 ChatGPT 级别的推理能力，以及实际运行代码、操作文件和迭代的权力 —— 所有这些都在版本控制之下。&lt;/p&gt; 
&lt;p&gt;简而言之，它是一种理解并执行仓库的聊天驱动开发工具。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;零配置 — 导入 OpenAI API 密钥，即可直接使用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全自动批准，同时通过运行网络禁用和目录沙箱化确保安全&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多模态 — 输入截图或图表就可以实现推理功能&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Codex CLI 可以在 macOS&amp;nbsp;12+、Ubuntu&amp;nbsp;20.04+/Debian&amp;nbsp;10+、Windows&amp;nbsp;11 的 WSL2 子系统中使用，要求最少拥有 4GB 内存（建议 8GB）。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345034/openai-codex-cli</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345034/openai-codex-cli</guid>
            <pubDate>Mon, 14 Apr 2025 02:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 发布 o3 与 o4-mini：开启多模态推理新时代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;距离 OpenAI 发布 &lt;a href=&quot;https://www.oschina.net/news/344606/openais-gpt-4-1-models&quot;&gt;GPT-4.1&lt;/a&gt; 仅过去两天，OpenAI 在本周再次投下「重磅炸弹」—— &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-o3-and-o4-mini%2F&quot; target=&quot;_blank&quot;&gt;正式发布&lt;/a&gt;&lt;/u&gt;其新一代推理模型 o3 与轻量级模型 o4-mini。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104452_zQp5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这两款模型在推理能力、视觉理解、个性化对话和跨领域应用等方面实现了显著飞跃，代表了当下人工智能技术的新高度。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o3：迄今为止最强的通用推理模型&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI o3 是目前最强大的推理型模型，专为应对复杂、多步骤的任务而打造，广泛适用于编程、数学、科学分析、图像理解等领域。&lt;/p&gt; 
&lt;p&gt;它在多个权威基准测试中创下新纪录，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codeforces 编程排名&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SWE-bench 软件工程测试&lt;/strong&gt;（无需构建自定义脚手架）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MMMU 多模态任务测试&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不仅如此，&lt;strong&gt;o3 在图像、图表和视觉感知任务中表现尤为出色&lt;/strong&gt;。对于需要图像分析、图表解读等多模态输入的复杂问题，o3 能给出结构化、深入且精准的回答。&lt;/p&gt; 
&lt;p&gt;外部专家评估结果显示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;o3 在处理真实、复杂任务时比 o1 少 20% 的重大错误。尤其在编程、商业咨询、科研假设等场景中，o3 表现出色，能提出新颖想法并进行深度自我审查。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;首批使用者评价 o3 是 「值得信赖的思维伙伴」，特别擅长在生物、数学和工程领域中生成并评估新假设。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0417/104214_ZHcj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;o4-mini：更小、更快、更高效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;与 o3 不同，&lt;strong&gt;o4-mini 是一款轻量级、优化后的高性价比推理模型&lt;/strong&gt;，在计算资源、响应速度与实际效果之间达成了优秀的平衡。&lt;/p&gt; 
&lt;p&gt;亮点包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIME 2024 和 2025 数学竞赛中表现最佳&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在非 STEM 任务（如数据科学）中的表现超越 o3-mini&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数学、编程、图像识别任务中效率极高&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✅ 由于模型本身更轻量，o4-mini 支持更高的调用频率和更低的成本，非常适合&lt;strong&gt;大批量、多并发、快响应&lt;/strong&gt;的应用场景。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;更自然的人机互动体验&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;无论是 o3 还是 o4-mini，这一代模型在对话体验上也有明显提升。得益于智能水平的增强与网络信息的集成支持，&lt;strong&gt;两款模型都能更好地理解用户意图，提供可验证、结构清晰的回答&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;支持上下文记忆引用，更贴合用户历史对话&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令遵循能力增强，响应更精准自然&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;更加个性化、情境感知的交互&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;专家评语摘要&lt;/h3&gt; 
&lt;table style=&quot;min-width:155px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;优势亮点&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o3&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;推理最强，图像理解领先，适用于高复杂任务&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;o4-mini&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;高性价比，适合大规模调用，非 STEM 场景表现跃升&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;外部专家一致认为，&lt;strong&gt;新模型在可用性、可靠性和语言自然度上均优于前代产品&lt;/strong&gt;，是未来 AI 助手的重要里程碑。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI 的 o3 与 o4-mini 的发布，标志着 AI 推理模型的又一次跃迁。从性能到体验，从通用性到多模态理解，它们都展现出前所未有的能力。&lt;/p&gt; 
&lt;p&gt;如果你在寻找一个既能处理复杂问题，又能快速响应且个性化的 AI 模型，这一代产品值得你深入了解与使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345032/openai-gpt-o3-and-o4-mini</guid>
            <pubDate>Mon, 14 Apr 2025 02:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>多模态视觉理解大模型推理优化</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div class=&quot;rich_media_content js_underline_content
                       autoTypeSetting24psection
            &quot; id=&quot;js_content&quot;&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;01&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;背景&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 85px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;大模型时代是人工智能领域的一个重要发展阶段，在当今人工智能研究领域，基于 Transformer 架构的多模态视觉理解大模型（VLM）在全世界范围内引发了深度的技术关注。多模态视觉理解大模型的主要创新在于将语言和视觉两种模态进行有效的对齐，使其不仅能够进行基本的图像识别，还能执行基于视觉输入的动态内容推理和复杂问题解答。可以应用在房内家具家电识别、涉黄涉爆检测、商家店铺门头识别等多个场景，相比传统模型取得更好的效果。但是由于多模态视觉理解大模型的推理性能比传统模型低，导致整体成本高，严重阻碍了多模态视觉理解大模型的推广。提高多模态视觉理解大模型的推理性能成为研究重点。我们是多模态大模型技术部门，负责多模态大模型相关的模型研发、推理优化和推广的工作。我们在 58 的多模态视觉理解的项目场景中，对推理框架和模型进行优化，使用多种方法提高多模态视觉理解模型的推理性能。&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
  &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;02&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
     &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;场景介绍&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
 &lt;/section&gt; 
 &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 58 的多模态视觉理解的项目中，都是后台提交任务对图片进行推理，没有与用户进行实时对话的场景，所以目前性能优化的重点是批量输出的场景。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;margin-left: 20px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;/ul&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;场景一：长 token 输入、短 token 输出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;多模态视觉大模型输入的是提示词+图片，输入的 token 通常都比较长，在 58 的场景内，98% 以上的推理场景是输出短 token，通常在 5 个 token 以内。比如在信安定制数据治理项目中，输出的 token 是只有「是」或者「否」。我们重点对这种场景进行性能优化。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
   &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;场景二：长 token 输入、长 token 输出&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;另外 2% 的推理场景是输出长 token，比如给一张简历的 pdf 图片，让大模型识别图片中的内容，输出的 token 一般是几百个以上。这种场景的占比很少，不是性能优化的重点方向。&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
   &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;cursor: default;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
        &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;03&lt;/span&gt;&lt;/p&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
      &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;性能指标&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
       &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
  &lt;/section&gt; 
  &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;VLM 推理服务重点关注两个指标：&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量&lt;/span&gt;&lt;/strong&gt;&lt;span leaf=&quot;&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;时延&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin: 10px 8px;color: rgb(27, 28, 30);font-size: 15px;text-align: start;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;吞吐量：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要从系统的角度来看，即系统在单位时间内能处理的 tokens 数量。由于我们的主要场景是长输入 token，短输出 token，所以吞吐量的计算以单位时间内能处理的请求作为衡量指标，即模型推理的 qpm。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
    &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: justify;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
      &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;时延：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;主要从用户的视角来看，即用户平均收到每个 token 所需的时间。计算方法为用户从发出请求到收到完整响应所需的时间除以生成序列长度。一般来讲，当时延不大于 50 ms/token 时，用户使用体验会比较流畅。&lt;/span&gt;&lt;/span&gt; 
     &lt;/section&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;text-align: justify;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;由&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;于我们的场景都是批量输出的场景，没有流式输出的场景，所以我们重点关注的性能指标是吞吐量。&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;04&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;优化内容&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_1&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.1 图像预处理优化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在多模态推理中 Vision Transformer (ViT) 是一个关键的模块，图像的预处理是将图像转换为适合 ViT 模型输入数据的过程。主要包括图像颜色空间转换、尺寸调整 (Resize)、划分图像块 (Patch Partitioning)、归一化（Normalize）等步骤。在 LMDeploy 框架中，图像预处理过程中主要通过 PIL(Pillow) 的 Image 模块在 CPU 上对图像进行处理，在图像 Resize 及 Partition 过程中，效率较低，耗时占整个 ViT 过程的 20% 以上。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;为了提升系统吞吐能力，减少图像预处理耗时，我们分别使用 Pillow 与 OpenCV 进行预处理测试，具体表现如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;CPU: Intel(R) Xeon(R) Silver 4410Y&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Python 3.10.12&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;Pillow 10.2.0&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;opencv_python 4.8.1.78&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2000 张不同分辨率图像&lt;/span&gt;&lt;/span&gt; 
       &lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014200&quot; data-ratio=&quot;0.10252996005326231&quot; src=&quot;https://oscimg.oschina.net/oscnet/1bfb0234-fa3d-4e69-ad7e-225bcbe39f01.png&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 1：Pillow 与 OpenCV 预处理耗时对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;使用 OpenCV 可以极大的减少图像预处理的耗时，平均处理单张图片的耗时由 23.67ms 减少到 12.03ms，性能提升 49.18%。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在 Resize 过程中，虽然两个处理库对应的插值方式均使用 BICUBIC，但当图像进行下采样时效果存在明显差异，使用 OpenCV 进行处理的图像存在波纹。如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img class=&quot;rich_pages wxw-img&quot; data-imgfileid=&quot;100014201&quot; data-ratio=&quot;0.5472222222222223&quot; data-s=&quot;300,640&quot; src=&quot;https://oscimg.oschina.net/oscnet/b96df915-b9d8-40bd-ba95-705072874e44.png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; style=&quot;width: 509px;height: 279px;&quot; type=&quot;block&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-size: 15px; text-align: center; cursor: default; line-height: 2em; margin-bottom: 8px; margin-top: 8px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 2：Pillow 与 OpenCV 效果对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;通过对比源码实现，发现二者在插值与边界处理实现上有所差异：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;插值计算方式有差异&lt;/span&gt;：二者均使用 4x4 的卷积核进行插值计算，OpenCV 直接使用三次多项式公式计算每个像素的权重，并对周围 16 个像素进行加权平均；而 Pillow 将三次卷积操作分解为两个一维卷积，先对水平方向进行卷积，然后再对垂直方向进行卷积。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: bold;&quot;&gt;边界处理的差异&lt;/span&gt;：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;OpenCV 供多种边界处理方式，例如 BORDER_REPLICATE, BORDER_REFLECT, BORDER_WRAP 等；Pillow 通常使用边界复制的方式进行处理，即边缘像素值被复制到图像外部，以避免在边缘出现伪影。&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;针对这个问题，OpenCV 说明文档中提供了相应的解决方案：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);color: rgb(0, 0, 0);&quot;&gt;To shrink an image, it will generally look best with INTER_AREA interpolation, whereas to enlare an image, it will generally look best with INTER_CUBIC (slow) or INTER_LINEAR (faster but still looks OK).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;于是我们根据不同的图像采样对插值方式进行动态调整，对图像降采样时，使用 INTER_AREA 插值，上采样时，使用 INTER_CUBIC(速度较慢，但效果最好)，调整后，Resize 结果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e376a935-28bc-49af-a8c6-cabb4db7286f.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38425925925925924&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; type=&quot;block&quot; data-imgfileid=&quot;100014202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 3：OpenCV 优化前后与&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;Pillow 效果对比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.2 ViT 模块支持 TensorRT&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;ViT 模块是多模态推理框架中一个必不可少的组成模块，主要负责图像相关处理及编码工作。ViT 模块的处理速度，直接影响整个框架的整体推理效率。为了进一步提升框架的推理效率，我们对 ViT 模块的耗时进行了分块分析，结果如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/7c067863-ae5f-4261-bc0f-f16e4b12bb25.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10119840213049268&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-imgfileid=&quot;100014203&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(0, 0, 0); cursor: default; font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 4：vision 模型推理耗时及内存占用情况&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝相关逻辑：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ce4defef-9707-41cd-88e1-c878c4646834.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5291181364392679&quot; data-type=&quot;png&quot; data-w=&quot;601&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;601&quot; data-imgfileid=&quot;100014175&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 5：LMdeploy VIT 阶段内存拷贝代码截图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;经过验证，内存拷贝耗时主要是等待 GPU 异步处理结果，所以实际上主要耗时模块为图像预处理及特征提取两部分。具体定位步骤如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;ul style=&quot;list-style-type: disc;margin-left: 8px;margin-right: 8px;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝逻辑修改&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;ul style=&quot;list-style-type: circle;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/vl/engine.py 取消结果拷贝至 cpu 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/serve/vl_async_engine.py 取消拷贝到 cpu 及转换 numpy 操作&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
      &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
        &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;lmdeploy/pytorch/message.py 中修改 InputEmbeddings 及类型为 Torch.Tensor(GPU)&lt;/span&gt;&lt;/span&gt; 
       &lt;/section&gt;&lt;/li&gt; 
     &lt;/ul&gt; 
     &lt;li&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
       &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;内存拷贝逻辑修改引起异常的分析&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;逻辑调整后，推理结果异常。在 vl/engine.py forward 增加输出结果日志后，推理正常。经验证输出结果日志操作起到同步等待作用，使用 torch.cuda.synchronize() 或者 sleep 验证猜想正确。后续在模型内增加日志输出结果或者以上两个操作，推理结果均正常。推理结果正常后定位耗时模块，定位到 ViT 中 extract_feature 为主要耗时模块。为了进一步提升推理效率，我们借鉴了 TensorRT-LLM 中的推理加速方案 TensorRT。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;TensorRT 是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT 可对多种应用场景进行推理加速，并且支持 TensorFlow、Caffe、Mxnet、Pytorch 等几乎所有的深度学习框架。将 TensorRT 和 NVIDIA 的 GPU 结合起来，能在几乎所有的框架中进行快速和高效的部署推理。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/92358ef8-bc80-4bf8-817c-4301d087eec0.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.486&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014176&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 6：Tensorrt 优化过程图&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在对 ViT 模块进行 TensorRT 改造时，主要包含模型转换、模型优化和推理部署三个阶段。模型转化支持 TensorFlow、PyTorch、ONNX 等主流深度学习框架的模型转换和优化，本文以 ONNX 为例进行说明。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;1、模型转换&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/be6a8f15-e0da-4080-aeac-586ca6fb9964.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7807308970099668&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;602&quot; data-imgfileid=&quot;100014173&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 7&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-size: x-small;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;ONNX 模型转换代码截图&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;导出 ONNX 时可能会遇到不支持的算子，如在导出快速傅里叶变换（FFT）和快速傅里叶逆变换（IFFT）时会遇到如下错误，&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;Exporting the operator &#39;aten::fft_rfftn&#39; to ONNX opset version 17 is not supported&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;这时需要调整模型网络结构或者自定义算子。在对 ViT 模块进行 ONNX 转换过程中，部分多模态模型的 ViT 中使用了 FlashAttention2 进行注意力加速，而 FlashAttention2 中的 flash_attn_func 是作为独立的内核实现的，不是 torch.nn.Module 的实例，导致导出器无法捕获计算图，如下：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;/usr/local/lib/python3.10/dist-packages/flash_attn/flash_attn_interface.py:90: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can&#39;t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;因此，对 Attention 模块进行了调整，使用 PyTorch 内部实现的缩放点积注意力（Scaled Dot-Product Attention, SDPA），如下图，至此模型便可成功转换成 ONNX 格式。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/e60836a9-5141-4603-9d85-270e50fd40be.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5825&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014174&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 8&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;缩放点积注意力 (SDPA) 代码截图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;2、模型优化&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;该阶段主要完成模型优化，如下图所示，在模型优化过程中会完成层间融合，精度校准等。这一步的输出是一个针对特定 GPU 平台和网络模型的优化过的 TensorRT 模型，这个 TensorRT 模型可以序列化存储到磁盘或内存中，存储到磁盘中的文件为 TensorRT planfile。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/1ef2a7d7-071f-44da-aa1f-150b5e299114.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.224&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014172&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 9：Tensorrt 模型优化及系列化流程图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;3、推理部署&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/8169cdc0-de30-4af8-9617-1e080e14ec9c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2064&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;625&quot; data-imgfileid=&quot;100014177&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 10：Tensorrt 部署及推理流程图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署阶段将上一个步骤中的 plan 文件反序列化，并创建一个 runtime engine，输入对应的图像数据，输出推理结果。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4、推理效率&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;经过 TRT 加速后，ViT 模块 feature_extract 速度缩减 45% 左右（不包含图片预处理），feature_extract 耗时在 ViT 中占比从 60% 减少至 45.36%，整体推理耗时耗时缩减在 70ms 左右。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.3 ViT 模块支持 CudaGraph&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;推理框架 lmdeploy 在 0.6.0 版本引入了 CUDA Graph,并提升了近 30% 的推理性能：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);&quot;&gt;&amp;nbsp;Employ CUDA graph to boost the inference performance (30%)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;不过受多方因素限制，目前 lmdeploy 只在语言模型中引入了 CUDA Graphs。为了进一步提升推理速度，我们在 ViT 模块中引入了 CUDA Graphs。CUDA Graphs 可以用于优化执行过程中的 CUDA 操作，在 GPU 上实现更加高效的深度学习模型推理。在使用 CUDA Graphs 时需要对 CUDA 操作进行录制（capture）和重放（replay），以此来减少 CPU 到 GPU 的调度开销，提高整体的执行效率。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;如下图，简单展示了 CUDA Graphs 的优势。在顶部，CPU 逐个启动一系列短内核。CPU 启动开销导致内核之间出现明显间隙。如果我们用 CUDA 图替换此内核序列，最初我们需要花费一些额外的时间来构建图并在第一次启动整个图时一次性启动整个图，但后续执行将非常快，因为内核之间的间隙将非常小。当多次重复相同的操作序列时，例如在许多训练步骤中重复，差异会更加明显。&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac8a403c-ee90-4fe0-81cd-65e63efbb452.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.372&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014178&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 11：CUDA Graphs 性能优势图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;首先，在 ViT 支持 CUDA Graphs 时，需要 torch.cuda.CUDAGraph 创建对应的图，然后使用 torch.cuda.graph() 对 ViT 的推理过程进行录制，在推理过程中，使用刚创建的图对录制的过程进行重放 CUDAGraph.play()。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;但是要注意，由于 CUDA Graphs 不支持动态控制流（如条件语句和循环），因此在设计算法时应尽量避免使用这些结构；其次，确保输入张量的形状在图创建时是固定的，因为 CUDA Graphs 的设计是基于静态形状的张量结构，创建 Graph 时，所有操作及其输入输出的形状必须在图创建时确定。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;而 ViT 模块在进行图像处理时，输入的图像数张量的形状是 [batch_size, channel, width, height]，其中 batch_size 是可变的且各视觉模型均已限定最大值。于是，我们在框架内部维护了 Graphs Pool，推理时使用 batch_size 索引至相应的 graph，再执行重放操作。&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;text-align: justify;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;增加 CUDA Graphs 后 ViT 模块平均耗时减少 30ms 左右。虽然 CUDA Graphs 可以在一定程度上提升推理的效率，但是在构建 graphs 也需要占用一些额外的显存，在使用时需要综合衡量具体的业务场景及硬件资源。&lt;/span&gt;&lt;/p&gt; 
    &lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;color: rgb(255, 104, 39);&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.4 图像 Token 化处理&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;输入 token 的长度对推理耗时影响很大，多模态模型中，图像部分占据了很大比例的 token 数，降低图像转换的 Token 数可提升推理性能。如下是结果对比：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/f660d32a-1b9f-4656-98d1-dbecee5fe26c.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29894179894179895&quot; data-type=&quot;png&quot; data-w=&quot;378&quot; style=&quot;width: 382px;height: 114px;&quot; data-imgfileid=&quot;100014204&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;图 12：&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot; data-pm-slice=&quot;1 1 [&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;color: rgb(51, 51, 51);font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); margin-bottom: 8px; cursor: default; margin-top: 8px; text-align: center; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;para&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;section&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: rgb(27, 28, 30); font-family: \&amp;quot;PingFang SC\&amp;quot;, \&amp;quot;Microsoft YaHei\&amp;quot;, Arial, 黑体, 宋体, sans-serif; font-size: 15px; letter-spacing: normal; background-color: rgb(255, 255, 255); cursor: default; text-align: justify; margin-top: 8px; margin-bottom: 8px; line-height: 2em;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;},&amp;quot;node&amp;quot;,{&amp;quot;tagName&amp;quot;:&amp;quot;span&amp;quot;,&amp;quot;attributes&amp;quot;:{&amp;quot;style&amp;quot;:&amp;quot;font-size: 16px;&amp;quot;},&amp;quot;namespaceURI&amp;quot;:&amp;quot;http://www.w3.org/1999/xhtml&amp;quot;}]&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;font-weight: normal;&quot;&gt;Token 数和推理耗时基本成正比&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bold;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;图像转换的 Token 数计算主要流程如下&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;（1）根据图像宽高比和分辨率大小将原图拆分成若干个 448*448 的 patch，拆分的原则是尽量保持图像不失真。拆分代码如下：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/30811eb3-1df8-4dc0-b6e3-6ea8f054445d.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9367088607594937&quot; data-type=&quot;png&quot; data-w=&quot;869&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014179&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;cursor: default;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 13：VLLM 中 InternVL2-8B 模型拆图代码截图&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;上述代码基本流程是，给定动态拆分的阈值范围，穷举出所有可能的目标比例，再根据原图比例匹配最佳的拆分规则，拆分逻辑图示如下图左上部分，图示中会被拆分成 6 个 path 块和一张缩略图。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b84a37b-1304-4f2d-84ad-324785e09a4b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.526&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);border-style: none;cursor: default;&quot; width=&quot;700&quot; data-imgfileid=&quot;100014180&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot;&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot; data-pm-slice=&quot;0 0 []&quot;&gt;&lt;span leaf=&quot;&quot;&gt;图 14&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;：&lt;/span&gt;&lt;/span&gt; 
     &lt;span style=&quot;color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: x-small;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: normal;orphans: 2;text-indent: 0px;text-transform: none;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;background-color: rgb(255, 255, 255);text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;float: none;display: inline !important;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;InternVL 模型整体框架图&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（2）一个 448*448 的 patch 生成的 token 数计算方式如下：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;background-color: rgb(214, 214, 214);font-weight: normal;&quot;&gt;image_tokens_per_patch=(force_image_size // patch_size)**2 * (downsample_ratio**2))&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;force_image_size=448,patch_size=14,downsample_ratio=0.5,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;这个计算后结果为 256。不同的模型值可能会有所差异。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;strong&gt;&lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-weight: normal;&quot;&gt;（3）分辨率为 896*1344 的图像，经过步骤 1 处理，会拆分成 2*3=6 个 patch，再加上一张缩略图（可选，有效果会更好），最终堆叠后 shape 是[7,3,448,448]，图像转换的 token 数为 7*256=1792。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;部署到线上时，单卡吞吐量上不去，其中一个原因是拆图规则导致拆分后的图片数量比较多，如分辨率 612*464，最合适的宽高比是 (4, 3)，按模型的图片拆分规则，图像将被拆分成[13,3,448,448]，转化后的 token 数达到 3328，再加上 prompt 的 token，总 token 数会达到 3400+，太长的输入 token 对模型推理速度影响很大，再加上显存和算力的限制，无法做到更大 batch 的推理，使得单卡推理的吞吐量很低。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;基于此原因，我们的优化思路是降低图像的总 token 数，经实验分析，官方代码在实现上存在比较大的冗余设计，如图像分辨率为 480*360，也会转换成 3328 个 token 数，对于低分辨率图像生成太多的 token 存在资源浪费。在保持图像内容不拉伸前提下，对图像的宽高比做调整，以适应 vit 的要求，优化后，480*320 的图像只转换成 512 个 token 数，这样在推理时能做到更大的 batch 处理。在我们实际落地场景中，处理后吞吐量能提升 1 倍。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.5 prefixcache 在多模态模型里应用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;在&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;PagedAttention 中，KV Cache 只是在一个请求内复用，而没有做到跨请求的 KV Cache 复用。长 prompt 的场景，prompt 在不同的请求中是相同的，KV Cache 的计算也是相同的，如果能把 prompt 的 KV Cache 保存下来，留给后续的请求复用，将会极大地降低首 Token 的耗时。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;在 LLM 模型里，prefixcache 分二个阶段，第一个阶段，当 prompt 第一次被推理时，是按 block_size(通常是 64) 大小对 input tokens 从前往后进行分块，计算每个分块的 hash 作为唯一标识，每个分块的 token_id 作为 key 进行缓存，这里不足 block_size 长度的块不会被缓存；第二阶段，当新 prompt 被推理时，会进行 prefix cache matching，命中就直接复用 kvcache，只计算未命中部分的 input tokens。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;多模态模型区别在于，一次任务的输入 tokens 组成由纯文本变成了文本+图片，由 system+prompt 变成了 system+image+prompt，在计算 prefix cache 时，image 对应的只是 padding tokens，那么在计算 prefix cache matching 时，不同图片可能匹配到一样的 prefix 上，这样推理结果就会出现错误。针对这个问题，在 input tokens 中对 image 进行范围标记，在计算 prefix cache 时不对 image token 进行 kvcache，只 cache image 之前的部分；在 prefix cache matching 时，也同样保证 image token 不会被复用。经实验验证，修改后能保证在开启 prefix cache 时，推理结果是正确的。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;需要注意，Prefix Caching 只节省了 prefill 阶段的耗时（也就是降低了 TTFT，Time To First Token），并不能节省解码阶段的耗时（也就是 TPOT，Time Per Output Token）。如果请求的主要耗时是在解码阶段（例如 prompt 很短而 completion 很长），或者多个请求的 prompt 并没有公共的前缀，那么 Prefix Caching 就对于整个 LLM 推理的性能提升帮助不大&lt;/span&gt;。&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
    &lt;h3 style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgba(0, 0, 0, 0.85);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt;&lt;span style=&quot;color: rgb(255, 104, 39);&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: rgb(255, 104, 39);font-weight: bolder;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;4.6 模型量化&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化是大模型领域中的一项关键技术，它通过降低模型参数的精度，将浮点数转换为整数或定点数从而实现模型的压缩和优化。模型量化可以减少模型尺寸，进而减少在推理时的显存消耗，并且在一些低精度运算较快的处理器上可以增加推理速度。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;量化分很多情况。从量化对象来说，量化可以是权重、激活、kv cache 和梯度；从量化的形式上来说分为线性量化和非线性量化，其中线性量化又分为对称量化和非对称量化；根据应用量化压缩模型的阶段，又可以将模型量化分为量化感知训练、量化感知微调、训练后量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;我们现阶段使用的量化方式是 AWQ 和 GPTQ，这两种量化都属于训练后量化，是针对权重的线性量化，其中 AWQ 采用对称量化，GPTQ 采用非对称量化。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;AWQ 量化的原理是对于 LLM，权重不是同等重要的，通过保留 1% 的显著权重可以大大减少量化误差。在此基础上采用激活感知的方法，考虑更大的激活幅度应该对应更重要的权重通道，在处理重要特征时起关键作用，逐通道确定最佳缩放因子。从而在量化所有权重的同时，最小化量化误差。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;GPTQ 对模型的每一层（通常是线性层或卷积层）进行单独处理，考虑了量化带来的误差，并通过调整未量化的权重来补偿这些误差。利用了二阶偏导 Hessian 矩阵的逆，来指导权重的调整，以减少整体的量化误差。将权重矩阵分成多个子矩阵（block），对每个子矩阵中的权重逐个进行量化，同时调整同一子矩阵内其他权重，以保持模型输出的相似性。其量化后的误差依赖一份高质量的校准数据。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;整体上来看，AWQ 相较于 GPTQ 量化的算法更直接，对校准数据依赖小；GPTQ 则更容易有比较好的量化效果，但是算法相对复杂，对校准数据依赖比较大，实际过程中用哪个更合适需要根据实际的场景选用。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;在实际测试中，不论是 AWQ 还是 GPTQ 实际采用的都是 w4A16 的量化策略，在推理的时候，性能差异比较小，在 RTX4090 显卡下，我们使用 vllm，对应不同参数，并且设置最优 batch，实际测试值如下：&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(25, 27, 31);cursor: default;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;针对单个请求的延时：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/ac7dd996-e553-40fb-b9a8-4832f70c1a3b.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2084507042253521&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;710&quot; type=&quot;block&quot; data-imgfileid=&quot;100014210&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-bottom: 8px;margin-top: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 15: 原始模型和量化模型的推理耗时比较&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;从测试结果看：在 4090 下，大 batch 的计算，使用 gemm 内核，速度不如原精度，原因是在大 batch 的情况下，增加了反量化的时间。使用 marlin 内核，计算的速度有优化，但是在大 batch 下，优化速度不明显。低 batch 的计算原精度是计算最慢的，gemm 的内核计算与 marlin 计算差别不是很大，都比原生的有大幅提高。原因是 gemm 在低 batch 下，也做了内核优化，这一点可以从原代码中验证：&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/89dafcc6-de64-4e34-b8ac-72982e9aeb04.png&quot; class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30575035063113604&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;713&quot; type=&quot;block&quot; data-imgfileid=&quot;100014211&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 16&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);box-sizing: border-box;max-width: 100%;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;VLLM 中 awq 量化模型 mul 计算逻辑代码&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: left;line-height: 2em;&quot;&gt; 
    &lt;span leaf=&quot;&quot;&gt;针对吞吐量：&lt;/span&gt; 
    &lt;section style=&quot;&quot; nodeleaf=&quot;&quot;&gt; 
     &lt;img src=&quot;https://oscimg.oschina.net/oscnet/c2d58729-66c8-42cd-ad10-c69be338f6b4.jpg&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.15281501340482573&quot; data-s=&quot;300,640&quot; data-type=&quot;webp&quot; data-w=&quot;746&quot; data-croporisrc=&quot;https://oscimg.oschina.net/oscnet/22f3d6f2-bfb2-465f-9504-408778ea5dbd.jpg&quot; data-cropselx2=&quot;578&quot; data-cropsely2=&quot;120&quot; data-imgfileid=&quot;100014212&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 17：原始模型和量化模型的吞吐量比较&lt;/span&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
     &lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;从测试结果看，对于短输出，其实吞吐量并没有优化，还下降了一点，原因是，对于短输出，主要的耗时在 prefill，prefill 是大 batch 的计算，在推理过程中，吞吐量会下降。但是对于长输出，decode 阶段占比比较高，内核对于 decode 的优化比较明显，综合吞吐量会上升。&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p style=&quot;text-align: justify;margin-bottom: 8px;margin-top: 8px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;总结：在实际使用中对于 W4A16 量化后的模型来说，模型占用的显存一定能节省。但是推理的整体性能和吞吐量，需要根据不同的任务特点，部署的硬件环境，调整部署的参数，以达到最优。而不是量化后的整体性能一定会优于未量化的模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;line-height: 2em;margin-bottom: 8px;margin-top: 8px;&quot;&gt; 
    &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;cursor: default;&quot;&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;margin-right: 12px;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: center;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 40px;height: 40px;vertical-align: top;overflow: hidden;border-width: 0px;border-radius: 0px 14px 0px 0px;border-style: none;border-color: rgb(62, 62, 62);background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 17px;&quot;&gt; 
        &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(255, 248, 244);font-size: 18px;font-family: Optima-Regular, PingFangTC-light;line-height: 0.5;&quot;&gt; 
         &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;05&lt;/span&gt;&lt;/p&gt; 
        &lt;/section&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;vertical-align: bottom;width: auto;min-width: 10%;height: auto;align-self: flex-end;line-height: 0;&quot;&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 19px;font-family: Optima-Regular, PingFangTC-light;line-height: 1.8;letter-spacing: 1px;color: rgb(243, 89, 41);&quot;&gt; 
       &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);line-height: 1.5;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&amp;nbsp; 优化数据&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
     &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);text-align: right;justify-content: flex-end;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);display: inline-block;width: 86.2969px;height: 5px;vertical-align: top;overflow: hidden;background-color: rgb(243, 89, 41);cursor: default;&quot;&gt; 
       &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);&quot;&gt; 
        &lt;svg viewBox=&quot;0 0 1 1&quot; style=&quot;float:left;line-height:0;width:0;vertical-align:top;&quot;&gt;&lt;/svg&gt; 
       &lt;/section&gt; 
      &lt;/section&gt; 
     &lt;/section&gt; 
    &lt;/section&gt; 
   &lt;/section&gt; 
   &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 8px;cursor: default;margin-top: 8px;text-align: center;line-height: 2em;&quot;&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;ul style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-right: 8px;margin-left: 8px;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot; class=&quot;list-paddingleft-1&quot;&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;评测模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：InternVL2-8B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;数据集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：信安群租房检测 4524 张图片&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;提示词&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：图中有 3 张以上的床，或者是有双层床，请直接给出是或者否，然后给出详细的解释。注意 1 张双层床有 2 张床&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;输出 token 数量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：max_tokens=1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;GPU&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;: RTX4090&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;对比框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;优化框架&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;：LMDeploy-0.6.0 优化版本&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
     &lt;li style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-size: 16px;&quot;&gt; 
      &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;text-align: justify;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt; 
       &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;吞吐量：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;由于我们的场景是长输入 token 和短输出 token，所以按单位时间内处理的请求数作为衡量指标。比较两个框架的推理 QPM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
      &lt;/section&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/1b84899b-305c-4427-8131-5600a10b72b8.png&quot; class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1893687707641196&quot; data-type=&quot;png&quot; data-w=&quot;602&quot; data-imgfileid=&quot;100014207&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p data-pm-slice=&quot;0 0 []&quot; style=&quot;text-align: center;margin-top: 8px;margin-bottom: 8px;line-height: 2em;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 12px;&quot;&gt;图 18：LMDeploy-0.6.0 优化前后召回率和吞吐量比较&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;section style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;text-align: justify;&quot;&gt; 
     &lt;span style=&quot;font-size: 16px;&quot;&gt;&lt;span style=&quot;font-size: 16px;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;font-weight: normal;&quot;&gt;LMDeploy-0.6.0 优化版本在推理效果不受影响的情况下，吞吐量提升到 LMDeploy-0.6.0 版本的 3.05 倍&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
    &lt;/section&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 15px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;text-align: justify;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);font-weight: bolder;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span leaf=&quot;&quot;&gt;&lt;span textstyle=&quot;&quot; style=&quot;font-size: 16px;&quot;&gt;徐海芳、李海洋、朱辰、张辉，MPai 平台视觉理解大模型推理团队&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;font-weight: bold;font-size: large;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
    &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;/section&gt; 
   &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/section&gt; 
  &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-top: 10px;margin-bottom: 10px;line-height: 1.5;color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/section&gt; 
 &lt;p style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);margin-bottom: 0px;line-height: 1.5;color: rgb(51, 51, 51);font-family: &amp;quot;PingFang SC&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, 黑体, 宋体, sans-serif;font-size: 16px;letter-spacing: normal;background-color: rgb(255, 255, 255);cursor: default;&quot;&gt;&lt;span style=&quot;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(27, 28, 30);font-size: 15px;cursor: default;&quot;&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span leaf=&quot;&quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;display: none;&quot;&gt; 
  &lt;mp-style-type data-value=&quot;3&quot;&gt;&lt;/mp-style-type&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color: #858585; font-size: 13px;&quot;&gt;本文分享自微信公众号 - 58 技术（architects_58）。&lt;br&gt;如有侵权，请联系 support@oschina.cn 删除。&lt;br&gt;本文参与「&lt;a href=&quot;https://www.oschina.net/sharing-plan&quot; target=&quot;_blank&quot;&gt;OSC 源创计划&lt;/a&gt;」，欢迎正在阅读的你也加入，一起分享。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5359019/blog/18160034</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5359019/blog/18160034</guid>
            <pubDate>Mon, 14 Apr 2025 02:30:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>《流浪地球 3》发布 AI 问答应用 WEi</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;电影《流浪地球 3》近日在青岛举行开机仪式，郭帆导演携主创团队齐聚亮相。在开机仪式现场，《流浪地球 3》剧组正式发布剧组专属的自研 AI 问答应用 WEi。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;365&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b58e821f644cfcd13feb137d9d2cac2428.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该应用依托大语言模型，基于 DeepSeek R1 大语言模型，NVIDIA、火山引擎作为「AI 支持合作伙伴」所开发，本地推理部分由 NVIDIA GeForce RTX 5090 D 加速，旨在为剧组提供一站式智能服务，大幅提升剧组创作效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，WEi 通过整合多元化知识库资源，包括在线信息源的专业资料、图像和影视参考，以及电影《流浪地球》系列剧本、世界观、编年史、人物小传、美术设定等内部资料，为剧组工作人员提供高效检索通道，同时期望在参考信息上既符合科学基础又保持设定一致性，提高剧组工作人员创作效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345026</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345026</guid>
            <pubDate>Mon, 14 Apr 2025 02:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 拟以 30 亿美元收购 AI 编程工具 Windsurf</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社报道称，OpenAI 正与人工智能辅助编程工具 Windsurf（前身为 Codeium）展开收购谈判，交易金额约为 30 亿美元。这一潜在收购将成为 OpenAI 迄今为止最大规模的并购交易，标志着其在 AI 驱动的开发者工具市场迈出重要一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5591fcd5e926e90d56e1521a2184484a0b3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Windsurf 是一款广受开发者欢迎的 AI 编程助手，能够基于自然语言提示生成代码、解释现有代码并执行相关任务。它不仅支持通过插件嵌入主流代码编辑器（如 Visual Studio Code），还提供专为 AI 辅助开发设计的自定义编辑器。Windsurf 自称是首款「代理式」集成开发环境 (IDE)，强调其在自动化和智能化编程流程中的独特优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;成立于 2021 年的 Windsurf（正式名称为 Exafunction Inc.）已累计融资超 2 亿美元，投资者包括 General Catalyst、Kleiner Perkins 和 Greenoaks Capital Partners。2023 年，其在 General Catalyst 领投的 1.5 亿美元融资中估值达 12.5 亿美元，而近期与投资者的谈判显示其估值已升至 30 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;X 平台上的讨论显示，业界对此次收购的反应复杂而热烈。一方面，许多开发者对 OpenAI 整合 Windsurf 的前景表示期待，认为这可能带来更强大的 AI 编程工具;另一方面，部分观点担忧收购可能对其他 AI 编程工具（如 Cursor）造成冲击，尤其是考虑到 OpenAI 此前通过其创业基金投资了 Cursor 的母公司 Anysphere。此外，微软近期对 Visual Studio Code 生态的收紧政策可能为 OpenAI 的收购策略带来变数。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，Windsurf 近期向用户发送邮件，宣布因「本周晚些时候的重大公告」而提供锁定 10 美元/月价格的机会，这一举动被外界解读为收购谈判的间接证据。然而，交易条款尚未最终敲定，谈判仍存在变数或破裂的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次收购若达成，将成为 OpenAI&amp;nbsp;最大规模的并购交易。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345019</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345019</guid>
            <pubDate>Mon, 14 Apr 2025 02:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>xAI 发布新 AI 工具 Grok Studio：可生成文档、代码和浏览器游戏</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;xAI 宣布为旗下 AI 聊天助手 Grok 增加全新功能 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgrok%2Fstatus%2F1912318583532872166&quot; target=&quot;_blank&quot;&gt;Grok Studio&lt;/a&gt;，可以用于编辑和创建文档，以及基础应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19a1c88ab76742bcfab01237646b8b0dc40.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Grok Studio 将在一个单独的窗口中打开，支持生成文档、代码、报告和浏览器游戏。&lt;/p&gt; 
&lt;p&gt;生成代码时，Grok Studio 会在「预览」选项卡中快速向用户展示其运行效果。HTML 代码片段可以运行 Python、C++、JavaScript、Typescript 和 Bash 脚本，也可以在此预览选项卡中查看。所有新项目都会在 Grok 回复的右侧打开。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1424&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/194259_TbOH_2720166.png&quot; width=&quot;1940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;xAI 表示，免费和付费的 Grok 用户都可以在 Grok.com 上使用该功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344972/xai-grok-studio</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344972/xai-grok-studio</guid>
            <pubDate>Sun, 13 Apr 2025 11:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯「元宝」可添加为微信好友：一键解析公众号文章、甚至把它置顶</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;就在刚刚，腾讯 AI 助手「元宝」支持添加为微信好友进行聊天。 &amp;nbsp;你可以和他对话，也可以发链接、文件给他——甚至可以把它置顶 。&lt;/p&gt; 
&lt;p&gt;如下图，在微信直接搜索「元宝」，点击「聊天」进入。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/190446_4eYx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191425_HCo3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1592&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190642_X4B1_2720166.png&quot; width=&quot;806&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;978&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/190707_Op4X_2720166.png&quot; width=&quot;814&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，这是腾讯元宝 APP 入驻微信的 AI 助手，搭载了混元和 DeepSeek 双模引擎，可一键解析公众号文章和任何图片和文档，短评后会发送详解文章，支持对解读内容做各种智能互动，支持陪伴互动。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/191518_XlEd_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1662&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/191457_Jiq2_2720166.png&quot; width=&quot;764&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344970</guid>
            <pubDate>Sun, 13 Apr 2025 11:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国团队自研 AI 图像生成大模型 HiDream-I1 正式开源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;HiDream 智象未来团队宣布正式开源图像生成大模型 HiDream-I1 与交互编辑模型 HiDream-E1。&lt;/p&gt; 
&lt;p&gt;HiDream-I1 在权威榜单 Artificial Analysis 中 24 小时内&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-ouXGp3kyyT7AfFmQ_Y5Cw&quot; target=&quot;_blank&quot;&gt;登顶&lt;/a&gt;&lt;/u&gt;，成为首个跻身全球第一梯队的中国自研生成式 AI 模型，并在图像质量、语义理解、艺术表现三大维度刷新行业纪录，实现图像的多风格生成，涵盖动漫、肖像、科幻等场景。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;984&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/183653_vhQa_2720166.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;目前，设计工具 Recraft 已集成 HiDream 模型，用户 3 步即可实现 「一键出图 + 智能编辑」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175700_50WE_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1&amp;nbsp; 已开源三个版本的模型，分别是：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175710_8HLD_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中 HiDream-I1-Full 是由 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhidreamai.com%2Fhome&quot; target=&quot;_blank&quot;&gt;HiDream.a&lt;/a&gt;i 团队发布的开源图像生成基础模型，具备 170 亿参数，旨在实现高质量的图像生成。该模型采用 Diffusion Transformer（DiT）架构，支持多种风格的图像生成，包括写实、卡通、艺术等，适用于多种创作场景。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心特性&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;卓越的图像质量&lt;/strong&gt;：在多个基准测试中表现出色，HPS v2.1 平均得分为 33.82，优于 SDXL、DALL·E 3 等主流模型&amp;nbsp;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;强大的提示词理解能力&lt;/strong&gt;：在 GenEval 和 DPG-Bench 等评测中，HiDream-I1 的表现优于其他开源模型，展示了其在理解和执行复杂提示词方面的能力。腾讯网+1 阿里云开发者社区-云计算社区-阿里云+1&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;开源且商业友好&lt;/strong&gt;：采用 MIT 许可证，允许用户在个人、科研和商业项目中自由使用生成的内容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;性能评估&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在多个评测中，HiDream-I1 展示了其强大的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DPG-Bench&lt;/strong&gt;：在整体、实体、属性等多个维度上得分领先，展示了其在图像生成质量方面的优势。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GenEval&lt;/strong&gt;：在单目标、双目标、计数、颜色等任务中表现优异，反映了其对提示词的准确理解和执行能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HPS v2.1&lt;/strong&gt;：在动画、概念艺术、绘画、照片等风格的图像生成中，HiDream-I1 的得分均高于其他主流模型，展示了其多风格生成的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175722_YQIr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175731_9IFw_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/175741_2jbr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;HiDream-I1-Full 模型整体采用 MIT 协议开源，可自由商用，但部分依赖组件（如 LLaMA3 编码器）需遵守各自协议，商用前应留意其具体限制。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344955</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344955</guid>
            <pubDate>Sun, 13 Apr 2025 09:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节 AI Lab 将全部并入 Seed</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 科技评论独家获悉，字节 AI Lab 即将全部收归 Seed 团队下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节 AI Lab 是 Seed 成立之前字节主要的 AI 研发部门，目前由李航管理，自 2024 年开始向 Seed 时任负责人朱文佳汇报。今年 2 月下旬，原 Google DeepMind 副总裁吴永辉入职字节，成为 Seed 基础研究负责人。此后李航的汇报对象变为吴永辉。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节 AI Lab 成立于 2016 年，最初由微软亚洲研究院前常务副院长马维英负责，直接向张一鸣汇报。 AI lab 目前有多个子团队，包括机器人、AI4S 等方向，几乎覆盖人工智能领域所有前沿技术研究。2018 年其团队规模达到 150 人，为字节跳动 AI 研究的核心部门。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI Lab 主要研究重点是开发为字节跳动内容平台服务的创新技术，字节推荐算法、短视频特效等功能均脱胎于此。其研究成果应用于今日头条、抖音等产品，是支持抖音成长为国民级应用的基石，并奠定了当时字节在国内 AI 领域的领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;随着抖音、TikTok 占据绝对优势的市场地位，流量商业化成为字节面临的 Top 级问题，AI Lab 在字节内部重要性下降。2020 年，AI Lab 定位从集团级前瞻性项目转为技术中台，为字节商业化团队业务提供支持，马维英的汇报对象也从张一鸣变为抖音负责人张楠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2020 年年中，马维英离开字节，AI Lab 负责人一职由李航接任至今。之后团队重组，2023 年开始，AI Lab 下属负责大语言模型的 NLP 组及开发视频生成模型的 PixleDance 被先后转入 Seed 之下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时为了应对新一轮大模型竞争，字节决定回归「始终创业」的价值观，建立独立的新组织，于是加快筹建了独立于原有组织架构的 Flow 和 Seed，前者做 AI 产品，后者做大模型研发。截至 2023 年底，两者已成为与抖音、TikTok、火山引擎等字节各大业务平级的组织。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Seed 自成立就在不断吸纳来自字节内外的人才。除收拢搜索、AML、AI Lab 等内部部门中大模型方向人才外，对外也在积极争抢人才。以面向应届博士的 Top Seed 招募计划为例，字节会给优秀候选人 3-1 职级，薪资不低于百万元。截至 2024 年底，字节 AI 研究者中超 40％比例是近两年加入的新人，对人才的渴求和重视程度可见一斑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据 AI 科技评论调查，加入字节以来，吴永辉已在字节署名三篇论文，均在强化学习方向。吴永辉于上月在 Seed 内部新建虚拟小组、缩短了汇报流程，创建一个更扁平的汇报体系，此次 AI Lab 将全部并入 Seed，也是吴永辉调整内部组织架构的一个重要举措。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344946</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344946</guid>
            <pubDate>Sun, 13 Apr 2025 09:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Notion Mail 正式发布：AI 驱动邮箱新体验</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Notion 正式推出电子邮件服务 Notion Mail，首发登陆 macOS 平台，iOS 和 Android 版即将上线。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1140&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0416/165124_3l5R_2720166.png&quot; width=&quot;2124&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 并非要取代 Gmail，而是作为重新设计的邮箱前端，提供独特的邮件管理体验。其核心为高度模块化系统，用户可自定义收件箱配置，并整合了丰富的 AI 功能，如智能文件夹、自动分类、快速回复、写作改进及智能会议安排等。产品与 Notion Calendar 无缝衔接，核心 AI 功能提供免费使用限额，无限制需订阅付费。目前仅支持英文，未来将扩展至 13 种语言。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0416/165012_T6gr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Notion Mail 主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail&lt;/a&gt;&lt;br&gt; 下载地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.notion.com%2Fproduct%2Fmail%2Fdownload&quot; target=&quot;_blank&quot;&gt;https://www.notion.com/product/mail/download&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/344936/notion-mail</link>
            <guid isPermaLink="false">https://www.oschina.net/news/344936/notion-mail</guid>
            <pubDate>Sun, 13 Apr 2025 08:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>