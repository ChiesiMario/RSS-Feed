<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 11 Mar 2025 02:41:00 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>苹果计划对 iOS、iPadOS 和 macOS 系统外观进行大幅重新设计</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-10%2Fapple-readies-dramatic-design-overhauls-for-ios-19-ipados-19-and-macos-16&quot; target=&quot;_blank&quot;&gt;据彭博社报道&lt;/a&gt;&lt;/u&gt;，苹果公司计划于今年晚些时候对 iOS、iPadOS 和 macOS 进行重大界面设计更新。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;外观设计&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;本次更新重点旨在优化用户体验并提升不同设备间的操作一致性，整体视觉将基于 visionOS 的设计理念进行延展，更新内容将涵盖操作系统的核心视觉元素，包括图标、菜单、应用程序、窗口样式及系统按钮等，目标是通过简化交互逻辑让用户更便捷地使用设备。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0311/103415_RHy0_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;系统功能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;此次更新仅限于交互设计方面，苹果无意合并其不同操作系统的底层架构，仍将保持 iOS、iPadOS 和 macOS 的独立性。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0311/103734_4yif_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;发布时间&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;预计这套全新的系统体系，将在今年 6 月的 WWDC 上发布，并体现在 iOS 19、iPadOS 19、macOS 16、visionOS 3 等系统中。&lt;/p&gt; 
&lt;p&gt;这将是 2013 年 iOS 7 以来苹果最大型的操作系统更新，也许将根本性地改变 iOS 系统的范式，你会期待这次更新带来哪些新功能？欢迎在评论区留言讨论。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338104/apple-ios-ipados-macos-design-overhaul</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338104/apple-ios-ipados-macos-design-overhaul</guid>
            <pubDate>Tue, 11 Mar 2025 02:30:53 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>广东出台 12 项措施支持 AI 与机器人产业创新发展</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;广东省人民政府办公厅印发推动人工智能与机器人产业创新发展若干政策措施（下文简称「《措施》」）。涵盖技术攻关、企业培育、应用场景、产业集聚、重点项目、数据要素、开源生态、人才、投融资、体系建设、交流平台、监管机制 12 个细分方面。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-221cf529afc31d4c9d4cc8031dbfc3f0510.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;一、支持关键核心技术攻关。&lt;/strong&gt;支持企业、高校、科研院所等各类创新主体开展联合攻关，围绕人工智能与机器人产业链上下游组建产业创新联盟，加快构建全过程创新链。组织实施省重点领域研发计划「新一代人工智能」「智能机器人」等旗舰项目、重大专项，在人工智能与机器人领域部署一批攻关任务。对国家科技重大专项符合省级配套条件的人工智能与机器人领域重点项目，省财政按规定给予配套奖励，单个项目省级配套金额超 1 亿元（含）的，按「一事一议」方式研究给予支持。创建人工智能与机器人领域制造业创新中心，对符合条件的国家级、省级制造业创新中心，省财政按规定分别给予最高 5000 万元、1000 万元的资金支持。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;二、培育优质企业。&lt;/strong&gt;支持企业整合人工智能与机器人产业链、创新链资源，推动集聚发展，整体提升产业链协同创新能力。构建以单项冠军企业、专精特新中小企业为骨干的人工智能与机器人领域企业梯次培育体系。对该领域获评国家级单项冠军企业、专精特新「小巨人」企业，在落实省级支持政策的基础上，强化省市联动，鼓励地市给予奖励，省财政进一步按照地市奖励资金 1∶1 予以激励，调动地市积极性，对国家级单项冠军企业奖励总额度最高 300 万元，对国家级专精特新「小巨人」企业奖励总额度最高 200 万元。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;三、打造应用场景。&lt;/strong&gt;建立省级跨部门协调机制，压实「管行业管人工智能应用」责任，实施「人工智能+」行动，在教育、医疗、交通、民政、金融、安全等领域广泛拓展应用。组织开展「机器人+」行动，围绕工业、农业、城市管理、医疗、养老服务、特种作业等领域，深入挖掘开放应用场景。鼓励各地市挖掘开放各类应用场景，招引企业打造一批典型案例。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;四、推动产业集聚发展。&lt;/strong&gt;依托重点产业集群开展人工智能赋能新型工业化试点，对研发工业领域大模型和应用解决案例给予支持，每年择优支持不超过 10 个标杆案例，每个给予最高 800 万元奖励，推动制造业企业智能化转型。发挥各类人工智能与机器人创新联盟、协会等行业组织作用，促进产业链快速整合。发挥高校、科研院所优势，推动创新成果产业化。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;五、支持重点项目建设。&lt;/strong&gt;统筹省市资源对全省人工智能与机器人重点项目开通「绿色通道」，依法依规加快项目用地、环评、节能、用林等审批，省市联动保障固定资产投资额 5000 万元以上的先进制造业项目。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;六、丰富数据要素供给。&lt;/strong&gt;构建高质量人工智能数据集和语料库，形成一批高质量数据产品和服务。支持发展数据交易市场，推动广州、深圳数据交易所打造国家级数据交易场所。支持开展「数据要素×」行动，深化数据要素应用赋能。支持加快培育数据企业，依托优势打造广东数据要素集聚发展区。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;七、完善人工智能与机器人开源创新生态。&lt;/strong&gt;支持企业、高校、科研院所、行业协会通过技术协作，联合共建面向人工智能与机器人领域的开源社区、开源生态中心和相关公共服务平台，提供技术交流共享、生态推广培育、算力调度、开放性行业大数据训练库、标准测试数据集、大模型评测开放服务、测试验证等服务。每年择优支持不超过 5 个符合条件的开源社区和开源生态中心，按不超过其上一年度审定运营费用的 30%，给予最高 800 万元资助。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;八、引育高水平领军人才。&lt;/strong&gt;围绕人工智能与机器人产业的发展需求和重点任务，支持企业引进培育一批具有突出技术创新能力、善于解决复杂工程技术问题的创新领军人才、青年拔尖人才。支持高校围绕人工智能与机器人领域开展高水平学科建设，进一步加强人才自主培育力度，加快打造人工智能与机器人产业人才大军。鼓励相关地市出台人工智能与机器人产业人才专项政策。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;九、加强产业投融资。&lt;/strong&gt;在省产业发展投资基金集群中设立人工智能与机器人产业基金，联合相关地市引导社会资本围绕人工智能与机器人产业链关键核心领域，着力投早、投小、投长期、投硬科技，创新基金管理机制，强化以尽职合规责任豁免为核心的容错机制。引导银行等金融机构为人工智能与机器人企业提供全生命周期的金融服务，丰富金融产品供给，加大对人工智能与机器人贷款贴息和风险补偿的政策支持力度。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;十、推进标准体系建设。&lt;/strong&gt;对于企业、科研院所围绕人工智能与机器人产业主导制定国际标准、国家标准、行业标准的，分别给予每项最高 50 万元、30 万元、15 万元的资助；对承担国际标准化组织技术委员会，全国、广东省专业标准化技术委员会秘书处的，分别给予每项最高 100 万元、30 万元、10 万元的资助。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;十一、打造高端交流平台。&lt;/strong&gt;举办「众创杯」人工智能与机器人专业创新创业大赛，在粤港澳大湾区博士博士后创新创业大赛、「创客中国」中小企业创新创业大赛暨「创客广东」大赛、「越来越好」国际设计大赛中设立人工智能与机器人有关专项赛。支持地市围绕人工智能与机器人高质量发展，打造具有国际影响力的学术会议、交流活动、创新创业大赛等活动。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;十二、建立包容审慎监管机制。&lt;/strong&gt;探索创新人工智能与机器人「监管沙盒」等包容审慎监管模式，营造鼓励创新、大胆试错的制度环境。加大财政资金对人工智能与机器人领域相关软课题研究的支持力度。完善生成式人工智能发展和管理机制，加快建设粤港澳大湾区生成式人工智能安全发展联合实验室。支持人工智能与机器人安全性相关的检测认证平台建设，提供安全风险、伦理道德等方面的评估认证服务。加快推动人工智能与机器人领域立法工作，为人工智能与机器人产业发展提供制度保障。&lt;/p&gt; 
 &lt;p style=&quot;color:#424242; margin-left:0; margin-right:0; text-align:justify&quot;&gt;本政策措施有效期至 2027 年 12 月 31 日。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338097</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338097</guid>
            <pubDate>Tue, 11 Mar 2025 02:10:53 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>美国要开听证会调查中国传统芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美国贸易代表办公室将在当地时间 11 日就中国生产的传统芯片（成熟制程芯片）举行听证会，探讨进一步提高相关关税的可能性。据美媒报道，这些芯片被广泛应用于汽车、洗衣机和电信设备等日常用品中。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次调查在美国前总统拜登任期内发起。美国商务部去年 12 月表示，含芯片的美国产品中，有 2/3 使用中国芯片；超过半数美国公司不知道其芯片的来源，其中还包括一些国防工业企业。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国社科院美国问题专家吕祥 10 日在接受《环球时报》记者采访时表示，目前中国在存储芯片方面的产能和技术都在显著提高，美国试图限制中国的出口和产能发展，但中国生产的高性能芯片在全球市场具有很大优势，目前美国处于两难的局面。 「对中国增加关税会损害中国对美出口是事实，但近几年我们对美出口的依赖程度也在降低。」吕祥表示。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《纽约时报》去年在报道这一调查时称，拜登政府近年来颁布了一系列出口管制措施，试图扼杀中国制造最先进计算机芯片的能力，但尚未针对中国生产传统芯片的能力采取太多措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报道称，中国政府和企业为这类芯片的生产投入了大量资金，芯片制造商在技术上取得了进步，进而吸引新客户、吸收有关制造的新知识。「中国生产的芯片也将让美国更难控制全球的半导体贸易。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;华泰证券今年 2 月发表专题研究称，过去 5 年，在地缘政治等外部因素和中国国内终端及设计企业的内生推动下，中国芯片代工行业尤其是成熟制程经历快速发展。其预测 2024-2027 年中国 12 寸成熟制程产能将保持年均 27% 的快速扩张，到 2027 年占全球的份额将达到 47%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据中国海关总署统计，2024 年中国集成电路出口 1595 亿美元，同比增长 17.4%，创历年新高。2025 年前两个月，中国集成电路出口 1804.4 亿元人民币，同比增长 13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;路透社报道称，美国对中国传统芯片的调查听证会在中美贸易关系紧张之际举行，可能会进一步加剧双方的经济摩擦。这项调查根据 1974 年的《贸易法》第 301 条进行，「特朗普于 2018 年利用该法对大量中国进口产品征收高额关税，引发美中之间长期贸易争端」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;韩国《每日经济》称，美国保守派智囊团和信息技术、电子产业相关团体以及国家安全、半导体相关研究所人士等将出席听证会。报道称，如果国家安全相关团体的意见得到认同，那么对中国半导体企业的追加限制「很有可能成为现实」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《每日经济》还称，韩国芯片企业也在密切关注听证会进展。三星电子在中国西安，SK 海力士在无锡和大连设有大规模半导体工厂，虽然主营业务与美国本次涉华调查的对象并不完全一致，但大多数人认为不能掉以轻心，因为美国如果对中国产传统芯片征收高额关税，有可能对韩国半导体企业也施加压力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;（环球时报，记者，李迅典）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338095</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338095</guid>
            <pubDate>Tue, 11 Mar 2025 02:04:53 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>周鸿祎谈 996 加班：人工智能发展得这么快，想有成就还得加班</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;996 工作制指的是早上 9 点上班、晚上 9 点下班，中午和傍晚休息 1 小时（或不到），总计工作 10 小时以上，并且一周工作 6 天的工作制度，代表着中国互联网企业盛行的加班文化。&lt;/p&gt; 
&lt;p&gt;日前，360 集团创始人周鸿祎谈 996，表示加班肯定要自愿才行，你只有工作比别人更努力，才能取得更好的成绩。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e34eb8a47acc13b9240cb9b8c0ea1bc69a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「我们确实不想加班，但是人工智能（发展得这么快），要想取得成就还是得加班，我们还是主张热爱这个事自愿加班，不热爱这个事（就不要加班）。」周鸿祎说。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于当年是不是也加了很多班的问题，周鸿祎回答道：「我现在还每天都加很多班」。&lt;/p&gt; 
&lt;p&gt;经济学家向松祚曾提出，如果工作没效率，一天工作 24 小时也没用；如果选择的是热爱的工作，感到开心、达到自身最好的状态，就不存在 996 或工作很累的问题了。&lt;/p&gt; 
&lt;p&gt;此前，联想集团董事长兼 CEO 杨元庆表示：「在联想，我们一直强调的是工作与生活的平衡，旗帜鲜明地反对 996。员工辛勤工作的目的是什么？是为了满足我们每一个人对美好生活的向往这样一个最终目标」。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/337895&quot; target=&quot;news&quot;&gt;大疆强制员工晚上 9 点必须下班，HR 赶人清场&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338040</guid>
            <pubDate>Wed, 05 Mar 2025 12:05:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里研究院：DeepSeek 是对开源大模型价值的强有力支持</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里研究院发布了一篇文章，以 DeepSeek 为例来讨论未来开源模型的风险治理改革与创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;文章内容指出，DeepSeek 以相对较小成本实现高性能大模型的发展创新，不仅证明了人工智能技术发展路径的多元性和动态性，更重要的是推动开源大模型发展实现了新的跃迁。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 DeepSeek 之前，围绕人工智能是否应开源的争议日趋激烈，在此背景下，DeepSeek 是对开源大模型价值的强有力支持：正是站在 LLaMa、千问等开源大模型的基础上，DeepSeek 通过更巧妙的工程设计挖掘了大模型的内在潜力、实现了性能上的超越。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;但另一方面，如果开源需要真正成为大模型的主导性发展模式，不可回避的另一重要问题仍然是开源大模型风险治理的改革，即我们能否创新开源治理机制以回应大模型开源后所可能引发的风险担忧。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;一、DeepSeek 开源模型风险：现有评估及无额外风险的结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 开源模型的发布同时也引发了海外对其安全风险的关注和讨论，众多海外国家和组织针对 DeepSeek 开源模型进行了针对国家安全、数据安全、版权风险和安全漏洞等方面的安全影响评估并提出了治理措施或建议。例如，美国云安全平台 Wiz Research 发现 DeepSeek 关联数据库存在泄露大量后端数据、操作细节等敏感信息的风险，该团队立即向 DeepSeek 披露了此问题，并提出人工智能公司应实施与公共云提供商和主要基础设施提供商同等的安全措施。[1]人工智能安全平台 Hiddenlayer 对 DeepSeek-R1 的安全评测结论指出，该模型存在无法抵御简单越狱攻击、思想链 (CoT) 推理可能会导致信息泄露等安全漏洞，建议确保部署环境的可控性再使用该开源模型。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;从评估结果来看，DeepSeek 开源模型的风险主要集中在数据安全和安全（safety）漏洞两个方面。DeepSeek 开源模型带来的数据安全风险主要表现为敏感数据的攻击泄露（关联数据库泄露 DeepSeek 内部敏感信息且攻击者易访问）以及思维链数据泄露（CoT 推理引入中间步骤可能会无意泄露敏感信息、内部逻辑以及模型训练中使用的专有数据等）。前者主要为数据库等基础设施的安全风险，这属于用户-模型数据交互链路中执行环境的特定环节，需要采用系统化的视角来进行安全加固，并非模型本身的固有安全漏洞。（参考阅读：《治理之智｜用户-模型数据交互安全：挑战、应对及思考》）后者则并非 DeepSeek 独有的问题，目前所有的推理模型技术都面临此类 CoT 数据泄露的数据安全风险。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 开源模型存在的安全漏洞风险则包含网络安全、内容安全、偏见与歧视、代码安全、CBRN（化学、生物、放射和核能）安全等方面。根据海外多个人工智能安全平台及研究团队（Enkrypt AI、Robust Intelligence 等）的安全评估和红队测试结果，DeepSeek-R1 模型在在部分测试项目上展现出相对与其他主流模型更高的安全风险，例如生成不安全代码的可能性比 OpenAI o1 高出 4 倍，偏见歧视内容诱导的成功率高达 83% 且比 Claude-3 Opus 高出 3 倍，生成 CBRN 相关内容的脆弱性是 OpenAI o1 和 Claude-3-Opus 的 3.5 倍等。但细究其评测结论的分析过程，其核心原因在于各国在安全风险优先级、模型输出内容管理要求、容忍度基准等方面存在差异性，导致各国对模型的安全表现评价各不相同。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;整体来看，排除评价标准差异化因素的影响，各国评估并未发现 DeepSeek 开源模型及其应用会造成额外的风险。换言之，DeepSeek 作为大模型技术并未带来相比于其他大模型的更多风险；但作为开源大模型，考虑到开源将降低使用门槛并让模型更加普及化，开源模型生态中的滥用误用情况则可能变多。此时开源模型并非主要的风险源，总体安全风险反而将受到复杂的上下游任务链参与方以及基础设施、系统拦防和使用场景等多重因素影响，而这便要求风险治理机制的进一步完善与改革。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;二、建立基于增量风险的开源模型风险治理机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源模型带来了技术普及化和应用多样化，但价值与风险并存的特征对于如何判断开源模型的风险特点、采取何种平衡性的治理方案提出了挑战。目前对模型开源的风险有两类判定标准，并相应形成了两类治理思路。一类考虑开源模型的「全量风险」，采取全域管控+开源特别豁免的平衡机制。「全量风险」机制以欧盟《人工智能法案》为代表，以事前风险防范为核心，在统一的综合性立法中通过分类分级方式地识别开源模型所有可能存在的风险，包括纳入暂时没有实际证据支撑但未来可能出现的感知风险，当出现足够证明不具有需要单独管制必要性的证据时再予以事后排除。而考虑到开源软件对于有效促进技术创新的价值，欧盟针对开源模型进行单独定义并设置复杂的「开源豁免+豁免例外」规则机制，将开源模型完全纳入法律规制之后再进行有限度的利益平衡。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一种治理思路是分析模型开源独有的「增量风险」，并采取有针对性的管控机制。「增量风险」指与来自现有其他可比技术的风险相比，开源模型是否会产生新的独特风险，并因此要求被特殊监管。2024 年 7 月底，美国国家电信和信息管理局（NTIA）发布报告，对于开源模型的「增量风险」的判断提供了与闭源模型、与其他现有技术，以及与现有开源模型相比较的三个参考标准。换言之，只要与这些参考标准相比没有出现新风险，即不属于被纳入监管范畴的增量风险。值得注意的是，上述标准将对开源模型「增量风险」的判定设置了较高评估门槛，而对于需要监管介入的增量风险判断将则强调证据支撑和科学审慎。在广泛调研各类开闭源模型并征求各方意见的基础上，NTIA 认为现有研究和证据无法完全满足上述三个风险评估标准，即开源模型没有需要额外进行单独管制的「增量风险」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;比较「全量风险」和「增量风险」两种机制不难发现，以「增量风险」为核心的开源风险治理整体倾向于事中事后的风险管控，可通过调整风险阈值来实现开源模型自由普惠和安全治理的利益平衡，而具有严谨证据支持的比较过程也能够排除认知风险风险的不合理影响。正因为此，本文认为基于「增量风险」的开源模型治理机制更能精确匹配模型开源的技术应用特征，有利于建立对于开源模型风险的客观认知，能够避免基于对未知风险的恐慌而采用非理性的过度规制，从而防止对开源价模型的价值发挥产生不当的阻碍效应。不过这并不代表「增量风险」管控机制就已能应对开源大模型风险治理的所有挑战，开源大模型所涉产业链条的复杂性使得「生态治理」可能是未来更需重视的改革理念和方向。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;三、构建大模型开源生态的协同治理体&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;开源大模型的主要安全风险在于误用滥用，因此安全风险的治理应对必须要考虑模型开源后的利益相关方，从而即引出了「生态治理」的改革理念。大模型开源生态具有产业链条多样化、参与主体多元化的特点，各方风险的控制能力以及针对误用滥用的防范责任有所差异。开源模型生态治理既不能完全放任，也不能仅将治理重心简单地聚焦于开源模型本身，而是要综合判断开源模型生态的结构对滥用误用风险的影响，采取合理的责任分担机制促进各方有效的治理协同合作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一方面，应基于科学证据分析开源模型生态的风险扩散特征，根据开源模型生态链分工机制分析开源模型滥用误用风险的产生和传递过程，合理划定各类主体的责任边界。在近期发布的《双用途基础模型滥用风险管理指南（NIST AI 800-1）》中，美国 NIST 明确了开源模型的风险不能仅由模型研发方承担，模型应用生态中的直接参与方（包括云计算提供方、模型托管平台、下游模型使用部署及应用开发者、分发平台、三方评测审计方、用户公众等）以及间接参与方（学术机构、外部研究者和政府机构等）都需要根据自身角色承担相应的责任，通过多方合作协同的方式有效管控模型应用中的风险。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;另一方面，应提升开源模型生态的风险治理能力，建立对开源模型生态的国际信任。目前对于开源人工智能安全的认知还存在着碎片化的问题，各国针对 DeepSeek 开源模型的评估结果凸显了模型安全风险的认知存在差异、模型安全基准在全球范围内并未对齐、测试标准不统一以及评估基准不够客观和缺乏公信的现实问题，相应的模型安全能力水平也不会对齐。在开源模型生态全球化发展的背景下，各国模型安全能力分布不均、资源不足的现状会对模型能力的普及和应用的拓展造成影响，引发对开源模型不当的限制。对此需要进一步推动不同主体在共商共享过程中共同探索，促进关于模型安全能力和资源的增长和积累，从而提升个体及整体层面的安全水平。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第三，应坚持「人工智能安全作为公共产品」的基本理念，推动安全公共知识的积累和认知协同。可以进一步利用开源模型生态的透明度和包容性，将安全作为开源模型生态构建的重要目标，促进多方参与和共享的协同治理模式，通过鼓励通过开源推动各方主体参与到模型安全能力的共同建设中，支持开放透明的模型研发应用，推动开源社区与学术机构和公众用户进行共同监督，在降低信息不对称的同时，在专业知识、风险识别和监测、应急响应等方面加强安全能力建设，促进监管、产业和社会公众对安全的人工智能建立信任。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338032</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338032</guid>
            <pubDate>Wed, 05 Mar 2025 10:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>稳定且高性价比的大模型存储：携程 10PB 级 JuiceFS 工程实践</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在过去两年多的时间里，随着 AI 大模型的快速发展，JuiceFS 在携程内部得到了越来越多 AI 用户的关注。目前，携程通过 JuiceFS 管理着 10PB 数据规模，为 AI 训练等多个场景提供存储服务。&lt;/p&gt; 
&lt;p&gt;本文将介绍携程如何使用 JuiceFS，以及基于 JuiceFS 实现的关键管理能力，包括多租户权限管理、计费功能、故障排查和监控等方面。同时，还将分享 3 个生产环境中的排障案例。最后，我们对比了 JuiceFS 与极速 NAS 的性能与成本，JuiceFS 在大多数业务场景中能提供与极速 NAS 接近的性能，同时成本仅为极速 NAS 的十分之一。&lt;/p&gt; 
&lt;h2&gt;01 JuiceFS 在携程的应用：从冷存到 AI 场景&lt;/h2&gt; 
&lt;p&gt;携程早在 2022 年就已经开始接入 JuiceFS，当时的主要目的是替代 GlusterFS，以提高其列表性能，服务 DBA，处理偏冷的数据。此外，这种解决方案能够与 OSS 的生命周期和运行策略相搭配，有效地降低 DBA 处理冷数据的成本。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fzh-cn%2Fblog%2Fuser-stories%2Fxiecheng-case&quot; target=&quot;_blank&quot;&gt;点击此处查看早期案例&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;随着 AI 应用的需求变化，尤其是在 AI 模型训练过程中，存储需求开始转向大带宽读写和频繁的写入操作，如模型的 checkpoint 保存、数据分发及存储等。&lt;/p&gt; 
&lt;p&gt;AI 这个场景最大的痛点在于，携程的训练和推理系统被分开管理，导致存储架构非常割裂。训练过程中产生的模型需要通过复杂的上传和下载流程来分发到其他平台，这个过程显得非常低效且繁琐。&lt;/p&gt; 
&lt;p&gt;目前的做法是，训练平台和推理平台通过 JuiceFS CSI 挂载相同的卷，但对权限进行区分：训练平台具备读写权限（ReadWriteMany），而推理平台则仅具备只读权限（ReadOnlyMany）。对于只读负载，预读功能可通过 JuiceFS 中的相关参数进行调优，以提高性能。&lt;/p&gt; 
&lt;p&gt;此外，AI 应用面临的另一个问题是存储性能的瓶颈，尤其是在读性能方面。AI 推理任务需要较高的带宽，而许多存储产品的带宽表现有限。与 OSS 配合使用时，存储带宽可以根据数据量的增加而自动扩展。例如，OSS 为用户提供的带宽与数据流量成正比，数据使用量越大，分配的带宽也越大，这种设计使得 AI 用户在大规模数据读取时能够获得所需的带宽。&lt;/p&gt; 
&lt;h2&gt;02 JuiceFS 部署架构 &amp;amp; 关键能力&lt;/h2&gt; 
&lt;p&gt;我们搭建的部署架构与社区大部分的推荐方案一致，采用了 TiKV + OSS 的组合。具体来说，架构由以下几个核心组成部分构成：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;TiKV &amp;amp; PD 作为元数据引擎&lt;/strong&gt;：TiKV 支持分布式架构和事务处理，具备出色的性能。通过跨 IDC 部署，确保系统的高可用性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ali OSS 作为存储底座&lt;/strong&gt;：结合专线网络提供大带宽传输能力。同时，OSS 的自动转冷功能使得系统在成本控制上具有优势，性价比高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;JuiceFS 客户端的定制化&lt;/strong&gt;：对 JuiceFS 客户端，进行了针对性修改，特别是在内部管理功能上，例如自助服务、计费系统、控制限速等。我们还进行了优化，以便用户在 Kubernetes (k8s) 环境中能够方便地使用。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a43c9b763a7aecfec8735cb15f83d8e8a2c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;关键能力 1：多租户权限管理与计费&lt;/h3&gt; 
&lt;p&gt;我们要为多个用户群体提供服务，包括 AI、DBA 等不同领域的用户。为了保证资源的合理使用，我们为每个申请用户提供了独立的 token，用户需使用 token 进行挂载，以此实现资源的隔离。&lt;/p&gt; 
&lt;p&gt;为了控制成本，我们对用户的使用进行严格监控和计费。我们在每个卷（Volume）级别进行实时监控，并按小时生成账单，确保每个用户的使用情况得到清晰记录和计费。&lt;/p&gt; 
&lt;p&gt;在 Kubernetes 环境中，很多用户选择使用动态存储类来实现存储的自动化调度。但为了实现自助申请并便于计费，我们采用了静态 PVC。这种方式可以方便地关联卷，并与自动化流程相结合，确保每个卷的费用被精确记录。在 JuiceFS 中，每个卷都记录了一个全局变量（&lt;code&gt;totalUsedSpace&lt;/code&gt;），该变量用于追踪与计费相关的使用情况。&lt;/p&gt; 
&lt;p&gt;虽然社区也支持对子目录的计费，但对于我们初期开发而言，按卷级别计费相对简单和高效。&lt;/p&gt; 
&lt;h4&gt;计费原理&lt;/h4&gt; 
&lt;p&gt;携程内部使用的工具 FinOps 可以定期拉取阿里云费用中心的数据，以获取每个云产品的费用信息。通过这个工具，我们能够实现对各项云服务费用的实时监控。&lt;/p&gt; 
&lt;p&gt;在使用这个工具时，当申请 JuiceFS 卷时，需要进行关联，卷的创建会与相应的用户关联。为了有效管理，我们每小时都会进行一次打点监控，记录空间使用情况、文件引用数量等指标，并将这些数据发送到 FinOps 系统。然后，FinOps 会对每个卷进行费用分摊，将 OSS 的费用按比例分摊到每个卷的所有者。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6a3de56cc1a1d026ce80962d0f93f6435c5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;费用异常：存储泄露&lt;/h4&gt; 
&lt;p&gt;在日常运营中，主要关注的是费用的上升情况和费用占用的趋势。这些费用数据能够反映出是否存在异常问题。在一次费用分析中，我们遇到了一个典型问题：通过 JuiceFS 统计的使用量没有明显变化，但整个 OSS 的成本却有所上升。经过进一步分析，确认阿里云的收费政策和 OSS 单价并未变化。然而，分摊出去的单价却上升了，导致了整体费用的增加。&lt;/p&gt; 
&lt;p&gt;在检查 JuiceFS 的计费统计和阿里云 OSS 上的文件量统计时，我们发现两者之间存在显著的差异。OSS 提供了一个存储空间清单功能，可以查看当前整个 bucket 下所有文件的使用量。&lt;strong&gt;我们通过使用 OSS 清单对数据进行聚合，发现 JuiceFS 统计的用量远低于 OSS 统计的用量。这导致了用户在 JuiceFS 中的存储空间使用量被低估，从而使得 OSS 存储空间的费用被错误地分摊给其他用户，进而导致其他用户的单价上升&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;这一差异的根本原因在于 JuiceFS 删除文件的实现方式。对于大量删除的文件，JuiceFS 使用软删除策略标记文件为已删除，但后台会逐步删除这些数据。由于在使用过程中禁用了所有后台任务，导致用户的删除操作产生了许多待处理（pending）和失败的删除请求。&lt;/p&gt; 
&lt;p&gt;进一步分析后，我们发现 JuiceFS 存在两种数据泄露情况：一是待处理删除（pending delete），二是回收站（trash）中的数据。为了应对这一问题，我们设置了一个额外的监控服务，每隔 6 小时扫描一次潜在的数据泄露。如果发现泄露数据，我们会启用一个专门的客户端，取消禁用后台任务，并清理这些泄露的数据。&lt;/p&gt; 
&lt;h4&gt;功能禁用&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;禁用回收站&lt;/strong&gt;：回收站功能在很多用户场景下并不需要开启。回收站是后台任务，需要额外的资源进行清理，尤其是在使用 TiKV（如 RocksDB 数据库）的情况下，回收站会对数据库性能造成一定压力，尤其在出现突发的大规模删除时。因此，我们选择不启用回收站功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;禁用备份元数据（BackupMeta）功能&lt;/strong&gt;：JuiceFS 提供了元数据备份功能，但在数据量较大时，逻辑备份速度较慢，无法满足我们的需求。为了提高备份效率，我们更倾向于使用 TiKV 提供的官方备份工具来进行数据库备份，这样可以更好地支持大规模数据的备份需求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;关键能力 2：日志收集与管理，提高排障效率&lt;/h3&gt; 
&lt;p&gt;我们使用内部工具将 TiKV 和 PD 中的日志收集到 ClickHouse，通过 Kafka 传输并最终存储到 ClickHouse 。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-55cdfb30ecc15697257048edf63d136a158.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过这样的日志收集，我们能够及时捕捉集群中的错误信息。许多情况下，集群可能会产生大量的错误，但用户并未察觉，且从客户端来看，性能似乎并未受到显著影响。然而，经过多次事故的处理，我们发现很多问题都是通过分析 TiKV 的日志来发现的，从而能在早期阶段及时解决潜在问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-97246dec5d4374e9451ce2ac7f6d3f3e433.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;关键能力 3：监控&lt;/h3&gt; 
&lt;p&gt;在监控方面，我们挑选了 TiKV 官方提供的一些关键指标来构建自有的监控系统。TiKV 和 TiDB 的整体监控体系相对复杂，官方提供的监控看板包含了大量信息，显得过于繁杂。刚接手时，这一部分确实没有很清晰的理解。&lt;/p&gt; 
&lt;p&gt;在实践过程中，我们最终选取了几个核心的指标，以便更有效地监控 TiKV 的性能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能相关指标：包括 CPU、内存使用情况以及热点读写。&lt;/li&gt; 
 &lt;li&gt;PD（相关指标：重点监控 Region leader 分布与调度情况。&lt;/li&gt; 
 &lt;li&gt;GC（垃圾回收）相关指标：包括 GC 时间和 MVCC 删除等信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b682cf0d76ef22368be478f44fb1433ee5c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 JuiceFS 客户端的监控中，我们通过 Prometheus 接口获取 CSI 的指标。然而，对于普通挂载情况，特别是在用户自行部署 JuiceFS 的机器上，我们无法直接控制或访问这些数据。因此，我们使用 JuiceFS 提供的 &lt;code&gt;state&lt;/code&gt; 文件来采集简化的监控指标。大部分场景中，state 文件已经能够覆盖我们需要的指标。为了高效采集数据，我们在每台机器上部署了一个 DaemonSet，通过该工具定期读取 &lt;code&gt;state&lt;/code&gt; 文件并进行监控。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1bc3d5bee5c45a51173ace7a9b8f2d00d63.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;客户端监控看板包括以下内容：CPU 和内存使用情况、启动时间和启动参数、Golang 性能指标（如堆内存中的活跃对象）、以及读写性能（包括缓冲区和块缓存的使用情况）。除了关注客户端的读写性能外，更多时候我们更侧重于整体带宽情况。&lt;/p&gt; 
&lt;h3&gt;关键能力 4：元数据备份&lt;/h3&gt; 
&lt;p&gt;在 TiKV 生态中，存在两个不同的 br 备份工具。TiKV 文档中提到的 br 工具只能备份通过 rawKV API 写入的数据，无法备份通过 txnKV API 写入的数据。&lt;/p&gt; 
&lt;p&gt;与此不同，TiDB 仓库中的 br 工具更侧重于备份 TiDB 数据。这个工具提供了 backup txn 子命令，专门用于备份通过 txnKV API 写入的数据。&lt;strong&gt;最终，我们采用了 TiDB 的全量快照备份方案，每日进行定时备份&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-320d9ae7c49c5f0edfc5a778bbdd0cc5228.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在使用 TiKV 集群版本 v5.2 并直接应用 TiDB br 工具的 master 分支代码，时，遇到了一些问题：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;虽然可以成功备份数据，但在恢复时出现了错误。&lt;/li&gt; 
 &lt;li&gt;在备份过程中，TiKV 持续尝试执行备份操作，且无法停止。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;针对这些问题，我们将其反馈给了 TiKV 社区，并在社区的帮助下成功解决了相关 bug。解决问题后，我们对备份过程进行了优化，通过设置备份限速为 50MB/s，使得备份过程能够在大约 15 分钟，内完成。&lt;/p&gt; 
&lt;p&gt;TiKV 备份通过 trip-tikv-manager 服务进行管理，该服务负责调度和执行备份任务。备份数据被存储在独立的对象存储，中，目前使用的是 Ceph 存储系统。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cbe9afd8006b2d45212f9413821f23a45e0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目前，在我们的最大集群扩展后的生产环境中，能够在 20 分钟内完成全量备份。备份任务基本上会在每天定时执行，并通过监控实时查看备份状态&lt;/strong&gt;。由于 JuiceFS 服务全天没有明显低谷，我们选择在白天对 TiKV 进行备份。&lt;/p&gt; 
&lt;p&gt;鉴于我们的系统部署为三中心结构，并已对 Region 实施了 Zone 级别的隔离，即便单一中心发生宕机，也不会影响到 TiKV 的可用性。因此，我们将 TiKV 的备份视作一种额外的安全措施，仅执行快照级别的备份与恢复操作。&lt;/p&gt; 
&lt;h2&gt;03 生产环境排障案例&lt;/h2&gt; 
&lt;h3&gt;案例 1：TiKV MVCC (Multi-Version Concurrency Control) 堆积&lt;/h3&gt; 
&lt;p&gt;这个问题是在去年 9 月被发现的。当时我们发现，尽管 TiKV 数据库和 JuiceFS 的整体使用量并没有显著增长，但数据库的磁盘空间和引擎大小却急剧下降。&lt;strong&gt;奇怪的是，TiKV 的 CPU 使用率和 QPS 并未发生明显变化。进一步分析日志后，发现大量与 region 相关的报错，这些错误是由于 MVCC（多版本并发控制） 堆积引起的&lt;/strong&gt;。MVCC 堆积后，region 内的旧版本数据不断累积，导致 region 无法正常分割，从而阻碍了硬盘空间的及时回收。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7710835625f5f2e6e986d3b15ae73bb804b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过深入排查并使用 tikv-ctl 工具解码报错的 region 中的 key 后，我们发现这些 key 均来自同一个 JuiceFS 卷。由于用户频繁更新文件，JuiceFS 中的 chunk Key 数量不断增加，每次更新都会在 TiKV 中生成新的版本，从而迅速消耗内存和磁盘资源。 进一步分析我们发现，TiKV MVCC 堆积问题与 JuiceFS 的元数据定义和存储方式密切相关。TiKV 作为支持 MVCC 的数据库，能够保证事务的隔离性。每当数据被更新时，TiKV 会为每个写入操作分配一个时间戳（TSO），从而创建一个新的版本，而不是直接修改原有数据。这种机制确保了事务的隔离性，并保证了读操作可以读取到一致的数据。&lt;/p&gt; 
&lt;p&gt;在实际应用中，JuiceFS 会将文件切分为多个 chunk，每个 chunk 包含若干 slice。当一个 chunk 被频繁更新时，TiKV 会为该 chunk 创建新的版本，导致相同 chunk key 在 TiKV 中产生多个版本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;频繁更新同一 chunk 会使 TiKV 无法及时回收过期的版本，从而迅速消耗存储资源，最终导致 MVCC 堆积&lt;/strong&gt;。随着这些未回收的旧版本不断积累，TiKV 的存储压力逐渐增加，可能会导致性能下降，甚至引发磁盘空间不足等问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-00f144732841d495befadaa331944b31d70.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体来说，高频更新文件导致以下两方面的性能问题：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;JuiceFS ：由于 chunk 记录的 slice 数量不断增多，JuiceFS 需要更多时间来恢复完整的文件视图。当 slice 数量过多时，JuiceFS 会暂停写入，并强制执行数据压缩（compaction）操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;TiKV：频繁写入版本会增加 RocksDB 中存储的数据量，导致 LSM 树的读性能下降，从而影响 TiKV 的整体性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;针对上述问题，我们采取了一种更加激进的垃圾回收（GC）策略。具体做法是设置一个独立服务，每隔 5 分钟通知 TiKV 的 PD 节点，告知它在接下来的 25 分钟内的数据可以被 GC 回收。这样，TiKV 在 GC 时能够通过 compaction 过程高效回收无用数据，减少了 GC 对 CPU 的占用。同时，通过加速 TiKV 的 compaction 过程，能够有效降低 MVCC 堆积的风险，防止版本过度堆积而导致的性能瓶颈。&lt;/p&gt; 
&lt;h3&gt;案例 2：大量容器同时扫盘打爆 TiKV&lt;/h3&gt; 
&lt;p&gt;在进行大量容器同时扫描磁盘时，TiKV 负载超过 70%，甚至出现崩溃的情况。经过排查发现，所有卷都是通过 CSI 形式挂载的。在使用 CSI 挂载 JuiceFS 时，会启动一个单独的 Pod 并在其中挂载 JuiceFS 客户端。由于 JuiceFS 客户端与应用 Pod 完全隔离，无法感知应用中的挂载点操作，导致 TiKV 的 PD（Placement Driver）管理节点的利用率不断上升。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-05a643139d360027938e8c7ff9a6901369b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;进一步调查后，发现大量 GET 请求，主要是文件查找操作。虽然 OSS 监控数据显示一切正常，但 TiKV 却持续受到来自历史失败请求的压力，导致性能下降。卷中存在大量小文件和超大目录，导致 TiKV 不断处理类似&quot;扫盘&quot;行为的请求。最初我们认为问题出在宿主机上的某些应用，但进一步排查后发现，JuiceFS 应用的 Pod 中有一个定时任务，该任务会定期扫描目录。多个 Pod 同时对一个超大目录进行扫描，造成 TiKV 负载极大。&lt;/p&gt; 
&lt;p&gt;针对这一问题，采取了以下对策：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;消除 updatedb 的影响&lt;/strong&gt;：通过使用 ConfigMap 将 /etc/updatedb.conf 挂载到用户 Pod 中，覆盖镜像自带的配置，并在配置中禁止扫描 JuiceFS 挂载点。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;限流元数据操作&lt;/strong&gt;：为了防止用户不经意间的行为影响 TiKV 集群的性能，我们修改了 JuiceFS 和 TiKV 相关代码，在元数据部分添加了限流机制，避免 TiKV 因过多文件查找请求而过载。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;进一步限流代码&lt;/strong&gt;：尽管之前对 OSS 带宽进行了限流，但问题仍未完全解决。因此，我们进一步添加了针对元数据操作的限流代码，特别是针对 TiKV 的元数据操作，从而缓解了 TiKV 集群服务质量下降的问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;案例 3：JuiceFS client OOM&lt;/h3&gt; 
&lt;p&gt;在使用 JuiceFS 的过程中，AI 用户，存在不规范的使用方式。这些用户会在 JuiceFS 中存储训练数据集，这些数据集可能是图片或文档，都是小文件，而且通常都是讲大量小文件集中存储在一个目录中。某些目录中的文件数量甚至达到数百万，甚至数千万个。当多个应用同时发起目录读取请求时，可能会导致内存溢出（OOM）问题，尤其是在目录中包含大量小文件时。&lt;/p&gt; 
&lt;p&gt;为了解决这一问题，我们对线上 JuiceFS 客户端进行了 pprof dump 分析，确认问题出在 JuiceFS 的目录读取实现。具体而言，在 JuiceFS 中，目录读取是一个阻塞式操作。每次读取目录时，系统会拉取该目录下所有文件的名称和属性。如果目录中包含大量文件，这一过程会消耗大量内存。例如，对于一个包含 500 万个文件的目录，单次目录读取请求会导致内存占用达到 3.7GB，并且这部分内存会被长时间持有。&lt;/p&gt; 
&lt;p&gt;为了解决这一问题，团队将全量读取目录的实现修改为流式缓冲读取方式，从而有效减少了内存占用，并防止了 OOM 问题的发生。在与社区沟通并反馈该问题后，社区积极参与修复，最终成功解决了这一问题。 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs%2Fpull%2F5162&quot; target=&quot;_blank&quot;&gt;meta: support dir stream #5162&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d95dff563fbd4a7097bf6a9f7d900df664d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 JuiceFS 的成本优势：十分之一极速 NAS&lt;/h2&gt; 
&lt;p&gt;我们对 JuiceFS 与阿里极速 NAS 的进行了性能对比，结果显示，在大部分读写场景下都不落于极速 NAS，甚至性能更加优秀。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ecf6a932cf1df6e8f819d61de9e90a83a96.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-33220c61767bf8e2b9d643b684a7a9c04b7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 具有客户端缓存和预取功能，并且采用了 OSS 大带宽、以及数据和元数据分离的设计，这使得它在大部分应用场景中表现出色，尤其是在大模型推理应用中。大模型推理应用通常需要高带宽的顺序读取场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;通过将 JuiceFS 与 OSS 结合使用，我们实现了一个分布式文件系统方案，能够在大多数业务场景中提供与极速 NAS 相同的功能和接近的性能，而成本仅为极速 NAS 的十分之一&lt;/strong&gt;。 这一成本优势是 JuiceFS 方案的最大魅力之一，它能够显著降低我们的运营成本。&lt;/p&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;p&gt;Q：&lt;strong&gt;大模型对于存储的主要需求是什么，还是只关注性价比&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;A：在大模型场景中，我们最关心的是顺序读写带宽。训练过程涉及训练数据和模型的加载，以及检查点（checkpoint）的写入。推理过程则主要涉及模型的加载。尽管整个流程中涉及一些写操作，但读操作占主导，因此，我们特别重视提升读带宽的性能。&lt;/p&gt; 
&lt;p&gt;Q：&lt;strong&gt;从对象存储拉取数据慢，有什么建议&lt;/strong&gt;?&lt;/p&gt; 
&lt;p&gt;A：JuiceFS 非常适合 AI 负载场景，能够提供非常高的顺序读写带宽。对于顺序读写，JuiceFS 可以启用预读功能，提前从 OSS 拉取数据，这能有效提升性能。然而，由于 OSS 的延迟一般高于 50ms，这可能会影响随机读写的性能。如果对低延迟有较高要求，NFS-Ex 和 CPFS 都能提供 1ms 以内的 4K 随机读写延迟。此外，JuiceFS 官方也提供了分布式缓存方案来降低延迟。总体来说，这之间是性能与成本之间的权衡。&lt;/p&gt; 
&lt;p&gt;Q：&lt;strong&gt;TiKV 元数据规模大概能支撑到多大的量？数据量大的场景，元数据是不是成为瓶颈&lt;/strong&gt;？&lt;/p&gt; 
&lt;p&gt;A：提供一组携程的数据供参考，我们的一台生产集群，TiKV 节点数量为 6 个，每个节点配置为 64 核 256 G 内存，承载着接近 40 亿个文件的负载。在这种配置下，TiKV 的 get p99 延迟仍然保持在 1.5ms 以下。实际生产中，元数据的延迟与 OSS 的延迟不在同一量级，因此 TiKV 并未成为瓶颈。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17869204</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17869204</guid>
            <pubDate>Wed, 05 Mar 2025 10:36:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>OCAI + DeepSeek 满血版双 buff 加成，OS 运维从此告别焦虑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;作者&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;黄敏杰、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;李强&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;编辑&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;cherry&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;审稿&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;丨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;林青、郑力博&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;当遇到忘记的 Shell 命令参数，你是否还在使用「xxxx --help」查询使用帮助？当你遇到 OS 的疑难问题，是否还在全网苦苦搜索解决方案？今天，OpenCloudOS 社区重磅推出新一代 OS 智能助手 OCAI-Agent，它集代码生成、场景化指南输出于一体，通过接入&lt;span style=&quot;color:#0052d9&quot;&gt;满血版 DeepSeek R1&amp;nbsp;&lt;/span&gt;模型，让你通过简单的中文指令，即可实现秒级 AI Agent 调用。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;一、OCAI 工具概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;很多 OS 运维工程师常陷于「文档迷宫」：面对上千页的官方手册、散落全网的技术贴、版本迭代带来的参数变更，每一次故障排查都可能演变成耗时数小时的文档检索工程。但 OCAI 的诞生，可能一切都变了……&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;先看一下这个，好像小白也可以实现对 OS 的运维：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70d16ddf9350a0b840202ffe51ace139f07.gif&quot; width=&quot;1632&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span style=&quot;color:#939393&quot;&gt;&lt;span&gt;&lt;span&gt;（划至文章底部可查看未加速操作版）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;目前，OCAI 已接入满血版 Deep&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Seek R1 模型，并将&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;全量文档、社区运维案例、Gitee 技术方案等异构数据，经向量化处理后形成动态知识图谱&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;也就是说，针对&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的使用、运维管理操作等场景，OCAI 可以帮为用户总结提炼并生成具体场景下的使用指南、命令、甚至代码，从而实现极大程度上的智能提效。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;当前版本主要分为三种模式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Chat 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;通过提问，开始调用 OCAI 问答系统，并让系统进入思考、推理及结果输出过程。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Cmd 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;直接执行的 Shell 命令，并根据用户指示执行相应任务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Code 模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;生成执行代码。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;1、Chat 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;安装完成并使配置生效后，在命令窗口中直接输入相关问题，无需加入任何命令前缀，即可方便调用&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OCAI&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能助手的问答能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;605&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-028ab812cd46fb2c0719bc268d985671c1c.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;也可通过&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;ocai chat &amp;lt;question&amp;gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;命令形式对问答能力进行调用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;1560&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-29e75a320b94368e7ceace43da99a2cd0bb.png&quot; width=&quot;2784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;2、Cmd 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;Cmd 模式支持根据用户指示生成可直接执行的 Shell 命令，用户确认后可立即执行获取结果。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;318&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d14cdba3fbefd417b4222230d1ead319e24.png&quot; width=&quot;2066&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;3、Code 模式&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;Code 模式下支持根据用户指示生成不同编程语言下的代码。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;804&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-25541a23c8c9c3ee960ae0f00cef6836755.png&quot; width=&quot;2200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;二、OCAI 背后的技术实现原理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;当前 OCAI 智能助手针对不同场景设计了多个 Agent 分别处理请求，采用 RAG 方式导入&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;特有知识库信息，通过&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OCAI-Service&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;与客户端进行交互，使用不同的底座模型对数据进行推理、总结和润色，最终输出给用户。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img height=&quot;441&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7b55da66d0b276adaafcdca8a792f808c13.png&quot; width=&quot;621&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;1、多 Agents 编排&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI 智能助手针对不同场景和数据源创建了多个不同的 Agents，每个 Agent 负责特定的一个领域的处理逻辑（如对话、命令生成、代码生成），并通过指定逻辑将多个 Agents 组合编排，从而使使用入口得以统一，多个 Agents 可以协同工作。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;2、RAG&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;针对通用模型缺少特定领域知识的情况，OCAI 智能助手采用 RAG(Retrieval Augmented Generation) 方式，将特定领域的知识库（如 OpenCloudOS 文档库）数据进行处理清洗和切分后，计算成向量形式并存入向量数据库。用户提问将先从向量数据库中检索出相关程度较高的资料，再统一拼接成 prompt 提交给大模型进行总结和回答。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;3、OCAI-Service&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI-Service 是 OCAI 智能助手的接口层服务。在直接提供服务调用接口的同时，还支持了上下文管理、接口转发、用户识别、身份鉴权、配置管理、反馈收集、统计日志等真实使用情况下必不可少的基础能力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI-Service 也为多模型选择及函数调用提供了通道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;strong&gt;4、底座模型&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OCAI 智能助手在处理逻辑的各个阶段使用了 DeepSeek 和混元的各类大模型，包括但不限于 DeepSeek-R1、DeepSeek-V3、混元 T1、混元 Turbo 等&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;三、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;如何使用&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;当前 OCAI-Agent RPM 包已在&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;OpenCloudOS 8/9 软件源上线，使用上述版本的用户可直接执行&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;yum install ocai-agent&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;先进行&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;img height=&quot;1622&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5ce8d1e053e59009b9dba811a755897580e.png&quot; width=&quot;3572&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RPM 包安装链接：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OC9:&amp;nbsp;&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;u&gt;https://mirrors.opencloudos.tech/opencloudos/9.2/AppStream/x86_64/os/Packages/ocai-agent-1.0.0-2.oc9.x86_64.rpm&lt;/u&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;OC8:&amp;nbsp;&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;u&gt;https://mirrors.opencloudos.tech/opencloudos/8.10/Extras/x86_64/os/Packages/ocai-agent-1.0.0-2.oc8.x86_64.rpm&lt;/u&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;完成安装后，请在&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;该网&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;址&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#0052d9&quot;&gt;&lt;em&gt;&lt;u&gt;（https://opencloudos.org/ospages/learnmore/ocai）&lt;/u&gt;&lt;/em&gt;&lt;/span&gt;内&lt;span&gt;输入&lt;span&gt;&lt;strong&gt;您的邮箱进行注册&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，并按照&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;邮件中的指引配置访问密钥&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，即可开始使用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#4a4a4a; margin-left:8px; margin-right:8px; text-align:center&quot;&gt;&lt;iframe frameborder=&quot;0&quot; height=&quot;300&quot; scrolling=&quot;no&quot; src=&quot;https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114137547931864&amp;amp;bvid=BV1hPRGYcE3B&amp;amp;cid=28794949378&amp;amp;p=1&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;为了确保服务的稳定性，OCAI-Agent 每天最多可调用 50 次。请合理安排您的使用频率，以免达到调用上限。如有更多需求，请关注后续更新或联系我们获取帮助。感谢您的理解与支持！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;OpenCloudOS 开源社区是由操作系统、云平台、软硬件厂商与个人携手打造中立开放、安全稳定且高性能的 Linux 操作系统及生态。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span style=&quot;color:#888888&quot;&gt;欢迎上下游厂商、高校及组织加入社区，共建开放共享的安全生态。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4d4bdd4525c9272aa6205e93686655ae07c.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#888888&quot;&gt;&lt;span&gt;扫码添加社区助手进群，添加时备注「OCAI」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338017/ocai-agent</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338017/ocai-agent</guid>
            <pubDate>Wed, 05 Mar 2025 10:07:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源、可定义数据中台 AllData 架构全解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;数据中台，是近几年才流行的概念。简单地说，就是一套可持续「让企业的数据用起来」的机制。&lt;/p&gt; 
&lt;p&gt;AllData 是一个开源的可定义数据中台，使用 GPL 协议，上层是 Wujie 微前端架构，底座是可插拔的后端架构，提供包括数据集成、数据存储、数据开发、数据治理、BI 展示等功能在内一条龙的解决方案。AllData 作者巫林壕在 2019 年就完成了该项目 ，并已经运行 5 年以上，GitHub 上的 Star 数已经超过了 2.6K。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;316&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5bb68507b486f1b0ce1bef71defb2d6143d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;AllData 能与大数据平台如 Hadoop、Spark 等无缝集成，支持关系型数据库如 MySQL、PostgreSQL，以及非关系型数据库如 MongoDB 等，确保与各类数据源的兼容。&lt;/p&gt; 
 &lt;p&gt;由于 AllData 数据中台主要基于 Java 进行开发，并结合了 Vue 等技术栈构建用户界面，因此它能够在支持 Java 应用的操作系统上稳定运行。&lt;/p&gt; 
 &lt;p&gt;得益于其灵活的底层架构和可插拔的后端设计，系统能够根据不同的业务需求进行定制和扩展，从而降低了二次开发的难度和成本。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt;
  3 月 14 日晚，巫林壕将做客开源中国 OSCHINA 直播间的《技术领航》栏目，为大家拆解数据中台 AllData 架构，并手把手教大家基于 Alldata 实现数据同步、处理、服务全流程。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt; 
  &lt;img height=&quot;691&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-468b59adcebcc15d3b659e3125117cde85a.png&quot; width=&quot;1202&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div style=&quot;text-align:center&quot;&gt;
   巫林壕，AllData 作者、杭州奥零数据科技创始人&amp;amp;CTO 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;strong&gt;直播标题：&lt;/strong&gt; 数据中台 AllData 架构全解&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;3 月 14 日周五 19:00-20:00&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;视频号 「OSC 开源社区」&lt;/p&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;直播亮点：&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;开源而生，AllData 的来时路与未来发展方向&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;技术干货：微前端+可插拔架构设计解析&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;15 分钟手把手操作数据同步→处理→服务全流程&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;揭秘商业用户重度使用的核心功能有哪些？&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;715&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f3830144b23e77bb9e604f097b58c653339.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;另外，我们还建了一个交流群，一起聊聊自己喜欢的开源项目～～当然啦，如果你有什么特别棒的开源项目，可以推荐过来呀～&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;396&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e7c43c0b0553350855a379af00c6c7c15d.jpg&quot; width=&quot;396&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了诸多社区或组织的大力支持，在此特别表示感谢：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;br&gt; 目前，Gitee 已经有超过 1350 万名开发者，累计托管超过 3600 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 36 万家企业。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;奥零数据&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;杭州奥零数据科技公司拥有核心产品 AllData 可定义数据中台，提供多样开源大数据组件模板，快速搭建极致性价比的数据中台。&lt;/p&gt; 
  &lt;p&gt;网址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.aolingdata.com%2F&quot; target=&quot;_blank&quot;&gt;http://www.aolingdata.com/&lt;/a&gt;&lt;/p&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技术领航&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/17870188</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/17870188</guid>
            <pubDate>Wed, 05 Mar 2025 09:50:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>如何使用 Gitee + Zadig 实现微服务架构持续交付</title>
            <description></description>
            <link>https://my.oschina.net/koderover/blog_beta/15298899</link>
            <guid isPermaLink="false">https://my.oschina.net/koderover/blog_beta/15298899</guid>
            <pubDate>Wed, 05 Mar 2025 09:31:00 GMT</pubDate>
        </item>
        <item>
            <title>RAG 市场的 2024：随需而变，从狂热到理性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 卢向东&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;转眼到了 2024 年尾，和小伙伴一起创立 TorchV 也接近一年。虽然这一年做了很多事情，但从技术层面上来说，RAG 肯定是不得不提的，所以今天分享一下作为大模型应用创业者所感知的这一年，RAG 市场环境的变化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;RAG vs Fine-tune&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 这一年，RAG 技术对应的市场需求变化也是挺大的。在讲变化之前，我觉得有必要分享一下为什么 RAG 是目前市场上不可或缺的一种大模型应用的技术实现方式，它的优点是什么？以及它和主要竞争技术之间的现状是怎么样的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;RAG 最开始被大家热推，更多是因为以下三个原因：可以避开大模型的上下文窗口长度的限制；可以更好地管理和利用客户专有的本地资料文件；可以更好地控制幻觉。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这三点到现在来看依然还是成立的，但上下文窗口这个优势已经慢慢淡化了，因为各大模型的上下文窗口都在暴涨，如 Baichuan2 的 192K，doubao、GLM-4 的 128K，过 10 万 tokens 的上下文窗口长度已经屡见不鲜，更别说一些特长的模型版本，以及月之暗面这样用长文本占据用户心智的模型。虽然这些模型是否内置了 RAG 技术不好说，但是 RAG 解决上下文窗口长度限制的特点已经不太能站得住脚。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是第二点管理和利用专属知识文件，以及第三点控制幻觉，现在反而是我认为 RAG 最大的杀手锏。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）专属知识文件管理&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因为 RAG 这种外挂文件的形式，我们便可以构建一个知识文件管理的系统来维护系统内的知识，包括生效和失效时间，知识的协作，以及便捷地为知识更新内容等。RAG 在知识维护上，既不需要像传统 NLP 那样由人工先理解再抽取问答对，也不需要像微调（fine-tune）那样需要非常专业的技术能力，以及微调之后的繁琐对齐（alignment）优化。所以如果客户的知识内容更新比较频繁（假设每天需要追加、替换大量实时资讯内容），特别是金融证券、企业情报等场景，RAG 知识更新便捷的特性真的非常合适。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）RAG 的幻觉控制&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的幻觉控制是一个有争议的话题，我之前写过类似观点，也有同学斩钉截铁地认为 RAG 和幻觉控制八竿子打不着，但我现在依然坚持 RAG 可以有效控制幻觉这个观点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先我们可以来看看 LLM 幻觉产生的主要原因：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 对于用户的提问输入，LLM 内部完全没有相应的知识来做应对。比如你问大模型，上周三我在思考一件事，但是现在想不起来，你帮我想想是什么。例子虽然夸张，但显而易见，LLM 也不知道，但是它会一本正经给你一些建议，当然肯定不是你想要的；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 当我们给 LLM 原始问题，以及多个模棱两可或互相影响的参考材料，那么 LLM 给出的最终答案也会出错。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;好，那么针对以上问题，是否我们解决好对原始问题的 「理解 - 检索 - 召回」，送到 LLM 的 context 足够清晰（指的是没有歧义内容、检索相关度高），结果就会非常准确？根据我们的实践结果，答案是明确的：今年 9 月份我们对一些项目进行了槽位填充（消除模糊问答）和元数据辅助之后，问答准确率可达到 98% 以上。比直接把大文本扔进同一个 LLM 测试的问答准确率几乎高出 14 个百分点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有同学会说，LLM 幻觉的深层原因是 temperature 或者说概率引起的。就我纯个人观点来看，现当下的 LLM 参数足够大、知识量足够多，temperature 引起的偏差对于最终结果的正确性影响已经微乎其微了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（三）市场表现&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你应该看出来了，在 RAG 和微调之间，我明显站队了，而且从一年前就开始站队了，我们创业的技术方向也是如此。从今天来看，我觉得 RAG 在 2024 年的表现确实要强于微调。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;499&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3a36116d31e8f9dc257f8e00f317e80a982.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图：Menlo Ventures 在 2024 年 11 月 20 日发布的市场调研报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;来源：https://menlovc.com/2024-the-state-of-generative-ai-in-the-enterprise/&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据 Menlo Ventures 发布的市场调研报告显示，RAG 以 51% 的市场份额在企业市场份额中占据绝对优势，Fine-tune 和 Prompting 工程均下降两倍多。Agent 今年属于纯增长，目前情况还不错，但在企业应用领域，多 Agents 的编排依然存在理解能力不足和生成幻觉等问题有待提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果去预测明年的企业级市场趋势，我觉得应用（Application）可能会是最大的关键词，甚至会超过 Agent 的热度。其实今年下半年已经能明显的看出来，越来越多传统大企业开始将大模型技术引入到业务中，而且他们的特点是要求高、需求刚、付费爽。而一旦大家开始在大模型的应用侧竞赛，RAG 在整个业务流程中白盒流程多、易控等特点愈发会受到企业客户和开发者的热捧，优势进一步拉大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;企业 AI 应用市场在 2024 年的变化&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）上半年：AI 无所不能，大而全&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年的上半年，AI 市场充斥着激情，那种热情似乎走在街上都会扑面而来，个人感觉最主要的推动者是自媒体和模型厂商。模型厂商的出发点很容易理解，快速打开市场嘛，但考虑到他们是要最终交付的，所以相对还是比较理性。但自媒体就不一样了，整个上半年看过太多的文章，大家也都是把最好的一面呈现给了大众，所以很多人会觉得我才几个月没关注，AI 已经发展到我不认识的地步了，AI 已经无所不能了。所以，在 2024 年上半年，我们接触到的企业需求中，占主流的是那种大而全的需求，要用 AI 替代他们业务的全流程或基本流程，气味中充满了使用者的野望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但实际情况并不理想，AI 或者大模型还真没到这个程度，而且最关键的是范式转换也还需时间。什么是范式转换？最简单的例子就是以前人们用笨重的蒸汽机推动主轴承转动，带动整车间的机器工作。但是换了电动机之后呢，工作方式变了，动力可是变得非常分散，比如你拿在手上吹头发的吹风机。带着微型电动机的吹风机和传统的蒸汽机在工作范式上就完全不同，采用 AI 大模型之后，企业的业务流程也存在范式改造的过程，并非一朝一夕可以完成的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所以，上半年我遇到的、参与的或者听说的那些大而全的 AI 项目，一半是在可行性推演中没有被验证，一半是交付之后效果很不理想，成功者寥寥。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）下半年：回归理性，小而难&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在今年 7 月份开始，陆续有一些传统大企业找上门来，包括非常知名的企业，以及世界 500 强和多家中国 500 强。如果从时间上来说，他们属于 AI 投入相对较晚的了，但他们的优势是需求非常明确，要求也极高。比如有些企业仅仅就是解决一个咨询服务的需求，在产品范围上就是一个 AI 问答，但要求准确率接近 100%，就像我们 CTO 在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《AIGC 时代的淘金者，TorchV 这一年的心路历程》&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;说到社保咨询一样。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;小而难的好处很明显，我能看到的是下面几点：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对企业现有业务流程改造相对较小，内部推动的阻力相对较小，企业客户配合度高；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;切口小，需求明确，建设成果的考核清晰可量化；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用功能较小但可用性较高的 AI 产品，可以让企业内部员工快速接受 AI，做进一步业务流程改造的前期预热；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;乐于承接大而全需求的合作厂商多半是外包性质的（这个观点有点伤人，但确实是我看到的现状），而专业的、交付成功率更高的厂商往往更喜欢需求清晰且有难度的任务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（三）关于 2025 年的预测&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我在上文中已经有提到，2025 年会有更多企业需求方采用 AI 技术，但企业永远不会为你的技术买单，他们只会为他们自己的使用价值买单。比如可以帮助他们提升销售额、业务流转效率更高，或者和竞争对手的竞争中获得优势，还有就是降低成本等等。所以，大模型应用端多端不够，还需要生长出藤蔓围绕着企业流程开花结果，这个任务最终会落在应用（Application）—— 内化了企业流程、借助了大模型能力的、带有可交互界面的程序。2025 年会成为大模型应用或 AI 应用之争。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外还有一个趋势也很明显，就是知识管理和协作。我们都说这波 AI 浪潮把原来 「没用」 的非结构化数据给激活了，所以我们马上会看到那些原来堆在角落里面的 「冷」 文件和知识（类似 wiki）会被大量启用，「热」 文件和知识会爆炸性增长，知识的协作和管理会成为新的问题 —— 就像你有再多的先进坦克和战车，却因为无序的交通都堵在阿登森林了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;AI 从业者观察&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因为我看到的不代表真相，所以这一章节会很短，仅仅分享两个发现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（一）AI 技术的下坡&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有两个感受（非证据）可以说明这一点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(1) 关于 AI 大模型的自媒体数量在减少，从搜索引擎趋势，加上我和几个业内朋友的 blog、公众号以及 X 的阅读量下降趋势也可以佐证这一点，下半年虽然市场理性回归，但整体热度是在下降的。OpenAI 不再持续放大招可能也是重要原因之一。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;(2) 我前期接触了很多因为 AI 热潮而在企业内部抽调精干力量组成的 AI 小组、AI 研究组和 AI 创新组等团队的成员，但下半年有不少类似团队已经解散，人员回归到原有岗位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;还有一点就是上半年加我微信好友的很多独立开发者或在职的个人，多半也已经在寻觅了半年机会之后放弃了继续探索，这一点在和他们交流，以及他们朋友圈的内容变化中可以明显感知。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;619&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e0b61fa320f93745cf792daf0e22d6fe227.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图：技术采用生命周期。现阶段的 AI 大模型市场似乎正处于过高期望之后的下坡过程中&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是这并不是坏事，上图已经告诉我们，这是必然规律。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;（二）价值开始显现&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前还奔跑在 AI 大模型应用赛道的公司，很多已经开始创造出客户价值，有了自己的优势。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;包括在海外风生水起的 Dify，在内容提取端的合合，以及肯定会成为国内 AI 巨无霸的火山引擎。当然我们还看到了一些深耕垂直行业的优秀团队，特别是在法律、医药、教育等行业。我们也在今年 6 月份开始做了产品转身，现在已经不再烦恼人家问我们 「你们和 dify、fastgpt、ragflow 有什么区别」，因为赛道已经开始慢慢不一样了，而且这个不一样依然是产品层面的，和服务什么行业无关。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;198&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e8cb1ce63e159dcd77334342f311f629de.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;卢向东&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;国内最早的 RAG 实践者之一，杭州萌嘉网络科技 CEO，公司主要研发 TorchV 品牌的大模型应用和知识库产品。公众号：土猛的员外。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338004</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338004</guid>
            <pubDate>Wed, 05 Mar 2025 09:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 编程技术与工具发展综述（2024 年 ）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 朱少民&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年 8 月下旬，一款 AI 代码编辑器 ——Cursor 火爆全球，火到一位 8 岁小女孩拿着它学编程，几十分钟内搭起来一个聊天机器人，其演示吸引来 180 万人在线围观。这导致有人大胆预言，未来编程只需要狂按 Tab 就够了。Cursor 确实好用，包括新推出的 「光标位置预测」 功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是 AI 编程发展没有那么快，在国内生成代码采纳率还比较低，根据《2024 软件研发应用大模型国内现状调研报告》，多数团队在 10-40% 之间，如图 1 所示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;454&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce564f5bd0fc36ee2aaa7dc75de3d3e72f3.png&quot; width=&quot;1101&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;图 1 大模型（LLM）在编程上的应用及其生成代码的采纳率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 2024 年，我们还看到了 「AI 程序员」 Devin 的诞生，Devin 能够独立完成复杂的编码和调试任务、自主查找和修复代码库中的错误，构建和部署应用程序。在 SWE-bench 编码基准测试中，Devin 能够解决 GitHub 中 13.86% 的真实问题，有了很大提升。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;说起 SWE-bench 编码基准测试（https://www.swebench.com/），2024 年进步很快，以 OpenAI 建立的 verified 子集（500 个问题）为例，4 月开始时，成功率只有 2.8%，到现在已提升到 53%，这表明 AI 在编程能力方面取得了显著的进步。这一提升反映了 AI 编程几个关键因素，正好用来总结 2024 年 AI 编程的进展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;模型能力的增强：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 模型的架构和算法不断优化，如从 Claude 3 Opus、GPT-4o 到 Claude 3.5 Sonnet、Claude 3.5 Haiku，大模型自身的能力不断提升，使得模型能够更好地理解和解决复杂的编程问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;智能体（AI agent）的引进：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体可以收集和学习与任务相关的知识，可以直接调用静态代码分析工具、直接调用搜索引擎和 API 为编程任务服务，并通过构建代码仓库知识图来帮助大模型全面理解软件仓库的结构和依赖关系，从而更好地定位问题根源并生成有效的代码补丁。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体还可以动态获取代码片段和问题相关的信息，并分析和总结收集到的信息，以便规划出更好的解决方案。例如从 RAG+GPT 4 (1106) 的 2.8% 提升到 SWE-agent+GPT 4 (1106) 的 22.4%、从 RAG+Claude 3 Opus 的 7% 提升到 SWE-agent+Claude 3 Opus 的 18.2%，效果都比较显著。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;多模态能力：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模态 LLM 使智能体能够综合利用视觉和文本信息，可以理解软件用户界面、处理的图表、可视化数据、语法高亮和交互映射等内容，更好地理解任务陈述以及获取任务相关的产品信息、开发过程信息，从而更全面地理解和解决问题。目前排在 SWE-bench verified 前 4 位都使用了 Claude-3.5-Sonnet，而它是多模态的、具备处理文本和视觉信息的能力，使其能够理解和修复包含图像或其他视觉元素的 GitHub 问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;和工具集成的框架：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可以支持智能体在处理复杂任务时进行更好的任务管理和执行，并促进不同 AI 模型和工具之间的协作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如 Composio SWE-Kit 集成文件操作、代码分析、Shell 命令执行、知识库管理和数据库操作等工具或能力，优势互补，将 SWE-bench verified 大幅度提升到 48.6%。再比如 OpenHands+CodeAct v2.1 将智能体的行为整合到统一代码行动空间的框架，允许 OpenHands 在编程任务中扮演全方位的智能助手角色，目前排在 SWE-bench verified 第一位（53%）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基于代码大模型的自身进化，以及 RAG 技术、智能体的有力支持，从而 LLM 有更好的上下文感知能力。例如，在代码大模型预训练时，其训练语料中加入抽象语法树（AST）、代码依赖关系等数据，新的代码生成模型则具有更强的上下文感知能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基础上，基于 AI 的编程工具能够根据给定的上下文（如函数名、注释、部分代码等）检索出最相关的代码片段和文档，能够提供完整的函数或代码块建议。这也使得 LLM 能够参考海量的代码库和技术文档，这不仅能缓解大模型的幻觉问题，显著提升代码生成与理解的准确性，而且能符合上下文的代码，更能满足开发的业务需求。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未来，研发人员和多个智能体、工具协同工作来完成编程工作，如论文 Flows:Building Blocks of Reasoning and Collaborating AI 所描述的（图 2 所示），构成一个复合竞争性编码流程，研发人员更多是提需求，由 LLM 和智能体实现自主编程的过程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;546&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-243a86d5adf6ad21f5d418b5511f81f0f05.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#7f7f7f&quot;&gt;&lt;span&gt;图 2 由 LLM 和智能体实现自主编程的过程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着大模型技术的迅速发展，在今年，我们明显能感到，AI 已从单一的辅助工具，逐渐演变为软件开发人员不可或缺的助手或伙伴。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了前面已介绍的 Cursor、Composio SWE-Kit、OpenHands CodeAct 等工具之外，国内主要使用 chatGPT、GitHub copilot、通义灵码、CodeGeeX、文心快码、蚂蚁 CodeFuse 等编程工具，国外还出现一些受欢迎的、新的编程工具，如 Codeium IDE Cascade、Solver ai、Websim ai 等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;493&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c4bc35246b3a57ea83c92f455823fb59b03.png&quot; width=&quot;796&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图 3 国内编程助手使用状况（来源同图 1）&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这些工具让我们能感受到 AI 卓越的生成能力和理解能力，帮助我们更高效地完成代码生成、代码评审、代码解释到单测生成、缺陷定位、代码优化等任务。这种进步也体现在今年国内企业一些落地实践中：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在一些大厂，LLM 已经实际应用到代码审查或 CI/CD 流程中（如 pull request），自动识别代码质量问题并提出改进建议。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些企业结合智能体和相关工具的支持，让基于 LLM 的研发平台生成代码流程图和类图，辅助自然语言解释，使得开发者更直观地理解代码结构和执行流程，增强智能编程的可视性和交互性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些开发团队借助智能体和 RAG 技术检索历史上已知的代码缺陷模式和已知问题，从而比较准确地识别潜在的缺陷和安全漏洞，甚至能够分析代码的功能意图，全面提升代码评审的能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;有些团队，根据 UI 设计图，让 LLM 自动生成相应的前端代码，大大减少了手动编码的时间，加快了从设计到实现的流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从应用效果看，前面调研的数据可供参考。在国内 AI 编程开展比较好的大厂，超过 80% 的工程师在使用 AI 编程工具完成日常的编程工作，近 30% 入库的代码由 AI 生成，生成代码平均采纳率超过 40%，有些产品线达到 60%。仅仅在编程这一项工作（虽然只占开发人员 20-30% 的工作量）上，研发效率能提升 20-30%。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;850&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-33b0554523cedb9d91ec30064a650d426eb.png&quot; width=&quot;1292&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;图 4 大模型时代的软件研发正确方式&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然，我们不能局限于这一个编程环境，最好要从需求开始就应用大模型。ATDD（验收测试驱动开发）是大模型时代软件研发的正确打开方式，让大模型帮我们生成需求及其验收标准，业务约束更明确了，上下文更清楚了，在此基础上分别由不同的模型生成产品代码和测试代码，再让它们之间相互验证和博弈（如图 4 所示），最终交付高质量的软件。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;未来，随着 AI 技术的不断成熟和创新，AI 编程工具将进一步提升智能化和可解释性，支持更多的编程语言和平台，并通过强化学习实现自适应优化。为了全面发挥 AI 编程技术的潜力，开发团队需要不断学习和适应新技术，优化开发流程，确保 AI 工具的有效应用和高质量输出。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者简介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ee7692932d7b07e9b2a9ffb1562965629.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;朱少民&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同济大学特聘教授、CCF 杰出会员、CCF TF 软件质量工程 SIG 主席、CCF2023 杰出演讲者、软件绿色联盟标准评测组组长、QECon 大会和 AiDD 峰会发起人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近三十年来一直从事软件工程的教学与研究工作，先后获得多项省、部级科技进步奖，已出版了二十多部著作和 4 本译作。曾任思科（中国）软件有限公司 QA 高级总监、IEEE ICST 2019 工业论坛主席、IEEE ICST、QRS 等程序委员、《软件学报》和《计算机学报》审稿人等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338002</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338002</guid>
            <pubDate>Wed, 05 Mar 2025 09:25:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>大模型撞上 「算力墙」后，超级应用的探寻之路</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / 傅聪&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，大模型教父 Sam Altman 在 Reddit 上的评论透露出 GPT-5 难产的隐忧，直言有限的算力约束让 OpenAI 面临迭代优先级的艰难抉择，在通往 AGI 的道路上一路高歌猛进的领头羊似乎撞上了 「算力墙」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除此之外，能耗、资金，难以根除的幻觉，有限的知识更新速率、有限的上下文宽度、高昂的运营成本等等，都让外界对大模型的发展忧心忡忡。面对棘手的困境与难题，大模型的未来，又该何去何从呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;下一代 「明星产品」&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「算力墙」 下，模型效果边际收益递减，训练和运营成本高昂，在这个时间节点，最好的 AI 产品会是什么？奥特曼、盖茨、小扎、吴恩达、李彦宏等一众大佬给出了一致的答案 —— 智能体（AI Agent）。2025，将会是智能体元年。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;什么是智能体？目前业界一致认可的公式是 「智能体 = LLM + 记忆 + 规划 + 工具」：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;591&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b99b6eda5484ca023d6608da04fb0d98f2.png&quot; width=&quot;1107&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型充当智能体的 「大脑」，负责对任务进行理解、拆解、规划，并调用相应工具以完成任务。同时，通过记忆模块，它还能为用户提供个性化的服务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体为什么是 「算力墙」 前 AI 产品的最优解决方案？这一问题的底层逻辑包含两个方面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;LLM 是目前已知最好的智能体底层技术。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智能体作为学术术语由来已久，从上世纪的 「符号、专家系统」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，到十年前风头无两的强化学习（代表作 AlphaGo&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【3】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;），再到现在的 LLM，agent 底层技术经历了三个大的阶段。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;符号系统的缺点在于过于依赖人工定义的 「符号」 和 「逻辑」，强化学习苦于训练数据的匮乏和 「模态墙」，而 LLM 一次性解决这些问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;人类语言就是一种高度抽象、跨模态、表达力充分的符号系统，同时它作为知识的载体，自然地存在大量数据可用于训练，还蕴含了人类的思维模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在此基础上训练得到的 LLM，自然具备被诱导出类人思考的潜力。在 COT（思维链）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【4】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;、TOT（思维树）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【5】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;等技术的加持下，大模型正在学习拆解自己的 「思维」，OpenAI 的 o1 就是典型案例，强化了推理能力的同时，也大大缓解了幻觉问题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2. 大模型做不到的，「现存工具」 强势补位。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;无法持续更新的知识库，可以通过 RAG（Retrieval Augmented Generation，检索增强生成）来解决。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 的出现，让各界越来越深刻地认识到，大模型没必要存储那么多知识，只需要如何使用搜索引擎这个外部工具即可。大模型可以在搜索结果上做进一步的信息筛选和优化，而搜索引擎弥补了大模型的知识缺陷，实现了 1+1&amp;gt;=2 的效果。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;RAG 可以被理解为智能体的最简单形式。未来的智能体可以实现多种工具的混合使用，甚至多智能体协作，这不是猜想，我们已经在学术界看到了惊艳的早期方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【6，7】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;「四把钥匙」 解锁潜力&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;领域模型小型化、平台化会成为新趋势。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「算力墙」 是一方面因素，但基座模型的趋同化和运营成本是源动力。GPT、Claude、Gemini 虽然各有所长，但实际体验越来越让大家分不出差异，基座模型作为智能体核心，决定了智能体效果下限，人人训练基座的可能性越来越低，「基座服务化」 很可能是最合理的商业模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;甚至，在错误不敏感的应用领域，出现一个开源、无商业限制的基座的可能性也很高。小应用开发商很可能很容易获得一个低成本 serving 的 「量化小基座」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「7B」 是一个 magic number！无论是 RAG 里的向量表征模型，还是文生图、文本识别（OCR）、语音合成（TTS）、人脸识别等等垂直领域，一个 1B~7B 的小模型已经可以满足很多生产、应用需要，并且效果也在逐步推高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【8，9，10】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。这些模型，作为智能体的 「三头六臂」，不需要太 「大」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同时，从学术角度来讲，各种领域专用模型的技术最优解也在逐渐趋同。应用开发者越来越不需要了解模型的底层技术，只需要懂得如何设计自己应用的任务流，懂一点点 COT 系列的 prompt engineering 的技巧，就可以利用 Maas（Model as a service）、Aaas（Agent as a service）这样的平台，如玩乐高一般搭建自己的 AI 云原生应用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2. 算力层深挖定制化、低能耗的可能性，但固化 transformer 可能不是最优解&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;虽说智能体不需要太大的模型，但其运营成本（模型推理计算成本）仍然较高。在短时间内，算力、能源仍然会是大模型领域令人头疼的高墙。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据报告&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，能源消耗将会是 2030 模型 scaling 最卡脖子的因素。也就是说，在算力到达瓶颈之前，首先可能会出现电能供应不足甚至交不起电费的问题。因此，算力层可以根据大模型底层技术的特性，产出针对性的芯片，尤其是加速运算和降低能耗。这是未来 AI 芯片领域的最优竞争力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那么，把 transformer 「焊死」 到板子上就是最佳方案吗？我知道你很急，但你先别急。大模型底层框架还存在底层路线之争。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们知道，Transformer 架构呈现了 O (n²) 的理论计算复杂度，这里的 n 指的是大模型输入序列的 token 数量，但其前任语言模型担当 RNN 只有 O (n) 的理论计算复杂度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最近，以 Mamba、RWKV 为代表的类 RNN 结构死灰复燃，公开挑战 transformer 地位。更有最新研究&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【13】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从理论上表明，RNN 对比 Transformer 的表达力，只差一个 in-context-retrieval。在这个方向的持续投入下，我们很可能会迎接一个介于 RNN 和 Transformer 之间的 「新王」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;612&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a0b844154fb7c7c6c5785d19d82ed9d97c5.png&quot; width=&quot;1268&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因此，算力层短时间内的主题仍然是 「半通用化」「高算力」「低能耗」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;3. 合成数据驱动新产业链&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;早有机构预测，人类社会可利用训练数据会在 2026 年耗尽。这可能还是一个乐观估计。光头哥 Tibor Blaho 还曾爆料，OpenAI 用于训练 「猎户座 「的数据中，已经包含了由 GPT-4 和 O1 产出的合成数据。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这不仅是因为自然存在的高质量文本的匮乏，还因为智能体所需的数据很可能需要显式地蕴含任务思考和规划的拆解信息。然而，针对合成数据的问题，学术界早有预警，模型可能会在合成数据上的持续训练中崩坏&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【14】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;409&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-abc80e1aa8efa6b89d26339a5ffb8f84c7f.png&quot; width=&quot;1106&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这是因为合成数据往往携带 「错误」 和 「幻觉」，在一些冷门的知识上尤甚。因此，合成数据的实用秘诀是 「去粗取精」，需要一定程度的 「人机协同」。在如何构造大批量、高质量的合成数据，让智能体能够在持续地与用户的交互中自我优化而不是劣化，将会成为众多无机器学习技术背景的开发者的头号难题。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;因此，面向数据进行定制化合成、评估、测试、标注、人机协同的 「纯数据」 产业，有可能会走上越来越重要的位置，不仅仅是服务于基座模型厂商。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;4. 多模态对齐很可能给基座模型带来质的提升&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最新研究发现，在没有预先约束和约定下，不同模态领域的最强模型正在向着某个世界模型认知领域收缩【15】，AI 模型对不同概念的数字化表达（向量表征）会逐步趋同，构建对这个世界的统一认知。这也符合我们人类对世界的认知：人类通过语言文字这种符号，将不同模态的信号统一地表达，并在脑中构建了某种受限于当前科技水平的统一模型，这是人类意识、社会沟通的前提。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;640&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2b649a1a09a15cf7b884e20d56d53e2351c.png&quot; width=&quot;553&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从这个角度理解，多模态大模型很可能是通向真正 AGI 的必经之路。将多模态信号统一对齐，是智能体与这个世界 「无障碍」 交互的前提，换个新潮的词汇，就是我们期待的 「具身智能」。谁不想拥有一台自己专属的 「Javis」 呢？而多模态大模型的突破，也同样依赖前文所述的算力和数据上的沉淀。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【1】https://epoch.ai/blog/can-ai-scaling-continue-through-2030&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【2】Newell, A., &amp;amp; Simon, H. A. (1956). The Logic Theory Machine – A Complex Information Processing System. IRE Transactions on Information Theory, 2(3), 61-79.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【3】Silver, David, et al. &quot;Mastering the game of Go with deep neural networks and tree search.&quot; nature 529.7587 (2016): 484-489.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【4】 Wei, Jason, et al. &quot;Chain-of-thought prompting elicits reasoning in large language models.&quot; Advances in neural information processing systems 35 (2022): 24824-24837.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【5】Yao, Shunyu, et al. &quot;Tree of thoughts: Deliberate problem solving with large language models.&quot; Advances in Neural Information Processing Systems 36 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【6】Karpas, Ehud, et al. &quot;MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.&quot; arXiv preprint arXiv:2205.00445 (2022).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【7】Schick, Timo, et al. &quot;Toolformer: Language models can teach themselves to use tools.&quot; Advances in Neural Information Processing Systems 36 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【8】https://huggingface.co/spaces/mteb/leaderboard&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【9】https://github.com/deep-floyd/IF&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【10】https://developer.nvidia.com/blog/pushing-the-boundaries-of-speech-recognition-with-nemo-parakeet-asr-&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;models/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【11】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2312.00752&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Mamba: Linear-time sequence modeling with selective state spaces&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【12】Peng, Bo, et al. &quot;Rwkv: Reinventing rnns for the transformer era.&quot; arXiv preprint arXiv:2305.13048 (2023).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【13】Wen, Kaiyue, Xingyu Dang, and Kaifeng Lyu. &quot;Rnns are not transformers (yet): The key bottleneck on in-context retrieval.&quot; arXiv preprint arXiv:2402.18510 (2024).&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【14】AI Models Collapse When Trained on Recursively Generated Data’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;【15】The Platonic Representation Hypothesis&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;作者简介：&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-801234c121b48f695ff62c699b6340119e6.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;傅聪&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;浙江大学计算机博士，美国南加州大学访问学者，《业务驱动的推荐系统：方法与实践》作者。高性能检索算法 NSG、SSG 的发明者，知乎科技博主 「傅聪 Cong」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;前阿里巴巴算法专家，目前就职于 Shopee（新加坡）任资深算法专家。在顶会和期刊 TPAMI、KDD、VLDB、IJCAI、EMNLP、CIKM 等发表十余篇论文，同时也是 Tpami、TKDE、KDD、ICLR、AAAI、IJCAI、EMNLP、ICLR 等会议的审稿人。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337999</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337999</guid>
            <pubDate>Wed, 05 Mar 2025 09:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源大模型未必更先进，但会更长久</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;文 / 顾钧&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「开源」 是指采用符合 OSI 官方认可的软件许可证进行软件发布的行为。目前大模型的 「开源」 与传统的开源定义并不相同。我所说的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源策略&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;是指以开源发布软件为起点，用户 / 开发者运营为途径的软件产品推广策略。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;450&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ce9ab25299ac92c8a92d48aab3b9721223.png&quot; width=&quot;1125&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;我的观点是，开源策略是大模型最好的竞争策略。&lt;/strong&gt;接下来让我们从头捋一捋推导过程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们先看大模型赛道的整体状况：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型是一项相对较新的技术。尽管 OpenAI 早在 2019 年就发布了第一个重要的模型 GPT-2，但大模型的广受关注实际始于 2022 年 11 月发布的 ChatGPT。8 个月以后 Meta 就与微软合作发布了开源大模型 LLaMA-2。这个赛道的主要玩家在技术和商业化上有差距，但没有到翻盘无望的程度。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型赛道不但包括模型的训练，也包括模型服务。训练是软件的制作成本，而服务是软件的长期运行成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型赛道的市场化程度非常高。算法、算力、数据、人才，这些构建大模型的基础要素并不为权力机构垄断，大多要从市场上获得。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型作为一项令人激动的技术，商业化场景覆盖了对企业 (2B) 与对个人 (2C) 两个大方向。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型赛道在海外是 「一超多强」，在国内则是 「多头并举」，两种典型的竞争格局都全了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以上，大模型赛道的元素非常丰富，各种商业化方法的排列组合都不缺，为我们的分析与推演提供了可贵的素材。对软件商业化问题感兴趣的朋友一定要长期关注这个赛道。只有这样的对象才能更有力地说明开源策略的重要性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其次，我们得明确一点 ——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 大模型竞争的赛点是什么？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;常用的判断依据包括：技术的先进性，C 端用户基数，依赖这个软件的生态系统大小等等。其中哪个更关键一点？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技术先进是好事，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但大模型领域的先进技术远没有达到能为大模型企业带来可观收入的程度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。整个大模型赛道还处在商业化的摸索阶段。这个时间点上的 「技术先进性」 更多是用于公关宣传的素材。考虑到数据获取、加工的成本，模型训练的成本，这是一种相当昂贵的宣传方式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;C 端用户指那些把大模型当成智能个人助理来使用的普通个人用户。OpenAI 在 ChatGPT 上一个重要且成功的操作就是把大模型从学术界、工业界直接推向了普通个体，让 C 端用户切实感受到了大模型的可能性与魅力。这一点被国内的大模型厂商广泛学习。在 B 站刷视频，国内知名的那几个大模型厂商的广告，你一个也不会落下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;受到大家的认可与喜爱固然重要，但&lt;strong&gt;对于 C 端用户，有两个需要时刻牢记的问题：一是&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; C 端用户是没有忠诚度的，谁免费就用谁，谁给补贴就用谁；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;二是&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;某一个大模型对 C 端用户比较难产生独特的粘性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一个问题的例证太多了，百团大战、滴滴快的、社区团购、pdd。大模型厂商维系 C 端流量的成本可能是个无底洞。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第二个问题则涉及两个方面，一是大模型赛道本身的极度内卷，技术上拉不开差距；二是普通用户的使用随意性很强，准确性要求也不高，最终各家大模型的基础能力都足以应付。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一个大模型的生态系统的大小，也就是指有多少开发者在基于这个大模型构建应用。我认为这是一个更靠谱的评价指标，是某个大模型最终能胜出的关键所在。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;构建开发者生态通常有两种做法，一种是提供 API 云服务，对注册开发者进行一定的云资源补贴；另一种是 「开源」 的方法，提供大模型免费下载，免费商用（一定条件下）。&lt;/strong&gt;两种方法各有支持者。闭源大模型一般会采用第一种方法，其中的代表有 OpenAI、Anthropic 等（为避免麻烦，国内厂商的名字就不提了）。能用第二种方法的，必然是某种程度上的 「开源」 模型，以 Meta 的 Llama 2、Llama 3 模型为首。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0.0001pt; margin-right:0px; text-align:center&quot;&gt;&lt;img height=&quot;1026&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ffd7efbdae1f135dc2b129c9cf368dce9a3.png&quot; width=&quot;1200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;前段时间李彦宏在 Create 2024 百度 AI 开发者大会上放言 「开源模型会越来越落后」。前文我有提到，此时此刻的技术先进性并不重要。甚至在计算机发展史上，很多领域中笑到最后的产品，并不是技术上最先进的。抛开成本和易用性，空谈技术先进性是最常见的错误。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那么具体到大模型领域，闭源与开源，两种方法孰优孰劣？我的回答是采取什么方法因人而异，但开源会更有优势。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型赛道的核心制约条件是成本太高 ——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; 训练成本高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;运行成本高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。如何尽可能降低成本，比对手坚持得更久一些是确保长期成功的必要条件。现在的宏观环境下，一味靠融资来支撑自己的高成本支出不是长久之计。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;闭源大模型厂商必须维持一定的云资源，工程师资源来支撑小额的开发者调试需求。投入产出上恐怕是算不过来的。即便闭源厂商愿意持续地补贴开发者，他们最终会发现大模型对开发者的粘性也非常有限，没比在 C 端用户那边好到哪里去。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大模型这一产品形态实在是太特殊了 —— 大多以自然语言为交互方式。因此大模型 API 云服务的接口是非常简单的，高度一致的。在这种情况下，如果开发者构建的大模型应用只是调用大模型的 API，那么大模型应用与某个具体的大模型之间很难形成强绑定。也就是说，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面对各种大模型云服务，主动权在开发者这里。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与之相对，&lt;strong&gt;开源的方法至少可以相当程度地省去为了拓展开发者生态而付出的大模型运行成本。&lt;/strong&gt;开发者免费下载大模型以后，会在自己的计算机资源上进行大模型应用的开发和调试。大模型厂商提供一些技术支持即可。同时因为大模型运行在本地，开发者在构建大模型应用时，为了物理部署上的便利，很可能会在应用与模型之间创造出物理部署上的耦合性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当然这种 「开源策略」 不是进攻的方法，而是 「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;先为不可胜，以待敌之可胜&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」。目标是以最小的代价，尽可能多地消耗闭源对手的资源与心气。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e50ab675a71a016a8fd47aba8c9533dacde.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;顾钧&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;资深开发者社区运营专家，目前担任杭州映云科技 (EMQ) 市场 &amp;amp; 开发者社区总监一职。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2004 年，顾钧从北京大学计算机系本科毕业，其后在工商银行、IBM、摩根士丹利、华为和 Zilliz 等多家知名企业工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;曾联合发起全球首个开源向量数据库项目 Milvu&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;s&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;并&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;帮助 Milvus 社区在两年间迅速拓展到两千家企业用户。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337998</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337998</guid>
            <pubDate>Wed, 05 Mar 2025 09:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>2024 中国开源模型：崛起与变革</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文 / Tiezhen、Adina、Lu Cheng&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中国在开源人工智能模型领域的崛起和变革成为全球瞩目的焦点：从学术到产业，从技术到生态，中国通过自主研发和协同创新，逐步完成了从 「追随者」 到 「引领者」 的转变。这种转变不仅是技术实力的体现，更是中国人工智能生态系统快速完善的真实写照。以下，我们将从崛起与变革两个维度，探讨中国开源模型在这一年取得的重大成就和未来展望。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;崛起&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;从 「追随者」 到 「引领者」&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中国学术界和产业界大力推进自主研发，在技术创新和模型能力上实现了显著飞跃，并在全球范围内取得了显著成就。&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopen-llm-leaderboard-open-llm-leaderboard.hf.space%2F&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face Open LLM 排行榜&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;数据显示，从智谱的 GLM 系列、阿里巴巴的 Qwen 系列到深度求索的 DeepSeek 系列，这些自主研发的模型在国内外各项评测中表现卓越。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;img height=&quot;798&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b88a736bf0e35cc263820fcde150380c6d3.png&quot; width=&quot;1047&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;每个月来自中国主要研究机构和公司的开源模型 / 数据集数量。图片源自 Hugging Face 中文社区模型社群：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;span style=&quot;color:#999999&quot;&gt;https://huggingface.co/spaces/zh-ai-community/zh-model-release-heatmap&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其中，Qwen 系列凭借灵活的多尺寸选项，强大的多语言支持以及友好的模型授权功能，赢得了社区开发者的高度评价。DeepSeek 通过引入多头潜在注意力（Multi-head Latent Attention, MLA）技术，在性能和成本上实现了革命性突破，开创高性价比的 AI 新纪元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;智谱的 CogVideoX 系列文生视频模型，成为全球首批开源的文生视频模型之一，不仅在技术方面让中国视频生成模型列入领先梯队，强化了中国模型在全球范围的竞争力，也为国际开源生态的发展产生了积极的影响，为全球开发者提供了更多创新和应用的可能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国开源模型从最初的质疑中崛起，逐步赢得了广泛认可。这不仅彰显了中国开源模型从追随者到行业引领者的跨越式成长，也为全球人工智能发展注入了新的活力与动力。中国开源模型的成功并非偶然。在政府对人工智能产业的持续支持以及国内人工智能行业对模型研发的巨额投入下，从基础算法到行业应用、从算力基础设施到数据资源整合，中国人工智能生态体系正在迅速完善。这一趋势表明，未来中国有可能在全球人工智能领域占据更为核心的地位。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;开源生态的繁荣与协作&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着开源模型影响力的提高，中国开源社区的活跃度也明显提升。无论是企业、研究机构还是个体开发者都更加积极地参与到开源工作中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;以阿里巴巴的通义千问 Qwen 为例，据不完全统计，截止 2024 年 9 月，全球已有近 8 万基于 Qwen 的衍生模型，超越了 Meta 的 Llama。该系列模型已被集成到 Hugging Face Transformers、Hugging Chat 和阿里自家的百炼平台中，极大促进了全球开发者的交流和协作，形成了国际化开源生态。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;北京智源研究院和上海人工智能实验室等研究机构，通过与企业和高校合作及开源平台的建设，建立了更完善的协作机制，从而在开源模型 (如 InternLM) 和数据集 (如 Infinity-MM) 领域贡献了大量有影响力的基础工作和资源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中国开源社区涌现出众多高质量的自发研究成果。其中，MAP 团队推出的全开源模型 Map Neo 引人瞩目。该模型在训练数据、脚本以及模型对齐工作上实现了全面公开，成为国内少有的真正意义上完全开源的项目。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;而 InstantX 团队的 InstantID 则作为中国模型在国际开源社区的 2024 年首秀，一经发布便获得了广泛关注，为中国模型在全球开源生态中赢得了更多认可。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;平衡发展与合规创新&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国在推动人工智能技术发展的同时，也在监管层面努力建立了完善、透明的治理机制。这种监管创新为开源模型的发展提供了稳定的政策环境，同时确保技术应用符合社会价值导向。比如 《人工智能示范法 2.0（专家建议稿）》对于免费且已开源方式提供人工智能研发的个人和组织给予减轻或免承担法律责任；《生成式人工智能服务管理暂行办法》 则明确了人工智能技术的使用和合规要求，促进了开源模型在合规框架下良性发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;变革&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;端上模型的兴起与隐私保护&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随着小型模型的性能逐步增强，更多高级 AI 正转向在个人设备上运行。这一趋势不仅显著降低了云端推理成本，还提升了用户隐私控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国 AI 社区在这一领域也做了重要贡献，推出了如 Qwen2-1.5B、MiniCPM 系列和 DeepSeek Janus 等多款移动友好型模型。其中，最新发布的 GLM Edge 1.5B 模型通过与高通 GenAI 扩展的联合优化，在搭载骁龙 8 Gen 4 处理器的手机上实现了每秒 65 个 tokens 的推理速度，接近人类语音的平均输出速率。尽管存在电池续航和内存占用过大等挑战，端上模型代表了 AI 技术隐私保护和成本优化的未来方向。中国在这一领域的探索，为行业提供了宝贵经验。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;推理扩展法则的潜力释放&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通过推理扩展法则，模型性能可通过延长 「思考时间」 而进一步优化。这一技术模拟了人类 「深思熟虑」 的过程，显著提升了模型在逻辑推理和复杂任务中的表现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国开源社区在逻辑推理领域推出了许多创新项目，包括阿里巴巴国际的 Macro-o1、通义千问团队的 QwQ、上海人工智能实验室的 LLaMA-O1 和清华大学的 Llama-3.2V-11B-cot。这些模型不仅在技术上各具特色，还通过开源策略分享了大量研究细节，为整个开源社区提供了丰富的资源，在这一过程中，小模型不仅在推理能力上有了显著提升，也推动了行业整体技术水平的进步。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;结合当前人工智能产业界的 「人工智能 +」 计划，小模型在特定任务优化上的优势愈发突出，预计将在金融、医疗和工业自动化等热门领域发挥引领作用，以更高效、更精准的方式满足多样化需求，帮助人工智能在实际应用场景中落地。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#4874cb&quot;&gt;&lt;strong&gt;开源多元化与应用细分&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中国开源模型的发展不仅体现在技术突破上，还在生态建设中展现出巨大的活力。中国开源模型从竞争激烈的 「百模大战」 逐步迈向多元化和深度细分，国内社区在今年发布了大量高质量开源模型，尤其是多模态理解与生成模型：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fmllms-664b68f4217010520d1987c2&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;多模态理解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：Qwen2-VL、Ovis、InternVL2、DeepSeek JanusFlow、GOT-OCR2_0；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fimage-models-66b0c329ddeea53c140fd84c&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图片生成&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：PixArt、Lumina、Kolors、Hunyuan-DiT、VAR、Meissonic；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Fvideo-models-666afd86cfa4e4dd1473b64c&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;视频生成&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：AnimateDiff-lightning、Latte、OpenSora、open-sora-plan、Pyramid Flow、CogVideoX；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fzh-ai-community%2Faudio-models-666983e79d56215237e411ae&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;TTS&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：GPT-SoVITS、ChatTTS、CosyVoice、FishAudio、MaskGCT、F5-TTS 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这一趋势表明，模型的竞争已经从单纯的规模比拼转向应用场景细化。为了更好地展现这一演进路径，我们在&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fzh-ai-community&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face 的中文模型社群&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中对各个领域的开源模型进行了系统整理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;strong&gt;展望&lt;/strong&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年，中国开源模型的发展展现了技术、生态和社会价值之间的深度协同。无论是从技术创新到社区建设，还是从行业实践到合规探索，中国开源生态体系的完善正在为全球人工智能发展注入源源不断的动力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 Hugging Face，我们坚信开源是推动人工智能技术进步和生态繁荣的核心力量。开源不仅能够打破技术壁垒，促进全球开发者之间的协作与创新，还能推动技术的普惠化，让更多的人能够平等地享受人工智能带来的便利与机遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在未来，中国开源模型有望继续为全人类的智能化生活提供更丰富的解决方案与可能性。我们希望看到更多来自中国的开源 AI 团队通过开放协作推动技术边界的不断拓展，共同构建一个更加包容、多元与可持续发展的人工智能的未来。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a5d60686c70430cd3f50d5ce0af17621950.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tiezhen&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;现任 Hugging Face 工程师，曾在 Google Brain 任职。兼具实干精神与梦想追求，坚信开源是连接全球的纽带，让 AI 的益处普惠大众。他秉持 &quot;高手在民间&quot; 的理念，渴望激励更多的开源模型从业者成为行业的关键意见领袖，挖掘群体的智慧与潜能，促进社区的成长和影响力的扩大。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:justify&quot;&gt;&lt;img height=&quot;204&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-77ccf0b11126b7efa913c41d44363e4d8d2.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Adina&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face 中文社区项目经理。拥有 10 年以上国际化工作经验，足迹遍及亚洲、非洲和欧洲。从社会科学研究员到科技公司项目专员，积累了丰富的跨领域与跨文化经验。专注推动人工智能在中文开源社区的应用与发展，为开发者和企业带来更多价值，助力知识共享与技术协作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4750483e084a8931724469418cd70e68a6e.png&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Lu Cheng&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hugging Face Fellow，致力于推动 AI 和开源软件的采纳和开发者体验。拥有超过十年的开发者关系、产品营销和开源生态构建的经验，曾在 Google 负责多个开发技术的深度推广和社区建设，包括 Android、Flutter 和 TensorFlow 等。他坚信开源是推动技术进步和开发者成长的关键步骤，希望有更多人参与开源和社区共建。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337996</guid>
            <pubDate>Wed, 05 Mar 2025 09:18:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 编程神器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-03-07%2Fai-startup-anysphere-in-talks-for-close-to-10-billion-valuation&quot; target=&quot;_blank&quot;&gt;据彭博社报道&lt;/a&gt;&lt;/u&gt;，Cursor 母公司 Anysphere 正在与投资者洽谈新一轮融资，估值可能高达 100 亿美元。这一数字是其三个月前估值的四倍（2024 年 12 月估值为 25 亿美元）。若融资成功，Cursor 将成为继 OpenAI、Anthropic 之后，AI 应用层又一家「百亿美元独角兽」。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0310/170903_Rt06_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anysphere（Cursor 的母公司）并不开发自己的生成式 AI 模型，而是依赖 Anthropic 和 OpenAI 的模型来驱动 Cursor。尽管如此，Cursor 凭借其易用性、速度以及对用户代码库的深入理解，赢得了开发者的广泛好评。&lt;/p&gt; 
&lt;p&gt;《The Information》报道指出，包括卡片初创公司 Ramp 和 AI 搜索引擎 Perplexity 在内的众多公司，都在使用 Cursor 来提升开发效率。&lt;/p&gt; 
&lt;p&gt;Cursor 提供免费、20 美元/月和 40 美元/月三种订阅模式，相较于竞争对手 Devin 每月 500 美元的定价，Cursor 在价格上具有明显优势。&lt;/p&gt; 
&lt;p&gt;《The Information》指出，Cursor 的收入增速已经超过了上一代软件初创公司。以 100 亿美元估值计算，Cursor 的市销率（估值/年化经常性收入）约为 66 倍。&lt;/p&gt; 
&lt;p&gt;Cursor 的快速发展，也加剧了 AI 编程助手市场的竞争。OpenAI 和 Anthropic 都在积极推出自己的代码编辑工具。&lt;/p&gt; 
&lt;p&gt;《The Information》报道称，Cursor 最初使用 OpenAI 的模型，但在 7 月将默认模型更改为 Anthropic。&lt;/p&gt; 
&lt;p&gt;几个月后，OpenAI 在 ChatGPT 中推出了名为 Canvas 的代码编辑工具。上周，Anthropic 也推出了自己的代码编辑器 Claude Code。此外，OpenAI 还在开发一款更高级的编码助手产品，旨在复制高级软件工程师的工作。&lt;/p&gt; 
&lt;p&gt;除了 OpenAI 和 Anthropic，其他初创公司也在积极布局。上个月，Kleiner Perkins 领投了 Codeium，估值接近 30 亿美元。Codeium 与 Cursor 类似，也在几个月前以 12.5 亿美元的估值融资 1.5 亿美元。Poolside 也在开发编码助手应用和模型，尽管去年收入不足 1000 万美元，但该公司可能在未来的融资中寻求 50 亿美元的估值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336236&quot; target=&quot;news&quot;&gt;使用 Cursor 编程的 15 条经验建议&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328600&quot; target=&quot;news&quot;&gt;Cursor 的开源替代来了：Roo-Cline&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/320498/anysphere-acquires-supermaven&quot; target=&quot;news&quot;&gt;Cursor 母公司 Anysphere 收购 AI 编码助手 Supermaven&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337993/anysphere-in-talks-for-close-to-10-billion-valuation</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337993/anysphere-in-talks-for-close-to-10-billion-valuation</guid>
            <pubDate>Wed, 05 Mar 2025 09:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>麦当劳餐厅引入 AI 技术，缓解员工日常工作压力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.techspot.com%2Fnews%2F107065-mcdonald-turns-ai-boost-order-accuracy-stay-ahead.html&quot; target=&quot;_blank&quot;&gt;据 TechSpot 报道&lt;/a&gt;&lt;/u&gt;，麦当劳正借助 AI 技术提升全球 4.3 万家餐厅的运营效率，缓解员工的日常工作压力。&lt;/p&gt; 
&lt;p&gt;据悉麦当劳将首先从与互联网连接的厨房设备、人工智能驾驶式餐厅和为经理提供的人工智能工具开始进行 AI 改造。&lt;/p&gt; 
&lt;p&gt;新技术提供了许多可能性。例如，计算机视觉可以在订单传递给顾客之前，使用厨房中的固定摄像头检查准确性。像麦当劳去年与 IBM 测试的那种自动点餐 AI，可以简化「汽车餐厅」订单。安装在厨房设备上的传感器可以实时收集数据，并据此更好地预测油炸锅或冰淇淋机何时最有可能出现故障。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-141dbbc1d525b54b58e81dea0e262c47926.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;麦当劳首席信息官 Brian Rice 表示，麦当劳的目标是「为顾客和员工带来更好的体验，他们如今要应对从机器故障到下错订单等各种问题」。&lt;/p&gt; 
&lt;p&gt;据报道，麦当劳在 2023 年末选择了谷歌云，为其每家餐厅提供更强大的计算能力，使其能够在现场处理和分析数据。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337989/mcdonald-turns-ai-boost-order-accuracy-stay-ahead</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337989/mcdonald-turns-ai-boost-order-accuracy-stay-ahead</guid>
            <pubDate>Wed, 05 Mar 2025 08:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>superfile —— 美观现代的终端文件管理器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;superfile 是一款功能强大的现代终端文件管理器，它能完成你所需的文件操作。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;275&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/163509_5ESm_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;275&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/163630_bjwN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;精致美观的用户界面&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;可以说好看才是 superfile 的初衷，所以整个 superfile 要尽量的好看。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;功能齐全&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;这个文件管理器允许你在文件管理器上执行几乎所有你想做的事情。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;完全可定制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;从基本的热键开始，整个主题颜色甚至边框样式都可以自定义。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;多面板&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;多面板允许你同时查看多个目录，只需几个简单的步骤即可进行复制和粘贴，而无需返回主目录。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/superfile</link>
            <guid isPermaLink="false">https://www.oschina.net/p/superfile</guid>
            <pubDate>Wed, 05 Mar 2025 08:38:00 GMT</pubDate>
        </item>
        <item>
            <title>罗永浩：细红线科技 2025 年春季招聘启动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 10 日，罗永浩在微博&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7762107285%2FPhRUQkj7D&quot; target=&quot;_blank&quot;&gt;发文表示&lt;/a&gt;&lt;/u&gt;，细红线科技 2025 年春季招聘已经启动，相关岗位如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;资深软件产品经理（5 名）&lt;/li&gt; 
 &lt;li&gt;AI 方向软件产品经理（5 名）&lt;/li&gt; 
 &lt;li&gt;IM 方向软件产品经理（2 名）&lt;/li&gt; 
 &lt;li&gt;BI 数据产品经理（2 名）&lt;/li&gt; 
 &lt;li&gt;商业化产品经理（2 名）&lt;/li&gt; 
 &lt;li&gt;软件产品实习生（8 名）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1152&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/154800_c89p_2720166.png&quot; width=&quot;1232&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;罗永浩并未在 JD 中透露各岗位的薪资待遇，部分岗位的职责如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1840&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0310/155313_5yVn_2720166.png&quot; width=&quot;854&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/336990&quot; target=&quot;news&quot;&gt;罗永浩从小米挖来操作系统「老兵」，为打造「AIOS」招兵买马&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328454&quot; target=&quot;news&quot;&gt;罗永浩 AI 初创项目 J1 Assistant 海外官网上线&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/326288&quot; target=&quot;news&quot;&gt;罗永浩「最后一次创业」最新进展：密集招聘大模型人才，或开发 AI 硬件&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337973</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337973</guid>
            <pubDate>Wed, 05 Mar 2025 07:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>抖音：少数账号以 AI 类工具为噱头实施诈骗等行为</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;抖音安全中心 3 月 10 日发布关于打击「非法荐股」等违法证券活动的公告（二）称，近日，平台发现，有少数账号在无相关资质情况下，声称可借助各种 AI 类工具，实现所谓「高回报高收益」，或以「推荐高效 AI 选股工具」「售卖 AI 炒股课程」为噱头引发用户关注，甚至对其实施诈骗等行为。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例一：账号「首*财经」「小*财富空间」等在无相关资质的情况下发布视频，声称借助某款 AI 类工具，对某只或某几只具体股票的未来走势进行「精准」分析预判，发布带有诱导投资倾向的具体投资话术，如「用**（某 AI 类工具）分析，某只股票短期内有较高上升潜力，止盈和止损价格可分别设定为‘**元’和‘**元’」。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例二：账号「小**博弈」「小**饱」等在无相关资质的情况下发布视频，声称借助某款 AI 类工具可实现「高收益」「高回报」，如「炒股 4 个月赚 230 万，AI 真的太香了」「你敢相信么，**（某 AI 类工具）可以帮你抓大妖股」「用**（某 AI 类工具），12 天（盈利）32%」「用**（某 AI 类工具）实在太强大了，居然全部获利，而且全部卖飞了」等。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;案例三：账号「爱股*队」「爱股*女」等在无相关资质的情况下，以「炒股神器」「时代机遇」「炒股机遇最大化」为噱头，宣传、推广或兜售某几款 AI 类工具的培训课程（具体形式包括训练营、培训班、教学资料等）。个别账号还试图通过暱称、头像、签名、评论等渠道，发布引流信息，诱导用户脱离抖音后前往第三方平台，甚至对其实施诈骗等违法行为。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上述言行，严重违反了平台规则，平台对相关账号和视频进行了严格处置，具体处置方式包括但不限于封禁账号、下架视频、收回直播和营利权限、抹除账号不当获取粉丝，以及清退违规账号所属 MCN 机构等。情节严重者，平台将向公安机关报案。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337969</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337969</guid>
            <pubDate>Wed, 05 Mar 2025 07:48:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Hugging Face 首席科学官担心 AI 正在变成「服务器上的应声虫」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;Hugging Face 联合创始人兼首席科学官 Thomas Wolf &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FThom_Wolf%2Fstatus%2F1897630495527104932&quot; target=&quot;_blank&quot;&gt;最近发文称&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;如果人工智能研究没有实质性突破，AI 可能仅会成为「服务器上的应声虫」，而非真正的创新者。&lt;/strong&gt;他进一步解释说，当前的人工智能开发范式无法产生能够进行创造性问题解决的 AI，而这种问题解决能力能够赢得诺贝尔奖。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f91c400aa9a6f13136086d41d35dc3afb13.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Wolf 认为，当前的 AI 发展路径难以产生能够进行创造性思考和突破性解决方案的系统。他指出，现有的 AI 模型更像是「非常听话的学生」，擅长填补已知知识之间的空白，但缺乏质疑现有认知框架和提出全新问题的能力。&lt;/p&gt; 
&lt;p style=&quot;color:#3a3a3a; margin-left:0; margin-right:0; text-align:justify&quot;&gt;沃尔夫在文章中写道，「要在数据中心创造爱因斯坦，我们不仅需要一个知道所有答案的系统，而且还需要一个能够提出别人从未想过或不敢问的问题的系统。」沃尔夫将这一问题部分归因于 AI 领域的「评估危机」。他指出，目前用于衡量 AI 系统进步的基准测试大多集中在有明确、封闭式答案的问题上，这限制了系统发展出质疑和创新能力的可能性。&lt;/p&gt; 
&lt;p style=&quot;color:#3a3a3a; margin-left:0; margin-right:0; text-align:justify&quot;&gt;作为解决方案，他建议行业应当发展新的评估标准，能够测量 AI 是否能采取「大胆的反事实方法」，并基于微小线索提出一般性建议。「科学最重要的方面是提出正确问题和质疑自己所学知识的能力，我们不需要一个能用常识回答所有问题的 A+ 学生，而是需要一个能看到并质疑其他人所错过的东西的 B 级学生。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337966/ai-is-becoming-yes-men-on-servers</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337966/ai-is-becoming-yes-men-on-servers</guid>
            <pubDate>Wed, 05 Mar 2025 07:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>