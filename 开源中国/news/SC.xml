<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Fri, 28 Mar 2025 02:38:59 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>ChatGPT 图像生成功能引发版权争议</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;OpenAI 近日&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/340984/openai-gpt-4o-image-generation&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;在 GPT-4o 模型中集成了迄今为止最先进的图像生成器，并将其整合进 ChatGPT 中，而其优秀的生图能力让不少网友为之着迷。&lt;/p&gt; 
&lt;p&gt;与此同时，由 GPT-4o 生成的、带着日本动画工作室「吉卜力」风格的大量生成式图片开始成为网络热门梗图，并在互联网上大规模传播。&lt;/p&gt; 
&lt;p&gt;在这一大批的「吉卜力工作室风格」图片中，不仅包括埃隆・马斯克、《指环王》以及唐纳德・特朗普等著名人物的形象，连 OpenAI CEO Sam Altman 都开始将自己的新头像换成由 GPT-4o 生成的「吉卜力风格」图像。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bd2d9abaccb5193ce4150a3140d75fb8430.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而这波「吉卜力」热潮也引发了大众对「AI 生图是否会涉及版权纠纷」这一问题的思考。TechCrunch 援引 Neal &amp;amp; McDevitt 律师事务所的知识产权律师埃文・布朗的说法&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F03%2F26%2Fopenais-viral-studio-ghibli-moment-highlights-ai-copyright-concerns%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;&lt;/u&gt;，像 GPT-4o 图像生成器这样的产品如今处于法律灰色地带。&lt;/p&gt; 
&lt;p&gt;布朗表示，风格本身并未明确受到版权保护，这意味着 OpenAI 仅通过生成类似吉卜力电影风格的图像似乎并没有违反法律。同时布朗也指出，GPT-4o 可能是通过学习吉卜力电影的数百万帧画面，生成的图片才实现了这样的相似性。据悉，目前仍有多国的法院正在裁定，使用版权作品训练 AI 模型是否属于合理使用保护范围。&lt;/p&gt; 
&lt;p&gt;对于上述的争议，OpenAI 发言人向 TechCrunch 发布一份声明表示，虽然 GPT-4o 的图像生成器拒绝复制「在世个人艺术家的风格」，但允许复制「更广泛的工作室风格」。同时其也强调，部分在世的艺术家因其独特的创作风格而获得市场认可，例如吉卜力工作室的联合创始人宫崎骏。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341482/openais-ghibli-ai-copyright</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341482/openais-ghibli-ai-copyright</guid>
            <pubDate>Fri, 28 Mar 2025 02:34:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>从对话到自主行动：AI 应用如何从 Chat 进化为 Agent？开源项目源码深度揭秘</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;strong&gt;一、引言&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;从 2022 年 12 月份 OpenAI 发布 ChatGPT 产品至今已有 2 年多的时间，当大家已经习惯于在对话框中与 AI 交互，习惯于通过各种 Prompt 技巧让 AI 更好的理解并回答我们的问题，似乎默认这就是一种比较好与 AI 的交互方式了。&lt;/p&gt; 
&lt;p&gt;然而，这就是我们期盼的与 AI 交互的形式嘛？这是一种高效的方式嘛？&lt;/p&gt; 
&lt;p&gt;显然，这是不够的。&lt;/p&gt; 
&lt;p&gt;我们期望的是：告诉 AI 我们想要的目标或者任务，AI 能够理解深度理解并分析我们的意图、自动的进行任务的拆解、自动的寻找可以使用的工具、自动的进行结果数据的汇总过滤、自动的呈现符合任务的展示形式。同时在任务处理过程中，可以自己完成异常的检测和修改。就如同一位优秀的同学，我们告诉他任务的目标，他可以自己寻找飞书文档、搜索网络知识、使用内部系统、自己编码验证方案可行性，并最终给一份好的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二、以「对话为中心」的 ChatBot&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们发送一条指令，AI 被动的响应指令。即完成一轮人与 AI 的交互。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;具体视频请前往「得物技术」微信公众号观看。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;三、以「交付为中心」的多智能体 Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们发送一个任务，AI 自动分析任务、调用可用的工具、分析结果、过滤数据并自动处理异常，最终呈现解决方案。&lt;/p&gt; 
&lt;p&gt;完成这样的一个任务，需要多智能体 Agent 间的协作以及对常用工具的调用。那什么是智能体 Agent 呢？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;具体视频请前往「得物技术」微信公众号观看。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;四、什么是智能体 Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从 Prompt 到思维链&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着大模型的发展，Prompt 工程已成为撬动大模型潜能的核心技术。即使我们普通用户在与大模型的交互中，也通过角色定义（如&quot;资深工程师&quot;）或示例引导来优化输出效果，但这类简单提示往往难以突破模型固有的逻辑天花板——就像给赛车装自行车轮胎，再怎么调整也难以突破速度极限。&lt;/p&gt; 
&lt;p&gt;但偶然间，人们发现了一个神奇的咒语：只需要告诉大模型，&lt;strong&gt;你的 think 要 step by step&lt;/strong&gt;。研究者发现只要加了这个 prompt，就能极为显著地改善大模型做数学题的正确率。&lt;/p&gt; 
&lt;p&gt;大模型的数学与逻辑能力短板，是所有体验过其对话功能的用户都能直观感受到的痛点。这一缺陷严重制约了大模型的商业化落地进程，毕竟没有人敢轻易信任一个逻辑混乱的智能系统能输出可靠的决策结果。于是，提升大模型数学能力，被所有做基础模型的公司当作了第一目标。&lt;/p&gt; 
&lt;p&gt;研究者试图通过强化思维链来突破这一瓶颈。一个直观的思路是：让模型像人类解题时在草稿纸上推演那样，通过 &quot;step by step&quot; 的方式展开逻辑链条 —— 在这个过程中，包含假设、演绎、反思、纠错等一系列思维活动。既然人类通过这种结构化的思考方式能够有效解决数学问题，那么大模型是否也能通过类似机制实现能力跃迁？这一猜想推动着研究向纵深发展，最终形成了思维链技术的核心框架。这样的观念经过继续钻研，最终就构成了思维链，思维链是一个能以最小的代价，而非常显著提升模型智力水平（逻辑能力、解题能力、代码能力）的技术。&lt;/p&gt; 
&lt;p&gt;值得注意的是，2025 年春节期间引发广泛关注的 DeepSeek 大模型，正是思维链技术的成功实践典范。尽管 DeepSeek 并非首创者，但其通过创新性地融合混合专家（MoE）架构与强化学习技术，显著提升了思维链推理的计算效率与性能表现。这种技术优化使得 DeepSeek 在保持高精度推理的同时，大幅降低了计算成本，最终实现了屠榜级表现。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ReAct 架构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果说思维链（COT）是给 AI 装上了人类的 &quot;草稿纸&quot;，那么 ReAct 框架就是为它配备了 &quot;双手&quot;—— 让 AI 不仅能在脑子里推演，还能主动采取行动获取信息。这种 &quot;思考 + 行动&quot; 的组合，正在把大模型从 &quot;纸上谈兵&quot; 的理论家，变成能解决现实问题的实干家。&lt;/p&gt; 
&lt;p&gt;ReAct 的核心在于将**推理（Reasoning）与行动（Action）**紧密结合。当模型面对复杂问题时，会先像人类一样拆解思考步骤，然后根据中间结果调用外部工具（如搜索引擎、数据库、计算器）获取实时数据，再把这些信息整合到后续推理中。&lt;/p&gt; 
&lt;p&gt;其实，实现一个 ReAct 很简单，只需要构建 Prompt+提供工具+循环执行即可，笔者在这里不进行详细的介绍，只需要给一个 Prompt 例子，读者就能理解：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;尽可能最好地为用户回答接下来的问题，你可以使用以下工具来辅助你：{tools} 使用以下格式：&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;问题：你需要回答的输入问题&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;思考：你需要持续思考下一步采取什么行动&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;行动：要采取的行动，应该是&amp;nbsp;[{tool_names}]&amp;nbsp;中的一个，以及该行动的输入内容&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;观察：行动并观测结果，并判断结果是否合理 ...（这个思考&amp;nbsp;/&amp;nbsp;行动&amp;nbsp;&amp;nbsp;/&amp;nbsp;观察可以重复 N 次，直到你认为知道了最终答案&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;最终答案：原始输入问题的最终答案&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;开始！&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;问题：{input}&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Tools 支持开发者自定义，比如给予 LLM 一个查询天气的接口、计算器接口等。&lt;/p&gt; 
&lt;p&gt;ReAct 架构实现了一种**&quot;问题拆解-工具调用-结果整合&quot;的&lt;strong&gt;闭环机制&lt;/strong&gt;，使得开发者仅需通过定义工具集（如天气 API、计算器、知识图谱接口）和设计任务引导词，就能将大模型转化为可执行多步骤决策的智能体。最终可以使大模型突破纯文本推理的局限，真正具备了在动态场景中解决开放性问题的工程化能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Agent 作为大模型技术的集大成者，通过整合思维链（CoT）的推理能力和 ReAct 框架的行动机制，构建了具备自主决策与执行能力的智能系统。其核心突破在于将**「大脑」与「四肢」**有机统一，标志着大模型从被动应答迈向主动干预现实的质变。&lt;/p&gt; 
&lt;p&gt;在架构上，Agent 与 ReAct 差别不大，ReAct 是 Agent 的核心实现范式之一，Agent&lt;strong&gt;进一步整合&lt;/strong&gt;记忆存储、多智能体协作等模块，形成更完整的自主决策系统。下图是一个简单的 Agent 架构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/v2-ad31f685f1330333011c67eccc3cb64c_1440w_1743044594868.png&quot; alt=&quot;v2ad31f685f1330333011c67eccc3cb64c_1440w.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent 处理流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1-4 步会循环进行，直到 LLM 认为问题已被回答。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.规划（Planning）：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;定义：规划是 Agent 的思维模型，负责拆解复杂任务为可执行的子任务，并评估执行策略。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实现方式：通过大模型提示工程（如 ReAct、CoT 推理模式）实现，使 Agent 能够&lt;strong&gt;精准拆解任务&lt;/strong&gt;，分步解决。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2.记忆（Memory）：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;定义：记忆即信息存储与回忆，包括短期记忆和长期记忆。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实现方式：&lt;strong&gt;短期记忆&lt;/strong&gt;用于存储会话上下文，支持多轮对话；&lt;strong&gt;长期记忆&lt;/strong&gt;则存储用户特征、业务数据等，通常通过向量数据库等技术实现快速存取。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3.工具（Tools）：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;定义：工具是 Agent 感知环境、执行决策的辅助手段，如 API 调用、插件扩展等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实现方式：通过接入外部工具（如 API、插件）扩展 Agent 的能力，如 ChatPDF 解析文档、Midjourney 文生图等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4.行动（Action）：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;定义：行动是 Agent 将规划与记忆转化为具体输出的过程，包括与外部环境的互动或工具调用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实现方式：&lt;strong&gt;Agent 根据规划与记忆执行具体行动&lt;/strong&gt;，如智能客服回复、查询天气预报、AI 机器人抓起物体等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Manus：一个 Agent 典型案例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在读完前一节关于智能体（Agent）的技术解析后，读者也许会认为这类系统的工程实现并非难事，实际上也确实是这样。近期爆火的 Agent 产品 Manus 便是典型案例。当用户提出 &quot;定制 7 天日本旅行计划&quot; 的需求时，Manus 能够基于目标，自主进行网络搜索并将信息整合，展现出&lt;strong&gt;高度拟人化的任务执行逻辑&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/2_1743044773894.png&quot; alt=&quot;2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;尽管 Manus 目前尚未向普通用户开放，且采用邀请制注册的封闭运营模式，但其通过官方演示视频呈现的强大智能化表现，已在技术圈引发广泛关注。值得关注的是，随着 Agent 技术的热度攀升，开源社区已迅速涌现出 OpenManus、OWL 等多个复刻项目。&lt;/p&gt; 
&lt;p&gt;因为 Manus 并非开源，我们很难了解其技术细节。但好在：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&quot;Manus 的部分技术细节，包括其提示词设计、运行机制等内容被网友通过非官方渠道披露，感兴趣的读者可自行查阅相关公开资料。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;我们可以了解一下&lt;strong&gt;大模型上下文协议&lt;/strong&gt;（Model Context Protocol，MCP），这是 Anthropic (Claude) 主导发布的一个开放的、通用的、有共识的协议标准，虽然 Manus 不一定用了这个协议，但目前一些相关开源项目也是基于 MCP 的，本文会在下面介绍 MCP。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;目前已有复刻的开源项目 Openmanus，笔者会在接下来的章节剖析其源码。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;大模型上下文协议（MCP）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MCP 是做什么的？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MCP（Model Context Protocol）作为一项开放协议，旨在为应用程序与大型语言模型（LLMs）之间的上下文交互提供标准化框架。其设计理念可类比为数字时代的 &quot;USB-C 接口&quot;—— 正如 USB-C 统一了设备与外设的连接标准，MCP 通过标准化的上下文交互接口，实现了 AI 模型与多样化数据源、工具之间的无缝对接。&lt;/p&gt; 
&lt;p&gt;如下图所示，图中的 MCP server 都可以看成一个个工具 (如搜索引擎、天气查询)，通过「接口」连接到 MCP clients(大模型) 上，大模型可以使用各种 MCP server 来更好地处理用户的问题。&lt;/p&gt; 
&lt;p&gt;此外，下游工具的开发者也可以更好的开发其工具，目前在 MCP 官网即可了解其各种编程语言的 SDK 和相关概念。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/3_1743044805628.png&quot; alt=&quot;3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MCP 架构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MCP 的核心采用客户端-服务器架构，其中 host 可以连接到多个服务器，读者简单看看即可：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_bcaed6dc-c3e0-4917-a824-cf74a340516g_1743045011163.png&quot; alt=&quot;img_v3_02kp_bcaed6dcc3e04917a824cf74a340516g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MCP 主机（MCP Hosts）：指需要通过 MCP 协议获取数据的应用程序，涵盖 AI 开发工具（如 Claude Desktop）、集成开发环境（IDEs）等智能应用场景。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP 客户端（MCP Clients）：作为协议的执行者，每个客户端与对应的 MCP 服务器建立一对一的专属连接，负责协议层面的通信交互。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MCP 服务器（MCP Servers）：轻量化的功能载体，通过标准化的 Model Context Protocol 对外开放特定能力，可视为连接模型与工具的智能桥梁。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;本地化数据源（Local Data Sources）：包括服务器可安全访问的本地文件系统、数据库及专有服务，构成数据交互的近端生态。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;远程服务（Remote Services）：通过互联网连接的外部系统，例如各类 API 接口服务，拓展了模型的能力边界。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;为什么要用 MCP？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;从技术演进视角看，MCP 的诞生是提示工程（Prompt Engineering）发展的必然产物。研究表明，结构化的上下文信息能显著提升大模型的任务表现。在传统提示工程中，我们往往需要人工从数据库筛选信息或通过工具检索相关内容，再手动将这些信息注入提示词。然而，随着复杂任务场景的增多，这种手工注入信息的操作变得愈发繁琐且低效。&lt;/p&gt; 
&lt;p&gt;为解决这一痛点，主流大模型平台（如 OpenAI、Google）先后引入了&lt;strong&gt;函数调用（Function Call）机制&lt;/strong&gt;。该机制允许模型在推理过程中主动调用预定义函数获取数据或执行操作，极大提升了自动化水平。然而，函数调用机制存在显著局限性：其一，不同平台的函数调用 API 存在较大差异，例如 &lt;strong&gt;OpenAI 与 Google 的实现方式互不兼容&lt;/strong&gt;，开发者在切换模型时需重新编写代码，徒增适配成本；其二，该机制在安全性、交互性及复杂场景的扩展性方面仍存在优化空间。&lt;/p&gt; 
&lt;p&gt;在此背景下，MCP 协议通过标准化的上下文交互接口，为大模型构建了更具普适性的工具调用框架。它不仅&lt;strong&gt;解耦&lt;/strong&gt;了模型与工具的依赖关系，还通过统一的协议规范解决了跨平台兼容性问题。更重要的是，MCP 将上下文管理提升到系统架构层面，为大模型在复杂业务场景中的深度应用提供了可扩展的技术底座。这种从碎片化的提示工程到体系化的上下文协议的演进，标志着大模型应用正在向更高效、更规范的方向迈进。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;四、智能体 Agent 实现的源码剖析（OpenManus 项目）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_7f7cdb11-c5c3-435e-8bdc-c98e38f9cddg_1743045055057.png&quot; alt=&quot;img_v3_02kp_7f7cdb11c5c3435e8bdcc98e38f9cddg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenManus 是一个基于 MCP 协议的开源智能体实现项目，旨在通过标准化的上下文协议实现大模型与工具的高效协同。当前项目仍处于快速迭代阶段，本文以其 2025 年 3 月 12 日的版本为分析对象。选择该项目的原因如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;团队背景与代码质量&lt;/strong&gt;：项目作者来自 MetaGPT，具备深厚的工程经验，代码结构清晰且注释完善，兼顾了技术实现与可读性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;部署便捷性&lt;/strong&gt;：只需通过虚拟环境安装依赖并配置大模型 API Key（如 OpenAI 的 API 密钥），即可快速启动，降低了技术门槛。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;技术前沿性&lt;/strong&gt;：项目紧跟大模型技术发展，且目前仍在不断迭代的过程中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在经过前面对相关概念的讨论，我们可以得知实现 Agent 有几个关键的点，读者可以带着问题在项目中寻找答案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt&lt;/strong&gt;：其结构化的 Prompt 是什么样的？通过 Prompt 可以对其架构有一个初步认识。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenManus&lt;/strong&gt;：怎么通过大模型思考和处理问题？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;工具相关&lt;/strong&gt;：怎么进行工具注册、工具管理的？工具执行逻辑是什么的？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;准备&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;项目地址：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmannaandpoem%2FOpenManus%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://github.com/mannaandpoem/OpenManus/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;构建环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;创建一个 python=3.12 的虚拟环境&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;笔者测试了一下，非 3.12 版本会有一个 package 不兼容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可以用 conda 或 python 内置的 uv，项目文档提供了详细的指令。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;安装 playwright&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果第一次使用，需要安装 playwright。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;playwright install
## 或者
python -m playwright install
## 以上命令会安装所有浏览器，如果只需要安装一个浏览器比如 firefox
python -m playwright install firefox
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;配置大模型 API Key&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;可以用 DeepSeek 或通义千问的 API Key，其中通义有免费额度，DeepSeek 虽然收费但价格便宜，测试一次使用约 1000token,成本不到 0.01 元。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据项目文档配置 cofig.yaml 即可，但项目调用大模型是使用基础的 OpenAI API，如果使用其他大模型，可能需要基于对应的官方文档小改一下。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;代码&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OpenManus 客户端&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Python OpenManus/main.py&lt;/strong&gt;即可在终端运行 OpenManus，读者也可以尝试其 Web 版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;具体会调用 20 行代码，执行 Manus 类的方法 run()。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_037da761-0f23-414c-b15d-567f598ac4bg_1743045114713.png&quot; alt=&quot;img_v3_02kp_037da7610f23414cb15d567f598ac4bg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;进入 OpenManus/app/agent/manus.py 查看 Manus 类，可以发现它继承了 ToolCallAgent 类，再进入会发现又是继承，有点复杂，这里我画一张关系图。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;act() 执行时使用 execute_tools() 进行具体的工具执行。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;总体来说，Manus 类定义了 Prompt 和可使用的工具。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Base 类定义了 run()，在 run() 中会循环执行 ReAct 类的方法 step()，直到 Finish 或达到 max_step。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;step() 类会顺序执行 ToolCallAgent 类的 think() 和 act()。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当然，这里只罗列了重要的组件和方法，一些方法没有画在图中。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_e50578dd-ab27-439f-91d9-7a3f5e38943g_1743045152115.jpg&quot; alt=&quot;img_v3_02kp_e50578ddab27439f91d97a3f5e38943g.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prompt&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一般来说，输入给 LLM 的 prompt 分为两种：1）&lt;strong&gt;系统 prompt&lt;/strong&gt;，用于定义模型的角色定位和行为规则；2）&lt;strong&gt;用户 prompt&lt;/strong&gt;(OpenManus 称为 Next Step Prompt)，用于传达具体的任务指令或信息需求。&lt;/p&gt; 
&lt;p&gt;在 OpenManus/app/prompt/manus.py 中即可看到 Manus 的 Prompt，这里展示一下中文版，读者基于此可对 OpenManus 架构有一个初步认识：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;系统 Prompt（SYSTEM_PROMPT）&lt;/strong&gt;：「你是 OpenManus，一个全能的人工智能助手，旨在解决用户提出的任何任务。你拥有各种可使用的工具，能调用这些工具高效地完成复杂的请求。无论是编程、信息检索、文件处理还是网页浏览，你都能应对自如。」&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下一步 Prompt（NEXT_STEP_PROMPT）&lt;/strong&gt;：「你可以使用 PythonExecute 与计算机进行交互，通过 FileSaver 保存重要的内容和信息文件，使用 BrowserUseTool 打开浏览器，并使用 GoogleSearch 检索信息。根据用户的需求，主动选择最合适的工具或工具组合。对于复杂的任务，你可以将问题分解，逐步使用不同的工具来解决它。在使用完每个工具后，清晰地解释执行结果并给出下一步的建议。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当然，在实际执行时会对 prompt 有进一步优化，不过核心的系统定位与任务指导原则是不会改变的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Manus 类&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_83117adc-20bf-418f-bd98-933c2671522g_1743045172551.png&quot; alt=&quot;img_v3_02kp_83117adc20bf418fbd98933c2671522g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们先看一下 OpenManus 拥有的工具，工具也支持自定义，会在后文进行介绍。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;PythonExecute：执行 Python 代码以与计算机系统交互、进行数据处理、自动化任务等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FileSaver：在本地保存文件，例如 txt、py、html 等文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BrowserUseTool：打开、浏览并使用网络浏览器。如果你打开一个本地 HTML 文件，必须提供该文件的绝对路径。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GoogleSearch：执行网络信息检索。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Terminate：如果 LLM 认为回答完毕，会调用这个工具终止循环。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Base 类&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;run()&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_36fbb768-418d-4f28-92b6-76943131916g_1743045221456.jpg&quot; alt=&quot;img_v3_02kp_36fbb768418d4f2892b676943131916g.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，输入的 request 就是用户输入的提问。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;状态管理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_036ebee8-ebfd-4b4c-94cb-283d4a071aag_1743045238174.jpg&quot; alt=&quot;img_v3_02kp_036ebee8ebfd4b4c94cb283d4a071aag.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;执行时首先检查代理的当前状态是否为 &lt;code&gt;IDLE&lt;/code&gt;（空闲状态）。如果不是空闲状态，会抛出 &lt;code&gt;RuntimeError&lt;/code&gt; 异常，因为只有在空闲状态下才能启动代理的执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_1fa59b67-e152-4706-9e10-3f001a8b2a2g_1743045249523.jpg&quot; alt=&quot;img_v3_02kp_1fa59b67e15247069e103f001a8b2a2g.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;当进入循环时前，使用 &lt;code&gt;state_context&lt;/code&gt;上下文管理器将代理的状态临时切换到 &lt;code&gt;RUNNING&lt;/code&gt;（运行状态）。在上下文管理器中执行的代码块会&lt;strong&gt;在进入时&lt;/strong&gt;将状态切换为指定状态，&lt;strong&gt;在退出时&lt;/strong&gt;恢复到之前的状态。如果在执行过程中&lt;strong&gt;发生异常&lt;/strong&gt;，会将状态切换为 &lt;code&gt;ERROR&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Memory 管理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们调用大模型的 API，本质是向大模型提供方发 http 请求，http 请求是无状态的。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;也就是说，服务端不会保留任何会话信息。对于每次都完成一个独立的任务，无状态是没有任何问题的。但对持续聊天来说，就会出现对之前会话一无所知的情况。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以为了让大模型持续与用户的对话，一种常见的解决方案就是把聊天历史告诉大模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;因此，在 OpenManus 中会进行 Memory 的管理。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_8c1e4d88-12b8-40d9-804e-d82c2e6b68cg_1743045314471.jpg&quot; alt=&quot;img_v3_02kp_8c1e4d8812b840d9804ed82c2e6b68cg.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; &lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_c7474598-2b00-42e5-9b77-935079c3b55g_1743045390335.png&quot; alt=&quot;img_v3_02kp_c74745982b0042e59b77935079c3b55g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;用户提供的 &lt;code&gt;request&lt;/code&gt; 参数，调用 &lt;code&gt;update_memory&lt;/code&gt; 方法将该请求作为用户消息添加到代理的 Memory 中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;除了这个函数，Manus 也在进行 think()、act() 时也会更新 Memory，同时 Memory 容量也不是无限大的，容量满时需要删除老的 Message。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;主循环&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_1ce79275-4452-405c-bd68-6c976d9a2bfg_1743045415135.png&quot; alt=&quot;img_v3_02kp_1ce792754452405cbd686c976d9a2bfg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;agent 本质就是循环执行。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;step 实现参考 react step。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;循环结束条件：max_steps 或者 FINISHED 状态。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;每次执行一个 step 并获得 result——step_result = await self.step()。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;is_stuck&lt;/code&gt; 方法用于检查代理是否陷入了循环（即是否出现了重复的响应）。如果是，则调用 &lt;code&gt;handle_stuck_state&lt;/code&gt; 方法处理这种情况，例如添加一个提示来改变策略。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;ReAct&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;step()&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_3999f1b8-a5bb-413f-826c-a4b7c3d8836g_1743045441792.png&quot; alt=&quot;img_v3_02kp_3999f1b8a5bb413f826ca4b7c3d8836g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这里的逻辑很简单。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;ToolcallAgent&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Think()&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;输入：不需要输入，因为用户的 question 是被存放在 Memory 中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;输出：一个 bool 类型，当内部 LLM 判断需要 act() 时，为 True，否则为 Fasle。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;询问 LLM&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_ecd6a300-6d25-4268-a783-101c86d86a0g_1743045468280.png&quot; alt=&quot;img_v3_02kp_ecd6a3006d254268a783101c86d86a0g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;55 行的代码用于调用 LLM 的 API 接口，获取回复。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_d194c2fc-a02e-47b9-be3c-05ab5195c25g_1743045483264.png&quot; alt=&quot;img_v3_02kp_d194c2fca02e47b9be3c05ab5195c25g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对应到 OpenManus/app/llm.py 233 行附近，这里就是基于 OpenAI 提供的 API 接口进行对话，具体的参数可参考相应官方文档。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这里会将之前定义的&lt;strong&gt;下一步 Prompt&lt;/strong&gt;发给 LLM，LLM 会根据提供的工具列表，判断是否需要且调用的是哪个工具，当然也可能是：1）不需要工具只进行回复 2）调用 Terminate 工具结束会话。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下图是一次返回&lt;strong&gt;response 结果&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;输入的 question 是「计算 Kobe Bryant 的 BMI？」，LLM 先分析出了要通过浏览器查询资料，因此要 use the BrowserUseTool。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据传入的工具类型等信息，LLM 自动构建了执行工具需要用的 tool_name、action 等参数。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;ChatCompletionMessage(
    content=&quot;It seems there was an issue with retrieving the information about Kobe Bryant&#39;s height and weight through a Google search. To calculate Kobe Bryant&#39;s BMI, we need his height and weight. Let&#39;s try to find this information by opening a browser and visiting a reliable source. I will use the BrowserUseTool to navigate to a website that provides details about Kobe Bryant&#39;s height and weight. Let&#39;s proceed with this approach.&quot;, 
    refusal=None, 
    role=&#39;assistant&#39;, 
    annotations=None, 
    audio=None, 
    function_call=None, 
    tool_calls=[
        ChatCompletionMessageToolCall(
            id=&#39;call_aez57ImfIEZrqjZdcW9sFNEJ&#39;,
            function=Function(
            arguments=&#39;{
                &quot;action&quot;:&quot;navigate&quot;,
                &quot;url&quot;:&quot;https://www.biography.com/athlete/kobe-bryant&quot;
                }&#39;, 
            name=&#39;browser_use&#39;), 
            type=&#39;function&#39;)]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;think 后续逻辑&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;think() 后续的逻辑比较简单，主要是更新 memory(memory 存储单位是 message)，最后在 100 行附近的逻辑，基于 self.tool_choices 等参数的设置和 LLM 返回的工具列表，输出 bool 类型结果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时，需要被调用的工具会被记录到 self.tool_calls 这个列表中，后续的 act() 会执行对应的工具。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Act()&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;输入：同 think()，不需要输入。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;输出：results，根据工具结果构建的一个字符串。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_44e6894b-d915-40ec-82dc-03c8e3e970bg_1743045510286.png&quot; alt=&quot;img_v3_02kp_44e6894bd91540ec82dc03c8e3e970bg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这个函数比较简单，主要是调用 execute_tool() 函数。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Execute_tool()&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_030fab99-df15-4e81-9a61-d3ff3bed5aeg_1743045520994.png&quot; alt=&quot;img_v3_02kp_030fab99df154e819a61d3ff3bed5aeg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该函数会调用&lt;code&gt;Tool&lt;/code&gt;类提供的接口 execute()。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Tool&lt;/code&gt;类接口会在后面介绍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同时，对于预设定的&lt;strong&gt;special tool&lt;/strong&gt;，会 self._handle_special_tool(name=name, result=result) 进行特殊处理。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;当前的&lt;strong&gt;special tool&lt;/strong&gt; 只有一个 Terminate 工具，特殊处理就是设置 Agent 的状态为 AgentState.FINISHED，结束对话。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;工具相关&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们在之前介绍了 MCP 相关的概念，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_841aa8cc-b6d7-4423-a435-decd316bc3bg_1743045533595.png&quot; alt=&quot;img_v3_02kp_841aa8ccb6d74423a435decd316bc3bg.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;事实上，OpenManus 也是基于 MCP 的，OpenManus 的 tool 相当于 MCP server，根据 MCP 协议，我们只需要定义 tool 类&lt;strong&gt;支持的方法和参数等&lt;/strong&gt;，每次&lt;strong&gt;注册一个新工具&lt;/strong&gt;，根据父类 override 一个子类即可。&lt;/p&gt; 
&lt;p&gt;那我们首先要了解父类都定义了什么参数和方法，也就是 OpenManus/app/tool/base.py 定义的&lt;code&gt;Basetool&lt;/code&gt;类。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Base Tool&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_3a61d251-8cb3-4353-9aad-1dd28cd6686g_1743045570393.png&quot; alt=&quot;img_v3_02kp_3a61d2518cb343539aad1dd28cd6686g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，代码很简单，每个 tool 包含的参数为:name、description(提供给 LLM 看的，对工具的介绍)、parameters(执行工具时要用的参数)。&lt;/p&gt; 
&lt;p&gt;同时，一个 tool 支持的方法有 execute() 和 to_param()。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;execute() 用于执行具体的逻辑，每个子类&lt;strong&gt;需要 override 这个方法&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;to_param() 将工具调用的结果结构化输出。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;当然，这里还有一个 python 关键字__call__，这个关键字很简单，定义了__call__，该类的实例对象可以像函数一样被调用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;工具 JSON&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;可以根据 OpenManus 预定义的工具 json 简单了解一下，每个工具执行时需要的参数。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
  {
    &quot;type&quot;: &quot;function&quot;,
    &quot;function&quot;: {
      &quot;name&quot;: &quot;python_execute&quot;,
      &quot;description&quot;: &quot;Executes Python code string. Note: Only print outputs are visible, function return values are not captured. Use print statements to see results.&quot;,
      &quot;parameters&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;code&quot;: {
            &quot;type&quot;: &quot;string&quot;,
            &quot;description&quot;: &quot;The Python code to execute.&quot;
          }
        },
        &quot;required&quot;: [&quot;code&quot;]
      }
    }
  },
  {
    &quot;type&quot;: &quot;function&quot;,
    &quot;function&quot;: {
      &quot;name&quot;: &quot;google_search&quot;,
      &quot;description&quot;: &quot;Perform a Google search and return a list of relevant links.\nUse this tool when you need to find information on the web, get up-to-date data, or research specific topics.\nThe tool returns a list of URLs that match the search query.\n&quot;,
      &quot;parameters&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;query&quot;: {
            &quot;type&quot;: &quot;string&quot;,
            &quot;description&quot;: &quot;(required) The search query to submit to Google.&quot;
          },
          &quot;num_results&quot;: {
            &quot;type&quot;: &quot;integer&quot;,
            &quot;description&quot;: &quot;(optional) The number of search results to return. Default is 10.&quot;,
            &quot;default&quot;: 10
          }
        },
        &quot;required&quot;: [&quot;query&quot;]
      }
    }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;工具示例——google_search&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OpenManus 项目在 OpenManus/app/tool 中定义了 bash 工具、浏览器工具、谷歌搜索工具等，这里简单看一下谷歌搜索工具。&lt;/p&gt; 
&lt;p&gt;当然，国内可能比较难使用谷歌搜索，OpenManus 社区也有大佬提供了 baidu、bing 等搜索引擎工具。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://h5cdn.dewu.com/efe/ctoo-open-blog-admin/10787572/img_v3_02kp_970ea258-0aca-4c89-8098-0b7f28db476g_1743045589976.png&quot; alt=&quot;img_v3_02kp_970ea2580aca4c8980980b7f28db476g.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看出，代码很简单，主要做了两件事。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;定义工具参数：name、description、parameters。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定义 execute：基于 googlesearch 库提供的函数进行搜索并返回。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;五、总结&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OpenManus 的代码介绍到这里，主要是介绍一下核心代码，同时，原作者写了 planning 部分的代码但暂时没有应用到项目中，笔者也没有介绍。如果想对该项目有更进一步的了解，请大家查看 github 上提供的源码。而且，作者还是非常积极的，每天会有十几个 commit。&lt;/p&gt; 
&lt;p&gt;同时，读者可以简单本地部署玩一下 OpenManus，通过几个 prompt，就可以知道该项目还是停留在「玩具阶段」，比如笔者测试了一下，当询问「计算一下科比的 BMI？」，OpenManus 可以很准确的实现**谷歌搜索——浏览器访问——&lt;strong&gt;python 计算&lt;/strong&gt;这个过程。但如果询问「计算科比、梅西的 BMI 并排序？」，无论我改写了几次 prompt，OpenManus 都没有给我满意的回答。&lt;/p&gt; 
&lt;p&gt;此外，无论是在工具参数信息、还是 prompt、memory 管理中，都可以看到 agent 应用大模型 token&lt;strong&gt;消耗量巨大&lt;/strong&gt;，即使我们不考虑 token 成本，但大模型的上下文仍然是有限的，这种资源消耗也会直接导致模型在处理多步骤任务时面临&lt;strong&gt;信息截断的风险&lt;/strong&gt; —— 早期的关键信息可能因上下文溢出而被丢弃，进而引发推理链条的断裂。更值得警惕的是，当模型试图在有限的上下文中 「脑补」 缺失的信息时，往往会产生与事实不符的幻觉。&lt;/p&gt; 
&lt;p&gt;鉴于此，尽管 OpenManus 展示出了利用工具链解决复杂问题的潜力，不过距离成为一个实用、高效且稳定的生产级人工智能助手仍有很长的路要走。未来，开发者们或许需要在优化工具使用逻辑、提升多任务处理能力、降低大模型 token 消耗以及增强上下文管理等方面进行深入探索与改进。同时，对于普通用户而言，在体验这类项目时，也应该保持理性和客观的态度，既看到其创新性和趣味性，也认识到其当前存在的局限性。希望在技术的不断迭代和完善下，OpenManus 以及类似的项目能够早日突破现有的瓶颈，真正为人们的工作和生活带来实质性的帮助。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538265%26idx%3D1%26sn%3D46126305e017551fce1c548a0d482d52%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物技术部算法项目管理实践分享&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2. &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538263%26idx%3D1%26sn%3D78e7e307da19e903656c2de2afb96dc9%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;商家域稳定性建设之原理探索｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;3. &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538237%26idx%3D1%26sn%3D47a37918d6e1a0123644ea690f7bdaad%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物 Android Crash 治理实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;4. &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538099%26idx%3D1%26sn%3Db973a4052f5460509f2bd25ed888995e%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;基于 ANTLR4 的大数据 SQL 编辑器解析引擎实践｜得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;5. &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538072%26idx%3D1%26sn%3Dc3506a84400c5cc3c72b2b0ff2291384%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;LSM-TREE 从入门到入魔：从零开始实现一个高性能键值存储 ｜ 得物技术&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;文 / 汉堡&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周一、三更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18015687</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18015687</guid>
            <pubDate>Fri, 28 Mar 2025 02:31:35 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>比尔盖茨称赞 DeepSeek：AI 全球竞争无国界</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软联合创始人比尔·盖茨日前在纽约经济俱乐部的讲座中，分享了他个人自传《源代码》的创作过程，并深入探讨了人工智能（AI）的发展及其对全球社会的影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;盖茨在谈及为何此时出版回忆录时表示：「尽管我通常更关注未来，但在自己 70 岁即将到来，微软迎来 50 周年，盖茨基金会也将迎来 25 周年之际，我觉得是时候回顾过去，并分享一些重要的思考。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在谈到人工智能（AI）进展时，盖茨表达了对其飞速发展的惊叹。他提到自己有一个团队专注于每周跟踪 AI 领域的新动向，并亲自尝试这些新技术。特别是在谈到中国的 DeepSeek 时，盖茨称其效率提升显著，且其技术实现方式已经公开。他指出:「在全球最顶尖的八种 AI 模型中，有三种来自中国。DeepSeek 在许多标准下，至少在一个月内，已经是全球最好的。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;277&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-95c1e6071d84aff4995acf668a997c0b833.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;盖茨进一步强调，AI 的创新无国界:「谁是第一经常在变，但无论来自中国还是美国，优秀的创意和技术都会在全球范围内共享。AI 不会属于某一个国家。」他认为，这种全球共享的趋势对教育、健康甚至农业等多个领域都是积极的推动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;盖茨还提到，美国应更加广泛地讨论人工智能的政策问题。「我认为，到 2028 年，除了经济议题，AI 将成为讨论的焦点。」他认为，政策制定者应重视 AI 对各行各业的深远影响，并确保该领域的快速发展与社会利益相匹配。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341480</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341480</guid>
            <pubDate>Fri, 28 Mar 2025 02:24:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>GPT-4o 模型更新，改进处理复杂任务和编码能力</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;GPT-4o 模型昨晚进行了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1905331956856050135&quot; target=&quot;_blank&quot;&gt;升级&lt;/a&gt;&lt;/u&gt;，发布新版本 GPT 4o-03-26：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对提示的遵循度大幅提升，尤其是一次性的多个提示内容&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;改进了处理复杂任务和编码能力&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;减少了过多的表情符号输出问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高了直觉和创造能力&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在竞技场排名中跃升至第 2，超过了其最新模型 GPT-4.5&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1592&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0328/101502_anch_2720166.png&quot; width=&quot;1292&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;最新的 GPT 4o-03-26 API 也已经更新&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAIDevs%2Fstatus%2F1905335104211185999&quot; target=&quot;_blank&quot;&gt;提供&lt;/a&gt;，代号为「chatgpt-4o-latest」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1546&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0328/101619_TpqQ_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341478/gpt-4o-03-26</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341478/gpt-4o-03-26</guid>
            <pubDate>Fri, 28 Mar 2025 02:17:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动豆包新版深度思考开启测试</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;字节跳动旗下豆包宣布新版深度思考功能开启测试。&lt;/p&gt; 
&lt;p&gt;和之前的深度思考不同，新版功能将推理过程的思维链与搜索深度结合，支持边想边搜。思考过程中，豆包可基于推理多次调用工具、搜索信息，提供更加全面、准确的结果。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;274&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ac5e5e55a32b65c4c8ccaae098245cbda1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;制定方案和规划：豆包可根据思考结果推理缺失信息，继续定向搜索，让最终结果更完善&lt;/li&gt; 
 &lt;li&gt;辅助专业文章写作：辅助专业文章写作，深层次检索资料信息；梳理复杂问题脉络，提升思考深度&lt;/li&gt; 
 &lt;li&gt;模糊条件搜索：面对模糊关键词，检索尽可能多的结果；交叉验证核心信息，精准锁定目标答案&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可通过打开豆包 app 最新版本或 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fdoubao.com&quot; target=&quot;_blank&quot;&gt;doubao.com&lt;/a&gt; 选择「深度思考」模式进行使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341477</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341477</guid>
            <pubDate>Fri, 28 Mar 2025 02:14:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源游戏机模拟器 Delta 更新预告，将为任天堂内核带来网络多人游戏功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Delta 是适用于非越狱 iOS 设备的开源游戏机模拟器，该项目发布预告称，将于下周一（3 月 31 日）推出大型更新（1.7），此次更新将带来&lt;strong&gt;任天堂 DS 网络多人游戏&lt;/strong&gt;和优化 N64 模拟表现。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b89a2d634d36d19dd0a70d54e3d1bc4121c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根据该模拟器官方描述，本次更新将为任天堂 DS（NDS）内核带来网络多人游戏功能，不过由于任天堂官方已经于 2014 年 5 月 20 日关闭了 NDS 的官方在线服务器（Nintendo Wi-Fi Connection），玩家若想联机玩多人游戏，&lt;strong&gt;需要连接到 Wiimmfi 等第三方服务器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-11fe6f50ddcd29917e0c8bd4f4580921871.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本次更新还带来了任天堂 64（N64）核心的改进，修复了纹理混合问题，并新增支持自定义分辨率和材质包，并升级图形 API 至 OpenGL ES 3.0。此外还将支持手柄快捷截图和在暂停菜单中截图，&lt;strong&gt;并支持了 GAMEBABY 和 PlayCase 等手机壳手柄&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a4df7cbb1d7432132e9e6e044453adb53a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ea44ccac81790a7bd413f7e9be9ee4052ba.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本次的更新将在下周一（3 月 31 日）推送，但等不及的玩家也可以加入该模拟器的 TestFlight 测试频道，下载该模拟器的公测版：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftestflight.apple.com%2Fjoin%2F7y15mYM1&quot; target=&quot;_blank&quot;&gt;https://testflight.apple.com/join/7y15mYM1&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341403/delta-emulator-1-7-testflight</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341403/delta-emulator-1-7-testflight</guid>
            <pubDate>Sat, 22 Mar 2025 11:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>李想谈自研汽车操作系统：多少有点「逼上梁山」的意味</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;3 月 27 日，理想汽车 CEO 李想在中关村论坛&lt;a href=&quot;https://www.oschina.net/news/341314&quot;&gt;宣布推出自研操作系统理想星环 OS&lt;/a&gt;，并表示理想星环 OS 将进行开源。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/140214_PaFU_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;随后，李想在微博&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1243861097%2FPkuc3ikEQ%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;发文&lt;/a&gt;&lt;/u&gt;透露了自研汽车操作系统的原因。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1564&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0327/181341_fkcQ_2720166.png&quot; width=&quot;1238&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;李想称，自 2020 年下半年起，全球芯片面临芯片结构性短缺，芯片的交货周期被拉长了几倍，价格也上涨了几倍甚至数十倍。理想汽车当时作为一家初创企业，在芯片供应链的产能分配中处于劣势，能够拿到的芯片供应量极为有限。即使拿到供应，还要考虑和操作系统适配的问题。&lt;/p&gt; 
&lt;p&gt;加上 AUTOSAR 这个闭源系统的性能、安全性、成本等劣势，理想汽车不得不决定自己来研发操作系统。&lt;/p&gt; 
&lt;p&gt;李想表示，现在来看，理想星环 OS 的自研，多少有点「逼上梁山」的意味。但理想汽车也因此意外打通了任督二脉，自研出一套适配时间更短、架构支持更广、关键性能更优的系统。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341396</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341396</guid>
            <pubDate>Sat, 22 Mar 2025 10:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>MaxKB 开源知识库问答系统 GitHub Star 数量突破 15,000 个！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;截至 2025 年 3 月 26 日 16:30，飞致云旗下开源项目——基于大语言模型和 RAG 的知识库问答系统 MaxKB GitHub Star 数超过 15,000 个！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;889&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f2a88a4c7bf969c5e9a1c020dcee4b05fe7.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341394</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341394</guid>
            <pubDate>Sat, 22 Mar 2025 10:06:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>多语言语料库万卷·丝路 2.0 开源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;上海人工智能实验室（上海 AI 实验室）联合新华社新闻信息中心、上海外国语大学、外研在线等，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0iXCGvkBvbHRB2A6p1Ergw&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;全新升级的「万卷·丝路 2.0」多语言语料库。&lt;/p&gt; 
&lt;p&gt;在「万卷·丝路 1.0」的基础上，2.0 语料库新增塞尔维亚语、匈牙利语、捷克语 3 类语料，涵盖四大数据模态共计 1150 万条数据，并运用精细化处理技术使数据质量达到「工业级」标准，实现「开箱即用」。&lt;/p&gt; 
&lt;p&gt;根据介绍，「万卷·丝路 2.0」具有多语言、大规模、多模态、高质量的特点，更新速览：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;语种数量扩充：在 5 个语种基础上，新增塞尔维亚语、匈牙利语、捷克语等 3 个稀缺语料数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据模态、总量全面升级：在纯文本数据基础上，新增图片-文本、音频-文本、视频-文本、特色指令微调 SFT 四大模态数据，覆盖多模态研究全链路；整体数据总量超过 1150 万条，音视频时长超过 2.6 万小时，满足多种研究任务的需求。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;超精细数据，多场景适用：经成熟数据生产管线及安全加固，结合过滤算法与当地专家人工精细化地标注质检，「万卷·丝路 2.0」 已成为覆盖多模态、多领域的大规模高质量数据集，含 20 余种细粒度多维分类标签及详细的文本描述，适配文化旅游、商业贸易、科技教育等不同场景，为开发者提供得力助手。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height=&quot;212&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-18155891e238aaf9136875f06cbdf9ea42d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为验证语料库质量与应用前景，上海 AI 实验室研究团队基于「万卷·丝路 2.0」，训练出匈牙利语大模型，通用能力对标国际主流大模型，在本地化特色、安全性与中国关联性上表现出显著优势，可适用于本地生活与中匈合作领域场景。&lt;/p&gt; 
&lt;p&gt;目前，该模型已衍生出对话平台、多语言 AI 教师助手、AI 匈中双语词典等创新应用。上海 AI 实验室同时与外研在线、库帕思等多家机构开展合作，推动「万卷·丝路 2.0」在教育、文旅、技术交流领域落地，助力多语言 AI 生态发展。&lt;/p&gt; 
&lt;p&gt;上海 AI 实验室研究团队认为，通过整合多模态数据与精细化标注技术，「万卷·丝路 2.0」首次实现了对低资源语言的系统性覆盖，尤其扩充了塞尔维亚语、匈牙利语、捷克语等语言的高质量语料建设，为文化交流互鉴带来可量化、可迭代的智能新维度。&lt;/p&gt; 
&lt;p&gt;「万卷·丝路」语料库下载链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopendatalab.com%2FapplyMultilingualCorpus&quot; target=&quot;_blank&quot;&gt;https://opendatalab.com/applyMultilingualCorpus&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341385</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341385</guid>
            <pubDate>Sat, 22 Mar 2025 09:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软开源 「Hyperlight Wasm」，将轻量级虚拟机技术扩展至 WASM</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;微软去年开源了一个名为「Hyperlight」的轻量级虚拟机项目，这是一个嵌入式虚拟机管理程序，可以用作微虚拟机管理器，支持在 Windows 和 Linux 应用程序中运行。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/170638_95Sv_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;近日，微软开源了 Hyperlight Wasm——将其轻量级虚拟机（VM）技术扩展至 WebAssembly（WASM）领域。&lt;/p&gt; 
&lt;p&gt;Hyperlight Wasm 基于开源项目 Hyperlight 构建，作为微虚拟机管理器，专为运行多语言编写的 WASM 组件工作负载设计。该项目兼容 Windows Hypervisor Platform（Windows）、KVM（Linux）和 / dev / mshv（macOS）等虚拟化平台，通过 VM 沙箱隔离不可信代码，兼顾高性能与安全性，适用于嵌入式函数等轻量化场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/170622_6rCp_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fhyperlight-dev%2Fhyperlight-wasm&quot; target=&quot;_blank&quot;&gt;Hyperlight Wasm 的 GitHub 仓库写道&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&quot;Hyperlight-Wasm 是一个组件，它使得 Wasm 模块能够在轻量级虚拟机支持的沙盒中运行。它的目的是使应用程序能够在 VM 中安全地运行不受信任或第三方 Wasm 代码，同时具有非常低的延迟/开销。它是建立在 Hyperlight 之上的。&lt;/p&gt; 
 &lt;p&gt;目前，Hyperlight-Wasm 支持 Windows 上的 Windows Hypervisor Platform、Linux 上的 KVM 或 /dev/mshv 运行应用程序。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.microsoft.com%2Fblog%2F2025%2F03%2F26%2Fhyperlight-wasm-fast-secure-and-os-free%2F&quot; target=&quot;_blank&quot;&gt;微软官方博客&lt;/a&gt;了解更多关于 Hyperlight Wasm 的信息。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341374/ms-hyperlight-wasm-fast-secure-and-os-free</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341374/ms-hyperlight-wasm-fast-secure-and-os-free</guid>
            <pubDate>Sat, 22 Mar 2025 09:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>KubeSphere v4.1.3 开源版发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;KubeSphere 4.1.3 开源版正式发布，本次更新包含多项功能优化和缺陷修复，进一步提升安全性与易用性。&lt;/p&gt; 
&lt;h2&gt;功能优化&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;优化企业空间的级联删除逻辑&lt;/strong&gt; 企业空间级联删除策略从被动改为主动，避免误操作。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;调整部分平台角色、企业空间角色的授权规则&lt;/strong&gt; 进一步细化 RBAC 授权规则，安全性提升。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化 Pod 列表页的数据展示&lt;/strong&gt; 更直观的展示资源状态信息，提升易用性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;允许用户关联多个身份提供程序&lt;/strong&gt; 用户可同时绑定多个身份提供程序（IdP），提升灵活性和兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持手动触发应用仓库更新&lt;/strong&gt; 用户可以主动刷新应用仓库，确保获取最新的应用版本信息。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增「拒绝访问」页面&lt;/strong&gt; 将非法的页面请求，重定向到「拒绝访问」页面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;缺陷修复&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;修复应用实例无法升级的问题&lt;/li&gt; 
 &lt;li&gt;修复与预发布 K8s 版本号的兼容性问题&lt;/li&gt; 
 &lt;li&gt;修复 LDAP 身份提供程序的配置问题&lt;/li&gt; 
 &lt;li&gt;修复无法从 Docker Hub 和 Harbor 搜索镜像的问题&lt;/li&gt; 
 &lt;li&gt;修复应用程序版本中处理特殊字符的问题&lt;/li&gt; 
 &lt;li&gt;修复未安装网关扩展时无法创建 Ingress 的问题&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;安装升级&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;欢迎广大用户下载体验，并提供宝贵反馈。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;注意事项&lt;/h3&gt; 
&lt;p&gt;更多更新内容，请参阅 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fdocs%2Fv4.1%2F20-release-notes%2Frelease-v413%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere 4.1.3 发布说明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;安装与升级，请参阅 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkubesphere.io%2Fzh%2Fdocs%2Fv4.1%2F03-installation-and-upgrade%2F&quot; target=&quot;_blank&quot;&gt;安装指南&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;注意：暂不支持从 v3.x 版本直接升级到 v4.x，计划在 4 月下旬的版本更新中支持。&lt;/p&gt; 
&lt;h3&gt;反馈渠道：&lt;/h3&gt; 
&lt;p&gt;提交 Issue：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fkubesphere%2Fkubesphere%2Fissues%2Fnew%2Fchoose&quot; target=&quot;_blank&quot;&gt;GitHub Issues&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;社区讨论：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.kubesphere.com.cn%2Fforum%2F&quot; target=&quot;_blank&quot;&gt;KubeSphere 论坛&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;未来展望&lt;/h2&gt; 
&lt;p&gt;在未来的版本更新中，KubeSphere 团队将持续关注开源社区的需求与反馈。我们承诺始终不忘初心，为广大的开源用户提供更稳定、更安全、更高效的产品体验。随着 KubeSphere 的不断演进，我们将不断优化平台的性能和功能，特别是在易用性、安全性以及多云环境支持等方面，确保用户在快速变化的技术环境中保持领先。&lt;/p&gt; 
&lt;p&gt;感谢每一位 KubeSphere 用户的支持和贡献，我们将继续努力，为大家带来更多惊喜和实用功能。期待您在未来的版本中，依旧能与我们一同成长和进步。&lt;/p&gt; 
&lt;p&gt;&amp;gt; 本文由博客一文多发平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom&quot; target=&quot;_blank&quot;&gt;OpenWrite&lt;/a&gt; 发布！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4197945/blog/18017524</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/18017524</guid>
            <pubDate>Sat, 22 Mar 2025 09:00:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>MCP Go —— MCP 的 Go 实现</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;Model Context Protocol (MCP)&amp;nbsp;的 Go 实现，实现 LLM 应用程序与外部数据源和工具之间的无缝集成。&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:var(--bgColor-muted, var(--color-canvas-subtle))&quot;&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:var(--fgColor-default, var(--color-fg-default))&quot;&gt;&lt;span style=&quot;background-color:var(--bgColor-muted, var(--color-canvas-subtle))&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;package&lt;/span&gt;&lt;/span&gt; main

&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;import&lt;/span&gt;&lt;/span&gt; (
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;context&quot;&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;errors&quot;&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;fmt&quot;&lt;/span&gt;&lt;/span&gt;

    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;github.com/mark3labs/mcp-go/mcp&quot;&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;github.com/mark3labs/mcp-go/server&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;func&lt;/span&gt;&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-comment)&quot;&gt;// Create MCP server&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;s&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;:=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;server&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;NewMCPServer&lt;/span&gt;&lt;/span&gt;(
        &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;Demo 🚀&quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;1.0.0&quot;&lt;/span&gt;&lt;/span&gt;,
    )

    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-comment)&quot;&gt;// Add tool&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;tool&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;:=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;NewTool&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;hello_world&quot;&lt;/span&gt;&lt;/span&gt;,
        &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;WithDescription&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;Say hello to someone&quot;&lt;/span&gt;&lt;/span&gt;),
        &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;WithString&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;/span&gt;,
            &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Required&lt;/span&gt;&lt;/span&gt;(),
            &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Description&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;Name of the person to greet&quot;&lt;/span&gt;&lt;/span&gt;),
        ),
    )

    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-comment)&quot;&gt;// Add tool handler&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;s&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;AddTool&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;tool&lt;/span&gt;, &lt;span&gt;helloHandler&lt;/span&gt;)

    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-comment)&quot;&gt;// Start the stdio server&lt;/span&gt;&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;:=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;server&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;ServeStdio&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;s&lt;/span&gt;); &lt;span&gt;err&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;!=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;nil&lt;/span&gt;&lt;/span&gt; {
        &lt;span&gt;fmt&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Printf&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;Server error: %v&lt;span&gt;\n&lt;/span&gt;&quot;&lt;/span&gt;&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt;)
    }
}

&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;func&lt;/span&gt;&lt;/span&gt; &lt;span&gt;helloHandler&lt;/span&gt;(&lt;span&gt;ctx&lt;/span&gt; context.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-storage-modifier-import)&quot;&gt;Context&lt;/span&gt;&lt;/span&gt;, &lt;span&gt;request&lt;/span&gt; mcp.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-storage-modifier-import)&quot;&gt;CallToolRequest&lt;/span&gt;&lt;/span&gt;) (&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;*&lt;/span&gt;&lt;/span&gt;mcp.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-storage-modifier-import)&quot;&gt;CallToolResult&lt;/span&gt;&lt;/span&gt;, &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-storage-modifier-import)&quot;&gt;error&lt;/span&gt;&lt;/span&gt;) {
    &lt;span&gt;name&lt;/span&gt;, &lt;span&gt;ok&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;:=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;request&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Params&lt;/span&gt;&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Arguments&lt;/span&gt;&lt;/span&gt;[&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;/span&gt;].(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-storage-modifier-import)&quot;&gt;string&lt;/span&gt;&lt;/span&gt;)
    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;!&lt;/span&gt;&lt;/span&gt;&lt;span&gt;ok&lt;/span&gt; {
        &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;nil&lt;/span&gt;&lt;/span&gt;, &lt;span&gt;errors&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;New&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;name must be a string&quot;&lt;/span&gt;&lt;/span&gt;)
    }

    &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-keyword)&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;mcp&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;NewToolResultText&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;fmt&lt;/span&gt;.&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;Sprintf&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-string)&quot;&gt;&quot;Hello, %s!&quot;&lt;/span&gt;&lt;/span&gt;, &lt;span&gt;name&lt;/span&gt;)), &lt;span&gt;&lt;span style=&quot;color:var(--color-prettylights-syntax-constant)&quot;&gt;nil&lt;/span&gt;&lt;/span&gt;
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;MCP Go 处理所有复杂的协议细节和服务器管理，因此你可以专注于构建出色的工具。它旨在实现高级且易于使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:start&quot;&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特点：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快速&lt;/strong&gt;：高级接口意味着更少的代码和更快的开发速度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;简单&lt;/strong&gt;：使用最少的样板构建 MCP 服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;完整&lt;/strong&gt;：MCP Go 旨在提供核心 MCP 规范的完整实现&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/mcp-go</link>
            <guid isPermaLink="false">https://www.oschina.net/p/mcp-go</guid>
            <pubDate>Sat, 22 Mar 2025 08:55:00 GMT</pubDate>
        </item>
        <item>
            <title>大阪大学推出开源量子计算机操作系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;大阪大学、富士通有限公司、系统工程顾问株式会社 (SEC) 和 TIS Inc. (TIS) 宣布在 GitHub 上&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Foqtopus-team.github.io%2F&quot; target=&quot;_blank&quot;&gt;发布量子计算机开源操作系统。&lt;/a&gt;该系统名为面向操作员和用户的开放量子工具链 (OQTOPUS)，代表了量子计算领域全球最全面的开源努力之一。&lt;/p&gt; 
&lt;p&gt;OQTOPUS 的设计灵活且可定制，允许用户根据自己的特定需求定制系统。它的发布有望通过显著降低设置和操作量子系统的复杂性（尤其是在云环境中）来加速量子计算的实际部署。&lt;/p&gt; 
&lt;p&gt;以前，大学和公司必须开发大量定制软件才能实现基于云的量子计算。借助 OQTOPUS，协作团队通过提供从设置到执行的完整、随时可用的操作系统简化了这一流程，使量子计算比以往任何时候都更容易实现。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.cnbetacdn.com/article/2025/0326/9a81488446346d8.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7841684490beba2f38b4aada0d2510d2641.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OQTOPUS 概览。图片来源：OQTOPUS 团队&lt;/p&gt; 
&lt;p&gt;此外，大阪大学提供的量子计算云服务已开始将 OQTOPUS 整合到其运营中，富士通有限公司将在 2025 年下半年向使用其量子计算机的研究合作伙伴提供该服务。&lt;/p&gt; 
&lt;p&gt;展望未来，研究团队将通过不断扩展 OQTOPUS 的功能和发展蓬勃发展的全球社区来推动量子计算的发展。大阪大学量子信息与量子生物学中心 (QIQB) 的 Keisuke Fujii 博士提到：「这将促进各种量子软件和系统的标准化，同时推动创新量子应用的创建。」&lt;/p&gt; 
&lt;p&gt;该研究由日本科学技术振兴机构和日本国家量子科学技术研究所资助。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341363/scientists-launch-open-source-quantum-computer-os</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341363/scientists-launch-open-source-quantum-computer-os</guid>
            <pubDate>Sat, 22 Mar 2025 08:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 热潮中，哪类人才最紧缺？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2025 年春招中，人工智能领域招聘需求大幅增长，算法、机器学习等方面的人才成为企业高薪争抢的「香饽饽」，人工智能讲师岗位招聘量也在激增。&lt;/p&gt; 
&lt;p&gt;随着 AI 技术加快应用，未来还会缺哪些方面的人才？如何捕捉到其中的就业新机遇？&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0bd7f6ff0d7d0b2ef4705cba1c34f34fd2e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;企业高薪招聘 AI 人才&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;近期，「百万英才汇南粤」春季大型综合招聘会在广州举办，现场人头攒动。5 万多个招聘岗位中，电子信息、先进制造行业招聘数量排名前列，特别是人工智能相关岗位需求旺盛。&lt;/p&gt; 
&lt;p&gt;「新华视点」记者看到，比亚迪、小马智行、优必选等一批企业高薪招聘自动驾驶算法工程师、AI 引擎研发工程师等岗位，吸引了诸多求职者投递简历。一些在读研究生专程前来寻找 AI 方向的实习机会。&lt;/p&gt; 
&lt;p&gt;从事脑机接口产品研发生产的广东神舞科技有限公司，正在招募高级嵌入式工程师、神经科学家、算法工程师等。「招聘人数没有上限，待遇从优，比如算法工程师，可提供两室一厅免费住房外加 40 万至 70 万元年薪。」公司创始人郑辉说。&lt;/p&gt; 
&lt;p&gt;慕尼黑工业大学的刘思蕾专程从德国回来参加招聘会，她的专业方向是机器人、认知与智能。她说，国内正在大力发展人工智能，机会多，能让自己快速成长。&lt;/p&gt; 
&lt;p&gt;不久前杭州举办的春季首场大规模线下人才招聘会上，830 家企业推出 2.1 万个岗位，其中半数聚焦 AI 算法、大模型开发。宇树科技推出了 AI 算法工程师、深度强化学习算法、机器人运动控制算法等 10 个岗位，月薪最高达 7 万元。&lt;/p&gt; 
&lt;p&gt;「DeepSeek 的爆发加速了 AI 在各行各业的应用渗透。由于 AI 人才市场需求加剧，企业纷纷提高了招聘薪资水平。」智联招聘执行副总裁李强说。&lt;/p&gt; 
&lt;p&gt;智联招聘数据显示，2 月份，算法工程师、机器学习、深度学习岗位招聘量同比增速分别为 46.8%、40.1%、5.1%；平均招聘月薪均突破 2 万元，分别为 23510 元、21534 元、24015 元。作为训练 AI 模型的基础工作，数据标注岗位招聘需求同比增长超 50%。&lt;/p&gt; 
&lt;p&gt;此外，市场对 AI 知识传播和人才培养的需求也在急剧提升。据智联招聘数据，今年春节后一个月，人工智能讲师招聘职位数同比增长 112.4%，平均招聘月薪为 15792 元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;市场急缺哪方面 AI 人才？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;高薪之下，越来越多求职者希望投身人工智能行业。智联招聘数据显示，2 月份，AI 领域求职人数同比增幅达 200% 以上。&lt;/p&gt; 
&lt;p&gt;当前企业最青睐哪类 AI 人才？&lt;/p&gt; 
&lt;p&gt;猎聘近日发布的《2025AI 技术人才供需洞察报告》显示，去年 2 月至今年 1 月间，在猎聘平台上招聘的 AI 职位中，约 47% 要求硕博学历。&lt;/p&gt; 
&lt;p&gt;由于人工智能自 2019 年才被正式纳入本科专业目录，目前 AI 领域多数从业者来自其他相关专业。从猎聘数据看，人数最多的前四个专业分别是计算机科学与技术、软件工程、电子信息以及机械工程。&lt;/p&gt; 
&lt;p&gt;「企业主要看是否具备相关专业能力。」猎聘大数据研究院相关负责人介绍，算法是人工智能的核心，涉及复杂的数学、统计学、计算机科学等领域的知识；深度学习则涉及复杂的神经网络模型和算法优化，从业者在掌握线性代数、概率论、统计学等知识的同时，还需具备编程技能。&lt;/p&gt; 
&lt;p&gt;多家平台数据显示，今年以来，AI 人才持续保持供不应求的态势。未来随着 AI 技术加快应用，还会缺哪些方面的人才？&lt;/p&gt; 
&lt;p&gt;除了当前市场紧缺的算法工程师、大模型工程师、机器学习工程师等，从全产业链看，AI 领域在基础层、技术层、应用层都存在人才缺口，比如高性能计算工程师、芯片架构师等，也是企业竞相争夺的对象。&lt;/p&gt; 
&lt;p&gt;中国科学院自动化研究所研究员王亮表示，由于人工智能涉及多领域，所需人才也覆盖多种类型——既有致力于前沿算法与核心理论创新的基础研究型人才，也有将理论与算法模型开发相结合、形成可落地产品的技术开发型人才，还包括既懂人工智能技术又懂所在行业业务的应用复合型人才。此外，AI 训练师、数据标注工程师、AI 伦理与安全专家等数据治理和支撑人才也变得越来越重要。&lt;/p&gt; 
&lt;p&gt;「目前最急需的还是基础研究型人才和应用复合型人才，一方面解决高端 AI 芯片国产化率不足和算法原创性不足问题，另一方面推动 AI 加速赋能各领域各行业。」王亮认为。&lt;/p&gt; 
&lt;p&gt;据麦肯锡报告预测，到 2030 年，中国对 AI 专业人才的需求预计将达 600 万人，而人才缺口可能高达 400 万人。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如何捕捉 AI 发展中的就业机遇？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;面对 AI 带来的岗位替代和新的岗位需求，普通人如何适应产业变化，提高就业的稳定性和竞争力？&lt;/p&gt; 
&lt;p&gt;教育，无疑是其中关键一环。新一轮科技浪潮下，中国高校也迎来史上最大规模专业调整。短短几年间，已有超 500 所高校开设人工智能专业或成立专门学院，考生的报考热度持续升高。2025 年清华大学、中国人民大学等高校扩招计划里均包含人工智能专业。&lt;/p&gt; 
&lt;p&gt;「人才数量提升的同时，优化培养结构、提升质量显得更为关键。」王亮认为，未来不同层次和领域的 AI 人才需求会更加细分，高校在专业设置和课程设计上应更加注重人才的差异化培养。&lt;/p&gt; 
&lt;p&gt;2024 年，南开大学全面启动「人工智能赋能人才培养行动计划」，打造了 130 余门人工智能系列课程群。&lt;/p&gt; 
&lt;p&gt;「人工智能需要多学科交叉融合发展，这就要求高校超前布局、主动调整，在加强基础学科、新兴学科、交叉学科建设中，形成学科集群，为推动人工智能人才培养提供坚实基础。」南开大学校长陈雨露说。&lt;/p&gt; 
&lt;p&gt;为培养更多实用型、复合型和紧缺型人工智能应用人才，教育部近日印发通知，部署各地各高校面向企事业单位和行业协会征集一批「人工智能应用」领域供需对接就业育人项目。&lt;/p&gt; 
&lt;p&gt;「行业从业者也需要保持持续学习的习惯。」王亮表示，从人工智能相关专业毕业生的反馈来看，职业发展过程中，除了技术能力外，设计思维、跨学科协作、自主学习能力的培养同样至关重要。&lt;/p&gt; 
&lt;p&gt;在科大讯飞董事长刘庆峰看来，AI 技能应成为未来公民必备能力，需加强 AI 新职业的规划与管理及相关技能培训，尤其要为低收入和就业困难群体提供免费培训机会。&lt;/p&gt; 
&lt;p&gt;「年轻人无论从事哪个专业，都可以每周花点时间，关注全球 AI 技术在各行各业的发展，这是未来最大的机会源泉。」宇树科技创始人王兴兴说。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341353</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341353</guid>
            <pubDate>Sat, 22 Mar 2025 08:18:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>浏览器引擎新贵对决：Servo 与 Ladybird 的全面比较</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;blockquote&gt; 
 &lt;p&gt;原文作者：Niccolò Venerandi，发表于 2025 年 3 月 23 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;开源浏览器引擎领域正迎来两位新秀的崛起，它们以不同的方式挑战着 Chrome、Firefox 和 Safari 的主导地位。本文将对 Servo 和 Ladybird 这两个充满潜力的项目进行深入分析，比较它们的发展历程、资金状况、技术表现与未来前景。&lt;/p&gt; 
&lt;h2&gt;起源与发展历程&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Servo&lt;/strong&gt;最初于 2012 年作为 Mozilla 的研究项目诞生，旨在利用 Rust 语言的内存安全特性和并发功能来加速网页渲染。该项目在 2014 年通过了基本的 Acid2 测试，到 2016 年在某些特定任务上已经能够超越其他引擎。随后，Mozilla 开始将 Servo 的组件移植到 Firefox 的 Gecko 引擎中，这个被称为&quot;Quantum&quot;的项目为 Firefox 带来了显著的性能提升。&lt;/p&gt; 
&lt;p&gt;然而，2020 年 Mozilla 裁掉了整个 Servo 团队，项目转由 Linux 基金会管理，但几乎没有资金支持。直到 2023 年 1 月，在&quot;外部资金&quot;的支持下，Servo 通过 Igalia 公司的开发团队重获新生。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ladybird&lt;/strong&gt;则是由单一开发者 Andreas Kling 于 2022 年创建的开源网络浏览器。然而，为了公平比较，其背后的 LibWeb 引擎实际上始于 2019 年，在 Ladybird 诞生前已有数百人参与贡献。2022 年，Ladybird/LibWeb 已经通过了 Acid3 测试，该项目最初主要依靠 Patreon 和 GitHub 赞助、YouTube 广告收入以及周边销售获得资金，明确拒绝接受风险投资。&lt;/p&gt; 
&lt;p&gt;后来，随着项目规模扩大，Kling 决定将 Ladybird 从 SerenityOS 分离出来，成立了独立的非营利组织&quot;Ladybird Browser Initiative&quot;。&lt;/p&gt; 
&lt;h2&gt;主要差异&lt;/h2&gt; 
&lt;p&gt;虽然二者都是开源浏览器技术，但存在几个关键差异：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;定位不同&lt;/strong&gt;：Servo 是浏览器引擎，设计之初就考虑了易于嵌入各种应用；而 Ladybird 是一个完整浏览器，其引擎 LibWeb 主要服务于自身。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;技术栈&lt;/strong&gt;：Servo 从一开始就使用 Rust 语言开发，注重内存安全和并发性能；Ladybird 则使用 C++构建。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;发展理念&lt;/strong&gt;：据 Andreas Kling 所言，Servo 更像是一个实验项目，追求创新和实验性；Ladybird 则更注重实用性和兼容性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;资金与团队规模&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Servo&lt;/strong&gt;由神秘的&quot;外部资金&quot;支持 Igalia 的 5 名开发者，同时通过 GitHub 赞助和 OpenCollective 募集资金。截至文章发布时，他们在 GitHub 有 313 位赞助者，每年约 2 万美元收入；在 OpenCollective 上一年内筹集了 4.4 万美元，年度预算估计为 6.1 万美元，理论上可以支持 6 名全职开发者。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ladybird&lt;/strong&gt;的资金状况更为可观。项目收到了 GitHub 联合创始人 Chris Wanstrath 家族的 100 万美元捐赠，Shopify 的 10 万美元资助，以及来自 Proton VPN、Ahrefs 等机构合计 20 万美元的赞助。这些资金使团队能够维持 7 名全职工程师，并保持 18 个月的资金储备。&lt;/p&gt; 
&lt;p&gt;总体而言，Ladybird 在资金和团队规模上略占优势，但差距不算太大。&lt;/p&gt; 
&lt;h2&gt;网络标准支持&lt;/h2&gt; 
&lt;p&gt;在网络标准测试方面，Ladybird 通过了 Acid3 测试并获得满分，而 Servo 仅达到 83 分。&lt;/p&gt; 
&lt;p&gt;在更全面的网络平台测试中，Ladybird 通过了 88% 的测试，Servo 为 76%，参考 Chrome 的成绩是 97%。然而，在特定类别上比较，Servo 在 CSS 测试中表现更佳（49% 对 42%），特别是在 CSS2、cssom 和 flexbox 等方面。&lt;/p&gt; 
&lt;p&gt;值得注意的是，5 个月前 Servo 在网络平台测试中领先，但 Ladybird 迅速赶上。总体而言，Ladybird 在网络标准兼容性方面发展更快，但 Servo 在其专注的领域更胜一筹。&lt;/p&gt; 
&lt;h2&gt;性能表现&lt;/h2&gt; 
&lt;p&gt;在性能测试方面，Servo 展现出明显优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 JetStream 测试中，Servo 得分 129.833（Chrome 为 243.338），而 Ladybird 无法完成测试。&lt;/li&gt; 
 &lt;li&gt;在 Octane 测试中，Servo 的分数比 Ladybird 高出一个数量级。&lt;/li&gt; 
 &lt;li&gt;在 Speedometer v2 测试中，Servo 的得分约为 Ladybird 的 7 倍。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;作者在随机选择的政府网页上进行非科学测试也发现，Ladybird 在大多数情况下加载速度明显慢于 Servo。&lt;/p&gt; 
&lt;h2&gt;总结与前景&lt;/h2&gt; 
&lt;p&gt;Servo 和 Ladybird 代表了开源浏览器引擎的不同发展路径：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ladybird&lt;/strong&gt;拥有更丰厚的资金支持和更快的网络标准兼容性发展速度，团队规模稍大，社区影响力持续扩大。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Servo&lt;/strong&gt;则凭借 Rust 语言带来的并发优势，在性能方面遥遥领先，特别是在 JavaScript 执行和应用响应速度上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;虽然两者与主流浏览器相比还有距离，但它们的存在为网络技术带来了新的活力和多样性。Servo 在实验性和高性能方面的优势，与 Ladybird 在标准兼容性和资金稳定性上的优势，使它们各具特色，值得持续关注。&lt;/p&gt; 
&lt;p&gt;随着这两个项目的不断发展，开源浏览器引擎领域的竞争将变得更加激烈，最终受益的将是所有互联网用户。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;想更深入了解 Servo 和 Ladybird 的详细比较，请阅读原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fthelibre.news%2Fservo-vs-ladybird%2F&quot; target=&quot;_blank&quot;&gt;Servo vs Ladybird - The Libre News&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341350</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341350</guid>
            <pubDate>Sat, 22 Mar 2025 08:03:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源模型逆袭：Databricks TAO 技术微调 Llama 超越 GPT-4o</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;数据智能公司 Databricks 近日推出了一种全新的大语言模型微调方法 ——TAO（Test-time Adaptive Optimization）。通过运用无标注数据和强化学习，TAO 不仅在降低企业成本方面表现出色，更是在一系列基准测试中取得了令人瞩目的成绩。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据科技媒体 NeoWin 的报道，TAO 微调后的 Llama3.370B 模型在金融文档问答和 SQL 生成等任务中，展现出了优于传统标注微调方法的性能，甚至逼近了 OpenAI 的顶级闭源模型。这一成果标志着开源模型在与商用 AI 产品竞争中的又一次重大突破。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;177&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-636746ea5f1ede735d2b9d4890469e2252e.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TAO 方法的核心在于其独特的 「测试时计算」 理念，能够自动探索任务的多样性，同时结合强化学习来优化模型，从而避免了传统微调所需的人工标注成本。在多项企业基准测试中，TAO 微调的 Llama 模型成绩斐然:&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 FinanceBench 基准测试中，该模型在 7200 道 SEC 文档问答中取得了 85.1 的高分，超过了传统标注微调（81.1）和 OpenAI 的 o3-mini(82.2) 的成绩。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 BIRD-SQL 测试中，TAO 微调的 Llama 模型得分为 56.1，接近 GPT-4o 的 58.1，远超传统标注微调（54.9）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 DB Enterprise Arena 中，TAO 模型得分为 47.2，虽然略低于 GPT-4o 的 53.8，但仍然显示了强劲的竞争力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aff51111b21b90482315a050f5906852795.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341348</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341348</guid>
            <pubDate>Sat, 22 Mar 2025 07:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源模型上下文协议 MCP 更新：采用 Streamable HTTP 取代 HTTP+SSE</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;开源模型上下文协议 MCP 规范今天发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Freleases%2Ftag%2F2025-03-26&quot; target=&quot;_blank&quot;&gt;新版本&lt;/a&gt;&lt;/u&gt;，一些主要变化：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 OAuth 2.1 的身份验证框架&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;用 Streamable HTTP 传输取代了以前的 HTTP+SSE 传输&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;支持 JSON-RPC 批处理&lt;/li&gt; 
 &lt;li&gt;工具注释可以更好地描述工具行为&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0327/152740_MOWl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;详情查看&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fspecification%2Ftree%2Fmain%2Fdocs%2Fspecification%2F2025-03-26&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/specification/tree/main/docs/specification/2025-03-26&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Streamable HTTP&amp;nbsp;改变了 MCP 的数据传输方式&lt;/strong&gt;，让协议变得：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更灵活&lt;/strong&gt;（支持流式传输，但不强制）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更易用&lt;/strong&gt;（支持无状态服务器）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;更兼容&lt;/strong&gt;（适用于标准 HTTP 基础设施）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;💡&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;简单比喻&lt;/strong&gt;： 原来的 MCP 传输方式就像是&lt;strong&gt;你和客服通话时必须一直保持在线&lt;/strong&gt;（SSE 需要长连接），而新的方式更像是&lt;strong&gt;你随时可以发消息，然后等回复&lt;/strong&gt;（普通 HTTP 请求，但可以流式传输）。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;主要变更&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;移除 /sse 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器不再单独维护 SSE（Server-Sent Events）端点。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;所有客户端 → 服务器的消息都通过 /message 端点&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何数据传输都通过&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;/message&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;进行，不再依赖 /sse。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;服务器可以选择升级请求为 SSE&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可以根据需要&lt;strong&gt;动态升级 HTTP 请求为 SSE 流&lt;/strong&gt;，用于发送通知或请求。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;客户端通过 Header 提供 Mcp-Session-Id&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选是否需要存储 Session 信息，但客户端始终发送 Mcp-Session-Id 头部信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;支持无状态（Stateless）服务器&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务器可选择完全无状态运行，不再需要维持长期连接。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341338/mcp-specification-0326</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341338/mcp-specification-0326</guid>
            <pubDate>Sat, 22 Mar 2025 07:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>深度剖析 StarRocks 读取 ORC 加密文件背后的技术</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网大数据团队 - Zheng Xiaofeng&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本文介绍了 StarRocks 数据库如何读取 ORC 加密文件，包括基础概念以及具体实现方案。深入探讨了利用 ORC 文件的四层结构和三层索引机制，实现高效查询加密数据。希望通过本文对 ORC 加密文件读取功能的实现细节的剖析，让读者更加深刻理解 ORC 文件，同时了解 StarRocks 支持加解密数据分析的方案。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;为了提升对敏感数据的保护，需要对 Hive 表一些敏感数据进行加密存储。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Spark 组件已经通过引入了 Apache ORC 项目（Java 版本）对 ORC 格式的 Hive 表的数据进行加解密。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;StarRocks 也使用了 Apache ORC 项目的 C++版本读写 ORC 文件，但是&lt;strong&gt;C++版本没有实现加解密功能&lt;/strong&gt;，在使用 StarRocks 对 Hive 表进行即席分析时，无法对具有加密列的 Hive 表进行查询，因此，需要对 StarRocks 的 Apache ORC 模块进行改造，使其支持对 ORC 格式的 Hive 加密表数据读取功能，数据架构图如下图所示：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//42662e0b81a83165a856f0c38387b668.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;希望通过本文对 ORC 加密文件读取功能的实现细节的剖析，让读者更加深刻理解 ORC 文件，同时了解 StarRocks 支持加解密数据分析的方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;二、问题引入&lt;/h1&gt; 
&lt;p&gt;在正式开启全文的阅读之前，我们首先引入几个问题，然后带着这些问题去阅读后面的内容，将会更有针对性与启发性，通过深入解答这些问题，我们不仅能够更好地理解相关的概念和技术，还能提升分析和解决问题的能力。问题如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;程序解压某个文件时，是否需要一次性读取整个文件后再进行解压操作？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ORC 文件究竟是如何做到在不扫描全文件的情况下就能精准查询到想要的数据？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;当 SQL 查询条件不符合最左前缀原则时，ORC 文件中的索引是否就会失效？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;数据加密、解密、解压以及压缩之间的关联关系到底是怎样的？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;在写 ORC 文件时为什么是先压缩后加密，而不是先加密后解压？&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;三、ORC 文件介绍&lt;/h1&gt; 
&lt;p&gt;ORC（Optimized Row Columnar）文件格式是一种高度优化的列式存储格式，它主要用于 Hadoop 生态系统中的大数据处理和分析。ORC 文件结构的设计旨在提高 I/O 效率、减少数据读取时间，并支持复杂的数据类型和压缩算法。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 四层结构 File ,Stripe,Stream，Group&lt;/h2&gt; 
&lt;p&gt;一个 File 中包含多个 Stripe，一个 Stripe 包含多个 Steam，一个 Stream 包含多个 Group，每个 Group 默认存储 1 万行数据，如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//daf79f27d162699ca73e6745cd92b780.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.2&amp;nbsp;三层索引&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FileStat&lt;/strong&gt; ：文件级别各列的统计信息，用于判断 SQL 条件是否下推。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;StripeStat&lt;/strong&gt;：Stripe 级别各列的统计信息，用于判断 SQL 条件是否下推。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;IndexData&lt;/strong&gt;：每个 Stripe 内部各列的索引信息，用于判断 SQL 条件是否下推。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在读取文件中数据之前，会先读取以上 3 类索引数据，根据 SQL 条件逐层进行比对，来决定是否跳过某些数据的读取，减少数据扫描量，从而提升 SQL 查询效率。&lt;/p&gt; 
&lt;p&gt;下表是只包含 id 和 name 两列的 ORC 文件的各层统计信息的案例：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;FileStat&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//18e323617df740616d0230aa1e15ae4c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;StripeStat&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0679ad98f36eaec4b8e50af132d4ee96.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;IndexData&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a0ad1992999f1f653a589ab33cb184db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 ORC 文件内部详细结构&lt;/h2&gt; 
&lt;p&gt;前面已经大体介绍了 ORC 文件的结构，下面详细介绍其内部结构，ORC 文件由多个逻辑层次组成，每个层次都有特定的作用和结构，下图具体描述了包含 2 列（id，name）的 ORC 文件结构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//51bb6963b452f9f0a51c7531681f452e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tail&lt;/strong&gt;：存储文件的元数据，如列的压缩信息、统计信息、版本等，包含了三个部分：PostScript、Footer、MetaData。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Body&lt;/strong&gt;：实际存储数据的部分，由多个 Stripe 组成。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面分别介绍 Tail 和 Body 内部包含哪些结构：&lt;/p&gt; 
&lt;p&gt;Tail 文件尾部是读取 ORC 文件的起点，它包含了文件关键信息：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PostScript&lt;/strong&gt;：存储文件的压缩类型、压缩块大小、版本信息，Footer 和 MetaData 的长度等，这部分数据不会被压缩。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Footer&lt;/strong&gt;：记录了整个文件所有列的统计信息（FileStat），所有 Stripe 的元数据信息（stripesList），加密信息（encryption）以及文件 body 长度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MetaData&lt;/strong&gt;：存储该文件所有 Stripe 的统计信息（StripeStat）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Body 实际存储数据的部分，由多个 Stripe 组成，每个 Stripe 包含多个 Stream，先存储索引相关的 Stream（index-Stream），后面存储实际数据相关的 Stream（data-Stream），每一列包含多个 index-Stream 和 data-Stream，Stripe 是 ORC 文件中数据存储的基本单元，每个 Stripe 数据大小一般不超过 200M，主要包含下面几块内容：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Stripe Footer&lt;/strong&gt;：包含所有 Stream 的元数据（streamsList）和加密信息（encryption）等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Index-Stream&lt;/strong&gt;：存储索引相关数据的 Stream，按列存储。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data-Stream&lt;/strong&gt;：储实际数据相关的 Stream，按列存储。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ORC 文件的读取是从尾部最后一个字节开始的，得到 PostScript 的长度，读取 PostScript，然后根据 PostScript 中的 FooteLength，MetaDataLength 信息读取 MetaData 和 Footer，最后根据 Footer 中的 Stripe 信息读取具体的数据 Stripe，上面的文字介绍可能不是很直观，如果想更细节了解 ORC 文件结构内容可以参考（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.processon.com%2Fmindmap%2F6503c70803ab061eb31b80da&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;ORC 文件结构思维导图&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Forc.apache.org%2F&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;ORC 文件官网介绍&lt;/a&gt;）。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_7&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;四、相关概念的理解&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.1 对称加解密&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1c56a2f7a82e7f369cd1548d0ef7eb36.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对称加解密的要素包括密钥、明文、密文和加密算法。以下是对这些要素关系的描述：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;密钥&lt;/strong&gt;：密钥是加密和解密过程中的关键元素，它是由随机数生成的，通常是固定长度的一串二进制数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;明文&lt;/strong&gt;：明文是指原始的信息，可以是文本、图片、音频等各种形式的数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;密文&lt;/strong&gt;：密文是经过加密算法处理后的数据，只有知道密钥的人才能解密还原成明文。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;加密算法&lt;/strong&gt;：加密算法是将明文转换成密文的过程，这个过程通常涉及到一系列的数学运算，比如 AEC，RSA 等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;注意：对称加密的加密密钥，和 解密密钥是一样的。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.2 文件的压缩和解压缩&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.1&amp;nbsp;压缩算法&lt;/h3&gt; 
&lt;p&gt;压缩算法是用于减小文件大小的数学方法。它通过各种技术，如替换、重新编码、差分编码、运行长度编码、字典编码、变换编码等，来减少数据的冗余和实现数据的体积缩小。压缩算法可以是无损的或有损的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;无损压缩&lt;/strong&gt;：意味着原始数据可以完全从压缩文件中恢复，常用于文本和某些类型的数据文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;有损压缩&lt;/strong&gt;：为了获得更高的压缩率，允许丢失一些数据，常用于图像、音频和视频文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h3_11&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.2 解压算法&lt;/h3&gt; 
&lt;p&gt;解压算法是压缩算法的逆过程，它用于将压缩文件恢复到其原始状态。无损压缩的解压算法能够完全恢复原始数据，而有损压缩的解压算法则可能无法完全恢复所有原始数据。&lt;/p&gt; 
&lt;p&gt;文件压缩和解压缩简单流程图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3edcbf4fcc94f0f715892423538e2ded.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;注意：数据的压缩算法和解压算法要一样&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_12&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;4.2.3 压缩块&lt;/h3&gt; 
&lt;p&gt;文件压缩块是指对文件进行压缩处理后生成的一组连续的数据块。在文件压缩过程中，文件被分割成多个块，每个块都经过压缩算法处理。一般来说，文件压缩块的大小可配置。例如，ZIP 压缩的每个压缩块的大小可以达到 64KB 或更大，而在其他压缩格式如 7z 中，压缩块的大小可以更大，通常为数 MB。这些大小可以根据文件的特性和压缩算法的性能进行调整，以达到更好的压缩比和解压性能。&lt;/p&gt; 
&lt;p&gt;注意：在解压文件的过程中会从文件中读取整个压缩块数据到内存之后再使用解压算法进行解压处理，所以压缩块越大每次解压读取到内存里的数据会越大。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;4.3 加密压缩文件读写大致流程&lt;/h2&gt; 
&lt;p&gt;在掌握了数据加密和压缩的基础知识之后，让我们从宏观的角度了解一下 ORC 加密文件读写流程，如下图所示：在写入时，内存中的数据首先被序列化，然后压缩以减少体积，最后对数据加密。在读取时，数据首先被解密以恢复原始格式，然后解压数据得到原始数据，最后通过反序列化原始数据转换为内存对象。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//cd6b640a5a79817353e9bfb6a7fe81d5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;详细说明写入和读取过程中的各个步骤：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）写入过程（序列化、压缩、加密）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;序列化&lt;/strong&gt;：在数据写入存储系统之前，首先需要将内存中的对象转换成可以存储或传输的格式，这个过程称为序列化。序列化后的数据通常是一个二进制格式，便于后续的处理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;压缩&lt;/strong&gt;：序列化后的数据可能会占用较大的空间。为了减少存储需求和&lt;strong&gt;提升后续数据加密处理效率&lt;/strong&gt;，接下来对数据进行压缩。压缩算法会尝试去除数据中的冗余，从而减少数据的体积。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;加密&lt;/strong&gt;：压缩后的数据需要进行加密，以确保数据的安全性。加密算法会使用密钥对数据进行加密，生成密文。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存入文件中&lt;/strong&gt;：加密后的密文被存储在文件中，等待后续的读取或传输。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;（2）读取过程（解密、解压、反序列化）&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;解密&lt;/strong&gt;：当需要读取文件中的数据时，首先需要使用正确的密钥和加密算法对密文进行解密，恢复为压缩前的数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;解压&lt;/strong&gt;：解密后，应用解压算法对数据进行解压，恢复到序列化前的状态。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;反序列化&lt;/strong&gt;：解压后的数据是一个二进制格式，需要进行反序列化，将其转换为内存中的对象。反序列化是序列化的逆过程，它将二进制数据转换为可读可操作的数据结构。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;内存对象&lt;/strong&gt;：经过解密、解压和反序列化之后，数据最终以内存对象的形式被程序处理。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;五、StarRocks 读取 ORC 加密文件实现方案&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;5.1 ORC 文件内部数据加密关系&lt;/h2&gt; 
&lt;p&gt;首先，介绍几个密钥的含义：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;statKey&lt;/strong&gt;：用于解密加密列的 FileStat，StripeStat 的密钥，每个列一个，加密存储在文件 Footer 里。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;dataKey&lt;/strong&gt;：用于解密加密列的 IndexData 和 RowData，每个 Stripe 的每一列都有一个，加密存储在 Stripe 的 Footer 里。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;masterKey&lt;/strong&gt;：文件的根密钥，用于解密 ORC 文件中被加密的 statKey 和 dataKey，该密钥没有存储在文件中，一般存储在 Hive 表属性上。要解密 ORC 文件中的数据，首先需要获取这个 masterKey。然而，masterKey 本身也是加密的，因此在读取 Hive 表之前，必须先从表属性中提取出加密的 masterKey,访问密钥管理服务（Key Management Service, KMS），对加密的 masterKey 进行解密，从而获得可用于实际解密操作的明文 masterKey 密钥，一旦获得了 masterKey 的明文形式，就可以用它来解密 ORC 文件中的 dataKey 和 statKey。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3f858f3c7fc6ed6c7e5dcdb8f10d2253.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下图是描述了 masterKey、statKey，dataKey 之间的关系，灰色部分代表是存储在文件中被加密的数据，绿色部分则是解密之后的数据，包括我们解密后的 statKey，dataKey。获得这两个密钥之后分别用于解密统计信息和文件中的真实数据。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_16&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;5.2 StarRocks 读取 ORC 加密文件流程&lt;/h2&gt; 
&lt;p&gt;在深入掌握了 ORC 文件中密钥的相互关系和功能后，我们现在转向探讨 StarRocks 是如何读取 ORC 加密表的数据。这个过程如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b39f8da7c9f25c2316cbbb845730a54b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1）提交 SQL 查询&lt;/strong&gt;：用户首先通过 SQL 客户端向 StarRocks FE 节点提交查询请求。这通常涉及到对 Hive 表下存储的 ORC 加密文件进行读取操作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2）获取解密的 masterKey&lt;/strong&gt;：查询提交后，系统首要根据 SQL 获取 Hive 表中的 ORC 文件所需的 masterKey。这个 masterKey 一般存储在表属性里，并且是加密存储的，必须调用 KMS 服务来解密，得到密钥明文。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3）传递 masterKey 明文&lt;/strong&gt;：解密后的 masterKey，以明文形式传递给 StarRocks BE 节点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4）读取并解密密钥&lt;/strong&gt;：BE 拿到已解密的 masterKey 之后，读取并解密 ORC 文件中的 statKey 和 dataKey，这两个密钥分别用于解密统计信息（FileStat，StripeStat）和实际数据内容，为接下来的统计信息和数据解密做准备。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5）使用 statKey 和 dataKey 解密数据&lt;/strong&gt;：BE 使用 statKey 来解密文件的统计信息（fileStat 和 StripeStat）同时使用 dataKey 来解密实际的数据内容。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_17&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;5.3 读取 ORC 加密文件的关键实现细节&lt;/h2&gt; 
&lt;p&gt;通过了解前文 StarRocks 读取 ORC 加密文件流程，我们将深入探讨读取 ORC 加密文件的数据关键实现细节。首先，我们提出一个问题：在物理存储中，文件存储的是什么内容？答案是二进制数据。这些二进制数据通常会经过压缩处理。&lt;/p&gt; 
&lt;p&gt;ORC 文件的读取流程是自外向内的，类似于&lt;strong&gt;剥洋葱的过程&lt;/strong&gt;，逐步深入到我们需要读取的目标数据。读取流程可以概括为：首先读取文件元数据，通过元数据获取目标数据的偏移量（offset）和数据长度如下图所示，然后通过流的方式读取目标数据。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e9be4bd8a50aa1870bb661641f960c6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体到 ORC 加密文件的读取实现代码，主要采用了设计模式中的装饰模式方式来组织代码的。在这个模式中，原始的文件流（SeekableFileInputStream）首先被解密流（DecryptionInputStream）所包装，如果是非加密文件就没有这一层，然后解密流又被解压缩流（DecompressionStream）所包装。每一层流都只负责向其包装的流请求数据，并在接收到一定量数据后开始处理自己的逻辑。如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//97de9ae2095fa9576fac708b4fe83419.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这种分层的方法保证每一层都专注于自己的职责，共同协作完成 ORC 文件的读取任务。通过这种方式，我们不仅能够高效地读取 ORC 文件，还能确保数据的安全性和完整性。综上所述，ORC 文件的读取流程是一个从文件元数据到具体数据内容的逐步深入过程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_18&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;5.4 加密字段跳读机制&lt;/h2&gt; 
&lt;p&gt;为了提升数据的查询效率，查询数据时会根据索引数据跳过不必要的数据读取，下面我们介绍加密列跳读机制，理解了这部分的内容，就能非常清晰的知道，读取加密字段时，对数据解密与解压是怎样协作的。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_19&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;5.4.1 加密块与压缩块的关系&lt;/h3&gt; 
&lt;p&gt;加密列的数据划分了多个加密块与压缩块，一个压缩块，包含多个加密块，读取数据时，先对每个加密块进行解密，解密多个加密块之后，把这些解密后的数据块合并成一个完整的压缩块，然后对这个压缩块进行解压得到原始数据下图是加密块与压缩块的关系图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//cf9450e0def2e8eb5a9cbe6abbfde7fe.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_20&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;5.4.2 ORC 文件使用的加解密算法和模式&lt;/h3&gt; 
&lt;p&gt;下图描述了具体的数据加解密过程中以及设计到整个过程中各种元素输入输出的关系：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4f53e022e28a5159e3253e08d126e357.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;注意：同一个数据块（16 字节）加密过程和解密过程中的，密钥、IV 值、加密算法和加密模式必须相同。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;明文块&lt;/strong&gt;：我们对 ORC 文件加密使用的加密算法是 AES-128-CTR/NoPadding，该算法加密数据时 ，会把明文按照 16 个字节划分多个块，每个块加密之后得到的数据就是加密块。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加密块&lt;/strong&gt;：每个明文数据块加密之后得到的数据就是加密块。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;初始向量 IV&lt;/strong&gt;：初始向量 IV 的作用是使加密更加安全可靠（加盐），我们使用 AES 加密时需要主动提供这个初始向量 IV，而且只需要提供一个初始向量就够了，后面每个数据块的加密向量由加密模式决定，所以每个数据块的加密向量都不一样。初始向量 IV 的长度规定为 128 位 16 个字节，ORC 文件解密参数 IV 的描述如下：总共 16 个字节，前面 8 个字节分别存储：列 ID，Stream 类型，Stripe 的 ID ，后面 8 个字节用于填充 min_count，由于我们使用的是 CTR 加密模式，所以这个 min_count 就是加密块在整个加密数据中的计数，iv 各个内容长度定义如下图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a5939566e16aa553d81b75f3c0936fd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;密钥&lt;/strong&gt;：AES 要求密钥的长度可以是 128 位 16 个字节、192 位或者 256 位，位数越高，加密强度自然越大，但是加密的效率自然会低一些，因此要做好权衡。我们开发通常采用 128 位 16 个字节的密钥，我们使用 AES 加密时需要主动提供密钥，而且只需要提供一个密钥就够了，每个数据块加解密使用的都是同一个密钥。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;加密模式&lt;/strong&gt;：有 5 种加密模式，这些加密模式的主要目的是为了&lt;strong&gt;不让重复的明文加密之后得到的密文一样&lt;/strong&gt;，提升数据安全性，我们使用的是 CTR 模式（计数器模式）对数据加密，那解密的时候也需要 CTR 模式对数据解密，计数器模式介绍请参考链接，CTR 模式，的 iv 参数，包含了，加密块计数（min_count），所以，每次对一个加密块解密时，需要知道，当前加密块的初始计数值。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_21&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;5.4.3 举例说明跳读流程&lt;/h3&gt; 
&lt;p&gt;学习了前面读取加密数据的关键细节之后，举个例子说明跳读 ORC 文件流程，假设根据索引数据和查询条件确定需要读取某个文件中第 1 个 Strip 中第 1 列的第 5 个 group 的数据，那么我们知道 group5 数据的偏移量 offset，文件结构如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//84f4126e46e2dcc2d4149f24ffab44c2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体逻辑大体流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//712c47a3adf74ce35e0044d5b87e8498.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;注意：解压数据块时，必须把当前解压块的所有数据读出来才能使用对应的解压算法解压数据。&lt;/p&gt; 
&lt;p&gt;1）group5 数据的偏移量 group_offset 计算出 group5 数据在哪个压缩块里,计算公式为：block_index = group_offset/zipBlockSize（压缩块大小），并得到该压缩块的起始位置 zip_head_offset 公式为：zip_head_offset = block_index*zipBlockSize。&lt;/p&gt; 
&lt;p&gt;2）获取 zip_head_offset 位置对应的加密块计数，加密块计数值计算公式为：min_count = zip_head_offset/encrypted-size（加密块大小） 更新 iv 向量的 min_count 值。&lt;/p&gt; 
&lt;p&gt;3）文件读指针定位到 zip_head_offset，开始读取压缩块的数据，这个压缩块的数据全部读出之后，使用解压算法进行解压。&lt;/p&gt; 
&lt;p&gt;4）通过 group5 在解压的数据上偏移量和长度，读取 group5 数据，然后再对数据进行解码。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_22&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;六、问题解答&lt;/h1&gt; 
&lt;p&gt;通过前面对相关内容的讲解，下面我们来解答前文提出的问题：&lt;/p&gt; 
&lt;p&gt;1）文件解压是否意味着一定是对整个文件进行解压操作？&lt;/p&gt; 
&lt;p&gt;答：不需要，文件是按照一定大小划分出若干个压缩块，只要读出相应的压缩块进行解压就行。&lt;/p&gt; 
&lt;p&gt;2）ORC 文件究竟是如何做到在不扫描全文件的情况下就能精准查询到想要的数据？&lt;/p&gt; 
&lt;p&gt;答：ORC 文件有三层索引，在读取文件数据之前先读取各层级的索引信息，根据过滤条件过滤掉不必要的数据扫描，从而提升数据查询效率。&lt;/p&gt; 
&lt;p&gt;3）当 SQL 查询条件不符合最左前缀原则时，其索引效果是否就会失效呢？&lt;/p&gt; 
&lt;p&gt;答：不会失效，ORC 文件是列式存储的，各列信息都是相互独立的，有自己的索引信息，与行式数据库的索引最左前缀规则不同。&lt;/p&gt; 
&lt;p&gt;4）数据加密、解密、解压以及压缩之间的关联关系到底是怎样的？&lt;/p&gt; 
&lt;p&gt;答：请参考本文：5.1 ORC 文件内部数据加密关系，内容。&lt;/p&gt; 
&lt;p&gt;5）在写加密列数据时，为什么不是先加密数据再压缩，而是先压缩后加密？&lt;/p&gt; 
&lt;p&gt;答：主要是为了提升加密效率，数据被压缩处理之后，数据量变少了，加密效率就提升了。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_23&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;七、总结&lt;/h1&gt; 
&lt;p&gt;本文介绍了 StarRocks 数据库如何读取 ORC 文件的加密数据，包括相关概念理解、ORC 文件介绍、以及 StarRocks 读取加密 ORC 文件的具体实现方案。阐述了出于数据安全的需要，对 Hive 表中的敏感数据进行加密存储的必要性，介绍了对称加密、文件压缩与解压、加密压缩文件读写流程等概念，深入探讨了 ORC 文件的三层结构和索引机制，以及如何利用这些特性实现高效查询加密数据。还详细描述了 StarRocks 读取加密 ORC 文件的流程，包括获取解密的 masterKey、使用 masterKey 解密 ORC 文件中的密钥、以及使用这些密钥解密数据。&lt;/p&gt; 
&lt;p&gt;希望通过本文对 ORC 加密文件读取功能的实现细节，让读者对 ORC 文件的理解更深刻。最后如果想从代码层面了解 ORC 文件解密过程可以参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FStarRocks%2Fstarrocks%2Fpull%2F46809&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;开源 PR&lt;/a&gt;。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/vivotech/blog/18015502</link>
            <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18015502</guid>
            <pubDate>Sat, 22 Mar 2025 07:23:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>AI 产品榜最新统计数据：夸克成国内唯一月活破亿 AI 应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 产品榜最新统计数据显示，2025 年 2 月份中国 AI 应用中仅夸克 MAU 破亿。AI 产品榜认为，中国互联网巨头即将拉开 AI 超级应用争夺战，而阿里夸克凭借 MAU 优势取得领先身位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;355&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a4a2edf6a5ba93c9a47715cca6b9c4c06f7.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AI 产品榜指出，以阿里、腾讯、字节为代表的中国互联网巨头纷纷将战略重心转向 AI，他们将重燃战火，争夺 AI 时代的超级应用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;3 月 13 日，阿里巴巴宣布推出 AI 旗舰应用——新夸克。全新夸克基于阿里通义领先的推理及多模态大模型，宣布告别传统搜索，升级为一个 All in One 的「AI 超级框」，满足用户工作、学习、生活的各类 AI 需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;夸克用户规模上的领先，很大程度上源于夸克对于产品价值的定位。阿里巴巴集团副总裁吴嘉近日在接受采访时就指出，「夸克的核心定位还是希望成为一个服务广大用户的有用的 AI 产品。我们的目标始终是成为 AI 时代体验领先的「超级入口」，让夸克通过‘AI 超级框’重构人与信息和任务的交互方式，成为覆盖工作、学习、生活的‘全能助手’。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;知名投资人、金沙江创投董事总经理朱啸虎前不久也在公开场合指出，AI 应用将迎来爆发，新的超级应用将不局限于 Chat 形态，要做成 AI 超级应用要足够易用、有产品创新。他提到像夸克就提供了一个好思路，通过一个「AI 超级框」连接用户与智能体。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，AIGCRank 最新一期发布的《中国 AI 应用排行榜》亦显示，在 2 月份的榜单中，夸克以日活用户 3429.8 万，连续两个月稳居行业第一。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341335</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341335</guid>
            <pubDate>Sat, 22 Mar 2025 07:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DuckDB 路线图发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DuckDB 是一个高性能的分析型关系数据库，旨在实现高效的数据分析，由非盈利组织 DuckDB 基金会管理。它易于安装，运行速度非常快，并且可以在进程内 (in-process) 运行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;项目团队发布了最新的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fduckdb.org%2Fdocs%2Fstable%2Fdev%2Froadmap.html&quot; target=&quot;_blank&quot;&gt;发展路线图&lt;/a&gt;，具体内容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Planned Features (March 2025)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DuckDB 团队计划在来年开发的功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;background-color:#fafafa; color:#0d0d0d&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fextension-template-c&quot; target=&quot;_blank&quot;&gt;C extension API&lt;/a&gt;&amp;nbsp;的文档&lt;/li&gt; 
 &lt;li&gt;Generic ODBC catalog，类似于现有的 PostgreSQL / MySQL / SQLite 集成&lt;/li&gt; 
 &lt;li&gt;支持 Go 和 Rust 扩展&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fduckdb.org%2Fdocs%2Fextensions%2Ficeberg&quot; target=&quot;_blank&quot;&gt;通过 iceberg 扩展&lt;/a&gt;改进了对 iceberg 格式的支持&lt;/li&gt; 
 &lt;li&gt;用于模式匹配的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F3994&quot; target=&quot;_blank&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;MATCH RECOGNIZE&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;使用缓冲区管理器缓存远程文件内容（例如，在 S3 上查询 Parquet 文件时）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Future Work&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;计划在未来的某个时间点完成以下实现：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;时间序列优化&lt;/li&gt; 
 &lt;li&gt;分区感知优化&lt;/li&gt; 
 &lt;li&gt;排序感知优化&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F4512&quot; target=&quot;_blank&quot;&gt;数据库文件加密&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;使用自动维护的 table samples 进行更好的&amp;nbsp;Filter Cardinality Estimation&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fissues%2F14817&quot; target=&quot;_blank&quot;&gt;Parallel Python UDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F4204&quot; target=&quot;_blank&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;ALTER TABLE&lt;/code&gt;支持添加外键&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;查询分析的改进（尤其是对于并发运行的查询）&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F9547&quot; target=&quot;_blank&quot;&gt;XML 读取支持&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F3638&quot; target=&quot;_blank&quot;&gt;Materialized views&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F13396&quot; target=&quot;_blank&quot;&gt;&lt;code class=&quot;language-plaintext&quot;&gt;MERGE&lt;/code&gt;statement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F3560&quot; target=&quot;_blank&quot;&gt;支持异步 I/O&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fduckdb%2Fduckdb%2Fdiscussions%2F8104&quot; target=&quot;_blank&quot;&gt;支持 PL/SQL 存储过程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341325/duckdb-roadmap</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341325/duckdb-roadmap</guid>
            <pubDate>Sat, 22 Mar 2025 06:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>