<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 03 Aug 2025 16:43:38 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Rust 跨平台开发框架 Tauri 开启 2025 董事会选举</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 是一个桌面 UI 框架，可让开发者使用每个平台的 Webview 技术栈为所有主要桌面操作系统构建应用程序，目前支持 Windows/macOS/Linux 等平台。开发者通过 Tauri 几乎可以使用任何编译为 HTML、JS 和 CSS 的前端框架来构建桌面 UI。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Tauri 核心库采用 Rust 编写，使用 Tauri 开发的应用程序的后端是一个基于 Rust 的二进制文件，带有一个前端可以与之交互的 API，通过 JS Api 调用后台接口。&lt;/p&gt; 
&lt;p&gt;日期，Tauri 社区正在进行 2025 董事会选举。根据 Tauri 的治理结构，董事会（Board of Directors）为核心决策机构，负责项目的整体健康与稳定。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;董事会选举安排&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;本次选举将有 5 个席位开放&lt;/strong&gt;，董事任期为两年，董事会规定最少 3 人，最多 7 人。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;选举采用&lt;strong&gt;两年轮换制&lt;/strong&gt;：每年选举部分席位，两年内覆盖全部席位，确保连续性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;申请流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;有意者应按以下三个步骤申请成为候选人：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;阅读 Tauri Governance 页面中董事角色职责；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;准备一份介绍材料，包括个人背景、与 Tauri 的关联，以及能为董事会贡献的方面；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;在 2025 年 7 月 7 日前提交申请&lt;/strong&gt;，可通过电子邮件发送至 board@tauri.app，或在 Discord 上联系 &lt;code&gt;@board&lt;/code&gt; 角色。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftauri.app%2Fblog%2Ftauri-board-elections-2025%2F" target="_blank"&gt;https://tauri.app/blog/tauri-board-elections-2025/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363686/tauri-board-elections-2025</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363686/tauri-board-elections-2025</guid>
      <pubDate>Fri, 01 Aug 2025 11:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>上半年我国软件业务收入 70585 亿元</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;工业和信息化部运行监测协调局公告&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.miit.gov.cn%2Fjgsj%2Fyxj%2Fxxfb%2Fart%2F2025%2Fart_68003fdb41984bcab3f1234f8c8eb449.html" target="_blank"&gt;指出&lt;/a&gt;&lt;span style="color:#000000"&gt;，&lt;/span&gt;2025 年上半年，我国软件和信息技术服务业（以下简称「软件业」）运行态势良好，软件业务收入稳健增长，利润总额保持两位数增长，软件业务出口保持正增长。&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;一、总体运行情况&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;软件业务收入稳健增长。上半年，我国软件业务收入 70585 亿元，同比增长 11.9%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;利润总额增速保持两位数增长。上半年，软件业利润总额 8581 亿元，同比增长 12.0%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;软件业务出口保持正增长。上半年，软件业务出口 283 亿美元，同比增长 5.3%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;二、分领域运行情况&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;软件产品收入平稳增长。上半年，软件产品收入 15441 亿元，同比增长 10.6%，占全行业收入比重为 21.9%。其中，基础软件产品收入 903 亿元，同比增长 13.8%；工业软件产品收入 1445 亿元，同比增长 8.8%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息技术服务收入保持两位数增长。上半年，信息技术服务收入 48362 亿元，同比增长 12.9%，占全行业收入的 68.5%。其中，云计算、大数据服务共实现收入 7434 亿元，同比增长 12.1%，占信息技术服务收入的 15.4%；集成电路设计收入 2022 亿元，同比增长 18.8%；电子商务平台技术服务收入 5882 亿元，同比增长 10.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;信息安全收入稳定增长。上半年，信息安全产品和服务收入 1052 亿元，同比增长 8.2%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;嵌入式系统软件收入稳定增长。上半年，嵌入式系统软件收入 5730 亿元，同比增长 8.5%。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:justify"&gt;&lt;strong&gt;三、分地区运行情况&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;上半年，东部地区、中部地区、西部地区和东北地区件业务收入分别同比增长 12.1%、12.5%、10.4% 和 9.2%。东部地区占全国软件业务总收入的 84.3%。&lt;/p&gt; 
&lt;p style="color:#070707; margin-left:0; margin-right:0; text-align:justify"&gt;京津冀地区软件业务收入同比增长 12.5%，长三角地区软件业务收入同比增长 13.7%。北京、广东、江苏、山东、上海软件业务收入居全国前 5，同比分别增长 12.6%、9.0%、14.4%、12.9% 和 18.0%。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363681</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363681</guid>
      <pubDate>Fri, 01 Aug 2025 10:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>agentUniverse 多智能体框架实现专家级金融分析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;div&gt;
  7 月 26 日，【Al Agent：从工具助手到自主行动】OSC 源创会·杭州站·115 期活动成功举办，蚂蚁集团智能投研架构师赵泽伟带来了题为《agentUniverse 多智能体框架实现专家级金融分析》的精彩演讲，深入阐述了如何利用多智能体技术突破金融智能化的关键瓶颈。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  赵泽伟展示了 agentUniverse 在金融投研核心场景的成功实践： 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    语控金融分析： 首创「白盒化」分析过程，确保每一步思路、数据来源清晰可见、可追溯，严格满足金融严谨性要求。支持灵活定制和修改分析流程，贴合不同金融专家的思维模式。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    报告解读/市场分析/政策解读/宏观分析： 构建专业化智能体矩阵，实现 7×24 小时全市场动态感知与投资机会挖掘。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化因子复现与计算： 攻克「精准可控代码生成」难题。通过「量化专家知识框架注入」、「多模态信息抽取（财报提取、校验）」、「代码质检与自迭代」等 Micro Agent 协作，平衡大模型创造力与金融计算所需的绝对精确性，确保结果基于真实金融数据与框架。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    QuantExpert®量化研报方法论复现： 同样应用专家框架注入与精准代码生成能力，擅长处理长文本拆解，保障量化研究的严谨复现。 
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div&gt;
    研报生成： 将 AI 分析能力无缝输出至支付宝理财等丰富业务场景。 
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt;
  基于这些实践，赵泽伟解释，agentUniverse 的核心创新在于两大关键技术：一是 PEER 仿金融专家协同推理，可以模拟人类金融专家团队的分工协作模式。不同智能体扮演专业角色（如分析师、计算校验员），通过高效协同提升整体分析的专业深度和可靠性，实现「分工带来专业」。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="734" src="https://oscimg.oschina.net/oscnet/up-5c9968e8248cd054725f87f10cc0546b22e.png" width="1408" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  二是 DITR 动态工具插值推理技术： 让智能体「通过实践检验推理」。智能体能在推理过程中动态调用并整合多样化专业工具（如数据查询、计算引擎、校验模块），实时验证分析步骤与结果，极大增强了复杂金融逻辑处理的可信度。丰富的工具生态也使其能快速适应不同分析场景需求。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height="596" src="https://oscimg.oschina.net/oscnet/up-0de916b64349622118b22423e076ef33106.png" width="1392" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div&gt;
  具体组件方面，agentUniverse 多智能体框架集成经产业验证的 
 &lt;code&gt;agentUniverse.RaG&lt;/code&gt;检索增强能力，确保信息准确； 
 &lt;code&gt;agentUniverse.Mem&lt;/code&gt;提供强大的多轮会话与记忆管理。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  此外，agentUniverse 还具备一些企业级特性，包括效果可观测与可反馈：，全链路记录服务、模型交互，支持效果评测与迭代优化；一键服务化，便捷启动 WebServer，轻松集成至现有业务系统；标准容器交付，提供标准 Docker 镜像，支持 K8S 等云原生部署；私有化扩展：，提供开放框架，支持企业无缝接入自研 RPC、消息、日志等私有组件。 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;div&gt;
   下期活动预告： 
 &lt;/div&gt; 
 &lt;div&gt;
   【AIoT 共振场：重构万物智联新图层】 OSC 源创会·深圳站·116 期 
 &lt;/div&gt; 
 &lt;div&gt;
   查看详情： https://www.oschina.net/event/8598019 
 &lt;/div&gt; 
&lt;/blockquote&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18686762</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18686762</guid>
      <pubDate>Fri, 01 Aug 2025 09:58:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Black Forest Labs 联手 Krea 开源 FLUX.1-Krea 模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Black Forest Labs 与 AI 初创公司 Krea 携手推出开源图像生成模型 FLUX.1-Krea [dev]，该模型专注于解决当前 AI 生成图像中普遍存在的"人工痕迹"问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev] 的核心设计理念是摆脱传统 AI 生成图像的"塑料感"和过度处理效果。许多现有的 AI 图像生成模型往往会产生过曝高光、不自然的色彩饱和度以及明显的人工痕迹，这些特征让观众一眼就能识别出是 AI 生成的作品。新模型通过算法优化和训练策略改进，着重呈现更加自然的光影效果和细节表现，让生成的图像更接近真实摄影作品的质感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="324" src="https://oscimg.oschina.net/oscnet/up-a8ccb9505eaffaaf11ac52a3315330cbaa7.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在技术架构方面，FLUX.1-Krea [dev]基于 Black Forest Labs 提供的 flux-dev-raw 基础模型构建。这是一个经过预训练并指导优化的 12B 参数扩散变换模型，为新模型的高质量输出奠定了坚实基础。Krea 团队在此基础上进行了深度定制化开发，通过监督微调和人类反馈强化学习两个关键阶段，精心策划了高质量的图像数据集用于模型训练。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;人类反馈强化学习的引入是该模型的重要技术亮点。这种训练方法让 AI 模型能够更好地理解和符合人类的审美标准，而不是仅仅依靠技术指标进行优化。通过大量人工标注和反馈数据，模型学会了区分什么样的图像效果更符合人类的视觉偏好，从而在生成过程中自动避免那些看起来"不自然"的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;FLUX.1-Krea [dev]的另一个重要优势是其与现有 FLUX 开源生态系统的完全兼容性。这意味着已经基于 FLUX 模型开发应用或工具的开发者可以无缝迁移到新模型，无需重新构建整个技术栈。这种兼容性设计大大降低了新技术的采用成本，有利于推动整个开源社区的技术升级。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Krea 表示，FLUX.1-Krea [dev]的开发不仅仅是技术层面的改进，更是对用户创作体验的全面优化。通过减少"AI 味"的视觉特征，用户可以创作出更具专业水准的视觉内容，无论是用于商业设计还是个人创作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363668</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363668</guid>
      <pubDate>Fri, 01 Aug 2025 09:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>如何修复上下文，缓解与避免上下文失败</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;作为我们之前文章《长上下文如何失败》的后续，这篇将介绍我们可以如何缓解甚至完全避免这些失败。&lt;/p&gt; 
&lt;p&gt;但在开始之前，让我们快速回顾一下&lt;/p&gt; 
&lt;p&gt;★ 长上下文常见的失败方式：&lt;/p&gt; 
&lt;p&gt;1. 上下文污染（Context Poisoning）： 当幻觉或其他错误被加入上下文中，并被反复引用。&lt;/p&gt; 
&lt;p&gt;2. 上下文干扰（Context Distraction）： 当上下文过长，导致模型过度依赖上下文，而忽视了训练中学到的知识。&lt;/p&gt; 
&lt;p&gt;3. 上下文混淆（Context Confusion）： 当上下文中包含冗余信息，模型因此生成质量较低的回应。&lt;/p&gt; 
&lt;p&gt;4. 上下文冲突（Context Clash）： 当新信息或工具与原有 prompt 中的信息发生冲突。&lt;/p&gt; 
&lt;p&gt;这一切都是信息管理问题。上下文中的每一项信息都会影响模型输出。正如老编程格言所说：「Garbage in, garbage out」。幸运的是，我们有很多方法可以应对这些问题。&lt;/p&gt; 
&lt;p&gt;★ 上下文管理策略&lt;/p&gt; 
&lt;p&gt;- RAG：选择性地添加相关信息以提高 LLM 的回答质量&lt;/p&gt; 
&lt;p&gt;- 工具加载（Tool Loadout）：只添加任务相关的工具定义到上下文&lt;/p&gt; 
&lt;p&gt;- 上下文隔离（Context Quarantine）：将不同上下文隔离在独立线程中使用&lt;/p&gt; 
&lt;p&gt;- 上下文剪枝（Context Pruning）：移除不相关或无用的信息&lt;/p&gt; 
&lt;p&gt;- 上下文摘要（Context Summarization）：将累积的上下文压缩为摘要&lt;/p&gt; 
&lt;p&gt;- 上下文卸载（Context Offloading）：将信息存储在 LLM 上下文之外的工具中&lt;/p&gt; 
&lt;p&gt;★ RAG（检索增强生成）&lt;/p&gt; 
&lt;p&gt;RAG 是指选择性地将相关信息加入上下文，以帮助 LLM 更好地生成回答。&lt;/p&gt; 
&lt;p&gt;虽然随着模型上下文窗口越来越大（如 Llama 4 Scout 的 1000 万 token），很多人觉得「把所有信息全塞进去」就够了，但如果像杂物抽屉那样使用上下文，杂物也会污染模型生成。&lt;/p&gt; 
&lt;p&gt;要想了解更多，作者推荐了一个新的课程：I don’t use RAG. I just retrieve documents.&lt;/p&gt; 
&lt;p&gt;★ 工具加载（Tool Loadout）&lt;/p&gt; 
&lt;p&gt;工具加载指的是为任务选择合适的工具描述加入上下文。&lt;/p&gt; 
&lt;p&gt;术语「loadout」来自游戏世界，指的是你选择的技能、武器和装备组合。&lt;/p&gt; 
&lt;p&gt;这项技术可以结合 RAG。例如，Tiantian Gan 和 Qiyao Sun 在其论文 RAG MCP 中展示了如何通过向量数据库检索相关工具描述。&lt;/p&gt; 
&lt;p&gt;- 研究发现，当工具数量超过 30 时描述会重叠，产生混淆；&lt;/p&gt; 
&lt;p&gt;- 超过 100 个工具几乎必然导致模型失败；&lt;/p&gt; 
&lt;p&gt;- 使用 RAG 技术将工具数控制在 30 以内，可将工具选择准确率提升 3 倍。&lt;/p&gt; 
&lt;p&gt;对于小模型问题更早就会暴露，例如论文 Less is More 指出：LLaMA 3.1 8b 给 46 个工具会失败，而给 19 个工具则表现良好。问题是混淆，而不是上下文长度限制。&lt;/p&gt; 
&lt;p&gt;即使动态工具选择方法未提升模型准确率，它带来的电量节省（18%）和速度提升（77%）也是值得的。&lt;/p&gt; 
&lt;p&gt;★ 上下文隔离（Context Quarantine）&lt;/p&gt; 
&lt;p&gt;这是指将不同任务拆分为独立线程，每个线程使用独立上下文。&lt;/p&gt; 
&lt;p&gt;例如 Anthropic 的多智能体研究系统就是用多个子智能体并行运行，彼此隔离、分别检索，最后由主智能体整合输出。&lt;/p&gt; 
&lt;p&gt;他们在评估中发现：&lt;/p&gt; 
&lt;p&gt;～ 使用多智能体时，相比单一 Claude Opus 4，回答准确率提升了 90.2%；&lt;/p&gt; 
&lt;p&gt;- 多智能体系统能将一个复杂任务拆分成多个子任务并行完成；&lt;/p&gt; 
&lt;p&gt;- 不同子智能体可使用不同的工具集，解决加载冲突问题。&lt;/p&gt; 
&lt;p&gt;★ 上下文剪枝（Context Pruning）&lt;/p&gt; 
&lt;p&gt;随着任务进行，智能体会累积大量上下文，可能需要清理。&lt;/p&gt; 
&lt;p&gt;作者推荐了一款轻量剪枝工具：Provence，其模型大小仅 1.75GB，调用简单，能将不相关信息剔除 95%，效果优秀。&lt;/p&gt; 
&lt;p&gt;剪枝更有效的方式是将上下文结构化成字典或模块，方便根据规则进行删减。&lt;/p&gt; 
&lt;p&gt;★ 上下文摘要（Context Summarization）&lt;/p&gt; 
&lt;p&gt;即便上下文足够长，过长的历史也会使模型过度依赖记忆，而非推理。&lt;/p&gt; 
&lt;p&gt;例如 Gemini 2.5 Pro 支持超过 100 万 token 的上下文，但一旦超出 10 万 tokens，模型就会偏向重复历史行为，而非生成新计划。&lt;/p&gt; 
&lt;p&gt;总结步骤可由独立 LLM 实现，并可积累评估数据，以持续优化摘要质量。&lt;/p&gt; 
&lt;p&gt;★ 上下文卸载（Context Offloading）&lt;/p&gt; 
&lt;p&gt;即将笔记或中间推理步骤移出上下文，存放于外部工具中，例如 Anthropic 的 「think tool」（更贴切应叫 「scratchpad」）。&lt;/p&gt; 
&lt;p&gt;用途包括：&lt;/p&gt; 
&lt;p&gt;1. 工具调用后中间结果分析；&lt;/p&gt; 
&lt;p&gt;2. 严格政策/合规规则场景；&lt;/p&gt; 
&lt;p&gt;3. 多步决策路径，每步都可能受前一步影响。&lt;/p&gt; 
&lt;p&gt;研究显示，在这些场景中，配合领域定制 prompt，可提升性能最多达 54%。&lt;/p&gt; 
&lt;p&gt;★ 总结&lt;/p&gt; 
&lt;p&gt;构建智能体最困难的部分通常就是上下文管理。&lt;/p&gt; 
&lt;p&gt;Karpathy 曾说过，让 LLM 「just pack the context window right」，就是智能体开发者的任务。&lt;/p&gt; 
&lt;p&gt;关键观点是：上下文不是免费的，每个 token 都会影响模型行为。&lt;/p&gt; 
&lt;p&gt;即便拥有更大的上下文窗口，也不是信息管理可以松懈的理由。构建或优化智能体时请问自己：&lt;/p&gt; 
&lt;p&gt;&amp;gt; 上下文中的每一项，是否都值得留下？&lt;/p&gt; 
&lt;p&gt;如果答案是否定的，那么你已经有了六种修复方法可用。&lt;/p&gt; 
&lt;p&gt;访问：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.dbreunig.com%2F2025%2F06%2F26%2Fhow-to-fix-your-context.html" target="_blank"&gt;www.dbreunig.com/2025/06/26/how-to-fix-your-context.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F5648162302%2FPDKpeqgWw%3Fpagetype%3Dprofilefeed" target="_blank"&gt;黄建同学，微博&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363652/how-to-fix-your-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363652/how-to-fix-your-context</guid>
      <pubDate>Fri, 01 Aug 2025 08:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>生命周期不足三个月，Windows 10 市占率急剧下降</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;根据微软的计划，Windows 10 的主流支持将于 2025 年 10 月 14 日结束，虽然微软会为用户提供额外一年的免费更新，但许多用户已经开始寻找替代方案。&lt;/p&gt; 
&lt;p&gt;根据 Statcounter 的最新数据，Windows 10 的市场份额正在急剧下降，2025 年 7 月，Windows 10 的市场份额从与 Windows 11 平分秋色，迅速跌落到低于 Windows 11。&lt;/p&gt; 
&lt;p&gt;目前 Windows 10 的市场份额为 42.99%，仅一个月就下降了 4.99 个百分点，而与去年同期相比，其市场份额更是从 64.99% 下降到了 42.99%，下降了 22 个百分点。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6d94c0944c9e3ac49225685785d2e6635f1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;与此同时，Windows 11 的市场份额则在迅速上升，从 47.98% 增加到 53.39%，仅一个月就增长了 5.41 个百分点，这一增长幅度对于备受争议的 Windows 11 来说实属罕见。与去年同期相比，Windows 11 的市场份额增长了 22.56 个百分点。&lt;/p&gt; 
&lt;p&gt;目前，还受支持的 Windows 版本（主要是 Windows 10 和 Windows 11）占据了超过 96% 的 Windows 市场份额。&lt;/p&gt; 
&lt;p&gt;其余的市场份额则被 Windows 7（2.04%）、Windows 8（0.88%）、Windows XP（0.44%）和 Windows 8.1（0.23%）瓜分。&lt;/p&gt; 
&lt;p&gt;对于仍在使用 Windows 10 的用户来说，现在可能需要开始考虑替代方案了，一种选择是加入微软的扩展安全更新计划，该计划可以为用户提供额外 12 个月的安全更新。&lt;/p&gt; 
&lt;p&gt;另一种选择是直接升级到 Windows 11，随着其它厂商也即将停止对 Windows 10 的驱动支持，放弃 Windows 10 也是迟早的选择。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363649</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363649</guid>
      <pubDate>Fri, 01 Aug 2025 08:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linus 仍在使用 AMD RX 580 显卡搭配线程撕裂者</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在 2025 年的今天，Linus Torvalds 依然在使用 2017 年发布的 AMD RX 580 作为其主要桌面显卡。这款基于 Polaris 架构的显卡在 Linux 圈子里得益于成熟完善的开源驱动支持，表现得相当出色，这也使得 Linus 对其青睐有加。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bbed3b6b8ea96e0939b6b75d90962a914e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FRadeon-RX-590-Torvalds" target="_blank"&gt;Phoronix 发现&lt;/a&gt;&lt;/u&gt;，在 Linux 6.17 中，AMD 的 DSC 技术引发了黑屏问题，Linus 亲自定位并回退了相关补丁，以保证内核开发的顺利进行。&lt;/p&gt; 
&lt;p&gt;Linus 在邮件中提到 「还是那个老掉牙的 Radeon RX 580」，简单一句话，尽显其对稳定性的偏好。&lt;/p&gt; 
&lt;p&gt;&lt;img height="576" src="https://static.oschina.net/uploads/space/2025/0801/163801_oitH_2720166.png" width="1368" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;虽然 RX 580 在现代游戏或 AI 工作负载下会力不从心，但对于编译内核来说，配合 Linus 的 AMD 线程撕裂者系统，已经完全足够。&lt;/p&gt; 
&lt;p&gt;Linus 几年前从英特尔转向了线程撕裂者 CPU，以加快 Linux 内核构建速度，事实证明这一选择非常明智。&lt;/p&gt; 
&lt;p&gt;在笔记本方面，Linus 也重回英特尔阵营，此前他曾短暂使用过苹果 M1 MacBook，他没有透露具体型号，但确认它使用的是 Intel 集成「i915」显卡。&lt;/p&gt; 
&lt;p&gt;Linus 一直对那些限制硬件或使内核开发复杂化的平台不太感兴趣，不少人应该还记得 2012 年的那场问答，当时 Linus 竖起中指，破口大骂：「NVIDIA，Fxxk You」。&lt;/p&gt; 
&lt;p&gt;如今 NVIDIA 虽然发布部分驱动源代码并改进了对开放内核的支持，但很显然 Linus 仍然偏爱开放的 AMD。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363647</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363647</guid>
      <pubDate>Fri, 01 Aug 2025 08:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MOSS-TTSD 开源：百万小时训练打造 AI 播客新王者</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;由清华大学语音与语言实验室 (Tencent AI Lab) 联合上海创智学院、复旦大学和模思智能打造的 MOSS-TTSD (Text to Spoken Dialogue) 近日正式开源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这款基于 Qwen3-1.7B-base 模型续训练的语音对话生成模型，以约 100 万小时单说话人语音数据和 40 万小时对话语音数据为基础，采用离散化语音序列建模方法，实现了中英双语的高表现力对话语音生成，特别适合 AI 播客、有声小说和影视配音等长篇内容创作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-486a73dddfa4c43623c233fef6faa3175cd.png" width="600" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MOSS-TTSD 的核心创新在于其 XY-Tokenizer，采用双阶段多任务学习方式，通过八层 RVQ 码本将语音信号压缩至 1kbps 比特率，同时保留语义与声学信息，确保生成语音的自然度和流畅性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;模型支持最长 960 秒的超长语音生成，避免了传统 TTS 模型拼接片段导致的不自然过渡。此外，MOSS-TTSD 具备零样本音色克隆能力，可通过上传完整对话片段或单人音频实现双人语音克隆，并支持声音事件控制，如笑声等非语言声音，赋予语音更丰富的表现力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;与市场上其他语音模型相比，MOSS-TTSD 在中文客观指标上大幅领先开源模型 MoonCast，韵律和自然度表现优异。然而，相较于字节跳动的豆包语音模型，其语气和节奏感略逊一筹，但在开源和免费商业使用的优势下，MOSS-TTSD 仍展现出强大的应用潜力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MOSS-TTSD 的发布为 AI 语音交互领域注入新活力，尤其在长篇访谈、播客制作和影视配音等场景中，其稳定性和表现力将推动内容创作的智能化进程。未来，团队计划进一步优化模型，增强多说话人场景下的语音切换准确性和情感表达。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363646</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363646</guid>
      <pubDate>Fri, 01 Aug 2025 08:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MCP-Use - 将任何 LLM 连接到任何 MCP</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;MCP-Use 是一种开源方式，可将&lt;strong style="color:#1f2328"&gt;任何 LLM 连接到任何 MCP 服务器&lt;/strong&gt;并构建具有工具访问权限的自定义 MCP 代理，而无需使用闭源或应用程序客户端。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要特点：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;开源&lt;/strong&gt; 将任何 LLM 连接到任何 MCP 服务器，无需供应商锁定&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活配置&lt;/strong&gt; 通过简单的配置系统支持任何 MCP 服务器&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轻松设置&lt;/strong&gt; 用于 MCP 服务器集成的简单基于 JSON 的配置&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用 LLM 支持&lt;/strong&gt; 与任何 LangChain 支持的 LLM 提供商兼容&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多服务器支持&lt;/strong&gt; 同时连接到多个 MCP 服务器以实现复杂的工作流程&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态服务器选择&lt;/strong&gt; 代理可以为每个任务动态选择最合适的 MCP 服务器&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span style="color:#1f2328"&gt;让开发人员轻松地将任何 LLM 连接到网页浏览、文件操作等工具。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果想快速开始，可访问&lt;a href="https://mcp-use.com/"&gt;mcp-use.com 网站&lt;/a&gt;，使用你最喜欢的 MCP 服务器构建和部署代理。&lt;/li&gt;
&lt;li&gt;访问&lt;a href="https://docs.mcp-use.com/"&gt;mcp-use 文档&lt;/a&gt;以开始使用 mcp-use 库&lt;/li&gt;
&lt;li&gt;对于 TypeScript 版本，可访问&lt;a href="https://github.com/mcp-use/mcp-use-ts"&gt;mcp-use-ts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/mcp-use</link>
      <guid isPermaLink="false">https://www.oschina.net/p/mcp-use</guid>
      <pubDate>Fri, 01 Aug 2025 08:15:00 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 年化收入 120 亿美元，ChatGPT 周活用户突破 7 亿</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fopenai-hits-12-billion-annualized-revenue-breaks-700-million-chatgpt-weekly-active-users" target="_blank"&gt;根据 The Information 的报道&lt;/a&gt;，OpenAI 年化收入已翻倍至 120 亿美元，同时其旗舰产品 ChatGPT 的周活跃用户数突破 7 亿。&lt;/p&gt; 
&lt;p&gt;快速增长的同时，OpenAI 的现金消耗也在加速。该公司已将 2025 年现金消耗预期上调至约 80 亿美元，较此前预期增加 10 亿美元。其在服务器租赁方面的支出可能超过此前预计的 140 亿美元。&lt;/p&gt; 
&lt;p&gt;在融资方面，OpenAI 正接近完成第二轮融资其中 75 亿美元融投资的承诺，红杉资本和 Tiger Global Management 等现有股东将各自投入数亿美元，其他参与方包括 Dragoneer 和 Founders Fund 等知名投资机构。&lt;/p&gt; 
&lt;p&gt;据上述报道，OpenAI 在 2025 年前七个月实现收入翻番，年化收入达到 120 亿美元，相比 2024 年约 40 亿美元的收入水平实现大幅增长。这一强劲增长使得该公司有望超越其 2025 年 127 亿美元的收入预期。&lt;/p&gt; 
&lt;p&gt;上述媒体援引知情人士透露，OpenAI 目前月收入约为 10 亿美元，相比年初的约 5 亿美元实现大幅跃升。主要驱动力来自更多企业和个人订阅其用于编程和其他任务的聊天机器人服务。&lt;/p&gt; 
&lt;p&gt;用户增长是推动收入上升的关键因素。ChatGPT 产品目前拥有约 7 亿周活跃用户，涵盖消费者和企业客户，相比 3 月底 OpenAI 所有产品 5 亿周活跃用户的数据实现显著增长。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363632</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363632</guid>
      <pubDate>Fri, 01 Aug 2025 07:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Vercel 发布 AI SDK 5，构建全栈 AI 应用的开发工具包</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Vercel 发布了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;AI SDK 5&lt;/a&gt;，这是一个用于构建全栈 AI 应用的开发工具包，它在前代基础上进行了全面升级，提供了更强大的功能、更高的灵活性和更好的开发体验。&lt;/p&gt; 
&lt;p&gt;&lt;img height="565" src="https://static.oschina.net/uploads/space/2025/0801/153828_B1BV_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是 AI SDK 5 的主要更新内容：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聊天功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;彻底重建&lt;/strong&gt;：引入了两种不同的消息类型——&lt;code&gt;UIMessage&lt;/code&gt; 和 &lt;code&gt;ModelMessage&lt;/code&gt;，解决了开发者在状态管理和聊天历史持久化方面的挑战。&lt;code&gt;UIMessage&lt;/code&gt; 是应用程序状态的「真实来源」，包含所有消息、元数据和工具结果，推荐用于持久化存储；&lt;code&gt;ModelMessage&lt;/code&gt; 则是为语言模型优化的简化表示。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;类型安全&lt;/strong&gt;：开发者可以创建自定义的 &lt;code&gt;UIMessage&lt;/code&gt; 类型，并在服务器和客户端之间传递，实现端到端的完全类型安全。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;流式传输&lt;/strong&gt;：引入了 &lt;code&gt;Data Parts&lt;/code&gt; 功能，允许开发者发送自定义数据块，如状态更新或部分工具结果，同时保持代码的可维护性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Agent 构建&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;精确的执行流控制&lt;/strong&gt;：&lt;code&gt;stopWhen&lt;/code&gt; 参数允许开发者定义工具调用循环的停止条件，例如达到特定步数或调用了某个特定工具；&lt;code&gt;prepareStep&lt;/code&gt; 钩子则允许在每一步执行前动态调整参数，如更换模型、修改系统提示或启用/禁用特定工具。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;面向对象封装&lt;/strong&gt;：新增的 &lt;code&gt;Agent&lt;/code&gt; 类为构建 Agent 提供了面向对象的封装。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;语音功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一提供商抽象&lt;/strong&gt;：通过 &lt;code&gt;experimental_generateSpeech&lt;/code&gt; 和 &lt;code&gt;experimental_transcribe&lt;/code&gt; API，为 OpenAI、ElevenLabs、DeepGram 等提供商的语音生成和转录服务提供了统一、类型安全的接口。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;工具调用增强&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;动态工具&lt;/strong&gt;：支持动态工具、提供商执行的工具（如 OpenAI 的网页搜索）以及更精细的生命周期钩子。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;其他更新&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;流媒体协议&lt;/strong&gt;：将 &lt;code&gt;SSE&lt;/code&gt; 作为标准的流媒体协议。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;全局提供商&lt;/strong&gt;：引入全局提供商（默认为 Vercel AI Gateway），简化模型 ID 的使用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;访问原始数据&lt;/strong&gt;：支持访问原始请求和响应数据以增强调试和控制能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zod 4 支持&lt;/strong&gt;：增加了对 Zod 4 的支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;迁移工具&lt;/strong&gt;：为帮助用户平滑迁移，Vercel 提供了自动化的代码修改工具（&lt;code&gt;codemods&lt;/code&gt;）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-sdk-5" target="_blank"&gt;点此查看发布说明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363628/vercel-ai-sdk-5</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363628/vercel-ai-sdk-5</guid>
      <pubDate>Fri, 01 Aug 2025 07:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软向报告 .NET 漏洞的用户支付高达 40000 美元的报酬</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;许多公司提供漏洞赏金计划，鼓励人们搜索并发现软件中的安全漏洞，并私下向供应商报告，以便在恶意攻击者利用漏洞之前实施并应用修复程序。安全研究人员和其他公众会获得金钱奖励，从而获得经济激励。&lt;/p&gt; 
&lt;p&gt;现在，微软已宣布对其 .NET Bounty 计划进行重大更新。&lt;/p&gt; 
&lt;p&gt;奖励金额现从 7000 美元起，最高可达令人垂涎的 40000 美元。请注意，最高奖励仅适用于私下披露远程代码执行 (RCE) 或特权提升 (EoP) 漏洞，并提供完整文档且造成严重影响的情况。&lt;/p&gt; 
&lt;p&gt;各奖励等级的细分如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/153421_aSuq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，.NET 赏金计划主要围绕 .NET 和 ASP.NET&amp;nbsp;Core 展开，包括 Blazor 和 Aspire。但新的产品类别现在涵盖了所有受支持的 .NET 和 ASP.NET 版本、适用于 .NET Framework 的 ASP.NET&amp;nbsp;Core、上述内容提供的模板、其存储库中的 GitHub Actions 以及 F# 等相关技术。&lt;/p&gt; 
&lt;p&gt;更新后的奖励结构确保了严重性等级的明确定义，以便高影响的问题获得更高的奖励，同时还提供了关于如何将报告视为「完整」的指南。您可以在微软的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmsrc.microsoft.com%2Fblog%2F2025%2F07%2F.net-bounty-program-now-offers-up-to-40000-in-awards%2F" target="_blank"&gt;专门博客文章&lt;/a&gt;中找到更多信息。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363626/dotnet-bounty-program-now-offers-up-to-40000-in-awards</guid>
      <pubDate>Fri, 01 Aug 2025 07:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>没有套路，真的免费：模力方舟全免费的模型都在这了</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;想找无套路，真免费，不限额度的大模型？别再满世界找了——来模力方舟就够。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;立即访问模力方舟 AI 模型广场：&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本文整理了目前模力方舟上完全免费开放使用的模型， 不是「每天送你 10 次体验」，也不是「注册送额度」，更不是「邀请获礼金」，而是&lt;strong&gt;不限次数、毫无限制、直接免费用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;无论你是想&lt;strong&gt;生成文本、写代码、合成语音、做推理，还是想过滤下内容风险&lt;/strong&gt;，模力方舟都准备好了免费的相关模型，&lt;strong&gt;全部 0 元接入、不限次数&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;通用语言模型：超能聊，跑得快&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen3-8B / Qwen3-4B / Qwen3-0.6B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151643_pivg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;国产开源的 Qwen3 系列，从轻量级到中型参数都有，支持「思考模式」与「对话模式」自由切换，还能写代码、讲英文、做推理。模型权重与 API 已全面开放，商用也不用担心授权问题。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Qwen2-7B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151659_Ojcp_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;升级版 Qwen 架构，专为「你让它干啥它就干啥」的指令模式设计，适合结构化问答、信息抽取等任务，照样免费用。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;InternLM3-8B-Instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;书生·浦语第三代，和 Qwen 一样属于国产头部阵营，指令跟随能力强、推理不拉胯，在 8B 量级里非常能打。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151711_9iVU_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GLM-4-9B / GLM-4-9B-Chat&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151725_ZpJL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自智谱的通用语言模型，性能扎实，特别适合中文语境下的多轮问答和对话场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-R1-Distill-Qwen 系列（14B / 7B / 1.5B）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151739_89cE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 模型的轻量蒸馏版，覆盖大中小三种参数体型，推理性能不错但定位仍是通用语言模型，适合对资源有要求的部署场景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;数学 / 定理证明：专精模型上场&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-Prover-V2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151756_uzEG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;专为 Lean 4 定理证明设计，具备将复杂问题拆解为子目标、合成链式推理过程的能力。模型通过 DeepSeek-V3 驱动的递归证明管线进行冷启动训练，融合非形式与形式数学推理，显著提升了定理证明效率与泛化能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;代码生成模型：小身材，大能力&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;codegeex4-all-9b&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151809_32Qh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;多语言代码生成模型，支持包括代码补全和生成、代码解释器、网络搜索、函数调用、仓库级代码问答在内的全面功能，覆盖软件开发的各种场景。是参数少于 10B 的顶尖代码生成模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;语音识别/合成模型：小体积，大用途&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;SenseVoiceSmall&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151839_AoYq_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自通义千问团队的轻量级语音模型，结合高效算法和小型化设计，提供低延迟和高准确度的语音处理能力，适用于资源受限的应用场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Spark-TTS-0.5B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151851_iZPk_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;来自 Spark Audio 团队的文本转语音模型，能够实现高精度、自然的语音合成。它高效、灵活、功能强大，适用于研究和生产环境。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;风控识别模型：确保内容合规&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;nsfw-classifier / Security-semantic-filtering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151909_OgHB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模力方舟提供了两种风控识别模型，分别面向图片分类和文本敏感内容过滤，确保内容合规与敏感信息保护。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;检索增强开发者福利：向量 + 重排模型也全免费&lt;/h4&gt; 
&lt;p&gt;模力方舟携手国产 GPU 伙伴，已将模型广场中 Embedding 与 Reranker 模型&lt;strong&gt;全部开放免费使用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;RAG 架构必备的检索向量和重排序能力，即刻零成本上手！&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Embedding 向量模型：支持中文、英文、多语言编码，适配主流语义检索任务；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reranker 重排序模型：优化文档排序效果，让你的检索结果相关且可信。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151936_fUHW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;所有模型支持 API 调用，无需申请、无需授权、直接接入，非常适合搜索类应用、知识库问答、RAG 业务开发等场景使用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;真免费，不限次，现在就能用&lt;/h3&gt; 
&lt;p&gt;马建仓再强调一次：上面这些模型&lt;strong&gt;没有「体验额度」，是「完全免费」&lt;/strong&gt;。不限制调用次数、不限制模型功能，可以直接接入使用。&lt;/p&gt; 
&lt;p&gt;立即访问模力方舟 AI 模型广场：&lt;strong&gt;&lt;a href="https://ai.gitee.com/serverless-api"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363622</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363622</guid>
      <pubDate>Fri, 01 Aug 2025 07:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元 3D 世界模型技术亮点速览</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;腾讯近日正式发布&lt;strong&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）&lt;/strong&gt;并全面开源。据称这是首个开源并且兼容传统 CG 管线的可漫游世界生成模型，为游戏开发、VR、数字内容创作等领域带来了全新的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150655_8uFO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据该模型的技术报告，HunyunWorld-1.0 采用生成式架构，结合全景图像合成与分层 3D 重建技术，实现了高质量、沉浸式的可漫游 3D 场景生成。&lt;/p&gt; 
&lt;p&gt;该模型通过语义分层的 3D 场景表征与生成算法，同时支持"文生世界"和"图生世界"两种生成方式。主要技术框架包括三部分，即全景世界代理生成、基于语义的世界分层与分层世界重建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/150932_iXbY_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;混元 3D 世界模型 1.0（HunyunWorld-1.0）是融合两类方法优势的创新框架，能够依据文本或图像输入生成沉浸式、可探索、可交互的 3D 场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;360°沉浸体验 ：通过全景图将复杂的 3D 世界高效地表征为 360 度覆盖的 2D 图像代理，为后续生成完整的 3D 世界建模提供了丰富的空间信息；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151052_YWxE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;工业级兼容性 ：生成的世界场景支持导出标准的 3D 网格格式，能够无缝导入现有 3D 建模软件和主流游戏引擎，用于二次开发；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151131_DzWQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原子级交互&amp;nbsp;：通过物体解耦的 3D 建模方式，生成物体和背景可分离的 3D 世界，支持精准的物体级交互控制，提升了生成世界的操作自由度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/151149_qD74_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2507.21809" target="_blank"&gt;点此查看更多技术细节&lt;/a&gt;&lt;/em&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363621</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363621</guid>
      <pubDate>Fri, 01 Aug 2025 07:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动 Seed 助力清华获机器人足球世界杯冠军</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;字节跳动 Seed 发文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4e6maGpWaEtWfj1rxkhI0w" target="_blank"&gt;宣布&lt;/a&gt;，其与清华大学赵明国教授团队联合研发的人形机器人运动算法 「HumanoidKick」 在 2025RoboCup 机器人世界杯人形组成人组比赛中，成功帮助清华火神队获得冠军。这也是中国机器人足球队首次在机器人世界杯该组别夺冠。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，此次夺冠的关键之一是&lt;strong&gt;基于视觉的&lt;strong&gt;&lt;strong&gt;端到端&lt;/strong&gt;&lt;/strong&gt;自主踢球算法 HumanoidKick&lt;/strong&gt;，由字节跳动 Seed 团队与清华大学赵明国教授团队联合提出并验证。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法面向人形机器人硬件，通过基于视觉的深度强化学习，实现了「找球 - 追球 - 踢球」全过程的统一策略，在实际足球比赛中验证有效。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="368" src="https://oscimg.oschina.net/oscnet/up-28b9adf735a26eea28efb96fd06fe8b5e72.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;HumanoidKick 算法尝试解决以下三项实际挑战：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从视觉到行动的实时联动&lt;/strong&gt;：传统机器人足球方案依赖手动编程的预设策略，面对场上变化，常陷入动作卡顿的困境，错失进攻的有利时机。该算法通过端到端深度强化学习方法，构建了视觉感知与机器人运动控制的毫秒响应机制，让机器人能像人类球员一样边「看」边「动」。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从动作整合到自主决策&lt;/strong&gt;：经过数千个环境的并行训练，机器人得以将多种分散的动作技能整合为统一连贯的端到端策略，构建起「单个动作」 「赛场行为」 「竞技策略」之间的关联。面对实时变化的赛场动态，机器人可以自主决策行动，并泛化出自适应的踢球能力。这种能力进化让机器人摆脱了被动执行预设动作的局限，实现了从零散技能到完整策略的突破。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;从仿真到真实环境的适应&lt;/strong&gt;：为了让算法在真实世界中保持稳定，团队采用精确建模和域随机化结合的训练方案——在仿真环境中，建模真实世界的感知噪声和物理扰动（如地面条件、关节噪声），让机器人在仿真环境中「经历」各种现实极端场景，实现从仿真环境到真机的无缝应用。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;依托仿真环境中的海量训练，HumanoidKick 算法在现实赛场中成功帮助机器人脱离既定动作流程束缚，依据瞬息万变的赛场态势，迅速自主规划行动方案。在比赛中，机器人展现出了较好的反应速度，最终取得胜利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363620</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363620</guid>
      <pubDate>Fri, 01 Aug 2025 07:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌开源 LangExtract，从非结构化文本提取结构化信息的 Python 库</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌开源了名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Flangextract" target="_blank"&gt;LangExtract&lt;/a&gt;的 Python 库，该库使用 LLMs 根据用户定义的指令从非结构化文本文档中提取结构化信息（诸如临床笔记或报告之类的材料），识别并整理关键细节，同时确保提取的数据与源文本相对应。&lt;/p&gt; 
&lt;p&gt;LangExtract 的核心优势在于其强大的功能特性。首先是「精确的源文本溯源」，它能将每一个提取出的信息精确映射回其在原始文本中的位置，并支持交互式高亮可视化，便于用户追溯和验证。&lt;/p&gt; 
&lt;p&gt;项目主页提供了快速上手的代码示例，演示了如何定义提示、提供示例、运行提取，并将结果保存为.jsonl 文件，最后生成交互式 HTML 可视化报告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0801/145804_AbcO_2720166.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;LangExtract 适用于任何领域，用户仅需提供少量示例即可定义提取任务，无需模型微调。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363619</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363619</guid>
      <pubDate>Fri, 01 Aug 2025 07:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>一张图解释上下文工程（Context Engineering ）</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;制图： Victoria Slocum&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-38450d8633e8576132b7439b4dd873cf590.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下为解释&lt;/p&gt; 
&lt;p&gt;---------------------------&lt;br&gt; 提示工程（Prompt Engineering）已死，上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴） 万岁！&lt;/p&gt; 
&lt;p&gt;（好吧，也没完全死掉——但它无疑正在进化成一种远为更强大的形态）&lt;/p&gt; 
&lt;p&gt;让我们来认识一下上下文工程（𝗖𝗼𝗻𝘁𝗲𝘅𝘁 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿𝗶𝗻𝗴）——这是一门艺术，致力于构建动态系统，从而精准地为大语言模型（LLM）提供成功完成任务所需的一切。&lt;/p&gt; 
&lt;p&gt;随着我们从简单的聊天机器人转向复杂的 AI 代理（Agent），我们正逐渐意识到，仅仅靠巧妙的提示语是不够的。真正重要的是精心编排一个完整的信息生态系统，并将这些信息输入到你的大语言模型中。&lt;/p&gt; 
&lt;p&gt;那么，这具体意味着什么呢？&lt;/p&gt; 
&lt;p&gt;它的核心在于构建动态系统，以正确的格式提供正确的信息和工具，从而让大语言模型能够切实地完成任务。&lt;/p&gt; 
&lt;p&gt;一个经过上下文工程设计的系统的构成解析：&lt;/p&gt; 
&lt;p&gt;✨用户信息 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗳𝗼𝗿𝗺𝗮𝘁𝗶𝗼𝗻): 偏好、历史记录和个性化数据。&lt;br&gt; ✨工具使用 (𝗧𝗼𝗼𝗹 𝗨𝘀𝗲): API、计算器、搜索引擎——任何大语言模型完成工作所需的工具。&lt;br&gt; ✨RAG 上下文 (𝗥𝗔𝗚 𝗖𝗼𝗻𝘁𝗲𝘅𝘁): 从像 Weaviate 这样的向量数据库中检索出的信息。&lt;br&gt; ✨用户输入 (𝗨𝘀𝗲𝗿 𝗜𝗻𝗽𝘂𝘁): 当前实际的查询或任务。&lt;br&gt; ✨代理推理 (𝗔𝗴𝗲𝗻𝘁 𝗥𝗲𝗮𝘀𝗼𝗻𝗶𝗻𝗴): 大语言模型的思考过程和决策链。&lt;br&gt; ✨聊天历史 (𝗖𝗵𝗮𝘁 𝗛𝗶𝘀𝘁𝗼𝗿𝘆): 提供对话连续性的先前交互记录。&lt;/p&gt; 
&lt;p&gt;那么，它的记忆架构是怎样的呢？&lt;/p&gt; 
&lt;p&gt;✨短期记忆 (𝗦𝗵𝗼𝗿𝘁-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存在于上下文窗口中，处理当前对话。&lt;br&gt; ✨长期记忆 (𝗟𝗼𝗻𝗴-𝘁𝗲𝗿𝗺 𝗺𝗲𝗺𝗼𝗿𝘆): 存储在向量数据库（如 Weaviate）中，跨会话持久化存储用户偏好和过去的交互记录。&lt;/p&gt; 
&lt;p&gt;这为什么重要？&lt;br&gt; 因为当代理系统（agentic systems）失败时，很少是因为模型本身不够聪明，而是因为我们没有给它提供正确的上下文。&lt;/p&gt; 
&lt;p&gt;信息的格式同样重要。一条结构清晰的错误信息，永远胜过一大堆杂乱的 JSON 数据。就像人类一样，大语言模型也需要清晰、易于理解的沟通方式。&lt;/p&gt; 
&lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FPDFOm8vhG" target="_blank"&gt;蚁工厂，微博&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363615</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363615</guid>
      <pubDate>Fri, 01 Aug 2025 06:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国上诉法院维持谷歌应用商店垄断裁决</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;位于旧金山的美国联邦第九巡回上诉法院 31 日裁定，驳回谷歌公司上诉，维持此前地方法院的陪审团裁决和法官指令。根据相关裁决和指令，谷歌将不得不改变其 Play 应用商店的一些重要管理方针，包括长期以来不允许其他应用商店在 Play 商店正常运营。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="300" src="https://oscimg.oschina.net/oscnet/up-097faa551a242c0ea617e6e9f397b03bcec.webp" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Epic 游戏公司此前在其开发的《堡垒之夜》游戏中，通过技术手段让玩家进行应用内购买时可选择绕过谷歌的支付系统，从而避免向谷歌支付 30% 的佣金，谷歌随后将该游戏从 Play 商店中下架。Epic 游戏公司在 2020 年就此提起针对谷歌的反垄断诉讼。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;陪审团 2023 年裁决，谷歌违反了联邦和加利福尼亚州反垄断法，故意获取或维持市场垄断地位，不合理地限制交易，并非法将 Play 商店的使用与该公司的结算服务捆绑在一起。地方法官 2024 年签发针对谷歌的指令，要求该公司整改 Play 商店，消除反竞争的行为。谷歌随后提起上诉，上诉期间该指令暂缓实施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;联邦第九巡回上诉法院法官的裁决驳回了谷歌的上诉，称地方法院在审理时并未滥用自由裁量权，所发布的指令得到陪审团裁决以及地方法院自身调查结果的支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这一最新的裁决公布后，Epic 首席执行官蒂姆·斯威尼在社交媒体平台上表示，安卓版 Epic 游戏商店将登陆 Play 商店。谷歌方面则表示，会继续上诉。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;按照相关法律程序，谷歌可以选择要求第九巡回上诉法院全体法官复审此案，也可以直接向最高法院上诉。（新华社）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363614</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363614</guid>
      <pubDate>Fri, 01 Aug 2025 06:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌发布面向程序员的开源字体：Google Sans Code</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌发布了一款面向程序员的开源字体：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgooglefonts%2Fgooglesans-code" target="_blank"&gt;Google Sans Code&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-94ed522f81ee53d97857a1fa258ac6bd4a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Google Sans Code 是一个等宽字体系列，为代码带来清晰度、可读性以及一丝谷歌独特的品牌特色。&lt;/p&gt; 
&lt;p&gt;主要特性&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;增强可读性：专为代码编辑器和终端中的最佳可读性而设计&lt;/li&gt; 
 &lt;li&gt;支持脚本：扩展拉丁文，支持多种语言&lt;/li&gt; 
 &lt;li&gt;变体字体：提供从 300 到 800 的广泛字重轴范围&lt;/li&gt; 
 &lt;li&gt;OpenType 功能：样式集、本地化形式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该字体源自谷歌的品牌字体设计风格，并为 Gemini 和 Android Studio 等产品开发，它确保每个字符即使在较小尺寸下也能保持清晰可辨。 此外，它还针对编程语言语法的独特排版需求进行了精细调整。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363609/googlesans-code</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363609/googlesans-code</guid>
      <pubDate>Fri, 01 Aug 2025 06:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 关联公司公布大语言模型部署方法专利</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;天眼查 App 显示，DeepSeek 关联公司杭州深度求索人工智能基础技术研究有限公司申请的「一种大语言模型的部署方法及系统」专利公布。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0afa30888a89708e3df22bbcdb8c9e1f8b2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9a97b9c49fa395a1f8e80a766f8cdd92565.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;摘要显示，该发明涉及人工智能领域，有益效果在于将预填充阶段和解码阶段分别部署在高性能计算能力和大内存的机器上，均衡负载任务，实现最大化的硬件利用，减少闲置算力，降低整体延迟，提高吞吐量，增强系统的扩展性和容错性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/363608</link>
      <guid isPermaLink="false">https://www.oschina.net/news/363608</guid>
      <pubDate>Fri, 01 Aug 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
