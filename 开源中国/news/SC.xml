<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 27 Aug 2025 02:43:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>vivo 等提出 DiMo-GUI：模态分治 + 动态聚焦，GUI 智能体推理时扩展的新范式</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;作者：vivo 互联网算法团队&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#40a9ff"&gt;&lt;strong&gt;本文入选 EMNLP 2025 Main Conference&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;EMNLP 会议&lt;/strong&gt;全称为 Conference on Empirical Methods in Natural Language Processing，由国际计算语言学协会 ACL 举办，是自然语言处理和人工智能领域最重要的学术会议之一。EMNLP 2025 会议共有 8174 篇投稿，Main Conference 接收率仅为 22.16%。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//53e017ae0673a706f87b381b014e1ca6.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;项目主页：&lt;/p&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fxie.infoq.cn%2Flink%3Ftarget%3Dhttps%253A%252F%252Fgithub.com%252Fvivo%252FDiMo-GUI" rel="nofollow" target="_blank"&gt;https://github.com/vivo/DiMo-GUI&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;本文介绍了一种无需额外训练的 GUI 定位框架 DiMo-GUI，针对多模态大语言模型（MLLMs）在复杂图形用户界面（GUI）定位任务中的挑战，通过动态视觉推理与模态感知优化显著提升性能。DiMo-GUI 采用逐级缩放的动态定位机制，迭代裁剪聚焦目标区域，减少视觉冗余；同时分离文本与图标模态，独立推理后结合指令评估确定最终目标，有效平衡多模态处理能力。在 GUI 定位任务最新的基准数据集上，DiMo-GUI 相较基线展现显著性能提升。作为即插即用框架，DiMo-GUI 适用于网页导航、移动应用自动化等场景，未来可通过回溯机制进一步提升鲁棒性。&lt;/p&gt; 
 &lt;p style="margin-left:0; margin-right:0"&gt;该工作由 vivo 互联网算法团队、加州大学默塞德分校、昆士兰大学共同完成。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、引言&lt;/h1&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;随着&lt;strong&gt;图形用户界面（Graphical User Interface, GUI）&lt;/strong&gt;在自动化导航和操作系统控制等领域的广泛应用，基于自然语言查询的 &lt;strong&gt;GUI 定位（GUI Grounding）&lt;/strong&gt;成为&lt;strong&gt;多模态大语言模型（multimodal large language models, MLLMs）&lt;/strong&gt;的重要研究方向。然而，GUI 环境的视觉复杂性、语言歧义以及空间杂乱等问题为精准定位带来了显著挑战。&lt;/p&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;本文基于最新研究《DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning》，介绍了一种无需额外训练的 GUI 定位框架——&lt;strong&gt;DiMo-GUI&lt;/strong&gt;，通过动态视觉推理和模态感知优化显著提升了多模态大模型在复杂 GUI 环境中的定位性能，推动了&lt;strong&gt;推理时扩展（test-time scaling）&lt;/strong&gt;在该领域的发展。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//0dc3cd4bfdb7f8a14c2a2fde07e79ed9.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;日常生活中，我们与电脑、手机的交互离不开图形用户界面。小到点赞、大到数据分析，我们都希望 AI 能像人一样，理解屏幕上的每一个按钮、每一段文字，并准确执行指令。然而，对于飞速发展中的多模态大模型来说，这却是前所未有的艰巨挑战。在一个复杂的 App、网页或桌面软件中，用户可能随手一句「点击开始播放」，但对于 AI 来说，准确找到这个指令对应的图标/按钮并不简单：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;模态混杂&lt;/strong&gt;：用户界面同时包含文本、图标、背景、装饰性元素等，干扰多；并且大多数 VLM 对文字理解更强，图标处理却弱，造成严重偏差；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;冗余信息&lt;/strong&gt;：高分辨率 UI 中，重要区域可能只占整体的几十分之一，模型容易定位错误区域。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;研究发现，传统方法如基于文本推理或单次视觉定位的管道在高分辨率、视觉拥挤的 GUI 中表现不佳。例如在最新的 ScreenSpot-Pro 数据集上，大多数通用模型如 GPT-4o, Qwen2-VL 等只有 1% 左右的正确率， 即使是针对于 GUI 定位任务的 ShowUI, Aria-UI 等智能体也只有 10% 左右的正确率。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、关键改进：模态分离 + 动态定位&lt;/h1&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;从上述问题出发，该研究推出零训练成本的 DiMo-GUI，通过模态感知的视觉推理推进训练时扩展，显著提升多模态大模型的图形界面（GUI）理解能力。主要的改进方式包括以下两点：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;动态视觉定位&lt;/strong&gt;：DiMo-GUI 采用逐级缩放机制，从粗略预测开始，基于初始座标生成候选焦点区域，并通过迭代裁剪逐步聚焦目标。例如，首次推理后，模型以预测座标为中心裁剪半个图像大小的区域作为下一轮输入，显著减少视觉冗余。动态迭代机制根据前后预测的座标距离（小于图像对角线六分之一时停止）实现自适应停止，避免「过度思考」。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;模态感知优化&lt;/strong&gt;：DiMo-GUI 将 GUI 元素分为文本和图标两类，分别进行独立的定位推理，生成文本座标（C_text）和图标座标（C_icon）。随后，模型结合原始指令和全分辨率图像评估两个候选座标，确定最终目标 （C*），有效平衡文本和图标的处理能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;这样的方式推动了&lt;strong&gt;推理时拓展（Test-time Scaling）&lt;/strong&gt;在 GUI 定位这一领域的发展，提供了新的思路和方式。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//e83f73873fbad7e248e1da405b99f189.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、实验结果：无需训练和任何额外数据，只在推理阶段就可以大幅提升性能&lt;/h1&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//b3d3d49204e1faa771ec0ad0791dea74.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;团队在最新的高分辨率 GUI 数据集 ScreenSpot-Pro 上验证发现：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;DiMo-GUI 可以作为即插即用的框架大幅提升多个 GUI 模型的性能。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;其中 OS-Atlas-7B 在引入 DiMo-GUI 之后获得了超过两倍的指标提升（18.9% -- 49.7%）, UGround-7B 和 UGround-V1-7B 也均获得了超过 10% 的指标提升。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;在相对简单的 ScreenSpot 数据集上，DiMo-GUI 同样可以提升多个模型的性能。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//92892c7de106ba9aac72c1532918459f.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;定性结果表示，模型加入 DiMo-GUI 之后可以通过动态定位逐步逼近正确结果。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img src="https://oscimg.oschina.net/oscnet//b763f01354805dae541a9ab9898a0ae1.png" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、总结&lt;/h1&gt; 
&lt;p style="color:#303030; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;DiMo-GUI&lt;/strong&gt;&amp;nbsp;提供了一种高效、通用且无需训练的 &lt;strong&gt;GUI 定位框架&lt;/strong&gt;，通过动态视觉推理和模态感知优化显著提升了多模态大语言模型在复杂 GUI 环境中的表现。其&lt;strong&gt;「即插即用」&lt;/strong&gt;特性使其可无缝集成到现有 &lt;strong&gt;GUI Agent &lt;/strong&gt;中，适用于网页导航、移动应用自动化等场景。未来研究可探索引入回溯机制以纠正早期错误，进一步提升定位鲁棒性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18689577</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18689577</guid>
      <pubDate>Wed, 27 Aug 2025 02:37:52 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>谷歌发布新图像生成模型 nano banana</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fintroducing-gemini-2-5-flash-image%2F" target="_blank"&gt;发布&lt;/a&gt;了其最先进的图像生成与编辑模型——Gemini 2.5 Flash Image（又名 nano banana）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9cb4376ea1cc064051cdbcd5e04a019d086.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-cd68bfaad4042c2de322bf1198b1e09f449.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;据官方介绍，Gemini 2.5 Flash Image 的主要特点包括下面几点：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;充分保持角色的一致性：它可以轻松地将同一个角色置于不同的环境中，或者从多个角度展示同一款产品，同时完美地保持其核心主体不变。&lt;/li&gt; 
 &lt;li&gt;基于提示的图片编辑：允许用户通过简单的自然语言指令，对图片进行精准的局部修改 。&lt;/li&gt; 
 &lt;li&gt;利用 Gemini 的现实世界知识：模型可借助 Gemini 强大的世界知识库，让图像生成变得更加「智能」。&lt;/li&gt; 
 &lt;li&gt;多幅图像融合：可以将一张图片中的物体「放」进另一张图片的场景里，整个过程只需一条提示指令就能完成。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;性能表现上，Gemini 2.5 Flash Image 在多项基准测试上均为第一名，超越 OpenAI ChatGPT 4o（GPT Image 1 high）、Qwen Image Edit 等模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfee07407ab38e2b001fd0dbe895d36f242.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;关于调用 API，具体的定价是每百万输出 token 30 美元，官方介绍，生成一张图片大约消耗 1290 个输出 token，也就是说，每张图片的成本约为 0.039 美元，换算下来人民币不到 3 毛钱。&lt;/p&gt; 
&lt;p&gt;目前，Gemini 2.5 Flash Image 已经可以通过 Gemini APP、Gemini API、Google AI Studio 和 Vertex AI 进行访问。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368669/google-gemini-2-5-flash-image</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368669/google-gemini-2-5-flash-image</guid>
      <pubDate>Wed, 27 Aug 2025 02:21:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>苹果内部正探讨收购 Mistral 和 Perlextity 可能性</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，苹果公司内部已就收购法国人工智能初创公司 Mistral 以及美国的 Perplexity 展开讨论。这一举措旨在增强其人工智能能力，以应对谷歌和三星等竞争对手的领先优势。&lt;/p&gt; 
&lt;p&gt;此前，苹果首席执行官蒂姆・库克在上个月暗示，公司对大规模人工智能相关收购持开放态度，以加速其人工智能发展路线图，这与苹果以往在并购方面的保守姿态有所不同。Mistral 在去年 B 轮融资后估值超过 60 亿美元，本月有报道称该公司正在洽谈以 100 亿美元估值筹集 10 亿美元资金。今年早些时候，彭博社也曾报道，苹果高管内部讨论过对 Perplexity 的潜在收购意向。&lt;/p&gt; 
&lt;p&gt;据《The Information》报道，苹果服务业务主管埃迪・库伊是收购人工智能公司以增强苹果产品实力的主要倡导者，他曾提议收购 Netflix 和特斯拉，但均被库克否决。而软件业务主管克雷格・费德里吉则对大规模人工智能收购持谨慎态度，他认为苹果有能力内部构建人工智能技术。&lt;/p&gt; 
&lt;p&gt;目前，苹果对这两起潜在收购仍存顾虑，因其可能涉及巨额资金，而苹果历史上极少有超亿美元的收购交易。若联邦裁决终止苹果与谷歌 200 亿美元的默认搜索引擎合作，苹果或更有动力收购人工智能搜索初创公司填补空缺。&lt;/p&gt; 
&lt;p&gt;截至目前，苹果、Mistral 和 Perplexity 均未对此置评。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368665</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368665</guid>
      <pubDate>Wed, 27 Aug 2025 02:13:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Opera 二季度营收同比增长 30%，AI 生态开启新一轮增长周期</title>
      <description/>
      <link>https://www.oschina.net/news/368662</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368662</guid>
      <pubDate>Wed, 27 Aug 2025 02:06:21 GMT</pubDate>
    </item>
    <item>
      <title>阿里开源视频生成模型 Wan2.2-S2V</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;阿里&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5FwE7TvjzDYQabnpnMru6Q" target="_blank"&gt;宣布&lt;/a&gt;开源全新多模态视频生成模型通义万相 Wan2.2-S2V，通过一张静态图片和一段音频，可生成电影级数字人视频，该模型单次生成的视频时长可达分钟级，提升数字人直播、影视制作、AI 教育等行业的视频创作效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="256" src="https://oscimg.oschina.net/oscnet/up-da3fb7fdb3af007528ceab6ea0bd26a6902.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，Wan2.2-S2V 可驱动真人、卡通、动物、数字人等多种类型图片，并支持肖像、半身以及全身等任意画幅，上传一段音频后，模型就能让图片中的主体形象完成说话、唱歌和表演等动作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;通义团队基于通义万相的通用视频生成能力，融合了文本引导的全局运动控制和音频驱动的细粒度局部运动，实现了复杂场景的音频驱动视频生成；引入 AdaIN 和 CrossAttention 两种控制机制，实现了更准确更动态的音频控制效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;生成时长上，Wan2.2-S2V 单次生成的视频时长可达业界领先的分钟级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Wan2.2-S2V 通过层次化帧压缩技术，大幅降低了历史帧的 Token 数量，通过该方式将 motion frames(历史参考帧) 的长度从数帧拓展到 73 帧， 从而实现了稳定的长视频生成效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Wan2.2-S2V 还支持文本控制，输入 Prompt 后还可对视频画面进行控制，实现镜头运动、角色轨迹和实体间互动，让视频主体的运动和背景的变化更丰富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在模型训练上，通义团队构建了超 60 万个片段的音视频数据集，通过混合并行训练进行全参数化训练，充分挖掘了 Wan2.2-S2V 模型的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时通过多分辨率训练、支持模型多分辨率的推理，Wan2.2-S2V 可支持不同分辨率场景的视频生成需求, 如竖屏短视频、横屏影视剧。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368660</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368660</guid>
      <pubDate>Wed, 27 Aug 2025 01:59:21 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国务院：建立健全人工智能开源贡献评价和激励机制，鼓励高校将开源贡献纳入学生学分认证和教师成果认定</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;国务院印发《关于深入实施「人工智能+」行动的意见》。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0826/191343_GXhC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中提到，促进开源生态繁荣。支持人工智能开源社区建设，促进模型、工具、数据集等汇聚开放，培育优质开源项目。建立健全人工智能开源贡献评价和激励机制，鼓励高校将开源贡献纳入学生学分认证和教师成果认定。支持企业、高校、科研机构等探索普惠高效的开源应用新模式。加快构建面向全球开放的开源技术体系和社区生态，发展具有国际影响力的开源项目和开发工具等。&lt;/p&gt; 
&lt;p&gt;原文：&lt;em&gt;https://www.gov.cn/zhengce/content/202508/content_7037861.htm&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368606</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368606</guid>
      <pubDate>Mon, 18 Aug 2025 11:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯游戏发布 AI 工具集 VISVISE，动画制作效率提升 8 倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在近日举行的科隆国际游戏展上，腾讯游戏正式发布了名为 VISVISE 的游戏创作 AI 工具集，该产品旨在大幅提升游戏美术师的工作效率，减少重复性劳动。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据介绍，VISVISE 工具集涵盖动画制作、模型制作、数字资产管理和智能 NPC 四个核心领域。其中最受关注的是 MotionBlink 动画生成工具，该工具能够根据用户输入的关键帧自动补全中间帧，快速生成完整的动画序列。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;腾讯游戏技术团队表示，使用 MotionBlink 工具，原本需要数天时间制作的 10 秒动画，现在仅需 4 秒即可完成 200 帧动画的生成，效率提升达到 8 倍。该工具不仅能显著减轻动画师的工作负担，生成的动画质量也能在某些情况下达到光学动作捕捉的水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="211" src="https://oscimg.oschina.net/oscnet/up-66204834e57b0c6dc3f5aaa12b702a8cd61.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;传统动画制作流程中，手动补帧通常占据动画师大部分工作时间。MotionBlink 的推出有效解决了这一痛点。现场体验的用户反馈称，该技术大幅降低了角色动画制作的门槛，为小型开发团队和独立创作者提供了有力的技术支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;除 MotionBlink 外，VISVISE 还包含 GoSkinning 工具，专门用于解决 3D 角色蒙皮制作中的效率问题。传统的蒙皮流程复杂且耗时，而 GoSkinning 通过 AI 技术实现了自动化处理。据测试数据显示，处理一个包含 2 万顶点的 3D 模型，使用该工具仅需 30 秒时间，大幅提升了工作效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="270" src="https://oscimg.oschina.net/oscnet/up-a489a914edc7b41eb74b895cdf1cb3f2679.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;腾讯游戏方面表示，VISVISE 工具集的推出不仅是技术层面的突破，更代表了对整个游戏开发工作流程的重新设计。通过 AI 技术的应用，美术师能够将更多精力投入到创意设计和艺术创作中，而非繁重的技术操作。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;业内专家认为，随着 AI 技术在游戏开发领域的深入应用，传统的内容制作模式正在发生根本性变化。像 VISVISE 这样的工具集有望推动整个游戏行业向更高效、更智能的方向发展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，腾讯游戏尚未公布 VISVISE 工具集的具体发布时间和使用方式，但表示将继续优化相关技术，为游戏开发者提供更完善的 AI 辅助工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368600</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368600</guid>
      <pubDate>Mon, 18 Aug 2025 10:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Chrome 测试新特性：一键设为默认浏览器并固定至任务栏</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌正在测试一项 Chrome 新特性，用户可以在设置页面通过 &lt;strong&gt;「一键操作」&lt;/strong&gt; 将 Chrome 同时设为 &lt;strong&gt;Windows 11 的默认浏览器&lt;/strong&gt; 并 &lt;strong&gt;固定到任务栏上&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c8ad80599c395d70a2597444696015e6f0c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5e646e64658fdffccb2016c1035431da87f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwindowsreport.com%2Fgoogle-preps-one-click-option-to-make-chrome-default-and-pin-it-to-windows-11-taskbar%2F" target="_blank"&gt;根据科技媒体 Windows Report 的报道&lt;/a&gt;，该功能的开发细节已出现在 Chromium 代码库中，按钮文字将改为 「将 Google Chrome 设为默认浏览器并固定到任务栏」（&lt;em&gt;「WIP Add option to pin to taskbar in settings.」&amp;nbsp;&lt;/em&gt;），且直接整合到设置页面，表明该特性并非短期实验，而是计划长期保留 。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-97e9429156e4e8c29003511c9ae4be43892.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，Mozilla 曾在 Firefox 浏览器的安装阶段短暂测试过类似提示，但未长期保留；相比之下，谷歌将功能深度融入浏览器设置中，未来可能会稳定上线 。&lt;/p&gt; 
&lt;p&gt;此外，该特性的推出可能与欧盟《数字市场法》有关，该法规要求用户在 Windows 上设置非 Edge 浏览器为默认浏览器后，除非用户明确拒绝，系统应自动将其固定到任务栏 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368599</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368599</guid>
      <pubDate>Mon, 18 Aug 2025 10:24:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软发布免费 VM 转换工具，支持 VMware 迁移至 Hyper-V</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软近日推出免费公测版「VM 转换工具」，可将 VMware 虚拟机迁移至基于 Hyper-V 的 Windows Server。该工具支持一次迁移最多 10 台虚拟机，兼容 BIOS 与 UEFI 系统，并保留引导配置。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c10d73d298129ec7f5bdbdaeaddfad87663.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该工具面向因合规或数据治理要求而倾向于本地部署的企业用户，现已发布于 Windows 管理中心。作为扩展安装程序，该工具允许在不借助额外代理程序的情况下，完成 VMware 虚拟机向 Hyper-V 环境的迁移。&lt;/p&gt; 
&lt;p&gt;迁移过程分为多个阶段：首先连接到现有虚拟化环境，并预检查关键组件和配置，确保迁移条件达标，若发现问题需由 IT 管理员手动修复。随后，工具利用变更块跟踪（CBT）技术创建源虚拟机的副本，并保持其正常运行。&lt;/p&gt; 
&lt;p&gt;在用户确认关机后，工具进行第二次复制，将首次复制以来产生的增量数据同步到目标主机，确保迁移过程无中断，减少停机时间，并在切换完成后保持系统一致性。&lt;/p&gt; 
&lt;p&gt;该工具一次可迁移多达 10 台虚拟机，并根据固件类型自动映射：BIOS 系统映射为 Hyper-V 的第一代（Generation 1），UEFI 系统映射为第二代（Generation 2），且完整保留引导配置。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;https://learn.microsoft.com/zh-cn/windows-server/manage/windows-admin-center/use/migrate-vmware-to-hyper-v&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368595</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368595</guid>
      <pubDate>Mon, 18 Aug 2025 10:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Docker Desktop 修复高危漏洞 CVE-2025-9074</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Docker 近日发布更新，修复了 Docker Desktop 在 Windows 10/11 和 macOS 版本中存在的一处高危漏洞。该漏洞编号为 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cve.org%2FCVERecord%3Fid%3DCVE-2025-9074" target="_blank"&gt;CVE-2025-9074&lt;/a&gt;，评分高达 9.3/10，利用难度低，风险极高。官方已在 Docker Desktop v4.44.3 中完成修复，建议所有用户立即升级。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0826/180337_8exE_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;问题源于容器可以在无需身份验证的情况下连接至 192.168.65.7:2375 的 Docker Engine API。攻击者可借此绕过隔离机制，直接访问宿主机文件系统。在验证实验中，研究团队证明了任何容器只需发起一个 Web 请求，就能触发漏洞并全面控制安装 Docker Desktop 的主机。&lt;/p&gt; 
&lt;p&gt;在 macOS 上，由于系统对应用有额外的文件系统限制，漏洞主要影响 Docker Desktop 的控制权，进一步攻陷整个系统的难度较大。但在 Windows 10/11 环境下，由于缺乏类似的限制，攻击风险更为严重。&lt;/p&gt; 
&lt;p&gt;值得注意的是，Linux 版 Docker Desktop 不受影响，因为其并未通过 TCP 连接依赖 Docker Engine API。要避免风险，用户需尽快升级至 v4.44.3 版本。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://docs.docker.com/desktop/release-notes/#4443&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368593</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368593</guid>
      <pubDate>Mon, 18 Aug 2025 10:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国务院发布《「人工智能+」行动意见》 2035 年迈入智能社会</title>
      <description/>
      <link>https://www.oschina.net/news/368591</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368591</guid>
      <pubDate>Mon, 18 Aug 2025 09:58:00 GMT</pubDate>
    </item>
    <item>
      <title>百度发布 AI 智能搜索工具「梯子 AI 」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;百度旗下的 AI 搜索 App「Tizzy.ai」完成了前期的测试，正式更名为「梯子 AI」。这款应用发布于 8 月 10 日，当时名称仍为「Tizzy.ai」，直到 8 月 21 日更新后改名为「梯子 AI」，版本号也直接从 1.0.0 跳到 1.2.0（官网 https://tizzy.baidu.com/）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0bf83789061d58fbed4ca9fa0cccf815533.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;「梯子 AI」定位为智能搜索助手，依托多个大模型能力开发而成，主打无广告智能搜索，整合深度思考、资源检索及影视娱乐功能（号称海量资源）。&lt;/p&gt; 
&lt;p&gt;应用描述：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;梯子 AI 是百度融合多个大模型能力开发的 AI 智能搜索工具。提供自动思考和深度思考的双模式智能引擎，全网分析给出精准答案；打造极简搜索体验，搜网址、搜天气、搜攻略等输入问题直达结果；提供热门丰富的海量短剧，无广告、无会员、流畅播放，打造极致观剧体验。&lt;/p&gt; 
 &lt;p&gt;梯子 AI 能帮你做什么&lt;/p&gt; 
 &lt;p&gt;【AI 双模智能搜索】支持自动思考与深度思考的双模式智能引擎，通过全网信息精准分析，结合你的偏好提供个性化答案，搜索结果更高效、更精准。&lt;/p&gt; 
 &lt;p&gt;【极简的交互体验】简洁搜索框，输入问题直达答案，没有任何推广信息，提供极致的搜索体验。&lt;/p&gt; 
 &lt;p&gt;【丰富的短剧生态】涵盖都市热血、玄幻仙侠、逆袭反转、穿越重生等多种类型，拥有丰富的热门短剧，畅看无阻。&lt;/p&gt; 
 &lt;p&gt;【沉浸式观剧体验】观看短剧过程无广告、无会员、加速缓冲，提供边看边搜，重新设计每个细节，打造极致的观剧体验。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368590</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368590</guid>
      <pubDate>Mon, 18 Aug 2025 09:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软旗下开源文档数据库 Do​​cumentDB 加入 Linux 基金会</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DocumentDB 是微软基于 PostgreSQL 构建的兼容 MongoDB 的文档数据库，目前已用于支持基于 vCore 的 Azure Cosmos DB for MongoDB 实例。今年年初，微软开源了 DocumentDB，因为它相信一个完全开源、兼容 MongoDB 的文档数据库能够实现。&lt;/p&gt; 
&lt;p&gt;出乎所有人的意料，微软竟然以最为宽松的 MIT 许可证&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevblogs.microsoft.com%2Fcosmosdb%2Fdocumentdb-is-gaining-momentum-in-the-open-source-database-world%2F" target="_blank"&gt;将其开源&lt;/a&gt;，该许可证允许开发者和组织将其无限制地集成到他们的解决方案中。DocumentDB 项目开源一周内，就获得了 1000 个 GitHub 星标、近 50 个 fork 以及多个 Pull 请求。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fe1c0989daaba4a35b2f8e816475b799172.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;DocumentDB 因其原生实现的面向文档的 NoSQL 数据库而广受开发者欢迎，它基于 PostgreSQL 框架，支持对 BSON（二进制 JSON）数据类型进行 CRUD（创建、读取、更新、删除）操作。此外，DocumentDB 还支持全文搜索、地理空间查询和矢量搜索。&lt;/p&gt; 
&lt;p&gt;今天，微软&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.microsoft.com%2Fblog%2F2025%2F08%2F25%2Fdocumentdb-joins-the-linux-foundation%2F" target="_blank"&gt;宣布&lt;/a&gt;DocumentDB 将成为 Linux 基金会的一部分。微软希望此举能够为 NoSQL 数据库创建一个开放标准。微软表示，它致力于与 MongoDB 驱动程序 100% 兼容，以确保文档数据库生态系统蓬勃发展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0826/174814_Mz6m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Azure Cosmos DB 副总裁 Kirill Gavrylyuk 表示：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;加入 Linux 基金会将为 DocumentDB 创建一个独立的身份，并为任何数据库提供商提供一个渠道来为我们的使命做出贡献。此外，Postgres 继续被誉为最受欢迎的平台，并将继续作为项目的支柱。对于 DocumentDB 而言，开源 Postgres 将比 Postgres 的分支版本更受青睐。Linux 基金会将确保 DocumentDB 遵守这些管理原则，以保持一致性。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Linux 基金会对 DocumentDB 项目的治理将确保供应商中立，并维护 DocumentDB 始终坚持 PostgreSQL 优先的承诺。Linux 基金会执行董事 Jim Zemlin 对 DocumentDB 加入基金会感到非常兴奋。他&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-welcomes-documentdb-to-advance-open-developer-first-nosql-innovation" target="_blank"&gt;表示&lt;/a&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;DocumentDB 填补了文档数据库生态系统中的一个关键空白，吸引了众多贡献者、用户和拥护者。更令人兴奋的是，它为基于文档的应用程序提供了一个开放标准，就像 SQL 为关系数据库所做的那样。通过加入 Linux 基金会，DocumentDB 确保了其开源未来，并助力 NoSQL 数据库标准和社区驱动的创新开辟了一条新道路。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;通过在 Linux 基金会的治理下，DocumentDB 能够确保其开源未来并推动社区创新。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368589/ms-documentdb-joins-the-linux-foundation</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368589/ms-documentdb-joins-the-linux-foundation</guid>
      <pubDate>Mon, 18 Aug 2025 09:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Fenster - 最精简的跨平台 GUI 库</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Fenster /ˈfɛnstɐ/——德语中「window」的意思。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这个库提供了最简洁、最实用的跨平台 2D 画布显示方式。只需几行代码，你就能实现跨平台的键盘/鼠标输入和音频播放。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;具有指定大小和标题的单一应用程序窗口。&lt;/li&gt;
&lt;li&gt;应用程序生命周期和系统事件均自动处理。&lt;/li&gt;
&lt;li&gt;最小 24 位 RGB 帧缓冲区。&lt;/li&gt;
&lt;li&gt;跨平台键盘事件（键码）。&lt;/li&gt;
&lt;li&gt;跨平台鼠标事件（X/Y + 鼠标点击）。&lt;/li&gt;
&lt;li&gt;跨平台计时器具有稳定的 FPS 速率。&lt;/li&gt;
&lt;li&gt;跨平台音频播放（WinMM、CoreAudio、ALSA）。&lt;/li&gt;
&lt;li&gt;简单的轮询 API，无需回调或多线程（如 Arduino/Processing）。&lt;/li&gt;
&lt;li&gt;一个约 300LOC 的 C99 头文件，易于理解和扩展。&lt;/li&gt;
&lt;li&gt;Go 绑定（&lt;code&gt;import "github.com/zserge/fenster"&lt;/code&gt;，参见&amp;nbsp;&lt;a href="https://pkg.go.dev/github.com/zserge/fenster"&gt;godoc&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;Zig 绑定（参见&amp;nbsp;&lt;a href="https://github.com/zserge/fenster/blob/main/examples/minimal-zig"&gt;examples/minimal-zig&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;Lua 绑定（参见&amp;nbsp;&lt;a href="https://github.com/jonasgeiler/lua-fenster"&gt;https://github.com/jonasgeiler/lua-fenster&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zserge/fenster/blob/main/examples/doom-c"&gt;可以运行 Doom&lt;/a&gt;！&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;strong&gt;示例&lt;/strong&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#59636e"&gt;// main.c&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span style="color:#cf222e"&gt;#include&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;"fenster.h"&lt;/span&gt;&lt;/span&gt;
&lt;span&gt;&lt;span style="color:#cf222e"&gt;#define&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;W&lt;/span&gt;&lt;/span&gt; 320
&lt;span&gt;&lt;span style="color:#cf222e"&gt;#define&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;H&lt;/span&gt;&lt;/span&gt; 240
&lt;span&gt;&lt;span style="color:#1f2328"&gt;int&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#6639ba"&gt;main&lt;/span&gt;&lt;/span&gt;() {
  &lt;span&gt;&lt;span style="color:#1f2328"&gt;uint32_t&lt;/span&gt;&lt;/span&gt; &lt;span&gt;buf&lt;/span&gt;[&lt;span&gt;&lt;span style="color:#0550ae"&gt;W&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;*&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;H&lt;/span&gt;&lt;/span&gt;];
  &lt;span&gt;&lt;span style="color:#cf222e"&gt;struct&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#1f2328"&gt;fenster&lt;/span&gt;&lt;/span&gt; &lt;span&gt;f&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; { .&lt;span&gt;&lt;span style="color:#0550ae"&gt;title&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0a3069"&gt;"hello"&lt;/span&gt;&lt;/span&gt;, .&lt;span&gt;&lt;span style="color:#0550ae"&gt;width&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;W&lt;/span&gt;&lt;/span&gt;, .&lt;span&gt;&lt;span style="color:#0550ae"&gt;height&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;H&lt;/span&gt;&lt;/span&gt;, .&lt;span&gt;&lt;span style="color:#0550ae"&gt;buf&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;buf&lt;/span&gt; };
  &lt;span&gt;&lt;span style="color:#6639ba"&gt;fenster_open&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;amp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;);
  &lt;span&gt;&lt;span style="color:#cf222e"&gt;while&lt;/span&gt;&lt;/span&gt; (&lt;span&gt;&lt;span style="color:#6639ba"&gt;fenster_loop&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;amp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;) &lt;span&gt;&lt;span style="color:#0550ae"&gt;==&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;0&lt;/span&gt;&lt;/span&gt;) {
    &lt;span&gt;&lt;span style="color:#cf222e"&gt;for&lt;/span&gt;&lt;/span&gt; (&lt;span&gt;&lt;span style="color:#1f2328"&gt;int&lt;/span&gt;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;0&lt;/span&gt;&lt;/span&gt;; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;W&lt;/span&gt;&lt;/span&gt;; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;&lt;span style="color:#0550ae"&gt;++&lt;/span&gt;&lt;/span&gt;) {
      &lt;span&gt;&lt;span style="color:#cf222e"&gt;for&lt;/span&gt;&lt;/span&gt; (&lt;span&gt;&lt;span style="color:#1f2328"&gt;int&lt;/span&gt;&lt;/span&gt; &lt;span&gt;j&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;0&lt;/span&gt;&lt;/span&gt;; &lt;span&gt;j&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;H&lt;/span&gt;&lt;/span&gt;; &lt;span&gt;j&lt;/span&gt;&lt;span&gt;&lt;span style="color:#0550ae"&gt;++&lt;/span&gt;&lt;/span&gt;) {
        &lt;span&gt;&lt;span style="color:#6639ba"&gt;fenster_pixel&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;amp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;, &lt;span&gt;i&lt;/span&gt;, &lt;span&gt;j&lt;/span&gt;) &lt;span&gt;&lt;span style="color:#0550ae"&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#6639ba"&gt;rand&lt;/span&gt;&lt;/span&gt;();
      }
    }
  }
  &lt;span&gt;&lt;span style="color:#6639ba"&gt;fenster_close&lt;/span&gt;&lt;/span&gt;(&lt;span&gt;&lt;span style="color:#0550ae"&gt;&amp;amp;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;f&lt;/span&gt;);
  &lt;span&gt;&lt;span style="color:#cf222e"&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style="color:#0550ae"&gt;0&lt;/span&gt;&lt;/span&gt;;
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;编译并运行：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span style="background-color:#f6f8fa"&gt;&lt;code&gt;# Linux
cc main.c -lX11 -lasound -o main &amp;amp;&amp;amp; ./main
# macOS
cc main.c -framework Cocoa -framework AudioToolbox -o main &amp;amp;&amp;amp; ./main
# windows
cc main.c -lgdi32 -lwinmm -o main.exe &amp;amp;&amp;amp; main.exe&lt;/code&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/fenster</link>
      <guid isPermaLink="false">https://www.oschina.net/p/fenster</guid>
      <pubDate>Mon, 18 Aug 2025 09:46:00 GMT</pubDate>
    </item>
    <item>
      <title>Firefox 带来 PWA 实验性实现</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Moziilla 宣布为 Firefox Windows 用户在 142 版本中带来一个新的实验性功能：渐进式 Web 应用（PWA）。该功能自 2018 年 Chrome 70 版本以来，一直就存在于桌面版 Chrome 中。&lt;/p&gt; 
&lt;p&gt;PWA 在 Firefox 中的发展历程相当坎坷，早在 Firefox 73（Nightly）时期，Mozilla 就尝试过一个名为 「Site-Specific Browsers（SSB）」 的 PWA 实验性实现，但这一功能从未完全开发完成，并在 2021 年 1 月被 Mozilla 移除。&lt;/p&gt; 
&lt;p&gt;当时，Mozilla 解释说，该功能存在 「多个已知问题」，并且保留它会占用 Firefox 团队在漏洞排查上的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月，Mozilla 发布了 Firefox Nightly 141 版本，重新加入了这一功能，并将其命名为 「Taskbar Tabs」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7e987d26d0238edd293a1f64eb53f150ab1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8d3309d0755d9440b38d337973c2381c7ca.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Firefox 产品经理 David Rubino 解释说，这一新的实现方式在设计上有所不同，Web 应用将保留 Firefox 的主要工具栏，包括地址栏、扩展程序和书签，以确保用户仍然感觉自己是在浏览器中。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368586</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368586</guid>
      <pubDate>Mon, 18 Aug 2025 09:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>书生发布 InternVL 3.5 最新视觉全系列模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;书生发布了最新的视觉模型 InternVL 3.5 全系列模型，从 1B 到 241B 共 8 个尺寸。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7fb0fd8578a3037d507a1059e08223c437f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;根据评测结果，书生 3.5 最高尺寸 241B 在视觉模型里的表现仅次于商业版的 GPT-5 和 Gemini 2.5 Pro。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-595c729823f646e6dbcd8b05be0bb57277f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-13518e6aab25fa7275c2777b42debccf8de.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;所有模型均已发布到 Hugging Face&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://huggingface.co/collections/OpenGVLab/internvl35-68ac87bd52ebe953485927fb&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;该模型的技术亮点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cascade Reinforcement Learning（Cascade RL）&lt;/strong&gt;：采用「离线 RL + 在线 RL」两阶段策略，实现更加稳健收敛和精细对齐，从而显著增强模型的推理能力，在 MMMU 和 MathVista 等任务上表现提升明显。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visual Resolution Router（ViR）&lt;/strong&gt;：动态调整视觉 token 的分辨率，兼顾性能与效率，使视觉理解更加灵活高效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Decoupled Vision-Language Deployment（DvD）&lt;/strong&gt;：将视觉编码器与语言模型分开部署至不同 GPU，有效平衡资源负载，提升推理速度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在推理性能提升高达 16.0%（整体推理任务中），同时相较于 InternVL3，实现了&amp;nbsp;&lt;strong&gt;4.05× 的推理速度加速。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368585</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368585</guid>
      <pubDate>Mon, 18 Aug 2025 09:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯开源 tRPC-Agent-Go：让 Go 开发者轻松构建智能 AI 应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯 tRPC 团队之前开源了 A2A 开发框架 tRPC-A2A-Go 和 MCP 开发框架 tRPC-MCP-Go，现在进一步&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrUcJ_9D1gVrdJUmzZP63zQ" target="_blank"&gt;推出&lt;/a&gt;&amp;nbsp;tRPC-Agent-Go&amp;nbsp;开发框架，实现 Go 语言 AI 生态开发框架的闭环。&lt;/p&gt; 
&lt;p&gt;公告称，当前主流 Agent 框架（AutoGen、CrewAI 、Agno、ADK 等）大部分都是基于 Python，而&amp;nbsp;Go 在微服务、并发与部署方面有天然优势，Go 在腾讯内部也有大规模应用，业界基于 Go 语言的 Agent 框架较少，大部分都是编排式的 workflow 框架，缺少真正的「去中心化、可协作、能涌现」的自主多 Agent 能力。tRPC-Agent-Go 直接利用 Go 的高并发与 tRPC 生态，把 LLM 的推理、协商和自适应性带到 Go 场景，满足复杂业务对「智能+性能」的双重需求。&lt;/p&gt; 
&lt;p&gt;tRPC-Agent-Go 采用模块化架构设计，由多个核心组件组成，组件都可插拔，通过事件驱动机制实现组件间的解耦通信，支持 callback 插入自定义逻辑：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Agent：核心执行单元，负责处理用户输入并生成响应&lt;/li&gt; 
 &lt;li&gt;Runner：Agent 的执行器，负责管理执行流程，串联 Session/Memory Service 等能力&lt;/li&gt; 
 &lt;li&gt;Model：支持多种 LLM 模型（OpenAI、DeepSeek 等）&lt;/li&gt; 
 &lt;li&gt;Tool：提供各种工具能力（Function、MCP、DuckDuckGo 等）&lt;/li&gt; 
 &lt;li&gt;Session：管理用户会话状态和事件&lt;/li&gt; 
 &lt;li&gt;Memory：记录用户的长期记忆和个性化信息&lt;/li&gt; 
 &lt;li&gt;Knowledge：实现 RAG 知识检索能力&lt;/li&gt; 
 &lt;li&gt;Planner：提供 Agent 的计划和推理能力&lt;/li&gt; 
 &lt;li&gt;CodeExecutor：提供 Agent 代码执行能力，支持 Local，Container 等模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="357" src="https://oscimg.oschina.net/oscnet/up-95bdd4a5582b1c5df0538b32ab59b27150e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="812" src="https://oscimg.oschina.net/oscnet/up-8a1ddd94dd74790efd81c8792dd5ce17680.webp" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;核心特点&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;多样化 Agent 系统&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLMAgent：基于大语言模型，支持工具调用和推理&lt;/li&gt; 
 &lt;li&gt;ChainAgent：链式执行，支持多步骤任务分解&lt;/li&gt; 
 &lt;li&gt;ParallelAgent：并行处理，支持多专家协作&lt;/li&gt; 
 &lt;li&gt;CycleAgent：循环迭代，支持自我优化&lt;/li&gt; 
 &lt;li&gt;GraphAgent：图工作流，兼容现有编排习惯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;丰富工具生态&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;内置常用工具&lt;/li&gt; 
 &lt;li&gt;支持 Function、MCP 协议等多种扩展方式&lt;/li&gt; 
 &lt;li&gt;灵活的工具组合和调用策略&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;智能会话管理&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 Redis 和内存存储的会话持久化&lt;/li&gt; 
 &lt;li&gt;长期记忆和个性化信息保持&lt;/li&gt; 
 &lt;li&gt;RAG 检索增强生成能力&lt;/li&gt; 
 &lt;li&gt;实时事件驱动架构&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;全链路可观测性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenTelemetry 全链路追踪和性能监控&lt;/li&gt; 
 &lt;li&gt;可视化调试界面和实时监控&lt;/li&gt; 
 &lt;li&gt;结构化日志和错误追踪&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368583</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368583</guid>
      <pubDate>Mon, 18 Aug 2025 09:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>货拉拉开源两款三方库</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;货拉拉开源了两款实用三方库 —— AspectPro Aop Plugin 和 page-spy-harmony，直击应用开发过程中「代码耦合高」「远程调试难」等高频痛点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在复杂的应用开发过程中，日志记录、性能监控、权限校验等功能虽然往往与核心业务逻辑关系不大，但却必不可少，但这些功能的代码散布于代码架构的各个角落。这种现象易导致代码耦合度增高、业务逻辑不够纯粹，不仅降低了代码的可读性，也为后期的维护带来了不小的挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;针对这一典型问题，货拉拉推出了轻量级鸿蒙运行时 hook 框架 AspectPro Aop Plugin，并同步开源其编译时代码修改插件 aspect-pro-plugin，两者配合使用可实现任意代码 hook 操作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;AspectPro Aop Plugin 对齐鸿蒙系统的 AOP 能力，开发者无需关心静态方法限制，即可对如按钮点击事件、链式构造类方法、不可写方法等多类行为进行精准 hook，并灵活更改参数与返回值；而 aspect-pro-plugin 则在编译阶段支持多种代码扫描、替换与导包策略，支持自定义配置规则。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;通过引入 AspectPro Aop Plugin，开发者可将横切逻辑独立封装、与业务代码解耦，从而显著提升代码结构清晰度与维护效率，避免「逻辑混杂」导致的后期维护成本激增问题，提升开发效率与代码质量。这一工具特别适合中大型项目中对代码规范与开发协作要求较高的团队使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;img height="293" src="https://oscimg.oschina.net/oscnet/up-4888079610c92e960fcf7334fe2f467752e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;远程可视化调试解决方案 page-spy-harmony 采用客户端-服务端的架构：在应用中集成一个轻量级的设备端 SDK，该 SDK 会在运行时采集关键数据；同时，开发者可以通过浏览器访问一个功能丰富的 Web 端控制枱，实时接收并可视化展示来自设备端的数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#e6e6e6; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;通过 page-spy-harmony，开发者可以一目了然地远程查看应用的运行时信息，包括详细的日志、网络请求往来以及 AppStorage 中的数据等。这不仅极大地提升了调试效率，还简化了远程协作的流程。无论是团队成员异地协作，还是远程协助用户或测试人员排查问题，page-spy-harmony 都能提供有力支持，加速问题的定位与修复。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368577</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368577</guid>
      <pubDate>Mon, 18 Aug 2025 08:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenZFS 2.3.4 发布：支持 Linux 6.16 内核、引入 zfs rewrite 子命令</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenZFS 2.3.4 已正式发布，最大亮点在于支持 Linux 6.16 内核，以及引入&amp;nbsp;zfs rewrite 子命令。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 支持 Linux 6.16 内核&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OpenZFS 2.3.4 新增对最新 Linux 6.16 稳定内核的支持，而此前 2.3.3 版本仅支持到 6.15。它仍兼容 Linux 4.18 及更高版本，以及 FreeBSD 13.3 及更新版本（包括即将发布的 FreeBSD 15.0）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 引入 &lt;code&gt;zfs rewrite&lt;/code&gt; 子命令&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;新增的 &lt;code&gt;zfs rewrite&lt;/code&gt; 命令允许以原样内容重写指定文件，但可更改其存储位置、压缩方式、校验和、去重策略、镜像副本数等配置参数。相比传统的读写拷贝、发送/接收、重命名等方案，此命令更高效（无需进入用户空间数据拷贝），尤其对 &lt;code&gt;sync=always&lt;/code&gt; 数据集效果显著（无需再写 ZIL），且在数据锁正常范围内可在负载下安全执行，不修改文件的修改时间等元数据。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.其他修复与更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;本次发布还包含一些 FreeBSD 平台的修复、打包方面更新以及其他若干较小的 bug 修复。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;https://github.com/openzfs/zfs/releases/tag/zfs-2.3.4&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/368576</link>
      <guid isPermaLink="false">https://www.oschina.net/news/368576</guid>
      <pubDate>Mon, 18 Aug 2025 08:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>比 Cursor 更快更稳定的 Coding Agent？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;搞了 2 年直播，我也是搞出名堂来了。&lt;/p&gt; 
&lt;p&gt;张宏波说要来我们这里搞直播，聊一聊 Coding Agent。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;张宏波是谁？&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他是编程语言领域的专家，是 OCaml 语言的前核心开发人员，&lt;/span&gt;OCaml 编译器获得过 2023 年 ACM SIGPLAN 编程语言软件奖。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，他还创造了&lt;/span&gt;&lt;span style="color:#000000"&gt;编程语言&lt;/span&gt;&amp;nbsp;&lt;span style="color:#000000"&gt;ReScript，被 Meta、谷歌、育碧、TinyMCE 等多个公司商用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;就这成就，已经值得吹一辈子了吧？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;但张宏波不一样，他觉得很遗憾。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;因为 ReScript 具备相当的技术实力，并且远超一些同行，但是相较于微软的 TypeScript 或者谷歌的 Dart，ReScript 的影响力远没有达到它应有的高度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;他想要打造的，是&lt;span style="background-color:#ffffff; color:#222222"&gt;一款现象级的编程语言&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;一直以来，张宏波都不甘平庸。就连他当初考到&lt;span style="background-color:#ffffff; color:#222222"&gt;清华大学电气工程及自动化系&lt;/span&gt;，都说是因为高考发挥失常才被调剂过去的。他真正想进的，是他一年后&lt;span style="background-color:#ffffff; color:#222222"&gt;成功转入的清华电子系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;所以在 2022 年，张宏波结束了他在 Meta 的 5 年职业生涯，来到了&lt;/span&gt;&lt;span&gt;粤港澳大湾区数字经济研究院（&lt;/span&gt;IDEA 研究院&lt;span&gt;）&lt;/span&gt;组建了基础软件中心，从零开始创立了 MoonBit。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这里插一句，张宏波加入 IDEA 研究院，源于沈向洋（Harry Shum）抛出的橄榄枝。&lt;/p&gt; 
&lt;p&gt;早年在曾在微软亚洲研究院实习时，沈向洋就是他的导师，并在实习结束后力荐张宏波前往美国继续深造。当然，张宏波之后也踏上了前往美国读博的旅程（后来还有中止读博一事今天且按下不表）。&lt;/p&gt; 
&lt;p&gt;彼时，沈向洋已经是粤港澳大湾区数字经济研究院创始人及理事长。张宏波也从当年的学生，成长为独当一面的顶尖专家。&lt;/p&gt; 
&lt;p&gt;这就不得不感叹，命运的回响如此奇妙。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;说回张宏波一手创立的 MoonBit——一个专门为 AI&amp;nbsp; 设计的开源编程语言。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;换句话来说，这个编程语言的目的，是让 AI 用起来最得心应手、最不容易出错。&lt;/p&gt; 
&lt;p&gt;现在，大家都在用 AI Coding 工具来写代码，但不论用的是 Java，还是 Python，亦或是 Rust 等其他主流编程语言，基本上已经定型了，只能在现有基础上「嫁接」AI 能力。所以，最终 AI 确实是把代码写出来了，但问题是怎么维护呢？&lt;/p&gt; 
&lt;p&gt;MoonBit 就不一样。它的语法、类型系统、错误处理机制等，在设计之初就深度考虑了如何让 AI 更容易地理解、生成和验证代码，从而保证了代码的可维护性。&lt;/p&gt; 
&lt;p&gt;就连&amp;nbsp;&lt;span style="background-color:#ffffff; color:#222222"&gt;JavaScript 标准委员会联席主席 Rob Palmer、Vue 和 Vite 之父尤雨溪等知名技术专家都屡次公开夸赞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最近，张宏波还带领团队，开发了一个 Coding Agent——MoonBit Pilot。据说比&lt;/strong&gt;&lt;span style="background-color:#ffffff; color:#000000"&gt;&amp;nbsp;Cursor 还更快、更稳定！&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-4a9f06ab1db5e6ac343b22234959e7d805f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这是他&lt;span style="background-color:#ffffff; color:#333333"&gt;从底层设计的一整套 AI 原生的开发者工具，包括编程语言的设计、编译器、调试器、包管理等，并在各个环节给予大模型最有效的反馈。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;也许你已经发现了，跟&lt;/span&gt;编程语言&amp;nbsp;MoonBit&amp;nbsp; 一样，也是 AI 原生。&lt;/p&gt; 
&lt;p&gt;所以，MoonBit Pilot 不仅可以生成所有编程语言的代码，而且针对 MoonBit 编程语言的优势极大。毕竟，还有谁能比自己人更清楚 MoonBit 嘛！&lt;/p&gt; 
&lt;p&gt;总之，不管是&amp;nbsp;MoonBit ，还是&amp;nbsp;MoonBit Pilot ，听来都不简单。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;现在，张宏波用 MoonBit Pilot 等 AI 工具写 MoonBit。过去一周，他用闲暇时间写了 309 个高质量的 Commits，实现了相当于过去一个优秀程序员一年的工作量。&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img height="646" src="https://oscimg.oschina.net/oscnet/up-2658c358aed8eef15d5387c10698412aeeb.png" width="500" referrerpolicy="no-referrer"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;他是怎么做到的？&lt;strong&gt;8 月 29 日晚，&lt;/strong&gt;IDEA 研究院基础软件中心首席科学家、MoonBit 团队负责人张宏波，将做客开源中国《技术领航》栏目直播间：&lt;/p&gt; 
&lt;div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     讲解 AI 原生编程语言 —— MoonBit 的底层设计 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Coding Agent —— MoonBit Pilot 的最新进展 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     实操演示：MoonBit Pilot 零干预辅助完成软件库 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     大规模代码重构关键：原生语义查找+分段编码 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Q&amp;amp;A 环节 （15min） 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   我们还会在直播间，随机抽取 5 名直播间评论区互动的幸运用户，赠送网页版 MoonBit Pilot&amp;nbsp;权限哦~ 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt; 
  &lt;br&gt; &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img height="8795" src="https://oscimg.oschina.net/oscnet/up-6a5dbdd0dde7efa92a215e410cc36f17215.jpg" width="3402" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;福袋抽奖：直播中将有 5 轮抽奖，参与就有机会获得 OSC T 恤、马建仓蛇年公仔（限量版）、代码圣杯、马克杯、冰箱贴、前沿技术书籍等。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，基本上每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0px; margin-right:0px; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18689590</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18689590</guid>
      <pubDate>Mon, 18 Aug 2025 08:34:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
