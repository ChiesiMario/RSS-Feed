<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 14 Aug 2025 07:44:03 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>蚂蚁集团开源新一代 JVM 即时编译器 Jeandle</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;蚂蚁集团&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYaMmozWGMKV3x7ZM5IP2KQ" target="_blank"&gt;宣布&lt;/a&gt;正式开源基于 LLVM 的 JVM JIT 编译器 Jeandle。公告写道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以「筋斗云」为喻，希望 Jeandle 可以为 JVM 加足马力，拓宽它的性能与生态边界，让 Java 如腾云驾雾般瞬息万里。&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/152859_uBKb_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;开源地址：&lt;/p&gt; 
&lt;p&gt;https://github.com/jeandle/jeandle-jdk&lt;br&gt; https://github.com/jeandle/jeandle-llvm&lt;/p&gt; 
&lt;p&gt;据介绍，Jeandle 是基于 OpenJDK Hotspot JVM 的全新 Just-In-Time（简称 JIT，即时）编译器，利用 LLVM 进行编译优化与代码生成，将 LLVM 的性能优势和生态优势引入 JVM 中。&lt;/p&gt; 
&lt;p&gt;&lt;img height="533" src="https://static.oschina.net/uploads/space/2025/0814/152948_uqyv_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了整合 JVM 和 LLVM 两个复杂的系统，Jeandle 需要攻克多个技术难题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 JVM 的垃圾回收机制&lt;/li&gt; 
 &lt;li&gt;为 JVM 中的各种功能分别定制 LLVM 特性&lt;/li&gt; 
 &lt;li&gt;基于 LLVM 实现针对 Java 语言的多类优化算法&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;......&lt;/p&gt; 
&lt;p&gt;Jeandle 开源伊始，目前已经实现了若干关键功能，同时也有大量的研发工作仍在进行中。未来规划：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025 年全量 Bytecode 支持：社区计划在今年年底的版本中完成各类基础功能的支持，包括 exception、GC、sychronization 等等，覆盖全量的 bytecode。&lt;/li&gt; 
 &lt;li&gt;2026 年持续聚焦于性能优化的「黑科技」：&lt;/li&gt; 
 &lt;li&gt;推出&amp;nbsp;Java 定制优化套件：研发针对 Java 语言的各类优化算法，使 Jeandle 具备全面的优化能力，包括但不限于锁优化、类型分析、逃逸分析、inline 等。同时实现基于运行时 profile 信息的优化能力和 deoptimization 能力&lt;/li&gt; 
 &lt;li&gt;加入 intrinsic：通过针对各类特殊场景定制的高效代码提升 Java 语言性能&lt;/li&gt; 
 &lt;li&gt;支持 on-stack replacement&lt;/li&gt; 
 &lt;li&gt;支持 G1 GC 算法&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366179</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366179</guid>
      <pubDate>Thu, 14 Aug 2025 07:31:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 初创公司 Midjourney 更新功能，允许标准订阅用户生成高清视频</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span&gt;AI 初创公司 Midjourney&amp;nbsp;&lt;/span&gt;今天&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1955773050751963144" target="_blank"&gt;宣布&lt;/a&gt;，他们根据社区反馈发布了一系列的新功能，其中标准订阅用户现在可以生成高清视频。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/152433_quiN_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外还有改善的视频审核功能和批量制作视频等功能。具体如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;服务更新相关：基于社区反馈对服务进行了一系列小改进，包括 HD 视频生成对 Standard Plan 用户开放、视频作业可生成更小批量（1 或 2 个视频/次，通过设置面板或命令行参数--bs 1 、--bs 2 触发 ）、Moodboards 分离到侧边菜单可访问的独立页面、视频作业缩略图改为显示最后一帧、视频内容审核准确性提升 。&lt;/li&gt; 
 &lt;li&gt;涉及公司/团队：未明确提及具体公司，但围绕服务更新，推测是某提供视频等服务的团队 。&lt;/li&gt; 
 &lt;li&gt;提及的人物标签：@everyone@here ，属于通知类标签 。&lt;/li&gt; 
 &lt;li&gt;相关话题标签：#ideas-and-features ，用于提交想法和功能建议 。&lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366176</guid>
      <pubDate>Thu, 14 Aug 2025 07:25:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动 VeOmni 框架开源：统一多模态训练效率飞跃！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;资料来源： &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-开发者社区&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;多模态时代的训练痛点，终于有了「特效药」&lt;/p&gt; 
&lt;p&gt;当大模型从单一语言向文本 + 图像 + 视频的多模态进化时，算法工程师们的训练流程却陷入了 「碎片化困境」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;当业务要同时迭代 DiT、LLM 与 VLM 时，很难在一套代码里顺畅切换；&lt;/li&gt; 
 &lt;li&gt;而当模型形态一旦变化，底层并行组合和显存调度往往需要大量手工改写，耗时耗力；&lt;/li&gt; 
 &lt;li&gt;DIT 模型蒸馏需要大量的资源消耗，但是缺少高效的训练 infra 支持来提升效率……&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些困扰行业的痛点，字节跳动的工程师们早就遇到了 —— 于是，VeOmni 应运而生。作为字节内部验证过的 「统一多模态训练框架」，它经过内部千卡级别真实训练任务检验，训练了 UI-Tars1.5 等重要模型，为了能将字节跳动核心 AI Infra 能力服务更多用户，字节跳动决定开源 VeOmni，火山引擎基于进一步上支持了视频模型训练等功能，让 VeOmni 支持了更多模型训练场景，可以更好地服务更多用户。&lt;/p&gt; 
&lt;span id="OSC_h4_1"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;VeOmni 是什么？一套框架，搞定所有多模态训练&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 是字节 Seed 团队与火山机器学习平台、IaaS 异构计算团队联合研发的统一多模态模型训练框架，核心定位是三个统一：「统一多模态、统一并行策略、统一算力底座」。&lt;/p&gt; 
&lt;p&gt;它通过统一的 API 将 LoRA 轻量微调、FSDP、Ulysses 和 Expert Parallel 等多种混合并行策略以及自动并行搜索能力内置于框架内部。无论是百亿级语言模型、跨模态视觉语言模型，还是 480P/720P、长序列的文本到视频（T2V）或图像到视频（I2V）生成模型，开发者都能够基于统一的训练流程快速启动训练。&lt;/p&gt; 
&lt;p&gt;框架支持在千卡级 GPU 集群上自动完成权重张量的切分、通信拓扑的优化、动态显存回收和异步 checkpoint。在开源的 Wan 2.1 等模型上实测显示，相较于同类开源方案，VeOmni 能够将训练吞吐提高超过 40%，同时显著降低显存使用与跨节点通信带宽压力。&lt;/p&gt; 
&lt;p&gt;借助 VeOmni，字节跳动成功实现了「支持最快落地的新模型形态、最大化超大规模算力利用率、最小化业务改动成本」三大目标，有效弥补了开源社区训练框架在扩展性和抽象层面上的不足，为包括 LLM 和 VLM 在内的多模态生成场景提供了一条统一且高效的训练路径。&lt;/p&gt; 
&lt;p&gt;火山引擎的用户可在机器学习平台中运用 VeOmni 的强大功能。&lt;/p&gt; 
&lt;span id="OSC_h4_2"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;五大核心优势，破解训练效率瓶颈&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 的 「高效」 不是口号，而是用技术细节堆出来的。我们拆解了多模态训练的核心痛点，给出了针对性解决方案：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;显存计算双优化：用最少的额外计算，换最多的显存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;传统 「大颗粒」 重计算要么全关、要么全开，往往用 10%–20% 的额外计算只换一点显存。VeOmni 不一样 —— 它先给每个前向张量算一笔 「ROI 账」：省 1MB 显存需要付出多少微秒计算。然后按 ROI 排序，只选性价比最高的算子重计算（比如 gate1_mul 省 40MB 只要 180μs，down_proj 要 4000μs，差距 22 倍！）。&lt;/p&gt; 
&lt;p&gt;VeOmni 框架在训练启动前自动把 ROI 排序，同等显存收益只选择性价比最高的算子进入重计算池：例如 gate1_mul 和 down_proj 都可回收约 40 MB，但前者只需 180µs、后者要 4000µs，差距达 22 倍。这样就能在保证显存不会超出的前提下，把额外计算开销压到最低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f15963df249589141d372ad78130413e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;结果是：显存够用的前提下，额外计算开销压到最低。实测显示，相比按层重计算，VeOmni 的 Recompute 占比从 60% 降到 30%（Recompute 越低，效率越高），对 DiT 720P 视频训练、千亿 LLM 长序列训练效果显著。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;混合并行 「组合拳」：一键匹配最优算力切分方案，显存峰值降 55%&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 内置多维并行体系，支持 FSDP、Ulysses 和 Expert Parallel (EP) 等多种并行原语，通过启动脚本可以一键进行笛卡尔组合，自动搜索最优的算力切分方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FSDP 负责将参数、梯度和优化器状态切片到各个 GPU，突破显存瓶颈，横向扩批简单可靠；&lt;/li&gt; 
 &lt;li&gt;Ulysses Parallel 针对长序列任务，将注意力沿 head 维度拆解，有效缓解单卡显存压力；&lt;/li&gt; 
 &lt;li&gt;Expert Parallel 专门适用于 MoE 模型，可高效支持超大规模专家网络的训练。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这套并行体系已被应用于字节跳动内部多种模型的训练中，在处理 480P 和 720P 分辨率的 T2V/I2V 任务时，通过 FSDP 和 Ulysses 的组合，单轮迭代显存峰值可降低至原有基线的 45%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;算子级性能深挖：小核算子融合，访存次数降百倍&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;针对 DiT 中大量「小核算子」导致的访存抖动，VeOmni 把注意力-FFN-残差链路重写为单核 Kernel，长序列下显存碎片显著减少，访存次数下降数百倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//afce03f7d8cbcb2bff0b447b13dc1dc4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//bb18ae198fde761b3d2d081c8696cb6b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;跨模型通吃：LLM/VLM/ 视频生成，一套框架全搞定&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 的优化不是 「针对性补丁」，而是对，生成式视频模型、千亿级语言模型，与 视觉语言模型，全部生效：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DiT 训练显存减半；&lt;/li&gt; 
 &lt;li&gt;LLM 长上下文窗口训练从「手动调显存」变为「自动无感切分」；&lt;/li&gt; 
 &lt;li&gt;VLM 双塔/单塔架构在 Ring 模式下可线性扩展到更多 GPU，负载均衡无需改代码。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;凭借「算子粒度重计算 + 混合并行 + 算子融合/升级」三大引擎，VeOmni 把原本困扰开源框架的扩展瓶颈彻底拆解，为字节跳动以及合作伙伴在多模态内容生成和大模型服务化道路上提供了即插即用、极致高效的算力底座。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;蒸馏加速：减少推理步数，降低推理成本&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在生成式模型的推理中，步数蒸馏是提升效率的关键一环。然而，蒸馏的训练周期极长，需要的计算资源也十分庞大。VeOmni 集成了轨迹蒸馏、分布匹配蒸馏（DMD）、自回归蒸馏等学界前沿方法，并将框架原生的训练加速能力（如显存优化、混合并行等）应用在蒸馏算法上，极大地减少了蒸馏的迭代周期和资源消耗。用户可通过启动脚本指定蒸馏目标：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 DMD 等效果优秀的蒸馏方法，能将模型稳定蒸馏至 4 步、8 步等目标步数甚至更少；&lt;/li&gt; 
 &lt;li&gt;支持蒸馏掉 CFG（无分类器引导）以消除冗余计算；&lt;/li&gt; 
 &lt;li&gt;支持用户自由编排蒸馏工作流，例如组合 「轨迹蒸馏预处理 + DMD 精调」 的多阶段蒸馏逻辑。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经由 VeOmni 蒸馏出的模型能够显著减少推理所需步数，同时保持生成结果的高质量，这对于降低计算成本、加速模型部署具有重要意义。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实测性能：比开源方案快 40%，多场景数据说话&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VeOmni 的效率不是 「自说自话」，而是用真实模型测试验证的，以 Wan2.1-14B 模型为例（Lora 训练）：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;计算型大卡：I2V 720P 训练速度比开源方案快 48% 以上，T2V 720P 快 44.4% 以上；&lt;/li&gt; 
 &lt;li&gt;访存型大卡：I2V 720P 快 59.5% 以上，T2V 720P 快 57.4% 以上；&lt;/li&gt; 
 &lt;li&gt;小参数量模型（Wan2.1-1.3B）：T2V 480P 训练速度提升 51% 以上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;卡型 1（计算型大卡）&lt;/p&gt; 
&lt;p&gt;I2V 训练速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f3127bf08dc9774d20b1262c87352e99.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;T2V 训练速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f39465da6844f0065bb3fd82d1a9d701.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;卡型 2（访存型大卡）&lt;/p&gt; 
&lt;p&gt;I2V 训练速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//21548247b760eccd256454a9b19f30b7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;T2V 训练速度：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1c05eb55c9148e8fc9ee41fbc7df7de4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不管是大模型还是小模型，不管是计算型还是访存型硬件，VeOmni 都能让算力发挥到极致！&lt;/p&gt; 
&lt;span id="OSC_h4_3"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;上手超简单：火山平台一键训练，性能分析可视化&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;VeOmni 不是 「专家专属工具」，而是开箱即用。目前，火山引擎在机器学习平台和 AI 云原生训练套件 TrainingKit 上都提供了 VeOmni 训练的最佳实践。下面我们以机器学习平台实践为例，介绍基于 VeOmni 训练框架对开源模型 Wan 进行 lora 训练，后续我们将推出基于 TrainingKit 的 VeOmni 部署实践。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;创建训练任务&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在快速入门选择需要训练的模型，并且配置实例规格及模型输出路径。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//31590466661f9e2eef65fef5916f8414.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f88fe1716fd8d5abaf5b023312375de0.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看训练任务详情&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;创建任务后可在「任务详情-日志」中查看训练详情。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//8a54f636c8d814cc29a730da2628b5c1.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPU 性能分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.导航到，自定义任务 &amp;gt; 任务详情，页面，在目标任务的管理页面单击，创建性能分析。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//82c9f5d93421f97b88b854ded7e4f46d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2.完成采集后，可在性能分析结果列表页面管理所有分析任务。点击「查看详情」将跳转至 perfetto 中展示性能分析火焰图。&lt;/p&gt; 
&lt;p&gt;每个 Worker 节点会根据其拥有的 GPU 数量或进程数生成多个进程文件。平台会将这些文件聚合成一个单一的结果文件，并根据 perfetto 的限制进行自动分片。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//b6a5e8d04c0237d22283b1f6eb94d3e2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//a0617c1987ef8a9f509d17535d5c12b9.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_4"&gt;&lt;/span&gt; 
&lt;h4&gt;从训练到推理，全链路打通&lt;/h4&gt; 
&lt;p&gt;目前火山引擎机器学习平台提供的数据集是用来训练飞天效果的 Lora 数据集，客户也可以自己选择合适的数据集进行预处理后来进行训练，具体使用方法随后更新。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;获取输出结果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在一键训练的时候客户指定了训练的模型结果保存的地方，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//6cac77d83565659304a433c9f88d9e67.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;输出模型结果保存文件路径类似下图&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;code class="language-text"&gt;checkpoints/  
├── &lt;span style="color:#d73a49"&gt;global&lt;/span&gt;\_step\_xxx/           &lt;span style="color:#6a737d"&gt;# 每次保存的权重快照  &lt;/span&gt;
│   ├── extra\_state/            &lt;span style="color:#6a737d"&gt;# 训练状态（按 rank 切分）  &lt;/span&gt;
│   │   └── extra\_state\_rank\_*.pt  
│   ├── hf\_ckpt/                &lt;span style="color:#6a737d"&gt;# HuggingFace 兼容格式  &lt;/span&gt;
│   │   ├── config.json  
│   │   └── diffusion\_pytorch\_model.safetensors  
│   ├── model/                  &lt;span style="color:#6a737d"&gt;# 模型参数分片  &lt;/span&gt;
│   │   └── \_\_*\_*.distcp  
│   └── optimizer/              &lt;span style="color:#6a737d"&gt;# 优化器状态分片  &lt;/span&gt;
│       └── \_\_*\_*.distcp  
└── latest\_checkpointed\_iteration.txt  &lt;span style="color:#6a737d"&gt;# 记录最新步数  &lt;/span&gt;&lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;客户可以到 hf_ckpt 下看到保存的 Lora 训练权重，得到的路径为 checkpoints/global_step_xxx/hf_ckpt/diffusion_pytorch_model.safetensors&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;使用脚本进行权重格式转换&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;将下列代码保存为 convert.p&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;code class="language-text"&gt;&lt;span style="color:#6a737d"&gt;#!/usr/bin/env python  # convert.py  ——  把 「blocks.…default.weight」 → 「diffusion\_model.blocks.…weight」  from pathlib import Path  &lt;/span&gt;
from safetensors.torch import &lt;span style="color:#d73a49"&gt;load&lt;/span&gt;\_file, &lt;span style="color:#d73a49"&gt;save&lt;/span&gt;\_file  
&lt;span style="color:#d73a49"&gt;import&lt;/span&gt; &lt;span style="color:#d73a49"&gt;sys&lt;/span&gt;  
  
&lt;span style="color:#d73a49"&gt;if&lt;/span&gt; &lt;span style="color:#d73a49"&gt;len&lt;/span&gt;(sys.argv) != &lt;span&gt;2&lt;/span&gt;:  
    sys.exit(f&lt;span style="color:#032f62"&gt;"用法: python {Path(\_\_file\_\_).name} &amp;lt;input.safetensors&amp;gt;"&lt;/span&gt;)  
  
inp = &lt;span style="color:#d73a49"&gt;Path&lt;/span&gt;(sys.argv[&lt;span&gt;1&lt;/span&gt;]).expanduser().resolve()  
&lt;span style="color:#d73a49"&gt;out&lt;/span&gt; = inp.with\_name(inp.stem + &lt;span style="color:#032f62"&gt;"\_styleB.safetensors"&lt;/span&gt;)  
  
tensors = &lt;span style="color:#d73a49"&gt;load&lt;/span&gt;\_file(&lt;span style="color:#d73a49"&gt;str&lt;/span&gt;(inp))  
converted = {}  
  
&lt;span style="color:#d73a49"&gt;for&lt;/span&gt; k, v &lt;span style="color:#d73a49"&gt;in&lt;/span&gt; tensors.items():  
    &lt;span style="color:#6a737d"&gt;# 若无前缀则加 diffusion\_model.  &lt;/span&gt;
    ifnot k.startswith(&lt;span style="color:#032f62"&gt;"diffusion\_model."&lt;/span&gt;):  
        k = &lt;span style="color:#032f62"&gt;"diffusion\_model."&lt;/span&gt; + k  
    &lt;span style="color:#6a737d"&gt;# 去掉 .default.  &lt;/span&gt;
    k = k.replace(&lt;span style="color:#032f62"&gt;".default."&lt;/span&gt;, &lt;span style="color:#032f62"&gt;"."&lt;/span&gt;)  
    converted[k] = v  
  
&lt;span style="color:#d73a49"&gt;save&lt;/span&gt;\_file(converted, &lt;span style="color:#d73a49"&gt;str&lt;/span&gt;(&lt;span style="color:#d73a49"&gt;out&lt;/span&gt;))  
print(f&lt;span style="color:#032f62"&gt;"✓ 已保存: {out}"&lt;/span&gt;)&lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;执行下面的命令，得到转换后的权重&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;pre style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;code class="language-text"&gt;&lt;span style="color:#6f42c1"&gt;python&lt;/span&gt; &lt;span style="color:#032f62"&gt;convert.py   &lt;/span&gt;
&lt;span style="color:#6a737d"&gt;yourpath/checkpoints/global\_step\_xxx/hf\_ckpt/diffusion\_pytorch\_model.safetensors&lt;/span&gt;     &lt;/code&gt;&lt;/span&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;使用 Vefuser 推理&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;训练完的模型，用火山 veFuser 推理更高效 ——veFuser 是火山引擎的扩散模型服务框架，针对 VeOmni 训练的 LoRA / 全量微调模型做了优化，能实现 「超低延迟」 视频生成。从训练到部署，全链路流畅！&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6800876/blog/18688206</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/18688206</guid>
      <pubDate>Thu, 14 Aug 2025 07:20:34 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>全球首个 AI Agent 市场「Mule Run」开启 Beta 测试</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;MuleRun &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmulerun_ai%2Fstatus%2F1955661198072115373" target="_blank"&gt;宣布&lt;/a&gt;其 AI Agent 市场「Mule Run」开启 Beta 测试。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0814/151422_yt3n_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mule Run 定位为全球首个 AI Agent 市场，旨在成为 AI 领域的 「eBay」，用户只需一个入口即可访问大量 AI Agent。这些 Agent 能够执行多种任务，包括游戏、编程，甚至帮助用户赚钱。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0814/151614_zZWD_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mule Run 的 Beta 测试目前采用邀请制。感兴趣的用户可以通过 Discord 加入其社区以获取更多信息。MuleRun 还通过社交媒体活动提供 5 个激活码，有效期为 72 小时，参与者需转发、关注并开启通知。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366173</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366173</guid>
      <pubDate>Thu, 14 Aug 2025 07:16:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 正以创纪录的速度创造新的亿万富翁</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F08%2F10%2Fai-artificial-intelligence-billionaires-wealth.html" target="_blank"&gt;据 CNBC 报道&lt;/a&gt;，全球已有近 500 家 AI 「独角兽」（估值超过 10 亿美元）的初创企业，它们的总估值达 2.7 万亿美元，且其中 100 家是在近两年内成立。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/150500_YLO8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这波浪潮造就了数十位新晋亿万富翁，集中分布在旧金山湾区。代表人物包括 Scale AI 联合创始人亚历山大·王（36 亿美元）、郭露西（10 亿美元+）、Anthropic CEO 达里奥·阿莫迪（12 亿美元+）、CoreWeave CEO 迈克尔·因特罗特（100 亿美元）、DeepSeek CEO 梁文锋、Figure AI 创始人布雷特·阿德科克、Perplexity CEO 阿拉温德·斯里尼瓦斯，以及 OpenAI 前高管伊利亚·苏茨凯夫和米拉·穆拉蒂等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="241" src="https://static.oschina.net/uploads/space/2025/0814/145511_mDy0_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;来源：量子位 https://mp.weixin.qq.com/s/tIYoRz4zm6SlylG-eq-maw&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;这些公司普遍保持私营，依赖风投、主权基金等融资，并频繁发生并购与股权转让。创始人更注重财富管理与二级市场操作，如股权抵押借款、投资同类科技公司等。&lt;/p&gt; 
&lt;p&gt;据了解，AI 财富高度集中于湾区，其中旧金山成为全球亿万富翁聚集地，生活成本、房地产等也因 AI 扎根而交由巨大影响。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366170</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366170</guid>
      <pubDate>Thu, 14 Aug 2025 07:07:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元开源 Hunyuan-GameCraft</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJ-EEjMJVLhPjnRGflbHu5w" target="_blank"&gt;宣布&lt;/a&gt;开源新工具&amp;nbsp;Hunyuan-GameCraft，声称可让用户像导演一样打造游戏场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Hunyuan-GameCraft 是基于 HunyuanVideo 底模的高动态交互式游戏视频生成框架，简单来说，它是一个「游戏视频生成工具」，只需要「输入一张图 + 文字描述+动作指令（按键盘方向键）」，就能输出高清动态游戏视频。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;无论是第一人称跑酷，还是第三人称探险，它都能实时生成流畅画面，仿佛你真的在游戏世界里自由穿梭。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-05412c3b9668b9449c51396d591d8ffe6c3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该工具解决了传统游戏内容生产中的三大难题：动作僵硬、场景静态以及生产成本高昂。Hunyuan-GameCraft 有以下三大优势：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自由流畅 ：统一连续动作空间，支持高精度控制（角度/速度），支持「边跑边转视角」的复杂操作；可以生成动态内容（例如主角和 NPC 运动、云层移动、雨雪、水流运动等）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;记忆增强 ：生成长视频时，角色和环境保持稳定不「穿帮」；通过混合历史条件，实现历史帧记忆，避免长视频生成时不连贯；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;成本骤降 ：无需人工建模或渲染，制作成本更低；对比现有的游戏模型闭源方案，泛化性强。阶段一致性蒸馏方案（Phased Consistency Model, PCM）和 DeepCache 压缩推理步数，量化 13B 模型支持消费级硬件 RTX 4090，无需高端服务器。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这样一来，Hunyuan-GameCraft 可以大幅降低游戏开发门槛，让个人创作者也能生产 3A 级动态内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-695af7f080b37088da5aac9131192d0a111.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;主要使用对象&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;游戏开发者：快速进行原型设计以及剧情动画预演论证，节约人工建模和渲染成本&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;视频创作者：用一张照片生成「异世界探险」短片，无需学 3D 建模&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;3D 设计师：可以快速将场景原画秒变动态场景，展示设计创意&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366164</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366164</guid>
      <pubDate>Thu, 14 Aug 2025 06:50:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软正在为 Edge 浏览器开发全新 UI：代号 Olympia、专注优化 AI 使用体验</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.windowscentral.com%2Fmicrosoft%2Fwindows-11%2Fmicrosoft-edge-olympia-ui-copilot-ai-revamped-design" target="_blank"&gt;根据 Windows Central 的报道&lt;/a&gt;，微软正在开发代号为 「Olympia」 的 Edge 浏览器 UI 更新，该设计以简洁实用为核心，围绕 Copilot 功能展开。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fe76a836e3d1bd169ce439ed660fd7a755.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据知情人士透露，该项目自 2024 年起便已启动，原代号为 Jupiter，目前部分测试版本已出现在 Edge Canary 中。 新版界面包括居中简化地址栏、垂直标签页布局、右侧功能菜单等，并强化搜索、语音输入功能，视觉风格贴合 Windows 11。&lt;/p&gt; 
&lt;p&gt;有观点认为，Olympia 或是为 Copilot 模式打造的专属界面，也可能是更彻底的 UI 重构。当前 Copilot 模式仅将按钮从窗口右侧移至地址栏左侧，而 Olympia 布局中 Copilot 图标位置与之完全一致，且随着 Copilot 模式能力增强，或需独特界面匹配其智能代理功能，这也符合微软关于生成式 AI 和智能 Agent 功能将改变 UI 的理念。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-78433eeb077904862d9925e2e12dcbf594b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前该功能尚未完善，部分区域仍不可用。微软此前尝试过类似设计但未上线，Olympia 最终能否落地，仍有待观察。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366162</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366162</guid>
      <pubDate>Thu, 14 Aug 2025 06:49:34 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Gemini 增加「自动记忆」和「临时聊天」功能</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;谷歌为旗下 AI 服务 Gemini 推出了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fgemini%2Ftemporary-chats-privacy-controls%2F" target="_blank"&gt;两项更新&lt;/a&gt;，分别是基于聊天上下文的「自动记忆」功能和保护隐私的「临时聊天」模式，以提供更个性化的 AI 体验。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;自动记忆（「个人上下文」）&lt;/strong&gt;：默认开启，无需用户再手动提示即可记住过往对话中的关键细节与偏好，并在后续回答中主动个性化（例如曾讨论过日本文化，之后询问视频创意时自动推荐日本美食）。&lt;em&gt;用户可在 Gemini 应用 → 设置 → 个人上下文 → 关闭「你与 Gemini 的过往聊天」来禁用。&lt;/em&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5ae3c546bff3bf2ccce191f83b8450db42b.png" referrerpolicy="no-referrer"&gt;&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;隐私调整&lt;/strong&gt;： 
  &lt;ul&gt; 
   &lt;li&gt;未来几周，「Gemini Apps Activity」更名为「Keep Activity」。若开启，从 9 月 2 日起谷歌会抽样使用用户上传的文件/图片以改进服务；若此前已关闭，则保持关闭。&lt;/li&gt; 
   &lt;li&gt;新增「临时聊天」模式（类似无痕浏览）：对话不会出现在历史记录，也不用于个性化或模型训练，仅保留 72 小时。&lt;br&gt; &lt;br&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-939444900548793ba6f27a4f1b65ee096ad.png" referrerpolicy="no-referrer"&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;根据谷歌官方公告，上述调整首先面向部分国家的 Gemini 2.5 Pro 用户推送，后续扩展到更多地区及 2.5 Flash 模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366159/google-gemini-temporary-chats-privacy</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366159/google-gemini-temporary-chats-privacy</guid>
      <pubDate>Wed, 13 Aug 2025 06:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cherry Studio v1.5.6 发布，支持通过图形化界面为 Code Agent 配置第三方模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Cherry Studio v1.5.6 已正式发布，新版本支持通过图形化界面为 Qwen Code、Gemini Cli 和 Claude Code 等 Code Agent 快速配置第三方模型，并实现一键启动，无需再手动配置模型与 Node.js 环境。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-53c4cbe1db86d83c77e9dd0ed9f1db54abd.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2cc17ff3452f8a9620abdfe50ab94d60b98.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cherry Studio 是一款跨平台的 AI 桌面应用，支持 Windows、macOS 和 Linux 系统。主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;多模型支持：兼容 40 余家主流模型服务商，如 OpenAI、Gemini、Anthropic 等，支持一键切换模型，满足不同场景需求。&lt;/li&gt; 
 &lt;li&gt;联网搜索功能：支持集成第三方搜索服务（如 Tavily、Exa），可让模型实时获取网络信息，增强回答的时效性和准确性。&lt;/li&gt; 
 &lt;li&gt;知识库管理：支持导入 PDF、Word、Excel 等多种格式文件，构建本地知识库，实现基于文档的精准问答。&lt;/li&gt; 
 &lt;li&gt;高度自定义：支持自定义 CSS 样式、对话布局、头像等，还可创建个性化 AI 助手，满足不同用户的个性化需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载地址：&lt;em&gt;https://github.com/CherryHQ/cherry-studio/releases/tag/v1.5.6&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366156/cherry-studio-1-5-6</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366156/cherry-studio-1-5-6</guid>
      <pubDate>Wed, 13 Aug 2025 06:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 宣布 Auto 模式不再免费</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;AI 编程工具 Cursor&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fen%2Fblog%2Faug-2025-pricing" target="_blank"&gt;宣布&lt;/a&gt;了两项关于定价的新政策。其中包括面向个人用户的「Auto」模式。此前，Auto&amp;nbsp;模式提供免费无限量请求，但这一政策将发生改变。新的计费模式预计将于 9 月 15 日左右生效。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/141755_w0lB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;具体变化如下&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;团队版（Teams）：由统一请求费用转向 「可变请求费用」&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Cursor 计划从 &lt;strong&gt;固定请求成本&lt;/strong&gt;，改为按任务复杂度调整费用——简单请求成本低，复杂任务（如完整 Pull Request）费用自然更高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;这一改动旨在统一团队版与个人版的计费体系。自 &lt;strong&gt;2025 年 9 月 15 日下次续费日起&lt;/strong&gt;生效；例如若你在 2025 年 6 月订阅年付计划，变更将于 2026 年 6 月执行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.cursor.com%2Fen%2Faccount%2Fpricing%23auto" target="_blank"&gt;&lt;strong&gt;个人版 「Auto 模式」：不再无限制免费&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;从 2023 年 12 月至 2025 年 6 月，Auto 模式与其他高端模型同价，但可无限使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;从 2025 年 9 月 15 日的下一次续费起&lt;/strong&gt;，Auto 模式将按 「包含额度」 分配，也会纳入每月使用限额（按 token 计费）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366153</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366153</guid>
      <pubDate>Wed, 13 Aug 2025 06:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>昆仑万维发布 Skywork Deep Research Agent v2</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在 SkyWork AI 技术发布周的第四天，昆仑万维集团&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKBSBOO6bq125BQ9YT4eiYA" target="_blank"&gt;宣布&lt;/a&gt;推出 Skywork Deep Research Agent v2。这一升级标志着天工超级智能体（Skywork Super Agents）的核心引擎得到了显著增强，为用户带来了更多模态、更高质量和更高效的体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Skywork Deep Research Agent 于 5 月 2 日上线以来。新版本的 Skywork Deep Research Agent v2 引入了「多模态深度调研」Agent，首次整合了多模态检索、理解和生成，解决了传统 Deep Research Agent 产品依赖纯文本检索分析的局限。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="242" src="https://static.oschina.net/uploads/space/2025/0814/141828_pO9c_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;昆仑万维 Skywork 团队推出的「多模态深度调研」Agent，通过技术创新，实现了多模态信息检索能力的提升，包括多模态爬取技术 MM-Crawler、长距离多模态信息收集、异步并行 Multi-Agent 多模态理解架构和多模态结果呈现能力。这些技术突破使得研究人员等用户能够一次性获得信息完整、节奏顺畅、视觉友好的深度报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，昆仑万维还推出了「多模态深度浏览器」智能体，重塑了社交媒体内容分析与数据洞察。这一智能体通过多项关键自研技术优化，包括升级 DOM+视觉推理方案、主流平台专项适配、并行搜索、多动作规划机制、智能筛选、人机无缝接管与隐私保护和安全承诺等，能够模拟人类浏览与交互方式，革新传统数据采集与分析模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Skywork Deep Research Agent v2 在多项 Agent 任务评测上超越现有模型，达到行业 SOTA 水平。在权威的搜索评测榜单 BrowseComp 上，其性能尤为突出，正确率达到 27.8%，开启并行思考模式后，正确率跃升至 38.7%，刷新了行业 SOTA 纪录。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366152</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366152</guid>
      <pubDate>Wed, 13 Aug 2025 06:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek App 发布更新，首次支持对话内容生成分享图功能</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;8 月 14 日，根据手机应用商店显示，DeepSeek App 发布了 1.3.0 版本更新，支持对话内容生成分享图功能。&lt;/p&gt; 
&lt;p&gt;更新之后，用户的问答对话可以通过原生功能生成图片，比截图分享更方便了。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/114037_lReb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，近期有不少传闻称，新一代 DeepSeek R2 有望在 8 月 15 日至 30 日期间发布，该消息日前&lt;a href="https://www.oschina.net/news/365948" target="_blank"&gt;被 DeepSeek 内部人士否认&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;早在今年年初，关于 R2 模型的消息就已开始流传。当时曾有预测称，R2 模型将在 3 月 17 日发布，但这一说法同样遭到了官方的否认。至今，DeepSeek 尚未正式公布 R2 模型的具体发布时间及技术细节，令众多关注者感到失望。&lt;/p&gt; 
&lt;p&gt;据报道，DeepSeek 团队今年 6 月曾加紧推进 R2 模型的开发工作。知情人士透露，CEO 梁文锋对模型的能力仍不满意，团队内部仍在进行性能提升，并未准备好正式投用。早期消息称，DeepSeek 原计划在 5 月推出 R2 模型，但由于各方面原因，该计划被延迟。新模型预计将能够生成更高质量的代码，并具备用非英语语言进行推理的能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366129</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366129</guid>
      <pubDate>Wed, 13 Aug 2025 03:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>nginx 1.29.1 主线版本发布</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;nginx 1.29.1&amp;nbsp;主线版现已&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2Fdownload.html" target="_blank"&gt;发布&lt;/a&gt;&lt;span style="color:#000000"&gt;。具体更新内容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Security： 在 ngx_mail_smtp_module 中使用「none」身份验证方法时，处理特制的登录名/密码可能会导致工作进程内存泄露给身份验证服务器（CVE-2025-53859）。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Change：现在默认禁用 TLSv1.3 certificate compression。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Feature：「ssl_certificate_compression」指令。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;Feature：使用 OpenSSL 3.5.1 或更新版本时支持 QUIC 中的 0-RTT。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;错误修复：使用 HTTP/2 和「early_hints」指令时，103 响应可能会被缓冲。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;错误修复：使用 HTTP/2 时处理具有相等值的「Host」和「:authority」header lines；该错误出现在 1.17.9 中。 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;错误修复：使用 HTTP/3&amp;nbsp;时处理带有 port 的「Host」header lines。 &lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;错误修复：无法在 NetBSD 10.0 上构建 nginx。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;错误修复：「smtp_auth」指令的「none」参数。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可查看&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnginx.org%2Fen%2FCHANGES" target="_blank"&gt;CHANGES&lt;/a&gt;&lt;span style="color:#000000"&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366128/nginx-1-29-1-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366128/nginx-1-29-1-released</guid>
      <pubDate>Wed, 13 Aug 2025 03:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 收购 Humanloop 核心团队</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Anthropic 近日完成了对 AI 工具平台 Humanloop 核心团队的收购，这一举措旨在强化其企业市场战略。虽然交易具体条款未被披露，但此次收购明显遵循了科技行业在 AI 人才争夺战中日益常见的"人才收购"模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 的三位联合创始人——CEO Raza Habib、CTO Peter Hayes 和 CPO Jordan Burgess——已全部加入 Anthropic，同时还有约十几名工程师和研究人员。该平台专注于提示管理、大语言模型评估和可观测性服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="296" src="https://oscimg.oschina.net/oscnet/up-5f55b40957d7e85d1526c72df79e3fe74ae.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;随着 Anthropic 在智能体和编程能力方面的领先优势，该公司在企业市场正快速增长。尽管 Anthropic 发言人确认公司并未收购 Humanloop 的资产或知识产权，但在 AI 行业，真正的价值往往存在于人才的大脑中，这使得资产收购变得相对次要。Humanloop 团队为 Anthropic 带来的是帮助企业安全、可靠地大规模运行 AI 系统的丰富经验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Anthropic API 产品负责人 Brad Abrams 表示："他们在 AI 工具和评估方面的成熟经验对我们继续推进 AI 安全工作和构建有用 AI 系统将极其宝贵。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在模型质量本身已不足以保持竞争优势的市场环境下，加强工具生态系统可能帮助 Anthropic 在性能和企业就绪度方面巩固其相对于 OpenAI 和 Google DeepMind 的领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 成立于 2020 年，最初是伦敦大学学院的衍生公司。该初创公司随后参加了 Y Combinator 和 Fuse 孵化器项目，并在两轮种子融资中筹集了 791 万美元，投资方包括 YC 和 Index Ventures。Humanloop 在帮助企业客户开发、评估和微调强大 AI 应用方面赢得了良好声誉，其客户包括 Duolingo、Gusto 和 Vanta 等知名企业。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;上个月，Humanloop 告知客户将关闭服务，为收购做准备。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此次人才收购的时机恰逢 Anthropic 向企业客户提供更长上下文窗口等功能，提升了其模型的能力和应用范围。本周早些时候，Anthropic 与美国政府中央采购部门达成协议，将向行政、司法和立法部门的政府机构销售 AI 服务，首年每个机构仅收费 1 美元——这明显是为了与 OpenAI 类似价格的产品竞争。政府和企业买家都需要 Humanloop 专长的评估、监控和合规功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这项收购也符合 Anthropic"安全第一"AI 公司的定位。Humanloop 的评估工作流程通过提供持续的性能测量、安全防护和偏见缓解，与这一使命完全契合。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Humanloop 前 CEO Raza Habib 在声明中表示："从创立之初，我们就专注于创建帮助开发者安全有效地构建 AI 应用的工具。Anthropic 对 AI 安全研究和负责任 AI 开发的承诺与我们的愿景完美契合。"&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366126</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366126</guid>
      <pubDate>Wed, 13 Aug 2025 03:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：OpenCat：我的造物之旅——从木头到智能，一个机器生命的诞生</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2123</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2123</guid>
      <pubDate>Wed, 13 Aug 2025 03:26:00 GMT</pubDate>
    </item>
    <item>
      <title>马斯克 xAI 公司联合创始人 Igor Babuschkin 离职</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;xAI 联合创始人 Igor Babuschkin &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fibab%2Fstatus%2F1955741698690322585" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;离职，他在社交媒体发布了一封感人至深的告别信，回顾了他在 xAI 的非凡历程，并宣布将创立 Babuschkin Ventures，专注于 AI 安全研究和支持推动人类进步的 AI 初创公司。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/104112_IXxb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&amp;nbsp;&lt;/span&gt;&lt;span&gt;回忆了与马斯克的初次会面，两人就 AI 和未来进行了数小时的深入交流，共同认识到世界需要一家具有不同使命的新 AI 公司。&lt;/span&gt;他还提到了 xAI 如何在短短时间内完成了看似不可能的任务——在 120 天内建成 Memphis 超级集群，以及团队如何以「疯狂的速度」推出前沿模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;马斯克很快回复了这条推文：感谢你帮助建立 @xAI！没有你就没有我们的今天。&lt;/p&gt; 
 &lt;p&gt;Igor Babuschkin(@ibab) 回应马斯克：谢谢你，Elon！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="962" src="https://static.oschina.net/uploads/space/2025/0814/104723_AJtI_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&lt;/span&gt;&amp;nbsp;是 AI 领域的资深研究员，曾在多家顶级 AI 实验室担任要职。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;他在德国多特蒙德工业大学（TU Dortmund）学习物理学（2010-2015），期间作为夏季研究生参与了 CERN 大型强子对撞机的 LHCb 实验研究。&lt;/li&gt; 
 &lt;li&gt;2017 年他转向机器学习和人工智能领域，加入 DeepMind，担任高级研究工程师，参与开发了能够达到《星际争霸 II》大师级水平的 AlphaStar AI。&lt;/li&gt; 
 &lt;li&gt;2020 年 11 月，他加入 OpenAI，专注于生成模型和代码生成，参与了 AlphaCode 和大型语言模型的研究。&lt;/li&gt; 
 &lt;li&gt;2022 年他短暂回到 DeepMind 担任高级研究工程师，专注于扩展 AI 系统并改进推理和生成能力。&lt;/li&gt; 
 &lt;li&gt;2023 年 5 月，Igor 与马斯克共同创立了 xAI，专注于构建可扩展和可解释的 AI 系统。他在 Nature 等顶级期刊发表了多篇重要论文，在强化学习、模仿学习和大规模训练等领域推动了 AI 的进步。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366115</guid>
      <pubDate>Wed, 13 Aug 2025 02:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 告别独立时代，Gitee 12 年坚守开启 AI 新程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;深圳北科大厦，几位外国客人，专注地盯着屏幕上 Gitee 的实操演示，不时还向一旁的中国工程师询问功能细节，转眼一小时过去——这一幕发生在 2018 年 10 月开源中国的深圳办公室，来访者正是 GitHub 的前两任 CEO ：Nat Friedman 与 Thomas Dohmke 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;而如今，这两位熟人走了，开源中国仍在，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;开启 AI 新程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 两任 CEO 的东方足迹&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2018 年 10 月，在中国开源年会 COSCon'18 的活动现场，开源中国 COO 徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（现任开源中国 CEO ）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一次见到了 Nat Friedman 。「衣着随意，一看就是程序员」，是徐勇对这位 GitHub 掌门人的第一印象。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可能是身处一个圈子的好感，徐勇与 Nat Friedman 在第二天讨论中国开源生态的闭门会上，聊得格外投机。当 Nat Friedman 得知开源中国也有一款类似 GitHub 的软件后，顿时来了兴趣，当即便和徐勇约定了第二天&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源中国拜访，于是就出现了开头的一幕。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那是 2018 年的一个凉爽的上午，一高一矮两个老外走进了开源中国办公室。徐勇回忆，上午十点，Nat Friedman 一行就来了。寒暄一阵之后，徐勇作为东道主，向 Nat Friedman 一行讲解起了当时的 Gitee 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「 Nat 大高个儿嘛，看屏幕就比较费劲，全程都是勾着腰。但看得出，他对 Gitee 很感兴趣，特别是一些功能上的创新——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;或者说，是中国的开发者市场。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彼时，开源历史上的一个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;里程碑事件引发全球瞩目：GitHub 被微软以 75 亿美元全资收购。GitHub 作为全球最知名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;且&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中立的开源协作平台，被科技巨头收购之后该何去何从？Nat Friedman 被任命为 CEO 未来又有何动作？外界众说纷纭。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但我们可以知道的是，Nat Friedman 官宣上任后的第一件事，并没有出现在 GitHub 的办公室，反而是来到了中国，特别是出现在了开源中国的办公室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一起观摩 Gitee 的演示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拜访的最后，Nat Friedman 团队其中一人向徐勇递出了名片，直白地问：「如果我们出钱收购，开源中国卖不卖？」 此人，正是当时 GitHub 的 CTO，也就是后来的第二任 CEO 的 Thomas Dohmke。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对此，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;内心坚定，但周全考虑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;并没有明确&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拒绝&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。而在这次深圳会面不久，微软全球 CEO Satya Nadella 来华，又特地安排了与开源中国马越&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（现开源中国董事长）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的会面，依旧提及收购事宜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;面对行业巨头抛来的橄榄枝，开源中国始终坚定选择&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;独立发展。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇后来回忆道：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「虽然 2018 年，开源中国也处于业务转型的阵痛期，在资本市场四处化缘，但将&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本土&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯一的代码托管平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;拱手让人&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，中国未来的开源生态又谈何自强呢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gitee 得坚持走自己的路，中国特色的路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;正如 Gitee 一开始就定下的基调：致敬 GitHub ，但绝不照搬，始终聚焦「开发者为本」，走出一条贴合中国开发者需求的特色之路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2 个人，7 年，「他们都离开了」，我们&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依然前行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 11 日，一则消息震动全球开发者社区：GitHub CEO Thomas Dohmke 宣布辞职，而 GitHub 将结束独立运营，整体并入微软 CoreAI 部门，且微软不再为其寻找新 CEO。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thomas Dohmke 在内部邮件中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提及&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：如今 GitHub 已有超过 10 亿个代码库与分支，开发者数量突破 1.5 亿，以及 Copilot 持续引领蓬勃发展的 AI 市场，拥有 2000 万用户&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;并&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不断增长......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-f5820ca29b80620e4822a8dee4106dad2fb.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如此成绩的背后，是微软与 GitHub 以开放的方式续写开源生态的共生故事：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源开放上，微软开源 WSL （ Windows Subsystem for Linux ），打破了 Windows 与 Linux 长期以来的生态壁垒，成为连接千万开发者的技术桥梁；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 产品功能上，开放地收购了 NPM 等工具厂商，使得 Actions 能力变强。GitHub Actions 于微软时期推出，甚至免费私有仓库也是在微软时期才开始提供；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;数据开放，GitHub 上的公开数据，成为开发者打磨工具、挖掘趋势、创造新方案的 「原始素材库」。而在大模型时代，无数聚焦代码生成、漏洞检测、自动化开发的大模型与工具，正是以 GitHub 的公开数据为训练基底;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对开发者生态来说，「开放」是微软收购 GitHub 之后的一个极为重要的关键词，并且以这样的开放实现了众多创举，其中就有 Copilot 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2021 年，随着生成式 AI 的崛起，微软与 OpenAI 合作推出 GitHub Copilot ，正式开启 AI 编程时代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如今，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Copilot &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;已&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从代码补全工具，发展成拥有 Copilot Chat&amp;amp;Voice 的对话式编程助手，再到能审查与修复代码、用 GitHub Spark 构建全栈应用的多模态智能体系统，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-438ee8757571e7fbed84b401bb5e002b19f.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但，乱世何妨缺英豪？尽管 GitHub Copilot 算是第一个在 AI 编程领域颠覆大家认知的产品，但过去这一年多，微软一定也意识到：在这波 AI 编程浪潮下，旗下的 GitHub 并没有发挥出其应有的影响力，而 Copilot 则更多地是在给旁人做嫁衣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;正如开源中国 CTO 红薯评价：「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不仅是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 还包括 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VSC&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ode 。Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 的价值体现在其不止有 1.5 亿用户和 10 亿仓库上，还有巨大的流量和用户惯性。但很明显，很多人已经不买 Copilot 的账了，说得更夸张一点就是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 在 AI 编程时代&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一开始的首发到现在暂时落后。微软希望改变现在的这个局面，其核心思路不再&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub+AI&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;，而是 All In AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;结合微软与 GitHub 目前遇到的危机，曾经的「开放」，也&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;步入「&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;缩紧&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;」。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;相较于 GitHub 在巨头体系下的战略调整，Gitee 的发展路径始终聚焦 「开发者为本」。没有大厂的资金狂投，却凭借 「草根」 式的坚韧，筑牢了中国开源创新的基础设施；没有急于追逐全球扩张，却深耕本土土壤，让每一个功能都贴合中国开发者的工作场景。这种扎根本土的坚守，让 Gitee 在开源浪潮中站稳了脚跟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;开源中国 12 年坚守，开启 AI 新程&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;看到卸任的新闻，回顾 Nat Friedman 、 Thomas Dohmke 与开源中国 2018 年的这段缘分，不禁令人唏嘘。7 年时间，他们已经离开&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这一变动让不少人感慨开源平台的命运流转，而在中国，另一个名字却始终稳健前行 —— Gitee 正以扎根本土的坚守与创新，书写着属于中国开源的独特篇章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;如今的 Gitee ，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;依托对中国开发者协作习惯的深刻理解，已进化为一站式软件工程平台，支撑起 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;1350w+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;开发者&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;36w+ 企业、2000+ 高校&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的高效协作&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;从代码托管到项目管理，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;再到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;DevOps 工具链，Gitee 的每一&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;次&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;迭代&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;升级&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;都紧扣本土开发者的真实需求 —— &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;让每一行代码，都有改变世界的力量&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-b9db8504e1b37af3a2ff6a04ccded8680c4.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当下，AI 浪潮席卷全球，软件开发正迎来智能化变革。面对这一时代呼唤，开源中国以「与时俱进」的姿态开启 AI 新程，推出&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面向开发者、终端用户与产业场景的 AI 应用共创平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟（ ai.gitee.com ）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟以全栈技术能力降低 AI 应用门槛，构建三大核心体系：技术基座通过多模态模型库、国产化算力优化和智能调度实现 「模型即服务」，配合低代码工具链加速开发；服务体系覆盖全链路商业化支持，提供安全合规的存储认证系统与企业级私有部署方案，推动金融、工业等垂直领域快速落地；开放生态通过 AI 审核分级、开发者收益倾斜和算力补贴机制，形成 "开发 - 反馈 - 迭代" 的创新闭环。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-9cc384e0174003faaf96509e8c548aa12fe.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#7f7f7f"&gt;100 层高楼已完成 90 层，模力方舟建立在 OSChina 与 Gitee 之上&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;12 载的坚守，有心酸、亦光荣！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在中国这片开源生态的土地上，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其实并没有如微软这样的顶级大厂，于资金上的猛烈加持，更多是如 Gitee 、模力方舟这样的「草根」搭台，一步一个脚印，深耕本土土壤，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;肩负起了中国软件工程基础设施建设的重任，筑牢了中国开源创新的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;过去十二年，Gitee 以学习为起点，在开源路上步步扎实；未来，Gitee 将以模力方舟为支点，在 AI 工程的新赛道上持续创新。从软件工程平台到 AI 工程平台，变的是技术形态，不变的是 「全心全意为开发者服务」 的初心。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在开源与 AI 交织的新远征中，Gitee 将继续扎根本土、拥抱世界，以自主创新的中国特色之路，为全球开发者贡献属于中国的开源力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4806939/blog/18688139</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4806939/blog/18688139</guid>
      <pubDate>Wed, 13 Aug 2025 02:42:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>智元发布行业首个机器人世界模型开源平台 Genie Envisioner</title>
      <description/>
      <link>https://www.oschina.net/news/366112</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366112</guid>
      <pubDate>Wed, 13 Aug 2025 02:21:00 GMT</pubDate>
    </item>
    <item>
      <title>Apache RocketMQ EventBridge：为什么 GenAI 需要 EDA？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;沈林，Apache RocketMQ PMC 成员，阿里云 EventBridge 负责人，专注于 EDA 研究。本文整理自作者在 Community Over Code Asia 2025 会议发表的主题演讲《Apache RocketMQ EventBridge: Why Your GenAI Needs EDA？》。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;EDA 的核心特点是：以事件为中心，实时响应变化。它不像传统"请求-响应"模式那样被动等待，而是"感知→触发→行动"全自动流转。在 AI 系统中，数据流、模型训练和推理、外部反馈等都可以作为"事件"，触发 AI 自动决策和联动执行。EDA 就像是 AI 时代的"神经系统"，让 AI 不仅能"思考"，还能"感知"和"行动"。它提升了系统的实时性、灵活性和自动化水平，是构建智能系统的关键支撑。AI 赋予系统"大脑"，EDA 构建系统的"神经"。&lt;/p&gt; 
&lt;p&gt;本文主要探讨在 AI 时代，EDA 的重要价值及它可以帮助我们解决的问题。&lt;/p&gt; 
&lt;h2&gt;EDA 的第一重价值：通过 RAG 缓解 AI 幻觉&lt;/h2&gt; 
&lt;p&gt;大家可能还有印象，2023 年上半年，Google 的早期 AI 模型发布时，回答一个关于詹姆斯·韦伯空间望远镜的问题时，犯了一个低级"错误"，这个答案本来在 Google 上很容易搜索到，但是 AI"一本正经"的给了一个错误答案，直接导致谷歌当天的股价跌了 8% 左右。但 AI 完全没有意识到自己的错误，这是为什么？&lt;/p&gt; 
&lt;h3&gt;1. 为什么会有 AI 幻觉？&lt;/h3&gt; 
&lt;p&gt;AI 幻觉的产生机制比较复杂，可简单从训练和推理两个阶段进行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;训练阶段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;数据覆盖不足&lt;/strong&gt;：若训练数据不包含特定信息，模型无法"无师自通"；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;过拟合&lt;/strong&gt;：模型过度学习训练数据中的细节与噪声，导致在面对新数据时泛化能力差；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;通用性与精度取舍&lt;/strong&gt;：通用大模型为覆盖广泛领域，在特定垂直领域的准确性可能有所牺牲。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;推理阶段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;自回归生成&lt;/strong&gt;：LLM（大语言模型）推理本质上是一个自回归过程，基于现有 Token 预测下一个最可能的 Token，这种概率性生成机制使得幻觉成为其固有潜在分布的一部分。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;连贯性优先于准确性&lt;/strong&gt;：GenAI 输出的时候倾向于生成流畅连贯的答案，而非绝对准确的答案。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 如何减少 AI 幻觉？&lt;/h3&gt; 
&lt;p&gt;为了解决 AI 幻觉，现在一般有三种主流的方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型微调（Fine-tuning）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;模型不好？最能直接想到的方法就是优化模型：丰富模型训练的数据、优化模型的参数，让其在垂直场景领域，回答更加精准。这种方式在很多场景是非常有效的，而且依旧被广泛采用。但是这种方式，要求也是比较高的，如果没有一定的人力和算力成本投入，将很难实现。尤其是在知识更新频繁的领域，模型需要不断调整，长期维护，投入代价相对较高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示词工程（Prompt Engineering）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以不调整模型，而是在向 LLM 提问的时候，把相关的数据和限定条件一起给到 LLM？答案是可以的，这就是提示词工程。&lt;/p&gt; &lt;p&gt;但是如何构造一个好的提示词，把 LLM 需要的上下文信息给到它，这个要求也是非常高的。不同人使用，提示词的构造水平也不同：这种方式就像是把"问问题"变成了一件"手工艺术活"。而且提示词优化虽然可以"压平"部分幻觉，但只要模型权重未变，提示词没有带上相关数据，提示词只能暂时把幻觉"藏"起来，而无法真正去除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;检索增强生成（RAG）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以自动帮我们生成一个高质量的提示词呢？在这个提示词中，包含了 LLM 回答需要的关键信息。这个就和我们最后一个要讲的 RAG 非常像了，让我们看下 RAG 到底是什么。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 什么是 RAG？&lt;/h3&gt; 
&lt;p&gt;RAG 可以简单理解为：向 LLM 提问的时候，同时给这个问题，检索一个上下文，一起给到 LLM。比如：如果我们问 DeepSeek：本次 Apache 峰会有哪些讲师聊到了 RAG 这个话题？DeepSeek 肯定不知道，因为它没有这个数据，网上暂时也还没有相关数据。但如果给到它一个关于本次大会讲师的讲稿资料包。这样 DeepSeek 就有非常强相关的上下文，回答问题的时候，就不会跑题答偏。&lt;/p&gt; 
&lt;p&gt;那 AI 要如何做到这一点呢？主要分两步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;建立索引&lt;/strong&gt;：首先，需要提前把讲师资料包存起来。但资料包可能非常大，我们需要快速找到跟提问的问题相关联的数据，这里就需要用到向量化。向量化本质上是对一个事物，从多个特征维度，进行数值标记。比如，标记我这个人，可以从年龄、身高、性别等多个特征标记，标记越多越清晰。如果两个向量在多维空间中的"位置"越接近，说明它们越相似。所以，我们需要提前把数据进行向量化，存到向量数据库里。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;检索生成&lt;/strong&gt;：然后，当我们向 LLM 提问时，可以先把问题向量化，根据向量化后的结果，去向量数据库查询关联性最大的原始知识数据。最后，将查到的知识数据，作为上下文和问题一起传给 LLM，LLM 就可以给一个更加准确的回答了。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-045b51500f01c2a85c12e955b7cd13f02bc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从这个过程中，我们会发现 RAG 有两个非常明显的优点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;不需要用知识库数据给大模型训练，既节省了成本，又保证了数据隐私；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不需要用提示词工程这样的"手工艺术活"，就可以让 AI 出现幻觉的概率变得足够低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 为什么 EventBridge 适合做 RAG？&lt;/h3&gt; 
&lt;p&gt;为什么是 EventBridge 适合来做 RAG 呢？ 我们先来看下什么是 EventBridge：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;EventBridge 的整个模型其实非常简洁：我们从下图左侧开始往右看，EventBridge 可以方便的把外部的数据，以标准化的事件格式，配合事件 Schema 集成到内部，中间可以存入事件总线（BUS），也可以选择不存储，然后通过过滤/转换，推送到下游服务中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;这个链路，正好可以满足 RAG 过程中需要的三要素：获取上游丰富的数据、自定义切分和向量化、持久化到多种向量化数据库中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73b0f09489921a9380a6cf55b6026f0ffb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;5. EventBridge 如何实现 RAG？&lt;/h3&gt; 
&lt;p&gt;用一个场景举例，比如我们想建一个关于 EventBridge 知识的智能问答机器人，可以回答关于 EventBridge 的常见问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;我们需要把存在上游 OSS 的 EventBridge 文档，通过 EventBridge 的事件流，进行 Chunk 切分、Embedding 向量化，然后存储到向量数据库；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成之后，当我们向 EventBridge 智能机器人提问"EventBridge 是什么？"，智能机器人会先把这个问题向量化，然后去向量数据库查找匹配度最高的相关内容，并一起传递给 LLM，LLM 就能结合查到的资料，给出非常精准的回答，减少幻觉产生。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-00e0291ba9dc0a5f24c08e141e6d17ebb3d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，阿里云大模型服务平台百炼的知识库 RAG 场景，已采用 EventBridge 的事件流能力，帮助众多客户减少了 LLM 问答中的幻觉问题，尤其在细分垂直领域效果显著。如果您感兴趣可以进行体验：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbailian.console.aliyun.com%2F%3F%26tab%3Dapp%23%2Fknowledge-base" target="_blank"&gt;https://bailian.console.aliyun.com/?&amp;amp;tab=app#/knowledge-base&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;EDA 的第二重价值：推理触发器（Inference Trigger）&lt;/h2&gt; 
&lt;p&gt;我们第二个想讨论的场景是推理触发器。&lt;/p&gt; 
&lt;h3&gt;1. 程序使用 LLM 的规模将远超人类&lt;/h3&gt; 
&lt;p&gt;目前，我们日常接触最多的 LLM 场景是人与 LLM 服务直接对话，如问 DeepSeek 一个问题或智能客服等。 但更常见且增长迅速的方式是程序触发 LLM。例如供应链优化和金融订单风控。&lt;/p&gt; 
&lt;p&gt;观察微服务就会发现，人调用 API 的量级远不如程序调用 API 的量级。相应地，我们可以想象，未来程序触发 LLM 的规模，也将远远超过人工使用 LLM。&lt;/p&gt; 
&lt;p&gt;这其中的机会，我们应该怎么把握？&lt;/p&gt; 
&lt;h3&gt;2. 推理诉求无处不在&lt;/h3&gt; 
&lt;p&gt;事实上，我们现有的商业系统中，已经存储了大量现成需要推理的场景。比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;消息服务里，存储了客户的评论，需要对其打标分析，这条评论是积极的还是消极的，并给个分数；&lt;/li&gt; 
 &lt;li&gt;DB 里存储了产品的描述介绍信息，想让 AI 给一些产品描述优化建议；&lt;/li&gt; 
 &lt;li&gt;OSS 或 S3 存储了大量的文档，想让 AI 对每个文档生成一个 100 字的文档摘要。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些诉求在以前可能需要人工处理，但现在都可以交给 LLM，从而极大提升工作效率。那怎么让现有的商业系统，方便、快捷、低成本的使用 AI，甚至不需要写一行代码，这个就是 EventBridge 擅长的地方了。&lt;/p&gt; 
&lt;h3&gt;3. 推理触发器：让模型被更好地使用&lt;/h3&gt; 
&lt;p&gt;为此，EventBridge 提供了三把武器：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f27bd8eda56c7eb4b1fe2a5c832ff70bbb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第一把武器------实时推理并将结果存到目标端：&lt;/strong&gt; 通过 EventBridge 可以实时监听并获取存在 DB、消息、或者存储服务中的数据，然后实时调用 LLM 推理服务，并将推理结果输出存到目标端。此过程也可以结合上一部分讲到的 RAG，但中间不一定是一个 LLM，也可以是一个 Agent，甚至是一个 AI Workflow。&lt;/p&gt; &lt;p&gt;这个过程看似简单，但有很多需要注意的地方：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;数据合并&lt;/strong&gt;：我们刚才聊到，LLM 的推理本质上是一个自回归过程，这次的输出会作为下一次的输入，无法一次性拿到结果，很多 LLM 只能支持以流式的方式返回数据，但下游往往需要的是一个确定性的结果，所以我们需要对流式数据进行合并再输出；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;数据格式&lt;/strong&gt;：很多业务场景下有明确的格式要求。比如上面提到的例子，让 LLM 对客户评论打标和评分，需要输出一个 JSON 结构。但不是所有 LLM 在 API 层面都支持 JSON 结构输出，我们需要通过提示词进行优化，让它尽可能输出一个符合要求的 JSON 结构。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;推理吞吐&lt;/strong&gt;：LLM 的自回归生成方式，导致单次请求 RT 长、TPS 低。所以，我们需要提升高并发能力，把昂贵的 GPU 资源使用效率发挥到极致，同时需要做好 TPM 和 RPM 的限流，也就是每分钟请求次数和每分钟 Token 数的限流，以保证链路不会有大量限流异常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以看到，具体落地会遇到很多挑战，但 EventBridge 可以帮助客户便捷高效地解决这些问题。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第二把武器------基于推理结果触发任务执行：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;除了让 LLM 推理输出结果存到目标端，EventBridge 还可以让 Agent 基于上游的某条消息，去调用某一个 Service，执行某一个动作，如发送邮件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第三把武器------离线异步推理提高资源利用率：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;对于实时性要求不高的推理场景，可以通过 EventBridge 实现离线异步推理，让稀缺的 GPU 资源被更好地调度利用，在云上的成本至少比实时推理便宜一半。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 的强大在于其应用，而 EDA（事件驱动架构）非常适合作为推理触发器，激活 AI 的价值。&lt;/p&gt; 
&lt;h2&gt;EDA 的第三重价值：构建 Agent 通信基础设施&lt;/h2&gt; 
&lt;p&gt;现在 AI Infra 非常热门，其概念非常广泛。对标 IT Infrastructure，我们这里讨论的话题是 AI 的通信。&lt;/p&gt; 
&lt;h3&gt;1. 微服务的通信离不开 Messaging，Agent 间的通信应该如何？&lt;/h3&gt; 
&lt;p&gt;在微服务时代，消息系统在微服务间的通信中扮演了重要角色。到了 AI 时代，消息系统是否依然起着关键作用？具体形式和产品又会有哪些变化？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c0ae2c687b84e25b6cf9a437040abeb17d4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;2. Agent 和 Service 的通信：Function Calling、MCP&lt;/h3&gt; 
&lt;p&gt;为了回答这个问题，我们先看下现在 AI 的通信是怎么做的。&lt;/p&gt; 
&lt;p&gt;首先，我们看下 Agent 和传统 Service 之间的通信。目前有两种主流的方式：Function Calling 和 MCP。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Function Calling：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 OpenAI 公司在 2023 年提出的。因为 LLM 本身是文本生成器, 不具备访问外部系统的能力。但是我们可以对 LLM 进行训练微调，让 LLM 理解外部的一些工具函数的定义，这样在遇到提问时，就可以按需生成这些工具函数需要的参数，然后调用这些工具函数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 2024 年 11 月 Anthropic 提出的，全称 Model Context Protocol‌，其本意是用来解决 LLM 无状态的问题。LLM 每次调用都是独立的，而 MCP 是用来给 LLM 提供运行上下文，相当于一个"Session 机制"。但是为什么 MCP 会被拿来和 Function Calling 放在一起呢？因为它也可以拿来调用工具函数。和 Function Calling 不同的是，它不需要 LLM 提前训练微调来理解函数的入参和返回值，而是通过上下文"提示词"告诉 LLM 参数返回值。所以 MCP 相比 Function Calling，对模型的依赖更小，更加通用，但效果相比 Function Calling 要差一点。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Agent 和 Agent 的通信：A2A&lt;/h3&gt; 
&lt;p&gt;我们再来看下 Agent 与 Agent 之间是怎么通信的。&lt;/p&gt; 
&lt;p&gt;Google 在今年 4 月份的时候，提出了一个 A2A 的通讯协议，其核心运行机制分为四步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：Client Agent 通过 Agent Card，看下远端 Agent 有哪些能力；&lt;/li&gt; 
 &lt;li&gt;第二步：根据 Agent Card 的能力描述，调用远端 Agent，创建一个 Task，让其帮忙完成一个任务；&lt;/li&gt; 
 &lt;li&gt;第三步：由于任务可能比较耗时，不一定能够立即响应。所以 A2A 协议允许远端 Agent 通过 SSE 协议，不间断的将任务的状态信息更新给 Client Agent；&lt;/li&gt; 
 &lt;li&gt;第四步：再将结果返回给 Client Agent，当然结果本身也是可以流式返回的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e2e33909d1e1fa5c7fb16b3509dba8dfa21.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;4. MCP 和 A2A 之间的区别&lt;/h3&gt; 
&lt;p&gt;那 MCP 和 A2A 协议有什么区别呢？Google 给它们的关系做了一个描述：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;A2A 协议像一种沟通语言：&lt;/strong&gt; 如果把 Agent 比做人，一个人如果能力有限，想让其他 Agent 帮忙怎么办？A2A 协议就可以派上用场了，A2A 协议像一种沟通语言，可以让 Agent 和其他 Agent 用同一种语言交流，不至于说话的时候驴唇不对马嘴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP 就像工具使用说明书：&lt;/strong&gt; Service 等价于人使用工具，可以提升人解决问题的能力。不过，使用工具也需要有些技巧，MCP 就像工具使用说明书，可以让 Agent 更方便的使用这些 Service，来扩展 Agent 的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-538598e9588c1dda1dac99334b8b440c970.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们把 Agent 比做人，把 Service 比做工具。但是，请人帮忙和请工具帮忙，真的可以分得这么清楚吗？&lt;/p&gt; 
&lt;h3&gt;5. 预测 1：A2A and MCP 可能走向融合&lt;/h3&gt; 
&lt;p&gt;A2A 和 MCP 的职责，设想很完美，但是实际运行的时候会遇到很多挑战。我们先来一起看看在 MCP 和 A2A 协议下，两者用来声明一个 Agent 或者 Service 能力的时候是怎么样的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这里举例了一个"查询北京天气"的服务，会发现两者声明自己能力的时候，非常类似：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c08367f12deb092a1cccd326b2b3ae2d53a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其次，两者的传输层协议也都非常相似，都支持 SSE 和 JSON-GRPC；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最后，我们从工程师开发角度，推演一个场景：当一个 Agent 需要获取"查询天气"的能力时，它并不真正关心该能力是由一个 Service 还是另一个 Agent 提供的。Agent 的核心关注点在于能力的接口定义：即有哪些可用能力、如何调用，以及预期的返回结果是什么。至于该能力的后端提供者是 Service 还是 Agent，对于调用方而言是无需关注的实现细节。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这里我们的第一个预测是：A2A and MCP 未来可能会合并，但具体怎么发展，还要看生态的选择。&lt;/p&gt; 
&lt;h3&gt;6. 预测 2: 点对点的通信是不够的&lt;/h3&gt; 
&lt;p&gt;这里的第二个预测是：现有 MCP 和 A2A 协议中，只包含的点对点通信是不够的。按照 A2A 协议的推演，当一个系统中有很多 Agent 时，所有 Agent 都通过"长连接"集成在一起：大家第一个直观的感受是什么？&lt;/p&gt; 
&lt;p&gt;连接太多了！ 如果两个 Agent 通过"长连接"集成在一起，感觉可能也没有什么。但是如果一个 Agent 同时需要和数百个甚至上千个 Agent 通信，系统中就会产生大量的长连接。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先对每一个 Agent 来讲，资源开销就非常大；&lt;/li&gt; 
 &lt;li&gt;其次，网状的连接，一旦某一个 Agent 出现问题，hang 住了某些资源，会不会拖垮其他 Agent 的服务？甚至拖垮整个系统？这类问题在微服务中，再常见不过了。&lt;/li&gt; 
 &lt;li&gt;最后，即使不会被出问题的 Agent 拖垮服务，但当这个出问题的 Agent 恢复时，之前的通讯是否依旧可以继续追踪？再次执行，是否已经幂等，是否有风险？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这里面有非常多的稳定、性能、成本、扩展性的挑战。这些问题在微服务中已经被多次验证过，有些经验我们可以学习过来。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-acaff61d3cd696e4c06caae076daf62ceb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;7. EventBridge Super Agent&lt;/h3&gt; 
&lt;p&gt;基于上面两个预测判断，我们给出了一个 RocketMQ EventBridge 的回答: 在这个模型中，我们引入了一个 EventBridge Agent Proxy 的角色。我们姑且称它为"Super"Agent ，但它不是一个真正的 Agent，而是可以代理 Agent 的能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，所有 Agent 都可以写一份自己的个人简历，把自己拥有的能力，注册到"Super"Agent 上；&lt;/li&gt; 
 &lt;li&gt;如果某个 Agent 需要调用其他 Agent 的能力，它可以在 "Super" Agent 中查找是否有其需要的 Agent。如果有，就可以直接通过与 "Super" Agent 的交互，来获得这个能力；&lt;/li&gt; 
 &lt;li&gt;当这个 Agent 需要多个其他 Agent 的能力时，也不需要和每一个 Agent 交互，都可以通过 "Super" Agent 代理实现，将原本的 N:N 模型简化为 1:1 模型。&lt;/li&gt; 
 &lt;li&gt;除此之外，"Super" Agent 中的 Proxy 除了 A2A 协议，还会路由和跟踪每一个 Task 的运行状态，即使在异常/重启/集群扩容等场景下，每一个 Task 都能被按预期处理，并把状态同步回 Agent。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;"Super"Agent 和微服务注册中心有点类似，不过区别在于，它不光是提供了微服务查找寻址的作用，同时还起到了服务代理的作用。如果我们脑洞再大一点，可以不仅局限于 Task 级别的任务追踪和管理，甚至还可以往上考虑一层，提供"User"级别的上下文：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我们现在的 Agent 都是没有记忆的，我们之前跟它说过的话，过几天再问它，它就不记得你了。&lt;/li&gt; 
 &lt;li&gt;但是每个人使用工具的习惯是不一样的。如果 Agent 能更好的理解你，记得你，就可以提供更加人性化的服务。&lt;/li&gt; 
 &lt;li&gt;作为 Agent 注册和代理中心，如果在为 Agent 提供代理的同时，还能同时提供"User"的上下文，并且用 Agent 的越多，"User"的身份画像越完善；反过来，Agent 越依赖，进入一个正向循环。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e0b899ea6d8383b99a2a6d186d58bca361a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，EventBridge Agent 代理还处于理论探索阶段，欢迎大家一起交流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参考文献与延伸阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Lewis et al., 2020]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Model Context Protocol (MCP) Specification, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[A2A: Agent-to-Agent Communication Protocol, Google, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apache RocketMQ EventBridge 官方文档：&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocketmq.apache.org%2F" target="_blank"&gt;https://rocketmq.apache.org/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;2025 杭州·云栖大会，来了！&lt;/p&gt; 
&lt;p&gt;9 月 24 日至 26 日，杭州·云栖小镇&lt;/p&gt; 
&lt;p&gt;三场重磅主论坛&lt;/p&gt; 
&lt;p&gt;超 110 场聚合话题专场&lt;/p&gt; 
&lt;p&gt;40000 平方米智能科技展区&lt;/p&gt; 
&lt;p&gt;点击&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyunqi.aliyun.com%2F2025%2Fticket%3FactivityId%3DNTQ1Ng%3D%3D%26ticketId%3DMTMy%26channelId%3DMzM0NA%3D%3D" target="_blank"&gt;此处&lt;/a&gt;免费注册领取云栖大会门票&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18688052</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18688052</guid>
      <pubDate>Wed, 13 Aug 2025 02:11:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>联想第一财季营收 1362 亿元，AI PC 市场份额领先全球</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;联想集团公布了截至 2025 年 6 月 30 日的第一财季业绩报告，显示出该公司在多个业务领域的强劲增长。报告显示，联想本季度实现营收 1362 亿元人民币，同比增长 22%，创下历史同期新高。此外，净利润也同比增长 22%，达到 28.16 亿元人民币，展现出企业盈利能力的显著增强。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="528" src="https://oscimg.oschina.net/oscnet/up-eeef33bdab809d7d5055d90415773e9216c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在具体业务表现方面，智能设备业务集团 （IDG） 营收为 973 亿元人民币，同比增长 17.8%。这一业务的运营利润率为 7.1%。在 PC 业务上，联想表现尤为突出，同比增长 19%，成为 15 个季度以来的最快增速。值得一提的是，联想在全球 PC 市场的份额达到了 24.6%，同样创下历史新高。同时，AI PC 的出货量超过整体 PC 出货量的 30%，在 Windows AI PC 市场中稳居第一。此外，在中国市场，具备五大 AI 特性的 AI PC 占到了笔记本总出货量的 27%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在智能手机业务方面，联想的营收为 162 亿元人民币，同比增长 14%。海外市场的表现也相当强劲，折叠屏手机的市场份额达到 51%，保持行业领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基础设施方案业务集团 （ISG） 的表现同样亮眼，营收达到 310 亿元人民币，同比增长 35.8%。其中，AI 基础设施业务的营收同比增长高达 155%，液冷技术方案收入也实现了 30% 的增长，显示出该领域的良好发展潜力。特别是在中国市场，ISG 的营收同比增长达 76%，运营利润率提升了 3 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;联想表示，当前 「超级智能」 正成为全球科技企业的新风口，这与其早前提出的 「混合式 AI」 战略相一致。联想在创新方面持续加码，本季度研发费用同比增长超过 10%，为未来的竞争力奠定了基础。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366100</guid>
      <pubDate>Wed, 13 Aug 2025 02:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
