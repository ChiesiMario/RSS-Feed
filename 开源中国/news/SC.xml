<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Fri, 07 Mar 2025 02:52:09 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>华为新笔记本被曝预装 Linux 系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，博主 @看山的叔叔发布动态，爆料称即将有五款笔记本新品问世。综合该博主以往爆料信息及图片中呈现的型号推测，此次爆料指向的大概率是华为笔记本。&lt;/p&gt; 
&lt;p&gt;据悉，这五款笔记本分别为 MateBook D14、MateBook D16、MateBook 14、MateBook GT 14 以及 MateBook X Pro，而这五款产品搭载的操作系统都是 Linux。&lt;/p&gt; 
&lt;p&gt;值得关注的是，这些笔记本或许并非严格意义上的全新产品。尽管已至 2025 年，但从图片信息来看，其仍将沿用 2024 命名。&lt;/p&gt; 
&lt;p&gt;这名博主还表示，&lt;strong&gt;如果用户有需要，华为店面可以帮助客户安装 Windows 系统，但只能是未激活版，需要用户自己想办法&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0307/103854_mi9H_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;早在去年 9 月，余承东就公开承认，Windows PC 可能要停止供货，以后就要用鸿蒙 PC 版了。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e9a3ffce642d457ff9d025ecacb32ccae06.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/256753&quot; target=&quot;news&quot;&gt;「鸿蒙之父」王成录：明年推出鸿蒙 PC 版系统&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337412</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337412</guid>
            <pubDate>Fri, 07 Mar 2025 02:42:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>因迁移云供应商，FreeDesktop.org 自建的 GitLab 服务将停机一周</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;FreeDesktop.org 近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.freedesktop.org%2Ffreedesktop%2Ffreedesktop%2F-%2Fissues%2F2076&quot; target=&quot;_blank&quot;&gt;发布公告&lt;/a&gt;，称其自建的 GitLab 服务将在本月底因迁移云供应商而关闭，持续时间可能长达一周。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0307/102742_EzWU_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;FreeDesktop.org 称其 GitLab 实例在 Mesa 图形驱动程序、Wayland 以及许多其他 Linux 桌面项目开发中至关重要。&lt;/p&gt; 
&lt;p&gt;由于 GitLab 实例的停机，Mesa 和其他依赖 GitLab 处理 PR、持续集成、错误报告，以及其他服务的 FreeDesktop.org 项目将暂停开发数日。计划迁移的起始日期为 3 月 16 日，预计将持续一周。&lt;/p&gt; 
&lt;p&gt;今年一月份，X.Org / FreeDesktop.org 遭遇了新的「云危机」——他们将在 4 月底失去 Equinix Metal 基础设施。这一基础设施曾由 Equinix 慷慨赞助，但现在即将消失，迫使 FreeDesktop.org 管理员迅速找到新的托管解决方案。&lt;/p&gt; 
&lt;p&gt;FreeDesktop.org 管理员已决定采用 Hetzner 服务器和 Fastly 作为 CDN。他们目前正在整理迁移计划，将所有数据从 Equinix Metal 迁移到德国主机 Hetzner。&lt;/p&gt; 
&lt;p&gt;当他们关闭 Equinix 托管的 GitLab 实例，备份所有数据，然后进行迁移时，将会开始停机。他们估计这个过程将从 3 月 16 日开始，持续一周左右，在此期间，这些项目的开发将实际上陷入停滞。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgitlab.freedesktop.org%2Ffreedesktop%2Ffreedesktop%2F-%2Fissues%2F2076&quot; target=&quot;_blank&quot;&gt;点此查看详细信息&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337407/freedesktop-down-1-week-soon</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337407/freedesktop-down-1-week-soon</guid>
            <pubDate>Fri, 07 Mar 2025 02:31:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Protocol Buffers v30.0 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Protocol Buffers 30.0 已经发布。Protocol Buffers（protobuf）是&amp;nbsp;Google 开源的语言无关、平台无关的可扩展机制，用于序列化结构化数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;具体更新内容包括：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;Announcements&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;此版本包括对以下内容的破坏性变更：Objective-C、Python、C++。&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[Objective-C] 删除旧版 WKT headers。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd9caebc313256ea2f5c6922113c1f3edf14b24ad&quot; target=&quot;_blank&quot;&gt;d9caebc&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 删除已弃用的 API。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F2a52b900a1b71d57fc68624a989145f57abefdf1&quot; target=&quot;_blank&quot;&gt;2a52b90&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 删除对旧生成代码的支持。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fcffa5902606ee3ebf23214b80251722b3654d5be&quot; target=&quot;_blank&quot;&gt;cffa590&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Objective-C] 删除 GPBUnknownFieldSet。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F2b93422f7eea500b26d1a9aaf7d07b3120f83d39&quot; target=&quot;_blank&quot;&gt;2b93422&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 修复版本下的封闭枚举验证（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F72b3eda2ec385863d7416f067f6cd0cefeed72bb&quot; target=&quot;_blank&quot;&gt;72b3eda&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 从 protobuf python cpp 扩展中删除已弃用的 GetDebugString()。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F721a45265b4e1d0f18d6775a0f1bafffdfc3088e&quot; target=&quot;_blank&quot;&gt;721a452&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 删除已弃用的反射方法 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F292f9646797d9e23fc66ba70fbda5903f2301ff0&quot; target=&quot;_blank&quot;&gt;292f964&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] 删除已弃用的 GetPrototype MessageFactory.GetPrototype()，(&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fc261b49a9575226efc9e5d269f6e5319a05d526e&quot; target=&quot;_blank&quot;&gt;c261b49&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] Python 嵌套消息类&amp;nbsp;&lt;strong&gt;qualname&amp;nbsp;&lt;/strong&gt;现在包含外部消息名称。（以前的&amp;nbsp;&lt;strong&gt;qualname 与嵌套消息的&lt;/strong&gt;&lt;strong&gt;名称&lt;/strong&gt;具有相同的结果，但不包括外部消息名称）（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F0720536eca20ca2f801127869d7f1211bceb3865&quot; target=&quot;_blank&quot;&gt;0720536&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 删除已弃用的 Python RPC Service Interfaces&amp;nbsp;(&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F5ba74b11e8d2bd5e9b22e972beb572668bf6191c&quot; target=&quot;_blank&quot;&gt;5ba74b1&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[Python] map field 的 Python setdefault 行为变更。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F81da6b999a8229942436f6c203a20633c65ebd26&quot; target=&quot;_blank&quot;&gt;81da6b9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[Python] 删除已弃用的 py_proto_library 宏。&lt;/li&gt; 
   &lt;li&gt;[C++] 禁止使用 Bazel+MSVC 构建 protobuf (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F117e7bbe74ac7c7faa9b6f44c1b22de366302854&quot; target=&quot;_blank&quot;&gt;117e7bb&lt;/a&gt;&amp;nbsp;)&lt;/li&gt; 
   &lt;li&gt;[C++] 删除已弃用的 Arena::CreateMessage。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd83a5365d16cff4be7da7d9a34eef14b24cc8733&quot; target=&quot;_blank&quot;&gt;d83a536&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 删除 CMake 子模块支持，转而支持获取或安装的依赖项。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F3f06ca4306a682e6ee631d8ea94b82baaafb14f0&quot; target=&quot;_blank&quot;&gt;3f06ca4&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 翻转处理 cmake 依赖项的默认行为。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F9cc685edf867acf5024a94502a3cbd7afa7a3daa&quot; target=&quot;_blank&quot;&gt;9cc685e&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 清除 arena 上的 oneof 消息后添加 ASAN poisoning。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F54d068e11c77ed387b97a60f435998b384e36e34&quot; target=&quot;_blank&quot;&gt;54d068e&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 将&lt;code&gt;type_name()&lt;/code&gt;和&lt;code&gt;cpp_type_name()&lt;/code&gt;的返回类型从&lt;code&gt;const char*&lt;/code&gt;升级为&lt;code&gt;absl::string_view&lt;/code&gt;。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fa9ad51f5b6a19eacc934bcb51db6282ec1fabb8c&quot; target=&quot;_blank&quot;&gt;a9ad51f&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 删除已弃用的 RepeatedPtrField::ClearedCount()。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fe8e3253f63f52d314af0e317d09642b9ceb1b40e&quot; target=&quot;_blank&quot;&gt;e8e3253&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 将若干字符串返回函数的返回类型升级为&lt;code&gt;absl::string_view&lt;/code&gt;。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fd1990d968a54176eb9f4229abe7f7c97ece50cec&quot; target=&quot;_blank&quot;&gt;d1990d9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 从 C++ 中的选项中删除 ctype（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Faebf8b9459f1da347a353c2fbbfe76230a457209&quot; target=&quot;_blank&quot;&gt;aebf8b9&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 在反射中删除&lt;code&gt;MutableRepeatedFieldRef::Reserve()&lt;/code&gt;（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F913f7b0c6d3c3e9876aea913b0d83bbd7fffe22c&quot; target=&quot;_blank&quot;&gt;913f7b0&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 删除已弃用的 JsonOptions 别名。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2Fe2eb0a19aa95497c8979d71031edbbab721f5f0a&quot; target=&quot;_blank&quot;&gt;e2eb0a1&lt;/a&gt;）&lt;/li&gt; 
   &lt;li&gt;[C++] 删除已弃用的 Arena::GetArena。（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Fcommit%2F30ed452eddacace2c3270dce9645b8f1f453ae4b&quot; target=&quot;_blank&quot;&gt;30ed452&lt;/a&gt;）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotobuf.dev%2Fnews%2F&quot; target=&quot;_blank&quot;&gt;Protobuf News&lt;/a&gt;&amp;nbsp;可能包括即将发生的变化的额外公告或预告。&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotobuf.dev%2Fsupport%2Fmigration%2F&quot; target=&quot;_blank&quot;&gt;迁移指南&lt;/a&gt;将包括针对破坏性变更的迁移指南（即将更新）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情可查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fprotocolbuffers%2Fprotobuf%2Freleases%2Ftag%2Fv30.0&quot; target=&quot;_blank&quot;&gt;https://github.com/protocolbuffers/protobuf/releases/tag/v30.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337406/protobuf-30-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337406/protobuf-30-0-released</guid>
            <pubDate>Fri, 07 Mar 2025 02:27:24 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源中国 2025 年战略部署会全揭密：AI 工具、AI 教育、AI 应用市场三箭齐发</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;p&gt;开源中国（OSCHINA）于近日圆满召开 2025 年战略部署会，正式公布未来核心增长路径——以&lt;strong&gt;模力方舟&lt;/strong&gt;为 AI 技术基座，通过 &lt;strong&gt;AI 工具、AI 教育与 AI 应用市场&lt;/strong&gt;三大业务矩阵协同发力，构建从底层能力支撑到场景化落地的全栈生态体系。&lt;/p&gt; 
 &lt;p&gt;作为战略核心的 Gitee AI 模力方舟，定位为 AI 模型即服务（MaaS）平台，为三大业务线提供通用 AI 能力支持。在此基座上：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 工具&lt;/strong&gt;板块以 Gitee SaaS 与私有化部署为双引擎，将软件工程全面升级为 AI 增强（AI Enhance）开发范式，实现项目管理、代码生成、智能测试、自动化运维的全链路提效；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 教育&lt;/strong&gt;依托 OSCHINA 社区、Gitee 平台与教育培训体系的深度融合，从 K12 少年培养到企业数字化人才赋能，贯穿技术普及、实践训练与认证输出的全生命周期；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 应用市场&lt;/strong&gt;聚焦打通 AI 技术到产业场景的「最后一公里」，通过汇聚开发者生态与企业需求，构建 AI 应用的部署与交易平台。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;这一战略架构以技术普惠为核心逻辑，模力方舟作为底层能力基座，通过标准化 AI 模型接口与开发工具链，降低技术应用门槛；AI 教育从内容生态、人才储备到技术认证，为行业输送适配 AI 时代的技术人才；AI 工具与 AI 应用市场则分别从生产力工具革新和场景化解决方案落地两端，形成「能力输出-需求匹配-价值闭环」的商业化链路。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;285&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100817_Vwaz_3820517.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; 工具：重构&lt;/strong&gt;&lt;strong&gt;软件工程&lt;/strong&gt;&lt;strong&gt;范式&lt;/strong&gt;&lt;strong&gt;，以 AI 增强驱动生产力革命&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;开源中国于 2013 年发布代码托管平台 Gitee，并于 2020 年开始牵头建设工信部国家开源托管平台项目。Gitee 于 2017 年上线发布针对企业级的研发效能平台 Gitee 企业版。截至目前，Gitee 已经服务 1350 万开发者用户、36 万家企业以及 2000 多家高等院校。&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;708&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100909_aJKN_3820517.png&quot; width=&quot;1644&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;2020 年以来，开源中国深耕 DevOps 全生命周期国产替代方案，在满足开发者需求的同时，打造出一个自主创新、安全可信的本土开源软件工具与生态，减少开发者对海外开源软件的过度依赖，构建安全可控的中国信息化体系。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;862&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/100934_EMQA_3820517.png&quot; width=&quot;1516&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p style=&quot;text-align:left&quot;&gt;在开源中国的战略蓝图中，Gitee 正从研发效能平台全面进化为「&lt;strong&gt;AI 增强型智能开发中枢&lt;/strong&gt;」。依托模力方舟的模型能力，平台深度整合 AI 技术至项目管理、代码开发、测试运维、流水线、效能洞察、文档管理、代码安全等全链路工具链，覆盖从需求设计到集成交付的完整生命周期。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;Gitee 以 AI Enhance 为核心，完成&lt;strong&gt;从研发效能平台到智能开发中枢的进化&lt;/strong&gt;。这一转型不仅解决了企业「降本增效」的迫切需求，更开启了「人机协同」的研发新范式——当 AI 深度融入每一行代码、每一次交付，技术普惠的愿景正在成为企业竞争力的基石。&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;AI 教育：从内容社区到人才生态的闭环布局，培养未来数字化创新力量&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;在开源中国的战略版图中，AI 教育不仅是技术普及的入口，更是撬动未来产业变革的支点。依托&lt;strong&gt;模力方舟 AI 技术基座、Gitee 工程实操基座与 OSCHINA 社区的生态势能&lt;/strong&gt;，开源中国正以&lt;strong&gt;「全周期、场景化、智能化」&lt;/strong&gt;为核心逻辑，通过&lt;strong&gt;「社区+平台+培训」&lt;/strong&gt;三位一体的协同模式，打造一站式全生命周期开源人才培养解决方案，重塑开源教育范式，构建从青少年启蒙到企业级赋能的终身教育闭环。&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;868&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101004_g3Uf_3820517.png&quot; width=&quot;1638&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;技术普惠：以社区+AI 平台构建学练用闭环，通过标准化工具降低学习门槛，实现人才供需精准对接。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;青少年启蒙：AI 驱动趣味化教学，结合开源项目实践，建立编程思维与开源意识双培养体系。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;高校赋能：「开源+AI」双引擎革新工程教育，AI 开发工具+国际认证体系推动产教深度协同。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;企业实战：AI 代码助手与模拟沙盘双轮驱动，打造人才能力升级系统，加速数字化转型进程。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;&lt;strong&gt;AI 应用市场：打通应用落地最后一公里，赋能百万 AI 开发者服务十亿用户&lt;/strong&gt;&lt;/h2&gt; 
 &lt;p&gt;Gitee AI 模力方舟将打造从模型开发到商业变现的一站式 AI 应用市场。平台通过&lt;strong&gt;技术基座、服务能力、开放生态&lt;/strong&gt;三大支柱，系统性解决 AI 应用落地难、成本高、场景碎片化的行业痛点，赋能百万开发者与企业无缝连接十亿终端用户。&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;1000&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101027_Vnm9_3820517.png&quot; width=&quot;1674&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;模力方舟以全栈技术能力降低 AI 应用门槛，构建三大核心体系：技术基座通过多模态模型库、国产化算力优化和智能调度实现「模型即服务」，配合低代码工具链加速开发；服务体系覆盖全链路商业化支持，提供安全合规的存储认证系统与企业级私有部署方案；开放生态通过 AI 审核分级、开发者收益倾斜和算力补贴机制，形成&quot;开发-反馈-迭代&quot;的创新闭环，推动金融、工业等垂直领域快速落地。平台以技术普惠和生态共赢为核心，实现从模型训练到商业转化的全流程赋能。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;img height=&quot;758&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101048_VScr_3820517.png&quot; width=&quot;1622&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;开源中国通过模力方舟 AI 应用市场，正在编织一张连接技术、产业与人的价值网络：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;对开发者&lt;/strong&gt;：这里是「零门槛创业平台」，100 万创新者将在此释放创造力；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;对企业&lt;/strong&gt;：这里是「数字化转型加速器」，30+ 行业的效率革命由此启动；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;对用户&lt;/strong&gt;：这里是「智能生活入口」，10 亿人将因 AI 享受到更便捷、更安全的服务。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;&lt;strong&gt;战略跃迁：从社区平台到 AI 驱动型技术服务商&lt;/strong&gt;&lt;/h2&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;img height=&quot;912&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/101112_REsn_3820517.png&quot; width=&quot;1630&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;p&gt;回望昨日，开源中国经历了从开源社区到代码托管平台，再到 DevOps 研发效能平台的演进，完成了从流量聚合到商业化闭环的蜕变。这一历程中，不仅为中国开源生态注入了活力，更推动了企业研发效能的规模化提升，验证了开源技术商业化的可行路径。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;而此次战略升级，标志着&lt;strong&gt;开源中国正式迈向「AI 驱动型技术服务商」的新阶段&lt;/strong&gt;：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;纵向贯通&lt;/strong&gt;：以教育培育生态、以工具提升效率、以市场兑现价值，形成从人才储备到技术落地的完整闭环。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;横向联动&lt;/strong&gt;：三大业务线数据互通、资源协同——社区教育为工具平台输送人才，AI 市场反哺开发者生态，工具迭代驱动教育内容升级，构建自循环的增长飞轮。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;社会价值&lt;/strong&gt;：通过降低 AI 使用门槛，助力中小企业与制造业、金融等传统行业实现智能化转型；以国产信创技术筑牢安全底座，推动自主可控的 AI 基础设施在政务、金融等关键领域落地，保障国家信息安全与产业链韧性，践行「技术普惠」初心的同时，扛起守护数字主权的时代责任。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;从推动每一行代码的创造力，到赋能千行百业的数字化转型，&lt;strong&gt;开源中国正以 AI 为杠杆，撬动技术商业化与产业智能化的双重革命&lt;/strong&gt;。这一进程，正在悄然重塑中国技术生态的未来图景。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337400/oschina-ai-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337400/oschina-ai-2025</guid>
            <pubDate>Fri, 07 Mar 2025 02:12:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>深圳拟设 500 亿元国资基金，聚焦人工智能、机器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;深圳国资官微发文称，截至 2024 年底，深圳国资打造了包括种子基金、天使基金、创投基金、产业基金、并购基金、母基金、S 基金、人才基金等在内的国资基金群，各类基金超过 500 支，基金总规模超 7000 亿元，投向战略性新兴产业和未来产业的资金规模超 90%，为培育发展新质生产力、实现高水平科技自立自强、塑造发展新动能新优势提供了有力支撑。&lt;/p&gt; 
&lt;p&gt;接下来，深圳国资国企接下来将聚焦「20+8」全产业链，打造全产业领域的科技创新基金网络，推动基金投向覆盖种子、天使、A 轮、B 轮、C 轮直至 IPO 的投资全生命周期，确保其中 A 轮及更早期的项目不低于 40%，投向 B 轮、C 轮项目均不低于 20%。&lt;/p&gt; 
&lt;p&gt;走访包括人工智能领域在内的初创企业覆盖不少于 10000 家，推进至立项尽调阶段企业不少于 1000 家，为战略性新兴产业及未来产业领域的科创企业提供不少于 100 亿元的创投资金支持。&lt;/p&gt; 
&lt;p&gt;聚焦人工智能、机器人等尖端科技领域，筹设规模不少于 500 亿元的涵盖科创企业全生命周期的国资基金。延长创新创业类基金存续期限最长至 15 年，针对不同基金，确定差异化考核指标、免责清单，不以单一项目亏损、单一时间节点为考核负面评价依据，按整个基金生命周期进行考核，助力投资机构更有底气、更加大胆地进行长期投资。更好发挥国有企业参与的各类投资基金作用，积极引进对接世界一流投资投行机构来深圳一起携手发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337399</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337399</guid>
            <pubDate>Fri, 07 Mar 2025 02:08:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌确认将在 6 月发布 Android 16</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.androidpolice.com%2Fandroid-16-is-on-track-for-june%2F&quot; target=&quot;_blank&quot;&gt;据 Android Police 报道&lt;/a&gt;&lt;/u&gt;，在 MWC 2025 上，Google 确认了将于 6 月发布 Android 16 系统。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f9b1b5f00ad73dac3341f293894653de0f1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Google 安卓生态系统总裁 Sameer Samat 在 MWC 2025 上透露，团队目前正全力以赴，目标计划在 6 月发布 Android 16 系统。&lt;/p&gt; 
&lt;p&gt;据悉，安卓 16 目前处于第 2 个测试版阶段。Samat 表示谷歌目前采用 Trunk Stable 开发模式，目的是缩短 Bug 修复周期，并加快新版本的发布，从而更快、更稳定地为用户提供系统支持。&lt;/p&gt; 
&lt;p&gt;Samat 强调，全球用户对安卓系统的功能和更新频率提出了较高要求。因此 Google 通过模块化和组件化改造安卓系统，让部分功能可以独立更新，从而无需等待操作系统版本发布。这一优化不仅提升了用户体验，也为开发者提供了更大的灵活性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337398/android-16-is-on-track-for-june</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337398/android-16-is-on-track-for-june</guid>
            <pubDate>Fri, 07 Mar 2025 02:06:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里通义千问大模型登顶全球开源社区榜首</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 6 日，全球最大的 AI 开源社区 HuggingFace 更新了大模型榜单，近期刚&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/337189&quot;&gt;发布并开源&lt;/a&gt;&lt;/u&gt;的阿里通义千问推理模型 QwQ-32B 成功登顶。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1856&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0307/095913_fror_2720166.png&quot; width=&quot;3360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，目前 QwQ-32B 居于榜单第一，超越微软的 Phi-4、DeepSeek-R1 等模型。&lt;/p&gt; 
&lt;p&gt;据了解，QwQ-32B 在数学、代码及通用能力上实现质的飞跃，用更小参数实现整体性能比肩 DeepSeek-R1，并突破性地让高性能推理模型在消费级显卡上实现本地部署，大幅降低了模型应用成本。&lt;/p&gt; 
&lt;p&gt;在一系列权威基准测试中，QwQ-32B 模型表现异常出色，几乎完全超越了 OpenAI-o1-mini，比肩最强开源推理模型 DeepSeek-R1。其中，在测试数学能力的 AIME24 评测集上，以及评估代码能力的 LiveCodeBench 中，QwQ-32B 表现与 DeepSeek-R1 相当，远胜于 o1-mini 及相同尺寸的 R1 蒸馏模型。&lt;/p&gt; 
&lt;p&gt;目前，QwQ-32B 已在魔搭社区、HuggingFace 及 GitHub 等平台基于宽松的 Apache2.0 协议开源，所有人都可免费下载模型进行本地部署，或者通过阿里云百炼平台直接调用模型 API 服务。同时，用户也将可通过通义 App 免费体验最新的 QwQ-32B 模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337397</guid>
            <pubDate>Fri, 07 Mar 2025 02:02:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>全球生成式 AI 应用 TOP 100 榜单公布：ChatGPT 第一、DeepSeek 第二</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日凌晨，全球著名风投机构 Andreessen Horowitz（简称 a16z）发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fa16z.com%2F100-gen-ai-apps-4%2F&quot; target=&quot;_blank&quot;&gt; 2025 年全球生成式 AI 应用前 100 排行榜&lt;/a&gt;&lt;/u&gt;，具体榜单共分为前 50 生成式 AI 应用（网页端）和前 50 生成式 AI（移动端）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7d73d8d52a68d2960c0ac00889b11ac8fcd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-01d42658a902ad470941487df69be866195.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中，&lt;strong&gt;DeepSeek 在网页端中排名第二&lt;/strong&gt;，其凭借 1 月开源自家 DeepSeek-R1 模型，在全球引起巨大热议，仅用 20 天便达成一千万用户的突破，比排名第一的 ChatGPT 快了近一倍（ChatGPT 打破一千万用户耗时 40 天）；而 ChatGPT 凭借 4 亿的周活跃用户和 1.75 亿的移动端用户，在网页端、移动端排名双第一。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4466873abf7caaeeb5f4830cc940aa317a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1e35e6512d78eb66212ae92f3de8bf40669.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，中国其他知名大模型也进入了该排行榜：字节跳动的豆包排名第 10；月之暗面排名 11；海螺视频排名 12；快手可灵排名 20，全部超过了 Sora、Midjourney、Runway 等知名产品。在移动端中，百度 AI 搜索排名第 4；夸克 AI 第 6；豆包排名第 7；DeepSeek 排名第 14。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337396/a16z-100-gen-ai-apps-2025</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337396/a16z-100-gen-ai-apps-2025</guid>
            <pubDate>Fri, 07 Mar 2025 01:51:38 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源中国马越：DeepSeek 不是国运级的创新，年轻人才是</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;「你很难要求大家还没吃饱喝足的情况下，去做开源。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果说关于 DeepSeek 的讨论已经过于泛滥，开源也许是当下依然值得讨论的主题。&lt;/p&gt; 
&lt;p&gt;长期以来，在国内谈起「开源」，都会无可避免地陷入一种尴尬的语境。&lt;/p&gt; 
&lt;p&gt;它当然是理想主义的。「开源」背后的自由、开放特性，被普遍认为是互联网精神的外化——源代码向公众开放共享，且允许在遵循特定许可证条款的前提下，对软件进行自由使用、修改和二次分发。&lt;/p&gt; 
&lt;p&gt;最知名的开源项目「Linux」是操作系统的内核，催生了数以千万计的开源软件，这是互联网世界的根基。&lt;/p&gt; 
&lt;p&gt;但它的背后经常跟着一个问题：为什么要开源？怎么考虑开源之后的商业化？哪怕到 DeepSeek 爆火的现在，也很难有人给出完美的答案。&lt;/p&gt; 
&lt;p&gt;开源中国董事长马越，是最有立场谈国内开源历史的人之一，他在这条路上走了 18 年。&lt;/p&gt; 
&lt;p&gt;2008 年，马越从硅谷回国创业，先是成立了「恒拓开源」——用开源软件帮助企业摆脱数据库、ERP 等大型软件的束缚。&lt;/p&gt; 
&lt;p&gt;但很快他就发现，这种方案很难摆脱 To B 项目制的重投入，还很容易做成外包公司。&lt;/p&gt; 
&lt;p&gt;随后，马越选择收购「开源中国」这个社区，开始了一段曲折的创业路——「开源中国」经历过数度转型，从开源社区，拓展到代码托管、代码工具链，在探索商业化期间，经历了从母公司剥离独立发展，2019 年被百度战略控股，最后，又在中美竞争、国产替代浪潮中决定重新独立发展，谋求上市。&lt;/p&gt; 
&lt;p&gt;做开源社区需要大量的资源、资金投入，在开源中国最艰难的时候，马越揹负的个人债务最高达 1.8 亿元。&lt;/p&gt; 
&lt;p&gt;1972 年出生的马越，有着一种老大哥式的坦率。他绝没有卖苦的意思，但你很容易从他的敍述中，体会到经历这些坎坷过后的幽默——他表示，在中国做 To B 就是「城市包围农村」，企业软件就是管理者智慧的固化。当中国的企业发展阶段还在初期，「你很难要求大家还没吃饱喝足的情况下，去做开源。」&lt;/p&gt; 
&lt;p&gt;但这些时刻都已经过去了。开源中国也已经摸索出一条更适合自己的、中国式的开源道路。&lt;/p&gt; 
&lt;p&gt;现在，开源中国已经成为全球第二大的代码托管平台，汇聚了超过 1800 万开发者。其自主研发的 DevOps 工具链已在金融、军工等关键领域，达到 80% 的市场渗透率。2024 年，开源中国的营收已超过 2 亿元。&lt;/p&gt; 
&lt;p&gt;《智能涌现》获悉，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/337301/oschina-series-c-funding-round&quot;&gt;「开源中国」近期正式完成数亿元 C 轮融资&lt;/a&gt;&lt;/u&gt;，由北京信息产业发展投资基金（北京信产基金）领投，深报一本股权投资基金（深报一本）及北京上河动量私募股权基金（上河动量）跟投。&lt;/p&gt; 
&lt;p&gt;至此，开源中国已累计获得超 16 亿元战略投资。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0306/194426_EaKH_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;△开源中国董事长马越&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;马越认为，哪怕在全球范围内，开源也不是件容易的事情。他以 GitHub 举例：从 2008 年成立开始直到被微软收购，在 2022 年 ChatGPT 爆发后推出 Copilot，才算是正式证明了商业化潜力。&lt;/p&gt; 
&lt;p&gt;「开源是强者和富人的游戏。」他说，上一代人都成长在物质更短缺的年代——商业社会也是如此，企业要先赚够了钱，才有余裕考虑是否开源，做一些人人为我、我为人人的好事。「吃饱了饭，才能有力气谈开源。」&lt;/p&gt; 
&lt;p&gt;这就不难理解，即使 DeepSeek 的爆火为全中国都打了一记强心针，马越的观点依然是冷静的。他认为，DeepSeek 很难根本性改变国内软件生态的问题，这是一个时代的局限。&lt;/p&gt; 
&lt;p&gt;而想要在开源路线上有所成就，这要求新一代的开发者，从 Day 1 就开始出海，像 DeepSeek 一样去全球市场中竞争。&lt;/p&gt; 
&lt;p&gt;如果说 DeepSeek 改变了什么，更多的都是文化和价值观层面的事情。「十年前大家普遍不理解开源，觉得开源是一群草根做的事，现在全社会都能认识到，开源等于创新。」马越说。&lt;/p&gt; 
&lt;p&gt;以下为《智能涌现》与开源中国董事长马越的对话，经编辑：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;DeepSeek 不是国运级产品，年轻人才是&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：开源中国现在是第二大代码托管平台，国内最大的开源社区。DeepSeek 的热潮，对你们的直观影响，是从什么时候开始的？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：就是他在 App Store 登顶那会儿。先是 V3，然后是 R1 发布，一下子就火起来了。我们春节一直在加班，让 DeepSeek 首先能在中国生产的 GPU 上运行，这需要大量工作，我们是第一个在沐曦芯片上部署的。&lt;/p&gt; 
&lt;p&gt;我们都在调侃，春节就两件事：DeepSeek、哪吒。DeepSeek 就是开源圈出了个哪吒。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：现在已经形成了一种论调：DeepSeek 是一个国运级的产品。但最近你的公开表达里，似乎对这一点不太认同。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：首先，大模型这个事情，你离不开英伟达吧？其次，你离不开 Transformer 架构；第三，你采用了蒸馏的思路，这些都不是国内原创的。&lt;/p&gt; 
&lt;p&gt;DeepSeek 本质上是在现有路线上走得最好，实现了弯道超车，这是值得尊敬的。&lt;/p&gt; 
&lt;p&gt;但是 DeepSeek 能够不依靠外部资金支持，也不做任何 PR，靠技术就能做到全球顶尖——以梁文锋为代表的年轻人崛起，这才是国运级的现象。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：那什么才算国运级的产品？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：完全原创的技术创新。谁说 Transformer 就是算法的终局？如果有人用非 Transformer 方案做出比 DeepSeek 强十倍的成果，那才是真正的突破，那是人类级的进步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 给开源生态最大的启示会是什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：让全社会认识到：开源等于创新。&lt;/p&gt; 
&lt;p&gt;DeepSeek 最令人唏嘘的是，在国内两年都默默无闻，也不如打广告的很多大模型公司，直到 2024 年开始，才因为技术，因为开源，被美国人超级关注——虽然一部分人特别支持，一部分人极力贬低，这种关注反而倒逼着国内形成了一种爱国情怀。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：以前大家不相信这个观点吗？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：以前很多人认为开源就是一帮草根、乌合之众，很难和大厂这种正规军相比。&lt;/p&gt; 
&lt;p&gt;其实二十年前我就在说这些话：开源约等于创新能力，创新能力和国力是映射关系。正是因为我们有钱了、富足了，才会有 DeepSeek 这样的企业出现。&lt;/p&gt; 
&lt;p&gt;以前没人听，现在有人听了。&lt;/p&gt; 
&lt;p&gt;第二点很重要，就是要对年轻人保持敬畏。不只是尊重，而是要怕年轻人，信任年轻人。每一代人都有自己的时代使命，也有时代局限性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：这群年轻人，或者新一代开源贡献者，为什么能成长起来？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：这种质变是建立在之前充分的量变基础上的。&lt;/p&gt; 
&lt;p&gt;这十年要感谢走在前面的互联网大厂，事实上国内的主要开源力量集中在这些有实力的企业上。包括百度、阿里、腾讯等组织的开源项目，还有华为的鸿蒙、欧拉等等。他们都是领着工资的员工，在搞这些开源工作，不是纯粹基于兴趣。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 证明一件最关键的事：通过底层技术突破，就能吸引大量用户，以及赢得尊重。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：现在我们国家最应该做两件事：一是牵头一起开发中国的 CUDA；二是让所有国产 GPU 都能快速支持这些模型。&lt;/p&gt; 
&lt;p&gt;说到生态，生态就是要有更多的人参与，而且大家都有高度共识。现在最大的问题不是芯片卡脖子，而是 CUDA 这个生态的制约。中国完全可以开发一套类似 CUDA 的系统，就像我们有自己的 GPU 一样。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源是富人和强者的游戏&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 爆火之后，找你讨论的人多吗？大家最关心什么话题？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：有人问我，DeepSeek 会不会给中国 To B 市场带来新生机？不可能那么快。&lt;/p&gt; 
&lt;p&gt;IT 外包的人天价格，20 年来的涨幅还不如按摩师。现在外包人天均价一千就算高的了，还有五六百的。你去按摩，现在一小时都要一两百块钱。十年前，IT 的外包时薪就比不上按摩了，现在差距更大，那是因为按摩价格涨得快。&lt;/p&gt; 
&lt;p&gt;中国软件没人愿意花钱，这是行业发展还不行的核心原因。要等这一代年轻人变成决策者，好时代才会来。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：本质还是因为国内企业发展阶段还比较早。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：开源本质上是强者和富人的游戏。正是因为我们吃饱喝足了，才会有 DeepSeek 这样的企业出现。上一代互联网用户普遍不愿意为软件和知识付费，腾讯会议掉线了就重连，也不愿意买会员。&lt;/p&gt; 
&lt;p&gt;但这一代年轻人生活富足，你们会改变这个局面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 会给上一代 To B 创业者带来什么启示吗？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：我觉得他们给创业者带来两个重要的启示。第一是要对钱保持敬畏。创业的目的就是为了挣钱，谈理想和情怀没意义。&lt;/p&gt; 
&lt;p&gt;DeepSeek 不太需要考虑商业化的问题，是因为幻方已经解决了这个事情。&lt;/p&gt; 
&lt;p&gt;上一代的软件创业者有个致命问题，一心想着烧钱，通过标准化产品打市场，这不是中国市场的运行逻辑，中国最有钱的金主都是大型企业，在中国想要赚钱，不做定制化是不现实的。&lt;/p&gt; 
&lt;p&gt;中国软件行业是城市包围农村，而美国是农村包围城市，腰部企业数量很多。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 会改变大家对商业化的看法吗？开源怎么考虑商业化，是这个领域的「天问」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：如果要开源做创业项目，技术必须得硬邦邦。就是和 DeepSeek 一样，Day 1 就出海，否则在中国太难赚钱了，时代还不够成熟。&lt;/p&gt; 
&lt;p&gt;大家总是会举例，比如红帽那套模式也能商业化，但是想用这种方式在中国做一个上市公司，还不是这个时代的事。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：你们自己也经历了很长一段商业化探索的时期，是从什么时候想明白要怎么做的？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：2020 年是个重要转折点。我们那年决定从百度独立出来，重新谋求 IPO。那段时间因为美国开始在很多尖端技术上断供，我们想抓住这个机会，真正成为一个独立的开源平台。&lt;/p&gt; 
&lt;p&gt;想要做真正的本土开源平台，必须要是彻底中立的第三方，这是选择重新独立发展的核心原因。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：想明白之后，都做了什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：我们现在从社区发展出了三大产品线。&lt;/p&gt; 
&lt;p&gt;开源中国社区（OSChina）现在已经完全进化成一个 AI 教育平台。我们是中国最大的开源社区，有 1000 多万用户。现在我们 24 人的团队能创造约 5000 万收入，还有净利润，这在社区团队中很少见。&lt;/p&gt; 
&lt;p&gt;第二块是代码托管和研发效能平台 Gitee，现在平台有 3600 万个代码仓库，服务 36 万家企业。主要提供代码托管私有化仓库服务，确保很多中小团队的代码安全，客单每年 3000 块左右。&lt;/p&gt; 
&lt;p&gt;从 2020 年到现在，我们已经能够提供 DevOps 全生命周期国产替代方案，在满足开发者需求的同时，也建立起一个自主创新、安全可信的本土开源软件工具与生态。&lt;/p&gt; 
&lt;p&gt;第三块是 AI 大模型平台「模力方舟」，模型体验、推理训练到应用部署等等服务，都会提供。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：为什么会从社区拓展到后来的 DevOps，以及 AI 大模型基座？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：一个开源公司想要成功，靠社区是不够的，我们需要找一个闭环的商业模式，像 GitHub 那条路——社区、代码托管是没法达到这个目标的。GitHub 也是在大模型浪潮来了之后，推出 Copilot，才把营收做起来。&lt;/p&gt; 
&lt;p&gt;以后没有净利润的公司很难在国内上市，所以我一直强调看毛利率和人效，这两个指标高了，自然会有净利润。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：你们现在的主要收入，来自哪里？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：我们主要收入来自 100 家左右的银行、券商、军工、制造业客户，都走大型私有部署形式。中小客户主要靠 SaaS 服务。&lt;/p&gt; 
&lt;p&gt;2024 年我们全国订单超过 2 亿，是一个突破。前年过 1 亿，2024 年翻了一倍，还实现了盈亏平衡，这很不容易。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：主要模式靠服务大型企业的话，怎么避免走到项目制的老路？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：我们的产品做得很复杂，是因为中国的大型企业的场景复杂。我们的流程引擎、角色引擎、交互界面、流水线都是可定制的，还能做各种插件，就是为了保证灵活性。&lt;/p&gt; 
&lt;p&gt;我们会帮客户做定制化配置，但是不做二次开发。我们现在 330 多人，这块业务占 200 多人，但定制化去做开发和交付的不到 10%。&lt;/p&gt; 
&lt;p&gt;第二是我们自己坚决不卖算力，只做第三方，比如给云厂商导流。&lt;/p&gt; 
&lt;p&gt;我们现在的路线很清晰：前端社区承载大流量，做开发者工具卖给企业，先 To C，再 To B，也算是一种产品驱动增长（Product-Driven Growth）的模式。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;一起发展，比单打独斗强&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：是否选择开源，企业的考量到底是什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：现在大模型不开源很难。苹果为什么到今天 iOS 都不开源？因为硬件生态已经形成垄断。如果没有类似这样的护城河，你不开源，凭什么在市场立足？&lt;/p&gt; 
&lt;p&gt;就像我十几年来一直说的，开源是创新的最佳方法论，也是市场竞争的方法论，是反强权的方法论。你做得好，我们就开源来和你竞争。当年有 Unix 和 Windows，就有 Linux；有 iOS，后来就有 Android，都一样。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：你做过很多并购，DeepSeek 的成功会改变投资人对开源项目的看法吗？开源项目的出路会变得宽吗？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：这也是我想问所有投资人和创业者的问题：投资的目的是啥？到底你希望怎么赚钱？&lt;/p&gt; 
&lt;p&gt;上市、被收购、分红都是一种退出方式。但现在在国内，要么 IPO，要么死掉，这很残酷。&lt;/p&gt; 
&lt;p&gt;中国的开源生态很分散，现在很多创业者缺乏一种共识，就是一起发展比单打独斗强。很多人把创业当作获取情绪价值的方式，就想当老大，宁可公司死也不愿意卖给别人。觉得卖了就是投降，这坎儿过不去。&lt;/p&gt; 
&lt;p&gt;如果放不下自己的 ego，最终就会害了自己，也害了客户和投资人。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 大获成功之后，你怎么评估现在我们所处的 AI 发展阶段？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：如果类比互联网那个时代，我们还是在大时代的开端状态，类似当年的拨号上网阶段。我从 1997 年开始上网，下载一张照片要四五天，网速只有 28K。但即便如此，我们也觉得很神奇。&lt;/p&gt; 
&lt;p&gt;现在就像出海探索新大陆，所以创业者只要带着干粮上了船，不淹死，就一定有收获。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：DeepSeek 会怎么改变现在国内的创业格局？你觉得更利好大厂还是创业公司？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：很难说，可能还是大厂比较有优势。&lt;/p&gt; 
&lt;p&gt;首先，DeepSeek 不是一个创业公司，人家不用外部资金就能买一万张卡，某种程度上也算个小大厂了。&lt;/p&gt; 
&lt;p&gt;我觉得 DeepSeek 给创业者带来两个重要的启示。第一是要对钱保持敬畏。创业的目的就是为了挣钱，谈理想和情怀没意义。&lt;/p&gt; 
&lt;p&gt;初创公司除非在算法、技术底层有突破，否则在工程层面，很难跟大厂拼数据，拼流量，这是最终商业化的两个要素。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：现在的大模型初创的转向都很明显，方向聚焦，专心做底层技术。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：这就是开源的可怕之处。&lt;/p&gt; 
&lt;p&gt;我前年就说，预训练是大厂的游戏，创业公司应该做垂直领域的训练，把更多精力放在推理上，烧钱的事情本来就不该做。&lt;/p&gt; 
&lt;p&gt;历史上都有很多例子，当年开源领域有很多做容器的公司，比如 Docker 刚出来时只是各种容器运行时技术中的一种。结果 K8s 生态起来之后，任何容器技术只要实现 K8s 兼容性，就可以融入云原生技术栈，这种强大的生态整合能力最终使其它技术方案逐渐边缘化，相当于前边都白做了。&lt;/p&gt; 
&lt;p&gt;所以我给大家的建议，包括我们自己的策略，就是产品功能要紧跟随，但要轻投入，商业模式要做轻一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;《智能涌现》：对开源中国来说，未来的目标会是什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;马越&lt;/strong&gt;&lt;/span&gt;：开源中国这十几年，积累了用户流量护城河，客户品牌美誉度，现在是通过信创找到了快速增长的收入模式。&lt;/p&gt; 
&lt;p&gt;我们在这轮融资之后，也会开始寻求进一步上市，希望成为 A 股人工智能开源第一股。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEY_NhbMX94bk6op8GDuG6g&quot; target=&quot;_blank&quot;&gt;《对话开源中国马越：DeepSeek 不是国运级的创新，年轻人才是》&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337320</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337320</guid>
            <pubDate>Wed, 05 Mar 2025 11:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>支持函数导入/导出，新增支持变量赋值节点，MaxKB 知识库问答系统 v1.10.2 LTS 版本发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;2025 年 3 月 6 日，MaxKB 开源知识库问答系统正式发布 v1.10.2 LTS 版本。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 MaxKB v1.10.2 LTS 版本中，&lt;strong&gt;函数库&lt;/strong&gt;方面，MaxKB 支持函数的导入/导出；&lt;strong&gt;应用&lt;/strong&gt;方面，新增支持「变量赋值」节点；&lt;strong&gt;模型管理&lt;/strong&gt;方面，MaxKB 新增支持 Ollama 供应商的重排模型。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;X-Pack 增强包&lt;/strong&gt;方面，MaxKB 应用接入功能支持 Slack。目前，MaxKB 支持对接的第三方应用包括企业微信、公众号、飞书、钉钉以及最新的 Slack。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;此外，MaxKB 开源项目组还进行了超过 40 项功能更新和问题修复。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;感谢广大社区用户的反馈和支持，MaxKB 期待与您携手创造更加美好的未来。&lt;/p&gt; 
&lt;h1&gt;亮点更新&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 支持函数导入/导出&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增函数的导入/导出功能，从而实现了函数模块在不同环境之间的无缝迁移。这一功能进一步方便了用户的函数共享过程，提升了系统的灵活性与实用性。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f196ce183a6e9256792ceea1be65b89695.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;▲图 1 MaxKB 支持函数导入/导出&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 新增支持「变量赋值」节点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增支持「变量赋值」节点。该节点为用户提供更为便捷的方式来更新工作流编排中的变量值，能够显著提升用户在配置和管理流程时的灵活性与效率。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;626&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1dfcf722f328519c2abb120eb726d5c46f1.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;▲图 2 MaxKB 新增支持「变量赋值」节点&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 新增支持 Ollama 供应商的重排模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 版本中，MaxKB 新增支持 Ollama 供应商的重排模型。目前 MaxKB 已经支持 Ollama 供应商提供的大语言模型、向量模型、视觉模型和重排模型，为用户提供了丰富的模型选择。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ad23e7ada247c9dfdcf55de68ffc8212e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;▲图 3 MaxKB 支持 Ollama 供应商的重排模型&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■ 应用接入支持 Slack（X-Pack 增强包）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;在 v1.10.2 LTS 专业版中，MaxKB 的应用接入功能新增支持接入 Slack。目前，MaxKB 支持对接的第三方应用包括企业微信、公众号、飞书、钉钉以及最新的 Slack，帮助企业将大模型能力快速注入原有业务系统，加速 AI 赋能业务的进程。&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;637&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c346e08537ec1f877de06169eb13f652e12.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;▲图 4 MaxKB 应用接入 Slack 配置页面&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;功能优化&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用（X-Pack）：开启思考过程后，优化在企业微信、飞书、钉钉、公众号中的回复过程；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用（X-Pack）：企业微信对话时支持上传图片；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用（X-Pack）：登录认证的 OIDC 设置支持配置&lt;em&gt;scope&lt;/em&gt;参数；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：支持创建空白应用；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：用户输入的参数新增支持密码框和开关组件；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：用户输入支持自定义标题；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：表单收集节点的参数新增支持密码框组件；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：上传音频文件类型新增 m4a 格式；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：通过调用应用 API Key 的方式进行对话时，支持上传文件参数；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：通过调用应用 API Key 的方式进行对话时，支持输出思考过程参数；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：基础信息节点中的用户输入表格中的参数，支持拖拽式调整顺序；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：判断器中的条件值支持变量解析；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：在多路召回节点的「执行详情」对话框中，优化分段显示内容（包含分段标题、文档和知识库）；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：当用户退出工作流编辑时提示用户保存数据；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：关联知识库引用分段数的最大值调整为 10000；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：高级编排中修改节点名称的操作修改为「…」→「重命名」；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;应用：单一图片生成节点生成多张图片时横向排列图片；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：优化问答页面布局为左右布局，左侧显示 AI 回答，右侧显示用户问题；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：优化用户打开问答页面时，显示历史对话记录；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：优化语音播放时仅播放最后一个内容；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：支持修改会话标题；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：支持执行生成问题失败的分段继续生成问题；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：支持为文档列表排序；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;知识库：支持在生成问题中使用&lt;em&gt;{title}&lt;/em&gt;变量获取分段标题；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;函数库：查询函数时忽略大小写；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：查询模型时忽略大小写；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;团队成员：查询成员时忽略大小写；&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系统：优化第一次登录时耗时较长的问题。&lt;/p&gt; 
&lt;h1&gt;问题修复&lt;/h1&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复 AI 回复内容中的图片无法放大的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复高级编排中的提示词窗口放大后编辑内容，按 ESC 键关闭窗口后不保存提示词的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复使用 vLLM 供应商大语言模型进行对话时，部分情况下回答无法结束的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复使用 Kimi 供应商的大语言模型进行对话时，Tokens 计算不准确的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复图片生成节点切换模型后参数设置未更新的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复当 Excel 表格中含有合并单元格的数据时，读取时会缺少数据的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复 OpenAI 调用格式没有思考过程参数的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复应用子节点中若有非必填参数，在父级应用中若未设置该参数，对话时会报错的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;应用：修复 Ollama 供应商的大语言模型使用&lt;/span&gt;&lt;em&gt;&lt;span&gt;num_ctx&lt;/span&gt;&lt;/em&gt;&lt;span&gt;参数时，进行对话会报错的问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;问答页面：修复在历史对话记录中，无法使用浏览器进行语音播放的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：修复问题框中无法在内容中间插入换行的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面：修复部分情况下会在文档的 URL 地址后面自动加上「/」，导致无法访问的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;问答页面（X-Pack）：修复显示设置中关闭历史记录后，问答页面的新建对话不显示的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;函数库：修复函数返回值为 0 时，调试时的输出结果显示错误的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：修复添加阿里云百炼的大语言模型时，如果是全模态模型提交会报错的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;模型设置：修复添加 Azure OpenAI 的 DeepSeek-R1 模型报错的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系统设置（X-Pack）：修复 Swagger 文档中接口参数显示不全的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系统设置（X-Pack）：修复在「外观设置」中设置「网站名称」后，问答页面的标签处不显示应用名称的问题；&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;■&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;系统设置（X-Pack）：修复登录页面加载时，默认 Logo 会闪现的问题。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337319/java-maxkb-1-10-2-lts-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337319/java-maxkb-1-10-2-lts-released</guid>
            <pubDate>Wed, 05 Mar 2025 11:49:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源中国完成数亿元 C 轮融资，迈向「开源 AI 第一股」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源技术生态领军企业开源中国&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;（开源共识（上海）网络技术有限公司）近日完成了数亿元 C 轮融资&lt;/strong&gt;，本轮融资由北京信息产业发展投资基金（北京信产基金）领投，深报一本股权投资基金（深报一本）及北京上河动量私募股权基金（上河动量）跟投。&lt;/p&gt; 
&lt;p&gt;此次融资将加速公司 AI 战略布局：深化现有产品矩阵的扩展、完善与全面 AI 化，构建软硬件协同的智能解决方案体系，促进人工智能在产业领域的 AI 应用落地。&lt;/p&gt; 
&lt;p&gt;至此，开源中国已累计获得超 16 亿元战略投资，投资方包括百度、华为、海望资本、张江科投、中科创星、天际资本、君联资本、上海国际创投、中移和创投资、瑞壹投资、容亿资本、泰达实业、中国互联网投资基金、国调科改、联想创投、上海浦东软件园、上海科创、北京信产基金、深报一本、上河动量等。构建起国有资本、科技大厂、创始团队&quot;3:3:4&quot;的良性股权结构，形成&quot;国家队护航、产业方协同、市场化运作&quot;的创新生态。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开发者生态的厚积薄发&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;作为中国开源基础设施奠基者，开源中国运营着 1800 万开发者聚集的 oschina.net 社区及代码托管平台 Gitee，服务 36 万企业级用户。其自主研发的 DevOps 工具链已在金融、军工等关键领域实现 80% 市场渗透率，成为信创替代工程的标杆案例，验证了开源商业化的中国路径。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2023/0630/103630_ng3i_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;AI 转型的战略升维&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;2024 年，公司推出对标 HuggingFace 的 AI 大模型平台&quot;模力方舟 (moark.com)&quot;，首创&quot;模型数据-算力调度-应用开发&quot;全栈服务体系。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-48d87ff5e72b3269622021604fd94f3e748.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;平台已实现三大突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;生态开放化&lt;/strong&gt;：聚合数千开源模型，打造 AI 应用创新基座；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服务一体化&lt;/strong&gt;：提供从模型体验、推理训练到应用部署的全生命周期服务；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;算力国产化&lt;/strong&gt;：完成多家国产 GPU 深度适配，成功运行 DeepSeek-V3 等千亿级模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;开源中国下一步将以模力方舟为核心，打造全方位的 AI 业务布局，助力 AI 应用创新、科技人才培养和新质生产力提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;起航，迈向「开源 AI 第一股」&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;开源中国以开发者生态为基座，构建开源领域‌「用户-流量-盈利」‌三重护城河，率先在信创市场完成‌开源商业化闭环验证‌，实现国产研发工具从技术突破到商业变现的质变。依托本轮战略投资，加速 AI 战略升级扩张市场领域，开辟第二增长曲线‌。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;目前开源中国已开始进入 IPO 倒计时，计划以&quot;开源 AI 第一股&quot;身份登陆资本市场，通过技术普惠推动新质生产力发展，助力中国在全球 AI 2.0 时代构建核心竞争力。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;北京信息产业发展投资基金表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源中国是中国开源生态与 AI 技术融合创新的标杆企业，其以开发者生态为根基、以信创替代为突破、以 AI 战略为驱动的增长路径，高度契合国家科技创新与自主可控的战略方向。领投本轮融资，既是基于对开源中国在国产软件基础设施领域不可替代地位的认可，更是看好其通过「模力方舟」平台推动 AI 技术普惠化、算力国产化和应用场景规模化落地的能力。&lt;/p&gt; 
 &lt;p&gt;我们期待通过资源协同与生态赋能，助力开源中国加速构建 AI 时代的技术底座，为全球 AI 2.0 竞争注入中国开源力量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;深报一本表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我们高度关注开源中国在国产软件替代浪潮中展现的商业化前景，凭借其构建的庞大开发者生态体系，公司有望在 AI 应用层持续释放开源技术的创新势能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;上河动量管理合伙人王欣表示：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;世界范围内，开源已经成为软件开发和人工智能创新的极其重要的推动力量。&lt;/p&gt; 
 &lt;p&gt;开源中国是服务于中国本土开源生态的先行者和坚守者，在地缘科技竞争的背景下，开源中国已经成为中国软件和人工智能领域具有国家级影响力的科技创新基础设施。相信开源中国的独特价值会得到越来越多的行业参与者和资本市场的认可。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337301/oschina-series-c-funding-round</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337301/oschina-series-c-funding-round</guid>
            <pubDate>Wed, 05 Mar 2025 10:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>个人开发者也能训练推理模型？GRPO 技术详解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 还在为训练推理模型烧光算力预算而发愁？当开源小模型遇上数学题就&quot;智商掉线&quot;，如何低成本突破性能瓶颈？&lt;/p&gt; 
 &lt;p&gt;传统 RLHF 动辄百万级算力投入，让多少团队在强化学习门前望而却步；格式混乱、逻辑断层、答案偏差------这些模型推理的顽疾是否也在阻碍你的 AI 产品落地？&lt;/p&gt; 
 &lt;p&gt;本文深入解析 DeepSeek 团队突破性的 GRPO（群组相对策略优化）技术，这项创新将强化学习所需计算资源几乎减半，甚至可以结合 LoRA 在普通消费级 GPU 上进行模型训练。作者通过亲身实践，成功在仅需 16GB 显存的环境下将 1B 参数的 Llama 3.2 转化为推理模型（后续文章会分享相关细节），完全颠覆了传统强化学习的资源需求认知。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Greg Schoeninger&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71410d1cd55685fc17beb84605c865f5851.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不久前，我们深入研究了 DeepSeek-R1 背后的技术原理，但是没有详细介绍其训练流程中采用的一项名为&quot;群组相对策略优化&quot;（Group Relative Policy Optimization, GRPO）的关键技术。&lt;/p&gt; 
&lt;p&gt;GRPO 本质上是一种旨在提升模型推理能力的强化学习算法。该技术最早发表于其研究论文《DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models》[1]，随后也被应用于 DeepSeek-R1 的后训练阶段。&lt;/p&gt; 
&lt;p&gt;在《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》这一论文[2]中，研究团队详细阐述了从基础预训练语言模型到最终推理模型的完整构建路径。虽然之前我们未深入探讨 GRPO 的数学原理和代码实现，但今天这篇文章将全面解析 GRPO 的技术细节，助力各位读者掌握这项技术的核心要义并应用于实际工作。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 要点回顾：DeepSeek-R1 如何运用 GRPO 技术&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为帮助理解，我们首先梳理从基础模型到推理模型的完整训练流程。该流程通过监督式微调（SFT）与群组相对策略优化（GRPO）的交替迭代实现模型能力跃升：&lt;/p&gt; 
&lt;p&gt;1.监督式微调（SFT）阶段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;冷启动训练&lt;/strong&gt;：采用数千条人工标注的高质量数据微调模型&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;数据验证&lt;/strong&gt;：所有样本均通过人工审核确保可靠性&lt;/p&gt; 
&lt;p&gt;2.GRPO 强化学习阶段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;推理轨迹训练&lt;/strong&gt; ：引导模型生成结构化推理过程（具有标签的推理轨迹）&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;三重确定性奖励&lt;/strong&gt;：基于格式规范性、逻辑一致性、答案正确性设计奖励机制&lt;/p&gt; 
&lt;p&gt;3.增强型 SFT 阶段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;合成数据生成&lt;/strong&gt;：创建 80 万条合成训练样本并进行筛选&lt;/p&gt; 
&lt;p&gt;b.&lt;strong&gt;模型自检过滤&lt;/strong&gt;：通过&quot;LLM As A Judge&quot;机制剔除错误响应&lt;/p&gt; 
&lt;p&gt;4.最终 GRPO 对齐阶段&lt;/p&gt; 
&lt;p&gt;a.&lt;strong&gt;价值观校准&lt;/strong&gt;：确保模型输出兼具实用性与安全性&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1a3d34d2c90323e9660a599d6baf9ba905.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在这篇文章中，我们将深入探讨 GRPO 的细节，助您掌握这项推动大模型推理能力突破的关键技术。笔者已开展基于 GRPO 的小模型训练实验，后续将发布完整代码与工程实践细节，通过可复现案例串联理论知识与实际应用。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 为什么 GRPO 很重要？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;TLDR ~ 大幅降低了计算需求且简化了强化学习流程。与 ChatGPT（PPO）使用的基于人类反馈的强化学习（RLHF）相比，所需的计算资源几乎减半。当你结合 LoRA 使用时，即使&quot;GPU poor&quot;（译者注：GPU 的性能不足）也能进行强化学习训练。我试过了，确实有效。我成功地将 1B 参数的 Llama 3.2 模型改造成了仅需 16GB 显存的推理模型。后续文章会分享代码和硬件要求细节。&lt;/p&gt; 
&lt;p&gt;我们只需在云 GPU 服务上花不到 100 美元，就能从自家车库训练推理模型。如果用自己的硬件跑小模型，基本上算是&quot;免费&quot;。其底层原理是什么呢？下一节将讨论从 PPO 到 GRPO 的演变过程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 从 PPO 到 GRPO&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;传闻 ChatGPT 背后的强化学习（RL）技术是 PPO（Proximal Policy Optimization，近端策略优化）。该流程在 InstructGPT 论文[3]中被提出，用于创建能够遵循指令而不仅仅是简单预测下一个单词的模型。&lt;/p&gt; 
&lt;p&gt;训练过程需要收集大量标注数据。对于给定的用户查询，模型需生成多个候选响应，然后由人类或 AI 在循环中对输出进行标注并按质量从优到劣排序。这些数据可用于训练&quot;奖励模型&quot;，其职责是为新接收的提示词计算&quot;奖励值&quot;。该奖励值应体现给定用户查询下模型响应的优劣程度。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7e2d394a6e114e400146d01db6dc67530d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;收集完所有这些经过排序和标注的数据后，即可启动 PPO 来训练大语言模型（LLM）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;问题在于 PPO 的训练成本可能非常高昂。&lt;/strong&gt; GRPO 论文[1]中的相关图表展示了 PPO 和 GRPO 过程中涉及的不同 LLM。下方蓝色和黄色方框中共有 4 个不同的 LLM。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-89e516de6f1f5de6d7805fc499a831b28e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了帮助大家理解上图的一些术语，我在这里给出了一些简单的定义：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;策略模型（Policy Model）&lt;/strong&gt; - 对当前正在训练的 LLM 的别称&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;参考模型（Reference Model）&lt;/strong&gt; - 被训练原始 LLM 的冻结版本&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;奖励模型（Reward Model）&lt;/strong&gt; - 基于人类偏好训练的模型（来自上文提到的 InstructGPT 技术）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;价值模型（Value Model）&lt;/strong&gt; - 试图估算特定动作长期奖励的模型&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;strong&gt;04 通过 GRPO 减少内存使用量&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在 PPO 算法中，策略模型和价值模型都包含需要通过反向传播进行优化的可训练参数。反向传播过程需要消耗大量内存资源。&lt;/strong&gt; 从上面的架构图可以看出，GRPO 算法移除了价值模型模块。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-909a6a3cd9958e6b2b842610e7167f00efc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;PPO 算法中混合使用了 4 个大语言模型（LLMs），这些模型都需要消耗大量的内存和计算资源。其中价值模型和奖励模型的参数量通常与正在训练的目标语言模型相当。参考模型通常是训练初期的语言模型的冻结副本。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-73a54d4ed060595c351d14255a2a026dcc4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这种实现方法不仅带来高昂的计算成本，还存在诸多需要协调的动态组件，而且还有多个模型需要优化。组件数量越多，通常意味着优化难度越大。GRPO 通过精简架构有效降低了系统复杂度。&lt;/p&gt; 
&lt;p&gt;出于兴趣，我在 H100 上测试了不同参数规模的模型，观察使用 GRPO 进行微调的难易程度。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f30692cc7db7719142a8d0c6d7bf4b34cda.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;如果想了解具体技术细节，可以查阅相关文档：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.oxen.ai%2Fblog%2Fgrpo-vram-requirements-for-the-gpu-poor&quot; target=&quot;_blank&quot;&gt;https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;若您理解了所有系统需求的来源，就可以开始参与开源项目贡献，或像我最近看到的 trl 仓库的这个 PR 那样，动手优化自己的机器学习库：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-46b6550e48276645bc3fb9fe2f1531ef4a2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 群组相对优势（Group Relative Advantages）&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在强化学习过程中，我们从语言模型（LLMs）中获取的主要信号是代表&quot;优势&quot;（Advantage）的&quot;A&quot;。这个信号为更新原始语言模型的权重提供了方向指导：&lt;strong&gt;当优势值较高时，我们需要鼓励模型重复当前行为；当优势值较低时，则需要引导模型尝试不同的行为。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 PPO 算法中，传统价值模型的核心任务是评估生成内容的质量，或者说预测这些内容获得高奖励值（high reward）的可能性。为了完成这项评估工作，需要训练大语言模型作为价值判断模块。那么 GRPO 是如何摆脱对价值模型的依赖的呢？&lt;/p&gt; 
&lt;p&gt;第一个技巧是：&lt;strong&gt;GRPO 不再针对单个查询生成单一输出，而是开始生成多个候选回答。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4651272806713abc0c71e0e9e4adb90f96.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具体来说，如果问题是一道数学题，模型可能会尝试几种不同的解题方法。以下面这个数学问题为例：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Mr. Curtis has 325 chickens on his farm where 28 are roosters and the rest are hens. Twenty hens do not lay eggs while the rest of the hens do. How many egg-laying hens does Mr. Curtis have on his farm?&lt;/p&gt; 
 &lt;p&gt;Curtis 先生的农场有 325 只鸡，其中 28 只是公鸡，其余是母鸡。其中有 20 只母鸡不下蛋，问有多少只产蛋母鸡？&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;模型可能会尝试多种解题思路，有的正确（答案为 227），有的不正确（答案为 305）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4f8c57fb9d114d8cd19c1c434f42d31ba6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;正确推理路径：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;First, let&#39;s find out how many hens there are. The total number of chickens is 325, and 28 are roosters. So, the number of hens is 325 - 28 = 297. Of these 297 hens, 20 do not lay eggs, so the number of egg-laying hens is 297 - 20 = 277.&lt;/p&gt; 
 &lt;p&gt;277&lt;/p&gt; 
 &lt;p&gt;首先，我们来看看有多少只母鸡。鸡的总数是 325 只，公鸡有 28 只。因此，母鸡的数量是 325 - 28 = 297。在这 297 只母鸡中，有 20 只不下蛋，所以下蛋母鸡的数量是 297 - 20 = 277。&lt;/p&gt; 
 &lt;p&gt;277&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;错误推理路径：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You need to subtract the 20 hens that do not lay eggs from the total number of hens to find the number of egg-laying hens. So, the number of egg-laying hens is 325 - 20 = 305.&lt;/p&gt; 
 &lt;p&gt;305&lt;/p&gt; 
 &lt;p&gt;您需要从母鸡总数中减去不下蛋的 20 只母鸡，才能求出下蛋母鸡的数量。因此，产蛋鸡的数量为 325 - 20 = 305。&lt;/p&gt; 
 &lt;p&gt;305&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;然后我们对每个输出根据其回答质量计算&quot;奖励值&quot;（reward）。可能存在多个评估不同响应属性的奖励函数。我们暂时将奖励函数视为黑盒，但知道它们会返回数值型结果------如果响应质量较好则数值较高，较差则较低，例如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Formatting（格式规范度）=1.0&lt;/li&gt; 
 &lt;li&gt;Answer（答案正确性）=0.0&lt;/li&gt; 
 &lt;li&gt;Consistency（逻辑一致性）=0.5&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;当获得所有输出的奖励值 (r) 后，GRPO 通过计算奖励值的均值 μ 和标准差 σ，生成群组相对优势 A。具体公式为：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-64e1b0b82899716c405d7c373fad02574d9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这个公式在机器学习特征工程中非常实用，它可以将任意数值归一化为更易学习的正负信号。&lt;/strong&gt; &lt;strong&gt;其直观含义是：&quot;这个数据点偏离平均值多少个标准差？&quot;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;让我们来看几个例子。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b9a698704de3094e3837dd1ab2500a2a14a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;若用原生 numpy 代码表示可能如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b22895474b1a709438951615cdb36e7923e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cba3c65046eea82fccdf170ae3480b63728.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;再试另一组数值：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cc74f64ff94df742a05791fc54f6d5685c6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过归一化，将奖励值转换为以均值为中心（0.0）的相对优势值。正值表示优于平均水平，负值表示劣于平均水平。这为我们建立了一套基准：&quot;给定当前提示词，平均响应的质量如何？&quot;在训练过程中，强化表现好的输出（提高其概率），抑制表现差的输出（降低其概率），从而引导模型优化方向。&lt;/p&gt; 
&lt;p&gt;这与传统价值模型的目标相似：预测给定响应的奖励值。由于我们现在训练的是语言模型，只需调整 temperature 参数即可生成多个候选回答，所有生成回答的平均奖励值即可作为衡量当前模型表现的良好信号，以及决定是否需要强化该行为。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 KL 散度&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;这个方程的最后一项是 KL 散度项。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-31fdc55549c04177692cffd66e30e71153b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;无需深入数学细节，这就是我们在训练过程中始终保留&quot;参考模型&quot;的原因。我们不希望新模型偏离原始模型太远，对于每个词元（token），都要确保新模型的预测结果不会与原始模型的预测结果产生过大偏差。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c452d93871b84a20051519ae616d6a561c3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;强制执行 KL 散度的直接原因是：初始模型已经具备生成连贯语句和遵循指令的能力。我们不希望新模型通过&quot;奖励欺骗&quot;（reward hack）或利用奖励信号中某些与原始模型不匹配的特性来取巧。&lt;strong&gt;例如，如果模型发现使用&quot;pamplemousse&quot;（葡萄柚的法语，发音有趣且较罕见）这个词能获得高奖励，但该词在预训练阶段并不常用，我们就要阻止模型过度依赖这种用词行为。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将这些要素整合，就得到了完整的最终方程！&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9c0e6e909d24b741ba1137deb08f79e43bc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;或者就像我们值得信赖的&quot;牛人 Eric&quot;说的那样... 这个数学公式看起来比实际复杂...&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-856291aa6b9db5cbd46f3cbcf9d349927ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;07 奖励信号机制&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1-Zero 研究的突破性在于，他们通过完全弃用&quot;神经奖励模型&quot;进一步大幅降低了内存消耗。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6f1e8b8d0e5a2080f1c94fa211bdd425e7c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这意味着什么？简而言之，他们直接使用正则表达式（regex）和字符串匹配技术生成奖励信号。&lt;strong&gt;研究团队认为，这种方法既能规避&quot;奖励欺骗&quot;（reward hacking）问题，又能简化整个训练流程。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果将前文提到的&quot;准确性奖励（Accuracy Rewards）&quot;和&quot;格式奖励（Format Rewards）&quot;规则转化为代码，其代码实现可能如下所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d0b618e57acda02c9b615ec705c4b7b9119.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;reference:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fwillccbb%2F4676755236bb08cab5f4e54a0475d6fb&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;训练过程中完全无需引入额外的奖励模型 LLM，仅需保留策略模型和参考模型作为主要内存占用源。将所需 LLM 数量从 4 个削减至 2 个，显著降低了 GPU 资源需求。&lt;/p&gt; 
&lt;p&gt;若你的直觉此时感到不对劲，质疑&quot;这种奖励函数是否具备泛化能力？&quot;，那么你是对的。&lt;strong&gt;这类奖励机制仅在预设的特定任务（如数学推理和格式规范）上表现良好，但无法扩展到其他实用场景。&lt;/strong&gt; 例如，模型可能擅长生成格式的数学解题过程，却无法完成开放式对话或创意写作。&lt;/p&gt; 
&lt;p&gt;我的预测是&quot;苦涩的教训&quot;（The Bitter Lesson）[4]将在此重现：当计算资源和数据量足够时，模型更倾向于自主学习。我们越是减少人工编码规则，让模型自主探索，其表现就越优异。当前 GRPO 的奖励机制仍显人工干预痕迹 ------ 为何不让模型自行学习奖励信号的权重呢？&lt;/p&gt; 
&lt;p&gt;尽管如此，尝试不同的奖励机制其实挺有意思的。&lt;strong&gt;GRPO 的亮点在于：&lt;/strong&gt; &lt;strong&gt;只要能用代码定义奖励函数（输入响应、输出数值），即可基于此进行优化。甚至可以通过外部 API 调用其他 LLM 生成奖励信号。&lt;/strong&gt; 我预感未来几周/月内，因为 GRPO 训练门槛的降低，开发者将开始探索各种创意奖励机制的设计。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓对于文中提到的&quot;不到 100 美元训练推理模型&quot;，你有何看法？欢迎在评论区畅所欲言。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2402.03300&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2402.03300&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.12948&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.12948&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2203.02155&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2203.02155&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.incompleteideas.net%2FIncIdeas%2FBitterLesson.html&quot; target=&quot;_blank&quot;&gt;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fghost.oxen.ai%2Fwhy-grpo-is-important-and-how-it-works%2F&quot; target=&quot;_blank&quot;&gt;https://ghost.oxen.ai/why-grpo-is-important-and-how-it-works/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17778588</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17778588</guid>
            <pubDate>Wed, 05 Mar 2025 09:49:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>trustcall —— 基于 LangGraph 的强大工具调用库</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;当被要求生成或修改大型 JSON blob 时，LLM 会遇到困难。&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;code&gt;trustcall&lt;/code&gt;可通过&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;要求 LLM 生成&amp;nbsp;&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc6902&quot;&gt;JSON 补丁&lt;/a&gt;操作来解决这个问题。这使得：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更快、更便宜地生成结构化输出。&lt;/li&gt;
&lt;li&gt;即使对于复杂的嵌套模式（定义为 pydantic、模式字典或常规 python 函数）也可以弹性重试验证错误&lt;/li&gt;
&lt;li&gt;准确更新现有模式，避免不必要的删除。&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可灵活适用于多种常见的 LLM 工作流程，例如：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Extraction&lt;/li&gt;
&lt;li&gt;LLM routing&lt;/li&gt;
&lt;li&gt;Multi-step agent tool use&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;415&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/173555_bjJK_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/trustcall</link>
            <guid isPermaLink="false">https://www.oschina.net/p/trustcall</guid>
            <pubDate>Wed, 05 Mar 2025 09:37:00 GMT</pubDate>
        </item>
        <item>
            <title>腾讯混元发布并开源图生视频模型，支持生成背景音效及 2K 视频</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 6 日，腾讯混元&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaOeJoWyQ78o45KlJnAtAkg&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;推出图生视频模型并对外开源，同时上线对口型与动作驱动等玩法，并支持生成背景音效及 2K 高质量视频。&lt;/p&gt; 
&lt;p&gt;开源内容包含权重、推理代码和 LoRA 训练代码，支持开发者基于混元训练专属 LoRA 等衍生模型。&lt;/p&gt; 
&lt;p&gt;目前在 Github、HuggingFace 等主流开发者社区均可下载体验。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Github: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent%2FHunyuanVideo-I2V&quot; target=&quot;_blank&quot;&gt;https://github.com/Tencent/HunyuanVideo-I2V&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Huggingface：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Ftencent%2FHunyuanVideo-I2V&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/tencent/HunyuanVideo-I2V&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据介绍，基于图生视频的能力，用户只需上传一张图片，并简短描述希望画面如何运动、镜头如何调度等，混元即可按要求让图片动起来，变成 5 秒的短视频，还能自动配上背景音效。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-79aaf27253683e0e75fd797b7842f3f77d1.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，上传一张人物图片，并输入希望「对口型」的文字或音频，图片中的人物即可「说话」或「唱歌」；使用「动作驱动」能力，还能一键生成同款跳舞视频。&lt;/p&gt; 
&lt;p&gt;目前用户通过混元 AI 视频官网即可体验（https://video.hunyuan.tencent.com/），企业和开发者可在腾讯云申请使用 API 接口使用。&lt;/p&gt; 
&lt;p&gt;腾讯混元表示，此次开源的图生视频模型，是混元文生视频模型开源工作的延续，模型总参数量保持 130 亿，模型适用于多种类型的角色和场景，包括写实视频制作、动漫角色甚至 CGI 角色制作的生成。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337275</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337275</guid>
            <pubDate>Wed, 05 Mar 2025 08:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Manus 邀请码炒至 6 万元，官方称将逐步有序释放</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;自发布以后，Manus 受到了热烈追捧，网友纷纷涌向 Manus 官网，从而导致页面一度因访问量过大而崩溃。目前，试用 Manus 需要输入邀请码，这导致邀请码一码难求。在二手交易平台上，邀请码的价格被炒至几百元到 6 万元不等。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;448&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-556805b52b9544d5e92e8dd8809b514dcf6.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;针对邀请码炒作问题，Manus AI 合伙人张涛在社交平台做出了回应。他首先感谢了大家对 Manus 的关注，并澄清了几点重要信息：一是公司从未开设任何付费获取邀请码的渠道；二是从未投入任何市场推广预算；三是内测期间系统容量有限，公司将优先保障现有用户的核心体验，并逐步有序释放邀请码。&lt;/p&gt; 
&lt;p&gt;张涛称，「目前采取邀请码机制，是因为此刻服务器容量确实有限，不得已而为之，团队也熬夜搞了一整天了。希望在接下来的时间里能让更多处在 waitlist 中的用户优先体验 Manus。」&lt;/p&gt; 
&lt;p&gt;「恳请大家对一家几十人的创业公司多一点包容和理解，团队正在全力输出，让大家早日体验上更好的产品。」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/337193/manus-ai-agent&quot; target=&quot;_blank&quot;&gt;Monica.im 发布 AI Agent 产品「Manus」&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337267</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337267</guid>
            <pubDate>Wed, 05 Mar 2025 08:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AMD 发布完全开源的 3B 参数语言模型 Instella</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;AMD 今天&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocm.blogs.amd.com%2Fartificial-intelligence%2Fintroducing-instella-3B%2FREADME.html&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;&lt;/u&gt;了完全开源的 3B 参数语言模型&amp;nbsp;Instella。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1614&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/155518_eNxW_2720166.png&quot; width=&quot;2188&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAMD-AIG-AIMA%2FInstella&quot; target=&quot;_blank&quot;&gt;https://github.com/AMD-AIG-AIMA/Instella&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;AMD 宣称 Instella 代表着&quot;完全开放的最先进的 30 亿参数语言模型 (LM)&quot;。这些模型是在 AMD Instinct MI300X GPU 上训练的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;通过完全开源 Instella 模型，包括权重、训练超参数、数据集和代码，我们旨在促进人工智能社区内的创新与合作。&lt;/p&gt; 
 &lt;p&gt;我们相信，透明度、可重复性和可访问性是人工智能研究与开发取得进展的关键驱动力。&lt;/p&gt; 
 &lt;p&gt;我们邀请开发人员、研究人员和人工智能爱好者探索 Instella，为其不断改进献计献策，并与我们一起推动语言模型的发展。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根据 AMD 公布的数据，其性能与 Llama 3.2 3B、Gemma-2 2B 和 Qwen 2.5 3B 等同类产品相比具有很强的竞争力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6b27824412274c03ca53d1b47afaedf5831.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337263/amd-instella-3b</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337263/amd-instella-3b</guid>
            <pubDate>Wed, 05 Mar 2025 07:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>智源开源多模态向量模型 BGE-VL</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;智源研究院宣布联合多所高校开发了多模态向量模型 BGE-VL，进一步扩充了原有生态体系。BGE-VL 在图文检索、组合图像检索等主要多模态检索任务中均取得了最佳效果。&lt;/p&gt; 
&lt;p&gt;BGE-VL 借助大规模合成数据 MegaPairs 训练而成。这一设计具备以下两大核心优势:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;优异的可扩展性：&lt;/strong&gt;MegaPairs 结合多模态表征模型、多模态大模型和大语言模型，在海量图文语料库中高效挖掘多模态三元组数据。其算法能够以极低成本持续生成多样化且高质量的多模态三元组。本次发布的版本涵盖 2600 万条样本，为多模态检索模型的训练提供了大规模、高价值的数据支持。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;卓越的数据质量：&lt;/strong&gt;相较于传统人工标注数据，MegaPairs 仅需 1/70 的数据量即可实现更优的训练效果。利用该合成数据，智源训练了多模态检索模型 BGE-VL，显著提升了多个主流多模态检索基准的性能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;BGE-VL 的技术报告已发布，相关数据、模型及代码资源将陆续向社区全面开放。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;论文地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.14475&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.14475&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;项目主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FVectorSpaceLab%2FMegaPairs&quot; target=&quot;_blank&quot;&gt;https://github.com/VectorSpaceLab/MegaPairs&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style=&quot;text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBAAI%2FBGE-VL-MLLM-S1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BAAI/BGE-VL-MLLM-S1&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337258</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337258</guid>
            <pubDate>Wed, 05 Mar 2025 07:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>vivo OS 部门设立 AI 领域板块</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbXnSMuj_jA5V9BeIDYuJkw&quot; target=&quot;_blank&quot;&gt;据雷锋网独家消息&lt;/a&gt;&lt;/u&gt;，vivo 近日进行了组织架构调整，其中其 AI 领域有了新的变动。&lt;/p&gt; 
&lt;p&gt;具体来看，vivo 原 OS 产品领域下将设立 AI 领域，人工智能一部、人工智能二部划入 AI 领域。原互联网平台运营领域总经理张飞被调任 AI 领域总经理，并兼管人工智能一部，无考察期，直接向公司副总裁、OS 产品领域负责人周围汇报。而原人工智能一部总经理肖方旭已于 1 月份离职。&lt;/p&gt; 
&lt;p&gt;据 vivo 员工透露，公司在 AI 大模型方面投入巨大，前期管理意志干预很重，可实际看来技术进展缓慢，此事早在去年内部就有过讨论，最终结果是暂时不做商业化考核，但暂停了对资金的投入。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;报道指出，目前 vivo 的大模型训练重心正在向端侧转移，云端的 700 亿参数大语言模型还在微调和优化中，暂停了该模型的预训练工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;公开资料显示，vivo 每年都会投入 20-30 亿用于大模型研发。截至 2024 年 10 月，vivo 在 AI 领域的投入已经超过 230 亿元，且 AI 研究院的研发人员数量也从 2019 年的 1 千人增加至 2 千多人，是目前公开披露 AI 投入最高的手机厂商之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337257</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337257</guid>
            <pubDate>Wed, 05 Mar 2025 07:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微信月活突破 10 亿</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QuestMobile 近日发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-mdl9gcCNmfLotd87SOIFg&quot; target=&quot;_blank&quot;&gt;2024 年度中国移动互联网实力价值榜&lt;/a&gt;&lt;/u&gt;，TOP50 赛道用户规模 NO.1 APP 如下。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2284&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152504_luN0_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本榜单体现了互联网行业 50 个细分赛道的第一名，微信在即时通讯位列第一，&lt;strong&gt;月活唯一突破 10 亿级，达到 10.8 亿&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;综合电商方面，淘宝以 9.6 亿月活排名第一。短视频方面的第一是抖音，月活 8.4 亿。&lt;/p&gt; 
&lt;p&gt;从 50 个 APP 所属的集团来看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;阿里旗下有 8 款：淘宝、高德地图、支付宝、钉钉、闲鱼、饿了么、菜鸟、盒马。&lt;/li&gt; 
 &lt;li&gt;腾讯旗下有 7 款：微信、搜狗输入法、腾讯视频、QQ 浏览器、酷狗音乐、王者荣耀、QQ 邮箱。&lt;/li&gt; 
 &lt;li&gt;字节旗下有 6 款：抖音、今日头条、番茄免费小说、剪映、番茄畅听、豆包。&lt;/li&gt; 
 &lt;li&gt;百度旗下有 2 款：百度、百度网盘。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;App 规模增长千万级榜单如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1548&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/152718_x9Xf_2720166.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;前十名的千万级体量 APP 增速排行榜中，字节旗下产品占据七夕，分别是：抖音商城、豆包、悟空浏览器、红果免费短剧、抖音精选、汽水音乐、番茄畅听音乐版，可见字节流量之猛。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337256</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337256</guid>
            <pubDate>Wed, 05 Mar 2025 07:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌搜索测试「AI Mode」：整合多模态和实时信息、一键解答复杂问题</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌公司昨日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fsearch%2Fai-mode-search%2F&quot; target=&quot;_blank&quot;&gt;发布博文&lt;/a&gt;，邀请谷歌搜索用户测试全新的&lt;strong&gt;「AI 模式」（AI Mode）&lt;/strong&gt;。用户可以提出更复杂的问题，并基于搜索结果，AI 生成更详细、更直观的答案。&lt;/p&gt; 
&lt;p&gt;谷歌表示，AI 模式将提供更高级的推理、思考和多模态能力，帮助用户更高效地获取信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;540&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0306/150029_Fzwi_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;谷歌表示，以往用户在处理复杂问题时，往往需要多次搜索才能解决，而「AI 模式」能够解决这个痛点。用户只需在桌面或移动设备上输入查询，点击新的「AI 模式」按钮即可体验。&lt;/p&gt; 
&lt;p&gt;此外，AI 模式页面底部还提供了「深入探索」快捷入口，用户可直接跳过常规搜索结果，专注于 AI 生成的内容。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-39952b2fa3ffbf6ae0dc3082083d80b34c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在移动设备上，用户可以通过上传图片或语音输入查询，但目前仅支持文本输出。AI 模式还支持历史搜索记录，方便用户查看过往查询。&lt;/p&gt; 
&lt;p&gt;AI 模式由定制版的 Gemini 2.0 驱动，能够访问实时数据源和知识图谱等资源。它通过「查询扩展」技术，从多个子主题和数据源中提取信息，并综合呈现。如果信息不足，用户将被引导至网页搜索结果。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;案例 1：鸟类迁徙路径&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用户提问：「候鸟如何知道迁徙路线？」AI 模式会进行多步搜索并组织结果，在移动设备上以轮播形式展示来源网站，随后提供简明答案和相关文章。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 2：户外拍摄最佳时间&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用户询问：「本周在波士顿公共花园拍摄户外订婚照的最佳时间是什么？」AI 模式结合实时天气信息，推荐具体日期和黄金时段，并注明日落时间。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;案例 3：睡眠追踪设备对比&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;用户提问：「智能戒指、智能手表和追踪垫在睡眠追踪功能上有何区别？」AI 模式以对比表格形式呈现答案，并支持后续问题，如「深度睡眠时心率如何变化？」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;从早期测试来看，AI 模式的查询长度是传统搜索的两倍，用户有 25% 的时间会进行后续提问。谷歌计划逐步向所有用户开放这一功能，目前测试主要面向高级用户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/337252/google-ai-mode-search</link>
            <guid isPermaLink="false">https://www.oschina.net/news/337252/google-ai-mode-search</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>