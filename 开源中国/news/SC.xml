<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 11 Jun 2025 21:44:55 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>macOS Tahoe 是最后一个支持英特尔处理器的 macOS 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;macOS Tahoe 支持四款使用英特尔处理器的 macOS，它们的发售年份是 2019 年和 2020 年。苹果对 Tahoe 的安全更新支持将持续到 2028 年秋天。&lt;/p&gt; 
 &lt;p&gt;从 macOS 27 开始，苹果新操作系统都将需要 Apple Silicon Mac。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 WWDC 举办的分会场上，苹果明确表示搭载英特尔处理器的 Mac 将不会获得明年推出的 macOS 27 更新，但仍可能会有添加安全修复的更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f223bac2bf7e49f84aa10b4c34782dd6b33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，苹果已经停止支持其产品线中某些非 Apple Silicon 型号。例如，macOS Tahoe 不适用于任何 Intel MacBook Air 或 Mac mini。&lt;/p&gt; 
&lt;p&gt;但 Tahoe 仍然支持部分英特尔 Mac，包括 2019 款 16 英寸 MacBook Pro、2020 款英特尔 13 英寸 MacBook Pro、2020 款 iMac 和 2019 款 Mac Pro。&lt;/p&gt; 
&lt;p&gt;根据苹果的警告，macOS 27 将不再支持所有这些老旧设备，因此 macOS 26 将是最后一个兼容版本。&lt;/p&gt; 
&lt;p&gt;这意味着苹果对英特尔 Mac 的支持正在逐步取消，公司希望将所有精力和创新都放在 Apple 自主芯片的机器上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354872</guid>
      <pubDate>Sat, 10 May 2025 10:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Seelen UI —— 完全可定制的 Windows 桌面环境</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Seelen UI 是一款旨在增强 Windows 桌面体验的工具，专注于自定义和提高工作效率。它可以无缝集成到你的系统中，提供一系列功能，让你可以个性化桌面并优化工作流程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt="" height="333" src="https://static.oschina.net/uploads/space/2025/0610/153055_JVfK_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;发挥创意&lt;/strong&gt;：Seelen UI 可让你根据自己的风格和需求定制桌面。可以调整菜单、小部件、图标和其他元素，打造个性化且美观的桌面环境。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;提升工作效率&lt;/strong&gt;：Seelen UI 可帮助你高效地组织桌面。借助平铺窗口管理器，窗口可自动排列，支持多任务处理，让工作更加流畅。&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;尽享音乐&lt;/strong&gt;：Seelen UI 集成媒体模块，兼容大多数音乐播放器，让你轻松享受音乐。可以随时暂停、继续播放和跳过曲目，无需打开其他窗口。&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;更快&lt;/strong&gt;：借助受 Rofi 启发的应用启动器，Seelen UI 提供了一种简单直观的方式来快速访问你的应用程序并执行命令。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;用户友好配置&lt;/strong&gt;：Seelen UI 提供直观的界面，方便用户自定义。只需点击几下，即可调整主题、任务栏布局、图标等设置。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Seelen UI 需要安装 WebView 运行时。在 Windows 11 系统中，WebView 运行时已预装在系统内。但在 Windows 10 系统中，WebView 运行时已包含在&lt;code&gt;setup.exe&lt;/code&gt;安装程序中。此外，Microsoft Edge 浏览器也需要安装才能正常运行。部分用户可能已修改系统并移除 Edge，因此请确保 Edge 和 WebView 运行时均已安装在你的系统中。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/seelen-ui</link>
      <guid isPermaLink="false">https://www.oschina.net/p/seelen-ui</guid>
      <pubDate>Sat, 10 May 2025 10:19:00 GMT</pubDate>
    </item>
    <item>
      <title>多源多表写入、数据格式增强，SeaTunnel 2.3.11 重磅更新来了！</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h1 style="text-align:center"&gt;&lt;img alt="2.3.11" src="https://oscimg.oschina.net/oscnet//58710d13d425ac4a438e096f3576a207.png" referrerpolicy="no-referrer"&gt;&lt;/h1&gt; 
&lt;p style="color:#333333; text-align:start"&gt;我们很高兴地宣布 Apache SeaTunnel 2.3.11 正式发布！作为一个专注于高性能、可扩展的数据集成平台，SeaTunnel 始终致力于为开发者和数据工程团队提供更强大、更灵活的异构数据处理能力。本次 2.3.11 版本在&lt;strong&gt;稳定性、易用性、连接器生态、数据转换能力以及引擎层面&lt;/strong&gt;都进行了重要增强。无论是支持更多新型数据源与目标端、多表写入、复杂格式支持，还是对关键 Bug 的修复与文档优化，本次更新都体现了社区对用户反馈的快速响应和持续进化的能力。下面让我们一起来详细了解 2.3.11 的亮点内容。&lt;/p&gt; 
&lt;h2&gt;功能更新 Highlights&lt;/h2&gt; 
&lt;h3&gt;新增连接器与功能增强&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP Sink 支持批量写入&lt;/strong&gt;：实现了 HTTP Sink 的批量写入功能，提高了数据写入效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持多表写入功能&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;ClickHouse&lt;/strong&gt;：新增支持多表写入功能，提升了数据同步的灵活性。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;TDengine&lt;/strong&gt;：新增支持多表写入功能，增强了数据处理能力。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;DataHub&lt;/strong&gt;：新增支持多表写入功能，扩展了数据集成场景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GraphQL Connector&lt;/strong&gt;：新增支持 GraphQL 连接器，丰富了数据源类型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Elasticsearch Source 支持 PIT（Point-in-Time）&lt;/strong&gt;：增强了 Elasticsearch 数据源的查询能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持 CSV 文件中不同列顺序的提取&lt;/strong&gt;：提升了文件数据处理的灵活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Apache Cloudberry 支持&lt;/strong&gt;：扩展了数据源的多样性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Aerospike Sink Connector&lt;/strong&gt;：丰富了数据写入目标。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增 Helm 测试用例&lt;/strong&gt;：增强了部署测试能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;配置与参数优化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;end_timestamp&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;参数&lt;/strong&gt;：在时间戳起始模式中添加了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;end_timestamp&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;参数，增强了数据读取的灵活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持占位符替换&lt;/strong&gt;：HTTP Connector 支持参数占位符替换，提升了配置的灵活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增远程主机验证选项&lt;/strong&gt;：FTP 数据通道新增远程主机验证选项，增强了安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化变量处理的健壮性&lt;/strong&gt;：改进了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;stop-seatunnel-cluster.sh&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;脚本中变量处理的健壮性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;移除无用配置项&lt;/strong&gt;：删除了 Iceberg Sink 中无用的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;iceberg.table.config&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;配置项。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化 JDBC 方言选择逻辑&lt;/strong&gt;：提升了 JDBC 连接器的兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持定义 Sink 列类型&lt;/strong&gt;：Transform 支持定义 Sink 列类型，增强了数据转换能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 SQL Transform 中的布尔类型&lt;/strong&gt;：提升了 SQL 转换的表达能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Iceberg Source 中的过滤条件&lt;/strong&gt;：增强了数据读取的灵活性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持源/汇状态类的 serialVersionUID 检查脚本&lt;/strong&gt;：提升了状态管理的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Web UI 的基本认证&lt;/strong&gt;：增强了 Web UI 的安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持 Rest-API v2 的 HTTPS 协议&lt;/strong&gt;：提升了 API 通信的安全性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增任务运行管理页面的异常信息格式化&lt;/strong&gt;：优化了异常信息的展示。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化 JDBC 的字符集分割算法&lt;/strong&gt;：提升了数据读取的准确性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;row_delimiter&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;选项&lt;/strong&gt;：Text File Sink 新增&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;row_delimiter&lt;/code&gt;选项，增强了文件写入的灵活性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Bug 修复&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;修复 SeaTunnelClient 无法正常退出的问题：增强了客户端的稳定性。&lt;/li&gt; 
 &lt;li&gt;修复 Oracle-CDC 重命名 DDL 事件缺失列类型的问题：提升了数据同步的准确性。&lt;/li&gt; 
 &lt;li&gt;修复 PostgreSQL Sink 尝试更新唯一键的问题：增强了数据写入的稳定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 Hive 客户端线程不安全的问题&lt;/strong&gt;：提升了多线程环境下的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 OceanBase MySQL JDBC Sink 创建语句错误的问题&lt;/strong&gt;：增强了兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 Kafka 枚举器分配分片时的空指针异常&lt;/strong&gt;：提升了数据读取的稳定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 JSON 输出中科学计数法表示的十进制数问题&lt;/strong&gt;：确保了数据的准确性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 Parquet Int32 转换错误的问题&lt;/strong&gt;：提升了数据类型处理的准确性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 CSV 格式分隔符的问题&lt;/strong&gt;：增强了文件解析的稳定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 MaxCompute Sink 写入日期小于实际日期的问题&lt;/strong&gt;：确保了数据写入的准确性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 MongoDB 中 Long 类型无法处理科学计数法字符串的问题&lt;/strong&gt;：提升了数据类型兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 Elasticsearch 添加列事件的问题&lt;/strong&gt;：增强了数据同步的稳定性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 SQL Server 在数据库名称包含点时创建表的问题&lt;/strong&gt;：提升了数据库兼容性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 DateUtils 无法解析带本地时区的日期时间字符串的问题&lt;/strong&gt;：确保了时间解析的准确性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 JDBC 默认连接参数无效的问题&lt;/strong&gt;：增强了连接配置的可靠性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;修复 Redis 写入失败但任务未失败的问题&lt;/strong&gt;：提升了错误处理的准确性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;文档更新&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;新增中文文档&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;MySQL-CDC Connector&lt;/li&gt; 
   &lt;li&gt;MongoDB-CDC Connector&lt;/li&gt; 
   &lt;li&gt;HiveJdbc Connector&lt;/li&gt; 
   &lt;li&gt;Jira Connector&lt;/li&gt; 
   &lt;li&gt;Cloudberry Connector&lt;/li&gt; 
   &lt;li&gt;GitHub Connector&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文档格式与内容优化&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复了 Markdown 格式问题，统一了标题格式，删除了无效的空格和重复内容。&lt;/li&gt; 
   &lt;li&gt;调整了&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;explode&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;trim&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;系列 SQL 函数的描述，提升了文档的准确性。&lt;/li&gt; 
   &lt;li&gt;更新了 Kafka 文档中的 Kerberos 部分，增强了安全配置的指导性。&lt;/li&gt; 
   &lt;li&gt;修复了死链接，提升了文档的可用性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;致谢贡献者&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:start"&gt;感谢@zhangshenghang 对本次版本发布的指导，以及以下贡献者对本次发布的代码提交、文档撰写、问题反馈做出的宝贵贡献（按用户名排序）：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:start"&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//1dd3b6fcd33c5aac23f32c462da301b7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:start"&gt;也感谢所有参与代码审核、功能测试、文档翻译和社区讨论的开发者、用户和贡献者！&lt;/p&gt; 
&lt;h2&gt;获取方式&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;镜像下载：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseatunnel.apache.org%2Fdownload" target="_blank"&gt;https://seatunnel.apache.org/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub Release 页面：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fseatunnel%2Freleases%2Ftag%2F2.3.11" target="_blank"&gt;SeaTunnel 2.3.11&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Maven 依赖更新：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsearch.maven.org%2Fsearch%3Fq%3Dorg.apache.seatunnel" target="_blank"&gt;Maven Central&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354859/apache-seatunnel-2-3-11-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354859/apache-seatunnel-2-3-11-released</guid>
      <pubDate>Sat, 10 May 2025 09:56:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Genspark 发布 AI 浏览器</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通用智能体 Genspark 发布了 AI 浏览器产品，官方称其具有&lt;strong&gt;极速、广告拦截、全能智能体、自动驾驶模式&lt;/strong&gt;的特性，并提供了 MCP 商店。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170325_JqCj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/170647_1Eqh_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="540" src="https://static.oschina.net/uploads/space/2025/0611/165940_ftHT_2720166.gif" width="960" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.genspark.ai%2Fbrowser" target="_blank"&gt;https://www.genspark.ai/browser&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Genspark 由百度前高管景鲲创立，今年 4 月宣布&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent"&gt;推出&lt;/a&gt;通用 AI 智能体"Genspark Super Agent"，号称是一款 "快速、准确、可控" 的通用 AI 代理。这一消息迅速在技术社区引发热议，众多专业人士将其与 Manus 相提并论，认为这标志着通用 AI 代理技术的新一轮角逐。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/344443" target="news"&gt;AI 智能体 Genspark 上线 9 天，收入近千万美元&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/342709/mainfunc-ai-genspark-super-agent" target="news"&gt;百度前高管的 AI 创企发布通用智能体：Genspark Super Agent&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354844/genspark-ai-browser</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354844/genspark-ai-browser</guid>
      <pubDate>Sat, 10 May 2025 09:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Ilya Sutskever：AI 将接管人类的一切</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在最近的演讲中，OpenAI 前首席科学家 Ilya Sutskever 回归母校多伦多大学，分享了他对人工智能（AI）发展的深刻见解。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 与多伦多大学的渊源颇深，20 年前他在这里获得了学士学位，而此次则是他从该校获得的第四个学位。他在演讲中回顾了自己在多伦多大学的学习经历，尤其感慨与 AI 领域先驱 Geoffrey Hinton 的学习机会，使他成为一名科学家。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-5833dd185f58bdfa34442db6dd544edf1b7.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 强调，接受现实并专注于改善现状是个人成长的重要心态。他提到，许多人容易陷入对过去的后悔，然而这种心态并不利于前进。他鼓励大家思考下一步的行动，尽管这一转变不易，但一旦做到，就会使事情变得更简单。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;接下来，Sutskever 转向了 AI 的主题。他指出，我们正处于一个特殊的时代，AI 的迅速发展正在改变我们的学习方式和工作模式。AI 正在以不可预测的方式影响着各行各业，一些工作会更早感受到变化，而另一些则可能稍晚。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;他预测，AI 未来将有能力完成所有人类能完成的任务。他认为人类大脑本质上是一种生物计算机，因此 AI 也理应具备完成所有人类任务的潜力。尽管当前的 AI 已能完成许多令人惊叹的任务，但仍存在不足之处，然而随着技术的进步，这些不足将得到改善。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 还提出了深刻的问题：当 AI 能够完成所有工作时，人类将如何应对这一变革？他强调，随着 AI 技术的发展，如何合理利用 AI 将成为人类面临的重要挑战，包括在工作、经济和 AI 研究等领域的应用。他认为，AI 的发展将极大加速人类的进步，但同时也会带来巨大的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Sutskever 指出，AI 的发展速度可能会超出我们的预期，未来几年内，AI 的能力将不断提升，其对生活的影响将更加显著。尽管目前难以完全预见 AI 带来的变化，但可以确定的是，AI 的进步将对每个人的生活产生深远的影响。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;a href="https://www.oschina.net/news/344437/ilya-sutskevers-ssi-valued-at-32b" target="_blank"&gt;OpenAI 前首席科学家 Ilya Sutskever 的公司估值达 320 亿美元&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354842</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354842</guid>
      <pubDate>Sat, 10 May 2025 09:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Sam Altman 最新文章《温和的奇点》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Sam Altman 今天在他的博客更新了一篇长文：&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthe-gentle-singularity" target="_blank"&gt;《The Gentle Singularity》&lt;/a&gt;&lt;/em&gt;，文中指出人类或许正迎来一个新的奇点，而这个奇点并非突如其来，而是温和地悄然降临。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1006" src="https://static.oschina.net/uploads/space/2025/0611/161536_O8JD_2720166.png" width="1264" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;以下是译文。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我们已越过临界点，起飞开始了。人类距离创造出数字超级智能已近在咫尺，而至少到目前为止，现实远比想象中来得平实自然。&lt;/p&gt; 
&lt;p&gt;街道上尚无机器人行走，我们大多数人也不整日与 AI 交谈。人们依然会因病离世，太空旅行依旧不易，宇宙中仍有诸多未解之谜。&lt;/p&gt; 
&lt;p&gt;然而，我们近期确实构建了在许多方面超越人类智慧的系统，它们能显著提升使用者的工作效率。最困难的部分已然过去：造就 GPT-4、o3 等系统的科学洞见来之不易，却将引领我们走得更远。&lt;/p&gt; 
&lt;p&gt;人工智能将以多种方式惠及世界，但由 AI 驱动的科学加速进步和生产效率提升所带来的生活质量改善，将是巨大的；未来可以远比现在美好。科学进步是整体进步的最大驱动力；想到我们本可拥有的更多可能，实在令人振奋。&lt;/p&gt; 
&lt;p&gt;从某种重要意义上说，ChatGPT 已经比历史上任何个体人类都更强大。数亿人每天依赖它处理日益重要的任务；一项微小的新能力便能产生巨大的积极影响；而一个微小的错位，乘以数亿用户，则可能造成深远的负面影响。&lt;/p&gt; 
&lt;p&gt;2025 年，能执行真正认知工作的智能体已然登场；编写计算机代码的方式将彻底改变。2026 年，我们可能迎来能够发现新见解的系统。2027 年，能在现实世界执行任务的机器人或将问世。&lt;/p&gt; 
&lt;p&gt;将会有更多人能够创作软件和艺术作品。但世界对这两者的需求远超当前供给，只要专家们善用新工具，他们很可能仍远胜于新手。总体而言，到 2030 年，单个人的生产力相比 2020 年所能达到的飞跃，将是惊人的巨变，许多人会找到从中获益的途径。&lt;/p&gt; 
&lt;p&gt;在最重要的方面，2030 年代或许不会天翻地覆。人们仍将爱自己的家人，表达创造力，玩游戏，在湖中畅游。&lt;/p&gt; 
&lt;p&gt;但在同样至关重要的其他方面，2030 年代很可能将与此前任何时代都截然不同。我们尚不知智能水平能超越人类多远，但我们即将揭开谜底。&lt;/p&gt; 
&lt;p&gt;在 2030 年代，智能与能源——即思想的涌现以及将思想变为现实的能力——将变得极度充裕。长久以来，这两者一直是人类进步的根本限制；在充裕的智能与能源（以及良好的治理）之下，理论上我们能够拥有其他一切。&lt;/p&gt; 
&lt;p&gt;我们已然生活在令人惊叹的数字智能时代，经历了初期的震惊后，大多数人已习以为常。我们飞快地从惊叹 AI 能生成优美的段落，转而期待它能创作优美的小说；从惊叹它能做出救命的医学诊断，转而期待它能研发治愈良方；从惊叹它能编写小程序，转而期待它能创立全新的公司。奇点的演变便是如此：奇迹成为日常，继而成为标配。&lt;/p&gt; 
&lt;p&gt;已有科学家坦言，借助 AI，他们的效率提升了数倍。先进 AI 令人着迷的原因众多，但或许最重大的意义在于，我们能利用它来加速 AI 自身的研究。我们或许能发现新的计算基材、更优的算法，甚至更多未知的突破。若能将十年的研究压缩至一年或一个月内完成，进步的速率显然将大不相同。&lt;/p&gt; 
&lt;p&gt;从今往后，我们已构建的工具将帮助我们探寻更深远的科学洞见，并助力我们打造更优的 AI 系统。这当然不等同于 AI 系统完全自主更新自身代码，但这已然是&lt;strong&gt;递归式自我改进&lt;/strong&gt;的雏形。&lt;/p&gt; 
&lt;p&gt;其他自我强化的循环也在发挥作用。巨大的经济价值创造已启动一个飞轮，推动着为运行日益强大的 AI 系统所需的复合式基础设施建设。能够制造其他机器人的机器人（某种意义上，也包括能建设其他数据中心的数据中心）已不再遥远。&lt;/p&gt; 
&lt;p&gt;若首批百万台人形机器人仍需传统方式制造，但之后它们便能运作整个供应链——采矿与冶炼、驾驶卡车、管理工厂等等——以制造更多机器人，而这些机器人又能建设更多芯片工厂、数据中心等，那么进步的速度显然将不可同日而语。&lt;/p&gt; 
&lt;p&gt;随着数据中心生产走向自动化，智能的成本终将趋近于电力的成本。（人们常好奇一次 ChatGPT 查询的耗能：平均每次查询耗电约 0.34 瓦时，相当于烤箱工作一秒多，或高效节能灯泡亮几分钟。耗水约 0.000085 加仑，约合十五分之一茶匙。）&lt;/p&gt; 
&lt;p&gt;技术进步的速率将持续加快，而人类总能适应几乎任何变化的特性仍将延续。挑战必然存在，如某些职业类别整体消失；但另一方面，世界财富将以前所未有的速度激增，使我们能认真考虑以往绝无可能的全新政策构想。我们或许不会立刻采纳全新的社会契约，但几十年后回望，渐进的变革终将累积成巨变。&lt;/p&gt; 
&lt;p&gt;历史经验表明，我们会找到新的工作与新的追求，并快速接纳新工具（工业革命后的职业变迁便是一个近例）。期望值会提升，但能力提升的速度同样迅猛，我们终将获得更好的事物。我们将为彼此创造越来越奇妙的东西。人类相比 AI 拥有一个长远而关键的优势：我们天生关注他人及其所思所为，而对机器则不甚在意。&lt;/p&gt; 
&lt;p&gt;千年前的农夫若审视我们许多人的工作，或许会认为那是「虚假的工作」，觉得我们不过是因食物充足、坐拥难以想象的奢华而游戏人生。我期待我们回望千年后的工作时，也会觉得它们「虚假」，但我毫不怀疑，从事它们的人必将感到无比重要与满足。&lt;/p&gt; 
&lt;p&gt;新奇迹诞生的速率将超乎想象。如今甚至难以预料到 2035 年我们将有何发现：或许今年解决高能物理难题，明年便开启太空殖民；今年取得重大材料科学突破，明年就实现真正的高带宽脑机接口。许多人会选择以相似的方式生活，但至少一部分人可能会选择「接入」（虚拟世界）。&lt;/p&gt; 
&lt;p&gt;展望未来，这听起来令人难以置信。但置身其中时，感受或许会是震撼但可控的。从相对论视角看，奇点是一点一滴发生的，融合是缓慢进行的。我们正攀登指数级技术进步的漫长弧线；向前看总是陡峭垂直，向后看则显得平坦，但它始终是一条平滑的曲线。（回想 2020 年，若有人预言 2025 年将接近通用人工智能，听起来会比我们现在对 2030 年的预测更为疯狂。）&lt;/p&gt; 
&lt;p&gt;伴随巨大机遇的，是严峻的挑战。我们亟需从技术和社会层面解决安全问题，而鉴于其经济影响，确保超级智能的广泛可及性也至关重要。最可取的前进路径或许是：&lt;/p&gt; 
&lt;p&gt;解决对齐问题：即我们能强有力地确保 AI 系统学习并践行人类集体真正的长期愿望（社交媒体信息流是 AI 未对齐的实例：其算法深谙如何让你持续滚动浏览，精准把握你的短期偏好，但这却是通过利用人脑的某种特性，凌驾于你的长期偏好之上）。&lt;/p&gt; 
&lt;p&gt;然后着力使超级智能变得廉价、普及，且不被任何个人、公司或国家过度垄断。&lt;/p&gt; 
&lt;p&gt;社会具有韧性、创造力且适应迅速。若能凝聚集体的意志与智慧，尽管会犯错，某些事情会出纰漏，但我们能快速学习调整，从而运用这项技术最大化收益、最小化风险。在由社会共同决定的宽泛边界内，给予用户充分自由至关重要。世界越早开始探讨这些边界何在以及如何定义集体对齐，结果越好。&lt;/p&gt; 
&lt;p&gt;我们（整个行业，而不仅是 OpenAI）正在为世界构建一个大脑。它将高度个性化、人人皆可轻松使用；限制我们的将是好点子的匮乏。长久以来，科技创业圈常嘲笑「点子大王」——那些只有想法却需要团队来实现的人。现在看来，他们即将迎来属于自己的高光时刻。&lt;/p&gt; 
&lt;p&gt;OpenAI 如今承载诸多角色，但首先且最重要的，我们是一家超级智能研究公司。前路漫长，但大部分路径已然照亮，未知的黑暗区域正迅速退去。能从事这份事业，我们深感庆幸。&lt;/p&gt; 
&lt;p&gt;廉价到无需计量的智能已触手可及。此言或许疯狂，但若在 2020 年告诉你们我们将达到今日之境，恐怕比如今我们对 2030 年的预测听起来更为疯狂。&lt;/p&gt; 
&lt;p&gt;愿我们借助超级智能，平稳、指数级、波澜不惊地向上攀升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;转载自：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrbEEJfEoCdV4aeV_LN46mg" target="_blank"&gt;https://mp.weixin.qq.com/s/rbEEJfEoCdV4aeV_LN46mg&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354832/the-gentle-singularity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354832/the-gentle-singularity</guid>
      <pubDate>Sat, 10 May 2025 08:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 据悉与谷歌达成新的云服务协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，OpenAI 与谷歌近期签署了一项新的云服务合作协议以获取更多计算资源。该协议将深化双方在技术领域的合作，涉及高性能计算资源及数据存储服务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/160306_SD6R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新协议旨在支持 OpenAI 的模型训练需求，并优化其产品性能。具体条款尚未公开，但预计将对人工智能行业发展产生重要影响。&lt;/p&gt; 
&lt;p&gt;两家公司尚未就该交易公开宣布任何消息，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fretail-consumer%2Fopenai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10%2F" target="_blank"&gt;但一位消息人士向路透社透露&lt;/a&gt;，谈判已持续数月，最终于 5 月达成协议。&lt;/p&gt; 
&lt;p&gt;自 2019 年以来，OpenAI 就与微软达成了协议，赋予其为这家初创公司构建新计算基础设施的独家权利。因此这笔交易将使 OpenAI 将其计算资源扩展到微软之外。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354829</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354829</guid>
      <pubDate>Sat, 10 May 2025 08:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源网盘应用 Alist 原开发者称项目已交由公司运营</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AList 是一款免费开源、支持多存储的自建网盘程序 (文件列表程序)，可以轻松在 VPS 服务器、NAS、普通电脑 Win、Mac、Linux 上部署。它除了能作为一款自建网盘 (将文件保存在设备硬盘上) 外，最大的特色就是支持「挂载各大主流网盘」。&lt;/p&gt; 
&lt;p&gt;近日，有用户在该项目 GitHub 仓库提交 issue，反馈官网出现 404 问题，并提出」项目是否被卖了」的疑问。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1184" src="https://static.oschina.net/uploads/space/2025/0611/150208_kinx_2720166.png" width="822" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAlistGo%2Falist%2Fissues%2F8649" target="_blank"&gt;https://github.com/AlistGo/alist/issues/8649&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Alist 原开发者 Xhofe 今日在订阅频道发布公告，&lt;strong&gt;称项目已交由公司运营&lt;/strong&gt;，之后会帮助审查开源版本仓库的代码，确保 release 分支由 CI 自动构建。此外&amp;nbsp;main 分支已开启分支保护，后续所有提交均需经过 PR 审核。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/145251_8h2m_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.me%2Falist_news%2F85" target="_blank"&gt;https://t.me/alist_news/85&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354817</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354817</guid>
      <pubDate>Sat, 10 May 2025 07:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包大模型 1.6 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;火山引擎正式发布了豆包大模型 1.6、豆包·视频生成模型 Seedance 1.0 pro、豆包·语音播客模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143623_6g0S_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;全新发布的豆包大模型 1.6 系列由三个模型组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doubao-seed-1.6：All-in-One 的综合模型，是国内首个支持 256K 上下文的思考模型，支持深度思考、多模态理解、图形界面操作等多项能力。支持选择开启或关闭深度思考、自适应思考三种方式，其中自适应思考模式可根据提示词难度自动决定是否开启思考，提升效果的同时大幅减少 tokens 消耗。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-thinking：豆包大模型 1.6 系列在深度思考方面的强化版本；在代码、数学、逻辑推理等基础能力上进一步提升；支持 256K 上下文。&lt;/li&gt; 
 &lt;li&gt;doubao-seed-1.6-flash：豆包大模型 1.6 系列的极速版本，支持深度思考、多模态理解、256K 上下文；延迟极低，TOPT 仅需 10ms；视觉理解能力比肩友商旗舰模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143455_cA7e_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在价格方面，&lt;strong&gt;豆包大模型 1.6 采用统一定价模式，首创按「输入长度」区间定价&lt;/strong&gt;，在企业使用最多的输入区间 0-32K 范围内，豆包大模型 1.6 的价格为输入 0.8 元/百万 tokens、输出 8 元/百万 tokens，综合成本比豆包 1.5·深度思考模型、DeepSeek R1 降低 63%。&lt;/p&gt; 
&lt;p&gt;Seedance 1.0 pro 模型每千 tokens 0.015 元，相当于每生成一条 5 秒的 1080P 视频只需 3.67 元，行业最低。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/143521_DcAP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;豆包·实时语音模型已全量上线火山方舟，对企业客户开放使用。该模型支持自然语言高级指令控制，具备唱歌表演、声线模仿、方言演绎等多种能力，语气、用语、思考方式等拟人感大幅提升，能随时打断与主动搭话。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354815</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354815</guid>
      <pubDate>Sat, 10 May 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cline 提供为期两周的免费 Grok-3 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 与 AI 代码工具开发商 Cline&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcline%2Fstatus%2F1932513639015329822"&gt;合作&lt;/a&gt;，为 Cline 用户提供为期两周的 Grok 3 模型免费访问权限。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082d9ece19970284ff4cd71ee2adcb88880.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需注册 Cline 账户，即可在 Cline 的提供商中选择并免费使用 x-ai/grok-3 模型进行编码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0611/142036_91S3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cline 是开源 AI 编程 Agent，以 VS Code 插件的形式提供，支持 Plan/Act 双模式，具有终端执行能力和 Model Context Protocol (MCP) 特性。它能够分析用户的项目文件结构、源代码等，帮助用户创建和编辑文件、执行终端命令、使用浏览器进行测试等，还可以通过 MCP 协议扩展其功能，添加自定义工具。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354810</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354810</guid>
      <pubDate>Sat, 10 May 2025 06:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>TickIt：基于 LLM 的自动化 Oncall 升级</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt; 
 &lt;div&gt;
  资料来源：
  &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2F" target="_blank"&gt;火山引擎-开发者社区&lt;/a&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  软件工程领域顶级学术会议之一 FSE 2025（The ACM International Conference on the Foundations of Software Engineering）预计将在 2025 年 6 月于挪威特隆赫姆举行，字节跳动 ByteBrain 团队的论文《TickIt: Leveraging Large Language Models for Automated Ticket Escalation》成功入选
 &lt;/div&gt; 
 &lt;div&gt;
  （https://arxiv.org/abs/2504.08475）。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  背景
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在云计算技术蓬勃发展的当下，对于火山引擎来说，工单/Oncall 成为了客户与技术支持&amp;amp;SRE 团队沟通的关键桥梁。随着云服务规模的不断扩大，每日会产生数以千计的 Oncall。这些 Oncall 通常以自然语言的形式，涵盖了使用咨询、功能需求，系统故障等各类复杂问题。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在传统的手动升级模式下，Oncall 值班人依赖个人经验判断工单是否严重，进而决定是否应该进一步升级。这一过程很依赖值班人员的经验判断，也难以形成统一标准。在过往的案例研究与故障覆盘中，我们发现由于人为疏漏，部分严重问题没有及时升级处理，从而导致了稳定性下降的风险，这也可能对火山引擎的客户满意度造成负面影响。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  如何在面对紧急问题时，及时识别并升级这些 Oncall，成为了提升客户满意度和保障服务质量的关键所在。针对这一问题，我们提出了 TickIt，旨在识别紧急的、报告严重问题的 Oncall，并及时地将其升级给产研/稳定性/故障应急等团队。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  挑战
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Oncall 问题具有显著的多样性，不同类型的问题需由不同专业背景的人员进行处理。例如，系统故障需要产研&amp;amp; SRE 迅速定位并修复，以减少服务中断时间；客户投诉以及负面情绪则需要客户经理及时安抚客户并解决问题，进而提升客户满意度。进一步来说，Oncall 问题还可进一步细分，例如判断其影响面大小、是否对业务有损等。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  现有的基于特征工程的分析方法，对 Oncall 内容的语义理解能力也较为有限，在实际应用中难以准确识别关键问题，致使重要 Oncall 无法及时升级处理。此外，Oncall 的严重程度也可能在对话过程中被（动态地）逐步澄清，而一些现有方法仅进行一次性分类，忽略了对话中不断更新的信息，无法在线及时识别到需要升级的情况。
 &lt;/div&gt; 
 &lt;div&gt;
  此外，挖掘 Oncall 之间的关系同样重要。当一个问题影响多个客户时，会产生多个相似的 Oncall。如果能及时捕获分析这些 Oncall 之间的关系，有助于更全面地评估问题的严重性与影响范围，而对于产研来说，可以合并这些 Oncall 共同处理，从而更加聚焦地解决问题。
 &lt;/div&gt; 
 &lt;div&gt;
  得益于大语言模型（LLM）在自然语言理解方面的强大能力，我们将其用于辅助理解 Oncall 中的文本信息，但是简单使用 LLM 并不能真正有效的解决上述挑战。在本文中，我们提出了基于 LLM 的 Oncall 分析方法 —— TickIt，该方法可以动态追踪 Oncall 中的信息，还能借助 LLM 深入理解 Oncall 对话的语义内容，及时识别严重问题并升级。同时，TickIt 还能挖掘不同 Oncall 问题现象之间的语义关联，识别潜在的共性问题，实现更高效的问题处理。
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 使用了字节的豆包（doubao）模型，旨在借助大语言模型（LLM）强大的自然语言处理能力，实现高效、准确的 Oncall 升级任务。该框架主要包含基于多分类的 Oncall 升级（Multi-class escalation）、重复 Oncall 分析 (Escalation deduplication) 和基于类别引导的微调（Category-guided fine-tuning）这三个核心功能模块。
 &lt;/div&gt; 
 &lt;div&gt;
  基于多分类的 Oncall 升级
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a38b4514cb694357dbd5a996f44a3ba2.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在 Oncall 升级功能中，TickIt 将 Oncall 升级问题视作多分类任务。依据产研&amp;amp; SRE &amp;amp;客户关系的不同职责和关注重点，预先定义了系统故障、客户投诉、资产损失等多种主题类别。而对于普通 Oncall，统一归为 「其他」 类别（无需升级处理）。为使大语言模型更好地完成 Oncall 多分类任务，TickIt 也在 System Prompt 中采用了一些技术来提升其分类表现，例如赋予其任务角色、思维链（COT）等。例如，在判断一个 Oncall 是否属于系统故障时，模型会分析对话内容中提到的故障现象、影响范围等因素，并逐步解释做出该分类决策的原因。这种方式增强了分类结果的逻辑性和可解释性，让人们更易理解和信任模型的判断。此外，TickIt 通过 Few-shot learning，辅助模型理解不同的 Oncall 类别。这些示例特别对易混淆的场景进行了举例示范，从而帮助模型更准确地区分各类 Oncall 的特征。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 采用在升级任务中所采用的 System Prompt 格式如下图所示：
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//a83ba70159b8a333261baa7c65e4b07e.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 分析
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//3ded1921020057de79c7cfbcfdbb01bd.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 分析是 TickIt 的另一个功能。当一个 Oncall 被判定需要升级时，TickIt 会对所有处于「Pending」状态的 Oncall 进行检查，以确定是否有类似问题已被升级。为此，TickIt 将 Oncall 在其生命周期中的状态抽象为有限状态机。当客户提交 Oncall 工单并被接受后，该 Oncall 对象进入 「Active」 状态。每当 Oncall 中有新的对话内容时，最新的对话记录会触发 TickIt 启动新一轮分析，此时将其设置为进入 「Analyzing」 状态。TickIt 会运用上述的基于多分类的升级方法，判断当前 Oncall 是否需要升级。如果被分类为 「其他」，则其状态返回 「Active」，等待下一轮对话交互；若被分类为预设好的严重问题类型中，则进入 「Pending」 状态，此时 TickIt 会检查是否有相似的 Oncall 已经被升级。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在判断 Oncall 是否重复时，TickIt 首先利用大语言模型提取 Oncall 中的问题描述，并借助 doubao-embedding model 将这些问题描述转化为向量表示。通过 consine similarity 来计算向量之间的相似度，并通过一个阈值参数 𝜃 来判断当前 Oncall 与已升级的 Oncall 是否相似（𝜃 通过参数选择实验确认，在本方法中 𝜃=0.88）。对于 TicketIt 判定当前需要升级的 Oncall，如果历史已有升级且相似的 Oncall，则会将当前 Oncall 与对应的历史 Oncall 进行关联，并不再重复告警（仅在关联工单中体现）。同时，TickIt 会将当前 Oncall 与已重复会利用大语言模型重写问题描述，从语义上更全面地归纳该类问题的共性特征，避免因个别 Oncall 工单描述的局限性而导致对问题的理解偏差。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  基于类别引导的微调
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//9a20ab7d348eaba17524ba79b94e8374.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  类别引导的微调是 TickIt 不断优化准确率的关键机制。当一个 Oncall 按照上述的流程被升级后，TickIt 会发送包含 Oncall 问题摘要的提醒通知卡片。通知卡片中有三个交互按钮，其中两个分别用于点赞或点踩；第三个按钮则是一个 Oncall 跳转链接，点击后可直接跳转到相关的聊天群中。TickIt 则会记录下这些通知卡片的交互行为作为自动升级的反馈数据。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//74dd763b0ca8e181846e69dffbc00e72.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在处理这些反馈数据时，TickIt 采用监督微调（SFT）方法，一条典型的 SFT 数据同时包含「对话内容」（Oncall 原始信息），「LLM 思考过程与类别判断」（LLM 的输出）。并按照 TickIt 用于 Oncall 升级任务的 System Prompt 来进行组织成数据集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  我们对四种反馈动作设置了不同的优先级，以避免同一 Oncall 下存在冲突的反馈。其中直接反馈（点赞、点踩）都会被纳入 SFT 的数据集中。根据我们的观察，相较于正面反馈（点赞）人们通常会在 Oncall 升级错误时更倾向提供一些负面反馈（点踩）。因此，点赞的数量要远小于点踩，也正是出于此原因，我们将点赞的优先级设置为最高（至少有一个人认为该告警是有帮助的）。而对于点踩的反馈来说，通常是认为误告警，因此则将其目标类别设置为「其它」（如无指定类别说明）。在该情况下，由于仅仅知道目标类别，而缺乏 COT 所需要的推理步骤，TickIt 则利用大语言模型完成目标分类下思维链步骤的补充。考虑到思维步骤的多样性，TickIt 会对每个 Oncall 进行三次可能思维链步骤的采样，以丰富数据集。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  通过这种方式，TickIt 能够处理用户反馈，并基于类别引导进行数据增强，最终构建出一个高质量的标注数据集。当积累了足够数量的标注数据后，TickIt 会运用 SFT 方法对模型进行离线优化，然后更新在线模型，从而不断提升模型在升级分类任务上的性能表现。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 的实验验证
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 在火山引擎的线上进行了全面部署，并取得了显著成效。在此期间，TickIt 共处理了数以万计的 Oncall。在收到的反馈中，约 81% 的反馈表明 TickIt 的升级决策是准确的，这也证明了 TickIt 在实际应用中的有效性和可靠性。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在进一步的 Oncall 升级性能评估方面，我们还对比了基于小语言模型（SLM）和大语言模型（LLM）的多种方法。小语言模型受限于参数规模，其语言理解能力相较 LLM 有较大差距，且部分非端到端的方法设计在信息传递过程中易出现信息丢失的情况。而基于 LLM 的方法则展现出了良好的准确率。我们通过消融实验验证了不同框架设计对模型性能的影。使用 CoT 的 LLM 方法，准确率和召回率均能达到 82% 左右。在此基础上，结合反思（Reflection）提示，模型能够对自身的推理和输出进行自我纠正，精度略微提升至 82.8%。但由于 CoT 提示已经使模型在得出结论前进行了充分的推理，在反思阶段模型难以获取新的关键信息来进一步提高输出的准确性和洞察力，因此反思技术对实验结果的提升效果并不显著。引入上下文学习（ICL）提示后，模型的召回率大幅提升至 89.2%，尽管精度略有下降，但这一结果充分体现了 LLM 方法强大的泛化能力。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//8b040985eb15eb72e4893c729c56be70.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在不同方法设计下的 Oncall 升级比较
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  进一步对 LLM 进行监督微调（SFT）后，模型性能得到了显著提升。以 CoT 提示为例，微调后的召回率从 82.1% 大幅提高到 91.2%，同时保持了 81.8% 的较高精度，F1 分数达到了 86.2%，在所有对比方法中表现最佳。这一结果有力地证明了 SFT 在利用 LLM 能力提升 Oncall 升级任务性能方面的有效性。然而，当 SFT 与其他基于提示的方法（如 Reflection 和 ICL）结合时，性能出现了轻微下降。这可能是因为 SFT 过程中使用了 ICL 中的一些样本或与训练数据分布相似的数据，使得模型在离线微调时已经学习了相应内容，从而在结合使用时产生了一定的冲突。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  在重复 Oncall 分析的实验中，通过调整相似度阈值来探寻最合适的参数，该参数在 0.86 - 0.95 之间时，F1 分数会随着参数的升高先上升后下降。当其设置过高时，严格的相似度约束可能会导致相似问题被错误分类到不同类别，使得评估结果中升级 Oncall 的数量相较于真实情况出现偏差，且该偏差与阈值并非单调关系。此外，基于问题现象的去重方法本身存在一定局限性，对于表现相同但根因不同的 Oncall，可能会出现错误去重的情况。而在针对 Oncall 问题重写的设计中，我们也进行了消融实验。实验结果表明，开启重写功能的 TickIt 相较于未开启该功能的实验设置来说，F1 分数提升了 1.7%。进一步对数据集进行分析，仅保留包含多个关联 Oncall 的升级进行实验，结果显示 TickIt 中的重写设计使得其 F1 分数从 0.706 提升至 0.749，提升幅度达到 6.1%。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//f44da441270f9c510f3972871725a119.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  重复 Oncall 识别下的参数选择实验
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &lt;img src="https://oscimg.oschina.net/oscnet//685b195201866bfe500add599463e6ee.jpg" referrerpolicy="no-referrer"&gt;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  Ticket 在重复 Oncall 识别下的问题重写消融实验
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  总结与局限性分析
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  TickIt 借助大语言模型实现了高效的自动化 Oncall 升级，为火山引擎带来了显著的效率提升。它从「帮助人们及时介入严重 Oncall」的角度，帮助火山引擎缩短了严重问题的响应时间，使得整体的 MTTR 降低了约 26%，并节约了人力投入成本。同时，TickIt 也得到了使用者的广泛认可。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  然而，TickIt 在实际应用中也暴露出一些局限性。对话中（个性化的）表达方式可能会对大语言模型的判断产生影响。例如，部分使用者可能会夸大问题的影响，导致不必要的升级；而有人也可能对严重问题描述过于平淡，使得 TickIt 未能及时识别出需要升级的情况。此外，如果 Oncall 所关联的云服务产品不够具体，相似的问题描述可能会因涉及不同的云服务产品而具有不同的严重程度，这容易导致大语言模型的误判，进而出现错误的升级。我们在后续的工作中会进一步优化 TickIt 的实际效果，助力火山引擎的稳定性工作。
 &lt;/div&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;div&gt;
  作者团队： 我们来自字节跳动的 ByteBrain 团队，我们致力于用 AI 技术，为各种基础架构与系统（数据库、云原生、大数据、网络等）降本增效、提升稳定性。
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354786</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354786</guid>
      <pubDate>Sat, 10 May 2025 03:46:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>3D 大模型公司 VAST 再获数千万美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;3D 大模型公司「VAST」宣布再次完成数千万美元的 Pre-A+轮融资，同时正式发布了全球首个 AI 驱动的一站式 3D 工作台 Tripo Studio，并即将推出全新算法 Tripo 3.0。&lt;/p&gt; 
&lt;p&gt;据称此次融资将重点投入 Tripo 系列大模型研发及 Tripo Studio 产品及生态平台建设，加速构建「AI+3D」全产业链条，打造「基础模型 + 生态插件 + 原生工作台」的端到端产品体系，从而构建覆盖专业级（PGC 生产者）、达人级（PUGC 创作者）到大众级（UGC 用户）的创作者画像完整梯度。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/114227_dFcn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，VAST 成立于 2023 年 3 月，是一家专注于通用 3D 大模型研发的 AI 公司，致力于通过打造大众级 3D 内容创作工具建立 3D UGC 内容平台，使基于 3D 的空间成为用户体验升级、内容表达创新和新质生产力提升的核心要素。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0402/185956_RSvr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;自 2024 年初起，VAST 持续迭代 Tripo 大模型，先后推出 Tripo1.0 至 Tripo2.5 等数十亿参数规模的 3D 大模型系列，同时发布 TripoSR、TripoSG、TripoSF 等广受全球开源社区认可的 3D 基础模型，并配套开发了系列 3D 软件生态插件。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/345674/vast-opensource-unirig" target="news"&gt;生成式 3D AI 公司 VAST 最新开源：通用自动骨骼绑定框架 UniRig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/342506" target="news"&gt;生成式 3D AI 公司 VAST 开源基础 3D 生成模型 TripoSG 和 TripoSF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354785</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354785</guid>
      <pubDate>Sat, 10 May 2025 03:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 Kendo UI 在实战应用 —— 打通数据链路，重塑业务效率</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在制造与供应链行业应用——打通数据链路，重塑业务效率" src="https://oscimg.oschina.net/oscnet//009b6caaeed5461884780886e08eac09.jpg" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;div&gt;
 在制造与供应链行业中，企业通常面对「信息孤岛」、「任务难协同」、「实时数据难可视」等挑战。
 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;作为一套成熟的 Web 界面控件解决方案，凭借其丰富的组件库与卓越的数据交互能力，已成为制造系统中构建高效、清晰、可操作用户界面的有力工具。
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;是带有 jQuery、Angular、React 和 Vue 库的 JavaScript UI 组件的最终集合，无论选择哪种 JavaScript 框架，都可以快速构建高性能响应式 Web 应用程序。通过可自定义的 UI 组件，Kendo UI 可以创建数据丰富的桌面、平板和移动 Web 应用程序。通过响应式的布局、强大的数据绑定、跨浏览器兼容性和即时使用的主题，Kendo UI 将开发时间加快了 50%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;行业关键痛点与挑战&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 生产排程混乱，难以动态调整&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;排产表手工维护，任务依赖关系不清晰；&lt;/li&gt; 
 &lt;li&gt;一旦生产任务调整，工序安排需人工同步，极易出错。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 物料与库存信息分散，数据透明度低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;原材料、在制品、半成品和成品数据分布于不同系统；&lt;/li&gt; 
 &lt;li&gt;缺乏统一视图，容易导致缺料、积压或发错货。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 设备利用率、产能瓶颈难以量化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;设备运转状态、停机时间、工单完成率难以直观掌握；&lt;/li&gt; 
 &lt;li&gt;管理层缺乏实时运营看板支撑决策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多角色协同效率低&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;采购、仓储、生产、质检等部门使用界面风格不一致；&lt;/li&gt; 
 &lt;li&gt;操作体验差，培训成本高，数据流转阻断。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Kendo UI 提供的关键解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;1. 精准的生产排程与任务可视化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gantt Chart 控件&lt;/strong&gt;：可视化呈现排程计划，支持任务依赖、拖拽重排、进度条展示，帮助排程人员动态优化排产逻辑。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduler 日历控件&lt;/strong&gt;：用于设备维护排程或产线预约，支持多资源并发视图。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;2. 统一的库存数据展示与交互操作&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Grid + 分组 + 分页 + 导出功能&lt;/strong&gt;：构建灵活的物料清单、库存看板，支持层级显示与动态筛选。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TreeView + PanelBar&lt;/strong&gt;：适用于多仓库、多区域的库存结构导航。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AutoComplete / MultiSelect&lt;/strong&gt;：提升物料录入与搜索效率，防止错录错查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;3. 实时可视化的运营监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Charts 图表组件（柱状图、折线图、圆环图等）：展&lt;/strong&gt;示各产线设备的稼动率、生产效率、工单完成情况等关键指标。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sparkline 小型趋势图&lt;/strong&gt;：适用于嵌入表格单元格中，轻量快速展现某项指标走势。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ProgressBar + KPI 指标块组合&lt;/strong&gt;：适合构建实时工厂大屏或车间电子看板。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;4. 多端一致的界面交互体验&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;响应式布局组件（ResponsivePanel / Drawer / TabStrip）：&lt;/strong&gt;适配桌面与平板设备，统一各角色使用体验。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload + Dialog + Tooltip + Notification&lt;/strong&gt;：用于上传质检报告、操作提示与反馈，提升人机交互流畅度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;丰富的表单验证机制&lt;/strong&gt;：确保关键业务数据录入安全、准确。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;应用场景示例&lt;/strong&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="界面控件 Kendo UI 在制造与供应链行业应用——打通数据链路，重塑业务效率" src="https://oscimg.oschina.net/oscnet//181f48127f99e600559a7997cf56e624.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;在数字化制造转型的背景下，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F3438" target="_blank"&gt;Kendo UI&lt;/a&gt;不仅是「界面构建工具」，更是连接业务流程与数据决策的桥梁。它以高可定制、高性能的前端控件能力，为制造与供应链行业提供了稳定、高效、专业的用户交互解决方案。从排程到仓储、从设备监控到多角色协同，Kendo UI 为企业打造真正可视、可控、可运营的管理界面，助力制造企业迈向数字化高质量发展。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354778</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354778</guid>
      <pubDate>Sat, 10 May 2025 03:25:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>百度百舸万卡集群的训练稳定性系统设计和实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;h1&gt;01 AI 训练稳定性的演进历程&lt;/h1&gt; 
&lt;p&gt;2012 年 ImageNet 竞赛中 AlexNet 的横空出世，开启了现代 AI 发展的新纪元。彼时我们不会想到，十年后支撑 AI 训练的 GPU 集群会从研究室里的几台服务器，发展成需要专门供电系统的万卡级计算矩阵。在这个算力爆发式增长的过程中，训练系统的稳定性管理正经历着从「简单运维」到「精密工程」的深刻变革。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 标早期的小模型时代：手动运维的黄金年代&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;2022 年之前的 AI 训练，更像是手工作坊式的精雕细琢。大多数训练任务只需十几块 GPU，利用 PyTorch 或 TensorFlow 的数据并行功能就能轻松应对。记得那时算法工程师们有个共识：如果训练遇到问题，重启往往比排查更高效。&lt;/p&gt; 
&lt;p&gt;当时我们构建的监控系统就像汽车仪表盘，只能显示最基本的任务状态。当训练意外中断时，工程师们会像侦探一样翻查日志 —— 如果发现是 GPU 报错，就联系运维同事。运维人员则带着「NVIDIA 三件套」（nvidia-smi、dcgm、nsys）到机房巡检，像老中医把脉般通过温度、功耗等指标判断硬件状态。这种工作模式虽简单，但应对数十卡规模的集群还算游刃有余。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&lt;/strong&gt; &lt;strong&gt;大模型风暴：从量变到质变的冲击&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;ChatGPT 的登场如同打开潘多拉魔盒，将 AI 训练带入新的纪元。当我们开始部署千卡/万卡集群时，才发现原有的运维体系就像用小渔网捕鲸鱼 —— 完全无法匹配新需求。&lt;/p&gt; 
&lt;p&gt;让我们通过百度百舸经历过的一个真实案例来深入理解这个问题：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;2024 年初，百度百舸帮助一家 AIGC 创业公司迅速将其训练规模从百卡扩展到千卡级别。然而在训练数天后的某个周末凌晨，训练进程意外发生了 hang 死。由于当时缺乏有效的故障感知和容错机制，直到第二天算法工程师发现任务超时退出时，已经耽误了数小时宝贵的训练时间。更糟糕的是，任务日志中除了简单的 timeout 报错外毫无线索，平台监控也显示所有训练节点状态正常。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;着急恢复训练的算法工程师没有立即上报问题，而是选择直接重新提交任务。但不幸的是，新任务运行数小时后再次出现相同的超时退出。这时他们才不得不寻求技术支持，但值班工程师面对这种任务 hang 死的问题也缺乏诊断经验，只能通过二分法慢慢定位。最终发现是某个节点的静默故障（SDC）导致了训练进程假死。等问题得到解决时，距离首次故障已经过去将近 30 小时，这意味着损失了价值巨大的千卡算力资源。&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;02 百度百舸集群训练稳定性全景图&lt;/h1&gt; 
&lt;p&gt;站在现在的时间点回望，AI 训练稳定性已从辅助功能演变为核心基础设施。就像现代建筑中的抗震结构，它虽不直接参与空间构成，却是万丈高楼得以屹立的关键。当行业向着数万卡集群迈进时，这套隐形护甲的质量，将直接决定 AI 进化的速度与边界。&lt;/p&gt; 
&lt;p&gt;在 2024 年百度百舸对训练过程的生命周期进行了更细致的拆分，提出了「无效训练时间」这一关键指标，并致力于将其最小化。具体来说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;任务无效训练时间 = 故障中断次数 × 任务故障恢复时长 + 任务常态写 Ckpt 总时长&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;其中，任务故障恢复时长 = 故障感知召回耗时（自动/人工定位）+ 任务调度耗时 + 任务初始化耗时 + 任务重算时长。&lt;/p&gt; 
&lt;p&gt;通过这个公式可以看出，要降低无效训练时间，需要「围绕基础设施稳定性」、「任务容错」两个维度来系统展开，重点解决三个方面的问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;提高基础设施的交付质量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提高任务故障容错的召回率、准确率和时效性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优化 checkpoint 机制，减少保存时间和恢复时的重算时间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过容错架构的整体变革，百度百舸形成了从 「任务负载 —&amp;nbsp;框架 —&amp;nbsp;通信&amp;nbsp;—&amp;nbsp;基础架构」全链路的自动异常感知、诊断、恢复能力，可覆盖 90%+ 的训练异常场景，时效性最快可以实现秒级异常感知、分钟级定位，以及平均 3 分钟的故障自愈能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5a9c915ac6d0cd3d443262a00768d1aeebb.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;03 基础设施交付质量保障&lt;/h1&gt; 
&lt;p&gt;基础设施的交付质量保障是稳定性的基础。&lt;/p&gt; 
&lt;p&gt;CPU 时代，机器的交付前可能仅会跑一些常规的 CPU 计算、网络的压力测试，并不会从业务视角去评估基础架构，机器交付后硬件异常的故障频率相对较少。有硬件故障时，通常走工单系统人工换机用户相对是可接受的。&lt;/p&gt; 
&lt;p&gt;而 GPU 时代，AI Infra 的交付则需要考虑 CPU、GPU、RDMA 网络、存储，甚至机房的功率、温度等各方面因素，遗漏任何一个环节都会成为后续稳定性的隐患。在交付给客户后，机器也可能会由于长时间的高负载运行频繁出现硬件故障，而 GPU 机器的高昂成本，使客户对节点故障感知、换机的时效性提出了非常高的要求。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-08b3f03a6cfd9c28b1a6a2f175eb081f37f.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;因此百度百舸对 GPU 机器交付前及交付后的稳定性质量进行了系统性管理：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;交付前，百度百舸会对机器进行 200 多项指标检测，然后进行 48 小时烤机，以及 NCCL-Test 的机内、机间的大环、同号卡通信性能基准测试，端到端的大模型训练、推理性能基准测试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;交付后，需要能够实时的感知节点故障及定期巡检，并具备分级处理的自愈能力，例如 Error 级别的故障实现自动排水、重启，Fault 级别故障实现自动换机。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;04 任务容错的准召率保障&lt;/h1&gt; 
&lt;p&gt;任务层面稳定性最核心的就是做好容错，能够让业务在无论遇到何种故障时都能快速恢复。&lt;/p&gt; 
&lt;p&gt;那么，首要的工作就是我们能够准确的识别出异常，然后对故障进行诊断定位，最后能够自动化的从异常中恢复。&lt;/p&gt; 
&lt;p&gt;因此，任务容错需要能够从端侧（即每个训练 worker）探测到进程与环境的各类异常，同时有个中心服务（Master）从任务全局的视角去诊断、定位异常，最终做出相应的决策来使任务能够快速从异常中恢复。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bede84ad1e729a350a1750dbfde88615822.webp" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务容错最重要的就是提升故障的召回率与准确率，即如何能够尽可能的准确识别、定位所有故障。我们将故障分类两类：显式故障和隐式故障。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;显式的故障通常比较容易召回，我们将实践积累的各种进程异常状态及各类报错 pattern 形成专家知识库，再结合硬件感知服务（HAS Agent）的硬件全链路 10 秒级监控能力，可以实现显式故障的召回率达到 95%+。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;隐式的异常则往往很难轻易的识别，例如训练进程 hang、慢节点就是典型的隐式故障，需要丰富的经验积累才能准确的识别出异常。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下面我们就以最典型的隐式故障场景 —— 训练进程 hang 死为例，来看下如何能够做好 hang 自动感知、诊断。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 训练****hang 的自动感知&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;训练任务发⽣ hang 之后，绝⼤多数情况都会以 timeout 的⽅式报错并退出进程，最常⻅的就是在通信过程中如果发⽣ hang，NCCL 的 watchdog 会中断通信，并有报如下 timeout 报错，然后再由 pytorch 的 torchrun 进程感知并中断训练过程。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[E ProcessGroupNCCL.cpp:828] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802710 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=15173, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1802713 milliseconds before timing out.



&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pytorch 默认为 10 分钟 NCCL 通信超时，而 Megatron-LM 为 30 分钟。在万卡规模训练场景中，意味着一万张卡要至少浪费 30 分钟才能被发现。这个时效性是不可接受的。而且当 30 分钟超时后程序会立马退出，很难有机会进行下一步定位，需要一些时效性更高的感知机制，并且在程序退出前获取一些有效信息供后续诊断分析。&lt;/p&gt; 
&lt;p&gt;很多公司、实验室在面对 hang 的问题时，会在采用框架层插桩的方式来 trace 训练进程，这种方式通常是比较直接且准确的，但是有比较强的侵入性，而且可能还会有一些性能开销。对于云厂商来说，需要寻找对用户更透明、更无损的方式来感知、定位 hang 异常。&lt;/p&gt; 
&lt;p&gt;如何感知训练 hang，以百度百舸的产品设计思路为例，我们可以从以下几个方向去思考：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;训练进程 hang 的最直观表现是什么？&lt;/p&gt; &lt;p&gt;人工判断一个任务是否 hang 了，最直接的方式就是看是否所有 worker 的任务日志一段时间内都不输出日志了，所以 hang 自动感知的第一种方法就是采集所有 worker 的日志，并判断所有 worker 日志中最后一行日志是否为 x 分钟前的（x 小于 Pytorch 的通信超时时间，例如 8 分钟），如果是则基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时进程有什么样的表现？&lt;/p&gt; &lt;p&gt;任务 hang 时，可能进程的调用栈都不在发生变化，进程的调用栈可以通过 py-spy/pystack 等工具进行探测，所以我们可以用此类工具对所有训练任务进行一个定时采样，当采集 n 个样本所有进程栈都没有变化时，可以判定一次 hang，这种方式通常可以将 hang 感知缩小至 3～5 分钟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;任务 hang 时监控指标有哪些变化？&lt;/p&gt; &lt;p&gt;训练进程中的 CUDA 算子计算、集合通信操作通常都是在毫秒，甚至微秒、纳秒内完成的，当任务在正常迭代过程中发生了 hang，我们常遇到的情况是所有 rank 的 RDMA 流量会降到 0，而 GPU 的利用率为 100%、SM 利用率则在很低的水位。如果持续几分钟都是这种状态时，意味着训练进程已经计算完成，在等着集合通信完成，这种情况下基本可以判定为 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;是否能在通信库中更快的感知通信 hang？&lt;/p&gt; &lt;p&gt;通常单次集合通信操作都是在 ms 级的，如果一次操作在 30 秒钟都没有完成，那就可以判定为通信 hang 死了。百度自研的 BCCL 集合通信库层可以对每一次集合通信操作都进行打点，来实现通信 hang 感知。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;上述几种方法，我们可以分别实现一种探针，来抓取相应的特征到中心端 master 组件进行下一步诊断和容错决策。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;百度集合通信库 BCCL 是百度智能云推出的一款面向大模型训练场景优化的集合通信库。&lt;/p&gt; 
 &lt;p&gt;BCCL 基于开源的 NCCL 进行了功能扩展和能力增强，针对大模型训练场景在可观测性、故障诊断、稳定性等方面进行优化，进一步提升集合通信库的可运维能力。相比 NCCL，BCCL 的关键特性如下：&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;可观测性：新增集合通信带宽实时统计能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;故障诊断：新增集合通信 hang 时的故障诊断能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;稳定性：增强网络稳定性和故障容错能力；&lt;/p&gt; 
 &lt;p&gt;*&amp;nbsp;性能优化：提升大模型训练主流 GPU 芯片的集合通信性能。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;strong&gt;4.2&lt;/strong&gt; &lt;strong&gt;训练 hang 的自动诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;有了以上感知手段，我们需要进一步的诊断、定位，来确定是否真的发生了 hang，以及 hang 的具体位置。具体的来讲，master 收集到各类 agent 的数据后，会做一些综合分析：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;是否真的发生了 hang？&lt;/p&gt; &lt;p&gt;感知阶段各种探针只能探测到 hang 的一种特征，并没有办法 100% 的确定是否真的 hang 住了，事实上不侵入用户进程是很难做到 100% 确定 hang 的。因此，为了提高 hang 的判定准确率，我们需要将各种特种综合起来判断，探针上报到 master 后，由一个 hang 诊断模块，按照一个时间窗口（例如 5 分钟），进行综合判断。如果在时间窗口内日志、监控、进程调用栈、通信库中有 2 条以上都处于不处于活跃状态时，我们判断任务真正发生了 hang。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;hang 的具体发生的位置？&lt;/p&gt; &lt;p&gt;确定任务 hang 了之后，我们需要找到 hang 所在的节点来对它进行隔离。因此诊断模块需要在探针上报的数据中进一步找寻特征，来确定 hang 发生的位置：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BCCL Tracehang 诊断：在感知阶段，BCCL 可以在通信库层面对所有 rank 的通信进行打点。如果有节点一直未完成通信则是发生了 hang。但是此节点可能并非真正发生 hang 的源头，有可能是在等待其他节点完成通信。诊断模块可以根据 BCCL 打印的通信组信息，进行交叉判断，如果某个节点在多个通信组中都未完成通信，那这个节点就是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA/GPU 指标诊断：上文中我们提到，通信阶段发生 hang 之后，所有 rank 的 RDMA 流量都会降到 0，而同时绝大部分 rank 的 GPU 利用率持续为 100%，只有某一两个 rank 的 GPU 利用率为 0，那这个 rank 很有可能是 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调用栈诊断：进程调用栈也可以作为一个 hang 源头诊断的重要参考。当发生 hang 之后，绝大部分的 rank 都要么处于 barrier 等待状态，要么处于通信等待阶段。只有个别的 rank 卡在其他函数上，那么通过对比分析，可以将调用栈与其他 rank 不同的节点初步判定为 hang 的源头。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;综合诊断：上面 3 种特征为我们提供了 hang 的诊断依据，将 3 者关联起来分析后，我们基本上可以比较准确的确定一个具体的 hang 的源头，再结合硬件故障感知的相关信息可以进一步明确根因。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;4.3&lt;/strong&gt; &lt;strong&gt;基于 eBPF 的隐式故障感知与诊断&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在复杂的大规模分布式训练场景中，传统用户态监控往往难以捕获系统内核层面的异常事件。&lt;/p&gt; 
&lt;p&gt;百度百舸基于 eBPF（Extended Berkeley Packet Filter）技术的隐式故障感知体系，能够在不侵入用户代码的前提下，对训练进程的系统调用、网络通信、CPU 调度等内核态行为以及训练框架关键函数运行时间建立立体观测能力。&lt;/p&gt; 
&lt;p&gt;eBPF 探针部署原理通过在内核关键路径注入轻量级探针，实现低开销的系统级行为捕获。针对训练场景特点，主要聚焦 4 类事件跟踪：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练关键函数跟踪：微秒级跟踪训练过程中，前向计算、反向计算、集合通信操作等关键函数执行耗时，记录函数间调用关系。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进程调度阻塞跟踪：挂钩 sched_switch 事件，检测进程在 TASK_UNINTERRUPTIBLE 状态持续时间，当单次持续超过阈值（如 5 秒）时捕获调用栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CUDA 运行时 API 监控：通过 uprobe 在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flibcuda.so" target="_blank"&gt;libcuda.so&lt;/a&gt; 等关键库注入探针，记录 CUDA API 调用耗时分布。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RDMA Verbs 级通信监控：在 ibv_post_send/ibv_poll_cq 等核心通信接口设置观测点，统计通信时延分布。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;结合上面 4 类事件，完成以下 2 类数据分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单体异常探测基线与实时数据对比。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;群体一致性检测。采用卡间对比算法，当某一 rank 的以下指标偏离集群中位数超过阈值时判定异常，包括系统调用频率、进程就绪队列等待时长、NVLink/RDMA 带宽利用率等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上所述方法，百度百舸针对以下 2 类典型的隐式故障进行诊断：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;训练 hang 根因定位。通过关联 eBPF 捕获的多维度数据进行如下操作：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;当检测到某 rank 的 GPU &amp;nbsp;Kernel 执行出现分钟级空跑（SM 利用率 &amp;gt; 70% 但无有效计算输出）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;同时伴随该节点 RDMA QP 状态停滞（ibv_poll_cq 无新完成事件）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;内核调度器显示进程处于 D 状态超过阈值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能抖动溯源。基于 eBPF 火焰图、时序图等进行分析：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抓取发生性能下降时段的 CPU on-cpu/off-cpu 堆栈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对比正常时段数据，识别出异常的锁竞争（futex 调用占比上升）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;结合 NUMA 内存访问统计，定位跨 NUMA 内存访问导致的 TLB 颠簸问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此类技术已在百度百舸的万卡规模训练集群中验证，相比单纯依赖应用层监控的方案，将隐式故障的平均检测时间从分钟级缩短至秒级，诊断准确率提升 40% 以上。&lt;/p&gt; 
&lt;p&gt;通过与既有硬件故障感知服务、BCCL 通信库监测体系联动，百度百舸形成了覆盖从硬件到系统内核再到应用层的立体化诊断能力。&lt;/p&gt; 
&lt;h1&gt;05 任务故障恢复的时效性保障&lt;/h1&gt; 
&lt;p&gt;故障恢复的时效性也是容错能力的一个重要指标，反映的是任务从故障发生到再次重新进入训练迭代的时间，恢复效率越高则算力浪费越少。影响到任务恢复效率有 2 个重要因素，一是任务平均中断时间，二是训练重算时间。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.1&lt;/strong&gt; &lt;strong&gt;多级重启策略减少故障中断时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任务发生异常后，上文中我们提到需要经过故障自动感知、诊断和自愈等 3 个环节，那么减少中断时间的核心思想，就是尽可能的缩短这 3 个环节的时间，通过多维度的感知、诊断手段可以将故障发现、定位的时效性降低至分钟级甚至秒级。自愈则需要能够根据不同的诊断结果进行分级恢复和故障屏蔽的能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;单点显式故障：重调度异常节点（replace），对节点进行集群级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;单点隐式故障：重调度异常节点，对节点进行任务级别屏蔽。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;非单点故障：原地重启尝试恢复（restart），无法恢复时重新调度所有节点（resubmit）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过多级重启策略，尽可能避免单点故障引发全部节点的重新调度。在万卡级别的训练场景中，百度百舸将大部分训练异常场景恢复时间从过去的 30min 缩短至现在的 30s 内，成功率到 95%+。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2&lt;/strong&gt; &lt;strong&gt;触发式 checkpoint 减少训练重算时间&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;除了上述的多级任务重启策略外，另一个提高任务故障恢复效率的重要手段就是减少训练重算时间。在探讨具体技术方案之前，我们先来看看目前主流的 checkpoint 保存策略。&lt;/p&gt; 
&lt;p&gt;传统的 checkpoint 保存通常采用固定间隔策略，比如每隔 N 个 step 或每隔 T 小时保存一次，这种方式实现简单但缺乏灵活性，可能会产生大量冗余存储，同时在故障发生时可能会损失较多训练进度。&lt;/p&gt; 
&lt;p&gt;而触发式 checkpoint 则是一种更智能的方案，它根据特定条件或异常事件（如故障、显存不足、显式指令等）动态触发模型状态保存。其核心目标是通过灵活的控制保存时机，减少不必要的存储开销和训练中断时间，从而降低因频繁或冗余保存导致的重算时间浪费。&lt;/p&gt; 
&lt;p&gt;随着大模型训练规模的扩大，还有一种更激进的「零重复 checkpoint」技术，即在每个训练 step 都保存一次 checkpoint。这种方案的优势在于可以将重算时间降到最低，确保故障发生时能够从最近的 step 恢复，几乎不会损失训练进度。但其显著的缺点是存储开销巨大，即使采用增量式存储，仍然需要相当大的存储空间和 I/O 带宽。此外，频繁的 checkpoint 操作也可能影响训练性能。&lt;/p&gt; 
&lt;p&gt;相比之下，触发式 checkpoint 走的是一条平衡之路。我们来看下它实现的几个核心要点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;集成容错：训练进程集成容错的故障感知与定位机制，在进程退出前自动触发保存。这种主动感知机制能够在故障发生的第一时间保存训练状态，最大限度减少进度损失。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高速转储：异步 checkpoint 保存机制会将 checkpoint 暂存到共享内存中，再由外部程序转储至磁盘。当某个节点异常时，容错组件会拉起新节点，并在新节点训练进程启动前，利用 RDMA 技术实现 checkpoint 快速从故障节点转储至新节点，这大大减少了从远程存储拉取 checkpoint 的时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;冗余备份：触发式 checkpoint 也并非完美无缺，例如在节点发生内核 crash 等严重故障时，可能无法触发自动保存。因此，需要通过定期的冗余备份机制进行兜底，确保 checkpoint 不会完全丢失。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;实践表明，当触发式 checkpoint 与异步、增量式的 checkpoint 机制结合使用时，可以在保证数据安全性的同时，显著提高 checkpoint 保存效率，减少训练重算时间。&lt;/p&gt; 
&lt;p&gt;相比零重复 checkpoint 的重型方案，触发式 checkpoint 提供了一个更实用的折中方案，在合理的存储开销下实现较好的容错效果。当然，具体选择哪种方案，还需要根据实际的训练规模、硬件条件和可用资源来权衡。&lt;/p&gt; 
&lt;p&gt;随着分布式训练规模的持续增长，相信未来会出现更多创新的 checkpoint 方案，比如基于预测的主动保存策略、多级存储架构的智能调度等，这些都将为提高大规模训练的可靠性提供新的可能。&lt;/p&gt; 
&lt;h1&gt;06 业务发展对稳定性的要求&lt;/h1&gt; 
&lt;p&gt;AI 训练的稳定性管理已经演变为智能时代的精密工程。从最初靠人工重启解决问题的摸索阶段，到如今能自动感知异常、快速恢复的智能系统，每一次进步都映照着算力规模的跨越式发展。&lt;/p&gt; 
&lt;p&gt;让人不禁思考，在未来十万卡集群的算力洪流中，或许会出现更精妙的动态平衡方案：既能像鹰隼般敏锐捕捉故障征兆，又能如雁群迁移般智能调度资源，在秒级恢复与 PB 级存储成本之间找到新的平衡支点。&lt;/p&gt; 
&lt;p&gt;目前百度百舸支持厂内千卡和万卡集群有效训练时长已经可达 99.5%，为客户大模型的预训练保驾护航，比如国内第一个数学大模型——九章算术，国内第一个类 Sora 大模型 —— Vidu 等。&lt;/p&gt; 
&lt;p&gt;----------END----------&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604282%26idx%3D1%26sn%3Dbf4ca5dcc5420b035888229cb177c562%26scene%3D21%23wechat_redirect" target="_blank"&gt;LLM 增强语义嵌入的模型算法综述&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604236%26idx%3D1%26sn%3D1b8ff1181ea3dc12ede0b0e849f009c6%26scene%3D21%23wechat_redirect" target="_blank"&gt;持续推进「人工智能＋」行动，百度智能云+DeepSeek 为何成为国有企业首选？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604214%26idx%3D1%26sn%3D71c43bcfd51b145fc769c15539570307%26scene%3D21%23wechat_redirect" target="_blank"&gt;GPU 云服务器的软件系统设计和实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604202%26idx%3D1%26sn%3D68fea54ea6869f0bf6d7cd67c11943a6%26scene%3D21%23wechat_redirect" target="_blank"&gt;基于 Flink 的配置化实时反作弊系统&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604182%26idx%3D1%26sn%3D224203a0b523de10d3b6365d9a3a0aa5%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度智能云 xDeepSeek，最具性价比的 DeepSeek 一体机合集来了！&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/17935991</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17935991</guid>
      <pubDate>Sat, 10 May 2025 03:02:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Hugging Face 发布开放权重模型贡献榜：Qwen 与 DeepSeek 跻身 TOP15</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Hugging Face 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fcfahlgren1%2Fmodel-release-heatmap" target="_blank"&gt;发布&lt;/a&gt;开放权重模型贡献榜，中国团队 Qwen 和 DeepSeek 成功入围前 15 名。该榜单表彰为开源社区提供高质量模型权重的团队，其模型广泛应用于学术与产业创新。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-2f6cdc5076cdfa96c95990be765043ef270.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由阿里巴巴云智能集团支持的 Qwen 团队，以 Qwen3 系列模型在指令跟随、代码生成等任务中的优异表现受到社区青睐。Qwen2.5-72B 系列位列开源大语言模型前列，其轻量化模型 QwQ-32B 通过强化学习优化，在数学推理和代码生成中媲美大型模型，大幅降低部署成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;DeepSeek 则以低成本、高性能的 R1 系列模型闻名。R1-0528 在 LiveCodeBench 排行榜中超越多个国际竞品，仅次于 OpenAI 顶尖模型。其轻量化版本 DeepSeek-R1-0528-Qwen3-8B 通过知识蒸馏技术，单 GPU 即可运行，在 AIME2025 数学测试中击败 Google 的 Gemini2.5Flash，展现了在特定领域的竞争优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Qwen 和 DeepSeek 的入榜反映了中国 AI 团队在开源生态中的崛起。Hugging Face 负责人表示，两团队的贡献为全球开发者提供了高效资源。NVIDIA 首席执行官黄仁勋也赞扬其性能与成本平衡正在重塑 AI 格局。未来，Qwen 计划探索多模态技术，DeepSeek 则将推出 R2 模型，持续推动 AI 创新。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354773/model-release-heatmap</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354773/model-release-heatmap</guid>
      <pubDate>Sat, 10 May 2025 02:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Android 16 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌发布了 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Fproducts%2Fandroid%2Fandroid-16%2F" target="_blank"&gt;Android 16 正式版&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-625ec525ab94813ebb3e980c0109b784e8a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79defc140e2b5a5857ec68c7355fa11d8d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为今年的第一次大版本升级，本次更新的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;面向按键式导航（三大金刚）的预测性返回手势&lt;/li&gt; 
 &lt;li&gt;强制通知分组&lt;/li&gt; 
 &lt;li&gt;以进度为中心的通知&lt;/li&gt; 
 &lt;li&gt;面向 Pixel 设备的桌面模式（开发者选项）&lt;/li&gt; 
 &lt;li&gt;低功耗蓝牙听力辅助设备支持&lt;/li&gt; 
 &lt;li&gt;自定义键盘快捷方式&lt;/li&gt; 
 &lt;li&gt;HDR 截图优化&lt;/li&gt; 
 &lt;li&gt;以旧换新模式等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Android 16 新特性详细介绍查看：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.android.com%2Fintl%2Fen_us%2Fnew-features-on-android%2F" target="_blank"&gt;https://www.android.com/intl/en_us/new-features-on-android/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354766/android-16</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354766/android-16</guid>
      <pubDate>Sat, 10 May 2025 02:42:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>界面控件 DevExpress WPF v24.2 新版亮点：报表等组件功能升级</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF 拥有 120+个控件和库，将帮助您交付满足甚至超出企业需求的高性能业务应用程序。通过 DevExpress WPF 能创建有着强大互动功能的 XAML 基础应用程序，这些应用程序专注于当代客户的需求和构建未来新一代支持触摸的解决方案。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;控件近期全新发布 v24.2，此版本进一步升级了网格、报表、地图等组件的功能，欢迎下载最新版体验！&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346%2Fdownload" target="_blank"&gt;DevExpress WPF v24.2 正式版下载&lt;/a&gt;&lt;/strong&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Grid（网格）控件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多单元格编辑&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;Microsoft Excel 允许您选择多个单元格并通过按 Ctrl + Enter（替代 Enter）应用文本更改，DevExpress WPF Grid 控件中添加了一个类似的特性，允许用户同时对多个单元格应用相同的值。要启用此功能，将&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.DataControlBase.SelectionMode" target="_blank"&gt;GridControl.SelectionMode&lt;/a&gt;设置为 Cell，将&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.Grid.TableView.MultiCellEditMode%3Fv%3D24.2" target="_blank"&gt;GridControl.MultiCellEditMode&lt;/a&gt;设置为 FocusedColumn/AllColumns。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 产品图集" src="https://oscimg.oschina.net/oscnet//a590e16b5907853d6c754e5c5bc46b88.gif" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;PDF Viewer&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;获取在页面缩略图面板中选择的页面&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;新的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;PdfViewer.GetSelectedThumbnailPageIndexes&lt;/a&gt;方法允许您获得在 Page Thumbnails 面板中所选页面的索引，可以在 DevExpress PDF Viewer 中提取、删除或导出选定的页面。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfViewerControl.ActualThumbnailsViewerSettings%3Fv%3D24.2" target="_blank"&gt;PdfViewerControl.ActualThumbnailsViewer&lt;/a&gt;属性来访问实际的缩略图查看器设置，并调用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FWPF%2FDevExpress.Xpf.PdfViewer.PdfThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes%3Fv%3D24.2" target="_blank"&gt;GetSelectedThumbnailPageIndexes&lt;/a&gt;方法来获取页面索引。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;下面的示例将在页面缩略图面板中选择的 PDF 文档的页面保存为图像：&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;&lt;em&gt;C#&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;using System.Windows.Media.Imaging;
using System.IO;
// ...
private void simpleButton_Click(object sender, RoutedEventArgs e) {
// Obtains the selected page indexes.
var pages = viewer.ActualThumbnailsViewerSettings.GetSelectedThumbnailPageIndexes();
// Saves each page from the collection to an image.
foreach (var i in pages) {
BitmapSource image = viewer.CreateBitmap(i, 1000);
PngBitmapEncoder encoder = new PngBitmapEncoder();
encoder.Frames.Add(BitmapFrame.Create(image));
using (var fileStream = new FileStream($"..\\MyBitmap{i + 1}.bmp", FileMode.Create)) {
encoder.Save(fileStream);
}
}
}&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;Reporting（报表）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WPF 报表设计器 - 维度符号&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;为了简化报表设计过程，此更新在&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.evget.com%2Fproduct%2F2346" target="_blank"&gt;DevExpress WPF&lt;/a&gt;报表设计器中引入了维度符号。当您调整控件的大小时，设计器会提供精确的视觉反馈，并根据指定的 ReportUnit 属性值（如英寸、厘米或像素）显示维度符号。&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt="DevExpress WPF v24.2 产品图集" src="https://oscimg.oschina.net/oscnet//b1ccdc0e972820bc31dddac86cddd3d6.png" referrerpolicy="no-referrer"&gt;
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;要管理符号的可见性，请使用&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.devexpress.com%2FXtraReports%2FDevExpress.XtraReports.Configuration.UserDesignerOptions.ShowDimensionNotations%3Fv%3D24.2" target="_blank"&gt;UserDesignerOptions.ShowDimensionNotations&lt;/a&gt;属性。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#ff6600"&gt;&lt;strong&gt;地图组件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持 Azure 地图&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;DevExpress WPF MapControl 现在可以显示 Microsoft Azure 地图数据，使用 AzureMapDataProvider 提供程序获取光栅图像磁贴。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:justify"&gt;&lt;strong&gt;注意&lt;/strong&gt;：在使用 Azure Maps 时，您必须阅读并理解 Microsoft 的使用条款：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fpricing%2Fdetails%2Fazure-maps%2F" target="_blank"&gt;https://azure.microsoft.com/en-us/pricing/details/azure-maps/&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354762</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354762</guid>
      <pubDate>Sat, 10 May 2025 02:36:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>OpenAI 推迟开源模型的发布时间</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 首席执行官山姆·奥特曼宣布，原计划于今年初夏发布的公开权重的开源模型预计&lt;strong&gt;将推迟至夏末发布&lt;/strong&gt;，而不是 6 月与公众见面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-52e03b48d8e7654af9853f14bbc91177053.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他表示研究团队做了一些出乎意料且非常令人惊奇的事情，这非常值得等待，但需要更长的时间。&lt;/p&gt; 
&lt;p&gt;今年 3 月底，OpenAI 宣布将发布自 GPT-2 以来的首个「开源」语言模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346315/open-ai-model-best-opensource-coming-soon" target="news"&gt;OpenAI 正在打造「最强」开源模型，计划今年初夏发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354761</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354761</guid>
      <pubDate>Sat, 10 May 2025 02:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Mistral 推出首个推理模型系列 Magistral</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmistral.ai%2Fnews%2Fmagistral" target="_blank"&gt;宣布推出&lt;/a&gt;其首个推理模型系列 Magistral，采用 step-by-step&lt;/span&gt;&amp;nbsp;&lt;span style="color:#212623"&gt;的方式，以提高数学和物理等主题的一致性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 有两种版本：Magistral Small 和 Magistral Medium。Magistral Small 拥有 240 亿个参数，在 Apache 2.0 协议下开源。Magistral Medium 是一款功能更强大的模型，目前已在 Mistral 的 Le Chat 聊天机器人平台、该公司的 API 以及第三方合作伙伴云平台上提供预览。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;img height="295" src="https://oscimg.oschina.net/oscnet/up-05ff3090a9b8126e0803e475b935c4f0aac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 在博客文章中写道：「Magistral 适用于各种企业用例，从结构化计算和程序逻辑到决策树和基于规则的系统。这些模型针对多步骤逻辑进行了微调，提高了可解释性，并以用户的语言提供了可追溯的思维过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Mistral 成立于 2023 年，该公司得到了 General Catalyst 等风险投资机构的支持，迄今已筹集超过 11 亿欧元（约合 12.4 亿美元）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;尽管 Mistral 资源雄厚，但在某些领域，例如推理模型开发，Mistral 仍落后于其他领先的人工智能实验室。从 Mistral 自身的基准测试来看，Magistral 似乎也并非一款特别有竞争力的版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;在 GPQA Diamond 和 AIME 测试中，Magistral Medium 的表现不及 Gemini 2.5 Pro 和 Anthropic 的 Claude Opus 4。在流行的编程基准 LiveCodeBench 上，Magistral Medium 也未能超越 Gemini 2.5 Pro。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;或许正因如此，Mistral 在其博客文章中大力宣扬 Magistral 的其他优势。声称 Magistral 在 Le Chat 中提供答案的速度是竞争对手的「10 倍」，并且支持多种语言，包括意大利语、阿拉伯语、俄语和简体中文。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:auto !important; margin-right:auto !important; text-align:start"&gt;&lt;span style="color:#212623"&gt;Magistral 的发布是在 Mistral 推出「vibe coding」客户端 Mistral Code 之后。在此之前的几周，Mistral&amp;nbsp;推出了几款专注于编码的模型，并推出了 Le Chat Enterprise，一项面向企业的聊天机器人服务，提供 AI 代理构建器等工具，并将 Mistral 的模型与 Gmail 和 SharePoint 等第三方服务集成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354760/mistral-magistral</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354760/mistral-magistral</guid>
      <pubDate>Sat, 10 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 发布 o3-pro：更强大，但也更「慢」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1932530409684005048" target="_blank"&gt;发布&lt;/a&gt;了 o3-pro 推理模型，基于 o3 所打造，拥有更强的数学、科学、编程等领域的表现。&lt;/p&gt; 
&lt;p&gt;据介绍，o3-Pro 可，自动调用多种工具，包括可以搜索网页、分析文件、推理视觉输入、使用 Python、通过记忆功能个性化回复等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;由于调用的工具较多，所以，思考的时间比 o1 Pro、o3 更长。&lt;/strong&gt;o3-pro 与 o3 系列一样拥有 200K 的上下文窗口和 100K 的输出，但价格却比它们暴降 80%。&lt;/p&gt; 
&lt;p&gt;性能表现上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;o3-pro 在专家评估中，评审人员普遍认为 o3 Pro 在多方面都比 o3 模型更进一步，尤其适合用在科学、教育、编程、商业和写作这些需要深度输出的任务中。&lt;/li&gt; 
 &lt;li&gt;在学术评估的基准测试中，o3-pro 的整体表现持续优于 o1-pro 和 o3。&lt;/li&gt; 
 &lt;li&gt;OpenAI 还通过四次尝试获取正确答案的方式进行实验发现，o3-pro 能保持较好的性能表现。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-440f5fd24e55a09735e48e4783972977b21.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ffff792d97fc13847cc2f83b51f91107089.png" referrerpolicy="no-referrer"&gt; &lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79e4c50f3dc3263fc980ed598022fbf89d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，o3-pro 已向 Pro 和 Team 用户提供，取代 o1-pro；企业版和教育版用户将在下周获得使用权限。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0611/102054_daJ8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;价格方面，o3-pro 输入为 20 美元/百万 token，输出 80 美元/百万 token；而 OpenAI CEO Sam Altman 昨晚宣布，o3 降价 80%——因此 o3 价格来到了输出 2 美元/百万 token、输入 8 美元/百万 token。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/354753/openai-o3-pro</link>
      <guid isPermaLink="false">https://www.oschina.net/news/354753/openai-o3-pro</guid>
      <pubDate>Sat, 10 May 2025 02:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
