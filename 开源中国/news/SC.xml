<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 29 Jul 2025 07:48:36 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>蚂蚁 inclusionAI 团队发布 Ming-lite-omni v1.5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁集团 inclusionAI 团队发布了全面升级版的全模态模型 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finclusionai.github.io%2Fzh%2Fblog%2Fming-lite-omni-1_5%2F" target="_blank"&gt;&lt;strong&gt;Ming-Lite-Omni v1.5&lt;/strong&gt;&lt;/a&gt;，基于 &lt;strong&gt;Ling-lite-1.5&lt;/strong&gt; 构建，总参数量为 &lt;strong&gt;203 亿&lt;/strong&gt;（其中 MoE 部分活跃参数为 &lt;strong&gt;30 亿&lt;/strong&gt;），在图像-文本理解、文档理解、视频理解、语音理解与合成、图像生成与编辑等全模态能力上显著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-95012b461af8180f5480bac2f4c85b95949.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ming-lite-omni v1.5 模型架构如下，主题参考了 Ming-lite-omni v1 版本的结构，区别在于为了增强图像编辑人物和场景一致性，升级 Vision head 支持参考图特征输入。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6c48bdf68ea2bcdfc0e8deb440f605297fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关键优化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;增强视频理解&lt;/strong&gt;：通过 &lt;strong&gt;MRoPE 3D 时空编码&lt;/strong&gt; 和针对长视频的 &lt;strong&gt;课程学习策略&lt;/strong&gt;，显著提升对复杂视觉序列的理解能力 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优化多模态生成&lt;/strong&gt;：采用双分支图像生成（ID 与场景一致性损失）和新的音频解码器及 BPE 编码，提升生成一致性与感知控制，实现高质量实时语音合成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据全面升级&lt;/strong&gt;：新增结构化文本数据、高质量产品信息及包括方言（如普通话、粤语、四川话等）在内的精细化视觉与语音感知数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;性能表现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在 &lt;strong&gt;MMVet&lt;/strong&gt;、&lt;strong&gt;MathVista&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt; 等数据集上表现突出，文档理解任务（如 &lt;strong&gt;ChartQA&lt;/strong&gt;、&lt;strong&gt;OCRBench&lt;/strong&gt;）取得 10B 以下参数模型中的 &lt;strong&gt;SOTA&lt;/strong&gt; 成绩。&lt;/li&gt; 
 &lt;li&gt;视频理解、语音理解与生成（支持多种方言）及图像生成（保持人物 ID 一致性编辑）均处于行业领先地位。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该模型已在 &lt;strong&gt;Hugging Face&lt;/strong&gt; 和 &lt;strong&gt;ModelScope&lt;/strong&gt; 上开放下载，并提供详细安装指南、代码示例和 &lt;strong&gt;Gradio&lt;/strong&gt; 演示。&lt;/p&gt; 
&lt;p&gt;Hugging Face: https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5&lt;br&gt; ModelScope: https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362971</guid>
      <pubDate>Tue, 29 Jul 2025 07:39:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>eBPF 助力 NAS 分钟级别 Pod 实例溯源</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;云存储 NAS 产品是一个可共享访问、弹性扩展、高可靠、高性能的分布式文件系统。 NAS 兼容了 POSIX 文件接口，可支持数千台计算节点共享访问，可挂载到弹性计算 ECS、容器实例等计算业务上，提供高性能的共享存储服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;鉴于多主机间共享的便利性和高性能， NAS 在得物的算法训练、应用构建等场景中均成为了基础支撑。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/36/36274710c18533ce5fc246ee82e640c2.jpeg" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在多业务共享的场景中，单个业务流量异常容易引发全局故障。目前，异常发生后需依赖&lt;strong&gt;云服务厂商 NAS &lt;/strong&gt;的溯源能力，&lt;strong&gt;但只能定位到主机级别，无法识别具体异常服务&lt;/strong&gt;。要定位到服务级别，仍需依赖所有使用方协同排查，并由 SRE 多轮统计分析，&lt;strong&gt;效率低下&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#6a6a6a"&gt;（若服务实例发生迁移或重建，排查难度进一步增加）&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;为避免因 NAS 异常或带宽占满导致模型训练任务受阻&lt;/strong&gt;，因此需构建支持服务级流量监控、快速溯源及 NAS 异常实时感知的能力，以提升问题定位效率并减少业务中断。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、流量溯源方案调研和验证&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;NAS 工作原理&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 本地挂载原理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux 平台上，NAS 的产品底层是基于标准网络文件系统 NFS（Network File System），通过将远端文件系统挂载到本地，实现用户对远端文件的透明访问。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NFS 协议（主要支持 NFS v3 和 v4，通常以 v3 为主）允许将远端服务挂载到本地，使用户能够像访问本地文件目录一样操作远端文件。文件访问请求通过 RPC 协议发送到远端进行处理，其整体流程如下：&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="465" src="https://oscimg.oschina.net/oscnet/up-3f3abf4fce2a08639688cf370284cf62cdd.png" width="620" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;文件系统访问时的数据流向示意&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="552" src="https://oscimg.oschina.net/oscnet/up-a5b7a533fbca51c726053b4598e79c9786f.jpg" width="507" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;Linux 内核中 NFS 文件系统&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NFS 文件系统读/写流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 Linux NFS 文件系统的实现中，文件操作接口由 nfs_file_operations 结构体定义，其读取操作对应的函数为:&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;//NFS 文件系统的 VFS 层实现的函数如下所示：
const&amp;nbsp;struct&amp;nbsp;file_operations nfs_file_operations = {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .llseek &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_llseek,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .read_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;= nfs_file_read,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .write_iter &amp;nbsp; &amp;nbsp; &amp;nbsp; = nfs_file_write,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
};&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;针对 NFS 文件系统的读操作涉及到 2 个阶段（写流程类似，只是函数名字有所差异，本文仅以读取为例介绍）。由于文件读取涉及到网络操作因此这两个阶段涉及为异步操作：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 两个阶段&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;读取请求阶段：&lt;/strong&gt;当应用程序针对 NFS 文件系统发起 read() 读操作时，内核会在 VFS 层调用 nfs_file_read 函数，然后调用 NFS 层的 nfs_initiate_read 函数，通过 RPC 的 rpc_task_begin 函数将读请求发送到 NFS Server，至此向 NFS Server 发起的请求工作完成。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;读响应阶段：&lt;/strong&gt;在 NFS Server 返回消息后，会调用 rpc_task_end 和 nfs_page_read_done 等函数，将数据返回到用户空间的应用程序。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="415" src="https://oscimg.oschina.net/oscnet/up-fd2c800299c65096f8d6eba7de108c0581f.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在了解 NFS 文件系统的读流程后，我们回顾一下 NFS Server 为什么无法区分单机访问的容器实例或进程实例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;这是因为 NFS 文件系统的读写操作是在内核空间实现的。当容器 A/B 和主机上的进程 C 发起读请求时，这些请求在进入内核空间后，统一使用主机 IP（如 192.168.1.2）作为客户端 IP 地址。因此，NFS Server 端的统计信息只能定位到主机维度，无法进一步区分主机内具体的容器或进程。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="516" src="https://oscimg.oschina.net/oscnet/up-91366119d285327518f226735b34227dddd.jpg" width="1080" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;内核空间实现示意&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;方案调研和验证&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;进程对应容器上下文信息关联&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;内核中进程以 PID 作为唯一编号，与此同时，内核会建立一个 struct task_struct 对象与之关联，在 struct task_struct 结构会保存进程对应的上下文信息。如实现 PID 信息与用户空间容器上下文的对应（进程 PID 1000 的进程属于哪个 Pod 哪个 Container 容器实例），我们需基于内核 task_struct 结构获取到容器相关的信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过分析内核代码和资料确认，发现可以通过 task_struct 结构中对应的 cgroup 信息获取到进程对应的 cgroup_name 的信息，而该信息中包含了容器 ID 信息，例如&lt;strong&gt; docker-2b3b0ba12e92...983.scope &lt;/strong&gt;，完整路径较长，使用 .... 省略。基于容器 ID 信息，我们可进一步管理到进程所归属的 Pod 信息，如 Pod NameSpace 、 Pod Name 、 Container Name 等元信息，最终完成进程 PID 与容器上下文信息元数据关联。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;struct&amp;nbsp;task_struct&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;css_set&amp;nbsp;__rcu &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;*cgroups;
}


struct&amp;nbsp;css_set&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;*subsys[CGROUP_SUBSYS_COUNT];
}


struct&amp;nbsp;cgroup_subsys_state&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;cgroup&amp;nbsp;*cgroup;
}


struct&amp;nbsp;cgroup&amp;nbsp;{
&amp;nbsp;&amp;nbsp;struct&amp;nbsp;kernfs_node&amp;nbsp;*kn; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/* cgroup kernfs entry */
}


struct&amp;nbsp;kernfs_node&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; *name; &amp;nbsp;// docker-2b3b0ba12e92...983.scope
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以某容器进程为例，该进程在 Docker 容器环境中的 cgroup 路径完整为 /sys/fs/cgroup/cpu/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podefeb3229_4ecb_413a_8715_5300a427db26.slice/docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;经验证，我们在内核中读取 task-&amp;gt;cgroups-&amp;gt;subsys[0]-&amp;gt;kn-&amp;gt;name 的值为 docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope 。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/92/92735ea140e6e0021584e2c7cc21b0b4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;其中容器 ID 字段为 docker- 与 .scope 间的字段信息，在 Docker 环境中一般取前 12 个字符作为短 ID，如 2b3b0ba12e92 ，可通过 docker 命令进行验证，结果如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;docker&amp;nbsp;ps -a|grep&amp;nbsp;2b3b0ba
2b3b0ba12e92&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; registry-cn-hangzhou-vpc.ack.aliyuncs.com/acs/pause:3.5&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;NAS 上下文信息关联&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;NAS 产品的访问通过挂载命令完成本地文件路径的挂载。我们可以通过 mount 命令将 NAS 手工挂载到本地文件系统中。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;mount&amp;nbsp;-t nfs -o vers=3,nolock,proto=tcp,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport \
&amp;nbsp;&amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test /mnt/nas&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;执行上述挂载命令成功后，通过 mount 命令则可查询到类似的挂载记录：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;5368 47 0:660 / /mnt/nas rw,relatime shared:1175 \
&amp;nbsp; &amp;nbsp; &amp;nbsp;- nfs 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test \ &amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp;rw,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,nolock,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;noresvport,proto=tcp,timeo=600,retrans=2,sec=sys, \
&amp;nbsp; &amp;nbsp; &amp;nbsp;mountaddr=192.168.0.91,mountvers=3,mountport=2049,mountproto=tcp,\
&amp;nbsp; &amp;nbsp; &amp;nbsp;local_lock=all,addr=192.168.0.92&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;核心信息分析如下：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;# 挂载点，父挂载点，挂载设备号 &amp;nbsp; 目录 &amp;nbsp; &amp;nbsp; 挂载到本机目录 &amp;nbsp;协议 &amp;nbsp; NAS 地址
5368&amp;nbsp; &amp;nbsp; &amp;nbsp;47&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0:660&amp;nbsp; &amp;nbsp; &amp;nbsp;/ &amp;nbsp; &amp;nbsp; &amp;nbsp; /mnt/nas &amp;nbsp; &amp;nbsp; nfs &amp;nbsp; &amp;nbsp;3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com:/test
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;maror:minor&amp;nbsp;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;挂载记录中的&lt;/span&gt;&lt;span style="color:#d92142"&gt;&lt;strong&gt; 0:660 &lt;/strong&gt;&lt;/span&gt;为本地设备编号，格式为 major:minor ， 0 为 major 编号， 660 为 minor 编号，系统主要以 minor 为主。在系统的 NFS 跟踪点 nfs_initiate_read 的信息中的 dev 字段则为在挂载记录中的 minor 编号。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;cat /sys/kernel/debug/tracing/events/nfs/nfs_initiate_read/format
format:
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:dev_t dev; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:8; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; field:u32 count; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;offset:32; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size:4; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;signed:0;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过用户空间 mount 信息和跟踪点中 dev_id 信息，则可实现内核空间设备编号与 NAS 详情的关联。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;内核空间信息获取&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如容器中进程针对挂载到本地的目录 /mnt/nas 下的文件读取时，会调用到 nfs_file_read() 和 nfs_initiate_read 函数。通过 nfs_initiate_read 跟踪点我们可以实现进程容器信息和访问 NFS 服务器的信息关联。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过编写 eBPF 程序针对跟踪点 tracepoint/nfs/nfs_initiate_read 触发事件进行数据获取，我们可获取到访问进程所对应的 cgroup_name 信息和访问 NFS Server 在本机的设备 dev_id 编号。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="673" src="https://oscimg.oschina.net/oscnet/up-b7e2eac3eeba85b51ed94f7a84d28a096ea.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;获取 cgroup_name 信息&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;进程容器上下文获取：&lt;/strong&gt; 通过 cgroup_name 信息，如样例中的 docker-2b3b0ba12e92...983.scope ，后续可以基于 container_id 查询到容器对应的 Pod NameSpace 、 Pod Name 和 Container Name 等信息，从而定位到访问进程关联的 Pod 信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NAS 上下文信息获取：&lt;/strong&gt; 通过 dev 信息，样例中的 660 ，通过挂载到本地的记录，可以通过 660 查询到对应的 NAS 产品的地址，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com 。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户空间元信息缓存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/aa/aa252b079e6ce3cb1e52e02ab5b4052a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在用户空间中，可以通过解析挂载记录来获取 DEV 信息，并将其与 NAS 信息关联，从而建立以 DevID 为索引的查询缓存。如此，后续便可以基于内核获取到 dev_id 进行关联，进一步补全 NAS 地址及相关详细信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;对于本地容器上下文的信息获取，最直接的方式是通过 K8s kube-apiserver 通过 list-watch 方法进行访问。然而，这种方式会在每个节点上启动一个客户端与 kube-apiserver 通信，显著增加 K8s 管控面的负担。因此，我们选择通过本地容器引擎进行访问，直接在本地获取主机的容器详情。通过解析容器注解中的 Pod 信息，可以建立容器实例缓存。后续在处理指标数据时，则可以通过 container-id 实现信息的关联与补全。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;三、架构设计和实现&lt;/h1&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;整体架构设计&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;内核空间的信息采集采用 Linux eBPF 技术实现，这是一种安全且高效的内核数据采集方式。简单来说，eBPF 的原理是在内核中基于事件运行用户自定义程序，并通过内置的 map 和 perf 等机制实现用户空间与内核空间之间的双向数据交换。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NFS 和 RPC 调用事件触发的基础上，可以通过编写内核空间的 eBPF 程序来获取必要的原始信息。当用户空间程序搜集到内核指标数据后，会对这些原始信息进行二次处理，并在用户空间的采集程序中补充容器进程信息（如 NameSpace、Pod 和 Container 名称）以及 NFS 地址信息（包括 NFS 远端地址）。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/c6/c687b3f4df8a2ce5d0ab5cd9f287dfd4.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;内核 eBPF 程序流程&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 NFS 文件读为例，通过编写 eBPF 程序跟踪 nfs_initiate_read / rpc_task_begin / rpc_task_end / nfs_page_read_done 等关键链路上的函数，用于获取到 NFS 读取的数据量和延时数据，并将访问链路中的进程上下文等信息保存到内核中的指标缓存中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="471" src="https://oscimg.oschina.net/oscnet/up-f854a1a8cdf429eff044e715772dc96dfb6.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;如上图所示， nfs_initate_read 和 rpc_task_begin 发生在同一进程上下文中，而 rpc_task_begin 与 rpc_task_end 是异步操作，尽管两者不处于同一进程上下文，但可以通过 task_id 进行关联。同时， page_read_done 和 rpc_task_end 则发生在同一进程上下文中。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="627" src="https://oscimg.oschina.net/oscnet/up-70f989400d6710f021cfa7577375a709030.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;nfs_initiate_read 函数调用触发的 eBPF 代码示例如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;

SEC("tracepoint/nfs/nfs_initiate_read")
int&amp;nbsp;tp_nfs_init_read(struct&amp;nbsp;trace_event_raw_nfs_initiate_read *ctx)
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步骤 1 获取到 nfs 访问的设备号信息，比如 3f0f3489aa-xxxx.cn-shanghai.nas.aliyuncs.com
&amp;nbsp; &amp;nbsp;&amp;nbsp;// dev_id 则为： 660&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;dev_t&amp;nbsp;dev_id =&amp;nbsp;BPF_CORE_READ(ctx, dev);
&amp;nbsp; &amp;nbsp; u64 file_id =&amp;nbsp;BPF_CORE_READ(ctx, fileid);
&amp;nbsp; &amp;nbsp; u32 count =&amp;nbsp;BPF_CORE_READ(ctx, count);
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;struct&amp;nbsp;task_struct&amp;nbsp;*task = (struct&amp;nbsp;task_struct *)bpf_get_current_task();


&amp;nbsp; &amp;nbsp;&amp;nbsp;// 步骤 2 获取进程上下文所在的容器 cgroup_name 信息
&amp;nbsp; &amp;nbsp;&amp;nbsp;// docker-2b3b0ba12e925820ac8545f67c8cadee864e5b4033b3d5004d8a3aa742cde2ca.scope
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;char&amp;nbsp;*cname =&amp;nbsp;BPF_CORE_READ(task, cgroups, subsys[0], cgroup, kn, name);
&amp;nbsp; &amp;nbsp;&amp;nbsp;if&amp;nbsp;(cname)
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_core_read_str(&amp;amp;info.container, MAX_PATH_LEN, cname);
&amp;nbsp; &amp;nbsp; }


&amp;nbsp; &amp;nbsp;&amp;nbsp;bpf_map_update_elem(&amp;amp;link_begin, &amp;amp;tid, &amp;amp;info, BPF_ANY);
}


SEC("tracepoint/nfs/nfs_readpage_done")
int&amp;nbsp;tp_nfs_read_done(struct&amp;nbsp;trace_event_raw_nfs_readpage_done *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_begin")
int&amp;nbsp;tp_rpc_task_begin(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;&amp;nbsp;//... 省略
}


SEC("tracepoint/sunrpc/rpc_task_end")
int&amp;nbsp;tp_rpc_task_done(struct&amp;nbsp;trace_event_raw_rpc_task_running *ctx)
{
&amp;nbsp; &amp;nbsp;//... 省略
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;用户空间程序架构&lt;/span&gt;&lt;/h2&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img height="606" src="https://oscimg.oschina.net/oscnet/up-b9cf6d19b68dcceaa9f6f459645264baaa8.jpg" width="1280" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;元数据缓存&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ NAS 挂载信息缓存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过解析挂载记录，可以获取 DEV 信息与 NAS 信息的关联关系。以下是实现该功能的关键代码详情：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;scanner := bufio.NewScanner(mountInfoFile)
count :=&amp;nbsp;0
for&amp;nbsp;scanner.Scan() {
&amp;nbsp; &amp;nbsp; line := scanner.Text()
&amp;nbsp; &amp;nbsp; devID,remoteDir, localDir, NASAddr = parseMountInfo(line)


&amp;nbsp; &amp;nbsp; mountInfo := MountInfo{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;DevID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; devID,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;RemoteDir: &amp;nbsp; &amp;nbsp; remoteDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;LocalMountDir: localDir,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;NASAddr： NASAddr,
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; mountInfos =&amp;nbsp;append(mountInfos, mountInfo)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 容器元信息缓存&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过 Docker 或 Containerd 客户端，从本地读取单机的容器实例信息，并将容器的上下文数据保存到本地缓存中，以便后续查询使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;podInfo := PodInfo{
&amp;nbsp; &amp;nbsp; NameSpace: &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.namespace"],
&amp;nbsp; &amp;nbsp; PodName: &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.name"],
&amp;nbsp; &amp;nbsp; ContainerName: labels["io.kubernetes.container.name"],
&amp;nbsp; &amp;nbsp; UID: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; labels["io.kubernetes.pod.uid"],
&amp;nbsp; &amp;nbsp; ContainerID: &amp;nbsp; conShortID,
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据处置流程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;用户空间程序的主要任务是持续读取内核 eBPF 程序生成的指标数据，并对读取到的原始数据进行处理，提取访问设备的 dev_id 和 container_id 。随后，通过查询已建立的元数据缓存，分别获取 NAS 信息和容器 Pod 的上下文数据。最终，经过数据合并与处理，生成指标数据缓存供后续使用。&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;func&amp;nbsp;(m *BPFEventMgr)&amp;nbsp;ProcessIOMetric() {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; events := m.ioMetricMap
&amp;nbsp; &amp;nbsp; iter := events.Iterate()


&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;iter.Next(&amp;amp;nextKey, &amp;amp;event) {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ① 读取到的 dev_id 转化为对应的完整 NAS 信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;devId := nextKey.DevId
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;mountInfo, ok := m.mountMgr.Find(int(devId))


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ② 读取 containerID 格式化并查询对应的 Pod 上下文信息
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;containerId := getContainerID(nextKey.Container)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;podInfo, ok = m.criMgr.Find(containerId)
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ③ 基于事件信息、NAS 挂载信息和 Pod 上下文信息，生成指标数据缓存&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;metricKey, metricValue := formatMetricData(nextKey， mountInfo, podInfo)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;value, loaded := metricCache.LoadOrStore(metricKey, metricValue)
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// ④ 指标数据缓存，生成最终的 Metrics 指标并更新&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;var&amp;nbsp;ioMetrics []metric.Counter
&amp;nbsp; &amp;nbsp; metricCache.Range(func(key, value&amp;nbsp;interface{})&amp;nbsp;bool&amp;nbsp;{
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;k := key.(metric.IOKey)
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;v := value.(metric.IOValue)


&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ioMetrics =&amp;nbsp;append(ioMetrics, metric.Counter{"read_count",&amp;nbsp;float64(v.ReadCount),
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[]string{k.NfsServer, v.NameSpace, v.Pod, v.Container})
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;// ...
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&amp;nbsp;true
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp; m.metricMgr.UpdateIOStat(ioMetrics)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;启动 Goroutine 处理指标数据：通过启动一个 Goroutine，循环读取内核存储的指标数据，并对数据进行处理和信息补齐，最终生成符合导出格式的 Metrics 指标。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 具体步骤&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;获取 NAS 信息：&lt;/strong&gt;从读取的原始数据中提取 dev_id ，并通过 dev_id 查询挂载的 NAS 信息，例如远端访问地址等相关数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;查询 Pod 上下文：&lt;/strong&gt;对 containerID 进行格式化处理，并查询对应的容器 Pod 上下文信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成指标数据缓存：&lt;/strong&gt;基于事件数据、NAS 挂载信息和 Pod 上下文信息，生成指标数据缓存。此过程主要包括对相同容器上下文的数据进行合并和累加。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;导出 Metrics 指标：&lt;/strong&gt;根据指标数据缓存，生成最终的 Metrics 指标，并更新到指标管理器。随后，通过自定义的 Collector 接口对外导出数据。当 Prometheus 拉取数据时，指标会被转换为最终的 Metrics 格式。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过上述步骤，用户空间能够高效地处理内核 eBPF 程序生成的原始数据，并结合 NAS 挂载信息和容器上下文信息，生成符合 Prometheus 标准的 Metrics 指标，为后续的监控和分析提供了可靠的数据基础。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自定义指标导出器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在导出指标的场景中，我们需要基于保存在 Go 语言中的 map 结构中的动态数据实时生成，因此需要实现自定义的 Collector 接口。自定义 Collector 接口需要实现元数据描述函数 Describe() 和指标搜集的函数 Collect() ，其中 Collect() 函数可以并发拉取，因此需要通过加锁实现线程安全。该接口需要实现以下两个核心函数：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Describe() ：用于定义指标的元数据描述，向 Prometheus 注册指标的基本信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Collect() ：用于搜集指标数据，该函数支持并发拉取，因此需要通过加锁机制确保线程安全。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;type&amp;nbsp;Collector&amp;nbsp;interface&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 指标的定义描述符
&amp;nbsp; &amp;nbsp; Describe(chan&amp;lt;- *Desc)
&amp;nbsp; &amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;// 并将收集的数据传递到 Channel 中返回
&amp;nbsp; &amp;nbsp; Collect(chan&amp;lt;- Metric)
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;我们在指标管理器中实现 Collector 接口， 部分实现代码，如下所示：&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-auto"&gt;nfsIOMetric := prometheus.NewDesc(
&amp;nbsp; &amp;nbsp; prometheus.BuildFQName(prometheusNamespace,&amp;nbsp;"",&amp;nbsp;"io_metric"),
&amp;nbsp; &amp;nbsp;&amp;nbsp;"nfs io metrics by cgroup",
&amp;nbsp; &amp;nbsp; []string{"nfs_server",&amp;nbsp;"ns",&amp;nbsp;"pod",&amp;nbsp;"container",&amp;nbsp;"op",&amp;nbsp;"type"},
&amp;nbsp; &amp;nbsp;&amp;nbsp;nil,
)


// Describe and Collect implement prometheus collect interface
func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Describe(ch&amp;nbsp;chan&amp;lt;- *prometheus.Desc) {
&amp;nbsp; &amp;nbsp; ch &amp;lt;- m.nfsIOMetric
}


func&amp;nbsp;(m *MetricMgr)&amp;nbsp;Collect(ch&amp;nbsp;chan&amp;lt;- prometheus.Metric) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;// Note：加锁保障线程并发安全
&amp;nbsp; &amp;nbsp; m.activeMutex.Lock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;defer&amp;nbsp;m.activeMutex.Unlock()
&amp;nbsp; &amp;nbsp;&amp;nbsp;
&amp;nbsp; &amp;nbsp;&amp;nbsp;for&amp;nbsp;_, v :=&amp;nbsp;range&amp;nbsp;m.ioMetricCounters {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;ch &amp;lt;- prometheus.MustNewConstMetric(m.nfsIOMetric, prometheus.GaugeValue, v.Count, v.Labels...)
&amp;nbsp; &amp;nbsp; }

&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;四、总结&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;当前 NAS 溯源能力已正式上线，以下是主要功能和视图介绍：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 单 NAS 实例整体趋势&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;支持基于环境和 NAS 访问地址过滤，展示 NAS 产品的读写 IOPS 和吞吐趋势图。同时，基于内核空间统计的延时数据，提供 P95 读写延时指标，用于判断读写延时情况，辅助问题分析和定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/14/14577d6fe8b2876ca7f5138680fc3667.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/9c/9c091aeaecc284956b851416de5d313a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在 NAS 流量溯源方面，我们结合业务场景设计了基于任务和 Pod 实例维度的流量分析视图：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ 任务维度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过聚合具有共同属性的一组 Pod 实例，展示任务级别的整体流量情况。该视图支持快速定位任务级别的流量分布，帮助用户进行流量溯源和多任务错峰使用的依据。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/0a/0a504606b05345b52061d2f754c15b51.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;u&gt;※ Pod 实例维度流量溯源&lt;/u&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;以 Pod 为单位进行流量分析和汇总，提供 Pod NameSpace 和 Name 信息，支持快速定位和分析实例级别的流量趋势，帮助细粒度监控和异常流量的精准定位。&lt;/span&gt;&lt;/p&gt; 
&lt;div style="text-align:left"&gt; 
 &lt;img src="https://static001.geekbang.org/infoq/90/90765c51493906beaf530c64494abc6a.png" referrerpolicy="no-referrer"&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在整体能力建设完成后，我们成功构建了 NAS 实例级别的 IOPS、吞吐和读写延时数据监控大盘。通过该能力，进一步实现了 NAS 实例的 IOPS 和吞吐可以快速溯源到任务级别和 Pod 实例级别，流量溯源时效从小时级别缩短至分钟级别，有效提升了异常问题定位与解决的效率。同时，基于任务流量视图，我们为后续带宽错峰复用提供了直观的数据支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;1.&lt;/span&gt;正品库拍照 PWA 应用的实现与性能优化｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;2.&lt;/span&gt;汇金资损防控体系建设及实践 | 得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;3.&lt;/span&gt;一致性框架：供应链分布式事务问题解决方案｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;4.&lt;/span&gt;得物社区活动：组件化的演进与实践&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#586c90"&gt;5.&lt;/span&gt;从 CPU 冒烟到丝滑体验：算法 SRE 性能优化实战全揭秘｜得物技术&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 泊明&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;关注得物技术，每周更新技术干货&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18683994</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18683994</guid>
      <pubDate>Tue, 29 Jul 2025 07:35:59 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达开源 Llama-3.3-Nemotron-Super-49B-v1.5 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;英伟达发布了 Llama-3.3-Nemotron-Super-49B-v1.5，这是一款专为推理和 Agentic 任务优化的开源模型，在单个 H100 GPU 上实现高吞吐量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1eb8efcbf4188aaa81c53fbda0c23259d86.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型介绍&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 是 Llama-3.3-Nemotron-Super-49B-V1.5 的简称。它是 Llama-3.3-Nemotron-Super-49B-V1 的升级版本（该模型是 Meta 的 Llama-3.3-70B-Instruct 的衍生模型），专为复杂推理和智能体任务设计，支持 128K tokens 的上下文长度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Llama Nemotron Super v1.5 采用神经架构搜索（Neural Architecture Search，NAS），使该模型在准确率和效率之间实现了良好的平衡，将吞吐量的提升有效转化为更低的运行成本。&lt;/p&gt; 
&lt;p&gt;（注：NAS 的目标是通过搜索算法从大量的可能架构中找到最优的神经网络结构，利用自动化方法替代人工设计神经网络架构，从而提高模型的性能和效率。）&lt;/p&gt; 
&lt;p&gt;模型经过了多阶段后训练，包括针对数学、代码、科学和工具调用的监督微调 (SFT)，以及用于聊天对齐的奖励感知偏好优化 (RPO)、用于推理的带可验证奖励的强化学习 (RLVR) 和用于工具调用能力增强的迭代直接偏好优化 (DPO)。&lt;/p&gt; 
&lt;p&gt;在多个基准测试中，该模型表现出色。例如，在 MATH500 上 pass@1 达到 97.4，在 AIME 2024 上达到 87.5，在 GPQA 上达到 71.97。模型支持 Reasoning On/Off 模式，用户可通过在系统提示中设置 /no_think 来关闭推理模式。官方推荐在推理开启时使用 temperature=0.6 和 Top P=0.95，在关闭时使用贪心解码。&lt;/p&gt; 
&lt;p&gt;该模型已准备好用于商业用途，遵循 NVIDIA Open Model License 和 Llama 3.3 社区许可协议。开发者可以通过 NVIDIA build.nvidia.com 或 Hugging Face 下载和试用该模型，并可使用 vLLM（推荐 v0.9.2）进行部署，官方仓库中提供了支持工具调用的解析器插件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362966</guid>
      <pubDate>Tue, 29 Jul 2025 07:26:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 出现大范围服务中断：目前已全部恢复，影响超 8 小时</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;代码托管平台 GitHub 从 2025 年 7 月 28 日 16:50 UTC（北京时间 7 月 29 日 00:50）起突发&lt;strong&gt;大规模服务中断&lt;/strong&gt;，受影响服务包括 Git 操作、API 请求、Pull 请求和 Issues 跟踪等核心功能 。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/150643_ZtSu_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管 GitHub 工程团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.githubstatus.com%2Fincidents%2Fs6d4x8c6cvv5" target="_blank"&gt;尝试了多种修复措施&lt;/a&gt;（如增设服务器容量、调整限流措施），初期效果不佳，直到北京时间 &lt;strong&gt;7 月 29 日 9:23 左右&lt;/strong&gt; 才取得实质性进展。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1416" src="https://static.oschina.net/uploads/space/2025/0729/150606_wHAe_2720166.png" width="1890" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最终，相关问题已逐步解决，截至目前，API 请求、Pull 请求等服务已全面恢复，整体中断时间超过 &lt;strong&gt;8 小时&lt;/strong&gt;。GitHub 官方表示正在深入调查具体原因，后续将发布详细技术分析报告。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.githubstatus.com/history&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362956</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362956</guid>
      <pubDate>Tue, 29 Jul 2025 07:07:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Julius AI 完成 1000 万美元种子轮融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362957</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362957</guid>
      <pubDate>Tue, 29 Jul 2025 07:07:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中国移动「九天」3.0 发布，多项核心技术同步开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;中国移动发布了其自主研发的 「九天」基础大模型 3.0。根据介绍，「九天众擎语言大模型」实现了架构上的突破性创新，采用可扩展至万亿级的&amp;nbsp;&lt;strong&gt;MoE 架构&lt;/strong&gt;。通过 15T token 的多阶段配比预训练数据与全流程治理体系，其推理能力得到显著强化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该模型还创新构建了 113 域 ×53 能力的二维分级后训练框架，结合动态强化学习策略，使复杂推理能力提升了&amp;nbsp;&lt;strong&gt;35%&lt;/strong&gt;。测评结果显示，「九天」语言大模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;GPQA-Diamond&lt;/strong&gt;&amp;nbsp;评测中，以&amp;nbsp;&lt;strong&gt;77.67 分&lt;/strong&gt;斩获全球第二，超越 DeepSeekR1 和 Qwen3。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;ArenaHard V1.0&lt;/strong&gt;&amp;nbsp;中，以&amp;nbsp;&lt;strong&gt;67.2 分&lt;/strong&gt;位居全球第一。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;在&amp;nbsp;&lt;strong&gt;BFCL V3&lt;/strong&gt;&amp;nbsp;评测中，达到&amp;nbsp;&lt;strong&gt;68 分&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在性能大幅跃升的同时，模型进一步强化了可控生成能力，通过精确流程内置等技术细节，实现了专业场景下的&lt;strong&gt;零幻觉&lt;/strong&gt;，破解了沉浸式角色演绎难题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基于最新的语言大模型，中国移动还同步推出了多个专项模型:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天代码大模型：&lt;/strong&gt;采用两阶段持续训练技术，支持代码生成、注释生成、单元测试生成、代码智能问答等任务，覆盖 Python、Java、JS、TS、Go、C++ 等 10 余种主流编程语言。在 EvalPlus、MHPP、LivecodeBenchv6 等多个代码生成榜单上表现领先。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;九天数学大模型：&lt;/strong&gt;在短思考、长思考模式下均达到业界 SOTA 水平，多项指标超越 Qwen2.5Math、Qwen3、DeepSeek Math、DeepSeek R1-Distill 等同参数量级模型。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「九天善智多模态大模型」引入复杂时空建模、流匹配图片视频渐进式联合训练、端到端局部可控注意力机制等创新技术。同时，通过融合多模态理解信息和联合图文交织数据训练，显著提升了模型对文本指令和输入条件图像视频的感知能力。这意味着模型不仅能生成高质量的图像视频，还能进行多轮对话式高可控精确编辑操作，大幅提升了视觉生成的灵活便利性。例如，在图片生成方面可支持多轮精准局部修改，如修改文字、修改背景、增加元素等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;模型的图理解和视频理解性能也得到了全面提升：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;图理解方面：&lt;/strong&gt;在 MMStar、HallusionBench 和 OCRBench 等图理解任务中，九天模型分别获得了&amp;nbsp;&lt;strong&gt;82.2、64.3 和 94.9 的高分&lt;/strong&gt;，处于业界领先水平。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;视频理解方面：&lt;/strong&gt;在 Videomme 和 MVbench 两个任务中均表现领先，超越 Qwen2-VL 和 InternVideo2。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，中国移动已将多项模型及核心技术进行开源：&lt;/span&gt;&lt;/p&gt; 
&lt;ol style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天数童结构化数据大模型&lt;/strong&gt;：包括 JT-DA-8B 模型及后续演进版本，支持下载模型权重、微调代码、推理代码等。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天数学大模型&lt;/strong&gt;：包括 JT-Math-8B 系列模型，支持下载模型权重、推理代码、技术报告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源九天代码大模型&lt;/strong&gt;：包括 JT-Coder-8B 系列模型，支持下载模型权重、推理代码、技术报告。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源业界首创的结构化数据模型评测数据及 TReB 评测体系&lt;/strong&gt;：涵盖 6 大任务、34 个能力，包括高质量、全面的数据、推理模式及评价指标，支持下载评测数据集、测试代码。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;开源 CCR-Bench 行业场景复杂指令遵循评测数据集&lt;/strong&gt;：包含 174 条高质量、多样化、高难度复杂指令数据，高度模拟健康专家、智能客服、医疗助手等典型工业场景，支持下载数据集。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362949</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362949</guid>
      <pubDate>Tue, 29 Jul 2025 06:45:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>特斯拉与三星签订 165 亿美元 AI 芯片制造协议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 28 日，三星电子在提交给监管机构的文件中表示，三星电子与一家全球大型公司签署了价值 22.8 万亿韩元（注：现汇率约合 1181.72 亿元人民币，约合 165 亿美元）的芯片制造协议，但未透露具体客户名称。&lt;/p&gt; 
&lt;p&gt;据消息人士透露，特斯拉正是这家客户，该公司目前与三星的合同芯片制造部门已有业务往来。&lt;/p&gt; 
&lt;p&gt;有外媒表示，三星电子公司将就新达成的 165 亿美元协议，为特斯拉公司生产半导体，这将为其表现不佳的晶圆代工部门提供助力。该合作的合同期 2025 年 7 月 24 日-2033 年 12 月 31 日。&lt;/p&gt; 
&lt;p&gt;对此，特斯拉 CEO 埃隆・马斯克确认了合作爆料，三星在美国得克萨斯州新建的巨型工厂将专门用于生产特斯拉的下一代 AI6 芯片（注：特斯拉汽车智驾芯片），并称「其战略重要性毋庸置疑」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99e430011e2ff79c31d84adca382c598c73.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;马斯克还称，三星目前正在生产 AI4 芯片。台积电将首先在中国台湾地区生产刚刚完成设计的 AI5 芯片，然后在美国亚利桑那州生产。&lt;/p&gt; 
&lt;p&gt;根据外媒今年 6 月报道，台积电在全球第三方晶圆代工市场的市占比为 67%，而排名第二的三星则仅占 11%。另外，有消息人士称，三星电子 2025 上半年晶圆代工部门获零奖金。此前，外媒援引供应链消息称，三星已启动「精选和聚焦」战略，集中资源提升 2nm 工艺良率，希望通过产量和成本优势来挑战台积电。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362947</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362947</guid>
      <pubDate>Thu, 17 Jul 2025 06:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>端侧原生大模型 SmallThinker 正式开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;上海交通大学 IPADS 研究所、上海交通大学人工智能学院联合初创公司本智激活（Zenergize AI），发布了开源端侧原生大模型 SmallThinker。&lt;/p&gt; 
&lt;p&gt;该系列模型采用为端侧算力、内存、存储特性而原生设计的模型架构，并从零开始预训练，具体包含两个尺寸的稀疏模型，分别是 SmallThinker-4B-A0.6B 和 SmallThinker-21B-A3B。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt; 
&lt;p&gt;SmallThinker 专为低成本硬件设计，可在百元级国产开发板（如瑞芯微 RK3588）上流畅运行百亿参数模型，旨在为资源受限的个人设备带来强大、私密且低延迟的 AI 能力，无需依赖云端。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1578" src="https://static.oschina.net/uploads/space/2025/0729/143436_ewWq_2720166.png" width="2044" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户可以通过 Transformers（版本需 &amp;gt;= 4.53.3）或 ModelScope 来运行该模型。官方 GitHub 仓库提供了详细的设置、模型转换和运行指南。官方提示，模型使用了稀疏的 lm_head，可能会导致一定的精度损失，但用户可以手动修改代码禁用此特性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct&lt;/li&gt; 
 &lt;li&gt;https://github.com/SJTU-IPADS/PowerInfer/tree/main/smallthinker&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362945</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362945</guid>
      <pubDate>Thu, 17 Jul 2025 06:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：AnyShake Project 开源地震监测系统</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2112</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2112</guid>
      <pubDate>Thu, 17 Jul 2025 06:18:00 GMT</pubDate>
    </item>
    <item>
      <title>谷歌 NotebookLM 即将推出「视频概览」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 NotebookLM 即将推出一项名为「视频概览 (Video Overviews)」的新功能，能以视频幻灯片形式呈现内容摘要。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/141652_Z58B_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Ftestingcatalog%2Fstatus%2F1949120138373914737" target="_blank"&gt;相关爆料称&lt;/a&gt;，这些视频概览将以视频幻灯片的形式呈现，内容包含文本、图像和其他视觉元素，并由女性声音进行旁白解说。&lt;/p&gt; 
&lt;p&gt;谷歌 NotebookLM 功能于去年推出，旨在通过 AI 虚拟主持人根据用户上传到 NotebookLM 的文档（如课程阅读材料或法律摘要）生成播客，帮助用户以另一种方式理解和消化文档中的信息。&lt;/p&gt; 
&lt;p&gt;用户可以上传中文 PDF、Google Docs、网页链接或文本，NotebookLM 会生成中文总结或回答基于中文来源的问题。支持高达 50 万字的单个来源，适合处理长篇中文文档。NotebookLM 目前支持 130 种语言的输入来源和聊天功能，包括中文（简体和繁体）。用户可以上传中文文档、网页链接或文本，并以中文与 AI 进行交互。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362937</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362937</guid>
      <pubDate>Thu, 17 Jul 2025 06:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>全球首家机器人 6S 店深圳开业</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;全球首家机器人「6S 店」于 7 月 28 日在深圳龙岗星河 WORLD 园区机器人剧场开业，店内集聚数百种机器人及配套零部件。多家企业带来的产品涵盖了家庭服务、医疗辅助、工业巡检、教育陪伴等多个领域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="358" src="https://oscimg.oschina.net/oscnet/up-5d0777ddd254f3732d7201680e7a9e95e67.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「机器人 6S 店究竟是什么？」深圳未来时代机器人有限公司 CEO 兼 6S 店店长林枫解释称，其在传统汽车 4S 店「销售（Sale）、零配件供应（Sparepart）、售后服务（Service）、信息反馈（Survey）」的基础上，新增「租赁（Lease）、个性化订制（Customized）」两大功能，形成独特的「6S」模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;活动现场数据显示，已有超 200 家产业链上下游企业表达进驻意向，其中人形及服务机器人企业近 50 家，涵盖从核心零部件研发到场景应用的全产业链环节。该店紧扣机器人产业特性，一方面将建立实时数据反馈机制，精准收集用户需求反哺研发；另一方面提供租赁服务，让用户无需购买即可体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据介绍，机器人 6S 店内置「机器人零配件超市」，汇聚伺服电机、减速器等核心元器件，能满足主流机器人维修需求，实现「快速响应、即时维修」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362936</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362936</guid>
      <pubDate>Thu, 17 Jul 2025 06:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>网信办整治自媒体发布不实信息，平台需优化 AI 生成内容标识</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;为持续深入整治「自媒体」发布不实信息乱象，进一步规范「自媒体」信息发布行为，按照 2025 年「清朗」系列专项行动总体安排，中央网信办决定自 7 月 24 日起，在全国范围内启动为期 2 个月的「清朗·整治‘自媒体’发布不实信息」专项行动。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="221" src="https://oscimg.oschina.net/oscnet/up-fcdd633462b44ba4d48a4e73cc8356abdca.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;专项行动重点整治四类突出问题：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;1.恶意蹭炒误导公众问题。涉热点舆情或公众人物时，假冒当事人、近亲属等，通过账号名称、简介等方式编造身份，蹭炒热点，混淆视听。涉重大舆情、突发事件时，假冒知情人士，编造起因进展、伤亡人数等，无中生有，干扰舆论。发布财经、军事、外交等重要领域信息时，虚构所谓「权威报道」「一手数据」「深度揭秘」等信息，胡编乱造，误导认知。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2.多种手段歪曲事实问题。利用人工智能生成合成技术，仿冒他人，或编造社会民生等领域虚假信息，欺骗公众。通过剧情摆拍、拼凑剪辑等方式，编造事件、虚构或夸大情节，引起关注。歪曲解读关乎公众利益的政策方针、法规文件，宣扬「即将取消」「重大变动」等不实信息，制造噱头。对往年社会新闻、政策发布等旧闻旧事摘头去尾，掩盖时间、地点、结果等关键要素，恶意炒作。借助网络黑灰产等渠道，以刷榜打榜买榜方式，通过热搜榜单呈现不实信息，操纵榜单。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;3.不做标注以假乱真问题。对涉及国内外时事、公共政策、社会事件等相关信息，未标注或未准确标注信息来源。以「网传」「网友表示」「来源于互联网」等方式发布信息，模糊标注信息来源，发布无实际依据内容。标注错误信息来源，或矩阵账号互相引用标注，导致公众无法追溯真实来源。以过小字号、隐蔽位置、进度条遮挡等方式标注，刻意弱化标注标识。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;4.专业领域信息不实问题。不进行专业资质认证，或以虚假认证、过期认证方式，冒用财经专家、医生、律师等身份。歪曲解读专业内容，如杜撰或篡改真实案例细节，发布未经科学验证或明显违背科学常识的信息，将不同的历史人物与事件张冠李戴、篡改史实。借专业知识分享名义，编造同质化文案或虚假故事，借机引流带货。发布教程，教授通过虚假摆拍、蹭热引流等方式打造「网红专家」人设，扰乱传播秩序。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中央网信办要求网站平台建立三大机制：在信息发布环节强制设置来源标注选项，未标注内容不得进入算法推荐池；细化专业资质认证流程，动态核验账号身份与运营业务匹配度;畅通举报渠道，对首次违规账号采取提示引导，对恶意编造重点领域信息、仿冒热点当事人的账号实施长期禁言或封号。同时，平台需完善负面清单、营利权限管理等制度，对存在突出问题的平台依法采取处罚措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次行动强调「标本兼治」，既通过技术手段压缩不实信息生存空间，如优化 AI 生成内容标识功能，又压实平台主体责任，要求其定期排查隐形变异问题。据网信办负责人介绍，专项行动将与日常监管形成合力，推动建立「自媒体」行业信用评价体系，引导内容创作者回归真实、专业的传播轨道，为公众营造可信、有序的网络环境。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362926</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362926</guid>
      <pubDate>Thu, 17 Jul 2025 05:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软为 Edge 浏览器推出新的 Copilot 模式，支持实时分析屏幕内容</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软正在为其 Edge 浏览器推出一种名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fzh-cn%2Fedge%2Fai-powered%2Fcopilot-mode" target="_blank"&gt;「Copilot Mode」&lt;/a&gt;的全新实验性模式，旨在提供一种由 AI 驱动的网页浏览体验。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0729/113855_QJwL_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模式包含多项新功能，包括全新的现代化主页（New Modern Homepage）、快速撰写（Quick Compose）、简单的任务切换（Simple Task Handoff）以及语音导航（Voice Navigation）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4177c9b14685e66cd78d1978e425461b2a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中一个核心功能是「Copilot Vision」，它允许 Copilot 「看到」用户的屏幕，即时扫描和分析屏幕上的内容，并实时提供相关的建议和见解。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362895/microsoft-edge-copilot-mode</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362895/microsoft-edge-copilot-mode</guid>
      <pubDate>Thu, 17 Jul 2025 03:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国内首个农业智能大模型上线，每亩地增收可达 200 元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中国中化集团推出了国内首个 「农业种植综合大模型」。这个大模型不仅依托于全国数百座农业技术服务中心的支持，更整合了超过千万条农业知识资源，为农民提供精准、科学的种植指导。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该农业种植综合大模型贯穿了 「耕、种、管、收」 的整个过程，能够进行高效、可靠的复杂任务处理。通过大模型的应用，农艺师只需在手机或平板电脑上就能实现线上智能决策，线下为农民提供贴身服务。这意味着，农民能够通过实时监测作物的生长情况、土壤湿度，以及气象和病虫害等重要因素，获取及时的建议，例如 「每亩需要多少肥料、何时浇水」 等信息。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-b29e4fd6f3ee345ed36aa8353bfd5d8e80a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;许多网友对此表示兴奋，甚至戏称这项技术让他们想起了小时候的 QQ 农场。科技的进步，不仅为农事决策带来了高效和便利，还能够让农民在增加收入的同时，享受到更多的乐趣和成就感。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据悉，使用这一大模型后，农事决策的时间可以缩短 75%，每亩地的增收可达 150 到 200 元。这对广大农民而言，无疑是一个好消息。农业种植综合大模型的上线，不仅提升了农业生产的智能化水平，也为全国的农业发展注入了新动力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362892</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362892</guid>
      <pubDate>Thu, 17 Jul 2025 03:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>上海 AI 实验室开源科学多模态大模型『书生』Intern-S1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;上海人工智能实验室（上海 AI 实验室）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fd7DfDz4yw_5ktewSpjzVDA" target="_blank"&gt;发布&lt;/a&gt;并开源『书生』科学多模态大模型 Intern-S1，声称多模态能力全球开源第一，文本能力比肩国内外一流模型，科学能力全模态达到国际领先，作为融合科学专业能力的基础模型，Intern-S1 综合性能为当前开源模型中最优。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公告介绍称，Intern-S1 在同一模型内实现了语言和多模态性能的高水平均衡发展，具备「全能高手」的实力；同时，作为「科学明星」，它还富集多学科专业知识，重点强化了科学能力，在化学、材料、地球等多学科专业任务基准上超越了顶尖闭源模型 Grok-4；此外，Intern-S1 还开创了「多任务的通专融合」的新范式，支持大规模多任务强化学习齐头并进，在保持能力全面的同时实现专业精通。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="319" src="https://oscimg.oschina.net/oscnet/up-e8b2a446e9dc17a212b7fc9fe2fd02a0f70.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-8d4b59325c224883c411d165c948180e543.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="153" src="https://oscimg.oschina.net/oscnet/up-99ef18ed34310abfc6028e4dc8aa28294d1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;为了更好地适应科学数据，Intern-S1 新增了动态 Tokenizer 和时序信号编码器，可支持多种复杂科学模态数据，实现了材料科学与化学分子式、生物制药领域的蛋白质序列、天文巡天中的光变曲线、天体碰撞产生的引力波信号、地震台网记录的地震波形等多种科学模态的深度融合。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Intern-S1 还实现了对科学模态数据的深入理解与高效处理，例如，其对化学分子式的压缩率相比 DeepSeek-R1 提升 70% 以上；在一系列基于科学模态的专业任务上消耗的算力更少，同时性能表现更优。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fd7DfDz4yw_5ktewSpjzVDA" target="_blank"&gt;查看官方公告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362877</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362877</guid>
      <pubDate>Thu, 17 Jul 2025 03:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GPT-5 即将发布！相关参数、功能与展望预测汇总</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;随着人工智能领域的竞争日益加剧，OpenAI 的下一代大语言模型 GPT-5 备受关注。根据最新信息，GPT-5 预计将于 2025 年年中至晚些时候发布，具体时间可能在 8 月或更晚。本文综合网络信息，整理了关于 GPT-5 的参数、功能及潜在影响的最新动态，为您呈现最全面的预览。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;发布日期与开发进展&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据 OpenAI 首席执行官 Sam Altman 在 2025 年 2 月发布的路线图，GPT-5 预计在 2025 年年中推出，具体可能在 8 月或稍晚。Altman 在近期采访中表示，GPT-5 的发布将晚于 GPT-4.5（代号 Orion，已于 2025 年 2 月 27 日发布），并强调其为「前沿模型」，代表重大技术飞跃。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;然而，开发过程中面临的技术与资源挑战可能导致进一步延迟。据报道，GPT-5（代号可能为 Orion 或 Arrakis）的训练成本高达 5 亿美元以上，且需要大规模数据中心支持，训练时间至少 6 个月。OpenAI 内部也经历了高管离职等动荡，可能影响开发进度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="241" src="https://oscimg.oschina.net/oscnet/up-44d549d72cc75a7aa62b1b9593f9f177949.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;参数规模与技术架构&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;虽然 OpenAI 尚未公开 GPT-5 的具体参数数量，但业界推测其参数规模将显著超越前代模型。以下是关键信息:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;参数规模&lt;/strong&gt;：GPT-4 据估拥有约 1.5 万亿参数，而 GPT-5 可能达到 3 至 50 万亿参数，具体取决于是否采用混合专家模型（MoE）。有报道称，GPT-5 可能利用 20，000 个 NVIDIA GB200 芯片或 150，000 个 H100 芯片进行训练，支持高达 80 万亿参数的模型。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;架构创新&lt;/strong&gt;：GPT-5 将整合 GPT 系列与 o 系列（如 o1、o3）的能力，采用统一架构，消除用户在不同任务间切换模型的需求。可能引入图神经网络 (GNN) 和增强注意力机制，提升语言处理效率和复杂情境理解能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;训练数据&lt;/strong&gt;：GPT-5 预计使用更大规模的多样化数据集，包括公开网络数据和私有企业数据，可能结合合成数据以应对数据短缺问题。然而，合成数据可能引发反馈循环，增加「幻觉」风险。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心功能与改进&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;GPT-5 被设计为多模态、统一智能系统，旨在提供更高效、准确的 AI 体验。以下是其核心功能的预期亮点:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;多模态能力&lt;/strong&gt;：GPT-5 将进一步增强多模态处理能力，支持文本、图像、语音和视频输入输出。基于 GPT-4o 的语音和图像处理基础，GPT-5 可能集成视频处理功能，例如通过 OpenAI 的 SORA 技术实现文本到视频的生成。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;高级推理能力&lt;/strong&gt;：OpenAI 强调 GPT-5 将显著提升链式推理（Chain-of-Thought）能力，擅长多步骤逻辑和决策制定。相比 GPT-4o 的快速响应，GPT-5 将更擅长处理复杂问题，如软件工程中的代码生成与调试、数学和物理等科学任务。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;上下文窗口扩展&lt;/strong&gt;：GPT-4o 的上下文窗口为 128，000 个 token，而 GPT-5 可能支持高达 500 万个 token，足以处理整本书籍或大型企业数据，提升长文本处理能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;减少幻觉&lt;/strong&gt;：GPT-5 预计将「幻觉」率降至 10% 以下，显著提高输出的准确性和可靠性，特别是在科学和编程领域。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;自主 AI 代理&lt;/strong&gt;：GPT-5 可能引入自主 AI 代理功能，能够执行现实世界的任务，如管理邮件、预订日程或根据用户偏好完成购物，减少人工干预。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;Canvas 工作空间&lt;/strong&gt;：基于 GPT-4o 的 Canvas 功能，GPT-5 将提供更强大的交互式工作空间，优化编码、数学和分步工作流程的体验。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;行业影响与应用前景&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;GPT-5 的发布将对多个领域产生深远影响:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;软件开发&lt;/strong&gt;：测试者反馈，GPT-5 在复杂软件项目中的代码生成和调试能力超越了 Anthropic 的 Claude4Sonnet，可能成为开发者首选工具。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;科学研究&lt;/strong&gt;：在数学、物理和生物学等学科中，GPT-5 的高级推理能力将加速研究进程，支持复杂数据分析和假设验证。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;商业与生产力&lt;/strong&gt;：通过自主 AI 代理和个性化功能，GPT-5 可优化客户服务、内容创作和日常任务自动化，提升企业效率。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;教育与医疗&lt;/strong&gt;：GPT-5 的多模态能力和上下文理解将革新教育领域的个性化学习，以及医疗领域的患者交互和文档处理。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;挑战与伦理考量&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;尽管前景光明，GPT-5 的开发和部署面临多重挑战:&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;成本与资源&lt;/strong&gt;：训练成本高昂，数据中心建设周期长，可能限制 OpenAI 的并行开发能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;伦理与安全&lt;/strong&gt;：大规模模型可能引发误用风险，如生成虚假信息或模拟人类行为。OpenAI 正在进行严格的安全测试，推迟了部分功能的发布。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;竞争压力&lt;/strong&gt;：Anthropic 的 Claude 系列、Google 的 Gemini 和 Meta 的 LLaMA 等竞品正在迅速追赶，迫使 OpenAI 在性能与可靠性之间找到平衡。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;用户反馈与社区期待&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;社交媒体上，开发者对 GPT-5 的期待集中在编程能力和推理性能的提升。部分用户在 X 平台上提到，GPT-5 的早期测试版在软件工程任务中表现优异，超越 Claude Sonnet4。然而，也有用户担忧其高昂的订阅成本和潜在的使用限制，类似 Anthropic 对 Claude Code Max 计划的调整可能引发的不满。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;GPT-5 作为 OpenAI 的下一代旗舰模型，预计将通过更大的参数规模、统一的架构和多模态能力，显著提升 AI 的推理、准确性和实用性。尽管面临成本、安全和竞争等多重挑战，其在编程、科研和商业领域的潜力不容忽视。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362874</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362874</guid>
      <pubDate>Thu, 17 Jul 2025 03:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 将在 8 月底面向 Claude Pro 和 Max 订阅用户推出新的每周使用限制</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAnthropicAI%2Fstatus%2F1949898502688903593" target="_blank"&gt;宣布&lt;/a&gt;，由于 Claude Code 的需求空前增长，将从 8 月 28 日起为 Claude Pro 和 Max 订阅计划引入新的每周使用量限制。此举旨在解决因少数极端使用案例和违反服务条款的行为（如账户共享和转售）导致的系统容量问题，以确保为所有用户提供更公平、可靠的服务。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/105318_5uv3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新的限制措施将在现有的每 5 小时重置限制的基础上，增加一个每 7 天重置的总体每周限制，以及一个针对 Claude Opus 4 的特定每周限制。Anthropic 估计，根据当前使用情况，新规将影响不到 5% 的订阅用户。&lt;/p&gt; 
&lt;p&gt;公司透露，一些重度用户在后台 24/7 连续运行模型，其中一个案例是在每月 200 美元的套餐上消耗了价值数万美元的模型用量。新限制旨在缓解此类高成本使用情况。&lt;/p&gt; 
&lt;p&gt;对于受影响的用户，Anthropic 给出了一些预期使用时长的参考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;大多数 Pro 用户在每周限制内预计可使用 40-80 小时的 Sonnet 4；&lt;/li&gt; 
 &lt;li&gt;大多数 Max 20x 用户则可使用 240-480 小时的 Sonnet 4 和 24-40 小时的 Opus 4。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对于超出限制的 Max 计划用户，Anthropic 将提供以标准 API 价格购买额外用量的选项。公司表示仍在探索支持长期使用案例的最佳方式，并欢迎重度用户提供反馈。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362871</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362871</guid>
      <pubDate>Thu, 17 Jul 2025 02:53:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>快手可灵发布 Kling Lab</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手的 Kling AI 团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FKling_ai%2Fstatus%2F1949760383692255518" target="_blank"&gt;宣布&lt;/a&gt;推出 Kling Lab，这是一个旨在简化创作流程、提高效率并促进协作的新工作空间。该产品目前正处于 Beta 测试阶段。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0729/104711_dOxb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，在 2025 世界人工智能大会（WAIC）上，可灵 AI 还披露了最新用户数据，在全球拥有超过 4500 万创作者，产品自发布以来迭代升级 30 余次，累计生成超 2 亿个视频和 4 亿张图片。&lt;/p&gt; 
&lt;p&gt;可灵 AI 产品及运营负责人李杨表示，4 月可灵 2.0 发布以来，服务的 B 端商家数量迎来爆发式增长。截至目前，全球范围内已有超过两万企业客户及开发者接入了可灵 AI 的 API（应用程序编程接口）接口，覆盖全球 149 个国家和地区。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362870</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362870</guid>
      <pubDate>Thu, 17 Jul 2025 02:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里开源通义万相 Wan2.2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;阿里&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FiPL7OLQhwYdoFelHt41N6Q" target="_blank"&gt;宣布&lt;/a&gt;开源视频生成模型「通义万相 Wan2.2」，此次共开源文生视频（Wan2.2-T2V-A14B）、图生视频（Wan2.2-I2V-A14B）和统一视频生成（Wan2.2-IT2V-5B）三款模型。其中文生视频模型和图生视频模型均为业界首个使用 MoE 架构的视频生成模型，总参数量为 27B，激活参数 14B。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，通义万相 2.2 率先在视频生成扩散模型中引入 MoE 架构，有效解决视频生成处理 Token 过长导致的计算资源消耗大问题。Wan2.2-T2V-A14B、Wan2.2-I2V-A14B 两款模型均由高噪声专家模型和低噪专家模型组成，分别负责视频的整体布局和细节完善，在同参数规模下，可节省约 50% 的计算资源消耗，在模型能上，通义万相 2.2 在复杂运动生成、人物交互、美学表达、复杂运动等维度上也取得了显著提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Wan2.2 还首创了「电影美学控制系统」，光影、色彩、构图、微表情等能力媲美专业电影水平。例如，用户输入「黄昏」、「柔光」、「边缘光」、「暖色调」「中心构图」等关键词，模型可自动生成金色的落日余晖的浪漫画面；使用「冷色调」、「硬光」、「平衡图」、「低角度」的组合，则可以生成接近科幻片的画面效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="213" src="https://oscimg.oschina.net/oscnet/up-9384df8eada31bdbc196286746847bfe546.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="177" src="https://oscimg.oschina.net/oscnet/up-58b00afb9376a3a0972e10d973fdb82ab5f.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="213" src="https://oscimg.oschina.net/oscnet/up-7c4a2896d24586d24ff41491862261a2aeb.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;通义万相还开源了一款 5B 小尺寸的统一视频生成模型，单一模型同时支持文生视频和图生视频，可在消费级显卡部署。该模型采用了高压缩率 3D VAE 架构，时间与空间压缩比达到高达 4×16×16，信息压缩率提升至 64，均实现了开源模型的最高水平，仅需 22G 显存（单张消费级显卡）即可在数分钟内生成 5 秒高清视频，是目前 24 帧每秒、720P 像素级的生成速度最快的基础模型。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362867</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362867</guid>
      <pubDate>Thu, 17 Jul 2025 02:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里云正式开源 LoongSuite：打造 AI 时代的高性能低成本可观测采集套件</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：阿里云可观测开源&lt;/p&gt; 
&lt;h2&gt;AI Agent 技术架构演进重塑软件工程实践方式&lt;/h2&gt; 
&lt;p&gt;在 AI Agent 开发领域，技术架构的演进正在重塑软件工程的实践方式。开发者既可以通过 Cursor、通义灵码、Claude Code 等智能编程助手提升代码生成效率，也可依托专业的 AI Agent 开发框架构建完整的智能体系统。技术生态呈现出多维度发展：实现方式既有需要深度编码的高代码方案，也有通过可视化组件拖拽的低代码平台；技术栈维度 Java 生态的 Spring AI Alibaba 与 Python 领域的 Dify、AgentScope 等工具形成跨语言支持体系，其中 Python 凭借其丰富的 AI 库生态占据主导地位。技术演进也催生新型开发范式：AutoGen 的多 Agent 对话框架、LangChain 的模块化组件体系，都在降低智能体开发的技术门槛。&lt;/p&gt; 
&lt;p&gt;我们把智能体的核心能力体系，总结成四个关键构成维度：感知层需要集成多模态交互能力，包括自然语言处理、语音识别和视频流分析；决策中枢由大模型构成，通过 AI 网关（如 Higress）实现模型调用的统一调度，同时也承担流量控制与安全防护的关键角色；记忆机制存储用户交互历史并具备上下文关联能力；工具集成方面，随着 MCP 协议的出现，工具的使用逐渐标准化。工具成为 AI Agent 和传统互联网时代的数字世界很好的沟通渠道。而 MCP 市场的出现可以将 MCP 工具集中进行管理和发现，高效完成 Agent 和工具的连接。同时，当单体 Agent 的能力边界被突破时，多 Agent 系统通过 A2A 协议实现协同计算，这种分布式智能架构能够处理更复杂的任务场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c3b5e0b94b8ba58ffcbf17953e3222070a3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;AI 工具链全景图&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;随着开发工具链的持续完善，AI Agent 在完成开发后需要进行部署。Agent 执行环境的差异化需求催生了多样的架构模式：面向个人用户的桌面端 Agent（如 Cherry Studio, DeepChat）可以通过云端沙箱环境将运行时延伸到云端，而面向企业服务的 Agent 则运行在具备资源隔离的云原生环境中，Serverless 架构（如函数计算）可以为其提供弹性伸缩的基础设施。在 AI Agent 运行过程中，一些通用的能力也需要由中间件来支撑：通过 Nacos 实现的动态 Prompt 管理以及 MCP 注册中心、Higress 可以作为 AI 模型和 MCP Server 统一代理、RocketMQ 支撑的异步任务队列、Redis 提供的状态存储等共同构成智能体运行的技术底座。同时，安全体系的构建面临数据合规与系统防护双重挑战。在数据治理层面，需建立敏感信息过滤机制和审计追踪系统；针对 MCP 协议的安全漏洞，可采用沙箱隔离、工具签名认证等技术手段构建防御体系。可观测性平台通过采集 Agent 与模型的调用、token 消耗、性能指标等关键信息，为系统优化和威胁检测提供数据支撑。&lt;/p&gt; 
&lt;h2&gt;可观测性：AI Agent 技术发展的重要基石&lt;/h2&gt; 
&lt;p&gt;正如前文提到，AI Agent 的开发已突破传统软件工程的边界，其非确定性决策机制与动态化执行流程对可观测性提出了革命性要求。一个智能体其背后涉及的多模态数据处理、大模型推理及工具链调用的复杂度呈指数级增长。这种复杂性不仅体现在技术架构层面，更深刻影响着系统的稳定性保障、成本控制与合规审计等核心运维环节。&lt;/p&gt; 
&lt;p&gt;AI Agent 的自主决策特性使其区别于传统软件应用，涉及多模态数据处理、大模型推理及工具调用等复杂交互。当这种非线性工作流应用于真实业务场景时，任何环节的异常都可能引发连锁反应。另一方面，当 Agent 与模型进行多轮交互时，中间过程可能产生惊人的 Token 消耗，甚至有可能陷入无休止的状态，形成所谓的 "Token 黑洞"。在缺乏链路追踪机制的情况下，开发者难以定位服务异常的根源。通过构建端到端的可观测能力可以提供坚实的决策依据。&lt;/p&gt; 
&lt;p&gt;AI Agent 的迭代升级需要在保持服务连续性的前提下进行，这要求建立完善的回归测试评估体系。每一次提示词、模型的变更都可能引发不可预见的副作用。每一次 AI Agent 的修改和发布上线，我们都需要对 Agent 执行的结果进行评估，这相当于对 AI Agent 进行"回归测试"。通过采集执行过程中的可观测数据，企业可以构建自动化评估框架，量化新版本对服务质量的影响，避免版本迭代风险失控。&lt;/p&gt; 
&lt;p&gt;随着生成式 AI 不断发展，可观测性正从运维工具进化为 AI 应用架构的核心组件。正是看到了这样的技术趋势，OpenTelemetry 社区推动的 GenAI 语义约定，正在构建跨框架、跨供应商的标准化数据规范。也是在这样的技术背景之下，阿里云正式开源 LoongSuite 可观测采集套件，在顺应 AI 时代技术发展趋势的基础上，帮助更多企业，通过高性能低成本的方式，更高效地利用标准化数据规范模型建立可观测体系。&lt;/p&gt; 
&lt;h2&gt;LoongSuite ：打造 AI 时代高性能低成本的可观测采集套件&lt;/h2&gt; 
&lt;p&gt;LoongSuite （/lʊŋ swiːt/）（音译，龙-sweet），作为下一代可观测性技术生态的核心载体，核心数据采集引擎实现了主机级探针与进程级插桩的有效结合，进程级探针实现应用内细粒度可观测数据采集，而主机探针则实现了高效灵活的数据处理和数据上报，以及通过 eBPF 等技术实现了进程外数据采集能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f16653bf7aa654aa37e5e43c6508112a9a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;LoongSuite 技术应用架构&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在进程级数据采集层面，LoongSuite 对 Java、Go、Python 等主流编程语言构建企业级观测能力。通过语言特性的深度适配，采集器能够自动捕获函数调用链路、参数传递路径及资源消耗，无需修改业务代码即可实现运行时状态的精准采集。这种无侵入式设计特别适用于动态更新频繁的技术环境，既保障观测数据的完整性，又避免对核心业务逻辑产生干扰。当面对复杂工作流时，系统可自动关联分布式追踪上下文，构建完整的执行路径拓扑。作为核心数据采集引擎，LoongCollector 实现多维度观测数据的统一处理，从原始数据采集到结构化转换，再到智能路由分发，整个流程通过模块化架构实现灵活编排。这种架构使观测数据既可对接开源分析平台实现自主治理，也可无缝衔接托管服务构建云原生观测体系。在技术生态构建方面，阿里云深度参与国际开源标准制定，其核心组件与 OpenTelemetry 等主流标准兼容。接下来，我们将逐一介绍相关组件。&lt;/p&gt; 
&lt;h3&gt;LoongCollector&lt;/h3&gt; 
&lt;p&gt;LoongCollector 作为新一代可观测性数据采集器，通过深度性能优化与技术架构创新，为云原生智算服务提供了高性能、高稳定的可观测数据采集与预处理解决方案，尤其在 AI 场景中展现出显著优势。&lt;/p&gt; 
&lt;p&gt;首先，LoongCollector 具备多维度的可观测数据采集能力，支持 Logs、Metrics、Traces、Events、Profiles 等多种类型数据的统一采集、处理与传输，实现了 All-in-One 的可观测性管理架构。它融合了实时日志采集、Prometheus 指标拉取、eBPF 技术等能力，在无需修改系统代码的前提下完成无侵入式监控，能够高效获取各类性能指标，尤其适用于大规模分布式训练和推理任务中的一体化可观测需求。&lt;/p&gt; 
&lt;p&gt;其次，LoongCollector 在性能与稳定性方面表现出色。其采用事件驱动架构、时间片调度、无锁化设计等技术，确保在高并发、大规模数据采集场景下仍能保持低资源消耗和高吞吐量。同时，其高低水位反馈队列机制和持久化缓存能力，使其具备良好的流量控制和容错能力，确保数据不丢失、采集不间断、服务不抖动，全面满足 AI 训练过程中对稳定性、连续性和可靠性的严苛要求。&lt;/p&gt; 
&lt;p&gt;再者，在 AI 场景中，LoongCollector 支持多种部署模式，包括 Agent 模式和集群模式，能够灵活适应分布式训练和推理任务的弹性需求。其具备自动发现容器上下文、关联 K8s 元信息、多租户隔离等能力，确保在复杂云原生环境下实现高效、安全的数据采集。同时，通过配置管理服务 ConfigServer，可实现对大规模 Agent 的集中管控与动态配置下发，显著提升运维效率与系统可控性。&lt;/p&gt; 
&lt;p&gt;此外，LoongCollector 实现了多维度观测数据的统一处理能力。从原始数据采集到结构化转换，到数据过滤聚合处理，再到路由分发，全流程模块化灵活编排、按需扩展。其支持 SPL 查询语言与多语言插件双引擎驱动，并内置丰富的数据处理算子，满足多样化、高吞吐的数据预处理场景。&lt;/p&gt; 
&lt;p&gt;综上所述，LoongCollector 凭借其全面的数据采集能力、卓越的性能表现、灵活的部署方式与强大的可编程性，成为 AI 场景下构建可观测性体系的核心基础设施，助力企业实现高效、稳定的智算服务运维。&lt;/p&gt; 
&lt;h3&gt;LoongSuite Python Agent&lt;/h3&gt; 
&lt;p&gt;LoongSuite Python Agent 基于 OpenTelemetry Python Agent 构建，OTel 社区由于还在制定 GenAI 语义规范，很多 AI 框架的支持尚未完全实现，目前基本只有 OpenAI 的插件可以支持可观测数据采集，和国内的流行 AI 框架相去甚远。LoongSuite Python Agent OTel GenAI 语义规范的最新实现，在遵循开源语义规范的基础上，添加了国内流行插件的支持。例如国内流行的 AgentScope, Agno 等 AI 编程框架，目前已经率先提供了支持，更多插件包括 Dify、Langchain、MCP Client 的支持，陆续会开源，并且会将这些插件贡献回 OTel 社区。通过 Python agent 我们可以轻松地采集 AI agent 调用模型和工具过程中的详细信息，耗时等多方面的数据。借助 OTel 项目可以将这些数据以标准的 OTLP 协议的方式上报到任意的存储之中，并且通过可视化的界面进行展示。&lt;/p&gt; 
&lt;h3&gt;LoongSuite Go Agent&lt;/h3&gt; 
&lt;p&gt;LoongSuite Go Agent 通过编译时插桩技术，为 Go 语言构建的 AI Agent 提供无侵入式的观测能力。通过深度解析 Go 语言的编译流程，在 AST 语法树分析阶段植入监控逻辑，实现了在不修改源代码的前提下完成可观测性能力的注入。LoongSuite Go Agent 采用编译增强机制，通过预定义的埋点规则引擎，在编译阶段自动注入 Span 创建、token 消耗等统计逻辑。内置对主流开发框架的完整支持，从基础通信协议到中间件交互，从微服务治理到数据持久化，系统已覆盖包括 HTTP、gRPC、数据库连接等在内的二十多个核心模块，能够自动捕获请求延迟分布、服务调用拓扑及资源竞争状态等关键指标。这种开箱即用的设计显著降低了观测体系的部署门槛，使开发者能够聚焦业务逻辑而非基础设施配置。LoongSuite Go Agent 可以精准捕获大模型调用的输入输出特征、Token 消耗模式及多轮交互的流程轨迹，为优化资源利用率提供了数据基础。目前支持的 AI Agent 开发框架包括 LangChainGo【1】，MCP Server【2】等，Eino、Ollma 等框架的支持也将陆续发布。&lt;/p&gt; 
&lt;h3&gt;LoongSuite Java Agent&lt;/h3&gt; 
&lt;p&gt;LoongSuite Java Agent 基于 OpenTelemetry Java Instrumentation 项目，通过字节码增强技术，为 Java 应用提供全链路的可观测性解决方案。借助对 Java 字节码的动态修改能力，实现了无需手动修改业务代码即可接入分布式追踪、指标收集和日志关联的观测体系。在极低性能开销的前提下，提供细粒度的运行时数据采集能力，适配从传统单体应用到云原生微服务的全场景观测需求。从基础的 Servlet、Spring、Dubbo 等开发框架，到 Redis、Kafka、MySQL 等中间件，再到 JVM 自身的性能指标采集，系统已覆盖超过 50+ 常用组件的自动埋点，能够自动捕获调用链路拓扑、方法执行耗时、异常堆栈及资源消耗等关键数据。这种即插即用的特性极大降低了可观测性接入的技术门槛，使开发者无需关注埋点细节即可获得全面的系统运行视图。针对高并发场景，其内置的采样策略与数据聚合机制可在保证观测精度的同时，有效控制数据量，满足生产环境的高可用性要求。目前已经在百炼大模型平台大规模生产落地，这些过程中积累的在大模型场景下数据采集的优化等方式将陆续发布到开源仓库。此外，针对常见的模型访问 SDK 如 OpenAI, DashScope 等，正在提供自动埋点支持，也欢迎社区贡献更多的插件实现。&lt;/p&gt; 
&lt;h3&gt;Loongsuite 与 Spring AI Alibaba 共建 AI 应用生态建设&lt;/h3&gt; 
&lt;p&gt;Spring AI 作为 Spring 生态与大模型能力融合的产物，在 Java 语言中提供了对 LLM 的抽象封装和易用的 API，同时在可观测性设计上充分拥抱 OpenTelemetry 标准，为关键调用提供了原生的可观测性能力。Spring AI Alibaba【3】 是 Alibaba 在 Spring AI 项目的基础上构建的 AI Agent 开发框架，深度集成了百炼大模型平台能力，提供了如工作台、Graph 等诸多可视化的白屏能力，以及各种开箱即用的预实现 Agent。Spring AI 的核心目标是让开发者能够以 Spring 的方式快速集成和使用 AI 能力。因此像 Spring 一样，可观测性被作为重要的组成部分集成在框架内部。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-483e2b3957f208292fdeef0998b8034673d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在可观测性上，Spring AI 提供以下关键能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动埋点：Spring AI 对所有涉及 LLM 调用、Prompt 构建、流式响应处理等关键路径进行了自动追踪埋点，并生成符合 OpenTelemetry 标准的 Span。&lt;/li&gt; 
 &lt;li&gt;上下文传播：支持在调用链中自动注入和提取 Trace ID 和 Span ID，确保与上下游服务的调用链路无缝衔接。&lt;/li&gt; 
 &lt;li&gt;指标导出：内置对请求延迟、token 使用量、模型响应长度等关键性能指标的采集与导出。&lt;/li&gt; 
 &lt;li&gt;日志关联：通过 MDC 或结构化日志机制，将当前 Span 上下文注入到日志中，便于问题排查时进行全栈分析。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些能力使得 Spring AI 在接入观测系统时无需额外开发即可实现完整的追踪、监控与日志联动。为了进一步提升可观测性覆盖范围并降低接入成本，Spring AI Alibaba 支持结合 LoongSuite Java Agent 进行部署。Java Agent 可以无侵入地对运行中的 JVM 应用进行字节码增强，从而实现对 Spring 框架、数据库访问、HTTP 请求等通用组件的自动埋点。&lt;/p&gt; 
&lt;h2&gt;LoongSuite 项目未来规划&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;面对 AI Agent 众多的框架，LoongSuite 将会针对市面上的主流 AI Agent 提供全面的可观测性数据采集能力，包括 Python 生态中的低代码平台 Dify、高代码框架 AgentScope、Agno、OpenAI Agent 等主流 AI Agent 开发框架，同时也包括 Java 生态中的 Spring AI Alibaba 以及其基础之上的低代码以及 0 代码 Agent JManus 提供强有力的支撑，Golang 生态中的 Eino, Langchain4go 等等，也欢迎有兴趣参与社区的同学一起参与贡献更多的框架。&lt;/li&gt; 
 &lt;li&gt;未来 Agent 会大量使用工具，多智能体的协同也将成为常态，LoongSuite 会打通 MCP 和多 Agent 通讯的观测盲区，突破 MCP token 黑洞，实现对 MCP 和 A2A 协议的可观测覆盖。&lt;/li&gt; 
 &lt;li&gt;AI Agent 开发完在测试和线上运行期间都需要对 AI Agent 的行为进行充分的评估，评估的能力逐步成为 AI Agent 生命周期中不可或缺的一环，和 Spring AI Alibaba 以及 AgentScope 等项目集成，发布开源可观测追踪和评估能力控制枱，形成从采集、存储到评估的 AI Agent 全周期覆盖。&lt;/li&gt; 
 &lt;li&gt;实现端到端可观测能力的覆盖，打通端侧 Agent 到模型内部的整条链路，实现 AI Agent 链路完整分析和快速诊断。&lt;/li&gt; 
 &lt;li&gt;LoongCollector 通过 eBPF 支持 CPU 和 GPU 场景下的 Profiling 能力，LoongSuite 也将和 SysOM【4】 社区共同推出 AI 场景下的 Profiling 能力。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;开源社区参与&amp;amp;贡献&lt;/h2&gt; 
&lt;p&gt;作为全球领先的云服务商，阿里云始终致力于开源观测技术的最前沿。我们深度投身于 OpenTelemetry（OTel）社区，坚定不移地参与、支持技术开放生态的构建以及全球技术标准的制定。过去几年，阿里云在 OpenTelemetry 社区中积极推动技术共享与代码贡献，深度融入社区多个关键领域，如 Semantic Conventions（可观测标准规范建设）、Java Instrumentation（Java 探针）、Go Instrumentation（Go 探针）、Profiling（性能分析）等。截至目前，我们累计向社区贡献并合并 1000+ PR Reviews 与 400+ Pull Requests。在这一开源贡献进程中，我们成功培养出 3 位 Maintainer、5 位 Approvers、1 位 Triager 以及 8 位 Member，为社区的技术演进与生态建设注入了强劲动力。&lt;/p&gt; 
&lt;p&gt;除却技术贡献，阿里云亦全力践行开源文化所倡导的分享与合作精神，积极推动新技术与新思想的蓬勃发展。例如，我们踊跃在 KubeCon、OTel Community Day 等全球性行业会议中分享技术成果，同时在社区内发起设立了面向亚太地区的友好交流时段，有力促进了与社区的跨地域技术交流与深度合作。也欢迎更多的开发者加入 OTel 社区以及 LoongSuite 中。LoongSuite 开源的代码仓库如下，欢迎参与贡献：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;LoongCollector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Floongcollector" target="_blank"&gt;https://github.com/alibaba/loongcollector&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;LoongSuite Python Agent:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Floongsuite-python-agent" target="_blank"&gt;https://github.com/alibaba/loongsuite-python-agent&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;LoongSuite Go Agent:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Floongsuite-go-agent" target="_blank"&gt;https://github.com/alibaba/loongsuite-go-agent&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;LoongSuite Java Agent:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Floongsuite-java-agent" target="_blank"&gt;https://github.com/alibaba/loongsuite-java-agent&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;【1】LangChainGo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftmc%2Flangchaingo" target="_blank"&gt;https://github.com/tmc/langchaingo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【2】MCP Server&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmark3labs%2Fmcp-go" target="_blank"&gt;https://github.com/mark3labs/mcp-go&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【3】Spring AI Alibaba&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Falibaba%2Fspring-ai-alibaba%2Fblob%2Fmain%2FREADME-zh.md" target="_blank"&gt;https://github.com/alibaba/spring-ai-alibaba/blob/main/README-zh.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【4】SysOM&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenanolis.cn%2Fsig%2Fsysom" target="_blank"&gt;https://openanolis.cn/sig/sysom&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18686155</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18686155</guid>
      <pubDate>Thu, 17 Jul 2025 02:08:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
