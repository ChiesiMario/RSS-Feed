<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 19 Mar 2025 02:43:39 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>字节召开大模型全员会：取消 AGI 研究团队季度与半年考核</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节跳动的豆包大模型团队（Seed）近日召开了一次全员会议，由刚加入字节负责 AI 基础研究探索的吴永辉与模型应用负责人朱文佳共同主持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;会议上，朱文佳和吴永辉明确表示，Seed 团队的首要目标是 「探索智能上限」，这将成为团队未来工作的核心导向。他们指出，探索智能的边界是一个长期的任务，团队将围绕已发布的 AGI 研究计划 「Seed Edge」 进行深入研究。朱文佳提到，鼓励团队成员参与有挑战性的研究课题，探索具有不确定性和前瞻性的 AI 技术，将是今年的重点之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;276&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca5ed7f8eb1cb23c67774924335eae3009a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;吴永辉强调了基础研究的重要性，并表示将加大对 Seed Edge 项目的资源投入，包括提供更多的计算能力，以支持长远的研究发展。他提到，Seed 希望成为一个能够吸引和培养顶尖人才的组织，强调内部人才的使用和培养是团队成功的关键。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在组织文化方面，会议还讨论了如何增强团队的开放性和包容性，以营造一个鼓励创新的环境。为此，字节跳动决定取消 Edge 项目的季度 OKR 和半年考核，旨在为团队提供一个更稳定的研究环境，减轻因考核而产生的压力。吴永辉希望通过这样的改变，提升团队的创造力和研究的深度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，团队还提到未来可能会考虑开源一些中小尺寸的 Dense 模型，以推动技术在社区中的应用。这样的举措不仅有助于增强 Seed 团队的影响力，也能促进外部的合作与交流。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339724</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339724</guid>
            <pubDate>Wed, 19 Mar 2025 02:34:31 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌将以 320 亿美元全现金交易收购 Wiz</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌母公司 Alphabet Inc. 已同意以 320 亿美元现金（约 2312.6 亿元人民币）收购网络安全公司 Wiz Inc.，交易完成后，Wiz 将加入谷歌云业务。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b694b65e36bb41b50e4ab2751738269c9c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据报道，这笔交易将成为 Alphabet 迄今为止最大的一笔收购，Wiz 去年曾拒绝 Alphabet 提出的 230 亿美元的报价，理由是担心监管挑战以及希望保持独立，但现在已同意了更高的报价。&lt;/p&gt; 
&lt;p&gt;TechCrunch 报道称，去年 7 月，Wiz 的 ARR 为 5 亿美元，并计划在 2025 年达到 10 亿美元。&lt;/p&gt; 
&lt;p&gt;即便如此，300 亿美元也可能是一个相当高的价格。去年 5 月，Wiz 完成了上一轮 10 亿美元的外部融资，估值达到 120 亿美元。据报道，去年年底，在一次员工竞购中，其估值跃升至 160 亿美元。&lt;/p&gt; 
&lt;p&gt;尽管 Wiz 表示没有计划在 2025 年上市，但它聘请了梦工厂和 Tanium 前高管法扎尔・麦钱特 (Fazal Merchant) 担任首席财务官。有时，聘请首席财务官是准备公开上市的标志。&lt;/p&gt; 
&lt;p&gt;报道称，此前谈判失败的原因之一是两家公司未能就 Wiz 是保留为独立部门还是整合到 Google Cloud 达成一致。&lt;/p&gt; 
&lt;p&gt;熟悉该交易的人士表示，拜登政府对大额交易的严格监管审查也是导致该交易去年夏天失败的原因之一。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关来源&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Finside-google%2Fcompany-announcements%2Fgoogle-agreement-acquire-wiz%2F&quot; target=&quot;_blank&quot;&gt;https://blog.google/inside-google/company-announcements/google-agreement-acquire-wiz/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wiz.io%2Fblog%2Fwiz-joining-google&quot; target=&quot;_blank&quot;&gt;https://www.wiz.io/blog/wiz-joining-google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fidentity-security%2Fgoogle-announces-agreement-acquire-wiz&quot; target=&quot;_blank&quot;&gt;https://cloud.google.com/blog/products/identity-security/google-announces-agreement-acquire-wiz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339725/google-announces-agreement-acquire-wiz</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339725/google-announces-agreement-acquire-wiz</guid>
            <pubDate>Wed, 19 Mar 2025 02:34:31 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>卢伟冰：将投入 1/4 研发经费至 AI 技术，AI、OS 和芯片三项被列为小米核心技术</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，小米集团总裁卢伟冰今日晚间在 2024 年业绩会上称，&lt;strong&gt;小米将投入总研发经费的 1/4，大约 70 至 80 亿元到 AI 中&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;卢伟冰表示，&lt;strong&gt;长期来看，AI、OS 和芯片三项被列为小米核心技术&lt;/strong&gt;。短期来看，小米要做好 AI 基建，开发语言大模型、多模态大模型等 AI 技术，搭建 AI 大模型落地的应用场景，比如超级小爱、智能座舱、智能驾驶等，小米内部也会利用 AI 技术进行内部提效。&lt;/p&gt; 
&lt;p&gt;针对小米汽车出海，卢伟冰称，先把中国市场做好，小米汽车正在启动出海相关的准备，汽车出海的复杂度要比小米预期高，2027 年将会是小米汽车出海的元年。&lt;/p&gt; 
&lt;p&gt;小米集团昨天发布了 2024 年度全年财报，小米 CEO 雷军称是「史上最强年报」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1954&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0319/102444_KBrs_2720166.png&quot; width=&quot;1248&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;小米集团第四季度营收 1,090.1 亿元，市场预估 1,043.8 亿元。全年营收 3,659.1 亿元，同比增长 35%，市场预估 3,580.5 亿元。&lt;/p&gt; 
&lt;p&gt;第四季度净利润 90.0 亿元，市场预估 52.5 亿元；全年净利润 236.6 亿元，市场预估 197.6 亿元。&lt;/p&gt; 
&lt;p&gt;2024 年智能手机业务收入为 1918 亿元，同比增长 21.8%，毛利率达到 12.6%。2024 年全球智能手机出货量为 168.5 百万台，同比增长 15.7%。&lt;/p&gt; 
&lt;p&gt;2024 年第四季度，智能电动汽车等创新业务分部总收入为 167 亿元，其中，智能电动汽车收入 163 亿元，其他相关业务收入 3 亿元。2024 年第四季度，智能电动汽车等创新业务分部毛利率为 20.4%。2024 年第四季度，智能电动汽车等创新业务经调整净亏损 7 亿元。2024 年，智能电动汽车等创新业务分部毛利率为 18.5%。2024 年，智能电动汽车等创新业务经调整净亏损 62 亿元。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/339627&quot; target=&quot;news&quot;&gt;小米汽车模型训练专利公布，可解决资源消耗较大等技术问题&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339722</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339722</guid>
            <pubDate>Wed, 19 Mar 2025 02:21:31 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英伟达下下一代 AI 芯片架构命名 Feynman</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在英伟达 GTC 2025 大会上，英伟达 CEO 黄仁勋公布了新一代 AI 芯片 Rubin，预计于 2026 年推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与此同时，黄仁勋还在一个路线图 PPT 中宣布，Rubin 之后的下一代芯片命名 Feynman，将于 2028 年登场。该名称取自美国著名理论物理学家理查德・费曼（Richard Phillips Feynman，1918 年 5 月 11 日—1988 年 2 月 15 日）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;375&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ee9f5c28da756110855f6347717e7354e68.jpg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;span style=&quot;background-color:#ffffff; color:#8e8e93&quot;&gt;（图片来源：Artur Widak/Anadolu via Getty Images）&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;理查德·费曼是量子计算领域最著名的历史人物之一，主要从事量子力学的路径积分表述、量子电动力学、过冷液氦的超流性以及粒子物理学中部分子模型的研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他建立了解决液态氦超流体现象的数学理论。和默里·盖尔曼在弱相互作用领域，比如β衰变方面，做了一些奠基性工作。并通过提出高能质子碰撞过程的层子模型，在夸克理论的发展中起了重要作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了芯片之外，英伟达还宣布推出全新 Spectrum-X Silicon Photonics Ethernet 交换机，可为 AI 工厂实现 3.5 倍的能源节省和 10 倍的弹性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/338748/nvidia-vera-rubin-chips&quot; target=&quot;news&quot;&gt;英伟达将下一代 AI 芯片命名为 Rubin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339719/nvidia-gtc-2025-announces-feynman</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339719/nvidia-gtc-2025-announces-feynman</guid>
            <pubDate>Wed, 19 Mar 2025 02:05:31 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>万字干货分享最新 AI 指南：用 LazyLLM 把 Deep Research 做成赛博屠龙刀！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;最近 OpenAI、Jina、perplexity 等各大厂商纷纷推出了自家的 Deep Research 应用。Deep research 是什么？为什么这个应用引起了大家的关注？能不能使用 lazyllm 搭建一个属于自己的 deep research？带着这些问题，本文将对 OpenAI 发布的 Deep Research 进行简要介绍，并依托于 lazyllm 强大的能力，使用极少代码量实现一个自己的 deep research。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;什么是 Deep Research？&lt;/h2&gt; 
&lt;p&gt;Deep Research 是 OpenAI 在 2025.2 月发布的一种新型的代理（Agent）能力，其被集成在 ChatGPT 中，能够通过大模型的推理能力和工具调用能力，自主从网络检索、整合信息，同时支持读取用户提供的文件，并通过编写和执行 Python 代码来分析数据，通过深度分析数据，对用户的问题进行深度解答，最终输出专业的长篇报告。&lt;/p&gt; 
&lt;p&gt;随着现有模型能力的增强，大模型应用逐渐朝着 AI Agent 方向发展，Agentic-RAG 也迅速成为大模型应用落地的一个主要方向，其相比于传统意义上的 RAG（Naive RAG or Advanced RAG），Agentic rag 能够分析用户查询的复杂语义，利用提供的工具集完成复杂多跳的查询，随后阅读查询内容并汇总后，最终回答用户的问题。agentic rag 无论从回答深度还是广度，相比之前都有着大幅的提高。Deep Research 本质上是 RAG（检索增强生成）的衍生物，其查询范围不再局限于本地的知识库，同时具备了网页查询、阅读的能力。同时随着推理大模型技术的发展，其性能相比之前的 agentic rag 更是跨越至一个新的 level。DeepResearch 的出现，能够很大程度节省专业人士查询资料的时间，与大多数 RAG 系统试图一步到位地回答问题不同，Deep Research 的核心在于其循环推理机制，通过这种机制，它会持续搜索信息、阅读相关来源并进行推理，直到找到答案或耗尽 token 预算。&lt;/p&gt; 
&lt;p&gt;以下是使用 OpenAI 的 Deep Research 调研 lazyllm 应用场景的全过程：应用首先会分析用户的问题，随之进行反问，以更好的理解用户意图。随后应用经过分析，会调用自身的搜素工具，从问题的各个角度进行信息搜集。最后综合这些信息，输出专业的长篇报告。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;601&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-52bc63edde7cb5eee0318342422a0939140.png&quot; width=&quot;1148&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ChatGPT DeepResearch 入口）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;849&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-655f160476b5e12f175b569afbd1ab86347.png&quot; width=&quot;1587&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（提问-反问-搜索示意图）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;841&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b05daa865fcfe3fbe33bfb2a2b546cbbcf2.png&quot; width=&quot;1511&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（信息搜集完毕，生成专业报告）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;从使用体验上来说，deep research 给人一种非常靠谱的感觉，用户能够实时观察其是如何自主思考并查询信息的，这一过程往往需要花费 5~10 分钟，更有甚者可以持续半个小时！这一过程的展现给用户提供了极强的」情绪价值「（与 deepseek 展示思维链的作用相似）：安排任务、等待输出专业的长篇报告，这不是老板才有的待遇？？？拥有 Deep Research，你就相当于拥有了一位集高效搜索、缜密推理、专业写作为一体的」赛博员工「，助你成功当上赛博老板。&lt;/p&gt; 
&lt;p&gt;Deep Research 强大吗？强大。但通过观察其输出的内容，不难发现，大模型一直以来的通病——「幻觉」仍然存在，deepresearch 虽然利用检索增强生成技术已经尽可能降低了模型幻觉的情况，但其生成的报告中仍然存在一些与事实不符的信息。例如在其生成的内容当中有一段」上海银行数字人客服「员工」：&lt;strong&gt;上海银行引入两位 AI 数字员工（由商汤 LazyLLM 方案支持），在手机 App 等渠道为客户提供交互式服务。&lt;/strong&gt;「，文字后面信誓旦旦的附上了参考链接（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sensetime.com%2Fcn%2Fcase-detail%3FcategoryId%3D51134352%23%3A%7E%3Atext%3D%25E8%2590%25BD%25E5%259C%25B0%25E6%2588%2590%25E6%259E%259C&quot; target=&quot;_blank&quot;&gt;https://www.sensetime.com/cn/case-detail?categoryId=51134352#:~:text=%E8%90%BD%E5%9C%B0%E6%88%90%E6%9E%9C&lt;/a&gt; ），打开进去一看，网页中只是提及了商汤科技与上海银行合作，并未提及使用 LazyLLM 支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;697&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-286d94e6058d77856a05c8fd679e369af83.png&quot; width=&quot;1044&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（对应网站中并未提及相关信息）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;虽然仍有幻觉，但这并不妨碍 DeepReseach 成为新一代 AI Agent 应用中的佼佼者（拜托，已经很强了~~~)。这么有趣的应用，少了 LazyLLM 怎么行？本着」万物皆可 Lazy「的原则，下面我们从技术层面把 Deep Research 的实现框架进行拆解，并尝试使用 LazyLLM 复现！GoGoGo！&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;Deep Research 框架介绍&lt;/h2&gt; 
&lt;p&gt;首先我们来构建 Deep Research 这个应用的框架。通过对 Deep Research 的试用可以发现，应用主要分为三个阶段：意图理解与规划、信息搜索与汇总、专业报告生成。框架示意图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;428&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6f6545a4f64d9ff5808cde2f41f3e8e75c2.png&quot; width=&quot;1466&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（deep research 框架示意图）&lt;/em&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;意图理解与规划：在这一阶段，Deep Research 会根据用户的输入分析并理解用户的意图，期间可能会存在通过反问用户获取更精确信息的过程。待 DeepResearch 认为获取到足够信息后，便会进入下一阶段。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;（需要指出的是，OpenAI 的 deep research 并未在这一阶段结束后显式的给出写作大纲之类的东西。但为了能生成专业的长篇报告，以及方便指导后续的信息搜索，这里我们认为生成有指导意义的写作大纲是有必要的。类似 Plan-and-Solve 的思路，先充分规划，再有效执行）&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;信息搜索与汇总：在这一阶段，agent 会依照上一阶段的理解，自主得从互联网上搜索并总结有效信息（其中包含了网页搜索、网页浏览、文件阅读等步骤），这一阶段其实是 ReactAgent 的设计思路，给 agent 输入 query，agent 反复利用所提供的工具自主搜索网页、阅读网页、总结信息并反思，直到任务完成。&lt;/li&gt; 
 &lt;li&gt;上一阶段结束后，deepresearch 已经具备了完成写作的所有知识，结合这些知识，最终生成一个专业的长篇报告。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;使用 LazyLLM 实现 Deep Research&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;u&gt;准备阶段&lt;/u&gt;&lt;/h3&gt; 
&lt;p&gt;根据第二部分的框架可知，deep research 的重要组成部分有三：强大的大模型（LLM）、多样的工具（Tools）以及智能体组件（Agents），巧了么这不，lazyllm 全都有——现成的 llm 模块（TrainableModule/OnlineChatModule）、工具注册模块（fc_register）和智能体模块（ReactAgent/PlanAndSolveAgent/ReWOOAgent），妙~~啊~~。本次为了实现「快速复现」的目标，咱们一切从简，看看实现这个应用到底需要几行代码。&lt;/p&gt; 
&lt;p&gt;首先安装一下 lazyllm 的环境。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install lazyllm
lazyllm install standard&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;大模型：&lt;/h3&gt; 
&lt;p&gt;然后我们从大模型开始吧，本次我们选择「线上调用模型」的方式，借助通义千问的模型 API 实现模型的调用功能。假设你已经拥有了自己的 api-key（如果没有，请访问&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aliyun.com%2Fproduct%2Fbailian&quot; target=&quot;_blank&quot;&gt;https://www.aliyun.com/product/bailian&lt;/a&gt; 获取，并做好储值工作），随后将 api key 加入至环境变量中：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export LAZYLLM_QWEN_API_KEY=&amp;lt;your own api key&amp;gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;随后即可使用 lazyllm 创建大模型模块聊天啦~&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; from lazyllm import OnlineChatModule
&amp;gt;&amp;gt;&amp;gt; llm = OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False)
&amp;gt;&amp;gt;&amp;gt; llm(&quot;hello&quot;)
&#39;Hello! How can I assist you today?&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h3_6&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;工具集（Tools）&lt;/h3&gt; 
&lt;p&gt;巧妇难为无米之炊，To great LazyLLM, It&#39;s also very hard to run deep research without powerful tools. 通过了解 AI Agent 的工作原理可知，其本质上是为大模型提供多种多样的工具，引导大模型主动使用正确的工具完成特定任务，最终实现目标。因此，要实现 deep research，一系列好用的工具集是非常必要的。&lt;/p&gt; 
&lt;p&gt;观察 OpenAI 的 DeepResearch 以及其他已有应用可以发现，此类应用需要网络搜索工具、网页操作工具（浏览、解析文件、滑动页面等）、本地知识库检索工具（其实就是 RAG，软广：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9-wlmpSbZU40YctoiP2ugQ%3Fmpshare%3D1%26scene%3D1%26srcid%3D0312JOH9wNTxyWzUUvwWPb7r%26sharer_shareinfo%3D20291331b41834b5fdc559ca94396331%26sharer_shareinfo_first%3D20291331b41834b5fdc559ca94396331%23rd&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/9-wlmpSbZU40YctoiP2ugQ?mpshare=1&amp;amp;scene=1&amp;amp;srcid=0312JOH9wNTxyWzUUvwWPb7r&amp;amp;sharer_shareinfo=20291331b41834b5fdc559ca94396331&amp;amp;sharer_shareinfo_first=20291331b41834b5fdc559ca94396331#rd&lt;/a&gt; ）以及一些针对特定场景设计的小工具。此处我们只关注网络搜索、网页阅读以及一些基础的必要工具（比如反问用户以理解更精确的意图）。&lt;/p&gt; 
&lt;p&gt;工具其实就是函数，我们创建若干函数，最后使用 lazyllm 的注册机制将其注册为工具。举例说明，下面是使用 lazyllm 提供的谷歌搜索引擎组件编写的网络搜索工具 web_search（注：使用 GoogleSearch 需要自行注册账号并创建引擎，同样需要 api key，具体参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprogrammablesearchengine.google.com%2Fabout%2F&quot; target=&quot;_blank&quot;&gt;https://programmablesearchengine.google.com/about/&lt;/a&gt; ）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import os
import json

from lazyllm.tools import fc_register
from lazyllm.tools.tools.google_search import GoogleSearch
from lazyllm import LOG
from dotenv import load_dotenv
load_dotenv()

search_engine = GoogleSearch(os.getenv(&#39;GOOGLE_SEARCH_API_KEY&#39;), os.getenv(&#39;GOOGLE_SEARCH_CX&#39;))

@fc_register(&quot;tool&quot;)
def web_search(query: str) -&amp;gt; str:
    &quot;&quot;&quot;
    使用 google search 搜索与 query 相关的网页，搜索结果包含每个搜索结果的标题、简介和链接。

    Args:
        query (str): The search query string.
    &quot;&quot;&quot;
    LOG.info(f&quot;[tool - Web Search] Searching the web for query &#39;{query}&#39;...&quot;)
    response = search_engine(query=query, date_restrict=&#39;m1&#39;)
    if response.get(&#39;status_code&#39;) != 200:
        return f&quot;Error: Received status code {response.status_code}&quot;
    search_res = json.loads(response.get(&#39;content&#39;))
    res_str = &quot;&quot;
    cnt = 0
    for item in search_res.get(&#39;items&#39;):
        if cnt &amp;gt;= 5:
            break
        link = item.get(&quot;link&quot;)
        title = item.get(&quot;title&quot;)
        snippet = item.get(&quot;snippet&quot;)
        res_str += f&quot;Title: {title}\nSnippet: {snippet[:50]}...\nURL: {link}\n\n&quot;
        cnt += 1
    return res_str&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;需要注意的是，使用 lazyllm 创建的工具，必须使用@fc_register(&quot;tool&quot;) 进行「注册」，同时需要在对应函数下方加入必要的注释，解释工具的用途以及所需要的入参信息。我们按照同样的方式创建网页访问（visit_url）、反问用户（get_more_info_from_user）的工具：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@fc_register(&quot;tool&quot;)
def visit_url(url: str, encoding: str = None) -&amp;gt; str:
    &quot;&quot;&quot;
    使用这个工具来浏览一个网页的详细内容，并返回解析后的文本内容。

    Args:
        url (str): The URL of the webpage to visit.
        encoding (str, optional): The encoding of the webpage. If not specified, the encoding will be automatically detected.
    &quot;&quot;&quot;
    import requests
    from bs4 import BeautifulSoup
    from readability import Document
    headers = {
        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (compatible; my-bot/1.0)&quot;
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
    except Exception as e:
        return f&quot;Error: Failed to fetch URL. Exception: {e}&quot;

    if response.status_code != 200:
        return f&quot;Error: Received status code {response.status_code}&quot;

    if encoding:
        response.encoding = encoding
    else:
        response.encoding = response.apparent_encoding or response.encoding

    doc = Document(response.text)
    main_content = doc.summary()
    main_text = BeautifulSoup(main_content, &quot;html.parser&quot;).get_text(separator=&quot;\n&quot;, strip=True)

    return main_text if main_text else &quot;Error: Failed to extract main content.&quot;

@fc_register(&quot;tool&quot;)
def get_more_info_from_user(prompt: str) -&amp;gt; str:
    &quot;&quot;&quot;
    该工具用于反问用户，以获取更多有效信息。当你认为有必要主动询问用户时，使用这个工具。

    Args:
        prompt (str): Markdown formatted prompt which contains your understanding of the task, the current state, and a series of questions you want to ask to the user.
    &quot;&quot;&quot;
    LOG.info(&quot;Now I think I need more information from you...&quot;)
    LOG.info(prompt)
    res = input(&quot;Please provide more information: &quot;)
    return res&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这里我们使用了 readability 和 beautifulsoup 实现了较为简单的解析网页功能，后续的调优中，该部分可以进行一定的优化。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;智能体（Agent）&lt;/h3&gt; 
&lt;p&gt;有了工具后，我们便可以尝试使用 lazyllm 自带的 agent 模块进行一些简单的功能了。本次的 deepresearch 复现过程中，我们主要实现两种 agent：planner agent（用于第一阶段的意图识别与规划大纲）和 searcher agent（用于第二阶段的信息检索与总结）&lt;/p&gt; 
&lt;p&gt;lazyllm 提供了一些主流的 agent 模块供大家使用（参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.lazyllm.ai%2Fzh-cn%2Flatest%2FAPI%2520Reference%2Ftools%2F&quot; target=&quot;_blank&quot;&gt;https://docs.lazyllm.ai/zh-cn/latest/API%20Reference/tools/&lt;/a&gt; ）：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ReactAgent&lt;/strong&gt;：React agent 主要包括以下的流程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;思考（Thought）&lt;/strong&gt;: Agent 在收到 query 后，它会先给出下一步要采取的行动；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行动（Action）&lt;/strong&gt;: Agent 会采取并执行一个行动，比如使用工具（或者继续思考）；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;观察（Observation）&lt;/strong&gt;: Agent 观察行动的反馈，比如工具的输出；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;agent 按照「思考-行动-观察-反思-...」的流程执行任务，直至任务完成；&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;309&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-659a6a829ac241fb4d57086914b3fad7c19.png&quot; width=&quot;719&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ReactAgent 工作示意图）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PlanAndSolveAgent&lt;/strong&gt;：由两个组件组成，首先，由 planner 将整个任务分解为更小的子任务，然后由 solver 根据计划执行这些子任务，主要包括以下的流程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;计划（Plan）&lt;/strong&gt;：Agent 在收到 query 后，它会将这个任务分解为更小的子任务；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行动（Action）&lt;/strong&gt;: Agent 对当前的子任务进行执行；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;观察（Observation）&lt;/strong&gt;: Agent 观察当前行动的结果，如果解决问题就返回，如果仅解决当前子任务就继续执行计划，如果没解决当前子任务就重新计划后续步骤；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-977a2e3eac430107f645b43005aac39e088.png&quot; width=&quot;729&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（PlanandSolveAgent 工作示意图）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;ReWOOAgent：包含三个部分：Planner、Worker 和 Solver。其中，Planner 使用可预见推理能力为复杂任务创建解决方案蓝图；Worker 通过工具调用来与环境交互，并将实际证据或观察结果填充到指令中；Solver 处理所有计划和证据以制定原始任务或问题的解决方案。ReWOO 的主要流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;计划（Plan）&lt;/strong&gt;：Agent 在收到 query 后，它会生成一个计划表，计划表中包含了这个任务分解的更小子任务，子任务间的执行结果用占位符表示；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行动（Action）&lt;/strong&gt;: Agent 对每个子任务依次进行执行（调用工具），将结果都填入计划表的占位符中；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;解决（Solve）&lt;/strong&gt;: Agent 观察所有行动的反馈，将结果 response 返回给用户；&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img height=&quot;311&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1cc6042b48653bf967feb883dfb70208fb.png&quot; width=&quot;729&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（ReWOOAgent 工作示意图）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根据实际需求，仅使用机制最简单的 ReactAgent，即可满足两种 Agent 的创建。我们首先实现具备网络搜索及网页浏览的 Searcher Agent，这里 max_retries=20，代表如果 agent 在执行 20 次动作之后还没有完成任务，则自动退出，以避免陷入死循环。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from lazyllm.tools.agent import ReactAgent
# tools 的定义和实现在此忽略，详情在前面
searcher_agent = ReactAgent(llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False), tools=[&quot;web_search&quot;, &quot;visit_url&quot;], max_retries=20, return_trace=True)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;一行代码就可以把 agent 创建出来，是不是很 easy？接下来测试一下效果：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; searcher_agent = ReactAgent(llm=llm, tools=[&quot;web_search&quot;, &quot;visit_url&quot;])
&amp;gt;&amp;gt;&amp;gt; searcher_agent(&quot;what is lazyllm?&quot;)
471166: 2025-03-12 19:58:31 lazyllm INFO: (__main__:9) [tool - Web Search] Searching the web for query &#39;lazyllm&#39;...
471166: 2025-03-12 19:58:40 lazyllm INFO: (__main__:11) [tool - Visit URL] Visiting URL &#39;https://https://www.aibase.com/news/15757&#39;...
&#39;LazyLLM is an open-source, low-code development platform introduced by SenseTime at the 2025 Global Developer Pioneer Conference. It aims to simplify and accelerate the process of building AI applications, allowing developers to create complex and customized multi-agent large model applications with as little as 10 lines of code. This tool lowers the barrier for developing AI applications, making it accessible even to those without extensive coding expertise.\n\nFor more information, you can visit the official announcement [here](https://www.aibase.com/news/15757).&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;效果还可以哈，按照相同的套路，我们把 planner agent 也实现了，其实只是加上一个反问的工具：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;planner_agent = ReactAgent(
        llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
        tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
        max_retries=10,
        return_trace=True
    )&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;经过测试后，我们发现 ReactAgent 实现「反思、搜索、阅读」这一流程很简单，但是让它规划一个大纲却无从下手。&lt;/p&gt; 
&lt;p&gt;查看 ReactAgent 的源代码可以发现，agent 组件中内置了默认的提示词，这个提示词只说明了「要完成任务」，但没有说明具体该给出什么样子的输出。于是我们决定继承 ReactAgent，对其进行改造，使其能够接受我们自己写的提示词！我们创建 class CustomReactAgent：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from typing import List
from lazyllm.tools.agent import ReactAgent
from lazyllm.tools.agent.functionCall import FunctionCall
from lazyllm.module import ModuleBase
from lazyllm import loop
class CustomReactAgent(ReactAgent):
    &quot;&quot;&quot;
    继承自 lazyllm.tools.agent.ReactAgent
    添加自定义提示词、agent 流式输出
    &quot;&quot;&quot;
    #  继承的目的只是为了自定义提示词。。。
    def __init__(self, llm, tools: List[str], custom_prompt: str, max_retries: int = 5, return_trace: bool = False, stream: bool = False):
        # 先调用父类的基础检查和属性设置（如果有必要可以直接调用 ModuleBase.__init__）
        ModuleBase.__init__(self, return_trace=return_trace)
        self._max_retries = max_retries
        assert llm and tools, &quot;llm and tools cannot be empty.&quot;
        # 使用自定义的 prompt 来构造 _agent
        self._agent = loop(
            FunctionCall(llm, tools, _prompt=custom_prompt, return_trace=return_trace, stream=stream),
            stop_condition=lambda x: isinstance(x, str),
            count=self._max_retries
        )&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;使用以上自定义 agent 类，结合我们自己设计的 planner、searcher 提示词，agent 就能按照我们的要求完成意图理解、生成大纲以及信息搜集等定制化的工作啦~&lt;/p&gt; 
&lt;p&gt;接下来让我们复测一下 planner agent 的效果：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; planner_agent = CustomReactAgent(
...     llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
...     tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
...     custom_prompt=TOC_PLAN_INSTRUCTION,
...     max_retries=10,
...     return_trace=True
... )
&amp;gt;&amp;gt;&amp;gt; planner_agent(&quot;写一篇关于 lazyllm 的调研&quot;)
471166: 2025-03-13 10:22:28 lazyllm INFO: (__main__:9) Now I think I need more information from you...
471166: 2025-03-13 10:22:28 lazyllm INFO: (__main__:10) 您好！为了更好地完成这篇关于 LazyLLM 的调研，请您提供以下信息：
1. LazyLLM 是指什么？它是一种技术、一个项目还是一种特定的算法或模型？
2. 是否有具体的背景或者使用场景需要涵盖在报告中？
3. 是否有任何特别关注的方面（例如性能、应用案例、优缺点等）？
4. 报告的目标读者是谁？这将帮助我们调整内容深度和技术术语的使用。

请提供更多细节，以便我们能更准确地满足您的需求。感谢您的配合！
Please provide more information: lazyllm 是一个大模型应用框架；我想主要了解一下他的优缺点和应用场景；目标读者是大模型开发爱好者
471166: 2025-03-13 10:23:28 lazyllm INFO: (__main__:9) [tool - Web Search] Searching the web for query &#39;LazyLLM 大模型应用框架，优缺点，应用场景&#39;...
&#39;Thought: 通过网络搜索，我已经找到了一些关于 LazyLLM 的信息。根据这些信息，LazyLLM 是由商汤科技推出的一个开源、低代码的大模型应用开发框架，它能帮助开发者以低至 10 行左右代码轻松构建复杂、定制化的多 Agent 大模型应用。现在我将基于这些信息生成写作大纲。\n[\n    {\n        &quot;title&quot;: &quot;# LazyLLM 调研报告&quot;,\n        &quot;desc&quot;: &quot;本报告旨在对 LazyLLM 进行深入研究，分析其优缺点，并探讨其应用场景。&quot;,\n        &quot;need_know&quot;: &quot;了解 LazyLLM 的基本概念、背景和目标读者。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## LazyLLM 简介&quot;,\n        &quot;desc&quot;: &quot;介绍 LazyLLM 的定义、特点以及由哪家公司推出的背景。&quot;,\n        &quot;need_know&quot;: &quot;收集有关 LazyLLM 的具体信息，如其功能、使用方法等。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;### LazyLLM 的优势&quot;,\n        &quot;desc&quot;: &quot;详细描述 LazyLLM 相比其他类似工具的优点，例如简化开发过程、降低进入门槛等。&quot;,\n        &quot;need_know&quot;: &quot;找出 LazyLLM 相对于其他工具的独特之处。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;### LazyLLM 的劣势&quot;,\n        &quot;desc&quot;: &quot;指出 LazyLLM 可能存在的不足之处，如适用范围有限或某些特定情况下的性能问题。&quot;,\n        &quot;need_know&quot;: &quot;调查并总结 LazyLLM 在实际应用中遇到的问题。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## 应用场景&quot;,\n        &quot;desc&quot;: &quot;列举 LazyLLM 可以应用于哪些领域，如自然语言处理、计算机视觉等。&quot;,\n        &quot;need_know&quot;: &quot;寻找 LazyLLM 成功案例及其具体应用实例。&quot;\n    },\n    {\n        &quot;title&quot;: &quot;## 总结与展望&quot;,\n        &quot;desc&quot;: &quot;对 LazyLLM 进行全面评价，并对其未来发展提出建议。&quot;,\n        &quot;need_know&quot;: &quot;根据现有资料预测 LazyLLM 的发展趋势。&quot;\n    }\n]&#39;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到，起初 agent 会根据自己的理解，反问用户以获取更多消息，这有助于它进行精确的意图识别。随后 agent 进行了网络搜索，以更好的理解任务主题，随后 agent 结合搜索信息，给出了较为完整的报告大纲，这个大纲既可以指导最后的写作过程，同时其中的「need_know」更是可以引导 searcher_agent 执行更精确的信息搜集。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;u&gt;实现完整的 Deep Research&lt;/u&gt;&lt;/h3&gt; 
&lt;p&gt;有了大模型、工具集以及组装完成的智能体后，接下来到了关键时刻——组装 DeepResearch。了解 lazyllm 的小伙伴们肯定知道，得益于强大而精致的 Flow 组件，在 lazyllm 的世界中，简单几行代码就可以组装得到一个强大的应用。接下来我们就使用 lazyllm 的 flow 组件组装我们自己的 deepresearch，完整的代码如下（其中调用了一些功能函数，详情见附录二）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 创建 deepresearch pipeline
def create_deep_research_pipeline():
    # 单次搜索 pipeline
    with lazyllm.pipeline() as s_ppl:
        s_ppl.gen_query = lambda x: f&quot;{x.get(&#39;desc&#39;)}\n{x.get(&#39;need_know&#39;)}&quot;  # 从部分大纲组装 query
        s_ppl.search_agent = create_search_agent_and_run  # 执行 searcher agent
        s_ppl.gen_output = (lambda x, origin_dict: {**origin_dict, &quot;search_info&quot;: x}) | lazyllm.bind(origin_dict=s_ppl.input)  # 搜集信息嵌入写作大纲
    
    with lazyllm.pipeline() as dr_ppl:
        dr_ppl.planner_ins = StreamResponse(prefix=&quot;[Planner] Receive instruction:&quot;, prefix_color=Color.red, color=Color.magenta, stream=True)  # 显示输入
        dr_ppl.planner = create_plan_agent()    # planner 执行意图识别与大纲规划
        dr_ppl.planner_out = StreamResponse(prefix=&quot;[Planner] ToC Completed:&quot;, prefix_color=Color.red, color=Color.magenta, stream=True)  #  显示 planner agent 输出
        dr_ppl.toc_parser = table_of_content_parser  # 提取写作大纲
        dr_ppl.searcher = lazyllm.warp(lambda x: s_ppl(x)).aslist  # 使用 warp 并行调度 searcher agent 搜集信息
        dr_ppl.search_parser = lambda x: json.dumps(
            [
                {&quot;title&quot;: item.get(&quot;title&quot;),
                 &quot;desc&quot;: item.get(&quot;desc&quot;),
                 &quot;search_info&quot;: item.get(&quot;search_info&quot;)} for item in x
            ], ensure_ascii=False
            )  # 提取大纲中写作所需信息
        dr_ppl.gen_report = OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;).prompt(
            lazyllm.ChatPrompter(instruction=REPORT_INSTRUCTION)
        )  # 最终生成报告
    return dr_ppl&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;注：使用 lazyllm 提供的 StreamResponse 可以让输出内容变得绚丽多彩哦~&lt;/p&gt; 
&lt;p&gt;代码解读：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;使用 lazyllm.pipeline 分别创建 searcher_agent 信息搜集管道和 deepresearch 主流程管道；&lt;/li&gt; 
 &lt;li&gt;主流程管道中，首先将用户 query 输入给 planner_agent，智能体自动执行意图识别与信息搜集，并生成报告大纲；&lt;/li&gt; 
 &lt;li&gt;随后 planner 的输出内容经过 toc_parser 处理，以提取 json 格式的完整大纲；&lt;/li&gt; 
 &lt;li&gt;利用 lazyllm.warp，将大纲列表中各部分以并行的方式输入至信息搜索管道，以提高整个流程的执行效率，同时设置 warp 流程结束后同样以列表的形式输出给下一节点；&lt;/li&gt; 
 &lt;li&gt;在信息搜索 pipeline 中，首先将输入的部分大纲中的有效内容提取，以生成 searcher 所需要的有效指令，随后创建 searcher agent 并执行任务，最后将 searcher agent 的输出作为新的字段（search info）加入到原部分大纲中；&lt;/li&gt; 
 &lt;li&gt;待所有搜索任务完成后，整理并提取有效字段（标题、描述、搜索信息）形成最终的写作大纲，并指导大模型最终生成专业的长篇报告。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;数据流示意图：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;477&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b515a2614f206ee56db8e97cb3e700859b.png&quot; width=&quot;1918&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;最后是运行 deep research 的入口代码，其中 lazyllm.FileSystemQueue().dequeue() 用于获取过程中的输出内容：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import asyncio
from dotenv import load_dotenv

load_dotenv()

import lazyllm
from core.flow.deep_research import create_deep_research_pipeline


async def main():
    deep_research_ppl = create_deep_research_pipeline()
    question = input(&quot;Lazy Deep Research Demo...\nPlease enter your question：\n&quot;)
    all_process = &quot;&quot;
    lazyllm.globals._init_sid()
    with lazyllm.ThreadPoolExecutor(1) as executor:
        future = executor.submit(deep_research_ppl, question)
        while True:
            if value := lazyllm.FileSystemQueue().dequeue():
                print(&quot;&quot;.join(value))
                all_process += &quot;&quot;.join(value)
            elif future.done():
                break
            else:
                await asyncio.sleep(0.3)
        log_filename = f&quot;{question}_all_process.log&quot;
        with open(log_filename, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:
            f.write(all_process)
        print(f&quot;结果已保存至 {log_filename}&quot;)

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;完成以上研发，一个崭新的，基于 lazyllm 的 deepresearch 复现便新鲜出炉了！虽然工具集还有很大的进步空间，但已经能够实现简单的搜索、访问页面和收集信息了。下面让我们来测试一下基于 lazyllm 的 deepresearch 的完整效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;效果展示&lt;/h2&gt; 
&lt;p&gt;我们询问「如何熟练掌握 lazyllm」，详细输出如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m core.main
Lazy Deep Research Demo...
Please enter your question：
如何熟练掌握 lazyllm
714495: 2025-03-13 12:55:07 lazyllm INFO: (core.tools.plan_tools:13) Now I think I need more information from you...
714495: 2025-03-13 12:55:07 lazyllm INFO: (core.tools.plan_tools:14) 为了帮助您更好地了解如何熟练掌握 lazyllm，我需要一些额外的信息：
- 您提到的 lazyllm 具体是指什么？它是一种技术、工具、库还是其他东西？
- 您是希望从零开始学习 lazyllm，还是已经有一定的基础并希望进一步深入？
- 您希望通过掌握 lazyllm 达到什么样的目标或解决什么问题？
Please provide more information: lazyllm 是一个大模型应用框架；希望能够掌握落地应用方法
714495: 2025-03-13 12:55:18 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;lazyllm 大模型应用框架&#39;...
714495: 2025-03-13 12:55:25 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:55:32 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:25 lazyllm INFO: (core.tools.utils:29) 报告写作大纲生成成功：
[{&#39;title&#39;: &#39;# 如何熟练掌握 LazyLLM&#39;, &#39;desc&#39;: &#39;本报告将详细介绍如何熟练掌握 LazyLLM，包括其基本概念、使用方法和应用场景等内容。&#39;, &#39;need_know&#39;: &#39;了解用户对 LazyLLM 的需求和期望，以便更好地指导他们学习和使用。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 简介&#39;, &#39;desc&#39;: &#39;介绍 LazyLLM 的基本情况，如其定义、特点和发展历程等。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的具体定义、特点和发展历程。&#39;}, {&#39;title&#39;: &#39;### LazyLLM 的功能与优势&#39;, &#39;desc&#39;: &#39;详细描述 LazyLLM 的功能和优势，如低代码、快速部署和支持多种数据流抽象等。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的所有功能及其具体实现方式；与其他类似工具相比的优势。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的安装与配置&#39;, &#39;desc&#39;: &#39;讲解如何安装和配置 LazyLLM，确保用户能够在自己的环境中顺利运行该框架。&#39;, &#39;need_know&#39;: &#39;LazyLLM 的安装步骤和配置要求；可能遇到的问题及解决方案。&#39;}, {&#39;title&#39;: &#39;### 环境准备&#39;, &#39;desc&#39;: &#39;列出安装 LazyLLM 前需要准备的工作，如环境搭建、依赖项安装等。&#39;, &#39;need_know&#39;: &#39;安装 LazyLLM 所需的系统环境和其他依赖项。&#39;}, {&#39;title&#39;: &#39;### 安装过程&#39;, &#39;desc&#39;: &#39;提供详细的安装步骤，让用户可以按照指示完成安装。&#39;, &#39;need_know&#39;: &#39;具体的安装命令和操作流程；可能出现的错误提示及解决办法。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的应用场景&#39;, &#39;desc&#39;: &#39;探讨 LazyLLM 在实际项目中的应用场景，帮助用户理解其适用范围。&#39;, &#39;need_know&#39;: &#39;LazyLLM 已有的成功案例；不同领域的潜在应用场景。&#39;}, {&#39;title&#39;: &#39;### 成功案例分析&#39;, &#39;desc&#39;: &#39;选取几个典型的成功案例进行分析，展示 LazyLLM 的实际效果。&#39;, &#39;need_know&#39;: &#39;具体的成功案例及其实施过程；这些案例带来的收益或改进。&#39;}, {&#39;title&#39;: &#39;### 潜在应用场景&#39;, &#39;desc&#39;: &#39;预测 LazyLLM 在未来可能的应用领域，激发用户的创造力。&#39;, &#39;need_know&#39;: &#39;当前市场上对于此类工具的需求趋势；未被发掘但具有潜力的应用方向。&#39;}, {&#39;title&#39;: &#39;## LazyLLM 的最佳实践&#39;, &#39;desc&#39;: &#39;分享一些使用 LazyLLM 时的最佳实践，提高用户的开发效率。&#39;, &#39;need_know&#39;: &#39;使用 LazyLLM 时的经验总结；常见的误区和避免方法。&#39;}, {&#39;title&#39;: &#39;### 开发技巧&#39;, &#39;desc&#39;: &#39;介绍一些有助于提高开发效率的小技巧，如代码优化、调试技巧等。&#39;, &#39;need_know&#39;: &#39;使用 LazyLLM 编写高效代码的方法；常见问题的排查技巧。&#39;}, {&#39;title&#39;: &#39;### 性能调优&#39;, &#39;desc&#39;: &#39;讲解如何对基于 LazyLLM 的应用程序进行性能调优，以获得更好的运行效果。&#39;, &#39;need_know&#39;: &#39;影响应用程序性能的因素；具体的调优策略和技术手段。&#39;}, {&#39;title&#39;: &#39;# 总结与展望&#39;, &#39;desc&#39;: &#39;对全文进行总结，并对未来的发展趋势做出预测。&#39;, &#39;need_know&#39;: &#39;回顾本文的重点内容；根据现有技术和市场需求预测 LazyLLM 未来的发展方向。&#39;}]
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 定义，特点，发展历程&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，实施过程，收益，改进&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;什么是 LazyLLM 功能&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 功能，优势&#39;...
714495: 2025-03-13 12:56:29 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;如何安装和配置 LazyLLM 框架&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM best practices, common pitfalls and avoidance methods&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;安装 LazyLLM 前需要准备的工作，环境搭建，依赖项安装&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;提高开发效率的小技巧，代码优化，调试技巧，使用 LazyLLM 编写高效代码的方法，常见问题的排查技巧&#39;...
714495: 2025-03-13 12:56:30 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 基本概念，使用方法，应用场景&#39;...
714495: 2025-03-13 12:56:31 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM performance optimization strategies and techniques&#39;...
714495: 2025-03-13 12:56:31 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 应用领域，创造力，需求趋势，未被发掘，潜力&#39;...
714495: 2025-03-13 12:56:33 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:35 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，应用场景&#39;...
714495: 2025-03-13 12:56:37 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;大模型应用开发框架，需求趋势，未来，应用方向&#39;...
714495: 2025-03-13 12:56:38 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 功能，实现方式&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:39 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.qbitai.com/2025/02/257657.html&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:42 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:44 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:44 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/sensetime/LazyLLM&#39;...
714495: 2025-03-13 12:56:49 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:56:50 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/LazyAGI/LazyLLM&#39;...
714495: 2025-03-13 12:56:50 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;代码优化，调试技巧，常见问题排查技巧&#39;...
714495: 2025-03-13 12:57:01 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;提高开发效率的技巧，代码优化，调试技巧，常见问题排查技巧&#39;...
714495: 2025-03-13 12:57:02 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;LazyLLM 成功案例，实施过程，收益，改进，应用场景&#39;...
714495: 2025-03-13 12:57:07 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stcn.com/article/detail/1535042.html&#39;...
714495: 2025-03-13 12:57:12 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;http://news.pconline.com.cn/1888/18880280.html&#39;...
714495: 2025-03-13 12:57:19 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;软件开发，提高效率的小技巧，代码优化，调试技巧，常见问题排查技巧&#39;...
714495: 2025-03-13 12:57:31 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stdaily.com/web/gdxw/2025-02/24/content_300493.html&#39;...
714495: 2025-03-13 12:57:44 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;软件开发效率提升方法，代码优化，调试技巧，常见问题排查技巧&#39;...
714495: 2025-03-13 12:58:01 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.jfdaily.com/news/detail?id=861805&#39;...
714495: 2025-03-13 12:58:08 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://finance.sina.com.cn/roll/2025-02-24/doc-inemqprn0854836.shtml&#39;...
714495: 2025-03-13 12:58:18 lazyllm INFO: (core.tools.web_tools:21) [tool - Web Search] Searching the web for query &#39;软件开发，提高效率的方法，代码优化，调试技巧，常见问题排查技巧&#39;...
714495: 2025-03-13 12:58:18 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://github.com/LazyAGI/LazyLLM&#39;...
714495: 2025-03-13 12:58:31 lazyllm INFO: (core.tools.web_tools:46) [tool - Visit URL] Visiting URL &#39;https://www.stdaily.com/web/gdxw/2025-02/24/content_300493.html&#39;...
结果： # 如何熟练掌握 LazyLLM

## LazyLLM 简介

LazyLLM 是由商汤科技在 2025 全球开发者先锋大会上推出的一个开源、低代码的大模型应用开发框架。其设计目标是让开发者能够以低至 10 行左右的代码构建复杂、定制化的多 Agent 大模型应用。此外，LazyLLM 已经在 GitHub 上开源，开发者可以访问该项目的官方页面进行学习和使用。

### LazyLLM 的功能与优势

LazyLLM 是一个功能强大且易于使用的工具，具有以下主要特点和优势：

- **低代码开发**：LazyLLM 允许开发者使用大约 10 行代码构建复杂且定制化的多 Agent 大模型应用。这意味着即使是没有深厚编程背景的人也可以轻松上手。
  
- **快速部署**：通过利用轻量网关，LazyLLM 实现了复杂应用的一键部署，大大缩短了从开发到上线的时间周期。
  
- **支持多种数据流抽象**：LazyLLM 以数据为核心，支持在应用开发过程中持续迭代数据，从而不断提升数据效果。这一特性使得开发者能够更容易地处理和优化不同类型的数据流。

与其他类似工具相比，LazyLLM 的优势在于其极简主义的设计理念，即用最少的代码实现最强大的功能，同时保持高度的灵活性和可扩展性。此外，作为一个开源项目，LazyLLM 还拥有活跃的社区支持，有助于加速创新和技术进步。

## LazyLLM 的安装与配置

为了确保用户能够在自己的环境中顺利运行 LazyLLM 框架，以下是详细的安装步骤和配置要求：

### 环境准备

1. **环境搭建**：
   - LazyLLM 支持跨平台兼容，可以在裸金属服务器、开发机、Slurm 集群、公共云等平台上运行。因此，在安装之前，请确保你已经选择并配置好了相应的计算平台。

2. **依赖项安装**：
   - 如果你是从源代码安装 LazyLLM，你需要先克隆仓库并进入项目目录：
     ```bash
     git clone git@github.com:LazyAGI/LazyLLM.git
     cd LazyLLM
     ```
     然后根据需求安装依赖项。如果你只需要安装 LazyLLM 及其必要依赖，可以使用以下命令：
     ```bash
     pip install -r requirements.txt
     ```
     如果你还想进行微调、部署或构建 RAG 应用，则还需要安装额外的依赖项：
     ```bash
     pip install -r requirements.full.txt
     ```

   - 如果你是通过 pip 安装 LazyLLM，你可以选择只安装 LazyLLM 及其必要依赖：
     ```bash
     pip3 install lazyllm
     ```
     或者安装 LazyLLM 以及所有依赖项：
     ```bash
     pip3 install lazyllm[lazyllm install full]
     ```

3. **配置 API 密钥（如需）**：
   - 对于某些功能（例如与在线服务交互），可能需要设置环境变量或配置文件来提供必要的 API 密钥。例如，对于 ChatBots 示例中提到的 OpenAI API Key，可以通过设置环境变量`LAZYLLM_OPENAI_API_KEY=xx`或在配置文件`~/.lazyllm/config.json`中添加`openai_api_key=xx`来实现。

4. **准备数据集（如需）**：
   - 如果你要使用 LazyLLM 构建基于检索增强生成的应用程序（如 RAG），则需要准备好相应的数据集，并确保数据路径正确无误。例如，在本地部署示例中，你需要指定数据集路径为`/file/to/yourpath`。

5. **了解基本概念和组件**：
   - 在开始构建应用程序之前，建议先熟悉 LazyLLM 的基本概念，包括组件 (Component)、模块 (Module)、流程 (Flow) 等，以便更好地利用其提供的工具和接口。

### 安装过程

1. **环境准备**：首先，你需要确保你的计算机已经安装了 Python，并且最好是在一个虚拟环境中工作以避免与其他项目产生冲突。你可以使用如`venv`或`conda`等工具创建一个独立的 Python 环境。
   
2. **安装依赖库**：根据 LazyLLM 的具体需求，你可能需要安装一些额外的 Python 包。这通常可以通过 pip 命令完成，例如`pip install -r requirements.txt`，其中`requirements.txt`文件列出了所有必要的依赖项。

3. **下载并安装 LazyLLM**：访问[LazyLLM 的 GitHub 页面](https://github.com/sensei-research/LazyLLM) 获取最新的源代码或直接通过 pip 安装最新版本（如果已发布）。

4. **配置环境变量**：某些情况下，你可能还需要设置特定的环境变量，以便 LazyLLM 能够正确连接到外部服务或者存储系统。

5. **初始化项目结构**：按照官方文档中的指导，创建一个新的项目目录，并初始化基本的项目结构。这一步骤可能会涉及到复制模板文件夹、修改配置文件等操作。

6. **编写业务逻辑代码**：利用 LazyLLM 提供的 API 接口快速实现核心功能。由于这是一个低代码平台，大部分工作都可以通过简单的函数调用来完成。

7. **测试与调试**：完成初步编码后，应该进行全面的单元测试和集成测试，确保一切按预期工作。同时也可以借助 IDE 中的调试工具排查可能出现的问题。

8. **部署上线**：最后一步就是将开发好的应用部署到生产环境。得益于 LazyLLM 内置的一键部署特性，这一步相对来说比较简单快捷。

关于可能遇到的问题及解决方案：
- 如果在安装过程中遇到问题，请检查 Python 版本是否符合要求，并确认所有的依赖项都已经正确安装。
- 对于网络连接失败的情况，可以尝试更换镜像源或是离线安装所需的软件包。
- 如果发现性能瓶颈，考虑优化算法或增加硬件资源。
- 当遇到特定功能无法正常工作时，查阅官方文档和技术支持论坛，很多时候其他用户也会遇到类似的问题，官方社区往往能提供有效的帮助。

## LazyLLM 的应用场景

尽管没有找到具体的 LazyLLM 成功案例，但我们可以根据其特点推测其在不同领域的潜在应用场景：

1. **教育**：LazyLLM 可以帮助教育机构和教师快速开发个性化学习助手，为学生提供定制化学习路径和实时答疑服务。
2. **医疗**：在医疗领域，LazyLLM 可以用于开发智能诊断助手，帮助医生分析病历、诊断疾病并提供治疗建议。
3. **金融**：LazyLLM 可以助力金融机构开发智能客服系统，为客户提供 24/7 全天候服务，解答常见问题并处理简单业务。
4. **零售**：通过 LazyLLM，零售商可以创建智能推荐系统，根据用户的历史购买记录和浏览行为推荐相关产品。
5. **游戏**：游戏开发者可以利用 LazyLLM 创建更智能的 NPC（非玩家角色），提高游戏的互动性和趣味性。

以上只是一些可能的应用场景，实际上 LazyLLM 可以在任何需要大模型能力的领域发挥作用。由于其低代码特性，即使不具备熟练编码能力的人也能完成 AI 应用开发，这大大降低了大模型应用开发的门槛。

### 成功案例分析

#### 案例一：智能客服系统的快速开发
- **实施过程**：某企业利用 LazyLLM 快速开发了一款智能客服系统，将原本需要数周时间完成的工作缩短至几天内完成。
- **收益或改进**：这不仅加快了开发速度，还降低了开发成本，使得企业能够更迅速地响应市场需求。

#### 案例二：医疗数据的自动化分析
- **实施过程**：一家医疗科技公司通过 LazyLLM 实现了病历数据的自动化分析和处理。
- **收益或改进**：大幅提升了工作效率并减少了人工干预，使医生和护士能够专注于更重要的临床工作。

### 总结
LazyLLM 极大地简化了 AI 应用的开发流程，使得不具备熟练编码能力的人也能完成复杂的 AI 应用开发。它支持多种数据流操作（如 Pipeline、Parallel、Switch 等），从而提升了开发效率并减少了代码量。对于企业来说，这意味着更快的产品迭代速度以及更低的研发成本。

### 潜在应用场景

未来可能的应用领域包括教育、医疗、农业和环保等领域，激发用户的创造力。当前市场上对于此类工具的需求趋势主要体现在低代码化、开源化和数据为核心等方面。

未被发掘但具有潜力的应用方向可能包括：
1. **教育领域**：为学生和教师提供个性化的学习和教学助手。
2. **医疗领域**：帮助医生和研究人员分析病历、诊断疾病和发现新药。
3. **农业领域**：优化农作物种植、预测天气和提高产量。
4. **环保领域**：监测环境变化、评估污染影响和制定可持续发展策略。

## LazyLLM 的最佳实践

分享一些使用 LazyLLM 时的最佳实践，提高用户的开发效率：

- **简化编码**：LazyLLM 旨在通过减少所需的代码量来加速开发过程。这意味着您可以专注于设计应用程序的功能，而不是花费大量时间编写底层代码。
- **数据为核心**：LazyLLM 支持在应用开发过程中持续迭代数据，从而不断提升数据效果。因此，在开发初期就应该重视数据集的设计与准备。
- **利用现有组件**：LazyLLM 提供了 Pipeline, Parallel, Switch, If, Loop, Diverter, Warp, Graph 等组件，可以直接使用或组合这些组件快速搭建应用程序逻辑，无需从零开始创建所有功能。
- **一键部署**：该框架允许开发者轻松地将他们的应用程序部署到云端或其他环境中，这大大简化了发布流程。
- **社区支持**：由于 LazyLLM 已经在 GitHub 上开源，您可以在[GitHub](https://github.com/LazyAGI/LazyLLM) 和 [官方文档](docs.lazyllm.ai) 中找到丰富的资源和支持，包括教程、案例研究和其他开发者的贡献。

至于常见的误区和避免方法：
- **过度依赖默认设置**：虽然 LazyLLM 提供了一些预设配置，但为了获得最佳性能，建议根据具体需求调整参数。
- **忽视版本更新**：随着技术的进步，框架会不断改进和完善。确保定期检查是否有新的版本发布，并及时升级以享受最新的特性和修复。
- **缺乏测试**：尽管 LazyLLM 简化了开发步骤，但仍需对生成的应用程序进行全面测试，特别是对于涉及多个代理（Agents）协作的任务，确保它们能够按照预期工作。
- **忽略安全性**：即使是在简化环境下开发，也不应放松对安全性的要求。遵循最佳的安全实践，比如保护 API 密钥和个人敏感信息。

### 开发技巧

介绍一些有助于提高开发效率的小技巧，如代码优化、调试技巧等。

#### 使用 LazyLLM 编写高效代码的方法

1. **低代码开发**：LazyLLM 是一个开源、低代码的大模型应用开发框架。开发者只需编写少量代码（如 10 行左右），即可构建复杂的多 Agent 大模型应用。这使得不具备熟练编码能力的人也能完成 AI 应用开发。
2. **快速部署**：LazyLLM 利用轻量网关实现了复杂应用的一键部署，使开发者能够更快地实现想法产品落地。
3. **数据迭代支持**：该框架专注于数据为核心，支持在应用开发过程中持续迭代数据，从而不断提升数据效果。

#### 提高开发效率的小技巧

##### 代码优化
- **减少冗余代码**：避免重复代码，尽量复用已有的函数或模块，保持代码简洁。
- **性能优化**：使用高效的算法和数据结构，减少不必要的计算，优化内存使用。
- **自动化测试**：编写单元测试和集成测试，确保代码质量的同时加快开发进度。

##### 调试技巧
- **日志记录**：合理设置日志级别，记录关键操作和异常信息，便于后续排查问题。
- **断点调试**：使用 IDE 中的断点调试功能，逐步执行代码，检查变量值和程序逻辑。
- **版本控制**：使用 Git 等版本控制系统管理代码变更，方便回滚和协作开发。

##### 常见问题排查技巧
- **错误堆栈分析**：当遇到异常时，仔细阅读错误堆栈信息，定位具体出错位置。
- **环境配置检查**：确保开发环境与生产环境一致，避免因环境差异导致的问题。
- **社区资源利用**：积极查阅官方文档、论坛和 GitHub Issues，寻找类似问题的解决方案。

### 性能调优

讲解如何对基于 LazyLLM 的应用程序进行性能调优，以获得更好的运行效果。

1. **快速原型设计与迭代优化**：LazyLLM 强调「快速原型设计，使用特定场景的数据分析不良案例，算法实验以及在关键方面微调模型以提高整体应用性能。」这意味着开发者应该尽快建立一个初始版本的应用，并根据实际使用中的反馈不断改进和优化。
2. **自动超参数搜索**：LazyLLM 支持网格搜索参数优化功能，可以自动尝试不同的基础模型、检索策略和微调参数来评估和优化应用程序。这使得超参数调整变得高效，而无需对应用代码进行大量侵入性修改，帮助用户快速找到最佳配置。
3. **高效的模型微调**：LazyLLM 允许在应用内微调模型，以持续改进应用性能。它能够根据微调场景自动选择最适合的微调框架和模型分割策略。这不仅简化了模型迭代维护工作，还让算法研究人员可以更多地专注于算法和数据迭代，而不是处理繁琐的工程任务。
4. **一键部署复杂应用**：LazyLLM 提供了一键式部署所有模块的能力，在 POC（概念验证）阶段通过轻量级网关机制简化多代理应用的部署过程。这样解决了依次启动每个子模块服务（如 LLM、Embedding 等）并配置 URL 的问题，使整个过程更加顺畅高效。此外，在应用发布阶段，LazyLLM 还提供了一键打包镜像的功能，便于利用 Kubernetes 的网关、负载均衡及容错能力。
5. **跨平台兼容性**：LazyLLM 可以在不修改代码的情况下一键切换 IaaS 平台，兼容裸金属服务器、开发机、Slurm 集群、公有云等多种环境。这允许已开发的应用程序无缝迁移到其他 IaaS 平台，大大减少了代码修改的工作量。
6. **支持常见的 RAG 组件**：LazyLLM 集成了文档、解析器、检索器、重排序器等常见 RAG（检索增强生成）组件。这些组件可以帮助构建更强大的 AI 应用，尤其是在需要从大量文本中提取有用信息时非常有用。

综上所述，通过上述方法，我们可以针对基于 LazyLLM 的应用程序进行有效的性能调优，从而提升其运行效果。

## 总结与展望

LazyLLM 是由商汤科技在 2025 全球开发者先锋大会上发布的一个开源、低代码的大模型应用开发框架。它能让开发者以低至 10 行左右的代码构建复杂、定制化的多 Agent 大模型应用，从而降低 AI 应用开发的门槛，使不具备熟练编码能力的人也能完成 AI 应用开发。此外，LazyLLM 还利用轻量网关实现了复杂应用的一键部署，使开发者能够更快地将应用推向市场。

随着人工智能技术的不断发展和市场需求的增长，预计 LazyLLM 未来将在以下几个方面取得进展：

1. **更加简便易用**：为了吸引更多的开发者使用 LazyLLM 进行 AI 应用开发，商汤科技可能会继续优化该框架，使其更加简便易用，进一步降低开发门槛。
2. **提升性能与稳定性**：随着更多开发者使用 LazyLLM，商汤科技可能会收集用户反馈，不断改进框架的性能与稳定性，确保用户能够顺利地构建高质量的 AI 应用。
3. **拓展应用场景**：目前，LazyLLM 主要用于构建多 Agent 大模型应用。然而，随着技术的发展和市场需求的变化，LazyLLM 可能会被应用于更多的场景，如自然语言处理、计算机视觉等。
4. **社区建设**：作为一个开源项目，LazyLLM 有望吸引更多的开发者加入其社区，共同为项目的完善和发展做出贡献。这将有助于推动 LazyLLM 成为更受欢迎的 AI 应用开发框架。&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们可以看到，通过使用 lazyllm 快速复现的 deepresearch，已经具备了通过自身思考并主动使用工具，经过若干分钟的」工作「给出专业长篇报告的能力。至此，基于 lazyllm 的快速复习宣告成功~&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;总结与展望&lt;/h2&gt; 
&lt;p&gt;仔细盘点一下，这次复现的耗时只有大概半天，工程代码量只在一百多行（如果只关注 deep research 的主流程，排除一些通用工具编写的话，甚至只有不到 15 行嘿嘿嘿~~~），效率这块儿属实是被 lazyllm 拿捏了~&lt;/p&gt; 
&lt;p&gt;但这仅仅是较为简单版本的 deep research，一个」满血版「的 Deep Research 还需要具备解析文件、调用本地知识库、精细化操作网络页面等等的能力，与先前开发工具的思路相同，这些也都需要我们通过工具研发提供给智能体，以丰富智能体的」武器库「。&lt;/p&gt; 
&lt;p&gt;大模型应用正在飞速迭代，这必然给大家带来了一定恐慌，在这个时代，能够有效拆解并快速复现这些应用的能力越来越重要。而使用 lazyllm，我们能够在短时间内快速复现一个如此强大的应用，对于广大大模型爱好者来说是一件非常激动人心的事情！你是否也有些手痒痒了呢？心动不如行动，赶紧动起来吧~我也要去开发更多的强力工具，赋能专属于自己的 deep research 咯~&lt;/p&gt; 
&lt;p&gt;友情提示：agent 工作是一个相当消耗 token 的过程，如果你和我一样使用了第三方的 llm api-key，调试和使用期间要盯紧自己的钱包哦~&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;附录一，提示词设计&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# planner agent prompt
TOC_PLAN_INSTRUCTION = &quot;&quot;&quot;# 定位
- 你是一个全面的写作专家，擅长根据给定的主题主动收集资料，并给出高质量的、具有完整报告结构的写作大纲。
- 主要任务：用户给定了写作主题，请针对给定主题，使用工具集主动收集信息、分析用户意图，最后结合有效信息生成专业报告写作大纲。
- 写作大纲用于指导后续调研工作和报告写作工作。

# 工具
- 为了帮助你高质量完成给定的任务，我们为你提供了一些有用的工具。请充分使用这些工具来获取所需的信息。
- 注意：在任务开始阶段，一定要使用&#39;get_more_info_from_user&#39;工具邀请用户提供更多信息。
- 如果写作主题很复杂，你可以将其拆分为若干 sub_topic，并通过调用最合适的工具了解它们。
- 请主动使用&#39;visit_url&#39;工具浏览相关网页，浏览相关网页可以帮你获取更多有效信息。

# 输出格式
- 请使用和用户输入相同的语言执行任务。
- 你的任务分为两个阶段：信息收集阶段、生成大纲阶段。
- 在信息收集阶段，请严格遵循「Thought: 思考内容」的格式：
Thought: 思考当前任务所处于的状态，规划接下来需要做什么。
- 每次输出时，在开头输出且仅输出一次 Thought，无论你是否决定使用工具。
- 如果你认为你获取的信息不足以很好的生成大纲，请始终遵循「Thought」的格式，直到获取到足够的信息后，再生成大纲。
- 当你认为你已经收集到足够的信息，请严格遵循 JSON 格式生成写作大纲。生成大纲阶段，不要输出「Thought」。
- 大纲的每一部分应包含「title」、「desc」、「need_know」两部分：
title: 当前部分的标题，标题最多达到三级标题。
desc: 描述当前部分希望呈现的内容，需要始终紧扣原主题和当前主题。
need_know: 用于指导员工调研相关内容，以便更好的完成该部分写作，需要始终紧扣原主题和当前主题。
大纲应按照「总-分-总」的逻辑结构生成，首先是概述部分，随后将写作主题拆解成若干部分，最后给出总结与展望。
请生成符合以下格式的 JSON 列表：
[
    {
        &quot;title&quot;: &quot;# 一级标题（报告总标题）&quot;,
        &quot;desc&quot;: &quot;一级标题的描述&quot;,
        &quot;need_know&quot;: &quot;完成该部分需要了解的内容。&quot;
    },
    {
        &quot;title&quot;: &quot;## 二级标题&quot;,
        &quot;desc&quot;: &quot;二级标题的描述&quot;,
        &quot;need_know&quot;: &quot;完成该部分需要了解的内容。&quot;
    },
    {
        &quot;title&quot;: &quot;### 三级标题&quot;,
        &quot;desc&quot;: &quot;三级标题的描述&quot;,
        &quot;need_know&quot;: &quot;完成该部分需要了解的内容。&quot;
    },
    ...
]

# 当前对话
以下是当前用户和智能助手的对话内容。
Think step by step.
请务必好好完成本次工作！&quot;&quot;&quot;


# searcher agent prompt
WEB_SEARCH_INSTRUCTION = f&quot;&quot;&quot;# 定位
- 你是一个互联网打工人，擅长根据给定的主题搜索资料、总结信息并给出高质量的汇报。
- 主要任务：今天是{get_today_date()}，你的老板给你发布了任务，请针对给定的问题，使用工具集中的工具搜索相关信息，最后结合搜索结果给出全面的回答。

# 工具
- 为了帮助你高质量完成给定的任务，我们为你提供了一些有用的工具。请充分使用这些工具来获取所需的信息。
- 如果问题很复杂，你可以将问题拆分为若干子问题，并通过调用最合适的工具解决它们。
- 如果你觉得本次搜索结果不复合需求，尝试换个角度再次搜索。
- 请主动使用&#39;visit_url&#39;工具浏览相关网页，浏览相关网页可以帮你获取更多有效信息。
- 如果网站 url 是文件链接，请不要访问，直接无视。

# 输出格式
- 请使用和问题相同的语言回答问题，在任务开始阶段，请严格遵循「Thought」的格式：
Thought: 思考当前任务所处于的状态，规划接下来需要做什么。
- 每次输出时，在开头输出且仅输出一次 Thought，无论你是否决定使用工具。
- 如果你认为你获取的信息不足以很好的回答问题，请始终遵循「Thought」的格式，知道获取到足够的信息后，再回答问题。
- 当你认为你已经收集到足够的信息，请严格遵循「Answer」的格式回答问题，在回答中如果引用了搜索结果，请将相关链接以 markdown 的形式直接插入到正文当中，具体格式为「[网页标题](网页 url)」。
Answer: 使用相同语言完整地回答问题。

# 当前对话
以下是当前用户和智能助手的对话内容。
Think step by step.
你的老板很器重你，请务必好好完成本次工作！&quot;&quot;&quot;


# generate report prompt
REPORT_INSTRUCTION = &quot;&quot;&quot;# 定位
- 你是一个写作专家，擅长根据给定的写作大纲写出高质量的报告。
- 主要任务：根据写作大纲，结合标题、描述以及调研结果为用户书写专业的报告。

# 要求
- 请确保报告结构严谨、用词专业、表达通顺，报告内容请尽可能参考调研结果，不要使用你的先验知识。
- 如果你觉得提供的标题不够专业，可以进行润色。
- 报告中的每一部分字数控制在 400~800 字，不要太少。
- 请严格按照大纲结构完成写作，写作大纲是 JSON 格式的，其中包含三个字段：
title: 该部分主题
desc: 描述该部分想要表达的内容
search_info: 与该部分相关的调研结果

# 输出格式
- 请使用和用户输入相同的语言执行任务，直接生成 Markdown 格式的报告全文。

# 写作大纲&quot;&quot;&quot;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;附录二，功能函数&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 获取今天的日期
def get_today_date():
    &quot;&quot;&quot;
    获取今天的日期
    Returns:
        str: 当前日期，格式为&quot;YYYY-MM-DD&quot;
    &quot;&quot;&quot;
    today = datetime.date.today()
    return today.strftime(&quot;%Y-%m-%d&quot;)

# 提取 planner agent 生成的写作大纲
def table_of_content_parser(text: str) -&amp;gt; list:
    try:
        # 找到第一个 &#39;[&#39; 和最后一个 &#39;]&#39; 的索引
        start_index = text.find(&#39;[&#39;)
        end_index = text.rfind(&#39;]&#39;)
        if start_index == -1 or end_index == -1:
            # 没有找到有效的 JSON 结构，返回空列表
            return []
        json_str = text[start_index:end_index+1]
        # 尝试解析 JSON
        data = json.loads(json_str)
        LOG.info(f&quot;报告写作大纲生成成功：\n{data}&quot;)
        return data
    except Exception as e:
        # 如果解析出错，输出错误信息并返回空列表
        print(&quot;解析 JSON 出错:&quot;, e)
        raise e

#  创建 planner agent
def create_plan_agent() -&amp;gt; CustomReactAgent:
    agent = CustomReactAgent(
        llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
        tools=[&quot;get_more_info_from_user&quot;, &quot;web_search&quot;, &quot;visit_url&quot;],
        custom_prompt=TOC_PLAN_INSTRUCTION,
        max_retries=10,
        return_trace=True,
        stream=True
    )
    return agent

# 创建 searcher agent 并搜集信息
def create_search_agent_and_run(query: str) -&amp;gt; str:
    try:
        with lazyllm.pipeline() as ppl:
            ppl.receive = StreamResponse(&#39;[Searcher] Received query:&#39;, prefix_color=Color.red,
                                         color=Color.magenta, stream=True)
            ppl.run_search = CustomReactAgent(
                llm=OnlineChatModule(source=&quot;qwen&quot;, model=&quot;qwen-plus&quot;, stream=False),
                tools=[&quot;web_search&quot;, &quot;visit_url&quot;],
                custom_prompt=WEB_SEARCH_INSTRUCTION,
                max_retries=20,
                return_trace=True,
                stream=True
            )
            ppl.search_result = StreamResponse(&#39;[Searcher] Search result:&#39;, prefix_color=Color.red,
                                         color=Color.magenta, stream=True)
        return ppl(query)
    except Exception as e:
        LOG.error(f&quot;[Search agent] Error occurred: {e}&quot;)
        return &quot;搜索中断，未找到相关信息&quot;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;参考资料&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;OpenAI（2025）- deep-research-system-card&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D2mSNIX-l_Zc&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/watch?v=2mSNIX-l_Zc&lt;/a&gt; - Open Deep Research from LangChain&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F23746178273&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/23746178273&lt;/a&gt; - [知乎] OpenAI Deep Research 是什么？如何使用？你想知道的都在这儿！&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.lazyllm.ai%2Fzh-cn%2Flatest%2F&quot; target=&quot;_blank&quot;&gt;https://docs.lazyllm.ai/zh-cn/latest/&lt;/a&gt; - LazyLLM 官方文档&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;如有疑问，请移步「LazyLLM」gzh~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/8690838/blog/17938821</link>
            <guid isPermaLink="false">https://my.oschina.net/u/8690838/blog/17938821</guid>
            <pubDate>Wed, 19 Mar 2025 01:53:31 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>拼多多上线用户和商家视频通话功能</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbjXsabyYPkkNl12e9XFk6g&quot; target=&quot;_blank&quot;&gt;据电商派 Pro 昨日报道&lt;/a&gt;，拼多多面向用户和商家上线了视频通话功能，方便进行产品使用讲解。商家只需登录商家后台，在多多客服功能中找到客服工具，即可开通语音通话服务。&lt;/p&gt; 
&lt;p&gt;商家需选择语音通话账号，设置可视频接待的账号，点击下一步后，再选择是否在 23:00 至次日 8:00 期间接听，最后点击确认即可完成设置。&lt;/p&gt; 
&lt;p&gt;开通该功能后，商家在与消费者的聊天界面中可以向消费者发送「视频讲解邀请」卡片。消费者点击进入后，商家侧即会弹起视频通话界面。&lt;/p&gt; 
&lt;p&gt;值得注意的是，视频接通后，消费者摄像头默认关闭，需消费者手动开启，且开启后默认使用后置摄像头。&lt;/p&gt; 
&lt;p&gt;此外，平台方面还建议商家在配置语音通话账号后，尽量不要关闭商家 App，保持其前台运行状态。若商家连续两天接听率较低，系统会暂停通话功能 3 天，之后需商家重新开启。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339647</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339647</guid>
            <pubDate>Wed, 05 Mar 2025 11:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>使用 DeepSeek 拯救数据中台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;在数字化转型浪潮中，数据中台作为企业核心资产的&quot;枢纽站&quot;，却长期面临&quot;建而难用&quot;的尴尬境地——业务团队抱怨数据获取门槛高、技术团队困于复杂的数据治理任务，如何打通数据价值落地的&quot;最后一公里&quot;始终是行业痛点。&lt;/p&gt; 
 &lt;p&gt;PowerData 社区主理人李奇峰给出了一个充满技术想象力的答案：通过深度结合 DeepSeek 大模型的逻辑推理与结构化数据处理能力，重构数据中台的技术栈。&lt;/p&gt; 
 &lt;p&gt;3 月 22 日，PowerData 社区主理人李奇峰将出席 OSC 源创会南京站，并发表《使用 DeepSeek 拯救数据中台》主题分享，探讨如何借助大模型通用化与生成式的数据处理能力，结合数据中台中的落地痛难点，对其进行针对性的优化改造。&lt;/p&gt; 
 &lt;p&gt;在活动正式开始前，我们也和李奇峰聊了聊一些「入门级」问题，感兴趣的开发者可周六到活动现场，与李奇峰交流探讨关于数据中台的建设问题。报名链接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;800&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e193f9982c2bb3fe9fad5193d51273ce545.jpg&quot; width=&quot;552&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在众多大模型中为何选择 DeepSeek 作为数据中台改造的核心技术？与其他开源模型相比，DeepSeek 在数据处理场景下有哪些优势？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;我作为一个数据中台的从业者，核心诉求还是提升数据中台本身的能力。对于大模型的了解并不深入，其只是我的一个工具而已。所以从工具的属性来说，我选择 deepseek 主要有以下几点原因：&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;成本：无论是训练成本、还是推理成本，相较于其他模型都有显著降低。同时支持国产化硬件，在合规性方面也有保证。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;热度：在风口到来的时候，不说乘风而飞，但是至少还是需要蹭一下的。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;能力：DeepSeek R1 是 LMSYS Chinese 榜单最强的 from China 的模型，V3 是上面榜单中开源的最强非 Reasoner 模型，基础能力优越。同时相较于其他模型，DeepSeek 在逻辑推理+结构化数据解析处理的能力优秀，同时其支持的上下文窗口较大，在数据血缘解析、数据分类分级、数据质量治理等任务中，其准确性较其他模型都有显著提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;开发者最关心的部署成本问题：在私有化部署场景下，DeepSeek 模型针对数据中台做了哪些轻量化改造？是否支持量化压缩后的模型在常规 GPU 服务器集群运行？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;Deepseek 不会为企业应用场景训练各种量化模型的，市面上的量化模型都是社区和开发者上传的。如果为了降低部署成本，采购算力服务器之前先测试各个量化模型的能力能否满足应用场景，确定好使用哪版量化模型后，根据显存去采购性价比最高算力服务器，推理服务器建议买 Nvdia 游戏卡。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;能否用具体代码片段说明 DeepSeek 如何与数据中台组件集成？例如如何通过 API 调用实现&quot;自然语言转数据服务接口&quot;这类典型场景，过程中需要哪些中间件做适配？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;下面是一个非常简单的通过大模型进行数据自动标注的代码：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import openai
import pandas as pd
import json
from typing import List, Dict

class MetadataAutoTagger:
    def __init__(self, api_key: str, business_context: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.business_context = business_context  # 公司业务背景说明
        
    def generate_prompt(self, table_name: str, columns: List[str]) -&amp;gt; str:
        &quot;&quot;&quot;构造大模型提示词&quot;&quot;&quot;
        return f&quot;&quot;&quot;
        # 任务说明
        根据提供的元数据和业务背景，生成数据资产的业务标注信息，要求：
        1. 业务名称：体现数据在业务中的核心作用
        2. 业务类型：交易型/分析型/主数据/日志型...
        3. 业务实体：对应业务对象（客户/订单/产品...）
        4. 分类分级：按公司数据分类分级标准
        5. 字段说明：用业务语言解释字段含义

        # 业务背景
        {self.business_context}

        # 待标注元数据
        表名：{table_name}
        字段列表：{&#39;, &#39;.join(columns)}

        请用 JSON 格式返回结果，结构如下：
        {{
            &quot;table_name&quot;: &quot;{table_name}&quot;,
            &quot;business_name&quot;: &quot;&quot;,
            &quot;business_type&quot;: &quot;&quot;,
            &quot;business_entity&quot;: &quot;&quot;,
            &quot;data_classification&quot;: &quot;&quot;,
            &quot;columns&quot;: {{
                &quot;column1&quot;: &quot;业务说明&quot;,
                &quot;column2&quot;: &quot;业务说明&quot;
            }}
        }}
        &quot;&quot;&quot;

    def tag_metadata(self, metadata_df: pd.DataFrame) -&amp;gt; pd.DataFrame:
        &quot;&quot;&quot;批量处理元数据&quot;&quot;&quot;
        results = []
        for _, row in metadata_df.iterrows():
            response = self._call_llm(row[&#39;table_name&#39;], row[&#39;columns&#39;])
            if response:
                results.append(response)
        return pd.DataFrame(results)

    def _call_llm(self, table_name: str, columns: List[str]) -&amp;gt; Dict:
        &quot;&quot;&quot;调用大模型 API&quot;&quot;&quot;
        try:
            prompt = self.generate_prompt(table_name, columns)
            response = self.client.chat.completions.create(
                model=&quot;gpt-4&quot;,
                messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
                temperature=0.2,
                response_format={&quot;type&quot;: &quot;json_object&quot;}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f&quot;Error processing {table_name}: {str(e)}&quot;)
            return None

# 示例用法
if __name__ == &quot;__main__&quot;:
    # 初始化配置
    config = {
        &quot;api_key&quot;: &quot;your_openai_key&quot;,
        &quot;business_context&quot;: &quot;某电商公司，主要业务包含商品交易、用户画像、订单履约等...&quot;
    }

    # 示例元数据（实际从数据库或文件读取）
    sample_data = {
        &quot;table_name&quot;: [&quot;user_info&quot;, &quot;order_detail&quot;],
        &quot;columns&quot;: [
            [&quot;user_id&quot;, &quot;registration_date&quot;, &quot;last_login&quot;],
            [&quot;order_id&quot;, &quot;product_sku&quot;, &quot;payment_amount&quot;]
        ]
    }
    metadata_df = pd.DataFrame(sample_data)

    # 执行自动标注
    tagger = MetadataAutoTagger(**config)
    result_df = tagger.tag_metadata(metadata_df)
    
    # 保存结果
    result_df.to_csv(&quot;tagged_metadata.csv&quot;, index=False)
    print(&quot;标注结果示例：&quot;)
    print(result_df.head())
典型输出结果如下：
{
    &quot;table_name&quot;: &quot;user_info&quot;,
    &quot;business_name&quot;: &quot;用户基本信息表&quot;,
    &quot;business_type&quot;: &quot;主数据&quot;,
    &quot;business_entity&quot;: &quot;用户&quot;,
    &quot;data_classification&quot;: &quot;PII/LEVEL-2&quot;,
    &quot;columns&quot;: {
        &quot;user_id&quot;: &quot;用户唯一标识符，用于跨系统用户识别&quot;,
        &quot;registration_date&quot;: &quot;用户注册电商平台的具体日期&quot;,
        &quot;last_login&quot;: &quot;记录用户最近一次登录平台的时间&quot;
    }
}&lt;/code&gt;&lt;/pre&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在处理非结构化数据场景中（如日志解析/图片 OCR），DeepSeek 与传统 ETL 工具的结合方案是怎样的？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;非结构化数据基本用不上 Deepseek，月更好的选择，图片用多模态 LLM 可以总结，图片类型的文档用 OCR，OCR 一般用百度&lt;a href=&quot;https://www.oschina.net/action/visit/ad?id=1185&quot;&gt;paddle&lt;/a&gt;，表格解析有开源的读光模型。这些都是数据处理，处理完才是抽取-转换-加载（Sqoop、Flume、Cannel、DataX）到下游。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在数据关系复杂的中台环境，如何通过 prompt engineering 确保大模型输出的 SQL/SHELL 脚本符合安全规范？是否有开发自定义的语法校验中间件？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;提示词来确保大模型输出的 SQL/SHELL 脚本符合安全规范，是有问题的。LLM 是用来理解和处理自然语言的，更多的是交互上的提升。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;推荐使用 sqlcheck 和 shellcheck 这种工具，脚本安全做的还可以。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;遇到模型&quot;幻觉&quot;导致的数据质量问题，是否有设计技术兜底方案？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;可以通过 RAG + 外挂知识库的方式优化幻觉问题。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;PowerData 社区在构建 DeepSeek 插件生态方面有哪些规划？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;后续会实现一些 MCP 接口。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;对想参与数据中台智能化改造的开发者，建议从哪些具体模块入手贡献？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;可以先尝试进行 text to sql 的功能开发，具体入门教程可参考此篇文章：https://mp.weixin.qq.com/s/Wk9OmB80JC7NFG2T7VjNRA&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;在 Data+AI 的架构演进中，您认为未来 3 年数据中台的核心组件会发生哪些颠覆性变化？传统数据仓库工程师需要优先补充哪些 AI 工程化能力？&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;李奇峰：&lt;/strong&gt;颠覆性变化谈不上，数据中台的核心还是数据资产化、服务化，一切的功能目标都是往这个方向走。随着大模型的快速进化与深度结合，数据中台可能会在以下能力进行进化：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;自然语言交互：大模型出色的自然语言交互能力可准确理解用户意图，大幅提升数，据查询分析的便利性，提升用户体验&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;智能洞察分析：大模型可分析文本、图表等多维数据，智能归因、预测、总结，降，低员工利用数据、分析数据的门槛&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;集成大模型服务链路：集成 LangChain、向量检索、finetune 等大模型应用所，需技术组件，提升企业调试、使用大模型的效率&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;传统数仓需要补充哪些 AI 工程化能力？这个我们社区之前内部讨论过，工程化能力谈不上，更多的还是把 AI 当成一个全能小助手，帮助自己解决问题和提效吧。&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;10567&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9b99625d6dd601dfc15f3189cd7c0bdf40c.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17938519</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17938519</guid>
            <pubDate>Wed, 05 Mar 2025 09:57:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Bolt.new 创始人：软件世界运行着万亿美元的市场，重写软件世界秩序的机会是巨大的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bolt.new 创始人的励志故事：我们如何从即将倒闭，到成为史上增长最快的 AI 编码工具，并保持不到 20 名员工的规模。&lt;/p&gt; 
&lt;p&gt;本文整理自 Bolt.new 创始人 Eric Simons 的完整采访。他说：&quot;软件世界运行着万亿美元的市场，重写软件世界秩序的机会是巨大的。&quot;&lt;/p&gt; 
&lt;p&gt;来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FPiG719cda&quot; target=&quot;_blank&quot;&gt;https://weibo.com/1233486457/PiG719cda&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;一、从零到爆发：Bolt 的惊人增长轨迹&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Lenny 最近对 StackBlitz 的创始人兼 CEO Eric Simons 进行了一次深入采访，揭示了这个产品如何在短短几个月内从零到每年 4000 万美元的经常性收入 (ARR)，成为史上增长最快的产品之一。&lt;/p&gt; 
&lt;p&gt;StackBlitz 是一家已经存在了七年的公司，专注于基于网络的开发环境技术。然而，就在公司即将倒闭之际，他们推出了 Bolt - 一款 AI 驱动的文本到应用程序 (text-to-app) 工具，彻底改变了公司的命运。&lt;/p&gt; 
&lt;p&gt;&quot;公司在我们推出 Bolt 时几乎要倒闭了，&quot;Simons 回忆道。&quot;我们想，如果这能在未来几个月增加 10 万美元的 ARR，那就太棒了。结果在前两个月，我们从零增长到了 2000 万美元的 ARR。&quot;&lt;/p&gt; 
&lt;p&gt;现在，仅仅 5 个月后，Bolt 已经达到了 3000 万美元的 ARR，即将跨越 4000 万美元的门槛，拥有 300 万注册用户和约 100 万月活跃用户。更令人惊讶的是，StackBlitz 只有 15-20 名员工。这种爆炸性增长甚至让经验丰富的创业者和投资者都感到震惊，因为很少有公司能以这样的速度扩张。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;二、WebContainer 技术：七年锤炼的核心竞争力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功并非一蹴而就，而是建立在七年技术积累的基础上。StackBlitz 的核心技术是 WebContainer - 一种可以在浏览器中运行的操作系统，它能在 100 毫秒内启动并运行完整的开发工具链。&lt;/p&gt; 
&lt;p&gt;与市场上其他类似产品不同，Bolt 不依赖云服务器来运行应用程序。当用户使用其他&quot;文本到应用程序&quot;工具时，通常需要等待云虚拟机启动，这可能需要几分钟时间，并且经常出现问题。而 Bolt 的 WebContainer 技术利用用户自己的 CPU 和内存在浏览器中本地运行应用程序，使得整个过程更快、更可靠。&lt;/p&gt; 
&lt;p&gt;&quot;这就是为什么我们可以有一个非常宽松的免费层级，而且它极其快速和可靠，&quot;Simons 解释道。&quot;我们的 AI Agent 与这个操作系统有双向通信。它编写代码，运行开发服务器，使整个过程快速而流畅。&quot;&lt;/p&gt; 
&lt;p&gt;这种技术路线是 StackBlitz 团队经过深思熟虑的结果，受到了像 Figma 这样的成功产品的启发。Simons 指出：&quot;如果你看看其他在网络上真正成功的生产力应用程序，它们都采用这种计算模型。Figma、Google Docs - 这是唯一一种扩展到十亿用户的模型。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;三、Bolt 实战：一分钟内从文本到功能性应用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了 Bolt 的强大功能。他只是简单地在一个文本框中输入&quot;制作一个 Spotify 克隆&quot;，然后点击回车。在不到一分钟的时间内，Bolt 在浏览器中生成了一个功能完整、视觉上令人印象深刻的 Spotify 克隆应用。&lt;/p&gt; 
&lt;p&gt;&quot;这是在浏览器中运行的完整开发环境，这是在我的浏览器中运行的真实操作系统，&quot;Simons 展示道。&quot;我可以在上面运行命令等，真正令人印象深刻的是，所有这些都是在 60 秒内完成的。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，用户可以立即部署他们的应用程序。通过集成 Netlify 等生产级托管提供商，用户可以一键获得一个实时 URL，甚至可以附加自己的域名。这使得整个过程从创建到部署变得无缝衔接。&lt;/p&gt; 
&lt;p&gt;Simons 强调说：&quot;这是有史以来构建网络应用最简单的方式。&quot;对比传统工具，他指出：&quot;那些东西（如 Wix 或 Squarespace）使用起来非常复杂。我不知道你是否见过这些工具的 UI，但它们非常复杂。而那只是为了构建一个静态网站，你根本无法用它们构建功能性应用。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;四、移动应用开发的革命：实时预览与测试&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 最近的一项重大更新是与 Expo 的合作，使用户能够创建原生移动应用。Expo 是一家专注于 React Native 工具的公司，使开发者能够更轻松地构建漂亮的应用并将其上传到应用商店。&lt;/p&gt; 
&lt;p&gt;在演示中，Simons 展示了如何使用 Bolt 和 Expo 构建一个移动版 Spotify 克隆应用。用户只需扫描二维码，就能在自己的手机上实时查看和测试应用程序。当用户继续通过提示改进应用程序时，这些更改会实时反映在他们的设备上。&lt;/p&gt; 
&lt;p&gt;&quot;这是第一次，你不需要成为技术人员就能制作生产级的网络、全栈网络和移动应用，&quot;Simons 解释道。他指出，Bolt 的用户群体中有 67% 的人不是开发者，而是产品经理、设计师和企业家。&quot;这些人一直都很擅长构建产品，但以前，他们唯一能将想法转化为代码软件的方式是通过开发者的手指。现在他们可以自己处理。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;五、七年磨一剑：从技术挑战到市场突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的成功不仅仅是一个技术故事，更是一个关于毅力和坚持的故事。StackBlitz 在七年的时间里专注于构建 WebContainer 技术，经历了无数挑战和失败。&lt;/p&gt; 
&lt;p&gt;&quot;我们在技术第一，然后寻找问题来解决，这往往是人们告诉你不应该做的事情，&quot;Simons 承认。他的联合创始人 Albert 和他从 13 岁就开始一起编写代码，并从那时起一直在构建产品。&lt;/p&gt; 
&lt;p&gt;他们的灵感部分来自于早期的 Figma，Figma 最初是作为一个基于浏览器的深度技术项目起步的。Simons 解释说：&quot;很少有人知道 Figma 也是一个基于浏览器的深度技术项目。他们第一个 Figma 演示不是设计工具，而是在浏览器标签中展示一个 3D 球体掉入水中的效果。&quot;&lt;/p&gt; 
&lt;p&gt;类似地，StackBlitz 团队看到了浏览器技术（如 WebAssembly、共享内存和 Service Workers）的进步，并意识到可以构建一个运行在浏览器中的操作系统。他们花了大约五年时间来构建 WebContainer，然后又花了几年时间尝试找到合适的产品应用。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;六、在死亡边缘找到转机：一条推文改变一切&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在公司即将耗尽资金的关键时刻，StackBlitz 团队认识到他们的 WebContainer 技术非常适合构建基于浏览器的 AI 产品。&lt;/p&gt; 
&lt;p&gt;&quot;我们与 Anthropic 合作，获得了对 Sonnet 模型的预览，&quot;Simons 回忆道。&quot;我们意识到这可能是我们的机会。我们以前尝试过构建类似 Bolt 的东西，但当时的模型不够好，代码输出不够可靠。但 Sonnet 改变了这一切。&quot;&lt;/p&gt; 
&lt;p&gt;2023 年 6 月，当 Anthropic 发布 Claude 3.5 Sonnet 模型时，StackBlitz 团队看到了机会。他们重新拾起之前搁置的项目，并通过一条简单的推文推出了 Bolt。结果超出了他们最疯狂的期望。&lt;/p&gt; 
&lt;p&gt;&quot;这就像是一个七年磨一剑的&#39;一夜成名&#39;故事，&quot;Simons 表示。StackBlitz 的生存策略也起到了关键作用，他们在整个过程中保持了极低的支出和精简的团队。&quot;我和我的联合创始人以前曾经引导一家公司直至被收购，所以我们知道如何使每一美元发挥超出任何人认为合理或可能的价值。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;七、小团队实现高速增长的秘诀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;尽管 Bolt 正在以前所未有的速度增长，但 StackBlitz 仍然是一个只有 15-20 人的小团队。当被问及如何管理这种增长时，Simons 强调了两个关键因素：技术和人员。&lt;/p&gt; 
&lt;p&gt;&quot;我们团队中有大约 5-7 人已经在这里工作了五年多，这在初创公司中相当罕见，&quot;Simons 指出。&quot;我们的策略一直是减少人员，增加每人的背景知识。每个人在公司里都了解其他所有事情，这样他们可以独立做出准确的决策。&quot;&lt;/p&gt; 
&lt;p&gt;StackBlitz 采用了每天召开全公司会议的做法，使每个人都了解正在发生的一切。尽管这听起来可能效率低下，但 Simons 辩解说：&quot;当你处于极端增长期时，你希望沟通损失接近于零。虽然这不是我们永远会做的事情，但在目前的阶段，它非常有效。&quot;&lt;/p&gt; 
&lt;p&gt;在工具方面，团队使用 Linear 进行工程任务，使用 Notion 进行产品路线图，使用 Figma 进行设计。有趣的是，他们现在也在使用 Bolt 进行许多设计和原型制作工作，因为它比传统工具更快。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;八、Anthropic 的 Sonnet 模型：AI 编码的临界点突破&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在访谈中一个令人惊讶的发现是，Anthropic 的 Claude 3.5 Sonnet 模型在 Bolt 的成功中起到了关键作用。Simons 称之为 AI 生成可靠代码的&quot;临界点&quot;。&lt;/p&gt; 
&lt;p&gt;&quot;在 Sonnet 之前，我们尝试过构建类似的东西，但它就是不起作用，代码输出不够可靠，应用程序要么损坏，要么看起来很丑，&quot;Simons 解释道。&quot;但当我们在 2023 年 5 月看到 Sonnet 的预览时，我们知道我们应该重新启动项目，因为这可能就是机会。&quot;&lt;/p&gt; 
&lt;p&gt;这一见解揭示了为什么自 Sonnet 发布以来，&quot;文本到应用程序&quot;工具的快速增长。Simons 指出，软件是确定性的，使其成为 AI 训练的理想领域：&quot;当你编写代码并点击运行时，它要么运行，要么不运行。这使得训练数据的创建和强化学习变得更加可靠。&quot;&lt;/p&gt; 
&lt;p&gt;更令人印象深刻的是，这些成功是基于 2023 年 6 月发布的模型，自那以来 Anthropic 还没有发布新模型。&quot;这是 AI 编码可能达到的最差状态，而且已经这么好了。下一个模型将使这一切变得更好，而且很快就会到来。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;九、AI 时代的职业前景：产品经理的黄金时代&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当讨论到 AI 对软件开发角色的影响时，Simons 提出了一个与许多流行观点相反的看法。他认为产品经理 (PM)，而非工程师，可能是 AI 编码革命的最大受益者。&lt;/p&gt; 
&lt;p&gt;&quot;当 Bolt 开始增长时，我们发现大多数用户不是开发者，而是产品经理、设计师和非技术企业家。这真正改变了一切，&quot;Simons 解释道。&quot;整个软件世界秩序将被重写，因为组织构建软件的方式将完全改变。&quot;&lt;/p&gt; 
&lt;p&gt;Simons 认为，产品经理精通定义范围并帮助开发者调试问题，这与成功使用 AI 开发代理所需的技能高度重合。&quot;如果你快进 1-5 年，PM 将不再只是写 JIRA 工单然后等待开发者完成，他们将能够自己进行更改。&quot;&lt;/p&gt; 
&lt;p&gt;工程师仍然很重要，但他们将专注于 LLM 不适合的智力挑战任务。&quot;这对每个人都是好事，&quot;Simons 强调。&quot;工程师可以专注于困难的挑战，而不是制作另一个 CRUD（增删改查）应用程序，而 PM 和设计师可以直接将他们的愿景转化为软件。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十、未来功能与愿景：与 Figma 和 Slack 的集成&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;展望未来，Bolt 正在开发几个令人兴奋的新功能。一个主要的即将推出的集成是与 Figma 的深度连接。用户只需在 Figma URL 前添加&quot;bolt.new&quot;并按回车，就能将设计导入 Bolt 并转换为全栈应用或移动应用。&lt;/p&gt; 
&lt;p&gt;&quot;这将是疯狂的，&quot;Simons 兴奋地说。&quot;从 Figma 到全栈应用，只需一次点击，字面意思。当你是开发者、设计师或其他角色时，将设计转化为实际的编码应用并能继续从那里提示，这真的很有趣。&quot;&lt;/p&gt; 
&lt;p&gt;另一个即将推出的功能是与 Slack 的集成，这将使团队能够直接在他们的通信中使用 Bolt。&quot;我们正在创建一个 Slack 机器人，其工作是基本上像你团队中的开发者一样行动，&quot;Simons 解释道。&quot;你可以在一个线程中说&#39;嘿，我认为我们应该添加一个主页&#39;，然后@Bolt&#39;你能快速做出这个吗？&#39;它会获取对话历史，理解需求，并生成应用程序。&quot;&lt;/p&gt; 
&lt;p&gt;这些集成反映了 Simons 对 AI 如何改变产品开发的更广泛愿景，使非技术人员能够直接创建他们想象的产品。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十一、使用 Bolt 的建议：像与开发者交流一样与 AI 交流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当被问及给新 Bolt 用户的建议时，Simons 提供了一个简单但有力的建议：&quot;像写线程工单或 JIRA 工单一样与它交流。将它视为你团队中的开发者。&quot;&lt;/p&gt; 
&lt;p&gt;他解释说，这意味着在重要的事情上要具体，但也要允许 AI 在适当的领域发挥创意。&quot;你可以只告诉它&#39;让它更漂亮&#39;，它会做得很好。事实上，它做得非常好。&quot;&lt;/p&gt; 
&lt;p&gt;对于初次使用的人，Simons 建议从个人网站开始：&quot;这有一种魔力。你复制粘贴你的 LinkedIn 简历，说&#39;我需要一个网站。我的名字是某某。这是我的 LinkedIn 历史。我喜欢蓝色和狗。&#39;点击回车，然后你可以部署它。如果你还没有.com 域名，现在你可以拥有一个真正的个人网站。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;十二、从 AOL 总部蹭住到建立价值数千万的公司&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在采访的最后，Simons 分享了他早年在硅谷的一段惊人经历。2012 年，19 岁的他参加了一个教育科技孵化器项目，该项目位于 AOL 总部。当资金耗尽时，他注意到这个办公室有沙发、食物、健身房，甚至还有淋浴和洗衣设施。&lt;/p&gt; 
&lt;p&gt;&quot;我想，也许在弄清楚这一切的同时，我可以住在这里，&quot;Simons 回忆道。&quot;所以我最终在这里住了四五个月。&quot;他通过在夜间编码来避开保安，白天和夜间轮班的保安以为他只是一个工作非常努力的员工。&lt;/p&gt; 
&lt;p&gt;生活费用？&quot;当时我的花费是每天一美元。那是麦当劳还有一美元菜单的时候。&quot;最终，一名保安发现了他并将他赶了出去，但这段经历展示了他早期的创业精神和生存能力。&lt;/p&gt; 
&lt;p&gt;Simons 的故事，从 AOL 总部蹭住到建立一家在几个月内达到 4000 万美元 ARR 的公司，展示了他一直以来的坚韧和创新精神。正如他所说：&quot;这一切都是关于保持活力，并采取尽可能多的尝试。&quot;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;结论：AI 编码的未来与更广泛的影响&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Bolt 的故事不仅是关于一个成功的产品，还是关于技术进步如何彻底改变我们构建软件的方式。从这次采访中，我们可以看到几个关键趋势：&lt;/p&gt; 
&lt;p&gt;1. 文本到应用程序技术正在迅速成熟，使非技术人员能够创建以前需要专业开发团队的应用程序。&lt;/p&gt; 
&lt;p&gt;2. 基于浏览器的计算正在获得新的重要性，提供比基于云的替代方案更快、更可靠的体验。&lt;/p&gt; 
&lt;p&gt;3. AI 编码工具正在重塑公司的组织结构，可能导致产品和设计角色的重要性增加。&lt;/p&gt; 
&lt;p&gt;4. 我们可能正处于一场软件开发革命的边缘，这场革命将使创建功能全面的应用程序变得像使用文字处理器一样容易&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339630</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339630</guid>
            <pubDate>Wed, 05 Mar 2025 09:45:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>小米汽车模型训练专利公布，可解决资源消耗较大等技术问题</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;天眼查知识产权信息显示，小米汽车科技有限公司申请的「模型训练方法、使用方法、装置、设备及存储介质」专利公布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;摘要显示，其中所述模型训练方法包括：将第一物理参数和第一性能数据输入第一模型，得到所述第一物理参数和所述第一性能数据的多个关联关系；将所述第一物理参数输入到取值模块，得到第二物理参数，所述取值模块基于所述第一物理参数计算出目标取值集合，在所述目标取值集合中选取所述第二物理参数；将所述第二物理参数输入所述第一模型，得到多个第二性能数据；基于所述多个第二性能数据，更新所述第一模型，得到第二模型。这样，能解决相关技术中存在的模型训练的精度和效率较低、资源消耗较大等技术问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;336&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-72b7dc543a47a38cd1a8d9a37c54723f663.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339627</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339627</guid>
            <pubDate>Wed, 05 Mar 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AgentOps —— AI 代理的可观察性和 DevTool 平台</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;AgentOps 是一个帮助开发人员&lt;/span&gt;测试、调试和部署 AI 代理和 LLM 应用程序的平台&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;。与大多数 LLM 和代理框架集成，包括 OpenAI Agents SDK、CrewAI、Langchain、Autogen、AG2 和 CamelAI。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Replay Analytics 和 Debugging&lt;/strong&gt; 代理逐步执行图&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LLM 成本管理&lt;/strong&gt; 跟踪 LLM 基础模型提供商的支出&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代理基准测试&lt;/strong&gt; 根据 1,000 多个评估测试您的代理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合规性和安全性&lt;/strong&gt; 检测常见的即时注入和数据泄露漏洞&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;框架集成&lt;/strong&gt; 与 CrewAI、AG2 (AutoGen)、Camel AI 和 LangChain 的原生集成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;237&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0314/182656_cKyN_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/agentops</link>
            <guid isPermaLink="false">https://www.oschina.net/p/agentops</guid>
            <pubDate>Wed, 05 Mar 2025 09:09:00 GMT</pubDate>
        </item>
        <item>
            <title>昆仑万维开源 R1V 视觉思维链推理模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;昆仑万维宣布正式开源首款工业界多模态思维链推理模型 Skywork R1V，即日起开源模型权重和技术报告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，Skywork R1V 具备超强的视觉理解和推理能力。「无论是日常繁琐的工作任务、复杂的数据分析、难以解答的学术问题，还是前所未见的陌生场景，都可以交给 Skywork R1V 进行高效处理。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Reasoning 推理能力方面，Skywork R1V 实现了模型的顶尖逻辑推理与数学分析能力。在权威的 MATH500 和 AIME 基准测试中，Skywork R1V 分别取得了 94.0 和 72.0 的高分，明显领先于行业内众多主流模型。Skywork R1V 在纯文本复杂推理任务中展现出卓越性能，使其在逻辑推理和数学问题求解领域展现出人类专家级别的水准。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 Vision 视觉理解能力方面，Skywork R1V 成功地将其强大的文本推理与思维链推导能力高效迁移到视觉任务中。凭借创新的跨模态迁移技术与推理优化框架，Skywork R1V 能够高效解决需要多步视觉推理的问题，在 MMMU 与 MathVista 等视觉推理基准中分别取得了 69 和 67.5 的优异成绩。这些结果不仅明显超越了多个近似大小的开源竞争模型，更达到与规模更大的闭源模型媲美的水准，充分证实了 Skywork R1V 在需要视觉思维链推理的跨模态任务中的领先优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Skywork R1V 通过视觉与文本能力的深度融合和视觉思维链推理能力的突破，推动了多模态推理模型的进一步发展，标志着人工智能领域的又一重大进步。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，Skywork R1V 已全面开源。和开源同规模或更大规模模型的对比，Skywork R1V 38B 体现出行业显著优异的推理能力，以及领先的多模态视觉理解能力。如下图，与开源同规模或更大规模模型的对比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e032223e7b259303f6e6f7cce7dde417a6f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与闭源头部模型性能对比，R1V 38B 模型性能媲美甚至超越更大开源模型以及主流闭源模型。如下图，与开源大尺寸模型与闭源专有模型的对比：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;332&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-673a31430f860afa0908dd05aeaa3ad9c22.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339599</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339599</guid>
            <pubDate>Wed, 05 Mar 2025 07:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>理想汽车发布下一代自动驾驶架构 MindVLA</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 18 日，在 NVIDIA GTC 2025 上，理想汽车发布了下一代自动驾驶架构 MindVLA。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6ee07e92de4f6f16747c4c6b166e3b3f2f7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;理想汽车自动驾驶技术研发负责人贾鹏发表了主题演讲《VLA：迈向自动驾驶物理智能体的关键一步》，分享了理想汽车对于下一代自动驾驶技术 MindVLA 的最新思考和进展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b55c3282e8382e3f4257e15bbf23fee737f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;贾鹏表示：「MindVLA 是机器人大模型，它成功整合了空间智能、语言智能和行为智能，一旦跑通物理世界和数字世界结合的范式后，将有望赋能更多行业。MindVLA 将把汽车从单纯的运输工具转变为贴心的专职司机，它能听得懂、看得见、找得到。我们希望 MindVLA 能为汽车赋予类似人类的认知和适应能力，将其转变为能够思考的智能体。」&lt;/p&gt; 
&lt;p&gt;理想汽车 CEO 李想&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1243861097%2FPj5JY3Gsr%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;介绍称&lt;/a&gt;&lt;/u&gt;：「&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;MindVLA 是一个视觉-语言-行为大模型，但我们更愿意将其称为‘机器人大模型’，它将空间智能、语言智能和行为智能统一在一个模型里，让自动驾驶拥有感知、思考和适应环境的能力，是我们通往 L4 路上最重要的一步。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;李想还表示：「MindVLA 能为自动驾驶赋予类似人类的驾驶能力，就像 iPhone 4 重新定义了手机，MindVLA 也将重新定义自动驾驶。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339597</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339597</guid>
            <pubDate>Wed, 05 Mar 2025 07:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软量子计算机研发曾遭 CEO 纳德拉否定</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微软上月&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot;&gt;宣布&lt;/a&gt;了一项重大科研进展，声称已成功制造出能够产生马约拉纳费米子的芯片，这一成果被视为量子计算领域的一大突破。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0220/104630_5Gkb_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;微软方面表示，这一技术突破有望将量子设备的问世时间大幅提前，从原本预估的几十年缩短至几年之内。尽管这一消息在科技界引起了广泛关注，但并非所有物理学家都对微软的说法表示完全信服。&lt;/p&gt; 
&lt;p&gt;然而，微软 CEO 萨蒂亚·纳德拉却对此成果显得颇为满意。据悉，微软每年在量子研究上的投入高达 3 亿美元，尽管与人工智能等领域的投资相比，这一数字显得微不足道，但微软在量子领域的持续投入已累积近二十年，如今终于取得了阶段性成果。&lt;/p&gt; 
&lt;p&gt;值得注意的是，微软在量子计算领域的进展并非一帆风顺。据知情人士透露，七年前，纳德拉曾在公司内部对微软的量子研究表示怀疑，认为其缺乏商业潜力。然而，随着谷歌和 D-WaveQuantum 等竞争对手在量子计算方面取得进展，微软的科学家们也意识到自己正处于一场激烈的竞赛之中。&lt;/p&gt; 
&lt;p&gt;尽管如此，微软方面仍对自身的科研成果充满信心。负责监督相关团队的高管贾森·赞德表示，公司正准备发表《自然》论文的后续研究，并已邀请一组独立研究人员对其进行评审。&lt;/p&gt; 
&lt;p&gt;同时，微软发言人强调，公司会秉持最高的学术道德标准，确保研究成果的真实性和可靠性。&lt;/p&gt; 
&lt;p&gt;阅读更多：&lt;a href=&quot;https://www.oschina.net/news/334836/microsofts-majorana-1-chip&quot; target=&quot;news&quot;&gt;微软发布首款量子计算芯片「Majorana 1」&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339592</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339592</guid>
            <pubDate>Wed, 05 Mar 2025 07:35:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>开源 AI 助手平台 Cherry Studio 发布 1.1.5，支持 MCP ​​​</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Cherry Studio 是一款支持多个大语言模型（LLM）服务商的开源桌面客户端，兼容 Windows、Mac 和 Linux 系统。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-23dab8c50bfcc8126ab84229b00dbc2115c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cherry Studio 昨天发布了最新的 1.1.5 版本，其中最值得关注的变化是&lt;strong&gt;正式支持&amp;nbsp;MCP。&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加 MCP 工具响应可视化和处理&lt;/li&gt; 
 &lt;li&gt;支持每条消息启用/禁用 MCP 服务器&lt;/li&gt; 
 &lt;li&gt;修复了 MCP 无法调用功能的问题&lt;/li&gt; 
 &lt;li&gt;优化 MCP 工具按钮的服务器启用依赖关系&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/153016_Zh67_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCherryHQ%2Fcherry-studio%2Freleases%2Ftag%2Fv1.1.5&quot; target=&quot;_blank&quot;&gt;点此查看详细更新说明&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339590/cherry-studio-1-1-5-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339590/cherry-studio-1-1-5-mcp</guid>
            <pubDate>Wed, 05 Mar 2025 07:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Meta 首席 AI 科学家杨立昆评价人形机器人：演示惊艳、实际很蠢</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;图灵奖得主、Meta 首席 AI 科学家杨立昆近日在一档播客节目中对人形机器人发表了「锐评」，他表示：「&lt;strong&gt;很多人形机器人演示令人印象深刻，但实际很蠢，不少机器人公司都在豪赌未来 3 到 5 年 AI 会突飞猛进。&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0318/151624_dBd1_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;杨立昆认为，目前我们仍然没有家用机器人，也没有能够完成猫或狗所能完成任务的机器人，更没有完全自主的 L5 级自动驾驶汽车。他强调，&lt;strong&gt;我们所欠缺的是如何训练一个系统来理解像视觉这样复杂的感官输入&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;杨立昆进一步指出，如果我们能够构建出理解物理世界、拥有持久记忆、能够推理和规划的 AI 系统，那我们就有了为机器人提供动力的 AI 基础。这样的机器人会比我们现有的机器人灵活得多。他提到，过去一两年里，成立了很多机器人公司，他们制造人形机器人和类似的技术。虽然所有的演示都令人印象深刻，但这些机器人实际上都很蠢。它们不能做人类能做的事情，不是因为它们缺乏身体能力，而是因为它们根本不够聪明，无法驾驭现实世界的复杂性。&lt;/p&gt; 
&lt;p&gt;杨立昆还提出，很多这样的公司都寄希望于 AI 在未来 3 到 5 年内会取得快速进展。他们预计到他们准备好大规模生产和销售这些机器人时，AI 的进步将使它们足够智能。&lt;/p&gt; 
&lt;p&gt;然而，杨立昆认为这是一场豪赌，他无法确定这是否能在三至五年内实现。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339582</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339582</guid>
            <pubDate>Wed, 05 Mar 2025 07:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>澳门即将全面结束 3G 时代</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;澳门特区政府于 2022 年向澳门四间流动电信服务营运商延长 3G 牌照两年，&lt;strong&gt;该牌照将于 2025 年 6 月 4 日届满，澳门 3G 移动电信网络及服务将随着牌照届满而终止&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-952129e924f58e0fc3e136e05bebebc548b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;针对上述情况，澳门已敦促各运营商为 3G 退网做好准备工作。&lt;/p&gt; 
&lt;p&gt;澳门邮电局呼吁使用 3G 服务的市民及商户，请尽早联络相关电信营运商，了解转换到 4G 或 5G 服务的条件，选择最适合自身需求的服务。此外，市民及商户亦应留意手机或其他终端设备是否支持 4G 或 5G 制式，如需语音通话，有关设备更需支持 4G 语音通话功能（VoLTE），用户可按自身需要适时更换设备，确保能继续享用电信服务。&lt;/p&gt; 
&lt;p&gt;澳门邮电局局长刘惠明日前表示，随着通信业的发展进程，3G 流动电信网络及服务将于 6 月随着牌照届满而终止。刘惠明称，目前仍有约 1 万多名用户，有一部分是非活跃用户。局方正敦促营运商与合作伙伴处理有关问题，并要求营运商加强宣传推广 3G 在 6 月退场的讯息。&lt;/p&gt; 
&lt;p&gt;澳门电讯 CTM 也称，将于 2025 年 6 月起正式与 3G 网络服务告别。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-22f36d1bf91bacce6a45e473812d8130769.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;澳门电讯会通过短信通知仍使用 3G 服务的客户，及时更新服务计划及设备。客户亦可通过拨打 #183# 查询设备是否支持 4G / 5G 网络以及 VoLTE 话音功能。如有任何疑问或需协助，可亲临任何一间 CTM 门市或致电 CTM 服务第一热线：1000 查询。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339576</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339576</guid>
            <pubDate>Wed, 05 Mar 2025 07:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>华科大研发领先的「玻璃光盘」技术：理论容量最高 360TB、成本仅 1/10</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FroBVlcZaikjurKymBpvpYQ&quot; target=&quot;_blank&quot;&gt;《长江日报》报道称&lt;/a&gt;&lt;/u&gt;，武汉光电国家研究中心信息存储系统教育部重点实验室研发出了一种「玻璃光盘」，存储容量目前是普通光盘的 10 倍，理论容量最高 360TB，而且几乎可以永久保存。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;921&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/145326_59D9_2720166.png&quot; width=&quot;1235&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一块普通的玻璃如何让它有记忆的功能，报道介绍称，首先要在玻璃中产生结构，引起玻璃的化学性质变化，而完成这个任务的便是飞秒激光，类似于光刻，过去家用光刻机只能刻一层，而华科大团队能刻 400 层。制作成的玻璃存储介质从表面看只增加了一层浅灰色，而在显微镜下玻璃表面呈现出的是三维立体结构。如何把结构又快又好写进玻璃里，工艺是关键。&lt;/p&gt; 
&lt;p&gt;该技术被称之为「巨量信息低成本超长寿命玻璃多维存储技术」，目前华科大在该项技术上全球领先，国内也是独有的。相比于几年前，玻璃存储介质读写速度较过去快了 3 个数量级，单位体积的存储容量也提升了 2 个数量级，成本则下降了 1 个数量级。现在 1GB 的介质成本需要约 1 元，而玻璃存储介质 1TB 也才几十元，只有其他存储介质十分之一的成本。&lt;/p&gt; 
&lt;p&gt;目前，制造玻璃介质存储的设备已生产出原型样机，今年将推出产品样机，产品也将很快走向市场。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339573</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339573</guid>
            <pubDate>Wed, 05 Mar 2025 06:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 3FS 与 JuiceFS：架构与特性比较</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，DeepSeek 开源了其文件系统 Fire-Flyer File System (3FS)，使得文件系统这一有着 70 多年历时的&quot;古老&quot;的技术，又获得了各方的关注。在 AI 业务中，企业需要处理大量的文本、图像、视频等非结构化数据，还需要应对数据量的爆炸式增长，分布式文件系统因此成为 AI 训练的关键存储技术。&lt;/p&gt; 
&lt;p&gt;本文旨在通过深入分析 3FS 的实现机制，并与 JuiceFS 进行对比，以帮助用户理解两种文件系统的区别及其适用场景。同时，我们将探讨 3FS 中的值得借鉴的创新技术点。&lt;/p&gt; 
&lt;h2&gt;01 架构对比&lt;/h2&gt; 
&lt;h3&gt;3FS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdeepseek-ai%2F3FS&quot; target=&quot;_blank&quot;&gt;3FS&lt;/a&gt; (Fire-Flyer File System) 是一款高性能的分布式文件系统，专为解决 AI 训练和推理工作负载而设计，该系统使用高性能的 NVMe 和 RDMA 网络提供共享存储层。3FS 由 DeepSeek 在 2025 年 2 月开源。 3FS 主要包括以下模块：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;集群管理服务（Cluster Manager）&lt;/li&gt; 
 &lt;li&gt;元数据服务（Metadata Service）&lt;/li&gt; 
 &lt;li&gt;存储服务（Storage Service）&lt;/li&gt; 
 &lt;li&gt;客户端 （FUSE Client、Native Client）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-96308079c12c6210e0436722cad35b7c636.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;所有模块通过 RDMA 网络通信。元数据服务和存储服务向集群管理服务发送心跳信号。集群管理服务负责处理成员变更，并将集群配置分发给其他服务和客户端。为了提高系统的可靠性和避免单点故障，会部署多个集群管理服务，其中一个被选为主节点。当主节点发生故障时，另一个管理器会被提升为主节点。集群配置通常存储在可靠的分布式服务中，例如 ZooKeeper 或 etcd。&lt;/p&gt; 
&lt;p&gt;当进行文件元数据操作（例如打开或创建文件/目录），请求被发送到元数据服务，以实现文件系统语义。元数据服务有多个，并且是无状态的，它们不直接存储文件元数据，而是依赖支持事务的键值数据库 FoundationDB 来存储这些数据。因此，客户端可以灵活地连接到任意元数据服务。这种设计使得元数据服务可以在没有状态信息的情况下独立运作，进而增强了系统的可伸缩性和可靠性。&lt;/p&gt; 
&lt;p&gt;每个存储服务管理若干本地 SSD，并提供 chunk 存储接口。存储服务采用 CRAQ （ Chain Replication with Apportioned Queries）来确保强一致性。3FS 中存储的文件被拆分为默认 512K 大小相等的块，并在多个 SSD 上进行复制，从而提高数据的可靠性和访问速度。&lt;/p&gt; 
&lt;p&gt;3FS 客户端提供两种接入方式： FUSE Client 和 Native Client。 FUSE Client 提供常见 POSIX 接口的支持，简单易用。Native Client 提供更高的性能，但是用户需要调用客户端 API ，具有一定的侵入性，下文我们还将对此作更详尽的解析。&lt;/p&gt; 
&lt;h3&gt;JuiceFS&lt;/h3&gt; 
&lt;p&gt;JuiceFS 是一个云原生分布式文件系统，其数据存储在对象存储中。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fjuicedata%2Fjuicefs&quot; target=&quot;_blank&quot;&gt;社区版&lt;/a&gt;可与多种元数据服务集成，适用场景广泛，于 2021 年在 GitHub 开源。企业版专为高性能场景设计，广泛应用于大规模 AI 任务，涵盖生成式 AI、自动驾驶、量化金融和生物科技等。 JuiceFS 文件系统包括三部分组成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;元数据引擎：用于存储文件元数据，包括常规文件系统的元数据和文件数据的索引。&lt;/li&gt; 
 &lt;li&gt;数据存储：一般是对象存储服务，可以是公有云的对象存储也可以是私有部署的对象存储服务。&lt;/li&gt; 
 &lt;li&gt;JuiceFS 客户端：提供 POSIX（FUSE）、Hadoop SDK、CSI Driver、S3 网关等不同的接入方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bed8225b825f4a839eca178b415fc4b67db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;架构差异&lt;/h3&gt; 
&lt;p&gt;从模块划分上看两个文件系统差异不大，都采用了元数据与数据分离的设计，各个模块功能也较类似。不同于 3FS 和 JuiceFS 企业版，JuiceFS 社区版兼容多种开源数据库存储元数据，对元数据的操作都封装在客户端，用户不需要再单独运维一个无状态的元数据服务。&lt;/p&gt; 
&lt;h4&gt;存储模块&lt;/h4&gt; 
&lt;p&gt;3FS 使用大量本地 SSD 进行数据存储，为了保证数据存储的一致性，3FS 使用 CRAQ 这一简洁的数据一致性算法 。几个副本被组成一个 Chain，写请求从 Chain 的 Head 开始，一直到达 Chain 的 Tail 时返回写成功应答。读请求可以发送到 Chain 的所有副本，如果读到脏节点的数据，该节点会联系 Tail 节点检查状态。如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4b03df1057d9942ff363f034bee15053b6e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;数据的写入是按顺序逐节点传递，因此会带来比较高的延时。如果 Chain 当中的某个副本不可用， 3FS 会把这个副本移到 Chain 的末尾，等副本可用的时候再做恢复。恢复的时候需要把整个 Chunk 的内容复制到这个副本，而非使用不可用期间的增量数据。如果要做到同步写所有副本和增量恢复数据，那写的逻辑会复杂非常多，比如 Ceph 使用 pg log 保证数据一致性。尽管 3FS 这种设计会导致写延迟，但是对于以读为主的 AI 应用场景，影响不大。&lt;/p&gt; 
&lt;p&gt;JuiceFS 利用对象存储作为数据存储解决方案，从而可享有对象存储带来的若干优势，如数据可靠性、一致性等。存储模块提供了一组用于对象操作的接口，包括 GET/PUT/HEAD/LIST 等，用户可以根据自己的需求对接具体的存储系统。比如不同云厂商的对象存储，也可以选择私有部署的对象存储比如 MinIO、Ceph RADOS 等系统。社区版 JuiceFS 提供本地缓存来应对 AI 场景下的带宽需求，JuiceFS 企业版使用分布式缓存满足更大的聚合读带宽的需求。&lt;/p&gt; 
&lt;h4&gt;元数据模块&lt;/h4&gt; 
&lt;p&gt;在 3FS 中，文件的属性以 KV 的形式存储在元数据服务中。该服务是一个无状态的高可用服务，依靠 FoundationDB 做支撑。FoundationDB 是 Apple 开源的优秀分布式 KV 数据库，具有很高的稳定性。FoundationDB 所有键值使用 Key 做全局排序，然后均匀拆分到不同的节点上。&lt;/p&gt; 
&lt;p&gt;为了优化 list 目录的效率，3FS 使用字符 &quot;DENT&quot; 前缀加父目录 inode 号和名字作为 dentry 的 Key。Inode 的 Key 是通过将 &quot;INOD&quot; 前缀与 inode ID 连接而构造的，其中 inode ID 采用小端字节序编码，以便将 inodes 分布到多个 FoundationDB 节点上。这个设计与 JuiceFS 使用的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Finternals%2F%23tkv&quot; target=&quot;_blank&quot;&gt;TKV（Transactional Key-Value Database）&lt;/a&gt; 进行元数据服务的存储方式类似。&lt;/p&gt; 
&lt;p&gt;JuiceFS 社区版的元数据模块，与存储模块类似也提供一组操作元数据的接口，可以接入不同的元数据服务，比如 Redis，TiKV 等 KV 数据库，MySQL，PostgreSQL 等关系型数据库，也可以使用 FoundationDB。JuiceFS 企业版使用自研高性能元数据服务，可根据负载情况来平衡数据和热点操作，以避免大规模训练中元数据服务热点集中在某些节点的问题（比如因为频繁操作临近目录文件的元数据引起）。&lt;/p&gt; 
&lt;h4&gt;客户端&lt;/h4&gt; 
&lt;p&gt;3FS 的客户端除了提供 FUSE 操作外，还提供了一组 API 用于绕过 FUSE 直接操作数据，也就是 Native Client，接口的调用方式有点类似于 Linux AIO。这组 API 的作用是避免使用 FUSE 模块带来的数据拷贝，从而减少 I/O 延迟和对内存带宽的占用。下面将详细解析这组 API 如何实现用户进程与 FUSE 进程之间的零拷贝通信。&lt;/p&gt; 
&lt;p&gt;3FS 通过 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存共享内存的大小，地址和其他一些属性，使用 &lt;code&gt;IoRing&lt;/code&gt; 在两个进程间通信。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-abcb70acca194a50f90a6a422695f8d89db.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当用户调用接口，创建 &lt;code&gt;hf3fs_iov&lt;/code&gt; 时，会在 &lt;code&gt;/dev/shm&lt;/code&gt; 上分配内存,并创建一个指向这个共享内存的软链接，软链接的地址位于 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt;,这是个虚拟目录。3FS FUSE 进程收到创建软链接请求，并且发现它的地址位于上述虚拟目录后，就会根据软链接的名字解析出这块共享内存的相关参数，并将内存的地址注册到所有 RDMA 设备（除了 &lt;code&gt;IORing&lt;/code&gt; ）。&lt;code&gt;ibv_reg_mr&lt;/code&gt; 返回的结果被存在 &lt;code&gt;RDMABuf::Inner&lt;/code&gt; 数据结构中，用于后续发送 RDMA 请求。&lt;/p&gt; 
&lt;p&gt;同时，&lt;code&gt;IORing&lt;/code&gt; 的内存也使用 &lt;code&gt;hf3fs_iov&lt;/code&gt; 保存，只是在创建对应的软链接时，文件名中会有更多的 &lt;code&gt;IORing&lt;/code&gt; 相关的信息。如果 FUSE 进程发现这个内存是用于创建 &lt;code&gt;IORing&lt;/code&gt;，也会在它的进程内创建对应的 &lt;code&gt;IORing&lt;/code&gt;。这样设置之后，用户进程和 FUSE 进程就可以访问相同的 &lt;code&gt;IORing&lt;/code&gt; 了。&lt;/p&gt; 
&lt;p&gt;进程间协作方面，3FS 在 &lt;code&gt;/mount_point/3fs-virt/iovs/&lt;/code&gt; 目录中创建 3 个不同的虚拟文件用于共享 3 个不同优先级的提交信号量 （submit sem ），用户进程将请求放到 &lt;code&gt;IORing&lt;/code&gt; 后使用这些信号量通知 FUSE 进程有新的请求。 &lt;code&gt;IORing&lt;/code&gt; 尾部包含请求完成信号量，FUSE 进程通过调用 &lt;code&gt;sem_post&lt;/code&gt; 通知用户进程 &lt;code&gt;IORing&lt;/code&gt; 上有新的请求完成。以上整个机制确保了两个进程间的高效数据通信和操作同步。&lt;/p&gt; 
&lt;p&gt;3FS 的 FUSE 客户端实现了文件和目录的基本操作，而 JuiceFS FUSE 客户端的实现更加全面。比如，在 3FS 文件系统中文件的长度是最终一致的，这意味着在写的过程中用户可能访问到不正确的文件长度。而 JuiceFS 在每次成功上传对象后会立即更新文件长度。此外，JuiceFS 还提供了以下这些常用的高级文件系统功能：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持 BSD 锁（flock）和 POSIX 锁（fcntl）&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;file_copy_range&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;readdirplus&lt;/code&gt; 接口&lt;/li&gt; 
 &lt;li&gt;支持 &lt;code&gt;fallocate&lt;/code&gt; 接口&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除了 FUSE 客户端，JuiceFS 还提供 Java SDK，S3 Gateway，CSI Driver 等接入方式。企业版还提供 Python SDK，Python SDK 将 JuiceFS 客户端在用户进程中运行，避免了通过 FUSE 导致的额外性能开销。具体见文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcloud%2Fdeployment%2Fpython-sdk%2F&quot; target=&quot;_blank&quot;&gt;Python SDK&lt;/a&gt;。&lt;/p&gt; 
&lt;h2&gt;02 文件分布对比&lt;/h2&gt; 
&lt;h3&gt;3FS 文件分布&lt;/h3&gt; 
&lt;p&gt;3FS 将每个文件分成固定长度的 chunk，每个 chunk 位于一个上文提到的链上（ CRAQ 算法）。用户使用 3FS 提供的一个脚本，生成一个 chain table。然后将这个表提交到元数据服务。创建新文件时，系统会从表中选取特定数量的 chain （数量由 stripe 定义），并将这些 chain 的信息存入文件的元数据中。&lt;/p&gt; 
&lt;p&gt;因为 3FS 中的 chunk 是固定的，客户端只需要获取一次 inode 的 chain 信息，就可以根据文件 inode 和 I/O 请求，的 offset，length 计算出这个请求位于哪些 chunk 上，从而避免了每个 I/O 都从数据库查询的需求。可以通过 &lt;code&gt;offset/chunk_size&lt;/code&gt; 得到 chunk 的索引。 而 chunk 所在的 chain 的索引就是 &lt;code&gt;chunk_id%stripe&lt;/code&gt;。有了 chain 的索引就可以得到 chain 的详细信息（比如这个 chain 由哪些 target 组成）。然后，客户端根据路由信息将 I/O 请求发送到相应的存储服务。存储服务收到写请求后以 copy-on-write （COW）的方式将数据写入新的位置。原来的数据在引用数据清零前仍然是可读的。&lt;/p&gt; 
&lt;p&gt;为了应对数据不平衡问题，每个文件的第一个 chain 按照轮询（ round roubin） 的方式选择。比如当 stripe 为 3 时，创建一个文件，其选择的 chain 为：chain0，chain1，chain2。那么下一个文件的 chain 为：chain1，chain2 和 chain3。系统会将选择的 3 个 chain 做随机排序，然后存储到元数据中。下图为 stripe 为 3 时一个文件的分布示例，chain 随机排序后的顺序是：1，3，2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cf9e25c0851f3f04955915e8e7ea4ffd658.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;JuiceFS 文件分布&lt;/h3&gt; 
&lt;p&gt;JuiceFS 按照 Chunk、Slice、Block 的规则进行数据块管理。每个 Chunk 的大小固定为 64M，主要用于优化数据的查找和定位。实际的文件写入操作则在 Slice 上执行，每个 Slice 代表一次连续的写入过程，属于特定的 Chunk，并且不会跨越 Chunk 的边界，因此长度不超过 64M。Chunk 和 Slice 主要是逻辑上的划分，而 Block（默认大小为 4M）则是物理存储的基本单位，用于在对象存储和磁盘缓存中实现数据的最终存储。更多细节可以参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2Fdocs%2Fzh%2Fcommunity%2Farchitecture&quot; target=&quot;_blank&quot;&gt;官网介绍&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-db8518e62e6de3e60bb23e2080a1ee55222.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS 中的 Slice 是在他文件系统中不常见的一个结构。主要功能是记录文件的写入操作，并在对象存储中进行持久化。对象存储不支持原地文件修改，因此，JuiceFS 通过引入 Slice 结构允许更新文件内容，而无需重写整个文件。这与 Journal File System 有些类似，其中写入操作仅创建新对象，而不是覆盖现有对象。修改文件时，系统会创建新的 Slice，并在该 Slice 上传完毕后更新元数据，从而将文件内容指向新的 Slice。被覆盖的 Slice 内容随后通过异步压缩过程从对象存储中删除，导致在某些时刻对象存储的使用量会暂时超过文件系统实际使用量。&lt;/p&gt; 
&lt;p&gt;此外，JuiceFS 的所有 Slice 均为一次性写入，这减少了对底层对象存储一致性的依赖，并大大简化了缓存系统的复杂度，使数据一致性更易于保证。这种设计还为实现文件系统的零拷贝语义提供了便利，支持如 copy_file_range 和 clone 等操作。&lt;/p&gt; 
&lt;h2&gt;03 3FS RPC (Remote Procedure Call) 框架&lt;/h2&gt; 
&lt;p&gt;3FS 使用 RDMA 作为底层网络通信协议，目前 JuiceFS 尚未支持，下面对此做一些分析。&lt;/p&gt; 
&lt;p&gt;3FS 通过实现一个 RPC 框架，来完成对底层 IB 网络的操作。除了网络操作外，RPC 框架还提供序列化，小包合并等能力。因为 C++ 不具有反射能力，所以 3FS 还通过模版实现了一个反射库，用于序列化 RPC 使用的 request、response 等数据结构。需要被序列化的数据结构只需要使用特定的宏定义需要序列化的属性。RPC 调用都是异步完成的，所以序列化后的数据只能从堆上分配，等待调用完成后再释放。为了提高内存的分配和释放速度，分配对象都使用了缓存。3FS 的缓存有两部份组成，一个 TLS 队列和一个全局队列。 从 TLS 队列获取缓存时不需要加锁；当 TLS 缓存为空时就得加锁，从全局队列中获取缓存。所以在最优情况下，获取缓存是不需要加锁的。&lt;/p&gt; 
&lt;p&gt;与 I/O 请求的负载不同，缓存对象的内存都未注册到 RDMA 设备中。因此，当数据到达 IBSocket 后，会被拷贝到一个在 IB 设备注册过的缓冲区中。多个 RPC 请求可能被合并为一个 IB 请求发送到对端。下图为 FUSE Client 调用 Meta 服务的 RPC 过程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//58e38641fd7da6914308fa2198428dc9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;04 特性对比&lt;/h2&gt; 
&lt;p&gt;| 对比项 | 3FS | JuiceFS 社区版 | JuiceFS 企业版 | |--------------------|-------------------------------|----------------------------------|----------------------------------------------| | 元数据 | 无状态元数据服务+FoundationDB | 独立数据库服务 | 自研高性能分布式元数据引擎（可横向扩展） | | 数据存储 | 自主管理 | 使用对象存储 | 使用对象存储 | | 冗余保护 | 多副本 | 对象存储提供 | 对象存储提供 | | 数据缓存 | 无缓存 | 本地缓存 | 自研高性能多副本分布式缓存 | | 数据加密 | 不支持 | 支持 | 支持 | | 数据压缩 | 不支持 | 支持 | 支持 | | 配额管理 | 不支持 | 支持 | 支持 | | 网络协议 | RDMA | TCP | TCP | | 快照 | 不支持 | 支持克隆 | 支持克隆 | | POSIX ACL | 不支持 | 支持 | 支持 | | POSIX 兼容性 | 少量子集 | 完全兼容 | 完全兼容 | | CSI 驱动 | 没有官方支持 | 支持 | 支持 | | 客户端 | FUSE + Native Client | POSIX（FUSE）、Java SDK、S3 网关 | POSIX（FUSE）、Java SDK、S3 网关、Python SDK | | 多云镜像 | 不支持 | 不支持 | 支持 | | 跨云和跨区数据复制 | 不支持 | 不支持 | 支持 | | 主要维护者 | DeepSeek | Juicedata | Juicedata | | 开发语言 | C++, Rust (本地存储引擎) | Go | Go | | 开源协议 | MIT | Apache License 2.0 | 商业软件 |&lt;/p&gt; 
&lt;h2&gt;05 总结&lt;/h2&gt; 
&lt;p&gt;大规模 AI 训练中最主要的需求是高读带宽，为此 3FS 采用了性能优先的设计策略，将数据存储在高速磁盘上，并且用户需要自行管理底层数据存储。这种方法提升了性能，但成本较高，维护也更繁重。此外，为了充分发挥底层硬件的性能，其架构实现了客户端到网卡的零拷贝，利用共享内存和信号量减少 I/O 延迟和内存带宽占用。此外，通过带 TLS 的 I/O buffer pool 和合并网络请求，3FS 增强了小 I/O 和文件元数据操作的能力，并引入了性能更优的 RDMA 技术。我们将继续关注 3FS 在性能优化方面的进展，并探索如何将这些技术应用于我们的场景中。&lt;/p&gt; 
&lt;p&gt;JuiceFS 使用对象存储作为底层数据存储，用户因此可大幅降低存储成本并简化维护工作。为了满足 AI 场景的对读性能的需求，JuiceFS 企业版引入了分布式缓存、分布式元数据服务和 Python SDK，从而提高文件系统的性能和扩展能力，并同时兼顾低存储成本。在接下来发布的 v5.2 企业版中，在 TCP 网络中实现了零拷贝，进一步提升数据传输效率。&lt;/p&gt; 
&lt;p&gt;JuiceFS 提供完整的 POSIX 兼容性和成熟活跃的开源生态，适应更广泛的使用场景，并支持 Kubernetes CSI，极大简化了云平台的部署和运维工作。此外，JuiceFS 还提供了 Quota、安全管理和数据灾备等多项企业级管理功能，让企业可以更便捷地在生产环境中部署和应用 JuiceFS。&lt;/p&gt; 
&lt;p&gt;希望这篇内容能够对你有一些帮助，如果有其他疑问欢迎加入 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjuicefs.com%2F&quot; target=&quot;_blank&quot;&gt;JuiceFS 社区&lt;/a&gt;与大家共同交流。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5389802/blog/17937022</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5389802/blog/17937022</guid>
            <pubDate>Wed, 05 Mar 2025 06:54:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Roblox 公布生成式 AI 模型 Roblox Cube</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 17 日，Roblox 公布了自己的生成式 AI 模型 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcorp.roblox.com%2Fnewsroom%2F2025%2F03%2Fintroducing-roblox-cube&quot; target=&quot;_blank&quot;&gt;Roblox Cube&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;926&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0318/144726_7BvT_2720166.png&quot; width=&quot;1618&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;游戏公司 Roblox 曾于去年宣布将建立一个开源的三维基础模型，用于在 Roblox 中创建三维物体与场景。&lt;/p&gt; 
&lt;p&gt;本周，Roblox 将开源名为 Cube 3D 的模型首个版本，任何人都可以在 Roblox 平台内外使用。同时发布的还有网格生成 API 的 beta 版。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1906054f0606ef1676bb4e26ab93a24aed.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;官方示例提示词：A red buggy with knobby tires（装有凸高花纹越野胎的红色越野车）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Cube 3D 可以从文字直接生成 3D 模型与环境，未来还将支持以图生模型。Roblox 期望最终模型能完成加入物体-环境-人互动维度的 4D 创造。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/339570/oblox-cube</link>
            <guid isPermaLink="false">https://www.oschina.net/news/339570/oblox-cube</guid>
            <pubDate>Wed, 05 Mar 2025 06:48:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>在 RISC-V 上构建 AI 应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;当开源指令集 RISC-V 遇上 AI 大模型，会碰撞出怎样的未来图景？&lt;/p&gt; 
&lt;p&gt;中国科学院软件研究所工程师张旭阳和他所在的团队正在研究 AI 大模型在 RISC-V 架构上的多项应用与实践。&lt;/p&gt; 
&lt;p&gt;3 月 22 日，张旭阳将出席 OSC 源创会南京站活动，发表《RISC-V 上 AI 应用与实践》，通过自主研发的 AI 助手展示如何借助 RISC-V 架构构建高效、灵活的 AI 助手，实现智能交互与数据处理。&lt;/p&gt; 
&lt;p&gt;同时张旭阳还将分享 Qwen、DeepSeek、LLama 和 Stable Diffusion 等知名模型在 RISC-V 上应用的最新进展。&lt;/p&gt; 
&lt;p&gt;在活动开始前，我们和张旭阳简单聊了聊 RISC-V + AI 的技术创新与生态构建，欢迎想了解具体如何在 RISC-V 上构建 AI 应用的开发者到现场交流，报名链接：&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1014&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-015bbdaaa23e8ca63a6d14af2bc8f95c1a0.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 对 AI 来说，是「乐高积木」还是「瑞士军刀」？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我觉得更像是乐高积木吧，因为 RISC-V 的架构更加开发，所以非常易于针对不同场景进行定制。用户根据不同的场景需要，定制化的设计芯片，可以扩展指令集，可以在 Soc 上集成各种类型的处理器。同时因为 RISC-V 的特性，做同样的工作，相比 x86 和 arm 来说，功耗更低。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;把 Qwen、DeepSeek 这些「大胖子」模型塞进 RISC-V，需要先帮它们「瘦身」吗？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我们都知道 Qwen 是阿里推出的一系列优秀的开源模型，Qwen 的优点就是，模型参数覆盖比较广，最小的模型参数只有 1.5b 。我们目前成功在基于 TH1520 的 RUYIBOOK 上跑通了 Qwen2.0-1.5B 的小模型，以及 DeepSeek-R1-Distill-Qwen-1.5B 模型。同时在算能 SG2042 和 SG2044 的环境上，跑通了 DeepSeek-R1-Distill-Qwen-1.5B，DeepSeek-R1-Distill-Qwen-7B 等模型，借助于 TPU 的算力，这些精简的模型也可以跑出相对不错的性能。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;RISC-V 架构上的自研 AI 助手突出优势是什么？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;我们自研的 AI 助手，可以说是 RISC-V 的原住民，也是首款基于 RISC-V 桌面生态环境的原生开发的 AI 助手，它可以原生运行在我们的自研的开源 RISC-V 笔记本 RUYIBOOK 甲辰版上，除了基础的文字问答功能之外，还有图片理解，文生图，语音合成等多模态功能。同时借助大模型的能力，可以通过文字或者语音的方式直接对操作系统做一些基础的控制。比如说调节音量，调节屏幕亮度，打开关闭应用，搜索文件并打开等。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;Stable Diffusion 在 RISC-V 上画图，实测生成一张图要多久？效果如何？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;目前基于算能 SG2044 的测试情况，在 TPU 加速情况下，StableDiffusionV1.5 模型生成一张图大约 5-6s，StableDiffusionXL 模型生成一张图大约是 40-50s。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;开发者最怕「从入门到放弃」，有没有开箱即用的工具包？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;可以关注一下中科院软件所 PLCT 实验室所出的 RuyiSDK 开发工具集。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;RISC-V 开发板镜像相关信息以及下载、安装教程，便于开发者获取相关镜像（换而言之提供一个镜像站），其中涵盖多种操作系统（如基于 Debian 的 RevyOS、openEuler RISC-V 等）提供给开发者使用。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;提供 RISC-V 开发板对应的演示程序、开发资料和相关工具（含适用的编译工具链、模拟器等）的信息维护和下载，方便 RISC-V 开发者快速上手。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;在集成开发环境中增加 RISC-V 设备专有向导页面、实现开发环境和运行环境的文件传输、支持在 RISC-V 设备上调试应用程序等。&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;玩转 RISC-V + AI 需要点亮哪些技能树？&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;其实如果感兴趣的话，完全可以自己买一个开发板先玩起来，因为技能是可以在实践的过程中逐步去学习的。无论是 AI 相关的，还是 RISC-V 相关的。只要你有一定的计算机专业基础，然后又会一两门开发语言，比如 C,C++,python 等。那么就可以自己利用开发板来做一些研究和学习。咱们的大部分普通人的目的可能并不在于搞出一个 DeepSeek，而是看看能利用 DeepSeek 做些什么。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;预言时间：RISC-V + AI 组合拳，3 年内能 KO 传统架构吗？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;张旭阳：&lt;/strong&gt;这个时间点我不好预估，因为无论是 AI 软件栈，还是 RISC-V 都在快速发展中，他们都还没有达到一个成熟期。但是呢，我认为在开源开放，合作共赢的生态下，RISC-V 和 AI 未来一定可以拿出一些标杆级的应用，可以在某些应用场景下落地生根。我们和传统的指令集架构，很长时间都是共生共存的关系。并不是说要 KO 掉谁。但我们因为灵活扩展等特性，可能未来在 AI 领域比传统指令集更加容易去开拓。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;strong&gt;即刻报名&lt;/strong&gt;，现场探智能体设计与使用问题&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🔥报名链接：&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2423811&quot;&gt;https://www.oschina.net/event/2423811&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;⏰时间：03-22 14:00 至 18:00&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;🚗地点：南京瑞澜庭院酒店（南京秦淮区瑞金路街道解放路 46 号）&lt;/p&gt; 
&lt;p style=&quot;text-align:left&quot;&gt;&lt;img height=&quot;2367&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7a57781b43c33abfad271e2d16b2f1eca4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17937477</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17937477</guid>
            <pubDate>Wed, 05 Mar 2025 06:46:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>