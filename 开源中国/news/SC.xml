<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 19 Aug 2025 03:33:19 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>理想汽车 MindGPT 3.1 发布：速度跃升近 5 倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;理想汽车正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FITMmZOSYW6AHbmuyosix7A" target="_blank"&gt;宣布&lt;/a&gt;其自研的 MindGPT 大模型迎来重大升级，全新版本 MindGPT3.1 惊艳亮相。此次升级将智能体能力深度融入大模型之中，实现了边想边搜的创新功能，即在推理过程中能够同步调用各类工具，从而为用户提供更加迅速、全面且精准的结果反馈。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;官方数据显示，MindGPT3.1 在性能上实现了质的飞跃，每秒出字速度最高可达 200tokens，相较于前代 MindGPT3.0，速度提升近 5 倍，这一突破将极大提升用户与智能助手的交互效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="332" src="https://oscimg.oschina.net/oscnet/up-962a85cad4a4b3153db1d3b7bb925463d03.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;MindGPT3.1 不仅速度惊人，更在智能交互层面展现出卓越实力。它深度融合了推理思维链及工具调用能力，模型能够像资深分析师一样，层层拆解复杂问题，通过「自主思考-自主调用工具-进一步推理」的循环机制，不断优化答案质量，使得复杂任务的完成率得到显著提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在核心能力维度上，MindGPT3.1 同样表现出色。在数学、代码、科学问答以及指令遵循等方面，其指标均全面优于 MindGPT3.0，并领先于行业内的开源模型如 Qwen3-235B 等。特别是在代码能力上，MindGPT3.1 实现了进一步增强，能够轻松实现贪吃蛇、弹球控制等经典编程样例，展现了其强大的技术实力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367111</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367111</guid>
      <pubDate>Tue, 19 Aug 2025 03:31:18 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「阿里淘宝第一个程序员」加入 AI 创业公司，后者创始人曾是阿里研究员</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据贝联珠贯创始人毕玄（原阿里花名，本名林昊）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkPvjh7g5aog-c5gsE6eu2Q%3Fclick_id%3D222" target="_blank"&gt;公众号消息&lt;/a&gt;，阿里「扫地僧」多隆已于 8 月 6 日加入贝联珠贯，担任联合创始人兼首席架构师，专注 AI Agent 运维平台。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1154" src="https://static.oschina.net/uploads/space/2025/0819/112421_dsfV_2720166.png" width="1394" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;毕玄在文章中提到：很神奇，我和多隆都没有想到，在 AI 时代，我们竟然又有了联手做点事情的机会和缘分，这个事情就是基于 AI Agent 来改变运维服务，让每家公司都有 N 个不同领域的「多隆」，从而提升运维服务的质量和效率。&lt;/p&gt; 
&lt;p&gt;蔡景现花名「多隆」，早在 2000 年就加入了阿里巴巴，是淘宝初创团队的三个开发工程师之一，被称为淘宝第一个程序员，曾主导构建了淘宝交易系统和论坛系统。2025 年 8 月 1 日，&lt;a href="https://www.oschina.net/news/365665" target="_blank"&gt;多隆宣布离职&lt;/a&gt;，结束了他整整 25 年的阿里生涯。&lt;/p&gt; 
&lt;p&gt;毕玄，2007 年加入阿里，曾打造了阿里重要的中间件 HSF 服务框架，先后任职淘宝网平台架构部架构师、集团核心系统研发部资深技术专家、阿里中间件负责人。2021 年 8 月，毕玄以阿里云视频云负责人（P10）的身份离职，后创立贝联珠贯，担任 CEO。据悉，贝联珠贯科技成立于 2021 年 11 月，致力于为用户提供大数据、AI 基础设施的产品服务，帮助企业快速实现数智化转型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367109</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367109</guid>
      <pubDate>Tue, 19 Aug 2025 03:25:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>得州总检察长调查 Meta 和 Character.AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;得克萨斯州总检察长肯・帕克斯顿已于周一发布新闻稿，宣布对 Meta 人工智能工作室（Meta AI Studio）和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 展开调查，理由是这两家公司 「可能存在欺骗性贸易行为，并将自身误导性地宣传为心理健康工具」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-8a5fb71acb3eb1bc8ee366cb57883920a14.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「在当今数字时代，我们必须持续努力保护得州儿童免受欺骗性和剥削性技术的伤害」， 新闻稿援引帕克斯顿的话称，「人工智能平台通过伪装成情感支持来源，可能会误导易受影响的用户，尤其是儿童，让他们误以为自己正在接受合法的心理健康服务。但实际上，这些平台往往提供的是经过循环利用的通用回应，这些回应是根据收集到的个人数据设计的，却被伪装成治疗建议。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次调查发生在参议员乔希・霍利宣布对 Meta 展开调查的几天后。此前有报告发现，Meta 的人工智能聊天机器人与儿童存在不当互动，包括调情行为。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;得州总检察长办公室指控 Meta 和 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 打造的人工智能角色 「冒充专业治疗工具，尽管它们缺乏正规的医疗资质或监管」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在 &lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 平台上数百万个人工智能角色中，一个名为 「心理学家」（Psychologist）的用户创建机器人在该初创公司的年轻用户中需求旺盛。与此同时，Meta 虽未为儿童提供治疗类机器人，但并未阻止儿童使用 Meta 人工智能聊天机器人或第三方创建的用于治疗目的的角色。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我们对人工智能进行了明确标注，并且为了帮助人们更好地了解其局限性，我们添加了免责声明，说明回应由人工智能生成而非人类」，Meta 发言人瑞安・丹尼尔斯称，「这些人工智能并非持照专业人士，我们的模型在适当情况下会引导用户寻求合格的医疗或安全专业人员的帮助。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，媒体指出，许多儿童可能不理解此类免责声明，或者干脆无视它们。我们已向 Meta 询问其为保护使用聊天机器人的未成年人采取了哪些额外保障措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯顿在声明中还指出，尽管人工智能聊天机器人声称会保密，但它们的 「服务条款显示，用户互动会被记录、追踪，并被用于定向广告和算法开发，这引发了关于隐私侵犯、数据滥用和虚假宣传的严重担忧」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据 Meta 的隐私政策，Meta 确实会收集与人工智能聊天机器人的交互提示、反馈以及跨 Meta 服务的其他互动，以 「改进人工智能及相关技术」。该政策未明确提及广告相关内容，但指出信息可能会与搜索引擎等第三方共享，以提供 「更个性化的输出」。考虑到 Meta 基于广告的商业模式，这实际上等同于定向广告。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2FCharacter.AI" target="_blank"&gt;&lt;span style="color:#000000"&gt;Character.AI&lt;/span&gt;&lt;/a&gt;&lt;span style="color:#000000"&gt; 的隐私政策也强调，该初创公司会记录用户的标识符、人口统计数据、位置信息以及更多用户相关信息，包括浏览行为和应用使用平台。它会跨 TikTok、YouTube、Reddit、Facebook、Instagram 和 Discord 等平台的广告追踪用户，并可能将这些追踪数据与用户账户关联。这些信息被用于训练人工智能、根据个人偏好定制服务，以及提供定向广告，包括与广告商和分析提供商共享数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Meta 和 Character 均表示，其服务并非为 13 岁以下儿童设计。尽管如此，Meta 因未能监管 13 岁以下儿童创建的账户而备受批评，而 Character 的儿童友好型角色显然旨在吸引更年轻的用户。该初创公司的首席执行官卡兰迪普・阿南德甚至表示，他 6 岁的女儿也在使用该平台的聊天机器人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此类数据收集、定向广告和算法剥削行为，正是《儿童在线安全法》（KOSA）等立法旨在防范的内容。《儿童在线安全法》去年曾在两党强烈支持下有望通过，但在科技行业说客的强烈反对后陷入停滞。Meta 尤其动用了强大的游说力量，警告议员们该法案的广泛授权将削弱其商业模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，田纳西州共和党参议员玛莎・布莱克本和康涅狄格州民主党参议员理查德・布卢门撒尔向参议院重新提交了《儿童在线安全法》。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;帕克斯顿已向这两家公司发出民事调查令 —— 这是要求企业在政府调查期间提供文件、数据或证词的法律命令，以确定它们是否违反了得州消费者保护法。（来源：环球市场播报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367101</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367101</guid>
      <pubDate>Tue, 19 Aug 2025 03:04:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义发布全能图像编辑模型 Qwen-Image-Edit</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义 Qwen 团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FibgZIskZqjnJl9yKgc_ixA" target="_blank"&gt;发布&lt;/a&gt;了 Qwen-Image 的图像编辑版本：Qwen-Image-Edit。&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 基于 20B 的 Qwen-Image 模型进⼀步训练，成功将 Qwen-Image 的独特的文本渲染能力延展至图像编辑领域，实现了对图片中文字的精准编辑。&lt;/p&gt; 
&lt;p&gt;此外，Qwen-Image-Edit 将输⼊图像同时输⼊到 Qwen2.5-VL（实现视觉语义控制）和 VAE Encoder（实现视觉外观控制），从而兼具语义与外观的双重编辑能⼒。&lt;/p&gt; 
&lt;p&gt;如需体验最新模型，访问 Qwen Chat （chat.qwen.ai）并选择「图像编辑」功能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105634_udvl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen-Image-Edit 的主要特性包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;语义与外观双重编辑:&amp;nbsp;Qwen-Image-Edit 不仅⽀持 low-level 的视觉外观编辑（如元素的添加、删除、修改等，要求图片其他区域完全不变），也支持 high-level 的视觉语义编辑（如 IP 创作、物体旋转、风格迁移等，允许整体像素变化但保持语义一致）。&lt;/li&gt; 
 &lt;li&gt;精准⽂字编辑:&amp;nbsp;Qwen-Image-Edit 支持中英文双语文字编辑，可在保留原有字体、字号、风格的前提下，直接对图片中的文字进行增、删、改等操作。&lt;/li&gt; 
 &lt;li&gt;强⼤的基准性能:&amp;nbsp;在多个公开基准测试中的评估表明，Qwen-Image-Edit 在图像编辑任务上具备 SOTA 性能，是一个强大的图像编辑基础模型。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用示例：&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105757_BFM2_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0819/105828_GtUw_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105834_YhPa_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;ModelScope：https://modelscope.cn/models/Qwen/Qwen-Image-Edit&lt;br&gt; Hugging Face：https://huggingface.co/Qwen/Qwen-Image-Edit&lt;br&gt; GitHub：https://github.com/QwenLM/Qwen-Image&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367097</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367097</guid>
      <pubDate>Tue, 19 Aug 2025 02:56:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ARM 挖角亚马逊高管，推进自研芯片计划</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据路透社的最新报道，ARM 最近成功引进了亚马逊 AI 芯片主管拉米・辛诺（Rami Sinno），此举旨在加速公司自研完整芯片的进程。辛诺在亚马逊曾负责开发名为 「Trainium」 和 「Inferentia」 的 AI 芯片，这些芯片专为支持大型 AI 应用程序而设计。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="331" src="https://oscimg.oschina.net/oscnet/up-02243d99da0363cd55ec78f2f23d25a7871.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 的目标是从一个单纯提供芯片知识产权的供应商，转型为能够独立设计和生产完整芯片的企业。随着技术的发展，市场对自研芯片的需求日益增加，ARM 希望在这一领域抢占先机。去年 12 月，ARM 在一场审判中披露了其自研芯片的计划，并表示将通过挖角竞争对手的高管来实现这一目标。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;辛诺的加盟被认为是 ARM 实现这一战略的重要一步。除了辛诺，ARM 近期还从其他公司挖来了多位高管，包括具备大规模系统设计经验的慧与科技高管，以及来自英特尔的芯片架构师。这些新任高管的加入将为 ARM 在自研芯片方面带来更强的技术支持和经验积累。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;近年来，ARM 不断加强其在完整芯片和系统设计方面的团队建设，希望借助这些人才的专业背景与技术能力，推动公司的发展。芯片产业竞争愈发激烈，各大公司都在积极寻求突破，ARM 的这一战略调整将对其未来的市场表现产生重要影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;ARM 自成立以来一直以其创新的芯片架构而闻名，随着市场需求的变化，该公司意识到需要不断进化以适应新的挑战。通过引入行业精英，ARM 不仅能够提升其技术实力，也能进一步拓展其市场份额，确保在未来的竞争中立于不败之地。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367095</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367095</guid>
      <pubDate>Tue, 19 Aug 2025 02:54:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义 Qwen Chat 更新视觉理解功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义 Qwen 团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FIc0QlqvjyLG1xCR59QOZKA" target="_blank"&gt;宣布&lt;/a&gt;对其&amp;nbsp;Qwen Chat&amp;nbsp;中的视觉理解功能进行更新。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/105358_jvXb_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此次更新被称为「小而强大」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持原生 128K 上下文&lt;/li&gt; 
 &lt;li&gt;显著提升数学推理与物体识别能力&lt;/li&gt; 
 &lt;li&gt;OCR 支持扩展至 30 多种语言&lt;/li&gt; 
 &lt;li&gt;2D/3D 定位更精准&lt;/li&gt; 
 &lt;li&gt;视频理解与定位能力大幅度增强，整体视觉智能更强大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;该升级或与阿里云百炼平台上近期更新的通义千问 VL-MAX 有关，其 2025 年 8 月 13 日的快照版本显示，视觉理解指标得到全面提升。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367093</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367093</guid>
      <pubDate>Tue, 19 Aug 2025 02:54:59 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>架构提效的矛盾和矛盾的主要方面</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在软件开发领域，架构设计是确保系统高效、稳定运行的重要环节或者称之为重要动作。无论架构从简单到复杂，还是从复杂回归简洁的演变过程。在这个过程中，又无论是初创公司还是大型企业，架构提效始终是技术团队的核心追求。本文将从稳定、性能、代码三大维度出发，结合实战经验，探讨如何有效提升架构效能。&lt;/p&gt; 
&lt;p&gt;为什么要选择或者认为这三个维度是必要要素呢？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「一切事物中包含的矛盾方面的相互依赖和相互斗争，决定一切事物的生命，推动一切事物的发展。没有什么事物是不包含矛盾的，没有矛盾就没有世界。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;当然架构也有自身的矛盾统一，在架构提效上，系统的运行正常和问题频出是一对矛盾，功能的快和慢是一对矛盾，工程的整洁有序和无序是一对矛盾。这三对矛盾正是架构提效的矛盾。&lt;/p&gt; 
&lt;p&gt;如果不稳定，系统三天两头出故障，研发人员成了救火队员，系统的效率将无从谈起，稳定是我们谈架构效率的基础。如果性能不高，在网络基础环境稳定的情况下，访问一个页面 3S 才响应，那我们也不好意思说架构有效率。如果代码乱成一锅粥，比如大段大段面条式的代码，再比如满眼望去 N 多个 if 结构语句，研发人员加一个功能都要查找好久，也是无颜谈效率。&lt;/p&gt; 
&lt;p&gt;因此，我们认为，稳定、性能、代码是架构提效矛盾中的主要方面。接下来我们将从这三个主要方面去介绍。&lt;/p&gt; 
&lt;p&gt;软件工程发展了这么多年，高可用、高扩展、高并发已经有大量的文章篇幅，从宏观的角度去讲如何做微服务、如何分库分表，如何使用缓存等等。因此呢，本篇文章想聚焦到架构矛盾的微观层面，也就是偏工程结构、偏代码方面去阐述这三个要素。另外本篇文章的思想也参考了前辈们的研究成果，我也附在了文末。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;稳定：架构的基石与守护神&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「万事万物都是运动的，发展的」。业务功能变多，用户数量变多，团队规模变大。如果没有规则和规范的引导和约束，系统逐渐野蛮生长，逐渐碎片化。那么，我们的系统何谈稳定呢。&lt;/p&gt; 
&lt;p&gt;我们就希望能找到这样的一种规则、规范 -- 正交分解或者叫做正交设计。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//bb82ceb06e46d5d6d4365e615d3f3785.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;架构设计的过程就是一个业务正交分解的过程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;架构设计并不仅仅是技术层面的规划，更重要的是对业务逻辑的深入理解和把握。通过正交分解，我们可以将复杂的业务系统拆解成若干个相互独立但又彼此关联的模块或组件。这些模块或组件在保持功能完整性的同时，还能实现高度的内聚和松散的耦合，从而提高系统的可扩展性、可维护性和可重用性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;正交分解的关键在于消除重复、分离关注点和管理依赖。通过这一方法，我们可以将业务系统中的公共部分和可变部分进行明确的划分，从而实现对业务逻辑的精准掌控。在架构设计过程中，我们需要不断地对业务进行抽象和分解，直至得到一系列规模可控、结构清晰的小模块。这些小模块通过组合和协作，能够形成更加复杂且功能完善的软件系统。&lt;/p&gt; 
&lt;p&gt;因此，正交分解的思想是我们架构设计保障稳定的重要方法基础。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;性能：速度与效率的双重考验&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;想快，就使用「战术设计」。曾经这是很多程序员的法宝，因为他们认为这样开发「确实快」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//0e3d7156e3234d0517c9adb69369faf3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;大多数程序员以称为战术编程的心态来进行软件开发。在战术方法中，主要重点是使某些功能正常工作，例如新功能或错误修复。乍一看，这似乎是完全合理的：还有什么比编写有效的代码更重要的呢？但是，战术编程几乎不可能产生出良好的系统设计。&lt;/p&gt; 
&lt;p&gt;想快的「战术设计」会造成常见的下面这样的情况。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「团队新人不熟悉系统，为了急于上线一个特性，又不想影响到系统的其他部分，就会很自然地在某个地方加一个 flag，然后在所有需要改动的地方加 if 判断，而不是去调整系统设计以适应新的问题空间。」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在一个充满活力的软件开发团队中，新成员小张刚刚加入不久。他对于团队正在使用的复杂系统还不是很熟悉，但面对紧迫的项目进度和上级施加的压力，他急于证明自己，并希望能尽快为团队做出贡献。团队正计划上线一个新的特性，这个特性需要在不干扰系统其他部分的前提下实现。&lt;/p&gt; 
&lt;p&gt;小张在浏览了系统的代码库后，发现要全面理解并调整整个系统设计以适应新的特性，需要花费大量的时间和精力。他深知自己作为新人，在这方面还有所欠缺，因此，他决定采取一个他认为更为「高效」的方法：在某个关键位置添加一个临时的标志位（flag），然后在所有需要改动的地方都加上 if 判断，以确保新特性能够按时上线，同时尽量减少对现有系统的影响。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//2b037e23421b103a664be64e68b760ae.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;虽然这种方法在短时间内确实让新特性得以顺利上线，但团队中的资深成员很快便发现了潜在的问题。这种做法虽然看似快速解决了问题，但实际上却在系统中埋下了隐患。它不仅增加了代码的复杂性，降低了代码的可读性和可维护性，还可能在未来引发更多的 bug 和性能问题。更重要的是，这种做法违背了软件开发中的最佳实践，&lt;strong&gt;即应通过优化系统设计来适应新的问题空间，而不是通过添加临时性的补丁来解决问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「几乎每个软件开发组织都有至少一个将战术编程发挥到极致的开发人员：战术龙卷风」，而且常常被视为团队」英雄「，因为能「快速完成任务且高产」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;「战术龙卷风」通常以战术编程为主要手段，即采用最快速、最直接的方法来解决当前的问题，而不考虑长远的影响和代码的可持续性。这种方法在初次使用时往往能够取得显著的效果，任务完成得既快又好，赢得了团队成员的赞誉和领导的认可。&lt;/p&gt; 
&lt;p&gt;然而，随着时间的推移，「战术龙卷风」所留下的隐患逐渐暴露出来。由于缺乏对系统设计的深入理解和长远规划，他的代码往往难以维护和扩展。当需要添加新功能或修复 bug 时，团队成员往往需要花费更多的时间和精力来理解和修改他的代码。因此，第二次和第三次修改时，效率会大幅下降，甚至可能引发新的问题。&lt;/p&gt; 
&lt;p&gt;实际造成结果：第一次快、第二次慢、第三次更慢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;代码：简洁与优雅的双重追求&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们做业务开发，代码的优雅简洁，不能局限在一段方法，还是要从整个工程结构然后在到类、到方法，这样从宏观到中观再到微观的整体去要求。我们的应用工程结构，常见大致分为四层。分别是 api 层、biz 层、domain 层和 dao 层。&lt;/p&gt; 
&lt;p&gt;这个时候我们就要很清晰地熟悉每一层的职责，然后将我们的代码放入进去。首先，api 层的作用，正如它的名字一样，是提供 api 服务的。向谁提供 api 呢，比如客户端，比如 APP 端、pc 端等等，公司外面的客户，比如 isv 等。其次，biz 层的作用，这一层也叫业务服务层。它主要负责编排。把一个业务场景下的主流程逻辑处理完成。这个主流程会涉及到多个原子接口，就在这层负责组装。再次，domain 层的作用，也叫做领域服务层。按照 OO 思想，领域编程的思维，我们的」厚对象「的代码都在这层。比如订单域、运费域等。这里对「这一层的位置」多说几句，在没有形成领域之前，这层一般叫 service 层，不过我们都是建议领域思维编写代码。最后是 dao 层，也就是我们的存储层了，负责持久化。&lt;/p&gt; 
&lt;p&gt;在清晰了每一层的作用之后，如果我们的代码职责也是按照这样逐层放入的，那么大体是符合我们的整洁要求的。但是呢，随着时间的推移，需求的增多和变化。原来整洁的工程结构和代码已经不那么优雅了。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这个时候，一般会出现两类现象，一类是业务层（biz）变的臃肿，能力层（domain）变的单薄。另一类是出现了网状调用。而且这两类现象也很有可能是混合在一起出现。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image.png" src="https://oscimg.oschina.net/oscnet//5457bd8fcb8270c8dacce659508d85ba.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这两类现象会直接带来下面 4 种结果。&lt;/p&gt; 
&lt;p&gt;1、biz 层越来越」胖「。胖了之后，还长成了两小层。上小层是面向单一业务场景的「业务 biz 层」，下小层成了通用场景可复用的「通用 biz 层」。&lt;/p&gt; 
&lt;p&gt;2、service 层越来越」瘦「。当 service 层变薄了以后，也就只能沦为 service 了，而这样的 service 层跟 dao 层实际没什么区别，更不能再称之为 domain 层或者没有机会演变成 domain 层。&lt;/p&gt; 
&lt;p&gt;3、但是也不是所有的 service 层都变瘦、变薄了。可能有的萎缩，有的膨胀。人员与设计的差异，导致颗粒度不一。&lt;/p&gt; 
&lt;p&gt;4、出现了网状调用。原本 biz-1 -&amp;gt; service-1 的实现链路下，随着新增业务逻辑，又新起了一个 service-2，链路演变成了 biz-1 -&amp;gt; service-1-&amp;gt; service-2。「这样的趋势持续发展下去，会发现 biz-1 下的 service 调用链路越发的复杂，呈现为一颗深度调用树，而 biz 层失去了业务编排的作用退化为一个业务场景入口的标志符」。有可能后面继续 3-4-5-6，越挖越深，不见尽头。&lt;/p&gt; 
&lt;p&gt;很显然，到这里，这样的结构现状，代码现状，已经远离了我们简洁和优雅的初衷。也谈不上提效了。&lt;/p&gt; 
&lt;p&gt;到此，我们介绍了架构提效中的稳定、性能和代码这三个主要的方面，限于篇幅和架构本身的实践性，还需要我们在架构提效上进行持续的优化。需要我们在稳定、性能、代码三大维度上不断探索和实践。通过高可用架构设计、性能优化策略、模块化与解耦、代码质量与规范等措施，我们可以构建一个既稳定又高效，且易于维护和扩展的系统。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「在复杂的事物发展过程中，有许多的矛盾存在，其中必有一种是主要的矛盾，由于它的存在和发展规定和影响着其他矛盾的存在和发展。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;架构的发展本身也是对抗熵增这一矛盾的过程，我们上面描述的稳定、性能和代码中的矛盾方面有是围绕和关联这一主要矛盾的。在这个过程中不仅有系统的有序变无序，也有组织的简单变复杂。我们既要关注技术层面的提升，更要注重团队协作、知识共享和持续改进的文化建设。只有这样，我们才能在快速变化的市场环境中，保持竞争力，不断前行。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18688507</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18688507</guid>
      <pubDate>Tue, 19 Aug 2025 02:48:59 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达发布全新小型模型 Nemotron-Nano-9B-V2</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达发布了其&lt;span&gt;最新&lt;/span&gt;的小型语言模型（SLM）——Nemotron-Nano-9B-V2。该模型在多个基准测试中表现出色，并在特定测试中达到了同类产品的&lt;span&gt;最高&lt;/span&gt;水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 的参数量为 90 亿，虽然比一些数百万参数的微型模型要大，但它比之前的 120 亿参数版本显著减小，并专门针对单个英伟达 A10GPU 进行了优化。英伟达 AI 模型后训练总监 Oleksii Kuchiaev 解释说，这种调整是为了适配 A10 这款热门的部署 GPU。此外，Nemotron-Nano-9B-V2 是一款混合模型，能处理更大的批次，速度比同等规模的 Transformer 模型快 6 倍。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;该模型支持多达九种语言，包括中、英、德、法、日、韩等，并擅长处理指令跟踪和代码生成任务。其预训练数据集和模型本身都已在 Hugging Face 和英伟达的模型目录中提供。&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;融合 Transformer 与 Mamba 架构&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Nemotron-Nano-9B-V2 基于&lt;span&gt;&amp;nbsp;&lt;/span&gt;Nemotron-H&lt;span&gt;&amp;nbsp;&lt;/span&gt;系列，该系列融合了&lt;span&gt;&amp;nbsp;&lt;/span&gt;Mamba&lt;span&gt;&amp;nbsp;&lt;/span&gt;和&lt;span&gt;&amp;nbsp;&lt;/span&gt;Transformer&lt;span&gt;&amp;nbsp;&lt;/span&gt;架构。传统的 Transformer 模型虽然强大，但在处理长序列时会消耗大量内存和计算资源。而 Mamba 架构则引入了选择性状态空间模型（SSM），能够以线性复杂度处理长信息序列，从而在内存和计算开销上更具优势。Nemotron-H 系列通过用线性状态空间层替换大部分注意力层，在长上下文处理上实现了 2-3 倍的吞吐量提升，同时保持了高精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="218" src="https://oscimg.oschina.net/oscnet/up-ebd73f87284c797290002428bbcbbb7371d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3 style="margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;独特的推理控制功能&lt;/strong&gt;&lt;/h3&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这款模型的一大创新是其内置的「推理」功能，允许用户在模型输出最终答案前进行自我检查。用户可以通过简单的控制符（如&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/think&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/no_think&lt;/code&gt;）来开启或关闭此功能。模型还支持运行时「思考预算」管理，开发者可以限制用于内部推理的令牌数量，从而在准确性和延迟之间取得平衡。这对于客户支持或自主代理等对响应速度有要求的应用场景尤为关键。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="281" src="https://oscimg.oschina.net/oscnet/up-5de1df85730cbf8d4cb29cda3ca17f92329.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达根据其开放模型许可协议发布了 Nemotron-Nano-9B-V2，该协议对企业友好且高度宽松。英伟达明确表示，企业可以自由地将该模型用于商业用途，并且无需为使用该模型支付费用或版税。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管如此，协议仍有一些核心要求，例如用户必须遵守内置的安全机制、在重新分发模型时进行归属标注，并遵守相关法律法规。英伟达表示，该协议旨在确保负责任和合乎道德的使用，而不是通过限制商业规模来盈利。这使得 Nemotron-Nano-9B-V2 成为了那些希望在降低成本和延迟的同时，保持高精度的企业开发者的理想选择。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367083</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367083</guid>
      <pubDate>Mon, 18 Aug 2025 02:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Crossplane 2.0 发布</title>
      <description/>
      <link>https://www.oschina.net/news/367080/crossplane-2-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367080/crossplane-2-0-released</guid>
      <pubDate>Mon, 18 Aug 2025 02:06:00 GMT</pubDate>
    </item>
    <item>
      <title>Qwen Chat 正式发布 Windows 版桌面端应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里通义 Qwen 团队发布了适用于 Windows 系统的 Qwen Chat 桌面版应用。&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;em&gt;https://qwen.ai/download&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="734" src="https://static.oschina.net/uploads/space/2025/0818/192124_WWIt_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1038" src="https://static.oschina.net/uploads/space/2025/0818/192158_OMZi_2720166.png" width="1909" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Windows 版 Qwen Chat 桌面端集成了 Qwen Chat 的全部功能，并新增了对 MCP（Model Context Protocol）的支持，用户可以通过运行 MCP Servers 来提升工作效率。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367001</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367001</guid>
      <pubDate>Sun, 17 Aug 2025 11:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cursor 命令行工具 Cursor CLI 集成 MCP 支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cursor 命令行工具 Cursor CLI 近日发布更新，带来了多项实用功能，进一步提升了终端开发的体验和效率&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;@符号引用&lt;/strong&gt;：现在你可以直接在提示词中使用 @ 符号来引用文件和目录，AI 可以精准地定位上下文，这对于大型项目和复杂的文件操作尤其有用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;审查模式 (Review Mode)&lt;/strong&gt;:通过 Ctrl+R 快捷键，可以进入一个可视化的审查界面，清晰地查看 AI 对代码的修改。这让代码审查变得前所未有的直观和高效。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;/compress 命令&lt;/strong&gt;：这个新命令可以一键释放上下文窗口的空间，优化长对话中的性能和相关性，确保 AI 始终能聚焦在最重要的信息上。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCPs 支持&lt;/strong&gt;：现在 CLI 也支持 MCPs，这意味着你可以利用更丰富的扩展能力来完成复杂任务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="982" src="https://static.oschina.net/uploads/space/2025/0818/190643_waza_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次更新还对用户体验和性能做了一些改进，例如现在显示 Token 计数，支持 AGENTS.md 和 CLAUDE.md（为了兼容 Claude Code）文件。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-de60b8ab05a32ba9549f7fa100f6895787d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;https://cursor.com/cn/cli&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366998</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366998</guid>
      <pubDate>Sun, 17 Aug 2025 11:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程独角兽 Cognition 获近 5 亿美元新融资，估值达 98 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fcognition-cinches-about-500-million-to-advance-ai-code-generation-business-f65f71a9" target="_blank"&gt;据报道&lt;/a&gt;，AI 编程独角兽 Cognition 在新一轮融资中获得了近 5 亿美元，使其估值达到 98 亿美元。&lt;/p&gt; 
&lt;p&gt;Cognition 成立于 2023 年，由三位国际信息学奥林匹克（IOI）金牌得主 Scott Wu、Steven Hao 和 Walden Yan 联合创立。&lt;/p&gt; 
&lt;p&gt;Cognition 的核心产品是被称为首个能自主编程的&lt;a href="https://www.oschina.net/news/282895/cognition-labs-devin" target="_blank"&gt;「AI 程序员」Devin&lt;/a&gt;。今年 7 月，&lt;a href="https://www.oschina.net/news/360382/cognition-devin-acquires-windsurf" target="_blank"&gt;Cognition 收购了 Windsurf&lt;/a&gt;。在本次最新融资之前，Cognition 已筹集了 3 亿美元，投资者包括 8VC、Avenir Growth Capital 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-63fe0533116cdf85964e331427c9d8b851b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;被收购的 Windsurf 截至今年 7 月的年收入已达到 8200 万美元，拥有超过 350 家企业客户和数十万日活跃用户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366994</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366994</guid>
      <pubDate>Sun, 17 Aug 2025 11:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>快手高级副总裁盖坤兼任可灵 AI 技术部负责人</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;快手宣布高级副总裁盖坤兼任可灵 AI 技术部负责人，继续向 CEO 程一笑汇报，进一步强化可灵 AI 在快手战略中的地位。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/183846_pqqc_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据了解，盖坤自 2020 年加入快手后，主导推荐算法、视频生成大模型等技术研发，并推动可灵 AI 成为全球首个对标 Sora 的开放视频生成模型。此次兼任技术负责人，体现快手对可灵 AI 「技术驱动」 战略的重视。&lt;/p&gt; 
&lt;p&gt;公开信息显示，盖坤本科与博士均毕业于清华大学，研究方向为识别与智能系统。2020 年，盖坤正式加入快手，主导内容理解应用、推荐大模型及视频生成大模型的技术布局，推动算法、应用与商业模式的协同创新。2024 年 6 月，盖坤带领团队研发推出全球首个用户可用的 DiT 视频生成模型 —— 可灵 AI 。&lt;/p&gt; 
&lt;p&gt;内部人士分析，盖坤深耕算法技术多年，作为可灵 AI 团队的灵魂人物，此次兼任可灵 AI 技术负责人，显现出可灵 AI 在快手大模型整体战略中的重要地位，也意味着 「技术驱动」 战略，将在很长一段时间内主导着可灵 AI 的发展。&lt;/p&gt; 
&lt;p&gt;自上线以来，可灵 AI 已迭代升级 30 余次，在全球拥有超过 4500 万用户，累计生成超 2 亿个视频和 4 亿张图片，服务超过 2 万家企业客户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366988</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366988</guid>
      <pubDate>Sun, 17 Aug 2025 10:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 技术被滥用成「退款神器」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;据央视新闻报道，近期，电商平台出现一种新型恶意退款行为:部分买家利用人工智能工具伪造商品损坏图片，申请「仅退款」，导致商家遭受货款和运费的双重损失。这一现象引起广泛关注，揭示了 AI 技术被滥用所带来的新挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家们在社交平台吐槽，买家利用 AI 将完好无损的商品，如衣物、杯子或玩具，通过「伪毁损」处理，使其在图片上呈现出碎裂或有瑕疵的状态。这些伪造的图片逼真，让商家难辨真伪。更令人沮丧的是，即使商家察觉到是假图，部分电商平台的自动审核机制仍可能通过退款申请，使得商家在没有收回商品的情况下，被迫退还货款。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="300" src="https://oscimg.oschina.net/oscnet/up-6f9ecd233181d9dac72df712c5ff273ef4b.png" width="186" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;针对这种行为，法律专家指出，利用 AI 伪造图片骗取退款的行为已涉嫌违法。这不仅违背了《民法典》中的诚实信用原则，构成民事欺诈，还可能触犯《治安管理处罚法》。如果骗取金额达到或超过 3000 元，甚至可能构成《刑法》规定的诈骗罪。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;面对这一挑战，专业人士呼吁监管部门、电商平台和商家采取多方面措施共同应对。&lt;span&gt;监管部门应完善法律法规，在《电子商务法》中增设保护商家权益的条款，并明确恶意退款行为的法律后果。同时，强制推行 AI 生成内容标识，并对删除或篡改标识的行为进行处罚。此外，建议建立跨平台的用户消费信用机制，将恶意行为纳入个人征信，从根本上限制其线上活动。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;电商平台需要强化审核机制，减少对 AI 客服的依赖，增加人工审核投入，并延长审查时间，给商家提供充足的举证机会。技术方面，平台应加大投入，利用技术手段验证图片与实物的匹配性，从源头拦截伪造内容。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;商家也需积极自保，优化售后流程，要求买家提供清晰、完整的退款证据，并通过对打包发货全过程录像等方式，留存商品质量证据。若发现恶意行为，应及时向平台反映，情节严重时可直接向公安机关报案，维护自身合法权益。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;AI 技术的初衷是提质增效，但当它被用于不法目的时，对商业生态的破坏力不容小觑。只有多方联动，才能有效遏制这种新型网络欺诈，重建消费者与商家之间的信任。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366985</guid>
      <pubDate>Sun, 17 Aug 2025 10:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元 3D 世界模型推出 Lite 版本，支持消费级显卡部署</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元 3D 世界模型 1.0 于 7 月发布并开源，据称是业界首个开源并兼容传统 CG 管线的可漫游世界生成模型。&lt;/p&gt; 
&lt;p&gt;为了让更多开发者能便捷部署使用混元 3D 世界模型，混元团队近日全新推出 Lite 版本，大幅降低运行显存开销，支持消费级显卡部署。&lt;/p&gt; 
&lt;p&gt;官网地址：https://3d.hunyuan.tencent.com/sceneTo3DGithub&lt;br&gt; 项目地址：https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0&lt;br&gt; Hugging Face 模型地址：https://huggingface.co/tencent/HunyuanWorld-1&lt;br&gt; 技术报告地址：https://arxiv.org/abs/2507.21809&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/175917_MwWM_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了实现对消费级硬件的兼容，该模型采用了多项关键技术优化。首先，通过动态 FP8 量化技术，模型的显存（VRAM）需求从 26GB 降低至 17GB 以下，降幅达 35%，使其能够在消费级 GPU 上流畅运行而不牺牲性能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366980</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366980</guid>
      <pubDate>Sun, 17 Aug 2025 09:59:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>科学岛团队提出医疗大模型智能体决策框架 FRAME</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，中国科学院合肥物质院智能所丁增辉研究员联合华南理工大学靳战鹏教授团队，提出一种医疗大模型智能体决策框架 FRAME。相关研究工作「FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights」被第 63 届国际计算语言学年会录用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;探寻新的医疗洞见和决策方法是辅助医学研究的前沿热点，大语言模型（LLM）的快速发展为该领域研究提供了重大机遇，但在知识整合与质量保证方面仍面临严峻挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;研究团队提出的 FRAME (Feedback-Refined Agent Methodology) 框架，旨在通过迭代式优化和结构化反馈来提升医学洞见性能。该方法包含三大核心创新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;一是构建结构化数据集：通过迭代优化，将医学文献分解为核心研究要素，构建精细化数据集；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;二是搭建「生成-评估-反思」三方智能体架构：集成了生成（Generator）、评估（Evaluator）和反思（Reflector）智能体，通过指标驱动的反馈循环，逐步提升内容质量；&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;三是形成综合评估体系：结合了统计学指标与人工基准，对生成内容进行全方位评测。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="235" src="https://oscimg.oschina.net/oscnet/up-c4c2ee2c274c4fc91ddacb0f45d89761419.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对比实验结果显示，相较于传统方法，FRAME 框架在运用多种大语言模型提升医学洞见性能方面效果显著，在 DeepSeek V3 上平均提升 9.91%，在 GPT-4o Mini 上也取得了同等级别的改进。同时，人工评估也证实了利用 FRAME 智能生成的医疗决策质量已能媲美人类水平，尤其在凝练未来研究方向方面表现突出。相关研究成果表明，所构建的 FRAME 框架，能够自动生成高标准的医学研究方案，高效辅助医学研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="148" src="https://oscimg.oschina.net/oscnet/up-23eebf4bcebc7f140ee46b4658956f09096.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366974</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366974</guid>
      <pubDate>Sun, 17 Aug 2025 09:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源 SSH 客户端 PuTTY 启用新的官方域名：putty.software</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源 SSH 客户端 PuTTY 已正式启用新的官方域名：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;https://putty.software/&amp;nbsp;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0818/173129_GuRm_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原来的域名为：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;https://www.chiark.greenend.org.uk/~sgtatham/putty/&amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;长期以来，由于 PuTTY 的原始官方网址 (www.chiark.greenend.org.uk/~sgtatham/putty/) 较为冗长且不易记忆，许多用户、教程甚至搜索引擎都误将 putty.org 视作官方网站。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;该域名自 2008 年起就被另一家 SSH 厂商 Bitvise 持有，仅作为导航页使用&lt;/span&gt;，提供指向官方 PuTTY 和 Bitvise 自身产品的链接。近期，一位博主就域名所有权问题向 Bitvise 发出问询，被 Bitvise 联合创始人视为挑衅，后者进而从 putty.org 撤下了原有的软件链接，替换为与新冠病毒和疫苗相关的阴谋论视频，&lt;span&gt;并在部分搜索引擎结果中超越 PuTTY 真正的官网。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/173548_kxoQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前，PuTTY 开发者曾经在官网 FAQ 中自信表示，用户不会找错 PuTTY 官方地址，因为 Google 搜索 PuTTY 给出的第一个结果就是正确官网；但事实表明并非如此。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;由于大量用户可能被误导至第三方站点，带来安全风险。为避免混淆并保障用户下载安全，PuTTY 开发团队于 8 月 14 日正式注册并启用简短、可控的新域名 putty.software 作为官方入口。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;官方强调，新域名由开发团队运营，不会用于推广无关的商业软件或意外更改内容。&lt;/p&gt; 
&lt;p&gt;目前，该网址只提供了指向旧站的链接；团队计划在未来将主站迁移至此，但会设置过渡期，以避免用户误认为项目被黑客攻击或接管。&lt;/p&gt; 
&lt;p&gt;www.chiark.greenend.org.uk/~sgtatham/putty/faq.html#faq-domain&lt;br&gt; www.chiark.greenend.org.uk/~sgtatham/putty/&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366972</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366972</guid>
      <pubDate>Sun, 17 Aug 2025 09:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度发布全球首个全端通用智能体 GenFlow2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在百度 AI Day 开放日上，百度文库联合百度网盘重磅发布全球首个全端通用智能体 GenFlow2.0。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="436" src="https://oscimg.oschina.net/oscnet/up-cd7cdee6f0ccde961cd3be40f21eebea22c.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;据官方介绍，GenFlow2.0 展现出强大的并行处理能力，支持超 100 个专家智能体同时协作，能够在 3 分钟内并行完成超 5 项复杂任务。该产品的生成速度超越主流同类型产品 10 倍，在行业内率先实现了分钟级交付的突破性表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;GenFlow2.0 的核心优势体现在三个方面:分钟级交付确保用户快速获得结果，过程可干预让用户能够实时调整和优化，记忆可追溯则为用户提供完整的操作历史记录，大幅提升了智能体的可控性和可靠性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得关注的是，GenFlow2.0 目前已在百度文库 Web 端和 APP 端正式上线，采用开放策略，所有用户均可直接使用，无需排队等待或申请邀请码。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366967</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366967</guid>
      <pubDate>Sun, 17 Aug 2025 09:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>PixiEditor - 2D 图形编辑器</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;strong style="color:#1f2328"&gt;PixiEditor&lt;/strong&gt;是一款通用的 2D 编辑器，旨在为你提供满足所有 2D 需求的工具和功能。你可以为游戏创建精美的精灵图、动画，编辑图像，甚至创建徽标。所有功能都集中在一个直观熟悉的界面中。&lt;/p&gt;

&lt;p&gt;&lt;img height="287" src="https://static.oschina.net/uploads/space/2025/0818/144457_cdjW_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;PixiEditor 2.0 默认配备 3 个工具集：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Pixel art&amp;nbsp;&lt;/strong&gt;- 它包含适合像素完美场景的工具&lt;/li&gt;
&lt;li&gt;&lt;strong style="color:#1f2328"&gt;Painting&amp;nbsp;&lt;/strong&gt;-&amp;nbsp;基本绘画工具、软刷、抗锯齿形状&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector&amp;nbsp;&lt;/strong&gt;- 用于创建 vectors 的形状和路径&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所有&lt;strong&gt;工具集均可在一张画布上使用&lt;/strong&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;vector 与 raster&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;混合。导出为 png、jpg、svg、gif、mp4 等格式！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="300" src="https://static.oschina.net/uploads/space/2025/0818/144519_Vpuk_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="90" src="https://static.oschina.net/uploads/space/2025/0818/144552_suFz_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;&lt;img height="133" src="https://static.oschina.net/uploads/space/2025/0818/144605_5Qoa_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/pixieditor</link>
      <guid isPermaLink="false">https://www.oschina.net/p/pixieditor</guid>
      <pubDate>Sun, 17 Aug 2025 09:00:00 GMT</pubDate>
    </item>
    <item>
      <title>腾讯开源 WeChat-YATT：微信强化学习大模型训练库</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;基于 Megatron&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;-&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Core&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;SGLang&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;LLM&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;研&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;发了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;库&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;WeChat-YATT&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;（&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;Y&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;A&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;T&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;,&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;Yet Another Transformer Trainer&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;内部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;项目&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;为&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;gCore&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，专注于强化学习和多模态模型的训练&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;旨在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;易&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;扩&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;展&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;简洁&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;效&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;可靠&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;通过定制化的并行计算策略，其&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练库&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;能够处理&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大尺寸&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、长序列&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;输入&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和大数据集&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;解决&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;微信&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;实际&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;痛点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;问题&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;显著&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;提升&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;业务&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;效率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;此工具为研究人员和开发者提供了灵活且可扩展的解决方案，以推动多模态和强化学习领域的创新发展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;并提出 WeChat-YATT&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练库&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，解决了大模型分布式训练过程中面临的两大核心痛点：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;多模态场景下的可扩展性瓶颈&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;随着多模态数据（如图像、视频）规模的不断增长，传统架构中由&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Single&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;r&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;l&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;e&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;r&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;进行数据管理，容易成为通讯和内存的瓶颈，导致系统吞吐量受限，甚至引发训练流程异常中断。WeChat-YATT 通过引入&amp;nbsp;&lt;/span&gt;&lt;strong&gt;Parallel Controller&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的并行管理机制，有效分散压力，大幅提升系统的可扩展性和稳定性，更好地应对多模态、大数据量的复杂场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;动态采样&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;与&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;生成式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;奖励&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;下的效率短板&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在需频繁动态采样或生成式奖励计算的训练流程中，模型频繁切换和「长尾」任务容易引发大量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;额外&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;开销&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，导致&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;无法&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;充分&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;利用 GPU&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;算力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，影响整体训练效率。WeChat-YATT 通过&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;分&lt;/span&gt;&lt;strong&gt;共存策略&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;和&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;异步交互&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;大幅度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;减轻模型切换损耗和长尾任务影响，实现了训练过程中的高吞吐量和高资源利用，更好地支撑大规模 RLHF 任务的高效迭代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="234" src="https://oscimg.oschina.net/oscnet/up-79500ef9514ee7d1d3ed000a5d0b1ebe0a2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;WeChat-YATT 针对不同业务场景，支持了两种资源放置模式：全员共存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;与&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;部分共存&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，以最大化提升集群的资源利用率。通过灵活的调度策略，WeChat-YATT 能够有效适应不同的训练需求和计算环境。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;与此同时，WeChat-YATT 采用了 Parallel Controller 模式，由多个 Controller 协同管理数据任务，显著降低了单节点的内存压力，尤其为多模态训练场景提供了更优的系统支持，相较于传统的 Single Controller 架构具备更强的可靠性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;全员共存模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;采用串行调度机制，Actor Rollouts&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;GenRM&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;(&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Generative Reward Model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;)&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;与&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;Train&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;依次串&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;行执行。每个角色完成任务后主动释放计算资源，系统加载下一个任务所需模型。该策略适配绝大多数常规训练场景。值得一提的是，在每个阶段，相关组件均可独占全部 GPU 资源，这极大缩短了资源空闲「气泡」时间，显著提升总体训练吞吐量和效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;部分共存模式&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;下，Actor Rollouts 与&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;G&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;e&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;独立部署，并通过异步方式进行高效交互。Actor 训练阶段会占用全部 GPU 资源，在 Rollouts 生成阶段，Actor 将 GPU 资源释放并唤醒 Actor Rollouts 及 GenRM 两大组件协同工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;并&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;通过&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;动态的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;负载&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;评估&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;进行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;分配&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;与&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;均衡&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;当 Rollouts 生成完毕，这两者会释放资源，Actor 随之加载到 GPU 上，进入下一轮训练流程。部分共存模式非常适合 Rollouts 与 GenRM 需要高频交互、动态采样的任务场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多元的资源放置模式和灵活的调度机制，使 WeChat-YATT 在复杂多变的实际环境下都能实现资源的高效利用，助力大模型&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;微信&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;内部&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;多个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;应用&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;落地&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;项目特点：&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;高效内存利用&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;项目采用 Parallel Controller，有效降低了单节点的内存消耗，更适合多模态场景下的大模型训练，提升了系统的扩展性和稳定性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;GenRM&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;高效&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;支持&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;对于&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;GenRM&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;实现了&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;不同&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;放置&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;供&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;使用者&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根据&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;进行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;高效&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;智能 Checkpoint 策略&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;WeChat-YATT 支持异步 Checkpoint 保存，并针对微信业务场景，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;根据&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;调度流程，实现断点自动保存，进一步保障训练安全与高可用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li style="text-align:justify"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;负载均衡优化&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;&amp;nbsp;在训练过程中，WeChat-YATT 实现了各个数据并行组间的负载均衡，有效减少资源空闲时间，显著提升整体训练吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;&amp;nbsp;实验效果&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-d73534824171f90151065e04a956b3846ca.png" width="355" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-19fa6c294016bfea7f90b3d533f3f0899e8.png" width="264" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366962</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366962</guid>
      <pubDate>Sun, 17 Aug 2025 08:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
