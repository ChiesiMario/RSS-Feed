<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:42:49 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>字节 Seedream 4.0 图像创作模型正式发布</title>
      <description/>
      <link>https://www.oschina.net/news/371058</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371058</guid>
      <pubDate>Tue, 09 Sep 2025 02:38:32 GMT</pubDate>
    </item>
    <item>
      <title>知名 Android 第三方桌面 Nova Launcher 将停止维护</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Android 第三方桌面&lt;span&gt;启动器 Nova Launcher 创始人和原始开发者 Kevin Barry 宣布，他已经离开收购 Nova Launcher 的分析公司 Branch，并不再参与该项目。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1658" src="https://static.oschina.net/uploads/space/2025/0909/103239_Hnwx_2720166.png" width="1502" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://teslacoilapps.com/nova/solong.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据悉，Nova Launcher 由 Kevin Barry 带队开发，于 2022 年被 Branch 收购。当时，Branch 承诺不会将 Nova Launcher 变为订阅式付费、带有广告的普通 Android 桌面启动器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d68adf6667956ed5f537c0b8b93ebbb0b93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据 Kevin Barry 透露，其在过去几个月不断为 Nova Launcher 的开源进行付出。其表示，虽然 Branch 曾在收购 Nova Launcher 时承诺，其若离职，Nova Launcher 最终则会开源，但 Barry 现被要求停止开发 Nova Launcher 和终止进行开源工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371057</guid>
      <pubDate>Tue, 09 Sep 2025 02:35:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义发布语音识别模型 Qwen3-ASR-Flash</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通义千问系列最新的语音识别模型 Qwen3-ASR-Flash 已正式发布，它基于 Qwen3 基座模型，经海量多模态数据以及千万⼩时规模的 ASR（自动语音识别）数据训练构建而成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101857_EGZg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 实现了⾼精度⾼鲁棒性的语⾳识别性能，⽀持 11 种语⾔和多种⼝⾳。与众不同的是，Qwen3-ASR-Flash⽀持⽤户以任意格式提供⽂本上下⽂，从⽽获得定制化的 ASR 结果，同时还⽀持歌声识别。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101903_kNR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="664" src="https://static.oschina.net/uploads/space/2025/0909/101933_MOCR_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1395" src="https://static.oschina.net/uploads/space/2025/0909/101944_O6J2_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 单模型支持多种语言、方言和口音的精准转录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中文：包括普通话以及四川话、闽南语、吴语、粤语等主要方言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;英语：支持英式、美式及多种其他地区口音。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;其他支持语言：法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语和阿拉伯语。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen3-ASR-Flash 的核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;领先的识别准确率：Qwen3-ASR-Flash 在多个中英文，多语种 benchmark 测试中表现最优。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;惊艳的歌声识别能力：支持歌唱识别,包括清唱与带 bgm 的整歌识别，实测错误率低于 8%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定制化识别：用户可以以任意格式 (如词汇表、段落或完整文档) 提供背景文本，模型能智能利用该上下文识别并匹配命名实体和其他关键术语，输出定制化的识别结果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语种识别与非人声拒识：模型能精确分辨语音的语种，自动过滤非语音片段，包括静音和背景噪声。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;鲁棒性：面对长难句、句中语言切换和重复词语等困难文本模式，以及在复杂的声学环境中，模型仍能保持高准确率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;体验方式：&lt;/p&gt; 
&lt;p&gt;ModelScope&lt;strong&gt;：&lt;/strong&gt;https://modelscope.cn/studios/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;HuggingFace:&amp;nbsp;https://huggingface.co/spaces/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;阿里云百炼 API&lt;strong&gt;：&lt;/strong&gt;https://bailian.console.aliyun.com/?tab=doc#/doc/?type=model&amp;amp;url=2979031&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371054</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371054</guid>
      <pubDate>Tue, 09 Sep 2025 02:21:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>deepin 截图录屏智能存储上线，AI 大招在路上</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;deepin 截图录屏作为大家日常使用频率 Top 级应用，之前收到了很多用户的真诚反馈和宝贵建议，感谢大家的积极参与和建言献策。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;目前，&lt;/span&gt;&lt;strong&gt;随着 deepin 25.0.7 版本的更新，deepin 截图录屏新功能也上线啦！&lt;/strong&gt;&lt;span&gt;本文将为大家详细介绍本次更新的具体内容，并透露一下 deepin 截图录屏在后续的产品功能规划，一起来看看吧。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;新增功能：智能区分存储方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span&gt;在之前的反馈中，很多用户提出了对&lt;/span&gt;&lt;strong&gt;截图存储方式&lt;/strong&gt;&lt;span&gt;进行优化的需求，希望能够将「保存至本地」和「保存至剪贴板」功能区分开来。本次版本便实现了此功能，如下所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;strong&gt;点击「√」（或双击截图区域、按回车等），&lt;/strong&gt;&lt;span&gt;截图自动复制到剪贴板，方便直接粘贴使用；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//0f8adb194cc09a47ebccc062f818f2b1.jpg" width="865" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;span&gt;点击「保存」，则将图片存储至本地，方便后续查找与管理。&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//f26dfdac799761b692f5066427950a1b.jpg" width="865" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;但如果你不想每次存图都选路径，别担心——旧版本中「固定文件夹存储」的便捷方式我们也做了保留！&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;更贴心的是，此次版本在「设置」中新增了「保存方式」选项：&lt;/span&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;span&gt;勾选「每次询问」：每次保存时均可自主选择文件夹；&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;勾选「指定位置」并选择具体位置：截图将自动存入预设文件夹，不再询问，省心省力。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p style="text-align:left"&gt;&lt;img align="left" src="https://oscimg.oschina.net/oscnet//6b16bcccdde6f02ed4b186f5ebe954fb.jpg" width="648" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;注意：设置内的「保存方式」仅对「保存到本地」场景生效，不会影响复制剪贴板的相关操作。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;此外，deepin 截图录屏还支持「智能打码、OCR 文字提取、贴图置顶、滚动长截图」等实用功能。更多关于 deepin 截图录屏的详细使用介绍可参考：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FAzxuEFQAJT-SZaG5BsDPww" target="_blank"&gt;&lt;span&gt;《霸榜用户最爱，deepin 截图录屏为何稳坐 Top 1 宝座？》&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p style="text-align:center"&gt;&lt;strong&gt;&lt;strong&gt;抢先看：后续产品规划&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;OCR 体验优化与文字识别模型升级&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;我们关注到用户反馈的 OCR 使用体验问题，特别是在文字识别时需要先保存图片的环节。针对这一问题，我们已制定优化方案，后续会将 OCR 识别逻辑改为"复制到剪贴板"，&lt;/span&gt;&lt;strong&gt;&lt;strong&gt;实现无需保存本地图片即可识别文字&lt;/strong&gt;&lt;/strong&gt;&lt;span&gt;，让操作更加流畅。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;同时，我们也将对 OCR 文字识别模型进行升级，大幅提升识别准确率，为大家带来更好的使用体验。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;注：目前最新版截图录屏中，如果您希望避免每次 OCR 识别时弹窗询问保存位置，可以进入"设置"-"保存方式"，选择"指定位置"来提升使用体验。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;strong&gt;&lt;strong&gt;截图录屏集成 AI 能力&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;UOS AI 将接入视觉处理大模型，支持识别图片、基于视觉推理，后续截图录屏也将拥有识别图片的能力。&lt;/span&gt;&lt;/p&gt; 
  &lt;p style="text-align:left"&gt;&lt;span&gt;你可以对屏幕上的任意内容进行截图，并直接向 AI 提问！具体功能还在紧张设计中，更多惊喜，敬请期待～&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371053</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371053</guid>
      <pubDate>Tue, 09 Sep 2025 02:15:37 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Databricks 融资 10 亿美元，估值超 1000 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.databricks.com%2Fcompany%2Fnewsroom%2Fpress-releases%2Fdatabricks-surpasses-4b-revenue-run-rate-exceeding-1b-ai-revenue" target="_blank"&gt;宣布&lt;/a&gt;即将完成 10 亿美元的 K 轮融资，对应估值超过 1000 亿美元。此轮融资由 Andreessen Horowitz、Insight Partners、MGX、Thrive Capital 和 WCM Investment Management 共同领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 表示，将利用这笔新资金加速其 AI 战略——扩展 Agent Bricks，推出全新 Lakebase 产品线，并推动全球增长。以及支持 Databricks 未来的 AI 收购，并深化 AI 研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="245" src="https://oscimg.oschina.net/oscnet/up-ba2a1094a2ce8345cb7359294aa377ea3d0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在公告中，Databricks 还透露了部分财务状况，披露其第二季度的年收入运行率超过 40 亿美元，同比增长 50%，并在过去 12 个月中实现了正自由现金流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该公司还表示，其人工智能产品的年营收运行率近期已超过 10 亿美元，净留存率超过 140%，目前有超过 650 家客户使用 Databricks 的产品，年收入超过 100 万美元。目前，共有超过 2 万家企业和组织在使用其软件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 联合创始人兼首席执行官 Ali Ghodsi 在公告中表示：「我们的团队正在构建企业未来几十年将依赖的数据和 AI 基础设施，从而取得这些成果。有了这笔新资金，我们将能够加快 Agent Bricks 的发展步伐，帮助各行各业的客户将其数据转化为生产级 AI 代理，并在创建新的 Lakebase 类别、为 AI 代理重塑数据库的过程中获得更大的发展动力。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 还指出，在前两个季度中，该公司已与微软、谷歌云、Anthropic、SAP 和 Palantir 建立或扩大了合作伙伴关系。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371049</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371049</guid>
      <pubDate>Tue, 09 Sep 2025 02:08:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥造物分享：流浪地球 550W（MOSS）小智 AI 生态中枢</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2186</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2186</guid>
      <pubDate>Tue, 09 Sep 2025 01:49:32 GMT</pubDate>
    </item>
    <item>
      <title>李彦宏颁发「百度最高奖」：心流团队获 100 万美元奖励</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，百度创始人李彦宏在内部活动上为技术团队颁发「百度最高奖」，获奖团队得到 100 万美元奖励，合人民币超 700 万元。「百度最高奖」已历经 15 届，语音识别、深度学习平台、大模型等大量 AI 技术均曾获奖，奖金总金额将近 4 亿元人民币。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-322339010570111171fc427256170f32b22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据了解，「百度最高奖」于 2010 年 7 月设立，鼓励「小团队做出大事业」，是百度公司最高级别的奖项，给予每个获奖团队 100 万美元奖励。奖项评选需满足三项条件：项目意义重大；成果远超预期；团队足够小，必须是小于等于 10 人。&lt;/p&gt; 
&lt;p&gt;本次百度最高奖的获奖团队为「心流」团队。据介绍，「心流」团队率先实现了端到端的多模态内容理解与序列生成技术。李彦宏在颁奖时表示，到今天，模型发展已经非常接近临界点，很快就会有各种有价值的应用被创造出来，「我们生活在一个非常令人兴奋、非常令人期待的环境当中」。&lt;/p&gt; 
&lt;p&gt;李彦宏称，百度搜索已有近 70% 结果含有 AI 生成内容，且通过「百看」带来富媒体形式，是全球所有的搜索引擎当中改造最激进的，这也代表搜索引擎的未来。&lt;/p&gt; 
&lt;p&gt;同时，百度慧博星数字人已达到「以假乱真」的地步，「很多人看不出是数字人还是真人」；百度萝卜快跑已覆盖全球 16 座城市，代表着最新一代的无人驾驶技术。&lt;/p&gt; 
&lt;p&gt;颁奖典礼现场，李彦宏在谈及 AI 发展时指出，「AI 大模型发展到今天，其实已接近了临界点，很快就会有各种各样非常有价值的应用能够创造出来，我们正生活在一个非常令人兴奋、非常令人期待的市场环境当中。」&lt;/p&gt; 
&lt;p&gt;「我们所从事的每一项工作都代表着未来，我也希望大家和我一起去期待，去迎接、去奋斗出一个创新在 C 位的社会。」李彦宏表示。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370987</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370987</guid>
      <pubDate>Sat, 06 Sep 2025 11:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「AI 教父」辛顿竟然被前女友竟用 ChatGPT 提分手</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，被誉为「AI 教父」 的 Geoffrey Hinton 在接受采访时&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F31feb335-4945-475e-baaa-3b880d9cf8ce" target="_blank"&gt;透露&lt;/a&gt;，他的前女友曾用 ChatGPT 给他发送分手信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1776" src="https://static.oschina.net/uploads/space/2025/0908/192243_YVS9_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Hinton 作为人工智能领域的先驱，其在 1980 年代的工作为机器学习和人工神经网络奠定了基础，去年还获得了诺贝尔物理学奖。&lt;/p&gt; 
&lt;p&gt;这位 AI 领域的权威人士却未能预料到自己会被 AI 工具所「伤害」，他的前女友用 ChatGPT 告诉他他有多糟糕，让他非常惊讶。「她用聊天机器人说出我的缺点，再传给我。」不过辛顿自认没有聊天机器人说的那么糟，所以也没有太难过。&lt;/p&gt; 
&lt;p&gt;事实上，让像 ChatGPT 这样的聊天机器人撰写分手短信等似乎并不是什么新鲜事，毕竟越来越多的人就一系列问题向 AI 咨询。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370985</guid>
      <pubDate>Sat, 06 Sep 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Agent Client Protocol —— 代码编辑器与 Agent 的通信协议</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Agent Client Protocol (ACP) 是用于连接代码编辑器和 Agent 的协议，对代码编辑器（用于查看和编辑源代码的交互式程序）与编码 Agent（使用生成式 AI 自主修改代码的程序）之间的通信进行了标准化。&lt;/p&gt;

&lt;p&gt;这一协议让开发者可以在编辑器中自由接入任意第三方智能体（Agent），无需依赖官方内置工具。其理念类似于语言服务器协议（LSP），通过解耦编辑器与 Agent 的交互方式，提供更灵活的扩展能力。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2f621ad18024ec580d997b820ea9139346e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;ACP 协议已经以 Apache 开源许可证发布，任何开发者都可基于它集成自己的 AI Agent。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/agent-client-protocol</link>
      <guid isPermaLink="false">https://www.oschina.net/p/agent-client-protocol</guid>
      <pubDate>Sat, 06 Sep 2025 11:18:00 GMT</pubDate>
    </item>
    <item>
      <title>商汤日日新为 Claude API 用户提供「搬家」大礼包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 5 日，Anthropic 宣布将禁止中资控股超过 50% 的公司使用 Claude 服务，并限制企业通过海外云服务、第三方平台等方式间接使用。&lt;/p&gt; 
&lt;p&gt;即日起，商汤日日新大模型 SenseNova 将为 Claude 用户提供「搬家」服务，帮助客户继续享受高质量的模型能力和服务。&lt;/p&gt; 
&lt;p&gt;相关模型详情可访问 platform.sensenova.cn 注册。&lt;/p&gt; 
&lt;p&gt;商汤将为从 Claude 迁移到「日日新」的新用户赠送 5000 万 Tokens 体验包；同时为用户提供专属搬家顾问，提供迁移系列培训，让新用户入驻新家舒适顺利。相关模型详情可访问 platform.sensenova.cn 注册。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/185753_qsE0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;商汤还提供最新交互模型——日日新 SenseNova V6.5 Omni API 的免费接入测试。用户也可在应用商店下载「商量 APP」免费体验！&lt;/p&gt; 
&lt;p&gt;另外，针对用户对高质量的编程和 Agent 工具的需求，商汤小浣熊还将提供 300,000 元会员权益，所有用户均可扫描文末二维码领取。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370978</guid>
      <pubDate>Sat, 06 Sep 2025 10:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达推出通用深度研究（UDR）系统</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达&lt;span&gt;最新&lt;/span&gt;发布另外一个通用深度研究（UDR）系统，目前仍处于原型阶段。该系统不仅可以与任何大语言模型 (LLM) 兼容，更为用户提供了高度定制的深度研究策略，彻底改变了以往研究智能体的工作方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据英伟达的&lt;span&gt;最新&lt;/span&gt;论文，UDR 系统的核心优势在于其极强的灵活性。过去，深度研究智能体往往依赖硬编码的方式，用户只能使用固定的工具和策略进行研究，无法进行个性化调整。而 UDR 系统的推出，意味着用户可以随心所欲地创建、编辑和优化自己的研究策略，甚至无需进行额外的模型训练。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-7461c3da8a2ceb3b17c20d0c5f84c7d2fba.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;UDR 系统配备了一个用户友好的界面，方便用户输入研究提示，随时更新进度并查看最终报告。与传统的对话式 LLM 不同，UDR 能够在研究过程中持续向用户反馈进展，极大提升了研究效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得一提的是，UDR 系统在设计上将研究逻辑与语言模型解耦，使开发者能够灵活选择&lt;span&gt;最先&lt;/span&gt;进的 AI 模型，并将其与量身定制的研究方案结合使用。这种创新的组合方式，让用户能够创造出更强大、更具适应性的深度研究工具。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 UDR 系统具有诸多优点，但仍存在一些需要改进的地方。系统的准确性依赖于底层 AI 模型生成代码的质量，同时用户设计的研究策略必须合理可行，否则可能导致生成的报告质量低下。此外，当前版本在执行过程中缺乏用户干预的能力，所有决策都需在研究开始前预设，限制了灵活性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员已提出了进一步的改进方案，包括提供可修改的策略库和更灵活的用户控制功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370976</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370976</guid>
      <pubDate>Sat, 06 Sep 2025 10:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>rainfrog - 命令行数据库工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Rainfrog 的目标是提供一个轻量级的、基于终端的数据库交互工具。该项目目前处于测试阶段。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过类似 vim 的键绑定和鼠标控制实现高效导航&lt;/li&gt;
&lt;li&gt;具有关键字高亮显示、会话历史记录和收藏夹的查询编辑器&lt;/li&gt;
&lt;li&gt;快速复制数据、过滤表以及在模式之间切换&lt;/li&gt;
&lt;li&gt;查看表元数据和属性的快捷方式&lt;/li&gt;
&lt;li&gt;跨平台（macOS、linux、windows、android 通过 termux）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="278" src="https://static.oschina.net/uploads/space/2025/0905/115915_L0YY_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/rainfrog</link>
      <guid isPermaLink="false">https://www.oschina.net/p/rainfrog</guid>
      <pubDate>Sat, 06 Sep 2025 10:11:00 GMT</pubDate>
    </item>
    <item>
      <title>腾讯混元翻译模型 Hunyuan-MT-7B 登顶开源热榜</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F19W9SEUxq7nuYQvVJz8faA" target="_blank"&gt;宣布&lt;/a&gt;，混元翻译模型 Hunyuan-MT-7B 登顶 Hugging Face 模型趋势榜第一位。官方表示，该模型和混元世界模型家族最新成员 HunyunWorld-Voyager 一起，拿下前三中的两席。&lt;/p&gt; 
&lt;p&gt;Hunyuan-MT-7B 于 9 月 1 日开源，其总参数量仅 7B，支持 33 个语种、5 种民汉语言/方言互译，是一个能力全面的轻量级翻译模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1506" src="https://static.oschina.net/uploads/space/2025/0908/175938_Dkn8_2720166.png" width="1216" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 8 月底结束的国际计算语言学协会（ACL）WMT2025 比赛中，Hunyuan-MT-7B（参赛名称：Shy-hunyuan-MT）拿下了全部 31 个语种比赛中的 30 个第 1 名，处于绝对领先地位。&lt;/p&gt; 
&lt;p&gt;这 31 个语种除了中文、英语、日语等常见语种，也包含捷克语、马拉地语、爱沙尼亚语、冰岛语等小语种。&lt;/p&gt; 
&lt;p&gt;腾讯混元表示，在业界常用的翻译能力测评数据集 Flores200 上，腾讯混元 Hunyuan-MT-7B 模型也有卓越的效果表现，明显领先于同尺寸模型，与超大尺寸模型效果对比也不逊色。&lt;/p&gt; 
&lt;p&gt;针对翻译场景，腾讯混元提出了一个完整的翻译模型训练范式，覆盖从预训练、到 CPT 再到监督调参、翻译强化和集成强化全链条，使得模型的翻译效果达到业界最优。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370969</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370969</guid>
      <pubDate>Sat, 06 Sep 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>上海发布 AI 广告扶持政策：最高 500 万补贴大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;上海市近日发布了《上海市支持人工智能赋能广告业创新发展的若干措施》，旨在通过一系列具体的扶持政策，推动人工智能技术在广告行业的深度应用和发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心扶持措施概览&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新政策的核心在于「AI+数字广告」生产要素的强化支持，具体措施包括:&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;大模型私有化部署补贴:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;对于采用第三方大模型进行私有化部署，并将其应用于广告垂类领域的数字广告企业，上海市将提供&lt;span&gt;最高&lt;/span&gt;可达核定合同额&lt;strong&gt;50%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 万元&lt;/strong&gt;的补贴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;语料研发与应用补贴:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;鼓励企业购买非关联方的语料进行广告垂类应用和「智能体」等研发。对于此类投入，企业可获得&lt;span&gt;最高&lt;/span&gt;核定合同额&lt;strong&gt;30%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 万元&lt;/strong&gt;的补贴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;算力租用支持:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;此外，有条件的区政府还将对租用算力的数字广告企业提供支持，按实际投入的&lt;strong&gt;30%&lt;strong&gt;比例，给予单个主体年度&lt;span&gt;最高&lt;/span&gt;&lt;/strong&gt;2000 万元&lt;/strong&gt;的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这一系列政策的出台，不仅体现了上海市抢占「AI+广告」产业制高点的决心，也旨在通过真金白银的投入，降低企业在技术研发和部署上的成本，激发市场的创新活力。通过支持大模型私有化部署、语料研发和算力投入，上海正着力打造一个集技术、数据和算力于一体的完整 AI 广告生态系统。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这些措施预计将吸引更多 AI 技术公司和传统广告企业在上海落地和发展，加速人工智能在广告创意、内容生成、精准投放等环节的深度融合，从而推动整个广告行业的数字化和智能化转型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370959</guid>
      <pubDate>Sat, 06 Sep 2025 09:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>HuggingFace 开源 FinePDFs 与 FineVision 数据集</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face 开源了两个大规模数据集 FinePDFs 和 FineVision，前者是目前最大的公开 PDF 语料库，后者则专为视觉-语言模型训练设计，旨在显著提升开源模型的能力。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/datasets/HuggingFaceFW/finepdfs&lt;br&gt; https://huggingface.co/datasets/HuggingFaceM4/FineVision&lt;/p&gt; 
&lt;p&gt;FinePDFs 是目前最大的公开 PDF 语料库，完全由 PDF 文件构建，包含约 3 万亿 tokens，覆盖 4.75 亿份文档、1733 种语言，数据量 3.65TB。&lt;/p&gt; 
&lt;p&gt;语料来自 105 个 CommonCrawl 快照（2013 夏—2025 年 2 月），经 datatrove 库去重、过滤与 PII 匿名化，采用 ODC-By 1.0 许可证。文档平均长度接近 HTML 数据集的两倍，长于 10 万，字符的样本显著，可用于提升开源 LLM 的长上下文能力。&lt;/p&gt; 
&lt;p&gt;数据集已按语言-脚本对划分，978 种语言超 100 万 tokens，66 种语言超 10 亿 tokens。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7cbae8687f50206187cf62b7ba1d65da7be.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FineVision 面向视觉-语言模型训练，整合 200 余个来源，含 1730 万张图像、2430 万样本、8890 万轮对话、95 亿回答 tokens，支持 GUI 导航、指向、计数等新能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-945829421e543e2f159fb676f6f537bbadb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方称在 10 项基准上带来 20% 以上提升，可显著增强开源 VLM 性能。数据已转为 Parquet，总量约 4.48 TB，支持流式加载。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370951</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370951</guid>
      <pubDate>Sat, 06 Sep 2025 09:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>宇树科技冲刺 IPO 将影响机器人产业格局</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，国内机器人领域头部企业宇树科技宣布，预计在 2025 年 10 月份至 12 月份期间向证券交易所提交 IPO 申请文件。这一消息在科技界和资本市场引发了广泛关注。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作为人形机器人商业化落地的标杆企业，宇树科技冲刺 IPO，有望成为影响机器人产业格局的关键节点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;首先，宇树科技冲刺 IPO，有望向市场证明其技术商业化的可行性。公司 2024 年营收突破 10 亿元，且连续 4 年实现盈利，其中，2024 年四足机器人贡献了 65% 的收入，验证了消费级场景的变现能力。若成功上市，通过完整披露研发数据、客户结构及成本模型，宇树科技将进一步证明其技术护城河并非只是「实验室成果」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;机器人企业不仅要注重技术研发，还要重视商业化落地。通过拓展应用场景，开发满足市场需求的产品，实现技术的商业价值转化，才能获得稳定的收入，增强资本吸引力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其次，宇树科技冲刺 IPO，将成为机器人产业链价值重估的催化剂，持续推动上游精密制造、中游系统集成、下游场景运营的全链条资本化，形成「技术—资本—产业」正循环，从而进一步优化产业链。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，宇树科技已经实现电机、减速器、控制器等核心部件全栈自研，国产化率超 90%。业内预计，宇树科技或将募资重点投向高扭矩密度电机、轻量化材料等领域，以打破机器人规模化应用的成本瓶颈。上市后，宇树科技势必会通过融资扩大产能，相关供应链企业有望迎来订单放量的黄金机遇，上下游协同的良性生态有望加速形成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;最后，宇树科技选择 IPO，本质上是资本效率与技术周期的精准匹配。2025 年 6 月份，宇树科技完成 C 轮融资，投后估值已达 120 亿元。该轮融资由中国移动旗下基金、腾讯、锦秋基金、阿里巴巴、蚂蚁集团和吉利资本共同领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇树科技冲刺 IPO，是机器人产业加速资本化的缩影。相信在资本市场与机器人产业的「双向奔赴」中，中国机器人企业将大幅提升竞争力。（证券日报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370948</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370948</guid>
      <pubDate>Sat, 06 Sep 2025 09:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>未来可能有高达 50% 的入门级工作将被 AI 取代</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;随着人工智能（AI）的迅速发展，许多公司正在经历前所未有的变革。曾经的职场成功故事，如 Hewlett Packard Enterprise 的首席执行官安东尼・内里 (Antonio Neri) 从客服代理晋升为 CEO，正在逐渐被 AI 的兴起所取代。分析师预测，未来可能有高达 50% 的入门级工作将被 AI 取代，这意味着许多刚刚步入职场的大学毕业生将面临前所未有的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在一项针对公共科技公司和成长中的风险投资企业的研究中，数据显示，从 2019 年到 2024 年，具有不到一年工作经验的求职者的就业机会下降了 50%。这一趋势影响到了销售、市场营销、工程、招聘、运营、设计、财务和法律等各个核心职能。这种变化不仅影响了求职者，也让企业面临重新培养人才的压力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管如此，行业专家指出，这种失去入门级岗位的情况可能促使组织内部的人才培养模式发生改变。随着公司的结构变得更加扁平化，入门级岗位可能会转变为更高要求的技能角色，要求求职者在进入职场前具备更多的能力。虽然对于即将毕业的学生来说，这意味着他们需要自行掌握这些技能，但也可能成为他们在竞争激烈的求职市场中脱颖而出的优势。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;各大高校也在积极调整课程，旨在为学生提供与 AI 相关的技能培训。虽然技术进步可能在短期内对就业率产生影响，但历史上技术革新在长期内并未导致大规模的失业。专家认为，当前大学毕业生面临的挑战，可能在未来几年内影响他们的职业发展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，尽管有许多未知数，许多经济学家认为 AI 对劳动市场的长期影响仍然具有高度的不确定性，企业和社会将需要时间来适应这一变化。随着技术的不断进步和 AI 的普及，职场的未来可能会迎来全新的模式，而不仅仅是对现有职场阶梯的替代。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370944</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370944</guid>
      <pubDate>Sat, 06 Sep 2025 08:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达收购 AI 编程初创公司 Solver</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Fbriefings%2Fnvidia-acquires-coding-startup-solver" target="_blank"&gt;据 The Information 报道&lt;/a&gt;，英伟达最近完成了对 AI 编程公司 Solver 的收购，进一步强化其在 AI 全栈生态的布局。&lt;/p&gt; 
&lt;p&gt;Solver 成立于 2022 年，前身为 Laredo Labs，专注于 AI Coding Agent，其产品能通过自然语言指令管理完整代码库（如生成、测试、修复代码），而非仅代码补全。公司曾获 800 万美元融资，创始团队包括前 Siri 和三星 Viv Labs 核心成员。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/161953_FkOn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Solver 的技术突破在于学习「超过一亿个软件项目的开发历史」，理解代码演进逻辑，可执行复杂任务（如重构模块、修复系统性漏洞）。其 API 支持多语言（Python、JavaScript 等），并与主流开发工具无缝集成。&lt;/p&gt; 
&lt;p&gt;此次收购是英伟达 2024-2025 年系列收购的关键一环，旨在构建「硬件+软件+云服务」全栈生态。Solver 将整合至英伟达开发者工具链（如 CUDA、NVIDIA AI Enterprise），降低 AI 应用开发门槛，反向驱动 GPU 需求增长。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</guid>
      <pubDate>Sat, 06 Sep 2025 08:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 重组 ChatGPT 「模型行为团队」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 内部邮件确认，原「模型行为团队」（Model Behavior）整体并入「后训练团队」（Post Training），直接向该团队负责人 Max Schwarzer 汇报。此举旨在把 AI 个性、安全与用户体验研究更深地嵌入核心模型开发流程，为 GPT-5 后续版本提供更快的迭代支持。&lt;/p&gt; 
&lt;p&gt;该团队原有 14 人，长期负责减少谄媚、平衡政治偏见、定义聊天语气等「人格化」工作。与此同时，模型行为团队创始负责人 Joanne Jang 宣布转岗，启动新项目 OAI Labs，探索超越传统聊天窗口的人机协作界面。Jang 称，新实验室将「让 AI 成为思考、创作、游戏、学习和连接的工具」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160802_ml0W_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160900_9Cth_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;业内分析指出，此次重组反映出 OpenAI 对「模型性格」商业化影响的重视：用户反馈 GPT-5「过于冷淡」或「过度迎合」后，公司已临时开放旧模型访问权限，并加速个性调优。同期发表的 OpenAI 研究论文也警告，行业惯用的「应试型」评估可能鼓励模型幻觉，未来需在评分机制中引入「不确定性诚实」指标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370934</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370934</guid>
      <pubDate>Sat, 06 Sep 2025 08:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Tilde AI 发布开源 TildeOpen LLM</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Latvian 语言技术公司 Tilde 发布了 TildeOpen LLM，这是一个开源的基础大语言模型（LLM），旨在支持欧洲语言，特别是那些较少被代表的国家和地区语言。这一举措标志着欧盟在语言公平和数字主权方面迈出了重要的一步。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="290" src="https://oscimg.oschina.net/oscnet/up-a3afc0c462ebfde5158ba6a9fda49510c9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen LLM 是一个拥有 300 亿参数的稠密解码器模型，采用了 CC-BY-4.0 的宽松许可证，能够支持从拉脱维亚语、立陶宛语到乌克兰语、土耳其语等多种语言。该模型的训练是在欧洲的&lt;span&gt;超级&lt;/span&gt;计算机 LUMI（芬兰）和 JUPITER 上进行的，使用了欧盟委员会的大型人工智能大奖挑战赛所提供的 200 万 GPU 小时的计算资源。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技术细节方面，TildeOpen LLM 通过受 EleutherAI 启发的 GPT-NeoX 脚本进行训练，共进行了 45 万次更新，使用了约 2 万亿个令牌。其训练过程包含三阶段采样：首先在语言间均匀分布，其次是对高数据量语言的自然分布进行增强，最后再进行均匀的扫查以确保平衡。模型的超参数包括 60 层、嵌入维度 6144、48 个注意力头、8192-token 的上下文窗口，以及使用 SwiGLU 激活、RoPE 位置编码和 RMSNorm 层规范化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在语言公平和数据主权方面，传统的主流模型往往侧重于英语和其他主要语言，导致在处理波罗的海、斯拉夫及其他较小的欧洲语言时表现不佳，常常出现语法错误和奇怪的措辞。而 TildeOpen 通过引入 「公平的标记器」，使得不同语言的文本以相似方式进行表示，从而减少标记数量，提高较少代表语言的推理效率。此外，组织可以选择在本地数据中心或符合欧盟要求的安全云中自我托管，确保遵循 GDPR 及其他数据保护法规，从而解决了与美国或亚洲托管模型相关的主权问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen 作为基础模型，预计会推出更多专门化版本，例如经过指令调优的翻译模型，这将进一步增强其功能。拉脱维亚通过 Tilde 的努力，期望在全球科技领域占据一席之地，同时致力于保护语言多样性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370933</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370933</guid>
      <pubDate>Sat, 06 Sep 2025 08:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
