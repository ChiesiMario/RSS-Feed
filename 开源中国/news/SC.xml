<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 24 Jun 2025 07:45:57 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>curl 之父发文介绍 OpenSSL 分支家族</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;curl 之父近日发表文章&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2025%2F06%2F23%2Fa-family-of-forks%2F" target="_blank"&gt;介绍&lt;/a&gt;&lt;/u&gt; OpenSSL 分支家族，展示了它们的差异、相似之处，以及支持它们所需的一些见解。&lt;/p&gt; 
&lt;p&gt;译文如下：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;curl 支持使用 11 种不同的 TLS 库进行编译。其中六个库是 OpenSSL 或其分支。让我向你展示它们的差异、相似之处，以及支持它们所需的一些见解。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;SSLeay&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这一切都始于 SSLeay。这是我发现的第一个 SSL 库，我们使用这个库在 1998 年春天为 curl 添加了第一个 HTTPS 支持。显然，SSLeay 项目早在 1995 年就已经启动了。&lt;/p&gt; 
&lt;p&gt;那是一个我们还只支持 SSL 的年代；TLS 会在之后才出现。&lt;/p&gt; 
&lt;p&gt;OpenSSL 一直拥有一个古怪、不一致且极其庞大的 API 集（其中一大部分是从 SSLeay 继承而来的），这进一步被稀疏的文档所复杂化，这些文档留给用户去依靠自己的想象力和技能去查阅源代码，以获取最后的细节解答（即使在 2025 年今天也是如此）。在 curl 中，我们经常收到关于如何使用这个库的偶尔问题报告，即使已经过了几十年。 presumably，这同样适用于所有 OpenSSL 用户。&lt;/p&gt; 
&lt;p&gt;OpenSSL 项目经常受到批评，认为他们在几年前升级到版本 3 之后，在性能方面有所疏忽。他们也一直进展缓慢或不愿采用新的 TLS 技术，例如 QUIC 和 ECH。&lt;/p&gt; 
&lt;p&gt;尽管如此，OpenSSL 已经成为一种主导的 TLS 库，尤其是在开源领域。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;LibreSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;回到 Heartbleed 事件时期，LibreSSL 分叉出来并成为独立的项目。他们删除了他们认为不属于库中的功能，创建了自己的 TLS 库 API。几年后，苹果在 macOS 上使用 LibreSSL 提供 curl。他们有一些本地修补，使它&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdaniel.haxx.se%2Fblog%2F2024%2F03%2F08%2Fthe-apple-curl-security-incident-12604%2F" target="_blank"&gt;行为与其他不同&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;LibreSSL 在 QUIC 的支持上落后，不支持 SSLKEYLOGFILE、ECH，而且如今在实现新功能方面似乎比 OpenSSL 更慢。&lt;/p&gt; 
&lt;p&gt;curl 自从创建以来就与 LibreSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;BoringSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 Heartbleed 事件时期由 Google 分叉出来。&lt;em&gt;Google 为 Google 做的&lt;/em&gt;，他们没有公开发布过，清理了很多原型和变量类型，并在 QUIC API 推动中处于领先地位。总体而言，大多数新的 TLS 发明都已在 BoringSSL 中实现和支持，比其他分叉更早。&lt;/p&gt; 
&lt;p&gt;Google 在 Android 的其他地方也使用这个。&lt;/p&gt; 
&lt;p&gt;curl 从创建以来就与 BoringSSL 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AmiSSL&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;一个为使 OpenSSL 能够在 AmigaOS 上正确编译和运行而制作的 OpenSSL 分支或变种。我对它了解不多，但在这里包含它是为了完整性。它似乎基本上是为 Amiga 系统移植的 OpenSSL。&lt;/p&gt; 
&lt;p&gt;当为 AmigaOS 编译时，curl 也能与 AmiSSL 兼容。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;QuicTLS&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由于 OpenSSL 延迟响应并拒绝提供 QUIC API，其他分支在 2020 年初期（我尚未看到有人解释原因）采取了行动。微软和 Akamai 分支了 OpenSSL，产生了 &lt;em&gt;QuicTLS&lt;/em&gt;，此后它试图成为一个 &lt;em&gt;轻量级&lt;/em&gt; 的分支，主要只是在与 BoringSSL 和 LibreSSL 支持相同风格的基础上添加 QUIC API。&lt;em&gt;轻量级&lt;/em&gt; 的含义是它们密切跟踪上游开发，并且除了 QUIC API 之外，没有打算在其他方面偏离。&lt;/p&gt; 
&lt;p&gt;在 OpenSSL 3.5 中，他们终于提供了一个与 fork（包括 QuicTLS）提供的 QUIC API 不同的 QUIC API。我认为这促使 QuicTLS 重新考虑其未来的发展方向，但我们仍在等待确切的进展。&lt;/p&gt; 
&lt;p&gt;curl 自从创建以来就与 QuicTLS 完美配合。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;AWS-LC&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这是由亚马逊维护的一个 BoringSSL 分支。与 BoringSSL 不同的是，他们确实进行了实际的（频繁的）发布，因此看起来像一个项目，即使是非亚马逊用户也可以实际使用和依赖——尽管他们存在的目的是 _维护一个与 AWS 使用的软件和应用程序兼容的安全 libcrypto _。令人惊讶的是，他们维护的不仅仅是「仅仅」 libcrypto。&lt;/p&gt; 
&lt;p&gt;这个分支最近显示出大量的活动，甚至在核心部分也是如此。&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.haproxy.com%2Fblog%2Fstate-of-ssl-stacks" target="_blank"&gt;2025 年 5 月由 HAProxy 团队进行的基准测试&lt;/a&gt; 表明，AWS-LC 显著优于 OpenSSL。&lt;/p&gt; 
&lt;p&gt;AWS-LC 提供的 API 与 BoringSSL 的 API 并不完全相同。&lt;/p&gt; 
&lt;p&gt;curl 与 AWS-LC 从 2023 年初开始就配合得非常好。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;家族树&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/img/202506/24145235_ALUZ.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;OpenSSL 分支家族树&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;OpenSSL 分支家族现状&lt;/h2&gt; 
&lt;p&gt;这六个不同的分支各自有其特定的特性、API 和功能，这些在不同版本中也会发生变化。目前我们仍然支持这六个分支，因为人们似乎仍在使用它们，而且维护起来是可行的。&lt;/p&gt; 
&lt;p&gt;我们使用相同的 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcurl%2Fcurl%2Fblob%2Fmaster%2Flib%2Fvtls%2Fopenssl.c" target="_blank"&gt;单个源代码文件&lt;/a&gt; 支持所有这些分支，并通过不断增长的 #ifdef 逻辑来实现。我们通过在 CI 中使用这些分支进行构建验证，尽管只使用了一小部分最近的版本。&lt;/p&gt; 
&lt;p&gt;随着时间的推移，这些分支似乎正在逐渐彼此分离。我认为这还不构成一个问题，但我们当然在监控这种情况，可能在某个时候需要进行一些内部重构以适应这种变化。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;未来&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我无法预见会发生什么。如果历史是一堂课，我们似乎更倾向于走向更多的分支，而不是更少的分支。但当然，每一位阅读这篇博客文章的读者现在都会思考，所有这些分支所耗费的重复努力以及由此带来的隐含低效性到底有多少。这不仅适用于这些库本身，也适用于像 curl 这样的用户。&lt;/p&gt; 
&lt;p&gt;我认为我们只能等待观察。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357005/a-family-of-openssl-forks</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357005/a-family-of-openssl-forks</guid>
      <pubDate>Tue, 24 Jun 2025 06:52:53 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Kotlin 2.2.0 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;Kotlin 2.2.0 版本现已&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fkotlin%2F2025%2F06%2Fkotlin-2-2-0-released%2F" target="_blank"&gt;发布&lt;/a&gt;。此版本包含全新和稳定的语言功能、工具更新、针对不同平台的性能改进以及重要修复。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;一些亮点更新内容如下：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;strong&gt;Language：&lt;/strong&gt;预览版中的新语言功能，包括上下文参数。一些之前处于实验阶段的功能现已稳定，例如 guard conditions、non-local break and continue 以及 multi-dollar interpolation。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin compiler：&lt;/strong&gt;统一管理编译器警告。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/JVM：&lt;/strong&gt;接口函数的默认方法生成发生变化。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/Native：&lt;/strong&gt;&amp;nbsp;LLVM 19 和用于跟踪和调整内存消耗的新功能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/Wasm：&lt;/strong&gt;分离的 Wasm target，以及为每个项目配置 Binaryen 的功能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kotlin/JS：&lt;/strong&gt;修复为@JsPlainObject 接口生成的复制方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradle：&lt;/strong&gt;&amp;nbsp;Kotlin Gradle 插件中包含二进制兼容性验证。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard library：&lt;/strong&gt;稳定的 Base64 和 HexFormat API。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#19191c"&gt;有关更改的完整列表可参阅&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fkotlinlang.org%2Fdocs%2Fwhatsnew22.html" target="_blank"&gt;Kotlin 2.2.0 中的新增功能&lt;/a&gt;或&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJetBrains%2Fkotlin%2Freleases%2Ftag%2Fv2.2.0" target="_blank"&gt;GitHub 上的发行说明&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357003/kotlin-2-2-0-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357003/kotlin-2-2-0-released</guid>
      <pubDate>Sun, 11 May 2025 06:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 上线 AI 音色设计功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;MiniMax 稀宇科技&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSUqhAd54Q15Huq-AQ9EeCA" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;旗下 MiniMax Audio 上线了「Voice Design 音色设计」功能。&lt;/p&gt; 
&lt;p&gt;音色的维度一般分成音频质量、发声方式、情感基调以及人物画像。该功能根据用户对音色需求的描述，模型自动拆解成音色相关的描述信息，并根据上述的描述来得到一个新的音色编码。同视频模型类似，该功能支持对音色的抽卡，如果不满意，多试几次，很容易得到理想中的专属独一音色，并可存储下来做后续的音频内容创作。&lt;/p&gt; 
&lt;p&gt;据介绍，通过 Voice Design 音色设计，用户可以通过自然语言来描述自己心中所想的音色，实现对多个维度的精准控制，甚至生成世界上不存在的音色。同时，Voice Design 与 Speech 02 语音模型在链路上相配合，用户在文字转语音中可真正实现了「所需即所得」，以「任意语言 × 任意口音 × 任意音色」，实现可全自定义的无限组合。&lt;/p&gt; 
&lt;p&gt;此外，Voice Design 解决了语音合成领域的两个挑战：难以精准匹配用户各个细分场景下的多样需求；复刻音色需要用户花费大量时间准备输入素材，并且存在潜在的版权风险。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/142945_xJzZ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，Voice Design 已上线 MiniMax Audio 国内、海外两个版本。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;国内版：minimaxi.com/audio&lt;/li&gt; 
 &lt;li&gt;海外版：minimax.io/audio&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/357002/minimax-voice-design</link>
      <guid isPermaLink="false">https://www.oschina.net/news/357002/minimax-voice-design</guid>
      <pubDate>Sun, 11 May 2025 06:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>空间理解模型 SpatialLM 正式发布首份技术报告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，空间理解模型 SpatialLM 正式发布首份技术报告。这一模型此前曾与 DeepSeek-V3、通义千问 Qwen2.5-Omni 一起登上全球最大的开源社区 HuggingFace 全球趋势榜前三。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/140955_PZlV_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为一款将大语言模型扩展到 3D 空间理解任务中的模型，SpatialLM 能从 3D 点云输入生成结构化的空间场景描述，这一过程突破了大语言模型对物理世界几何与空间关系的理解局限，让机器具备空间认知与推理能力，为具身智能等相关领域提供空间理解基础训练框架。&lt;/p&gt; 
&lt;p&gt;在开源后经过广泛的实际验证，本次技术报告聚焦 SpatialLM 1.1 升级版本，其不仅包含了详细的消融实验与训练配方，还在点云编码方式、分辨率、用户指定识别类目等维度上实现优化。&lt;/p&gt; 
&lt;p&gt;多项基准测试数据显示：该模型在任务数据集微调后，在空间布局识别、3D 物体检测任务中，均达到了相比与最新专业模型持平或更优的效果。&lt;/p&gt; 
&lt;p&gt;&lt;img height="309" src="https://static.oschina.net/uploads/space/2025/0624/141014_3iIl_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本次报告重点围绕&lt;strong&gt;算法框架&lt;/strong&gt;和&lt;strong&gt;训练数据&lt;/strong&gt;两方面展开。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在算法架构方面&lt;/strong&gt;，SpatialLM 将大语言模型（LLMs）扩展到 3D 空间理解任务中，特别在结构化室内建模领域实现了重要突破。&lt;/p&gt; 
&lt;p&gt;这一技术路线打破了传统任务专属架构（task-specific architecture）的限制，创新性地采用可编辑的文本形式表达场景结构。这一创新设计具有双重技术优势：&lt;/p&gt; 
&lt;p&gt;一方面&lt;strong&gt;发挥了群核科技强大数据集能力&lt;/strong&gt;，通过持续训练不断优化空间识别精度；另一方面&lt;strong&gt;通过接入大语言模型，系统可直接接收并理解自然语言指令&lt;/strong&gt;，使空间理解模型从简单任务执行工具转变为能够真正理解用户意图的智能系统，从而推进了 LLMs 在空间理解和推理方向的能力边界。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/141138_pYOw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;SpatialLM 模型的网络结构&lt;/strong&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;在训练数据方面，SpatialLM 构建了一个全新的包含 3D 结构化信息的合成点云数据集，打破了真实数据稀缺且难以标注的局限。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1149" src="https://static.oschina.net/uploads/space/2025/0624/141210_bppP_2720166.png" width="974" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;该数据集包含超 1.2 万场景、5.4 万个房间的结构化室内点云数据，其规模远超 ScanNet（仅包含 1,513 个场景）等现有数据集。所有数据均源自真实项目的专业设计模型，经严格筛选与解析后形成符合真实世界统计分布的虚拟环境，相较程序化生成的 ProcTHOR 等数据集具有更高真实性。&lt;/p&gt; 
&lt;p&gt;项目地址：https://manycore-research.github.io/SpatialLM/&lt;br&gt; 报告详情：https://arxiv.org/abs/2506.07491&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356998</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356998</guid>
      <pubDate>Sun, 11 May 2025 06:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Roo Code 3.21.4 发布，添加新的 Claude Code 提供商</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Roo Code 3.21.4 已发布，此版本添加了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fproviders%2Fclaude-code" target="_blank"&gt;新的 Claude Code 提供商&lt;/a&gt;，允许用户通过 Claude Code 直接在 Roo Code 中使用其现有的 Claude Max 订阅。这意味着用户可以利用其订阅权益，无需额外支付按令牌计费的 API 费用，并可访问 Claude Sonnet 4、Opus 4 等高级模型，同时享受零设置复杂性和对 Claude 思维模式及推理能力的完全访问。&lt;/p&gt; 
&lt;p&gt;此次更新还修复了多文件差异应用时的起始行参数不正确问题，以及 Ollama 在某些模型上出现的验证错误。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增 Claude Code provider 可用于本地 CLI 集成，允许用户将 Claude Max 订阅直接在 Roo Code 中使用，连接订阅后，使用订阅福利而非按 token 支付 API 费用，还可使用 Claude Sonnet 4、Opus 4 等高级模型，且在初始设置时选择 Claude Code 作为提供商，无需 API 密钥，还能完全访问 Claude 的思考模式和推理能力。&lt;/li&gt; 
 &lt;li&gt;修复了多个文件差异应用时起始行参数未正确工作的错误，以及解决了导致 Ollama 无法与某些模型配合使用的验证错误。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.roocode.com%2Fupdate-notes%2Fv3.21.4" target="_blank"&gt;https://docs.roocode.com/update-notes/v3.21.4&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356980/roocode-3-21-4</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356980/roocode-3-21-4</guid>
      <pubDate>Sun, 11 May 2025 03:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>vivo Pulsar 万亿级消息处理实践 (2) - 从 0 到 1 建设 Pulsar 指标监控链路</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者：vivo 互联网大数据团队- You Shuo&lt;/p&gt; 
 &lt;p&gt;本文是《vivo Pulsar 万亿级消息处理实践》系列文章第 2 篇，Pulsar 支持上报分区粒度指标，Kafka 则没有分区粒度的指标，所以 Pulsar 的指标量级要远大于 Kafka。在 Pulsar 平台建设初期，提供一个稳定、低时延的监控链路尤为重要。&lt;/p&gt; 
 &lt;p&gt;系列文章：&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;《&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzI4NjY4MTU5Nw%3D%3D%26mid%3D2247501335%26idx%3D1%26sn%3D3701be0b8b7b789e29c1ca53ba142e9d%26scene%3D21%23wechat_redirect" target="_blank"&gt;vivo Pulsar 万亿级消息处理实践-数据发送原理解析和性能调优&lt;/a&gt;》&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;本文是基于 Pulsar 2.9.2/kop-2.9.2 展开的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;作为一种新型消息中间件，Pulsar 在架构设计及功能特性等方面要优于 Kafka，所以我们引入 Pulsar 作为我们新一代的消息中间件。在对 Pulsar 进行调研的时候（比如：性能测试、故障测试等），针对 Pulsar 提供一套可观测系统是必不可少的。Pulsar 的指标是面向云原生的，并且官方提供了 Prometheus 作为 Pulsar 指标的采集、存储和查询的方案，但是使用 Prometheus 采集指标面临以下几个&lt;strong&gt;问题&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 自带的时序数据库不是分布式的，它受单机资源的限制；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 在存储时序数据时消耗大量的内存，并且 Prometheus 在实现高效查询和聚合计算的时候会消耗大量的 CPU。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;除了以上列出的可观测系统问题，Pulsar 还有一些指标本身的问题，这些问题&lt;strong&gt;包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 的订阅积压指标单位是 entry 而不是条数，这会严重影响从 Kafka 迁移过来的用户的使用体验及日常运维工作；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 没有 bundle 指标，因为 Pulsar 自动均衡的最小单位是 bundle，所以 bundle 指标是调试 Pulsar 自动均衡参数时重要的观测依据；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;kop 指标上报异常等问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;针对以上列出的几个问题，我们在下面分别展开敍述。&lt;/p&gt; 
&lt;h1&gt;二、Pulsar 监控告警系统架构&lt;/h1&gt; 
&lt;p&gt;在上一章节我们列出了使用 Prometheus 作为观测系统的局限，由于 Pulsar 的指标是面向云原生的，采用 Prometheus 采集 Pulsar 指标是最好的选择，但对于指标的存储和查询我们使用第三方存储来减轻 Prometheus 的压力，整个监控告警系统架构如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c032b72031868384106c1cc665fafc42.gif" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在整个可观测系统中，各组件的职能如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar、bookkeeper 等组件提供暴露指标的接口&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 访问 Pulsar 指标接口采集指标&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;adaptor 提供了服务发现、Prometheus 格式指标的反序列化和序列化以及指标转发远端存储的能力，这里的远端存储可以是 Pulsar 或 Kafka&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Druid 消费指标 topic 并提供数据分析的能力&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;vivo 内部的检测告警平台提供了动态配置检测告警的能力&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于以上监控系统的设计逻辑，我们在具体实现的过程中遇到了几个比较&lt;strong&gt;关键的问题：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;**一、**adaptor 需要接收 Pulsar 所有线上服务的指标并兼容 Prometheus 格式数据，所以在调研 Prometheus 采集 Pulsar 指标时，我们基于 Prometheus 的官方文档开发了 adaptor，在 adaptor 里实现了服务加入集群的发现机制以及动态配置 prometheus 采集新新加入服务的指标：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 动态加载配置：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprometheus.io%2Fdocs%2Fprometheus%2Flatest%2Fconfiguration%2Fconfiguration%2F" target="_blank"&gt;Prometheus 配置-官方文档&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prometheus 自定义服务发现机制：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprometheus.io%2Fblog%2F2015%2F06%2F01%2Fadvanced-service-discovery%2F" target="_blank"&gt;Prometheus 自定义服务发现-官方文档&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在可以动态配置 Prometheus 采集所有线上正在运行的服务指标之后，由于 Prometheus 的指标是基于 protobuf 协议进行传输的，并且 Prometheus 是基于 go 编写的，所以为了适配 Java 版本的 adaptor，我们基于 Prometheus 和 go 提供的指标格式定义文件（remote.proto、types.proto 和 gogo.proto）生成了 Java 版本的指标接收代码，并将 protobuf 格式的指标反序列化后写入消息中间件。&lt;/p&gt; 
&lt;p&gt;**二、**Grafana 社区提供的 Druid 插件不能很好的展示 Counter 类型的指标，但是 bookkeeper 上报的指标中又有很多是 Counter 类型的指标，vivo 的 Druid 团队对该插件做了一些改造，新增了计算速率的聚合函数。&lt;/p&gt; 
&lt;p&gt;druid 插件的安装可以参考官方文档（&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrafana.com%2Fgrafana%2Fplugins%2Fabhisant-druid-datasource%2F" target="_blank"&gt;详情&lt;/a&gt;）&lt;/p&gt; 
&lt;p&gt;**三、**由于 Prometheus 比较依赖内存和 CPU，而我们的机器资源组又是有限的，在使用远端存储的基础上，我们针对该问题优化了一些 Prometheus 参数，这些参数包括：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.retention=30m&lt;/strong&gt;：该参数配置了数据的保留时间为 30 分钟，在这个时间之后，旧的数据将会被删除。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.min-block-duration=5m&lt;/strong&gt;：该参数配置了生成块（block）的最小时间间隔为 5 分钟。块是一组时序数据的集合，它们通常被一起压缩和存储在磁盘上，该参数间接控制 Prometheus 对内存的占用。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--storage.tsdb.max-block-duration=5m&lt;/strong&gt;：该参数配置了生成块（block）的最大时间间隔为 5 分钟。如果一个块的时间跨度超过这个参数所设的时间跨度，则这个块将被分成多个子块。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;--enable-feature=memory-snapshot-on-shutdown&lt;/strong&gt;：该参数配置了在 Prometheus 关闭时，自动将当前内存中的数据快照写入到磁盘中，Prometheus 在下次启动时读取该快照从而可以更快的完成启动。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;三、Pulsar 指标优化&lt;/h1&gt; 
&lt;p&gt;Pulsar 的指标可以成功观测之后，我们在日常的调优和运维过程中发现了一些 Pulsar 指标本身存在的问题，这些问题包括准确性、用户体验、以及性能调优等方面，我们针对这些问题做了一些优化和改造，使得 Pulsar 更加通用、易维护。&lt;/p&gt; 
&lt;h2&gt;3.1 Pulsar 消费积压指标&lt;/h2&gt; 
&lt;p&gt;原生的 Pulsar 订阅积压指标单位是 entry，从 Kafka 迁移到 Pulsar 的用户希望 Pulsar 能够和 Kafka 一样，提供以消息条数为单位的积压指标，这样可以方便用户判断具体的延迟大小并尽量不改变用户使用消息中间件的习惯。&lt;/p&gt; 
&lt;p&gt;在确保配置 brokerEntryMetadataInterceptors=&lt;/p&gt; 
&lt;p&gt;org.apache.pulsar.common.intercept.AppendIndexMetadataInterceptor 情况下，Pulsar broker 端在往 bookkeeper 端写入 entry 前，通过拦截器往 entry 的头部添加索引元数据，该索引在同一分区内单调递增，entry 头部元数据示例如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;biz-log-partition-1 -l 24622961 -e 6
Batch Message ID: 24622961:6:0
Publish time: 1676917007607
Event time: 0
Broker entry metadata index: 157398560244
Properties:
"X-Pulsar-batch-size    2431"
"X-Pulsar-num-batch-message    50"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以分区为指标统计的最小单位，基于 last add confirmed entry 和 last consumed entry 计算两个 entry 中的索引差值，即是订阅在每个分区的数据积压。下面是 cursor 基于订阅位置计算订阅积压的示意图，其中 last add confirmed entry 在拦截器中有记录最新索引，对于 last consumed entry，cursor 需要从 bookkeeper 中读取，这个操作可能会涉及到 bookkeeper 读盘，所以在收集延迟指标的时候可能会增加采集的耗时。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f954824fee0a365add038a1a9aed4e3b.gif" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上图是新订阅积压指标和原生积压指标的对比，新增的订阅积压指标单位是条，原生订阅积压指标单位是 entry。在客户端指定单条发送 100w 条消息时，订阅积压都有明显的升高，当客户端指定批次发送 100w 条消息的时候，新的订阅积压指标会有明显的升高，而原生订阅积压指标相对升高幅度不大，所以新的订阅积压指标更具体的体现了订阅积压的情况。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a62f11043d23bcbc8c667854834e2437.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3.2 Pulsar bundle 指标&lt;/h2&gt; 
&lt;p&gt;Pulsar 相比于 Kafka 增加了自动负载均衡的能力，在 Pulsar 里 topic 分区是绑定在 bundle 上的，而负载均衡的最小单位是 bundle，所以我们在调优负载均衡策略和参数的时候比较依赖 bunlde 的流量分布指标，并且该指标也可以作为我们切分 bundle 的参考依据。我们在开发 bundle 指标的时候做了下面两件事情：&lt;/p&gt; 
&lt;p&gt;统计当前 Pulsar 集群非游离状态 bundle 的负载情况对于处于游离状态的 bundle（即没有被分配到任何 broker 上的 bundle），我们指定 Pulsar leader 在上报自身 bundle 指标的同时，上报这些处于游离状态的 bundle 指标，并打上是否游离的标签。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;效果&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d465e1009a88707edf424e50711bfd36.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上图就是 bundle 的负载指标，除了出入流量分布的情况，我们还提供了生产者/消费者到 bundle 的连接数量，以便运维同学从更多角度来调优负载均衡策略和参数。&lt;/p&gt; 
&lt;h2&gt;3.3 kop 消费延迟指标无法上报&lt;/h2&gt; 
&lt;p&gt;在我们实际运维过程中，重启 kop 的 Coordinator 节点后会偶发消费延迟指标下降或者掉 0 的问题，从 druid 查看上报的数据，我们发现在重启 broker 之后消费组就没有继续上报 kop 消费延迟指标。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）原因分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;由于 kop 的消费延迟指标是由 Kafka lag exporter 采集的，所以我们重点分析了 Kafka lag exporter 采集消费延迟指标的逻辑，下图是 Kafka-lag-exporter 采集消费延迟指标的示意图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e1c60c3dfc3fbdfdcbacbe9501bd9c30.gif" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;其中，kafka-lag-exporter 计算消费延迟指标的逻辑会依赖 kop 的 describeConsumerGroups 接口，但是当 GroupCoordinator 节点重启后，该接口返回的 member 信息中 assignment 数据缺失，kafka-lag-exporter 会将 assignment 为空的 member 给过滤掉，所以最终不会上报对应 member 下的分区指标，代码调试如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//44161110538352a1751268f3d5e09c35.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//756d27b220d957877e1713dd1ac7e29a.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为什么 kop/Kafka describeConsumerGroups 接口返回 member 的 assignment 是空的？因为 consumer 在启动消费时会通过 groupManager.storeGroup 写入__consumer_&lt;/p&gt; 
&lt;p&gt;offset，在 coordinator 关闭时会转移到另一个 broker，但另一个 broker 并没有把 assignment 字段反序列化出来（序列化为 groupMetadataValue，反序列化为 readGroupMessageValue），如下图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//378c807ffd55bb262d54d26e52e6d73a.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）解决方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 GroupMetadataConstants#readGroup-&lt;/p&gt; 
&lt;p&gt;MessageValue() 方法对 coordinator 反序列化消费组元数据信息时，将 assignment 字段读出来并设置（序列化为 groupMetadataValue，反序列化为 readGroupMessageValue），如下图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//97fe15c2e044eb609406a2ab3d5e51e8.png" alt="图片" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;四、总结&lt;/h1&gt; 
&lt;p&gt;在 Pulsar 监控系统构建的过程中，我们解决了与用户体验、运维效率、Pulsar 可用性等方面相关的问题，加快了 Pulsar 在 vivo 的落地进度。虽然我们在构建 Pulsar 可观测系统过程中解决了一部分问题，但是监控链路仍然存在单点瓶颈等问题，所以 Pulsar 在 vivo 的发展未来还会有很多挑战。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18619289</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18619289</guid>
      <pubDate>Sun, 11 May 2025 03:41:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>谷歌开源智能体通信协议 Agent2Agent (A2A) 已被 Linux 基金会接管</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 6 月 23 日，Linux 基金会在北美开源峰会&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.linuxfoundation.org%2Fpress%2Flinux-foundation-launches-the-agent2agent-protocol-project-to-enable-secure-intelligent-communication-between-ai-agents" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;启动&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fa2aproject%2FA2A" target="_blank"&gt;Agent2Agent（A2A）&lt;/a&gt;项目。该项目由谷歌于 2025 年 4 月发起并获得 100 多家领先技术公司支持，旨在创建一个开放协议，实现 AI 智能体间的安全通信与协作。Linux 基金会将负责 A2A 项目的管理，确保其中立性、协作性和治理性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8fe3e4a0fa786414ab6de80f762399a6327.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;A2A 协议赋予开发者构建跨平台、厂商和框架自由互操作的智能体的能力。它允许智能体在动态多智能体环境中发现彼此、安全交换信息并跨系统协作。这有助于提高模块化程度、降低供应商锁定风险并加速创新。&lt;/p&gt; 
&lt;p&gt;加入 Linux 基金会后，A2A 规范化了其对开放、协作生态系统的承诺——提供更大的自主权并提高生产力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Linux 基金会执行董事吉姆·泽姆林表示，「我们很高兴成为 Agent2Agent 协议项目的新家园，通过加入 Linux 基金会，A2A 将确保长期的中立性、协作性和治理性，这将解锁下一代由智能体间协作驱动的生产力时代。」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Linux 基金会的治理下，A2A 将保持供应商中立，强调包容性贡献，并继续关注协议的扩展性、安全性以及跨行业的实际可用性。&lt;/p&gt; 
&lt;p&gt;多家科技巨头表达了对 A2A 项目的支持。AWS 副总裁 Swami Sivasubramanian 认为，智能体 AI 对客户体验至关重要，A2A 加入 Linux 基金会将创造更多机会。谷歌云计算业务副总裁兼总经理 Rao Surapaneni 表示，A2A 协议为通信建立了重要开放标准，推动了跨平台和系统的真正互操作性 AI 智能体的发展。思科 Outshift 总经理兼高级副总裁 Vijoy Pandey 强调了社区驱动开发在智能体间广泛采用中的重要性。Salesforce 产品架构师 Gary Lerhaupt 称，企业 AI 的未来在于智能体间的无缝协作。SAP 全球人工智能高级副总裁兼全球负责人 Walter Sun 表示，A2A 开放标准确保了不同厂商的智能体能够交互、共享上下文并协同工作。微软产品副总裁 Yina Arenas 承诺，将结合开放互操作性与企业级功能，负责任地大规模部署智能体。ServiceNow 平台工程与人工智能技术集团执行副总裁 Joe Davis 表示，A2A 的开放标准构建了跨平台协作的基础。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356965/linux-foundation-launches-the-agent2agent-protocol-project</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356965/linux-foundation-launches-the-agent2agent-protocol-project</guid>
      <pubDate>Sun, 11 May 2025 02:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>抢答题：「把文字变成数字」、「对结果精修」，都是什么技术？</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;写 AI 应用，你总不能就指望大模型直出的效果吧，很多必要的时候，需要「通过外部策略」的方式去影响大模型处理资料的逻辑，检索增强生成技术&amp;nbsp;RAG 是这种路数，而 RAG 中，Embedding 和 Reranker 又是重中之重的环节，当前这两个环节也都有专门模型化范式来接入，并且已成为高效构建智能问答、知识检索、推荐系统等应用的核心组件。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智能问答&lt;/strong&gt;：通过高精度的 Embedding 建立问答对检索索引，结合 Reranker 精细排序，显著提升答案的相关性与准确率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;知识库检索&lt;/strong&gt;：在海量文档中精准定位用户意图，支持多轮对话和上下文关联检索。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐系统&lt;/strong&gt;：基于用户历史行为与商品描述生成向量表示，实现个性化推荐、相似内容召回。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;舆情监测&lt;/strong&gt;：快速将海量文本转为向量，通过聚类与分类算法进行主题发现与情感分析。&lt;/p&gt; 
&lt;p&gt;这些都是典型的需要&amp;nbsp;Embedding 与 Reranker 给力的场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0624/103257_8UDj_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这过程中，「把文字变成数字」与「对检索结果精修」是两大核心环节。下面以通俗的方式，分两块为你说明 Embedding 和 Reranker 的原理与价值。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Embedding：把语义「压缩」成向量&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;想象你在把一本书里的每句话都翻译成一长串数字，这串数字既要能表达句子的中心意思，又要在空间里与含义相近的句子靠得更近。Embedding 模型，就是完成这件「翻译」工作的机器。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多层语义提取&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Embedding 模型内部运用了多层 Transformer 编码器。第一层关注词与词之间的基本搭配（如「苹果」与「果汁」关系）；中间层捕捉句子结构（比如主谓宾），最后几层则把整句话和上下文联系起来，形成一个高维向量。在 Qwen3‑Embedding‑8B 中，这个向量高达 4096 维，让模型能够在更广的维度上区分细微差异。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对比学习让向量更「聪明」&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;训练时，模型不仅看成对的问答或同义句怎么对应，更会把数千万甚至上亿条不相关的句子拉远。这样，真正相似的句子在向量空间里互相靠近，不相干的句子被推得更远，检索时才不会把「苹果手机电池续航」误当成「香蕉营养价值」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;动静结合的量化策略&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;向量越大，存储和检索压力越大。动态量化技术能让模型在运行时自动决定哪些维度可以用更低精度来存（节省空间），哪些维度要保持高精度（保证关键语义不丢失）。在实际部署中，这让检索速度实现了「百毫秒级」响应，同时节省了约 60–70% 的存储。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Reranker：给检索结果「打分」再排序&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Embedding 检索出来的是一个粗略的「候选集」，真正要交给用户之前，还需要一位「品质检验师」——Reranker，将这些候选答案再打一遍分、排个序，让最优答案排在最前面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;深度交互，跳出双塔局限&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;传统双塔结构（query 和 document 分别编码）虽然高效，但只在编码后进行一次简单匹配，会错失一些深度关联。我们的 Reranker 在两侧编码后，还会引入多轮交互注意力——就好像让问题和答案反复「对话」，捕捉细节差异，才能判断「哪句话更贴近用户真实意图」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;实时反馈持续进化&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当用户点击某个答案或给出负面评价时，这些行为会被立即反馈到在线增量学习系统中。Reranker 会在后台快速微调自身参数，就像运动员不断根据比赛录像调整战术，保证随着业务热点变化，排序效果始终领先。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;多目标优化兼顾公平与准确&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;除了相关性打分外，模型还联合了分类（这是不是好答案？）、回归（该答案得分应该是多少？）和对比损失（同类答案之间应该怎么排）三个目标共同训练，确保排序既精准又稳定，不会因为单一指标过拟合而出现极端情况。&lt;/p&gt; 
&lt;p&gt;总的来说，&lt;strong&gt;Embedding 负责将文本「量化」到高维空间，为检索打下基础；Reranker 则在此基础上「打磨」结果，确保输给用户的是最精炼、最相关的答案&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;为了让更多开发者和企业能够零门槛体验最前沿的 AI 能力，模力方舟携手国产 GPU 厂商，重磅宣布——&lt;strong&gt;已部署的 17 个 Embedding 和 Reranker 模型，全量免费使用&lt;/strong&gt;！&lt;/p&gt; 
&lt;p&gt;&lt;img height="964" src="https://static.oschina.net/uploads/space/2025/0624/103342_VXq3_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;还有更多的免费模型选择，尽在模力方舟之模型广场：&lt;em&gt;&lt;strong&gt;&lt;a href="https://ai.gitee.com/serverless-api" target="_blank"&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1520" src="https://static.oschina.net/uploads/space/2025/0624/103354_4RFB_2720166.png" width="1074" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;好东西一起分享之，图片拿去转吧。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356959</guid>
      <pubDate>Sun, 11 May 2025 02:34:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软发布设备端模型 Mu，支持在 Windows 中设置智能体</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindowsexperience%2F2025%2F06%2F23%2Fintroducing-mu-language-model-and-how-it-enabled-the-agent-in-windows-settings%2F" target="_blank"&gt;宣布&lt;/a&gt;推出面向设备端的小参数模型 Mu。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1294" src="https://static.oschina.net/uploads/space/2025/0624/103032_Y3sh_2720166.png" width="3086" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Mu 仅有 3.3 亿参数，但其性能可以比肩微软之前发布的小参数模型 Phi-3.5-mini，体量却比它小 10 倍左右，并且在离线 NPU 的笔记本设备上，可以跑出每秒超过 100 tokens 的响应，这在小参数模型领域非常罕见。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0fe4a5c2aa3f7e02f94f3883e0a0a49dd2c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，Mu 支持在 Windows 中设置智能体，可将自然语言指令实时转化为系统操作，例如，只需对着电脑说一句 「把鼠标指针调大一些，调整屏幕亮度」，智能体就能精准定位到相关设置项一键完成调整。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356958/microsoft-mu-language-model-</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356958/microsoft-mu-language-model-</guid>
      <pubDate>Sun, 11 May 2025 02:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>前字节 Seed 大语言模型负责人乔木被辞退</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;此前，一份有关字节跳动豆包大模型核心技术人员乔某及同组 HRBP 程某存在不正当关系的举报文件在网上广泛传播。6 月 23 日，红星资本局获悉，字前字节 Seed 大语言模型负责人乔木以及关联 HRBP 已被辞退。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-d1fc69ad929f39468990c7341f686a6bd81.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;字节在最新发布的一期廉政通报中提到：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;公司 Seed 部门（字节跳动豆包大模型团队）某前员工与支持其团队的某前 HRBP（人力资源）存在未申报的亲密关系，属于公司利益冲突管理规定的禁止场景（如上下级关系、共同直属上级或一方为另一方 HRBP 等）。二人不仅未按规定申报利益冲突，且在接受调查过程中多次作虚假陈述，严重违反公司制度。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据通报，字节跳动已对涉事二人作出辞退处理，并全额扣发其年终奖。对此，字节官方尚无说法。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356956</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356956</guid>
      <pubDate>Sun, 11 May 2025 02:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>博士生用 Typst 取代 LaTeX 写论文引热议：编译速度快 9 倍，但导师并不满意</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;一位博士生最近在网上分享了自己使用 Typst（而非传统的 LaTeX）撰写博士论文的经历，在技术社区引发了激烈讨论。这个选择看似小众，却触及了学术界一个由来已久的痛点：LaTeX 虽然功能强大，但学习曲线陡峭、编译速度缓慢、错误信息晦涩难懂。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="400" src="https://oscimg.oschina.net/oscnet/up-da99f6b5d1fdd0954f78d4992bf7563f660.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;从 90 秒到 10 秒：速度是第一生产力&lt;/h2&gt; 
&lt;p&gt;作者选择 Typst 的直接原因很简单——一位朋友的 LaTeX 论文编译时间竟然长达 90 秒。「我太容易分心了，根本无法忍受在做小改动时要等 90 秒的编译时间。」相比之下，Typst 的编译速度快得惊人：即使是 150 页以上的论文，完整编译只需 15 秒，内容修改几乎是即时更新的。&lt;/p&gt; 
&lt;p&gt;HackerNews 用户 WhyNotHugo 深有同感：「我最后一篇论文用的是 makefile，通常能工作。但不工作时，运行两次就能修复。最罕见的情况下，我必须运行&lt;code&gt;git clean -xdf&lt;/code&gt;，然后下一次运行就能工作了。」另一位用户 shusaku 则幽默地评论道：「疯狂的定义就是做同样的事情两次却期待不同的结果。巧合的是，这正是编译 LaTeX 的基本方式。」&lt;/p&gt; 
&lt;h2&gt;Typst 的语言设计：现代化的力量&lt;/h2&gt; 
&lt;p&gt;Typst 最大的亮点在于其精心设计的语言。作者将其描述为「Markdown 和动态类型 Rust 的混合体」，这种组合听起来很奇怪，但实际使用起来却非常舒适。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typst"&gt;#let numbers = (1,2,5,8)
This is *bold text*. The sum of [#numbers.map(it =&amp;gt; str(it)).join(", ")] is *#numbers.sum()*
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这段代码会生成：「This is &lt;strong&gt;bold text&lt;/strong&gt;. The sum of [1, 2, 5, 8] is &lt;strong&gt;16&lt;/strong&gt;」&lt;/p&gt; 
&lt;p&gt;相比 LaTeX 中到处都是反斜杠的语法，Typst 的设计更加直观。更重要的是，Typst 拥有一个设计良好的脚本语言。正如作者所说：「我对 LaTeX 最大的抱怨是没有任何东西是一致的。每个包都定义自己的小工具，甚至连基本的 if 语句都不统一。感觉你不是在学 LaTeX，而是在分别学习每个包。」&lt;/p&gt; 
&lt;h2&gt;实际应用：不只是纸上谈兵&lt;/h2&gt; 
&lt;p&gt;作者展示了一个实际案例：他收集了各种硬件描述语言的元数据，存储在 TOML 文件中。由于 Typst 可以直接解析 TOML，他能够轻松地用这些数据生成论文中的分类图表。这种程度的编程集成在 LaTeX 中几乎是不可想象的。&lt;/p&gt; 
&lt;p&gt;HackerNews 用户 lizimo 分享了更有趣的应用场景：「我们已经在生产环境中使用 Typst 生成 PDF 文档几个月了，比如发票和标签。每天生成数千份文档，我很高兴其中一些被打印出来，供仓库里做实际工作的人使用。」&lt;/p&gt; 
&lt;h2&gt;痛点仍在：生态系统的挑战&lt;/h2&gt; 
&lt;p&gt;然而，Typst 并非完美无缺。最大的问题来自于参考文献管理。Typst 每个文档只能有一个参考文献部分和文件，这对于需要为引言和每篇包含的论文分别设置参考文献的博士论文来说是个致命缺陷。虽然 Alexandria 包提供了解决方案，但仍需要额外的工作。&lt;/p&gt; 
&lt;p&gt;更大的挑战在于生态系统。正如 HackerNews 用户 gumbojuice 指出：「我坚持使用 LaTeX，不是因为偏好，而是因为期刊/会议仍然不接受比如 typst。他们会接受吗？我不知道，这取决于他们是否愿意将其整合到工具链中。」&lt;/p&gt; 
&lt;h2&gt;导师的不同视角&lt;/h2&gt; 
&lt;p&gt;有趣的是，作者的导师对此有完全不同的看法。导师认为：「问题是你必须调整它才能让事情看起来符合要求。这不一定是优势。作为导师，我会建议在所有手稿都用 LaTeX 编写的领域中使用 Typst 吗？不会。」&lt;/p&gt; 
&lt;p&gt;导师特别指出，从监督者的角度来看，他几乎没有在源代码中编辑任何文本，而是让作者自己编辑文本和格式，这相当低效。&lt;/p&gt; 
&lt;h2&gt;社区的两极化反应&lt;/h2&gt; 
&lt;p&gt;HackerNews 的讨论呈现出明显的两极分化。支持者认为 Typst 代表了未来。用户 commandersaki 列出了 Typst 的诸多优势：「编译时不会生成 5 个该死的文件」、「编译是即时的」、「诊断信息更容易理解（有点像 Rust 编译器的建议风格）」。&lt;/p&gt; 
&lt;p&gt;反对者则担心 Typst 的持续性。用户 dleslie 警告说：「三十年后 LaTeX 仍将是开源的，可能还会被维护。Typst 看起来是开源和闭源的混合体；这种模式往往会忽视开源部分，在闭源部分实现关键功能。」&lt;/p&gt; 
&lt;p&gt;用户 the-wumpus 则反驳道：「网页应用编辑器是闭源的，但它提供的大部分功能都是开源的，所以本地编辑体验类似（在我看来更好）。typst 编译器、LSP 和你需要使用的所有东西都是开源的。」&lt;/p&gt; 
&lt;h2&gt;写在最后&lt;/h2&gt; 
&lt;p&gt;正如作者在结论中所说：「如果你像我一样，喜欢玩编程语言，容易被工具困扰，更喜欢可以调整到完全符合自己要求的工具，而不是开箱即用但难以调整的工具，那么 Typst 绝对值得一试。」&lt;/p&gt; 
&lt;p&gt;对于学术界来说，Typst 的出现提供了一个思考的契机：我们是否应该继续忍受 LaTeX 的种种不便，仅仅因为「大家都在用」？还是应该拥抱新技术带来的效率提升？&lt;/p&gt; 
&lt;p&gt;用户 rcpt 的评论或许代表了一种新的可能：「自从我写 LaTeX 以来已经有十年了，我同意它的所有痛点。但似乎 LaTeX 正是 LLM 会完美处理的东西。我觉得今天使用它不会太糟糕。」&lt;/p&gt; 
&lt;p&gt;无论选择哪种工具，重要的是它能帮助研究者更好地表达思想。正如用户 noelwelsh 所说：「在一天结束时，我不是在试图迁移任何人。使用你认为最好的。对于我的使用场景，我确信 Typst 是比 LaTeX 更好的选择。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356954</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356954</guid>
      <pubDate>Sun, 11 May 2025 01:57:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Solon Expression Language (SnEL)：轻量高效的 Java 表达式引擎</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;h2&gt;一、SnEL 是什么？&lt;/h2&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;Solon Expression Language（简称 SnEL）是 Solon 生态体系中的轻量级表达式引擎，专为 Java 开发者设计。它采用独特的"求值表达式"模型，通过简洁的语法实现复杂逻辑处理，同时保持极高的执行效率和安全性。&lt;/p&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;项目地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Gitee:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/noear/solon-expression"&gt;https://gitee.com/noear/solon-expression&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub:&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnoear%2Fsolon-expression" target="_blank"&gt;https://github.com/noear/solon-expression&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二、核心特性解析&lt;/h2&gt; 
&lt;h3&gt;1. 安全可靠的表达式引擎&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;无副作用设计&lt;/strong&gt;：禁止&lt;code&gt;new&lt;/code&gt;实例化、控制语句等危险操作&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;上下文隔离&lt;/strong&gt;：通过&lt;code&gt;StandardContext&lt;/code&gt;严格管控变量访问范围&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 丰富的表达式能力&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 复杂逻辑表达式示例&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;expr&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"""
    ((age &amp;gt; 18 AND salary &amp;lt; 5000) OR NOT isMarried) 
    AND tags IN ['vip','premium'] 
    OR level == 'gold'"""&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;支持功能主要包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基础运算：算术、比较、逻辑运算&lt;/li&gt; 
 &lt;li&gt;集合操作：IN/NOT IN 集合判断&lt;/li&gt; 
 &lt;li&gt;嵌套访问：多级对象属性/方法调用&lt;/li&gt; 
 &lt;li&gt;静态方法：直接调用类静态方法&lt;/li&gt; 
 &lt;li&gt;三元运算：条件表达式支持&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;更多参考官网：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Farticle%2F1043" target="_blank"&gt;《SnEL 求值表达式语法和能力说明》&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. 独创的模板引擎&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;双模式模板处理：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 求值表达式模板&lt;/em&gt;
SnEL.evalTmpl(&lt;span style="color:#50a14f"&gt;"订单总额：#{order.amount * 0.95}"&lt;/span&gt;);

&lt;em&gt;// 属性表达式模板（带默认值）&lt;/em&gt;
SnEL.evalTmpl(&lt;span style="color:#50a14f"&gt;"配置参数：${server.timeout:3000}"&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;三、企业级功能深度解析&lt;/h2&gt; 
&lt;h3&gt;1. 上下文增强方案&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 标准 Map 上下文&lt;/em&gt;
Map&amp;lt;String,Object&amp;gt; ctx = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;HashMap&lt;/span&gt;&amp;lt;&amp;gt;();
ctx.put(&lt;span style="color:#50a14f"&gt;"user"&lt;/span&gt;, userService.getCurrent());

&lt;em&gt;// 增强型 Bean 上下文&lt;/em&gt;
&lt;span style="color:#986801"&gt;StandardContext&lt;/span&gt; &lt;span style="color:#986801"&gt;context&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;StandardContext&lt;/span&gt;(userEntity);
context.properties(configProps); &lt;em&gt;// 绑定配置属性&lt;/em&gt;

&lt;em&gt;// 虚拟 root 访问&lt;/em&gt;
SnEL.eval(&lt;span style="color:#50a14f"&gt;"root.id &amp;gt; 1000"&lt;/span&gt;, context);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 多场景表达式转换&lt;/h3&gt; 
&lt;p style="color:#24292e; text-align:start"&gt;基于 AST 的通用转换接口：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#986801"&gt;Expression&lt;/span&gt; &lt;span style="color:#986801"&gt;expr&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.parse(&lt;span style="color:#50a14f"&gt;"age &amp;gt; 18 AND status=='active'"&lt;/span&gt;);

&lt;em&gt;// 转换为 Redis 查询语法&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;redisFilter&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; RedisFilterTransformer.getInstance().transform(expr);

&lt;em&gt;// 转换为 Elasticsearch DSL&lt;/em&gt;
Map&amp;lt;String,Object&amp;gt; esQuery = ElasticsearchFilterTransformer.getInstance().transform(expr);

&lt;em&gt;// 输出语法树结构&lt;/em&gt;
PrintUtil.printTree(expr);
&lt;/code&gt;&lt;/pre&gt; 
&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px"&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;转换器类型&lt;/th&gt; 
   &lt;th&gt;输出示例&lt;/th&gt; 
   &lt;th&gt;应用场景&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Redis&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;(@age:[18 +inf] @status:{active})&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;缓存查询&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Milvus&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;((metadata["age"] &amp;gt; 18) and (metadata["status"] == "active"))&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;向量数据库&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;Elasticsearch&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;{bool={must=[{range={age={gt=18}}}, {term={status={value=active}}}]}}&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;全文检索&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;SQL&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;&lt;code&gt;WHERE age &amp;gt; 18 AND status='active'&lt;/code&gt;&lt;/td&gt; 
   &lt;td style="border-color:#dfe2e5; border-style:solid; border-width:1px"&gt;数据库查询&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;四、典型应用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;动态规则引擎：金融风控规则配置&lt;/li&gt; 
 &lt;li&gt;智能路由：微服务调用条件路由&lt;/li&gt; 
 &lt;li&gt;低代码平台：表单校验逻辑动态配置&lt;/li&gt; 
 &lt;li&gt;数据分析：实时数据过滤与计算&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;五、快速入门&lt;/h2&gt; 
&lt;h3&gt;1. 添加依赖&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.noear&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;solon-expression&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;最新版本&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;span style="color:#e45649"&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. 基础用法示例&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;class&lt;/span&gt; &lt;span style="color:#c18401"&gt;Demo&lt;/span&gt; {
    &lt;span style="color:#a626a4"&gt;public&lt;/span&gt; &lt;span style="color:#a626a4"&gt;static&lt;/span&gt; &lt;span style="color:#a626a4"&gt;void&lt;/span&gt; &lt;span style="color:#4078f2"&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; {
        Map&amp;lt;String,Object&amp;gt; context = &lt;span style="color:#a626a4"&gt;new&lt;/span&gt; &lt;span style="color:#c18401"&gt;HashMap&lt;/span&gt;&amp;lt;&amp;gt;();
        context.put(&lt;span style="color:#50a14f"&gt;"price"&lt;/span&gt;, &lt;span style="color:#986801"&gt;99.5&lt;/span&gt;);
        context.put(&lt;span style="color:#50a14f"&gt;"discount"&lt;/span&gt;, &lt;span style="color:#986801"&gt;0.8&lt;/span&gt;);
        
        &lt;span style="color:#986801"&gt;Object&lt;/span&gt; &lt;span style="color:#986801"&gt;result&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.eval(&lt;span style="color:#50a14f"&gt;"price * discount &amp;gt; 50"&lt;/span&gt;, context);
        System.out.println(&lt;span style="color:#50a14f"&gt;"是否符合条件："&lt;/span&gt; + result);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. 性能优化建议&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;复用解析结果：对固定表达式使用 SnEL.parse() 缓存 AST&lt;/li&gt; 
 &lt;li&gt;上下文优化：复杂对象优先使用 StandardContext&lt;/li&gt; 
 &lt;li&gt;避免频繁解析：高并发场景预编译表达式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;六、企业实践案例&lt;/h2&gt; 
&lt;h3&gt;案例 1：电商促销系统&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-java"&gt;&lt;em&gt;// 动态计算促销条件&lt;/em&gt;
&lt;span style="color:#986801"&gt;String&lt;/span&gt; &lt;span style="color:#986801"&gt;rule&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span style="color:#50a14f"&gt;"""
    (user.level IN ['VIP','SVIP'] OR order.amount &amp;gt; 1000) 
    AND inventory.stock &amp;gt; 0 
    AND NOT blacklist.contains(user.id)"""&lt;/span&gt;;
    
&lt;span style="color:#986801"&gt;Boolean&lt;/span&gt; &lt;span style="color:#986801"&gt;rst&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; SnEL.eval(rule, context);&lt;/code&gt;&lt;/pre&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356941</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356941</guid>
      <pubDate>Sun, 11 May 2025 00:43:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>🎉夜莺监控 V8 发版，内置支持 DeepSeek 对接</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#333333; text-align:left"&gt;夜莺监控发布了 v8.beta14 版本，这个版本是可以上生产的，强烈建议升级。正式版会在每年夜莺大会上发布，今年预计是 7.4 号。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;下面快速介绍一下 v8.beta14 的主要更新。&lt;/p&gt; 
&lt;h2&gt;beta14 重点更新&lt;/h2&gt; 
&lt;h3&gt;支持 Postgres 告警&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;又支持了一个新的告警数据源：Postgres，可以对 Postgres 中的数据做异常判定啦，有些业务数据（比如订单数据、商品数据）可能是存在 Postgres 或 MySQL 等 OLTP 库中，所以这算是多了一个业务数据告警的手段，业务监控的告警规则不用很多，但是通常都极为关键。&lt;/p&gt; 
&lt;p&gt;&lt;img height="630" src="https://oscimg.oschina.net/oscnet/up-e30994bca7c3d950bb85c39db5c1e5ccd77.png" width="1890" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;您可以在&lt;code&gt;集成中心-数据源&lt;/code&gt;添加 Postgres 数据源，目前的开源版本，该数据源仅支持告警，不支持看图（即时查询、仪表盘等）。&lt;/p&gt; 
&lt;h3&gt;对接 AI 做 Summary&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;告警事件 Pipeline 新增一个新的内置处理器：AI Summary，可以使用 DeepSeek 等对告警事件做总结，将总结之后的信息附加到告警事件中，进而通过告警消息发出。让您的监控与 AI 之间的联动触手可及。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1190" src="https://oscimg.oschina.net/oscnet/up-8c07f9b00aebd755c3f0a894362cb7207f8.png" width="2002" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;填入 AI 服务器的地址和 API Key，以及要使用的模型，即可引入 AI Summary 的能力。夜莺内置提供了一个提示词，您可以根据自己的需求修改提示词。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;更多使用文档，可以参考红色箭头指向的那个&lt;code&gt;使用说明&lt;/code&gt;。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;事件处理器非常具有想象力，欢迎给我们投稿分享您的实践案例。&lt;/p&gt; 
&lt;h3&gt;告警事件匿名访问&lt;/h3&gt; 
&lt;p style="color:#333333; text-align:left"&gt;重新设计了告警事件匿名访问的逻辑。您可以在告警事件详情页面找到&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;生成分享链接&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的入口。最新逻辑是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;默认不支持匿名访问，必须登录才能看到事件详情&lt;/li&gt; 
 &lt;li&gt;通过&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;生成分享链接&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;可以生成一个带 token（有过期时间）的 URL，访问那个 URL 就可以匿名访问了&lt;/li&gt; 
 &lt;li&gt;如果夜莺配置文件 config.toml 中直接开启了全局的匿名访问，则匿名访问的 token 就没用了，只要访问&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;/share/alert-his-events/${id}&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;就会直接放行，配置文件中的全局匿名访问配置位置是：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;&lt;span&gt;&lt;span&gt;[&lt;span style="color:#a6e22e"&gt;Center&lt;/span&gt;.&lt;span style="color:#a6e22e"&gt;AnonymousAccess&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#a6e22e"&gt;PromQuerier&lt;/span&gt; = &lt;span style="color:#66d9ef"&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 就是下面这个&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#a6e22e"&gt;AlertDetail&lt;/span&gt; = &lt;span style="color:#66d9ef"&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;p style="color:#333333; text-align:left"&gt;如果夜莺开放在公网，请不要打开匿名访问！&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;其他 Changelog 请参考&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale%2Freleases%2Ftag%2Fv8.0.0-beta.14" target="_blank"&gt;github release&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;页面。&lt;/p&gt; 
&lt;h2&gt;升级须知&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;大家可以从夜莺的&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fccfos%2Fnightingale%2Freleases" target="_blank"&gt;github releases&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;页面下载到最新的发布包。&lt;/p&gt; 
&lt;p style="color:#333333; text-align:left"&gt;v6/v7 版本都可以平滑升级：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;建议先备份老版本的二进制、配置、integrations 目录等，留好后路，然后就可以放心大胆升级了&lt;/li&gt; 
 &lt;li&gt;如果夜莺所用的 DB 账号有建表、改表权限，会自动更新表结构，否则就要参考代码仓库里&amp;nbsp;docker/migratesql&amp;nbsp;手工改表结构了&lt;/li&gt; 
 &lt;li&gt;integrations 目录可以直接替换成新版&lt;/li&gt; 
 &lt;li&gt;配置文件 etc/config.toml 建议认真 diff 一下&lt;/li&gt; 
 &lt;li&gt;容器启动的话，直接拉取 latest 镜像重启即可&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;夜莺产品特性介绍的 PPT&lt;/h2&gt; 
&lt;p style="color:#333333; text-align:left"&gt;有些人可能对夜莺的产品还不太了解，特准备了一份 PPT，请参考：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fc9xudyniiq.feishu.cn%2Fslides%2FO6xJsUzZclzeUrdMb9DcynVtnSf" target="_blank"&gt;PPT&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356937/nightingale-release-v8beta-14</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356937/nightingale-release-v8beta-14</guid>
      <pubDate>Sun, 11 May 2025 00:17:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>宇树王兴兴为高考生送上报考建议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;随着高考成绩、分数线陆续公布，对于那些想投身具身智能行业的考生，宇树科技创始人王兴兴发文结合自身的经历给出一些专业报考建议。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="264" src="https://oscimg.oschina.net/oscnet/up-513fc7219a635ce3cbb2d6d3d7ae7738440.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你从小喜欢拆解维修一些电子产品，或者动手 DIY 做点东西，推荐学习机械或电子相关专业。具体的专业细分名字很多，请注意区分，对于自己感兴趣的学校和专业，大家最好直接去对应学院的官网，直接看看具体的详细介绍，看看老师们在做什么课题或项目。哪怕专业名字一模一样，每个学校的差别也非常大。中间如果想多学习 AI，也可以多花时间自学。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你对智能如何产生感兴趣、如果你有 AGI 的梦想，且数学还不错，推荐直接学习计算机科学/人工智能相关专业，也一并请直接多查查对应学院的详细信息，甚至可以直接先去对应实验室看看。当然，还是建议中间可以稍微花一些时间，学习一些硬件相关的原理，比如自己动手画个 PCB 板子等，简单实用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;当然，现实里，大多数同学没有那么幸运，能直接进入自己理想的学校和专业，或者进入以后发现不适合自己或者不喜欢。这其实完全不是大问题，非常常见和正常。请不要放弃努力寻找自己喜欢和擅长的事，寻找新的方向，并请一定努力去实践。你可以转专业，哪怕转不了，也一点问题没有，你可以直接去找自己感兴趣方向的老师，直接沟通去他的实验室做事，甚至完全可以直接全都自学。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;后续上学时，请大家也不要局限于书本和论文，具身智能是物理世界的智能，一定要多动手，拧螺丝、调电路、写程序、debug，马上自己动手编程，进入实验室、参与机器人比赛等等，在实战中迅速提升自己。我自己至今，也还会自己直接上手拆装零部件，敲敲代码等。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;如果你想成为最顶尖的人才，一定要超脱课本，主动持续学习，学习当下最前沿的科技领域。持续关注顶级学术会议最新论文等；积极参与最具探索性的开源项目并尝试复现和改进；与同样渴望挑战边界的同学、研究者组建小组，共同探讨前沿问题，碰撞思想。每个同学，都有机会成为全人类未来科技方向的探索者和实践者。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;最后，我想说，在未来的学业中，你们或许会感到迷茫，不知前进的方向，但不要担心，每个人都会迷茫，我也一样。在大学期间，要较多的探索自己的多种可能性，多尝试，找到爱好点和擅长点。如果你的爱好恰巧也是你擅长的，那恭喜你，你找到了可以为之奋斗一生的目标。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;在成长过程中，你们可能目睹了一次又一次的时代浪潮，见证了一个又一个商业奇迹，外贸、房地产、基建、互联网、消费电子、移动互联网、新能源汽车，等等。可能你们会羡慕前人，觉得机会变少了，觉得宇宙的科技树没有太多可以探索的了。但请不要灰心，AI 和机器人的时代才刚刚开始，还有大量的挑战和机会在等你们。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356888</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356888</guid>
      <pubDate>Sat, 10 May 2025 10:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>网易有道开源首个专注数学教育的模型 Confucius3-Math</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;网易有道宣布正式开源「子曰 3」系列大模型的数学模型（英文名称 Confucius3-Math），这是国内首个专注于数学教育，可在单块消费级 GPU 上高效运行的开源推理模型。&lt;/p&gt; 
&lt;p&gt;据了解，Confucius3-Math 是由网易有道 AI 团队开发的&lt;strong&gt;140 亿参数开源推理大语言模型&lt;/strong&gt;，专门针对 K-12 数学教育场景进行优化。与通用模型不同，Confucius3-Math 具有以下特点：&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;数学任务上的顶尖性能&lt;/strong&gt;&lt;br&gt; 通过专门的强化学习训练，在中文 K-12 数学问题上的表现超越了参数规模更大的模型&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;高性价比的部署方案&lt;/strong&gt;&lt;br&gt; 可在单张消费级 GPU（如 RTX 4090D）上高效运行&lt;/p&gt; 
&lt;p&gt;✅&lt;strong&gt;文化与课程体系的深度契合&lt;/strong&gt;&lt;br&gt; 针对中国国家数学课程标准和解题方法论进行了优化&lt;/p&gt; 
&lt;p&gt;Confucius3-Math 采用纯强化学习的后期训练流程，结合创新的数据调度策略和改进的组相对优势估计器开发而成。Confucius3-Math 在解决国内数学问题任务中展现出了显著优势。其通过大规模增强学习以及一系列的创新算法，训练成本仅为 2.6 万美元，推理性能约为 DeepSeek R1 的 15 倍。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-8732b5278351553b8f60ad1d228c44e8d50.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;附 1：Demo 地址，欢迎试用&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconfucius.youdao.com%2F" target="_blank"&gt;https://confucius.youdao.com/&lt;/a&gt;&lt;br&gt; 附 2：模型开源地址&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FConfucius3-Math" target="_blank"&gt;https://github.com/netease-youdao/Confucius3-Math&lt;/a&gt;&lt;br&gt; 附 3：论文地址&lt;br&gt; &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fnetease-youdao%2FConfucius3-Math%2Fblob%2Fmain%2FConfucius3-Math.pdf" target="_blank"&gt;https://github.com/netease-youdao/Confucius3-Math/blob/main/Confucius3-Math.pdf&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356885</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356885</guid>
      <pubDate>Sat, 10 May 2025 09:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ChinaTextbook —— 所有小初高、大学 PDF 教材</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;虽然国内教育网站已提供免费资源，但大多数普通人获取信息的途径依然受限。有些人利用这一点，在某站上销售这些带有私人水印的资源。为了应对这种情况，将这些资源集中并开源，以促进义务教育的普及和消除地区间的教育贫困。&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;小学数学&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%B8%80%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;一年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%80%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;一年级下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%BA%8C%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;二年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%BA%8C%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;二年级下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%B8%89%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;三年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%89%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;三年级下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E5%9B%9B%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;四年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%9B%9B%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;四年级下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E4%BA%94%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;五年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%BA%94%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;五年级下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%20%C2%B7%20%E6%95%B0%E5%AD%A6%E5%85%AD%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;六年级上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%B0%8F%E5%AD%A6/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AD%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;六年级下册&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;初中数学&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B8%83%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%83%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初一上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B8%83%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B8%83%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初一下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E5%85%AB%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AB%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初二上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E5%85%AB%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E5%85%AB%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初二下册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B9%9D%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B9%9D%E5%B9%B4%E7%BA%A7%E4%B8%8A%E5%86%8C.pdf"&gt;初三上册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/blob/master/%E5%88%9D%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE/%E4%B9%9D%E5%B9%B4%E7%BA%A7/%E4%B9%89%E5%8A%A1%E6%95%99%E8%82%B2%E6%95%99%E7%A7%91%E4%B9%A6%C2%B7%E6%95%B0%E5%AD%A6%E4%B9%9D%E5%B9%B4%E7%BA%A7%E4%B8%8B%E5%86%8C.pdf"&gt;初三下册&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;高中数学&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E9%AB%98%E4%B8%AD/%E6%95%B0%E5%AD%A6/%E4%BA%BA%E6%95%99%E7%89%88%EF%BC%88A%E7%89%88%EF%BC%89%EF%BC%88%E4%B8%BB%E7%BC%96%EF%BC%9A%E7%AB%A0%E5%BB%BA%E8%B7%83%26%E6%9D%8E%E5%A2%9E%E6%B2%AA%EF%BC%89-%E4%BA%BA%E6%B0%91%E6%95%99%E8%82%B2%E5%87%BA%E7%89%88%E7%A4%BE"&gt;目录&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;大学数学&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E7%AC%AC%E4%B8%83%E7%89%88"&gt;高等数学&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"&gt;线性代数&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6"&gt;离散数学&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook/tree/master/%E5%A4%A7%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA"&gt;概率论&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.dxsx.net/index.php"&gt;更多数学资料-(大学数学网)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;问题：如何合并被拆分的文件？&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;由于 GitHub 对单个文件的上传有最大限制，超过 100MB 的文件会被拒绝上传，超过 50MB 的文件上传时会收到警告。因此，文件大小超过 50MB 的文件会被拆分成每个 35MB 的多个文件。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;示例&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;文件被拆分的示例：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;义务教育教科书 · 数学一年级上册.pdf.1&lt;/li&gt;
&lt;li&gt;义务教育教科书 · 数学一年级上册.pdf.2&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;解决办法&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;要合并这些被拆分的文件，您只需执行以下步骤 (其他操作系统同理)：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将合并程序&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;下载到包含 PDF 文件的文件夹中。&lt;/li&gt;
&lt;li&gt;确保&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;和被拆分的 PDF 文件在同一目录下。&lt;/li&gt;
&lt;li&gt;双击&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;mergePDFs-windows-amd64.exe&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;程序即可自动完成文件合并。&lt;/li&gt;
&lt;/ol&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;下载方式&lt;/h3&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;您可以通过以下链接，下载文件合并程序：&lt;/p&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;&lt;a href="https://github.com/TapXWorld/ChinaTextbook-tools/releases"&gt;下载文件合并程序&lt;/a&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;文件和程序示例&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;mergePDFs-windows-amd64.exe&lt;/li&gt;
&lt;li&gt;义务教育教科书 · 数学一年级上册.pdf.1&lt;/li&gt;
&lt;li&gt;义务教育教科书 · 数学一年级上册.pdf.2&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/chinatextbook</link>
      <guid isPermaLink="false">https://www.oschina.net/p/chinatextbook</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
    </item>
    <item>
      <title>谷歌 AI 编程工具 Gemini Code Assist 发布更新，增强上下文管理能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 AI 编程助手&amp;nbsp;Gemini Code Assist 近日&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGoogleCloudTech%2Fstatus%2F1936136971849441648" target="_blank"&gt;发布更新&lt;/a&gt;&lt;/u&gt;，集成了最新的&amp;nbsp;Gemini 2.5&amp;nbsp;模型，带来了更强的个性化和更灵活的上下文管理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0623/174100_cmzw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户现在可以创建自定义快捷命令来处理重复性任务，并在&amp;nbsp;VS Code&amp;nbsp;或&amp;nbsp;JetBrains IDE&amp;nbsp;的&amp;nbsp;Gemini&amp;nbsp;设置中配置项目编码规范，这些规则在每次生成代码时自动生效。&lt;/p&gt; 
&lt;p&gt;上下文管理方面，Gemini Code Assist&amp;nbsp;支持将整个文件夹或工作区加入上下文，上下文窗口可达&amp;nbsp;100 万 tokens，并可通过「@」符号精确添加特定文件或目录。&lt;/p&gt; 
&lt;p&gt;此外，新增的上下文抽屉（Context Drawer）可视化面板能显示当前参与对话的文件与路径，支持一键添加/移除。聊天窗口右上角现可开启多个会话，所有历史对话会自动保存并支持一键恢复。&lt;/p&gt; 
&lt;p&gt;同时，Google 的&amp;nbsp;Jules 异步编码代理也将登陆&amp;nbsp;AI Studio，未来可能以「Vibe coding」桌面应用的形式推出。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356882</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356882</guid>
      <pubDate>Sat, 10 May 2025 09:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源鸿蒙代码规模突破 1.3 亿行</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEGCrwLfPlELGTq0DGmeTZw" target="_blank"&gt;据 OpenAtom OpenHarmony 分享&lt;/a&gt;，2025 年 6 月 21 日，由开源鸿蒙项目群工作委员会主办的开源鸿蒙社区年中技术会议在东莞三丫坡盛大召开。&lt;/p&gt; 
&lt;p&gt;开源鸿蒙项目群工作委员会主席、华为终端 BG 软件部总裁龚体为本次大会致辞。他表示，&lt;strong&gt;开源四年多来，开源鸿蒙实现全面生态跃迁：代码规模突破 1.3 亿行，凝聚 8700 多位开发者智慧&lt;/strong&gt;；社区治理持续升级，新增 8 个关键 SIG，系统性补齐路由、北斗、Web 等关键技术版图；400 余家生态伙伴的 1200 余款产品通过兼容性测评，覆盖金融、交通、教育、医疗、航天等多个行业领域。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8c873b452dab8e67e8a87ad3868acef8dc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;消费端同步跨越升级 —— 鸿蒙 PC、Pura X 及 nova 系列设备全面搭载 HarmonyOS 5 操作系统，2 万多个原生应用与元服务成功上架，标志着万物智联生态正式进入规模化落地新阶段。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356872</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356872</guid>
      <pubDate>Sat, 10 May 2025 09:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度文心快码 AI IDE 上线</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;百度文心快码宣布上线独立 AI 原生开发环境工具 Comate AI IDE。根据介绍，Comate AI IDE 是行业首个多模态、多智能体协同 AI IDE，首创设计稿一键转代码，模型已接入文心 4.0 X1 Turbo，开箱即用。目前百度每天新增的代码中，文心快码生成的代码占比已超过 43%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="271" src="https://oscimg.oschina.net/oscnet/up-933809d1b828cf04041454b88391e408dd4.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1a1a1a; text-align:justify"&gt;&lt;span style="color:#000000"&gt;不同于当前主流 AI 代码助手以插件形态附着在 VS Code、JetBrains 等开发平台，Comate AI IDE 完全自研，重构从编辑器交互到底层逻辑的全链路开发体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1a1a1a; text-align:justify"&gt;&lt;span style="color:#000000"&gt;核心技术上，Comate AI IDE 集成了文心 4.0 X1 Turbo 模型与升级版 Zulu 智能体，支持自动任务拆解与自主决策执行。开发者可通过自然语言或语音输入复杂需求，由智能体自主生成代码、实时预览、持续优化。例如，开发者上传 Figma 设计稿，系统可自动生成高还原度前端代码，省去大量重复性编写工作。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356871</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356871</guid>
      <pubDate>Sat, 10 May 2025 09:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克：xAI 计划用 Grok 3.5 重写人类知识库</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，马斯克在 X&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1936333964693885089" target="_blank"&gt;宣布&lt;/a&gt;，旗下 AI 公司 xAI 将用新一代大模型 Grok 3.5（或许直接叫 Grok 4）重写整个人类知识库，添加缺失信息，删除错误内容，然后基于这个「纯净版」知识库重新训练模型。&lt;/p&gt; 
&lt;p&gt;马斯克认为，在任何基于未修正数据训练的基础模型中，都有太多的垃圾。&lt;/p&gt; 
&lt;p&gt;AI 为了迎合用户的要求，会自己加戏，从而凭空想象出很多不存在，或者还未发生的细节，直接当成真实事件嵌入到文章里。而一旦这样的内容多了，这些看似真实的内容甚至会被 AI 重新咀嚼回去训练，再被下一次输出时引用。这时候，真真假假就更难以分辨了。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b1fa8925a68e196d59d0eb4bed7287ebb5b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;简单来说，马斯克想让 Grok 成为人类知识的审核员和补全者。据悉，新一代 Grok 拥有高级推理能力，能够识别知识库中的错误和缺失。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356867</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356867</guid>
      <pubDate>Sat, 10 May 2025 08:48:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
