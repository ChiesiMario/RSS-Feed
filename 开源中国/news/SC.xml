<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 28 Apr 2025 07:38:43 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>2023 年最热门的 AI 职位——「提示词工程师」已过时</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;据《华尔街日报》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fthe-hottest-ai-job-of-2023-is-already-obsolete-1961b054&quot; target=&quot;_blank&quot;&gt;报道&lt;/a&gt;，曾被誉为 2023 年最热门 AI 职位、年薪可达 20 万美元的「提示工程师」（Prompt Engineer）正迅速降温。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/144406_aPB5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根据微软近期一项覆盖 31 个国家 31,000 名员工的调查，在未来 12 至 18 个月企业考虑增设的新职位中，提示工程师排名倒数第二，远低于 AI 训练师、AI 数据专家和 AI 安全专家等职位。&lt;/p&gt; 
&lt;p&gt;所谓提示词工程，是指设计、开发、测试和优化用于与生成式 AI 模型交互的文本输入（即「提示词」），目标是引导 AI 模型生成准确且符合需求的输出，发挥 AI 模型的潜力。但是，由于 AI 模型固有的不透明性，这种操作的科学性和有效性始终存在疑问，也有很多人借此营销、行骗。&lt;/p&gt; 
&lt;p&gt;报道指出，「提示词工程师」热度发生变化的核心原因在于，&lt;strong&gt;现代 AI 模型已能更好地理解用户意图，甚至在指令不清时主动提问，大大降低了对精心设计提示词的依赖&lt;/strong&gt;。另一个关键因素是企业策略的转变。相比设立专门职位，许多公司选择对现有员工提供 AI 工具和培训，将使用 AI 的能力视为一项基础技能。&lt;/p&gt; 
&lt;p&gt;招聘市场的实际数据也印证了这一趋势。尽管在 ChatGPT 面世后，用户对「提示工程师」的搜索量曾短暂飙升，但企业发布的实际招聘岗位数量始终极少，搜索热度也已大幅回落并趋于平稳。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347101</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347101</guid>
            <pubDate>Mon, 28 Apr 2025 06:45:13 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软发布 2025 工作趋势：每位员工都将成为 Agent 的 「老板」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软近日在其官网发布了 2025 年工作趋势指数报告，分析了来自全球 31 个国家和地区的 31，000 家企业。报告结合了 LinkedIn 劳动力市场趋势、数万亿个 Microsoft365 的生产力信号以及众多专家的见解，指出 「人机协作」 模式正在重塑企业架构，催生出一种全新的 「前沿公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-262509e06b372a5030a9fbb7c87f5ba548a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「前沿公司」 是一种新型的组织形式，主要围绕智能体（Agent）构建，以适应快速变化的商业环境和技术进步。这种公司的核心特点是将人类智慧与智能体相结合，形成高效的团队，显著提高生产力和创新能力，并节省工作时间。在这样的公司中，智能体可以是各种自动化工具或智能助手，执行从数据处理到复杂决策支持的多种任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告指出，随着智能体的广泛应用，员工将逐步成为 「Agent 老板」，他们不仅需要管理和优化这些智能体，还需具备相应的新技能。这意味着未来每位员工都要像初创公司的 CEO 一样思考如何利用 AI 来提升工作效率。根据调研显示，67% 的企业领导者表示他们熟悉 Agent 的概念，而这一比例在员工中仅为 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，前沿公司的组织结构也将发生变化，变得更加灵活和以结果为导向。这种新的工作架构会根据业务需求动态调整，灵活组合人类和智能体资源，以实现最佳效果。微软指出，随着智能体的加入，未来每位员工都有可能从第一天起就参与到复杂的工作中，甚至一名初级员工也可以借助 AI 管理整个营销活动。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在这个新模式中，企业需要关注人机协作的比例，确保资源的高效利用。同时，管理层需要重构职能，以适应这种人机协作的新趋势。微软还提到，员工需要从 「工具使用者」 转变为 「合作伙伴」，通过与智能体的双向互动激发创新能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347091</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347091</guid>
            <pubDate>Mon, 28 Apr 2025 05:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Hyprnote —— 会议专用 AI 记事本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#3c3c43&quot;&gt;Hyprnote 专为会议繁忙的人士打造，是一款&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;适用于连续会议的 AI 记事本。本地优先且可扩展。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;录并转录您的会议&lt;/li&gt;
&lt;li&gt;从原始会议记录中生成&lt;strong&gt;有力的摘要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;离线&lt;/strong&gt;工作使用&lt;strong&gt;开源模型&lt;/strong&gt;（&lt;em&gt;Whisper&lt;/em&gt;和&lt;em&gt;Llama&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;高度&lt;a href=&quot;https://docs.hyprnote.com/extensions/&quot;&gt;可扩展&lt;/a&gt;，由&lt;a href=&quot;https://docs.hyprnote.com/plugins/&quot;&gt;插件提供支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;div style=&quot;margin-left:auto; margin-right:auto&quot;&gt;
&lt;div style=&quot;margin-right:calc(50% - 678px)&quot;&gt;
&lt;div&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亮点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;增强你的笔记&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随意记下一些东西，Hyprnote 将根据您的备忘录制作会议记录。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt=&quot;&quot; height=&quot;391&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/152058_SbVr_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;离线和隐私&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hyprnote 是本地优先的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;392&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151933_5xtQ_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;扩展和插件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就像 VSCode 一样，可以根据你的情况添加或创建扩展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;382&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151827_6b1U_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://docs.hyprnote.com/extensions/transcript.html&quot;&gt;transcript extension&lt;/a&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&amp;nbsp;&lt;/span&gt;由&amp;nbsp;&lt;a href=&quot;https://docs.hyprnote.com/plugins/listener.html&quot;&gt;listener plugin&lt;/a&gt;&amp;nbsp;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;useEffect&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;channel&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;new&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#953800&quot;&gt;Channel&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;SessionEvent&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;subscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;channel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;onmessage&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;started&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;stopped&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;unsubscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/hyprnote</link>
            <guid isPermaLink="false">https://www.oschina.net/p/hyprnote</guid>
            <pubDate>Mon, 28 Apr 2025 05:53:00 GMT</pubDate>
        </item>
        <item>
            <title>腾讯正式开源跨端框架 Kuikly：基于 Kotlin 创建 Android、iOS、鸿蒙、Web、小程序应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;腾讯跨端框架&amp;nbsp;Kuikly 正式开源。根据官方介绍，Kuikly 是基于 Kotlin Multiplatform 的 UI 与逻辑全面跨端综合解决方案，由腾讯大前端领域 Oteam（公司级）推出，目的在于提供一套一码多端、极致易用、动态灵活的全平台高性能开发框架。&lt;/p&gt; 
&lt;p&gt;Kuikly（Kotlin UI Kit，发音同 quickly）使用 Kotlin 开发了声明式 UI 框架，映射到系统原生控件做渲染，最终用 KMM（Kotlin Multiplatform Mobile）实现跨端。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c10e21f658b9ab50513e216dc7c37cfa28e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;虽然是全平台，但目前暂时只开源了 Android 和 iOS，鸿蒙部分 5 月才开源，而 Web 和，小程序暂定是 Q2：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/121851_K8I9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 开源地址：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent-TDS%2FKuiklyUI&quot;&gt;https://github.com/Tencent-TDS/KuiklyUI&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 基于 Kotlin MultiPlatform（KMP）技术，它利用了 KMP 逻辑跨平台的能力，并抽象出通用的跨平台 UI 渲染接口，复用平台的 UI 组件，从而达到 UI 跨平台，具有轻量、高性能、可动态化等优点；同时，KuiklyBase 基建同样支持逻辑跨端。 让开发者&lt;strong&gt;可以使用 Kotlin 创建 Android、iOS、鸿蒙、Web、小程序应用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-911df639ea27ac02b452b9a379738d91ddd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/c0981983-cece-4d31-9488-e775586c8881.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;Kuikly 跨端框架系统要求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;iOS 12.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android 5.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HarmonyOS Next 5.0.0 (12) 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kotlin 版本 1.3.10 版本及以上&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkuikly.tds.qq.com%2F%25E7%25AE%2580%25E4%25BB%258B%2Farch.html&quot;&gt;https://kuikly.tds.qq.com/%E7%AE%80%E4%BB%8B/arch.html&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347077/tencent-tds-kuikly</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347077/tencent-tds-kuikly</guid>
            <pubDate>Mon, 28 Apr 2025 04:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>GPUStack v0.6 超重磅更新：vLLM 多机分布式、升腾 MindIE 等</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;GPUStack 是一个 100% 开源的模型服务平台&lt;/strong&gt; ，支持 &lt;strong&gt;Linux、Windows 和 macOS&lt;/strong&gt; ，支持 &lt;strong&gt;NVIDIA、AMD、Apple Silicon、升腾、海光、摩尔线程&lt;/strong&gt; 等 GPU 构建&lt;strong&gt;异构 GPU 集群&lt;/strong&gt; ，支持 &lt;strong&gt;LLM、多模态、Embedding、Reranker、图像生成、Speech-to-Text 和 Text-to-Speech&lt;/strong&gt; 模型，支持 &lt;strong&gt;vLLM、MindIE、llama-box&lt;/strong&gt; （&lt;strong&gt;基于 llama.cpp 与 stable-diffusion.cpp&lt;/strong&gt; ）等多种推理引擎与&lt;strong&gt;推理引擎多版本并行&lt;/strong&gt; ，支持&lt;strong&gt;资源自动调度分配、模型故障自动恢复、多机分布式推理、混合异构推理、推理请求负载均衡、资源与模型监控指标观测、国产化支持、用户管理与 API 认证授权等各种企业级特性&lt;/strong&gt; ，提供 &lt;strong&gt;OpenAI 兼容 API 无缝接入 Dify、RAGFlow、FastGPT、MaxKB 等各种上层应用框架&lt;/strong&gt;，是企业建设模型服务平台的理想选择。&lt;/p&gt; 
&lt;p&gt;GPUStack 一直&lt;strong&gt;致力于以最简单易用的方式，帮助用户快速纳管异构 GPU 资源并运行所需的 AI 模型，从而支撑 RAG、AI Agents 以及其他生成式 AI 落地场景&lt;/strong&gt;。为用户打造绝佳的使用体验是我们始终坚持的目标。最新发布的 v0.6 是迄今为止最重磅的版本，全方位完善了平台的整体功能、性能、稳定性和用户使用体验。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPUStack v0.6 版本的核心更新包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;vLLM 多机分布式推理&lt;/strong&gt;：提供生产级的多机分布式推理能力，支撑 DeepSeek R1 / V3 等单机 GPU 资源无法运行的超大参数量模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;升腾 MindIE 支持&lt;/strong&gt;：为升腾 910B 和 310P 用户提供内置的 MindIE 推理引擎支持，以提供最佳的模型推理表现。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型兼容性检测&lt;/strong&gt;：提供对模型是否支持部署的兼容性检测，目前提供对模型架构支持、操作系统兼容、资源可用性、本地路径可用性等依赖的实时检测，后续还会持续加入更多检测条件，提供更加友好的模型部署体验。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型下载管理&lt;/strong&gt;：支持管理已下载的模型文件、支持以不占用 GPU 资源分配为前提，发起单机/多机的模型下载任务、支持将本地路径的模型文件添加到 UI 中进行统一管理。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型故障自动恢复&lt;/strong&gt;：支持模型在发生故障时的自动恢复机制。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;端口暴露优化&lt;/strong&gt;：优化需要暴露的端口范围，API 入口到模型实例的推理请求统一经过代理转发，不再需要暴露模型实例端口，降低 96% 以上的端口暴露，并支持用户自定义。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增强国际化支持&lt;/strong&gt;：GPUStack 用户遍布全球上百个国家和地区，本次 GPUStack 社区用户贡献了俄语和日语支持，为不同语言的用户提供更加友好的使用体验，加速推进 GPUStack 的全球化应用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI / UX 全方位优化&lt;/strong&gt;：全方位的 UI / UX 优化，逐帧打磨，打造业界最好用的模型推理平台。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这一版本总共包含&lt;strong&gt;上百项增强、修复、稳定性改进和用户体验优化&lt;/strong&gt;，为用户的生产落地提供强大的场景支持。&lt;/p&gt; 
&lt;p&gt;有关 &lt;strong&gt;GPUStack&lt;/strong&gt; 的详细信息，可以访问：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 仓库地址: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;https://github.com/gpustack/gpustack&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;GPUStack 用户文档: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gpustack.ai&quot; target=&quot;_blank&quot;&gt;https://docs.gpustack.ai&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;重点特性介绍&lt;/h2&gt; 
&lt;h3&gt;vLLM 多机分布式推理&lt;/h3&gt; 
&lt;p&gt;随着大语言模型的参数规模不断提升，传统单机 GPU 资源已难以满足推理部署的实际需求。为此，GPUStack 在当前版本中正式支持生产级的 vLLM 多机分布式推理能力。通过跨主机部署，将模型按张量或按层切分，分布到多个节点运行，从而实现对超大参数模型（如 DeepSeek R1、DeepSeek V3 等）的推理支持。&lt;/p&gt; 
&lt;p&gt;当前，GPUStack 对以下两类推理引擎提供分布式支持：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;llama-box：异构分布式，适用于研发测试环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持 Linux、Windows 和 macOS 操作系统；&lt;/p&gt; 
&lt;p&gt; • 允许不同操作系统、不同品牌、不同规格的 GPU 混合实现异构分布式推理；&lt;/p&gt; 
&lt;p&gt; • 可在桌面或轻量服务器上快速构建异构分布式推理环境；&lt;/p&gt; 
&lt;p&gt; • 更适用于日常研发、模型验证、兼容性测试等场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;vLLM：同构分布式，面向生产环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持在多台 Linux 服务器之间进行同构分布式推理；&lt;/p&gt; 
&lt;p&gt; • 要求参与节点的硬件环境基本一致（如 GPU 型号、数量、显存）；&lt;/p&gt; 
&lt;p&gt; • 支持张量并行和流水线并行，具备良好的推理吞吐能力；&lt;/p&gt; 
&lt;p&gt; • 适合生产环境下对高并发、低延迟模型服务的部署需求。&lt;/p&gt; 
&lt;p&gt;通过 vLLM 和 llama-box 的分布式推理能力，GPUStack 能够覆盖&lt;strong&gt;从模型研发验证到大规模生产部署的完整流程&lt;/strong&gt;。在研发阶段，用户可使用 llama-box 构建灵活的测试集群；在生产部署阶段，则可通过 vLLM 提供稳定可靠的推理服务能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec5d9aef8c8a1a7aeacd7175a0c0e600.png&quot; alt=&quot;model-info&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;升腾 MindIE 支持&lt;/h3&gt; 
&lt;p&gt;在之前版本中，GPUStack 基于 llama-box 推理引擎初步支持了升腾 910B 和 310P 芯片的模型推理。然而由于算子支持不全及相关生态不够完善，实际使用中存在较多限制，例如只支持模型的部分量化精度，在性能和稳定性方面也弱于升腾官方推理引擎 MindIE。&lt;/p&gt; 
&lt;p&gt;为了提升用户在升腾 NPU 上的模型推理体验，GPUStack 现已内置集成 MindIE 推理引擎，对 910B 和 310P 提供更加稳定且高性能的模型推理能力。&lt;/p&gt; 
&lt;p&gt;MindIE 是升腾官方推出的高性能深度学习推理框架，具备运行加速、调试调优与快速部署等多项优势，目前在升腾硬件上表现最为出色。得益于其较为成熟的软硬件协同生态，MindIE 已成为在 NPU 上部署推理模型的主流方案。&lt;/p&gt; 
&lt;p&gt;当前，GPUStack 已完成对 MindIE 引擎的初步集成，相比于 llama-box 引擎，在部分场景可以达到数倍的推理速度提升。未来还将持续优化，并探索对更多推理引擎的支持，例如 vLLM（vLLM-Ascend），以满足在升腾平台上的多样化模型推理需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0680304502e35923518c9dcf932256b.png&quot; alt=&quot;image-20250415095544399&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型兼容性检测&lt;/h3&gt; 
&lt;p&gt;在过往版本中，用户直接从 Hugging Face 或 ModelScope 搜索任意模型进行部署时，存在一定的失败可能性。常见原因包括显存不足、操作系统与推理引擎不兼容、模型架构不被支持、本地路径配置错误等。这些问题不仅浪费时间，还严重影响用户体验。&lt;/p&gt; 
&lt;p&gt;为了解决这一痛点，GPUStack 推出了&lt;strong&gt;模型兼容性检测机制&lt;/strong&gt;。系统会在部署前自动检测模型与运行环境的匹配情况，涵盖模型架构与引擎支持、操作系统兼容性、GPU 资源是否充足、本地路径是否有效等多个关键维度。通过这些检测，潜在问题能够被提前识别，并提供清晰提示，帮助用户避免不必要的部署失败。&lt;/p&gt; 
&lt;p&gt;我们设定了三个明确的目标：第一，部署前提供清晰的兼容性提示；第二，在满足条件的情况下将部署成功率提升至 99% 以上；第三，对于特殊需求场景，允许用户跳过检测，强制部署，保留灵活性。&lt;/p&gt; 
&lt;p&gt;这项功能特性将持续演进，未来将支持更多检测项、覆盖更广泛的系统环境，不断完善检测机制，全面助力用户在不同平台上实现稳定、高效的模型部署。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fb036e198f11d8e36ec761c749ecca62.png&quot; alt=&quot;image-20250421173053252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下载管理&lt;/h3&gt; 
&lt;p&gt;在模型部署过程中，模型文件的统一管理与高效分发始终是用户关注的核心问题。以往，模型下载通常依赖于实例启动时自动触发，既需占用 GPU 资源，又常常依赖额外的手动操作才能完成下载；同时，GPUStack 也无法管理用户预先下载到本地路径的模型文件，导致部署效率低下，管理体验不佳。&lt;/p&gt; 
&lt;p&gt;为此，GPUStack 引入了&lt;strong&gt;模型文件下载管理&lt;/strong&gt; 模块：用户可在 UI 中为多个目标主机手动发起模型的下载任务，且&lt;strong&gt;无需占用 GPU 资源&lt;/strong&gt;。各节点上已下载的模型文件也可在 UI 中统一可视化管理与部署，进一步提升了部署的灵活性与效率。&lt;/p&gt; 
&lt;p&gt;同时，GPUStack 还支持将本地已有的模型文件路径添加到 UI 中进行统一管理，适配私有部署、离线环境等多种使用场景。通过这一模块，既解决了用户独立下载模型文件的需求，也使 GPUStack 能够更好地支持多机分布式部署，提升了部署效率与多机协同能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0f873b0ef5ec73c42ae118694f3825ee.png&quot; alt=&quot;image-20250415204131503&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型故障自动恢复&lt;/h3&gt; 
&lt;p&gt;在追求高可用性和稳定性的生产环境中，模型推理服务的稳定性至关重要。为了进一步提升这一点，GPUStack 引入了&lt;strong&gt;模型故障自动恢复机制&lt;/strong&gt;！当模型发生故障时，GPUStack 会自动触发恢复机制，迅速尝试重新启动模型，确保服务不中断。&lt;/p&gt; 
&lt;p&gt;同时，为了避免过于频繁的无效重启，GPUStack 采用了&lt;strong&gt;5 分钟为上限的指数退避延迟机制&lt;/strong&gt;，在故障持续时逐步延迟重启，避免系统资源的浪费。总体而言，v0.6 版本提供的模型故障自动恢复机制大幅提升了模型服务的容错能力，让生产的模型推理更加稳健！&lt;/p&gt; 
&lt;h3&gt;端口暴露优化&lt;/h3&gt; 
&lt;p&gt;在旧版本架构中，每台 Worker 节点需为每个模型实例开放端口访问，以供 Server 端进行推理请求的转发。在用户大规模使用时暴露了一些问题：由于大量端口需要映射，容器启停缓慢，且在启动时容易发生端口冲突；防火墙配置容易遗漏，导致推理请求转发异常。此外，也不支持用户自定义端口范围。&lt;/p&gt; 
&lt;p&gt;为此，我们在 v0.6 版本中重构了端口暴露机制：推理请求从 API 入口到模型实例的链路现已通过统一的代理转发，无需再为每个模型实例开放端口访问。同时优化了端口分配，将端口暴露范围压缩超过 96%，显著降低部署复杂度和运维风险。同时也支持用户自定义端口配置，使系统能够灵活适配不同的网络环境与安全策略，为用户带来更简单、稳定的部署体验。&lt;/p&gt; 
&lt;h3&gt;增强国际化支持&lt;/h3&gt; 
&lt;p&gt;目前 GPUStack 的用户遍布全球上百个国家和地区，随着 GPUStack 用户群体在全球范围内的持续扩大，我们致力于为不同语言背景的开发者提供一致、便捷的使用体验。本次 GPUStack 社区用户贡献了&lt;strong&gt;俄语&lt;/strong&gt; 和&lt;strong&gt;日语&lt;/strong&gt;支持，标志着 GPUStack 在国际化进程中的又一重要里程碑。&lt;/p&gt; 
&lt;p&gt;通过持续拓展多语言能力，GPUStack 为全球社区用户创造了更加包容与高效的使用体验。未来，我们将继续深化本地化支持，为全球用户提供更全面、更优质的服务体验，加速推动 AI 应用的全球落地与普及。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8781f64407b5d62f1496d53824097f69.png&quot; alt=&quot;image-20250413233340395&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8e1e428e259bcf52136144df288263a0.png&quot; alt=&quot;image-20250413233303590&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;全方位的 UI / UX 优化&lt;/h3&gt; 
&lt;p&gt;在本次版本中，我们对 UI / UX 进行了全方位优化，从信息展示到交互细节，几乎每一处都经过精心打磨，力求带来更流畅、更易用的使用体验。过去几个月收集的每一条用户建议，都是此次优化的重要参考。&lt;/p&gt; 
&lt;p&gt;我们始终坚持一个目标：打造业界最好用的模型推理平台，而 GPUStack 正在持续朝这一目标稳步前进。也正因为有用户的积极反馈，我们才能不断迭代优化------如果你有任何建议或想法，欢迎随时向我们提出，我们会认真评估并持续改进。&lt;/p&gt; 
&lt;h2&gt;参与开源&lt;/h2&gt; 
&lt;p&gt;想要了解更多关于 GPUStack 的信息，可以访问我们的仓库地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://github.com/gpustack/gpustack&lt;/strong&gt;&lt;/a&gt;。如果你对 GPUStack 有任何建议，欢迎&lt;strong&gt;提交 GitHub issue&lt;/strong&gt; 。在体验 &lt;strong&gt;GPUStack&lt;/strong&gt; 或提交 issue 之前，请在我们的 GitHub 仓库上&lt;strong&gt;点亮 Star&lt;/strong&gt; ⭐️关注我们，也非常欢迎大家一起参与到这个开源项目中！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果觉得对你有帮助，欢迎&lt;strong&gt;点赞&lt;/strong&gt; 、&lt;strong&gt;转发&lt;/strong&gt; 、&lt;strong&gt;关注&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/gpustack/blog/18260677</link>
            <guid isPermaLink="false">https://my.oschina.net/gpustack/blog/18260677</guid>
            <pubDate>Mon, 28 Apr 2025 03:43:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>得物业务参数配置中心架构综述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;现状与痛点&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在目前互联网飞速发展的今天，企业对用人的要求越来越高，尤其是后端的开发同学大部分精力都要投入在对复杂需求的处理，以及代码架构，稳定性的工作中，在对比下，简单且重复的 CRUD 就显得更加浪费开发资源。目前 scm 供应链管理页面中，存在约 77% 的标准页面，这些标准页面里，还存在着很多类似的参数配置页面，就是对某一个模型进行增、删、改、查、导入、导出进行类似的操作，这种开发工作技术含量较低，而且相对耗费人力。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;什么是业务参数配置中心&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;参数配置中心，是一个能够通过配置的方式，快速生成前端页面以及配套增、删、改、查、导入、导出服务的配置平台，它与得物内部低代码前端页面平台 wizard 相互集成，参数配置中心提供后台增删改查服务，wizard 输出对应的前端页面代码，并可以支持用户自定义修改。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;使用场景&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;针对读多写少的简单的单表的增删改查；&lt;/li&gt; 
 &lt;li&gt;业务中需要交给运营来修改的复杂 ark 配置（简单配置除外），可以尝试使用业务参数配置中心接入，减少人为修改 JSON 可能产生的错误，导致系统无法编译进而产生故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;比如如下的 JSON：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[{&quot;position&quot;:&quot;1&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;2&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;3&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;4&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;5&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;6&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;7&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;8&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;业务参数配置中心极速体验&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;后台服务搭建流程，以及数据录入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据读取可以通过参数配置中心的 SDK，输入自己的业务入参以及自己的业务出参，SDK 会自动根据方案下的参数以及用户的输入条件，查询出对应的参数信息：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-95529e5439a558b65e0757f2e1313155752.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从上面的快速体验里可以看到很多名词，你一定有会有下面的疑问：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-964c6ee7e450e7cce90376eddb00b05c04f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、整体架构与原理&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;实现思路&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;首先我们对这种普通的页面进行初步剖析：页面中总体包含搜索条件、静态展示字段以及操作栏，搜索条件一般是静态字段的子集，并且操作栏的功能一般都类似，所以为了能够结构化地构造出这样的页面，我们可以将静态展示字段进行进一步抽象：比如元素、维度、参数、方案、参数实例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1adfd37a09e81f9bf0438a2bed718c19a80.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;构成页面的每一个业务字段，统称元素，因为有些字段是大家常用的（比如仓库，品牌，一级类目，省份等），它有自己的字段名称，以及取值范围。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一条记录一定有能够标注其唯一性的信息，可能是一个字段或者是多个字段，在参数中心里，能确定一条记录唯一性的所有字段就叫做维度，维度这个概念在参数中心里很重要，它是不可变的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在业务发展过程里，可以改变值的字段，就叫参数，也可以说一条记录里，除了维度，都可以叫做参数。&lt;/p&gt; 
&lt;p&gt;综合维度和参数，举个例子，比如商品信息，商品 ID 就是维度，商品售价、折扣率就是参数。或者医院挂号系统，科室 ID 就是维度，挂号费，出诊时间就是参数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一个参数方案它管理着一个场景下的业务配置，可以简单理解一个方案就代表着一个页面，包含了上述我们说的维度以及参数，并且指定了可以指定哪些字段为搜索条件，哪些是必填字段，哪些字段可以多选。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数实例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;描述好方案并生成页面后，实际产生的业务配置数据，我们称之为参数实例。&lt;/p&gt; 
&lt;p&gt;经过刚才对页面元素的解剖，大家会发现搭建一个这样的页面，犹如建房子一样，维度与参数是最基础的木料，创建方案就是设计建造的过程，参数实例就是一个个真实的房间，所以业务参数配置中心整体产品思路如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54cf2fc71dbf64169277bd863672f638b30.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;整体架构&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;通过上文的介绍，我们介绍了业务参数配置中心最核心的概念，接下来我们看看整体的架构设计。我们针对这些最核心的概念，来设计实现这些业务功能的架构、核心包含领域模型、领域服务、应用服务以及基础设施层需要的存储部件，以及外部可以整合的导入导出框架、日志框架（外部依赖的框架也可以自己实现）、核心的元素维护、方案维护，存储设计好之后，我们就需要一个 SDK，可以让用户访问到我们的数据。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f29f79f77a54e147851172489afd9765082.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系统的实体关系图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4876084e664581f0f46677ab3e1b89d59d7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过上文我们可以初步了解到整体的架构设计，那么每一个子模块我们如何实现？接下来我们分析更加细节的原理。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心原理&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如何设计存储的细节是这个系统的一大挑战，因为既要兼顾页面的灵活变动，也要兼顾数据整体的一致性不受影响，同时也要兼顾整体数据的查询性能，下面的小节列出了所有这些核心的挑战点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;存储流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每一个页面的字段都不一样，我们是怎么存储的？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-072aa230f23621ba48c937b8f7db995c249.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从上面的两个页面可以看到，因为页面的字段变化多端，所以我们的思考是，必须采用抽象存储的方式来应对，核心用一张，大宽表存储，其中包含很多抽象列，每一个抽象列在不同的方案下，业务含义不同。&lt;/p&gt; 
&lt;p&gt;同时把方案的元数据：维度、参数、以及功能性设置（如每个字段是否可以删除，是否需要多选）单独存储，每个方案下的大宽表里的抽象列的业务含义，就存储在这些元数据表中。&lt;/p&gt; 
&lt;p&gt;同时为了应对大批量的查询，我们引入了 OLAP 的数据库，对于在应用内部的单点查询，我们走 MySQL 实现，如果运营后台针对某个字段做大批量查询，则可以用 OLAP 数据库来缓解查询压力。&lt;/p&gt; 
&lt;p&gt;下面是存储的整个过程以及举例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68a28fece8de3ef9c82fc7843e8110e2a2e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SDK 查询流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因为在业务参数使用时，各个业务方有自己的业务对象，所以我们在 SDK 中集成了反射的能力，可以避免用户直接感知到底层的抽象存储，查询的流程使用上比较简单，一共分为三步，第一步为自定义 request，第二步自定义 response，第三步调用 SDK 方法获取参数实例，比如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;定义 request：&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigRequest implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置类型

  */

 private String configType;

 */***

  * 设备编号

  */

 private String deviceNo;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定义 response&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigResponse implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置类型

  */

 private String configType;

 */***

  * 设备编号

  */

 private String deviceNo;



     */***

  * 配置明细

  */

 private List&amp;lt;CameraConfigDto&amp;gt; configValueList;



     [@Data](https://my.oschina.net/difrik)

 public static class CameraConfigDto implements Serializable {

     private String position;

     */***

      * 白平衡 (Red)

      */

     private BigDecimal red;

     */***

      * 白平衡 (Blue)

      */

     private BigDecimal blue;

     */***

      * 白平衡 (Green)

      */

     private BigDecimal green;

     */***

      * 亮度 (Brightness)

      */

     private BigDecimal brightness;

     */***

      * 自动曝光时间上限 (us)

      */

     private BigDecimal autoExposureTimeUpperLimit;

     */***

      * 采集帧率

      */

     private BigDecimal acquisitionFrameRate;

     */***

      * 增益自动开关 (us)

      */

     private String gainAuto;

     */***

      * 增益自动上限

      */

     private BigDecimal gainAutoUpperLimit;

     */***

      * 增益自动上限

      */

     private BigDecimal gainAutoLowerLimit;

 }
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;调用 SDK 的服务方法查询&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigRequest pinkDeviceCameraConfigRequest = new PinkDeviceCameraConfigRequest();&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setConfigType(&quot;DEVICE_NO&quot;);&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setDeviceNo(&quot;123@LuSun&quot;);&lt;/p&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 单个查询场景&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigResponse response =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParams(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;,

      pinkDeviceCameraConfigRequest,

      PinkDeviceCameraConfigResponse.class);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 批量查询场景&lt;/p&gt; &lt;p&gt;PageQueryOption pageQueryOption = new PageQueryOption();&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageIndex(1);&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageSize(200);&lt;/p&gt; &lt;p&gt;PageInfo&amp;lt;PinkDeviceCameraConfigResponse&amp;gt; paramsPage =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParamsPage(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;, 

     pinkDeviceCameraConfigRequest, 

     PinkDeviceCameraConfigResponse.class,

     pageQueryOption);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;获得结果&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19953d23e8dcd9b90b57575b8fc6c5533ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;整体查询实现原理如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68822ebba4f5d690e41c18c156dffdad174.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 目前整个服务的性能在 10+ms 左右：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f86b118721761e37edb0d80428c83fa7355.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数优先级实现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为什么会有参数优先级这个功能？&lt;/p&gt; 
&lt;p&gt;比如有一个场景，要维护一个供应链系统中的补货参数：安全库存，低于这个安全库存的时候，要通知商家进行补货，整个供应链里有 100 个仓库，20 个一级类目，200 个二级类目，2000 个三级类目，涉及到 500 个品牌，要维护每一个商品的安全库存，你会怎么实现？&lt;/p&gt; 
&lt;p&gt;你一定不会把 100 仓库_2000 类目_500 品牌 = 1000000000 种可能全都设置一遍参数，对你来说，重点类目，要单独详细配置安全库存，非重点类目可能只需要管控到一级或者二级类目即可，这样你所需要的配置会大大减少。那么参数的决策就需要遵循一定的规则，比如:&lt;/p&gt; 
&lt;p&gt;有仓库+一级类目+二级类目+三级类目，的安全库存，优先取；&lt;/p&gt; 
&lt;p&gt;如果取不到，则取仓库+一级类目+二级类目的安全库存；&lt;/p&gt; 
&lt;p&gt;再取不到，取仓库+一级类目的安全库存。&lt;/p&gt; 
&lt;p&gt;比如：&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋 安全库存 100&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋-运动鞋，安全库存 500&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋-运动鞋-篮球鞋，安全库存 1000&lt;/p&gt; 
&lt;p&gt;那如果一个商品是篮球鞋的话，则会命中安全库存 1000 的规则，如果是登山鞋的话，只能命中运动鞋的规则取 500，如果是高跟鞋，则只能取 100 的安全库存。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（事实上这种补货规则要详细的多，这里只是方便大家理解需求，并不是真正的参数）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;也就是说，当用户的入参同时可能命中多条参数的时候，需要通过优先级来判断应该返回哪个参数。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-92bbffb30b7b6f12d6b8fa4717437f376d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了加速查询，系统在设计时添加了两层缓存：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-129d351a3be37ca0cf02b4472de6fcd50e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 当后台数据发生变化时，会将对应的缓存进行失效。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-821ca41cc55e1456a0ad3fb0ba5dc76247f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素多选处理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;维度多选场景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-28b192d9ccc63092c15fcc0f12187ddf449.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;参数多选场景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4a1bdf71195372e13f56ab0aa27813e3ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;既要保证维度唯一，又要保证能正常搜索，以及展示，如何实现？业务参数配置中心引入了一个&quot;组&quot;的概念，是将同属于一行的参数实例，归为一个组，这个组是最小的新建、编辑单位。&lt;/p&gt; 
&lt;p&gt;对于新增流程如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd67e7858a3927f9960d4c2d364c0dc4a6a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对于修改流程，如下图所示： &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ed29af351bef248291bc76b841bafcedcae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素范围查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;页面中的字段，我们统称为元素，只要是字段，一定有它的取值范围，我们平衡了用户使用成本以及系统性能，将字段取值类型划分成了四种：&lt;/p&gt; 
&lt;p&gt;1）枚举类元素&lt;/p&gt; 
&lt;p&gt;2）dubbo 全量接口元素&lt;/p&gt; 
&lt;p&gt;3）dubbo 单点查询接口元素&lt;/p&gt; 
&lt;p&gt;4）自定义文本元素&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;枚举元素由用户手动在页面创建，一般几十个以内为佳，创建成本不高，比如经常用到的 &quot;是&quot;，&quot;否&quot;，或者比如单据类型等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 全量接口元素，一般是几十到上百个的体量，比如一级类目，仓库等，地址。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 单点查询接口，一般是几千到几万体量的取值范围，无法直接在内存里存储所有枚举，比如品牌等。只能通过两个接口来完成搜索以及数据的展示，比如&quot;品牌 ID &amp;gt;品牌名称&quot;接口，和 &quot;品牌名称-&amp;gt;品牌 ID&quot; 接口。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定义文本，非枚举类字段，可以选择使用自定义文本来承接。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;比如以下是可以通过 dubbo 接口全量获取配置的元素：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-265ea951a69d044a0e77e39825e029716fc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与 dubbo 全量接口的录入类似，单点搜索接口与全量接口不同的点在于，单点接口需要保留一个变量，给系统查询时调用，比如&quot;通过品牌 ID 查询品牌名称&quot; 和 &quot;通过品牌名称查询品牌 ID&quot; ，需要留给系统调用的入参，用#{var}代替。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-154171e3bd51e9ec195984b8fc5f2408f3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当然，有时元素的范围并不是只取决于它自己，可能也取决于同页面里其他元素的取值，比如说有一个质量原因的字段，当一级类目为鞋时，取值为 A、B、C，为服装时为 D、E、F，这是元素范围在设置时，就需要将对应的元素入参维护到其中，比如：&lt;/p&gt; 
&lt;p&gt;| 接口入参类型 | 接口入参取值 | | --- | --- | | com.d.s.q.s.d.r.ConfigRequest | {&quot;ruleVersion&quot;:#{ruleVersion},&quot;spuId&quot;:#{spuId}} |&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;导入导出&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是导入处理流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72582bd979727a7d8718ed80cfe71b8973e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了照顾使用人员的体验，再多数导入场景时，我们的导入文件都用的是文案，而不是后台存储的数值，比如导入的字段包含类目时，导入文件输入的是鞋、服装、美妆等文案，而不是 2、3、4 这样存储在后台的数值，那么势必这里就会有将文案转换成数值的过程，这其中就用到了 2.3.5 章节中提到的元素范围查询使用的接口，当然，对于需要其他元素作为入参的元素，我们默认每个元素左边的元素都可以作为当前元素的入参。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;业务参数配置中心不适合做什么？&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;有极为复杂的 UI 交互&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;较为复杂的校验逻辑（长期计划支持）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高频写入场景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;应用查询参数时以非&quot;=&quot;条件匹配&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;三、总结与展望&lt;/h1&gt; 
&lt;p&gt;本文简要描述了业务参数配置中心的设计思路，参数配置中心配套生成增、删、改、查、导入、导出服务，并且结合前端低代码平台自动生成前端代码，平台目前业务参数中心已经有 40+个场景接入节省了大量的工作人日，能够让研发人员，摆脱低效的 CRUD，更专注于自己内部业务逻辑的开发。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对于目前系统的未来规划：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;持续增加 SDK 的查询灵活性：包括不限于批量代参数优先级对数据进行查询、通过 SDK 分页查询全量参数、对系统字段吐出方便业务方使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持续增加对方案定义的灵活性：支持更多的元素范围的定义，比如 HTTP 等调用方式；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持续增加对元数据定义的灵活性：部分元数据的取值可能需要同页面中的另一个元素的取值来决定，所以在取值渲染时，可以保留给其他元素的占位符，进而随着页面的动态变动，后台取值也可以动态变动。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539092%26idx%3D1%26sn%3D6fc02ccebc5c838f143d5128691a635b%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物增长兑换商城的构架演进&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539014%26idx%3D1%26sn%3D90a168b730490ae84a0917863ad3e077%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物自研 DGraph4.0 推荐核心引擎升级之路&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538986%26idx%3D1%26sn%3Db6b82a790a3c696bce27704472e799b2%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;大语言模型的训练后量化算法综述 | 得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538473%26idx%3D1%26sn%3D0a83895ef8dcd555e9926151a989b663%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何合理规划 Elasticsearch 的索引｜得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538394%26idx%3D1%26sn%3D51f91adc969a03f7c8baa31f6cc39c67%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;DPP 推荐引擎架构升级演进之路｜得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;文 / sakuta&lt;/h4&gt; 
&lt;p&gt;关注得物技术，每周新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18230829</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18230829</guid>
            <pubDate>Mon, 28 Apr 2025 03:24:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Anthropic 向逆向工程 Claude Code 的开发者发送删除通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F25%2Fanthropic-sent-a-takedown-notice-to-a-dev-trying-to-reverse-engineer-its-coding-tool%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 报道称&lt;/a&gt;&lt;/u&gt;，在 Anthropic 的 Claude Code 和 OpenAI 的 Codex CLI 两款「智能体」式 AI 编程工具的较量中，后者获得了更多开发者的青睐。部分原因在于，Anthropic 向一位试图逆向工程 Claude Code 的开发者发出了删除通知，而 Claude Code 的使用许可要比 Codex CLI 更加严格。&lt;/p&gt; 
&lt;p&gt;Claude Code 和 Codex CLI 都是让开发者能够利用云端的 AI 模型来完成各种编程任务的工具，功能相似。两家公司几乎在同一时期发布了这两款工具，争夺开发者的关注。&lt;/p&gt; 
&lt;p&gt;Codex CLI 的源代码采用 Apache 2.0 许可证，允许分发和商业使用。相比之下，Claude Code 则依赖于 Anthropic 的商业许可证，限制了「在未获得公司明确许可的情况下对其进行修改」的方式。&lt;/p&gt; 
&lt;p&gt;另外，Anthropic 对 Claude Code 的源代码进行了「混淆」，意味着其源代码并不容易获得。当有开发者通过反混淆手段将代码发布到 GitHub&amp;nbsp;时，Anthropic &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgithub%2Fdmca%2Fblob%2Fmaster%2F2025%2F03%2F2025-03-10-anthropic.md&quot; target=&quot;_blank&quot;&gt;提出了 DMCA 投诉&lt;/a&gt; ——&amp;nbsp;这是一份要求删除代码的版权通知。&lt;/p&gt; 
&lt;p&gt;社交媒体上的开发者们对 Anthropic 此举&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FtheLance%2Fstatus%2F1914458771679486389&quot; target=&quot;_blank&quot;&gt;非常不满意&lt;/a&gt;，认为这种做法远不如 OpenAI 发布 Codex CLI 时的开放态度。在 Codex CLI 发布后的短短一周内，OpenAI 就将几十条开发者建议纳入了工具的代码库，其中包括一个让 Codex CLI 能调用来自其他竞争者（包括 Anthropic）的 AI 模型的功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2820&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/105716_o6ne_2720166.png&quot; width=&quot;1289&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 尚未对此事作出回应。Claude Code 仍处于测试阶段，并且存在一些 bug。而在未来，Anthropic 有望以宽松的许可证发布源代码。公司对源代码进行混淆的原因多种多样，其中之一便是出于「安全」考虑。&lt;/p&gt; 
&lt;p&gt;对于 OpenAI 来说，这多少是一次公关上的胜利，因为最近几个月，OpenAI 一直回避开源发布，转而推出专有、封闭的产品。这可能标志着实验室方法的一个更广泛的转变；OpenAI 首席执行官 Sam Altman 今年早些时候表示，他认为公司在开源问题上一直站在「历史错误的一边」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</guid>
            <pubDate>Mon, 28 Apr 2025 02:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Transformers 作者：未来互联网将演变为 AI Agent 网络</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，Transformers 合著者 Illia Polosukhin 接受了 a16z 的专题采访，并在交流中分享了自己对于 AI、Agent 等方面的观点。&lt;/p&gt; 
&lt;p&gt;开篇，Illia 就分享了自己对现有 AI Agent 的看法。他表示，据团队观察，大量用户对需要复杂规划的场景特别感兴趣。但这种局面在未来将会反过来：AI 助理将会主动提出方案给用户，用户也仅需要做出方向性选择即可。对于这种 AI 何时面世，Illia 预测在未来一年内，就会出现首批成熟应用的场景。&lt;/p&gt; 
&lt;p&gt;对于「死亡互联网理论」，Illia 则坦言：虽然开放网络正在消亡，但并非网络上的机器人数量过多，而是因为平台容易被垃圾信息攻陷。对此他认为智能 Agent 能够为人类进行信息把关，未来 AI 助手也会成为互联网「垃圾分拣员」：能够为用户提供上下文链接，如实指出错误信息并揭露事实真相。&lt;/p&gt; 
&lt;p&gt;另外，主持人问及「未来将会有多少 AI Agent？与人类的数量比例又是如何？」时，Illia 则表示，未来每个人都会拥有属于自己的 AI 助手，而 AI 助手的背后可能运行着数十个子 Agent 项目，因此这会构建起一个庞大的 Agent 网络，并且每个人都将如同获得一套「按需助理系统」。&lt;/p&gt; 
&lt;p&gt;主持人还特别向&amp;nbsp;Transformers 作者问起了对 DeepSeek 的看法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Robert:&lt;/p&gt; 
 &lt;p&gt;您如何看待 DeepSeek 最新发布的高性能开源模型？相比其他选项，它不仅表现优异且成本更低，更特别的是由中国对冲基金以开源方式推出。&lt;/p&gt; 
 &lt;p&gt;Illia:&lt;/p&gt; 
 &lt;p&gt;首先这确实是激动人心的突破。他们在有限硬件上实现大规模高性能模型训练的工程能力令人惊艳，证明优秀工程实践能大幅降低成本。中国模型训练成本正在快速下降，但最关键的创新在于：他们提出了一种极其简单的强化学习方法——这个方法具有普适性，无论是 10 亿还是 70 亿参数模型都能快速获得优异效果。&lt;/p&gt; 
 &lt;p&gt;这种「阶跃式创新」让我想起 Transformer 的诞生——原理简单、开箱即用、人人可复现。&lt;/p&gt; 
 &lt;p&gt;坦白讲，这类基础方法论本应自由传播 (毕竟只是公式或原理)，但必须承认 DeepSeek 团队极其专业，他们凭借后发优势规避了许多早期问题。现在更重要的机遇在于：借助可验证计算技术，我们可以训练用户或社区拥有的模型——确切知道训练数据来源。&lt;/p&gt; 
 &lt;p&gt;当前所有开源模型都只公开参数，无人知晓训练数据构成，即便公布也无法验证真伪。&lt;/p&gt; 
 &lt;p&gt;区块链领域现在有机会联合训练一个「加密透明」的开源模型：所有人都能验证数据输入、训练过程及潜在偏差，确保没有隐藏后门或恶意代码。这样的模型才能真正成为 AI 时代可信赖的基础设施。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhDgE_7fIb-ps4xSOuced_A&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/hDgE_7fIb-ps4xSOuced_A&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347060</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347060</guid>
            <pubDate>Mon, 28 Apr 2025 02:31:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克旗下 xAI 拟融资 200 亿美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-26%2Felon-musk-s-xai-holdings-is-in-discussions-to-raise-20-billion&quot; target=&quot;_blank&quot;&gt;彭博社援引知情人士透露&lt;/a&gt;&lt;/u&gt;，马斯克旗下 xAI 目前正与投资者洽谈，计划筹集大约 200 亿美元资金，用于其新合并的人工智能初创公司和社交媒体业务。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/102209_yrAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;数据提供商 PitchBook 的数据显示，&lt;strong&gt;如果成功，这笔交易将成为历史上第二大创业公司融资&lt;/strong&gt;，仅次于今年早些时候 OpenAI 的 400 亿美元融资。据知情人士透露，凭借此轮洽谈中的融资，xAI 的估值超过 1200 亿美元。&lt;/p&gt; 
&lt;p&gt;值得一提的是，该轮融资可能有助于偿还马斯克在将 X 前身 ——Twitter 私有化后所承担的一部分债务。知情人士透露，上述债务一直对 X 构成财务压力。此前彭博社报道指出，仅在今年 3 月，X 就支付了约 2 亿美元的债务服务费用，截止 2024 年底，其年度利息支出将超过 13 亿美元。&lt;/p&gt; 
&lt;p&gt;据了解，尽管谈判仍处于初期阶段，但 xAI 目标是未来几个月内筹集资金。知情人士表示，融资规模可能会超过最初的 200 亿美元，具体金额和条款尚未确定。&lt;/p&gt; 
&lt;p&gt;报道指出，这一大规模融资凸显了投资者对人工智能公司日益增长的兴趣，同时也显示了马斯克作为商业巨头和政治影响力人物的地位。尽管特斯拉的市值有所下滑，但马斯克的其他企业仍在蓬勃发展，例如马斯克的火箭公司 SpaceX，于去年一次私募交易中被估值为 3500 亿美元，成为历史上最有价值的初创公司。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</guid>
            <pubDate>Mon, 28 Apr 2025 02:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动推出 QuaDMix：大型语言模型预训练数据质量与多样性的统一框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节跳动近日宣布推出其全新的数据选择框架 QuaDMix，旨在提升大型语言模型（LLM）预训练的效率和泛化能力。众所周知，模型的训练效果受基础数据集的质量和多样性影响很大。然而，传统的数据筛选方法往往将质量和多样性视为两个独立的目标，先进行质量过滤，再进行领域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b5dc2134907308fa5f27fb6e2823c7d4cf.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;这种逐步优化的方式忽略了质量与多样性之间的复杂相互关系。优质数据集往往存在领域偏差，而多样化的数据集可能会降低质量。因此，在固定的训练预算下，如何同时优化这两个维度以最大化模型性能，成为了一个亟待解决的难题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 框架的主要运作分为三个阶段：特征提取、质量聚合和质量 - 多样性感知采样。在初始阶段，每个文档都会被标注领域标签和多项质量评分。通过归一化和合并这些评分，生成一个综合质量分数。接着，系统通过基于 sigmoid 的函数采样文档，优先考虑高质量样本，并通过参数化控制确保领域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了优化模型，QuaDMix 在不同参数设置下训练了数千个代理模型。通过这些代理实验训练的回归模型可以预测性能结果，从而识别出最佳采样配置。这种方法使得在高维参数空间中进行结构化探索成为可能，从而更好地将数据选择与下游任务对接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;实验结果显示，QuaDMix 在 RefinedWeb 数据集上进行的验证实验中，与多种基线模型相比，平均得分达到了 39.5%。这些基线模型包括随机选择、Fineweb-edu、AskLLM、DCLM 等。实验结果表明，联合优化策略在整体表现上始终优於单独关注质量或多样性的方法。此外，经过优化的数据混合更能提升特定下游任务的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 为大型语言模型的预训练数据选择提供了一个系统化的解决方案，解决了长期以来同时优化数据质量与多样性的挑战。通过结合质量聚合和领域感知采样，QuaDMix 建立了一种可扩展的方法论，提升了 LLM 预训练的效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347054</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347054</guid>
            <pubDate>Mon, 28 Apr 2025 02:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>月暗开源 Kimi-Audio，单一框架执行多种语音任务；照片秒变可对话数字人，LemonAI 推出 Slice Live 丨日报</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-42daa67a23199a5e38b5a98abb2517572ae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;开发者朋友们大家好：&lt;/p&gt; 
&lt;p&gt;这里是 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 &lt;strong&gt;技术&lt;/strong&gt; 」、「有亮点的 &lt;strong&gt;产品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有态度的 &lt;strong&gt;观点&lt;/strong&gt; 」、「有看点的 &lt;strong&gt;活动&lt;/strong&gt; 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。&lt;/p&gt; 
&lt;p&gt;本期编辑：@赵怡岭、&lt;a href=&quot;https://my.oschina.net/u/862736&quot;&gt;@鲍勃&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;01.有话题的技术&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、百度推出文心 4.5 Turbo 和深度思考模型 X1 Turbo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-041ced382bdd171c05e0c36d4df884fc4c9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 25 日，在面向开发者的 Create 大会重磅推出两款全新模型：文心 4.5 Turbo 和深度思考模型 X1 Turbo。&lt;/p&gt; 
&lt;p&gt;两款模型主打多模态、强推理和低成本。百度旗下新搜索智能助手文小言也宣布全面接入，免费向用户开放，即日起用户打开文小言 APP 即可使用。&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 Turbo 进一步强化了多模态能力。在多个基准测试集中，文心 4.5 Turbo 多模态能力已与 GPT-4.1 持平，甚至在部分维度优于 GPT-4o。&lt;/p&gt; 
&lt;p&gt;而文心大模型 X1 Turbo 则在 4.5 Turbo 的基础上进行了「深度思考」升级。无论是问答能力、内容创作、逻辑推理，还是工具调用、多模态处理，X1 Turbo 均实现全方位增强，整体表现领先于 DeepSeek R1 和最新版本 V3。(@APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、GPT-4o 模型再次升级&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-768e3d496ec29c08bc8237c168b4e93a021.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 5 日，OpenAI 称对 GPT 4o 模型进行了升级。&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman 发文宣布 GPT-4o 迎来能力改进，具体如下：&lt;/p&gt; 
&lt;p&gt;新升级的 GPT 4o 模型个性化更强，优化了模型保存「记忆」的时机，并增强其在 STEM 领域的问题解决能力，还对其响应方式进行了细微的调整，使其更加主动，能够更好地引导对话走向富有成效的结果，同时对回复的细节进行了微调，让 GPT-4o 在各种任务中的表现更直观、更易用，（&lt;a href=&quot;https://my.oschina.net/u/104417&quot;&gt;@ai&lt;/a&gt; 寒武纪、APPSO）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、总体性能第一：月之暗面开源全新音频基础模型 Kimi-Audio，横扫十多项基准测试&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a5ea5773cd4c3850cedde7d0db1f67f2923.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 26 日，Kimi 发布了新的开源项目 ------ 一个全新的通用音频基础模型 Kimi-Audio，支持语音识别、音频理解、音频转文本、语音对话等多种任务，在十多个音频基准测试中实现了最先进的 （SOTA） 性能。结果显示，Kimi-Audio 总体性能排名第一，几乎没有明显短板。&lt;/p&gt; 
&lt;p&gt;Kimi-Audio 采用了集成式架构设计，包括三个核心组件 ------ 音频分词器（Audio Tokenizer）、音频大模型（Audio LLM）、音频去分词器（Audio Detokenizer）。&lt;/p&gt; 
&lt;p&gt;这一架构使 Kimi-Audio 能够在单一模型框架下，流畅地处理从语音识别、理解到语音对话等多种音频语言任务。同时，音频分词器还提取连续的声学向量，以增强感知能力。（@机器之心）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、Cognition Labs 推出 DeepWiki 项目，可为 GitHub 仓库提供 AI 驱动的实时交互式文档&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-52eb7173b2ff5edf181b86039e133aa6f11.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（图片来源：deepwiki 官网）&lt;/p&gt; 
&lt;p&gt;对于开源项目，这项服务完全免费，甚至无需注册。访问 deepwiki.com，探索已经收录的热门开源项目的 Wiki，或者把正在浏览的任何 GitHub 仓库 URL 中的 github.com 替换成 deepwiki.com，即可无缝跳转到该仓库的 DeepWiki 页面。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对话式文档： 直接向代码库「提问」，DeepWiki 会尝试理解问题并给出文档级的解答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度研究 （Deep Research）： 对于复杂问题，可以开启此功能，让 AI Agent 进行更深入的分析和回答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;按需索引： 如果关注的公开仓库还没被收录，可以请求 DeepWiki 索引&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;私有仓库支持： 对于私有仓库，可以通过注册 Devin 账户（devin.ai）来获得服务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;轻松分享： 生成的 Wiki 页面和问答结果都可以通过链接分享，方便团队成员保持信息同步（@AI 寒武纪）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;5、Adobe 发布商用级 AI 图像生成模型 Firefly Image 4 系列&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Adobe 更新发布了 Firefly Image 4 和 Firefly Image 4 Ultra 两大 AI 图像生成模型，支持最高 2K 分辨率输出。&lt;/p&gt; 
&lt;p&gt;这两款模型均基于 Adobe Stock 等授权内容以及公共领域数据训练，如侵犯版权，可以让 Adobe 赔偿。（@三花 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、MLX-Audio: 苹果芯片上的高效语音合成模型库，提供 TTS REST API&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MLX-Audio 是一个基于 Apple MLX 框架构建的文本转语音 （TTS） 和语音转语音 （STS） 库，专为 Apple Silicon 芯片优化，提供出色的语音合成性能。&lt;/p&gt; 
&lt;p&gt;核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;苹果芯片加速： 在 M 系列芯片上实现快速推理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多语言支持： 支持多种语言；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语音定制： 提供丰富的语音定制选项；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语速调节： 0.5x 到 2.0x 的语速调节范围；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可视化交互： 具有 3D 音频可视化的交互式网页界面；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;REST API: 提供用于 TTS 生成的 REST API；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能优化： 支持量化以优化性能；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文件快速访问： 通过 Finder/资源管理器集成直接访问输出文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;支持模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Kokoro: 多语言 TTS 模型，支持多种语言和语音风格。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CSM （Conversational Speech Model） : Sesame 的对话语音模型，支持文本转语音和使用参考音频样本进行声音定制。(@GitHub)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02.有亮点的产品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、AceditAI 面试教练：实时转录、问题检测和个性化回复等功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Acedit 是一款 Chrome 浏览器插件，作为你的 AI 面试教练：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;智能练习：&lt;/strong&gt; 上传职位描述和简历，Acedit 即可生成个性化的练习问答，并通过 AI 模拟面试助你充分准备。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时 AI 建议：&lt;/strong&gt; 在 Google Meet、Zoom、Teams 等在线面试平台，Acedit 能读取面试问题，并结合你的简历、领英资料等信息，提供实时 AI 生成的答案建议。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;定制求职信：&lt;/strong&gt; 内置 AI 工具，轻松生成个性化求职信。(@ProductHunt)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2、LemonAI 推出 Slice Live：照片秒变实时数字人&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Lemon Slice Live 是一款实时音视频 AI 数字人模型，让你体验前所未有的视频聊天。基于扩散变换模型 （DiT） 技术，它能将任何角色图像立即转化为支持 10 多种语言的交互式视频通话。无需训练或设置特定角色模型，上传一张照片即可与任意角色流畅对话，兼容写实、卡通、绘画等多种风格，支持高达 25 FPS 的实时渲染。（@三花 AI、LemonAI 官网）&lt;/p&gt; 
&lt;h2&gt;03.有态度的观点&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Anthropic 研究员：从理论上讲 AI 有可能产生意识&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，Anthropic 研究员 Kyle Fish 受公司邀请做了一期访谈节目，其中他在节目中表示，理论上讲 AI 是可能产生意识的。&lt;/p&gt; 
&lt;p&gt;Kyle Fish 认为，虽然当前 AI 的整体系统与人类大脑在功能和结构上存在差异，但如果能够以足够高的保真度，去模拟人脑，其中包括模拟神经递质分子的作用，那么从理论上讲，AI 有可能产生意识。&lt;/p&gt; 
&lt;p&gt;他还进一步表示，如果将大脑中的神经元逐个被替换成芯片，在替换过程中保持个体的行为和功能的不变，那么替换完成后，个体的意识体验可能不会发生太大变化。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Anthropic 为了探索模型更深层次的体验与潜在意识，启动了一项研究计划，旨在调查 AI 模型是否能够有潜在的偏好和痛苦迹象，并且去判断这是否符合道德。(@APPSO)&lt;/p&gt; 
&lt;h2&gt;04.有看点的活动&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、脑机接口智能技术应用挑战赛正式开启报名！( 04.26-05.28)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b36b85455f3a09c836074daef9eb7d38a3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（图片来源：智姬）&lt;/p&gt; 
&lt;p&gt;脑机接口智能技术应用挑战赛（AI-Based BCI Tech Competition）是由中关村领智青年人才自主创新发展中心联合姬械机科技集团发起的，以脑与智能（Brain and Al）为主题方向的人工智能脑接口（Al-based BCl）前沿创新技术与应用竞赛。&lt;/p&gt; 
&lt;p&gt;通过本次技术比赛为脑机科技创新者提供系统性技术支持与创新资源对接，重点推进脑机接口技术问题的解决，同时实现脑机接，口的行业应用示范与产业化落地创新探索。&lt;/p&gt; 
&lt;p&gt;赛题发布与比赛报名 ：04/26 - 05/28&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;参赛团队报名审核 ：05/28 - 06/08（截止报名） 比赛形式：（1）线下自主赛题解答； （2） 线上提交赛题答案；（3）现场场答辩分享；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;一等奖 1 名奖金 30 万 （第一名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二等奖 2 名奖金 15 万 （第二名、第三名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三等奖 5 名奖金 8 万 （第四名、第五名、第六名、第七名、第八名） 。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前官方已发布&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbvxYvC8jiE4xc56QP1ihig&quot; target=&quot;_blank&quot;&gt;相关赛题简介&lt;/a&gt;：基于不同的通道脑机，完成与之相关的技术题、应用题。（@智姬）&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fd190df182060c949e714b0be523d5431a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 学习笔记：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ&quot; target=&quot;_blank&quot;&gt;级联 vs 端到端、全双工、轮次检测、方言语种、商业模式...语音 AI 开发者都在关心什么？丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA&quot; target=&quot;_blank&quot;&gt;a16z 最新报告：AI 数字人应用层即将爆发，或将孕育数十亿美金市场丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA&quot; target=&quot;_blank&quot;&gt;a16z 合伙人：语音交互将成为 AI 应用公司最强大的突破口之一，巨头们在 B2C 市场已落后太多丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA&quot; target=&quot;_blank&quot;&gt;ElevenLabs 33 亿美元估值的秘密：技术驱动+用户导向的「小熊软糖」团队丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw&quot; target=&quot;_blank&quot;&gt;端侧 AI 时代，每台家居设备都可以是一个 AI Agent 丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg&quot; target=&quot;_blank&quot;&gt;世界最炙手可热的语音 AI 公司，举办了一场全球黑客松，冠军作品你可能已经看过&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw&quot; target=&quot;_blank&quot;&gt;多模态 AI 怎么玩？这里有 18 个脑洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg&quot; target=&quot;_blank&quot;&gt;AI 重塑宗教体验，语音 Agent 能否成为突破点？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA&quot; target=&quot;_blank&quot;&gt;对话 TalktoApps 创始人：Voice AI 提高了我五倍的生产力，语音输入是人机交互的未来&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fr2z1bilamX6YWTg90F8xYA&quot; target=&quot;_blank&quot;&gt;a16z 最新语音 AI 报告：语音将成为关键切入点，但非最终产品本身（含最新图谱）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;写在最后：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们欢迎更多的小伙伴参与 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。&lt;/p&gt; 
&lt;p&gt;对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b097a16f69dc64b4f3a6805bc0066e50a2f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;素材来源官方媒体/网络&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/agora/blog/18255332</link>
            <guid isPermaLink="false">https://my.oschina.net/agora/blog/18255332</guid>
            <pubDate>Sun, 27 Apr 2025 12:10:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>谷歌认为自己是唯一能运营 Chrome 的公司，如若转手，将「万劫不复」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在美国司法部对谷歌在搜索引擎市场的非法垄断案中，谷歌 Chrome 浏览器总经理 Parisa Tabriz &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffortune.com%2Farticle%2Fgoogle-chrome-suffer-if-forced-to-sell-parisa-tabriz%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;&lt;/u&gt;，将谷歌与 Chrome 「剥离」是不可能的，并补充说，她认为「Chrome 不可能在其他地方被复制」。&lt;/p&gt; 
&lt;p&gt;Tabriz 强调造就 Chrome 浏览器今日成功的基石，源于 17 年来与谷歌其他部门的紧密协作。&lt;/p&gt; 
&lt;p&gt;Tabriz 表示，谷歌 Chrome 是 Chrome 团队、谷歌以及向公司的开源 Chromium 项目提交技术贡献的公司「17 年合作」的结果，该项目的开源代码也被用于其他几个谷歌项目，如 Android 操作系统。「谷歌在 Chromium 上投入了数亿美元」，Tabri 说到，并表示其他公司「目前并没有以任何有意义的方式做出贡献。」&lt;/p&gt; 
&lt;p&gt;专家 James Mickens 认为，将 Chrome 从谷歌内部基础设施进行剥离在技术上是「feasible」（可行的），并不会破坏其功能。他指出，谷歌仍有动力继续为开源项目 Chromium 贡献技术。&lt;/p&gt; 
&lt;p&gt;然而，Tabriz 反驳称，&lt;strong&gt;谷歌自 2015 年以来贡献了 Chromium 超过 90% 的代码&lt;/strong&gt;，其他公司几乎没有实质性投入。&lt;/p&gt; 
&lt;p&gt;Tabriz 透露，谷歌正积极将 AI 技术融入 Chrome。用户目前可通过扩展程序使用 OpenAI 的 ChatGPT 和 Perplexity AI，或调整设置以便于使用其他 AI 模型搜索，不过 Gemini 被设为默认 AI 助手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</guid>
            <pubDate>Sun, 27 Apr 2025 11:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 改进 GPT-4o 模型，带来更强的智能和个性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;本月初，OpenAI 发布了多个新的 AI 模型。面向开发者的 GPT-4.1 模型引入了对 100 万个 Token 上下文窗口的支持，并在指令遵循、编码和智能方面进行了改进。o3 和 o4-mini 推理模型在多个 AI 基准测试中取得了最佳结果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4d30e4eac108c004154d6855d6c524ec1d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;即使在发布这些新模型之后，OpenAI 仍在持续更新 GPT-4o 模型。&lt;/p&gt; 
&lt;p&gt;今年 3 月，OpenAI 对 GPT-4o 进行了增强，使其更加直观、更具创造力、更具协作性，并具有更好的指令遵循性、更强大的编码能力以及更清晰的沟通风格。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我们今天更新了 GPT-4o！智力和个性都得到了提升。&lt;/p&gt; 
 &lt;p&gt;— 萨姆·奥尔特曼 (@sama)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;今天，OpenAI CEO 奥特曼&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1915902652703248679&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;对 GPT-4o 模型进行再次更新，重点提升了智能和个性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;优化 GPT-4o 保存记忆的时间长度并增强 STEM 的问题解决能力；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;还对 GPT-4o 响应方式进行了细微的更改，使其更加主动，更好地引导对话取得富有成效的结果。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/190903_uoAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此增强版本目前仅通过 ChatGPT 体验提供，开发者尚无法通过 API 访问。&lt;/p&gt; 
&lt;p&gt;OpenAI 声称，该模型现在展现出了更好的「氛围」、格式、对用户需求的直觉以及其他定性增强。然而，由于改进更难以量化，他们并未分享此版本的最新基准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9f13b1ef859a79511ac123aa8987b2341b7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;艾丹·麦克劳克林 (Aidan McLaughlin) 目前在 OpenAI 负责模型设计和能力开发，他在 Twitter 上表示，此次 GPT-4o 更新是 OpenAI 迄今为止为主要 4o 系列发布的最快的更新，这表明发布速度正在加快。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;太喜欢这个模型了！简直太有意思了！&lt;/p&gt; 
 &lt;p&gt;如果你有什么反馈，欢迎留言！&lt;/p&gt; 
 &lt;p&gt;- Aidan McLaughlin (@aidan_mclau)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;虽然基准衡量了人工智能模型的核心能力，但「氛围」等现实世界方面的改进表明 OpenAI 越来越关注整体用户体验和交互风格。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346982/openai-updated-gpt-4o</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346982/openai-updated-gpt-4o</guid>
            <pubDate>Sun, 27 Apr 2025 11:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>模力方舟百模破浪 —— 北京经开区推进 AI 开源开放生态共创</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;4 月 27 日下午，在北京人工智能产业生态创新发布会上，开源人工智能社区「模力方舟」正式发布，「开源人工智能应用创新大赛」也同步启动，经开区将围绕建设全域人工智能之城，助力共建国内 AI 开源开放生态。&lt;/p&gt; 
&lt;p&gt;模力方舟依托开源中国 17 年生态构建，积累超 1800 万开发者、2000 余所高校、36 万家企业，以绝对中立平台面向开发者提供从开源模型、训练数据集、国产算力底座到模型在线微调测试的全流程支持，降低大模型开发门槛，提高开发效率，以深厚的开源和开发者服务底蕴，致力于成为 AI 时代的重要创新引擎与生态共建平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/182702_pFoc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://ai.gitee.com/&quot;&gt;https://ai.gitee.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;「模力方舟」旨在对标国外开源社区 Hugging Face，于 2024 年 1 月上线，算力供给方面与沐曦 MetaX、华为升腾、天数智芯、摩尔线程等国产 GPU 企业合作，目前已积累约 16000 个开源模型及约 10000 个高质量数据集，覆盖自然语言处理、计算机视觉等主流 AI 领域，注册用户数超 100 万。&lt;/p&gt; 
&lt;p&gt;建设「模力方舟」有哪些资源基础？未来又将如何推进？北京经开区有关负责人介绍：「此前，经开区与北京市联动投资牵引国内头部开源社区企业——开源中国总部落地经开区。基于开源中国在传统开源领域的生态积累，围绕人工智能开源大模型和国产算力底座软硬一体化适配，我们启动了人工智能开源社区‘模力方舟’建设工作。」&lt;/p&gt; 
&lt;p&gt;为助力「模力方舟」建设成为具有国际影响力的开源人工智能社区，经开区将支持开源中国从夯实平台能力、引导资源汇聚、打造国际品牌、政策保驾护航四个方面展开工作。具体来说，充分依托公有云的弹性拓展特性与私有云的安全可控优势，精心构建起具备高并发处理能力、能够实现低延时响应的算力基础设施体系；整合自然语言处理、计算机视觉、语音识别等多个 AI 核心领域的国内外前沿模型，以及图像数据集、文字数据集、各类先进算法；围绕「一赛一会」这一核心策略持续扩大影响力，举办开源人工智能大赛及开源峰会等品牌活动，推动具有高成长性的开源 AI 创业项目在开源社区形成落地集聚；对优质开源项目、优秀商业化应用、开源生态活动给予一定资金支持等。&lt;/p&gt; 
&lt;p&gt;值得一提的是，在本次发布会上，「一赛一会」核心策略中的「开源人工智能应用创新大赛」正式启动。由开源中国联合战略合作伙伴，华为升腾、商汤科技、智谱（Z.ai）、沐曦 MetaX、天数智芯、睿思芯科、希姆计算等国内领先人工智能企业共同发起。他们将为赛事提供核心算力支持、先进 AI 模型、优质数据资源以及行业生态联动支持。这是一场全国性的人工智能赛事，定位国家级影响力赛会，通过竞赛展示开源与人工智能前沿技术创新和商业化应用，推动产业化落地，为项目实践应用提供发展平台。大赛设专业组和青少年组两个组别：专业组赛道涵盖 AI 医疗、AI 金融、AI 智能制造、视觉呈现与感知、具身智能与机器人、AI 教育与智能教学解决方案等七大方向，青少年组赛道包括创新场景实践应用、AI 算法设计与优化等四大方向。&lt;/p&gt; 
&lt;p&gt;此外，入选团队将在半决赛中与 2025 GOTC 全球开源技术峰会深度联动，为参赛团队打造国际化的展示舞台。优秀项目可在峰会分论坛演讲，演示对抗和大咖点评，全程媒体直播，让创新成果获得最大曝光。&lt;/p&gt; 
&lt;p&gt;与此同时，为更好地促进参赛团队创新成果落地，大赛主办方与经开区政府积极联动，将设立一、二、三等奖及多项单项奖项，为获奖团队提供奖金和配套政策支持，同时协调优质办公空间及算力资源的方式支持优秀项目孵化落地。&lt;/p&gt; 
&lt;p&gt;本次大赛旨在打造一项全国性、具有国家级影响力的人工智能赛事，目标是通过赛事展示技术创新与商业化应用，推动产业落地，聚焦人工智能的前沿技术，同时也为项目的实际应用提供发展平台。&lt;/p&gt; 
&lt;p&gt;目前，大赛已面向全国范围的参赛者开放报名，参赛团队可通过报名通道提供成熟的技术方案、商业化路径与应用场景等作品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346975</guid>
            <pubDate>Sun, 27 Apr 2025 10:27:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>谷歌在垄断审判中被曝向三星支付巨款预装 Gemini 应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;彭博社报道称，正在进行的谷歌反垄断审判本周的证词显示，谷歌每月向三星支付「巨额资金」，以在其设备上预装其 Gemini 人工智能应用程序。这一信息正值法官阿米特·梅塔 (Amit Mehta) 已裁定谷歌的搜索引擎构成非法垄断之后，目前谷歌的律师正与美国司法部就潜在的处罚力度展开辩论。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3bc9b596b7ba040b8f52188c972b5dfbbfc.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;谷歌平台和设备合作副总裁彼得·菲茨杰拉德周一作证称，谷歌与三星之间的这笔付款协议始于今年 1 月份。值得注意的是，这笔交易启动于谷歌被认定违反反垄断法之后，而此前谷歌被判定垄断的部分原因正是其与苹果、三星等公司类似的搜索默认合作协议。作为合作的一部分，三星在 1 月份推出的 Galaxy S25 系列手机中，将 Gemini 设置为长按电源键时的默认 AI 助手，而三星自家的 Bixby 助手则被置于次要地位。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;据《The Information》报道，菲茨杰拉德在证词中提及，包括 Perplexity 和微软在内的其他公司也曾向三星推销在其设备上预装人工智能助手应用的协议。然而，美国司法部律师指出，谷歌提交的试图修改与手机制造商协议的信函实际上是在庭审前夕，即上周才发出的，暗示这些举动可能是应对庭审压力。此外，《The Information》报道称，当天提交的谷歌内部幻灯片似乎显示，谷歌「正在考虑更具限制性的分销协议，要求合作伙伴在谷歌搜索和 Chrome 浏览器之外预装 Gemini」。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;关于支付细节，彭博社报道称，菲茨杰拉德表示，与三星的 Gemini 协议为期两年，除了固定的月费外，谷歌还将向三星支付一定比例的 Gemini 应用订阅收入。彭博社援引美国司法部律师戴维·达尔奎斯特（David Dahlquist）的话称，这笔固定的月费是一笔「巨款」，但具体数额尚未公开。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346972</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346972</guid>
            <pubDate>Sun, 27 Apr 2025 10:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>昆仑万维 2024 年营收 56.6 亿，研发费用 15.4 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;昆仑万维日前&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FEAtGxplLxQkmhQtvMNqjew&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;2024 年度财报，公司实现营业总收入 56.6 亿元，同比增长 15.2%。整体毛利率达 73.6%。全年研发费用为 15.4 亿元，同比增长 59.5%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;财报显示，公司 AGI 与 AIGC 业务商业化取得重要进展，其中，AI 社交报告期内单月最高收入突破 100 万美元，成为海外收入增长速度最快的中国 AI 应用之一；截止 2025 年 3 月底，AI 音乐年化流水收入 ARR 达到约 1,200 万美金（月流水收入约 100 万美金）。短剧平台 DramaWave 年化流水收入 ARR 达到约 1.2 亿美金（月流水收入约 1000 万美金），进一步加速 AI 商业化进程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;321&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-17907b25e9045ba880f14778875f3df05f4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;海外信息分发与元宇宙平台 Opera 继续保持高速增长，2024 年实现营业收入 4.8 亿美元，同比增长 21.1%；海外社交网络和短剧平台业务实现营业收入 12.5 亿元，同比增长 28.5%，综合推动公司海外业务收入规模上升至 51.5 亿元，同比增长 21.9%，占总收入比重达 91.0%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告期内，「天工」峰值日活跃用户超过 100 万，峰值月活跃用户突破 1,000 万。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346955</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346955</guid>
            <pubDate>Sun, 27 Apr 2025 08:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>我国将加快建立人工智能知识产权保护规则</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，我国人工智能领域呈现良好的发展势头，根据世界知识产权组织报告，中国已经成为全球人工智能专利的最大拥有国，在全球的占比达到 60%。下一步，我国将持续推进人工智能相关知识产权制度创新，加快建立人工智能、大数据等新领域新业态知识产权保护规则；建设人工智能领域专利池，促进更多人工智能领域专利从实验室走向产业链。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人工智能是新一轮科技革命和产业变革的重要驱动力量。国家知识产权局局长申长雨表示，近年来，国家知识产权局积极回应人工智能新领域、新业态、新模式发展的需要，深入推进人工智能领域知识产权制度创新，为人工智能技术发展和产业发展提供有力的制度供给。包括及时修改完善《专利审查指南》，发布《人工智能相关发明专利申请指引》，积极回应和解决了有关人工智能专利申请主体、保护客体、审查标准等热点问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「聚焦人工智能重点领域，为相关专利申请提供快速审查服务，严厉打击抢注‘DeepSeek’等相关商标申请行为，持续强化知识产权保护，护航人工智能领域科技创新。与此同时，加快人工智能技术在知识产权领域的运用，推动知识产权工作数字化转型和智能化升级，不断提升知识产权治理效能。」申长雨说。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据介绍，下一步，国家知识产权局将积极推动知识产权与人工智能共生演进、双向赋能、融合发展。其中，将持续推进人工智能相关知识产权制度创新，加快建立人工智能、大数据等新领域新业态知识产权保护规则，为发展人工智能技术提供更加有力的法治保障。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，提高人工智能知识产权保护和运用水平，健全知识产权支撑关键核心技术攻关工作体系，加大人工智能领域专利申请按需审查服务力度，做好相关发明专利分析预警和导航服务，指导建设人工智能领域专利池，深入实施专利转化运用专项行动，促进更多人工智能领域专利从实验室走向产业链，赋能相关产业发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，积极参与人工智能领域知识产权全球治理，推动完善相关国际规则和标准，促进全球人工智能产业发展，让人工智能技术更好造福全人类。（经济参考报，记者，汪子旭）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346940</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346940</guid>
            <pubDate>Sun, 27 Apr 2025 08:07:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「思考更长时间」 而非 「模型更大」 是提升模型在复杂软件工程任务中表现的有效途径</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：明巍/临城/水德&lt;/p&gt; 
&lt;p&gt;还在为部署动辄数百 GB 显存的庞大模型而烦恼吗？还在担心私有代码库的安全和成本问题吗？通义灵码团队最新研究《Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute》探索了如何通过扩展测试时计算（Test-Time Compute Scaling, TTS），让个人可部署的开源大模型（如仅需单卡运行的 32B 模型），达到与顶级闭源模型（如 DeepSeek R1, OpenAI o1）相媲美的代码推理和问题解决能力。&lt;/p&gt; 
&lt;h3&gt;核心亮点：&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;性能飞跃：32B 模型在结合了两种 Test Time Scaling 策略后，在 SWE-bench Verified 基准上，成功解决了 46.0% 的真实 GitHub Issue，与 DeepSeek R1 和 OpenAI o1 等更大规模的业界领先模型表现相当；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实证 TTS 现象：内部 TTS (Internal TTS) 通过高质量、多阶段的合成开发轨迹进行训练，让模型学会深度思考，模型在面对更有挑战的问题时，会动态地分配更多计算资源（输出更多 Token），这验证了&quot;思考更长时间&quot;确实能提升模型解决复杂任务的能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最优开发过程搜索：在软件开发的关键决策点（如仓库理解、故障定位）进行干预，利用过程奖励模型和结果奖励模型指导搜索，以更优的计算效率找到最佳解决方案。同时利用更大的推理 budget 会产生更优的性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;方法：内外兼修的 Test-time Scaling 策略&lt;/h3&gt; 
&lt;p&gt;我们提出了一个统一的测试时计算（TTS）扩展框架，包含两种互补策略：&lt;/p&gt; 
&lt;h4&gt;1. 内部 TTS (Internal Test-Time Scaling)： 内化深度思考能力&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高质量轨迹合成 (High-Quality Trajectory Synthesis)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;数据源&lt;/strong&gt; ： 从 GitHub 上筛选，超过 1000 星标，的高质量仓库，收集真实的 &lt;code&gt;&amp;lt;issue, pull-request, codebase&amp;gt;&lt;/code&gt; 三元组数据。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;初始过滤&lt;/strong&gt;： 应用启发式规则过滤数据，例如，保留描述足够详细的 issue (≥20 字符, ≤3 超链接)，以及修改量适中 (1-5 个代码文件, 非纯测试文件修改) 的 PR。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;环境构建与验证&lt;/strong&gt; ： 利用 &lt;code&gt;ExecutionAgent &lt;/code&gt;尝试为每个仓库自动构建可执行的测试环境，确保后续能够进行真实的补丁验证。无法成功构建或运行环境的仓库被排除，最终形成包含约 9000 个 issue 和 300 个仓库，的高质量数据集。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;轨迹引导与增强 (Trajectory Bootstrapping)：&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;基础框架&lt;/strong&gt; ： 基于开源的 &lt;code&gt;SWE-SynInfer &lt;/code&gt;框架（包含仓库理解、故障定位、补丁生成三个阶段），增加了补丁验证 (Patch Verification) 阶段，形成 &lt;code&gt;SWE-SynInfer+&lt;/code&gt; 框架。在此阶段，模型需生成复现代码来自动验证补丁有效性，并在失败时进行迭代优化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;引导模型&lt;/strong&gt;： 使用开源推理模型 DeepSeek R1 作为教师模型，在其多次内部推理迭代和优化的能力下，生成详尽的、包含多轮思考与修正的，长思维链（Long CoT）轨迹。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;开发上下文的拒绝采样 (Development-Contextualized Rejection Sampling)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;多维质量把关&lt;/strong&gt; ： 对生成的轨迹进行严格的多维度验证和过滤： 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;仓库理解准确性&lt;/strong&gt;： 检查模型识别的待修改文件是否与开发者实际修改的文件一致。&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;故障定位准确性&lt;/strong&gt;： 确认模型生成的补丁是否作用于开发者实际修改的代码位置（类、函数、代码块）。&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Issue 复现代码有效性&lt;/strong&gt;： 验证生成的复现代码能否在原始代码上触发问题，在应用开发者补丁后问题消失。&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;补丁正确性&lt;/strong&gt;： 应用模型补丁后，运行其生成的复现代码和仓库原有的单元测试，检查问题是否解决且无新问题引入。&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;复杂性过滤&lt;/strong&gt;： 筛除掉基础模型（Qwen2.5 Coder 32B）无需复杂推理就能一次性解决的简单问题，确保训练数据能有效激发模型的深度推理潜力。&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;保留有效中间步骤&lt;/strong&gt;： 如果一个轨迹的补丁验证失败，但之前的仓库理解、故障定位等步骤是正确的，保留这些正确的中间步骤数据，避免浪费有价值的推理过程信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;推理式训练 (Reasoning Training)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;学习目标&lt;/strong&gt;： 采用标准的监督学习，优化模型生成正确推理动作（包括思考过程和最终行动）的条件概率。损失函数同时计算轨迹中每个步骤的 &quot;思考（think）&quot;（规划、反思、修正等）和 &quot;回答（answer）&quot;（最终输出的 API 调用、代码补丁等）部分，促使模型学习完整的决策过程。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;历史信息剪枝&lt;/strong&gt; ： 为提高多轮推理效率，借鉴 DeepSeek R1 的机制，在生成第 &lt;code&gt;i&lt;/code&gt; 步时，历史上下文中只保留第 &lt;code&gt;i-1&lt;/code&gt; 步的 &lt;code&gt;answer&lt;/code&gt; 部分，舍弃 &lt;code&gt;think&lt;/code&gt; 部分，减少冗余信息。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. 外部 TTS (External Test-Time Scaling): 优化决策搜索路径&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;基于开发流程的搜索策略 (Development-Process-Based Search, Dev-Search)：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;核心思想： 软件工程任务是长链条决策过程，中间步骤的错误会严重影响最终结果。我们摒弃仅在终点验证或对每一步都进行低效验证的做法，选择在，三个关键决策阶段（仓库理解、故障定位、补丁生成）集中进行搜索和评估，以高效利用计算预算。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;过程奖励模型 (Process Reward Model, PRM) 引导：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;训练目标： 训练 PRM（基于基础模型微调）来判断中间输出的正确性（二元分类任务）。例如，判断识别的文件是否正确，定位的代码位置是否准确。&lt;/li&gt; 
   &lt;li&gt;引导方式： 在每个阶段生成 N 个候选输出，使用 PRM 对其打分，保留 Top-k 的高分候选进入下一阶段，实现轻量级的、有指导的 Beam Search，有效剪枝低潜力路径。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;执行验证与结果奖励模型 (Outcome Reward Model, ORM) 排序：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;补丁验证： 在补丁生成阶段，利用模型生成的复现代码和仓库自带的回归测试，对候选补丁进行执行验证，确保其有效性且不破坏原有功能。&lt;/li&gt; 
   &lt;li&gt;最终排序： 对于通过执行验证的多个候选补丁（可能存在多个），使用 ORM 进行最终排序。ORM 基于 DPO 进行训练，学习偏好&quot;通过所有测试&quot;的补丁优于&quot;未通过测试&quot;的补丁。重要的是，ORM 仅需 Issue 描述和候选补丁作为输入，不依赖中间推理步骤，易于集成。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;* 所有模型均基于开源的 Qwen2.5 Coder 32B 模型进行训练，该模型可在消费级显卡上进行部署。&lt;/p&gt; 
&lt;h3&gt;实验评估：&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 整体性能 SOTA：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;结果&lt;/strong&gt; ：训练的 SWE-Reasoner 32B 模型结合了内部和外部 TTS (Unified TTC, budget=8) 后，达到了 &lt;strong&gt;46.0%&lt;/strong&gt; 的 Issue 解决率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;对比&lt;/strong&gt; ：在 &lt;strong&gt;≤100B 参数量级&lt;/strong&gt; 的模型中处于领先地位，超越了如 DeepSeek R1 671B (41.20%) 等更大的开源模型，并且接近业界顶尖的闭源模型 &lt;strong&gt;Claude 3.5 Sonnet v2 (46.20%) 和 OpenAI o1 (45.60%)&lt;/strong&gt; 。（详见图 1 和表 1）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;泛化性与独特性&lt;/strong&gt; ： 该模型在 SWE-bench 覆盖的 &lt;strong&gt;12 个不同 Python 仓库&lt;/strong&gt; 上均表现出鲁棒的性能，在多数仓库上媲美或超越 DeepSeek R1 671B（详见图 2）。此外，通过与其他模型的解决实例对比，我们的方法能够&lt;strong&gt;独立解决 17 个&lt;/strong&gt; 其他模型无法解决的 Issue，展现了独特的解题能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7db136b0910f0176b97a3c5b1acf6fb954a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 1: 在 SWE-Bench Verified 上，对具有扩展测试时间计算的较小 LLM 与较大模型的性能进行比较&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72f7e7d2804b299d8dfa3b233a7800bde83.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;表 1: 与不同模型和框架在 SWE-bench Verified 基准上的性能比较。&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-34e04a33bd527f603d32925d74cd5399fbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 2: 针对不同仓库的 issue 解决率比较&lt;/em&gt;&lt;/p&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;内部 TTS 研究分析：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;不同难度性能优势：Long CoT 训练相比 Short CoT 训练在解决更难 issue 上提升明显（基于社区解决频率划分的 Level 5，效果提升约 6 倍，详见图 3）。&lt;/li&gt; 
 &lt;li&gt;Test-Time Scaling 现象：Reasoning 模型在解决更难的问题上会尝试输出更多 token，有明显的 test-time scaling 现象（SWE-Reasoner 和 OpenAI o1），Claude 3.5 Sonnet 也有这个 TTS 现象，但是整体输出 token 较少。而 Short CoT 模型则没有这种明显的自适应计算行为（详见图 4）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3c30dd96e1f621562e4abaabc3b0de14eaf.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 3: 在不同难度的 SWE-bench Verified 上的不同模型的解决率&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4621ed1a8486d72ecc1601d79134bff04f0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 4: 在不同难度的 SWE-bench Verified 上的不同模型的平均输出 tokens 比较&lt;/em&gt;&lt;/p&gt; 
&lt;ol start=&quot;3&quot;&gt; 
 &lt;li&gt;外部 TTS 研究分析：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Dev-Search 策略优势&lt;/strong&gt; ，在控制相同推理预算（Rollout 次数 1, 2, 4, 8）的条件下，我们提出的 Dev-Search 策略&lt;strong&gt;始终优于&lt;/strong&gt;仅依赖执行验证 (Exec)、执行验证+ORM (ORM_Exec) 或投票 (Voting) 的基线方法。这证明了在关键开发流程中进行干预和指导能带来更优的搜索效率。（详见图 5）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;预算与性能关系 (TTS)&lt;/strong&gt; ： 增加推理预算（Generation Budget）通常能带来性能的提升，再次验证了&lt;strong&gt;外部 TTS 的有效性&lt;/strong&gt; 。预算的增加对于解决&lt;strong&gt;简单和中等难度&lt;/strong&gt;（Level 1-4）的问题提升尤为明显。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高难度任务瓶颈&lt;/strong&gt; ： 对于&lt;strong&gt;最高难度&lt;/strong&gt; （Level 5）的问题，过高的推理预算反而可能导致性能轻微下降。这暗示对于极其复杂的任务，仅靠外部搜索扩展可能已触及模型&lt;strong&gt;内在推理能力&lt;/strong&gt;的瓶颈，需要内部 TTS（想得更深）的共同作用或更强的基础模型能力。（详见图 6）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-434beb18c7bb820d3f490ae790cab2d9350.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 5: 不同搜索方式在相同 budget 下的性能比较&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-468c4c7e44d51a148124f91360ce28d2836.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图 6: 在不同难度的 SWE-bench Verified 上使用不同 budget 的能力比较&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;结论&lt;/h3&gt; 
&lt;p&gt;本研究成功展示了通过统一的测试时计算（TTS）扩展框架，可以显著增强个人可部署的开源 SWE Agent 的代码推理和问题解决能力。我们证明了&quot;思考更长时间&quot;（增加推理计算）而非&quot;模型更大&quot;（增加参数）是提升模型在复杂软件工程任务中表现的有效途径。这项工作为在资源受限环境下（如私有部署）使用和发展高性能 SWE Agent 开辟了新的可能性。&lt;/p&gt; 
&lt;h3&gt;展望与思考：更智能更自适应的 SWE Agent&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;自适应计算&lt;/strong&gt; ： 未来可以研究如何让模型根据任务难度&lt;strong&gt;动态、自适应地调整计算资源的投入&lt;/strong&gt;，实现效率与效果的最佳平衡。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;环境与验证&lt;/strong&gt;： 提升自动化测试环境构建和解决方案验证的鲁棒性与规模，是进一步利用强化学习 (RL) 释放 SWE Agent 潜力的关键。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;任务泛化&lt;/strong&gt;： 将此 TTS 框架应用到更广泛的软件工程任务中，如测试用例生成和代码重构等。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;🔎 &lt;strong&gt;详细方案请参考论文：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;arxiv📄: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.23803&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2503.23803&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Github🌟: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyingweima2022%2FSWE-Reasoner&quot; target=&quot;_blank&quot;&gt;https://github.com/yingweima2022/SWE-Reasoner&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18219052</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18219052</guid>
            <pubDate>Sun, 27 Apr 2025 07:54:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Graphiti —— 为 AI 代理构建实时知识图谱</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Graphiti 是一个用于构建和查询时序感知知识图谱的框架，专为在动态环境中运行的 AI 代理量身定制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与传统的检索增强生成 (RAG) 方法不同，Graphiti 持续将用户交互、结构化和非结构化企业数据以及外部信息集成到一个连贯且可查询的图中。该框架支持增量数据更新、高效检索和精确的历史查询，无需完全重新计算图谱，因此非常适合开发交互式、情境感知的 AI 应用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;Graphiti 专门为解决动态和频繁更新的数据集的挑战而设计，使其特别适合需要实时交互和精确历史查询的应用程序。&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用 Graphiti 可以：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;集成并维护动态用户交互和业务数据。&lt;/li&gt;
&lt;li&gt;促进代理基于状态的推理和任务自动化。&lt;/li&gt;
&lt;li&gt;使用语义、关键字和基于图形的搜索方法查询复杂、不断变化的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;实时增量更新：&lt;/strong&gt;立即集成新的数据事件，无需批量重新计算。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;双时间数据模型：&lt;/strong&gt;明确跟踪事件发生和摄取时间，允许准确的时间点查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效混合检索：&lt;/strong&gt;结合语义嵌入、关键字（BM25）和图遍历，实现低延迟查询，而无需依赖 LLM 摘要。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自定义实体定义：&lt;/strong&gt;通过简单的 Pydantic 模型灵活地创建本体并支持开发人员定义的实体。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性：&lt;/strong&gt;通过并行处理有效管理大型数据集，适用于企业环境。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;281&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/152503_famB_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/graphiti</link>
            <guid isPermaLink="false">https://www.oschina.net/p/graphiti</guid>
            <pubDate>Sun, 27 Apr 2025 07:28:00 GMT</pubDate>
        </item>
        <item>
            <title>手机版 QQ 支持微信小程序</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QQ 手机端最新版本新增了对微信小程序的支持。&lt;/p&gt; 
&lt;p&gt;经实测，在最新版本的 QQ 手机端下，用户在首页下拉或在搜索处即可唤醒「QQ 转微信小程序」的相关入口。首次从 QQ 进入微信小程序会跳转至微信进行账号授权，随后即可在 QQ 处直接唤醒相关小程序。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/142420_lJxN_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;980&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/142621_Zc2r_2720166.png&quot; width=&quot;746&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/142400_VcHG_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，QQ 处的小程序内登录的账号，会与授权过信息的微信保持一致。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346915</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346915</guid>
            <pubDate>Sun, 27 Apr 2025 06:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>