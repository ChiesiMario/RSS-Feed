<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Mar 2025 12:36:10 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>SpacetimeDB 1.0 正式发布，Rust 编写的开源关系型数据库</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;SpacetimeDB 1.0 已正式发布。&lt;/p&gt; 
&lt;p&gt;SpacetimeDB&amp;nbsp;是 Rust 实现的开源关系型数据库，可让你通过名为&quot;modules&quot;的存储过程将应用程序逻辑直接上载到数据库中。&lt;/p&gt; 
&lt;p&gt;你的客户端无需在客户端和数据库之间部署网络或游戏服务器，而是直接连接到数据库，在数据库内部执行您的应用逻辑。你可以像在普通服务器中一样，在模块中编写所有权限和授权逻辑。&lt;/p&gt; 
&lt;p&gt;这意味着你可以用一种语言 Rust 编写整个应用程序，并将其部署为一个二进制文件。不再有微服务、不再有容器、不再有 Kubernetes、不再有 Docker、不再有虚拟机、不再有 DevOps、不再有基础设施、不再有运营、不再有服务器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2023/0810/113841_TOav_4252687.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;SpacetimeDB 1.0 发布公告&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspacetimedb.com%2Fblog%2Fintroducing-spacetimedb-1-0&quot; target=&quot;_blank&quot;&gt;写道&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;这是整个团队多年来一直努力实现的一个里程碑。我们投入了大量的工程和技术努力，以确保我们的 API 在所有语言和库中保持稳定，同时使 SpacetimeDB 成为一个在生产环境中可以信赖的稳定产品。&lt;/p&gt; 
 &lt;p&gt;因此，我们正式退出测试版，并推出我们的 &lt;strong&gt;首个生产就绪版本&lt;/strong&gt;！&lt;/p&gt; 
 &lt;p&gt;使用这个版本，你可以使用 SpacetimeDB Standalone 来托管自己的应用程序，并放心数据格式和 API 将不会在下一个主要版本发布之前发生变化。对于未来的主要版本发布，我们也将提供迁移路径。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ae28ccb74a2c8bf1d578457cdc49a6070.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;其他值得关注的变化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;新的云托管服务 Maincloud&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;流线化的稳定客户端 SDK，包括 TypeScript、C#和 Rust&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;C# 和 Rust 中的精简稳定模块 API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;某些工作负载的性能显著提升&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全新的可变订阅 API，允许您逐步更改订阅&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;精美的全新版本管理器 CLI 命令&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;全新的网站界面和账户管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;OpenID Connect 集成和 API&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Maincloud&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;与 SpacetimeDB 1.0 一同推出的，还有其托管云服务 Maincloud。Maincloud 与独立版本类似，但无需让用户处理任何部署问题！只需运行以下命令即可：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot;&gt;spacetime publish -s maincloud your-app&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;下载地址 &amp;amp; 发布公告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fclockworklabs%2FSpacetimeDB%2Freleases%2Ftag%2Fv1.0.0&quot; target=&quot;_blank&quot;&gt;https://github.com/clockworklabs/SpacetimeDB/releases/tag/v1.0.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338417/spacetimedb-1-0-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338417/spacetimedb-1-0-0</guid>
            <pubDate>Thu, 06 Mar 2025 11:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek：「国运级创新」，凭啥？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;768&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4eb15815df212b6763b81b49b68f594857.jpg&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;前言&lt;/span&gt;：&lt;/strong&gt;&lt;br&gt; 春节前后，要说国内外科技圈最火热的名字，DeepSeek 绝对算头一个。「开源大模型之光」、「AI 领域新星」、「有望比肩 OpenAI」…… 各种赞誉纷至沓来，甚至有人直接将其冠于「国运级创新」的说法。「国运级创新」？ 这个帽子可实在不小。但是有人会质疑，凭啥？本文则试着从产业共识的角度来分析，笔者认为它确实担得起。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. DeepSeek&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，是国运级创新！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;要探寻 「DeepSeek 是国运级创新」 这一说法的源头，最早的说法来自游戏圈内极具影响力的人物——现象级 3A 游戏《黑神话：悟空》的制作公司游戏科学创始人冯骥。他在新浪微博上就曾公开表示：「DeepSeek 可能是个国运级别的科技成果」。冯骥以其独到的眼光和对技术趋势的敏锐洞察力而著称，他的这番评价，无疑引发了广泛关注。下图是他的微博截图。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1058&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2827904619db71dd8976e59971d5613c281.webp&quot; width=&quot;1078&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;国内安全领域的领军人物，360 集团创始人周鸿祎也表达了对 DeepSeek 的有力支持。 在今年两会期间接受《新京报》记者关于 「人工智能技术开源」 话题的采访时，他 「举双手赞同」 冯骥关于 DeepSeek 「国运级别的科技成果」 的评价。他认为开源模式形成了巨大的虹吸效应，一旦形成气候，将彻底战胜闭源。凭借更低的成本和更开放的技术普惠路径，中国在 AI 应用规模和渗透率上比美国更高。周鸿祎作为在 IT 行业深耕多年的资深人士，他的认可更显分量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-828276f780bb3ae6d229892554c1bb867c7.webp&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（图片来自新京报）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;著名技术社区 CSDN 的高级副总裁李建忠今年也撰文《DeepSeek 关键技术创新及对 AI 生态的影响》，从技术生态的角度深入分析了 DeepSeek。 他认为 DeepSeek 的巨大影响力，不仅在于其在 AI 领域实现的多项关键技术创新，更在于它，引发了对全球 AI 生态格局升级和重塑的深刻思考。 作为深耕开发者生态多年的行业大 V，李建忠盛赞 DeepSeek 「或将成为中国开发者拥抱 AI 时代的最佳选择」。 来自开发者社区的积极评价，无疑是最直接且最具说服力的市场反馈。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;不仅如此，国际媒体也敏锐捕捉到了 DeepSeek 的崛起，并将其与具有历史意义的 「人造衞星时刻 (Sputnik moment)」 相提并论。 「人造衞星时刻」 源于 1957 年前苏联成功发射人类首颗人造衞星 Sputnik 1 号， 这一事件震惊世界， 象征着科技竞争格局的突变，以及对原有技术领导者的挑战。 外媒借用 「人造衞星时刻」 来形容 DeepSeek，一方面是认同 DeepSeek 在人工智能尤其是在大模型技术领域取得的突破性进展， 另一方面是预示着其可能打破美国在 AI 领域的领先地位， 并对全球 AI 竞争格局产生深远影响。 这种来自国际舆论场的积极信号， 进一步印证了 DeepSeek 在全球 AI 领域的影响力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. DeepSeek&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;，真的是「国运级创新」吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;但是，很多人可能会质疑，它凭啥，可以担当得起「国运级创新」这个评价？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 虽然开源，虽然它的性能优异媲美一流的商业大模型，同时成本低廉为顶尖商业大模型的几十分之一，而且拥有大量的技术创新，包括在算法上和工程上。但是这些优点在行业内并非独有。在它之前，Meta 公司的 Llama 系列、阿里公司的 QWen 系列、欧洲公司的 Mistral 系列等开源大模型，早已在业界积累了良好的口碑，且同样具备出色的性能和开源特性。近年来，开源大模型已经成为行业内的重要趋势，开源本身已经不再是稀缺资源。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;而且技术特性上，让它成本最低的模型架构 MOE（Mixture of Expert）也不是原创，Mistral 之前早就这么做了。而纯用深度学习来进行模型推理能力的增强，这也是 OpenAI 半年前发布 OpenAI O1 的做法，只不过它没有开源而已。所以有人质疑，即便 DeepSeek 在部分指标上超越了前辈项目，这种领先是否足以称为颠覆性突破？此外，DeepSeek 的模型虽然开源，论文虽然公开而且很详细，但底层技术路线的原创性究竟有多少？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;它凭什么能够在短时间内获得如此高的评价，甚至被视为「国运级创新」？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;笔者认为，DeepSeek 是堪称「国运级「的科技创新，不仅仅是它的性能好、成本低、开源这三个技术方面的特点，最重要的原因，是它&lt;strong&gt;&lt;span style=&quot;color:#c0392b&quot;&gt;初步达成了国内外的产业共识&lt;/span&gt;&lt;/strong&gt;。而产业共识，尤其是中国人领导的产业共识，非常难得，非常有价值，之前基本没有，就是我顶它为国运级创新的理由。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;3. 共识是什么？产业共识又是什么？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;产业共识？ 这是什么？这玩意儿有这么重要？当然重要！ 甚至可以说，产业共识，才是 「国运级创新」 最坚实的基石。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;要理解 「产业共识」 的价值，我们先得搞清楚，啥是 「共识」？字典上说，共识，就是指对某件事物或观点的普遍认同。 放到社会学和心理学层面，共识更意味着一种，群体性的认知、价值取向和行动方向的统一。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;「共识」 究竟为何如此重要？ 我们不妨从以下几个维度来剖析：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共识是行动的「方向盘」：&lt;/strong&gt;&lt;span&gt;&amp;nbsp;想象一下，如果一个团队，每个人都朝着不同的方向努力，力量就会被分散，效率就会大打折扣。 共识就像是 「方向盘」， 能够统一方向， 让群体力量朝着同一个目标前进， 避免内耗， 提升效率。 无论是家庭生活、团队协作、还是社会治理， 「方向一致」 都是高效行动的前提，而 「共识」 就是确保方向一致的关键。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共识是信任的「桥梁」：&lt;/strong&gt;&lt;span&gt;&amp;nbsp;人与人之间的合作， 离不开信任。 而 「共识」 恰恰是建立信任的 「桥梁」。 当彼此之间有了共同的认知、共同的价值观、共同的目标， 信任的基石就得以建立。 「共识」 能够减少误解， 降低沟通成本， 促进彼此理解和支持， 从而建立起更深厚的信任关系。 信任就像是人际关系的纽带，而 「共识」 就是构建信任的桥梁。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共识是稳定的「压舱石」&lt;/strong&gt;&lt;span&gt;： 社会和群体的稳定， 需要共同的规则和秩序来维系。 「共识」 就如同 「压舱石」， 能够维护群体和社会的稳定。 当社会成员对基本价值观、行为准则、社会秩序等达成共识， 社会就能保持稳定和凝聚力， 减少冲突和对抗， 构建和谐稳定的社会环境。 稳定就像是大船的压舱石，而 「共识」 就是社会稳定的压舱石。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共识是创新的「催化剂」&lt;/strong&gt;&lt;span&gt;： 创新往往需要集思广益， 需要不同观点的碰撞和融合。 「共识」 看似是统一思想， 但实际上， 它也能成为创新的 「催化剂」。 在 「共识」 的基础上， 不同的观点和想法才能更好地交流和融合， 激发新的思路， 碰撞出创新的火花。 共识并非 「求同」， 而是在 「存异」 的基础上 「求同」， 最终实现 「和而不同」 的创新局面。 创新就像化学反应，而 「共识」 就是催化反应的催化剂。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;共识是力量的「倍增器」&lt;/strong&gt;&lt;span&gt;： 单个人、单个组织的力量终究有限。 「共识」 能够将分散的力量 「聚合」 起来， 形成 「1+1&amp;gt;2」 的 「倍增效应」。 当一个群体， 一个社会， 甚至一个国家， 在某个重要方向上达成共识， 就能凝聚起强大的合力， 共同应对挑战， 实现共同目标。 力量源于团结，而 「共识」 就是凝聚力量、倍增力量的源泉。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;更进一步， 如果我们从人类文明演进的宏大视角来看， 「共识」 的重要性， 就更加不言而喻了。 正如畅销书《人类简史》所揭示的， 远古的智人之所以能够战胜其他更强壮、更聪明的古人类（例如尼安特人等）， 最终成为地球的主宰， 并非仅仅依靠个体力量，而是因为智人掌握了一种独特的生存技能—— 「讲故事， 形成共识， 组织大规模合作」。正是 「共识」 这种神奇的力量， 让智人能够将分散的个体组织起来， 击败其他古人类，形成部落、城邦、国家， 构建复杂的社会结构， 共同应对自然挑战， 直至最终创造出辉煌的人类文明。 从某种意义上说， 「人类文明史」， 就是一部 「共识进化史」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1024&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ef5b090ee221607c5f340d5853a09191a5f.png&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;图为一批原始人协同工作击杀大象&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;理解了 「共识」 在人类社会中的重要性， 我们再来看 「产业共识」。 所谓 「产业共识」， 就是将 「共识」 的理念， 应用到 「产业」 领域。 具体而言， 「产业共识」 指的是产业链上下游各个环节， 以及相关利益方， 对于某个产业发展方向、技术路线、价值理念等达成的普遍认同。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;那么， 「产业共识」 对于 IT 产业， 又意味着什么呢？ 它又将发挥哪些独特而重要的作用呢？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;统一方向，凝聚力量&lt;/strong&gt;&lt;span&gt;： 产业共识就像一个 「指挥棒」，能够引导产业资源向同一个方向集中，避免内耗和重复建设，形成合力，共同推动产业快速发展。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;降低风险，提升效率&lt;/strong&gt;&lt;span&gt;： 有了产业共识，大家就能在相对确定的方向上进行创新和投入，减少试错成本，加速技术迭代和市场推广，提高整体产业效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;构建生态，合作共赢&lt;/strong&gt;&lt;span&gt;： 产业共识能够促进产业链各环节的协同合作，形成互信互利的合作关系，构建健康可持续的产业生态，最终实现共赢。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;我们回顾，一下这么多年 IT 产业发展史，我们就能看到 「产业共识」 的力量，有很多很好的例子，我稍微举几个：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;Linux 操作系统的崛起&lt;/strong&gt;&lt;span&gt;：&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;当我们审视 DeepSeek 的崛起轨迹，历史正在重演 Linux 的传奇。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Linux 的成功，绝对是 IT 产业 「产业共识」 的典范。&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#404040&quot;&gt;&lt;span&gt;1991 年当芬兰大学生 Linus Torvalds 在大学宿舍敲下第一行内核代码时，没人能预见这个「个人玩具」会重构全球操作系统格局。彼时的 Unix 闭源帝国 AT&amp;amp;T 与 Microsoft Windows 商业巨轮，正如今天的 OpenAI GPT 系列和 Anthropic Claude 系列，用高墙锁死创新。但是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;Linux 用开源、开放，的理念迅速获得了全球开发者的认同和响应，同时也打破了 Unix 商业发行版和 Microsoft Windows 的垄断，从个人开发者到商业公司谷歌、IBM、红帽等，无数开发者参与到 Linux 的开发和完善中，最终 Linux 成为了，服务器、嵌入式系统、移动设备等领域最主流的操作系统之一。 Linux 的成功， 打破了商业操作系统的垄断，构建了一个庞大而充满活力的开源生态系统。 可以说，没有开源共识和产业界对 Linux 的共同支持， 云计算、大数据、移动互联网等技术发展都难以想象。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;HDFS (Hadoop 分布式文件系统) 的普及&lt;/strong&gt;&lt;span&gt;： HDFS 又是另外一个很好的例子。HDFS 最早是作为 Google 内部大数据分布式存储和计算的 GFS 的开源实现，但是后来在大数据浪潮中，HDFS 成为了，存储海量数据的标准基础设施。 HDFS 开源、可扩展、高容错，的特性，完美契合了大数据时代的需求，迅速获得了包括互联网巨头、金融机构、科研机构等各行各业的广泛采用。 HDFS 的普及， 降低了大数据存储和处理的门槛，加速了大数据技术的应用和创新。 可以说，没有 HDFS 的产业共识， 大数据产业格局将会非常不同。后来即便是 GFS 的实际发明人 Google，在推出 Google Cloud 对外，提供服务的时候，也不得不支持在他们眼里技术落后的 HDFS。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;Kubernetes (K8s) 容器编排系统的流行&lt;/strong&gt;&lt;span&gt;： 在云计算和容器技术兴起的大背景下，Kubernetes 脱颖而出，成为了云原生（Cloud Native）中容器编排领域的标准。 Kubernetes 强大的容器管理能力、灵活的扩展性、丰富的生态系统，赢得了包括 Google、Microsoft、Amazon、阿里、字节、腾讯等云巨头在内的整个 IT 产业的共同拥抱。 Kubernetes 的流行， 极大地简化了应用部署和管理，加速了云原生技术的普及，推动了云计算的快速发展。 可以说，没有 Kubernetes 的产业共识， 云原生应用开发和部署模式将面临更多挑战。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;这些例子都充分说明，「产业共识」 对于 IT 产业的健康发展和技术创新，具有至关重要的作用。 它不仅仅是一种 「认同」，更是一种 「力量」， 一种能够凝聚产业资源、加速技术创新、构建繁荣生态、提升整体竞争力的 「战略性资源」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;反观中国 IT 产业发展历程，我们会发现，在形成，国际，产业共识方面，中国 IT 产业的案例相对较少，或者说没有特别值得一提的案例。这并非是中国技术能力不足，而是由多种复杂因素造成的：一方面中国 IT 起步较晚，错失早期行业事实标准制定机会；另一方面，早期发展策略侧重 「自主可控」 和 「国产替代」： 这在保障国家信息安全、建立自主产业链方面取得了显著成就， 但在，推动技术标准国际化、形成全球产业共识方面，客观上有所侧重；还有就是文化和语言差异，影响技术理念传播： 技术标准的推广和产业共识的形成， 除了技术实力，也需要文化和语言的传播。 当然还有国际政治和市场环境的复杂性： 近年来，国际政治经济环境日趋复杂， 技术 「脱钩」 和 「逆全球化」 趋势抬头， 也为中国 IT 技术走向国际，形成全球产业共识增加了阻力。但这并不意味着中国 IT 产业无法形成产业共识，更不意味着中国技术无法走向世界。 事实上，近年来，我们已经看到一些积极的趋势：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;中国企业积极参与国际标准制定： 越来越多的中国企业开始积极参与国际技术标准的制定， 例如在 5G、人工智能、物联网等新兴领域，中国企业的话语权和影响力正在显著提升。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;开源开放成为新趋势： 越来越多的中国 IT 企业开始拥抱开源开放， 通过开源项目和开放平台， 与全球开发者社区和产业界进行更广泛的合作和交流， 为形成产业共识创造更有利条件。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;「一带一路」 倡议推动技术和标准输出： 「一带一路」 倡议为中国 IT 技术和标准 「走出去」 提供了重要平台和机遇， 通过基础设施建设和产业合作， 中国技术和标准在发展中国家和地区的影响力不断扩大。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;在这样的背景下， DeepSeek 的出现， 以及它所展现出的 「产业共识」 潜力， 就显得尤为重要和值得关注。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;4. 凭啥说 DeepSeek 已经初步达成了产业共识？ 体现在哪些方面？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;我认为，DeepSeek 已经初步达成产业共识，先看看产业的实际情况。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;IT 产业围绕大模型领域，可以按照技术层次，从下往上分为四层。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;904&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e212d801965b9dcd4528c52e1f40e83fef9.png&quot; width=&quot;1730&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;而当前，每一层的国内外玩家都非常认同和积极拥抱 DeepSeek，这就是产业共识。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（1）&lt;/span&gt;&lt;strong&gt;基石层&lt;/strong&gt;&lt;span&gt;：国内外的 CPU/GPU 厂家都纷纷宣称支持 DeepSeek，其中包括国际的 Intel、AMD，国内的海光、沐曦、华为、隧原、&lt;/span&gt;摩尔线程、&lt;span&gt;天数智芯、昆仑芯、&lt;/span&gt;壁仞科技、&lt;span&gt;龙芯等宣称支持 DeepSeek。几乎找不到一家 CPU/GPU 厂家说不支持 DeepSeek，各家的区别可能是有的支持 R1 满血版，有的支持 R1 蒸馏版而已。这一层还包括一体机、操作系统、网络、存储、IDC 等。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（2）&lt;/span&gt;&lt;strong&gt;云服务层&lt;/strong&gt;&lt;span&gt;：同样国内外的云厂商纷纷宣称支持 DeepSeek，其中包括国际的 AWS、Microsoft Azure、Nvidia Nim，和国内的阿里云、腾讯云、百度云、火山云，还有三家电信运营商的云，此外还有一些中小企业例如商汤科技、硅基流动等也宣称提供部署 DeepSeek 多个版本的云服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;646&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-65464c7380c891a0572a028abe9217ce193.webp&quot; width=&quot;736&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;（以上信息来自&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;https://www.perplexity.ai/）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（3）&lt;/span&gt;&lt;strong&gt;软件产品集成层&lt;/strong&gt;&lt;span&gt;：企业软件巨头们也纷纷宣布支持 DeepSeek，例如 SAP 宣布在集成 DeepSeek 在它的 ERP 软件中，国内 ERP 巨头用友宣布已经集成 DeepSeek 到它的 BIP 产品中，此外还有浪潮通软、金蝶等 N 多企业软件宣称集成了 DeepSeek。其他宣称支持 DeepSeek 的商业软件，包括 BI 产品、CRM 产品就更多了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;（4）&lt;/span&gt;&lt;strong&gt;甲方应用层&lt;/strong&gt;&lt;span&gt;：各行业的甲方巨头们也纷纷支持 DeepSeek，例如工商银行集成 DeepSeek 到工行内部大模型服务平台，服务于财报分析助手、财富管家、智能客服、风险评估等业务中，在北京友谊医院/清华长庚医院也宣称已经集成了 DeepSeek 在他们的数字化平台中，还有能源、交通等多家央企宣称集成了 DeepSeek。中兴努比亚手机、OPPO 手机也纷纷宣称在他们的手机系统上集成了 DeepSeek 大模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;这非常难得，因为之前笔者曾经一度觉得很困扰，因为大模型模型的不统一，导致上下每一层都存在巨大的适配工作，而只要其中任何一层的适配工作没有做好，都会导致最终大模型应用落地的体验很差，要么最终输出准确性不及预期，实际落地需要大量的 dirty work；要么整个系统延迟巨高，用户体感很差。现在好了，每一层的企业都在主动适配 DeepSeek，这样能大大减轻各个层面的适配工作，让大模型应用的落地成本更低、速度更快、体验更好。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;更难得的事，笔者上个月在沙特利雅得参加沙特开源峰会 2025，跟沙特本地 IT 人士沟通的时候，他们也充分认同 DeepSeek 的价值，对来自中国的开源 AI 充满好感，有的数字化产品之前使用 ChatGPT API 的也在迁移到 DeepSeek 上。而这也为集成 DeepSeek 的中国 IT 软件进入中东市场创造了有利的条件。沙特只是一带一路上的一个国家，但是管中窥豹可以看出，DeepSeek 对于中国拓展一带一路上的数字基础设施建设和数字经济业务，能起到非常好的标杆作用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;2240&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7ca0344af9eab3d374819dc4a69de9d0341.jpg&quot; width=&quot;3360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#ff2941&quot;&gt;这就是产业共识的力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;5. 产业共识，对 DeepSeek 的未来有啥影响？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;笔者认为，如果 DeepSeek 真的能够持续巩固和扩大这种 「产业共识」， 那么它未来的发展，将获得源源不断的强大助推力：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;加速技术创新&lt;/strong&gt;&lt;span&gt;： 产业共识将为 DeepSeek 提供更广阔的技术创新空间和资源支持，吸引更多优秀人才和资本的涌入，促进其在 AI 核心技术上不断突破，保持技术领先优势。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;拓展应用场景&lt;/strong&gt;&lt;span&gt;： 产业共识将帮助 DeepSeek 更快地渗透到各行各业，拓展更丰富的应用场景，实现技术与产业的深度融合，释放 AI 技术的巨大商业价值和社会价值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;构建生态壁垒&lt;/strong&gt;&lt;span&gt;： 产业共识将有助于 DeepSeek 构建强大的产业生态系统，形成技术、市场、生态等多重壁垒，提升长期竞争力，成为中国 AI 产业生态的核心力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;strong&gt;提升中国 AI 产业竞争力&lt;/strong&gt;&lt;span&gt;： DeepSeek 的崛起和产业共识的形成，将带动整个中国 AI 产业的蓬勃发展，提升中国在全球 AI 领域的竞争力，甚至有望改写全球 AI 产业格局。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;6. 总结一下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 是不是 「国运级创新」， 现在下定论可能还为时过早。 但它，初步达成的 「产业共识」 ， 的确为我们提供了一个全新的视角， 让我们看到了中国 IT 产业 「聚沙成塔， 众木成林」 的希望。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;如果 DeepSeek 能够继续保持开放合作的姿态， 持续技术创新， 不断扩大产业共识， 那么它未来的发展， 真的值得我们期待，甚至有可能超出我们的想象。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;DeepSeek 「国运级创新」， 凭啥？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;strong&gt;凭 「产业共识」！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;你觉得这个道理， 站得住脚吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;(欢迎在评论区留下你的看法！)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3742410/blog/17885347</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3742410/blog/17885347</guid>
            <pubDate>Thu, 06 Mar 2025 10:58:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>「一脑多机」通用具身智能平台「慧思开物」发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;北京人形机器人创新中心（国家地方共建具身智能机器人创新中心）在京发布全球首个「一脑多能」「一脑多机」的通用具身智能平台「慧思开物」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「慧思开物」的应用是对基於单一场景单一任务做专项开发这一传统机器人应用开发模式的颠覆，同时也填补了具身智能领域在通用软件系统方面的空白，真正推动智能机器人从单一任务执行向复杂环境下的自主决策与执行能力跃升。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;img height=&quot;289&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-804921cd73199cb7a3d3f1073e873a9888b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;282&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a38d5a4d0328e61acdf9f224eb5f046bd60.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;em&gt;来源：央视新闻&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338410</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338410</guid>
            <pubDate>Thu, 06 Mar 2025 10:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里通义实验室开源 R1-Omni，全模态模型+RLVR</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里通义实验室&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPC1s42i6PvwelFL8JTIAbw&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;开源 R1-Omni 模型，业界首个将具有可验证奖励的强化学习（Reinforcement Learning with Verifiable Reward，RLVR）应用于全能多模态大语言模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;研究人员利用 RLVR 对开源 Omni 模型 HumanOmni-0.5B 进行优化，在推理能力、情感识别准确性和泛化能力三个关键方面显著提高了其性能。R1-Omni 能够更清楚地理解视觉和听觉信息如何促进情绪识别，能够明确展示哪些模态信息对特定情绪的判断起到了关键作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了验证 R1-Omni 的性能，项目团队将其与原始的 HumanOmni-0.5B 模型、冷启动阶段的模型以及在 MAFW 和 DFEW 数据集上有监督微调的模型进行了对比。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5f25e57a50cb46139c49aca195c12da36b8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;实验结果显示，在同分布测试集（DFEW 和 MAFW）上，R1-Omni 相较于原始基线模型平均提升超过 35%，相较于 SFT 模型在 UAR 上的提升高达 10% 以上。在不同分布测试集（RAVDESS）上，R1-Omni 同样展现了卓越的泛化能力，WAR 和 UAR 均提升超过 13%。这些结果充分证明了 RLVR 在提升推理能力和泛化性能上的显著优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;149&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8bd3fe6b0d2d65935730b58b1f041cc492.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，R1-Omni 的一大亮点在于其透明性（推理能力）。通过 RLVR 方法，音频信息和视频信息在模型中的作用变得更加清晰可见。比如，在情绪识别任务中，R1-Omni 能够明确展示哪些模态信息对特定情绪的判断起到了关键作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「这种透明性不仅帮助我们更好地理解模型的决策过程，也为未来的研究提供了重要参考方向。未来，我们期待 R1-Omni 在更多复杂场景中发挥作用，为多模态任务的研究与应用开辟新的道路。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338400</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338400</guid>
            <pubDate>Thu, 06 Mar 2025 09:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>8 条 AI 编程指南</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;1. 合理选择开发工具：不同的 AI 编程工具有其各自的专长。对于复杂应用推荐使用 Cursor/Windsurf，轻量级应用开发选择 Bolt/Lovable，移动应用开发使用 Replit，UI 设计则可以使用 v0。&lt;/p&gt; 
&lt;p&gt;2. 完善项目上下文：要以 .md 文档形式详细说明项目信息，包括：产品需求文档（PRD）、技术栈说明、文件结构、前端开发规范和后端架构设计。这样能有效防止 AI 生成偏离预期的内容。推荐使用 CodeGuide 编写 AI 开发文档，它与各类 AI 工具都能良好配合。&lt;/p&gt; 
&lt;p&gt;3. 拆分任务逐步实现：不要期望 AI 能一次性完成 「构建一个 AirBNB 克隆版「 这样的大型任务。应该将项目分解为页面级任务，再把每个页面细分为组件级任务。记住 AI 一次最多能处理 3 个小任务。&lt;/p&gt; 
&lt;p&gt;4. 选择适合 AI 的技术栈：Claude Sonnet 3.5、GPT-4o、o3 和 o1 等 AI 模型在处理 React 和 Python 框架时表现出色。因此建议网页应用选用 NextJS、viteJS 和 Python，移动应用则使用 React Native（如果使用 Claude，SwiftUI 也是不错的选择）。&lt;/p&gt; 
&lt;p&gt;5. 善用项目模板：不要每次都从零开始，这样会浪费时间和资源。使用现成的项目模板（如 CodeGuide NextJS Starter Kit）可以快速搭建开发环境，提高效率。&lt;/p&gt; 
&lt;p&gt;6. 设定 AI 使用规范：通过规则文件来约束 AI 的行为，确保其遵循项目规范。可以创建 .cursorrules（项目规则）和 .windsurfrules 等文件来设定全局 AI 规则。&lt;/p&gt; 
&lt;p&gt;7. 组合多种工具优势：目前没有单一工具能完全满足 AI 开发的所有需求。建议使用 Perplexity 做研究，ChatGPT 语音做头脑风暴，CodeGuide 写文档，Firecrawl 做数据爬取，再配合其他 AI 编程工具来构建代码库。&lt;/p&gt; 
&lt;p&gt;8. 保持耐心和平和心态：与 AI 协作就像与 「外星智慧「 沟通，需要学习理解 AI 的语言（提示词工程）。虽然 AI 可能会出错或产生偏差，但保持耐心和专注，慢慢引导它按照你的意图工作。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2e701684197e228cc10e7f64da73fd944b6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fcj_zZZz%2Fstatus%2F1890078645089346038&quot; target=&quot;_blank&quot;&gt;https://x.com/cj_zZZz/status/1890078645089346038&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/336236&quot; target=&quot;news&quot;&gt;使用 Cursor 编程的 15 条经验建议&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338397</guid>
            <pubDate>Thu, 06 Mar 2025 09:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>消息称 Meta 正在测试首款内部 AI 训练芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fartificial-intelligence%2Fmeta-begins-testing-its-first-in-house-ai-training-chip-2025-03-11%2F&quot; target=&quot;_blank&quot;&gt;路透社&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息称，Meta 正在测试用于训练 AI 系统的内部芯片，作为减少对 Nvidia 等硬件制造商依赖的战略的一部分。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息人士透露，Meta 的芯片旨在处理特定于 AI 的工作负载，与台积电合作生产的，测试部署是在 Meta 完成芯片的首次「流片」后开始的。目前该公司正在试行该芯片的「小规模部署」，并计划在测试顺利的情况下扩大产量以供大规模使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8d9cf4d0ccb1197c434c008852d14c65a1.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 之前曾部署过定制的 AI 芯片，但仅用于运行模型，而不是训练模型。路透社指出，该公司的多项芯片设计工作曾因未能达到内部预期而被取消或缩减。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Meta 预计今年的资本支出将达到 650 亿美元，其中大部分将用于购买 Nvidia GPU。如果该公司通过转向内部芯片能够减少哪怕是一小部分成本，那么对其来说都是巨大的胜利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338393/meta-testing-first-in-house-ai-training-chip</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338393/meta-testing-first-in-house-ai-training-chip</guid>
            <pubDate>Thu, 06 Mar 2025 08:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>余承东预告：首款原生鸿蒙正式版手机下周发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;华为常务董事、终端 BG 董事长、智能汽车解决方案 BU 董事长余承东&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1100856704%2FPiavhsK1W%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;今日宣布&lt;/a&gt;&lt;/u&gt;：「首款搭载原生鸿蒙正式版的「想不到的产品」，下周见！」&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0312/161848_tDhG_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;余承东在视频中介绍：「去年 10 月，原生鸿蒙全面开启公测，目前已收到 400 万条用户反馈的优化建议、系统迭代了 30 多个版本、新增 150 多项功能特性，已有 2 万个鸿蒙原生应用和元服务上架，同时微信、抖音、支付宝、高德地图、京东等 App 下载量已超 200 万。」&lt;/p&gt; 
&lt;p&gt;余承东宣布，「原生鸿蒙正式版体验大有不同，流畅度大幅提升，带来了更安全的隐私保护，还有全新小艺在盘古、DeepSeek 双模型加持下，轻松应对各种复杂的推理场景，更高效、更智慧，情感也更加丰富。」&lt;/p&gt; 
&lt;p&gt;他表示，「&lt;strong&gt;下周，首款搭载原生鸿蒙正式版的手机就要来了，华为终端也将全面进入原生鸿蒙时代。&lt;/strong&gt;」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338389</guid>
            <pubDate>Thu, 06 Mar 2025 08:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>青云科技关于 KubeSphere 中 Docker 组件合规性的声明</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在云原生技术蓬勃发展的今天，合规性与技术透明度已成为企业级产品的核心基石。作为始终践行「开放透明」理念的开源践行者，青云科技始终将用户权益与技术合规置于首位。为响应社区关切并明确技术责任边界，现正式发布《青云科技关于 KubeSphere 中 Docker 组件合规性的声明》，以全方位保障您的数字化转型之旅安全可信。&lt;/p&gt; 
&lt;h2&gt;青云科技关于 KubeSphere 中 Docker 组件合规性的声明&lt;/h2&gt; 
&lt;p&gt;北京青云科技集团股份有限公司（以下简称&quot;青云科技&quot;或&quot;我司&quot;）始终秉承开放透明的合作原则，致力于为用户提供安全、合规的云原生产品解决方案。为保障用户权益并明确产品责任边界，现就我司 KubeSphere 容器管理平台（以下简称&quot;本平台&quot;）的产品信息与 Docker 组件使用合规性作以下官方声明：&lt;/p&gt; 
&lt;h3&gt;一. 产品定位与技术架构&lt;/h3&gt; 
&lt;p&gt;KubeSphere 容器管理平台是由青云科技自主研发的&lt;strong&gt;企业级容器集群调度与管理平台。&lt;/strong&gt; 本平台基于开源 Kubernetes 技术构建，专注于为全球用户提供高效稳定的容器化应用部署、运维及全生命周期管理服务，适用于混合云、异构多云及边缘计算等复杂场景。&lt;/p&gt; 
&lt;h3&gt;二. 适用范围&lt;/h3&gt; 
&lt;p&gt;本文就 KubeSphere 容器管理平台中 Docker 组件合规性的声明适用于以下 KubeSphere 产品版本形态：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KubeSphere 开源版。&lt;/li&gt; 
 &lt;li&gt;KubeSphere 企业版（包含更名前的青云 QKCP）。&lt;/li&gt; 
 &lt;li&gt;青云容器平台（可信版）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;三. 版权与 Docker 组件合规声明&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 平台组件构成说明&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;本平台属服务器端软件，其技术实现与交付内容严格遵循开源协议规范。&lt;/li&gt; 
 &lt;li&gt;我司提供的软件安装包及最终用户运行环境中，不包含 Docker Desktop 软件及通过 Docker Desktop 引入的任何组件。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Docker 组件使用合规性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;本平台软件安装包内集成的 &lt;strong&gt;Docker Community Edition (docker-ce) 与 Docker Engine&lt;/strong&gt;，均直接从 Docker 官方渠道所列单独路径下载。依据 Docker 官方网站上该路径所含版权声明（可访问链接 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.docker.com%2Fengine%2F&quot; target=&quot;_blank&quot;&gt;https://docs.docker.com/engine/&lt;/a&gt; 获取详细信息），&lt;strong&gt;其版本声明明确标注为&quot;Docker Engine is licensed under the Apache License, Version 2.0.&quot;。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;我司对上述组件的集成行为完全符合 Apache License 2.0 协议要求，且未通过 Docker Desktop 途径获取相关技术组件。因此，&lt;strong&gt;不受&quot;for commercial use of Docker Engine obtained via Docker Desktop&quot;所述范围的限制，其行为完全符合 Docker 官方规定。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 用户自主选择权&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;用户是否使用平台软件安装包内集成提供的 Docker 系列组件，&lt;strong&gt;取决于用户自身，而非必要使用。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;我司提供 Docker Community Edition (docker-ce) 与 containered 等多种容器运行时解决方案，用户可根据实际业务需求选取使用。同时我司提供相关的架构咨询与交付服务。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在我司提供的产品之外，若用户因自行在环境中安装 Docker Desktop 产生合规争议，需对其个人行为负相应的法律责任。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;四. 用户支持与协作&lt;/h3&gt; 
&lt;p&gt;青云科技始终将用户信任置于首位。如您对上述声明内容存有任何疑问，或需进一步了解技术细节、探讨合作方案，欢迎通过以下方式联系我司专业团队：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;服务热线：400-8576-886&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E5%AE%98%E6%96%B9%E9%82%AE%E7%AE%B1%EF%BC%9Asupport%40kubesphere.cloud&quot; target=&quot;_blank&quot;&gt;官方邮箱：support@kubesphere.cloud&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我司将严格履行技术合规责任，持续为全球用户提供中立安全可靠的云原生基础设施服务。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附注：&lt;/strong&gt; 本文内容最终解释权归北京青云科技集团股份有限公司所有。&lt;/p&gt; 
&lt;p&gt;&amp;gt; 本文由博客一文多发平台 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenwrite.cn%3Ffrom%3Darticle_bottom&quot; target=&quot;_blank&quot;&gt;OpenWrite&lt;/a&gt; 发布！&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4197945/blog/17884779</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4197945/blog/17884779</guid>
            <pubDate>Thu, 06 Mar 2025 08:17:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>原字节跳动 AI 大将骆怡航加盟生数科技，出任 CEO</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1642634100%2FPiaXvECdR%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;根据新浪科技的独家报道&lt;/a&gt;&lt;/u&gt;，原字节跳动 AI 大将、火山引擎 AI 应用产品线一号位&lt;strong&gt;骆怡航已于近日加入生数科技，担任 CEO 一职，将全面负责公司研发、产品、商业化及团队管理工作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;骆怡航毕业于清华大学自动化系，在云计算及 AI 领域有超过十年的工作经验，拥有扎实的技术背景、产业理解和商业化经验，在加入生数科技前，骆怡航担任字节跳动火山引擎 AI 应用产品线一号位，向火山引擎总裁汇报，全权负责产品线的战略、产品和商业化。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;576&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0312/161018_oYWJ_2720166.png&quot; width=&quot;1058&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，该条产品线由骆怡航从 0 组建，涵盖多个传统 AI、大模型及大模型应用产品，管理规模数百人，是火山引擎当前的重点产品线之一。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，生数科技发布视频大模型 Vidu 2.0，视频生成速度突破 10 秒以内，成本降至不到行业平均水平的一半。据悉，Vidu 用户已覆盖 200 多个国家和地区，深受不同职业和年龄层用户的喜爱。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0312/160925_dgaK_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在生数科技内部人士看来，骆怡航的加入，将有助于公司加快技术转化、商业化进程，推动 Vidu 在影视、动漫、广告、教育、游戏、文旅等领域的深度落地。此外，生数科技将迈入规模化和全球化发展阶段，有成熟大厂管理经验背景的高管也将有助于生数科技完善组织架构，提升团队战斗力。&lt;/p&gt; 
&lt;p&gt;此前，生数科技已引入商业化副总裁王川、品牌市场负责人刘婷婷等人。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338384</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338384</guid>
            <pubDate>Thu, 06 Mar 2025 08:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>PHP 远程代码执行高危漏洞 CVE-2024-4577 正被大规模利用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Bleeping Computer &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Fcritical-php-rce-vulnerability-mass-exploited-in-new-attacks%2F&quot; target=&quot;_blank&quot;&gt;近日报道称&lt;/a&gt;&lt;/u&gt;，影响 Windows 系统的 PHP 远程代码执行漏洞 CVE-2024-4577 正被大规模利用。&lt;/p&gt; 
&lt;p&gt;该漏洞虽然已经于 2024 年 6 月修复，但攻击者依然利用该漏洞，在全球范围内发起广泛攻击，控制尚未及时修复的系统。&lt;/p&gt; 
&lt;p&gt;据了解，这是一个 PHP-CGI 参数注入漏洞，影响以 CGI 模式运行的 Windows PHP 安装，成功利用该漏洞的攻击者可在未经授权的情况下执行任意代码，导致系统完全被控制。&lt;/p&gt; 
&lt;p&gt;Cisco Talos 发现，自 2025 年 1 月起，未知攻击者利用该漏洞攻击日本组织，窃取凭证信息外，还尝试建立持久性、提升权限至 SYSTEM 级别，并部署「TaoWu」Cobalt Strike 工具包。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f77fef00b5fdee3333f1c4a087d2ca0c71.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;GreyNoise 报告称，攻击者已将目标扩展至全球，美国、新加坡、日本等国成为重灾区。2025 年 1 月，其全球蜜罐网络（GOG）检测到 1089 个独特 IP 地址尝试利用该漏洞。&lt;/p&gt; 
&lt;p&gt;GreyNoise 数据显示，网络上至少存在 79 款利用该漏洞的工具，在 2025 年 2 月，检测到多国网络中的利用尝试激增，表明攻击者正在自动化扫描易受攻击的目标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338377/critical-php-rce-vulnerability</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338377/critical-php-rce-vulnerability</guid>
            <pubDate>Thu, 06 Mar 2025 07:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ThingsPanel 开源 MCP 服务器：连接物联网与 AI 的桥梁</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#111111; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;我们很高兴地宣布 ThingsPanel MCP 正式开源。这是一个基于 Model Context Protocol (MCP) 的服务器实现，旨在为 ThingsPanel 物联网平台提供 AI 模型集成能力。&lt;/p&gt; 
&lt;h2&gt;项目简介&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;ThingsPanel MCP 是一个轻量级的中间件，它使得 AI 模型（如 Claude、GPT 等）能够以标准化的方式与物联网设备进行交互。通过实现 Model Context Protocol，它提供了一个安全、可控的接口，使 AI 模型能够：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查询和管理物联网设备&lt;/li&gt; 
 &lt;li&gt;获取设备历史数据&lt;/li&gt; 
 &lt;li&gt;处理设备告警&lt;/li&gt; 
 &lt;li&gt;执行设备控制命令&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;技术特点&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;标准化接口&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;完整实现 Model Context Protocol 规范&lt;/li&gt; 
   &lt;li&gt;支持 stdio 和 SSE 传输方式&lt;/li&gt; 
   &lt;li&gt;RESTful API 设计&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;模块化架构&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;核心功能模块化设计&lt;/li&gt; 
   &lt;li&gt;插件式工具扩展&lt;/li&gt; 
   &lt;li&gt;支持按需启用/禁用功能&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;开发友好&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;完整的类型提示&lt;/li&gt; 
   &lt;li&gt;异步 I/O 支持&lt;/li&gt; 
   &lt;li&gt;详细的 API 文档&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;部署灵活&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;提供 Docker 支持&lt;/li&gt; 
   &lt;li&gt;支持环境变量配置&lt;/li&gt; 
   &lt;li&gt;最小化外部依赖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;适用场景&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;项目特别适合以下场景的技术团队：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;需要为物联网平台添加 AI 能力&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;自然语言设备控制&lt;/li&gt; 
   &lt;li&gt;数据分析和可视化&lt;/li&gt; 
   &lt;li&gt;智能告警处理&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;正在开发 AI 助手，需要物联网集成能力&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;设备状态查询&lt;/li&gt; 
   &lt;li&gt;历史数据分析&lt;/li&gt; 
   &lt;li&gt;设备控制和自动化&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;构建智能运维系统&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;设备异常检测&lt;/li&gt; 
   &lt;li&gt;预测性维护&lt;/li&gt; 
   &lt;li&gt;自动化运维&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;快速上手&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;安装&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install thingspanel-mcp&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;配置&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span style=&quot;color:#e36209&quot;&gt;export&lt;/span&gt; THINGSPANEL_API_KEY=&lt;span style=&quot;color:#032f62&quot;&gt;&quot;您的 API 密钥&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;运行&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;thingspanel-mcp&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;技术栈&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;语言：Python 3.8+&lt;/li&gt; 
 &lt;li&gt;传输协议：Model Context Protocol&lt;/li&gt; 
 &lt;li&gt;API 风格：RESTful&lt;/li&gt; 
 &lt;li&gt;容器化：Docker &amp;amp; Docker Compose&lt;/li&gt; 
 &lt;li&gt;测试框架：pytest&lt;/li&gt; 
 &lt;li&gt;代码质量：mypy, black, isort&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;开源信息&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;许可证：Apache License 2.0&lt;/li&gt; 
 &lt;li&gt;仓库地址：https://gitee.com/ThingsPanel/thingspanel-mcp &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;文档：完整的英文和中文文档&lt;/li&gt; 
 &lt;li&gt;贡献指南：提供详细的开发者指南&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;后续规划&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;我们计划在保持项目稳定性的同时，逐步添加以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;批量设备操作支持&lt;/li&gt; 
 &lt;li&gt;设备分组管理&lt;/li&gt; 
 &lt;li&gt;数据统计分析接口&lt;/li&gt; 
 &lt;li&gt;Webhook 支持&lt;/li&gt; 
 &lt;li&gt;更多第三方集成&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;参与贡献&lt;/h2&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;我们欢迎社区贡献，无论是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;报告问题&lt;/li&gt; 
 &lt;li&gt;提交功能建议&lt;/li&gt; 
 &lt;li&gt;改进文档&lt;/li&gt; 
 &lt;li&gt;提交代码&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;技术支持&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Issues：技术问题讨论&lt;/li&gt; 
 &lt;li&gt;项目文档：使用指南和 API 文档&lt;/li&gt; 
 &lt;li&gt;示例代码：标准用例实现&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;这个项目的目标是为物联网开发者提供一个实用、可靠的工具，帮助他们更容易地将 AI 能力集成到物联网应用中。我们注重代码质量和文档完整性，希望能为社区提供一个值得信赖的解决方案。&lt;/p&gt; 
&lt;p style=&quot;color:#111111; margin-left:0; margin-right:0; text-align:start&quot;&gt;欢迎各位开发者试用和反馈，一起推动项目进步！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338376/thingspanel-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338376/thingspanel-mcp</guid>
            <pubDate>Thu, 06 Mar 2025 07:31:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>为什么说 JSON 不一定是 LLM 结构化输出的最佳选择？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 在使用大语言模型时，如何在保证输出质量的同时降低成本？在众多数据输出格式中，究竟应该如何选择？&lt;/p&gt; 
 &lt;p&gt;我们今天为大家带来的文章中，作者通过实际测试给出建议：在某些场景下，相比广泛使用的 JSON 格式，不妨考虑一下其他数据格式，做一些测试，挑选出既能控制成本又能保证稳定性和速度的最佳选项。&lt;/p&gt; 
 &lt;p&gt;文章通过对比 TSV、CSV、Columnar JSON、YAML、TOML 和 JSON 六种格式，从 token 使用量、响应时间和实用性三个维度进行了深入分析。作者指出，没有一种格式能在所有场景下都表现最佳。文章详细分析了每种格式的优劣势，并提供了一个实用的投资回报率计算方法，帮助读者评估是否值得将现有系统从 JSON 转换为其他格式。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | David Gilbertson&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当要求大语言模型（LLM）输出结构化数据时，所采用的格式会对结果产生比较大的影响。本文对比了六种不同的格式，评估考察了它们的处理速度、tokens 消耗以及各自的限制。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 简要说明&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;JSON 虽然是多数人的首选，但它对 tokens 的消耗极大。处理相同数据时，它可能需要其他格式两倍的 tokens。&lt;/p&gt; 
&lt;p&gt;需要注意的是，没有一种格式能在所有情况下都表现最佳，以下是一个决策指南：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7ec39896fc3d3679ce7a11780ae2500f61e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（如果你好奇为何没有提及 XML，那是因为我有个个人目标：50 年不碰 XML ------ 只剩下 4 年就能达成了！）&lt;/p&gt; 
&lt;p&gt;我将在下文中详细解释这些格式选择，并探讨每种格式的局限性。但在此之前，先让我们对比一下它们的 token 使用情况和速度。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 token 使用情况&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;探究 JSON 之外的其他选项，主要目的是为了减少所需的 tokens 数量，这样做可以降低运营成本并缩短响应时间。&lt;/p&gt; 
&lt;p&gt;为了对这些格式进行有效比较，我们将基于它们表示特定数据集所需的 token 数量来进行评估。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 比较框架&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本次比较我将使用一段文本作为输入，该文本包含了关于欧盟每个国家的一段信息。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8e50ab87cb9683306d67a1d3a1c4b5339a0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我将要求 LLM 将这段普通文本转换成结构化数据，其中每个国家都是一条记录，每条记录包含国家名称、领导人姓名、领导人出生日期、领导人性别、人口数量和领土面积等键/值对。&lt;/p&gt; 
&lt;p&gt;我将针对每种结构化输出格式执行这一操作，并检查六种格式的输出结果是否相同。&lt;/p&gt; 
&lt;p&gt;感兴趣的朋友，可以在这个 gist[1] 中查看完整的代码。对于不太感兴趣的朋友，这里展示了我如何为每种格式定义 name、可选的 hint 以及 parser（这里将所有数据解析成 Pandas DataFrame）：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c0a13f96703898de6c7ca324a996d388a64.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLM（本次测试使用的是 gpt-4o-mini）能够以不同格式准确返回相同的数据。当然，如果数据更复杂，或者使用的 LLM 不够强大，结果可能就不会这么精确了。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 比较结果&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;下表展示了使用不同格式表示数据所需的 tokens 数量。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-22079d7588db10f57fdd85fd544a99231d5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;JSON 所需的 tokens 数量是 TSV 的两倍。这个差异不容小觑。设想一下，如果你在某个 API 的价格页面上看到，选择 JSON 格式的数据需要支付 1 美元，而 TSV 格式只需 0.5 美元，YAML 格式则是 0.8 美元。&lt;/p&gt; 
&lt;p&gt;当然，这些结果仅针对我们的示例数据。展示本图表的目的并非要让你认为 JSON 在所有情况下都会大量消耗 tokens，而是让你相信值得用其他格式测试自己的数据。&lt;/p&gt; 
&lt;p&gt;接下来，我们来看看这些格式的响应时间。&lt;/p&gt; 
&lt;p&gt;尽管 JSON &quot;只&quot;需要两倍于 TSV 的 tokens ，但其响应时间通常比 TSV 慢四倍。我原本以为 token 数量与响应时间之间的关系是近似线性的 ------ 接近 O(n)，因此如此夸张的响应时间出乎我的意料，我建议我们可以将这种现象的时间复杂度设为 O(my)。&lt;/p&gt; 
&lt;p&gt;将数据结构化输出的响应时间还是蛮重要的，所以赶紧测试吧。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 局限性与考虑因素&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;如果这些格式都同样可靠和灵活，那么结论就会很简单：使用 TSV。但事实并非如此，所以让我们对每一种格式进行更深入的了解。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 TSV&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在表示表格数据时，TSV 和 CSV 格式颇为相似，区别在于 TSV 使用制表符分隔每一行的数据，而 CSV 则采用逗号。如果数据中本身就包含逗号或制表符，那么这些值就需要用双引号括起来，这时两种格式的 tokens 使用差异才会显现。&lt;/p&gt; 
&lt;p&gt;由于制表符在数据中出现的频率低于逗号，因此 TSV 在大多数情况下使用的分隔符数量会少于 CSV。&lt;/p&gt; 
&lt;p&gt;在解析数据时，TSV 与 CSV 相比 JSON，在纯 Python 环境下解析起来略显复杂。虽然可以利用 Python 内置的 csv 模块进行解析，但使用 Pandas 库会更加便捷。在其他编程语言中，解析这两种格式要么需要编写更多代码，要么得依赖第三方库。&lt;/p&gt; 
&lt;p&gt;如果数据中不含换行符，TSV 可以轻松地逐行解析。&lt;strong&gt;因此，若想从 LLM 流式传输响应数据并&lt;/strong&gt; 实时&lt;strong&gt;处理每一行数据，TSV（以及 CSV）都是不错的选择。虽然 TOML、YAML 和 JSON 也能实现类似功能，但处理起来会更加繁琐。&lt;/strong&gt; 另外，本文尚未测试的 NDJSON 也是一个值得考虑的选项。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 CSV&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如前文所述，CSV 格式的挑战在于逗号在数据中较为常见，这可能会导致两种情况：要么是需要更多的 tokens 来处理这些逗号，要么是 LLM 在处理时未能正确进行转义，从而产生错误的数据。因此，如果你的数据可能包含逗号，最好避免使用 CSV，或者设计一个详尽的提示词，并实施有效的评估流程，以便准确衡量其可靠性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对于 TSV 和 CSV 两种格式，你需要用那些可能包含特殊字符（如逗号、制表符、换行符和双引号）的数据来测试你的系统配置。这样，你才能确保系统能够正确处理这些特殊情况。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 Columnar JSON&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Columnar JSON 并不是一个常见的技术术语；我之所以将它纳入这次比较，是因为我很好奇它的 tokens 使用效率如何。&lt;/p&gt; 
&lt;p&gt;可能有些人还不清楚 Columnar JSON 是什么样的，下面就是前文提到的国家数据所对应的 Columnar JSON 格式：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9428ef8b78e0bdb835baea9f4cda42d717f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在所有格式中，Columnar JSON 的直观性最差。但是，由于其结构特点，每个字段名只会出现一次，而不是每条记录都重复，这样就能节省 tokens。&lt;/p&gt; 
&lt;p&gt;我注意到，有时 LLM 能够理解&quot;Columnar JSON&quot;的含义，但有时候需要一些额外的提示词，例如：&quot;应以列名作为键名，对应的列内容以列表的形式组织呈现&quot;。&lt;/p&gt; 
&lt;p&gt;要解析 columnar JSON，你可以这样将其传递给 Pandas 处理：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8742900bd0a0c9bd237f20e2e53833ad8be.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与 CSV 和 TSV 不同，columnar JSON 支持嵌套的数据结构，因此它非常适合表示那些某些字段具有复杂结构的记录列表。&lt;/p&gt; 
&lt;p&gt;这三种格式------TSV、CSV、columnar JSON------仅适用于表示表格数据，即以记录列表为核心的结构。它们都不适合用来表示像配置文件这样的单一 top-level object（译者注：指在结构化数据格式（如 JSON/YAML/TOML）中，最外层定义的单一根对象，通常作为整个数据结构的入口点。）。而接下来的三种格式（YAML、TOML、JSON）则更为灵活多变。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.4 YAML&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;YAML 能够返回一个 top-level list（译者注：指在结构化数据格式中，最外层直接定义为列表结构而非对象。），但我注意到，某些 LLM 更倾向于生成一个 top-level object。因此，在给出提示词时，我们需要明确指出，以确保 LLM 按照统一的格式返回数据。&lt;/p&gt; 
&lt;p&gt;我还遇到了一个问题，即 LLM 在返回字符串值时，格式可能会不一致。在某些情况下，这可能无关紧要，但 YAML 有五种不同的方式来表示字符串，而其中只有一种能够正确解析转义序列（例如\t, \u03B1）。因此，如果你的数据中包含转义序列，那么最好明确要求 LLM 使用双引号来定义字符串。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;YAML 相较于 JSON，存在更多的&quot;陷阱&quot;和注意事项。建议你深入了解这些潜在的问题，而不是盲目地期待 LLM 能够自动正确地格式化 YAML。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了解析 YAML，你需要安装一个第三方库。我个人使用的是 pyyaml，这是一个无依赖的库。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.5 TOML&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;TOML 是在此场景中唯一不支持 top-level list 的格式，因为它的设计初衷是作为一种配置文件格式。因此，若想用 TOML 来表示记录列表，就必须将这些记录包含在一个 top-level object 内，并告诉 LLM 你想在这个对象中调用什么键。&lt;/p&gt; 
&lt;p&gt;TOML 在使用上通常会比 YAML 需要更多的 token，因为 TOML 要求所有的字符串值都必须用引号括起来。&lt;/p&gt; 
&lt;p&gt;在解析方面，如果你的 Python 版本是 3.11 或以上，那么内置的 TOML 解析器[2]就可以直接使用。如果不是，那就需要安装 tomlkit 或类似的库来处理。&lt;/p&gt; 
&lt;p&gt;TOML 的普及度不及 YAML，你可能会担心 LLM 在处理 TOML 格式时是否会遇到难题。但在我所使用的顶级 LLM 中，并没有发现明显的格式处理问题。我认为，TOML 相较于 YAML 的简洁性在一定程度上弥补了这一普及度差距。而且，YAML 有多种方式可以表达相同的数据，这可能会降低 LLM 的确定性，使得两种格式的可靠性相差无几。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根据我的个人经验，TOML 和 YAML 都可能出现错误，但这些错误通常可以通过更精确的提示词来解决。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;关于 YAML 中的字符串和转义序列的问题，TOML 也同样存在。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;总体而言，TOML 和 YAML 非常相似，TOML 需要更多的 token，不支持 top-level lists，但对于使用 Python 3.11 或以上版本的用户来说，不需要额外的解析库。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.6 JSON&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;关于 JSON，其实没什么特别需要强调的。它之所以能成为默认格式，是因为它用途广泛、易于解析，而且出错率低。只是它包含了大量的引号、逗号、冒号和换行符，这些都增加了 token 的数量，这一点稍显遗憾。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;值得注意的是，如果你想要使用 LLM 服务商提供的&quot;结构化数据模式&quot;，或者使用像 Guardrails[3]、Outlines[4] 这样的结构化工具，JSON 往往是唯一的选择。但我认为这种情况会随着时间的推移而有所改变。随着越来越多的基于 LLM 的应用投入实际使用，开发者会开始关注如何减少 token 使用等优化措施，LLM 服务商也会通过支持更多结构化数据格式来满足这一需求。&lt;/p&gt; 
&lt;p&gt;理想的情况是，LLM 服务商能够调整模型，使其能够可靠地处理多种格式的数据，并在结构化数据模式中提供这些格式作为可选项。&lt;/p&gt; 
&lt;p&gt;这里有一个注意事项：对于有关 LLM 在输出特定格式时的可靠性方面的旧建议，我们应该保持谨慎。正如 OpenAI 在 2024 年 8 月的一篇博客文章中所提到的[5]，GPT-4 的早期版本在处理复杂的 JSON 测试时的正确率仅为 35%，而较新版本的 GPT-4 正确率则高达 85%。这在 GPT-4 系列中是一个巨大的飞跃。&lt;/p&gt; 
&lt;p&gt;这一点对于使用某些特殊功能或软件包的人来说尤为重要，这些功能或软件包可能会基于一年或更久之前的假设或证据来强制输出结构化数据。你可能并不需要这些功能或软件包，它们可能会迫使你使用 JSON，而实际上你可以选择更经济、更快捷的格式。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 实际应用&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在理论层面这些格式各有优势，但假设你已经有了一套使用 JSON 的结构化数据处理系统，并且运行得很顺畅。你知道 TSV 格式也能适用于你的数据，那么是否有必要进行格式转换呢？&lt;/p&gt; 
&lt;p&gt;如果你关注的是速度------因为人们需要等待 LLM 生成 token，那么你需要评估等待时间的价值，这部分在这里不展开讨论。&lt;/p&gt; 
&lt;p&gt;但如果你只是在后台运行一个进程，这个问题就简单多了。举例来说，我们可以设定以下假设条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;你的时间成本是每天 1000 美元&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;将现有系统从 JSON 转换为 TSV 需要半天时间&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;输出 token 的费用是每百万 0.60 美元&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;使用 TSV 可以减少 50% 的 token 使用量&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;你希望一年内收回投资&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们可以用一个小 Python 脚本来计算这些数值：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f69e9075bdd7f5c7bebe4b594c36a14407d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;根据计算，如果你现在每天生成大约 4,566,210 个 JSON token，一年后就能实现收支平衡。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当然，你应该根据自己的实际情况来调整这些数值，但以下基准数据可供你参考。如果你每天只生成几千个结构化数据的 token（并且不介意速度），那么盲目调整数据格式的性价比极低。但如果你每天需要处理数千万个 token，那么探索其他格式绝对是一个划算的决定。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 总结&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;选择默认的 JSON 格式确实很有吸引力，因为它灵活、稳定且解析起来简单。但相对而言，它的处理速度较慢，成本也更高。因此，不妨考虑一下其他数据格式，做一些测试，挑选出既能控制成本又能保证稳定性和速度的最佳选项。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;David Gilbertson&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;I like machine learning stuff.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你在实际项目中最常用哪种数据格式？遇到过哪些意想不到的问题？欢迎分享经验👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgist.github.com%2Fdavidgilbertson%2Ffcabb55478b4a4e1537a706f808b8b09&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/davidgilbertson/fcabb55478b4a4e1537a706f808b8b09&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.python.org%2F3%2Flibrary%2Ftomllib.html&quot; target=&quot;_blank&quot;&gt;https://docs.python.org/3/library/tomllib.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fguardrails-ai%2Fguardrails&quot; target=&quot;_blank&quot;&gt;https://github.com/guardrails-ai/guardrails&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fdottxt-ai%2Foutlines&quot; target=&quot;_blank&quot;&gt;https://github.com/dottxt-ai/outlines&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-structured-outputs-in-the-api%2F&quot; target=&quot;_blank&quot;&gt;https://openai.com/index/introducing-structured-outputs-in-the-api/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdavid-gilbertson.medium.com%2Fllm-output-formats-why-json-costs-more-than-tsv-ebaf590bd541&quot; target=&quot;_blank&quot;&gt;https://david-gilbertson.medium.com/llm-output-formats-why-json-costs-more-than-tsv-ebaf590bd541&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17883527</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17883527</guid>
            <pubDate>Thu, 06 Mar 2025 07:28:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>逆向分析 Github Copilot，探索代码补全能力的实现细节</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;GitHub Copilot 是一种基于机器学习的代码自动补全工具，它使用来自 GitHub 的大量代码作为训练数据，并结合 OpenAI 的语言模型来生成代码。Copilot 还能学习用户的编码习惯，根据上下文推断出正确的代码片段。&lt;/p&gt; 
&lt;p&gt;为了探索其 VSCode 插件的实现，我们进行了以下逆向工程。&lt;/p&gt; 
&lt;h2&gt;准备工作&lt;/h2&gt; 
&lt;p&gt;由于 Copilot 没有开源，我们需要进行一些逆向的准备。首先，找到 VSCode 插件的安装目录，拿到经过压缩混淆的 extension.js。然后，通过分割 webpack_modules、识别模块依赖、优化压缩后的语法和 require 的模块 id 取名等步骤，对代码进行逆向处理。&lt;/p&gt; 
&lt;h2&gt;入口分析&lt;/h2&gt; 
&lt;p&gt;入口文件的模块 id 是 91238，经过手动优化操作，可以大致还原其原始样貌。在 VSCode 的 active 函数中，copilot 做了大量初始化工作，并将各个模块的示例注册到 context 中。&lt;/p&gt; 
&lt;h2&gt;代码提示入口逻辑&lt;/h2&gt; 
&lt;p&gt;代码提示逻辑在 registerGhostText 中注册，主要通过 InlineCompletionItemProvider 实现。其核心逻辑包括判断用户是否关闭了 InlineSuggestEnable、document 是否在处理白名单内、用户是否取消了输入等，若不满足条件则提前 return，不进行代码提示。然后调用 getGhostText 方法获取 texts，并通过 completionsFromGhostTextResults 拿到最终的 completions。&lt;/p&gt; 
&lt;h2&gt;getGhostText 核心逻辑&lt;/h2&gt; 
&lt;p&gt;getGhostText 是获取提示代码的核心方法，其逻辑包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;提取 Prompt：通过 extractprompt.extractPrompt 获取 prompt 对象。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;边界判断：判断是否包含在 .copilotignore 里的文件、上下文是否太小、用户是否已经取消等三种情况。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;二级缓存：保存上一次的 prefix 和 suffix，若当前请求的 prefix 和 suffix 与之前的一样，则读取缓存内容。若未命中缓存，计算当前的 prompt 是否在缓存范围内，copilot 采取 LRU 缓存策略，默认缓存 100 条。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;真正发起请求：设置 Debounce 时延，判断 contextualFilterScore 是否达到阈值，最后向后台发送 prompt 请求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-578f48c2e81b288fb7d2d52e2fac1803777.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;prompt 的组成&lt;/h2&gt; 
&lt;p&gt;prompt 由多种类型组合而成，包括 BeforeCursor、AfterCursor、SimilarFile、ImportedFile、LanguageMarker、PathMarker 等。不同类型的优先级通过 Priorities 辅助类设置，如 highSnippetPriority &amp;gt; beforeCursorPriority &amp;gt; importedFilePriority &amp;gt; lowSnippetPriority &amp;gt; pathMarkderPriority &amp;gt; languageMarkerPriority。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-49d262082d2bb695078a8c544ed9f9b431b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;抓包实验&lt;/h2&gt; 
&lt;p&gt;通过抓包实验，可以看到在 Copilot 发起的请求中，prompt 包含了 Path Marker 和 BeforeCursor 两个部分。如果代码相关性够高，还会生成对应的 snippet。&lt;/p&gt; 
&lt;h2&gt;小结&lt;/h2&gt; 
&lt;p&gt;从 Copilot 中可以学到以下核心思想：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;对于编辑器输入的边界判断，包括太少、太多、取消等等很多场景齐全的考虑&lt;/li&gt; 
 &lt;li&gt;缓存思想，利用多级缓存策略保护后台，模型运算本身就是一件昂贵的事情&lt;/li&gt; 
 &lt;li&gt;prompt 的设计，不仅仅包含了上下文代码，在文件解析、编辑器打开的相关代码上还做了很多&lt;/li&gt; 
 &lt;li&gt;利用简单的 Jaccard 算法计算分词后的文本相似度，能够快速决策出当前上下文相关的 snippet&lt;/li&gt; 
 &lt;li&gt;实验特性，在 Copilot 中，大量的参数、优先级、设置字段都是通过实验来控制的，有一套完整的监控上报体系，帮助 Copilot 去调整这些参数，以达到更好的效果&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmengjian-github%2Fcopilot-analysis&quot; target=&quot;_blank&quot;&gt;https://github.com/mengjian-github/copilot-analysis&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338373</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338373</guid>
            <pubDate>Thu, 06 Mar 2025 07:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Anthropic CEO：未来 3-6 个月内，90% 的代码将由 AI 编写</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Anthropic 首席执行官达 Dario Amodei 在 U.S. Foreign Relations Committee (CFR) 上&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.aibase.com%2Fnews%2F16219&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，他认为在未来 3 到 6 个月内，90% 的代码将由 AI 编写；在 12 个月后，几乎所有的代码都可能由 AI 生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不过他也补充称，虽然这一趋势可能听起来令人担忧，但程序员在定义所需功能、应用程序设计和决策方面仍将发挥关键作用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Amodei 表示，虽然人类程序员的参与仍将必不可少，但 AI 将逐渐承担许多人类的任务。他鼓励重新评估「有用」和「无用」的概念，并认为人类的生活仍将有意义，而 AI 将带来新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;433&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1d6e1707a9e7f798d77cff8849380c0e52.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在被 CFR 主席 Mike Froman 问及关于「DeepSeek」是否可以被视为「Sputnik moment」时。Amodei 则认为，DeepSeek 并没有什么不寻常之处，只是成本降低曲线上的又一个数据点。他强调，人人都能编程的未来正在迅速到来。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，OpenAI 首席执行官 Sam Altman 也在播客中分享了他对编程未来的看法。他认为，编程方法将在未来五到十年内发生重大变化，许多人已经使用自然语言进行编程，逐渐淘汰传统的编码方法。Altman 开玩笑称，目前很少有人通过写代码来编程，这意味着编程的定义和所需技能将发生巨大变化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338372/anthropic-ceo-ai-will-be-writing-90-of-code-in-3-6-months</guid>
            <pubDate>Thu, 06 Mar 2025 07:09:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里巴巴董事局主席蔡崇信：AI 开源开放将让中小企业受益</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 12 日上午，在新加坡举办的一场论坛中，阿里巴巴集团董事长蔡崇信分享了对 AI 开源开放的看法。他说，开源的力量在于令中小企业和创业者低成本使用 AI，未来的应用繁荣将受益于今天的开源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;「技术进步的意义不在于中国是否拥有比美国更好的 AI，而是在于开源能够普惠地帮助人们掌握 AI 的力量」，蔡崇信表示，AI 不是大企业的专属游戏，中小企业将受益于开源开放，未来应用繁荣将正是今天开源的结果。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在去年 11 月的 2024 年世界互联网大会乌镇峰会期间，阿里巴巴 CEO 吴泳铭在互联网企业家论坛上表示，阿里巴巴目前已经发布了超过 100 个开源模型，累计下载量超过 4000 万次。基于「通义千问」模型进行二次开发的衍生模型数量已突破 7.8 万个，活跃开发者超过 800 万。&lt;/p&gt; 
&lt;p&gt;据其介绍，目前已有超过 30 万家企业接入通义大模型，利用 AI 技术重塑代码开发、药物研发、生产制造等多个行业。吴泳铭认为，行业「并不需要」众多的基础大模型，而是需要针对不同规模、不同领域的开源模型来满足市场需求。&lt;/p&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/337397&quot; target=&quot;news&quot;&gt;阿里通义千问大模型登顶全球开源社区榜首&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333071&quot; target=&quot;news&quot;&gt;全球开源大模型前十均为阿里通义千问衍生模型&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338371</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338371</guid>
            <pubDate>Thu, 06 Mar 2025 07:08:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>上海徐汇：最高奖励 3000 万元，加快培育科技领军企业</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海《徐汇区关于加快培育科技领军企业的实施意见》已发布。该，意见自 2025 年 2 月 24 日起试行，试行期二年。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《实施意见》明确了 10 个支持方向：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.支持高能级企业集聚发展。引导企业扩大投资、归集核心职能，招引一批主营业务突出、竞争优势明显的高能级企业。加快吸引和促进符合区域产业发展导向的高能级企业，经综合评估，可给予最高 1000 万元的一次性支持；对行业影响力大、专业能力强、竞争优势明显的企业，经综合评估，可给予不超过 3000 万元的奖励。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2.大力引进优质企业。发挥企业「标杆」导向作用，引进一批核心技术能力强、引领产业发展集聚、市场占有率高的高成长性企业。加快吸引和促进符合区域产业发展导向的高成长企业、潜力企业等，经综合评估，可给予最高 500 万元的一次性支持；对示范效应好、专业能力硬、发展潜力突出的企业，经综合评估，可给予不超过 1500 万元的奖励。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3.支持企业规模化发展。支持企业做大做强，不断集聚业务，提升规模能级和辐射能力，根据企业所属行业领域、经营水平及成长发展能力等综合因素，经综合评估，可给予不超过 3000 万元的奖励。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4.加快创新型企业梯队建设。引导企业提升创新能级和核心竞争实力，壮大创新型领军企业梯队和「蓄水池」。对新增高新技术企业资质的，经认定，可给予最高 30 万元奖励；对重新认定高新技术企业资质的，经认定，可给予最高 10 万元奖励。对新增上海科技小巨人（培育）企业等资质，经认定，可给予一定资金支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;5.提升企业技术攻关能力。围绕战新产业和未来产业等领域，扎实推进「赛马制」等攻关新模式，鼓励企业加速研发创新，开展跨领域基础研究或者颠覆性技术攻关，经评审，可给予不超过项目总投入 30%、最高 300 万元的支持；鼓励企业推动科研成果转化落地、产业试点示范，经评审，可给予不超过项目总投入 30%、最高 1000 万元的支持；主动服务企业开展研发费用税前加计扣除、技术合同登记、技术先进型服务企业认定，并享受相应的支持政策。对技术合同成交额大幅提升的单位，经评审，可给予不超过 50 万元的奖励。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;6.支持标杆应用场景建设。鼓励开展应用场景「揭榜挂帅」，支持企业建立针对应用场景的技术、产品和解决方案资源库。对形成行业或区域标杆引领、示范效应带动强的应用场景建设项目，经评审，可按不超过项目总投入的 30%,给予不超过 300 万元的支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;7.支持创新合作发展。鼓励企业充分利用区域丰富的科技创新资源开展创新创业活动，降低科技创新成本，激发科技创新动能，提升科技创新能级。支持科技企业申请科技创新服务券，经认定，给予每年不超过 80 万元的支持。支持企业数字化转型，对符合区域产业发展方向的企业购买云计算等服务的，经综合评估，可给予每年不超过 200 万元的支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;8.加强市区联动。支持企业申报国家、市级政策，对获得市级及以上资金扶持的项目，结合区域或行业特点，对具有行业示范作用、竞争优势显著的项目，经综合评估，可给予企业一定资金支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;9.做实做细人才服务保障。对用人单位引进的国内外优秀人才，按照相关政策推荐申请「光启人才行动计划」，并提供人才落户、安居、医疗、出入境等方面便利化服务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;10.打造高能级品牌活动。鼓励企业发挥国际化、市场化、品牌化、专业化等资源优势，举办或者承办在行业领域内或者国内外具有较大影响力的创新或者产业活动，经评价，给予一定支持。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338370</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338370</guid>
            <pubDate>Thu, 06 Mar 2025 06:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek-R1 联网搜索能力测评：腾讯元宝综合实力领先</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;3 月 11 日，中文大模型测评基准 SuperCLUE &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fs_ZjP3tjxkyTVEPK_GucZg&quot; target=&quot;_blank&quot;&gt;发布最新报告&lt;/a&gt;，测评了各平台接入 DeepSeek-R1 的联网搜索能力，测评内容包括基础检索能力如文化生活、经济生活、实时新闻等，以及分析推理能力如推理计算、分析排序、数据检索与分析等，&lt;/p&gt; 
&lt;p&gt;测评结果显示，腾讯元宝在 10 家接入 DeepSeek-R1 的平台中联网搜索能力最强，在总分、基础检索能力和分析推理能力三项核心指标上均排名第一。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;4468&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0312/145142_W1Ch_2720166.png&quot; width=&quot;3488&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，本次测评模拟了用户的真实搜索需求，考察 AI 在查找实时新闻、文化生活、经济动态等信息时的准确度，以及在复杂问题上的推理计算、数据分析和排序能力。而据测试结果显示，元宝在基础检索能力、分析推理能力均超越多个平台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338369</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338369</guid>
            <pubDate>Thu, 06 Mar 2025 06:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Podman Desktop 1.17 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Podman Desktop 1.17 现已&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpodman-desktop.io%2Fblog%2Fpodman-desktop-release-1.17&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;，此次发布带来了一些新功能和改进内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3688b5217b2e0c08738fab182fd8e779c2f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;新的运行工作流&lt;/strong&gt;&amp;nbsp;：只需几步即可从镜像启动容器。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;301&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-65147053cb407644e58554ca245efee35ef.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;注册镜像配置&lt;/strong&gt;&amp;nbsp;：通过专用命令简化注册镜像的设置。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;296&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9a0de9db5d21cf7c8d8b00f2f27ab9579a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;278&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f13919e9948beb0c68b67e97f3e223f8fbb.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;更流畅的 kind 集群体验&lt;/strong&gt;&amp;nbsp;：轻松启动 Kubernetes 集群，无需预安装 kind 二进制文件。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;275&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2fbbd33f4ac028e86ada307ada14b907604.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Podman 5.4&lt;/strong&gt;&amp;nbsp;：升级到最新的 Podman 引擎，提升性能和功能。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Pods 重新定义&lt;/strong&gt;&amp;nbsp;：Podman pods 和 Kubernetes pods 之间清晰分离，提升可用性。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ecea9d2ae8ac16c0b8a1e6a5e180ece46b.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#000000&quot;&gt;Kubernetes 实验模式&lt;/strong&gt;&amp;nbsp;：改变资源收集和监控的方式。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3fbafe477d14c57369d8cb90685b04213ce.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpodman-desktop.io%2Fblog%2Fpodman-desktop-release-1.17&quot; target=&quot;_blank&quot;&gt;查看官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338355/podman-desktop-1-17-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338355/podman-desktop-1-17-released</guid>
            <pubDate>Thu, 06 Mar 2025 06:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>豆包文生图技术报告发布，数据处理、预训练、RLHF 全流程公开</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;豆包大模型团队&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3E4s2c7TcWQ_g_6DdJPJkQ&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;文生图技术报告，首次公开 Seedream 2.0 图像生成模型技术细节，覆盖数据构建、预训练框架、 后训练 RLHF 全流程。报告针对 Seedream 2.0 原生中英双语理解、文字渲染、高美感、分辨率与画幅变换等特性的实现，进行了具体介绍。&lt;/p&gt; 
&lt;p&gt;豆包大模型团队文生图模型 Seedream 2.0 于 2024 年 12 月初在豆包 APP 和即梦上线，相比 Ideogram 2.0、Midjourney V6.1、Flux 1.1 Pro 等主流模型，该模型更好解决了文本渲染能力欠佳、对中国文化理解不足等诸多实际问题，支持原生中英双语，美感、指令遵循等能力有整体提升。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:rgba(0, 0, 0, 0.9)&quot;&gt;Seedream 2.0 采用了全新的预训练架构设计，其整体框图如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;274&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-457ee588823b38a7eef1e2ee5c0e9e855d4.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;根据介绍，团队为了较全面客观地评估模型，围绕图文匹配度、结构准确率、美感等基础维度，严格构建了 Bench-240 评测基准。通过测试发现 Seedream 2.0 面向英文提示词，其生成内容的结构合理性、文本理解准确性高于主流模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;459&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b1b01a3b00d4f19f14b66e8f4a52dca01a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中文综合能力同样突出，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;其生成与渲染文字可用率达 78%，完美响应率为 63%，高于业界目前其他模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;465&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e549ec802bb4d76bbba44b30474aebe0c15.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;公告称，此次技术报告的发布，旨在推动图像生成技术进一步发展，加强业内交流。展望未来，团队将持续探索更高效地 Scaling 模型参数及数据的创新技术，进一步提升模型的性能边界。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;完整报告详情可查看：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技术展示页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fteam.doubao.com%2Ftech%2Fseedream&quot; target=&quot;_blank&quot;&gt;https://team.doubao.com/tech/seedream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;技术报告：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2503.07703&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2503.07703&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/338350</link>
            <guid isPermaLink="false">https://www.oschina.net/news/338350</guid>
            <pubDate>Thu, 06 Mar 2025 05:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动 EB 级日志系统设计与优化实践</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e27a1d3e532d1aab8b65d5203bac1eab.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   作者｜刘卯银，火山引擎日志系统架构师 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8942fd743308c45d84b2a600e94847fa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   日志在可观测技术发展的早期是用做故障回顾的。 我们通过 metrics 发现指标异常，比如成功率下降，然后通过 trace 找到了有异常的某个服务，最后才通过日志找到具体的原因（接口返回异常）。 在现代日志系统里，这些都可以通过日志来一站式解决： trace 本身就是一种特殊格式的日志，metrics 可以通过日志来实时生成。 
 &lt;/div&gt; 
 &lt;div&gt;
   日志主要有三个明显优势： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     生成和采集非常容易，基本上各个编程语言都有日志框架； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     采集是旁路的，不需要用户系统做任何改造。日志生成到文件，日志采集器去读文件后采集到日志系统； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     保留了大量的细节。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   日志的挑战也很明确：日志量大，流量容易突发，非结构化的数据难以利用。 
 &lt;/div&gt; 
 &lt;div&gt;
   本文将主要探讨如何解决日志面临的挑战。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;字节跳动日志系统介绍&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;EB&lt;/strong&gt; 
  &lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;级日志系统 TLS（Tinder&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt; 
  &lt;strong&gt;Log&lt;/strong&gt; 
  &lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;Service）&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4921393194a0512d1f9e28b5aab33f7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   字节跳动在集团内部和火山引擎（公有云）是一套统一的日志系统 TLS（Tinder Log Service），下面简称 TLS。集团内部包括抖音、头条、飞书、懂车帝在内的大部分用户的日志都是在 TLS 上。用户的日志包含了运营、运维、审计和 Trace 等类型的日志。TLS 对用户提供采集、存储、加工、查询分析、告警、消费、投递等功能。大家知道字节跳动的业务规模增长比较迅猛、最近的抖音电商也是快速增长，TLS 经受住了业务快速增长导致日志规模快速增长的考验。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;TLS 的演进&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//1de7b567db5294791cb60ea117e65c64.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   早期字节跳动没有统一的日志系统，各业务系统存在日志需求，不得不各自自建，选用的方案五花八门，有基于 ELK 的，有基于 Clickhouse 的，也有基于对象存储+Hive 的。自建的日志系统存在稳定性不足、运维复杂、成本高、弹性不足等诸多痛点，于是我们构建了日志的 1.0 系统。因为主要是运维日志，我们调研了业内开源的一些方案，综合需求和进度要求，最终选择了类似 Loki 的方案。 
 &lt;/div&gt; 
 &lt;div&gt;
   Loki 是 Grafana 旗下一款开源的日志低成本解决方案，没有全文索引，查询日志主要通过扫描。日志 1.0 的数据存储在 HDFS 上，采用扫描式查询，解决了自建系统的稳定性不足、运维复杂、成本高和弹性不足的问题。但是日志 1.0 有一个问题没有解决，那就是性能。因为没有索引，所以查询速度很慢，有同学调侃，查日志的时间，都可以去泡杯咖啡了。 
 &lt;/div&gt; 
 &lt;div&gt;
   1.0 显然不能满足客户的需求，所以我们又马不停蹄的开发了日志 2.0，我们在 1.0 的基础上增加了自研的倒排索引，同时把底层存储更换为了字节内部自研的池化存储 bytestore，2.0 上线后查询性能得到了很大的提升，所以我们把 trace 的数据也接入进来了。 
 &lt;/div&gt; 
 &lt;div&gt;
   随着业务系统的进一步演进，只有索引还是不够的，因为有很多用户希望能基于日志来做运营分析，需要实时的日志报表分析，日志告警等能力。因此我们又开发了日志 3.0（TLS），我们认为 TLS 是一个比较现代且全面的日志系统。日志 3.0 在 2.0 的基础上增加了列存、OLAP 分析引擎以及智能 AI 引擎，同时底层存储也引入了高性能的混合存储。为了满足业务系统多样性的需求，我们还加大了在生态兼容方面的投入，3.0 时代，日志规模也达到了 EB 级。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;字节跳动日志系统 TLS 的设计优化实践&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;现代日志系统的核心属性&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a6dc3be41760eca4e05d1ac007090049.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   在我们看来，一个现代的日志系统具备以下几个方面的核心属性： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     高性能：实时的日志系统必须具备查询分析百亿行日志秒级返回的能力。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     弹性&amp;amp;高可用：日志的量不好预估、存在突发，必须要具备弹性能力；高可用是基本的稳定性诉求。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     高效率：海量的数据只有在成本足够低的时候才能发挥出重要的价值，要让用户能用的起，所以要提升日志系统的效率，降本增效。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     生态兼容：适应用户业务系统的多样性，让更多的用户能方便的接入，让更多的日志发挥出价值。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     丰富的功能：日志加工、可视化仪表盘、日志告警满足用户的多样化需求，适应更多场景的日志。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     智能化：智能化有两个方面，一是日志系统具备智能运维 AIOPS 的能力，包括日志聚类、智能文本分析、机器学习算子；另外一个是提供智能助手，帮助用户写 SQL，写正则，用自然语言生成图表等。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;为高性能而设计的数据组织方式&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d89dae7feec9c09e8592344c89f02988.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   TLS 对外提供写入、消费、查询、分析四个数据面的重要接口，这几个接口的性能决定了 TLS 的性能。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     日志原文：日志顺序写入，顺序读取，是消息队列相似的接口，所以我们也按消息队列的方式来组织数据。原文以 append 的方式写入到底层存储，顺序读取消费。我们按日志到达服务端的时间构建了时间的稀疏索引，用于获取消费位点。同时为了能够对流量进行控制，我们引入了 shard 的概念，每个 shard 是一个顺序的性能流，类似于 Kafka 的 partition，用户需要保序的时候可以指定 shard 写入，需要高性能的时候可以分散到多个 shard 做负载均衡。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     索引：用户需要通过关键字查询日志原文，为了提升查询效率，我们构建了倒排索引。倒排索引存储了关键字和日志行号的对应关系，查询关键字的时候直接获取日志行号，不用做扫描查询。用户查询是指定时间窗口查询的，我们在索引里存放了日志的时间。为了减少查询时间窗口内的数据量，我们做了个优化，把时间相近的日志存放在一起，并以小时为切分单位来分组存放。查询某一个小时内的日志只需要处理对应小时的分组，其它小时的分组可以直接跳过。同时按小时分组存放还有一个好处，小时内的索引只需要存放小时内的时间，如果精确到秒用 0-3599（12 位） 就可以表示时间，大大缩小了时间字段的存储空间。因为数据量少了，一次 I/O 可以读更多的有效数据上来，也提升了时间过滤的效率。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     列存：OLAP 引擎分析数据最高效的就是列式存储了，因为对某一个字段的聚合分析不需要读取别的字段。还是上面的那个道理，相对于行存，列存一次 I/O 可以读取更多的有效数据，自然就提升了性能。TLS 为了适应小流量的场景，列存的切分窗口设置为按天切分，如果按小时切分一些小流量的场景列存会切的太碎，I/O 太小读取效率不高。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存储：TLS 的这三种类型的数据都统一存放到了字节跳动内部的池化存储 bytestore，池化存储通过 EC 做数据冗余，保证数据的可靠性。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;系统架构&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//afa92f12dcf5cc56ada63c05b8d8ab7c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   这是 TLS 的系统架构，分为存储集群、计算集群和管控集群。 重点介绍一下计算集群的组件： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     API Gateway：用户操作的统一入口； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     ShardServer：原文引擎，负责原文的写入、消费、索引查询到，行号后返回日志原文； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Query：OLAP 查询分析引擎，负责列存 SQL 分析和查询结果的聚合； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     IndexServer：索引、列存的写入构建； 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     SearchServer：索引查询。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   可以看到我们的系统架构遵循了三个原则： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存算分离：计算和存储可以分别扩展，这是为了弹性而做出的选择。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     读写分离：也是为了适应弹性做出的选择。前面介绍过字节内部的日志系统是从扫描查询演进过来的，有非常重的读，计算节点会把 100G 的网卡读带宽打满。所以对我们来说，读写分离很重要，一方面是读写资源隔离，另一方面业务系统也在向索引查询切换，需要足够的弹性来支撑这种迁移。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     数据面和管控面分离：数据面和管控面是完全分离的。数据面有完整的配置信息缓存，管控面故障时，数据面的业务不会中断。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;多级缓存和热点消除&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a927c673fcd1414ef3c8a05655e75eed.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   增加缓存是提升性能最有效的手段，我们在系统的多个层级都设置了缓存。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     ShardServer：近期写入的数据马上就会被消费，所以 shardserver 在数据落盘的同时在内存里保存了最近写入的数据，保证索引消费、实时消费、投递都能在缓存里命中。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     IndexServer：缓存索引列存构建的元数据信息，包括索引、列存文件清单，索引的 meta 信息以及列存的 footer 信息，查询的时候从 IndexServer 实时获取才能查询到最新的数据。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Query：Query 上有元数据缓存，中间结果缓存，数据缓存。重点提一下中间结果缓存：因为查询分析命令大部分都是分析最近时间点的数据，所以直接缓存结果大多是无效的，我们需要的是一个中间结果的缓存，联合最新写入的数据和之前查询的中间结果缓存一起计算出当前查询的结果后返回，中间结果的缓存命中率是很高的。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     SearchServer：Searchserver 的缓存和 query 类似，SearchServer 是索引查询的缓存，query 是 SQL 分析的缓存。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Bytestore：Bytestore 上会缓存热点数据，主要是对物理盘的缓存。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   缓存可以提升系统的性能，但缓存要么是全局的，要么就要有亲和节点。我们的缓存是按节点亲和的，会碰到一个问题：日志的流量不太好预估，由于某些事件或者故障发生，日志的量会出现井喷。调度的亲和会造成节点的热点，产生瓶颈。我们的解决方式是在每个服务的入口都设置队列，当一个节点的队列达到水位，说明这个节点已经有请求积压了，处于繁忙状态，这时候会返回 busy，发送节点会根据节点的负载情况，重新选择一个负载低的节点进行重试，从而消除热点。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;索引实时可见&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//04794f3416e8a9444744c2fb5e8289e7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   索引的实时可见是实时业务系统的需求。我们的日志系统 TLS 已经应用到了实时业务场景，所以对从写入成功到可以查询的时间是有要求的，而索引和列存是一个批处理的数据结构，这决定了写入到查询不是立即可见的。用开源自建的小伙伴应该了解 ES 有一个 refresh_interval 参数来控制索引的可见时间，官方建议不能配置的太小，否则频繁刷盘会影响性能。 
 &lt;/div&gt; 
 &lt;div&gt;
   能否兼顾性能和可见性？我们做了索引的内存可见，实测可以在 HDD 的场景把索引的可见性做到 3 秒以内。什么是内存可见呢？数据到了 IndexWriter 后，先放在内存的 buffer 中，如果数据量比较大，buffer 达到设定大小后就开始构建索引写盘，如果 3 秒还没达到设定大小，我们在内存里构建了索引的数据结构，查询的时候可以从内存里查，这就做到了索引的 3 秒可见。内存中的索引会有一定的淘汰策略，进行 merge 后刷盘。 
 &lt;/div&gt; 
 &lt;div&gt;
   需要注意，ES 有一个 translog ，用途是在掉电的时候恢复数据，而我们不需要 translog，因为我们有日志原文，我们通过记录原文消费的 offset 来记录索引的构建进度。但如果处理的不好，内存构建的索引会有幻读的问题，比如在内存中构建了索引，用户也查询到了，突然这个节点故障，内存里的数据丢失，重新启动后提供服务，之前已经查到的数据又查不到了，只有等索引从记录的进度开始重新构建后才能查到，这就是幻读。我们是通过一致性的视图管理来解决幻读的，通过 commit point 记录了索引可见的进度，故障后重启时只有当 commit point 之前的索引都构建好了才会让用户再次查询到。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;EB 级日志系统 TLS 的采集客户端&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e5fe7270407f299ac067709dff0c7c27.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   系统的采集客户端叫 LogCollector ，采用的是多 pipeline 的设计，目的是进行资源隔离、故障隔离。比如某个 output 出现问题，不会影响到其它的 output。在 pipeline 设置有自适应的反压机制，输出端慢采集速度也会放慢。在资源上采用的是资源共享和自动调配机制，每个 pipeline 有独享的内存资源，还有一个全局的共享资源池以应对某些 pipeline 的流量突发。 
 &lt;/div&gt; 
 &lt;div&gt;
   为了应对 AI 时代训练任务的需求，我们还开发了秒级生命周期的容器日志采集能力，通过实时监控 K8s 的事件，做到启动到退出生命周期只有几秒的容器日志能正常采集，不漏不丢。采集客户端的性能非常重要，因为采集客户端部署在用户侧，装机量大，效率提升对成本的收益非常明显。我们也持续在优化采集客户端的性能，这些优化包括： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     批量处理：将日志读取一批后统一处理，降低了 Lock/Unlock 操作的次数，减少了日志状态等对象的内存分配频率。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     并行处理：日志的结构化全部并发多线程执行，提升了 CPU 密集型任务的处理的速率。虽然我们采集客户端通常只配置 1C，但是因为有很多 I/O 操作，多线程是可以提高处理性能的。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     零拷贝技术：日志读取到结构化处理到 OutPut，共用一份内存，避免无效的内存拷贝性能开销，省略非必要的编码/解码动作。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     内存池：对通用数据结构进行池化管理，减少内存碎片。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     其他（以 JSON 采集模式为例）：byte 级别直接操作 JSON 日志，省略内存分配，避免类型转换和反射，提高了 JSON 日志的处理速度。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;如何应对业务的快速增长&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//bf22d05d45ee15c9c3a67bba5d11c5be.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   应对业务的快速增长，我们的策略是多 AZ、多集群部署。TLS 对用户看到是统一的 EB 级大集群，实际内部是由多个小的集群组成的。这样设计有两个方面的考虑，一是故障域隔离，减少故障爆炸半径；二是能充分利用多个机房的资源，有这种灵活性才能拿到足够多的机器应对业务突发上量。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存算分离：前面提到过存算分离，这里再详细说说。我们的存储使用相对大一些的集群，方便资源共享，而计算使用相对小的集群，故障隔离，资源隔离。这样做除了计算集群和存储集群分别灵活扩展外，还有一个优势：计算集群支持离线升级。一个存储集群上有多个计算集群，因为是共享存储，在升级某个计算集群的时，可以把待升级的集群上的业务全部切到其他计算集群，切走后在没有业务流量的情况下升级计算集群，升级完再逐渐把流量灰度切回来。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     Serverless：所有的服务都是云原生的，包括存储都是 on K8s，读写服务资源隔离，分别灵活扩展。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     多集群管理：因为有多个小的集群，多集群管理就非常重要了，弹性是通过多集群管理来实现的，自动负载分配，自动负载均衡。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     存储集群故障时切换：计算集群故障时对业务是没有影响的，快速切换集群后只需要根据水位处理扩容。存储集群故障时，是不是业务就中断了呢？我们在存储集群故障时做了一些降级处理的预案：因为日志写入不中断很重要，写入如果中断有些 SDK 上传的日志就丢了，所以我们在存储集群故障时将写入流量切换到新集群，切换后写数据不中断，新写入的数据在新集群上也可查询，只是历史数据需要等待故障集群恢复时才可查。有些用户对日志的稳定性要求更高，给我们提了 3AZ 高可用的需求，目前在规划中。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;租户隔离&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//40f2695e9e0560fc1a2bc8a329edf636.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   无论是公有云还是内部的系统，除非系统的建设是垂直隔离的孤岛，都绕不开租户隔离的问题。我们的处理策略是多点位的流控和资源控制，并且按照单请求/单 shard/单 topic/单租户设置多个分级，控制住扇入和扇出。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     写入和消费链路：写入和消费是对用户明确了系统的规格的，shard 就是读写的性能单元。为了防止一些异常的场景，我们还设置了租户级别的流控： 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 shard/租户的写入带宽流控，写入 QPS 流控； 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 shard/租户的读取带宽流控，读取 QPS 流控。 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     查询分析链路：查询分析链路对用户明确了单个 Topic 的并发控制 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       按 Topic /租户的并发数流控 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     访问存储：访问存储的流控就是要控制扇出，当然存储自己也会有控制扇入的流控，这里是一个双重保障。 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       分析引擎单 shard 扫描数据量的流控； 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       单节点访问存储的带宽/QPS 流控。 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     资源控制：资源控制有三个方面的控制，CPU、内存的使用量、读盘量： 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       分析引擎按请求/Topic/租户的三级资源流控 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       查询引擎按请求/Topic/租户的三级资源流控 
     &lt;/div&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;div&gt;
       访问存储按 shard 设置了单次请求扫描的数据量 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;高效混合存储&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8740a5a87fd84b6419330f7c131c145a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   开源自建的日志系统，通常使用全 SSD，因为 HDD 的 IOPS 能力有限，需要做大量的优化，否则 HDD 的 IOPS 性能会成为系统的瓶颈。但是对于日志的应用场景，HDD 比 SSD 更适合，因为日志的读写都是顺序 I/O，HDD 的带宽能力是足够的，且 HDD 没有寿命问题、单位容量成本比 SSD 低很多，所以我们需要一个高效率的混合存储，充分利用 SSD 的小 I/O 响应延迟以及 HDD 的低成本优势。 
 &lt;/div&gt; 
 &lt;div&gt;
   通常的混合存储是转储模型，数据先以 3 副本的方式写入 SSD，然后后台 Dump 到 HDD。这种模型会有以下四个问题： 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     三副本导致 SSD 的寿命和成本问题。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     小 I/O 性能差：SSD overlap 写入的问题，小于 4KB 写要对齐到 4KB，写前擦除等。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     后台读对 SSD 的压力，dump 到 HDD 会有一次全量的数据读。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     三副本导致的网络流量放大（图中箭头旁边的数字标识的是流量放大）。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt;
   我们的高效混合存储在架构上做了大的优化，实现了全流程的 EC 直写。首先我们设置了一个 WAL log 层，整个节点上的所有写请求汇聚成一条大的顺序流，聚合后 EC 满条带写入到 SSD，如果用户下发的本身就是大 I/O，就会 bypassSSD 直写 HDD。用户的数据在 Membuffer 里聚合，聚合到一定大小或者达到了强制刷盘的时间才下刷到 HDD。这么设计后，用户写入的数据先给用户返回成功后，在内存中充分聚合，充分聚合到满条带 EC 写 HDD。 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     写 SSD 由副本变成了 EC，大幅减少写入量和网络流量。 
   &lt;/div&gt; &lt;/li&gt; 
  &lt;li&gt; 
   &lt;div&gt;
     都是大块 IO 写 SSD、HDD。SSD 寿命、系统的吞吐量、访问延迟都有极大的改善。 
   &lt;/div&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div&gt; 
  &lt;strong&gt;私有编解码协议&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9c56e3ab4521d805fbad7fff87cf6dfc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   我们发现日志里的 key 占比通常会超过 30% ，而每条日志的 key 几乎都是一样的，对于这种结构化的日志，如果对 key 进行一个编码，可以大幅缩减数据量。通常大家使用 ProtoBuffer 的标准编解码在盘上存储或在网络上发送数据，Protobuffer 没法对相同的 key 进行压缩。因此我们自研了一个私有编解码协议，把日志的 key 映射成数字编码，解码的时候把数字再转换为 key，把 key 到数字的映射存放在日志里，这样 key 只有一次存储，节省约 30% 的网络数据传输和存储空间。 
 &lt;/div&gt; 
 &lt;div&gt;
   同时日志在流转及查询过程中，大部分场景不需要读数据，只需要读 header 里的元数据。但是在 PB 编码的情况下是需要对整个 PB 进行反序列化的，浪费大量的计算资源，增加了延迟。因此，在我们的私有化协议里，把 head 和 data 分别编码和压缩，读 head 的时候，只需要解压和序列化 header，大幅提升了流转过程中的解析速度。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;弹性&amp;amp;高性能&amp;amp;高效率的总结&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5d64d4c99bca66d81824a1c1f0cde2d7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;生态兼容实践-输入和输出生态建设&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ed3fc149d567f7949b017a7ccd326150.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   我们认为最好的生态是支持标准协议的兼容的同时提供更高性能的私有接口，让用户有更多的兼容性选择。在 TLS 上也在践行这一套理念。 
 &lt;/div&gt; 
 &lt;div&gt;
   标准协议兼容：写入和消费 TLS 支持标准的 Kafka 协议接口，OpenTelemetry 接口，S3 接口，在查询分析侧我们支持开源的 Grafana，支持 SQL92 标准的 SQL 命令，也提供了 ES 类似的 stringquery 接口。 
 &lt;/div&gt; 
 &lt;div&gt;
   私有高性能接口：日志采集提供了高性能的采集客户端 LogCollector、多语言 SDK，日志消费提供了消费组和消费者的多语言 SDK，查询分析侧也提供了高性能的多语言 SDK。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;生态兼容实践-Kafka 协议&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//2b8f3e272d4635df42cc17e0e5cb83d1.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   刚刚提到了开源的生态兼容，Kafka 协议是大数据生态的标准协议，使用范围广，因此我们选择了兼容 Kafka 协议。由于底层存储是共享存储，因此不需要 Kafka 的副本机制，我们将 Kafka 改造成了一个存算分离的架构，共享日志原文的存储，可兼容 TLS 的输入和输入生态，支持采集过来的日志用 Kafka 协议消费，也支持从 Kafka 协议导入的数据通过 SDK 进行消费。 
 &lt;/div&gt; 
 &lt;div&gt;
   在 Kafka 业务层面，保留了 Kafka 的 broker 和 coordinator 的实现逻辑，分别支持水平扩展，保留了对 Kafka 协议的兼容，用户在使用的时候看到的是一个增强的 Serverless 的 Kafka。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;数据加工（ETL）&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c6c70061a30f5c0c306d3b8485cb90a8.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   数据加工是日志数据结构化的一个必备功能，TLS 为用户提供了简单易用，类 Python 的日志加工脚本语言，支持语法调试、执行预览，很容易上手。用户只需要简单的编写加工语句即可对日志数据进行加工。日志加工的工作流程是读取源 Topic 内的日志数据，根据用户配置的加工语句对日志进行过滤、富化、脱敏、分发的处理，然后输入出到目的 Topic。TLS 提供了丰富的日志加工函数，通过加工函数来便捷的加工日志。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;日志智能化的实践—快速故障定位&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c81b69d6a108815d1707b3173d22ea7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   日志系统的智能化目前在进行两个方向的建设：智能运维和 AI 日志助手。 
 &lt;/div&gt; 
 &lt;div&gt;
   智能运维主要是通过机器学习的聚类算法进行日志聚类、文本分析、模板匹配；AI 助手主要是用自然语言去生成查询分析语句，写 SQL，配置正则表达式，生成图表等。 
 &lt;/div&gt; 
 &lt;div&gt;
   这里重点介绍下日志智能化的应用。快速故障定位是火山引擎稳定性团队的诉求，期望能够借助日志实现【快速感知】【快速决策】【快速止损】【快速恢复】。我们的实现方式是：以存储产品为例，首先将各个业务模块的日志都接入到日志系统 TLS，在线上模拟常见的故障，根据日志聚类的结果，将出现的日志模板配置到对应的故障。下次出现类似的日志 pattern 时，TLS 就会判断出现了对应的故障，将结果以告警的形式推送，并直接明确故障类型，处理预案。线上出现故障后也可以提取模板，配置到故障库里，下次再出现类似的故障就会产生告警。同时 TLS 还支持故障的拓扑，在出现故障的时候明确出问题的节点。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;内容回顾&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7fde6e62c1aeda80fee1ffe37d99beb9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;用户案例&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;内部案例：对象存储日志上云&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//a72c6c774c5eecc62c9dbbd8856f1083.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   字节跳动的对象存储建设的比日志系统早，早期对象存储有对日志的需求而集团没有日志系统，所以采用了自建。对象存储团队基于自己的业务需求，采用了 2 个采集 agent + 3 套日志查询系统来支撑业务。1 个 agent 采集实时日志，用 filebeat，另一个 agent 自己开发，采集滚动后的历史日志，上传到对象存储降低成本。对于热日志使用 ES 做实时查询，Hive 做离线分析。对于冷日志，开发了一套扫描查询引擎去询对象存储内的日志。 
 &lt;/div&gt; 
 &lt;div&gt;
   对象存储自建的这套系统建设复杂，运维成本高，3 个查询入口查询起来不方便，成本非常高，也没有精力投入后续的优化。后来日志系统 TLS 建立起来后，对象存储果断切换到 TLS，一次采集，多种应用集成，低成本多功能，免运维。切换后对象存储的同学用起来非常满意，后面把历史冷日志也导入了 TLS，他们专心于自己的业务能力建设。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;客户案例—某国际旅行社&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f64a82deb3a93f255e50d75f65366264.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   该案例把火山引擎的日志系统 TLS 当作一个在线的 OLAP 数据库在使用。客户为在线机票服务商，通过自己的搜索服务在各航空公司网站获取机票报价信息，经过处理后，对线上的机票平台提供报价、订单等服务，并对验价异常、报价异常、订单异常等实时告警。我们为客户提供了日志加工、运营大盘、检索分析、日志告警等功能。因为是在线的系统，TLS 的可用性、可靠性就非常重要，任何问题都会直接对客户产生资损。目前客户在 TLS 上运行 2 年多，非常平稳。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;下一步展望&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img src=&quot;https://oscimg.oschina.net/oscnet//4dc9f33845d62e01dbc4f91aea73d489.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;strong&gt;关于作者&lt;/strong&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   刘卯银，火山引擎日志系统架构师 ，现负责火山引擎日志系统的设计、研发和架构技术演进。从 0 到 1 构建了火山引擎云原生日志系统 TLS，并主导了日志系统架构的升级换代。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt;
   资料来源： 
  &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.volcengine.com%2Farticles%2F7389141787136229403&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;字节跳动 EB 级日志系统设计与优化实践 - 文章 - 开发者社区 - 火山引擎&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/6800876/blog/17884414</link>
            <guid isPermaLink="false">https://my.oschina.net/u/6800876/blog/17884414</guid>
            <pubDate>Thu, 06 Mar 2025 05:46:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>