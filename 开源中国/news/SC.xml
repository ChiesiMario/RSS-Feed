<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 15 Sep 2025 21:43:16 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>BentoML 发布 llm-optimizer，LLM 推理和性能优化开源工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;BentoML 近日发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bentoml.com%2Fblog%2Fannouncing-llm-optimizer" target="_blank"&gt;llm-optimizer&lt;/a&gt;，这是一个用于基准测试和优化 LLM 推理的开源工具。它支持多个推理框架，并兼容任何开源 LLM。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4e424ad07868e5d205d0e99984f6e8bf1b4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;llm-optimizer 旨在将 LLM 性能优化的繁琐手动工作自动化。您可以在一个地方运行结构化实验、应用约束并可视化结果，只需几个命令即可。&lt;/p&gt; 
&lt;p&gt;使用示例&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;llm-optimizer estimate \
  --model meta-llama/Llama-3.1-8B-Instruct \
  --input-len 1024 \
  --output-len 512 \
  --gpu A100 \
  --num-gpus 2&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;预期输出&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;=== Configuration ===
Model: meta-llama/Llama-3.1-8B-Instruct
GPU: 2x A100
Precision: fp16
Input/Output: 1024/512 tokens
Target: throughput

Fetching model configuration...
Model: 8029995008.0B parameters, 32 layers

=== Performance Analysis ===
Best Latency (concurrency=1):
  TTFT: 43.1 ms
  ITL: 2.6 ms
  E2E: 1.39 s

Best Throughput (concurrency=512):
  Output: 18873.3 tokens/s
  Input: 23767.8 tokens/s
  Requests: 14.24 req/s
  Bottleneck: Memory

=== Roofline Analysis ===
Hardware Ops/Byte Ratio: 142.5 ops/byte
Prefill Arithmetic Intensity: 52205.5 ops/byte
Decode Arithmetic Intensity: 50.9 ops/byte
Prefill Phase: Compute Bound
Decode Phase: Memory Bound

=== Concurrency Analysis ===
KV Cache Memory Limit: 688 concurrent requests
Prefill Compute Limit: 8 concurrent requests
Decode Capacity Limit: 13 concurrent requests
Theoretical Overall Limit: 8 concurrent requests
Empirical Optimal Concurrency: 16 concurrent requests

=== Tuning Commands ===

--- SGLANG ---
Simple (concurrency + TP/DP):
  llm-optimizer --framework sglang --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tp_size*dp_size=[(1, 2), (2, 1)]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_sglang.json
Advanced (additional parameters):
  llm-optimizer --framework sglang --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tp_size*dp_size=[(1, 2), (2, 1)];chunked_prefill_size=[1434, 2048, 2662];schedule_conservativeness=[0.3, 0.6, 1.0];schedule_policy=fcfs" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_sglang.json

--- VLLM ---
Simple (concurrency + TP/DP):
  llm-optimizer --framework vllm --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tensor_parallel_size*data_parallel_size=[(1, 2), (2, 1)]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_vllm.json
Advanced (additional parameters):
  llm-optimizer --framework vllm --model meta-llama/Llama-3.1-8B-Instruct --gpus 2 --host 127.0.0.1 --server-args "tensor_parallel_size*data_parallel_size=[(1, 2), (2, 1)];max_num_batched_tokens=[1024, 1177, 1331]" --client-args "num_prompts=1000;dataset_name=sharegpt;random_input=1024;random_output=512;num_prompts=1000;max_concurrency=[256, 512, 768]" --output-dir tuning_results --output-json tuning_results/config_1_vllm.json&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该工具解决了 LLM 部署中的一个常见挑战：在不依赖手动试错的情况下，为延迟、吞吐量和成本找到最佳配置。llm-optimizer 为探索 LLM 性能景观提供了一种结构化的方式。它通过实现系统基准和跨可能配置的自动搜索，消除了重复的猜测。&lt;/p&gt; 
&lt;p&gt;开源地址：&lt;em&gt;https://github.com/bentoml/llm-optimizer&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372359/bentoml-llm-optimizer</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372359/bentoml-llm-optimizer</guid>
      <pubDate>Sat, 13 Sep 2025 11:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>北京中小学全面开设人工智能通识课</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FecvZHwNwJg6PafacKW5iEg" target="_blank"&gt;据报道&lt;/a&gt;，自 2025 年秋季学期起，北京市 1400 余所中小学全面开设人工智能通识教育课程，覆盖 183 万余名中小学生，成为全国首个省级全域推进人工智能通识教育的地区。&lt;/p&gt; 
&lt;p&gt;报道称，课程资源方面，首批覆盖全学段的 160 套市级课程资源已上线，每套资源包含 15 分钟左右的核心教学视频、教学指南及活动任务单；&lt;/p&gt; 
&lt;p&gt;通过「视频 + 工具 + 任务单」模式满足教师授课、备课及学生自主学习 3 类场景需求，搭建 AI「课程超市」和「应用超市」，为课堂教学提供基础支撑。&lt;/p&gt; 
&lt;p&gt;市教委相关负责人表示，北京市将持续优化人工智能教育课程资源，结合教学反馈迭代更新；开展应用示范校评选和优秀案例推广，形成可复制经验。&lt;/p&gt; 
&lt;p&gt;同时，负责人还表示，要深化「京娃」系列智能体研发，拓展「AI + 教育」应用场景等，以首批课程资源为起点，力争将北京中小学人工智能教育打造成全国标杆，真正让数字技术赋能每一位师生，为培养担当民族复兴大任的时代新人奠定坚实基础。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372356</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372356</guid>
      <pubDate>Sat, 13 Sep 2025 11:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI Evals 新增原生音频输入和评估功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 的 Evals 工具现已支持原生音频输入和音频评分，无需文本转录即可直接评估模型的音频响应。这项新功能极大简化了语音识别和生成模型的评估过程，使得开发者能够更高效地测试和优化其音频应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9522f36b3f1e768600ee99a85f02e860156.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过使用 Evals 的原生音频支持，用户可以上传音频文件，并直接在平台上进行性能评估。这一改进不仅减少了数据处理的复杂性，还提高了评估结果的准确性和可靠性。对于需要频繁测试和调整音频模型的开发者来说，这是一个重要的进步。&lt;/p&gt; 
&lt;p&gt;应用场景包括但不限于：智能语音助手的开发与优化、语音识别系统的性能评估，以及音频内容生成的质量控制。&lt;/p&gt; 
&lt;p&gt;如需了解更多关于如何使用 Evals 的新功能，参考官方 Cookbook 指南：&lt;em&gt;https://cookbook.openai.com/examples/evaluation/use-cases/evalsapi_audio_inputs&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372353</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372353</guid>
      <pubDate>Sat, 13 Sep 2025 11:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软研究院发布 RenderFormer，基于 Transformer 的神经渲染模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软研究院近日发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Frenderformer-how-neural-networks-are-reshaping-3d-rendering%2F" target="_blank"&gt;RenderFormer&lt;/a&gt;，这是一个纯机器学习的神经架构，旨在通过机器学习完全替代传统图形计算，实现全功能 3D 渲染，无需传统图形计算。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-973c5649e34320d01d3888bfd65c9a319d3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2008d874aeabcfe09955bf61fd0b256737b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;RenderFormer 整体架构如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;双分支 Transformer 架构：分为视角无关（View-Independent）和视角相关（View-Dependent）两个阶段。视角无关阶段通过自注意力机制捕捉阴影、漫反射等全局光照效果；视角相关阶段通过交叉注意力机制建模可见性、反射等视角依赖效果。&lt;/li&gt; 
 &lt;li&gt;相对空间位置编码：创新性地采用改进的旋转位置编码（RoPE），基于三角形的 3D 空间位置而非序列索引，保持场景平移不变性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79adce0f291f87580ef10043c6928fce017.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，RenderFormer 是首个证明神经网络能学习完整图形渲染流水线的模型，支持任意 3D 场景和全局光照效果，无需依赖光线追踪或光栅化技术。它通过三角形令牌（triangle tokens）表示 3D 场景，编码空间位置、表面法线及材质属性，结合光线束令牌（ray bundle tokens）处理视角信息，实现端到端渲染。该成果已获 SIGGRAPH 2025 接收并开源。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://microsoft.github.io/renderformer&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372349</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372349</guid>
      <pubDate>Sat, 13 Sep 2025 10:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>亚马逊云科技否认大中华区裁员</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;9 月 15 日，有消息称亚马逊云科技（AWS）大中华区计划裁员，预计将发生在 9 月底至 10 月之间，或涉及超 20% 的员工，目前 AWS 大中华区人员规模不到 1700 人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对此，亚马逊云科技发言人表示：「相关报道严重失实，亚马逊云科技持续在中国积极招聘人才，为中国企业提供全球领先、安全可靠的云技术。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年 7 月，亚马逊发布了 2025 年第二季度财报，二季度营收同比增长 13% 至 1677 亿美元；净利润 181.64 亿美元，与上年同期的 134.85 亿美元相比大幅增长 35%；稀释后每股收益为 1.68 美元。亚马逊已承诺今年在 AI 领域的投资将高达 1000 亿美元。亚马逊 AWS 云业务在二季度营收 308.73 亿美元，略高于市场预期的 308 亿美元，同比增长 17%，增速与上一季度持平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;AWS 的增速仍低于其主要竞争对手微软云和谷歌云。在电话会上，亚马逊 CEO 安迪·贾西试图向分析师保证，和其云计算竞争对手相比，AWS 一直保持着「相当重要」的领导地位，他对公司 AI 产品的发展感到乐观：「我们 AWS 领域的业务规模比其他公司的云业务大得多，我认为第二位的规模约为 AWS 的 65%。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网资料显示，亚马逊云科技于 2013 年进入中国，通过本地合作伙伴北京光环新网科技股份有限公司（光环新网）和宁夏西云数据科技有限公司（西云数据），提供与全球一致的云服务体验和安全级别，API（应用程序接口）、SDK（软件开发工具包）、CLI（命令行工具）与全球其他地区相同，开发者无需额外适配，即可实现全球化应用部署。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，亚马逊云科技在中国云计算市场面临激烈的竞争。根据研究机构 Canalys 的报告显示，2025 年第一季度中国大陆的云计算支出达到 116 亿美元，前三名阿里云、华为云和腾讯云的市场份额分别为 33%、 18% 和 10%，三家巨头合计占领了整个中国云计算市场的 61%。（澎湃新闻）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372348</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372348</guid>
      <pubDate>Sat, 13 Sep 2025 10:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Roo Code 上线远程连接功能 Roomote Control</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程工具 Roo Code 近期推出了名为 &lt;strong&gt;Roomote Control&lt;/strong&gt; 的新功能，旨在提升用户在 VS Code 中的编码体验。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/181541_VqYx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Froo_code%2Fstatus%2F1966280158031335625" target="_blank"&gt;据介绍&lt;/a&gt;，Roomote Control 允许用户通过手机或浏览器远程连接和控制本地 VS Code 环境中的 Roo Code。该工具直接在用户的系统上运行，确保代码库保持私有和完全安全。&lt;/p&gt; 
&lt;p&gt;用户可以在远程设备上启动新任务、选择模式和模型，所有更新会实时同步回本地 IDE。即使暂时离开，用户也可以让任务在后台继续运行，提高工作效率。&lt;/p&gt; 
&lt;p&gt;Roomote Control 作为 Roo Code Pro 订阅的一部分，提供 14 天的免费试用期，之后每月收费 20 美元。&lt;/p&gt; 
&lt;p&gt;使用方法如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;连接步骤&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;在 Roo Code 中导航到 Cloud 菜单并点击「Connect」。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;登录 Roo Code 网站并在 IDE 中启用远程控制。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;在浏览器中访问 Roo Code Cloud，确保远程切换已启用。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;功能体验&lt;/strong&gt;：用户可以在远程部分查看 IDE 的开放目录，点击加号图标启动新任务，输入提示并观察任务的执行。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过 Roomote Control，Roo Code 进一步扩展了其作为 AI 驱动的自主编码代理的功能，使用户能够随时随地高效地管理编码任务。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372344</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372344</guid>
      <pubDate>Sat, 13 Sep 2025 10:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>全球首个 AI 政府部长来了</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;综合环球网等媒体报道，阿尔巴尼亚总理埃迪·拉马当地时间 11 日宣布新内阁名单，&lt;strong&gt;&lt;strong&gt;其中包括任命一个名为「迪埃拉」（在阿尔巴尼亚语中意为「太阳」）的人工智能担任公共采购部长&lt;/strong&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;&lt;strong&gt;这也使得阿尔巴尼亚成为世界上第一个任命非实体的人工智能担任政府部长的国家。&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="254" src="https://oscimg.oschina.net/oscnet/up-01dfab898dc0952c33998cbf206a06145f0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 5 月，拉马历史性地第四次当选阿尔巴尼亚总理。今年夏天，拉马曾畅想有朝一日该国能有一位数字部长，甚至是一位人工智能总理，不过当时几乎没人想到这一天会这么快到来。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;拉马在周四宣布新内阁的讲话中表示：「迪埃拉是第一位并非以实体形式存在，而是由人工智能虚拟生成的内阁成员。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉马还表示，招标决定权将从各部手中逐步移交给「迪埃拉」，「迪埃拉」将审查政府与私营公司签订的每一份招标合同，并客观评估每一份招标合同的优点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉马强调，「迪埃拉」将帮助阿尔巴尼亚「成为一个公共招标 100% 没有腐败的国家」。长期以来，授予此类合同一直是这个巴尔干国家腐败丑闻的根源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这种形象对阿尔巴尼亚加入欧盟的梦想造成了打击。阿尔巴尼亚目前是欧盟的候选国，拉马希望在 2030 年之前成为欧盟正式成员国，但政治分析人士称，这一目标过于雄心勃勃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;拉马还称，将有一个专用部门为「迪埃拉」提供支持，并推动人工智能在政府各部门的应用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;不过，阿尔巴尼亚政府并未提供有关「迪埃拉」可能会受到何种人类监督的详细信息，也没有就有人可能操纵这个人工智能机器人的风险作出说明。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「迪埃拉」此前已经为阿尔巴尼亚公民所知，她的虚拟形象是一个身穿阿尔巴尼亚传统服饰的女子，于今年年初在电子平台作为一款人工智能虚拟助手上线，该平台允许公民以数字方式访问几乎所有政府服务。「迪埃拉」负责帮助公民和企业获取政府文件，通过语音指令提供帮助，以及签发带有电子印章的文件。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372341</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372341</guid>
      <pubDate>Sat, 13 Sep 2025 10:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯 AI 编程工具 CodeBuddy 推出个人订阅方案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯旗下 AI 编程工具 CodeBuddy 正式公布了其个人订阅方案。用户每月支付 9.95 美元即可获得 1000 credits，并且每日还会额外赠送 100 credits（于零点重置）。&lt;/p&gt; 
&lt;p&gt;付费版功能&lt;br&gt; ✅1000 credits/month&lt;br&gt; ✅100 credits/day, reset daily&lt;br&gt; ✅All premium models&lt;br&gt; ✅Unlimited BuddyTab&lt;br&gt; ✅Unlimited Next Edit Prediction&lt;br&gt; ✅Previews&lt;/p&gt; 
&lt;p&gt;免费版功能&lt;br&gt; ✅2 week pro trial with 500 credits&lt;br&gt; ✅50 credits/day, reset daily&lt;br&gt; ✅All premium models&lt;br&gt; ✅Unlimited BuddyTab&lt;br&gt; ✅Unlimited Next Edit Prediction&lt;/p&gt; 
&lt;p&gt;&lt;img height="733" src="https://static.oschina.net/uploads/space/2025/0915/175958_W3lT_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.codebuddy.ai/profile/plan&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;订阅用户可以调用全部高级模型，并无限使用 BuddyTab 与 Next Edit Prediction 功能。对于新用户，CodeBuddy 提供一次性的为期 2 周，的 Pro 试用，其中包含 500 credits 以及每日 50 credits 的赠送。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372340</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372340</guid>
      <pubDate>Sat, 13 Sep 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>xAI 正在测试 Grok 4 Fast，宣称是「地球上最快思考模型」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;xAI 已开始对 Grok 4 Fast &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.testingcatalog.com%2Fxai-launches-grok-4-fast-in-early-access-beta-with-up-to-10x-speed%2F" target="_blank"&gt;进行灰度测试&lt;/a&gt;，并宣称这是「目前地球上最快的思考模型」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-820d3dda386ef2105d157daacaa4058bcfd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3fbbb5515d6180fa2258e4d055d8fdc166e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该模型据称是 Grok 4 的加速版，已在 Grok 网页端、iOS 应用以及 X 平台上向部分用户推送。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/174413_VUST_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;新版本主打极速响应，同时力求保持高水平的智能密度。为了方便用户体验，网页端为订阅用户新增了「Enable early access models」开关，允许他们提前试用尚在实验阶段的新模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372333</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372333</guid>
      <pubDate>Sat, 13 Sep 2025 09:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Pantheon CLI - 科学 「聊天式分析」 类人框架</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#1f2328; text-align:start"&gt;Pantheon-CLI 是专为科学研究打造的&lt;strong&gt;首个完全开源的「聊天式分析」类人框架&lt;/strong&gt;。定义 AI 时代研究者与数据交互的新方式。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;strong&gt;博士水平的科学助手&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Pantheon-CLI 是首个用于复杂真实世界分析的命令行智能（CLI）Agent 助手，能够像人类一样处理博士级别的单细胞与空间组学任务。这不仅是一个工具——&lt;strong&gt;它是一位加入你科研团队的 AI 科学家&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;&lt;strong&gt;混合式编程&lt;/strong&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在同一个环境中，你可以：
&lt;ul&gt;
&lt;li&gt;第一行写 Python 代码&lt;/li&gt;
&lt;li&gt;下一行使用自然语言描述&lt;/li&gt;
&lt;li&gt;甚至混合使用 R/Julia 语言&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;科学家只需专注于&lt;strong&gt;探索&lt;/strong&gt;，无需在不同工具与环境之间来回切换。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;功能特性&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="color:#1f2328; text-align:start"&gt;用 Pantheon-CLI 的开源力量重塑你的数据分析工作流——它为多语言无缝集成、轻松数据分析与下一代科研发现而生。&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.1 与数据对话&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;使用 Pantheon-CLI，你可以处理任何本地数据，不局限于文本、CSV、Excel，还包括 anndata、pkl、torch，以及任何 Python/R/Julia 支持的数据格式。&lt;/li&gt;
&lt;li&gt;你无需将任何数据上传至服务器——分析能力完全依赖于你的计算机。也可以将 Pantheon-CLI 安装在服务器上，解锁无限分析可能。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.2 混合式编程&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在 Pantheon-CLI 中，所有变量都保存在环境中，突破了传统编程的限制。你可以随时用自然语言「编程」，CLI 会自动生成 Python/R/Julia 代码并运行。&lt;/li&gt;
&lt;li&gt;这是全球首个具备变量持久化支持的 Agent。在编码过程中，你可以随时输入自然语言，Pantheon-CLI 将自动执行你想要的分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.3 MCP 集成&lt;a href="https://github.com/aristoteleo/pantheon-cli/blob/main/assets/feature_3.jpg" target="_blank"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;通过 Pantheon-CLI，构建了一个具备人机交互全栈能力的助手：读写文件、创建文件、运行命令、生成代码、读取网页。&lt;/li&gt;
&lt;li&gt;不同于传统 Agent，该项目几乎实现了 Claude Code 的所有能力，并进一步优化——致力于让 Pantheon-CLI 更适合数据分析，而非纯粹的代码编程。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.4 类人行为&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;像人类科学家一样，Pantheon-CLI 可读取网页教程与 PDF 论文，然后开始规划分析。&lt;/li&gt;
&lt;li&gt;给 LLM 输入教程常能得到更好的输出，但并非所有网页都易于访问。项目重构了更强大的网页抓取能力，尽可能复现人类在分析前会做的一切准备工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.5 任务规划&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;在 Pantheon-CLI 中，可从论文中学习并自动规划、构建科学 Agent。学习论文的 Method 部分，像人类专家一样搭建逐步执行的 Agent。&lt;/li&gt;
&lt;li&gt;对于数据科学任务，现有 Agent 的通用做法是「计划并逐步执行」，但这依赖于人类预先定义的步骤。Pantheon-CLI 则能从论文或教程中自动学习并规划工作流。这与人类专家的做法有何不同？&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.6 多模型提供商支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Pantheon-CLI 支持主流大模型提供商，包括 OpenAI、Anthropic、Gemini、Deepseek、Qwen 等，因此你不受制于任一模型。&lt;/li&gt;
&lt;li&gt;这看似简单，却非常实用：支持任何大模型，且无需「Claude Code 风格」的专用 API——通用 LLM API 即可。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.7 本地 LLM 支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;出于某些数据隐私合规需求，Pantheon-CLI 可基于 ollama 使用本地大模型离线完成数据分析。&lt;/li&gt;
&lt;li&gt;在本地运行数据与本地运行模型，是 Pantheon-CLI 的另一个有趣优势。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.8 多 RAG 支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;提供完整的预学习 RAG 方案。通过强大的网页爬虫汇集文档信息，构建一个「外置大脑」，随后将用户意图与之匹配，生成更可靠的输出。&lt;/li&gt;
&lt;li&gt;虽然 RAG 仍在争论中，但很多时候用户找不到「合适教程」作为精确输入。在这种情况下，RAG 就很有价值——毕竟极长上下文也会消耗大量 tokens。后续会释放更大的 RAG 数据库供下载。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.9 生物学支持&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;借助在生物组学分析方面的经验，预置了系统级组学工具集，帮助你完成上游测序比对、下游注释与差异分析，甚至完整复现一篇生物学论文中的全部分析。&lt;/li&gt;
&lt;/ul&gt;

&lt;div style="text-align:start"&gt;
&lt;h3&gt;3.10 Notebook Support&lt;/h3&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;想象一下：从现在起，当你在笔记本中分析数据时，如果你有特定的需求，却不想翻阅复杂的文档，你只需要进行一次对话，分析工作就能瞬间完成。&lt;/li&gt;
&lt;li&gt;它不仅用于编写代码，还能自动运行和修改代码以生成正确结果，甚至能够处理文件并从网站学习——这些功能是其他任何工具都无法比拟的。&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/pantheon-cli</link>
      <guid isPermaLink="false">https://www.oschina.net/p/pantheon-cli</guid>
      <pubDate>Sat, 13 Sep 2025 09:45:00 GMT</pubDate>
    </item>
    <item>
      <title>《人工智能安全治理框架》2.0 版发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;在国家互联网信息办公室的指导下，国家计算机网络应急技术处理协调中心组织专业机构、科研院所、行业企业等持续跟踪人工智能风险变化演进，梳理调整风险分类，研究形成风险分级方法，动态调整更新防范治理措施，制定&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FaFGCdWSxHxGdxC9e76wuXw" target="_blank"&gt;《人工智能安全治理框架》2.0 版&lt;/a&gt;，&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;作为网安标委技术文件发布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;旨在&lt;/span&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;推动增进人工智能安全治理共识，促进协同共治、普惠共享，为应对人工智能快速发展的新⻛险新挑战，安全有效地释放应用需求，促进人工智能技术和产业发展提供参考指引。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="background-color:#ffffff; color:#222222"&gt;《人工智能安全治理框架》1.0 版（以下简称《框架》）于 2024 年 9 月发布。国家互联网应急中心负责同志表示，《框架》2.0 版的发布，顺应全球人工智能发展潮流，统筹技术创新与治理实践，在人工智能安全、伦理、治理等方面不断深化共识，促进形成安全、可信、可控的人工智能发展生态，构建跨国界、跨领域、跨行业的协同治理格局。同时，有助于推进多边机制下人工智能安全治理合作，推动世界范围内技术成果的普惠共享，确保人类社会共享人工智能发展的红利。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="401" src="https://oscimg.oschina.net/oscnet/up-3e656b6a8b8754221ca5273024e8dfad42e.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372324</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372324</guid>
      <pubDate>Sat, 13 Sep 2025 09:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Visual Studio Code 1.104 正式发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Visual Studio Code 1.104 已正式发布，本次更新涵盖模型灵活性、安全、生产力、协作、MCP、终端、语言支持以及社区工程等全方位改进。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-107a801bf4556b3f657242fc4038270c98c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-dc1c7a85d5267af937abf535a52fe77085e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;主要变化如下&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增 Auto 模型选择预览与 LanguageModelChatProvider API&lt;/li&gt; 
 &lt;li&gt;支持多模型智能切换与扩展接入&lt;/li&gt; 
 &lt;li&gt;安全方面强化敏感文件编辑确认和终端自动批准机制&lt;/li&gt; 
 &lt;li&gt;生产力方面优化文件变更管理&lt;/li&gt; 
 &lt;li&gt;Prompt 与 Agent 上下文支持&lt;/li&gt; 
 &lt;li&gt;数学公式渲染及 Chat 界面体验&lt;/li&gt; 
 &lt;li&gt;协作功能引入实验性 Chat Sessions&lt;/li&gt; 
 &lt;li&gt;多会话进度追踪和 GitHub coding agent 增强&lt;/li&gt; 
 &lt;li&gt;MCP 新增指令写入&lt;/li&gt; 
 &lt;li&gt;访问权限控制与自动发现开关&lt;/li&gt; 
 &lt;li&gt;终端支持独立窗口&lt;/li&gt; 
 &lt;li&gt;IntelliSense 补全与粘性滚动&lt;/li&gt; 
 &lt;li&gt;语言层面强化 Python 生态支持与 Pylance AI 功能&lt;/li&gt; 
 &lt;li&gt;Git 与 PR 扩展改进 worktree&lt;/li&gt; 
 &lt;li&gt;PR 视图及代码操作&lt;/li&gt; 
 &lt;li&gt;工程与社区方面引入 Playwright MCP 实验&lt;/li&gt; 
 &lt;li&gt;Issue Reporter 新选项及 UI 可配置性&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看&amp;nbsp;https://code.visualstudio.com/updates/v1_104&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372323</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372323</guid>
      <pubDate>Sat, 13 Sep 2025 09:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Cursor 升级 Tab 模型，实时强化学习提升开发者建议精准度</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 是一款基于人工智能的编程平台，最近宣布对其 Tab 模型进行了升级。Tab 模型是为开发者提供自动补全建议的系统。此次升级显著减少了低质量建议的数量，提高了建议的准确性。具体来说，新的 Tab 模型相比于之前的版本，建议数量减少了 21%，而接受率提高了 28%。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="303" src="https://oscimg.oschina.net/oscnet/up-5f8f2f76b53766cb4cfaec598400aa74c36.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 在其博客中表示，实现高接受率不仅仅是让模型变得更智能，还需要懂得何时提供建议、何时不提供。为了应对这一挑战，Cursor 考虑了训练一个单独的模型，用于预测某个建议是否会被接受。该公司引用了一项 2022 年的研究，指出这种方法在 GitHub Copilot 中取得了成功。研究中采用了逻辑回归过滤器，分析编程语言、最近的接受历史和训练字符等特征，将那些得分较低的建议隐藏起来。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，Cursor 认为这种解决方案虽然可以预测用户接受建议的概率，但希望有一个更通用的机制，能够重用 Tab 模型学到的强大代码表示。Cursor 希望通过改变 Tab 模型的结构，避免在最初就产生低质量建议，而不是后续再进行过滤。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;因此，Cursor 采用了策略梯度方法，这是一种强化学习的方法。当用户接受建议时，模型会得到奖励;当建议被拒绝时，模型会受到惩罚;而在选择保持沉默时则不会得到任何反馈。此方法需要 「在线」 数据，即从当前使用的模型收集的反馈。Cursor 通过每天多次向用户部署新的检查点，并迅速基于新交互对模型进行再训练，来解决这一问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Cursor 表示，当前从部署检查点到收集数据的过程仅需 1.5 到 2 小时，这在 AI 行业中已经算是较快，但仍有进一步加速的空间。该公司的 Tab 模型每天处理超过 4 亿个请求，Cursor 希望这一改进能够提升开发者的编码体验，并计划在未来进一步开发这些方法。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在线强化学习是该领域最令人兴奋的方向之一，一位在 OpenAI 从事后训练的工程师在社交媒体上对此表示赞赏，称 Cursor 似乎是&lt;span&gt;第一&lt;/span&gt;个成功在大规模上实施该技术的公司。&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;不久前，Cursor 的母公司 Anysphere 宣布融资 9 亿美元，估值达 99 亿美元，并推出了一项月费 200 美元的 「超值」 计划，承诺提供 20 倍于 20 美元月费 「专业版」 的使用量。此外，Cursor 还在同月进行了平台更新，新增了自动代码审查、记忆功能和一键设置模型上下文协议服务器的功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372315</guid>
      <pubDate>Sat, 13 Sep 2025 08:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Genspark AI 浏览器正式发布，支持本地运行开源模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Genspark AI 浏览器正式发布，官方称其&lt;strong&gt;为世界首个支持本地运行开源模型的 AI 浏览器&lt;/strong&gt;。使用大模型无需联网，可在本地设备离线运行 169 款开源模型，包括 GPT-OSS、Gemma3 等，响应速度极快且完全免费，并集成了全能智能体、广告拦截等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-205a66f89555bba425f98420cd70b1a0e86.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1636" src="https://static.oschina.net/uploads/space/2025/0915/164241_hahS_2720166.png" width="2988" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下载地址：&lt;em&gt;https://www.genspark.ai/browser&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;除端侧 AI 大模型外，Genspark AI 浏览器集成全能智能体，可在任意网页实时比价、分析评论、寻找最优交易；购物站点一键「Find best deal」即可锁定最低价格。Autopilot 模式允许 AI 自主浏览并收集信息；内置 MCP 商店供用户扩展功能；系统级广告拦截提供无广告纯净体验。目前提供 Windows 版本下载，官网已开放获取。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372311</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372311</guid>
      <pubDate>Sat, 13 Sep 2025 08:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达违反反垄断法，市场监管总局依法决定实施进一步调查</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;国家市场监管总局发布公告称，&lt;span style="background-color:#ffffff; color:#222222"&gt;近日，经初步调查，英伟达公司违反《中华人民共和国反垄断法》和《市场监管总局关于附加限制性条件批准英伟达公司收购迈络思科技有限公司股权案反垄断审查决定的公告》，市场监管总局依法决定对其实施进一步调查。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="291" src="https://oscimg.oschina.net/oscnet/up-05819d861c5fa6b672979b892bc20198c1c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372305</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372305</guid>
      <pubDate>Sat, 13 Sep 2025 08:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程工具 Cursor 升级 Tab 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程工具 Cursor&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcursor.com%2Fblog%2Ftab-rl" target="_blank"&gt;宣布&lt;/a&gt;对其代码自动补全系统 Tab 模型进行重大升级。此次升级聚焦于减少低质量建议，显著提升准确性。据 Cursor 称，新模型提供的建议数量比旧版减少 21%，但接受率提高了 28%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7d38fa82207b8f8398156bf34ea4383041e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为解决此前模型存在的问题，Cursor 最初考虑训练单独模型预测建议接受度，参考 2022 年 GitHub Copilot 相关研究，采用逻辑回归过滤技术。但 Cursor 期望更通用机制，最终利用强化学习中的策略梯度方法，使模型因建议被接受获奖励，被拒则受惩罚。该方法需「在线策略」数据，Cursor 通过每日多次向用户部署新检查点，并依据最新交互快速重新训练模型来实现。&lt;/p&gt; 
&lt;p&gt;Cursor 希望实现不只是事后过滤失败建议，而是让主模型本身在建议生成阶段就尽量避免「坏建议」。他们用 policy gradient 方法来训练 Tab 模型，让模型在做出建议 vs 不建议的决策上，最大化一个定义好的 reward 函数。这个 reward 重在：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;鼓励建议被接受（accept suggestions）&lt;/li&gt; 
 &lt;li&gt;惩罚建议被拒绝&lt;/li&gt; 
 &lt;li&gt;不建议（show nothing）在模型判断不确定或建议被低接收率预计的情况下也给予中性或某种 reward。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;举例来说，如果模型估计建议被接受的机会至少 25%，显示建议会有正 reward；如果低于，则建议不被显示以避免 negative reward。&lt;/p&gt; 
&lt;p&gt;目前，Tab 模型在平台上响应用户每一次操作，每日处理超 4 亿次请求。业内对此次升级反响积极，有 OpenAI 工程师称赞 Cursor 在前沿技术规模化应用方面的领先尝试。&lt;/p&gt; 
&lt;p&gt;今年 6 月，Cursor 母公司 Anysphere 融资 9 亿美元，估值达 99 亿美元，并推出高端订阅计划，同时平台更新了自动代码审查等功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372303</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372303</guid>
      <pubDate>Sat, 13 Sep 2025 08:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 董事会主席承认 AI 泡沫：有人会血赚也有人会血亏</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;AI 领域的狂热情绪正引发一场关于「泡沫」的激烈辩论，而 OpenAI 董事会主席 Bret Taylor 对此给出了一个明确但复杂的答案：我们确实身处泡沫之中，但这并不妨碍 AI 最终创造巨大的经济价值。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt;
 近日，在接受媒体 The Verge 采访时，Bret Taylor 赞同了
 &lt;span&gt;OpenAI 首席执行官 Sam Altman 先前的观点&lt;/span&gt;，承认「我们正处于 AI 泡沫中，有人将损失一大笔钱」。
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 警告称，&lt;strong&gt;与任何颠覆性技术浪潮一样，这一过程将不可避免地产生巨大的赢家，同时也会让许多人损失惨重。&lt;/strong&gt;他同时认为，AI 将改变经济格局并创造巨大价值，这与市场存在泡沫，是两个可以同时成立的事实。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 将当前的 AI 热潮与上世纪 90 年代末的互联网泡沫进行了直接比较。他指出，&lt;strong&gt;尽管当时无数公司在泡沫破裂中倒下，但从长远来看，「1999 年的那些人（对互联网未来的判断）在某种程度上是正确的」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;如今，亚马逊和谷歌等诞生于那个时代的公司已成为全球市值最高的企业之一，证明了泡沫下的远见最终能够兑现：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「实际上，如果你看看世界的 GDP，互联网的存在实际上创造了多少或影响了互联网？有人可能会说，1999 年的所有人都是对的。它对几乎所有指标都有同样的影响。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;关键在于区分泡沫的「方向性」&lt;/strong&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 详细阐述了他对 AI 泡沫与互联网泡沫的类比。他认为，&lt;strong&gt;关键在于区分方向的正确性与具体投资标的的成功率。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;互联网泡沫时期，许多商业模式如 Webvan（网上生鲜配送）最终失败，但其核心理念在互联网基础设施成熟后，由 Instacart 和 DoorDash 等公司成功实现。这表明，即便最初的尝试失败，其背后的趋势和需求是真实存在的。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;同样，在互联网早期，大量投资光纤网络的公司破产，但这些基础设施最终被后来者利用，支撑了整个数字经济的繁荣。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 表示，「AI 将改变经济」和「很多人会亏钱」这两个论断可以同时为真：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「我认为 AI 将改变经济是事实，我认为它将像互联网一样，在未来创造巨大的经济价值。同时我认为我们也处于泡沫之中，很多人会损失很多钱。&lt;strong&gt;我认为两者同时是绝对正确的，而且这两件事同时发生的历史先例很多。」&lt;/strong&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;这意味着当前的巨额投资，无论最终流向哪家公司，都在为下一代 AI 应用铺平道路，但并非所有参与者都能分享到最后的果实。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;AI 如此「烧钱」的原因：市场尚不成熟&lt;/strong&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;Taylor 并不同意「模型迭代已显著放缓」的观点，他以编码任务为例，指出新模型在特定领域的性能仍有「阶跃式」提升。但他同时认为，随着模型能力的成熟和普及，对于许多任务而言，模型已达到「足够好」的水平。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;他预测，未来构建 AI 应用将更像是「如何使用数据库」，而非「如何编写数据库」。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;对于市场上关于 AI 投入产出比的质疑，例如一份 MIT 报告指出许多企业 AI 支出未见成效，Taylor 认为，&lt;strong&gt;这主要是因为市场尚不成熟。&lt;/strong&gt;许多公司正在进行「AI 观光」（AI tourism），试图自己构建解决方案，其过程复杂且容易失败。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;他相信，正确的路径是购买像 Sierra（用于客服）或 Harvey（用于法律）这样专注于特定领域的成熟 AI 解决方案。随着更多「应用型 AI 公司」的出现，企业将能更直接地购买到解决其痛点 AI 代理，从而真正实现 AI 的价值。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:justify"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0; text-align:left"&gt;「我认为我们正处于 AI 的早期阶段，还没有一个出色的供应商来解决您业务中遇到的每个问题。因此，您要么必须等待，要么必须自己构建它。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372298</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372298</guid>
      <pubDate>Sat, 13 Sep 2025 07:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Anthropic 发布 LLM Agent 工具编写指南</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 官方博客近日发布了一份详细指南&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.anthropic.com%2Fengineering%2Fwriting-tools-for-agents" target="_blank"&gt;&lt;em&gt;《Writing effective tools for LLM agents—using LLM agents》&lt;/em&gt;&lt;/a&gt;，阐述如何利用 Model Context Protocol（MCP）为 LLM Agent 设计高效工具，并提出了「原型-评估-协作」三步迭代流程，归纳了五大设计原则。&lt;/p&gt; 
&lt;p&gt;1. 谨慎选择工具&lt;br&gt; 2. 清晰的命名空间&lt;br&gt; 3. 让工具返回更具意义的上下文&lt;br&gt; 4. 优化返回信息的 Token 效率&lt;br&gt; 5. 通过提示工程提升工具说明的质量&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-54ceebb7c490a4f1d803e1a0d17a5f1bf5f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;文章指出，工具是「确定性系统与非确定性 Agent 之间的合约」，开发者需跳出传统 API 思维，面向 Agent 的上下文限制与策略多样性重新设计接口。&lt;/p&gt; 
&lt;p&gt;作者透露，文中多数结论由 Claude Code 反复分析评估脚本、重构工具描述与模式后自动得出，且仍在通过保留测试集防止过拟合。Anthropic 已同步开源工具评估 Cookbook，并预告未来 MCP 协议与底层 LLM 升级时，同样方法可让工具能力随 Agent 同步演进。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372294/anthropic-writing-tools-for-agents</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372294/anthropic-writing-tools-for-agents</guid>
      <pubDate>Sat, 13 Sep 2025 07:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里 Qoder 新升级，Repo Wiki 支持共享、编辑和导出</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;过去两年虽有众多 AI 编程工具涌现，但在真实软件开发中仍面临诸多挑战，如工程复杂度高、不确定性强和知识无沉淀传承等，现有工具难以满足开发需要，Qoder 正是为解决这些问题而推出。Qoder 是阿里巴巴发布的一款全新的 Agentic 编程平台，它集成了全球顶尖的编程模型，提供最强的上下文工程能力，可一次检索 10 万个代码文件。基于强大的编程智能体，可实现 AI 自主研发，大幅提升真实软件的开发效率。&lt;/p&gt; 
&lt;p&gt;据官方披露，Qoder 上线 5 天用户规模突破 10 万，&lt;strong&gt;其中 Repo Wiki 功能受到开发者广泛好评。&lt;/strong&gt; Repo Wiki 能基于代码自动为工程生成结构化的文档，涵盖工程架构、引用关系图谱、技术文档等内容，并持续跟踪代码与文档的变更，把知识沉淀为可复用的工程资产。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6d025ed54bfc027f70832d07af8b3f21d11.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;举例来说，&lt;strong&gt;在新项目开始时&lt;/strong&gt; ，Repo Wiki 可以根据工程代码自动生成架构图谱、模块文档、API 手册以及依赖关系文档，帮助团队搭建工程框架，让成员快速了解工程结构。&lt;strong&gt;对于遗留系统研发&lt;/strong&gt; ，Repo Wiki 能快速分析工程结构，帮助开发者理解代码逻辑，解决遗留工程文档缺失或过时的问题。更为重要的是，&lt;strong&gt;工程中存在许多隐性知识&lt;/strong&gt; ，如设计决策考量、模块之间深层依赖关系等，这些知识通常散落在文档、邮件或口头交流中，难以被有效获取。Repo Wiki 能够将这些隐性知识显性化，以结构化的形式存储和呈现，方便开发者和智能体更全面、准确地理解代码工程。同时 Repo Wiki 对于&lt;strong&gt;软件代码的学习和传承&lt;/strong&gt;大有帮助，让开发者更快地理解陌生代码库，提高开发、学习和交接效率。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;今天， Repo Wiki 正式上线新功能：支持 Wiki 共享、编辑和导出。&lt;/strong&gt; 为了让知识更好地在团队中流转，Qoder 提供了 Wiki 共享能力。当用户在本地生成 Wiki 时，会自动在代码库中创建一个专属目录，只需将该目录推送至代码仓库，即可将生成的文档轻松共享给团队成员，实现协作共建。&lt;/p&gt; 
&lt;p&gt;此外，为确保 Wiki 与代码始终保持一致，Qoder 内置了自动检测机制。当发现代码变更导致文档滞后时，系统会及时提醒更新 Wiki。同时为了支持灵活自定义，开发者可以直接修改 Wiki 内容， 实现手工维护。&lt;/p&gt; 
&lt;p&gt;Qoder 目前在公测期，欢迎免费下载体验：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqoder.com%2F" target="_blank"&gt;https://qoder.com/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18691841</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18691841</guid>
      <pubDate>Sat, 13 Sep 2025 07:22:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>蚂蚁开源发布《大模型开源开发生态全景与趋势》报告</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁开源联合 Inclusion AI&amp;nbsp;发布了一份大模型开发生态下的开源项目全景图，和一份对生态趋势的洞察报告。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0915/151228_jv6C_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://antoss-landscape.my.canva.site/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;据悉，这是报告 5 月首次发布后的 2.0 版本，不仅全面揭示了人工智能开源领域的发展现状和未来趋势，还纳入了百余天内开源社区的新动向，为行业发展提供重要参考。&lt;/p&gt; 
&lt;p&gt;报告最初起源于蚂蚁集团内部的技术趋势洞察，其中的数据全部来源于开源社区，通过对 GitHub 全平台项目的分析，使用 OpenRank 算法对项目进行筛选和排名。&lt;/p&gt; 
&lt;p&gt;具体来看，本次发布的大模型开源开发生态全景图共收录了分布在 22 个技术领域的 114 个最受关注的开源项目，分为 AI Agent 和 AI Infra 两大技术方向。&lt;/p&gt; 
&lt;p&gt;据报告显示，在参与全景图项目开发的约 36 万全球开发者中，统计到美国开发者占比 24%，中国开发者占比 18%，其次是印度（8%）、德国（6%）和英国（5%）。中美两国合计贡献超四成核心力量。更值得关注的是，在大模型开源策略上，中国厂商更倾向于开放权重的开源模型路线，而美国头部厂商则多采用闭源模式。&lt;/p&gt; 
&lt;p&gt;和全景图一同发布的还有一份详尽的洞察报告《从社区数据出发，再看大模型开源开发生态全景与趋势》。该报告指出，62% 的大模型生态下的开源项目诞生于 2022 年 10 月「GPT 时刻」之后，平均「年龄」仅 30 个月，这反映出 AI 开源生态的高速迭代特性。&lt;/p&gt; 
&lt;p&gt;另外，AI 编程工具的爆发式增长也成为了瞩目的趋势。数据显示，2025 年新出现的 Coding 工具平均获得 3 万以上开发者 Star 关注，其中 Gemini CLI 开源仅 3 个月，星标数已突破 6 万，成为增长最快的项目之一。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372284</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372284</guid>
      <pubDate>Sat, 13 Sep 2025 07:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
