<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 23 Apr 2025 07:36:38 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>智元机器人开源仿真评测工具 Genie Sim Benchmark</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元机器人&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvAk6c0rzo6ps43uZsIc3kA&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;推出并开源基于仿真功能的模型评测和验证工具 Genie Sim Benchmark，专注为具身 AI 模型提供精准的性能测试和优化支持。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「作为 Genie Sim(智元仿真平台) 的开源评测版本，Genie Sim Benchmark 是智元继开源百万真机数据集和海量仿真数据集后，又一里程碑式的开源项目。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，Genie Sim 能够精准还原机器人的操作环境，为多样化任务提供标准化的自动评测体系，衡量模型在各种场景下的表现，加速算法迭代流程，同时减少模型评测对昂贵物理硬件的依赖，显著降低测试成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;218&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2361db80f04bdb27b0c1364779ea48b7643.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Genie Sim 构建了大规模的高精度具身智能三维资产库，形成了涵盖丰富物体、场景及机器人模型的完整仿真体系。所有资产均采用人工精细建模、三维重建与生成式 AI（AIGC）等技术打造，在确保高度真实性的同时兼顾种类多样性和资产生成效率，全面满足机器人复杂操作任务的仿真评测需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2bea77c14e21ac2be1c31034ea2d73f3cb0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;还提供了基于场景重建的高保真、高精度的仿真评测环境，涵盖多种场景和物体，高度还原真实世界。Genie Sim 的仿真评测环境能够模拟真实世界中影响算法性能的条件和变量，为模型评测提供高度真实的测试基准。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;智元方面表示，经对比验证，GO-1 模型仿真测试结果与真机结果误差小于 5%。这一仿真精度的突破源于对真机测试环境和交互物体在仿真环境中进行完全 1:1 的还原，以及底盘、关节和末端控制动力学与真机的精准校准。算法开发者可以高度信赖模型在仿真中的评测结果，大幅减少真机测试次数，使算法迭代效率提升 5 倍以上，测试成本减少 95%，助力研发团队专注核心算法优化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346159</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346159</guid>
            <pubDate>Wed, 23 Apr 2025 06:38:45 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>QEMU 10.0 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;QEMU 10.0 版本现已推出，一些更新&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fnews%2FQEMU-10.0-Released&quot; target=&quot;_blank&quot;&gt;亮点&lt;/a&gt;如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 LoongArch 的 KVM QEMU 现在支持 CPU 热插拔、para-virtualzied IPI、steam time 等功能。&lt;/li&gt; 
 &lt;li&gt;RISC-V QEMU 支持多种新的 ISA/扩展，添加了 Tenstorrent Ascalon CPU、Xiangshan Nanhu CPU 以及 Microblaze-V 通用主板。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 添加了英特尔 Clearwater Forest CPU 型号。此外，还有一个 Sierra Forest 「v2」 CPU 型号，与 QEMU 的原始 Sierra Forest CPU 型号相比有所改进。&lt;/li&gt; 
 &lt;li&gt;VirtIO SCSI 设备在 QEMU 10.0 中获得了「真正的」多队列支持。这种适当的多队列支持可以增强 I/O 可扩展性。&lt;/li&gt; 
 &lt;li&gt;QEMU 10.0 图形代码添加了新的「apple-gfx-pci」和「apple-gfx-mmio」设备，以便使用 macOS 主机的 para-virtualized&amp;nbsp;图形框架为 macOS 客户机提供加速图形。apple-gfx-pci 适用于 x86_64 guests，而 apple-gfx-mmio 适用于 AArch64 macOS。&lt;/li&gt; 
 &lt;li&gt;QEMU 10 的 VFIO 代码改进了所有 Gen11 和 Gen12 硬件的 Intel IGD 图形设备 pass-through 功能。&lt;/li&gt; 
 &lt;li&gt;QEMU VFIO 代码还增加了对旧版 ATI X550 GPU 的支持。&lt;/li&gt; 
 &lt;li&gt;Linux AIO 和 IO_uring 后端现在可以使用「RWF_DSYNC」标志进行 FUA 写入请求，而不是依赖模拟来提高已禁用写入缓存的 guest disks 性能。&lt;/li&gt; 
 &lt;li&gt;改进了 QEMU 文档。&lt;/li&gt; 
 &lt;li&gt;继续致力于在 QEMU 中支持更多 Rust 编程语言的使用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多详细信息可参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.qemu.org%2FChangeLog%2F10.0&quot; target=&quot;_blank&quot;&gt;Wiki 发行说明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.qemu.org%2Fdownload%2F%23source&quot; target=&quot;_blank&quot;&gt;下载地址&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346156/qemu-10-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346156/qemu-10-0-released</guid>
            <pubDate>Mon, 14 Apr 2025 06:29:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>探索 AI 未来：Xinference v1.5.0 模型虚拟空间全新上线！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Xorbits Inference（Xinference）是一个，性能强大且功能全面的，分布式，推理框架。可用于大语言模型（LLM），语音识别模型，多模态模型等各种模型的推理。通过 Xorbits Inference，你可以轻松地，一键部署你自己的模型或内置的前沿开源模型 - &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference%25E3%2580%2582%25E6%2597%25A0%25E8%25AE%25BA%25E4%25BD%25A0%25E6%2598%25AF%25E7%25A0%2594%25E7%25A9%25B6%25E8%2580%2585%25EF%25BC%258C%25E5%25BC%2580%25E5%258F%2591%25E8%2580%2585%25EF%25BC%258C%25E6%2588%2596%25E6%2598%25AF%25E6%2595%25B0%25E6%258D%25AE%25E7%25A7%2591%25E5%25AD%25A6%25E5%25AE%25B6%25EF%25BC%258C%25E9%2583%25BD%25E5%258F%25AF%25E4%25BB%25A5%25E9%2580%259A%25E8%25BF%2587&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference。无论你是研究者，开发者，或是数据科学家，都可以通过&lt;/a&gt; Xorbits Inference 与最前沿的 AI 模型，发掘更多可能。 &amp;nbsp; Xinference 的功能和亮点有：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌟 模型推理，轻而易举：大语言模型，语音识别模型，多模态模型的部署流程被大大简化。一个命令即可完成模型的部署工作。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚡️ 前沿模型，应有尽有：框架内置众多中英文的前沿大语言模型，包括 baichuan，chatglm2 等，一键即可体验！内置模型列表还在快速更新中！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🖥 异构硬件，快如闪电：通过 ggml，同时使用你的 GPU 与 CPU 进行推理，降低延迟，提高吞吐！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;⚙️ 接口调用，灵活多样：提供多种使用模型的接口，包括 OpenAI 兼容的 RESTful API（包括 Function Calling），RPC，命令行，web UI 等等。方便模型的管理与交互。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🌐 集群计算，分布协同：支持分布式部署，通过内置的资源调度器，让不同大小的模型按需调度到不同机器，充分使用集群资源。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🔌 开放生态，无缝对接：与流行的三方库无缝对接，包括 LangChain， LlamaIndex， Dify，以及 Chatbox。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🎉 Xinference v1.5.0 重磅发布！&lt;/p&gt; 
&lt;p&gt;🚀 重点亮点&lt;/p&gt; 
&lt;p&gt;🧩 模型虚拟空间正式上线！&lt;/p&gt; 
&lt;p&gt;随着模型更新频繁，不同模型对依赖的要求也越来越复杂，老模型需要老版本库，新模型又依赖新版包，常常出现互相冲突的问题。 现在，通过模型虚拟空间，每个模型可以独立拥有一套安装包环境，相互隔离、互不影响，模型运行更稳定！ 📄 配置与使用方式详见文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🖥️ 易用性增强&lt;/p&gt; 
&lt;p&gt;🔄 模型加载支持展示进度，也可随时取消模型加载 🧠 Gradio 聊天界面支持展示思考过程（🧪 需打开「解析思维过程」）&lt;/p&gt; 
&lt;p&gt;🧪 社区版&lt;/p&gt; 
&lt;p&gt;📦 更新指南&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📥 pip：pip install &#39;xinference==1.5.0&#39;&lt;/li&gt; 
 &lt;li&gt;🐳 Docker：拉取最新版本即可，也可以直接在镜像内用 pip 更新。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📝 更新日志&lt;/p&gt; 
&lt;p&gt;🆕 新模型支持&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤖 LLM &amp;nbsp; &amp;nbsp; * 🌐 GLM-4 0414 &amp;nbsp; &amp;nbsp; * 🧠 Qwen2.5-Omni &amp;nbsp; &amp;nbsp; * ☁️ Skywork-OR1-preview&lt;/li&gt; 
 &lt;li&gt;🖼️ 多模态 &amp;nbsp; &amp;nbsp; * 🔍 InternVL3（已支持 AWQ 量化） &amp;nbsp; &amp;nbsp; * 🌊 SeaLLMs-v3 &amp;nbsp; &amp;nbsp; * 🗣️ Paraformer-ZH &amp;nbsp; &amp;nbsp; * 🛰️ Megatts3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🛠️ 功能增强&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧠 Gradio 聊天界面支持展示思考过程（需打开「解析思维过程」）&lt;/li&gt; 
 &lt;li&gt;📐 Vision 模型支持 min/max_pixels 控制输入分辨率&lt;/li&gt; 
 &lt;li&gt;📥 模型下载支持进度显示与取消&lt;/li&gt; 
 &lt;li&gt;⚙️ 默认并发数设置为 CPU 核心数&lt;/li&gt; 
 &lt;li&gt;🧪 支持 InternVL3 的 AWQ 推理&lt;/li&gt; 
 &lt;li&gt;🏎️ 默认使用最新版 xllamacpp 引擎&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🐛 BUG 修复&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧊 修复 vLLM 引擎停止时卡住的问题&lt;/li&gt; 
 &lt;li&gt;🧩 修复 llama.cpp 多分片模型加载失败&lt;/li&gt; 
 &lt;li&gt;📂 修复 GGUF 模型路径错误&lt;/li&gt; 
 &lt;li&gt;🧮 修复量化参数不生效问题&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 文档更新&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📘 kokoro 使用指南&lt;/li&gt; 
 &lt;li&gt;📘 模型虚拟空间特性： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Finference.readthedocs.io%2Fzh-cn%2Flatest%2Fmodels%2Fvirtualenv.html&quot; target=&quot;_blank&quot;&gt;https://inference.readthedocs.io/zh-cn/latest/models/virtualenv.html&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🏢 企业版&lt;/p&gt; 
&lt;p&gt;🎬 支持文生视频界面，企业版新增文生视频模块界面，AI 视频创作更直观、操作更友好。 🚀 升腾适配能力增强，适配模型范围进一步扩展，支持更多模型在升腾上稳定高效运行。&lt;/p&gt; 
&lt;p&gt;我们感谢每一位参与的社区伙伴对 Xinference 的帮助和支持，也欢迎更多使用者和开发者参与体验和使用 Xinference。 &amp;nbsp; 欢迎您在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxorbitsai%2Finference&quot; target=&quot;_blank&quot;&gt;https://github.com/xorbitsai/inference&lt;/a&gt; 给我们一个，星标，这样你就可以在 GitHub 上及时收到每个新版本的通知。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346151/xinference-1-5-0</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346151/xinference-1-5-0</guid>
            <pubDate>Mon, 14 Apr 2025 06:19:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>腾讯混元 3D 生成模型发布 2.5 版本新模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯混元 3D 生成模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fv6BJ2ZyvInnj_zopaC2z5Q&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;正式推出 2.5 版本新模型，多视图支持 pbr 贴面，不仅能上传多图，细节还更丰富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时建模精细度上大幅提升。v2.5 版本模型架构全面升级，总参数量从 1B 提升至 10B，有效面片数增加超 10 倍，实现超高清的几何细节建模，表面更平整、边缘更锐利、细节更丰富，有效几何分辨率达到 1024。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-067b104bbcf24a734d5cd7f472b98205ff4.gif&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b86aada5a6ce301269b3cc5b4cba07f42fb.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新版本支持 4K 高清纹理和细粒度 bump 凹凸贴图，能够模拟物体表面高低起伏的视觉效果。此外，为满足专业创作者需求，混元 3D v2.5 优化了骨骼蒙皮系统，支持非标准姿态下的自动骨骼绑定和自动蒙皮权重赋值，大幅提升 3D 动画生成效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3D 生成工作流功能也进一步升级，提供文生/图生 3D 智能减面模型、多视图生 3D 模型等专业管线模板，用户可根据场景选择对应生产管线、灵活调整参数，生成特定风格和特征的 3D 资产，助力游戏开发、动画制作等垂直场景的高效搭建。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;混元 3D AI 创作引擎全面更新至 v2.5 模型底座，同时免费生成额度翻倍，提升至每天 20 次。混元 3D 生成 API 也已正式上线腾讯云，面向企业和开发者开放。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346148</guid>
            <pubDate>Mon, 14 Apr 2025 05:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>清华博士带队，发布全球首个自回归视频生成大模型「Magi-1」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，由清华博士曹越创立的 Sand.AI，公布了一款名为「Magi-1」的自回归视频生成模型，其主打两个能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;无限长度扩展：通过前一段生成的内容进行后一段视频的制作，从而实现跨时间的无缝连贯敍事；&lt;/li&gt; 
 &lt;li&gt;生成时长控制精准到每一秒。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115406_dDdh_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;而从公布的数据显示，具体性能测试结果如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Physics-IQ（对多种物理定律的理解）基准测试：Magi-1 获得 56.02% 的高分成绩，超越可灵 1.6、Sora 等一众模型；&lt;/li&gt; 
 &lt;li&gt;人类评估：与海螺、腾讯混元、通义万相 Wan2.1 相比，Magi-1 在指令跟随和运动质量等方面更具优势，但与可灵 1.6 在视觉质量存在差距；&lt;/li&gt; 
 &lt;li&gt;VBench-I2V 基准：Magi-1（2 倍解码器）以 89.28 的高分排名第一，在动态程度（Dynamic Degree）上有较大优势。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0423/115713_mOF3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;技术上，Magi-1 整体架构基于 Diffusion Transformer，采用 Flow-Matching 作为训练目标。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1247121c5ed762e2b9adea14a9780bf743.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;值得一提的是，据公布的信息显示，Magi-1 通过自回归去噪方式预测固定长度的视频片段，提高了视频生成效率和前后因果性（保证前后内容生成逻辑一致）。&lt;/p&gt; 
&lt;p&gt;目前，Magi-1 已上架 Sand.AI 官网（可以免费体验！），并且模型权重、代码也进行 100% 开源，技术报告也进行全面公布。&lt;/p&gt; 
&lt;p&gt;而背后的 Sand.AI 创始人为曹越，其博士毕业于清华大学软件学院，并于 2018 年获清华大学特等奖学金。曹越于 2022 年创办 AGI 公司「光年之外」，后加入智源研究院领导多模态与视觉研究中心。随后在 2023 年，曹越创立了 Sand.AI，并很长一段时间与其他成员保持「隐身」状态。&lt;/p&gt; 
&lt;p&gt;团队成员方面，有不少与曹越有着类似的历程：智源研究院实习、光年之外创始成员、微软亚洲研究院实习等等。另据了解，San.AI 已完成三轮融资，主要参与方包括今日资本、经纬创投等。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;体验链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsand.ai%2F&quot; target=&quot;_blank&quot;&gt;https://sand.ai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSandAI-org%2FMagi-1&quot; target=&quot;_blank&quot;&gt;https://github.com/SandAI-org/Magi-1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HuggingFace：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fsand-ai%2FMAGI-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/sand-ai/MAGI-1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346129/sand-ai-magi1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346129/sand-ai-magi1</guid>
            <pubDate>Mon, 14 Apr 2025 03:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenBMB 开源社区推出代码 Agent「卷姬」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenBMB 开源社区宣布推出代码 Agent 新成员「卷姬」，官方介绍其能够「高效获取有价值的内容」。&lt;/p&gt; 
&lt;p&gt;具体来看，用户只需要在「卷姬」官网输入想要提取的内容，便可在等待后获取到综述报告。而「卷姬」拥有两种处理模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;普通模式：输出标题和关键词描述，提交并等待生成。&lt;/li&gt; 
 &lt;li&gt;专业模式：可进一步自定义素材来源，选择「在线检索」或「上传文件」。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aea0d199a34728e37f357830ab2a77c6f59.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;团队方面表示，卷姬 SurveyGO 与 OpenAI DeepResearch、AutoGLM-沉思和 Gemini DeepResearch 相比，它的逻辑更严谨、学术性更强，适合深度分析，在多个方面有着不同的优势体现：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;结构维度：SurveyGO 生成文章的目录层次分明；&lt;/li&gt; 
 &lt;li&gt;内容维度：SurveyGO 导言部分更具深度，结尾分析更见功力，角度全面，丝滑缜密；&lt;/li&gt; 
 &lt;li&gt;观点维度、引用维度：论述详细，辅以合理的引用支持，观点有理有据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;据悉，卷姬 SurveyGO 采用 LLMxMapReduce-V2 长文本整合生成技术。该技术由 AI9Star、OpenBMB、清华大学团队联合研发，核⼼在于借助⽂本卷积算法实现多篇参考⽂献的聚合来代替现有⽅法中常⻅的检索，从⽽实现对全部参考⽂章的充分利⽤。&lt;/p&gt; 
&lt;p&gt;目前，卷姬已上线官网，LLMxMapReduce-V2 的相关论文和开源内容也已公布。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;体验链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsurveygo.thunlp.org%2F&quot; target=&quot;_blank&quot;&gt;https://surveygo.thunlp.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2504.05732&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2504.05732&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;开源链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fthunlp%2FLLMxMapReduce%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://github.com/thunlp/LLMxMapReduce/tree/main&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346126</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346126</guid>
            <pubDate>Mon, 14 Apr 2025 03:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>宝马计划年内在中国新车型中引入 DeepSeek 的 AI 技术</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;在近日于上海举行的汽车展上，德国汽车制造商宝马（BMW）宣布，将于今年晚些时候在其新车型中集成中国初创公司 DeepSeek 的人工智能技术。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;这次合作的具体细节虽然尚未完全披露。&lt;/span&gt;宝马首席执行官奥利弗・齐普塞 (Oliver Zipse) 在展会上表示，这一举措标志着宝马在中国市场进一步加强与本地科技公司的合作。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-977e8740166a69b506b93255cfe68566f85.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;齐普塞强调，中国在人工智能领域的创新步伐迅速，宝马希望借助这种技术提升其汽车的智能化水平。「在这里，AI 技术正在飞速发展。我们正在加强与当地公司的合作，以便将这些先进的人工智能技术整合进我们的车辆中。」&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#242424&quot;&gt;此外，宝马在汽车电动化和智能化方面的努力也在不断加码。随着全球汽车市场向电动和智能化转型，宝马希望通过与 DeepSeek 的合作，增强在这些领域的竞争力。齐普塞提到，未来的汽车将不仅仅是交通工具，更会成为用户生活的智能助手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346115</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346115</guid>
            <pubDate>Mon, 14 Apr 2025 03:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英伟达终止 Lepton AI 运营</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，网上曝出 Lepton AI 已通知用户，Lepton 将于 2025 年 5 月 20 日正式停止运营，此后用户将无法再访问 Lepton AI 平台上的服务或提交的数据，建议用户在该日期之前尽快下载或备份所需数据。服务终止时，若用户账户中仍有未使用的积分，官方将会在关停后予以退款处理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105739_VR8C_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不仅如此，官方网站已经禁止新账户注册，显示正在维护。Lepton AI 的官方推特显示也已经被注销。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105705_sxuq_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/105711_hYyj_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;收购消息刚被曝出来时，许多人猜测英伟达收购后是会仅保留机器学习人才、大砍业务，还是会继续运营 Lepton AI 的云平台。目前看来，英伟达似乎更在意的人才，而非其相关具体业务，毕竟如今已经选择了关闭服务。交易完成时 Lepton AI 约有 20 名员工，目前还未有消息指出这些员工的去留。&lt;/p&gt; 
&lt;p&gt;英伟达此番价值可能达数亿美元的收购，实现了让 LeptonAI 投资方红杉中国、CRV 和 Fusion Fund 较为可观的退出，大约在两年前他们参与了该公司 1100 万美元的种子轮融资。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;阅读更多：&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/341235&quot; target=&quot;news&quot;&gt;英伟达正在洽谈收购贾扬清创业公司 Lepton AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/343328&quot; target=&quot;news&quot;&gt;贾扬清已入职英伟达&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346110</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346110</guid>
            <pubDate>Mon, 14 Apr 2025 02:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Apache NetBeans 25 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Apache NetBeans 25&lt;span&gt;&amp;nbsp;现&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fblogs%2Fentry%2Fannounce-apache-netbeans-25-released%2F&quot; target=&quot;_blank&quot;&gt;已正式发布&lt;/a&gt;。NetBeans 是一个主要面向 Java 的集成开发环境，同时支持 C/C++、PHP、JavaScript 和其他编程语言。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;一些更新内容包括：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Note&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Platform users：此版本通过设置&lt;code&gt;-J-DTopSecurityManager.disable=true&lt;/code&gt;(&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8169&quot; target=&quot;_blank&quot;&gt;#8169&lt;/a&gt;) 禁用了 NetBeans 内部安全管理器层。以 JDK 21 或更高版本为目标平台的现有应用程序应手动将此选项添加到其 launcher.conf 中。NetBeans 26 移除了安全管理器层，因此该 flag 无效 (&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fissues%2F8258&quot; target=&quot;_blank&quot;&gt;#8258&lt;/a&gt;&amp;nbsp;)。另请参阅&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenjdk.org%2Fjeps%2F486&quot; target=&quot;_blank&quot;&gt;JEP 486&lt;/a&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gradle&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;EST 单个文件应该适用于名称与相应文件名不匹配的测试类。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8021&quot; target=&quot;_blank&quot;&gt;#8021&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;并行运行测试的操作&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7979&quot; target=&quot;_blank&quot;&gt;#7979&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Gradle init 应遵循配置 Java 运行时&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8223&quot; target=&quot;_blank&quot;&gt;#8223&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Maven&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Maven：改进依赖项解析（例如，对于像 lombok 这样的注释处理器）&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8057&quot; target=&quot;_blank&quot;&gt;#8057&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Maven 远程索引迁移和重构&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7976&quot; target=&quot;_blank&quot;&gt;#7976&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 ProjectReload 中缺失的工件&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7855&quot; target=&quot;_blank&quot;&gt;#7855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;候选版本不应该窃取 GA 版本中的 Maven 索引&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8199&quot; target=&quot;_blank&quot;&gt;#8199&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 FruchtermanReingoldLayout 中的无限循环&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8217&quot; target=&quot;_blank&quot;&gt;#8217&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 maven 索引器的查询限制&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8198&quot; target=&quot;_blank&quot;&gt;#8198&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Ant&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修复大规模 Ant 项目打开时出现的 ConcurrentModificationException&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7989&quot; target=&quot;_blank&quot;&gt;#7989&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在 WSL 上运行的 Payara Server 实例在保存时部署会破坏「Web 应用程序」Ant 项目&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8144&quot; target=&quot;_blank&quot;&gt;#8144&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:start&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Java&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;修复 Windows 上由于 java.hints、java.source.base 中的 CRLF 不匹配导致的测试失败&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7910&quot; target=&quot;_blank&quot;&gt;#7910&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 MacOS 中 java.hints 测试失败问题&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7926&quot; target=&quot;_blank&quot;&gt;#7926&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;将嵌入式 tomcat 从 9.0.71 更新到 9.0.96&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7919&quot; target=&quot;_blank&quot;&gt;#7919&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 java/j2ee.persistence 测试并将其添加到构建管道中&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7943&quot; target=&quot;_blank&quot;&gt;#7943&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;修复 switch 模式提示中可能出现的越界异常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7973&quot; target=&quot;_blank&quot;&gt;#7973&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7949] 修复「case null」的处理&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7980&quot; target=&quot;_blank&quot;&gt;#7980&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;确保 AttrContext.returnResult 的 checkContext 在 javac 的 Scopes 中设置为 Check.basicHandler，以避免其抛出异常&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8016&quot; target=&quot;_blank&quot;&gt;#8016&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;将 CI jobs 降级至 JDK 23&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8061&quot; target=&quot;_blank&quot;&gt;#8061&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;提高 Java 代码补全（sealed）测试的稳定性&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8066&quot; target=&quot;_blank&quot;&gt;#8066&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;合并 jakarta.web.beans 和 web.beans&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7958&quot; target=&quot;_blank&quot;&gt;#7958&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;更新 textmate 支持&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7971&quot; target=&quot;_blank&quot;&gt;#7971&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;将 nb-javac 升级到 JDK 24b29&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8037&quot; target=&quot;_blank&quot;&gt;#8037&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[NETBEANS-7069] 支持 Nashorn 15.x for JDK &amp;gt;= 15&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F7972&quot; target=&quot;_blank&quot;&gt;#7972&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;apidoc 拼写错误修复&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8148&quot; target=&quot;_blank&quot;&gt;#8148&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;仅在 JDK 23 及更高版本上设置 javadoc 23 特定标志&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Fpull%2F8152&quot; target=&quot;_blank&quot;&gt;#8152&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;......&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多详情可查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fnetbeans%2Freleases%2Ftag%2F25&quot; target=&quot;_blank&quot;&gt;https://github.com/apache/netbeans/releases/tag/25&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnetbeans.apache.org%2Ffront%2Fmain%2Fdownload%2Fnb25%2F&quot; target=&quot;_blank&quot;&gt;https://netbeans.apache.org/front/main/download/nb25/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346107/apache-netbeans-25-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346107/apache-netbeans-25-released</guid>
            <pubDate>Mon, 14 Apr 2025 02:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 有意愿收购谷歌 Chrome 浏览器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fgoogle-contemplated-exclusive-gemini-ai-deals-with-android-makers-2025-04-22%2F&quot;&gt;路透社报道称&lt;/a&gt;，OpenAI 旗下 ChatGPT 产品负责人表示，&lt;strong&gt;若反垄断执法人员成功迫使 Alphabet（Google 母公司）出售 Chrome 浏览器，OpenAI 将有意收购谷歌 Chrome 浏览器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0423/102749_NjaW_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此前，美国法官 Amit Mehta 判定谷歌的 Chrome 浏览器涉及垄断行为，该公司需从本周一开始采取补救措施，而谷歌计划针对该判决上诉。&lt;/p&gt; 
&lt;p&gt;检察官在当地周一的开庭陈述上表示，谷歌搜索垄断可能会令其在 AI 方面带来优势。谷歌则表示，提供生成式 AI 产品的公司会存在竞争，谷歌还在庭审中提供了一份 OpenAI 的内部文件，这份文件称 ChatGPT 在消费级 AI 聊天机器人市场中处于领先地位，并不认为谷歌是其最大竞争对手。&lt;/p&gt; 
&lt;p&gt;ChatGPT 产品负责人 Nick Turley 表示，&lt;strong&gt;OpenAI 去年曾与谷歌联系，商讨建立潜在合作关系，让 ChatGPT 使用谷歌的搜索技术&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;Turley 认为，ChatGPT 若能使用谷歌搜索的 API，那将能为用户提供更好的 AI 产品。据悉，OpenAI 于去年 7 月首次联系谷歌，但后者在 8 月以「涉及太多竞争对手」为由，拒绝了上述合作。&lt;/p&gt; 
&lt;p&gt;OpenAI 一直在开发自己的搜索工具，虽然 OpenAI 原本希望在 2025 年底之前让 ChatGPT 上线搜索功能并依靠该引擎完成 80% 的搜索工作，但 Turley 在作证时表示，该公司现在认为达到这一成绩仍需要数年时间。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/322108/openai-hires-former-chrome-engineer&quot;&gt;又一名 Chrome 创始工程师加入 OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/321528/openai-considers-taking-on-google-with-browser&quot;&gt;OpenAI 考虑开发浏览器，与谷歌竞争&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346103/openai-chrome-google-us-judge</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346103/openai-chrome-google-us-judge</guid>
            <pubDate>Mon, 14 Apr 2025 02:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Manus 开源平替，Kortix-AI 发布开源通用 AI 智能体平台 Suna</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Kortix-AI 正式发布开源通用 AI 智能体平台 Suna，定位为热门 AI 工具 Manus 的开源替代品。Suna 集成了浏览器自动化、文件管理、网络爬虫、扩展搜索、命令行执行、网站部署及 API 集成等功能，通过自然语言对话实现复杂任务的自动化处理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;305&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-01ba5fdfe0002965d001a22e6205e28616c.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;主要功能：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;浏览器自动化：通过内置浏览器控制模块，Suna 可自主导航网页、点击元素、填写表单并提取数据，适用于任务如价格比较或表单提交。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;文件管理：支持文档创建、编辑与组织，允许用户通过对话指令生成报告或管理项目文件。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;网络爬虫与扩展搜索：具备高效的网页抓取与信息检索能力，可跨平台搜索并整合数据，如分析社交媒体评论或市场趋势。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;命令行执行：支持运行系统命令与脚本，自动化本地任务，如批量文件处理或服务器管理。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;网站部署：提供一键式网站部署功能，结合 API 集成，简化从开发到上线的流程。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;API 与服务集成：通过 LiteLLM 支持 OpenAI、Anthropic 等多种大语言模型（LLM），并可连接 Supabase、GitHub 等外部服务，扩展功能边界。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Suna 发布后，社区对其开源性与功能全面性给予高度评价。开发者称其「将 Manus 的商业能力带入开源领域」，尤其在自动化复杂任务方面表现优异。 然而，部分用户指出，自托管的初始配置需一定技术背景，建议 Kortix 推出更简化的云端部署选项。社区已在探讨增强 Suna 的多模态能力，如支持图像生成与实时语音交互。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346097</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346097</guid>
            <pubDate>Mon, 14 Apr 2025 02:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DistilQwen2.5-DS3-0324 发布：知识蒸馏 + 快思考 = 更高效解决推理难题</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：蔡文睿（清素）、汪诚愚（熊兮）、严俊冰（玖烛）、黄俊（临在）&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;在大语言模型领域的快速发展中，如何&lt;strong&gt;有效平衡高效推理和模型思维能力&lt;/strong&gt;之间的矛盾一直是学术界和工业界关注的重点。DeepSeekV3-0324 默认没有采用深度思考的模式，使得模型推理速度更快，兼顾了快速推理和复杂任务处理之间的平衡。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DistilQwen&lt;/strong&gt; &lt;strong&gt;系列&lt;/strong&gt;是阿里云人工智能平台 PAI 推出的蒸馏语言模型系列，包括&lt;strong&gt;DistilQwen2、DistilQwen2.5、DistilQwen2.5-R1&lt;/strong&gt; 等。在此次工作中，我们将 DeepSeekV3-0324 基于快思考的推理能力成功迁移到更轻量的小模型中，全新推出 &lt;strong&gt;DistilQwen2.5-DS3-0324&lt;/strong&gt;。在继承了原始模型思维链蒸馏的精华的同时，引入了&lt;strong&gt;快思考策略&lt;/strong&gt;，显著提升了推理速度，使得在资源受限的设备和边缘计算场景中，模型能够高效执行复杂任务。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;实验显示，DistilQwen2.5-DS3-0324 系列模型在多个基准测试中表现突出，其 32B 模型效果甚至接近参数量接近其 10 倍的闭源大模型。在复杂问题解决方面，也大幅降低了思维链的长度，展示了卓越的效率。&lt;strong&gt;DistilQwen2.5-DS3-0324 系列的发布，助力「大模型+快思考」的新模式&lt;/strong&gt;，逐步成为解决推理难题的标准配置。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a44937451ac82d3b8c6ed1970704e0dd.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;为方便开发者和企业在实际应用中使用 DistilQwen2.5-DS3-0324 系列模型，已将所有的 Checkpoint 在 Hugging Face 和 Model Scope 开源社区中公开。本文将深入阐述 DistilQwen2.5-DS3-0324 的蒸馏算法、性能评估，并且提供在阿里云人工智能平台 PAI 上的使用指南及相关下载教程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 中的蒸馏技术&lt;/h1&gt; 
&lt;p&gt;本节中，我们主要描述 DistilQwen2.5-DS3-0324 系列模型训练中使用的数据增强与知识蒸馏技术。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;推理模型通过深度思考可以解决复杂的推理任务，但这种深度思考也带来了大规模的计算资源需求。模型思考的过程中一般都有反思机制的参与，其会反复推敲模型已有的推理步骤，确保每个步骤都正确推进。这种反思机制在提高推理准确率的同时，也会不可避免地带来一些重复冗余的部分，导致推理模型所需的计算资源居高不下。因此，取得模型深度思考和快速回答间的平衡显得格外重要。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此外，蒸馏模型的参数量普遍较小。而由于自身参数量的显著差异，大模型与小模型的认知与推理轨迹有时并不完全一致。以数学问题为例：小模型由于自身参数量的限制，会倾向于使用更基础的方法去解决问题。而大模型基于其强大的推理能力，会采用较为高阶的方法。正是由于大小模型的认知轨迹偏差，小模型有时无法有效理解大模型的思维链。如果直接将大模型的思维链全部蒸馏到小模型中，往往无法达到最优效果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;针对这些问题，我们设计了一种小型推理模型蒸馏框架，主要包含 2 个阶段：快思考 CoT 数据收集，CoT 轨迹认知对齐。该框架可以让模型在快速思考的同时，消除认知轨迹偏差带来的负面影响。我们通过第一阶段收集大模型的快思考数据，在第二阶段对快思考数据进行与小模型的认知能力对齐，最终使用对齐后的快思考 CoT 对 Qwen2.5 系列基座小模型进行监督微调（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;快思考 CoT 数据收集&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，模型深度思考和快速回答间的平衡显得格外重要。如果模型的中间思考步骤出现错误，此时的反思机制可以有效帮助模型自查纠错。但如果模型输出的是正确的思考步骤，此时反复的自查思考反而会导致不必要的资源浪费。因此，我们需要一种快思考 CoT，其保留了必要的推理和自查纠错步骤，同时去除了不必要的重复冗余部分。这种快思考 CoT 大幅缩减了推理长度，可以帮助模型进行快速思考和快速回复，在资源受限场景中高效完成任务。我们的快思考 CoT 数据主要来源于：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;推理大模型 CoT 数据的 Long To Short 思维链改写。基于 DeepSeek-R1 的推理数据，我们从中提炼关键步骤，生成更高效、简洁的推理路径。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;快思考大模型蒸馏。我们认为 DeepSeek-V3-0324 的输出具备快思考的特点，我们从中蒸馏出一些推理轨迹，涵盖数学、代码和科学问题等多个领域。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;特别的，针对推理大模型产生的思维链过于冗长的问题，我们进一步使用 QwQ-32B 对思维链进行改写，其功能在于精简思维链长度，降低蒸馏模型的输出 token 数量，同时，保证思维链的正确性，避免错误传播到蒸馏模型中。使用大模型进行 Long To Short 思维链改写的 Prompt 如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at simplifying reasoning processes.
Given a problem, its answer and its reasoning process, your task is to simplify the reasoning process so that a small language model (e.g., a 7B model) can reliably follow the steps to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the simplified reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;CoT 轨迹认知对齐&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，大小模型间的认知推理轨迹有时存在显著偏差。因此，对于待蒸馏的大模型快思考 CoT 数据集，小模型可能无法有效理解全部内容。举例来说，对于计算直角边分别为 3 和 4 的三角形面积，大模型可能使用线性代数进行求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4323edb8ff0d97ef14445f75c67e3c21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;这种方式对小模型而言比较难以学会，其一般采用简单的算术方法求解：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c9971930330f9f1c83cb1fa794fe13a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;因此，直接将大模型的输出蒸馏到小模型容易造成小模型难以拟合的问题。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们采用了 LLM-as-a-Judge 的范式，对大模型的推理过程进行评价并改进。给定问题、大模型的推理过程和问题的答案，我们使用模型判断这个推理过程是简单、中等还是困难。难度等级的核心标准是小模型是否能够遵循给定的推理过程得到问题的答案。以下是思维链的难度等级及定义：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中等： 小模型可以遵循该推理过程得到问题的答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;简单： 给定的推理过程过于简单，缺少小模型所需的必要步骤，导致大模型可以依赖其强大的推理能力解决问题，但小模型无法遵循该过程得到答案。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;困难： 给定的推理过程过于复杂或过于困难，导致小模型无法遵循该过程得到答案。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;其中，我们使用如下 Prompt 调用 QwQ-32B 模型进行思维链难度的估计：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a highly capable evaluator.
Your task is to assess the given reasoning process from the perspective of a small language model (e.g., 7B). 
Specifically, determine whether the reasoning process provides sufficient detail for a small model to solve the problem, or whether it is too simplistic (i.e., lacking critical details) or too complex (i.e., containing unnecessary or confusing steps). 

Difficulty Definitions (from the perspective of a small model): 
- Easy: The reasoning process is overly simplistic relative to the problem&#39;s difficulty; it omits essential details that a small model needs to solve the problem.
- Medium: The reasoning process is appropriately balanced, offering enough detailed guidance.
- Hard: The reasoning process is overly complex, with extraneous or convoluted steps that could hinder a small model&#39;s ability to follow it. 

Output Format:
You must output exactly one word: easy, medium, or hard. Do NOT provide any additional text, explanation.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;基于一个大模型的问题与思维链集合，我们可以将其分为简单、中等和困难三类。对于评级为中等的部分，我们予以保留。对于被评为简单和困难的数据，我们使用模型对思维链进行改进。具体来说：对于简单部分，我们扩展其推理过程，直至小模型可以遵循扩展的过程得到答案。对于评级为困难的部分，我们精简其推理过程，直至小模型可以遵循精简的过程得到答案。精简思维链的过程可以参考 Long To Short 的 Prompt 示例。扩展思维链的过程与 Long To Short 相反，其 Prompt 模版如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You are a helpful assistant who is highly skilled at extending reasoning processes.
Given a problem, its answer and its reasoning process, your task is to extend the reasoning process by adding necessary details and intermediate steps so that a small language model (e.g., a 7B model) can follow the extended reasoning process to solve the problem. \\
If the original reasoning process is divided into multiple steps separated by two newline characters, your output must preserve this formatting. \\
You must output ONLY the extended reasoning process with no additional explanation or commentary.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们之后对改进结果进行进一步验证，包括：对改进后的思维链再次评价难度等级，检测其是否被归类为中等难度。如果改进后的思维链通过验证，说明改进有效，该数据可以被小模型有效理解，我们将其保留。如果验证不通过，说明改进无效，我们将返回到改进步骤，重新进行改进，直至通过验证。最终，我们获取了优化后的思维链数据集，其组成部分如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;初始难度评级为中等的数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始难度评级为简单，经过改进扩展后评为中等并通过验证的数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始难度评级为困难，经过改进精简后评为中等并通过验证的数据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此时，数据集内所有思维链的最终难度评级均为中等，意味着小模型可以有效理解数据集内的所有思维链，并能遵循这些思维链解决相应推理问题。上文提到的大小模型认知轨迹偏差问题在改进后的数据集中得到妥善解决，其可能带来的负面影响也被消除。相关流程如下所示：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//688591ec35d4073130ee1caaf6bd497c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关工作参考论文 Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们在第二阶段使用这种 CoT 轨迹认知对齐机制对得到的快思考 CoT 数据进行优化，最终使用优化后的数据集对 Qwen2.5 系列基座模型进行监督微调（SFT），得到 DistilQwen2.5-DS3-0324 系列模型。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5-DS3-0324 模型效果评测&lt;/h1&gt; 
&lt;p&gt;在本节中，我们从多个角度评测 DistilQwen2.5-DS3-0324 系列蒸馏小模型在推理任务上的实际效果；同时，我们将通过统计数据印证 DistilQwen2.5-DS3-0324 系列模型推理的快速性和高效性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型综合能力评测&lt;/h2&gt; 
&lt;p&gt;我们在多个模型推理能力评测基准上测试了 DistilQwen2.5-DS3-0324 系列模型的能力，涵盖数学、代码和科学问题三个主流推理领域。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数学领域：采用 AIME2024 和 MATH-500 两个基准。AIME2024 为美国数学邀请赛的 2024 年测试集，含 30 道高难题，聚焦代数与几何等复杂推理能力；MATH-500 涵盖 500 道题，旨在全面考察模型在数学解题上的能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代码领域：使用 LiveCodeBench V2，其包含 2023 年 5 月-2024 年 5 月的 511 个代码问题，测试模型在高难度编码、自我修复和执行测试等方面的综合能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;科学问题领域：使用 GPQA-Diamond 和 MMLU-PRO。前者为高质量专家级科学问题集（共 198 题），后者涵盖 12,000+道题，强调模型的复杂推理能力而非仅靠知识检索，精准追踪大模型在推理任务上的进步和不足。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;如下图所示，DistilQwen2.5-DS3-0324 系列模型在 7B、14B 和 32B 四个参数量级的模型中，与原始 Qwen2.5 模型的效果进行了对比。可以看出，DistilQwen2.5-DS3-0324 系列模型的推理能力在多个评测基准上取得了一致而明显的效果提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们还将 DistilQwen2.5-DS3-0324-32B 与当前主流的非推理大模型作了比较，结果如下图所示。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//4774cc392eb93d60a2c732815125d227.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;可以看出，尽管这些大模型的参数量是自己的数十倍，DistilQwen2.5-DS3-0324-32B 依旧在这些推理基准上取得了相对不错的结果。其中，DistilQwen2.5-DS3-0324-32B 在 AIME2024 和 MATH-500 两个基准上高于多个闭源大模型（例如 Qwen-Max 和 Claude-Sonnet-3.7），在 LiveCodeBench 超过了其他所有大模型，包括其教师模型 DeepSeek-V3-0324。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;平衡精度和输出 Token 数量&lt;/h2&gt; 
&lt;p&gt;为展示 DistilQwen2.5-DS3-0324 系列模型高效推理效果，以 32B 模型为例，我们分别统计了 DistilQwen2.5-DS3-0324 模型和 DistilQwen2.5-R1 系列模型在各个推理 benchmark 上输出的平均 token 数。可以看出，相较于采用深度思考进行推理的模型，DistilQwen2.5-DS3-0324 系列模型推理输出的 token 数量大幅降低，与 DeepSeek-V3-0324（teacher model）的输出 Token 数相当，兼顾了快速推理和复杂任务处理。这种快思考的特点使得 DistilQwen2.5-DS3-0324 系列模型在资源受限的设备和边缘计算场景中依旧能高效解决复杂推理任务。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//85ba45740e3afe28cb2efa233a239871.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型输出案例&lt;/h2&gt; 
&lt;p&gt;我们在此列举一些有趣的小例子，以体现 DistilQwen2.5-DS3-0324 系列模型强大的代码能力。以下 case 均为 DistilQwen2.5-DS3-0324-32B 输出结果。为便于复现，我们还提供了不同 case 对应的 prompt。将 prompt 对应的模型输出代码保存到本地 html 文件中，使用浏览器打开 html 文件即可复现类似结果。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例一：前端网页生成：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8622f5305c8f41ee9a740afeb6915fbf.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt：Create a detailed web page for a new SAAS with all the necessary information images and pricing and all, give me the code so that I can test locally using vscode.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例二：贪吃蛇游戏&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f5aae0fd15a345f08fdf98c360ee5d33.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Prompt: Develop an interactive version of the classic Snake game in a single HTML file using HTML, inline CSS, and inline JavaScript. The game must include responsive controls, dynamic score tracking, and a game-over screen with a restart option. Use proper image assets for the snake and food items (no placeholders) so that the entire game is self-contained.&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_9&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;模型下载和使用&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在阿里云人工智能平台 PAI 上的实践&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 库为例，简要介绍如何在 PAI-DSW 上使用 DistilQwen2.5-DS3-0324 模型。首先需要保证 PAI-DSW 镜像内 transformers 版本大于等于 4.37.0，否则会在加载模型时报错：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以 DistilQwen2.5-DS3-0324-7B 为例，我们可以使用如下代码调用模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;xxxxx&quot;
messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant. You should think step-by-step.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=2048
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5-DS3-0324 在开源社区的下载&lt;/h2&gt; 
&lt;p&gt;我们在 Hugging Face 和 Model Scope 上开源了我们蒸馏后的模型，分别为&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-7B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-7B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-14B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-14B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-DS3-0324-32B&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-DS3-0324-32B&lt;/a&gt;。以 Hugging Face 为例，用户可以使用如下代码下载这两个模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-7B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-7B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-14B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-14B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-DS3-0324-32B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-DS3-0324-32B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;小结与未来工作&lt;/h1&gt; 
&lt;p&gt;综上所述，DistilQwen2.5-DS3-0324 系列模型通过知识蒸馏快思考策略，实现了在资源受限环境中的高效推理，兼顾了快速推理和处理复杂任务的需求。这一系列模型在多个基准测试中表现优异，证明了其卓越的推理能力和实际应用价值。作为「大模型+快思考」新模式的经典案例，DistilQwen2.5-DS3-0324 系列为小模型的广泛应用提供了巨大的空间。未来，我们将继续优化和提升 DistilQwen 系列模型的蒸馏技术，以进一步增强小模型的智能水平和推理效率，推广更多高效、轻量化的语言模型，支持开发者和企业在实际应用中的广泛采用。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_13&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;参考资料&lt;/h1&gt; 
&lt;p&gt;相关发表论文&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang. Training Small Reasoning LLMs with Cognitive Preference Alignment. arXiv&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;技术文章&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5-R1 发布：知识蒸馏助推小模型深度思考：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1659288&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1659288&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2.5 发布：通义千问蒸馏小模型再升级：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1653842&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2：通义千问大模型的知识蒸馏实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2 蒸馏小模型的训练、评测、压缩与部署实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大语言模型数据增强与模型蒸馏解决方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;技术交流答疑群&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8a44ba73f4d5fc38c496db477b936e55.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_15&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&amp;nbsp;&lt;/h1&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/18224086</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18224086</guid>
            <pubDate>Mon, 14 Apr 2025 01:56:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>全球首个自回归视频生成大模型「Magi-1」重磅开源</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;Magi-1 是首个实现顶级画质输出的自回归视频生成模型，模型权重、代码 100% 开源。其主打能力，一是无限长度扩展，实现跨时间的无缝连贯敍事。二是能将控制精确到每一「秒」，10s 内自定义视频时长。&lt;/p&gt;

&lt;p&gt;Magi-1 整体架构基于 Diffusion Transformer，采用 Flow-Matching 作为训练目标。其最大的特点是不把视频当成一个整体去生成，而是通过自回归去噪方式预测固定长度的视频片段（chunk），每个片段固定为 24 帧。&lt;/p&gt;

&lt;p&gt;在注意力机制上，也是提出了多项创新，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Block-Causal Attention&lt;/li&gt;
&lt;li&gt;Parallel Attention Block&lt;/li&gt;
&lt;li&gt;QK-Norm 和 GQA&lt;/li&gt;
&lt;li&gt;Flex-Flash-Attention&lt;/li&gt;
&lt;li&gt;计算负载均衡&lt;/li&gt;
&lt;li&gt;零冗余通信原语&lt;/li&gt;
&lt;li&gt;自适应多阶段重叠&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;推理基础设施方面，主要针对实时流式视频生成和在 RTX 4090 GPU 上的经济高效部署两种场景进行设计，以满足不同应用需求。&lt;/p&gt;

&lt;p&gt;目前官网支持免费试玩 Magi-1：&lt;a href=&quot;https://sand.ai/magi&quot;&gt;https://sand.ai/magi&lt;/a&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/magi-1</link>
            <guid isPermaLink="false">https://www.oschina.net/p/magi-1</guid>
            <pubDate>Sun, 13 Apr 2025 11:45:00 GMT</pubDate>
        </item>
        <item>
            <title>百度 Al 智能体心响 App 上线</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;百度通用 Al 智能体心响 App 已低调上线安卓应用市场。该应用介绍称，这是一款以「AI 任务完成引擎」为核心的手机端超级智能体产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;545&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-282aac1eb0a56c4d21d1903e980e2f7a194.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;应用详情介绍，心响是一款以「AI 任务完成引擎」为核心的手机端超级智能体产品，通过自然语言交互帮助用户实现复杂任务拆解、动态执行与可视化结果交付。依托大模型与多智能体协同能力，心响深度赋能知识解析、旅游规划、学习办公等核心生活场景，致力于成为用户的&#39;超级大脑」+「最强辅助」，让用户从繁琐流程中解放一站式让复杂问题智能决策，效率调度，闭环解决实现全流程托管。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;功能亮点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.主脑调度系统：全流程任务托管&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;智能拆解：将复杂需求拆解为可执行步骤，并提供实时进度追踪。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;资源协同：连接核心场景的垂直领域专家智能体确保任务精准落地。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;动态优化：根据任务进展自动调整策略，突发问题实时预警并生成解决方案。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2.旅游攻略：沉浸式行程规划&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一句话定制行程：用户仅需输入一句话需求，心响便可生成完整攻略，联动动态地图可视化路线。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;视频互动决策：数字人导游引导用户选择天数、预算、玩法，强化「身临其境」决策体验。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3.智慧图表：数据可视化革新&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;一键生成复杂图表：基于行业数据自动生成动态排行榜、柱状图、折线图等 10+图表类型，支持定时任务制图 (如哪吒 2 票房走势、实时股价走势)&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;4.定时任务：自动化追踪与提醒&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;高频任务托管：如每日儿童故事生成、黄金价格盯盘、股票波动监测，AI 自动执行并推送结果。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;个性化&amp;amp;长期追踪：支持例如苹果发布会动态汇总埃隆·马斯克业务进展跟踪，信息整合不遗漏关键节点&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;5.恋爱挑战：社交技能训练场&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;模拟恋爱对话：拆解社交需求，生成个性化恋爱对象，提供对话练习与总结报告，提升情感沟通技巧。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345995</guid>
            <pubDate>Sun, 13 Apr 2025 10:09:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「HarmonyOS 协同・创新」 即将启幕，开发者携手共创新未来</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;margin-left:0.0001pt; margin-right:0px&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鸿蒙开发者联盟官网&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成为鸿蒙开发者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当智能终端从「单一设备」走向「全域协同」，从智能家居的联动控制到工业互联的高效协同，从车载系统的无缝衔接到移动办公的跨端流转，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;开发者如何在这场变革中抢占先机？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 以分布式技术打破硬件边界，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「一次开发、多端部署」能力已悄然渗透至千行百业，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用全场景生态重构用户体验，正为全球开发者打开一扇通向未来的大门。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但随之而来的挑战也愈发明显：如何高效利用分布式架构实现跨端协同&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 技术如何深度赋能鸿蒙应用开发？复杂场景下的性能优化有哪些「避坑指南」？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;4 月 27 日，由开源中国主办，山东省软件行业协会协办的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;「HarmonyOS 协同·创新」（软件行业专场）将在济南启幕&lt;/strong&gt;&lt;/span&gt;。这是一场专为鸿蒙生态建设者打造的深度对话——技术大咖、实战派工程师与数百名开发者齐聚，共同探索操作系统的无限可能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主题：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;HarmonyOS 协同·创新（软件行业专场）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;时间&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：2025 年 4 月 27 日 14:00-17:20（13:40 开放签到） &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;地点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：济南市山创创意园·ChillPlay Base&amp;amp;coffee（山 6 创意园内，科技氛围与咖啡香交融的灵感空间）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;适合人群&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：鸿蒙应用开发者、技术团队负责人、生态合作企业&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;🤝&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与顶尖专家面对面：破解开发者的「真问题」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;华为云 HCDE 专家姚圣伟将解读鸿蒙生态战略布局及 2025 年新机遇，拆解&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;鸿蒙分布式架构&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，揭秘跨端协同开发的核心逻辑。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;科技公司软件工程师刘&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;张豪&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;分享&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;AI 赋能鸿蒙生产力&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的实战案例，探索智能化开发新路径。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互联网医疗&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;大前端&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;专家黄沅带来&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;高频问题解析与优化指南&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，助力开发者提升效率、少走弯路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;活动特设「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;互动时刻&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」环节，专家&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;现&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;场坐镇答疑解惑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。无论是分布式架构设计、多端协同逻辑，还是代码调试中的疑难问题，参与者均可通过现场提问与专家零距离交流，快速打通技术堵点，获取针对性解决方案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;另外，本次活动特设茶歇交流时间，与数百名鸿蒙开发者、技术专家、企业代表轻松氛围中碰撞创新灵感，拓展行业人脉。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;👏&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;微信扫码，即刻报名：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;6141&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fa6fad32606b45577ffd51a7a220b5e6ae4.png&quot; width=&quot;2160&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;加入&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.huawei.com%2Fconsumer%2Fcn%2Fforum%2F%3Fha_source%3DKaiyuanzhongguo%26ha_sourceId%3D89000456&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;鸿蒙开发者联盟官网&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;，快速成为鸿蒙开发者！&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18219336</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18219336</guid>
            <pubDate>Sun, 13 Apr 2025 09:45:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>OpenAI o3/o4-mini 模型在生成的文本中嵌入特殊字符水印</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;AI 初创公司 Rumi &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rumidocs.com%2Fnewsroom%2Fnew-chatgpt-models-seem-to-leave-watermarks-on-text&quot; target=&quot;_blank&quot;&gt;发现&lt;/a&gt;&lt;/u&gt; OpenAI 在最新的 o3 和 o4-mini 模型中，&lt;strong&gt;嵌入了窄不换行空格（Narrow No-Break Space, NNBSP, U+202F）等特殊 Unicode 字符。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这些字符在普通视图中与标准空格无异，但在 SoSciSurvey 或 Sublime Text 等专业工具中，可检测其独特代码。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;433&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0422/170754_EvLW_2720166.gif&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Rumi 表示在 GPT-4o 等 OpenAI 此前模型中，并不存在这些设置，这些选项可以通过简单的「查找替换」移除，&lt;strong&gt;推测这可能是 OpenAI 故意设置的水印。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Rumi 强调，这种字符检测方法误报率极低，但易被绕过的缺陷明显。另一种解释是，这些字符符合排版规则，用于防止货币符号与金额或姓名缩写间换行，可能是模型从训练数据中习得的习惯。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-591091037deae24e2952a8c940f02f296fd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 此前曾探索过多种水印方案，例如在 2024 年初为 DALL・E 3 图像添加 C2PA 元数据，以及 2025 年 4 月在 GPT-4o 模型上测试可见的「ImageGen」标签。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345971/new-chatgpt-models-seem-to-leave-watermarks-on-text</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345971/new-chatgpt-models-seem-to-leave-watermarks-on-text</guid>
            <pubDate>Sun, 13 Apr 2025 09:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>突破极限：高负载场景下的单机 300M 多行正则日志采集不是梦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：裘文成（翊韬）&lt;/p&gt; 
&lt;h2&gt;问题背景&lt;/h2&gt; 
&lt;p&gt;在当今数字化时代，日志数据已成为企业 IT 运营和业务分析的关键资源。然而，随着业务规模的扩大和系统复杂度的提升，日志数据的体量呈现爆发式增长，给日志采集和处理系统带来了巨大挑战。最近，我们遇到了一个典型案例，充分体现了当前日志服务采集在高负载场景下面临的困境，以下为客户现状：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量日志与正则采集：客户的某项业务产生了数量巨大的多行日志，并且需要通过正则表达式进行日志解析。这种复杂的采集模式本身就对系统资源提出了较高要求。&lt;/li&gt; 
 &lt;li&gt;关键业务影响：这些日志数据和客户的核心业务分析任务直接相关。过高的采集延迟会影响数据分析的准确性。&lt;/li&gt; 
 &lt;li&gt;采集性能瓶颈：客户根据 iLogtail 启动参数配置文档【1】对 iLogtail 的线程数等进行了调整，在压测时采集速度依然只有 90M/s，但实际压测时的日志生成速度在 200M/s，远超采集速度。这导致了日志采集出现近 1 小时的延迟。&lt;/li&gt; 
 &lt;li&gt;业务需求升级：客户计划进一步增加压测量，预计写入流量将达到 300MB/s。这将进一步加剧采集延迟问题。&lt;/li&gt; 
 &lt;li&gt;业务负载高：客户的业务已经占据了大部分的 CPU 资源，比较困难继续为 iLogtail 提供更多的资源。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;技术难点&lt;/h2&gt; 
&lt;p&gt;在收到客户反馈后，我们立即着手分析问题并制定优化策略。通过获取客户的测试日志样本并进行深入测试，我们发现了以下关键技术难点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;性能瓶颈&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑战: 即使在优化的测试环境中，我们也无法达到客户期望的 300MB/s 处理速度。&lt;/li&gt; 
   &lt;li&gt;数据: 采用 16 线程并行处理，最高吞吐量仅为约 270MB/s。&lt;/li&gt; 
   &lt;li&gt;影响: 无法满足客户的性能需求，可能导致日志处理延迟和数据分析滞后。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;资源消耗与业务冲突&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑战: 为接近目标性能，iLogtail 需要占用大量系统资源。&lt;/li&gt; 
   &lt;li&gt;数据: 需要 16 个线程才能达到 270MB/s 的处理速度。&lt;/li&gt; 
   &lt;li&gt;影响: 高强度的资源占用严重影响服务器上的其他业务进程，可能导致整体系统性能下降。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;线程扩展效益递减&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;挑战: 简单增加处理线程数量并不能线性提升性能，达到一定线程数后，性能增益呈现边际递减趋势。&lt;/li&gt; 
   &lt;li&gt;影响: 表明仅依靠增加硬件资源难以实现质的突破，需要从算法层面进行优化。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4dea9c44863a5defa1b6380f69179c6c72a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;优化过程与成果&lt;/h2&gt; 
&lt;p&gt;怕看官们等不及，在深入技术细节之前，让我们先一睹为快，直观呈现这次优化的成果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能质的飞跃：成功将采集速率提升至超过 300MB/s，完全满足客户需求。&lt;/li&gt; 
 &lt;li&gt;资源利用大幅优化：在保持高性能的同时，将所需线程数从 16 减少到 8，显著降低了 CPU 占用。&lt;/li&gt; 
 &lt;li&gt;创新解决方案：针对资源受限的场景，我们推出了 IngestProcessor 方案。使用这种方案，iLogtail 仅需 1 个线程就能实现 320MB/s 的采集速度，为客户提供了极致的资源效率选择。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-686e8501b0fbeb6948311dbd45331cb7d68.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;本文分析和测试，皆在以下硬件环境进行测试&lt;/p&gt; 
&lt;p&gt;硬件环境&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;计算资源：阿里云 ECS 实例（规格：ecs.c5.8xlarge）&lt;/li&gt; 
 &lt;li&gt;存储资源：PL3 规格的 ESSD 云盘&lt;/li&gt; 
 &lt;li&gt; 
  &lt;ul&gt; 
   &lt;li&gt;为避免磁盘 I/O 出现瓶颈，在高日志量的输出和采集场景，我们推荐使用 PL3 规格的 ESSD 云盘。本文将基于该规格的 ESSD 云盘进行性能分析，详情可参考 ESSD 云盘官方文档【2】&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c40335c27e61f532a7c6b41aa5854c30a08.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;多行日志采集性能提升&lt;/h3&gt; 
&lt;h4&gt;初步观察&lt;/h4&gt; 
&lt;p&gt;为深入了解性能瓶颈，我们首先将注意力放在多行日志的处理性能上。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;客户的日志主要是多行格式。&lt;/li&gt; 
 &lt;li&gt;多行日志采集步骤在日志正则处理之前，可能对整体性能产生重大影响。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在深入研究多行日志采集性能时，我们观察到了一个令人震惊的现象。尽管预期多行日志处理会对性能产生一定影响，但实际测试结果却远远超出了我们的初步估计。在统一的单线程环境下，我们记录到以下数据：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;单行日志采集速度：425MB/s&lt;/li&gt; 
 &lt;li&gt;多行日志采集速度：98MB/s&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-98807d652af01f20d8f17f1072693e46377.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这近乎 80% 的性能下降不仅令人惊讶，更引发了我们对多行采集算法实现的深度思考：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;性能差距：从 425MB/s 骤降至 98MB/s，这种程度的性能退化远远超出了我们对多行处理的初始预期。&lt;/li&gt; 
 &lt;li&gt;异常性：如此巨大的差异明显超出了正常的多行处理开销，显然存在一个重大的性能瓶颈。&lt;/li&gt; 
 &lt;li&gt;算法效率质疑：这一现象使我们不得不重新审视当前多行采集算法的实现效率。可能存在某些未优化的操作或不必要的重复计算。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;iLogtail 多行日志处理原理&lt;/h4&gt; 
&lt;p&gt;iLogtail 的多行日志合并功能基于特定的日志格式将分散的多行数据聚合为完整事件。其工作流程如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;用户配置行首正则表达式。&lt;/li&gt; 
 &lt;li&gt;iLogtail 对每行日志开头应用此正则。&lt;/li&gt; 
 &lt;li&gt;若某行不匹配，iLogtail 继续等待直至找到匹配的行首。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;举个例子，假设我们有如下的日志格式，通常我们会配置行首正则为 \d+-\d+-\d+\s\d+:\d+:\d+.\d+\s.*，iLogtail 会拿着这个正则对每行进行匹配，将这些单行日志合并成一个完整的多行日志。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;2024-03-15 14:23:45.678 ERROR 987654 --- [TaskExecutor-1] c.e.d.s.TaskScheduler                   : Failed to process task due to unexpected exception  
java.lang.NullPointerException: Cannot invoke &quot;com.example.data.model.Task.getPriority()&quot; because &quot;task&quot; is null  
  at com.example.data.processor.TaskProcessor.processTask(TaskProcessor.java:123)  
  at com.example.data.scheduler.TaskScheduler.lambda$scheduleTask$1(TaskScheduler.java:89)  
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)  
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)  
  at java.lang.Thread.run(Thread.java:748)  
Caused by: java.lang.IllegalArgumentException: Task ID cannot be null or empty  
  at com.example.data.validator.TaskValidator.validateTask(TaskValidator.java:45)  
  at com.example.data.processor.TaskProcessor.processTask(TaskProcessor.java:115)  
  ... 4 common frames omitted
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;性能瓶颈分析&lt;/h3&gt; 
&lt;p&gt;深入 iLogtail 的实现机制，我们发现性能瓶颈的关键在于其正则匹配方法。&lt;/p&gt; 
&lt;p&gt;iLogtail 使用 boost::regex_match 函数进行全量匹配，这在处理大规模日志时会产生显著的性能开销。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool BoostRegexMatch(const char* buffer, size_t size, const boost::regex&amp;amp; reg, string&amp;amp; exception) {
    // ...
    if (boost::regex_match(buffer, buffer + size, reg))
        return true;
    // ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;对于之前提到的日志示例，正则表达式会对第一行的全部 253 个字符进行匹配，这在处理大量日志时会导致性能下降。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c05eee7da11ac673c070a2ed24207f1c8ff.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了量化这一性能问题，我编写了测试代码进行实验，目的是观察随着与行首正则无关的日志长度增加（即 .* 匹配的部分），boost::regex_match 的执行时间如何变化。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static void BM_Regex_Match(int batchSize) {
    std::string buffer = &quot;2024-07-19 15:02:16.055 INFO &quot;;
    std::string regStr = &quot;\\d+-\\d+-\\d+\\s\\d+:\\d+:\\d+\\.\\d+\\s.*&quot;;
    boost::regex reg(regStr);
    std::ofstream outFile(&quot;BM_Regex_Match.txt&quot;, std::ios::trunc);
    outFile.close();
    for (int i = 0; i &amp;lt; 1000; i++) {
        std::ofstream outFile(&quot;BM_Regex_Match.txt&quot;, std::ios::app);
        buffer += &quot;a&quot;;
        int count = 0;
        uint64_t durationTime = 0;
        for (int j = 0; j &amp;lt; batchSize; j++) {
            count++;
            uint64_t startTime = GetCurrentTimeInMicroSeconds();
            if (!boost::regex_match(buffer, reg)) {
                std::cout &amp;lt;&amp;lt; &quot;error&quot; &amp;lt;&amp;lt; std::endl;
            }
            durationTime += GetCurrentTimeInMicroSeconds() - startTime;
        }
        outFile &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\t&#39; &amp;lt;&amp;lt; &quot;durationTime: &quot; &amp;lt;&amp;lt; durationTime &amp;lt;&amp;lt; std::endl;
        outFile &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\t&#39; &amp;lt;&amp;lt; &quot;process: &quot; &amp;lt;&amp;lt; formatSize(buffer.size() * (uint64_t)count * 1000000 / durationTime)
                &amp;lt;&amp;lt; &quot;/s&quot; &amp;lt;&amp;lt; std::endl;
        outFile.close();
    }
}

int main(int argc, char** argv) {
    logtail::Logger::Instance().InitGlobalLoggers();
    std::cout &amp;lt;&amp;lt; &quot;BM_Regex_Match&quot; &amp;lt;&amp;lt; std::endl;
    BM_Regex_Match(10000);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;通过这个实验，可以观察到一个关键现象：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;随着与行首正则无关的日志长度增加（即 .* 匹配的那部分日志），boost::regex_match 的执行时间也呈线性增长。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8600e54e65ef9b7e45c4d057487bc0435ad.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;基于实验结果，我们可以得出以下结论：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;全量匹配的低效性：boost::regex_match 对整行进行匹配，即使只有行首部分是关键的。&lt;/li&gt; 
 &lt;li&gt;资源浪费：匹配时间与日志行长度呈线性关系，大部分匹配时间花在了与实际分割逻辑无关的内容上（.* 匹配的部分）,这在处理大量长行日志时会导致严重的性能下降。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;性能优化&lt;/h4&gt; 
&lt;p&gt;基于性能瓶颈分析，我们确定了关键的优化方向：实现部分匹配。这种方法只对日志行首进行匹配，而不是整行，有望显著提高处理效率。&lt;/p&gt; 
&lt;p&gt;为了避免重复造轮子，在调研后，我们发现 Boost 库提供了一个替代方案：boost::regex_search 函数，通过适当配置，这个函数能够精确满足我们的需求。以下是优化后的代码实现：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool BoostRegexSearch(const char* buffer, size_t size, const boost::regex&amp;amp; reg, string&amp;amp; exception) {
    // ...
    if (boost::regex_search(buffer, buffer + size, what, reg, boost::match_continuous)) {
        return true;
    }
    // ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;关键改进点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 boost::regex_search 替代 boost::regex_match。&lt;/li&gt; 
 &lt;li&gt;添加 boost::match_continuous 标志，确保只匹配前缀，如果字符串的开头子串满足正则表达式，就会返回成功。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种实现方式允许我们精确控制匹配过程，只关注日志行首，这正是多行日志处理所需要的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7dfea97286fb5b001a5025f88f7563185cc.gif&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了量化这一优化的效果，和 boost::regex_match 一样，我也对 boost::regex_search 根据日志长度进行了测试。可以发现，新方案的执行时间基本保持稳定，不受日志长度影响。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ec2a7ac92247bc5dfa0cb212e1578acb9a6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;优化后的多行算法，实际采集效果&lt;/h4&gt; 
&lt;p&gt;我们对使用优化后多行算法的 iLogtail，进行了多行日志采集，以下是测试的详细结果：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-233d6b9d35e1ba04aabb249c7657c868f71.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多行采集性能飞跃&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优化后的多行采集速度从 98MB/s 提升到 350MB/s&lt;/li&gt; 
   &lt;li&gt;性能提升幅度：257%（约 3.57 倍）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;接近单行采集性能&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优化后的多行采集速度（350MB/s）已接近单行采集（425MB/s）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;相对於单行采集的性能比：82.35%&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;资源利用效率 
  &lt;ul&gt; 
   &lt;li&gt;在保持单线程的情况下实现显著性能提升&lt;/li&gt; 
   &lt;li&gt;体现了算法优化在提高资源利用效率方面的巨大潜力&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-791501e2ae0e0f6c532bb47c9e255f6f08c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;用户体验优化&lt;/h4&gt; 
&lt;p&gt;在 iLogtail 的已有实现中，用户配置的行首正则表达式通常包含 .*后缀。这是由于之前的匹配机制会匹配整行内容，为了让客户不改动采集配置，只需要升级 iLogtail 版本 2.1 及以上，就能享受到该多行采集性能优化，我们设计了一个以下兼容性策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;正则表达式解析： 
  &lt;ul&gt; 
   &lt;li&gt;在处理用户配置时，iLogtail 会自动分析正则表达式。&lt;/li&gt; 
   &lt;li&gt;如果检测.*后缀的存在，iLogtail 动态调整正则表达式，移除.*后缀。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;正则匹配双方案&lt;/h3&gt; 
&lt;h4&gt;改进多行日志性能后的多行正则匹配采集&lt;/h4&gt; 
&lt;p&gt;在优化多行日志采集性能后，我们进一步探讨了将改进后的多行采集与正则提取相结合的效果。下面详细分析了这种组合方案的性能表现及其实际应用价值。在 8 线程下， iLogtail 的多行日志采集性能已经可以到 370MB/s，已经足够满足客户的采集速度需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9a53269d67d66f267e3747a2ccd1cb12f9c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;采集速率提升&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优化后的采集速率从 270MB/s 提升到 370MB/s&lt;/li&gt; 
   &lt;li&gt;性能提升幅度：37%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;资源利用优化&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;线程数从 16 减少到 8，减少了 50%&lt;/li&gt; 
   &lt;li&gt;在减少一半 CPU 资源的同时，仍然实现了显著的性能提升&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;正则提取的限制&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;由于正则提取需要对日志进行全量匹配，多行采集的部分优化手段在此无法应用&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-21a28be48e32fe8cfec9acea7578426b0e9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;本地资源紧张 - 快速迁移 IngestProcessor&lt;/h4&gt; 
&lt;p&gt;尽管我们成功地在 8 线程下实现了 iLogtail 对多行日志的采集和正则提取，但这种方法仍然面临着一些挑战：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高资源需求：需要占用 8 个 CPU 核心，对机器资源造成显著压力。&lt;/li&gt; 
 &lt;li&gt;客户端限制：并非所有客户都有能力或意愿增加机器资源。&lt;/li&gt; 
 &lt;li&gt;可扩展性问题：随着业务压力增加，客户端资源可能成为瓶颈。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了应对这些挑战，阿里云日志服务推出了一个创新的解决方案：写入处理器（IngestProcessor）。这种方法不仅有效解决了资源限制问题，还大幅提高了处理效率。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;工作原理&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;数据流：通过 iLogtail 采集的日志数据首先经过 IngestProcessor。&lt;/li&gt; 
   &lt;li&gt;处理位置：数据处理过程在日志服务中完成，而非客户端。&lt;/li&gt; 
   &lt;li&gt;资源优化：这种方法显著减少了客户端资源占用，释放计算能力。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;注意事项&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IngestProcessor 不支持日志聚合（将多个日志合并为一个）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;该功能需要额外计费。详细信息请参考阿里云官方文档：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Foverview-of-sls-data-processing%E3%80%82&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/sls/user-guide/overview-of-sls-data-processing。&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;IngestProcessor 不仅可以解决资源限制问题，还提供了丰富的数据处理能力：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;字段提取：从原始日志字段中通过正则表达式、Key-Value 格式、JSON 等解析方式提取出新的字段。&lt;/li&gt; 
   &lt;li&gt;扩展字段：为原始日志添加新的字段。&lt;/li&gt; 
   &lt;li&gt;丢弃字段：删除原始日志的部分字段。&lt;/li&gt; 
   &lt;li&gt;数据脱敏：将原始日志的敏感信息进行脱敏处理。&lt;/li&gt; 
   &lt;li&gt;数据过滤：丢弃原始日志的部分数据。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bfb2569eb40392dd36fbacc794f4b9953e4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由于 IngestProcessor 使用的 SPL 语法和 iLogtail 使用的 SPL 语法一致，因此我们可以直接把 iLogtail 使用的 SPL 语句复制到 IngestProcessor 上，实现快速迁移。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9dda5fb6df1d2d8121b1f709723d26e3212.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们在 10 个 shard 的环境下进行了详细的性能测试。以下是使用的 SPL 语句和测试结果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;资源利用效率：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;IngestProcessor 方案将客户端 CPU 占用从 16 核心降至 &lt;strong&gt;1 核心&lt;/strong&gt; ，减少了 &lt;strong&gt;93.75%&lt;/strong&gt; 。&lt;/li&gt; 
   &lt;li&gt;同时保持了 &lt;strong&gt;320MB/s&lt;/strong&gt; 的高采集速率，与不解析正则时的多行采集极限速率接近。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能平衡：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;虽然采集速率略有下降，但资源占用的大幅减少使得整体效率显著提升。&lt;/li&gt; 
   &lt;li&gt;对于资源受限的环境，这种轻微的速度降低是完全可以接受的。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可扩展性：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;通过将处理负载转移到云端，客户端获得了更大的扩展空间。&lt;/li&gt; 
   &lt;li&gt;这种方案为处理更大规模的日志数据提供了可能性。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7fc13de9e185916d51d2af02dd9132b1ba0.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1422c85cccffacaecc712510c62b4435c4b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实际应用价值&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;成本效益：客户可以通过评估硬件资源成本和 IngestProcessor 使用成本，灵活选择适合自己的方案，降低了总体拥有成本。&lt;/li&gt; 
 &lt;li&gt;灵活部署：使客户能在资源受限的环境中部署高级日志处理功能。&lt;/li&gt; 
 &lt;li&gt;快速迁移：与 iLogtail 使用相同的 SPL 语法，便于现有用户快速采用新方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;结论&lt;/h2&gt; 
&lt;p&gt;通过这次全面的性能测试和优化，我们可以得出以下结论：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;高效性：优化后的 iLogtail 能够在 8 线程下稳定地处理 300MB/s 的多行日志数据并进行正则提取，展现了卓越的性能。&lt;/li&gt; 
 &lt;li&gt;灵活的计算迁移方案：在传统的基于 iLogtail 进行日志采集和处理的方案外，结合 iLogtail 的高效采集和 IngestProcessor 的强大处理能力，我们实现了一个既高效又灵活的日志处理方案，能够在 1 线程下稳定地处理 300MB/s 的多行日志数据并进行正则提取。这种组合能够满足各种复杂的日志处理需求，而不会对客户端性能造成额外负担。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;注意事项：正则提取的性能还受到正则表达式本身复杂度的影响。如果正则表达式设计得过于复杂，或者包含大量的回溯操作，可能会导致匹配效率显著下降，尤其是在处理大规模数据时。因此，在编写正则表达式时，应尽量优化其结构，避免不必要的嵌套和冗余匹配。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;【1】iLogtail 启动参数配置文档：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fsls%2Fuser-guide%2Fconfigure-the-startup-parameters-of-logtail&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/sls/user-guide/configure-the-startup-parameters-of-logtail&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;【2】ESSD 云盘官方文档：&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fecs%2Fuser-guide%2Fessds&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/ecs/user-guide/essds&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18061836</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18061836</guid>
            <pubDate>Sun, 13 Apr 2025 08:57:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>TrueNAS 25.04.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;TrueNAS 25.04（代号「Fangtooth」）已正式&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ftruenas%2Fcomments%2F1k0wmsf%2Ftruenas_2504_fangtooth_release_whats_new_whats%2F&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;&lt;/u&gt;，此版本将 CORE（基于 FreeBSD）和 SCALE（基于 Linux）两大分支进行了统一 ——&amp;nbsp;彻底拥抱 Linux 作为核心基础。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0d194d2668963146adb1a21b1ed4dce3650.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdownload.sys.truenas.net%2FTrueNAS-Fangtooth%2F25.04.0%2F&quot; target=&quot;_blank&quot;&gt;https://download.sys.truenas.net/TrueNAS-Fangtooth/25.04.0/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.truenas.com%2Fdownload-truenas-scale%2F&quot; target=&quot;_blank&quot;&gt;https://www.truenas.com/download-truenas-scale/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;TrueNAS（原 FreeNAS）是一套开放源代码的网络存储设备（英语：NAS）服务器系统，由 iXsystems 进行开发，采用 OpenZFS 文件系统。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8e5f41e4ad75eb50d40ff3eff841bf403d1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;继 TrueNAS 24.10 「Electric Eel」提升性能和引入 Docker 支持后，Fangtooth 带来超过 1000 项更新，修复 150 多个 bug。尽管 iXsystems 目前仅推荐早期采用者使用，但这一版本无疑为 TrueNAS 的未来指明了方向。&lt;/p&gt; 
&lt;p&gt;对于从 CORE 13.x 迁移的用户，此版本保留了熟悉的 NAS 功能（如 SMB、NFS 和 iSCSI），并新增 Docker 和 LXC 支持。&lt;/p&gt; 
&lt;p&gt;TrueNAS 25.04 采用 Linux Kernel 6.12，显著扩展了硬件兼容性，提升了系统灵活性。新增的 Fast Deduplication 功能尤其适用于全 NVMe 系统（如 H30 和 F100 型号），有效减少特定工作负载下的存储占用，特别是在虚拟化环境中表现出色。&lt;/p&gt; 
&lt;p&gt;此外，RAID-Z 扩展速度大幅提升，方便用户管理不断增长的数据池。虚拟化方面，LXC 和 QEMU / KVM 通过 Incus 管理，提供替代 jails 的方案，并改进 VM 系统，同时支持 Secure Boot 和 TPM 需求（目前仍为实验性功能）。&lt;/p&gt; 
&lt;p&gt;新版应用管理支持为新应用直接分配 IP 地址，现有应用将在 6 月 1 日前获得此功能。&lt;/p&gt; 
&lt;p&gt;对于企业用户，TrueNAS 25.04 新增支持 GPOS STIG 配置以满足严格合规需求，以及为 iSCSI 和 NFS 带来 RDMA 支持，&lt;/p&gt; 
&lt;p&gt;此外还包括 VMware 工作负载的块级克隆、Fibre Channel 支持、更快的 SMB 文件复制速度，以及通过 NFS 访问快照目录实现便捷文件恢复等功能。&lt;/p&gt; 
&lt;p&gt;TrueCommand 用户在升级前需先更新至 3.1 版本以确保兼容性。对于生产环境，TrueNAS 24.10.2.1 仍是更稳妥的选择，而 25.04 则适合测试新功能或部署新系统的用户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345966/truenas-fangtooth-25-04-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345966/truenas-fangtooth-25-04-released</guid>
            <pubDate>Sun, 13 Apr 2025 08:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>IDC：2028 年中国大数据 IT 支出规模为 621.7 亿美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;国际数据公司（IDC）近日发布了 2025 年 V1 版本《全球大数据支出指南》。&lt;/p&gt; 
&lt;p&gt;IDC 最新数据显示，2024 年全球大数据 IT 总投资规模约为 3540 亿美元，2028 年预计接近 6441 亿美元，五年复合增长率（CAGR）约为 16.8%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-96a02ac263c915dce3750f69f6273d87c0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;聚焦中国市场，IDC 预计，&lt;strong&gt;2028 年中国大数据 IT 支出规模为 621.7 亿美元，全球占比约 10%&lt;/strong&gt;，五年复合增长率约为 24.9%，增速位居全球第一。&lt;/p&gt; 
&lt;p&gt;IDC 认为，中国大数据市场承压上行，整体市场规模增速有所放缓。从短期发展来看，产业数字化转型浪潮与人工智能应用深化共同催生了企业对数据质量、数据时效性的更高标准，推动企业在数据治理体系建设和数据资产管理方面持续加码，为大数据市场注入发展动能。内需增速放缓和激烈竞争推动企业业务出海，促进了企业对大数据平台及解决方案的需求。长期来看，随着政府和企业预算逐步释放和市场规模渐成体系，中国市场大数据 IT 支出增速将逐步趋于平稳。&lt;/p&gt; 
&lt;p&gt;从硬件市场的角度来看，IDC 认为中国大数据 IT 投资仍将以较大比例流入硬件市场，占比接近 45%。&lt;/p&gt; 
&lt;p&gt;IDC 预测，大数据软件市场在五年预测期内有较大发展潜力，2028 年软件市场规模超 181 亿美元，五年复合增长率（CAGR）约为 19.5%。&lt;/p&gt; 
&lt;p&gt;聚焦大数据服务市场，IDC 认为表示，2028 年中国市场对大数据服务支出规模近 163 亿美元。面对全球服务市场增速放缓的大趋势，中国大数据服务市场将以 1.5 倍于全球平均水平的五年复合增长率（CAGR）稳步增长。&lt;/p&gt; 
&lt;p&gt;IDC 预计，未来五年，政府、金融和软件与信息服务行业将成为大数据技术市场支出规模较大的行业，支出合计近整个市场的五成。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345963</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345963</guid>
            <pubDate>Sun, 13 Apr 2025 08:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>抖音：利用 AI 治理 Q1 封禁黑产账号 260 万个</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;抖音&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLLxnCtJwUp5BrU8YPr54mw&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;《2025 第一季度黑产治理数据报告》指出，今年第一季度，抖音封禁水军、欺诈和违规导流相关黑产账号 260 万个，并将涉嫌违法犯罪的线索上报有关部门。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告称，在大模型基础上，通过构建以 AI 为核心的治理体系，构建覆盖风险感知、智能决策、闭环处置的治理体系，系统性提升 AI 在复杂场景下的风险治理应用，单个案例的处理时间达秒级，各环节运行综合准确率达到 85% 以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以水军治理为例，利用 AI 能力搭建智能机器人工具，实现了风险发现、预警、巡检、研判和回扫等环节的自动化运营。这使得平台在「刷量」识别和处置上的效率大幅提升，不仅能 3 分钟内完成自动研判，且准确率高达 95% 以上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在今年第一季度的试运行中，平台网络水军服务违规的巡检效率提升了 10.25 倍，日均拦截违规请求 6000 万次，封禁水军账号超 20 万个。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;410&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b7cdb4b418c967372a14b0d3f00d3f4b2d9.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在欺诈治理方面，进一步完善了仿冒、购物、刷单、交友等多个场景的安全模型。2025 年至今，抖音共封禁欺诈相关账号 140 万个，每日下发提醒短信超 80 万条，拨打反诈预警电话近 17 万次。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;针对违规导流问题，在 AI 技术的深度运用下，一季度站内相关违规的举报量下降了 73.3%，平台封禁导流违规账号近 100 万个，处置违规视频内容 745 万条。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345961</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345961</guid>
            <pubDate>Sun, 13 Apr 2025 08:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>