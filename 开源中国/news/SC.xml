<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Feb 2025 12:50:10 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>Python 3.14 Alpha 5 发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Python 3.14 Alpha 5 已发布，此版本的最大亮点是引入了新的可选尾调用 (Tail-Call) 解释器，它可以将 Python 代码的执行速度提升高达 30%。&lt;/p&gt; 
&lt;p&gt;当前，尾调用解释器需要在 x86_64 或 AArch64 架构上使用 Clang 19 或更新版本进行编译。对于 GCC 支持，预计将在未来实现。对于希望利用尾调用解释器的用户，特别是那些启用了 Profile Guided Optimization（PGO）的 Python 构建，应该会看到显著的性能提升。&lt;/p&gt; 
&lt;p&gt;详情查看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpythoninsider.blogspot.com%2F2025%2F02%2Fpython-3140-alpha-5-is-out.html&quot; target=&quot;_blank&quot;&gt;发布公告&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;请注意，Alpha 版本旨在进行开发和测试，用户在生产环境中使用时需谨慎，并且可能会遇到未预期的问题。&lt;/p&gt; 
&lt;p&gt;按照官方开发进度，预计在 3 月 14 日发布 Python 3.14 Alpha 6 版本，随后在四月份发布第七个也是最终的 Alpha 版本。接下来，计划进行四个 Beta 版本和两个发布候选版本，以度过夏季。如果一切顺利，Python 3.14.0 正式版本预计在 10 月 7 日发布。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333408/python-3-14-alpha-5</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333408/python-3-14-alpha-5</guid>
            <pubDate>Sat, 08 Feb 2025 11:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 2025 生态内容征集大赛 | 1 月投稿作品及评审结果</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家好，我们在 2024 年底推出了 「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」，公开征集 RWKV 相关的作品，包括但不限于 RWKV 相关的论文、讲解 RWKV 的教程，以及基于 RWKV 的应用等。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，活动共收到 RWKV 生态作品投稿 &lt;strong&gt;11 份&lt;/strong&gt;，包括 &lt;strong&gt;3 篇论文、7 款应用和 1 篇教程/动画&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文将公布 2025 年 1 月的活动投稿作品及评审结果。&lt;/p&gt; 
&lt;h2&gt;评审结果和意见&lt;/h2&gt; 
&lt;h3&gt;论文类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UI&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
   &lt;li&gt;投稿人：Kmui&lt;/li&gt; 
   &lt;li&gt;获奖类型：金奖（4888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：基于 RWKV 的全新研究方向，因此获得金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OmniRWKVSR&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
   &lt;li&gt;投稿人：nomodeset&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UNet&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-UNet：Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
   &lt;li&gt;投稿人：Gavin&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;应用类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;fla-rwkv7&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Ffla-hub%2Frwkv7-6790fd37b4b6137b088a0d8a&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/collections/fla-hub/rwkv7-6790fd37b4b6137b088a0d8a&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：flash-linear-attention 的 RWKV-7 支持&lt;/li&gt; 
   &lt;li&gt;投稿人：张宇&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：如果可以解决这个库运行 Bo 的 MMLU 脚本时的速度和显存占用问题，&lt;strong&gt;可升级金奖&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;conRWKV&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F00ffcc%2FconRWKV&quot; target=&quot;_blank&quot;&gt;https://github.com/00ffcc/conRWKV&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：提供了一个高并发的 RWKV 云端推理引擎，以方便后续基于 RWKV 的应用&lt;/li&gt; 
   &lt;li&gt;投稿人：#9AC8E2&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;R-translator&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fl15y%2FR-translator&quot; target=&quot;_blank&quot;&gt;https://github.com/l15y/R-translator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 RWKV 的 AI 翻译工具&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;获奖类型：铁奖（888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-ZeroCoT&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2FRWKV-ZeroCoT&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/RWKV-ZeroCoT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：ZoreCoT 的原始实现&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;获奖类型：铁奖（888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;substitute&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAXFOX%2Fsubstitute&quot; target=&quot;_blank&quot;&gt;https://github.com/AXFOX/substitute&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 Ai00 Server（RWKV） 驱动的 Kdenlive 字幕校验和替换工具&lt;/li&gt; 
   &lt;li&gt;投稿人：我想上岸&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;rwkv v6 7b cot&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fly444983%2FRWKV_ST_for_AI00%2Ffile%2Fview%2Fmaster%3FfileName%3D7B_LY_COT.state%26status%3D2&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/ly444983/RWKV_ST_for_AI00/file/view/master?fileName=7B_LY_COT.state&amp;amp;status=2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 RWKV-V6-7B 的 rwkv cot state&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;new_rwkv_pip&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2Fnew_rwkv_pip&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/new_rwkv_pip&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：重构后的 rwkv_pip 库，把 v4-v7 各代模型都整理成统一的结构&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;教程/动画类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;有思维的语言模型：RWKV-7 状态演化过程&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1DY6fYdECa%2F&quot; target=&quot;_blank&quot;&gt;https://www.bilibili.com/video/BV1DY6fYdECa/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-7 状态演化视频&lt;/li&gt; 
   &lt;li&gt;投稿人：136279841&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：作品高赞评论在质疑效果，请用 v7 的实际效果去向用户证明。如果用户认可，可升级奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;评审结果快速对照表格&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名称&lt;/th&gt; 
   &lt;th&gt;作品分类&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初评奖项&lt;/th&gt; 
   &lt;th&gt;得奖理由&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UI&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;Kmui&lt;/td&gt; 
   &lt;td&gt;金奖（4888 元）&lt;/td&gt; 
   &lt;td&gt;基于 RWKV 的全新研究方向&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OmniRWKVSR&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;nomodeset&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UNet&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;Gavin&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;有思维的语言模型：RWKV-7 状态演化过程&lt;/td&gt; 
   &lt;td&gt;教程/动画&lt;/td&gt; 
   &lt;td&gt;136279841&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;作品高赞评论在质疑效果，请用 v7 的实际效果去向用户证明。如果用户认可，可升级奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;substitute&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;我想上岸&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fla-rwkv7&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;张宇&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;如果可以解决这个库运行 Bo 的 MMLU 脚本时的速度和显存占用问题，可&lt;strong&gt;升级金奖。&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R-translator&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;铁奖（888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rwkv v6 7b cot&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-ZeroCoT&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;铁奖（888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;new_rwkv_pip&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conRWKV&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;#9AC8E2&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;奖品/奖金发放规则&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;实物奖品（RWKV 周边等）&lt;strong&gt;以&lt;/strong&gt;顺丰快递&lt;/strong&gt;方式发出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;奖金&lt;/strong&gt;以&lt;strong&gt;转账或第三方线上平台&lt;/strong&gt;等方式发放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情况下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;领取奖金，团队内部&lt;strong&gt;自行协商分配奖金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿与奖项升级&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均会获得&lt;strong&gt;评审意见&lt;/strong&gt;。请根据评审意见优化你的作品，然后可&lt;strong&gt;再次投稿以升级奖项&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;奖项成功升级时，我们将补发&lt;strong&gt;前后两个奖金的差价&lt;/strong&gt;。例如投稿作品从铁奖（888 元）升级到银奖（2888 元），则补发 2888-888=2000 元奖金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活动海报&lt;/strong&gt;，欢迎各位转发！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-de56881e7277f3f31798464afb87dbc3c15.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333398</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333398</guid>
            <pubDate>Sat, 08 Feb 2025 09:57:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>别再买 9.9 的 deepseek 本地部署啦！一文教你轻松部署，告别 「服务器繁忙」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;开源的意义，在于人人机会均等。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;本人 IT 小白，不会写代码、不会看文档，甚至一句「 Hello ，World 」 用 Python 写完，都要靠高亮来判断语法是否正确。哈哈哈，像我这样的人，离本地部署，畅玩 Deepseek 远吗？&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;实测！世上无难事，只要肯动手！&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是我用公司配发的 HP 笔记本，本地部署 deepseek 的傻瓜式流程，内容如下：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;设备： HP Laptop 14&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;系统：Win&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;应用程序：LM Studio&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;模型版本：DeepSeek R1 Distill Qwen 1.5B &lt;span style=&quot;color:#8f959e&quot;&gt;（我都这配置了，还要啥自行车）&lt;/span&gt;；DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;辅助工具：VS code &lt;span style=&quot;color:#8f959e&quot;&gt;（轻量？不不不，它是神）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;为什么我会选用 LM Studio &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;在尝试部署之前，同事跟我推荐过一个叫「 Ollama 」 的开源工具，但我实测之后发现，在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2F&quot; target=&quot;_blank&quot;&gt;https://ollama.com/&lt;/a&gt; （ Ollama 官网）下载 Windows 版本时，可能会跳转到 github ，响应超时而无法下载。&lt;/p&gt; 
 &lt;p&gt;并且，Ollama 主要围绕命令行展开，不像 LM Studio 具备直观的图形化操作界面，通过「点点点」就可以使用，所以，对于很多名词都不明所以的我来说——&lt;strong&gt;能用，比好不好用，更重要。&lt;/strong&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_1&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;1、于是，我进入 LM Studio 的官网（ &lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flmstudio.ai%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://lmstudio.ai/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; ），并下载了首页的 0.3.9 版本。&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fe0fc4d91864142b575cad0941864dbb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_2&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;2、下载 LM Studio 3.9.0-6-x68 安装包，所需空间 1.3 &lt;/strong&gt;&lt;strong&gt;GB&lt;/strong&gt;&lt;strong&gt; （全中文的，没有门槛）&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a9c2a4552e660adf721db6398545166a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;打开【 LM-Studio 】，就可以使用该软件，也可以创建桌面快捷。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1c26e3812675b161bb2711f22a87de0d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;界面长这样👇&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//14810d4ac4953cce2010fb5f0fc7e593.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_3&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;3、英文界面？没事儿！内置简体中文~&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//381dd1bf2bc27a93d7cd0133f14a362e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4521be9d0ece8c5f6522e29c72f58cb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_4&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;4、接下来，我们就可以下载模型了，也超简单&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5b68c13f9a0a6c4737a2d41f8cc92b69.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;但是，问题来了！！！&lt;/strong&gt;第一次下载 LM Studio ，搜索模型并下载，往往下载不了，这是因为 LM Studio 关联 Hugging Face 或 llama.cpp 的模型库，默认下载地址无法正常访问。&lt;strong&gt;此时，我们可以通过 VScode ，修改 LM Studio 的安装文件解决。&lt;/strong&gt;（ 怎么下载 VScode ？别搞了兄弟！）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;退出 LM Studio 后，打开 LM Studio 的安装目录，如👇图&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c7e5de0c94f6bc1ac0a848d340120b9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;找到两个文件，路径如下&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\main\index.js&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\renderer\main_window.js&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bad366546f55463174a123dcd533fb38.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;打开 VScode ，在 VCcode 同时打开这两个文件&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e72d38f52a807e0bd51fa1a323451edf.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷键 ctrl+shift+h 调出批量替换，将 &lt;code&gt;huggingface.co&lt;/code&gt; 替换成 &lt;code&gt;hf-mirror.com&lt;/code&gt; ，然后快捷键 ctrl+alt+enter 应用替换（两个文件同时打开时，可同时替换）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bd348a106dd3879fb521b5ffad959a78.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷键 ctrl+s ，保存文件即可退出 VScode ，再打开 LM Studio 就可以搜索下载模型了~&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;span id=&quot;OSC_h4_5&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;5、搜索适合设备配置的模型，下载并使用&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1323fb9dc1b4b3b3f89f726b17290d9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;一开始，小编也只敢用 HP 本下载最小的 1.5B ，但后面搜索了一些资料，整理下表：&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeb8f9a7b500a326f92c20de7d91ce400c8.jpg&quot; width=&quot;784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;span id=&quot;OSC_h4_6&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;6、实测阶段&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 1.5B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;问题设置 1：人有几只脚？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//334794f64dac8ccb583dd0137b9e933c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 2：请简述一下，什么是「模型蒸馏」？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//962255f6c3582b01c7913ace1faf11fd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//069652c7705521531ac17af8bab48c79.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c72aa05116825a0c8727b76d77d13e1c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 3：8.11 和 8.4 谁大？直接得出结论。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bb33fdd55da3112b2dcf57f18e1fbe8c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;问题设置 1：你认为「模型开源」的意义是什么？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c5c2039712441d2048404de675270ba.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 2：你如何评价梁文锋？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b3f62d7ac407be1f2b9fa9b7f19304aa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 3：你认为，人工智能的下一个技术突破点是？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e76d56190bda354d2f8bf81e6f187557.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;得到这个回答时，我发现，并不是我想要的，所以，我又继续追问了一个问题：&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;如果不局限于中国呢？如果是全球人工智能技术，你觉得下一个技术突破点是什么？ &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是 7B 的答案（因为不好截图，所以用文字表达）：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;在人工智能领域，每一次技术突破都伴随着对现有局限性的突破和技术创新。如果将目光放长远，并不限于中国的地区或行业背景，全球范围内，下一个可能的技术突破方向可以从以下几个角度进行分析：&lt;/p&gt; 
  &lt;p&gt;1. &lt;strong&gt;通用人工智能（AGI）的突破&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;目前，AI 主要集中在特定任务上（如 NLP、计算机视觉等），仍然缺乏真正具有「通用性」的自主学习能力。如何让机器具备类似人类般的学习能力和通用认知模式仍然是一个未解之谜。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;符号推理与&lt;/strong&gt;&lt;strong&gt;知识图谱&lt;/strong&gt;：结合符号逻辑和知识图谱，使得 AI 能够进行更抽象的推理和概念理解。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;strong&gt;的进化&lt;/strong&gt;：探索更具效率和创造力的强化学习方法，推动 AGI 的发展。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨模态理解和整合&lt;/strong&gt;：使 AI 能够更好地理解和处理多模态信息（如文本、图像、音频等），从而具备更全面的理解能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;2. &lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;与协作&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;当前的大模型（如 GPT 系列、LLama 系列）已经在特定领域展现了强大的性能，但规模和复杂性仍然有限。未来，通过模型的联合训练和知识共享（如「元学习」或「模型平均」），可能实现更大规模、更高效的 AI 系统。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;具体方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型协作与知识共享&lt;/strong&gt;：多个研究机构或企业联合训练大型语言模型，促进知识的开放性和共享性。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多领域&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;的融合&lt;/strong&gt;：创建涵盖科学、艺术、医疗等多领域的大型模型，提升跨领域应用的能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;3. &lt;strong&gt;人机协作与&lt;/strong&gt;&lt;strong&gt;自适应系统&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;随着 AI 技术的成熟，人机协作将成为未来的重要趋势。如何让 AI 能够更自然地与人类交互、理解和协同工作，仍然是一个关键方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;情感理解与伦理决策&lt;/strong&gt;：开发能够理解人类情感和价值观的 AI 系统，使其在复杂的社会环境中做出更具伦理性的决策。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;动态任务适应&lt;/strong&gt;：设计更加灵活的 AI 系统，能够在不同情境中自适应任务要求，提升通用性。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;4. &lt;strong&gt;多模态与跨媒体理解&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;当前 AI 大多局限於单一模态（如文本或图像），如何整合多种模态信息（如文本、音频、视频、甚至传感器数据）进行更全面的理解和推理，仍然是一个未解之谜。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模态融合框架&lt;/strong&gt;：开发能够处理并整合多种模态数据的模型架构。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨领域&lt;/strong&gt;&lt;strong&gt;知识图谱&lt;/strong&gt;：构建跨领域的知识图谱，帮助 AI 更好地理解不同模态之间的关系。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;5. &lt;strong&gt;硬件与效率优化&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;虽然大模型在软件层面取得了进展，但计算资源（如 GPU、TPU 等）仍然是制约其广泛应用的关键因素。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;未来可能会有更高效的硬件设计和算法优化，使得 AI 系统的计算效率显著提升。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;6. &lt;strong&gt;伦理与安全&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;AI 的自主性和复杂性可能带来新的伦理问题和安全风险。如何在技术发展的同时确保 AI 系统的安全性和透明性，也是一个重要方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;系统的透明性&lt;/strong&gt;：研究如何让 AI 系统更加透明，以便于人类理解和监督。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;法律与框架的完善&lt;/strong&gt;：推动相关法律法规的制定，确保 AI 技术的发展符合社会价值观。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;总结&lt;/p&gt; 
  &lt;p&gt;从全球视角来看，下一个技术突破可能集中在以下方面：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;推动 AGI（通用人工智能）的发展；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;扩展大模型的协作和共享能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;提升多模态理解和人机协作能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;优化硬件效率并确保伦理安全。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p&gt;这些方向既需要基础理论研究，也需要跨学科合作和技术落地。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;span id=&quot;OSC_h4_7&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;7、后记&lt;/h4&gt; 
 &lt;p&gt;体验了几个回合下来，首先能肯定的是，上文测试的两个模型确实没有网页版 or APP 版所输出的内容有趣（怪小编&lt;s&gt;财&lt;/s&gt;实力不行），但至少不会出现「服务器繁忙」，且不联网也可以使用。&lt;/p&gt; 
 &lt;p&gt;其次，通过 LM Studio ，我们还可以轻松部署甚多有意思的开源模型在本地，而写这一篇超超超超超基础的博客，无非是在回答本文一开始的那句话：&lt;strong&gt;开源的意义，在于人人机会均等&lt;/strong&gt;。不仅是程序员、开发者、AI 从业人员，如根本不会写代码的我，也可以共享这一份人类智慧。&lt;/p&gt; 
 &lt;p&gt;可能有人会说，1.5B 能干什么？像个傻子！7B 能干什么？上不得枱面！对此，小编想用 Deepseek R1 自己输出的一句话回答大伙儿——&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;火焰不需要羡慕灰烬的重量（满血模型，也是从第一行代码而来的）&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;最后，分享一个昨晚在地铁上亲历的场景：&lt;/p&gt; 
 &lt;p&gt;寒假快结束了，两个小学生在地铁上互抄作业，小学生 A 说：「牛 B 呀！寒假生活你居然做完了？！」 小学生 B 说：「你傻呀！用 AI 呀~手机摸出来给我玩两把！我跟你上分！」&lt;/p&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
 &lt;/div&gt; 
 &lt;p&gt;PS：希望在哪些网络覆盖不佳、基础设备不好，逼仄、失语的角落，也能萌芽智慧之光......&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/17563840</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/17563840</guid>
            <pubDate>Sat, 08 Feb 2025 09:32:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>百度今年或将发布下一代 AI 模型 Ernie 5.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F12%2Fchina-tech-giant-baidu-to-release-next-generation-ai-model-this-year-as-deepseek-shakes-up-market.html&quot; target=&quot;_blank&quot;&gt;据 CNBC 报道&lt;/a&gt;&lt;/u&gt;，百度今年将发布下一代 AI 模型 Ernie 5.0。&lt;/p&gt; 
&lt;p&gt;消息人士称，被称为「基础模型」的 Ernie5.0，将在多模态能力方面有重大增强，但没有具体说明其功能。「多模态」AI 指可以处理文本、视频、图像和音频等不同形式的数据，并进行转换和结合 —— 比如将文本转化为视频，或反向操作。而基础模型能够理解语言，执行包括生成文本、图像在内的多种任务，同时支持与人类自然语言的互动。&lt;/p&gt; 
&lt;p&gt;这一消息正值苹果公司将其潜在客户&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333288&quot;&gt;转向&lt;/a&gt;&lt;/u&gt;阿里巴巴之后，市场普遍猜测此举是百度为了应对局势的变化，试图稳住股价和市场地位。&lt;/p&gt; 
&lt;p&gt;百度首席执行官李彦宏本周在迪拜的世界政府峰会上表示：「我们正处于一个令人激动的时代……12 个月内，基础模型的推理成本预计将下降 90% 以上。如果成本能够大幅降低，意味着生产力将呈同等比例提升。这也正是创新的核心所在。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;报道称，百度的文心大模型已经在其多个面向消费者和企业的产品中应用，包括云存储和内容创作。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;百度上个月宣布，截至 2024 年底，其文库平台已吸引 4000 万付费用户，比 2023 年底增长了 60%。包括利用 AI 根据公司财报生成 PPT 在内的一系列新功能，已在 1 月开始向用户发布。&lt;/p&gt; 
&lt;p&gt;当前的 ERNIE 模型版本为 4.0，于 2023 年 10 月发布。2024 年 8 月，百度发布了升级版的 ERNIE 4.0 &quot;turbo&quot;，目前并未正式宣布下一次更新的计划。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333389</guid>
            <pubDate>Sat, 08 Feb 2025 09:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Go 1.24 正式发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Go 1.24 已正式发布，Go 1.24 在 Go 1.23 的基础上带来了许多改进。以下是一些显著的变更。&lt;/p&gt; 
&lt;h2&gt;语言变更&lt;/h2&gt; 
&lt;p&gt;Go 1.24 现在完全支持 generic type aliases：类型别名可以被参数化，就像定义的类型一样。有关详细信息，请参阅语言规范。&lt;/p&gt; 
&lt;h2&gt;性能改进&lt;/h2&gt; 
&lt;p&gt;运行时的一些性能改进使得在一系列代表性基准测试中平均降低了 2-3% 的 CPU 负载。这些改进包括基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fabseil.io%2Fabout%2Fdesign%2Fswisstables&quot; target=&quot;_blank&quot;&gt;Swiss Tables&lt;/a&gt; 的新内置 &lt;code&gt;map&lt;/code&gt; 实现、更高效的内存分配（针对小对象）以及新的运行时内部互斥锁实现。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;go&lt;/code&gt; 命令现在提供了一种跟踪模块工具依赖的机制。使用 &lt;code&gt;go get-tool&lt;/code&gt; 向当前模块添加 &lt;code&gt;tool&lt;/code&gt; 指令。使用 &lt;code&gt;go tool [工具名称]&lt;/code&gt; 来运行使用 &lt;code&gt;tool&lt;/code&gt; 指令声明的工具。有关 go 命令，的更多信息，请参阅发布说明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;go vet&lt;/code&gt; 子命令中的新 &lt;code&gt;test&lt;/code&gt; 分析器报告了测试包中测试、模糊测试、基准测试和示例声明的常见错误。有关 vet 的更多信息，请参阅发布说明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;标准库新增内容&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;标准库现在包括一套新的机制，以促进 FIPS 140-3 合规性。FIPS 140-3 合规性，的应用程序无需对源代码进行任何更改即可使用新的机制来使用批准的算法。有关 FIPS 140-3 合规性，的更多信息，请参阅发布说明。除了 FIPS 140 之外，之前位于 x/crypto 模块中的几个包现在也包含在，标准库，中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基准测试现在可以使用更快且更少出错的 &lt;code&gt;[testing.B.Loop](about:blank)&lt;/code&gt; 方法来执行基准迭代，例如用 &lt;code&gt;for b.Loop() { ... }&lt;/code&gt; 代替典型的涉及 &lt;code&gt;b.N&lt;/code&gt; 的循环结构，如 &lt;code&gt;for range b.N&lt;/code&gt;。有关新基准函数的更多信息，请参阅发布说明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新的 &lt;code&gt;[os.Root](about:blank)&lt;/code&gt; 类型提供了在特定目录下执行文件系统操作的能力。有关文件系统访问的更多信息，请参阅发布说明。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;运行时提供了一种新的最终化机制 &lt;code&gt;[runtime.AddCleanup](about:blank)&lt;/code&gt;，它比 &lt;code&gt;[runtime.SetFinalizer](about:blank)&lt;/code&gt; 更灵活、更高效且更少出错。有关清理操作的更多信息，请参阅发布说明。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;改进的 WebAssembly 支持&lt;/h2&gt; 
&lt;p&gt;Go 1.24 增加了一个新的 &lt;code&gt;go:wasmexport&lt;/code&gt; 指令，允许 Go 程序将函数导出到 WebAssembly 主机，并支持将 Go 程序构建为 WASI &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FWebAssembly%2FWASI%2Fblob%2F63a46f61052a21bfab75a76558485cf097c0dbba%2Flegacy%2Fapplication-abi.md%23current-unstable-abi&quot; target=&quot;_blank&quot;&gt;reactor/library&lt;/a&gt;。在发布说明中了解更多关于 WebAssembly 的信息。&lt;/p&gt; 
&lt;p&gt;要查看完整更新日志，请参考&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgo.dev%2Fdoc%2Fgo1.24&quot; target=&quot;_blank&quot;&gt;发布说明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgo.dev%2Fdl%2F&quot; target=&quot;_blank&quot;&gt;https://go.dev/dl/&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333376/go-1-24</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333376/go-1-24</guid>
            <pubDate>Sat, 08 Feb 2025 08:36:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英特尔开源全新 NLP 模型：Polite Guard</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英特尔&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;推出 Polite Guard，一种用于文本分类任务的开源自然语言处理 (NLP) 语言模型，采用 MIT 许可。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 旨在使开发人员更容易生成自己的合成数据并微调他们的模型、通过提供针对敌对攻击的防御机制来增强系统的弹性、允许开发人员评估和比较他们的模型在礼貌分类方面的性能，以及通过确保在各个平台上进行尊重和礼貌的互动来提高客户满意度和忠诚度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该模型由 BERT 微调而来，可将文本分为四个不同的类别：polite, somewhat polite、neutral 以及 impolite。目前，英特尔已在&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 和&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FIntel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;Hugging Face&lt;/a&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;上开源了相关的数据集和 Polite Guard 源代码。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 数据集包含三个部分：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Few-Shot 提示生成 50,000 个带标签样本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Chain-of-Thought（CoT）提示生成的 50,000 个带标签样本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;来自企业培训的 200 个经过匿名化处理（屏蔽个人标识符）的标注样本。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告指出，合成数据被划分为训练集（80%）、验证集（10%）和测试集（10%），每组均根据标签进行平衡。Polite Guard 模型完全在合成数据上进行训练，但在合成数据和真实标注数据的测试集上进行评估，准确率和 F1 分数均达到了 92.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46439a7eec58b0b02d7e2377a193c43abe8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e66b191ecaab81e31ad281895c85f48be6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;英特尔社区博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333358/intel-polite-guard</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333358/intel-polite-guard</guid>
            <pubDate>Sat, 08 Feb 2025 07:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英国和美国拒绝签署国际人工智能宣言</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在巴黎举行的全球峰会上，英国和美国没有签署人工智能（AI）国际宣言。这份由法国、中国和印度等国签署的声明承诺以&quot;开放&quot;、&quot;包容&quot;和&quot;道德&quot;的方式来发展人工智能技术。&lt;/p&gt; 
&lt;p&gt;在巴黎举行的人工智能行动峰会的讨论重点是人工智能对社会和环境的影响——以及需要采取哪些行动来获取其利益和防范其风险。&lt;/p&gt; 
&lt;p&gt;美国和英国没有解释不签署的原因。&lt;/p&gt; 
&lt;p&gt;但早些时候，美国副总统万斯（JD Vance）在巴黎对与会代表说，对人工智能（AI）的过多监管可能会&quot;扼杀一个刚刚起飞的变革性行业&quot;。万斯周二在巴黎举行的峰会上告诉世界各国领导人，人工智能是&quot;特朗普政府不会浪费的机会&quot;，并表示&quot;有利于增长的人工智能政策&quot;应优先于安全。他说，这将需要促进人工智能发展的监管，&quot;而不是扼杀它&quot;。万斯还说，欧洲领导人尤其应该&quot;以乐观而非恐惧的态度看待这一新领域&quot;。&lt;/p&gt; 
&lt;p&gt;他的这番话似乎让他与法国总统埃马纽埃尔-马克龙（Emmanuel Macron）产生了分歧，后者为进一步监管的必要性进行了辩护。&lt;/p&gt; 
&lt;p&gt;马克龙在峰会上说：&quot;我们需要这些规则来推动人工智能的发展。&quot;这是在讨论人工智能发展对社会、环境和治理的影响之际发表的。&lt;/p&gt; 
&lt;p&gt;参加巴黎峰会的政策制定者、高管和外交官们一直在思考如何获取人工智能创新的经济效益，同时应对该技术的风险。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1decb699dddc94378060a3327ba296ab72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;法国总统埃马纽埃尔-马克龙（Emmanuel Macron）在社交媒体上发布了自己出演热门电影和电视剧的 deepfake 搞笑片段汇编，拉开了本次峰会的序幕。&lt;/p&gt; 
&lt;p&gt;欧盟委员会主席乌苏拉-冯德莱恩（Ursula von der Leyen）周二表示：&quot;本次峰会的重点是行动，而这正是我们现在所需要的。&quot;她说，在整个峰会期间，欧洲一直倡导的人工智能方法也将强调创新、合作和&quot;拥抱开源&quot;技术的力量。&lt;/p&gt; 
&lt;p&gt;此次会议的召开正值美欧贸易关系日益紧张之际。美国总统特朗普已决定对进口到美国的钢铁和铝征收关税，此举将影响英国和欧盟。&lt;/p&gt; 
&lt;p&gt;据悉， 英国不会立即采取报复行动，因为英国既要与特朗普政府保持良好关系，又要与欧盟建立更紧密的关系，因此英国希望走一条微妙的道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333337</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333337</guid>
            <pubDate>Sat, 08 Feb 2025 05:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI CEO 奥尔特曼：愿意在人工智能领域与中国合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日，美国企业家埃隆·马斯克等投资人当地时间 2 月 10 日提议「以 974 亿美元竞购」由其参与创建的美国开放人工智能研究中心（OpenAI）的非营利性母公司。&lt;/p&gt; 
&lt;p&gt;对此，2 月 11 日在法国巴黎出席人工智能行动峰会的 OpenAI 首席执行官萨姆·奥尔特曼&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot;&gt;再次强调「公司不卖」&lt;/a&gt;&lt;/u&gt;，并表示，「如果马斯克愿意谈」，那么他将「很乐意收购推特（即社交媒体平台 X）」。&lt;/p&gt; 
&lt;p&gt;奥尔特曼还表示，「&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;愿意在人工智能领域与中国合作，并将为此尽最大努力，因为这很重要。&lt;/strong&gt;&lt;/span&gt;」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c01d53e2a43f4d2a467d4d590cc812b528.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据外媒周一报道，特斯拉 CEO 埃隆·马斯克正率领一群投资者，提出以 974 亿美元收购 OpenAI 的控制权。马斯克律师马克·托贝罗夫补充说，他已于周一提交收购要约。&lt;/p&gt; 
&lt;p&gt;报道援引托贝罗夫提供的马斯克声明称，「现在是时候让 OpenAI 回归其曾经开源、注重安全的初衷了。」&lt;/p&gt; 
&lt;p&gt;OpenAI 首席执行官山姆·奥尔特曼在 X 平台上发帖称，他写道：「不了，谢谢。不过如果你愿意的话，我们可以花 97.4 亿美元收购推特。」随后，马斯克在 X 平台上回复这位 OpenAI 负责人，称他为「骗子」。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333323</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333323</guid>
            <pubDate>Sat, 08 Feb 2025 03:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>稚晖君创业公司智元近日在深圳新设立「灵犀」产品线</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.leiphone.com%2Fcategory%2Frobot%2FIYV9qXAR1wFN5Omd.html&quot; target=&quot;_blank&quot;&gt;根据「AI 科技评论」独家报道&lt;/a&gt;，智元机器人三大事业部之一灵犀近日在深圳设立，目前正在招兵买马。&lt;/p&gt; 
&lt;p&gt;据了解，智元此前调整组织架构，新设立三大产品线，分别是远征、灵犀和 Genie。此外还有几个一级部门，例如灵巧手。&lt;/p&gt; 
&lt;p&gt;智元新成立的三大产品线分设三地，除了「灵犀」产品线在深圳外，远征产品线在上海，Genie 产品线大部队在北京。&lt;/p&gt; 
&lt;p&gt;远征、灵犀、Genie 三大产品线总裁分别由王闯（前大疆 Livo 激光雷达负责人）、稚晖君、姚卯青（前蔚来工程总监）担任。据了解，Genie 产品线前身是由上海交大闫维新教授和姚卯青指挥的研究院。&lt;/p&gt; 
&lt;p&gt;目前灵犀产品线由稚晖君暂代，还在招一号位人选。灵犀系列是智元产品矩阵之一，原先只有产品，并没有配备专门产品线。此次新设立的灵犀产品线，将承接此前的灵犀系列产品。2024 年 10 月，智元曾宣布&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhiyuan-robot.com%2FDOCS%2FOS%2FX1-PDG&quot; target=&quot;_blank&quot;&gt;开源灵犀 X1&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67d9642e1e623e3859f9c4aa1823336b99b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;稚晖君所在部门为 CTO Office，领衔 X-Lab 和 EI-Lab。X-Lab 由稚晖君指挥，EI-Lab 则归北大计算机学院前沿计算研究中心助理教授董豪管理。&lt;/p&gt; 
&lt;p&gt;据介绍，灵犀主要做 To C，面向养老方向。而远征和 Genie 在产品腿部形态上做区分，远征做足式机器人，Genie 则是轮式机器人。&lt;/p&gt; 
&lt;p&gt;智元自成立起便开启全栈自研，涵盖软件、硬件、大脑、小脑和云系统等。技术上，智元提出具身智能 G1 到 G5 的演进路径和技术框架，目前处于 G2 和 G3 阶段。&lt;/p&gt; 
&lt;p&gt;智元持续推进量产工作。2024 年 12 月，智元机器人正式宣布开启机器人量产。2025 年 1 月 6 日，智元量产第 1000 台通用具身机器人正式下线。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/254290&quot; target=&quot;news&quot;&gt;稚晖君首款创业产品——智元机器人「远征 A1」发布&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327297&quot; target=&quot;news&quot;&gt;智元机器人重磅开源百万真机数据集 AgiBot World&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328925&quot; target=&quot;news&quot;&gt;智元机器人具身算法团队推出 EnerVerse 架构&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333319</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333319</guid>
            <pubDate>Sat, 08 Feb 2025 03:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>梁文锋实习往事：月薪 1.6 万、没毕业就被任命为部门经理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前「今日闵行」公众号&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e1Eva97SJCgDJp3ukjlwA&quot; target=&quot;_blank&quot;&gt;发文称&lt;/a&gt;，DeepSeek 创始人梁文锋 2009 年曾在上海闵行的上海艾麒信息科技股份有限公司实习，负责内容也跟人工智能有关。&lt;/p&gt; 
&lt;p&gt;据艾麒信息创始人周朝恩透露，梁文锋是其浙大校友，&lt;strong&gt;2009 年梁文锋以实习生身份加入艾麒，后经推荐直接担任新技术部经理，月薪 16000 元&lt;/strong&gt;，算是高薪特别聘请的。&lt;/p&gt; 
&lt;p&gt;「入职后，他便全身心投入到人工智能视频与图像技术的研究中，常常一整天都待在办公室里，专注地钻研技术难题，甚至半天都不出来一次。」&lt;/p&gt; 
&lt;p&gt;他还透露了对梁文锋的第一印象：「初见梁文锋时，他戴着一副眼镜，斯文有礼，身材清瘦，给人一种文静内敛的印象。」&lt;/p&gt; 
&lt;p&gt;不过在深入接触后，周朝恩发梁文锋虽不善言辞，但在技术交流中却能清晰地表达自己的观点，「他为人沉着冷静，性格简单直接，对产品和技术有着极高的追求，堪称典型的技术男风格」。&lt;/p&gt; 
&lt;p&gt;周朝恩介绍称，梁文锋在艾麒信息期间，当时公司新技术部也在研究做 100M CPU 的手机上视频编解码技术，并充分运用手机上 GPU 来高效处理视频编解码等技术。在这过程中，梁文锋积累了丰富的技术经验，为他后续创业打下了坚实的技术基础。&lt;/p&gt; 
&lt;p&gt;他也曾管理过多位算法工程师，采用扁平化管理方式，给予团队成员充分的自由和信任，发挥每个人的特长，并带领团队攻克了多项技术难题，优化了图像视频处理算法，提升了服务性能。&lt;/p&gt; 
&lt;p&gt;丰富的管理经验在他创业后得到了延续。周朝恩告诉记者，梁文锋招聘的团队成员大多是数学竞赛一等奖、拿过国际金牌的算法人才，这种对高端人才的管理和激励方式，使得他在管理量化投资和深度求索时能够迅速组建一支高效专业的技术团队。&lt;/p&gt; 
&lt;p&gt;2023 年 5 月，梁文锋在筹备深度求索之前，还特意回到艾麒公司进行调研。&lt;/p&gt; 
&lt;p&gt;此次调研，他比约定的时间提早 3 分钟来到了周朝恩的办公室，他不仅仅是看望老同事，而且还了解到艾麒信息也正在做大模型相关产品，「他与我们探讨了人工智能相关技术，交流了将近 2 个小时」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333308</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333308</guid>
            <pubDate>Sat, 08 Feb 2025 03:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 创始人未出席巴黎 AI 峰会</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期有消息称，中国人工智能企业深度求索（DeepSeek）创始人梁文锋受邀参加在巴黎举办的&quot;AI 行动峰会&quot;（AI for Action Summit）。此次峰会聚焦全球人工智能技术发展、伦理治理及跨领域协作，被视为推动全球 AI 治理框架落地的重要国际会议。为期两天的人工智能行动峰会已于当地时间 10 日在法国首都巴黎的大皇宫拉开帷幕。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FphNF2U-ytrx6v97fqes_tA&quot; target=&quot;_blank&quot;&gt;根据凤凰网科技的报道&lt;/a&gt;&lt;/u&gt;，接近 DeepSeek 的人士称梁文锋没有参加这次在巴黎举办的人工智能行动峰会，公司层面也无人参加。&lt;/p&gt; 
&lt;p&gt;目前，除传闻受邀的梁文锋外，已披露的参会名单包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI 首席技术官米拉·穆拉蒂&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china&quot;&gt;DeepMind 首席执行官戴密斯·哈萨比斯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;法国总统马克龙&lt;/li&gt; 
 &lt;li&gt;欧盟委员会数字事务副主席维斯塔格&lt;/li&gt; 
 &lt;li&gt;图灵奖得主杨立昆&lt;/li&gt; 
 &lt;li&gt;斯坦福大学 HAI 研究院院长李飞飞等人&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;法国总统马克龙在这次峰会开幕前夕曾表示，不会因为某个技术来自特定国家和地区就去禁用它，因为这很荒谬，他认为，DeepSeek 的出现是一个好消息，并希望下一代这样的模型会出现在欧洲。&lt;/p&gt; 
&lt;p&gt;此外，值得注意的是，2 月 11 日，彭博社对 7 位初创公司创始人及 AI 专家的调研显示，预计 DeepSeek 的估值在 10 亿美元到逾 1500 亿美元之间，估值区间的中间值为 20 亿至 300 亿美元。这样的预测无疑让持有 84% 股份的梁文峰身家暴涨，有望跻身亚洲科技巨富之列。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333302</guid>
            <pubDate>Sat, 08 Feb 2025 02:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Apollo 2.4.0 发布，分布式配置管理中心</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Apollo 2.4.0 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FyZ37eRPBwQtP-TQy1YPWag&quot; target=&quot;_blank&quot;&gt;已发布&lt;/a&gt;，包含了诸如客户端多 AppId 支持、集群级权限控制支持、客户端监控指标增强、配置全局搜索等重大更新。&lt;/p&gt; 
&lt;p&gt;Apollo（阿波罗）是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。&lt;/p&gt; 
&lt;p&gt;Apollo 2.4.0 主要新特性如下：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客户端多 AppId 支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客户端现在支持从多个 appid 加载配置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;集群级权限控制支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用户可以按照集群粒度配置命名空间的编辑和发布权限，从而能满足不同场景的权限管理要求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客户端监控指标增强&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客户端显著增强了可观测性，提供了 ConfigMonitor API 以及通过 JMX 和 Prometheus 导出指标的选项。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;配置全局搜索&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;管理员用户可以针对配置项的 Key 和 Value 进行全局模糊搜索，从而更容易在应用、环境、集群和命名空间中定位配置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;客户端缓存支持 K8S ConfigMap&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Apollo Java 客户端支持配置信息缓存在 K8S ConfigMap 中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;应用访问密钥支持观察者模式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在正式启用应用密钥之前，可以将应用访问密钥配置为观察模式，从而仅作记录而不实际拦截配置获取。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;命名空间和配置项的数量限制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用户可以限制命名空间的数量以及单个命名空间中的配置项数量，从而避免单个应用的配置过大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查看更多内容：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo%2Freleases%2Ftag%2Fv2.4.0&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo/releases/tag/v2.4.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo-java%2Freleases%2Ftag%2Fv2.4.0&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo-java/releases/tag/v2.4.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 官方网站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.apolloconfig.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.apolloconfig.com/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 仓库地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapolloconfig%2Fapollo&quot; target=&quot;_blank&quot;&gt;https://github.com/apolloconfig/apollo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apollo 公共邮箱：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3Aapollo-config%40googlegroups.com&quot; target=&quot;_blank&quot;&gt;apollo-config@googlegroups.com&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333300/apollo-config-2-4-0-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333300/apollo-config-2-4-0-released</guid>
            <pubDate>Sat, 08 Feb 2025 02:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马云现身阿里杭州总部，闪现闲鱼、夸克两大业务办公区</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日下午，阿里巴巴创始人马云现身阿里杭州园区，身穿阿里巴巴黑色文化夹克，全程微笑并向员工挥手致意。&lt;/p&gt; 
&lt;p&gt;据社交媒体上的阿里员工透露，今日上午，马云先出现的地方是阿里西溪园区 A 区 2 号楼的闲鱼。此后，下午又有人在 C 区的夸克偶遇马云，身旁还有阿里巴巴集团 CEO 吴泳铭陪同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60c6d8f397d9898ecffe3d57cacc36134b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作为阿里 AI To C 的代表产品，夸克近期也升级了品牌 Slogan—「2 亿人的 AI 全能助手」。&lt;/p&gt; 
&lt;p&gt;同时，阿里 AI To C 正在「招贤纳士」，以提升用户的信息服务体验。2 月 6 日，全球顶尖人工智能科学家、Salesforce 集团（CRM）前副总裁许主洪（Steven Hoi）&lt;a href=&quot;https://www.oschina.net/news/332267&quot; target=&quot;_blank&quot;&gt;正式加入阿里&lt;/a&gt;，出任集团副总裁，向吴嘉汇报，负责 AI To C 业务的多模态基础模型及 Agents 相关基础研究与应用解决方案。&lt;/p&gt; 
&lt;p&gt;有偶遇马云的阿里员工表示，「马老师精神真的好好，特别开心的跟我们合影打招呼，就在智能信息这层，巡楼祝大家新年快乐。」&lt;/p&gt; 
&lt;p&gt;据悉，去年 11 月 29 日，马云第一次出现在阿里西溪园区 C 区，即杭州全球总部新园区。12 月 8 日，马云参加了蚂蚁集团成立 20 周年活动。在活动上，马云着重提到了 AI 发展，他表示，从今天来看，未来 20 年的 AI 时代能带来的改变会超出所有人的想象，因为 AI 会是一个更加伟大的时代。&lt;/p&gt; 
&lt;p&gt;2 月 8 日，马云也曾被网友在新加坡的一个高尔夫球场偶遇。当时，他正在享受一场悠闲的球赛，看起来状态极佳。马云在新加坡的现身也引发了不少猜测，有人认为他可能正在为阿里巴巴的全球化战略做准备，也有人认为他只是单纯地享受个人时光。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333296</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333296</guid>
            <pubDate>Sat, 08 Feb 2025 02:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百川智能 CEO 王小川：AGI 的尽头是生命科学</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo7wg-YavNVPm-KJxFpJ9uA&quot; target=&quot;_blank&quot;&gt;百川智能创始人兼 CEO 王小川接受晚点对话的采访&lt;/a&gt;&lt;/u&gt;，表示「不是文本创作、不是物理模型，&lt;strong&gt;AGI 的尽头是生命科学&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;采访中，王小川提到，之所以坚定了公司方向聚焦医疗，是因为大模型是造人的，而医生是人类职业中最复杂的之一，所以它可以成为一个标尺。并且他认为，大模型能造出医生时，就是达到了 AGI。&lt;/p&gt; 
&lt;p&gt;同时，王小川对 DeepSeek 的「火爆全球」表示振奋，一方面他认为 DeepSeek 改变了行业格局，中国离实现 AGI 和应用爆发更近，另一方面，他觉得 DeepSeek 的出圈让更多人体验到了 AI，教育了整个行业。&lt;/p&gt; 
&lt;p&gt;在谈及训练医疗大模型费用时，&lt;strong&gt;王小川认为医疗模型有更高的价值，它关系生命健康，因此不能按 token 来算钱&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;王小川还预测了未来的技术发展趋势。AI 通过学会使用工具，一步步学习制造工具，最后形成循环，AI 写完代码自己运行，AI 自己造工具自己用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333290</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333290</guid>
            <pubDate>Sat, 08 Feb 2025 02:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国行苹果 AI 敲定与阿里巴巴合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根据科技媒体 The Information 的独家报道，&lt;strong&gt;苹果公司已经与阿里巴巴达成合作，为国行版的 iPhone 用户提供 AI 功能&lt;/strong&gt;，消息来源为一位知情人士。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0212/101826_AE4P_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，苹果与阿里巴巴共同开发的国行 AI 功能已提交给国内相关部门审核。&lt;/p&gt; 
&lt;p&gt;两位对该项目有直接了解的人士称，苹果在 2023 年开始测试来自中国开发者的不同 AI 模型，并一度选择百度作为主要合作对象，但由于百度在为苹果智能开发模型方面的进展未达到美国公司的标准，因此该合作后来被取消。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;苹果最近几个月开始考虑其他选项，评估腾讯、字节跳动、阿里巴巴以及 Deepseek 开发的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;报道还提到，&lt;strong&gt;苹果最终放弃了最近呼声很高的 DeepSeek ，因为 DeepSeek 团队缺乏支持像苹果这样的大客户所需的人力和经验&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;648&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0212/101851_M45f_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日前，苹果向开发者发送了关于「利用苹果智能的力量」开发者活动的相关邮件。&lt;/p&gt; 
&lt;p&gt;值得关注的是，本次活动将于 3 月 25 日 10:00 至 12:00 在上海&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/332912&quot;&gt;举行&lt;/a&gt;&lt;/u&gt;，活动主题将围绕苹果智能和机器学习两个方面。而这一举动，也暗示在中国大陆的苹果智能 AI 功能或将上线。&lt;/p&gt; 
&lt;p&gt;截至发稿前，苹果和阿里巴巴官方尚未对此作出回应，但这两家公司美股涨幅均已超过 1%，百度股价下跌超 4%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相关来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fapple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&quot; target=&quot;_blank&quot;&gt;https://www.theinformation.com/articles/apple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333288</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333288</guid>
            <pubDate>Sat, 08 Feb 2025 02:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>李彦宏谈 DeepSeek 爆火：创新是不能被计划的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在阿联酋迪拜举办的 World Governments Summit 2025 峰会上，百度创始人李彦宏与阿联酋 AI 部长奥马尔·苏丹·奥拉马对谈时提及 DeepSeek 表示：创新是不能被计划的。「你不知道创新何时何地到来，你所能做的是，营造一个有利于创新的环境。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-20f4da7c355029d6c8b5f97139534ed0d93.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 突然爆火背后，李彦宏称，如果回顾过去几百年，大多数创新都与降低成本有关，不仅是在人工智能领域，甚至不仅仅是在 IT 行业。如果能将成本降低一定数量、一定百分比，这意味着生产率提高了相同的百分比。这几乎就是创新的本质。而今天，创新的速度比以前快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以科技行业为例，在过去，当业界谈论摩尔定律时常说，每 18 个月性能会翻倍、成本会减半；但今天，当大家谈论大语言模型时，可以说每 12 个月，推理成本就可以降低 90% 以上。这比人们过去几十年经历的计算机革命要快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「大语言模型是一个非常庞大的领域。在中国，我们必须在推理和训练方面创新以降低成本。幸运的是，过去一年，我们看到了显著进步。」李彦宏表示，在对话中，奥拉马还提到，几周前，当 DeepSeek 成为人人都谈论的话题时，不少全球大型芯片厂商股价大幅下跌。因为巨头们此前需要花费数十亿美元用于推理数据中心、训练这些人工智能系统和模型。在 DeepSeek 的冲击下，数据中心和 AI 基础设施的未来是否会发生变化？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李彦宏表示，自己在过去一个月左右的时间里，一直在思考这个问题。从基本面来看，最重要的仍然是技术进步非常快，成本每年降低约 90%，性能越来越好。「当技术发展如此之快，你无法停止投资。你必须投资，以确保处于这场技术创新或革命的最前沿。我们仍需对芯片、数据中心和云基础设施进行持续投入，用于打造更优秀、更智能的下一代模型。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为此，企业需要使用更多的算力来尝试不同的路径。「也许，在某个时刻你会找到一条捷径，比如说只需 600 万美元就能训练出一个模型，但在此之前，你可能已经花费了数十亿美元，用来探索哪条路才是花费这 600 万美元的正确途径。」李彦宏说。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他认为，目前的 AI 应用离那种级别的应用还有很远的距离。「整个世界目前都在焦急地寻找这样的超级 App。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333284</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333284</guid>
            <pubDate>Sat, 08 Feb 2025 02:05:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度文小言（原文心一言）App 接入 DeepSeek-R1 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;iOS 版百度文小言（原文心一言）App 日前迎来了 4.9.0 版本更新，更新描述称该版本已接入 DeepSeek-R1 模型，优化拍照解题功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a4769f89c4a201f4028836651b2741d29f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲ 百度文小言（原文心一言）App 接入 DeepSeek-R1 模型&lt;/p&gt; 
&lt;p&gt;接入 DeepSeek-R1 模型后，文心一言 App 的拍照解题功能得到了显著提升。用户在使用该功能时，可以清晰地看到解题过程中的思考步骤，这与 DeepSeek 特有的思维链功能非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cc68ae51d81f06ed72ba3d94755a877e04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1944e58c65fe9c878bae4407b0cf63cf2ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用户表示，「这极大地提升了用户的解题体验。用户通过拍摄问题，系统将自动识别并给出详细的解题思路，这对于需要进行学习和复习的用户来说是个好消息。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333181</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333181</guid>
            <pubDate>Fri, 07 Feb 2025 10:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>LibreOffice 25.2 正式发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;开源办公软件 LibreOffice 25.2 &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.documentfoundation.org%2Fblog%2F2025%2F02%2F06%2Flibreoffice-25-2%2F&quot; target=&quot;_blank&quot;&gt;已正式发布&lt;/a&gt;&lt;/u&gt;，这是其今年发布的第一个重大更新版本。&lt;/p&gt; 
&lt;p&gt;正如预期的那样，这次更新带来了大量变化，遍布整个生产力套件，包括显著的界面更改、可访问性改进以及更多重要的互操作性增强，以支持跨套件的工作流程。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6e0efe1096043b00228d329f455df0ce8c1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;重要的是要记住，像 LibreOffice 这样的开源软件并非凭空出现；它是人类创造的，其中许多人无偿工作，其他人则仅被支付以工作于特定部分。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-92184ded85f6ccdaa1c8efc71bb7effd84c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们都有自己的愿望清单，列出了我们希望我们最喜欢的开源应用程序添加的功能和更改，但我们不应让这影响我们欣赏现有的、正在运行和支持的一切。&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 总共包含了 6 个月的开发成果，其中 47% 的代码提交来自由「LibreOffice 相关生态公司」雇佣的开发者，31% 来自 The Document Foundation 的开发者，其余来自志愿者。&lt;/p&gt; 
&lt;p&gt;下面介绍 LibreOffice 25.2 主要变化。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7aa0e33bc7a0a17a221b921404f8639dc2b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 能够读取和写入 OpenDocument Format (ODF) 1.4 格式。这是最新的文件格式规范，已经被 Microsoft Office 所采用。确保 ODT、ODP 等文件在 LibreOffice 中能够良好工作是很重要的。&lt;/p&gt; 
&lt;p&gt;其他方面，这次更新在 LibreOffice 24.8 引入的隐私变更基础上，增加了清除与任何文档相关的所有个人信息的能力，例如作者姓名和时间戳、编辑时间、文档模板、跟踪更改等。&lt;/p&gt; 
&lt;p&gt;任何处理大量不同文档类型的人一定会欣赏到，现在在&lt;em&gt;&lt;strong&gt;「File &amp;gt; Recent Documents」&lt;/strong&gt;&lt;/em&gt;菜单中包括了一个复选框，仅显示活动应用程序的文件。&lt;/p&gt; 
&lt;p&gt;用户界面更改包括对主题的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdesign.blog.documentfoundation.org%2F2024%2F12%2F20%2Flibreoffice-themes-will-replace-the-color-customization%2F&quot; target=&quot;_blank&quot;&gt;重大改进&lt;/a&gt;！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a1b86c12cb53d7c1288ec12cb2094880071.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;新主题可以在应用内下载并快速应用（目前只有少数几个，但随着创意人士的……嗯，发挥创意，数量预计会增长！）&lt;/p&gt; 
&lt;p&gt;如果您一直渴望有机会独立于系统主题来更改 LibreOffice UI 中的特定颜色，现在您可以做到了！前往&lt;em&gt;「Tools &amp;gt; Options &amp;gt; LibreOffice &amp;gt; Appearance」&lt;/em&gt;，在主题选择器中选择「自定义」，然后使用颜色选择器进行调整。&lt;/p&gt; 
&lt;p&gt;您可以更改从文档页面颜色、主应用背景图片、工具栏颜色等的一切——应用在更改之间会要求重启。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-03fbca1f828b47c2d50029598030f182e24.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;▲ LibreOffice 25.2 中更新的项目符号样式&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Writer&lt;/em&gt;&amp;nbsp;包含以下改进：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;更新了无序列表（项目符号）的默认项&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;跟踪更改管理器调整，包括聚焦高亮和排序&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更好地支持从 DOCX 导入的顶级行形状&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;为 DOCX 文件提供字体回退，针对不可用的字体&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;为文档设置默认缩放级别（覆盖文件中存储的级别）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;选项将回复评论提升为根评论&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;现在支持内联标题&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;从 &lt;em&gt;导航器&lt;/em&gt; 中删除特定类型的所有内容（不包括标题）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;页码向导&lt;/em&gt; 选项使数字适应现有边距&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;现在可以自定义注释背景颜色&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在 &lt;em&gt;导航器&lt;/em&gt; 中的标题上悬停，以在工具提示中查看单词和字符计数&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Calc&lt;/em&gt; 新增：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;支持在 OOXML 中导入和导出&lt;/strong&gt; &lt;code&gt;connections.xml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;状态栏图标指示是否已关闭 &lt;em&gt;自动计算&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;新增「处理重复记录」对话框，用于选择/删除重复记录&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;改进了「函数向导」对话框和「函数侧边栏」中的搜索功能&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在包含相邻数据的单元格中，默认选中所有相邻单元格&lt;/strong&gt;1&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;「数据下方摘要」选项添加到「小计」对话框&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可以将求解器模型保存到电子表格中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;添加了数据透视表、数据透视图表和自动筛选的表单保护选项&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;LibreOffice 25.2 &lt;em&gt;Impress&lt;/em&gt; 展示：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;改进了_Impress_模板&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;对象可以一步在_Impress_幻灯片中居中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;文本框对象现在支持「软边缘」和「发光」效果&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SVG 导出支持段落半透明形状文本&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在窗口模式下可以激活自动重复的幻灯片&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;打印时演示者备注中的溢出文本不再被截断&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwiki.documentfoundation.org%2FReleaseNotes%2F25.2&quot; target=&quot;_blank&quot;&gt;此版本的官方发布说明&lt;/a&gt;提供了更多关于这些以及其他更改的信息，包括代码提交、错误报告以及涵盖技术原因的博客文章链接。&lt;/p&gt; 
&lt;h3&gt;其他更改&lt;/h3&gt; 
&lt;p&gt;除了 Linux，macOS 用户还获得了与内置的「快速预览」文件预览功能的集成，允许在完全打开文档之前（可能还消除了完全打开的需要）预览文档。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Draw&lt;/em&gt;：支持在导入的 PDF 中剪辑描边路径&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Base&lt;/em&gt;：SQL 对话框现在在会话期间保留用户输入&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;em&gt;Math&lt;/em&gt;：公式可以存储在用户定义的分类中&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;与专有 OOXML 文档的互操作性调整&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;从侧边栏的「属性」面板中可以控制连字符&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;对象边界现在可以独立于格式标记进行切换&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持粘贴带有 HTML 删除线的格式化文本&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;libvisio 已更新至 v0.1.8&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;改进了无障碍访问&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此外，还有一个新的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.libreoffice.org%2F&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;LibreOffice 帮助&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fask.libreoffice.org%2F&quot; target=&quot;_blank&quot;&gt;网站&lt;/a&gt;，用户可以在那里寻求其他用户的反馈。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;em&gt;LibreOffice 25.2&amp;nbsp;下载地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.libreoffice.org%2Fdownload%2Fdownload-libreoffice%2F&quot; target=&quot;_blank&quot;&gt;https://www.libreoffice.org/download/download-libreoffice/&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333173/ibreoffice-25-2-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333173/ibreoffice-25-2-released</guid>
            <pubDate>Fri, 07 Feb 2025 09:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>男子用 DeepSeek 买彩票中奖：买 10 元中 5 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日，词条#用 DeepSeek 买彩票真中奖了#登上微博热搜榜第一，引起许多网友热议。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/172819_3xs4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据媒体报道，日前，安徽芜湖一男子发帖称，自己按照 DeepSeek 推荐的号码买双色球，真的中奖了。&lt;/p&gt; 
&lt;p&gt;该男子用 5 组 DeepSeek 推荐的数字下注，&lt;strong&gt;合计 10 元，其中一组数字中了「2+1」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/173130_nyzI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，这是第一次买双色球，也是才接触 DeepSeek，突发奇想想看看到底准不准，这样的行为不能「上头」，自己之后不会再用 DeepSeek 推荐的数字继续买彩票。&lt;/p&gt; 
&lt;p&gt;据中国福利彩票服务热线工作人员介绍，&lt;strong&gt;上述情况是中了六等奖，奖金为 5 元。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于该男子的做法，有网友表示：「合计 10 元，中了 5 元？有没有可能没有 DeepSeek，你买五组也有这个概率呢？我觉得也没必要神话 DeepSeek。」「随机概率这么大，跟它真没太大关系。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333169</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333169</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度李彦宏：自动驾驶比人开车安全十倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日消息，「世界政府峰会」（World Goverments Summit 2025）今日在阿联酋迪拜开幕，百度创始人李彦宏今日上午在主论坛上与阿联酋 AI 部长奥马尔・苏丹・奥拉马（Omar Sultan AI Olama）对谈时表示，Robotaxi 可以大大降低交通事故死亡率。从萝卜快跑的实际记录来看，出险率仅为人类驾驶员的 1/14。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8b66f69d2ba73a703403b32ebdae56e2f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李彦宏表示：「技术进步非常快，自动驾驶比人类司机安全十倍。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74a55024af52c507dd898d356bf590ace0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据了解，2024 年第二季度，百度的自动驾驶服务萝卜快跑供应的自动驾驶订单约 89.9 万单，同比增长 26%。截至 2024 年 7 月 28 日，萝卜快跑累计为公众提供的自动驾驶出行服务订单超过 700 万单。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/301302&quot; target=&quot;news&quot;&gt;百度旗下的「萝卜快跑」无人驾驶出租车武汉街头撞倒行人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333160</guid>
            <pubDate>Fri, 07 Feb 2025 08:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>