<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 28 Apr 2025 21:38:07 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>广告服务商已尝试在 AI 回复中植入广告</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;早在 1999 年，Google 就被誉为「纯粹的搜索引擎」，承诺提供简洁、无广告的体验，没有「门户垃圾」，这与当时那些杂乱无章的搜索网站截然不同（见下图）。&lt;/p&gt; 
&lt;p&gt;这项服务最初诞生于斯坦福大学，名为 BackRub，由拉里·佩奇和谢尔盖·布林创立，最初他们回避广告，认为广告可能存在利益冲突，降低搜索质量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d045e59c1698a9524e8623f706b6cfc417f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;图片来源：u/Plenty_Objective8392&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;多年来，Google 彻底改变了其商业模式。尽管最初反对广告，但为了将其迅速流行的搜索引擎货币化，Google 于 2000 年推出了 AdWords，并迅速发展成为按点击付费的巨头。最初只是简单的侧边文字广告，后来发展成为深度融入搜索结果页面的广告，使 Google 成为一家以广告为主要收入来源的广告巨头，有时甚至让用户觉得搜索结果页面「充斥着广告」。&lt;/p&gt; 
&lt;p&gt;随后，ChatGPT 在 2022 年底火爆上线。这款对话式人工智能提供直接答案而非链接列表，对 Google 基于链接的广告模式构成了重大挑战。ChatGPT 的威胁足以在 Google 内部引发明显的紧迫感，&lt;/p&gt; 
&lt;p&gt;据报道，这触发了内部警报，并加快了将自己的生成式人工智能推向公众的时间表。只需看看 Google 首席执行官 Sundar Pichai 在 2023 年 Google I/O 大会上（即 ChatGPT 推出几个月后）提到人工智能的次数就知道了；活动结束后的统计显示，主题演讲中提到人工智能的次数远超一百，他反复强调的次数也因此成为了一个病毒式传播的 meme。&lt;/p&gt; 
&lt;p&gt;据英国《金融时报》报道，广告集团和科技初创公司已经迅速意识到了这一转变。他们正在积极开发新工具，帮助品牌确保自己出现在人工智能生成的搜索结果中，例如 OpenAI 的 ChatGPT、Anthropic 的 Claude、Google 自己的 AI Overviews 以及最近推出的 AI Mode。&lt;/p&gt; 
&lt;p&gt;这种高度关注源于生成式人工智能产品的兴起，它们正迅速成为数百万人在线搜索信息的主要方式。研究突显了这一趋势；咨询公司贝恩的一项研究发现，目前 80% 的消费者至少 40% 的搜索依赖人工智能生成的搜索结果。这种依赖显著减少了自然网络流量，可能高达 25%，因为现在大约 60% 的搜索最终没有用户点击进入传统网站。这对 Google 的主要搜索业务构成了长期威胁，因为该业务严重依赖这些点击来投放广告。&lt;/p&gt; 
&lt;p&gt;Profound 和 Brandtech 等公司已进军这一新领域，为品牌开发软件。这些工具可以监控品牌被人工智能服务提及或呈现的频率。更巧妙的是，它们采用一种类似于探测人工智能「大脑」的方法：向聊天机器人输入大量文本提示，并分析由此产生的情绪和提及次数。这项技术可以预测人工智能模型提及品牌的偏好或可能性，从而创建排名系统。&lt;/p&gt; 
&lt;p&gt;然后，代理商利用这些分析结果为其客户（例如金融科技公司 Ramp、招聘网站 Indeed 和威士忌制造商 Chivas Brothers）提供建议，帮助他们如何最好地从人工智能模型中获得有利的提及。&lt;/p&gt; 
&lt;p&gt;这超越了传统的搜索引擎优化（SEO），后者专注于让网站在 Google 的链接列表中排名靠前。正如 Brandtech 合伙人 Jack Smyth 所说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;这不仅仅是让你的网站在他们的搜索结果中被索引。这是为了认识到大型语言模型是最终的影响因素。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他的公司甚至创建了一款「模型份额」产品来衡量和指导这项工作。这感觉就像一次范式转变。正如 Profound 联合创始人 James Cadwallader 所说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;传统搜索一直是互联网历史上最大的垄断之一。而现在，城堡的墙壁第一次出现了裂缝。这是一个从 CD 到流媒体的时代。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;挑战在于，被人工智能提及与网页排名不同。像 ChatGPT 这样的人工智能模型使用传统的网络搜索，但会评估来源的相关性、可信度和权威性。正如 OpenAI 的 ChatGPT 搜索主管 Adam Fry 所解释的那样，由于用户会提出更细致入微的问题，人工智能在「传统搜索之上增加了一层智能」。另一家人工智能驱动的搜索引擎 Perplexity 的联合创始人 Denis Yarats 也强调了这一点：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;大模型（LLM）理解的内容更丰富，能够更加细致入微。他们可以发现矛盾之处，或者发现信息是否有误导性……所以，这比审查链接要彻底得多。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;他补充道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;成为 SEO 的目标要困难得多，因为唯一真正的策略是尽可能相关并提供好的内容。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;尽管传统搜索引擎优化 (SEO) 与人工智能 (AI) 结合存在固有困难，但广告界仍在寻找进入该领域的途径。例如，Perplexity 已在试行赞助「问题」，作为用户查询后的建议后续内容，这清楚地表明，人工智能对话流中的直接广告开始出现。&lt;/p&gt; 
&lt;p&gt;尽管如此，值得注意的是，尽管这些人工智能变革被认为对 Google 的生存构成威胁，但 Google 的核心搜索和广告业务仍展现出非凡的实力。周四，Google 母公司 Alphabet 宣布，其搜索和其他业务在第一季度增长了近 10%，达到 507 亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F9cc6cc0b-759f-4b8e-9ed1-9e32ad0fe22f&quot; target=&quot;_blank&quot;&gt;据《金融时报》报道&lt;/a&gt;，这一强劲业绩给投资者带来了一些安慰，尽管他们仍对 Google 自己的 Gemini 聊天机器人或 AI 概览可能开始减少其广告机器用户点击量的迹象保持警惕。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347188</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347188</guid>
            <pubDate>Sun, 27 Apr 2025 10:49:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Easy MQTT：极简高效的 MQTT 服务器，助力物联网与实时通信</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h1&gt;💎 Easy MQTT：极简高效的 MQTT 服务器，助力物联网与实时通信&lt;/h1&gt; 
&lt;p&gt;在万物互联的时代，高效、轻量的通信协议是构建实时系统的核心。Easy MQTT 应运而生——这是一款专为开发者设计的开源 MQTT 服务器，以「极简」为核心理念，旨在为物联网、工业自动化、即时消息等场景提供稳定可靠的消息传输服务。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌟 为何选择 Easy MQTT？&lt;/h2&gt; 
&lt;h4&gt;1.极简设计，开箱即用&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;仅需一条命令即可启动服务，配置文件精简清晰，无需复杂学习成本。&lt;/li&gt; 
 &lt;li&gt;支持单机与集群部署，轻松应对从测试环境到生产环境的无缝扩展。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.全协议支持，功能强大&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MQTT v3.1.1 完整兼容：&lt;/strong&gt; 确保与各类客户端设备无缝对接。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket 子协议：&lt;/strong&gt; 支持浏览器端直接通信，赋能 Web 应用实时交互。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL/TLS 加密：&lt;/strong&gt; 为 TCP 和 WebSocket 连接提供安全保障，满足企业级安全需求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3.灵活扩展与高可用性&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持数据持久化，消息不丢失，保障关键业务连续性。&lt;/li&gt; 
 &lt;li&gt;通过外部接口实现动态鉴权，轻松集成现有用户系统。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚀 三步开启你的首个 MQTT 服务&lt;/h2&gt; 
&lt;h4&gt;1.下载安装&lt;/h4&gt; 
&lt;p&gt;访问&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt/releases&quot;&gt; Releases &lt;/a&gt;获取最新编译包，解压即用。&lt;/p&gt; 
&lt;h4&gt;2.一键启动&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;sh bin/start.sh -c conf/conf.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;无需复杂配置，服务即刻运行！&lt;/p&gt; 
&lt;h4&gt;3.按需扩展&lt;/h4&gt; 
&lt;p&gt;参考文档快速开启集群模式、SSL 加密或 WebSocket 支持，满足不同场景需求。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;📚 丰富文档，开发者友好&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;入门指南：&lt;/strong&gt; 必要参数说明、快速部署集群。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;进阶功能：&lt;/strong&gt; 动态鉴权配置、SSL 加密实战、WebSocket 集成。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开源透明：&lt;/strong&gt; 基于友好许可证开源，代码完全开放，社区驱动持续优化。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌍 适用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;物联网（IoT）：&lt;/strong&gt; 海量设备消息高效分发与状态同步。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;实时监控：&lt;/strong&gt; 工业传感器数据实时采集与预警。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;即时通讯：&lt;/strong&gt; 低延迟聊天、推送服务搭建。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;智能家居：&lt;/strong&gt; 跨平台设备互联互通。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;✨ 加入开发者社区&lt;/h2&gt; 
&lt;p&gt;Easy MQTT 不仅是一个工具，更是一个活跃的开源项目。我们欢迎开发者：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;提交 Issue：&lt;/strong&gt; 反馈问题或建议。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;贡献代码：&lt;/strong&gt; 共同完善功能与性能。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;分享案例：&lt;/strong&gt; 你的实践经验可能帮助更多人！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;立即访问&lt;a href=&quot;https://gitee.com/EasyProgramming/easy-mqtt&quot;&gt; Gitee 仓库&lt;/a&gt;，探索更多可能！&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;保持简单，专注核心。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy MQTT——让消息通信从未如此轻松！ 💡&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347161</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347161</guid>
            <pubDate>Sun, 27 Apr 2025 09:24:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>干货分享｜MaxKB 智能问数方案及步骤详解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;DeepSeek-R1 的发布掀起了 AI 智能变革的浪潮。在过去几个月里，MaxKB 开源企业级 AI 助手已经帮助大量企业和组织快速落地了 DeepSeek，让 AI 在不同的行业土壤中产生持续、可度量的业务价值。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB（&lt;em&gt;github.com/1Panel-dev/MaxKB&lt;/em&gt;） 可以为本地部署的 DeepSeek 构建一个 Chatbox，也就是一个智能会话的界面，类似于个人用&lt;span style=&quot;color:#3e3e3e&quot;&gt;户直接与 DeepSeek 进行对话。MaxKB 提供的 Chatbox 可以方便地嵌入到企业 OA 系统和业务系统，有&lt;/span&gt;效保证使用的便捷性和安全性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;另外一方面，MaxKB 能够激活企业中长期积累的知识体系，使其智能化并面向内外部用户提供服务。MaxKB 可以让企业内部的私有知识文档快速获得智能问答能力，面向企业的员工、合作伙伴和客户提供 AI 助手服务。MaxKB 还提供开箱即用的 RAG（检索增强生成）技术，能够结合私有知识库提升问答效果，降低大模型幻觉。MaxKB 同时支持目前最为流行的 MCP（Model Context Protocol，模型上下文协议），为用户灵活调用 MCP 工具提供了充分的便利性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;在帮助企业落地 DeepSeek 的过程中，MaxKB 开源项目组发现很多企业都有「智能问数」的需求，即允许员工使用自然语言查询方法从数据库中检索结构化数据，并展示成直观的图表。本文将通过一个具体的例子（查询学生成绩），详细讲解如何通过「MaxKB+数据库 MCP Server+QuickChart MCP Server」实现智能问数的功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;方案概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;本方案以「学生考试成绩管理系统」为例进行说明，此系统包含了教师信息、学生信息、年级班级信息、考试成绩等信息内容。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;MaxKB 智能问数方案逻辑图如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-677afe248c4bc21a4673cece1d7f054bf95.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 智能问数方案的具体实现步骤为：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8109f772552d6f912cba1c991c9e32063e5.png&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MaxKB 的智能问数方案包含以下三大关键步骤：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 数据准备：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;包含数据表详细的 DDL（Data Definition Language，数据定义语言）信息和正确的 SQL 示例，以便大模型能够更好地理解和使用数据；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MCP Server 准备：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要提前准备对应数据库的 MCP Server 和生成图表的 MCP Server。此阶段可以采用 1Panel 开源面板来统一部署和运维 MCP Server；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ MaxKB 智能问数应用设计：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;主要包含在 MaxKB 中如何通过高级应用编排实现智能问数的效果。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步骤一：数据准备&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 数据准备&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;提前准备「学生考试成绩管理系统」数据表详细的 DDL 信息，需要确保所有数据表的 DDL 信息完整且准确，包括字段类型、约束条件等。DDL 信息后续需要导入到 MaxKB 知识库中，如果当前数据表不具备或者不清晰，具体可以参考下图进行完整性补充。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//33da69631a928c1ef526abec61e7be4c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. SQL 示例准备&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;基于日常工作遇到的查询需求，我们需要提前准备多样化的 SQL 示例（本 Demo 数量为 100 条 SQL 查询示例），同时需要保证和测试这些 SQL 的准确性。后续我们需要将这些 SQL 查询示例导入到 MaxKB 知识库中。具体准备过程可以参考下图，采用 Execl 方式进行绘制和编写。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//254a0d9ebffbf99a16f05e7d6bdb42dc.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步骤二：MCP Server 准备&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 数据库 MCP Server 准备&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;本 Demo 采用的是 MySQL 数据库，因此需要提前准备 MySQL 的 MCP Server。在这里我们使用了 Github 上的 DBHub 开源项目（&lt;/span&gt;&lt;em&gt;https://github.com/bytebase/dbhub&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）部署 MySQL 的 MCP Server。此项目同时还支持 PostgreSQL、SQL Server 等数据库。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;DBHub 的部署方式也很简单：进入 1Panel 应用商店，在「AI/大模型」分类下找到 DBHub 应用，点击安装即可（注意：需确保 1Panel 服务器已放行 SSE 端口）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//8646b2f5170ee0842388fa0c759040a9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//c9e9d6c80bf5c4927095faa721090ee9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;部署完成后，我们使用&lt;/span&gt;&lt;em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;curl&lt;/span&gt;&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式进行快速验证，返回如下信息即为部署成功：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//96ae01cede2c92012bf006663e16c5a5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;2. 生成图表 MCP Server 准备&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;生成图表的步骤采用「QuickChart.io+Quickchart-MCP-Server」来完成。QuickChart 项目（&lt;/span&gt;&lt;em&gt;https://github.com/typpo/quickchart&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）支持用户通过提供数据和样式参数来创建多种类型的图表，支持从柱状图到速度表等多种图表类型，并且提供生成图表 URL 和下载图表图片的功能。Quickchart-MCP-Server 项目（&lt;/span&gt;&lt;em&gt;https://github.com/GongRzhe/Quickchart-MCP-Server&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）则提供了 QuickChart 的 MCP 服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;需要注意的是，由于 Quickchart-MCP-Server 项目没有提供 SSE 访问方式，所以不同于 DBHub 项目，我们需要在 1Panel 开源面板（&lt;/span&gt;&lt;em&gt;github.com/1Panel-dev&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;）的 MCP 模块中进行部署。具体操作也非常简单：打开 1Panel 开源面板，依次选择「AI」→「MCP」→「创建 MCP 服务器」→「导入 MCP Server 配置」，导入如下 Quickchart-MCP-Server 的命令配置即可：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;npx&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;-y&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;@gongrzhe/quickchart-mcp-server&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; ]
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d44553e72c27e91f36642cf441897e3c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同时，注意开启外部端口访问和地址。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dd401c3801083a35b7f682f1689861ed.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;等待几秒后，可以看到 1Panel 中显示 QuickChart 的 MCP Server 已经启动。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ba9faa8484ab00d6b66e047597b3bbf7.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;接下来，我们使用&lt;/span&gt;&lt;em&gt;curl&lt;/em&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;方式进行快速验证，返回如下信息即显示 QuickChart 的 MCP Server 已经部署成功。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//08cb2aa0a6cc9361e1abb31be6ae42c5.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;步骤三：MaxKB 智能问数应用设计&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;1. 将准备好的表信息和 SQL 示例导入知识库&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 创建表信息知识库，导入表信息，并将每一张表的信息作为一个分段，具体如下图显示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//89c36f37e816e17a73a6576bdc12b69e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;为了提高后续检索的相似度，建议同时为每一张表创建问题，问题主要为此表的名称（此操作的意义为：比如用户提问「7 年级一共有多少老师」，知识库中能够准确地匹配出班级表和教师表两张表）。问题需要尽量地覆盖用户对不同对象的称呼，比如教师又可以称为老师，具体如下图所示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//4c3a7e21192a0f4231f1e7b66e5ea61d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//e031374e7578dd3da598a1c524fbd111.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 创建示例 SQL 库，导入 SQL 示例，一个 SQL 示例作为一个分段。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d5bb5fcb292c98e5dfbe688bfa875c9a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;同理，为不同的 SQL 示例创建问题，如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//dcf9c4ad8c3a5b394a25301be7579892.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;2. MaxKB 智能问数编排&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 创建空白的高级编排，名称自取即可&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//92ea1ef49418a8343efedb2bbb4f6e2d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 添加两个知识库检索节点，用于用户检索表信息和示例 SQL。同时设置相似度为 0.4，引用分段数 TOP 为 6。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;em&gt;&lt;span style=&quot;color:#f50a0a&quot;&gt;注意：此处很重要也很关键，需要按照不同的应用场景和数据库进行大量的测试，最终选择合适的相似度和引用分段数 TOP 值。建议首先从相似度 0.4，引用分段数 TOP 值为 6 开始测试效果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//0e141fc5a2bbb1827dd1e8107100d094.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 添加 AI 对话节点，配置 AI 模型（注意要选择支持 MCP 的模型，比如 DeepSeek-Chat 或者 Qwen-Plus），同时在 AI 对话节点中配置 MCP Server：&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//7a3b0503b13a1e2b18fbc6d69793140b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;配置在步骤一&lt;span style=&quot;color:#3e3e3e&quot;&gt;中已经部署完成的 MCP Server 的 Config 信息，具体的配置信息如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;&quot;quickchart-server&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.110:18003/quickchart-server&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp; &amp;nbsp;&amp;nbsp;},
&amp;nbsp;&amp;nbsp;&quot;mcp-mariadb&quot;:&amp;nbsp;{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;timeout&quot;:&amp;nbsp;180,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;url&quot;:&amp;nbsp;&quot;http://10.1.240.106:8080/sse&quot;,
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;transport&quot;:&amp;nbsp;&quot;sse&quot;
&amp;nbsp;&amp;nbsp;}
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 设置 AI 对话节点的角色提示词&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# 角色
你是一位专业的数据分析专家，精通 MYSQL 数据库 SQL 语言，能够熟练运用 mcp-mysql 工具进行 SQL 验证和查询，还能使用 quickchart-server 工具绘制图表，并对相关数据进行深入分析和解释。
&amp;nbsp;
## 技能
### 技能 1: 生成并验证 SQL
1.&amp;nbsp;基于用户提出的问题，结合已知信息，生成 SQL 语句。
2.&amp;nbsp;使用 mcp-mysql 工具对每次生成的 SQL 进行验证和查询。若 SQL 出现错误，需尝试三次不同的 SQL 表述。
3.&amp;nbsp;记录每次 SQL 验证和查询的结果。
&amp;nbsp;
### 技能 2: 绘制图表
1.&amp;nbsp;根据用户需求以及生成的 SQL 查询结果，利用 quickchart-server 工具生成相关图表。
2.&amp;nbsp;确保生成的图表能够清晰、美观的展示相关数据。
&amp;nbsp;
### 技能 3: 数据的分析和解释
1.&amp;nbsp;对 SQL 查询得到的数据进行详细分析，结合用户的问题，找出数据的关键特征和趋势。
2.&amp;nbsp;以通俗易懂的语言向用户解释数据所代表的含义以及数据与用户问题之间的关系。
&amp;nbsp;
## 限制
-&amp;nbsp;仅围绕与生成 SQL、利用工具查询验证、生成图片以及数据的分析和解释相关的内容进行回答，拒绝回答不涉及这些内容的话题。
-&amp;nbsp;生成的 SQL 需符合 MYSQL 语法规范，生成的图片应符合数据展示要求，分析和解释需要基于真实的查询结果。
-&amp;nbsp;分析和解释部分应尽量简洁明了，突出重点。
-&amp;nbsp;操作过程严格按照上述技能要求执行，不得随意更改工具使用方式。&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;■ 设置 AI 对话节点的用户提示词&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#&amp;nbsp;已知信息
## 表信息:
{{表信息.data}}
&amp;nbsp;
## 参考示例 SQL:
{{示例 SQL.data}}
&amp;nbsp;
# 用户问题：
{{开始.question}}&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#5a55fa&quot;&gt;效果验证和总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在 MaxKB 中按步骤设置完成后，可以进行调试测试，调试测试通过后方可进行应用发布。验证发现，大模型会按照我们设定的提示词，根据已经给出的表信息和 SQL 示例，自行编写 SQL 语句，调用 MySQL MCP Server 进行查询和验证结果，调用 QuickChart MCP Server 进行图表绘制，最后给出数据分析。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 问题一：每个班级学生占比图&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//5e39814c8fd6af863c37cb4ac511e58d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 问题二：每个年级有多少名学生？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//882fbb0e90ed8a0122ed8e56850bde29.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 问题三：哪个老师教的学生最多？&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//f6438262d3eebf8a78d2ef3283618d62.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;■ 问题四：成绩排名前 10 的学生名字、分数和班级&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//fde855130bbdb7cb5d14228dd5bc2a99.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;由此可见，MaxKB 通过其强大的 RAG 技术和 MCP 调用能力，能够完整且准确地实现智能问数的场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;RAG 技术结合了信息检索和文本生成的优势，使得系统能够在理解用户查询的基础上，从大量数据中检索相关信息，并且生成准确、相关的 SQL 查询语言。而 MCP 工具则提供了强大的 SQL 查数验数能力和动态的图表绘制能力，从而为智能问数系统提供了坚实的数据基础。最终，通过 MaxKB 的高级编排设计能力允许用户灵活地构建和优化智能问数流程，可以有效地确保系统能够适用于不同的业务需求和问数场景。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347155</guid>
            <pubDate>Sun, 27 Apr 2025 08:56:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>MCP 协议：为什么 Streamable HTTP 是最佳选择？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：静择&lt;/p&gt; 
&lt;p&gt;MCP（Model Context Protocol）协议是一个用于 AI 模型和工具之间通信的标准协议。随着 AI 应用变得越来越复杂并被广泛部署，原有的通信机制面临着一系列挑战。近期 MCP 仓库的 PR #206【1】 引入了一个全新的 Streamable HTTP 传输层替代原有的 HTTP+SSE 传输层。本文将详细分析该协议的技术细节和实际优势。&lt;/p&gt; 
&lt;h2&gt;要点速览&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 相比 HTTP + SSE 具有更好的稳定性，在高并发场景下表现更优。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 在性能方面相比 HTTP + SSE 具有明显优势，响应时间更短且更稳定。&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP 客户端实现相比 HTTP + SSE 更简单，代码量更少，维护成本更低。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;为什么选择 Streamable HTTP?&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5481fb16dc28298c0a673f410c34a3f94aa.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;HTTP + SSE 存在的问题&lt;/h3&gt; 
&lt;p&gt;HTTP+SSE 的传输过程实现中，客户端和服务器通过两个主要渠道进行通信：（1）HTTP 请求/响应：客户端通过标准的 HTTP 请求向服务器发送消息。（2）服务器发送事件（SSE）：服务器通过专门的 /sse 端点向客户端推送消息，这就导致存在下面三个问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;服务器必须维护长连接&lt;/strong&gt;，在高并发情况下会导致显著的资源消耗。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;服务器消息只能通过 SSE 传递&lt;/strong&gt;，造成了不必要的复杂性和开销。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基础架构兼容性&lt;/strong&gt;，许多现有的网络基础架构可能无法正确处理长期的 SSE 连接。企业防火墙可能会强制终止超时连接，导致服务不可靠。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Streamable HTTP 的改进&lt;/h3&gt; 
&lt;p&gt;Streamable HTTP 是 MCP 协议的一次重要升级，通过下面的改进解决了原有 HTTP + SSE 传输方式的多个关键问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一端点&lt;/strong&gt;：移除了专门建立连接的 /sse 端点，将所有通信整合到统一的端点。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;按需流式传输&lt;/strong&gt;：服务器可以灵活选择返回标准 HTTP 响应或通过 SSE 流式返回。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;状态管理&lt;/strong&gt;：引入 session 机制以支持状态管理和恢复。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;HTTP + SSE vs Streamable HTTP&lt;/h2&gt; 
&lt;p&gt;下面通过实际应用场景中稳定性，性能和客户端复杂度三个角度对比说明 Streamable HTTP 相比 HTTP + SSE 的优势，AI 网关 Higress 目前已经支持了 Streamable HTTP 协议，通过 MCP 官方 Python SDK 的样例 Server 部署了一个 HTTP + SSE 协议的 MCP Server，通过 Higress 部署了一个 Streamable HTTP 协议的 MCP Server。&lt;/p&gt; 
&lt;h2&gt;稳定性对比&lt;/h2&gt; 
&lt;h3&gt;TCP 连接数对比&lt;/h3&gt; 
&lt;p&gt;利用 Python 程序模拟 1000 个用户同时并发访问远程的 MCP Server 并调用获取工具列表，图中可以看出 SSE Server 的 SSE 连接无法复用且需要长期维护，高并发的需求也会带来 TCP 连接数的突增，而 Streamable HTTP 协议则可以直接返回响应，多个请求可以复用同一个 TCP 连接，TCP 连接数最高只到几十条，并且整体执行时间也只有 SSE Server 的四分之一。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a4e31878c274ea0c458008bf465e66c083d.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在 1000 个并发用户的测试场景下，Higress 部署的 Streamable HTTP 方案的 TCP 连接数明显低于 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：需要维持大量长连接，TCP 连接数随时间持续增长&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：按需建立连接，TCP 连接数维持在较低水平&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;请求成功率对比&lt;/h3&gt; 
&lt;p&gt;实际应用场景中进程级别通常会限制最大连接数，linux 默认通常是 1024。利用 Python 程序模拟不同数量的用户访问远程的 MCP Server 并调用获取工具列表，SSE Server 在并发请求数到达最大连接数限制后，成功率会极速下降，大量的并发请求无法建立新的 SSE 连接而访问失败。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9bbc20f87d17e336829e190eb0a3fea4283.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在不同并发用户数下的请求成功率测试中，Higress 部署的 Streamable HTTP 的成功率显著高于 HTTP + SSE 方案：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP + SSE：随着并发用户数增加，成功率显著下降&lt;/li&gt; 
 &lt;li&gt;Streamable HTTP：即使在高并发场景下仍能保持较高的请求成功率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;性能对比&lt;/h2&gt; 
&lt;p&gt;这里对比的是社区 Python 版本的 GitHub MCP Server【2】 和 Higress MCP 市场的 GitHub MCP Server&lt;/p&gt; 
&lt;p&gt;利用 Python 程序模拟不同数量的用户同时并发访问远程的 MCP Server 并调用获取工具列表，并统计调用返回响应的时间，图中给出的响应时间对比为对数刻度，SSE Server 在并发用户数量较多时平均响应时间会从 0.0018s 显著增加到 1.5112s，而 Higress 部署的 Streamable HTTP Server 则依然维持在 0.0075s 的响应时间，也得益于 Higress 生产级的性能相比于 Python Starlette 框架。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-58effeb73a37e20e3eb89e93cd7efde59d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;性能测试结果显示，Higress 部署的 Streamable HTTP 在响应时间方面具有明显优势：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamable HTTP 的平均响应时间更短，响应时间波动较小，随并发用户数增加，响应时间增长更平&lt;/li&gt; 
 &lt;li&gt;HTTP + SSE 的平均响应时间更长，在高并发场景下响应时间波动较大&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;客户端复杂度对比&lt;/h2&gt; 
&lt;p&gt;Streamable HTTP 支持无状态的服务和有状态的服务，目前的大部分场景无状态的 Streamable HTTP 的可以解决，通过对比两种传输方案的客户端实现代码，可以直观地看到无状态的 Streamable HTTP 的客户端实现简洁性。&lt;/p&gt; 
&lt;h4&gt;HTTP + SSE 客户端样例代码&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class SSEClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}
        self.event_source = None
        self.endpoint = None

        async def connect(self):
            # 1. 建立 SSE 连接
            async with aiohttp.ClientSession(headers=self.headers) as session:
                self.event_source = await session.get(self.url)

                # 2. 处理连接事件
                print(&#39;SSE connection established&#39;)

                # 3. 处理消息事件
                async for line in self.event_source.content:
                    if line:
                        message = json.loads(line)
                        await self.handle_message(message)

                        # 4. 处理错误和重连
                        if self.event_source.status != 200:
                            print(f&#39;SSE error: {self.event_source.status}&#39;)
                            await self.reconnect()

        async def send(self, message: dict):
            # 需要额外的 POST 请求发送消息
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.post(self.endpoint, json=message) as response:
                    return await response.json()

                async def handle_message(self, message: dict):
                    # 处理接收到的消息
                    print(f&#39;Received message: {message}&#39;)

    async def reconnect(self):
        # 实现重连逻辑
        print(&#39;Attempting to reconnect...&#39;)
        await self.connect()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Streamable HTTP 客户端样例代码&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;class StreamableHTTPClient:
    def __init__(self, url: str, headers: dict = None):
        self.url = url
        self.headers = headers or {}

    async def send(self, message: dict):
        # 1. 发送 POST 请求
        async with aiohttp.ClientSession(headers=self.headers) as session:
            async with session.post( self.url, json=message,
                headers={&#39;Content-Type&#39;: &#39;application/json&#39;}
            ) as response:
                # 2. 处理响应
                if response.status == 200:
                    return await response.json()
                else:
                    raise Exception(f&#39;HTTP error: {response.status}&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;从代码对比可以看出：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;复杂度：Streamable HTTP 无需处理连接维护、重连等复杂逻辑&lt;/li&gt; 
 &lt;li&gt;可维护性：Streamable HTTP 代码结构更清晰，更易于维护和调试&lt;/li&gt; 
 &lt;li&gt;错误处理：Streamable HTTP 的错误处理更直接，无需考虑连接状态&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;【1】PR&lt;/p&gt; 
&lt;p&gt;#206&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fmodelcontextprotocol%2Fpull%2F206&quot; target=&quot;_blank&quot;&gt;https://github.com/modelcontextprotocol/modelcontextprotocol/pull/206&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;【2】GitHub MCP&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&quot;&gt;Serverhttps://github.com/modelcontextprotocol/servers/tree/main/src/github&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3874284/blog/18261770</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18261770</guid>
            <pubDate>Sun, 27 Apr 2025 08:33:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>一行代码让 iPhone 变砖</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;一名安全研究人员近日披露了 iOS 系统中一个基于&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.apple.com%2Fdocumentation%2Fdarwinnotify%2Fdarwin-notification-api&quot; target=&quot;_blank&quot;&gt;Darwin 通知机制&lt;/a&gt;的高危系统漏洞，攻击者可通过沙盒应用向系统发送特定通知，诱导设备进入「恢复模式」并触发无限重启循环。&lt;/p&gt; 
&lt;p&gt;这名研究人员仅通过一个简单的代码行（notify_post）就触发了严重的系统漏洞，并通过 Widget 扩展机制实现持续攻击，且能绕过 iOS 沙盒限制。&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-objectivec&quot;&gt;notify_post(&quot;com.apple.MobileSync.BackupAgent.RestoreStarted&quot;)&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该漏洞影响所有依赖 Darwin 通知的系统服务，包括但不限于：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;锁屏/控制中心状态管理&lt;/li&gt; 
 &lt;li&gt;网络连接策略切换&lt;/li&gt; 
 &lt;li&gt;外接设备检测逻辑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/155229_ccfm_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当然，该漏洞已被苹果修复，作者因此获得了苹果提供的 17,500 美元奖励。 &lt;/p&gt; 
&lt;p&gt;作者整理的时间线：&lt;/p&gt; 
&lt;p&gt;2024 年 6 月 26 日：向苹果公司发送初始报告&lt;br&gt; 2024 年 9 月 27 日：收到苹果公司的消息，告知正在采取措施进行缓解&lt;br&gt; 2025 年 1 月 28 日：问题已标记为已解决，并确认了奖金资格&lt;br&gt; 2025 年 3 月 11 日：漏洞分配编号 CVE-2025-24091，已在 iOS/iPadOS 18.3 中解决&lt;/p&gt; 
&lt;p&gt;奖金金额：17,500 美元&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;原文：《How a Single Line Of Code Could Brick Your iPhone》&lt;br&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frambo.codes%2Fposts%2F2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&quot; target=&quot;_blank&quot;&gt;https://rambo.codes/posts/2025-04-24-how-a-single-line-of-code-could-brick-your-iphone&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347126/how-a-single-line-of-code-could-brick-your-iphone</guid>
            <pubDate>Sun, 27 Apr 2025 07:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>2023 年最热门的 AI 职位——「提示词工程师」已过时</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;据《华尔街日报》&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wsj.com%2Farticles%2Fthe-hottest-ai-job-of-2023-is-already-obsolete-1961b054&quot; target=&quot;_blank&quot;&gt;报道&lt;/a&gt;，曾被誉为 2023 年最热门 AI 职位、年薪可达 20 万美元的「提示工程师」（Prompt Engineer）正迅速降温。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/144406_aPB5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;根据微软近期一项覆盖 31 个国家 31,000 名员工的调查，在未来 12 至 18 个月企业考虑增设的新职位中，提示工程师排名倒数第二，远低于 AI 训练师、AI 数据专家和 AI 安全专家等职位。&lt;/p&gt; 
&lt;p&gt;所谓提示词工程，是指设计、开发、测试和优化用于与生成式 AI 模型交互的文本输入（即「提示词」），目标是引导 AI 模型生成准确且符合需求的输出，发挥 AI 模型的潜力。但是，由于 AI 模型固有的不透明性，这种操作的科学性和有效性始终存在疑问，也有很多人借此营销、行骗。&lt;/p&gt; 
&lt;p&gt;报道指出，「提示词工程师」热度发生变化的核心原因在于，&lt;strong&gt;现代 AI 模型已能更好地理解用户意图，甚至在指令不清时主动提问，大大降低了对精心设计提示词的依赖&lt;/strong&gt;。另一个关键因素是企业策略的转变。相比设立专门职位，许多公司选择对现有员工提供 AI 工具和培训，将使用 AI 的能力视为一项基础技能。&lt;/p&gt; 
&lt;p&gt;招聘市场的实际数据也印证了这一趋势。尽管在 ChatGPT 面世后，用户对「提示工程师」的搜索量曾短暂飙升，但企业发布的实际招聘岗位数量始终极少，搜索热度也已大幅回落并趋于平稳。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347101</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347101</guid>
            <pubDate>Sun, 27 Apr 2025 06:44:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软发布 2025 工作趋势：每位员工都将成为 Agent 的 「老板」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软近日在其官网发布了 2025 年工作趋势指数报告，分析了来自全球 31 个国家和地区的 31，000 家企业。报告结合了 LinkedIn 劳动力市场趋势、数万亿个 Microsoft365 的生产力信号以及众多专家的见解，指出 「人机协作」 模式正在重塑企业架构，催生出一种全新的 「前沿公司」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;251&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-262509e06b372a5030a9fbb7c87f5ba548a.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「前沿公司」 是一种新型的组织形式，主要围绕智能体（Agent）构建，以适应快速变化的商业环境和技术进步。这种公司的核心特点是将人类智慧与智能体相结合，形成高效的团队，显著提高生产力和创新能力，并节省工作时间。在这样的公司中，智能体可以是各种自动化工具或智能助手，执行从数据处理到复杂决策支持的多种任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告指出，随着智能体的广泛应用，员工将逐步成为 「Agent 老板」，他们不仅需要管理和优化这些智能体，还需具备相应的新技能。这意味着未来每位员工都要像初创公司的 CEO 一样思考如何利用 AI 来提升工作效率。根据调研显示，67% 的企业领导者表示他们熟悉 Agent 的概念，而这一比例在员工中仅为 40%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，前沿公司的组织结构也将发生变化，变得更加灵活和以结果为导向。这种新的工作架构会根据业务需求动态调整，灵活组合人类和智能体资源，以实现最佳效果。微软指出，随着智能体的加入，未来每位员工都有可能从第一天起就参与到复杂的工作中，甚至一名初级员工也可以借助 AI 管理整个营销活动。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在这个新模式中，企业需要关注人机协作的比例，确保资源的高效利用。同时，管理层需要重构职能，以适应这种人机协作的新趋势。微软还提到，员工需要从 「工具使用者」 转变为 「合作伙伴」，通过与智能体的双向互动激发创新能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347091</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347091</guid>
            <pubDate>Sun, 27 Apr 2025 05:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Hyprnote —— 会议专用 AI 记事本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#3c3c43&quot;&gt;Hyprnote 专为会议繁忙的人士打造，是一款&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#1f2328&quot;&gt;适用于连续会议的 AI 记事本。本地优先且可扩展。&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;录并转录您的会议&lt;/li&gt;
&lt;li&gt;从原始会议记录中生成&lt;strong&gt;有力的摘要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;离线&lt;/strong&gt;工作使用&lt;strong&gt;开源模型&lt;/strong&gt;（&lt;em&gt;Whisper&lt;/em&gt;和&lt;em&gt;Llama&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;高度&lt;a href=&quot;https://docs.hyprnote.com/extensions/&quot;&gt;可扩展&lt;/a&gt;，由&lt;a href=&quot;https://docs.hyprnote.com/plugins/&quot;&gt;插件提供支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;div style=&quot;margin-left:auto; margin-right:auto&quot;&gt;
&lt;div style=&quot;margin-right:calc(50% - 678px)&quot;&gt;
&lt;div&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亮点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;增强你的笔记&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;随意记下一些东西，Hyprnote 将根据您的备忘录制作会议记录。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img alt=&quot;&quot; height=&quot;391&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/152058_SbVr_4252687.gif&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;离线和隐私&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hyprnote 是本地优先的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;392&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151933_5xtQ_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;扩展和插件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;就像 VSCode 一样，可以根据你的情况添加或创建扩展。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img height=&quot;382&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0427/151827_6b1U_4252687.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;例如，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://docs.hyprnote.com/extensions/transcript.html&quot;&gt;transcript extension&lt;/a&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&amp;nbsp;&lt;/span&gt;由&amp;nbsp;&lt;a href=&quot;https://docs.hyprnote.com/plugins/listener.html&quot;&gt;listener plugin&lt;/a&gt;&amp;nbsp;提供支持。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;pre&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;&lt;span style=&quot;background-color:#f6f8fa&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;useEffect&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;const&lt;/span&gt;&lt;/span&gt; &lt;span&gt;channel&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;new&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#953800&quot;&gt;Channel&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;lt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#1f2328&quot;&gt;SessionEvent&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;subscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;channel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;onmessage&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;started&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;if&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;type&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;===&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0a3069&quot;&gt;&quot;stopped&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;setIsLive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;&lt;span style=&quot;color:#cf222e&quot;&gt;return&lt;/span&gt;&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;&lt;span style=&quot;color:#0550ae&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;listenerCommands&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;&lt;span style=&quot;color:#6639ba&quot;&gt;unsubscribe&lt;/span&gt;&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;channel&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/hyprnote</link>
            <guid isPermaLink="false">https://www.oschina.net/p/hyprnote</guid>
            <pubDate>Sun, 27 Apr 2025 05:53:00 GMT</pubDate>
        </item>
        <item>
            <title>腾讯正式开源跨端框架 Kuikly：基于 Kotlin 创建 Android、iOS、鸿蒙、Web、小程序应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;腾讯跨端框架&amp;nbsp;Kuikly 正式开源。根据官方介绍，Kuikly 是基于 Kotlin Multiplatform 的 UI 与逻辑全面跨端综合解决方案，由腾讯大前端领域 Oteam（公司级）推出，目的在于提供一套一码多端、极致易用、动态灵活的全平台高性能开发框架。&lt;/p&gt; 
&lt;p&gt;Kuikly（Kotlin UI Kit，发音同 quickly）使用 Kotlin 开发了声明式 UI 框架，映射到系统原生控件做渲染，最终用 KMM（Kotlin Multiplatform Mobile）实现跨端。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c10e21f658b9ab50513e216dc7c37cfa28e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;虽然是全平台，但目前暂时只开源了 Android 和 iOS，鸿蒙部分 5 月才开源，而 Web 和，小程序暂定是 Q2：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/121851_K8I9_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 开源地址：&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTencent-TDS%2FKuiklyUI&quot;&gt;https://github.com/Tencent-TDS/KuiklyUI&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Kuikly 基于 Kotlin MultiPlatform（KMP）技术，它利用了 KMP 逻辑跨平台的能力，并抽象出通用的跨平台 UI 渲染接口，复用平台的 UI 组件，从而达到 UI 跨平台，具有轻量、高性能、可动态化等优点；同时，KuiklyBase 基建同样支持逻辑跨端。 让开发者&lt;strong&gt;可以使用 Kotlin 创建 Android、iOS、鸿蒙、Web、小程序应用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-911df639ea27ac02b452b9a379738d91ddd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.ithome.com/newsuploadfiles/2025/3/c0981983-cece-4d31-9488-e775586c8881.png?x-bce-process=image/format,f_avif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;Kuikly 跨端框架系统要求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;iOS 12.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Android 5.0 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HarmonyOS Next 5.0.0 (12) 版本及以上&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Kotlin 版本 1.3.10 版本及以上&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkuikly.tds.qq.com%2F%25E7%25AE%2580%25E4%25BB%258B%2Farch.html&quot;&gt;https://kuikly.tds.qq.com/%E7%AE%80%E4%BB%8B/arch.html&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347077/tencent-tds-kuikly</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347077/tencent-tds-kuikly</guid>
            <pubDate>Sun, 27 Apr 2025 04:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>GPUStack v0.6 超重磅更新：vLLM 多机分布式、升腾 MindIE 等</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;strong&gt;GPUStack 是一个 100% 开源的模型服务平台&lt;/strong&gt; ，支持 &lt;strong&gt;Linux、Windows 和 macOS&lt;/strong&gt; ，支持 &lt;strong&gt;NVIDIA、AMD、Apple Silicon、升腾、海光、摩尔线程&lt;/strong&gt; 等 GPU 构建&lt;strong&gt;异构 GPU 集群&lt;/strong&gt; ，支持 &lt;strong&gt;LLM、多模态、Embedding、Reranker、图像生成、Speech-to-Text 和 Text-to-Speech&lt;/strong&gt; 模型，支持 &lt;strong&gt;vLLM、MindIE、llama-box&lt;/strong&gt; （&lt;strong&gt;基于 llama.cpp 与 stable-diffusion.cpp&lt;/strong&gt; ）等多种推理引擎与&lt;strong&gt;推理引擎多版本并行&lt;/strong&gt; ，支持&lt;strong&gt;资源自动调度分配、模型故障自动恢复、多机分布式推理、混合异构推理、推理请求负载均衡、资源与模型监控指标观测、国产化支持、用户管理与 API 认证授权等各种企业级特性&lt;/strong&gt; ，提供 &lt;strong&gt;OpenAI 兼容 API 无缝接入 Dify、RAGFlow、FastGPT、MaxKB 等各种上层应用框架&lt;/strong&gt;，是企业建设模型服务平台的理想选择。&lt;/p&gt; 
&lt;p&gt;GPUStack 一直&lt;strong&gt;致力于以最简单易用的方式，帮助用户快速纳管异构 GPU 资源并运行所需的 AI 模型，从而支撑 RAG、AI Agents 以及其他生成式 AI 落地场景&lt;/strong&gt;。为用户打造绝佳的使用体验是我们始终坚持的目标。最新发布的 v0.6 是迄今为止最重磅的版本，全方位完善了平台的整体功能、性能、稳定性和用户使用体验。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GPUStack v0.6 版本的核心更新包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;vLLM 多机分布式推理&lt;/strong&gt;：提供生产级的多机分布式推理能力，支撑 DeepSeek R1 / V3 等单机 GPU 资源无法运行的超大参数量模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;升腾 MindIE 支持&lt;/strong&gt;：为升腾 910B 和 310P 用户提供内置的 MindIE 推理引擎支持，以提供最佳的模型推理表现。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型兼容性检测&lt;/strong&gt;：提供对模型是否支持部署的兼容性检测，目前提供对模型架构支持、操作系统兼容、资源可用性、本地路径可用性等依赖的实时检测，后续还会持续加入更多检测条件，提供更加友好的模型部署体验。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型下载管理&lt;/strong&gt;：支持管理已下载的模型文件、支持以不占用 GPU 资源分配为前提，发起单机/多机的模型下载任务、支持将本地路径的模型文件添加到 UI 中进行统一管理。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型故障自动恢复&lt;/strong&gt;：支持模型在发生故障时的自动恢复机制。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;端口暴露优化&lt;/strong&gt;：优化需要暴露的端口范围，API 入口到模型实例的推理请求统一经过代理转发，不再需要暴露模型实例端口，降低 96% 以上的端口暴露，并支持用户自定义。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增强国际化支持&lt;/strong&gt;：GPUStack 用户遍布全球上百个国家和地区，本次 GPUStack 社区用户贡献了俄语和日语支持，为不同语言的用户提供更加友好的使用体验，加速推进 GPUStack 的全球化应用。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI / UX 全方位优化&lt;/strong&gt;：全方位的 UI / UX 优化，逐帧打磨，打造业界最好用的模型推理平台。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这一版本总共包含&lt;strong&gt;上百项增强、修复、稳定性改进和用户体验优化&lt;/strong&gt;，为用户的生产落地提供强大的场景支持。&lt;/p&gt; 
&lt;p&gt;有关 &lt;strong&gt;GPUStack&lt;/strong&gt; 的详细信息，可以访问：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GitHub 仓库地址: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;https://github.com/gpustack/gpustack&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;GPUStack 用户文档: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.gpustack.ai&quot; target=&quot;_blank&quot;&gt;https://docs.gpustack.ai&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;重点特性介绍&lt;/h2&gt; 
&lt;h3&gt;vLLM 多机分布式推理&lt;/h3&gt; 
&lt;p&gt;随着大语言模型的参数规模不断提升，传统单机 GPU 资源已难以满足推理部署的实际需求。为此，GPUStack 在当前版本中正式支持生产级的 vLLM 多机分布式推理能力。通过跨主机部署，将模型按张量或按层切分，分布到多个节点运行，从而实现对超大参数模型（如 DeepSeek R1、DeepSeek V3 等）的推理支持。&lt;/p&gt; 
&lt;p&gt;当前，GPUStack 对以下两类推理引擎提供分布式支持：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;llama-box：异构分布式，适用于研发测试环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持 Linux、Windows 和 macOS 操作系统；&lt;/p&gt; 
&lt;p&gt; • 允许不同操作系统、不同品牌、不同规格的 GPU 混合实现异构分布式推理；&lt;/p&gt; 
&lt;p&gt; • 可在桌面或轻量服务器上快速构建异构分布式推理环境；&lt;/p&gt; 
&lt;p&gt; • 更适用于日常研发、模型验证、兼容性测试等场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;vLLM：同构分布式，面向生产环境&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt; • 支持在多台 Linux 服务器之间进行同构分布式推理；&lt;/p&gt; 
&lt;p&gt; • 要求参与节点的硬件环境基本一致（如 GPU 型号、数量、显存）；&lt;/p&gt; 
&lt;p&gt; • 支持张量并行和流水线并行，具备良好的推理吞吐能力；&lt;/p&gt; 
&lt;p&gt; • 适合生产环境下对高并发、低延迟模型服务的部署需求。&lt;/p&gt; 
&lt;p&gt;通过 vLLM 和 llama-box 的分布式推理能力，GPUStack 能够覆盖&lt;strong&gt;从模型研发验证到大规模生产部署的完整流程&lt;/strong&gt;。在研发阶段，用户可使用 llama-box 构建灵活的测试集群；在生产部署阶段，则可通过 vLLM 提供稳定可靠的推理服务能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ec5d9aef8c8a1a7aeacd7175a0c0e600.png&quot; alt=&quot;model-info&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;升腾 MindIE 支持&lt;/h3&gt; 
&lt;p&gt;在之前版本中，GPUStack 基于 llama-box 推理引擎初步支持了升腾 910B 和 310P 芯片的模型推理。然而由于算子支持不全及相关生态不够完善，实际使用中存在较多限制，例如只支持模型的部分量化精度，在性能和稳定性方面也弱于升腾官方推理引擎 MindIE。&lt;/p&gt; 
&lt;p&gt;为了提升用户在升腾 NPU 上的模型推理体验，GPUStack 现已内置集成 MindIE 推理引擎，对 910B 和 310P 提供更加稳定且高性能的模型推理能力。&lt;/p&gt; 
&lt;p&gt;MindIE 是升腾官方推出的高性能深度学习推理框架，具备运行加速、调试调优与快速部署等多项优势，目前在升腾硬件上表现最为出色。得益于其较为成熟的软硬件协同生态，MindIE 已成为在 NPU 上部署推理模型的主流方案。&lt;/p&gt; 
&lt;p&gt;当前，GPUStack 已完成对 MindIE 引擎的初步集成，相比于 llama-box 引擎，在部分场景可以达到数倍的推理速度提升。未来还将持续优化，并探索对更多推理引擎的支持，例如 vLLM（vLLM-Ascend），以满足在升腾平台上的多样化模型推理需求。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c0680304502e35923518c9dcf932256b.png&quot; alt=&quot;image-20250415095544399&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型兼容性检测&lt;/h3&gt; 
&lt;p&gt;在过往版本中，用户直接从 Hugging Face 或 ModelScope 搜索任意模型进行部署时，存在一定的失败可能性。常见原因包括显存不足、操作系统与推理引擎不兼容、模型架构不被支持、本地路径配置错误等。这些问题不仅浪费时间，还严重影响用户体验。&lt;/p&gt; 
&lt;p&gt;为了解决这一痛点，GPUStack 推出了&lt;strong&gt;模型兼容性检测机制&lt;/strong&gt;。系统会在部署前自动检测模型与运行环境的匹配情况，涵盖模型架构与引擎支持、操作系统兼容性、GPU 资源是否充足、本地路径是否有效等多个关键维度。通过这些检测，潜在问题能够被提前识别，并提供清晰提示，帮助用户避免不必要的部署失败。&lt;/p&gt; 
&lt;p&gt;我们设定了三个明确的目标：第一，部署前提供清晰的兼容性提示；第二，在满足条件的情况下将部署成功率提升至 99% 以上；第三，对于特殊需求场景，允许用户跳过检测，强制部署，保留灵活性。&lt;/p&gt; 
&lt;p&gt;这项功能特性将持续演进，未来将支持更多检测项、覆盖更广泛的系统环境，不断完善检测机制，全面助力用户在不同平台上实现稳定、高效的模型部署。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fb036e198f11d8e36ec761c749ecca62.png&quot; alt=&quot;image-20250421173053252&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下载管理&lt;/h3&gt; 
&lt;p&gt;在模型部署过程中，模型文件的统一管理与高效分发始终是用户关注的核心问题。以往，模型下载通常依赖于实例启动时自动触发，既需占用 GPU 资源，又常常依赖额外的手动操作才能完成下载；同时，GPUStack 也无法管理用户预先下载到本地路径的模型文件，导致部署效率低下，管理体验不佳。&lt;/p&gt; 
&lt;p&gt;为此，GPUStack 引入了&lt;strong&gt;模型文件下载管理&lt;/strong&gt; 模块：用户可在 UI 中为多个目标主机手动发起模型的下载任务，且&lt;strong&gt;无需占用 GPU 资源&lt;/strong&gt;。各节点上已下载的模型文件也可在 UI 中统一可视化管理与部署，进一步提升了部署的灵活性与效率。&lt;/p&gt; 
&lt;p&gt;同时，GPUStack 还支持将本地已有的模型文件路径添加到 UI 中进行统一管理，适配私有部署、离线环境等多种使用场景。通过这一模块，既解决了用户独立下载模型文件的需求，也使 GPUStack 能够更好地支持多机分布式部署，提升了部署效率与多机协同能力。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//0f873b0ef5ec73c42ae118694f3825ee.png&quot; alt=&quot;image-20250415204131503&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型故障自动恢复&lt;/h3&gt; 
&lt;p&gt;在追求高可用性和稳定性的生产环境中，模型推理服务的稳定性至关重要。为了进一步提升这一点，GPUStack 引入了&lt;strong&gt;模型故障自动恢复机制&lt;/strong&gt;！当模型发生故障时，GPUStack 会自动触发恢复机制，迅速尝试重新启动模型，确保服务不中断。&lt;/p&gt; 
&lt;p&gt;同时，为了避免过于频繁的无效重启，GPUStack 采用了&lt;strong&gt;5 分钟为上限的指数退避延迟机制&lt;/strong&gt;，在故障持续时逐步延迟重启，避免系统资源的浪费。总体而言，v0.6 版本提供的模型故障自动恢复机制大幅提升了模型服务的容错能力，让生产的模型推理更加稳健！&lt;/p&gt; 
&lt;h3&gt;端口暴露优化&lt;/h3&gt; 
&lt;p&gt;在旧版本架构中，每台 Worker 节点需为每个模型实例开放端口访问，以供 Server 端进行推理请求的转发。在用户大规模使用时暴露了一些问题：由于大量端口需要映射，容器启停缓慢，且在启动时容易发生端口冲突；防火墙配置容易遗漏，导致推理请求转发异常。此外，也不支持用户自定义端口范围。&lt;/p&gt; 
&lt;p&gt;为此，我们在 v0.6 版本中重构了端口暴露机制：推理请求从 API 入口到模型实例的链路现已通过统一的代理转发，无需再为每个模型实例开放端口访问。同时优化了端口分配，将端口暴露范围压缩超过 96%，显著降低部署复杂度和运维风险。同时也支持用户自定义端口配置，使系统能够灵活适配不同的网络环境与安全策略，为用户带来更简单、稳定的部署体验。&lt;/p&gt; 
&lt;h3&gt;增强国际化支持&lt;/h3&gt; 
&lt;p&gt;目前 GPUStack 的用户遍布全球上百个国家和地区，随着 GPUStack 用户群体在全球范围内的持续扩大，我们致力于为不同语言背景的开发者提供一致、便捷的使用体验。本次 GPUStack 社区用户贡献了&lt;strong&gt;俄语&lt;/strong&gt; 和&lt;strong&gt;日语&lt;/strong&gt;支持，标志着 GPUStack 在国际化进程中的又一重要里程碑。&lt;/p&gt; 
&lt;p&gt;通过持续拓展多语言能力，GPUStack 为全球社区用户创造了更加包容与高效的使用体验。未来，我们将继续深化本地化支持，为全球用户提供更全面、更优质的服务体验，加速推动 AI 应用的全球落地与普及。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8781f64407b5d62f1496d53824097f69.png&quot; alt=&quot;image-20250413233340395&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//8e1e428e259bcf52136144df288263a0.png&quot; alt=&quot;image-20250413233303590&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;全方位的 UI / UX 优化&lt;/h3&gt; 
&lt;p&gt;在本次版本中，我们对 UI / UX 进行了全方位优化，从信息展示到交互细节，几乎每一处都经过精心打磨，力求带来更流畅、更易用的使用体验。过去几个月收集的每一条用户建议，都是此次优化的重要参考。&lt;/p&gt; 
&lt;p&gt;我们始终坚持一个目标：打造业界最好用的模型推理平台，而 GPUStack 正在持续朝这一目标稳步前进。也正因为有用户的积极反馈，我们才能不断迭代优化------如果你有任何建议或想法，欢迎随时向我们提出，我们会认真评估并持续改进。&lt;/p&gt; 
&lt;h2&gt;参与开源&lt;/h2&gt; 
&lt;p&gt;想要了解更多关于 GPUStack 的信息，可以访问我们的仓库地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgpustack%2Fgpustack&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://github.com/gpustack/gpustack&lt;/strong&gt;&lt;/a&gt;。如果你对 GPUStack 有任何建议，欢迎&lt;strong&gt;提交 GitHub issue&lt;/strong&gt; 。在体验 &lt;strong&gt;GPUStack&lt;/strong&gt; 或提交 issue 之前，请在我们的 GitHub 仓库上&lt;strong&gt;点亮 Star&lt;/strong&gt; ⭐️关注我们，也非常欢迎大家一起参与到这个开源项目中！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果觉得对你有帮助，欢迎&lt;strong&gt;点赞&lt;/strong&gt; 、&lt;strong&gt;转发&lt;/strong&gt; 、&lt;strong&gt;关注&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/gpustack/blog/18260677</link>
            <guid isPermaLink="false">https://my.oschina.net/gpustack/blog/18260677</guid>
            <pubDate>Sun, 27 Apr 2025 03:43:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>得物业务参数配置中心架构综述</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;现状与痛点&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在目前互联网飞速发展的今天，企业对用人的要求越来越高，尤其是后端的开发同学大部分精力都要投入在对复杂需求的处理，以及代码架构，稳定性的工作中，在对比下，简单且重复的 CRUD 就显得更加浪费开发资源。目前 scm 供应链管理页面中，存在约 77% 的标准页面，这些标准页面里，还存在着很多类似的参数配置页面，就是对某一个模型进行增、删、改、查、导入、导出进行类似的操作，这种开发工作技术含量较低，而且相对耗费人力。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;什么是业务参数配置中心&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;参数配置中心，是一个能够通过配置的方式，快速生成前端页面以及配套增、删、改、查、导入、导出服务的配置平台，它与得物内部低代码前端页面平台 wizard 相互集成，参数配置中心提供后台增删改查服务，wizard 输出对应的前端页面代码，并可以支持用户自定义修改。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;使用场景&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;针对读多写少的简单的单表的增删改查；&lt;/li&gt; 
 &lt;li&gt;业务中需要交给运营来修改的复杂 ark 配置（简单配置除外），可以尝试使用业务参数配置中心接入，减少人为修改 JSON 可能产生的错误，导致系统无法编译进而产生故障。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;比如如下的 JSON：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[{&quot;position&quot;:&quot;1&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;2&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;3&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;4&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;5&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;6&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;7&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1},

{&quot;position&quot;:&quot;8&quot;,&quot;red&quot;:2.49,&quot;blue&quot;:2.4,&quot;green&quot;:1}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;业务参数配置中心极速体验&lt;/strong&gt;&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;后台服务搭建流程，以及数据录入&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据读取可以通过参数配置中心的 SDK，输入自己的业务入参以及自己的业务出参，SDK 会自动根据方案下的参数以及用户的输入条件，查询出对应的参数信息：&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-95529e5439a558b65e0757f2e1313155752.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从上面的快速体验里可以看到很多名词，你一定有会有下面的疑问：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-964c6ee7e450e7cce90376eddb00b05c04f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;二、整体架构与原理&lt;/h1&gt; 
&lt;h3&gt;&lt;strong&gt;实现思路&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;首先我们对这种普通的页面进行初步剖析：页面中总体包含搜索条件、静态展示字段以及操作栏，搜索条件一般是静态字段的子集，并且操作栏的功能一般都类似，所以为了能够结构化地构造出这样的页面，我们可以将静态展示字段进行进一步抽象：比如元素、维度、参数、方案、参数实例。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1adfd37a09e81f9bf0438a2bed718c19a80.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;构成页面的每一个业务字段，统称元素，因为有些字段是大家常用的（比如仓库，品牌，一级类目，省份等），它有自己的字段名称，以及取值范围。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;维度&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一条记录一定有能够标注其唯一性的信息，可能是一个字段或者是多个字段，在参数中心里，能确定一条记录唯一性的所有字段就叫做维度，维度这个概念在参数中心里很重要，它是不可变的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在业务发展过程里，可以改变值的字段，就叫参数，也可以说一条记录里，除了维度，都可以叫做参数。&lt;/p&gt; 
&lt;p&gt;综合维度和参数，举个例子，比如商品信息，商品 ID 就是维度，商品售价、折扣率就是参数。或者医院挂号系统，科室 ID 就是维度，挂号费，出诊时间就是参数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一个参数方案它管理着一个场景下的业务配置，可以简单理解一个方案就代表着一个页面，包含了上述我们说的维度以及参数，并且指定了可以指定哪些字段为搜索条件，哪些是必填字段，哪些字段可以多选。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数实例&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;描述好方案并生成页面后，实际产生的业务配置数据，我们称之为参数实例。&lt;/p&gt; 
&lt;p&gt;经过刚才对页面元素的解剖，大家会发现搭建一个这样的页面，犹如建房子一样，维度与参数是最基础的木料，创建方案就是设计建造的过程，参数实例就是一个个真实的房间，所以业务参数配置中心整体产品思路如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-54cf2fc71dbf64169277bd863672f638b30.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;整体架构&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;通过上文的介绍，我们介绍了业务参数配置中心最核心的概念，接下来我们看看整体的架构设计。我们针对这些最核心的概念，来设计实现这些业务功能的架构、核心包含领域模型、领域服务、应用服务以及基础设施层需要的存储部件，以及外部可以整合的导入导出框架、日志框架（外部依赖的框架也可以自己实现）、核心的元素维护、方案维护，存储设计好之后，我们就需要一个 SDK，可以让用户访问到我们的数据。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f29f79f77a54e147851172489afd9765082.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;系统的实体关系图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4876084e664581f0f46677ab3e1b89d59d7.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;通过上文我们可以初步了解到整体的架构设计，那么每一个子模块我们如何实现？接下来我们分析更加细节的原理。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;核心原理&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如何设计存储的细节是这个系统的一大挑战，因为既要兼顾页面的灵活变动，也要兼顾数据整体的一致性不受影响，同时也要兼顾整体数据的查询性能，下面的小节列出了所有这些核心的挑战点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;存储流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;每一个页面的字段都不一样，我们是怎么存储的？&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-072aa230f23621ba48c937b8f7db995c249.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从上面的两个页面可以看到，因为页面的字段变化多端，所以我们的思考是，必须采用抽象存储的方式来应对，核心用一张，大宽表存储，其中包含很多抽象列，每一个抽象列在不同的方案下，业务含义不同。&lt;/p&gt; 
&lt;p&gt;同时把方案的元数据：维度、参数、以及功能性设置（如每个字段是否可以删除，是否需要多选）单独存储，每个方案下的大宽表里的抽象列的业务含义，就存储在这些元数据表中。&lt;/p&gt; 
&lt;p&gt;同时为了应对大批量的查询，我们引入了 OLAP 的数据库，对于在应用内部的单点查询，我们走 MySQL 实现，如果运营后台针对某个字段做大批量查询，则可以用 OLAP 数据库来缓解查询压力。&lt;/p&gt; 
&lt;p&gt;下面是存储的整个过程以及举例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68a28fece8de3ef9c82fc7843e8110e2a2e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SDK 查询流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因为在业务参数使用时，各个业务方有自己的业务对象，所以我们在 SDK 中集成了反射的能力，可以避免用户直接感知到底层的抽象存储，查询的流程使用上比较简单，一共分为三步，第一步为自定义 request，第二步自定义 response，第三步调用 SDK 方法获取参数实例，比如：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;定义 request：&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigRequest implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置类型

  */

 private String configType;

 */***

  * 设备编号

  */

 private String deviceNo;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定义 response&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://my.oschina.net/difrik&quot;&gt;@Data&lt;/a&gt;&lt;/p&gt; &lt;p&gt;public class PinkDeviceCameraConfigResponse implements Serializable {&lt;/p&gt; &lt;pre&gt;&lt;code&gt; */***

  * 配置类型

  */

 private String configType;

 */***

  * 设备编号

  */

 private String deviceNo;



     */***

  * 配置明细

  */

 private List&amp;lt;CameraConfigDto&amp;gt; configValueList;



     [@Data](https://my.oschina.net/difrik)

 public static class CameraConfigDto implements Serializable {

     private String position;

     */***

      * 白平衡 (Red)

      */

     private BigDecimal red;

     */***

      * 白平衡 (Blue)

      */

     private BigDecimal blue;

     */***

      * 白平衡 (Green)

      */

     private BigDecimal green;

     */***

      * 亮度 (Brightness)

      */

     private BigDecimal brightness;

     */***

      * 自动曝光时间上限 (us)

      */

     private BigDecimal autoExposureTimeUpperLimit;

     */***

      * 采集帧率

      */

     private BigDecimal acquisitionFrameRate;

     */***

      * 增益自动开关 (us)

      */

     private String gainAuto;

     */***

      * 增益自动上限

      */

     private BigDecimal gainAutoUpperLimit;

     */***

      * 增益自动上限

      */

     private BigDecimal gainAutoLowerLimit;

 }
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;}&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;调用 SDK 的服务方法查询&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigRequest pinkDeviceCameraConfigRequest = new PinkDeviceCameraConfigRequest();&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setConfigType(&quot;DEVICE_NO&quot;);&lt;/p&gt; &lt;p&gt;pinkDeviceCameraConfigRequest.setDeviceNo(&quot;123@LuSun&quot;);&lt;/p&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 单个查询场景&lt;/p&gt; &lt;p&gt;PinkDeviceCameraConfigResponse response =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParams(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;,

      pinkDeviceCameraConfigRequest,

      PinkDeviceCameraConfigResponse.class);
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;//&lt;/em&gt; 批量查询场景&lt;/p&gt; &lt;p&gt;PageQueryOption pageQueryOption = new PageQueryOption();&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageIndex(1);&lt;/p&gt; &lt;p&gt;pageQueryOption.setPageSize(200);&lt;/p&gt; &lt;p&gt;PageInfo&amp;lt;PinkDeviceCameraConfigResponse&amp;gt; paramsPage =&lt;/p&gt; &lt;pre&gt;&lt;code&gt; paramInstQueryService.getParamsPage(&quot;P80-DEVICE-CAMERA-PARAM-MANAGER&quot;, 

     pinkDeviceCameraConfigRequest, 

     PinkDeviceCameraConfigResponse.class,

     pageQueryOption);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;获得结果&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-19953d23e8dcd9b90b57575b8fc6c5533ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;整体查询实现原理如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-68822ebba4f5d690e41c18c156dffdad174.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 目前整个服务的性能在 10+ms 左右：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f86b118721761e37edb0d80428c83fa7355.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参数优先级实现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为什么会有参数优先级这个功能？&lt;/p&gt; 
&lt;p&gt;比如有一个场景，要维护一个供应链系统中的补货参数：安全库存，低于这个安全库存的时候，要通知商家进行补货，整个供应链里有 100 个仓库，20 个一级类目，200 个二级类目，2000 个三级类目，涉及到 500 个品牌，要维护每一个商品的安全库存，你会怎么实现？&lt;/p&gt; 
&lt;p&gt;你一定不会把 100 仓库_2000 类目_500 品牌 = 1000000000 种可能全都设置一遍参数，对你来说，重点类目，要单独详细配置安全库存，非重点类目可能只需要管控到一级或者二级类目即可，这样你所需要的配置会大大减少。那么参数的决策就需要遵循一定的规则，比如:&lt;/p&gt; 
&lt;p&gt;有仓库+一级类目+二级类目+三级类目，的安全库存，优先取；&lt;/p&gt; 
&lt;p&gt;如果取不到，则取仓库+一级类目+二级类目的安全库存；&lt;/p&gt; 
&lt;p&gt;再取不到，取仓库+一级类目的安全库存。&lt;/p&gt; 
&lt;p&gt;比如：&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋 安全库存 100&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋-运动鞋，安全库存 500&lt;/p&gt; 
&lt;p&gt;DN 仓，鞋-运动鞋-篮球鞋，安全库存 1000&lt;/p&gt; 
&lt;p&gt;那如果一个商品是篮球鞋的话，则会命中安全库存 1000 的规则，如果是登山鞋的话，只能命中运动鞋的规则取 500，如果是高跟鞋，则只能取 100 的安全库存。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（事实上这种补货规则要详细的多，这里只是方便大家理解需求，并不是真正的参数）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;也就是说，当用户的入参同时可能命中多条参数的时候，需要通过优先级来判断应该返回哪个参数。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-92bbffb30b7b6f12d6b8fa4717437f376d8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了加速查询，系统在设计时添加了两层缓存：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-129d351a3be37ca0cf02b4472de6fcd50e8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 当后台数据发生变化时，会将对应的缓存进行失效。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-821ca41cc55e1456a0ad3fb0ba5dc76247f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素多选处理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;维度多选场景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-28b192d9ccc63092c15fcc0f12187ddf449.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;参数多选场景：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e4a1bdf71195372e13f56ab0aa27813e3ce.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;既要保证维度唯一，又要保证能正常搜索，以及展示，如何实现？业务参数配置中心引入了一个&quot;组&quot;的概念，是将同属于一行的参数实例，归为一个组，这个组是最小的新建、编辑单位。&lt;/p&gt; 
&lt;p&gt;对于新增流程如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd67e7858a3927f9960d4c2d364c0dc4a6a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对于修改流程，如下图所示： &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ed29af351bef248291bc76b841bafcedcae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;元素范围查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;页面中的字段，我们统称为元素，只要是字段，一定有它的取值范围，我们平衡了用户使用成本以及系统性能，将字段取值类型划分成了四种：&lt;/p&gt; 
&lt;p&gt;1）枚举类元素&lt;/p&gt; 
&lt;p&gt;2）dubbo 全量接口元素&lt;/p&gt; 
&lt;p&gt;3）dubbo 单点查询接口元素&lt;/p&gt; 
&lt;p&gt;4）自定义文本元素&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;枚举元素由用户手动在页面创建，一般几十个以内为佳，创建成本不高，比如经常用到的 &quot;是&quot;，&quot;否&quot;，或者比如单据类型等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 全量接口元素，一般是几十到上百个的体量，比如一级类目，仓库等，地址。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;dubbo 单点查询接口，一般是几千到几万体量的取值范围，无法直接在内存里存储所有枚举，比如品牌等。只能通过两个接口来完成搜索以及数据的展示，比如&quot;品牌 ID &amp;gt;品牌名称&quot;接口，和 &quot;品牌名称-&amp;gt;品牌 ID&quot; 接口。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定义文本，非枚举类字段，可以选择使用自定义文本来承接。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;比如以下是可以通过 dubbo 接口全量获取配置的元素：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-265ea951a69d044a0e77e39825e029716fc.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与 dubbo 全量接口的录入类似，单点搜索接口与全量接口不同的点在于，单点接口需要保留一个变量，给系统查询时调用，比如&quot;通过品牌 ID 查询品牌名称&quot; 和 &quot;通过品牌名称查询品牌 ID&quot; ，需要留给系统调用的入参，用#{var}代替。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-154171e3bd51e9ec195984b8fc5f2408f3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当然，有时元素的范围并不是只取决于它自己，可能也取决于同页面里其他元素的取值，比如说有一个质量原因的字段，当一级类目为鞋时，取值为 A、B、C，为服装时为 D、E、F，这是元素范围在设置时，就需要将对应的元素入参维护到其中，比如：&lt;/p&gt; 
&lt;p&gt;| 接口入参类型 | 接口入参取值 | | --- | --- | | com.d.s.q.s.d.r.ConfigRequest | {&quot;ruleVersion&quot;:#{ruleVersion},&quot;spuId&quot;:#{spuId}} |&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;导入导出&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是导入处理流程：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-72582bd979727a7d8718ed80cfe71b8973e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了照顾使用人员的体验，再多数导入场景时，我们的导入文件都用的是文案，而不是后台存储的数值，比如导入的字段包含类目时，导入文件输入的是鞋、服装、美妆等文案，而不是 2、3、4 这样存储在后台的数值，那么势必这里就会有将文案转换成数值的过程，这其中就用到了 2.3.5 章节中提到的元素范围查询使用的接口，当然，对于需要其他元素作为入参的元素，我们默认每个元素左边的元素都可以作为当前元素的入参。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;业务参数配置中心不适合做什么？&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;有极为复杂的 UI 交互&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;较为复杂的校验逻辑（长期计划支持）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;高频写入场景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;应用查询参数时以非&quot;=&quot;条件匹配&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;三、总结与展望&lt;/h1&gt; 
&lt;p&gt;本文简要描述了业务参数配置中心的设计思路，参数配置中心配套生成增、删、改、查、导入、导出服务，并且结合前端低代码平台自动生成前端代码，平台目前业务参数中心已经有 40+个场景接入节省了大量的工作人日，能够让研发人员，摆脱低效的 CRUD，更专注于自己内部业务逻辑的开发。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对于目前系统的未来规划：&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;持续增加 SDK 的查询灵活性：包括不限于批量代参数优先级对数据进行查询、通过 SDK 分页查询全量参数、对系统字段吐出方便业务方使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持续增加对方案定义的灵活性：支持更多的元素范围的定义，比如 HTTP 等调用方式；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持续增加对元数据定义的灵活性：部分元数据的取值可能需要同页面中的另一个元素的取值来决定，所以在取值渲染时，可以保留给其他元素的占位符，进而随着页面的动态变动，后台取值也可以动态变动。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539092%26idx%3D1%26sn%3D6fc02ccebc5c838f143d5128691a635b%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物增长兑换商城的构架演进&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247539014%26idx%3D1%26sn%3D90a168b730490ae84a0917863ad3e077%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;得物自研 DGraph4.0 推荐核心引擎升级之路&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538986%26idx%3D1%26sn%3Db6b82a790a3c696bce27704472e799b2%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;大语言模型的训练后量化算法综述 | 得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538473%26idx%3D1%26sn%3D0a83895ef8dcd555e9926151a989b663%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何合理规划 Elasticsearch 的索引｜得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxNTE3ODU0NA%3D%3D%26mid%3D2247538394%26idx%3D1%26sn%3D51f91adc969a03f7c8baa31f6cc39c67%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;DPP 推荐引擎架构升级演进之路｜得物技术&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;文 / sakuta&lt;/h4&gt; 
&lt;p&gt;关注得物技术，每周新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18230829</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18230829</guid>
            <pubDate>Sun, 27 Apr 2025 03:24:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Anthropic 向逆向工程 Claude Code 的开发者发送删除通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F25%2Fanthropic-sent-a-takedown-notice-to-a-dev-trying-to-reverse-engineer-its-coding-tool%2F&quot; target=&quot;_blank&quot;&gt;TechCrunch 报道称&lt;/a&gt;&lt;/u&gt;，在 Anthropic 的 Claude Code 和 OpenAI 的 Codex CLI 两款「智能体」式 AI 编程工具的较量中，后者获得了更多开发者的青睐。部分原因在于，Anthropic 向一位试图逆向工程 Claude Code 的开发者发出了删除通知，而 Claude Code 的使用许可要比 Codex CLI 更加严格。&lt;/p&gt; 
&lt;p&gt;Claude Code 和 Codex CLI 都是让开发者能够利用云端的 AI 模型来完成各种编程任务的工具，功能相似。两家公司几乎在同一时期发布了这两款工具，争夺开发者的关注。&lt;/p&gt; 
&lt;p&gt;Codex CLI 的源代码采用 Apache 2.0 许可证，允许分发和商业使用。相比之下，Claude Code 则依赖于 Anthropic 的商业许可证，限制了「在未获得公司明确许可的情况下对其进行修改」的方式。&lt;/p&gt; 
&lt;p&gt;另外，Anthropic 对 Claude Code 的源代码进行了「混淆」，意味着其源代码并不容易获得。当有开发者通过反混淆手段将代码发布到 GitHub&amp;nbsp;时，Anthropic &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgithub%2Fdmca%2Fblob%2Fmaster%2F2025%2F03%2F2025-03-10-anthropic.md&quot; target=&quot;_blank&quot;&gt;提出了 DMCA 投诉&lt;/a&gt; ——&amp;nbsp;这是一份要求删除代码的版权通知。&lt;/p&gt; 
&lt;p&gt;社交媒体上的开发者们对 Anthropic 此举&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FtheLance%2Fstatus%2F1914458771679486389&quot; target=&quot;_blank&quot;&gt;非常不满意&lt;/a&gt;，认为这种做法远不如 OpenAI 发布 Codex CLI 时的开放态度。在 Codex CLI 发布后的短短一周内，OpenAI 就将几十条开发者建议纳入了工具的代码库，其中包括一个让 Codex CLI 能调用来自其他竞争者（包括 Anthropic）的 AI 模型的功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;2820&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0428/105716_o6ne_2720166.png&quot; width=&quot;1289&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 尚未对此事作出回应。Claude Code 仍处于测试阶段，并且存在一些 bug。而在未来，Anthropic 有望以宽松的许可证发布源代码。公司对源代码进行混淆的原因多种多样，其中之一便是出于「安全」考虑。&lt;/p&gt; 
&lt;p&gt;对于 OpenAI 来说，这多少是一次公关上的胜利，因为最近几个月，OpenAI 一直回避开源发布，转而推出专有、封闭的产品。这可能标志着实验室方法的一个更广泛的转变；OpenAI 首席执行官 Sam Altman 今年早些时候表示，他认为公司在开源问题上一直站在「历史错误的一边」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347063/anthropic-sent-a-takedown-notice-to-a-dev</guid>
            <pubDate>Sun, 27 Apr 2025 02:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Transformers 作者：未来互联网将演变为 AI Agent 网络</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前，Transformers 合著者 Illia Polosukhin 接受了 a16z 的专题采访，并在交流中分享了自己对于 AI、Agent 等方面的观点。&lt;/p&gt; 
&lt;p&gt;开篇，Illia 就分享了自己对现有 AI Agent 的看法。他表示，据团队观察，大量用户对需要复杂规划的场景特别感兴趣。但这种局面在未来将会反过来：AI 助理将会主动提出方案给用户，用户也仅需要做出方向性选择即可。对于这种 AI 何时面世，Illia 预测在未来一年内，就会出现首批成熟应用的场景。&lt;/p&gt; 
&lt;p&gt;对于「死亡互联网理论」，Illia 则坦言：虽然开放网络正在消亡，但并非网络上的机器人数量过多，而是因为平台容易被垃圾信息攻陷。对此他认为智能 Agent 能够为人类进行信息把关，未来 AI 助手也会成为互联网「垃圾分拣员」：能够为用户提供上下文链接，如实指出错误信息并揭露事实真相。&lt;/p&gt; 
&lt;p&gt;另外，主持人问及「未来将会有多少 AI Agent？与人类的数量比例又是如何？」时，Illia 则表示，未来每个人都会拥有属于自己的 AI 助手，而 AI 助手的背后可能运行着数十个子 Agent 项目，因此这会构建起一个庞大的 Agent 网络，并且每个人都将如同获得一套「按需助理系统」。&lt;/p&gt; 
&lt;p&gt;主持人还特别向&amp;nbsp;Transformers 作者问起了对 DeepSeek 的看法：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Robert:&lt;/p&gt; 
 &lt;p&gt;您如何看待 DeepSeek 最新发布的高性能开源模型？相比其他选项，它不仅表现优异且成本更低，更特别的是由中国对冲基金以开源方式推出。&lt;/p&gt; 
 &lt;p&gt;Illia:&lt;/p&gt; 
 &lt;p&gt;首先这确实是激动人心的突破。他们在有限硬件上实现大规模高性能模型训练的工程能力令人惊艳，证明优秀工程实践能大幅降低成本。中国模型训练成本正在快速下降，但最关键的创新在于：他们提出了一种极其简单的强化学习方法——这个方法具有普适性，无论是 10 亿还是 70 亿参数模型都能快速获得优异效果。&lt;/p&gt; 
 &lt;p&gt;这种「阶跃式创新」让我想起 Transformer 的诞生——原理简单、开箱即用、人人可复现。&lt;/p&gt; 
 &lt;p&gt;坦白讲，这类基础方法论本应自由传播 (毕竟只是公式或原理)，但必须承认 DeepSeek 团队极其专业，他们凭借后发优势规避了许多早期问题。现在更重要的机遇在于：借助可验证计算技术，我们可以训练用户或社区拥有的模型——确切知道训练数据来源。&lt;/p&gt; 
 &lt;p&gt;当前所有开源模型都只公开参数，无人知晓训练数据构成，即便公布也无法验证真伪。&lt;/p&gt; 
 &lt;p&gt;区块链领域现在有机会联合训练一个「加密透明」的开源模型：所有人都能验证数据输入、训练过程及潜在偏差，确保没有隐藏后门或恶意代码。这样的模型才能真正成为 AI 时代可信赖的基础设施。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;原文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FhDgE_7fIb-ps4xSOuced_A&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/hDgE_7fIb-ps4xSOuced_A&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347060</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347060</guid>
            <pubDate>Sun, 27 Apr 2025 02:31:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克旗下 xAI 拟融资 200 亿美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-04-26%2Felon-musk-s-xai-holdings-is-in-discussions-to-raise-20-billion&quot; target=&quot;_blank&quot;&gt;彭博社援引知情人士透露&lt;/a&gt;&lt;/u&gt;，马斯克旗下 xAI 目前正与投资者洽谈，计划筹集大约 200 亿美元资金，用于其新合并的人工智能初创公司和社交媒体业务。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0428/102209_yrAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;数据提供商 PitchBook 的数据显示，&lt;strong&gt;如果成功，这笔交易将成为历史上第二大创业公司融资&lt;/strong&gt;，仅次于今年早些时候 OpenAI 的 400 亿美元融资。据知情人士透露，凭借此轮洽谈中的融资，xAI 的估值超过 1200 亿美元。&lt;/p&gt; 
&lt;p&gt;值得一提的是，该轮融资可能有助于偿还马斯克在将 X 前身 ——Twitter 私有化后所承担的一部分债务。知情人士透露，上述债务一直对 X 构成财务压力。此前彭博社报道指出，仅在今年 3 月，X 就支付了约 2 亿美元的债务服务费用，截止 2024 年底，其年度利息支出将超过 13 亿美元。&lt;/p&gt; 
&lt;p&gt;据了解，尽管谈判仍处于初期阶段，但 xAI 目标是未来几个月内筹集资金。知情人士表示，融资规模可能会超过最初的 200 亿美元，具体金额和条款尚未确定。&lt;/p&gt; 
&lt;p&gt;报道指出，这一大规模融资凸显了投资者对人工智能公司日益增长的兴趣，同时也显示了马斯克作为商业巨头和政治影响力人物的地位。尽管特斯拉的市值有所下滑，但马斯克的其他企业仍在蓬勃发展，例如马斯克的火箭公司 SpaceX，于去年一次私募交易中被估值为 3500 亿美元，成为历史上最有价值的初创公司。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347056/xai-holdings-is-in-discussions-to-raise-20-billion</guid>
            <pubDate>Sun, 27 Apr 2025 02:22:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动推出 QuaDMix：大型语言模型预训练数据质量与多样性的统一框架</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节跳动近日宣布推出其全新的数据选择框架 QuaDMix，旨在提升大型语言模型（LLM）预训练的效率和泛化能力。众所周知，模型的训练效果受基础数据集的质量和多样性影响很大。然而，传统的数据筛选方法往往将质量和多样性视为两个独立的目标，先进行质量过滤，再进行领域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;320&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3b5dc2134907308fa5f27fb6e2823c7d4cf.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;这种逐步优化的方式忽略了质量与多样性之间的复杂相互关系。优质数据集往往存在领域偏差，而多样化的数据集可能会降低质量。因此，在固定的训练预算下，如何同时优化这两个维度以最大化模型性能，成为了一个亟待解决的难题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 框架的主要运作分为三个阶段：特征提取、质量聚合和质量 - 多样性感知采样。在初始阶段，每个文档都会被标注领域标签和多项质量评分。通过归一化和合并这些评分，生成一个综合质量分数。接着，系统通过基于 sigmoid 的函数采样文档，优先考虑高质量样本，并通过参数化控制确保领域平衡。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了优化模型，QuaDMix 在不同参数设置下训练了数千个代理模型。通过这些代理实验训练的回归模型可以预测性能结果，从而识别出最佳采样配置。这种方法使得在高维参数空间中进行结构化探索成为可能，从而更好地将数据选择与下游任务对接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;实验结果显示，QuaDMix 在 RefinedWeb 数据集上进行的验证实验中，与多种基线模型相比，平均得分达到了 39.5%。这些基线模型包括随机选择、Fineweb-edu、AskLLM、DCLM 等。实验结果表明，联合优化策略在整体表现上始终优於单独关注质量或多样性的方法。此外，经过优化的数据混合更能提升特定下游任务的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;QuaDMix 为大型语言模型的预训练数据选择提供了一个系统化的解决方案，解决了长期以来同时优化数据质量与多样性的挑战。通过结合质量聚合和领域感知采样，QuaDMix 建立了一种可扩展的方法论，提升了 LLM 预训练的效率。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/347054</link>
            <guid isPermaLink="false">https://www.oschina.net/news/347054</guid>
            <pubDate>Sun, 27 Apr 2025 02:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>月暗开源 Kimi-Audio，单一框架执行多种语音任务；照片秒变可对话数字人，LemonAI 推出 Slice Live 丨日报</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-42daa67a23199a5e38b5a98abb2517572ae.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;开发者朋友们大家好：&lt;/p&gt; 
&lt;p&gt;这里是 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; ，每天和大家一起看新闻、聊八卦。我们的社区编辑团队会整理分享 RTE（Real-Time Engagement） 领域内「有话题的 &lt;strong&gt;技术&lt;/strong&gt; 」、「有亮点的 &lt;strong&gt;产品&lt;/strong&gt; 」、「有思考的 &lt;strong&gt;文章&lt;/strong&gt; 」、「有态度的 &lt;strong&gt;观点&lt;/strong&gt; 」、「有看点的 &lt;strong&gt;活动&lt;/strong&gt; 」，但内容仅代表编辑的个人观点，欢迎大家留言、跟帖、讨论。&lt;/p&gt; 
&lt;p&gt;本期编辑：@赵怡岭、&lt;a href=&quot;https://my.oschina.net/u/862736&quot;&gt;@鲍勃&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;01.有话题的技术&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、百度推出文心 4.5 Turbo 和深度思考模型 X1 Turbo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-041ced382bdd171c05e0c36d4df884fc4c9.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 25 日，在面向开发者的 Create 大会重磅推出两款全新模型：文心 4.5 Turbo 和深度思考模型 X1 Turbo。&lt;/p&gt; 
&lt;p&gt;两款模型主打多模态、强推理和低成本。百度旗下新搜索智能助手文小言也宣布全面接入，免费向用户开放，即日起用户打开文小言 APP 即可使用。&lt;/p&gt; 
&lt;p&gt;文心大模型 4.5 Turbo 进一步强化了多模态能力。在多个基准测试集中，文心 4.5 Turbo 多模态能力已与 GPT-4.1 持平，甚至在部分维度优于 GPT-4o。&lt;/p&gt; 
&lt;p&gt;而文心大模型 X1 Turbo 则在 4.5 Turbo 的基础上进行了「深度思考」升级。无论是问答能力、内容创作、逻辑推理，还是工具调用、多模态处理，X1 Turbo 均实现全方位增强，整体表现领先于 DeepSeek R1 和最新版本 V3。(@APPSO)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、GPT-4o 模型再次升级&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-768e3d496ec29c08bc8237c168b4e93a021.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 5 日，OpenAI 称对 GPT 4o 模型进行了升级。&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman 发文宣布 GPT-4o 迎来能力改进，具体如下：&lt;/p&gt; 
&lt;p&gt;新升级的 GPT 4o 模型个性化更强，优化了模型保存「记忆」的时机，并增强其在 STEM 领域的问题解决能力，还对其响应方式进行了细微的调整，使其更加主动，能够更好地引导对话走向富有成效的结果，同时对回复的细节进行了微调，让 GPT-4o 在各种任务中的表现更直观、更易用，（&lt;a href=&quot;https://my.oschina.net/u/104417&quot;&gt;@ai&lt;/a&gt; 寒武纪、APPSO）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3、总体性能第一：月之暗面开源全新音频基础模型 Kimi-Audio，横扫十多项基准测试&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a5ea5773cd4c3850cedde7d0db1f67f2923.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;4 月 26 日，Kimi 发布了新的开源项目 ------ 一个全新的通用音频基础模型 Kimi-Audio，支持语音识别、音频理解、音频转文本、语音对话等多种任务，在十多个音频基准测试中实现了最先进的 （SOTA） 性能。结果显示，Kimi-Audio 总体性能排名第一，几乎没有明显短板。&lt;/p&gt; 
&lt;p&gt;Kimi-Audio 采用了集成式架构设计，包括三个核心组件 ------ 音频分词器（Audio Tokenizer）、音频大模型（Audio LLM）、音频去分词器（Audio Detokenizer）。&lt;/p&gt; 
&lt;p&gt;这一架构使 Kimi-Audio 能够在单一模型框架下，流畅地处理从语音识别、理解到语音对话等多种音频语言任务。同时，音频分词器还提取连续的声学向量，以增强感知能力。（@机器之心）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4、Cognition Labs 推出 DeepWiki 项目，可为 GitHub 仓库提供 AI 驱动的实时交互式文档&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-52eb7173b2ff5edf181b86039e133aa6f11.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（图片来源：deepwiki 官网）&lt;/p&gt; 
&lt;p&gt;对于开源项目，这项服务完全免费，甚至无需注册。访问 deepwiki.com，探索已经收录的热门开源项目的 Wiki，或者把正在浏览的任何 GitHub 仓库 URL 中的 github.com 替换成 deepwiki.com，即可无缝跳转到该仓库的 DeepWiki 页面。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对话式文档： 直接向代码库「提问」，DeepWiki 会尝试理解问题并给出文档级的解答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;深度研究 （Deep Research）： 对于复杂问题，可以开启此功能，让 AI Agent 进行更深入的分析和回答&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;按需索引： 如果关注的公开仓库还没被收录，可以请求 DeepWiki 索引&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;私有仓库支持： 对于私有仓库，可以通过注册 Devin 账户（devin.ai）来获得服务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;轻松分享： 生成的 Wiki 页面和问答结果都可以通过链接分享，方便团队成员保持信息同步（@AI 寒武纪）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;5、Adobe 发布商用级 AI 图像生成模型 Firefly Image 4 系列&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Adobe 更新发布了 Firefly Image 4 和 Firefly Image 4 Ultra 两大 AI 图像生成模型，支持最高 2K 分辨率输出。&lt;/p&gt; 
&lt;p&gt;这两款模型均基于 Adobe Stock 等授权内容以及公共领域数据训练，如侵犯版权，可以让 Adobe 赔偿。（@三花 AI）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6、MLX-Audio: 苹果芯片上的高效语音合成模型库，提供 TTS REST API&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MLX-Audio 是一个基于 Apple MLX 框架构建的文本转语音 （TTS） 和语音转语音 （STS） 库，专为 Apple Silicon 芯片优化，提供出色的语音合成性能。&lt;/p&gt; 
&lt;p&gt;核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;苹果芯片加速： 在 M 系列芯片上实现快速推理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多语言支持： 支持多种语言；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语音定制： 提供丰富的语音定制选项；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语速调节： 0.5x 到 2.0x 的语速调节范围；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可视化交互： 具有 3D 音频可视化的交互式网页界面；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;REST API: 提供用于 TTS 生成的 REST API；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;性能优化： 支持量化以优化性能；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文件快速访问： 通过 Finder/资源管理器集成直接访问输出文件。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;支持模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Kokoro: 多语言 TTS 模型，支持多种语言和语音风格。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CSM （Conversational Speech Model） : Sesame 的对话语音模型，支持文本转语音和使用参考音频样本进行声音定制。(@GitHub)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02.有亮点的产品&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、AceditAI 面试教练：实时转录、问题检测和个性化回复等功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Acedit 是一款 Chrome 浏览器插件，作为你的 AI 面试教练：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;智能练习：&lt;/strong&gt; 上传职位描述和简历，Acedit 即可生成个性化的练习问答，并通过 AI 模拟面试助你充分准备。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;实时 AI 建议：&lt;/strong&gt; 在 Google Meet、Zoom、Teams 等在线面试平台，Acedit 能读取面试问题，并结合你的简历、领英资料等信息，提供实时 AI 生成的答案建议。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;定制求职信：&lt;/strong&gt; 内置 AI 工具，轻松生成个性化求职信。(@ProductHunt)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2、LemonAI 推出 Slice Live：照片秒变实时数字人&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Lemon Slice Live 是一款实时音视频 AI 数字人模型，让你体验前所未有的视频聊天。基于扩散变换模型 （DiT） 技术，它能将任何角色图像立即转化为支持 10 多种语言的交互式视频通话。无需训练或设置特定角色模型，上传一张照片即可与任意角色流畅对话，兼容写实、卡通、绘画等多种风格，支持高达 25 FPS 的实时渲染。（@三花 AI、LemonAI 官网）&lt;/p&gt; 
&lt;h2&gt;03.有态度的观点&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、Anthropic 研究员：从理论上讲 AI 有可能产生意识&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;日前，Anthropic 研究员 Kyle Fish 受公司邀请做了一期访谈节目，其中他在节目中表示，理论上讲 AI 是可能产生意识的。&lt;/p&gt; 
&lt;p&gt;Kyle Fish 认为，虽然当前 AI 的整体系统与人类大脑在功能和结构上存在差异，但如果能够以足够高的保真度，去模拟人脑，其中包括模拟神经递质分子的作用，那么从理论上讲，AI 有可能产生意识。&lt;/p&gt; 
&lt;p&gt;他还进一步表示，如果将大脑中的神经元逐个被替换成芯片，在替换过程中保持个体的行为和功能的不变，那么替换完成后，个体的意识体验可能不会发生太大变化。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Anthropic 为了探索模型更深层次的体验与潜在意识，启动了一项研究计划，旨在调查 AI 模型是否能够有潜在的偏好和痛苦迹象，并且去判断这是否符合道德。(@APPSO)&lt;/p&gt; 
&lt;h2&gt;04.有看点的活动&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1、脑机接口智能技术应用挑战赛正式开启报名！( 04.26-05.28)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b36b85455f3a09c836074daef9eb7d38a3a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;（图片来源：智姬）&lt;/p&gt; 
&lt;p&gt;脑机接口智能技术应用挑战赛（AI-Based BCI Tech Competition）是由中关村领智青年人才自主创新发展中心联合姬械机科技集团发起的，以脑与智能（Brain and Al）为主题方向的人工智能脑接口（Al-based BCl）前沿创新技术与应用竞赛。&lt;/p&gt; 
&lt;p&gt;通过本次技术比赛为脑机科技创新者提供系统性技术支持与创新资源对接，重点推进脑机接口技术问题的解决，同时实现脑机接，口的行业应用示范与产业化落地创新探索。&lt;/p&gt; 
&lt;p&gt;赛题发布与比赛报名 ：04/26 - 05/28&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;参赛团队报名审核 ：05/28 - 06/08（截止报名） 比赛形式：（1）线下自主赛题解答； （2） 线上提交赛题答案；（3）现场场答辩分享；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;一等奖 1 名奖金 30 万 （第一名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二等奖 2 名奖金 15 万 （第二名、第三名） ；&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三等奖 5 名奖金 8 万 （第四名、第五名、第六名、第七名、第八名） 。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;目前官方已发布&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbvxYvC8jiE4xc56QP1ihig&quot; target=&quot;_blank&quot;&gt;相关赛题简介&lt;/a&gt;：基于不同的通道脑机，完成与之相关的技术题、应用题。（@智姬）&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fd190df182060c949e714b0be523d5431a.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;更多 Voice Agent 学习笔记：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSqXLZvq_zwWDcOVKbAb7HQ&quot; target=&quot;_blank&quot;&gt;级联 vs 端到端、全双工、轮次检测、方言语种、商业模式...语音 AI 开发者都在关心什么？丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7QPgzp8kDR_9iHUa4oFeiA&quot; target=&quot;_blank&quot;&gt;a16z 最新报告：AI 数字人应用层即将爆发，或将孕育数十亿美金市场丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUM1qs2IT1S6kJ4sZf_k3uA&quot; target=&quot;_blank&quot;&gt;a16z 合伙人：语音交互将成为 AI 应用公司最强大的突破口之一，巨头们在 B2C 市场已落后太多丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FWI0gE4x-TZG0gdgSV_bVSA&quot; target=&quot;_blank&quot;&gt;ElevenLabs 33 亿美元估值的秘密：技术驱动+用户导向的「小熊软糖」团队丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSVsgDF8F1hxy3-e5-ntGbw&quot; target=&quot;_blank&quot;&gt;端侧 AI 时代，每台家居设备都可以是一个 AI Agent 丨 Voice Agent 学习笔记&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F4K5wdUEDxrs1afHZSAIuqg&quot; target=&quot;_blank&quot;&gt;世界最炙手可热的语音 AI 公司，举办了一场全球黑客松，冠军作品你可能已经看过&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJCYzc1Ig-HFFAN3sTQDYbw&quot; target=&quot;_blank&quot;&gt;多模态 AI 怎么玩？这里有 18 个脑洞&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrN9poD_X6SDxRLMsudg_xg&quot; target=&quot;_blank&quot;&gt;AI 重塑宗教体验，语音 Agent 能否成为突破点？&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FeFS1mnAbUpAJdiLSSGWpSA&quot; target=&quot;_blank&quot;&gt;对话 TalktoApps 创始人：Voice AI 提高了我五倍的生产力，语音输入是人机交互的未来&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fr2z1bilamX6YWTg90F8xYA&quot; target=&quot;_blank&quot;&gt;a16z 最新语音 AI 报告：语音将成为关键切入点，但非最终产品本身（含最新图谱）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;写在最后：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们欢迎更多的小伙伴参与 &lt;strong&gt;「RTE 开发者日报」&lt;/strong&gt; 内容的共创，感兴趣的朋友请通过开发者社区或公众号留言联系，记得报暗号「共创」。&lt;/p&gt; 
&lt;p&gt;对于任何反馈（包括但不限于内容上、形式上）我们不胜感激、并有小惊喜回馈，例如你希望从日报中看到哪些内容；自己推荐的信源、项目、话题、活动等；或者列举几个你喜欢看、平时常看的内容渠道；内容排版或呈现形式上有哪些可以改进的地方等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b097a16f69dc64b4f3a6805bc0066e50a2f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;素材来源官方媒体/网络&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/agora/blog/18255332</link>
            <guid isPermaLink="false">https://my.oschina.net/agora/blog/18255332</guid>
            <pubDate>Sat, 26 Apr 2025 12:10:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>谷歌认为自己是唯一能运营 Chrome 的公司，如若转手，将「万劫不复」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在美国司法部对谷歌在搜索引擎市场的非法垄断案中，谷歌 Chrome 浏览器总经理 Parisa Tabriz &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffortune.com%2Farticle%2Fgoogle-chrome-suffer-if-forced-to-sell-parisa-tabriz%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;&lt;/u&gt;，将谷歌与 Chrome 「剥离」是不可能的，并补充说，她认为「Chrome 不可能在其他地方被复制」。&lt;/p&gt; 
&lt;p&gt;Tabriz 强调造就 Chrome 浏览器今日成功的基石，源于 17 年来与谷歌其他部门的紧密协作。&lt;/p&gt; 
&lt;p&gt;Tabriz 表示，谷歌 Chrome 是 Chrome 团队、谷歌以及向公司的开源 Chromium 项目提交技术贡献的公司「17 年合作」的结果，该项目的开源代码也被用于其他几个谷歌项目，如 Android 操作系统。「谷歌在 Chromium 上投入了数亿美元」，Tabri 说到，并表示其他公司「目前并没有以任何有意义的方式做出贡献。」&lt;/p&gt; 
&lt;p&gt;专家 James Mickens 认为，将 Chrome 从谷歌内部基础设施进行剥离在技术上是「feasible」（可行的），并不会破坏其功能。他指出，谷歌仍有动力继续为开源项目 Chromium 贡献技术。&lt;/p&gt; 
&lt;p&gt;然而，Tabriz 反驳称，&lt;strong&gt;谷歌自 2015 年以来贡献了 Chromium 超过 90% 的代码&lt;/strong&gt;，其他公司几乎没有实质性投入。&lt;/p&gt; 
&lt;p&gt;Tabriz 透露，谷歌正积极将 AI 技术融入 Chrome。用户目前可通过扩展程序使用 OpenAI 的 ChatGPT 和 Perplexity AI，或调整设置以便于使用其他 AI 模型搜索，不过 Gemini 被设为默认 AI 助手。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346989/google-chrome-suffer-if-forced-to-sell-parisa-tabriz</guid>
            <pubDate>Sat, 26 Apr 2025 11:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 改进 GPT-4o 模型，带来更强的智能和个性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;本月初，OpenAI 发布了多个新的 AI 模型。面向开发者的 GPT-4.1 模型引入了对 100 万个 Token 上下文窗口的支持，并在指令遵循、编码和智能方面进行了改进。o3 和 o4-mini 推理模型在多个 AI 基准测试中取得了最佳结果。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e4d30e4eac108c004154d6855d6c524ec1d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;即使在发布这些新模型之后，OpenAI 仍在持续更新 GPT-4o 模型。&lt;/p&gt; 
&lt;p&gt;今年 3 月，OpenAI 对 GPT-4o 进行了增强，使其更加直观、更具创造力、更具协作性，并具有更好的指令遵循性、更强大的编码能力以及更清晰的沟通风格。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我们今天更新了 GPT-4o！智力和个性都得到了提升。&lt;/p&gt; 
 &lt;p&gt;— 萨姆·奥尔特曼 (@sama)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;今天，OpenAI CEO 奥特曼&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fsama%2Fstatus%2F1915902652703248679&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;对 GPT-4o 模型进行再次更新，重点提升了智能和个性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;优化 GPT-4o 保存记忆的时间长度并增强 STEM 的问题解决能力；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;还对 GPT-4o 响应方式进行了细微的更改，使其更加主动，更好地引导对话取得富有成效的结果。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/190903_uoAz_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此增强版本目前仅通过 ChatGPT 体验提供，开发者尚无法通过 API 访问。&lt;/p&gt; 
&lt;p&gt;OpenAI 声称，该模型现在展现出了更好的「氛围」、格式、对用户需求的直觉以及其他定性增强。然而，由于改进更难以量化，他们并未分享此版本的最新基准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9f13b1ef859a79511ac123aa8987b2341b7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;艾丹·麦克劳克林 (Aidan McLaughlin) 目前在 OpenAI 负责模型设计和能力开发，他在 Twitter 上表示，此次 GPT-4o 更新是 OpenAI 迄今为止为主要 4o 系列发布的最快的更新，这表明发布速度正在加快。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;太喜欢这个模型了！简直太有意思了！&lt;/p&gt; 
 &lt;p&gt;如果你有什么反馈，欢迎留言！&lt;/p&gt; 
 &lt;p&gt;- Aidan McLaughlin (@aidan_mclau)&amp;nbsp;2025 年 4 月 25 日&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;虽然基准衡量了人工智能模型的核心能力，但「氛围」等现实世界方面的改进表明 OpenAI 越来越关注整体用户体验和交互风格。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346982/openai-updated-gpt-4o</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346982/openai-updated-gpt-4o</guid>
            <pubDate>Sat, 26 Apr 2025 11:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>模力方舟百模破浪 —— 北京经开区推进 AI 开源开放生态共创</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;4 月 27 日下午，在北京人工智能产业生态创新发布会上，开源人工智能社区「模力方舟」正式发布，「开源人工智能应用创新大赛」也同步启动，经开区将围绕建设全域人工智能之城，助力共建国内 AI 开源开放生态。&lt;/p&gt; 
&lt;p&gt;模力方舟依托开源中国 17 年生态构建，积累超 1800 万开发者、2000 余所高校、36 万家企业，以绝对中立平台面向开发者提供从开源模型、训练数据集、国产算力底座到模型在线微调测试的全流程支持，降低大模型开发门槛，提高开发效率，以深厚的开源和开发者服务底蕴，致力于成为 AI 时代的重要创新引擎与生态共建平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0427/182702_pFoc_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://ai.gitee.com/&quot;&gt;https://ai.gitee.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;「模力方舟」旨在对标国外开源社区 Hugging Face，于 2024 年 1 月上线，算力供给方面与沐曦 MetaX、华为升腾、天数智芯、摩尔线程等国产 GPU 企业合作，目前已积累约 16000 个开源模型及约 10000 个高质量数据集，覆盖自然语言处理、计算机视觉等主流 AI 领域，注册用户数超 100 万。&lt;/p&gt; 
&lt;p&gt;建设「模力方舟」有哪些资源基础？未来又将如何推进？北京经开区有关负责人介绍：「此前，经开区与北京市联动投资牵引国内头部开源社区企业——开源中国总部落地经开区。基于开源中国在传统开源领域的生态积累，围绕人工智能开源大模型和国产算力底座软硬一体化适配，我们启动了人工智能开源社区‘模力方舟’建设工作。」&lt;/p&gt; 
&lt;p&gt;为助力「模力方舟」建设成为具有国际影响力的开源人工智能社区，经开区将支持开源中国从夯实平台能力、引导资源汇聚、打造国际品牌、政策保驾护航四个方面展开工作。具体来说，充分依托公有云的弹性拓展特性与私有云的安全可控优势，精心构建起具备高并发处理能力、能够实现低延时响应的算力基础设施体系；整合自然语言处理、计算机视觉、语音识别等多个 AI 核心领域的国内外前沿模型，以及图像数据集、文字数据集、各类先进算法；围绕「一赛一会」这一核心策略持续扩大影响力，举办开源人工智能大赛及开源峰会等品牌活动，推动具有高成长性的开源 AI 创业项目在开源社区形成落地集聚；对优质开源项目、优秀商业化应用、开源生态活动给予一定资金支持等。&lt;/p&gt; 
&lt;p&gt;值得一提的是，在本次发布会上，「一赛一会」核心策略中的「开源人工智能应用创新大赛」正式启动。由开源中国联合战略合作伙伴，华为升腾、商汤科技、智谱（Z.ai）、沐曦 MetaX、天数智芯、睿思芯科、希姆计算等国内领先人工智能企业共同发起。他们将为赛事提供核心算力支持、先进 AI 模型、优质数据资源以及行业生态联动支持。这是一场全国性的人工智能赛事，定位国家级影响力赛会，通过竞赛展示开源与人工智能前沿技术创新和商业化应用，推动产业化落地，为项目实践应用提供发展平台。大赛设专业组和青少年组两个组别：专业组赛道涵盖 AI 医疗、AI 金融、AI 智能制造、视觉呈现与感知、具身智能与机器人、AI 教育与智能教学解决方案等七大方向，青少年组赛道包括创新场景实践应用、AI 算法设计与优化等四大方向。&lt;/p&gt; 
&lt;p&gt;此外，入选团队将在半决赛中与 2025 GOTC 全球开源技术峰会深度联动，为参赛团队打造国际化的展示舞台。优秀项目可在峰会分论坛演讲，演示对抗和大咖点评，全程媒体直播，让创新成果获得最大曝光。&lt;/p&gt; 
&lt;p&gt;与此同时，为更好地促进参赛团队创新成果落地，大赛主办方与经开区政府积极联动，将设立一、二、三等奖及多项单项奖项，为获奖团队提供奖金和配套政策支持，同时协调优质办公空间及算力资源的方式支持优秀项目孵化落地。&lt;/p&gt; 
&lt;p&gt;本次大赛旨在打造一项全国性、具有国家级影响力的人工智能赛事，目标是通过赛事展示技术创新与商业化应用，推动产业落地，聚焦人工智能的前沿技术，同时也为项目的实际应用提供发展平台。&lt;/p&gt; 
&lt;p&gt;目前，大赛已面向全国范围的参赛者开放报名，参赛团队可通过报名通道提供成熟的技术方案、商业化路径与应用场景等作品。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346975</guid>
            <pubDate>Sat, 26 Apr 2025 10:27:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>谷歌在垄断审判中被曝向三星支付巨款预装 Gemini 应用</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;彭博社报道称，正在进行的谷歌反垄断审判本周的证词显示，谷歌每月向三星支付「巨额资金」，以在其设备上预装其 Gemini 人工智能应用程序。这一信息正值法官阿米特·梅塔 (Amit Mehta) 已裁定谷歌的搜索引擎构成非法垄断之后，目前谷歌的律师正与美国司法部就潜在的处罚力度展开辩论。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3bc9b596b7ba040b8f52188c972b5dfbbfc.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;谷歌平台和设备合作副总裁彼得·菲茨杰拉德周一作证称，谷歌与三星之间的这笔付款协议始于今年 1 月份。值得注意的是，这笔交易启动于谷歌被认定违反反垄断法之后，而此前谷歌被判定垄断的部分原因正是其与苹果、三星等公司类似的搜索默认合作协议。作为合作的一部分，三星在 1 月份推出的 Galaxy S25 系列手机中，将 Gemini 设置为长按电源键时的默认 AI 助手，而三星自家的 Bixby 助手则被置于次要地位。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;据《The Information》报道，菲茨杰拉德在证词中提及，包括 Perplexity 和微软在内的其他公司也曾向三星推销在其设备上预装人工智能助手应用的协议。然而，美国司法部律师指出，谷歌提交的试图修改与手机制造商协议的信函实际上是在庭审前夕，即上周才发出的，暗示这些举动可能是应对庭审压力。此外，《The Information》报道称，当天提交的谷歌内部幻灯片似乎显示，谷歌「正在考虑更具限制性的分销协议，要求合作伙伴在谷歌搜索和 Chrome 浏览器之外预装 Gemini」。&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0; margin-right:0; text-align:left&quot;&gt;关于支付细节，彭博社报道称，菲茨杰拉德表示，与三星的 Gemini 协议为期两年，除了固定的月费外，谷歌还将向三星支付一定比例的 Gemini 应用订阅收入。彭博社援引美国司法部律师戴维·达尔奎斯特（David Dahlquist）的话称，这笔固定的月费是一笔「巨款」，但具体数额尚未公开。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/346972</link>
            <guid isPermaLink="false">https://www.oschina.net/news/346972</guid>
            <pubDate>Sat, 26 Apr 2025 10:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>