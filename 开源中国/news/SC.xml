<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 20 Aug 2025 02:54:06 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>DeepSeek V3.1-Base 开源发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 最新开源模型 V3.1-Base 已上架 HuggingFace，相关信息如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型参数为 685B&lt;/li&gt; 
 &lt;li&gt;基座模型（Base），用于微调和二次开发&lt;/li&gt; 
 &lt;li&gt;基于 DeepSeek V3 架构，包含自定义代码实现&lt;/li&gt; 
 &lt;li&gt;混合精度设计，支持 BF16、FP8（E4M3）、FP32 张量类型&lt;/li&gt; 
 &lt;li&gt;支持 FP8 量化，提升推理效率&lt;/li&gt; 
 &lt;li&gt;采用 Safetensors 安全张量格式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1240" src="https://static.oschina.net/uploads/space/2025/0820/104516_2Mto_2720166.png" width="1150" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104605_duz9_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/104713_pqfx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3.1-Base" target="_blank"&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367323</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367323</guid>
      <pubDate>Wed, 20 Aug 2025 02:47:53 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>小米集团基于 Apache Doris + Apache Paimon 实现 6 倍性能飞跃</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;企业在数据驱动的道路上，始终面临一对核心矛盾：既需要低成本、可扩展的存储方案来承载海量结构化、半结构化乃至非结构化数据（这正是数据湖的强项），又渴望实时、低延迟的分析能力来支撑业务决策（这是分析型数据库的核心优势）。&lt;/p&gt; 
&lt;p&gt;然而现实是，单独的解决方案往往难以两全：以 Apache Paimon 为代表的数据湖技术，虽凭借开放格式、弹性扩展和低成本存储成为企业数据中台的基石，但在低延迟响应上存在天然短板；而以 Apache Doris 为代表的分析型数据库，虽能提供高效的查询性能，却缺乏数据湖的存储灵活性与开放性。&lt;/p&gt; 
&lt;p&gt;本文的核心观点是："架起数据库与数据湖的桥梁" 并非趋势，而是破局的关键。小米通过将 Apache Doris（数据库）与 Apache Paimon（数据湖）深度融合，不仅解决了数据湖分析的性能瓶颈，更实现了 "1+1&amp;gt;2" 的协同效应。&lt;/p&gt; 
&lt;h2&gt;数据库与数据湖的互补之力&lt;/h2&gt; 
&lt;p&gt;"桥接数据库与数据湖"的核心价值，在于构建"&lt;strong&gt;存储灵活、计算高效、格式协同&lt;/strong&gt; "的一体化架构------不仅是存储与计算能力的分工互补，更包含&lt;strong&gt;数据格式层面的深度协同&lt;/strong&gt;，让两者的技术特性形成叠加效应。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 数据湖仓的分工定位&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;从基础能力来看，两者的分工已形成天然互补：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Apache Paimon 作为数据湖，核心优势体现在存储层：其开放格式（兼容 Spark、Flink、Trino 等多引擎）、基于对象存储（S3、HDFS）的 PB 级弹性扩展能力，以及对事务、Schema 演进的原生支持，使其成为海量异构数据的"统一存储基座"，兼顾低成本与兼容性。&lt;/li&gt; 
 &lt;li&gt;Apache Doris 作为分析型数据库，核心优势体现在计算层：分布式并行引擎、向量化执行框架、以及针对复杂聚合场景的算子优化，使其能提供毫秒至秒级的低延迟查询响应，成为数据价值挖掘的"高效计算引擎"。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;2. 数据格式的特性互补&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更深层的协同点，在于数据格式的特性互补：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;数据湖格式（如 Paimon）为适配多引擎读写与大规模存储场景，在设计上以通用性为优先，虽能满足跨引擎兼容需求，但在高频查询、复杂计算场景下，其通用格式的解析效率、IO 开销难以进一步优化；&lt;/li&gt; 
 &lt;li&gt;而数据库（如 Doris）则拥有专为查询性能设计的 &lt;strong&gt;高效内部存储格式&lt;/strong&gt;------例如基于列存的分层存储结构、自适应编码压缩算法（如字典编码、RLE 压缩）、原生索引（如前缀索引、 bloom filter）等，这些格式通过深度耦合计算引擎的执行逻辑，可最大限度减少数据扫描量与 IO 消耗，实现亚秒级查询响应。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3. 桥接架构的双向赋能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;桥接架构下，数据湖仓可实现&lt;strong&gt;双向赋能&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;海量冷数据、全量历史数据以 Paimon 格式存储于数据湖，保持低成本与多引擎兼容性；&lt;/li&gt; 
 &lt;li&gt;高频访问的热数据、需复杂聚合的核心指标，则通过 Doris 的物化视图、本地缓存等机制，转换为 Doris 高效内部格式存储，借助其原生存储与计算的协同优化，实现极致查询性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;这种模式既避免了单一数据湖格式在查询性能上的瓶颈，又解决了单一数据库格式在存储成本与扩展性上的局限。唯有通过"桥接"，才能让数据湖的通用存储优势与数据库的高效格式特性形成合力，实现"存储成本可控、查询性能最优"的理想状态。&lt;/p&gt; 
&lt;h2&gt;Apache Doris &amp;amp; Paimon 在小米的实践与挑战&lt;/h2&gt; 
&lt;p&gt;Apache Paimon 是一款优秀的开放数据湖格式，其流批一体的设计很好的满足了湖上数据的实时处理需求。&lt;/p&gt; 
&lt;p&gt;Doris 在 2.1 版本开始支持 Paimon Catalog，可以直接访问 Paimon 数据并加速 Paimon 数据分析。在 Paimon TPC-DS 1TB 测试集上，Doris 的总体查询性能是 Trino 的 5 倍。&lt;/p&gt; 
&lt;p&gt;从 2.1 版本到 3.0、3.1 版本，Doris 在持续针对 Paimon 格式进行功能更新和性能增强，包括但不限于以下功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;通过元信息对 Paimon 数据进行分区、分桶裁剪和谓词下推，优化查询效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Deletion Vector 读取，利用向量化 C++ 引擎加速 Paimon 更新数据的读取。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 数据的本地文件缓存，充分利用本地高速磁盘提升热点数据的查询效率。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon 时间旅行、增量数据读取、Branch/Tag 数据读取，方便用户进行 Paimon 数据的多版本管理。&lt;/li&gt; 
 &lt;li&gt;支持基于 Paimon 的物化视图，包括分区级别的增量物化视图构建，以及本文后续将要介绍的基于快照级别的增量构建，同时支持强一致的物化视图透明改写能力，将湖和仓的能力深度结合。&lt;/li&gt; 
 &lt;li&gt;支持 Paimon Rest Catalog（DLF），方便云上用户接入 Paimon 生态，实现统一元数据管理。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;在本文中，我们将重点介绍小米如何基于 Doris + Paimon 构建统一湖仓平台，以及在项目开发过程中的功能贡献和优化思路。&lt;/p&gt; 
&lt;h2&gt;01 化繁为简：基于 Doris + Paimon 的统一湖仓平台建设&lt;/h2&gt; 
&lt;p&gt;作为一家业务覆盖汽车、IoT、手机、互联网服务等多个领域的大型企业，小米集团对 OLAP 系统和湖仓平台提出了如下关键需求：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多维度分析&lt;/strong&gt;：支持高并发、低延迟的多维聚合分析（如用户行为、设备状态、运营监控等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多源接入&lt;/strong&gt;：需要打通 Flink、Spark、Flink CDC 等流批框架的输入，覆盖离线、实时全链路数据处理场景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;统一数据访问&lt;/strong&gt;：支持跨引擎、多格式的数据消费需求（如 Doris、Paimon、Iceberg 等）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;降低平台复杂度&lt;/strong&gt;：减少技术栈分裂，统一数据建模与管控，提升数据平台运维效率。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;当前架构的挑战与瓶颈&lt;/h3&gt; 
&lt;p&gt;尽管已有较成熟的数据平台体系，但小米的 OLAP 湖仓架构长期存在如下"繁杂、割裂"的结构问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;存储多源异构，数据重复堆叠&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;为满足不同业务对数据的不同时效性需求，需要按照分钟、小时、天级别的时效性要求，将数据存储在不同的数据系统中（Iceberg、Paimon、Druid、Doris），导致数据冗余、不一致等问题&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;湖仓割裂，缺乏统一接口&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需要同时使用不同的引擎进行数据查询，（如 Presto、Druid、Doris、Spark 等）。各系统有独立的数据建模、运维和权限控制逻辑，平台治理成本高，入口不统一，使用方式不统一。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//54a06d5419f01bd3f147603a3e36c475.png" alt="化繁为简：基于 Doris + Paimon 的统一湖仓平台建设.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这些问题不仅增加了平台负担，也制约了 OLAP 架构在大规模实时应用场景下的稳定性和扩展性。&lt;/p&gt; 
&lt;h3&gt;统一引擎 + 统一存储&lt;/h3&gt; 
&lt;p&gt;为应对上述挑战，小米构建了基于 &lt;strong&gt;Apache Doris + Apache Paimon&lt;/strong&gt; 的统一湖仓一体化架构，作为未来 OLAP 平台的核心形态。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;统一计算引擎：Apache Doris + Spark&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;采用 Doris + Spark 的计算引擎组合。Doris 负责实时数据和交互式数据分析，以及高并发查询场景。Spark 负责离线批处理场景。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;统一数据湖存储：Apache Paimon&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;以 Apache Paimon 作为统一数据存储格式。Paimon 的设计非常适合流、批数据一体化存储。实现批流一体、湖仓一体的数据管理。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4523b53882f118d0fe114ba1b214b893.png" alt="统一引擎 + 统一存储.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过这一架构转型，极大地简化了系统架构：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;计算引擎：Presto、Druid、Doris、Spark -&amp;gt; Doris、Spark&lt;/li&gt; 
 &lt;li&gt;存储格式：Iceberg、Paimon、Doris、Druid -&amp;gt; Doris、Paimon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;02 深度融合：基于 Doris + Paimon 查询加速实践&lt;/h2&gt; 
&lt;p&gt;小米在引入 Apache Paimon 构建湖仓平台后，虽解决了海量数据的存储问题，却在实际业务中遭遇了三大关键瓶颈，直接影响了数据价值的释放：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;聚合性能不足&lt;/strong&gt;：Doris 在读取 Paimon 的 Merge-on-Read 表时，受限于 Paimon SDK（Java）单线程处理多文件的排序与合并，在高并发场景下完全无法满足业务对 "秒级响应" 的需求。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;物化视图更新代价高昂&lt;/strong&gt;：分区级增量更新机制粒度在某些场景下可以满足用户的增量更新需求。但对于非分区表，或者单分区数据量较大的表，依然有较高的更新成本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HDFS 读取延迟不稳定&lt;/strong&gt;：HDFS 多副本读取时，默认 60 秒的超时阈值和网络抖动，导致查询延迟波动极大，业务方难以依赖数据结果快速做出决策。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题并非单纯的技术瑕疵 ------ 它们直接拖慢了业务决策速度，同时因资源浪费和低效运行增加了企业成本。&lt;/p&gt; 
&lt;p&gt;针对上述瓶颈，小米通过深度整合 Apache Doris 与 Apache Paimon 的特性，打造了&lt;strong&gt;三大 "桥接" 方案&lt;/strong&gt;，实现了从 "问题" 到 "解决方案" 的精准突破。&lt;/p&gt; 
&lt;h3&gt;方案一：用 Doris 计算引擎加速 Paimon 聚合能力&lt;/h3&gt; 
&lt;p&gt;Doris 本身拥有强大的数据聚合计算能力，同时支持 Aggregate Key 聚合表模型，该模型在应用场景上和 Paimon 聚合表非常类似，因此可以作为 Paimon 聚合表很好的补充。&lt;/p&gt; 
&lt;p&gt;针对原先 Doris 读取 Paimon 聚合表性能不足的问题，小米采用了将文件合并与排序逻辑 "上移" 至 Doris 的查询引擎的方案，利用 Doris 的分布式并行计算与向量化执行能力，替代 Paimon SDK 的单线程处理模式。具体而言：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;放弃 JNI 调用 Paimon Java SDK 的方式，改用 Doris 原生 Parquet Reader 直接读取 Paimon 数据文件；&lt;/li&gt; 
 &lt;li&gt;借助 Doris 的 Hash 算子实现分布式聚合（无需排序步骤），充分发挥 C++ 引擎的性能优势。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e1dbabcb52805e9fb9c1bbdabf4dcec.png" alt="方案一：用 Doris 计算引擎加速 Paimon 聚合能力.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;经过此方案改造，聚合表的查询时长&lt;strong&gt;从 40 秒缩短至 8 秒，性能提升近 5 倍。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案二：快照级增量物化视图实现高效更新&lt;/h3&gt; 
&lt;p&gt;Doris 支持 Paimon、Iceberg 等数据湖表格式的异步物化视图构建，并且支持分区级别的增量物化视图刷新与查询透明改写。物化视图作为数据库与数据湖的直接桥梁，对查询加速起到了至关重要的作用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//46574d04066c2797c966cd797925a8f0.png" alt="方案二：快照级增量物化视图实现高效更新.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;为了进一步提高物化视图的时效性，并降低物化视图的更新开销。小米进一步研发了基于快照级别的物化视图增量刷新能力，并且贡献到了 Apache Doris 社区。&lt;/p&gt; 
&lt;p&gt;首先，小米开发了 Paimon 表的快照级别的增量读取能力，如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该功能可以仅读取指定 snapshot 区间的增量数据。&lt;/p&gt; 
&lt;p&gt;基于该功能，小米进一步开发了基于快照级别的增量物化视图功能：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;在 Paimon 中创建一张聚合表&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;CREATE TABLE paimon_aggregate_table (
  dt bigint,
  k1 bigint
  k2 string,
  v1 int,
  v2 double
)
USING paimon
PARTITIONED BY (dt)
TBLPROPERTIES (
  'bucket' = '2',
  'bucket-key' = 'k1,k2',
  'fields.v1.aggregate-function' = 'sum',
  'fields.v2.aggregate-function' = 'max',
  'merge-engine' = 'aggregation',
  'primary-key' = 'dt,k1,k2'
);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Doris 中创建对应的物化视图&lt;/p&gt; &lt;pre&gt;&lt;code class="language-SQL"&gt;  CREATE MATERIALIZED VIEW paimon_aggregate_table_mv
  BUILD DEFERRED
  REFRESH INCREMENTAL
  PARTITION BY (dt)
  DISTRIBUTED BY RANDOM BUCKETS 2
  AS 
  SELECT dt, k1, SUM(a1) AS a1
  FROM paimon_aggregate_table
  GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Doris 的异步物化视图框架会在后台定时执行如下语句：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;INSERT INTO paimon_aggregate_table_mv
SELECT dt, k1, SUM(a1) AS a1
paimon_aggregate_table@INCR('startSnapshotId'='1', 'endSnapshotId'='2')
GROUP BY dt, k1;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;利用快照读取功能和 Doris 聚合功能，准实时的更新物化视图，避免全量计算。&lt;/p&gt; 
&lt;p&gt;通过此方案，&lt;strong&gt;更新成本显著降低，数据时效性大幅提升，且得益于 Doris 优化的 SQL 透明改写能力，用户无需修改 SQL 即可自动享受物化视图的加速效果。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;方案三：HDFS 读取长尾优化与缓存机制&lt;/h3&gt; 
&lt;p&gt;针对 HDFS 读取延时不稳定的问题，小米采用了如下两方面措施：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. HDFS 快速超时与重试&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;HDFS 在读取数据时，会利用多副本机制，当一个副本的读取时间超过阈值后，会切换到另一个副本尝试读取。超市阈值由参数 &lt;code&gt;dfs.client.socket-timeout&lt;/code&gt;控制，默认是 60 秒。这导致首次读取的超时时间过长，在 HDFS 抖动或负载较高的情况下，会导致查询延迟显著增加。我们通过将该阈值降低到 100 毫秒，让读取情况进行快速的超时重试，显著降低了查询长尾，&lt;strong&gt;P99 性能提升 1 倍，总体性能提升 10%。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e3d184f7c8d525920cddc271ac838bcf.png" alt="方案三：HDFS 读取长尾优化与缓存机制.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Doris 数据缓存&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;针对高并发查询场景，单纯的降低 HDFS 的重试超时时间，无法彻底的解决 HDFS 查询延迟高的问题。因此，我们利用 Doris 的数据缓存能力，将热点数据缓存在本地高速磁盘上，完美解决了高并发场景的查询延迟问题。在开启缓存的情况下，从 5 并发到 80 并发，查询延迟可以&lt;strong&gt;降低&lt;/strong&gt; &lt;strong&gt;25% 到 300%。&lt;/strong&gt; 同时，得益于数据剪枝能力、高性能的算子，&lt;strong&gt;Doris 的整体查询并发能力是 Presto 的 5 倍。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//29901c93faeb0f8dfc37da040b805da1.png" alt="2. Doris 数据缓存.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;总结与展望&lt;/h2&gt; 
&lt;p&gt;小米在 Apache Doris 和 Paimon 上的深度融合实践，是典型的数据库与数据湖的互补增效的体现。在这些实践下，小米在湖仓数据分析场景下获得了可观的业务收益：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;查询平均延迟从 60 秒降至 10 秒，性能提升 6 倍；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高并发场景下（5 并发提高至 80 并发），查询延迟降低 25% 到 300%；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;整体查询并发能力达到 Presto 的 5 倍，有效减少了计算资源。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;目前，这些能力已经全部回馈到了 Apache Doris 社区。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在未来，小米将继续探索和拓展 Apache Doris 在数据湖仓上的能力和场景，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用 Doris 全流量替换 Presto 集群实现降本增效。&lt;/li&gt; 
 &lt;li&gt;进一步加强针对 Paimon、Iceberg 湖格式增量物化视图的能力。&lt;/li&gt; 
 &lt;li&gt;Doris 湖仓架构容器化以满足更灵活的部署方式。&lt;/li&gt; 
 &lt;li&gt;基于 Doris 的 Compute Group 虚拟计算组能力实现多业务间的资源隔离，提高资源利用率，降低维护成本。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/selectdb/blog/18688781</link>
      <guid isPermaLink="false">https://my.oschina.net/selectdb/blog/18688781</guid>
      <pubDate>Wed, 20 Aug 2025 02:35:53 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>英伟达正开发新款「中国特供」 AI 芯片，性能强于 H20</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fworld%2Fchina%2Fnvidia-working-new-ai-chip-china-that-outperforms-h20-sources-say-2025-08-19%2F" target="_blank"&gt;据路透社援引知情人士透露&lt;/a&gt;，英伟达正在研发面向中国市场的新型 AI 芯片 B30A，其性能超越当前获准销售的 H20 芯片，并计划最快于 2025 年 9 月向中国客户提供测试样品。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0820/103840_kcWl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据悉，该芯片采用单芯片设计，预计其算力约为旗舰级 B300 加速卡双芯片配置的一半。此外，该芯片将配备高带宽内存（HBM）和 NVLink 技术，以提升处理器间的数据传输效率。&lt;/p&gt; 
&lt;p&gt;单芯片设计指所有主要电路都制作在同一块连续的硅晶圆上，而不是分散在多个芯片上。消息人士表示，目前芯片最终规格还没完全敲定，但 NVIDIA 希望最快下个月向中国客户提供样品进行测试。&lt;/p&gt; 
&lt;p&gt;根据相关曝光的信息，B30A 很可能是基于同样单芯片设计的 Blackwell B300A 修改而来。通过单芯片集成核心电路，B30A 在保持 Blackwell 架构先进性的同时，降低了被认定为「高性能计算设备」的风险，从而规避更严格的出口审查。&lt;/p&gt; 
&lt;p&gt;该芯片基于最新 Blackwell 架构、其核心战略定位在于，在满足美国商务部出口管制条例（EAR）的前提下，提供超越上一代特供芯片 H20 的性能，以应对中国市场日益增长的 AI 算力需求和本土厂商的竞争。&lt;/p&gt; 
&lt;p&gt;此前，有消息称，美国政府与 NVIDIA、AMD 达成协议，将在中国销售芯片的 15% 营收上缴给美国政府，以取得半导体出口许可。与此同时，中国官媒指控 NVIDIA 芯片存在安全风险，并警告中国科技公司谨慎购买 H20。&lt;/p&gt; 
&lt;p&gt;此外，据知情人士透露，NVIDIA 也正准备推出另一款针对中国市场的新芯片，同样基于最新 Blackwell 架构，主要用于 AI 推理任务。该芯片暂名 RTX6000D，售价将低于 H20，其规格较弱且制造需求更简单。该芯片设计是为了落在美国政府设定的门槛之下，采用传统 GDDR 内存，内存带宽为 1398 GB/s，计划 9 月提供少量产品给中国客户。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367317</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367317</guid>
      <pubDate>Wed, 20 Aug 2025 02:31:53 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动否认自研 AI 手机</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;针对近日市场上有关字节跳动正在研发「豆包手机」的传言，字节跳动相关负责人明确回应称，该消息不实，豆包目前并无推出自有手机产品的计划。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据介绍，豆包始终致力于将自身 AI 能力向包括手机厂商在内的各类硬件厂商开放。在此过程中，虽会与部分合作伙伴共同开展完整解决方案的尝试，但所有合作均不涉及自有手机产品的研发与推出。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="339" src="https://oscimg.oschina.net/oscnet/up-70f77e4956e520cdce2146bdfaa4e1c28a6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据了解，2019 年 1 月，字节跳动收购锤子科技部分专利使用权，当时便引发市场对于字节将进入手机市场的猜测。此后，原坚果手机团队在字节跳动内部以「新石实验室」为名开展工作，定位为集团硬件中台，探索智能手机及教育硬件等智能硬件产品。不过，2021 年 1 月，「新石实验室」并入由 Musical.ly 原创始人阳陆育负责的教育硬件团队，合并后的团队专注于教育领域，不再研发坚果手机、TNT 显示器等其他无关产品。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;今年以来，类似传闻亦多次出现。1 月，有消息称字节跳动选择与努比亚合作开发 AI 手机，字节跳动回应称消息不实；2 月，关于荣耀前 CEO 赵明将加盟字节跳动并负责手机业务的传言，字节跳动同样表示信息不实。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;豆包大模型作为字节跳动旗下重要的 AI 产品，数据显示，其 2024 年累计用户规模已超 1.6 亿，11 月平均每日新增下载用户达 80 万，单日活跃用户近 900 万。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在技术应用方面，2025 年 7 月 30 日，火山引擎宣布豆包·图像编辑模型 SeedEdit 3.0 正式登陆火山方舟；8 月 1 日，小米浏览器升级「AI 搜索」功能，通过接入豆包大模型及火山方舟高代码智能体产品，进一步提升了 AI 搜索的效率与服务丰富度。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367315</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367315</guid>
      <pubDate>Wed, 20 Aug 2025 02:20:53 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 计划通过股权出售成为全球最有价值私营公司，估值达 5000 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 正在考虑进行一轮价值 60 亿美元的股权出售，这将使其估值达到 5000 亿美元，超越目前全球最有价值的私人公司 SpaceX（估值 3500 亿美元）。这次股权出售的股份将主要由现有和前员工出售。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-6a3f4b40ac1c67918c3c1507155d1ac2163.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;过去一年，OpenAI 经历了迅猛的增长，微软和软银等投资者已经为该公司投入了至少 400 亿美元，使其在 2023 年 3 月的估值达到了 3000 亿美元。而在 2022 年 10 月，OpenAI 的估值仅为 1570 亿美元。如果此次股权出售成功，OpenAI 将成为全球估值&lt;span&gt;最高&lt;/span&gt;的私人公司。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;当前，参与此次股权出售谈判的投资者包括已经对 OpenAI 投资的三家机构:软银、Dragoneer 投资集团和 Thrive 资本。根据彭博社的报道，相关谈判仍处于早期阶段，最终的数字可能会有所变动。OpenAI 对此未作出评论。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在人工智能领域，OpenAI 正处于激烈的竞争之中。全球多家科技巨头，包括 Meta、谷歌、亚马逊和微软，正在大力投入人工智能研发， hiring engineers and building data centers。仅在 2025 年，这四家公司在人工智能领域的投入就超过了 1550 亿美元。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管自 2022 年发布 ChatGPT 以来，人工智能技术有了显著提升，但 OpenAI 在本月发布的&lt;span&gt;最新&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 模型 GPT-5 的表现却并未得到热烈反响。用户反馈称，该版本的写作质量不如之前的版本，且缺乏以往的个性化特征。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;OpenAI 首席执行官山姆・奥特曼表示，虽然公司追求的是 「通用人工智能」，即能在大多数任务上超越人类的 AI，但他在最近的发布会上表示，GPT-5 是 「普遍智能」 的，但尚未能够 「持续学习」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367312</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367312</guid>
      <pubDate>Wed, 20 Aug 2025 02:02:53 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepSeek 刚刚更新线上模型版本至 V3.1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;DeepSeek 在官方社群宣布，其线上模型版本已升级至 V3.1，上下文长度拓展至 128k。&lt;/p&gt; 
&lt;p&gt;&lt;img height="300" src="https://static.oschina.net/uploads/space/2025/0819/193913_BlOM_2720166.png" width="1196" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;欢迎前往官方网页、APP、小程序测试，API 接口调用方式保持不变。&lt;/p&gt; 
&lt;p&gt;接口信息：https://platform.deepseek.com/usage&lt;/p&gt; 
&lt;p&gt;近日市场再度传出深度求索下一代 AI 大模型 DeepSeek-R2 的发布消息，预计时间窗口为 8 月 15 日至 30 日。对此，接近 DeepSeek 人士表示，该消息不实，并确认 DeepSeek-R2 在 8 月内并无发布计划。 &lt;/p&gt; 
&lt;p&gt;DeepSeek 创始人梁文锋在内部表示，他对 R2 取得的进展并不满意，并一直在竭力投入更多的时间来研发一款能够让该公司在 AI 领域保持领先地位的先进模型。&lt;/p&gt; 
&lt;p&gt;梁文峰要求模型达到更出色的结果才批准发布，R2 的发布还因更新版模型的数据标注时间超出预期而被推迟。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367254</guid>
      <pubDate>Mon, 18 Aug 2025 11:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 总裁透露 OpenAI 的 AGI 之路</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在最新一期的《Latent Space》访谈中，OpenAI 总裁 Greg Brockman 深入阐述了公司迈向 AGI 的整体路线图，核心可概括为「三个转向」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;技术转向：从「一次性预训练」到「强化学习推理」&lt;/li&gt; 
 &lt;li&gt;资源转向：把「算力」视为唯一稀缺资源&lt;/li&gt; 
 &lt;li&gt;落地转向：从「科研样品」到「可审计的生产 Agent」&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7470bcfe83cc59abb3b2fd2b11145f80512.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Greg Brockman 透露，GPT-4 发布之后，团队内部覆盘「它为何还不是 AGI」，结论是仅靠大规模预训练无法解决可靠性不足的问题，必须让模型在与真实世界的交互中「试错—反馈—再训练」。因此 GPT-5 首次引入强化学习驱动的「动态推理」范式：模型边使用边生成数据，再用这些数据进行再训练，逼近人类「边做边学」的循环。&lt;/p&gt; 
&lt;p&gt;他将这种「推理-重训」飞轮称为「超临界学习」（supercritical learning）：当算力放大 10× 乃至 10 000× 时，模型不仅能掌握任务本身，还能推演出二阶、三阶后果，从而快速逼近 AGI。&lt;/p&gt; 
&lt;p&gt;Greg Brockman 还把「算力」视为唯一稀缺资源，他认为算法壁垒往往可通过堆算力解决；AGI 进度条几乎与可用计算量线性相关。OpenAI 已把「持续投入大规模计算」写入长期资源策略，并认为未来 AGI 的形态会是「一个模型管理器」——本地小模型按需调用云端大算力，实现自适应计算。&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;总的来说，OpenAI 的 AGI 路线图可概括为「用强化学习把模型放进真实世界，用算力把反馈循环推到极致，用安全可控的 Agent 形态把能力嵌入千行百业」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367248</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367248</guid>
      <pubDate>Mon, 18 Aug 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Firefox 143 被发现不适用于某些旧 Windows 10 版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在旧版 Windows 10 上运行 Firefox 浏览器的用户即将迎来很大困扰。目前在 Nightly 频道提供的最新版本 Firefox 143 已不再适用于 1803 之前的版本。&lt;/p&gt; 
&lt;p&gt;在 Windows 10 1703、1709 或 2015 LTSB 等老版本上启动该浏览器时，用户会收到以下错误：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于未找到 api-ms-win-core-console-11-2-0.dll，代码无法继续执行。重新安装程序或许可以解决此问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0700df38d95ae0494d0de12f07efb1ce47d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FTheBobPony%2Fstatus%2F1955740560292999460" target="_blank"&gt;这一发现&lt;/a&gt;迅速引发了用户的讨论（他们已经对 Mozilla 向浏览器添加不必要的、耗费资源的内容&lt;a href="https://www.oschina.net/news/366029" target="_blank"&gt;感到不满&lt;/a&gt;），他们要求 Mozilla 放弃旧版 Windows 10，这并非罕见之举。尽管 Windows 10 总体上仍然受支持，但许多应用程序已无法在旧的版本上运行。&lt;/p&gt; 
&lt;p&gt;尽管如此，考虑到 Mozilla 浏览器仍然支持 Windows 7，放弃对部分 Windows 10 市场份额的支持却令人意外，不过某些旧版本（例如 2015 LTSB 和 2016 LTSC）仍然受支持。Windows&amp;nbsp;10 2015 LTSB 版本将于 2025 年 10 月停止支持，而 2016 LTSC 版本将继续获得更新，直到 2016 年 10 月。&lt;/p&gt; 
&lt;p&gt;然而事实证明，Mozilla 并没有在 1803 之前的 Windows 10 版本上淘汰 Firefox。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reddit.com%2Fr%2Ffirefox%2Fcomments%2F1mph4ra%2Fstarting_with_firefox_143_it_will_now_only%2F" target="_blank"&gt;Mozilla 工程师在 Reddit 上&lt;/a&gt;迅速处理了此事，并确认 Firefox 143 Nightly 无法在旧版 Windows 10 上运行的问题只是一个 bug，而非故意为之。因此，该问题应该很快就会得到修复。您可以&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbugzilla.mozilla.org%2Fshow_bug.cgi%3Fid%3D1983020" target="_blank"&gt;在 Bugzilla 官方网站上&lt;/a&gt;跟踪发现的 bug 。&lt;/p&gt; 
&lt;p&gt;与此同时，用户创建了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faubymori%2FFirefox-OldWindows%252010-Fix" target="_blank"&gt;一个临时解决方案&lt;/a&gt;，让浏览器在 Firefox 软件工程师准备永久修复程序期间能够正常运行。这也可以提醒大家不要依赖 Nightly 版本，因为这些版本的更改有时可能会导致浏览器完全崩溃。&lt;/p&gt; 
&lt;p&gt;Mozilla 尚未宣布终止 Windows 10 支持的计划。不过，由于 Windows 7 仍受支持，因此可以预期开发人员将在相当长的一段时间内继续在 Windows 10 上更新 Firefox。另一方面，微软近日透露，Edge 浏览器在 2025 年 10 月主流支持结束后，仍将在 Windows 10 上继续支持三年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367246</guid>
      <pubDate>Mon, 18 Aug 2025 11:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Claudia —— 基于 Tauri 2 的 Claude Code 桌面客户端</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Claudia 是一款强大的桌面应用程序，作为 Claude Code 的图形化命令中心，为 AI 辅助开发工作流程提供了直观的界面。该应用基于 Tauri 2、React 和 TypeScript 构建，填补了 Claude Code CLI 与开发者全面视觉体验之间的空白。&lt;/p&gt;

&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0818/181014_4hpz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;Claudia 通过提供功能丰富的图形用户界面（GUI），改变了开发者与 Claude Code 的交互方式，提升了生产力并简化了 AI 辅助开发流程。该应用程序基于您现有的 Claude Code 安装，自动检测您的&lt;code&gt;~/.claude&lt;/code&gt;目录，并为项目、会话和自定义 AI 代理提供可视化界面。&lt;/p&gt;

&lt;p&gt;Claudia 为存储在&lt;code&gt;~/.claude/projects/&lt;/code&gt;中的所有 Claude Code 项目提供了可视化浏览器。您可以：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过用户友好的界面浏览项目&lt;/li&gt;
&lt;li&gt;查看并恢复带有完整上下文的过往编码会话&lt;/li&gt;
&lt;li&gt;搜索特定项目和会话&lt;/li&gt;
&lt;li&gt;查看会话元数据，包括首次消息和时间戳&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该应用程序自动检测正在运行的 Claude Code 会话，并允许您从中央界面进行管理。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/claudia-code</link>
      <guid isPermaLink="false">https://www.oschina.net/p/claudia-code</guid>
      <pubDate>Mon, 18 Aug 2025 10:39:00 GMT</pubDate>
    </item>
    <item>
      <title>XZ Utils 后门仍然潜伏在 Docker 镜像中</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;安全研究公司 Binarly &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.binarly.io%2Fblog%2Fpersistent-risk-xz-utils-backdoor-still-lurking-in-docker-images" target="_blank"&gt;发布报告称&lt;/a&gt;，曾在 2024 年曝光的 &lt;strong&gt;XZ Utils 后门&lt;/strong&gt;仍在部分 Docker 镜像中潜伏，提醒开发者和运维人员容器供应链的潜在风险仍未彻底消除。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;xz-utils&lt;/code&gt; 软件包曾在 2024 年被发现存在严重后门（CVE‑2024‑3094，CVSS 10.0 分）。该后门通过 &lt;code&gt;liblzma.so&lt;/code&gt; 对 OpenSSH 函数加钩子，实现绕过 SSH 认证和远程执行权限操作。&lt;/p&gt; 
&lt;p&gt;尽管该漏洞在公开后迅速修复，但 Binarly 团队最新扫描显示，&lt;strong&gt;截至 2025 年 8 月，仍有 12 个 Debian 官方基础镜像直接包含该后门&lt;/strong&gt;，并且通过依赖关系，至少有 &lt;strong&gt;35 个镜像存在潜在传播风险&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0819/183442_zItb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;针对该情况，Debian 维护者回应称，这些镜像属于过时开发版，主要保留历史记录，因此选择不移除。Binarly 则提醒，即便利用条件苛刻，这些带网络触发能力的后门镜像仍可能被自动化构建或无意拉取带入生产环境，存在潜在安全威胁。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367240</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367240</guid>
      <pubDate>Mon, 18 Aug 2025 10:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>达梦数据：公司董事兼总经理被留置</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;达梦数据发布公告称，公司于近期收到湖北省应城市监察委员会下发的《立案通知书》及《留置通知书》，对公司董事兼总经理皮宇立案调查并实施留置措施。&lt;/p&gt; 
&lt;p&gt;目前，公司已对相关工作进行妥善安排，预计该事项不会对公司生产经营产生重大影响。其他董事、监事和高级管理人员均正常履职，公司及子公司日常经营情况正常，各项业务稳步推进。&lt;/p&gt; 
&lt;p&gt;&lt;img height="532" src="https://oscimg.oschina.net/oscnet/up-3b66d352d66b8255335b97b879b6b195785.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367239</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367239</guid>
      <pubDate>Mon, 18 Aug 2025 10:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>欧洲 AI 创企发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;欧洲知名 AI 初创公司 Multiverse Computing 近日发布了两款极其微小的 AI 模型，小到可以用鸡脑和蝇脑来命名。该公司声称这是全球最小但仍保持高性能的模型，能够处理聊天、语音识别，其中一款甚至具备推理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这些超小型模型专为物联网设备设计，同时可以在智能手机、平板电脑和个人电脑上本地运行。公司创始人罗曼·奥鲁斯向 TechCrunch 表示："我们可以将模型压缩到如此程度，使其能够适配各种设备。你可以在本地运行它们，直接在 iPhone 上，甚至在 Apple Watch 上。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Multiverse Computing 总部位于西班牙多诺斯蒂亚，在全球设有办公室，员工约 100 人，是一家备受关注的欧洲 AI 初创公司。该公司由欧洲顶级量子计算和物理学教授罗曼·奥鲁斯、量子计算专家塞缪尔·穆格尔和前 Unnim 银行副首席执行官恩里克·利萨索·奥尔莫斯共同创立。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="387" src="https://oscimg.oschina.net/oscnet/up-994e0870ab2f0680c22e597e4d0461fe9b9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;今年 6 月，该公司凭借名为"CompactifAI"的模型压缩技术成功融资 1.89 亿欧元（约 2.15 亿美元）。自 2019 年成立以来，公司累计融资约 2.5 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;CompactifAI 是一种量子启发的压缩算法，能够在不牺牲模型性能的前提下减小现有 AI 模型的体积。奥鲁斯解释说:"我们拥有的压缩技术不是计算机科学或机器学习领域人员会采用的典型压缩技术，因为我们来自量子物理学背景。这是一种更加精妙和精细的压缩算法。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;该公司已经发布了大量开源模型的压缩版本，特别是流行的小型模型如 Llama4Scout 或 Mistral Small3.1，并刚刚推出了 OpenAI 两个新开源模型的压缩版本。公司还压缩了一些大型模型，比如提供 DeepSeek R1Slim 版本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;专注于模型小型化的 Multiverse 将额外精力投入到创造尽可能小但功能强大的模型上。其两款新模型小到足以为几乎任何物联网设备带来聊天 AI 功能，并且无需互联网连接。公司幽默地称这个系列为"模型动物园"，因为产品是根据动物大脑尺寸命名的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;名为 SuperFly 的模型是 Hugging Face 开源模型 SmolLM2-135 的压缩版本。原始模型有 1.35 亿个参数，专为设备端使用开发。SuperFly 压缩至 9400 万个参数，奥鲁斯将其比作蝇脑的大小。他说："这就像拥有一只苍蝇，但稍微聪明一点。"&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;SuperFly 专为在极其受限的数据上进行训练而设计，比如设备操作数据。Multiverse 设想将其嵌入家用电器中，让用户能够通过语音命令操作设备，如对洗衣机说"开始快洗"，或询问故障排除问题。通过少量处理能力（如 Arduino），该模型就能处理语音界面，公司向 TechCrunch 进行了现场演示。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;另一款名为 ChickBrain 的模型更大，有 32 亿个参数，但功能也更强大，具备推理能力。Multiverse 表示这是 Meta Llama3.18B 模型的压缩版本，但小到足以在 MacBook 上运行，无需互联网连接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，奥鲁斯表示 ChickBrain 在多个标准基准测试中实际上略微超越了原始模型，包括语言技能基准 MMLU-Pro、数学技能基准 Math500 和 GSM8K，以及通用知识基准 GPQA Diamond。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;需要注意的是，Multiverse 并未声称其模型动物园会在这些基准测试中击败最大的最先进模型，动物园的性能甚至可能不会出现在排行榜上。关键在于该公司的技术能够在不影响性能的情况下缩小模型尺寸。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;奥鲁斯表示，公司已在与所有领先的设备和家电制造商进行洽谈。他说:"我们正在与苹果洽谈，也在与三星、索尼和惠普对话。惠普在最后一轮融资中作为投资者参与进来。"这轮融资由知名欧洲风投公司 Bullhound Capital 领投，包括 HP Tech Ventures 和东芝在内的多家机构参与。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这家初创公司还为其他形式的机器学习提供压缩技术，如图像识别，在六年时间里已获得巴斯夫、Ally、穆迪、博世等客户。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;除了直接向主要设备制造商销售模型外，Multiverse 还通过托管在 AWS 上的 API 提供压缩模型，任何开发者都可以使用，通常比竞争对手收取更低的 token 费用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367238</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367238</guid>
      <pubDate>Mon, 18 Aug 2025 10:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>小米 Q2 净利润同比增长 75.4%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;小米集团公布 Q2 财报，数据显示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;小米集团第二季度营收 1159.6 亿元人民币，同比增长 30.5%，创历史新高。预估 1149.4 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;调整后净利润 108.3 亿元人民币，同比增长 75.4%，同样创下历史新高。预估 102.3 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;营业利润 134.4 亿元人民币，预估 104.3 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;研发支出 77.6 亿元人民币，同比增长 41.2%。预估 71.8 亿元人民币。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;智能电动汽车及 AI 等创新业务分部收入达到人民币 213 亿元，其中汽车业务贡献了 206 亿元。该分部的毛利率高达 26.4%，远高于去年同期的 15.4%。财报将其归因于核心零部件成本下降、单位制造成本降低，以及高 ASP（平均售价）的 Xiaomi SU7 Ultra 交付。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="217" src="https://oscimg.oschina.net/oscnet/up-7c457b8deb1369b766421cd8022a09bb76f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心业务进展：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能电动汽车：&lt;/strong&gt;已成为绝对的增长引擎。本季度收入达 213 亿元，交付 81,302 辆新车。毛利率高达 26.4%，远超市场预期，显示出强大的成本控制和高端车型交付能力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;IoT 与生活消费产品：&lt;/strong&gt;表现亮眼，收入 387 亿元，同比猛增 44.7%，毛利率提升至 22.5%。智能大家电（空调、冰箱、洗衣机）是主要增长动力。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;智能手机：&lt;/strong&gt;尽管出货量微增 0.6% 至 4240 万台，但收入同比下滑 2.1% 至 455 亿元，毛利率从 12.1% 降至 11.5%，主要受境外市场竞争及国内促销活动影响。&lt;/span&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;互联网服务：&lt;/strong&gt;收入稳定增长至 91 亿元，同比增长 10.1%，但毛利率从 78.3% 微降至 75.4%。&lt;/span&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;小米集团表示，2025 年第二季度，智能大家电的收入创历史新高，同比增长达 66.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="2551" src="https://static.oschina.net/uploads/space/2025/0819/175808_cTEa_4252687.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367233</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367233</guid>
      <pubDate>Mon, 18 Aug 2025 09:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌工程师提交补丁：Linux 内核首次支持 OOM 策略可编程</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 内核正迎来一项可能改变内存管理方式的新提案。来自谷歌的内存管理专家 Roman Gushchin 提交了一组补丁，计划允许通过 BPF（eBPF）直接定制系统在 &lt;strong&gt;内存溢出（OOM, Out-of-Memory）&lt;/strong&gt; 时的处理逻辑。这意味着，长期以来依赖内核默认 OOM killer 或用户空间工具（如 systemd-oomd）的局限性，或将被更灵活、可编程的机制取代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="712" src="https://static.oschina.net/uploads/space/2025/0819/174242_BTqv_2720166.png" width="1082" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://lore.kernel.org/lkml/20250818170136.209169-1-roman.gushchin@linux.dev/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;该方案的核心思路是在内核触发 OOM killer 之前，先调用 BPF 程序。运维人员或云平台可以借此决定是终止某个特定进程、清理某个内存 cgroup，甚至通过删除 tmpfs 文件来释放内存，而不必一刀切地依赖内核默认策略。同时，新的补丁还引入基于 PSI（Pressure Stall Information） 的 OOM 触发机制，更好地判断何时真正进入「内存压力」状态，从而避免系统假死或误杀关键进程。&lt;/p&gt; 
&lt;p&gt;在实现上，这些补丁增加了新的 BPF 辅助函数，例如显式杀死指定进程的 &lt;code&gt;bpf_oom_kill_process()&lt;/code&gt;，以及获取内存 cgroup 根节点的 &lt;code&gt;bpf_get_root_mem_cgroup()&lt;/code&gt;，为内核空间提供了更强的可编程接口。&lt;/p&gt; 
&lt;p&gt;如果最终被合入主线，Linux 将首次赋予开发者和运维团队在内核层面 &lt;strong&gt;「编写自己的 OOM 策略」&lt;/strong&gt; 的能力，这对数据中心、云计算平台以及对内存敏感的服务部署而言，都可能带来深远影响。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367232</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367232</guid>
      <pubDate>Mon, 18 Aug 2025 09:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Gemini API 支持抓取 URL</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌宣布其 Gemini API 中的 URL Context 工具&lt;strong&gt;已正式支持直接抓取 URL 内容&lt;/strong&gt;，无需额外脚本或中间步骤。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0819/172728_9w7A_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Gemini API 提供了 &lt;strong&gt;URL Context 功能&lt;/strong&gt;，允许你在请求中直接嵌入网页链接，模型会自动访问并解析网页内容。支持的内容类型包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文本网页（HTML、JSON、TXT 等）&lt;/li&gt; 
 &lt;li&gt;PDF 文件&lt;/li&gt; 
 &lt;li&gt;图片（PNG、JPEG、WebP 等）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;不支持的内容：YouTube 视频、Google Docs、付费墙内容等。&lt;/p&gt; 
&lt;p&gt;✅ 使用示例（Python SDK）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
  model="gemini-2.5-flash",
  contents=[
      "总结这篇文章的内容：",
      types.Part.from_uri(
        uri="https://example.com/article",
        mime_type='text/html'
      )
  ]
)
print(response.text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;使用限制&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次最多支持 &lt;strong&gt;20 个 URL&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;单个 URL 内容大小上限为 &lt;strong&gt;34MB&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;抓取内容会计入 &lt;strong&gt;输入 Tokens 费用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果你使用 &lt;strong&gt;Gemini CLI&lt;/strong&gt;，也可以通过 &lt;code&gt;web_fetch&lt;/code&gt; 工具快速抓取网页，例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gemini-cli web-fetch --prompt "总结 https://example.com/article 的主要内容"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该工具会自动识别提示中的 URL 并调用 Gemini API 抓取内容。&lt;/p&gt; 
&lt;p&gt;如你正在开发基于 Gemini 的应用，&lt;strong&gt;URL Context 功能&lt;/strong&gt;已足够替代传统的爬虫或 HTML 解析器，大幅提升开发效率。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关链接&lt;/p&gt; 
&lt;p&gt;https://ai.google.dev/gemini-api/docs/url-context&lt;br&gt; https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#url-context&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367231/gemini-api-url-context</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367231/gemini-api-url-context</guid>
      <pubDate>Mon, 18 Aug 2025 09:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>淘宝「AI 万能搜」功能灰度测试</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;淘宝正在灰度测试一项名为「AI 万能搜」的新功能，旨在通过大模型技术重构电商搜索体验。该功能位于淘宝搜索页的「AI 万能搜」标签页，标志着 AI 技术在电商领域的应用正从企业端（B 端）营销，加速渗透至消费者端 (C 端) 的实用阶段。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「AI 万能搜」是一款基于大模型的 AI 问答产品，能够理解用户的自然语言提问并进行深度思考。用户提问后，AI 会生成一份融合文字、商品、视频和图片的「答案报告」，以解决用户在购物过程中遇到的各种消费难题，例如购物攻略、口碑评测和优惠咨询等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;据了解，目前「AI 万能搜」主要聚焦于四大核心场景:穿搭指南、送礼清单、选购攻略和问口碑。该功能的一大亮点在于，用户可以清晰地看到 AI 的思考过程，其思考逻辑主要分为三个步骤:获取信息、查询需求和分析总结。尽管目前尚不清楚其底层大模型是否只使用了「千问」，但这一功能已经展现出 AI 在提升消费者购物决策效率上的巨大潜力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="649" src="https://oscimg.oschina.net/oscnet/up-ea057aa8125432f67b68af7319fc597d9e8.jpg" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367229</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367229</guid>
      <pubDate>Mon, 18 Aug 2025 09:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Abogen - 文本转语音工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Abogen 是一款功能强大的文本转语音工具，可轻松将 ePub、PDF 或文本文件在几秒钟内转换为带有匹配字幕的高质量音频。可以使用&lt;a href="https://huggingface.co/hexgrad/Kokoro-82M"&gt;Kokoro-82M&lt;/a&gt;将其用于有声读物、Instagram、YouTube、TikTok 的配音，或任何需要自然语音的文本转语音项目。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151846_7vpx_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&amp;nbsp;&lt;img alt="" height="499" src="https://static.oschina.net/uploads/space/2025/0813/151903_hNpV_4252687.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/abogen</link>
      <guid isPermaLink="false">https://www.oschina.net/p/abogen</guid>
      <pubDate>Mon, 18 Aug 2025 09:19:00 GMT</pubDate>
    </item>
    <item>
      <title>Vercel 旗下 AI 前端开发工具 v0 推出 iOS 应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel 旗下 AI 前端开发工具 v0&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fv0%2Fstatus%2F1957487790205325760"&gt;宣布&lt;/a&gt;即将推出其 iOS 应用程序，目前已开放候补名单注册。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0819/164508_7TkM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;http://v0.app/ios&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;根据官方发布的信息，其宣传语为 「Anything. Anyone. Anywhere.」。用户现在可以通过官方链接加入等待列表。&lt;/p&gt; 
&lt;p&gt;Vercel v0 是一个利用自然语言提示生成全栈 web 应用的 AI 工具，其核心优势在于通过简单的文本描述即可快速生成高质量的用户界面和代码。自 2023 年首次推出以来，v0 凭借其在前端 UI 生成上的卓越表现，特别是在 React 和 Next.js 框架中的应用，赢得了开发者和企业的广泛认可。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367213</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367213</guid>
      <pubDate>Mon, 18 Aug 2025 08:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>中山大学联合美团打造 X-SAM 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;中山大学、鹏城实验室与美团三方联合研发的 X-SAM 图像分割模型近期正式发布，这款多模态大模型在图像分割领域实现了重要突破，将传统的"分割万物"能力升级为"任意分割"，显著提升了模型的适应性和应用范围。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;传统的 Segment Anything Model（SAM）虽然在生成密集分割掩码方面表现出色，但其只能接受单一视觉提示输入的设计局限性明显。针对这一技术瓶颈，研究团队创新性地提出了视觉定位分割 (Visual Grounded Segmentation， VGS) 任务框架，通过交互式视觉提示实现对所有实例对象的精确分割，为多模态大语言模型提供了像素级的理解能力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的技术架构采用了多项创新设计。模型支持统一的输入格式和输出表示，能够处理多种类型的视觉和文本查询输入。其核心的双编码器架构确保了对图像内容和分割特征的深度理解，而分割连接器则提供多尺度信息融合，大幅提升分割精度。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="432" src="https://oscimg.oschina.net/oscnet/up-17e3fd0c4916165c034f2f1fecd344dd8e9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;最值得关注的是，X-SAM 集成了&lt;span&gt;最新&lt;/span&gt;的 Mask2Former 架构作为分割解码器，这使得模型能够在单次操作中同时分割多个目标对象，彻底突破了传统 SAM 只能处理单一对象的技术限制。这一改进不仅提高了处理效率，也为复杂场景下的批量分割任务提供了可能。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在模型训练方面，研究团队采用了三阶段渐进式训练策略，通过逐步增强的学习过程确保模型性能的稳定提升。经过在 20 多个主流分割数据集上的全面测试，X-SAM 在对话生成分割任务和图文理解任务中均取得了领先的性能表现，验证了其技术方案的有效性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;X-SAM 的发布为图像分割技术发展指明了新方向，也为构建更加智能的通用视觉理解系统提供了重要的技术基础。研究团队表示，下一步将重点探索该技术在视频领域的应用拓展，推动图像与视频分割技术的统一化发展，进一步提升机器视觉理解能力的边界。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这项研究成果不仅在学术层面具有重要意义，其在自动驾驶、医疗影像、工业检测等实际应用场景中的潜力也值得期待。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367209</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367209</guid>
      <pubDate>Mon, 18 Aug 2025 08:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ElevenLabs 上线 Eleven Music API，首款商用 AI 音乐生成接口</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;ElevenLabs&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Felevenlabs.io%2Fblog%2Feleven-music-now-available-in-the-api" target="_blank"&gt;宣布推出 Eleven Music API&lt;/a&gt;，这是首款基于全授权数据训练、专为开发者打造的商用 AI 音乐生成接口。自 2024 年推出以来，创作者已通过该工具生成超 75 万首歌曲，印证市场强劲需求。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;使用文档：https://elevenlabs.io/docs/cookbooks/music/quickstart&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77a672de334942fafedf640d6297bfa4453.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该 API 突破性解决了 AI 音乐领域的版权痛点，其模型基于百万小时授权音频数据训练，采用类 GPT 的 Transformer 架构，可通过文本提示实时生成多风格、多情绪的原创音乐，彻底规避未授权数据引发的法律风险，为游戏、广告、内容创作等行业提供合规解决方案。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367208/eleven-music-now-available-in-the-api</guid>
      <pubDate>Mon, 18 Aug 2025 08:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
