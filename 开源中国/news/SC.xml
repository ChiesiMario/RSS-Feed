<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 23 Aug 2025 12:42:45 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Meta 陷入史上最大 AI 训练数据侵权案，面临 3.59 亿美元索赔</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;美国加利福尼亚州法院最近受理的一起诉讼案件，将全球科技巨头 Meta 推到了舆论的风口浪尖。两家成人影片制作公司 Strike3 和 Counterlife Media 的联合起诉，不仅揭露了 AI 训练背后的数据获取黑幕，更以高达 3.59 亿美元的索赔金额，为整个科技行业敲响了版权保护的警钟。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这起诉讼的核心指控令人震惊。根据法庭文件显示，Meta 公司自 2018 年以来一直在明知故犯地从盗版来源下载受版权保护的影片内容，累计涉及至少 2396 部作品。这些非法获取的视频资料被用于训练包括 Meta Movie Gen 视频生成模型和 LLaMA 语言大模型在内的多种 AI 系统，为 Meta 的人工智能技术发展提供了重要的数据支撑。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更加令人意外的是 Meta 获取这些内容的方式。起诉文件详细披露，Meta 并非简单地下载这些盗版内容，而是主动利用 BitTorrent 文件共享技术进行大规模的非法内容获取。这种 P2P 下载方式的特殊之处在于，下载者同时也会成为内容的分发者，通过"种子"技术向网络中的其他用户传播相同的文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Meta 选择这种下载方式绝非偶然。BitTorrent 协议的核心优势在于其分布式下载机制能够显著提升大文件的传输速度，这对于需要处理海量视频数据的 AI 训练项目而言具有重要价值。然而，这也意味着 Meta 不仅仅是被动的内容接收者，更是主动的盗版内容传播者，其行为的恶劣性质因此被进一步放大。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;原告方的律师团队在起诉书中强调，Meta 完全有能力通过合法途径获取所需的训练数据。无论是直接购买版权授权，还是修改下载工具的设置以避免传播行为，Meta 都拥有多种合规选择。然而，该公司却选择了最具争议的方式持续进行非法下载和传播活动，这种明知故犯的行为模式充分显示了其侵权的故意性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这起诉讼案件并非孤立事件，而是近年来 AI 公司版权争议的最新爆发点。此前已有多位知名作家对 Meta 提起类似诉讼，指控其未经许可使用受版权保护的文学作品训练 AI 大模型。值得注意的是，在那些案件的法庭审理过程中，Meta 已经公开承认确实曾从盗版来源获取过训练内容。这一承认不仅为当前的诉讼提供了重要的法律依据，也让 Meta 在这起新案件中处于更加被动的地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Strike3 公司在这起诉讼中的角色转变具有重要的象征意义。作为美国最活跃的版权维权机构之一，Strike3 长期以来主要专注于起诉个人盗版用户，通过大量的民事诉讼来维护版权方的合法权益。然而，此次将矛头直指 Meta 这样的科技巨头，标志着版权保护战线正在向更高层面扩展，传统的版权维权策略开始适应 AI 时代的新挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;3.59 亿美元的索赔金额虽然数字庞大，但其计算依据相当清晰。按照美国版权法的相关规定，每部被侵权作品的法定赔偿金最高可达 15 万美元，而 2396 部涉案影片的总赔偿金额上限正好接近这一数字。这种按作品数量累计的赔偿方式，充分体现了版权法对批量侵权行为的严厉态度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;对于 Meta 而言，这起诉讼的影响远超经济层面的损失。作为全球领先的科技公司，Meta 在人工智能领域的投资规模巨大，其 AI 产品的竞争力很大程度上依赖于高质量训练数据的获取。如果法庭最终认定 Meta 的数据获取方式违法，这不仅会对公司的财务状况造成直接冲击，更可能迫使其重新审视整个 AI 训练数据的获取策略。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这起诉讼案件的更深层意义在于它可能成为 AI 行业版权规范的重要转折点。随着人工智能技术的快速发展，训练数据的需求量呈现爆炸式增长，而现有的版权法律框架显然还没有完全适应这种新兴技术的发展需求。Meta 案件的审理结果很可能为整个行业的数据使用规范确立重要的法律先例。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;目前，Meta 公司尚未对这起诉讼作出正式回应，但业界普遍认为这将是一场持续时间较长的法律拉锯战。无论最终结果如何，这起案件已经向所有 AI 公司发出了明确信号:在追求技术进步的同时，必须严格遵守版权法律的相关规定，否则将面临巨大的法律和经济风险。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367923</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367923</guid>
      <pubDate>Mon, 18 Aug 2025 10:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Gitee 企业版 AI 队友邀测开启：程序员的贴身助理来了</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在团队协作开发中，有两类工作总让人心力交瘁：&lt;/p&gt; 
&lt;p&gt;🤦&amp;nbsp;&lt;strong&gt;一类是 PR 审查&lt;/strong&gt;：信息量大、变更复杂、上下文冗长。哪怕只是一个小改动，也得花不少时间理清上下文、理解影响范围；&lt;/p&gt; 
&lt;p&gt;🤦&amp;nbsp;&lt;strong&gt;另一类是安全漏洞排查&lt;/strong&gt;：依赖众多、更新频繁，稍有疏忽就可能埋下风险，事后追溯更是代价高昂。&lt;/p&gt; 
&lt;p&gt;这些工作既重要又琐碎，既不能不做，又难以做好。更现实的是，&lt;strong&gt;AI 想真正胜任这些工作，还远远不够成熟&lt;/strong&gt;，市面上的 AI 工具要么误报多，要么落地难，无法真正服务于企业级的研发流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gitee 企业版刚刚推出的「AI 队友」功能，就是为了解决这个现实问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-92cde867ee668b21e5a6c74cccb9abee554.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们不指望也不敢完全让 AI 替我们做此类决策，我们更需要的是一位靠谱的「实习生型 Bot」：&lt;strong&gt;不会瞎拍板、不会乱判断，但能主动发现问题&lt;/strong&gt;，让代码审得更清楚，安全盯得更扎实。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;PR 审查队友：让代码审得更快、更准、更稳&lt;/h2&gt; 
&lt;p&gt;面对频繁提交的 PR 和复杂的协作背景，人工审查不仅耗时耗力，还容易遗漏关键问题。PR 审查队友通过智能分析与规则驱动，协助审查人员聚焦重点内容，在不替代人工判断的前提下，有效提升审查效率。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6eeccbe08f3b64b5a96a21b811333ad0ade.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它的核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;自动触发审查&lt;/strong&gt;：在 PR 新建、更新或重新打开时，自动完成初步审查，也可通过 @PR 审查队友 /review 指令手动发起；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="123" src="https://oscimg.oschina.net/oscnet/up-8bc1b8ee6c9c96cc6e2e2ecaeaaa001cc30.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;结构化检查维度：涵盖功能逻辑、安全性、性能与可维护性四大类问题，生成清晰的评论意见；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="609" src="https://oscimg.oschina.net/oscnet/up-af5b6323ed9f0906ddce24f2182fc3f0cac.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;规则灵活配置：支持每个仓库独立设置最多 10 条自定义规则，结合上传的 txt 格式企业规范，实现差异化审查策略；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-d022b59593b0d8a77758afc7b00b730ea97.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多仓库支持：每位审查队友可同时服务最多 5 个仓库，超出可灵活增配，满足企业规模化协作需求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;文件过滤能力：支持以 glob 规则排除自动生成文件（如 RPC、templ 等），避免干扰审查结果；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;权限与管理机制：仅企业管理员或仓库负责人可配置和管理队友，保障安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;专属工作区与任务日志：可查看历史审查行为、审查计划分布与执行状态，便于团队协同管理；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c420fcc3c18ef0789db500fb56dd16104c3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PR 审查队友适用定位：补充人工盲区，聚焦潜在风险，不做决策，只做提醒。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;安全分析队友：盯紧依赖，提前识别风险&lt;/h2&gt; 
&lt;p&gt;随着项目日益依赖第三方组件，单靠人工排查已难以满足对代码安全的管理要求。安全分析队友基于啄木鸟 CodePecker SCA 引擎，提供高频自动扫描与 AI 分析能力，帮助团队实现持续的依赖安全治理。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0df7dcc13bfe7b34ebd592e1be2c43f83b7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;它的核心能力包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动化漏洞扫描：支持每周定时扫描与手动即时扫描，确保漏洞发现不滞后；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-104b5eb66845a60904220e0bf99b3c105d1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CVE 漏洞识别与报告生成：自动检测仓库代码及依赖中的 CVE 漏洞，提供风险等级、定位详情及修复建议；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-65793620a6c467ce93126cd6641c481f8e7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI 风险分析总结：为高危问题自动创建缺陷卡片，帮助开发者快速理解风险并推动闭环处理；&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f62beeb23754240b78102b58f865903c34e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;多语言支持：覆盖 JavaScript、Python、Java 等主流语言，适配不同技术栈的项目；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;仓库级配置能力：可自动识别代码语言，灵活适配扫描策略；扫描行为与结果均可在工作区中可视化查看。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;安全分析队友适用定位：提前暴露依赖漏洞，推动闭环修复，保障交付安全。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;现已开放邀测，欢迎扫码体验&lt;/h2&gt; 
&lt;p&gt;目前，「AI 队友」功能已在 Gitee 企业版中正式上线，公开邀测同步开启。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;查看 AI 队友的详细配置&amp;amp;最佳实践指南：&lt;a href="https://help.gitee.com/enterprise/ai/ai_teamates" target="_blank"&gt;https://help.gitee.com/enterprise/ai/ai_teamates&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果你的团队也在面对 PR 审查负担、漏洞排查难题，欢迎申请试用，让 AI 队友来帮你分担重复性工作、提升团队整体效能。&lt;/p&gt; 
&lt;p&gt;👇&lt;strong&gt;扫码进群获取邀测资格与使用指引&lt;/strong&gt;👇&lt;/p&gt; 
&lt;p&gt;&lt;img height="396" src="https://oscimg.oschina.net/oscnet/up-eb9aab33f9912c1b53ec2b87e6f098590ce.png" width="396" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-af428a1f9979c04cfb1484b3743ef1cb247.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367917</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367917</guid>
      <pubDate>Mon, 18 Aug 2025 10:04:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>治理算法滥用，核心在于「算法透明」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;8 月 22 日,《新华每日电讯》发表题为《治理算法滥用，核心在于「算法透明」》的评论。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;近年来，算法滥用事件频发，这些事件不断提醒我们：打开「算法黑箱」已成为数字时代必须面对的核心议题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;算法滥用的社会危害性不容小觑。首先，用户自主选择接收的信息范围被无形限制。算法根据用户历史行为构建偏好模型，不断强化同类内容推送，形成「信息茧房」。人们被困在自我重复的信息回音壁中，逐渐失去接触多元观点、挑战自我认知的机会，社会共识的基础被悄然侵蚀。这也是当下网络戾气激增、群体情绪激化突出的成因之一。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;其次，用户可能因算法滥用而遭受消费者权益损害。「千人千面」的定价策略让老用户看到更高价格，「精准营销」跨越隐私边界，用户在不自知中成为「被算计的对象」。更值得警惕的是，算法滥用可能助长网络谣言、网络暴力等不良信息的传播。为追求用户停留时长，算法往往优先推送煽动性、情绪化内容，使理性声音被淹没，情绪变得极端化，甚至引发线下事件。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;治理算法滥用的核心在于「打开黑箱」，实现算法透明。《互联网信息服务算法推荐管理规定》所要求的平台公示算法推荐服务的基本原理、目的意图和主要运行机制，正是这一理念的重要实践。但需要明确的是，算法透明并非要求公开商业秘密或核心技术细节，而是揭示算法服务的基本规则和对用户权益的影响方式。就像我们不需要了解发动机的制造原理，但有权知道汽车的安全性能和油耗标准一样，用户有权知晓算法如何影响他们的信息环境和决策选择。这种有限度的透明，既保护了企业的创新动力，又保障了用户的基本知情权和选择权，让用户真正有能力自由挑选自己想要了解或喜欢的网络信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;当然，治理算法滥用需要多方协同发力。其一，网络平台应当以清晰易懂的方式说明算法服务对用户权益的影响，提供必要的关闭或调整选项。特别是对于老年人等特殊群体，要结合老年人经常面临的实际问题，适当增加诸如反电信网络诈骗、反伪科普等内容的推送比例。其二，监管机构需实施常态化监管，督促平台持续优化内部算法安全管理机制和算法技术应用提示说明机制，确保平台以简明扼要、清晰易懂的方式公开算法推荐服务的基本情况。其三，社会公众也需要积极参与治理活动，提升信息素养，培养数字时代的批判性思维，主动寻求多元信息源，共同构建健康透明、向上向善的网络信息生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得注意的是，打开「算法黑箱」存在一定技术门槛。算法公示机制的根本目的是实现个体权益受算法技术应用影响方式的「可视化」，所以，公示范围、公示频率应当围绕该目的而合理设置，而非以「信息倾泻」的方式让公众无从知晓算法技术应用对自身权益究竟有何影响。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;进一步而言，平台算法公示信息更适宜与普法信息同步呈现，避免一般社会公众误认为算法技术应用对自身权益存在影响就等于「重大威胁」，借由普法信息打消公众不必要的担忧，帮助公众在准确知晓权益影响程度、方式的基础上，自主选择相应的服务选项。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;归根结底，算法原理公示从来都不是减损企业市场竞争技术优势地位的强制性规范，而是为了引导信息服务行业提供更优质的信息服务、形成更健康的行业惯例。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:black; text-align:left"&gt;&lt;span style="color:#000000"&gt;在实践中，开设「平台算法原理公示」专栏、公开算法推荐服务权益影响说明、用户代表参与算法设计、第三方算法安全审计等方式，不仅是数字时代算法技术应用监管的创新尝试，更是数字时代技术安全治理理念的重要进步。阳光是最好的消毒剂，只有让算法运行在阳光下，才能打破信息茧房的桎梏，构建真正开放、包容、健康的数字空间。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367915</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367915</guid>
      <pubDate>Mon, 18 Aug 2025 10:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>俄罗斯 HapticVLM 系统发布，触觉识别准确率 84.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;来自俄罗斯斯科尔科沃科学技术研究院的科研团队最新研发了一个名为 HapticVLM 的多模态触觉系统，材料识别准确率高达 84.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;根据介绍，HapticVLM 系统的技术核心体现在其精巧的架构设计上。系统巧妙地融合了深度卷积网络与视觉语言推理技术，实现了从视觉信息到触觉反馈的无缝转换。整个识别过程如行云流水般顺畅:系统首先通过先进的 ConvNeXt 架构对物体进行深度扫描，精准识别出是金属的冰冷坚硬、木材的温润质朴，还是织物的柔软细腻。随后，系统会生成极其稳健的视觉嵌入数据，为后续的材料识别提供坚实的数据基础。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="356" src="https://oscimg.oschina.net/oscnet/up-ca52106883566230e53bf4b3497fa8821a0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;HapticVLM 还具备了环境感知的智慧。借助最新的 Qwen2-VL-2B-Instruct 视觉语言模型，系统能够智能推测周围环境的温度状况，并将这一信息 seamlessly 整合到触觉体验中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;当用户的手指轻抚虚拟物体表面时，HapticVLM 会通过高精度扬声器产生与特定材质完美匹配的振动反馈。这些振动并非简单的机械震动，而是经过精密计算的复合波形，能够准确模拟金属表面的坚实感、木质纹理的粗糙感，以及丝绸面料的顺滑感。每一次触碰都能带来令人信服的真实感受。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;通过集成的帕尔贴模块，HapticVLM 能够提供精确的动态温度变化，让用户真切感受到金属的冰冷、木材的温和，甚至是刚刚烘焙完成的面包所散发的温暖。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;实验数据表明，在涵盖五种不同听觉触觉模式的综合测试中，系统平均识别准确率达到了 84.67%，这一成绩在同类技术中堪称翘楚。在 15 种复杂环境场景的温度估算挑战中，系统表现出了 86.7% 的超高准确率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;不过，研究团队也坦诚当前系统存在的局限性，并明确了未来的发展方向。团队计划在触觉模式的广度和深度上进一步拓展，同时加强用户体验研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;HapticVLM 系统的应用前景极其广阔，几乎涵盖了所有需要触觉交互的数字化场景。在虚拟现实游戏中，玩家将能够真实感受到剑刃的锋利和盔甲的厚重。在在线购物平台上，消费者可以在购买前就体验到商品的真实手感。在远程医疗领域，医生能够通过触觉反馈进行更精确的远程诊断。在教育培训中，学生可以通过触觉体验更深入地理解物理和化学知识。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367907</guid>
      <pubDate>Mon, 18 Aug 2025 09:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Kimi K2 再提速，最高可达每秒 100 Tokens</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;月之暗面今日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMMklNqYVQWdCRzWQwOUs0Q" target="_blank"&gt;宣布&lt;/a&gt;，经过工程师们的不懈努力，kimi-k2-turbo-preview 模型输出速度已经提升至每秒 60 Tokens，最高可达每秒 100 Tokens。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;目前该模型仍然享受 5 折特惠价格，模型每百万 tokens 输入价格（缓存命中）¥2.00，输入价格（缓存未命中）¥8.00，输出价格 ¥32.00。9 月 1 日恢复原价。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9de6fdf009846744551a9cb1485708ffcde.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;更多信息请访问官网&lt;em&gt; https://platform.moonshot.cn&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;月之暗面 8 月 1 日发布 Kimi K2 高速版 —— Kimi-K2-turbo-preview，模型参数与 Kimi-K2 一致，但输出速度由每秒 10 Tokens 提升至每秒 40 Tokens。&lt;/p&gt; 
&lt;p&gt;Kimi K2 是一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367902</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367902</guid>
      <pubDate>Mon, 18 Aug 2025 08:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>PlutoPrint - 从 HTML 生成 PDF 和图像</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;PlutoPrint 是一个轻量级且易于使用的 Python 库，可直接从 HTML 或 XML 内容生成高质量的 PDF 和图像。&lt;/p&gt;

&lt;p&gt;它基于&lt;a href="https://github.com/plutoprint/plutobook"&gt;PlutoBook&lt;/a&gt;强大的渲染引擎，并提供简单的 API，可将 HTML 转换为清晰的 PDF 文档或色彩鲜艳的图像文件。这使其成为报告、发票或视觉快照的理想选择。&lt;/p&gt;

&lt;table cellspacing="0" style="-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#1f2328; display:block; font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Segoe UI&amp;quot;,&amp;quot;Noto Sans&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;; font-size:16px; font-style:normal; font-variant:tabular-nums; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; max-width:100%; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:max-content; word-spacing:0px"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="border-color:#d1d9e0"&gt;Invoices&lt;/th&gt;
&lt;th style="border-color:#d1d9e0"&gt;Tickets&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;img height="323" src="https://static.oschina.net/uploads/space/2025/0821/154554_nIdG_4252687.png" width="569" referrerpolicy="no-referrer"&gt;&lt;/td&gt;
&lt;td style="border-color:#d1d9e0; border-image:none 100% / 1 / 0 stretch; border-style:solid; border-width:0.666667px"&gt;&lt;img height="327" src="https://static.oschina.net/uploads/space/2025/0821/154608_8DTR_4252687.png" width="567" referrerpolicy="no-referrer"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/plutoprint</link>
      <guid isPermaLink="false">https://www.oschina.net/p/plutoprint</guid>
      <pubDate>Mon, 18 Aug 2025 08:45:00 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic 寻求 100 亿美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-08-21%2Fanthropic-in-talks-to-raise-up-to-10-billion-in-new-funding" target="_blank"&gt;根据《彭博社》的报道&lt;/a&gt;，Anthropic 正就一轮高达 100 亿美元的新融资进行最后谈判，此轮融资将使其投后估值达到约 1700 亿美元。因投资者需求远超预期，原定 50 亿美元的融资规模被直接翻倍。本轮完成后，Anthropic 现金储备将大幅增加。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a4f572245a4ba561e4f3b580fcb0e2fcb0f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Anthropic 成立于 2021 年，由前 OpenAI 核心成员创建，其主要产品 Claude 系列 AI 模型在市场中广受关注。截至 2024 年，其曾获得亚马逊与谷歌等巨头的大规模投资，此次新一轮融资若成功，将令其资金实力更上层楼。&lt;/p&gt; 
&lt;p&gt;据悉，投资公司 Iconiq Capital 将领投该轮融资。知情人士透露，其他预计的参与者包括 TPG Inc.、光速创投、Spark Capital 和 Menlo Ventures。Anthropic 还与卡塔尔投资局和新加坡主权基金新加坡政府投资公司（GIC）就加入这一轮谈判进行了讨论&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367897</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367897</guid>
      <pubDate>Mon, 18 Aug 2025 08:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>庆祝 Debian 「第 100000 岁生日」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Debian 社区通过邮件列表庆祝 Debian 的「第 100000 岁生日」 : D&lt;/p&gt; 
&lt;p&gt;当然这里的「100000」并非真正的十万，而是二进制表示，即「0b100000」，相当于十进制的 32 年，或十六进制的 &lt;code&gt;0x20&lt;/code&gt;。这意味着 Debian 成立已经整 32 年了，而 Debian 的成立日期正好是 &lt;strong&gt;1993-08-16&lt;/strong&gt;。因此，2025-08-16 是 Debian 的 32 周年纪念日。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0822/162849_Baek_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://lists.debian.org/debian-devel-announce/2025/08/msg00006.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在周年纪念之际，Debian 社区特别感谢了为最新版本 &lt;strong&gt;Debian 13 「Trixie」&lt;/strong&gt; 发布付出努力的各个团队，包括负责镜像与软件包的 FTPMaster、统筹发布的 Release 团队、Installer 与镜像制作团队、文档与翻译贡献者，以及修复关键 Bug 的开发者们。文章还提到，代码签名服务的改进为未来安全更新打下了坚实基础。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367896</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367896</guid>
      <pubDate>Mon, 18 Aug 2025 08:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Pulsar 中的消息保留、过期及积压机制解析</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;在 Pulsar broker 中, 消息的 Retention, Expiry 和 Backlog quota 是比较重要的功能，它们表现的是 Pulsar 对于流经它的数据的管理。 但是受限于复杂度和文档语言等因素，开发者可能无法在第一时间很直观的了解它们。&lt;/p&gt; 
&lt;p&gt;本系列上篇为大家介绍了 Retention 和 Expiry 的概念、行为、应用、实现和注意事项&lt;a href="https://my.oschina.net/apachepulsar/blog/18688106"&gt;技术文档 | Pulsar 中的消息保留、过期及积压机制解析（上）&lt;/a&gt;，本文将带来关于 Backlog quota 的解析。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Backlog quota&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 概念&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Backlog 意为消息积压，指未被消费的消息；quota 意为配额，指对于未消费消息的限制。&lt;strong&gt;因此 Backlog quota 是为了限制消息堆积。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当消费者的消费速率跟不上生产者的生产速率时，会出现消息堆积的情况，这在日常开发过程中非常常见。尽管**相比于其他消息队列，Pulsar 提供了几乎可以无限扩容消费者数量的机制 **(Shared, Key_Shared 订阅模式) 来提高消费速率， 但是在实际的业务场景中，消息堆积的情况也时有发生。&lt;/p&gt; 
&lt;p&gt;为了应对这种情况，Pulsar 提供了 Backlog quota 机制来在一定程度治理它。当然，这种治理无法提高消费者的消费速率，只是在生产速率和消费速率之间做出一种平衡，比如说它的一种治理策略是自动清理 Backlog 消息。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-fd21c3936cb8cf9fff04263bc486f32160b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 行为&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Pulsar 在 Topic 级别和 Subscription 级别都有 Backlog 的概念。Topic 级别的 Backlog 是指该 Topic 下所有 Subscription 的 Backlog 总和 (pulsar_msg_backlog 和 pulsar_storage_backlog_size 的含义略有差异，这里使用 pulsar_msg_backlog 的含义)，Subscription 级别的 Backlog 是指当前 Subscription 的 Backlog。&lt;/p&gt; 
&lt;p&gt;Backlog quota 机制实际工作在 Subscription 级别，它和 Expiry 机制略有相似，但更加强大。它对于 Backlog 有两项限制、两种作用域和三种治理策略：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1 两项限制&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;limitTime：Backlog 的最大存活时间，单位是秒，超过这个时间的 Backlog 会进入治理流程；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;limitSize：Backlog 的最大大小，单位是字节，超过这个大小的 Backlog 会进入治理流程；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2.2 两种作用域&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;destination_storage：针对 Topic 的 Backlog 的存储空间，和 limitSize 搭配使用；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;message_age：针对 Topic 的 Backlog 的消息存活时间，和 limitTime 搭配使用；&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2.3 三种治理策略&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;producer_request_hold：当 Backlog 超过限制，Pulsar 会挂起 Producer 的链接请求，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;consumer_backlog_eviction：当 Backlog 超过了限制，Pulsar 会自动移动所有超限的 Subscription 的游标 (相当于自动确认这些消息，使得这些消息对 Consumer 不可见)，将 Backlog 降低到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;producer_exception：当 Backlog 超过了限制，客户端创建 Producer 会抛出异常，直到 Backlog 降到限制以下。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 应用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1 监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 在 Prometheus 上提供了 pulsar_msg_backlog 和 pulsar_storage_backlog_size 来分别观测 Topic 级别的未消费的消息数量、未消费消息的总大小。如果这两个指标数值较高，说明该 Topic 消息积压严重。&lt;/p&gt; &lt;p&gt;另外，Pulsar 也提供了 pulsar_subscription_back_log 这一 Subscription 级别的指标，当我们发现某个 Topic 的 backlog 数值较高时，可以通过查看该 Topic 下的 pulsar_subscription_back_log 指标来找到具体的 Subscription；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;通过 Topic stats 来监控 Backlog quota 的情况：&lt;/p&gt; &lt;p&gt;pulsar-admin topics stats &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;3.2 设置&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;和 Retention 和 Expiry 一样，Backlog quota 的设置也分为两个级别：namespace 和 topic 级别。在 Namespace 级别设置了之后，该 Namespace 的所有 Topic 都会继承该策略；在 Topic 级别设置了之后，该 Topic 会覆盖 Namespace 的设置。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Namespace 级别&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;查看当前 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces get-backlog-quotas my-tenant/my-ns&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;设置 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces set-backlog-quota my-tenant/my-ns --limitTime 3600 --policy producer_request_hold --type message_age&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;删除 Namespace 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin namespaces remove-backlog-quota my-tenant/my-ns&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Topic 级别&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;查看当前 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics get-backlog-quotas &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;设置 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics set-backlog-quota &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt; --limitTime 3600 --policy producer_request_hold --type message_age&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;删除 Topic 的 Backlog quota&lt;/p&gt; &lt;p&gt;pulsar-admin topics remove-backlog-quota &lt;a href="persistent://my-tenant/my-ns/my-topic"&gt;persistent://my-tenant/my-ns/my-topic&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;4. 实现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Backlogquota 机制的触发有两个入口，分别是 ServerCnx#handleProducer(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fblob%2Fv3.0.4%2Fpulsar-broker%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpulsar%2Fbroker%2Fservice%2FServerCnx.java%23L1448" target="_blank"&gt;https://github.com/apache/pulsar/blob/v3.0.4/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java#L1448&lt;/a&gt;) 和 BrokerService#startBacklogQuotaChecker()(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapache%2Fpulsar%2Fblob%2Fv3.0.4%2Fpulsar-broker%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpulsar%2Fbroker%2Fservice%2FBrokerService.java%23L657" target="_blank"&gt;https://github.com/apache/pulsar/blob/v3.0.4/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java#L657&lt;/a&gt;) ,前者和后者略有差距，这里不做详细解释。仅以 BrokerService#startBacklogQuotaChecker() 为例，简单介绍 Backlog quota 的执行流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.1 Backlog Quota Checker 初始化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 Pulsar 启动时， BrokerService#startBacklogQuotaChecker() 会检查当前 Broker 是否允许 Backlog quota 检查（broker.conf 的 backlogQuotaCheckEnabled(default=true)）。如果允许，向线程池注册一个定时任务，定时任务的执行周期是 broker.conf 的 backlogQuotaCheckIntervalInSeconds(default=60s)。Pulsar 每隔 60s 检查一次所有 Topic 的 Backlog quota，如果 Topic 设置了 Backlog quota，执行后续流程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4.2 Backlog Quota 执行流程&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;遍历所有 Topic，如果 Topic 设置了 Backlog quota，执行后续流程。否则，跳过该 Topic；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;优先根据 limitSize 检查该 Topic 消费最慢的 Subscription 的 Backlog 是否超过了限制，如果未超限，再根据 limitTime 检查；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 Backlog 超过了限制，根据 policy 执行相应的治理策略：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;producer_request_hold：挂起 Producer 的链接请求，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;consumer_backlog_eviction：自动移动所有超限的 Subscription 的游标，将 Backlog 降低到限制以下；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;producer_exception：客户端创建 Producer 会抛出异常，直到 Backlog 降到限制以下。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;5. 注意事项&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pulsar 暴露出的 Prometheus 指标中的 pulsar_storage_backlog_size 并不完全精准，它只是一个近似值。在 Shared 和 Key_Shared 模式下，允许消息单独确认消息，但是这些单独确认的消息不会加入到 Backlog 的计算中，因此这个指标并不会精准反映 Backlog 情况，它通常会比实际数值大；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;pulsar_msg_backlog 一般也是近似值，不会将 Ack 空洞计算在内，但是如果将 broker.conf 的 exposePreciseBacklogInPrometheus 设置为 true，则会将单独确认的消息计算在内，pulsar_msg_backlog 会更加精准；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;由于 EntryFilter(&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpulsar.apache.org%2Fdocs%2F3.2.x%2Fdevelop-plugin%2F%23entry-filter" target="_blank"&gt;https://pulsar.apache.org/docs/3.2.x/develop-plugin/#entry-filter&lt;/a&gt;) 机制的存在，在消费消息时可以根据 EntryFilter 过滤掉一些消息，这些被过滤掉的消息严格来说并不算 Backlog，但是我们在计算 Backlog 时，不可能将 Bookkeeper 中的所有消息都拉取出来计算。因此如果 Broker 挂载了 EntryFilter 插件，pulsar_msg_backlog 和 pulsar_storage_backlog_size 以及 pulsar_subscription_back_log 都无法精准反映实际的 Backlog 情况，它们通常会比实际数据大一些；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不管是根据 limitSize 还是 limitTime 来限制 Backlog，当 policy=consumer_backlog_eviction 时，都无法完全精准的清理 Backlog。理想情况下，会将 Backlog 降低到原来的 10%；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果在 Broker 端禁用 Backlog quota checker (将 broker.conf 中 backlogQuotaCheckEnabled 设置为 false)，并且设置的 Backlog quota 的 policy=consumer_backlog_eviction，Pulsar 将不会自动清理 Backlog；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果使用 Backlog quota，然后 Backlog 达到了阈值，并且 policy=producer_request_hold 或 producer_exception ，在 Broker 重启或自动重平衡时，会导致所有的 Producer 无法链接到 Broker，进而无法生产消息，直到 Backlog 降到限制以下；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果使用 limitTime 限制 Backlog，需要注意 Client 和 Broker 的时间同步，否则可能会导致 Backlog 无法正确的清理。因为此时 Backlog 的判断是以 Broker 的时间为基准的；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果该 Topic 设置了 Retention，Backlog quota 必须要小于 Retention。假设 Retention 设置了 10GB，Backlog quota 必须要小于 10GB。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在文章最后，对 Pulsar 的 Retention, Expiry 和 Backlog quota 做一个总结：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Retention 是 Pulsar 对于过期数据的保留和清理策略，它工作在 Topic 级别，通过定时任务清理过期数据，将全部 Subscription 都消费过后的数据从存储介质上删除来清理存储空间；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Expiry 即为 Message TTL，它工作在 Subscription 级别，通过定时任务来检查 Subscription 中超时未消费的消息，并自动的将这些消息确认，使其对消费者不可见；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Backlog quota 是对未被消费的消息的限制，它实际工作在 Subscription 级别，通过定时任务来检查 Subscription 中的 Backlog，如果 Backlog 超过了限制，会执行相应的治理策略，拒绝新的 Producer 链接或者自动确认消息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这三个功能并不冲突，它们可以组合使用，我们可以**通过 Retention 删除过期数据，通过 Expiry 处理超时未消费的数据，通过 Backlog quota 治理消息堆积。**但是由于他们三者都涉及到了对数据的操作，大家在使用时应当谨慎，在使用前根据实际业务仔细评估，避免数据丢失或者数据不一致的情况。&lt;/p&gt; 
&lt;p&gt;社区将持续输出更多 Pulsar 的技术内容；欢迎加入社群讨论或在评论区留言，与我们交流更多关于 Pulsar 的问题。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/apachepulsar/blog/18689158</link>
      <guid isPermaLink="false">https://my.oschina.net/apachepulsar/blog/18689158</guid>
      <pubDate>Mon, 18 Aug 2025 08:24:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AWS CEO 认为「用 AI 全面替代初级员工」是愚蠢的想法</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;亚马逊 AWS 首席执行官 Matt Garman 近日在一次采访中&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DnfocTxMzOP4" target="_blank"&gt;表示&lt;/a&gt;，&lt;strong&gt;用人工智能全面替代初级员工，是「我听过最蠢的想法」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;他强调，初级员工不仅成本低，更是最容易与 AI 工具结合的群体，是企业长期发展的关键力量。如果公司完全依赖 AI，而不培养新人，十年后可能会面临无人具备核心技能的困境。他认为，企业应该继续招聘应届生，教他们如何构建软件、分解问题和采用最佳实践。他说 AI 时代最有价值的技能与大学学位不相关。要保住自己的工作员工必须不停的继续学习更新技能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1498" src="https://static.oschina.net/uploads/space/2025/0822/162212_K8BN_2720166.png" width="2664" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Garman 批评一些企业用「AI 写了多少代码」来衡量价值，称这是一个误导性的指标。在他看来，代码质量远比数量重要。&lt;/p&gt; 
&lt;p&gt;与此同时，AWS 内部已有超过八成的开发人员在使用 AI 工具，涵盖写单元测试、文档和代码等工作，并且使用率还在持续上升。但 Garman 强调，AI 应该作为助手来提升效率，而不是用来取代年轻人才。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367892</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367892</guid>
      <pubDate>Mon, 18 Aug 2025 08:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>达梦数据三天两度发布公告：公司两位董事先后被立案调查</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;8 月 21 日晚，达梦数据再发布公告称，公司于近日收到湖北省应城市监察委员会下发的《立案通知书》和《管护通知书》，对公司董事兼高级副总经理陈文立案调查并实施管护措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前公司及子公司日常经营情况正常，各项业务稳步推进。公司尚未知悉上述事项的进展及结论，将密切关注后续进展并及时履行信息披露义务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img alt="" height="284" src="https://oscimg.oschina.net/oscnet/up-c40855a0dc2577d4d1cd7a522484e3a3c78.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司 2024 年报显示，陈文，女，1973 年 7 月出生，本科学历，高级经济师。1997 年 7 月专科毕业于湖北省高等商业专科学校财务会计专业，2004 年 7 月本科毕业于华中农业大学法律专业。2002 年 1 月至 2020 年 11 月，在达梦有限历任销售经理、华东区域市场总监、副总经理、高级副总经理；2020 年 11 月至今，在达梦数据担任董事、高级副总经理；2021 年 3 月至今，在北京达梦担任总经理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;公司 2024 年报显示，陈文 2024 年从公司领取税前薪酬为 304.41 万元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;8 月 19 日，达梦数据也曾发布公告表示，公司董事兼总经理皮宇被立案调查并实施留置措施。&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;达梦数据成立于 2000 年，是国内数据库产品开发服务商，主要提供各类数据库软件及集群软件、云计算与大数据等一系列数据库产品及相关技术服务。其客户包括建设银行、中国人保、国家电网、中国航信、中国移动、中国烟草等企业，产品应用于党政、金融、能源、航空、通信等数十个领域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;该公司于 2024 年 6 月 12 日在上海证券交易所科创板上市，成为「国产数据库第一股」。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从 6 月披露的半年报预告来看，达梦数据预计 2025 年上半年实现营业收入 4.95 亿～5.13 亿元，较去年同期增长 40.63%～45.74%。2025 年一季度，达梦数据实现收入 2.58 亿元，归母净利润 9816 万元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/367239" target="news"&gt;达梦数据：公司董事兼总经理被留置&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367891</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367891</guid>
      <pubDate>Mon, 18 Aug 2025 08:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Vercel 宣布旗下 AI Gateway 服务正式 GA</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Vercel&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fai-gateway-is-now-generally-available"&gt;宣布&lt;/a&gt;&amp;nbsp;AI Gateway 已正式 GA，它建立在 Vercel 为数百万用户提供支持的 v0.app 系统之上，经过实战验证，具有高度稳定性和可靠性。&lt;/p&gt; 
&lt;p&gt;该服务支持数百种模型，通过统一 API 调用，无需单独管理各厂商 API 密钥、账户或配额，提供零加价（含自带密钥 BYOK）、高并发、自动故障转移、亚 20 毫秒延迟，并兼容 OpenAI 格式及 AI SDK 5。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;import { streamText } from 'ai'

const result = streamText({
  model: 'xai/grok-4', // defaults to Vercel AI Gateway
  prompt: 'How does Vercel AI Gateway have no markup on tokens?'
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;据介绍，以下开发者和团队使用 AI Gateway：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要&lt;strong&gt;动态评估或切换模型&lt;/strong&gt;的使用场景&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;追求&lt;strong&gt;高调用上限&lt;/strong&gt;、&lt;strong&gt;避免 rate-limit&amp;nbsp;&lt;/strong&gt;阻碍服务&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;希望&lt;strong&gt;第一时间访问新模型&lt;/strong&gt;的应用&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对&lt;strong&gt;高可用性&lt;/strong&gt;有强要求、不能容忍单点故障&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;希望&lt;strong&gt;集中查看使用成本与监控数据&lt;/strong&gt;，简化资源管理流程&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Vercel 称该服务已在 v0.app 等产品中承载数百万用户，现可供所有团队正式使用。开发者只需修改模型字符串即可秒级切换供应商，并可实时查看用量与成本，避免锁定单一模型或平台。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://vercel.com/ai-gateway/models&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367885</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367885</guid>
      <pubDate>Mon, 18 Aug 2025 08:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>WPS Office for Windows 上线 64 位新版本：更快更流畅</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;WPS Office 在官网上线 Windows 系统 64 位新版本，取消 Beta 字样，升级为正式版。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f9186f413660b14e6218f734654db06ee32.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;测试结果显示，相对 Windows 系统的 32 位版本，其文字组件的绘制速度提高 10.82%，表格组件的计算速度提高 12.82%，演示组件的新建速度提高 10.35%，PDF 组件的翻页速度提高 27.13%。&lt;/p&gt; 
&lt;p&gt;如果 Windows 电脑 CPU 是 X64 架构，且内存（RAM）大于 4GB，将 WPS 更新为 64 位版本，将更好地利用硬件能力发挥软件的性能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367881</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367881</guid>
      <pubDate>Mon, 18 Aug 2025 08:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 为 Responses API 发布两项更新</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 为其 Responses API&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAIDevs%2Fstatus%2F1958660214057791853" target="_blank"&gt;推出&lt;/a&gt;了 Connectors 和 Conversations 两项新功能，分别用于简化外部服务数据拉取和提供原生对话记录持久化能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e6b4c8a74c627e8d55f7864cb74b221bb67.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-796585c8fc755074c5d9b4261c49e0990bc.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Connectors 允许开发者通过一次 API 调用，从 Gmail、Google Calendar、Google Drive、Dropbox、Teams、Outlook Calendar+Email、SharePoint 等外部服务拉取邮件、日程、文件及聊天记录，并可直接用于 deep research 场景。&lt;/p&gt; 
&lt;p&gt;Conversations 则提供原生对话记录持久化能力，无需自建数据库即可为用户保存聊天线程。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/news/351200" target="_blank"&gt;Responses API &lt;/a&gt;是 OpenAI 的状态化 API，支持包括网络搜索、文件搜索和计算机使用在内的多种新工具，为开发者提供更简洁、灵活的方式与 OpenAI 模型交互。&lt;/p&gt; 
&lt;p&gt;文档：&lt;em&gt;https://platform.openai.com/docs/guides/tools-connectors-mcp&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367878</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367878</guid>
      <pubDate>Mon, 18 Aug 2025 07:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌以 47 美分价格向美政府提供 AI 服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;谷歌周四宣布将推出 Gemini 政府版（Gemini for Government），并通过与美国总务管理局的新协议，以每年不到 50 美分的价格向美国联邦政府提供该模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这也是继 OpenAI 和 Anthropic 后，最新一家以极低价格向美国政府供应人工智能模型的公司。此前，OpenAI 和 Anthropic 均宣布以 1 美元的年费向美国联邦机构供应其旗下模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="263" src="https://oscimg.oschina.net/oscnet/up-ca46f0d381dd2bba05fa817d976c1daacc1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与 OpenAI 和 Anthropic 不同的是，谷歌已经在美国政府云业务中深度参与，这也为 Gemini 的后续部署提供了更大的便利。据悉，Gemini 政府版仅限于谷歌云平台使用，幷包含对 Notebook LM AI 的访问权限，其为一款用于研究和笔记的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;谷歌母公司 Alphabet 首席执行官 Sundar Pichai 在一份声明中表示，很荣幸能与美国总务管理局合作，推出 Gemini 政府版。在 Workspace 服务的基础上，Gemini 政府版将提供全栈式的人工智能创新方案，包括由最新模型支持，并基于安全云基础设施的 NotebookLM 和 Veo 等工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;美国总务管理局则称，Gemini 政府版的定价为每个机构每年 47 美分，该优惠将持续至 2026 年。谷歌称，这是在此前报价基础上再提供了 71% 的折扣。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;span style="color:#000000"&gt;先试用，后买单&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，谷歌和美国政府都未提及 Gemini 政府版在一年后的正式定价。但与谷歌共同参与政府项目的 OpenAI 曾表示，一年后，美国各政府机构要么在试用期结束访问，要么签订新的 ChatGPT Enterprise 付费协议。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息人士透露，目前各家 AI 公司的低价似乎是为了加速政府采用人工智能，并推动官员快速做出决定的一种策略。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这一定价显然也难以持续，尤其是考虑到运行人工智能的数据中心算力成本不断高涨，1 美元甚至更低的年费价格更像是「为爱发电」。各家公司可能希望在一年期的试用之后，能够在政府订单中夺得更大的份额以收回利润。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;联邦采购服务局局长 Josh Gruenbaum 表示，这是美国政府过去几个月在 OneGov 项目上推出的战略的新发展。但谷歌与美国总务管理局过去几个月部署模型的不同点在于，谷歌响应了众多不同政策的要求，并整合了众多不同的举措。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;谷歌公共部门首席执行官 Karen Dahut 则强调，谷歌与其他任何服务真正不同之处在于：为联邦工作人员提供了一个完全集成的人工智能就绪平台。它既符合 FedRAMP 高标准的安全性，并且包含 Gemini 及其所有辅助功能。（财联社，马兰）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/364855/openai-chatgpt-usa-government-for-free" target="news"&gt;&lt;span style="color:#2980b9"&gt;OpenAI 以 1 美元价格向美国政府提供 ChatGPT&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/365914" target="news"&gt;&lt;span style="color:#2980b9"&gt;Anthropic 以 1 美元为美国政府提供 AI 服务&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367877</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367877</guid>
      <pubDate>Mon, 18 Aug 2025 07:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>可灵 AI 正式发布基于 2.1 模型的全新首尾帧功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="background-color:#ffffff; color:rgba(0, 0, 0, 0.9)"&gt;可灵 AI 今天正式向所有用户推出基于 2.1 模型的「首尾帧」功能，&lt;/span&gt;其效果较 1.6 模型提升 235%，进一步提升了 AI 视频生成的可控性，广泛适用于广告营销、影视、短剧、动画等创意制作场景。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-da2cd9ac596c0499b86067d7d90184057a7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;首尾帧功能的核心价值在于它赋予了创作者前所未有的视频控制能力。传统的 AI 视频生成往往像是一场技术赌博，用户输入文字描述后，只能被动等待系统生成结果，无法对视频的具体走向进行精准把控。而可灵 AI 的首尾帧技术彻底打破了这种被动局面，创作者现在可以明确指定视频的起始画面和结束画面，让 AI 在这两个关键节点之间生成流畅自然的过渡内容。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e58d24c67ee168ae526cba8899c5207bab2.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这种精准控制能力的实现并非简单的技术拼接，而是基于深度学习算法对视频时空连续性的深刻理解。2.1 模型通过分析海量的视频数据，学会了如何在给定的首尾约束条件下，生成既符合物理规律又富有创意表现力的中间帧序列。每一帧画面的生成都要考虑到与前后帧的连贯性，确保整个视频呈现出丝滑流畅的视觉效果。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367876</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367876</guid>
      <pubDate>Mon, 18 Aug 2025 07:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯元宝接入 DeepSeek V3.1 最新版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯元宝&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FPjqXA_EotWwX5te9_ppwIg" target="_blank"&gt;宣布&lt;/a&gt;已正式接入 DeepSeek V3.1 最新版。相比上一代，DeepSeek V3.1-Think 能在更短的时间内给出答案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0822/154414_rCOP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方称此次模型更新，带来两大突破：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;思考更快，灵感秒现：相比上一代，DeepSeek V3.1-Think 能在更短的时间内给出答案，助你更快一步抓住灵感，高效完成工作。&lt;/li&gt; 
 &lt;li&gt;更强的 Agent 能力：新模型大幅提升了工具使用和智能体能力，帮你轻松搞定复杂任务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="1749" src="https://static.oschina.net/uploads/space/2025/0822/154526_K89t_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;体验：&lt;em&gt;https://yuanbao.tencent.com/download&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367871</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367871</guid>
      <pubDate>Mon, 18 Aug 2025 07:45:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AMD FSR 开源项目暗示了对旧款 GPU 的潜在支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AMD 最近发布了 FidelityFX Super Resolution SDK 2.0，以配合向基于机器学习的 FSR 4 的转变，但奇怪的是，该公司似乎还意外地通过其 AMD GPUOpen 项目将库开源到 FSR 4，让精通技术的浏览器可以一窥 FSR 4 的内部工作原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-173169245625002af1951211817b3c39b54.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这些文件后来从 AMD 的 GPUOpen 库中删除，但有人迅速抓取了文件目录的屏幕截图，从中可以看出足够的信息。最大的亮点之一是包含 8 位整数 (INT8) 库，这些库使用的资源更少，但精度也低于 RDNA 4 中使用的库，这表明 AMD 有或可能有打算为 RX 7000 GPU 发布 FSR 4。&lt;/p&gt; 
&lt;p&gt;FSR 4 最初宣布为 AMD 的 Radeon RX 9000 系列 GPU 独有，但这种情况可能不会持续太久。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-68f4c2091693f71d72cb93c5f04eab923a1.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前曾有迹象表明 AMD FSR 4 可能会支持较旧的 RDNA 硬件，甚至有一些 mod&amp;nbsp;项目成功地使其在较旧的硬件上运行，但这是一个重要的官方信号，表明 AMD 可能正在努力将其移植到较旧的硬件上。&lt;/p&gt; 
&lt;p&gt;也有人猜测 INT8 库可能是为 PlayStation 5 Pro 设计的，但文件类型似乎表明并非如此——PS5 使用 .PSSL 格式，而这些着色器被打包为 .HLSL 格式，表明它们是为 PC 设计的。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367865</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367865</guid>
      <pubDate>Mon, 18 Aug 2025 07:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美团智能头盔研发实践系列 02：软件功能篇</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;本文系《美团智能头盔研发实践系列》的第二篇文章，围绕智能头盔如何通过主动安全和被动安全相结合的方式有效保护骑手，主要包括智能头盔骑行通话质量强化、智能语音助手、碰撞摔倒监控等三项软件能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-b82e78f56c21d3c578ed700c4b6b0f0513e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;引言&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美团智能头盔作为专为外卖骑手打造的智能安全装备，具备蓝牙通话、戴盔识别、智能语音助手、碰撞摔倒监控等功能，核心软件功能围绕如何通过主动安全和被动安全相结合的方式有效保护骑手。&lt;/p&gt; 
&lt;p&gt;本期分享主要介绍智能头盔骑行通话质量、智能语音助手、碰撞摔倒监控三项软件能力。其中"骑行通话质量和智能语音助手"降低骑手操作手机导致的"分心"，帮助骑手"防患于未然"。"碰撞摔倒监控"最大限度的保护骑手、快速的感知事故和触发救治。&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;安全风险与体系&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;2.1 安全挑战&lt;/h3&gt; 
&lt;p&gt;外卖骑手面临着独特的安全挑战，他们的工作性质，如午晚高峰短时集中的压力和交通复杂环境，显著增加了事故风险。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事故和违规行为&lt;/strong&gt;：研究表明，工作压力与骑手的分心驾驶和危险驾驶行为之间存在关联，这些行为往往导致交通事故的发生。例如，为了赶时间，骑手可能会超速、闯红灯或逆行。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;车辆类型&lt;/strong&gt;：许多外卖骑手使用摩托车或电动自行车，这些车辆本身就具有不稳定性，且缺乏足够的安全保护措施 。尤其是在亚洲，摩托车因其效率而成为首选，但也导致了交通安全事故的增加。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;工作环境&lt;/strong&gt;：外卖骑手有时需要在恶劣的天气条件下工作，这进一步增加了他们的道路安全风险。此外，长时间工作和不规律的休息也可能导致疲劳驾驶，影响骑手的反应能力和判断力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;行为因素&lt;/strong&gt;：骑手的安全态度和风险认知对其驾驶行为有重要影响。研究发现，安全知识的缺乏与骑手的不良驾驶行为有关。此外，工作场所的安全氛围也会影响骑手的安全合规行为。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.2 安全体系&lt;/h3&gt; 
&lt;p&gt;骑手安全防护可以分为&lt;strong&gt;主动安全&lt;/strong&gt; 和&lt;strong&gt;被动安全&lt;/strong&gt;两个方面，它们共同构成了骑行安全的完整体系。&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;主动安全是指在骑行过程中，通过技术手段和行为规范来预防事故的发生&lt;/strong&gt;。例如，骑手应遵守交通规则，如不闯红灯、不超速、不随意变道等，这些行为有助于减少因人为失误导致的事故。此外，现代两轮车也配备了多种主动安全技术，如 ABS（防抱死制动系统）、TCS（牵引力控制系统）等，这些系统通过传感器实时监测车轮状态，确保在紧急制动或加速时车辆仍能保持稳定。例如，业界某电动车企业在其两轮车上应用了 AI 视觉辅助系统，结合姿态感应系统，能够识别车辆倾倒、非正常移动等危险情况，从而提前预警。这些技术的引入，大大提升了骑行的安全性。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;被动安全则是在事故发生时，通过防护装备、传感装备，最大限度地减少伤害、及时触发救治&lt;/strong&gt;。例如，头盔是骑行者最重要的被动安全装备之一，它能够有效保护头部免受撞击，降低颅脑损伤的风险。此外，骑行手套、护膝、护肘等防护装备也能在摔倒时减少擦伤和扭伤。在车辆设计方面，一些高端两轮车也尝试引入类似汽车的被动安全设计，如带式座椅，以在碰撞时保护骑手。然而，由于两轮车的结构限制，其被动安全系统仍处于发展阶段，尚未达到与汽车同等水平。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主动安全&lt;/strong&gt; 和&lt;strong&gt;被动安全&lt;/strong&gt;并非孤立存在，而是相辅相成。骑手在日常骑行中应注重主动安全意识的培养，如佩戴护具、遵守交通规则、保持车距等，同时也要关注车辆的安全配置，合理利用主动安全技术，以降低事故发生的风险。只有在主动预防的基础上，被动安全措施才能发挥最大作用，为骑手提供全方位的保护。&lt;/p&gt; 
&lt;p&gt;随着科技的发展，越来越多的智能化技术被应用于外卖配送领域，这些技术不仅提升了骑行的安全性，也为未来两轮车的安全发展提供了更多可能性。&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;智能头盔安全能力&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h3&gt;3.1 主动安全篇&lt;/h3&gt; 
&lt;p&gt;1）&lt;strong&gt;第一个主动安全能力------摩托骑行 60km/h 速度下双向听得清&lt;/strong&gt;。骑行中操作手机进行通话和应用交互是导致骑手分心驾驶的主要原因，占比极高。配送骑手载具涵盖电动车与摩托车，虽然前者一般工况下均速不超过 15km/h，但后者属于机动车，在部分不禁摩的城市，极端情况下，时速可达 60km/h，对智能头盔降噪性能提出极限挑战。智能头盔作为长时佩戴装备，舒适性至关重要，开放式蓝牙耳机设计面临技术瓶颈：低频泄漏导致音质劣化、私密性差、环境噪声干扰严重以及高速风噪与回声对通话质量的毁灭性冲击。&lt;/p&gt; 
&lt;p&gt;智能硬件团队连续攻关物理降噪技术、波束成型技术、AGC 和 AEC 算法技术，有效攻克了 60km/h 时速下降噪问题。物理降噪技术，采用气动学优化的头盔结构，结合轻量化抗冲击材料，从源头抑制风噪。波束成型（Beamforming）技术，通过调整两个麦克风的摆放位置和灵敏度，形成一个"拾音束"，保留目标方向的声音（人声），同时屏蔽其他方向的噪声。AGC 自动增益控制算法、AEC 回声消除算法，60km/h 时速下精准分离人声与噪声。&lt;/p&gt; 
&lt;p&gt;依托仿真人头系统、精密麦克风阵列及人工嘴等专业设备进行声学验证，在严格模拟的 60km/h 骑行噪声、复杂社会生活及工地噪声背景下，智能头盔成功实现了对哈曼曲线目标的稳定达成------在时速 60km 的严苛环境下确保通话清晰度与私密性，显著减少骑手因操作手机导致的分心风险。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//806159b1f94c20e1c8fedb5787b46fec.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;第二个主动安全能力------智能语音助手降低手机操作繁琐性&lt;/strong&gt;。除了通话，骑手骑行过程中存在大量手机交互需求，如接单/查看订单、回复消息、导航设置等。传统界面操作方式在骑行场景下存在重大安全隐患，根据数据统计骑手骑行时大概 90% 以上的操作都是与配送行为强相关。&lt;/p&gt; 
&lt;p&gt;安全需求和数据调研表明，语音交互是骑手在骑行或处理订单时更安全的交互方式，解放双手和双眼。伴随着 AI 大模型在意图理解、内容生成和泛化方面能力提升，通过 AI 助手 + 智能头盔结合，提升骑手 Hands-Off 能力、降低安全风险成为可能。&lt;/p&gt; 
&lt;p&gt;智能头盔内置语音关键词识别算法，"小灵小灵"一键唤醒智能助手。通过蓝牙与骑手手机连接，通过语音交互随时随地召唤 AI 能力助力接单决策、订单配送、违规申诉、IM 沟通。"小灵小灵"，一句轻唤唤醒智能头盔连接履约垂域大模型。这不仅是语音助手，更是骑手的"云端搭档"。智能头盔连接履约垂域大模型，成为骑手 AI 能力的入口。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;决策赋能&lt;/strong&gt;：实时分析周边订单热力（如"现代城订单密集"），结合骑手位置智能规划路径，提升接单效率；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;情感交互&lt;/strong&gt;：识别"订单太少"的焦虑情绪，提供解决方案，替代手机操作降低骑行风险；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无缝协同&lt;/strong&gt;：通过 IM 沟通模块自动生成话术模板，申诉违规订单时化身"数字律师"，守护骑手权益。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"小灵小灵，一会儿路上帮我接顺路的订单"。 "已帮你找到顺路订单"。 "小灵小灵，最近订单太少怎么办"。 "距您 4 公里的现代城目前订单较多，建议前往"。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//3a9273f44b2e5fe277a21a09294f4d3e.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;3.2 被动安全篇&lt;/h3&gt; 
&lt;p&gt;1）&lt;strong&gt;第一个被动安全能力------可靠的、苛刻的物理防护能力&lt;/strong&gt;。智能头盔设计需要满足国家强制标准，行业上，电动车头盔设计满足电动自行车乘员头盔标准就足够了（GB 811-2022 B3 电动自行车乘员头盔国家标准）。但从骑手安全角度出发，我们主动将设计标准提升至摩托车头盔级别（GB 811-2022 A3 摩托车乘员头盔国家标准）。世界衞生组织（WHO）数据显示，佩戴头盔能显著降低摩托车事故伤亡率，可减少近 40% 的死亡风险、超 70% 的严重受伤概率。美团智能头盔从基础防护层面，为骑手安全筑牢根基：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;保护头部免受冲击&lt;/strong&gt;：智能头盔是外卖骑手最重要的安全装备之一，它能够有效吸收碰撞时产生的冲击力，防止头部受到严重伤害。在交通事故中，头部是最脆弱的部位，一旦与坚硬的路面或电线杆、行道树发生碰撞，后果不堪设想。头盔可以起到缓冲、减震的作用，从而降低受伤比例和死亡率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;提高可见性&lt;/strong&gt;：虽然头盔本身并不直接提高可见性，但其设计通常包括透气孔和通风系统，有助于骑手在骑行过程中保持头部的干爽和舒适。此外，头盔的反光背心等配件可以在夜间或光线不足的环境中提高骑手的可见性，减少交通事故的发生。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;增强舒适性和实用性&lt;/strong&gt;：头盔的设计不仅注重安全性能，还兼顾了舒适性和实用性。例如，头盔内部设有缓冲层，可以吸收外力冲击，同时头盔内置的风道和前后换气口可以保持头部的通风和干燥。此外，一些高端头盔还配备了护目镜，可以有效阻挡灰尘和雨水，确保骑手的视野清晰。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//52a55281195d7fd7c24a9a787b1b6c73.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;第二个被动安全能力------意外摔倒监护功能&lt;/strong&gt;。交通事故是造成骑手和三者人身伤亡、财产损失的重要原因之一。当骑手不幸出现交通事故时，智能头盔不仅在物理上保护骑手，还可以通过传感器和相关算法识别事故的发生，同时联动前端和后台，实现：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;平台报警与人工介入&lt;/strong&gt;。AI 外呼骑手确认事故，大象消息推送商管安全员。&lt;/li&gt; 
 &lt;li&gt;快速呼叫救援。支持一键拨打 120。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;信息收集&lt;/strong&gt;。时间地点、事故前速度、传感器数据、现场音视频等。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;骑手关怀&lt;/strong&gt;。事故后第一时间 App 弹窗、AI 外呼，搭建骑手和平台之间的沟通桥梁，让骑手感知到平台时刻关注骑手安全。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;同时，有助于事故后信息分析、处理和事故预防，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;事故还原&lt;/strong&gt;。通过事故采集信息可最大程度还原事故经过。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;保险协助&lt;/strong&gt;。通过精确的事故时间、地点等信息，有助于骑手与保险公司之间事故理赔。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高风险路段提前预警&lt;/strong&gt;。多名骑手发生事故路段/地点，标记为高风险位置，为其他路过骑手提前预警。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//33bcfd231f97e70b12a81515a67fb2ca.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;当骑手发生事故后，端、边、云各个组件协同工作，完成整个碰撞摔倒监控功能，包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;头盔借助于内置的加速度传感器和自研运动特征识别算法，识别到骑手疑似出现碰撞，并将疑似事故信息上报手机 App。&lt;/li&gt; 
 &lt;li&gt;骑手 App 进一步融合了手机中多种特征和传感器原始数据，确认是否为真实事故。&lt;/li&gt; 
 &lt;li&gt;骑手 App（在骑手授权的情况下）将会录制一段时间的事故现场音视频，留存现场音视频信息。&lt;/li&gt; 
 &lt;li&gt;与此同时，骑手 App 将弹出反馈页面等待骑手反馈，若骑手选择自己可以解决或者没摔倒，则表示此事件为小事故或误报，不再后续处理。&lt;/li&gt; 
 &lt;li&gt;若骑手一键拨打 120 或长时间未得到反馈，则表示此事件可能为严重事故，云端将会执行 AI 外呼骑手，进一步确认事故。&lt;/li&gt; 
 &lt;li&gt;若确认为严重事故，或骑手长时间未接听，则此事故信息将会被自动推送站长和安全员，人工介入。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//25130d8086f0d95a2d1fd24b2a56b9d0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除了事故实时处理的相关功能外，碰撞摔倒监控收到的数据，有助于事故进一步分析，包括：速度、特征、位置、传感器参数分析等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//52251664c5a7014a962ad4326d245896.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;碰撞摔倒监控功能使用端、边、云协同处理框架。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;端&lt;/strong&gt;：智能头盔通过分析骑手头盔运动特征，提供碰撞/摔倒原始实时感知；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;边&lt;/strong&gt;：手机提供速度、IOD、姿态等高密度、高实时性关键信息并支撑融合算法的执行，对疑似事故进一步筛选判断，同时使用 App 弹窗与骑手确认事故，并在事故后自动录制音视频；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;云&lt;/strong&gt;：云服务器提供数据记录、AI 站长助理、大象消息推送、事故音视频 AI 解析等能力，进一步确认事故，并为人工介入提供服务帮助。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;端、边、云协同处理，有效提升了感知系统的准确性和实时性。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//553e3e97c8ce5aff7ed4aba211ce6ef4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;总结和展望&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;美团智能头盔作为骑手配送的核心生产工具，已在实际应用中取得显著成效。通过语音交互技术替代传统手机操作，优化了骑手在配送过程中的多任务处理难题，大幅降低了分心驾驶带来的安全隐患。实际数据显示，使用智能头盔的骑手在配送效率和安全指标上均有明显提升。一线骑手反馈表明，这一工具已成为日常工作不可或缺的装备，特别在高峰时段和复杂路况下价值更为突出。&lt;/p&gt; 
&lt;p&gt;2025 年，美团将会研发下一代智能头盔。新型号将不再仅是一个交互工具，而是美团自研多模态大模型的重要入口和数据采集平台。硬件本身将会提供更全面的环境感知能力，不仅提升配送效率和安全性，这将为整个即时配送行业带来一场技术革新。&lt;/p&gt; 
&lt;p&gt;| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024 年货】、【2023 年货】、【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//cfa84bd9f6d0ac9aacadd6874b5b035b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明"内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申请授权。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18688334</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18688334</guid>
      <pubDate>Mon, 18 Aug 2025 07:32:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>OpenAI Codex CLI 发布 v0.23.0，新增模型选择功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 为旗下命令行工具 Codex CLI 发布了 v0.23.0 新版本，新增了在命令行中动态切换模型的功能，当前可选版本包括 gpt-5 high。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Codex CLI 是一个轻量级的 AI 编程助手，采用 TypeScript 和 Node.js 编写，可以直接在用户的终端命令行运行，旨在充分发挥 AI 模型强大的推理能力，连接本地代码环境，甚至支持处理截图或草图进行多模态编程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;用户需通过 npm 全局升级至最新版本：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install -g @openai/codex&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;随后在交互界面执行 /model 即可列出并选择所需模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-083a314bd4eca0b83c7bd1c92b29b26d6b8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;下载地址：&lt;em&gt;https://github.com/openai/codex/releases/tag/rust-v0.23.0&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/367862</link>
      <guid isPermaLink="false">https://www.oschina.net/news/367862</guid>
      <pubDate>Mon, 18 Aug 2025 07:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
