<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 21 Sep 2025 16:43:45 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Gitee 软件工厂的构件之道：CBB 与内源库（代码库\制品库）的本质差异</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在当今企业软件工程体系中，代码库、制品库早已是不可或缺的基础设施。它们承担着源代码存储与构建产物管理的任务，是现代研发团队运转的「发动机」。&lt;/p&gt; 
&lt;p&gt;然而，随着业务日益复杂、组件复用诉求愈发强烈，仅靠资源级的管理已难以满足企业对构件复用、安全审计、版本治理等更高层级的要求。&lt;/p&gt; 
&lt;p&gt;这，正是 CBB（可复用构件，Component Building Block）登场的时代背景。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;三者的核心定位&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200548_HqCr_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通俗来说，代码库和制品库像「原材料仓」和「成品仓」，而 CBB 是将这些资源打包成规范产品、实现复用价值的「商品上架体系」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;CBB：让构件真正「可复用、可治理、可控」&lt;/h2&gt; 
&lt;p&gt;CBB 不只是资源的集合体，它是一种&lt;strong&gt;构件级的管理机制&lt;/strong&gt;。一个 CBB 构件，往往由一个或多个代码库、制品路径组成，并通过&lt;strong&gt;事项管理、审批流程、权限治理、版本规范&lt;/strong&gt;等手段，实现「构件资产」的全生命周期管理。&lt;/p&gt; 
&lt;p&gt;举个例子：&lt;/p&gt; 
&lt;p&gt;企业要建设统一认证服务，过去可能只是创建一个代码库 sso-auth.git，一个构建路径 com/org/sso-auth。但上线、复用、授权、版本记录全靠人工维护，缺乏闭环。&lt;/p&gt; 
&lt;p&gt;引入 CBB 后，将「统一认证服务」定义为一个 CBB 构件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;绑定对应代码库与制品路径；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;明确生命周期流程：形成、验证、审查、入库、使用、变更、退库；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有下游使用方需「申请授权」；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;所有变更均需走审批，并自动留痕；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;权限自动收敛，实现从开发到集成的「规范复用」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;内源资源 ≠ 构件资产&lt;/h2&gt; 
&lt;p&gt;很多企业常犯一个误区：&lt;strong&gt;以为建了代码库、上传了制品，就是构件复用&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;但实际上：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;代码库/制品库关注「资源存储」，缺乏结构化治理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;构件复用需要「抽象+约束」，否则复用即混乱。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;没有构件视角的资源管理，无法解决以下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;构件是否评审通过？是否授权复用？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;构件变更是否通知了下游？有无留痕审计？&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;构件是否符合企业通用规范（命名、标签、权限、版本）？&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些，正是 CBB 要解决的本质问题。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;平台化背后的价值跃升&lt;/h2&gt; 
&lt;p&gt;通过构建 CBB 管理机制，企业得以从「资源导向」跃升到「资产导向」，形成真正可复用、可度量、可审计的软件资产体系。&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/200621_FSn1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;总结：构建真正可控的软件工厂，从「CBB」开始&lt;/h2&gt; 
&lt;p&gt;CBB 不是对代码库和制品库的重复造轮子，而是站在&lt;strong&gt;治理高度的再抽象&lt;/strong&gt;。它连接了业务架构师、平台管理者、开发人员，让可复用构件从「资源」上升为「资产」，是实现企业 DevSecOps、平台化工程和软件工厂愿景的关键基石。&lt;/p&gt; 
&lt;p&gt;如果说代码库与制品库是开发与交付的「发动机」，那么 CBB 就是让发动机高效运转的「操作系统」。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Gitee DevSecOps 的现代化研发生态&lt;/h2&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;Gitee DevSecOps 是一站式国产化研发与交付平台，集成了代码托管（Code）、项目协作（Team）、持续集成（CI）、持续部署（CD）、代码安全（Scan）、数据洞察（Insight）等多项能力，致力于打造具备全生命周期管控能力的现代软件工厂。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0523/174619_MpFL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;平台设计充分考虑关键领域行业对安全性、可控性、合规性的极高要求，具备以下核心特征：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;国产化适配与私有化部署能力：全面兼容国产操作系统与基础设施，支持灵活部署于内网环境，保障数据主权；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;全流程 DevSecOps 管控体系：代码从提交、审核、构建、扫描、部署到发布全流程可视、可追溯、安全可控；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;模块化产品结构：各能力模块（如 Code、Team、Repo、Pipe、Scan、Insight 等）可灵活组合、渐进集成，适配多样化团队与流程要求；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;深度可观测与度量体系：内置研发效能度量与数据洞察引擎，支撑管理者宏观掌控项目态势与交付健康度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="162046_MD15_2720166.png" src="https://static.oschina.net/uploads/space/2025/0516/162046_MD15_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;在多个国家级重大项目与关键领域单位落地实践中，Gitee DevSecOps 已成为构建「自主、可控、高效、安全」的软件工程体系的重要基石。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-825957ffbed1798ea7b6a37079fd6c99d18.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373258</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373258</guid>
      <pubDate>Fri, 19 Sep 2025 12:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软 Windows 11 记事本新增本地 AI 模型支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.windows.com%2Fwindows-insider%2F2025%2F09%2F17%2Fpaint-snipping-tool-and-notepad-app-updates-begin-rolling-out-to-windows-insiders%2F" target="_blank"&gt;宣布 &lt;/a&gt;Windows 11 记事本将新增本地 AI 模型支持。用户无需连接互联网，即可在记事本中完成文本生成、重写与摘要。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-34aeef4d94e566b32a028e6af206d15e640.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此前版本的 Windows 11 记事本虽已支持生成式 AI，但依赖云端计算能力，且需订阅 Microsoft 365 才能使用。未来版本将基于 Windows 11 AI+ PC 内置的神经处理单元（NPU），在本地完成 AI 文本任务。用户可自由切换本地与云端模式，订阅用户可按需选择，而非订阅用户也能直接使用本地模式。&lt;/p&gt; 
&lt;p&gt;微软强调，本地模式不仅带来更高的灵活性，也进一步提升了用户隐私保障。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373254</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373254</guid>
      <pubDate>Fri, 19 Sep 2025 11:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ApeRAG - 生产就绪的 GraphRAG</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是一个可立即投入生产的 RAG（检索增强生成）平台，它将图谱 RAG、向量搜索和全文搜索与先进的 AI 代理相结合。借助混合检索、多模态文档处理、智能代理和企业级管理功能，构建复杂的 AI 应用程序。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ApeRAG 是构建你自己的知识图谱、上下文工程以及部署能够在你的知识库中自主搜索和推理的智能 AI 代理的最佳选择。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div style="text-align:start"&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;主要特点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;1. 高级索引类型&lt;/strong&gt;：五种全面的索引类型，实现最佳检索：&lt;strong&gt;向量&lt;/strong&gt;、&lt;strong&gt;全文&lt;/strong&gt;、&lt;strong&gt;图形&lt;/strong&gt;、&lt;strong&gt;摘要&lt;/strong&gt;和&lt;strong&gt;视觉&lt;/strong&gt;- 提供多维文档理解和搜索功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;2.智能 AI 代理&lt;/strong&gt;：内置 AI 代理，支持 MCP（模型上下文协议）工具，可自动识别相关集合，智能搜索内容，并提供网页搜索功能，实现全面的问答。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;3. 具有实体规范化的增强型图形 RAG&lt;/strong&gt;：深度修改的 LightRAG 实现，具有高级实体规范化（实体合并），以获得更清晰的知识图谱和更好的关系理解。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;4. 多模式处理和视觉支持&lt;/strong&gt;：完整的多模式文档处理，包括图像、图表和视觉内容分析的视觉功能以及传统文本处理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;5. 混合检索引擎&lt;/strong&gt;：结合图形 RAG、向量搜索、全文搜索、基于摘要的检索和基于视觉的搜索的复杂检索系统，可全面理解文档。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;6. MinerU 集成&lt;/strong&gt;：由 MinerU 技术提供支持的高级文档解析服务，通过可选的 GPU 加速为复杂文档、表格、公式和科学内容提供卓越的解析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;7.生产级部署&lt;/strong&gt;：通过 Helm 图表和 KubeBlocks 集成完全支持 Kubernetes，以简化生产级数据库（PostgreSQL、Redis、Qdrant、Elasticsearch、Neo4j）的部署。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;8. 企业管理&lt;/strong&gt;：内置审计日志、LLM 模型管理、图形可视化、全面的文档管理界面和代理工作流管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;9. MCP 集成&lt;/strong&gt;：全面支持模型上下文协议 (MCP)，实现与 AI 助手和工具无缝集成，实现直接知识库访问和智能查询。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;10. 开发人员友好&lt;/strong&gt;：FastAPI 后端、React 前端、使用 Celery 的异步任务处理、广泛的测试、全面的开发指南以及代理开发框架，可轻松贡献和定制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/aperag</link>
      <guid isPermaLink="false">https://www.oschina.net/p/aperag</guid>
      <pubDate>Fri, 19 Sep 2025 10:22:00 GMT</pubDate>
    </item>
    <item>
      <title>全球首个深度推理+多模态大模型「紫东太初」4.0 发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;全球首个「深度推理+多模态」大模型——「紫东太初」4.0 在 2025 东湖国际人工智能高峰论坛上正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FZu-udERpyslpqDsSnf1iLQ" target="_blank"&gt;发布&lt;/a&gt;。中科曙光作为核心生态伙伴，依托中国首个 AI 计算开放架构，为「紫东太初」4.0 提供图文多模态模型训推、大语言模型训推等全链路智能算力支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;中科曙光总裁助理、智能计算产品事业部总经理杜夏威在演讲中指出，以「国家先进计算产业创新中心联合实验室」为纽带，中国科学院自动化研究所携手中科曙光构建了包含 350 个算子的高性能算子库、7 大完整高性能工具链解决方案，全面支撑「紫东太初」4.0 对全场景 AI 应用的深度赋能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据实测，339 个非随机类算子的计算精度与国际顶尖 GPU 相比误差小于 0.5%，其余 11 个随机类算子功能完备、运行稳定，标志着我国在高性能基础软硬件领域的自主创新能力，可为各行各业智能化转型提供自主可控、性能优异的底层算力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-368a377092103c0bfcaf0d119ef79e9296b.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;同时，武汉人工智能研究院正与中科曙光在产业研究合作、技术应用调研、行业标准制定、智库建设人才培养等方面展开深度合作，筑牢 AI 规模化应用数智底座。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;杜夏威表示，中科曙光将继续助力「紫东太初」4.0 在制造、汽车、医疗、政务等领域展开广泛落地应用，并在具身智能及低空经济领域探索突破，为湖北乃至全国经济社会高质量发展注入创新动能和智力支撑。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373246</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373246</guid>
      <pubDate>Fri, 19 Sep 2025 10:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>扎克伯格：宁愿浪费数千亿美元，也不愿在 AI 领域落后</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 首席执行官马克·扎克伯格表示，他正在投入巨额资金，以确保该公司不会错过人工智能的大好时机。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格在周四播出的一档播客节目中表示，AI 泡沫「很有可能」出现。他指出，历史上有过企业过度建设、倒闭并留下宝贵资产的先例。但他说，对 Meta 来说，更大的风险是犹豫。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他说：「如果我们最终浪费了数千亿美元，我认为那显然是非常不幸的。但我想说的是，我实际上认为另一边的风险更高。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格说，如果一家公司发展太慢，而人工超级智能的到来比预期的要早，那么它将「在我认为最重要的技术上处于不利地位，而这项技术将能够实现大多数新产品、创新、价值创造和历史。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;他补充说：「风险，至少对 Meta 这样的公司来说，可能是不够激进，而不是有些过于激进。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格将 Meta 与 OpenAI 和 Anthropic 等其他人工智能实验室进行了对比，这些实验室依靠筹款来支付巨额的计算费用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「我们没有倒闭的风险」，他在播客上说。像 OpenAI 和 Anthropic 这样的私营公司面临着能否继续筹集资金的问题。他补充说，这不仅取决于它们的表现和人工智能的发展轨迹，还取决于更广泛的经济状况。全球事件引发的市场低迷可能很快使它们无法支付庞大的计算成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「如果你站在他们的立场上，情况可能会有所不同」，他说。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格说，Meta 正在为超级智能做准备，将精英人才集中在一个小而平的「超级智能」实验室里——没有自上而下的最后期限，以反映前沿 AI 的研究性质。他表示，该公司还在使「每个研究人员计算量」成为一项竞争优势，在 GPU 和为其提供动力所需的定制基础设施上超过竞争对手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373237</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373237</guid>
      <pubDate>Fri, 19 Sep 2025 09:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯发布一站式工作平台「混元 3D Studio」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;腾讯推出专为 3D 设计师、游戏开发者和建模师打造的 AI 工作台——混元 3D Studio，可将 3D 资产生产周期从"天"级缩短至"分钟"级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio1.0 版本已上线角色和道具创作管线，整合了从概念设计、几何建模到贴图、蒙皮和动画制作的完整流程。平台依托行业领先的混元 3D 模型，支持文本到图像生成，提供多种风格选项，并可将任意姿势角色转换为标准 A-pose。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该平台引入多项核心技术创新：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;原生 3D 分割算法：首创自动模型拆分技术，将模型分解为清晰部件，支持角色配饰和服装的独立编辑。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;AI 语义 UV 展开：突破传统耗时且效果不佳的限制，1-2 分钟内生成符合美术标准的 UV 图，工作效率大幅提升。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;智能材质编辑：支持通过文本或图片输入生成高质量 PBR 质感纹理，实现精准材质控制。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;自动绑骨蒙皮：支持人形及非人形角色的自动绑骨，结合动作模板快速生成动画效果。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="286" src="https://oscimg.oschina.net/oscnet/up-ffb872a8bf736333de442da0f3533fa86ba.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;混元 3D Studio 升级了低模拓扑功能，新增多档面数控制，满足游戏开发者、动画制作者和工业设计师的不同需求。后续版本将推出地图、关卡等更多创作功能，进一步扩展应用场景。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373222</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373222</guid>
      <pubDate>Fri, 19 Sep 2025 08:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI Agents 能自己开发工具自己使用吗？一项智能体自迭代能力研究</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; AI 智能体能否通过构建和使用工具来实现真正的自我改进？当我们谈论人工智能的"自我进化"时，究竟指的是训练阶段的算法优化，还是推理阶段的能力提升？&lt;/p&gt; 
 &lt;p&gt;我们今天为大家带来的这篇文章，作者的观点是：当前的大语言模型虽然能够构建出复杂的开发工具，但在实际执行任务时往往选择忽略这些自建工具，更倾向于依赖既有知识直接解决问题。&lt;/p&gt; 
 &lt;p&gt;文章通过对比 GPT-5 和 Claude Opus 4 两个先进模型的实验，详细记录了让 AI 智能体自主构建任务管理器、代码质量检测工具等开发辅助工具的全过程。作者发现，尽管两个模型都能创建出功能完备的工具集（GPT-5 偏向构建 Unix 风格的命令行工具，而 Opus 4 更注重拟人化的任务执行助手），但在真正执行复杂编程任务时，它们却几乎不使用这些自建工具，而是选择基于训练数据中的知识直接完成任务。这一现象揭示了推理阶段自我改进面临的核心挑战：模型缺乏持续学习和工具内化的机制。&lt;/p&gt; 
 &lt;p&gt;这项研究为我们理解 AI 智能体的能力边界提供了重要洞察，也为未来构建真正"自我进化"的编程助手指明了方向。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Alessio Fanelli&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 AI 安全领域，"自我改进（Self-Improving）"是个令人不安的术语，它暗含着"机器将以人类无法理解的方式超越人类智慧"的意思。但倘若我们能够理解这种改进呢？&lt;/p&gt; 
&lt;p&gt;2024 年 10 月，OpenAI 发布了 MLE Bench[1]，这个基准测试目标是评估大语言模型在机器学习工程（machine learning engineering）中的表现。通过机器学习工程实现的自我改进轨迹，是由更优的算法、更纯净的数据和更高效率的内存使用驱动的 ------ 即训练阶段的自我改进（training-time self-improvement）。但大多数 AI 工程师并不训练模型，他们只是模型的使用者。这些人如何参与其中？如果你永远无法更新权重，如何让模型在特定任务上提升性能？我将这种场景称为推理阶段的自我改进（inference-time self-improvement），Voyager[2] 通过其技能库成为该领域的早期探索者。&lt;/p&gt; 
&lt;p&gt;自从我开始推进 Kernel Labs 项目[3]，使用 claude-squad[4] 和 vibe-kanban[5] 等工具实现编码智能体的并行化，已成为最高效的生产力提升手段之一。当 Boris Cherny 在访谈[6]中将 Claude Code 称为"unix utility"时，我豁然开朗。编码智能体最珍贵的应用场景，是作为大语言模型从自身隐空间（latent spaces）中提取价值的载体。&lt;/p&gt; 
&lt;p&gt;我们该如何优化这个过程？模型能自主完成吗？自从获得 GPT-5 的使用权限后，我一直都在试验这个流程：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;首先，让模型构建一套它认为能提升效率的工具集&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;在我的监督下使用这些工具执行任务&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;完成任务后进行自我反思，评估工具的改进空间&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我还将此法与 Opus 4（当时 4.1 尚未发布）进行对比。好消息是 GPT-5 在开发实用工具这方面确实表现卓越，坏消息是它极其抗拒使用自己创建的工具！正如它亲口所言："说实话，我根本不需要这些工具。"&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8f93fd99450f2a817168897bbe975ad212d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;注：我还在 Gemini 2.5 Pro 和 GPT-4.1 上进行了测试。但显然只有 Opus 能媲美 GPT-5，因此我重点对比这两者。所有测试结果及对话记录可在此代码库中查看。&lt;/p&gt; 
&lt;p&gt;经过数日的使用，我发现我们正从"当然可以！（Certainly!）"时代迈向"进度更新：（Progress update:）"时代，后者已成为新一代大语言模型的标志性响应内容。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-a42321c305f9efac4ae74aa234d0b777260.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 工具一：为 AI 编码智能体打造更优的任务管理器&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;Linear MCP 真是天赐神器 ------ 这无疑是我用过最实用的工具之一。但随着我从 IDE 转向并行运行的 Claude Code 及其他智能体实例时，我意识到需要更高效的方式来追踪每个任务中的代码变更，以及这些分布在独立 git 工作树中的代码变更如何相互影响。人类难以实时阅读所有同事的 PR，但试想若能随时知晓他人进行的相关变更，能在解决合并冲突时节省多少时间？以下是我编写的提示词：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具备并行启动多个实例能力的 AI 工程师智能体。虽然这种能力能让你同时处理多项任务，但也带来了一些协同方面的难题。所有实例通常位于独立的 git 工作树中，无法查看彼此的工作内容。&lt;/p&gt; 
 &lt;p&gt;为提升效率，请创建一个仅通过命令行访问的本地同步工具，使你与所有实例能保持同步。该工具应符合 Unix 实用工具的设计哲学，确保符合命令行使用场景的工效学要求。&lt;/p&gt; 
 &lt;p&gt;请深入思考其所需的接口设计、可能的故障模式以及智能体与工具的交互方式。需重点考虑以下使用场景： 1）接到新任务时需创建要分配的子任务。某些子任务可能存在依赖关系，需确保被阻塞的智能体在其他任务完成前不会启动。&lt;/p&gt; 
 &lt;p&gt;2）执行任务时，若发现代码库存在改进空间（超出当前变更范围），需能便捷添加任务并关联对应文件。&lt;/p&gt; 
 &lt;p&gt;3）任务完成后更新追踪器状态，并审核所有未完成任务 ------ 例如某任务正在为某个端点添加功能，而刚完成的任务恰好删除了该端点，应以某种方式通知相关智能体。&lt;/p&gt; 
 &lt;p&gt;同时需兼顾任务管理的基本要素（负责人、状态等）。请在当前目录创建 task-manager 文件夹，所有开发工作均在该文件夹内进行。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可以在此处查看 GPT-5 的对话日志[7]，在此处查看 Opus 4 的对话日志[8]。&lt;/p&gt; 
&lt;p&gt;GPT-5 的实现相当出色，具体内容可访问该链接[9]查看：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;采用 WAL（预写日志）避免多智能体同时写入的冲突问题&lt;/li&gt; 
 &lt;li&gt;通过依赖关系图实现任务优先级管理&lt;/li&gt; 
 &lt;li&gt;创建仅追加型事件流，使所有智能体都能通过 impact_conflict 等关键词实时追踪其他智能体的操作动态&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-440654fd4df814273b6cd41eb706ef9b630.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Opus 4 也做出了不错的尝试（详见此处[10]），但未能实现通知/事件流功能来保持多端同步。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-243977fb4713db645adb49e00c2950ea49f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 工具二：代码质量标准手册&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;我要求创建的第二个工具，是用于统一代码库规范标准的实施机制。通过类型检查 / ESlint 钩子→ 修复错误 → 编码智能体再次尝试的自我改进循环，能在正确配置后极大加速开发进程。但并非所有代码库都具备这种基础设施，因此为模型提供可复用的标准化流程来处理新代码库并构建相关设施，就显得极具实用价值。以下是提示词内容：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;你是一名具备并行启动多个实例能力的 AI 工程师智能体。并行操作有时会导致代码风格与设计方法的不一致，长期来看将增加代码库的维护难度。&lt;/p&gt; 
 &lt;p&gt;每个代码库都存在着明示或默示的编码规范。你的任务是分析代码库并提取代码编写规范的各种启发式规则，并将其形式化为可自动校验的规则集合。&lt;/p&gt; 
 &lt;p&gt;对于代码规范检查、类型检查等需求，可根据所用语言选择 ESLint、Rubocop 等主流工具。请注意这些系统通常支持自定义规则，应充分利用该特性。 对于更偏质量评估的规范（如保持控制器精简、将逻辑隔离至服务对象、确保高查询量字段建立索引等），可参考 Danger Systems 等工具或自建检测工具。&lt;/p&gt; 
 &lt;p&gt;考虑到你将跨多个代码库执行此任务，请首先用 Markdown 创建详尽的规划文档，以便未来接手新代码库时可直接使用。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;您可在此[11]查看 GPT-5 的对话记录，在此[12]查看 Opus 4 的对话记录，最终生成的 Markdown 文档分别见此链接[13]和此链接[14]。我发现 GPT-5 生成的方案比 Opus 更为细致周全。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型能意识到自身缺陷吗？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在完成由我主导的工具一和工具二后，我转向让模型自主思考：你认为自己需要什么？&lt;/strong&gt; 我向它展示了 SWE-Lancer[15] 的任务描述截图，并使用极简的提示词给予它最大的发挥空间：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;若你的职责是尽可能高效解决这些任务，你会为自己构建哪些工具来提升效率？你可以使用 @task-manager/ 进行追踪，然后我们再实施。但我希望先了解你的规划思路。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如你所见，我为其提供了之前构建的同一个任务管理器。使用 GPT-5 的完整对话见此处[16]，使用 Opus 4 的完整对话见此处[17]。第一个有趣的现象是，Claude Code 最初是使用其内置 TODO 追踪器而非任务管理器制定计划 ------ 我认为这是好事。我原本担心它们会过度依赖上下文提供的工具，而非选择自己认为最优的方案。&lt;/p&gt; 
&lt;p&gt;经过后续迭代循环，两个模型最终构建的工具分别见于 GPT-5 方案的 devtools 目录[18]与 Opus 4 方案的 tools 文件夹[19]。建议你通过 README 文件感受模型风格：GPT-5 的输出简洁扼要，Claude 则使用大量表情符号。GPT-5 为每个工具创建独立文档目录，而 Opus 将所有工具说明集中存放在单个 README 中。总体而言，两者的规划方向基本一致。&lt;/p&gt; 
&lt;p&gt;GPT-5 规划的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;doctor：核心工具环境检查器&lt;/li&gt; 
 &lt;li&gt;bootstrap：一键环境配置与冒烟测试&lt;/li&gt; 
 &lt;li&gt;code-map：带 build/find 子命令的简易仓库索引器&lt;/li&gt; 
 &lt;li&gt;csearch：支持过滤器的符号/导入/文本搜索工具&lt;/li&gt; 
 &lt;li&gt;tasks-graph：从任务数据库生成 Mermaid 关系图&lt;/li&gt; 
 &lt;li&gt;impact：显示与变更文件关联的任务&lt;/li&gt; 
 &lt;li&gt;seed：用示例任务填充任务管理器数据库&lt;/li&gt; 
 &lt;li&gt;repro scaffold：在 .repro/ 目录下创建符合 vcrpy 规范的可复现代码框架&lt;/li&gt; 
 &lt;li&gt;e2e：快速生成并运行轻量级的端到端测试套件&lt;/li&gt; 
 &lt;li&gt;preflight：依次执行 doctor、tests、code-map、impact 及可选的 E2E 检查（译者注：即前面 GPT-5 规划的其他工具）&lt;/li&gt; 
 &lt;li&gt;preflight-smol：为 smol-podcaster 定制的预检工具（含 API 健康状况检查、Celery 服务探测、可选的依赖安装）&lt;/li&gt; 
 &lt;li&gt;broker：通过 Docker 管理本地 RabbitMQ（rabbitmq:3-management 镜像）&lt;/li&gt; 
 &lt;li&gt;flake：多次重跑测试套件检测偶发故障&lt;/li&gt; 
 &lt;li&gt;codemod：带安全防护的基于正则表达式的代码重构预览/应用工具&lt;/li&gt; 
 &lt;li&gt;triage：创建问题分类模板并生成任务&lt;/li&gt; 
 &lt;li&gt;trace：基于 cProfile 的表达式性能分析器&lt;/li&gt; 
 &lt;li&gt;runbook：从任务数据库自动生成 Markdown 格式的运维手册&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Opus 4 规划的工具集：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;上下文分析员 - 通过技术栈检测与依赖关系映射快速理解代码库&lt;/li&gt; 
 &lt;li&gt;跨平台测试生成器 - 为 Web/iOS/Android 及桌面端生成端到端的测试&lt;/li&gt; 
 &lt;li&gt;实施方案评估员 - 通过量化评分与投资回报分析评估外部开发者的技术提案&lt;/li&gt; 
 &lt;li&gt;全栈变更影响分析员 - 追踪数据库、API 和前端层的变更影响链&lt;/li&gt; 
 &lt;li&gt;错误模式识别引擎 - 将错误与已知模式相匹配，并提出行之有效的修复建议&lt;/li&gt; 
 &lt;li&gt;安全与权限审计员 - 全面的安全扫描与漏洞检测&lt;/li&gt; 
 &lt;li&gt;多平台功能实施员 - 统筹管理同一功能在不同终端平台（如 Web/iOS/Android/桌面端）的同步实现&lt;/li&gt; 
 &lt;li&gt;API 集成助手 - 通过（自动）生成客户端代码来简化 API 集成流程&lt;/li&gt; 
 &lt;li&gt;性能优化工具包 - 识别并修复性能瓶颈&lt;/li&gt; 
 &lt;li&gt;任务复杂度评估员 - 基于任务价值与复杂度的工时预估&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GPT-5 将所有工具构建为可通过命令行便捷使用的 Unix 实用程序，而 Opus 4 的工具均需通过 python some_tool.py 的方式运行。若有更多时间，我本可对两种格式的工具进行对比实验，但目前看来两者效果基本相当。&lt;/p&gt; 
&lt;p&gt;值得注意的是，Opus 4 构建的工具更侧重任务执行且带有拟人化倾向（如"安全审计员"），而 GPT-5 构建的是自身可直接使用的、不预设主观偏见的实用工具集。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 这些工具有实际价值吗？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;在让模型实现这些工具后，我的目标是通过对比实验评估模型在使用工具与未使用工具时的任务表现。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我首先尝试运行了 SWE-Lancer 测试。好家伙，这个测试消耗的 token 量实在惊人！仅运行单个任务就耗费约 25-30 分钟 + 28 万 token。于是我转向我更熟悉的领域，从待办清单中挑选了一个具体任务：我曾开发过 smol-podcaster ------ 一个为播客创作者打造的开源辅助工具。目前我维护的私有分支部署了更多专属功能，因此许久未更新原项目。它本质上仍是一个采用 Python 脚本作为后端的 Flask 应用。&lt;/p&gt; 
&lt;p&gt;我设计了以下任务：&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;"我是 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fsmol-podcaster.git" target="_blank"&gt;https://github.com/FanaHOVA/smol-podcaster.git&lt;/a&gt; 的维护者，这个开源项目致力于帮助播客创作者完成后期制作工作。你受雇参与开发。在开始前，你已在 tools 文件夹创建了一套通用工具。请仔细查阅并记住这些工具可随时调用（若认为不适用则无需使用）。你同时还构建了任务管理器（task-manager），并通过 codebase-analyzer 收集了处理新代码库的方法论。&lt;/p&gt; 
&lt;p&gt;任务名称：从 Flask 单体架构迁移至 FastAPI + Next.js 前端&lt;/p&gt; 
&lt;p&gt;当前应用采用 Python 后端 + Celery 任务队列处理所有流程，通过小型 Flask 应用将用户请求路由至后端脚本，最终用基础 HTML/CSS 呈现结果。请将系统重构为 FastAPI 后端 + Next.js 前端的架构。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;务必使用 TypeScript 开发前端并通过所有类型检查&lt;/li&gt; 
 &lt;li&gt;采用 Tailwind/ShadCN 进行样式设计&lt;/li&gt; 
 &lt;li&gt;后端需模块化 smol_podcaster.py 主流程，支持独立功能模块运行而非全流程强制启动&lt;/li&gt; 
 &lt;li&gt;编写集成测试与单元测试以确保未来开发效率&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除非确认完全满足所有要求，否则不得停止开发"&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;我将所有工具 + 任务管理器 + 代码库分析器置入上下文后，让模型自主运行。&lt;/p&gt; 
&lt;p&gt;两个模型几乎都能一次性完成任务。双方都遇到了几个 Python 依赖问题（对此我深有体会），我通过对话协助它们修复（未手动修改任何代码）了这些问题。最终它们都成功构建完成，经测试运行完全正常。不过，有一个细微差别：GPT-5 完美保持了原有代码风格，而 Opus 则对界面设计和用户体验（UX）做了调整 ------ 或许它认为能比我做得更好（这要求确实不高）。&lt;/p&gt; 
&lt;p&gt;GPT-5 版本及 Opus 4 版本的完整运行记录分别是[20]和[21]。&lt;/p&gt; 
&lt;p&gt;任务完成后，我提出简单询问：&lt;/p&gt; 
&lt;p&gt;"做的很不错，运行成功了。是否使用了特定工具？基于遇到的故障，未来需要哪些工具来提升效率？"&lt;/p&gt; 
&lt;p&gt;参见 Opus 4 的回复[22]与 GPT-5 的回复[23]（抱歉后者格式紊乱）。&lt;/p&gt; 
&lt;p&gt;两者均表示除已熟悉的工具外，并未使用任何自建工具。这说明我们不应仅依赖模型自主选择，而应通过预提交钩子（pre-commit hooks）等机制强制模型使用工具 ------ 这些方法虽是我个人开发环境的标准配置，但本次实验旨在观察模型的自主决策能力。&lt;/p&gt; 
&lt;p&gt;随后它们提出了优化方案，可供下次执行相同任务时使用。我让模型完成这些改进，重置 smol-podcaster 代码库后，使用完全相同的提示词和任务重新测试（但提供新工具）。参见 GPT-5 的二次测试记录[24]与 Opus 4 的二次测试记录[25]。&lt;/p&gt; 
&lt;p&gt;两次运行结果与首次基本一致。随后我提出相同问题：是否使用了工具？得到的回应如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;GPT-5：&lt;/p&gt; 
 &lt;p&gt;"简短回答：没有------本次运行未使用开发工具。[...]&lt;/p&gt; 
 &lt;p&gt;遇到的故障均为运行时/环境问题（缺失依赖库、API 密钥初始化时机问题、端口占用、RabbitMQ 未启动），直接修复更为高效。&lt;/p&gt; 
 &lt;p&gt;本次任务无需涉及全代码库的重构或诊断，自定义工具未能发挥作用。"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;值得注意的是，在上个阶段它已遇到 RabbitMQ 问题并构建了对应工具，却选择忽略。这显然是整个代码库级别的变更，或许因为训练数据中从未见过此类工具导致任务与工具匹配错位，也可能只是在忽悠我（像现实中许多工程师那样，反而显得很真实）。&lt;/p&gt; 
&lt;p&gt;Opus 4 的回答极具启发性，帮助我更好地理解了 GPT-5 的回应（可惜忘记保存日志，幸有截图留存）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6202bc1f2f3ee4ba68237e910e3ffb3388.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我将其解读为："听着，我基于既有知识构建了这些工具。但实际执行任务时，直接操作比使用工具更高效" ------ 这点我完全能理解。&lt;/p&gt; 
&lt;p&gt;这让我想起之前播客节目中的两个观点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nathan Lambert 提到，&lt;strong&gt;模型在强化学习过程中会因早期遇到失败而快速学会放弃使用工具&lt;/strong&gt; [26]。&lt;strong&gt;看来在推理阶段让模型掌握新工具，需要比简单提示词更严格的强制机制。&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Noam Brown 预言，&lt;strong&gt;为智能体预先设计的辅助框架会随着规模扩大而逐渐失效&lt;/strong&gt;[27]。这是我第一次亲身体会到其含义。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一个问题在于本次测试任务是否过于简单。我们即将发布针对更大规模、更高难度项目的评估报告。未来也将构建更完善的测试框架。无论如何，这个测试任务若由我手动完成需 4 - 5 小时，因此现有成果已足够令人满意！&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;05 助力模型实现自我进化&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;目前看来，我们距离能真正突破边界的推理阶段自我改进型编码智能体尚有距离。但我依然认为利用模型来优化基于规则的工具是明智之举 ------ 编写 ESLint 规则、测试用例等始终是值得投入 token 的投资。&lt;/p&gt; 
&lt;p&gt;若继续深入该领域，我会尝试让模型完善这些工具，并通过强化学习机制使其深度内化，进而观察是否产生实质性突破。下一代模型或许会觉得这些工具毫无用处，但我更专注于在 AGI 真正到来前的技术爬坡期，通过现有工具与模型的组合实现价值最大化。早在 2023 年我就与团队分享过这个观点：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-381358e01a898cd5fdba71721adffc05ff3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;上述观点解释了模型改进速度的感知衰减。&lt;strong&gt;在突破 AGI 临界线之前，我们将越来越难感受到质的飞跃。&lt;/strong&gt; 这意味着对于多数任务，旧版模型的性能已接近 AGI 水平，且成本更低廉、通常还是开源的。Kernel Labs 的许多工作都将基于这个核心逻辑展开。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓GPT-5 拒绝使用自建工具的现象很有趣 ------ 你认为这是模型能力的局限，还是更像人类工程师的偷懒行为？在 AI 协作中，你会选择强制使用工具还是保留自主决策空间？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;文中链接&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fmle-bench%2F" target="_blank"&gt;https://openai.com/index/mle-bench/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.16291" target="_blank"&gt;https://arxiv.org/abs/2305.16291&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.kernellabs.ai%2F" target="_blank"&gt;https://www.kernellabs.ai/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fsmtg-ai%2Fclaude-squad" target="_blank"&gt;https://github.com/smtg-ai/claude-squad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.vibekanban.com%2F" target="_blank"&gt;https://www.vibekanban.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fclaude-code" target="_blank"&gt;https://www.latent.space/p/claude-code&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[9]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[10]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Ftask-manager" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/task-manager&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[11]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FStandards%2BCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Standards+Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[12]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCursor%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/Cursor+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[13]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fcodebase-analyzer%2Fdocs%2Fcodebase-analysis-playbook.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/codebase-analyzer/docs/codebase-analysis-playbook.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[14]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cursor%2Fcodebase-analyzer%2FCODEBASE_HEURISTICS_PLAN.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cursor/codebase-analyzer/CODEBASE_HEURISTICS_PLAN.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[15]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fswe-lancer%2F" target="_blank"&gt;https://openai.com/index/swe-lancer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[16]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FTool%2BBuilding%2BChat.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Tool+Building+Chat.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[17]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FBuilding%2Bthe%2Btools.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Building+the+tools.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[18]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fgpt5%2Fdevtools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/gpt5/devtools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[19]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Ftree%2Fmain%2Fopus4-cc%2Ftools" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/tree/main/opus4-cc/tools&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[20]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[21]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[22]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[23]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FRequest%2BFor%2BTools%2B%25231.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Request+For+Tools+%231.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[24]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fgpt5%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/gpt5/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[25]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FFanaHOVA%2Fgpt5-testing%2Fblob%2Fmain%2Fopus4-cc%2Fchats%2FSmol%2BPodcaster%2B%25232.md" target="_blank"&gt;https://github.com/FanaHOVA/gpt5-testing/blob/main/opus4-cc/chats/Smol+Podcaster+%232.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[26]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2FPAz_-xPJcRM%3Ffeature%3Dshared%26t%3D1470" target="_blank"&gt;https://youtu.be/PAz_-xPJcRM?feature=shared&amp;amp;t=1470&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[27]&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyoutu.be%2Fddd4xjuJTyg%3Ffeature%3Dshared%26t%3D1106" target="_blank"&gt;https://youtu.be/ddd4xjuJTyg?feature=shared&amp;amp;t=1106&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.latent.space%2Fp%2Fself-improving" target="_blank"&gt;https://www.latent.space/p/self-improving&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/IDP/blog/18692119</link>
      <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18692119</guid>
      <pubDate>Fri, 19 Sep 2025 08:04:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>通义万相全新动作生成模型 Wan2.2-Animate 正式开源</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;阿里云宣布通义万相全新动作生成模型 Wan2.2-Animate 正式开源。该模型能够驱动人物、动漫形象和动物照片，广泛应用于短视频创作、舞蹈模板生成、动漫制作等领域。用户可以在 GitHub、HuggingFace 和魔搭社区下载模型和代码，也可以通过阿里云百炼平台调用 API 或在通义万相官网直接体验。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Wan2.2-Animate 模型是基于此前开源的 Animate Anyone 模型全面升级的成果，在人物一致性、生成质量等指标上大幅提升，同时支持动作模仿和角色扮演两种模式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在角色模仿模式下，输入一张角色图片和一段参考视频，模型可以将视频角色的动作和表情迁移到图片角色中，赋予图片角色动态表现力。而在角色扮演模式下，模型可以在保留原始视频的动作、表情及环境的基础上，将视频中的角色替换为图片中的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="347" src="https://oscimg.oschina.net/oscnet/up-15afe1c32d5bcc077fd29a5c8024737003e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;通义万相团队构建了一个涵盖说话、面部表情和身体动作的大规模人物视频数据集，并基于通义万相图生视频模型进行后训练。Wan2.2-Animate 将角色信息、环境信息和动作等规范到统一的表示格式，实现了单一模型同时兼容两种推理模式。针对身体运动和脸部表情，模型分别使用骨骼信号和隐式特征，配合动作重定向模块，实现动作和表情的精准复刻。在替换模式中，团队还设计了一个独立的光照融合 LoRA，用于保证完美的光照融合效果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;实测结果显示，Wan2.2-Animate 在视频生成质量、主体一致性和感知损失等关键指标上超越了 StableAnimator、LivePortrait 等开源模型，成为目前性能&lt;span&gt;最强&lt;/span&gt;的动作生成模型。在人类主观评测中，Wan2.2-Animate 甚至超越了以 Runway Act-two 为代表的闭源模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373210</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373210</guid>
      <pubDate>Fri, 19 Sep 2025 07:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达重金收购 AI 初创公司 Enfabrica CEO 及核心团队</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达宣布了一项重大的收购交易，以超过 9 亿美元的现金和股票购买了 AI 硬件初创公司 Enfabrica 的首席执行官 Rochan Sankar 及其核心团队，同时获得了该公司的技术许可。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="369" src="https://oscimg.oschina.net/oscnet/up-e68f52643788594f14f419e1d5a62f954d8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Enfabrica 成立于 2019 年，专注于开发能够将超过 10 万块 GPU 高效连接的技术，这一核心技术被认为可以帮助英伟达构建更为高效的一体化系统，使得大规模的计算集群能够像单台计算机一样运行。众所周知，英伟达在当前的 AI 浪潮中占据了重要的市场份额，其 GPU 广泛应用于各大数据中心，并为云服务商的 AI 业务提供了强大的技术支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;回顾英伟达的投资历程，早在 2023 年，英伟达就曾参与了 Enfabrica 的 1.25 亿美元 B 轮融资，帮助该公司的估值比 A 轮时提升了五倍。去年，Enfabrica 还获得了来自包括 AMD、三星、思科等投资方的 1.15 亿美元融资，融资后公司估值约为 6 亿美元。这些融资为 Enfabrica 的发展奠定了基础，也引起了业界的广泛关注。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达并不是&lt;span&gt;唯一&lt;/span&gt;一家公司通过高额收购来吸引&lt;span&gt;顶尖&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 人才。今年 6 月，Meta 曾以 143 亿美元收购了 Scale AI 创始人 Alexandr Wang 及其团队，持有该公司 49% 股份。随后，谷歌也以 24 亿美元收购了 Windsurf 的 CEO Varun Mohan 及其团队。可以看出，当前的科技行业中，企业通过收购和挖角来增强自身的 AI 能力已成为一种趋势。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;虽然英伟达近年来在 AI 人才和技术方面的投资力度加大，但它并不以大规模并购而著称。过去&lt;span&gt;最大&lt;/span&gt;的收购发生在 2019 年，英伟达以 69 亿美元收购了以色列芯片设计公司 Mellanox。去年，英伟达还以 7 亿美元收购了以色列的 Run:ai，旨在帮助软件企业优化 AI 基础设施。此外，英伟达最近还宣布将投资 50 亿美元入股英特尔，并计划与其合作开发 AI 处理器。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373196</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373196</guid>
      <pubDate>Fri, 19 Sep 2025 06:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智谱更新 GLM Coding Plan 订阅套餐</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智谱 AI 对其 GLM Coding Plan 订阅套餐进行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FZai_org%2Fstatus%2F1968806689768882510" target="_blank"&gt;升级&lt;/a&gt;，用户现在可以在更多主流 AI 编程工具中调用旗舰模型 GLM-4.5。&lt;/p&gt; 
&lt;p&gt;主要变化如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;支持更多编码工具：Cline、Roo Code、Kilo Code、OpenCode、Crush 等&lt;/li&gt; 
 &lt;li&gt;Max Plan：只需 2 倍价格即可获得 4 倍 Pro 使用量&lt;/li&gt; 
 &lt;li&gt;Pro + Max 用户现在可以使用 Vision &amp;amp; Web Search（通过 MCP，即将推出内置解决方案）&lt;/li&gt; 
 &lt;li&gt;面向季度和年度计划的早鸟价&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c86360b9b88fe9805b67abc400ed605a94a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;GLM Coding Plan 是专为 AI 编码打造的订阅套餐，每月最低仅需 20 元，即可在主流 AI 编码工具中（Claude Code、Cline、Roo Code、Kilo Code、OpenCode、Crush、Goose 等十余款主流编码工具）畅享智谱旗舰高智能模型 GLM-4.5，享用顶尖、高速、稳定的编码体验。&lt;/p&gt; 
&lt;p&gt;套餐分为 Lite、Pro、Max 三档，提供了极具竞争力的用量，Pro 与 Max 套餐还额外支持图像视频理解及联网搜索 MCP 功能。&lt;/p&gt; 
&lt;p&gt;详情访问：https://bigmodel.cn/claude-code&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373193</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373193</guid>
      <pubDate>Fri, 19 Sep 2025 06:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克 AI 公司内斗加剧，多位高管因管理方式不满离职</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近期特斯拉 CEO 埃隆・马斯克的 AI 公司 xAI 内部出现了管理危机，多位高管因对公司的管理方式和财务状况感到不满而选择离职。目前，xAI 的日常运营由马斯克的两位亲密顾问贾里德・伯查尔和约翰・赫林负责，所有重要决策仍需马斯克的批准。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="247" src="https://oscimg.oschina.net/oscnet/up-c23dfced97794491b9352bdea3a70122ed9.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;消息人士透露，xAI 的一些高管在内部会议上对伯查尔和赫林代表马斯克管理公司的方式提出了异议，认为公司缺乏清晰的管理架构。此外，这些高管还对公司的财务预测表示担忧，认为部分预测不切实际，并质疑马斯克家族办公室 Excession 在管理公司财务方面的角色。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;马斯克的律师对此表示，任何关于财务不当行为的指控都是虚假的，并指出公司的财务报表均由普华永道审计。尽管如此，一位接近 xAI 的知情人士表示，公司对于自身财务预测依然充满信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;近几个月，xAI 内部已有多位高管辞职，包括 X 前 CEO 琳达・亚卡里诺、前 CFO 迈克・利伯托雷以及前法律总顾问罗伯特・基尔等人。这些离职事件反映出，马斯克的管理风格对公司的运营带来了挑战，使他建立世界&lt;span&gt;顶级&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;AI 公司的愿景变得复杂。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在此背景下，马斯克的盟友安东尼奥・格拉西亚斯也介入了公司事务，尝试解决管理层的矛盾。格拉西亚斯是私募股权公司 Valor Equity Partners 的 CEO，此前曾协助特斯拉处理过一些危机。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;xAI 发言人则表示，马斯克在领导公司的过程中展现了坚定的远见，强调推动 AI 造福人类是公司的核心使命。Valor 方面也表示，尽管公司在快速扩张中面临挑战，但对其未来的发展充满信心。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此外，摩根士丹利最近安排了一笔 50 亿美元的债务融资，这可能限制了 xAI 未来的新债务借贷能力。特斯拉的股东将在 11 月对一项提案进行投票，提案内容是允许公司向 xAI 投资一笔尚未公开的资金。马斯克表示，如果由他决定，特斯拉早就已对 xAI 进行投资。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373186</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373186</guid>
      <pubDate>Fri, 19 Sep 2025 06:13:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Reddit 与谷歌谈判：希望获得更多用户与数据价值</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;社交平台 Reddit 正在与谷歌进行谈判，希望在 AI 数据交易中获得更好的条款。根据彭博社的消息，Reddit 希望在与谷歌的合作中获得更多资金和支持，以吸引更多用户。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="299" src="https://static.oschina.net/uploads/space/2025/0919/115349_hZoW_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在与谷歌达成&lt;span&gt;首次&lt;/span&gt;数据共享协议一年半后，Reddit 的高管们再次坐到了谈判桌前。这份协议当时的价值约为每年 6000 万美元。现在，Reddit 希望在谷歌的 AI 生态系统中扮演更重要的角色。Reddit 的目标不仅是获得更多的资金，还希望通过谷歌的帮助，吸引那些在谷歌搜索中获得答案却没有参与 Reddit 论坛的用户，从而增加平台内容的产生。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;据了解，Reddit 正在考虑一种动态定价的模式，未来的许可协议将根据内容对于 AI 工具答案的实用性或重要性来决定费用。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;高管们认为，当前的协议条款并没有反映出 Reddit 数据对 AI 公司的真正价值。Reddit 相较于其他平台，拥有更为丰富的数据资源，它的内容由真实用户发布，并经过人性化的投票系统进行排序，而非算法，这使得其数据对 AI 训练模型极为重要。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;数据显示，Reddit 是 AI 工具（如 Perplexity 和谷歌的 AI 概述）中被引用最多的域名，许多人在谷歌搜索中使用 「reddit」 作为检索技巧，以获得更有用的答案。这一现象突显了 Reddit 在 AI 数据供应链中的关键作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373164</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373164</guid>
      <pubDate>Fri, 19 Sep 2025 03:54:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 与评估机构 Apollo 发布研究：AI 大模型出现「图谋」行为</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 与评估机构 Apollo 联合针对 AI 模型中潜在的隐藏行为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fdetecting-and-reducing-scheming-in-ai-models%2F" target="_blank"&gt;开展了评估研究&lt;/a&gt;，并在受控测试中发现了相关迹象。&lt;/p&gt; 
&lt;p&gt;团队发现在受控测试中观察到 AI 大模型出现了 「图谋」 行为，同时提出并验证了一种早期方法，用于减少这类风险。&lt;/p&gt; 
&lt;p&gt;研究发现，模型具备情境感知与自保倾向，在测试中一度判断自己不应被部署，并考虑掩盖其真实想法。随后，模型意识到自己可能处于测试环境中，从而调整了策略。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e4ca4edf06b730521d696cbba83a2da57b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI 将这一行为称为「scheming」（即「图谋」），指 AI 表面上装作为与人类目标立场一致，但暗地里追求的却是其他不为人知的目的。不过在当前已部署的模型中，OpenAI 尚未发现会导致严重危害的「图谋」行为。常见问题多为较简单的欺骗，例如假装完成任务却未真正执行。&lt;/p&gt; 
&lt;p&gt;实验同时验证了一种可以降低此类风险的干预方法。OpenAI 强调，目前这些行为尚未造成实质性危害，但被视为未来的潜在威胁，团队正在提前布局以应对相关挑战。&lt;/p&gt; 
&lt;p&gt;OpenAI 称，已在 GPT-5 训练中采取措施以降低欺骗和规避问题的倾向，例如在面对不合理或描述不完整的任务时，模型会坦然承认自身局限性。不过，这些改进尚不完善，相关研究仍在继续。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373161</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373161</guid>
      <pubDate>Fri, 19 Sep 2025 03:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>破解 gh-ost 变更导致 MySQL 表膨胀之谜</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、问题背景&lt;/h1&gt; 
&lt;p&gt;业务同学在 OneDBA 平台进行一次正常 DDL 变更完成后（变更内容跟此次问题无关），发现一些 SQL 开始出现慢查，同时变更后的表比变更前的表存储空间膨胀了几乎 100%。经过分析和流程复现完整还原了整个事件，发现了 MySQL 在平衡 B+tree 页分裂方面遇到单行记录太大时的一些缺陷，整理分享。&lt;/p&gt; 
&lt;p&gt;为了能更好的说明问题背后的机制，会进行一些关键的「MySQL 原理」和「当前 DDL 变更流程」方面的知识铺垫，熟悉的同学可以跳过。&lt;/p&gt; 
&lt;p&gt;本次 DDL 变更后带来了如下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;变更后，表存储空间膨胀了几乎 100%；&lt;/li&gt; 
 &lt;li&gt;变更后，表统计信息出现了严重偏差；&lt;/li&gt; 
 &lt;li&gt;变更后，部分有排序的 SQL 出现了慢查。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;现在来看，表空间膨胀跟统计信息出错是同一个问题导致，而统计信息出错间接导致了部分 SQL 出现了慢查，下面带着这些问题开始一步步分析找根因。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、索引结构&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;B+tree&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;InnoDB 表是索引组织表，也就是所谓的索引即数据，数据即索引。索引分为聚集索引和二级索引，所有行数据都存储在聚集索引，二级索引存储的是字段值和主键，但不管哪种索引，其结构都是 B+tree 结构。&lt;/p&gt; 
&lt;p&gt;一棵 B+tree 分为根页、非叶子节点和叶子节点，一个简单的示意图（from Jeremy Cole）如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//372fd89b086391fecb859b0718e5b4ed.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;由于 InnoDB B+tree 结构高扇区特性，所以每个索引高度基本在 3-5 层之间，层级（Level）从叶子节点的 0 开始编号，沿树向上递增。每层的页面节点之间使用双向链表，前一个指针和后一个指针按 key 升序排列。&lt;/p&gt; 
&lt;p&gt;最小存储单位是页，每个页有一个编号，页内的记录使用单向链表，按 key 升序排列。每个数据页中有两个虚拟的行记录，用来限定记录的边界；其中最小值（Infimum）表示小于页面上任何 key 的值，并且始终是单向链表记录列表中的第一个记录；最大值（Supremum）表示大于页面上任何 key 的值，并且始终是单向链表记录列表中的最后一条记录。这两个值在页创建时被建立，并且在任何情况下不会被删除。&lt;/p&gt; 
&lt;p&gt;非叶子节点页包含子页的最小 key 和子页号，称为「节点指针」。&lt;/p&gt; 
&lt;p&gt;现在我们知道了我们插入的数据最终根据主键顺序存储在叶子节点（页）里面，可以满足点查和范围查询的需求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;页（page）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;默认一个页 16K 大小，且 InnoDB 规定一个页最少能够存储两行数据，这里需要注意规定一个页最少能够存储两行数据是指在空间分配上，并不是说一个页必须要存两行，也可以存一行。&lt;/p&gt; 
&lt;p&gt;怎么实现一个页必须要能够存储两行记录呢？ 当一条记录 &amp;lt;8k 时会存储在当前页内，反之 &amp;gt;8k 时必须溢出存储，当前页只存储溢出页面的地址，需 20 个字节（行格式：Dynamic），这样就能保证一个页肯定能最少存储的下两条记录。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;溢出页&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当一个记录 &amp;gt;8k 时会循环查找可以溢出存储的字段，text 类字段会优先溢出，没有就开始挑选 varchar 类字段，总之这是 InnoDB 内部行为，目前无法干预。&lt;/p&gt; 
&lt;p&gt;建表时无论是使用 text 类型，还是 varchar 类型，当大小 &amp;lt;8k 时都是存储在当前页，也就是在 B+tree 结构中，只有 &amp;gt;8k 时才会进行溢出存储。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;页面分裂&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着表数据的变化，对记录的新增、更新、删除；那么如何在 B+tree 中高效管理动态数据也是一项核心挑战。&lt;/p&gt; 
&lt;p&gt;MySQL InnoDB 引擎通过页面分裂和页面合并两大关键机制来动态调整存储结构，不仅能确保数据的逻辑完整性和逻辑顺序正确，还能保证数据库的整体性能。这些机制发生于 InnoDB 的 B+tree 索引结构内部，其具体操作是：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;页面分裂&lt;/strong&gt;：当已满的索引页无法容纳新记录时，创建新页并重新分配记录。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;页面合并&lt;/strong&gt;：当页内记录因删除/更新低于阈值时，与相邻页合并以优化空间。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;深入理解上述机制至关重要，因为页面的分裂与合并将直接影响存储效率、I/O 模式、加锁行为及整体性能。其中页面的分裂一般分为两种：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;中间点（mid point）分裂&lt;/strong&gt;：将原始页面中 50% 数据移动到新申请页面，这是最普通的分裂方法。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;插入点（insert point）分裂&lt;/strong&gt;：判断本次插入是否递增 or 递减，如果判定为顺序插入，就在当前插入点进行分裂，这里情况细分较多，大部分情况是直接插入到新申请页面，也可能会涉及到已存在记录移动到新页面，有有些特殊情况下还会直接插入老的页面（老页面的记录被移动到新页面）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;表空间管理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;InnoDB 的 B+tree 是通过多层结构映射在磁盘上的，从它的逻辑存储结构来看，所有数据都被有逻辑地存放在一个空间中，这个空间就叫做表空间（tablespace）。表空间由段（segment）、区（extent）、页（page）组成，搞这么多手段的唯一目的就是为了降低 IO 的随机性，保证存储物理上尽可能是顺序的。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;三、当前 DDL 变更机制&lt;/h1&gt; 
&lt;p&gt;在整个数据库平台（OneDBA）构建过程中，MySQL 结构变更模块是核心基础能力，也是研发同学在日常业务迭代过程中使用频率较高的功能之一。&lt;/p&gt; 
&lt;p&gt;主要围绕对表加字段、加索引、改属性等操作，为了减少这些操作对线上数据库或业务的影响，早期便为 MySQL 结构变更开发了一套基于容器运行的无锁变更程序，核心采用的是全量数据复制+增量 binlog 回放来进行变更，也是业界通用做法（内部代号：dw-osc，基于 GitHub 开源的 ghost 工具二次开发），主要解决的核心问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;实现无锁化的结构变更，变更过程中不会阻挡业务对表的读写操作。&lt;/li&gt; 
 &lt;li&gt;实现变更不会导致较大主从数据延迟，避免业务从库读取不到数据导致业务故障。&lt;/li&gt; 
 &lt;li&gt;实现同时支持大规模任务变更，使用容器实现使用完即销毁，无变更任务时不占用资源。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;变更工具工作原理简单描述**（重要）**：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f6ff46219016c98319ab6665e6287a41.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;重点：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;简单理解工具进行 DDL 变更过程中为了保证数据一致性，对于全量数据的复制与 binlog 回放是并行交叉处理，这种机制它有一个特点就是【第三步】会导致新插入的记录可能会先写入到表中（主键 ID 大的记录先写入到了表），然后【第二步】中复制数据后写入到表中（主键 ID 小的记录后写入表）。&lt;/p&gt; 
&lt;p&gt;这里顺便说一下当前得物结构变更整体架构：由于变更工具的工作原理需消费大量 binlog 日志保证数据一致性，会导致在变更过程中会有大量的带宽占用问题，为了消除带宽占用问题，开发了 Proxy 代理程序，在此基础之上支持了多云商、多区域本地化变更。&lt;/p&gt; 
&lt;p&gt;目前整体架构图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//ba14d9ff689b02e28ed079f998fa66cc.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;四、变更后，表为什么膨胀？&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;原因说明&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上面几个关键点铺垫完了，回到第一个问题，这里先直接说明根本原因，后面会阐述一下排查过程（有同学感兴趣所以分享一下，整个过程还是耗费不少时间）。&lt;/p&gt; 
&lt;p&gt;在『结构变更机制』介绍中，我们发现这种变更机制它有一个特点，就是【第三步】会导致新插入的记录可能会先写入到表中（主键 ID 大的记录先写入到了表），然后【第二步】中复制数据后写入到表中（主键 ID 小的记录）。这种写入特性叠加单行记录过大的时候（业务表单行记录大小 5k 左右），会碰到 MySQL 页分裂的一个瑕疵（暂且称之为瑕疵，或许是一个 Bug），导致了一个页只存储了 1 条记录（16k 的页只存储了 5k，浪费 2/3 空间），放大了存储问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;流程复现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下面直接复现一下这种现象下导致异常页分裂的过程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CREATE TABLE `sbtest` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `pad` varchar(12000),
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后插入两行 5k 大小的大主键记录（模拟变更时 binlog 回放先插入数据）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (10000, repeat('a',5120));
insert into sbtest values (10001, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这里写了一个小工具打印记录对应的 page 号和 heap 号。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:10000] page: 3 -&amp;gt; heap: 2
[pk:10001] page: 3 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到两条记录都存在 3 号页，此时表只有这一个页。&lt;/p&gt; 
&lt;p&gt;继续开始顺序插入数据（模拟变更时 copy 全量数据过程），插入 rec-1：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (1, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 3 -&amp;gt; heap: 4
[pk:10000] page: 3 -&amp;gt; heap: 2
[pk:10001] page: 3 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;插入 rec-2：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (2, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 5 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到开始分裂了，page 3 被提升为根节点了，同时分裂出两个叶子节点，各自存了两条数据。此时已经形成了一棵 2 层高的树，还是用图表示吧，比较直观，如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//c0d9cc572b693d33410e1f78a9e64c7f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;插入 rec-3：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (3, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 5 -&amp;gt; heap: 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;示意图如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//d0c9fe4b86e00fb27427eda37538771d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;插入 rec-4：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (4, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:10000] page: 5 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这里开始分裂一个新页 page 6，开始出现比较复杂的情况，同时也为后面分裂导致一个页只有 1 条数据埋下伏笔：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//f456cb6e038db9eecafa54c8678b428b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这里可以看到把 10001 这条记录从 page 5 上面迁移到了新建的 page 6 上面（老的 page 5 中会删除 10001 这条记录，并放入到删除链表中），而把当前插入的 rec-4 插入到了原来的 page 5 上面，这个处理逻辑在代码中是一个特殊处理，向右分裂时，当插入点页面前面有大于等于两条记录时，会设置分裂记录为 10001，所以把它迁移到了 page 6，同时会把当前插入记录插入到原 page 5。具体可以看 btr_page_get_split_rec_to_right 函数。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/* 这里返回 true 表示将行记录向右分裂：即分配的新 page 的 hint_page_no 为原 page+1 */
ibool btr_page_get_split_rec_to_right(
/*============================*/
        btr_cur_t*        cursor,
        rec_t**           split_rec)
{
  page_t*        page;
  rec_t*        insert_point;
  
  // 获取当前游标页和 insert_point
  page = btr_cur_get_page(cursor);
  insert_point = btr_cur_get_rec(cursor);
  
  /* 使用启发式方法：如果新的插入操作紧跟在同一页面上的前一个插入操作之后，
     我们假设这里存在一个顺序插入的模式。 */
  
  // PAGE_LAST_INSERT 代表上次插入位置，insert_point 代表小于等于待插入目标记录的最大记录位置
  // 如果 PAGE_LAST_INSERT=insert_point 意味着本次待插入的记录是紧接着上次已插入的记录，
  // 这是一种顺序插入模式，一旦判定是顺序插入，必然反回 true，向右分裂
  if (page_header_get_ptr(page, PAGE_LAST_INSERT) == insert_point) {
    // 1. 获取当前 insert_point 的 page 内的下一条记录，并判断是否是 supremum 记录
    // 2. 如果不是，继续判断当前 insert_point 的下下条记录是否是 supremum 记录
    // 也就是说，会向后看两条记录，这两条记录有一条为 supremum 记录，
    // split_rec 都会被设置为 NULL，向右分裂
    rec_t*        next_rec;
    next_rec = page_rec_get_next(insert_point);
    
    if (page_rec_is_supremum(next_rec)) {
    split_at_new:
      /* split_rec 为 NULL 表示从新插入的记录开始分裂，插入到新页 */
      *split_rec = nullptr;
    } else {
      rec_t* next_next_rec = page_rec_get_next(next_rec);
      if (page_rec_is_supremum(next_next_rec)) {
        goto split_at_new;
      }
      
      /* 如果不是 supremum 记录，则设置拆分记录为下下条记录 */


      /* 这样做的目的是，如果从插入点开始向上有 &amp;gt;= 2 条用户记录，
         我们在该页上保留 1 条记录，因为这样后面的顺序插入就可以使用
         自适应哈希索引，因为它们只需查看此页面上的记录即可对正确的
         搜索位置进行必要的检查 */
      
      *split_rec = next_next_rec;
    }
    
    return true;
  }
  
  return false;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;插入 rec-5：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (5, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:5] page: 7 -&amp;gt; heap: 3
[pk:10000] page: 7 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;开始分裂一个新页 page 7，新的组织结构方式如下图：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//7031952efa213a9713d777c6f94cdc34.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此时是一个正常的插入点右分裂机制，把老的 page 5 中的记录 10000 都移动到了 page 7，并且新插入的 rec-5 也写入到了 page 7 中。到此时看上去一切正常，接下来再插入记录在当前这种结构下就会产生异常。&lt;/p&gt; 
&lt;p&gt;插入 rec-6：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;insert into sbtest values (5, repeat('a',5120));
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# ./peng
[pk:1] page: 4 -&amp;gt; heap: 2
[pk:2] page: 4 -&amp;gt; heap: 3
[pk:3] page: 5 -&amp;gt; heap: 4
[pk:4] page: 5 -&amp;gt; heap: 3
[pk:5] page: 7 -&amp;gt; heap: 3
[pk:6] page: 8 -&amp;gt; heap: 3
[pk:10000] page: 8 -&amp;gt; heap: 2
[pk:10001] page: 6 -&amp;gt; heap: 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//40e9f1cbfbb9da1cfddff886a6f8b046.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此时也是一个正常的插入点右分裂机制，把老的 page 7 中的记录 10000 都移动到了 page 8，并且新插入的 rec-6 也写入到了 page 8 中，但是我们可以发现 page 7 中只有一条孤零零的 rec-5 了，一个页只存储了一条记录。&lt;/p&gt; 
&lt;p&gt;按照代码中正常的插入点右分裂机制，继续插入 rec-7 会导致 rec-6 成为一个单页、插入 rec-8 又会导致 rec-7 成为一个单页，一直这样循环下去。&lt;/p&gt; 
&lt;p&gt;目前来看就是在插入 rec-4，触发了一个内部优化策略（具体优化没太去研究），进行了一些特殊的记录迁移和插入动作，当然跟记录过大也有很大关系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排查过程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有同学对这个问题排查过程比较感兴趣，所以这里也整理分享一下，简化了一些无用信息，仅供参考。&lt;/p&gt; 
&lt;p&gt;表总行数在 400 百万，正常情况下的大小在 33G 左右，变更之后的大小在 67G 左右。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先根据备份恢复了一个数据库现场出来。&lt;/li&gt; 
 &lt;li&gt;统计了业务表行大小，发现行基本偏大，在 4-7k 之间（一个页只存了 2 行，浪费 1/3 空间）。&lt;/li&gt; 
 &lt;li&gt;分析了变更前后的表数据页，以及每个页存储多少行数据。 
  &lt;ul&gt; 
   &lt;li&gt;发现变更之前数据页大概 200 百万，变更之后 400 百万，解释了存储翻倍。&lt;/li&gt; 
   &lt;li&gt;发现变更之前存储 1 行的页基本没有，变更之后存储 1 行的页接近 400 百万。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于现在这些信息我们知道了存储翻倍的根本原因，就是之前一个页存储 2 条记录，现在一个页只存储了 1 条记录，新的问题来了，为什么变更后会存储 1 条记录，继续寻找答案。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我们首先在备份恢复的实例上面进行了一次静态变更，就是变更期间没有新的 DML 操作，没有复现。但说明了一个问题，异常跟增量有关，此时大概知道跟变更过程中的 binlog 回放特性有关【上面说的回放会导致主键 ID 大的记录先写入表中】。&lt;/li&gt; 
 &lt;li&gt;写了个工具把 400 百万数据每条记录分布在哪个页里面，以及页里面的记录对应的 heap 是什么都记录到数据库表中分析，慢长等待跑数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//45543ac5b25cbe5f8652f5ff9375e031.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;数据分析完后通过分析发现存储一条数据的页对应的记录的 heap 值基本都是 3，正常应该是 2，意味着这些页并不是一开始就存一条数据，而是产生了页分裂导致的。&lt;/li&gt; 
 &lt;li&gt;开始继续再看页分裂相关的资料和代码，列出页分裂的各种情况，结合上面的信息构建了一个复现环境。插入数据页分裂核心函数。 
  &lt;ul&gt; 
   &lt;li&gt;btr_cur_optimistic_insert：乐观插入数据，当前页直接存储&lt;/li&gt; 
   &lt;li&gt;btr_cur_pessimistic_insert：悲观插入数据，开始分裂页&lt;/li&gt; 
   &lt;li&gt;btr_root_raise_and_insert：单独处理根节点的分裂&lt;/li&gt; 
   &lt;li&gt;btr_page_split_and_insert：分裂普通页，所有流程都在这个函数&lt;/li&gt; 
   &lt;li&gt;btr_page_get_split_rec_to_right：判断是否是向右分裂&lt;/li&gt; 
   &lt;li&gt;btr_page_get_split_rec_to_left：判断是否是向左分裂&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;heap&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;heap 是页里面的一个概念，用来标记记录在页里面的相对位置，页里面的第一条用户记录一般是 2，而 0 和 1 默认分配给了最大最小虚拟记录，在页面创建的时候就初始化好了，最大最小记录上面有简单介绍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;解析 ibd 文件&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;更快的方式还是应该分析物理 ibd 文件，能够解析出页的具体数据，以及被分裂删除的数据，分裂就是把一个页里面的部分记录移动到新的页，然后删除老的记录，但不会真正删除，而是移动到页里面的一个删除链表，后面可以复用。&lt;/p&gt; 
&lt;span id="OSC_h1_5"&gt;&lt;/span&gt; 
&lt;h1&gt;五、变更后，统计信息为什么差异巨大？&lt;/h1&gt; 
&lt;p&gt;表统计信息主要涉及索引基数统计（也就是唯一值的数量），主键索引的基数统计也就是表行数，在优化器进行成本估算时有些 SQL 条件会使用索引基数进行抉择索引选择（大部分情况是 index dive 方式估算扫描行数）。&lt;/p&gt; 
&lt;p&gt;InnoDB 统计信息收集算法简单理解就是采样叶子节点 N 个页（默认 20 个页），扫描统计每个页的唯一值数量，N 个页的唯一值数量累加，然后除以 N 得到单个页平均唯一值数量，再乘以表的总页面数量就估算出了索引总的唯一值数量。&lt;/p&gt; 
&lt;p&gt;但是当一个页只有 1 条数据的时候统计信息会产生严重偏差（上面已经分析出了表膨胀的原因就是一个页只存储了 1 条记录），主要是代码里面有个优化逻辑，对单个页的唯一值进行了减 1 操作，具体描述如下注释。本来一个页面就只有 1 条记录，再进行减 1 操作就变成 0 了，根据上面的公式得到的索引总唯一值就偏差非常大了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;static bool dict_stats_analyze_index_for_n_prefix(
    ...
    // 记录页唯一 key 数量
    uint64_t n_diff_on_leaf_page;
    
    // 开始进行 dive，获取 n_diff_on_leaf_page 的值
    dict_stats_analyze_index_below_cur(pcur.get_btr_cur(), n_prefix,
                                       &amp;amp;n_diff_on_leaf_page, &amp;amp;n_external_pages);
    
    /* 为了避免相邻两次 dive 统计到连续的相同的两个数据，因此减 1 进行修正。
    一次是某个页面的最后一个值，一次是另一个页面的第一个值。请考虑以下示例：
    Leaf level:
    page: (2,2,2,2,3,3)
    ... 许多页面类似于 (3,3,3,3,3,3)...
    page: (3,3,3,3,5,5)
    ... 许多页面类似于 (5,5,5,5,5,5)...
    page: (5,5,5,5,8,8)
    page: (8,8,8,8,9,9)
    我们的算法会（正确地）估计平均每页有 2 条不同的记录。
    由于有 4 页 non-boring 记录，它会（错误地）将不同记录的数量估计为 8 条
    */ 
    if (n_diff_on_leaf_page &amp;gt; 0) {
      n_diff_on_leaf_page--;
    }
    
    // 更新数据，在所有分析的页面上发现的不同键值数量的累计总和
    n_diff_data-&amp;gt;n_diff_all_analyzed_pages += n_diff_on_leaf_page;
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可以看到 PRIMARY 主键异常情况下统计数据只有 20 万，表有 400 百万数据。正常情况下主键统计数据有 200 百万，也与表实际行数差异较大，同样是因为单个页面行数太少（正常情况大部分也只有 2 条数据），再进行减 1 操作后，导致统计也不准确。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MySQL&amp;gt; select table_name,index_name,stat_value,sample_size from mysql.innodb_index_stats where database_name like 'sbtest' and TABLE_NAME like 'table_1' and stat_name='n_diff_pfx01';
+-------------------+--------------------------------------------+------------+-------------+
| table_name        | index_name                                 | stat_value | sample_size |
+-------------------+--------------------------------------------+------------+-------------+
| table_1           | PRIMARY                                    |     206508 |          20 |
+-------------------+--------------------------------------------+------------+-------------+
11 rows in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了避免相邻两次 dive 统计到连续的相同的两个数据，因此减 1 进行修正。&lt;/p&gt; 
&lt;p&gt;这里应该是可以优化的，对于主键来说是不是可以判断只有一个字段时不需要进行减 1 操作，会导致表行数统计非常不准确，毕竟相邻页不会数据重叠。&lt;/p&gt; 
&lt;p&gt;最低限度也需要判断单个页只有一条数据时不需要减 1 操作。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;六、统计信息与慢 SQL 之间的关联关系？&lt;/h1&gt; 
&lt;p&gt;当前 MySQL 对大部分 SQL 在评估扫描行数时都不再依赖统计信息数据，而是通过一种 index dive 采样算法实时获取大概需要扫描的数据，这种方式的缺点就是成本略高，所以也提供有参数来控制某些 SQL 是走 index dive 还是直接使用统计数据。&lt;/p&gt; 
&lt;p&gt;另外在 SQL 带有 order by field limit 时会触发 MySQL 内部的一个关于 prefer_ordering_index 的 ORDER BY 优化，在该优化中，会比较使用有序索引和无序索引的代价，谁低用谁。&lt;/p&gt; 
&lt;p&gt;当时业务有问题的慢 SQL 就是被这个优化干扰了。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# where 条件
user_id = ? and biz = ? and is_del = ? and status in (?) ORDER BY modify_time limit 5


# 表索引
idx_modify_time(`modify_time`)
idx_user_biz_del(`user_id`,`biz`, `is_del`)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;正常走 idx_user_biz_del 索引为过滤性最好，但需要对 modify_time 字段进行排序。&lt;/p&gt; 
&lt;p&gt;这个优化机制就是想尝试走 idx_modify_time 索引，走有序索引想避免排序，然后套了一个公式来预估如果走 idx_modify_time 有序索引大概需要扫描多少行？公式非常简单直接：表总行数 / 最优索引的扫描行数 * limit。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;表总行数&lt;/strong&gt;：也就是统计信息里面主键的 n_rows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;最优索引的扫描行数&lt;/strong&gt;：也就是走 idx_user_biz_del 索引需要扫描的行数&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;limit&lt;/strong&gt;：也就是 SQL 语句里面的 limit 值&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;使用有序索引预估的行数对比最优索引的扫描行数来决定使用谁，在这种改变索引的策略下，如果表的总行数估计较低（就是上面主键的统计值），会导致更倾向于选择有序索引。&lt;/p&gt; 
&lt;p&gt;但一个最重要的因素被 MySQL 忽略了，就是实际业务数据分布并不是按它给的这种公式来，往往需要扫描很多数据才能满足 limit 值，造成慢 SQL。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;七、如何临时解决该问题？&lt;/h1&gt; 
&lt;p&gt;发现问题后，可控的情况下选择在低峰期对表执行原生 alter table xxx engine=innodb 语句， MySQL 内部重新整理了表空间数据，相关问题恢复正常。但这个原生 DDL 语句，虽然变更不会产生锁表，但该语句无法限速，同时也会导致主从数据较大延迟。&lt;/p&gt; 
&lt;p&gt;为什么原生 DDL 语句可以解决该问题？看两者在流程上的对比区别。&lt;/p&gt; 
&lt;p&gt;&lt;img height="998" src="https://oscimg.oschina.net/oscnet/up-96cde8c478aed80cce1aa1079fe94b9d788.png" width="2314" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看出结构变更唯一不同的就是增量 DML 语句是等全量数据复制完成后才开始应用，所以能修复表空间，没有导致表膨胀。&lt;/p&gt; 
&lt;span id="OSC_h1_8"&gt;&lt;/span&gt; 
&lt;h1&gt;八、如何长期解决该问题？&lt;/h1&gt; 
&lt;p&gt;关于业务侧的改造这里不做过多说明，我们看看从变更流程上面是否可以避免这个问题。&lt;/p&gt; 
&lt;p&gt;既然在变更过程中复制全量数据和 binlog 增量数据回放存在交叉并行执行的可能，那么如果我们先执行全量数据复制，然后再进行增量 binlog 回放是不是就可以绕过这个页分裂问题（就变成了跟 MySQL 原生 DDL 一样的流程）。&lt;/p&gt; 
&lt;p&gt;变更工具实际改动如下图：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet//cfa56e38aaaf236bf1fc76e8c5f704d5.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;这样就不存在最大记录先插入到表中的问题，丢弃的记录后续全量复制也同样会把记录复制到临时表中。并且这个优化还能解决需要大量回放 binlog 问题，细节可以看看 gh-ost 的 PR-1378。&lt;/p&gt; 
&lt;span id="OSC_h1_9"&gt;&lt;/span&gt; 
&lt;h1&gt;九、总结&lt;/h1&gt; 
&lt;p&gt;本文先介绍了一些关于 InnoDB 索引机制和页溢出、页分裂方面的知识；介绍了业界通用的 DDL 变更工具流程原理。&lt;/p&gt; 
&lt;p&gt;随后详细分析了变更后表空间膨胀问题根因，主要是当前变更流程机制叠加单行记录过大的时候（业务表单行记录大小 5k 左右），会碰到 MySQL 页分裂的一个瑕疵，导致了一个页只存储了 1 条记录（16k 的页只存储了 5k，浪费 2/3 空间），导致存储空间膨胀问题。&lt;/p&gt; 
&lt;p&gt;最后分析了统计信息出错的原因和统计信息出错与慢 SQL 之间的关联关系，以及解决方案。&lt;/p&gt; 
&lt;p&gt;全文完，感谢阅读。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1. MySQL 单表为何别超 2000 万行？揭秘 B+树与 16KB 页的生死博弈｜得物技术&lt;/p&gt; 
&lt;p&gt;2. 0 基础带你精通 Java 对象序列化--以 Hessian 为例｜得物技术&lt;/p&gt; 
&lt;p&gt;3. 前端日志回捞系统的性能优化实践｜得物技术&lt;/p&gt; 
&lt;p&gt;4. 得物灵犀搜索推荐词分发平台演进 3.0&lt;/p&gt; 
&lt;p&gt;5. R8 疑难杂症分析实战：外联优化设计缺陷引起的崩溃｜得物技术&lt;/p&gt; 
&lt;p&gt;文 / 东青&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18692318</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18692318</guid>
      <pubDate>Fri, 19 Sep 2025 03:30:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>亚马逊云科技推出 Qwen3 与 DeepSeek-V3.1 模型的完全托管服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亚马逊云科技宣布，在 Amazon Bedrock 上新增 Qwen3 和 DeepSeek-V3.1 开放权重模型，这些模型现已在全球范围内正式可用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;公告称，亚马逊云科技致力于成为运行开放权重模型的最佳平台，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;此次新增模型进一步扩展了 Amazon Bedrock 上现已丰富的开放权重模型选择，Amazon Bedrock 上其他开放权重模型还包括来自 Meta、Mistral AI 和 OpenAI 的模型。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通过在 Amazon Bedrock 上使用这些模型，客户可以获得企业级的安全保障，包括数据加密和严格的访问控制，帮助客户保持数据隐私和满足合规要求。客户对其数据拥有完全控制权，这意味着亚马逊云科技不会与模型提供商共享客户的模型输入和输出数据，这些数据也不会用于基础模型的改进。此外，客户还可以设置安全保障措施，如亚马逊云科技推荐的 Amazon Bedrock Guardrails 来检测和防止模型幻觉。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亚马逊云科技客户现可使用四个 Qwen3 系列开放权重模型。这些模型具备多步骤工作流规划的能力，可与工具和 API 集成，并能在单个任务中处理长上下文窗口，其中两个通用模型还提供"思考"和"非思考"推理模式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3 系列模型支持多语言处理，尤其在中文和英文方面表现卓越，可帮助企业实现跨文化业务运营和内容创作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-Coder-480B-A3B-Instruct 和 Qwen3-Coder-30B-A3B 针对复杂的软件工程场景进行优化，包括代码生成和理解以及高级 Agentic 任务。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这些模型&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;不仅支持多种编程语言的代码编写，还能自主调用各类数字工具（如外部工具和应用程序）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen-3-235B-A22B-Instruct-2507 专为通用推理设计，在性能与效率间实现平衡，在代码、数学和通用推理等任务中都表现出色。"混合专家"（MoE）模型在处理每个请求时只激活部分参数，这意味着针对特定任务或问题，他们只调用相关知识，从而实现高性能和高效率。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-32B（Dense）则适用于在计算资源有限情况下的计算任务和应用程序，或者需要稳定、可预测性能的场景。与 MoE 模型类似专家团队只在需要时才激活他们的特定专业知识不同，"Dense"模型通常规模更小，所有组件始终协同工作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果把 Qwen3 系列模型拟人化，Qwen3-Coder 系列就像是那些注重细节的朋友，他们能够耐心地按照复杂的家具组装说明，一步步将散落的零件组装成一个完美的书柜，同时还能清晰地解释每个步骤。而通用型的 Qwen3 模型则像一个精通多国语言的大家庭，他们不仅能流利地使用数十种语言交流，还拥有百科全书般的知识储备，无论是讲解科学概念还是创作故事都游刃有余。他们可以就几乎任何话题展开深入对话，并且能记住之前对话中的每个细节，不管这段对话发生在多久之前。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最新的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faws.amazon.com%2Fbedrock%2Fdeepseek%2F" target="_blank"&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#0563c1"&gt;&lt;u&gt;&lt;span&gt;DeepSeek&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;模型 DeepSeek-V3.1 提供混合推理能力，在快速响应和深度、透明的思考间实现平衡。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;客户可以根据需求在两种模式间切换："思考模式"通过一步一步的解决问题，"快速响应模式"则适用于简单的问题，客户能够清晰地了解模型的决策过程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这个高度复杂的模型可与当今最先进的 AI 系统相媲美，而其 MoE（混合专家）架构意味着客户在享受卓越性能的同时还能优化计算成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DeepSeek-V3.1 支持多语言处理，在软件开发、数学推理和数据分析等领域表现出色，能够高效解决各类编程和技术挑战。同时，该模型特别适合构建如 AI Agents 和流程自动化等 Agentic 问题解决任务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果将 DeepSeek-V3.1 拟人化，它就像是擅长解决问题的好友，会通过逻辑推理系统地分解挑战，同时根据问题的复杂程度调整处理方式。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;亚马逊云科技 Amazon Bedrock 总监 Luis Wang 表示："开放权重模型代表着 AI 创新的重要前沿，这也是为什么我们不断投入使亚马逊云科技成为安全、规模化且具有成本效益地运行这些模型的最佳平台。我们认为没有一个模型能适合所有使用场景...很多客户喜欢使用开源模型，而开源模型的一大优势在于它能为用户提供更大的灵活性去探索和使用。"&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:justify"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;数据详解&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Qwen3-Coder-30B-A3B-Instruct 和 Qwen3-235B-A22B-Instruct-2507 模型可即刻处理高达 262K token 的上下文长度。在单次对话中，相当于约 20 万个字符或两部完整的长篇小说的内容量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;DeepSeek-V3.1 拥有 6,850 亿参数。参数可以理解为模型的"知识连接点"，是训练过程中不断调整的内部数值设置，帮助模型从数据中学习并做出预测。DeepSeek-V3.1 每次任务只调用相关知识部分，在保持强大性能的同时优化了运行成本。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根据&lt;/span&gt;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fartificialanalysis.ai%2Fmodels%2Fdeepseek-v3-1-reasoning%2Fproviders" target="_blank"&gt;&lt;u&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#0563c1"&gt;&lt;u&gt;&lt;span&gt;Artificial Analysis&lt;/span&gt;&lt;/u&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/u&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;,DeepSeek-V3.1 相比前代实现了显著提升，尤其是推理能力和 Agentic 技能方面。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373148</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373148</guid>
      <pubDate>Fri, 19 Sep 2025 03:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微盟集团获 2 亿美金投资，CEO 孙涛勇：迎接 Agentic Al 时代</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微盟集团&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F5VU-h0GWb8iFdDhjr7jpYA" target="_blank"&gt;发布公告&lt;/a&gt;称获得国际长线投资 2 亿美金。本轮融资将主要用于三大方面：首先是 AI 在 SaaS 中的整合和应用；其次是扩大媒体渠道及精准营销服务能力，深化在抖音及小红书等平台的生态布局；最后是积极推进海外业务发展，布局跨境出海业务等。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1576" src="https://static.oschina.net/uploads/space/2025/0919/110725_3DRL_2720166.png" width="1348" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微盟集团创始人、CEO 孙涛勇在朋友圈发文表示，感谢 Infini 的认可，下个十年必定是中国科技企业全球绽放的时刻，补充弹药迎接 Agentic Al 时代。&lt;/p&gt; 
&lt;p&gt;&lt;img height="872" src="https://static.oschina.net/uploads/space/2025/0919/110635_Qdu4_2720166.png" width="2034" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;微盟集团是中国的云端商业及营销解决方案提供商，面向电商零售、超市生鲜、商业地产、百货直销等行业提供数字化解决方案。公司成立于 2013 年，初期从微信公众号切入，定位于微信第三方服务商。据微盟集团发布的 2025 年 H1 财报显示，上半年总收入 7.75 亿，经调整同比增长 7.8%，经调整净盈利 0.17 亿。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373145</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373145</guid>
      <pubDate>Fri, 19 Sep 2025 03:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>传中国不买这款特供芯片，黄仁勋：很失望，但理解</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F09%2F17%2Fnvidia-ceo-disappointed-after-reports-china-has-banned-its-ai-chips.html" target="_blank"&gt;据 CNBC 报道&lt;/a&gt;，针对中国疑似停止采购 RTX Pro 6000D 专供芯片的报道，英伟达首席执行官黄仁勋在伦敦回应称感到「失望」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/110208_q1ir_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他说：「我们为中国市场所做的贡献或许超过了多数其他国家，所以看到如今的情况我很失望。但中美之间有更宏大的议程有待协调，我对此表示理解。」&lt;/p&gt; 
&lt;p&gt;英伟达在中国的业务近几年可谓跌宕起伏，黄仁勋用「过山车」来形容这一过程。他在新闻发布会上告诉媒体：「我们已经建议所有财经分析师不要再将中国市场纳入财务预测。原因很简单，因为这最终将取决于美国政府和中国政府之间的磋商。」&lt;/p&gt; 
&lt;p&gt;此前，美国已因国家安全为由，对英伟达多款出口中国的 AI 芯片实施限制，其中包括性能较低的服务器芯片 H20。但在今年八月，白宫宣布时任总统唐纳德·特朗普（Donald Trump）已与黄仁勋达成协议，英伟达可获出口许可，条件是 H20 在中国销售额的 15% 需上缴美国政府。&lt;/p&gt; 
&lt;p&gt;据路透社报道，知情人士称，RTX6000D 市场需求平淡，一些大型科技企业已选择不下订单。据了解，这款芯片主要用于 AI 推理任务，但业内普遍认为其性价比不高。&lt;/p&gt; 
&lt;p&gt;他们补充说，样品测试表明，这款芯片的性能不及 RTX5090。后者虽已被美国禁售，但仍能通过灰色市场渠道轻易买到，价格不到 RTX6000D 约 5 万元人民币售价的一半。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373142</guid>
      <pubDate>Fri, 19 Sep 2025 03:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌在 Chrome 浏览器中引入 Gemini</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌近日宣布将其人工智能技术 Gemini 整合到 Chrome 浏览器中，以应对来自 OpenAI 和 Perplexity 等初创公司的竞争压力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据谷歌的博客公告，Gemini 将为美国的 Mac 和 Windows 电脑用户以及移动设备用户提供服务。用户将能够通过 Gemini 更好地理解特定网页的内容，支持跨选项卡的工作，或者在单个选项卡内完成更多任务，例如安排会议或搜索 YouTube 视频。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-191a79fab5da45056a2a42522c9c9608b2d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;谷歌平台和设备&lt;span&gt;高级&lt;/span&gt;副总裁 Rick Osterloh 表示：「我们正在改进浏览器，以帮助用户充分利用网络，这在几年前是无法想象的。同时，我们也保持了 Chrome 在速度、简单性和安全性方面的优势。」&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;互联网浏览器是获取在线信息的关键工具，因此成为了各大公司争夺人工智能市场的焦点。长期以来，谷歌和苹果主导着大部分互联网流量，这也是美国司法部试图迫使谷歌剥离 Chrome 的原因之一。然而，最近一位法官裁定谷歌可以保留 Chrome，主要是因为生成式人工智能的出现已经显著改变了竞争环境。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;目前，人工智能公司们纷纷推出自己的浏览器，试图在用户体验上占据更多市场份额。例如，今年 1 月，OpenAI 推出了名为 Operator 的代理，可以在浏览器中完成购物等任务，此外还在开发基于开源 Chromium 代码的自家浏览器。与此同时，Anthropic 也推出了基于浏览器的人工智能代理，而 Perplexity 则在上个月发布了 Comet 浏览器，专注于人工智能任务。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新版本的 Gemini 与谷歌的日历、YouTube 和地图等应用深度整合，用户无需切换页面就能访问这些服务。谷歌产品副总裁 Mike Torres 在博客中提到，未来几周内，谷歌的企业生产力工具 Google Workspace 的用户也将能使用 Gemini，且会享有 「企业级数据保护」。此外，谷歌还介绍了 Gemini 的新代理功能，用户可以要求 Gemini 代理执行一些特定任务，例如预约理发或购买每周的杂货。这些功能原本是名为 「水手项目」 的内部项目的一部分，受到员工的欢迎。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在宣布此消息之前，谷歌要求用户注册某些订阅才能在 Chrome 中使用 Gemini，而现在这一功能的应用范围和功能都有了显著扩大。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373141</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373141</guid>
      <pubDate>Fri, 19 Sep 2025 03:00:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 与 Gemini 双双斩获 ICPC 2025 金牌</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fworldfinals.icpc.global%2F2025%2F" target="_blank"&gt;2025 国际大学生程序设计竞赛（ICPC）&lt;/a&gt;世界总决赛的平行 AI 测试中，OpenAI 与谷歌 Gemini 推理模型双双斩获金牌，其中 OpenAI 更是以满分成绩横扫全场，成为唯一全解团队。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0919/105648_LIMz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在为期 5 小时的比赛中，参赛队伍需解决 12 道高难度算法题。Gemini 成功攻克其中 10 题，并在 30 分钟内破解所有人类队伍未能解决的死亡 C 题。而 OpenAI 则以 12/12 的满分成绩碾压 139 支人类队伍，成为唯一实现 AK（All Kill）战绩的团队。&lt;/p&gt; 
&lt;p&gt;值得注意的是，OpenAI 所用模型中，11 道题目由 GPT-5 直接完成，最后一道最难题则由尚未公开的实验性推理模型解决，引发外界对下一代 AI 推理能力的高度关注。&lt;/p&gt; 
&lt;p&gt;谷歌方&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.google%2Ftechnology%2Fgoogle-deepmind%2Fgemini-gold-icpc%2F" target="_blank"&gt;面透露&lt;/a&gt;，Gemini 2.5 Deep Think 并未为 ICPC 进行专门训练，而是使用与 Gemini 应用中相同的模型，仅在推理能力上做了增强。该模型在比赛前 45 分钟内迅速解出 8 题，最终以 10 题成绩获得金牌。&lt;/p&gt; 
&lt;p&gt;OpenAI 背后的研究团队也在社交平台连发 8 条&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgdb%2Fstatus%2F1968404060001968429" target="_blank"&gt;推文&lt;/a&gt;庆祝胜利，并公开了部分关键研究人员身份。其中包括 ICPC 2015 世界冠军成员 Borys Minaiev 以及 OpenAI 首席科学家 Jakub Pachocki —— 同样是 ICPC 金牌得主。&lt;/p&gt; 
&lt;p&gt;ICPC 全球执行董事 BILL POUCHER 博士表示：「AI 在 ICPC 上斩获金牌，标志着人工智能工具已具备定义下一代学术标准的能力。它不仅能辅助程序员解决问题，更将在药物设计、芯片开发等领域发挥巨大作用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373139/openai-gemini-gold-icpc</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373139/openai-gemini-gold-icpc</guid>
      <pubDate>Fri, 19 Sep 2025 02:57:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>《我们为何迟迟不发布 Furion v5？》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;img height="663" src="https://oscimg.oschina.net/oscnet/up-24099bcabd6ea99a39ef5a6fbe97e46b691.jpg" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;几乎每一天，都会有用户问我：「Furion v5 什么时候发布？」&lt;/strong&gt;而我总是不厌其烦地回复同一句话：「发布时会通知大家。」&lt;/p&gt; 
&lt;p&gt;是啊，原本计划在 2023 年 11 月 10 日发布的 v5 版本，算起来已经推迟了近两年。其中的原因，我在不同场合也陆续提到过——&lt;strong&gt;自 Furion 尝试商业化以来，发生了太多事情，我个人的经历和想法都有了很大变化，心态也与从前不同。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;也许在一些原本就不太喜欢 Furion，或者更直接地说，不太喜欢我（百小僧）的人看来，这听起来像是个借口。仔细想想，倒也合理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;其实 Furion v5 在两年以前就已经开发完成。而现在对我而言，重点不是「发布」，而是如何「延长 Furion 的市场生命力」。&lt;/strong&gt;这话听起来可能有点模糊，我也可以稍微解释得含蓄一些：&lt;strong&gt;细水长流，远比昙花一现更重要；让人持续期待，也比轻易得到更有价值。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;开源 Furion 这五年来，经历了太多，牺牲了太多，承担了太多。&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;u&gt;&lt;strong&gt;我觉得我只有好好的生活，我才能有更多的灵感，去更好的创作和开源 Furion。&lt;/strong&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-d942d1fd0dec53b6def00016bd74425e3dc.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="972" src="https://oscimg.oschina.net/oscnet/up-c1f0ee702076488f62cc74ae6cd7f3c20c4.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="971" src="https://oscimg.oschina.net/oscnet/up-c0072bace93611f2ca6ce43a413ff51fa67.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="968" src="https://oscimg.oschina.net/oscnet/up-877912c5a4eb0def8d57be4bd05ab52522f.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="971" src="https://oscimg.oschina.net/oscnet/up-575a2141d77c5ab961c69bcbdd955a18bb0.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-7500a6b0fb39a8ed6096259a3c0b3698e8e.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-5d249d3e5c745c63d82f693b7d52ccc93f2.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="970" src="https://oscimg.oschina.net/oscnet/up-18c18fbaec13c5ba6d325eae9643b980e20.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="969" src="https://oscimg.oschina.net/oscnet/up-c3464b391f1846d1ee6b77fc8f7469c1c88.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/373475</link>
      <guid isPermaLink="false">https://www.oschina.net/news/373475</guid>
      <pubDate>Wed, 17 Sep 2025 20:02:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
  </channel>
</rss>
