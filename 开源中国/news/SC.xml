<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 18 Jul 2025 07:47:48 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>美团开源 OIBench 与 CoreCodeBench</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;Meituan-M17 团队联合上海交大等机构，分别推出了 OIBench（聚焦高区分度算法题评测）与 CoreCodeBench（聚焦多场景工程级代码基准）两大数据集，旨在揭示大模型编程能力真实水平，这两大数据集已分别在 GitHub 和 Huggingface 上进行开源。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-03ba67b8aecb4f3bfded919a2a68ff949fc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;当前，大语言模型（LLMs）在编程领域的能力宣称引人瞩目——DeepMind 的 AlphaCode 曾对标人类竞技编程选手，OpenAI 顶尖模型屡被报道通过谷歌面试、挑战 LeetCode 表现不俗。然而，当深入审视这些模型在真实、复杂场景下的表现时，现有评估体系的深层局限性便暴露无遗，形成了显著的「宣传与现实的认知鸿沟」。&lt;/p&gt; 
&lt;p&gt;一方面，在&lt;strong&gt;算法能力评估&lt;/strong&gt;上，尽管模型在传统基准（如 HumanEval、MBPP）上通过率高达 90%，但移植到更高难度的信息学奥赛或 Codeforces Div.2 C 级题目时，顶尖模型的通过率骤降至个位数或不足 15%，远逊于人类选手（如 ACM 校队成员平均 70%），动态规划等题型错误率甚至超 80%。传统评测集已「饱和」且区分度不足，新引入的高难度题目又面临数据「泄漏」风险和人机对比（Elo）的复现性差、效率指标粗略等问题。&lt;/p&gt; 
&lt;p&gt;另一方面，转向&lt;strong&gt;真实工程能力评估&lt;/strong&gt;，问题同样严峻。现有工程基准（如 FullStackBench、SWEBench）虽在多样性和语言覆盖上有进展，但其任务类型主要集中於单段落代码生成，难以覆盖真实开发中跨文件协作、代码修复（BugFix）、测试驱动开发、多函数协同等核心环节。数据构建方法也受限于随机挖空（易忽略核心逻辑）或依赖稀缺的 GitHub PR 记录（需大量人工清洗标注），导致评测「偏科」，无法科学、全面地评估模型在复杂工程中的准确性、健壮性和适用性。&lt;/p&gt; 
&lt;p&gt;为了系统性地解决这两大评估困境——&lt;strong&gt;更真实地衡量顶尖模型的算法推理能力与更全面地评估其工程级代码能力&lt;/strong&gt;——Meituan-M17 团队联合上海交大等机构，分别推出了 OIBench（聚焦高区分度算法题评测）与 CoreCodeBench（聚焦多场景工程级代码基准）两大数据集，并托管于 AGI-Eval 评测社区。下文将详细介绍它们的构建理念、评测方法及对主流大模型能力的深度剖析。&lt;/p&gt; 
&lt;h1&gt;OIBench 篇&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/707a2d1d2bf198c2510043dcd4fb1663877512.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;背景：评测集局限性的深层分析&lt;/h2&gt; 
&lt;p&gt;尽管 GPT-4o 模型被冠以 "竞赛级" 头衔，甚至有声音称其算法水平接近 ACM 区域赛金牌选手，但实际在面对未经大量公开数据训练的、更高难度的信息学奥赛级别问题时，其通过率却往往低至个位数，与 985 级别高校 ACM 校队成员的平均通过率存在显著差距。&lt;/p&gt; 
&lt;p&gt;当部分评测宣称 Claude 3.5 Sonnet 可替代中级开发人员时，它在动态规划等高难度题型中错误率却高达 80% 以上，且无法独立完成需数学建模的复杂竞赛题。&lt;/p&gt; 
&lt;p&gt;诸如文心一言、通义千问等模型在 MBPP 基础题库中通过率可达 90% 以上，但移植至 Codeforces Div.2 C 级题目时，通过率却不足 15%，远低于人类选手平均 70% 的水平。&lt;/p&gt; 
&lt;p&gt;这些鲜明的对比，共同指向一个核心问题：当前对 LLM 编程能力的评估，存在明显的 "宣传与现实的认知鸿沟"。这种差异不仅源于模型能力边界的复杂性，也暴露出现有评估体系的诸多局限性。具体表现为：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;评测集 「饱和」 与区分度不足&lt;/strong&gt;：传统评测集（如 HumanEval、MBPP）由于模型能力的快速提升，通过率普遍超过 90%，已无法有效区分最先进模型的细微优劣。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据 「泄漏」 风险&lt;/strong&gt;： 尽管一些新评测集（如 Codeforces、USACO、LeetCode）引入了高难度题目，但由于大模型预训练数据包含大量互联网公开内容，这些题目可能已被模型 「见过」，导致评测结果虚高，无法真实反映其推理能力。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;人机对比的局限性&lt;/strong&gt;：现有基于 Elo 评分体系的模型与真人选手对比方法，存在周期长、选手水平波动大、复现性差等问题，难以提供精确且可靠的评估。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;效率指标的粗略性： 部分评测虽引入运行时间、内存等效率指标，但通常仅为粗略的平均分，无法细致反映模型在不同类型题目上的性能差异。&lt;/p&gt; 
&lt;p&gt;为了解决上述这些评估困境、评测出全球顶尖模型真实的编程能力，&amp;nbsp;Meituan-M17 团队推出了&lt;strong&gt;更真实、更具区分度的评估基准 OIBench 数据集，并托管于 AGI-Eval 评测社区&lt;/strong&gt;，并在 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fmeituan%2FOIBench" target="_blank"&gt;Huggingface&lt;/a&gt; 和 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FOIBench" target="_blank"&gt;GitHub&lt;/a&gt; 上开源。基于此数据集，我们对全球 18 个主流大模型的算法编程能力进行了系统评测并量化得分，详细评分榜单如下所示，可以看到全球顶尖大模型距离以往所宣称的编程能力还存在很大差距，哪怕是最高分的 o4-mini-high 也仅仅只有 36.35 分，距离人类竞赛选手的水平还相差甚远，甚至很多模型只有个位数的得分。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/c15ae4d3cace0307a614ece0854b52e071970.png" alt="表 1: OIBench AC Rate 表" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 的评测榜单未来将由 AGI-Eval 评测社区长期维护更新，欢迎持续关注。榜单地址如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;网页端地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fevaluation%2Fdetail%3Fid%3D60" target="_blank"&gt;https://agi-eval.cn/evaluation/detail?id=60&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;微信公众号文章&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqjZLqHVz-BxQweApyUEtDw" target="_blank"&gt;AGI-Eval 大模型评测&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;论文地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10481" target="_blank"&gt;https://arxiv.org/abs/2506.10481&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Github 地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FOIBench" target="_blank"&gt;https://github.com/AGI-Eval-Official/OIBench&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文数据均引用自 OIBench v1.0 论文（arxiv:2506.10481v3），发布日期 2025 年 6 月 13 日。&lt;/p&gt; 
&lt;p&gt;接下来为大家详细介绍 OIBench 数据集是如何构建以及如何对大模型进行评测的。&lt;/p&gt; 
&lt;h2&gt;1. OIBench 的构建与创新&lt;/h2&gt; 
&lt;p&gt;OIBench 是一个高质量、私有且极具挑战性的信息学奥赛级别算法题库，旨在提供一个更真实、更具区分度的评估基准。该数据集的算法题主要来源于中国 ACM-ICPC 队伍和信息学奥赛的高校教练团队精心编纂，他们拥有丰富的高难度算法题设计经验和独到见解。&lt;/p&gt; 
&lt;p&gt;为了确保 OIBench 题目的高质量和高挑战性，我们制定了三条严格的准入标准，OIBench 具备以下关键特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;原创性与私有性&lt;/strong&gt;：OIBench 包含 250 道候选题目，经难度验证后保留 212 道高难度、防泄漏的信息学奥赛题目（IOI Level）。所有题目在发布前都经过严格检索，确保未在任何公开平台出现，最大程度避免数据污染风险。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;难度分级与把控&lt;/strong&gt;：每道题目都参照信息学竞赛和 Codeforces 难度评级进行标注。同时，为避免主观偏差，我们引入了自动化验证机制 —— 只有当 GPT-4o、Qwen2.5-Coder-32B、Doubao-32k-pro、Llama3.1-405B 这几个标杆大模型中 「最多只有一个模型能解出」 时，该题才会被收录，从而确保了题目的 「硬核」 难度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;高标准测试用例与标准解答&lt;/strong&gt;：每道题都配备覆盖大数据量、边界情况等多样的测试用例，力求暴露代码在时间和空间上的潜在瓶颈。同时，每道题都必须配备经过所有测试用例严格验证的 C++ 标准解答，以确保题目本身的准确性及评测的公正性。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;中英文双语支持&lt;/strong&gt;： 数据集提供中英文双语版本，方便全球大模型从业者使用。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们还在论文中展示了 OIBench 与其他主流评测集的对比（见下表），可以看到 OIBench 在题目难度和测试用例规模上都相对更高。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/ad5a7a3767a8e629b0b759e2c2b7cea864999.png" alt="表 2: OIBench 与其他代码评测集基础统计信息表" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 在题目难度和测试用例规模上显著领先于其他主流评测集。例如，在其他榜单上表现较好的 GPT-4o 模型在 OIBench 上仅能答对 2.6% 的题目，同时 OIBench 的测试用例数量大幅超过了其他算法竞赛基准，对标真实的竞赛环境。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/18647fd505aefa45fcc54194188f0ef121519.png" alt="表 3: GPT-4o 模型在 OIBench 与其他评测集通过率对比表 " referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;强抗数据污染能力&lt;/strong&gt;：在评测集设计中，「同源污染」 是一个重要挑战。由于大模型的预训练和微调数据往往会爬取大量互联网内容，容易出现模型在训练阶段就见过类似题目的情况，从而导致评测分数虚高，无法真实反映模型实际能力。虽然 OIBench 在数据构造时极力避免使用互联网可公开检索的题目，但一些相近的题目仍可能在大模型的预训练或微调阶段带来数据污染。为此，我们专门设计了实验来验证 OIBench 的抗污染能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;具体做法&lt;/strong&gt;：我们从 OIBench 中抽取部分题目，模拟它们在模型训练数据中 「泄漏」 的场景，并与常规训练数据混合，对比模型在 OIBench 上的表现提升。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;实验证明&lt;/strong&gt;：即使模拟少量题目 「泄漏」 到模型的训练数据中，OIBench 的得分提升也极为有限，风险分数几乎为零，表明其对数据污染具有很强的鲁棒性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. OIBench 评测结果与发现&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;参评模型与评测方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 对 18 个主流大模型（包括 14 个指令微调模型和 4 个基础模型）进行了 zero-shot 评测，涵盖 C++、Python、Java、JavaScript 四种语言。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/eb24e8bc42ce3120a20be682dae41ff3240284.png" alt="表 4:  OIBench 上基座模型、指令微调模型、推理模型的表现" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主榜单结果&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;推理模型表现突出&lt;/strong&gt;：推理类模型（如 o4-mini-high）在 OIBench 上的平均得分高达 21.4%，远高于普通指令微调模型（约 3.6%）。这表明 OIBench 能有效区分模型的推理和链式思考能力，且 o4-mini-high 在所有语言和任务上表现最优。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;闭源模型优势明显&lt;/strong&gt;：闭源模型平均得分 14.5%，显著高于开源模型（6.3%），这主要得益于闭源模型在算力和数据质量上的优势。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基础模型决定上限&lt;/strong&gt;：指令微调模型在 OIBench 上的表现高度依赖其基础模型的能力，说明基础模型的预训练质量是决定代码能力的关键。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek-V3-0324 的亮点&lt;/strong&gt;：作为非推理模型，DeepSeek-V3-0324 表现突出，得益于其采用了 DeepSeek-R1 的链式推理蒸馏方案，推理能力大幅提升。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;语言偏好与中英文差异&lt;/strong&gt;： 模型在 JavaScript 和 Python 上的表现平均比 C++ 和 Java 低 10% 以上，可能与训练数据分布有关；中英文题目表现差异极小，甚至中文略优。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;伪代码（Pseudocode）提示的积极作用&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;OIBench 的高难度对普通模型来说挑战巨大。为了更细致地分析模型的能力，我们还引入了 「伪代码提示」 评测：将标准解答转为伪代码并作为提示输入，考查模型理解和复现解题思路的能力。&lt;/p&gt; 
&lt;p&gt;结果显示，所有模型在有伪代码提示时表现均有明显提升，尤其是强推理模型（如 o3-mini-high 和 o4-mini-high）提升尤为显著。这说明伪代码极大降低了题目的推理难度，更能考查模型的代码理解与生成能力。同时，推理模型在理解解题思路方面依然具备优势。进一步分析发现，指令微调模型的表现与其基础模型高度相关，说明代码生成能力主要取决于预训练水平。&lt;/p&gt; 
&lt;p&gt;在提供伪代码提示后，所有模型表现均有明显提升，尤其是强推理模型，这说明伪代码能有效降低推理难度，更能考查模型的代码理解与生成能力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推理效率&lt;/strong&gt;：随着 「测试时推理」 成为提升大模型能力的重要手段， OpenAI-o1、DeepSeek-R1 等模型在解题时会生成大量推理内容。我们统计了各模型推理时的 Token 消耗与通过率的关系，发现 o4-mini-high 能以更少的 Token 解出更多题目，推理效率最高；DeepSeek-V3-0324 虽然表现不俗，但推理 Token 数量也最多，体现其长链推理的特点。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/ea497e4d24ab1e6451de79600bcf9a9d150460.png" alt="图 1: OIBench 模型通过率与推理消耗 Token 量关系图" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;3. 模型与人类选手的对比&lt;/h2&gt; 
&lt;p&gt;许多技术人员都关心：现在的大语言模型在算法编程题上的表现，和真正的竞赛选手相比到底如何？OpenAI、 DeepSeek 会用线上编程平台 Codeforces 的 Elo 评分体系来做模型与人类的对比，并报告自家模型最新的 Elo 分数，但这种方式存在一些问题：比如数据时间跨度长（一般需要半年以上的参赛记录）、在线选手水平波动大，导致对比结果不够精确，也不容易复现。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OIBench 创新性地采用了更可控的方法&lt;/strong&gt;：邀请了中国 985 级别高校 ACM 校队选手参与部分题目的作答，并将其成绩与大模型直接对比，提供了更精准、可复现的人机对比数据；我们用小提琴图展示了每个模型在所有人类选手中的排名分布，能直观反映模型与人类在不同题目上的表现差异。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;排名规则参考了信息学奥赛（IOI）的标准&lt;/strong&gt;：先比较通过的测试用例数量，数量相同则按运行时间排序（越快越高）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;提交标准&lt;/strong&gt;：人类选手的答案以最后一次提交为准。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;人类解答开源&lt;/strong&gt;: 分析中所涉及的人类解答记录也将匿名化并开源，便于后续研究和复现。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/364b49bcc6369d303486297b86de3364257727.png" alt="图 2: 模型与人类选手的对比关系图" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在小提琴图中，各模型在每道题中的人类排名位置会作为一个数据点，这些数据点形成的概率密度图就是小提琴图中的「琴身」。「琴身」的宽度显示模型排名分布的密度，越宽表示模型在对应的排名区间内出现的频率越高，从而直观地反映出模型排名表现的集中趋势。中央的框线代表排名数据最集中的区域，以 o4-mini-high 举例，它的排名大致超过了 42% 的人类选手。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;三种类型的模型表现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;低谷型&lt;/strong&gt;： 多数题目排名靠后，只能超越不到 20% 的人类选手，多为没有长链推理能力的模型。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;双峰型&lt;/strong&gt;： 在部分题目上能超越一半人类选手，但在另一些题目上表现较差，多数支持长链推理的模型属于此类型，显示其在特定题型上的优势和短板。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;橄榄型&lt;/strong&gt;： 排名分布更均匀，表现更接近人类整体能力分布，目前只有 o4-mini-high 具备这种全面和稳定的推理特征。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4. OIBench 总结与展望&lt;/h2&gt; 
&lt;p&gt;本文深入分析了当前大模型编程能力评估中存在的认知鸿沟，揭示了 "宣传" 与 "现实" 之间的差距。Meituan-M17 团队，通过 OIBench 这一高质量、高区分度的私有数据集，清晰揭示了顶级 LLM 在面对复杂算法挑战时，与人类顶尖水平之间的真实差距。不仅为大语言模型的算法推理能力评测树立了一个全新标杆，也为整个行业带来了更多思考。&lt;/p&gt; 
&lt;p&gt;它让我们看到：即使在模型能力突飞猛进的今天，真正高质量、高难度的算法挑战依然能够 "难倒" 最先进的 AI。尤为重要的是，希望 OIBench 的开源和透明能够为社区协作和持续创新做出一些贡献。我们期待它能成为连接学术、产业和开发者的桥梁，推动大模型在算法智能领域迈向新高度。未来，随着模型能力和评测需求的不断演进，OIBench 也会持续迭代，与大家共同见证 AI 推理的进化之路。&lt;/p&gt; 
&lt;p&gt;与此同时，我们也观察到，对于大多数人类开发者来说，即使他们接受过专业的算法设计训练，面对高难度算法和复杂系统设计，同样需要工具和智能助手的辅助才能更上一层楼。大模型的强大推理和代码生成能力，正好能为人类开发者提供有力支持，帮助他们提升算法设计和代码实现的效率。OIBench 促使我们深入思考：&lt;strong&gt;未来的代码开发，已超越 "人" 或 "模型" 单打独斗的模式，转变为人机协同、优势互补的新范式&lt;/strong&gt;。&lt;/p&gt; 
&lt;h1&gt;CoreCodeBench 篇&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-ceb6f19f2da88e2f684c177f14580a6a10d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;背景：工程级代码评估的挑战&lt;/h2&gt; 
&lt;p&gt;研究发现，现有的代码基准数据集在面对复杂的工程场景时普遍存在缺乏多样性和可控性的双重问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;工程开发环节覆盖有限&lt;/strong&gt;：尽管现有基准（如 FullStackBench、SWEBench）在领域和语言多样性上取得进展，但其任务类型仍主要集中於单段落代码生成。而真实工程实践通常涉及跨文件、跨模块的协同，以及代码修复、测试驱动开发、多函数协作等复杂任务，这些都应被工程级基准全面覆盖。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;数据构建方法局限&lt;/strong&gt;：大多数数据集采用随机挖空或从代码仓库的历史&amp;nbsp;PR&amp;nbsp;记录中提取修改点（如 GitHub 的 Pull Request）。前者容易忽略项目的核心逻辑代码段，后者不仅数据量稀少，还需投入大量人工进行数据清洗和标注，难以规模化构建高质量的评测题目。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;总之，我们发现现有的代码基准测试大多「偏科」了。它们要么只关注单个函数的补全，忽略了开发者修复 Bug 、根据单元测试反向开发的真实场景；要么采用随机挖空的方式，难以触及代码的核心逻辑。这导致我们无法科学、完整、全面地测评 LLM 在真实工程场景中的代码能力，尤其是在可靠性和适用性方面，我们亟需一个能解决此难题的方案。&lt;/p&gt; 
&lt;p&gt;为了应对上述挑战，&amp;nbsp;Meituan-M17 团队、上海交大联合发布了一个全新的&lt;strong&gt;大模型工程级别代码基准测试&amp;nbsp;CoreCodeBench 数据集，托管到 AGI-Eval 社区&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CoreCodeBench 榜单地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fevaluation%2Fdetail%3Fid%3D64" target="_blank"&gt;https://agi-eval.cn/evaluation/detail?id=64&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;微信公众号文章&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FihNeyk1RauSUicBcGWI2pA" target="_blank"&gt;AGI-Eval 模型评测&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;论文预印版&lt;/strong&gt;：《CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark》。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/6db13f36c76ac08f4e76f2301112430f132450.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;论文地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Farxiv.org%2Fabs%2F2507.05281" target="_blank"&gt;http://arxiv.org/abs/2507.05281&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub 地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAGI-Eval-Official%2FCoreCodeBench" target="_blank"&gt;https://github.com/AGI-Eval-Official/CoreCodeBench&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;它专注于评估大语言模型在真实工程项目中的综合代码能力，覆盖了从代码开发到代码修正的多个核心阶段。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/d00f4a444d9cce46b92a9ca1c04ff32b141353.png" alt="图 3: CoreCodeBench 题型展示" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p1.meituan.net/meituantechblog/e7d7f6245abec170dad5a1910d4aecf963987.png" alt="图 4: CoreCodeBench 模型能力榜单" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过在 CoreCodeBench 上对当前主流大语言模型的全面评测，我们得出了以下关键结论：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;大模型编程能力迭代进步显著，但发展不均衡&lt;/strong&gt;：较新的模型 {如 Claude 3.7 、o4 mini（high）} 相较于前代产品表现出明显进步。然而，受测模型在代码修正（BugFix）任务上表现欠佳，尤其是单函数任务场景下，修正任务的成功率全部低于开发任务，这揭示了当前 LLM 在理解和修复深层逻辑错误方面存在的普遍短板。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;多函数协作是当前大模型编程场景的主要瓶颈&lt;/strong&gt;：几乎所有模型在处理多函数任务时的表现都显著劣於单函数任务。这表明，当需要同时处理多个函数间的依赖关系、调用逻辑和协同实现时，当前大模型的跨函数推理和规划能力尚显不足。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;大模型编程场景普遍缺乏灵活的规划与分层推理能力&lt;/strong&gt;：在多函数代码生成任务中，我们观察到大多数模型严格遵循输入提示中的函数顺序生成代码，而非像人类工程师那样，基于功能依赖（如先实现被调用的工具函数）进行优化。这一现象反映了当前模型在面对复杂任务时，倾向于采用默认的顺序策略，缺乏主动规划的意识。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;1. 基准构建方法与实验分析&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;数据集构建方法：CorePipe 流程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为了构建一个既关注多样化工程问题，又聚焦于核心代码的基准，CoreCodeBench 中设计了从工程代码仓库到多种函数题型的全自动化构建流程 CorePipe。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/c0fafa80ae9fcd7b85d7bca671ec2934319541.png" alt="图 5: CorePipe 自动化生产数据流程示意图" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，CorePipe 基于函数调用树，系统化地生成覆盖三大核心场景的单函数与多函数题目，确保每一道题目都直击「要害」：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;精选真实项目&lt;/strong&gt;：我们从 PyPI 对应的 GitHub 仓库中筛选出高活跃度、高测试覆盖率和高技术复杂度的顶级开源项目。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;定位核心代码&lt;/strong&gt;：通过动态和静态追踪代码的执行，我们首先构建函数调用图，再利用抽象语法树（AST）抽取出关键函数中的核心代码，精准定位项目中那些「牵一发而动全身」的核心代码块。我们能精准定位项目中那些「牵一发而动全身」的核心函数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;模拟三大真实场景&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;直接开发&lt;/strong&gt;（Development）：&amp;nbsp;不仅仅是填空，我们利用 GPT-4o 生成高质量的函数功能描述，并由 Claude 3.5 Sonnet 进行「挑刺」和审核，确保模型是在理解真正需求的前提下进行开发。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代码修正&lt;/strong&gt;（BugFix）：告别简单的语法错误，转而使用 LLM 生成更隐蔽、更复杂的逻辑错误，真实模拟了开发中那些令人头疼的 Bug 。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;测试驱动开发&lt;/strong&gt;（TDD）：提供完整的单元测试，要求模型根据测试用例反向开发功能代码，考察其遵循现代开发范式的能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;引入多函数难题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们将上述单函数问题按照真实的函数调用关系组合起来，创造出更复杂的多函数题目，全面考验模型在宏观层面的代码组织和规划能力。&lt;/p&gt; 
&lt;h2&gt;2. 实验结果与深度分析&lt;/h2&gt; 
&lt;p&gt;为确保评测的科学性，我们采用了信息增益分数（IG Score）作为核心指标，并通过&amp;nbsp;&lt;strong&gt;IG Filter（信息增益过滤）和专业工程师人工审核（最终合格率 78.55%）&lt;/strong&gt; 对题目质量进行充分的监测，兼具&lt;strong&gt;可读性、准确性和完整性&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;2.1 单函数与多函数任务分析&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/3880e195179b9c7170e4b2dc56760d0e155540.jpg" alt="表 5: CoreCodeBench 单函数和多函数任务榜单" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图可以看出，实验结果有力地支持了我们的核心结论， Claude 3.7 在所有任务中表现突出。&lt;/p&gt; 
&lt;p&gt;但所有模型在多函数任务上的普遍表现下滑差於单模型任务，这可能是因为多函数任务需同时处理多个函数间的依赖关系、调用逻辑和协同实现，对大语言模型的跨函数推理和规划能力要求更高，以及在 BugFix 任务上的集体短板，清晰地勾勒出当前技术的能力边界。&lt;/p&gt; 
&lt;h3&gt;2.2 模型规划能力洞察&lt;/h3&gt; 
&lt;p&gt;多函数任务的实验分析揭示，&lt;strong&gt;模型缺乏对实现顺序的规划能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;大多数模型严格遵循输入提示中的函数顺序生成代码。当前模型在多函数代码生成时缺乏灵活规划能力与分层推理能力，往往采用默认的顺序输出策略，而非基于逻辑或功能依赖进行优化。&lt;/p&gt; 
&lt;p&gt;这种「顺序执行」而非「逻辑执行」的策略，是其与人类工程师在解决复杂问题思路上的一大差异。&lt;/p&gt; 
&lt;h3&gt;2.3 极限挑战&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/014baa15a3e9fa538f8946e1ef87a6cc169891.png" alt="图 6: CoreCodeBench-Difficult 数据集的模型结果" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们通过放宽多函数问题的复杂度限制，构建了&amp;nbsp;CoreCodeBench-Difficult&amp;nbsp;数据集。&lt;/p&gt; 
&lt;p&gt;在该测试中，所有模型的通过率均低于 30%，这不仅印证了该基准在揭示模型局限性方面的有效性，也为未来技术的突破提供了严苛的测试平台。&lt;/p&gt; 
&lt;h3&gt;2.4 LLM 代码能力全景雷达图&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/968a856ea20107dbef5236fbb904b6f8249232.png" alt="图 7: 前沿 LLM 代码能力雷达图" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们将模型的六个核心场景表现绘制成雷达图，可以直观地看到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;没有一个模型能在所有场景中独占鳌头，证明了 CoreCodeBench&amp;nbsp;&lt;strong&gt;评估维度的全面性&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;开发（Development）和测试驱动开发（TDD）任务中，单/多函数表现并不完全相关，说明&lt;strong&gt;开发多关联函数需要额外的规划能力&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;代码修正（BugFix）任务中，单/多函数表现高度相关，这说明&lt;strong&gt;调试更依赖于一种通用的、局部的错误修正技能&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为进一步分析各评测维度之间的关系，我们计算了所有模型在六个维度上的皮尔逊相关系数并绘制热力图。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/855a4c86166ab69686d5b2daa2504e56137569.png" alt="图 8: 代码能力项相关度分析" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示可以观察得到，相关系数的测算结果表明，CoreCodeBench 的六个核心场景之间既存在一定的&lt;strong&gt;相关性&lt;/strong&gt;，也体现出各自的&lt;strong&gt;差异性&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Single-function 任务之间相关性较高，表现出&lt;strong&gt;单函数任务在基础编程、理解和实现能力上的共性&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;Multi-TDD 和 Multi-Development 存在一定的相关性，这是因为&amp;nbsp;&lt;strong&gt;Multi-function 任务通常考察模型在更复杂场景下的综合能力&lt;/strong&gt;，包括多步推理、实现规划等，与单函数任务所需的基础能力存在明显区别。&lt;/li&gt; 
 &lt;li&gt;Multi-BugFix&amp;nbsp;虽然属于多函数任务，但它和单函数任务相关性高，反而和 Multi-TDD、Multi-Development 相关性低。这是因为&amp;nbsp;&lt;strong&gt;Multi-BugFix&amp;nbsp;任务的本质更接近于「单点排查」，它更侧重于具体细节或某一局部的能力考察，而与需要全局综合能力的多函数任务存在差异&lt;/strong&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3. CoreCodeBench 总结与展望&lt;/h2&gt; 
&lt;p&gt;CoreCodeBench&amp;nbsp;的构建与应用，旨在为大语言模型的代码能力评估提供一把更科学、更全面、更贴近真实的「工程标尺」。回顾我们的研究，我们系统性地揭示了当前顶尖 LLM 在真实工程场景中的核心短板：&lt;strong&gt;无论是多么先进的模型，都在逻辑错误修复方面步履维艰；在面对多函数协同任务时，其跨函数推理与规划能力都显得捉襟见肘；并且，它们普遍缺乏人类工程师所具备的灵活规划与分层推理能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;然而，这些被揭示的局限性并非技术的终点，而是为下一代大语言模型的发展指明了清晰的优化方向。我们相信，通过在 CoreCodeBench 这类更贴近真实工程需求的基准上进行训练和迭代，大语言模型将能更快地从一个「代码片段生成器」，进化成一个真正具备分析、规划和解决复杂工程问题的「虚拟软件工程师」，从而在软件开发领域释放出更深远的变革力量。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;通过 OIBench 和 CoreCodeBench 两大基准的构建和评测，Meituan-M17 团队系统性地揭示了当前大语言模型在编程领域的真实能力边界。这两个数据集不仅填补了现有评估体系的空白，更重要的是为整个行业提供了一面"照妖镜"，让我们能够更清晰地看到顶尖 AI 模型与人类专业水平之间的真实差距。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心发现包括&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;即使是最强的推理模型，在复杂算法挑战面前仍显不足，距离真正的竞赛选手水平还有很大差距；&lt;/li&gt; 
 &lt;li&gt;在工程级代码任务中，模型普遍在代码修复和多函数协作方面存在明显短板；&lt;/li&gt; 
 &lt;li&gt;现有模型缺乏人类工程师所具备的灵活规划和分层推理能力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;展望未来&lt;/h2&gt; 
&lt;p&gt;这些发现并非技术发展的终点，而是为下一代大语言模型的优化指明了明确方向。我们相信，通过在更贴近真实需求的基准上持续训练和迭代，AI 将逐步从"代码生成工具"进化为真正的"智能开发伙伴"，与人类开发者形成优势互补的协作关系。&lt;/p&gt; 
&lt;p&gt;Meituan-M17 团队将持续致力于高质量评估研究，推动大语言模型技术向更广阔的未来发展。&lt;/p&gt; 
&lt;h2&gt;One More Thing - 从大模型到 Code Agent 的评测范式迁移&lt;/h2&gt; 
&lt;p&gt;当前大量涌现的 Code Agent 类框架与产品，使得人机协作解决更加复杂的工程问题成为可能，这预示着对 Code Agent 在实际工程场景中与人类协作能力的评估，将变得日益关键。然而，现有的 Code Agent 评测基准（如 SWE-bench 系列）存在一个核心问题：&lt;strong&gt;它们将人类开发者完全排除在评估流程之外&lt;/strong&gt;。这种 「端到端」 的自动化评测，虽然能比较容易的量化模型在封闭任务上的表现，却无法回答一个更关键的问题：在真实、开放的开发环境中，Code Agent 能否与人类高效协作？当前多数 Code Agent 框架在交互设计上对人机交互的忽视，导致其评测结果与实际应用价值之间存在明显脱节。&lt;/p&gt; 
&lt;p&gt;结合 OIBench 引发的关于人机协同、优势互补的思考，Meituan-M17 团队也开始关注人机协作评测这一新的评测范式在 Code Agent 场景的应用，进而弥补当前范式引起的评测结果与实际应用价值间的鸿沟。基于此，我们与 AGI-Eval 评测社区合作，设计并计划举办一项创新的人机协作编程竞赛。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;竞赛核心设计如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;评测目标&lt;/strong&gt;：竞赛旨在真实模拟人类开发者与搭载不同大模型的 Code Agent 协作解决复杂工程任务的全过程。我们关注的不再仅仅是任务的最终成败，而是&lt;strong&gt;整个协作流程的质量与效率&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;关键指标&lt;/strong&gt;：我们将记录并分析一系列过程性指标，包括：模型的意图理解准确度、需求澄清的有效性、交互轮次、决策效率以及最终任务完成的质量与速度。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;评测流程如下&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/63a5fc4a1f67b4be5f31828f032fa30518009.png" alt="图 9: Code Agent 评估流程图" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;价值与产出&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;首个人机协作榜单&lt;/strong&gt;：我们将产出首个聚焦人机协作效能的 Code Agent 性能榜单，从模型硬实力（自主解决问题的能力）与协作流畅度（与人交互的体验）两大维度进行评估。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;深度洞察与改进&lt;/strong&gt;：这些宝贵的数据和洞察，将揭示当前 Code Agent 在真实协作场景下的优势与短板，为打造更智能、更实用的下一代开发工具提供坚实的实证依据，真正推动人机协同编程走向成熟。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这项竞赛不仅填补了现有评测体系的空白，更为探索未来人机协作的无限可能提供了宝贵的数据和实践参考。对这项比赛感兴趣的小伙伴，欢迎前往 AGI-Eval 评测社区了解详情。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/1c438755881e6541eff96bc9f0845d652459748.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;网页端地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fagi-eval.cn%2Fcompetition%2Factivity" target="_blank"&gt;https://agi-eval.cn/competition/activity&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;招聘信息&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;岗位名称：【北斗计划】基座大模型算法研究员（评测与探索）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着 AI 下半场的到来，传统的评测范式已经无法适配持续提升的模型能力，针对 ChatBot 模型的 Arena 评测的有效性也遭到质疑，如何面向现阶段以及未来的模型能力进行科学有效的评估本身也是个极具挑战和价值的研究方向。OpenAI 研究者也表示，AI 接下来比拼的不是训练，而是「如何定义并评估真正有用的任务」。&lt;/p&gt; 
&lt;p&gt;在这样的背景下，美团大模型评测团队以指引通往 AGI &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3A%E7%9A%84%E9%81%93%E8%B7%AF%E4%B8%BA%E7%9B%AE%E6%A0%87%EF%BC%8C%E6%B7%B1%E8%80%95%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E7%A0%94%E7%A9%B6%EF%BC%8C%E7%B3%BB%E7%BB%9F%E6%80%A7%E7%9A%84%E7%90%86%E8%A7%A3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BD%93%E5%89%8D%E8%83%BD%E5%8A%9B%E6%B0%B4%E5%B9%B3%E5%8F%8A%E6%9C%AA%E6%9D%A5%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%AD%A4%E4%B8%BA%E5%9F%BA%E7%A1%80%E5%AE%8C%E5%96%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E8%83%BD%E5%8A%9B%E7%9F%A9%E9%98%B5%E3%80%82%E6%AC%A2%E8%BF%8E%E5%90%84%E8%B7%AF%E8%8B%B1%E6%89%8D%E5%8A%A0%E5%85%A5%EF%BC%8C%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F%EF%BC%9Aliuxingyu10%40meituan.com%E3%80%82" target="_blank"&gt;的道路为目标，深耕模型评测研究，系统性的理解大模型当前能力水平及未来技术发展方向，并以此为基础完善模型评测能力矩阵。欢迎各路英才加入，联系方式：liuxingyu10@meituan.com。&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;| 关注「美团技术团队」微信公众号，在公众号菜单栏对话框回复【2024 年货】、【2023 年货】、【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://p0.meituan.net/meituantechblog/b0364d579285ab22aa6235bd100d7c22178175.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;| 本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明 "内容转载自美团技术团队"。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 &lt;a href="https://www.oschina.net/action/GoToLink?url=mailto%3Atech%40meituan.com" target="_blank"&gt;tech@meituan.com&lt;/a&gt; 申请授权。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/meituantech/blog/18685058</link>
      <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/18685058</guid>
      <pubDate>Fri, 18 Jul 2025 07:21:29 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>报告：71% 的人不愿聘用不具备 AI 技能的开发人员</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Infragistics 最新发布的一项&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#585858"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.appbuilder.dev%2F2025-app-development-trends-part-2" target="_blank"&gt;&lt;span&gt;&lt;span&gt;《2025 年应用开发趋势报告》&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;显示，71％ 的受访者表示，他们不会聘请不具备 AI 技能的开发人员。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;30% 的受访者表示，今年他们面临的最大挑战之一是招聘合格的开发人员。除了招聘 AI 领域人才外，53% 的领导者还寻求具备云计算技能的人才，35% 的领导者在寻求具备解决问题的能力的人，35% 的领导者寻求采用安全编码实践的开发人员。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Infragistics 首席运营官 Jason Beres 表示：「AI 正在迅速改变企业开发应用程序的方式——从简化工作流程到降低安全风险——但如果没有一支技术精湛的团队，单凭技术本身是不够的。随着企业寻求在业务中扩大 AI 的应用，聘请精通 AI 和机器学习的开发人员，并投资于技能提升，对于推动创新和保持竞争力至关重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，受访者表示面临的一些其他主要挑战是网络安全威胁（45%）、实施人工智能（37%）和留住合格的开发人员（35%）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;调查发现，目前有 87% 的团队在开发过程中使用 AI，而目前尚未使用 AI 的公司中，有 45% 表示他们可能会在明年内开始使用。AI 在开发领域最大的应用场景是自动化重复性任务（40%）、创建布局和页面（34%）以及检测错误。约三分之一的领导者认为，AI 可以让开发人员腾出时间去做更有意义的工作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;几乎所有（99%）在应用程序开发过程中使用 AI 的公司都将 AI 工具用于安全目的。64% 的公司使用 AI 工具进行安全评估、60% 用于测试代码、59% 用于识别趋势以检测安全漏洞，58% 用于扫描代码以查找漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-00357b61dccfee8da65a90bca27b3134624.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;近一半（45%）的受访者表示，网络安全威胁是他们在 2025 年面临的首要挑战之一。低代码与 AI 的结合不仅使应用程序开发更高效，而且更安全。&lt;/span&gt;还有 76% 的技术领导者认为 AI 将提高低代码工具的效率，只有 16% 的人认为 AI 将取代低代码开发。&lt;/p&gt; 
&lt;p&gt;更多详情可查看&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.appbuilder.dev%2F2025-app-development-trends-part-2" target="_blank"&gt;此处&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361019</guid>
      <pubDate>Fri, 18 Jul 2025 07:02:29 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>IntelliJ IDEA 从 2025.3 版本开始只提供单一安装程序</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;JetBrains &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fintellij-idea-unified-distribution-plan%2F" target="_blank"&gt;宣布了&lt;/a&gt; IntelliJ IDEA 迁移到统一发行版的计划：「&lt;strong&gt;以后将只有一个 IntelliJ IDEA 安装程序，取代分别下载的 Community Edition 和 Ultimate Edition&lt;/strong&gt;。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f541e5ae8e14a12c6ab5ca622afdf89f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从&amp;nbsp;2025.3 版本开始，&lt;strong&gt;IntelliJ IDEA Community Edition 将不再作为单独的产品发行&lt;/strong&gt;。所有用户都将下载单个 IntelliJ IDEA 发行版：一个安装程序，一个更新流。&lt;/p&gt; 
&lt;p&gt;对于 Ultimate 用户来说：&lt;strong&gt;IDE 将被简称为 IntelliJ IDEA，不带「Ultimate」后缀&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在这种新设置中，所有 Ultimate 功能仍然需要订阅才能解锁。 但即使没有订阅，IDE 仍将保持完整功能，可供商业和非商业项目免费使用，并将包含比当前 Community Edition 更多的功能。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.jetbrains.com%2Fzh-hans%2Fidea%2F2025%2F07%2Fintellij-idea-unified-distribution-plan%2F" target="_blank"&gt;官方公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361007/intellij-idea-unified-distribution-plan</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361007/intellij-idea-unified-distribution-plan</guid>
      <pubDate>Thu, 17 Jul 2025 06:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​首个基于 AI 的恶意软件 LameHug 现身，窃取 Windows 设备数据</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;科技媒体 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsecurity%2Flamehug-malware-uses-ai-llm-to-craft-windows-data-theft-commands-in-real-time%2F" target="_blank"&gt;BleepingComputer&lt;/a&gt; 报道了一种新型恶意软件 LameHug 的出现，该软件利用了阿里开源的 Qwen2.5-Coder-32B-Instruct 大型语言模型，针对 Windows10 和 Windows11 设备进行数据窃取。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="345" src="https://oscimg.oschina.net/oscnet/up-eec711f70b3c1570b78cf188268fca9dee1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;LameHug 的独特之处在于它采用了大型语言模型生成攻击指令，进而搜刮受害者设备上的敏感数据。根据 CERT-UA（乌克兰国家网络安全事件响应团队）的报告，LameHug 是用 Python 编写的，依赖于 Hugging Face API 与 Qwen LLM 进行交互。恶意软件通过特定的提示词，动态生成窃取数据的指令。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;LameHug 通过恶意电子邮件传播，通常邮件内附有一个 ZIP 文件，其中包含 LameHug 的加载器。CERT-UA 已经识别出至少三种不同的变体，包括名为 「Attachment.pif」、「AI_generator_uncensored_Canvas_PRO_v0..9.exe」 和 「image.py」 的文件。在具体的攻击过程中，LameHug 会执行系统侦察和数据窃取命令，这些命令均是通过提示词动态生成的。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;生成的命令主要用于收集系统信息并保存到一个文本文件（info.txt）中。它会在关键的 Windows 目录 (如文档、桌面和下载) 中搜索敏感文件，并通过 SFTP 或 HTTP POST 请求将这些数据发送给攻击者。这种利用 AI 技术的恶意软件的出现，可能引发一种新的攻击模式，为网络安全带来了更大的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;随着 LameHug 的广泛传播，安全专家提醒用户要提高警惕，及时更新防病毒软件和系统补丁，谨慎处理陌生邮件和附件，以防止此类恶意软件的侵害。对于广大用户而言，网络安全意识的提升显得尤为重要。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361006</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361006</guid>
      <pubDate>Thu, 17 Jul 2025 06:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微语 0.8.8 发布，开源 AI 问答平台</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;企业级多租户团队协作工具，免费开源 N 件套：企业 IM、在线客服、企业知识库/帮助文档、客户之声、工单系统、AI 对话、工作流、呼叫中心、视频客服、开放平台。&lt;/p&gt; 
&lt;h2&gt;语言&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/README.zh.md"&gt;中文&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="weiyu" src="https://oscimg.oschina.net/oscnet//93c656e542bc2bd566c502c9fa67a081.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;管理端&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="chat" src="https://oscimg.oschina.net/oscnet//c085beb04c0303db9403ad1d101f4851.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;多渠道&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="channel" src="https://oscimg.oschina.net/oscnet//af716261fd2adef709f3c64b7b532e02.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;客服端&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="agent" src="https://oscimg.oschina.net/oscnet//50cacebdda154723bc173cc05cdb67e6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;介绍&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/team/readme.zh.md"&gt;企业 IM&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;局域网即时通讯&lt;/li&gt; 
 &lt;li&gt;企业成员管理&lt;/li&gt; 
 &lt;li&gt;聊天记录监控&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/service/readme.zh.md"&gt;全渠道客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;多渠道接入&lt;/li&gt; 
 &lt;li&gt;人工客服&lt;/li&gt; 
 &lt;li&gt;客服 Agent 智能体，对接自有数据，自动执行操作&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/kbase/readme.zh.md"&gt;知识库&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;对接大模型&lt;/li&gt; 
 &lt;li&gt;自定义知识库&lt;/li&gt; 
 &lt;li&gt;Function Calling&lt;/li&gt; 
 &lt;li&gt;Mcp&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ticket/readme.zh.md"&gt;工单系统&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;工单管理&lt;/li&gt; 
 &lt;li&gt;工单 SLA 管理&lt;/li&gt; 
 &lt;li&gt;工单统计和报表&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/ai/readme.zh.md"&gt;AI Agent&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ollama/DeepSeek/ZhipuAI/...&lt;/li&gt; 
 &lt;li&gt;智能体&lt;/li&gt; 
 &lt;li&gt;工作流&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/core/readme.workflow.md"&gt;工作流&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;自定义表单&lt;/li&gt; 
 &lt;li&gt;自定义流程&lt;/li&gt; 
 &lt;li&gt;工单流程可视化&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/modules/voc/readme.zh.md"&gt;客户之声&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;意见反馈&lt;/li&gt; 
 &lt;li&gt;服务投诉&lt;/li&gt; 
 &lt;li&gt;问卷调查&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/freeswitch/readme.zh.md"&gt;呼叫中心&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 FreeSwitch 的专业呼叫平台&lt;/li&gt; 
 &lt;li&gt;支持来电弹屏、自动分配、通话录音&lt;/li&gt; 
 &lt;li&gt;数据统计，语音与文字服务无缝集成&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://gitee.com/270580156/weiyu/blob/main/plugins/webrtc/readme.zh.md"&gt;视频客服&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于 WebRTC 技术的高清视频通话&lt;/li&gt; 
 &lt;li&gt;支持一键视频对话与屏幕共享&lt;/li&gt; 
 &lt;li&gt;适用于需要直观展示的服务场景&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;开放平台&lt;/h3&gt; 
&lt;h2&gt;Docker 快速开始&lt;/h2&gt; 
&lt;h3&gt;方法一：克隆项目并启动 docker compose 容器，默认使用云模型，智谱 AI&lt;/h3&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;git &lt;span style="color:#0086b3"&gt;clone&lt;/span&gt; https://gitee.com/270580156/weiyu.git &amp;amp;&amp;amp; &lt;span style="color:#0086b3"&gt;cd&lt;/span&gt; weiyu/deploy/docker &amp;amp;&amp;amp; docker compose -p weiyu -f docker-compose.yaml up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;申请智谱 AI&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.bigmodel.cn%2Fusercenter%2Fproj-mgmt%2Fapikeys" target="_blank"&gt;API Key&lt;/a&gt;&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# zhipuai&lt;/em&gt;
&lt;em&gt;# SPRING_AI_ZHIPUAI_BASE_URL: https://open.bigmodel.cn/api/paas&lt;/em&gt;
SPRING_AI_ZHIPUAI_API_KEY: &lt;span style="color:#dd1144"&gt;'sk-xxx'&lt;/span&gt; // 替换为智谱 AI API Key
SPRING_AI_ZHIPUAI_CHAT_ENABLED: &lt;span style="color:#dd1144"&gt;"true"&lt;/span&gt;
SPRING_AI_ZHIPUAI_CHAT_OPTIONS_MODEL: glm-4-flash
SPRING_AI_ZHIPUAI_CHAT_OPTIONS_TEMPERATURE: 0.7
SPRING_AI_ZHIPUAI_EMBEDDING_ENABLED: &lt;span style="color:#dd1144"&gt;"true"&lt;/span&gt;
SPRING_AI_ZHIPUAI_EMBEDDING_OPTIONS_MODEL: embedding-2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;方法二：使用 docker compose ollama，默认安装 ollama，默认使用 qwen3:0.6b 模型&lt;/h3&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;git &lt;span style="color:#0086b3"&gt;clone&lt;/span&gt; https://gitee.com/270580156/weiyu.git &amp;amp;&amp;amp; &lt;span style="color:#0086b3"&gt;cd&lt;/span&gt; weiyu/deploy/docker &amp;amp;&amp;amp; docker compose -p weiyu -f docker-compose-ollama.yaml up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;docker 拉取 ollama 模型。配置文件中可以配置其他模型，如 deepseek-r1 等&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 对话模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull qwen3:0.6b
&lt;em&gt;# 嵌入模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull bge-m3:latest
&lt;em&gt;# 重新排序 Rerank 模型&lt;/em&gt;
docker &lt;span style="color:#0086b3"&gt;exec&lt;/span&gt; ollama-bytedesk ollama pull linux6200/bge-reranker-v2-m3:latest
&lt;em&gt;# 或者从 huggingface 下载模型&lt;/em&gt;
&lt;em&gt;# docker exec ollama-bytedesk ollama pull hf.co/&amp;lt;username&amp;gt;/&amp;lt;model-repository&amp;gt;&lt;/em&gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;停止容器&lt;/h4&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;docker compose -p weiyu -f docker-compose.yaml stop
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h4&gt;修改配置，否则上传图片、文件和知识库无法正常显示&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;修改&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;docker-compose.yaml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件，或&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;code&gt;docker-compose-ollama.yaml&lt;/code&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;文件，修改以下配置项：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 请将服务器 127.0.0.1 替换为你的服务器 ip&lt;/em&gt;
&lt;em&gt;# 头像的访问地址，请修改为服务器实际的地址&lt;/em&gt;
BYTEDESK_FEATURES_AVATAR_BASE_URL: http://127.0.0.1:9003
&lt;em&gt;# 文件上传的访问地址，请修改为服务器实际的地址&lt;/em&gt;
BYTEDESK_UPLOAD_URL: http://127.0.0.1:9003
&lt;em&gt;# 知识库的访问地址，请修改为服务器实际的地址&lt;/em&gt;
BYTEDESK_KBASE_API_URL: http://127.0.0.1:9003
&lt;/code&gt;&lt;/pre&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;方法三：宝塔面板&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fbaota" target="_blank"&gt;宝塔面板部署&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;方法四：源码启动&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitee.com/link?target=https%3A%2F%2Fwww.weiyuai.cn%2Fdocs%2Fzh-CN%2Fdocs%2Fdeploy%2Fsource" target="_blank"&gt;源码启动&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;演示&lt;/h2&gt; 
&lt;p style="color:#40485b; margin-left:0; margin-right:0; text-align:left"&gt;本地预览&lt;/p&gt; 
&lt;div&gt; 
 &lt;pre&gt;&lt;code&gt;&lt;em&gt;# 请将 127.0.0.1 替换为你的服务器 ip&lt;/em&gt;
http://127.0.0.1:9003/
&lt;em&gt;# 开放端口：9003, 9885&lt;/em&gt;
默认用户名: admin@email.com
默认密码: admin&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360990</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360990</guid>
      <pubDate>Thu, 17 Jul 2025 04:11:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Meta 在挖走苹果 AI 部门主管后，再次挖走两名核心专家</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;彭博社记者马克・古尔曼&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-07-17%2Fmeta-hires-two-key-apple-ai-experts-after-poaching-their-boss" target="_blank"&gt;透露&lt;/a&gt;，Meta 又挖走了苹果公司的两位关键人工智能研究人员，此前不久 Meta 刚刚从苹果挖走了其 AI 王牌——人工智能模型负责人庞若鸣（Ruoming Pang），也就是这两名研究人员的主管。&lt;/p&gt; 
&lt;p&gt;报道称，Meta 聘请了苹果公司的 Mark Lee 和 Tom Gunter 加入其超级智能实验室 (Superintelligence Labs) 团队。Lee 在近日离开苹果后已入职 Meta，而 Gunter 将在不久的将来入职。且 Gunter 上个月就已经从苹果离开，之后曾在另一家人工智能公司工作，并于最近几天离职。&lt;/p&gt; 
&lt;p&gt;&lt;img height="251" src="https://oscimg.oschina.net/oscnet/up-6a4af53d5d0f57a57747c4bc6cec56f5b24.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本月早些时候，苹果公司人工智能模型负责人庞若鸣被 Meta 挖走。据悉，为了争取庞若鸣的加入，Meta 提供了一份价值超 2 亿美元的多年薪酬方案。&lt;/p&gt; 
&lt;p&gt;庞若鸣于 2021 年从 Alphabet 离职并加入苹果，领导苹果基础模型团队。Lee 和 Gunter 此前均为该团队成员。该团队约有 100 人，主要负责开发支持苹果设备上 「Apple Intelligence」 及其它 AI 功能的核心基础模型。&lt;/p&gt; 
&lt;p&gt;据悉，Meta 承诺的薪酬比苹果支付给其基础模型团队工程师的薪酬要高出数倍。为了防止更多人离职，苹果已经开始为该团队中的一些工程师提供加薪，以吸引他们留下。&lt;/p&gt; 
&lt;p&gt;尽管如此，这与 Meta 的出价仍相去甚远。例如，Gunter 即将加入一个由数位人工智能专家组成的团队，这些专家都获得了价值超 1 亿美元的多年期薪酬包。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style="text-align:start"&gt;&lt;a href="https://www.oschina.net/news/359359/meta-recruits-apples-head-of-ai-models" target="_blank"&gt;消息称 Meta 招募了苹果的 AI 模型高管&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360982</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360982</guid>
      <pubDate>Thu, 17 Jul 2025 03:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Jason Wei 提出「验证者定律」：所有可能解决且易于验证的任务都将被人工智能解决</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Jason Wei（OpenAI 核心科学家、思维链提示词核心作者、o1 关键人物）近期&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2F_jasonwei%2Fstatus%2F1945287045251052007" target="_blank"&gt;提出&lt;/a&gt;验证不对称性理论及&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.jasonwei.net%2Fblog%2Fasymmetry-of-verification-and-verifiers-law" target="_blank"&gt;「验证者定律」（Verifier's Law）&lt;/a&gt;，其核心观点是：训练 AI 解决一个任务的难易程度与该任务的可验证性成正比，所有可能解决且易于验证的任务，终将都被 AI 攻克。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;验证的不对称性指的是有些任务验证起来比解决起来容易得多。随着强化学习的普遍应用，这个概念变得越来越重要。&lt;/p&gt; 
 &lt;p&gt;比如：数独谜题、编写 Instagram 网页代码、或 BrowseComp 问题（找到答案很难，但验证起来非常简单）。&lt;/p&gt; 
 &lt;p&gt;有的任务则接近对称，比如计算两个 900 位数字之和。还有些任务提出方案容易，但验证却很难（比如核实一篇长文章的事实，或提出「只吃野牛」的新饮食法）。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;具体而言，任务的可验证性取决于以下五个关键属性：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;客观真理&lt;/strong&gt;：所有人对「好」的解决方案有普遍共识。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;快速验证&lt;/strong&gt;：任何给定的解决方案可在几秒钟内完成验证。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可扩展验证&lt;/strong&gt;：可同时验证大量解决方案。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;低噪声&lt;/strong&gt;：验证结果与解决方案质量高度相关。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;连续奖励&lt;/strong&gt;：可对多个解决方案进行优劣排序 。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7387b887042eaf1d9e3b0a62295b13721e4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Jason Wei 指出，过去十年中，大多数 AI 基准测试都符合前四条标准（因此已被解决），而符合这些标准的任务将推动 AI 快速进步，而难以验证的任务则进展缓慢。&lt;/p&gt; 
&lt;p&gt;此外，验证者定律也揭示了未来人类与 AI 协作的核心：将复杂、模糊的现实问题转化为 AI 可理解和优化的、可清晰验证的任务。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360981/asymmetry-of-verification-and-verifiers-law</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360981/asymmetry-of-verification-and-verifiers-law</guid>
      <pubDate>Thu, 17 Jul 2025 03:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节视觉大模型负责人杨建朝宣布「暂时休息」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;网易科技获悉，字节跳动豆包大模型视觉多模态生成方向负责人杨建朝于 7 月 17 日上午在公司内部宣布「暂时休息」，相关工作已完成交接。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据多位接近字节的人士透露，目前仍能在字节内部系统中查到杨建朝的信息。消息人士称，杨建朝的工作将由周畅（花名「时光」）接手。目前，周畅所在架构仍为「多模态交互与世界模型」部门，向吴永辉汇报。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;关于此次人事变动的原因，有知情人士向网易科技表示为「家庭因素」，此前也有传言称其因无法兼顾北美与国内的工作节奏，长期处于高强度压力下，身心俱疲，也有版本称其为「提前退休」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;实际上，早前就有杨建朝计划「休息」的传闻，而选择在此时正式官宣，消息人士表示可能是考虑到上半年绩效考核刚刚结束，为下半年重新安排工作提供空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="323" src="https://oscimg.oschina.net/oscnet/up-e084d80744b14ca7360272b901a726c9179.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;网易科技了解到，Seed 视觉模型研究团队，办公地点分布在北美圣何塞、新加坡和中国多个城市，涵盖图片生成、视频生成及视觉模型基础研究等方向。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;自 2025 年 2 月谷歌 DeepMind 研究副总裁吴永辉加入字节、担任 Seed 基础研究负责人以来，Seed 内部的组织与权责结构便发生了一系列深层调整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在大模型竞争进入深水区的背景下，核心技术负责人的异动，令外界对字节内部 AI 技术路线的稳定性产生更多关注。不过，也有知情人士表示，字节在内部多次强调对基础研究的长期投入不会动摇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;杨建朝是字节 AI 体系内公认的「技术大牛」。2006 年，他曾获得中国科学技术大学郭沫若奖学金，后赴美深造，师从「计算机视觉之父」Thomas Huang（黄煦涛），在伊利诺伊大学香槟分校完成博士后研究。他曾在 Adobe、Snapchat 等公司从事视觉算法研究，2018 年加入字节跳动 AI Lab 任研发总监，后负责智能创作团队，2023 年起带领 Seed 视觉部门。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;接任者周畅同样是国内技术领域的重要人物。本科毕业于复旦大学，博士就读于北京大学，曾担任阿里巴巴通义千问大模型的技术负责人，主导开发了 2021 年发布的 M6 多模态预训练模型。这是阿里与清华联合推出的中文语境下最大规模 AI 模型，被视为阿里大模型战略的重要里程碑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2025 年 7 月，周畅从阿里离职，引发广泛猜测，曾一度传出其将创业的消息。最终据多方确认，他选择加入字节跳动，加入 Seed 团队。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360974</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360974</guid>
      <pubDate>Thu, 17 Jul 2025 03:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI o1 核心贡献者把 AI 定义为「第四种杠杆」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近期，前 OpenAI 研究员 Hyung Won Chung 在离职消息曝光后，首次系统性地&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fhwchung27%2Fstatus%2F1945355238187393257" target="_blank"&gt;分享了他对 AI 的长期思考&lt;/a&gt;，塑造了一个新的想法：「AI 杠杆机制」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/111013_yM8G_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在传统经济学里，人类只拥有三种杠杆：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;人力杠杆：让别人替你干活。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;资本杠杆：让钱替你生钱。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代码杠杆：让软件替你规模化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Hyung Won Chung 认为，&lt;strong&gt;AI 正在成为第四种杠杆&lt;/strong&gt;，具备前三者从未同时拥有的三大特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;组合性&lt;/strong&gt;——多个 AI Agent 可以任意拼接，形成「复合杠杆」；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;——复制 1 万份拷贝的边际成本趋近于零；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;自治性&lt;/strong&gt;——Agent 可以自主规划、执行、纠错，甚至自我复制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;因此，AI 杠杆的「放大系数」远超传统杠杆：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;1 个 Agent ≈ 1 名员工；&lt;br&gt; 10 个 Agent ≠ 10 倍成本，而是 10 倍产出且零额外协调开销。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 Chung 看来，人工智能并不仅仅是一种工具，而是一种史无前例的「杠杆机制」——可以以极低的输入，撬动巨大的价值输出，从个人到文明层面，全面重塑创造力的来源。&lt;/p&gt; 
&lt;p&gt;另外，Chung 还提出了一个设问：「如果把整个人类文明看作一个系统，它的目标是什么？」他的答案是：持续发现新知识，也就是科学进步。&lt;/p&gt; 
&lt;p&gt;在他构想中，AI 不仅是个工具，更是连接人类知识尖峰的壳层。今天的科学知识被分布在不同领域、不同学者之间，彼此割裂，合作成本极高。而 AI 能将这些高维孤岛串联起来，像细菌的质粒一样，进行「知识的水平基因转移」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360973</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360973</guid>
      <pubDate>Thu, 17 Jul 2025 03:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>社区搜索离线回溯系统设计：架构、挑战与性能优化</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、项目背景&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在社区场景中，我们积累了丰富的用户互动数据。这些历史互动信息对 CTR/CVR 预估建模具有重要参考价值，用户的每次互动都反映了其特定维度的偏好特征。当前，已在多个业务实践中验证，基于用户历史互动特征进行未来行为预测是有效的。用户互动序列越长，包含的偏好特征就越丰富，但同时也带来了更大的技术挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;目前社区搜索领域已经在序列建模方向取得了一些应用成果，显著提升了搜索效率，但在该方向上仍有优化空间，主要体现在：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;算法精排模型现状：&lt;/strong&gt;长周期的用户互动特征尚未被充分利用，现有模型仅使用了基础标识信息，泛化能力有待提升。我们计划引入 SIM 方案来增强个性化序列建模能力，推动搜索效率提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;&lt;strong&gt;迭代效率优化：&lt;/strong&gt;当前互动特征优化依赖于实时数据采集链路，新增特征需要长时间数据积累（2 个月以上）才能验证效果。我们计划建设用户特征离线回溯服务，降低算法优化对实时数据的依赖，加快项目迭代速度，提高实验效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;离线回溯主要解决迭代效率问题，本文重点探讨在社区搜索场景下开发离线回溯，并做离线一致性验证过程中发现的一些问题，针对这些问题做了哪些优化措施及思考。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、架构设计&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;全局架构&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;序列产出流程链路&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;在线流程链路&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在线链路通过实时数仓提供全量表和实时流两种数据源，在特征平台下构建 1w 长度的实时用户画像，召回阶段 SP，将画像传给 SIM 引擎，在引擎中完成对用户序列 hard/soft search 等异步加工，最终传给 Nuroe，完成在线序列 dump 落表。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;离线流程链路&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;离线链路通过仿真在线的处理逻辑，利用请求 pv 表和离线数仓提供的 10w 原始序列，模拟在线序列 10w-&amp;gt;1w-&amp;gt;100 的过程，最终产出离线回溯序列。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;最终通过在线/离线全链路数据的一致性验证，确认全流程数据无 diff（或 diff 可解释），序列流程可靠性达标，可交付算法团队用于模型训练。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5a43670aaaf2d538a4f675c1683bcd08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;序列产出全局架构&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;在线架构&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在线侧抽象 GSU 模块支持社区搜索和增长搜索等多场景复用。该模块在 QP（Query Processing）阶段后，通过外调基于 DSearch 构建的 SIM 引擎进行用户序列处理。SIM 引擎内完成 hard/soft search 等用户序列加工，在精排阶段前获取 topk 序列特征及对应 sideinfo，并将其透传给精排模块，最终实现用户序列的落表存储。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5d0ecb14f2c2907387d1c1d0c8aae445.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;在线通用 GSU 模块&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;离线链路&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据产出三阶段&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;原始序列预处理阶段&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过收集一个用户，按照 [月初 ts+1w, &amp;nbsp;月末 ts] 将序列进行预处理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;pv 表合并序列表阶段&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;按照 user_id 将画像和 pv 表合并，将每个 request_id 的数据按照 request_time 过滤处理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;用户序列加工阶段&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;完成 hard/soft search 等用户序列加工逻辑处理，包括对长期序列按照相似度过滤，对短期序列按照时间过滤等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//11339d8e2dbad7a6c7820310e64eb360.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;离线回溯链路图&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;三、问题与挑战&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在离线回溯开发阶段，主要面临以下挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;任务执行问题&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;任务频繁失败或执行效率低下，数据规模达单表数 TB 级别，且序列分布不均，部分长尾用户序列过长导致严重数据倾斜；&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;一致性校验阶段问题&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;异常类型复杂多样，累计发现 25+种异常原因，导致数据 diff 形态复杂，一致性原因分析困难。修复链路冗长，涉及问题修复、在线索引重建、数据累计和离线数据回补，单次修复周期约需一周。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//868464bb108cf35c3b3a1de8196faf23.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;四、从踩雷到填坑的实战记录&lt;/h1&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;离线任务运行耗时长的问题&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;问题说明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;初步方案运行时存在两大问题：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;1.任务处理延迟显著，单个任务运行 3-8 小时。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;2.任务处理无法运行成功频繁 OOM。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f18ed0476e47272382816f78e6bac457.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;任务执行慢&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//190795e2a1b4e19f24bcd7a80bc0f1d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;任务频繁 OOM&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ 方案优化&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;任务执行慢主要是有长尾用户打满 10w 长序列，出现数据倾斜问题甚至 oom。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过对链路优化，先将原始 10w 长序列做预处理，由于回溯一般按照一个月跑数据，可以利用 pv 表先统计有哪些有效用户，对有效用户按照 【月初 ts+1w, &amp;nbsp;月末 ts】截取原始序列，获取相对较短的预处理队列。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e803521ebf9b49c3ded61c3cab526b74.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;任务倾斜&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//02626be3811dec82df6178b5a78c6c6d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;原始序列预处理&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;ODPS 任务性能调优&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;a. 按照&amp;nbsp;&lt;strong&gt;CPU :&amp;nbsp;MEM&amp;nbsp;=&amp;nbsp;&amp;nbsp;1 : 4 调整计算和存储的比例，可以最大化利用资源，因为我们申请的资源池都是按照这个固定比例来的。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d41848eb7dafa12617af771a7b4550c7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;资源没有最大化使用&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;b. 在固化计算/存储比例参数后，可以通过 xxx.split.size 和 xxx.num 共同调优。xxx.split.size 可以实现输入分片大小，减少 oom 机会。xxx.num 可以实现扩大并发数，加快任务的执行（xxx 代表 mapper、reducer、joiner 几个阶段）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//7cd197902a7b9b9cee16229cb8a8cd71.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;分批次完成阶段处理&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;c. 减少自定义&lt;strong&gt;UDF&lt;/strong&gt;使用。在离线任务中有部分逻辑比较复杂，可能需要数据平铺、聚合、再内置函数等。最好的使用原则是内置函数&amp;gt;「数据平铺+内置函数」&amp;gt;自定义&lt;strong&gt;UDF&lt;/strong&gt;。由于自定义&lt;strong&gt;UDF&lt;/strong&gt;运行在 Java 沙箱环境中，需通过多层抽象层 （序列化/反序列化、类型转换），测试发现大数据量处理过程性能相对最差。&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;一致性验证归因难的问题&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;问题说明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;在线/离线全链路数据的一致性验证过程中，由于按照天级全量 dump 序列，需要验证 15 个序列，每个序列 diff 量在 10w～50w 不等，这种多序列大规模的 diff 问题人工核验效率太慢。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;整体 diff 率分析&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过统计全序列 diff 率并聚类分析高 diff 样本，定位共性根因，实现以点带面的高效问题修复。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;diff 归因工具&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;通过建立数据 diff 的归因分类体系（如排序不稳定、特征穿越等），并标注标准化归因码，实现对 diff 问题的快速定位与根因分析，显著提升排查效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//bfa7752adc3c9bec1d33d01dc53a525d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;归因码分类&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;重复度统计工具&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;由于在线受当时环境的影响，离线回溯无法 100% 复现原始序列，一致性差异在所难免。我们通过聚焦主要特征并统计其重复度，结合「diff 率+重复度」双维度评估方案，为算法决策提供量化依据，有效减少无效迭代。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//372dbe821f76c8f1f2373c21db4a6244.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;重复度统计&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;现状梳理不足的问题&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;问题说明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;由于前期对业务场景理解不足（如用户行为模式、异常数据、测试账户等），部分潜在问题未在开发阶段充分识别，直至数据一致性验证时才集中暴露，导致需紧急调整数据处理逻辑。由於单次全链路修复需 3-5 天，进而对项目进度造成一定延迟。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;问题 case1：滑动图片：离线回溯数据分析时发现序列中大量重复且占比很高，后确定为滑动图片行为&lt;/p&gt; 
&lt;p&gt;解决方案：对滑动图片操作连续多次修改为只记录第一次&lt;/p&gt; 
&lt;p&gt;问题 case2：合并下单：测试购买序列有 id 重复，实时数仓反馈购买有合并下单的情况，ts 会相同&lt;/p&gt; 
&lt;p&gt;解决方案：为了保持离线回刷数据稳定性，将序列按照 ts/id 双维度排序&lt;/p&gt; 
&lt;p&gt;问题 case3：异常数据：有行为时间戳超过当前时间的异常数据&lt;/p&gt; 
&lt;p&gt;解决方案：数仓对异常数据丢弃&lt;/p&gt; 
&lt;p&gt;问题 case4：测试账户：数据不规范导致数据 diff&lt;/p&gt; 
&lt;p&gt;解决方案：测试账户数据忽略&lt;/p&gt; 
&lt;p&gt;问题 case5：query 问题：取归一化后还是原始的 query、空字符串问题&lt;/p&gt; 
&lt;p&gt;解决方案：query 为空过滤修复&lt;/p&gt; 
&lt;p&gt;问题 case6：数据穿越问题：画像原始数据 request_time 取 neuron 时间导致&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//56d1c5feb7fd51e49bce353209d2e663.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;解决方案：在线修改 request_time 获取时间，离线回溯前置 3s&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;修复周期长的问题&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;问题说明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;数据问题的完整修复流程包含三个阶段，全流程通常需要 5-7 个工作日完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//17e2b0e9b943517817ed845680b945ea.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;Diff 归因阶段（1-3 日）&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要定位数据差异的根本原因，区分是数据异常、处理逻辑错误还是业务规则变更导致&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;涉及多团队协作排查（数据/算法/工程）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;复杂问题可能需要多次验证&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;问题修复阶段（1-3 日）&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;根据归因结果修改代码逻辑或数据处理流程&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可能涉及历史数据修正&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;数据迭代阶段（2-3 日）&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在线画像引擎部署新数据&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;累计在线数据&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;离线画像回补数据&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;受限于初期人力投入，我们在当前方案基础上通过多轮版本迭代逐步完成数据一致性验证。后续将通过工具升级（数据边界划分+自动化校验框架）和数据采样策略，实现验证到修复的阶跃式提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;数据边界划分&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;现行方案离线链路都是算法工程来维护，排查链路太长，需要数据源有稳定的保障机制。后续将划分数据边界，各团队维护并保障数据模块在离线的一致性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d8954fead9ed0a6fe71a6206b53da6e3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;数据边界划分&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;※ &amp;nbsp;全链路采样方案减少验证时间&lt;/strong&gt;&lt;/span&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;离在线一致性验证方面耗时较长，主要在于数据量太大，在数仓构建、特征平台构建、累计数据等流程消耗大量的时间，如果全链路先针对少量用户走通全链路，能快速验证流程可行性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//0069ba0e0a9bd6833a6ec35cda0e6dc5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;采样方案&lt;/span&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style="color:#000000"&gt;平台基建的问题&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;问题说明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;首次构建序列建模体系，由于缺乏标准化基础设施，被迫采用烟囱式开发模式，导致多链路验证复杂且问题频发。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;平台待建能力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;特征平台排序功能不足，只支持单一字段排序，不支持多字段联合排序，导致排序结果不稳定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;特征平台过滤功能限制，仅支持毫秒级时间戳过滤。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;索引构建效率低,个性化行为序列表数据量过大（3TB），导致索引构建压力大，初始构建耗时约 28 小时。升级至 FS3 集群后，构建时间降至 12 小时左右,最短至 7 小时，但仍未达理想效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_13"&gt;&lt;/span&gt; 
&lt;h1&gt;五、展望与总结&lt;/h1&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;后续我们将深入研究行业内的优秀解决方案，并结合我们的业务特性进行有针对性的优化。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;例如，我们会尝试实施离在线数据与逻辑一致性方案，这种方案包括以下几个特点：&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;数据一致性：离线与在线共用同一套原始画像，能够解决数据源不一致导致的差异问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;逻辑一致性：离线与在线都调用 GSU 服务，实现统一的序列逻辑处理，避免逻辑差异。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;技术架构复杂性：新方案带来了新的技术挑战，比如在线处理 10 万序列可能引发的 I/O 问题、离在线的 sim 引擎采用存算一体和存算分离架构。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;综上，没有绝对完美的技术方案，最终都是在成本、性能和效率多方面权衡后的相对最优解。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//31bf9f3c1ef93545432b5e221bd97fd5.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#a0a0a0"&gt;离在线数据与逻辑一致性方案&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;本次特征回溯虽面临性能与数据对齐等挑战，但团队通过攻坚积累了经验，为特征平台后续特征回溯工具化打下基础，也期待能为后续算法模型迭代带来质的飞跃。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;往期回顾&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;1.从 「卡顿」 到 「秒开」：外投首屏性能优化的 6 个实战锦囊｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;2.从 Rust 模块化探索到 DLB 2.0 实践｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;3.eBPF 助力 NAS 分钟级别 Pod 实例溯源｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;4.正品库拍照 PWA 应用的实现与性能优化｜得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#6a6a6a"&gt;5.汇金资损防控体系建设及实践 | 得物技术&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;文 / 野雨&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;关注得物技术，每周更新技术干货&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#3e3e3e"&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/5783135/blog/18684911</link>
      <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18684911</guid>
      <pubDate>Thu, 17 Jul 2025 02:55:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>开源 AI 客户端 Cherry Studio 1.5.0 新增「全局记忆」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源 AI 助手平台 Cherry Studio 更新至 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbuAdCwtDYQK3GePzx90THw" target="_blank"&gt;v1.5.0 &lt;/a&gt;版本，新增了&lt;strong&gt;全局记忆 (Global Memory)&lt;/strong&gt;功能。该功能基于 mem0 实现，允许用户为单个助手开启或关闭全局记忆。&lt;/p&gt; 
&lt;p&gt;目前该功能处于 Beta 阶段，将在 GitHub 上收集反馈并持续优化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;其他新增功能&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gemini 支持 URL 上下文&lt;/strong&gt;：现在可以让 Gemini 模型直接读取和理解网页内容了。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更快的流式响应&lt;/strong&gt;：增强了对 Anthropic 和 OpenAI API 的流式输出支持，打字机效果响应更快，体验更佳。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP 功能增强&lt;/strong&gt;：在设置中新增了对&amp;nbsp;302AI&amp;nbsp;服务商的支持，并以徽章形式清晰展示当前 MCP server 的版本。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DMXAPI 绘画&lt;/strong&gt;：新增了更多绘画模型支持，为你的创作带来更多可能性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;修复和优化&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;对&lt;strong&gt;助手与话题，列表&lt;/strong&gt;进行了专项性能优化，不仅提升了话题的渲染效率，还修复了删除助手时可能出现的错误，整体使用更流畅。&lt;/li&gt; 
 &lt;li&gt;修复了从未打开过的话题在导出为 Markdown 文件时内容为空的问题。&lt;/li&gt; 
 &lt;li&gt;修复了在对话中调用视觉模型时，无法粘贴图片的问题。&lt;/li&gt; 
 &lt;li&gt;修复并完善了全局快捷键，并为 Linux Wayland 用户提供了更好的支持。&lt;/li&gt; 
 &lt;li&gt;修复了在网格模式下，消息工具栏按钮有时无法点击的问题。&lt;/li&gt; 
 &lt;li&gt;修复了 Azure API 在部分场景下的兼容性问题。&lt;/li&gt; 
 &lt;li&gt;修复了翻译历史记录在特定操作下无法正确设置源语言的问题。&lt;/li&gt; 
 &lt;li&gt;修复了部分 WebDAV 服务器因不支持流式传输而无法兼容的问题。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FCherryHQ%2Fcherry-studio%2Freleases%2Ftag%2Fv1.5.0" target="_blank"&gt;https://github.com/CherryHQ/cherry-studio/releases/tag/v1.5.0&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360969/cherry-studio-1-5-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360969/cherry-studio-1-5-0</guid>
      <pubDate>Thu, 17 Jul 2025 02:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 发布 ChatGPT agent</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 于今日凌晨通过直播发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-chatgpt-agent%2F" target="_blank"&gt; ChatGPT agent&lt;/a&gt;，这是一个融合了 Operator（网站交互能力）和 Deep Research（信息整合能力）以及 ChatGPT 本体能力的统一智能体系统，能够自主思考并选择合适工具（如 Operator、Deep Research 和 ChatGPT 本体），完成复杂任务，例如浏览网站、运行代码、生成 PPT 和电子表格等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0718/101506_tVbg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户只需通过自然语言提示，ChatGPT agent 就能自动完成从思考到行动的全过程，并可在任务中接受中断和修改指令 。OpenAI 在直播中展示了 ChatGPT agent 用于婚礼策划（如挑选服装、预订酒店和挑选礼物）和工作场景（如分析数据并制作演示文稿）的演示。&lt;/p&gt; 
&lt;p&gt;ChatGPT agent 面向 ChatGPT Pro、Plus 和 Team 用户开放，Pro 用户每月可调用 400 次，Plus 和 Team 用户每月可调用 40 次，预计本月底完成 Pro 版部署，Plus 和 Team 版也将很快完成，后续还将上线企业版和教育版 。&lt;/p&gt; 
&lt;p&gt;OpenAI 强调，尽管功能强大，但存在潜在风险（如 prompt injection 攻击），已采取多层安全防护和用户控制措施，用户需谨慎使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360965/openai-chatgpt-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360965/openai-chatgpt-agent</guid>
      <pubDate>Thu, 17 Jul 2025 02:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​特朗普宣布 900 亿美元 AI 中心投资计划，谷歌和黑石集团领投</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在宾夕法尼亚州举办的首届能源与创新峰会上，美国总统特朗普&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Farticles%2F2025%2F07%2Fpresident-trump-solidifies-u-s-position-as-leader-in-ai%2F" target="_blank"&gt;宣布&lt;/a&gt;了一项重磅投资计划，总额超过 900 亿美元，旨在将宾夕法尼亚州打造成美国人工智能的核心地带。此次投资不仅涵盖数据中心的建设，还包括能源基础设施的提升及人工智能相关人才的培训。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="381" src="https://oscimg.oschina.net/oscnet/up-4901dd844e39e6fc8f183bf10024f52004c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在这一投资计划中，谷歌作为主要参与者，将投资于建设大型数据中心，并已与当地的水电站签署了一项为期 20 年的供电协议。此外，黑石集团也表示将投资 250 亿美元，与公用事业公司 PPL 合作，共同在宾夕法尼亚州东北部建设能源和数据基础设施。这些项目预计将为当地创造数千个就业机会。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;核心参与者 CoreWeave 也宣布将在兰卡斯特投资 60 亿美元，建立一个最高可达 300 兆瓦的数据中心，该中心的建设预计将创造 600 个建筑工人和 175 个全职运营岗位。此项投资计划不仅有助于满足日益增长的数据需求，还将大幅推动当地经济的发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此次峰会还强调了 「能源安全人工智能」 的理念，宾夕法尼亚州正被重新定位为数据中心能源的引擎，许多项目如核电升级和天然气发电厂的改造正在进行中。这些举措将为宾夕法尼亚州的电力供应注入新的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;各大企业也纷纷响应这一投资计划。例如，黑石集团宣布将投资 250 亿美元开发数据中心与能源基础设施，预计将创造 6000 个建筑工作岗位和 3000 个新的永久性岗位。而布鲁克菲尔德则与谷歌达成了 30 亿美元的协议，重新启动两个水电设施，预计将保护 300 个新工作岗位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其他企业如安桥、Equinor 和第一能源公司等也纷纷参与投资，进一步扩大宾夕法尼亚州在能源和人工智能领域的影响力。特朗普的这一计划，不仅将为当地带来丰厚的经济收益，也将推动美国在人工智能领域的发展。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360962</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360962</guid>
      <pubDate>Thu, 17 Jul 2025 02:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>从依赖到可控：开源基础设施的国家命题</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;在过去十年里，代码托管平台经历了从开发工具向基础设施的演化。不仅仅是开发者日常协作的载体，更成为支撑科研、产业、信创工程和开源生态建设的根本平台。&lt;/p&gt; 
&lt;p&gt;随着国家数字化战略的深入推进，「代码平台是否自主可控」这一问题，已从技术议题上升为现实战略问题。平台的稳定性、安全性、治理权，决定了其能否承担长期、关键的系统角色。&lt;/p&gt; 
&lt;p&gt;Gitee 正是在这一战略背景下，逐步从代码协作平台走向国家级开源基础设施的定位。而这一趋势的现实依据，也在最近的一次广泛关注的事件中被进一步印证。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;strong&gt;GitHub 403 事件说明了什么&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;2025 年 4 月 12 日晚起，中国大陆部分用户在未登录状态下访问 GitHub 时遇到 403 拒绝访问错误。GitHub 后续在状态页发布说明，称此次中断源于一次配置变更造成的「非预期影响」，问题在次日下午被修复。&lt;/p&gt; 
&lt;p&gt;虽然这是一次技术事件，并非平台刻意封锁，但它再次揭示了一个不容忽视的结构性事实：&lt;strong&gt;当前中国开发者对全球主流托管平台仍缺乏访问控制权、预警机制与服务协商能力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;哪怕一次无意操作，也可能导致全链条的访问中断。而这正是基础设施「可控性」的核心：不能仅仅依赖对方「不出问题」，而要拥有面对突发事件时的缓冲机制与替代路径。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;strong&gt;代码平台是战略基础设施，不是功能网站&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;现代软件工程全流程——从源代码托管、分支管理，到协作开发、依赖声明、版本发布、安全审计——都依赖代码平台构建。对国家而言，平台不仅关乎开发效率，更关乎研发主权与生态稳定。&lt;/p&gt; 
&lt;p&gt;尤其在国产操作系统、AI 框架、基础开发工具链不断推进替代的当下，大量信创工程与科研系统都要求在可信平台中进行代码协作。&lt;strong&gt;一旦平台不可用，影响的不只是某个项目，而是整个体系的运转稳定性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这正是「代码即国力」的现实语境：平台决定协作是否可持续，生态决定技术是否能演进。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;strong&gt;历史上已有多次「平台不可用」的现实案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;GitHub 的 403 事件不是第一次访问异常事件。2019 年，GitHub 曾因出口管制限制了伊朗、敍利亚、克里米亚等地的访问权限，相关账号遭冻结；2022 年后，部分俄罗斯高校与企业的组织账号也被限制访问。&lt;/p&gt; 
&lt;p&gt;这些先例说明：&lt;strong&gt;开源平台无法始终保持政治中立，其可用性具有现实边界&lt;/strong&gt;。中国作为全球开发者最活跃的国家之一，不能在战略支撑设施层面对外部平台形成绝对依赖。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#c0392b"&gt;&lt;strong&gt;Gitee 的职责，是保障国家技术生态的连续性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Gitee 目前已承担国家代码库的备份任务，并为信创工程、AI 模型项目、工业软件协同等场景提供国产托管服务。平台支持主流开发协议与工具链，具备依赖安全审计、开源合规报告、模型项目适配等基础能力。&lt;/p&gt; 
&lt;p&gt;更重要的是，Gitee 并不以「替代 GitHub」为目标，而是以建设中国本土长期可用、制度可托管、生态可沉淀的开源基础设施为使命。这意味着即使外部平台可访问，中国开发者也始终拥有一个&lt;strong&gt;主场能力完整、风险容忍度高、制度合规的备选方案。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;马建仓写在最后：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;任何平台都可能出现技术异常，但当基础设施不可控时，问题的本质不是技术，而是体系风险。我们并不怀疑全球协作的价值，但必须正视，在不确定性上升的时代背景下，一个国家应具备自主的开源基础设施，才能为技术发展提供确定性空间。&lt;/p&gt; 
&lt;p&gt;Gitee 的建设，是在为这种确定性提供基础支持。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;真正可持续的开放协作，不应只有一个平台、一个路径。基础设施建设的本质，是为开发者提供在关键时刻不被动、不掉线、不失联的保障能力。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360890</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360890</guid>
      <pubDate>Wed, 16 Jul 2025 10:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节视觉大模型负责人今日内部官宣「暂时休息」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.163.com%2Ftech%2Farticle%2FK4M5GU1B00098IEO.html" target="_blank"&gt;根据网易科技的独家报道&lt;/a&gt;&lt;/u&gt;，7 月 17 日上午，字节跳动豆包大模型视觉多模态生成方向负责人杨建朝在公司内部宣布「暂时休息」，相关工作已完成交接，其职务由周畅（花名「时光」）接手。&lt;/p&gt; 
&lt;p&gt;周畅所在架构为「多模态交互与世界模型」部门，向 Seed 基础研究负责人吴永辉汇报 。&lt;/p&gt; 
&lt;p&gt;此次人事变动原因未明确，有知情人士称是「家庭因素」，也有传言称杨建朝因长期高强度工作身心俱疲，甚至有「提前退休」的说法 。&lt;/p&gt; 
&lt;p&gt;杨建朝是字节 AI 体系内公认的「技术大牛」，曾师从「计算机视觉之父」Thomas Huang，2018 年加入字节跳动，2023 年起带领 Seed 视觉部门 。&lt;/p&gt; 
&lt;p&gt;接任者周畅本科毕业于复旦大学，博士就读于北京大学，曾任阿里巴巴通义千问大模型技术负责人，主导开发了 M6 多模态预训练模型，2025 年 7 月从阿里离职后加入字节跳动 Seed 团队 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360880</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360880</guid>
      <pubDate>Wed, 16 Jul 2025 09:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌高管澄清 Chrome OS 合并到 Android 的报道</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌 Android 生态系统负责人 Sameer Samat 最近确认，谷歌计划将 Chrome OS 与 Android &lt;a href="https://www.oschina.net/news/360389/google-says-chromeos-will-merge-into-android"&gt;合并&lt;/a&gt;为一个统一平台，未来 Chromebook 和 Android 平板电脑将运行基于 Android 的桌面优化版本，从而提供跨设备的无缝体验。&lt;/p&gt; 
&lt;p&gt;不过，Samat 随后在社交媒体上&lt;strong&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fssamat%2Fstatus%2F1944822333811970336" target="_blank"&gt;澄清表示&lt;/a&gt;&lt;/strong&gt;，他只是重申了 2024 年谷歌博客中的&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.chromium.org%2F2024%2F06%2Fbuilding-faster-smarter-chromebook.html" target="_blank"&gt;公告&lt;/a&gt;&lt;/u&gt;，即 Chrome OS 将基于 Android 底层技术（如 Android 内核）构建，以提升性能、加快开发速度，并让笔记本电脑和手机更好地协同工作。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1652" src="https://static.oschina.net/uploads/space/2025/0717/173104_cc16_2720166.png" width="1276" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管 Samat 的澄清强调 Chrome OS 体验将基于 Android 技术构建，而非字面意义上的「合并」，但外界普遍认为这暗示了 Chrome OS 和 Android 将走向深度融合，未来二者将更紧密地整合。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360879</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360879</guid>
      <pubDate>Wed, 16 Jul 2025 09:33:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Python 核心开发者对 Rust 的期望</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;PyO3 维护者 David Hewitt 在 2025 年 Python 语言峰会上探讨了对 Rust 的期望。&lt;/p&gt; 
&lt;p&gt;David Hewitt 指出：「根据对 PyPI 上传包中原生扩展的统计估算，有约 1/4 到 1/3 的新项目选择 Rust 实现本地扩展。」&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;他展示了 PyO3 如何简化 Python 中的 Rust 使用，并讨论了 Rust 在支持 Python 自由线程方面的优势，以及在 GCC 后端和子解释器隔离方面的挑战。他还提出了 Python 核心开发者是否应投资 Rust 的问题，认为 Rust 的采用可能增加开发者人才库，并建议开发更高层次的 Rust API 以替代 C API。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="font-family:-apple-system,BlinkMacSystemFont,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;,&amp;quot;Segoe UI&amp;quot;,&amp;quot;PingFang SC&amp;quot;,&amp;quot;Hiragino Sans GB&amp;quot;,&amp;quot;Microsoft YaHei&amp;quot;,&amp;quot;Helvetica Neue&amp;quot;,Helvetica,Arial,sans-serif"&gt;对于是否要&lt;/span&gt;投入 Rust，David Hewitt 认为可借鉴如 Linux 内核「Rust for Linux」的策略：先从隔离模块切入，逐步推行。&lt;/p&gt; 
&lt;p&gt;当然也存在一些挑战，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;社区中对平台兼容、调试体验、二进制膨胀都表达担忧。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rust 目前尚无稳定 ABI，panic 行为也可能增加体积（David 建议关闭 panic 并禁用 std 库以缓解）&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;总的来说，David Hewitt 并非完全反对 Rust，而是在「可选、渐进、工具链完善」的框架下持审慎开放态度。Rust 的吸引力在于扩展人才库、提升安全性和模块化能力，但要落地则需构建系统与平台支持上的配合。下一步若能拆解边界、验证原型，就有可能慢慢形成「Rust for Python」的生态愿景。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpyfound.blogspot.com%2F2025%2F06%2Fpython-language-summit-2025-what-do-core-developers-want-from-rust.html" target="_blank"&gt;详情查看原文。&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360855/core-python-developers-want-from-rust</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360855/core-python-developers-want-from-rust</guid>
      <pubDate>Wed, 16 Jul 2025 07:40:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>《自然》网站：中国 AI 模型「又一个 DeepSeek 时刻」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;英国《自然》杂志网站 16 日发表文章说，中国人工智能（AI）模型 Kimi K2 发布后引发轰动，世界迎来「又一个 DeepSeek 时刻」。中国在 6 个月内推出第二款令人印象深刻的模型，表明这一成功并非偶然。文章摘要如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;继今年 1 月 DeepSeek-R1 震惊世界之后，全球研究人员对中国推出的第二个强大的 AI 模型越来越感到兴奋。北京月之暗面科技有限公司于 7 月 11 日推出了 Kimi K2。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="298" src="https://oscimg.oschina.net/oscnet/up-fa03af77a29513f15fe583488e9a54394d3.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Kimi K2 在编程方面的表现尤其出色，在 LiveCodeBench（一个专门用于评估大型语言模型编码能力的数据集）等测试中取得了高分。此外，Kimi K2 似乎还颇具写作天赋，在一些专业测试中名列前茅。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，包括硅谷的开源社区等在内的 AI 开发者都在热议 Kimi K2。官方数据显示，其总参数规模达到了万亿级别（1T），不过由于采用混合专家架构，每次任务仅动态激活 320 亿参数，只需调用模型中相关模块，从而有助于控制所需算力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;与 DeepSeek 系列模型类似，Kimi K2 采用开源协议发布，允许研究人员免费下载并进行本地部署与二次开发。同时，该模型支持通过应用程序接口调用，其定价显著低于「克劳德 4」等主流闭源模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;美国艾伦人工智能研究所机器学习研究员纳坦·兰伯特说：「今年早些时候发布的 DeepSeek-R1 更像是 AI 发展轨迹中的前传，而非昙花一现。Kimi K2 是全球最佳的全新开源模型。」（新华社）&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/360215/kimi-k2" target="_blank"&gt;月之暗面发布并开源 Kimi K2：擅长代码与 Agentic 任务&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360853</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360853</guid>
      <pubDate>Wed, 16 Jul 2025 07:12:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>QuestDB 9.0 正式发布，高性能开源时序数据库</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;QuestDB 是一款开源的时序数据库，提供了超低延迟、高吞吐量和多层存储引擎，支持多种协议（如 InfluxDB 行协议、PostgreSQL 协议、REST API），并与许多工具和语言集成，非常适合金融市场数据、实时分析等场景。&lt;/p&gt; 
&lt;p&gt;QuestDB 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fquestdb%2Fquestdb%2Freleases%2Ftag%2F9.0.0" target="_blank"&gt;发布&lt;/a&gt;重大版本 9.0，增加了 N 维数组、日历感知的物化视图 (materialized views)、提高了数据去重效率、实现了更智能的 JOIN，并重构了 Web 控制枱的 UX。&lt;/p&gt; 
&lt;p&gt;下面介绍&amp;nbsp;QuestDB 9.0 值得关注的新特性。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;支持 N 维数组&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;引入真正的 N 维数组（类似 NumPy 的数组），支持零拷贝切片、转置、累积操作和聚合，适用于市场数据订单簿深度或机器学习权重快照，目前支持 &lt;code&gt;DOUBLE[]&lt;/code&gt; 类型，更多数据类型即将推出。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bcb957ee2bfc9035579b27e3cc9e5e477f7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;二进制行协议&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;支持二进制 &lt;code&gt;DOUBLE[]&lt;/code&gt; / &lt;code&gt;DOUBLE&lt;/code&gt; 协议，提升高吞吐量摄取效率，降低带宽使用，加快服务器端处理速度。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;import pandas as pd
from questdb.ingress import Sender

df = pd.DataFrame({
    'symbol': pd.Categorical(['ETH-USD', 'BTC-USD']),
    'side': pd.Categorical(['sell', 'sell']),
    'price': [2615.54, 39269.98],
    'amount': [0.00044, 0.001],
    'ord_book_bids': [
        np.array([2615.54, 2618.63]),
        np.array([39269.98, 39270.00])
    ],
    'timestamp': pd.to_datetime(['2021-01-01', '2021-01-02'])})

conf = f'http::addr=localhost:9000;'
with Sender.from_conf(conf) as sender:
    sender.dataframe(df, table_name='trades', at='timestamp')&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;升级物化视图&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新增高效的 &lt;code&gt;replace commit&lt;/code&gt; 机制、支持自 &lt;code&gt;UNION&lt;/code&gt; 查询、延迟或推迟刷新，并引入三种新的视图刷新模式（&lt;code&gt;TIMER&lt;/code&gt;、&lt;code&gt;MANUAL&lt;/code&gt; 和 &lt;code&gt;PERIOD&lt;/code&gt;），后者支持时区感知、日历调度的刷新。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;优化数据去重&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;提高数据去重效率，新增优化以跳过未更改的数据，减少 I/O 开销。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;import pandas as pd
from questdb.ingress import Sender

df = pd.DataFrame({
    'symbol': pd.Categorical(['ETH-USD', 'BTC-USD']),
    'side': pd.Categorical(['sell', 'sell']),
    'price': [2615.54, 39269.98],
    'amount': [0.00044, 0.001],
    'ord_book_bids': [
        np.array([2615.54, 2618.63]),
        np.array([39269.98, 39270.00])
    ],
    'timestamp': pd.to_datetime(['2021-01-01', '2021-01-02'])})

conf = f'http::addr=localhost:9000;'
with Sender.from_conf(conf) as sender:
    sender.dataframe(df, table_name='trades', at='timestamp')&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;改进 Web 控制枱&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;界面焕然一新，支持多行查询同时执行、查询日志记录，以及通过右键点击运行箭头获取查询计划，便于调试。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5a75647747a5801a5b947e40d9934391525.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e2d5e0df806acc6ec114c042c70fad3489e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ASOF JOIN with TOLERANCE&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;新增 &lt;code&gt;TOLERANCE&lt;/code&gt; 参数，允许为匹配设置合理的时间范围，便于处理特定时间后「过期」的数据。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;DECLARE
  @level := insertion_point(bids[2], bid_volume),
  @price := bids[1][@level]
SELECT
  md.timestamp market_time,
  @level level,
  @price market_price,
  cp.timestamp core_time,
  cp.bid_price core_price
FROM  (
  core_price
  WHERE timestamp IN today()
  AND symbol = 'GBPUSD'
  LIMIT -6
) cp
-- Match the bid to its nearest price within one second.
ASOF JOIN market_data md
ON symbol TOLERANCE 1s;&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fquestdb.com%2Fblog%2Fquestdb-9-release%2F" target="_blank"&gt;详情查看发布公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360851/questdb-9-released</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360851/questdb-9-released</guid>
      <pubDate>Wed, 16 Jul 2025 06:50:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​Anthropic 估值飙升至 1000 亿美元，年收入增长四倍</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;据知情人士透露，Anthropic 的最新估值已突破 1000 亿美元，较四个月前的 580 亿美元几乎翻了一番。这一估值的提升，主要得益于 Anthropic 近期向部分投资者披露的财务表现，尤其是其年化收入在 2023 年上半年增长了四倍，已超过 40 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="283" src="https://oscimg.oschina.net/oscnet/up-2b2cb044977b9978c1bd2df664e5717d5e0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;为了支持这一增长，Anthropic 在 3 月完成了 35 亿美元的股权融资，并计划在今年总计融资 55 亿美元。尽管整个 AI 行业仍在进行巨额投入，但头部公司如 Anthropic 已经展示出强大的商业化能力，吸引了投资者的关注，特别是在 AI 编码等高利润领域的表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;从盈利能力的角度来看，Anthropic 的财务状况相对复杂。公司通过直接向客户销售其 AI 模型和 Claude 聊天机器人，实现了约 60% 的毛利率，未来有望提高到 70%。不过，Anthropic 还通过亚马逊云和谷歌云进行销售，这部分业务的毛利率却为负 30%。截至 2023 年底，该公司的 70% 收入来自直销，整体毛利率在 50% 至 55% 之间，未见显著改善。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作为大型语言模型的成功应用之一，自动化编码任务也为 Anthropic 带来了丰厚的收益。其编码助手 Claude Code 自 5 月全面上线以来，下载量每周增长六倍，目前已达到 300 万次。该产品也成为公司的重要收入来源，贡献了超过 2 亿美元的年化收入。此外，Anthropic 的增长还间接推动了其他初创公司的发展，如竞争对手 Cursor，其年收入自去年 11 月以来增长了 10 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在资金消耗方面，Anthropic 与 OpenAI 面临着相似的挑战。预计 Anthropic 在今年的现金消耗为 30 亿美元，而 OpenAI 预计为 68 亿美元。尽管 OpenAI 的收入是 Anthropic 的数倍，但其现金消耗却更少。总体而言，两家公司的惊人收入增长让投资者感到乐观，预计都会超越年初设定的目标。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/360846</link>
      <guid isPermaLink="false">https://www.oschina.net/news/360846</guid>
      <pubDate>Wed, 16 Jul 2025 06:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
