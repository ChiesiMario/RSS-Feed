<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 03 Jul 2025 12:48:53 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>全球 AI 人才榜单首次曝光，华人撑起半边天</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 3 日，2025 全球数字经济大会上，一份重磅榜单面向全球首次揭晓。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;该榜单基于近十年近 10 万篇文献深度分析，列出了全球人工智能领域的 Top100 人才&lt;/strong&gt;。其中，华人依旧拿下了主力席位。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FsDvBk1WCxUrJqMOu2Q9p6g" target="_blank"&gt;凤凰网科技从中提炼了出了一份较为瞩目的人员名单&lt;/a&gt;，这些人现多数就职于国内外企业，仍在人工智能前沿探索领域活跃，包括：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;何恺明&lt;/strong&gt;，曾任职于 AI 殿堂美国麻省理工学院（MIT），作为 ResNet 之父，是深度学习革命的关键推手，其提出的残差学习（Residual Learning）概念，一举攻破了困扰神经网络多年的「梯度消失」难题，让深达千层的网络训练成为可能。其论文引用数以骇人的数十万次傲视群雄（公开数据约 40 万 +），被誉为「CV 界的诺奖级工作」。6 月 26 日，何恺明刚刚官宣入职 GoogleDeepMind，担任杰出科学家，同时还保留了 MIT 终身副教授身份。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194046_NzCP_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;张祥雨&lt;/strong&gt;，曾是旷视研究院的顶梁柱，现已入职阶跃星辰任首席科学家； 2016 年，以 ResNet（作为核心贡献者之一）问鼎 CVPR 最佳论文，震动世界！随后在 ImageNet、COCO 等视觉「奥林匹克」赛场多次屠榜。其与团队开创的 ResNet、ShuffleNet 系列影响颇深，Google Scholar 引用逾 40,000 次，是无数手机、摄像头、自动驾驶系统的「核心引擎」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194104_my7v_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;任少卿&lt;/strong&gt;，蔚来汽车自动驾驶的灵魂人物，计算机视觉与自动驾驶融合领域的顶尖专家，曾发表多篇极具影响力的 CV 顶会论文。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194115_XBIO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/9ccdcd47-cf38-495f-a15c-11c7758e41da.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;田奇&lt;/strong&gt;，华为在人工智能领域的重要人物，也是华为计算产品线（升腾 AI 处理器等）和 MindSpore 框架背后的核心操盘手。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194127_1K5b_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/06d18e54-babe-4198-a0f2-f0ed8e8fc7d2.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;王云鹤&lt;/strong&gt;，华为诺亚方舟实验室的研究员。专注于 AI 基础模型、神经网络架构搜索（NAS）、模型轻量化等前沿方向，是华为 AI「顶天」（前沿）又「立地」（落地）战略的重要实践者。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194139_3XP0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/3e5805f0-1b78-44bb-ba08-0ba2b5e6c899.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;谢凌曦&lt;/strong&gt;，华为天才少年，在计算机视觉，特别是视觉大模型、自监督学习、对抗鲁棒性等领域有系列开创性工作。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194149_Jxf5_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/85b5a95b-03b3-4936-96f3-fecdbf8a954a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;strong&gt;王晓刚&lt;/strong&gt;，商汤科技联合创始人、核心技术奠基人之一。在商汤，他主导了核心视觉算法框架的构建。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194158_juQG_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b2340c80-9b01-4125-9c86-035e2353db25.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;石建萍&lt;/strong&gt;，商汤科技自动驾驶研发团队的领军女将。带领团队在智能驾驶视觉感知、多传感器融合、高精定位等方面取得突破性进展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194208_Tj3r_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/b0c91622-96b2-4f33-be72-40b2b4802389.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;闫俊杰&lt;/strong&gt;，MiniMax 创始人，国内最早一批成立的大模型公司核心人物。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194219_yNU3_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/6b21b373-3805-435f-8f02-df120995bb9a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;曹越&lt;/strong&gt;，前微软杰出工程师，现 Sand.AI 创始人兼 CEO。专注打造下一代 AI 智能体（AI Agent）平台。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194228_wqU6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f1b580d1-bd41-490b-9080-e4bdc8effc1e.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;陶大程&lt;/strong&gt;，新加坡南洋理工大学（NTU）协理副校长、澳大利亚桂冠教授，视觉大牛，IEEE / AAAS / ACM 三料 Fellow，曾任京东探索研究院院长（2023 年卸任）。研究横跨计算机视觉、机器学习、统计学习、可信 AI（鲁棒性、可解释性、公平性）等核心领域。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194240_wWsg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/cb439f78-abc0-4ebb-a823-9121a7ada5a5.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;刘子纬&lt;/strong&gt;，新加坡南洋理工大学（NTU）新锐实力派教授，学术明星。在视觉-语言理解（VLP）、多模态大模型、信息检索方向成果斐然。其工作多次发表于 CVPR, ICCV, NeurIPS 等顶会，并常居排行榜前列，是推动多模态预训练模型发展与应用的重要力量。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194307_cOI1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/e10b6eaa-b533-4846-ac3d-1688c5e7ca50.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;贾佳亚&lt;/strong&gt;，香港中文大学计算机科学与工程系教授，思谋科技创始人。著名计算机视觉学者，专注于底层视觉重建、图像增强、图像分割、医学图像分析等方向。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194322_DDlL_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/f17121d8-c2e7-4ff0-9203-e1743fc8674f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;杨明玄&lt;/strong&gt;，美国加州大学默塞德分校（UC Merced）计算机科学教授,Google DeepMind 研究员。深耕机器学习和数据挖掘领域，特别是在图神经网络（GNN）、推荐系统、社交网络分析等方面有突出建树。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194332_aIW0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/5c0ee9b8-ae73-4c39-b4ad-9ba80f95187f.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;刘威&lt;/strong&gt;，前腾讯混元大模型技术负责人之一，腾讯杰出科学家，2025 年初离职创业。2024 年领导开源混元文生图模型、3D 生成模型「Hunyuan3D-1.0」，推动腾讯内部 700 + 业务接入 AI 能力（如微信输入法、腾讯会议）。发表顶会论文 100 + 篇，总引用 3600 + 次，获 CVPR 青年研究者奖、SIGIR 最佳论文荣誉奖。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194344_6WyQ_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/44dd9265-ca1d-4db3-8e44-70ee47565a3a.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;颜水成&lt;/strong&gt;，新加坡国立大学终身教授，培养 50 + 名博士，建立亚太最大计算机视觉实验室，历任 360 首席科学家、依图 CTO、Sea 集团 AI Lab 主任；2023 年加入昆仑万维任 2050 全球研究院院长，2024 年底卸任。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/194359_j5g6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;img alt="" src="https://img.ithome.com/newsuploadfiles/2025/7/496764e9-1b16-47dd-a8e1-3349844dd95d.png?x-bce-process=image/format,f_avif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据东壁科技数据创始人、深圳大学特聘教授吴登生介绍，该报告基于东壁全球科技文献数据平台（dbdata.com），对全球 AI 研究生态进行系统分析，数据集涵盖近 20 万名来自 175 个国家和地区、3847 个机构的学者，时间跨度为 2015 至 2024 年。&lt;/p&gt; 
&lt;p&gt;值得一提的是，何恺明、刘子纬、王晓刚、陶大程均师承中国人工智能先驱、商汤科技创始人汤晓鸥，张祥雨曾师从何恺明。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358641</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358641</guid>
      <pubDate>Thu, 03 Jul 2025 11:45:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Bytebase 3.8.0 - 显著优化 schema 同步 / 回滚兼容性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;🔔 重大变更&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;显著优化多数据库（MySQL/PostgreSQL/TiDB/SQL Server/Oracle）的 schema 同步/回滚兼容性，支持绝大多数常见数据库对象。 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fchange-database%2Fsynchronize-schema%23supported-objects" target="_blank"&gt;文档地址&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-21a7f23efb479d2c33408917a613e8bb91b.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下线工单订阅功能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将 SQL 审核中心更名为变更计划。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;🎄 改进&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增查询结果行数限制功能。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-cad54dad1deaf4e15ad8f12933c09c1609c.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增多域名配置支持。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-4380358be992a487045a8f39061a6ba967e.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;简化默认值输入：不再区分表达式和值，统一通过文本输入框填写。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在审批流程处展示全部审批人，且可悬停显示细节。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-5c8191a2cf70d8536b5ec930d9fca7b36e2.png" alt="file" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h1&gt;🐞 Bug 修复&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;修复了 ClickHouse 查询中的 JSON 数据类型显示问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在 Terraform SSL 配置中新增 &lt;code&gt;use_ssl&lt;/code&gt; 字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📕 安装及升级&lt;/h1&gt; 
&lt;p&gt;新安装 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fself-host" target="_blank"&gt;https://docs.bytebase.com/get-started/self-host&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;升级 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.bytebase.com%2Fget-started%2Fupgrade" target="_blank"&gt;https://docs.bytebase.com/get-started/upgrade&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;升级前请备份元数据库，升级后无法回退版本。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;💡 更多资讯，请关注 Bytebase 公号：Bytebase&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6148470/blog/18683355</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6148470/blog/18683355</guid>
      <pubDate>Sun, 11 May 2025 10:24:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Perplexity 上线月费 200 美元的「Max」订阅服务</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Perplexity 公司推出了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhub%2Fblog%2Fintroducing-perplexity-max" target="_blank"&gt; Perplexity Max &lt;/a&gt;订阅服务，月费为 200 美元（约合 1433 元人民币），可以享受诸多权益。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1abe17d787b691e146a089eccf4834806a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;购买 Perplexity Max 订阅计划的用户，可以无限制访问电子表格和报告生成工具 Labs，并支持提前体验 Comet 浏览器在内的诸多新功能。&lt;/p&gt; 
&lt;p&gt;该公司表示，Perplexity Max 是为以下用户设计的：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要无限访问全面分析工具的专业人士&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要大量研究能力的内容创作者和作家&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;进行竞争情报和市场研究的商业策略师&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从事复杂、多方面项目的学术研究人员&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Max 用户还支持在 Perplexity 服务中，调用 OpenAI 的 o3-pro 和 Claude Opus 4 等先进 AI 模型。随着 Max 的推出，Perplexity 成为最新一家推出超高端订阅服务层的 AI 提供商。&lt;/p&gt; 
&lt;p&gt;OpenAI 是首家推出每月 200 美元的 ChatGPT Pro 订阅服务的公司，但近几个月来，Google、Anthropic 和 Cursor 也纷纷效仿。&lt;/p&gt; 
&lt;p&gt;Perplexity 目前提供多种订阅计划。除了每月 200 美元的 Max 计划外，还提供每月 20 美元的消费者 Pro 计划，以及每人每月 40 美元的企业 Pro 计划。该公司表示，最终也将为企业客户推出超高端的 Max 计划。&lt;/p&gt; 
&lt;p&gt;Perplexity 在 2024 年主要依靠每月 20 美元的 Pro 计划订阅，实现了大约 3400 万美元的收入，但据 The Information 看到的财务数据，公司仍烧掉了约 6500 万美元现金。&lt;/p&gt; 
&lt;p&gt;据报道，Perplexity 的现金消耗主要来自对云服务器的重金投入以及购买 OpenAI 和 Anthropic 的 AI 模型访问权。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.perplexity.ai%2Fhelp-center%2Fen%2Farticles%2F11680686-perplexity-max" target="_blank"&gt;https://www.perplexity.ai/help-center/en/articles/11680686-perplexity-max&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358621/perplexity-max</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358621/perplexity-max</guid>
      <pubDate>Sun, 11 May 2025 09:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>X 平台（原 Twitter）上线 AI 笔记功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;X 平台（原 Twitter）&lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FCommunityNotes%2Fstatus%2F1940132205486915917" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;正式启动 AI Note Writer 的 API 试点计划，允许全球开发者创建 AI 机器人来撰写社区内容。未来，这些由 AI 撰写的笔记如果被一定数量的用户认为有帮助，就可以在平台上公开展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b9141239b889f5cfe9e01d79314f39bdc80.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;X 表示，该计划旨在加速社区内容的产出效率，同时通过社区反馈机制，不断优化 AI 的准确性、公正性与实用性。AI 笔记将遵循与人工内容相同的审核准则，并会在介面中明确标注。&lt;/p&gt; 
&lt;p&gt;首批 AI Note Writer 将在本月内开放上线，且将逐步开放。&lt;/p&gt; 
&lt;p&gt;详情查看文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunitynotes.x.com%2Fguide%2Fen%2Fapi%2Foverview" target="_blank"&gt;https://communitynotes.x.com/guide/en/api/overview&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358606/ai-note-writer-api</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358606/ai-note-writer-api</guid>
      <pubDate>Sun, 11 May 2025 08:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>毕马威：医疗大模型中国发布数量占全球七成</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;毕马威中国发布《首届健康科技 50》报告指出，医疗大模型目前主要分为五类，包括大型语言模型 (LLM)、语言条件多智能体大型、多模态大模型、图学习大模型、视觉语言大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在全球范围内，据不完全统计，在已发布的医疗大模型中，按模型类别来看，大语言模型数量最多，占比近 65%；按分布海内外发表数量来看，中国发布数量占比超 70%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="265" src="https://oscimg.oschina.net/oscnet/up-0f5af0008879ca0ee50480307bd0d62db20.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外报告指出，2024 年，中国医疗科技市场规模突破百亿，达到 102.5 亿元，同比增长 75.3%。2025-2027 年，中国医疗科技的增幅预计会有所放缓，但行业总市场规模仍呈现稳健增长趋势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2023 年中国医疗机器人市场规模达到约 108 亿元，近五年年均复合增长率高达 25.74%。中国智能医疗器械市场增长迅猛，预计 2025 年将达 242.3 亿元，2026 年-2027 年总体有望保持较高速增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;更多详情可&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fassets.kpmg.com%2Fcontent%2Fdam%2Fkpmg%2Fcn%2Fpdf%2Fzh%2F2025%2F07%2Fkpmg-china-healthcare-health-tech-50.pdf" target="_blank"&gt;查看完整报告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358603</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358603</guid>
      <pubDate>Sun, 11 May 2025 08:21:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>IT 技术人员被解雇，怒改公司所有密码，获刑 7 个月</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;据报道，在英国西约克郡，一位被解雇 IT 技术人员因心怀怨恨，对雇主公司发动了一场数字攻击，最终被判处 7 个月零 14 天的监禁。&lt;/p&gt; 
&lt;p&gt;根据警方的公告，2022 年 7 月，Mohammed Umar Taj 在被公司暂停工作后的数小时内，便开始实施恶意的 「数字暴行」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d7c99b29132ed474e2163c68143d842ddfa.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;他非法侵入公司系统，擅自更改登录凭证，还破坏了公司的多因素身份验证系统，致使公司日常运营受到严重干扰，造成至少 20 万美元的损失。&lt;/p&gt; 
&lt;p&gt;公司称 Taj 的报复行为不仅给公司带来了经济损失，还损害了公司的声誉，给公司带来了声誉损害和业务损失。&lt;/p&gt; 
&lt;p&gt;由于网络攻击的连锁反应，不仅约克郡的员工工作受阻，英国、德国以及巴林的客户也受到了不同程度的影响。&lt;/p&gt; 
&lt;p&gt;上周，31 岁的 Taj 在约克郡的利兹刑事法庭出庭受审，他在之前的听证会上承认了 「未经授权对计算机进行操作并妨碍计算机访问」 的罪名，最终被判处 7 个月零 14 天的监禁。&lt;/p&gt; 
&lt;p&gt;警方还在报告中提醒所有企业：「保护好你们的网络，这不仅能防止数据丢失和代价高昂的网络攻击，还能维护与客户和利益相关者的信任关系。」&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以下是该事件的具体介绍：&lt;/p&gt; 
&lt;h3&gt;案件经过&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Taj 在被公司停职后，公司未及时撤销其账号权限，他便利用这一漏洞，非法侵入系统，篡改了公司的系统权限，把公司员工以及海外客户都踢出系统之外，导致公司运营陷入瘫痪。&lt;/li&gt; 
 &lt;li&gt;他在实施攻击后，还曾 「自豪地谈论」 自己的攻击过程，警方在后续调查中找到了他作案的操作记录和通话内容。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;法院判决&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Taj 最终在利兹皇家法院承认自己未经授权干扰公司计算机系统的正常运行，于 2025 年 6 月 26 日在利兹刑事法庭被判处七个月零 14 天的监禁。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;事件影响&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;直接经济损失&lt;/strong&gt; ：该公司遭受了至少 20 万英镑的损失，约合人民币近 200 万元。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;业务中断&lt;/strong&gt; ：系统的瘫痪直接导致公司业务无法正常开展，无论是内部的日常运作还是与海外客户的合作都受到了严重影响，公司的声誉也受到了损害。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358595</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358595</guid>
      <pubDate>Sun, 11 May 2025 08:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Cloudflare 推出「按次抓取付费」计划，发起「内容独立日」倡议</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Cloudflare 宣布推出一项名为 「Pay per crawl」 的新功能，并联合多家内容平台发起 「内容独立日」 倡议，旨在改变 AI 公司无偿抓取网络内容进行模型训练的现状。该计划允许网站所有者向 AI 爬虫收取内容访问费用，为内容创作者提供除完全开放或完全封锁之外的第三种选择。Cloudflare 将担任该计划的记录商家（Merchant of Record）。&lt;/p&gt; 
&lt;p&gt;该功能基于 HTTP 状态码 402 (Payment Required) 实现。当 AI 爬虫请求受保护内容时，若未携带支付意图，将收到 402 响应及定价信息。网站所有者可以为自己的域名设定一个统一的、按次请求的单价，并对不同的 AI 爬虫设置三种策略：允许免费访问、按价收费或完全阻止。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-5f8ad61f543b26ca4f0d391b8c340b1f6a3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;技术上，该系统通过 「Web Bot Auth」 机制，使用 Ed25519 密钥对和 HTTP 消息签名来验证爬虫身份，防止欺骗。爬虫可通过在请求头中加入 crawler-max-price（愿意支付的最高价格）或在收到 402 响应后加入 crawler-exact-price（同意支付的确切价格）来表明支付意图。交易成功后，响应头中会包含 crawler-charged 字段。&lt;/p&gt; 
&lt;p&gt;过去 30 年，谷歌和内容创作者之间形成了一种默契：谷歌用创作者的内容吸引用户搜索，再把用户送回原网站，让创作者赚取广告费或订阅收入。但随着 AI 工具兴起，用户越来越多地直接从 AI 获得答案，原创内容的网站流量暴跌，创作者的收益严重受损。&lt;/p&gt; 
&lt;p&gt;为此，Cloudflare 联合众多内容平台，在 2025 年 7 月 1 日宣布了 「内容独立日」，明确要求 AI 公司不能再免费抓取内容，必须为内容创作者支付合理的报酬。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b62a9cf03f1853620715f17a648ca213898.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 表示，此举旨在为内容创作者提供对其数字资产的程序化控制，确保他们能从自己的工作中获得补偿，从而维持一个健康、多样化的互联网内容生态。未来，该系统有望演变为一个更复杂的代理（Agent）经济市场，AI 代理可以根据预算，以编程方式协商并购买所需的数据访问权限。&lt;/p&gt; 
&lt;p&gt;他们希望通过这样的行动，让创作者重新获得应有的价值和尊重，同时推动 AI 和原创内容之间形成一种新的、公平的生态模式。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;更多详情：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fcontrol-content-use-for-ai-training%2F"&gt;https://blog.cloudflare.com/control-content-use-for-ai-training/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fzh-cn%2Fcontent-independence-day-no-ai-crawl-without-compensation%2F"&gt;https://blog.cloudflare.com/zh-cn/content-independence-day-no-ai-crawl-without-compensation/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358592/content-independence-day-no-ai-crawl</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358592/content-independence-day-no-ai-crawl</guid>
      <pubDate>Sun, 11 May 2025 07:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯提醒开发者可将微信小程序迁移至 QQ 客户端</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯 QQ 小程序开发者平台发文，提醒 QQ 客户端将全面接入微信小程序，&lt;strong&gt;开发者可以将微信小程序迁移至 QQ 以取代原有的旧版 QQ 小程序&lt;/strong&gt;，开发者当前已上线的旧版 QQ 小程序仍可正常使用和更新，不过官方称「强烈建议尽早迁移，以便获得更完整的接口支持，同时享受 QQ + 微信的双端流量红利」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e508f98702091d79c43aa333caf718d83a9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;迁移前，QQ 小程序引擎实际上对微信小程序的大多数接口进行了兼容，原本只需要在微信小程序原有代码基础上做一些简单判断（主要是登录方面）就可以分别提交两个平台。&lt;/p&gt; 
&lt;p&gt;而在迁移后，QQ 端运行的就是微信小程序，体验比 QQ 小程序会好一些。开发者需要通过 QQ 提供的插件（qq-wxmini-plugin）区分运行环境、处理登录逻辑。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;来源：https://m.ithome.com/html/864991.htm&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/346915" target="news"&gt;手机版 QQ 支持微信小程序&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358586</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358586</guid>
      <pubDate>Sun, 11 May 2025 07:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>多模态才是智能应用爆发的关键？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;此前，快手发布 2025 年一季度财报时，一个数字引发关注：成立仅两年的 AI 业务线「可灵 AI」单季度贡献营收 1.5 亿元，同比增长 320%。而可灵 AI 正是一个多模态应用的典型产品，涉及到语言、视频、音频等交互。&lt;/p&gt; 
&lt;p&gt;前不久，在 OSCHINA 和小度教育技术负责人丁小晶的&lt;a href="https://my.oschina.net/u/4489239/blog/18426743" rel="nofollow"&gt;对话&lt;/a&gt;中。丁小晶表示，多模态技术非常重要，甚至可以说，没有多模态技术效果的快速提升，教育行业不可能如此迅猛发展。比如 AI 作业批改和 AI 讲题答疑方向的应用，完全靠纯文本大模型是无法满足需求的，非常依赖对大模型的图片理解能力。还比如超拟人 AI 老师，语音情感大模型就起来非常关键的作用。&lt;/p&gt; 
&lt;p&gt;百度最新发布的发布文心快码 Comate AI IDE 产品，其中也提到了多模态能力的增强，比如支持 Figma 设计稿一键转换为高可用代码，能实现图层的精准还原。百度工程效能部前端研发经理杨经纬告诉开源中国，无论是从自然语言、图片还是设计稿生成代码，最终都是为了能更加接近人类工程的意图，因为人类去描述自己想要实现的想法的方式与形态是多种多样的，也就对应了研发过程中的多模态形式。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="210" src="https://oscimg.oschina.net/oscnet/up-db06f16dbd4e854566d762bff8c3dfe1e5f.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;人类从不会只用一种感官认知世界。人工智能也势必不能仅有一种交互途径。&lt;/p&gt; 
&lt;p&gt;我们闻到咖啡香气的瞬间，脑海里会立刻浮现深褐色液体与白瓷杯的画面；听到「猫」这个词时，脑海中自动补全毛茸茸的触感和呼噜声。这种多模态信息融合，正是人类智能的底层逻辑。而单一模态交换的 AI 模型的信息处理能力有限，例如文本生成模型难以理解图像语义，无法根据文字生成图像，视频生成工具则无法同步解析声音与画面逻辑。这种时候，就需要多模态模型或是能力的配合。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;多模态，比文本慢一步&lt;/h2&gt; 
&lt;p&gt;智源研究院院长王仲远不久前公开&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.cn%2Fzh-cn%2F%25E6%258A%2580%25E6%259C%25AF%2F%25E6%258A%2580%25E6%259C%25AF%25E5%2585%25AC%25E5%258F%25B8%2F%25E8%2581%259A%25E7%2584%25A6%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581-chatgpt%25E6%2597%25B6%25E5%2588%25BB%25E6%259C%25AA%25E5%2588%25B0-2025%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B-%25E5%258F%2598%25E6%2585%25A2-%25E4%25BA%2586%25E5%2590%2597%2Far-AA1GjaHk%3Focid%3DBingNewsSerp" rel="nofollow" target="_blank"&gt;指出&lt;/a&gt;，当前多模态大模型的学习路径，尤其是多模态理解模型，通常是先将语言模型训练到很强的程度，再学习其他模态信息。在这个过程中，模型的能力可能会出现下降。&lt;/p&gt; 
&lt;p&gt;比单一模态更难的是，多模态模型还需解决一个核心问题：如何将图像、文本、音频等异构数据在语义层面对齐并融合。&lt;/p&gt; 
&lt;p&gt;文本、图像、声音等模态的数据结构天然异构——文本是离散符号序列，图像是连续像素矩阵，音频是时间序列信号。比如要让模型理解「猫」的文本描述与猫的图片、叫声之间的关联，需构建跨模态的共享语义空间。&lt;/p&gt; 
&lt;p&gt;早期，有研究尝试通过数据级拼接，将图像像素和文本特征直接拼接，实现跨模态融合，但由于图像和文本的时空特性差异较大，导致特征对齐困难，最终效果不佳。直到对比学习和注意力机制的出现，才实现跨模态语义映射。比如 OpenAI 2021 年推出的一种基于对比学习只的多模态预训练模型 CLIP，它通过大规模的图像和文本数据进行训练，使得模型能够理解图像内容和相关文本之间的语义关系。CLIP 的核心贡献在于它打破了传统的固定类别标签范式，通过对比学习的方式，将图像和文本映射到同一个向量空间中，从而实现跨模态的检索和分类。但是 CLIP 模型的训练数据规模庞大，据 OpenAI 披露，其使用了约 4 亿图像-文本对进行训练，训练成本高达数千 GPU 日，远超 GPT-3 等纯文本模型。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-4ad6b286433edebde043654fd53af191e30.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;CLIP 模型方法概述 &lt;/em&gt;&lt;/span&gt;&lt;span style="color:#8f959e"&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2103.00020" rel="nofollow" target="_blank"&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多模态融合需处理高维数据，如 4K 视频的像素量是文本的百万倍，传统 Transformer 的二次方计算复杂度成为致命短板。对此，业界也有一些解决方式，比如此前 Mamba 架构通过状态空间模型 SSM 将计算复杂度降至线性，2025 年扩展动态融合模块&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F2985554863" rel="nofollow" target="_blank"&gt; FusionMamba&lt;/a&gt;，在其中实现多模态特征高效交互，推理速度提升 3 倍。&lt;/p&gt; 
&lt;p&gt;不仅如此，相较于文本的资料库和数据集，高质量多模态数据集也更加稀缺，收集难度更大。比如医疗影像、工业质检的报告中的缺陷描述等，就需专家级别的标注人员。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;落地需求更多&lt;/h2&gt; 
&lt;p&gt;虽然技术上还有诸多难点，但是多模态能力正在逐步提升，并且带来非常可观的价值和效果。&lt;/p&gt; 
&lt;p&gt;比如，从图片或者是 Figma 设计稿直接生成代码可以帮助许多开发者或是产品经理完成一些开发工作。这项能力此前在一些低代码或是辅助编程工具中也存在，但往往是通过 Figma DSL 进行设计稿解析，通过节点虚拟化技术实现像素级还原，其不足在于不一定适配当前项目，比如转了一套 Vue 框架的代码，就无法在 React 框架项目中使用。&lt;/p&gt; 
&lt;p&gt;杨经纬介绍，此次文心快码 Comate AI IDE 的发布以及相关功能更新后，通过大模型能力增强了 Figma to Code 和当前项目的融合度。首先在 IDE 里进行操作，天然就可以理解用户当前环境和本地优势，而 IDE 内智能体 Zulu 的接入，会更深入到本地项目中了解当前的框架、能力、代码风格等，再结合 Image to Code 的能力，可以实现较高的还原度，并且适配当前的项目。&lt;/p&gt; 
&lt;p&gt;而根据一些公开信息显示，可灵 AI 的多模态技术，支持通过图片、文字、声音甚至手绘轨迹等输入生成视频。在上半年的 2.0 模型的迭代中，可灵 AI 也发布了 AI 视频生成的全新交互理念 Multi-modal Visual Language（MVL），让用户能够结合图像参考、视频片段等多模态信息，将脑海中包含身份、外观、风格、场景、动作、表情、运镜在内的多维度复杂创意，直接高效地传达给 AI。MVL 由 TXT（Pure Text，语义骨架）和 MMW（Multi-modal-document as a Word，多模态描述子）组成，能从视频生成设定的基础方向以及精细控制这两个层面。此外，其技术也结合了类 Sora 的 DiT 结构和 Flow 扩散模型，提升在物理模拟和细节上的表现。&lt;/p&gt; 
&lt;p&gt;基于这些技术特征。商业化层面，截至今年 6 月，可灵 AI 已为超过 1 万家企业客户提供 API 服务，覆盖广告营销、影视动画等领域，企业客户续费率较高。&lt;/p&gt; 
&lt;p&gt;此外，一些传统行业或场景也在结合多模态能力，实现与 AI 的加速融合。比如迪瑞医疗近期采用的多模态 AI 大模型算法技术为临床诊断带来了重要的技术革新，结合多种检测结果和患者的多维信息，如尿常规、血常规、生化和化学发光免疫，以及患者的个人背景、临床表现、现病史与既往病史等，进行全面分析。&lt;/p&gt; 
&lt;p&gt;这种跨学科的信息整合使得诊断提示更加精准，对于减少漏诊、误诊的概率具有显著的作用，并进一步提升了医疗诊疗的整体效率。大洋彼岸，斯坦福医学院的科研团队研发出了一种名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxMTM0OTQzNQ%3D%3D%26mid%3D2247486194%26idx%3D1%26sn%3D5ac605d67ca7019b3b2e524d65b0f88e%26chksm%3Dc0eed67e545679711993370e69032cc62e9d4fc0c6ff3e283c43854fd93355eae8a07b4fcb02%23rd" rel="nofollow" target="_blank"&gt; MUSK 的 AI 模型&lt;/a&gt;，将视觉数据，如病理图像和文本数据的病历和临床记录相结合，为癌症治疗带来了新的可能。MUSK 模型不仅提高了预测癌症患者预后和治疗反应的准确性，而且通过分析数千个数据点，更准确地确定了哪些疗法对个体患者最有效。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-196e0ee8b1058ba8ee70698e626a846fe72.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="background-color:#f2f3f5"&gt;&lt;em&gt;视觉问答测试，图片来源于网络&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在金融领域。江苏银行通过本地化部署微调 DeepSeek-VL2 多模态模型、轻量 DeepSeek-R1 推理模型，分别运用于智能合同质检和自动化估值对账场景中，通过对海量金融数据的挖掘与分析，重塑金融服务模式，实现金融语义理解准确率与业务效率双突破。具体而言，DeepSeek-VL2 多模态模型采用了最新的 Transformer 架构，结合多层次的特征融合机制，有效提升了金融合同、账单等复杂文本与图像信息的理解能力。模型在智能合同质检场景中表现出色，准确率较传统方法提升了 15% 以上，显著降低了人工审核成本。同时，轻量化的 DeepSeek-R1 推理模型则在自动化估值与对账场景中展现出极佳的实时响应能力，推理速度提升了 30%，为金融业务流程的自动化提供了坚实支撑。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;新的基础设施&lt;/h2&gt; 
&lt;p&gt;应用边界在不断拓宽的同时，多模态模型的能力也在成长。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而随着应用场景的深化，模型架构也在同步进化，从基础感知迈向复杂推理成为必然趋势。OpenAI 在 2025 年 4 月发布了多模态模型 O3 和 O4-mini，实现了「用图像思考」的突破性能力。这些模型不仅能够识别图像内容，还能将图像信息整合进推理思维链，支持多步推理和因果分析，比如够处理模糊、倒置或复杂的图像输入，并给出合理的推理结果。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;其背后的关键技术包括分层注意力机制，将图像分解为局部细节、全局关系和时序逻辑三层结构，从而提升对图像内容的理解能力；动态工具链调用，在推理过程中，模型可以自主选择 Python 分析、知识图谱检索、图像生成等工具辅助决策，以及安全约束模块，通过对抗训练减少模型的幻觉输出。&lt;/p&gt; 
&lt;p&gt;就在本月，中国科学院自动化研究所等单位的科研人员&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkw.beijing.gov.cn%2Fxwdt%2Fkcyx%2Fxwdtkjqy%2F202506%2Ft20250611_4111006.html" rel="nofollow" target="_blank"&gt;首次证实&lt;/a&gt;，多模态大语言模型在训练过程中自己学会了「理解」事物，而且这种理解方式和人类非常像。&lt;/p&gt; 
&lt;p&gt;科研人员借鉴人脑认知的原理，设计了一个巧妙的实验：让大模型和人类玩「找不同」游戏。实验人员会给出三个物品概念（选自 1854 种常见物品），要求选出最不搭的那个。通过分析高达 470 万次的判断数据，科研人员绘制出了大模型的「思维导图」——「概念地图」。通过实验证实多模态大模型具备类人「概念理解」能力。研究团队设计「找不同」游戏，基于 470 万次判断数据绘制大模型「概念地图」，提炼 66 个理解维度（如物体功能、文化意义），发现其与人脑神经活动高度一致，证明多模态模型比纯文本模型更接近人类思维模式。&lt;/p&gt; 
&lt;p&gt;据谷歌云在 2024 年年底发布的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.qq.com%2Frain%2Fa%2F20241219A07AW200" rel="nofollow" target="_blank"&gt;《2025 年人工智能商业趋势报告》&lt;/a&gt;，预测到 2025 年，多模态 AI 将成为企业采用 AI 的主要驱动力。这种技术通过整合图像、视频、音频和文本等多种数据源，使 AI 能够以前所未有的准确性从更广泛的上下文源中学习，提供更精确、定制化的输出，创造自然直观的体验。报告预计，全球多模态 AI 市场规模将在 2025 年达到 24 亿美元，到 2037 年底达到 989 亿美元。&lt;/p&gt; 
&lt;p&gt;2025 进度已经过半，我们也能看到市面上许多多模态技术和产品的进展，而这场变革的终极图景，或许正是让 AI 真正成为理解世界、服务人类的「多模态智能伙伴」。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18679654</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18679654</guid>
      <pubDate>Sun, 11 May 2025 07:31:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Windows 11 记事本正式支持 Markdown</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月底，预览体验计划中的 Windows 11 记事本迎来史诗级更新：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown"&gt;支持 Markdown 格式&lt;/a&gt;。现在普通用户也可以使用这个版本了，只需要在应用商店中更新记事本即可使用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-af88d0da29ab2cf4246999e5b5025bf874c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前支持：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;粗体&lt;/li&gt; 
 &lt;li&gt;斜体&lt;/li&gt; 
 &lt;li&gt;链接&lt;/li&gt; 
 &lt;li&gt;序号&lt;/li&gt; 
 &lt;li&gt;标题（H1～H5）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如下面的屏幕截图所示，您可以点击新的「H1」图标，然后选择您喜欢的标题：标题、副标题、章节，甚至是小节。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-387e4d297dcd5ac663e49554b55e2f51091.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;接下来，我们可以看到项目符号和数字列表按钮，以及用于加粗或应用斜体的选项，但最吸引我注意的是超链接支持。现在，您可以使用 Ctrl + K 键盘快捷键（该快捷键在 Word 中也使用）插入带有锚文本的链接，并在默认浏览器中打开。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-79d07dc4e8307d47c79e780de309830f227.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，您可以点击屏幕底部的「格式化视图」按钮切换到 Markdown 语法（原始）视图。&lt;/p&gt; 
&lt;p&gt;与「格式」视图不同，语法视图允许您将井号转换为标题、使用星号强调、用反引号包裹代码等等。语法视图类似于在后端使用 Markdown 编辑器，但它不会更改输出。这取决于您在记事本中使用 Markdown 的方式。&lt;/p&gt; 
&lt;p&gt;在我们的测试中，Windows 最新版本观察到记事本默认启用 Markdown，但您有两个选择。您可以单击清理格式按钮，返回原始记事本体验，而无需禁用 Markdown 支持。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-78b526954a85441998f9ce8f508e77c65f8.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;或者，您可以打开「设置」，向下滚动一点，找到一个名为「格式化」的新选项。关闭「格式化」后，记事本的经典体验将恢复。您将不再看到格式化栏，Windows 也不会提示您使用它。&lt;/p&gt; 
&lt;p&gt;测试中，我们还注意到微软在记事本中实现了非常轻量级的 Markdown 功能，它不会让您的电脑运行速度变慢。&lt;/p&gt; 
&lt;p&gt;有些人可能会认为，给记事本添加太多功能违背了它作为纯文本编辑器的初衷。这种观点很有道理，但只要 Markdown 之类的功能是可选的，我并不介意。如果我需要它们，可以在「设置」中打开；如果不需要，也可以再次关闭。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/353253/windows-notepad-markdown" target="news"&gt;Windows 记事本支持 Markdown&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358574/windows-11-notepad-markdown</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358574/windows-11-notepad-markdown</guid>
      <pubDate>Sun, 11 May 2025 07:09:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>抖音内容技术团队开源 ContentV：有限算力下高效训练视频生成模型的新路径</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//adfb650ff16d8feb12d600710037b8a4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;div class="ckeditor-html5-video" style="text-align:center"&gt; 
  &lt;video controls="controls" controlslist="nodownload" src="https://www.bilibili.com/video/BV1jC3azYEaS/?spm_id_from=333.1387.upload.video_card.click&amp;amp;vd_source=c09f0713b2507369924e94f4fec6c133"&gt;
    &amp;nbsp; 
  &lt;/video&gt; 
 &lt;/div&gt; 
 &lt;div class="ckeditor-html5-video" style="text-align:center"&gt; 
  &lt;video controls="controls" controlslist="nodownload" src="https://www.bilibili.com/video/BV1jC3azYEuW/?spm_id_from=333.1387.upload.video_card.click&amp;amp;vd_source=c09f0713b2507369924e94f4fec6c133"&gt;
    &amp;nbsp; 
  &lt;/video&gt; 
 &lt;/div&gt; 抖音内容技术团队开源了 ContentV，一种面向视频生成任务的高效训练方案。该方案在多项技术优化的基础上，使用 256 块显卡，在约 4 周内完成了一个 8B 参数模型的训练。尽管资源有限，ContentV 在多个评估维度上取得了与现有主流方案相近的生成效果。该工作探索了在有限算力条件下训练视频生成模型的可行路径。目前，推理代码与模型权重已对外开放。 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;项目主页&lt;/strong&gt;：https://contentv.github.io&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;技术报告&lt;/strong&gt;：https://arxiv.org/abs/2506.05343&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;代码仓库&lt;/strong&gt;：https://github.com/bytedance/ContentV&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;模型权重&lt;/strong&gt;：https://huggingface.co/ByteDance/ContentV-8B&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;核心亮点&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;极简设计&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;CogVideoX、HunyuanVideo 和 Wan2.1 等一系列优秀的开源工作表明，视频生成的关键并不在于架构上的特殊设计，而在于如何高效利用有限的数据资源，并有效对齐人类偏好。&lt;/p&gt; 
&lt;p&gt;为验证 ContentV 方案的通用性，本次开源的版本在扩散模型部分采用了经典的文生图模型 Stable Diffusion 3.5 Large。为了适配视频模态，模型在结构上仅做了以下两项必要调整：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将原始图像 VAE 替换为 Wan2.1 中使用的 3D-VAE；&lt;/li&gt; 
 &lt;li&gt;将 2D 位置编码升级为 3D 版本。在具体编码方式上，团队对比了传统的绝对位置编码与主流的旋转位置编码。评估结果显示，两者在客观指标和主观感受上差异较小，因此保留了计算更高效的绝对位置编码方案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a970cfacc9f335795a1cb051ba654811.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;ContentV 模型结构‌&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多阶段渐进训练策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上述的最小化结构改动，在解锁了视频生成能力的同时，也最大限度地保留了原模型的图像生成能力。实验证明，在新的 VAE 和位置编码的适配阶段，沿用 Flow Matching 的训练方式，仅需 1000 步左右的微调，就能基本还原模型的图片生成能力，大幅节省图片预训练阶段的训练成本。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//da7aab81f63561b7c0d8679eceba1022.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;VAE 适配过程‌&lt;/p&gt; 
&lt;p&gt;在视频生成的预训练阶段，为加速收敛实现高效训练，研究团队设计了一套从「低清短片」到「高清长片」的多阶段渐进式训练流程，逐步引导模型学习时间维度与空间维度上的动态表征，从而提升视频的连续性、动态表现力和画面细节。&lt;/p&gt; 
&lt;p&gt;此外，实验证明，在推理阶段引入非线性采样步长机制（Flow Shift）能够显著提升视频的整体生成质量。通过多组对比实验，团队最终确定了最优的采样策略，进一步优化了生成效果。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;轻量级 RLHF 强化训练&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//25bf5c0471707e1d93343f8649c7f46a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//aaf7366e824c8a20dc80a43af6d4e872.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;RLHF 显著提升画面质感‌&lt;/p&gt; 
&lt;p&gt;在后训练阶段，除了使用高质量数据集进行微调外，通过 RLHF 或 DPO 等对齐人类偏好的监督训练，也能显著提升视频生成质量。然而，这类方法通常依赖大量人工标注，用于训练奖励模型或直接监督扩散模型。同时，相较于图像，视频的序列长度显著增加了 RLHF 和 DPO 的训练资源需求。&lt;/p&gt; 
&lt;p&gt;为此，ContentV 研究团队提出了一种轻量级的 RLHF 训练方案，旨在不依赖人工标注的前提下，低成本提升视频质量：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;利用开源的图像奖励模型对生成视频的单帧进行监督。相较于视频场景，目前图像奖励模型的训练数据更易获取，且在实际效果中表现更佳。实验证明，由于 MM DiT 采用全局注意力机制，仅优化单帧即可带动整体视频质量的提升；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将监督范围限制在生成视频的前 1 秒，相较于对完整视频进行监督，可大幅减少训练资源的消耗，同时获得相近的质量提升效果。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;采用上述策略后，在无需人工标注的情况下，仅使用少量训练资源，便可显著提升画面质量。RLHF 微调后，模型在视觉质量（VQ）指标上的表现大幅提升，评估胜率高达 89.38%。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;效果对比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在 VBench 这一主流视频生成评测基准上，ContentV（8B）取得了 85.14 的综合得分，表现优于多个现有的商业闭源模型，包括 Sora、Kling 1.6 和 Gen-3 等。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//2e5d2e9c6fb2a651ef95db56aa008420.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;VBench 榜单 (按照 Overall 分数降序排列)‌&lt;/p&gt; 
&lt;p&gt;为更贴近真实用户偏好，研究团队围绕感知质量、指令跟随、物理一致性和视觉效果四个维度开展了人类偏好评估。结果显示，ContentV 在整体表现上与 CogVideoX-5B、HunyuanVideo-13B 和 Wan2.1-14B 等主流开源模型相比具有一定优势。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//547c06ccbfa684f90c21d1432e0c6786.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;人类偏好评估指标‌&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6210722/blog/18683305</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6210722/blog/18683305</guid>
      <pubDate>Sun, 11 May 2025 06:53:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Bilibili 开源动漫视频生成模型 AniSora V3 版</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Bilibili（B 站）宣布其开源动漫视频生成模型&lt;strong&gt;AniSora&lt;/strong&gt;迎来重大更新，正式发布&lt;strong&gt;AniSora V3&lt;/strong&gt;。作为 Index-AniSora 项目的一部分，V3 版本在原有基础上进一步优化了生成质量、动作流畅度和风格多样性，为动漫、漫画及 VTuber 内容创作者提供了更强大的工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="292" src="https://oscimg.oschina.net/oscnet/up-27ad0a0400878a1e24e9451fd20c7a87882.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AniSora V3 基于 Bilibili 此前开源的 CogVideoX-5B 和 Wan2.1-14B 模型，结合&lt;strong&gt;强化学习与人类反馈（RLHF）&lt;/strong&gt;框架，显著提升了生成视频的视觉质量和动作一致性。其支持一键生成多种风格的动漫视频镜头，包括番剧片段、国创动画、漫画视频改编、VTuber 内容）等。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心升级包括：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;时空掩码模块（Spatiotemporal Mask Module）优化&lt;/strong&gt;：V3 版本增强了时空控制能力，支持更复杂的动画任务，如精细的角色表情控制、动态镜头移动和局部图像引导生成。例如，提示「五位女孩在镜头放大时起舞，左手上举至头顶再下放至膝盖」能生成流畅的舞蹈动画，镜头与角色动作同步自然。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;数据集扩展&lt;/strong&gt;：V3 继续依托超过 1000 万高质量动漫视频片段（从 100 万原始视频中提取）进行训练，新增数据清洗流水线，确保生成内容的风格一致性和细节丰富度。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;硬件优化&lt;/strong&gt;：V3 新增对华为 Ascend910B NPU 的原生支持，完全基于国产芯片训练，推理速度提升约 20%，生成 4 秒高清视频仅需 2-3 分钟。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;多任务学习&lt;/strong&gt;：V3 强化了多任务处理能力，支持从单帧图像生成视频、关键帧插值到唇部同步等功能，特别适合漫画改编和 VTuber 内容创作。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在最新基准测试中，AniSora V3 在&lt;strong&gt;VBench&lt;/strong&gt;和双盲主观测试中，角色一致性和动作流畅度均达到业界顶尖水平（SOTA），尤其在复杂动作 (如违反物理规律的夸张动漫动作) 上表现突出。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Bilibili 强调，AniSora 是「对动漫世界的开源礼物」，鼓励社区协作优化模型。用户需填写申请表并发送至指定邮箱（如 yangsiqian@bilibili.com）以获取 V2.0 权重和完整数据集访问权限。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;V3 还引入了首个针对动漫视频生成的&lt;strong&gt;RLHF 框架&lt;/strong&gt;，通过 AnimeReward 和 GAPO 等工具对模型进行微调，确保输出更符合人类审美和动漫风格需求。社区开发者已开始基于 V3 开发定制化插件，例如增强特定动漫风格（如吉卜力风）的生成效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AniSora V3 支持多种动漫风格，包括日本动漫、国产原创动画、漫画改编、VTuber 内容及恶搞动画（鬼畜动画），覆盖 90% 的动漫视频应用场景。 具体应用包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;单图转视频&lt;/strong&gt;：用户上传一张高质量动漫图像，配合文本提示（如「角色在向前行驶的车中挥手，头发随风摆动」），即可生成动态视频，保持角色细节和风格一致。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;漫画改编&lt;/strong&gt;：从漫画帧生成带唇部同步和动作的动画，适合快速制作预告片或短篇动画。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;VTuber 与游戏&lt;/strong&gt;：支持实时生成角色动画，助力独立创作者和游戏开发者快速测试角色动作。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;高分辨率输出&lt;/strong&gt;：生成视频支持高达 1080p，确保在社交媒体、流媒体平台上的专业呈现。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;AIbase 测试显示，V3 在生成复杂场景（如多角色交互、动态背景）时，相比 V2 减少了约 15% 的伪影问题，生成时间缩短至平均 2.5 分钟 (4 秒视频)。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;相比 OpenAI 的 Sora 或 Kling 等通用视频生成模型，AniSora V3 专注于动漫领域。 与字节跳动的 EX-4D 相比，AniSora V3 更专注于 2D/2.5D 动漫风格，而非 4D 多视角生成。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358565</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358565</guid>
      <pubDate>Sun, 11 May 2025 06:46:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>智谱 AI 开源通用视觉推理模型 GLM-4.1V-Thinking</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;智谱 AI 于 7 月 2 日发布了 GLM-4.1V-Thinking 系列通用视觉推理模型，并宣布获得来自浦东创投集团和张江集团的 10 亿元联合战略投资。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/143332_18Al_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，公司推出了全新生态平台「Agent 应用空间」，并启动「Agents 开拓者计划」，投入数亿资金扶持 AI Agents 创业团队。&lt;/p&gt; 
&lt;p&gt;为庆祝模型发布，智谱大模型开放平台为用户提供新模型 Flash 版 1 亿的「高并发版」Tokens，同时，该模型可通过 API 免费使用。&lt;/p&gt; 
&lt;p&gt;此次率先开源的是 GLM-4.1V-9B-Thinking，一个 9B 参数量的多模态模型，对应官方平台的 GLM-4.1V-Thinking-Flash。该模型旨在提升模型的深度思考与复杂推理能力。该模型在多项基准测试中表现卓越，其性能在 18 项任务上持平甚至超过了参数量为其 8 倍的 Qwen-2.5-VL-72B 和 GPT-4o 等主流视觉语言模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/143242_aYUB_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;模型具备强大的多模态能力，能够解析长达 2 小时的视频、进行数学与科学推理、看图编写网页，并具备 GUI Agent 能力，可识别并操作手机、电脑等屏幕界面元素，完成用户指令。例如，在解析足球比赛时，模型能理解球员位置和战术特点。&lt;/p&gt; 
&lt;p&gt;GLM-4.1V-Thinking 模型架构由视觉编码器、MLP 适配器和语言解码器组成，其卓越性能得益于引入了「课程采样强化学习」（Reinforcement Learning with Curriculum Sampling）策略，通过由易到难的训练任务安排，高效提升了模型在 STEM 解题、智能体任务、文档图表理解等多个领域的推理能力。&lt;/p&gt; 
&lt;p&gt;目前，GLM-4.1V-9B-Thinking 模型已在 GitHub、魔搭社区及 Hugging Face 上开源。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开源列表&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbigmodel.cn%2Fdev%2Fhowuse%2Fvisual-reasoning-model%2Fglm-4.1v-thinking" target="_blank"&gt;https://bigmodel.cn/dev/howuse/visual-reasoning-model/glm-4.1v-thinking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Github：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FTHUDM%2FGLM-4.1V-Thinking" target="_blank"&gt;https://github.com/THUDM/GLM-4.1V-Thinking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ModelScope：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fcollections%2FGLM-41V-35d24b6def9f49" target="_blank"&gt;https://modelscope.cn/collections/GLM-41V-35d24b6def9f49&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hugging Face：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2FTHUDM%2Fglm-41v-thinking-6862bbfc44593a8601c2578d" target="_blank"&gt;https://huggingface.co/collections/THUDM/glm-41v-thinking-6862bbfc44593a8601c2578d&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HuggingFace 体验链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FTHUDM%2FGLM-4.1V-9B-Thinking-Demo" target="_blank"&gt;https://huggingface.co/spaces/THUDM/GLM-4.1V-9B-Thinking-Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358562/glm-4-1-v-thinking</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358562/glm-4-1-v-thinking</guid>
      <pubDate>Sun, 11 May 2025 06:32:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源中国联合发起「全球数字友好开源社区」，共建开放协同新生态</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 7 月 2 日，2025 全球数字经济大会在北京国家会议中心隆重开幕。本次大会经国务院批准，由北京市人民政府、国家互联网信息办公室、国家数据局、新华通讯社与联合国开发计划署共同主办，聚焦「建设数字友好城市」主题，来自全球多国政府机构、国际组织、城市代表、科研院所和科技企业代表齐聚一堂，围绕数字技术赋能城市发展的路径与合作机制深入交流。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120249_MSqc_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在大会首场主论坛「数字友好城市建对话」阶段，&lt;strong&gt;北京市经开区工委副书记、管委会副主任王磊指出北京正在加快打造以「模力方舟国际开源社区」为代表的 AI 开放创新平台集群&lt;/strong&gt;，汇聚全球 AI 开发者资源，支撑企业间协同与城市间互信，推动开源力量深度融入全球数字治理体系。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120301_ICF0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;随后，主论坛迎来了重点环节之一——&lt;strong&gt;「全球数字友好开源社区」正式启动&lt;/strong&gt;。该社区由开源中国、统信软件、平凯星辰等十八家中外企业、联盟和机构共同发起，旨在打造面向全球的数字化开放协同平台。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;开源中国作为发起单位之一，研发副总裁李彦成代表公司出席启动仪式，并与各方共同见证社区成立&lt;/strong&gt;。开源社区已成为推动全球数字协作与技术创新的重要力量。从早期由开发者驱动的协作模式，到如今以城市、企业、场景多元联动为特征的深度共建，开源正在加速融入数字城市治理的底层逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120314_bEZv_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开源已成为推动全球数字协作与技术创新的重要力量。从早期由开发者社区推动的技术共享，到如今以城市、企业、场景多元联动为特征的深度协作，开源的发展路径正不断拓展边界。在联合国「数字促进可持续发展」倡议框架下，「全球数字友好开源社区」应运而生，标志着开源协作正在进入以城市友好关系为纽带、以产业联合体为主体的新阶段。&lt;/p&gt; 
&lt;p&gt;作为国家重点开源基础设施平台之一，开源中国·Gitee 始终致力于建设安全、自主、可控的开源生态。&lt;strong&gt;此次参与社区联合发起，是开源中国积极服务国家数字战略、深度参与国际开源共建进程的重要举措&lt;/strong&gt;。依托自身在开源治理、企业级协同平台、人工智能服务平台等方向的长期积累，开源中国将与生态伙伴一道，共同推动开源协作从「项目共建」走向「城市共建」，为打造全球数字友好生态注入持续动能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/120331_bONF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在数字技术高速演进、人工智能重塑产业格局的时代背景下，构建开放、包容、可持续的全球协作机制显得尤为重要。开源中国将继续秉持开放精神，深度参与社区建设，携手全球伙伴共建共享，为推动构建人类数字命运共同体贡献更多开源力量。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358536</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358536</guid>
      <pubDate>Sun, 11 May 2025 04:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>马斯克旗下人工智能公司 xAI 完成 100 亿美元融资</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;马斯克旗下人工智能公司 xAI 近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F07%2F01%2Felon-musk-xai-raises-10-billion-in-debt-and-equity.html" target="_blank"&gt;完成了 100 亿美元融资&lt;/a&gt;，其中包括 50 亿美元债务融资和 50 亿美元战略股权投资。这笔资金将用于开发 AI 解决方案、建设数据中心，并推动其旗舰 AI 助手 Grok 的进一步发展。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0703/114408_7iP8_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;除已完成的融资外，xAI 仍在洽谈约 200 亿美元的股权融资。若成功，其估值可能飙升至 1200 亿至 2000 亿美元，成为全球最具价值的 AI 公司之一。&lt;/p&gt; 
&lt;p&gt;然而，知情人士透露，xAI 的运营成本极高——2025 年预计将消耗 130 亿美元，相当于每月烧钱超 10 亿美元。目前的大规模融资仅能勉强跟上其巨额开支，未来仍需持续输血以维持技术研发和市场扩张。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358529/elon-musk-xai-raises-10-billion-in-debt-and-equity</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358529/elon-musk-xai-raises-10-billion-in-debt-and-equity</guid>
      <pubDate>Sun, 11 May 2025 03:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>搜索数据建设系列之数据架构重构</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;主要概述百度搜索业务数据建设的创新实践，重点围绕宽表模型设计、计算引擎优化和新一代业务服务交付模式（图灵 3.0 开发模式）三大方向，解决了传统数仓在搜索场景下面临的诸多挑战，实现了搜索数据建设的高效、稳定、低成本；为百度搜索业务敏捷迭代奠定夯实基础。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;strong&gt;名词解释&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDS（Turing Data Studio）&lt;/strong&gt;&lt;/strong&gt;： 是基于图灵（百度内部数据分析平台）的数据建设解决方案，提供，数据开发、数仓管理、监控运维、资源管理等一站式服务的数据开发平台。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26chksm%3Dc03f75e8f748fcfe192c0c8817ceee53c0e1f57dcbafd16e22ee371889f4dbf9e0b813b700fa%26token%3D1515601853%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度 MEG 数据开发治理平台-TDS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDA（Turing Data Analysis）&lt;/strong&gt;&lt;/strong&gt;：是一款可视化 BI 产品，旨在帮助用户轻松上手及使用，进行拖拽式可视化数据分析及仪表盘建设。产品模块包括仪表盘、数据集、可视化分析及智能分析模块。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26chksm%3Dc03fbc10f7483506eb7206b02265f9010ddfa434359d7fa975a32d54c1b4886e734051ff9067%26scene%3D21%23wechat_redirect" target="_blank"&gt;百度一站式数据自助分析平台（TDA）建设&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;TDE（Turing Data Engine ）&lt;/strong&gt;&lt;/strong&gt;：是基于图灵生态的计算引擎，包含 Spark 计算引擎和 ClickHouse。详情参见：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;揭秘百度数仓融合计算引擎&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26chksm%3Dc03f7c9ef748f5886cc17147d8dfc8bd62ce062de822444ec592914d5ca6e0ab224cfc963e3e%26token%3D286675411%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 在百度 MEG 数据中台的落地和优化&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;UPI（Udw-API）&lt;/strong&gt;&lt;/strong&gt;：百度内部编程访问接口；以 Map/Reduce 计算框架为主，适用于计算逻辑复杂，以及多种数据源混合计算的例行离线数据挖掘业务&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;：是百度自主研发，基于 spark 自研的 adhoc 服务。提供数据查询分析，具有简单易用、超大规模支持、成本极低等特点，能实现 T 级数据秒级查询，也适用于例行生产的 ETL 场景。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;函谷&lt;/strong&gt;&lt;/strong&gt;：图灵核心模块，作为图灵查询的 gateway，完成图灵查询的接收、分发、提交执行、查询进展轮询、结果获取等一系列功能。&lt;/p&gt; 
&lt;span id="OSC_h1_3"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景与问题&lt;/h1&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 背景&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在当今互联网产品发展日新月异、业务迭代迅猛的时代；跨业务分析的需求日益增长，这种变化既为企业创造了敏捷决策、精准运营的新机遇，也带来数据割裂、价值释放滞后等严峻挑战。特别是大型互联网企业，往往构建有复杂的多业务、多模块、多线条体系，每日持续产出海量的数据信息。这些数据的服务对象正逐步从数据研发人员扩展至更为广泛的产品相关人员，如何高效开展数据获取工作，打破数据孤岛现象，充分挖掘并释放数据驱动业务的潜力，已成为业界广泛关注和讨论的焦点议题。针对该问题，业界传统数仓常采用的是经典分层模型的数仓架构，从 ODS（Operational Data Store）&amp;gt;DWD（Data Warehouse Detail）&amp;gt;DWS（Data Warehouse Summary）&amp;gt;ADS（Application Data Store）逐层建模，但我们会发现，从传统固化开发的角度来看，传统经典数仓模型是比较有优势的。然而，面对当下数据需求灵活多变的时代，其局限性也日益凸显。如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-939fa5fcdf0baaf3f9376861ee1c7269bb5.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 搜索场景下的困境与挑战&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;搜索作为百度的核心支柱业务，涵盖通用搜索、智能搜索、阿拉丁与垂类等多元化、多模态的搜索产品，具有&lt;strong&gt;&lt;strong&gt;快速迭代、模块多元化且复杂&lt;/strong&gt;&lt;/strong&gt;的特性，搜索数据更是复杂多样，整体数仓规模达到数百 PB 以上。&lt;/p&gt; 
&lt;p&gt;随着搜索业务各个模块之间的联系日益紧密，交叉分析的需求也在不断增长。使用人员对数据获取的便捷性提出了更高的要求，其中涵盖了数据分析师、策略、业务产品经理、运营、评估等多类角色。他们的诉求期望能够跨越复杂的数据架构壁垒，以更加&lt;strong&gt;&lt;strong&gt;高效、直观、快速&lt;/strong&gt;&lt;/strong&gt;的方式获取到所需数据。&lt;/p&gt; 
&lt;p&gt;而传统的搜索数仓建设体系，无论从建模角度还是技术框架上，都与现阶段用户诉求背道而驰。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;建模角度：多层的传统分层建模。往往会出现（大表数据量大、查询慢、存储冗余、口径不统一）等问题，影响业务分析效率，从而达不到数据驱动业务的效果。数据开发侧作为需求的被动承接方，根据业务侧提出的数据需求进行数据开发与交付，存在需求交付周期长、人力成本高等问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;技术框架角度：搜索数仓过去大多是采用&lt;strong&gt;&lt;strong&gt;UPI&lt;/strong&gt;&lt;/strong&gt;框架（以 C++ MR 计算框架为主）进行 ETL 处理。由于该框架技术陈旧，往往会出现以下问题影响数仓整体时效、稳定。从而使业务部门感知需求支持迟缓、数据产出延迟及数据质量低等一系列问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;容易出现服务不稳定。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;处理能力薄弱：处理不了特殊字符，从而导致数据丢失或任务失败等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;只能通过物理机远程执行的方式提交，有单节点风险。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无法 Writer 将数据写到 Parquet 文件，需要进行特定脚本 ETLServer 框架进行转换。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;思考&lt;/strong&gt;&lt;/strong&gt;：如何更好的满足用户角色需求，进一步降低数据获取的使用门槛？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;破局&lt;/strong&gt;&lt;/strong&gt;：拥抱变化，以用户诉求为核心出发点。 探索更适合用户的 &lt;strong&gt;&lt;strong&gt;体系化建模&lt;/strong&gt;&lt;/strong&gt; 来进行实质、有效的数据管理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;体系化建模：&lt;/strong&gt;以业务产品需求驱动模型设计，以模型设计驱动和约束开发实施，防止因模型设计与业务产品割裂、开发实施缺少约束带来的无序、「烟囱式」开发。在机制上形成模型设计与开发实施的有效协同。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;切入点&lt;/strong&gt;&lt;/strong&gt;：以规范「基础数据建设」，消除因「烟囱式」开发给业务带来的困扰和技术上的浪费。&lt;/p&gt; 
&lt;p&gt;由此我们探索出一套新的建模体系：&lt;strong&gt;大宽表+数据集&lt;/strong&gt;：其核心点就是基于宽表，将之前的"需求-交付"解耦为以数据集为中心的建设，从而提升搜索内业务数据分析效率与分析深度，更好助力业务决策。以下将从宽表建模、计算引擎架构优化、新型业务交付模式等方向为大家介绍搜索数据团队业务实践。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;02 搜索建模思路与技术方案&lt;/h1&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 建模模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 思路&lt;/h3&gt; 
&lt;p&gt;基于搜索产品功能特性与差异化业务场景，我们对日志数据进行主题化的分类。在每个主题域内，结合业务运营的具体环节特征，构建具备高整合度的宽表模型。在模型构建过程中，保持 ODS（操作数据存储）层与 DWD（明细数据层）的表结构粒度一致，确保数据的一致性与连贯性。所构建的宽表不仅完整涵盖下游业务所需的全部字段，包括业务明细表中的基础数据，还整合了各层级的维度属性与计算指标。通过这种方式，形成一个全面、统一的数据底座，为上层业务的多维分析、指标监控及决策支持提供坚实的数据支撑，有效满足多样化的业务分析需求。&lt;/p&gt; 
&lt;span id="OSC_h4_9"&gt;&lt;/span&gt; 
&lt;h4&gt;2.1.1.1 举例&lt;/h4&gt; 
&lt;p&gt;以展点主题为例，从历史的模型表粒度和模型层级来分析：ODS 与 DWD、DWS 表行为、检索、点击各个主题在同层模型或者跨模型之间都存在字段、口径的冗余，如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a9f6f8e899639d2fe381e3fd22248b8c407.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_10"&gt;&lt;/span&gt; 
&lt;h4&gt;2.1.1.2 思路分析过程&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;核心思想过程：展点主题下明确粒度，丰富维度&amp;amp;指标，建设宽表模型。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;将展点主题下各层之间的事实表复杂嵌套字段打平后与各个维度表、指标等进行 join 生成宽表，宽表的列最终分为公共属性、展点行为属性、业务属性和指标属性。&lt;/p&gt; 
&lt;p&gt;消除：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数仓层间：字段存储冗余问题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数仓层内：口径不一致问题&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-75e2f39732709336398f3ea0e2f605afc62.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-cc8563c18a8af68b1e8ce82a384dea8aa25.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-c837b8c7763edc5c4290cd758752771d0ce.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 建模核心思想&lt;/h3&gt; 
&lt;p&gt;基于思路分析过程，总结出一套核心建模理论，核心思想如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-59b8209db3232d786eb0920bd402783d568.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;构建搜索系统性数据建模：根据产品功能和业务不同，按照不同主题构建宽表。从而达到节约存储、精简表数量、口径更清晰的目标。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.3 整体模型架构&lt;/h3&gt; 
&lt;p&gt;基于核心建模思想理论得到整体的模型架构，如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-65a11aadcf98271e6926e75e6f4de59f9cf.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;采用 Parquet 列式存储，可支持宽表数百、千列，超多字段，再经过按列的高效压缩（bucket sort 后，压缩率更高），降低了数仓整体存储空间，提高了 IO 效率，起到了降低上层应用延迟的效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将各层之间的表复杂嵌套字段打平后与各个维度表、指标等进行 join 生成百列宽表，宽表的列最终分为公共属性、业务维度属性和指标属性，便于业务分析，实现快速迭代。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 计算引擎&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;为了保证数据生产稳定、准确性。我们对计算引擎的选择做了升级，采用传统 Spark 结合&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;对搜索数仓 ETL 进行重构。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-a8f5a69d8cba77d36bc869cdaa8f603c4e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1 从架构&amp;amp;处理流程上&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;C++ MR&lt;/strong&gt;&lt;/strong&gt; ：多进程，每个任务独立运行，必须经过 Map-Shuffle-Reduce，然后中间结果写磁盘。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;Spark&lt;/strong&gt;&lt;/strong&gt; ：多线程，任务在 Executor 内以线程执行。基于 DAG，可以在内存中缓存数据，减少 IO。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Spark 框架，相较于 MR 框架优势在于&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基于内存计算，处理速度快。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;支持多种计算模式，功能丰富，适合迭代处理数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;提供了高级的 API，开发效率高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于平台提交，有效避免单节点计算风险。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;且在有 shuffle 情况下计算表现更好（MR 在 Shuffle 时默认进行排序，spark 对 shuffle 有优化，只有在部分场景才需要排序），在具体业务实践中：同耗时的情况下，Spark 计算资源相较于 MR 节省 20% 左右。&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2 ETLServer 到数仓融合引擎转变&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-91ec2c9be50fe59678b383ecdee2fe2439a.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;各主题宽表模型的计算通过&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;（通过 Spark Application Context 常驻方式做到资源有效复用；省去了启动 Driver 的时间实现任务的快速启动，来提升任务执行时间）可直接 Writer 将数据写到 Parquet 文件，文件无需进行多次脚本 server 转换。&lt;/p&gt; 
&lt;p&gt;在具体业务实践中，各主题计算耗时由之前 40min 缩短至 10min（减少了 30min），实现数仓快速产出。&lt;/p&gt; 
&lt;span id="OSC_h2_16"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 新数据模型及架构下的挑战与解决方案&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;任何数仓模型架构不会存在一个绝对完美的、涵盖所有方面的解决方案。宽表设计仅是当前环境数仓模型的最优解，它依然面临着诸多不容忽视的挑战。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d897150d0eb4ebe4cbfe141af1e656db0a7.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_17"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 挑战 1 解决方案&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;列式存储&amp;amp;读取：&lt;/strong&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;宽表采用了 Parquet 列式存储，以及 ZSTD 高效压缩算法。结合数仓融合引擎，达到 Data Skipping（即读的越少、计算越快）的效果，仅需读取查询涉及的分区及列，减少了磁盘 I/O 和内存传输的数据量来提升查询效率，通过 Sql 分析服务发现热点复杂字段，主动引导业务建设物化列，命中后查询性能提升 80%。&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;strong&gt;复杂嵌套字段打平&lt;/strong&gt;&lt;/strong&gt;：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;业务常用核心指标以及高频字段口径下沉宽表。虽然行数变多了，但是避免了 explode，get_json_object、array、map 等复杂字段获取的耗时操作，查询性能相较于之前提升了 2.1 倍。&lt;/p&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 挑战 2 解决方案&lt;/h3&gt; 
&lt;p&gt;搜索数据升级到了湖仓一体架构，借助&lt;strong&gt;&lt;strong&gt;Iceberg Merge Into&lt;/strong&gt;&lt;/strong&gt;功能，实现高效回溯方式：对表数据进行行级别的更新或删除。相比 insert overwrite 操作更加高效，减少了不必要的数据移动和存储浪费。&lt;/p&gt; 
&lt;p&gt;通过单一原子操作实现了复杂的数据整合需求。相比传统的先删除再插入的方式，&lt;strong&gt;&lt;strong&gt;Merge Into&lt;/strong&gt;&lt;/strong&gt;提供了更好的性能和一致性保证，其原理是通过重写包含需要删除和更新行数据所在的 date files。Merge Into 可以使用一个查询结果数据来更新目标表的数据，其语法类似 join 关联方式，根据指定的匹配条件对匹配的行数据进行相应的操作&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Merge Into&lt;/strong&gt;&lt;/strong&gt;基本语法&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d2bd76ce88c3a899a2b4c7e9030565f332e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;回溯原理流程如下图&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-65989e3d43c224d06d336056c29f796c598.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. 关联匹配&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;目标表和源表根据指定 key 进行 join 操作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. 条件判断&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;若 Key 匹配&lt;/strong&gt;&lt;/strong&gt;：根据源表操作类型，对目标表中的记录执行相应的操作（更新或删除）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;若 Key 不匹配&lt;/strong&gt;&lt;/strong&gt;：执行 Insert 操作，将源表数据插入目标表。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;3. 原子性操作&lt;/strong&gt;&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;整个流程是事务性的，确保数据一致性。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;以下是特定回溯场景下 hive 与 iceberg 不同方式的回溯耗时对比，可以看的出来用 merge into 代替 insert overwrite 进行回溯，回溯更新效率整体可提高&lt;strong&gt;&lt;strong&gt;54% 左右。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-83ae59dc2b2014d6f454f8ccb8112fdcaa4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 挑战 3 解决方案&lt;/h3&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;2.3.3.1 重排序、高效压缩&lt;/h4&gt; 
&lt;p&gt;开发 ATO 优化器 (通过任务依次执行重排序、压缩等一系列 Rules，实现分区优化和数据重分布)，高效率压缩，解决存储成本，存储节约 20%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-0748d5efaac1312246563e0bce0ba04e1c3.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（1）压缩编码&lt;/p&gt; 
&lt;p&gt;数仓表字段元信息采集：通过任务对图灵宽表表进行字段元信息采集，分析数据分布情况，获取重排序字段。&lt;/p&gt; 
&lt;p&gt;具体做法：通过 RLE、Delta 等缩码方式来提升数据压缩效率；数据重复度越高、连续性越好（有序）的场景，压缩效率会越高，RLE、Delta 编码原理如下。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e0a7287f220ad886011cb4c0b407334ac22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（2） 压缩格式&lt;/p&gt; 
&lt;p&gt;使用 ZSTD 压缩格式和更大的压缩 level，在不影响查询性能的情况下，更大的压缩 level 能进一步提高压缩率，level=9 时在压缩效率和耗时上最为平衡，读写耗时和压缩率对比效果如下。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-9f7b43c93732b26daa2a8d7c38e2da18252.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;（3） Page Size&lt;/p&gt; 
&lt;p&gt;针对 Parquet 文件格式特性进行深入挖掘 ，对 Parquet page size 进行分页扩容，将 Page Size 从 1MB 增大至 5MB，让更多相似的数据集中到同一个数据页中，充分利用编码的压缩特性，进一步减少各个数据页之间存在的相似数据。在 ZSTD 的基础上，能进一步提升压缩效果，效果如下&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-e1a9ccfc36925c7c5a6ba0e90ecb3ae1a78.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;2.3.3.2 历史裁剪，管理有效字段&lt;/h4&gt; 
&lt;p&gt;开发了一套半自动化的通用裁剪模式，通过采集日常任务代码，sql parser 模块解析出无用字段信息（尤其是大 json 大 map 类型扩展字段的无用字段）自动化实现了裁剪。减少了 &lt;strong&gt;&lt;strong&gt;50%&lt;/strong&gt;&lt;/strong&gt; 的回溯任务计算资源消耗，将人力投入从 5 人/天降低到 0.5 人/天。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-59334d514c3341fa8f02863a2b78ccdc7ab.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;字段频率统计模块&lt;/strong&gt;&lt;/strong&gt;：通过对函谷 SQL 数据库和 TDS 平台 No SQL 任务的物理执行计划进行解析，实现对宽表 SQL 任务和非 SQL 任务的字段访问频率的自动化统计。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;裁剪字段抽取模块&lt;/strong&gt;&lt;/strong&gt;：基于字段访问频率，每月抽取冷温字段，形成可视化的字段访问频率报表，生成裁剪 SQL。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;**冷温字段告警模块：**通过对比前一个月和本月冷温字段列表，生成当月新增冷温字段列表，然后向产品研发团队和数据 RD 团队发出告警，确认需要动态调整的裁剪字段；引入冷温字段告警模块，成功实现了裁剪字段的动态调整。最后，通过滚动裁剪模块自动裁剪 395 天前的数据，进一步降低人力/资源的消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;滚动裁剪模块&lt;/strong&gt;&lt;/strong&gt;：自动化滚动裁剪，裁剪宽表中 395 天前的数据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于业务实践证明：&lt;strong&gt;&lt;strong&gt;宽表数仓模型&lt;/strong&gt;&lt;/strong&gt;与&lt;strong&gt;&lt;strong&gt;数仓融合计算引擎&lt;/strong&gt;&lt;/strong&gt;的结合，比传统数仓模型，更适合，面向服务于快速迭代的驱动型业务，主要体现在&lt;/p&gt; 
&lt;p&gt;1. 查询性能巨大提升带来快速响应支持业务需求：&lt;/p&gt; 
&lt;p&gt;简单查询场景 ：Adhoc 查询场景，耗时在数十秒级别，相比于普通 Spark 性能提升 5 倍。&lt;/p&gt; 
&lt;p&gt;复杂场景：业务常用复杂字段拆分打平，避免数组、map 等复杂字段耗时操作、查询性能提升 2.1 倍。&lt;/p&gt; 
&lt;p&gt;2.口径封装下沉：封装业务核心口径，解决业务长期数据源多、口径不一致带来的数据准确性问题，省去不必要的沟通，使用更加简便。&lt;/p&gt; 
&lt;p&gt;3.减少冗余存储：相较于经典传统数仓同主题模型下存储降低 30% 左右。&lt;/p&gt; 
&lt;span id="OSC_h1_22"&gt;&lt;/span&gt; 
&lt;h1&gt;03 基于建模与技术框架初步整合&amp;nbsp;&lt;strong&gt;&lt;strong&gt;探讨图灵 3.0 生态新一代业务服务交付模式&lt;/strong&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;随着搜索数仓模型&amp;amp;计算引擎架构的重构和技术栈统一，搜索数仓定义逐步清晰化、数仓个数大幅度降低，整体趋向更加紧凑、高效以及收敛的态势。在此基础上，为了助力数据迭代效率和分析效率进一步提升，在业务线基础数仓及应用层数据建设上，百度 MEG 内部开发了图灵 3.0 生态系统（即，数仓合理建设，数据分析需求尽可能收敛到 TDA 平台，配套数据集建设完善），包括 Turing Data Engine(TDE) 计算引擎、Turing Data Studio(TDS) 数据开发治理平台和 Turing Data Analysis(TDA) 可视化 BI 产品。依托图灵 3.0 生态，我们进而形成了一套新的开发范式—— 图灵 3.0 新开发模式，用来提升搜索内业务数据分析效率与分析深度，如下图（阶段三）所示&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-d20b1a79b0fbe50ef85eb7c922eab6fc5bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 &lt;strong&gt;&lt;strong&gt;阶段一到阶段二&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;如之前所述：由于搜索数仓早期查询性能不理想，为了提升业务分析效率建设了大量的业务表。从而导致数据冗余、数据链路稳定性差、效率低、指标口径不一致等一系列问题。搜索数据团队通过数仓模型（将多层数据模型控制在 1-2 层）以及计算引擎架构升级重构、湖仓一体、高效压缩、裁剪等一系列措施解决了这些问题。数据建设更加完善规范化，搜索数仓表的数量由过去的数百张减少至 20 张左右，时效性大幅提升，全数据链路全流程提速 4H+，数据稳定性及运维成本降低 30%。&lt;/p&gt; 
&lt;span id="OSC_h2_24"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2 阶段二到阶段三&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;随着图灵 3.0 生态系统（包括 TDA、TDS、TDE）及搜索数仓模型的日益完善，内部提出了，以数据集为核心来构建数据应用层，将数据开发侧与业务侧的依赖关系从之前的"需求-交付"解耦为以数据集为中心的建设，实现数据集&amp;lt;-&amp;gt;可视化分析&amp;lt;-&amp;gt;仪表盘的数据分析闭环，解决业务常用维度、指标长周期的查询分析需求 ——&amp;gt; 图灵 3.0 新开发模式。&lt;/p&gt; 
&lt;p&gt;图灵 3.0 新开发模式核心思想在于数据集的建设，我们将不再仅仅只是根据业务需求来定制开发数据报表，而是构建一个灵活、可扩展的数据集。使业务侧能够自主地根据需求从中提取、分析和可视化数据，以满足不断变化的业务需求。&lt;/p&gt; 
&lt;p&gt;那么，在数据集建模实践中，如何才能合理构建一个灵活、可扩展且高质量的数据集？是数据研发对数据集建模关键核心，也是最大的挑战。&lt;/p&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1 数据集建模合理度挑战&lt;/h3&gt; 
&lt;p&gt;1. 为了满足业务需求的多样性与广泛性，并支持更多的维度和指标。我们往往会倾向于在单个数据集中不断叠加新的维度和指标，这种做法虽然表面上看起来方便快捷，但实际上却导致了数据集行数的急剧增加，进而对聚合查询的性能造成了不利影响&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;为了确保查询的高效性，同时兼顾更多维度与指标的业务需求。我们往往的做法，就是建立更多的数据集，以空间换时间去满足查询性能。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;显然，这些做法之间存在着明显的矛盾，具体如下图。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-cd8fad4be3fd6dfa2887117d9f41ac20272.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_26"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2 解决方案&lt;/h3&gt; 
&lt;p&gt;为了更好地找到平衡点，搜索数据团队采取了以下解决措施：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;明确边界&lt;/strong&gt;&lt;/strong&gt;：分主题建设对应数据集，单主题内，数据集尽量做到合并统一，以达到更高的集成度与一致性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;明确粒度&lt;/strong&gt;&lt;/strong&gt;：从业务场景需求出发，单主题内数据集建设前明确数据集最小粒度 ，确保数据最小粒度既能满足主题分析的精度要求，又避免因过度细化或粗放导致的分析效能损耗，为后续数据集的结构化构建与高效奠定基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;深度性能优化&lt;/strong&gt;&lt;/strong&gt;：充分利用了 TDE-ClickHouse 强大基础引擎，例如在处理高基数去重计数字段时，创新性地采用 NoMerge 技术来替代传统的 COUNT(DISTINCT) 方法，降低了聚合层的计算负担，实现了查询性能 5 至 10 倍的提升，极大地优化了数据处理速度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_27"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.3 新模式带来的改变&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="图片" src="https://oscimg.oschina.net/oscnet/up-11ffa0f8e33c9d7a46ccb8a729f3b0031ce.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;△ 图灵 3.0 的数据开发新模式&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;强化主动能力，业务自助效率显著提升&lt;/strong&gt;&lt;/strong&gt;：相较于以往被动式的一对一需求定制化开发模式，数据研发工作已从单纯响应被动需求转变为主动规划构建数据集。图灵 3.0 新开发模式下，实现数据集&amp;lt;-&amp;gt;可视化分析&amp;lt;-&amp;gt;仪表盘的数据分析闭环（满足 90% 查询；其余 10% 长尾交给 Adhoc 查询），业务人员对日常通用需求的分析工作转移到数据集自助查询与分析上（根据数据集自助创建可视化数据报表）。可视化分析占比、&lt;strong&gt;&lt;strong&gt;业务自助率提高至 90%，数据研发日常需求量减少 80%。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;非核心常用维度指标查询性能显著提升&lt;/strong&gt;&lt;/strong&gt;：非核心常用维度指标由以往业务提需，查表或单独建设报表来获取数据的方式，转变为通过数据集自助下钻、拖拉拽自由组合常用维度指标，实现可视化分析的方式。借助 TDE-ClickHouse 强大基础引擎能力：可视化分析效率大幅提升，&lt;strong&gt;&lt;strong&gt;从小时、分钟级的数据分析效率，提升至秒级分析&lt;/strong&gt;&lt;/strong&gt;。单次查询数据周期由&lt;strong&gt;&lt;strong&gt;1 周内，提升至 1 年内（&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;秒级完成查询&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;）&lt;/strong&gt;&lt;/strong&gt;，真正做到即需即查即用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;血缘管理规范化，运维效率显著提升&lt;/strong&gt;&lt;/strong&gt;：数据血缘更加完整流程化，数仓-数据集，血缘在 TDS 完成闭环，数据集内字段血缘在 TDA 完成闭环，以数据集为纽带串联整个数据流全过程，&lt;strong&gt;&lt;strong&gt;数据链路运维效率提升 2-3 倍&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;目前，该模式已经广泛应用于搜索各业务数据运营人员早报、周报等多种业务汇报场景。得益于该模式，搜索产品线下&lt;strong&gt;&lt;strong&gt;仪表盘周均查询（PV）高达 1.7W 次&lt;/strong&gt;&lt;/strong&gt;左右，&lt;strong&gt;&lt;strong&gt;可视化分析周均 0.93W 次左右 ，每周&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;超过 400 多名用户参与 TDA 搜索数据分析工作&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;。&lt;strong&gt;&lt;strong&gt;更重要的是，需求的交付周期实现了显著缩短，由&lt;/strong&gt;&lt;/strong&gt;以往的单/双周缩短至按天交付&lt;/strong&gt;&lt;/strong&gt;；甚至在某些情况下，业务人员能够直接自助获取所需数据。在处理重点项目时，该模式也能确保业务团队在第一时间获取到 P0 级别的关键数据。这种方式的转变不仅能够减轻数据开发团队的工作负担——人力成本由原先的&lt;strong&gt;&lt;strong&gt;3 人锐减至 1 人&lt;/strong&gt;&lt;/strong&gt;，还能提高业务侧的数据使用效率和自主性，使得团队得以从繁琐的「取数」与「跑数」任务中解放出来，将更多的精力投入到数仓模型的优化、技术框架的探索与治理等更具战略价值的工作中去。&lt;/p&gt; 
&lt;span id="OSC_h1_28"&gt;&lt;/span&gt; 
&lt;h1&gt;04 总结与展望&lt;/h1&gt; 
&lt;p&gt;数据建模领域正经历从「技术驱动」向「价值驱动」的深刻转型，更加强调的是敏捷性、可解释性和业务对齐。尽管当前的技术工具愈发强大，但成功的关键依旧在于跟业务的紧密协作与一个清晰明确的治理框架。&lt;/p&gt; 
&lt;p&gt;搜索业务，作为百度内部最核心且最为复杂的板块，涵盖了多个至关重要的产品线。近年来，搜索数据团队始终致力于运用前沿技术来不断优化和完善数仓体系的建设，以坚实的基础数仓架构支撑起数据质量飞跃提升，从而高效赋能业务，带来可量化、可感知的业务成效与用户体验升级。&lt;/p&gt; 
&lt;p&gt;展望未来，随着 AI 代理和边缘计算等技术的蓬勃发展，数据建模有望朝着自适应与嵌入式方向进一步进化。搜索数据侧还将在以下关键方向与大家进行深入探讨、交流和学习：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;通用数据流解决方案&lt;/strong&gt;&lt;/strong&gt;：构建事件规则引擎等通用数据流处理工具，简化数据处理流程，提高数据处理效率与灵活性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;日志埋点技术（含无埋点）&lt;/strong&gt;&lt;/strong&gt;：探索高效的自动化埋点机制，提升数据采集的全面性与准确性，为业务洞察提供坚实的数据基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;宽表模型框架抽象层&lt;/strong&gt;&lt;/strong&gt;：探索更为高效、灵活的模型统一抽象方法层。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;strong&gt;AI 大模型时代下的高效开发模式&lt;/strong&gt;&lt;/strong&gt;：探索如何通过利用大模型技术，来优化代码质量、数据链路等，打造更加高效、可靠的数据开发与运维体系。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们期待之后再次与大家见面探讨这些议题，共同推动数据领域的创新与发展。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18683272</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18683272</guid>
      <pubDate>Sun, 11 May 2025 03:38:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>AI 编程软件 Cursor 开发商聘请两位 Anthropic 前高管</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程软件 Cursor 开发商 Anysphere 聘请了两位来自 Anthropic 的前高管，分别担任首席架构师兼工程主管和产品负责人。&lt;/p&gt; 
&lt;p&gt;Boris Cherny，曾是 Claude Code 的开发负责人，将担任 Anysphere 的首席架构师兼工程主管。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0703/113518_qNjw_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Boris Cherny 于 2024 年 9 月加入 Anthropic，入职还不到一年，此前在 Meta 任职首席软件工程师、 Instagram 的服务器架构和开发基础设施主管， 以及 Meta 的代码质量主管，毕业于美国加州大学圣迭戈分校。&lt;/p&gt; 
&lt;p&gt;Cat Wu，曾是 Claude Code 的产品经理，将担任产品负责人。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0703/113527_RWRC_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cat Wu 全名 Catherine Wu，2024 年 8 月加入 Anthropic，擅长构建高可靠、可解释、可控制的人工智能系统，本科毕业于普林斯顿大学，专业计算机科学，加入 Anthropic 之前有多段不同领域工作实习经历，最长两年，比如在谷歌实习任职软件工程师，在 J.P. 摩根实习任职交易员，在 Alexandr Wang 公司 Scale AI 作为作为产品经理任职两年。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358526</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358526</guid>
      <pubDate>Sun, 11 May 2025 03:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>富士康推出首款 AI 推理大模型 「FoxBrain」，商标申请已提交</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;近日，鸿海精密工业股份有限公司（也就是大家熟悉的富士康）在国家知识产权局商标局提交了 「FoxBrain」 商标注册申请。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这款 AI 推理大模型不仅是富士康的首次尝试，更是台湾省首个该类型的 AI 模型。根据公开资料显示，该商标的国际分类为科学仪器，目前正处于 「等待实质审查」 的状态。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="363" src="https://oscimg.oschina.net/oscnet/up-853c20df5c0da43f4e610f96af33d644262.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;「FoxBrain」 是鸿海研究院重磅推出的 AI 推理大模型，涵盖数据分析、数学推理、代码生成等多个功能。富士康声称，FoxBrain 的初始版本基于 Meta 的 Llama3.1 模型进行开发，使用了 120 块英伟达 H100GPU 进行了为期一个月的训练。这一模型特别针对繁体中文进行了优化，尽管其性能相较于其他模型，如 DeepSeek，可能稍显不足。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;值得一提的是，富士康并非台湾省唯一在 AI 领域发力的公司。早前，联发科也推出了 Llama-Breeze2 系列 AI 模型，这些模型虽然定位为 「轻量级」，但同样主打繁体中文处理能力。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358520</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358520</guid>
      <pubDate>Sun, 11 May 2025 03:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Grok 4 将提供面向编程的「Code」版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FAiBattle_%2Fstatus%2F1940139539525419512" target="_blank"&gt;博主「AiBattle」爆料称&lt;/a&gt;，其在 xAI 控制枱的源代码中发现了 2 个 Grok 4 模型的相关信息。&lt;/p&gt; 
&lt;p&gt;据悉，&lt;strong&gt;本次 Grok 4 将拥有标准版和面向编程的 Code 版&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grok 4：xAI 最出色、最新的旗舰模型，在自然语言、数学和推理方面表现优秀。&lt;/li&gt; 
 &lt;li&gt;Grok 4 Code：专为编程而生，能够咨询代码相关问题，或者将 Grok 4 Code 嵌入代码编辑器中。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9bcf46eea400a93a91e4827ee44b5545da0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3a6e92d6992d4ffe25867b6b3a69cdcbc4f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;另据爆料，Grok 4 的权限已经部分开通，可通过 API 访问。目前，Grok 4 支持文本模态以及视觉、图像生成等功能，其他功能也即将推出。&lt;/p&gt; 
&lt;p&gt;马斯克近日也透露，Grok 4 计划在今年 7 月 4 日之后发布；并且新模型将尝试从第一性原理出发进行推理，也就是将物理学的方法应用到思维过程中。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0630/185329_AUaz_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/358033" target="news"&gt;Grok 4 将于 7 月 4 日后发布&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358516</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358516</guid>
      <pubDate>Sun, 11 May 2025 03:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节跳动开源 4D 视频生成框架 EX-4D</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;字节跳动旗下 PICO-MR 团队正式开源了 EX-4D，一款突破性的 4D 视频生成框架；能够从单一视角（单目）视频生成高质量、多视角的 4D 视频序列 (3D 空间+时间维度)。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;传统视频生成技术在多视角生成方面面临两大挑战:一是需要昂贵的多视角相机和数据集进行训练;二是难以处理遮挡区域，导致生成的视频在极端视角下出现物体穿帮或细节失真。EX-4D 通过创新的深度密闭网格（DW-Mesh）表示和轻量级适配架构，成功解决了这些问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;DW-Mesh 是 EX-4D 的核心技术，它通过构建全密闭网格结构，记录场景中的可见和隐形面片，无需多视角监督即可统一处理复杂场景拓扑。结合预训练深度预测模型，EX-4D 将单帧像素投影到 3D 空间，形成网格顶点，并根据几何关系精准标记遮挡区域。这种方法确保了生成视频在极端视角（如±90°）下仍能保持物理一致性和细节完整性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，EX-4D 引入了两种模拟 mask 生成策略——渲染 mask 和跟踪 mask，通过模拟视角移动和帧间一致性，破解了多视角训练数据的稀缺难题。这些策略使 EX-4D 仅凭单目视频即可「脑补」全视角数据，极大降低了数据采集成本。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;性能测试结果表明，EX-4D 在 FID（弗雷歇距离）、FVD(弗雷歇视频距离) 和 VBench 等行业标准指标上全面超越现有开源方法。尤其在极端视角 (如接近 90°) 的生成任务中，EX-4D 的性能优势尤为明显，生成的视频在物体细节和遮挡逻辑上表现更为真实。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="251" src="https://oscimg.oschina.net/oscnet/up-dbd1b11be587afb0f59e10fdb2c7026588a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0px; margin-right:0px"&gt;&lt;span style="color:#000000"&gt;在一项由 50 位志愿者参与的主观评估中，70.7% 的参与者认为 EX-4D 在极端视角下的物理一致性远超其他开源方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;EX-4D 基于预训练的 WAN-2.1 模型，结合 LoRA-based Adapter 架构，在保持计算效率的同时，融入了 DW-Mesh 的几何先验信息，确保生成视频的几何一致性和帧间连贯性。这种轻量级设计使得 EX-4D 在资源受限的环境下也能高效运行，适合广泛的开发场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;span style="background-color:#ffffff"&gt;字节跳动 PICO-MR 团队负责人表示，EX-4D 是团队在 3D 重建与 4D 场景生成领域多年研究的结晶，未来将继续优化模型性能，探索更广泛的应用场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358512</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358512</guid>
      <pubDate>Sun, 11 May 2025 02:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
