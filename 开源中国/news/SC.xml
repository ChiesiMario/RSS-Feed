<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - news - 简体中文</title>
    <link>https://www.oschina.net/news/project</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 14 Aug 2025 03:00:09 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>马斯克 xAI 公司联合创始人 Igor Babuschkin 离职</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;xAI 联合创始人 Igor Babuschkin &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fibab%2Fstatus%2F1955741698690322585" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;离职，他在社交媒体发布了一封感人至深的告别信，回顾了他在 xAI 的非凡历程，并宣布将创立 Babuschkin Ventures，专注于 AI 安全研究和支持推动人类进步的 AI 初创公司。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0814/104112_IXxb_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&amp;nbsp;&lt;/span&gt;&lt;span&gt;回忆了与马斯克的初次会面，两人就 AI 和未来进行了数小时的深入交流，共同认识到世界需要一家具有不同使命的新 AI 公司。&lt;/span&gt;他还提到了 xAI 如何在短短时间内完成了看似不可能的任务——在 120 天内建成 Memphis 超级集群，以及团队如何以「疯狂的速度」推出前沿模型。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;马斯克很快回复了这条推文：感谢你帮助建立 @xAI！没有你就没有我们的今天。&lt;/p&gt; 
 &lt;p&gt;Igor Babuschkin(@ibab) 回应马斯克：谢谢你，Elon！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="962" src="https://static.oschina.net/uploads/space/2025/0814/104723_AJtI_2720166.png" width="1282" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;Igor Babuschkin&lt;/span&gt;&amp;nbsp;是 AI 领域的资深研究员，曾在多家顶级 AI 实验室担任要职。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;他在德国多特蒙德工业大学（TU Dortmund）学习物理学（2010-2015），期间作为夏季研究生参与了 CERN 大型强子对撞机的 LHCb 实验研究。&lt;/li&gt; 
 &lt;li&gt;2017 年他转向机器学习和人工智能领域，加入 DeepMind，担任高级研究工程师，参与开发了能够达到《星际争霸 II》大师级水平的 AlphaStar AI。&lt;/li&gt; 
 &lt;li&gt;2020 年 11 月，他加入 OpenAI，专注于生成模型和代码生成，参与了 AlphaCode 和大型语言模型的研究。&lt;/li&gt; 
 &lt;li&gt;2022 年他短暂回到 DeepMind 担任高级研究工程师，专注于扩展 AI 系统并改进推理和生成能力。&lt;/li&gt; 
 &lt;li&gt;2023 年 5 月，Igor 与马斯克共同创立了 xAI，专注于构建可扩展和可解释的 AI 系统。他在 Nature 等顶级期刊发表了多篇重要论文，在强化学习、模仿学习和大规模训练等领域推动了 AI 的进步。&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366115</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366115</guid>
      <pubDate>Thu, 14 Aug 2025 02:44:24 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub 告别独立时代，Gitee 12 年坚守开启 AI 新程</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;深圳北科大厦，几位外国客人，专注地盯着屏幕上 Gitee 的实操演示，不时还向一旁的中国工程师询问功能细节，转眼一小时过去——这一幕发生在 2018 年 10 月开源中国的深圳办公室，来访者正是 GitHub 的前两任 CEO ：Nat Friedman 与 Thomas Dohmke 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;而如今，这两位熟人走了，开源中国仍在，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;开启 AI 新程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#646a73"&gt;......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 两任 CEO 的东方足迹&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2018 年 10 月，在中国开源年会 COSCon'18 的活动现场，开源中国 COO 徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（现任开源中国 CEO ）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;第一次见到了 Nat Friedman 。「衣着随意，一看就是程序员」，是徐勇对这位 GitHub 掌门人的第一印象。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;可能是身处一个圈子的好感，徐勇与 Nat Friedman 在第二天讨论中国开源生态的闭门会上，聊得格外投机。当 Nat Friedman 得知开源中国也有一款类似 GitHub 的软件后，顿时来了兴趣，当即便和徐勇约定了第二天&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;到&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源中国拜访，于是就出现了开头的一幕。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;那是 2018 年的一个凉爽的上午，一高一矮两个老外走进了开源中国办公室。徐勇回忆，上午十点，Nat Friedman 一行就来了。寒暄一阵之后，徐勇作为东道主，向 Nat Friedman 一行讲解起了当时的 Gitee 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「 Nat 大高个儿嘛，看屏幕就比较费劲，全程都是勾着腰。但看得出，他对 Gitee 很感兴趣，特别是一些功能上的创新——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;或者说，是中国的开发者市场。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;彼时，开源历史上的一个&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;里程碑事件引发全球瞩目：GitHub 被微软以 75 亿美元全资收购。GitHub 作为全球最知名&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;且&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;中立的开源协作平台，被科技巨头收购之后该何去何从？Nat Friedman 被任命为 CEO 未来又有何动作？外界众说纷纭。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但我们可以知道的是，Nat Friedman 官宣上任后的第一件事，并没有出现在 GitHub 的办公室，反而是来到了中国，特别是出现在了开源中国的办公室&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一起观摩 Gitee 的演示&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拜访的最后，Nat Friedman 团队其中一人向徐勇递出了名片，直白地问：「如果我们出钱收购，开源中国卖不卖？」 此人，正是当时 GitHub 的 CTO，也就是后来的第二任 CEO 的 Thomas Dohmke。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对此，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;内心坚定，但周全考虑&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;并没有明确&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;拒绝&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。而在这次深圳会面不久，微软全球 CEO Satya Nadella 来华，又特地安排了与开源中国马越&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#8f959e"&gt;（现开源中国董事长）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;的会面，依旧提及收购事宜。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;面对行业巨头抛来的橄榄枝，开源中国始终坚定选择&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;独立发展。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;徐勇后来回忆道：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「虽然 2018 年，开源中国也处于业务转型的阵痛期，在资本市场四处化缘，但将&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本土&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;唯一的代码托管平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;拱手让人&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，中国未来的开源生态又谈何自强呢&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Gitee 得坚持走自己的路，中国特色的路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;正如 Gitee 一开始就定下的基调：致敬 GitHub ，但绝不照搬，始终聚焦「开发者为本」，走出一条贴合中国开发者需求的特色之路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2 个人，7 年，「他们都离开了」，我们&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;依然前行&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2025 年 8 月 11 日，一则消息震动全球开发者社区：GitHub CEO Thomas Dohmke 宣布辞职，而 GitHub 将结束独立运营，整体并入微软 CoreAI 部门，且微软不再为其寻找新 CEO。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Thomas Dohmke 在内部邮件中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提及&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;：如今 GitHub 已有超过 10 亿个代码库与分支，开发者数量突破 1.5 亿，以及 Copilot 持续引领蓬勃发展的 AI 市场，拥有 2000 万用户&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;并&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不断增长......&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="334" src="https://oscimg.oschina.net/oscnet/up-f5820ca29b80620e4822a8dee4106dad2fb.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如此成绩的背后，是微软与 GitHub 以开放的方式续写开源生态的共生故事：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源开放上，微软开源 WSL （ Windows Subsystem for Linux ），打破了 Windows 与 Linux 长期以来的生态壁垒，成为连接千万开发者的技术桥梁；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GitHub 产品功能上，开放地收购了 NPM 等工具厂商，使得 Actions 能力变强。GitHub Actions 于微软时期推出，甚至免费私有仓库也是在微软时期才开始提供；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;数据开放，GitHub 上的公开数据，成为开发者打磨工具、挖掘趋势、创造新方案的 「原始素材库」。而在大模型时代，无数聚焦代码生成、漏洞检测、自动化开发的大模型与工具，正是以 GitHub 的公开数据为训练基底;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对开发者生态来说，「开放」是微软收购 GitHub 之后的一个极为重要的关键词，并且以这样的开放实现了众多创举，其中就有 Copilot 。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2021 年，随着生成式 AI 的崛起，微软与 OpenAI 合作推出 GitHub Copilot ，正式开启 AI 编程时代。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如今，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Copilot &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;已&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从代码补全工具，发展成拥有 Copilot Chat&amp;amp;Voice 的对话式编程助手，再到能审查与修复代码、用 GitHub Spark 构建全栈应用的多模态智能体系统，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="326" src="https://oscimg.oschina.net/oscnet/up-438ee8757571e7fbed84b401bb5e002b19f.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但，乱世何妨缺英豪？尽管 GitHub Copilot 算是第一个在 AI 编程领域颠覆大家认知的产品，但过去这一年多，微软一定也意识到：在这波 AI 编程浪潮下，旗下的 GitHub 并没有发挥出其应有的影响力，而 Copilot 则更多地是在给旁人做嫁衣。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;正如开源中国 CTO 红薯评价：「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不仅是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 还包括 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;VSC&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ode 。Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 的价值体现在其不止有 1.5 亿用户和 10 亿仓库上，还有巨大的流量和用户惯性。但很明显，很多人已经不买 Copilot 的账了，说得更夸张一点就是 Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub 在 AI 编程时代&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;一开始的首发到现在暂时落后。微软希望改变现在的这个局面，其核心思路不再&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;Git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;H&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;ub+AI&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;span&gt;&lt;span&gt;&lt;span&gt;，而是 All In AI。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;结合微软与 GitHub 目前遇到的危机，曾经的「开放」，也&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;步入「&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;缩紧&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;」。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;相较于 GitHub 在巨头体系下的战略调整，Gitee 的发展路径始终聚焦 「开发者为本」。没有大厂的资金狂投，却凭借 「草根」 式的坚韧，筑牢了中国开源创新的基础设施；没有急于追逐全球扩张，却深耕本土土壤，让每一个功能都贴合中国开发者的工作场景。这种扎根本土的坚守，让 Gitee 在开源浪潮中站稳了脚跟。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;开源中国 12 年坚守，开启 AI 新程&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;看到卸任的新闻，回顾 Nat Friedman 、 Thomas Dohmke 与开源中国 2018 年的这段缘分，不禁令人唏嘘。7 年时间，他们已经离开&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这一变动让不少人感慨开源平台的命运流转，而在中国，另一个名字却始终稳健前行 —— Gitee 正以扎根本土的坚守与创新，书写着属于中国开源的独特篇章。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;如今的 Gitee ，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;依托对中国开发者协作习惯的深刻理解，已进化为一站式软件工程平台，支撑起 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;1350w+&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;开发者&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;36w+ 企业、2000+ 高校&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的高效协作&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;从代码托管到项目管理，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;再到&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;DevOps 工具链，Gitee 的每一&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;次&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;迭代&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;升级&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;都紧扣本土开发者的真实需求 —— &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;让每一行代码，都有改变世界的力量&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-b9db8504e1b37af3a2ff6a04ccded8680c4.png" width="552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;当下，AI 浪潮席卷全球，软件开发正迎来智能化变革。面对这一时代呼唤，开源中国以「与时俱进」的姿态开启 AI 新程，推出&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;面向开发者、终端用户与产业场景的 AI 应用共创平台&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;——&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟（ ai.gitee.com ）。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;模力方舟以全栈技术能力降低 AI 应用门槛，构建三大核心体系：技术基座通过多模态模型库、国产化算力优化和智能调度实现 「模型即服务」，配合低代码工具链加速开发；服务体系覆盖全链路商业化支持，提供安全合规的存储认证系统与企业级私有部署方案，推动金融、工业等垂直领域快速落地；开放生态通过 AI 审核分级、开发者收益倾斜和算力补贴机制，形成 "开发 - 反馈 - 迭代" 的创新闭环。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;img height="282" src="https://oscimg.oschina.net/oscnet/up-9cc384e0174003faaf96509e8c548aa12fe.png" width="554" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:center"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#7f7f7f"&gt;100 层高楼已完成 90 层，模力方舟建立在 OSChina 与 Gitee 之上&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:.0001pt; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;12 载的坚守，有心酸、亦光荣！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在中国这片开源生态的土地上，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;其实并没有如微软这样的顶级大厂，于资金上的猛烈加持，更多是如 Gitee 、模力方舟这样的「草根」搭台，一步一个脚印，深耕本土土壤，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;肩负起了中国软件工程基础设施建设的重任，筑牢了中国开源创新的&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;根&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;过去十二年，Gitee 以学习为起点，在开源路上步步扎实；未来，Gitee 将以模力方舟为支点，在 AI 工程的新赛道上持续创新。从软件工程平台到 AI 工程平台，变的是技术形态，不变的是 「全心全意为开发者服务」 的初心。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;在开源与 AI 交织的新远征中，Gitee 将继续扎根本土、拥抱世界，以自主创新的中国特色之路，为全球开发者贡献属于中国的开源力量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4806939/blog/18688139</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4806939/blog/18688139</guid>
      <pubDate>Thu, 14 Aug 2025 02:42:24 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>智元发布行业首个机器人世界模型开源平台 Genie Envisioner</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;智元机器人&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FvIORutIHio41I0_RdSvxFQ" target="_blank"&gt;宣布&lt;/a&gt;推出面向真实世界机器人操控的统一世界模型平台 --- Genie Envisioner（GE）。 不同于传统「数据—训练—评估」割裂的流水线模式，GE 将未来帧预测、策略学习与仿真评估首次整合进以视频生成为核心的闭环架构，使机器人在同一世界模型中完成从「看」到「想」再到「动」的端到端推理与执行。、&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;当前机器人学习系统普遍采用分阶段开发模式——数据收集、模型训练、策略评估，每个环节相互独立，并需要专门的基础设施和任务特定调优。这种碎片化架构增加了开发复杂度，延长了迭代周期，限制了系统的可扩展性。GE 平台通过构建统一的视频生成世界模型，将这些分散的环节集成到一个闭环系统中。基于约 3000 小时的真实机器人操控视频数据，GE 建立了从语言指令到视觉空间的直接映射，保留了机器人与环境交互的完整时空信息。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;&lt;img height="359" src="https://oscimg.oschina.net/oscnet/up-9e779b08554174964903820746608b89226.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;GE 的核心突破在于构建了基于世界模型的以视觉中心的建模范式。不同于主流 VLA（Vision-Language-Action）方法依赖视觉-语言模型将视觉输入映射到语言空间进行间接建模，GE 直接在视觉空间中建模机器人与环境的交互动态。这种方法完整保留了操控过程中的空间结构和时序演化信息，实现了对机器人-环境动态更精确、更直接的建模。这一视觉中心的建模范式带来了两个关键优势：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;高效的跨本体泛化能力&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;基于强大的视觉空间预训练，GE-Act 仅需极少量数据即可实现跨平台迁移。在 Agilex Cobot Magic 和 Dual Franka 等全新机器人平台上，GE-Act 仅使用 1 小时（约 250 个演示）的遥操作数据就实现了高质量的任务执行。相比之下，即使是在多本体数据上有大规模预训练的π0 和 GR00T 模型，在相同数据量下的表现也不如 GE-Act。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这种高效泛化源于 GE-Base 在视觉空间中学习到的通用操控表征。通过直接建模视觉动态而非依赖语言抽象，模型能够捕捉到跨平台共享的底层物理规律和操控模式，从而实现快速适配。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="340" src="https://oscimg.oschina.net/oscnet/up-682debad2a8cc04919c242725f76a1431ca.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;长时序任务的精确执行能力&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更重要的是，视觉中心建模赋予了 GE 强大的未来时空预测能力。通过在视觉空间中显式建模时序演化，GE-Act 能够规划和执行需要长时序推理的复杂任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#3e3e3e; margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;在折叠纸盒等超长步骤任务中，GE-Act 展现出了远超现有 SOTA 方法的性能。以纸盒折叠为例，这项任务需要精确执行超过 10 个连续子步骤，每个步骤都依赖于前序动作的准确完成。GE-Act 达到了 76% 的成功率，而专门针对柔性物体操控优化的π0 仅为 48%，UniVLA 和 GR00T 则完全无法完成（0% 成功率）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;这种长时序执行能力的提升不仅源于 GE 的视觉世界建模，同时也得益于我们创新设计的 sparse memory 模块。通过这样的模块设计，能够帮助机器人选择性地保留关键历史信息，从而在长时序任务中保持精确的上下文理解。通过预测未来的视觉状态，GE-Act 能够"预见"动作的长期后果，从而生成更连贯、更稳定的操控序列。相比之下，基于语言空间的方法在长时序任务中容易出现误差累积和语义漂移。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#1d1d1d; margin-left:0; margin-right:0; text-align:justify"&gt;&lt;span style="color:#000000"&gt;&lt;img height="267" src="https://oscimg.oschina.net/oscnet/up-f5f50fbfcf620d524eb4680b8cf07bfccbf.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;基于视觉中心建模理念，GE 平台包含三个紧密集成的组件：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Base：多视角视频世界基础模型&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Base 是整个平台的核心基础，采用自回归视频生成框架，将输出分割为离散的视频块（video chunks），每块包含 N 帧。模型的关键创新在于其多视角生成能力和稀疏记忆机制。通过同时处理来自头部相机和双臂腕部相机的三路视角输入，GE-Base 能够保持空间一致性并捕捉完整的操控场景。稀疏记忆机制通过随机采样历史帧来增强长时序推理能力，使模型能够在保持时序连贯性的同时处理长达数分钟的操控任务。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="174" src="https://oscimg.oschina.net/oscnet/up-0475a4c1c079e38953216e3ab0870bf0c5a.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;训练采用两阶段策略：首先在 3-30Hz 的多分辨率采样下进行时序适应训练（GE-Base-MR），使模型对不同运动速度具有鲁棒性；随后在 5Hz 固定采样率下进行策略对齐微调（GE-Base-LF），与下游动作建模的时序抽象保持一致。整个训练基于 AgiBot-World-Beta 数据集的约 3000 小时、超 100 万条真机数据，使用 32 块 A100 GPU 训练约 10 天完成。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="164" src="https://oscimg.oschina.net/oscnet/up-0a9acef7c1d6dc6644be9e9ed33a6e0ff61.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Act：平行流匹配动作模型&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Act 作为即插即用的动作模块，通过 160M 参数的轻量级架构将 GE-Base 的视觉潜在表征转换为可执行的机器人控制指令。其设计巧妙地与 GE-Base 的视觉主干平行设计，采用与 GE-Base 相同网络深度的 DiT 块但使用更小的隐层维度以提高效率。通过交叉注意力机制，动作路径能够充分利用视觉特征中的语义信息，确保生成的动作与任务指令保持一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="146" src="https://oscimg.oschina.net/oscnet/up-7eb9b05e82c8e0b32b33f216f17720e3c7d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Act 的训练分为三个阶段：动作预训练阶段将视觉表征投射到动作策略空间；任务特定视频适应阶段更新视觉生成组件以适应特定任务；面向特定任务的动作微调完整模型以捕捉细粒度控制动态。特别值得注意的是其异步推理模式：视频 DiT 以 5Hz 运行进行单步去噪，而动作模型以 30Hz 运行进行 5 步去噪，这种"慢-快"双层优化使得系统能在机载 RTX 4090 GPU 上以 200 毫秒完成 54 步动作推理，实现实时控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="232" src="https://oscimg.oschina.net/oscnet/up-d51e33e5353faa835a677b8bbe5490561a1.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;GE-Sim：层次化动作条件仿真器&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;GE-Sim 将 GE-Base 的生成能力扩展为动作条件的神经仿真器，通过层次化动作条件机制实现精确的视觉预测。该机制包含两个关键组件：Pose2Image 条件将 7 维末端执行器姿态（位置、姿态、夹爪状态）投影到图像空间，通过相机标定生成空间对齐的姿态图像；运动向量计算连续姿态间的运动增量，编码为运动令牌并通过交叉注意力注入到每个 DiT 块中。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="217" src="https://oscimg.oschina.net/oscnet/up-7083a0ea94bed7448611a5ca8747b5d4081.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;这种设计使 GE-Sim 能够精确地将低层控制指令转换为视觉预测，支持闭环策略评估。在实际应用中，策略模型生成的动作轨迹被 GE-Sim 转换为未来的视觉状态，这些生成的视频再反馈给策略模型产生下一步动作，形成完整的仿真闭环。通过分布式集群并行化，GE-Sim 可实现每小时数千次的策略 rollout 评估，为大规模策略优化提供了高效的评估平台。更重要的是，GE-Sim 还能作为数据引擎，通过在不同初始视觉环境下执行相同动作轨迹来生成多样化的训练数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="139" src="https://oscimg.oschina.net/oscnet/up-115cb9730ef9b5af303d525fc92e0c6761e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;此外，为了评估面向具身任务的世界模型质量，团队在 GE 核心组件之外开发了 EWMBench 评测套件。它从场景一致性、轨迹精度、运动动力学一致性，到语义对齐，全方位打分。多名专家的主观评级与 GE-Bench 排名高度一致，验证了其对机器人任务相关性评测的可靠性。在与 Kling、Hailuo、OpenSora 等先进模型的对比中，GE-Base 在多项体现视觉建模质量的关键指标上均取得最优成绩，且与人类判断高度一致。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#000000"&gt;&lt;img height="159" src="https://oscimg.oschina.net/oscnet/up-40f011244762f77df3ea098b6ff45463753.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366112</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366112</guid>
      <pubDate>Thu, 14 Aug 2025 02:22:24 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Apache RocketMQ EventBridge：为什么 GenAI 需要 EDA？</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;沈林，Apache RocketMQ PMC 成员，阿里云 EventBridge 负责人，专注于 EDA 研究。本文整理自作者在 Community Over Code Asia 2025 会议发表的主题演讲《Apache RocketMQ EventBridge: Why Your GenAI Needs EDA？》。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;EDA 的核心特点是：以事件为中心，实时响应变化。它不像传统"请求-响应"模式那样被动等待，而是"感知→触发→行动"全自动流转。在 AI 系统中，数据流、模型训练和推理、外部反馈等都可以作为"事件"，触发 AI 自动决策和联动执行。EDA 就像是 AI 时代的"神经系统"，让 AI 不仅能"思考"，还能"感知"和"行动"。它提升了系统的实时性、灵活性和自动化水平，是构建智能系统的关键支撑。AI 赋予系统"大脑"，EDA 构建系统的"神经"。&lt;/p&gt; 
&lt;p&gt;本文主要探讨在 AI 时代，EDA 的重要价值及它可以帮助我们解决的问题。&lt;/p&gt; 
&lt;h2&gt;EDA 的第一重价值：通过 RAG 缓解 AI 幻觉&lt;/h2&gt; 
&lt;p&gt;大家可能还有印象，2023 年上半年，Google 的早期 AI 模型发布时，回答一个关于詹姆斯·韦伯空间望远镜的问题时，犯了一个低级"错误"，这个答案本来在 Google 上很容易搜索到，但是 AI"一本正经"的给了一个错误答案，直接导致谷歌当天的股价跌了 8% 左右。但 AI 完全没有意识到自己的错误，这是为什么？&lt;/p&gt; 
&lt;h3&gt;1. 为什么会有 AI 幻觉？&lt;/h3&gt; 
&lt;p&gt;AI 幻觉的产生机制比较复杂，可简单从训练和推理两个阶段进行分析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;训练阶段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;数据覆盖不足&lt;/strong&gt;：若训练数据不包含特定信息，模型无法"无师自通"；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;过拟合&lt;/strong&gt;：模型过度学习训练数据中的细节与噪声，导致在面对新数据时泛化能力差；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;通用性与精度取舍&lt;/strong&gt;：通用大模型为覆盖广泛领域，在特定垂直领域的准确性可能有所牺牲。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;推理阶段：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;自回归生成&lt;/strong&gt;：LLM（大语言模型）推理本质上是一个自回归过程，基于现有 Token 预测下一个最可能的 Token，这种概率性生成机制使得幻觉成为其固有潜在分布的一部分。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;连贯性优先于准确性&lt;/strong&gt;：GenAI 输出的时候倾向于生成流畅连贯的答案，而非绝对准确的答案。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 如何减少 AI 幻觉？&lt;/h3&gt; 
&lt;p&gt;为了解决 AI 幻觉，现在一般有三种主流的方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型微调（Fine-tuning）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;模型不好？最能直接想到的方法就是优化模型：丰富模型训练的数据、优化模型的参数，让其在垂直场景领域，回答更加精准。这种方式在很多场景是非常有效的，而且依旧被广泛采用。但是这种方式，要求也是比较高的，如果没有一定的人力和算力成本投入，将很难实现。尤其是在知识更新频繁的领域，模型需要不断调整，长期维护，投入代价相对较高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;提示词工程（Prompt Engineering）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以不调整模型，而是在向 LLM 提问的时候，把相关的数据和限定条件一起给到 LLM？答案是可以的，这就是提示词工程。&lt;/p&gt; &lt;p&gt;但是如何构造一个好的提示词，把 LLM 需要的上下文信息给到它，这个要求也是非常高的。不同人使用，提示词的构造水平也不同：这种方式就像是把"问问题"变成了一件"手工艺术活"。而且提示词优化虽然可以"压平"部分幻觉，但只要模型权重未变，提示词没有带上相关数据，提示词只能暂时把幻觉"藏"起来，而无法真正去除。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;检索增强生成（RAG）：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;那可不可以自动帮我们生成一个高质量的提示词呢？在这个提示词中，包含了 LLM 回答需要的关键信息。这个就和我们最后一个要讲的 RAG 非常像了，让我们看下 RAG 到底是什么。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 什么是 RAG？&lt;/h3&gt; 
&lt;p&gt;RAG 可以简单理解为：向 LLM 提问的时候，同时给这个问题，检索一个上下文，一起给到 LLM。比如：如果我们问 DeepSeek：本次 Apache 峰会有哪些讲师聊到了 RAG 这个话题？DeepSeek 肯定不知道，因为它没有这个数据，网上暂时也还没有相关数据。但如果给到它一个关于本次大会讲师的讲稿资料包。这样 DeepSeek 就有非常强相关的上下文，回答问题的时候，就不会跑题答偏。&lt;/p&gt; 
&lt;p&gt;那 AI 要如何做到这一点呢？主要分两步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;建立索引&lt;/strong&gt;：首先，需要提前把讲师资料包存起来。但资料包可能非常大，我们需要快速找到跟提问的问题相关联的数据，这里就需要用到向量化。向量化本质上是对一个事物，从多个特征维度，进行数值标记。比如，标记我这个人，可以从年龄、身高、性别等多个特征标记，标记越多越清晰。如果两个向量在多维空间中的"位置"越接近，说明它们越相似。所以，我们需要提前把数据进行向量化，存到向量数据库里。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;检索生成&lt;/strong&gt;：然后，当我们向 LLM 提问时，可以先把问题向量化，根据向量化后的结果，去向量数据库查询关联性最大的原始知识数据。最后，将查到的知识数据，作为上下文和问题一起传给 LLM，LLM 就可以给一个更加准确的回答了。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-045b51500f01c2a85c12e955b7cd13f02bc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;从这个过程中，我们会发现 RAG 有两个非常明显的优点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;不需要用知识库数据给大模型训练，既节省了成本，又保证了数据隐私；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不需要用提示词工程这样的"手工艺术活"，就可以让 AI 出现幻觉的概率变得足够低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 为什么 EventBridge 适合做 RAG？&lt;/h3&gt; 
&lt;p&gt;为什么是 EventBridge 适合来做 RAG 呢？ 我们先来看下什么是 EventBridge：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;EventBridge 的整个模型其实非常简洁：我们从下图左侧开始往右看，EventBridge 可以方便的把外部的数据，以标准化的事件格式，配合事件 Schema 集成到内部，中间可以存入事件总线（BUS），也可以选择不存储，然后通过过滤/转换，推送到下游服务中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;这个链路，正好可以满足 RAG 过程中需要的三要素：获取上游丰富的数据、自定义切分和向量化、持久化到多种向量化数据库中。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-73b0f09489921a9380a6cf55b6026f0ffb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;5. EventBridge 如何实现 RAG？&lt;/h3&gt; 
&lt;p&gt;用一个场景举例，比如我们想建一个关于 EventBridge 知识的智能问答机器人，可以回答关于 EventBridge 的常见问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;我们需要把存在上游 OSS 的 EventBridge 文档，通过 EventBridge 的事件流，进行 Chunk 切分、Embedding 向量化，然后存储到向量数据库；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;完成之后，当我们向 EventBridge 智能机器人提问"EventBridge 是什么？"，智能机器人会先把这个问题向量化，然后去向量数据库查找匹配度最高的相关内容，并一起传递给 LLM，LLM 就能结合查到的资料，给出非常精准的回答，减少幻觉产生。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-00e0291ba9dc0a5f24c08e141e6d17ebb3d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，阿里云大模型服务平台百炼的知识库 RAG 场景，已采用 EventBridge 的事件流能力，帮助众多客户减少了 LLM 问答中的幻觉问题，尤其在细分垂直领域效果显著。如果您感兴趣可以进行体验：&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbailian.console.aliyun.com%2F%3F%26tab%3Dapp%23%2Fknowledge-base" target="_blank"&gt;https://bailian.console.aliyun.com/?&amp;amp;tab=app#/knowledge-base&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;EDA 的第二重价值：推理触发器（Inference Trigger）&lt;/h2&gt; 
&lt;p&gt;我们第二个想讨论的场景是推理触发器。&lt;/p&gt; 
&lt;h3&gt;1. 程序使用 LLM 的规模将远超人类&lt;/h3&gt; 
&lt;p&gt;目前，我们日常接触最多的 LLM 场景是人与 LLM 服务直接对话，如问 DeepSeek 一个问题或智能客服等。 但更常见且增长迅速的方式是程序触发 LLM。例如供应链优化和金融订单风控。&lt;/p&gt; 
&lt;p&gt;观察微服务就会发现，人调用 API 的量级远不如程序调用 API 的量级。相应地，我们可以想象，未来程序触发 LLM 的规模，也将远远超过人工使用 LLM。&lt;/p&gt; 
&lt;p&gt;这其中的机会，我们应该怎么把握？&lt;/p&gt; 
&lt;h3&gt;2. 推理诉求无处不在&lt;/h3&gt; 
&lt;p&gt;事实上，我们现有的商业系统中，已经存储了大量现成需要推理的场景。比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;消息服务里，存储了客户的评论，需要对其打标分析，这条评论是积极的还是消极的，并给个分数；&lt;/li&gt; 
 &lt;li&gt;DB 里存储了产品的描述介绍信息，想让 AI 给一些产品描述优化建议；&lt;/li&gt; 
 &lt;li&gt;OSS 或 S3 存储了大量的文档，想让 AI 对每个文档生成一个 100 字的文档摘要。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些诉求在以前可能需要人工处理，但现在都可以交给 LLM，从而极大提升工作效率。那怎么让现有的商业系统，方便、快捷、低成本的使用 AI，甚至不需要写一行代码，这个就是 EventBridge 擅长的地方了。&lt;/p&gt; 
&lt;h3&gt;3. 推理触发器：让模型被更好地使用&lt;/h3&gt; 
&lt;p&gt;为此，EventBridge 提供了三把武器：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2f27bd8eda56c7eb4b1fe2a5c832ff70bbb.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第一把武器------实时推理并将结果存到目标端：&lt;/strong&gt; 通过 EventBridge 可以实时监听并获取存在 DB、消息、或者存储服务中的数据，然后实时调用 LLM 推理服务，并将推理结果输出存到目标端。此过程也可以结合上一部分讲到的 RAG，但中间不一定是一个 LLM，也可以是一个 Agent，甚至是一个 AI Workflow。&lt;/p&gt; &lt;p&gt;这个过程看似简单，但有很多需要注意的地方：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;数据合并&lt;/strong&gt;：我们刚才聊到，LLM 的推理本质上是一个自回归过程，这次的输出会作为下一次的输入，无法一次性拿到结果，很多 LLM 只能支持以流式的方式返回数据，但下游往往需要的是一个确定性的结果，所以我们需要对流式数据进行合并再输出；&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;数据格式&lt;/strong&gt;：很多业务场景下有明确的格式要求。比如上面提到的例子，让 LLM 对客户评论打标和评分，需要输出一个 JSON 结构。但不是所有 LLM 在 API 层面都支持 JSON 结构输出，我们需要通过提示词进行优化，让它尽可能输出一个符合要求的 JSON 结构。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;推理吞吐&lt;/strong&gt;：LLM 的自回归生成方式，导致单次请求 RT 长、TPS 低。所以，我们需要提升高并发能力，把昂贵的 GPU 资源使用效率发挥到极致，同时需要做好 TPM 和 RPM 的限流，也就是每分钟请求次数和每分钟 Token 数的限流，以保证链路不会有大量限流异常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以看到，具体落地会遇到很多挑战，但 EventBridge 可以帮助客户便捷高效地解决这些问题。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第二把武器------基于推理结果触发任务执行：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;除了让 LLM 推理输出结果存到目标端，EventBridge 还可以让 Agent 基于上游的某条消息，去调用某一个 Service，执行某一个动作，如发送邮件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第三把武器------离线异步推理提高资源利用率：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;对于实时性要求不高的推理场景，可以通过 EventBridge 实现离线异步推理，让稀缺的 GPU 资源被更好地调度利用，在云上的成本至少比实时推理便宜一半。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI 的强大在于其应用，而 EDA（事件驱动架构）非常适合作为推理触发器，激活 AI 的价值。&lt;/p&gt; 
&lt;h2&gt;EDA 的第三重价值：构建 Agent 通信基础设施&lt;/h2&gt; 
&lt;p&gt;现在 AI Infra 非常热门，其概念非常广泛。对标 IT Infrastructure，我们这里讨论的话题是 AI 的通信。&lt;/p&gt; 
&lt;h3&gt;1. 微服务的通信离不开 Messaging，Agent 间的通信应该如何？&lt;/h3&gt; 
&lt;p&gt;在微服务时代，消息系统在微服务间的通信中扮演了重要角色。到了 AI 时代，消息系统是否依然起着关键作用？具体形式和产品又会有哪些变化？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c0ae2c687b84e25b6cf9a437040abeb17d4.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;2. Agent 和 Service 的通信：Function Calling、MCP&lt;/h3&gt; 
&lt;p&gt;为了回答这个问题，我们先看下现在 AI 的通信是怎么做的。&lt;/p&gt; 
&lt;p&gt;首先，我们看下 Agent 和传统 Service 之间的通信。目前有两种主流的方式：Function Calling 和 MCP。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Function Calling：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 OpenAI 公司在 2023 年提出的。因为 LLM 本身是文本生成器, 不具备访问外部系统的能力。但是我们可以对 LLM 进行训练微调，让 LLM 理解外部的一些工具函数的定义，这样在遇到提问时，就可以按需生成这些工具函数需要的参数，然后调用这些工具函数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP：&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;是 2024 年 11 月 Anthropic 提出的，全称 Model Context Protocol‌，其本意是用来解决 LLM 无状态的问题。LLM 每次调用都是独立的，而 MCP 是用来给 LLM 提供运行上下文，相当于一个"Session 机制"。但是为什么 MCP 会被拿来和 Function Calling 放在一起呢？因为它也可以拿来调用工具函数。和 Function Calling 不同的是，它不需要 LLM 提前训练微调来理解函数的入参和返回值，而是通过上下文"提示词"告诉 LLM 参数返回值。所以 MCP 相比 Function Calling，对模型的依赖更小，更加通用，但效果相比 Function Calling 要差一点。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Agent 和 Agent 的通信：A2A&lt;/h3&gt; 
&lt;p&gt;我们再来看下 Agent 与 Agent 之间是怎么通信的。&lt;/p&gt; 
&lt;p&gt;Google 在今年 4 月份的时候，提出了一个 A2A 的通讯协议，其核心运行机制分为四步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第一步：Client Agent 通过 Agent Card，看下远端 Agent 有哪些能力；&lt;/li&gt; 
 &lt;li&gt;第二步：根据 Agent Card 的能力描述，调用远端 Agent，创建一个 Task，让其帮忙完成一个任务；&lt;/li&gt; 
 &lt;li&gt;第三步：由于任务可能比较耗时，不一定能够立即响应。所以 A2A 协议允许远端 Agent 通过 SSE 协议，不间断的将任务的状态信息更新给 Client Agent；&lt;/li&gt; 
 &lt;li&gt;第四步：再将结果返回给 Client Agent，当然结果本身也是可以流式返回的。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e2e33909d1e1fa5c7fb16b3509dba8dfa21.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;4. MCP 和 A2A 之间的区别&lt;/h3&gt; 
&lt;p&gt;那 MCP 和 A2A 协议有什么区别呢？Google 给它们的关系做了一个描述：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;A2A 协议像一种沟通语言：&lt;/strong&gt; 如果把 Agent 比做人，一个人如果能力有限，想让其他 Agent 帮忙怎么办？A2A 协议就可以派上用场了，A2A 协议像一种沟通语言，可以让 Agent 和其他 Agent 用同一种语言交流，不至于说话的时候驴唇不对马嘴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP 就像工具使用说明书：&lt;/strong&gt; Service 等价于人使用工具，可以提升人解决问题的能力。不过，使用工具也需要有些技巧，MCP 就像工具使用说明书，可以让 Agent 更方便的使用这些 Service，来扩展 Agent 的能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-538598e9588c1dda1dac99334b8b440c970.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;我们把 Agent 比做人，把 Service 比做工具。但是，请人帮忙和请工具帮忙，真的可以分得这么清楚吗？&lt;/p&gt; 
&lt;h3&gt;5. 预测 1：A2A and MCP 可能走向融合&lt;/h3&gt; 
&lt;p&gt;A2A 和 MCP 的职责，设想很完美，但是实际运行的时候会遇到很多挑战。我们先来一起看看在 MCP 和 A2A 协议下，两者用来声明一个 Agent 或者 Service 能力的时候是怎么样的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;这里举例了一个"查询北京天气"的服务，会发现两者声明自己能力的时候，非常类似：&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c08367f12deb092a1cccd326b2b3ae2d53a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;其次，两者的传输层协议也都非常相似，都支持 SSE 和 JSON-GRPC；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最后，我们从工程师开发角度，推演一个场景：当一个 Agent 需要获取"查询天气"的能力时，它并不真正关心该能力是由一个 Service 还是另一个 Agent 提供的。Agent 的核心关注点在于能力的接口定义：即有哪些可用能力、如何调用，以及预期的返回结果是什么。至于该能力的后端提供者是 Service 还是 Agent，对于调用方而言是无需关注的实现细节。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这里我们的第一个预测是：A2A and MCP 未来可能会合并，但具体怎么发展，还要看生态的选择。&lt;/p&gt; 
&lt;h3&gt;6. 预测 2: 点对点的通信是不够的&lt;/h3&gt; 
&lt;p&gt;这里的第二个预测是：现有 MCP 和 A2A 协议中，只包含的点对点通信是不够的。按照 A2A 协议的推演，当一个系统中有很多 Agent 时，所有 Agent 都通过"长连接"集成在一起：大家第一个直观的感受是什么？&lt;/p&gt; 
&lt;p&gt;连接太多了！ 如果两个 Agent 通过"长连接"集成在一起，感觉可能也没有什么。但是如果一个 Agent 同时需要和数百个甚至上千个 Agent 通信，系统中就会产生大量的长连接。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先对每一个 Agent 来讲，资源开销就非常大；&lt;/li&gt; 
 &lt;li&gt;其次，网状的连接，一旦某一个 Agent 出现问题，hang 住了某些资源，会不会拖垮其他 Agent 的服务？甚至拖垮整个系统？这类问题在微服务中，再常见不过了。&lt;/li&gt; 
 &lt;li&gt;最后，即使不会被出问题的 Agent 拖垮服务，但当这个出问题的 Agent 恢复时，之前的通讯是否依旧可以继续追踪？再次执行，是否已经幂等，是否有风险？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这里面有非常多的稳定、性能、成本、扩展性的挑战。这些问题在微服务中已经被多次验证过，有些经验我们可以学习过来。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-acaff61d3cd696e4c06caae076daf62ceb2.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;7. EventBridge Super Agent&lt;/h3&gt; 
&lt;p&gt;基于上面两个预测判断，我们给出了一个 RocketMQ EventBridge 的回答: 在这个模型中，我们引入了一个 EventBridge Agent Proxy 的角色。我们姑且称它为"Super"Agent ，但它不是一个真正的 Agent，而是可以代理 Agent 的能力。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，所有 Agent 都可以写一份自己的个人简历，把自己拥有的能力，注册到"Super"Agent 上；&lt;/li&gt; 
 &lt;li&gt;如果某个 Agent 需要调用其他 Agent 的能力，它可以在 "Super" Agent 中查找是否有其需要的 Agent。如果有，就可以直接通过与 "Super" Agent 的交互，来获得这个能力；&lt;/li&gt; 
 &lt;li&gt;当这个 Agent 需要多个其他 Agent 的能力时，也不需要和每一个 Agent 交互，都可以通过 "Super" Agent 代理实现，将原本的 N:N 模型简化为 1:1 模型。&lt;/li&gt; 
 &lt;li&gt;除此之外，"Super" Agent 中的 Proxy 除了 A2A 协议，还会路由和跟踪每一个 Task 的运行状态，即使在异常/重启/集群扩容等场景下，每一个 Task 都能被按预期处理，并把状态同步回 Agent。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;"Super"Agent 和微服务注册中心有点类似，不过区别在于，它不光是提供了微服务查找寻址的作用，同时还起到了服务代理的作用。如果我们脑洞再大一点，可以不仅局限于 Task 级别的任务追踪和管理，甚至还可以往上考虑一层，提供"User"级别的上下文：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;我们现在的 Agent 都是没有记忆的，我们之前跟它说过的话，过几天再问它，它就不记得你了。&lt;/li&gt; 
 &lt;li&gt;但是每个人使用工具的习惯是不一样的。如果 Agent 能更好的理解你，记得你，就可以提供更加人性化的服务。&lt;/li&gt; 
 &lt;li&gt;作为 Agent 注册和代理中心，如果在为 Agent 提供代理的同时，还能同时提供"User"的上下文，并且用 Agent 的越多，"User"的身份画像越完善；反过来，Agent 越依赖，进入一个正向循环。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-e0b899ea6d8383b99a2a6d186d58bca361a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，EventBridge Agent 代理还处于理论探索阶段，欢迎大家一起交流。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;参考文献与延伸阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Lewis et al., 2020]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Model Context Protocol (MCP) Specification, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[A2A: Agent-to-Agent Communication Protocol, Google, 2024]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apache RocketMQ EventBridge 官方文档：&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frocketmq.apache.org%2F" target="_blank"&gt;https://rocketmq.apache.org/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;2025 杭州·云栖大会，来了！&lt;/p&gt; 
&lt;p&gt;9 月 24 日至 26 日，杭州·云栖小镇&lt;/p&gt; 
&lt;p&gt;三场重磅主论坛&lt;/p&gt; 
&lt;p&gt;超 110 场聚合话题专场&lt;/p&gt; 
&lt;p&gt;40000 平方米智能科技展区&lt;/p&gt; 
&lt;p&gt;点击&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyunqi.aliyun.com%2F2025%2Fticket%3FactivityId%3DNTQ1Ng%3D%3D%26ticketId%3DMTMy%26channelId%3DMzM0NA%3D%3D" target="_blank"&gt;此处&lt;/a&gt;免费注册领取云栖大会门票&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18688052</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18688052</guid>
      <pubDate>Thu, 14 Aug 2025 02:12:24 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>联想第一财季营收 1362 亿元，AI PC 市场份额领先全球</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;联想集团公布了截至 2025 年 6 月 30 日的第一财季业绩报告，显示出该公司在多个业务领域的强劲增长。报告显示，联想本季度实现营收 1362 亿元人民币，同比增长 22%，创下历史同期新高。此外，净利润也同比增长 22%，达到 28.16 亿元人民币，展现出企业盈利能力的显著增强。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="528" src="https://oscimg.oschina.net/oscnet/up-eeef33bdab809d7d5055d90415773e9216c.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在具体业务表现方面，智能设备业务集团 （IDG） 营收为 973 亿元人民币，同比增长 17.8%。这一业务的运营利润率为 7.1%。在 PC 业务上，联想表现尤为突出，同比增长 19%，成为 15 个季度以来的最快增速。值得一提的是，联想在全球 PC 市场的份额达到了 24.6%，同样创下历史新高。同时，AI PC 的出货量超过整体 PC 出货量的 30%，在 Windows AI PC 市场中稳居第一。此外，在中国市场，具备五大 AI 特性的 AI PC 占到了笔记本总出货量的 27%。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在智能手机业务方面，联想的营收为 162 亿元人民币，同比增长 14%。海外市场的表现也相当强劲，折叠屏手机的市场份额达到 51%，保持行业领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;基础设施方案业务集团 （ISG） 的表现同样亮眼，营收达到 310 亿元人民币，同比增长 35.8%。其中，AI 基础设施业务的营收同比增长高达 155%，液冷技术方案收入也实现了 30% 的增长，显示出该领域的良好发展潜力。特别是在中国市场，ISG 的营收同比增长达 76%，运营利润率提升了 3 个百分点。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;联想表示，当前 「超级智能」 正成为全球科技企业的新风口，这与其早前提出的 「混合式 AI」 战略相一致。联想在创新方面持续加码，本季度研发费用同比增长超过 10%，为未来的竞争力奠定了基础。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366100</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366100</guid>
      <pubDate>Thu, 14 Aug 2025 02:07:24 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Warm-Flow 1.8.0 重大更新</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;h1&gt;🚀 Warm-Flow 迎来重大突破，自研仿钉钉设计器震撼发布！&lt;/h1&gt; 
&lt;p&gt;亲爱的开发者朋友们，我们很高兴地宣布 Warm-Flow 工作流引擎迎来了 1.8.0 版本的重大更新！这次更新不仅带来了全新的功能特性，更在用户体验上实现了质的飞跃。&lt;/p&gt; 
&lt;h2&gt;🔥 核心亮点&lt;/h2&gt; 
&lt;h3&gt;自主研发仿钉钉设计器&lt;/h3&gt; 
&lt;p&gt;Warm-Flow 现在同时支持&lt;strong&gt;经典模式&lt;/strong&gt;和&lt;strong&gt;仿钉钉模式&lt;/strong&gt;双设计器！我们基于 logic-flow 自主研发了仿钉钉设计器，避免了维护两套代码的复杂性，实现了更好的统一性和可维护性。&lt;/p&gt; 
&lt;h3&gt;智能交互体验升级&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;跳转线自动识别：当您绘制回退线条时，系统会自动识别并设置为退回跳转类型&lt;/li&gt; 
 &lt;li&gt;节点自由拖动：经典模式下节点和连线文字支持自由拖动调整&lt;/li&gt; 
 &lt;li&gt;智能编辑控制：设计器现在根据流程发布状态自动判断是否可编辑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;功能增强与优化&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;新增&lt;span style="color:#e74c3c"&gt;&lt;strong&gt;getFirstBetweenNode&lt;/strong&gt;&lt;/span&gt;接口，快速获取第一个中间节点&lt;/li&gt; 
 &lt;li&gt;流程图渲染支持顶部名称显示/隐藏控制&lt;/li&gt; 
 &lt;li&gt;中间节点新增用户图标，界面更加友好&lt;/li&gt; 
 &lt;li&gt;优化代码格式和注释，提升开发体验&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📊 可视化展示&lt;/h2&gt; 
&lt;p&gt;新版流程设计器界面更加美观直观：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="新版流程图" src="https://oscimg.oschina.net/oscnet//46766d71052a25ab76b7d79977217d8f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img alt="新版流程图" src="https://oscimg.oschina.net/oscnet//cfec2f0265cb8499c40e5a308c9e2d84.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;🌟 为什么选择 Warm-Flow？&lt;/h2&gt; 
&lt;p&gt;作为国产工作流引擎，Warm-Flow 具有以下优势：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;简洁轻量&lt;/strong&gt; - 五脏俱全，灵活扩展性强&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;双模式支持&lt;/strong&gt; - 原生支持经典和仿钉钉双模式&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;快速集成&lt;/strong&gt; - 可通过 jar 包快速集成设计器&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;广泛兼容&lt;/strong&gt; - 支持多种 ORM 框架和数据库&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🎯 功能全景&lt;/h2&gt; 
&lt;p&gt;&lt;img alt="功能思维导图" src="https://oscimg.oschina.net/oscnet//4b82123be783b0346de0e06f295de26a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 快速体验&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;演示地址&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.hhzai.top" target="_blank"&gt;http://www.hhzai.top&lt;/a&gt; &lt;strong&gt;账号密码&lt;/strong&gt;：admin/admin123&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;官方网站&lt;/strong&gt;：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwarm-flow.dromara.org" target="_blank"&gt;https://warm-flow.dromara.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;想要深入了解？观看我们的视频教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1AWRGYEEVr%2F" target="_blank"&gt;从零精通: 全流程开发与源码解读&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;立即升级到 Warm-Flow 1.8.0，体验全新的工作流设计之旅！&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366088/warm-flow-1-8-0</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366088/warm-flow-1-8-0</guid>
      <pubDate>Wed, 13 Aug 2025 01:04:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>wlnmp 一键安装包更新 250813</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;wlnmp 一键安装包 250813 更新内容如下：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span style="color:#000000"&gt;（更新）php8.1.33、php8.2.29、php8.3.23、php8.3.24、php8.4.10、php8.4.11、MySQL8.0.43、MySQL8.4.6&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;关于 wlnmp&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;从&lt;u&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;2019&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/u&gt;年初开始维护 wlnmp 一键安装包这个项目，起初只是为了在日常运维过程中，可以快速的部署 lnmp 服务。wlnmp 已支持国产龙蜥 AnolisOS、OpenCloudOS、欧拉 OpenEuler 系统等。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;wlnmp 一键安装包基于上游开源软件二次开发，可以在 x86_64、aarch64 架构的 Linux 系统上通过 wlnmp 提供的镜像源，快速部署 Nginx/Mysql/PHP 等常用软件，支持 php、MySQL 多个版本在同一系统中并存。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;PS：&lt;/strong&gt;wlnmp 就是一个第三方的源，通过二次开发封装，将一些常用的软件汇总到一起，方便用户使用安装为目的，从 2019 年至今，已开发持续更新了&amp;nbsp;&lt;strong&gt;7263&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;个 rpm 包，目前服务器的资源流量全部由 「&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.hsy.com%2F" target="_blank"&gt;火数云&lt;/a&gt;」 赞助支持。&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;PPS：&lt;/strong&gt;如果你有积极向上的开源软件，想要收录至&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmirrors.wlnmp.com%2F" target="_blank"&gt;wlnmp 源&lt;/a&gt;中，可以联系我，可以是成品 rpm 包，也可委托我这边进行打包，当然这一切都是免费的。&lt;/p&gt; 
&lt;div&gt;
 &lt;strong&gt;PPPS：&lt;/strong&gt;如您有其它软件、系统等其它商业定制需求可直接联系。
&lt;/div&gt; 
&lt;div&gt;
 &amp;nbsp;
&lt;/div&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#72c490"&gt;&lt;strong&gt;系统支持：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;Alibaba CloudLinux 2.1903/3&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;AlmaLinux 8.x/9.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;AnolisOS 7.x/8.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;CentOS 7.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;CentOS 8.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;&lt;/span&gt;OpenCloudOS 8.x/9.x&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦ OpenEuler 20.03&lt;/span&gt;(SP1~SP4)&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;OpenEuler 22.03&lt;/span&gt;(SP1~SP4)&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;OpenEuler 24.03&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;✦&amp;nbsp;RockyLinux 8.x/9.x&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;传统方式添加 wlnmp 镜像源，实现 yum/dnf 一键安装部署！&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;安装便捷，稳定更新，模块集成&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;span&gt;免费使用，为爱发电&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;安装使用见：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Finstall" target="_blank"&gt;install&lt;/a&gt;&lt;/p&gt; 
&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="background-color:#ffffff; color:#333333"&gt;更新日志可查看：&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Fchangelog" target="_blank"&gt;ChangeLo&lt;/a&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.wlnmp.com%2Fchangelog" target="_blank"&gt;g&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366084</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366084</guid>
      <pubDate>Wed, 13 Aug 2025 00:40:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>直播聊聊大模型外挂：RAG 技术</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;2020 年，Meta AI 提出了 RAG 概念，旨在解决&lt;strong&gt;大模型的两大瓶颈：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一是知识滞后：大模型基于预训练数据，无法获取训练数据之外的最新信息，如实时政策或企业私有文档。&lt;/p&gt; 
&lt;p&gt;二是幻觉风险：模型可能生成看似合理实则错误的内容，例如编造论文或数据。&lt;/p&gt; 
&lt;p&gt;RAG 通过「检索+生成」两个阶段来解决这些问题：首先动态地从外部知识库中检索相关信息，然后将这些信息作为上下文提供给大模型进行答案生成。这样不仅能够利用最新的外部知识，还能显著减少幻觉，并使得答案的来源可追溯，从而大幅提升回答的准确性和可靠性。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;尽管利用 RAG 能缓解大模型幻觉问题，但还做不到 100%。我们想知道，RAG 到底能发挥多大的作用呢？怎么判断 RAG 的效果好不好？向量化在 RAG 中的作用是什么？无向量 RAG 会是一种未来范式吗？目前有哪些 RAG 产品，各有什么优劣？······&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;8 月 19 日晚，开源中国将邀请 5 名技术专家，就 RAG 技术的发展与应用展开交流。&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;直播主题：&lt;/strong&gt;大模型外挂：RAG 技术&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;8 月 19 日周二 20:00-21:30&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;视频号 「OSC 开源社区」&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;直播嘉宾：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主持人：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;顾钧，杭州映云科技市场总监，上海开源信息技术协会副秘书长&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;讨论嘉宾：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;傅聪，Shopee（新加坡）资深算法专家，高性能检索算法 NSG、MAG 作者&lt;/li&gt; 
 &lt;li&gt;肖玉民，TorchV 联合创始人 &amp;amp; CTO&lt;/li&gt; 
 &lt;li&gt;祝海林，Idea 研究院 MoonBit AI 辅助编程工具工程师、AutoCoder 作者&lt;/li&gt; 
 &lt;li&gt;张颖峰，英飞流 InfiniFlow 联合创始人兼 CEO&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="923" src="https://oscimg.oschina.net/oscnet/up-de9003999691f6802a5effee93c0aa13f13.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;直播亮点&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;RAG 的概念、发展历史，与大模型、Agent 的关系&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 能多大程度解决幻觉问题？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;大模型自身幻觉减少后，RAG 是否还有存在必要？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;向量检索的关键作用，以及无向量 RAG 范式&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 开源项目推荐，以及市面上主流 RAG 产品的优缺点&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;RAG 效果评估标准、技术极限与未来&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;直播福利：&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;本次直播中，我们将有 5 轮抽奖，参与就有机会获得 OSC T 恤、马建仓蛇年公仔（限量版）、代码圣杯、马克杯、冰箱贴、前沿技术书籍等。立即扫码预约直播吧！&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img alt="up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" height="253" src="https://oscimg.oschina.net/oscnet/up-d0ddd08ceeff2b5526d3def6537a6ac649b.png" width="400" referrerpolicy="no-referrer"&gt;&lt;br&gt; &lt;br&gt; 我们还建了一个 AI 交流群，可以经进来唠唠嗑~&lt;/p&gt; 
 &lt;p&gt;&lt;img height="200" src="https://oscimg.oschina.net/oscnet/up-32d5360d0666b500c240202d47193824a56.png" width="200" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span style="color:#27ae60"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;【数智漫谈】&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;OSCHINA 视频号直播畅聊栏目【数智漫谈】，每期一个技术话题，三五位专家围坐，各抒己见，畅聊开源。给大家带来最新的行业前沿、最热门的技术话题、最有趣的开源项目、最犀利的思想交锋。如果你手上也有新点子、好项目，想要跟同行交流分享，欢迎联系我们，讲坛随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:center"&gt;&lt;img height="537" src="https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png" width="400" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3859945/blog/18688119</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18688119</guid>
      <pubDate>Tue, 12 Aug 2025 15:38:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>FastBuildAI，面向 AI 创业者设计的开源 AI 应用框架 1.0.0-beta.2 已经发布</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;FastBuildAI-面向 AI 创业者设计的开源 AI 应用框架 1.0.0-beta.2 已经发布。&lt;/p&gt; 
&lt;p&gt;此版本更新内容包括：&lt;/p&gt; 
&lt;p&gt;优化&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;优化前后台 UI 细节&lt;/li&gt; 
 &lt;li&gt;优化首屏加载速度&lt;/li&gt; 
 &lt;li&gt;优化 docker 部署内存消耗&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;修复&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;若干已知问题&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看：&lt;a href="https://gitee.com/FastbuildAI/FastbuildAI/releases/1.0.0-beta.2"&gt;https://gitee.com/FastbuildAI/FastbuildAI/releases/1.0.0-beta.2&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366043</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366043</guid>
      <pubDate>Tue, 12 Aug 2025 12:19:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>License Manager 发布首个框架版本 v0.1.0 —— 开源现代化软件授权管理解决方案</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;h1&gt;License Manager 发布首个框架版本 v0.1.0 —— 开源现代化软件授权管理解决方案&lt;/h1&gt; 
&lt;h2&gt;填补市场空白，解决授权管理痛点&lt;/h2&gt; 
&lt;p&gt;随着软件产业的快速发展，越来越多的开发者和企业面临着软件授权管理的挑战。&lt;/p&gt; 
&lt;p&gt;传统的授权方案要么过于复杂，要么缺乏灵活性，难以满足现代软件分发的需求。&lt;/p&gt; 
&lt;p&gt;License Manager 的诞生，正是为了填补这一空白。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「我们在实际项目中发现，现有的授权管理工具要么收费昂贵，要么功能单一，很难找到一个既开源又功能完整的解决方案。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;—— 项目负责人&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;因此，团队决定打造一个现代化、易用、完全开源的授权管理系统。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1284" src="https://oscimg.oschina.net/oscnet/up-fc77b60f8628c46a3ec3d649dc3aeb4f642.png" width="2552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1284" src="https://oscimg.oschina.net/oscnet/up-1b4184682c9c5c5c8804da1373e32058617.png" width="2552" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;技术先进，架构清晰&lt;/h2&gt; 
&lt;p&gt;License Manager 采用当前主流技术栈：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;后端：Go 语言构建，高性能 &amp;amp; 高并发&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;前端：Vue 3 + TypeScript，现代化交互体验&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署：支持 Docker 一键部署，降低运维成本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;国际化：内置多语言支持&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;系统架构采用，前后端分离，与 RESTful API 设计，方便第三方系统集成。&lt;/p&gt; 
&lt;p&gt;同时支持 JWT 认证，和 细粒度权限控制，保障系统安全。&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;开放生态，社区驱动&lt;/h2&gt; 
&lt;p&gt;License Manager 采用 GPL-3.0 协议，鼓励社区参与和商业应用。&lt;/p&gt; 
&lt;p&gt;源代码和文档已在 Gitee 全面开放。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「开源不仅是代码的开放，更是思维的开放。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;—— 项目团队&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h2&gt;发展规划&lt;/h2&gt; 
&lt;p&gt;根据路线图，后续版本将陆续推出：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;✅ 客户管理模块&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 核心授权算法实现&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 硬件指纹绑定功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ API 安全增强&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;✅ 实时监控与统计分析&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;适用场景包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;软件开发商的产品授权管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;企业内部软件管理&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SaaS 服务权限控制&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;快速体验&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
git clone https://gitee.com/cedar-v/license-manager.git

cd license-manager

docker compose up -d --build

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;系统默认运行在 &lt;a href="https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Flocalhost%3A18080" target="_blank"&gt;http://localhost:18080&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;默认管理员账号：&lt;span style="color:#efb080"&gt;admin&lt;/span&gt;&lt;span style="color:#e394dc"&gt; / &lt;/span&gt;&lt;span style="color:#efb080"&gt;admin123&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;项目地址&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;源码仓库：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://gitee.com/cedar-v/license-manager"&gt;https://gitee.com/cedar-v/license-manager&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;关于 License Manager&lt;/h2&gt; 
&lt;p&gt;License Manager 是一个专注于软件授权管理的开源项目，旨在为开发者和企业提供完整的许可证管理解决方案。&lt;/p&gt; 
&lt;p&gt;欢迎开发者贡献代码、提交反馈，共同完善项目！&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366037</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366037</guid>
      <pubDate>Tue, 12 Aug 2025 11:50:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>用户吐槽 Firefox 新 AI 功能「臃肿」：导致 CPU 占用飙升、又耗电又卡</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span&gt;近期，Mozilla 在 Firefox 141 版本中引入了 AI 功能，包括 AI 标签分组和 AI 聊天机器人。然而，这一更新却引发了大量用户的不满。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;用户普遍反映，启用这些 AI 功能后，浏览器出现了一个名为 "Inference" 的进程，占用大量 CPU 资源，导致电脑卡顿、电池续航时间大幅缩短。例如，Reddit 用户 u/st8ic88 表示，Firefox 一打开，CPU 占用就飙升，电池电量迅速耗尽，而罪魁祸首就是这个 "Inference" 进程。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-e9493780e2b2beec826dc0ef0ffc57bc6d0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-99f9b4c534089ece948b58fafd004bf713d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;用户批评 Mozilla 盲目跟风，将浏览器变成了 "AI 游乐场"，违背了浏览器本应简单高效的原则。 此外，用户发现无法直接终止 "Inference" 进程，否则会导致 Firefox 崩溃并重启。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;虽然 Mozilla 的本意是通过本地 AI 模型保护用户隐私，但实际效果却适得其反。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;如果用户想要关闭这些功能，可以通过浏览器的高级设置来禁用这些功能，在新标签页中输入 about:config，接受风险警告，并通过搜索栏找到相关设置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366029</guid>
      <pubDate>Tue, 12 Aug 2025 11:07:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>深开鸿携手 Arm 成立开源鸿蒙 Arm SIG 组</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;深开鸿&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F2-DXuJ-lKbQyE4DqxIrG6g" target="_blank"&gt;宣布&lt;/a&gt;，其与全球半导体 IP 巨头 Arm 公司联合发起的开源鸿蒙 Arm SIG（Special Interest Group）正式通过 OpenHarmony 项目管理委员会（PMC）评审，深开鸿获任副组长单位。&lt;/p&gt; 
&lt;p&gt;这一合作标志着开源鸿蒙生态在 ARM 架构适配方面迈出关键一步，将为产业带来更完善的芯片支持方案。&lt;/p&gt; 
&lt;p&gt;目前已有 6 家芯片及板卡企业加入开源鸿蒙 Arm SIG。该 SIG 组将聚焦 ARM 架构芯片的深度优化，联合产业链伙伴共同解决 ARM 架构芯片在开源鸿蒙系统中的关键性能问题，推进从内核层、系统服务层到框架层的全栈性能提升：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;内核层：优化任务调度与内存管理，提升实时性表现&lt;/li&gt; 
 &lt;li&gt;系统服务层：增强异构计算能力，释放多核芯片潜力&lt;/li&gt; 
 &lt;li&gt;框架层：精简 API 调用链路，降低应用开发门槛，并加强 AI 推理框架&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;深开鸿表示，ARM 架构作为移动生态的基石，在全球范围内具有广泛的影响力。此次 SIG 组的成立，将显著提升开源鸿蒙在 ARM 芯片上的运行效率，为开发者提供更加友好、完善的工具链支持。这不仅有助于降低开发成本，提高开发效率，还将为未来更多高性能、低功耗的开源鸿蒙终端设备的落地奠定基础。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366028</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366028</guid>
      <pubDate>Tue, 12 Aug 2025 10:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Debian GNU/Hurd 2025 发布</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Debian GNU/Hurd 2025 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flists.debian.org%2Fdebian-hurd%2F2025%2F08%2Fmsg00038.html" target="_blank"&gt;已正式发布&lt;/a&gt;，该版本是基于 Debian 13.0 「Trixie」 稳定版制作的快照，虽非官方 Debian 稳定版，但它是官方认可的 GNU/Hurd 架构移植版本。&lt;/p&gt; 
&lt;p&gt;Debian GNU/Hurd 2025 提供了 i386 和 amd64 两个架构的安装 ISO（NETINST 版本）与预装磁盘镜像，方便用户在如 QEMU 的虚拟环境中体验安装与使用。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0813/183901_xqiF_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;主要亮点与改进一览&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;64 位支持完全实现&lt;/strong&gt;：该版本在 64 位架构上实现了与 i386 架构相当的包覆盖率，甚至略有优势——部分软件仅提供 64 位版本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;采用 Rump 层的用户态磁盘驱动&lt;/strong&gt;：通过 NetBSD Rump 层在用户空间支持磁盘驱动器，这一机制用于实现对 USB 磁盘和 CD-ROM 的支持。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;使用 xattr 默认记录翻译器&lt;/strong&gt;：这使得可以更顺利地从其他操作系统（如使用 mmdebstrap 的系统）中进行引导与安装。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rust 已移植至 Hurd&lt;/strong&gt;：这为未来 Rust 生态在 GNU/Hurd 上的应用打下了基础。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;改进支持&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;启用了对 USB 磁盘与光驱的原生支持（通过 Rump）&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;SMP（多核）支持包已可用并能正常工作&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;控制枱现使用 xkb 支持键盘布局，同时支持 multiboot 引导提供的 framebuffer&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;新增对 acpi、rtc、apic、hpet 等硬件功能的支持&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文档与修复&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;改善了文档内容&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;修复了多个问题，如中断请求（IRQ）、NFSv3、libports、管道边缘情况（pipes corner cases）等&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366026</guid>
      <pubDate>Tue, 12 Aug 2025 10:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 企业扎堆赴港上市</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;在全球人工智能（以下简称「AI」）竞赛加速的背景下，香港市场正成为 AI 企业 IPO 的热门选择。Wind 资讯数据显示，截至 8 月 12 日记者发稿，已递交港股 IPO 申请的企业有 213 家，其中约 50 家企业为 AI 企业。&lt;/p&gt; 
&lt;p&gt;与此同时，港股 AI 板块表现亮眼。截至 8 月 12 日收盘，恒生人工智能主题指数今年以来累计涨幅达 30.69%。进一步梳理发现，目前向港交所递交招股书的 AI 企业普遍具备深厚的技术积累和强大的融资能力，但其财务表现分化明显，仅少数企业实现盈利，多数仍处于亏损状态。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;政策红利持续&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;为何香港市场成为 AI 企业上市的首选地？政策红利、资本热度、行业需求形成多重合力。&lt;/p&gt; 
&lt;p&gt;AI 企业纷纷赴港 IPO 的背后，是港交所上市规则第 18C 章对人工智能企业上市门槛的持续放宽。2023 年，港交所推出特专科技上市机制第 18C 章，将 AI 企业纳入支持范围。2024 年，港交所下调第 18C 章的市值门槛，将已商业化企业的市值门槛从 60 亿港元降至 40 亿港元，未商业化企业从 100 亿港元降至 80 亿港元，以适配不同发展阶段的 AI 企业。&lt;/p&gt; 
&lt;p&gt;今年 5 月份，港交所再次推出「科企专线」，允许第 18A 章、第 18C 章企业保密递表，进一步提升保密性和审核效率，鼓励 AI 等新兴企业进入港股市场。&lt;/p&gt; 
&lt;p&gt;在政策的大力支持下，企业纷纷加快赴港 IPO 的步伐，进一步拓宽了融资渠道。例如，深圳海清智元科技股份有限公司（以下简称「海清智元」）计划将募集资金用于技术研发、产能扩建及全球化布局。诺比侃人工智能科技（成都）股份有限公司（以下简称「诺比侃」）计划将募集资金用于加强核心技术研究、建设研发中心和新总部基地、寻求战略投资及收购机会等。&lt;/p&gt; 
&lt;p&gt;A 股市场的 AI 企业同样加速了赴港上市的进程。澜起科技股份有限公司、兆易创新科技集团股份有限公司等已向港交所递交了 IPO 申请书。&lt;/p&gt; 
&lt;p&gt;沙利文大中华区执行总监周明子在接受《证券日报》记者采访时表示，一些专注于前沿人工智能算法研究的初创公司，港股市场可以为其提供融资和发展的机会。&lt;/p&gt; 
&lt;p&gt;与此同时，在一级市场上，AI 领域投融资热度持续升温。IT 桔子数据显示，今年上半年国内 AI 领域一级市场融资事件达 345 笔，较去年同期增加 88 笔，预估总融资金额达到 300.66 亿元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;递表企业覆盖多个领域&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;拟 IPO 的 AI 企业覆盖多个细分领域，技术路线也呈现多元化。当前已递表的企业主要集中在 AI 应用层，涉及 AI 制药、AI 辅助诊疗、AI 机器人等细分领域。在 AI 技术层面，以 AI 大模型公司为主；而在 AI 基础层面，主要是 AI 芯片供应商等。&lt;/p&gt; 
&lt;p&gt;对于部分 AI 应用层企业而言，盈利模式初现端倪，商业化路径也逐步清晰。例如，8 月 6 日递交港股 IPO 申请的海清智元，专注于多光谱 AI 技术，2024 年净利润达到 4041 万元，实现扭亏为盈。2025 年第一季度继续盈利，净利润为 1414.4 万元。尽管其已实现盈利，但市场仍关注其技术落地的持续性和供应链的稳定性。&lt;/p&gt; 
&lt;p&gt;尽管 AI 技术层企业数量较少，但仍受资本青睐。大模型企业滴普科技股份有限公司在 IPO 前获得红杉资本等多轮投资；诺比侃提供基于 AI 行业模型的软硬一体化解决方案，涵盖智能化监测、检测和运维等服务，目前公司已完成 6 轮融资。&lt;/p&gt; 
&lt;p&gt;此外，年内在港上市的 AI 公司认购火爆。「AI+机器人企业」北京极智嘉科技股份有限公司（以下简称「极智嘉」）、「AGI 技术企业」云知声智能科技股份有限公司（以下简称「云知声」）、「无人驾驶系统研发的 AI 服务企业」博雷顿科技股份公司的公开认购倍数分别达到 133.62 倍、91.66 倍、198.72 倍，申购人数均超万人，投资者参与意愿强烈。&lt;/p&gt; 
&lt;p&gt;「AI 行业正呈现百花齐放的格局。」中金公司投资银行部董事总经理、TMT 组执行负责人楼欣宇表示，所有的软件、应用生态都值得用 AI 重构一遍，背后蕴含着万亿元级别的机遇。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;商业化难题待解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;港股市场对 AI 企业的认可度较高。以 AI 软件公司商汤科技为例，该公司凭借多模态大模型技术的优势，在港股上市后市值持续攀升，目前港股市值已超过 600 亿港元，稳居港股 AI 板块前列。&lt;/p&gt; 
&lt;p&gt;不仅商汤科技如此，今年 6 月 30 日上市的云知声，凭借语音大模型技术的积累，也获得了资本巨头的青睐。上市首日，其股票最高价较发行价涨幅超过 50%，目前最新市值已突破 400 亿港元。&lt;/p&gt; 
&lt;p&gt;然而，尽管资本热捧，AI 企业估值与商业化能力的错配问题也日益凸显。&lt;/p&gt; 
&lt;p&gt;一些企业虽在技术研发上领先，但商业化路径仍未打通。例如，某 AI 企业连续 6 年亏损，2025 年第一季度数据显示，公司营业收入同比增长 168.23%，但净利润仍为负值。&lt;/p&gt; 
&lt;p&gt;另有一些 AI 企业因研发投入较高，上市后迅速启动再融资以补充现金流。截至 8 月 12 日，至少有 11 家 AI 公司进行过一次或多次再融资。&lt;/p&gt; 
&lt;p&gt;商汤科技上市后累计再融资规模约 72.85 亿港元，用于打造 AI 云、智能硬件的商业化应用及大模型衍生产品的开发等。&lt;/p&gt; 
&lt;p&gt;去年 6 月份在港股上市的 AI 制药企业晶泰控股，是首家根据第 18C 章规则在香港联交所上市的特专科技公司。Wind 资讯数据显示，截至 8 月 12 日，晶泰控股再融资规模为 32.18 亿港元，已超过 IPO 募资额。&lt;/p&gt; 
&lt;p&gt;「AI 应用商业化进程已进入加速阶段。」中银证券首席策略分析师王君认为，大模型能力初步支撑 AI 商业化的拐点，部分垂类 AI 应用的商业模式已率先跑通。在港股市场中，AI 编程、AI 广告、AI 多模态等赛道的商业模式正逐步落地。&lt;/p&gt; 
&lt;p&gt;未来，随着资本的持续涌入，AI 企业上市队伍或将进一步扩容。然而，或许只有真正找到商业化路径的企业，才能在这场竞赛中赢得长跑。（证券日报）&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366023</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366023</guid>
      <pubDate>Tue, 12 Aug 2025 10:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源 3D 建模与动画软件 Blender 将推出原生 iPad 版本</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Blender &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.blender.org%2F2025%2F07%2Fbeyond-mouse-keyboard%2F" target="_blank"&gt;透露&lt;/a&gt;正在开发一款原生的 iPad 版开源 3D 创作套件，包含专为依赖平板电脑的艺术家设计的全功能多点触控界面。&lt;/p&gt; 
&lt;p&gt;据介绍，为适配触控与 Apple Pencil 操作，Blender iPad 版采用全新的界面设计，包括单窗口全屏布局、浮动工具面板、图标化侧边栏、触控友好的轮盘菜单，以及多指手势与快捷操作提示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-77d2b784d18da5e1187f3c784bef19dc243.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;（Blender for iPad 渲染图）&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;团队还表示，这些优化不仅服务于移动用户，也会反哺到桌面版，例如 Quick Favorites 编辑器和可切换 UI 元素等功能已出现在 Blender 5.0 alpha 中。&lt;/p&gt; 
&lt;p&gt;首个技术演示将于 8 月 10–14 日在温哥华的 SIGGRAPH 2025 上公开亮相，随后在阿姆斯特丹的 Blender Conference 2025（9 月 15–19 日）进一步展示。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0c2679723a74cd0b9b5ebc5868e0986c968.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开发工作正在进行中，Blender 社区贡献者也被邀请参与改进触控交互、iOS 文件集成及性能优化等环节。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;相关来源&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://devtalk.blender.org/t/blender-and-tablets/41558&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.creativebloq.com/3d/blender-on-ipad-is-finally-happening-and-it-could-be-the-app-every-artist-needs&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;https://www.macrumors.com/2025/07/25/blender-ipad-pro-app-in-development&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366022</guid>
      <pubDate>Tue, 12 Aug 2025 10:24:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>SelectDB x 同辕开发：在 ARM 架构下实现 25% 分析性能提升</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;strong&gt;近日，北京飞轮数据科技有限公司（以下简称「飞轮科技」）旗下现代化数据仓库 SelectDB 完成同辕开发深度适配，正式获得 Kunpeng Native 测试认证证书。&lt;/strong&gt; 该认证表明 SelectDB 深度兼容鲲鹏芯片，可实现高效部署。通过与同辕开发协同创新，SelectDB 实时分析、湖仓一体、存算分离等核心能力，可针对性解决海量数据处理慢、实时决策延迟、运维复杂等痛点，助力金融、制造、互联网等行业用户快速释放数据价值。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="鲲鹏技术认证证书.JPEG" src="https://oscimg.oschina.net/oscnet//70887b2266176fd647936cf0cce5eddd.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;北京飞轮数据科技有限公司创立于 2022 年，成立以来，飞轮科技在积极投身 Apache Doris 开源社区建设的同时，自主研发了现代化实时数据仓库 SelectDB，面向全球提供多种部署形态的实时数据仓库产品 SelectDB 与相关解决方案，满足大规模实时数据场景下的极速查询分析需求，为工业界构建全新的实时数据分析通用标准。目前，飞轮科技已服务全球 5000 余家金融、电信、制造、能源、汽车、物流、政务等中大型企业，并基于丰富的行业经验，沉淀了实时报表、用户画像、数据湖查询、日志分析等成熟的解决方案。&lt;/p&gt; 
&lt;p&gt;随着企业实时数据分析需求爆发式增长，传统数据仓库在应对海量高并发查询、多源异构数据分析及兼容要求时面临巨大挑战。&lt;strong&gt;为突破性能瓶颈并构建自主可控的分析体系，飞轮科技联合鲲鹏启动深度技术协同，基于其全栈生态进行深度优化，并进行了代码开发、门禁配置及功能、性能测试。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SelectDB 在原有架构和同辕开发 ARM 架构下性能对比 .JPEG" src="https://oscimg.oschina.net/oscnet//17baeeba0727583104d67e8697daf1fa.jpeg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;测试数据表明，&lt;strong&gt;SelectDB 完全兼容同辕开发架构，在单机 1FE + 1BE 环境下，在从原有架构迁移到鲲鹏 ARM 平台之后，实现了 25% 的显著速度提升。&lt;/strong&gt; 在同等资源配置下，SelectDB 结合同辕开发，能够帮助企业分析效率跃升、海量数据亚级极速分析，筑牢实时决策基石。&lt;/p&gt; 
&lt;p&gt;作为鲲鹏计算产业生态重要伙伴，未来，SelectDB 将进一步强化与鲲鹏生态的深度协同，持续提升兼容性与开放性，深化联合解决方案与资源共享，并在同辕开发架构中持续优化分析性能，携手夯实企业级实时数据分析底座，驱动千行百业数智化转型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366021</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366021</guid>
      <pubDate>Tue, 12 Aug 2025 10:22:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Blender 原生支持 Windows 11 on Arm</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.blender.org%2F2025%2F08%2Fblender-for-windows-on-arm%2F" target="_blank"&gt;根据 Blender 的开发公告&lt;/a&gt;，自一年多前，Blender 团队联合微软、Linaro 与高通启动了将 Blender 移植至支持 Windows ARM64 架构（WoA）的开发计划，得益于高通作为 Blender Development Fund 的「大力支持者」（Patron 级别），项目获得了资源雄厚的推动。&lt;/p&gt; 
&lt;p&gt;&lt;img height="592" src="https://static.oschina.net/uploads/space/2025/0813/180440_YQN3_2720166.png" width="1572" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Blender 4.3 是首个正式支持 WoA 架构的版本，Blender 开发团队介绍称，当前重点是引入 Vulkan 渲染后端，以显著提升 EEVEE 视窗（viewport）性能，&lt;/p&gt; 
&lt;p&gt;关键优化目标包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;着色器（shader）性能优化，提升 UI 流畅度；&lt;/li&gt; 
 &lt;li&gt;利用 Adreno GPU 架构的瓦片渲染（tiling）机制，加快视窗刷新速度&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载地址：&lt;em&gt;https://builder.blender.org/download/daily/archive/&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366020/blender-for-windows-on-arm</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366020/blender-for-windows-on-arm</guid>
      <pubDate>Tue, 12 Aug 2025 10:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>消息称 Altman 将联合创办脑机接口公司，挑战马斯克的 Neuralink</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;span style="color:#000000"&gt;英国&lt;/span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F04484164-724e-4fc2-92a2-e2c13ea639bd" target="_blank"&gt;《金融时报》报道&lt;/a&gt;&lt;span style="color:#000000"&gt;称，Sam Altman 正在与他人共同创立一家名为 Merge Labs 的脑机接口初创公司，并正在为其筹集资金，资金可能主要来自 OpenAI 的风险投资团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这家初创公司的估值预计为 8.5 亿美元。一位知情人士告诉 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F08%2F12%2Fsam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink%2F" target="_blank"&gt;TechCrunch&lt;/a&gt;，谈判仍处于初期阶段，OpenAI 尚未承诺参与，因此条款可能会有所调整。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="194" src="https://oscimg.oschina.net/oscnet/up-a994c9873892e90803fc1c1aca1ac9c5b5f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息指出，Merge Labs 还与 Alex Blania 合作，后者运营着 Tools for Humanity（原名 World）—— Altman 的眼球扫描数字身份识别项目，该公司称其「允许任何人验证他们的人类身份」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Merge Labs 将与 Elon Musk 的 Neuralink 展开竞争，后者正在开发用于植入大脑的计算机接口芯片。马斯克于 2016 年创立了 Neuralink（尽管直到 2017 年才为人所知），目前该公司已取得重大进展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Neuralink 目前正在对患有严重瘫痪的患者进行临床试验。其目标是让患者能够通过思维控制设备。该公司于 6 月以 90 亿美元的估值完成了 6 亿美元的 E 轮融资。 Neuralink（或许还有 Merge Labs）或许会彻底改变人类与科技的互动方式。有些人甚至会说，他们的技术或许能带领人类走向「奇点」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366013</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366013</guid>
      <pubDate>Tue, 12 Aug 2025 09:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Pika 发布音频驱动的视频生成模型</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;Pika&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fpika_labs%2Fstatus%2F1954935844936024476"&gt;发布&lt;/a&gt;了一款突破性的音频驱动视频生成模型（Audio-Driven Performance Model），能近乎实时地生成具有逼真表情和完美唇形同步的视频，速度提升 20 倍且成本大幅降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0813/174657_uvNx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，该模型支持任意长度和风格的视频制作，并能在 6 秒或更短的时间内完成高清视频的生成。新模型在速度上提升了 20 倍，同时成本也大幅降低。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0813/174616_eifl_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pika 以生成逼真视频的 AI 技术而知名。而据公开信息，郭文景是 Pika Labs 的联合创始人与 CEO。她与联合创始人兼 CTO Chenlin Meng 均为斯坦福大学 AI Lab 博士生，在 2023 年 4 月从斯坦福辍学、创立了 Pika Labs，致力于开发基于文本生成短视频的 AI 工具。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0723/144812_Lkpt_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Pika 的&lt;a href="https://www.oschina.net/news/361912"&gt;核心产品&lt;/a&gt;为「文生视频」模型，号称用户一句话描述，就能生成风格多样的动画短视频。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366012</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366012</guid>
      <pubDate>Tue, 12 Aug 2025 09:51:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>v0.dev 更名为 v0.app，上线 Agent 模式</title>
      <description>&lt;div class="content"&gt;
                                                                                            &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fvercel.com%2Fblog%2Fv0-app" target="_blank"&gt;根据 Vercel 官方公告&lt;/a&gt;，Vercel 旗 AI 前端开发工具 v0.dev 现已更名为 v0.app，并正式上线 Agent 模式，旨在成为面向所有人的 AI 构建器。用户只需一个提示，即可快速生成并部署包含 UI、内容、后端和逻辑的完整应用程序。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0813/173740_ovdx_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;v0.app 的 Agent 模式赋予其研究、推理和规划能力，能够与用户协作或独立完成端到端工作。v0.app 通过 Agentic 智能自动规划、调整和改进，显著减少了提示次数。目前，v0.app 为每日为前 10 万用户提供免费限时额度。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1856" src="https://static.oschina.net/uploads/space/2025/0813/173924_HXe8_2720166.png" width="3360" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;访问&lt;em&gt;https://v0.app/&lt;/em&gt;体验&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/366010</link>
      <guid isPermaLink="false">https://www.oschina.net/news/366010</guid>
      <pubDate>Tue, 12 Aug 2025 09:41:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
