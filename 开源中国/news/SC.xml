<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-最新资讯</title>
        <link>https://www.oschina.net/news/project</link>
        <atom:link href="http://rsshub.app/oschina/news" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-最新资讯 - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)</description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        <language>en</language>
        <lastBuildDate>Mon, 22 Jul 2024 15:16:00 GMT</lastBuildDate>
        <ttl>180</ttl>
        <item>
            <title>开源日报 | 谷歌淘汰 goo.gl 短链服务；Llama3 开源模型被玩出花了；关于开源芯片的观点文章；如何写出万人唾骂的软件；OpenAI 正与博通谈判开发 AI 芯片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.22&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available&quot;&gt;谷歌将于 2025 年彻底淘汰 goo.gl 短链服务&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Google URL Shortener 是谷歌在 2009 年推出的一项长网址缩短服务，将长链接以 https://goog.gl/* 的形式输出为更短的链接。2018 年，谷歌宣布淘汰和过渡 Google URL Shortener 服务，转而引导用户使用 Firebase Dynamic Links (FDL)；此举意味着其不再接受新的网址缩短服务，但会继续为现有网址提供服务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f582b660e075dbd05b28f5b23f7a2a5dcf2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;时至今日，谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;将于 2025 年彻底关闭 Google URL Shortener 服务。&lt;/span&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;「任何使用 Google URL Shortener 构建的 https://goo.gl/* 形式链接的开发人员都将受到影响，并且这些 URL 在 2025 年 8 月 25 日之后将不再返回响应。」&lt;/span&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F296813&quot; target=&quot;_blank&quot;&gt;OpenAI 正与博通谈判，或启动 7 万亿美元 AI 芯片计划&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;据 The Information 报道， OpenAI 已经与博通进行了会谈，讨论开发新人工智能芯片的计划。&lt;/p&gt; 
&lt;p&gt;据悉，OpenAI 目前正在探索制造自己的人工智能芯片的可能性。此举不仅能有效整合软件和硬件，还有助于缓解当前人工智能芯片短缺的问题。此外，据说 OpenAI 正在积极招募前谷歌员工，希望利用他们在开发 Tensor 处理器方面的经验和专业知识来制造自己的 AI 芯片。报道强调，OpenAI 开发出能与英伟达相媲美的 AI 服务器芯片的可能性很小，需要多年的研发才能取得显著成果。&lt;/p&gt; 
&lt;p&gt;此前，业内人士指出，OpenAI CEO Sam Altman 制定了雄心勃勃的人工智能芯片发展计划，旨在筹集 7 万亿美元资金，改造全球半导体产业生态系统，推动通用人工智能产业的发展。&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F296808&quot; target=&quot;_blank&quot;&gt;苹果开源小模型 DCLM-Baseline-7&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;据 Venturebeat 报道，苹果公司的研究团队在 Hugging Face 上发布了一系列开放的 DCLM 模型。&lt;/p&gt; 
&lt;p&gt;该系列包括两个主要模型：一个有 70 亿个参数，另一个有 14 亿个参数。这两个模型在基准测试中的表现都相当不错，尤其是较大的那个模型--其性能超过了 Mistral-7B，并正在接近其他领先的开放模型，包括 Llama 3 和 Gemma。&lt;/p&gt; 
&lt;p&gt;值得注意的是，随着模型权重、训练代码和预训练数据集的发布，该项目真正实现了开源。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fapple%2FDCLM-7B&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/apple/DCLM-7B&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fadb_w9yycyfZRR2iW86KNg&quot; target=&quot;_blank&quot;&gt;CrowdStrike 造成 850 万台 Windows 蓝屏&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;7 月 19 日，美国安全软件 CrowdStrike 更新出错，导致 Windows 电脑大规模蓝屏，引发全球多个地区的公共服务陷入瘫痪。据悉，多国的航空、铁路、银行、企业、媒体、酒店等多领域因此次 Windows 系统崩溃宕机，连新能源产业链生产也收到了影响。&lt;/p&gt; 
&lt;p&gt;微软官方发布博文称，CrowdStrike 的更新影响了 850 万台 Windows 设备，约占 Windows 设备总数的 1%。虽然百分比很小，但对经济和社会造成的广泛影响反映了无数运营许多关键服务的企业使用 CrowdStrike 的事实。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-bc394b9cb0d0d35fc70ee8d22d8fff39ab5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1233486457%2FOoyK2goO3&quot; target=&quot;_blank&quot;&gt;Llama3 开源模型被玩出花了&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     Llama3 开源模型被玩出花了，最近好有几个基于 Meta Llama3 的优化项目，都说性能比肩 GPT-4o 级别。
     &lt;br&gt; 一个是 Groq（就是做专有 LPU 芯片的那家）的 Llama-3-Groq-Tool-Use Model，说是这个基于 Llama3 的完全微调，在 BFCL（伯克利函数调用）榜上排名第一，击败所有其他型号，包括 Claude Sonnet 3.5、GPT-4 Turbo、GPT-4o 和 Gemini 1.5 Pro 等专有型号。它的训练特色是，不使用任何用户数据，只使用合成数据。
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;高飞&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1686707751%2FOoD1MqPbd&quot; target=&quot;_blank&quot;&gt;一篇关于开源芯片的观点文章&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;p&gt;阐述开源芯片技术体系的三个层次：&lt;/p&gt; 
    &lt;p&gt;L1—开放指令集：任何人都可以免费获取指令集手册，无需授权即可设计与实现处理器芯片。RISC-V 属于这个层次。&lt;/p&gt; 
    &lt;p&gt;L2—开源设计实现：处理器芯片的微架构设计文档和源代码实现均开源，可自由获取。香山属于这个层次。&lt;/p&gt; 
    &lt;p&gt;L3—开源工具：处理器芯片的设计与实现过程中需要使用工具开源。开发香山的敏捷开发平台（Minjie）属于这个层次。&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;包云岗&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2056277053%2FOoCaYEdzk%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;梳理一下英特尔事件的发展过程&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;intel 的 13/14 代崩溃问题已经酝酿了好久了，可能有新观众不知道到底这几个月发生了什么，这里列出一个粗略的时间线。&lt;/p&gt; 
   &lt;p&gt;2023 年中起便有零零星星在论坛有用户反馈 intel 的高端 CPU 出现必须要降频才能保证游戏不出现崩溃报错的现象，有一些用户通过 RMA 向 intel 调换了新的 CPU 后回复正常。&lt;/p&gt; 
   &lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62c0bba966608f88d610ede05b0c973b579.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
   &lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.chiphell.com%2Fthread-2621606-1-1.html&quot; target=&quot;_blank&quot;&gt;https://www.chiphell.com/thread-2621606-1-1.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;凌晨刚醒&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1481944214%2FOoGsxuqz4&quot; target=&quot;_blank&quot;&gt;中国要为奠定理论系统做准备了&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;今天人类信息技术的发展，已经进入了一个全新的时代，信息的采集，信息的存储，信息的传输，信息的加工，信息的利用，都和香农的时代发生了巨大的变化，今天需要逐渐形成新的信息理论，这给王成录这样的人留下了很多机会。他们在一线已经做出了世界一流的产品，对于操作系统的理解，早就不是一个单机的管理与驱动，而是要把万物都连接起来，用一个系统整合众多的能力，把信息的一切都包容其中。&lt;/p&gt; 
  &lt;p&gt;鸿蒙系统不仅是中国有了一个自己的操作系统，在安全性有了巨大提升，相对于其他的系统，鸿蒙系统远远超出了传统系统的思维，把 PC、平板、手机、手表和众多的智能产品整合起来，这需要全新的理论来做支撑，这个事情就应该有王成录这样的人来做。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;飞象网项立刚&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrL_C32cKijrAyx11UfSNBg&quot; target=&quot;_blank&quot;&gt;如何写出万人唾骂的软件 - 史上最大 Windows 蓝屏事故分析&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;在这次事故中，850 多万台 Windows 电脑的用户没有选择 - 在微软的许可下，CrowdStrike 强行自动升级了他们的系统配置文件，结果悲剧了。&lt;/p&gt; 
  &lt;p&gt;尽管升级到最新的防病毒软件可以增强系统安全性，但这也可能影响系统的稳定性，所以这是一个需要权衡轻重的选择。对于不同的用户，安全性和稳定性的相对重要程度是不一样的。比如，爱冒险喜欢尝鲜不怕 Z turn 的同学可以选择第一时间更新，911 电话中心可能应该等新版本被一定数量用户验证后再更新。 微软和 CrowdStrike 凭什么替所有人做出一刀切的选择？&lt;/p&gt; 
  &lt;p&gt;是时候把选择权交给用户了。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;老万故事会&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2Fv002AOUyL303BR7jE3f5Fy1ZLH9l8F9exEuvXePzty1jy4I__&quot; target=&quot;_blank&quot;&gt;微软蓝屏事故背后：一个小文件是如何让全球计算机瘫痪的？&lt;/a&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;令人难以置信的是，一个很小的文件 (专家称只够容纳一个网页图像) 居然导致了世界上最大的 IT 中断事故。这个名为「C-00000291*.sys」的文件隐藏在 CrowdStrike 的 Falcon sensor 安全产品更新中。该问题文件在微软公司的 Windows 操作系统中引发了一个错误，导致计算机无法正常工作，并触发了可怕的「蓝屏死机」。&lt;/p&gt; 
   &lt;p&gt;这一事件以前所未有的规模暴露了全球 IT 系统的脆弱性，并凸显出如此多的组织和个人依赖于少数几家科技公司存在的危险性。如果其中一家公司出现故障或遭到黑客攻击，其后果可能波及全球经济的大片领域。微软凭借其 Windows 操作系统主导了个人电脑业务，而 CrowdStrike 已成为数千家公司和组织的首选供应商，后者希望保护其最重要系统免受网络攻击。&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;- &lt;strong&gt;凤凰网科技&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn807805201&quot; target=&quot;_blank&quot;&gt;阿里巴巴发布 2024 年 ESG 报告：AI 前沿科技应用于医疗、助老、助残领域&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;在 ESG 战略方向的指引下，阿里巴巴进一步深化 ESG 治理，成效显著。报告指出，ESG 的核心是围绕如何成为一家更好的公司。过去一年，阿里巴巴集团自身运营净碳排放和价值链碳强度继续实现「双降」，平台生态减排实现显著提升；将科技创新力量以及平台能力服务于无障碍、医疗、乡村、适老化等领域，并取得了不错的进展，医疗 AI 胰腺癌早筛项目落地、高德轮椅导航持续扩城、乡村特派员深入更多县域助力乡村建设；并深化了公司 ESG 治理架构。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;金融界&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMjM5NDE0MjI4MA%3D%3D%26mid%3D2656320355%26idx%3D1%26sn%3D4cbf1a71dc38a150a56b3884624f326b%26scene%3D0&quot; target=&quot;_blank&quot;&gt;应对 VMWare 政策之变，还有比虚拟化替换更重要的事&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;随着企业业务和应用系统的多元化发展，除了虚拟化技术之外，容器、公有云、私有云、超融合、裸金属等多种技术架构应运而生，各业务场景对技术的需求强度各异。用户更大的困惑在于，如何高效整合这些主流技术和服务，让整个 IT 基础架构变的更加合理（不花冤枉钱），进而优化现有虚拟化环境性能、让资源利用率提升。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;优刻得云计算&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnew.qq.com%2Frain%2Fa%2F20240722A025R600%3Fsuid%3D%26media_id%3D&quot; target=&quot;_blank&quot;&gt;硅谷新公司 SF Compute：AI 算力的&quot;Airbnb&quot;，奥特曼亲弟领投，估值 5 亿&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#303030&quot;&gt;半年多过去，这家做算力生意的初创公司「San Francisco Compute」从名不见经传的「Underdog」来到台前。上周，Sam Altman 亲弟弟 Jack Altman 主理的 Alt Capital 领投其 1200 万美元种子轮融资，让它的估值来到约 5 亿人民币（7000 万美元）。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;硅星人 Pro&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2Fv006Q49ZiJlK66KhuL09EAiBvCLGCuNIL1EMnviymIutJlcB9vYZTv7Z2WC252ThgRQk&quot; target=&quot;_blank&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;特朗普将启动 AI「曼哈顿计划」？&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;特朗普和盟友们最近正在起草一项关于 AI 的行政命令，该命令暂定为「AI 曼哈顿计划」，用以开发军事技术，同时审查和取消一些不必要和繁重的法规。&lt;/p&gt; 
  &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:justify&quot;&gt;这表明特朗普第二届政府可能会更重视【如何推行有利于硅谷投资者和公司的人工智能政策】。同时也更重视对于美国高精尖技术的保护和垄断。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;探索映像&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fishare.ifeng.com%2Fc%2Fs%2F8bQ6DDqpVIi&quot; target=&quot;_blank&quot;&gt;被 AlphaGo 击败的李世石，用 8 年重建崩塌的世界&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;现在离 ChatGPT 的发布过去了不足两年，我们已看到多个领域被 AI 影响，而生活更多方面似乎也被埋下了改变的伏笔，我们总忍不住想要去推测和畅想未来的 AI。&lt;/p&gt; 
 &lt;p&gt;在这个语境下，比其他行业和领域更早受到 AI 冲击的围棋界，能帮助我们看到一种已经发生的可能性。&lt;/p&gt; 
 &lt;p&gt;击败人类后，更强的 AI 在进一步去「人味」&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;爱范儿&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bjnews.com.cn%2Fdetail%2F1721630423129982.html&quot; target=&quot;_blank&quot;&gt;中国 AI 大模型测评报告：公众及传媒行业大模型使用与满足研究&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#191919&quot;&gt;一年半时间，从 ChatGPT（一款生成式大语言模型）到 Sora（一款生成式视频模型）生成式预训练大模型（下称：大模型），原本平静的全球科技圈刮起飓风。作为新质生产力发展的重要引擎，AI 大模型的交互体验和生成能力预示着生产力的前进方向，人工智能也正在成为经济高质量发展的最强增量。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;新京报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstatic.nfapp.southcn.com%2Fcontent%2F202407%2F21%2Fc9096119.html&quot; target=&quot;_blank&quot;&gt;追问四部门利用政务数据牟利 2.48 亿：公共数据能收费吗？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#252525&quot;&gt;政府机关利用政务数据违规经营收费，罕见被通报，连日来引起诸多讨论。政务数据究竟能否收费利用？其授权运营的合规边界在哪？怎么才能让海量的政务数据「供得出」「流得动」「用得好」？&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;南方都市报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flapce%2Flapce&quot; target=&quot;_blank&quot;&gt;lapce/lapce&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;352&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fb40172a9db77fc34f3ab25aa0626ade6bf.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Flapce%2Flapce&quot; target=&quot;_blank&quot;&gt;https://github.com/lapce/lapce&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;Lapce 是&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#24292f&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;用 Rust 编写的快速且功能强大的代码编辑器&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#24292f&quot;&gt;，UI 则是采用&amp;nbsp;Floem。它使用&amp;nbsp;Xi-Editor&amp;nbsp;的&amp;nbsp;Rope Science&amp;nbsp;进行文本编辑，并使用&amp;nbsp;Wgpu&amp;nbsp;进行渲染。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/meituantech/blog/11585606&quot; target=&quot;_blank&quot;&gt;一文讲清多线程和多线程同步&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;本篇文章将深入探讨多线程编程的基本概念（原子操作、CAS、Lock-free、内存屏障、伪共享、乱序执行等）、常见模式和最佳实践。通过具体的代码示例，希望能够帮助大家掌握多线程编程的核心技术，并在实际开发中应用这些知识，提升软件的性能和稳定性。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;kfifo&quot; height=&quot;265&quot; src=&quot;https://oscimg.oschina.net/oscnet/db91961f99806e32b43699dabf6aa99f52953.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FS7X3XMV5k8snjVm9aXQDjA&quot; target=&quot;_blank&quot;&gt;程序员应该掌握的三种编程语言&lt;span&gt;——&lt;/span&gt;有 Zig 无 Rust？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：我觉得重点该掌握的是 js/TS，python 和 c 语言。 js 语言什么都能做，甚至前端开发是离不开的，尽管有 wasm 等。其次 python 是简单的。c 语言是底层开发最佳选择之一。 其它语言什么的，都很难说是必要，当然，对于理解程序开发思维的程序员来说，学习一门新语言简直就是小菜一碟，老手程序员应该做到语言无关性…&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：感觉 zig 最大问题是：它官网我看了半天，硬是没看明白 zig 优势究竟是什么，和其他语言不同是什么，解决了什么传统模式的痛点。还有就是它教程里，似乎把预编译的导入文件#include，变成了一个赋值语句？然后也没说明为什么要这样设计，目的是什么。看的云里雾里。知其然却不知起所以然。这很不利于宣传。而 rust 至少这方面就做的很好，解决了什么痛点，所有权为什么要那样设计，都写的很明白。zig 我是真没看懂它官网&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：上过‘’编程语言‘’这门课的人应该可以看出 Finch 的学院气太重了，过度追求通用性，导致理解难度大幅上升。同为 MIT 出品的 Julia 都好得多。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：纯纯野榜了，不实用也不先进，程序员还是先把 c 和 linux api/abi 学好，一通百通，rust 和 zig 之类的各种东西还都没个定数，swift 这种纯业务的等真有需求再说吧。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：zig 是 C 的继承者，而 Rust 是一个新品种，适用于某些领域，而不适合全盘替代 C&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：rust 对标的是 c++&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：醒醒，这里是 China&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：Swift 还能出现？纯纯野榜！苹果的御用语言，接替 objc 的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：swift 生态怎么样，可以写嵌入式吗？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：rust 写着巨难受&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：写 rust 感觉像是做数学证明，每一步都得写明明白白，不然就过不了，俗称和编译器做斗争&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：仓颉吧还是，未来的中国是仓颉的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：变则通，可以主修一门语言，但不要轻视其他语言，多学几门语言总没错&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：为啥一个即将退出的 s6 要和退出几年的 P8 比，咋不和 P12 比？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：感觉说的很好，但是 zig 的薪资什么的肯定不是国内可以想象的了&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FasHjbQEC2o2udSJ6ciFhNg&quot; target=&quot;_blank&quot;&gt;美国安全软件更新导致「微软蓝屏」&lt;span&gt;——&lt;/span&gt;Linux 用户和马斯克都在看乐子&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：随便一个 bug 都能控制部分全球地区的电脑，so？国产有点广告肿么了？能死？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：系统问题能被你引申到国产有广告没问题你也是可以的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：这种大规模更新都不提前做测试的吗&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：这次能看出 Azure 在全球商业版图有多恐怖，Azure 的云服务深入各行各业。 一个安全软件的更新合并入 azure 的 windows 库，再由 azure 进行全球分发更新。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：想想蛮恐怖的，如果这是在中美发生战时冲突的话，大量用了美国操作系统的关键部门和行业，咋办？看来关键行业部门的操作系统必须要国产化，这个国产操作系统小而专即可，不需要像微软 windowd 系统那么庞大复杂需要兼容那么多&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：上个世纪大家就想到啦，美国军方都不在关键上用 Windows&lt;img alt=&quot;[旺柴]&quot; src=&quot;https://res.wx.qq.com/mpres/zh_CN/htmledition/comm_htmledition/images/pic/common/pic_blank.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;，有军用的 Army Secure OS&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：这次算是信誉扫地了，这也是依赖并无条件信任某个软件提供商可能产生的结果之一。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：好歹是家计算机安全供应商，居然能这样搞...大规模的更新推动不提前测试，现在的安全环境得烂成什么样子啊，没有测试的更新补丁在完全没人管控和监测的情况下大规模被打在了各个公司的电脑上&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：个人用户没事的&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：这次恢复很费时间吧！？需要每个电脑都需要 winre 或 wenpe 恢复吧！？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：不至于，安全模式应该能搞定，只是对于不了解的人还是很困难的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：来，和我一起念：世界就是一个草台班子&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：所以驱动一旦搞不好就会直接寄掉&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：linux 内核：我们也要学习蓝屏！微硬：看见没，这才叫真蓝屏！学着点！&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/303139&quot; target=&quot;_blank&quot;&gt;腾讯云发布国产服务器操作系统 TencentOS Server V3&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：又是一个 centos 发行版&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：他家不是有个一个了吗又有整一个&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：怎么和数据库有关呢？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：看到 GPU 利用率我就懂了，平时放着不利用不是浪费么&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：腾子啊，这个不赚钱，别了吧。我们不希望 sudo 要充值啊&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：sudo 充钱算什么， ls, cp, mv, cat 统统收钱起来&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：CentOS 原地替换，重启即生效？这个可以！&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：孤陋寡闻了吧，AlmaLinux 和 RockyLinux 老早就出了迁移工具。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：都是魔改的系统，能不能别叫国产系统？老老实实做一个 linux 分支系统不好吗？&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303369</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303369</guid>
            <pubDate>Mon, 22 Jul 2024 11:04:06 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>2024 开源学术会议征文通知</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h3&gt;&lt;strong&gt;背景信息&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;开源在物理世界萌芽、发展并成为数字经济创新创业的主导模式，是新时代新质生产力的代表。&lt;/p&gt; 
&lt;p&gt;开源是一场伟大的社会创新活动，其对人类社会的影响远超工业革命，催生伟大的理论，也需要伟大理论的指导！&lt;/p&gt; 
&lt;p&gt;开源社会存在合理性解释、开源社会意识及其可能的物质力量、如何推动中国开源创新、数字公共产品国际合作、数字主权、数字世界规则及治理、开源社会组织运营模式、企业开源方法论、开源人才培养等都是亟待解决的重大现实问题。构建开源理论，需要突破物理世界理论框架，需要范式创新。&lt;/p&gt; 
&lt;p&gt;时代呼唤懂代码的哲学社会科学工作者，通过开源理论社会工程，一起推动人类数字命运共同体的实现。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c58f77cd0905cee0ed7337d7917104b94e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;1&amp;nbsp;&lt;strong&gt;会议信息&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;会议名称&lt;/strong&gt;：2024 开源学术会议&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;会议主题&lt;/strong&gt;：开源创新理论与实践&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;会议时间&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;会议地点&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;主办单位&lt;/strong&gt;：上海开源信息技术协会&lt;/p&gt; 
&lt;p&gt;开源创新与数字治理研究院&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;承办单位&lt;/strong&gt;：上海对外经贸大学（暂定）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;协办单位：&lt;/strong&gt;&lt;br&gt; 《华东师范大学学报》(自然科学版)&lt;br&gt; CCF 开源发展委员会&lt;br&gt; 上海市电子学会开源专业委员会&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;支持单位：&lt;/strong&gt;华东师范大学、上海对外经贸大学、上海交通大学、复旦大学、东华大学、北京科技大学、中国科学院科技战略咨询研究院、对外经济贸易大学全球开源协作研究中心、CSDN 中国开发者网络等&lt;/p&gt; 
&lt;h3&gt;2&amp;nbsp;&lt;strong&gt;征文范围&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;本次学术大会围绕「开源」展开，面向以下主题征集论文和演讲稿，包括但不限于：&lt;/p&gt; 
&lt;p&gt;1）开源社会存在合理性解释、开源社会意识及其可能的物质力量、开源供应链安全、开源创新国际合作等；&lt;/p&gt; 
&lt;p&gt;2）国家开源创新政策比较、开源社会组织、开源项目、开源社区及其指标体系；&lt;/p&gt; 
&lt;p&gt;3）企业开源竞争战略、数字化转型开源解决方案、开源办公室、开源治理、开源文化等；&lt;/p&gt; 
&lt;p&gt;4）开放科学、开源教育、开源应用、开源案例研究等。&lt;/p&gt; 
&lt;h3&gt;3&amp;nbsp;&lt;strong&gt;征文格式要求&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 字数限制&lt;/strong&gt;：论文全文字数范围 8000~12000 字（包括参考文献）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 文件格式&lt;/strong&gt;：提交文档应为 Word 和 PDF 格式。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 引用风格&lt;/strong&gt;：请遵循 APA、MLA 或芝加哥引用风格等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. 论文语言&lt;/strong&gt;：中英文论文均可，但必须包括英文摘要。&lt;/p&gt; 
&lt;h3&gt;4&amp;nbsp;&lt;strong&gt;投稿方式&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;请通过以下邮箱提交您的论文：&lt;/p&gt; 
&lt;p&gt;投稿邮箱：osac@shanghaiopen.org.cn&lt;br&gt; 投稿请注明：投稿人姓名+论文题目&lt;/p&gt; 
&lt;h3&gt;5&amp;nbsp;&lt;strong&gt;重要日期&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;投稿截止日期&lt;/strong&gt;：2024 年 9 月 15 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;会议录稿通知日期&lt;/strong&gt;：2024 年 9 月 25 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;会议召开时间&lt;/strong&gt;：待定&lt;/p&gt; 
&lt;h3&gt;6&amp;nbsp;&lt;strong&gt;审稿流程&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. 初审阶段&lt;/strong&gt;：组委会将对投稿进行初步筛选，以确定是否符合征文主题和格式要求。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 同行评审&lt;/strong&gt;：符合要求的论文将发送给至少两位领域专家进行盲审。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. 终审决定&lt;/strong&gt;：论文评定委员会将根据同行评审的意见做出最终录用决定。&lt;/p&gt; 
&lt;h3&gt;7&amp;nbsp;&lt;strong&gt;参会及论文发表&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;所有被录用的论文作者将被邀请在会议上进行演讲。&lt;/li&gt; 
 &lt;li&gt;优秀论文将有机会获得最佳论文奖，并被推荐到《华东师范大学学报》(自然科学版) 等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;8&amp;nbsp;&lt;strong&gt;联系咨询&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;对于本次学术会议，如您有任何问题咨询，可以联系本次大会组委会联络人：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;联系人：王伟&lt;/li&gt; 
 &lt;li&gt;联系电话：13661537027&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;9&amp;nbsp;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;请确保您的论文是原创的，并且没有在其他期刊或会议上发表过。&lt;/li&gt; 
 &lt;li&gt;遵循征文格式要求，以确保您的论文能顺利进入审稿流程。&lt;/li&gt; 
 &lt;li&gt;保持关注会议官方网站或邮件通知，以获取最新的会议和审稿信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;2024 开源学术会议大会组委会&lt;/p&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;上海开源信息技术协会&lt;/p&gt; 
&lt;p style=&quot;text-align:right&quot;&gt;2024 年 7 月 22 日&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;上海开源信息技术协会&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;上海开源信息技术协会成立于 2020 年 3 月 24 日，是市科协一星级协会、市民政 3A 级社团组织。协会由致力于开源信息技术创新的企业、高校、科研院所、社会组织及专业人员等自愿组成。由致力于开源信息技术创新的企业、高校、科研院所、社会组织及专业人员等自愿组成。协会自成立以来，始终坚持基于自组织创新创业共同体模式，以专业、公开、公正、透明的精神，服务国家及上海市数字经济发展战略。对接各种开源创新要素，积极促进上海开源人才高地、开源产业聚集地、开源服务业高度发达、开源创新营商环境最优城市建设。具体工作重心：一是开源理论构建，并积极推动社会实践；二是中国开源创新社会工程，推动大中小学开源教育；三是数字」一带一路「；四是上海开源产业发展。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303363</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303363</guid>
            <pubDate>Mon, 22 Jul 2024 10:15:35 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>一文讲清多线程和多线程同步</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p&gt;多线程编程是现代软件开发中的一项关键技术，在多线程编程中，开发者可以将复杂的任务分解为多个独立的线程，使其并行执行，从而充分利用多核处理器的优势。然而，多线程编程也带来了挑战，例如线程同步、死锁和竞态条件等问题。本篇文章将深入探讨多线程编程的基本概念（原子操作、CAS、Lock-free、内存屏障、伪共享、乱序执行等）、常见模式和最佳实践。通过具体的代码示例，希望能够帮助大家掌握多线程编程的核心技术，并在实际开发中应用这些知识，提升软件的性能和稳定性。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7998cb8e9779e36bdccf1f53e96ccc3a092.jpg&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;1 多线程&lt;/h2&gt; 
&lt;h3&gt;1.1 线程的概念&lt;/h3&gt; 
&lt;p&gt;十多年前，主流观点主张在可能的情况下优先选择多进程而非多线程。如今，多线程编程已经成为编程领域的事实标准。多线程技术在很大程度上改善了程序的性能和响应能力，使其能够更加高效地利用系统资源，这不仅归功于多核处理器的普及和软硬件技术的进步，还归功于开发者对多线程编程的深入理解和技术创新。&lt;/p&gt; 
&lt;p&gt;那么什么是线程呢？线程是一个执行上下文，它包含诸多状态数据：每个线程有自己的执行流、调用栈、错误码、信号掩码、私有数据。Linux 内核用任务（Task）表示一个执行流。&lt;/p&gt; 
&lt;h4&gt;1.1.1 执行流&lt;/h4&gt; 
&lt;p&gt;一个任务里被依次执行的指令会形成一个指令序列（IP 寄存器值的历史记录），这个指令序列就是一个指令流，每个线程会有自己的执行流。考虑下面的代码（本文代码块为 C++）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int calc(int a, int b, char op) {
  int c = 0;
  if (op == &#39;+&#39;)
    c = a + b;
  else if (op == &#39;-&#39;)
    c = a - b;
  else if (op == &#39;*&#39;)
    c = a * b;
  else if (op == &#39;/&#39;)
    c = a / b;
  else
    printf(&quot;invalid operation\n&quot;);
  return c;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;calc 函数被编译成汇编指令，一行 C 代码对应一个或多个汇编指令，在一个线程里执行 calc，那么这些机器指令会被依次执行。但是，被执行的指令序列跟代码顺序可能不完全一致，代码中的分支、跳转等语句，以及编译器对指令重排、处理器乱序执行会影响指令的真正执行顺序。&lt;/p&gt; 
&lt;h4&gt;1.1.2 逻辑线程 vs 硬件线程&lt;/h4&gt; 
&lt;p&gt;线程可以进一步区分为逻辑线程和硬件线程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;逻辑线程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;程序上的线程是一个逻辑上的概念，也叫任务、软线程、逻辑线程。线程的执行逻辑由代码描述，比如编写一个函数实现对一个整型数组的元素求和：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int sum(int a[], int n) {
    int x = 0;
    for (int i = 0; i &amp;lt; n; ++i) 
        x += a[i];
    return x;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这个函数的逻辑很简单，它没有再调用其他函数（更复杂的功能逻辑可以在函数里调用其他函数）。我们可以在一个线程里调用这个函数对某数组求和；也可以把 sum 设置为某线程的入口函数，每个线程都会有一个入口函数，线程从入口函数开始执行。sum 函数描述了逻辑，即要做什么以及怎么做，偏设计；但它没有描述物质，即没有描述这个事情由谁做，事情最终需要派发到实体去完成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;硬件线程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;与逻辑线程对应的是硬件线程，这是逻辑线程被执行的物质基础。&lt;/p&gt; 
&lt;p&gt;芯片设计领域，一个硬件线程通常指为执行指令序列而配套的硬件单元，一个 CPU 可能有多个核心，然后核心还可能支持超线程，1 个核心的 2 个超线程复用一些硬件。从软件的视角来看，无须区分是真正的 Core 和超出来的 VCore，基本上可以认为是 2 个独立的执行单元，每个执行单元是一个逻辑 CPU，从软件的视角看 CPU 只需关注逻辑 CPU。一个软件线程由哪个 CPU/核心去执行，以及何时执行，不归应用程序员管，它由操作系统决定，操作系统中的调度系统负责此项工作。&lt;/p&gt; 
&lt;h3&gt;1.2 线程、核心、函数的关系&lt;/h3&gt; 
&lt;p&gt;线程入口函数是线程执行的起点，线程从入口函数开始、一个指令接着一个指令执行，中间它可能会调用其他函数，那么它的控制流就转到了被调用的函数继续执行，被调用函数里还可以继续调用其他函数，这样便形成一个函数调用链。&lt;/p&gt; 
&lt;p&gt;前面的数组求和例子，如果数组特别大，则哪怕是一个简单的循环累加也可能耗费很长的时间，可以把这个整型数组分成多个小数组，或者表示成二维数组（数组的数组），每个线程负责一个小数组的求和，多个线程并发执行，最后再累加结果。&lt;/p&gt; 
&lt;p&gt;所以，为了提升处理速度，可以让多个线程在不同数据区段上执行相同（或相似）的计算逻辑，同样的处理逻辑可以有多个执行实例（线程），这对应对数据拆分线程。当然，也可以为两个线程指定不同的入口函数，让各线程执行不同的计算逻辑，这对应对逻辑拆分线程。&lt;/p&gt; 
&lt;p&gt;我们用一个例子来阐述线程、核心和函数之间的关系，假设有遛狗、扫地两类工作要做：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;遛狗就是为狗系上绳子然后牵着它在小区里溜达一圈，这句话就描述了遛狗的逻辑，即对应到函数定义，它是一个对应到设计的静态的概念。&lt;/li&gt; 
 &lt;li&gt;每项工作，最终需要人去做，人就对应到硬件：CPU/Core/VCore，是任务被完成的物质基础。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;那什么对应软件线程？ 任务拆分。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;一个例子&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假设现在有 2 条狗需要遛、3 个房间需要打扫。可以把遛狗拆成 2 个任务，一个任务是遛小狗，另一个任务是遛大狗；打扫房间拆分为 3 个任务，3 个房间对应 3 个任务，执行这样的拆分策略后，将会产生 2+3=5 个任务。但如果只有 2 个人，2 个人无法同时做 5 件事，让某人在某时干某事由调度系统负责。&lt;/p&gt; 
&lt;p&gt;如果张三在遛小狗，那就对应一个线程被执行，李四在扫房间 A，则表示另一个线程在执行中，可见线程是一个动态的概念。&lt;/p&gt; 
&lt;p&gt;软件线程不会一直处于执行中，原因是多方面的。上述例子是因为人手不够，所以遛大狗的任务还处于等待被执行的状态，其他的原因包括中断、抢占、条件依赖等。比如李四扫地过程中接到一个电话，他需要去处理更紧急的事情（接电话），则扫地这个事情被挂起，李四打完电话后继续扫地，则这个线程会被继续执行。&lt;/p&gt; 
&lt;p&gt;如果只有 1 个人，则上述 5 个任务依然可以被依次或交错完成，所以多线程是一个编程模型，多线程并不一定需要多 CPU 多 Core，单 CPU 单 Core 系统依然可以运行多线程程序（虽然最大化利用多 CPU 多 Core 的处理能力是多线程程序设计的一个重要目标）。1 个人无法同时做多件事，单 CPU/单 Core 也不可以，操作系统通过时间分片技术应对远多于 CPU/Core 数的多任务执行的挑战。也可以把有些任务只分配给某些人去完成，这对应到 CPU 亲和性和绑核。&lt;/p&gt; 
&lt;h3&gt;1.3 程序、进程、线程、协程&lt;/h3&gt; 
&lt;p&gt;进程和线程是操作系统领域的两个重要概念，两者既有区别又有联系。&lt;/p&gt; 
&lt;h4&gt;1.3.1 可执行程序&lt;/h4&gt; 
&lt;p&gt;C/C++源文件经过编译器（编译+链接）处理后，会产生可执行程序文件，不同系统有不同格式，比如 Linux 系统的 ELF 格式、Windows 系统的 EXE 格式，可执行程序文件是一个静态的概念。&lt;/p&gt; 
&lt;h4&gt;1.3.2 进程是什么&lt;/h4&gt; 
&lt;p&gt;可执行程序在操作系统上的一次执行对应一个进程，进程是一个动态的概念：进程是执行中的程序。同一份可执行文件执行多次，会产生多个进程，这跟一个类可以创建多个实例一样。进程是资源分配的基本单位。&lt;/p&gt; 
&lt;h4&gt;1.3.3 线程是什么&lt;/h4&gt; 
&lt;p&gt;一个进程内的多个线程代表着多个执行流，这些线程以并发模式独立执行。操作系统中，被调度执行的最小单位是线程而非进程。进程是通过共享存储空间对用户呈现的逻辑概念，同一进程内的多个线程共享地址空间和文件描述符，共享地址空间意味着进程的代码（函数）区域、全局变量、堆、栈都被进程内的多线程共享。&lt;/p&gt; 
&lt;h4&gt;1.3.4 进程和线程的关系&lt;/h4&gt; 
&lt;p&gt;先看看 linus 的论述，在 1996 年的一封邮件里，Linus 详细阐述了他对进程和线程关系的深刻洞见，他在邮件里写道：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;把进程和线程区分为不同的实体是揹着历史包袱的传统做法，没有必要做这样的区分，甚至这样的思考方式是一个主要错误。&lt;/li&gt; 
 &lt;li&gt;进程和线程都是一回事：一个执行上下文（context of execution），简称为 COE，其状态包括： 
  &lt;ul&gt; 
   &lt;li&gt;CPU 状态（寄存器等）&lt;/li&gt; 
   &lt;li&gt;MMU 状态（页映射）&lt;/li&gt; 
   &lt;li&gt;权限状态（uid、gid 等）&lt;/li&gt; 
   &lt;li&gt;各种通信状态（打开的文件、信号处理器等）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;传统观念认为：进程和线程的主要区别是线程有 CPU 状态（可能还包括其他最小必要状态），而其他上下文来自进程；然而，这种区分法并不正确，这是一种愚蠢的自我设限。&lt;/li&gt; 
 &lt;li&gt;Linux 内核认为根本没有所谓的进程和线程的概念，只有 COE（Linux 称之为任务），不同的 COE 可以相互共享一些状态，通过此类共享向上构建起进程和线程的概念。&lt;/li&gt; 
 &lt;li&gt;从实现来看，Linux 下的线程目前是 LWP 实现，线程就是轻量级进程，所有的线程都当作进程来实现，因此线程和进程都是用 task_struct 来描述的。这一点通过/proc 文件系统也能看出端倪，线程和进程拥有比较平等的地位。对于多线程来说，原本的进程称为主线程，它们在一起组成一个线程组。&lt;/li&gt; 
 &lt;li&gt;简言之，内核不要基于进程/线程的概念做设计，而应该围绕 COE 的思考方式去做设计，然后，通过暴露有限的接口给用户去满足 pthreads 库的要求。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1.3.5 协程&lt;/h4&gt; 
&lt;p&gt;用户态的多执行流，上下文切换成本比线程更低，微信用协程改造后台系统后，获得了更大吞吐能力和更高稳定性。如今，协程库也进了 C++ 20 新标准。&lt;/p&gt; 
&lt;h3&gt;1.4 为什么需要多线程&lt;/h3&gt; 
&lt;h4&gt;1.4.1 什么是多线程&lt;/h4&gt; 
&lt;p&gt;一个进程内多个线程并发执行的情况就叫多线程，每个线程是一个独立的执行流，多线程是一种编程模型，它与处理器无关、跟设计有关。&lt;/p&gt; 
&lt;p&gt;需要多线程的原因包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;并行计算&lt;/strong&gt;：充分利用多核，提升整体吞吐，加快执行速度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;后台任务处理&lt;/strong&gt;：将后台线程和主线程分离，在特定场景它是不可或缺的，如：响应式用户界面、实时系统等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们用 2 个例子作说明。&lt;/p&gt; 
&lt;h4&gt;1.4.2 通过多线程并发提升处理能力&lt;/h4&gt; 
&lt;p&gt;假设你要编写一个程序，用于统计一批文本文件的单词出现次数，程序的输入是文件名列表，输出一个单词到次数的映射。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 类型别名：单词到次数的映射
using word2count = std::map&amp;lt;std::string, unsigned int&amp;gt;;

// 合并&quot;单词到次数映射列表&quot;
word2count merge(const std::vector&amp;lt;word2count&amp;gt;&amp;amp; w2c_list) {/*todo*/}

// 统计一个文件里单词出现次数（单词到次数的映射）
word2count word_count_a_file(const std::string&amp;amp; file) {/*todo*/}

// 统计一批文本文件的单词出现次数
word2count word_count_files(const std::vector&amp;lt;std::string&amp;gt;&amp;amp; files) {
    std::vector&amp;lt;word2count&amp;gt; w2c_list;
    for (auto &amp;amp;file : files) {
        w2c_list.push_back(word_count_a_file(file));
    }
    return merge(w2c_list);
}

int main(int argc, char* argv[]) {
    std::vector&amp;lt;std::string&amp;gt; files;
    for (int i = 1; i &amp;lt; argc; ++i) {
        files.push_back(argv[i]);
    }
    auto w2c = word_count_files(files);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这是一个单线程程序，word_count_files 函数在主线程里被 main 函数调用。如果文件不多、又或者文件不大，那么运行这个程序，很快就会得到统计结果，否则，可能要等一段长的时间才能返回结果。&lt;/p&gt; 
&lt;p&gt;重新审视这个程序会发现：函数 word_count_a_file 接受一个文件名，吐出从该文件计算出的局部结果，它不依赖于其他外部数据和逻辑，可以并发执行，所以，可以为每个文件启动一个单独的线程去运行 word_count_a_file，等到所有线程都执行完，再合并得到最终结果。&lt;/p&gt; 
&lt;p&gt;实际上，为每个文件启动一个线程未必合适，因为如果有数万个小文件，那么启动数万个线程，每个线程运行很短暂的时间，大量时间将耗费在线程创建和销毁上，一个改进的设计：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;开启一个线程池，线程数等于 Core 数或二倍 Core 数（策略）。&lt;/li&gt; 
 &lt;li&gt;每个工作线程尝试去文件列表（文件列表需要用锁保护起来）里取一个文件。 
  &lt;ul&gt; 
   &lt;li&gt;成功，统计这个文件的单词出现次数。&lt;/li&gt; 
   &lt;li&gt;失败，该工作线程就退出。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;待所有工作线程退出后，在主线程里合并结果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这样的多线程程序能加快处理速度，前面数组求和可以采用相似的处理，如果程序运行在多 CPU 多 Core 的机器上，就能充分利用多 CPU 多 Core 硬件优势，多线程加速执行是多线程的一个显而易见的主要目的，此其一。&lt;/p&gt; 
&lt;h4&gt;1.4.3 通过多线程改变程序编写方式&lt;/h4&gt; 
&lt;p&gt;其二，有些场景会有阻塞的调用，如果不用多线程，那么代码不好编写。&lt;/p&gt; 
&lt;p&gt;比如某程序在执行密集计算的同时，需要监控标准输入（键盘），如果键盘有输入，那么读取输入并解析执行，但如果获取键盘输入的调用是阻塞的，而此时键盘没有输入到来，那么其他逻辑将得不到机会执行。&lt;/p&gt; 
&lt;p&gt;代码看起来会像下面这样子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// 从键盘接收输入，经解释后，会构建一个 Command 对象返回
Command command = getCommandFromStdInput();
// 执行命令
command.run();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;针对这种情况，我们通常会开启一个单独的线程去接收输入，而用另外的线程去处理其他计算逻辑，避免处理输入阻塞其他逻辑处理，这也是多线程的典型应用，它改变了程序的编写方式，此其二。&lt;/p&gt; 
&lt;h3&gt;1.5 线程相关概念&lt;/h3&gt; 
&lt;h4&gt;1.5.1 时间分片&lt;/h4&gt; 
&lt;p&gt;CPU 先执行线程 A 一段时间，然后再执行线程 B 一段时间，然后再执行线程 A 一段时间，CPU 时间被切分成短的时间片、分给不同线程执行的策略就是 CPU 时间分片。时间分片是对调度策略的一个极度简化，实际上操作系统的调度策略非常精细，要比简单的时间分片复杂的多。如果一秒钟被分成大量的非常短的时间片，比如 100 个 10 毫秒的时间片，10 毫秒对人的感官而言太短了，以致于用户觉察不到延迟，仿佛计算机被该用户的任务所独占（实际上并不是），操作系统通过进程的抽象获得了这种任务独占 CPU 的效果（另一个抽象是进程通过虚拟内存独占存储）。&lt;/p&gt; 
&lt;h4&gt;1.5.2 上下文切换&lt;/h4&gt; 
&lt;p&gt;把当前正在 CPU 上运行的任务迁走，并挑选一个新任务到 CPU 上执行的过程叫调度，任务调度的过程会发生上下文切换（context swap），即保存当前 CPU 上正在运行的线程状态，并恢复将要被执行的线程的状态，这项工作由操作系统完成，需要占用 CPU 时间（sys time）。&lt;/p&gt; 
&lt;h4&gt;1.5.3 线程安全函数与可重入&lt;/h4&gt; 
&lt;p&gt;一个进程可以有多个线程在同时运行，这些线程可能同时执行一个函数，如果多线程并发执行的结果和单线程依次执行的结果是一样的，那么就是线程安全的，反之就不是线程安全的。&lt;/p&gt; 
&lt;p&gt;不访问共享数据，共享数据包括全局变量、static local 变量、类成员变量，只操作参数、无副作用的函数是线程安全函数，线程安全函数可多线程重入。每个线程有独立的栈，而函数参数保存在寄存器或栈上，局部变量在栈上，所以只操作参数和局部变量的函数被多线程并发调用不存在数据竞争。&lt;/p&gt; 
&lt;p&gt;C 标准库有很多编程接口都是非线程安全的，比如时间操作/转换相关的接口：ctime()/gmtime()/localtime()，c 标准通过提供带_r 后缀的线程安全版本，比如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;char* ctime_r(const time* clock, char* buf);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这些接口的线程安全版本，一般都需要传递一个额外的 char * buf 参数，这样的话，函数会操作这块 buf，而不是基于 static 共享数据，从而做到符合线程安全的要求。&lt;/p&gt; 
&lt;h4&gt;1.5.4 线程私有数据&lt;/h4&gt; 
&lt;p&gt;因为全局变量（包括模块内的 static 变量）是进程内的所有线程共享的，但有时应用程序设计中需要提供线程私有的全局变量，这个变量仅在函数被执行的线程中有效，但却可以跨多个函数被访问。&lt;/p&gt; 
&lt;p&gt;比如在程序里可能需要每个线程维护一个链表，而会使用相同的函数来操作这个链表，最简单的方法就是使用同名而不同变量地址的线程相关数据结构。这样的数据结构可以由 Posix 线程库维护，成为线程私有数据 (Thread-specific Data，或称为 TSD)。&lt;/p&gt; 
&lt;p&gt;Posix 有线程私有数据相关接口，而 C/C++等语言提供 thread_local 关键字，在语言层面直接提供支持。&lt;/p&gt; 
&lt;h4&gt;1.5.5 阻塞和非阻塞&lt;/h4&gt; 
&lt;p&gt;一个线程对应一个执行流，正常情况下，指令序列会被依次执行，计算逻辑会往前推进。但如果因为某种原因，一个线程的执行逻辑不能继续往前走，那么我们就说线程被阻塞住了。就像下班回家，但走到家门口发现没带钥匙，只能在门口徘徊，任由时间流逝，而不能进入房间。&lt;/p&gt; 
&lt;p&gt;线程阻塞的原因有很多种，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;线程因为 acquire 某个锁而被操作系统挂起，如果 acquire 睡眠锁失败，线程会让出 CPU，操作系统会调度另一个可运行线程到该 CPU 上执行，被调度走的线程会被加入等待队列，进入睡眠状态。&lt;/li&gt; 
 &lt;li&gt;线程调用了某个阻塞系统调用而等待，比如从没有数据到来的套接字上读数据，从空的消息队列里读消息。&lt;/li&gt; 
 &lt;li&gt;线程在循环里紧凑的执行测试&amp;amp;设置指令并一直没有成功，虽然线程还在 CPU 上执行，但它只是忙等（相当于白白浪费 CPU），后面的指令没法执行，逻辑同样无法推进。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果某个系统调用或者编程接口有可能导致线程阻塞，那么便被称之为阻塞系统调用；与之对应的是非阻塞调用，调用非阻塞的函数不会陷入阻塞，如果请求的资源不能得到满足，它会立即返回并通过返回值或错误码报告原因，调用的地方可以选择重试或者返回。&lt;/p&gt; 
&lt;h2&gt;2 多线程同步&lt;/h2&gt; 
&lt;p&gt;前面讲了多线程相关的基础知识，现在进入第二个话题，多线程同步。&lt;/p&gt; 
&lt;h3&gt;2.1 什么是多线程同步&lt;/h3&gt; 
&lt;p&gt;同一进程内的多个线程会共享数据，对共享数据的并发访问会出现 Race Condition，这个词的官方翻译是竞争条件，但 condition 翻译成条件令人困惑，特别是对初学者而言，它不够清晰明了，翻译软件显示 condition 有状况、状态的含义，可能翻译成竞争状况更直白。&lt;/p&gt; 
&lt;p&gt;多线程同步是指：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;协调多个线程对共享数据的访问，避免出现数据不一致的情况。&lt;/li&gt; 
 &lt;li&gt;协调各个事件的发生顺序，使多线程在某个点交汇并按预期步骤往前推进，比如某线程需要等另一个线程完成某项工作才能开展该线程的下一步工作。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;要掌握多线程同步，需先理解为什么需要多线程同步、哪些情况需要同步。&lt;/p&gt; 
&lt;h3&gt;2.2 为什么需要同步&lt;/h3&gt; 
&lt;p&gt;理解为什么要同步（Why）是多线程编程的关键，它甚至比掌握多线程同步机制（How）本身更加重要。识别什么地方需要同步是编写多线程程序的难点，只有准确识别需要保护的数据、需要同步的点，再配合系统或语言提供的合适的同步机制，才能编写安全高效的多线程程序。&lt;/p&gt; 
&lt;p&gt;下面通过几个例子解释为什么需要同步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 1&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;有 1 个长度为 256 的字符数组 msg 用于保存消息，函数 read_msg() 和 write_msg() 分别用于 msg 的读和写：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 1
char msg[256] = &quot;this is old msg&quot;;

char* read_msg() {
    return msg;
}

void write_msg(char new_msg[], size_t len) {
    memcpy(msg, new_msg, std::min(len, sizeof(msg)));
}

void thread1() {
    char new_msg[256] = &quot;this is new msg, it&#39;s too looooooong&quot;;
    write_msg(new_msg, sizeof(new_msg));
}

void thread2() {
    printf(&quot;msg=%s\n&quot;, read_msg());
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果线程 1 调用 write_msg()，线程 2 调用 read_msg()，并发操作，不加保护。因为 msg 的长度是 256 字节，完成长达 256 字节的写入需要多个内存周期，在线程 1 写入新消息期间，线程 2 可能读到不一致的数据。即可能读到 &quot;this is new msg&quot;，而后半段内容 &quot;it&#39;s very...&quot; 线程 1 还没来得及写入，它不是完整的新消息。&lt;/p&gt; 
&lt;p&gt;在这个例子中，不一致表现为数据不完整。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 2&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;比如对于二叉搜索树（BST）的节点，一个结构体有 3 个成分：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一个指向父节点的指针&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一个指向左子树的指针&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;一个指向右子树的指针&lt;/p&gt; &lt;p&gt;// example 2 struct Node { struct Node *parent; struct Node *left_child, *right_child; };&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这 3 个成分是有关联的，将节点加入 BST，要设置这 3 个指针域，从 BST 删除该节点，要修改该节点的父、左孩子节点、右孩子节点的指针域。对多个指针域的修改，不能在一个指令周期完成，如果完成了一个成分的写入，还没来得修改其他成分，就有可能被其他线程读到了，但此时节点的有些指针域还没有设置好，通过指针域去取数可能会出错。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 3&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑两个线程对同一个整型变量做自增，变量的初始值是 0，我们预期 2 个线程完成自增后变量的值为 2。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 3
int x = 0; // 初始值为 0
void thread1() { ++x; }
void thread2() { ++x; }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;简单的自增操作，包括三步：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;加载&lt;/strong&gt;：从内存中读取变量 x 的值存放到寄存器&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;更新&lt;/strong&gt;：在寄存器里完成自增&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;保存&lt;/strong&gt;：把位于寄存器中的 x 的新值写入内存&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;两个线程并发执行++x，让我们看看真实情况是什么样的：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;如果 2 个线程，先后执行自增，在时间上完成错开。无论是 1 先 2 后，或是 2 先 1 后，那么 x 的最终值是 2，符合预期。但多线程并发并不能确保对一个变量的访问在时间上完全错开。&lt;/li&gt; 
 &lt;li&gt;如果时间上没有完全错开，假设线程 1 在 core1 上执行，线程 2 在 core2 上执行，那么，一个可能的执行过程如下：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;首先，线程 1 把 x 读到 core1 的寄存器，线程 2 也把 x 的值加载到 core2 的寄存器，此时，存放在两个 core 的寄存器中 x 的副本都是 0。&lt;/li&gt; 
 &lt;li&gt;然后，线程 1 完成自增，更新寄存器里 x 的值的副本（0 变 1），线程 2 也完成自增，更新寄存器里 x 的值的副本（0 变 1）。&lt;/li&gt; 
 &lt;li&gt;再然后，线程 1 将更新后的新值 1 写入变量 x 的内存位置。&lt;/li&gt; 
 &lt;li&gt;最后，线程 2 将更新后的新值 1 写入同一内存位置，变量 x 的最终值是 1，不符合预期。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;线程 1 和线程 2 在同一个 core 上交错执行，也有可能出现同样的问题，这个问题跟硬件结构无关。之所以会出现不符合预期的情况，主要是因为&quot;加载+更新+保存&quot;这 3 个步骤不能在一个内存周期内完成。多个线程对同一变量并发读写，不加同步的话会出现数据不一致。&lt;/p&gt; 
&lt;p&gt;在这个例子中，不一致表现为 x 的终值既可能为 1 也可能为 2。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 4&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;用 C++类模板实现一个队列：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 4
template &amp;lt;typename T&amp;gt;
class Queue {
    static const unsigned int CAPACITY = 100;
    T elements[CAPACITY];
    int num = 0, head = 0, tail = -1;
public:
    // 入队
    bool push(const T&amp;amp; element) {
        if (num == CAPACITY) return false;
        tail = (++tail) % CAPACITY;
        elements[tail] = element;
        ++num;
        return true;
    }
    // 出队
    void pop() {
        assert(!empty());
        head = (++head) % CAPACITY;
        --num;
    }
    // 判空
    bool empty() const { 
        return num == 0; 
    }
    // 访队首
    const T&amp;amp; front() const {
        assert(!empty());
        return elements[head];
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代码解释：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;T elements[]保存数据；2 个游标，分别用于记录队首 head 和队尾 tail 的位置（下标）。&lt;/li&gt; 
 &lt;li&gt;push() 接口，先移动 tail 游标，再把元素添加到队尾。&lt;/li&gt; 
 &lt;li&gt;pop() 接口，移动 head 游标，弹出队首元素（逻辑上弹出）。&lt;/li&gt; 
 &lt;li&gt;front() 接口，返回队首元素的引用。&lt;/li&gt; 
 &lt;li&gt;front()、pop() 先做断言，调用 pop()/front() 的客户代码需确保队列非空。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;假设现在有一个 Queue&amp;lt;int&amp;gt;实例 q，因为直接调用 pop 可能 assert 失败，我们封装一个 try_pop()，代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Queue&amp;lt;int&amp;gt; q;
void try_pop() {
    if (!q.empty()) {
        q.pop();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果多个线程调用 try_pop()，会有问题，为什么？&lt;/p&gt; 
&lt;p&gt;原因：判空+出队这 2 个操作，不能在一个指令周期内完成。如果线程 1 在判断队列非空后，线程 2 穿插进来，判空也为伪，这样就有可能 2 个线程竞争弹出唯一的元素。&lt;/p&gt; 
&lt;p&gt;多线程环境下，读变量然后基于值做进一步操作，这样的逻辑如果不加保护就会出错，这是由数据使用方式引入的问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 5&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;再看一个简单的，简单的对 int32_t 多线程读写。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 5
int32_t data[8] = {1,2,3,4,5,6,7,8}; 

struct Foo {
    int32_t get() const { return x; }
    void set(int32_t x) { this-&amp;gt;x = x; }
    int32_t x;
} foo;

void thread_write1() {
    for (;;) { for (auto v : data) { foo.set(v); } }
}

void thread_write2() {
    for (;;) { for (auto v : data) { foo.set(v); } }
}

void thread_read() {
    for (;;) { printf(&quot;%d&quot;, foo.get()); }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2 个写线程 1 个读线程，写线程在无限循环里用 data 里的元素值设置 foo 对象的 x 成分，读线程简单的打印 foo 对象的 x 值。程序一直跑下去，最后打印出来的数据，会出现除 data 初始化值外的数据吗？&lt;/p&gt; 
&lt;p&gt;Foo::get 的实现有问题吗？如果有问题？是什么问题？&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例 6&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;看一个用数组实现 FIFO 队列的程序，一个线程写 put()，一个线程读 get()。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// example 6
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;algorithm&amp;gt;

// 用数组实现的环型队列
class FIFO {
    static const unsigned int CAPACITY = 1024;  // 容量：需要满足是 2^N

    unsigned char buffer[CAPACITY];             // 保存数据的缓冲区
    unsigned int in = 0;                        // 写入位置
    unsigned int out = 0;                       // 读取位置

    unsigned int free_space() const { return CAPACITY - in + out; }
public:
    // 返回实际写入的数据长度（&amp;lt;= len），返回小于 len 时对应空闲空间不足
    unsigned int put(unsigned char* src, unsigned int len) {
        // 计算实际可写入数据长度（&amp;lt;=len）
        len = std::min(len, free_space());

        // 计算从 in 位置到 buffer 结尾有多少空闲空间
        unsigned int l = std::min(len, CAPACITY - (in &amp;amp; (CAPACITY - 1)));
        // 1. 把数据放入 buffer 的 in 开始的缓冲区，最多到 buffer 结尾
        memcpy(buffer + (in &amp;amp; (CAPACITY - 1)), src, l);   
        // 2. 把数据放入 buffer 开头（如果上一步还没有放完），len - l 为 0 代表上一步完成数据写入
        memcpy(buffer, src + l, len - l);
        
        in += len; // 修改 in 位置，累加，到达 uint32_max 后溢出回绕
        return len;
    }

    // 返回实际读取的数据长度（&amp;lt;= len），返回小于 len 时对应 buffer 数据不够
    unsigned int get(unsigned char *dst, unsigned int len) {
        // 计算实际可读取的数据长度
        len = std::min(len, in - out);

        unsigned int l = std::min(len, CAPACITY - (out &amp;amp; (CAPACITY - 1)));
        // 1. 从 out 位置开始拷贝数据到 dst，最多拷贝到 buffer 结尾
        memcpy(dst, buffer + (out &amp;amp; (CAPACITY - 1)), l);
        // 2. 从 buffer 开头继续拷贝数据（如果上一步还没拷贝完），len - l 为 0 代表上一步完成数据获取
        memcpy(dst + l, buffer, len - l);

        out += len; // 修改 out，累加，到达 uint32_max 后溢出回绕
        return len;
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/db91961f99806e32b43699dabf6aa99f52953.png&quot; alt=&quot;kfifo&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;环型队列只是逻辑上的概念，因为采用了数组作为数据结构，所以实际物理存储上并非环型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;put() 用于往队列里放数据，参数 src+len 描述了待放入的数据信息。&lt;/li&gt; 
 &lt;li&gt;get() 用于从队列取数据，参数 dst+len 描述了要把数据读到哪里、以及读多少字节。&lt;/li&gt; 
 &lt;li&gt;capacity 精心选择为 2 的 n 次方，可以得到 3 个好处： 
  &lt;ul&gt; 
   &lt;li&gt;非常技巧性的利用了无符号整型溢出回绕，便于处理对 in 和 out 移动&lt;/li&gt; 
   &lt;li&gt;便于计算长度，通过按位与操作&amp;amp;而不必除余&lt;/li&gt; 
   &lt;li&gt;搜索 kfifo 获得更详细的解释&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;in 和 out 是 2 个游标： 
  &lt;ul&gt; 
   &lt;li&gt;in 用来指向新写入数据的存放位置，写入的时候，只需要简单增加 in。&lt;/li&gt; 
   &lt;li&gt;out 用来指示从 buffer 的什么位置读取数据的，读取的时候，也只需简单增加 out。&lt;/li&gt; 
   &lt;li&gt;in 和 out 在操作上之所以能单调增加，得益于上述 capacity 的巧妙选择。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;为了简化，队列容量被限制为 1024 字节，不支持扩容，这不影响多线程的讨论。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;写的时候，先写入数据再移动 in 游标；读的时候，先拷贝数据，再移动 out 游标；in 游标移动后，消费者才获得 get 到新放入数据的机会。&lt;/p&gt; 
&lt;p&gt;直觉告诉我们 2 个线程不加同步的并发读写，会有问题，但真有问题吗？如果有，到底有什么问题？怎么解决？&lt;/p&gt; 
&lt;h3&gt;2.3 保护什么&lt;/h3&gt; 
&lt;p&gt;多线程程序里，我们要保护的是数据而非代码，虽然 Java 等语言里有临界代码、sync 方法，但最终要保护的还是代码访问的数据。&lt;/p&gt; 
&lt;h3&gt;2.4 串行化&lt;/h3&gt; 
&lt;p&gt;如果有一个线程正在访问某共享（临界）资源，那么在它结束访问之前，其他线程不能执行访问同一资源的代码（访问临界资源的代码叫临界代码），其他线程想要访问同一资源，则它必须等待，直到那个线程访问完成，它才能获得访问的机会，现实中有很多这样的例子。比如高速公路上的汽车过检查站，假设检查站只有一个车道，则无论高速路上有多少车道，过检查站的时候只能一辆车接着一辆车，从单一车道鱼贯而入。&lt;/p&gt; 
&lt;p&gt;对多线程访问共享资源施加此种约束就叫串行化。&lt;/p&gt; 
&lt;h3&gt;2.5 原子操作和原子变量&lt;/h3&gt; 
&lt;p&gt;针对前面的两个线程对同一整型变量自增的问题，如果&quot;load、update、store&quot;这 3 个步骤是不可分割的整体，即自增操作++x 满足原子性，上面的程序便不会有问题。&lt;/p&gt; 
&lt;p&gt;因为这样的话，2 个线程并发执行++x，只会有 2 个结果：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;线程 a ++x，然后线程 b ++x，结果是 2。&lt;/li&gt; 
 &lt;li&gt;线程 b ++x，然后线程 a ++x，结果是 2。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;除此之外，不会出现第三种情况，线程 a、b 孰先孰后，取决于线程调度，但不影响最终结果。&lt;/p&gt; 
&lt;p&gt;Linux 操作系统和 C/C++编程语言都提供了整型原子变量，原子变量的自增、自减等操作都是原子的，操作是原子性的，意味着它是一个不可细分的操作整体，原子变量的用户观察它，只能看到未完成和已完成 2 种状态，看不到半完成状态。&lt;/p&gt; 
&lt;p&gt;如何保证原子性是实现层面的问题，应用程序员只需要从逻辑上理解原子性，并能恰当的使用它就行了。原子变量非常适用于计数、产生序列号这样的应用场景。&lt;/p&gt; 
&lt;h3&gt;2.6 锁&lt;/h3&gt; 
&lt;p&gt;前面举了很多例子，阐述多线程不加同步并发访问数据会引起什么问题，下面讲解用锁如何做同步。&lt;/p&gt; 
&lt;h4&gt;2.6.1 互斥锁&lt;/h4&gt; 
&lt;p&gt;针对线程 1 write_msg() + 线程 2 read_msg() 的问题，如果能让线程 1 write_msg() 的过程中，线程 2 不能 read_msg()，那就不会有问题。这个要求，其实就是要让多个线程互斥访问共享资源。&lt;/p&gt; 
&lt;p&gt;互斥锁就是能满足上述要求的同步机制，互斥是排他的意思，它可以确保在同一时间，只能有一个线程对那个共享资源进行访问。&lt;/p&gt; 
&lt;p&gt;互斥锁有且只有 2 种状态：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;已加锁（locked）状态&lt;/li&gt; 
 &lt;li&gt;未加锁（unlocked）状态&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;互斥锁提供加锁和解锁两个接口：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;加锁（acquire）&lt;/strong&gt;：当互斥锁处于未加锁状态时，则加锁成功（把锁设置为已加锁状态），并返回；当互斥锁处于已加锁状态时，那么试图对它加锁的线程会被阻塞，直到该互斥量被解锁。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;解锁（release）&lt;/strong&gt;：通过把锁设置为未加锁状态释放锁，其他因为申请加锁而陷入等待的线程，将获得执行机会。如果有多个等待线程，只有一个会获得锁而继续执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们为某个共享资源配置一个互斥锁，使用互斥锁做线程同步，那么所有线程对该资源的访问，都需要遵从&quot;加锁、访问、解锁&quot;的三步：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;DataType shared_resource;
Mutex shared_resource_mutex;

void shared_resource_visitor1() {
    // step1: 加锁
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation1
    // step3: 解锁
    shared_resource_mutex.unlock();
}

void shared_resource_visitor2() {
    // step1: 加锁
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation2
    // step3: 解锁
    shared_resource_mutex.unlock();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;shared_resource_visitor1() 和 shared_resource_visitor2() 代表对共享资源的不同操作，多个线程可能调用同一个操作函数，也可能调用不同的操作函数。&lt;/p&gt; 
&lt;p&gt;假设线程 1 执行 shared_resource_visitor1()，该函数在访问数据之前，申请加锁，如果互斥锁已经被其他线程加锁，则调用该函数的线程会阻塞在加锁操作上，直到其他线程访问完数据，释放（解）锁，阻塞在加锁操作的线程 1 才会被唤醒，并尝试加锁：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果没有其他线程申请该锁，那么线程 1 加锁成功，获得了对资源的访问权，完成操作后，释放锁。&lt;/li&gt; 
 &lt;li&gt;如果其他线程也在申请该锁，那么： 
  &lt;ul&gt; 
   &lt;li&gt;如果其他线程抢到了锁，那么线程 1 继续阻塞。&lt;/li&gt; 
   &lt;li&gt;如果线程 1 抢到了该锁，那么线程 1 将访问资源，再释放锁，其他竞争该锁的线程得以有机会继续执行。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如果不能承受加锁失败而陷入阻塞的代价，可以调用互斥量的 try_lock() 接口，它在加锁失败后会立即返回。&lt;/p&gt; 
&lt;p&gt;注意：在访问资源前申请锁访问后释放锁，是一个编程契约，通过遵守契约而获得数据一致性的保障，它并非一种硬性的限制，即如果别的线程遵从三步曲，而另一个线程不遵从这种约定，代码能通过编译且程序能运行，但结果可能是错的。&lt;/p&gt; 
&lt;h4&gt;2.6.2 读写锁&lt;/h4&gt; 
&lt;p&gt;读写锁跟互斥锁类似，也是申请锁的时候，如果不能得到满足则阻塞，但读写锁跟互斥锁也有不同，读写锁有 3 个状态：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;已加读锁状态&lt;/li&gt; 
 &lt;li&gt;已加写锁状态&lt;/li&gt; 
 &lt;li&gt;未加锁状态&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;对应 3 个状态，读写锁有 3 个接口：加读锁，加写锁，解锁：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;加读锁：如果读写锁处于已加写锁状态，则申请锁的线程阻塞；否则把锁设置为已加读锁状态并成功返回。&lt;/li&gt; 
 &lt;li&gt;加写锁：如果读写锁处于未加锁状态，则把锁设置为已加写锁状态并成功返回；否则阻塞。&lt;/li&gt; 
 &lt;li&gt;解锁：把锁设置为未加锁状态后返回。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;读写锁提升了线程的并行度，可以提升吞吐。它可以让多个读线程同时读共享资源，而写线程访问共享资源的时候，其他线程不能执行，所以，读写锁适合对共享资源访问&quot;读大于写&quot;的场合。读写锁也叫&quot;共享互斥锁&quot;，多个读线程可以并发访问同一资源，这对应共享的概念，而写线程是互斥的，写线程访问资源的时候，其他线程无论读写，都不可以进入临界代码区。&lt;/p&gt; 
&lt;p&gt;考虑一个场景：如果有线程 1、2、3 共享资源 x，读写锁 rwlock 保护资源，线程 1 读访问某资源，然后线程 2 以写的形式访问同一资源 x，因为 rwlock 已经被加了读锁，所以线程 2 被阻塞，然后过了一段时间，线程 3 也读访问资源 x，这时候线程 3 可以继续执行，因为读是共享的，然后线程 1 读访问完成，线程 3 继续访问，过了一段时间，在线程 3 访问完成前，线程 1 又申请读资源，那么它还是会获得访问权，但是写资源的线程 2 会一直被阻塞。&lt;/p&gt; 
&lt;p&gt;为了避免共享的读线程饿死写线程，通常读写锁的实现，会给写线程优先权，当然这处决于读写锁的实现，作为读写锁的使用方，理解它的语义和使用场景就够了。&lt;/p&gt; 
&lt;h4&gt;2.6.3 自旋锁&lt;/h4&gt; 
&lt;p&gt;自旋锁（Spinlock）的接口跟互斥量差不多，但实现原理不同。线程在 acquire 自旋锁失败的时候，它不会主动让出 CPU 从而进入睡眠状态，而是会忙等，它会紧凑的执行测试和设置 (Test-And-Set) 指令，直到 TAS 成功，否则就一直占着 CPU 做 TAS。&lt;/p&gt; 
&lt;p&gt;自旋锁对使用场景有一些期待，它期待 acquire 自旋锁成功后很快会 release 锁，线程运行临界区代码的时间很短，访问共享资源的逻辑简单，这样的话，别的 acquire 自旋锁的线程只需要忙等很短的时间就能获得自旋锁，从而避免被调度走陷入睡眠，它假设自旋的成本比调度的低，它不愿耗费时间在线程调度上（线程调度需要保存和恢复上下文需要耗费 CPU）。&lt;/p&gt; 
&lt;p&gt;内核态线程很容易满足这些条件，因为运行在内核态的中断处理函数里可以通过关闭调度，从而避免 CPU 被抢占，而且有些内核态线程调用的处理函数不能睡眠，只能使用自旋锁。&lt;/p&gt; 
&lt;p&gt;而运行在用户态的应用程序，则推荐使用互斥锁等睡眠锁。因为运行在用户态应用程序，虽然很容易满足临界区代码简短，但持有锁时间依然可能很长。在分时共享的多任务系统上、当用户态线程的时间配额耗尽，或者在支持抢占式的系统上、有更高优先级的任务就绪，那么持有自旋锁的线程就会被系统调度走，这样持有锁的过程就有可能很长，而忙等自旋锁的其他线程就会白白消耗 CPU 资源，这样的话，就跟自旋锁的理念相背。&lt;/p&gt; 
&lt;p&gt;Linux 系统优化过后的 mutex 实现，在加锁的时候会先做有限次数的自旋，只有有限次自旋失败后，才会进入睡眠让出 CPU，所以，实际使用中，它的性能也足够好。此外，自旋锁必须在多 CPU 或者多 Core 架构下，试想如果只有一个核，那么它执行自旋逻辑的时候，别的线程没有办法运行，也就没有机会释放锁。&lt;/p&gt; 
&lt;h4&gt;2.6.4 锁的粒度&lt;/h4&gt; 
&lt;p&gt;合理设置锁的粒度，粒度太大会降低性能，太小会增加代码编写复杂度。&lt;/p&gt; 
&lt;h4&gt;2.6.5 锁的范围&lt;/h4&gt; 
&lt;p&gt;锁的范围要尽量小，最小化持有锁的时间。&lt;/p&gt; 
&lt;h4&gt;2.6.6 死锁&lt;/h4&gt; 
&lt;p&gt;程序出现死锁有两种典型原因：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ABBA 锁&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假设程序中有 2 个资源 X 和 Y，分别被锁 A 和 B 保护，线程 1 持有锁 A 后，想要访问资源 Y，而访问资源 Y 之前需要申请锁 B，而如果线程 2 正持有锁 B，并想要访问资源 X，为了访问资源 X，所以线程 2 需要申请锁 A。线程 1 和线程 2 分别持有锁 A 和 B，并都希望申请对方持有的锁，因为线程申请对方持有的锁，得不到满足，所以便会陷入等待，也就没有机会释放自己持有的锁，对方执行流也就没有办法继续前进，导致相持不下，无限互等，进而死锁。&lt;/p&gt; 
&lt;p&gt;上述的情况似乎很明显，但如果代码量很大，有时候，这种死锁的逻辑不会这么浅显，它被复杂的调用逻辑所掩盖，但抽茧剥丝，最根本的逻辑就是上面描述的那样。这种情况叫 ABBA 锁，既某个线程持有 A 锁申请 B 锁，而另一个线程持有 B 锁申请 A 锁。这种情况可以通过 try lock 实现，尝试获取锁，如果不成功，则释放自己持有的锁，而不一根筋下去。另一种解法就是锁排序，对 A/B 两把锁的加锁操作，都遵从同样的顺序（比如先 A 后 B），也能避免死锁。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;自死锁&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于不支持重复加锁的锁，如果线程持有某个锁，而后又再次申请锁，因为该锁已经被自己持有，再次申请锁必然得不到满足，从而导致死锁。&lt;/p&gt; 
&lt;h3&gt;2.7 条件变量&lt;/h3&gt; 
&lt;p&gt;条件变量常用于生产者消费者模式，需配合互斥量使用。&lt;/p&gt; 
&lt;p&gt;假设你要编写一个网络处理程序，I/O 线程从套接字接收字节流，反序列化后产生一个个消息（自定义协议），然后投递到一个消息队列，一组工作线程负责从消息队列取出并处理消息。这是典型的生产者-消费者模式，I/O 线程生产消息（往队列 put），Work 线程消费消息（从队列 get），I/O 线程和 Work 线程并发访问消息队列，显然，消息队列是竞争资源，需要同步。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/fb99fb443c76b32cb536646eda91dfa731825.png&quot; alt=&quot;proceduer-consumer&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以给队列配置互斥锁，put 和 get 操作前都先加锁，操作完成再解锁。代码差不多是这样的：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void io_thread() {
    while (1) {
        Msg* msg = read_msg_from_socket();
        msg_queue_mutex.lock();
        msg_queue.put(msg);
        msg_queue_mutex.unlock();
    }
}

void work_thread() {
    while (1) {
        msg_queue_mutex.lock();
        Msg* msg = msg_queue.get();
        msg_queue_mutex.unlock();
        if (msg != nullptr) {
            process(msg);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;work 线程组的每个线程都忙于检查消息队列是否有消息，如果有消息就取一个出来，然后处理消息，如果没有消息就在循环里不停检查，这样的话，即使负载很轻，但 work_thread 还是会消耗大量的 CPU 时间。&lt;/p&gt; 
&lt;p&gt;我们当然可以在两次查询之间加入短暂的 sleep，从而让出 cpu，但是这个睡眠的时间设置为多少合适呢？设置长了的话，会出现消息到来得不到及时处理（延迟上升）；设置太短了，还是无辜消耗了 CPU 资源，这种不断问询的方式在编程上叫轮询。&lt;/p&gt; 
&lt;p&gt;轮询行为逻辑上，相当于你在等一个投递到楼下小邮局的包裹，你下楼查验没有之后就上楼回房间，然后又下楼查验，你不停的上下楼查验，其实大可不必如此，何不等包裹到达以后，让门衞打电话通知你去取呢？&lt;/p&gt; 
&lt;p&gt;条件变量提供了一种类似通知 notify 的机制，它让两类线程能够在一个点交汇。条件变量能够让线程等待某个条件发生，条件本身受互斥锁保护，因此条件变量必须搭配互斥锁使用，锁保护条件，线程在改变条件前先获得锁，然后改变条件状态，再解锁，最后发出通知，等待条件的睡眠中的线程在被唤醒前，必须先获得锁，再判断条件状态，如果条件不成立，则继续转入睡眠并释放锁。&lt;/p&gt; 
&lt;p&gt;对应到上面的例子，工作线程等待的条件是消息队列有消息（非空），用条件变量改写上面的代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void io_thread() {
    while (1) {
        Msg* msg = read_msg_from_socket();
        {
            std::lock_guard&amp;lt;std::mutex&amp;gt; lock(msg_queue_mutex);
            msg_queue.push_back(msg);
        }
        msg_queue_not_empty.notify_all();
    }
}

void work_thread() {
    while (1) {
        Msg* msg = nullptr;
        {
            std::unique_lock&amp;lt;std::mutex&amp;gt; lock(msg_queue_mutex);
            msg_queue_not_empty.wait(lock, []{ return !msg_queue.empty(); });
            msg = msg_queue.get();
        }
        process(msg);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;std::lock_guard 是互斥量的一个 RAII 包装类，std::unique_lock 除了会在析构函数自动解锁外，还支持主动 unlock()。&lt;/p&gt; 
&lt;p&gt;生产者在往 msg_queue 投递消息的时候，需要对 msg_queue 加锁，通知 work 线程的代码可以放在解锁之后，等待 msg_queue_not_empty 条件必须受 msg_queue_mutex 保护，wait 的第二个参数是一个 lambda 表达式，因为会有多个 work 线程被唤醒，线程被唤醒后，会重新获得锁，检查条件，如果不成立，则再次睡眠。条件变量的使用需要非常谨慎，否则容易出现不能唤醒的情况。&lt;/p&gt; 
&lt;p&gt;C 语言的条件变量、Posix 条件变量的编程接口跟 C++的类似，概念上是一致的，故在此不展开介绍。&lt;/p&gt; 
&lt;h3&gt;2.8 lock-free 和无锁数据结构&lt;/h3&gt; 
&lt;h4&gt;2.8.1 锁同步的问题&lt;/h4&gt; 
&lt;p&gt;线程同步分为阻塞型同步和非阻塞型同步。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;互斥量、信号、条件变量这些系统提供的机制都属于阻塞型同步，在争用资源的时候，会导致调用线程阻塞。&lt;/li&gt; 
 &lt;li&gt;非阻塞型同步是指在无锁的情况下，通过某种算法和技术手段实现不用阻塞而同步。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;锁是阻塞同步机制，阻塞同步机制的缺陷是可能挂起你的程序，如果持有锁的线程崩溃或者 hang 住，则锁永远得不到释放，而其他线程则将陷入无限等待；另外，它也可能导致优先级倒转等问题。所以，我们需要 lock-free 这类非阻塞的同步机制。&lt;/p&gt; 
&lt;h4&gt;2.8.2 什么是 lock-free&lt;/h4&gt; 
&lt;p&gt;lock-free 没有锁同步的问题，所有线程无阻碍的执行原子指令，而不是等待。比如一个线程读 atomic 类型变量，一个线程写 atomic 变量，它们没有任何等待，硬件原子指令确保不会出现数据不一致，写入数据不会出现半完成，读取数据也不会读一半。&lt;/p&gt; 
&lt;p&gt;那到底什么是 lock-free？有人说 lock-free 就是不使用 mutex / semaphores 之类的无锁（lock-Less）编程，这句话严格来说并不对。&lt;/p&gt; 
&lt;p&gt;我们先看一下 wiki 对 Lock-free 的描述:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Lock-freedom allows individual threads to starve but guarantees system-wide throughput. An algorithm is lock-free if, when the program threads are run for a sufficiently long time, at least one of the threads makes progress (for some sensible definition of progress). All wait-free algorithms are lock-free. In particular, if one thread is suspended, then a lock-free algorithm guarantees that the remaining threads can still make progress. Hence, if two threads can contend for the same mutex lock or spinlock, then the algorithm is not lock-free. (If we suspend one thread that holds the lock, then the second thread will block.)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;翻译一下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;第 1 段：lock-free 允许单个线程饥饿但保证系统级吞吐。如果一个程序线程执行足够长的时间，那么至少一个线程会往前推进，那么这个算法就是 lock-free 的。&lt;/li&gt; 
 &lt;li&gt;第 2 段：尤其是，如果一个线程被暂停，lock-free 算法保证其他线程依然能够往前推进。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;第 1 段给 lock-free 下定义，第 2 段则是对 lock-free 作解释：如果 2 个线程竞争同一个互斥锁或者自旋锁，那它就不是 lock-free 的；因为如果暂停（Hang）持有锁的线程，那么另一个线程会被阻塞。&lt;/p&gt; 
&lt;p&gt;wiki 的这段描述很抽象，它不够直观，稍微再解释一下：lock-free 描述的是代码逻辑的属性，不使用锁的代码，大部分具有这种属性。大家经常会混淆这 lock-free 和无锁这 2 个概念。其实，lock-free 是对代码（算法）性质的描述，是属性；而无锁是说代码如何实现，是手段。&lt;/p&gt; 
&lt;p&gt;lock-free 的关键描述是：如果一个线程被暂停，那么其他线程应能继续前进，它需要有系统级（system-wide）的吞吐。&lt;/p&gt; 
&lt;p&gt;如图，两个线程在时间线上，至少有一个线程处于 running 状态。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/5b45d715f8b8e6576d9e841a9a4c4bd1217086.png&quot; alt=&quot;Lock-free&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们从反面举例来看，假设我们要借助锁实现一个无锁队列，我们可以直接使用线程不安全的 std::queue + std::mutex 来做：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;template &amp;lt;typename T&amp;gt;
class Queue {
public:
    void push(const T&amp;amp; t) {
        q_mutex.lock();
        q.push(t);
        q_mutex.unlock();
    }
private:
    std::queue&amp;lt;T&amp;gt; q;
    std::mutex q_mutex;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果有线程 A/B/C 同时执行 push 方法，最先进入的线程 A 获得互斥锁。线程 B 和 C 因为获取不到互斥锁而陷入等待。这个时候，线程 A 如果因为某个原因（如出现异常，或者等待某个资源）而被永久挂起，那么同样执行 push 的线程 B/C 将被永久挂起，系统整体（system-wide）没法推进，而这显然不符合 lock-free 的要求。因此：所有基于锁（包括 spinlock）的并发实现，都不是 lock-free 的。&lt;/p&gt; 
&lt;p&gt;因为它们都会遇到同样的问题：即如果永久暂停当前占有锁的线程/进程的执行，将会阻塞其他线程/进程的执行。而对照 lock-free 的描述，它允许部分 process（理解为执行流）饿死但必须保证整体逻辑的持续前进，基于锁的并发显然是违背 lock-free 要求的。&lt;/p&gt; 
&lt;h4&gt;2.8.3 CAS loop 实现 Lock-free&lt;/h4&gt; 
&lt;p&gt;Lock-Free 同步主要依靠 CPU 提供的 read-modify-write 原语，著名的&quot;比较和交换&quot;CAS（Compare And Swap）在 X86 机器上是通过 cmpxchg 系列指令实现的原子操作，CAS 逻辑上用代码表达是这样的：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bool CAS(T* ptr, T expect_value, T new_value) {
   if (*ptr != expect_value) {
      return false;
   }
   *ptr = new_value;
   return true;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CAS 接受 3 个参数：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;内存地址&lt;/li&gt; 
 &lt;li&gt;期望值，通常传第一个参数所指内存地址中的旧值&lt;/li&gt; 
 &lt;li&gt;新值&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;逻辑描述：CAS 比较内存地址中的值和期望值，如果不相同就返回失败，如果相同就将新值写入内存并返回成功。&lt;/p&gt; 
&lt;p&gt;当然这个 C 函数描述的只是 CAS 的逻辑，这个函数操作不是原子的，因为它可以划分成几个步骤：读取内存值、判断、写入新值，各步骤之间是可以插入其他操作的。不过前面讲了，原子指令相当于把这些步骤打包，它可能是通过 lock; cmpxchg 指令实现的，但那是实现细节，程序员更应该注重在逻辑上理解它的行为。&lt;/p&gt; 
&lt;p&gt;通过 CAS 实现 Lock-free 的代码通常借助循环，代码如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;do {
    T expect_value = *ptr;
} while (!CAS(ptr, expect_value, new_value));
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;创建共享数据的本地副本：expect_value。&lt;/li&gt; 
 &lt;li&gt;根据需要修改本地副本，从 ptr 指向的共享数据里 load 后赋值给 expect_value。&lt;/li&gt; 
 &lt;li&gt;检查共享的数据跟本地副本是否相等，如果相等，则把新值复制到共享数据。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;第三步是关键，虽然 CAS 是原子的，但加载 expect_value 跟 CAS 这 2 个步骤，并不是原子的。所以，我们需要借助循环，如果 ptr 内存位置的值没有变（*ptr == expect_value），那就存入新值返回成功；否则说明加载 expect_value 后，ptr 指向的内存位置被其他线程修改了，这时候就返回失败，重新加载 expect_value，重试，直到成功为止。&lt;/p&gt; 
&lt;p&gt;CAS loop 支持多线程并发写，这个特点太有用了，因为多线程同步，很多时候都面临多写的问题，我们可以基于 CAS 实现 Fetch-and-add(FAA) 算法，它看起来像这样：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;T faa(T&amp;amp; t) {
    T temp = t;
    while (!compare_and_swap(x, temp, temp + 1));
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;第一步加载共享数据的值到 temp，第二步比较+存入新值，直到成功。&lt;/p&gt; 
&lt;h4&gt;2.8.4 无锁数据结构：lock-free stack&lt;/h4&gt; 
&lt;p&gt;无锁数据结构是通过非阻塞算法而非锁保护共享数据，非阻塞算法保证竞争共享资源的线程，不会因为互斥而让它们的执行无限期暂停；无阻塞算法是 lock-free 的，因为无论如何调度都能确保有系统级的进度。wiki 定义如下：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A non-blocking algorithm ensures that threads competing for a shared resource do not have their execution indefinitely postponed by mutual exclusion. A non-blocking algorithm is lock-free if there is guaranteed system-wide progress regardless of scheduling.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下面是 C++ atomic compare_exchange_weak() 实现的一个 lock-free 堆栈（from CppReference）：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;template &amp;lt;typename T&amp;gt;
struct node {
    T data;
    node* next;
    node(const T&amp;amp; data) : data(data), next(nullptr) {}
};
 
template &amp;lt;typename T&amp;gt;
class stack {
    std::atomic&amp;lt;node&amp;lt;T&amp;gt;*&amp;gt; head;
public:
    void push(const T&amp;amp; data) {
      node&amp;lt;T&amp;gt;* new_node = new node&amp;lt;T&amp;gt;(data);
      new_node-&amp;gt;next = head.load(std::memory_order_relaxed);
      while (!head.compare_exchange_weak(new_node-&amp;gt;next, new_node,
                                        std::memory_order_release,
                                        std::memory_order_relaxed));
    }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;代码解析：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;节点（node）保存 T 类型的数据 data，并且持有指向下一个节点的指针。&lt;/li&gt; 
 &lt;li&gt;std::atomic&amp;lt;node*&amp;gt;类型表明 atomic 里放置的是 Node 的指针，而非 Node 本身，因为指针在 64 位系统上是 8 字节，等于机器字长，再长没法保证原子性。&lt;/li&gt; 
 &lt;li&gt;stack 类包含 head 成员，head 是一个指向头结点的指针，头结点指针相当于堆顶指针，刚开始没有节点，head 为 NULL。&lt;/li&gt; 
 &lt;li&gt;push 函数里，先根据 data 值创建新节点，然后要把它放到堆顶。&lt;/li&gt; 
 &lt;li&gt;因为是用链表实现的栈，所以，如果新节点要成为新的堆顶（相当于新节点作为新的头结点插入），那么新节点的 next 域要指向原来的头结点，并让 head 指向新节点。&lt;/li&gt; 
 &lt;li&gt;new_node-&amp;gt;next = head.load 把新节点的 next 域指向原头结点，然后 head.compare_exchange_weak(new_node-&amp;gt;next, new_node)，让 head 指向新节点。&lt;/li&gt; 
 &lt;li&gt;C++ atomic 的 compare_exchange_weak() 跟上述的 CAS 稍有不同，head.load() 不等于 new_node-&amp;gt;next 的时候，它会把 head.load() 的值重新加载到 new_node-&amp;gt;next。&lt;/li&gt; 
 &lt;li&gt;所以，在加载 head 值和 CAS 之间，如果其他线程调用 push 操作，改变了 head 的值，那没有关系，该线程的本次 cas 失败，下次重试便可以了。&lt;/li&gt; 
 &lt;li&gt;多个线程同时 push 时，任一线程在任意步骤阻塞/挂起，其他线程都会继续执行并最终返回，无非就是多执行几次 while 循环。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这样的行为逻辑显然符合 lock-free 的定义，注意用 CAS+Loop 实现自旋锁不符合 lock-free 的定义，注意区分。&lt;/p&gt; 
&lt;h3&gt;2.9 程序序：Program Order&lt;/h3&gt; 
&lt;p&gt;对单线程程序而言，代码会一行行顺序执行，就像我们编写的程序的顺序那样。比如：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;会先执行 a=1 再执行 b=2，从程序角度看到的代码行依次执行叫程序序，我们在此基础上构建软件，并以此作为讨论的基础。&lt;/p&gt; 
&lt;h3&gt;2.10 内存序：Memory Order&lt;/h3&gt; 
&lt;p&gt;与程序序相对应的内存序，是指从某个角度观察到的对于内存的读和写所真正发生的顺序。内存操作顺序并不唯一，在一个包含 core0 和 core1 的 CPU 中，core0 和 core1 有着各自的内存操作顺序，这两个内存操作顺序不一定相同。从包含多个 Core 的 CPU 的视角看到的全局内存操作顺序跟单 core 视角看到的内存操作顺序亦不同，而这种不同，对于有些程序逻辑而言，是不可接受的，例如：&lt;/p&gt; 
&lt;p&gt;程序序要求 a = 1 在 b = 2 之前执行，但内存操作顺序可能并非如此，对 a 赋值 1 并不确保发生在对 b 赋值 2 之前，这是因为：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果编译器认为对 b 赋值没有依赖对 a 赋值，那它完全可能在编译期调整编译后的汇编指令顺序。&lt;/li&gt; 
 &lt;li&gt;即使编译器不做调整，到了执行期，也有可能对 b 的赋值先于对 a 赋值执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;虽然对一个 Core 而言，如上所述，这个 Core 观察到的内存操作顺序不一定符合程序序，但内存操作序和程序序必定产生相同的结果，无论在单 Core 上对 a、b 的赋值哪个先发生，结果上都是 a 被赋值为 1、b 被赋值为 2，如果单核上乱序执行会影响结果，那编译器的指令重排和 CPU 乱序执行便不会发生，硬件会提供这项保证。&lt;/p&gt; 
&lt;p&gt;但多核系统，硬件不提供这样的保证，多线程程序中，每个线程所工作的 Core 观察到的不同内存操作序，以及这些顺序与全局内存序的差异，常常导致多线程同步失败，所以，需要有同步机制确保内存序与程序序的一致，内存屏障（Memory Barrier）的引入，就是为了解决这个问题，它让不同的 Core 之间，以及 Core 与全局内存序达成一致。&lt;/p&gt; 
&lt;h3&gt;2.11 乱序执行：Out-of-order Execution&lt;/h3&gt; 
&lt;p&gt;乱序执行会引起内存顺序跟程序顺序不同，乱序执行的原因是多方面的，比如编译器指令重排、超标量指令流水线、预测执行、Cache-Miss 等。内存操作顺序无法精确匹配程序顺序，这有可能带来混乱，既然有副作用，那为什么还需要乱序执行呢？答案是为了性能。&lt;/p&gt; 
&lt;p&gt;我们先看看没有乱序执行之前，早期的有序处理器（In-order Processors）是怎么处理指令的？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;指令获取，从代码节内存区域加载指令到 I-Cache&lt;/li&gt; 
 &lt;li&gt;译码&lt;/li&gt; 
 &lt;li&gt;如果指令操作数可用（例如操作数位于寄存器中），则分发指令到对应功能模块中；如果操作数不可用，通常是需要从内存加载，则处理器会 stall，一直等到它们就绪，直到数据被加载到 Cache 或拷贝进寄存器&lt;/li&gt; 
 &lt;li&gt;指令被功能单元执行&lt;/li&gt; 
 &lt;li&gt;功能单元将结果写回寄存器或内存位置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;乱序处理器（Out-of-order Processors）又是怎么处理指令的呢？&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;指令获取，从代码节内存区域加载指令到 I-Cache&lt;/li&gt; 
 &lt;li&gt;译码&lt;/li&gt; 
 &lt;li&gt;分发指令到指令队列&lt;/li&gt; 
 &lt;li&gt;指令在指令队列中等待，一旦操作数就绪，指令就离开指令队列，那怕它之前的指令未被执行（乱序）&lt;/li&gt; 
 &lt;li&gt;指令被派往功能单元并被执行&lt;/li&gt; 
 &lt;li&gt;执行结果放入队列（Store Buffer），而不是直接写入 Cache&lt;/li&gt; 
 &lt;li&gt;只有更早请求执行的指令结果写入 cache 后，指令执行结果才写入 Cache，通过对指令结果排序写入 cache，使得执行看起来是有序的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;指令乱序执行是结果，但原因并非只有 CPU 的乱序执行，而是由两种因素导致：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;编译期&lt;/strong&gt;：指令重排（编译器），编译器会为了性能而对指令重排，源码上先后的两行，被编译器编译后，可能调换指令顺序，但编译器会基于一套规则做指令重排，有明显依赖的指令不会被随意重排，指令重排不能破坏程序逻辑。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;运行期&lt;/strong&gt;：乱序执行（CPU），CPU 的超标量流水线、以及预测执行、Cache-Miss 等都有可能导致指令乱序执行，也就是说，后面的指令有可能先于前面的指令执行。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2.12 Store Buffer&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;为什么需要 Store Buffer？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑下面的代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void set_a() {
    a = 1;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;假设运行在 core0 上的 set_a() 对整型变量 a 赋值 1，计算机通常不会直接写穿通到内存，而是会在 Cache 中修改对应 Cache Line&lt;/li&gt; 
 &lt;li&gt;如果 Core0 的 Cache 里没有 a，赋值操作（store）会造成 Cache Miss&lt;/li&gt; 
 &lt;li&gt;Core0 会 stall 在等待 Cache 就绪（从内存加载变量 a 到对应的 Cache Line），但 Stall 会损害 CPU 性能，相当于 CPU 在这里停顿，白白浪费着宝贵的 CPU 时间&lt;/li&gt; 
 &lt;li&gt;有了 Store Buffer，当变量在 Cache 中没有就位的时候，就先 Buffer 住这个 Store 操作，而 Store 操作一旦进入 Store Buffer，core 便认为自己 Store 完成，当随后 Cache 就位，store 会自动写入对应 Cache。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所以，我们需要 Store Buffer，每个 Core 都有独立的 Store Buffer，每个 Core 都访问私有的 Store Buffer，Store Buffer 帮助 CPU 遮掩了 Store 操作带来的延迟。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Store Buffer 会带来什么问题？&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
assert(a == 1);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;上面的代码，断言 a==1 的时候，需要读（load）变量 a 的值，而如果 a 在被赋值前就在 Cache 中，就会从 Cache 中读到 a 的旧值（可能是 1 之外的其他值），所以断言就可能失败。但这样的结果显然是不能接受的，它违背了最直观的程序顺序性。&lt;/p&gt; 
&lt;p&gt;问题出在变量 a 除保存在内存外，还有 2 份拷贝：一份在 Store Buffer 里，一份在 Cache 里；如果不考虑这 2 份拷贝的关系，就会出现数据不一致。那怎么修复这个问题呢？&lt;/p&gt; 
&lt;p&gt;可以通过在 Core Load 数据的时候，先检查 Store Buffer 中是否有悬而未决的 a 的新值，如果有，则取新值；否则从 cache 取 a 的副本。这种技术在多级流水线 CPU 设计的时候就经常使用，叫 Store Forwarding。有了 Store Buffer Forwarding，就能确保单核程序的执行遵从程序顺序性，但多核还是有问题，让我们考查下面的程序：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;多核内存序问题&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;int a = 0; // 被 CPU1 Cache
int b = 0; // 被 CPU0 Cache

// CPU0 执行
void x() {
    a = 1;
    b = 2;
}

// CPU1 执行
void y() {
    while (b == 0);
    assert(a == 1);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;假设 a 和 b 都被初始化为 0；CPU0 执行 x() 函数，CPU1 执行 y() 函数；变量 a 在 CPU1 的 local Cache 里，变量 b 在 CPU0 的 local Cache 里。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU0 执行 a = 1 的时候，因为 a 不在 CPU0 的 local cache，CPU0 会把 a 的新值 1 写入 Store Buffer 里，并发送 Read Invalidate 消息给其他 CPU。&lt;/li&gt; 
 &lt;li&gt;CPU1 执行 while (b == 0)，因为 b 不在 CPU1 的 local cache 里，CPU1 会发送 Read 消息去其他 CPU 获取 b 的值。&lt;/li&gt; 
 &lt;li&gt;CPU0 执行 b = 2，因为 b 在 CPU0 的 local Cache，所以直接更新 local cache 中 b 的副本。&lt;/li&gt; 
 &lt;li&gt;CPU0 收到 CPU1 发来的 read 消息，把 b 的新值 2 发送给 CPU1；同时存放 b 的 Cache Line 的状态被设置为 Shared，以反应 b 同时被 CPU0 和 CPU1 cache 住的事实。&lt;/li&gt; 
 &lt;li&gt;CPU1 收到 b 的新值 2 后结束循环，继续执行 assert(a == 1)，因为此时 local Cache 中的 a 值为 0，所以断言失败。&lt;/li&gt; 
 &lt;li&gt;CPU1 收到 CPU0 发来的 Read Invalidate 后，更新 a 的值为 1，但为时已晚，程序在上一步已经崩了（assert 失败）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;怎么办？答案留到内存屏障一节揭晓。&lt;/p&gt; 
&lt;h3&gt;2.13 Invalidate Queue&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;为什么需要 Invalidate Queue？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当一个变量加载到多个 core 的 Cache，则这个 Cache Line 处于 Shared 状态，如果 Core1 要修改这个变量，则需要通过发送核间消息 Invalidate 来通知其他 Core 把对应的 Cache Line 置为 Invalid，当其他 Core 都 Invalid 这个 CacheLine 后，则本 Core 获得该变量的独占权，这个时候就可以修改它了。&lt;/p&gt; 
&lt;p&gt;收到 Invalidate 消息的 core 需要回 Invalidate ACK，一个个 core 都这样 ACK，等所有 core 都回复完，Core1 才能修改它，这样 CPU 就白白浪费。&lt;/p&gt; 
&lt;p&gt;事实上，其他核在收到 Invalidate 消息后，会把 Invalidate 消息缓存到 Invalidate Queue，并立即回复 ACK，真正 Invalidate 动作可以延后再做，这样一方面因为 Core 可以快速返回别的 Core 发出的 Invalidate 请求，不会导致发生 Invalidate 请求的 Core 不必要的 Stall，另一方面也提供了进一步优化可能，比如在一个 CacheLine 里的多个变量的 Invalidate 可以攒一次做了。&lt;/p&gt; 
&lt;p&gt;但写 Store Buffer 的方式其实是 Write Invalidate，它并非立即写入内存，如果其他核此时从内存读数，则有可能不一致。&lt;/p&gt; 
&lt;h3&gt;2.14 内存屏障&lt;/h3&gt; 
&lt;p&gt;那有没有方法确保对 a 的赋值一定先于对 b 的赋值呢？有，内存屏障被用来提供这个保障。&lt;/p&gt; 
&lt;p&gt;内存屏障（Memory Barrier），也称内存栅栏、屏障指令等，是一类同步屏障指令，是 CPU 或编译器在对内存随机访问的操作中的一个同步点，同步点之前的所有读写操作都执行后，才可以开始执行此点之后的操作。语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。&lt;/p&gt; 
&lt;p&gt;内存屏障，其实就是提供一种机制，确保代码里顺序写下的多行，会按照书写的顺序，被存入内存，主要是解决 Store Buffer 引入导致的写入内存间隙的问题。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void x() {
    a = 1;
    wmb();
    b = 2;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;像上面那样在 a=1 和 b=2 之间插入一条内存屏障语句，就能确保 a=1 先于 b=2 生效，从而解决了内存乱序访问问题，那插入的这句 smp_mb()，到底会干什么呢？&lt;/p&gt; 
&lt;p&gt;回忆前面的流程，CPU0 在执行完 a = 1 之后，执行 smp_mb() 操作，这时候，它会给 Store Buffer 里的所有数据项做一个标记（marked），然后继续执行 b = 2，但这时候虽然 b 在自己的 cache 里，但由于 store buffer 里有 marked 条目，所以，CPU0 不会修改 cache 中的 b，而是把它写入 Store Buffer；所以 CPU0 收到 Read 消息后，会把 b 的 0 值发给 CPU1，所以继续在 while (b) 自旋。&lt;/p&gt; 
&lt;p&gt;简而言之，Core 执行到 write memory barrier（wmb）的时候，如果 Store Buffer 还有悬而未决的 store 操作，则都会被 mark 上，直到被标注的 Store 操作进入内存后，后续的 Store 操作才能被执行，因此 wmb 保障了 barrier 前后操作的顺序，它不关心 barrier 前的多个操作的内存序，以及 barrier 后的多个操作的内存序，是否与 Global Memory Order 一致。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
b = 2;
wmb();
c = 3;
d = 4;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;wmb() 保证&quot;a=1;b=2&quot;发生在&quot;c=3;d = 4&quot;之前，不保证 a = 1 和 b = 2 的内存序，也不保证 c = 3 和 d = 4 的内部序。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Invalidate Queue 的引入的问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;就像引入 Store Buffer 会影响 Store 的内存一致性，Invalidate Queue 的引入会影响 Load 的内存一致性。因为 Invalidate queue 会缓存其他核发过来的消息，比如 Invalidate 某个数据的消息被 delay 处置，导致 core 在 Cache Line 中命中这个数据，而这个 Cache Line 本应该被 Invalidate 消息标记无效。如何解决这个问题呢？&lt;/p&gt; 
&lt;p&gt;一种思路是硬件确保每次 load 数据的时候，需要确保 Invalidate Queue 被清空，这样可以保证 load 操作的强顺序&lt;/p&gt; 
&lt;p&gt;软件的思路，就是仿照 wmb() 的定义，加入 rmb() 约束。rmb() 给我们的 invalidate queue 加上标记。当一个 load 操作发生的时候，之前的 rmb() 所有标记的 invalidate 命令必须全部执行完成，然后才可以让随后的 load 发生。这样，我们就在 rmb() 前后保证了 load 观察到的顺序等同于 global memory order&lt;/p&gt; 
&lt;p&gt;所以，我们可以像下面这样修改代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;a = 1;
wmb();
b = 2;

while(b != 2) {};
rmb();
assert(a == 1);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;系统对内存屏障的支持&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;gcc 编译器在遇到内嵌汇编语句 asm volatile(&quot;&quot; ::: &quot;memory&quot;)，将以此作为一条内存屏障，重排序内存操作，即此语句之前的各种编译优化将不会持续到此语句之后。&lt;/p&gt; 
&lt;p&gt;Linux 内核提供函数 barrier() 用于让编译器保证其之前的内存访问先于其之后的完成。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#define barrier() __asm__ __volatile__(&quot;&quot; ::: &quot;memory&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CPU 内存屏障：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;通用 barrier，保证读写操作有序， mb() 和 smp_mb()&lt;/li&gt; 
 &lt;li&gt;写操作 barrier，仅保证写操作有序，wmb() 和 smp_wmb()&lt;/li&gt; 
 &lt;li&gt;读操作 barrier，仅保证读操作有序，rmb() 和 smp_rmb()&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;为了提高处理器的性能，SMP 中引入了 store buffer(以及对应实现 store buffer forwarding) 和 invalidate queue。&lt;/li&gt; 
 &lt;li&gt;store buffer 的引入导致 core 上的 store 顺序可能不匹配于 global memory 的顺序，对此，我们需要使用 wmb() 来解决。&lt;/li&gt; 
 &lt;li&gt;invalidate queue 的存在导致 core 上观察到的 load 顺序可能与 global memory order 不一致，对此，我们需要使用 rmb() 来解决。&lt;/li&gt; 
 &lt;li&gt;由于 wmb() 和 rmb() 分别只单独作用于 store buffer 和 invalidate queue，因此这两个 memory barrier 共同保证了 store/load 的顺序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;3 伪共享&lt;/h2&gt; 
&lt;p&gt;多个线程同时读写同一个 Cache Line 中的变量、导致 CPU Cache 频繁失效，从而使得程序性能下降的现象称为&lt;strong&gt;伪共享&lt;/strong&gt;（False Sharing）。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const size_t shm_size = 16*1024*1024; //16M
static char shm[shm_size];
std::atomic&amp;lt;size_t&amp;gt; shm_offset{0};

void f() {
    for (;;) {
        auto off = shm_offset.fetch_add(sizeof(long));
        if (off &amp;gt;= shm_size) break;
        *(long*)(shm + off) = off; // 赋值
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;考察上面的程序：shm 是一块 16M 字节的内存，我测试的机器的 L3 Cache 是 32M，16M 字节能确保 shm 在 Cache 里放得下。f() 函数的循环里，视 shm 为 long 类型的数组，依次给每个元素赋值，shm_offset 用于记录偏移位置，shm_offset.fetch_add(sizeof(long)) 原子性的增加 shm_offset 的值（因为 x86_64 系统上 long 的长度为 8，所以 shm_offset 每次增加 8），并返回增加前的值，对 shm 上 long 数组的每个元素赋值后，结束循环从函数返回。&lt;/p&gt; 
&lt;p&gt;因为 shm_offset 是 atomic 类型变量，所以多线程调用 f() 依然能正常工作，虽然多个线程会竞争 shm_offset，但每个线程会排他性的对各 long 元素赋值，多线程并行会加快对 shm 的赋值操作。我们加上多线程调用代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;std::atomic&amp;lt;size_t&amp;gt; step{0};

const int THREAD_NUM = 2;

void work_thread() {
    const int LOOP_N = 10;
    for (int n = 1; n &amp;lt;= LOOP_N; ++n) {
        f();
        ++step;
        while (step.load() &amp;lt; n * THREAD_NUM) {}
        shm_offset = 0;
    }
}

int main() {
    std::thread threads[THREAD_NUM];
    for (int i = 0; i &amp;lt; THREAD_NUM; ++i) {
        threads[i] = std::move(std::thread(work_thread));
    }
    for (int i = 0; i &amp;lt; THREAD_NUM; ++i) {
        threads[i].join();
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;main 函数里启动 2 个工作线程 work_thread。&lt;/li&gt; 
 &lt;li&gt;工作线程对 shm 共计赋值 10 轮，后面的每一轮会访问 Cache 里的 shm 数据，step 用于 work_thread 之间每一轮的同步。&lt;/li&gt; 
 &lt;li&gt;工作线程调用完 f() 后会增加 step，等 2 个工作线程都调用完之后，step 的值增加到 n * THREAD_NUM 后，while() 会结束循环，重置 shm_offset，重新开始新一轮对 shm 的赋值。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/a74220a3c91fffad017e1ca8b3b02d28157434.png&quot; alt=&quot;false-sharing-1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;编译后执行上面的程序，产生如下的结果：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;time ./a.out

real 0m3.406s
user 0m6.740s
sys 0m0.040s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;time 命令用于时间测量，a.out 程序运行完成后会打印耗时，real 列显式耗时 3.4 秒。&lt;/p&gt; 
&lt;h3&gt;3.1 改进版 f_fast&lt;/h3&gt; 
&lt;p&gt;我们稍微修改一下 f 函数，改进版 f 函数取名 f_fast：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void f_fast() {
    for (;;) {
        const long inner_loop = 16;
        auto off = shm_offset.fetch_add(sizeof(long) * inner_loop);
        for (long j = 0; j &amp;lt; inner_loop; ++j) {
            if (off &amp;gt;= shm_size) return;
            *(long*)(shm + off) = j;
            off += sizeof(long);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;for 循环里，shm_offset 不再是每次增加 8 字节（sizeof(long)），而是 8*16=128 字节，然后在内层的循环里，依次对 16 个 long 连续元素赋值，然后下一轮循环又再次增加 128 字节，直到完成对 shm 的赋值。如图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/3a6d828073f5cd09877a906edbb5e8c3240113.png&quot; alt=&quot;no-false-sharing&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;编译后重新执行程序，结果显示耗时降低到 0.06 秒，对比前一种耗时 3.4 秒，f_fast 性能提升明显。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;time ./a.out

real 0m0.062s
user 0m0.110s
sys 0m0.012s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;f 和 f_fast 的行为差异&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;shm 数组总共有 2M 个 long 元素，因为 16M / sizeof(long) 得 2M：&lt;/p&gt; 
&lt;p&gt;1、f() 函数行为逻辑&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;线程 1 和线程 2 的 work_thread 里会交错地对 shm 元素赋值，shm 的 2M 个 long 元素，会顺序的一个接一个的派给 2 个线程去赋值。&lt;/li&gt; 
 &lt;li&gt;可能的行为：元素 1 由线程 1 赋值，元素 2 由线程 2 赋值，然后元素 3 和元素 4 由线程 1 赋值，然后元素 5 又由线程 2 赋值...&lt;/li&gt; 
 &lt;li&gt;每次分派元素的时候，shm_offset 都会 atomic 的增加 8 字节，所以不会出现 2 个线程给同 1 个元素赋值的情况。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2、f_fast() 函数行为逻辑&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;每次派元素的时候，shm_offset 原子性的增加 128 字节（16 个元素）。&lt;/li&gt; 
 &lt;li&gt;这 16 个字节作为一个整体，派给线程 1 或者线程 2；虽然线程 1 和线程 2 还是会交错的操作 shm 元素，但是以 16 个元素（128 字节）为单元，这 16 个连续的元素不会被分开派发给不同线程。&lt;/li&gt; 
 &lt;li&gt;一次派发的 16 个元素，会在一个线程里被一个接着一个的赋值（内部循环里）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3.2 为什么 f_fast 更快&lt;/h3&gt; 
&lt;p&gt;第一眼感觉是 f_fast() 里 shm_offset.fetch_add() 调用频次降低到了原来的 1/16，有理由怀疑是原子变量的竞争减少导致程序执行速度加快。为了验证，让我们在内层的循环里加一个原子变量 test 的 fetch_add，test 原子变量的竞争会像 f() 函数里 shm_offset.fetch_add() 一样激烈，修改后的 f_fast 代码变成下面这样：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;void f_fast() {
    for (;;) {
        const long inner_loop = 16;
        auto off = shm_offset.fetch_add(sizeof(long) * inner_loop);
        for (long j = 0; j &amp;lt; inner_loop; ++j) {
            test.fetch_add(1);
            if (off &amp;gt;= shm_size) return;
            *(long*)(shm + off) = j;
            off += sizeof(long);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;为了避免 test.fetch_add(1) 的调用被编译器优化掉，我们在 main 函数的最后把 test 的值打印出来。编译后测试一下，结果显示：执行时间只是稍微增加到 real 0m0.326s，很显然，并不是 atomic 的调用频次减少导致性能飙升。&lt;/p&gt; 
&lt;p&gt;重新审视 f() 循环里的逻辑：f() 循环里的操作很简单：原子增加、判断、赋值。我们把 f() 的里赋值注释掉，再测试一下，发现它的速度得到了很大提升，看来是*(long*)(shm + off) = off 这一行代码执行慢，但这明明只是一行赋值。我们把它反汇编来看，它只是一个 mov 指令，源操作数是寄存器，目标操作数是内存地址，从寄存器拷贝数据到一个内存地址，为什么会这么慢呢？&lt;/p&gt; 
&lt;h3&gt;3.3 原因&lt;/h3&gt; 
&lt;p&gt;现在揭晓答案：导致 f() 性能底下的元凶是伪共享（false sharing）。那什么是伪共享？要说清这个问题，还得联系 CPU 的架构以及 CPU 怎么访问数据，回顾一下关于多核 Cache 结构。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;背景知识&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;现代 CPU 可以有多个核，每个核有自己的 L1-L2 缓存，L1 又区分数据缓存（L1-DCache）和指令缓存（L1-ICache），L2 不区分数据和指令 Cache，而 L3 是跨核共享的，L3 通过内存总线连接到内存，内存被所有 CPU 所有 Core 共享。&lt;/p&gt; 
&lt;p&gt;CPU 访问 L1 Cache 的速度大约是访问内存的 100 倍，Cache 作为 CPU 与内存之间的缓存，减少对内存的访问频率。&lt;/p&gt; 
&lt;p&gt;从内存加载数据到 Cache 的时候，是以 Cache Line 为长度单位的，Cache Line 的长度通常是 64 字节，所以，那怕只读一个字节，但是包含该字节的整个 Cache Line 都会被加载到缓存，同样，如果修改一个字节，那么最终也会导致整个 Cache Line 被冲刷到内存。&lt;/p&gt; 
&lt;p&gt;如果一块内存数据被多个线程访问，假设多个线程在多个 Core 上并行执行，那么它便会被加载到多个 Core 的的 Local Cache 中；这些线程在哪个 Core 上运行，就会被加载到哪个 Core 的 Local Cache 中，所以，内存中的一个数据，在不同 Core 的 Cache 里会同时存在多份拷贝。&lt;/p&gt; 
&lt;p&gt;那么，便会存在缓存一致性问题。当一个 Core 修改其缓存中的值时，其他 Core 不能再使用旧值。该内存位置将在所有缓存中失效。此外，由于缓存以缓存行而不是单个字节的粒度运行，因此整个缓存行将在所有缓存中失效。如果我们修改了 Core1 缓存里的某个数据，则该数据所在的 Cache Line 的状态需要同步给其他 Core 的缓存，Core 之间可以通过核间消息同步状态，比如通过发送 Invalidate 消息给其他核，接收到该消息的核会把对应 Cache Line 置为无效，然后重新从内存里加载最新数据。&lt;/p&gt; 
&lt;p&gt;当然，被加载到多个 Core 缓存中的同一 Cache Line，会被标记为共享（Shared）状态，对共享状态的缓存行进行修改，需要先获取缓存行的修改权（独占），MESI 协议用来保证多核缓存的一致性，更多的细节可以参考 MESI 的文章。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例分析&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假设线程 1 运行在 Core1，线程 2 运行在 Core2。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;因为 shm 被线程 1 和线程 2 这两个线程并发访问，所以 shm 的内存数据会以 Cache Line 粒度，被同时加载到 2 个 Core 的 Cache，因为被多核共享，所以该 Cache Line 被标注为 Shared 状态。&lt;/li&gt; 
 &lt;li&gt;假设线程 1 在 offset 为 64 的位置写入了一个 8 字节的数据（sizeof(long)），要修改一个状态为 Shared 的 Cache Line，Core1 会发送核间通信消息到 Core2，去拿到该 Cache Line 的独占权，在这之后，Core1 才能修改 Local Cache&lt;/li&gt; 
 &lt;li&gt;线程 1 执行完 shm_offset.fetch_add(sizeof(long)) 后，shm_offset 会增加到 72。&lt;/li&gt; 
 &lt;li&gt;这时候 Core2 上运行的线程 2 也会执行 shm_offset.fetch_add(sizeof(long))，它返回 72 并将 shm_offset 增加到 80。&lt;/li&gt; 
 &lt;li&gt;线程 2 接下来要修改 shm[72]的内存位置，因为 shm[64]和 shm[72]在一个 Cache Line，而这个 Cache Line 又被置为 Invalidate，所以，它需要从内存里重新加载这一个 Cache Line，而在这之前，Core1 上的线程 1 需要把 Cache Line 冲刷到内存，这样线程 2 才能加载最新的数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种交替执行模式，相当于 Core1 和 Core2 之间需要频繁的发送核间消息，收到消息的 Core 的 Cache Line 被置为无效，并重新从内存里加载数据到 Cache，每次修改后都需要把 Cache 中的数据刷入内存，这相当于废弃掉了 Cache，因为每次读写都直接跟内存打交道，Cache 的作用不复存在，这就是性能低下的原因。&lt;/p&gt; 
&lt;p&gt;这种多核多线程程序，因为并发读写同一个 Cache Line 的数据（临近位置的内存数据），导致 Cache Line 的频繁失效，内存的频繁 Load/Store，从而导致性能急剧下降的现象叫伪共享，伪共享是性能杀手。&lt;/p&gt; 
&lt;h3&gt;3.4 另一个伪共享的例子&lt;/h3&gt; 
&lt;p&gt;假设线程 x 和 y，分别修改 Data 的 a 和 b 变量，如果被频繁调用，也会出现性能低下的情况，怎么规避呢？&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;struct Data {
    int a;
    int b;
} data; // global

void thread1() {
    data.a = 1;
}

void thread2() {
    data.b = 2;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;空间换时间&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;避免 Cache 伪共享导致性能下降的思路是用空间换时间，通过增加填充，让 a 和 b 两个变量分布到不同的 Cache Line，这样对 a 和 b 的修改就会作用于不同 Cache Line，就能避免 Cache 失效的问题。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;struct Data {
    int a;
    int padding[60];
    int b;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Linux kernel 中存在__cacheline_aligned_in_smp 宏定义用于解决 false sharing 问题。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#ifdef CONFIG_SMP
#define __cacheline_aligned_in_smp __cacheline_aligned
#else
#define __cacheline_aligned_in_smp
#endif

struct Data {
    int a;
    int b __cacheline_aligned_in_smp;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;从上面的宏定义，可以看到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在多核系统里，该宏定义是 __cacheline_aligned，也就是 Cache Line 的大小&lt;/li&gt; 
 &lt;li&gt;在单核系统里，该宏定义是空的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4 小结&lt;/h2&gt; 
&lt;p&gt;pthread 接口提供的几种同步原语如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/9b8c086ae944f0d4861f9b398c673c0e349572.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由于 linux 下线程和进程本质都是 LWP，那么进程间通信使用的 IPC（管道、FIFO、消息队列、信号量）线程间也可以使用，也可以达到相同的作用。 但是由于 IPC 资源在进程退出时不会清理（因为它是系统资源），因此不建议使用。&lt;/p&gt; 
&lt;p&gt;以下是一些非锁但是也能实现线程安全或者部分线程安全的常见做法：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/43010f87d03c76ab29d444f3469875ac380936.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，上面很多做法都是采用了副本，尽量避免在 thread 中间共享数据。最快的同步就是没同步（The fastest synchronization of all is the kind that never takes place），Share nothing is best。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;|&lt;/strong&gt; 在美团公众号菜单栏对话框回复【2023 年货】、【2022 年货】、【2021 年货】、【2020 年货】、【2019 年货】、【2018 年货】、【2017 年货】等关键词，可查看美团技术团队历年技术文章合集。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://p1.meituan.net/travelcube/b0364d579285ab22aa6235bd100d7c22178175.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=mailto%3A%E6%9C%AC%E6%96%87%E7%B3%BB%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%87%BA%E5%93%81%EF%BC%8C%E8%91%97%E4%BD%9C%E6%9D%83%E5%BD%92%E5%B1%9E%E7%BE%8E%E5%9B%A2%E3%80%82%E6%AC%A2%E8%BF%8E%E5%87%BA%E4%BA%8E%E5%88%86%E4%BA%AB%E5%92%8C%E4%BA%A4%E6%B5%81%E7%AD%89%E9%9D%9E%E5%95%86%E4%B8%9A%E7%9B%AE%E7%9A%84%E8%BD%AC%E8%BD%BD%E6%88%96%E4%BD%BF%E7%94%A8%E6%9C%AC%E6%96%87%E5%86%85%E5%AE%B9%EF%BC%8C%E6%95%AC%E8%AF%B7%E6%B3%A8%E6%98%8E%E2%80%9C%E5%86%85%E5%AE%B9%E8%BD%AC%E8%BD%BD%E8%87%AA%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E2%80%9D%E3%80%82%E6%9C%AC%E6%96%87%E6%9C%AA%E7%BB%8F%E8%AE%B8%E5%8F%AF%EF%BC%8C%E4%B8%8D%E5%BE%97%E8%BF%9B%E8%A1%8C%E5%95%86%E4%B8%9A%E6%80%A7%E8%BD%AC%E8%BD%BD%E6%88%96%E8%80%85%E4%BD%BF%E7%94%A8%E3%80%82%E4%BB%BB%E4%BD%95%E5%95%86%E7%94%A8%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%AF%B7%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E8%87%B3tech%40meituan.com%E7%94%B3%E8%AF%B7%E6%8E%88%E6%9D%83%E3%80%82&quot; target=&quot;_blank&quot;&gt;本文系美团技术团队出品，著作权归属美团。欢迎出于分享和交流等非商业目的转载或使用本文内容，敬请注明「内容转载自美团技术团队」。本文未经许可，不得进行商业性转载或者使用。任何商用行为，请发送邮件至 tech@meituan.com 申请授权。&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/meituantech/blog/11585606</link>
            <guid isPermaLink="false">https://my.oschina.net/meituantech/blog/11585606</guid>
            <pubDate>Mon, 22 Jul 2024 09:22:30 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>谷歌将于 2025 年彻底淘汰 goo.gl 短链服务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Google URL Shortener 是谷歌在 2009 年推出的一项长网址缩短服务，将长链接以 https://goog.gl/* 的形式输出为更短的链接。2018 年，谷歌宣布淘汰和过渡 Google URL Shortener 服务，转而引导用户使用 Firebase Dynamic Links (FDL)；此举意味着其不再接受新的网址缩短服务，但会继续为现有网址提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;时至今日，谷歌&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.googleblog.com%2Fen%2Fgoogle-url-shortener-links-will-no-longer-be-available%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;将于 2025 年彻底关闭 Google URL Shortener 服务。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「任何使用 Google URL Shortener 构建的 https://goo.gl/* 形式链接的开发人员都将受到影响，并且这些 URL 在 2025 年 8 月 25 日之后将不再返回响应。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为了帮助开发者跟踪和过渡可能受影响的链接，从 2024 年 8 月 23 日开始，goo.gl 链接将开始为一定比例的现有链接显示提示，在导航到原始目标页面之前通知用户该链接将在 2025 年 8 月 25 日之后不再受支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;314&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f582b660e075dbd05b28f5b23f7a2a5dcf2.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;随着时间的推移，有提示的相关链接百分比将会增加，直到关闭日期。一旦关闭，链接将简单地返回 404 响应。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;值得注意的是，这一提示页面可能会对 goo.gl 链接的当前流程造成干扰，譬如妨碍重定向流程或影响目标页面中一些嵌入数据的显示。因此，谷歌方面建议用户尽快对 goo.gl 链接进行转换；对于受影响的用户，可在现有的 goo.gl 链接中添加查询参数 「si=1」。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303321/google-url-shortener-links-will-no-longer-be-available</guid>
            <pubDate>Mon, 22 Jul 2024 08:28:21 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>大模型代码助手下一步：探索智能问答，图生代码等场景</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;7 月 27 日，第 105 期 OSC 源创会即将在杭州举办，本次沙龙以【AI 编程革新研发效能】为主题，将深入探讨 AI 编程助手背后的技术架构、在开发者群体中的使用情况、以及它们在当前市场中的应用，并探讨未来它们对软件开发领域的影响和改变。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;在活动正式开始前，我们邀请到本次活动的讲师之一，蚂蚁 CodeFuse IDE 插件技术负责人肖斌，提前为各位开发 er 们路透下蚂蚁 CodeFuse 相关信息，对 CodeFuse 和 AI 编程感兴趣的小伙伴们可以点击链接，报名参与活动：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;a href=&quot;https://www.oschina.net/event/2332361&quot;&gt;&lt;span&gt;https://www.oschina.net/event/2332361&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img height=&quot;533&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3712eccd90d8cb09658750e8a1fbf500461.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;演讲嘉宾：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;肖斌，蚂蚁 CodeFuse IDE 插件技术负责人&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;演讲议题：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;蚂蚁代码大模型落地实践&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span&gt;议题简介：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;本次演讲从提升研发效能的场景出发，介绍基于大模型的蚂蚁智能研发体系，阐述相关的技术方案和选型，以及在大模型落地上工程领域上的实践及对应结果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：您是在什么时候加入团队的？为什么看好这个方向？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;2021 年加入团队，一直从事软件工程智能化方向的研究和探索，当下专注于代码生成，AI 对话等方向,目前是 CodeFuse IDE 插件技术负责人。我认为大模型是未来研发领域的方向，人的精力是有限的，优秀的大模型，能学习到已有的知识，在日常工作中协同辅助研发人员，快速完成相关任务，同时帮助研发人员快速成长。未来甚至能自主的做一些简单的研发任务。极大的提高整体研发效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：日常主要工作是什么，目前的工作强度大吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;统筹安排 CodeFuse IDE 插件中所有技术相关事项，主要精力会负责探索和调研 CodeFuse IDE 插件技术方案，并且深入参与到产品研发工作，保障产品效果。由于大模型还是处于快速发展的时期，这块工作强度以及工作难度还是比较有挑战性的。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：几乎每个大厂都结合&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;大模型&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;推出了代码助手的产品，CodeFuse 有什么特别之处？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;数据训练上和蚂蚁背景强结合，这一点是其他产品无法做到的。比如学习蚂蚁内沉淀的优秀知识库。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;产品能力上和蚂蚁业务强结合，比如图生代码，以及对话和内网仓库，内网部署平台结合&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;同时自研代码助手也能保证数据安全&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：觉得目前 CodeFuse &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;IDE&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt; 插件做的最好的功能是哪个？为什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;目前最好的是代码补全，因为补全会在写代码过程中时时刻刻的辅助研发工作。是目前核心能力。但深入研究代码补全技术同时，我们还探索其他方向，比如智能问答，图生代码等&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。相信在不久的将来，AI 能力会覆盖研发领域各个阶段，从整体上共同提高研发幸福感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：技术选型时有哪些标准和考量？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;重点考虑用户体感，用户体感从技术选型上有两个方面，准确性和速度。比如代码补全，补的不准确，或者补全速度慢，用户体感肯定会下降，这样的产品用户不会满意。所以针对准确性和速度上，我们做了大量的研究和探索，同时也产出了一些论文，可以共享给大家。技术方向有了一些阶段性成果后，我们会首先进行一系列评测，通过评测后落到产品上进行 AB 实验，基于 AB 实验效果，推进技术演进方向。同时在产品层面也提高了用户体感。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：在实际应用中，CodeFuse 作为辅助开发的工具，表现是否符合预期？有没有什么意外的收获或挑战？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;表现是符合预期或者说超出预期，CodeFuse 较好的提升了蚂蚁同学的研发效率，也获取了蚂蚁内部的科技创新奖。至于挑战，创新的东西跳转肯定是有的，特别是大模型相关的应用，模型幻觉，能力边界等都是较大的挑战，我们也在不断通过技术手段去解决相关难题。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#2ea121&quot;&gt;OSCHINA：预计开发者能从这次演讲中获得哪些收益？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;肖斌：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;了解代码大模型发展方向，了解代码大模型在蚂蚁研发领域的落地&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/4489239/blog/12394403</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/12394403</guid>
            <pubDate>Mon, 22 Jul 2024 07:02:22 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>2028 年中国数据仓库软件市场规模将达 23.6 亿美元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;国际数据公司（IDC）于近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.idc.com%2Fgetdoc.jsp%3FcontainerId%3DprCHC52446524&quot; target=&quot;_blank&quot;&gt;发布&lt;/a&gt;了《2023 年下半年中国数据仓库软件市场跟踪报告》。数据显示，2023 年中国数据仓库软件市场规模为 9.4 亿美元，同比增长 7.8%。其中，本地部署数据仓库软件规模 4.8 亿美元，同比增长 3.6%；公有云数据仓库软件规模 4.6 亿美元，同比增长 12.6%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;IDC DataSphere 预测，2023 年到 2028 年全球企业侧的年产数据规模呈爆发增长态势，到 2028 年数据规模将达到 317.1 ZB，2023-2028 年复合增长率为 30.2%，为未来数据仓库的应用带来了更广泛的市场空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;到 2028 年，中国数据仓库软件市场规模将达到 23.6 亿美元，2023-2028 的 5 年市场年复合增长率（CAGR）为 20.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;394&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6af1feb7b5d0e33d4a2fbbfb8b4042c616f.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2023 下半年，中国数据仓库&lt;strong style=&quot;color:#01010f&quot;&gt;本地部署模式&lt;/strong&gt;市场前 5 名厂商总计占比 58.5%。出于数据安全和合规性的考虑，本地部署模式的数据仓库产品仍将是金融、政府、能源、以及大型企业的首选。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#01010f&quot;&gt;2023 下半年中国数据仓库本地部署模式市场厂商份额情况如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;与本地部署市场相比，&lt;strong style=&quot;color:#01010f&quot;&gt;公有云&lt;/strong&gt;数据仓库服务的市场集中度更高，前五名厂商份额共计超过 90%。预计 2024 年，公有云数据仓库市场规模将超过本地部署市场，到 2028 年，公有云数据仓库市场占比将达到 59.6%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;342&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5323455dd42ca486e2a971607c017150855.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong style=&quot;color:#01010f&quot;&gt;2023 下半年中国数据仓库公有云模式市场厂商份额情况如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;355&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-379638b33063e37971467912b2cc49102ee.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303300</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303300</guid>
            <pubDate>Mon, 22 Jul 2024 06:52:10 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>首轮嘉宾阵容公布，GOTC 2024 即将开启！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span&gt;8 月 15 日至 16 日，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://gotc.oschina.net/&quot; rel=&quot;nofollow&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;GOTC 2024&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;&lt;span&gt;将在上海张江科学会堂盛大开启。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GOTC 2024 与上海浦东软件园联合举办，并结合 「GOTC（全球开源技术峰会）」 与 「GOGC（全球开源极客嘉年华）」，&lt;/span&gt;是一场面向全球开发者的全新的开源技术盛会。期间将举行开幕式暨主论坛、高峰论坛、平行论坛、行业沙龙、青年黑客松等活动。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;本次大会聚焦数据基础与&amp;nbsp;GenAI&amp;nbsp;开发范式、开源数据库与 AI 协同创新、LLMOps 最佳实践、硬核 AI 技术创新与实践、云原生与微服务架构以及开源人才与教育等主题。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;届时，&lt;strong&gt;10&lt;strong&gt;0+&amp;nbsp;&lt;/strong&gt;&lt;/strong&gt;海内外深耕开源技术的行业领袖们将到场与开发者们分享他们的创新思考与未来实践。&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;strong&gt;首轮嘉宾阵容公布！&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;3676&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6a2894f8f7f2f0f9a1234290ba9dd4e314d.jpg&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 报名通道现已开启，诚邀全球各技术领域开源爱好者共襄盛举！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参会报名，请访问&lt;/strong&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F8762568606000%3Ftd%3D6895280870225&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;https://www.huodongxing.com/event/8762568606000?td=6895280870225&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 将于 8 月 15 日在上海张江科学会堂盛大开启，为期两天。GOTC 2024 与上海浦东软件园联合举办，并结合 「GOTC（全球开源技术峰会）」 与 「GOGC（全球开源极客嘉年华）」，旨在打造一场全新的开源盛会。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;全球开源技术峰会（Global Open-source Technology Conference，简称 GOTC）始于 2021 年，是面向全球开发者的开源技术盛会；2024 全球开源极客嘉年华（GOGC 2024）由浦东软件园携手 S 创共建，与开源中国、Linux 基金会等品牌联合呈现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:center&quot;&gt;&lt;img height=&quot;1081&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c757b3c3ae95b5ea402ba8821dca68b2297.jpg&quot; width=&quot;1921&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此次大会将集结全球范围内对开源技术充满热情的开发者、社区成员、创业者、企业领袖、媒体人，以及各开源项目应用场景的产业精英、跨界才俊与年轻力量。通过主题演讲、圆桌讨论、创新集市、人才集市、黑客松、技术展示和互动工作坊等形式，与会者将有机会交流实践经验、探索前沿技术，让我们一起激发创新活力、展示开源魅力、促进跨领域合作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更多大会信息，访问官网查看：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;https://gotc.oschina.net&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&amp;nbsp;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/3859945/blog/12305454</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/12305454</guid>
            <pubDate>Mon, 22 Jul 2024 03:31:37 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>中共中央：完善生成式人工智能发展和管理机制</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;新华社受权发布《中共中央关于进一步全面深化改革推进中国式现代化的决定》，其中提到要健全网络综合治理体系，深化网络管理体制改革，整合网络内容建设和管理职能，推进新闻宣传和网络舆论一体化管理。&lt;/p&gt; 
&lt;p&gt;完善生成式人工智能发展和管理机制，加强网络空间法治建设，健全网络生态治理长效机制，健全未成年人网络保护工作体系。要加强网络安全体制建设，建立人工智能安全监管制度。&lt;/p&gt; 
&lt;p&gt;此外，决定还提到要深化人才发展体制机制改革，实施更加积极、更加开放、更加有效的人才政策，完善人才自主培养机制，加快建设国家高水平人才高地和吸引集聚人才平台。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;322&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b4bdf54a7bf28e2c59d8f25158fa1d57055.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303254</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303254</guid>
            <pubDate>Mon, 22 Jul 2024 03:22:53 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>deepin 助力开源桌面生态：mesa LLVMpipe ORCJIT 上游化的台前幕后</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;383&quot; src=&quot;https://oscimg.oschina.net/oscnet/%E4%B8%AD%E6%96%87.jpg&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;内容来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fmesa-llvmpipe-orcjit-deepin%2F&quot; target=&quot;_blank&quot;&gt;deepin（深度）社区&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;近日，mesa 开源图形驱动合并了 llvmpipe 的 ORCJIT 后端的 Merge Request (MR)，并实现了对 riscv64 架构的支持。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;LLVMpipe 是什么？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;LLVMpipe 是 mesa 驱动中的一种软件渲染器，它不使用 GPU 硬件，而是利用 LLVM 中的 JIT 编译器，动态地将待渲染的图形相关代码转译为栅格化的数据用于显示，相对于 softpipe 而言性能更优。&lt;/p&gt; 
&lt;p&gt;饱受诟病的闭源驱动从始至终都是阻碍 riscv64 架构桌面生态的一大原罪，导致大部分 riscv64 架构的开发板的内置 GPU 完全或部分不可用，桌面发行版只能使用软件渲染作为替代方案。&lt;/p&gt; 
&lt;p&gt;然而，在很长一段时间，mesa 的 LLVMpipe 使用的 JIT 后端是老旧的、缺乏架构支持的 MCJIT，而非更新的、架构支持更加广泛的 ORCJIT。由于前者已经明确由后者替代接续，不再接受新的架构更新，这使得 mesa 在 riscv64 等架构上使用软件渲染时只能使用性能更加低下的 softpipe，最终导致桌面环境几乎无法使用，使得桌面生态遭受毁灭性的打击。&lt;/p&gt; 
&lt;p&gt;正因如此，开源社区急切地渴望在 riscv64 架构上拥有一个更快的软件渲染器。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;ORCJIT 的首次尝试&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;时间推进到了 2022 年 7 月。一位 &lt;strong&gt;Alex Fan (@alexfanqi)&lt;/strong&gt; 的开发者提交了 MR 17801，为 mesa 引入了新的 ORCJIT 后端，同时还为其加上了 riscv64 支持，这使得在 riscv64 上使用 LLVMpipe 软件渲染成为了可能。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;442&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d75b83b32cc4a37c03cdaa02cccad85d6a.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这个 MR 并没有第一时间被合并，因为有开发者指出它没有一个开关用以在编译时切换后端、代码不够简洁需要优化、缺少着色器缓存等问题，还需要进一步优化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从此开始，长达两年的 LLVMpipe ORCJIT 后端合并的长跑开始了。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;2022 年 7 月，openEuler 社区的 RISC-V SIG 发现了这个 PR 并将其并集成，发布了一篇文章介绍了它的性能提升效果。&lt;/p&gt; 
&lt;p&gt;然而，就在 riscv64 平台的开源桌面生态即将迎来曙光的时候，世事难料，随着 mesa 开发分支的高速推进，原来的 Merge Request 缺乏维护，与主线的差异和冲突越来越大，渐渐的被淹没在冗长的 MR 列表中，逐渐被人淡忘。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;社区的接力：开源软件不灭的火种&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;2023 年 11 月，一位名为 &lt;strong&gt;Yukari Chiba (@YukariChiba)&lt;/strong&gt; 的开发者在维护自己的发行版时，遇到了同样的问题。她受够了大部分主线发行版在遇到这个问题时切换到 softpipe 的忍让态度，决定着手解决这个问题。&lt;/p&gt; 
&lt;p&gt;被尘封在 MR 列表中的 patch，再一次化作荧幕上的光芒。&lt;/p&gt; 
&lt;p&gt;11 月 1 日，@YukariChiba 在某个群组里发布了一张在飞腾派上以开启了 ORCJIT 的主线 mesa 使用 LLVMpipe 运行 glxinfo 的截图，并在次日发布了一张在 PineTab-V 上使用 LLVMpipe 运行 glmark 的截图。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;600&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1ba864847edc700e94dbd1d6b7d899fea36.jpg&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;11 月 8 日，@YukariChiba 以相同的 ID，在 mesa 主线中重新提交了 MR 26018，旨在为主线版本 mesa 提供参考 patch 的同时，推进 mesa 主线的合并。&lt;/p&gt; 
&lt;p&gt;很快，deepin、ArchLinux RISC-V、AOSC OS 等发行版也先后使用了这一版 MR 的补丁，RISC-V 主线化的桌面体验再一次达到了可用的状态。&lt;/p&gt; 
&lt;p&gt;2024 年 4 月，Icenowy Zheng (@icenowy) 在 ORCJIT MR 的基础上增加了着色器缓存和 loongarch 架构的支持，这意味着 ORCJIT 后端一旦合入，所有的主流桌面架构都能实现性能优异的 LLVMpipe 支持。&lt;/p&gt; 
&lt;p&gt;众人拾柴火焰高，长风破浪会有时，LLVMpipe ORCJIT 这一突破性进展受到越来越多开发者的关注，合并进入主线逐渐被提上了日程。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;MR 的接力冲刺和最终合并&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;6 月 19 日，有开发者评论：&lt;/p&gt; 
&lt;blockquote&gt;
 Is there anything outstanding that is preventing this from being merged into the main mesa branch?
&lt;/blockquote&gt; 
&lt;p&gt;而这打破了 MR 评论区的宁静。在后续的 1 个月里，社区贡献者们对该 MR 提出了数十条修改意见；&lt;strong&gt;Dave Airlie (@airlied) &lt;/strong&gt;为帮助 ORCJIT 最终落地提交了数个前序修改和代码结构优化；MR 提交者 &lt;strong&gt;@YukariChiba &lt;/strong&gt;根据修改意见对 MR 提交内容修改了数十个版本，并最终在 6 月 28 日提交了最终版本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;最终，7 月 16 日，Merge Request 26018 完成了合并前 CI 检查，被 mesa 主线合入，标志这这一场由全球无数开发者参与、持续两年的开源马拉松圆满落幕。&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;633&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f2984bb91c944634d2ed91eee40e41cc153.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;deepin 的持续跟踪与维护：幕后故事&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;在 mesa 提交 MR 的这位 ID 称作 &lt;strong&gt;@YukariChiba&lt;/strong&gt; 的开发者还有另外的身份：&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Findex%2Fzh&quot; target=&quot;_blank&quot;&gt;deepin（深度）开源社区&lt;/a&gt;的研发工程师，deepin-ports SIG 开发者，deepin RISC-V port 的维护者之一。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;deepin-ports SIG 在 2023 年成功将 RISC-V 的支持合并到了主线，同时也对主流的开发板进行了适配。与其它开源社区一样，deepin 也饱受无法主线化、依赖闭源驱动组件的 GPU 图形驱动的困扰，mesa 的 ORCJIT 后端支持此时无异于雪中送炭。&lt;/p&gt; 
&lt;p&gt;deepin 在 2023 年 12 月 6 日便对这一份更新的 patch 做了内部的打包验证，并在 VisionFive2、LicheePi4A、SG2042 EVB 等开发板上做了实机验证和性能测试。&lt;/p&gt; 
&lt;p&gt;次日，deepin 合并了此 MR 的 patch 到 mesa 主线仓库，为 riscv64 架构默认打开了 ORCJIT 支持，并在后续所有的 riscv64 设备镜像中启用。&lt;/p&gt; 
&lt;p&gt;从 2023 年 11 月的初版补丁，直到 2024 年 7 月 16 日的最终合并，deepin 的 mesa 版本也相应的从 23.1.2 一路升级到了 24.1.0。在这过程中，deepin-ports SIG 积极适配新版 mesa 并刷新补丁，做到了在版本迭代的过程中补丁持续有效，助力了此特性的测试和维护，客观上为 mesa 上游的最终合并提供了社区支持。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;606&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e00e91bf07071077d3537baa7cfe480c1cc.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在此期间，deepin 同时也超前引入了尚未合并、基于 ORCJIT 提交的 loongarch 支持补丁和着色器缓存补丁，为 deepin-ports 两大架构 riscv64 和 loong64 提供了更高性能的软件渲染，完善了 deepin 的桌面生态。&lt;/p&gt; 
&lt;p&gt;未来，deepin 还将继续跟进 mesa 等开源软件的上游更新和后续的性能优化，为完善 amd64/arm64/riscv64/loong64 四大架构的开源桌面体验而不懈努力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h1&gt;附录：&lt;/h1&gt; 
&lt;p&gt;（1）deepin 全版本镜像（含 deepin V15）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdistrowatch.com%2Findex.php%3Fdistribution%3Ddeepin&quot; target=&quot;_blank&quot;&gt;https://distrowatch.com/index.php?distribution=deepin&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;（2）deepin RISC-V 架构镜像（LicheePi 4A、VisionFive 等）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepin.org%2Fzh%2Fdownload%2F&quot; target=&quot;_blank&quot;&gt;https://www.deepin.org/zh/download/&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303248</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303248</guid>
            <pubDate>Mon, 22 Jul 2024 02:41:53 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>「鸿蒙之父」王成录计划建立鸿蒙操作系统理论体系系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;深圳开鸿数字产业发展有限公司 CEO 王成录近日&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1936879191%2FOoqOxth61&quot; target=&quot;_blank&quot;&gt;发表微博&lt;/a&gt;，称已收到哈尔滨工业大学博士研究生录取通知书，专业为电子信息。他表示，将跟随徐晓飞教授学习，计划&lt;strong&gt;用三年时间把鸿蒙操作系统理论体系系统全面建立起来&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1760&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0722/102746_fUay_2720166.png&quot; width=&quot;2800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;王成录曾主导鸿蒙系统开发，也曾担任华为终端 BG 软件部总裁、华为消费者业务 AI 与智慧全场景业务部总裁。2022 年 5 月，王成录正式从华为离职，就职深圳开鸿数字产业发展有限公司（简称 「深开鸿」），出任 CEO。&lt;/p&gt; 
&lt;p&gt;有网友在该微博的评论区留言询问，「今年能买到鸿蒙 PC 吗？」，王成录回复「会有的」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1070&quot; src=&quot;https://static.oschina.net/uploads/space/2024/0722/103517_9RRL_2720166.png&quot; width=&quot;2360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;延伸阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/288918&quot; target=&quot;_blank&quot;&gt;王成录：开源鸿蒙是我国基础软件领域唯一一次架构创新&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/256753&quot; target=&quot;_blank&quot;&gt;「鸿蒙之父」 王成录：明年推出鸿蒙 PC 版系统&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303247</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303247</guid>
            <pubDate>Mon, 22 Jul 2024 02:37:13 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ZrLog 3.1 发布，用更快的速度、更便捷的功能，让你的记录更生动</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;还记得最初选择写博客的理由吗？是希望用它来记录生活中的点滴，在闲暇时翻阅，重温过往的经历，品味岁月的滋味，还是分享知识，记录成长？&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;从 ZrLog 3.1 起支持本地部署，并配合 CDN 或 GitHub Pages 服务实现动静结合，轻松实现无服务上云（低成本上云，仅需要域名费用），让你的网站更加轻盈、快速。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;ZrLog 3.1 带着满满的诚意和升级而来，它不仅在性能上有了显著提升，更带来了许多实用的功能改进，致力于为用户提供更便捷、高效的写作体验，让每个人都能更轻松地记录生活，让记忆更鲜活！&lt;/p&gt; 
 &lt;h4&gt;性能提升，速度飞跃&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;首次加载渲染优化&lt;/strong&gt;: 服务端直接插入页面所需数据，大幅提升管理后台页面首次加载速度&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;页面缓存机制&lt;/strong&gt;: 管理后台页面缓存机制，页面切换更流畅，告别等待&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Simple Web Server 升级&lt;/strong&gt;: 降低内存占用量，提升系统效率&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GraalVM Native 打包&lt;/strong&gt;: 将 Java 代码编译成原生可执行文件，启动速度大幅提升，运行效率更高，占用更少的内存资源，带来流畅的写作体验&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;支持主流平台&lt;/strong&gt;: ZrLog 3.1 提供了 Windows、Linux 和 macOS (x86_64 和 Apple 芯片) 的直接可执行包，方便在各种设备上轻松使用 ZrLog&lt;/p&gt; 
 &lt;h4&gt;功能增强：更便捷更强大&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;写作体验更佳&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;PWA 支持&lt;/strong&gt;: 将博客写作添加到桌面或 Dock 栏，随时随地开启写作之旅。 就算没有网络，也可以随时随地创作，灵感来了就写，再也不怕错过！&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;管理更便捷&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;zip 包在线更新升级&lt;/strong&gt;: 告别下载，在线更新更方便快捷，随时拥有最新功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化管理后台用户输入参数校验&lt;/strong&gt;: 提升安全性，避免错误输入&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化网站设置内容&lt;/strong&gt;: 更便捷的博客管理体验，轻松掌控博客的各个方面&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化管理后台侧边栏选中样式&lt;/strong&gt;: 操作更清晰明了，更轻松地找到所需功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化登录页面排版&lt;/strong&gt;: 界面更美观，体验更友好，拥有更愉悦的写作环境&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化常用插件配置首次加载&lt;/strong&gt;: 配置更快速，使用更便捷，更快地使用各种功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化管理后台无网络情况下的提示方式&lt;/strong&gt;: 提升用户体验，在任何网络环境下都能轻松使用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;PWA 模式下，记录上次打开的页面&lt;/strong&gt;: 方便继续创作，提高效率，随时回到上次写作的位置&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;性能更优越&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;整站静态化&lt;/strong&gt;: 彻底释放闲置 VPS，配合阿里云 CDN 或 Nginx 分流，提升网站速度，更快速地分享记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化 Github Action 缓存机制&lt;/strong&gt;: 提升构建速度，缩短 CI/CD 流程，让博客始终保持最新状态&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;插件更强大&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;插件中心优化&lt;/strong&gt;: 采用 CDN 无服务化，访问更快更稳定，轻松找到需要的插件&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修复插件异步写入流卡住问题&lt;/strong&gt;: 提升插件稳定性，确保记录安全保存&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修复新版本插件下载完后跳转问题&lt;/strong&gt;: 更便捷的插件安装体验，轻松使用新功能&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化数据库备份插件备份逻辑&lt;/strong&gt;: 提升备份效率，更放心地保存记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化畅言插件配置&lt;/strong&gt;: 更易于配置，使用更便捷，更轻松地与读者互动&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化插件页面渲染加载等待&lt;/strong&gt;: 提升插件整体稳定性，确保流畅的使用体验&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;新增 rss 插件&lt;/strong&gt;: 方便 RSS 订阅博客内容，让更多人看到记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化文章标签选取&lt;/strong&gt;: 标签选择更便捷，管理更方便，更轻松地整理记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;备份数据库插件的备份文件加密处理&lt;/strong&gt;: 提升备份安全性，更放心地保存记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;升级备份数据库插件的 &lt;code&gt;mysqldump&lt;/code&gt; 版本&lt;/strong&gt;: 支持更新的数据库版本，提升兼容性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;静态化后生成的静态站点支持同步更新到 git 仓库&lt;/strong&gt;: 配合 pages 服务，轻松实现低成本的博客部署&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;添加文章分类重排插件&lt;/strong&gt;: 便于浏览，更直观地管理文章&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;安全更可靠&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;数据库备份优化&lt;/strong&gt;: 针对备份内容未变更情况，不再进行重复备份和上传，节省资源，更放心地保存记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修复自动摘要重复截取问题&lt;/strong&gt;: 确保摘要准确，方便读者快速了解记录&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修复 3.0 版本的标签敏感字符问题&lt;/strong&gt;: 提升标签的兼容性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;支持配置 robots.txt 文件&lt;/strong&gt;: 更有效地控制搜索引擎爬虫访问，保护隐私&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;其他优化&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;可移除上传的文章预览头图&lt;/strong&gt;: 更灵活的图片管理，更自由地选择展示方式&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;管理后台显示程序对磁盘的使用量&lt;/strong&gt;: 方便查看系统资源占用情况，更了解系统状况&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;修复 3.0 版本的管理后台，在 Safari 上 Cookie 无法持久化的问题&lt;/strong&gt;: 提升浏览器兼容性，在不同浏览器上都能流畅使用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化管理界面的错误页面&lt;/strong&gt;: 提升用户体验，更方便地解决问题&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;自动下载 docker 升级后丢失的主题&lt;/strong&gt;: Docker 模式更好用&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;支持配置 favicon 图标和 pwa 应用的图标&lt;/strong&gt;: 个性化定制博客，让记录更有个性&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化关于文章的 api 响应输出&lt;/strong&gt;: 更便捷的接口调用，方便将记录与其他平台连接&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;移除默认主题的 jquery 依赖&lt;/strong&gt;: 减轻页面负担，提升加载速度，更快速地访问博客&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;优化默认主题在暗黑模式下的表格样式&lt;/strong&gt;: 视觉体验更舒适，更轻松地阅读记录&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr&gt; 
 &lt;p&gt;&lt;strong&gt;使用 PWA 模式下的，文章撰写页面空间更大，更专注&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;x&quot; src=&quot;https://oscimg.oschina.net/oscnet/20240722100902_197.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;全屏编辑状态&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;x&quot; src=&quot;https://oscimg.oschina.net/oscnet/20240722100730_907.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;都看到这里了，肯定感兴趣了，赶快点下 star 收藏下，免得下次就找不到了&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitHub: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F94fzb%2Fzrlog&quot; target=&quot;_blank&quot;&gt;https://github.com/94fzb/zrlog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;码云: &lt;a href=&quot;https://gitee.com/94fzb/zrlog&quot;&gt;https://gitee.com/94fzb/zrlog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;程序主页: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zrlog.com&quot; target=&quot;_blank&quot;&gt;https://www.zrlog.com&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SimpleWebServer: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F94fzb%2Fsimplewebserver&quot; target=&quot;_blank&quot;&gt;https://github.com/94fzb/simplewebserver&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;现在就访问 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zrlog.com&quot; target=&quot;_blank&quot;&gt;官方网站&lt;/a&gt; 下载体验 ZrLog 3.1 最新版本，感受性能与功能的全面升级，让我们一起，用 ZrLog 记录生活的点滴，用文字留住时光，让回忆更生动！&lt;/p&gt; 
&lt;/div&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303246/zrlog-3-1-released</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303246/zrlog-3-1-released</guid>
            <pubDate>Mon, 22 Jul 2024 02:34:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>本周六，杭州源创会，聊聊 AI 编程</title>
            <description></description>
            <link>https://www.oschina.net/event/2332361</link>
            <guid isPermaLink="false">https://www.oschina.net/event/2332361</guid>
            <pubDate>Mon, 22 Jul 2024 02:04:58 GMT</pubDate>
        </item>
        <item>
            <title>微软：850 万台 Windows 设备受到 CrowdStrike 中断影响</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;微软企业和操作系统安全副总裁 David Weston &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblogs.microsoft.com%2Fblog%2F2024%2F07%2F20%2Fhelping-our-customers-through-the-crowdstrike-outage%2F&quot; target=&quot;_blank&quot;&gt;发文&lt;/a&gt;表示，大约有 850 万台 Windows 设备受到了最近的 CrowdStrike 中断的影响。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「虽然软件更新偶尔会造成干扰，但像 CrowdStrike 事件这样的重大事件并不常见。我们目前估计，CrowdStrike 的更新影响了 850 万台 Windows 设备，占所有 Windows 机器的不到 1%。虽然这个比例很小，但广泛的经济和社会影响反映了运行许多关键服务的企业对 CrowdStrike 的使用。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;267&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-bc394b9cb0d0d35fc70ee8d22d8fff39ab5.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不过他并没有透露安装 CrowdStrike 软件的 Windows 设备中受影响的百分比。虽然受影响的设备数量相对较少，但此次事故破坏范围广泛且遍布全球，影响到了银行、零售商、经纪公司、铁路网络等行业。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Weston 表示，该公司一直在与 CrowdStrike 合作解决问题，已经开发出了一种可扩展的解决方案，可帮助 Microsoft 的 Azure 基础设施加速修复 CrowdStrike 的错误更新。同时，他们还在与亚马逊网络服务和谷歌云平台合作以共同寻找最有效的方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「此次事件表明，我们广泛的生态系统（全球云提供商、软件平台、安全供应商和其他软件供应商以及客户）具有相互联系的特性。这也提醒我们，对于整个技术生态系统中的所有人来说，使用现有机制优先考虑安全部署和灾难恢复是多么重要。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/302903/latest-crowdstrike-update-causes-blue-screen-of-death-on-windows&quot; target=&quot;_blank&quot;&gt;Crowdstrike 更新导致全球 Windows 大面积蓝屏死机&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303145/8-5m-windows-devices-crowdstrike-outage</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303145/8-5m-windows-devices-crowdstrike-outage</guid>
            <pubDate>Sun, 21 Jul 2024 03:48:33 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>周鸿祎谈为何微软蓝屏故障在中国少：90% 的电脑大多数用 360</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;360 创始人周鸿祎连发三条视频，以日前发生的因 Crowdstrike 更新导致全球 Windows 大面积蓝屏死机事件为主题，谈论了国产安全软件的重要性以及这场史上最大 IT 事故所带来的启发。&lt;/p&gt; 
&lt;p&gt;「这次的事件也再次展露了微软在整个市场中的占有率之高、覆盖面之广以及其系统崩溃所带来的威力，不亚于在数字世界投下 100 万颗原子弹。」&lt;/p&gt; 
&lt;p&gt;他指出，在因为 CrowdStrike 软件出错和微软发生冲突导致蓝屏、导致全世界很多基础设施出问题之际，中国却基本上没有受到影响的原因在于：「中国 90% 的电脑上绝大多数企业杀毒软件都用的是 360 杀毒和 360 安全衞士，我们有很大的优势。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;479&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2f40e586308e5d08f4e73406a462eb80a0a.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;并补充到，360 有一个自动化的蓝屏修复技术，在出现蓝屏的时候只需重启系统便可以快速恢复，不会影响到用户的正常使用。360 安全软件在全球范围内有着丰富的实践经验，在安全性和稳定性上绝对经得起考验，迄今没有出过一起类似的安全事故。&lt;/p&gt; 
&lt;p&gt;同时，周鸿祎也认为，微软此次的全球大面积蓝屏事件给我们敲响了警钟，我们国家的电脑网络安全必须要掌握在自己手里，电脑的杀毒软件也一定要是国产品牌。这样才能保证在数字化、智能化的时代，不会因为一个小 Bug、小更新或小小的攻击导致整个社会、整个城市、整个国家陷入停摆。&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303143</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303143</guid>
            <pubDate>Sun, 21 Jul 2024 03:11:46 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>腾讯云发布国产服务器操作系统 TencentOS Server V3</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2024 中国国际金融展上，腾讯云副总裁胡利明发布了全新的腾讯云国产服务器操作系统 TencentOS Server V3。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;胡利明介绍，TencentOS Server V3 具备安全可信、稳定高效等特性，并针对云和 AI 场景做了众多升级，极大提升了数据库等软件性能，以及 CPU、GPU 等资源的利用率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;279&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ccc0b70054e2a5da85f5f08b05daa0b6026.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TencentOS Server 是腾讯自主研发的企业级 Linux 服务器操作系统。在实践方面，TencentOS Server V3 全面兼容主流的国产芯片服务器，支持建设了鲲鹏、海光和飞腾三大主流 CPU 超大规模的服务器集群。目前 TencentOS Server 凭借近 1000 万套的部署规模成为国内部署量最大的 Linux 操作系统。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据介绍，此次发布的 TencentOS Server V3 具备四大亮点：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;数据库整体性能提升 30%，内存节省超过 15%&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;在离线混部+能耗控制方案，大幅提升资源利用率&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;集成大模型推理加速框架，GPU 利用率提升 2 倍&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;CentOS 原地替换，重启即生效，安全稳定&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303139</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303139</guid>
            <pubDate>Sun, 21 Jul 2024 02:42:46 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源 AI 和 ML 工具的安全风险日益增加</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Protect AI 最新发布的一份 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotectai.com%2Fthreat-research%2Fjuly-vulnerability-report&quot; target=&quot;_blank&quot;&gt;2024 年 7 月漏洞报告&lt;/a&gt;在各种大语言模型（LLM）中发现了 20 个严重漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这些漏洞是通过 Protect AI 的「huntr」漏洞赏金计划发现的，这也是全球首个 AI/ML 漏洞赏金计划。该社区由 15,000 多成员组成，在整个 OSS AI/ML 供应链中寻找有影响力的漏洞。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「我们发现供应链中用于构建支持 AI 应用程序的机器学习模型的工具容易受到独有的安全威胁。这些工具是开源的，每月被下载数千次以构建企业 AI 系统。它们还可能存在漏洞，这些漏洞可能直接导致完全的系统接管，例如未经身份验证的远程代码执行或本地文件包含。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img height=&quot;397&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b6b666b8b6b2712bc5cec516474555d6f60.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此次报告的漏洞涉及了 ZenML、lollms 和 AnythingLLM 等广泛使用的工具。ZenML 中的权限提升漏洞，未经授权的用户可以通过发送精心设计的 HTTP 请求将其权限提升到服务器帐户。可以通过修改请求负载中的 is_service_account 参数来利用此漏洞。利用此漏洞的攻击者可能会破坏整个系统，导致未经授权的访问和控制。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;lollms 中的本地文件包含 (LFI) 漏洞，允许攻击者读取或删除服务器上的敏感文件，从而可能导致数据泄露或拒绝服务。该漏洞源于 lollms 中的 sanitize_path_from_endpoint 函数未正确处理 Windows-style paths，导致其容易受到目录遍历攻击。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;AnythingLLM 中的路径遍历漏洞使得攻击者可以读取、删除或覆盖关键文件，包括应用程序的数据库和配置文件。该漏洞位于 normalizePath() 函数中，可导致数据泄露、应用程序入侵或拒绝服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fprotectai.com%2Fthreat-research%2Fjuly-vulnerability-report&quot; target=&quot;_blank&quot;&gt;查看完整报告&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/303036/protect-ai-july-vulnerability-report</link>
            <guid isPermaLink="false">https://www.oschina.net/news/303036/protect-ai-july-vulnerability-report</guid>
            <pubDate>Sat, 20 Jul 2024 03:05:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>@所有人，RWKV 中文官网正式上线啦！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;@所有人，RWKV 中文官网（www.rwkv.cn）正式上线啦！&lt;/p&gt; 
&lt;p&gt;在全新推出的 RWKV 中文官网，你可以查看&lt;strong&gt;关于 RWKV 的绝大多数信息&lt;/strong&gt;，包括但不限于 RWKV 架构的介绍、RWKV 多模态等研究和相关论文、RWKV 的本地部署和推理教程、RWKV 的全参/微调训练教程，以及 RWKV 最新新闻动态...&lt;/p&gt; 
&lt;p&gt;RWKV 中文官网目前有四大板块，分别是首页、生态页、资讯页，以及 RWKV 中文文档页面，现在让我们一起看看这些页面都有什么内容吧！&lt;/p&gt; 
&lt;h2&gt;官网首页&lt;/h2&gt; 
&lt;p&gt;在官网首页，你可以看到 RWKV 架构特性、RWKV 最新的模型版本和下载链接、RWKV 的 Uncheatable Eval 评分，以及基于 RWKV 的落地案例等信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1084&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f42fef551ad96af8a050d31a27e9bf03ad6.png&quot; width=&quot;2430&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;生态页&lt;/h2&gt; 
&lt;p&gt;生态页面则包含 RWKV 多模态等相关研究和论文、RWKV 的在线体验 Demo、RWKV 的多模态模型，以及一些效果较好的 RWKV 社区微调模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1017&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b44edeb913197190de3ea56d88ce4dd80d.png&quot; width=&quot;1762&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;资讯页&lt;/h2&gt; 
&lt;p&gt;在资讯页可以查阅 RWKV 最新的动态新闻，包括 RWKV 近期发布了哪些新模型或论文、RWKV 是否举办社区活动或参加外部活动，方便大家了解 RWKV 的最新动态。&lt;/p&gt; 
&lt;p&gt;此外，「技术博客」板块会分享 RWKV 相关的技术内容，例如 RWKV 的微调、基于 RWKV 的新应用、新研究等内容。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1168&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca9d95ad241abb3c038caab27ed24e24693.png&quot; width=&quot;2133&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 中文文档&lt;/h2&gt; 
&lt;p&gt;RWKV 官网的&lt;strong&gt;文档页&lt;/strong&gt;包含了 RWKV 的中文教程文档，比如 RWKV 百科、RWKV 微调教程、RWKV Runner 和 Ai00 等 RWKV 本地部署工具的推理和 API 等教程。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1170&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4653e825e9ce0040b3e514b2c9f24ee60a3.png&quot; width=&quot;2418&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;小提示：文档页支持明亮模式和黑夜模式，可以点击页面左下方的菜单进行调整。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;p&gt;作为一个刚上线的站点，RWKV 中文官网肯定会有不足之处。如果您发现网站存在 Bug ，或者希望网站添加某个方向的 RWKV 相关内容，欢迎发生邮件到 「contact@rwkvos.com」 向我们反馈！&lt;/p&gt; 
&lt;p&gt;点击下方的 「阅读原文」 ，可以直达 RWKV 中文官网（&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F%25EF%25BC%2589%25E3%2580%2582&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/）。&lt;/a&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302975</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302975</guid>
            <pubDate>Fri, 19 Jul 2024 10:56:45 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源日报 | 微软蓝屏波及全球；GPT-4o 迷你版；泡沫最大的半导体公司；GPU 独孤求败？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.7.19&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302903/latest-crowdstrike-update-causes-blue-screen-of-death-on-windows&quot;&gt;Crowdstrike 更新导致全球 Windows 大面积蓝屏死机&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&lt;span&gt;全球大量&amp;nbsp;&lt;/span&gt;Windows 用户今天在更新 CrowdStrike 后遇到了蓝屏死机 (BSOD) 错误。&lt;/span&gt;该问题似乎很普遍，影响运行不同 CrowdStrike 版本的机器。在社交媒体上，全球不同地区的用户纷纷在抱怨这个突如其来的蓝屏死机错误。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a6e7c309e7dde294b84a38e4898d503b6c2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302869/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules&quot;&gt;英伟达全面转向开源 GPU 内核模块&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;英伟达通过官方博客现在&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fzh-cn%2Fblog%2Fnvidia-transitions-fully-towards-open-source-gpu-kernel-modules%2F&quot; target=&quot;_blank&quot;&gt;正式宣布&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;，其开源内核模块最终将取代闭源驱动 —— 目前正处于完全过渡到开源 GPU 内核模块的时刻。在即将发布的 R560 驱动版本中，他们将作出这一更改。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;借助 R515 驱动程序，英伟达于 2022 年 5 月发布了一套开源的&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.nvidia.cn%2Fzh-cn%2Fblog%2Fnvidia-releases-open-source-gpu-kernel-modules%2F&quot; target=&quot;_blank&quot;&gt;Linux GPU 内核&lt;/a&gt;模块，该模块采用双许可证，即 GPL 和 MIT 许可。初始版本主要面向数据中心计算 GPU，而 GeForce 和工作站 GPU 则处于 Alpha 状态。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;当时，他们宣布在后续版本中将提供更可靠、功能齐全的 GeForce 和工作站 Linux 支持，&lt;strong&gt;NVIDIA 开放内核模块最终将取代闭源驱动&lt;/strong&gt;。&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302856/openai-gpt-4o-mini&quot;&gt;OpenAI 发布「小」模型 GPT-4o Mini&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GPT-4o mini GPT-4o mini 在 MMLU 上的得分为 82%，目前在 LMSYS 排行榜（在新窗口中打开）上的聊天偏好方面优于 GPT-4。它的价格为每百万输入代币 15 美分，每百万输出代币 60 美分，比以前的前沿模型便宜一个数量级，比 GPT-3.5 Turbo 便宜 60% 以上。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0719/101059_1rfr_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;GPT-4o mini 以其低成本和低延迟实现了广泛的任务，如连锁或并行多个模型调用（如调用多个 API）、向模型传递大量上下文（如完整代码库或对话历史）或通过快速、实时文本回复与客户交互（如客户支持聊天机器人）的应用。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前，GPT-4o mini 的应用程序接口支持文本和视觉，未来还将支持文本、图像、视频和音频输入和输出。该模型的上下文窗口可容纳 128K 标记，每个请求最多支持 16K 输出标记，知识库可持续到 2023 年 10 月。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GPT-4o mini 现已作为文本和视觉模型提供给助手应用程序接口（Assistants API）、聊天完成应用程序接口（Chat Completions API）和批处理应用程序接口（Batch API）。在 ChatGPT 中，免费、Plus 和 Team 用户从今天开始将能访问 GPT-4o mini，以取代 GPT-3.5。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/302881/deepseek-v2-0628-lmsys-leaderboard&quot;&gt;DeepSeek-V2 登上全球开源大模型榜首&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;美国时间 2024 年 7 月 16 日，LMSYS 组织的大模型竞技场（Chatbot Arena）更新结果发布，DeepSeek-V2-0628 超越 Llama3-70B、Qwen2-72B、Nemotron-4-340B、Gemma2-27B 等开源模型，登上全球开源模型榜首。&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/291284&quot;&gt;DeepSeek-V2&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;&amp;nbsp;是幻方量化旗下组织深度求索在今年 5 月份发布的第二代开源 MoE 模型，其优势包括：参数更多、能力更强、成本更低。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0719/113534_3J1h_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2652916941%2FOocMnslpi%23repost&quot; target=&quot;_blank&quot;&gt;2022 年 11 月开源，我们达到一个小小的里程碑：4000 star&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt;
     2022 年 11 月开源，到现在也还没满两年，我们达到一个小小的里程碑：4000 star，并且国内和海外对半开。这个过程没有什么奇技淫巧，我坚信老老实实做好产品和技术，老老实实去做好社区，这是一家以开源为本的公司的基础。让我开心的是，我们的独立贡献者有 70~80 个，大部分不是一些简单的修正（当然，我们也非常欢迎），而是深度参与了一些 feature 的研发，由衷地表示感谢。#GreptimeDB#
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;zx-dennis&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1757693565%2FLDciEd1ps&quot; target=&quot;_blank&quot;&gt;从一个建筑生成器变成了城市生成器&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p&gt;从去年开始，就看到大佬 Pavel Oliva 在推上频繁地测试自己的建筑生成器 Buildify，最近终于发布了。没想到的是，已经从一个建筑生成器变成了城市生成器，还完美兼容知名开源地理插件 Blender OSM。而更没想到的是，免费，可商用。&lt;/p&gt; 
     &lt;p&gt;▶ 下载地址：&lt;span style=&quot;background-color:#ffffff; color:#636363&quot;&gt;https://paveloliva.gumroad.com/l/buildify&lt;/span&gt;&lt;br&gt; ▶ 神仙作者：Pavel Oliva&amp;nbsp;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;Simon_阿文&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fawtmt.com%2Farticles%2F3719673&quot; target=&quot;_blank&quot;&gt;GPU，独孤求败?&lt;/a&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;p&gt;据台媒报道，台积电近期准备开始生产英伟达最新 Blackwell 平台架构 GPU，同时因英伟达的客户需求强劲，故此对台积电的晶圆订单增加 25%；并有可能令本周放榜的台积电上调今年盈利预期。&lt;/p&gt; 
     &lt;p&gt;报道引述业界消息指出，亚马逊、戴尔、谷歌、Meta 及微软等都会使用 Blackwell 架构 GPU 来建立 AI 伺服器，令需求超出预期。&lt;/p&gt; 
     &lt;p&gt;英伟达的利好，让大家对人工智能、GPU 和 AI 芯片有了更多的想法，但这能继续持续吗？&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
   &amp;nbsp;
  &lt;/div&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- &lt;strong&gt;半导体行业观察&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzUzODc0MjQwOA%3D%3D%26mid%3D2247506774%26idx%3D2%26sn%3D6061c04330c0d15652a3518132a486a3%26scene%3D0&quot; target=&quot;_blank&quot;&gt;史上最大泡沫的半导体公司&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;谁是全球最大泡沫的半导体公司？有人说是英伟达。&lt;/p&gt; 
  &lt;p&gt;但是，英伟达的动态估值只有 60 倍，以它仍然无懈可击的 GPU 产品，以及垄断市场的地位，你很难说这个估值高得离谱，何况，AI 未来是何等的星辰大海。&lt;/p&gt; 
  &lt;p&gt;更重要的是，英伟达完全能够交得出业绩，90% 的毛利率，50% 的净利率，一年数百亿美元的净利润，距离微软的水平也不是很遥远，你可以说英伟达的估值不便宜，但说是泡沫，似乎也不妥。&lt;/p&gt; 
  &lt;p&gt;如果对比另外一个半导体公司，英伟达的估值可以说低得可怜。因为那家半导体公司的动态 PE，是英伟达的 10 倍。不到一年时间，它的市值暴涨 4 倍，接近 2000 亿美元。而一年的营收，在 30 亿美元的水平，净利润只有区区 3 亿美元，算下来，PE 接近 600 倍。&lt;/p&gt; 
  &lt;p&gt;这家公司叫 ARM。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微信&amp;nbsp;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;格隆汇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FOobOXexSE&quot; target=&quot;_blank&quot;&gt;DeepSeek 刚刚发布了他们最新的 DeepSeek-V2-0628&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;DeepSeek 刚刚发布了他们最新的 DeepSeek-V2-0628，在 huggingface 已经可以下载了，但是这个非量化版本实在是太大了，达到了 236B, 按照官方的说法, 需要 8 块 80G 的显卡才能跑起来. 即使是 4bit 量化的版本 (由于刚发布 3 小时, 还没人去量化), 估计消费级硬件也只有 192G 的顶配 Apple M2 Ultra 可以试一试了. 好奇为啥不推出一款差不多 70b 的型号? 33b 的倒是有, 但是还没更新。&lt;/p&gt; 
  &lt;p style=&quot;text-align:right&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;karminski-牙医&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.cn%2Ftech%2F2024-07-18%2Fdetail-inceqqcu6224066.d.html&quot; target=&quot;_blank&quot;&gt;摩尔线程万卡 GPU 集群新进展！性能可提升 20 倍&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#000000; margin-left:0; margin-right:0; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;摩尔线程官方宣布，与清华系 AI 系统软件公司清程极智正式建立战略合作关系，旨在加速国产大规模 GPU 智算集群的产业化进程，推动 AI 算力生态的快速发展，为大模型行业提供更强大、灵活且高效的基础设施支持。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;快科技&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.shangyexinzhi.com%2Farticle%2F21020999.html&quot; target=&quot;_blank&quot;&gt;中国市场手机 AI 用什么大模型？三星增加了字节豆包，市场还在等待苹果的答案&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;在一段时间的摸索和沉淀之后，各家 AI 手机的战略轮廓逐渐变得更加清晰，厂商们在自研大模型之外，也陆续尝试接入 AI 公司的通用大模型，比拼用户体验。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;蓝鲸财经&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.app.dawuhanapp.com%2Fp%2F39348582.html&quot; target=&quot;_blank&quot;&gt;鸿蒙生态创新中心落地武汉，将重点做这些事——&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;鸿蒙生态（武汉）创新中心是继深圳、成都之后，华中首个、全国第三个鸿蒙生态创新中心，是一个集技术服务、展示体验、教育培训、活动推广等功能于一体的高水平公共服务平台。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;大武汉&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F3g.k.sohu.com%2Ft%2Fn807210882&quot; target=&quot;_blank&quot;&gt;4 年、230 亿美元、创谷歌收购纪录，这家公司怎么做到的？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:start&quot;&gt;在竞争激烈的市场中，Wiz 的卖点是「一站式平台」，提供云工作负载保护（CWPP）、云安全姿态管理（CSPM）、云基础设施权限管理（CIEM）等功能。同时，Wiz 还与许多其它初创公司合作，建立生态系统，提供灵活性。&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;极客公园&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fk.sina.cn%2Farticle_1750070171_684ff39b02001a8vo.html&quot; target=&quot;_blank&quot;&gt;GPT-4o 迷你版发布，ChatGPT 杀死 ChatGPT&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#1a1a1a; text-align:justify&quot;&gt;自 2023 年下半年起，「落地」就成了 AI 圈内最常提及的话题。一个明显的趋势是，为了加快 AI 的落地，模型尺寸在变小，更轻量、更垂的模型不断推出，模型变得越来也便宜。&lt;/p&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;strong&gt;36 氪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffinance.sina.com.cn%2Froll%2F2024-07-18%2Fdoc-inceqcpw8606444.shtml&quot; target=&quot;_blank&quot;&gt;中国电信星辰大模型首次落地手机终端&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国电信推出首款 AI 手机麦芒 30，搭载高通骁龙 695 处理器，内置中国电信自研的星辰大模型。据了解该手机可实现文案创作、图像生成、智能问答、一键调用 AI 等功能。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;第一财经&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ft.cj.sina.com.cn%2Farticles%2Fview%2F5953466483%2F162dab07301901aam8&quot; target=&quot;_blank&quot;&gt;突破 CUDA 包围圈，再出一招&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;为了突破 CUDA 护城河，现在已经有各种努力，比如 HIPIFY 帮助将 CUDA 源代码转换为适用于 AMD GPU 的可移植 C++ 代码，然后是之前由 AMD 资助的 ZLUDA，允许 CUDA 二进制文件通过 CUDA 库的直接替换在 AMD GPU 上运行。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;但现在又出现了一个新的竞争者：SCALE。SCALE 现已作为 GPGPU 工具链公开，允许 CUDA 程序在 AMD 图形处理器上本地运行。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:right&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;半导体行业观察&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenturns%2Fopenturns&quot; target=&quot;_blank&quot;&gt;openturns/openturns&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;300&quot; src=&quot;https://static.oschina.net/uploads/space/2022/0309/162049_93U0_4252687.png&quot; width=&quot;450&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopenturns%2Fopenturns&quot; target=&quot;_blank&quot;&gt;https://github.com/openturns/openturns&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;OpenTURNS 是一个 C++ 和 Python 库，内置专用于处理不确定性数据的模型和算法。该库的主要目标是提供处理工业应用研究中的不确定性所需的所有功能。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/4939618/blog/11209676&quot; target=&quot;_blank&quot;&gt;如何实现埋点日志精准监控&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;日志中台承载了百度千亿量级 PV 的埋点流量，如何对这些流量进行准确监控，并支持个性化字段的抽取、下钻，是日志中台的一大难题。本文简单介绍了日志中台的基本概念及实时流架构，并基于此深入讲解了低成本实现可扩展、高准确度的埋点监控的技术方案。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img alt=&quot;图片&quot; height=&quot;273&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1fd9e4039010395c4724a35238f95ae75a0.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-e6qyQaUxaKZDJ5LRiQ5Qg&quot; target=&quot;_blank&quot;&gt;Crowdstrike 更新导致全球 Windows 大面积蓝屏死机&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：信息安全厂商 CrowdStrike 的一款产品在更新后，众多运行 Windows 的电脑瞬间成废砖。CrowdStrike 的首席威胁猎人 Brody Nisbet 已确认了这个问题，并在 X 上发布了以下内容： 存在一个有错误的通道文件，所以不是完全意义上的正确更新。有一种解决方法：1、引导 Windows 进入安全模式或 WRE。2、进入 C:\Windows\System32\drivers\CrowdStrike。3、找到并删除匹配「C-00000291*.sys」的文件。4. 正常启动。他在后来的另一个帖子中写道：「这个解决方法并不能帮助所有人，不过我目前也没有进一步可付诸实践的方法可以帮助用户。」&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：睡醒后，全公司都蓝屏了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：夫妻双双把家还。干不了活，回家了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：刚刚经历蓝屏，公司几百台办公笔记本电脑一台接一台蓝屏。在家办公的也未能幸免。起初还以为是公司网络故障导致的。工作的激情戛然而止，公司一下子热闹起来。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：为了给中国的牛马休息，微软他，我哭死！&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：哭错坟了兄弟，这不是微软的&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：这是上公有云的优点之一&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：网管：重启，或者换台电脑，试试！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：Linux 用户前来吃瓜&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：我说今儿为啥 OneDrive 提示「很抱歉，OneDrive 服务器出现问题 -- (错误代码: 0x8004def5)」&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：这是另外一个问题&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：我用 MAC 别和我聊这个话题&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：有个问题，蓝屏了，想截屏发个朋友圈该怎么截？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：用门锁拍，拍完记得还回去&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：重命名一下文件就行，别忘了 sudo 提权&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/302720/google-now-defaults-to-not-indexing-your-content&quot; target=&quot;_blank&quot;&gt;Google 搜索引擎默认不再索引新内容&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：本身是消费端【找内容】的主场景，已经变成生产端【内容曝光】的主场景。搜索领域的「推荐算法、信息流」该革新了，不管是个性化还是非个性化方向。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：感觉就是从年初开始，google 的搜索质量确实越来越差了，无论是中文英文&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：翻译一下： 你们产出的垃圾内容太多了，我们的服务器不够用了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：不索引新内容如何发现新「独角兽」呢？这样会加强既得势者的垄断，保护了垄断者，拒绝了新创新者。&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/news/302713/deepin-m1-updates-to-rc2&quot; target=&quot;_blank&quot;&gt;新进展！deepin M1 项目更新至 deepin V23 RC2 版本&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：一堆 bug 没解决去适配 mac&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：你可以自己动手解决 bug，也可以多捐钱加快 bug 处理速度， 不要一边吃饭一边骂厨子&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：Fedora 适配好几年了，驱动拷过来就行了，这还值得写一下？&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：deepin 底层是 ubuntu，他可适配不了 centos&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：v23 rc2 是真的难用，各种 bug 多的要死&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fa2aARBU7HLvlPNGJv9Uu_Q&quot; target=&quot;_blank&quot;&gt;编程高手如何给代码「下毒」？&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：直接代码里暗度陈仓，留点小秘密，被优化后，到黑市上以另一个身份，贩卖个好价钱，一石二鸟，既给自己创收，又让压力到了对方那边。并且这锅到时候也不用你背，顶多算 bug&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：话说，你不删都崩溃的代码，为什么要多此一举，给公司创造利益。我的意思是，删代码，公司起诉你，找你索赔这种方式创造利润。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：没事，正常写也是屎山，无需刻意&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：写成废码，说得好像请你回来，你能维护一样，搞笑&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：程序员何苦为难程序员，老板哪会关心代码怎么写的，有问题背锅的是下一个程序员，怎么实现我不管，限你今天就搞定&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：数据清洗技术，代码质量评分，AI 优先淘汰废码程序员&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：如果 AI 给代码埋雷没有任何人会知道&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：每天一条辞职小技巧&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：打工人互害&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：公司也学会防御性审核，一旦发现防御性代码，立即开除而且无需补偿&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：代码进分支不会审查吗？不能随便什么代码都进&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：情绪化严重的码农，泄愤都未必代表事情的经过他是对的，有可能是唯心主义者&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：你这样敲码的话，有没有一种可能，没等公司把你辞退，你就率先因为看不懂自己上个月写的代码而提桶跑路了？&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：过于愤世嫉俗了哇，人人微笑，微笑人人！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：连代码审核都不做的公司，跑就跑了，还弄这么多花花肠子&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;最后，欢迎扫码下载「开源中国 APP」，阅读海量技术报告、程序员极客分享！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d27cc3636c021c266537f4729dc0f84fdc3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302974</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302974</guid>
            <pubDate>Fri, 19 Jul 2024 10:53:45 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV-6-World 14B 正式开源发布，迄今最强的稠密纯 RNN 大语言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2024 年 7 月 19 日，RWKV 开源基金会宣布正式向全球开源 &lt;strong&gt;RWKV-6-World-14B&lt;/strong&gt; 模型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV-6-World-14B 是迄今最强的稠密纯 RNN 大语言模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在最新的性能测试中， RWKV-6-World 14B 模型英语性能相当于 Llama2 13b。此外，在同参数的模型评测中，RWKV-6-World 14B 的&lt;strong&gt;多语言性能显著最强&lt;/strong&gt;，且&lt;strong&gt;支持全球 100+种语言和代码&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;在「无法作弊的模型评测」 Uncheatable Eval 排行榜中，RWKV-6-World 14B 的综合评测分数比 llama2 和 Qwen1.5 更强。&lt;/p&gt; 
&lt;h2&gt;评测数据&lt;/h2&gt; 
&lt;p&gt;本次模型基准测试涵盖了 &lt;strong&gt;4&lt;/strong&gt; 款接近 &lt;strong&gt;14B&lt;/strong&gt; 参数规模的开源大语言模型。&lt;/p&gt; 
&lt;p&gt;在测试中，英语的性能测试将通过 12 个独立的基准测试来衡量大模型在常识推理和世界知识等英语内容上的表现。&lt;/p&gt; 
&lt;p&gt;多语言能力的评估中，则采用了 xLAMBDA、xStoryCloze、 xWinograd 和 xCopa 四种基准测试，深度探索了评估模型在多语言环境中的逻辑推理、故事理解、歧义解决和因果推理能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8cb336e733632131a25421ba02f04a29a7c.png&quot; width=&quot;1773&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;由于 RWKV-5 系列模型最大只有 7B 参数，我们选择了 RWKV-4 14B 模型作为纵向对比。&lt;/p&gt; 
&lt;p&gt;可以看到，相比于此前发布的 RWKV-4 14B 模型，RWKV-6-World 14B 的&lt;strong&gt;英文&lt;/strong&gt;性能和&lt;strong&gt;多语言&lt;/strong&gt;性能都获得巨大提升。&lt;/p&gt; 
&lt;p&gt;RWKV-6-World-14B 模型的性能改进，大大得益于从 RWKV-4 到 RWKV-6 的架构改进，有关 RWKV-6 架构的优化细节，请参考文章：&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FBP0zlW2MT50gt3QpNjFwqQ&quot; target=&quot;_blank&quot;&gt;RWKV-6 论文到底说了什么？分享会回顾来啦！&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;不作弊的 RWKV 模型&lt;/h2&gt; 
&lt;p&gt;值得强调的是，我们在训练 RWKV 模型时，并未加入任何基准测试的数据集。换言之，我们没有为了获取更佳的评分结果而进行&lt;strong&gt;特殊优化&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;RWKV 不刷榜也不刷星，因此 RWKV 模型的实际能力比它的各种评分排行更强。&lt;/p&gt; 
&lt;p&gt;既然承诺不作弊，我们也第一时间对 RWKV-6-World-14B 模型进行了 &amp;nbsp;「无法作弊的模型评测」 —— &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval&quot; target=&quot;_blank&quot;&gt;Uncheatable Eval&lt;/a&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Uncheatable Eval 会使用最新的 arXiv 论文和新闻文章等&lt;strong&gt;实时语料库&lt;/strong&gt;，以此来评估语言模型的真实建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;有关 Uncheatable Eval 的详细介绍，可参见此文章：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FifsgWchvSow9JU2tNMvJZA&quot; target=&quot;_blank&quot;&gt;RWKV 在「不可作弊的模型评测」中获得良好成绩&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-6-World 14B 的 Uncheatable Eval 评测&lt;/h3&gt; 
&lt;p&gt;此次 Uncheatable Eval 评测选取了常见的 &lt;strong&gt;5&lt;/strong&gt; 款开源 &lt;strong&gt;14B&lt;/strong&gt; 参数模型，测评数据则选择 &lt;strong&gt;7 月最新发布&lt;/strong&gt;的 arXiv 论文、新闻、ao3 小说和 GitHub 代码等实时数据。&lt;/p&gt; 
&lt;p&gt;具体评分和综合排名如下：&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-625a8beb483bb9abdb043140d406a9e3837.png&quot; width=&quot;1462&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以看到，RWKV-6-World 14B 在此次测试中排行&lt;strong&gt;第 2&lt;/strong&gt;，&lt;strong&gt;综合评测分数比相同尺寸的 llama2 和 Qwen1.5 更强。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;而 Mistral 最新发布的 12B 模型使用了比 RWKV-6 多几倍的数据，它的性能更强。我们会继续为 RWKV 模型补充优质数据，与它看齐。&lt;/p&gt; 
&lt;h2&gt;模型下载和体验&lt;/h2&gt; 
&lt;p&gt;目前 RWKV-6-World 14B 模型还没有在线 Demo，可以从以下平台下载 RWKV-6-World 14B 模型并&lt;strong&gt;本地部署&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-6-world%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv-6-world/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ModelScope：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv-6-world%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/rwkv-6-world/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRwkv-6-world%2Ffile&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/Rwkv-6-world/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;由于 Ai00 只支持 safetensor（&lt;code&gt;.st&lt;/code&gt;）格式的模型，如果你打算使用 Ai00 体验 RWKV-6-World 14B 模型 ，可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcgisky%2Fai00_rwkv_x060%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;Ai00 HF 仓库&lt;/a&gt;中下载&lt;strong&gt;已经转成 .st 格式的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;本地部署 14B 模型的显存需求&lt;/h3&gt; 
&lt;p&gt;如果你计划本地部署并推理 RWKV-6-World 14B 模型，参考的 VRAM （显存）消耗如下：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;量化方式&lt;/th&gt; 
   &lt;th&gt;显存参考&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fp16&lt;/td&gt; 
   &lt;td&gt;约 28G&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;int8 -量化 56 层&lt;/td&gt; 
   &lt;td&gt;约 15G&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nf4 - 量化 56 层&lt;/td&gt; 
   &lt;td&gt;约 10G&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;新模型效果预览&lt;/h2&gt; 
&lt;p&gt;以下为 RWKV-6-World 14B 模型的实测效果：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以下案例使用 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2Fai00%2FIntroduction&quot; target=&quot;_blank&quot;&gt;Ai00&lt;/a&gt; 作为推理服务器，int8 + 30 层量化，未加载任何 State&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;自然语言处理（情感分析）&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;1773&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-09c6e1bc589e25f4503b2ba238ac602cee7.png&quot; width=&quot;1733&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;自然语言处理（机器阅读理解）&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;831&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9c45d572025904359c754576f9ddd9b3fce.png&quot; width=&quot;1727&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;散文诗文学创作&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;1146&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-733fa5608aa98d12f1043dd5352c18eecb5.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;阅读并修改一段代码&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/0f0618be-7598-4374-8b81-70b601f3271b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;2432&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5e30b9e87d6fce96bc82df6bf088c58ee3b.png&quot; width=&quot;1736&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;金融学论文选题建议&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/36151cd5-ec32-4e29-94f0-d7b9512f1b42.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;1063&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1e79ff8414e6d3456e4d3dfca3d659247c7.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;提取新闻关键内容&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/9a53eae3-286d-4e83-8010-befa1d951573.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img height=&quot;1327&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e2e7e991aa7788cf6856676af1cbd414a6d.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;一句话扩写文本&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;931&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ff3cbe5b93dc1a7591e0bf07e2f824aea85.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&amp;nbsp;&lt;/h3&gt; 
&lt;h3&gt;python 编程贪吃蛇小游戏&lt;/h3&gt; 
&lt;p&gt;&lt;img height=&quot;3803&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-969c48a5a664382fed965153e98ef11eeb0.png&quot; width=&quot;2000&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/870e8170-9810-4a99-9a97-6b3a71ce04fd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意：目前开源发布的所有 RWKV 模型均为基底模型。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基底模型具备一定的指令和对话能力，但为了保持其通用性和泛化能力，基底模型未进行任何对齐，也未针对某一类任务做优化。因此，&lt;strong&gt;基底模型在特定任务上的表现并不代表 RWKV 模型最优水准。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果希望 RWKV 模型在某种类型的任务上表现良好且稳定，建议使用此类任务的数据集对 RWKV 模型进行微调训练。&lt;/p&gt; 
&lt;p&gt;目前我们已经发布了一些 RWKV 基底模型对特定任务进行微调训练的教程，详情可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2FRWKV-Fine-Tuning%2FIntroduction&quot; target=&quot;_blank&quot;&gt;RWKV 中文文档 - RWKV 微调教程&lt;/a&gt; 中查看。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;随着 RWKV-6 架构发布 14B 模型，&lt;strong&gt;RWKV-7 架构的测试工作也在紧密地进行中&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此外，RWKV 社区近期有很多新的研究，比如首个基于 RWKV 的医学图像修复模型 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2407.11087&quot; target=&quot;_blank&quot;&gt;Restore-RWKV&lt;/a&gt; 、海外社区做的 RWKV + Attention 混合架构 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2407.12077&quot; target=&quot;_blank&quot;&gt;GoldFinch &lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;我们很快会带来更多 RWKV-7 的消息，敬请关注「RWKV 元始智能」公众号，以在第一时间获取 RWKV 最新动态。&lt;/p&gt; 
&lt;h2&gt;RWKV 模型介绍&lt;/h2&gt; 
&lt;p&gt;RWKV 是一种创新的深度学习网络架构，它将 Transformer 与 RNN 各自的优点相结合，同时实现高度并行化训练与高效推理。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RWKV 模型架构论文：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RWKV-4&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13048&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2305.13048&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RWKV-5/6（Eagle &amp;amp; Finch）：&lt;/strong&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.05892&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.05892&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入我们的 QQ 频道和群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 中文官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QQ 频道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://www.oschina.net/news/302972</link>
            <guid isPermaLink="false">https://www.oschina.net/news/302972</guid>
            <pubDate>Fri, 19 Jul 2024 10:49:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>发布 「k8s 生态周报」 这件小事，他坚持了 5 年</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;8 月 15 日至 16 日，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://gotc.oschina.net/&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;GOTC 2024 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;将在上海张江科学会堂盛大开启。云原生技术专家、Kong 高级软件工程师张晋涛将以「云原生与微服务架构」论坛出品人的身份出席大会，并以《云原生时代下企业流量治理的机遇和挑战》为题发表演讲。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这是张晋涛第二次参加 GOTC 大会。三年前参加首届 GOTC 大会时，开源中国 OSCHINA 对他&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/question/4489239_2323127&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;进行了采访&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;，那时他还是 k8s ingress-nginx 项目的 reviewer，现在他已经是这个项目的 maintainer。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;不变的是，他仍然专注于云原生技术领域，为 Containerd、Docker、Helm、k8s、KIND 等众多开源项目贡献代码。还有一件事，就是坚持更新「k8s 生态周报」。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;587&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f41c9022be8ed6b3fadaf5d72fc65d461c6.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;云原生技术专家、Kong Senior Software Engineer&amp;nbsp; 张晋涛&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2019 年 3 月 25 日，张晋涛发布了第一篇《k8s 生态周报》，篇幅较短，不过百余字。文中记录着：Docker 6 周岁， 已一度成为容器技术的代名词。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从那以后，张晋涛每周都会固定发布一篇 k8s 生态领域的相关文章，持续了近五年。最后一篇是在去年年底，两千多字，除了有 k8s v1.29 正式发布的消息之外，还记录着：在 Docker 十周年，Docker Inc. 收购了开发框架 Testcontainers 背后的公司 AtomicJar。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;他观点鲜明：」Docker Inc. 只要保持住当前的势头继续发展，应该还是可以有个不错的发展的，毕竟 Docker 也确实是个生产力工具，用户基数在那里的。「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;348&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2be0c0bc76d5e0d43878e80a05eab2b86e.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这五年中，k8s 生态圈内大大小小的事，只要是张晋涛认为值得关注和推荐的内容，他都会记录下来，加上自己的观点，再发布出去。见解越来越多，篇幅也越来越长。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;张晋涛曾表示：「k8s 生态中相关信息和变化有很多，在这个信息爆炸的时代，稍不留神就会错过很多有价值的信息，但持续地去追这些消息，也过于浪费时间，而且还需要去筛选信息。」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《k8s 生态周报》的持续更新，让他一直保持着对前沿技术的关注，能够更好地把握前进的方向，不至于在技术更迭的浪潮中迷茫。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;身处其中，张晋涛对技术走向有着敏锐的直觉。他曾预测，2022 年 k8s 的技术趋势可能将围绕安全性和 eBPF 展开。现在回过头来看，不论是 2022 年 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cncf.io%2Freports%2Fcncf-annual-survey-2022&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;CNCF 报告中&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;凸显的企业对安全性的关注，还是 L3AF 开源、cilium 在厂商中的落地和普及，都证明了事实确实如此。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;关于 k8s ，我们有很多问题想问他：哪些技术或趋势在 2023 年变得尤为重要？今年又有什么变化？这种变化对行业意味着什么？未来几年内 k8s 会朝哪个方向发展？来来看看张晋涛的答案。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;在 k8s 领域，你认为哪些技术或趋势在 2023 年变得尤为重要？今年 k8s 有什么变化引起你的注意？这种变化对行业意味着什么？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2023 年，安全性仍然是一个很重要的部分，加上也发生了很多相关的事件，这让整个行业都对安全进行了更加广泛的思考。其次就是，AI 技术持续火热，几乎所有厂商默认选择将 k8s 作为标准的基础设施，所以对于如何在 k8s 上进行 AI 的训练和部署及 GPU 调度等，也是非常重要的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;除了 AI 和安全之外，今年 k8s 领域还清理了很多历史遗留问题，对一些前几年活跃但现在逐渐不维护的项目进行归档以及合并。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这其实释放了两个信号：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;维护者团队的新生力量不足，在进行开源项目的维护中，新生代力量很重要，但是对于已经存在几年的项目而言，进入项目的门槛也在相应地提高。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;行业焦点正在从原先单纯的 infra 逐步向上层迁移，以 k8s 为首的 infra 已经成为行业标准，所以后续对于 infra 只会更加聚焦和集中。接下来三到五年中，云原生生态中不会再像前几年那样有大量新的项目呈井喷式出现，而是会将现有的项目推向行业标准。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;基于你对 k8s 生态的理解，再次大胆地预测一下，未来几年内 k8s 会朝哪个方向发展，以及有哪些潜在的挑战和机遇。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;目前一个最为突出的方向就是与 AI 的集成。随着 ChatGPT 等 AI 技术浪潮的到来，这一趋势更加明显。 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;挑战的话，主要是两个方面：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;k8s 最初并不是为 AI 或者说 GPU 调度诞生的，所以这些集成/扩展都是构筑在现有的 k8s 之上的。但 k8s 还是很复杂的，有一些设计方面的挑战需要解决。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GPU 厂商有很多，异构计算也是一个很主要的方向。尤其是在国内，要解决更多适配的问题，并且这些厂商可能并不能由开源社区的上游进行推动。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;但是机遇也很多的，因为现在这方面也属于市场竞争的早期，同时无论是 infra 或者是相应的产品等，还在持续地创新和涌现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;您在 2023 年总结中提到，目前在 Kong Inc. 做 k8s 相关的事情，包括上游的 Gateway API、Kong k8s Ingress controller、Helm chart、Operator 等项目。这些都是与 k8s 生态紧密相关的开源项目。你对开源是怎么看的？会如何影响你的日常工作？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;感谢开源。我很早就开始接触开源，并且也一直在积极参与到开源项目和开源社区中。在这个过程中我学习到了很多，也认识了很多有趣的伙伴，我的职业发展其实也可以说是围绕着开源展开的。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Kong Inc. 是一家开源商业化公司，公司鼓励大家参与到开源社区中，积极&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;地&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对开源项目作出贡献。所以这并不会影响到我的日常工作。同时我们也是 k8s Gateway API 项目的活跃贡献者和维护者，通过积极地和上游社区进行协作，也可以更好地让我们的项目得到发展，达到双赢的状态。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;你对 2024 年有哪些个人目标或期待？你希望在哪些方面取得进步？有什么计划去实施？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2024 年已经过去一半，今年计划排得&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;比较满，所以鸽了一些文章，期待下半年我能更好地安排时间，恢复我的更新。同时，今年也在更加积极地活跃在 AI 领域，希望能将自己过往的一些 AI 经验与现在的 LLM 及相关产品进行融合，发挥更大的价值。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;再次参加 GOTC 大会，并成为「云原生与微服务架构」论坛的出品人，有什么想对参会者说的？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;欢迎大家来参加 GOTC 大会，这绝对是一场充满干货的盛会！同时也是一个非常好的机会，可以和各行业的朋友们进行交流和面基，了解大家现在在做什么，有遇到哪些问题和解决问题的思路。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;同时「云原生与微服务架构」场，非常欢迎对云原生和微服务架构感兴趣的朋友来围观，本次聚集了来自 AWS、华为、腾讯、AutoMQ、云杉网络等多个公司的新老朋友来分享大家来自生产实践总结的经验，相信一定能为大家带来有价值的精彩分享！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;GOTC 2024 报名通道现已开启，诚邀全球各技术领域开源爱好者共襄盛举！&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参会报名，请访问&lt;/strong&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huodongxing.com%2Fevent%2F8762568606000%3Ftd%3D6895280870225&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#3370ff&quot;&gt;https://www.huodongxing.com/event/8762568606000?td=6895280870225&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;GOTC 2024 将于 8 月 15 日在上海张江科学会堂盛大开启，为期两天。GOTC 2024 与上海浦东软件园联合举办，并结合 「GOTC（全球开源技术峰会）」 与 「GOGC（全球开源极客嘉年华）」，旨在打造一场全新的开源盛会。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;全球开源技术峰会（Global Open-source Technology Conference，简称 GOTC）始于 2021 年，是面向全球开发者的开源技术盛会；2024 全球开源极客嘉年华（GOGC 2024）由浦东软件园携手 S 创共建，与开源中国、Linux 基金会等品牌联合呈现。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;1081&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c757b3c3ae95b5ea402ba8821dca68b2297.jpg&quot; width=&quot;1921&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此次大会将集结全球范围内对开源技术充满热情的开发者、社区成员、创业者、企业领袖、媒体人，以及各开源项目应用场景的产业精英、跨界才俊与年轻力量。通过主题演讲、圆桌讨论、创新集市、人才集市、黑客松、技术展示和互动工作坊等形式，与会者将有机会交流实践经验、探索前沿技术，让我们一起激发创新活力、展示开源魅力、促进跨领域合作。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:.0001pt; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;更多大会信息，访问官网查看：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;https://gotc.oschina.net&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    </description>
            <link>https://my.oschina.net/u/3859945/blog/11591606</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/11591606</guid>
            <pubDate>Fri, 19 Jul 2024 10:18:45 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>