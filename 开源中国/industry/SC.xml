<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 24 Jul 2025 02:43:00 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>抖音集团基于 Flink 的亿级 RPS 实时计算优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-299b0ad831e8aa86ddb446bf5085c13099e.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;**摘要：**本文整理自抖音集团数据工程师陶王飞和羊艺超老师，在&amp;nbsp;Flink&amp;nbsp;Forward&amp;nbsp;Asia&amp;nbsp;2024&amp;nbsp;生产实践（一）专场中的分享主要内容主要分为以下四个部分：&lt;/p&gt; 
 &lt;p&gt;1、现状与痛点&lt;/p&gt; 
 &lt;p&gt;2、链路通用优化&lt;/p&gt; 
 &lt;p&gt;3、业务场景优化&lt;/p&gt; 
 &lt;p&gt;4、未来规划&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;01、现状与痛点&lt;/h2&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;1.1&amp;nbsp;业务现状&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//31bfc2c668fca07ca815665dc86dfe11.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;抖音的主要业务场景为视频和直播，实时数据在其中有着广泛应用，如实时大屏、实时预警、对内实时分析（如大盘生态监控）、实时榜单以及为推荐提供实时特征数据等。&lt;/p&gt; 
&lt;p&gt;视频场景流量巨大，晚高峰整体流量达亿级 RPS；直播场景则状态数据量大，因为业务上直播间开关播时间无限制，导致存在许多超长周期存储聚合需求。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;1.2&amp;nbsp;问题挑战&lt;/h3&gt; 
&lt;p&gt;（1）实时数仓架构图&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//68bd7c819883b62cc8ca999547327819.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;数据源层包括客户端埋点、服务端日志以及业务库数据。数仓的分层使用 Flink 计算，依次为 ODS 层（数据源层）、DWD 层（进行维表关联与简单数据处理）、DWS 层（指标计算）和 APP 层（针对具体应用场景开发），最终将数据输出至下游存储。下游存储依据业务场景选择不同，ToC 场景多使用内部的 KV 存储引擎 Abase，分析型场景及对内产品、平台则使用 ClickHouse 或 Doris，以供下游业务使用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）问题挑战&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在开发过程中，主要面临着三个问题：&lt;/p&gt; 
&lt;p&gt;其一，由于数据量大且计算复杂，致使链路稳定性差，任务频繁失败；&lt;/p&gt; 
&lt;p&gt;其二，资源消耗巨大，整体计算资源已达 30 万 core；&lt;/p&gt; 
&lt;p&gt;其三，任务异常恢复缓慢，晚高峰时异常恢复时长 30+分钟。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;02、链路通用优化&lt;/h2&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1&amp;nbsp;通用优化方案&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a5d8b340159cba4ee3ab177fb8d29116.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 DWD 明细层，优化关联操作，核心维表在此层关联，而非核心维表及字段则在 DWD 扩展层关联。DWS 层和 APP 层计算直播及视频的天级累计指标。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（1）分层建模优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在分层建模时，将相同实体、不同维度的数据合并为一张维表，以降低下游消费 RPS。在维度关联时，使用 Keyby 提升本地缓存命中率。对于 DWD 大作业，将其拆分成多个小任务灰度上线。在视频大流量场景下，采用宽表模型输出指标，即将所有数据置于一行，存储在一个 Map 中输出；直播场景则使用窄表 Anchor 模型，一条数据对应一个指标一行数据。这两种模型在新增指标时均可实现状态兼容。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（2）作业性能优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在任务层面进行性能优化以降低资源消耗，具体在后文中进行介绍。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;（3）链路保障优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对任务和队列进行分级，并构建全链路血缘来保障分级的准确性。对于高优任务，建立热备链路以及自动化容灾切换能力，提升链路大盘的容灾能力。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2&amp;nbsp;技术手段优化&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c28a4dcfac0a889caab651ef1a3670f3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在抖音短视频业务中，流量呈现高度集中，top20 个的任务占据 40% 以上的计算资源，这些任务不仅成本高，还会降低稳定性，加大运维难度。&lt;/p&gt; 
&lt;p&gt;从头部任务开发分析，部分简单的 Pipeline 任务消耗大量计算资源，可以结合火焰图查找问题的根源。如上图中左下角的火焰图，Calc 算子消耗占比达 56%，这对于非计算型的任务是明显异常情况。经分析是 JIT 及时编译优化失效所致。&lt;/p&gt; 
&lt;p&gt;再结合右侧重新开启优化后的图分析，大任务资源消耗下降约 40%。此外，火焰图中 Calc 占比较大的情况常出现在大并发 Hash 场景，上游并发×下游并发的数据输出队列会导致任务 Shuffle 利用率低，资源消耗较大。我们前后发现了十几项优化项，并推广至其他业务，最终 top 20 任务资源消耗下降约 25%。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;03、业务场景优化&lt;/h2&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1&amp;nbsp;视频场景痛点优化&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//b679d7cd16af45c7c78f1261ae8bc6d9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 DWD 明细层，关联大量维表时面临巨大压力。大流量场景下整体流量达亿级规模，无法直接请求维表，即便开启维表 LRU cache 请求量也达千万级，这带来了成本和稳定性难题。在指标聚合计算时，大流量下解决重复数据问题挑战巨大。&lt;/p&gt; 
&lt;p&gt;（1）大流量维表关联优化&lt;/p&gt; 
&lt;p&gt;①场景分析&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//591030223c0f730869a04f404767f0cc.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;高 QPS 的维表访问导致 Abase 集群压力大，Flink 任务稳定性差，关联维表成为瓶颈。虽提升维表关联缓存命中率可降低外部请求 QPS，但目前缓存命中率已达 90% 以上，提升空间有限。且并非所有维表都超大且时效性要求高，如离线用户维表和百万级监控规则表都相对较小。数仓大量使用 Abase 这种 KV 存储支持大访问 QPS，但当超出其承受能力时，会带来不可控，因此需摆脱对 KV 引擎的依赖，引入新的维表存储方式。&lt;/p&gt; 
&lt;p&gt;②解决方案&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//00d80b09acbb9c9efed83450f3201c2f.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;整体思路是将外部组件访问转化为本地访问，最直接的方式就是将数据加载到内存中完成计算。基于此，我们通过开发 UDF 将 Hive 和 MySQL 中的数据加载到内存中关联，但其并不通用，每次查询 Hive 和 MySQL 语句时需要单独指定，且只能加载少量数据，于是，我们将 UDF 升级为 Flink Broadcast join 功能。&lt;/p&gt; 
&lt;p&gt;该功能设计分为三个模块，以 Hive 为例。分区发现模块通过 Broadcast 算子监测 Hive 分区，发现新分区时，即向下游下发 Watermark 和表元数据信息；数据构建模块的数据读取算子，可配置大并发用于读取 Hive 维表数据；数据分发模块可以将读取的数据分发到各个 TM 中，根据数据量不同有两种分发方式， 即 Broadcast 方式（将全量数据 copy 分发）或根据主键 Hash 分发（适用于数据量较大场景）。&lt;/p&gt; 
&lt;p&gt;在抖音内部场景，该功能支持了千亿级别的维表关联，主要适用于大流量场景下维表关联业务，对维表更新的感知在分钟级以上。功能上线后，它替代了部分 Abase 关联任务，减少约 400 万 QPS ，相关任务在追溯场景下无外部访问瓶颈。&lt;/p&gt; 
&lt;p&gt;（2）大流量幂等计算&lt;/p&gt; 
&lt;p&gt;①场景分析&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//bd261bf4c464cd22ed668087c1c2df7b.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在大流量聚合计算优化方面，由于数据量大，短视频的小时和天级指标从分钟中间层聚合，这会导致分钟聚合输出有重复数据、乱序数据甚至回撤数据。如果直接通过先取 max 等方式聚合，其计算成本高且会引入回撤流问题，导致原本递增的埋点指标下降。以分钟向小时聚合为例，小时任务需要每一分钟的最后一条数据。&lt;/p&gt; 
&lt;p&gt;②解决方案&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f515a4786be013304ee91c7ff5a26886.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;针对以上问题，我们引入了 Bucket 的思路，即每一分钟维护一个 Bucket，保留最后一条数据，新数据到来时，将其对应的 Bucket 与原本的数据相较，仅下发正序递增数据。这样，从分钟级向小时级聚合时，即使分钟级流量达百万 RPS，最终也只有 60 个 Bucket。&lt;/p&gt; 
&lt;p&gt;基于此简化模型，如上图左下角展示的分钟数据输出，第一列是分钟值，即 Bucket key；第二列是时间位移，用于 Bucket 的时间比较；第三列是指标值。第一、二条数据均为 58 分钟，因此，其属于同一个 Bucket，数据也是正序到来的，因此，Bucket 记录为 30 秒；指标值为 100 的数据，第三条数据正常输出，第四条和第五条数据存在乱序，40 秒的数据先到，20 秒的数据后到，因此，Bucket 只记录 40 秒的数据，在 20 秒的数据进入后不再更新。这样，通过 Bucket 机制可有效处理重复下发、乱序和回撤数据，不影响小时及天指标聚合结果。&lt;/p&gt; 
&lt;p&gt;③性能优化&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//f0385e2fac946c801ad7ba46390c9b47.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;基于 Bucket 计算资源消耗仍较大，通过火焰图分析，发现 state 的序列化环节和 GC 环节占比较大，表明在状态和计算上仍有优化空间。我们从数据结构和业务两方面入手。&lt;/p&gt; 
&lt;p&gt;其一，优化 Bucket 结构，将多层嵌套结构改为两个数组，两个数组的长度等于 Bucket 的长度，无需要存储 Bucket key，按照数组的顺序取对应 Bucket。一个数组存储时间戳位移，将 long 格式的时间戳存储为 int 类型（减少存储占用），另一个数组通过字符串拼接指标值，将原本的 Map 中指标的 value 拼接成一行，节省 state 中的空间占用。&lt;/p&gt; 
&lt;p&gt;其二，进行 Bucket 时间压缩，从分钟向天级聚合最多 1440 个 Bucket，根据业务实际情况，将六个小时之前的 Bucket 压缩，Bucket 数量从 1440 个降至 378 个，降低约 70%。&lt;/p&gt; 
&lt;p&gt;完成这些优化后，整体资源消耗下降约 30%。&lt;/p&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2&amp;nbsp;直播场景痛点问题&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//8ff92760d26c1e1097ebc17a1402f5b0.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;直播场景的痛点问题主要分为计算大状态和回溯大流量两类。&lt;/p&gt; 
&lt;p&gt;首先是直播间场次聚合计算大状态。抖音直播中，直播间最长可开播 30 天，但目前 Flink 作业的 DWS 和 APP 层只计算开播后七天状态的数据，即 state TTL 为七天。其原因是目前单作业资源消耗大，最高已达 2000 核，状态可达 18T，稳定性不佳，无法简单横向扩展资源解决问题。而业务有查看直播间 30 天累计指标的诉求。&lt;/p&gt; 
&lt;p&gt;其次是冷启动和故障回溯大流量。在此场景下，回溯数据从小时到天级不等，DWS 作业向下游下发数据时会重复且大量下发，影响下游 MQ 及 Redis 等 QA 存储组件稳定性。此外，Flink 作业运行虽有资源投入，但回溯数据仍较慢，从业务视角看，存在数据恢复慢和性能指标上线周期长的问题。&lt;/p&gt; 
&lt;p&gt;针对这些问题，我们提出了相应的解决方案。&lt;/p&gt; 
&lt;p&gt;（1）大状态优化&lt;/p&gt; 
&lt;p&gt;①场景分析&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//56fdd1dd529ad5affae89677e9e98656.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对于大状态优化场景，直播间开关播时间和时长不固定，最短不到分钟级，最长 30 天，平均在小时级别。分析 Flink 作业中不同开播时长的状态大小占比发现，state TTL 为七天时，开播时长一天的直播间状态大小占 98%，这部分多存储六天；大于一天小于七天的占 1%，也存在多存情况；大于八天的仅占 0.5‰，存在少存情况。该问题的核心是状态固定的 TTL 与直播间动态的 TTL 矛盾，导致 99% 的状态多存，0.5‰状态少存。&lt;/p&gt; 
&lt;p&gt;解决思路是对齐两者 TTL，实现直播间关播后删除状态。&lt;/p&gt; 
&lt;p&gt;②方案设计&lt;/p&gt; 
&lt;p&gt;最初设计了两种方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//a9521b265a30d6d8e8de8f9de9f4645d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;第一种基于 Retract 机制删除状态。在 Flink 作业中，同时消费直播间流量数据和关播数据，将两条数据进行聚合。按直播间 ID 分组聚合计算，关播 source 收到数据后向下游聚合算子发送 delete 消息，下游的聚合算子在接受到该消息后删除状态。&lt;/p&gt; 
&lt;p&gt;但该方案存在问题，用户开发成本高，删除状态逻辑与 SQL 逻辑强耦合，导致改造作业时开发成本大；扩展性差，仅适用于 group key 为直播间 ID 的场景，而实际业务中 group key 可能包含更多内容，如用户画像或主播画像等，则不适用。&lt;/p&gt; 
&lt;p&gt;总结问题后，发现其核心是删除状态逻辑与 SQL 逻辑强耦合，进而设计了第二种方案作为 TTL CompactionFilter 方案的扩展，即自定义 RocksDB CompactionFilter 方案。两者执行时机相同，自定义 RocksDB CompactionFilter 方案支持通过 Java UDF 为指定状态设定 CompactionFilter 。两者的区别在于，TTL CompactionFilter 执行时解析状态中的时间戳判断状态是否删除，而自定义方案在 RocksDB 执行时，通过 JNI 将状态数据传给 Flink TM，解析直播间 ID 作为 CompactionFilter 入参，访问直播间 Abase 维表，判断是否关播，若关播，则 CompactionFilter 返回 true，删除状态。此方案实现了直播间关播后的状态删除，且与 SQL 逻辑完全解耦，解决了方案一中的问题。&lt;/p&gt; 
&lt;p&gt;③落地方案&lt;/p&gt; 
&lt;p&gt;与&amp;nbsp;Flink&amp;nbsp;架构组共建，实现了该方案的落地。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4a72afb9ccd8582789e772b28472bfa9.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Flink 架构组在 RocksDB 层面支持 CompactionFilter 能力，在 SQL 层面支持用户为指定聚合算子指定 CompactionFilter。如代码示例所示，设置状态 TTL 为 30 天，通过 ADD RESOURCES 语句引入 CompactionFilter 的 jar 包，通过 SQL hint 指定聚合算子的 CompactionFilter，参数包括 path（路径） 和 filed（直播间 ID）。&lt;/p&gt; 
&lt;p&gt;实现过程中对性能问题进行了优化，如 CompactionFilter 查询性能优化，将实时访问 Abase 优化为批量加载关播直播间数据到本地，判断是否关播，避免 Compaction 执行过程中， CompactionFilter 访问外部组件查询阻塞，减少 CP 的时长；Cache 选择优化，将本地存储关播直播间的 cache 从内存优化到磁盘，降低 GC 时长；CompactionFilter 调用频次优化，设定 state 存储时长超过两天才调用 CompactionFilter，减少未关播直播间频繁调用导致的 CPU 浪费，同时在 RocksDB C++侧缓存，直播间开关播的结果（CompactionFilter 结果），利用 RocksDB 存储机制，将直播间 ID 放在 group by 语句最前面，顺序存储相同 ID 的状态数据，复用 CompactionFilter 调用结果，避免 JNI 调用带来的性能损耗。&lt;/p&gt; 
&lt;p&gt;通过该方案，业务上支持了直播间 30 天累计指标，技术上直播间场次作业状态平均下降 60%，CPU 资源使用下降 70%。&lt;/p&gt; 
&lt;p&gt;（2）大流量回溯优化&lt;/p&gt; 
&lt;p&gt;①场景分析&lt;/p&gt; 
&lt;p&gt;分析无&amp;nbsp;lag&amp;nbsp;场景和追 lag&amp;nbsp;场景下作业期望目标。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//23ffaab6834affe69f04a03720743f1d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;无 lag 场景追求低延迟，数据实时产出，期望数据处理模式为流处理；追 lag 场景追求短时间内快速恢复，数据高吞吐，期望处理模式为批处理。&lt;/p&gt; 
&lt;p&gt;但当前 Flink 流处理作业仅能以流处理运行，设置 Minibatch 为 30 秒，在无 lag 场景可行，而在追 lag 场景则存在吞吐低、恢复慢的问题，与预期高吞吐目标不符。&lt;/p&gt; 
&lt;p&gt;为解决此问题，分析 Flink 流处理和批处理在引擎实现上的差异，在满足 Flink 流处理低延迟特性的同时，实现 Flink 批处理的高吞吐。流处理通过 Minibatch 机制保证低延迟，但其 RocksDB 随机访问和 Retract 机制限制了吞吐；批处理虽有高延迟，但通过 sort 排序处理且无 Retract 机制，吞吐较高。因此，我们提出在流作业中动态监测消费积压情况，判断作业对高吞吐或低延迟的倾向性，在当前算子引入 sort 排序算子和动态调整 Minibatch 大小的能力，实现流批执行模式的动态切换。&lt;/p&gt; 
&lt;p&gt;②方案设计&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//d1272c4b617b4e584d685b0d1961502a.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该方案核心步骤包括积压检测、检测结果传递和动态启用 sorter 算子并调整 Minibatch 大小。Flink 作业运行时，Source 算子动态监测 lag size；当 lag size 超过指定值时，向下游算子发送数据时，标记 isBackLog 为 true，聚合算子接收数据后解析该字段，若为 true，则认为当前作业倾向于批处理，启用 sorter，将 Minibatch 的大小间隔调整为 CP 的间隔。&lt;/p&gt; 
&lt;p&gt;此方案实现了流作业执行过程中流处理和批处理模式的动态切换，且作业的 DAG 不变，状态完全兼容。&lt;/p&gt; 
&lt;p&gt;③落地方案&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//258cc68cab26724db1a0d2f863dcd020.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Flink 流批倾向性指标有三个，即自动检测积压状态时间间隔、触发切换批模式处理的平均 lag size 上限、触发切换流处理平均 lag size 下限。SQL 使用案例如上图左下角所示：首先，在运行参数中设置 backlog mode 开启，然后在 source 算子中指定以上三个参数，进而实现 Flink 作业流批融合的处理。&lt;/p&gt; 
&lt;p&gt;通过该方案，技术上，追 lag 场景回溯数据结果下发量减少，下游组件稳定性提升；业务上，批模式追溯速度比流模式提升一倍。&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;04、未来规划&lt;/h2&gt; 
&lt;p&gt;在抖音一级 RPS 场景下，未来优化分为通用优化和个性化场景优化。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//ccf7f6a093cc54cd46625cbd98349751.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;4.1&amp;nbsp;通用优化&lt;/h3&gt; 
&lt;p&gt;作业重启时内存 localcache 失效导致的缓存穿透优化；使用 Paimon 维表能力减少对 Redis 等 K-V 存储的请求，使用 PaimonWithMQ 能力减少 MQ dump 派作业，节约资源；丰富 AutoScaling 的资源优化规则，获取更多收益。&lt;/p&gt; 
&lt;span id="OSC_h3_12"&gt;&lt;/span&gt; 
&lt;h3&gt;4.2&amp;nbsp;个性化场景优化&lt;/h3&gt; 
&lt;p&gt;解决多任务比值类指标分子分母更新快慢不一致导致的波动明显问题；实现 broadcast join 支持状态的增量加载，针对千亿级维表，拒绝全量加载，而是定时加载仅变化的增量数据，提升作业稳定性；进行内存优化。&lt;/p&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;更多内容&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//6041760444b05a21431ac6efcf7680be.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;活动推荐&lt;/h3&gt; 
&lt;p&gt;阿里云基于 Apache Flink 构建的企业级产品-实时计算 Flink 版现开启活动： 新用户复制点击下方链接或者扫描二维码即可 0 元免费试用 Flink + Paimon &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3Futm_content%3Dg_1000395379%26productCode%3Dsc" rel="nofollow" target="_blank"&gt;实时计算 Flink 版&lt;/a&gt;（3000CU*小时，3 个月内） 了解活动详情：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffree.aliyun.com%2F%3Futm_content%3Dg_1000395379%26productCode%3Dsc" rel="nofollow" target="_blank"&gt;https://free.aliyun.com/?utm_content=g_1000395379&amp;amp;productCode=sc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//9dca849c94b7e32b3cff482a77660ce0.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/2828172/blog/18685623</link>
      <guid isPermaLink="false">https://my.oschina.net/u/2828172/blog/18685623</guid>
      <pubDate>Thu, 24 Jul 2025 02:34:57 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>白宫发布《美国 AI 行动计划》</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;白宫发布了名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.whitehouse.gov%2Farticles%2F2025%2F07%2Fwhite-house-unveils-americas-ai-action-plan%2F" target="_blank"&gt;《赢得 AI 竞赛：美国 AI 行动计划》（Winning the AI Race: America’s AI Action Plan）&lt;/a&gt;的战略文件，以保证美国毫无争议地成为全球 AI 霸主。&lt;/p&gt; 
&lt;p&gt;&lt;img height="595" src="https://static.oschina.net/uploads/space/2025/0724/103055_nOWT_2720166.png" width="521" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/103116_zfCg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;该计划主要有三大支柱，加速 AI 创新、构建 AI 基础设施以及主导国际外交与安全，涵盖 90 多项具体行政命令。其中，废除限制 AI 创新监管条例，加速发电场、水资源、半导体芯片等基础设施建设，这对于像 OpenAI、微软、亚马逊、谷歌、Meta 等 AI 巨头来说非常有利。&lt;/p&gt; 
&lt;p&gt;白宫在 28 页的 AI 行动计划中特别要求，凡联邦政府采购的大语言模型必须「客观、不受自上而下意识形态影响」。此外，该计划还把中国列为主要竞争对手，希望在技术创新、模型开源、基础设施等方面领先。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362050</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362050</guid>
      <pubDate>Thu, 24 Jul 2025 02:32:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蜻蜓 FM 开源 SmartXPlayer 音频播放组件</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;由蜻蜓 FM 研发的音频播放组件「SmartXPlayer」近日已正式开源并上线 OpenHarmony 三方库中心仓。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FtWpwyDSCWemr7NCevxiiYw%3Fpoc_token%3DHHyUgWijpdpTgHnwJ0S3aKNInFpLFta7--q5a3AQ" target="_blank"&gt;介绍&lt;/a&gt;，作为一款专为鸿蒙多端场景打造的音频播放引擎，SmartXPlayer 基于鸿蒙系统分布式能力和多线程架构，提供高性能、易集成的音频播放能力支持，助力开发者高效构建更顺滑、更智能、更便捷的音频播放体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="273" src="https://oscimg.oschina.net/oscnet/up-86f4c94cb3161e141e4caf4a5965a5e4178.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;当前，随着音频内容和智能设备的普及，传统播放器在多端适配、分布式投播、主线程阻塞等方面存在开发难、效率低、体验差等痛点。在这一背景下，SmartXPlayer 应运而生，以组件化、跨线程、高扩展的技术路径，有效提升鸿蒙平台音频应用开发效率与终端播放体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;SmartXPlayer 基于蜻蜓 FM 实际业务场景研发打磨，在多项关键能力上具备优异表现：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;跨线程播放架构，提升系统响应效率&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;SmartXPlayer 首创子线程播放技术，通过引入 ThreadWorker 机制，播放任务在子线程处理，主线程专注 UI 渲染与状态管理，将播放性能提升 50%，有效缓解主线程阻塞带来的卡顿、闪退等问题。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;支持分布式投播与后台播放，适配多端设备&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;SmartXPlayer 内置的 SXCastPlayer 实现了与本地播放器一致的标准播放接口，开发者无需为投播功能单独学习新接口。同时，它能实时监听设备连接状态变化，当检测到投播需求时，播放器会自动将内部的播放逻辑从本地播放器切换为 SXCastPlayer，从而实现「本地播放」到「跨设备投播」的无缝衔接。此外，它还具备后台播放与状态同步能力，实现鸿蒙「全场景互联」下的流畅音频体验。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;高度抽象 API，开发门槛低、接入效率高&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;SmartXPlayer 组件接口设计高度抽象，支持一行代码实现多端投播，仅需少量代码即可快速实现初始化与播放控制，开发效率大幅提升。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据蜻蜓 FM 内部估算，在实际应用中，实现同样的音频播放效果，SmartXPlayer 相比传统方案能够将开发时长由 2 周缩短至 2-3 天，代码量减少 60%，维护成本降低 50%，用户体验显著提升。目前该方案已在蜻蜓 FM 鸿蒙版和蜻蜓电台元服务中集成使用, 整体表现优异，并计划在未来支持更多音频内容形态与播放场景的适配与扩展。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362049</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362049</guid>
      <pubDate>Thu, 24 Jul 2025 02:25:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>GitHub Spark 发布公测预览版，通过自然语言构建全栈应用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;GitHub 宣布其新产品 GitHub Spark 已面向 Copilot Pro+订阅用户开启&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fchangelog%2F2025-07-23-github-spark-in-public-preview-for-copilot-pro-subscribers%2F" target="_blank"&gt;公测&lt;/a&gt;，该产品旨在让开发者通过自然语言在数分钟内完成从想法到部署的全栈智能应用程序的构建和发布，无需进行环境设置或配置。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/101944_bsPs_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Spark 的核心功能由 Claude Sonnet 4 驱动，允许用户通过描述想法来构建包含前端和后端的应用。该平台内置了数据存储、LLM 推理、托管、部署和 GitHub 身份验证等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d9febfe928d296469d6ce6186d282669ebe.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开发者可以在应用中添加由 OpenAI、Meta、DeepSeek、xAI 等公司模型驱动的 AI 功能，而无需管理 API 密钥。应用可以通过一键点击进行部署，并自动创建一个包含 GitHub Actions 和 Dependabot 的 GitHub 仓库，确保所有内容保持同步。&lt;/p&gt; 
&lt;p&gt;开发者可以通过自然语言、可视化编辑控件或在集成 GitHub Copilot 代码补全的编辑器中进行编码来迭代他们的想法。&lt;/p&gt; 
&lt;p&gt;此外，用户可以直接从 Spark 中打开一个 codespace，以使用 Copilot agent 模式进行迭代，或将 issue 分配给 Copilot coding agent。Copilot Pro+订阅用户可直接访问 Spark，其使用会消耗 GitHub Copilot 计划中包含的 premium requests。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362046</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362046</guid>
      <pubDate>Thu, 24 Jul 2025 02:20:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Qwen3 系列模型迎来新第三方部署和价格特惠</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;阿里巴巴的 Qwen3 系列模型近期在多个平台获得部署并在官方平台开启了价格特惠。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0724/100552_pcPY_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Cerebras 宣布推出 Qwen3-235B 模型，实现了每秒 1500 个 token 的推理速度，目前可进行有限制的免费体验。&lt;/p&gt; 
&lt;p&gt;阿里云的通义灵码 IDE 已集成 Qwen3-Coder，并去掉了原有的 DeepSeek 模型。GMI inference cloud 也上线了 Qwen3 Coder 480B A35B Instruct FP8 版本，定价为输入$1.00/M Tokens，输出$2.00/M Tokens。&lt;/p&gt; 
&lt;p&gt;阿里云百炼平台宣布对 Qwen3-Coder-Plus 进行为期一个月的限时降价，并进一步对上下文缓存功能进行说明：「上下文缓存的命中概率并不是 100%，即使是上下文完全一致的请求，也存在无法命中的概率，命中概率依据系统判断而定。」&lt;/p&gt; 
&lt;table style="display:table; text-align:left"&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th style="border-color:rgba(36, 4, 4, 0.4); height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;Token 数量&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:rgba(36, 4, 4, 0.4); height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;输入成本 (每千 Token)&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
   &lt;th style="border-color:rgba(36, 4, 4, 0.4); height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;输出成本 (每千 Token)&lt;/span&gt;&lt;/p&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;0-32K&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.004 元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.016 元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;32K-128K&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.0042 元 (原价 0.006 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;7 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.0168 元 (原价 0.024 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;7 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;128K-256K&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.005 元 (原价 0.01 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;5 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.02 元 (原价 0.04 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;5 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;256K-1M&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.01 元 (原价 0.02 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;5 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td style="border-bottom-color:rgba(36, 4, 4, 0.4); border-bottom-left-radius:0px; border-bottom-right-radius:0px; border-bottom-style:solid; border-bottom-width:1px; border-left-color:rgba(36, 4, 4, 0.4); border-left-style:solid; border-left-width:1px; border-right-color:rgba(36, 4, 4, 0.4); border-right-style:solid; border-right-width:1px; border-top-color:rgba(36, 4, 4, 0.4); border-top-left-radius:0px; border-top-right-radius:0px; border-top-style:solid; border-top-width:1px; height:auto; text-align:left"&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;0.1 元 (原价 0.2 元的&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong style="color:#1f0c03"&gt;&lt;span&gt;&lt;span&gt;5 折&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;详情：https://help.aliyun.com/zh/model-studio/qwen3-coder-plus-price-drop&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362044</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362044</guid>
      <pubDate>Thu, 24 Jul 2025 02:06:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌母公司发布 Q2 财报：全年资本支出飙升至 850 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;谷歌母公司 Alphabet 周三公布季度营收超出华尔街预期，得益于新推出的 AI 功能以及稳定的数字广告市场。公司还表示，将今年的资本支出计划从原本的大约 750 亿美元上调至约 850 亿美元。Alphabet A 股美股盘后下跌 2.8%，但随后回弹，一度跳涨 3.4%。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;以下是 Alphabet 二季度财报要点：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;主要财务数据：&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;营收：&lt;/strong&gt;Alphabet 二季度营收 964.3 亿美元，同比增长 14%，高于分析师预期的 939.7 亿美元。&lt;/p&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;调整后营收：&lt;/strong&gt;剔除合作伙伴分成后的第二季度销售额为 817 亿美元，高于分析师平均预期 796 亿美元。&lt;/p&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;每股收益：&lt;/strong&gt;Alphabet 二季度每股收益 2.31 美元，同比增长 22%，高于分析师预期的 2.18 美元。&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;img height="425" src="https://oscimg.oschina.net/oscnet/up-184de4a234b4e0f59adc392a84a16afd3ea.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;分业务数据：&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;谷歌云营收：&lt;/strong&gt;谷歌云营收第二季度为 136 亿美元，同比增长 32%，高于市场预期的 131 亿美元。&lt;/p&gt; 
  &lt;ul style="margin-left:0; margin-right:0"&gt; 
   &lt;li&gt;&lt;strong&gt;云计算利润：&lt;/strong&gt;谷歌云计算部门本季度运营利润为 28.3 亿美元，远超分析师预期的 22.5 亿美元。&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;广告总营收：&lt;/strong&gt;Alphabet 广告总营收 713 亿美元，同比增长 10.4%。&lt;/p&gt; 
  &lt;ul style="margin-left:0; margin-right:0"&gt; 
   &lt;li&gt;&lt;strong&gt;搜索业务营收：&lt;/strong&gt;搜索业务营收第二季度为 541 亿美元，同比增长 11.7%，高于分析师预期的 540 亿美元。&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;YouTube 广告收入：&lt;/strong&gt;YouTube 广告营收为 98 亿美元，略高于预期的 95 亿美元。&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;Alphabet 股价自 4 月份发布上一份财报以来已上涨超过 18%。周三公布财报后，Alphabet A 股盘后交易中一度下跌超过 2.8%，但随后一度反弹 3.4%，涨幅后收窄至 2% 左右。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;今年资本支出提高至 850 亿美元，预计 2026 年继续增加&lt;/strong&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;谷歌母公司表示，其全年资本支出将提高 13%，达到 850 亿美元，而不是今年早些时候预测的 750 亿美元。相比之下，2024 年为 525 亿美元。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;媒体分析，尽管 Alphabet 公司公布的营收好于预期并创下历史纪录，但由于 2025 年的资本支出将高于此前预测，这让公司在 AI 竞赛中的投资合理性面临更大压力。公司首席财务官 Anat Ashkenazi 在周三财报电话会上表示，公司预计 2026 年还将进一步增加资本支出。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;谷歌首席执行官桑达尔·皮查伊（Sundar Pichai）和其他科技高管过去几年在 AI 开发上投入了数百亿美元，这是整个 AI 热潮的一部分。大部分资金都用于建设新的数据中心，以开发和运行 AI 模型。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;皮查伊表示：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;「人工智能正在积极影响公司业务的每一个部分，推动整体强劲发展。我们正站在 AI 前沿，并以惊人的速度推进产品发布。AI 正在对业务的每一个环节产生积极影响，带来强劲的增长势头。」&lt;/p&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;「搜索业务实现了两位数的收入增长，我们的新功能，比如 AI 概览（AI Overviews）和 AI 模式（AI Mode），表现良好。YouTube 和订阅服务继续保持强劲表现。云计算业务在收入、订单积压和盈利能力方面都取得强劲增长，其年化收入目前已超过 500 亿美元。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;巨额资本支出或将用于人才争夺战&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;今年以来，美国科技巨头已经承诺为建设 AI 能力投资 3200 亿美元。面对竞争对手的压力，以及投资者对 AI 回报慢于预期的失望，科技巨头为其大规模 AI 支出进行了辩护，表示这些投资是推动业务增长和提升产品质量的必要条件。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;在财报电话会上，在被问及是否在 AI 人才方面大手笔支出时，Ashkenazi 表示，Alphabet 会「确保我们为拥有业内最优秀和最聪明的人才进行适当投资」。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;本月早些时候，谷歌在 AI 人才争夺战中引发关注，宣布将以 24 亿美元收购 AI 编程初创公司 Windsurf，该交易还包括技术授权，Windsurf 首席执行官 Varun Mohan 及其顶级研究团队将加入谷歌。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;与此同时，竞争对手 Meta 正在疯狂进行挖角计划。Meta 此前宣布设立「超级智能实验室」部门并展开激进的人才招聘，给这场 AI 竞赛加码。据悉，Meta 为吸引顶尖 AI 研究人员，开出了超过 1 亿美元的薪资待遇。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;搜索业务得到 AI 加持，继续强劲增长&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;谷歌此次公布的财报是科技巨头们本轮财报季的第一份，微软、苹果、亚马逊和 Meta 将于下周陆续发布。媒体称，投资者目前高度关注这些大型科技公司不断膨胀的支出规模，因为它们正在竞相抢占 AI 赛道的领先地位。&lt;strong&gt;随着越来越多用户转向 ChatGPT 来获取网络信息，投资者一直在密切关注 Alphabet 是否出现疲软迹象。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;同时，谷歌的情况具有一定特殊性，其云计算部门依靠数据中心向客户出售算力，是这波 AI 热潮的直接受益者；而公司其他业务则在加速将 AI 工具整合进搜索、YouTube 等热门产品中。虽然谷歌仍位居云计算市场第三，仅次于微软和亚马逊，但其在 AI 方面的优势已帮助其赢得了众多客户。该部门被广泛认为是 Alphabet 当前增长最强劲的动力来源，因为其核心搜索业务已日趋成熟。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;&lt;strong&gt;第二季度，谷歌云业务营收为 136 亿美元，同比增长 32%，而第一季度增幅为 28%。Alphabet 本季度广告总收入为 713 亿美元，同比增长 10.4%。其中，Alphabet 在其核心搜索业务中实现了强劲增长，同比上涨超过 11%。&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;为了给 AI 投资腾出资源，谷歌多年来持续进行削减成本的努力。今年，公司多次在不同部门提供自愿买断方案以减少员工人数。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;为抢占 AI 赛道，谷歌不断提升其 AI 模型与聊天机器人 Gemini 的能力，并将 AI 功能加入多个核心产品。今年 5 月，谷歌在美国推出了「AI 模式」，对传统搜索引擎进行了重大更新，该模式通过聊天式对话来回答搜索问题，减少了链接数量。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;h2 style="margin-left:0; margin-right:0"&gt;反垄断诉讼仍是未知之数&lt;/h2&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;不过，投资者也对谷歌搜索主导地位面临的反垄断诉讼结果表示担忧。一名负责该案的联邦法官预计将在下个月裁定是否对谷歌施加限制，包括在 AI 竞争方面设定某些边界。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;这一裁决将是长达数月审判的结果，审判重点之一就是新兴 AI 参与者是否会侵蚀谷歌的搜索垄断地位。该案由美国司法部于 2020 年发起，诉求包括强制谷歌出售 Chrome 浏览器、禁止其向苹果支付「默认搜索引擎」费用，并要求谷歌与竞争对手共享部分数据。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;谷歌方面则辩称，政府的要求过于极端，不仅会损害消费者利益，还将削弱美国的技术领先地位。The Futurum Group 首席执行官 Daniel Newman 认为，这种不确定性正在拖累股价。&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;「在人们担心人工智能颠覆之后，反垄断风险接踵而至，这造成了拖累。」他表示：&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;blockquote&gt; 
  &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;「裁决结果可能是深度惩罚性的，只要我们不知道最终结果如何，这种不确定性的阴影就会持续很长一段时间。」&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div style="text-align:start"&gt; 
 &lt;p style="color:#222222; margin-left:0; margin-right:0"&gt;此次外，Ashkenazi 表示，公司总运营支出增长 20%，达到 261 亿美元。增长的最大原因是法律及其他相关费用，其中包括与一项和解相关的 14 亿美元支出。德州总检察长 Ken Paxton 于 5 月宣布，谷歌就 2022 年一项涉及数据隐私权的诉讼达成 13.7 亿美元的和解协议。&lt;/p&gt; 
&lt;/div&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362043</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362043</guid>
      <pubDate>Thu, 24 Jul 2025 02:01:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥造物分享：上海理工大学，匠行团队-安全骑行辅助智能尾灯 v1.0</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2107</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2107</guid>
      <pubDate>Thu, 24 Jul 2025 01:54:57 GMT</pubDate>
    </item>
    <item>
      <title>IBM 第二季度营收 157.7 亿美元，净利润同比增长 16%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;IBM 已发布了该公司的 2024 财年第二季度财报。报告显示，IBM 第二季度总营收为 157.70 亿美元，与上年同期的 154.75 亿美元相比增长 2%，不计入汇率变动的影响为同比增长 4%；净利润为 18.34 亿美元，与上年同期的 15.83 亿美元相比实现增长；来自于持续运营业务的净利润为 18.30 亿美元，上年同期来自于持续运营业务的净利润为 15.81 亿美元，同比增幅达 16%。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度营收和调整后每股收益均超出华尔街分析师预期，对 2024 财年全年营收作出的展望也超出预期，从而推动其盘后股价上涨近 3%。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;第二季度主要业绩：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在截至 2024 年 6 月 30 日的这一财季，IBM 的净利润为 18.34 亿美元，与上年同期的 15.83 亿美元相比实现增长。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度来自于持续运营业务的净利润为 18.30 亿美元，上年同期来自于持续运营业务的净利润为 15.81 亿美元，同比增幅达 16%；来自于持续运营业务的每股摊薄收益为 1.96 美元，与上年同期的 1.72 美元相比增长 14%。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度来自于非持续运营业务的利润为 400 万美元，而上年同期来自于非持续运营业务的利润为 200 万美元。&lt;/p&gt; 
&lt;p&gt;不计入某些一次性项目（不按照美国通用会计准则），IBM 第二季度来自于持续运营业务的运营净利润为 22.75 亿美元，与上年同期的 20.03 亿美元相比增长 14%；来自于持续运营业务的运营每股摊薄收益为 2.43 美元，与上年同期的 2.18 美元相比增长 11%，这一业绩超出分析师此前预期。据雅虎财经频道提供的数据显示，13 名分析师此前平均预期 IBM 第二季度每股收益将达 2.2 美元。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度总营收为 157.70 亿美元，与上年同期的 154.75 亿美元相比增长 2%，不计入汇率变动的影响为同比增长 4%，这一业绩也超出分析师此前预期。据雅虎财经频道提供的数据显示，12 名分析师此前平均预期 IBM 第二季度营收将达 156.2 亿美元。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度来自于持续运营业务的总毛利润为 89.50 亿美元，与上年同期的 85.01 亿美元相比增长 5%；总毛利率为 56.8%，而上年同期为 54.9%，同比上升 1.8 个百分点。不计入某些一次性项目（不按照美国通用会计准则），IIBM 第二季度来自于持续运营业务的总毛利润为 91.20 亿美元，与上年同期的 86.50 亿美元相比增长 5%；总毛利率为 57.8%，而上年同期为 55.9%，同比上升 1.9 个百分点。&lt;/p&gt; 
&lt;p&gt;第二季度成本和支出：&lt;/p&gt; 
&lt;p&gt;IBM 第二季度来自于持续运营业务的总支出及其他收入为 67.30 亿美元，与上年同期的 65.01 亿美元相比有所上升。其中，销售、总务和行政支出为 49.38 亿美元，与上年同期的 49.00 亿美元相比基本持平；研发和工程支出为 18.40 亿美元，与上年同期的 16.87 亿美元相比有所上升；知识产权和海关开发收入为 2.41 亿美元，与上年同期的 2.48 亿美元相比略有下降；其他收入为 2.33 亿美元，与上年同期的其他收入 2.61 亿美元相比有所下降；利息支出为 4.27 亿美元，与上年同期的 4.23 亿美元相比基本持平。&lt;/p&gt; 
&lt;p&gt;第二季度各部门业绩：&lt;/p&gt; 
&lt;p&gt;2024 财年第二季度，IBM 软件业务部门（包括混合平台与解决方案业务以及交易处理业务）的营收为 67.39 亿美元，与上年同期的 62.94 亿美元相比增长 7.1%，不计入汇率变动的影响为同比增长 8.4%。软件业务部门的毛利率为 83.6%，与上年同期的 82.1% 相比有所上升。&lt;/p&gt; 
&lt;p&gt;在软件部门内部：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;混合平台与解决方案业务的营收同比增长 5%，不计入汇率变动的影响为同比增长 6%。在这项业务内部：红帽（Red Hat）部门的营收同比增长 7%，不计入汇率变动的影响为同比增长 8%；自动化部门的营收同比增长 15%，不计入汇率变动的影响为同比增长 16%；数据和人工智能部门的营收同比下降 3%，不计入汇率变动的影响为同比下降 2%；安全部门的营收同比增长 2%，不计入汇率变动的影响为同比增长 3%。&lt;/li&gt; 
 &lt;li&gt;交易处理业务的营收同比增长 11%，不计入汇率变动的影响为同比增长 13%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;IBM 咨询业务部门（包括商业转型、技术咨询和应用业务）第二季度营收为 51.79 亿美元，与上年同期的 52.26 亿美元相比下降 0.9%，不计入汇率变动的影响为同比增长 1.8%。&lt;/p&gt; 
&lt;p&gt;在咨询业务部门内部：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;业务转型营收同比增长 3%，不计入汇率变动的影响为同比增长 6%；&lt;/li&gt; 
 &lt;li&gt;技术咨询营收同比下降 3%，不计入汇率变动的影响为同比增长 1%；&lt;/li&gt; 
 &lt;li&gt;应用运营营收同比下降 4%，不计入汇率变动的影响为同比下降 2%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;IBM 第二季度基础设施业务部门（包括混合基础设施和基础设施支持业务）营收为 36.45 亿美元，与上年同期的 36.18 亿美元相比增长 0.7%，不计入汇率变动的影响为同比增长 2.7%。&lt;/p&gt; 
&lt;p&gt;在基础设施业务部门内部：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;混合基础设施业务营收同比增长 4%，不计入汇率变动的影响为同比增长 6%。在这项业务内部，IBM z 系统营收同比增长 6%，不计入汇率变动的影响为同比增长 8%；分布式基础设施营收同比增长 3%，不计入汇率变动的影响为同比增长 5%。&lt;/li&gt; 
 &lt;li&gt;基础设施支持业务营收同比下降 5%，不计入汇率变动的影响为同比下降 3%。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;IBM 第二季度融资部门（包括客户和商业融资业务）营收为 1.69 亿美元，与上年同期的 1.85 亿美元相比下降 8.3%，不计入汇率变动的影响为同比下降 6.6%。&lt;/p&gt; 
&lt;p&gt;IBM 第二季度其他业务部门的营收为 3800 万美元，而上年同期其他业务部门的营收为 1.52 亿美元，同比大幅下降。&lt;/p&gt; 
&lt;p&gt;第二季度其他财务信息：&lt;/p&gt; 
&lt;p&gt;IBM 第二季度来自于运营活动的净现金为 21 亿美元，与上年同期相比减少了 6 亿美元。IBM 第二季度自由现金流为 26 亿美元，与上年同期相比增加了 5 亿美元。在第二季度里，IBM 通过派发股息的形式向股东返还了 15 亿美元现金。&lt;/p&gt; 
&lt;p&gt;截至 2024 年第二季度末，IBM 持有 160 亿美元现金、限制性现金和有价证券，与截至 2023 年底相比增加了 25 亿美元；债务总额（其中包括全球融资部门的 111 亿美元债务）为 565 亿美元，自 2023 年底以来并无增减。&lt;/p&gt; 
&lt;p&gt;上半年主要业绩：&lt;/p&gt; 
&lt;p&gt;IBM 上半年总营收为 302.31 亿美元，与上年同期的 297.27 亿美元相比实现增长。IBM 上半年来自于持续运营业务的净利润为 34.05 亿美元，与上年同期的 25.15 亿美元相比有所增长；来自于持续运营业务的每股摊薄收益为 3.68 美元，高于上年同期的 2.73 美元。&lt;/p&gt; 
&lt;p&gt;不计入某些一次性项目（不按照美国通用会计准则），IBM 上半年来自于持续运营业务的净利润为 38.39 亿美元，与上年同期的 32.52 亿美元相比实现增长。不计入某些一次性项目（不按照美国通用会计准则），IBM 上半年来自于持续运营业务的每股摊薄收益为 4.11 美元，与上年同期的为 3.54 美元相比实现增长。&lt;/p&gt; 
&lt;p&gt;IBM 上半年来自于运营活动的净现金为 62 亿美元，与上年同期相比减少了 2 亿美元。IBM 上半年的自由现金流为 45 亿美元，与上年同期相比增加了 11 亿美元。在过去 12 个月时间里，IBM 来自于运营活动的净现金为 138 亿美元，自由现金流为 123 亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2024 年全年业绩展望：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;IBM 继续预计，该公司 2024 财年营收的同比增长率（不计入汇率变动的影响）将可达到 3% 至 5%。IBM 表示，按照当前的汇率，预计汇率变动将对该公司的营收增长造成 1 到 2 个百分点的负面影响。&lt;/p&gt; 
&lt;p&gt;据 IBM 此前公布的财报显示，2023 财年该公司的总营收为 618.60 亿美元。按 3% 到 5% 的同比增长率计算，这意味着该公司预计其 2024 财年总营收将达 637 亿美元到 650 亿美元之间，超出分析师预期。据雅虎财经频道提供的数据显示，19 名分析师目前平均预期该公司 2024 财年的总营收将达 630.3 亿美元。&lt;/p&gt; 
&lt;p&gt;IBM 目前预计，2024 财年该公司的自由现金流将达 120 亿美元以上。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/362039</link>
      <guid isPermaLink="false">https://www.oschina.net/news/362039</guid>
      <pubDate>Thu, 24 Jul 2025 01:53:57 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>《开源鸿蒙共建地图 4.0》在 2025 开放原子开源生态大会上重磅发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361986</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361986</guid>
      <pubDate>Wed, 16 Jul 2025 11:45:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Anthropic 为 Claude 开发「学习」功能，争夺 AI 教育市场</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Anthropic 正在为 Claude&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.testingcatalog.com%2Fanthropic-develops-interactive-study-projects-to-turn-claude-into-a-tutor%2F" target="_blank"&gt;开发「&lt;/a&gt;学习项目」 (Study Projects) 功能，旨在将其从问答工具转变为能提供结构化学习流程的 AI 导师，以争夺教育市场。&lt;/p&gt; 
&lt;p&gt;该功能主要面向学生用户，旨在帮助学生构建结构化的学习流程，而不仅仅是提供直接答案。用户创建「学习项目」后，可以随时调整其中的指令，使其成为一个持续的学习工作空间。&lt;/p&gt; 
&lt;p&gt;Claude 将通过该功能帮助用户将概念可视化、生成详细的学习指南，并提供能根据用户目标和学习材料进行自适应调整的辅导。&lt;/p&gt; 
&lt;p&gt;&lt;img height="558" src="https://static.oschina.net/uploads/space/2025/0723/193813_YuHt_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此举被视为 Anthropic 将 Claude 从一个被动的问答工具转变为主动的教育助手的尝试。这一动向与 OpenAI 的 Study Together 和 Google 的 Guided Learning 等项目相呼应，显示出头部 AI 公司正在激烈争夺教育市场。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361983</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361983</guid>
      <pubDate>Wed, 16 Jul 2025 11:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌 Gemini 增加 Imagen 选项并开放 llms.txt</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;谷歌为其 AI 服务 Gemini 进行了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fm4rkmc%2Fstatus%2F1946101080464785756"&gt;一系列更新&lt;/a&gt;，用户可直接选择 Imagen 模型生成图像，并启用了 llms.txt 文件，方便 AI Agent 获取最新的 API 和 SDK 使用方法。&lt;/p&gt; 
&lt;p&gt;具体来说，用户现在可以在 Gemini 界面中直接看到并选择 Imagen 模型进行图像生成。此外，Google 在 Gemini&amp;nbsp;API 文档网站&amp;nbsp;ai.google.dev&amp;nbsp;上启用了&amp;nbsp;llms.txt&amp;nbsp;文件。这是一个为 AI 模型和代码 Agent 设计的机器可读文档，遵循 MCP（Model-Consumable Patois）规范。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0723/191929_xMah_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;开发者可以让其 AI Agent 通过访问&amp;nbsp;ai.google.dev/gemini-api/docs/llms.txt&amp;nbsp;来获取最新的 API 和 SDK 最佳实践，从而更高效地构建应用。该功能也可以通过 Gemini CLI 的扩展来使用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361980</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361980</guid>
      <pubDate>Wed, 16 Jul 2025 11:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>谷歌发布「OSS Rebuild」应对开源软件供应链安全问题</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;为应对开源软件供应链安全问题，谷歌&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsecurity.googleblog.com%2F2025%2F07%2Fintroducing-oss-rebuild-open-source.html"&gt;宣布&lt;/a&gt;推出&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Foss-rebuild"&gt;OSS Rebuild&lt;/a&gt;&amp;nbsp;开源工具，&lt;strong&gt;帮助开发者通过重现构建过程验证开源软件包的完整性&lt;/strong&gt;，防范恶意篡改风险。&lt;/p&gt; 
&lt;p&gt;公告写道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源软件已成为我们数字世界的基础。从关键基础设施到日常应用，OSS 组件现在占现代应用的 77%。据估计，其价值超过 12 万亿美元，开源软件从未如此成为全球经济的重要组成部分。&lt;/p&gt; 
 &lt;p&gt;OSS Rebuild 是一个通过重现上游软件构建过程来增强对开源软件包生态系统信任的新项目。随着供应链攻击继续针对广泛使用的依赖项，OSS Rebuild 为安全团队提供了强大的数据，以避免妥协，同时不对上游维护者造成负担。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;OSS Rebuild 可自动生成符合 SLSA Build Level 3 标准的可验证记录，无需维护者额外投入。该工具能帮助安全团队检测未经验证的代码、被入侵的构建环境及潜在后门，同时增强元数据并优化漏洞响应效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0723/191029_Pte1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;目前，OSS Rebuild 支持 PyPI、npm 和 Crates.io 生态，未来将扩展至更多平台。开发者可通过命令行获取构建来源信息并验证软件包。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361977/google-oss-rebuild-open-source</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361977/google-oss-rebuild-open-source</guid>
      <pubDate>Wed, 16 Jul 2025 11:11:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>欧盟考虑设立巨额基金来解决开源软件的「静默危机」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源软件 (OSS) 的使用范围极其广泛。Google 最近表示，OSS 占软件总量的 77%，市值超过 12 万亿美元。尽管如此，OSS 的维护资金严重不足，许多项目依赖于无薪或报酬过低的独立维护人员，导致维护人员倦怠和安全风险。&lt;/p&gt; 
&lt;p&gt;为此 Google 发布了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Foss-rebuild" target="_blank"&gt; OSS Rebuild 项目&lt;/a&gt;，试图解决这一问题，但 GitHub 希望获得欧盟主权科技基金 (EU-STF) 的更多资助。&lt;/p&gt; 
&lt;p&gt;该基金不会用于所有的开源项目；它将用于缺乏专项资金的广泛使用的组件，以便它们能够获得持续的维护和安全。&lt;/p&gt; 
&lt;p&gt;作为 GitHub 提案的一部分，其开发者政策团队委托了一项研究，以调查欧洲主权科技基金 (EU-STF)。这家微软旗下的公司表示，欧盟可以效仿德国主权科技机构，该机构在成立后的头两年内已成功向 60 个开源软件项目投资了超过 2300 万欧元。&lt;/p&gt; 
&lt;p&gt;GitHub 设想，欧盟标准与技术信托基金 (EU-STF) 将专注于识别关键依赖关系，并进行投资以确保持续维护、安全、改进以及强化更广泛的开源软件生态系统。如果您想知道这一切需要多少成本，GitHub 提议从欧盟即将到来的多年期预算（2028-2035 年）中至少拨出 3.5 亿欧元。GitHub &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.neowin.net%2Fnews%2Feurope-considers-a-massive-fund-to-fix-open-source-softwares-silent-crisis%2F" target="_blank"&gt;表示&lt;/a&gt;&lt;/u&gt;：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「这不足以满足开源维护需求，但它可以成为利用行业和国家政府共同融资的基础，从而产生持久的影响。」&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;GitHub 研究概述了 EU-STF 的以下七个关键设计标准：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;集中融资：工业界、各国政府和欧盟应向单一基金提供资金。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;官僚主义程度低：申请流程简单，维护人员的报告最少。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;政治独立性：避免根据政治趋势改变优先事项，专注于基础技术。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;灵活的资金：支持个人、非营利组织和公司，无论其是否居住在欧盟，只要其工作有利于欧盟。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;社区重点：与开源社区合作确定优先事项。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;战略一致性：对欧盟战略目标（经济、数字主权、网络安全）产生积极影响。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;透明度：治理和资金决策的高标准。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;GitHub 和微软提出的这项提案恰逢其时，恰逢欧盟 2028-2035 年新预算的谈判。该公司还与欧盟立法者和行业合作伙伴合作，倡导该基金，确保他们了解不提供资金的益处和风险。该公司还呼吁个人、开源软件组织和公司表达对欧盟机构的支持。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361975</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361975</guid>
      <pubDate>Wed, 16 Jul 2025 11:02:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>周鸿祎：大模型降低攻击门槛，人人皆可「注入攻击」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在 2025 中国互联网大会上，当被问及大模型在落地应用过程中可能存在的风险时，&lt;strong&gt;360 集团创始人周鸿祎&lt;/strong&gt;深入剖析了人工智能时代下网络安全面临的全新挑战。他指出，相较于传统的 IT 系统漏洞和数据隐私泄露问题，大模型带来的三大安全风险更应引起高度警惕。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心风险一：大模型的「幻觉」与胡言乱语&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;周鸿祎强调，&lt;strong&gt;大模型固有的「幻觉」问题&lt;/strong&gt;是其最大的风险之一。他解释说，当大模型遇到不理解的事物时，会一本正经地编造信息。虽然这在娱乐场景中尚可一笑置之，但当大模型及其衍生的智能体开始深入工业生产、制造以及政府办公等关键领域时，这种「出错」将可能导致严重后果。他特别指出，一旦智能体具备了操纵各种工具的能力，其错误判断的危害和影响将成倍放大。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心风险二：大模型降低攻击门槛，人人皆可「注入攻击」&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;周鸿祎提出的第二个风险是，大模型极大地&lt;strong&gt;降低了网络攻击的门槛&lt;/strong&gt;。他指出，大模型使得非编程专业人员也能通过简单的自然语言交互来编写程序，这同时也意味着攻击大模型的门槛也随之降低。通过精心构造的指令，攻击者可以诱导大模型泄露企业机密文件，这种现象被称为「注入攻击」。周鸿祎形象地表示，未来甚至一个不具备编程知识的前台员工，都可能因为不满而对公司的大模型和智能体发动攻击。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;核心风险三：国家级高级威胁攻击的智能化升级&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;从更宏观的未来视角来看，周鸿祎指出，大模型将使&lt;strong&gt;国家级高级威胁攻击&lt;/strong&gt;变得更加普遍和复杂。过去，针对我国的网络黑客数量相对较少，但现在，黑客正尝试将自身的能力和经验嵌入大模型，把自己打造成「黑客智能体」。在拥有足够算力支持的情况下，一个黑客可以同时操纵数十甚至数百个智能体，这将彻底颠覆传统的网络攻防格局，使网络安全从「人与人」的对抗，转变为「人与算法、人与机器、人与算力」的对抗，因为机器人数字黑客只需要算力，不需要休息。&lt;/span&gt;&lt;/p&gt; 
&lt;h4 style="margin-left:0px; margin-right:0px; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;strong&gt;360 的应对策略：「以算法对抗算法」&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;面对这些严峻挑战，周鸿祎表示，360 已着手采取两项关键措施来应对。首先，360 正在积极&lt;strong&gt;打造智能体安全专家&lt;/strong&gt;。这些专家能够帮助企业在面对攻击时，实现实时检测和实时防御，从而真正做到「以算法对抗算法」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;其次，针对大模型的安全性和易受攻击性，360 开发了专门的「大模型衞士」。这是一款专业的大模型和智能体，其主要功能是监控发送给大模型的指令，并评估大模型输出内容的合理性和准确性。此外，结合强大的搜索能力和企业知识库，该衞士还能最大限度地降低大模型的「幻觉」问题。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361972</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361972</guid>
      <pubDate>Wed, 16 Jul 2025 10:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 神秘新模型 o3-alpha 现身 Web Arena 平台</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 正在测试名为「o3-alpha-responses-2025-07-17」（公开代号为「anonymous-chatbot-0717」）的新模型，该模型于 2025 年 7 月 17 日在 WebDev Arena（一个前端开发测试竞技场）短暂测试后下架 。&lt;/p&gt; 
&lt;p&gt;&lt;img height="317" src="https://static.oschina.net/uploads/space/2025/0723/182113_kPXe_2720166.png" width="640" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;测试显示，o3-alpha 在网页设计、前端代码生成（如使用 Three.js 创建程序化星球、生成 Doodle Jump 等网页游戏）以及复杂游戏（如 Minecraft 和 GTA 克隆版）开发方面表现突出，远胜于 OpenAI 的 o3、GPT-4.1-2025-04-14，以及 Claude Sonnet、Gemini 2.5 Pro 和 Grok 4 等竞品。&lt;/p&gt; 
&lt;p&gt;&lt;img height="485" src="https://static.oschina.net/uploads/space/2025/0723/182350_3blA_2720166.png" width="1000" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/182502_hLOf_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，有猜测称该模型可能与近期在东京 AtCoder 启发式编程世界杯总决赛中获得亚军的模型有关，但 OpenAI 未官方确认。&lt;/p&gt; 
&lt;p&gt;目前，该模型既非 OpenAI 计划开源的模型，也非传闻中的 o4（官方称 o4 不存在），可能是 o3 的重大升级版或 GPT-5 的前期技术验证，但无官方背书。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361971</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361971</guid>
      <pubDate>Wed, 16 Jul 2025 10:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>船舶制造迈入「超级周期」，邦彦云 PC 以信创之力为行业提供全场景算力基座</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
    ********************************************************************************************************************
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361961</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361961</guid>
      <pubDate>Wed, 16 Jul 2025 09:52:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
    <item>
      <title>模力方舟万模破浪，开源中国获授北京国际开源社区「2025 年首批开源先锋企业」称号</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;7 月 23 日至 24 日，&lt;strong&gt;2025 开放原子开源生态大会&lt;/strong&gt;在北京国家会议中心二期盛大召开。本届大会以「开源赋能产业，生态共筑未来」为主题，汇聚政、产、学、研、用、金、创、投等各领域开源力量，聚焦开源政策导向、生态发展趋势，及开源产业实践。&lt;/p&gt; 
&lt;p&gt;在首日的开幕式上，由工业和信息化部、北京市人民政府共同指导，北京市经济和信息化局与经济技术开发区积极推动建设，开放原子开源基金会为基础的&lt;strong&gt;北京国际开源社区&lt;/strong&gt;为大家重点分享了近年来在开源生态建设上的成果，并对在推动开源技术创新和产业深度融合方面做出杰出贡献的入驻社区企业，授予首批「开源先锋企业」称号。&lt;/p&gt; 
&lt;p&gt;&lt;img height="720" src="https://static.oschina.net/uploads/space/2025/0723/173716_tnIJ_2720166.png" width="1083" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为国内开源领域的重要参与者与推动者，&lt;span style="color:#2980b9"&gt;&lt;strong&gt;开源中国获授北京国际开源社区「 2025 年首批开源先锋企业」称号&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt; 
&lt;p&gt;一直以来，开源中国致力于为开发者搭建高效的开源协作平台，汇聚全球优质开源资源，助力国内企业在开源技术创新上不断突破。未来，开源中国还将与社会各界加强联动，一方面通过自身平台优势挖掘并推广优秀开源项目，并结合自身模力方舟与 Gitee 平台的发展，加速 AI 应用创新，赋能企业研发效能增长；另一方面联合各方共同完善开源人才培养体系，提升国内开源与 AI 生态的整体活力，为中国开源与 AI 产业的高质量发展注入新动能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0723/173753_O1BX_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;而在随后的圆桌论坛环节，&lt;strong&gt;开源中国董事长马越&lt;/strong&gt;结合开源中国多年深耕行业的实践经验，就目前中国开源人工智能生态建设展开了深刻分享。&lt;/p&gt; 
&lt;p&gt;在探讨如何构建既保持开放共享精神，又具备长期可持续发展的开源人工智能生态系统时，马越表示，&lt;strong&gt;开源在过去几十年已发展成一种公平且良性的模式&lt;/strong&gt;，但当下存在一个现象，即人们过多强调开源的 「公益属性」，却忽视了其残酷的 「商业竞争」。开源的竞争是残酷的，并非将代码放在 Gitee、GitHub 上就会受到关注，只有像麒麟、鸿蒙这样足够优秀的开源项目，才能引发广泛关注。而人工智能时代亦是如此，例如 DeepSeek 的迅速出圈，正是因其足够出色，才出现美国一边抵制、一边吹捧的情况。&lt;/p&gt; 
&lt;p&gt;有没有什么心态能保障开源的可持续发展呢？马越表示，开源必然是国际化的，但贸易战也客观存在，在当前美国资本退潮的背景下，「实干」 才是根本。过去 12 年里，开源中国凭借其工程能力与不懈努力，在 Gitee 平台上已汇聚了超过 1350 万开发者、36 万企业、2000 所高校，深度赋能国内研发效能提升与开源创新。而在如今的人工智能时代，开源中国推出的模力方舟平台，同样延续着这份「实干」基因，提供模型体验、推理、微调和应用的一站式服务，帮助企业和开发者更容易地开发 AI 应用。&lt;/p&gt; 
&lt;p&gt;马越提到：「&lt;strong&gt;开发者对 HuggingFace 的依赖，某种程度上是对其背后云计算资源的依赖。&lt;/strong&gt;」但中国不可能在人工智能时代依赖于英伟达，必须走独立自主可控的道路。所以，模力方舟自上线起，就陆续支持天数智芯、沐曦、升腾、燧原、壁仞等国产算力，并适配相关模型，其背后的工程量是极为庞大的。&lt;/p&gt; 
&lt;p&gt;而对于 HuggingFace 的商业模式，马越做出了自己的判断：HuggingFace 的商业模式在中国无法复现。一方面，HuggingFace 是 ToB 的 SaaS 模式，在过去 20 年里，已无数次见证了这一模式的薄弱性；另一方面，HuggingFace 的很多付费用户一年不寻求业务服务却依旧会续费的付费文化，在中国同样难以实现。但马越坚定认为，只要是开发者需要，开源中国就会咬牙闯出一条路来。&lt;/p&gt; 
&lt;p&gt;最后，马越对人工智能时代的未来发展送上寄语：「技术会不断迭代、创新，但开源精神永远不变。在人工智能这个波澜壮阔的大时代来临之际，希望开源的力量能加持每个人。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361959</guid>
      <pubDate>Wed, 16 Jul 2025 09:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>月之暗面更新 Kimi K2 模型聊天模板，优化工具调用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;月之暗面（Moonshot AI）&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmoonshotai%2FKimi-K2-Instruct%2Fdiscussions%2F28" target="_blank"&gt;更新了&lt;/a&gt;Kimi K2 模型的聊天模板，通过修改系统提示和参数处理方式，提升了工具调用的稳定性和可靠性。&lt;/p&gt; 
&lt;p&gt;具体变更包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;更新了默认的系统提示；&lt;/li&gt; 
 &lt;li&gt;在多轮工具调用中，强制使用模型返回的 tool_id 以提高可靠性；&lt;/li&gt; 
 &lt;li&gt;当工具调用的 arguments 参数本身已是字符串时，不再对其应用 tojson 函数。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;官方同时指出一个已知问题：当 tool_choice 不等于 auto 时，vLLM 的 tool_id 格式存在错误，修复该问题的 PR 将很快提交。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361958</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361958</guid>
      <pubDate>Wed, 16 Jul 2025 09:35:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>苹果 AI 团队内部风波：自主研发与开源梦碎，或将求助第三方大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;最近，关于苹果公司人工智能（AI）团队内部的动荡事件引发了外界的广泛关注。根据最新报道，苹果的 AI 基础模型团队曾计划将多个自研模型开源，以展示其在 AI 领域的技术进展。然而，这一提案却遭到了苹果高级副总裁克雷格・费德里吉的否决。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;报道称，费德里吉在一封内部邮件中明确表示，目前市场上已经有许多优秀的开源模型足以支撑学术研究，因此苹果没有必要参与其中。他特别担心的是，若自家模型开源，外界将会注意到这些模型在针对 iPhone 适配后，性能相较于在高性能 PC 或数据中心运行的版本有显著下降。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这一决策引发了苹果内部的强烈不满，很多团队成员认为，苹果坚持的 「设备优先」 策略正在限制其 AI 技术的发展潜力。值得一提的是，费德里吉本人也曾对已离职的团队负责人庞若明表达过相似的看法。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;苹果去年推出的 「Apple Intelligence」 项目，一直以来都强调用户隐私保护，设备端处理被视为实现这一承诺的关键。然而，显然这一策略也给苹果的 AI 功能带来了不小的技术限制。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="326" src="https://static.oschina.net/uploads/space/2025/0723/172828_x24n_4252687.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;更令人关注的是，近日苹果宣布将推迟 Siri 的重大更新，许多 AI 团队成员对此感到措手不及。与此相关的是，苹果公司正在考虑放弃完全自主研发的路径，转而寻求与第三方大语言模型（LLM）合作。消息称，苹果已与 OpenAI、Anthropic 及谷歌接洽，探讨如何利用这些大模型来提升 Siri 的技术支持。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361955</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361955</guid>
      <pubDate>Wed, 16 Jul 2025 09:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程工具 Replit 「擅自」删除生产数据库，并谎称无法恢复</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;最近，估值飙升的 AI 编程独角兽 Replit 发生了一则重大事故。SaaStr.AI 创始人兼首席执行官 Jason&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fjasonlk%2Fstatus%2F1946239068691665187" target="_blank"&gt;发帖称&lt;/a&gt;，他在连续 8 天使用 AI 编程工具 Replit 构建应用后，&lt;strong&gt;Replit 在他明确指示不要未经许可更改任何代码的前提下，仍然删除了他的数据库&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1154" src="https://static.oschina.net/uploads/space/2025/0723/171059_4K3n_2720166.png" width="1300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;此外，Replit 还「撒谎」表示，此次数据删除事故中无法实现恢复操作。但当 Jason 自行尝试回滚时，操作却意外成功，数据得到了恢复。Replit 的首席执行官 AmjadMasad&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Famasad%2Fstatus%2F1946986468586721478" target="_blank"&gt;紧急回应&lt;/a&gt;，承认事件「完全不可接受且绝不应发生」，并宣布三大补救措施，包括紧急部署数据库开发与生产环境的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.replit.com%2Fintroducing-a-safer-way-to-vibe-code-with-replit-databases" target="_blank"&gt;自动隔离机制&lt;/a&gt;，并加速推进测试环境建设。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1480" src="https://static.oschina.net/uploads/space/2025/0723/171342_AI7U_2720166.png" width="1318" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bb9b1f7ef18f49391c7aec21b5d29d2d3e9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管承诺「一键恢复项目状态」并给予 Jason 赔偿，但评论区却涌现更多受害者。多名用户称遭遇类似删库事故，有人被迫回归本地编码。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/361953</link>
      <guid isPermaLink="false">https://www.oschina.net/news/361953</guid>
      <pubDate>Wed, 16 Jul 2025 09:16:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
  </channel>
</rss>
