<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Thu, 02 Jan 2025 07:36:03 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>开源日报 | Qwen-VL 大模型全面降价；华为轮值董事长孟晚舟新年致辞；「技术债务就像是幸存者的战斗伤痕」；国产 AI 舞台站满了「90 后天才」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎阅读 OSCHINA 编辑部出品的开源日报，每天更新一期。&lt;/p&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#ff9900&quot;&gt;&lt;strong&gt;# 2024.12.31&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日要闻&lt;/span&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301378&quot; target=&quot;_blank&quot;&gt;IBM 计划收购 HashiCorp，遭英国反垄断监管机构审查&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;据 TechCrunch 报道，英国反垄断监督机构竞争与市场管理局（CMA）已开始调查 IBM 计划收购云软件厂商 HashiCorp 是否会影响竞争。&lt;/p&gt; 
  &lt;p&gt;CMA 周一表示，它将在 1 月 16 日前邀请有关各方就这一并购发表评论。该监管机构暂定 2 月 25 日为最后期限，以决定是批准该交易还是将其提交进一步审查。&lt;/p&gt; 
  &lt;p&gt;IBM 于今年 4 月宣布同意以约 64 亿美元的价格收购 HashiCorp。如果收购继续进行，将扩大 IBM 在云计算和人工智能领域的推进力度，并让该公司获得 HashiCorp 约 4400 家客户的名册。&lt;/p&gt; 
  &lt;p&gt;CMA 于 8 月通知 HashiCorp 将对合并进行审查。美国联邦贸易委员会也在调查这一交易。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301401&quot; target=&quot;_blank&quot;&gt;阿里云再度降价：Qwen-VL 大模型全面降价&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;阿里云今天宣布，Qwen-VL 大模型全面降价。这是阿里云本年度的第三轮降价。&lt;/p&gt; 
  &lt;p&gt;Qwen-VL-Plus 模型价格直降 81%，输入价格仅为 0.0015 元/千 tokens，创下全网最低价格；而更高性能的 Qwen-VL-Max 降价至 0.003 元/千 tokens，降幅达到 85%。根据新的定价，1 元钱可以最多处理大约 600 张 720P 图片，或者 1700 张 480P 图片。&lt;/p&gt; 
  &lt;p&gt;Qwen-VL 系列大模型是阿里云推出的多模态大模型，已成为开源社区最受欢迎的模型之一，具备强大的视觉推理能力。该模型不仅能够识别不同分辨率和长宽比的图片，还能理解 20 分钟以上的长视频，并具备自主操作手机和机器人等智能体的视觉理解能力。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#245bdb&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327292&quot;&gt;智谱深度推理模型 GLM-Zero 预览版上线&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;智谱宣布发布本年度最后一个模型 GLM-Zero 的初代版本 GLM-Zero-Preview，这是智谱首个基于扩展强化学习技术训练的推理模型。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;根据介绍，GLM-Zero-Preview 是 GLM 家族中专注于增强 AI 推理能力的模型，擅长处理数理逻辑、代码和需要深度推理的复杂问题。同基座模型相比，GLM-Zero-Preview 在不显著降低通用任务能力的情况下，在专家任务能力方面的表现大幅提升，其在 AIME 2024、MATH500 和 LiveCodeBench 评测中，效果与 OpenAI o1-preview 相当。&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型表现如下：&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;247&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd02998897ee2c465a04b26d597ad65ae3.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;span style=&quot;color:#d83931&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/327323&quot;&gt;Altman 公布 OpenAI 2025 年将发布的技术产品&lt;/a&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;OpenAI 首席执行官萨姆・奥特曼（Sam Altman）发帖公布了该公司 2025 年即将发布的技术产品，分别是：&lt;/span&gt;&lt;/p&gt; 
  &lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
   &lt;li&gt;&lt;span&gt;AGI（通用人工智能）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;Agents（智能体）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的 GPT-4o 升级版&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的记忆存储&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更长的上下文窗口&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;「Grow up mode」（成人模式）&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;深度研究特色功能&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span&gt;更好的 Sora 以及更好的个性化定制&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8b88947df326c888e90ad352129eac9d6b6.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pingwest.com%2Fw%2F301379&quot; target=&quot;_blank&quot;&gt;华为轮值董事长孟晚舟新年致辞：2024 年是原生鸿蒙关键一年，一年走过其它操作系统十多年发展之路&lt;/a&gt;&lt;/h3&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;p&gt;据华为官网显示，华为轮值董事长孟晚舟今日发布新年致辞，对客户、生态伙伴、产业链伙伴、员工和家属等表达了感谢。&lt;/p&gt; 
  &lt;p&gt;她在致辞中提到，在万物智联的赛道上，2024 年是原生鸿蒙的关键一年，鸿蒙生态建设千帆起航。鸿蒙千帆计划得到了众多行业伙伴的积极响应，短短一年时间，我们就走过其它操作系统十多年的发展之路，创造了「鸿蒙速度」。&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;今日观察&lt;/span&gt;&lt;/h2&gt; 
&lt;div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;社交观察&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F3146485692%2FP6Fdbs7pg&quot; target=&quot;_blank&quot;&gt;「全球互联网上中文内容比例很低」是一个误读&lt;/a&gt;&lt;/h4&gt; 
  &lt;p&gt;有人用图一来说明全球互联网上中文内容比例很低，只占 1.4%，实际上这是一个误读。我以前说过一次，这个数据统计方法并不是计算文字量或者网页数量，而是计算使用某种语言的网站数量。&lt;/p&gt; 
  &lt;p&gt;举个例子，微博网站在这个统计中，只能将样本数字+1，别管微博上边有多少中文内容，在这个统计方法中，微博跟万年没人看的某些个人站没有区别，都只算一个网站。同样是 W3Techs 提供的数据，图二就很能解释这个问题，只是中文网站数量少，并不是中文内容少。&lt;/p&gt; 
  &lt;div&gt; 
   &lt;div&gt;
    &lt;img alt=&quot;&quot; height=&quot;766&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-482daac5671878f6a85c04be877532dd134.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;img alt=&quot;&quot; height=&quot;463&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6f886a14ad542db607c9f12aece90f15540.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
   &lt;/div&gt; 
   &lt;div&gt;
    &amp;nbsp;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;div style=&quot;text-align:right&quot;&gt;
    &lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;BugOS 技术组&lt;/strong&gt;&lt;/span&gt;
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP6DrHa8Ob&quot; target=&quot;_blank&quot;&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式： M = &amp;nbsp;( (P * 4B) / (32 / Q) &amp;nbsp;) * 1.2&lt;/p&gt; 
   &lt;p&gt;M: 所需的 GPU 显存，单位是 GB。&lt;br&gt; P: 模型的参数数量。例如，7B 模型有 70 亿个参数。&lt;br&gt; 4B: 每个参数占用的字节数，这里假设每个参数占用 4 个字节（通常指 FP32 或 Float32 格式）。&lt;br&gt; 32: 4 个字节等于 32 位。&lt;br&gt; Q: 加载模型时使用的位数。例如，16 位 (FP16/BF16)，8 位 (INT8) 或 4 位 (INT4)。这通常称为量化。&lt;br&gt; 1.2: 表示额外开销的系数，通常为 20%。这考虑了除了模型权重之外还需要加载到 GPU 显存中的其他数据，例如优化器状态、梯度等。&lt;/p&gt; 
   &lt;p&gt;如使用 FP16 量化加载 Llama 70B 模型，计算过程就是&lt;br&gt; M = &amp;nbsp;( (70,000,000,000 * 4) / (32 / 16) &amp;nbsp;)* 1.2 = 168 GB&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; 蚁工厂&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2169039837%2FP7e1GcOVX&quot; target=&quot;_blank&quot;&gt;大模型导航资源&lt;/a&gt;&lt;/h4&gt; 
   &lt;p&gt;分享个大模型导航资源，里面收集了几乎全部的模型，具有里程碑意义的论文，排行榜，测试集，训练框架，部署，应用，书籍等&lt;/p&gt; 
   &lt;p&gt;github.com/Hannibal046/Awesome-LLM&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&lt;strong&gt; karminski-牙医&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
   &lt;h4&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1706699904%2FP6mWLnFlv&quot; target=&quot;_blank&quot;&gt;英伟达虽然欠下来了大量的「技术债务」，但在他看来「技术债务就像是幸存者的战斗伤痕。」&lt;/a&gt;&lt;/h4&gt; 
   &lt;div&gt; 
    &lt;div&gt; 
     &lt;div&gt; 
      &lt;p&gt;关于先做个垃圾出来，读《英伟达之芯》又看到了一个好例子：&lt;/p&gt; 
      &lt;p&gt;3dfx 破产之后，一个加入英伟达的员工被英伟达的代码库震惊到了，「简直就像是癌症」「代码写得一塌糊涂，开发工具链也是一团乱麻，最重要的是，他们对此毫不在意」「他们一心只想着下一块芯片流片，其他什么都不顾。」&lt;/p&gt; 
      &lt;p&gt;而之前 3dfx 的工作方式则是追求完美，他在那里写出的程序优雅，开发的系统条理清晰、注释详尽，但结果却是一败涂地。&lt;/p&gt; 
      &lt;p&gt;他给的总结相当精辟，英伟达虽然欠下来了大量的「技术债务」，但在他看来「技术债务就像是幸存者的战斗伤痕。」&lt;/p&gt; 
     &lt;/div&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- 微博&amp;nbsp;&lt;strong&gt;i 陆三金&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;媒体观察&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819939622972077660%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;AI 发展：训练数据即将遭遇瓶颈&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;训练数据即将遭遇的瓶颈已悄然浮现。有研究机构预测，到 2028 年左右，用于训练 AI 模型的数据集典型规模将达到公共在线文本总估计量的规模。换句话说，AI 可能会在大约 4 年内耗尽训练数据。与此同时，数据所有者（如报纸出版商）开始打击对其内容的滥用行为，进一步收紧了访问权限，这将引发「数据共享」规模上的危机。为此，开发人员必须寻找变通之道。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;科技日报&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.ce.cn%2Fcysc%2Ftech%2Fgd2012%2F202412%2F30%2Ft20241230_39251115.shtml&quot; target=&quot;_blank&quot;&gt;全面拥抱人工智能——访 360 集团创始人周鸿祎&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;我国人工智能大模型具有广阔发展前景，但要在全球大模型产业竞争中赢得主动，一是要充分发挥我国制度优势，与国外通用大模型展开竞争；二是充分用好我国工业种类齐全、场景众多的优势，将大模型和各种应用场景结合，推动一场新型工业革命，这是实现发展「弯道超车」的关键。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;经济日报&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819927511172343210%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;国产 AI 舞台，站满了「90 后天才」&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;从资本到产业对人才的大手笔抢先押注现状来看，有关 AI 的比拼，无疑不止算力，而更在于人才。&lt;/span&gt;&lt;/p&gt; 
   &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;科创板日报&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819926514777138655%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;「国产英伟达」们，扎堆上市&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，GPU 企业想要快速发展，必然离不开资本的助力，冲击上市仍是「国产英伟达」们获取资金弹药的重要途径。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;而在等待资本市场的大门开启之前，它们也需要直面生存的考验。张建中曾直言，「摩尔线程目标为至少先存活 10 年」。在这场「国产替代」光荣而艰辛的征途中，中国算力企业的竞逐才刚刚开始。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:rgba(0, 0, 0, 0.9)&quot;&gt;财经天下 WEEKLY&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1819915034550649526%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;冷眼与嘲讽之后，谷歌的 AI 大模型翻盘之路&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#262626&quot;&gt;谷歌正在逐渐夺回大模型竞赛的行业关注度和开发者认同，反垄断大锤还尚未真正落下，谷歌获得了一个难得的发展窗口来在新的技术革新潮流中暂时站稳脚跟，为下一个人工智能时代真正到来前做好准备。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;- &lt;/span&gt;&lt;span style=&quot;color:#252525&quot;&gt;&lt;strong&gt;锦缎研究院&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftech.ifeng.com%2Fc%2F8fjJTSFA8ou&quot; target=&quot;_blank&quot;&gt;AI「爆改」快递行业的第二年&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;div&gt; 
  &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;从简单的寄件、查件入手，到面向快递小哥打造「知识库」、再到帮助完成业务信息的汇总整理，甚至到供应链的智慧控制，大模型在快递行业的能力正在被逐步释放。选择私有化部署模型、自研大模型的快递公司们都相信一点：大模型是值得的长期投资，它在快递行业的应用上限仍然有一个广阔空间等待发掘。&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:right&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;-&lt;strong&gt;&amp;nbsp;光锥智能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;今日推荐&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;开源项目&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fliriliri%2Faya&quot; target=&quot;_blank&quot;&gt;liriliri/aya&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;333&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ebd9d1bb174c2b67c92d4e694388364cd8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fliriliri%2Faya&quot; target=&quot;_blank&quot;&gt;https://github.com/liriliri/aya&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#1f2328; text-align:start&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;AYA 是一款内置 ADB 并基于其功能编写用户界面的桌面应用。相比于原始的 ADB 命令行输入，AYA 安装傻瓜，功能齐全，全图形化界面，一键操作，极大地提高用户效率。&lt;/span&gt;&lt;/p&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;每日一博&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://my.oschina.net/u/4939618/blog/16883119&quot; target=&quot;_blank&quot;&gt;网页多模态建模思考&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;本文从网页理解业务出发，从多模态信息融合，预训练任务构建角度，探讨通用网页建模方案。首先，指出网页的特殊性，即从不同观察视角下，网页存在富文本、树形结构，和图层堆叠三种形态。在此基础上，对比了多种多模态融合思路的优缺点，给出一种较好的方案。进一步，提出多粒度、多维度的网页预训练方案；最后，探索了大模型时代，利用现有多模态模型，低成本的适配到网页的一种可行思路。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;图片&quot; height=&quot;173&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-42f7e135775e8f8238f20f5e042a576e488.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div&gt; 
  &lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;开源之声&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;&lt;span style=&quot;color:#ffffff&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ff9900&quot;&gt;用户观点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FjS984AtnzvXfNwjPVFakZg&quot; target=&quot;_blank&quot;&gt;最强开源终端模拟器 Ghostty 正式发布 1.0：原生 UI 体验、采用 Zig 编写、速度飞快、支持 Mac 和 Linux、支持 GPU 加速&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：什么玩意？不支持 windows？我今晚就去提 issue，炮轰作者&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：不至于，README&amp;nbsp;里有写是有计划支持&amp;nbsp;Windows&amp;nbsp;的。终端模拟器不支持&amp;nbsp;Windows&amp;nbsp;是非常常见的情况&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：zig&amp;nbsp;比 rust 吹实在&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：只要 C&amp;nbsp;ABⅠ在行业上占大头，zig 就永远实在。zig 直接调用 C 真的很爽！&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：完全可以理解，等下就去试试。Who&amp;nbsp;care&amp;nbsp;Windows?&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 6：和 Rust 写的 Warp 比如何？Zig 应用越来越多，好事。&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 7：Warp&amp;nbsp;性能不太行，输出多了卡，&amp;nbsp;不知道后续的版本会不会优化&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 8：目前在用 wezterm，感觉真正的 killer&amp;nbsp;feature 是 multiplexing，tmux 快捷键记不住。目前看 ghost 没有 multiplexing，也没有 tmux&amp;nbsp;integration，期待。&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 9：好吧，我还是用 WinTerm 吧&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 10：你不觉得这玩意反应要慢半拍么，而且伪开源不让人放心。&lt;/span&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 11：我看不懂源代码，所以不存在放心与否～&lt;/span&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 12：不知道跟 wezterm 比起来怎么样&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 13：用上了，之前用 wezterm，个人感觉比 wezterm 更简洁高效。两个都很好。&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 14：可以替换掉&amp;nbsp;iTerm2 了&lt;/span&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 15：我用 powershell7.5&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;&lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLAiX2TcypVQbdG8s9Y2OMA&quot; target=&quot;_blank&quot;&gt;中国 AI 的进步之快，让美国人开始怀疑现实了&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 1：飘了&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 2：哪来这么多反思哥反思姐？作为机器学习领域的从业者，国内 ai 领域实际上就是在突飞猛进的发展，海外各类先进模型和理论也至少一半是大陆出海华人的贡献。现在大环境不好，但不是国内从业者夜以继日的努力是网民一句话所能掩盖的！&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 3：当然 DeepSeek 不太一样的是，它不太缺卡，2021 年就囤了 1 万张英伟达 A100，那会儿 ChatGPT 还没影呢，和 Meta 为了元宇宙囤卡却阴差阳错的赶上 AI 浪潮很像，DeepSeek 买那么多卡，是为了做量化交易⋯⋯&lt;/span&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 4：阴差阳错，就好比你买了一把锅铲，本来打算是用来炒菜的，后来发现打老公也挺好使！&lt;/span&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;观点 5：中美 ai 发展的确差不多，期待落地&lt;/span&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;---END---&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2024/0912/150800_DfGR_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327414</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327414</guid>
            <pubDate>Tue, 31 Dec 2024 11:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 生态内容征集大赛（2025 年）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;很高兴告诉大家：RWKV 社区推出&quot;&lt;strong&gt;RWKV 生态内容征集大赛&lt;/strong&gt; &quot;，此活动在 &lt;strong&gt;2025 年全年内&lt;/strong&gt;公开征集 RWKV 相关的内容，包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;与 RWKV 相关的论文&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;讲解 RWKV 的教程，例如文章、视频、动画&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;基于 RWKV 的应用&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;我们会根据&lt;strong&gt;内容的质量、新颖度、与 RWKV 的相关度&lt;/strong&gt;，发放生态奖励：&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;奖项&lt;/th&gt; 
   &lt;th&gt;奖金&lt;/th&gt; 
   &lt;th&gt;参考论文&lt;/th&gt; 
   &lt;th&gt;参考教程&lt;/th&gt; 
   &lt;th&gt;参考应用&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铂奖&lt;/td&gt; 
   &lt;td&gt;6888 元&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.06973&quot; target=&quot;_blank&quot;&gt;RWKV-CLIP&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.19369&quot; target=&quot;_blank&quot;&gt;RWKV-SAM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpoloclub.github.io%2Ftransformer-explainer%2F&quot; target=&quot;_blank&quot;&gt;铂金教程参考&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenMOSE%2FRWKV-LM-RLHF&quot; target=&quot;_blank&quot;&gt;RWKV-LM-RLHF&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;金奖&lt;/td&gt; 
   &lt;td&gt;4888 元&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.19535&quot; target=&quot;_blank&quot;&gt;StyleRWKV&lt;/a&gt;，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.10856&quot; target=&quot;_blank&quot;&gt;RWKV-edge&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FProfTomYeh%2Fstatus%2F1839706195508208089&quot; target=&quot;_blank&quot;&gt;金奖教程参考&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FOpenMOSE%2FRWKV-Infer&quot; target=&quot;_blank&quot;&gt;RWKV-Infer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;银奖&lt;/td&gt; 
   &lt;td&gt;2888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fshengxia%2FRWKV_Role_Playing&quot; target=&quot;_blank&quot;&gt;RWKV_Role_Playing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铜奖&lt;/td&gt; 
   &lt;td&gt;1888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;铁奖&lt;/td&gt; 
   &lt;td&gt;888 元&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
   &lt;td&gt;---&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;除了获奖作品，其他所有&lt;strong&gt;符合条件的投稿&lt;/strong&gt; 均可获得 &lt;strong&gt;RWKV 周边&lt;/strong&gt;一套，包括 RWKV T 恤、帆布袋、徽章、冰箱贴各 1 个。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-77625c3ead2e14d462793268eba2d3cb448.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;投稿规则&lt;/h2&gt; 
&lt;h3&gt;RWKV 论文&lt;/h3&gt; 
&lt;p&gt;我们征集任何与 RWKV 相关的论文，&lt;strong&gt;无论是谁写的，无论是否中会，只要内容新颖。&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的论文&lt;strong&gt;不限发布平台&lt;/strong&gt;，支持所有可公开查阅的论文平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;RWKV 文章&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的文章以&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fwrite&quot; target=&quot;_blank&quot;&gt;知乎-文章&lt;/a&gt;为默认发布平台，允许多平台分发。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在知乎发布文章时，请添加 &lt;code&gt;rwkv&lt;/code&gt; 话题：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e980b9c31863b214fac301b41edaa9fcd3a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;发布后，应当可以在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhihu.com%2Ftopic%2F27422569%2Fnewest&quot; target=&quot;_blank&quot;&gt;知乎- RWKV 话题&lt;/a&gt;中查看您的投稿。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 文章需要满足以下要求：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文章正文不少于 300 字，每个章节或操作步骤需要有合理的配图&lt;/li&gt; 
 &lt;li&gt;文章应有合理的结构，示例结构：准备微调数据 -&amp;gt; 微调的调参等配置过程 -&amp;gt; 遇到的问题和解决方案 -&amp;gt; 微调效果&lt;/li&gt; 
 &lt;li&gt;文章语句清晰易懂，内容新颖&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RWKV 视频和动画&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 相关的视频和动画以 &lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2F&quot; target=&quot;_blank&quot;&gt;bilibili&lt;/a&gt;&lt;/strong&gt; 为默认投稿平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 Bilibili 发布 RWKV 视频或动画时，需要带上 &lt;code&gt;RWKV&lt;/code&gt; 标签。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e5881d6a993bc1f88f77a388cf6aa70284c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 视频和动画需要满足以下条件：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频时长不低于 1 分钟&lt;/li&gt; 
 &lt;li&gt;视频画质不低于 720P&lt;/li&gt; 
 &lt;li&gt;视频音频无限制，可以是 AI 或真人配音，如无音频则需要配字幕&lt;/li&gt; 
 &lt;li&gt;内容新颖&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RWKV 应用&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV 应用需要开源发布，以 &lt;strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;/strong&gt; 为默认发布平台。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 GitHub 开源发布 RWKV 应用时，需要在 GitHub 仓库的设置中加上 &lt;code&gt;rwkv&lt;/code&gt; 标签。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1cfbe9e8859dff7e3a4dafc4cffd2ec2bda.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;仓库添加话题后，应当可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ftopics%2Frwkv%3Fo%3Ddesc%26s%3Dupdated&quot; target=&quot;_blank&quot;&gt;GitHub-rwkv 话题最新项目&lt;/a&gt;中查看您的 RWKV 应用。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;投稿的 RWKV 应用需要满足以下条件：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;应用需具有清晰的核心功能，并能够在真实场景中运行，内容新颖&lt;/li&gt; 
 &lt;li&gt;代码具备可读性，包含必要的注释&lt;/li&gt; 
 &lt;li&gt;README 等文档中包含&lt;strong&gt;依赖版本&lt;/strong&gt; 和&lt;strong&gt;操作步骤&lt;/strong&gt;等用户指南&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;活动规则&lt;/h2&gt; 
&lt;h3&gt;活动时间&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;用户投稿时间：2025 年全年（2025.01.01 ~ 2025.12.31）&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;投稿反馈通道&lt;/h3&gt; 
&lt;p&gt;投稿后，请加入 &lt;strong&gt;RWKV 社区活动&lt;/strong&gt; QQ 群：858016738 ，联系管理员登记投稿。&lt;/p&gt; 
&lt;p&gt;任何关于本活动的疑问，也可以在群内讨论。&lt;/p&gt; 
&lt;h3&gt;评审规则&lt;/h3&gt; 
&lt;p&gt;由彭博等 RWKV 社区核心成员、大模型专家组成评审团，对参赛作品进行评审。&lt;/p&gt; 
&lt;p&gt;评审结果会&lt;strong&gt;在 2025 年每个自然月的下旬公布&lt;/strong&gt;，作品奖励会在次月发放。&lt;/p&gt; 
&lt;h3&gt;投稿内容范围&lt;/h3&gt; 
&lt;p&gt;所有投稿内容需要&lt;strong&gt;与 RWKV 架构或模型相关&lt;/strong&gt;，其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;论文&lt;/strong&gt;：基于 RWKV 架构或其变体，在语言、多模态、序列、强化学习等等领域的论文，也包括可解释性、理论分析、量化压缩、下游任务等等&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;教程（文章、视频、动画等）&lt;/strong&gt;：RWKV 架构解析、代码解读、微调案例等教程&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;：基于 RWKV 架构或模型的应用，例如训练和推理框架，也包括角色扮演、助手、写作、游戏等等具体应用&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;奖品发放方式&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;现金奖励的币种为人民币，以汇款或转账方式发出，奖金为含税金额&lt;/li&gt; 
 &lt;li&gt;RWKV 周边奖励为实物，以快递方式发出&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327403</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327403</guid>
            <pubDate>Tue, 31 Dec 2024 09:21:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>RWKV 社区 12 月动态速览！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2024 年 12 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 12 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;12 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文： StyleRWKV（RWKV 视频风格迁移）&lt;/li&gt; 
   &lt;li&gt;新论文： L3TC（RWKV 文本压缩）&lt;/li&gt; 
   &lt;li&gt;新论文： A Survey of RWKV（RWKV 综述）&lt;/li&gt; 
   &lt;li&gt;新论文： PCF-RWKV（RWKV 碳足迹评估模型）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV-edge（RWKV 边缘设备部署）&lt;/li&gt; 
   &lt;li&gt;新论文： RWkV-DPA（RWKV DPA 估计器）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV-IR（RWKV 图像修复模型）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RWKV-7-0.1B&lt;/li&gt; 
   &lt;li&gt;新模型： QRWKV6-32B-Instruct&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;12 月 7 日，RWKV 团队在华中科技大学进行技 AI 技术讲座&lt;/li&gt; 
   &lt;li&gt;12 月 21 日，RWKV 团队在中山大学深圳校区开展技术分享&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区项目动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Frwkv.com&quot; target=&quot;_blank&quot;&gt;rwkv.com&lt;/a&gt; 优化更新，改善用户体验&lt;/li&gt; 
   &lt;li&gt;RWKV WebGPU DEMO：在浏览器中本地运行 RWKV-7-world-0.1B 模型&lt;/li&gt; 
   &lt;li&gt;RWKV pip 、RWKV Runner 、Ai00 均已支持 RWKV-7 模型推理&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括&lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt;或 &lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Style-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：StyleRWKV: High-Quality and High-Efficiency Style Transfer with RWKV-like Architecture&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.19535&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.19535&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-27&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文介绍了 StyleRWKV，一种新的风格迁移方法。它采用受 RWKV 启发的架构来解决先前方法的缺点，如高计算复杂度等问题。通过 Re-WKV 注意力机制等关键要素，它实现了高效且高质量的风格迁移。&lt;/p&gt; 
&lt;p&gt;实验证明，StyleRWKV 在风格化质量、模型复杂性和推理效率方面都优于最先进的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-76f4da92fb94758eee1524c772611e218f2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;L3TC&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：L3TC: Leveraging RWKV for Learned Lossless Low-Complexity Text Compression&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.16642&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.16642&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;L3TC 是一种新的学习型无损低复杂度文本压缩方法。它采用 RWKV 作为基础架构，并提出了异常值感知分词器和高秩重参数化策略，在不增加推理复杂度的前提下提升了模型学习能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1561585610e5942ba1ff4fe4700db22cbb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;实验结果验证，L3TC 相较于 gzip 压缩节省了 48% bit。与同性能的其他学习型压缩器相比，L3TC 模型的参数减少 50 倍，且实时解码速度高达 MB/s 量级。&lt;/p&gt; 
&lt;h3&gt;A Survey of RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：A Survey of RWKV&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.14847&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.14847&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-19&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文深入探究 RWKV，架构方面剖析其融合机制，应用上梳理多领域成果，分析长序列和多模态等挑战，探讨处理能力、安全、硬件等未来方向，为其研究与应用提供坚实理论支撑，助力该领域发展。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-56cdad20b17b4c1b1d166aefdaf2fd152b5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;PCF-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：PCF-RWKV: Product Carbon Footprint Estimation System Based on Large Language Model&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.preprints.org%2Fmanuscript%2F202412.1705%2Fv1&quot; target=&quot;_blank&quot;&gt;https://www.preprints.org/manuscript/202412.1705/v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PCF-RWKV 是一款基于 RWKV 架构的产品碳足迹评估模型，具有多个堆叠残差块和三个任务专用的低等级适配器 (LoRA)。通过集成 Multi-Agents 技术，PCF-RWKV 可自动构建生产流程的 LCI，将生产流程与排放因子相匹配以计算碳足迹，从而提高企业碳足迹评估的效率和安全性，并解决传统方法的局限性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-25471592bccbee4e63b4a7dfa15d8204a90.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-edge&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：RWKV-edge: Deeply Compressed RWKV for Resource-Constrained Devices&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.10856&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.10856&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-edge，旨在解决资源受限设备运行 RWKV 模型的难题。其采用低秩近似、稀疏性预测和聚类头等技术，将 RWKV 模型压缩了 4.95-3.8 倍，而准确度仅损失 2.95pp。&lt;/p&gt; 
&lt;p&gt;RWKV-edge 为在边缘设备部署 RWKV 模型提供有效方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c43b7055799d32ed245247d5335b01c74f8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-DPA&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Linear Attention Based Channel Estimation Scheme for V2X Communications&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10779439&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10779439&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV-DPA 是一种用于车联网 （V2X） 通信的创新信道估计方案，它使用线性注意力机制捕捉输入符号之间的相关性，并结合数据导频辅助（DPA）估计来动态跟踪信道变化，从而提升信道估计性能。&lt;/p&gt; 
&lt;p&gt;仿真结果表明，RWKV-DPA 评估器在误码率（BER）和归一化均方误差（NMSE）方面性能上优于其他基于深度学习的估计器，同时保持了较低的计算复杂度。在涉及高速运动的场景中，RWKV-DPA 估计器表现出卓越的性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a6be5ccdae33fda4b489ae87abea8a978c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-IR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Exploring Real&amp;amp;Synthetic Dataset and Linear Attention in Image Restoration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.03814&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.03814&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-IR：基于 RWKV 的图像修复模型，支持全局和局部感受野。RWKV-IR 在 Urban100 x4 的实验上比 SwinIR 好 0.08dB，比 MambaIR 好 0.03dB，展示了 RWKV-IR 的先进图像恢复能力和快速收敛能力。&lt;/p&gt; 
&lt;p&gt;项目主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fyuzhend.github.io%2FReSyn.github.io%2F&quot; target=&quot;_blank&quot;&gt;https://yuzhend.github.io/ReSyn.github.io/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;TRINet-architecture&quot; src=&quot;https://oscimg.oschina.net/oscnet//f961cf8b2e5940a2ae43c5638abc87fe.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型动态&lt;/h2&gt; 
&lt;h3&gt;新模型： RWKV-7-0.1B&lt;/h3&gt; 
&lt;p&gt;2024 年 12 月 11 日，RWKV 基金会正式发布了首款 RWKV-7 架构模型：RWKV-7-World-0.1B-v2.8。&lt;/p&gt; 
&lt;p&gt;RWKV-7-World-0.1B-v2.8 是目前全球最强的 0.1B 多语言模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HF 主站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HF 镜像站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://hf-mirror.com/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ModelScope：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FBlink_DL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/Blink_DL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;更多关于 RWKV-7-0.1B 介绍参见：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FrV0-QqKHG8q8VOC7IHeG_g&quot; target=&quot;_blank&quot;&gt;RWKV-7-World-0.1B 发布&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;新模型： QRWKV6-32B-Instruct&lt;/h3&gt; 
&lt;p&gt;QRWKV6-32B-Instruct 由 RWKV 海外社区完成训练并发布。&lt;/p&gt; 
&lt;p&gt;QRWKV6-32B-Instruct 是使用 RWKV-V6 替换 Qwen-32B-Instruct 的 Transformer 注意力头，再使用少量数据训练，就能使它具有 RWKV 的效率和显存优势，克服原有的 Transformer 架构限制。&lt;/p&gt; 
&lt;p&gt;QRWKV6-32B-Instruct 现已上传到 Hugging Face 仓库： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2Frecursal%2FQRWKV6-32B-Instruct-Preview-v0.1&quot; target=&quot;_blank&quot;&gt;recursal/QRWKV6-32B-Instruct-Preview-v0.1 &lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;在线体验 DEMO： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffeatherless.ai%2Fmodels%2Frecursal%2FQRWKV6-32B-Instruct-Preview-v0.1&quot; target=&quot;_blank&quot;&gt;https://featherless.ai/models/recursal/QRWKV6-32B-Instruct-Preview-v0.1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社区活动&lt;/h2&gt; 
&lt;p&gt;此版块包含 &lt;strong&gt;RWKV 官方动态&lt;/strong&gt;，以及 &lt;strong&gt;RWKV 社区举办或参加的各类活动&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 进高校第四站：华中科技大学&lt;/h3&gt; 
&lt;p&gt;应华科开放原子开源俱乐部的邀请，RWKV 开源项目团队于 12 月 7 日在华中科技大学国家网安基地校区做了一次深度解析 RWKV 模型的 AI 技术讲座，现场反响热烈。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f7d2be5062a1839e34612297a8c8a929586.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 进高校第五站：中山大学&lt;/h3&gt; 
&lt;p&gt;12 月 21 日，RWKV 开源团队在中山大学深圳校区开展技术分享，吸引了众多对人工智能和深度学习感兴趣的学生和研究人员参与。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ef4be5de7a72cef77d63eeff9f26b350b67.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;欢迎各高校了解 RWKV、共建活动，或开展 RWKV 相关的研究，我们将竭力为您提供帮助。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;联系微信：jadexlaw&lt;/li&gt; 
 &lt;li&gt;邮箱：luoxuan@rwkvos.com&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RWKV 社区项目动态&lt;/h2&gt; 
&lt;h3&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Frwkv.com&quot; target=&quot;_blank&quot;&gt;rwkv.com&lt;/a&gt; 优化&lt;/h3&gt; 
&lt;p&gt;RWKV 英文官网 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.com%2F&quot; target=&quot;_blank&quot;&gt;rwkv.com&lt;/a&gt; 进行了排版和内容等优化更新，显著提升了用户体验。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-143d31be96429c27ecc162b48fa7440c9a5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV WebGPU DEMO&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;无需下载任何应用，在浏览器中本地运行 RWKV-7-world-0.1B 模型！&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fcryscan%2Fweb-rwkv&quot; target=&quot;_blank&quot;&gt;web-rwkv&lt;/a&gt; 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcryscan.github.io%2Fweb-rwkv-puzzles%2F%23%2Fchat&quot; target=&quot;_blank&quot;&gt;RWKV WebGPU DEMO&lt;/a&gt; 在浏览器中本地运行 RWKV-7-world-0.1B 模型！加载后，模型可以离线运行，不需要任何服务器通信。&lt;/p&gt; 
&lt;p&gt;除了运行 RWKV 模型进行对话，WebGPU DEMO 也支持自动 15 Puzzle 、RWKV 作曲、回看模型 state 等功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9e8b6d042f1658853456c8aefa9774c4c77.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;我们很快会推出更详细的 RWKV WebGPU DEMO 介绍文章，敬请期待！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;RWKV pip 包发布 0.8.28 版本&lt;/h3&gt; 
&lt;p&gt;RWKV pip 包发布了 0.8.28 版本，已支持 RWKV-7 架构。&lt;/p&gt; 
&lt;p&gt;新版 pip 包支持通过 &lt;code&gt;os.environ[&quot;RWKV_V7_ON&quot;] = &#39;1&#39;&lt;/code&gt; 启动 RWKV-7 推理。&lt;/p&gt; 
&lt;h3&gt;RWKV Runner 支持 RWKV-7&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FjosStorer%2FRWKV-Runner%2Freleases&quot; target=&quot;_blank&quot;&gt;RWKV Runner&lt;/a&gt; 从 1.8.9 版本开始支持 RWKV-7 模型。&lt;/p&gt; 
&lt;h3&gt;Ai00 支持 RWKV-7&lt;/h3&gt; 
&lt;p&gt;web-rwkv、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAi00-X%2Fai00_server%2Freleases&quot; target=&quot;_blank&quot;&gt;Ai00&lt;/a&gt;最新版本均已支持 RWKV-7 推理。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327397</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327397</guid>
            <pubDate>Tue, 31 Dec 2024 08:57:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>网页多模态建模思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;本文从网页理解业务出发，从多模态信息融合，预训练任务构建角度，探讨通用网页建模方案。首先，指出网页的特殊性，即从不同观察视角下，网页存在富文本、树形结构，和图层堆叠三种形态。在此基础上，对比了多种多模态融合思路的优缺点，给出一种较好的方案。进一步，提出多粒度、多维度的网页预训练方案；最后，探索了大模型时代，利用现有多模态模型，低成本的适配到网页的一种可行思路。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;01 综述&lt;/h1&gt; 
&lt;p&gt;网页本质上是一种超文本，一般由超文本标记语言来定义（例如 HTML）。HTML 是一种基础技术，常与 CSS、JavaScript 一起被众多网站用于设计网页、网页应用程序以及移动应用程序的用户界面 。网页浏览器内核通过解释 HTML 文件，通过视觉引擎将其渲染成可视化网页。&lt;/p&gt; 
&lt;p&gt;由于 HTML 的复杂性特点，使得网页体现出多模态性，多粒度性，并且这些模态内部存在复杂的对应关系。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多模态性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所谓多模态性，即从不同视角下，网页体现出不同的形态。从信息载体角度看，它是文本、图像、视频等多媒体元素集合。从视觉层面看，它拥有图层的概念，是各层图像堆叠起来形成了一张完整的「图片」。从底层代码逻辑看，它是一种特殊的类 XML 语言，定义了一棵具有层次关系的树（dom-tree）。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多粒度性&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;所谓多粒度性，即网页无论从哪种模态看，都是由粒度不等的元素组成的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以资讯类网页举例，从信息载体模态看，网页由段落组成，段落又由句子组成，句子由 tokens 组成；&lt;/p&gt; 
 &lt;p&gt;从视觉层面，网页由不同尺寸的图层，依次堆叠而成；&lt;/p&gt; 
 &lt;p&gt;从底层代码逻辑看，html 由不同高度以及大小的子树构成。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;内在的对齐逻辑&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;多种模态的基本元素之间，存在多对多的对齐关系。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;对于 dom-tree 的结点，对应视觉层面的一个图层，亦可对应着一个或者多个句子&lt;/p&gt; 
 &lt;p&gt;一个句子，可能对应着一个结点，也可能对应着多个结点&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;一个例子：多模态的网页表示&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9a68799619487d4d13e1e65530c502edaaa.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△语义：句子{图像、视频等可文本化）的集合&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1c057353f56b7591a592066fd456df918a0.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△结构：dom 结点构成的树&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-de73382e2ab59c30101daf9bbaa02660652.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△视觉：图层的叠加（轮廓图）&lt;/p&gt; 
&lt;p&gt;由于网页的多模态性，多粒度性，以及潜在对齐关系的特点，使得对网页的建模，与对富文本的建模思路有着显著的不同。如果将网页作为富文本处理，会丢失大量的信息&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;举一个简单的例子，一个文本位于网页的不同位置（譬如正文区域，推荐区域），它的重要性是完全不一样的。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;而复杂的业务下游应用，例如网页质量甄别，网页结构化分块等，仅依赖文本的语义信息是远远不够的，需要综合考虑多模态的信息，以及多模态间的对齐信息。&lt;/p&gt; 
&lt;p&gt;下面，结合业界研究和我们的探索，从多模态信息融合、预训练方案方面展开。最后，探讨 LLM 时代，网页多模态模型的可能的探索方向。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_3&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;02 多模态多粒度特征融合&lt;/h1&gt; 
&lt;p&gt;如何将多粒度，多模态的特征融合，是一个复杂的问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 多粒度信息的表示&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这个部分，业内解决方案较多。&lt;/p&gt; 
&lt;p&gt;对&lt;strong&gt;语义信息建模&lt;/strong&gt;，基于 hierarchical attention 的有较多方案。一种方式，是通过 bert 等编码器，输入 tokens，取 CLS 单元输出作为句子的向量表示；再通过 transformer 结构，输入句子向量，计算句子间 attention，得到句子以及篇章的稠密向量表示，用于下游任务。&lt;/p&gt; 
&lt;p&gt;对于&lt;strong&gt;结构建模&lt;/strong&gt;，以 html-dom 为基本单元。通过全连接层，融合 bounding box 座标、webkit 提取的 css style 信息等。&lt;/p&gt; 
&lt;p&gt;对于&lt;strong&gt;视觉建模&lt;/strong&gt;，可以基于 vit，以 patch 为基本单元。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. 多对多对应关系下，多模态信息融合&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这部分，相关研究主要有四种方案：顶层融合，底层融合、多模态统一建模以及多模态交叉 attention 的方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-800824f2678ef96daec39a396908620c116.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;底层融合即在输入层将多模态信息对齐后拼接作为 transformer 层的输入。这种方案对多任务预训练方案设计（包括任务类型，多任务 loss 权重设计）要求较高，不利于多种模态的信息的平衡。&lt;/p&gt; 
&lt;p&gt;顶层融合即在顶层获取一个结点或者语句对应的多模态向量，拼接后用于下游分类或回归任务。缺点在于，各模态独立建模的时候，缺少了相关信息交互，不能充分利用多模态之间的对齐信息。&lt;/p&gt; 
&lt;p&gt;多模态统一建模，以 LayoutV2 为例，将文本、图片信息通过不同的编码器定长编码后，输入统一的 transformer 中。对于多模态综合理解任务来说，很难在输入层显示的注入多模态的对齐信息；网页结构的单元向量与语义、视觉（网页轮廓图）的单元向量亦很难通过浅层的编码器投影到相同的语义空间内。&lt;/p&gt; 
&lt;p&gt;通过对比，认为在网页建模场景下，多模态交叉 attention 是一个较好的方案。具体来说，各模态分域表示，域之间相互独立；通过多模态交叉 attention 层完成多模态间信息交互。DocFormer 提出的 multi-modal attention，Beit3 提出的 MultiWay Transformer 等本质上均为这种思路。&lt;/p&gt; 
&lt;p&gt;在多对多对齐关系下（即一个模态的基本单元，可能对应另外一个模态多个基本单元）。可使用聚合函数（例如 average-pooling，lstm 等），将对应模态上一层 transformer-encode 输出的对应单元序列，通过聚合操作后变换为定长向量，输入到多模态 attention 层计算。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-42f7e135775e8f8238f20f5e042a576e488.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d458c22d4438625ff4b8a868228cd254a5b.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_4&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;03 预训练任务设计&lt;/h1&gt; 
&lt;p&gt;如何设计针对多个模态，不同粒度的任务，以及如何低成本的构建伪标签，是训练网页基座模型的关键。&lt;/p&gt; 
&lt;p&gt;分析业务中下游任务的特点，在预训练阶段设计了如下 4 个类别的的预训练任务。 &lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4623962da781deb0d521bd0b838298fb8b2.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;对于细粒度的语义预训练场景，借鉴 token 粒度 MLM 的思路，mask 完整的句子，并且通过 decoder 重建句子。&lt;/p&gt; 
&lt;p&gt;对于粗粒度的篇章预训练场景，结合搜索点击日志，mask 掉 title 后，通过 decoder 去噪重建 title 以及生成用户点击的 query。&lt;/p&gt; 
&lt;p&gt;对于细粒度的 html-dom 粒度预训练场景，通过 html_tag mask/重建，结点乱序重排进行训练。&lt;/p&gt; 
&lt;p&gt;对于篇章粒度的结构任务，通过 GPT 等生成页面类型的伪标签，作为监督信号训练。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;04 展望：LLM 时代的网页基座模型探索方向&lt;/h1&gt; 
&lt;p&gt;现阶段，多模态大模型发展到新的阶段，已经可以将图片（视频）、文本通过统一的 decoder 模型处理&amp;nbsp;。如何有效利用已有大模型的能力，低成本适配到网页，是当前研究的热点和难点。&lt;/p&gt; 
&lt;p&gt;一个朴素的思想，是将整个 html 源码输入给大模型，做进一步 postpretrain 使得模型适配网页。但是，由于网页源码的平均长度非常大（根据我们对百度网页库的统计，平均源码长度在 160k），如果再将节点的样式以 style 标签形式注入，源码长度预计会翻数十倍。面向海量网页计算极难落地。再者，针对网页场景下做若干轮 post-pretrain 成本亦很高。&lt;/p&gt; 
&lt;p&gt;一个可行思路是，通过 adaptor 网络，将网页 html-dom 的结构、位置以及视觉信息变换到已有多模态大模型的空间中，压缩成若干定长向量表示。&lt;/p&gt; 
&lt;p&gt;通过 adaptor 网络与 LLM 联合训练，调低 LLM 的学习率（尽量不扰动已有 LLM 的参数，保留 LLM 的泛化性）；通过特殊标签，注入 adaptor 产出的 tokens 向量，让 LLM 解释隐式向量代表的含义，训练 adaptor 网络。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;例如，构建 prompt：&lt;/p&gt; 
 &lt;p&gt;以下是一个网页的 dom 结点表示&amp;lt;STRUCT&amp;gt;adaptor_tokens&amp;lt;/STRUCT&amp;gt;，输出 css 描述文本：style=&quot;xxxxx&quot;&lt;/p&gt; 
 &lt;p&gt;训练 adator 网络，使得产出的 tokens 向量能够与 LLM 的语义空间打平&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;———— END————&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603657%26idx%3D1%26sn%3D6ba08a7cf4a124c94c4cd51786217499%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度垂搜一站式研发平台演进实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603628%26idx%3D1%26sn%3Df75ddec65ee183dc0c3d48b7e1fdb1ea%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;初探图谱 Embedding 用于异常检测（一）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603616%26idx%3D1%26sn%3D6f18533697c0a083f9c58373ac6b1a85%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;AIAPI - 转向 AI 原生检索&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603585%26idx%3D1%26sn%3D1ea31a1565c49bc466ddb99b6d9e63d9%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;学校新来了一位 AI 作文老师：能看、会评、还教改写&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603457%26idx%3D1%26sn%3Db3a0dcf00cb7a38bf62729c279619824%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;搞定十万卡集群！贫穷限制了我的想象力…&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4939618/blog/16883119</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/16883119</guid>
            <pubDate>Tue, 31 Dec 2024 08:37:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>「AI 为伍，重启征程」2024 OSC 源创会年终盛典在珠海圆满落幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt;
  12 月 28 日， 
 &lt;strong&gt;「&lt;/strong&gt; 
 &lt;strong&gt;AI&lt;/strong&gt; 
 &lt;strong&gt; 为伍，重启征程」2024 OSC 源创会年终盛典&lt;/strong&gt;在珠海嘉远世纪酒店圆满落下帷幕。本次活动由开源中国、Gitee 主办，华为联合主办，珠海市香洲区科技和工业信息化局、广东省科学院珠海产业技术研究院、珠海市软件行业协会、珠海市科技发展促进会、澳门亚太 IT 协会提供支持。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  本次活动秉承「自由、开放、分享」的宗旨，自开启报名后就受到了全国各地开发者和 IT 企业的关注，吸引到行业内的顶尖专家、技术领袖和一线开发者积极报名， 
 &lt;strong&gt;现场观众达 400&lt;/strong&gt; 
 &lt;strong&gt;余人，会场座无虚席，参会人数再创新高。&lt;/strong&gt; 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  2024 年，源创会走过不同城市，举办了 8 场城市沙龙，1 场年终盛典，汇聚上千位开发者、近 70 位优秀讲师。与此同时，开源中国和 Gitee AI 社区生态的发展也离不开业界专家与合作伙伴的支持。为了感谢各位合作伙伴的支持与贡献，本次大会组委会特别颁发 
 &lt;strong&gt;「源创会 2024 年度技术领航者」&lt;/strong&gt; 
 &lt;strong&gt;、&lt;/strong&gt; 
 &lt;strong&gt;「开源中国 2024 年度突出贡献专家」&lt;/strong&gt; 、 
 &lt;strong&gt;「 Gitee AI 年度最佳合作伙伴」&lt;/strong&gt;三大奖项。 
&lt;/div&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;div&gt;
  大会现场巧妙设置了一系列精彩纷呈、趣味盎然的活动，如「可乐滚滚乐」、「展台互动集章」、「寻找神秘人」等小游戏，让参会者门在繁忙的学习交流之余，也能尽情享受活动带来的欢乐时光。 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height=&quot;757&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60c6f827a4c838c5c35d9126e2b007ab682.png&quot; width=&quot;1140&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img height=&quot;582&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ea03f4327186e36e640b473448e4f40f4fe.png&quot; width=&quot;1132&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
 &lt;h1&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;大会精彩内容集锦&lt;/span&gt;&lt;/h1&gt; 
 &lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
 &lt;h2&gt;「AI 为伍，开源同行」主论坛&lt;/h2&gt; 
 &lt;blockquote&gt; 
  &lt;div&gt;
    聚焦开源与大模型技术的融合与发展 
  &lt;/div&gt; 
 &lt;/blockquote&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;625&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6288527b46f51a02af66a1db7f29a28fd7.png&quot; width=&quot;942&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   上午，在「AI 为伍，开源同行」的主论坛现场，华为资深开源工程师李佳伟发表了题为《主流开源软件原生支持升腾：大模型训练与推理的轻松之选》的精彩演讲，详细阐述了华为升腾在对主流开源软件，诸如 vLLM 、ONNXRuntime 、ollama 、llama.cpp 等进行原生支持方面所取得的显著进展以及当前的实际状况，旨在为广大开发者搭建起更为便捷、高效的大模型训练与推理平台，助力其在 AI 领域的探索与创新之路更加顺畅无阻。 
 &lt;/div&gt; 
 &lt;div&gt;
   李佳伟指出，在当今时代的科技浪潮中，AI 软件领域正呈现出爆发式增长的强劲态势，不断突破传统边界，实现着颠覆性的成长与跨越，同时，代码规模朝着更加精简高效的方向发展，已成为不可逆转的趋势。面对智能计算领域开源软件如雨后春笋般蓬勃涌现的局面，华为升腾秉持着开放、包容的态度，诚挚欢迎各路贤才精英踊跃加入，共同挖掘技术潜力，拓展创新边界，携手推动 AI 技术迈向新的高峰，为全球科技产业的发展贡献力量，共绘智能未来的宏伟蓝图。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;615&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9bc4705e402f42be1a8d343736695b058c6.png&quot; width=&quot;928&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   红帽大中华区首席架构师张家驹带来题为《大模型技术创新与合作——在人工智能领域拥抱开源价值观》的分享。步入 AI 时代，开源概念亦需顺势革新，秉持 100% 开源价值观成为必然要求，这意味着不仅代码要开源、权重需开放，训练数据以及训练方法等方面同样要实现开源共享。基于这样的理念，红帽精心发起了 InstructLab 项目。InstructLab 志在打造一个开放包容的社区平台，让每一个人都能拥有平等参与大模型开发的契机，使 AI 真正化作普惠大众的技术力量。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;603&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-012129eb7b9d5c29e6c8ccb962d26c18c78.png&quot; width=&quot;928&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   在《大模型在研发安全的应用实践》的分享中，腾讯代码安全负责人张栋强调，代码安全已成为大企业推进安全左移的核心点。传统代码安全方案在效率与能力上存在明显瓶颈，腾讯混元大模型通过其卓越的语义理解与泛化能力，在存量场景中突破传统能力上限，有效提升高危风险检出的准确率（质）、检出数（量）和修复效率。更重要的是在增量场景中，大模型为逻辑类漏洞和自动审计提供了落地的可能，使传统技术较难解决的复杂问题得以推进，实现从「提质提量」到「扩边增效」，推动代码安全实现质的突破与应用领域的拓展。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;616&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a015e8fd1330ce4668420c5dfd1b510175c.png&quot; width=&quot;927&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   蚂蚁集团高级算法专家余航则是分享了 CodeFuse 基座模型。CodeFuse 源于蚂蚁自身的开发场景及代码库沉淀，基于海量高质量代码数据和代码领域特色词表，以及多任务微调技术 MFT ，已从单环节智能化演进到企业级端到端的研发智能体探索，并开源了多个自研和微调的代码大模型，总下载量近 200 万。 
 &lt;/div&gt; 
 &lt;div&gt;
   余航详细介绍了，CodeFuse 旗下极具特色的仓库级代码图大模型 CGM，在行业权威的 SWE-Bench Lite 榜单上表现卓越，成功解决了 41.67% 的问题，在竞争激烈的 SWE-Bench Lite 开源榜单中脱颖而出，荣登榜首之位。这一成绩的取得，不仅彰显了 CodeFuse 模型的高超性能与精准能力，更为整个代码大模型领域树立了新的标杆，为后续的研究与应用提供了极具价值的参考与借鉴，有望引领行业朝着更加高效、智能的方向发展。 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;610&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-199292b7ce5c5f0cd5d7393c7a66ffc5dc5.png&quot; width=&quot;919&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   Vivo 高级系统架构专家徐海波在题为《 vivo 蓝河操作系统的 AI 技术探索与前沿实践》的分享。他介绍，BlueOS 蓝河操作系统是 vivo 自研面向通用人工智能时代的智能操作系统，具备更智慧的 AI 交互、更流畅的性能、更安全的内核及框架等特点。 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
  &lt;h2&gt;「GenAI 开发关键技术」主论坛&lt;/h2&gt; 
  &lt;blockquote&gt; 
   &lt;div&gt;
     聚焦 GenAI 开发中的关键技术 
   &lt;/div&gt; 
  &lt;/blockquote&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;604&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-08cb237f3c5cb587ad110e4b2e7f94810ee.png&quot; width=&quot;897&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    在下午「GenAI 开发关键技术」主论坛中，英飞流创始人兼 CEO 张颖峰发表题为《新一代企业级多模态 RAG 引擎》的演讲。张颖峰表示，随着 LLM 多模态能力的增强，RAG 也需要步入多模态时代，它并不限于对日常图片，音视频的检索增强，还应该涵盖当下占据大部分的非结构化文档，发掘出这些数据的商业价值。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;618&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e6a80737e9be486a7d34acaf407bf736f4c.png&quot; width=&quot;913&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    Gitee 私有云产品总监林靖靖发表《数据智能跟踪体系的构建》分享，深入阐述了 Gitee DevOps 如何打破信息孤岛，形成研发管理全域智能的产品组合，结合企业过程资产库和研发过程资产信息库，基于 AI 大模型 multiagents 和 RAG 技术，实现企业组织研发过程智能化、体系化，加速体系成熟，构筑智能化软件工厂。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;604&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cec210f483ef6a15b932c90d0eb7aeed78.png&quot; width=&quot;915&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    文心快码 Baidu Comate 架构师徐晓强发布题为《文心快码在代码生成场景下的知识丰富探索与实践》的演讲。为了提供给开发者更加准确的生成结果，文心快码这两年不断丰富上下文的探索，在代码续写场景下做「准确度」和「速度」的平衡。也探索了基于 Agent 的代码改写能力。随着模型能力的提升，文心快码已经能够在更多场景和更模糊的指令下完成更困难的任务。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;607&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-10b5d6472c3fa89cd02d73699ad65380c7e.png&quot; width=&quot;922&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    IDEA 基础软件中心高级工程师费浩祥发布题为《MoonBit 和 AI 的协同设计》的演讲。会上，费浩祥为大家介绍了 MoonBit 是如何在编程语言和工具链的上针对 AI 代码生成进行协同设计，并介绍这些设计是如何改善模型的性能，从而帮助 MoonBit 用户完成常见的编码任务。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;615&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7ad18a4d35ede9554bee7a8bde8c201b7e7.png&quot; width=&quot;915&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    华为开源生态专家杨滔发表《大模型时代的升腾 AI 》主题分享。杨滔指出，人工智能时代，升腾基础软硬件平台提供从底层算力、算子、框架、套件等层面对人工智能从模型开放到应用的全流程支持。 
  &lt;/div&gt; 
  &lt;div&gt;
    在人工智能框架方面，升思 MindSpore 持续创新，通过易用性提示，对大模型训推的支持，拥抱 AI 时代的创新，降低用户开发和应用成本。 
  &lt;/div&gt; 
  &lt;div&gt;
    AI 应用使能套件作为升腾生态领域的关键窗口，专注于赋予开发者围绕模型的全方位的能力，涵盖模型训练与推理一体的高效流程，有力地降低了升腾硬件开发的技术门槛。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;616&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9323e5b39bf9903dfaf010be001731182d1.png&quot; width=&quot;915&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    矩阵起源研发 VP 赵晨阳在题为《如何利用多模态模型构建适用于 LLM 搜索的数据》的分享中表示，智能体表现好坏依赖于数据，也进一步应证了高质量「知识」对于 LMM 的重要性。随后，赵晨阳进一步阐述在多模态数据融合阶段，更是需要创新性的算法和模型架构，来打破不同模态之间的语义鸿沟，实现数据的有机整合和协同表达。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;618&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2158984da12de417f86ea183d0f0092ba11.png&quot; width=&quot;927&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    Java 开发者应该如何构建 Agent？会上，Spring AI Alibaba 项目负责人刘军则向大家介绍了基于百炼模型服务的 AI 应用开发框架「 Spring AI Alibaba 」及其开发框架的架构与基本使用。Spring AI Alibaba 开源项目基于 Spring AI 构建，是阿里云通义系列模型及服务在 Java AI 应用开发领域的最佳实践，提供高层次的 AI API 抽象与云原生基础设施集成方案，可以帮助开发者快速构建 AI 应用。 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;img height=&quot;616&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e129d7547d9c85e6c0c4a4b7b8d5b4968d3.png&quot; width=&quot;921&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    Alluxio 首席架构师傅正佳带来题为《构建大模型时代的高性能 AI 数据底座》的分享。傅正佳介绍，Alluxio 是一个位于数据存储和计算框架之间，提供数据抽象、统一访问、分布式缓存加速、数据亲和性调度等功能的开源数据编排平台。Alluxio 通过帮助企业构建大模型时代的高性能 AI 数据底座以应对 I/O 挑战，提升 AI 算力的效率与性能，被广泛应用于模型训练与推理、自动驾驶、AI 制药、金融量化以及视频渲染等场景。 
  &lt;/div&gt; 
  &lt;div&gt; 
   &lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
   &lt;h2&gt;「升腾 AI 大模型与应用开发」分论坛&lt;/h2&gt; 
   &lt;blockquote&gt; 
    &lt;div&gt;
      聚焦升腾 AI 大模型与应用开发 
    &lt;/div&gt; 
   &lt;/blockquote&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;649&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-09f43971f063549241591e17cf938f1dd4a.png&quot; width=&quot;919&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     在下午的「升腾 AI 大模型与应用开发」分论坛上，华为升思生态总监王神迪博士带来题为《升思 MindSpore AI 框架使能大模型原生创新》的分享。升思 MindSpore 作为大模型时代 AI 框架的新选择，作为中国乃至世界的框架「新势力」，引领技术创新，加速全面智能化时代到。目前，社区下载量 1000 万+，社区核心贡献者 3.5 万，认证企业数超 1500+ 家。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;687&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8d5d0f602b6d8542509a415f14e4183c21c.png&quot; width=&quot;916&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     华为主任工程师张俊怡发表了题为《升腾大模型 MindSpeed 训练加速库系列介绍》的演讲。张俊怡围绕 MindSpeed 向大家介绍训练加速库系列，深入阐释了其核心技术架构与独特优势。MindSpeed 训练加速库旨在应对当前人工智能领域对高效、快速训练日益增长的需求，通过优化算法、改进内存管理以及充分利用硬件并行计算能力等手段，显著提升了模型训练的速度与效率。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;814&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c0d7b41b6e29813fd062bffb97d3e009cf8.png&quot; width=&quot;1084&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     华为升腾生态套件项目架构师潘邵武带来题为《升腾生态开发套件，模型训推新体验》的分享。为提升升腾平台的模型开发效率，加速开发者 AI 应用创新，华为计算产品线牵头开发了 AI 应用使能套件，已适配 LLaMa-Factory 、Stable Diffusion WebUI 等开源生态套件，覆盖了微调训练、推理部署、模型评测等模型开发应用全流程。会上，潘邵武围绕升腾生态，向大家展示了 AI 应用使能套件生态全景，以及 OpenI 启智社区所开展的各类活动，希望与广大开发者共建升腾 AI 生态。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;627&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b9ffa343341260036dfd60c7ce1a2a362e.png&quot; width=&quot;921&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     迅龙软件系统开发工程师徐洋帆为大家带来题为《香橙派：开源+ AI ，探索无限可能》的分享。徐洋帆介绍，香橙派与华为升腾目前联合研发的高算力人工智能产品，包括 OrangePi Alpro、OrangePi Al Studio 等，具有强大的计算能力和高效的运算速度，能满足市场上各行各业及个人开发者对 AI 推理应用开发的需求，能让企业以更低的门槛尝试 A，推动企业的智能化升级。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;654&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aca8e06a98a5ebc243f4a2bb5fba04fd894.png&quot; width=&quot;922&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     魔乐社区负责人、天翼云专家李宝龙为大家带来题为《与魔乐一起，繁荣国产 AI 生态》的分享。魔乐社区（Modelers）是全新的人工智能社区，拥有包容的工具链体系，已托管和展示升思、DeepSpeed、AI 应用使能套件等框架或平台。他还表示，魔乐社区坚持走开源、公益的路线，免费、长期支撑应用创新。值得一提的是，魔乐社区对用户制定了成长激励计划，鼓励用户在不同领域深入学习和实践，从而实现个人和专业上的成长与发展。 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;625&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-935398b1541ccdf5c2d97900708b27e5cc9.png&quot; width=&quot;912&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     开源中国 Gitee AI 负责人彭博则为大家分享《 Gitee AI 如何在国产算力上构建 Serverless API 及其应用场景》。彭博指出，模型引擎和应用引擎已经暴露出一些问题，如模型引擎体验失败率高，应用引擎要编写跟 GPU 推理相关的代码门槛高等等。因此 Gitee AI 推出 Serverless API，直接调用 API，无须关心底层的 GPU 推理代码；同时兼容 OpenAl 接口，门槛低；体验稳定，部署简单；按次付费，价格实惠。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;685&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e2bd0c60f0082318248c3626e8197027977.png&quot; width=&quot;913&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     落到具体，情感机器（北京）科技有限公司 AI 生态负责人陈少宏则是为大家带来题为《 SwanLab+openMind 打造国产 AI 开发者工具链》的分享。他介绍，情感机器（北京）科技有限公司是一家专注于人工智能和机器学习底层工具研发的高科技企业。旗下 SwanLab 是一款专为 AI 训练设计的过程记录工具，帮助开发者发掘出最具潜力的 AI 模型，将与 AI 应用使能套件共同打造全球领先的人工智能研发工具链。 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt;
     在本次 
    &lt;strong&gt;2024 &lt;/strong&gt; 
    &lt;strong&gt;OSC&lt;/strong&gt; 
    &lt;strong&gt; 源创会年终盛典&lt;/strong&gt;的推进过程中，我们心怀无尽感激，向一路同行的赞助商、支持单位、合作伙伴们致以最诚挚的鸣谢。 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt; 
      &lt;strong&gt;赞助商及支持单位&lt;/strong&gt; 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;526&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-76342f33f173a817318980d182400389d1e.png&quot; width=&quot;904&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;div&gt; 
      &lt;strong&gt;合作伙伴&lt;/strong&gt; 
     &lt;/div&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;div&gt; 
    &lt;img height=&quot;358&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e25b48eb839592ed279e28923d77b51b260.png&quot; width=&quot;925&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
   &lt;/div&gt; 
   &lt;div&gt;
     &amp;nbsp; 
   &lt;/div&gt; 
   &lt;div&gt; 
    &lt;em&gt;&lt;strong&gt;我们明年源创会再见&lt;/strong&gt;&lt;/em&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/oschinaofficial/blog/16928110</link>
            <guid isPermaLink="false">https://my.oschina.net/oschinaofficial/blog/16928110</guid>
            <pubDate>Tue, 31 Dec 2024 06:29:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>smart-chatRoom —— 分布式简易聊天系统</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;基于 Redis/RocketMQ + SpringBoot + Vue +Websocket 实现分布式、跨服务器节点共享的分布式简易聊天系统，通过该核心实例实现了跨服务器节点无法共享 WebSocket 会话 Session，无法跨节点查询用户会话信息的痛点； 借助 Redis 实现了跨通道 WebSocket 通信，按通道进行会话交流的亮点; 借助 RocketMQ 实现高并发场景下的会话消费堆积、会话丢失问题。&lt;/span&gt;&lt;/p&gt;

&lt;p style=&quot;color:#252b3a; margin-left:0; margin-right:0; text-align:start&quot;&gt;主要亮点如下：&lt;/p&gt;

&lt;ul style=&quot;margin-left:0; margin-right:11px&quot;&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道的订阅发送，按通道实现 Session 共享&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道的消息会话隔离，保证消息交流的安全性&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 Redis 多通道消息监控、消息存储，实现离线消息的暂存&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息发布、订阅，按消息主题区分消息会话&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息分类处理，实现按标签共享 Session、消费 Session&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息离线发送，用户上线按照上次消费位点接收离线消息&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持基于 RocketMQ 中间件的消息监听，处理重复消息，实现消息发布的高效率&lt;/li&gt;
&lt;li style=&quot;list-style-type:disc&quot;&gt;支持单聊、群聊、广播、按指定通道交流&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/smart-chatroom</link>
            <guid isPermaLink="false">https://www.oschina.net/p/smart-chatroom</guid>
            <pubDate>Tue, 31 Dec 2024 06:01:00 GMT</pubDate>
        </item>
        <item>
            <title>百度 25 周年李彦宏发全员信：AI 应用将在 2025 年井喷</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 1 月 1 日是百度成立 25 周年，百度创始人李彦宏晚间发出全员信表示，「25 年来，我们始终走在技术的最前沿，始终相信技术创新才是百度的核心竞争力。」&lt;/p&gt; 
&lt;p&gt;李彦宏在信中表明了对 2025 年的期待，「虽然超级应用尚未出现，但 AI 的实际渗透率已经不低，并且将在 2025 年继续井喷式增长。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;附全员信原文：&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;各位百度同学，今天是百度成立 25 周年的日子。25 年前的今天，七个怀揣着技术改变世界的梦想的年轻人在中关村北大资源宾馆的两间小屋子里开始了一段创业旅程。中国互联网的历史从此发生了改变。今天，超过一半的中国人每月都要使用百度获取信息，找到所求，「百度」这两个原本毫无意义的汉字成了一个家喻户晓的名字。&lt;/p&gt; 
 &lt;p&gt;25 年来，我们不忘初心，风雨兼程，先后经历了 PC 互联网时代，移动互联网时代，现在已经基本进入了人工智能时代。我们从简单的网页搜索功能开始，逐步发展出了贴吧、知道、百科、地图、文库、网盘等明星产品，我们依托强大的用户基础，历时十余年的时间，逐步打造出了人工智能时代从芯片、框架到模型、应用等四层全栈技术，为中国互联网和世界 AI 领域培养了一批又一批的科学技术人员、开发者和创业者。&lt;/p&gt; 
 &lt;p&gt;25 年来，我们始终走在技术的最前沿，始终相信技术创新才是百度的核心竞争力，我们多年来一直把超过收入 20% 的资金投入到研发上，并且不遗余力地尝试把最前沿的技术产品化，让更多的人从中受益，因为我们相信只有规模化的应用才能让技术发挥它的价值，甚至近年来在人工智能方面的实践表明，重大的技术突破，颠覆式的创新往往是规模化应用的结果，而不是原因。没有万卡集群就不会有大模型的智能涌现，就不会有这次生成式 AI 的浪潮；没有数以亿计的运营公里数，无人驾驶就不可能比有人驾驶安全十倍；没有大量的 AI 原生应用的推动，国产 AI 芯片就不可能真正成熟！&lt;/p&gt; 
 &lt;p&gt;当然，走在技术的最前沿也意味着我们要冒更大的风险，要承受高于同行的失败概率，要耐得住寂寞，要忍受别人的不理解甚至白眼，要不断试错，要知道哪一天方向走错了需要迅速调整方向，重新出发，甚至要对自己的能力边界有清醒的认知，并且不断总结经验教训，以利再战！&lt;/p&gt; 
 &lt;p&gt;刚刚过去的 2024 年也是过去 25 年的一个缩影，充满了机遇和挑战，时而令人兴奋，时而令人沮丧，有些工作一直到最后一天才知道成或不成。如同过去一样，这一年我们坚定地在 AI 技术上探索创新，我们在全球首创了基于图片的检索增强技术 iRAG，大大降低了图片生成的幻觉问题；我们致力于让不会写程序的素人具备程序员的能力，为此我们发布了秒哒，这与全球主流的代码辅助生成形成鲜明的对比；我们也在大模型应用领域独树一帜，为 4000 万文库的付费用户提供无与伦比的内容创作和思想碰撞能力！&lt;/p&gt; 
 &lt;p&gt;对于 2025 年，我们充满期待。我们意识到今天的人工智能领域，竞争比任何时候都更加激烈，技术迭代的速度比以往任何时候都更快，我们面临的挑战也是前所未有的。但是我们坚信，大模型赋能的 AI 原生应用正在各行各业各种场景迅速普及，虽然超级应用尚未出现，AI 的实际渗透率已经不低，并且将在 2025 年继续井喷式增长。我们也期待，我们在 2023、2024 种下的种子能够在 2025 生根发芽，开花结果，并且不断获得市场的验证和认可。&lt;/p&gt; 
 &lt;p&gt;感谢每一位同学一直以来对百度使命的忠诚陪伴，全情投入，愿百度在未来的日子里，继续乘风破浪，勇往直前，创造更加辉煌的明天！&lt;/p&gt; 
 &lt;p&gt;Robin&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327634</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327634</guid>
            <pubDate>Tue, 31 Dec 2024 05:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>欢迎 PaliGemma 2 – 来自 Google 的新视觉语言模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;我们很高兴迎来 Google 全新的视觉语言模型 &lt;strong&gt;PaliGemma 2&lt;/strong&gt;，这是 PaliGemma 的一个新版本。与其前代产品一样，PaliGemma 2 使用强大的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fsiglip-659d5e62f0ae1a57ae0e83ba&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;SigLIP&lt;/strong&gt;&lt;/a&gt; 进行视觉处理，但在文本解码部分升级到了最新的 &lt;strong&gt;Gemma 2&lt;/strong&gt;。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;模型规模和输入分辨率&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;PaliGemma 2 提供了新的预训练模型，参数规模包括 &lt;strong&gt;3B&lt;/strong&gt; 、 &lt;strong&gt;10B&lt;/strong&gt; 和 &lt;strong&gt;28B&lt;/strong&gt;。所有模型均支持以下多种输入分辨率:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;224x224&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;448x448&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;896x896&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种多样化的组合为不同的使用场景提供了极大的灵活性，使实践者能够根据质量和效率需求之间的平衡进行选择。与之相比，上一代 PaliGemma 仅提供 &lt;strong&gt;3B&lt;/strong&gt; 版本。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;预训练和微调能力&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;这些预训练模型被设计为更容易适配下游任务。首个 PaliGemma 模型因其广泛适配性被社区用于多种任务。本次迭代引入了更高质量的预训练模型和更多选择，进一步增强了灵活性。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;DOCQI 数据集示例&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;Google 此次发布了一些基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fgoogle%2Fdocci&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;DOCCI&lt;/strong&gt;&lt;/a&gt; 数据集的微调模型，展现了长篇、细致和富有表现力的图像描述能力。这些微调模型提供 &lt;strong&gt;3B&lt;/strong&gt; 和 &lt;strong&gt;10B&lt;/strong&gt; 两个版本，支持输入分辨率 &lt;strong&gt;448x448&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;此次发布包含了所有开放的模型仓库、Transformers 框架的集成、微调脚本，以及我们基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FHuggingFaceM4%2FVQAv2&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;VQAv2 数据集&lt;/strong&gt;&lt;/a&gt; 微调的视觉问答模型演示。这些资源为用户提供了全面的工具支持，助力探索和开发更多创新应用。&lt;/p&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;资源链接&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;本次发布包括开源模型库、transformers 集成、微调脚本以及视觉问答演示。以下是相关资源链接:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fpaligemma-2-release-67500e1e1dbfdd4dee27ba48&quot; target=&quot;_blank&quot;&gt;发布合集&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;微调模型演示 Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h1_5&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;PaliGemma 2 介绍&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;PaliGemma 2 是 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fpaligemma&quot; target=&quot;_blank&quot;&gt;PaliGemma 视觉语言模型&lt;/a&gt; 的一个新迭代，由 Google 于五月发布。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 将强大的 SigLIP 图像编码器与 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fgemma2&quot; target=&quot;_blank&quot;&gt;Gemma 2&lt;/a&gt; 语言模型连接起来。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;PaliGemma2 Architecture&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054322.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;PaliGemma2 Architecture&lt;/p&gt; 
&lt;p&gt;新的模型基于 &lt;strong&gt;Gemma 2&lt;/strong&gt; 的 &lt;strong&gt;2B&lt;/strong&gt; 、&lt;strong&gt;9B&lt;/strong&gt; 和 &lt;strong&gt;27B&lt;/strong&gt; 语言模型，分别对应 &lt;strong&gt;3B&lt;/strong&gt; 、&lt;strong&gt;10B&lt;/strong&gt; 和 &lt;strong&gt;28B&lt;/strong&gt; 的 PaliGemma 2 变体。这些模型的名称考虑了紧凑图像编码器的附加参数。正如上文所述，这些模型支持三种不同的分辨率，为下游任务的微调提供了很大的灵活性。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 根据 &lt;strong&gt;Gemma 许可证&lt;/strong&gt; 分发，该许可证允许重新分发、商业使用、微调以及创建模型衍生品。&lt;/p&gt; 
&lt;p&gt;此版本包含以下基于 &lt;strong&gt;bfloat16&lt;/strong&gt; 精度的检查点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;9 个预训练模型&lt;/strong&gt;: 3B、10B 和 28B，分辨率支持&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;224x224&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;448x448&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;896x896&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;2 个在 DOCCI 数据集上的微调模型&lt;/strong&gt;: 基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fgoogle%2Fdocci&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;DOCCI&lt;/strong&gt;&lt;/a&gt; 数据集 (图像-文本配对)，支持 &lt;strong&gt;3B&lt;/strong&gt; 和 &lt;strong&gt;10B&lt;/strong&gt; 的 PaliGemma 2 变体，输入分辨率为 &lt;strong&gt;448x448&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;模型能力&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;如同之前的 PaliGemma 发布一样，预训练 (pt) 模型在下游任务的微调中表现出色。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;预训练数据集&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;pt 模型在以下数据混合集上进行了预训练。这些多样化的预训练数据集使模型能够在相似领域的下游任务中使用更少的示例进行微调。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WebLI&lt;/strong&gt;: 一个基于公共网络构建的大规模多语言图像 - 文本数据集。WebLI 数据集的多样化分割使模型具备了多方面的能力，如视觉语义理解、物体定位、视觉文本理解和多语言能力。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CC3M-35L&lt;/strong&gt;: 从网页上精心挑选的英语图像 - 替代文本数据集 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faclanthology.org%2FP18-1238%2F&quot; target=&quot;_blank&quot;&gt;Sharma et al., 2018&lt;/a&gt;)。数据集的标签通过 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcloud.google.com%2Ftranslate&quot; target=&quot;_blank&quot;&gt;Google Cloud Translation API&lt;/a&gt; 翻译成了 34 种额外的语言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Visual Question Generation with Question Answering Validation (VQ2A)&lt;/strong&gt;: 一个改进的问题回答数据集。该数据集也被翻译成了相同的 34 种语言，使用了 Google Cloud Translation API。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenImages&lt;/strong&gt;: 检测和物体感知的问答数据集 (Piergiovanni et al., 2022)，通过手动规则生成，基于 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.googleapis.com%2Fopenimages%2Fweb%2Ffactsfigures_v7.html&quot; target=&quot;_blank&quot;&gt;OpenImages 数据集&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WIT&lt;/strong&gt;: 从 Wikipedia 收集的图像和文本数据集 (Srinivasan et al., 2021)。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;微调模型与基准测试&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;PaliGemma 2 团队在多种视觉语言理解任务上对 PT 模型进行了内部微调，并提供了这些微调模型的基准测试结果。详细信息可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fgoogle%2Fpaligemma2-28b-pt-896%23paligemma-2-results-by-model-resolution-and-size&quot; target=&quot;_blank&quot;&gt;模型卡&lt;/a&gt; 和 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt; 中找到。&lt;/p&gt; 
&lt;p&gt;PaliGemma 2 基于 &lt;strong&gt;DOCQI 数据集&lt;/strong&gt; 微调，可以实现多种图像描述任务，包括文本渲染、捕捉空间关系以及包含世界知识的描述。&lt;/p&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;性能比较&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;以下表格展示了 DOCQI 微调模型与其他模型的性能对比 (数据来自 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt; 中的 Table 6):&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;参数量&lt;/th&gt; 
   &lt;th&gt;字符数 (#char)&lt;/th&gt; 
   &lt;th&gt;句子数 (#sent)&lt;/th&gt; 
   &lt;th&gt;NES ↓&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniGPT-4&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;484&lt;/td&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;52.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mPLUG-Owl2&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;459&lt;/td&gt; 
   &lt;td&gt;4.4&lt;/td&gt; 
   &lt;td&gt;48.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;InstructBLIP&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;510&lt;/td&gt; 
   &lt;td&gt;4.0&lt;/td&gt; 
   &lt;td&gt;42.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLAVA-1.5&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;395&lt;/td&gt; 
   &lt;td&gt;4.2&lt;/td&gt; 
   &lt;td&gt;40.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VILA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;871&lt;/td&gt; 
   &lt;td&gt;8.6&lt;/td&gt; 
   &lt;td&gt;28.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PaliGemma&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;535&lt;/td&gt; 
   &lt;td&gt;8.9&lt;/td&gt; 
   &lt;td&gt;34.3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PaLI-5B&lt;/td&gt; 
   &lt;td&gt;5B&lt;/td&gt; 
   &lt;td&gt;1065&lt;/td&gt; 
   &lt;td&gt;11.3&lt;/td&gt; 
   &lt;td&gt;32.9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PaliGemma 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;529&lt;/td&gt; 
   &lt;td&gt;7.7&lt;/td&gt; 
   &lt;td&gt;28.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PaliGemma 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10B&lt;/td&gt; 
   &lt;td&gt;521&lt;/td&gt; 
   &lt;td&gt;7.5&lt;/td&gt; 
   &lt;td&gt;20.3&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;span id=&quot;OSC_h3_10&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;span&gt;指标说明:&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;#char&lt;/strong&gt;: 生成的描述中平均字符数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;#sent&lt;/strong&gt;: 平均句子数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;NES&lt;/strong&gt;: 非蕴含句子数 (数值越低越好)，用于衡量事实不准确性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;您可以在下面找到 DOCQI 检查点的部分模型输出，展示模型的多样性和灵活性。&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Input Image&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Caption&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 1&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054547.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;折线图展示了 ImageNet 模型在微调后的 Top-1 准确率表现。图中有四条不同颜色的线条: 蓝色、橙色、绿色和黑色。&lt;strong&gt;蓝色线条是四条线中最低的一条&lt;/strong&gt; ，它代表了表现最差的模型结果。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 2&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180054606.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一张白纸的特写镜头，上面用黑色的文字打印着内容。纸张中间稍微弯曲，文字使用打字机字体呈现。纸张顶部写着 &quot;&lt;strong&gt;Ashley Hotel West Coast&lt;/strong&gt;&quot;，其下是 &quot;&lt;strong&gt;WiFi Internet Service&lt;/strong&gt;&quot;。再下面是 &quot;&lt;strong&gt;Username: fqpp&lt;/strong&gt;&quot;，最后是 &quot;&lt;strong&gt;Password: aaeu&lt;/strong&gt;&quot;。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 3&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055484.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一幅描绘大衞·鲍伊「Ziggy Stardust」造型的壁画被画在一面白墙上。壁画展示了三张并排的面孔，每张都有红色的头发，眼睛上画着蓝色的闪电图案。面孔的妆容包括蓝色眼影、粉红色腮红和红色嘴唇。中间的面孔上方有一个黑色的方形窗口，窗口内用白色文字写着 &quot;&lt;strong&gt;JAM&lt;/strong&gt;&quot;，字体为蓝色。画面的一侧停着一辆银色汽车。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 4&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055346.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;从上方俯瞰一张白色大理石台面，枱面上放着四个咖啡杯。左边有两个灰色的杯子，左下角有一个白色的杯子，右侧则是另一个灰色的杯子。右上角放着一个带木质底座的金属水果篮，里面装满了橙子。左边还有一个装有水的透明玻璃水壶，画面中仅显示了部分内容。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img alt=&quot;Image 5&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180055610.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;一张白色书本的特写，上半部分是白色区域，底部有一条蓝色条纹。白色部分印有黑色文字，内容为: &quot;&lt;strong&gt;Visual Concept Learning from User-tagged Web Video&lt;/strong&gt;&quot; 。黑色文字下方有一个白色框，框内包含五张小图片。最左边的图片是一名站在草地中的人，右侧紧接的是一张蓝色海洋的图片。&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;演示&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;为了演示效果，Hugging Face 团队对 &lt;strong&gt;PaliGemma 2 3B&lt;/strong&gt; 模型进行了微调，输入分辨率为 448x448，数据集使用的是 &lt;strong&gt;VQAv2&lt;/strong&gt; 的一小部分。我们采用了 &lt;strong&gt;LoRA 微调&lt;/strong&gt; 和 &lt;strong&gt;PEFT&lt;/strong&gt; 方法，具体细节将在微调部分进行讲解。&lt;/p&gt; 
&lt;p&gt;下面的演示展示了最终结果。您可以自由查看 Space 中的代码了解其工作原理，或者克隆代码以适配您的自定义微调需求。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://eastwind-cdn.dongs.xyz/image/202412180057439.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_12&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;如何与 Transformers 一起使用&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;您可以使用 🤗 Transformers 库对 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 模型进行推理，通过 &lt;strong&gt;PaliGemmaForConditionalGeneration&lt;/strong&gt; 和 &lt;strong&gt;AutoProcessor&lt;/strong&gt; APIs 实现操作。请确保您安装的 Transformers 版本为 &lt;strong&gt;4.47 或更高&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip&amp;nbsp;install&amp;nbsp;transformers&amp;gt;=4.47
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在安装完成后，您可以按照以下示例运行推理。同样重要的是，请确保遵循用于训练模型的任务提示格式，以获得最佳效果:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt;&amp;nbsp;transformers&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;AutoProcessor,&amp;nbsp;PaliGemmaForConditionalGeneration
&lt;span&gt;from&lt;/span&gt;&amp;nbsp;PIL&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;Image
&lt;span&gt;import&lt;/span&gt;&amp;nbsp;requests

model_id&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;google/paligemma2-10b-ft-docci-448&quot;&lt;/span&gt;
model&amp;nbsp;=&amp;nbsp;PaliGemmaForConditionalGeneration.from_pretrained(model_id)
model&amp;nbsp;=&amp;nbsp;model.to(&lt;span&gt;&quot;cuda&quot;&lt;/span&gt;)
processor&amp;nbsp;=&amp;nbsp;AutoProcessor.from_pretrained(model_id)

prompt&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;&amp;lt;image&amp;gt;caption&amp;nbsp;en&quot;&lt;/span&gt;
image_file&amp;nbsp;=&amp;nbsp;&lt;span&gt;&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.png&quot;&lt;/span&gt;
raw_image&amp;nbsp;=&amp;nbsp;Image.open(requests.get(image_file,&amp;nbsp;stream=&lt;span&gt;True&lt;/span&gt;).raw).convert(&lt;span&gt;&quot;RGB&quot;&lt;/span&gt;)

inputs&amp;nbsp;=&amp;nbsp;processor(prompt,&amp;nbsp;raw_image,&amp;nbsp;return_tensors=&lt;span&gt;&quot;pt&quot;&lt;/span&gt;).to(&lt;span&gt;&quot;cuda&quot;&lt;/span&gt;)
output&amp;nbsp;=&amp;nbsp;model.generate(**inputs,&amp;nbsp;max_new_tokens=&lt;span&gt;200&lt;/span&gt;)

input_len&amp;nbsp;=&amp;nbsp;inputs[&lt;span&gt;&quot;input_ids&quot;&lt;/span&gt;].shape[&lt;span&gt;-1&lt;/span&gt;]
print(processor.decode(output[&lt;span&gt;0&lt;/span&gt;][input_len:],&amp;nbsp;skip_special_tokens=&lt;span&gt;True&lt;/span&gt;))
&lt;span&gt;#&amp;nbsp;A&amp;nbsp;medium&amp;nbsp;shot&amp;nbsp;of&amp;nbsp;two&amp;nbsp;cats&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;a&amp;nbsp;pile&amp;nbsp;of&amp;nbsp;brown&amp;nbsp;fishing&amp;nbsp;nets.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;in&amp;nbsp;the&amp;nbsp;foreground&amp;nbsp;is&amp;nbsp;a&amp;nbsp;gray&amp;nbsp;tabby&amp;nbsp;cat&amp;nbsp;with&amp;nbsp;white&amp;nbsp;on&amp;nbsp;its&amp;nbsp;chest&amp;nbsp;and&amp;nbsp;paws.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;is&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;its&amp;nbsp;side&amp;nbsp;with&amp;nbsp;its&amp;nbsp;head&amp;nbsp;facing&amp;nbsp;the&amp;nbsp;bottom&amp;nbsp;right&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&amp;nbsp;The&amp;nbsp;cat&amp;nbsp;in&amp;nbsp;the&amp;nbsp;background&amp;nbsp;is&amp;nbsp;laying&amp;nbsp;on&amp;nbsp;its&amp;nbsp;side&amp;nbsp;with&amp;nbsp;its&amp;nbsp;head&amp;nbsp;facing&amp;nbsp;the&amp;nbsp;top&amp;nbsp;left&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&amp;nbsp;The&amp;nbsp;cat&#39;s&amp;nbsp;body&amp;nbsp;is&amp;nbsp;curled&amp;nbsp;up,&amp;nbsp;its&amp;nbsp;head&amp;nbsp;is&amp;nbsp;slightly&amp;nbsp;turned&amp;nbsp;to&amp;nbsp;the&amp;nbsp;right,&amp;nbsp;and&amp;nbsp;its&amp;nbsp;front&amp;nbsp;paws&amp;nbsp;are&amp;nbsp;tucked&amp;nbsp;underneath&amp;nbsp;its&amp;nbsp;body.&amp;nbsp;There&amp;nbsp;is&amp;nbsp;a&amp;nbsp;teal&amp;nbsp;rope&amp;nbsp;hanging&amp;nbsp;from&amp;nbsp;the&amp;nbsp;fishing&amp;nbsp;net&amp;nbsp;in&amp;nbsp;the&amp;nbsp;top&amp;nbsp;right&amp;nbsp;corner&amp;nbsp;of&amp;nbsp;the&amp;nbsp;image.&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;您还可以使用 transformers 集成中的 &lt;strong&gt;&lt;code&gt;bitsandbytes&lt;/code&gt;&lt;/strong&gt; 来加载具有量化的模型。以下示例使用了 &lt;strong&gt;4-bit &lt;code&gt;nf4&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt;&amp;nbsp;transformers&amp;nbsp;&lt;span&gt;import&lt;/span&gt;&amp;nbsp;BitsAndBytesConfig

bnb_config&amp;nbsp;=&amp;nbsp;BitsAndBytesConfig(
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;load_in_4bit=&lt;span&gt;True&lt;/span&gt;,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;bnb_4bit_quant_type=&lt;span&gt;&quot;nf4&quot;&lt;/span&gt;,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;bnb_4bit_compute_dtype=torch.bfloat16
)
model&amp;nbsp;=&amp;nbsp;PaligemmaForConditionalGeneration.from_pretrained(
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;model_id,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;quantization_config=bnb_config,
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;device_map={&lt;span&gt;&quot;&quot;&lt;/span&gt;:&lt;span&gt;0&lt;/span&gt;}
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;我们快速测试了量化对性能的影响，通过评估一个 3B 微调检查点在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Flmms-lab%2Ftextvqa&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;textvqa&lt;/strong&gt;&lt;/a&gt; 数据集上的表现，使用 224x224 输入图像。这是我们在 5,000 个验证集条目上获得的结果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;bfloat16&lt;/strong&gt;，无量化: &lt;strong&gt;60.04%&lt;/strong&gt; 准确率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;8-bit&lt;/strong&gt;: **59.78%**。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;4-bit&lt;/strong&gt;，使用上面代码片段中的配置: **58.72%**。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些结果非常鼓舞人心！当然，量化对于更大的检查点更有意义，我们建议您始终在您所使用的领域和任务上测量结果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;微调&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;如果您之前已经微调过 &lt;strong&gt;PaliGemma&lt;/strong&gt;，那么用于微调 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 的 API 是相同的，您可以直接使用现有代码。我们提供了 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2Fpaligemma.py&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt; 和一个 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;notebook&lt;/a&gt; 来帮助您微调模型，冻结模型部分参数，或应用内存高效的微调技术，如 &lt;strong&gt;LoRA&lt;/strong&gt; 或 &lt;strong&gt;QLoRA&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;我们使用 &lt;strong&gt;LoRA&lt;/strong&gt; 对 PaliGemma 2 模型在 VQAv2 验证集的一半进行了微调，以供演示。这项任务使用了 &lt;strong&gt;3 块 A100&lt;/strong&gt; 显卡 (80GB VRAM)，耗时半小时。&lt;/p&gt; 
&lt;p&gt;您可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmerve%2Fpaligemma2-3b-vqav2&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt; 找到模型，此外 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;这个 Gradio 演示&lt;/a&gt; 展示了模型的效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_14&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/h1&gt; 
&lt;p&gt;新发布的 &lt;strong&gt;PaliGemma 2&lt;/strong&gt; 比之前的版本更加令人兴奋，具有不同的规模以满足各种需求，并提供更强大的预训练模型。我们期待看到社区能够构建出什么样的成果！&lt;/p&gt; 
&lt;p&gt;我们感谢 Google 团队发布了这一令人惊叹且开放的模型系列。特别感谢 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FMolbap&quot; target=&quot;_blank&quot;&gt;Pablo Montalvo&lt;/a&gt; 将模型集成到 Transformers 中，以及 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Flysandre&quot; target=&quot;_blank&quot;&gt;Lysandre&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FRaushanTurganbay&quot; target=&quot;_blank&quot;&gt;Raushan&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FArthurZ&quot; target=&quot;_blank&quot;&gt;Arthur&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fydshieh&quot; target=&quot;_blank&quot;&gt;Yieh-Dar&lt;/a&gt; 和团队其他成员的努力，他们迅速完成了模型的评审、测试和合并工作。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_15&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span&gt;资源&lt;/span&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Fgoogle%2Fpaligemma-2-release-67500e1e1dbfdd4dee27ba48&quot; target=&quot;_blank&quot;&gt;发布合集&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fblog%2Fpaligemma&quot; target=&quot;_blank&quot;&gt;PaliGemma 博客文章&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmerveenoyan%2Fsmol-vision%2Fblob%2Fmain%2FFine_tune_PaliGemma.ipynb&quot; target=&quot;_blank&quot;&gt;微调脚本&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmerve%2Fpaligemma2-3b-vqav2&quot; target=&quot;_blank&quot;&gt;在 VQAv2 上微调模型&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fmerve%2Fpaligemma2-vqav2&quot; target=&quot;_blank&quot;&gt;微调模型演示&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fpapers%2F2412.03555&quot; target=&quot;_blank&quot;&gt;技术报告&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;英文原文: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf.co%2Fblog%2Fpaligemma2&quot; target=&quot;_blank&quot;&gt;https://hf.co/blog/paligemma2&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;原文作者: Merve Noyan, Andreas P. Steiner, Pedro Cuenca, Aritra Roy Gosthipaty&lt;/p&gt; 
 &lt;p&gt;译者: xiaodouzi666&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/HuggingFace/blog/17019541</link>
            <guid isPermaLink="false">https://my.oschina.net/HuggingFace/blog/17019541</guid>
            <pubDate>Tue, 31 Dec 2024 05:39:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>IBM 收购 HashiCorp 交易面临英国反垄断审查</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2024%2F12%2F30%2Fuk-antitrust-watchdog-launches-review-of-ibms-hashicorp-takeover%2F&quot; target=&quot;_blank&quot;&gt;据 TechCrunch 报道&lt;/a&gt;，英国反垄断监督机构竞争与市场管理局（CMA）已开始调查 IBM 计划收购云软件厂商 HashiCorp 是否会影响竞争。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-699fccb664555c8767ef7615467cd7deac2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;CMA 周一表示，它将在 1 月 16 日前邀请有关各方就这一并购发表评论。该监管机构暂定 2 月 25 日为最后期限，以决定是批准该交易还是将其提交进一步审查。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;IBM 于今年 4 月宣布同意以约 64 亿美元的价格收购 HashiCorp。如果收购继续进行，将扩大 IBM 在云计算和人工智能领域的推进力度，并让该公司获得 HashiCorp 约 4400 家客户的名册。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;CMA 于 8 月通知 HashiCorp 将对合并进行审查。美国联邦贸易委员会也在调查这一交易。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/289379/ibm-acquire-hashicorp-6-4-billion&quot; target=&quot;news&quot;&gt;IBM 以 64 亿美元收购 HashiCorp&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327615/ibms-acquire-hashicorp-takeover-faces-uk-antitrust-scrutiny</guid>
            <pubDate>Tue, 31 Dec 2024 03:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>一个大模型需要多大 GPU 内存才能跑起来的计算公式</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;一个大模型需要多大 GPU 内存才能跑起来的计算公式： M = &amp;nbsp;((P * 4B) / (32 / Q) &amp;nbsp;) * 1.2&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;M: 所需的 GPU 显存，单位是 GB。&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;P: 模型的参数数量。例如，7B 模型有 70 亿个参数。&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;4B: 每个参数占用的字节数，这里假设每个参数占用 4 个字节（通常指 FP32 或 Float32 格式）。&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;32: 4 个字节等于 32 位。&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;Q: 加载模型时使用的位数。例如，16 位 (FP16/BF16)，8 位 (INT8) 或 4 位 (INT4)。这通常称为量化。&lt;/li&gt; 
 &lt;li style=&quot;color: rgb(51, 51, 51); margin-left: 0px; margin-right: 0px; text-align: left;&quot;&gt;1.2: 表示额外开销的系数，通常为 20%。这考虑了除了模型权重之外还需要加载到 GPU 显存中的其他数据，例如优化器状态、梯度等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;如使用 FP16 量化加载 Llama 70B 模型，计算过程就是&lt;br&gt; &lt;strong&gt;M = &amp;nbsp;( (70,000,000,000 * 4) / (32 / 16) &amp;nbsp;)* 1.2 = 168 GB&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ecd94df1c281b114f9cbb19306dc7f358e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;——&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F2194035935%2FP6DrHa8Ob&quot; target=&quot;_blank&quot;&gt;蚁工厂&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327612</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327612</guid>
            <pubDate>Tue, 31 Dec 2024 03:53:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>X.Org Server 的代码提交次数创 10 年新高</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;根据 X.Org Server 的&amp;nbsp;&lt;/a&gt;&lt;span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;Git 提交记录&lt;/a&gt;，在刚刚过去的 2024 年，&lt;/span&gt;X.Org Server 的代码&lt;span&gt;提交次数达到了 2014 年以来的最高峰。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;虽然提交次数比前几年多了不少，但这并不意味着 &lt;/span&gt;X.Org Server&amp;nbsp;&lt;span&gt;的复兴，因为 Wayland 仍在 Linux 桌面上占据主导地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d93cec2031e1ac95173fc30bde92b9e8801.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据统计，X.Org Server 去年有 708 次提交... 比起 2018 年的 535 次提交（每年 200~300 次）要多得多。但即使是在 2010 年代中期，Wayland 还在积极开发的时候，每年也只有 400~500 次提交... 在 2024 年之前，提交次数最多的是 2014 年，当时有 952 次提交。&lt;/p&gt; 
&lt;p&gt;按行数计算，2024 年 X.Org Server 新增了 11998 行代码，删除了 14680 行代码。这比近几年每年 X.Org Server 代码库中通常 5-6 千行代码的变化要多。但仍远低于 X.Org Server 积极开发的 2000 年代更高的代码更新量。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a555233d997eb149ec68424bd0390abacf2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;2024 年的 X.Org Server 之所以如此活跃主要有两个原因。&lt;/p&gt; 
&lt;p&gt;首先，X.Org Server 中的 XWayland 代码仍在继续积极开发，用于支持新的 Wayland 协议和其他修复/添加内容... XWayland 是 X.Org Server 中继续开发新功能的主要领域，也是唯一的领域。&lt;/p&gt; 
&lt;p&gt;另一个原因是开源开发者 Enrico Weigelt。&lt;/p&gt; 
&lt;p&gt;Enrico Weigelt 主要负责 X.Org Server 的修复和改进工作，围绕 X.Org Server 的测试和更好的 CI BSD 覆盖范围。在红帽或英特尔等主要厂商都没有投资 X.Org Server 开发的情况下，Enrico 几乎是单枪匹马地完成了一些 X.Org Server 修复和其他小功能工作。&lt;/p&gt; 
&lt;p&gt;Enrico Weigelt 负责了今年 X.Org Server&amp;nbsp; 63% 的&amp;nbsp;&lt;span&gt;Git 提交... 其他活跃的开发者包括 Olivier Fourdan、Michel Dänzer、Alan Coopersmith、Peter Hutterer 和 Erik Kurzinger，他们大多只关注 XWayland 的改进/修正。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;除此之外，去年 X.Org Server 的许多提交都是为了安全修复。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b87e1a0baefae75b023d31ef6fe6bafe102.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0102/111918_vgsn_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;就代码行数而言，X.Org Server 多年来基本处于停滞状态，唯一的主要功能工作是围绕 XWayland 进行的。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.phoronix.com%2Fmisc%2Fxserver-eoy-2024%2Findex.html&quot; target=&quot;_blank&quot;&gt;点此查看 X.Org Server 的更多 GitStats 数据&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327607/xorg-server-2024-gitstats</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327607/xorg-server-2024-gitstats</guid>
            <pubDate>Tue, 31 Dec 2024 03:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Star 超 9 k，AI 小白也能玩转企业 LLM 应用开发</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;现在大模型 workflow 产品有很多，比如 BISHENG 、MaxKB、Dify、FastGPT、RagFlow 等等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;其中，毕昇 BISHENG 是一个开源的&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;大模型应用开发平台，专门&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;面向企业场景，具备高精度文档解析 ETL4LLM 能力。自去年 8 月份开源以来， GitHub 上的 Star 数已经超过 9k 了。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;对于 AI 小白来说，毕昇 BISHENG &lt;/span&gt;平台也很友好。&lt;/strong&gt;因为平台上有很多现成的模板，开发一个大模型应用简直不要太简单！编程、开发测试、合同审核、招投标、高级翻译、会议纪要等等，只需要根据自己需求，调整参数就能用。全程都是可视化界面操作。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;788&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6995a9ece3a8a4f407abd152f1b17f921d.png&quot; width=&quot;1015&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;1 月 3 日，OSCHINA 开源中国将邀请 BISHENG 产品负责人鲁力，做客直播栏目《开源项目老牌与新秀》第 3 期，分享其对 BISHENG—— 大模型 workflow 产品设计思考、技术方案。谈一谈它，与 Dify、Coze 有什么差异。同时，还将分享他在企业大模型应用落地过程中踩过的那些坑。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;本次直播中有一个重点环节，就是实操演示 —— 手把手教你怎么用 BISHENG 搭建各种大模型应用，例如合同审核、报告生成等。想体验的小伙伴可以点击链接：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbisheng.dataelem.com%2F&quot; target=&quot;_blank&quot;&gt;https://bisheng.dataelem.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;微信扫码，赶紧预约直播吧~&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;2388&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d72821bf78b0b3f33f49b2d818702279e20.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了诸多社区或组织的大力支持，在此特别表示感谢：&lt;/strong&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:left&quot;&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前，Gitee 已经有超过 1200 万名开发者，累计托管超过 2800 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 30 万家企业。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;渠成开源社区&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;渠成开源社区由禅道项目管理软件团队发起，社区的经营主体为青岛渠成开源计算机网络技术研究中心，是非营利性社会服务活动的社会组织。 渠成开源社区主要面向一线开源软件生产者、贡献者、组织者、赞助商和用户，以解决具体实际问题为宗旨，旨在打造以开源软件为核心纽带的开源生态系统，真正做到让每一个优秀的开源软件都能实现商业化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.qucheng.cc&quot; target=&quot;_blank&quot;&gt;www.qucheng.cc&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源项目老牌与新秀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是开源中国 OSCHINA 推出的一档直播栏目，旨在为开源项目提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请开源项目的作者、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的开源项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/16971110</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/16971110</guid>
            <pubDate>Tue, 31 Dec 2024 03:09:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>Altman 公布 OpenAI 2025 年将发布的技术产品</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;OpenAI 首席执行官萨姆·奥特曼（Sam Altman）发帖公布了该公司 2025 年即将发布的技术产品，分别是：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;AGI（通用人工智能）、Agents（智能体）、更好的 GPT-4o 升级版、更好的记忆存储、更长的上下文窗口、「Grow up mode」（成人模式）、深度研究特色功能、更好的 Sora 以及更好的个性化定制。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;418&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8b88947df326c888e90ad352129eac9d6b6.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327323</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327323</guid>
            <pubDate>Tue, 31 Dec 2024 03:09:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>用 BISHENG 构建企业 LLM 应用，简直不要太简单！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;现在大模型 workflow 产品有很多，比如 BISHENG 、MaxKB、Dify、FastGPT、RagFlow 等等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;其中，毕昇 BISHENG 是一个开源的&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#40485b&quot;&gt;大模型应用开发平台，专门&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;面向企业场景，具备高精度文档解析 ETL4LLM 能力。自去年 8 月份开源以来， GitHub 上的 Star 数已经超过 9k 了。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff; color:#333333&quot;&gt;对于 AI 小白来说，毕昇 BISHENG &lt;/span&gt;平台也很友好。&lt;/strong&gt;因为平台上有很多现成的模板，开发一个大模型应用简直不要太简单！编程、开发测试、合同审核、招投标、高级翻译、会议纪要等等，只需要根据自己需求，调整参数就能用。全程都是可视化界面操作。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;788&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f6995a9ece3a8a4f407abd152f1b17f921d.png&quot; width=&quot;1015&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;1 月 3 日，OSCHINA 开源中国将邀请 BISHENG 产品负责人鲁力，做客直播栏目《开源项目老牌与新秀》第 3 期，分享其对 BISHENG—— 大模型 workflow 产品设计思考、技术方案。谈一谈它，与 Dify、Coze 有什么差异。同时，还将分享他在企业大模型应用落地过程中踩过的那些坑。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;本次直播中有一个重点环节，就是实操演示 —— 手把手教你怎么用 BISHENG 搭建各种大模型应用，例如合同审核、报告生成等。想体验的小伙伴可以点击链接：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbisheng.dataelem.com%2F&quot; target=&quot;_blank&quot;&gt;https://bisheng.dataelem.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;微信扫码，赶紧预约直播吧~&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;2388&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d72821bf78b0b3f33f49b2d818702279e20.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;另外，本次直播得到了诸多社区或组织的大力支持，在此特别表示感谢：&lt;/strong&gt;&lt;/p&gt; 
&lt;div style=&quot;text-align:left&quot;&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;目前，Gitee 已经有超过 1200 万名开发者，累计托管超过 2800 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 30 万家企业。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;渠成开源社区&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;渠成开源社区由禅道项目管理软件团队发起，社区的经营主体为青岛渠成开源计算机网络技术研究中心，是非营利性社会服务活动的社会组织。 渠成开源社区主要面向一线开源软件生产者、贡献者、组织者、赞助商和用户，以解决具体实际问题为宗旨，旨在打造以开源软件为核心纽带的开源生态系统，真正做到让每一个优秀的开源软件都能实现商业化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span&gt;&lt;span&gt;官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=http%3A%2F%2Fwww.qucheng.cc&quot; target=&quot;_blank&quot;&gt;www.qucheng.cc&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;开源项目老牌与新秀&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是开源中国 OSCHINA 推出的一档直播栏目，旨在为开源项目提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请开源项目的作者、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的开源项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeeec97bc896bc61c715698bd6acc1f83b3.jpg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/16971110</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/16971110</guid>
            <pubDate>Tue, 31 Dec 2024 02:55:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>1 月 18 北京源创会，看 2025 如何加速技术开发</title>
            <description></description>
            <link>https://www.oschina.net/event/2407669</link>
            <guid isPermaLink="false">https://www.oschina.net/event/2407669</guid>
            <pubDate>Tue, 31 Dec 2024 02:54:00 GMT</pubDate>
        </item>
        <item>
            <title>另辟蹊径打造高精度的 VL 文字提取工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;一、应用场景：设备铭牌识别环境&lt;/h2&gt; 
&lt;p&gt;在工业和医疗等领域的设备管理中，设备铭牌的信息提取是一项常见但极具挑战性的任务。这些铭牌通常包含关键信息如型号、序列号、制造日期等，对于资产管理、维护记录和故障排除至关重要。然而，实际拍摄的照片往往存在以下难题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;角度与透视问题&lt;/strong&gt;：由于拍摄角度各异，上传的照片中设备铭牌可能出现严重的透视变形，导致文字倾斜或扭曲。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;光线与反射干扰&lt;/strong&gt;：现场光线条件复杂，强光反射或阴影遮挡使得铭牌上的文字难以清晰辨认。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;背景杂乱&lt;/strong&gt;：周围环境复杂，背景中的其他物体可能干扰文本区域的识别。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这些问题直接使用视觉语言（VL）模型进行识别时，会导致极低的准确率和可靠性。为了解决这些问题，最近和 Gitee AI 团队进行了深度友好的沟通，最终得到了一套完整的解决方案，通过 UVDoc 图像校正工具预处理图片，再利用 QwenVL 进行信息识别，并最终使用大型语言模型（LLM）实现结构化数据提取，显著提升了铭牌文字的提取效果。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f0fe8c7dbf79cea800ebd5fd45eacd503ea.jpg&quot; width=&quot;250&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c0a5b16fd9f82586a0a5e5b09bb17c64735.jpg&quot; width=&quot;141&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;img alt=&quot;&quot; height=&quot;202&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f047384ddb6dfa3a43fd16be34037953c4.jpg&quot; width=&quot;269&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;二、技术方法&lt;/h2&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;1. UVDoc 图像校正工具：提升输入质量&lt;/h3&gt; 
&lt;p&gt;针对上述难题，我们首先采用 GiteeAI 团队最新发布的&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=UVDoc&quot; rel=&quot;nofollow&quot;&gt;UVDoc 图像校正工具&lt;/a&gt;对原始照片进行预处理。该工具利用先进的计算机视觉算法，自动检测并纠正图像中的透视变形，恢复铭牌的真实形状。同时，它还可以调整图像的亮度和对比度，减少光线和反射带来的干扰。经过 UVDoc 校正后的图像不仅提高了文本的可读性，还为后续的文字识别提供了更佳的基础。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=UVDoc&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=UVDoc&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;2. QwenVL：强大的信息识别引擎&lt;/h3&gt; 
&lt;p&gt;完成图像预处理后，接下来是关键的信息识别阶段。我们选择了 QwenVL 作为核心识别引擎，其融合了最新的视觉语言模型技术，能够在复杂背景条件下精准定位并识别出文本内容。QwenVL 不仅可以处理常规印刷体文字，还能应对手写体以及多种语言混合的情况，极大地拓宽了应用范围。此外，QwenVL 还支持多模态输入，可以同时解析图像中的其他非文本元素，如图标、表格等，为用户提供更加全面的信息提取服务。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen2-VL-72B&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen2-VL-72B&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;3. LLM 结构化数据提取：智能化处理结果&lt;/h3&gt; 
&lt;p&gt;最后一步是将 QwenVL 输出的结果进一步转化为结构化的数据格式。这一步骤依赖于 Qwen2.5-72B-Instruct，它具备强大的自然语言理解能力，可以从非结构化的文本中抽取出有价值的结构化信息。例如，在设备铭牌识别场景中，Qwen2.5-72B-Instruct 可以自动识别并分类不同的字段，如型号、序列号、制造日期等；同时生成易于检索和分析的结构化数据，极大地方便了后续的数据管理和应用。&lt;br&gt; 地址：&lt;a href=&quot;https://ai.gitee.com/serverless-api?model=Qwen2.5-72B-Instruct&quot; rel=&quot;nofollow&quot;&gt;https://ai.gitee.com/serverless-api?model=Qwen2.5-72B-Instruct&lt;/a&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;三、结果展示&lt;/h2&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;957&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e1ac616d8505ee8718c66b5aa216a66688f.png&quot; width=&quot;1370&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了验证我们的方案的有效性，我们进行了实验，共同处理了 30 张具有不同角度和光线条件的设备铭牌照片。实验分为两组：一组直接使用 QwenVL 进行识别（直接 VL 组），另一组先使用 UVDoc 工具预处理后再使用 QwenVL 识别（联合处理组）。以下是两组的数据对比及更深入的统计分析：&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_7&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;（一）数据对比表&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;识别情况&lt;/th&gt; 
   &lt;th&gt;直接 VL 组 (张)&lt;/th&gt; 
   &lt;th&gt;联合处理组 (张)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;正确识别&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;部分识别&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;完全不能识别&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;总计&lt;/td&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;30&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;span id=&quot;OSC_h3_8&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;（二）进一步统计分析&lt;/h3&gt; 
&lt;p&gt;最近我在做科研项目，所以简单按照科研项目的分析逻辑做了一下进一步的数据分析，相关内容就截图了。&lt;/p&gt; 
&lt;span id=&quot;OSC_h4_9&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;1. 准确率提升&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;正确识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：8/30 = 26.7%&lt;/li&gt; 
   &lt;li&gt;联合处理组：28/30 = 93.3%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;部分识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：12/30 = 40%&lt;/li&gt; 
   &lt;li&gt;联合处理组：2/30 = 6.7%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;完全不能识别率&lt;/strong&gt;：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;直接 VL 组：10/30 = 33.3%&lt;/li&gt; 
   &lt;li&gt;联合处理组：0/30= 0%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h4_10&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;2. 平均准确度&lt;/h4&gt; 
&lt;p&gt;平均准确度定义为每个样本被正确识别的比例。计算方法如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-196c8ee868b55cd221c9cb66160298a7693.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;直接 VL 组平均准确度：8/30 = 26.7%&lt;/li&gt; 
 &lt;li&gt;联合处理组平均准确度：28/30 = 93.3%&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id=&quot;OSC_h4_11&quot;&gt;&lt;/span&gt; 
&lt;h4&gt;3. Kappa 系数（Cohen&#39;s Kappa）&lt;/h4&gt; 
&lt;p&gt;Kappa 系数用于衡量分类系统的可靠性，考虑了偶然一致性。其公式为：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f2688c169d186ec03283ab51948f08da1ec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Kappa 系数表明联合处理组的一致性远高于直接 VL 组，说明前者在实际应用中更为可靠。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_12&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;四、结论&lt;/h3&gt; 
&lt;p&gt;从以上数据分析可以看出，联合处理组的表现显著优于直接 VL 组：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;准确性大幅提升&lt;/strong&gt;：联合处理组的正确识别率从 26.7% 提高到了 93.3%，几乎达到了完全正确识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;部分识别减少&lt;/strong&gt;：联合处理组部分识别的比例从 40% 降低到 6.7%，表明大多数情况下都能实现完全正确的识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无法识别消除&lt;/strong&gt;：联合处理组实现了零失败，所有照片均能至少部分识别，而直接 VL 组有 10 张照片完全不能识别。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;可靠性更高&lt;/strong&gt;：Kappa 系数显示联合处理组的一致性远高于直接 VL 组，证明了其在实际应用中的优越性能。&lt;br&gt; &amp;nbsp;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;514&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e116320452808f0eb70d24e1a6e9b74d503.png&quot; width=&quot;1781&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;综上所述，在高精度的图文识别场景中，通过 UVDoc 图像校正工具预处理图片、QwenVL 进行信息识别以及 LLM 进行结构化数据提取，成功解决了设备铭牌识别中的难题，构建了一个高效且精确的文字提取系统。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/bojinzhu/blog/17003148</link>
            <guid isPermaLink="false">https://my.oschina.net/bojinzhu/blog/17003148</guid>
            <pubDate>Tue, 31 Dec 2024 02:36:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>百度网页版新增「AI 搜」功能，基于文心大模型打造</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度近日在百度搜索 Web 端首页上线了百度「AI 搜」入口，「AI 搜」基于原百度搜索 AI 伙伴改版升级而来，在此前的基础上做功能升级。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0102/100753_fgNl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，百度「AI 搜」是基于百度文心大模型打造的桌面端 AI 搜索引擎，目前内容侧已经打通百度搜索引擎、百度健康、百度律临、百度文库、百度教育等内容生态，可确保搜索结果可靠、权威。&lt;/p&gt; 
&lt;p&gt;目前百度「AI 搜」主要提供包括话题探索、问题解决、决策辅助、知识答疑、主题研究、学习创作等功能，覆盖文生图、文生文、逻辑推理、多轮对话、智能摘要、AI 修图等 AI 技术。&lt;/p&gt; 
&lt;p&gt;此外，百度「AI 搜」也提供了文心智能体入口，在对话框中可通过@方式与不同智能体进行交互，方便用户使用和创建智能体。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327593</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327593</guid>
            <pubDate>Tue, 31 Dec 2024 02:09:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>天天 AI-250101：DeepSeek、多模态大模型、OpenAI 新产品、AI 十大趋势</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h2&gt;95 后 AI 天才少女罗福莉加入小米，引领 DeepSeek-V3 大模型革命&lt;/h2&gt; 
&lt;p&gt;DeepSeek-V3 是一款国产大模型，因其卓越的性能和极低的训练成本而受到关注，被称为「AI 界的拼多多」。罗福莉是 DeepSeek-V2 的关键开发者之一，她将加入小米的 AI 大模型团队。此外，小米在 AI 领域的大动作，包括组建 AI 实验室大模型团队和搭建 GPU 万卡集群。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F8V5YQJe2FWmTgF5MB-0XYw&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;智源王仲远：多模态大模型对产业更加重要，得多模态大模型得天下 | MEET 2025&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;量子位报道了智源王仲远在 MEET 2025 会议上的发言，他强调了多模态大模型在产业中的重要性，并认为掌握多模态大模型技术的企业将在未来的竞争中占据优势。这一观点不仅展示了多模态大模型的潜力，也为 AI 技术的未来应用提供了广阔的想象空间。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-atK3TGA0lhVMbjXcbyLTA&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;惊喜！Sam Altman 确定 OpenAI 新产品，AGI、Agents、成人模式&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AIGC 开放社区报道了 Sam Altman 宣布的 OpenAI 新产品，包括人工通用智能（AGI）、智能代理（Agents）和成人模式。这些新产品的发布预示着 AI 技术在多个领域的新应用，从提高工作效率到满足特定用户需求。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMBAtQGN8uV4BICaRWB5NZA&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;「智」驱未来，2024 AI 大模型技术与应用发展峰会成功举办&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AIGC 开放社区报道了 2024 AI 大模型技术与应用发展峰会的成功举办，峰会聚焦了 AI 大模型的最新技术进展和应用案例。这一峰会为行业专业人士提供了一个交流和学习的平台，推动了 AI 技术的创新和发展。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FKjar8p2EeDHSwjz3d9eR3w&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Grammarly 收购 Coda，扩大生成式 AI 影响力&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AIGC 开放社区报道了 Grammarly 收购 Coda 的消息，这一举措将扩大 Grammarly 在生成式 AI 领域的影响力。通过这次收购，Grammarly 将能够提供更广泛的 AI 服务，满足更多用户的需求。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6KMdFQEFnfI-O-dok2psyQ&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;最新扣子 (coze) 实战工作流：这么神奇的数字人工作流原来是这样搭建的&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;杰克船长的 AIGC 介绍了最新扣子 (coze) 实战工作流，展示了如何搭建数字人工作流。这一教程为用户提供了详细的步骤和方法，降低了技术门槛，使得更多人能够参与到数字人工作流的搭建中。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FpUp5wcikWPubr14R0FMILw&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;算力租赁，谁是盈利最强企业？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;数说商业探讨了算力租赁领域的盈利最强企业，分析了算力租赁市场的竞争力和企业经营策略。这一讨论为理解算力租赁行业的发展趋势和企业竞争提供了宝贵的视角。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdBMZd7pXKfqzZWf9dXX16w&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;装上记忆，Agent 牛了！&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;探索 AGI 报道了 AI 代理（Agent）技术的新进展，强调了记忆功能对 AI 代理性能的提升。这一进展不仅展示了 AI 代理技术的强大潜力，也为 AI 技术在更多领域的应用提供了新的可能性。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FXvxtSJ5KbYO2q2wXbD6PXg&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;《2024 年度 AI 十大趋势报告》重磅发布！技术创新、产品洗牌、行业动态一文看尽&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;量子位智库发布了《2024 年度 AI 十大趋势报告》，全面总结了 AI 领域的技术创新、产品变革和行业动态。报告指出了 AI 技术在多个子领域的进步，如自然语言处理、计算机视觉和机器学习，以及 AI 产品如何重塑行业格局。这份报告为理解 AI 的未来趋势提供了宝贵的视角。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F6pBRLJ_nC6nBs3P334690g&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Postgres.new：具有 AI 的 Postgres 沙箱&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AIGC 前沿技术追踪报道了 Postgres.new 的发布，这是一个具有 AI 功能的 Postgres 沙箱。它允许用户在一个安全的环境中测试和学习 Postgres 数据库，同时体验 AI 技术带来的便利。这一工具的推出，为数据库管理和 AI 技术的结合提供了新的平台。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FlJTCi0L4lznDT94X2GQ5DQ&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;F5 预测：2025 年亚太地区企业 AI 应用的五大趋势&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;AI 前线报道了 F5 对 2025 年亚太地区企业 AI 应用的五大趋势的预测。这些趋势包括 AI 在客户体验、运营效率、数据安全等方面的应用，以及 AI 技术如何帮助企业实现数字化转型。这一预测为亚太地区的企业提供了宝贵的指导和参考。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkNKy5qQ1F3eZNTs9htRMWg&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;大模型圈最新现状：一半在用 DeepSeek，另一半在玩「颜文字」？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;硅星人 Pro 探讨了大模型圈的最新现状，指出一半的从业者在使用 DeepSeek，而另一半则在探索「颜文字」等创新应用。这一现象反映了 AI 大模型技术的广泛应用和 AI 技术的趣味性。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoJvkthZPh9BsaLn2lugCKw&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;奥特曼是否担心马斯克用政治力量惩罚他？&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;硅星人 Pro 提出了一个有趣的问题：奥特曼是否担心马斯克用政治力量惩罚他？这一问题虽然带有幽默色彩，但也引发了对 AI 技术、政治力量和个人影响力的讨论。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FFL1hfVyrbctuMCUd2A3DgA&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;谷歌劈柴立军令状：必斩 OpenAI，夺回第一！&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;硅星人 Pro 报道了谷歌的决心，要在 AI 领域击败 OpenAI，重回行业领先地位。这一宣言显示了谷歌在 AI 技术竞争中的决心和信心，预示着未来 AI 领域的激烈竞争。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FdpAN2RgYEB7LeK6Ki1Axuw&quot; target=&quot;_blank&quot;&gt;来源&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;&amp;nbsp;原文&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdeep-dive-deepseek-model-performance-advantages-limitations%2F&quot; target=&quot;_blank&quot;&gt;DeepSeek 3.0 大模型深度解析&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2025 年 1 月 1 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241231%2F&quot; target=&quot;_blank&quot;&gt;天天 AI：DeepSeek、多模态大模型、OpenAI 新产品、AI 十大趋势&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 31 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2F95-genius-girl-joins-xiaomi-leading-deepseek-v3-ai-revolution%2F&quot; target=&quot;_blank&quot;&gt;95 后 AI 天才少女罗福莉加入小米，引领 DeepSeek-V3 大模型革命&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 30 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241230%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241230&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 30 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241227%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241227&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 27 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241226%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241226&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 26 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241225%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241225&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 25 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241224%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241224&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 24 日&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.2agi.net%2Fblog%2Fdaily-ai-20241223%2F&quot; target=&quot;_blank&quot;&gt;天天 AI-20241223&lt;/a&gt; 
  &lt;div&gt;
   作者：2AGI
  &lt;/div&gt; 2024 年 12 月 23 日&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327583</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327583</guid>
            <pubDate>Tue, 31 Dec 2024 00:35:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>开源 ChatBox 本地 Agent GPT 客户端智能工具介绍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;h1&gt;&lt;strong&gt;ChatBox 智能工具发布新版本&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;ChatBox 能帮你做什么？ChatBox 是一款 AIAgent，它可以帮助你提供非常便捷的智能操作功能，一些简单的操作&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;比如帮你快速查看你电脑的信息，比如你的电脑信息：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3e34e4ef823b1536d7ce2e97a7ad4128.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1020&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7159e5c7c3e8b73a1d8e6a2669f6093d5d9.png&quot; width=&quot;550&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;非常简单，你只需要对话就可以知道自己电脑所有信息，当然对于经常使用电脑的人来说可能没有必要的，但是对小白来说它还是非常重要的，还有，如果你忘记了如何创建一个 react ts 的项目的指令，那么也可以使用我们的 ChatBox&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//3c8151902109a03eda3a969630863fb2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;768&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a963aeb26ecff6c7542c02b5ed985b5c49a.png&quot; width=&quot;1024&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;AI 会执行一个会自动执行多个函数，从而实现帮助用户创建项目安装依赖打开项目，如果你忘记一些指令的适合那么它非常合适&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;推理&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;我们同样为 ChatBox 实现了 O1 的推理效果（接近 o1-mini 的效果需要看推理使用的模型）&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;在右下角选择我们的推理模型&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet//2a8907e1845ea36e16a845eb0dffc21b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1241&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ce362a735cc0df15aa549a81d5d3c31041.png&quot; width=&quot;550&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;一个简单的测试案例：一个 5 升的水和一个 6 升的水如何取到 3 升水&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&lt;em&gt;&amp;gt;&amp;nbsp;开始思考&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;我们有两个量具，一个容量为 5 升，另一个容量为 6 升。我们的目标是利用这两个量具得到正好 3 升的水。初步思考可以从装满其中一个量具并倒入另一个开始。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;一种方法是：&lt;/em&gt;
&lt;em&gt;&amp;gt;
&amp;gt;&amp;nbsp;1.&amp;nbsp;将 6 升的水桶装满（水桶状态：5 升空，6 升满）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;2.&amp;nbsp;把 6 升水桶的水倒入 5 升水桶，直到 5 升水桶装满（水桶状态：5 升满，6 升剩 1 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;3.&amp;nbsp;把 5 升水桶的水全部倒掉（水桶状态：5 升空，6 升剩 1 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;4.&amp;nbsp;再次将 6 升水桶的水倒入 5 升水桶，水桶状态：5 升装 1 升，6 升空。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;5.&amp;nbsp;再次将 6 升水桶装满（水桶状态：5 升装 1 升，6 升满）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;6.&amp;nbsp;将 6 升水桶的水倒入 5 升水桶，直到 5 升水桶满（水桶状态：5 升满，6 升装 4 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;此时，6 升水桶中会剩余 3 升水。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;我们可以反过来看问题：&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;7.&amp;nbsp;将 5 升的水桶装满（5 升满，6 升空）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;8.&amp;nbsp;把 5 升水桶的水倒入 6 升水桶（水桶状态：5 升空，6 升装 5 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;9.&amp;nbsp;再次将 5 升的水桶装满（水桶状态：5 升满，6 升装 5 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;10.&amp;nbsp;把 5 升水桶里的水倒入 6 升水桶，直到 6 升水桶满（5 升装 4 升，6 升满）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;11.&amp;nbsp;将 6 升水桶的水倒掉（水桶状态：5 升装 4 升，6 升空）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;12.&amp;nbsp;再次将 5 升水桶里的水倒入 6 升水桶（水桶状态：5 升空，6 升装 4 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;13.&amp;nbsp;将 5 升的水桶再次装满（水桶状态：5 升满，6 升装 4 升）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;14.&amp;nbsp;将 5 升水桶的水倒入 6 升水桶直到满位置（水桶状态：5 升装 3 升，6 升满）。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;此时，5 升水桶中有 3 升水。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;使用数学方法可以帮助确认我们的操作步骤是合理的：&lt;/em&gt;
&lt;em&gt;&amp;gt;
&amp;gt;&amp;nbsp;6 升和 5 升之间的差额系统可以用来倒水，重复操作之后达到 3 升，可以通过理清水量的加减关系，如通过方程 (np&amp;nbsp;+&amp;nbsp;mq&amp;nbsp;=&amp;nbsp;d) 考虑欧几里得算法，其中 n 和 m 是整数，而 p 和 q 是 6 和 5 的整数倍数（因为我们倒水过程就是在找能运算得到目标水量即 d:3）。&lt;/em&gt;
&lt;em&gt;&amp;gt;
&amp;gt;&amp;nbsp;这个问题的解决方法通过线性结合的整数解（n 和 m）能够在两个水桶之间进行正好满足 d=3 升。&lt;/em&gt;
&lt;em&gt;&amp;gt;
&amp;gt;&amp;nbsp;通过上两个方法步骤的验证我们已经计算出符合欧几里得解的过程，因此得出其中一个水桶的正确 3 升水量。&lt;/em&gt;
&lt;em&gt;&amp;gt;&amp;nbsp;要用 5 升和 6 升的水桶得到正好 3 升的水，可以按照以下步骤进行：&lt;/em&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;开始&lt;/strong&gt;：5 升桶（空），6 升桶（空）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 1 步&lt;/strong&gt;：将 6 升桶装满。方法是直接装满自来水或其他水源。（5 升空，6 升满）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 2 步&lt;/strong&gt;：将 6 升桶里的水倒入 5 升桶，直到 5 升桶满。（5 升满，6 升装 1 升）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 3 步&lt;/strong&gt;：把 5 升桶里的水全部倒掉。（5 升空，6 升装 1 升）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 4 步&lt;/strong&gt;：再次将 6 升桶剩下的 1 升水倒入 5 升桶。（5 升装 1 升，6 升空）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 5 步&lt;/strong&gt;：重新将 6 升桶装满。（5 升装 1 升，6 升满）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;第 6 步&lt;/strong&gt;：将 6 升桶的水倒入 5 升桶，直到 5 升桶满。此时，5 升桶已经有 1 升，通过这一步，加上 4 升，正好将 5 升桶填满，6 升桶还剩下 3 升水。（5 升满，6 升装 3 升）&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;现在，您在 6 升桶中得到了正好 3 升的水。这样通过简单的倒水步骤，巧妙地就能得到所需的水量。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;结束语&lt;/strong&gt;&lt;/h2&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;当然我们的 ChatBox 是开源的，如果你感兴趣也可以加入我们的.NET AI 与 SK 的爱情故事&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;ChatBox 开源地址 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAIDotNet%2FChatBox&quot; target=&quot;_blank&quot;&gt;https://github.com/AIDotNet/ChatBox&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327579</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327579</guid>
            <pubDate>Mon, 30 Dec 2024 19:08:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>MaxKB 开源知识库问答系统累计下载数量超过 300,000 次！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;截至 2024 年 12 月 30 日 22:00，飞致云旗下开源项目——基于大语言模型和 RAG 的知识库问答系统 MaxKB 全网累计下载数量超过 300,000 次！&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1920&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-57c3f0572e63d8de65224aed3505d57a880.jpg&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/327493</link>
            <guid isPermaLink="false">https://www.oschina.net/news/327493</guid>
            <pubDate>Mon, 30 Dec 2024 03:48:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
    </channel>
</rss>