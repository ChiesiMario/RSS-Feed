<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 11 Feb 2025 07:36:17 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>DeepSeek 梁文锋身家暴涨，有专家预计或超黄仁勋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社报道显示，7 位创业公司创始人和人工智能专家对 DeepSeek 的估值存在巨大分歧，估值区间在 10 亿美元到 1550 亿美元之间。按照彭博亿万富翁指数中间值估算，DeepSeek 估值约在 20 亿至 300 亿美元，而持有公司 84% 股份的梁文锋，身家可能在 16.8 亿到 252 亿美元之间，有望跻身亚洲最富有的科技大亨之列，甚至问鼎中国首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同业内人士给出的估值差异极大。波士顿风险投资公司 Glasswing Ventures 创始人鲁迪纳・塞塞里认为，按同行公司估值，DeepSeek 最少值 10 亿美元；研究工程师 Sebastian Raschka 则觉得，凭借强大的品牌认知度，其估值应在 20 亿到 100 亿美元之间，高于 Mistral AI。而 Sweat Free Telecom 创始人查纳基亚・拉姆德夫的预测更为乐观，认为 DeepSeek 估值可达 1550 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2fbcd3fec3d8b307089121298b01c62f34.webp&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前 1 月有报道称，软银集团洽谈牵头对 OpenAI 进行最高 400 亿美元融资，融资后估值达 3000 亿美元。若 DeepSeek 按此估值一半计算，梁文锋个人财富或达 1260 亿美元，有望超过英伟达 CEO 黄仁勋，身家远超钟睒睒等富豪，在同领域也将远超字节跳动创始人张一鸣（2024 年福布斯中国内地富豪榜显示张一鸣身价 456 亿美元，梁文锋身家或为其 3 倍） 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;梁文锋出生于 1985 年，本硕就读于浙江大学信息与通用工程专业，师从项志宇，研究机器视觉，2010 年毕业。毕业后，他投身量化投资，成立幻方量化，仅 6 年管理规模达千亿，成为 「量化四大天王」 之一。2023 年 5 月，梁文锋决心进军通用人工智能领域，7 月成立 DeepSeek，被视为量化投身 AI 创业第一人。2024 年 12 月底，DeepSeek 发布的 DeepSeek-V3 火遍全网。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不过，由于 DeepSeek 收入、利润等财务数据保密，外界只能通过对比 OpenAI、Anthropic 等公司估值来推测其价值，这些估值仅供参考。梁文锋的真实身家究竟几何，还需时间揭晓。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333142</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333142</guid>
            <pubDate>Tue, 11 Feb 2025 07:18:14 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「互联网之子」 Aaron Swartz 雕像在互联网档案馆揭幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Aaron Swartz 的大理石雕像上周五在互联网档案馆的礼堂揭幕，有大约 300 人出席，半身像下方刻有文字&lt;em&gt;「The Internet&#39;s Own Boy（互联网之子）」&lt;/em&gt;。本周重 312 磅的雕像将先转移至大厅，直至获得许可放置在当地公园内。&lt;/p&gt; 
&lt;p&gt;揭幕仪式上，Creative Commons 联合创始人 Lisa Rein 强调：「崇拜 Aaron 的前提是正确理解他的故事——他并非殉道者，而是为公众已付费的科学研究成果应自由获取而战。」电子前沿基金会（EFF）执行董事 Cindy Cohn 则称，这座雕像「提醒人们为真理与正义持续斗争」。科幻作家 Cory Doctorow 在视频致辞中暗讽特朗普政府时期的政治环境：「这是一个希望稀缺的时代，但这座雕像应激励我们让世界变得更好」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f82cf0e74040f33cd165bbe250c47ae3e5c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Aaron Swartz 出生于 1986 年，参与了 RSS 和 Markdown、web.py 等项目的开发，被视为是 Reddit 的联合创始人。&lt;/p&gt; 
&lt;p&gt;2011 年 1 月他因为在 MIT 下载学术论文而遭到逮捕，面临最高 35 年的刑期，他拒绝了认罪协议，于 2013 年 1 月 11 日自杀身亡。他在当年被追授进入互联网名人堂。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/92332/in-memory-of-aron-swartz&quot; target=&quot;news&quot;&gt;纪念 Aaron Swartz：他用生命捍衞了互联网的开放和自由&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/36671/aaron-swartz-kill-himself&quot; target=&quot;news&quot;&gt;web.py 作者 Aaron Swartz 自杀身亡&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</guid>
            <pubDate>Sat, 08 Feb 2025 06:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌 DeepMind CEO：DeepSeek 模型是中国最好的作品，但炒作有点夸大</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌旗下人工智能公司 DeepMind 首席执行官戴米斯·哈萨比斯（Demis Hassabis）在巴黎一场谷歌主办的活动上，对 Deepseek 的 AI 模型做出了评价。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/113748_Ev6o_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;哈萨比斯称赞 DeepSeek 的模型是令人印象深刻的作品，并表示「我认为这可能是我见过中国最好的作品」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;哈萨比斯认为，其在短时间内完成的开发和训练成本控制方面表现出色，然而从技术角度来看，哈萨比斯指出，Deepseek 并没有展示出非常大的科学进步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;他表示：「尽管有很多人吹捧，但其实这背后并没有真正的新的科学进步……它（DeepSeek）在人工智能中使用的是已知的技术。」他补充说，围绕 DeepSeek 的炒作「有点夸张」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;他还声称，DeepMind 本周发布的 Gemini 2.0 Flash 模型比 DeepSeek 大模型更为高效。&lt;/p&gt; 
&lt;p&gt;此外，哈萨比斯还谈到了通用人工智能（AGI）的前景，他认为 AI 行业正在走向 AGI，且可能在未来 5 年左右实现这一目标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china</guid>
            <pubDate>Sat, 08 Feb 2025 03:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>TIOBE 2 月榜单：Rust 达新高，Mojo 和 Zig 崭露头角</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 公布了 2025&amp;nbsp;年 2 月的&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;编程语言排行榜&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;64&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1df184cb150f1180b39eb214604fb7eeef4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;自去年 &lt;a href=&quot;https://www.oschina.net/news/296488/tiobe-index-202406&quot;&gt;6 月&lt;/a&gt;成功超越了 C 成为了 TIOBE 指数中新的第二名之后，C++ 便稳定在了这一位置上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE CEO&amp;nbsp;Paul Jansen&amp;nbsp;点评道，「随着全球对每秒计算能力的需求日益增长，而硬件的发展速度却未能跟上这一需求，程序的运行速度变得越来越重要。正因如此，在 TIOBE 指数中，那些以速度见长的编程语言逐渐崭露头角也就不足为奇了。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了&amp;nbsp;C++，Go 也稳居榜单前 10，Rust 则达到 1.47% 的历史新高。此外，以速度著称的 Mojo 和 Zig 也分别位列第 51 和第 56 位，正在叩响前 50 名的大门。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;你可能会好奇，Python 这种慢速语言是如何在这些竞争激烈的语言面前生存下来的。这是因为，除了性能之外，如今还有另一个驱动因素：&lt;strong style=&quot;color:#404040&quot;&gt;学习一门新编程语言的难易程度&lt;/strong&gt;。除了需要处理更多的数据，世界还需要更多的程序员。完全依赖 AI 开发应用程序目前还无法实现，因此对新程序员的需求依然非常高。由于软件工程专业毕业生的数量远远无法满足市场需求，许多非软件工程师也开始纷纷加入编程的行列，而他们最喜欢的语言正是 Python。这就是为什么 Python 依然能够稳居编程语言的主流地位。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TIOBE 2 月 TOP 20 编程语言&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;404&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0707406f2fb35a7fdf61ce778525b8f614.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TOP 10 编程语言 TIOBE 指数走势（2002-2024）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;226&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70c51a5ab719ba0927f95909df990227d21.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;第 21-50 名编程语言排行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;417&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-52892925983133de7bb115cd8a0c1d16f89.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;第 51-100 名如下，由于它们之间的数值差异较小，仅以文本形式列出（按字母排序）：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ABC, ActionScript, Algol, Alice, Apex, APL, AutoLISP, CFML, CHILL, Clipper, CLIPS, Clojure, Crystal, Curl, Elm, Erlang, F#, Forth, Groovy, Hack, Icon, Inform, Io, JScript, LabVIEW, Modula-2, Mojo, MQL5, NATURAL, Nim, OCaml, Occam, OpenCL, OpenEdge ABL, PL/I, Q, Raku, Ring, Scheme, Simulink, Smalltalk, SPARK, SPSS, Stata, SystemVerilog, Vala/Genie, VHDL, Wolfram, X++, Zig&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 编程社区指数（The TIOBE Programming Community index）是一个衡量编程语言受欢迎程度的指标，该指数每月更新一次。评判的依据来自世界范围内的工程师、课程和第三方供应商，包括流行的搜索引擎，如 Google、必应、雅虎、维基百科、亚马逊、YouTube 和百度都被用于指数计算。值得注意的是，TIOBE 指数并不代表编程语言的好坏或编写代码的多少。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;该指数可以用来检查你的编程技能是否还能跟上时代的步伐，或者在开始建立一个新的软件系统时，基于指数对采用何种编程语言做出决策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F&quot; target=&quot;_blank&quot;&gt;TIOBE 指数&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;的定义方式，以及详细榜单信息&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;均可查看官网&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333092/tiobe-index-202502</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333092/tiobe-index-202502</guid>
            <pubDate>Sat, 08 Feb 2025 03:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Sam Altman：AI 成本每年暴跌 10 倍，2035 年人人都有超级大脑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthree-observations&quot; target=&quot;_blank&quot;&gt;更新了个人博客&lt;/a&gt;&lt;/u&gt;，其中他预测 AI 成本每年将暴跌 10 倍，并且到了 2035 年，人人都能拥有超级大脑。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/111413_19Xl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文中，Altman 提到自己对 AI 经济学的三点观察：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI 模型的智能水平大致等于其训练和运行所使用资源的对数；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;使用固定级别 AI 的成本大约每 12 个月降低 10 倍，价格下降会极大促进 AI 的使用；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;线性增长的智能水平所创造的社会经济价值呈超指数级增长。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;并且 Altman 总结，如果这三点趋势继续保持，AI 对社会的影响将是巨大的。 &amp;nbsp;Altman 还预测，AI Agents 最终可能会像「虚拟同事」一样与人类协作，在各个领域的知识工作中发挥作用。&lt;/p&gt; 
&lt;p&gt;此外，Altman 还认为，在某些方面，AI 在经济上的作用可能会类似于晶体管，AI 也能够大规模推广，并渗透到经济的各个角落。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;最后，Altman 还表示确保 AGI 的广泛受益，让 AGI 的好处惠及全社会至关重要。并且他提议持续降低智能计算的成本，让人人都能负担得起 AI，按照这一目标，或将在 2035 年人人都能获得近乎无限的智能支持。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;附上博客原文：&lt;/p&gt; 
&lt;h3&gt;三点观察&lt;/h3&gt; 
&lt;p&gt;我们的使命是确保 AGI（通用人工智能）造福全人类。&lt;/p&gt; 
&lt;p&gt;如今，一些接近 AGI 的系统已经开始显现，因此我们认为理解当前所处的阶段至关重要。AGI 的定义较为模糊，但通常指的是一种能够在人类水平上解决越来越复杂问题的系统，且适用于多个领域。&lt;/p&gt; 
&lt;p&gt;（作者注释：本文使用「AGI」一词，我们的目的是清晰表达，并无意改变或重新定义我们与微软的合作关系，以及避免断章取义的解读，我们完全预计将与微软保持长期合作。）&lt;/p&gt; 
&lt;p&gt;人类天生具有构建工具的能力，并且拥有理解和创造的驱动力，这促使世界不断进步。每一代人都会在前人发现的基础上进一步创新，创造出更强大的工具——&lt;strong&gt;从电力到晶体管，再到计算机、互联网，如今则是 AGI。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管人类的创新历程并非一帆风顺，但从长远来看，这一进程始终推动着社会发展，使人们的生活在各个方面都得到极大改善。&lt;/p&gt; 
&lt;p&gt;从某种角度来看，AGI 只是人类不断攀登进步阶梯的又一个工具。但从另一个角度来看，它可能标志着一个真正不同的时代的开始。未来的经济增长前景令人惊叹，我们甚至可以设想一个世界：所有疾病都能被治愈，我们拥有更多时间陪伴家人，并能够充分发挥自己的创造潜力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;或许再过十年，地球上的每个人都能拥有比今天最具影响力的人更强的能力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们持续见证 AI 发展的迅猛进步，以下是关于 AI 经济学的三点观察：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;AI 模型的智能水平大致等于其训练和运行所使用资源的对数。这些资源主要包括训练计算（compute）、数据和推理计算（inference compute）。目前的趋势表明，只要投入足够的资金，就能持续且可预测地提升 AI 能力，而支撑这一趋势的缩放定律（Scaling Laws）在多个数量级范围内都被证明是准确的。&lt;/li&gt; 
 &lt;li&gt;使用固定级别 AI 的成本大约每 12 个月降低 10 倍，价格下降会极大促进 AI 的使用。一个明显的例子是 GPT-4 在 2023 年初的使用成本，相比 GPT-4o 在 2024 年中期，其每个 token 的价格下降了约 150 倍。摩尔定律每 18 个月带来 2 倍的性能提升，而 AI 成本下降的速度远超这一趋势，影响将更加深远。&lt;/li&gt; 
 &lt;li&gt;线性增长的智能水平所创造的社会经济价值呈超指数级增长。这一趋势意味着，对于 AI 的指数级投资在可预见的未来不会停止。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;如果这三点趋势继续保持，AI 对社会的影响将是巨大的。&lt;/p&gt; 
&lt;p&gt;目前，&lt;strong&gt;我们已经开始推出 AI Agents，它们最终可能会像「虚拟同事」一样与人类协作。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以软件工程领域的 AI Agent 为例——这是我们认为极为重要的应用方向之一。设想未来的 AI Agent 能够完成大部分经验 3-5 年的顶级公司软件工程师可以完成的任务，但任务时长限制在几天内。它不会有突破性的创新想法，需要大量的人类监督和指导，在某些方面表现出色，同时在某些意想不到的地方表现较差。&lt;/p&gt; 
&lt;p&gt;尽管如此，它仍可以被视作一名真实但相对初级的虚拟同事。&lt;strong&gt;现在，想象一下如果有 1000 个这样的 AI Agnet，或者 1000000 个。再进一步，设想这样的 AI Agnet 被应用到所有知识型工作领域，其影响将难以估量。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，AI 在经济上的作用可能会类似于晶体管——一个重大科学突破，能够大规模推广，并渗透到经济的各个角落。如今，我们不会特别关注晶体管或生产晶体管的公司，但它们的存在让我们的计算机、电视、汽车、玩具等设备变得更加强大、近乎奇迹般地运作。&lt;/p&gt; 
&lt;p&gt;世界的变化不会一蹴而就，它从未如此。短期内，生活仍将继续，2025 年的人们大概率会和 2024 年一样度过日常——我们仍会相爱、组建家庭、在网上争论、去大自然中远足等等。&lt;/p&gt; 
&lt;p&gt;然而，未来的到来将不可忽视，长期来看，社会和经济的变化将是巨大的。人类将找到新的事物去探索，找到新的方式去互相帮助、去竞争，但这些方式可能与今天的工作模式截然不同。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在这样的时代，主动性、意志力和决策能力将变得尤为宝贵。正确地决定要做什么，并在不断变化的世界中找到前进的道路，将具有极高的价值。因此，韧性和适应能力将成为关键技能。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AGI 将是史上最强大的杠杆，极大增强人类的主观能动性，它不会削弱个人的影响力，反而会让个体的能力比以往任何时候都更强大。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AGI 的影响不会均匀分布。某些行业可能变化不大，但科学进步的速度可能比今天快得多，甚至可能超越 AGI 带来的所有其他变革。&lt;/p&gt; 
&lt;p&gt;长期来看，许多商品的价格将大幅下降（目前，智能成本和能源成本是许多行业的主要限制因素）。与此同时，奢侈品和一些稀缺资源（如土地）的价格可能反而会飙升。&lt;/p&gt; 
&lt;p&gt;从技术角度来看，AGI 的发展道路相对清晰。但如何将 AGI 融入社会，公共政策和社会共识将起到至关重要的作用。&lt;strong&gt;这也是我们不断尽早、频繁推出 AI 产品的原因之一——让社会与技术共同演进，为未来做好准备。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI 将渗透到经济和社会的方方面面，未来，我们会期待一切都变得智能化。面对这一趋势，许多人认为应该给予个人更多对技术的控制权，比如开放源码等措施，同时也要接受在安全性与个体赋权之间找到平衡，必然需要做出一些取舍。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们始终希望避免鲁莽行事，未来在 AGI 安全性方面可能会做出一些不受欢迎的重要决策和限制。但总体而言，随着 AGI 的逐步实现，我们认为更倾向于个体赋权是正确的方向。否则，我们可能会看到另一条道路。&lt;/p&gt; 
&lt;p&gt;确保 AGI 的广泛受益，让 AGI 的好处惠及全社会至关重要。从历史来看，科技进步通常会改善健康状况、经济繁荣等关键指标，且长期来看整体趋势是向好的。但技术本身不会自动带来更大的平等，如果希望在社会公平方面做得更好，我们可能需要新的思维方式。&lt;/p&gt; 
&lt;p&gt;尤其值得关注的是，资本与劳动力之间的力量平衡可能会被打破，这可能需要及早干预。&lt;/p&gt; 
&lt;p&gt;我们愿意考虑一些听起来不太寻常的想法，比如给每个人分配一定的「计算预算」（compute budget），让全球所有人都能充分利用 AI。&lt;strong&gt;当然，也有一种更简单的方法：持续降低智能计算的成本，让人人都能负担得起 AI。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;到 2035 年，每个人都应该能够调用相当于 2025 年全人类智慧总和的智力资源。所有人都应当获得近乎无限的智能支持，并自由地发挥想象力&lt;/strong&gt;。目前，世界上仍有大量人才因缺乏资源而无法充分发挥自己的潜力，如果我们改变这一点，全球的创造力将迎来爆发式增长，并为所有人带来巨大的福祉。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333079/sam-altman-three-observations</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333079/sam-altman-three-observations</guid>
            <pubDate>Sat, 08 Feb 2025 03:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>被面试官拷问三个小时，应届博士无缘 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1823558407486179899%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;据媒体报道&lt;/a&gt;&lt;/u&gt;，应聘者刘哲回忆起去年 5 月参加 DeepSeek 线上面试的经历。那时，面试官连续 3 小时的高强度提问让他倍感压力。尽管他作为 211、985 高校的应届博士生，在校期间已崭露头角，但面对那些深入且具有挑战性的问题，他仍感到不小的难度。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;「最开始有一个 coding（编程）环节，会根据应聘者的专业出题，测试结果将决定应聘者是否能进入面试环节。面试持续 3 小时，由两位面试官分别进行，每位面试官负责 1.5 小时。其中一位面试官会深入考察机器学习的基础知识，连续提问 1.5 小时，据说所有应聘者都会被问到相同的题目，以便于他们进行比较和排名。接下来的 1.5 小时则是针对项目经验的讨论，他们特别关注应聘者在项目执行过程中的思考方式。」据刘哲所述，面试由 HR 主持，两位面试官都很年轻，不超过 30 岁，整个面试过程体验良好，能够感受到团队充满青春活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7ed8b4dc5acec727a286bfd36d21d80307e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;「在我所经历过的互联网公司中，&lt;strong&gt;DeepSeek 是唯一一家会根据应聘者的专业背景量身定制编程题目的公司。&lt;/strong&gt;」回顾面试经历，刘哲这样描述。在刘哲看来，DeepSeek 的崛起似乎是必然的。他透露，应聘者普遍来自清华、北大等顶尖学府，面试过程严谨且要求高，当时招聘并未设定人数上限，明显感受到公司旨在网络顶尖智慧人才，只招收天才级别的精英。&lt;/p&gt; 
&lt;p&gt;网络上也有人在分享面试 DeepSeek 的经历时表示遇到了出乎意料的问题。例如，面对「DPO 为什么用 KL 散度,不用交叉熵?机器学习中什么时候必须用 KL 散度，什么时候必须用交叉熵,什么时候两者可互换」这样的问题，有网友不禁感叹：「这还是我能理解的中文吗？」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f13afeea08b0fb9b3fe3418f8dd4256571b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据知情人透露，有朋友曾参与 DeepSeek 的面试，并直接与创始人对话。总体感受是，公司充满愿景，洋溢着理想主义精神，研究氛围优于高校实验室，非常适合对 AI 充满热情的研究人员。&lt;/p&gt; 
&lt;p&gt;另外，一些参加过 DeepSeek 面试的人表示，公司不设 KPI 考核，采取扁平化管理模式，每位核心算法人员都能直接与梁文峰探讨问题，不太像传统公司，更像大学的一个研究团队。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333075</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333075</guid>
            <pubDate>Sat, 08 Feb 2025 03:04:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>全球开源大模型前十均为阿里通义千问衍生模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，全球最大 AI 开源社区 Huggingface 发布了最新的开源大模型榜单（Open LLM Leaderboard），其中榜单显示，其排名前十的开源大模型全部是基于阿里通义千问（Qwen）开源模型二次训练的衍生模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5d2384f1f2035007cae119894ebe4235ed3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;来源：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fopen-llm-leaderboard%2Fopen_llm_leaderboard%23%2F&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;据悉，Open LLM Leaderboard 是目前全球最具权威性的开源大模型榜单，其测试维度涵盖阅读理解、逻辑推理、数学计算、事实问答等。&lt;/p&gt; 
&lt;p&gt;而通义千问 Qwen 大模型已经成为全球最大的开源模型族群。在海内外开源社区中，Qwen 的衍生模型数量已突破 9 万，超越美国 Meta 公司旗下的 Llama 系列开源模型，位居全球第一。在 Hugging face2024 年的开源模型下载中，Qwen 模型系列中的 Qwen2.5-1.5B-Instruct 的下载量占总下载量的 26.6%，是全球下载量最高的开源模型。&lt;/p&gt; 
&lt;p&gt;此外，此前爆火的 DeepSeek 公司基于 R1 推理模型蒸馏了 6 个模型开源给社区，其中有 4 个模型来自 Qwen。近期，著名 AI 科学家李飞飞团队用较少的资源和数据训练出的 s1 推理模型，同样以 Qwen 模型为基础模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333071</guid>
            <pubDate>Sat, 08 Feb 2025 02:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克欲以 7000 亿收购 OpenAI，奥特曼回应：不如让我们收购 X</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 2 月 10 日（路透社）&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fmarkets%2Fdeals%2Felon-musk-led-group-makes-974-billion-bid-control-openai-wsj-reports-2025-02-10%2F&quot; target=&quot;_blank&quot;&gt;报道称&lt;/a&gt;&lt;/u&gt;，由埃隆·马斯克（Elon Musk）领衔的财团周一表示，已经提出以 974 亿美元（当前约 7,115 亿元人民币）收购 OpenAI 的运营资产。报道指出，这一举动可能会对蓬勃发展的 AI 行业产生重大影响。数月前，这位亿万富翁曾起诉这家人工智能初创公司，试图阻止其向营利性企业过渡。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-caff5ae16c7c36c9f1368d8366a9be892c9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次收购提议的背景是，OpenAI 首席执行官萨姆・阿尔特曼正在尝试对公司进行重组，计划将其非营利董事会与盈利业务分离。然而，目前尚不清楚阿尔特曼和非营利董事会是否已经就过渡价格达成一致。&lt;/p&gt; 
&lt;p&gt;对于这一消息，阿尔特曼在 X 平台上&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1889062013109703009&quot; target=&quot;_blank&quot;&gt;回应称&lt;/a&gt;&lt;/u&gt;：「不用了，谢谢，但如果你愿意，我们可以以 97.4 亿美元的价格收购推特。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;516&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;马斯克随后还单独发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1889070627908145538&quot; target=&quot;_blank&quot;&gt;推文&lt;/a&gt;&lt;/u&gt;，称奥特曼是「Scam Altman（骗子奥特曼）」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1070&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0211/104848_aRfy_2720166.png&quot; width=&quot;1286&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333069</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333069</guid>
            <pubDate>Sat, 08 Feb 2025 02:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动开源大语言模型应用开发框架 Eino</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字节跳动技术团队发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJQREuZyI6ug3cc9Ov7diog&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，基于 Golang 的大模型应用综合开发框架 Eino 已正式开源，旨在提供简洁、可扩展、可靠的开发工具。&lt;/p&gt; 
&lt;p&gt;据悉，Eino 基于明确的「组件」定义，提供强大的流程「编排」，覆盖开发全流程，旨在帮助开发者以最快的速度实现最有深度的大模型应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74d0fd011f9ebf4fd3950e2f6cc1b0f23bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;项目地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://github.com/cloudwego/eino&lt;/li&gt; 
 &lt;li&gt;https://github.com/cloudwego/eino-ext&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;字节跳动技术团队介绍，Eino 作为旨在覆盖 devops 全流程的大模型应用开发框架，具有内核稳定、API 简单易懂、丰富的扩展性、提供开箱即用的配套工具等特点，能够帮助开发者快速、简单的上手。&lt;/p&gt; 
&lt;p&gt;Eino 已成为字节跳动内部大模型应用的首选全代码开发框架，已有包括豆包、抖音、扣子等多条业务线、数百个服务接入使用。字节跳动表示，未来还将以 Eino 开源库为核心代码仓库，坚持内外用一套代码，与社区共建最优秀的大模型应用开发框架。&lt;/p&gt; 
&lt;p&gt;Eino&amp;nbsp;借鉴了 LangChain 和 LlamaIndex 等开源框架的优势，并结合前沿研究，提供了一系列丰富的组件抽象，如 ChatModel、Tool、ChatTemplate 等，方便用户组合开发。通过强大的编排框架（Graph、Chain），Eino 支持类型检查、流式处理、并发管理等功能，简化了开发流程。&lt;/p&gt; 
&lt;p&gt;Eino 框架结构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/103841_1C2B_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，Eino 提供了流式处理、回调机制、可视化开发工具等功能，帮助开发者高效构建 AI 应用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333062</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333062</guid>
            <pubDate>Sat, 08 Feb 2025 02:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>外交部回应 DeepSeek 引发国际广泛关注讨论</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2 月 10 日外交部例行记者会上，有记者提问称，日前中国人工智能企业深度求索（DeepSeek）推出性能优越、免费商用的开源大模型，且训练成本相较同类产品更低，在国际上引起广泛关注和热烈讨论，请问发言人对此有何评论？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;外交部发言人郭嘉昆表示：具体的专业问题建议向主管部门了解。我想强调的是，当前，人工智能的新技术不断突破，新业态持续涌现，新应用加快拓展，已经成为新一轮科技革命和产业变革的重要驱动力量。中国积极拥抱智能变革，大力推进人工智能创新发展，重视人工智能安全，支持鼓励企业自主创新，为全球人工智能发展作出了积极贡献。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中方积极推动人工智能普惠发展，帮助发展中国家加强能力建设，主张开源人工智能技术，促进人工智能服务的可及性，实现各国共享智能红利。同时，我们反对以意识形态划线，反对泛化国家安全概念、将经贸问题政治化的做法。中方愿同各方加强人工智能交流合作，坚持以共商促共享，携手打造开放包容、互利共赢的发展环境，共同在人工智能的广阔天地里深度求索。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333056</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333056</guid>
            <pubDate>Sat, 08 Feb 2025 01:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>操作教程丨使用 1Panel 开源面板快速部署 DeepSeek-R1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;近期，DeepSeek-R1 模型因其在数学推理、代码生成与自然语言推理等方面的优异表现而受到广泛关注。作为能够有效提升生产力的工具，许多个人和企业用户都希望能在本地部署 DeepSeek-R1 模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;通过 1Panel 的应用商店能够简单、快速地在本地部署 DeepSeek-R1 模型。本教程将按照安装 Ollama→安装 OpenWebUI→安装并使用 DeepSeek-R1 的顺序，为您介绍使用 1Panel 开源面板部署 DeepSeek-R1 模型的具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在部署好 DeepSeek 之后，用户也可以尝试将其与 MaxKB 开源知识库问答系统进行对接，构建一个自己的 Chatbox，也就是一个与 DeepSeek 大模型的智能会话界面。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;一、从 1Panel 应用商店安装 Ollama&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;Ollama 是一个开源的本地大语言模型运行框架，专门为在本地便捷部署和运行大型语言模型而设计。为了能够正常运行 DeepSeek-R1 模型，需要先在本地安装 Ollama，本章节将介绍具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;首先，从 1Panel 首页进入「应用商店」，在「AI/大模型」分类下找到 Ollama，点击「安装」按钮进行安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3eb857757eb258cc4161d9b4046acdfe2e0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在安装详情页中，您可以自定义端口并勾选「端口外部访问」选项，其他设置保持默认，最后点击「确认」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f1f981b2e3061d054c784539d621db3ab6.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;Ollama 安装成功后，在 1Panel 操作界面中返回应用商店的「已安装」标签页，看到 Ollama 已经安装成功。此时点击「服务端口:11434」按钮，浏览器自动跳转新标签页，若标签页内显示「Ollama is running」，则表示 Ollama 已成功安装并正常运行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-dd4e30cec3cefda771ea15fb930c61b37ae.jpg&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1fa60c450c2a377092f78c7c44a5a1467c0.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;二、从 1Panel 应用商店安装 OpenWebUI&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;由于 Ollama 本身没有用户交互界面，为了提升模型的使用体验，我们需要从 1Panel 的应用商店中安装 OpenWebUI。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5e5456150b638b4dbe716ca3839f814339b.png&quot; width=&quot;979&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;OpenWebUI 是一款高度可扩展、功能丰富、操作便捷的自托管 AI 平台，它提供了一个更直观的用户界面，同时增强了安全性和扩展性。OpenWebUI 与 Ollama 相结合，能够方便地管理和使用本地部署的大型语言模型。本章节将介绍安装 OpenWebUI 的具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;确认 Ollama 正常运行后，返回 1Panel 应用商店，在「AI/大模型」分类中找到 OpenWebUI，点击「安装」按钮进行安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d0545f49855958419fbb4aacff814f0760.jpg&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在安装详情页中，您需要填写 Ollama 服务地址和 Secret Key，并勾选「端口外部访问」选项，其他设置保持默认，最后点击「确认」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9ed84ad322dc29653252b58c00a0abe586e.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;OpenWebUI 安装成功后，返回 1Panel 应用商店「已安装」标签页，点击「服务端口:3000」按钮，进入 OpenWebUI 控制枱（注意：如果浏览器未能显示 OpenWebUI 控制枱页面，请在 OpenWebUI 应用显示的「已安装」时间超过 5 分钟以后再进行访问）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9aa59370c5af4fd4ad89aec078704932e3a.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在 OpenWebUI 控制枱中，依次设置「名称」、「电子邮箱」和「密码」，完成设置后，点击「创建管理员账号」按钮。稍等片刻，页面会弹出更新提示窗口，点击「确认，开始使用！」按钮，提示窗口消失后，即可开始使用 OpenWebUI。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cfb617497b6a6c3ca0f93ce15df4f43edf8.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;三、通过 OpenWebUI 安装并使用 DeepSeek-R1&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;本章节将介绍如何通过 OpenWebUI 安装和使用 DeepSeek-R1 模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;1. 安装 DeepSeek-R1 模型：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;返回至 OpenWebUI 控制枱页面，点击页面左上角的「选择一个模型」选项，在搜索框中输入「deepseek-r1:1.5b」，然后点击「从 Ollama.com 拉取 deepseek-r1:1.5b」选项。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-060b281d5425c3d9dd26e454ce843597c57.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;2. 使用 DeepSeek-R1 模型：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;模型下载完成后，刷新页面，确认页面左上角的模型显示为「deepseek-r1:1.5b」。然后点击屏幕中央的输入框，就可以开始和 DeepSeek-R1 模型对话了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;922&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-309adcc2cdecb9c8f9caaff84223ca49b0d.png&quot; width=&quot;1608&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;稍等片刻，收到回复后即可确认 DeepSeek-R1 已通过 1Panel 成功部署到您的服务器。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5748142a990c5a72b8fb2d6db37312c833.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;四、使用 GPU 为 DeepSeek- R1 加速&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;使用 GPU 为 DeepSeek-R1 加速可以显著提升模型的推理速度。在本章节中，我们以 NVIDIA GPU 为例，介绍如何在 1Panel 中为 DeepSeek-R1 配置加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;重要提示：在启用 GPU 加速之前，请确保服务器已经安装 GPU 卡并配置了相关驱动。&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span style=&quot;color:#3e3e3e&quot;&gt;进入 1Panel 应用商店的「已安装」标签页，点击 Ollama 应用下的「参数」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-579e56d39751e426ecc172ba3966317a62a.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;点击「编辑」按钮进入参数配置页面的「详情」界面，勾选「高级设置」选项，并启用「编辑 compose 文件」选项。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//47c9356c33a5e702b5a41a3de4be878b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;此时，在 compose 内容编辑框中，输入以下与 GPU 相关的代码：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;reservations:
       devices:
              -  driver: nvidia
                  count: all
                  capabilities: [gpu]&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;输入完成后，点击编辑页面中的「确认」按钮，Ollama 会自动重建。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;当重建完成后，Ollama 在 1Panel 应用商店中的状态变更为「已启动」，此时可以使用 NVIDIA GPU 为 DeepSeek-R1 提供加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-37ea6f8a8900338c209c5bbb3b25bcac4ac.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;五、企业如何用好 DeepSeek？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;DeepSeek 部署完成后，该如何让各个业务部门使用好这个能力超强的大模型呢？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;这时候，MaxKB 开源知识库问答系统就可以发挥积极作用了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b3d7952c60ed617db87088d004d8cf9fa7b.jpg&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;首先，MaxKB 可以为本地部署的 DeepSeek 构建一个 Chatbox，也就是一个智能对话的界面，类似于个人用户直接与 DeepSeek 进行对话。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;MaxKB 提供的 Chatbox 可以方便地嵌入到企业 OA 系统和业务系统，让员工使用更加便捷、安全。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ba43c99463a01d2e8219fa6a91eb22765b8.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;另一方面，企业内部有非常多的私有知识文档，这些内容是经过长期的积累和不断修订形成的，在企业内部可以形成知识库问答系统为企业的员工、合作伙伴和客户提供服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;904&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3762219074a17fe370af4ecb448ce1f2a4b.png&quot; width=&quot;947&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;MaxKB 提供开箱即用的 RAG（Retrieval-Augmented Generation，检索增强生成）技术，能够结合私有知识库提升问答效果，有效降低大模型幻觉。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333030</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333030</guid>
            <pubDate>Fri, 07 Feb 2025 14:31:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Linux 内核新补丁调整 AC 电源插拔行为，向 Windows 看齐以提升硬件兼容性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;AMD 工程师主导优化，解决便携设备休眠唤醒痛点。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;近日，AMD 工程师 Mario Limonciello 向 Linux 内核&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flinux-pm%2F20250208162210.3929473-1-superm1%40kernel.org%2F&quot; target=&quot;_blank&quot;&gt;提交了一系列补丁&lt;/a&gt;&lt;/u&gt;，旨在调整系统在&lt;strong&gt;s2idle（挂起到空闲）&lt;/strong&gt;状态下的 AC 电源插拔行为，使其更贴近 Windows 11 的逻辑。&lt;/p&gt; 
&lt;p&gt;这一改动主要针对笔记本电脑、手持游戏设备（如 Steam Deck 同类产品）在休眠时因电源状态切换导致的兼容性问题，尤其是此前曝光的 Legion Go S（搭载 AMD Ryzen Z2 芯片）的固件级故障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;为何需要「模仿」Windows？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当前，Linux 与 Windows 在 s2idle 状态下的电源行为存在关键差异：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;：插入或拔出 AC 电源时，系统会完全唤醒，若后续无用户操作则重新进入睡眠。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;：AC 事件仅触发短暂唤醒后立即重回休眠，可能导致硬件固件因快速状态切换出现异常（例如某些设备无法正确处理快速进入/退出低功耗模式）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Limonciello 指出，由于 OEM 厂商通常基于 Windows 进行硬件验证，Linux 的差异行为易暴露底层固件缺陷。新补丁通过记录休眠前的电池状态，并在 AC 事件后对比状态变化，决定是否彻底唤醒系统，从而减少「兼容性陷阱」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技术细节：唤醒机制与能耗监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唤醒逻辑重构&lt;/strong&gt;&lt;br&gt; 补丁在 ACPI 电池驱动中新增&lt;code&gt;suspend_state&lt;/code&gt;字段，休眠时保存当前电源状态（如是否充电）。若唤醒后检测到状态变化（如从充电变为放电），则触发系统完全唤醒，而非立即休眠。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能耗统计透明化&lt;/strong&gt;&lt;br&gt; 新增&lt;code&gt;/sys/power/suspend_stats/last_sleep_energy&lt;/code&gt;文件，以&lt;strong&gt;毫安时（mAh）&lt;/strong&gt;为单位记录上次休眠周期的电池消耗量，方便用户空间工具分析功耗问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;争议与用户控制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管新行为默认启用，但开发者社区对其适用场景存在分歧。例如，若笔记本合盖时连接电源，是否应强制唤醒？Limonciello 认为，这与用户外接扩展坞的场景需求一致，但用户仍可通过禁用 ACPI 电池设备的&lt;code&gt;power/wakeup&lt;/code&gt;属性恢复旧逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;影响与未来展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此次调整尤其利好搭载 AMD 芯片的设备，但惠及所有支持 s2idle 的 x86/ARM 平台。随着 Linux 在掌机市场的渗透（如 Steam OS 设备），此类优化将显著提升用户体验。此外，补丁的「Windows 兼容性驱动」思路或成为未来硬件支持的新范式，减少厂商因生态差异对 Linux 的适配成本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;br&gt; Linux 在电源管理领域的「向 Windows 学习」，并非妥协，而是以用户体验为优先的务实选择。这一补丁不仅修复了长期存在的兼容性痛点，也为开源生态与 OEM 厂商的协作提供了新思路。未来，类似「求同存异」的优化或成常态，进一步模糊两大操作系统在硬件支持上的体验边界。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</guid>
            <pubDate>Fri, 07 Feb 2025 11:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>图解系列｜DeepSeek-R1 的出众推理能力从何而来？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; DeepSeek-R1 到底有什么特别之处？它为什么能在推理任务上取得如此出色的表现？这背后的训练方法又蕴含着怎样的创新？&lt;/p&gt; 
 &lt;p&gt;当我们需要模型处理数学题、编程任务，或是进行逻辑分析时，高质量的推理能力显得尤为重要。然而，传统的训练方法往往需要耗费大量人力物力，这对许多研究团队和企业来说都是不小的负担。&lt;/p&gt; 
 &lt;p&gt;今天这篇深度解析 DeepSeek-R1 训练方法的文章，将展示一个令人耳目一新的解决方案：如何通过创新的强化学习方法，在少量高质量人工标注数据的情况下，打造出一个推理能力出众的 AI 模型。文章详细介绍了 DeepSeek 团队如何通过&quot;自动验证机制&quot;来训练模型，这种方法不仅大大降低了对人工标注数据的依赖，还能持续提升模型的推理质量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Jay Alammar&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fa463c0670c30f6fa2098b0a2cfb8cedbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 代表了人工智能发展的又一重要里程碑。对于机器学习领域的研究人员与开发者群体而言，这次发布之所以备受关注，主要有以下两点：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;首先，这是一款开源权重的模型，并且提供了更小的、经过蒸馏的版本；&lt;/li&gt; 
 &lt;li&gt;其次，它公布并深入探讨了训练方法，该方法能够复现类似于 OpenAI O1 的推理模型。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;本文将带您了解这一模型的构建过程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1- 长推理链的 SFT 数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.2- 一个过渡性的、擅长推理的高质量大语言模型（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3- 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与大多数现有的大语言模型一样，DeepSeek-R1 也是逐个生成 token，但其独特之处在于擅长解决数学和推理问题。这是因为它能够通过生成一系列思考 tokens 来详细阐述其思考过程，从而更加深入地处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5b41809ec9dc436f27455aa39b8ef58c830.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下图摘自书籍《Hands-On Large Language Models》的第 12 章，展示了创建高质量大语言模型的三个主要步骤：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5960076009014b645e62ad11df7e601f3dd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;语言建模阶段&lt;/strong&gt;，我们利用海量的网络数据训练模型预测下一个词汇，从而得到一个基础模型。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;监督式微调阶段&lt;/strong&gt;，这一步骤让模型在执行指令和回答问题时更加得心应手，进而得到一个指令调优的模型或称为监督式微调/SFT 模型。&lt;/p&gt; 
&lt;p&gt;3）最后是&lt;strong&gt;偏好调优阶段&lt;/strong&gt;，这一步骤进一步优化模型的行为，使其更符合人类偏好，最终形成的是你在各种平台和应用中使用的偏好调优后的 LLM。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1 遵循了这一通用框架。其第一步的具体内容源自于之前关于 DeepSeek-V3 模型的研究论文[1]。R1 使用的是该论文中的基础模型（并非最终的 DeepSeek-V3 模型），并且同样经历了 SFT（监督式微调）和偏好调优阶段，但它的独特之处在于这些阶段的具体操作方法。&lt;/p&gt; 
&lt;p&gt;在 R1 的构建过程中，有三个关键点值得特别关注。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 长推理链的 SFT 数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71048a70e57a4dd98c33f2c0fb43d5a0d16.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这些长思维链推理的实例数量庞大（总共达到 60 万个）。如此大规模的实例获取难度极高，且若要依靠人工标注，成本也将极为昂贵。&lt;/strong&gt; 因此，这些实例的创建过程是我们需要强调的第二个独特之处。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 一个过渡性的、擅长推理的高质量 LLM（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这些数据是由 R1 的前身，一个专注于推理但尚未命名的姊妹模型所生成的。这个姊妹模型受到了另一个模型 R1-Zero 的启发（我们将在稍后讨论）。它之所以意义重大，并不是因为它是一个非常好用的 LLM，而在于在它的创建过程中，几乎无需依赖标注数据，仅通过大规模的强化学习，就能培育出一个擅长处理推理问题的模型。&lt;/p&gt; 
&lt;p&gt;接着，这个未命名的推理专家模型的输出结果，可以用来训练一个更为多能的模型，它不仅能够处理推理任务，还能应对其他类型的任务，满足用户对大语言模型（LLM）的普遍期待。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4851fe74d4b6fa9ff29c1036a1790de83f4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此处分为两个步骤：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在此过程中，我们利用强化学习（RL）来构建一个临时的推理模型。随后，这个模型被用于生成用于监督式微调（SFT）的推理示例。然而，能够创建这个模型的关键，在于之前的一项实验，该实验成功打造了一个名为 DeepSeek-R1-Zero 的早期模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fbae4d4fb50b77fa5484a9d220719bbe4d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;R1-Zero 的独特之处在于，它能够在没有经过标注的 SFT 训练集的情况下，依然在推理任务上表现卓越。它的训练过程直接从预训练的基础模型出发，通过强化学习训练（跳过了 SFT 阶段）。它的表现非常出色，能够与 O1 模型相媲美。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd68b8120aaa63d61a0ca7bb0b7333d62ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这一成就重要重大，因为数据一直是机器学习模型能力的助推器。那么，这个模型是如何打破这一传统的呢？这主要归功于以下两点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 现代基础模型在质量和能力上已经达到了一个临界点（这个基础模型是在高达 14.8 万亿的高质量 tokens 上训练而成的）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 与通用聊天或写作请求不同，推理问题可以实现自动验证或标注。&lt;/strong&gt; 可以通过以下这个示例来说明这一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例：推理问题的自动验证&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是一个可能出现在 RL 训练步骤中的提示词/问题：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;编写一段 Python 代码，获取一个数字列表，返回排序后的列表，并在列表开头添加数字 42。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这样的问题非常适合自动验证。假设我们将这个问题抛给正在训练的模型，它会生成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用软件语法检查器可以验证生成的代码是否为有效的 Python 代码。&lt;/li&gt; 
 &lt;li&gt;我们可以运行这段 Python 代码，以检查其是否能够成功执行。&lt;/li&gt; 
 &lt;li&gt;其他现代代码生成 LLM 可以创建单元测试来验证代码的行为是否符合预期（它们自身无需具备推理能力）。&lt;/li&gt; 
 &lt;li&gt;我们甚至可以进一步，通过测量代码的执行时间，让训练过程偏好那些性能更优的解决方案，即使其他解决方案也是正确的 Python 程序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在训练步骤中，我们可以向模型提出这样的问题，并生成多种可能的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f83bf0627d5f3ff8f1fda69f2a0769899e6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们可以不依赖人工干预，自动进行检查，发现第一个输出根本不是代码。第二个输出是代码，但并非 Python 代码。第三个输出看似是一个解决方案，却未能通过单元测试，而第四个输出则是正确的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1c61910f7a45c46610b945fcd73cf50a89.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些反馈都是可以直接用来优化模型的信号。这一过程当然是在大量示例（以小批量形式）和连续的训练步骤中完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2e60359299a142483ec274c460a0c90dc6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些奖励信号和模型更新是模型在强化学习训练过程中不断进步的关键，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ce02ceb2d7a3049768b4b796755b83f0f9f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与此能力提升相伴的是，模型生成了更长的响应，即使用了更多的思考 tokens 来处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4c90ef53271c751b695ad334dddfbb87f40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;尽管这个过程很有价值，但 R1-Zero 模型在推理问题上的高分表现背后，仍存在一些问题，使其实际可用性未达理想状态。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;虽然 DeepSeek-R1-Zero 展现出了卓越的推理能力，并自主发展出了出人意料的强大推理行为，但它也遭遇了一些挑战，比如文本可读性不佳和语言混杂等问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;R1 模型的设计目标是提高可用性。因此，它（DeepSeek-R1-Zero）不仅仅完全依赖于强化学习过程，而是如前文所述，在以下两个方面发挥作用：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 创建一个过渡性的推理模型，用以生成监督式微调（SFT）的数据点。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 训练 R1 模型，以在推理和非推理问题上取得进步（利用其他类型的验证器）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-694a728dfc22ac72182045659f53b114a1b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;为了提升过渡性推理模型的实际效用，我们对其进行了监督式微调（SFT）训练，这一步骤在数千个推理问题示例上进行（部分示例由 R1-Zero 生成并筛选）。在论文中，这些示例被称为&quot;冷启动数据&quot;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2.3.1. 冷启动阶段&lt;/p&gt; 
 &lt;p&gt;与 DeepSeek-R1-Zero 不同，为了防止基础模型在强化学习训练初期出现不稳定的冷启动问题，对于 DeepSeek-R1，我们构建并收集了少量长思维链（CoT）数据对模型进行微调，将其作为初始的强化学习策略模型。为收集这类数据，我们探索了多种方法：使用带有长 CoT 示例的小样本提示技术、直接提示模型生成带有反思和验证的详细答案、收集 DeepSeek-R1-Zero 生成的易读格式输出，并通过人工标注员对结果进行后处理细化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;但或许你会问，既然我们已经有了这些数据，为什么还需要依赖强化学习过程呢？答案在于数据的规模。我们可以获取的可能只有 5,000 个示例的数据集，而训练 R1 则需要 600,000 个示例。&lt;/strong&gt; 这个过渡性模型帮助我们缩小了这一差距，并使我们能够合成生成那些极为重要的数据。&lt;/p&gt; 
&lt;p&gt;对于监督式微调（SFT）这一概念，可能你还不太熟悉，它是一种训练过程，通过向模型展示形式为提示词和正确补全的训练示例来进行。下面这个图展示了书籍《Hands-On Large Language Models》第 12 章中的一些 SFT 训练示例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e00bd1bb414511cf4a13d9225c9ed6bb7ba.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;这样，R1 模型不仅在推理任务上表现卓越，还能有效地应对其他非推理类任务。这一过程与我们之前提到的强化学习过程相似，但因为它涵盖了非推理领域的应用，所以它还引入了一个实用性奖励模型和安全性奖励模型（与 Llama 模型有相似之处），用于处理这些应用领域的提示词。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cd6bf829caa63d1804a38dcdf71e88e2293.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与 GPT2[2] 和 GPT3[3] 等同源的早期模型一样，DeepSeek-R1 也是由 Transformer[4] 解码器块堆叠而成，总共包含了 61 个这样的块。其中，前三个块是密集层，而后续的则是采用了混合专家层（MoE）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-817d8e03a6a9f616d918a3f53eb7e8bdede.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;关于模型的维度大小和其他超参数配置，具体信息如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0acee698853f2545eaf2350f4bae0ca92ea.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有关模型架构的更多详细信息，可以在他们之前发表的两篇论文中找到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V3 Technical Report[1]&lt;/li&gt; 
 &lt;li&gt;DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models[5]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 Conclusion&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;通过上述内容，相信你现在应该对 DeepSeek-R1 模型有了基本的理解。&lt;/p&gt; 
&lt;p&gt;如果你觉得需要更多基础知识来理解这篇文章，我建议你获取一本《Hands-On Large Language Models》[6]或者在线在 O&#39;Reilly[7] 上阅读，并在 Github[8] 上查看相关内容。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Jay Alammar&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Machine learning R&amp;amp;D. Builder. Writer. Visualizing artificial intelligence &amp;amp; machine learning one concept at a time. @CohereAI.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你觉得 AI 模型最难掌握的是哪种推理能力？欢迎在评论区分享你的观点👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2412.19437v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2412.19437v1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-gpt2%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-gpt2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fhow-gpt3-works-visualizations-animations%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/how-gpt3-works-visualizations-animations/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-transformer%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-transformer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2401.06066&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llm-book.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.llm-book.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearning.oreilly.com%2Flibrary%2Fview%2Fhands-on-large-language%2F9781098150952%2F&quot; target=&quot;_blank&quot;&gt;https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FhandsOnLLM%2FHands-On-Large-Language-Models&quot; target=&quot;_blank&quot;&gt;https://github.com/handsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.languagemodels.co%2Fp%2Fthe-illustrated-deepseek-r1&quot; target=&quot;_blank&quot;&gt;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17553692</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17553692</guid>
            <pubDate>Fri, 07 Feb 2025 10:19:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>豆包开源视频生成模型 VideoWorld</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmXaktIsD3w5BgCJQb6R7xQ&quot; target=&quot;_blank&quot;&gt;据豆包大模型团队官方公众号消息&lt;/a&gt;&lt;/u&gt;，在北京交通大学和中国科学技术大学的联合研究下，由豆包大模型团队提出的 「VideoWorld」 视频生成实验模型近日正式开源。&lt;/p&gt; 
&lt;p&gt;据介绍，不同于 Sora 、DALL-E 、Midjourney 等主流多模态模型，&lt;strong&gt;VideoWorld 在业界首次实现无需依赖语言模型，即可认知世界&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.09781&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.09781&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代码链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2FVideoWorld&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/VideoWorld&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmaverickren.github.io%2FVideoWorld.github.io&quot; target=&quot;_blank&quot;&gt;https://maverickren.github.io/VideoWorld.github.io&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「VideoWorld」 通过分析和处理大量视频数据，实现了复杂的推理、规划和决策能力。研究团队的实验显示，模型在仅有 300M 参数的情况下，便取得了显著的效果。与现有依赖语言或标签数据的模型不同，VideoWorld 能够独立进行知识学习，尤其在折纸、打领结等复杂任务中，能够提供更加直观的学习方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fc6aac365dbf1a8e0403b8bb24da8452019.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了验证该模型的有效性，研究团队搭建了围棋对战和机器人模拟操控两种实验环境。围棋作为一项高度策略性游戏，可以有效评估模型的规则学习和推理能力，而机器人任务则考察模型在控制和规划方面的表现。在训练阶段，模型通过观看大量视频演示数据，逐步建立起对未来画面的预测能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332996</guid>
            <pubDate>Fri, 07 Feb 2025 10:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 服务站点大全</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中国信息通信研究院去年 7 月 11 日发布国内首个算力互联公共服务平台，并联合产业界开展算力互联网共识共创行动。&lt;/p&gt; 
&lt;p&gt;该算力互联公共服务平台是推进和管理全国算力互联互通和算力互联网体系的综合服务平台，包括算力标识管理、算力互联网业务查询、算力统一大市场、政策和研究、标准体系、开源项目和运行监测等功能。&lt;/p&gt; 
&lt;p&gt;中国信通院今日宣布，为便利国内 AI 开发者「找调用算力」需求，算力互联公共服务平台宣布增设全球云服务商 DeepSeek 服务能力汇总功能页面（截至 2 月 5 日已汇集 22 家服务商）。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstateioc.cn%2Farticle-details%2FVjX&quot; target=&quot;_blank&quot;&gt;https://stateioc.cn/article-details/VjX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最后欢迎各位使用 Gitee AI —— Gitee AI 的 Serverless API 为您提供开箱即用的企业级的大模型 API 服务。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/174609_Xr4I_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332995</guid>
            <pubDate>Fri, 07 Feb 2025 09:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ai.com 域名现已跳转至 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;现在在浏览器输入&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.com%2F&quot; target=&quot;_blank&quot;&gt;ai.com&lt;/a&gt;，将直接重定向至 DeepSeek 官网 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.deepseek.com%2F&quot; target=&quot;_blank&quot;&gt;https://chat.deepseek.com/&lt;/a&gt;)。&lt;/p&gt; 
&lt;p&gt;ai.com 域名的定位被视作前沿 AI 的象征，此前这一域名曾长期跳转至 ChatGPT、谷歌 Gemini 以及马斯克的 xAI 官网。根据 Whois 数据，ai.com 域名注册于 1993 年，有效期直至 2031 年 5 月，注册联系人来自马来西亚首都吉隆坡。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;219&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ceffc7eb4acfec05d9bcabc263bf478854.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332978</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332978</guid>
            <pubDate>Fri, 07 Feb 2025 08:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>消息称软银投资 400 亿美元，取代微软成为 OpenAI 最大金主</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;消息人士向 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F07%2Fsoftbank-set-to-invest-40-billion-in-openai-at-260-billion-valuation-sources-say.html&quot; target=&quot;_blank&quot;&gt;CNBC &lt;/a&gt;透露，软银即将完成对 OpenAI 的 400 亿美元初始投资，投资前估值为 2600 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Faber 报道称软银将在未来 12 到 24 个月内支付这笔资金，这意味着 OpenAI 的投资后估值将达到 3000 亿美元，第一笔款项最快将于今年春季到账。软银最多可以筹集其中的 100 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;295&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-34a9ea12a4cc3504f16154eda1fdbbc331a.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;部分资金预计将用于 OpenAI 对 Stargate 的承诺。Stargate 是软银、OpenAI 和甲骨文公司的合资企业，由美国现任总统唐纳德-特朗普于今年 1 月宣布成立。该计划要求向美国的人工智能基础设施投资数十亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;这一轮融资也意味着软银将超越微软，成为 OpenAI 公司的最大投资者。去年 10 月，私人投资者对 OpenAI 的估值为 1570 亿美元。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332971/softbank-40-billion-openai</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332971/softbank-40-billion-openai</guid>
            <pubDate>Fri, 07 Feb 2025 08:15:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Yandex 开发并开源 Perforator，每年可为企业节省数十亿美元的服务器基础设施成本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;推出&lt;/span&gt; &lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，这是一款可以识别和评估公司整个代码库中效率低下的代码的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;帮助开发人员识别最占资源的代码部分，并提供详细的统计数据，以便后续优化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;该解决方案可以帮助企业每年减少 &lt;/span&gt;&lt;span&gt;20% &lt;/span&gt;&lt;span&gt;的 &lt;/span&gt;&lt;span&gt;CPU &lt;/span&gt;&lt;span&gt;资源使用量。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;通过利，用&lt;/span&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;span&gt;，企业可以根据公司规模节省数百万甚至数十亿美元的开支，并将资源用于进一步的创新和增长。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;可通过&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;免费访问。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;（上海，&lt;/span&gt;&lt;span&gt;2025&lt;/span&gt;&lt;span&gt;年&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;月&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;日）全球领先的科技公司 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;开发并开源了&lt;/span&gt;&lt;span&gt; Perforator&lt;/span&gt;&lt;span&gt;，这是一款用于对服务器和应用程序进行持续实时监控和分析的创新工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;帮助开发人员识别最占资源的代码部分，并提供详细的统计数据，以便进行后续优化。通过识别代码中的低效部分并支持基于配置文件的优化，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了准确的数据，使企业能够手动优化其应用程序，根据公司规模，降低基础设施成本最多可达 &lt;/span&gt;&lt;span&gt;20%&lt;/span&gt;&lt;span&gt;。这每年可能节省数百万甚至数十亿美元。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;帮助企业在不牺牲性能的情况下最大化服务器的使用效率，&lt;/span&gt;&lt;span&gt;」 Yandex &lt;/span&gt;&lt;span&gt;的高级开发人员、&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;团队负责人&lt;/span&gt;&lt;span&gt; Sergey Skvortsov &lt;/span&gt;&lt;span&gt;表示。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;企业使用&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;可以优化代码，减少服务器负载，最终降低能源和设备成本。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为什么使用 &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;Perforator&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;资源优化对于大型数据中心、大型科技公司以及资源有限的小型企业和初创公司至关重要。公司可以利用 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;优化现有的基础设施，而无需投资额外的设备，也不牺牲性能。该工具已经在 &lt;/span&gt;&lt;span&gt;Yandex &lt;/span&gt;&lt;span&gt;的许多服务中使用了超过一年，现在可以供全球的公司、开发人员和研究人员使用。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;公司可以将 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;部署在自己的服务器上，减少对外部云服务提供商的依赖，同时保持对数据的完全控制。这使得 &lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;非常适合那些对数据安全要求严格且在封闭基础设施中运营的组织。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;可以为各种规模的公司带来益处，从拥有&lt;/span&gt;&lt;span&gt; 10 &lt;/span&gt;&lt;span&gt;至&lt;/span&gt;&lt;span&gt; 100 &lt;/span&gt;&lt;span&gt;台服务器的小型企业，每年节省数百万美元，到拥有数千台服务器甚至更多的大型企业，每年节省数亿美元甚至数十亿美元，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov &lt;/span&gt;&lt;span&gt;指出。&lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;无论公司规模如何，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;都能帮助您减少基础设施成本，为进一步的创新和增长释放更多资源。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;如何工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;提供了关于服务器资源使用的详细洞察，并分析代码对性能的影响，突出了哪些应用程序消耗了最多的系统资源。&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;使用&lt;/span&gt;&lt;span&gt; eBPF &lt;/span&gt;&lt;span&gt;技术在&lt;/span&gt;&lt;span&gt; Linux &lt;/span&gt;&lt;span&gt;内核中运行小程序，既安全又不会拖慢系统速度。&lt;/span&gt;&lt;span&gt;eBPF &lt;/span&gt;&lt;span&gt;能够在不更改源代码的情况下，改善监控、安全性和性能优化。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;支持&lt;/span&gt;&lt;span&gt; C&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;C++&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Go&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Rust&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Python &lt;/span&gt;&lt;span&gt;和 &lt;/span&gt;&lt;span&gt;Java &lt;/span&gt;&lt;span&gt;等原生编程语言。该解决方案通过火焰图提供深入的分析和数据可视化，使问题诊断变得易于管理。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;287&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f866d0af24a5577182b973257c103fef72e.png&quot; width=&quot;602&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;生成的火焰图示例&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「Perforator &lt;/span&gt;&lt;span&gt;在&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;的高需求环境中经过了超过一年的实战测试，提供了广泛的功能，使其成为一款可靠且多功能的服务器性能监控和优化解决方案，&lt;/span&gt;&lt;span&gt;」 Sergey Skvortsov&lt;/span&gt;&lt;span&gt;补充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的一个关键优势是支持基于配置文件的优化（&lt;/span&gt;&lt;span&gt;PGO&lt;/span&gt;&lt;span&gt;），它能够自动将&lt;/span&gt;&lt;span&gt; C++ &lt;/span&gt;&lt;span&gt;程序的速度提高多达 &lt;/span&gt;&lt;span&gt;10%&lt;/span&gt;&lt;span&gt;。此外，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;设计可以在个别计算机上无缝运行，使其不仅适合大型企业，还能为初创公司和科技爱好者提供便利。更重要的是，&lt;/span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;为大企业提供了包括&lt;/span&gt;&lt;span&gt; A/B &lt;/span&gt;&lt;span&gt;测试功能在内的重要特性，帮助做出更明智的决策。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;为开发人员和企业提供的开源解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;将&lt;/span&gt;&lt;span&gt; Perforator &lt;/span&gt;&lt;span&gt;开源的决定体现了&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;致力于促进社区合作开发系统技术的承诺。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「我们相信，开源诸如此类基础系统的技术能够推动全球技术创新」， &lt;/span&gt;&lt;span&gt;Sergey Skvortsov&lt;/span&gt; &lt;span&gt;补充道。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;我们的目标是让我们的技术造福全球，并为开发人员和企业提供价值。此外，技术的开放性使我们能够与社区共同做出有关配置文件分析基础设施开发的决策。&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;接下来会发生什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;将在近期增加更多功能，包括与&lt;/span&gt;&lt;span&gt; Python &lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt; Java &lt;/span&gt;&lt;span&gt;的更好集成以及对事件的更精确分析。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;的源代码现已在&lt;/span&gt; &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fyandex%2Fperforator&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#1155cc&quot;&gt;GitHub&lt;/span&gt;&lt;/span&gt;&lt;/a&gt; &lt;span&gt;上公开，和其他&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;开源解决方案一起提供，如&lt;/span&gt;&lt;span&gt;YaFSDP&lt;/span&gt;&lt;span&gt;，这是一个旨在加速大语言模型训练的工具。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Perforator &lt;/span&gt;&lt;span&gt;是&lt;/span&gt;&lt;span&gt; Yandex &lt;/span&gt;&lt;span&gt;开源工具系列中的最新成员。您可以在&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopensource.yandex%2Fen%2F&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;此页面&lt;/span&gt;&lt;/a&gt;&lt;span&gt;查看该公司所有的开源项目，包括&lt;/span&gt;&lt;span&gt; YaFSDP&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;AQLM&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Ytsaurus &lt;/span&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332970</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332970</guid>
            <pubDate>Fri, 07 Feb 2025 08:14:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>GitHub Copilot：Agent 觉醒</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;本文翻译自：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.blog%2Fnews-insights%2Fproduct-news%2Fgithub-copilot-the-agent-awakens%2F&quot; target=&quot;_blank&quot;&gt;https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0ad483c840f09803ba7d525bf909fa01465.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;当我们于 2021 年推出 GitHub Copilot 时，我们有一个明确的目标：通过一个帮助开发者编写更好代码的 AI 编程助手，让开发者的生活变得更轻松。这个名字反映了我们的信念，即人工智能（AI）不会取代开发者。相反，它始终站在开发者身边。而且，就像任何优秀的副驾驶一样，Copilot 也可以独立飞行：例如，在提供 PR 回复、自动修复安全漏洞或头脑风暴如何实现问题解决方案时。&lt;/p&gt; 
&lt;p&gt;今天，我们用更加强大的&lt;strong&gt;代理式人工智能 (agentic AI)&lt;/strong&gt;升级了&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Ffeatures%2Fcopilot%2Fwhats-new%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblogtop%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;GitHub Copilot&lt;/a&gt;——推出&lt;strong&gt;代理模式 (agent mode)&lt;/strong&gt;，并发布 Copilot Edits 的 GA 版本，两者均已在 VS Code 中上线。&lt;/p&gt; 
&lt;p&gt;我们在模型选择器中为所有 Copilot 用户增加了 Gemini 2.0 Flash。我们还首次展示了 Copilot 的新自主代理，代号为 Project Padawan。从代码补全、聊天、多文件编辑到工作空间和代理，Copilot 将人类置于软件开发这一创造性工作的中心。AI 帮助处理你不想做的事情，这样你就有更多时间做自己想做的事情。&lt;/p&gt; 
&lt;h2&gt;代理模式 (Agent mode) 进入预览阶段&lt;/h2&gt; 
&lt;p&gt;GitHub Copilot 的新代理模式能够迭代自己的代码，识别错误并自动修复。它可以建议终端命令并要求您执行它们。它还可以分析运行时错误并具有自我修复功能。&lt;/p&gt; 
&lt;p&gt;在代理模式下，Copilot 不仅会迭代自己的输出，还会迭代输出结果。它会一直迭代，直到完成所有必要的子任务以完成您的提示。现在，Copilot 不仅能够执行您请求的任务，还能够推断出一些未指定但也是实现主要请求所必需的额外任务。更好的是，它能够捕捉到自己的错误，让您无需从终端复制/粘贴回聊天中。&lt;/p&gt; 
&lt;p&gt;以下是一个示例，展示了 GitHub Copilot 如何构建一个用于跟踪马拉松训练的 Web 应用程序：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fof--3Fq1M3w%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/of--3Fq1M3w?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;要开始使用，您需要下载 VS Code Insiders，然后为 GitHub Copilot Chat 启用代理模式设置：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ba42dfaaf982a3e645b4436884e52e9dbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;然后，在 Copilot 编辑面板中，从「编辑」切换到模型选择器旁边的「Agent」：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/113603_Wgac_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;代理模式将改变开发者在使用编辑器时的工作方式；因此，我们将其带给 Copilot 支持的所有 IDE。我们也知道今天的 Insiders 版本并不完美，并欢迎您在接下来的几个月里提供反馈，以便我们改进 VS Code 和底层代理技术。&lt;/p&gt; 
&lt;h2&gt;Copilot Edits 在 VS Code 中已正式 GA&lt;/h2&gt; 
&lt;p&gt;去年 10 月在 GitHub Universe 上宣布的 Copilot Edits，结合了 Chat 和 Inline Chat 的优点，具有对话流程和能够在您管理的文件集中进行行内更改的能力。&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F95&quot; target=&quot;_blank&quot;&gt;您之前提供的反馈&lt;/a&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%2Fissues%2F1098&quot; target=&quot;_blank&quot;&gt;在 GitHub Universe 上&lt;/a&gt;对于将此功能作为 GA 版本发布到 VS Code 至关重要。感谢！&lt;/p&gt; 
&lt;p&gt;在 Copilot Edits 中，您指定要编辑的一组文件，然后使用自然语言向 GitHub Copilot 提出您所需的内容。Copilot Edits 通过为快速迭代设计的 UI，在您的代码空间中对多个文件进行行内更改。在审查建议的更改、接受可行的更改并进行后续询问时，您始终保持在代码的流程中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c40d04de582b53363ee3ddcdea11b12a89a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在这背后，Copilot Edits 利用双模型架构来提升编辑效率和准确性。首先，一个基础语言模型会考虑 Edits 会话的完整上下文来生成初始编辑建议。您可以在以下基础语言模型中选择您偏好的一个：OpenAI 的 GPT-4o、o1、o3-mini、Anthropic 的 Claude 3.5 Sonnet，以及现在新增的 Google 的 Gemini 2.0 Flash。为了获得最佳体验，我们开发了一个推测性解码端点，针对快速应用文件中的更改进行了优化。基础模型提出的编辑建议会被发送到推测性解码端点，该端点随后将在编辑器中直接提出这些更改。&lt;/p&gt; 
&lt;p&gt;Copilot Edits 之所以有效，是因为它将控制权交给了您，从设置正确上下文到接受更改。整个过程是迭代的：当模型出错时，您可以审查多个文件中的更改，接受好的更改并迭代，直到与 Copilot 一起找到正确的解决方案。接受更改后，您可以运行代码以验证更改，并在需要时在 Copilot Edits 中撤销更改，以回到先前的有效工作状态。Copilot Edits 位于次级侧边栏（默认位于右侧），这样您在审查建议的更改时可以与主侧边栏中的视图（如资源管理器、调试或源代码控制视图）进行交互。例如，您可以在左侧的&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Ftesting&quot; target=&quot;_blank&quot;&gt;测试视图中&lt;/a&gt;运行单元测试，同时使用右侧的 Copilot Edits 视图，这样在每次迭代中，您都可以验证 Copilot Edits 提出的更改是否通过了您的单元测试。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fdocs%2Feditor%2Fvoice&quot; target=&quot;_blank&quot;&gt;通过语音&lt;/a&gt;在使用 Copilot 修改时是一种自然的体验。只需与 Copilot 对话，就能使互动变得顺畅且具有对话性。这几乎就像是与一位在该领域具有专业知识的同事互动，使用你在现实生活中结对编程时相同的迭代流程。&lt;/p&gt; 
&lt;p&gt;接下来在我们的路线图上，我们将改进「应用更改」的投机解码端点性能，支持从 Copilot Chat 过渡到 Copilot Edits，通过保留上下文来实现，向工作集建议文件，并允许您撤销建议的块。如果您想成为第一批体验这些改进的人，请确保使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Finsiders%2F&quot; target=&quot;_blank&quot;&gt;VS Code Insiders&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat&quot; target=&quot;_blank&quot;&gt;GitHub Copilot Chat&lt;/a&gt;扩展的预发布版本。为了帮助我们改进这个功能，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-release%3Futm_source%3Dagent-awakens-announcement%26utm_medium%3Dblog%26utm_campaign%3Dagentic-ai&quot; target=&quot;_blank&quot;&gt;请在我们的仓库中提交问题&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;除了 VS Code 的 GA 之外，Copilot Edits 现在也在 Visual Studio 2022 中处于预览阶段。&lt;/p&gt; 
&lt;h2&gt;Padawan 项目：GitHub 上的 SWE 代理&lt;/h2&gt; 
&lt;p&gt;我们激动地与大家分享我们自主开发的 SWE（软件工程师）智能代理，以及我们设想这类代理将如何融入 GitHub 用户体验。&lt;/p&gt; 
&lt;p&gt;当我们在代号 Project Padawan 的产品今年晚些时候发布时，您将可以直接将问题分配给 GitHub Copilot，使用任何 GitHub 客户端，并让它生成经过全面测试的拉取请求。一旦任务完成，Copilot 将指派人类审阅者对 PR 进行审核，并努力解决他们提出的反馈。从某种意义上说，这就像将 Copilot 作为贡献者引入 GitHub 上的每一个仓库。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/114025_eVHJ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.youtube.com%2Fembed%2FVWvV2-XwBMM%3Ffeature%3Doembed&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/embed/VWvV2-XwBMM?feature=oembed&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;该功能背后，Copilot 会为分配给它的每个任务自动启动一个安全的云沙盒。然后它异步克隆仓库，设置环境，分析代码库，编辑必要的文件，并构建、测试和检查代码。此外，Copilot 还会考虑问题或 PR 中的任何讨论，以及仓库中的任何自定义指令，以便它理解任务的全貌意图，以及项目的指南和约定。&lt;/p&gt; 
&lt;p&gt;就像我们之前在 Copilot 扩展和 Copilot 模型选择器中做的那样，我们也将提供机会将集成到这个 AI 原生工作流程中，并与合作伙伴和客户紧密合作，形成一个紧密的反馈循环。我们相信 Project Padawan 的最终状态将改变团队管理关键但日常任务的方式，例如修复错误或创建和维护自动化测试。因为最终，一切都是关于通过让他们专注于重要的事情来赋予开发者力量，并让协作者做其余的工作。别担心，我们会保持耐心，所以代理不会「黑化」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332928/github-copilot-the-agent-awakens</guid>
            <pubDate>Fri, 07 Feb 2025 03:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV 社区动态 2025 年 1 月</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2025 年 1 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 1 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;1 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文： Rate-Aware Learned Speech Compression（RWKV 语音压缩）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV-UNet（RWKV 医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文： FSSC（RWKV 触觉传感跨域适应）&lt;/li&gt; 
   &lt;li&gt;新论文： TRP（RWKV 知识图谱补全）&lt;/li&gt; 
   &lt;li&gt;新论文： TCVADS（RWKV 视频异常检测）&lt;/li&gt; 
   &lt;li&gt;新论文： RWKV Voice Dialog System（RWKV 语音对话系统）&lt;/li&gt; 
   &lt;li&gt;新论文： Visualrwkv-Hm（RWKV 视觉语言模型）&lt;/li&gt; 
   &lt;li&gt;新论文： AutoGMM-RWKV（RWKV 无线传感器网络安全）&lt;/li&gt; 
   &lt;li&gt;新论文： Revenge of the Fallen?（RWKV 语言理解对比研究）&lt;/li&gt; 
   &lt;li&gt;新论文： Enhancing Transformer RNNs（RWKV 多时间视角增强）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新模型： RKWV-7-1.5B&lt;/li&gt; 
   &lt;li&gt;新模型： RKWV-7-0.4B&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 创始人闭门会开启报名&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区项目动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV Othello&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括&lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt;或 &lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;Rate-Aware Learned Speech Compression&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Rate-Aware Learned Speech Compression&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.11999&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.11999&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文提出了一种基于通道感知熵模型的学习语音压缩方案，该方案通过替换传统的量化器来增强率失真性能。它利用多尺度卷积和 RWKV 混合块来提高编码器和解码器的表示能力。&lt;/p&gt; 
&lt;p&gt;实验结果表明，与现有编解码器相比，提出的方法在比特率节省和声学质量指标方面取得了显著改善。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4f7caaf051f652da78952613f6f383bf0d0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-UNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：RWKV-UNet: Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 RWKV-UNet，它将 RWKV 结构融入 U-Net 用于医学图像分割。通过 IR-RWKV 模块增强长距离依赖捕获能力，结合 CCM 模块改善跳跃连接。&lt;/p&gt; 
&lt;p&gt;实验表明，RWKV-UNet 在多个数据集上取得 SOTA 性能，平衡了性能和效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ba61005fb424e4a90b230f40c5da963eedd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;FSSC&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Reducing Cross-Sensor Domain Gaps in Tactile Sensing via Few-Sample-Driven Style-to-Content Unsupervised Domain Adaptation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F1424-8220%2F25%2F1%2F256&quot; target=&quot;_blank&quot;&gt;https://www.mdpi.com/1424-8220/25/1/256&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-01-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文介绍了 FSSC，一种全新的 few-sample-driven style-to-content 无监督域适应方法。它采用基于 RWKV 架构的设计来应对跨传感器域适应中的难题，例如传感器差异导致的域差距等问题。借助 GLAB 层、FST 模块等重要组件，它达成了有效减少触觉传感跨传感器域差距的目标。&lt;/p&gt; 
&lt;p&gt;实验表明，FSSC 在跨传感器域适应任务的准确性以及对少量样本的利用效率上均超越了现有的先进方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c9929c53128b28220a6b2be13e7004e05d5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Knowledge Graph Completion&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Efficient Relational Context Perception for Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.00397&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.00397&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-31&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;文提出一种用于知识图谱补全的新方法，它采用受 Rwkv 启发的 Triple Receptance Perception (TRP) 架构来解决先前知识图谱嵌入模型的缺点，如表达能力有限、计算成本高等问题。通过 TRP 中的时间混合和通道混合模块等关键要素，它实现了高效且高质量的知识图谱补全。&lt;/p&gt; 
&lt;p&gt;实验表明，该方法在链接预测和三元分类任务方面都优于最先进的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-651119224e074229f55231cb42a9b12bc21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;TCVADS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Injecting Explainability and Lightweight Design into Weakly Supervised Video Anomaly Detection Systems&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2412.20201&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2412.20201&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-12-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文介绍了一种名为 TCVADS 的视频异常检测系统。该系统采用两个阶段的运行模式。在第一阶段，系统使用增强的 RWKV 模块来进行高效的时间序列分析。通过结合知识蒸馏和跨模态学习技术，TCVADS 在性能上优于现有的方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7948ea9998ad0a372ce2ede11942518b7bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV Voice Dialog System&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Voice dialog system based on RWKV model&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10762107&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10762107&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-11-28&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出开发一个面向老年人的智能语音对话系统，采用经 LoRA 微调的 RWKV 模型。实验结果表明它提高了答案的流畅性和合理性，在老年护理方面有应用潜力，未来工作会对模型进行优化。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b9cb2625db793016ac552cb831c4bb0a7a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Visualrwkv-Hm&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Visualrwkv-Hm: Enhancing Linear Visual-Language Models Via Hybrid Mixing&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5028149&quot; target=&quot;_blank&quot;&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5028149&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-11-21&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出 VisualRWKV-HM，这是一种线性复杂度的视觉语言模型。它基于 RWKV 整合了时间和跨状态混合。在多个基准测试上达到了 SOTA，在 24K 上下文时比 LLaVA-1.5 等模型效率更高，还展现出强大的可扩展性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d60804f11cb6f97d2d77b7d9b04c8202f47.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AutoGMM-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：AutoGMM-RWKV: A Detecting Scheme Based on Attention Mechanisms Against Selective Forwarding Attacks in Wireless Sensor Networks&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F10729884&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/abstract/document/10729884&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-10-23&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了 AutoGMM-RWKV 用于检测无线传感器网络中的选择性转发攻击。它聚焦于节点单轮转发率时间序列，通过将自编码器、高斯混合模型和 K - 均值与 RWKV 相结合，提高了检测精度。模拟结果显示误检率和漏检率较低，提供了一个可靠的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ca49954aa5387686e8d7257714795a83744.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Revenge of the Fallen?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.19178&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.19178&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-08-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出，在语言任务中，Transformer 一直占据主导地位，但近期 RWKV 等循环模型出现。本文表明像 RWKV 这样的当代循环模型在模拟人类语言理解方面能够与 Transformer 相媲美甚至超越它们，开启了新的研究方向。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-950085a35252d8db50bb7a763699263aacf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Enhancing Transformer RNNs with Multiple Temporal Perspectives&lt;/li&gt; 
 &lt;li&gt;论文链接：https://arxiv.org/abs/2402.02625&lt;/li&gt; 
 &lt;li&gt;发布日期：2024-07-11&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出多时间视角概念以增强循环神经网络（RNN）。将其应用于 RWKV 模型时，能以极少的参数增加丰富上下文理解。实证结果验证了其有效性，在基准测试中表现提升且保持线性推理复杂度。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a57d07d01cf1ad8f5a65263282fa35c72d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 模型动态&lt;/h2&gt; 
&lt;h3&gt;新模型： RKWV-7-1.5B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-1.5B-v3 模型于 2025 年 1 月 28 日正式发布！&lt;/p&gt; 
&lt;p&gt;RWKV-7-1.5B 模型基于 RWKV World v3 数据集（共 3.1T 数据）训练而来。在英文和多语言评测中，RWKV-7-1.5B 模型的评分对比其他同参数模型处于&lt;strong&gt;绝对领先&lt;/strong&gt;地位。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-56b7f8f2ab08a6d01054853563dd460ec50.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;新模型： RKWV-7-0.4B&lt;/h3&gt; 
&lt;p&gt;RWKV-7-World-0.4B-v2.9 模型于 2025 年 1 月 8 日正式发布！&lt;/p&gt; 
&lt;p&gt;RWKV-7-World-0.4B 在 world-2.9（从 world-v3 数据集中采样 2T tokens）数据集上训练。其英文和多语言能力&lt;strong&gt;显著超越其他 0.4B 模型&lt;/strong&gt;，且支持全球 100+ 种语言和代码。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-88a64b43559f9bbfd783387587d05122cf5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社区活动&lt;/h2&gt; 
&lt;p&gt;此版块包含 &lt;strong&gt;RWKV 官方动态&lt;/strong&gt;，以及 &lt;strong&gt;RWKV 社区举办或参加的各类活动&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;RWKV 创始人闭门会开启报名&lt;/h3&gt; 
&lt;p&gt;2 月 21 日晚 7 点，将在上海组织 「RWKV-7 与未来趋势「 的闭门会。&lt;/p&gt; 
&lt;p&gt;RWKV 创始人彭博会线下参加，欢迎 RWKV 开发者、感兴趣的业内人士扫码报名🤝&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c23a88285bae005e1f5e9a0b05360a9ec7b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;RWKV 社区项目动态&lt;/h2&gt; 
&lt;h3&gt;RWKV Othello&lt;/h3&gt; 
&lt;p&gt;RWKV 社区成员 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042&quot; target=&quot;_blank&quot;&gt;@Jellyfish042&lt;/a&gt; 基于 RWKV-7 架构开发了 RWKV Othello 项目。&lt;/p&gt; 
&lt;p&gt;项目 GitHub 仓库： &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FJellyfish042%2FRWKV_Othello&quot; target=&quot;_blank&quot;&gt;https://github.com/Jellyfish042/RWKV_Othello&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;RWKV Othello 项目利用 Othello（也称为反转棋或黑白棋）的 CoT 数据训练了仅 8.8M 参数的 RWKV-7-Othello 模型。&lt;/p&gt; 
&lt;p&gt;RWKV-7-Othello 模型可以和人类或其他模型自动对战 Othello 游戏，且在与人类对战时实现了非常高的胜率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5cdd352820faef98513bceb46e59e9a65b4.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332925</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332925</guid>
            <pubDate>Fri, 07 Feb 2025 03:36:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
    </channel>
</rss>