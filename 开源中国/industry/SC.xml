<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Jul 2025 16:45:46 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>Iceberg 在图灵落地应用</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;百度 MEG 上一代大数据产品存在平台分散、易用性差等问题，导致开发效率低下、学习成本高，业务需求响应迟缓。为了解决这些问题，百度 MEG 内部开发了图灵 3.0 生态系统，包括 Turing Data Engine(TDE) 计算&amp;amp;存储引擎、Turing Data Studio(TDS) 数据开发治理平台和 Turing Data Analysis(TDA) 可视化 BI 产品。依托图灵 3.0 生态，我们引入了数据湖表格式：Apache Iceberg，利用其特性并在多种业务场景下进行优化实践，解决图灵数仓业务实时数据入湖，数据表历史记录更新效率低等多个痛点问题。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 图灵 3.0 生态概述&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;由于百度 MEG 上一代大数据产品存在平台多、易用性差及数据流转繁琐等问题。这些问题导致开发人员研发效率低及多平台间高昂的学习成本；业务部门的感知则是需求交付迟缓、数据产出延迟及数据质量低等问题。为了解决上述问题，我们构建了新一代大数据解决方案——"图灵 3.0"，旨在覆盖数据全生命周期，支持全链路数据操作，提供高效敏捷且统一的强大数据生态系统，其中包括数据计算引擎、数据开发和数据分析三个核心部分：&lt;/p&gt; 
&lt;p&gt;1. TDE（Turing Data Engine）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247581388%26idx%3D1%26sn%3De71a4f3c4ca283ac6e8fe51d0a45a02b%26scene%3D21%23wechat_redirect" target="_blank"&gt;图灵生态的计算引擎&lt;/a&gt;，包含基于 Hive、Iceberg 进行数据处理的 Spark 和&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247601378%26idx%3D1%26sn%3D9234aeef05c3813cfb34d9a064261984%26scene%3D21%23wechat_redirect" target="_blank"&gt;ClickHouse 高性能计算引擎&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;2. TDS（Turing Data Studio）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247599508%26idx%3D1%26sn%3D19094522609ca58528295a8ccbb061bd%26scene%3D21%23wechat_redirect" target="_blank"&gt;一站式数据开发治理平台&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;3. TDA（Turing Data Analysis）：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247584876%26idx%3D1%26sn%3D7bf459415ef8d51685d4e1c335b0603e%26scene%3D21%23wechat_redirect" target="_blank"&gt;新一代可视化 BI 产品&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;本文主要介绍数据湖表格式 Iceberg 在图灵 3.0 生态下的应用与实践。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1764b56858226d39002905e95ec9f32e1d2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△图灵 3.0 生态产品&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2 问题&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;MEG 数据中台基于 Hive 构建了离线数据仓库，已支持手百，搜索，商业，贴吧，小说，用增架构，销售等多个业务需求，但随着业务的发展，业务对数据的实时性以及查询性能等有更高要求，当前主要存在以下几个问题：&lt;/p&gt; 
&lt;p&gt;1. 商业、电商、销售等业务，周期性地更新行业等信息，单次更新数据量占比小、字段少，但是基于 Hive 的数据更新（以下简称：数据回溯）只能通过全量覆盖写的方式实现，数据回溯周期长、效率低、成本高。&lt;/p&gt; 
&lt;p&gt;2. 由于 Hive 在实时数据更新以及事务支持上存在一定局限性，无法有效满足业务构建实时数仓的需求。&lt;/p&gt; 
&lt;p&gt;3. 在处理大规模数据集上，Hive 的查询性能受到如元数据的加载解析以及每次访问数据都需通过分布式文件系统 listFile 遍历文件列表等问题的影响，导致性能降低。&lt;/p&gt; 
&lt;p&gt;基于上述问题，我们通过技术调研，最终引入了开源的数据湖表格式 Iceberg，构建数据湖存储服务，并借助大数据生态的 Spark、Flink 等计算引擎来实现数据湖的分析，将其无缝集成到图灵生态中，帮助业务提效降本，构建更快速、更高效、更低成本的数据中台产品。&lt;/p&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.3 Hive 和 Iceberg 对比&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Hive 作为一个基于 Hadoop 生态系统的开源数据仓库工具，主要用于对大规模结构化数据进行存储、查询和分析。而 Iceberg 作为新一代数据湖表格式，提供了类似传统数据库的事务性，保证和数据一致性，并支持复杂的数据操作，如行级更新和删除等，更加适合实时更新，流批一体数据场景，下表列出 Hive 和 Iceberg 一些主要特性对比：&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Hive&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;Iceberg&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;行级更新&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;不支持&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持 merge into、&lt;/span&gt; 
         &lt;span&gt;upsert&lt;/span&gt; 
         &lt;span&gt;等语法进行行级别更新能力&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;时效性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;小时级别/天级&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;分钟级&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;事务&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;非完整的 ACID 事务&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持完整的 ACID 事务，同时使用多快照提供了读写分离的特性&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;元数据管理方式&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;基于 Mysql 进行元数据存储&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;通过文件组织管理，直接存储数据文件元数据&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;数据版本控制&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;无&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:middle"&gt; 
       &lt;div&gt; 
        &lt;div style="text-align:center"&gt; 
         &lt;span&gt;支持时间旅⾏(Time travel) 特性，可基于快照进行历史数据版本管理和访问&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.4 Iceberg 的组织结构&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Iceberg 文件组织分为元数据层和数据层，主要包含 version-hint，metadata file、snapshot file、manifest file 和 data file 文件类型，具体如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;metadata 元数据层&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;a. version-hint：该文件作为元数据索引初始文件，记录了 Iceberg 表的版本号，通过版本号找到对应的 metadata file。&lt;/p&gt; 
&lt;p&gt;b. metadata file：记录了 Iceberg 表的 schemas、properties 以及快照等信息。&lt;/p&gt; 
&lt;p&gt;c. snapshot file（manifest-list）：每次数据 commit 会生成一个新的快照，保存了该快照下每个 manifest file 路径及对应的分区范围。&lt;/p&gt; 
&lt;p&gt;d. manifest file：记录数据文件元信息，包含每个数据文件的路径、文件的大小等一系列统计信息（如文件每列的最大最小值、空值数等），实现元数据和数据文件的关联。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;data 数据层&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;data file：实际的数据文件，以 parquet 等列存格式存储数据。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f4a0f78b290db1caccb1aa213d0eb2ebc13.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表结构&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f506fa444f1e285b84c15e9adb1fd379988.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 文件组织结构&lt;/p&gt; 
&lt;p&gt;通过上述 Iceberg 元数据文件组织结构，Iceberg 实现了文件级的元信息统计及版本化管理。&lt;/p&gt; 
&lt;span id="OSC_h1_7"&gt;&lt;/span&gt; 
&lt;h1&gt;02 Iceberg 能力建设与应用&lt;/h1&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 图灵生态能力适配&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1 统一元数据服务&lt;/h3&gt; 
&lt;p&gt;由于原生 iceberg 缺少元数据的可视化管理能力，我们通过构建统一的元数据微服务，将 Iceberg 表和 Hive 表元数据进行管理，对应用层提供相关表和分区的增删改查等接口，统一数据存储的元数据操作入口。&lt;/p&gt; 
&lt;p&gt;该微服务主要包含常驻 SparkSession 模块，EngineMetaService 模块和元数据模块，通过将 SparkSession 常驻，为用户提供 Iceberg 表和 Hive 表元数据和分区数据的增删改查功能，以及可视化的元数据管理界面。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-76e46b4f67c2c75cd8176866ca4893e5c2e.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△统一元数据服务架构&lt;/p&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.2 打通 Iceberg 和 Hive 联邦查询&lt;/h3&gt; 
&lt;p&gt;为了兼容历史业务存量 Hive 表，同时降低用户使用 Iceberg 的成本。我们在计算引擎层面打通 Iceberg 和 Hive 联邦查询能力，并保证了 Iceberg 表与原有方式语法一致。&lt;/p&gt; 
&lt;p&gt;通常在一条 SQL 执行过程中，主要可简化以下 Parse、Analyzer、Optimizer、CBO 四个流程。通过在 Analyzer 和 Plan 阶段进行改进优化，来打通 Iceberg 和 Hive 表联邦查询。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Analyzer 阶段：该阶段主要是将 spark 未解析的逻辑计划进行解析，我们通过对 SparkSessionCatalog 加载方式改造，优先加载 iceberg 表使用的 catalog 类型，如果用户 SQL 使用的是 Iceberg 表，则对应会使用 IcebergCatalog 和 iceberg 数据源访问，否则使用 SessionCatalog 与 Hive 数据源访问。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Optimizer 阶段：为加强数据安全管理，我们进一步打通 Iceberg 表鉴权能力，在基于逻辑计划生成物理计划阶段，解析注入表、字段信息以及表操作类型规则，并与公司内数管平台交互，实现对 Iceberg 表和字段的鉴权&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a5292d689d944eafa1fc34ca2637e610b9f.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 和 Hive 联邦查询适配流程&lt;/p&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 存量 Hive 低成本迁移 Iceberg&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;现有数仓业务数据主要存储于 Hive 表，为支持业务快速切换 Iceberg 应用新技术，我们建设了存量 Hive 表低成本迁移至 Iceberg 表的能力。&lt;/p&gt; 
&lt;p&gt;以下是在实践过程中的两种迁移方案对比：&lt;/p&gt; 
&lt;p&gt;方式 1：使用 Iceberg 功能 migrate 进行原地迁移，通过社区提供的 CALL migrate 语法，直接执行如下示例的 SQL 语句，即可将 Hive 表升级为 Iceberg 表。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CALL&amp;nbsp;catalog_name.system.migrate('db.sample', map('foo',&amp;nbsp;'bar'));﻿


&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;该方案操作简单且可回滚，但这种方式在图灵生态落地过程中也存在一些问题：&lt;/p&gt; 
&lt;p&gt;该方式会基于原 Hive 表的数据信息构建 Iceberg 元数据信息，并将原 Hive 表名重命名为 sample_backup_，同时数据路径也进行重命名。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;下游无法读：在执行迁移过程中，原 Hive 表对应的路径已经被重命名，进而导致下游业务无法正常读取正在迁移中的表。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多表挂载冲突：在业务的使用场景中，存在同一份物理数据被多个 Hive 表挂载可能，直接修改路径会导致其他表失效。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;方式 2：基于上述问题，我们进一步对现有方案进行优化，不改变 Hive 表原有的数据路径，来实现 Hive 低成本迁移 Iceberg，具体流程如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;构建 Iceberg 元数据：直接复用 Hive 的分区数据，新建同名的 Iceberg 表，并重建 Iceberg 元数据，最终新 Iceberg 表的元数据信息实际指向是 Hive 分区数据存储位置。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据校验：当 Iceberg 元数据构建完成后，查询 Iceberg 表中字段数据，和迁移之前 Hive 表字段数据，进行一致性校验，验证迁移是否符合预期。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;读写切换：数据校验完成后，我们只需要将对应表的属性更新为 Iceberg。因为我们已经打通了 Iceberg 和 Hive 的查询，且迁移后表名未变，业务可正常使用原有表名及语法进行查询和写入，降低迁移成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-eea52f5d044ee6bc0ba16749ae9f4589492.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Hive 迁移 Iceberg 整体实现流程&lt;/p&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 Iceberg 在图灵的应用和性能优化&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_13"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.1 图灵实时数仓应用&lt;/h3&gt; 
&lt;p&gt;在图灵数仓大部分场景中，用户主要依托天级或小时级运行的离线 Spark 任务来完成数据入仓。在这种模式下，难以满足部分对数据实时性要求较高的需求。&lt;/p&gt; 
&lt;p&gt;为解决该问题，我们基于 Iceberg+Flink 构建的图灵实时湖仓架构，整体重构流程如下图所示。该架构模式实现了数据分钟级别实时入仓，显著提升了数据入仓的时效性。进一步扩展了整个图灵的应用场景。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;针对数据分析和 case 排查等场景，业务可基于图灵常驻计算引擎进行实时查询，快速获取所需要的数据支持业务分析决策；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对策略迭代、特征生产以及机器学习等复杂计算场景，可基于 spark 例行任务进行加工生产；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对策略数据调研分析、科学计算等复杂场景通过数据交互计算引擎 Jupyter 进行数据计算。通过构建图灵实时湖仓架构，既保证了数据分析的时效性又兼顾了复杂计算任务的处理能力，有效提升了业务的数据处理效率和分析决策能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-fabfc35e204c90fdf9ccd937438c044d8c6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△图灵实时湖仓架构演变&lt;/p&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.2 行级更新策略&lt;/h3&gt; 
&lt;p&gt;在图灵数仓业务场景下，商业、搜索、电商、销售等业务，周期性地更新行业等信息。而 Hive 在该场景下支持相对较弱，需通过全量覆盖写方式刷新数据，这种方式在大数据量场景下，回溯数据周期长，消耗资源大，所需要的人力时间成本也高。我们通过利用 Iceberg 行级更新的特性，基于 update、merge into 等方式回溯进行字段变更，能够很大程度的提高回溯效率，降低资源和人力成本。&lt;/p&gt; 
&lt;p&gt;针对数据行级更新，Iceberg 提供了两种策略，分别为 COW(Copy on Write： 写时复制) 或 MOR (Merge on Read：读时合并)，其中 MOR 根据其标记删除文件的区别又细分了两种方式（Equality Delete File 和 Position Delete File）。&lt;/p&gt; 
&lt;div&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;table border="1" cellspacing="0" style="border-collapse:collapse; border:1px solid #dcdde0"&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新策略&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新后的读取效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;更新时写入效率&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;适用场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="background-color:#d5e7fb; border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;备注&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;COW&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最慢&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读多写少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;﻿&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 标记条件删除（&lt;/span&gt; 
         &lt;span&gt;&lt;span style="color:#191b1f"&gt;&lt;span&gt;Equality Delete File&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 
         &lt;span&gt;）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;较快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;最快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写入多、读取少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读开销：每次读取数据需要额外读取标记删除列数据进行比较。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写开销：只需要存储标记过滤数据的条件，写入成本极低。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;MOR 标记位置删除（Position Delete File）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;快（依赖更新数据量）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;较快&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;少量数据更新、读取少场景&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
      &lt;td colspan="1" rowspan="1" style="border-style:solid; border-width:1px; vertical-align:top"&gt; 
       &lt;div&gt; 
        &lt;div&gt; 
         &lt;span&gt;读开销：加载每个文件需过滤的数据行号。（删除行过多，影响性能）&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
        &lt;div&gt; 
         &lt;span&gt;写开销：需要扫描一遍原数据，找出待删除数据的行号。&lt;/span&gt; 
         &lt;div&gt;
           &amp;nbsp; 
         &lt;/div&gt; 
        &lt;/div&gt; 
       &lt;/div&gt; &lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
  &lt;/div&gt; 
  &lt;div&gt;
    &amp;nbsp; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;﻿&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;关于 COW 和 MOR 更新策略的文件表现形式如下图所示，我们针对不同场景采用不同更新策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对于日常数据查询分析场景，小时级&amp;amp;天级离线例行生成加工场景，由于查询次数会远多于数据更新次数，可默认采用 COW 策略；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;针对一些业务更新少量字段进行长周期回溯场景，以及实时场景，写入频繁，通过使用 MOR 策略，来支持用户进行数据回溯变更字段信息，以提升数据更新效率并节省资源。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-082e448b69e5bbdb64cc8dbc417fdcbe04d.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△COW 和 MOR 两种更新策略对比&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-45b92197037fdcbd76356145ee09137730c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△MOR 两种删除文件类型&amp;amp;更新字段示例&lt;/p&gt; 
&lt;p&gt;在业务进行数据回溯应用过程中，我们采用 MOR(Position Delete File) 进行行级数据更新，通过原 Hive 回溯和新 Iceberg 回溯两种方式对比，在一天 24 小时不同分区上，验证了 Hive 和 Iceberg 新旧的回溯效率，如下图所示，业务回溯效率整体可平均提升 50%+；进一步地对比单次回溯一年数据消耗的计算资源量对比，平均整体降低 70%+的计算资源消耗，整体上极大提升回溯效率，并降低资源成本。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ec2f7bfd27359aea682e96ed16bd8438b28.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△ Hive 和 Iceberg 回溯效率对比&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;2.3.3 Iceberg 表生命周期管理和性能优化&lt;/h3&gt; 
&lt;p&gt;在 Iceberg 应用实践的过程中，针对不同业务场景遇到的问题，我们汇总如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件过多：在实时湖仓业务场景，为了要保证数据的时效性，通常是分钟级别的 commit 操作，在这种场景下，单个作业执行一天，则需要 1440 个 commit，如果执行时间更长，则会产生更多的 commit，随着时间的累积，元数据以及数据文件等都会产生大量的小文件，对于整体查询的性能会产生一定的影响。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;存储资源增加：如果 iceberg 表的快照不及时进行清理，可能会造成数据存储增加，导致存储账号资源紧张。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;缺乏分区数据统一管理：在一些业务场景，只需要保存一定天数的分区数据，针对无用数据需要进行删除处理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据文件组织不均衡且无序：由于表数据写入是随机无序，且针对表数据文件大小会存在不均衡的情况。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;针对上述问题，我们通过对 Iceberg 表进行全生命周期管理，并结合 Iceberg 特性优化表查询性能，保障整个数据链路的稳定性，整体框架如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-6f3d4d018567c082ed09d5addc93eb145e6.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表生命周期管理和性能优化流程&lt;/p&gt; 
&lt;p&gt;以上流程主要包含表数据生命周期管理和表性能优化两部分。&lt;/p&gt; 
&lt;p&gt;一方面，对于表数据生命周期管理，我们通过在线服务执行定时任务，来实现对表数据和元数据进行全生命周期监控，具体如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;数据分区过期：基于用户配置的表生命周期，进行分区数据删除，保证数据文件按期清理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元数据快照清理：为用户提供按照时间维度天级别和按照个数维度小时级别两种快照过期策略，精细化元数据快照过期处理，实现存储资源的高效利用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;元数据孤儿文件清理：通过天级例行任务来触发清理由于计算引擎执行任务失败等情况产生的一些没有被引用的孤儿文件，避免元数据累积影响性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;另一方面，在表性能优化方面，我们结合图灵数仓表使用情况，并基于 Iceberg 原生特性，为用户在平台侧提供 Iceberg 表优化算子（如下图示例），主要包含以下两种能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;小文件合并：通过制定合并文件大小，对表数据文件进行重写合并，避免产生大量小文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;z-order 排序优化：实现对表相关字段进行重排序，提升查询性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-ba76a39d6a2f835b0d8fb1866416f21a652.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;△Iceberg 表优化算子任务创建示例&lt;/p&gt; 
&lt;p&gt;我们通过对 Iceberg 表整体的生命周期管理，实现了数据和元数据的统一治理，表元数据小文件数万个降低到数百级别，合理控制了元数据产生的数量，并解决了数据频繁回溯场景下存储快速增加的问题。而在表查询优化方面，通过在一些表的数据重分布和字段重排序应用，在部分业务表查询性能提速 50%。&lt;/p&gt; 
&lt;span id="OSC_h1_16"&gt;&lt;/span&gt; 
&lt;h1&gt;03 未来规划&lt;/h1&gt; 
&lt;p&gt;Iceberg 作为图灵 3.0 生态中的重要组成部分，基于其高时效性、行级更新能力、小文件合并以及 Z-order 等成体系的数据优化的技术解决方案，为 MEG 数据中台业务提供构建湖仓一体，解决数据回溯等痛点问题的能力。目前 Iceberg 的应用已覆盖搜索，商业，销售，用增架构等多个业务线，通过低成本助力业务将存量 Hive 迁移 Iceberg 表，为业务提供高性能数据查询，同时实现对业务的降本增效。此外，我们也在不断完善 Iceberg 数据存储引擎的各项能力，包含表数据智能治理、查询优化、智能索引以及特定场景的性能问题等，并不断扩大 Iceberg 的业务覆盖范围。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18679436</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18679436</guid>
      <pubDate>Sat, 10 May 2025 10:17:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>RWKV 社区六月动态：多次亮相高规格活动，适合混合架构的新特性发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;欢迎大家收看《RWKV 社区最新动态》，本期内容收录了 RWKV 社区 2025 年 6 月的最新动态。&lt;/p&gt; 
&lt;p&gt;只需 3 分钟，快速了解 RWKV 社区 6 月都有哪些新鲜事！&lt;/p&gt; 
&lt;h2&gt;6 月动态省流版（TL;DR）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 模型新闻动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV-8 系列之 DeepEmbedAttention 发布&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 学术研究动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新论文：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation（基于 RWKV 的医学视频生成，已被 &lt;strong&gt;MICCAI 2025 提前接收&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新论文：Pan-Sharpening via Causal-Aware Feature Distribution Calibration（基于 RWKV 的全色锐化，一区顶刊 &lt;strong&gt;TGRS&lt;/strong&gt; 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration（基于 RWKV 的低光照图像恢复，已入选 &lt;strong&gt;CVPR 2025&lt;/strong&gt;）&lt;/li&gt; 
   &lt;li&gt;新论文：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing（RWKV 的视觉语言模型，发表于 JCR Q1 期刊 Information Fusion）&lt;/li&gt; 
   &lt;li&gt;新论文：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection（遥感变化检测，IEEE TAES 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR（基于 RWKV 的语音识别，Interspeech 2025 接收）&lt;/li&gt; 
   &lt;li&gt;新论文：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV（基于 RWKV 的音乐生成）&lt;/li&gt; 
   &lt;li&gt;新论文：Out-of-Distribution Semantic Occupancy Prediction（引入 RWKV 增强特征的 3D 语义占用预测）&lt;/li&gt; 
   &lt;li&gt;新论文：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification（基于 RWKV 的量子增强图像分类）&lt;/li&gt; 
   &lt;li&gt;新论文：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation（基于 RWKV 的医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文：Exploring Diffusion with Test-Time Training on Efficient Image Restoration（基于 RWKV 的图像修复）&lt;/li&gt; 
   &lt;li&gt;新论文：Relational Context Modeling for Improved Knowledge Graph Completion（混合 RWKV 架构的知识图谱补全）&lt;/li&gt; 
   &lt;li&gt;新论文：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation（基于 RWKV 的医学图像分割）&lt;/li&gt; 
   &lt;li&gt;新论文：RWKV-IF: Efficient and Controllable RNA Inverse Folding via Attention-Free Language Modeling（基于 RWKV 的 RNA 逆折叠）&lt;/li&gt; 
   &lt;li&gt;新论文：A Parallel Processing Architecture for Long-Term Power Load Forecasting（基于 RWKV 的长期电力负荷预测）&lt;/li&gt; 
   &lt;li&gt;新论文：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance（集体运动临界性盲识别）&lt;/li&gt; 
   &lt;li&gt;新论文：融合接收加权键值架构和球面几何特征的甲状腺结节分割方法（基于 RWKV 的医学影像分割）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区项目动态&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;rwkv_Ascend（RWKV 和升腾共建的算子库）&lt;/li&gt; 
   &lt;li&gt;rwkv7-g1-1.5b-instruct-preview（RWKV 的后训练模型）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;RWKV 社区市场活动&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;RWKV 参加亚马逊云科技中国峰会&lt;/li&gt; 
   &lt;li&gt;RWKV 参加 RTE Open Day&lt;/li&gt; 
   &lt;li&gt;RWKV 参加魔搭开发者大会&lt;/li&gt; 
   &lt;li&gt;RWKV 参加 GAIC 全球互联网架构大会&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相上海开源创新箐英荟&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相国际技术进出口交易会&lt;/li&gt; 
   &lt;li&gt;RWKV 亮相香港 NovaX 国际创投嘉年华&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;RWKV 模型新闻动态&lt;/h2&gt; 
&lt;h3&gt;RWKV-8 系列之 DeepEmbedAttention&lt;/h3&gt; 
&lt;p&gt;5 月 27 日，我们公开了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首个新特性 DeepEmbed：对端侧友好的稀疏设计，解决 MoE 显存占用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;6 月 30 日，与其相关的另一个新特性 DeepEmbedAttention（DEA）也正式公布。这是一种基于 RWKV-8 DeepEmbed 思路的注意力变体，拥有极小的 KV 缓存，尤其适合混合模型（例如后续的 RWKV-7s 混合模型），可将它们的长上下文性能提升到 Transformer 水准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="DeepEmbedAttention-loss" src="https://oscimg.oschina.net/oscnet/up-1df5adeb74b9c9eb0c3f35fe35e39185bf0.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;详细报道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F3q1cldAEsk1576SLK24CTw" target="_blank"&gt;RWKV-8 系列之 DeepEmbedAttention：精简 KV 缓存，尤其适合混合模型（RWKV-7s）&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RWKV 学术研究动态&lt;/h2&gt; 
&lt;p&gt;RWKV 学术研究包括 &lt;strong&gt;基于 RWKV 架构的新论文&lt;/strong&gt; 或 &lt;strong&gt;RWKV 社区参加的学术研究&lt;/strong&gt;。&lt;/p&gt; 
&lt;h3&gt;FEAT&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.04956" target="_blank"&gt;https://arxiv.org/abs/2506.04956&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-05&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型架构中的 WKV 注意力机制，提出了 FEAT 模型，通过统一的空间-时间-通道注意力机制解决医疗视频生成中通道交互不足、计算复杂度高和去噪指导粗糙的问题。在多个数据集上实现了高效高质量的医疗视频生成。&lt;/p&gt; 
&lt;p&gt;该项工作十分新颖和出色，已经以 top9% 的评分提前入选 &lt;strong&gt;MICCAI 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250605-FEAT" src="https://oscimg.oschina.net/oscnet/up-467d7594221b6e113f5533aa24c0fe733fb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Pan-Sharpening via Causal-Aware Feature Distribution Calibration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11023855" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11023855&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-04&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种新的全色锐化方法，通过因果推断解决网络优化中的频率不平衡问题。该方法在训练阶段利用 RWKV 架构的全局感受野，有效学习高频分量的长尾分布，并量化特征偏差的累积方向。&lt;/p&gt; 
&lt;p&gt;实验结果表明，该方法在多个基准数据集上均优于现有先进方法，展示了其在全色锐化任务中的有效性和鲁棒性。&lt;/p&gt; 
&lt;p&gt;文中方法在全色锐化任务中有出色的表现，已入选一区顶刊 &lt;strong&gt;IEEE Transactions on Geoscience and Remote Sensing&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250604-Pan-Sharpening_via_Causal-Aware_Feature_Distribution_Calibration" src="https://oscimg.oschina.net/oscnet/up-eec12432c41aab67b1095296c7aa214168b.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2505.23068" target="_blank"&gt;https://arxiv.org/abs/2505.23068&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型，提出了一种统一的多状态视角模型 URWKV，用于低光照图像恢复。该模型通过定制化的 URWKV 块感知和分析复杂退化，利用多阶段状态实现自适应场景感知的亮度调制。显著提升了性能。&lt;/p&gt; 
&lt;p&gt;论文受到广泛认可，已入选 &lt;strong&gt;CVPR 2025&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-URWKV" src="https://oscimg.oschina.net/oscnet/up-b0e6fa626bfa9e998ebf650bc70d4c9f7ee.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;VisualRWKV-HM&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：VisualRWKV-HM: Enhancing linear visual-language models via hybrid mixing&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1566253525004099" target="_blank"&gt;https://www.sciencedirect.com/science/article/pii/S1566253525004099&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-06&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="20250606-VisualRWKV-HM" src="https://oscimg.oschina.net/oscnet/up-2d4c04b5430391084f2b0de8de9a7905587.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 VisualRWKV-HM，这是一种具有线性复杂度的视觉语言模型，在单图像、多图像和多视图基准测试中均达到了 SOTA 性能。&lt;/p&gt; 
&lt;p&gt;与基于 Transformer-Mamba 架构的混合模型 LongLLaVA 相比，它在上下文长度为 16K 时消耗的内存更少，吞吐量提高了 24%。此外，VisualRWKV-HM 具有良好的可扩展性，通过扩展状态编码器和解码器，可以进一步提高性能。&lt;/p&gt; 
&lt;h3&gt;SMNet&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：SMNet: A Semantic Guided Mamba Network for Remote Sensing Change Detection&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F11039697" target="_blank"&gt;https://ieeexplore.ieee.org/abstract/document/11039697&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型和 Mamba 架构提出了一种新的遥感变化检测模型 SMNet，该模型通过整合多层次特征表示，有效解决了当前方法在变化检测任务中性能有限和特征表达能力不足的问题。SMNet 利用 RWKV 的多方向 WKV 注意力机制和 Mamba 的空间架构，增强了模型处理语义信息的能力。&lt;/p&gt; 
&lt;p&gt;实验结果表明，SMNet 在多个遥感变化检测基准数据集上表现出色，显著优于现有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250618-SMNet_A_Semantic_Guided" src="https://oscimg.oschina.net/oscnet/up-56b21424d56741e3598d42c23708a33f28e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Accurate, fast, cheap: Choose three. Replacing Multi-Head-Attention with Bidirectional Recurrent Attention for Long-Form ASR&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.19761" target="_blank"&gt;https://arxiv.org/abs/2506.19761&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-24&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文研究了将多头注意力（MHA）替换为双向循环注意力（RA）在长语音识别（ASR）中的应用，发现双向 RWKV-Conformer 模型在保持相似准确率的同时，效率更高。通过引入 Direction Dropout 方法，进一步提升了模型的灵活性和性能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250624-Accurate,fast,cheap" src="https://oscimg.oschina.net/oscnet/up-9e59775226d89bf420c19693e382a38938d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MIDI-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.13001" target="_blank"&gt;https://arxiv.org/abs/2506.13001&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 MIDI-RWKV ，一个用于个性化、多轨道、长上下文和可控符号音乐填充的新型模型。该模型采用 RWKV-7 线性架构，能够在边缘设备上实现高效且连贯的音乐协同创作。MIDI-RWKV 通过微调初始状态实现了在极小样本条件下的个性化。&lt;/p&gt; 
&lt;p&gt;实验结果表明，MIDI-RWKV 在多项定量和定性指标上均优于现有方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-MIDI-RWKV" src="https://oscimg.oschina.net/oscnet/up-059e2194193005d16941dfb46b2a50126d7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Out-of-Distribution Semantic Occupancy Prediction&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Out-of-Distribution Semantic Occupancy Prediction&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.21185" target="_blank"&gt;https://arxiv.org/abs/2506.21185&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-26&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这篇论文为解决自动驾驶中的"意外"物体识别难题，创新性地引入 RWKV 架构来强化模型的特征感知力，并提出了 OccOoD 框架。它巧妙融合了精细的 3D 体素和全局的鸟瞰图视角，能更准确地判断异常。为了训练和验证模型，作者还独创性地构建了合成异常数据集.&lt;/p&gt; 
&lt;p&gt;实验结果表明，在不影响常规物体识别性能的前提下，实现了对未知风险的精准捕获。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250626-Out-of-Distribution Semantic Occupancy Prediction" src="https://oscimg.oschina.net/oscnet/up-541580df9785f32fdb7111c003976df721d.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Vision-QRWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.06633" target="_blank"&gt;https://arxiv.org/abs/2506.06633&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-07&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种量子增强的混合架构 Vision-QRWKV，用于图像分类任务。通过将变分量子电路（VQC）集成到 RWKV 的通道混合组件中，模型提升了非线性特征转换能力。&lt;/p&gt; 
&lt;p&gt;实验表明，该模型在多个医疗和标准图像数据集上表现优于经典模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250607-Vision-QRWKV" src="https://oscimg.oschina.net/oscnet/up-669a60a01e8d0426df73da6bbf8f6477034.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Diet-Seg&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Diet-Seg: Dynamic Hardness-Aware Learning for Enhanced Brain Tumor Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.05.31.657149v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.05.31.657149v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-03&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种新型脑肿瘤分割框架 Diet-Seg，通过将基于熵的像素级难度估计与动态学习率调节策略结合，有效提升了脑肿瘤分割的准确性。Diet-Seg 框架采用 RWKV-UNet 作为主干网络，以捕捉全局空间依赖性。&lt;/p&gt; 
&lt;p&gt;实验结果表明，Diet-Seg 在 BraTS2018--2021 数据集上表现优于现有方法，特别是在肿瘤子区域的分割上取得了显著提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250603-Diet-Seg Dynamic" src="https://oscimg.oschina.net/oscnet/up-4e65bcaea7495f4a3f7ef38e13fafaed70c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;DiffRWKVIR&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Exploring Diffusion with Test-Time Training on Efficient Image Restoration&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.14541" target="_blank"&gt;https://arxiv.org/abs/2506.14541&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-17&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了 DiffRWKVIR 框架，该框架将测试时训练（TTT）与高效扩散相结合，通过 Omni-Scale 2D 状态演化扩展 RWKV 的位置依赖参数化，实现全局上下文感知，并通过块优化闪存处理加速计算，最终在图像修复任务中超越现有方法，显著提升了效率和效果。&lt;/p&gt; 
&lt;p&gt;该论文还提出了先验引导的高效扩散方法，通过提取紧凑的图像先验表示，加速了训练和推理过程，同时解决了传统扩散模型中的计算低效问题。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250617-Exploring Diffusion with Test-Time Training on Efficient Image Restoration" src="https://oscimg.oschina.net/oscnet/up-185f166afa6a20a24ff6dfbff5ca302ec83.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RCME&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Relational Context Modeling for Improved Knowledge Graph Completion&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.engineeringletters.com%2Fissues_v33%2Fissue_6%2FEL_33_6_28.pdf" target="_blank"&gt;https://www.engineeringletters.com/issues_v33/issue_6/EL_33_6_28.pdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-01&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型和 TuckER 模型，提出了一种名为 RCME 的混合架构，用于改进知识图谱补全。RCME 结合了 RWKV 的序列建模能力和动态嵌入生成，以及 TuckER 的关系解码鲁棒性，在链接预测和三元组分类任务中表现优于多种先进模型。&lt;/p&gt; 
&lt;p&gt;实验结果表明，该架构在多个基准数据集上均取得了显著的性能提升。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250601-Relational Context Modeling for Improved" src="https://oscimg.oschina.net/oscnet/up-3df836cf1461d197114ffa8bce7c49241b6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Med-URWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2506.10858" target="_blank"&gt;https://arxiv.org/abs/2506.10858&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-12&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文基于 RWKV 模型提出了一种名为 Med-URWKV 的纯 RWKV 架构，该架构基于 U-Net 框架构建，并融入了基于 ImageNet 的预训练，以进一步探索 RWKV 在医学图像分割任务中的潜力。&lt;/p&gt; 
&lt;p&gt;研究通过在七个数据集上的实验，验证了 Med-URWKV 在医学图像分割任务中的有效性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250612-Med-URWKV" src="https://oscimg.oschina.net/oscnet/up-5b67fb50ae77f12d7a02f9c6fa831e31496.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV-IF&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2025.06.13.659654v1" target="_blank"&gt;https://www.biorxiv.org/content/10.1101/2025.06.13.659654v1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-14&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV 模型提出了一种名为 RWKV-IF 的高效可控 RNA 逆折叠框架，通过将结构到序列的生成建模为条件语言建模任务，以线性复杂度捕获长程依赖关系。研究引入了一种解码策略，结合 Top-k 采样、温度控制和 G-C 含量偏向，生成结构准确且具有生物物理意义的序列。显著优于传统搜索基线方法。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250614-RWKV-IF" src="https://oscimg.oschina.net/oscnet/up-a3f69a2c1c24040e3bee2df1570eebd2a19.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;MP-RWKV&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：A Parallel Processing Architecture for Long-Term Power Load Forecasting&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.mdpi.com%2F2673-4591%2F97%2F1%2F26" target="_blank"&gt;https://www.mdpi.com/2673-4591/97/1/26&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV-TS 模型提出了 MP-RWKV，通过并行处理路径解决长期电力负荷预测中不同预测范围的挑战。MP-RWKV 通过上下文状态机制和位置感知注意力机制，在短期和长期预测场景中均表现出色。&lt;/p&gt; 
&lt;p&gt;实验结果表明，MP-RWKV 在 24 小时至 432 小时的预测范围内均优于现有基准模型，尤其在传统模型性能下降的长期预测中表现突出。显著提升了长期电力负荷预测的准确性和稳定性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-A Parallel Processing Architecture for Long-Term Power Load Forecasting" src="https://oscimg.oschina.net/oscnet/up-1cd2d5a4b1ab3666aacf1439e4e1a8c45c4.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;Blind Identification&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D5297784" target="_blank"&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5297784&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-06-16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;本文基于 RWKV-7 序列模型提出了一种无参数的集体运动临界性识别方法，通过分析单智能体轨迹数据来检测 Vicsek 模型中的临界区域。&lt;/p&gt; 
&lt;p&gt;该方法利用预测香农熵的方差作为指标，无需系统控制参数或全局信息，成功在 L=32 和 L=64 系统中识别出临界噪声水平，且结果符合有限尺寸缩放原理。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250616-Blind Identification of Collective Motion Criticality Using Sequence Model Predictive Entropy Variance" src="https://oscimg.oschina.net/oscnet/up-80916e606288454a3f41baab295cf426a08.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;融合接收加权键值架构和球面几何特征的甲状腺结节分割方法&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;论文名称：融合接收加权键值架构和球面几何特征的甲状腺结节分割方法&lt;/li&gt; 
 &lt;li&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.biomedeng.cn%2Farticle%2F10.7507%2F1001-5515.202412009" target="_blank"&gt;https://www.biomedeng.cn/article/10.7507/1001-5515.202412009&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;发布日期：2025-05-29&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;论文提出了一种融合接收加权键值架构（RWKV）和球面几何特征（SGF）采样技术的甲状腺结节分割方法。该方法通过二维偏移预测和像素级采样位置调整，有效捕捉邻近区域细节，实现精确分割。同时，本研究引入了区块注意力模块（PAM），利用区域交叉注意力机制优化解码器特征图，使其更精确关注编码器的高分辨率特征。&lt;/p&gt; 
&lt;p&gt;在甲状腺结节区域分割数据集（TN3K）和甲状腺影像数字数据库（DDTI）上的实验表明，本文所提方法的戴斯相似系数（DSC）分别达到 87.24% 和 80.79%，优于现有模型，且计算复杂度较低，或可为甲状腺结节精确分割提供一种高效解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="20250529-融合接收加权键值架构和球面几何特征的甲状腺结节分割方法" src="https://oscimg.oschina.net/oscnet/up-ab6be27562fe5cd66667ddfadbe4265a5c9.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社区活动&lt;/h2&gt; 
&lt;h3&gt;RWKV 参加亚马逊云科技中国峰会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 19 日，RWKV 团队受邀出席于上海举办的亚马逊云科技中国峰会，并荣膺「智创未来」领航奖。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="AMZ-1" src="https://oscimg.oschina.net/oscnet/up-f86080aa51519b5f93f947f0abf82dddc3c.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加 RTE Open Day&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 21 日至 22 日，北京，一场属于技术人的盛会------RTE Open Day 拉开帷幕。RWKV 团队与来自全国的技术爱好者和开发者们齐聚一堂，展示前沿应用，共话 AGI 的无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="RTE Openday AGI Playground-3" src="https://oscimg.oschina.net/oscnet/up-b3b31a96ba8288b0c7b1da1bb4fc8d1d81b.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加魔搭开发者大会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日，在国家信息中心指导、魔搭社区主办的 2025 魔搭开发者大会上，RWKV 团队受邀出席。团队与广大开发者深入分享了 RWKV 的最新进展与架构的核心亮点，共探 AI 技术的新可能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="ModelScope-2" src="https://oscimg.oschina.net/oscnet/up-c4cf19d1c15dd0f606d0a8e16b9b6a283f2.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 参加 GAIC 全球互联网架构大会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 14 日，在全球互联网架构大会上，RWKV 团队深度解析了 RWKV 最新架构在精度、显存占用及运算速度等方面的核心优势，并面向公众分享了简单易用的基于 RWKV 进行微调、推理与多模态开发的最佳实践。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="GIAC-1" src="https://oscimg.oschina.net/oscnet/up-62a00f9d678a10835a9faac67b61310ad08.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相上海开源创新箐英荟&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 28 日，RWKV 团队出席由上海开源信息技术协会主办的 2025 上海开源创新箐英荟，并凭借其卓越的技术贡献和活跃的社区生态，荣获主办方颁发的"优秀开源项目奖"。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-1" src="https://oscimg.oschina.net/oscnet/up-059448850eedb205228e74d972e9cc20be4.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="SHOPEN-2" src="https://oscimg.oschina.net/oscnet/up-1dccb3bfe4475ff6bdb9e7b19d5de026d95.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相国际技术进出口交易会&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 11 日至 13 日，RWKV 团队携其创新成果亮相上海世博展览馆，出席（上海）国际技术进出口交易会。会上，团队向与会者展示了 RWKV 在端侧部署、低资源消耗及可持续学习等方面的卓越优势，引发广泛关注。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="CSITF-1" src="https://oscimg.oschina.net/oscnet/up-aca0e633ac77f03ce72e551535a52187854.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;RWKV 亮相香港 NovaX 国际创投嘉年华&lt;/h3&gt; 
&lt;p&gt;2025 年 6 月 30 日至 7 月 1 日，RWKV 团队登陆香港，在 NovaX Global Investmatch Carnival 国际创投嘉年华 2025 的舞台上，与全球顶尖的创投机构和行业领袖齐聚一堂，共同探讨 AI 技术的商业前景与未来机遇。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="NovaX-1" src="https://oscimg.oschina.net/oscnet/up-e8e859c258f108b8ebb09921dd3b78b4edb.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;社区项目动态&lt;/h2&gt; 
&lt;h3&gt;rwkv_Ascend&lt;/h3&gt; 
&lt;p&gt;cann-ops-rwkv 是 RWKV 与升腾共建的算子仓库，欢迎 rwkv 爱好者学习、使用和魔改的 RNN attention（rwkv、fla）系列算子代码。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;项目地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fappleinsky%2Frwkv_Ascend" target="_blank"&gt;https://github.com/appleinsky/rwkv_Ascend&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;rwkv7-g1-1.5b-instruct-preview&lt;/h3&gt; 
&lt;p&gt;此项目是 RWKV7-G1 1.5B 的后训练模型，强化了指令遵循能力和中文能力，同时拥有更高的情商。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;模型地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FSeikaijyu%2Frwkv7-g1-1.5b-instruct-preview" target="_blank"&gt;https://hf-mirror.com/Seikaijyu/rwkv7-g1-1.5b-instruct-preview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="RWKV7-G1-1.5B-instruct" src="https://oscimg.oschina.net/oscnet/up-beed0d3d6a0e327fb38fe4d0b43057e9996.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn" target="_blank"&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 论坛：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F" target="_blank"&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 频道：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc" target="_blank"&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 视频教程：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933" target="_blank"&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358194</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358194</guid>
      <pubDate>Sat, 10 May 2025 08:39:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>Ubuntu Debcrafters 团队成立，旨在维护 Ubuntu 档案库健康</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Canonical 工程副总裁 Jon Seager 发文&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdiscourse.ubuntu.com%2Ft%2Fintroducing-debcrafters%2F63674" target="_blank"&gt;宣布&lt;/a&gt;&amp;nbsp;Ubuntu Debcrafters 团队的成立。主要目标在于维护 Ubuntu 档案库的健康，但也旨在吸引广泛的 Linux 发行版专业人才。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 表示，其鼓励 Debian、Arch Linux、NixOS 等发行版的贡献者加入 Debcrafters&amp;nbsp;团队，贡献的同时还可以获得报酬，并促进学习和想法共享。该团队由 Debian 开发人员、稳定版本更新 (SRU) 团队成员和档案管理员组成，并于 2025 年 5 月初首次开始合作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="250" src="https://oscimg.oschina.net/oscnet/up-0e0b14cf8de1e9a97b9c9dba65bf6513bb0.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Seager 在 Debcrafters 公告中解释道：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;Debcrafters 的主要使命是维护 Ubuntu 档案的健康。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;该团队将负责同步和合并来自 Debian 的软件包、审查提议的迁移问题、上游 Ubuntu 增量，并负责重大转变，例如升级到 glibc 和过去的示例，例如 t64 和 python3 转变。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将管理存档测试重建的调度、触发和报告，这些重建工作在我们对关键软件包进行重大更改时进行。我们在默认启用框架指针时以及切换 coreutils 到 uutilsUbuntu 25.10 中的实现时都执行了这些操作。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将负责 autopkgtestUbuntu 基础架构的演变和维护，并在引入更多发行版规模的集成测试方面发挥重要作用。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;他们将致力于改进 Ubuntu 档案库、其贡献者和状态的报告和仪表板，并对塑造我们用于构建和塑造 Ubuntu 的工具产生更广泛的兴趣。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style="color:#000000"&gt;这支团队与桌面、服务器和基础团队的不同之处在于，他们处理的软件包范围非常广泛。Debcrafters 团队的成员每个周期都会迁移数千个软件包——其中许多软件包他们并不十分熟悉，但他们将运用不断提升的发行版维护和打包技能，在没有其他明确或现有所有者的情况下进行维护。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358188/ubuntu-debcrafters</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358188/ubuntu-debcrafters</guid>
      <pubDate>Sat, 10 May 2025 08:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软被曝将「AI 使用量」纳入员工考核，直接挂钩绩效</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.businessinsider.com%2Fmicrosoft-internal-memo-using-ai-no-longer-optional-github-copilot-2025-6" target="_blank"&gt;根据《商业内幕》的报道&lt;/a&gt;，微软开发者工具部门总裁 Julia Liuson 最近发出内部邮件，要求各级主管在评估员工绩效时，将其使用 GitHub Copilot 等内部 AI 工具的情况纳入考量。&lt;/p&gt; 
&lt;p&gt;Liuson 表示，AI 已成为微软日常工作的核心，就像团队协作、数据导向思维和沟通能力一样，使用 AI 不再是选择题，而是每个岗位的基本要求。她指出，员工是否有效使用 AI，应该被纳入对其整体表现和影响力的全面评估之中。&lt;/p&gt; 
&lt;p&gt;具体执行框架如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;基础合规层&lt;/strong&gt; ：要求员工在邮件撰写、会议记录、代码开发等高频场景 100% 启用 Copilot 基础功能，系统自动记录使用时长和任务覆盖率。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;效能增值层&lt;/strong&gt; ：按岗位类型设定差异化 KPI，如开发人员需实现 30% 代码由 Copilot 生成，销售部门需达成 AI 优化提案的成交率提升指标。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;创新应用层&lt;/strong&gt; ：将员工使用 Copilot 开发新工作流程或业务解决方案的实践成果，纳入晋升评估加分项。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;知情人士透露，微软各团队的绩效考核标准不尽相同，目前已有部分团队考虑在下一个财年正式将 AI 工具使用情况作为绩效指标之一。另据两位了解内情的人士称，这一改变旨在应对微软内部 Copilot 服务推广缓慢的问题。微软希望提升整体使用率，也希望产品开发人员更深入理解自家 AI 工具的运作方式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358184/ms-internal-memo-using-ai-no-longer-optional-github-copilot</guid>
      <pubDate>Sat, 10 May 2025 08:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Meta 将其 AI 部门重组为 「超级智能实验室」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Meta 公司首席执行官马克-扎克伯格（Mark Zuckerberg）正在重组公司的人工智能工作，以打造人工智能 「superintelligence」为中心。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;据&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fzuckerberg-announces-meta-superintelligence-effort-more-hires%3Fsrnd%3Dundefined" target="_blank"&gt;彭博社&lt;/a&gt;报道，其从该公司于周一发出的一份内部备忘录得知，Meta 公司所有从事人工智能工作的团队今后都将隶属于一个名为 Meta 超级智能实验室（Meta Superintelligence Labs）的新团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="366" src="https://oscimg.oschina.net/oscnet/up-44145dfdb97dd1159efb1314b8297ede5e1.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;「超级智能实验室」 将由前 Scale AI 首席执行官亚历山大・王（Alexandr Wang）担任首席人工智能官，负责整体方向与管理。他将与 GitHub 前首席执行官纳特-弗里德曼（Nat Friedman）合作，后者将负责 Meta 的人工智能产品和应用研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;扎克伯格一直在努力在人工通用智能（AGI）竞赛中取得领先，主要是通过收购人工智能公司和顶级人工智能公司的员工。本月早些时候，Meta 向 Scale AI 投资了 143 亿美元，并在此过程中引入了 Wang。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style="color:#000000"&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357367/metas-recruiting-three-openai-researchers" target="news"&gt;Meta 成功挖角三名 OpenAI 研究人员&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oschina.net/news/357940" target="news"&gt;OpenAI 被曝将重新调整薪酬以应对 Meta 挖人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358181/meta-superintelligence-labs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358181/meta-superintelligence-labs</guid>
      <pubDate>Sat, 10 May 2025 07:49:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>微软开源 GitHub Copilot Chat 的 VS Code 扩展</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;微软在 5 月举办的开发者大会上&lt;a href="https://www.oschina.net/news/350732/ms-vs-code-open-source-ai-editor"&gt;宣布&lt;/a&gt;要将 VS Code 打造成开源 AI 编辑器，近日该计划达成了&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcode.visualstudio.com%2Fblogs%2F2025%2F06%2F30%2FopenSourceAIEditorFirstMilestone" target="_blank"&gt;首个里程碑&lt;/a&gt;——GitHub Copilot Chat 的 VS Code 扩展采用 MIT 开源许可证正式开源。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1098" src="https://static.oschina.net/uploads/space/2025/0701/153012_qXMd_2720166.png" width="2460" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fmicrosoft%2Fvscode-copilot-chat" target="_blank"&gt;https://github.com/microsoft/vscode-copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;该扩展提供了类似 Cursor 的 Chat 面板，通过聊天的方式来编辑代码，它还可以根据代码提交者、变量和斜线命令等信息，给出与代码库相关的回答。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4a176b7fa906f848e0f9b0982762510cc49.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-190bfc8a0cc77c524892684d44d95a0f15c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;扩展地址：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGitHub.copilot-chat" target="_blank"&gt;https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;由于 Copilot Chat 与 VS Code 深度集成，其发布与 VS Code 同步进行，因此每个新版本的 Copilot Chat 仅兼容最新版本的 VS Code。这意味着如果你使用的是旧版本的 VS Code，将无法使用最新的 Copilot Chat。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358178</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358178</guid>
      <pubDate>Sat, 10 May 2025 07:31:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>字节、腾讯、阿里等 13 家头部企业去年利润总额同比增 19.7%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;5 月底结束的 2024 年度企业所得税汇算清缴数据显示，字节跳动、腾讯、阿里巴巴等 13 家头部企业营业收入和利润总额同比分别增长 11.9%、19.7%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;上述企业是数字经济领域的代表企业，汇算清缴数据显示，2024 年度，数字经济及其核心产业营业收入和利润总额同比分别增长 5.9%、2.7%。其中，信息传输、软件和信息技术服务业营业收入和利润总额同比分别增长 11.5%、13.2%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;除数字经济外，2024 年度，医药制造、航空航天等高技术产业营业收入和利润总额同比分别增长 8.9%、7.5%。细分行业看，科学研究和技术服务业营业收入和利润总额同比分别增长 11.7%、7.5%，航空航天产业营业收入和利润总额同比分别增长 10.5%、26.3%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，机器人产业也步入发展快车道，近两年机器人产业营业收入平均同比增长 10.2%。其中，特殊作业机器人、服务消费机器人、工业机器人 2024 年度同比分别增长 28.4%、12.4%、7%，多场景应用加速落地。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;总体上看，数字经济、高技术产业、机器人产业三个领域 2024 年度共减免企业所得税 1.97 万亿元，总营业收入同比增长 7.1%，利润总额同比增长 5.2%，我国新质生产力持续发展壮大。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;国家税务总局相关负责人表示，税务部门将不折不扣落实落细结构性减税降费政策，同时，依法严厉打击违规享受、恶意骗取税费优惠等违法行为，坚决防止政策「红包」落入不法分子「腰包」。（新京报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358163</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358163</guid>
      <pubDate>Sat, 10 May 2025 06:03:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁数科面向香港市场开放四大自研技术</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁数科面向香港市场开放四大自研技术——Layer2 网络、大模型开发工具、「区块链+IoT」可信架构、机构级 Web3 钱包技术，为香港建设全球数字资产创新中心提供全栈技术服务。&lt;/p&gt; 
&lt;p&gt;&lt;img height="388" src="https://oscimg.oschina.net/oscnet/up-e94b03fe5b81530ba178b109352a29a4037.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;资料显示，蚂蚁数科自 2016 年起投入区块链技术研发，全球区块链授权专利排名第一，核心技术如智能合约、网络传输、存储引擎、跨链技术等已取得重大突破，处于全球领先水平。此前，蚂蚁数科作为核心成员加入香港金管局 Ensemble 沙盒，并宣布将海外总部落户香港。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358160</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358160</guid>
      <pubDate>Sat, 10 May 2025 05:55:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>加锁失效，非锁之过，加之错也</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;作者：京东零售，邢成&lt;/p&gt; 
&lt;span id="OSC_h3_1"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;多个进程或线程同时 (或着说在同一段时间内) 访问同一资源会产生并发问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;银行两操作员同时操作同一账户就是典型的例子。比如 A、B 操作员同时读取一余额为 1000 元的账户，A 操作员为该账户增加 100 元，B 操作员同时为该账户减去 50 元，A 先提交，B 后提交。 最后实际账户余额为 1000-50=950 元，但本该为 1000+100-50=1050。&lt;strong&gt;这就是典型的并发问题&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;从事零售供应链库存业务，对库存数量操作增减十分频繁，同样存在类似上述银行取款遇到的问题，库存数量操作有误势必给前台销售产生损失影响，因此需要关注对库存数量并发操作下的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;下面通过一个真实的案例分享在并发情况下如何保证库存数量的准确性。&lt;/p&gt; 
&lt;span id="OSC_h3_2"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;问题是什么-加锁失效&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;看看下面这段流程和代码，思考会有并发问题吗？&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//c52b6c3f660ed58046c9e16a5be9c444.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;加锁前&lt;/strong&gt; &lt;strong&gt;，获取箱子明细数据，此处在锁之外，存在并发脏读问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//1036ef25fae37b26c448522f6777c80c.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; &lt;strong&gt;加锁后&lt;/strong&gt; &lt;strong&gt;，并进行箱子上架分批次回传业务处理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//020a84a9615ca8e8cec22118aefca76f.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; &lt;strong&gt;加锁后，&lt;/strong&gt; &lt;strong&gt;更新箱子明细上架数量逻辑：已上架数量 = 加锁前的明细数据（脏读） + 报文回传的明细数据，直接进行行更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//21d80ae4a594960a582dde2c19321099.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;原因是什么-加锁的位置不正确&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//20d9ce564f5386039bb12242e16ef05b.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心的问题原因&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;业务分布式锁失效：&lt;/strong&gt; 使用分布式锁加锁了，但是仍然使用加锁前查询的数据，导致出现脏读&lt;/p&gt; 
&lt;p&gt;2.&lt;strong&gt;Mysql 锁失效：&lt;/strong&gt; 数据库更新时，未上任何锁，导致脏读的数据直接覆盖更新当前行&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;有同学这时问了，为啥防重码也没有生效呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;防重码主要是用作幂等逻辑的，同一个请求多次处理，结果仍然是相同的。&lt;/p&gt; 
&lt;p&gt;但是这是两次不同的请求，防重码是不同的，因此不能只依赖防重码保证一致性。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;&lt;strong&gt;解决方案有哪些&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1、代码层面：&lt;/strong&gt; 使用锁（如互斥锁、读写锁、分布式锁等）来控制资源的访问，数据获取的全部操作都需要再获取锁后才进行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;将获取箱子明细的代码移动到加锁之后，只有获取到分布式锁，才能执行分批次上架查询和更新（串行化）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//5ffc0121557805521cbb33921c4be06a.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;对应改造后的代码：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//751c2001d8d70843f24dcf8b6fa5eaa6.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2、数据库层面：&lt;/strong&gt; 实现事务管理，确保数据的一致性；合理设置事务隔离级别，以防止脏读、或者采用乐观锁或悲观锁来处理并发更新，合理设计查询效率，减少锁竞争。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;数据库的并发上锁处理和业务代码的上锁是互补的关系&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;因为无法保证后续业务的调整或其他业务代码的调用能始终保持获取数据的一致性，数据库的并发上锁处理更多是一种兜底保证机制。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;乐观锁更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//e4262e1d681aa19763c8066296032481.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;悲观锁更新&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet//4078a93beef3c9b077595bb8968b3a5d.webp" alt="在这里插入图片描述" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;扩展方案&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;应用程序设计：&lt;/strong&gt; 在应用程序设计阶段，尽量避免长时间持有数据库连接或事务，减少并发操作的可能性，利用 AI 代码评审或者人工提前找出可能出现并发问题的地方；合理设置锁的粒度，避免锁失效。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;网络负载层面：&lt;/strong&gt; 采用限流控制访问频率；采用分布式数据库，进行数据分片，降低单节点并发压力；使用负载均衡，将网络请求分发到不同的服务器，提高系统处理并发的能力，防止系统过载。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;1.&lt;strong&gt;请求层面：&lt;/strong&gt; 前端点击防重、系统幂等防重、尽可能降低同一请求的多次重试访问引起的一致性问题。&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;通过以上措施，可以在不同层面有效地防止并发问题，保证系统的数据的一致性。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4090830/blog/18638221</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4090830/blog/18638221</guid>
      <pubDate>Sat, 10 May 2025 03:26:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>通义千问 Qwen-TTS 新增支持北京话、上海话和四川话中文方言</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通义千问团队更新并&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F-VDOJrDgVzC6JI4CVTHe4w" target="_blank"&gt;上线&lt;/a&gt;了 Qwen-TTS 文本转语音服务，&amp;nbsp;新增支持生成三种中文方言，包括北京话、上海话和四川话。&lt;/p&gt; 
&lt;p&gt;据介绍，Qwen-TTS 使用了超过 300 万小时的大规模语料库进行训练，合成效果达到了人类级别的自然度和表现力，旨在提供超自然、富有表现力的音频，并能智能处理韵律、语速和情感。&lt;/p&gt; 
&lt;p&gt;值得一提的是，Qwen-TTS 能够根据输入文本自动调整韵律、节奏和情绪变化，进一步提升语音的真实感和表达力。&lt;/p&gt; 
&lt;p&gt;目前，Qwen-TTS 支持七种中英双语音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京话）、Jada（上海话） 和 Sunny（四川话）。未来，我们还将推出更多语言和语音风格，进一步丰富用户的选择体验。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fqwenlm.github.io%2Fblog%2Fqwen-tts%2F" target="_blank"&gt;https://qwenlm.github.io/blog/qwen-tts/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358128/qwen-tts</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358128/qwen-tts</guid>
      <pubDate>Sat, 10 May 2025 03:06:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>消息称苹果考虑让 Anthropic 和 OpenAI 为 Siri 提供支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#212623"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-30%2Fapple-weighs-replacing-siri-s-ai-llms-with-anthropic-claude-or-openai-chatgpt" target="_blank"&gt;彭博社&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;报道称，苹果正在考虑使用 OpenAI 和 Anthropic 的 AI 模型来支持其更新版 Siri，而不是使用该公司内部开发的技术。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="329" src="https://oscimg.oschina.net/oscnet/up-b75a8d1cc618ffd03df5516bae4e561bc31.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;消息指出，苹果公司正在继续构建一个名为「LLM Siri」的内部项目，该项目使用内部 AI 模型。但该公司已要求 OpenAI 和 Anthropic 训练其可在苹果云基础设施上运行的 AI 模型版本，以供测试。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;由于一系列技术挑战，苹果被迫将原定于 2025 年发布的人工智能 Siri 推迟到 2026 年或更晚。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;这一失败或许由来已久；过去几年，苹果在 AI 竞赛中一直落后于谷歌、OpenAI 和 Anthropic。虽然 Siri 已经可以调用 ChatGPT 来回答难题，但苹果现在似乎正在探索与第三方 AI 提供商的技术进行更深入的整合。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358124</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358124</guid>
      <pubDate>Sat, 10 May 2025 02:44:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 编程助手 Cursor 提供 Web 和移动端版本</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 编程助手 Cursor &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cursor.com%2Fcn%2Fblog%2Fagent-web" target="_blank"&gt;推出&lt;/a&gt;&lt;/u&gt;了可在网页和移动设备上使用的 AI Agent 功能。用户现在可以通过浏览器或手机随时启动复杂的编码任务，例如修复错误或进行代码库问答，并让 Agent 在后台运行。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1522" src="https://static.oschina.net/uploads/space/2025/0701/102654_ieGo_2720166.png" width="1684" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1078" src="https://static.oschina.net/uploads/space/2025/0701/102948_z9W9_2720166.png" width="1398" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;任务完成后，用户可以在桌面端的 Cursor IDE 中无缝衔接，审查、合并代码修改，或与团队成员分享链接进行协作。&lt;/p&gt; 
&lt;p&gt;该功能支持并行执行，用户可以同时启动多个使用不同模型的 Agent，并比较结果以选择最佳方案。为了获得更好的移动端体验，Cursor 支持安装为渐进式网络应用（PWA），从而实现推送通知、全屏界面和离线查看等原生应用体验。此外还集成了 Slack，用户可以直接在 Slack 中通过提及@Cursor 来触发 Agent。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2c82f625dd429efeb71a6d75f6189dbb4bd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;定价方面，网页和移动端 Agent 与 Background Agents 采用相同的模式，目前运行计算本身免费，仅根据用户选择的 AI 模型收取使用费。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.cursor.com%2Fget-started%2Fweb-and-mobile-agent%23slack-integration-not-working" target="_blank"&gt;详情查看文档&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358117/cursor-web-and-mobile-agent</guid>
      <pubDate>Sat, 10 May 2025 02:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 澄清与谷歌芯片传闻：并无大规模合作计划</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;日前，有报道称&amp;nbsp;OpenAI 正转向其竞争对手的 AI 芯片以满足日益增长的需求。对此，OpenAI 对外发布声明，&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.com%2Fen-us%2Fnews%2Ftechnology%2Fopenai-says-it-has-no-plan-to-use-googles-in-house-chip%2Far-AA1HItOZ%3Focid%3DBingNewsSerp" target="_blank"&gt;否认&lt;/a&gt;了媒体有关其计划采用谷歌自研芯片的报道。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 的一位发言人表示，尽管该公司正在对谷歌的张量处理单元（TPU）进行早期测试，但目前并没有大规模使用这些芯片的打算。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="378" src="https://oscimg.oschina.net/oscnet/up-d1a613253026c0819f2d66ccaa58bfeeeac.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在人工智能领域，实验室测试各种芯片的情况十分普遍，但要实现新硬件的大规模应用通常需要较长时间。此外，这也涉及到不同的架构和软件支持，难度不小。OpenAI 表示，目前正积极使用英伟达的图形处理器（GPU）和 AMD 的人工智能芯片，以满足日益增长的计算需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，OpenAI 也在研发自己的芯片，预计将在今年达到 「定型」 里程碑，届时这些芯片的设计将最终确定并投入生产。此前有报道称，OpenAI 已与谷歌云服务达成合作协议，以满足其不断增长的计算能力需求。这一合作被认为是人工智能领域两个主要竞争对手之间的一次意外联手。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;尽管 OpenAI 在计算能力方面的主要来源将是由新兴云公司 CoreWeave 提供支持的 GPU 服务器，谷歌也在积极扩大其自研人工智能芯片（TPU）的外部可用性。TPU 芯片之前主要用于谷歌的内部项目，但现在也开始吸引包括苹果在内的其他科技巨头以及一些初创公司的关注，如 Anthropic 和 Safe Superintelligence，这些公司都是 OpenAI 的竞争对手。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358116</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358116</guid>
      <pubDate>Sat, 10 May 2025 02:24:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>豆包上线「深入研究」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;豆包「深入研究」功能已经在豆包 App、网页版及电脑版正式开启测试，用户可免费体验。&lt;/p&gt; 
&lt;p&gt;基于模型的搜索、推理及 Agent 能力，「深入研究」可以帮助用户更快速、全面和结构化地处理高难度的复杂任务。针对长途旅行攻略、复杂购买决策、最新政策解读、商业科技趋势发展等需要获取大量资料、长时间研究的问题，借助「深入研究」能力，几分钟即可完成初步方案。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-9f6c1c14ffd9352f40ee1c98040fd7cff53.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;同时，豆包还支持以可视化网页和报告文档两种方式呈现研究结果。&lt;/p&gt; 
&lt;p&gt;据介绍，将豆包更新至最新版后，打开 App 或电脑版，选择「深入研究」，输入详细指令或一句话 prompt，等待几分钟，即可生成一份报告。使用豆包 App 生成报告后，还可以打开报告内容，选择右上角「听」按钮，一键转成播客，随时听。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358039</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358039</guid>
      <pubDate>Fri, 09 May 2025 11:18:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>德国要求苹果和谷歌从应用商店下架 DeepSeek</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fsustainability%2Fboards-policy-regulation%2Fdeepseek-faces-expulsion-app-stores-germany-2025-06-27%2F" target="_blank"&gt;据路透社报道&lt;/a&gt;，德国数据保护专员梅克·坎普发布声明，宣称已要求苹果和谷歌公司从其在德国的应用商店中下架中国初创公司自主研发的人工智能（AI）大语言模型「深度求索」（DeepSeek）的应用。他给出的理由是所谓的数据安全担忧。&lt;/p&gt; 
&lt;p&gt;坎普在声明中指控 DeepSeek「非法将用户个人数据传输至中国」，并要求苹果与谷歌尽快审查这一要求，以决定是否在德国封禁该应用，不过并未设定具体的处理时限。&lt;/p&gt; 
&lt;p&gt;媒体报道显示，谷歌公司证实已收到相关通知，目前正在进行评估；而苹果公司则暂未对此作出回应。&lt;/p&gt; 
&lt;p&gt;此前，DeepSeek 也因所谓数据安全问题，在欧美多地遭遇审查。另据媒体报道，意大利已于今年稍早以「个人数据使用不透明」为由，将 DeepSeek 应用从应用商店下架；荷兰则禁止政府设备使用该应用；比利时也建议政府官员避免使用 DeepSeek，并表示相关评估仍在进行中。与此同时，美国国会议员正计划提出法案，禁止联邦政府机构使用任何中国开发的 AI 模型。&lt;/p&gt; 
&lt;p&gt;针对部分国家传出禁止或限制使用 DeepSeek 的消息，中国外交部发言人此前已作出回应。在今年 2 月 6 日的例行记者会上，外交部发言人表示，中国政府始终高度重视数据隐私和安全保护，并依法开展相关工作，从未要求且将来也不会要求企业或个人以违法形式采集或存储数据。&lt;/p&gt; 
&lt;p&gt;此外，在今年 3 月 18 日的例行记者会上，另一位外交部发言人再次强调，中方一贯反对泛化国家安全概念、将经贸科技问题政治化的做法，并将坚定维护中国企业的合法权益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358029</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358029</guid>
      <pubDate>Fri, 09 May 2025 10:36:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>RWKV-8 系列之 DeepEmbedAttention：精简 KV 缓存，尤其适合混合模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;5 月 27 日，我们公开了 &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FYl79XfbMCO6ecAdKGzboRg" target="_blank"&gt;RWKV-8 首个新特性 DeepEmbed：对端侧友好的稀疏设计，解决 MoE 显存占用&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;今天，我们公开与其相关的另一个新特性：&lt;strong&gt;DeepEmbedAttention（DEA）&lt;/strong&gt; ，这是一种基于 RWKV-8 的 DeepEmbed 思路构建的注意力变体，拥有&lt;strong&gt;极小的 KV 缓存&lt;/strong&gt; ，尤其适合&lt;strong&gt;混合模型&lt;/strong&gt;（例如后续的 RWKV-7s 混合模型），可将它们的长上下文性能提升到 Transformer 水准。&lt;/p&gt; 
&lt;p&gt;DEA 的结构定义例子：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# q: D =&amp;gt; 256
# k: D =&amp;gt; 32, k_up: 32 =&amp;gt; 256, k_emb: V =&amp;gt; 256
# v: D =&amp;gt; 32, vup: 32 =&amp;gt; D, v_emb: V =&amp;gt; D
q = ln_q(q(x))
k = ln_k(k_up(k(x)) * k_emb(idx))
v = ln_v(tanh(v_up(v(x))) * v_emb(idx))   
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;然后将 QKV 的输出加到 RWKV-7 的输出上。这适合并行计算，例如可在不同设备（或异构计算）计算 QKV 和 RWKV-7 部分。&lt;/p&gt; 
&lt;p&gt;这个注意力头的维度是 256，但由于 DEA 的 &lt;code&gt;key&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 只需缓存 32 维，KV 总共只需缓存 64 个值（32+32）。&lt;/p&gt; 
&lt;p&gt;对于 RWKV-7，只需在每层加上一个 DEA head，就能显著增强长上下文能力。因此，对比现有的高效注意力机制（例如 MLA 使用 576 个值），&lt;strong&gt;DEA 的 KV 缓存进一步缩小到 64/576 = 1/9&lt;/strong&gt;，实现了极致效率。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-c7be8702b07a9534c09539a5fa78e2cdc44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;图中 loss delta 图的横轴是随着前文长度增加时 token 的位置（token_pos），纵轴表示两种架构在不同 token 位置的 loss 差值（token_loss delta）。&lt;/p&gt; 
&lt;p&gt;实验结果显示：随着前文长度增加，RWKV-7s（加入 DeepEmbed 和 DEA）在越来越长前文的 loss &lt;strong&gt;相较原版 RWKV-7 持续下降&lt;/strong&gt;，从 -0.13 降至 -0.17。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;这意味着 RWKV-7s 这类添加了 DEA 的混合模型，在处理长上下文时表现更好。因为 token 越靠后，所依赖的前文也越长，而 loss 差值持续扩大，代表 RWKV-7s 对比 RWKV-7 更有能力利用越来越长的前文所包含的越来越多的信息，语言建模能力越来越强。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;最后，尽管 DEA 的 KV 缓存非常小，但它仍会随上下文长度而缓慢增长。&lt;strong&gt;RWKV-8 的目标，是在完全无 KV 缓存的情况下也能实现强上下文能力&lt;/strong&gt;，且我们也有方法，后续逐步公布，欢迎大家关注。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358026</guid>
      <pubDate>Fri, 09 May 2025 10:11:00 GMT</pubDate>
      <author>来源: 资讯</author>
    </item>
    <item>
      <title>欧洲首台百万兆次级超级计算机 JUPITER 启用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;位于德国的于利希超级计算中心（Jülich Supercomputing Center）近日&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspectrum.ieee.org%2Fjupiter-exascale-supercomputer-europe" target="_blank"&gt;推出&lt;/a&gt;了欧洲首台百万兆次级超级计算机 JUPITER (木星)。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="312" src="https://oscimg.oschina.net/oscnet/up-37c973b7767f9f8d83e4f3ade8a1fabef7f.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 于 2025 年 6 月首次亮相于全球最强大计算机系统的 TOP500 排行榜上，位列第四。它拥有 5900 个加速计算节点，配备了约 24000 颗 Nvidia Grace-Hopper&amp;nbsp;超级芯片和 1300 个使用 Rhea1 处理器的节点。此外，JUPITER 还采用了 InfiniBand NDR 网络来确保高速数据传输。该计算机的设计旨在支持复杂的科学计算任务，推动气候模型和天气预报的研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这个项目旨在创建一个地球系统的数字复制品，以更好地监测和预测自然现象与人类活动的相互作用。研究者们表示，需要这样一台大型机器来处理气候和大气数据，JUPITER 能以 700 米的分辨率展示这些物理现象，从而为气象学和气候科学提供更深入的洞察。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，德国伊尔梅瑙工业大学的物理学家们也在利用 JUPITER 进行研究。他们专注于可视化热羽流，探讨流体和气体的对流与湍流现象。科学家们通过这台超级计算机的强大运算能力，能够呈现出以前无法获得的细节，进一步理解自然界中复杂的流动模式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;JUPITER 的建设始于 2018 年，经过多次升级和完善，在 2024 年计划推出的 JEDI 原型机和 JETI 过渡系统模块的支持下，最终在 2025 年全面投入使用。该计算机的能效设计也备受关注，其制冷系统利用附近的鲁尔河水，为校园建筑提供取暖，展现出对能源消耗的关注和可持续发展理念。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358021/jupiter-exascale-supercomputer-europe</guid>
      <pubDate>Fri, 09 May 2025 09:38:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>JSON Crack —— 将 JSON 可视化为交互式图表</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p style="text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;JSON Crack 是一款以结构化交互式图表形式可视化 JSON 数据的工具，方便用户探索、格式化和验证 JSON。它提供多种功能，例如将 JSON 转换为其他格式（CSV、YAML）、生成 JSON Schema、执行查询以及将可视化结果导出为图像。其设计兼顾了可读性和易用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可视化工具&lt;/strong&gt;：立即将 JSON、YAML、CSV、XML 和 TOML 转换为暗模式或亮模式下的交互式图形或树。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转换&lt;/strong&gt;：无缝转换数据格式，如将 JSON 转换为 CSV 或将 XML 转换为 JSON，以便于共享。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;格式化和验证&lt;/strong&gt;：美化和验证 JSON、YAML 和 CSV 以获得清晰准确的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码生成&lt;/strong&gt;：生成 TypeScript 接口、Golang 结构和 JSON 模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JSON Schema&lt;/strong&gt;：创建 JSON Schema、模拟数据并验证各种数据格式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高级工具&lt;/strong&gt;：解码 JWT、随机化数据以及运行 jq 或 JSON 路径查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;导出图像&lt;/strong&gt;：将你的可视化效果下载为 PNG、JPEG 或 SVG。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐私&lt;/strong&gt;：所有数据处理都是本地的；服务器上不会存储任何内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img height="438" src="https://static.oschina.net/uploads/space/2025/0630/164831_2A2G_4252687.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/jsoncrack</link>
      <guid isPermaLink="false">https://www.oschina.net/p/jsoncrack</guid>
      <pubDate>Fri, 09 May 2025 09:20:00 GMT</pubDate>
    </item>
    <item>
      <title>AI 造物社区项目发布指引</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;strong&gt;使用前请先注册 OSC 开源社区账号，按照以下说明操作，照片清晰，报告整洁，介绍全面，附件有代码， 基本会一次性审核通过。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;1. 注册账号&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172849_N1db_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;完成注册并登录后，进入造物社区&amp;nbsp;&lt;/strong&gt;&lt;em&gt;&lt;u&gt;&lt;a href="https://www.oschina.net/ai-creation"&gt;&lt;strong&gt;https://www.oschina.net/ai-creation&lt;/strong&gt;&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;strong&gt;，点击「发布一个新项目/发布一个新的造物」，发布新项目。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172907_YADg_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;2. 项目基础信息&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;标「&lt;span style="color:#d83931"&gt;*&lt;/span&gt;」的为必填项目。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;封面图片上传格式为 4:3，分辨率 1080P，图片内存大小建议小于 1MB，过大容易上传失败。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目介绍部分简要填写项目简介即可。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/172927_GAOA_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;3. 「项目详情」页&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;视频请先上传到 B 站/优酷/腾讯，然后在「视频代码」处粘贴视频分享的嵌入代码（iframe 格式），以下是 B 站复制嵌入代码的方式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173137_W7Ba_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;项目内容填写可根据实际完成项目内容填写，格式可参考示例。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173149_4iMQ_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;代码的插入请使用「代码块」工具插入&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173201_y81p_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;注意格式整洁，正文字号建议用默认字号 14px，标题建议用三级标题&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用 AI 工具前，需先用鼠标选中需要 AI 介入的文段内容，再选择对应的 AI 工具对文段进行润色，AI 翻译当前仅支持「中=英互译」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173212_caKR_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;4. 「所需物料」页&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「硬件组件」一栏点击「添加」，可填写硬件名称、购买网址、购买数量及硬件描述。可添加多个硬件明细。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173223_TJzj_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「软件应用和在线服务」一栏点击「添加」，可添加制作项目所用的软件平台及敏捷制造、供应链服务等。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173234_DrKy_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在「手动工具和生产设备」一栏点击「添加」，可填写用于制作项目的设施设备。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&amp;nbsp;&lt;/h4&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;5. 「附件清单」页&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;在「外壳和定制部件」一栏点击「添加」，可上传 3D 模型、结构件设计图纸等内容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「代码」一栏点击「添加」，可项目代码及硬件「库」等内容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在「原理图和电路图」一栏点击「添加」，可项目接线图、原理图等，建议上传 JPG/PNG 格式文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;编辑完成后点击「下一步」。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;6. 上传团队成员信息，并「发布」项目&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;完成项目内容的编辑之后，先点击「设置为发布」，之后点击「预览项目」可查看自己的项目。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;发布之后若查出存在问题，可在项目预览界面，点击「编辑/删除」再次修改。若在项目通过之后发现存在问题，依旧可再次修改项目，直到项目完善。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173246_6PYI_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;查询项目发布历史可以在「个人中心」——「我的造物」中进行查询或项目修改/删除。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0630/173255_JgBm_9214603.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;&lt;span style="color:#245bdb"&gt;&lt;strong&gt;参考示例&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2006"&gt;https://www.oschina.net/ai-creation/details/2006&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2005"&gt;https://www.oschina.net/ai-creation/details/2005&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/ai-creation/details/2063"&gt;https://www.oschina.net/ai-creation/details/2063&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/358019</link>
      <guid isPermaLink="false">https://www.oschina.net/news/358019</guid>
      <pubDate>Fri, 09 May 2025 09:19:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>悟了，多模态才是智能应用爆发的关键</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;此前，快手发布 2025 年一季度财报时，一个数字引发关注：成立仅两年的 AI 业务线「可灵 AI」单季度贡献营收 1.5 亿元，同比增长 320%。而可灵 AI 正是一个多模态应用的典型产品，涉及到语言、视频、音频等交互。&lt;/p&gt; 
&lt;p&gt;前不久，在 OSCHINA 和小度教育技术负责人丁小晶的&lt;a href="https://my.oschina.net/u/4489239/blog/18426743" rel="nofollow"&gt;对话&lt;/a&gt;中。丁小晶表示，多模态技术非常重要，甚至可以说，没有多模态技术效果的快速提升，教育行业不可能如此迅猛发展。比如 AI 作业批改和 AI 讲题答疑方向的应用，完全靠纯文本大模型是无法满足需求的，非常依赖对大模型的图片理解能力。还比如超拟人 AI 老师，语音情感大模型就起来非常关键的作用。&lt;/p&gt; 
&lt;p&gt;百度最新发布的发布文心快码 Comate AI IDE 产品，其中也提到了多模态能力的增强，比如支持 Figma 设计稿一键转换为高可用代码，能实现图层的精准还原。百度工程效能部前端研发经理杨经纬告诉开源中国，无论是从自然语言、图片还是设计稿生成代码，最终都是为了能更加接近人类工程的意图，因为人类去描述自己想要实现的想法的方式与形态是多种多样的，也就对应了研发过程中的多模态形式。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="210" src="https://oscimg.oschina.net/oscnet/up-db06f16dbd4e854566d762bff8c3dfe1e5f.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;人类从不会只用一种感官认知世界。人工智能也势必不能仅有一种交互途径。&lt;/p&gt; 
&lt;p&gt;我们闻到咖啡香气的瞬间，脑海里会立刻浮现深褐色液体与白瓷杯的画面；听到「猫」这个词时，脑海中自动补全毛茸茸的触感和呼噜声。这种多模态信息融合，正是人类智能的底层逻辑。而单一模态交换的 AI 模型的信息处理能力有限，例如文本生成模型难以理解图像语义，无法根据文字生成图像，视频生成工具则无法同步解析声音与画面逻辑。这种时候，就需要多模态模型或是能力的配合。&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;多模态，比文本慢一步&lt;/h2&gt; 
&lt;p&gt;智源研究院院长王仲远不久前公开&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.msn.cn%2Fzh-cn%2F%25E6%258A%2580%25E6%259C%25AF%2F%25E6%258A%2580%25E6%259C%25AF%25E5%2585%25AC%25E5%258F%25B8%2F%25E8%2581%259A%25E7%2584%25A6%25E5%25A4%259A%25E6%25A8%25A1%25E6%2580%2581-chatgpt%25E6%2597%25B6%25E5%2588%25BB%25E6%259C%25AA%25E5%2588%25B0-2025%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B-%25E5%258F%2598%25E6%2585%25A2-%25E4%25BA%2586%25E5%2590%2597%2Far-AA1GjaHk%3Focid%3DBingNewsSerp" rel="nofollow" target="_blank"&gt;指出&lt;/a&gt;，当前多模态大模型的学习路径，尤其是多模态理解模型，通常是先将语言模型训练到很强的程度，再学习其他模态信息。在这个过程中，模型的能力可能会出现下降。&lt;/p&gt; 
&lt;p&gt;比单一模态更难的是，多模态模型还需解决一个核心问题：如何将图像、文本、音频等异构数据在语义层面对齐并融合。&lt;/p&gt; 
&lt;p&gt;文本、图像、声音等模态的数据结构天然异构——文本是离散符号序列，图像是连续像素矩阵，音频是时间序列信号。比如要让模型理解「猫」的文本描述与猫的图片、叫声之间的关联，需构建跨模态的共享语义空间。&lt;/p&gt; 
&lt;p&gt;早期，有研究尝试通过数据级拼接，将图像像素和文本特征直接拼接，实现跨模态融合，但由于图像和文本的时空特性差异较大，导致特征对齐困难，最终效果不佳。直到对比学习和注意力机制的出现，才实现跨模态语义映射。比如 OpenAI 2021 年推出的一种基于对比学习只的多模态预训练模型 CLIP，它通过大规模的图像和文本数据进行训练，使得模型能够理解图像内容和相关文本之间的语义关系。CLIP 的核心贡献在于它打破了传统的固定类别标签范式，通过对比学习的方式，将图像和文本映射到同一个向量空间中，从而实现跨模态的检索和分类。但是 CLIP 模型的训练数据规模庞大，据 OpenAI 披露，其使用了约 4 亿图像-文本对进行训练，训练成本高达数千 GPU 日，远超 GPT-3 等纯文本模型。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="304" src="https://oscimg.oschina.net/oscnet/up-4ad6b286433edebde043654fd53af191e30.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="color:#8f959e"&gt;&lt;em&gt;CLIP 模型方法概述 &lt;/em&gt;&lt;/span&gt;&lt;span style="color:#8f959e"&gt;&lt;u&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2103.00020" rel="nofollow" target="_blank"&gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;多模态融合需处理高维数据，如 4K 视频的像素量是文本的百万倍，传统 Transformer 的二次方计算复杂度成为致命短板。对此，业界也有一些解决方式，比如此前 Mamba 架构通过状态空间模型 SSM 将计算复杂度降至线性，2025 年扩展动态融合模块&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F2985554863" rel="nofollow" target="_blank"&gt; FusionMamba&lt;/a&gt;，在其中实现多模态特征高效交互，推理速度提升 3 倍。&lt;/p&gt; 
&lt;p&gt;不仅如此，相较于文本的资料库和数据集，高质量多模态数据集也更加稀缺，收集难度更大。比如医疗影像、工业质检的报告中的缺陷描述等，就需专家级别的标注人员。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;落地需求更多&lt;/h2&gt; 
&lt;p&gt;虽然技术上还有诸多难点，但是多模态能力正在逐步提升，并且带来非常可观的价值和效果。&lt;/p&gt; 
&lt;p&gt;比如，从图片或者是 Figma 设计稿直接生成代码可以帮助许多开发者或是产品经理完成一些开发工作。这项能力此前在一些低代码或是辅助编程工具中也存在，但往往是通过 Figma DSL 进行设计稿解析，通过节点虚拟化技术实现像素级还原，其不足在于不一定适配当前项目，比如转了一套 Vue 框架的代码，就无法在 React 框架项目中使用。&lt;/p&gt; 
&lt;p&gt;杨经纬介绍，此次文心快码 Comate AI IDE 的发布以及相关功能更新后，通过大模型能力增强了 Figma to Code 和当前项目的融合度。首先在 IDE 里进行操作，天然就可以理解用户当前环境和本地优势，而 IDE 内智能体 Zulu 的接入，会更深入到本地项目中了解当前的框架、能力、代码风格等，再结合 Image to Code 的能力，可以实现较高的还原度，并且适配当前的项目。&lt;/p&gt; 
&lt;p&gt;而根据一些公开信息显示，可灵 AI 的多模态技术，支持通过图片、文字、声音甚至手绘轨迹等输入生成视频。在上半年的 2.0 模型的迭代中，可灵 AI 也发布了 AI 视频生成的全新交互理念 Multi-modal Visual Language（MVL），让用户能够结合图像参考、视频片段等多模态信息，将脑海中包含身份、外观、风格、场景、动作、表情、运镜在内的多维度复杂创意，直接高效地传达给 AI。MVL 由 TXT（Pure Text，语义骨架）和 MMW（Multi-modal-document as a Word，多模态描述子）组成，能从视频生成设定的基础方向以及精细控制这两个层面。此外，其技术也结合了类 Sora 的 DiT 结构和 Flow 扩散模型，提升在物理模拟和细节上的表现。&lt;/p&gt; 
&lt;p&gt;基于这些技术特征。商业化层面，截至今年 6 月，可灵 AI 已为超过 1 万家企业客户提供 API 服务，覆盖广告营销、影视动画等领域，企业客户续费率较高。&lt;/p&gt; 
&lt;p&gt;此外，一些传统行业或场景也在结合多模态能力，实现与 AI 的加速融合。比如迪瑞医疗近期采用的多模态 AI 大模型算法技术为临床诊断带来了重要的技术革新，结合多种检测结果和患者的多维信息，如尿常规、血常规、生化和化学发光免疫，以及患者的个人背景、临床表现、现病史与既往病史等，进行全面分析。&lt;/p&gt; 
&lt;p&gt;这种跨学科的信息整合使得诊断提示更加精准，对于减少漏诊、误诊的概率具有显著的作用，并进一步提升了医疗诊疗的整体效率。大洋彼岸，斯坦福医学院的科研团队研发出了一种名为&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzkxMTM0OTQzNQ%3D%3D%26mid%3D2247486194%26idx%3D1%26sn%3D5ac605d67ca7019b3b2e524d65b0f88e%26chksm%3Dc0eed67e545679711993370e69032cc62e9d4fc0c6ff3e283c43854fd93355eae8a07b4fcb02%23rd" rel="nofollow" target="_blank"&gt; MUSK 的 AI 模型&lt;/a&gt;，将视觉数据，如病理图像和文本数据的病历和临床记录相结合，为癌症治疗带来了新的可能。MUSK 模型不仅提高了预测癌症患者预后和治疗反应的准确性，而且通过分析数千个数据点，更准确地确定了哪些疗法对个体患者最有效。&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img height="285" src="https://oscimg.oschina.net/oscnet/up-196e0ee8b1058ba8ee70698e626a846fe72.png" width="800" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;span style="background-color:#f2f3f5"&gt;&lt;em&gt;视觉问答测试，图片来源于网络&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:left"&gt;在金融领域。江苏银行通过本地化部署微调 DeepSeek-VL2 多模态模型、轻量 DeepSeek-R1 推理模型，分别运用于智能合同质检和自动化估值对账场景中，通过对海量金融数据的挖掘与分析，重塑金融服务模式，实现金融语义理解准确率与业务效率双突破。具体而言，DeepSeek-VL2 多模态模型采用了最新的 Transformer 架构，结合多层次的特征融合机制，有效提升了金融合同、账单等复杂文本与图像信息的理解能力。模型在智能合同质检场景中表现出色，准确率较传统方法提升了 15% 以上，显著降低了人工审核成本。同时，轻量化的 DeepSeek-R1 推理模型则在自动化估值与对账场景中展现出极佳的实时响应能力，推理速度提升了 30%，为金融业务流程的自动化提供了坚实支撑。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;新的基础设施&lt;/h2&gt; 
&lt;p&gt;应用边界在不断拓宽的同时，多模态模型的能力也在成长。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;而随着应用场景的深化，模型架构也在同步进化，从基础感知迈向复杂推理成为必然趋势。OpenAI 在 2025 年 4 月发布了多模态模型 O3 和 O4-mini，实现了「用图像思考」的突破性能力。这些模型不仅能够识别图像内容，还能将图像信息整合进推理思维链，支持多步推理和因果分析，比如够处理模糊、倒置或复杂的图像输入，并给出合理的推理结果。&lt;/p&gt; 
&lt;p style="text-align:left"&gt;其背后的关键技术包括分层注意力机制，将图像分解为局部细节、全局关系和时序逻辑三层结构，从而提升对图像内容的理解能力；动态工具链调用，在推理过程中，模型可以自主选择 Python 分析、知识图谱检索、图像生成等工具辅助决策，以及安全约束模块，通过对抗训练减少模型的幻觉输出。&lt;/p&gt; 
&lt;p&gt;就在本月，中国科学院自动化研究所等单位的科研人员&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fkw.beijing.gov.cn%2Fxwdt%2Fkcyx%2Fxwdtkjqy%2F202506%2Ft20250611_4111006.html" rel="nofollow" target="_blank"&gt;首次证实&lt;/a&gt;，多模态大语言模型在训练过程中自己学会了「理解」事物，而且这种理解方式和人类非常像。&lt;/p&gt; 
&lt;p&gt;科研人员借鉴人脑认知的原理，设计了一个巧妙的实验：让大模型和人类玩「找不同」游戏。实验人员会给出三个物品概念（选自 1854 种常见物品），要求选出最不搭的那个。通过分析高达 470 万次的判断数据，科研人员绘制出了大模型的「思维导图」——「概念地图」。通过实验证实多模态大模型具备类人「概念理解」能力。研究团队设计「找不同」游戏，基于 470 万次判断数据绘制大模型「概念地图」，提炼 66 个理解维度（如物体功能、文化意义），发现其与人脑神经活动高度一致，证明多模态模型比纯文本模型更接近人类思维模式。&lt;/p&gt; 
&lt;p&gt;据谷歌云在 2024 年年底发布的&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnews.qq.com%2Frain%2Fa%2F20241219A07AW200" rel="nofollow" target="_blank"&gt;《2025 年人工智能商业趋势报告》&lt;/a&gt;，预测到 2025 年，多模态 AI 将成为企业采用 AI 的主要驱动力。这种技术通过整合图像、视频、音频和文本等多种数据源，使 AI 能够以前所未有的准确性从更广泛的上下文源中学习，提供更精确、定制化的输出，创造自然直观的体验。报告预计，全球多模态 AI 市场规模将在 2025 年达到 24 亿美元，到 2037 年底达到 989 亿美元。&lt;/p&gt; 
&lt;p&gt;2025 进度已经过半，我们也能看到市面上许多多模态技术和产品的进展，而这场变革的终极图景，或许正是让 AI 真正成为理解世界、服务人类的「多模态智能伙伴」。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18679654</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18679654</guid>
      <pubDate>Fri, 09 May 2025 09:07:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
