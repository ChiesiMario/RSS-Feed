<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 12 Feb 2025 21:39:34 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>RWKV 2025 生态内容征集大赛 | 1 月投稿作品及评审结果</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;大家好，我们在 2024 年底推出了 「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FUeKemVw9HnTU6FBL1iM0bg&quot; target=&quot;_blank&quot;&gt;RWKV 2025 生态内容征集大赛&lt;/a&gt;」，公开征集 RWKV 相关的作品，包括但不限于 RWKV 相关的论文、讲解 RWKV 的教程，以及基于 RWKV 的应用等。&lt;/p&gt; 
&lt;p&gt;2025 年 1 月，活动共收到 RWKV 生态作品投稿 &lt;strong&gt;11 份&lt;/strong&gt;，包括 &lt;strong&gt;3 篇论文、7 款应用和 1 篇教程/动画&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;本文将公布 2025 年 1 月的活动投稿作品及评审结果。&lt;/p&gt; 
&lt;h2&gt;评审结果和意见&lt;/h2&gt; 
&lt;h3&gt;论文类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UI&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03971&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.03971&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-UI: UI Understanding with Enhanced Perception and Reasoning&lt;/li&gt; 
   &lt;li&gt;投稿人：Kmui&lt;/li&gt; 
   &lt;li&gt;获奖类型：金奖（4888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：基于 RWKV 的全新研究方向，因此获得金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OmniRWKVSR&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.00404&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.00404&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：Exploring Linear Attention Alternative for Single Image Super-Resolution&lt;/li&gt; 
   &lt;li&gt;投稿人：nomodeset&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-UNet&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.08458&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.08458&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-UNet：Improving UNet with Long-Range Cooperation for Effective Medical Image Segmentation&lt;/li&gt; 
   &lt;li&gt;投稿人：Gavin&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;应用类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;fla-rwkv7&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fcollections%2Ffla-hub%2Frwkv7-6790fd37b4b6137b088a0d8a&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/collections/fla-hub/rwkv7-6790fd37b4b6137b088a0d8a&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：flash-linear-attention 的 RWKV-7 支持&lt;/li&gt; 
   &lt;li&gt;投稿人：张宇&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：如果可以解决这个库运行 Bo 的 MMLU 脚本时的速度和显存占用问题，&lt;strong&gt;可升级金奖&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;conRWKV&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2F00ffcc%2FconRWKV&quot; target=&quot;_blank&quot;&gt;https://github.com/00ffcc/conRWKV&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：提供了一个高并发的 RWKV 云端推理引擎，以方便后续基于 RWKV 的应用&lt;/li&gt; 
   &lt;li&gt;投稿人：#9AC8E2&lt;/li&gt; 
   &lt;li&gt;获奖类型：银奖（2888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;R-translator&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fl15y%2FR-translator&quot; target=&quot;_blank&quot;&gt;https://github.com/l15y/R-translator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 RWKV 的 AI 翻译工具&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;获奖类型：铁奖（888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RWKV-ZeroCoT&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2FRWKV-ZeroCoT&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/RWKV-ZeroCoT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：ZoreCoT 的原始实现&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;获奖类型：铁奖（888 元）&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;substitute&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FAXFOX%2Fsubstitute&quot; target=&quot;_blank&quot;&gt;https://github.com/AXFOX/substitute&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 Ai00 Server（RWKV） 驱动的 Kdenlive 字幕校验和替换工具&lt;/li&gt; 
   &lt;li&gt;投稿人：我想上岸&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;rwkv v6 7b cot&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2Fly444983%2FRWKV_ST_for_AI00%2Ffile%2Fview%2Fmaster%3FfileName%3D7B_LY_COT.state%26status%3D2&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/ly444983/RWKV_ST_for_AI00/file/view/master?fileName=7B_LY_COT.state&amp;amp;status=2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：基于 RWKV-V6-7B 的 rwkv cot state&lt;/li&gt; 
   &lt;li&gt;投稿人：lyyyy&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;new_rwkv_pip&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FBeortext%2Fnew_rwkv_pip&quot; target=&quot;_blank&quot;&gt;https://github.com/Beortext/new_rwkv_pip&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：重构后的 rwkv_pip 库，把 v4-v7 各代模型都整理成统一的结构&lt;/li&gt; 
   &lt;li&gt;投稿人：Beortust&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可再次投稿评审以升级奖项&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;教程/动画类&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;有思维的语言模型：RWKV-7 状态演化过程&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;投稿链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1DY6fYdECa%2F&quot; target=&quot;_blank&quot;&gt;https://www.bilibili.com/video/BV1DY6fYdECa/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;项目介绍：RWKV-7 状态演化视频&lt;/li&gt; 
   &lt;li&gt;投稿人：136279841&lt;/li&gt; 
   &lt;li&gt;获奖类型：参与奖&lt;/li&gt; 
   &lt;li&gt;评审意见：作品高赞评论在质疑效果，请用 v7 的实际效果去向用户证明。如果用户认可，可升级奖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;评审结果快速对照表格&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;作品名称&lt;/th&gt; 
   &lt;th&gt;作品分类&lt;/th&gt; 
   &lt;th&gt;投稿人&lt;/th&gt; 
   &lt;th&gt;初评奖项&lt;/th&gt; 
   &lt;th&gt;得奖理由&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UI&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;Kmui&lt;/td&gt; 
   &lt;td&gt;金奖（4888 元）&lt;/td&gt; 
   &lt;td&gt;基于 RWKV 的全新研究方向&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OmniRWKVSR&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;nomodeset&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-UNet&lt;/td&gt; 
   &lt;td&gt;论文&lt;/td&gt; 
   &lt;td&gt;Gavin&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;该领域已存在若干 RWKV 论文，如果有实际 DEMO 证明作品的效果最好，可升级金奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;有思维的语言模型：RWKV-7 状态演化过程&lt;/td&gt; 
   &lt;td&gt;教程/动画&lt;/td&gt; 
   &lt;td&gt;136279841&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;作品高赞评论在质疑效果，请用 v7 的实际效果去向用户证明。如果用户认可，可升级奖。&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;substitute&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;我想上岸&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fla-rwkv7&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;张宇&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;如果可以解决这个库运行 Bo 的 MMLU 脚本时的速度和显存占用问题，可&lt;strong&gt;升级金奖。&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;R-translator&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;铁奖（888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rwkv v6 7b cot&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;lyyyy&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RWKV-ZeroCoT&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;铁奖（888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;new_rwkv_pip&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;Beortust&lt;/td&gt; 
   &lt;td&gt;参与奖&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conRWKV&lt;/td&gt; 
   &lt;td&gt;应用&lt;/td&gt; 
   &lt;td&gt;#9AC8E2&lt;/td&gt; 
   &lt;td&gt;银奖（2888 元）&lt;/td&gt; 
   &lt;td&gt;应用缺少实际用户，可面向社区内外宣传并招募用户，有真实用户后可以&lt;strong&gt;再次投稿评审以升级奖项&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;奖品/奖金发放规则&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;实物奖品（RWKV 周边等）&lt;strong&gt;以&lt;/strong&gt;顺丰快递&lt;/strong&gt;方式发出&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;奖金&lt;/strong&gt;以&lt;strong&gt;转账或第三方线上平台&lt;/strong&gt;等方式发放&lt;/li&gt; 
 &lt;li&gt;同一投稿作品有&lt;strong&gt;多位作者&lt;/strong&gt;的情况下，由&lt;strong&gt;作品投稿人&lt;/strong&gt;领取奖金，团队内部&lt;strong&gt;自行协商分配奖金&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;二次投稿与奖项升级&lt;/h2&gt; 
&lt;p&gt;所有投稿作品均会获得&lt;strong&gt;评审意见&lt;/strong&gt;。请根据评审意见优化你的作品，然后可&lt;strong&gt;再次投稿以升级奖项&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;奖项成功升级时，我们将补发&lt;strong&gt;前后两个奖金的差价&lt;/strong&gt;。例如投稿作品从铁奖（888 元）升级到银奖（2888 元），则补发 2888-888=2000 元奖金。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;附活动海报&lt;/strong&gt;，欢迎各位转发！&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-de56881e7277f3f31798464afb87dbc3c15.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;* 本活动最终解释权归元始智能所有。&lt;/strong&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333398</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333398</guid>
            <pubDate>Fri, 07 Feb 2025 09:57:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>别再买 9.9 的 deepseek 本地部署啦！一文教你轻松部署，告别 「服务器繁忙」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;开源的意义，在于人人机会均等。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;本人 IT 小白，不会写代码、不会看文档，甚至一句「 Hello ，World 」 用 Python 写完，都要靠高亮来判断语法是否正确。哈哈哈，像我这样的人，离本地部署，畅玩 Deepseek 远吗？&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;实测！世上无难事，只要肯动手！&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是我用公司配发的 HP 笔记本，本地部署 deepseek 的傻瓜式流程，内容如下：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;设备： HP Laptop 14&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;系统：Win&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;应用程序：LM Studio&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;模型版本：DeepSeek R1 Distill Qwen 1.5B &lt;span style=&quot;color:#8f959e&quot;&gt;（我都这配置了，还要啥自行车）&lt;/span&gt;；DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;辅助工具：VS code &lt;span style=&quot;color:#8f959e&quot;&gt;（轻量？不不不，它是神）&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p&gt;&lt;strong&gt;为什么我会选用 LM Studio &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;在尝试部署之前，同事跟我推荐过一个叫「 Ollama 」 的开源工具，但我实测之后发现，在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Follama.com%2F&quot; target=&quot;_blank&quot;&gt;https://ollama.com/&lt;/a&gt; （ Ollama 官网）下载 Windows 版本时，可能会跳转到 github ，响应超时而无法下载。&lt;/p&gt; 
 &lt;p&gt;并且，Ollama 主要围绕命令行展开，不像 LM Studio 具备直观的图形化操作界面，通过「点点点」就可以使用，所以，对于很多名词都不明所以的我来说——&lt;strong&gt;能用，比好不好用，更重要。&lt;/strong&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_1&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;1、于是，我进入 LM Studio 的官网（ &lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flmstudio.ai%2F&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;https://lmstudio.ai/&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; ），并下载了首页的 0.3.9 版本。&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fe0fc4d91864142b575cad0941864dbb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_2&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;2、下载 LM Studio 3.9.0-6-x68 安装包，所需空间 1.3 &lt;/strong&gt;&lt;strong&gt;GB&lt;/strong&gt;&lt;strong&gt; （全中文的，没有门槛）&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a9c2a4552e660adf721db6398545166a.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;打开【 LM-Studio 】，就可以使用该软件，也可以创建桌面快捷。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//1c26e3812675b161bb2711f22a87de0d.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;界面长这样👇&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//14810d4ac4953cce2010fb5f0fc7e593.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_3&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;3、英文界面？没事儿！内置简体中文~&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//381dd1bf2bc27a93d7cd0133f14a362e.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c4521be9d0ece8c5f6522e29c72f58cb.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;span id=&quot;OSC_h4_4&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;4、接下来，我们就可以下载模型了，也超简单&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//5b68c13f9a0a6c4737a2d41f8cc92b69.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;但是，问题来了！！！&lt;/strong&gt;第一次下载 LM Studio ，搜索模型并下载，往往下载不了，这是因为 LM Studio 关联 Hugging Face 或 llama.cpp 的模型库，默认下载地址无法正常访问。&lt;strong&gt;此时，我们可以通过 VScode ，修改 LM Studio 的安装文件解决。&lt;/strong&gt;（ 怎么下载 VScode ？别搞了兄弟！）&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;退出 LM Studio 后，打开 LM Studio 的安装目录，如👇图&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//7c7e5de0c94f6bc1ac0a848d340120b9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;找到两个文件，路径如下&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\main\index.js&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;\resources\app.webpack\renderer\main_window.js&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bad366546f55463174a123dcd533fb38.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;打开 VScode ，在 VCcode 同时打开这两个文件&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e72d38f52a807e0bd51fa1a323451edf.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷键 ctrl+shift+h 调出批量替换，将 &lt;code&gt;huggingface.co&lt;/code&gt; 替换成 &lt;code&gt;hf-mirror.com&lt;/code&gt; ，然后快捷键 ctrl+alt+enter 应用替换（两个文件同时打开时，可同时替换）&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bd348a106dd3879fb521b5ffad959a78.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;快捷键 ctrl+s ，保存文件即可退出 VScode ，再打开 LM Studio 就可以搜索下载模型了~&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;span id=&quot;OSC_h4_5&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;&lt;strong&gt;5、搜索适合设备配置的模型，下载并使用&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e1323fb9dc1b4b3b3f89f726b17290d9.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;一开始，小编也只敢用 HP 本下载最小的 1.5B ，但后面搜索了一些资料，整理下表：&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;307&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-aeb8f9a7b500a326f92c20de7d91ce400c8.jpg&quot; width=&quot;784&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;span id=&quot;OSC_h4_6&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;6、实测阶段&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 1.5B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;问题设置 1：人有几只脚？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//334794f64dac8ccb583dd0137b9e933c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 2：请简述一下，什么是「模型蒸馏」？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//962255f6c3582b01c7913ace1faf11fd.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//069652c7705521531ac17af8bab48c79.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//c72aa05116825a0c8727b76d77d13e1c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 3：8.11 和 8.4 谁大？直接得出结论。&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//bb33fdd55da3112b2dcf57f18e1fbe8c.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;DeepSeek R1 Distill Qwen 7B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;问题设置 1：你认为「模型开源」的意义是什么？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3c5c2039712441d2048404de675270ba.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 2：你如何评价梁文锋？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//b3f62d7ac407be1f2b9fa9b7f19304aa.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;问题设置 3：你认为，人工智能的下一个技术突破点是？&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e76d56190bda354d2f8bf81e6f187557.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;得到这个回答时，我发现，并不是我想要的，所以，我又继续追问了一个问题：&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;如果不局限于中国呢？如果是全球人工智能技术，你觉得下一个技术突破点是什么？ &lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;以下是 7B 的答案（因为不好截图，所以用文字表达）：&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;在人工智能领域，每一次技术突破都伴随着对现有局限性的突破和技术创新。如果将目光放长远，并不限于中国的地区或行业背景，全球范围内，下一个可能的技术突破方向可以从以下几个角度进行分析：&lt;/p&gt; 
  &lt;p&gt;1. &lt;strong&gt;通用人工智能（AGI）的突破&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;目前，AI 主要集中在特定任务上（如 NLP、计算机视觉等），仍然缺乏真正具有「通用性」的自主学习能力。如何让机器具备类似人类般的学习能力和通用认知模式仍然是一个未解之谜。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;符号推理与&lt;/strong&gt;&lt;strong&gt;知识图谱&lt;/strong&gt;：结合符号逻辑和知识图谱，使得 AI 能够进行更抽象的推理和概念理解。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;strong&gt;的进化&lt;/strong&gt;：探索更具效率和创造力的强化学习方法，推动 AGI 的发展。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨模态理解和整合&lt;/strong&gt;：使 AI 能够更好地理解和处理多模态信息（如文本、图像、音频等），从而具备更全面的理解能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;2. &lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;与协作&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;当前的大模型（如 GPT 系列、LLama 系列）已经在特定领域展现了强大的性能，但规模和复杂性仍然有限。未来，通过模型的联合训练和知识共享（如「元学习」或「模型平均」），可能实现更大规模、更高效的 AI 系统。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;具体方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;模型协作与知识共享&lt;/strong&gt;：多个研究机构或企业联合训练大型语言模型，促进知识的开放性和共享性。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多领域&lt;/strong&gt;&lt;strong&gt;大模型&lt;/strong&gt;&lt;strong&gt;的融合&lt;/strong&gt;：创建涵盖科学、艺术、医疗等多领域的大型模型，提升跨领域应用的能力。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;3. &lt;strong&gt;人机协作与&lt;/strong&gt;&lt;strong&gt;自适应系统&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;随着 AI 技术的成熟，人机协作将成为未来的重要趋势。如何让 AI 能够更自然地与人类交互、理解和协同工作，仍然是一个关键方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;情感理解与伦理决策&lt;/strong&gt;：开发能够理解人类情感和价值观的 AI 系统，使其在复杂的社会环境中做出更具伦理性的决策。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;动态任务适应&lt;/strong&gt;：设计更加灵活的 AI 系统，能够在不同情境中自适应任务要求，提升通用性。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;4. &lt;strong&gt;多模态与跨媒体理解&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;当前 AI 大多局限於单一模态（如文本或图像），如何整合多种模态信息（如文本、音频、视频、甚至传感器数据）进行更全面的理解和推理，仍然是一个未解之谜。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模态融合框架&lt;/strong&gt;：开发能够处理并整合多种模态数据的模型架构。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨领域&lt;/strong&gt;&lt;strong&gt;知识图谱&lt;/strong&gt;：构建跨领域的知识图谱，帮助 AI 更好地理解不同模态之间的关系。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;5. &lt;strong&gt;硬件与效率优化&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;虽然大模型在软件层面取得了进展，但计算资源（如 GPU、TPU 等）仍然是制约其广泛应用的关键因素。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;未来可能会有更高效的硬件设计和算法优化，使得 AI 系统的计算效率显著提升。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;6. &lt;strong&gt;伦理与安全&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;AI 的自主性和复杂性可能带来新的伦理问题和安全风险。如何在技术发展的同时确保 AI 系统的安全性和透明性，也是一个重要方向。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;可能的技术方向包括：&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt;系统的透明性&lt;/strong&gt;：研究如何让 AI 系统更加透明，以便于人类理解和监督。&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;法律与框架的完善&lt;/strong&gt;：推动相关法律法规的制定，确保 AI 技术的发展符合社会价值观。&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;总结&lt;/p&gt; 
  &lt;p&gt;从全球视角来看，下一个技术突破可能集中在以下方面：&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt; &lt;p&gt;推动 AGI（通用人工智能）的发展；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;扩展大模型的协作和共享能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;提升多模态理解和人机协作能力；&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;优化硬件效率并确保伦理安全。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
  &lt;p&gt;这些方向既需要基础理论研究，也需要跨学科合作和技术落地。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;span id=&quot;OSC_h4_7&quot;&gt;&lt;/span&gt; 
 &lt;h4&gt;7、后记&lt;/h4&gt; 
 &lt;p&gt;体验了几个回合下来，首先能肯定的是，上文测试的两个模型确实没有网页版 or APP 版所输出的内容有趣（怪小编&lt;s&gt;财&lt;/s&gt;实力不行），但至少不会出现「服务器繁忙」，且不联网也可以使用。&lt;/p&gt; 
 &lt;p&gt;其次，通过 LM Studio ，我们还可以轻松部署甚多有意思的开源模型在本地，而写这一篇超超超超超基础的博客，无非是在回答本文一开始的那句话：&lt;strong&gt;开源的意义，在于人人机会均等&lt;/strong&gt;。不仅是程序员、开发者、AI 从业人员，如根本不会写代码的我，也可以共享这一份人类智慧。&lt;/p&gt; 
 &lt;p&gt;可能有人会说，1.5B 能干什么？像个傻子！7B 能干什么？上不得枱面！对此，小编想用 Deepseek R1 自己输出的一句话回答大伙儿——&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;火焰不需要羡慕灰烬的重量（满血模型，也是从第一行代码而来的）&lt;/strong&gt;。&lt;/p&gt; 
 &lt;p&gt;最后，分享一个昨晚在地铁上亲历的场景：&lt;/p&gt; 
 &lt;p&gt;寒假快结束了，两个小学生在地铁上互抄作业，小学生 A 说：「牛 B 呀！寒假生活你居然做完了？！」 小学生 B 说：「你傻呀！用 AI 呀~手机摸出来给我玩两把！我跟你上分！」&lt;/p&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
 &lt;/div&gt; 
 &lt;p&gt;PS：希望在哪些网络覆盖不佳、基础设备不好，逼仄、失语的角落，也能萌芽智慧之光......&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/7819858/blog/17563840</link>
            <guid isPermaLink="false">https://my.oschina.net/u/7819858/blog/17563840</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>百度今年或将发布下一代 AI 模型 Ernie 5.0</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.cnbc.com%2F2025%2F02%2F12%2Fchina-tech-giant-baidu-to-release-next-generation-ai-model-this-year-as-deepseek-shakes-up-market.html&quot; target=&quot;_blank&quot;&gt;据 CNBC 报道&lt;/a&gt;&lt;/u&gt;，百度今年将发布下一代 AI 模型 Ernie 5.0。&lt;/p&gt; 
&lt;p&gt;消息人士称，被称为「基础模型」的 Ernie5.0，将在多模态能力方面有重大增强，但没有具体说明其功能。「多模态」AI 指可以处理文本、视频、图像和音频等不同形式的数据，并进行转换和结合 —— 比如将文本转化为视频，或反向操作。而基础模型能够理解语言，执行包括生成文本、图像在内的多种任务，同时支持与人类自然语言的互动。&lt;/p&gt; 
&lt;p&gt;这一消息正值苹果公司将其潜在客户&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333288&quot;&gt;转向&lt;/a&gt;&lt;/u&gt;阿里巴巴之后，市场普遍猜测此举是百度为了应对局势的变化，试图稳住股价和市场地位。&lt;/p&gt; 
&lt;p&gt;百度首席执行官李彦宏本周在迪拜的世界政府峰会上表示：「我们正处于一个令人激动的时代……12 个月内，基础模型的推理成本预计将下降 90% 以上。如果成本能够大幅降低，意味着生产力将呈同等比例提升。这也正是创新的核心所在。」 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;报道称，百度的文心大模型已经在其多个面向消费者和企业的产品中应用，包括云存储和内容创作。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;百度上个月宣布，截至 2024 年底，其文库平台已吸引 4000 万付费用户，比 2023 年底增长了 60%。包括利用 AI 根据公司财报生成 PPT 在内的一系列新功能，已在 1 月开始向用户发布。&lt;/p&gt; 
&lt;p&gt;当前的 ERNIE 模型版本为 4.0，于 2023 年 10 月发布。2024 年 8 月，百度发布了升级版的 ERNIE 4.0 &quot;turbo&quot;，目前并未正式宣布下一次更新的计划。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-741c4810e55393b362a8f9a60b8c98a65dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333389</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333389</guid>
            <pubDate>Fri, 07 Feb 2025 09:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英特尔开源全新 NLP 模型：Polite Guard</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;英特尔&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;推出 Polite Guard，一种用于文本分类任务的开源自然语言处理 (NLP) 语言模型，采用 MIT 许可。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 旨在使开发人员更容易生成自己的合成数据并微调他们的模型、通过提供针对敌对攻击的防御机制来增强系统的弹性、允许开发人员评估和比较他们的模型在礼貌分类方面的性能，以及通过确保在各个平台上进行尊重和礼貌的互动来提高客户满意度和忠诚度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该模型由 BERT 微调而来，可将文本分为四个不同的类别：polite, somewhat polite、neutral 以及 impolite。目前，英特尔已在&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fintel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt; 和&lt;/span&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fdatasets%2FIntel%2Fpolite-guard&quot; target=&quot;_blank&quot;&gt;Hugging Face&lt;/a&gt;&lt;span style=&quot;color:#262626&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;上开源了相关的数据集和 Polite Guard 源代码。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Polite Guard 数据集包含三个部分：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Few-Shot 提示生成 50,000 个带标签样本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;使用 Chain-of-Thought（CoT）提示生成的 50,000 个带标签样本。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;来自企业培训的 200 个经过匿名化处理（屏蔽个人标识符）的标注样本。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告指出，合成数据被划分为训练集（80%）、验证集（10%）和测试集（10%），每组均根据标签进行平衡。Polite Guard 模型完全在合成数据上进行训练，但在合成数据和真实标注数据的测试集上进行评估，准确率和 F1 分数均达到了 92.4%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46439a7eec58b0b02d7e2377a193c43abe8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;167&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3e66b191ecaab81e31ad281895c85f48be6.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多详情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.intel.com%2Ft5%2FBlogs%2FTech-Innovation%2FArtificial-Intelligence-AI%2FIntroducing-Intel-s-new-NLP-model-Polite-Guard%2Fpost%2F1664135&quot; target=&quot;_blank&quot;&gt;英特尔社区博客&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333358/intel-polite-guard</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333358/intel-polite-guard</guid>
            <pubDate>Fri, 07 Feb 2025 07:28:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>英国和美国拒绝签署国际人工智能宣言</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;在巴黎举行的全球峰会上，英国和美国没有签署人工智能（AI）国际宣言。这份由法国、中国和印度等国签署的声明承诺以&quot;开放&quot;、&quot;包容&quot;和&quot;道德&quot;的方式来发展人工智能技术。&lt;/p&gt; 
&lt;p&gt;在巴黎举行的人工智能行动峰会的讨论重点是人工智能对社会和环境的影响——以及需要采取哪些行动来获取其利益和防范其风险。&lt;/p&gt; 
&lt;p&gt;美国和英国没有解释不签署的原因。&lt;/p&gt; 
&lt;p&gt;但早些时候，美国副总统万斯（JD Vance）在巴黎对与会代表说，对人工智能（AI）的过多监管可能会&quot;扼杀一个刚刚起飞的变革性行业&quot;。万斯周二在巴黎举行的峰会上告诉世界各国领导人，人工智能是&quot;特朗普政府不会浪费的机会&quot;，并表示&quot;有利于增长的人工智能政策&quot;应优先于安全。他说，这将需要促进人工智能发展的监管，&quot;而不是扼杀它&quot;。万斯还说，欧洲领导人尤其应该&quot;以乐观而非恐惧的态度看待这一新领域&quot;。&lt;/p&gt; 
&lt;p&gt;他的这番话似乎让他与法国总统埃马纽埃尔-马克龙（Emmanuel Macron）产生了分歧，后者为进一步监管的必要性进行了辩护。&lt;/p&gt; 
&lt;p&gt;马克龙在峰会上说：&quot;我们需要这些规则来推动人工智能的发展。&quot;这是在讨论人工智能发展对社会、环境和治理的影响之际发表的。&lt;/p&gt; 
&lt;p&gt;参加巴黎峰会的政策制定者、高管和外交官们一直在思考如何获取人工智能创新的经济效益，同时应对该技术的风险。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d1decb699dddc94378060a3327ba296ab72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;法国总统埃马纽埃尔-马克龙（Emmanuel Macron）在社交媒体上发布了自己出演热门电影和电视剧的 deepfake 搞笑片段汇编，拉开了本次峰会的序幕。&lt;/p&gt; 
&lt;p&gt;欧盟委员会主席乌苏拉-冯德莱恩（Ursula von der Leyen）周二表示：&quot;本次峰会的重点是行动，而这正是我们现在所需要的。&quot;她说，在整个峰会期间，欧洲一直倡导的人工智能方法也将强调创新、合作和&quot;拥抱开源&quot;技术的力量。&lt;/p&gt; 
&lt;p&gt;此次会议的召开正值美欧贸易关系日益紧张之际。美国总统特朗普已决定对进口到美国的钢铁和铝征收关税，此举将影响英国和欧盟。&lt;/p&gt; 
&lt;p&gt;据悉， 英国不会立即采取报复行动，因为英国既要与特朗普政府保持良好关系，又要与欧盟建立更紧密的关系，因此英国希望走一条微妙的道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333337</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333337</guid>
            <pubDate>Fri, 07 Feb 2025 05:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI CEO 奥尔特曼：愿意在人工智能领域与中国合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日，美国企业家埃隆·马斯克等投资人当地时间 2 月 10 日提议「以 974 亿美元竞购」由其参与创建的美国开放人工智能研究中心（OpenAI）的非营利性母公司。&lt;/p&gt; 
&lt;p&gt;对此，2 月 11 日在法国巴黎出席人工智能行动峰会的 OpenAI 首席执行官萨姆·奥尔特曼&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot;&gt;再次强调「公司不卖」&lt;/a&gt;&lt;/u&gt;，并表示，「如果马斯克愿意谈」，那么他将「很乐意收购推特（即社交媒体平台 X）」。&lt;/p&gt; 
&lt;p&gt;奥尔特曼还表示，「&lt;span style=&quot;color:#e67e22&quot;&gt;&lt;strong&gt;愿意在人工智能领域与中国合作，并将为此尽最大努力，因为这很重要。&lt;/strong&gt;&lt;/span&gt;」&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c01d53e2a43f4d2a467d4d590cc812b528.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据外媒周一报道，特斯拉 CEO 埃隆·马斯克正率领一群投资者，提出以 974 亿美元收购 OpenAI 的控制权。马斯克律师马克·托贝罗夫补充说，他已于周一提交收购要约。&lt;/p&gt; 
&lt;p&gt;报道援引托贝罗夫提供的马斯克声明称，「现在是时候让 OpenAI 回归其曾经开源、注重安全的初衷了。」&lt;/p&gt; 
&lt;p&gt;OpenAI 首席执行官山姆·奥尔特曼在 X 平台上发帖称，他写道：「不了，谢谢。不过如果你愿意的话，我们可以花 97.4 亿美元收购推特。」随后，马斯克在 X 平台上回复这位 OpenAI 负责人，称他为「骗子」。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/333069&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333323</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333323</guid>
            <pubDate>Fri, 07 Feb 2025 03:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>稚晖君创业公司智元近日在深圳新设立「灵犀」产品线</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.leiphone.com%2Fcategory%2Frobot%2FIYV9qXAR1wFN5Omd.html&quot; target=&quot;_blank&quot;&gt;根据「AI 科技评论」独家报道&lt;/a&gt;，智元机器人三大事业部之一灵犀近日在深圳设立，目前正在招兵买马。&lt;/p&gt; 
&lt;p&gt;据了解，智元此前调整组织架构，新设立三大产品线，分别是远征、灵犀和 Genie。此外还有几个一级部门，例如灵巧手。&lt;/p&gt; 
&lt;p&gt;智元新成立的三大产品线分设三地，除了「灵犀」产品线在深圳外，远征产品线在上海，Genie 产品线大部队在北京。&lt;/p&gt; 
&lt;p&gt;远征、灵犀、Genie 三大产品线总裁分别由王闯（前大疆 Livo 激光雷达负责人）、稚晖君、姚卯青（前蔚来工程总监）担任。据了解，Genie 产品线前身是由上海交大闫维新教授和姚卯青指挥的研究院。&lt;/p&gt; 
&lt;p&gt;目前灵犀产品线由稚晖君暂代，还在招一号位人选。灵犀系列是智元产品矩阵之一，原先只有产品，并没有配备专门产品线。此次新设立的灵犀产品线，将承接此前的灵犀系列产品。2024 年 10 月，智元曾宣布&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.zhiyuan-robot.com%2FDOCS%2FOS%2FX1-PDG&quot; target=&quot;_blank&quot;&gt;开源灵犀 X1&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-67d9642e1e623e3859f9c4aa1823336b99b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;稚晖君所在部门为 CTO Office，领衔 X-Lab 和 EI-Lab。X-Lab 由稚晖君指挥，EI-Lab 则归北大计算机学院前沿计算研究中心助理教授董豪管理。&lt;/p&gt; 
&lt;p&gt;据介绍，灵犀主要做 To C，面向养老方向。而远征和 Genie 在产品腿部形态上做区分，远征做足式机器人，Genie 则是轮式机器人。&lt;/p&gt; 
&lt;p&gt;智元自成立起便开启全栈自研，涵盖软件、硬件、大脑、小脑和云系统等。技术上，智元提出具身智能 G1 到 G5 的演进路径和技术框架，目前处于 G2 和 G3 阶段。&lt;/p&gt; 
&lt;p&gt;智元持续推进量产工作。2024 年 12 月，智元机器人正式宣布开启机器人量产。2025 年 1 月 6 日，智元量产第 1000 台通用具身机器人正式下线。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/254290&quot; target=&quot;news&quot;&gt;稚晖君首款创业产品——智元机器人「远征 A1」发布&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/327297&quot; target=&quot;news&quot;&gt;智元机器人重磅开源百万真机数据集 AgiBot World&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/328925&quot; target=&quot;news&quot;&gt;智元机器人具身算法团队推出 EnerVerse 架构&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333319</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333319</guid>
            <pubDate>Fri, 07 Feb 2025 03:41:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>梁文锋实习往事：月薪 1.6 万、没毕业就被任命为部门经理</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;日前「今日闵行」公众号&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F9e1Eva97SJCgDJp3ukjlwA&quot; target=&quot;_blank&quot;&gt;发文称&lt;/a&gt;，DeepSeek 创始人梁文锋 2009 年曾在上海闵行的上海艾麒信息科技股份有限公司实习，负责内容也跟人工智能有关。&lt;/p&gt; 
&lt;p&gt;据艾麒信息创始人周朝恩透露，梁文锋是其浙大校友，&lt;strong&gt;2009 年梁文锋以实习生身份加入艾麒，后经推荐直接担任新技术部经理，月薪 16000 元&lt;/strong&gt;，算是高薪特别聘请的。&lt;/p&gt; 
&lt;p&gt;「入职后，他便全身心投入到人工智能视频与图像技术的研究中，常常一整天都待在办公室里，专注地钻研技术难题，甚至半天都不出来一次。」&lt;/p&gt; 
&lt;p&gt;他还透露了对梁文锋的第一印象：「初见梁文锋时，他戴着一副眼镜，斯文有礼，身材清瘦，给人一种文静内敛的印象。」&lt;/p&gt; 
&lt;p&gt;不过在深入接触后，周朝恩发梁文锋虽不善言辞，但在技术交流中却能清晰地表达自己的观点，「他为人沉着冷静，性格简单直接，对产品和技术有着极高的追求，堪称典型的技术男风格」。&lt;/p&gt; 
&lt;p&gt;周朝恩介绍称，梁文锋在艾麒信息期间，当时公司新技术部也在研究做 100M CPU 的手机上视频编解码技术，并充分运用手机上 GPU 来高效处理视频编解码等技术。在这过程中，梁文锋积累了丰富的技术经验，为他后续创业打下了坚实的技术基础。&lt;/p&gt; 
&lt;p&gt;他也曾管理过多位算法工程师，采用扁平化管理方式，给予团队成员充分的自由和信任，发挥每个人的特长，并带领团队攻克了多项技术难题，优化了图像视频处理算法，提升了服务性能。&lt;/p&gt; 
&lt;p&gt;丰富的管理经验在他创业后得到了延续。周朝恩告诉记者，梁文锋招聘的团队成员大多是数学竞赛一等奖、拿过国际金牌的算法人才，这种对高端人才的管理和激励方式，使得他在管理量化投资和深度求索时能够迅速组建一支高效专业的技术团队。&lt;/p&gt; 
&lt;p&gt;2023 年 5 月，梁文锋在筹备深度求索之前，还特意回到艾麒公司进行调研。&lt;/p&gt; 
&lt;p&gt;此次调研，他比约定的时间提早 3 分钟来到了周朝恩的办公室，他不仅仅是看望老同事，而且还了解到艾麒信息也正在做大模型相关产品，「他与我们探讨了人工智能相关技术，交流了将近 2 个小时」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333308</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333308</guid>
            <pubDate>Fri, 07 Feb 2025 03:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 创始人未出席巴黎 AI 峰会</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近期有消息称，中国人工智能企业深度求索（DeepSeek）创始人梁文锋受邀参加在巴黎举办的&quot;AI 行动峰会&quot;（AI for Action Summit）。此次峰会聚焦全球人工智能技术发展、伦理治理及跨领域协作，被视为推动全球 AI 治理框架落地的重要国际会议。为期两天的人工智能行动峰会已于当地时间 10 日在法国首都巴黎的大皇宫拉开帷幕。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FphNF2U-ytrx6v97fqes_tA&quot; target=&quot;_blank&quot;&gt;根据凤凰网科技的报道&lt;/a&gt;&lt;/u&gt;，接近 DeepSeek 的人士称梁文锋没有参加这次在巴黎举办的人工智能行动峰会，公司层面也无人参加。&lt;/p&gt; 
&lt;p&gt;目前，除传闻受邀的梁文锋外，已披露的参会名单包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI 首席技术官米拉·穆拉蒂&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china&quot;&gt;DeepMind 首席执行官戴密斯·哈萨比斯&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;法国总统马克龙&lt;/li&gt; 
 &lt;li&gt;欧盟委员会数字事务副主席维斯塔格&lt;/li&gt; 
 &lt;li&gt;图灵奖得主杨立昆&lt;/li&gt; 
 &lt;li&gt;斯坦福大学 HAI 研究院院长李飞飞等人&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;法国总统马克龙在这次峰会开幕前夕曾表示，不会因为某个技术来自特定国家和地区就去禁用它，因为这很荒谬，他认为，DeepSeek 的出现是一个好消息，并希望下一代这样的模型会出现在欧洲。&lt;/p&gt; 
&lt;p&gt;此外，值得注意的是，2 月 11 日，彭博社对 7 位初创公司创始人及 AI 专家的调研显示，预计 DeepSeek 的估值在 10 亿美元到逾 1500 亿美元之间，估值区间的中间值为 20 亿至 300 亿美元。这样的预测无疑让持有 84% 股份的梁文峰身家暴涨，有望跻身亚洲科技巨富之列。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333302</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333302</guid>
            <pubDate>Fri, 07 Feb 2025 02:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>RWKV-7 2.9B 模型正式发布，SOTA 架构，带来 SOTA 使用体验</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 2 月 11 日，RWKV 基金会正式发布 RWKV-7-World-2.9B-V3 模型（以下简称 RWKV-7-2.9B）。&lt;/p&gt; 
&lt;p&gt;RWKV-7-2.9B 模型基于 RWKV World V3 数据集训练。无论是&lt;strong&gt;模型评测&lt;/strong&gt;还是&lt;strong&gt;实际体验&lt;/strong&gt;，RWKV-7-2.9B 都超越了上一代 RWKV-6-&lt;strong&gt;7B&lt;/strong&gt; 模型。&lt;/p&gt; 
&lt;h3&gt;英文和多语言测评&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 模型的英文和多语言能力，均&lt;strong&gt;显著超越所有同尺寸模型&lt;/strong&gt;，包括 &lt;strong&gt;Llama 3.2 3B、Qwen2.5 3B&lt;/strong&gt; 等知名优秀开源模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d75cea1cbd01a3f14f4250fc3b49ce974da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;MMLU 测试&lt;/h3&gt; 
&lt;p&gt;在&lt;strong&gt;选择题&lt;/strong&gt;形式的 MMLU 测试上，RWKV-7-2.9B 模型得分为 &lt;strong&gt;54.56&lt;/strong&gt;%。作为对比，上一版本的 RWKV-6-World-3B-V2.1 模型 MMLU 评分是 &lt;strong&gt;32.38&lt;/strong&gt;%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV-7-2.9B 基底模型的性能提升完全通过&lt;strong&gt;常规训练&lt;/strong&gt;实现，未针对任何测试进行「优化」，也没有采取退火或 post-training 等优化策略。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;生成案例&lt;/h2&gt; 
&lt;p&gt;以下是 RWKV-7-2.9B 的生成案例（使用 RWKV Runner 运行）：&lt;/p&gt; 
&lt;h3&gt;代码任务&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2c8e4dddba547a3a1e2f3473517ac578748.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e77fd7b64c80a0fc62785042feb96839832.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;多语言任务&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 多语言写请假信：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4b6f6adf1987001921bcb9ba30dc8c803dd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;以下是图中的原文和翻译：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;Lieber Herr [先生的名字],
Ich möchte Ihnen mitteilen, dass ich mich auf dem Weg zur Marsrakete befinde und morgen eine Woche lang fehlen werde. Ich habe diese Entscheidung getroffen, weil ich mein Leben erkunden möchte.
Es war ein großer Genuss, von Ihnen unterrichtet worden zu sein und vieles zu lernen. Ich werde dieses Wissen nie vergessen.
Ich hoffe, dass wir uns bald wiedersehen werden und danke Ihnen für alles!
Mit freundlichen Grüßen
[Ihr Name]
尊敬的[先生姓名]先生：
我在此通知您我正在前往火星火箭的途中，我将从明天起缺席一周。做出这个决定是因为我想探索我的生活。
能够接受您的教导并学习很多东西是一种极大的享受。我将永远不会忘记这些知识。
希望我们能很快再次见面并为一切向您致谢！
此致
敬礼
[您的姓名]
--------------------------------------------------------------------------------------
عزيزي السيد [اسم المعلم$$],
أود أن أخبرك أنني أتجه حالياً إلى سفينة الغوص تحت الماء وأنا غائب ليوم واحد في الأسبوع. قررت هذا القرار لأنني أريد أن أكتشف العالم.
لقد كان من الجيد التعلم منك واستلام معلومات عديدة. سأحافظ على هذه المعرفة دائمًا في ذاكرتي.
آمل أن نلقى بعضًا مرة أخرى وأشكرك على كل شيء!
باحترام،
[اسم المطالب]
尊敬的[老师姓名]先生：
我谨此告知您：我将开始参与深海潜水艇的作业项目（每周将固定缺席一日）。作出这个决定是因为我想借此机会探索未知的世界。
能跟随您学习并收获丰富的知识是我的荣幸，这些宝贵的教导我将永远铭记于心。
期待未来能有重逢之日！衷心感谢您给予的一切！
此致，敬礼
[申请人姓名]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;角色扮演&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 进行「八戒」角色扮演，&lt;strong&gt;未添加任何角色扮演提示词或者角色预设&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-16c7b7c3d510d80e6e6a07dc7499606cb54.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;小说续写&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 续写小说（高亮板块为 deepseek-R1 生成的前文）：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b28c60063a5dfba402cba27473bb63ad559.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;模型下载&lt;/h3&gt; 
&lt;p&gt;RWKV-7-2.9B 现已上传到各大模型平台，可以从以下仓库下载：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HF 主站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HF 镜像站：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhf-mirror.com%2FBlinkDL%2Frwkv-7-world&quot; target=&quot;_blank&quot;&gt;https://hf-mirror.com/BlinkDL/rwkv-7-world&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ModelScope：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FBlink_DL%2Frwkv-7-world%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/Blink_DL/rwkv-7-world/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel: &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2Frwkv-7-world%2F&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/rwkv-7-world/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;在线 Demo&lt;/h3&gt; 
&lt;p&gt;可在 Hugging Face Demo 在线体验 RWKV-7-2.9B 模型：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在线 Demo 为续写模式，不支持直接对话。请使用以下两种格式输入 prompts :&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;User: (你的问题，比如「请为我推荐三本适合五岁小孩阅读的世界名著」 )
 
Assistant:
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Instruction: （你希望模型进行什么操作，比如「请将下列瑞典语翻译成中文」）
 
Input:（输入给模型的内容，比如「hur l?ng tid tog det att bygga twin towers」）
 
Response:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;未来计划&lt;/h2&gt; 
&lt;p&gt;RWKV-7-2.9B 模型的强大能力，得益于 RWKV-7 架构的精妙改进。在应用了「动态 State 演化机制」后，RWKV-7 拥有强大的 in-context-learning（上下文学习）能力，在推理过程中更好地学习上下文的关系，生成的内容生更精简、更合理。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV-7 的架构思路和细节：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fj7IgeaqgnLfVl_sVn6OmzQ&quot; target=&quot;_blank&quot;&gt;RWKV-7：极先进的大模型架构，长文本能力极强&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV-7-7B 预计将使用新的 RWKV World V3.1 数据集训练。World V3.1 数据集将在 World V3 的基础上新增大量数学、代码和 reasoning 数据，进一步增强模型的&lt;strong&gt;代码、数学和推理能力&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;请关注我们的公众号「RWKV 元始智能」，第一时间获取 RWKV 动态！&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;RWKV 是一种创新的深度学习网络架构，它结合了 Transformer 与 RNN 的优点，同时实现高度并行化训练与高效推理。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 中文官网（包括大量 RWKV 多模态论文）：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV 英文官网：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Frwkv.com%2F&quot; target=&quot;_blank&quot;&gt;https://rwkv.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV-5/6（Eagle &amp;amp; Finch）论文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2404.05892&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2404.05892&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RWKV-4 论文：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2305.13048&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2305.13048&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区！您可从 RWKV 官网了解 RWKV 模型，也可加入我们的官方论坛、QQ 频道和群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RWKV 论坛：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QQ 频道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333299</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333299</guid>
            <pubDate>Fri, 07 Feb 2025 02:40:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>马云现身阿里杭州总部，闪现闲鱼、夸克两大业务办公区</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日下午，阿里巴巴创始人马云现身阿里杭州园区，身穿阿里巴巴黑色文化夹克，全程微笑并向员工挥手致意。&lt;/p&gt; 
&lt;p&gt;据社交媒体上的阿里员工透露，今日上午，马云先出现的地方是阿里西溪园区 A 区 2 号楼的闲鱼。此后，下午又有人在 C 区的夸克偶遇马云，身旁还有阿里巴巴集团 CEO 吴泳铭陪同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-60c6d8f397d9898ecffe3d57cacc36134b4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;作为阿里 AI To C 的代表产品，夸克近期也升级了品牌 Slogan—「2 亿人的 AI 全能助手」。&lt;/p&gt; 
&lt;p&gt;同时，阿里 AI To C 正在「招贤纳士」，以提升用户的信息服务体验。2 月 6 日，全球顶尖人工智能科学家、Salesforce 集团（CRM）前副总裁许主洪（Steven Hoi）&lt;a href=&quot;https://www.oschina.net/news/332267&quot; target=&quot;_blank&quot;&gt;正式加入阿里&lt;/a&gt;，出任集团副总裁，向吴嘉汇报，负责 AI To C 业务的多模态基础模型及 Agents 相关基础研究与应用解决方案。&lt;/p&gt; 
&lt;p&gt;有偶遇马云的阿里员工表示，「马老师精神真的好好，特别开心的跟我们合影打招呼，就在智能信息这层，巡楼祝大家新年快乐。」&lt;/p&gt; 
&lt;p&gt;据悉，去年 11 月 29 日，马云第一次出现在阿里西溪园区 C 区，即杭州全球总部新园区。12 月 8 日，马云参加了蚂蚁集团成立 20 周年活动。在活动上，马云着重提到了 AI 发展，他表示，从今天来看，未来 20 年的 AI 时代能带来的改变会超出所有人的想象，因为 AI 会是一个更加伟大的时代。&lt;/p&gt; 
&lt;p&gt;2 月 8 日，马云也曾被网友在新加坡的一个高尔夫球场偶遇。当时，他正在享受一场悠闲的球赛，看起来状态极佳。马云在新加坡的现身也引发了不少猜测，有人认为他可能正在为阿里巴巴的全球化战略做准备，也有人认为他只是单纯地享受个人时光。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333296</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333296</guid>
            <pubDate>Fri, 07 Feb 2025 02:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百川智能 CEO 王小川：AGI 的尽头是生命科学</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fo7wg-YavNVPm-KJxFpJ9uA&quot; target=&quot;_blank&quot;&gt;百川智能创始人兼 CEO 王小川接受晚点对话的采访&lt;/a&gt;&lt;/u&gt;，表示「不是文本创作、不是物理模型，&lt;strong&gt;AGI 的尽头是生命科学&lt;/strong&gt;」。&lt;/p&gt; 
&lt;p&gt;采访中，王小川提到，之所以坚定了公司方向聚焦医疗，是因为大模型是造人的，而医生是人类职业中最复杂的之一，所以它可以成为一个标尺。并且他认为，大模型能造出医生时，就是达到了 AGI。&lt;/p&gt; 
&lt;p&gt;同时，王小川对 DeepSeek 的「火爆全球」表示振奋，一方面他认为 DeepSeek 改变了行业格局，中国离实现 AGI 和应用爆发更近，另一方面，他觉得 DeepSeek 的出圈让更多人体验到了 AI，教育了整个行业。&lt;/p&gt; 
&lt;p&gt;在谈及训练医疗大模型费用时，&lt;strong&gt;王小川认为医疗模型有更高的价值，它关系生命健康，因此不能按 token 来算钱&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;王小川还预测了未来的技术发展趋势。AI 通过学会使用工具，一步步学习制造工具，最后形成循环，AI 写完代码自己运行，AI 自己造工具自己用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333290</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333290</guid>
            <pubDate>Fri, 07 Feb 2025 02:23:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>国行苹果 AI 敲定与阿里巴巴合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;根据科技媒体 The Information 的独家报道，&lt;strong&gt;苹果公司已经与阿里巴巴达成合作，为国行版的 iPhone 用户提供 AI 功能&lt;/strong&gt;，消息来源为一位知情人士。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0212/101826_AE4P_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据悉，苹果与阿里巴巴共同开发的国行 AI 功能已提交给国内相关部门审核。&lt;/p&gt; 
&lt;p&gt;两位对该项目有直接了解的人士称，苹果在 2023 年开始测试来自中国开发者的不同 AI 模型，并一度选择百度作为主要合作对象，但由于百度在为苹果智能开发模型方面的进展未达到美国公司的标准，因此该合作后来被取消。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;苹果最近几个月开始考虑其他选项，评估腾讯、字节跳动、阿里巴巴以及 Deepseek 开发的模型&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;报道还提到，&lt;strong&gt;苹果最终放弃了最近呼声很高的 DeepSeek ，因为 DeepSeek 团队缺乏支持像苹果这样的大客户所需的人力和经验&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;648&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0212/101851_M45f_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;日前，苹果向开发者发送了关于「利用苹果智能的力量」开发者活动的相关邮件。&lt;/p&gt; 
&lt;p&gt;值得关注的是，本次活动将于 3 月 25 日 10:00 至 12:00 在上海&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/332912&quot;&gt;举行&lt;/a&gt;&lt;/u&gt;，活动主题将围绕苹果智能和机器学习两个方面。而这一举动，也暗示在中国大陆的苹果智能 AI 功能或将上线。&lt;/p&gt; 
&lt;p&gt;截至发稿前，苹果和阿里巴巴官方尚未对此作出回应，但这两家公司美股涨幅均已超过 1%，百度股价下跌超 4%。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;相关来源：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fapple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&quot; target=&quot;_blank&quot;&gt;https://www.theinformation.com/articles/apple-partners-with-alibaba-to-develop-ai-features-for-iphone-users-in-china&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333288</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333288</guid>
            <pubDate>Fri, 07 Feb 2025 02:19:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>李彦宏谈 DeepSeek 爆火：创新是不能被计划的</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在阿联酋迪拜举办的 World Governments Summit 2025 峰会上，百度创始人李彦宏与阿联酋 AI 部长奥马尔·苏丹·奥拉马对谈时提及 DeepSeek 表示：创新是不能被计划的。「你不知道创新何时何地到来，你所能做的是，营造一个有利于创新的环境。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;284&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-20f4da7c355029d6c8b5f97139534ed0d93.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 突然爆火背后，李彦宏称，如果回顾过去几百年，大多数创新都与降低成本有关，不仅是在人工智能领域，甚至不仅仅是在 IT 行业。如果能将成本降低一定数量、一定百分比，这意味着生产率提高了相同的百分比。这几乎就是创新的本质。而今天，创新的速度比以前快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以科技行业为例，在过去，当业界谈论摩尔定律时常说，每 18 个月性能会翻倍、成本会减半；但今天，当大家谈论大语言模型时，可以说每 12 个月，推理成本就可以降低 90% 以上。这比人们过去几十年经历的计算机革命要快得多。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「大语言模型是一个非常庞大的领域。在中国，我们必须在推理和训练方面创新以降低成本。幸运的是，过去一年，我们看到了显著进步。」李彦宏表示，在对话中，奥拉马还提到，几周前，当 DeepSeek 成为人人都谈论的话题时，不少全球大型芯片厂商股价大幅下跌。因为巨头们此前需要花费数十亿美元用于推理数据中心、训练这些人工智能系统和模型。在 DeepSeek 的冲击下，数据中心和 AI 基础设施的未来是否会发生变化？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李彦宏表示，自己在过去一个月左右的时间里，一直在思考这个问题。从基本面来看，最重要的仍然是技术进步非常快，成本每年降低约 90%，性能越来越好。「当技术发展如此之快，你无法停止投资。你必须投资，以确保处于这场技术创新或革命的最前沿。我们仍需对芯片、数据中心和云基础设施进行持续投入，用于打造更优秀、更智能的下一代模型。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为此，企业需要使用更多的算力来尝试不同的路径。「也许，在某个时刻你会找到一条捷径，比如说只需 600 万美元就能训练出一个模型，但在此之前，你可能已经花费了数十亿美元，用来探索哪条路才是花费这 600 万美元的正确途径。」李彦宏说。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他认为，目前的 AI 应用离那种级别的应用还有很远的距离。「整个世界目前都在焦急地寻找这样的超级 App。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333284</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333284</guid>
            <pubDate>Fri, 07 Feb 2025 02:05:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度文小言（原文心一言）App 接入 DeepSeek-R1 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;iOS 版百度文小言（原文心一言）App 日前迎来了 4.9.0 版本更新，更新描述称该版本已接入 DeepSeek-R1 模型，优化拍照解题功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a4769f89c4a201f4028836651b2741d29f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲ 百度文小言（原文心一言）App 接入 DeepSeek-R1 模型&lt;/p&gt; 
&lt;p&gt;接入 DeepSeek-R1 模型后，文心一言 App 的拍照解题功能得到了显著提升。用户在使用该功能时，可以清晰地看到解题过程中的思考步骤，这与 DeepSeek 特有的思维链功能非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cc68ae51d81f06ed72ba3d94755a877e04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1944e58c65fe9c878bae4407b0cf63cf2ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用户表示，「这极大地提升了用户的解题体验。用户通过拍摄问题，系统将自动识别并给出详细的解题思路，这对于需要进行学习和复习的用户来说是个好消息。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333181</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333181</guid>
            <pubDate>Thu, 06 Feb 2025 10:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>男子用 DeepSeek 买彩票中奖：买 10 元中 5 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日，词条#用 DeepSeek 买彩票真中奖了#登上微博热搜榜第一，引起许多网友热议。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/172819_3xs4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据媒体报道，日前，安徽芜湖一男子发帖称，自己按照 DeepSeek 推荐的号码买双色球，真的中奖了。&lt;/p&gt; 
&lt;p&gt;该男子用 5 组 DeepSeek 推荐的数字下注，&lt;strong&gt;合计 10 元，其中一组数字中了「2+1」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/173130_nyzI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，这是第一次买双色球，也是才接触 DeepSeek，突发奇想想看看到底准不准，这样的行为不能「上头」，自己之后不会再用 DeepSeek 推荐的数字继续买彩票。&lt;/p&gt; 
&lt;p&gt;据中国福利彩票服务热线工作人员介绍，&lt;strong&gt;上述情况是中了六等奖，奖金为 5 元。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于该男子的做法，有网友表示：「合计 10 元，中了 5 元？有没有可能没有 DeepSeek，你买五组也有这个概率呢？我觉得也没必要神话 DeepSeek。」「随机概率这么大，跟它真没太大关系。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333169</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333169</guid>
            <pubDate>Thu, 06 Feb 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度李彦宏：自动驾驶比人开车安全十倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日消息，「世界政府峰会」（World Goverments Summit 2025）今日在阿联酋迪拜开幕，百度创始人李彦宏今日上午在主论坛上与阿联酋 AI 部长奥马尔・苏丹・奥拉马（Omar Sultan AI Olama）对谈时表示，Robotaxi 可以大大降低交通事故死亡率。从萝卜快跑的实际记录来看，出险率仅为人类驾驶员的 1/14。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8b66f69d2ba73a703403b32ebdae56e2f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李彦宏表示：「技术进步非常快，自动驾驶比人类司机安全十倍。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74a55024af52c507dd898d356bf590ace0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据了解，2024 年第二季度，百度的自动驾驶服务萝卜快跑供应的自动驾驶订单约 89.9 万单，同比增长 26%。截至 2024 年 7 月 28 日，萝卜快跑累计为公众提供的自动驾驶出行服务订单超过 700 万单。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/301302&quot; target=&quot;news&quot;&gt;百度旗下的「萝卜快跑」无人驾驶出租车武汉街头撞倒行人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333160</guid>
            <pubDate>Thu, 06 Feb 2025 08:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>嘉立创集团加入 openKylin，助推社区计算多元化生态繁荣</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;text-align:justify&quot;&gt;&lt;span&gt;近日，深圳嘉立创科技集团股份有限公司（简称「嘉立创集团」），签署 OpenAtom openKylin（简称「openKylin」）社区 CLA（Contributor License Agreement 贡献者许可协议），正式加入 openKylin 开源社区。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1527&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8345ba8245337a544b99cf88d729976dd5.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;嘉立创集团&lt;/span&gt;&lt;/span&gt;&lt;span&gt;是电子及机械产业一站式基础设施服务提供商，旗下拥有电子及机械产业一站式服务提供商嘉立创科技、大批量 PCB/PCBA 智造企业中信华和国内领先的样品/小批量电子元器件线上服务商立创商城等三大运营板块。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;依托产业链一站式服务、全流程闭环数字化底座、柔性化智能制造等领先优势以及百万级用户基础，公司打造了「一站式产业互联智造模式」，为客户提供覆盖从打样到小批量再到大批量的 PCB 智造、电子元器件商城、SMT、激光钢网等电子产业链和 CNC 机械智造、3D 打印、FA 机械电气零部件商城等机械产业链一体化服务，以及以 EDA、CAM、DFM、CAD 软件为核心的工业软件集群。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;410&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-620266042dadaea8fb8477b013d338fc9ca.jpg&quot; width=&quot;940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;在加入 openKylin 社区后，嘉立创集团除了在产品适配、市场推广、技术协同等关键业务领域积极作为与开拓进取之外，也将进一步秉持开放合作、互利共赢的发展理念，充分发挥自身资源优势与产品的优越性，对 openKylin 社区进行全方位的业务支持，助力实现开源生态的繁荣发展，&lt;span&gt;为经济持续发展、科技再创新高提供源动力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333148</guid>
            <pubDate>Thu, 06 Feb 2025 07:55:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>DeepSeek 梁文锋身家暴涨，有专家预计或超黄仁勋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社报道显示，7 位创业公司创始人和人工智能专家对 DeepSeek 的估值存在巨大分歧，估值区间在 10 亿美元到 1550 亿美元之间。按照彭博亿万富翁指数中间值估算，DeepSeek 估值约在 20 亿至 300 亿美元，而持有公司 84% 股份的梁文锋，身家可能在 16.8 亿到 252 亿美元之间，有望跻身亚洲最富有的科技大亨之列，甚至问鼎中国首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同业内人士给出的估值差异极大。波士顿风险投资公司 Glasswing Ventures 创始人鲁迪纳・塞塞里认为，按同行公司估值，DeepSeek 最少值 10 亿美元；研究工程师 Sebastian Raschka 则觉得，凭借强大的品牌认知度，其估值应在 20 亿到 100 亿美元之间，高于 Mistral AI。而 Sweat Free Telecom 创始人查纳基亚・拉姆德夫的预测更为乐观，认为 DeepSeek 估值可达 1550 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2fbcd3fec3d8b307089121298b01c62f34.webp&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前 1 月有报道称，软银集团洽谈牵头对 OpenAI 进行最高 400 亿美元融资，融资后估值达 3000 亿美元。若 DeepSeek 按此估值一半计算，梁文锋个人财富或达 1260 亿美元，有望超过英伟达 CEO 黄仁勋，身家远超钟睒睒等富豪，在同领域也将远超字节跳动创始人张一鸣（2024 年福布斯中国内地富豪榜显示张一鸣身价 456 亿美元，梁文锋身家或为其 3 倍） 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;梁文锋出生于 1985 年，本硕就读于浙江大学信息与通用工程专业，师从项志宇，研究机器视觉，2010 年毕业。毕业后，他投身量化投资，成立幻方量化，仅 6 年管理规模达千亿，成为 「量化四大天王」 之一。2023 年 5 月，梁文锋决心进军通用人工智能领域，7 月成立 DeepSeek，被视为量化投身 AI 创业第一人。2024 年 12 月底，DeepSeek 发布的 DeepSeek-V3 火遍全网。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不过，由于 DeepSeek 收入、利润等财务数据保密，外界只能通过对比 OpenAI、Anthropic 等公司估值来推测其价值，这些估值仅供参考。梁文锋的真实身家究竟几何，还需时间揭晓。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333142</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333142</guid>
            <pubDate>Thu, 06 Feb 2025 07:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「互联网之子」 Aaron Swartz 雕像在互联网档案馆揭幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Aaron Swartz 的大理石雕像上周五在互联网档案馆的礼堂揭幕，有大约 300 人出席，半身像下方刻有文字&lt;em&gt;「The Internet&#39;s Own Boy（互联网之子）」&lt;/em&gt;。本周重 312 磅的雕像将先转移至大厅，直至获得许可放置在当地公园内。&lt;/p&gt; 
&lt;p&gt;揭幕仪式上，Creative Commons 联合创始人 Lisa Rein 强调：「崇拜 Aaron 的前提是正确理解他的故事——他并非殉道者，而是为公众已付费的科学研究成果应自由获取而战。」电子前沿基金会（EFF）执行董事 Cindy Cohn 则称，这座雕像「提醒人们为真理与正义持续斗争」。科幻作家 Cory Doctorow 在视频致辞中暗讽特朗普政府时期的政治环境：「这是一个希望稀缺的时代，但这座雕像应激励我们让世界变得更好」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f82cf0e74040f33cd165bbe250c47ae3e5c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Aaron Swartz 出生于 1986 年，参与了 RSS 和 Markdown、web.py 等项目的开发，被视为是 Reddit 的联合创始人。&lt;/p&gt; 
&lt;p&gt;2011 年 1 月他因为在 MIT 下载学术论文而遭到逮捕，面临最高 35 年的刑期，他拒绝了认罪协议，于 2013 年 1 月 11 日自杀身亡。他在当年被追授进入互联网名人堂。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/92332/in-memory-of-aron-swartz&quot; target=&quot;news&quot;&gt;纪念 Aaron Swartz：他用生命捍衞了互联网的开放和自由&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/36671/aaron-swartz-kill-himself&quot; target=&quot;news&quot;&gt;web.py 作者 Aaron Swartz 自杀身亡&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</guid>
            <pubDate>Thu, 06 Feb 2025 06:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>