<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 19 Jun 2025 07:44:31 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>开源模型上下文协议 MCP 更新规范文档，添加对结构化工具输出的支持</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源模型上下文协议 MCP 昨天更新了规范文档，主要变更如下：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;移除对 JSON-RPC 批处理的支持（PR #416）&lt;/li&gt; 
 &lt;li&gt;添加对结构化工具输出的支持（PR #371）&lt;/li&gt; 
 &lt;li&gt;将 MCP 服务器归类为 OAuth 资源服务器，添加受保护资源元数据以发现相应的授权服务器。（PR #338）&lt;/li&gt; 
 &lt;li&gt;要求 MCP 客户端按照 RFC 8707 中描述的方式实现资源指示器，以防止恶意服务器获取访问令牌。（PR #734）&lt;/li&gt; 
 &lt;li&gt;在授权规范中阐明安全注意事项和最佳实践，并在新的安全最佳实践页面中说明。&lt;/li&gt; 
 &lt;li&gt;增加引导支持，使服务器能够在交互过程中向用户请求更多信息。（PR #382）&lt;/li&gt; 
 &lt;li&gt;在工具调用结果中增加资源链接支持。（PR #603）&lt;/li&gt; 
 &lt;li&gt;在使用 HTTP 时，后续请求中需通过&amp;nbsp;&lt;code&gt;MCP-Protocol-Version&lt;/code&gt;&amp;nbsp;头指定协商的协议版本。（PR #548）&lt;/li&gt; 
 &lt;li&gt;将生命周期操作中的 SHOULD 改为 MUST&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelcontextprotocol.io%2Fspecification%2F2025-06-18%2Fchangelog" target="_blank"&gt;https://modelcontextprotocol.io/specification/2025-06-18/changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356195</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356195</guid>
      <pubDate>Thu, 19 Jun 2025 07:33:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源代码编辑器 Zed 上线「调试器」功能</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;开源代码编辑器 Zed &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fblog%2Fdebugger" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;推出「调试器（Debugger）」功能，称这是向 Zed 1.0 迈出的重要一步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;调试器特性&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;快速&lt;/strong&gt; ：减少上下文切换时间，让用户能更专注于调试。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;熟悉&lt;/strong&gt; ：与 Zed 的设计语言保持一致，支持典型的调试流程，方便用户快速上手。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;可配置&lt;/strong&gt; ：用户可自定义 UI、键绑定、调试配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-43c899b5d73c5470109aecf601bbff05ba7.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Zed 开箱即支持调试多种流行编程语言，包括 Rust、C/C++、JavaScript、Go 和 Python。通过扩展系统，Zed 可以支持任何实现调试适配器协议（DAP）的调试适配器。&lt;/p&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;技术架构&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   采用两层架构，数据层与调试适配器直接通信，UI 层从数据层获取数据进行界面渲染。
  &lt;/div&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   数据层负责维护会话状态、缓存响应、使失效数据，UI 层按需请求数据，避免不必要的请求，便于后续实现协作调试。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;调试适配器集成&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   扩展了 Zed 的扩展 API 以支持调试器集成，通过定义自定义架构等方式，让扩展作者能轻松将调试适配器集成到 Zed 中。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="margin-left:0px; margin-right:0px; text-align:start"&gt;&lt;strong&gt;内联变量值实现&lt;/strong&gt;&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; 
  &lt;div style="margin-left:0; margin-right:0"&gt;
   利用 Tree-sitter 查询准确识别当前执行范围内的变量，无需依赖 LSP 服务器与调试适配器的紧密集成，目前支持 Python、Rust、Go 等语言。
  &lt;/div&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;详情查看文档：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fzed.dev%2Fdocs%2Fdebugger" target="_blank"&gt;https://zed.dev/docs/debugger&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356190/zed-debugger</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356190/zed-debugger</guid>
      <pubDate>Thu, 19 Jun 2025 06:59:28 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>开源 Rust 浏览器引擎 Servo 支持 GIF</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Servo 是一款开源的浏览器引擎，最初由 Mozilla 开发。它使用 Rust 语言编写，旨在提供高效、安全的网页渲染能力，并且采用并行渲染技术，以提高网页加载速度和性能。&lt;/p&gt; 
&lt;p&gt;近日，Servo 团队介绍了最近的更新内容，其中一项重要新功能是&lt;strong&gt;支持显示动态 GIF&lt;/strong&gt;，并且还可以通过 HTML "img"标签加载 SVG 图像。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/142856_yG2V_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在推进其 Trusted Types API、输入类型 &amp;lt;input type=color&amp;gt; 支持、更好的布局和 CSS 支持，以及支持各种其他 API 和功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-958f8cd0cc574887e5f2e0cc055fb9586cf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Servo 还在继续努力提升围绕 Servo 嵌入支持的开发者体验，以 Servo 作为 Chromium 的 CEF 替代方案在应用程序中利用 Servo。&lt;/p&gt; 
&lt;p&gt;详情查看&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fservo.org%2Fblog%2F2025%2F06%2F18%2Fthis-month-in-servo%2F" target="_blank"&gt;https://servo.org/blog/2025/06/18/this-month-in-servo/&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356185/servo-may-2025-animated-gifs</guid>
      <pubDate>Sun, 11 May 2025 06:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>美国科技巨头推动联邦立法，禁止各州单独监管 AI</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;《金融时报》报道称，近日美国多家大型科技公司正积极推动一项联邦禁令，旨在禁止各州自行制定人工智能（AI）监管法规。此次立法倡议得到了亚马逊、谷歌、微软和 Meta 等公司的支持，目的是避免各州在 AI 监管方面各自为政，影响行业的整体发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;知情人士透露，这项禁令提案已经被纳入众议院版本的 「大而美」 预算法案中。参议院也计划在近期推出自己的版本，并希望能够在 7 月 4 日之前完成相关立法工作。前联邦众议员、现任 INCOMPAS 首席执行官 Chip Pickering 是这项提案的重要推动者，他表示，保持美国在技术领域的领导地位是确保国家竞争力的关键。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;INCOMPAS 组织于 2024 年成立了 「人工智能竞争中心」（AICC），专注于游说国会与监管机构，以适应快速发展的 AI 行业。随着 AI 监管讨论的加剧，尤其是在欧盟出台新规后，亚马逊和 Meta 也加入了该组织，试图通过统一监管来增强竞争力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;然而，此提案引发了广泛的争议。反对者认为，大型科技公司推动禁令的真正目的是为了巩固自身在 AGI（通用人工智能）竞争中的垄断地位。范德比尔特大学的政策加速中心 AI 与科技政策主任 Asad Ramzanali 表示，负责任的创新不应该惧怕法律的约束。同时，麻省理工学院的教授 Max Tegmark 也批评称，这种行为是科技巨头为了进一步集中财富和权力的扩张。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;另一方面，支持禁令的人士认为，联邦层面的统一监管将有助于避免各州的分歧，保持行业的创新能力，从而在全球 AI 竞争中处于有利地位。AI 安全倡导者如 Anthropic 联合创始人 Dario Amodei 则警告称，如果完全依赖企业自我监管，可能会带来严重的社会风险。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356176</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356176</guid>
      <pubDate>Sun, 11 May 2025 06:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>百度垂搜数据管理系统弹性调度优化实践</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;百度垂直搜索系统将搜索核心能力赋能阿拉丁（百度搜索特型结果）、垂直领域搜索、应用内搜索等场景，支撑了数百个检索场景、百亿级内容数据的检索。随着接入业务数量和数据量不断增长，系统在海量数据管理与调度上遭遇新的挑战，通过垂搜数据管理系统弹性调度优化实践来满足业务增长需求。&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;01 背景&lt;/h1&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.1 简介&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;百度垂搜架构的召回引擎经过历史架构演进确定了&lt;strong&gt;&lt;strong&gt;异构&lt;/strong&gt;&lt;/strong&gt;部署的架构模型，相较于同构部署在容量自动调整、数据按需存储等方面更具效率与成本的优势，同时在海量数据和海量检索方面也实现了高可用和高性能。目前系统已承接 80+业务，全机房部署了数百个检索服务，数千个索引库，共计数百亿文档收录。随着接入新业务数量的增加，以及存量业务的深入迭代，我们遇到了更加复杂多样的场景，进而对系统提出更高的要求。本文主要介绍我们的系统在海量数据管理与调度上面临的问题， 以及各项优化工作落地后在系统扩展性、稳定性等方面取得的效果。&lt;/p&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;1.2&amp;nbsp;当前数据管理架构存在的问题&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此前我们的系统设计了弹性伸缩机制应对流量和数据量的上涨，冷热分离机制实现了资源按需部署。随着接入业务的增加，系统逐渐暴露出一些新的问题，主要体现在以下几点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;元信息管理瓶颈。系统使用 ETCD 进行服务发现和心跳管理， 然而所有业务实例&lt;strong&gt;&lt;strong&gt;直连 ETCD&lt;/strong&gt;&lt;/strong&gt;存在严重读写放大问题， 导致 ETCD 负载超发出现&lt;strong&gt;&lt;strong&gt;单点瓶颈&lt;/strong&gt;&lt;/strong&gt;, 限制集群规模进一步增长。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依靠人工评估资源。新业务的接入或者一些大事件运营保障依赖人工估算所需资源，&lt;strong&gt;&lt;strong&gt;不仅耗费人力，而且不够准确&lt;/strong&gt;&lt;/strong&gt;，估算过高，服务长期处于低负载会造成资源浪费，估算过低，服务容易过载，进而导致稳定性问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;数据量增长瓶颈。 当前的架构可以在无需重新建库的情况下原地扩分片，但是分片数只能倍数扩展，并且&lt;strong&gt;&lt;strong&gt;分片数量有限制&lt;/strong&gt;&lt;/strong&gt;，大库场景容易触发上限，进而导致数据量无法继续增长。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_4"&gt;&lt;/span&gt; 
&lt;h1&gt;02 检索系统与数据管理系统架构&lt;/h1&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.1&amp;nbsp;检索系统架构概览&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;首先简单介绍下垂搜检索系统的各模块，如下图所示:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-c6fa6c464ffb4e6ea05cb47989be85fcbaf.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;RANK。检索精排模块，负责 query 理解、请求构造、多队列拆分、正排数据获取、策略因子计算、算分排序、返回结果组装等流程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS。检索召回引擎，负责基础召回/粗排，根据基础相关性等权重因子进行数据的粗筛，支持基于 term 倒排拉链和 ANN 向量基础召回。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BUILD。数据建库模块，负责数据处理、切词、生成正排/倒排/向量/摘要等功能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;每个垂类 (业务) 拥有一套独立的上述检索系统服务，数据管理系统为每个业务的检索系统提供&lt;strong&gt;&lt;strong&gt;实例调度、容量管理、服务发现、心跳管理、路由控制&lt;/strong&gt;&lt;/strong&gt;等能力，数据管理系统面向的核心管理对象是召回引擎 (BS)。&lt;/p&gt; 
&lt;span id="OSC_h3_6"&gt;&lt;/span&gt; 
&lt;h3&gt;2.1.1&amp;nbsp;垂搜召回引擎&lt;/h3&gt; 
&lt;p&gt;如下图所示，百度垂搜的召回引擎是一个&lt;strong&gt;&lt;strong&gt;流式、多分片、异构、有状态的倒排+向量&lt;/strong&gt;&lt;/strong&gt;索引引擎:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6a59f451eae4330c4d002228c9ca5d20b51.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;流式。业务经过离线建库环节产出建库包并生效到 Kafka 中，召回引擎再从 Kafka 消费，数据从建库到检索可实现&lt;strong&gt;&lt;strong&gt;秒级生效&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;多分片。业务数据量超过单机存储上限，会被拆分成多个分片 (slice)，每个分片由 PaaS 层面实例承载，并对应 Kafka 的一段 partition 区间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;异构。单个业务的若干个资源号 (resource) 之间支持独占或者混部，一般根据服务负载设置不同副本数，根据数据量设置不同分片数。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;有状态。每个实例承载一个或多个分片数据，周期性汇报心跳，消费分片由中控服务统一调度。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;名词解释:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;resource(资源号): 一类或者一个场景的数据集合，即一个&lt;strong&gt;&lt;strong&gt;索引库&lt;/strong&gt;&lt;/strong&gt;，一个业务通常包含多个资源号 (如图中 mobile_game，pc_game， game_video 等)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slice(分片):数据调度基本单位，一个 resource 根据数据量可能会拆分成多个 slice(mobile_game 有三个 slice, pc_game 和 game_video1 个)。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;slot:数据划分的基本单位，一个 slice 下有若干个 slot， 与 Kafka 的 partition 一一对应，在业务接入时根据数据量级确定。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;pod:PaaS 层面实际的物理存储容器，一个 pod 会承载一个或多个 slice，由中控服务统一调度。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;动态化数据管理系统&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;动态化数据管理系统负责召回引擎的每个实例从建库到检索，从部署到下线的全生命周期管理。经过&lt;strong&gt;&lt;strong&gt;服务重构、架构升级、新功能建设&lt;/strong&gt;&lt;/strong&gt;等方面的优化工作，形成了包括中控服务，心跳服务 (HeartbeatService), 名字服务 (NamingService), 存储 ETCD 等模块的现有系统架构:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-da1b5525954986be5194f44d536e0d8d45b.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_8"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.1&amp;nbsp;中控服务&lt;/h3&gt; 
&lt;p&gt;整个动态化数据管理系统的核心模块，负责各类调度任务的发起、控制等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;资源号接入/下线。新增资源号 (索引库)，为每个资源号根据副本数、资源号之间部署关系等调度实例；下线资源号， 对应资源号的数据发起清理以及实例回收。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;副本保活。每个资源号实际副本数可能由于扩缩副本或 PaaS 层面迁移，导致与目标副本数不一致，中控服务负责定期轮训所有资源号 (分片)，维持副本数与目标一致。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;容量管理。自动扩缩容服务/人工基于负载调整资源号的副本数，并通过副本保活生效，基于数据量调整资源号分片数，通过任务控制器生效。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可用度控制。上线重启需要保证分片维度的可用度，变更由 PaaS 发起，每个实例重启前需要请求中控服务的探针，中控服务根据当前分片可用度决定实例是否可以重启。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_9"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.2&amp;nbsp;名字服务 NamingService&lt;/h3&gt; 
&lt;p&gt;提供服务发现，实例屏蔽，建库路由控制等能力：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;服务发现。周期性加载并更新全量业务的资源号检索路由拓扑信息，对每个分片过滤心跳丢失、未消费完成、重启中等暂不可用实例。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实例屏蔽。支持异常实例的分片维度/App 维度屏蔽，线上快速止损，并保留现场便于后续问题追查。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建库路由控制。提供离线建库侧全量业务资源号与 Kafka partition 映射关系查询，资源号倒排索引双写控制。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_10"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.3&amp;nbsp;心跳服务 HeartbeatService&lt;/h3&gt; 
&lt;p&gt;负责召回引擎 (BS) 实例、分片心跳信息收集并持久化，实例消费区间信息传递等:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;心跳管理。收集召回引擎实例上报的心跳信息，包括实例自身心跳以及消费分片信息， 并将心跳信息聚合后写入 ETCD。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;实例调度信息传递。获取由中控调度下发的最新消费分片信息，写入心跳请求 response，实例感知到消费分片发生变化后，清理旧分片数据，并重新消费新分片数据。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_11"&gt;&lt;/span&gt; 
&lt;h3&gt;2.2.4&amp;nbsp;存储 ETCD&lt;/h3&gt; 
&lt;p&gt;动态化数据管理系统各类元信息持久化存储:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;实例心跳信息。包括版本号，实例唯一标识，上报时间戳，消费分片等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分片路由拓扑信息。分片下全量副本状态信息，包括 endpoint，snapshot 版本，上报时间戳，消费状态等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;业务资源号拓扑信息、建库路由信息。单业务视角下全量资源号信息，包括版本号，分片数，副本数，对应 Kafka partition 区间，rpc 参数配置等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h1_12"&gt;&lt;/span&gt; 
&lt;h1&gt;03 弹性调度机制优化实践&lt;/h1&gt; 
&lt;span id="OSC_h2_13"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.1&amp;nbsp;服务发现、心跳管理模块重构&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_14"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.1&amp;nbsp;原有架构&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6f12910e29c40a1a821609e09c774e7296d.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;可以看到在原有架构，业务 RANK 和 BS 实例都是直连 ETCD，随着业务接入数量的增加逐渐暴露出一些问题:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;读流量放大。同业务的不同 RANK 实例会各自访问 ETCD 获取相同的路由拓扑，导致读流量放大，对于 RANK 实例数多的业务放大现象愈发明显。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;写流量放大。每个分片含有多个副本，在进行更新时，一轮周期内同一个分片会被写入多次，导致写流量放大，对于副本数多的分片写竞争愈发激烈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;升级改造困难。路由筛选策略、心跳上报策略均内嵌在 sched-lib 中, 进行升级需要给每个业务 RANK/BS 上线，人力成本巨大。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;为了解决上述问题，我们对心跳管理和服务发现模块进行了微服务拆分，新增心跳服务 (以下简称 HS) 和名字服务 (以下简称 NS) 避免了业务实例直连 ETCD，同时引入了 Prometheus，对心跳上报状态和路由获取状态等信息进行监控和可视化展示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-bb9efb9826cf2b2ebe1bae522ce0df14546.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_15"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.2&amp;nbsp;NS(NamingService) 设计&lt;/h3&gt; 
&lt;p&gt;我们对 NS 的定位是作为 ETCD 的 cache，采用 Read-Through 的模式，对全量业务的 RANK 提供拓扑信息查询，RANK 不再直接访问 ETCD:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;NS 本身设计为一个&lt;strong&gt;&lt;strong&gt;无状态服务&lt;/strong&gt;&lt;/strong&gt;， RANK 可以访问任意一台 NS 获取拓扑，NS 实例之间拓扑路由&lt;strong&gt;&lt;strong&gt;保证最终一致性&lt;/strong&gt;&lt;/strong&gt;，NS 在拓扑变更时返回拓扑信息+MD5(拓扑)+更新时间戳，未变更时仅返回 MD5 和时间戳， RANK 基于 MD5 和时间戳自行判断是否需要更新。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;拓扑更新策略下沉到 NS 中，RANK 获取到的拓扑即为直接可用拓扑，针对不同业务提供不同的控制策略并且后续升级改造只需上线 NS，成本大幅降低。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;单机房 3 台 NS 实例即可支撑全部业务拓扑查询，重构前后 ETCD 读流量比例为 M:3，M 为平均每个业务 RANK 实例数，假设 N 取 30，则读流量下降 90%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-93ea29c3774379e1a2cabf37f1ed095a248.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_16"&gt;&lt;/span&gt; 
&lt;h3&gt;3.1.3&amp;nbsp;HS(HeartbeatService) 设计&lt;/h3&gt; 
&lt;p&gt;HS 负责收集 BS 实例本身的心跳以及实例消费的分片的心跳，周期性&lt;strong&gt;&lt;strong&gt;聚合写入&lt;/strong&gt;&lt;/strong&gt;ETCD，并且向 BS 实例返回其最新的消费分片信息:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;HS 采用无主节点设计，也支持任意水平扩展。同一个业务的不同 BS 实例通过&lt;strong&gt;&lt;strong&gt;一致性 hash&lt;/strong&gt;&lt;/strong&gt;方式请求同一台 HS 实例, 便于 HS 进行分片维度的信息聚合，这样在大部分时间，每个分片无论有多少个副本一个周期内只会被写入一次，实例本身的心跳采用批量更新形式，写竞争大幅降低。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 在上报心跳的同时会从 HS 的 response 中获取自身消费的最新分片信息，如果分片信息变化，则清理老分片数据，消费新分片数据，后续只上报新分片状态信息。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;单机房 3 台 NS 实例即可支撑全部业务心跳更新，重构前后 ETCD 写流量比例为 N:1，N 为平均每个分片副本数，假设 N 取 5，则写流量下降 80%。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-f141ad59566f2bbe45c04a1a0dac2046805.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_17"&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;自动扩缩容&lt;/strong&gt;&lt;/h2&gt; 
&lt;span id="OSC_h3_18"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.1&amp;nbsp;当前现状&lt;/h3&gt; 
&lt;p&gt;BS 是一个&lt;strong&gt;&lt;strong&gt;多分片、异构&lt;/strong&gt;&lt;/strong&gt;服务，即每个 App 内通常部署了多个资源号，各业务 App 在 PasS 层面隔离部署，在资源利用率、扩缩容管理等方面我们遇到以下问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;整体资源利用率低。全机房拥有上百个 BS 业务 App、上千个资源号，PaaS 层面的整体平均峰值 CPU 利用率低于平均水平，峰值 CPU 超过 70% 的资源号占比不足 20%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;依赖人工进行资源号副本数调整。一般上线前通过人工压测评估放量后所需的资源然后进行申请，有时候通过压测难以估算真实的资源，并且后续业务迭代或者流量变化也会引起资源使用的变化，如果负载超发，服务稳定性难以保障，如果负载太过空闲，也会造成资源浪费。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;无法直接接入 PaaS 层面自动扩缩容能力。一方面 PaaS 无法感知每个 App 内资源号维度负载信息，另一方面每个实例承载分片信息只能由中控服务调度，因此无法直接服用 PaaS 层面自动扩缩容能力。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-05f53f5b84434e08c78529d148cd54a6dcb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h3_19"&gt;&lt;/span&gt; 
&lt;h3&gt;3.2.2&amp;nbsp;自动扩缩容实现&lt;/h3&gt; 
&lt;p&gt;为了实现容量自适应调整，我们开发了一个自动扩缩容服务，对全量资源号进行容量管理。自动扩缩容服务周期性计算资源号维度负载，根据负载情况，触发中控服务进行资源号副本数调整，或者 PaaS 层面实例数调整。对于扩容，优先调度存量资源池中实例，如果存量实例不足则触发 PaaS 扩容；对于缩容，先将空闲副本数回收至空闲资源池，再触发 PaaS 缩容。对于自动扩缩容服务的设计我们主要考虑了以下几点:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-53d9ad28a3b34ec0ecb4706a0bc8f9316eb.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_20"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;负载指标选取&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;垂搜系统大部分业务 BS 为纯内存版本，且几乎没有下游网络请求，属于典型的计算密集型业务， 因此我们选择 CPU 作为负载计算参考指标，另外资源号混部场景进一步结合 QPS 和 Latency 进行判断。此前我们已经实现了基于 Prometheus 采集实分片维度 CPU、MEM、QPS、Latency、建库数据量等指标全量业务覆盖，因此可以低成本的获取到全量&lt;strong&gt;&lt;strong&gt;资源号维度&lt;/strong&gt;&lt;/strong&gt;的负载数据。&lt;/p&gt; 
&lt;span id="OSC_h4_21"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;负载状态流转&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;每个资源号从扩容到缩容，共定义如下 7 种状态：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;enum LoadStatus { LOAD_STATUS_LOAD_OK = 0; //正常负载 LOAD_STATUS_OVERLOAD = 1; //超负载 LOAD_STATUS_IDLELOAD = 2; //低负载 LOAD_STATUS_BS_ADD_REPLICA = 3; //bs 扩副本中 LOAD_STATUS_BS_REMOVE_REPLICA = 4; // bs 缩副本中 LOAD_STATUS_TRIGGER_PAAS_EXPENSION = 5; // PaaS 扩容中 LOAD_STATUS_TRIGGER_PAAS_SHRINK = 6; // PaaS 缩容中 }&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;每个资源号根据负载情况在上述状态之间流转:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8fa2f7581ed63466a8f24640ad7258bba52.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_22"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;扩缩容执行流程&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;扩副本&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优先调度 App 内空闲实例，不足则触发 PaaS 层面实例数扩容，循环执行直到负载恢复正常。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-edfbd8b326a5709833d414a5fb013f357ed.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;缩容&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;先将资源号多余副本释放为空闲实例，再触发 PaaS 层面缩容，循环执行直到资源号负载以及空闲实例数回到正常水平。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-504ce96574f2dc384b323509ab32bd78022.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_23"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3&amp;nbsp;&lt;strong&gt;资源号扩分片进阶&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;每个资源号随着数据量级不断增长，分片数也需要动态扩展，否则会出现分片内存超发的情况。&lt;/p&gt; 
&lt;span id="OSC_h3_24"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.1&amp;nbsp;&lt;strong&gt;当前扩分片方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;每个资源号按 resource-&amp;gt;slice-&amp;gt;slot 的层级划分，slot 是数据划分最小单位与 kafka partion 一一对应，在业务接入时每个资源号 slot(partion) 的数量已经确定。扩层时，资源号的 slot 数量不变，&lt;strong&gt;&lt;strong&gt;分片数变成原来 2 倍， 每个分片的 slot 数则为原来的 1/2&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8db852d84d0b6a8d63c9bac9fed576d9490.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;原有的扩分片方案可以在无需重新建库的情况下实现业务无感的原地分片扩缩操作，然而依旧存在两个问题:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;分片数按指数增长，当分片数超过一定数值，将带来不容忽视的资源成本。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果初始分配 slot 数太少，当 slice:slot=1:1 时，无法再扩层，数据增长出现瓶颈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_25"&gt;&lt;/span&gt; 
&lt;h3&gt;3.3.2&amp;nbsp;&lt;strong&gt;进阶扩展方案&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;对于分片无法继续扩展但是依旧需要继续建库的情况，先前的方案只能是重建一个新的资源号，需要业务、架构共同介入，历史上我们使用原方案迁移一个资源号，前后&lt;strong&gt;&lt;strong&gt;投入近 3 周时间&lt;/strong&gt;&lt;/strong&gt;，耗费成本巨大，因此我们需要一个成本更低的方案。通过分析，当前分片的扩展瓶颈主要有以下三个限制条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;每个资源号的 slots 是一段连续的区间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;BS 的 slot 与 Kafka 的 partition 一一对应。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;初始分配 slot 数太少，且后续不支持调整。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;只需要打破其中任意一个条件，则可以消除瓶颈。综合考虑改造成本、扩展灵活性、实现难度等因素，我们选择从条件三入手，在新的 partition 区间重建分片，分片数和 slot 数根据数据量设置，将旧分片的数据全量复制到新的分片上，再将新分片替换旧分片，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-1534a9d4b6b75072160e0a0470563a1c8c8.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h4_26"&gt;&lt;/span&gt; 
&lt;h4&gt;&lt;strong&gt;整体实现&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;对于一个流式建库系统，业务可能时刻都在进行数据建库，我们希望做到迁移过程中业务依旧可以持续建库，并且保证数据不丢失、时序不错乱。我们的方案是将数据分为存量数据 (老分片中的全量数据) 和增量数据 (实时写入的新数据)，对于增量数据可以通过双写机制，同时写入新旧分片，存量数据则通过构建 snapshot 的方法迁移至新分片，新分片数据 ready 后，再由服务发现层将检索流量切换至新分片，整体流程如下:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;离线侧开启双写，保证增量倒排索引数据同时写入新旧分片，正排和摘要部分数据无需变化。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;基于旧分片构建新分片 snapshot, 并记录构建时间点。将该时间点前旧分片所有数据进行 resharding 构建新分片 snapshot。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;新分片的 BS 实例加载构建好的 snapshot，然后每个 partition 的消费 offset&lt;strong&gt;&lt;strong&gt;回退到 snapshot 构建时间点开始重新消费&lt;/strong&gt;&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;服务发现层将资源号到 slot 区间映射切换到新分片上，检索流量从老分片迁移至新分片。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将旧分片 BS 实例回收，并关闭双写。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-2cc22fbbf1492e639ef2bf5cbd76b4f8c3a.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_27"&gt;&lt;/span&gt; 
&lt;h1&gt;04 总结与展望&lt;/h1&gt; 
&lt;span id="OSC_h2_28"&gt;&lt;/span&gt; 
&lt;h2&gt;4.1&amp;nbsp;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;本文介绍了百度垂搜检索数据管理架构在弹性机制建设上的一系列优化工作，并且在扩展性、稳定性、以及成本效率等方面均取得了预期成果:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;扩展性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 负载下降一个量级，单机房 BS、RANK 集群规模提升两个量级， 单分片副本数上限提升至 5000+。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;分片扩展数量不再受限，解决了部分存量业务无法扩展分片导致的内存超发问题，并支持搜索创新业务数据量从百万级逐步增加至数十亿量级。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;稳定性&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;存量调度问题被修复，新增多种路由调度策略以应对不同场景，分片可用度不足干预时间从小时级缩短至分钟级。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;ETCD 负载不再超发，慢查询基本消失，稳定性风险基本消除，心跳上报、拓扑获取状态建立监控，异常情况及时感知。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;成本效率&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;全机房 BS 接入自动扩缩容，实现容量自适应调整，整体峰值 CPU 利用率提升了 15%+，同时相比之前减少了 80% 人工介入容量调整的情况出现。&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;部分业务通过分片合并，最终使用存储资源为下降至原来的 20%，并且检索 97 分位耗时降低了 20ms，业务侧效果与先前打平。&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_29"&gt;&lt;/span&gt; 
&lt;h2&gt;4.2&amp;nbsp;&lt;strong&gt;展望&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;目前索引库的自动扩缩容机制实现了副本数随负载 (CPU) 的自动调整，后续将实现分片数随数据量的自动调整。另外，在大库场景将持续建设流批一体机制，以追求用更低的存储成本实现更高的检索性能。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4939618/blog/18627327</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/18627327</guid>
      <pubDate>Sun, 11 May 2025 03:11:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Sam Altman 透露将在今年夏季发布 GPT-5</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今天凌晨，OpenAI 发布了其联合创始人兼首席执行官 Sam Altman 的 40 分钟深度专访。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0619/105636_pUBl_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1935357512011890815" target="_blank"&gt;透露&lt;/a&gt;&lt;/u&gt;，备受瞩目的 GPT-5 预计将于今年夏天推出，不过具体发布日期尚未确定。&lt;/p&gt; 
&lt;p&gt;据报道，GPT-5 性能将远超 GPT-4，测试者表示其在多方面有显著进步。据悉，这款新模型将整合 OpenAI 的核心技术，融合 GPT-4o 自然语言处理的灵活性与 o3 在代码及科学推理方面的优势，打造更强大的统一系统。&lt;/p&gt; 
&lt;p&gt;Altman 暗示，GPT-5 或许不仅是性能上的升级，更可能是 OpenAI 迈向统一、类似代理模型的重要一步，使其向人工通用智能（AGI）目标更进一步。&lt;/p&gt; 
&lt;p&gt;此外，据 AI 工程师 Tibor Blaho 和投资者「Chris（chatgpt21）」消息透露，OpenAI 或将在 7 月发布一个大规模模型，而该模型有望为 GPT-5。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/354761" target="news"&gt;OpenAI 推迟开源模型的发布时间&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356142</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356142</guid>
      <pubDate>Sun, 11 May 2025 02:56:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​OpenAI 终止与 Scale AI 合作</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 发言人当地时间周三向&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-18%2Fopenai-is-phasing-out-its-work-with-scale-ai-after-meta-deal" target="_blank"&gt;彭博社&lt;/a&gt;透露，在 Meta 与 Scale AI 达成交易后，OpenAI 将逐步停止与 Scale AI 的合作，并切断与该数据供应商的联系。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 表示，早在 Meta 上周宣布向这家初创公司投资数十亿美元并任命 Alexandr Wang 担任首席执行官之前，该公司就已开始逐步结束与 Scale AI 的合作。OpenAI 一直在寻找其他供应商来获取更专业的数据，以开发日益先进的 AI 模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="336" src="https://oscimg.oschina.net/oscnet/up-77faf9c892257b37289b5ccb5a6d4304d54.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;OpenAI 断绝关系的决定引发了人们对 Scale AI 核心数据标签业务的质疑。上周，路透社报道称，谷歌也在讨论放弃 Scale AI 作为数据提供商的计划。随着 Meta 与 Scale AI 达成合作，Scale AI 的一些竞争对手表示，他们收到了大量寻求「中立」合作伙伴的 AI 模型供应商的兴趣。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的一篇博客文章中，Scale AI 的总法律顾问试图驳斥 Meta 将在此次交易后获得优待的说法。Scale AI 的高管表示，公司不会与 Meta 分享其他客户的机密信息，并且新任首席执行官 Wang 不会直接参与公司的日常运营。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在周三发布的另一篇博客文章中，Scale AI 的临时首席执行官 Jason Droege 则表示，公司将「加倍投入」其应用程序业务，其中包括为政府和企业构建定制的 AI 应用程序。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356119/openai-drops-scale-ai-meta</guid>
      <pubDate>Sun, 11 May 2025 02:29:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Midjourney 发布首个 AI 视频生成模型 V1</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 初创公司 Midjourney &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fmidjourney%2Fstatus%2F1935377193733079452" target="_blank"&gt;宣布&lt;/a&gt;推出其备受期待的首款 AI 视频生成模型 V1，支持图像到视频的生成，并可实现从文本直接生成视频。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1216" src="https://static.oschina.net/uploads/space/2025/0619/102551_SwUy_2720166.png" width="1286" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;V1 目前仅通过 Discord 平台的网页端提供服务，基础订阅费为每月 10 美元。&lt;/p&gt; 
&lt;p&gt;根据 Midjourney 的官方介绍，V1 基于此前的图像模型生态进行打造。&lt;/p&gt; 
&lt;p&gt;Midjourney V1 操作分为自动和手动两种模式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动模式下，平台会根据用户生成的图片，自动创建「动作提示词」并让画面运动起来；&lt;/li&gt; 
 &lt;li&gt;手动模式则是由用户提供提示词。同时，Midjourney V1 也分为「低动态」和「高动态」两种运动模式。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;V1 的发布让 Midjourney 加入与 OpenAI 的 Sora、Runway 的 Gen 4 等 AI 视频模型的竞争。其目标不止于为好莱坞或广告业生成素材，公司 CEO David Holz 称这是迈向 「实时开放世界模拟」 AI 模型的一步，后续还计划开发 3D 渲染和实时 AI 模型。 &amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356115/midjourney-launches-its-first-ai-video-generation-model-v1</guid>
      <pubDate>Sun, 11 May 2025 02:26:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>MiniMax 考虑赴港 IPO？知情人士：属实，仍处于初步筹备阶段</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;有消息称，AI 独角兽稀宇科技 (MiniMax) 正考虑在香港进行首次公开募股（IPO）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;对此，有接近 MiniMax 的知情人士向澎湃新闻记者表示，MiniMax 内部确实有类似想法，但目前仍处于初步筹备阶段。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="275" src="https://oscimg.oschina.net/oscnet/up-1c8fdc630a51d77c2dbbdb3ff2131f20e68.png" width="700" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;官网介绍显示，MiniMax 是全球领先的通用人工智能科技公司。自 2022 年初成立以来，以「与所有人共创智能」为使命，致力于推动人工智能科技前沿发展，实现通用人工智能 (AGI）。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，MiniMax 已自主研发了一系列多模态通用大模型，包括 MiniMax M1、Hailuo-02、Speech-02 和 Music-01，具备超长上下文处理能力，能够理解、生成并整合包括文本、音频、图像、视频和音乐在内的多种模态。并基于这些自研模型推出一系列 AI 原生产品，包括 MiniMax、海螺 AI、MiniMax Audio、星野等，以及面向企业和开发者的开放平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;2024 年 3 月，MiniMax 获 6 亿美元 A 轮融资，投后估值 25 亿美元，由阿里巴巴领投，此前融资的投资方也包括腾讯等。据媒体报道称，MiniMax 的实际估值目前已经超过 2024 年所报道过的「25 亿美元」。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356108</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356108</guid>
      <pubDate>Sun, 11 May 2025 02:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>融云 AI 机器人上线，独家直连 AI 平台，加速落地创新探索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;AI 技术的爆发为各行各业带来了前所未有的机遇，各类创新应用如雨后春笋般涌现——从图像生成、视频创作，到智能搜索引擎、代码助手，AI 正在重塑人们的工作与生活方式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;而在这一波浪潮中，ChatBot 类产品及其衍生形态——如虚拟角色、智能客服和 AI 助理——作为 AI 普及的「OG」，始终占据着核心地位。无论是全球科技巨头的布局，还是创业团队的创新尝试，这一领域依然活力十足，不断有优秀的新产品崭露头角。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;深度整合 IM 对话与 AI 能力，融云 AI 机器人正式上线。&lt;span&gt;提供&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;独立的机器人用户类型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，拥有&lt;/span&gt;&lt;strong&gt;&lt;span&gt;详细的事件回调能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;strong&gt;独家直连 AI 平台&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，大幅降低开发者落地 AI 社交、智能回复等业务的成本，给开发者的创新探索加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;无论是以全新产品角逐市场，还是在现有产品中增加附加玩法。融云 AI 机器人都可以&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;有效缩短业务上线周期，助力开发者快速探索充满潜力的 AI 赛道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;场景丰富，响应稳定&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持基于指定机器人的详细事件回调，方便开发者精准掌握用户与机器人的互动，如单聊消息、群聊@指令等，并基于不同事件进行定制化处理，灵活响应各类业务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;无论是自动回复、任务触发，还是群聊助手，都可以借助融云 AI 机器人轻松实现更智能、更丰富的交互，&lt;/span&gt;&lt;span&gt;&lt;span&gt;提升产品的用户体验及业务运营效率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;以单聊和群聊两种主要对话场景来看：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在单聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过与机器人对话，可触发多轮智能对话、内容生成等功能，支持流式或非流式输出，适用于&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 陪伴、角色扮演&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等社交场景&lt;/span&gt;&lt;span&gt;&lt;span&gt;及&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;AI 知识问答、智能客服&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等商务社交场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="636" src="https://oscimg.oschina.net/oscnet/up-faa3c43ddca6e7fdc989dafeddb8f0d1286.png" width="585" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;除了稳定高效的多轮对话支持外，还可以实现智能任务执行功能，响应用户发起的智能操作请求，如「生成北京出行计划」、&lt;span&gt;「写一封邮件」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;等；或&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;查询个人事务，如「我今天还有哪些未完成的任务」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;&lt;span&gt;在群聊中&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过 @ 机器人，触发与 AI 机器人的沟通或智能业务处理流程，如：&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;FAQ 问答：解析用户意图并自动回复；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;工单创建：识别需求并提交至工单系统；&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;日程提醒：识别时间表达并添加到日历服务。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;快速上线，降本增效&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;提供独立的机器人类型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;融云 IM 提供独立的机器人服务，自带区别于真实用户类型的业务逻辑，大幅降低开发者在 AI 对话类业务实现时针对机器人的特殊处理逻辑，从底层能力上满足开发者灵活创新的 AI 对话需求，极具拓展性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;独家直连&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;&amp;nbsp;AI 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;融云 AI 机器人业内独家实现了与第三方 AI 平台的对接，开发者无需进行繁琐的中间处理，即可快速接入 AI Agent 创建调试及大模型推理服务，显著降低开发难度，为开发者的 AI 社交、智能客服等业务落地打开了一个「绿色极速通道」。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;此前，开发者若想借助 AI 平台赋能自身的 AI 对话类业务，需要自行实现中间的需求中转和消息流转，链路长、问题多。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过融云 AI 机器人，开发者可在简单调用接口后实现对 AI 平台能力的关联，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;链路稳定、响应高效&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并可以在融云&lt;/span&gt;&lt;strong&gt;&lt;span&gt;流式消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等底层能力和&lt;/span&gt;&lt;strong&gt;&lt;span&gt;内容审核&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;等周边服务的配套支持下实现灵活的业务需求。&lt;/span&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;&lt;span&gt;接入便捷，灵活搭建&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;融云 AI 机器人支持 Webhook 回调、Dify 平台对接，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方便开发者根据自身的业务情况选择对接方式：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;设置 Webhook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可通过 Webhook 回调，将用户向机器人发送的消息同步到自己的业务服务器，由业务服务器自由对接自研或私有大模型自建服务（&lt;em&gt;如私有部署的 LLM、LangChain、RAG 检索系统等&lt;/em&gt;）。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;通过这一方式可以实现灵活的消息接入、参数定制、响应策略，&lt;/span&gt;&lt;span&gt;&lt;span&gt;适合有高度定制化、私有化部署、安全隔离等要求的业务场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;对接 AI Agent 平台&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;支持对接已&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;接入 OpenAI、Claude、Gemini 等多种大模型的 Dify 平台。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;客户可在 Dify 平台上创建一个自己的 AI Agent（&lt;/span&gt;&lt;em&gt;&lt;span&gt;如：聊天机器人&lt;/span&gt;&lt;/em&gt;&lt;span&gt;），同时在融云服务端创建一个机器人，并将该机器人通过配置直接与 Dify 平台创建的 AI Agent 进行对接。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;这样，&lt;/span&gt;&lt;span&gt;&lt;span&gt;无需自行搭建模型服务，就可以实现多轮 AI 对话、知识库问答、RPA 流程（&lt;em&gt;机器人流程自动化&lt;/em&gt;）等&lt;/span&gt;&lt;span&gt;&lt;span&gt;高级功能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="text-align:center"&gt;&lt;img alt="" height="148" src="https://oscimg.oschina.net/oscnet/up-7518cc39e9922c3ad838434add534928cc3.png" width="580" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span style="color:#0045ff"&gt;&lt;span&gt;快速搭建 AI 陪伴应用示例&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;以 AI 陪伴应用为例，融云提供从 AI 角色配置、Prompt 预设到 IM 对接的全链路服务，&lt;/span&gt;&lt;span&gt;&lt;span&gt;快速搭建 AI 陪伴应用。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在 Dify 中创建和调试 AI Agent&amp;nbsp;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪创建聊天助手&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪填写人设&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪设置 LLM 和参数&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪配置开场白&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑ 在融云服务端创建机器人并完成关联&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过 Server API 创建机器人&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;▪通过&lt;/span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;Agent 地址&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;设置机器人的回调配置信息，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;关联 AI Agent&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;☑在客户端集成 IM SDK， AI 角色便可出现在 App 中，提供&lt;/span&gt;&lt;span&gt;&lt;span&gt;智能破冰、AI 陪伴等能力，助力应用提升用户粘性和商业价值。&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;详细接入流程可见本期推文次条&lt;/span&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p style="margin-left:0; margin-right:0"&gt;&lt;span&gt;&lt;span&gt;更多详情见&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#0045ff"&gt;&lt;em&gt;&lt;span&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.rongcloud.cn%2Fplatform-chat-api%2Fbot%2Foverview" target="_blank"&gt;开发者文档&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356103</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356103</guid>
      <pubDate>Sun, 11 May 2025 02:01:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
    <item>
      <title>Firefox 139 测试内置 Perplexity AI 搜索</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;负责 Firefox 搜索的产品经理&amp;nbsp;Gayatri &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fconnect.mozilla.org%2Ft5%2Fdiscussions%2Ftry-out-perplexity-ai-search-in-firefox-139%2Ftd-p%2F98352" target="_blank"&gt;宣布&lt;/a&gt;&lt;/u&gt;团队正在与 Perplexity 合作，将&amp;nbsp;Perplexity AI 搜索内置到 Firefox 139 中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-db094748597759caee52fd4a82e08cdcb33.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="450" src="https://static.oschina.net/uploads/space/2025/0618/191849_B1yu_2720166.png" width="1390" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Perplexity 是一个 AI 驱动的搜索引擎，能直接以对话形式回答你的问题——无需翻阅大量搜索结果。它特别适用于以下情况：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅&amp;nbsp;需要快速简洁的答案，避免在多个信息源中迷失&lt;/li&gt; 
 &lt;li&gt;📚&amp;nbsp;在研究或学习时需要准确且引用充分的资料&lt;/li&gt; 
 &lt;li&gt;✍️&amp;nbsp;在创作或处理技术内容，如博客文章或代码片段&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Firefox 团队表示，这是他们更广泛目标的组成部分，即在使用搜索方式以及信任哪些工具来帮助他们完成任务方面为用户提供更多选择。如果体验良好，可能会考虑在未来支持更多 AI 回答或搜索选项。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356035/perplexity-ai-search-in-firefox</guid>
      <pubDate>Sat, 10 May 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>DeepEP —— 开源 EP 通信库</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                        
                                                                                    &lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;DeepEP 是专为&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Mixture-of-Experts (MoE)&lt;/span&gt;&amp;nbsp;和 &lt;span style="background-color:#ffffff; color:#1f2328"&gt;expert parallelism (EP)&lt;/span&gt;&amp;nbsp;定制的通信库。它提供高吞吐量和低延迟的&amp;nbsp;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;all-to-all&lt;/span&gt;&amp;nbsp;GPU 内核，也就是所谓的 MoE 调度和组合。该库还支持低精度操作，包括 FP8。&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;为了与 DeepSeek-V3&amp;nbsp;论文中提出的 group-limited gating algorithm 保持一致，DeepEP 提供了一组针对非对称域带宽转发（例如将数据从 NVLink 域转发到 RDMA 域）进行优化的内核。这些内核提供高吞吐量，使其适合训练和推理预填充任务。此外，它们还支持 SM (Streaming Multiprocessors)&amp;nbsp;数量控制。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span&gt;&lt;span&gt;&lt;span style="color:#1f2328"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span style="background-color:#ffffff"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;对于延迟敏感的推理解码，DeepEP 包含一组具有纯 RDMA 的低延迟内核，以最大限度地减少延迟。该库还引入了一种 hook-based 通信计算重叠方法，该方法不占用任何 SM 资源。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p style="color:#333333; margin-left:0; margin-right:0; text-align:start"&gt;&lt;strong&gt;要求&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li style="text-align:start"&gt;Hopper GPU（以后可能支持更多架构或设备）&lt;/li&gt;
&lt;li style="text-align:start"&gt;Python 3.8 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;CUDA 12.3 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;PyTorch 2.1 及以上版本&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 NVLink&lt;/li&gt;
&lt;li style="text-align:start"&gt;用于节点内通信的 RDMA 网络&lt;/li&gt;
&lt;/ul&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/deepep</link>
      <guid isPermaLink="false">https://www.oschina.net/p/deepep</guid>
      <pubDate>Sat, 10 May 2025 10:35:00 GMT</pubDate>
    </item>
    <item>
      <title>Gitee MCP 现已支持远程访问：无需本地部署，AI 助手即插即用</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今年三月，&lt;a href="https://www.oschina.net/news/338794/gitee-mcp-server"&gt;Gitee 正式发布了官方 MCP Server&lt;/a&gt;，让 AI 助手深度参与代码仓库的管理，助力开发者更高效地工作。&lt;/p&gt; 
&lt;p&gt;今天，Gitee MCP 正式支持远程访问，上线了&lt;code&gt;Remote mcp-gitee&lt;/code&gt;：无需安装、即开即用，让 AI 助手可以远程、安全地与 Gitee 交互，真正做到「即连即用」。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;开源地址：&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;什么是 Remote mcp-gitee？&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;是 Gitee 推出的远程版 MCP Server，无需本地部署，默认运行在云端，同时也拥有全面的接口能力，支持仓库、文件、Issue、PR、用户信息获取、评论等众多操作，满足常见开发协作需求。&lt;/p&gt; 
&lt;p&gt;你可以通过简单配置直接将其接入任意支持 MCP Streamable HTTP 协议的客户端，&lt;strong&gt;无需安装依赖、编译构建，也无需配置本地环境&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;与此前的本地部署方式不同，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;将服务完全托管在云端，为用户提供了开箱即用、跨平台、跨设备的一致使用体验。&lt;/p&gt; 
&lt;h2&gt;远程 MCP 有哪些使用场景&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI 驱动的协作&lt;/strong&gt;：通过&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手能够自动创建 Issue、提取任务、拆解子任务、发起/合并 PR，减轻日常操作负担。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;低门槛接入&lt;/strong&gt;：无需本地搭建或安装依赖，企业或个人团队只需配置一次，即可将 MCP 能力集成至工作流中。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;跨团队标准化流程&lt;/strong&gt;：所有操作通过远端 MCP 接入，统一管理权限、审计、日志，便于追踪和审查。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;无需部署即可读写代码仓库&lt;/h2&gt; 
&lt;p&gt;借助&lt;code&gt;Remote mcp-gitee&lt;/code&gt;，AI 助手将具备完整的上下文访问能力，能够直接调用 Gitee 接口，获取仓库结构、读取文件内容、创建 Issue、生成 PR，甚至合并代码、发布版本。&lt;/p&gt; 
&lt;p&gt;你只需要准备一个 Gitee 访问令牌，并将其配置在客户端中，即可激活整个智能协作流程：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
&amp;nbsp;&amp;nbsp;"mcpServers": {
&amp;nbsp; &amp;nbsp;&amp;nbsp;"gitee": {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"url":&amp;nbsp;"https://api.gitee.com/mcp",
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"headers": {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;"Authorization":&amp;nbsp;"Bearer &amp;lt;YOUR PERSONAL ACCESS TOKEN&amp;gt;"
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;本方法适用于 Cursor、Trae 等多种主流客户端，配置完毕后，即可直接连接 Remote mcp-gitee。&lt;/p&gt; 
&lt;h3&gt;在 Cursor 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;进入 Cursor 设置页面，选择&lt;code&gt;Tools &amp;amp; Integrations&lt;/code&gt;，新建一个 MCP Server。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182420_lanO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌，保存即可。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182431_KJ6X_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;返回设置页面，可以看到 mcp-gitee server 已正常连接。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182440_lOSn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3&gt;在 Trae 中连接 Remote mcp-gitee&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;选择任意一种方式进入 MCP 设置页面。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182451_sEtI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;搜索 Gitee 并添加。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182501_L5XD_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;将配置信息复制到文件中，填入 Gitee 账号的私人令牌（Trae 暂时未支持远程连接，需手动复制远程连接的配置信息）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182511_Y51c_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;确认后，mcp-gitee server 已成功连接至 Trae。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height="360" src="https://static.oschina.net/uploads/space/2025/0618/182521_D6Qz_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0618/182549_TvrI_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;同时，开发者也可选择自行部署 Remote mcp-gitee 至本地，具体流程可访问项目仓库查看：&lt;a href="https://gitee.com/oschina/mcp-gitee"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;即插即用的智能协作，就在 Gitee&lt;/h2&gt; 
&lt;p&gt;Gitee 始终致力于在 AI 时代持续探索智能开发的边界。无论是底层协议支持，还是工具链能力拓展，我们都希望为开发者&lt;strong&gt;提供更开放、更易用、更高效、更先进的基础设施&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Remote mcp-gitee&lt;/code&gt;让 Gitee MCP 能力以即插即用的方式走进开发者日常。无需安装、无需配置环境，只需一段 JSON 与私人令牌，就能让 AI 真正参与项目开发的各个环节。&lt;/p&gt; 
&lt;p&gt;现在，&lt;code&gt;Remote mcp-gitee&lt;/code&gt;已全面开放使用，欢迎体验轻量、流畅的智能协作能力，欢迎访问项目仓库了解更多信息。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;u&gt;&lt;strong&gt;&lt;a href="https://gitee.com/oschina/mcp-gitee" target="_blank"&gt;https://gitee.com/oschina/mcp-gitee&lt;/a&gt;&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356026</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356026</guid>
      <pubDate>Sat, 10 May 2025 10:27:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国家互联网信息办公室：中国已有 433 款大模型完成备案</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在 2025 上海世界移动通信大会（MWC 上海 2025）开幕式上，国家互联网信息办公室副主任王京涛在致辞中指出，截至目前，中国已经有 433 款大模型完成备案，上线提供服务。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛表示，目前中国已成为全球最大的互联网市场，拥有全球最多的网民和移动互联网的用户，以及最活跃的数字技术和应用创新生态，建成了全球规模最大、技术领先、性能优越的网络基础设施。在追求自身发展的同时，中国也积极地推进各国共享互联网发展机遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;面向未来，中国要坚持发展与安全并重研究，加强发展战略、治理规则和技术标准的对接协调，推动人工智能朝着有益、安全、公平的方向健康、有序发展。要尊重各国网络主权，尊重各国的互联网发展道路和治理模式，共同构筑和平、开放、安全、合作、有序的网络空间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;王京涛还表示，以人工智能为代表的新的数字技术，给人类生产生活带来前所未有的机遇的同时，不同地区、国家、群体间享受数字红利的差距依然较大。对此，他建议，秉持人类共同体理念，广泛开展人工智能国际合作，帮助发展中国家加强能力建设，提高人工智能的技术的可及性，弥合全球智能鸿沟，释放更多的智能红利。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356024</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356024</guid>
      <pubDate>Sat, 10 May 2025 10:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「最火 AI 编程软件」 Cursor 备受风投公司青睐，公司估值超过 180 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2025-06-17%2Fai-startup-anysphere-fields-vc-offers-at-over-18-billion-valuation"&gt;据彭博援引知情人士报道&lt;/a&gt;，近几周来，投资者已与 Cursor 开发商 Anysphere 接洽，商讨一项融资协议，该协议将使这家初创公司的估值达到 180 至 200 亿美元。该提议是在这家 AI 初创公司年收入超过 5 亿美元后不久提出的。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/180654_RHv6_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;知情人士透露，该公司并未主动寻求新一轮融资，而是投资者主动接洽。&lt;/p&gt; 
&lt;p&gt;Anysphere 首席执行官 Michael Truell 此前透露，超过半数财富 500 强企业使用 Cursor，日活用户超过 100 万人。OpenAI、Spotify、美国职业棒球大联盟和 Instacart 等知名公司均为其用户。&lt;/p&gt; 
&lt;p&gt;这家成立于 2023 年的公司年化收入已突破 5 亿美元，被硅谷投资者誉为 「史上收入增长最快的初创公司」。虽然公司目前并不缺乏现金，但考虑到有利的融资条件，Anysphere 可能会选择增加更多资本储备。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356022</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356022</guid>
      <pubDate>Sat, 10 May 2025 10:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>bzip2 的 crate 包已完全从 C 迁移到 Rust</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;bzip2 0.6.0&amp;nbsp;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftrifectatech.org%2Fblog%2Fbzip2-crate-switches-from-c-to-rust%2F" target="_blank"&gt; 已发布&lt;/a&gt;，团队称新版本默认采用他们实现的 bzip2 算法 libbz2-rs-sys，bzip2 的 crate 包也已完全从 C 迁移到 Rust，bzip2&amp;nbsp;库现在编译更快、跨编译更简单。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173858_3xAW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;尽管现在 bzip2 的使用不如以前广泛，但许多协议和库仍需支持它以满足规范要求。团队借鉴了在 zlib-rs 项目中的经验，对 bzip2 的实现进行了更新。&lt;/p&gt; 
&lt;p&gt;在性能方面，Rust 实现通常优于 C 实现，尽管在某些情况下两者性能相当。压缩性能测试显示，Rust 实现的压缩速度比 C 实现快 14% 左右。在解压缩方面，Rust 实现也带来了显著的速度提升，测试结果显示平均速度快了 5%-10%。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://static.oschina.net/uploads/space/2025/0618/173936_x7TO_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;移除 C 语言依赖后，Rust 项目在交叉编译时的复杂性大大降低，编译为 WebAssembly 等平台的问题也得到了解决。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读：&lt;a href="https://www.oschina.net/news/256102/sudo-rs-0-2-0-first-stable" target="news"&gt;sudo-rs 发布首个稳定版 0.2.0：内存安全、用 Rust 重写的 sudo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356012/bzip2-crate-switches-from-c-to-rust</guid>
      <pubDate>Sat, 10 May 2025 09:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​字节跳动 Seedance 1.0 模型评测结果超越谷歌 Veo 3</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在近期的人工智能视频生成领域，字节跳动悄然发布了一款名为 Seedance1.0 的新模型，该模型在独立的评测中已经超越了谷歌最新推出的 Veo3。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 的研究论文中详细介绍了该模型的创新之处。字节跳动的团队通过对空间和时间层的解耦，结合了多模态位置编码，从而使得该模型能够同时处理文本到视频和图像到视频的生成任务。这样的方法支持复杂的场景切换和多镜头敍事，保持了一致的主题表现。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="185" src="https://oscimg.oschina.net/oscnet/up-cdfc14b924c4930f690c558ca675747c61e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;此外，Seedance1.0 的性能离不开字节跳动强大的数据管道。团队精心构建了一个大规模、多来源的数据集，配有详细的双语注释和丰富的动作与静态特征标注，确保生成内容的准确性。同时，采用了一种新颖的强化学习设置，结合了三个奖励模型，重点关注基础对齐、动作质量和美观度。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-3b8266677daa9731bb02990119d48c53102.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在评测中，Seedance1.0 在多个维度上超过了 Veo3。在与电影导演合作开发的 SeedVideoBench 基准测试中，该模型在遵循提示和动作真实感方面取得了更高的分数。在图像到视频的任务中，Seedance 保持了输入帧的视觉一致性，而 Veo3 则在某些情况下出现了光照和纹理的变化。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="293" src="https://oscimg.oschina.net/oscnet/up-47383f948234dcb7e6170c1e5457953697d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在推理性能方面，Seedance1.0 也表现出色。该模型能够在 41.4 秒内生成一段 1080p 的五秒视频，这一速度远超其他竞争对手，如 Sora、Runway Gen-4 和 Veo3。字节跳动还表示，他们在降低成本和延迟方面取得了重大进展，使得视频生成向实时应用的目标迈进了一步。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Seedance1.0 计划于 2025 年 6 月集成到 Doubao 和 Jimeng 等平台，旨在显著改善专业工作流程和常规创作任务。虽然 Veo3 因首次结合了真实视频与环境音效和对话而备受瞩目，但 Seedance1.0 在视觉保真度、运动稳定性和敍事连贯性方面表现更为出色，虽然在音频能力上有所欠缺。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/356005</link>
      <guid isPermaLink="false">https://www.oschina.net/news/356005</guid>
      <pubDate>Sat, 10 May 2025 09:17:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>通过 AIOps、生成式 AI 和机器学习，实现更智能的可观测性</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;云与 AI 成为基础设施与平台的当下，运维团队正面临多重挑战：指标、日志、跟踪数据割裂形成的「数据孤岛」，被动响应机制导致的平均修复时间攀升，传统监控在动态微服务架构中的失效等等。&lt;/p&gt; 
 &lt;p&gt;而在现代应用开发的背景下，可观测性可以从各种来源收集和分析数据：日志、指标和追踪 —— 以深入了解在你环境中运行的应用程序的行为。而通过可观测性方案 + AI，也能为现代 IT 系统实现更加智能的可观测性。&lt;/p&gt; 
 &lt;p&gt;本周六，第 114 期 OSC 源创会将在北京举办，以「AI 运维「开挂」指南」为主题。Elastic 社区首席布道师刘晓国将出席活动，并发表《通过 AIOps、生成式 AI 和机器学习，实现更智能的可观测性》主题演讲。在活动正式开始前，先来简单了解下可观测方案。&lt;/p&gt; 
 &lt;p&gt;&lt;img height="1440" src="https://oscimg.oschina.net/oscnet/up-499956c715242acc73d6281d0bffbe0ce6b.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您提到现代系统需从「被动响应转向主动防御」，当前企业在可观测性实践中面临的最大痛点是什么？传统监控方案为何难以应对云原生环境下的复杂性？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;数据量大，存储成本高、海量数据处理压力大，很多企业的可观测性数据（指标，日志及跟踪）存在于不同的数据库中，从而造成数据孤岛，手动关连它们或通过一些工具进行转化比较困难。当真正的事件发生后，很难找到真正的原因。另外人工分析这些数据几乎是不可能的，特别是想从被动响应转向主动防御。 &lt;strong&gt;Elastic 的全面可观测性方案&lt;/strong&gt;可以采用机器学习的方法来对实时数据进行分析，并查看异常事件，从而完成从被动响应转向主动防御的需求。这些异常的事件可以结合通知/告警的方式以不同的形式发送给运维人员。云原生环境中的服务频繁启动，停止和扩展，传统的监控很难实时地跟踪这些变化。另外，传统监控难以在云环境中捕获服务的调用链和依赖关系。Elastic 的服务图可以很方便地显示各个服务之间的调用关系，并在图上以不同的颜色显示该服务的健康状态。我们可以结合机器学习及大模型来进一步解释及提供修正的方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 可观测性方案的优势是什么？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic 可观测性方案把指标，日志，跟踪及通用分析数据保存于同一个数据库中，尽管存在于同一个平台的不同索引里。Elastic 使用 ECS (Elastic Common Schema) 语义语法来定义统一的字段名称。这样不同的索引还是可以通过一些字段进行关联。当一个事件发生时（比如响应缓慢可以在跟踪视图可见），我们可以同时同时在一个平台查看日志，指标，从而找出真正的事件原因。Elastic 全观测性方案可以更快地位 IT 团队找出根因，而不用在各个不同的平台里进行手动关联，或通过一种转换的方式来进行操作。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：在您遇到的案例中，是否有某个问题通过传统监控完全无法捕捉，却因 Universal Profiling 的‘全栈可见性’意外暴露？当时团队如何反应？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Elastic Universal Profiling™ 是一种全系统、始终在线、连续的分析解决方案，无需代码检测、重新编译、主机上调试符号或服务重新启动。 通用分析利用 &lt;span style="color:#6425d0"&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Febpf.io%2F" target="_blank"&gt;eBPF&lt;/a&gt;&lt;/span&gt; 在 Linux 内核空间内运行，以不引人注目的方式以最小的开销仅捕获所需的数据。它可以帮我们定位消耗时间最多的函数以及这些函数的调用情况，并以火焰图的形式表达出来。它可以帮我们了解整个基础架构中哪些代码行始终消耗 CPU 资·源。我们可以通过 Universal Profiling 工具来优化我们的代码设计。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：&lt;/strong&gt;&lt;strong&gt;AI&lt;/strong&gt;&lt;strong&gt; Assistant 生成的操作建议需要人工复核吗？在您经历的案例中，运维团队对 AI 建议的信任度如何建立？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我们的 AI Assistant 是基于 LLM RAG 基础之上的智能助手。我们可以建立自己的知识库，从而消除人工智能在推理时产生的幻觉。这些知识库存在于 Elastic 自己的索引里，是可以由运维人员自己创建的，或者直接有运营手册直接导入的。这些知识库可以来自 github，runbook， playbook 等。另外 Elasticsearch 的文档非常全面，很多大模型对 Elasticsearch 的文档进行了充分的训练。通常来说，产生幻觉的机会还是蛮少的。我们将来甚至可以推出自己的大模型。针对有些敏感的操作，我们可以在助手里做出相应的选择。在 AI 进行回答问题之前，通常会查看自己的知识库得到最相近的答案。如果 AI 提供的推理是建立在自己的知识库之上，或者我们在自己平时积累的解决方案之上，那么 AI 推理提出的解决方案还是相当可以接受的。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：您认为 &lt;/strong&gt;&lt;strong&gt;LLM&lt;/strong&gt;&lt;strong&gt;+Observability 的结合会催生哪些新&lt;/strong&gt;&lt;strong&gt;范式&lt;/strong&gt;&lt;strong&gt;？未来是否可能出现「自主修复系统」？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;是的，这种完全可能。目前在 Elastic 的可观测性方案中，我们使用 AIOps 来针对可观测性提供解决方案。由于 LLM 具有良好的推理及总结功能，甚至它还可以帮我们关联不同索引里的数据。结合私有知识库，LLM+Observability 为我们的可观测性提供良好的解决方案。Elastic 的可观测性其实还有一个叫做 AutoOps 的解决方案。其实主要是针对集群的运行及查询，摄入的监控，并提出相应的解决方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：对于资源有限的中小团队，部署智能可观测性最应规避的‘过度设计’陷阱是什么？能否分享一个最小可行方案的搭建路径？」&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;我觉得尽量采用通用标准，比如 OpenTelemetry 从而规避锁定厂商。另外，尽量避免工具泛滥，膨胀。工具多了，维护的成本也会增加，带来的问题也会很多。如把需要的数据采集到一个数据库中，而不是分散到不同的平台中。还有最好采用一下比较成熟的解决方案，而不是一些未经得到证实的方案。Elastic 其实已经提供了一个比较简介的部署方案，从数据摄取，处理，展示，搜索，及到事件的捕获，通知/告警。在同一个平台即可搞定所有的事。我们还可以结合人工智能来帮助我们摄取，优化，推理，并提供解决方案。&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：开发者需掌握哪些新技能来驾驭智能运维时代？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;日志，指标及跟踪的数据采集，处理及分析技能（Elastic Stack, OpenTelemetry 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;数据整合的能力，比如数据采集，清洗，丰富等&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;熟悉 Kafka, Spark, Flink, Logstash, Beats, Elastic Agents 等数据处理框架。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI/ML 能力。Elastic 中使用 ML 来监测异常事件。虽然开发者不需要掌握很深的 ML 能力，但是知道其作用并如何使用即可。。如果使用 LLMs 来帮助我们分析文件，解决问题。在海量的数据里找到洞察。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;具有使用一些构建易用，直观的运维可视化界面能力（比如 Kibana, Grafana 等）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;通知及告警&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AI agents&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;OSCHINA：Elastic 近年从&lt;/strong&gt;&lt;strong&gt;搜索引擎&lt;/strong&gt;&lt;strong&gt;扩展到可观测性、安全甚至&lt;/strong&gt;&lt;strong&gt;生成式 AI&lt;/strong&gt;&lt;strong&gt;领域，这种跨界拓展背后的核心逻辑是什么？在您看来，未来 3 年 Elastic 最可能颠覆的 「下一个生态位」 会是什么？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;刘晓国：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;其实 Elastic 在很多年前已经进入到可观测性及安全领域。早期我们还有企业搜索。这些构成了 Elastic 的三大技术方案。目前企业搜索已经退出，更多地集成到我们的 Search 解决方案里。Elastic 在过去的三年里大量投入到 AI 领域。我们的向量搜索库 Elasticsearch 是世界上下载最多的数据库。在未来，我们将围绕 AI 打造智能解决方案。LLMs 为这些提供了良好的基础。我们结合 MCP 这种 AI agents 通过自然语言的方式对我们的数据进行查询，分析，并提出解决方案。AI 智能体在未来肯定会越来越聪明，并为我们的可观测性带来自动处理的能力！&lt;/p&gt; 
 &lt;p&gt;&lt;img height="10252" src="https://oscimg.oschina.net/oscnet/up-c40d45614995bacbd788286afa1eafa1aa4.png" width="3125" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/4489239/blog/18627539</link>
      <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18627539</guid>
      <pubDate>Sat, 10 May 2025 08:48:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>Docker Desktop 4.42 发布，集成 MCP 工具包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Docker Desktop&amp;nbsp;4.42 &lt;u&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;已发布&lt;/a&gt;&lt;/u&gt;，新增原生支持 IPv6 网络，智能 DNS 解析、集成 Docker MCP Toolkit、增强 AI 相关功能等。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-b35f142c42d62e4321cd5c076947810288e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在网络功能方面，Docker Desktop 4.42 为满足多样化的企业网络需求，引入了原生 IPv6 网络支持，开发者可灵活选择 IPv4 / IPv6 双栈（默认）、IPv4 专用或 IPv6 专用模式。&lt;/p&gt; 
&lt;p&gt;新版本还新增智能 DNS 解析功能，能够检测主机的网络堆栈，并过滤不支持的 DNS 记录类型，有效减少 IPv4 或 IPv6 限制环境下的连接问题。&lt;/p&gt; 
&lt;p&gt;这些网络设置可在 Docker Desktop 的「Settings」 &amp;gt; 「Resources」 &amp;gt; 「Network」中调整，并支持团队集中管理和强制执行，从而提升复杂网络配置的可靠性。&lt;/p&gt; 
&lt;p&gt;在工具方面，Docker Desktop 4.42 集成 Docker MCP Toolkit，开发者无需额外安装，可以直接使用 GitHub、MongoDB 和 HashiCorp 等热门 MCP 服务器，并可将其连接至 Claude Desktop、Cursor 等客户端或 Docker 自家 AI 代理 Gordon。此外还新增 docker mcp 命令，支持通过命令行管理服务器、客户端及配置。&lt;/p&gt; 
&lt;p&gt;Docker 正致力于成为一个全面的 AI 解决方案，&lt;a href="https://www.oschina.net/news/340579/docker-model-runner-run-llms-natively"&gt;此前已内置 LLM 模型运行器&lt;/a&gt;，使得基于 llama.cpp 的服务器模型部署更加便捷。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-desktop-4-42-native-ipv6-built-in-mcp-and-better-model-packaging%2F" target="_blank"&gt;详情查看发布公告&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355998/docker-desktop-4-42-native-ipv6-built-in-mcp</guid>
      <pubDate>Sat, 10 May 2025 08:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>【视频】Solon Flow vs Drools - 业务规则应用对比</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#24292e; text-align:start"&gt;探索视频：&lt;/p&gt; 
&lt;p&gt;&lt;iframe height="400" scrolling="no" src="https://player.bilibili.com/player.html?isOutside=true&amp;amp;aid=114703174993573&amp;amp;bvid=BV1FfNjz1EzQ&amp;amp;cid=30560947818&amp;amp;p=1" style="box-sizing: border-box; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial; color: rgb(36, 41, 46); font-family: -apple-system, &amp;quot;system-ui&amp;quot;, &amp;quot;Segoe UI&amp;quot;, Helvetica, Arial, sans-serif, &amp;quot;Apple Color Emoji&amp;quot;, &amp;quot;Segoe UI Emoji&amp;quot;, &amp;quot;Segoe UI Symbol&amp;quot;; text-align: start; background-color: rgb(255, 255, 255);" width="700" referrerpolicy="no-referrer"&gt;&lt;/iframe&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/355985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/355985</guid>
      <pubDate>Sat, 10 May 2025 07:53:00 GMT</pubDate>
      <author>来源: 投稿</author>
    </item>
  </channel>
</rss>
