<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:40:35 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>字节 Seedream 4.0 图像创作模型正式发布</title>
      <description/>
      <link>https://www.oschina.net/news/371058</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371058</guid>
      <pubDate>Tue, 09 Sep 2025 02:38:32 GMT</pubDate>
    </item>
    <item>
      <title>知名 Android 第三方桌面 Nova Launcher 将停止维护</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;知名 Android 第三方桌面&lt;span&gt;启动器 Nova Launcher 创始人和原始开发者 Kevin Barry 宣布，他已经离开收购 Nova Launcher 的分析公司 Branch，并不再参与该项目。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1658" src="https://static.oschina.net/uploads/space/2025/0909/103239_Hnwx_2720166.png" width="1502" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://teslacoilapps.com/nova/solong.html&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据悉，Nova Launcher 由 Kevin Barry 带队开发，于 2022 年被 Branch 收购。当时，Branch 承诺不会将 Nova Launcher 变为订阅式付费、带有广告的普通 Android 桌面启动器。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d68adf6667956ed5f537c0b8b93ebbb0b93.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据 Kevin Barry 透露，其在过去几个月不断为 Nova Launcher 的开源进行付出。其表示，虽然 Branch 曾在收购 Nova Launcher 时承诺，其若离职，Nova Launcher 最终则会开源，但 Barry 现被要求停止开发 Nova Launcher 和终止进行开源工作。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371057</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371057</guid>
      <pubDate>Tue, 09 Sep 2025 02:35:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>阿里通义发布语音识别模型 Qwen3-ASR-Flash</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;通义千问系列最新的语音识别模型 Qwen3-ASR-Flash 已正式发布，它基于 Qwen3 基座模型，经海量多模态数据以及千万⼩时规模的 ASR（自动语音识别）数据训练构建而成。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101857_EGZg_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 实现了⾼精度⾼鲁棒性的语⾳识别性能，⽀持 11 种语⾔和多种⼝⾳。与众不同的是，Qwen3-ASR-Flash⽀持⽤户以任意格式提供⽂本上下⽂，从⽽获得定制化的 ASR 结果，同时还⽀持歌声识别。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0909/101903_kNR1_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img height="664" src="https://static.oschina.net/uploads/space/2025/0909/101933_MOCR_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="1395" src="https://static.oschina.net/uploads/space/2025/0909/101944_O6J2_2720166.png" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Qwen3-ASR-Flash 单模型支持多种语言、方言和口音的精准转录：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;中文：包括普通话以及四川话、闽南语、吴语、粤语等主要方言。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;英语：支持英式、美式及多种其他地区口音。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;其他支持语言：法语、德语、俄语、意大利语、西班牙语、葡萄牙语、日语、韩语和阿拉伯语。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Qwen3-ASR-Flash 的核心特性：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;领先的识别准确率：Qwen3-ASR-Flash 在多个中英文，多语种 benchmark 测试中表现最优。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;惊艳的歌声识别能力：支持歌唱识别,包括清唱与带 bgm 的整歌识别，实测错误率低于 8%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;定制化识别：用户可以以任意格式 (如词汇表、段落或完整文档) 提供背景文本，模型能智能利用该上下文识别并匹配命名实体和其他关键术语，输出定制化的识别结果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;语种识别与非人声拒识：模型能精确分辨语音的语种，自动过滤非语音片段，包括静音和背景噪声。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;鲁棒性：面对长难句、句中语言切换和重复词语等困难文本模式，以及在复杂的声学环境中，模型仍能保持高准确率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;体验方式：&lt;/p&gt; 
&lt;p&gt;ModelScope&lt;strong&gt;：&lt;/strong&gt;https://modelscope.cn/studios/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;HuggingFace:&amp;nbsp;https://huggingface.co/spaces/Qwen/Qwen3-ASR-Demo&lt;/p&gt; 
&lt;p&gt;阿里云百炼 API&lt;strong&gt;：&lt;/strong&gt;https://bailian.console.aliyun.com/?tab=doc#/doc/?type=model&amp;amp;url=2979031&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371054</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371054</guid>
      <pubDate>Tue, 09 Sep 2025 02:21:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Databricks 融资 10 亿美元，估值超 1000 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;Databricks &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.databricks.com%2Fcompany%2Fnewsroom%2Fpress-releases%2Fdatabricks-surpasses-4b-revenue-run-rate-exceeding-1b-ai-revenue" target="_blank"&gt;宣布&lt;/a&gt;即将完成 10 亿美元的 K 轮融资，对应估值超过 1000 亿美元。此轮融资由 Andreessen Horowitz、Insight Partners、MGX、Thrive Capital 和 WCM Investment Management 共同领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 表示，将利用这笔新资金加速其 AI 战略——扩展 Agent Bricks，推出全新 Lakebase 产品线，并推动全球增长。以及支持 Databricks 未来的 AI 收购，并深化 AI 研究。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="245" src="https://oscimg.oschina.net/oscnet/up-ba2a1094a2ce8345cb7359294aa377ea3d0.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;在公告中，Databricks 还透露了部分财务状况，披露其第二季度的年收入运行率超过 40 亿美元，同比增长 50%，并在过去 12 个月中实现了正自由现金流。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;该公司还表示，其人工智能产品的年营收运行率近期已超过 10 亿美元，净留存率超过 140%，目前有超过 650 家客户使用 Databricks 的产品，年收入超过 100 万美元。目前，共有超过 2 万家企业和组织在使用其软件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 联合创始人兼首席执行官 Ali Ghodsi 在公告中表示：「我们的团队正在构建企业未来几十年将依赖的数据和 AI 基础设施，从而取得这些成果。有了这笔新资金，我们将能够加快 Agent Bricks 的发展步伐，帮助各行各业的客户将其数据转化为生产级 AI 代理，并在创建新的 Lakebase 类别、为 AI 代理重塑数据库的过程中获得更大的发展动力。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;Databricks 还指出，在前两个季度中，该公司已与微软、谷歌云、Anthropic、SAP 和 Palantir 建立或扩大了合作伙伴关系。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/371049</link>
      <guid isPermaLink="false">https://www.oschina.net/news/371049</guid>
      <pubDate>Tue, 09 Sep 2025 02:08:32 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>🔥🔥造物分享：流浪地球 550W（MOSS）小智 AI 生态中枢</title>
      <description/>
      <link>https://www.oschina.net/ai-creation/details/2186</link>
      <guid isPermaLink="false">https://www.oschina.net/ai-creation/details/2186</guid>
      <pubDate>Tue, 09 Sep 2025 01:49:32 GMT</pubDate>
    </item>
    <item>
      <title>李彦宏颁发「百度最高奖」：心流团队获 100 万美元奖励</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;今日，百度创始人李彦宏在内部活动上为技术团队颁发「百度最高奖」，获奖团队得到 100 万美元奖励，合人民币超 700 万元。「百度最高奖」已历经 15 届，语音识别、深度学习平台、大模型等大量 AI 技术均曾获奖，奖金总金额将近 4 亿元人民币。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-322339010570111171fc427256170f32b22.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据了解，「百度最高奖」于 2010 年 7 月设立，鼓励「小团队做出大事业」，是百度公司最高级别的奖项，给予每个获奖团队 100 万美元奖励。奖项评选需满足三项条件：项目意义重大；成果远超预期；团队足够小，必须是小于等于 10 人。&lt;/p&gt; 
&lt;p&gt;本次百度最高奖的获奖团队为「心流」团队。据介绍，「心流」团队率先实现了端到端的多模态内容理解与序列生成技术。李彦宏在颁奖时表示，到今天，模型发展已经非常接近临界点，很快就会有各种有价值的应用被创造出来，「我们生活在一个非常令人兴奋、非常令人期待的环境当中」。&lt;/p&gt; 
&lt;p&gt;李彦宏称，百度搜索已有近 70% 结果含有 AI 生成内容，且通过「百看」带来富媒体形式，是全球所有的搜索引擎当中改造最激进的，这也代表搜索引擎的未来。&lt;/p&gt; 
&lt;p&gt;同时，百度慧博星数字人已达到「以假乱真」的地步，「很多人看不出是数字人还是真人」；百度萝卜快跑已覆盖全球 16 座城市，代表着最新一代的无人驾驶技术。&lt;/p&gt; 
&lt;p&gt;颁奖典礼现场，李彦宏在谈及 AI 发展时指出，「AI 大模型发展到今天，其实已接近了临界点，很快就会有各种各样非常有价值的应用能够创造出来，我们正生活在一个非常令人兴奋、非常令人期待的市场环境当中。」&lt;/p&gt; 
&lt;p&gt;「我们所从事的每一项工作都代表着未来，我也希望大家和我一起去期待，去迎接、去奋斗出一个创新在 C 位的社会。」李彦宏表示。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370987</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370987</guid>
      <pubDate>Sat, 06 Sep 2025 11:28:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>「AI 教父」辛顿竟然被前女友竟用 ChatGPT 提分手</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;近日，被誉为「AI 教父」 的 Geoffrey Hinton 在接受采访时&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.ft.com%2Fcontent%2F31feb335-4945-475e-baaa-3b880d9cf8ce" target="_blank"&gt;透露&lt;/a&gt;，他的前女友曾用 ChatGPT 给他发送分手信息。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1776" src="https://static.oschina.net/uploads/space/2025/0908/192243_YVS9_2720166.jpg" width="1280" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Hinton 作为人工智能领域的先驱，其在 1980 年代的工作为机器学习和人工神经网络奠定了基础，去年还获得了诺贝尔物理学奖。&lt;/p&gt; 
&lt;p&gt;这位 AI 领域的权威人士却未能预料到自己会被 AI 工具所「伤害」，他的前女友用 ChatGPT 告诉他他有多糟糕，让他非常惊讶。「她用聊天机器人说出我的缺点，再传给我。」不过辛顿自认没有聊天机器人说的那么糟，所以也没有太难过。&lt;/p&gt; 
&lt;p&gt;事实上，让像 ChatGPT 这样的聊天机器人撰写分手短信等似乎并不是什么新鲜事，毕竟越来越多的人就一系列问题向 AI 咨询。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370985</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370985</guid>
      <pubDate>Sat, 06 Sep 2025 11:23:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Agent Client Protocol —— 代码编辑器与 Agent 的通信协议</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;Agent Client Protocol (ACP) 是用于连接代码编辑器和 Agent 的协议，对代码编辑器（用于查看和编辑源代码的交互式程序）与编码 Agent（使用生成式 AI 自主修改代码的程序）之间的通信进行了标准化。&lt;/p&gt;

&lt;p&gt;这一协议让开发者可以在编辑器中自由接入任意第三方智能体（Agent），无需依赖官方内置工具。其理念类似于语言服务器协议（LSP），通过解耦编辑器与 Agent 的交互方式，提供更灵活的扩展能力。&lt;/p&gt;

&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-2f621ad18024ec580d997b820ea9139346e.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

&lt;p&gt;ACP 协议已经以 Apache 开源许可证发布，任何开发者都可基于它集成自己的 AI Agent。&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/agent-client-protocol</link>
      <guid isPermaLink="false">https://www.oschina.net/p/agent-client-protocol</guid>
      <pubDate>Sat, 06 Sep 2025 11:18:00 GMT</pubDate>
    </item>
    <item>
      <title>商汤日日新为 Claude API 用户提供「搬家」大礼包</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;9 月 5 日，Anthropic 宣布将禁止中资控股超过 50% 的公司使用 Claude 服务，并限制企业通过海外云服务、第三方平台等方式间接使用。&lt;/p&gt; 
&lt;p&gt;即日起，商汤日日新大模型 SenseNova 将为 Claude 用户提供「搬家」服务，帮助客户继续享受高质量的模型能力和服务。&lt;/p&gt; 
&lt;p&gt;相关模型详情可访问 platform.sensenova.cn 注册。&lt;/p&gt; 
&lt;p&gt;商汤将为从 Claude 迁移到「日日新」的新用户赠送 5000 万 Tokens 体验包；同时为用户提供专属搬家顾问，提供迁移系列培训，让新用户入驻新家舒适顺利。相关模型详情可访问 platform.sensenova.cn 注册。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/185753_qsE0_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;商汤还提供最新交互模型——日日新 SenseNova V6.5 Omni API 的免费接入测试。用户也可在应用商店下载「商量 APP」免费体验！&lt;/p&gt; 
&lt;p&gt;另外，针对用户对高质量的编程和 Agent 工具的需求，商汤小浣熊还将提供 300,000 元会员权益，所有用户均可扫描文末二维码领取。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370978</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370978</guid>
      <pubDate>Sat, 06 Sep 2025 10:58:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达推出通用深度研究（UDR）系统</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;英伟达&lt;span&gt;最新&lt;/span&gt;发布另外一个通用深度研究（UDR）系统，目前仍处于原型阶段。该系统不仅可以与任何大语言模型 (LLM) 兼容，更为用户提供了高度定制的深度研究策略，彻底改变了以往研究智能体的工作方式。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据英伟达的&lt;span&gt;最新&lt;/span&gt;论文，UDR 系统的核心优势在于其极强的灵活性。过去，深度研究智能体往往依赖硬编码的方式，用户只能使用固定的工具和策略进行研究，无法进行个性化调整。而 UDR 系统的推出，意味着用户可以随心所欲地创建、编辑和优化自己的研究策略，甚至无需进行额外的模型训练。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="351" src="https://oscimg.oschina.net/oscnet/up-7461c3da8a2ceb3b17c20d0c5f84c7d2fba.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;UDR 系统配备了一个用户友好的界面，方便用户输入研究提示，随时更新进度并查看最终报告。与传统的对话式 LLM 不同，UDR 能够在研究过程中持续向用户反馈进展，极大提升了研究效率。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;值得一提的是，UDR 系统在设计上将研究逻辑与语言模型解耦，使开发者能够灵活选择&lt;span&gt;最先&lt;/span&gt;进的 AI 模型，并将其与量身定制的研究方案结合使用。这种创新的组合方式，让用户能够创造出更强大、更具适应性的深度研究工具。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管 UDR 系统具有诸多优点，但仍存在一些需要改进的地方。系统的准确性依赖于底层 AI 模型生成代码的质量，同时用户设计的研究策略必须合理可行，否则可能导致生成的报告质量低下。此外，当前版本在执行过程中缺乏用户干预的能力，所有决策都需在研究开始前预设，限制了灵活性。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;研究人员已提出了进一步的改进方案，包括提供可修改的策略库和更灵活的用户控制功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370976</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370976</guid>
      <pubDate>Sat, 06 Sep 2025 10:39:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>rainfrog - 命令行数据库工具</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                            &lt;p&gt;&lt;span style="background-color:#ffffff; color:#1f2328"&gt;Rainfrog 的目标是提供一个轻量级的、基于终端的数据库交互工具。该项目目前处于测试阶段。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;特性：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过类似 vim 的键绑定和鼠标控制实现高效导航&lt;/li&gt;
&lt;li&gt;具有关键字高亮显示、会话历史记录和收藏夹的查询编辑器&lt;/li&gt;
&lt;li&gt;快速复制数据、过滤表以及在模式之间切换&lt;/li&gt;
&lt;li&gt;查看表元数据和属性的快捷方式&lt;/li&gt;
&lt;li&gt;跨平台（macOS、linux、windows、android 通过 termux）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt="" height="278" src="https://static.oschina.net/uploads/space/2025/0905/115915_L0YY_4252687.gif" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
      <link>https://www.oschina.net/p/rainfrog</link>
      <guid isPermaLink="false">https://www.oschina.net/p/rainfrog</guid>
      <pubDate>Sat, 06 Sep 2025 10:11:00 GMT</pubDate>
    </item>
    <item>
      <title>腾讯混元翻译模型 Hunyuan-MT-7B 登顶开源热榜</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F19W9SEUxq7nuYQvVJz8faA" target="_blank"&gt;宣布&lt;/a&gt;，混元翻译模型 Hunyuan-MT-7B 登顶 Hugging Face 模型趋势榜第一位。官方表示，该模型和混元世界模型家族最新成员 HunyunWorld-Voyager 一起，拿下前三中的两席。&lt;/p&gt; 
&lt;p&gt;Hunyuan-MT-7B 于 9 月 1 日开源，其总参数量仅 7B，支持 33 个语种、5 种民汉语言/方言互译，是一个能力全面的轻量级翻译模型。&lt;/p&gt; 
&lt;p&gt;&lt;img height="1506" src="https://static.oschina.net/uploads/space/2025/0908/175938_Dkn8_2720166.png" width="1216" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;在 8 月底结束的国际计算语言学协会（ACL）WMT2025 比赛中，Hunyuan-MT-7B（参赛名称：Shy-hunyuan-MT）拿下了全部 31 个语种比赛中的 30 个第 1 名，处于绝对领先地位。&lt;/p&gt; 
&lt;p&gt;这 31 个语种除了中文、英语、日语等常见语种，也包含捷克语、马拉地语、爱沙尼亚语、冰岛语等小语种。&lt;/p&gt; 
&lt;p&gt;腾讯混元表示，在业界常用的翻译能力测评数据集 Flores200 上，腾讯混元 Hunyuan-MT-7B 模型也有卓越的效果表现，明显领先于同尺寸模型，与超大尺寸模型效果对比也不逊色。&lt;/p&gt; 
&lt;p&gt;针对翻译场景，腾讯混元提出了一个完整的翻译模型训练范式，覆盖从预训练、到 CPT 再到监督调参、翻译强化和集成强化全链条，使得模型的翻译效果达到业界最优。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370969</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370969</guid>
      <pubDate>Sat, 06 Sep 2025 10:01:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>上海发布 AI 广告扶持政策：最高 500 万补贴大模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;上海市近日发布了《上海市支持人工智能赋能广告业创新发展的若干措施》，旨在通过一系列具体的扶持政策，推动人工智能技术在广告行业的深度应用和发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;核心扶持措施概览&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;新政策的核心在于「AI+数字广告」生产要素的强化支持，具体措施包括:&lt;/p&gt; 
&lt;ul style="margin-left:0; margin-right:0"&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;大模型私有化部署补贴:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;对于采用第三方大模型进行私有化部署，并将其应用于广告垂类领域的数字广告企业，上海市将提供&lt;span&gt;最高&lt;/span&gt;可达核定合同额&lt;strong&gt;50%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 万元&lt;/strong&gt;的补贴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;语料研发与应用补贴:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;鼓励企业购买非关联方的语料进行广告垂类应用和「智能体」等研发。对于此类投入，企业可获得&lt;span&gt;最高&lt;/span&gt;核定合同额&lt;strong&gt;30%&lt;/strong&gt;，&lt;span&gt;最高&lt;/span&gt;&lt;strong&gt;500 万元&lt;/strong&gt;的补贴。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style="margin-left:0; margin-right:0"&gt;&lt;strong&gt;算力租用支持:&lt;/strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;此外，有条件的区政府还将对租用算力的数字广告企业提供支持，按实际投入的&lt;strong&gt;30%&lt;strong&gt;比例，给予单个主体年度&lt;span&gt;最高&lt;/span&gt;&lt;/strong&gt;2000 万元&lt;/strong&gt;的支持。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这一系列政策的出台，不仅体现了上海市抢占「AI+广告」产业制高点的决心，也旨在通过真金白银的投入，降低企业在技术研发和部署上的成本，激发市场的创新活力。通过支持大模型私有化部署、语料研发和算力投入，上海正着力打造一个集技术、数据和算力于一体的完整 AI 广告生态系统。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这些措施预计将吸引更多 AI 技术公司和传统广告企业在上海落地和发展，加速人工智能在广告创意、内容生成、精准投放等环节的深度融合，从而推动整个广告行业的数字化和智能化转型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370959</guid>
      <pubDate>Sat, 06 Sep 2025 09:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>HuggingFace 开源 FinePDFs 与 FineVision 数据集</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Hugging Face 开源了两个大规模数据集 FinePDFs 和 FineVision，前者是目前最大的公开 PDF 语料库，后者则专为视觉-语言模型训练设计，旨在显著提升开源模型的能力。&lt;/p&gt; 
&lt;p&gt;https://huggingface.co/datasets/HuggingFaceFW/finepdfs&lt;br&gt; https://huggingface.co/datasets/HuggingFaceM4/FineVision&lt;/p&gt; 
&lt;p&gt;FinePDFs 是目前最大的公开 PDF 语料库，完全由 PDF 文件构建，包含约 3 万亿 tokens，覆盖 4.75 亿份文档、1733 种语言，数据量 3.65TB。&lt;/p&gt; 
&lt;p&gt;语料来自 105 个 CommonCrawl 快照（2013 夏—2025 年 2 月），经 datatrove 库去重、过滤与 PII 匿名化，采用 ODC-By 1.0 许可证。文档平均长度接近 HTML 数据集的两倍，长于 10 万，字符的样本显著，可用于提升开源 LLM 的长上下文能力。&lt;/p&gt; 
&lt;p&gt;数据集已按语言-脚本对划分，978 种语言超 100 万 tokens，66 种语言超 10 亿 tokens。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-7cbae8687f50206187cf62b7ba1d65da7be.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;FineVision 面向视觉-语言模型训练，整合 200 余个来源，含 1730 万张图像、2430 万样本、8890 万轮对话、95 亿回答 tokens，支持 GUI 导航、指向、计数等新能力。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-945829421e543e2f159fb676f6f537bbadb.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;官方称在 10 项基准上带来 20% 以上提升，可显著增强开源 VLM 性能。数据已转为 Parquet，总量约 4.48 TB，支持流式加载。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370951</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370951</guid>
      <pubDate>Sat, 06 Sep 2025 09:15:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>宇树科技冲刺 IPO 将影响机器人产业格局</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;近日，国内机器人领域头部企业宇树科技宣布，预计在 2025 年 10 月份至 12 月份期间向证券交易所提交 IPO 申请文件。这一消息在科技界和资本市场引发了广泛关注。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;作为人形机器人商业化落地的标杆企业，宇树科技冲刺 IPO，有望成为影响机器人产业格局的关键节点。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;首先，宇树科技冲刺 IPO，有望向市场证明其技术商业化的可行性。公司 2024 年营收突破 10 亿元，且连续 4 年实现盈利，其中，2024 年四足机器人贡献了 65% 的收入，验证了消费级场景的变现能力。若成功上市，通过完整披露研发数据、客户结构及成本模型，宇树科技将进一步证明其技术护城河并非只是「实验室成果」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;机器人企业不仅要注重技术研发，还要重视商业化落地。通过拓展应用场景，开发满足市场需求的产品，实现技术的商业价值转化，才能获得稳定的收入，增强资本吸引力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;其次，宇树科技冲刺 IPO，将成为机器人产业链价值重估的催化剂，持续推动上游精密制造、中游系统集成、下游场景运营的全链条资本化，形成「技术—资本—产业」正循环，从而进一步优化产业链。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;目前，宇树科技已经实现电机、减速器、控制器等核心部件全栈自研，国产化率超 90%。业内预计，宇树科技或将募资重点投向高扭矩密度电机、轻量化材料等领域，以打破机器人规模化应用的成本瓶颈。上市后，宇树科技势必会通过融资扩大产能，相关供应链企业有望迎来订单放量的黄金机遇，上下游协同的良性生态有望加速形成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;最后，宇树科技选择 IPO，本质上是资本效率与技术周期的精准匹配。2025 年 6 月份，宇树科技完成 C 轮融资，投后估值已达 120 亿元。该轮融资由中国移动旗下基金、腾讯、锦秋基金、阿里巴巴、蚂蚁集团和吉利资本共同领投。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;宇树科技冲刺 IPO，是机器人产业加速资本化的缩影。相信在资本市场与机器人产业的「双向奔赴」中，中国机器人企业将大幅提升竞争力。（证券日报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370948</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370948</guid>
      <pubDate>Sat, 06 Sep 2025 09:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>未来可能有高达 50% 的入门级工作将被 AI 取代</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;随着人工智能（AI）的迅速发展，许多公司正在经历前所未有的变革。曾经的职场成功故事，如 Hewlett Packard Enterprise 的首席执行官安东尼・内里 (Antonio Neri) 从客服代理晋升为 CEO，正在逐渐被 AI 的兴起所取代。分析师预测，未来可能有高达 50% 的入门级工作将被 AI 取代，这意味着许多刚刚步入职场的大学毕业生将面临前所未有的挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在一项针对公共科技公司和成长中的风险投资企业的研究中，数据显示，从 2019 年到 2024 年，具有不到一年工作经验的求职者的就业机会下降了 50%。这一趋势影响到了销售、市场营销、工程、招聘、运营、设计、财务和法律等各个核心职能。这种变化不仅影响了求职者，也让企业面临重新培养人才的压力。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;尽管如此，行业专家指出，这种失去入门级岗位的情况可能促使组织内部的人才培养模式发生改变。随着公司的结构变得更加扁平化，入门级岗位可能会转变为更高要求的技能角色，要求求职者在进入职场前具备更多的能力。虽然对于即将毕业的学生来说，这意味着他们需要自行掌握这些技能，但也可能成为他们在竞争激烈的求职市场中脱颖而出的优势。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;各大高校也在积极调整课程，旨在为学生提供与 AI 相关的技能培训。虽然技术进步可能在短期内对就业率产生影响，但历史上技术革新在长期内并未导致大规模的失业。专家认为，当前大学毕业生面临的挑战，可能在未来几年内影响他们的职业发展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;然而，尽管有许多未知数，许多经济学家认为 AI 对劳动市场的长期影响仍然具有高度的不确定性，企业和社会将需要时间来适应这一变化。随着技术的不断进步和 AI 的普及，职场的未来可能会迎来全新的模式，而不仅仅是对现有职场阶梯的替代。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370944</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370944</guid>
      <pubDate>Sat, 06 Sep 2025 08:47:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>英伟达收购 AI 编程初创公司 Solver</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.theinformation.com%2Fbriefings%2Fnvidia-acquires-coding-startup-solver" target="_blank"&gt;据 The Information 报道&lt;/a&gt;，英伟达最近完成了对 AI 编程公司 Solver 的收购，进一步强化其在 AI 全栈生态的布局。&lt;/p&gt; 
&lt;p&gt;Solver 成立于 2022 年，前身为 Laredo Labs，专注于 AI Coding Agent，其产品能通过自然语言指令管理完整代码库（如生成、测试、修复代码），而非仅代码补全。公司曾获 800 万美元融资，创始团队包括前 Siri 和三星 Viv Labs 核心成员。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/161953_FkOn_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Solver 的技术突破在于学习「超过一亿个软件项目的开发历史」，理解代码演进逻辑，可执行复杂任务（如重构模块、修复系统性漏洞）。其 API 支持多语言（Python、JavaScript 等），并与主流开发工具无缝集成。&lt;/p&gt; 
&lt;p&gt;此次收购是英伟达 2024-2025 年系列收购的关键一环，旨在构建「硬件+软件+云服务」全栈生态。Solver 将整合至英伟达开发者工具链（如 CUDA、NVIDIA AI Enterprise），降低 AI 应用开发门槛，反向驱动 GPU 需求增长。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370938/nvidia-acquires-coding-startup-solver</guid>
      <pubDate>Sat, 06 Sep 2025 08:20:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenAI 重组 ChatGPT 「模型行为团队」</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 内部邮件确认，原「模型行为团队」（Model Behavior）整体并入「后训练团队」（Post Training），直接向该团队负责人 Max Schwarzer 汇报。此举旨在把 AI 个性、安全与用户体验研究更深地嵌入核心模型开发流程，为 GPT-5 后续版本提供更快的迭代支持。&lt;/p&gt; 
&lt;p&gt;该团队原有 14 人，长期负责减少谄媚、平衡政治偏见、定义聊天语气等「人格化」工作。与此同时，模型行为团队创始负责人 Joanne Jang 宣布转岗，启动新项目 OAI Labs，探索超越传统聊天窗口的人机协作界面。Jang 称，新实验室将「让 AI 成为思考、创作、游戏、学习和连接的工具」。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160802_ml0W_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0908/160900_9Cth_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;业内分析指出，此次重组反映出 OpenAI 对「模型性格」商业化影响的重视：用户反馈 GPT-5「过于冷淡」或「过度迎合」后，公司已临时开放旧模型访问权限，并加速个性调优。同期发表的 OpenAI 研究论文也警告，行业惯用的「应试型」评估可能鼓励模型幻觉，未来需在评分机制中引入「不确定性诚实」指标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370934</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370934</guid>
      <pubDate>Sat, 06 Sep 2025 08:10:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Tilde AI 发布开源 TildeOpen LLM</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;Latvian 语言技术公司 Tilde 发布了 TildeOpen LLM，这是一个开源的基础大语言模型（LLM），旨在支持欧洲语言，特别是那些较少被代表的国家和地区语言。这一举措标志着欧盟在语言公平和数字主权方面迈出了重要的一步。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="290" src="https://oscimg.oschina.net/oscnet/up-a3afc0c462ebfde5158ba6a9fda49510c9d.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen LLM 是一个拥有 300 亿参数的稠密解码器模型，采用了 CC-BY-4.0 的宽松许可证，能够支持从拉脱维亚语、立陶宛语到乌克兰语、土耳其语等多种语言。该模型的训练是在欧洲的&lt;span&gt;超级&lt;/span&gt;计算机 LUMI（芬兰）和 JUPITER 上进行的，使用了欧盟委员会的大型人工智能大奖挑战赛所提供的 200 万 GPU 小时的计算资源。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在技术细节方面，TildeOpen LLM 通过受 EleutherAI 启发的 GPT-NeoX 脚本进行训练，共进行了 45 万次更新，使用了约 2 万亿个令牌。其训练过程包含三阶段采样：首先在语言间均匀分布，其次是对高数据量语言的自然分布进行增强，最后再进行均匀的扫查以确保平衡。模型的超参数包括 60 层、嵌入维度 6144、48 个注意力头、8192-token 的上下文窗口，以及使用 SwiGLU 激活、RoPE 位置编码和 RMSNorm 层规范化。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在语言公平和数据主权方面，传统的主流模型往往侧重于英语和其他主要语言，导致在处理波罗的海、斯拉夫及其他较小的欧洲语言时表现不佳，常常出现语法错误和奇怪的措辞。而 TildeOpen 通过引入 「公平的标记器」，使得不同语言的文本以相似方式进行表示，从而减少标记数量，提高较少代表语言的推理效率。此外，组织可以选择在本地数据中心或符合欧盟要求的安全云中自我托管，确保遵循 GDPR 及其他数据保护法规，从而解决了与美国或亚洲托管模型相关的主权问题。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;TildeOpen 作为基础模型，预计会推出更多专门化版本，例如经过指令调优的翻译模型，这将进一步增强其功能。拉脱维亚通过 Tilde 的努力，期望在全球科技领域占据一席之地，同时致力于保护语言多样性。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/370933</link>
      <guid isPermaLink="false">https://www.oschina.net/news/370933</guid>
      <pubDate>Sat, 06 Sep 2025 08:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>合理选择任务调度的路由策略，可以帮助降本 50%</title>
      <description>&lt;div class="content"&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：黄晓萌（学仁）&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="225" src="https://oscimg.oschina.net/oscnet/up-95c58fbed31f7c7be0c1d4fb9dcd324f094.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h2_1"&gt;&lt;/span&gt; 
&lt;h2&gt;概述&lt;/h2&gt; 
&lt;p&gt;有许多的业务场景需要用到短周期的任务，比如：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;订单异步处理：每分钟扫描超时未支付的订单进行订单处理。&lt;/li&gt; 
 &lt;li&gt;风险监控：每分钟扫描 metrics 指标，发现异常进行报警。&lt;/li&gt; 
 &lt;li&gt;数据同步：每天晚上同步库存、门店信息。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;任务调度系统负责管理这些短周期的任务，通过用户设置的调度时间，周期性的把任务分发给执行器执行。每次任务要分发给哪个执行器执行，就是由路由策略决定的。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-bfa179d2d832985259fd56c4cb3164f3350.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;不同任务处理不同的业务逻辑，有些执行时间长，有些执行时间短，有些消耗资源多，有些消耗资源少。如果选择的路由策略不合适，可能会导致集群中执行器负载分配不平均，资源利用率上不去，成本上升，甚至产生稳定性故障。&lt;/p&gt; 
&lt;span id="OSC_h2_2"&gt;&lt;/span&gt; 
&lt;h2&gt;轮询（Round Robin）&lt;/h2&gt; 
&lt;p&gt;轮询（Round Robin）路由策略是一种简单且常见的负载均衡方法，其核心原理是按照顺序将请求或任务依次分发到后端节点上，从而确保任务的平均分布，避免资源过度集中在某一节点上。具体实现方式通常是维护一个计数器，记录当前分配的节点索引。分发请求时，该索引递增并对节点总数取模，从而实现循环分配。在任务调度系统中，分为任务级别轮询和应用级别轮询。&lt;/p&gt; 
&lt;span id="OSC_h3_3"&gt;&lt;/span&gt; 
&lt;h3&gt;任务级别轮询&lt;/h3&gt; 
&lt;p&gt;代表产品是 XXLJOB &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;1]&lt;/strong&gt; ，为每个任务都维护了一个计数器。比如有 ABC 三个执行器。每个任务调度的时候都会按照 A-&amp;gt;B-&amp;gt;C-&amp;gt;A 这个顺序轮询机器。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;如果所有任务的调度时间都一致（比如每小时执行一次），会导致所有任务每次执行都落在同一台后端节点上，负载严重不均衡。为了解决这个问题，XXL-JOB 初始化每个任务计数器的时候，做了随机，可以大大降低该问题的概率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;pre style="margin-left:0; margin-right:0; text-align:justify"&gt;&lt;code&gt;&lt;span&gt;AtomicInteger count = routeCountEachJob.&lt;span style="color:#ca7d37"&gt;get&lt;/span&gt;(jobId);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&lt;span style="color:#ca7d37"&gt;if&lt;/span&gt;&amp;nbsp;(count ==&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;null&lt;/span&gt;&amp;nbsp;|| count.&lt;span style="color:#ca7d37"&gt;get&lt;/span&gt;() &amp;gt;&amp;nbsp;&lt;span style="color:#0e9ce5"&gt;1000000&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;em&gt;// 初始化时主动 Random 一次，缓解首次压力&lt;/em&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; count =&amp;nbsp;&lt;span style="color:#ca7d37"&gt;new&lt;/span&gt;&amp;nbsp;AtomicInteger(&lt;span style="color:#ca7d37"&gt;new&lt;/span&gt;&amp;nbsp;Random().nextInt(&lt;span style="color:#0e9ce5"&gt;100&lt;/span&gt;));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&amp;nbsp;&lt;span style="color:#ca7d37"&gt;else&lt;/span&gt;&amp;nbsp;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;em&gt;// count++&lt;/em&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; count.addAndGet(&lt;span style="color:#0e9ce5"&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果任务的调度频率不一致，因为每个任务都按照自己计数器轮询，也有可能在某个周期，大部分任务都调度到同一个执行器上，导致负载不均衡。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h3_4"&gt;&lt;/span&gt; 
&lt;h3&gt;应用级别轮询&lt;/h3&gt; 
&lt;p&gt;整个应用下所有任务共享同一个计数器，每个任务调度的时候，都会让计数器+1。该算法可以保证所有执行器接收到的任务次数是平均的。如果所有任务负载和执行时间差不多，是负载均衡的，但是如果有大任务和小任务并存，情况又不一样了。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4d9dff721251ff1fbb2639b630c2867d23c.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;有 ABC 三个执行器，job1~job6 一共 6 个任务需要依次调度，其中 job1 和 job4 是大任务。&lt;/li&gt; 
 &lt;li&gt;job1 调度到 A 节点，job2 调度到 B 节点，job3 调度到 C 节点，job4 调度到 A 节点，job5 调度到 B 节点，job6 调度到 C 节点。&lt;/li&gt; 
 &lt;li&gt;job1 和 job4 这 2 个大任务，每次都调度到 A 节点，导致 A 节点负载比其他节点高。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h3_5"&gt;&lt;/span&gt; 
&lt;h3&gt;阶段总结&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果所有任务负载和执行时间差不多，建议选择应用级别轮询。&lt;/li&gt; 
 &lt;li&gt;如果有大任务和小任务存在，这两种算法都有可能导致负载不均衡，建议给大任务配置任务级轮询，防止每次都落到同一台节点上。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_6"&gt;&lt;/span&gt; 
&lt;h2&gt;随机&lt;/h2&gt; 
&lt;p&gt;随机路由策略是一种简单的负载均衡算法，它通过随机选择一个后端服务器来处理每个请求，来达到负载均衡的目的。在任务调度系统中，任务每次调度的时候，随机选一个执行器执行。&lt;/p&gt; 
&lt;p&gt;随机路由策略由于算法完全依赖随机数生成器，负载均衡全凭运气，如果拉长时间区间（比如看一整天的调度情况）看可能是负载均衡的，但是可能存在短时间负载不均的问题（某些服务器在一定时间段内被选中的概率较高）。&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;最近最少使用（LFU）&lt;/h2&gt; 
&lt;p&gt;最近最少使用（LFU，Least Frequently Used）是一种基于访问频率的缓存淘汰算法，主要用于内存管理和缓存系统中。其实现机制是为每个数据项维护一个访问计数器，数据被访问时计数器加 1，当需要淘汰数据时，选择计数器值最小的数据项。&lt;/p&gt; 
&lt;p&gt;在任务调度系统中，可以统计执行器的调度次数，优先选择最近使用次数最少的执行器进行任务调度，从而达到负载均衡的目的。如果所有任务都配置成 LFU 路由策略，该算法最终使用效果，和轮询算法是差不多的，算法还复杂，没有太大必要。如果集群中的任务配置了多种路由策略，不同执行器调度次数不一样，出现了负载不均衡的情况，给新任务配置 LFU 算法，一定能调度到调度次数最少的执行器上，才能真正发挥它的作用。&lt;/p&gt; 
&lt;p&gt;开源 XXLJOB 具体实现上，使用的是任务级别的 LFU，最终使用效果和任务级别轮询一致。&lt;/p&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;最近最久未使用（LRU）&lt;/h2&gt; 
&lt;p&gt;最近最久未使用 (LRU,Least Recently Used) 是一种基于访问时间的缓存淘汰算法，主要用于管理有限缓存空间内的内存数据，当缓存已满时，依据数据最近使用时间，优先移除最近最久未使用的数据。&lt;/p&gt; 
&lt;p&gt;在任务调度系统中，可以统计执行器的调度时间，优先选择最久未调度的执行器进行任务调度，从而达到负载均衡的目的。因为每次调度的时候，也会更新执行器调度次数，所以该算法最终使用效果，和 LFU 是差不多的。&lt;/p&gt; 
&lt;p&gt;开源 XXLJOB 具体实现上，使用的是任务级别的 LRU，最终使用效果和任务级别轮询一致。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;一致性哈希&lt;/h2&gt; 
&lt;p&gt;有些业务场景，需要任务每次执行在固定的机器上，比如执行器上有缓存，可以较少下游数据加载、加快任务处理速度。最直接的想法就是使用哈希算法，通过任务 ID（JobId）和执行器数量取 mod，把任务调度到固定的机器上。但是如果某个执行器挂掉了，或者执行器扩容的时候，执行器数量发生了变更，会导致所有任务重新哈希到了不同的机器上，所有缓存全部失效，可能会导致后端流量一下子突增。&lt;/p&gt; 
&lt;p&gt;XXLJOB 提供了一致性哈希路由算法，可以保证执行器挂掉或者扩容的时候，大部分任务调度的执行器不变。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;一致性哈希算法将 2^32 划分为一个逻辑环，其中每个执行器节点根据哈希值被映射到环上的某个位置。任务通过 JobId 做哈希也映射到环上，然后顺时针找到最近的执行器，即为目标执行器。如下图所示，job1 固定调度到执行器 A，job2 和 job3 固定调度到执行器 B，job4 固定调度到执行器 C：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0ad01a71277a9f227ced3b876fa4a2360dd.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;如果添加一个执行器 D，通过哈希值映射到了 job2 和 job3 中。如下图所示，job2 会调度到执行器 D 上，其他任务调度的机器保持不变：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-19e2de7321e73d275cb09c27e427f7a4793.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;如果执行器 C 突然挂掉了，如下图所示，job4 会调度到执行器 A 上，其他任务调度的机器保持不变：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-49f2dd8255ad7f43faeb56e5e0a37506e9f.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如果执行器节点不多，直接映射到哈希环上的时候，有可能无法平均分布，导致任务分配不均。为了解决这个问题，可以引入虚拟节点（XXLJOB 引入了 100 个虚拟节点），将虚拟节点平均分布在哈希环上，然后物理节点映射虚拟节点。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0af27b26f0bd8673df6d331804136865584.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，一共有 3 个执行器 ABC，每个执行器分配 4 个虚拟节点，保证所有虚拟节点平均分布在哈希环上，这样所有任务调度就基本上负载均衡了。&lt;/p&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;负载最低路由策略&lt;/h2&gt; 
&lt;p&gt;上面提到的路由策略都没法解决一个问题，就是应用下同时存在大任务和小任务，导致执行器负载不均衡。那么我们是否可以采集所有执行器的负载，每次调度的时候按照负载最低优先调度呢？确实有些调度系统是这样做的，代表产品是 Kubernets &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;2]&lt;/strong&gt; 。Kubernetes 使用 kube-scheduler 进行调度，本质上是把 Pod 调度到合适的 Node 上，默认策略就是调度到负载最低的 Node 上。在容器服务中，每个 Pod 都会预制占用 cpu 和内存，kube-scheduler 每调度一个 Pod，就能实时更新所有 Node 的负载，该算法没有问题。&lt;/p&gt; 
&lt;p&gt;但是在传统的任务调度系统中（比如 XXLJOB），一般都是通过线程运行任务的，没法提前知道每个任务会占用多少资源。任务调度到执行器上，也不是马上导致执行节点负载上升，通常会有滞后性。甚至有些逻辑复杂的任务，可能好几分钟后才会有大量的 IO 操作，导致该执行节点好几分钟后才能明显负载上升。举个例子，有 AB 两个执行节点：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A 节点上当前有 1 个任务在运行，A 节点负载 20%，B 节点当前没有任务运行，负载 0%。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-be10f131d25815e10c703a6b56b4c79afaf.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;这个时候有 job2~job5 一共 4 个任务要调度，都选择了当时负载最低的执行器 B。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-4c2a38d0bbec16b75d051f38e62fe5263d3.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;4 个任务都发送到执行器 B 后，过了一会，执行器 B 负载上升到 100%，执行器 A 还是 5%，导致负载不均衡。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_11"&gt;&lt;/span&gt; 
&lt;h2&gt;任务权重路由策略&lt;/h2&gt; 
&lt;p&gt;有没有办法可以像 kube-scheduler 一样，调度的时候就预算每个执行节点的负载呢？因为定时任务都是周期性运行的，每次执行的代码或者脚本是固定的，通过业务逻辑或者历史执行时间，我们其实是知道哪些是大任务哪些是小任务的。每次任务调度的时候，我们只要知道当前各个执行器上运行了多少个大任务多少个小任务，就能把当前这个任务分发到最合适的执行器上。&lt;/p&gt; 
&lt;p&gt;MSE-XXLJOB &lt;strong&gt;[&lt;/strong&gt; &lt;strong&gt;3]&lt;/strong&gt; 设计并实现了任务权重路由策略，每个任务都可以用户自定义权重（int 值），交互流程如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0d9160df2b04280c0c7c1f1887c088ecc37.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;如上图所示，&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scheduler 调度器开始调度任务。&lt;/li&gt; 
 &lt;li&gt;RouteManger 负责路由策略，如果是任务权重路由策略，去 WorkerManger 里寻找当前权重最小的执行器，并更新该执行器的权重（+当前任务的权重）。&lt;/li&gt; 
 &lt;li&gt;RouteManger 把任务分发给权重最小的执行器执行任务。&lt;/li&gt; 
 &lt;li&gt;执行器运行完任务，更新 WorkerManger，把该执行器的权重减去该任务的权重。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;下面以一个详细的例子来说明。当前有两个执行器，有 ABCD 4 个任务需要调度，其中 A 是大任务，按照历史经验 cpu 会占用 50%，BCD 是小任务，每个会占用 cpu 20%。将 A 任务权重设置为 5，BCD 设置为 2。初始化执行器 1 和执行器 2 的权重都是 0。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A 任务调度到执行器 1，执行器 1 的权重变为 5，执行器 2 的权重还是 0。B 任务选择任务权重最小的机器，调度到执行器 2，执行器 2 的权重变为 2。C 任务选择任务权重最小的机器，调度到执行器 2，执行器 2 的权重变为 4。D 任务选择任务权重最小的机器，调度到执行器 2，执行器 2 的权重变为 6。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-294a2873a5488022b9503489236d079c705.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;这个时候，又有个小任务 E 要调度，权重也是 2，选择当前权重最小的机器 1，则机器 1 的权重变为了 7，如下图&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-0cb6bdad28fca8ad7ad85a7041fd24a8586.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;小任务 B 和 C 执行很快就跑完了，这个时候执行器 2 的权重减去 4，变为了 2，如下图：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-a8fbdbf6a298620ffc183e8eb4853863b44.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;这个时候又来个大任务 F，权重是 5，选择权重最小的机器 2，机器 2 的任务权重变为了 7，如下图：&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-d431902415007920bbd5594f3d235dfe1c6.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;可以看到该算法，将每个任务实际消耗的资源映射成任务权重，可以实时统计每个执行器的权重，提前规划不同权重的任务分配到哪个执行器上去执行，达到全局最优解。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;span id="OSC_h2_12"&gt;&lt;/span&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;在真实生产环境下，不同的任务处理不同的业务逻辑，如果选错路由策略，可能会导致集群中大部分执行节点负载不到 10%，但是个别节点负载会冲高到 100%，虽然平均负载不高，但是也无法减少规格，可能还需要增大规格防止出稳定性问题。但是如果选对了路由策略，集群所有节点负载均衡，就可以减少节点规格，成本降低 50% 以上。下面以一个表格详细介绍不同路由算法的场景：&lt;/p&gt; 
&lt;p&gt;&lt;img height="352" src="https://oscimg.oschina.net/oscnet/up-135f88cb4ca465c1c8dfa02b9b2f2522ea3.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1] XXLJOB&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fxuxueli%2Fxxl-job" target="_blank"&gt;https://github.com/xuxueli/xxl-job&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;[2] Kubernets&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.csdn.net%2Fjy02268879%2Farticle%2Fdetails%2F148855464" target="_blank"&gt;https://blog.csdn.net/jy02268879/article/details/148855464&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;[3] MSE-XXLJOB&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fschedulerx%2Fschedulerx-xxljob%2Fgetting-started%2Fcreate-and-deploy-a-xxljob-job-in-a-container-in-10-minutes" target="_blank"&gt;https://help.aliyun.com/zh/schedulerx/schedulerx-xxljob/getting-started/create-and-deploy-a-xxljob-job-in-a-container-in-10-minutes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/3874284/blog/18689928</link>
      <guid isPermaLink="false">https://my.oschina.net/u/3874284/blog/18689928</guid>
      <pubDate>Sat, 06 Sep 2025 07:55:00 GMT</pubDate>
      <author>原创</author>
    </item>
  </channel>
</rss>
