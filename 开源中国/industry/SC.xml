<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 26 Feb 2025 07:36:22 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>谷歌发布免费版 AI 编程工具 Gemini Code Assist</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Google DeepMind 昨天&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGoogleDeepMind%2Fstatus%2F1894349711160578093&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;面向全球开发者推出 AI 编程工具 Gemini Code Assist：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;每月提供高达 18 万次的代码补全配额（相当于免费）&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;128K tokens 上下文窗口&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;支持公有领域的所有编程语言&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1376&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/143934_eTUv_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0226/145135_vjzh_2720166.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Gemini Code Assist 背后的模型为 Google Gemini 2.0 针对编程开发微调的版本，更适合用于编程开发领域，开发者可以通过插件形式在 Microsoft Visual Studio Code 和 JetBrains IDE 等流行的集成开发环境中使用，&lt;span style=&quot;background-color:#ffffff; color:#4c4e4d&quot;&gt;开发者可在聊天对话中上传大型文件，以帮助 AI 更好地理解代码库整体结构。&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual Studio Code：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitems%3FitemName%3DGoogle.geminicodeassist&quot; target=&quot;_blank&quot;&gt;https://marketplace.visualstudio.com/items?itemName=Google.geminicodeassist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;JetBrains IDE：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplugins.jetbrains.com%2Fplugin%2F24198-gemini-code-assist&quot; target=&quot;_blank&quot;&gt;https://plugins.jetbrains.com/plugin/24198-gemini-code-assist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fapps%2Fgemini-code-assist&quot; target=&quot;_blank&quot;&gt;http://github.com/apps/gemini-code-assist&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335823/gemini-code-assist-free</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335823/gemini-code-assist-free</guid>
            <pubDate>Wed, 26 Feb 2025 06:50:18 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>近 80k star，这个强大的 Open WebUI 自托管 AI 项目不能错过</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                        
                                                                                    &lt;p&gt;&lt;strong&gt;Open WebUI 是一个&lt;a href=&quot;https://docs.openwebui.com/features/plugin/&quot;&gt;可扩展&lt;/a&gt;、功能丰富且用户友好的自托管 AI 平台，完全支持离线运行。&lt;/strong&gt;它支持多种 LLM（大型语言模型）运行器，如&lt;strong&gt; Ollama &lt;/strong&gt;和&lt;strong&gt; OpenAI &lt;/strong&gt;兼容 API，并内置了用于 RAG 的&lt;strong&gt;推理引擎&lt;/strong&gt;，使其成为&lt;strong&gt;一个强大的 AI 部署解决方案&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;更多信息，请查看我们的&lt;a href=&quot;https://docs.openwebui.com/features/plugin/&quot;&gt;Open WebUI 文档&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Open WebUI 演示&quot; src=&quot;https://oscimg.oschina.net/oscnet//79afb79a0bd0b56998e1a7e520e6826b.gif&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Open WebUI 的关键特性⭐&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;🚀&lt;strong&gt;轻松设置&lt;/strong&gt;：使用 Docker 或 Kubernetes（kubectl、kustomize 或 helm）无缝安装，支持&lt;code&gt;:ollama&lt;/code&gt;和&lt;code&gt;:cuda&lt;/code&gt;标签的镜像，体验无忧。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🤝&lt;strong&gt;Ollama/OpenAI API 集成&lt;/strong&gt;：轻松集成 OpenAI 兼容 API，与 Ollama 模型一起进行多样化的对话。自定义 OpenAI API URL，连接到&lt;strong&gt;LMStudio、GroqCloud、Mistral、OpenRouter 等&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🛡️&lt;strong&gt;细粒度权限和用户组&lt;/strong&gt;：管理员可以创建详细的用户角色和权限，确保安全的用户环境。这种细粒度的控制不仅增强了安全性，还能为用户带来定制化的体验，培养用户的归属感和责任感。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📱&lt;strong&gt;响应式设计&lt;/strong&gt;：在桌面电脑、笔记本电脑和移动设备上享受无缝体验。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📱&lt;strong&gt;移动设备上的渐进式 Web 应用（PWA）&lt;/strong&gt;：通过我们的 PWA 在移动设备上享受类似原生应用的体验，提供离线访问 localhost 和无缝用户界面。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;✒️🔢&lt;strong&gt;完整支持 Markdown 和 LaTeX&lt;/strong&gt;：通过全面支持 Markdown 和 LaTeX，提升你的 LLM 体验，实现更丰富的交互。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🎤📹&lt;strong&gt;免提语音/视频通话&lt;/strong&gt;：通过集成的免提语音和视频通话功能，体验无缝沟通，让聊天环境更加动态和互动。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🛠️&lt;strong&gt;模型构建器&lt;/strong&gt;：通过 Web UI 轻松创建 Ollama 模型。通过&lt;a href=&quot;https://openwebui.com/&quot;&gt;Open WebUI 社区&lt;/a&gt;集成，创建和添加自定义角色/代理、自定义聊天元素以及轻松导入模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🐍&lt;strong&gt;原生 Python 函数调用工具&lt;/strong&gt;：通过在工具工作区中内置代码编辑器支持，增强你的 LLM。通过添加纯 Python 函数，实现与 LLM 的无缝集成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;📚&lt;strong&gt;本地 RAG 集成&lt;/strong&gt;：借助开创性的检索增强生成（RAG）支持，开启聊天互动的未来。你可以直接在聊天中加载文档，或通过&lt;code&gt;#&lt;/code&gt;命令在查询前访问文档库中的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🔍&lt;strong&gt;RAG 的网络搜索&lt;/strong&gt;：使用&lt;code&gt;SearXNG&lt;/code&gt;、&lt;code&gt;Google PSE&lt;/code&gt;、&lt;code&gt;Brave Search&lt;/code&gt;、&lt;code&gt;serpstack&lt;/code&gt;、&lt;code&gt;serper&lt;/code&gt;、&lt;code&gt;Serply&lt;/code&gt;、&lt;code&gt;DuckDuckGo&lt;/code&gt;、&lt;code&gt;TavilySearch&lt;/code&gt;、&lt;code&gt;SearchApi&lt;/code&gt;和&lt;code&gt;Bing&lt;/code&gt;等提供商进行网络搜索，并将结果直接注入到聊天体验中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌐&lt;strong&gt;网络浏览功能&lt;/strong&gt;：通过在&lt;code&gt;#&lt;/code&gt;命令后跟上 URL，将网站无缝集成到聊天体验中。此功能允许你将网络内容直接融入对话中，提升互动的丰富度和深度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🎨&lt;strong&gt;图像生成集成&lt;/strong&gt;：通过使用 AUTOMATIC1111 API 或 ComfyUI（本地）以及 OpenAI 的 DALL-E（外部）等选项，无缝融入图像生成能力，为你的聊天体验增添动态视觉内容。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;⚙️&lt;strong&gt;多模型对话&lt;/strong&gt;：轻松与多种模型同时互动，发挥它们的独特优势，获得最佳响应。通过并行使用多种模型，提升你的体验。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🔐&lt;strong&gt;基于角色的访问控制（RBAC）&lt;/strong&gt;：通过限制权限确保安全访问；只有授权人员可以访问你的 Ollama，模型创建/拉取权限仅限管理员。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌐🌍**多语言支持*/：通过我们的国际化（i18n）支持，用你偏好的语言体验 Open WebUI。加入我们，共同扩展支持的语言！我们正在积极寻找贡献者！&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🧩&lt;strong&gt;管道、Open WebUI 插件支持&lt;/strong&gt;：通过&lt;a href=&quot;https://github.com/open-webui/pipelines&quot;&gt;Pipelines 插件框架&lt;/a&gt;，将自定义逻辑和 Python 库无缝集成到 Open WebUI 中。启动你的 Pipelines 实例，将 OpenAI URL 设置为 Pipelines URL，探索无限可能。&lt;a href=&quot;&quot;&gt;示例&lt;/a&gt;包括函数调用、用户速率限制以控制访问、使用 Langfuse 等工具进行使用情况监控、通过 LibreTranslate 进行实时翻译以支持多语言、有毒信息过滤等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;🌟&lt;strong&gt;持续更新&lt;/strong&gt;：我们致力于通过定期更新、修复和新功能来改进 Open WebUI。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;想了解更多关于 Open WebUI 的特性吗？请查看我们的&lt;a href=&quot;https://docs.openwebui.com/features&quot;&gt;Open WebUI 文档&lt;/a&gt;，获取全面的概述！&lt;/p&gt;

&lt;p&gt;🔗还要查看 Open WebUI 社区！&lt;/p&gt;

&lt;p&gt;别忘了探索我们的姊妹项目&lt;a href=&quot;https://openwebui.com/&quot;&gt;Open WebUI 社区&lt;/a&gt;，在这里你可以发现、下载和探索定制化的 Modelfiles。Open WebUI 社区为通过 Open WebUI 增强你的聊天互动提供了广泛的可能性！🚀&lt;/p&gt;

                                                                    &lt;/div&gt;
                                                                </description>
            <link>https://www.oschina.net/p/open-webui</link>
            <guid isPermaLink="false">https://www.oschina.net/p/open-webui</guid>
            <pubDate>Wed, 26 Feb 2025 06:38:18 GMT</pubDate>
        </item>
        <item>
            <title>DistilQwen2.5 发布：通义千问蒸馏小模型再升级</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;span id=&quot;OSC_h1_1&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;因高计算成本和复杂性，在例如移动设备和边缘计算场景等资源有限的环境中，限制了大语言模型的普及。如何在保留模型性能的同时提高计算效率并降低部署成本，已成为研究和工业界必须面对的关键挑战。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;在此背景下，我们正式推出基于 Qwen2.5 的轻量化大模型系列 DistilQwen2.5。该模型通过创新的双层蒸馏框架实现突破，基于数据优化策略重构指令数据集强化模型理解能力，并且采用参数融合技术实现细粒度知识迁移。实验表明，DistilQwen2.5 在多项基准测试中性能超越原模型，同时显著降低计算资源消耗。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//00b032cb44a18bbc409cd11c99a3592d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;DistilQwen2.5 蒸馏模型的 Checkpoint 已在 Hugging Face 及 Model Scope 全面开源。本文将介绍 DistilQwen2.5 的蒸馏算法、效果评测，以及 DistilQwen2.5 模型在阿里云人工智能平台 PAI 上的使用方法，并提供在各开源社区的下载使用教程。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_2&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5 中的知识蒸馏技术&lt;/h1&gt; 
&lt;p&gt;本节中，主要描述 DistilQwen2.5 模型训练中使用的黑盒化和白盒化的知识蒸馏技术。其中，DistilQwen2.5 模型蒸馏的算法框架如下图所示。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//6d51353007a4cea597e2663a45e4dd33.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;指令数据搜集层&lt;/h2&gt; 
&lt;p&gt;DistilQwen2.5 模型蒸馏算法的首要步骤是指令数据收集层，旨在搜集大量高质量指令数据，以供后续教师模型使用。为了确保数据的多样性和高效性，整合了多个来源的数据集，包括开源数据集 Magpie、Openhermes 和 Mammoth 2 等。此外，还引入了大量私有合成数据集，以丰富指令样本的多样性。为有效整合数据源，确保指令语言主要涵盖中英文，同时对指令进行了难度打分和任务相关的重新抽样。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;首先，在许多应用场景中，模型需要能够跨语言工作。为应对中文数据相对不足的挑战，利用 Qwen-max 进行了数据扩展。通过设计特定的 Prompt，让 Qwen-max 生成了内容不同但任务类型相同的中英文指令，从而平衡了中英文数据的比例。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;其次，任务多样性是实现模型全面能力的关键环节。借鉴 WizardLM 中对大语言模型能力的评估维度，在 DistilQwen2 模型蒸馏中继续使用之前的方法，定义了 33 种任务类型，涵盖广泛的应用场景。我们创建了一个包含 3 万条任务的分类数据集，并基于 Deberta v3 训练了任务分类器。该分类器在测试集上的准确性与 ChatGPT 相当，使得指令数据标注具备高度的可靠性和准确性。通过如此精细的任务标签，能够更好地控制数据集中不同任务类型的分布，确保模型在训练过程中获得全面和深入的能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;此外，在评估指令数据的难易程度时，采用了 LLM-as-a-Judge 的范式。利用教师模型对指令执行的准确性、相关性、帮助性和详细程度进行评分，这为模型提供了一种客观的指令难度评估机制。具体而言，我们引入了一种名为模型拟合难度分数（MFD Score）的指标来衡量每条指令在蒸馏训练中的价值。MFD 分数是根据学生模型得分与教师模型得分之间的差值计算得出的。如果某条指令的 MFD 分数较高，则说明该指令对蒸馏训练更具价值，而低难度的指令则可以从训练集中移除。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;指令遵循优化层（黑盒化蒸馏）&lt;/h2&gt; 
&lt;p&gt;黑盒化蒸馏主要依赖于教师模型的输出，而非其内部表征。我们选择采用黑盒化蒸馏算法的原因有两个：首先，这种算法的训练速度比白盒化蒸馏更快，有助于节省训练时间和计算资源；其次，黑盒化蒸馏适用于开源和闭源的大型模型。在指令遵循优化层中，我们并不直接通过蒸馏微调的方法来优化学生模型，而是利用教师大模型，首先引入一种 Multi-Agent 模式，以对指令数据进行大幅度提升和优化。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;指令扩展：在这一过程中，教师大模型充当指令扩展的 Agent，生成与输入指令相似的新指令。在扩展指令时，我们要求该 Agent 始终保持原始任务的自然语言处理类别不变，以避免产生不必要的幻觉。例如，当输入的指令为「简要概述牛顿第一运动定律」时，输出可以是「解释开普勒第三定律的含义」，而不是「介绍爱因斯坦的生平」。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令选择：指令选择 Agent 的目标是筛选出对模型训练具有高度价值的指令，筛选标准包括信息量、实用性和泛化潜力等。这一过程不仅保证了增强数据集的质量，也有效过滤了对模型蒸馏训练帮助不大的指令数据。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;指令改写：在经过指令扩展和选择后，指令改写 Agent 进一步提升数据的质量和多样性，同时保持指令意图不变。例如，将「提供气候变化经济影响的总结」改写为「解释气候变化如何影响经济」。此外，对于复杂任务如逻辑推理、数学问题和编程等，我们鼓励生成链式思维（Chain-of-Thought, CoT）输出，以进一步提升小模型的推理能力和解决问题的逻辑性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;黑盒化蒸馏过程遵循监督学习范式，以增强的指令响应对作为训练样本。学生模型能够在有限的参数量下，充分吸收和理解来自大模型的知识。这种方法不仅增强了学生模型解决任务的能力，也使其能够在多任务环境中取得更好的效果。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_5&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;知识融合优化层（白盒化蒸馏）&lt;/h2&gt; 
&lt;p&gt;黑盒化知识蒸馏仅依赖教师模型输出的概率最高的 token，而白盒化知识蒸馏则更关注教师模型输出 logits 的分布，从而为学生模型提供更丰富的信息。通过模仿教师模型的 logits 分布，白盒化蒸馏可以更有效地传递知识，进一步提升学生模型的性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//10623cba5e71cbba341a58beaaefaf49.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;传统的白盒化蒸馏算法对于工业大规模数据的蒸馏场景是不可行的，原因有三个：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;GPU 内存消耗过高：如果在训练学生模型的同时进行教师模型的前向传播，所需的计算资源将显著增加。对于拥有 32B 或者 72B 参数的巨型教师模型，GPU 内存甚至可能无法承受。这种情况严重限制了模型的训练效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;长时间的存储和读取：对于离线生成的教师模型 logits，其存储和读取通常需要占用大量的时间。尤其是当数据集非常庞大时，磁盘空间的消耗也变得难以忽视。这种高昂的存储和读取开销成为了系统瓶颈。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;词汇表不匹配问题：教师模型和学生模型通常使用不同的词汇表，导致它们的 logits 张量无法直接匹配。这种不匹配阻碍了知识的准确传递，降低了蒸馏过程的有效性。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;我们在教师模型的输出中观察到，前 10 个 token 的概率之和几乎为 1，这表明教师模型的所有知识几乎都包含在前 10 个 token 中。因此只保存教师模型每个序列位置中概率最大的 10 个 token 的概率。由此我们构建了一个对于大模型和大数据量下可扩展的白盒化知识蒸馏系统，支持以下功能：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//a3a97882de486068e44629d28e52dd04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_6&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;DistilQwen2.5 模型效果评测&lt;/h1&gt; 
&lt;p&gt;在本节中，从多个角度评测 DistilQwen2.5 蒸馏小模型的实际效果；同时，我们对使用不同规模的教师大模型进行模型融合训练的效果进行评测。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_7&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型综合能力评测&lt;/h2&gt; 
&lt;p&gt;我们在多个权威指令遵循评测基准上测试了 DistilQwen2.5 蒸馏小模型的能力。AlpacaEval 2.0 使用 GPT-4 作为评判员来评估生成回复的质量。特别地，AlpacaEval 2.0 引入了长度控制的胜率（Length-controlled Win Rates），以避免 GPT-4 偏向于较长回复，从而减少评估偏差。MT-Bench 是包括来自 8 个类别的 80 个任务，同样使用 GPT-4 作为评判标准，并提供两种不同的评估模式：多轮对话和单轮对话。IFEval 专注于使用「可验证的指令」进行模型效果的评估，这使得结果更加客观。根据所使用的 Prompt 不同，IFEval 提供了 instruction-loose 和 strict-prompt 两种评估模式。如下表所示，DistilQwen2.5 在 0.5B、1.5B、3B 和 7B 四个参数量级的模型中，与原始 Qwen2.5 模型的效果进行了对比。可以看出，本文描述的知识蒸馏算法显著提升了现有大语言模型的指令遵循能力，并在多个评测基准上取得了一致而明显的效果提升。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_8&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型细粒度能力评测&lt;/h2&gt; 
&lt;p&gt;我们进一步使用 MT-bench 基准测试对 DistilQwen2.5 模型的各项细粒度能力进行评测，例如文本生成、代码生成、数学问题、角色扮演等，每个任务都旨在从不同的角度测试模型的能力。通过对 DistilQwen2.5 模型模型在 MT-bench 基准测试中的表现进行分析，我们可以准确量化 DistilQwen2.5 模型在各个方面的细粒度能力，并将其与原始模型进行比较。从实验结果可以看出，在绝大部分细粒度能力层面，DistilQwen2.5 模型比原始 Qwen2.5 模型有明显的提升。下图给出 0.5B 和 1.5B 模型在各个细粒度能力的对比。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div&gt;
  &amp;nbsp; 
&lt;/div&gt; 
&lt;span id=&quot;OSC_h2_9&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;与其他模型能力对比&lt;/h2&gt; 
&lt;p&gt;为了横向比较同期发布的不同参数规模的模型效果，下表展示了这些模型在 AlpacaEval 2.0 的评测结果，对于每个参数量级，从低到高进行排序。我们重点对比了 Qwen2、Qwen2.5 以及先前发布的 DistilQwen2 模型。对于英文模型，我们也横向对比 Llama、Phi3、Mistral 等系列模型。模型效果排序如下所示。可以看出，DistilQwen2.5 系列模型对比其他各类模型，具有很高的性价比，其效果接近了参数量接近或大于其参数量两倍的模型。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//be57d99e1d8cdeb5c10b9a407a4adcbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_10&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型融合实验评测&lt;/h2&gt; 
&lt;p&gt;经过对大模型 logtis 生成速度的优化，我们对 logits 的推理速度提升了至少 4 倍，节省存储空间为原本的 1/1000。使用 5 万条数据时，时间具体耗时如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//2ac326b4d4d8fa99485a261603a0cd82.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;针对不同训练数据量级（1K/10K/100K/200K）下和不同教师模型（7B/14B/32B/72B）大小的蒸馏效果，我们也进行了探索，效果如下图所示，从中可以得到一些关于蒸馏数据量和教师模型参数量大小的结论：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;数据量和模型大小都存在边际效应，随着数据量的成倍提升，效果提升减缓；随着模型规模的上升（32B/72B）并没有对比 14b 模型带来更明显的提升。这表明，学生模型和教师模型在参数量差距过大的情况下，对教师模型的学习能力有限。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在小数据量（～1K）或充分数据量（&amp;gt;200K）的情况下，提升教师模型规模带来的效果提升不明显。在 10K-100K 条数据量下，不同规模的教师模型提升较为明显。这可能是由于在小数据的场景下，学生模型对教师模型的能力还没有充分学习；而在大数据场景下随着数据量大饱和，学生模型已经能从数据中学习到充分的知识。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//9e77f03e07ddb7a4c0a08e044135e6f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_11&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;模型输出案例&lt;/h2&gt; 
&lt;p&gt;对于同一指令，我们对比了 DistilQwen2.5-7B-Instruct 和 GPT-4o、DeepSeek-V3、Qwen2.5-Max、Qwen2-7B-Instruct 回复对比结果，特别是知识性和逻辑推理类问题。从输出结果可以看出，DistilQwen2.5-7B-Instruct 的输出在一些场景上具有更好的事实正确性和逻辑推理能力。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例一：知识性问题&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//07201ddab1feecac2e755b540b0e6149.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例二：知识性问题&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//3741184cb687b09f003da0782a3ae1b5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;示例三：逻辑推理类问题&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//287f2042bf191c17c6c12934c6a211a9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_12&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;模型下载和使用&lt;/h1&gt; 
&lt;span id=&quot;OSC_h2_13&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5 在阿里云人工智能平台 PAI 上的实践&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 库为例，简要介绍如何在 PAI-DSW 上使用 DistilQwen2.5 模型。首先需要保证 PAI-DSW 镜像内 transformers 版本大于等于 4.37.0，否则会在加载模型时报错：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;以 DistilQwen2.5-7B-Instruct 为例，我们可以使用如下代码调用模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-7B-Instruct&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;请给我简单介绍一下杭州西湖。&quot;
messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_14&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;DistilQwen2.5 在开源社区的下载&lt;/h2&gt; 
&lt;p&gt;我们在 HuggingFace 和 ModelScope 上开源了我们蒸馏后的模型，分别为&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-0.5B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-0.5B-Instruct&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-1.5B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-1.5B-Instruct&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-3B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-3B-Instruct&lt;/a&gt;和&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-7B-Instruct&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;alibaba-pai/DistilQwen2.5-7B-Instruct&lt;/a&gt;。以 HuggingFace 为例，用户可以使用如下代码下载这两个模型：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-0.5B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-0.5B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-1.5B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-1.5B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-3B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-3B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-7B-Instruct&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-7B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_15&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;数据集下载和使用&lt;/h1&gt; 
&lt;p&gt;为了支持社区开发者在微调 DistilQwen2.5 模型时避免「灾难性遗忘」（catastrophic forgetting）现象，我们开源了部分用于模型训练的数据集。这一数据集旨在为模型微调提供坚实的基础，有助于提升模型在新任务上的适应性的同时，保持在之前任务上的性能。此外，在微调其他类似大语言模型时，也可以利用这一数据集进行指令遵循能力的增强。以下是关于数据集的信息和下载使用说明。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_16&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;数据格式等相关信息&lt;/h2&gt; 
&lt;p&gt;该部分数据包含了数学、代码、知识问答、指令遵循、创意生成等内容，总数据量为 100K。用户可以在用自己的数据对模型微调时加入 DistilQwen_100K，或者其子集，从而使其在下游任务表现良好的同时不至于丧失其通用能力，保证模型的泛化性。数据格式为 JSON 格式，示例数据如下：&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[
    {
        &quot;instruction&quot;: &quot;The ratio of the number of molar teeth in the human upper jaw at the age of 6 is 2:1 compared to number of incisors teeth. There are total 8 incisors in the human mouth. What is the number of molar teeth in the human upper jaw for this age group?&quot;,
        &quot;output&quot;: &quot;## Step 1: Determine the total number of incisors in the upper jaw.\nSince there are a total of 8 incisors in the human mouth and the incisors are evenly distributed between the upper and lower jaw, we divide the total number of incisors by 2 to find the number in the upper jaw. So, 8 incisors / 2 = 4 incisors in the upper jaw.\n\n## Step 2: Use the given ratio to find the number of molar teeth in the upper jaw.\nThe ratio of molar teeth to incisors in the upper jaw at the age of 6 is given as 2:1. This means for every 1 incisor, there are 2 molar teeth. Since we determined there are 4 incisors in the upper jaw, we multiply this number by 2 to find the number of molar teeth. So, 4 incisors * 2 = 8 molar teeth.\n\nThe final answer is: $\\boxed{8}$&quot;
    },
    {
        &quot;instruction&quot;: &quot;This is the text of a lecture I am giving tomorrow. Can you go over it and make recommendations to improve clarity and flow?&quot;,
        &quot;output&quot;: &quot;I&#39;d be happy to help you review your lecture text and provide suggestions for improvement. Please go ahead and share the text with me, and I&#39;ll get started.\n\nAdditionally, it would be helpful to know a bit more about the context of your lecture. Could you tell me:\n\n* What is the topic of your lecture?\n* Who is your audience (e.g. students, professionals, general public)?\n* What is the purpose of the lecture (e.g. to inform, to persuade, to educate)?\n* How long is the lecture supposed to be?\n\nThis information will help me provide more targeted and relevant feedback.&quot;
    }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h2_17&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;数据集在开源社区的下载&lt;/h2&gt; 
&lt;p&gt;该数据集已上传至 ModelScope，用户可以使用 ModelScope 提供的脚本和命令行工具自行下载使用该数据集。&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//47f399f0906433f82868f9a72178f4bb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;#验证 SDK token
from modelscope.hub.api import HubApi
api = HubApi()
api.login(&#39;your_token_id&#39;)

#数据集下载
from modelscope.msdatasets import MsDataset
ds =  MsDataset.load(&#39;PAI/DistilQwen_100k&#39;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;span id=&quot;OSC_h1_18&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;小结与未来工作&lt;/h1&gt; 
&lt;p&gt;在当前人工智能领域的快速发展中，大语言模型（LLMs）凭借其出色的自然语言理解和生成能力，已在多个应用场景中得到广泛应用。然而，随着这些应用的扩展，其高计算成本和复杂性在资源有限的环境下的接受度逐渐降低，成为行业普及的一大瓶颈。为了解决这一问题，我们提出了 DistilQwen2.5 轻量化模型系列，依托 Qwen2.5 大模型，通过一系列创新的知识蒸馏技术，使得模型在保留原有优越性能的同时显著降低了计算资源需求。为了进一步促进技术的推广与应用，我们将 DistilQwen2.5 模型的 Checkpoint 以及部分训练数据集开源至 Hugging Face 和 Model Scope 等社区，力图为开发者和企业提供更为便捷的操作环境，助力他们在实际项目中迅速实现技术落地。在未来，我们将继续致力于优化并发布 DistilQwen 系列模型，并且针对特定领域（如深度推理等）进行模型的定制化优化，使得 DistilQwen 系列模型在多样化需求下展现出更强的专业能力。&lt;/p&gt; 
&lt;span id=&quot;OSC_h1_19&quot;&gt;&lt;/span&gt; 
&lt;h1&gt;参考资料&lt;/h1&gt; 
&lt;p&gt;相关发表论文&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;技术文章&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2：通义千问大模型的知识蒸馏实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DistilQwen2 蒸馏小模型的训练、评测、压缩与部署实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;大语言模型数据增强与模型蒸馏解决方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&amp;nbsp;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/17771966</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/17771966</guid>
            <pubDate>Sun, 23 Feb 2025 06:22:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>第四范式推出大模型推理端侧解决方案 ModelHub AIoT</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;第四范式宣布推出大模型推理端侧解决方案 ModelHub AIoT，用户在端侧可轻松部署如 DeepSeek R1、Qwen 2.5、Llama 2/3 系列等小尺寸蒸馏模型，离线运行，并可灵活在多个模型之间切换，兼顾了模型压缩、推理性能，解决了部署与优化的复杂性。&lt;/p&gt; 
&lt;p&gt;公告称，该方案不仅能够满足用户对隐私和实时性的需求，还极大降低了 AI 大模型推理成本。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;375&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-68368870524ea2bae030e74a3f08dbf13ea.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1） 无需联网，端侧低延时运行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;优秀的端侧推理框架在端侧算力的支持下，展现出卓越的性能与适配性。模型在本地即时处理请求，提供流畅的用户体验。在网络不稳定或离线环境下，端侧模型仍能正常运行，确保服务的连续性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2） 数据隐私与安全性提升&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在端侧部署模型，数据无需上传至云端，所有计算和处理都在本地设备上完成，避免了云端传输和存储过程中的潜在泄露风险，降低了数据被黑客攻击或滥用的可能性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3） 成本效率与资源优化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;端侧部署有效降低对云端资源的依赖，本地处理减少了云端计算和存储的需求，降低了服务器成本和 API 调用成本，无需频繁上传大量数据，节省了网络带宽资源。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335816</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335816</guid>
            <pubDate>Sun, 23 Feb 2025 06:21:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>湖北武汉发布人工智能新举措，单个项目最高资助 2000 万元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;湖北省武汉市近日发布《武汉市促进人工智能产业发展若干政策措施》（以下简称《措施》），支持关键技术突破，组织实施市级科技重大专项，给予单个项目最高 2000 万元资金支持。这是继《武汉建设国家人工智能创新应用先导区实施方案（2023—2025 年）》（以下简称《方案》）描绘「蓝图」后，武汉首发人工智能支持政策。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;306&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-61a78873a71f5fe5575177b36a5d6045fa3.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;《措施》锚定「打造国内一流的人工智能创新集聚区和产业高地」，分别从支持关键技术突破、强化普惠算力供给、增强模型创新能力、支持公共服务平台建设等 10 个方面给予支持。措施呈现三个亮点：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是强调普惠性。《措施》提出，根据算力使用情况每年设立总额不低于 1000 万元的算力服务券，重点支持中小企业购买算力服务，对企业使用算力服务费用给予 50% 最高 20 万元补助，补助期限不超过三年。同时，《措施》提出，引育高端人才、汇聚形成人工智能百亿元基金投资生态等，注重补齐要素。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;二是提倡开源协同。《措施》指出，对开源开放、协同共享的人工智能公共服务平台，开展服务效果评审，经评审通过的，按照平台实际建设投入费用给予 30% 最高 500 万元资金支持。对人工智能领域中试平台，根据设备投入、开放频次、服务质量等，给予最高 1000 万元资金支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;三是坚持应用导向。《措施》提出，要围绕电子信息制造、工业质检、教育、医疗、遥感、文创、金融等领域每年遴选一批性能先进的垂直行业模型，对牵头研发单位按照研发和算力成本给予最高 1000 万元补助。支持在全市各行业、各领域开展人工智能大模型先行先试应用。《措施》还提出，每年遴选一批人工智能示范应用场景项目，按照项目总投入资金给予 30% 最高 100 万元资金支持。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335813</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335813</guid>
            <pubDate>Sun, 23 Feb 2025 05:58:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>香港发布首个生成式人工智能大模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;人民网香港 2 月 25 日电 (记者陈然) 由香港科技大学主导成立的研究机构香港生成式人工智能研发中心 (HKGAI)，25 日发布生成式人工智能大模型 HKGAI V1。这是香港首个生成式人工智能大模型，为香港人工智能生态发展注入新的活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据介绍，HKGAI V1 是业界首个基于 DeepSeek 进行全参数微调、持续训练产生的大模型。该模型以香港最大的大模型本地知识库为支持，可识别粤语、英语、普通话，并生成不同语言的回答。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;香港特区政府创新科技及工业局局长孙东当日在发布会致辞时表示，人工智能正引领新一轮技术革命和产业变革，在这波以人工智能为代表的科技浪潮中，香港没有缺席。他期待香港研发的大语言模型能够立足香港，尽快提供予业界及市民使用，服务大众，未来服务全球海外华人。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;香港科技大学首席副校长、香港生成式人工智能研发中心主任郭毅可表示，HKGAI V1 大模型的推出，将进一步加强落地场景的应用能力。相信该大模型可为香港数字化转型、构造海外华人的大模型生态和全球人工智能发展贡献重要力量。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，HKGAI V1 涵盖 5 个应用场景，可实时回答用户提问，协助用户撰写文件、生成会议概要、提供香港法例及案件参考等。在香港特区政府数字政策办公室的协调下，特区政府已有约 70 个部门参与试用 HKGAI 提供的大模型辅助办公应用系统。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335802</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335802</guid>
            <pubDate>Sun, 23 Feb 2025 04:01:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>特斯拉 FSD 闯红灯，马斯克回应：我们用了中国互联网上的公开视频数据来训练</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;特斯拉的 FSD 辅助驾驶功能&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/news/335712&quot;&gt;昨日在中国已正式上线&lt;/a&gt;&lt;/u&gt;，此前该功能仅在北美地区可用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-664bbc6e85ff22161ee153cc2a2847960d1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据早期用户反馈，FSD 在中国的驾驶环境中表现良好，已展现出对中国交通规则和路况的适应能力。&lt;/p&gt; 
&lt;p&gt;从网友发布的体验视频来看，对于某些路段，FSD 会做出不遵守交规的行为，比如闯红灯、左转车道直行——非常符合「老司机」的开车风格。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1330&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/111744_y9qf_2720166.png&quot; width=&quot;638&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在 X 平台一条讨论 FSD 在中国表现效果的推文中，Elon Musk &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1894444545301205133&quot; target=&quot;_blank&quot;&gt;回复称&lt;/a&gt;：特斯拉通过视频训练的方式，使得 FSD 系统能够快速适应中国的道路标志和交通法规。他指出，特斯拉利用中国互联网上公开的网络视频资源进行了&lt;strong&gt;模拟预训练&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;1734&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/112645_fwxo_2720166.png&quot; width=&quot;1264&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F7841338587%2FPfXgB9ERi%3Fpagetype%3Dprofilefeed&quot; target=&quot;_blank&quot;&gt;&lt;img height=&quot;1534&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0226/110821_cKHT_2720166.png&quot; width=&quot;1780&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F0sBdmqqvIkgr37QXayv_7Q&quot; target=&quot;_blank&quot;&gt;根据「晚点」的独家报道&lt;/a&gt;&lt;/u&gt;，多位接触过特斯拉的人士透露，&lt;strong&gt;今年 2 月初，特斯拉选择调拨部分美国自动驾驶工程师来中国做成熟版本 FSD 的本地化部署并优化算法&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;据悉，按照中国的相关法规，特斯拉无法将收集的中国行车数据传至海外以训练相应的 FSD 模型。因此本次总部团队空降中国，理论上这能在数据不出境的前提下，尽可能提升 FSD 在华的性能。&lt;/p&gt; 
&lt;p&gt;此前，马斯克曾在本月的特斯拉财报电话会上，透露了 FSD 入华面临的双重窘境，中美两地均无法实现异地训练 FSD。对此马斯克表示，&lt;strong&gt;特斯拉会互联网上找一些中国道路的视频，然后拿去给 FSD 先训练着，而这些视频中将包含部分短视频内容&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;报道指出，&lt;strong&gt;特斯拉中国的团队无需再从头开始训练 FSD ，他们将会接力美国的总部工程师，完成中国特定道路场景的算法优化（比如外卖车 「鬼探头」、公交专用车道等），而此次训练的数据来自特斯拉去年至今在中国特定道路上行驶的工程车&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;据知情人士透露，特斯拉中国目前正在进行针对部分员工的定向 FSD 测试，覆盖研发部门的部分人员。如果情况顺利，下一步特斯拉中国将在内部进行员工分批测试。再往后是向工信部提交车辆召回（OTA）审批，通过后向购买了 FSD 功能的车主推送升级。特斯拉中国原本计划在今年 3 月底或 4 月初获得有关部门的推送许可。&lt;/p&gt; 
&lt;p&gt;至于性能方面，目前中国版 FSD 的功能会比特斯拉美国此前推广的 V13 版更初级更简单，因为它不是依靠海量中国的道路数据训练而来；而知情人士对相关内容没有置评。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335712&quot; target=&quot;news&quot;&gt;特斯拉 FSD 部分能力在中国已推送，命名为「FSD 智能辅助驾驶功能」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335792</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335792</guid>
            <pubDate>Sun, 23 Feb 2025 03:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>3 月 22，南京源创会，聊聊生成式 AI 应⽤构建</title>
            <description></description>
            <link>https://www.oschina.net/event/2423811</link>
            <guid isPermaLink="false">https://www.oschina.net/event/2423811</guid>
            <pubDate>Sun, 23 Feb 2025 03:25:00 GMT</pubDate>
        </item>
        <item>
            <title>宇树科技 G1 人形机器人展示武打动作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;昨日，宇树科技&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1818617132%2FPfVTPwcFT&quot; target=&quot;_blank&quot;&gt;发布视频&lt;/a&gt;&lt;/u&gt;展示了旗下 G1 人形机器人最新更新。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a3bcf2e1605d912f524016b7bd99e7c90ca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;视频中，宇树 G1 人形机器人在镜头前展示了「武打动作」的实操，其能够依靠自身完成单脚飞腿加 360° 转身动作。&lt;/p&gt; 
&lt;p&gt;据宇树科技官方介绍，宇树 G1 机器人算法继续升级，现在已经支持「任意动作任意学」。视频显示，G1 机器人完成了连续武打动作，并能够保持平衡。&lt;/p&gt; 
&lt;p&gt;宇树 G1 人形机器人于 2024 年 5 月发布，定价 9.9 万元起，官方称其为「人形智能体、AI 化身」，支持模仿&amp;amp;强化学习驱动。外观设计方面，该机器人体重约 35kg、身高约 127cm，拥有 23~43 个关节电机，关节最大扭矩 120N・m。&lt;/p&gt; 
&lt;p&gt;近期，宇树科技还公布了宇树 G1 舞蹈视频，视频中机器人动作自然流畅，受到外力干扰依然能够完成舞蹈动作，不受外界影响。&lt;/p&gt; 
&lt;p&gt;此前，在 2025 年央视春晚中，著名电影导演张艺谋携手杭州宇树科技、新疆艺术学院带来了一个名为《秧 BOT》的节目，而其中表演的机器人基于宇树 Unitree H1 人形机器人打造，宇树 G1 和宇树 Go 系列机器狗也一同登台。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335780</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335780</guid>
            <pubDate>Sun, 23 Feb 2025 02:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 开源周第三日：开源 DeepGEMM</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek 开源周第三日宣布推出 DeepGEMM，一个支持密集和 MoE GEMM 的 FP8 GEMM 库，为 V3/R1 训练和推理提供支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;该库采用 CUDA 编写，在安装过程中无需编译，通过使用轻量级的即时编译（JIT）模块在运行时编译所有内核。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;511&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-671a532b18c34cce2c70603de74b6366ac2.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0px; margin-right:0px; text-align:left&quot;&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335425/deepseek-flashmla&quot; target=&quot;_blank&quot;&gt;「DeepSeek 开源周」 首发项目：FlashMLA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/335624&quot; target=&quot;_blank&quot;&gt;DeepSeek 开源周第二日：开源 DeepEP 通信库&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335779/deepseek-deepgemm</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335779/deepseek-deepgemm</guid>
            <pubDate>Sun, 23 Feb 2025 02:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek R2 将提前推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;据路透社援引三位知情人士的&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fartificial-intelligence%2Fdeepseek-rushes-launch-new-ai-model-china-goes-all-2025-02-25%2F&quot; target=&quot;_blank&quot;&gt;消息称&lt;/a&gt;&lt;/u&gt;，DeepSeek 正在加速推出 1 月发布的 R1 模型升级版 — DeepSeek R2。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0226/101542_Mkzx_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;其中两位知情人士表示，&lt;strong&gt;DeepSeek 原计划在 5 月初发布 R2，但现在希望尽早推出&lt;/strong&gt;，具体时间尚未透露。该公司表示，希望新模型在编程能力上表现更佳，并能够支持英语以外的多种语言进行推理。&lt;/p&gt; 
&lt;p&gt;此外，DeepSeek 在同日&lt;a href=&quot;https://www.oschina.net/news/335661&quot;&gt;重新开放了 API 充值入口&lt;/a&gt;，此前因资源紧张，其曾一度关闭充值入口。目前 deepseek-chat 模型优惠期结束，调用价格已变更为每百万输入 tokens 2 元，每百万输出 tokens 8 元。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;路透社的独家报道：&lt;/p&gt; 
&lt;p&gt;- DeepSeek 原计划在 5 月初发布新一代 R2 模型，但已经开始考虑提前发布，这段时间 Grok 3、Claude 3.7、Qwen 2.5-Max 等竞品接连推出，还是有影响的；&lt;/p&gt; 
&lt;p&gt;- 梁文锋在距离清华、北大两所高校步行可达的地段设立了北京办公室，非常乐于和实习生以及应届生一起工作和讨论问题，而且从不鼓励加班；&lt;/p&gt; 
&lt;p&gt;- 采访中一名已经离职的研究员依然对前老板赞不绝口，「他把我们视为专家，不断提问，一起学习，而且愿意下放管理权，普通员工也能参与核心技术，这很让人兴奋」；&lt;/p&gt; 
&lt;p&gt;- 梁文锋在幻方量化时就以薪酬慷慨著称，他会给数据科学家开出 150 万的年薪，而同行给的数字一般不会超过 80 万；&lt;/p&gt; 
&lt;p&gt;- 在创办 DeepSeek 前，幻方量化就制定了把 70% 对可支配收入投入到 AI 研究上的战略，从 2020 年到 2021 年，幻方量化花了 12 亿买卡训练模型；&lt;/p&gt; 
&lt;p&gt;- 这样的异常支出让幻方量化受到了证券监管部门的注意，但最终没有做出干预，这对后来 DeepSeek 的问世至关重要，因为 2022 年开始，中国企业就不太能够合规买到 A100 了；&lt;/p&gt; 
&lt;p&gt;- DeepSeek-R1 爆火之后，梁文锋被建议不要和媒体接触，因为担心过度炒作会引起不必要的争议，尤其是在地缘政治的风口浪尖，苟住再说；&lt;/p&gt; 
&lt;p&gt;- 另有前员工表示，DeepSeek 不缺算力，能够进行大规模训练，但梁文锋对更具经济成本的模型架构非常关注，这决定了 DeepSeek 的发展路线以及后来的巨大成功；&lt;/p&gt; 
&lt;p&gt;- 全球的 AI 大厂至今都还在消化 DeepSeek-R1 造成的影响，也都盯着 R2 的时间表，它的发布会是今年 AI 行业的又一个关键时刻。&lt;/p&gt; 
&lt;p&gt;——转载自「&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fweibo.com%2F1560906700%2F5138215416104782&quot; target=&quot;_blank&quot;&gt;阑夕&lt;/a&gt;」微博&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;阅读更多&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335624&quot; target=&quot;news&quot;&gt;DeepSeek 开源周第二日：开源 DeepEP 通信库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/335425/deepseek-flashmla&quot; target=&quot;news&quot;&gt;「DeepSeek 开源周」首发项目：FlashMLA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335778/deepseek-rushes-launch-new-ai-model</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335778/deepseek-rushes-launch-new-ai-model</guid>
            <pubDate>Sun, 23 Feb 2025 02:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里开源新一代 AI 视频模型通义万相 Wan2.1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里巴巴宣布全面开源旗下视频生成模型万相 2.1 模型，采用 Apache2.0 协议。此次开源的两个参数版本模型：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;14B 版本万相模型在指令遵循、复杂运动生成、物理建模、文字视频生成等方面表现突出，在权威评测集 Vbench 中，万相 2.1 以总分 86.22% 大幅超越 Sora、Luma、Pika 等国内外模型，稳居榜首位置。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;1.3B 版本万相模型不仅超过了更大尺寸的开源模型，甚至还和一些闭源的模型结果接近，同时能在消费级显卡运行，仅需 8.2GB 显存就可以生成 480P 视频，适用于二次模型开发和学术研究。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，本次开源的 Wan2.1 在处理复杂运动、还原真实物理规律、提升影视质感以及优化指令遵循方面具有显著的优势，无论是创作者、开发者还是企业用户，都可以根据自己的需求选择合适的模型和功能，轻松实现高质量的视频生成。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，万相还支持业内领先的中英文文字特效生成，满足广告、短视频等领域的创意需求。在权威评测集 VBench 中，万相以总分 86.22% 的成绩登上榜首位置，大幅领先了 Sora、Minimax、Luma、Gen3、Pika 等国内外视频生成模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;246&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9615e1f458e5844f6acaf6771c609b63a80.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;294&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a089f7a00ad59e58257cca5822b066df814.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于主流的 DiT 和线性噪声轨迹 Flow Matching 范式，万相大模型通过一系列技术创新实现了生成能力的重大进步。包括自研高效的 3D 因果 VAE、可扩展的预训练策略、大规模数据链路构建以及自动化评估指标。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335777</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335777</guid>
            <pubDate>Sun, 23 Feb 2025 02:10:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ChatGPT 现已可用作 Safari 默认搜索引擎</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.macrumors.com%2F2025%2F02%2F24%2Fchatgpt-safari-search-extension%2F&quot; target=&quot;_blank&quot;&gt;据 Macrumors 报道&lt;/a&gt;&lt;/u&gt;，OpenAI 今天更新了 ChatGPT 应用程序，添加了一个新的 Safari 扩展，允许将 ChatGPT 用作通过 Safari 搜索栏进行搜索时的默认搜索引擎。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8702663a83430f6d7607f657f1fdf88d30.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;更新到最新版本的 ChatGPT 应用程序后，用户可在设置应用程序的 Safari 部分启用 ChatGPT 搜索扩展。打开后，在 Safari 搜索栏中输入的所有查询都会指向 ChatGPT 搜索，而不是谷歌或任何默认设置的搜索引擎。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/194253_LjLU_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;该扩展需要获得访问 Google.com 或你的默认搜索引擎网站的许可，但一旦获得许可，用户输入的任何搜索都会重定向到 ChatGPT 的搜索功能，而不是通过 Safari 设置中的默认设置。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335717/chatgpt-safari-search-extension</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335717/chatgpt-safari-search-extension</guid>
            <pubDate>Sat, 22 Feb 2025 11:43:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>特斯拉 FSD 部分能力在中国已推送，命名为「FSD 智能辅助驾驶功能」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;特斯拉官网显示，&lt;strong&gt;FSD 驾驶套件被更名为「FSD 智能辅助驾驶功能」&lt;/strong&gt;，并重新描述其具有的能力，售价仍是 6.4 万元。此前 FSD 功能被直译为「完全自动驾驶能力」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1010&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/185751_YZtN_2720166.png&quot; width=&quot;780&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;另据澎湃新闻报道，特斯拉方面相关人士透露，&lt;strong&gt;公司已将 FSD 的中文表述定为「智能辅助驾驶功能」或「智能辅助驾驶系统」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1310&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/185847_aWQi_2720166.png&quot; width=&quot;2310&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不过目前看来，这相比特斯拉官网给出的名字少了其中的「FSD」。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335712</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335712</guid>
            <pubDate>Sat, 22 Feb 2025 10:59:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenHands —— AI 驱动的软件开发代理平台</title>
            <description>OpenHands 代理可以执行人类开发人员可以执行的任何操作：修改代码、运行命令、浏览网页、调用 API，甚至从 StackOverflow 复制代码片段。</description>
            <link/>
            <guid isPermaLink="false">OpenHands —— AI 驱动的软件开发代理平台</guid>
            <pubDate>Sat, 22 Feb 2025 10:40:00 GMT</pubDate>
        </item>
        <item>
            <title>英国《金融时报》：中国「非常值得投资」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新华社伦敦 2 月 24 日电（记者郑博非）英国《金融时报》24 日发表文章，尽管面临挑战，中国经济基本面没有发生根本变化。越来越多投资者意识到，中国非常值得投资。文章摘要如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国股市今年开始反弹，全球投资者都在问：中国是否具备投资价值？答案是肯定的，而且一直都是如此。将全球第二大市场视为不可投资是错误的。投资者——尤其是外国投资者——现在正在重新发现中国，中国能够在某些特定领域带来巨大的创新和机遇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;文章说，目前，中国市值超过 10 亿美元且自由现金流收益率超过 10% 的公司有 250 多家，而美国却不到 150 家。在这 250 多家中国上市公司中，多数属于非科技行业，因此投资机会不仅限于互联网和人工智能领域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大盘股在中国上市公司中所占比例仍然较小，给新入市者留下很多空间。在 11 个主要行业中，有 7 个行业的大盘股在中国的集中度低于美国。这意味着每个行业中，市值排名前五企业所占比例更小。此外，中国科技行业的集中度也要比美国低得多，这意味着像深度求索（DeepSeek）这样的私营初创企业可以在不被巨头主导的环境中兴起。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335708</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335708</guid>
            <pubDate>Sat, 22 Feb 2025 10:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Trivy：Go 语言编写的开源安全扫描工具</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Trivy 是 Aqua Security 开发的开源安全扫描工具，专注于检测容器镜像、文件系统、代码仓库等场景中的安全漏洞、配置错误及敏感信息泄露问题。&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0225/182528_qWAW_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;GitHub 地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Faquasecurity%2Ftrivy&quot; target=&quot;_blank&quot;&gt;https://github.com/aquasecurity/trivy&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Trivy 凭借其全面的检测能力、易用性和开源特性，成为容器安全领域的核心工具。核心功能多场景覆盖：&lt;/p&gt; 
&lt;ul style=&quot;list-style-type:disc; margin-left:0; margin-right:0&quot;&gt; 
 &lt;li&gt;支持扫描容器镜像、文件系统、Kubernetes 集群、Git 仓库及云环境，识别操作系统包（如 Alpine、Debian）和语言依赖项（如 npm、PyPI）的已知漏洞（CVE）；&lt;/li&gt; 
 &lt;li&gt;高精度匹配：内置实时更新的漏洞数据库（如 NVD、Red Hat），提供漏洞描述、修复建议及影响范围分析；&lt;/li&gt; 
 &lt;li&gt;配置错误检查：基础设施即代码（IaC）扫描：检测 Terraform、Kubernetes 等 IaC 文件的配置错误，例如权限过大或敏感端口暴露；&lt;/li&gt; 
 &lt;li&gt;敏感信息泄露检测：自动扫描代码中的密钥、密码等敏感数据；&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;软件物料清单生成：自动生成符合 CycloneDX 或 SPDX 标准的 SBOM&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2019/0519/084011_8jse_12.gif&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-89a60262258f1b0d8ed08fff7f4797000fe.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335706</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335706</guid>
            <pubDate>Sat, 22 Feb 2025 10:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>AI 生成文章，作者是 AI？文本数据原作者？提问用户？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;无限猴子与结构蜘蛛&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;假设有一只猴子，它会一直随机地在打字机上敲击键盘。那么只要给它的足够长的时间，它就几乎肯定可以敲出人类任何一本已有图书的内容，例如莎士比亚的全集。从数学上讲，在无限次尝试中，猴子可以敲打出任何一部作品的概率都无限趋近于 1。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;这就是著名的无限猴子定理，它是「荒诞」的。就像如果把一杯水倒入大海中，在之后的某个时刻，我们刚刚好可以打捞出一杯一模一样的水一般。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;但是现在我们已经完全不需要畅想无限猴子了。在自然语言处理（NLP）和文本生成领域，要模仿特定的风格生成文本，如果结合大规模预训练模型、风格特征提取、文本生成调优等技术方法，就可以做到「以假乱真」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:auto !important; margin-right:auto !important; text-align:justify&quot;&gt;&lt;img height=&quot;1288&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/180621_6eOp_3820517.png&quot; width=&quot;1266&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;一种关于 AI 的新型自指罗素悖论：由 AI 写作的一篇「我坚决不看任何 AI 写的东西」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;这就是同样基于概率的 deepseek 晚近「震惊人类」的创作，它生成的文本几乎无法分辨是不是人写的，并能够模拟任何风格与作者的文本。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;AI 眼中的「文学风格」是什么样的？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;如果说类似网文、公文等因其程式化、商业化的文体特征，既没有什么独一无二的「作者性」，也没有什么高明的文学性，很容易找到它们「批量生成方式」的话，那我们不妨直接摆上人类整个文学史上最高段的作家之一——三岛由纪夫为例，让 AI 生成一段三岛式的文段：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;暴雨中的剑道场弥漫着铁锈与朽木的气息，汗水顺着少年绷紧的脊梁滑落，在榻榻米上洇出深色图腾。竹刀相击的脆响里，他看见师父眼角的皱纹藏着江户时代某场未竟的复仇。当狂风掀开纸门，携来山茶花的残瓣黏在汗湿的胸膛时，他恍然领悟肉体不过是盛装耻辱的陶器，唯有在彻底粉碎的瞬间，方能窥见永恒澄明的月光。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;三岛的文风「汪洋恣肆，波云诡谲」，比喻惊世骇俗，往往「语不惊人死不休」，令人拍案叫绝，难以名状。而 Deepseek 交出的答卷，即使还不能说已经足够「以假乱真」，但文风的确已经相当有极具辨识度的三岛韵味了。那么 AI 是怎么做到的呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;当我们说「三岛由纪夫式的段落」时，我们首先在表达的，是一种极度抽象、模糊的文本特征，亦即一种经过后人总结与概括出的美学风格。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;相信很少有人可以否认，三岛由纪夫的核心风格至少是包括以下几个方面的：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;极端美学：三岛强调死亡之美、肉体之美、秩序与毁灭的共存。他的文字往往冷峻、华丽，带有仪式感。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;日本传统与西方现代性的交融：他擅长描绘日本传统武士道精神、神道教意象，同时又深受西方文学影响（如尼采、波德莱尔）。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;强烈的视觉意象：他的描写极富画面感，常用光影、色彩、质感等细节来增强感官刺激。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;短促有力的句子与复杂华美的句群交替：他能够在冷静、简洁的描述和繁复的抒情段落之间切换自如。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;有美与毁灭的共存、个人意志与时代洪流、武士道精神的绝对化等思想冲突：「唯有被烈焰吞噬的建筑，才能显现其真正的轮廓」「他宁愿让自己的信仰碎裂成光辉四溅的玻璃，也不愿在时代的尘埃中沉默」「肉体不过是意志的器皿，若器皿已破，则意志亦得解放」等。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;不仅如此，嗜读三岛的人们也很容易就可以总结出三岛有以下这些鲜明的修辞风格，甚至可以说风格鲜明到了若是不如此，就根本「不像」三岛作品的程度：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;对自然的高度拟人化：如「秋日的阳光像一柄锐利的匕首，斜斜地刺入庭院，那金色的光芒在枯叶上燃烧，宛如即将自焚的舞姬。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;对肉体的极端关注：如「他脱下衬衫，背肌绷紧，皮肤因寒冷而泛起淡淡的青白色，像是刀刃轻抚过的瓷器。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;华丽的比喻与象征：「在夜色中，寺庙的影子倒映在水面，仿佛一匹黑色的战马正在湖心饮水。」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而以上三岛核心美学特点与修辞特点的描述正是 AI 自己的「体会」，已经非常准确与出色了，与专家精心编撰的文学史教材中对三岛风格的概括可以说具有几乎同样准确的知识深度。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;上述这些在人类看来是美学风格的东西，在进行过语料库构建与风格学习的机器眼中，却全然是另一番景象。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;机器在收集足够的三岛由纪夫文本后，会首先进行预处理。三岛由纪夫的作品会被机器进行分句、分词，处理日语/中文/翻译英文版本等，并「确保数据格式一致」。此后，机器会采用 TF-IDF、BERTembeddings 等方法分析三岛文本的常见词汇与独特短语，比如他偏好使用的比喻、色彩词、身体意象等。有了上述准备工作，机器就可以对文本进行句法分析，从而识别出三岛句子的结构模式，比如：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·修饰性强的长句（多层定语、隐喻、插入语）&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·简短有力的断句（刀锋般的短句，强调死亡、决绝）。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;其后，机器就可以训练风格分类器（Style Classifier），用以区分三岛文本与其他作家的文本，并让模型学习他的词汇分布、句法模式、修辞风格，从中提取独特的风格特征了。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;AI 是怎么生成特定风格的文本的？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;当模型根据人类给定的条件来调整输出，并生成特定风格、主题或情感的文字时，比如生成三岛由纪夫风格的文字，就叫做「受控文本生成」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;大模型会限制输出自己句子的平均长度、从句嵌套深度、比喻使用率等，使其符合三岛的句法特点，并优先使用「死亡、美、毁灭、身体、宗教」等高频词，以保持风格一致性。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而且如果降低温度（Temperature），就可以控制词汇分布、减少生成随机性，使生成文本更符合训练数据风格，并更具连贯性，不至于过于发散。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;人类也很容易训练一个句法转换模型（Syntax Transfer Model）和比喻生成器（Metaphor Generator），用以将普通文本转换成三岛风格，比如：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·普通句子：「落叶在风中飘零」「他的手指微微颤抖」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;·三岛风格：「秋风撕裂枝头，枯叶如烧尽的诗篇，沉默地坠落」「他的指尖如风中残烛，颤抖着，仿佛即将熄灭」&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;甚至还可以结合情感分析模型（Sentiment Analysis），调整文本的情绪参数，让生成更具三岛式的「悲壮美感」或「压抑感」。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;最后是大模型的评估与优化环节，机器可以自己计算三岛文本与生成文本的困惑度。（Perplexity），评估其可读性与风格一致性，并使用 BERTScore（计算生成文本与参考文本之间单词片段的重复率）、BLEU（衡量生成文本覆盖了多少原文的关键内容）、ROUGE（将文本转化为上下文语义向量，计算生成文本与原文在深层语义上的相似度）等方式，衡量生成文本与三岛原文的相似度。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;再加上人类「专家」的最后的评估与调优，机器就可以把文学、美学风格转化为数据、概率，并由此模拟任何人的写作风格。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;作者应该是 AI 本身，还是「原作者」，亦或是问问题的用户？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;卡夫卡在临终前给了好友布洛德一份遗嘱，要求他死后销毁所有未发表的手稿，其中包括《城堡》、《审判》等公认最伟大的文学作品。卡夫卡此前就多次表达过类似的意愿，并甚至亲手销毁过自己的手稿，但布洛德选择了&quot;背叛&quot;他最好朋友的遗愿。他不但没有销毁这些手稿，反而倾尽毕生精力整理、编辑并出版了它们。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;米兰·昆德拉正是以这个故事展开他的著名的文论作品《被背叛的遗嘱》的，而且恐怕没有人会对此抱有异议：布洛德救赎了文学，即使他背叛了作家本人的意愿与友谊，他还是干得漂亮，他做得太对了！&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;然而如果我们思考昆德拉在这本书中提出的另一个有趣的问题，答案似乎就不如此黑白鲜明了。斯特拉文斯基坚持认为，演奏者必须严格按照自己乐谱演奏，他反对任何形式的擅自改动。即使在有些时候，经过改动后的乐谱演出效果更好。那么这种有悖于作曲家或艺术家原意的「更好」的改动，是可以被允许的吗？昆德拉借题发挥道：&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;毫无疑问，人们完全可能把《追忆逝水年华》中的某个句子写得更好些。但上哪儿去找这么个愿意读一本修改后的普鲁斯特作品的疯子呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;即使在实质意义上，被改动后的文本是比原来的文本「更好」的，这种改动也是不被允许的。这个问题在昆德拉这里之所以是不证自明的，根本原因在于他认为作者的作品是一个有机的整体，任何改动都可能破坏其内在的逻辑和意义。后人首先应该尊重作者的创作意图，并尽量理解和还原作者想要表达的思想和情感。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;所以昆德拉并没有在这个问题上更进一步，这个被改动了个别词句的，甚至已经改变了作者原意的「文本」，他的作者，到底应该是普鲁斯特，还是应该是普鲁斯特以及改动了这段文本的那个人两人合著呢？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而昆德拉之所以没有考虑这个问题，主因或许是印刷时代的纸质图书生成方式，被其他人改动了个别字句的《追忆似水年华》因为没有人愿意看的「市场性」原因根本没有被印出来的价值，而且著作权也不允许这样的著作被印出来。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;所以文本的作者是普鲁斯特与一个没有经过普鲁斯特允许的改写者的情况是不可能发生的。在信息的生产与流通并不依赖纸质图书的印刷、出版的数字时代，一般出现这种偷偷改动原文个别字句并据为己用的情况，自然会被判定为洗稿。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;但如果这段文本的创作者是具有生成能力的大语言模型呢？尤其是大语言模型生成的文本是在它学习了原作者的大量文本后，利用上述手段生成了在人类可以识别的「风格」上完全相同的新的文本。如果 AI 生成文本的风格与原作还有差距，那也只是 AI「还」不能出色地完成仿写任务，而不是 AI「不能」完成这个任务。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;那么 AI 通过仿写生成的文本，他的「作者」到底应该是 AI 本身，是原始文本数据的提供者「原作者」，还是那个通过提问词一步步引导 AI 生产出了这段文本的用户？&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;很多人认为 AI 生成的内容应视为「委托作品」，著作权归属于终端用户。但另一种观点认为，AI 生成的内容缺乏人类创作者的直接参与，不应视为作品，因而不受著作权法保护。纯粹由 AI 生成的艺术作品不应该获得版权保护，因为 AI 提示本身不足以使用户成为作品的作者。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;而 AI 在生成内容时，未经授权使用他人作品进行训练，已经出现过实际的侵权案例。例如，Thomson Reuters 在与 Ross Intelligence 的诉讼中，法院裁定 Ross 未经授权复制其内容用于 AI 训练，侵犯了其版权。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:auto !important; margin-right:auto !important; text-align:justify&quot;&gt;&lt;img height=&quot;216&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0225/180643_5zwk_3820517.png&quot; width=&quot;1236&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;不过美国的版权所有者态度与法律尺度比其他国家更为严苛。据传，几乎所有的著名 AI 公司都曾向数字图书馆安娜的档案提出过合作邀约，但最后美国公司都因为对于版权问题的担忧而最终放弃了合作。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;随着 AI 技术的不断进步，AI 生成内容的著作权归属和相关法律伦理问题只会更加复杂。具有推理与文本生成能力的 AI 技术将为人类社会的方方面面的格局都带来无比重大的改变，版权的概念与相关的法律条文概莫能外。&lt;/p&gt; 
&lt;p style=&quot;color:#2b2b2b; margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;em&gt;原文标题：AI 生成的文本，版权应该属于谁？&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;原文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fculture.ifeng.com%2Fc%2F8h7hfSZDQgO&quot; target=&quot;_blank&quot;&gt;https://culture.ifeng.com/c/8h7hfSZDQgO&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335702/who-is-the-author-of-aigc</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335702/who-is-the-author-of-aigc</guid>
            <pubDate>Sat, 22 Feb 2025 10:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>🔥 用 solon-ai 写个简单的 deepseek 程序（构建全国产 ai 智能体应用）</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;用国产应用开发框架（及生态），对接国产 ai。构建全国产 ai 智能体应用。&lt;/p&gt; 
&lt;h3&gt;1、先要申请个 apiKey&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;打开&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.deepseek.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.deepseek.com&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;官网，申请个 apiKey 。（一万字略过）&lt;/p&gt; 
&lt;h3&gt;2、试试：Hello deepseek&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;用 solon-initializr (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fsolon.noear.org%2Fstart%2F&quot; target=&quot;_blank&quot;&gt;https://solon.noear.org/start/&lt;/a&gt;)，生成一个 solon-web 模板项目。之后:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;在应用属性里添加配置（app.yml）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;solon.ai.chat:&lt;/span&gt;
  &lt;span style=&quot;color:#986801&quot;&gt;deepseek:&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiUrl:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;https://api.deepseek.com/v1/chat/completions&quot;&lt;/span&gt; &lt;em&gt;# 使用完整地址（而不是 api_base）&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiKey:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;sk-9f4415ddc57049658189************&quot;&lt;/span&gt;  &lt;em&gt;# 填写自己申请的 apiKey&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;model:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;deepseek-chat&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;用配置器类构建通用聊天模型&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Configuration&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;DeepseekConfig&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Bean&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; ChatModel &lt;span style=&quot;color:#4078f2&quot;&gt;chatModel&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@Inject(&quot;${solon.ai.chat.deepseek}&quot;)&lt;/span&gt; ChatConfig config)&lt;/span&gt; {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; ChatModel.of(config).build();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;添加测试用的控制器&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;DemoController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    ChatModel chatModel;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;hello&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; String &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;(String message)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; chatModel.prompt(message).call().getMessage().getContent();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;测试一下&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;启动项目。打开浏览器地址：&lt;code&gt;http://localhost:8080/hello?message=hello&lt;/code&gt;。效果良好：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//f0e9c394da0efba47e22276823f509c5.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;3、尝试把输出改成 sse，方便打字效果的聊天窗口开发&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;这里需要添加两个插件依赖，协助流式输出 sse 数据。&lt;/p&gt; 
&lt;table cellspacing=&quot;0&quot; style=&quot;-webkit-text-stroke-width:0px; background-color:#ffffff; border-collapse:collapse; border-spacing:0px; box-sizing:border-box; color:#24292e; display:block; font-family:-apple-system,&amp;quot;system-ui&amp;quot;,&amp;quot;Segoe UI&amp;quot;,Helvetica,Arial,sans-serif,&amp;quot;Apple Color Emoji&amp;quot;,&amp;quot;Segoe UI Emoji&amp;quot;,&amp;quot;Segoe UI Symbol&amp;quot;; font-size:16px; font-style:normal; font-variant-caps:normal; font-variant-ligatures:normal; font-weight:400; letter-spacing:normal; margin-bottom:16px; margin-top:0px; orphans:2; overflow:auto; text-align:start; text-decoration-color:initial; text-decoration-style:initial; text-decoration-thickness:initial; text-transform:none; white-space:normal; widows:2; width:960px; word-spacing:0px&quot;&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;th&gt;插件&lt;/th&gt; 
   &lt;th&gt;作用&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;&lt;code&gt;org.noear:solon-web-rx&lt;/code&gt;&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;提供响应式输出（就是流式输出）&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;&lt;code&gt;org.noear:solon-web-sse&lt;/code&gt;&lt;/td&gt; 
   &lt;td style=&quot;border-color:#dfe2e5; border-style:solid; border-width:1px&quot;&gt;提供 sse 渲染支持&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;加好依赖后，只需要改进下控制器的几行代码：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;DemoController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    ChatModel chatModel;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Produces(MimeType.TEXT_EVENT_STREAM_UTF8_VALUE)&lt;/span&gt; &lt;em&gt;//这个很重要，申明用 sse 格式渲染&lt;/em&gt;
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;hello&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Flux&amp;lt;String&amp;gt; &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;(String message)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; Flux.from(chatModel.prompt(message).stream())
                .filter(resp -&amp;gt; resp.hasChoices())
                .map(resp -&amp;gt; resp.getMessage().getContent());
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;测试一下&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;启动项目。再次打开浏览器地址：&lt;code&gt;http://localhost:8080/hello?message=hello&lt;/code&gt;。效果良好：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//e5203586a3b8b8af6b4163714088004d.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;4、现在开始 RAG，以 「联网搜索」 作为知识库&lt;/h3&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;这里把「联网搜索」，做为一个知识库使用（内部是动态搜索的）。用它作为 RAG 的外部检索支持。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;应用属性加一块配置&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span style=&quot;color:#986801&quot;&gt;solon.ai.chat:&lt;/span&gt;
  &lt;span style=&quot;color:#986801&quot;&gt;deepseek:&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiUrl:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;https://api.deepseek.com/v1/chat/completions&quot;&lt;/span&gt; &lt;em&gt;# 使用完整地址（而不是 api_base）&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiKey:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;sk-9f4415ddc57049658189************&quot;&lt;/span&gt;  &lt;em&gt;# 填写自己申明的 apiKey&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;model:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;deepseek-chat&quot;&lt;/span&gt;
    
&lt;span style=&quot;color:#986801&quot;&gt;solon.ai.repo:&lt;/span&gt;
  &lt;span style=&quot;color:#986801&quot;&gt;websearch:&lt;/span&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiUrl:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;https://api.bochaai.com/v1/web-search&quot;&lt;/span&gt; &lt;em&gt;# 使用完整地址（而不是 api_base）&lt;/em&gt;
    &lt;span style=&quot;color:#986801&quot;&gt;apiKey:&lt;/span&gt; &lt;span style=&quot;color:#50a14f&quot;&gt;&quot;sk-demo...&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;配置器类也调整下&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Configuration&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;DeepseekConfig&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Bean&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; ChatModel &lt;span style=&quot;color:#4078f2&quot;&gt;chatModel&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@Inject(&quot;${solon.ai.chat.deepseek}&quot;)&lt;/span&gt; ChatConfig config)&lt;/span&gt; {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; ChatModel.of(config).build();
    }
    
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Bean&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; Repository &lt;span style=&quot;color:#4078f2&quot;&gt;repository&lt;/span&gt;&lt;span&gt;(&lt;span style=&quot;color:#4078f2&quot;&gt;@Inject(&quot;${solon.ai.repo.websearch}&quot;)&lt;/span&gt; AiConfig config)&lt;/span&gt; {
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;WebSearchRepository&lt;/span&gt;(&lt;span style=&quot;color:#0184bb&quot;&gt;null&lt;/span&gt;, config);
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;再改改控制器（输出重新写回简单的方式，不然不好截图）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;&lt;span style=&quot;color:#4078f2&quot;&gt;@Controller&lt;/span&gt;
&lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;DemoController&lt;/span&gt; {
    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    ChatModel chatModel;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Inject&lt;/span&gt;
    Repository repository;

    &lt;span style=&quot;color:#4078f2&quot;&gt;@Mapping(&quot;hello&quot;)&lt;/span&gt;
    &lt;span style=&quot;color:#a626a4&quot;&gt;public&lt;/span&gt; String &lt;span style=&quot;color:#4078f2&quot;&gt;hello&lt;/span&gt;&lt;span&gt;(String message)&lt;/span&gt; &lt;span style=&quot;color:#a626a4&quot;&gt;throws&lt;/span&gt; IOException {
        &lt;em&gt;//检索&lt;/em&gt;
        List&amp;lt;Document&amp;gt; context = repository.search(&lt;span style=&quot;color:#a626a4&quot;&gt;new&lt;/span&gt; &lt;span style=&quot;color:#c18401&quot;&gt;QueryCondition&lt;/span&gt;(message).limit(&lt;span style=&quot;color:#986801&quot;&gt;4&lt;/span&gt;));

        &lt;em&gt;//消息增强&lt;/em&gt;
        &lt;span style=&quot;color:#986801&quot;&gt;ChatMessage&lt;/span&gt; &lt;span style=&quot;color:#986801&quot;&gt;chatMessage&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; UserMessage.augment(message, context);

        &lt;em&gt;//提交大模型并简单返回（不然，截图不好截）&lt;/em&gt;
        &lt;span style=&quot;color:#a626a4&quot;&gt;return&lt;/span&gt; chatModel.prompt(chatMessage).call().getMessage().getContent();
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;测试一下&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;启动项目。打开浏览器地址：&lt;code&gt;http://localhost:8080/hello?message=solon%20%E6%98%AF%E8%B0%81%E5%BC%80%E5%8F%91%E7%9A%84%EF%BC%9F&lt;/code&gt;。效果良好：&lt;/p&gt; 
&lt;p style=&quot;color:#24292e; text-align:start&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//18bfae28a4f48b983dcc7a867cdd6ddc.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/335701</link>
            <guid isPermaLink="false">https://www.oschina.net/news/335701</guid>
            <pubDate>Sat, 22 Feb 2025 10:04:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>大模型选型攻略，限免！</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;赠书啦，欢迎大家在评论区聊聊「大模型选型那些事」，畅所欲言&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;我们将在评论区随机选出 3 名 OSCer，赠送&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;《AI 赋能：大模型概念、技术及企业级项目应用&lt;/strong&gt;&lt;strong&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;一本&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#2c3e50&quot;&gt;活动截止时间：2 月 28 日 18:00&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;面对市场上众多的大模型选择，如何进行科学的选型也成为了企业面临的一个重要问题。根据笔者的实践经验总结，我们会从&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;大模型基础信息评估、大模型性能评估&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;和&lt;/span&gt;&lt;strong&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;大模型的备案信息评估&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;三个维度来进行大模型的选型。&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;大模型基础信息评估&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型基础信息评估作为选型的第一步，显得尤为关键。下面我们将从参数量、数据规模和维度、模型架构、模型能力应用领域、供应商企业特征以及社区支持与生态系统等六个角度，详细阐述大模型基础信息评估。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;1.参数量&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;参数量是衡量大模型复杂度的重要指标，它直接影响到模型的表达能力和学习能力。根据大模型的缩放定律和涌现能力，参数量越大，模型的学习能力和表达能力通常越强。然而，参数量的增加也会带来计算资源的消耗和训练难度的提升。这也会影响到项目执行中的微调策略，以及上线运行时的计算资源。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，根据企业的计算资源和业务需求，选择适当参数量的模型。对于资源有限的企业，可以选择参数量适中的模型以平衡性能和资源消耗。避免盲目追求大参数量，要结合实际应用场景来评估模型的性能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;2.模型数据规模和维度&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;数据是训练大模型的基础，数据规模和维度的选择直接影响到模型的训练效果和性能。大而全的数据集有助于模型学习更广泛的知识，提高泛化能力，而特定领域的数据集则能使模型在特定任务上表现更出色。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此，优先选择与企业所在行业、领域相关的数据集训练的模型，以确保模型对特定领域有深入的理解。同时，考虑数据的丰富性和多样性，以提高模型的泛化能力和适应性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;3.模型架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;模型架构决定了大模型的学习方式和性能上限。&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前主流的大模型架构大多基于 Transformer，但不同模型在架构上可能有所创新和优化，以适应不同的应用场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;因此&lt;/span&gt;&lt;span style=&quot;color:#ff0000&quot;&gt;，&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;在实际项目中，要关注模型架构的创新性和优化点，了解其在提升性能、降低计算复杂度等方面的改进，选择经过验证、性能稳定的模型架构，以降低实际应用中的风险。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;4.模型能力应用领域&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同的大模型可能针对特定领域进行了优化，或者其底层训练数据决定了其应用能力。因此，在选择大模型时，需要根据企业的实际需求来确定模型的应用领域。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.供应商企业特征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;供应商的企业特征也是选型时需要考虑的因素之一。包括供应商的信誉、技术实力、服务质量等都会影响到模型的使用体验和后续支持。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;社区支持与生态系统&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;一个活跃的社区和丰富的生态系统意味着更多的资源和支持，有助于企业在使用过程中解决问题和优化模型。社区的活跃度和生态系统的完善程度也是评估大模型价值的重要因素。&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_2&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;大模型性能评估&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型性能评估是选定基础信息后的关键环节，它旨在全面衡量大模型在实际应用中的表现。在项目实操中，我们从两个主要方面来评价大模型的性能：&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;大模型通用模型能力&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;和&lt;/span&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;场景适应能力&lt;/strong&gt;&lt;/span&gt;&lt;span style=&quot;color:#000000&quot;&gt;。对于通用模型能力，我们会综合考察备选大模型在基础能力、智商能力、情商能力和工具提效能力等各方面的表现，以此来判断其是否具备类似于人的通用智能。而场景适应能力评估则更为具体，我们会根据项目的实际需求设计验证性问题，通过大模型对这些问题的回答和处理情况来检验其是否真正符合项目的特定要求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;img height=&quot;401&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8bff27e462a46054d55333b18902f01043.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;表 1.大模型通用能力评估方法问题量表&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;435&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-27d3432a05284e47bcb989e67234f71529a.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;图 1.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型通用测试评估示例&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;455&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-81d3dc57c57a1493421ccf78a888fdd8100.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;图 2.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型提示词优化后的特定场景评估示例&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;457&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6c36432f534adb2fa1fe6b94fa1bbdfd1da.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;图 3.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型微调后的场景能力测试评估示例&lt;/span&gt;&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_3&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;&lt;strong&gt;大模型备案信息评估&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前虽然没有明确要求企业在构建私有大模型时只能应用备案过的大模型，但是完成备案的大模型都经过了严格的能力审查，在模型性能和安全性上有较强的优势，因此建议企业优先选用通过备案的大模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;1. 大模型备案概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型备案，即生成式人工智能（大语言模型）上线备案，是网信部门针对生成合成（深度合成）类算法的特定管理流程。这一制度的设立，旨在确保大模型在上线运行前已经通过了严格的能力审查和安全评估，从而保障其在模型性能和安全性方面达到一定的标准。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在这里，「生成式人工智能技术」特指那些具备文本、图片、音频、视频等内容生成能力的模型及相关技术。而「深度合成技术」则涵盖了利用深度学习、虚拟现实等手段制作文本、图像、音频、视频等网络信息的技术。这些技术包括文本生成与风格转换、问答对话，以及人脸生成与替换、人物属性编辑等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（1）大模型备案的主体&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据《生成式人工智能服务管理暂行办法》的规定，具有舆论属性或社会动员能力的生成式人工智能服务提供者，需按照国家相关规定开展安全评估并进行备案。这些服务提供者主要分为两类：平台运营方和技术支持方。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（2）大模型备案流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&amp;nbsp;如下图所示，大模型备案流程的重要节点如下：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;678&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-6d05f943e3d30a4d32010089051cbabd587.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;图 4.&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff; color:#000000&quot;&gt;大模型备案流程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（3）大模型备案所需材料&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在进行大模型备案时，服务提供者需要准备以下材料：&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型上线备案申请表：详细填写模型的基本信息、开发团队情况、应用场景等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 1：安全自评估报告：对模型的安全性进行全面评估，包括数据安全性、算法安全性、系统安全性等方面。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 2：模型服务协议：明确服务提供者与用户之间的权利义务关系，保障双方合法权益。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 3：语料标注规则：详细说明模型在训练过程中使用的语料标注规则和方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 4：关键词拦截列表：列出可能被模型识别并拦截的关键词或敏感词汇。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;附件 5：评估测试题集：提供一套用于评估模型性能和准确性的测试题集。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;综上所述，大模型备案制度的确立和实施对于规范我国人工智能技术的发展具有重要意义。通过严格的备案流程和材料审核，可以确保大模型在合法性、安全性和性能方面达到高标准，从而推动我国人工智能产业的健康、可持续发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;2. 企业对备案信息审查评估&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;大模型在备案时会提交详细的应用场景、安全自评估报告、模型的预料标注规则、关键词和敏感词拦截信息以及测试集信息等。这对企业全面了解和评估大模型的能力和应用，确定供应商是否具备本项目的实施能力至关重要。以下是我们在项目实践中的常用方法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（1）明确评估目标与标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在开始评估前，企业应首先明确自身的业务需求、技术要求和安全标准。这有助于企业在后续的评估过程中，更加针对性地审查相关信息，确保所选大模型能够满足企业的安全需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（2）审查应用场景&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;企业需仔细阅读大模型备案中提供的应用场景描述，了解模型的主要用途、使用环境和预期效果。通过对比企业的实际需求，判断该模型是否适用于本企业的业务场景。同时，关注应用场景中可能存在的风险点和挑战，以便在后续合作中制定相应的应对措施。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;（3）分析安全自评估报告&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;安全是企业在选择大模型时不可忽视的重要因素。企业应详细审查安全自评估报告，了解模型在数据安全、算法安全和系统安全等方面的设计和实施情况。特别关注报告中提到的安全漏洞和应对措施，确保模型在实际应用中能够保障企业数据的安全性和完整性。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（4）核查预料标注规则&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;预料标注规则直接影响大模型对数据的理解和处理能力。企业应核查这些规则是否科学、合理，并符合企业的数据处理需求。通过对比不同模型的标注规则，选择那些能够更准确地反映企业数据特征和处理逻辑的模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（5）检查关键词和敏感词拦截信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;关键词和敏感词拦截功能对于保障信息安全和遵守法律法规至关重要。企业应检查备案信息中提供的关键词和敏感词列表，确保其全面且符合企业的合规要求。同时，测试模型的拦截功能是否有效，以避免在实际应用中出现不当内容或敏感信息的泄露。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（6）评估测试集信息与模型性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;测试集信息是评估大模型性能的重要依据。企业应审查测试集的设计是否合理、数据是否丰富多样，并了解测试过程中的评估指标和方法。通过对比不同模型的测试结果，选择那些在准确率、召回率等关键指标上表现优异的模型。此外，企业还可以自行设计测试用例，对模型进行进一步的性能测试。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;综上所述，企业对大模型备案信息的审查评估是一个系统而细致的过程。通过明确评估目标、审查应用场景、分析安全报告、核查标注规则、检查关键词拦截信息以及评估测试集信息与模型性能等具体步骤，企业可以更加全面地了解大模型的能力和应用情况，从而做出更加明智的选择。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;以上内容节选自《AI 赋能：大模型概念、技术及企业级项目应用》&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;作者：田野，张建伟&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;436&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-111c957c954945b1bd502ae1abb3549868e.png&quot; width=&quot;372&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;span id=&quot;OSC_h2_4&quot;&gt;&lt;/span&gt; 
 &lt;h2&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;&lt;strong&gt;《AI 赋能：大模型概念、技术及企业级项目应用&lt;/strong&gt;&lt;strong&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span&gt;田野，张建伟&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;京东「计算机与互联网」图书销量榜 TOP1！&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;三一集团副总裁、三一商用车智造公司总经理吴盛楠、徐工集团工程机械股份有限公司副总裁闫君，倾情作序。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;color:#007aaa&quot;&gt;联想方案服务业务集团大模型与智能体项目实践经验总结，全景式展现大模型产品生态圈及技术原理，提出大模型选型和建设标准及项目实施方法，企业建设、部署、应用大模型的实用指南。&lt;/span&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;本书聚焦于大模型技术在企业中的实际应用，帮助读者应用大模型为企业降本增效。全书共 6 章：初识大模型、大模型产品生态圈、大模型的技术原理、企业如何部署和应用大模型、企业大模型项目的实施方法、大模型企业应用实践。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;本书提供了详细的大模型选型和建设标准，旨在为企业提供一份清晰的大模型建设指南，帮助读者了解如何建设、部署和应用大模型。本书详细介绍了企业大模型项目的实施方法，从项目规划到工程化部署，并通过具体的企业应用实践案例，展示了大模型在基座型基础设施、企业知识中台、业务知识库、智能体及个人办公智能辅助工具中的强大应用潜力，帮助读者在实践中掌握应用大模型的关键技术和管理能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;本书的读者对象为人工智能、机器学习和数据分析等领域的从业人员，对企业数字化转型和智能化应用感兴趣的企业管理者和决策者，希望通过大模型技术和实施方法增强自身技能的技术研究者和开发者，以及对大模型技术感兴趣并希望深入了解和探索这一前沿科技及其应用场景的读者。&lt;/span&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/17766917</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/17766917</guid>
            <pubDate>Sat, 22 Feb 2025 09:41:00 GMT</pubDate>
            <author>原创</author>
        </item>
    </channel>
</rss>