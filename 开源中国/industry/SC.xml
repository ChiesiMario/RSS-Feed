<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Tue, 11 Feb 2025 16:36:30 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>百度文小言（原文心一言）App 接入 DeepSeek-R1 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;iOS 版百度文小言（原文心一言）App 日前迎来了 4.9.0 版本更新，更新描述称该版本已接入 DeepSeek-R1 模型，优化拍照解题功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5a4769f89c4a201f4028836651b2741d29f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲ 百度文小言（原文心一言）App 接入 DeepSeek-R1 模型&lt;/p&gt; 
&lt;p&gt;接入 DeepSeek-R1 模型后，文心一言 App 的拍照解题功能得到了显著提升。用户在使用该功能时，可以清晰地看到解题过程中的思考步骤，这与 DeepSeek 特有的思维链功能非常相似。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4cc68ae51d81f06ed72ba3d94755a877e04.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1944e58c65fe9c878bae4407b0cf63cf2ab.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有用户表示，「这极大地提升了用户的解题体验。用户通过拍摄问题，系统将自动识别并给出详细的解题思路，这对于需要进行学习和复习的用户来说是个好消息。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333181</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333181</guid>
            <pubDate>Fri, 07 Feb 2025 10:42:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>男子用 DeepSeek 买彩票中奖：买 10 元中 5 元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;今日，词条#用 DeepSeek 买彩票真中奖了#登上微博热搜榜第一，引起许多网友热议。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/172819_3xs4_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据媒体报道，日前，安徽芜湖一男子发帖称，自己按照 DeepSeek 推荐的号码买双色球，真的中奖了。&lt;/p&gt; 
&lt;p&gt;该男子用 5 组 DeepSeek 推荐的数字下注，&lt;strong&gt;合计 10 元，其中一组数字中了「2+1」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/173130_nyzI_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;他表示，这是第一次买双色球，也是才接触 DeepSeek，突发奇想想看看到底准不准，这样的行为不能「上头」，自己之后不会再用 DeepSeek 推荐的数字继续买彩票。&lt;/p&gt; 
&lt;p&gt;据中国福利彩票服务热线工作人员介绍，&lt;strong&gt;上述情况是中了六等奖，奖金为 5 元。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于该男子的做法，有网友表示：「合计 10 元，中了 5 元？有没有可能没有 DeepSeek，你买五组也有这个概率呢？我觉得也没必要神话 DeepSeek。」「随机概率这么大，跟它真没太大关系。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333169</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333169</guid>
            <pubDate>Fri, 07 Feb 2025 09:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>百度李彦宏：自动驾驶比人开车安全十倍</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2 月 11 日消息，「世界政府峰会」（World Goverments Summit 2025）今日在阿联酋迪拜开幕，百度创始人李彦宏今日上午在主论坛上与阿联酋 AI 部长奥马尔・苏丹・奥拉马（Omar Sultan AI Olama）对谈时表示，Robotaxi 可以大大降低交通事故死亡率。从萝卜快跑的实际记录来看，出险率仅为人类驾驶员的 1/14。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8b66f69d2ba73a703403b32ebdae56e2f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;李彦宏表示：「技术进步非常快，自动驾驶比人类司机安全十倍。」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74a55024af52c507dd898d356bf590ace0f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据了解，2024 年第二季度，百度的自动驾驶服务萝卜快跑供应的自动驾驶订单约 89.9 万单，同比增长 26%。截至 2024 年 7 月 28 日，萝卜快跑累计为公众提供的自动驾驶出行服务订单超过 700 万单。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/301302&quot; target=&quot;news&quot;&gt;百度旗下的「萝卜快跑」无人驾驶出租车武汉街头撞倒行人&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333160</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333160</guid>
            <pubDate>Fri, 07 Feb 2025 08:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>嘉立创集团加入 openKylin，助推社区计算多元化生态繁荣</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;text-align:justify&quot;&gt;&lt;span&gt;近日，深圳嘉立创科技集团股份有限公司（简称「嘉立创集团」），签署 OpenAtom openKylin（简称「openKylin」）社区 CLA（Contributor License Agreement 贡献者许可协议），正式加入 openKylin 开源社区。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1527&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-e8345ba8245337a544b99cf88d729976dd5.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span&gt;嘉立创集团&lt;/span&gt;&lt;/span&gt;&lt;span&gt;是电子及机械产业一站式基础设施服务提供商，旗下拥有电子及机械产业一站式服务提供商嘉立创科技、大批量 PCB/PCBA 智造企业中信华和国内领先的样品/小批量电子元器件线上服务商立创商城等三大运营板块。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;依托产业链一站式服务、全流程闭环数字化底座、柔性化智能制造等领先优势以及百万级用户基础，公司打造了「一站式产业互联智造模式」，为客户提供覆盖从打样到小批量再到大批量的 PCB 智造、电子元器件商城、SMT、激光钢网等电子产业链和 CNC 机械智造、3D 打印、FA 机械电气零部件商城等机械产业链一体化服务，以及以 EDA、CAM、DFM、CAD 软件为核心的工业软件集群。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;410&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-620266042dadaea8fb8477b013d338fc9ca.jpg&quot; width=&quot;940&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;在加入 openKylin 社区后，嘉立创集团除了在产品适配、市场推广、技术协同等关键业务领域积极作为与开拓进取之外，也将进一步秉持开放合作、互利共赢的发展理念，充分发挥自身资源优势与产品的优越性，对 openKylin 社区进行全方位的业务支持，助力实现开源生态的繁荣发展，&lt;span&gt;为经济持续发展、科技再创新高提供源动力。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333148</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333148</guid>
            <pubDate>Fri, 07 Feb 2025 07:55:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>DeepSeek 梁文锋身家暴涨，有专家预计或超黄仁勋</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;彭博社报道显示，7 位创业公司创始人和人工智能专家对 DeepSeek 的估值存在巨大分歧，估值区间在 10 亿美元到 1550 亿美元之间。按照彭博亿万富翁指数中间值估算，DeepSeek 估值约在 20 亿至 300 亿美元，而持有公司 84% 股份的梁文锋，身家可能在 16.8 亿到 252 亿美元之间，有望跻身亚洲最富有的科技大亨之列，甚至问鼎中国首富。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不同业内人士给出的估值差异极大。波士顿风险投资公司 Glasswing Ventures 创始人鲁迪纳・塞塞里认为，按同行公司估值，DeepSeek 最少值 10 亿美元；研究工程师 Sebastian Raschka 则觉得，凭借强大的品牌认知度，其估值应在 20 亿到 100 亿美元之间，高于 Mistral AI。而 Sweat Free Telecom 创始人查纳基亚・拉姆德夫的预测更为乐观，认为 DeepSeek 估值可达 1550 亿美元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;148&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d2fbcd3fec3d8b307089121298b01c62f34.webp&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前 1 月有报道称，软银集团洽谈牵头对 OpenAI 进行最高 400 亿美元融资，融资后估值达 3000 亿美元。若 DeepSeek 按此估值一半计算，梁文锋个人财富或达 1260 亿美元，有望超过英伟达 CEO 黄仁勋，身家远超钟睒睒等富豪，在同领域也将远超字节跳动创始人张一鸣（2024 年福布斯中国内地富豪榜显示张一鸣身价 456 亿美元，梁文锋身家或为其 3 倍） 。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;梁文锋出生于 1985 年，本硕就读于浙江大学信息与通用工程专业，师从项志宇，研究机器视觉，2010 年毕业。毕业后，他投身量化投资，成立幻方量化，仅 6 年管理规模达千亿，成为 「量化四大天王」 之一。2023 年 5 月，梁文锋决心进军通用人工智能领域，7 月成立 DeepSeek，被视为量化投身 AI 创业第一人。2024 年 12 月底，DeepSeek 发布的 DeepSeek-V3 火遍全网。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;不过，由于 DeepSeek 收入、利润等财务数据保密，外界只能通过对比 OpenAI、Anthropic 等公司估值来推测其价值，这些估值仅供参考。梁文锋的真实身家究竟几何，还需时间揭晓。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333142</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333142</guid>
            <pubDate>Fri, 07 Feb 2025 07:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>「互联网之子」 Aaron Swartz 雕像在互联网档案馆揭幕</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;Aaron Swartz 的大理石雕像上周五在互联网档案馆的礼堂揭幕，有大约 300 人出席，半身像下方刻有文字&lt;em&gt;「The Internet&#39;s Own Boy（互联网之子）」&lt;/em&gt;。本周重 312 磅的雕像将先转移至大厅，直至获得许可放置在当地公园内。&lt;/p&gt; 
&lt;p&gt;揭幕仪式上，Creative Commons 联合创始人 Lisa Rein 强调：「崇拜 Aaron 的前提是正确理解他的故事——他并非殉道者，而是为公众已付费的科学研究成果应自由获取而战。」电子前沿基金会（EFF）执行董事 Cindy Cohn 则称，这座雕像「提醒人们为真理与正义持续斗争」。科幻作家 Cory Doctorow 在视频致辞中暗讽特朗普政府时期的政治环境：「这是一个希望稀缺的时代，但这座雕像应激励我们让世界变得更好」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f82cf0e74040f33cd165bbe250c47ae3e5c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Aaron Swartz 出生于 1986 年，参与了 RSS 和 Markdown、web.py 等项目的开发，被视为是 Reddit 的联合创始人。&lt;/p&gt; 
&lt;p&gt;2011 年 1 月他因为在 MIT 下载学术论文而遭到逮捕，面临最高 35 年的刑期，他拒绝了认罪协议，于 2013 年 1 月 11 日自杀身亡。他在当年被追授进入互联网名人堂。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;相关阅读&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/92332/in-memory-of-aron-swartz&quot; target=&quot;news&quot;&gt;纪念 Aaron Swartz：他用生命捍衞了互联网的开放和自由&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/36671/aaron-swartz-kill-himself&quot; target=&quot;news&quot;&gt;web.py 作者 Aaron Swartz 自杀身亡&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333126/aaron-swartz-marble-statue-unveiled-internet-archive</guid>
            <pubDate>Fri, 07 Feb 2025 06:33:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌 DeepMind CEO：DeepSeek 模型是中国最好的作品，但炒作有点夸大</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;谷歌旗下人工智能公司 DeepMind 首席执行官戴米斯·哈萨比斯（Demis Hassabis）在巴黎一场谷歌主办的活动上，对 Deepseek 的 AI 模型做出了评价。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/113748_Ev6o_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;哈萨比斯称赞 DeepSeek 的模型是令人印象深刻的作品，并表示「我认为这可能是我见过中国最好的作品」&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;哈萨比斯认为，其在短时间内完成的开发和训练成本控制方面表现出色，然而从技术角度来看，哈萨比斯指出，Deepseek 并没有展示出非常大的科学进步。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;他表示：「尽管有很多人吹捧，但其实这背后并没有真正的新的科学进步……它（DeepSeek）在人工智能中使用的是已知的技术。」他补充说，围绕 DeepSeek 的炒作「有点夸张」。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;他还声称，DeepMind 本周发布的 Gemini 2.0 Flash 模型比 DeepSeek 大模型更为高效。&lt;/p&gt; 
&lt;p&gt;此外，哈萨比斯还谈到了通用人工智能（AGI）的前景，他认为 AI 行业正在走向 AGI，且可能在未来 5 年左右实现这一目标。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333095/deepseeks-ai-model-the-best-work-out-of-china</guid>
            <pubDate>Fri, 07 Feb 2025 03:39:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>TIOBE 2 月榜单：Rust 达新高，Mojo 和 Zig 崭露头角</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 公布了 2025&amp;nbsp;年 2 月的&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;编程语言排行榜&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;64&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1df184cb150f1180b39eb214604fb7eeef4.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;自去年 &lt;a href=&quot;https://www.oschina.net/news/296488/tiobe-index-202406&quot;&gt;6 月&lt;/a&gt;成功超越了 C 成为了 TIOBE 指数中新的第二名之后，C++ 便稳定在了这一位置上。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE CEO&amp;nbsp;Paul Jansen&amp;nbsp;点评道，「随着全球对每秒计算能力的需求日益增长，而硬件的发展速度却未能跟上这一需求，程序的运行速度变得越来越重要。正因如此，在 TIOBE 指数中，那些以速度见长的编程语言逐渐崭露头角也就不足为奇了。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;除了&amp;nbsp;C++，Go 也稳居榜单前 10，Rust 则达到 1.47% 的历史新高。此外，以速度著称的 Mojo 和 Zig 也分别位列第 51 和第 56 位，正在叩响前 50 名的大门。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;你可能会好奇，Python 这种慢速语言是如何在这些竞争激烈的语言面前生存下来的。这是因为，除了性能之外，如今还有另一个驱动因素：&lt;strong style=&quot;color:#404040&quot;&gt;学习一门新编程语言的难易程度&lt;/strong&gt;。除了需要处理更多的数据，世界还需要更多的程序员。完全依赖 AI 开发应用程序目前还无法实现，因此对新程序员的需求依然非常高。由于软件工程专业毕业生的数量远远无法满足市场需求，许多非软件工程师也开始纷纷加入编程的行列，而他们最喜欢的语言正是 Python。这就是为什么 Python 依然能够稳居编程语言的主流地位。&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TIOBE 2 月 TOP 20 编程语言&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;404&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0707406f2fb35a7fdf61ce778525b8f614.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;TOP 10 编程语言 TIOBE 指数走势（2002-2024）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;226&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-70c51a5ab719ba0927f95909df990227d21.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong style=&quot;color:#333333&quot;&gt;第 21-50 名编程语言排行&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;417&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-52892925983133de7bb115cd8a0c1d16f89.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;第 51-100 名如下，由于它们之间的数值差异较小，仅以文本形式列出（按字母排序）：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ABC, ActionScript, Algol, Alice, Apex, APL, AutoLISP, CFML, CHILL, Clipper, CLIPS, Clojure, Crystal, Curl, Elm, Erlang, F#, Forth, Groovy, Hack, Icon, Inform, Io, JScript, LabVIEW, Modula-2, Mojo, MQL5, NATURAL, Nim, OCaml, Occam, OpenCL, OpenEdge ABL, PL/I, Q, Raku, Ring, Scheme, Simulink, Smalltalk, SPARK, SPSS, Stata, SystemVerilog, Vala/Genie, VHDL, Wolfram, X++, Zig&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TIOBE 编程社区指数（The TIOBE Programming Community index）是一个衡量编程语言受欢迎程度的指标，该指数每月更新一次。评判的依据来自世界范围内的工程师、课程和第三方供应商，包括流行的搜索引擎，如 Google、必应、雅虎、维基百科、亚马逊、YouTube 和百度都被用于指数计算。值得注意的是，TIOBE 指数并不代表编程语言的好坏或编写代码的多少。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;该指数可以用来检查你的编程技能是否还能跟上时代的步伐，或者在开始建立一个新的软件系统时，基于指数对采用何种编程语言做出决策。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2Fprogramminglanguages_definition%2F&quot; target=&quot;_blank&quot;&gt;TIOBE 指数&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;的定义方式，以及详细榜单信息&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.tiobe.com%2Ftiobe-index%2F&quot; target=&quot;_blank&quot;&gt;均可查看官网&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333092/tiobe-index-202502</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333092/tiobe-index-202502</guid>
            <pubDate>Fri, 07 Feb 2025 03:32:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Sam Altman：AI 成本每年暴跌 10 倍，2035 年人人都有超级大脑</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;OpenAI CEO Sam Altman &lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.samaltman.com%2Fthree-observations&quot; target=&quot;_blank&quot;&gt;更新了个人博客&lt;/a&gt;&lt;/u&gt;，其中他预测 AI 成本每年将暴跌 10 倍，并且到了 2035 年，人人都能拥有超级大脑。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/111413_19Xl_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;文中，Altman 提到自己对 AI 经济学的三点观察：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI 模型的智能水平大致等于其训练和运行所使用资源的对数；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;使用固定级别 AI 的成本大约每 12 个月降低 10 倍，价格下降会极大促进 AI 的使用；&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;线性增长的智能水平所创造的社会经济价值呈超指数级增长。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;并且 Altman 总结，如果这三点趋势继续保持，AI 对社会的影响将是巨大的。 &amp;nbsp;Altman 还预测，AI Agents 最终可能会像「虚拟同事」一样与人类协作，在各个领域的知识工作中发挥作用。&lt;/p&gt; 
&lt;p&gt;此外，Altman 还认为，在某些方面，AI 在经济上的作用可能会类似于晶体管，AI 也能够大规模推广，并渗透到经济的各个角落。 &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;最后，Altman 还表示确保 AGI 的广泛受益，让 AGI 的好处惠及全社会至关重要。并且他提议持续降低智能计算的成本，让人人都能负担得起 AI，按照这一目标，或将在 2035 年人人都能获得近乎无限的智能支持。&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;附上博客原文：&lt;/p&gt; 
&lt;h3&gt;三点观察&lt;/h3&gt; 
&lt;p&gt;我们的使命是确保 AGI（通用人工智能）造福全人类。&lt;/p&gt; 
&lt;p&gt;如今，一些接近 AGI 的系统已经开始显现，因此我们认为理解当前所处的阶段至关重要。AGI 的定义较为模糊，但通常指的是一种能够在人类水平上解决越来越复杂问题的系统，且适用于多个领域。&lt;/p&gt; 
&lt;p&gt;（作者注释：本文使用「AGI」一词，我们的目的是清晰表达，并无意改变或重新定义我们与微软的合作关系，以及避免断章取义的解读，我们完全预计将与微软保持长期合作。）&lt;/p&gt; 
&lt;p&gt;人类天生具有构建工具的能力，并且拥有理解和创造的驱动力，这促使世界不断进步。每一代人都会在前人发现的基础上进一步创新，创造出更强大的工具——&lt;strong&gt;从电力到晶体管，再到计算机、互联网，如今则是 AGI。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管人类的创新历程并非一帆风顺，但从长远来看，这一进程始终推动着社会发展，使人们的生活在各个方面都得到极大改善。&lt;/p&gt; 
&lt;p&gt;从某种角度来看，AGI 只是人类不断攀登进步阶梯的又一个工具。但从另一个角度来看，它可能标志着一个真正不同的时代的开始。未来的经济增长前景令人惊叹，我们甚至可以设想一个世界：所有疾病都能被治愈，我们拥有更多时间陪伴家人，并能够充分发挥自己的创造潜力。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;或许再过十年，地球上的每个人都能拥有比今天最具影响力的人更强的能力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们持续见证 AI 发展的迅猛进步，以下是关于 AI 经济学的三点观察：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;AI 模型的智能水平大致等于其训练和运行所使用资源的对数。这些资源主要包括训练计算（compute）、数据和推理计算（inference compute）。目前的趋势表明，只要投入足够的资金，就能持续且可预测地提升 AI 能力，而支撑这一趋势的缩放定律（Scaling Laws）在多个数量级范围内都被证明是准确的。&lt;/li&gt; 
 &lt;li&gt;使用固定级别 AI 的成本大约每 12 个月降低 10 倍，价格下降会极大促进 AI 的使用。一个明显的例子是 GPT-4 在 2023 年初的使用成本，相比 GPT-4o 在 2024 年中期，其每个 token 的价格下降了约 150 倍。摩尔定律每 18 个月带来 2 倍的性能提升，而 AI 成本下降的速度远超这一趋势，影响将更加深远。&lt;/li&gt; 
 &lt;li&gt;线性增长的智能水平所创造的社会经济价值呈超指数级增长。这一趋势意味着，对于 AI 的指数级投资在可预见的未来不会停止。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;如果这三点趋势继续保持，AI 对社会的影响将是巨大的。&lt;/p&gt; 
&lt;p&gt;目前，&lt;strong&gt;我们已经开始推出 AI Agents，它们最终可能会像「虚拟同事」一样与人类协作。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以软件工程领域的 AI Agent 为例——这是我们认为极为重要的应用方向之一。设想未来的 AI Agent 能够完成大部分经验 3-5 年的顶级公司软件工程师可以完成的任务，但任务时长限制在几天内。它不会有突破性的创新想法，需要大量的人类监督和指导，在某些方面表现出色，同时在某些意想不到的地方表现较差。&lt;/p&gt; 
&lt;p&gt;尽管如此，它仍可以被视作一名真实但相对初级的虚拟同事。&lt;strong&gt;现在，想象一下如果有 1000 个这样的 AI Agnet，或者 1000000 个。再进一步，设想这样的 AI Agnet 被应用到所有知识型工作领域，其影响将难以估量。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在某些方面，AI 在经济上的作用可能会类似于晶体管——一个重大科学突破，能够大规模推广，并渗透到经济的各个角落。如今，我们不会特别关注晶体管或生产晶体管的公司，但它们的存在让我们的计算机、电视、汽车、玩具等设备变得更加强大、近乎奇迹般地运作。&lt;/p&gt; 
&lt;p&gt;世界的变化不会一蹴而就，它从未如此。短期内，生活仍将继续，2025 年的人们大概率会和 2024 年一样度过日常——我们仍会相爱、组建家庭、在网上争论、去大自然中远足等等。&lt;/p&gt; 
&lt;p&gt;然而，未来的到来将不可忽视，长期来看，社会和经济的变化将是巨大的。人类将找到新的事物去探索，找到新的方式去互相帮助、去竞争，但这些方式可能与今天的工作模式截然不同。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在这样的时代，主动性、意志力和决策能力将变得尤为宝贵。正确地决定要做什么，并在不断变化的世界中找到前进的道路，将具有极高的价值。因此，韧性和适应能力将成为关键技能。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AGI 将是史上最强大的杠杆，极大增强人类的主观能动性，它不会削弱个人的影响力，反而会让个体的能力比以往任何时候都更强大。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AGI 的影响不会均匀分布。某些行业可能变化不大，但科学进步的速度可能比今天快得多，甚至可能超越 AGI 带来的所有其他变革。&lt;/p&gt; 
&lt;p&gt;长期来看，许多商品的价格将大幅下降（目前，智能成本和能源成本是许多行业的主要限制因素）。与此同时，奢侈品和一些稀缺资源（如土地）的价格可能反而会飙升。&lt;/p&gt; 
&lt;p&gt;从技术角度来看，AGI 的发展道路相对清晰。但如何将 AGI 融入社会，公共政策和社会共识将起到至关重要的作用。&lt;strong&gt;这也是我们不断尽早、频繁推出 AI 产品的原因之一——让社会与技术共同演进，为未来做好准备。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI 将渗透到经济和社会的方方面面，未来，我们会期待一切都变得智能化。面对这一趋势，许多人认为应该给予个人更多对技术的控制权，比如开放源码等措施，同时也要接受在安全性与个体赋权之间找到平衡，必然需要做出一些取舍。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;我们始终希望避免鲁莽行事，未来在 AGI 安全性方面可能会做出一些不受欢迎的重要决策和限制。但总体而言，随着 AGI 的逐步实现，我们认为更倾向于个体赋权是正确的方向。否则，我们可能会看到另一条道路。&lt;/p&gt; 
&lt;p&gt;确保 AGI 的广泛受益，让 AGI 的好处惠及全社会至关重要。从历史来看，科技进步通常会改善健康状况、经济繁荣等关键指标，且长期来看整体趋势是向好的。但技术本身不会自动带来更大的平等，如果希望在社会公平方面做得更好，我们可能需要新的思维方式。&lt;/p&gt; 
&lt;p&gt;尤其值得关注的是，资本与劳动力之间的力量平衡可能会被打破，这可能需要及早干预。&lt;/p&gt; 
&lt;p&gt;我们愿意考虑一些听起来不太寻常的想法，比如给每个人分配一定的「计算预算」（compute budget），让全球所有人都能充分利用 AI。&lt;strong&gt;当然，也有一种更简单的方法：持续降低智能计算的成本，让人人都能负担得起 AI。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;到 2035 年，每个人都应该能够调用相当于 2025 年全人类智慧总和的智力资源。所有人都应当获得近乎无限的智能支持，并自由地发挥想象力&lt;/strong&gt;。目前，世界上仍有大量人才因缺乏资源而无法充分发挥自己的潜力，如果我们改变这一点，全球的创造力将迎来爆发式增长，并为所有人带来巨大的福祉。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333079/sam-altman-three-observations</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333079/sam-altman-three-observations</guid>
            <pubDate>Fri, 07 Feb 2025 03:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>被面试官拷问三个小时，应届博士无缘 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1823558407486179899%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;据媒体报道&lt;/a&gt;&lt;/u&gt;，应聘者刘哲回忆起去年 5 月参加 DeepSeek 线上面试的经历。那时，面试官连续 3 小时的高强度提问让他倍感压力。尽管他作为 211、985 高校的应届博士生，在校期间已崭露头角，但面对那些深入且具有挑战性的问题，他仍感到不小的难度。&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;background-color:#ffffff; color:#222222&quot;&gt;「最开始有一个 coding（编程）环节，会根据应聘者的专业出题，测试结果将决定应聘者是否能进入面试环节。面试持续 3 小时，由两位面试官分别进行，每位面试官负责 1.5 小时。其中一位面试官会深入考察机器学习的基础知识，连续提问 1.5 小时，据说所有应聘者都会被问到相同的题目，以便于他们进行比较和排名。接下来的 1.5 小时则是针对项目经验的讨论，他们特别关注应聘者在项目执行过程中的思考方式。」据刘哲所述，面试由 HR 主持，两位面试官都很年轻，不超过 30 岁，整个面试过程体验良好，能够感受到团队充满青春活力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7ed8b4dc5acec727a286bfd36d21d80307e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;「在我所经历过的互联网公司中，&lt;strong&gt;DeepSeek 是唯一一家会根据应聘者的专业背景量身定制编程题目的公司。&lt;/strong&gt;」回顾面试经历，刘哲这样描述。在刘哲看来，DeepSeek 的崛起似乎是必然的。他透露，应聘者普遍来自清华、北大等顶尖学府，面试过程严谨且要求高，当时招聘并未设定人数上限，明显感受到公司旨在网络顶尖智慧人才，只招收天才级别的精英。&lt;/p&gt; 
&lt;p&gt;网络上也有人在分享面试 DeepSeek 的经历时表示遇到了出乎意料的问题。例如，面对「DPO 为什么用 KL 散度,不用交叉熵?机器学习中什么时候必须用 KL 散度，什么时候必须用交叉熵,什么时候两者可互换」这样的问题，有网友不禁感叹：「这还是我能理解的中文吗？」&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f13afeea08b0fb9b3fe3418f8dd4256571b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据知情人透露，有朋友曾参与 DeepSeek 的面试，并直接与创始人对话。总体感受是，公司充满愿景，洋溢着理想主义精神，研究氛围优于高校实验室，非常适合对 AI 充满热情的研究人员。&lt;/p&gt; 
&lt;p&gt;另外，一些参加过 DeepSeek 面试的人表示，公司不设 KPI 考核，采取扁平化管理模式，每位核心算法人员都能直接与梁文峰探讨问题，不太像传统公司，更像大学的一个研究团队。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333075</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333075</guid>
            <pubDate>Fri, 07 Feb 2025 03:04:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>全球开源大模型前十均为阿里通义千问衍生模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，全球最大 AI 开源社区 Huggingface 发布了最新的开源大模型榜单（Open LLM Leaderboard），其中榜单显示，其排名前十的开源大模型全部是基于阿里通义千问（Qwen）开源模型二次训练的衍生模型。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5d2384f1f2035007cae119894ebe4235ed3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;来源：&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2Fopen-llm-leaderboard%2Fopen_llm_leaderboard%23%2F&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/&lt;/a&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;据悉，Open LLM Leaderboard 是目前全球最具权威性的开源大模型榜单，其测试维度涵盖阅读理解、逻辑推理、数学计算、事实问答等。&lt;/p&gt; 
&lt;p&gt;而通义千问 Qwen 大模型已经成为全球最大的开源模型族群。在海内外开源社区中，Qwen 的衍生模型数量已突破 9 万，超越美国 Meta 公司旗下的 Llama 系列开源模型，位居全球第一。在 Hugging face2024 年的开源模型下载中，Qwen 模型系列中的 Qwen2.5-1.5B-Instruct 的下载量占总下载量的 26.6%，是全球下载量最高的开源模型。&lt;/p&gt; 
&lt;p&gt;此外，此前爆火的 DeepSeek 公司基于 R1 推理模型蒸馏了 6 个模型开源给社区，其中有 4 个模型来自 Qwen。近期，著名 AI 科学家李飞飞团队用较少的资源和数据训练出的 s1 推理模型，同样以 Qwen 模型为基础模型。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333071</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333071</guid>
            <pubDate>Fri, 07 Feb 2025 02:54:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>马斯克欲以 7000 亿收购 OpenAI，奥特曼回应：不如让我们收购 X</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 2 月 10 日（路透社）&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.reuters.com%2Fmarkets%2Fdeals%2Felon-musk-led-group-makes-974-billion-bid-control-openai-wsj-reports-2025-02-10%2F&quot; target=&quot;_blank&quot;&gt;报道称&lt;/a&gt;&lt;/u&gt;，由埃隆·马斯克（Elon Musk）领衔的财团周一表示，已经提出以 974 亿美元（当前约 7,115 亿元人民币）收购 OpenAI 的运营资产。报道指出，这一举动可能会对蓬勃发展的 AI 行业产生重大影响。数月前，这位亿万富翁曾起诉这家人工智能初创公司，试图阻止其向营利性企业过渡。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-caff5ae16c7c36c9f1368d8366a9be892c9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此次收购提议的背景是，OpenAI 首席执行官萨姆・阿尔特曼正在尝试对公司进行重组，计划将其非营利董事会与盈利业务分离。然而，目前尚不清楚阿尔特曼和非营利董事会是否已经就过渡价格达成一致。&lt;/p&gt; 
&lt;p&gt;对于这一消息，阿尔特曼在 X 平台上&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1889062013109703009&quot; target=&quot;_blank&quot;&gt;回应称&lt;/a&gt;&lt;/u&gt;：「不用了，谢谢，但如果你愿意，我们可以以 97.4 亿美元的价格收购推特。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;516&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0211/105032_Gj7Z_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;马斯克随后还单独发布了&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Felonmusk%2Fstatus%2F1889070627908145538&quot; target=&quot;_blank&quot;&gt;推文&lt;/a&gt;&lt;/u&gt;，称奥特曼是「Scam Altman（骗子奥特曼）」。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1070&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0211/104848_aRfy_2720166.png&quot; width=&quot;1286&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333069</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333069</guid>
            <pubDate>Fri, 07 Feb 2025 02:50:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动开源大语言模型应用开发框架 Eino</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字节跳动技术团队发文&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FJQREuZyI6ug3cc9Ov7diog&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;，基于 Golang 的大模型应用综合开发框架 Eino 已正式开源，旨在提供简洁、可扩展、可靠的开发工具。&lt;/p&gt; 
&lt;p&gt;据悉，Eino 基于明确的「组件」定义，提供强大的流程「编排」，覆盖开发全流程，旨在帮助开发者以最快的速度实现最有深度的大模型应用。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-74d0fd011f9ebf4fd3950e2f6cc1b0f23bf.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;项目地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;https://github.com/cloudwego/eino&lt;/li&gt; 
 &lt;li&gt;https://github.com/cloudwego/eino-ext&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;字节跳动技术团队介绍，Eino 作为旨在覆盖 devops 全流程的大模型应用开发框架，具有内核稳定、API 简单易懂、丰富的扩展性、提供开箱即用的配套工具等特点，能够帮助开发者快速、简单的上手。&lt;/p&gt; 
&lt;p&gt;Eino 已成为字节跳动内部大模型应用的首选全代码开发框架，已有包括豆包、抖音、扣子等多条业务线、数百个服务接入使用。字节跳动表示，未来还将以 Eino 开源库为核心代码仓库，坚持内外用一套代码，与社区共建最优秀的大模型应用开发框架。&lt;/p&gt; 
&lt;p&gt;Eino&amp;nbsp;借鉴了 LangChain 和 LlamaIndex 等开源框架的优势，并结合前沿研究，提供了一系列丰富的组件抽象，如 ChatModel、Tool、ChatTemplate 等，方便用户组合开发。通过强大的编排框架（Graph、Chain），Eino 支持类型检查、流式处理、并发管理等功能，简化了开发流程。&lt;/p&gt; 
&lt;p&gt;Eino 框架结构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0211/103841_1C2B_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，Eino 提供了流式处理、回调机制、可视化开发工具等功能，帮助开发者高效构建 AI 应用。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333062</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333062</guid>
            <pubDate>Fri, 07 Feb 2025 02:38:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>外交部回应 DeepSeek 引发国际广泛关注讨论</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在 2 月 10 日外交部例行记者会上，有记者提问称，日前中国人工智能企业深度求索（DeepSeek）推出性能优越、免费商用的开源大模型，且训练成本相较同类产品更低，在国际上引起广泛关注和热烈讨论，请问发言人对此有何评论？&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;外交部发言人郭嘉昆表示：具体的专业问题建议向主管部门了解。我想强调的是，当前，人工智能的新技术不断突破，新业态持续涌现，新应用加快拓展，已经成为新一轮科技革命和产业变革的重要驱动力量。中国积极拥抱智能变革，大力推进人工智能创新发展，重视人工智能安全，支持鼓励企业自主创新，为全球人工智能发展作出了积极贡献。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中方积极推动人工智能普惠发展，帮助发展中国家加强能力建设，主张开源人工智能技术，促进人工智能服务的可及性，实现各国共享智能红利。同时，我们反对以意识形态划线，反对泛化国家安全概念、将经贸问题政治化的做法。中方愿同各方加强人工智能交流合作，坚持以共商促共享，携手打造开放包容、互利共赢的发展环境，共同在人工智能的广阔天地里深度求索。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333056</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333056</guid>
            <pubDate>Fri, 07 Feb 2025 01:51:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>操作教程丨使用 1Panel 开源面板快速部署 DeepSeek-R1</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;近期，DeepSeek-R1 模型因其在数学推理、代码生成与自然语言推理等方面的优异表现而受到广泛关注。作为能够有效提升生产力的工具，许多个人和企业用户都希望能在本地部署 DeepSeek-R1 模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;通过 1Panel 的应用商店能够简单、快速地在本地部署 DeepSeek-R1 模型。本教程将按照安装 Ollama→安装 OpenWebUI→安装并使用 DeepSeek-R1 的顺序，为您介绍使用 1Panel 开源面板部署 DeepSeek-R1 模型的具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在部署好 DeepSeek 之后，用户也可以尝试将其与 MaxKB 开源知识库问答系统进行对接，构建一个自己的 Chatbox，也就是一个与 DeepSeek 大模型的智能会话界面。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;一、从 1Panel 应用商店安装 Ollama&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;Ollama 是一个开源的本地大语言模型运行框架，专门为在本地便捷部署和运行大型语言模型而设计。为了能够正常运行 DeepSeek-R1 模型，需要先在本地安装 Ollama，本章节将介绍具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;首先，从 1Panel 首页进入「应用商店」，在「AI/大模型」分类下找到 Ollama，点击「安装」按钮进行安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3eb857757eb258cc4161d9b4046acdfe2e0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在安装详情页中，您可以自定义端口并勾选「端口外部访问」选项，其他设置保持默认，最后点击「确认」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0f1f981b2e3061d054c784539d621db3ab6.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;Ollama 安装成功后，在 1Panel 操作界面中返回应用商店的「已安装」标签页，看到 Ollama 已经安装成功。此时点击「服务端口:11434」按钮，浏览器自动跳转新标签页，若标签页内显示「Ollama is running」，则表示 Ollama 已成功安装并正常运行。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-dd4e30cec3cefda771ea15fb930c61b37ae.jpg&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1fa60c450c2a377092f78c7c44a5a1467c0.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;二、从 1Panel 应用商店安装 OpenWebUI&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;由于 Ollama 本身没有用户交互界面，为了提升模型的使用体验，我们需要从 1Panel 的应用商店中安装 OpenWebUI。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-5e5456150b638b4dbe716ca3839f814339b.png&quot; width=&quot;979&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;OpenWebUI 是一款高度可扩展、功能丰富、操作便捷的自托管 AI 平台，它提供了一个更直观的用户界面，同时增强了安全性和扩展性。OpenWebUI 与 Ollama 相结合，能够方便地管理和使用本地部署的大型语言模型。本章节将介绍安装 OpenWebUI 的具体步骤。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;确认 Ollama 正常运行后，返回 1Panel 应用商店，在「AI/大模型」分类中找到 OpenWebUI，点击「安装」按钮进行安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3d0545f49855958419fbb4aacff814f0760.jpg&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在安装详情页中，您需要填写 Ollama 服务地址和 Secret Key，并勾选「端口外部访问」选项，其他设置保持默认，最后点击「确认」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9ed84ad322dc29653252b58c00a0abe586e.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;OpenWebUI 安装成功后，返回 1Panel 应用商店「已安装」标签页，点击「服务端口:3000」按钮，进入 OpenWebUI 控制枱（注意：如果浏览器未能显示 OpenWebUI 控制枱页面，请在 OpenWebUI 应用显示的「已安装」时间超过 5 分钟以后再进行访问）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9aa59370c5af4fd4ad89aec078704932e3a.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;在 OpenWebUI 控制枱中，依次设置「名称」、「电子邮箱」和「密码」，完成设置后，点击「创建管理员账号」按钮。稍等片刻，页面会弹出更新提示窗口，点击「确认，开始使用！」按钮，提示窗口消失后，即可开始使用 OpenWebUI。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-cfb617497b6a6c3ca0f93ce15df4f43edf8.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;三、通过 OpenWebUI 安装并使用 DeepSeek-R1&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;本章节将介绍如何通过 OpenWebUI 安装和使用 DeepSeek-R1 模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;1. 安装 DeepSeek-R1 模型：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;返回至 OpenWebUI 控制枱页面，点击页面左上角的「选择一个模型」选项，在搜索框中输入「deepseek-r1:1.5b」，然后点击「从 Ollama.com 拉取 deepseek-r1:1.5b」选项。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-060b281d5425c3d9dd26e454ce843597c57.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;2. 使用 DeepSeek-R1 模型：&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;模型下载完成后，刷新页面，确认页面左上角的模型显示为「deepseek-r1:1.5b」。然后点击屏幕中央的输入框，就可以开始和 DeepSeek-R1 模型对话了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;922&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-309adcc2cdecb9c8f9caaff84223ca49b0d.png&quot; width=&quot;1608&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;稍等片刻，收到回复后即可确认 DeepSeek-R1 已通过 1Panel 成功部署到您的服务器。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f5748142a990c5a72b8fb2d6db37312c833.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;四、使用 GPU 为 DeepSeek- R1 加速&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;使用 GPU 为 DeepSeek-R1 加速可以显著提升模型的推理速度。在本章节中，我们以 NVIDIA GPU 为例，介绍如何在 1Panel 中为 DeepSeek-R1 配置加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;重要提示：在启用 GPU 加速之前，请确保服务器已经安装 GPU 卡并配置了相关驱动。&lt;/span&gt;&lt;/strong&gt;&lt;br&gt; &lt;span style=&quot;color:#3e3e3e&quot;&gt;进入 1Panel 应用商店的「已安装」标签页，点击 Ollama 应用下的「参数」按钮。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-579e56d39751e426ecc172ba3966317a62a.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;点击「编辑」按钮进入参数配置页面的「详情」界面，勾选「高级设置」选项，并启用「编辑 compose 文件」选项。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;div&gt;
 &lt;img src=&quot;https://oscimg.oschina.net/oscnet//47c9356c33a5e702b5a41a3de4be878b.jpg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;此时，在 compose 内容编辑框中，输入以下与 GPU 相关的代码：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;reservations:
       devices:
              -  driver: nvidia
                  count: all
                  capabilities: [gpu]&lt;/code&gt;&lt;/pre&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;输入完成后，点击编辑页面中的「确认」按钮，Ollama 会自动重建。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;当重建完成后，Ollama 在 1Panel 应用商店中的状态变更为「已启动」，此时可以使用 NVIDIA GPU 为 DeepSeek-R1 提供加速。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-37ea6f8a8900338c209c5bbb3b25bcac4ac.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span style=&quot;color:#005eeb&quot;&gt;五、企业如何用好 DeepSeek？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;DeepSeek 部署完成后，该如何让各个业务部门使用好这个能力超强的大模型呢？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;这时候，MaxKB 开源知识库问答系统就可以发挥积极作用了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;1080&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b3d7952c60ed617db87088d004d8cf9fa7b.jpg&quot; width=&quot;1920&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;首先，MaxKB 可以为本地部署的 DeepSeek 构建一个 Chatbox，也就是一个智能对话的界面，类似于个人用户直接与 DeepSeek 进行对话。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;MaxKB 提供的 Chatbox 可以方便地嵌入到企业 OA 系统和业务系统，让员工使用更加便捷、安全。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#000000; text-align:start&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;987&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ba43c99463a01d2e8219fa6a91eb22765b8.png&quot; width=&quot;1939&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;另一方面，企业内部有非常多的私有知识文档，这些内容是经过长期的积累和不断修订形成的，在企业内部可以形成知识库问答系统为企业的员工、合作伙伴和客户提供服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;904&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3762219074a17fe370af4ecb448ce1f2a4b.png&quot; width=&quot;947&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;span style=&quot;color:#3e3e3e&quot;&gt;MaxKB 提供开箱即用的 RAG（Retrieval-Augmented Generation，检索增强生成）技术，能够结合私有知识库提升问答效果，有效降低大模型幻觉。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333030</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333030</guid>
            <pubDate>Thu, 06 Feb 2025 14:31:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>Linux 内核新补丁调整 AC 电源插拔行为，向 Windows 看齐以提升硬件兼容性</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;AMD 工程师主导优化，解决便携设备休眠唤醒痛点。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;近日，AMD 工程师 Mario Limonciello 向 Linux 内核&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flore.kernel.org%2Flinux-pm%2F20250208162210.3929473-1-superm1%40kernel.org%2F&quot; target=&quot;_blank&quot;&gt;提交了一系列补丁&lt;/a&gt;&lt;/u&gt;，旨在调整系统在&lt;strong&gt;s2idle（挂起到空闲）&lt;/strong&gt;状态下的 AC 电源插拔行为，使其更贴近 Windows 11 的逻辑。&lt;/p&gt; 
&lt;p&gt;这一改动主要针对笔记本电脑、手持游戏设备（如 Steam Deck 同类产品）在休眠时因电源状态切换导致的兼容性问题，尤其是此前曝光的 Legion Go S（搭载 AMD Ryzen Z2 芯片）的固件级故障。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;为何需要「模仿」Windows？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当前，Linux 与 Windows 在 s2idle 状态下的电源行为存在关键差异：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;：插入或拔出 AC 电源时，系统会完全唤醒，若后续无用户操作则重新进入睡眠。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;：AC 事件仅触发短暂唤醒后立即重回休眠，可能导致硬件固件因快速状态切换出现异常（例如某些设备无法正确处理快速进入/退出低功耗模式）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Limonciello 指出，由于 OEM 厂商通常基于 Windows 进行硬件验证，Linux 的差异行为易暴露底层固件缺陷。新补丁通过记录休眠前的电池状态，并在 AC 事件后对比状态变化，决定是否彻底唤醒系统，从而减少「兼容性陷阱」。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;技术细节：唤醒机制与能耗监控&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唤醒逻辑重构&lt;/strong&gt;&lt;br&gt; 补丁在 ACPI 电池驱动中新增&lt;code&gt;suspend_state&lt;/code&gt;字段，休眠时保存当前电源状态（如是否充电）。若唤醒后检测到状态变化（如从充电变为放电），则触发系统完全唤醒，而非立即休眠。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;能耗统计透明化&lt;/strong&gt;&lt;br&gt; 新增&lt;code&gt;/sys/power/suspend_stats/last_sleep_energy&lt;/code&gt;文件，以&lt;strong&gt;毫安时（mAh）&lt;/strong&gt;为单位记录上次休眠周期的电池消耗量，方便用户空间工具分析功耗问题。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;争议与用户控制&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;尽管新行为默认启用，但开发者社区对其适用场景存在分歧。例如，若笔记本合盖时连接电源，是否应强制唤醒？Limonciello 认为，这与用户外接扩展坞的场景需求一致，但用户仍可通过禁用 ACPI 电池设备的&lt;code&gt;power/wakeup&lt;/code&gt;属性恢复旧逻辑。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;影响与未来展望&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;此次调整尤其利好搭载 AMD 芯片的设备，但惠及所有支持 s2idle 的 x86/ARM 平台。随着 Linux 在掌机市场的渗透（如 Steam OS 设备），此类优化将显著提升用户体验。此外，补丁的「Windows 兼容性驱动」思路或成为未来硬件支持的新范式，减少厂商因生态差异对 Linux 的适配成本。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;br&gt; Linux 在电源管理领域的「向 Windows 学习」，并非妥协，而是以用户体验为优先的务实选择。这一补丁不仅修复了长期存在的兼容性痛点，也为开源生态与 OEM 厂商的协作提供了新思路。未来，类似「求同存异」的优化或成常态，进一步模糊两大操作系统在硬件支持上的体验边界。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</link>
            <guid isPermaLink="false">https://www.oschina.net/news/333017/linux-patches-ac-plug-s2idle</guid>
            <pubDate>Thu, 06 Feb 2025 11:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>图解系列｜DeepSeek-R1 的出众推理能力从何而来？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; DeepSeek-R1 到底有什么特别之处？它为什么能在推理任务上取得如此出色的表现？这背后的训练方法又蕴含着怎样的创新？&lt;/p&gt; 
 &lt;p&gt;当我们需要模型处理数学题、编程任务，或是进行逻辑分析时，高质量的推理能力显得尤为重要。然而，传统的训练方法往往需要耗费大量人力物力，这对许多研究团队和企业来说都是不小的负担。&lt;/p&gt; 
 &lt;p&gt;今天这篇深度解析 DeepSeek-R1 训练方法的文章，将展示一个令人耳目一新的解决方案：如何通过创新的强化学习方法，在少量高质量人工标注数据的情况下，打造出一个推理能力出众的 AI 模型。文章详细介绍了 DeepSeek 团队如何通过&quot;自动验证机制&quot;来训练模型，这种方法不仅大大降低了对人工标注数据的依赖，还能持续提升模型的推理质量。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | Jay Alammar&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-6fa463c0670c30f6fa2098b0a2cfb8cedbd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;DeepSeek-R1 代表了人工智能发展的又一重要里程碑。对于机器学习领域的研究人员与开发者群体而言，这次发布之所以备受关注，主要有以下两点：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;首先，这是一款开源权重的模型，并且提供了更小的、经过蒸馏的版本；&lt;/li&gt; 
 &lt;li&gt;其次，它公布并深入探讨了训练方法，该方法能够复现类似于 OpenAI O1 的推理模型。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;本文将带您了解这一模型的构建过程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.1- 长推理链的 SFT 数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.2- 一个过渡性的、擅长推理的高质量大语言模型（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3- 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 回顾：大语言模型（LLMs）的训练方法&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与大多数现有的大语言模型一样，DeepSeek-R1 也是逐个生成 token，但其独特之处在于擅长解决数学和推理问题。这是因为它能够通过生成一系列思考 tokens 来详细阐述其思考过程，从而更加深入地处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5b41809ec9dc436f27455aa39b8ef58c830.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;下图摘自书籍《Hands-On Large Language Models》的第 12 章，展示了创建高质量大语言模型的三个主要步骤：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5960076009014b645e62ad11df7e601f3dd.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;1）&lt;strong&gt;语言建模阶段&lt;/strong&gt;，我们利用海量的网络数据训练模型预测下一个词汇，从而得到一个基础模型。&lt;/p&gt; 
&lt;p&gt;2）&lt;strong&gt;监督式微调阶段&lt;/strong&gt;，这一步骤让模型在执行指令和回答问题时更加得心应手，进而得到一个指令调优的模型或称为监督式微调/SFT 模型。&lt;/p&gt; 
&lt;p&gt;3）最后是&lt;strong&gt;偏好调优阶段&lt;/strong&gt;，这一步骤进一步优化模型的行为，使其更符合人类偏好，最终形成的是你在各种平台和应用中使用的偏好调优后的 LLM。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 DeepSeek-R1 的训练步骤&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;DeepSeek-R1 遵循了这一通用框架。其第一步的具体内容源自于之前关于 DeepSeek-V3 模型的研究论文[1]。R1 使用的是该论文中的基础模型（并非最终的 DeepSeek-V3 模型），并且同样经历了 SFT（监督式微调）和偏好调优阶段，但它的独特之处在于这些阶段的具体操作方法。&lt;/p&gt; 
&lt;p&gt;在 R1 的构建过程中，有三个关键点值得特别关注。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 长推理链的 SFT 数据&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-71048a70e57a4dd98c33f2c0fb43d5a0d16.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这些长思维链推理的实例数量庞大（总共达到 60 万个）。如此大规模的实例获取难度极高，且若要依靠人工标注，成本也将极为昂贵。&lt;/strong&gt; 因此，这些实例的创建过程是我们需要强调的第二个独特之处。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2 一个过渡性的、擅长推理的高质量 LLM（但在非推理任务上表现稍逊）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;这些数据是由 R1 的前身，一个专注于推理但尚未命名的姊妹模型所生成的。这个姊妹模型受到了另一个模型 R1-Zero 的启发（我们将在稍后讨论）。它之所以意义重大，并不是因为它是一个非常好用的 LLM，而在于在它的创建过程中，几乎无需依赖标注数据，仅通过大规模的强化学习，就能培育出一个擅长处理推理问题的模型。&lt;/p&gt; 
&lt;p&gt;接着，这个未命名的推理专家模型的输出结果，可以用来训练一个更为多能的模型，它不仅能够处理推理任务，还能应对其他类型的任务，满足用户对大语言模型（LLM）的普遍期待。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4851fe74d4b6fa9ff29c1036a1790de83f4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3 利用大规模强化学习（RL）构建推理模型&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;此处分为两个步骤：&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.1- 以推理为导向的大规模强化学习（R1-Zero）&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在此过程中，我们利用强化学习（RL）来构建一个临时的推理模型。随后，这个模型被用于生成用于监督式微调（SFT）的推理示例。然而，能够创建这个模型的关键，在于之前的一项实验，该实验成功打造了一个名为 DeepSeek-R1-Zero 的早期模型。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fbae4d4fb50b77fa5484a9d220719bbe4d6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;R1-Zero 的独特之处在于，它能够在没有经过标注的 SFT 训练集的情况下，依然在推理任务上表现卓越。它的训练过程直接从预训练的基础模型出发，通过强化学习训练（跳过了 SFT 阶段）。它的表现非常出色，能够与 O1 模型相媲美。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fd68b8120aaa63d61a0ca7bb0b7333d62ab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这一成就重要重大，因为数据一直是机器学习模型能力的助推器。那么，这个模型是如何打破这一传统的呢？这主要归功于以下两点：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 现代基础模型在质量和能力上已经达到了一个临界点（这个基础模型是在高达 14.8 万亿的高质量 tokens 上训练而成的）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 与通用聊天或写作请求不同，推理问题可以实现自动验证或标注。&lt;/strong&gt; 可以通过以下这个示例来说明这一点。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;示例：推理问题的自动验证&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是一个可能出现在 RL 训练步骤中的提示词/问题：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;编写一段 Python 代码，获取一个数字列表，返回排序后的列表，并在列表开头添加数字 42。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;这样的问题非常适合自动验证。假设我们将这个问题抛给正在训练的模型，它会生成：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;使用软件语法检查器可以验证生成的代码是否为有效的 Python 代码。&lt;/li&gt; 
 &lt;li&gt;我们可以运行这段 Python 代码，以检查其是否能够成功执行。&lt;/li&gt; 
 &lt;li&gt;其他现代代码生成 LLM 可以创建单元测试来验证代码的行为是否符合预期（它们自身无需具备推理能力）。&lt;/li&gt; 
 &lt;li&gt;我们甚至可以进一步，通过测量代码的执行时间，让训练过程偏好那些性能更优的解决方案，即使其他解决方案也是正确的 Python 程序。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;在训练步骤中，我们可以向模型提出这样的问题，并生成多种可能的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f83bf0627d5f3ff8f1fda69f2a0769899e6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们可以不依赖人工干预，自动进行检查，发现第一个输出根本不是代码。第二个输出是代码，但并非 Python 代码。第三个输出看似是一个解决方案，却未能通过单元测试，而第四个输出则是正确的解决方案。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a1c61910f7a45c46610b945fcd73cf50a89.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些反馈都是可以直接用来优化模型的信号。这一过程当然是在大量示例（以小批量形式）和连续的训练步骤中完成的。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c2e60359299a142483ec274c460a0c90dc6.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这些奖励信号和模型更新是模型在强化学习训练过程中不断进步的关键，如下图所示。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-ce02ceb2d7a3049768b4b796755b83f0f9f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;与此能力提升相伴的是，模型生成了更长的响应，即使用了更多的思考 tokens 来处理问题。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4c90ef53271c751b695ad334dddfbb87f40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;尽管这个过程很有价值，但 R1-Zero 模型在推理问题上的高分表现背后，仍存在一些问题，使其实际可用性未达理想状态。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;虽然 DeepSeek-R1-Zero 展现出了卓越的推理能力，并自主发展出了出人意料的强大推理行为，但它也遭遇了一些挑战，比如文本可读性不佳和语言混杂等问题。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;R1 模型的设计目标是提高可用性。因此，它（DeepSeek-R1-Zero）不仅仅完全依赖于强化学习过程，而是如前文所述，在以下两个方面发挥作用：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1- 创建一个过渡性的推理模型，用以生成监督式微调（SFT）的数据点。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2- 训练 R1 模型，以在推理和非推理问题上取得进步（利用其他类型的验证器）。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-694a728dfc22ac72182045659f53b114a1b.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.2- 利用过渡性推理模型生成 SFT 推理数据&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;为了提升过渡性推理模型的实际效用，我们对其进行了监督式微调（SFT）训练，这一步骤在数千个推理问题示例上进行（部分示例由 R1-Zero 生成并筛选）。在论文中，这些示例被称为&quot;冷启动数据&quot;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;2.3.1. 冷启动阶段&lt;/p&gt; 
 &lt;p&gt;与 DeepSeek-R1-Zero 不同，为了防止基础模型在强化学习训练初期出现不稳定的冷启动问题，对于 DeepSeek-R1，我们构建并收集了少量长思维链（CoT）数据对模型进行微调，将其作为初始的强化学习策略模型。为收集这类数据，我们探索了多种方法：使用带有长 CoT 示例的小样本提示技术、直接提示模型生成带有反思和验证的详细答案、收集 DeepSeek-R1-Zero 生成的易读格式输出，并通过人工标注员对结果进行后处理细化。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;但或许你会问，既然我们已经有了这些数据，为什么还需要依赖强化学习过程呢？答案在于数据的规模。我们可以获取的可能只有 5,000 个示例的数据集，而训练 R1 则需要 600,000 个示例。&lt;/strong&gt; 这个过渡性模型帮助我们缩小了这一差距，并使我们能够合成生成那些极为重要的数据。&lt;/p&gt; 
&lt;p&gt;对于监督式微调（SFT）这一概念，可能你还不太熟悉，它是一种训练过程，通过向模型展示形式为提示词和正确补全的训练示例来进行。下面这个图展示了书籍《Hands-On Large Language Models》第 12 章中的一些 SFT 训练示例：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-e00bd1bb414511cf4a13d9225c9ed6bb7ba.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;2.3.3- 常规强化学习训练阶段&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;这样，R1 模型不仅在推理任务上表现卓越，还能有效地应对其他非推理类任务。这一过程与我们之前提到的强化学习过程相似，但因为它涵盖了非推理领域的应用，所以它还引入了一个实用性奖励模型和安全性奖励模型（与 Llama 模型有相似之处），用于处理这些应用领域的提示词。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-cd6bf829caa63d1804a38dcdf71e88e2293.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 模型架构&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;与 GPT2[2] 和 GPT3[3] 等同源的早期模型一样，DeepSeek-R1 也是由 Transformer[4] 解码器块堆叠而成，总共包含了 61 个这样的块。其中，前三个块是密集层，而后续的则是采用了混合专家层（MoE）。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-817d8e03a6a9f616d918a3f53eb7e8bdede.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;关于模型的维度大小和其他超参数配置，具体信息如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0acee698853f2545eaf2350f4bae0ca92ea.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;有关模型架构的更多详细信息，可以在他们之前发表的两篇论文中找到：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V3 Technical Report[1]&lt;/li&gt; 
 &lt;li&gt;DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models[5]&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;strong&gt;04 Conclusion&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;通过上述内容，相信你现在应该对 DeepSeek-R1 模型有了基本的理解。&lt;/p&gt; 
&lt;p&gt;如果你觉得需要更多基础知识来理解这篇文章，我建议你获取一本《Hands-On Large Language Models》[6]或者在线在 O&#39;Reilly[7] 上阅读，并在 Github[8] 上查看相关内容。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Jay Alammar&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Machine learning R&amp;amp;D. Builder. Writer. Visualizing artificial intelligence &amp;amp; machine learning one concept at a time. @CohereAI.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;❓你觉得 AI 模型最难掌握的是哪种推理能力？欢迎在评论区分享你的观点👇&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2412.19437v1&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2412.19437v1&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-gpt2%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-gpt2/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fhow-gpt3-works-visualizations-animations%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/how-gpt3-works-visualizations-animations/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[4]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fjalammar.github.io%2Fillustrated-transformer%2F&quot; target=&quot;_blank&quot;&gt;https://jalammar.github.io/illustrated-transformer/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[5]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2401.06066&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/2401.06066&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[6]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.llm-book.com%2F&quot; target=&quot;_blank&quot;&gt;https://www.llm-book.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[7]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flearning.oreilly.com%2Flibrary%2Fview%2Fhands-on-large-language%2F9781098150952%2F&quot; target=&quot;_blank&quot;&gt;https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[8]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FhandsOnLLM%2FHands-On-Large-Language-Models&quot; target=&quot;_blank&quot;&gt;https://github.com/handsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fnewsletter.languagemodels.co%2Fp%2Fthe-illustrated-deepseek-r1&quot; target=&quot;_blank&quot;&gt;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/17553692</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/17553692</guid>
            <pubDate>Thu, 06 Feb 2025 10:19:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>豆包开源视频生成模型 VideoWorld</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FmXaktIsD3w5BgCJQb6R7xQ&quot; target=&quot;_blank&quot;&gt;据豆包大模型团队官方公众号消息&lt;/a&gt;&lt;/u&gt;，在北京交通大学和中国科学技术大学的联合研究下，由豆包大模型团队提出的 「VideoWorld」 视频生成实验模型近日正式开源。&lt;/p&gt; 
&lt;p&gt;据介绍，不同于 Sora 、DALL-E 、Midjourney 等主流多模态模型，&lt;strong&gt;VideoWorld 在业界首次实现无需依赖语言模型，即可认知世界&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;论文链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.09781&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.09781&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;代码链接：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2FVideoWorld&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/VideoWorld&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;项目主页：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmaverickren.github.io%2FVideoWorld.github.io&quot; target=&quot;_blank&quot;&gt;https://maverickren.github.io/VideoWorld.github.io&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;「VideoWorld」 通过分析和处理大量视频数据，实现了复杂的推理、规划和决策能力。研究团队的实验显示，模型在仅有 300M 参数的情况下，便取得了显著的效果。与现有依赖语言或标签数据的模型不同，VideoWorld 能够独立进行知识学习，尤其在折纸、打领结等复杂任务中，能够提供更加直观的学习方式。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fc6aac365dbf1a8e0403b8bb24da8452019.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为了验证该模型的有效性，研究团队搭建了围棋对战和机器人模拟操控两种实验环境。围棋作为一项高度策略性游戏，可以有效评估模型的规则学习和推理能力，而机器人任务则考察模型在控制和规划方面的表现。在训练阶段，模型通过观看大量视频演示数据，逐步建立起对未来画面的预测能力。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332996</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332996</guid>
            <pubDate>Thu, 06 Feb 2025 10:00:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DeepSeek 服务站点大全</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;中国信息通信研究院去年 7 月 11 日发布国内首个算力互联公共服务平台，并联合产业界开展算力互联网共识共创行动。&lt;/p&gt; 
&lt;p&gt;该算力互联公共服务平台是推进和管理全国算力互联互通和算力互联网体系的综合服务平台，包括算力标识管理、算力互联网业务查询、算力统一大市场、政策和研究、标准体系、开源项目和运行监测等功能。&lt;/p&gt; 
&lt;p&gt;中国信通院今日宣布，为便利国内 AI 开发者「找调用算力」需求，算力互联公共服务平台宣布增设全球云服务商 DeepSeek 服务能力汇总功能页面（截至 2 月 5 日已汇集 22 家服务商）。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;地址：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstateioc.cn%2Farticle-details%2FVjX&quot; target=&quot;_blank&quot;&gt;https://stateioc.cn/article-details/VjX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;最后欢迎各位使用 Gitee AI —— Gitee AI 的 Serverless API 为您提供开箱即用的企业级的大模型 API 服务。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;em&gt;&lt;a href=&quot;https://ai.gitee.com/serverless-api&quot; target=&quot;_blank&quot;&gt;https://ai.gitee.com/serverless-api&lt;/a&gt;&lt;/em&gt;&lt;/u&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0210/174609_Xr4I_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332995</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332995</guid>
            <pubDate>Thu, 06 Feb 2025 09:46:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>ai.com 域名现已跳转至 DeepSeek</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;现在在浏览器输入&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fai.com%2F&quot; target=&quot;_blank&quot;&gt;ai.com&lt;/a&gt;，将直接重定向至 DeepSeek 官网 (&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fchat.deepseek.com%2F&quot; target=&quot;_blank&quot;&gt;https://chat.deepseek.com/&lt;/a&gt;)。&lt;/p&gt; 
&lt;p&gt;ai.com 域名的定位被视作前沿 AI 的象征，此前这一域名曾长期跳转至 ChatGPT、谷歌 Gemini 以及马斯克的 xAI 官网。根据 Whois 数据，ai.com 域名注册于 1993 年，有效期直至 2031 年 5 月，注册联系人来自马来西亚首都吉隆坡。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;219&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-8ceffc7eb4acfec05d9bcabc263bf478854.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/332978</link>
            <guid isPermaLink="false">https://www.oschina.net/news/332978</guid>
            <pubDate>Thu, 06 Feb 2025 08:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>