<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Fri, 18 Apr 2025 07:36:28 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>如何合理规划 Elasticsearch 的索引</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;h2&gt;一、背景&lt;/h2&gt; 
&lt;p&gt;随着 ES 在业务场景中的使用逐渐增多，平台对 ES 集群的稳定性、管理、运维的压力逐渐增大，通过日常的运维情况来看，发现用户对 ES 的了解熟悉程度参差不齐，经常性的遇到索引创建不规范，或者参考别人索引的创建脚本进行创建索引，对索引没有一个比较清晰的认知，对索引结构的规划也寥寥无几，为此，平台使用了一些列手段来帮助用户提前合理规划模板，比如索引、模板的创建接入飞书审批流，平台侧会逐一结合业务场景和 ES 集群情况详细沟通确定索引或者模板结构；又比如 ES 内核增加业务不停服的动态扩分片能力，旨在进行不合理索引的治理提升 ES 集群稳定性（索引一旦创建分片是不能修改的），我们内部改动 ES&lt;strong&gt;源码实现了不停服动态扩分片。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;因此有必要从 ES 的索引讲起，让大家对 ES 的索引从概念、原理到使用有一个清晰的认知，希望日常业务场景中用到 ES 的同学能够抽时间读一下。当然文章避免不了存在主观的分析，大家可以在文章底部进行评论或者私聊我们，一起探讨。好了废话不多说了，现在开始介绍。&lt;/p&gt; 
&lt;h1&gt;二、什么是 index(索引)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;下面会针对索引的组成和基本结构结合官方文档逐一介绍。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;基本概念&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;index(索引) 是索引是具有相似特征的文档（Document）集合，类似于关系型数据库中的表。每个索引都具有自己唯一的名称与_id。并且可以进行不同的参数配置与 mapping 映射。以适应不同的业务场景。索引中的最小单位是文档。每一条文档 (doc) 都是一个 json 格式的数据对象。包含了实际的具体数据以及该数据所对应的元数据。文档可以是结构化，半结构化或非结构化的数据。索引在 elasticsearch 中被用于存储，检索与分析数据。通过对索引进行搜索与聚合操作可以快速地找到相关的文档。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;官方描述：The index is the fundamental unit of storage in Elasticsearch, a logical namespace for storing data that share similar characteristics. After you have Elasticsearch deployed, you’ll get started by creating an index to store your data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;翻译：索引是 Elasticsearch 中存储数据的基本单位，是一个逻辑命名空间，用于存储具有相似特性的数据。在部署 Elasticsearch 后，您将通过创建索引来存储数据。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;An index is a collection of documents uniquely identified by a name or an alias. This unique name is important because it’s used to target the index in search queries and other operations.&lt;/p&gt; 
 &lt;p&gt;翻译：索引是一种文档集合，通过名称或别名唯一标识。这个唯一名称非常重要，因为它用于在搜索查询和其他操作中定位索引。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;三、索引结构详解&lt;/h1&gt; 
&lt;p&gt;索引结构详解&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-129e7712ef064f085f8595c90ff6913782f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;创建索引结构
PUT /index_demo
{
&amp;nbsp;&amp;nbsp;&quot;aliases&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;index_demo_alias&quot;&amp;nbsp;: { }
&amp;nbsp; },
&amp;nbsp;&amp;nbsp;&quot;mappings&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;properties&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;id&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;long&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;name&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;text&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;fields&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;keyword&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;keyword&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;ignore_above&quot;&amp;nbsp;: 256
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;status&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;keyword&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;createDate&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;long&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; },
&amp;nbsp;&amp;nbsp;&quot;settings&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;index&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;refresh_interval&quot;&amp;nbsp;:&amp;nbsp;&quot;5s&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;number_of_shards&quot;&amp;nbsp;:&amp;nbsp;&quot;3&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;number_of_replicas&quot;&amp;nbsp;:&amp;nbsp;&quot;1&quot;
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ignore_above 属性说明：&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;ignore_above 的默认值通常为 256 个字符，这意味着任何超过 256 个字符的字符串将不会被索引或存储。&lt;/p&gt; 
 &lt;p&gt;- 该参数仅适用于 keyword 类型的字段，因为这些字段主要用于过滤、排序和聚合操作，不需要进行全文搜索。&lt;/p&gt; 
 &lt;p&gt;-&amp;nbsp;ignore_above 的值以字符为单位计算，包括英文字符和汉字。例如，一个汉字和一个英文字符都算作一个字符。&lt;/p&gt; 
 &lt;p&gt;- 性能优化：通过限制字段长度，可以减少索引大小和查询时间，从而提高性能。&lt;/p&gt; 
 &lt;p&gt;- 避免资源浪费：对于包含大量数据的字段，如日志文件中的长字符串，可以通过 ignore_above 避免不必要的存储和索引。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;官方描述：Strings longer than the&amp;nbsp;ignore_above&amp;nbsp;setting will not be indexed or stored. For arrays of strings,&amp;nbsp;ignore_above&amp;nbsp;will be applied for each array element separately and string elements longer than&amp;nbsp;ignore_above&amp;nbsp;will not be indexed or stored.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;3.1 别名&lt;/h2&gt; 
&lt;p&gt;别名将其生命置于群集状态内，由主节点（master node) 管理; 这意味着如果你有一个名为 xiaoming 的别名指向一个名为 potato 的索引，那么开销就是群集状态映射中的一个额外键，它将名称 xiaoming 映射到具体的索引字符串。这意味着与其他指数相比，别名的重量要轻得多; 可以维护数千个而不会对集群产生负面影响。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;官方原话：An alias points to one or more indices or data streams. Most Elasticsearch APIs accept an alias in place of a data stream or index name.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Aliases enable you to:&lt;/p&gt; 
 &lt;p&gt;- Query multiple indices/data streams together with a single name&lt;/p&gt; 
 &lt;p&gt;- Change which indices/data streams your application uses in real time&lt;/p&gt; 
 &lt;p&gt;- Reindex data without downtime&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;翻译：别名（Alias）可以指向一个或多个索引或数据流。大多数 Elasticsearch API 接受别名代替数据流或索引名称。别名的功能包括：&lt;/p&gt; 
 &lt;p&gt;- 使用单一名称查询多个索引/数据流；&lt;/p&gt; 
 &lt;p&gt;- 实时更改应用程序使用的索引/数据流；&lt;/p&gt; 
 &lt;p&gt;- 在不中断服务的情况下进行扩分片。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;可以看到索引有上面三个作用，&lt;strong&gt;平台建议为每个索引添加别名&lt;/strong&gt;（动态扩分片依赖别名）。添加别名可以在索引创建时和创建后再添加，即索引可以随时添加，但是平台还是建议你在创建索引时候指定别名，&lt;strong&gt;避免动态扩分片时候再去修改代码重新部署应用。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;添加别名的几种方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 创建索引时指定别名&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;PUT /test_index
{
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;settings&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;number_of_shards&quot;&amp;nbsp;: 1,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;number_of_replicas&quot;&amp;nbsp;: 1
&amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;aliases&quot;:{&quot;test_alias&quot;:{}},
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;mappings&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;properties&quot;&amp;nbsp;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;field1&quot;&amp;nbsp;: {&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;&amp;nbsp;:&amp;nbsp;&quot;text&quot;&amp;nbsp;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;createdAt&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;type&quot;:&amp;nbsp;&quot;date&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;format&quot;:&amp;nbsp;&quot;yyyy-MM-dd HH:mm:ss&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2. 已存在的索引添加别名&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;POST /_aliases
{
&amp;nbsp;&amp;nbsp;&quot;actions&quot;: [
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;add&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;index&quot;:&amp;nbsp;&quot;test_index&quot;,&amp;nbsp;# 索引名
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;alias&quot;:&amp;nbsp;&quot;test_alias&quot;&amp;nbsp;# 别名
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;3. 别名更换&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;别名更换可以零停机进行动态扩分片。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;POST /_aliases
{
&amp;nbsp;&amp;nbsp;&quot;actions&quot;: [
&amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;add&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;index&quot;:&amp;nbsp;&quot;existing_index&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;alias&quot;:&amp;nbsp;&quot;test_alias&quot;&amp;nbsp;# 别名
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp; {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;remove&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;index&quot;:&amp;nbsp;&quot;old_index&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;alias&quot;:&amp;nbsp;&quot;old_test_alias&quot;&amp;nbsp;# 别名
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; &amp;nbsp; }
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3.2 映射&lt;/h2&gt; 
&lt;p&gt;建立索引时需要定义文档的数据结构，这种结构叫作映射。在映射中，文档的字段类型一旦设定后就不能更改。因为字段类型在定义后，elasticsearch 已经针对定义的类型建立了特定的索引结构，这种结构不能更改。借助映射可以给文档新增字段。另外，elasticsearch 还提供了自动映射功能，即在添加数据时，如果该字段没有定义类型，elasticsearch 会根据用户提供的该字段的真实数据来猜测可能的类型，从而自动进行字段类型的定义。&lt;/p&gt; 
&lt;h2&gt;3.3 字段类型&lt;/h2&gt; 
&lt;p&gt;字段类型（Field Type）是定义数据格式和索引方式的重要概念，它决定了字段在索引中的存储、搜索和聚合行为。下面针对日常用到最多的三个字段类型进行解释，text、keyword、Numeric（Integer、Long）。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Text&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;text 字段类型是 Elasticsearch 中用于全文搜索的核心字段类型。它通过分析器将文本拆分为单个词，并存储为倒排索引，适用于非结构化文本的搜索和分析。然而，由于其经过分析器处理，不适用于排序和聚合操作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 特点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全文搜索：&lt;/strong&gt; text 字段类型主要用于存储和索引可读的文本内容，例如邮件正文、产品描述、新闻文章等。这些字段会被分析器（analyzer）处理，将字符串拆分为单个词（term），以便进行全文搜索。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;分词处理：&lt;/strong&gt; text 字段支持分词器（tokenizer），可以根据语言和需求选择不同的分词策略（如标准分词器、正则表达式分词器等）。分词后的结果会存储为倒排索引，便于快速检索。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不适用于排序和聚合：&lt;/strong&gt; 由于 text 字段经过分析器处理，其原始字符串无法直接用于排序或聚合操作。如果需要排序或聚合，通常需要结合 keyword 字段类型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持多字段映射：&lt;/strong&gt; 可以通过多字段（multi-field）映射同时使用 text 和 keyword 类型，以满足全文搜索和精确匹配的需求。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 使用场景&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全文搜索：&lt;/strong&gt; 适用于需要对文本内容进行模糊搜索的场景，例如搜索引擎、新闻网站、商品搜索等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文本分析：&lt;/strong&gt; 可以结合分析器（如 TF-IDF、BM25 等）进行文本相似性搜索或评分计算。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;日志分析：&lt;/strong&gt; 用于分析和搜索日志文件中的文本内容，提取关键信息。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;内容管理：&lt;/strong&gt; 在内容管理系统中，用于存储和搜索文档、文章等内容。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. 官方建议&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Use a field as both text and keyword&lt;/p&gt; 
 &lt;p&gt;Sometimes it is useful to have both a full text (text) and a keyword (keyword) version of the same field: one for full text search and the other for aggregations and sorting. This can be achieved with multi-fields.&lt;/p&gt; 
 &lt;p&gt;通过多字段映射同时使用 text 和 keyword 类型，可以实现全文搜索和精确匹配的双重需求。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;4. 平台建议&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;明确业务使用场景，如果不需要进行模糊搜索的话，设置为 keyword 类型，来避免分词带来的存储开销，增加系统压力。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Keyword&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;keyword&lt;/em&gt;字段类型是一种用于存储和索引结构化数据的字段类型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 特点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不进行分词：&lt;/strong&gt; keyword 字段类型不会对字段值进行分词处理，而是将其作为整体存储。这意味着字段值会被原样存储到倒排索引中，不会被拆分成单独的单词或短语。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;精确匹配：&lt;/strong&gt; 由于字段值不进行分词，keyword 字段类型非常适合用于精确匹配查询，例如查找特定的电子邮件地址、身份证号或状态码等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;tips：&lt;/strong&gt; 在 term 查询中可以结合 case_insensitive 属性，忽略大小写对值进行搜索，但不支持 terms 查询。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;支持排序和聚合：&lt;/strong&gt; keyword 字段类型可以用于排序和聚合操作，例如按状态码统计数量或按用户 ID 进行分组。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;存储效率高：&lt;/strong&gt; 由于不需要分词，keyword 字段类型的存储开销较低，适合存储大量具有唯一性或固定值的字段。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 使用场景&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;精确查询：&lt;/strong&gt; 适用于需要精确匹配的场景，例如查找特定的电子邮件地址、身份证号、状态码等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;排序和聚合：&lt;/strong&gt; 当需要对数据进行排序或聚合时，keyword 字段类型是理想选择。例如，按用户 ID 排序或按状态统计数量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;标签和分类：&lt;/strong&gt; 用于存储标签、分类等结构化数据，例如用户画像标签（学生、IT、教师等）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;唯一性字符串：&lt;/strong&gt; 适用于存储具有唯一性的字符串，如 SpuId、货号、得物订单号等。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Numeric&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;数值类型，包含 long、interger、short、byte、double、float 等数字类型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 特点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;整数类型：&lt;/strong&gt; 适用于范围查询、排序和聚合操作。由于整数类型占用空间较小，推荐优先使用范围较小的类型（如 integer 或 long）以提高索引和搜索效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;浮点类型：&lt;/strong&gt; 适用于需要高精度的计算场景。如果数据范围较大或精度要求不高，可以使用 scaled_float 类型并设置合适的 scale 值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;选择合适的类型：&lt;/strong&gt; 在满足需求的前提下，尽量选择范围较小的类型以节约存储空间和提升性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;tips&lt;/p&gt; 
 &lt;p&gt;如果确定业务使用场景，建议 keyword 代替数值类型字段，如果不确定则采用多字段，keyword 在 term 查询中性能更佳。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3306ddf8b4bb4953bf98c9e87c6e92ac196.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;3.4 针对字段类型选择的几条建议&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;针对 Text 和数值类型场景的字段，尽量改成 keyword 字段类型，来提升查询速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在不确定业务查询有哪些需求的情况下，设置多字段类型 keyword。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;枚举字段没有特殊业务场景下，统一使用 keyword 字段类型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;业务不需要范围查询的话，使用 keyword 字段类型（支持聚合和排序的）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对 keyword 字段类型进行模糊查询会性能较差，使用多字段类型 wildcard 来模糊查询性能更高。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;尽量不要使用聚合查询，text 的 fielddata 会加大对内存的占用，如有需求使用，建议使用 keyword。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;需要中文分词的话，不要使用默认分词器，推荐使用 ik_smart，ik_max_word 会生成更多的分词，其中含有重复的内容，需谨慎使用。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;时间字段不要使用 keyword，除非点查，推荐使用 date/long 类型，支持范围查询，建议精确到分钟，会提高查询效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;keyword 字段类型不适用于模糊 wildcard 查询，建议使用 wildcard 字段类型。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5c0c872ccde433d906584724b29b1c11cc0.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;日期的查询条件为 now 时，并不能有效利用缓存，尽量换成绝对时间值。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ES 默认字段个数最大 1000，但建议不要超过 100，对于不需要建立索引的字段，不写入 ES。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;将不需要建立索引的字段 index 数据设置为 false，对字段不分词，不索引可以减少很多运算操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;不建议或者禁止每次写入后立马进行显示的 refresh，refresh 会带来较高的磁盘 IO，和 CPU 消耗，甚至有可能导致 ES 宕机。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;持续补充......&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;3.5 索引结构与关系性数据库对比&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-951b6c3a4fdf40ef6d7829c7863f2b4da95.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;四、索引 (Shard) 结构-分片与副本&lt;/h1&gt; 
&lt;h2&gt;4.1 什么是 Shard&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;基本概念&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;分片是管理文档的一个数据单元，分片是 Elasticsearch 中逻辑概念。ES 内部把索引中文档进行按照一定路由规则（文档_id 的 hash 值与分片数取余）进行路由到不同的存储数据单元，存储数据单元就是分片。你可以理解为 MySQL 的分表。&lt;/p&gt; 
&lt;p&gt;ElS 的逻辑分片就是一个 Lucene 索引，一个 ES 索引是分哦的集合，当 ES 在索引中搜索的时候，他发送查询到每一个属于索引的分片（Lucene 索引）进行检索，最后合并每个分片的结果得到一个全局的结果集。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分片划分&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;分片分为&lt;strong&gt;primary shard(主分片)&lt;/strong&gt; 和 &lt;strong&gt;replicate shard(副本分片)&lt;/strong&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;主分片：&lt;/strong&gt; 索引的基本数据存储单元，每个索引被水平拆分为多个主分片，每个分片都是互相独立的。包含一部分索引的数据与索引的结构 (segement)。每个分片都可以在集群中不同的节点上进行移动与复制。以提高数据的可用性与容错性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;副本分片：&lt;/strong&gt; 主分片的完整拷贝，用于冗余存储和容灾，副本分片和主分片在 ES 节点数足够的情况下不会同时存在一个 ES 节点。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;注意：单分片的记录条数不要超过上限 2,147,483,519。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;主副分片分布示意图&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3eb972387527c130877697c27743f14a261.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分片的功能&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. 主分片&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数据存储与写入：&lt;/strong&gt; 所有文档通过路由算法（如&amp;nbsp;hash(_id) % num_primary_shards（主分片数））分配到主分片，主分片负责处理索引、更新、删除等写操作。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;扩展性：&lt;/strong&gt; 通过增加节点和分片分布，实现数据的水平扩展。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;不可变性：&lt;/strong&gt; 主分片数量在索引创建时通过&amp;nbsp;number_of_shards&amp;nbsp;参数设定，创建后无法修改（需重建索引）。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 副本分片&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;高可用性：&lt;/strong&gt; 当主分片所在节点宕机时，副本分片自动升级为主分片（和对应的主分片不在一个节点），避免数据丢失和服务中断。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;读取负载均衡：&lt;/strong&gt; 副本分片可并行处理查询请求，提升读吞吐量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;动态调整：&lt;/strong&gt; 副本分片数量通过&amp;nbsp;number_of_replicas&amp;nbsp;参数动态配置，支持按需扩展或缩减。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;4.2 分片数规划&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;分片的基本概念和功能咱们咱们已经了解，在日常 ES 运维过程中发现不少同学对分片和数量的设置没有什么概念，照搬其他同学的比较多，这是严重错误的。咱们在实际的业务场景中也要做好分片（主副）数量的规划，来避免慢查、数据倾斜、磁盘容量浪费等问题。&lt;/p&gt; 
 &lt;p&gt;当索引分片数量过多时，可能会对 ES 性能产生不利影响。因为每个分片都需要一定量的内存来存储索引数据和缓存，从而导致内存消耗增加。另外当查询或写入数据涉及多个分片时，ES 需要在节点之间进行传输和协调数据，从而增加网络开销，这也会导致查询和写入性能的降低。可见分片数量的选择需要慎重考虑。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;索引在不同场景中，其分片分设置是不一样的，接下来咱们会在下面四个场景中来进行阐述。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;读场景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;索引单分片 20g~40g，尽量减少分片数，可以降低热点，因为当分片数过多时，就容易出现长尾子请求，即有可能部分子请求因 ES 集群节点异常、Old GC、网络抖动等延迟响应，导致整个请求响应缓慢。另一方面，拆分过多的子请求无法提升数据节点请求吞吐，不能充分利用 CPU。在尽量减少主分片数的情况下，同时也可以适当增加副本数，从而提升查询吞吐。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;写场景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;索引单分片 10g~20g，小分片更有利于数据写入。小分片维护的 segment 数量远低于大分片，在数据刷新落盘与段合并上更有优势。由於单分片数据量更少，在写入时数据可以更快地缓存至内存中并通过 refresh 参数更快的持久化至磁盘中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;日志存储场景&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;需要考虑每日写入集群的数据总量大小。通过过数据量与数据节点数评估索引分片数量。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在日志存储后是否需要兼顾查询与聚合性能。合理大小的分片数据量能够提高查询效率。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;根据日志持久化策略，采用按月/周/天的策略生成索引。并使用 ILM(索引生命周期管理策略) 动态对日志索引进行完整生命周期的管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;建议副本数设置为 0 来减少磁盘容量成本。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;小数据量索引业务场景&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于数据量比较小的索引，增加索引分片数并不一定会带来性能提升，反而可能会带来一些负面影响。&lt;/p&gt; 
&lt;p&gt;首先，增加索引分片数会增加集群的管理开销，包括维护分片的状态、备份和恢复分片等。如果索引数据量比较小，这种开销可能会超过性能提升带来的收益。&lt;/p&gt; 
&lt;p&gt;其次，增加索引分片数可能会导致数据分布不均衡，从而影响查询性能。具体来说，如果某些分片中的数据量过小，可能会导致这些分片的查询性能比其他分片差。此外，如果查询涉及到多个分片，数据的合并操作也会增加查询时间。&lt;/p&gt; 
&lt;p&gt;因此，对于数据量比较小的索引，在查询场景下，通常建议将分片数设置为 1 或 2，以避免不必要的开销和性能问题。如果需要提高查询性能，可以考虑配置索引副本，优化查询语句或使用缓存。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;通用场景&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;根据实际业务场景提前规划预算索引数据量，做好分片数量规划（索引一旦创建无法修改分片数）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;分片数量：推荐公式：主分片数 ≈ 总数据量 / 单分片容量上限（官方建议单分片 10-50GB，单个分片文档数在 1 亿条以内，日志场景可放宽至 50-100GB）。&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;注意：分片数量平台强烈建议或者要求设置为 ES data 节点角色的整数倍。&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;副本数量：增加副本数可提升读性能，但会降低写入速度（需同步更多副本），因此在读场景可以酌情考虑。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果索引是时序类，或者数据过大，单分片几百 G，可以结合生命周期和索引模板进行索引滚动管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;平台不建议使用自动移 routing 值进行分片，默认使用文档_id 就好。&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;原因：使用自定义 routing 值进行路由分片的话很容易产生数据倾斜，另外 ES 内部会多一些计算逻辑来如何进行分片路由，在写入较高的场景下也会有一定的性能损耗。&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;控制分片数量，分片数不是越多越好，过多分分片，也会造成 ES 集群元数据管理的压力，降低系统的性能损耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;设置 total_shards_per_node，将索引压力分摊至多个节点。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;index.routing.allocation.total_shards_per_node 参数可以限制每个节点上的 shard 数量，从而将索引的压力分摊到多个节点，这样可以提高集群性能和可用性，避免某个节点过载导致整个集群出现问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;index.routing.allocation.total_shards_per_node 是一个索引级别设置（创建索引和对已有索引进行设置），语法如下：&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;PUT&amp;nbsp;&amp;lt;index_name&amp;gt;/_settings
{
&amp;nbsp; &amp;nbsp; &quot;index.routing.allocation.total_shards_per_node&quot;:&amp;lt;number_of_shards&amp;gt;
}
&amp;lt;index_name&amp;gt;为索引名字，&amp;lt;number_of_shards&amp;gt;表示每个节点上该索引的分片数量。
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;持续调整索分片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对于集群分片的调整，通常不是一蹴而就的。随着业务的发展，不断新增的子业务，或 原有子业务规模发生突变，都需要持续调整分片数量。&lt;/p&gt; 
&lt;h2&gt;4.3 索引与资源消耗的关系&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;分片数量与内存消耗&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;每个分片都是独立的 Lucene 索引，需要维护倒排索引、缓存等内存结构。分片数量过多会导致以下问题：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;内存占用激增：&lt;/strong&gt; 每个分片默认占用约 10-30MB 内存（含元数据），数千分片可能消耗数十 GB 内存。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;文件句柄耗尽：&lt;/strong&gt; 集群总分片数过多会占用大量文件描述符，可能触发&quot;too many open files&quot;错误。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;CPU 热点问题：&lt;/strong&gt; 分片分配不均会导致部分节点负载过高。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Segment 碎片化&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;分片由多个 segment 组成，segment 数量过多会：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;增加 IO 压力：&lt;/strong&gt; 查询需遍历多个 segment 文件。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;占用堆内存：&lt;/strong&gt; 每个 segment 需加载部分元数据到内存，百万级 segment 可能消耗数 GB 内存。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;影响 GC 效率：&lt;/strong&gt; 频繁的 segment 合并会触发 Full GC。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;五、总结&lt;/h1&gt; 
&lt;p&gt;创建一个索引需要结合业务使用场景考量字段类型选择和是否需要索引分词，按照数据规模和业务增长速度来确定分片和副本的数量的大小。索引的结构直接影响集群的稳定性，因此我们在创建索引的时候要养成习惯，作为技术方案的一环去仔细打磨这样才能保证线上的稳定性。&lt;/p&gt; 
&lt;p&gt;大家工作中遇到的一些稳定性问题，和使用上的一些问题都可以找我们一起探讨，寻找最优解。&lt;/p&gt; 
&lt;p&gt;文 / 阳光&lt;/p&gt; 
&lt;p&gt;关注得物技术，每周一、三更新技术干货&lt;/p&gt; 
&lt;p&gt;要是觉得文章对你有帮助的话，欢迎评论转发点赞～&lt;/p&gt; 
&lt;p&gt;未经得物技术许可严禁转载，否则依法追究法律责任。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5783135/blog/18167537</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5783135/blog/18167537</guid>
            <pubDate>Fri, 18 Apr 2025 07:32:24 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>字节跳动开源 Godel-Rescheduler</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;字节跳动&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FLJ-I7DDrqL7_-e9-tdVqVQ&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;开源 Godel-Rescheduler，一个基于全局最优调度策略的重调度框架。不仅能识别集群中的异常节点和任务，还能智能推荐任务到最合适的位置，并通过图算法生成详细的迁移步骤，确保集群的整体稳定性，真正实现全局最优调度。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Godel-Rescheduler 由两个核心模块组成：Policy Manager 和 Movement Manager。其中，Policy Manager 负责输出重调度决策，而 Movement Manager 则负责拆解并执行这些决策。整个框架的目标是通过重调度，使集群朝向全局最优状态发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;361&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4c02b26fb541ccdf67a167df4122427eb4.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，字节跳动已经成功将 Godel-Rescheduler 应用到多个内部项目中，支持多种重调度策略的协同工作。例如：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;合并部署重调度：优化上下游应用实例在相同节点上的调度。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;负载均衡重调度：在负载、内存带宽、网络带宽等方面进行优化。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;碎片整理重调度：有效减少 CPU、GPU 等资源的碎片率等。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在实际应用中，Godel-Rescheduler 已帮助字节跳动的数万卡 GPU 集群将碎片率控制在 5% 以下，同时在大规模混合部署集群中，热点节点比例控制在 0.1% 以下。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;接下来，Godel-Rescheduler 将持续扩展和优化：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;更多重调度策略：引入更多实时数据，以丰富调度策略的多样性。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;稳定性建设：在优化调度效果的同时，持续降低重调度对集群稳定性的影响。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;扩展性优化：进一步简化策略接入方式，提升插件化能力。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;通用指标构建：制定通用的重调度评价指标，以全面评估调度效果。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;优化可解释性：增强重调度算法的可解释性，帮助用户更好地理解调度决策的依据。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345304</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345304</guid>
            <pubDate>Fri, 18 Apr 2025 06:50:24 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>微软开源 DeepSeek-R1 魔改版「MAI-DS-R1」：响应 99% 敏感提示、风险降 50%</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;微软今天开源了一款「魔改版」的 DeepSeek-R1 模型&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcommunity.microsoft.com%2Fblog%2Fmachinelearningblog%2Fintroducing-mai-ds-r1%2F4405076&quot; target=&quot;_blank&quot;&gt;「MAI-DS-R1」&lt;/a&gt;，其在保留原有推理性能的基础上进行了大幅度增强，尤其是在响应和屏蔽词方面有了显著改进：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;MAI-DS-R1 可以响应 99.3% 的敏感话题提示，比原版 R1 提升了 2 倍，这对于政治学术研究、社会问题、伦理道德研究等帮助巨大；但在安全风险大幅度降低，比原版 R1 降低了 50%。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1d053e10b28247309a20e59106571c44164.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，MAI-DS-R1 是后训练优化的 DeepSeek-R1 模型，微软在训练 MAI-DS-R1 的过程中，从大约 350000 个被屏蔽的主题示例中，收集和筛选查询关键词，将这些关键词转化为多个问题，并翻译成不同语言；还通过 DeepSeek R1 和内部模型为这些问题生成答案和思维链。&lt;/p&gt; 
&lt;p&gt;此外，训练数据中还纳入了来自 Tulu3 SFT 数据集的 110K 个安全和违规示例，这些示例涵盖了 CoCoNot、WildJailbreak 和 WildGuardMix 等内容。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height=&quot;684&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0418/142835_hjBJ_2720166.png&quot; width=&quot;1456&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fmicrosoft%2FMAI-DS-R1&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/microsoft/MAI-DS-R1&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;随后，微软对 MAI-DS-R1 进行了综合评估。在敏感话题响应方面，MAI-DS-R1 能够成功响应 99.3% 的敏感话题提示，这一表现显著优于 DeepSeek R1 和 R1-1776。&lt;/p&gt; 
&lt;p&gt;在安全性评估方面，MAI-DS-R1 在 HarmBench 评估中表现出色，相比 DeepSeek R1 和 R1-1776，在减少有害内容方面降低了 50% 风险。这说明虽然 MAI-DS-R1 能响应更多的敏感话题，但还是在安全控制范围之内。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-823d2f8af8e3a7240c9af642f78b87839a3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;总而言之，&lt;span&gt;那些想体验一下「放飞自我」版 R1 的小伙伴们可以试试这个，体验一下打开全新世界。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345301/microsoft-mai-ds-r1</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345301/microsoft-mai-ds-r1</guid>
            <pubDate>Fri, 18 Apr 2025 06:38:24 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>法官裁定谷歌非法垄断，或迫使其拆分广告业务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;美国联邦法院的最新一项裁决&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fstorage.courtlistener.com%2Frecap%2Fgov.uscourts.vaed.533508%2Fgov.uscourts.vaed.533508.1410.0.pdf&quot; target=&quot;_blank&quot;&gt;判定&lt;/a&gt;&lt;span style=&quot;color:#000000&quot;&gt;，谷歌因「故意获取并维持广告技术市场的垄断权」而违反了反垄断法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;324&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8593d22fd40b0ddabcd20daec14ace9e49.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据周四提交的文件，当地法院将制定简报时间表和听证日期，以确定针对反垄断违法行为的适当补救措施。补救措施可能包括迫使谷歌拆分其广告业务，例如出售其谷歌广告管理器，其中包括 AdX 广告交易平台和 DFP（DoubleClick for Publishers），即用于发布商的广告服务器。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;或者，法院可以强制采取行为补救措施，允许谷歌保持其业务完整，但会施加限制以确保公平竞争，例如禁止谷歌在拍卖中优先考虑自己的交易或需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对此，谷歌监管事务副总裁 Lee-Anne Mulholland 在一封电子邮件声明中&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F04%2F17%2Fjudge-rules-google-illegally-monopolized-ad-tech-opening-door-to-potential-breakup%2F&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;：「我们赢了一半的官司，剩下的一半我们会上诉。法院裁定，我们的广告商工具和收购（例如 DoubleClick）不会损害竞争。我们不同意法院关于我们发布商工具裁决。发布商有很多选择，他们选择谷歌是因为我们的广告技术工具简单、实惠且有效。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，在另一起反垄断案件中，另一位美国联邦法官去年裁定谷歌非法垄断了整个互联网搜索市场。该法官尚未就该案发布救济措施，但预计将在 2025 年中期发布。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;相关阅读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.oschina.net/news/321046/usa-justice-departmen-google-sell-chrome&quot; target=&quot;_blank&quot;&gt;美国司法部将推动谷歌出售 Chrome，以打破垄断&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt; &lt;p style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/339992/eu-apple-google-breached-dma-antitrust-rules&quot; target=&quot;_blank&quot;&gt;欧盟认定苹果、谷歌违反了 DMA 反垄断法规&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345292/judge-rules-google-illegally-monopolized-ad-tech</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345292/judge-rules-google-illegally-monopolized-ad-tech</guid>
            <pubDate>Mon, 14 Apr 2025 06:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 研究员姚顺雨：AI 将由解决问题转为定义问题</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;上半场是预训练，是用算法、架构解决问题；&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;下半场，是 RL 终于起作用了，要做的是定义问题和评估。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;日前，毕业于清华大学姚班，现任 OpenAI 研究院的姚顺雨&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fysymyth.github.io%2FThe-Second-Half%2F&quot; target=&quot;_blank&quot;&gt;发布博文&lt;/a&gt;，探讨了其对 AI 未来的发展预测。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0418/141654_PIy5_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;姚顺雨回顾了 AI 的发展历史。其表示，几十年来 AI 主要致力于开发新的训练方法和模型，取得了显著成就，而这些成就都源于基础性创新，例如搜索、深度强化学习（Deep RL）和推理能力。而如今，深度强化学习终于开始泛化，AI 为人类赋能的局面也得到了变化。&lt;/p&gt; 
&lt;p&gt;姚顺雨认为，随着强化学习的突破，AI 开始解决多样化的任务，如软件工程、创意写作和 IMO 级别的数学问题。通过语言和推理的引入，AI 能够跨领域泛化任务，解决复杂问题。姚顺雨还提到，AI 的下半场将由解决问题转向定义问题，评估方法的创新将成为关键。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-480072bbbfa62fc4f00ed636ff4dd3b6404.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此外，姚顺雨还表示，传统的评估方法已难以应对复杂的现实需求，AI 需要具备长时记忆和适应能力。他强调，新的评估方式应着眼于实际应用，推动 AI 产品的效用和商业价值，为行业带来更大的创新和影响。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345290/ysy-the-second-half</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345290/ysy-the-second-half</guid>
            <pubDate>Mon, 14 Apr 2025 06:18:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>八大金刚、网红斗舞，深圳具身智能马拉松跑到哪了</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;240&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-24b7a055d82f59792efc41afa7dc6813fd5.gif&quot; width=&quot;424&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;清明假期，拥有 3800 万国际粉丝的网红「甲亢哥」 Speed 中国行旅程来到了深圳站，打卡「深圳特色」——与人形机器人互动、一起跳舞。这个直播片段在全球的观看量预估超 5000 万，成了对外展示深圳的一个重要切面。直播间弹幕刷屏的「China Tech」也传达出一个信息——具身智能技术的研究正飞速进步，而拥有完备机器人产业链的深圳也正通过技术与文化的深度融合，以人形机器人+超级 IP 的破圈效应，为全球人机协作标注中国座标。&lt;/p&gt; 
&lt;p&gt;再往前倒 2 个月，蛇年春节后，「深圳具身智能八大金刚」这一概念在科技圈不胫而走。这一称号所指的具体企业虽未完全公开，但结合政策动向、融资动态与技术路径，可能性较高的是优必选、普渡科技、逐际动力、众擎机器人、帕西尼感知科技、跨维智能、数字华夏和智平方这 8 家企业。除了「八大金刚」，深圳还聚集了星尘智能、桥介数物、灵触科技等具身智能企业，这些企业也不乏亮眼的研究。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;496&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3927e44e562fa58c54b669c5c6642e1f6f7.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;透过这些具身智能公司的主要研究方向与成果，我们也能窥见整个具身智能研究的核心范式迁移与技术收敛趋势：技术上，感知、决策、行动三大学科正从「孤立优化」转向「闭环耦合」；应用层面，具身智能体正从「任务专用型」向「通用适应型」跃迁。比如此前专注触觉感知的帕西尼，已通过异构感知-控制联合训练推出首款人形机器人&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.paxini.com%2Frobot&quot; target=&quot;_blank&quot;&gt;TORA-ONE&lt;/a&gt;，其双手内搭载近两千个帕西尼自主研发生产的 ITPU 多维触觉传感单元，拥有 0.01N 的精准力控能力，能实现物体 6D 位姿识别与柔性抓取，可以广泛应用于工业制造、精密制造、医疗康养、仓储物流等多种场景。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_1&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;技术线：婴儿学步和超感官并存&lt;/h2&gt; 
&lt;p&gt;广义上的具身智能是指具有物理形态的智能体，除了人形机器人外，智能车、四足机器狗等等都囊括其中。随着灵巧手、人形机器人研发的加速，现在我们提到的具身智能常用来专指人体形态的智能体。这类机器人无论是在外形上还是行动上，都在朝着「无限接近真实人类」的目标出发。&lt;/p&gt; 
&lt;p&gt;人类的大脑与身体构造，可以简单概括为一条「感知-认知-控制」闭环链路：五感负责接收外界信息；大脑皮层整合多模态信息并生成决策；脊髓与周围神经系统传递信号；小脑实时协调运动肌群完成动作；成年人体拥有 206 块骨骼、约 360 个关节，主要活动关节 86 个，运动自由度达可以达到 230+。&lt;/p&gt; 
&lt;p&gt;参照人类生理结构，具身智能机器人的研发可解构为以下核心模块：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;感知层：替代人类五感，包括激光雷达（视觉）、六维力传感器（触觉）、IMU（前庭平衡觉）等；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;机器人大脑：主导认知与决策，大模型技术突飞猛进后，具身智能的决策系统研究开始依赖多模态大模型实现因果推理；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;机器人小脑：运动控制中枢，通过模型预测控制、全身协同控制等算法实现毫米级精度；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;行动层：对应人体肌肉与骨骼系统，由伺服电机（肌肉）、谐波减速器（肌腱）、碳纤维连杆（骨骼）等构成执行机构。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;442&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-46dfde3c6af89e66cbc31685a382a623fad.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从这 4 个角度出发，也能很直观看出现有的机器人和人类之间差距。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_2&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;感知&lt;/h3&gt; 
&lt;p&gt;感知方面，机器人已初步构建起与人类五感对应的传感器体系，但是在感知精度和不同感官的配合上还有差距。比如，人眼对运动物体的识别反应最快接近 0.1 秒，如接住飞来的棒球。而机器人依赖多维感知+计算，面对快速移动物体时决策延迟达有时可能达到 0.3-0.5 秒甚至更长。此外，人的五感配合非常丝滑，比如看到地面积水，脚底触觉感知到鞋底打滑，立刻便能判断摔倒风险，但机器人可能因传感器数据冲突，激光雷达与 IMU 的位姿误差，导致动作卡顿。&lt;/p&gt; 
&lt;p&gt;但机器人在感知的「生物合理性」上存在硬伤：视觉系统依赖人工标注数据集，无法像人类婴儿般通过自监督学习理解未知物体。更关键的是，多模态数据的时空对齐误差可达 10ms 级，而人类神经传导延迟仅 1ms，这会导致机器人面对动态场景时易出现「感官割裂」——例如当激光雷达检测到前方障碍物时，惯性导航单元可能因振动干扰传递错误位姿数据，引发运动控制冲突。&lt;/p&gt; 
&lt;p&gt;不过，有时候机器人也会拥有人类无法企及的「超感官」能力，比如工业分拣机器人通过太赫兹成像检测材料内部缺陷，农业机器人利用多光谱相机分析作物病虫害，核电站检修机器人搭载 γ 射线传感器定位辐射源等等。这些超越生物极限的感知手段，正在特定垂直领域重构生产力标准。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_3&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;大脑&lt;/h3&gt; 
&lt;p&gt;传统机器人决策系统依赖分层架构，如 ROS MoveIt 通过集成采样、优化算法等实现运动规划，并与基于规则的状态机协同。新兴具身智能企业则引入百亿参数级多模态大模型，如智平方自主研发的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FcuVzo0CjphIEt7lV7GM63g&quot; target=&quot;_blank&quot;&gt;AI2R Brain 具身大模型，已成功部署于 Alpha Bot 系列机器人&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;从这个角度看，现有的大语言模型虽在文本理解、逻辑推理等任务中表现显著，但其能力边界高度依赖训练数据的规模与质量，GPT-4 的训练语料库涵盖约 13 万亿 token 的文本数据，接近人类个体一生阅读量的数千倍。这种数据暴力美学使 LLMs 能够模拟人类语言模式，但仍然存在无法解释、不可避免的幻觉。&lt;/p&gt; 
&lt;p&gt;相比之下，具身智能的决策系统面临更严峻的数据瓶颈。以动作-状态对为单位计算，当前全球可用的高质量具身智能数据集总量预估是千万级，而且数据模态复杂，需要同步记录视觉、力觉、关节位姿等信号，所以扩展起来也十分费劲。几个知名具身数据集覆盖的场景也有限：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;RoboMIND：汇聚了来自 Franka Emika Panda、Tien Kung、AgileX Cobot Magic V2.0 和 UR5e 四种不同机器人实体的海量数据，目前总计约十万条轨迹，年底将达到三十余万条。轨迹涵盖了 479 个任务、96 个不同的物体类别以及 38 项操作技能。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AgiBot World：全球首个基于全域真实场景、全能硬件平台、全程质量把控的百万真机数据集。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Meta Ego4D：最大规模开源数据集，含 4000 小时第一视角视频+3D 关节数据，但仅覆盖日常交互场景。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;斯坦福 BEHAVIOR：包含 1000 种家庭任务仿真数据，但物理引擎精度误差达 15%。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;DeepMind Open X-Embodiment：整合 22 种机器人形态的 50 万条操作记录，但硬件异构性导致跨平台泛化率不足 30%。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;这种数据稀缺性源于两大挑战：一是采集成本高昂，单台人形机器人采集 1 小时多模态数据，需要用到 RGB-D 相机+六维力传感器+IMU，成本较高，且需专业工程师全程监控；二是标注效率低下，需要人类标注员二次处理机器人操作视频的数据。&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1821723693588178341%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;有业内人士估算&lt;/a&gt;，特斯拉的人形机器人 Optimus 至少需要数百万小时的数据才能完全准备好在特斯拉工厂工作，这期间可能需要至少 5 亿美元的数据采集成本。&lt;/p&gt; 
&lt;p&gt;高昂的采集成本也拖慢了具身智能数据的收集进度。目前业界的解决方式多是叠加「仿真+迁移」的技术，在虚拟环境中生成数亿条廉价数据预训练，再通过少量真实数据微调。但仿真器与现实的「物理鸿沟」仍导致实际场景性能损失 40% 以上。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_4&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;小脑&lt;/h3&gt; 
&lt;p&gt;在机器人运动控制领域，「小脑」技术的核心挑战在于复现生物神经系统的高效性与鲁棒性。&lt;/p&gt; 
&lt;p&gt;人类小脑通过约 690 亿神经元构成的微电路，以毫秒级延迟协调全身 600 余块肌肉，功耗不足 5 瓦，却能在湿滑路面行走、接住意外抛来的钥匙等动态场景中展现惊人的适应性。&lt;/p&gt; 
&lt;p&gt;传统方法依赖于精确的物理建模和数学推导，强调理论框架的完备性，但开发周期长、适应性有限。比如动力学模型控制，需建立复杂的运动学与动力学模型，通过在线优化计算生成轨迹，但依赖高精度传感器和实时计算，对动态环境适应性差，难以应对复杂地形或突发扰动。此外还有模型预测控制（MPC），通过预测未来数步的动力学状态，优化当前控制输入，缺点是计算复杂度高，非线性模型求解速度慢，仅适用于特定步态或场景。&lt;/p&gt; 
&lt;p&gt;随着 AI 技术的发展，数据驱动的学习算法逐渐成为主流，显著降低开发门槛并提升适应性。比如过仿真环境设计奖励机制，让机器人自主探索最优策略。&lt;/p&gt; 
&lt;p&gt;又或是仿真学习，通过人类示教或动作捕捉数据生成运动策略。目前，桥介数物也正是通过 learning-based 的方式，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.dutenews.com%2Fn%2Farticle%2F8793981&quot; target=&quot;_blank&quot;&gt;让机器人在仿真环境中通过深度强化学习自主学会行动策略&lt;/a&gt;，将开发周期从数月缩短至数天。&lt;/p&gt; 
&lt;p&gt;然而，这类算法的工程化落地仍面临一些困境，比如动态环境建模的物理鸿沟，仿真器中训练的模型因摩擦系数、空气阻力等参数误差，迁移到真实场景时成功率会有所下降；此外还有算力与能效的失衡问题，双足机器人实时运动控制需要的功耗远超人类小脑同等任务功耗。&lt;/p&gt; 
&lt;span id=&quot;OSC_h3_5&quot;&gt;&lt;/span&gt; 
&lt;h3&gt;行动&lt;/h3&gt; 
&lt;p&gt;行动上的进步很明显，比如去年走都走不稳的人形机器人，今年已经可以和人类一起跳手绢舞、斧头舞，完成后空翻等各种动作了。在机器人行动层技术的研究中，核心目标是通过仿生结构与驱动系统的协同设计，逼近甚至超越人类运动系统的效率与适应性。&lt;/p&gt; 
&lt;p&gt;人类的行动自由度大概在 200-300 范围，可以实现许多精细动作，比如人的单只手掌的 27 个自由度允许抓握从鸡蛋到扳手的全品类工具。相比之下，当前人形机器人的行动层仍受制于机械设计的物理桎梏：能与人类共舞的众擎机器人 SE01 已经走在业界前沿，其&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.engineai.com.cn%2Fproduct_one&quot; target=&quot;_blank&quot;&gt;32 个自由度&lt;/a&gt;虽能完成前空翻等高动态动作，但执行叠衣、拧瓶盖等精细任务时，其手部动作与人类手指的连续柔顺控制存在代际差距。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;238&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b11e15e9dda43fca3315dfafa613237102c.gif&quot; width=&quot;426&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;此前曾被视作机器人巅峰之作的波士顿动力 Atlas 也仅有 28 个自由度，背后也是高昂的成本在支撑。为了降低成本，提升性能，波士顿动力公司正转向全电驱动技术的研究。即便如此，这样一个机器人的售价也在&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.163.com%2Fdy%2Farticle%2FJQHOBGHC0511D0C3.html%23%3A%7E%3Atext%3D%25E5%25BD%2593%25E5%2589%258D%25E7%2589%2588%25E6%259C%25AC%25E7%259A%2584Atlas%25E9%25A2%2584%25E8%25AE%25A1%25E5%2594%25AE%25E4%25BB%25B7%25E5%259C%25A815%25E4%25B8%2587%25E7%25BE%258E%25E5%2585%2583%25E5%25B7%25A6%25E5%258F%25B3%25E3%2580%2582%2C%25E8%25BF%2599%25E4%25B8%25AA%25E4%25BB%25B7%25E6%25A0%25BC%25E8%2599%25BD%25E7%2584%25B6%25E4%25B8%258D%25E8%258F%25B2%25EF%25BC%258C%25E4%25BD%2586%25E8%2580%2583%25E8%2599%2591%25E5%2588%25B0%25E5%2585%25B6%25E5%25BC%25BA%25E5%25A4%25A7%25E7%259A%2584%25E5%258A%259F%25E8%2583%25BD%25E5%2592%258C%25E6%25BD%259C%25E5%259C%25A8%25E7%259A%2584%25E6%258A%2595%25E8%25B5%2584%25E5%259B%259E%25E6%258A%25A5%25EF%25BC%258C%25E5%25AF%25B9%25E4%25BA%258E%25E5%25A4%25A7%25E5%259E%258B%25E5%2588%25B6%25E9%2580%25A0%25E4%25BC%2581%25E4%25B8%259A%25E6%259D%25A5%25E8%25AF%25B4%25E4%25BB%258D%25E5%2585%25B7%25E6%259C%2589%25E4%25B8%2580%25E5%25AE%259A%25E5%2590%25B8%25E5%25BC%2595%25E5%258A%259B%25E3%2580%2582%2520%25E6%259C%2589%25E8%25B6%25A3%25E7%259A%2584%25E6%2598%25AF%25EF%25BC%258C%25E5%259C%25A8Atlas%25E4%25B9%258B%25E5%25A4%2596%25EF%25BC%258C%25E5%25B8%2582%25E5%259C%25BA%25E4%25B8%258A%25E4%25B9%259F%25E5%2587%25BA%25E7%258E%25B0%25E4%25BA%2586%25E4%25B8%2580%25E4%25BA%259B%25E6%259B%25B4%25E7%25BB%258F%25E6%25B5%258E%25E7%259A%2584%25E9%2580%2589%25E6%258B%25A9%25E3%2580%2582&quot; target=&quot;_blank&quot;&gt;15 万美元左右&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;从每个细分技术场景来看，也就不难解释，为什么机器人在许多日常生活场景中难以复刻人类的灵活与直觉，但是常常在一些人类实现不了地方取得意外之喜。想让机器人既能跳得了舞、切得了钻石、做得了手术，又能剥完整鸡蛋，还有很长的路要走。&lt;/p&gt; 
&lt;span id=&quot;OSC_h2_6&quot;&gt;&lt;/span&gt; 
&lt;h2&gt;供应链：从以月为单位到当天送达&lt;/h2&gt; 
&lt;p&gt;「这不是一家公司的事情。」&lt;/p&gt; 
&lt;p&gt;我们常常能从具身智能企业那里听到这句话。动辄十亿级的研发资金需求，全球范围内稀缺的复合型人才，以及从毫米级触觉传感器到千瓦级关节模组的超长产业链，让具身智能乃至整个机器人产业不仅仅需要上下游的配合，更需要各个细分技术厂商、通用技术厂商的配合。&lt;/p&gt; 
&lt;p&gt;技术研发的爆点将在哪天到来难以预测，在那之前，各式零部件、基础耗材的攻击也是对产业链的一大考验。&lt;/p&gt; 
&lt;p&gt;近期，逐际动力联合创始人兼首席运营官张力就公开表示，「深圳在机器人硬件供应链上优势明显，有的硬件我们上午下单，当天下午就能做好送到，这极大提升了机器人公司硬件产品的迭代速度。」对比此前，有学者在国外做机器人相关研究时，经常需要从中国购买零部件，通常得一两个月才能收到货，而发货地多是深圳粤海街道发货。&lt;/p&gt; 
&lt;p&gt;因为机器人产业起步早、政策扶植等因素，深圳积累了硬件、供应链优势。有了供应链优势，再结合技术，量产才能成为可能。&lt;/p&gt; 
&lt;p&gt;3 月 3 日，深圳市工业和信息化局发布《深圳市加快推进人工智能终端产业发展行动计划（2025—2026 年）》。其中提出目标，到 2026 年，深圳市人工智能终端产业核心竞争力进一步增强，产品「含深度」进一步提升，产业生态持续丰富。具体来看，目标包括届时深圳市人工智能终端产业规模达 8000 亿元以上、力争 1 万亿元，集聚不少于 10 家现象级人工智能终端企业，人工智能终端产品产量突破 1.5 亿台；手机、计算机、大模型一体机、可穿戴设备等领域推出 50 款以上爆款人工智能终端产品，智能制造、智慧金融、智慧城市、智慧养老、智慧政务等领域打造 60 个以上人工智能终端典型应用场景。&lt;/p&gt; 
&lt;p&gt;同日，深圳市科技创新局发布《深圳市具身智能机器人技术创新与产业发展行动计划（2025—2027 年）》。其中提到，到 2027 年，深圳市在机器人关键核心零部件、AI 芯片、人工智能与机器人融合技术、多模态感知技术、高精度运动控制技术、灵巧操作技术等方面取得突破。具体来看，目标包括届时深圳市新增培育估值过百亿企业 10 家以上、营收超十亿企业 20 家以上，实现十亿级应用场景落地 50 个以上，关联产业规模达到 1000 亿元以上，具身智能机器人产业集群相关企业超过 1200 家。打造公共服务平台矩阵，吸引更多上下游企业、科研机构、创新团队等加入，形成更完善的产业生态，具身智能机器人产业综合实力达到国际领先水平。&lt;/p&gt; 
&lt;p&gt;中信证券认为，人形机器人产业快速发展，全球主要整机厂商陆续开始出货，人形机器人将迎来商业化。今年以来，随着一些具身智能整机厂商陆续公布量产计划，2025 年可能是人形机器人量产的元年的观点也正在升温。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;74&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-2ea50a939ccbd5d5d966f3a5bcae25f3de8.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;774&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-717bc0e7bb7303e625c3dfc274a2086fea7.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;具身智能的进化、量产，本质是一场对人类生物本能的工程学解构——当机器人用碳纤维骨骼和代码复刻出人类 230 个自由度的动作时，我们不仅需要技术的突破，更需要整个产业链的配合。&lt;/p&gt; 
&lt;p&gt;本篇我们从宏观角度看了深圳具身智能「明星」企业的概况和技术，接下来，我们将持续追踪具身智能的技术攻坚与商业化落地，从多个角度深入解析具身智能的技术与发展。欢迎投稿和交流：18655807197&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;4 月 26 日，&lt;strong&gt;【未来智造：机器⼈软件系统技术前沿】&lt;/strong&gt;OSC 源创会·深圳站·112 期开启：&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;听日本创客高须正和拆解机器人竞赛中的 &lt;span style=&quot;background-color:#ffffff; color:#0052ff&quot;&gt;ROS 实战密码&lt;/span&gt;；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;深挖&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#0052ff&quot;&gt;具身智能数据生态&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;的底层逻辑，建设开源生态；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;直面&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#0052ff&quot;&gt;运动控制&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;的「脑机战争」技术博弈；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;触摸全球首款&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#0052ff&quot;&gt;双模态多维触觉灵巧手技术&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;，见证触觉传感升级；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;看国产 &lt;/span&gt;&lt;span&gt;RT-Thread&lt;/span&gt;&lt;span&gt; 如何用硬实力&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span style=&quot;background-color:#ffffff; color:#0052ff&quot;&gt;机器人操作系统&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;难题；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;5 大领域专家带你穿透技术瓶颈，直抵机器人智能化核心战场。&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;现场更有精美茶歇和超多礼品相待！&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;（号外：报名本期源创会即可享受 4 月 24 日-26 日的 FAIR plus-机器人全产业链接会现场通票，一睹机器人全产业链展会风采）&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;🔥 &lt;span style=&quot;background-color:#ffffff; color:#3da742&quot;&gt;&lt;strong&gt;即刻报名：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/event/8595590&quot;&gt;&lt;u&gt;&lt;em&gt;https://www.oschina.net/event/8595590&lt;/em&gt;&lt;/u&gt;&lt;/a&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt; 🔥&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;⏰ &lt;span style=&quot;background-color:#ffffff; color:#3da742&quot;&gt;&lt;strong&gt;时间：2025-04-26 12:00 至 16:30&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;🏠 &lt;span style=&quot;background-color:#ffffff; color:#3da742&quot;&gt;&lt;strong&gt;地点：深圳市，福⽥区，福华三路深圳会展中⼼8 号馆&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;4 月 24-26 日，&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「机器人全产业链接会（FAIR plus 2025）」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;也讲在&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;深圳会展中心（福田）7-8 号馆举办，同期举办 LogiMAT China2025。活动内容精彩纷呈，包含学术会议、技术沙龙、社区培育，其中的技术社区共建会，涵盖开源技术沙龙、社区生态召集会、标准工作组会议；另外还有场景协同开发对接会，精准对接匹配各方需求，新品发布及产品说明会，为企业展示新品提供平台。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;p style=&quot;margin-left:8px; margin-right:8px&quot;&gt;&lt;img height=&quot;10025&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d713a34d8bfec30f2c1ce347fd7e7fdd457.png&quot; width=&quot;3125&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4489239/blog/18183912</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4489239/blog/18183912</guid>
            <pubDate>Mon, 14 Apr 2025 06:17:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>腾讯混元开源定制化图像生成插件 InstantCharacter</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;腾讯混元&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Ft5kR44NShOJ1xfIopmG3_Q&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;开源定制化图像生成插件 InstantCharacter，并实现了对开源文生图模型 Flux 的兼容。「通过这个插件，在大模型中，只需要一张图加一句话，你可以让任何角色以你想要的姿势出现在任何地方。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;示例：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;输入原始图片&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4df196bc9c553a794b45d8cf1060d941f53.webp&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;+ prompt ：a &amp;nbsp;rabbit is in the kitchen holding a spoon and drinking soup&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;就能得到下面的图：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-522d4d038451c2800349f2773df0f0bcc22.webp&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;+prompt：a rabbit in the city,cyberpunk&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;就可以得到：&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;200&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-786026e787b00731c879cb61528879c252a.webp&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，InstantCharacter 的优势在于可以确保角色在不同场景中的一致性和真实性、画质和精度高，同时具有灵活的文本编辑性，用户可以根据需要灵活切换任意场景，让人物生成任意动作。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;其在角色一致性和图像生成的精确度上超过了此前业界的相关技术，能够处理多种风格和复杂度的图像。通过这个插件，内容创作者可以让生成的角色保持高度一致，能够更高效地创作出符合其需求的视觉作品，可以用于连环画、影片创作等场景。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;539&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4d73bdbca36b5f47b7bf14231e5f9000413.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;测评结果显示，InstantCharacter 实现的效果媲美 GPT 4o 等业界领先模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;681&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1b566bbb0acb6b270f4557ea3249ce96e7f.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;InstantCharacter 利用 DiT 模型构建了一个创新的框架。框架引入了一个可扩展的适配器（adapter），采用多个 transformer encoder，能够有效处理开放域的角色特征，并与现代扩散变换器的潜在空间无缝交互。这种设计使得系统能够灵活适应不同的角色特征。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:left&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;同时，为了有效训练框架，腾讯混元团队还构建了一个包含千万级样本的大规模角色数据集。数据集被系统地组织为成对（多视角角色）和非成对（文本-图像组合）子集。这种双数据结构使得身份一致性和文本可编辑性能够通过不同的学习路径同时优化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345284</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345284</guid>
            <pubDate>Mon, 14 Apr 2025 05:56:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenAI 推出</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;为了更积极地与 Google 等竞争对手的人工智能公司竞争，OpenAI 推出了&amp;nbsp;&lt;strong&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fflex-processing&quot; target=&quot;_blank&quot;&gt;Flex 处理 (Flex processing)&lt;/a&gt;&lt;/u&gt;&lt;/strong&gt;，这是一种 API 选项，&lt;strong&gt;它提供更低的人工智能模型使用价格，但响应时间较慢且「偶尔资源不可用」&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;「Flex processing&amp;nbsp;」可以显著降低 Chat Completions 或 Responses 请求的成本，但会以较慢的响应时间和偶尔的资源不可用为代价。它非常适合非生产或低优先级任务，如模型评估、数据丰富化或异步工作负载。&lt;/p&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0418/115203_ZCQZ_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;OpenAI 表示， Flex 处理是 OpenAI 最近发布的 o3 和 o4-mini 推理模型的测试版，旨在处理模型评估、数据丰富和异步工作负载等低优先级和 「非生产」 任务。&lt;/p&gt; 
&lt;p&gt;它将 API 成本降低了整整一半。对于 o3，Flex 处理价格为每百万输入词元（约 75 万字）5 美元，每百万输出词元 20 美元，而标准价格为每百万输入词元 10 美元，每百万输出词元 40 美元。&lt;/p&gt; 
&lt;p&gt;对于 o4-mini，Flex 将价格从每百万输入词元 1.10 美元和每百万输出词元 4.40 美元降至每百万输入词元 0.55 美元和每百万输出词元 2.20 美元。&lt;/p&gt; 
&lt;p&gt;Flex 处理的推出正值前沿人工智能价格持续攀升之际，而竞争对手也纷纷推出更便宜、更高效的预算导向型模型。周四，Google 推出了 Gemini 2.5 Flash ，这款推理模型的性能与 DeepSeek R1 相当，甚至更胜一筹，而且输入词元成本更低。&lt;/p&gt; 
&lt;p&gt;OpenAI 在致客户的一封宣布推出 Flex 定价的电子邮件中还指出，其使用等级体系中 1-3 级的开发者必须完成新引入的身份验证流程才能访问 o3。（等级由在 OpenAI 服务上花费的金额决定。）O3 的推理摘要和流式 API 支持也需要经过身份验证。&lt;/p&gt; 
&lt;p&gt;OpenAI 此前表示，身份验证旨在阻止不良行为者违反其使用政策。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;了解更多：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fflex-processing&quot; target=&quot;_blank&quot;&gt;https://platform.openai.com/docs/guides/flex-processing&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345261/openai-flex-processing</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345261/openai-flex-processing</guid>
            <pubDate>Mon, 14 Apr 2025 03:52:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>飞猪推出新 AI 产品「问一问」</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;飞猪宣布推出新 AI 产品「问一问」，首先面向飞猪 F5 及以上会员开放体验。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，「问一问」定位是一个多智能体驱动的 AI 产品。它能像专业的旅游服务从业者一样思考问题、执行任务，还可以调用飞猪上的机票、酒店价格和库存，以及景点、玩法等专有数据，给出真实、可用的旅行方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;276&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0072977933356d6824d4cdd37de1a715c8d.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「问一问」集成了通义千问的多个主力模型，并通过多智能体分工协作加自主决策的方式，提升了对复杂旅行需求的识别精度和处理效率。在训练过程中融入了由飞猪构建的高质量旅行场景数据集，并接入平台的实时报价引擎，包括机票、酒店的实时价格和库存，旅行路线、景点和碎片化玩法等数据沉淀。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;飞猪「问一问」产品负责人刘洪敏表示，「在‘问一问’研发过程中，我们的技术团队反复调研专业旅行定制师的工作流，将相关知识和经验融入到 AI 的分析、执行、决策各个节点，提升思维链效率和产出质量。另一方面，作为一个旅行服务的开放平台，飞猪本身也积累了海量的商品、目的地、玩法、服务和评价等信息，它们都是历经无数次消费者正负向反馈的真实数据，是训练 AI 的重要底料。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345251</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345251</guid>
            <pubDate>Mon, 14 Apr 2025 03:14:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>能否将扩散模型思想应用于 LLMs 领域？大型语言扩散模型（LLDM）详解</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;编者按：&lt;/strong&gt; 当你面对需要高质量逆向推理能力的应用场景时，传统大语言模型是否让你感到力不从心？在诗歌逆向补全、逻辑逆向推导等任务中，为什么即使是 GPT-4o 这样的强大模型也会表现失常？&lt;/p&gt; 
 &lt;p&gt;文章深入介绍了 LLaDA(Large Language Diffusion with mAsking) 这一创新模型的工作原理、训练过程与性能表现。与传统自回归模型不同，LLaDA 借鉴了计算机视觉领域的扩散模型思想，通过逐步去除掩码来生成文本，而非从左到右逐个生成 token。&lt;/p&gt; 
 &lt;p&gt;性能测试显示，8B 参数的 LLaDA 基础模型明显优于同等规模的 LLaMA 2，并与 LLaMA 3 表现相当。更令人惊喜的是，LLaDA 在逆向推理任务中表现出色，有效解决了自回归模型在&quot;逆向诅咒&quot;上的局限性，甚至在诗歌逆向补全任务中超越了 GPT-4o 和 Qwen 2.5。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;作者 | AI Papers Academy&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;编译 | 岳扬&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在这篇文章，我们将对《Large Language Diffusion Models》这篇论文进行解析，介绍首个基于扩散模型的 LLM，该模型可与强大的 LLM 相媲美。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f2bc981b8e713cb0d30a265917a6a0977b8.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Paper authors (Source[1])&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;01 引言&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;近年来，大语言模型（LLMs）变得极其强大，为通向通用人工智能（AGI）铺平了道路。这些模型本质上是自回归的，即根据给定的 token 序列预测下一个 token。我们可以把这个过程想象成它们在一个词一个词地生成回答内容，其中的每个新词都基于前面已有的词汇。事实证明，这种方法非常强大，让我们取得了今天的成就。&lt;/p&gt; 
&lt;p&gt;然而，这种方法也面临着一些挑战。例如，&lt;strong&gt;按顺序逐个生成 token 的计算成本很高&lt;/strong&gt; 。此外，&lt;strong&gt;固有的从左到右的建模方式限制了模型在逆向推理（reversal reasoning）任务中的有效性。&lt;/strong&gt; 后文将提到一个案例 ------ 逆向诗歌补全任务，即给定诗歌中的一句话，模型需要预测诗中这句话前一句的内容。无论如何，有一点值得探讨：&lt;strong&gt;自回归建模是否唯一可行的方式？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;《Large Language Diffusion Models》对这一假设提出了挑战。正如 LLMs 是自然语言处理的基石一样，扩散模型则是计算机视觉领域的王者，是顶级文生图模型的核心技术。在本文中，我们将解读研究人员如何将扩散模型应用于语言建模领域。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;02 什么是扩散模型？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;让我们先快速回顾一下计算机视觉中的扩散模型，这将有助于我们理解本文的核心思想。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c7f247cb734cf9399a9c2ad31ec1f67ef1c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;扩散模型逐步去除图像中的噪声（Cat images source[2]）&lt;/p&gt; 
&lt;p&gt;扩散模型以提示词作为输入，例如&quot;一只猫坐在一台笔记本电脑上&quot;。模型通过学习逐步去除图像中的噪声来生成清晰的图像。模型从最左侧所示的随机噪声图像开始，每一步都去除部分噪声。去噪过程是以输入提示词为条件的，因此最终生成的图像会匹配提示词内容。上图中的三个点（...）表示本例中我们跳过了一些中间步骤。最终我们得到一张清晰的猫图像，这就是扩散模型根据给定提示词生成的最终输出。&lt;/p&gt; 
&lt;p&gt;在训练过程中，为了学习如何去除噪声，我们会逐步向清晰图像添加噪声，这个过程称为扩散过程。该领域已取得一系列进展，但这不是本文的重点。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;03 大型语言扩散模型的直观理解&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-628cbcf00b82e8b038212ce67241cf17d06.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLaDA 逐步去除 token 序列中的掩码&lt;/p&gt; 
&lt;p&gt;本文介绍的模型名为 LLaDA，全称是 Large Language Diffusion with mAsking。我们从最左侧的 token 序列开始，其中黑色部分表示被掩码的 token。黄色的未掩码 token 代表提示词，黑色的被掩码 token 代表待生成的响应。请注意，这里的被掩码的 token 由特殊符号表示，不同于我们之前提到的图像中叠加的噪声。&lt;/p&gt; 
&lt;p&gt;我们逐步去除 token 序列中的掩码，蓝色代表已解除掩码的 token。最终，我们移除所有掩码，得到针对输入提示词的完整响应。在本例中，清晰的响应 token 序列对应文字为：&quot;从前，在一个小村庄里，住着一只聪明的老猫头鹰（Once upon a time, in a small village, there lived a wise old owl）&quot;。&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;04 LLaDA 训练与推理过程概述&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;让我们来深入探讨大型语言扩散模型的更多细节。下图展示了该模型的两个训练阶段（预训练与监督式微调）以及推理过程。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-eb1920b5061ab0e2ff45d664db3a7b05fab.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLaDA 训练过程与推理示意图（Source[1]）&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.1 LLaDA 训练阶段 1 ------ 预训练阶段&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;我们从预训练阶段开始，如上图最左侧所示。&lt;/p&gt; 
&lt;p&gt;顶部是训练集中的一个样本序列。我们随机选择掩码比例 t（0 到 1 之间的值），随后独立地为每个 token 随机决定是否掩码，概率为 t。这一步会产生部分被掩码的 token 序列。该序列被输入模型的核心组件 ------ mask predictor（这是一个基于 Transformer 的模型），该模型通过计算掩码 token 上的交叉熵损失，训练其还原被掩码的 token。预训练数据集规模为 2.3 万亿 token。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.2 LLaDA 训练阶段 2 ------ 监督式微调&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;第二个训练阶段是监督式微调，如上图中间部分所示。&lt;strong&gt;此阶段的目的是增强 LLaDA 遵循指令的能力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;顶部是包含提示词和响应的样本。我们希望训练模型根据提示词生成响应。与预训练类似，我们随机掩码样本中的部分 token，但此次仅掩码响应部分的 token，保留提示词完整。随后，我们将提示词和部分被掩码的响应输入 mask predictor，以恢复响应中被掩码的 token。此过程与预训练阶段非常相似，区别在于此过程仅掩码样本的响应部分。&lt;/p&gt; 
&lt;p&gt;训练过程的掩码比例（决定多少 token 被掩码）对每个样本都是随机的。这意味着在训练过程中，模型会接触到几乎未掩码的样本和高度掩码的样本。&lt;/p&gt; 
&lt;p&gt;在这一阶段，研究人员使用了 450 万样本训练 LLaDA。由于样本长度不一致，因此研究人员使用特殊的序列结束 tokens 填充样本。通过这种方式，模型就能在人类设置的固定长度的（artificial fixed-length）输入上进行训练，并能预测序列结束 tokens，从而终止生成过程。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.3 推理阶段：LLaDA 如何生成文本&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;了解完 LLaDA 的训练方式后，接下来让我们回顾一下上图右侧所示的推理过程。&lt;/p&gt; 
&lt;p&gt;给定提示词后，会创建包含完整提示词和被完全掩码的响应的样本。然后通过称为逆向扩散过程（reverse diffusion process）的迭代流程，逐步解除响应部分的掩码。每次迭代开始时，我们会得到一个包含完整提示词和被部分掩码的响应的序列。将其输入 mask predictor 后，它会预测出所有被掩码的 token。然而，部分预测出的 token 会被重新掩码，因此响应仍保持部分掩码状态，直到最后一次迭代，我们才会获得完整响应。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;4.4 推理期间的重新掩码策略&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;迭代次数是模型的超参数，需要在计算成本与生成质量间权衡（更多迭代次数可提升生成质量）。在每次迭代中，重新掩码的 token 数量基于总迭代次数。但如何决定哪些 token 需要重新掩码？研究者未采用随机方法，而是使用了两种更有效的策略：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;低置信度重新掩码（Low-confidence remasking）&lt;/strong&gt; ------ 此方法中，预测置信度最低的 token 会被重新掩码。对于每个 token，mask predictor 都会从词表中选择概率最高的 token 作为预测结果。此处的最高概率代表 token 预测的置信度，反映模型对此 token 相较于其他选项的正确性确定程度。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;半自回归重新掩码（Semi-autoregressive remasking）&lt;/strong&gt; ------ 响应长度可能因提示词而异。对于需要简短回答的提示词，大部分响应内容可能是序列结束标记。为避免生成过多高置信度的序列结束标记，会将待生成的响应划分为多个区块，并按从左到右顺序依次处理。在每个区块内部应用逆向扩散过程进行采样。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;&lt;strong&gt;05 LLaDA Results&lt;/strong&gt;&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;5.1 Benchmark Results&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-1722a74f816dfa334f530ffb7f055c067a1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLaDA 与 LLaMA 模型对比（Source[1]）&lt;/p&gt; 
&lt;p&gt;在上图中，我们对比了 8B 参数的 LLaDA 基础模型与规模相近的 LLaMA 3 和 LLaMA 2 在多项任务上的表现。&lt;strong&gt;使用红色标注的 LLaDA 明显优于使用蓝色标注的 LLaMA 2，并与使用紫色标注的 LLaMA 3 表现相当，甚至在部分任务上优于 LLaMA 3。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;图中结果为各模型基础版本的测试结果。未在此图表展示的经过指令调优的模型性能对比中，LLaMA 3 更具优势。但需注意，指令调优版 LLaMA 3 在预训练阶段后既进行了监督式微调也进行了强化学习训练，而指令调优版 LLaDA 仅在预训练阶段后进行了监督式微调。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.2 LLaDA 在不同规模下的性能扩展规律（LLaDA Scaling Trends）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-74c2dcc11f6287aaa8ca5b00e3507368a34.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;LLaDA 在语言任务上的性能扩展规律（Source[1]）&lt;/p&gt; 
&lt;p&gt;论文中另一张有趣的图表展示了 LLaDA 在语言任务上的扩展能力。研究人员以不同训练计算资源（x 轴显示）训练了规模相近的 LLaDA 和自回归基线模型（autoregressive baselines）。每张子图代表不同任务，y 轴显示模型性能。&lt;strong&gt;LLaDA 展现出强大的扩展能力，与自回归基线模型竞争力相当。&lt;/strong&gt; 在数学数据集 GSM8K 上，LLaDA 的扩展优势尤为显著；而在推理数据集 PIQA 上，LLaDA 稍落后于自回归模型，但随着浮点运算量（FLOPs）的增加，差距逐渐缩小。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;5.3 打破「逆向诅咒」&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7b120834fbe63429dfa2c64eb38d3b8e47c.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;诗歌补全任务上的模型性能对比（Source[1]）&lt;/p&gt; 
&lt;p&gt;上表展示了诗歌补全任务上的模型性能对比。该任务要求模型根据给定诗句生成下一句（正向任务）或前一句（逆向任务）。观察 GPT-4o 的表现，其在正向任务中的性能显著优于逆向任务，这是自回归训练固有的局限性。LLaDA 则在此取得突破，在正向和逆向任务中表现更均衡，并在逆向任务中超越 GPT-4o 和 Qwen 2.5。&lt;strong&gt;大型语言扩散模型在更大规模的模型训练中表现如何，让我们拭目以待！&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;strong&gt;06 结语：语言模型迎来新时代？&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;LLaDA 通过将扩散模型应用于文本生成任务，掀起了语言建模的范式转变。其双向推理能力与强大的扩展性，向传统的自回归模型发起了挑战。&lt;strong&gt;虽然该模型尚处探索初期，但这场技术跃迁或将定义 AI 发展的下一程，未来可期。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Thanks for reading!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Hope you have enjoyed and learned new things from this blog!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the author&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;AI Papers Academy&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;At AI Papers Academy, we simplify AI research papers and concepts, making AI more accessible.&lt;/p&gt; 
&lt;p&gt;Our goal is to save you time by breaking down complex ideas into clear, digestible insights.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;END&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;本期互动内容 🍻&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;❓&lt;strong&gt;有人认为扩散模型对文本生成是&#39;杀鸡用牛刀&#39;，你同意吗？为什么？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🔗文中链接🔗&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;[1]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.09992&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2502.09992&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2]&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fimproving-diffusion-models-as-an-alternative-to-gans-part-1%2F&quot; target=&quot;_blank&quot;&gt;https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;原文链接：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Faipapersacademy.com%2Flarge-language-diffusion-models%2F&quot; target=&quot;_blank&quot;&gt;https://aipapersacademy.com/large-language-diffusion-models/&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/IDP/blog/18181991</link>
            <guid isPermaLink="false">https://my.oschina.net/IDP/blog/18181991</guid>
            <pubDate>Mon, 14 Apr 2025 02:45:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>公安部道研中心：虚假宣传自动驾驶可面临 2 年以下刑期</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;近日，公安部道路交通安全研究中心官方公众号「交通言究社」发表《智慧领航，安全护航——智能网联汽车辅助驾驶功能使用须谨慎》一文，提到近期因驾驶人错误使用辅助驾驶导致的交通事故，并揭示其原因——部分驾驶人对辅助驾驶的认知不到位，误以为「辅助驾驶=自动驾驶」。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;文章指出，部分驾驶人开启辅助驾驶功能后做出玩手机、睡觉、聊天、吃东西等危险行为，不仅违反了道路交通安全法律法规，也对其他道路使用者的安全构成严重威胁。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;2021 年 8 月，中国国家市场监督管理总局、国家标准化管理委员会批准发布《汽车驾驶自动化分级》（GB/T 40429-2021）标准，将驾驶自动化分为 0 至 5 级。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;373&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9ec350f80a4cb1369cfdbb89909afc2e5ae.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（一）关于车企误导宣传的相关法律责任&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据《中华人民共和国广告法》第二十八条，若车企通过广告或宣传材料虚构、夸大辅助驾驶功能（如将 2 级辅助驾驶描述为 「自动驾驶」），误导消费者购买，市场监管部门可依据《中华人民共和国广告法》对虚假宣传行为处以广告费用 5-10 倍罚款，情节严重的吊销营业执照。若虚假宣传造成严重后果（如引发交通事故致人伤亡），可能触犯《中华人民共和国刑法》第二百二十二条，可对责任人处 2 年以下有期徒刑或拘役，并处或单处罚金。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（二）关于驾驶人滥用辅助驾驶的相关法律责任&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据《中华人民共和国道路交通安全法》及其实施条例，机动车驾驶人始终对车辆运行安全负主体责任。当前我国道路通行环境下，市面量产汽车仍处于 2 级辅助驾驶阶段，系统仅提供有限的辅助驾驶功能，因此，驾驶人在使用辅助驾驶功能时，必须持续履行观察路况、预判风险和及时接管的义务。若驾驶人在辅助驾驶功能激活期间未尽上述义务，存在「脱手脱眼」行为，公安机关交通管理部门将依据《中华人民共和国道路交通安全法》第九十条，认定其存在妨碍安全驾驶的违法行为，依法处以罚款并记分。一旦因此类行为引发交通事故，驾驶人将承担主要责任，需依法承担民事赔偿；若事故导致人员伤亡或重大财产损失，还可能构成交通肇事罪，被追究刑事责任。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（三）关于生产销售「智驾神器」的相关法律责任&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对生产、销售者而言。根据《中华人民共和国刑法》第一百四十六条规定，「智驾神器」不符合保障人身、财产安全的国家标准或行业标准（如干扰车辆安全监测系统），若造成严重后果（如交通事故致人伤亡），生产者和销售者可能被判处 5 年以下有期徒刑或拘役，并处销售金额 50% 至 2 倍罚金；后果特别严重的（如多人伤亡），刑期可至 5 年以上有期徒刑，罚金同上。若设备设计或宣传直接诱导驾驶人脱离监管（如 「解放双手」「免接管」），导致重大交通事故，可能被认定为危害公共安全，最高可判处死刑。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对使用者而言。根据《中华人民共和国道路交通安全法》及其实施条例，使用「智驾神器」导致双手脱离方向盘、视线偏离道路，仍属于「妨碍安全驾驶行为」，依法处以罚款并记分。一旦引发交通事故，驾驶人将承担主要责任，需依法承担民事赔偿；若事故导致人员伤亡或重大财产损失，还可能构成交通肇事罪，被追究刑事责任。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对销售平台而言。根据《中华人民共和国电子商务法》第三十八条规定，电子商务平台经营者知道或者应当知道平台内经营者销售的商品或者提供的服务不符合保障人身、财产安全的要求，或者有其他侵害消费者合法权益行为，未采取必要措施的，依法与该平台内经营者承担连带责任。对关系消费者生命健康的商品或者服务，电子商务平台经营者对平台内经营者的资质资格未尽到审核义务，或者对消费者未尽到安全保障义务，造成消费者损害的，依法承担相应的责任。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;（四）关于驾驶人酒后使用辅助驾驶的相关法律责任&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于驾驶人本人启用辅助驾驶功能上路通行。即便本人通过使用「智驾神器」等方式实现脱手驾驶，未实际操纵方向盘驾驶车辆，仍然属于道路交通安全违法行为，属于醉酒驾驶的，还有可能构成危险驾驶罪。原因在于，驾驶人在使用辅助驾驶相关功能时，需要通过账号登录，验证识别等方式进行授权和许可，表明驾驶人对车辆启动具有明知且认可的主观心态，驾驶人驾驶辅助驾驶汽车上道路通行期间，具有掌握车辆控制权、监控道路交通环境、保持专注并随时准备接管车辆的义务，此种义务不能由未实际操作方向盘，或者车辆具有辅助驾驶功能等理由予以免除。驾驶人在明知自身因醉驾等原因导致风险控制能力下降，且车辆的情况，仍然放弃驾驶责任，放任不具有自动驾驶能力的车辆自主行驶，具有充分的社会危害性，既属于《中华人民共和国道路交通安全法实施条例》第六十二条第 3 款规定的分心驾驶行为，亦属于酒后驾驶行为。情节严重，构成犯罪的，还应当以危险驾驶罪追究其刑事责任。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于帮助处于醉酒状态的驾驶人设定终点、启动车辆、规避驾驶员监控系统（DMS），再由辅助驾驶汽车根据预先设定好的线路行驶的行为，《中华人民共和国道路交通安全法》第二十二条第 3 款规定，任何人不得强迫、指使、纵容驾驶人违反道路交通安全法律法规和机动车安全驾驶要求驾驶机动车。在明知驾驶人处于醉酒状态，且不会对车辆进行驾驶的情况下，仍然为其设定路线、启动车辆，实质上纵容并帮助了车主实施分心驾驶、醉酒驾驶等道路交通安全违法行为，应追究其相应的法律责任。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;总之，当前国内量产车型所搭载自动驾驶系统尚处于 2 级辅助驾驶阶段，系统属于「执行者」角色，驾驶人才是最终责任主体，违反法律或不安全使用行为不仅面临行政处罚，还可能承担事故赔偿甚至刑事责任。因此，驾驶人应做自己生命的「第一责任人」，严格遵守《中华人民共和国道路交通安全法》，在使用辅助驾驶系统时保持专注，确保随时可控。（中国青年报）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345239</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345239</guid>
            <pubDate>Mon, 14 Apr 2025 02:40:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Grok 新增「记忆」功能，可回复个性化内容</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;马斯克旗下 xAI&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2Fgrok%2Fstatus%2F1912670183472476653&quot;&gt;宣布&lt;/a&gt;&amp;nbsp;Grok 新增 「记忆」 功能，能根据用户过去的对话内容记住相关细节。用户寻求推荐或建议时会得到个性化的回复 —— 当然前提是用户的使用频率足够高，让它能 「学会」 你的喜好。&lt;/p&gt; 
&lt;p&gt;同时，「记忆」 也是透明的，用户可以确切地看到 Grok 知晓的内容，并选择 「忘记」 什么。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0418/103645_rJtV_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;相比之下，ChatGPT 早已支持类似的记忆功能，且最近升级后，能够&lt;strong&gt;调用用户完整的聊天历史&lt;/strong&gt;。谷歌的 Gemini 同样具备持久记忆，能根据&lt;strong&gt;不同用户的习惯调整回应&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;目前，Grok 的这项记忆功能已&lt;strong&gt;通过测试版&lt;/strong&gt;形式登陆 Grok.com 网站以及 iOS 和 Android 应用，但&lt;strong&gt;暂不向欧盟和英国用户开放&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;用户可以在设置菜单的「数据控制」页面关闭该功能，也能在网页端的 Grok 聊天界面，通过点击记忆下方的图标删除单条记忆 ——Android 版本很快也将支持这一操作。&lt;/p&gt; 
&lt;p&gt;xAI 表示，X 平台上的 Grok 也将逐步具备「记忆」功能。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345238/xai-grok-memories</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345238/xai-grok-memories</guid>
            <pubDate>Mon, 14 Apr 2025 02:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>谷歌发布 Gemini 2.5 Flash：性能与效率的平衡之作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;2025 年 4 月 17 日，谷歌正式宣布通过 Google AI Studio 和 Vertex AI 平台推出 Gemini 2.5 Flash 预览版。作为 2.0 Flash 的全面升级，这款新模型在保持速度和成本优势的同时，显著提升了推理能力，成为谷歌首款真正意义上的混合推理模型。&lt;/p&gt; 
&lt;h2&gt;思考能力成为焦点&lt;/h2&gt; 
&lt;p&gt;Gemini 2.5 Flash 最引人注目的特点在于其可控制的思考能力。不同于传统模型直接生成输出，Gemini 2.5 系列模型能够在响应前进行「思考」过程，更好地理解提示，分解复杂任务，并规划回答。这一特性使模型在处理需要多步推理的复杂任务时（如解决数学问题或分析研究问题）能够给出更准确、更全面的答案。&lt;/p&gt; 
&lt;p&gt;据谷歌官方介绍，在 LMArena 的 Hard Prompts 基准测试中，Gemini 2.5 Flash 表现出色，仅次于 2.5 Pro。这一成就标志着较小规模模型也能实现接近顶级模型的推理能力，为开发者提供了更经济的选择。&lt;/p&gt; 
&lt;h2&gt;精细化控制思考预算&lt;/h2&gt; 
&lt;p&gt;谷歌深知不同使用场景对质量、成本和延迟有着不同的权衡要求。为此，Gemini 2.5 Flash 引入了「思考预算」（thinking budget）机制，允许开发者对模型在思考阶段可以生成的最大 token 数量进行精细控制。更高的预算可以让模型进行更深入的推理，提高输出质量。&lt;/p&gt; 
&lt;p&gt;值得注意的是，思考预算仅设置上限，模型不会浪费资源——如果提示不需要太多思考，模型会自动调整使用的思考量。谷歌表示，模型已经训练成能够根据任务复杂度自动决定思考时间的长短。&lt;/p&gt; 
&lt;p&gt;如果开发者希望保持最低成本和延迟，同时仍然获得比 2.0 Flash 更好的性能，可以将思考预算设为 0。当然，他们也可以在 API 中使用参数或在 Google AI Studio 和 Vertex AI 中使用滑块来设置特定的思考预算。对于 2.5 Flash，预算范围可以从 0 到 24576 个 token。&lt;/p&gt; 
&lt;h2&gt;性价比领先的思考模型&lt;/h2&gt; 
&lt;p&gt;Gemini 2.5 Flash 的价格策略引人注目。根据谷歌提供的数据，这款模型保持了最佳的价格性能比，尤其是相较于竞争对手的同类产品。在输入价格方面，每百万 token 为 0.15 美元，输出价格为每百万 token 0.60 美元，相比 OpenAI 的 o4-mini、Anthropic 的 Claude Sonnet 3.7 和 xAI 的 Grok 3 Beta 等竞品，具有明显的成本优势。&lt;/p&gt; 
&lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;1999&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d67320ae707ff147ab25e0d656d8ad5004a.png&quot; width=&quot;1361&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在性能上，Gemini 2.5 Flash 在多项基准测试中表现出色。例如，在「Humanity&#39;s Last Exam」（无工具）测试中达到了 12.1% 的成绩，在 GPQA Diamond 科学测试中达到了 78.3% 的单次尝试成绩，在 AIME 2025 数学测试中达到了 78.0% 的单次尝试成绩。虽然在某些指标上略逊于更昂贵的模型，但考虑到其价格，这些成绩令人印象深刻。&lt;/p&gt; 
&lt;h2&gt;开发者反应褒贬不一&lt;/h2&gt; 
&lt;p&gt;在技术社区 Hacker News 上，对谷歌 AI 产品的讨论热度颇高。一些用户表示，自从谷歌将 Gemini 2.5 Pro（实验版）免费提供以来，他们已成为谷歌模型的忠实用户。用户 zoogeny 分享道：「Gemini 2.5 Pro 是如此大的进步，以至于我对谷歌的模型整体产生了信心。它不仅在我接触的大多数主题上比我更聪明，而且也不是完全顺从。该模型会对我提出反驳，而不是扭曲自己以找到同意的方式。」&lt;/p&gt; 
&lt;p&gt;一些用户甚至表示已取消对 Anthropic 的订阅，转而使用谷歌的服务。用户 jeeeb 称：「在并排比较 Gemini Pro 和 Claude Sonnet 3.7 的编码回答几次后，我决定取消我的 Anthropic 订阅，只使用 Gemini。」&lt;/p&gt; 
&lt;p&gt;然而，也有用户提出了一些担忧。有人指出，谷歌 Gemini 网页应用存在基本层面的问题，如速度慢、卡在「显示思考」环节、拒绝接受一次性发送的 20 万 token 提示等。另有用户担忧谷歌可能会像过去一样，通过提供免费服务直到竞争对手消亡，然后降低质量的方式来操控市场。&lt;/p&gt; 
&lt;h2&gt;行业影响与前景&lt;/h2&gt; 
&lt;p&gt;Gemini 2.5 Flash 的发布进一步加剧了 AI 模型市场的竞争。有分析认为，谷歌正在 AI 竞赛中悄然领先，特别是在企业应用领域。相较于 OpenAI 和 Anthropic 等竞争对手，谷歌拥有垂直整合的芯片渠道、深厚的供应链和丰富的运营知识，为其提供了显著的成本优势。&lt;/p&gt; 
&lt;p&gt;此外，谷歌拥有的海量数据资源也是其不可忽视的优势。随着基础模型提供商已经处理完普通爬网数据并竞相消费视频和剩余内容，新数据变得越来越有价值，成为长期竞争的关键因素。&lt;/p&gt; 
&lt;p&gt;Gemini 2.5 Flash 的推出标志着谷歌在 AI 领域的野心。虽然目前仍处于预览阶段，但谷歌表示，将继续改进这一模型，并将很快推出更多功能，然后才会将其正式发布用于全面生产。&lt;/p&gt; 
&lt;p&gt;随着 AI 技术的快速发展，不同公司之间的竞争日益激烈。对于开发者和用户来说，这场竞争带来了更多选择，也推动了 AI 技术的不断进步。谷歌能否凭借 Gemini 2.5 Flash 在这场竞争中赢得优势，值得市场持续关注。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345237</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345237</guid>
            <pubDate>Mon, 14 Apr 2025 02:32:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>百度创始人李彦宏 2025 年首场演讲海报曝光</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;百度创始人李彦宏的 2025 年首场演讲海报曝光，他将于 4 月 25 日在 Create2025 百度 AI 开发者大会上，带来持续 1 个小时的演讲《模型的世界，应用的天下》。&lt;/p&gt; 
&lt;p&gt;海报背景文案囊括了 MCP、智能体、数字人、模型成本等 AI 热点议题，预告了李彦宏将在大会现场带来百度 AI 的全新产品发布和业务进展。&lt;/p&gt; 
&lt;p&gt;此前，百度预告将在 Create 大会上发布文心大模型 4.5 Turbo，从海报看，李彦宏或将在演讲中详细介绍这款模型的特色和能力。&lt;/p&gt; 
&lt;ul&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img height=&quot;1440&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0418/102350_tW8f_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;文心大模型 4.5 Turbo 强在哪里？&lt;/li&gt; 
 &lt;li&gt;MCP 会带来更开放的生态吗?&lt;/li&gt; 
 &lt;li&gt;智能体应用的下一站在哪里？&lt;/li&gt; 
 &lt;li&gt;模型迭代太快，应用会不会过时？&lt;/li&gt; 
 &lt;li&gt;开发者的机会在哪里？&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;相关阅读：&lt;a href=&quot;https://www.oschina.net/news/343749&quot; target=&quot;news&quot;&gt;百度文心大模型 4.5 Turbo 将于 4 月 25 日亮相&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345236</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345236</guid>
            <pubDate>Mon, 14 Apr 2025 02:26:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>字节跳动开源 UI-TARS-1.5：基于视觉-语言模型构建的多模态智能体</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;字节豆包大模型团队&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FgRqyNlF8BTkh9f36UlW3ew&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;开源 UI-TARS-1.5。&lt;/p&gt; 
&lt;p&gt;据介绍，这是一款基于视觉-语言模型构建的开源多模态智能体，能够在虚拟世界中高效执行各类任务。目前，UI-TARS-1.5 已在 7 个典型的 GUI 图形用户界面评测基准中取得 SOTA 表现，并首次展现了其在游戏中的长时推理能力和在开放空间中的交互能力。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;684&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0418/101719_9W5Z_2720166.png&quot; width=&quot;1280&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;UI-TARS-1.5 基于该团队此前提出的原生智能体方案 UI-TARS，通过强化学习进一步增强了模型的高阶推理能力，使模型能够在「行动」前先进行「思考」。&lt;/p&gt; 
&lt;p&gt;该版本的模型中，团队还展示了一个新的愿景：以游戏为载体来增强基础模型的推理能力。与数学、编程等领域相比，游戏更多依赖直观的、常识性的推理，并较少依赖专业知识，因此，游戏通常是评估和提升未来模型通用能力的理想测试场景。&lt;/p&gt; 
&lt;p&gt;据介绍，UI-TARS 作为原生 GUI 智能体，具备真实操作电脑和手机系统的能力，同时，还可操控浏览器、完成复杂交互任务。&lt;/p&gt; 
&lt;p&gt;UI-TARS-1.5 能够实现精准 GUI 操作，基于团队在四个维度的技术探索：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;视觉感知增强：依托大规模界面截图数据，模型可理解元素的语义与上下文，形成精准描述。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;System 2 推理机制：在动作前生成「思维（thought）」，支持复杂任务的多步规划与决策。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;统一动作建模：构建跨平台标准动作空间，通过真实轨迹学习提升动作可控性与执行精度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;可自我演化的训练范式：通过自动化的交互轨迹采集与反思式训练，模型持续从错误中改进，适应复杂环境变化。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;开源地址&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fbytedance%2FUI-TARS&quot; target=&quot;_blank&quot;&gt;https://github.com/bytedance/UI-TARS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fseed-tars.com%2F&quot; target=&quot;_blank&quot;&gt;https://seed-tars.com/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Arxiv&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2501.12326&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/2501.12326&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345234/bytedance-ui-tars-1-5</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345234/bytedance-ui-tars-1-5</guid>
            <pubDate>Mon, 14 Apr 2025 02:18:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>10 亿上海具身智能基金正式成立</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;由上海国有资本投资有限公司与浦东新区联合发起的上海具身智创创业投资合伙企业（有限合伙）（以下简称「上海具身智能基金」）已于近日完成工商注册，目标规模 10 亿元人民币，首关 5.6 亿元人民币。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;上海具身智能基金由上海国资母基金、浦东创投、张江集团共同担任基石出资人，国投孚腾担任基金管理人，浦东创投担任执行事务合伙人，基金将依托张江机器人谷，聚焦具身智能本体、核心零部件、泛机器人等产业链关键环节，加速技术研发与产业转化，助力上海构建国际领先的具身智能产业集群。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;266&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-7e14f6e8d13867a59603ab9e17aa3ba9e45.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该基金将重点投向三大领域：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;具身智能本体：支持人形机器人、工业协作机器人等智能体的研发与场景落地&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;核心零部件：突破高精度传感器、仿生驱动装置、边缘计算芯片等「卡脖子」技术&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;泛机器人应用：拓展医疗康复、智慧物流、特种作业等垂直场景的智能化解决方案&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345232</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345232</guid>
            <pubDate>Mon, 14 Apr 2025 02:12:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>阿里开源通义万相「首尾帧生视频」14B 模型</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里通义万相「首尾帧生视频模型」&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FkudRFGW7MZRfESYS__V5LA&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;开源，该模型参数量为 14B，是业界首个百亿参数规模的开源首尾帧视频模型。可根据用户指定的开始和结束图片，生成一段能衔接首尾画面的 720p 高清视频。公告称，此次升级将能满足用户更可控、更定制化的视频生成需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于现有的 Wan2.1 文生视频基础模型架构，通义万相首尾帧生视频模型进一步引入了额外的条件控制机制，通过该机制可实现流畅且精准的首尾帧变换；在训练阶段，团队还构建了专门用于首尾帧模式的训练数据，同时针对文本与视频编码模块、扩散变换模型模块采用了并行策略，这些策略提升了模型训练和生成效率，也保障了模型具备高分辨率视频生成的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在推理阶段，为了在有限内存资源的条件下支持高清视频推理，万相首尾帧模型分别采用了模型切分策略以及序列并行策略，在确保推理效果无损的前提下，显著缩短了推理时间。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;239&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3ffeced748a2e76ecdd763255e46c87121b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;基于该模型，用户可完成更复杂、更个性化的视频生成任务，可以实现同一主体的特效变化、不同场景的运镜控制等视频生成。例如，上传相同位置不同时间段的两张外景图片，输入一段提示词，通义万相首尾帧生成模型即可生成一段四季交替变化或者昼夜变化的延时摄影效果视频；上传两张不同画面的场景，还可通过旋转、摇镜、推进等运镜控制衔接画面，在保证视频和预设图片一致性前提下，同时让视频拥有更丰富的镜头。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345229</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345229</guid>
            <pubDate>Mon, 14 Apr 2025 02:02:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>有了它，AI 都能直接管理 Gitee 代码仓啦</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                    
                                                                                                                                                    &lt;div&gt; 
 &lt;p&gt;不久前，Gitee 开源了官方的 MCP Server——&lt;a href=&quot;https://gitee.com/oschina/mcp-gitee&quot;&gt;Gitee MCP Server&lt;/a&gt;。有了它，我们就能用 AI 助手直接管理 Gitee 代码仓了！&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;读取文件内容、查看 PR 变更、理解 Issue 描述，甚至直接操作代码管理任务，比如创建 PR、合并分支、发布版本等等，全都不是问题。&lt;/strong&gt;&lt;/p&gt; 
 &lt;p style=&quot;text-align:left&quot;&gt;简单来说，Gitee MCP Server 让 AI 不再是「代码的旁观者」，真正成为了参与软件开发过程的智能助手。&lt;/p&gt; 
 &lt;p&gt;如果你是&lt;strong&gt;个人开发者&lt;/strong&gt;， Gitee MCP Server 可以让 AI 助手直接参与 PR 审查，减少低级错误，提高代码质量；如果你是&lt;strong&gt;开源项目维护者&lt;/strong&gt;，可以接入 Gitee MCP Server，让 AI 助手帮助处理大量 Issue，并提供自动化代码审查，提升社区协作效率。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;既然它是一个 MCP Server，那么所有支持 MCP Client 的应用都能用，&lt;/strong&gt;比如 Cursor、claude desktop、windsurf、cherry studio 或是自行实现的带有 mcp client 的 Agent，等等。（之前「马建仓」就&lt;a href=&quot;https://www.oschina.net/news/340077&quot;&gt;秀了把操作&lt;/a&gt;：没写一行代码，只用 Cursor 和 Gitee MCP 做了个贪吃蛇游戏。 ）&lt;/p&gt; 
 &lt;p style=&quot;text-align:center&quot;&gt;&lt;img height=&quot;339&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-9a4168709eaed70c553754b7015120c1931.png&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;那，这么好的东西怎么用呢？&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;4 月 21 日晚，&lt;strong&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;Gitee 研发工程师黄家建&lt;/span&gt;&lt;/strong&gt;将做客【开源中国】直播栏目《技术领航》，手把手教学如何上手 Gitee MCP Server：从安装与配置开始，实战演练如何用 AI 开发工具结合 Gitee MCP Server 实现 AI + 研发流程的融合。&lt;/p&gt; 
 &lt;p&gt;当然啦，作为 Gitee MCP Server 核心开发者，黄家建还会结合自己的实践经验，讲一讲 MCP 协议是什么，与 function call 到底有什么区别。&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;赶紧打开微信，扫码预约直播吧~&lt;/strong&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;img height=&quot;1840&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-858977b0e133cc1bd2a46be9d6dc787b8dc.png&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt; 
 &lt;/div&gt; 
 &lt;div&gt;
   &amp;nbsp; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span style=&quot;color:#2980b9&quot;&gt;&lt;strong&gt;Gitee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;Gitee（码云）是开源中国于 2013 年推出的基于 Git 的代码托管平台、企业级研发效能平台，提供中国本土化的代码托管服务。&lt;br&gt; 目前，Gitee 已经有超过 1350 万名开发者，累计托管超过 3600 万个代码仓库，是中国境内规模最大的代码托管平台。同时，旗下企业级 DevOps 研发效能管理平台 Gitee 企业版已服务超过 36 万家企业。&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;网址：&lt;a href=&quot;https://gitee.com/&quot;&gt;https://gitee.com/&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;hr&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;《技术领航》是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
  &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18184933</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18184933</guid>
            <pubDate>Sun, 13 Apr 2025 13:44:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>北京市人工智能产业投资基金追加投资智谱（Z.ai）2 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fbaijiahao.baidu.com%2Fs%3Fid%3D1829640482444053837%26wfr%3Dspider%26for%3Dpc&quot; target=&quot;_blank&quot;&gt;《北京日报》报道称&lt;/a&gt;，&lt;strong&gt;北京市人工智能产业投资基金追加投资北京智谱华章科技股份有限公司（以下简称智谱）2 亿人民币。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金表示，智谱是基金成立以来投资的第一家 AI 大模型企业，也是目前成长最快的企业。智谱在包括文本、推理、语音、图像、视频、代码等在内的全面模型能力上有深厚积累。此外，商业化布局完善，拥有超过百万规模的开发者社区和企业用户。&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金表示：希望通过这次投资，进一步推动智谱在开源模型和算法创新方面的能力建设。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4 月 15 日，智谱开源 32B/9B 系列 GLM 模型，包括了基座、推理和沉思模型，所有模型采用宽松的 MIT 许可协议，免费商用、分发，引发业内关注。与此同时，智谱启用全新域名 Z.ai，目前该平台整合了 32B 基座、推理、沉思三类 GLM 模型，后续将作为智谱最新模型的交互体验入口。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;472&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/192641_FbK5_2720166.png&quot; width=&quot;1080&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;智谱此前在开源方面已经做了很多贡献，2023 年率先开源国内第一个 Chat 大模型 ChatGLM-6B，短时间内就吸引超过千万次下载。智谱持续为开源社区和大模型生态发展注入源源不断的活力。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京市人工智能产业投资基金自 2023 年 12 月成立以来，围绕北京市在人工智能领域的总体布局，开展直接股权投资。重点方向包括人工智能芯片、训练数据及相关软件等底层技术领域，大模型算法创新、具身智能、可信 AI 等关键领域，以及大模型等人工智能技术产品开发和垂直行业创新应用等相关领域。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;阅读更多&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344631&quot; target=&quot;news&quot;&gt;智谱启动上市辅导&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/news/344598&quot; target=&quot;news&quot;&gt;智谱开源 32B/9B 系列 GLM 模型，极速版最高达到 200 tokens/秒&lt;/a&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345155</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345155</guid>
            <pubDate>Sun, 13 Apr 2025 11:29:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Figma 要求 AI 初创公司停止使用「Dev Mode」一词</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                    
                                                        &lt;p&gt;近日，设计协作平台 Figma 向瑞典人工智能编程初创公司 Loveable 发出了一份停止使用&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FBillHeyman%2Fstatus%2F1912182928471412932&quot; target=&quot;_blank&quot;&gt;警告&lt;/a&gt;，原因是 &lt;strong&gt;Loveable 将其新产品的某项功能命名为「Dev Mode」，而 Figma 声称该术语已被其注册为商标&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a60eef82084c2c7bde0249e75284af4f5bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftsdr.uspto.gov%2F%23caseNumber%3D98045640%26caseSearchType%3DUS_APPLICATION%26caseType%3DDEFAULT%26searchType%3DstatusSearch&quot; target=&quot;_blank&quot;&gt;据美国专利商标局的记录显示&lt;/a&gt;，Figma 在 2024 年 11 月成功注册了「Dev Mode」商标。该公司于 2023 年推出了自己的「Dev Mode」功能，旨在帮助设计师和开发者更好地协作。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1838&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0417/183511_QrFp_2720166.png&quot; width=&quot;2684&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.figma.com%2Fdev-mode%2F&quot; target=&quot;_blank&quot;&gt;https://www.figma.com/dev-mode/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Figma 在致 Loveable 的信中表示：「我们很荣幸您认同‘Dev Mode’是连接设计与开发的软件工具的理想名称。」&lt;/p&gt; 
&lt;p&gt;然而，Figma 强调，该术语已与其软件广泛关联，并且公司需要「保护我们的知识产权」，因此要求 Loveable 停止在其产品中使用「Dev Mode」一词。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/345147/figma-the-term-dev-mode</link>
            <guid isPermaLink="false">https://www.oschina.net/news/345147/figma-the-term-dev-mode</guid>
            <pubDate>Sun, 13 Apr 2025 10:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>