<?xml version="1.0" encoding="UTF-8"?>
<rss
    xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>开源中国-综合资讯</title>
        <link>https://www.oschina.net/news/industry</link>
        <atom:link href="http://8.134.148.166:30044/oschina/news/industry" rel="self" type="application/rss+xml"></atom:link>
        <description>开源中国-综合资讯 - Powered by RSSHub</description>
        <generator>RSSHub</generator>
        <webMaster>contact@rsshub.app (RSSHub)</webMaster>
        <language>en</language>
        <lastBuildDate>Wed, 26 Mar 2025 07:37:31 GMT</lastBuildDate>
        <ttl>5</ttl>
        <item>
            <title>清华大学开源 Video-T1：无需重新训练 AI 视频秒变高清大片</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;清华大学的研究团队近日开源了其最新的研究成果——Video-T1。这项技术的核心在于测试时缩放 （Test-Time Scaling， TTS），旨在通过在视频生成过程的推理阶段投入更多的计算资源，显著提升生成视频的质量和与文本提示的一致性，而无需重新进行昂贵的模型训练。这一创新性的方法为视频生成领域带来了新的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;何为「测试时缩放」?&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;在大型语言模型 （LLMs） 领域，研究人员已经发现，通过在测试阶段增加计算量可以有效提升模型性能。Video-T1 借鉴了这一思路，并将其应用于视频生成领域。简单来说，传统的视频生成模型在接收到文本提示后，会直接生成一段视频。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;而采用了 TTS 的 Video-T1，则像是在生成视频的过程中进行多次「搜索」和「筛选」，&lt;strong&gt;通过生成多个候选视频，并利用「测试验证器」进行评估，最终选择质量最高的视频&lt;/strong&gt;。这就像一位精雕细琢的艺术家，在完成最终作品前会尝试多种不同的方法和细节。&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的核心技术&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 并没有直接增加训练成本，而是专注于如何更有效地利用现有模型的能力。其核心方法可以理解为在模型的「噪声空间」中寻找更优的视频生成轨迹。为了实现这一目标，研究团队提出了两种主要的搜索策略:&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;随机线性搜索 （Random Linear Search）&lt;/strong&gt;:这种方法通过&lt;strong&gt;随机采样多个高斯噪声&lt;/strong&gt;，让视频生成模型对这些噪声进行逐步去噪，生成多个候选视频片段，然后利用测试验证器对这些候选视频进行评分，最终选择得分最高的视频。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;strong&gt;帧树搜索 （Tree-of-Frames， ToF）&lt;/strong&gt;:考虑到同时对所有帧进行全步去噪会带来巨大的计算成本，ToF 采用了一种更高效的策略。它将视频生成过程分为三个阶段:首先进行&lt;strong&gt;图像级别的对齐&lt;/strong&gt;，这会影响后续帧的生成;其次，在测试验证器中使用&lt;strong&gt;动态提示&lt;/strong&gt;，重点关注&lt;strong&gt;运动的稳定性&lt;/strong&gt;和&lt;strong&gt;物理上的合理性&lt;/strong&gt;，并根据反馈指导搜索过程;最后，评估视频的整体质量，并选择与文本提示对齐度最高的视频。ToF 这种自回归的方式能够更智能地探索视频生成的可能性。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;291&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-a31db7613d8e9d4e81825607ee221dc4a49.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;TTS 的显著效果&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;实验结果表明，随着测试时计算量的增加（即生成更多候选视频），模型性能会持续提升。这意味着，通过投入更多的推理时间，即使是同一个视频生成模型，也能够产生&lt;strong&gt;更高质量、与文本提示更加一致的视频&lt;/strong&gt;。研究人员在多个视频生成模型上进行了实验，结果都显示出 TTS 能够稳定地带来性能提升。同时，不同的测试验证器关注的评估方面有所不同，因此在性能提升的速率和程度上也存在差异。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;Video-T1 的 TTS 方法在常见的提示类别（如场景、物体）和容易评估的维度 (如图像质量) 上取得了显著的改进。通过观察官方提供的视频演示可以看出，经过 TTS 处理后的视频在&lt;strong&gt;清晰度、细节和与文本描述的贴合度&lt;/strong&gt;上都有明显的提升。例如，描述「戴着太阳镜在泳池边当救生员的猫」的视频，在经过 TTS 处理后，猫的形象更加清晰，救生员的动作也更加自然。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;293&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-97931a836bd63018b344817d13e7d029863.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;h3 style=&quot;margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;挑战与展望&lt;/span&gt;&lt;/h3&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;尽管 TTS 在许多方面都带来了显著的进步，但研究人员也指出，对于一些难以评估的潜在属性，例如&lt;strong&gt;运动的流畅性&lt;/strong&gt;和&lt;strong&gt;时序上的一致性&lt;/strong&gt;（避免画面闪烁），TTS 的改进效果相对有限。这主要是因为这些属性需要对跨帧的运动轨迹进行精确控制，而目前的视频生成模型在这方面仍然面临挑战。&lt;/span&gt;&lt;/p&gt; 
&lt;p style=&quot;color:#242424; margin-left:0px; margin-right:0px; text-align:start&quot;&gt;&lt;span style=&quot;color:#000000&quot;&gt;清华大学开源的 Video-T1 通过创新的测试时缩放策略，为提升视频生成质量提供了一种新的有效途径。它无需昂贵的重新训练，而是通过更智能地利用推理时的计算资源，让现有模型焕发出更强的能力。随着未来研究的深入，我们有理由期待 TTS 技术在视频生成领域发挥越来越重要的作用。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341094</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341094</guid>
            <pubDate>Wed, 26 Mar 2025 07:19:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>哥伦比亚大学研发 3D 光子电子芯片，突破 AI 数据传输瓶颈</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;美国哥伦比亚大学工程团队与康奈尔大学工程团队合作成功开发出全球首款&lt;strong&gt;三维集成光子-电子芯片&lt;/strong&gt;，实现了前所未有的效率和带宽。&lt;/p&gt; 
&lt;p&gt;相关研究论文已于&amp;nbsp;3 月 21 日发表于《自然・光子学》上：&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41566-025-01633-0&quot; target=&quot;_blank&quot;&gt;DOI:&amp;nbsp;10.1038/s41566-025-01633-0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-131d9e739b45c53af3cedf7d25d9ece622b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;▲&amp;nbsp;电气工程教授 Keren Bergman，及电气研究生、论文合著者 Michael Cullen&lt;/p&gt; 
&lt;p&gt;他们通过深度融合光子技术与先进的互补金属氧化物半导体电子技术，让这种新型三维光电子芯片实现了 800Gb/s 超高带宽与 120 飞焦 / 比特的极致能效，带宽密度达 5.3 Tb/s/mm² 远超现有基准。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-fd9154017bb1eae29074e948da27f8417bc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这项突破性的技术有望重塑 AI 硬件，使未来的智能系统能够以更快的速度传输数据，同时显著降低能耗，这对于智能汽车、大规模 AI 模型等未来技术至关重要。&lt;/p&gt; 
&lt;p&gt;Bergman 教授表示：「我们展示了一种能够以空前之低的能耗传输大量数据的技术。这项创新突破了长期以来限制传统计算机和 AI 系统数据传输的能源壁垒。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341093</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341093</guid>
            <pubDate>Wed, 26 Mar 2025 07:15:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>OpenBao 获采纳为 EdgeX 的秘密存储</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为增强安全性和开放性，EdgeX Foundry 正式将 OpenBao 作为 EdgeX 4.0 版本的默认秘密存储。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;EdgeX Foundry 是一个开源的 IoT/边缘计算框架，由 Linux 基金会托管。它旨在通过灵活的微服务架构，实现设备、应用和服务之间的无缝通信。无论你在自动化、能源还是建筑管理领域，EdgeX 都能以标准化的方式将一切连接起来。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;152&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c1956e610d420b596ef4a166f66529a5a0b.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此前，EdgeX 主要依赖 HashiCorp Vault 安全存储敏感信息。然而，随着 Vault 转向商业源许可证（BSL），EdgeX 社区选中了 OpenBao 作为未来的替代方案。OpenBao 是一个由社区驱动的开源项目，属于 Linux 基金会。它提供基于身份的秘密和加密管理系统，确保敏感数据得到保护。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公告&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FMZsyEUjRY2JkmfAaY9o-BA&quot; target=&quot;_blank&quot;&gt;指出&lt;/a&gt;，选择 OpenBao 的原因包括：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;无缝迁移 – OpenBao 设计上与其上游 API 兼容，切换过程顺利且无忧。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;开放和供应商中立的许可证 – 开源自由和长期社区合作。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;安全优先的方法 – 强加密和基于身份的访问控制确保秘密安全。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style=&quot;color:#000000&quot;&gt;活跃的社区支持 – 专注团队确保持续改进、安全更新和功能增强。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于已经在使用 EdgeX 的用户，这一变更几乎不会造成影响。核心服务已更新以支持 OpenBao，同时保持与之前相同的 API，意味着干扰最小。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341087</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341087</guid>
            <pubDate>Wed, 26 Mar 2025 07:05:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>顶尖 AI 专家齐国君自美归国：加盟西湖大学、拿过华为总裁奖</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.scmp.com%2Fnews%2Fchina%2Fscience%2Farticle%2F3303527%2Fai-expert-guo-jun-qi-leaves-us-china&quot; target=&quot;_blank&quot;&gt;根据《南华早报》的报道&lt;/a&gt;&lt;/u&gt;，屡获殊荣的人工智能（AI）专家和计算机科学家齐国君在美国工作十几年后，已回国加盟位于杭州的西湖大学领导 「MAPLE 实验室」 团队。&lt;/p&gt; 
&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.westlake.edu.cn%2Ffaculty%2Fguojun-qi.html&quot; target=&quot;_blank&quot;&gt;据西湖大学官网介绍&lt;/a&gt;&lt;/u&gt;，齐国君，安徽合肥人，国际电气和电子工程师协会会士（IEEE Fellow）、国际模式识别联合会会士（IAPR Fellow）、国际计算机协会（ACM）杰出科学家，中国科学技术大学郭沫若奖得主。&lt;/p&gt; 
&lt;p&gt;齐国君课题组主要开展机器感知和学习方向的研究，致力于研发对虚实场景进行多模态感知、生成与交互的人工智能系统，并应用于多媒体计算、基于 AIGC 的智慧创作等领域。他在人工智能多模态算法与模型、智慧创作与虚拟现实等多个领域取得了多项开创性成果。已在相关国际会议与杂志上发表论文共计 200 余篇，引用近 20000 次。&lt;/p&gt; 
&lt;p&gt;西湖大学形容，通俗地讲，齐国君可以被看做机器的 「养育者」，他开发模型，教机器能够同时理解文字、图片、音频、视频等多种媒介传递的信息，让机器变得 「更智能」。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/145658_Rof3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;从 2014 年到 2024 年，齐国君在美国做了十年研究，他先加入了 IBM T.J. Watson 研究中心担任研究员，之后进入美国中佛罗里达大学执教一年。然后离开美国中佛罗里达大学，加入华为美国研究中心，担任技术副总裁（Technical VP）和首席 AI 科学家（Chief AI Scientist）。&lt;/p&gt; 
&lt;p&gt;在华为美国研究中心，他主要负责华为云 EI 智能体项目，主持设计 TrafficGo 智慧城市系统，优化整合了每天数亿级的多模态数据，对 200 多个路口的复杂路况进行实时调控，极大提升了交通出行效率和应急事件处理速度，因此获得华为总裁奖。&lt;/p&gt; 
&lt;p&gt;再然后，他去了 OPPO，一手创立了 OPPO 西雅图研究中心，还是立足于多模态数据的处理，把研究的边界往虚拟现实领域拓宽了一步。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341086</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341086</guid>
            <pubDate>Wed, 26 Mar 2025 07:00:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>中国大模型密集开源，影响几何？</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年以来，中国大模型开源的消息一个接一个。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里云通义千问从除夕夜开源全新的视觉模型 Qwen2.5-VL，再到本月初发布并开源了全新推理模型 QwQ-32B，在开源当日就登顶全球主流 AI 开源社区 Hugging Face 的趋势榜。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;DeepSeek(深度求索) 达成过「开源周」，其在 2 月末连续五天发布五个代码库，并于近日继续开源上线了升级后的 DeepSeek-V3 模型。 阶跃星辰则在一个月左右时间开源三款多模态大模型，其最新开源的是图生视频模型 Step-Video-TI2V，支持生成的视频具备运动幅度可控和镜头运动可控两大核心特点，同时自带一定的特效生成能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;为何开源大模型成为中国当前的发展潮流？FutureLabs 未来实验室首席专家胡延平对中新社记者表示，大模型厂商普遍选择开源，且有强劲的市场爆发力，是因为人工智能发展处在四个重要时刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;一是端侧智能的需求崛起，包括个人单机部署 AI 方面的需求，推动端侧智能快速发展。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;二是企业行业 AI 部署的需求驱动，千行百业 AI 需求激增，但通用云端大模型难以满足差异化的业务场景与数据隐私保护的需要。开源凭借灵活性和定制化能力，成为企业实现差异化部署的首选，开源模型体现出随需应变的明显优势。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中新社记者获取的数据显示，截至 3 月 25 日，通义千问开源模型 Qwen 系列的全球下载量已超 2 亿。通过千千万万的开发者和中小企业，通义大模型深入千行百业，包括医疗、教育、金融、电力、交通、计算机等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;三是 AI 产业生态化进入加速时刻，出现分工协作体系，上下游协作关系更为清晰。头部企业聚焦模型能力强化，中小企业则基于开源模型开发细分场景应用，形成企业数量更大的产业腰部、大模型后市场，这是一个分工日趋明确的产业生态。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;四是 AI 大模型能力提升显著，从「可用」进入「高可用」时刻，用户、应用由此进入爆发性增长时刻。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据中国工信部官方消息，目前，中国已成为全球开源参与者数量排名第二、增长速度最快的国家。另有数据显示，阿里通义开源模型的衍生模型数量已突破 10 万个，成为全球最大的开源模型族群。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国大模型密集开源，影响几何？&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;中国科学院院士梅宏曾表示，大语言模型在未来需要像互联网一样，走向开源，由全世界共同维护一个开放共享的基础模型，尽力保证其与人类知识的同步。否则，任何一个机构所掌控的基础模型都难以让其他机构用户放心地上传应用数据，也就很难产生足以满足各行各业业务需求的大量应用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;胡延平说，以通义千问为代表的中国大模型正借助这一波开源大势，缩小与全球领先 AI 技术的差距，最重要的是中国开源的生态化获得极大成功，为今后发展积蓄了较强势能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;阿里云高级总监朱迅垚认为，现在大家逐步认识到，开源模型将成为推动中国人工智能发展最强劲的引擎。下一步，建议从国家到地方再到企业，以更加积极的态度拥抱开源，同时在布局智能算力、构建高质量数据集、上云用云等方面加快创新步伐，紧跟世界先进水平。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;有外媒近日报道称，中国科技公司选择开源路线，不仅是为了与同类型公司展开竞争，更是为了加速 AI 的采用和创新。开源模型降低了成本，为产品创新打开了大门。这一趋势不仅将推动中国 AI 领域的快速发展，甚至可能缩短技术差距。&amp;nbsp;(中新社，记者，夏宾)&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341084</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341084</guid>
            <pubDate>Wed, 26 Mar 2025 06:57:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>苹果花费约 10 亿美元采购英伟达 AI 服务器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;苹果公司曾公开宣称其正在使用 Apple Silicon 服务器来支持&amp;nbsp;Apple Intelligence&amp;nbsp;的运行，&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.investors.com%2Fnews%2Ftechnology%2Fapple-stock-apple-joins-ai-data-center-race%2F&quot; target=&quot;_blank&quot;&gt;但根据 Loop Capital 分析师 Ananda Baruah 的说法&lt;/a&gt;&lt;/u&gt;，&lt;strong&gt;该公司现在也在花费 10 亿美元购买 NVIDIA 的 AI 服务器&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;他在给投资者的一份报告中写道： 「&amp;nbsp;AAPL 正式加入大型服务器集群 Gen AI 游戏，超微[Super Micro Computer] 和戴尔是关键的服务器合作伙伴。虽然我们仍在收集更全面的信息，但这似乎有可能成为 Gen AI LLM（大型语言模型）集群。」&lt;/p&gt; 
&lt;p&gt;Baruah 声称，苹果正在购买 250 台 NVIDIA NVL72 服务器，每台服务器的成本在 370 万至 400 万美元之间。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;梳理事件时间线如下：&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 4 月：消息称苹果将使用自研芯片搭建 AI 服务器&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 6 月：消息称苹果数据中心将全面采用 Apple Silicon&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2024 年 9 月：苹果软件工程高级副总裁 Craig Federighi 公开确认，Apple Intelligence 服务完全运行在自研服务器上，称这是「行业云端处理新标准」。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;2025 年 3 月：分析师披露苹果订购 250 台英伟达 NVL72 服务器，单台成本 370 万至 400 万美元（现汇率约合 2685.9 万至 2903.7 万元人民币），总价近 10 亿美元（现汇率约合 72.59 亿元人民币）。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;据 NVIDIA 称，其 NVL72 服务器包含 36 个 Grace CPU 和 72 个 Blackwell GPU。该公司还表示，截至 2025 年 3 月 18 日，该服务器尚未上市。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4be572287f934556dc646afc95fcd6fca2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;毫无疑问，苹果现在可以预订服务器，而且该公司认为有必要扩大其服务器，这并不奇怪。从数量来看，这可能是为了开发目的，而不是面向公众，但现在还无法判断——这是假设报道是正确的。&lt;/p&gt; 
&lt;p&gt;如果它的目的不仅仅是开发，那么这与 Federighi 的说法并不完全相符，他认为使用 Apple Silicon 服务器「为行业云端处理树立了新标准」。&lt;/p&gt; 
&lt;p&gt;他说：「在我们之前没有 Apple Silicon 服务器的情况下，在数据中心构建服务器，并构建一个在数据中心运行的自定义操作系统，这是一项艰巨的任务。」「[创建]信任模型，除非服务器正在运行的所有软件的签名已发布到透明日志中，否则您的设备将拒绝向服务器发出请求，这无疑是解决方案中最独特的元素之一，并且对信任模型至关重要。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341081/apple-spend-1-billion-on-nvidia-servers-for-ai-analyst</guid>
            <pubDate>Wed, 26 Mar 2025 06:50:27 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>DistilQwen2.5-R1 发布：知识蒸馏助推小模型深度思考</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;p&gt;作者：蔡文睿（清素）、汪诚愚（熊兮）、严俊冰（玖烛）、黄俊（临在）&lt;/p&gt; 
&lt;h1&gt;引言&lt;/h1&gt; 
&lt;p&gt;随着 DeepSeek-R1 和 QwQ-32B 等面向深度推理的大语言模型的开源，&quot;大模型+慢思考&quot;已成为拓展大语言模型智能边界的标准配置。然而，这些模型在资源受限的移动设备和边缘计算场景中的普及仍面临巨大挑战。因此，学术界和工业界迫切需要解决如何有效利用知识蒸馏技术，将这些超大规模深度推理模型的知识迁移到小模型中，从而提升计算效率并降低部署成本的问题。为此，我们在 DistilQwen2.5 系列蒸馏小模型（看&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;）的基础上，推出了更为强大的 DistilQwen2.5-R1 系列深度推理模型。&lt;/p&gt; 
&lt;p&gt;DistilQwen2.5-R1 系列以少量来自 DeepSeek-R1 的思维链蒸馏数据为基础，通过一系列创新的蒸馏策略，有效强化了小模型的深度思考能力。实验评估结果显示，DistilQwen2.5-R1 系列中的多种小规模模型在各项基准测试中表现优异（见下图）。例如，DistilQwen2.5-R1-7B 性能显著超越了其他开源蒸馏模型，包括 OpenThinker-7B。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//ef4e1a2e97f3cb673adaa04eb8d7d3ff.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//af944f244cb9a874812fd4148abf399f.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;为方便开发者和企业在实际应用中使用 DistilQwen2.5-R1 系列模型，其所有的 Checkpoint 已在 Hugging Face 和 Model Scope 开源社区中公开。本文将深入阐述 DistilQwen2.5-R1 的蒸馏算法、性能评估，并且提供在阿里云人工智能平台 PAI 上的使用指南及相关下载教程。&lt;/p&gt; 
&lt;h1&gt;DistilQwen2.5-R1 中的知识蒸馏技术&lt;/h1&gt; 
&lt;p&gt;本节中，我们主要描述 DistilQwen2.5-R1 模型训练中使用的数据增强与知识蒸馏技术。&lt;/p&gt; 
&lt;p&gt;由于自身参数量的显著差异，大模型与小模型的认知与推理轨迹有时并不完全一致。以数学问题为例：对于有的数学问题，小模型由于自身参数量的限制，会倾向于使用更基础的方法去解决问题。而大模型基于其强大的推理能力，会采用较为高阶的方法。比如经典的鸡兔同笼问题，小模型倾向于使用简单枚举法逐一试错，而大模型会直接通过列方程的较高级方法求解。&lt;/p&gt; 
&lt;p&gt;正是由于大小模型的认知轨迹偏差，小模型有时无法有效理解大模型的思维链，此时如果直接该思维链（Chain-of-Thought，CoT）蒸馏到小模型中，往往效果不佳。为此，我们设计了一种小型推理模型训练框架，以消除这种认知轨迹偏差带来的负面影响。在后续训练中，我们还利用这种偏差数据进一步提升小模型的推理能力，最终推出基于该训练框架的 DistilQwen2.5-R1 系列模型。我们提出的训练技术框架包含两个阶段：CoT 数据&quot;评价-改进-验证&quot;机制，以及基于不同认知轨迹数据的偏好优化算法。总体而言，DistilQwen2.5-R1 模型蒸馏的详细算法框架如下图所示：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//df8e195e8ebd7ef30667779a2dcb9f01.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;给定原始的大模型思维链数据集，例如从 DeepSeek-R1 蒸馏的数据集，在一阶段，我们先对其进行数据难度评价，接着根据数据的难度等级对其进行相应的优化，优化之后还要对结果进行验证。我们使用改进且被验证的 CoT 数据集对模型进行 SFT 训练，获取模型的基础推理能力。在二阶段，我们利用一阶段已有的不同难度的 CoT 数据构造偏好数据集，在一阶段的基础上进一步提升小模型的推理能力。&lt;/p&gt; 
&lt;h2&gt;CoT 数据&quot;评价-改进-验证&quot;机制&lt;/h2&gt; 
&lt;p&gt;正如上文中提到的，大小模型间的认知推理轨迹有时存在显著偏差。因此，对于待蒸馏的大模型思维链数据集，小模型无法完全理解。阶段一正是基于这种认知偏差对数据集进行优化，采用了 LLM-as-a-Judge 的范式，对大模型的推理过程进行评价并改进。&lt;/p&gt; 
&lt;p&gt;给定问题、大模型的推理过程和问题的答案，我们使用模型判断这个推理过程是简单、中等还是困难。难度等级的核心标准是小模型是否能够遵循给定的推理过程得到问题的答案。以下是思维链的难度等级及定义：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;中等： 小模型可以遵循该推理过程得到问题的答案。&lt;/li&gt; 
 &lt;li&gt;简单： 给定的推理过程过于简单，缺少小模型所需的必要步骤，导致大模型依赖其强大的推理能力解决问题，而小模型无法遵循该过程得到答案。&lt;/li&gt; 
 &lt;li&gt;困难： 给定的推理过程过于复杂或过于困难，导致小模型无法遵循该过程得到答案。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;基于一个大模型的问题与思维链集合，我们可以将其分为简单、中等和困难三类。对于评级为中等的部分，我们予以保留。对于被评为简单和困难的数据，我们使用模型对思维链进行改进。具体来说：对于简单部分，我们扩展其推理过程，直至小模型可以遵循扩展的过程得到答案。对于评级为困难的部分，我们精简其推理过程，直至小模型可以遵循精简的过程得到答案。&lt;/p&gt; 
&lt;p&gt;我们之后对改进结果进行进一步验证，包括：对改进后的思维链再次评价难度等级，检测其是否被归类为中等难度，以及验证小模型是否能够遵循改进的思维链解决问题。如果改进后的思维链通过验证，说明改进有效，该数据可以被小模型有效理解，我们将其保留。如果验证不通过，说明改进无效，我们将返回到改进步骤，重新进行改进，直至通过验证。最终，我们获取了优化后的思维链数据集，其组成部分如下：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;初始难度评级为中等的数据。&lt;/li&gt; 
 &lt;li&gt;初始难度评级为简单，经过改进扩展后评为中等并通过验证的数据。&lt;/li&gt; 
 &lt;li&gt;初始难度评级为困难，经过改进精简后评为中等并通过验证的数据。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;此时，数据集内所有思维链的最终难度评级均为中等，意味着小模型可以有效理解数据集内的所有思维链，并能遵循这些思维链解决相应推理问题。上文提到的大小模型认知轨迹偏差问题在改进后的数据集中得到妥善解决，其可能带来的负面影响也被消除。我们使用优化后的思维链数据集对 Qwen2.5 系列基座模型进行监督微调（SFT），得到 DistilQwen2.5-R1 系列模型的基础结果。&lt;/p&gt; 
&lt;h2&gt;基于多种认知轨迹数据的偏好优化&lt;/h2&gt; 
&lt;p&gt;在第二阶段，我们基于第一阶段得到的不同难度等级数据对模型进行进一步提升。&lt;/p&gt; 
&lt;p&gt;具体来说，在第一阶段中，评级难度为中等的思维链数据是正确且适合小模型的思维链，小模型能够有效理解该思维链并解决问题。而难度评级为简单或困难的思维链数据依然是正确的思维链，只是不适合小模型。在此基础上，我们使用模型将正确的推理过程改写为一个错误的推理过程。错误的推理过程没有逻辑性，且会误导小模型，使得小模型完全无法遵循该错误的推理过程解决问题。&lt;/p&gt; 
&lt;p&gt;基于改写得到的错误思维链，我们将其与简单、中等和困难的思维链进行两两组合，组成多种偏好数据对。这些偏好数据对中有的偏差大，有的偏差小。基于不同种类的偏好数据对及其特点，我们分别使用针对性的参数配置，在第一阶段模型的基础上，采用 DPO 算法进一步优化小模型的推理能力。&lt;/p&gt; 
&lt;p&gt;最终，我们利用第一阶段得到的不同难度等级的认知轨迹（思维链）数据以及基础模型结果，得到了 DistilQwen2.5-R1 系列模型。&lt;/p&gt; 
&lt;h1&gt;DistilQwen2.5-R1 模型效果评测&lt;/h1&gt; 
&lt;p&gt;在本节中，我们从多个角度评测 DistilQwen2.5-R1 系列蒸馏小模型的实际效果；同时，我们将 DistilQwen2.5-R1 系列模型和当前业界的前沿模型对比效果。&lt;/p&gt; 
&lt;h2&gt;模型综合能力评测&lt;/h2&gt; 
&lt;p&gt;我们在多个模型推理能力评测基准上测试了 DistilQwen2.5-R1 系列模型的能力，涵盖数学、代码和科学问题三个主流推理领域。&lt;/p&gt; 
&lt;p&gt;在数学领域，我们使用 AIME2024 和 MATH-500 这两个基准进行测试，AIME2024 是美国数学邀请赛的 2024 年测试集，包含 30 道高难度数学题，用于评估大语言模型在复杂数学推理和问题解决能力，尤其考察代数、几何等领域的综合应用。MATH-500 是一个数学推理能力的基准测试，包含 500 个测试样本，旨在全面考察模型在数学解题上的能力。它与 AIME2024 类似，但有其独特的测试目标和对比结果，用于衡量模型在不同数学题目上的准确性。&lt;/p&gt; 
&lt;p&gt;在代码领域，我们使用 LiveCodeBench 基准，LiveCodeBench 是一个动态更新的基准测试平台，用于全面评估大型语言模型在复杂编码场景中的能力。它通过从顶级竞赛平台收集高难度编程任务来测试模型的代码生成、自我修复代码执行和测试等能力，是一个综合性、无污染的评价基准。在本次评测中，我们使用 LiveCodeBench 基准的 V2 版本，其包含 2023 年 5 月-2024 年 5 月的 511 个代码问题。&lt;/p&gt; 
&lt;p&gt;在科学问题领域，我们使用 GPQA-Diamond（Grade-Level Problems in Question Answering Diamond）基准，其由纽约大学、CohereAI 及 Anthropic 的研究人员联合发布，包含 198 条结果，是 GPQA 系列中最高质量的评测数据，用于评估模型解决专家级科学问题的能力。&lt;/p&gt; 
&lt;p&gt;如下图所示，DistilQwen2.5-R1 系列模型在 3B、7B、14B 和 32B 四个参数量级的模型中，与原始 Qwen2.5 模型的效果进行了对比。可以看出，本文描述的小型推理模型训练框架显著提升了现有语言模型的推理能力，并在多个评测基准上取得了一致而明显的效果提升。&lt;/p&gt; 
&lt;p&gt;| AIME2024 实验结果对比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//207b970abad48f4d17f71e0d222d2f8e.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | MATH-500 实验结果对比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//1056c98b3384267199dea8c9af2ea521.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | --- | --- | | GPQA Diamond 实验结果对比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//9a42d598276ac93534537cecbe86b9d5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | LiveCodeBench V2 实验结果对比：&lt;br&gt; &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b971800722e3b79bcf1d45428aa572a3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; |&lt;/p&gt; 
&lt;h2&gt;与其他模型能力对比&lt;/h2&gt; 
&lt;p&gt;为了横向比较同期发布的不同参数规模的推理模型效果，下表分别是 DistilQwen2.5-R1 系列模型在各个参数量级上与其他前沿推理模型在上文提到的 4 个基准的评测结果。我们重点对比了 DistilQwen2.5-R1 系列与 OpenThinker、DeepSeek-R1-Distill-Qwen 等系列模型。&lt;/p&gt; 
&lt;p&gt;以下是 7B 量级的对比结果，可以看出，DistilQwen2.5-R1-7B 模型超越了 Bespoke-Stratos-7B 和 OpenThinker-7B。值得注意的是，相较于 OpenThinker-7B，DistilQwen2.5-R1-7B 在使用更少训练数据的情况下在所有基准上达到了更高的结果。DeepSeek-R1-Distill-Qwen-7B 使用了 800k 闭源训练数据，而 DistilQwen2.5-R1-7B 使用了开源数据进行训练（OpenThoughts 数据集过滤和改写得到的子集），在基于开源数据模型领域内处于领先地位。&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;模型&lt;/strong&gt; | &lt;strong&gt;训练数据量&lt;/strong&gt; | &lt;strong&gt;AIME2024&lt;/strong&gt; | &lt;strong&gt;MATH-500&lt;/strong&gt; | &lt;strong&gt;GPQA Diamond&lt;/strong&gt; | &lt;strong&gt;LiveCodeBench V2&lt;/strong&gt; | | --- | --- | --- | --- | --- | --- | | &lt;em&gt;DeepSeek-R1-Distill-Qwen-7B (reported)&lt;/em&gt; | &lt;em&gt;800k&lt;/em&gt; | &lt;em&gt;55.5&lt;/em&gt; | &lt;em&gt;92.8&lt;/em&gt; | &lt;em&gt;49.1&lt;/em&gt; | &lt;em&gt;-&lt;/em&gt; | | Bespoke-Stratos-7B (reported) | 17k | 20.0 | 82.0 | 37.8 | 36.1 | | OpenThinker-7B (reported) | 114k | ++31.3++ | ++83.0++ | ++42.4++ | ++39.9++ | | **DistilQwen2.5-R1-7B ** | &lt;strong&gt;105k&lt;/strong&gt; | &lt;strong&gt;43.33&lt;/strong&gt; | &lt;strong&gt;88.4&lt;/strong&gt; | &lt;strong&gt;42.93&lt;/strong&gt; | &lt;strong&gt;46.38&lt;/strong&gt; |&lt;/p&gt; 
&lt;p&gt;以下是 32B 量级的对比结果。同样地，DistilQwen2.5-R1-32B 在所有已知基准上超越了 Sky-T1-32B-Preview，以及在绝大多数基准上超越了 OpenThinker-32B。&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;模型&lt;/strong&gt; | &lt;strong&gt;训练数据量&lt;/strong&gt; | &lt;strong&gt;AIME2024&lt;/strong&gt; | &lt;strong&gt;MATH-500&lt;/strong&gt; | &lt;strong&gt;GPQA Diamond&lt;/strong&gt; | &lt;strong&gt;LiveCodeBench V2&lt;/strong&gt; | | --- | --- | --- | --- | --- | --- | | &lt;em&gt;DeepSeek-R1-Distill-Qwen-32B (reported)&lt;/em&gt; | &lt;em&gt;800k&lt;/em&gt; | &lt;em&gt;72.6&lt;/em&gt; | &lt;em&gt;94.3&lt;/em&gt; | &lt;em&gt;62.1&lt;/em&gt; | &lt;em&gt;-&lt;/em&gt; | | Sky-T1-32B-Preview (reported) | 17k | 43.3 | 86.4 | 56.8 | &lt;em&gt;-&lt;/em&gt; | | OpenThinker-32B (reported) | 114k | ++66.0++ | ++90.6++ | ++61.6++ | &lt;strong&gt;68.9&lt;/strong&gt; | | &lt;strong&gt;DistilQwen2.5-R1-32B&lt;/strong&gt; | &lt;strong&gt;105k&lt;/strong&gt; | &lt;strong&gt;70.0&lt;/strong&gt; | &lt;strong&gt;93.8&lt;/strong&gt; | &lt;strong&gt;62.12&lt;/strong&gt; | ++65.95++ |&lt;/p&gt; 
&lt;h2&gt;模型多次推理评测&lt;/h2&gt; 
&lt;p&gt;我们还测试了 DistilQwen2.5-R1 系列模型在上文提到的四个基准上多次推理的结果，模型会对同一个问题生成 k 个回答进行评测，即 Pass&lt;a href=&quot;https://my.oschina.net/kaiprince&quot;&gt;@k&lt;/a&gt; 指标。以下是 DistilQwen2.5-R1-7B 和 DistilQwen2.5-R1-32B 在四个基准上 Pass@k 结果（k=2、4、8、16、32、64）。&lt;/p&gt; 
&lt;p&gt;可以看出，随着模型推理次数 k 的逐步增加，两个模型在所有基准上的评测准确率大幅提高。值得注意的是，随着 k 的增加，DistilQwen2.5-R1-7B 在 MATH-500 和 GPQA-Diamond 上涨幅巨大，并且不断逼近 DistilQwen2.5-R1-32B 水准。这表明我们的推理模型训练框架在小模型领域内拥有巨大潜力。我们可以通过多次推理的方式使 7B 模型拥有媲美 32B 模型的能力，极大减少了推理所需的计算资源。&lt;/p&gt; 
&lt;p&gt;| &lt;img src=&quot;https://oscimg.oschina.net/oscnet//ce3b51665de26ca24a5594370d2c0b98.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | --- | | &lt;img src=&quot;https://oscimg.oschina.net/oscnet//d87903ad8d3726d0b56720b8f76f97a1.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; | | &lt;img src=&quot;https://oscimg.oschina.net/oscnet//b7da22ba53431b02d34fff15a7cc1ac3.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt; |&lt;/p&gt; 
&lt;h2&gt;模型输出&lt;/h2&gt; 
&lt;p&gt;对同一数学问题，我们对比了 DistilQwen2.5-R1 系列模型在 7B、32B 量级和同等量级模型的推理结果。从输出结果可以看出，DistilQwen2.5-R1 系列模型在同量级推理模型中处于领先地位。&lt;/p&gt; 
&lt;h1&gt;模型下载和使用&lt;/h1&gt; 
&lt;h2&gt;DistilQwen2.5-R1 在阿里云人工智能平台 PAI 上的实践&lt;/h2&gt; 
&lt;p&gt;以下 HuggingFace transformers 库为例，简要介绍如何在 PAI-DSW 上使用 DistilQwen2.5-R1 模型。首先需要保证 PAI-DSW 镜像内 transformers 版本大于等于 4.37.0，否则会在加载模型时报错：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;KeyError: &#39;qwen2&#39;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;以 DistilQwen2.5-R1-7B 为例，我们可以使用如下代码调用模型：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-7B&quot;

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;xxxxx&quot;
messages=[
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Your role as an assistant involves thoroughly exploring questions through a systematic long thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution. In the Thought section, detail your reasoning process using the specified format: &amp;lt;|begin_of_thought|&amp;gt; {thought with steps separated with &#39;\n\n&#39;} &amp;lt;|end_of_thought|&amp;gt; Each step should include detailed considerations such as analisying questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The solution should remain a logical, accurate, concise expression style and detail necessary step needed to reach the conclusion, formatted as follows: &amp;lt;|begin_of_solution|&amp;gt; {final formatted, precise, and clear solution} &amp;lt;|end_of_solution|&amp;gt; Now, try to solve the following question through the above guidelines:&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;DistilQwen2.5-R1 在开源社区的下载&lt;/h2&gt; 
&lt;p&gt;我们在 Hugging Face 和 Model Scope 上开源了我们蒸馏后的模型，分别为&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-3B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-3B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-7B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-7B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-14B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-14B&lt;/a&gt;、&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Falibaba-pai%2FDistilQwen2.5-R1-32B&quot; target=&quot;_blank&quot;&gt;DistilQwen2.5-R1-32B&lt;/a&gt;。以 Hugging Face 为例，用户可以使用如下代码下载这两个模型：&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from huggingface_hub import snapshot_download

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-3B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-3B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-7B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-7B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-14B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-14B/&quot;)

model_name = &quot;alibaba-pai/DistilQwen2.5-R1-32B&quot;
snapshot_download(repo_id=model_name, cache_dir=&quot;./DistilQwen2.5-R1-32B/&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;小结与未来工作&lt;/h1&gt; 
&lt;p&gt;本文介绍了 DistilQwen2.5-R1 系列深度推理模型，它在少量来自 DeepSeek-R1 的思维链数据基础上，通过创新蒸馏策略增强了小模型的深度思考能力。实验结果表明，该系列模型在多个基准测试中表现出色，尤其是 DistilQwen2.5-R1-7B 的性能全面超越了其他开源蒸馏模型。为了方便实际应用，这些模型的 Checkpoint 已在 Hugging Face 和 Model Scope 社区中公开，并提供了在阿里云人工智能平台 PAI 上的操作指南。在未来，随着大语言模型和知识蒸馏技术更进一步的发展，我们将推出各种领域、各种规格的 DistilQwen 系列模型，充分促进大语言模型在实际应用中的降本增效。&lt;/p&gt; 
&lt;h1&gt;参考资料&lt;/h1&gt; 
&lt;p&gt;相关发表论文&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud. COLING 2025&lt;/li&gt; 
 &lt;li&gt;Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang. Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning. EMNLP 2024&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;技术文章&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;DistilQwen2.5 发布：通义千问蒸馏小模型再升级：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1653842&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1653842&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DistilQwen2：通义千问大模型的知识蒸馏实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdeveloper.aliyun.com%2Farticle%2F1633882&quot; target=&quot;_blank&quot;&gt;https://developer.aliyun.com/article/1633882&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DistilQwen2 蒸馏小模型的训练、评测、压缩与部署实践：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Ftraining-evaluation-compression-and-deployment-of-distilqwen2%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_5.111b25e7cqc8bb&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/training-evaluation-compression-and-deployment-of-distilqwen2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;大语言模型数据增强与模型蒸馏解决方案：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhelp.aliyun.com%2Fzh%2Fpai%2Fuser-guide%2Fllm-data-enhancement-and-model-distillation-solution%3Fspm%3Da2c4g.11186623.help-menu-30347.d_2_3_0_2_6.7b2a25e7Ft8jcP&quot; target=&quot;_blank&quot;&gt;https://help.aliyun.com/zh/pai/user-guide/llm-data-enhancement-and-model-distillation-solution&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;技术交流答疑群&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet//fa60dfa833375be7ed5b66008fb94ed5.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/5583868/blog/18007679</link>
            <guid isPermaLink="false">https://my.oschina.net/u/5583868/blog/18007679</guid>
            <pubDate>Wed, 26 Mar 2025 06:45:27 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>FaunaDB 将于 5 月停止服务，承诺开源核心技术版本</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;NoSQL 数据库 FaunaDB 的供应商 Fauna &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ffauna.com%2Fblog%2Fthe-future-of-fauna&quot; target=&quot;_blank&quot;&gt;表示&lt;/a&gt;，由于缺乏支持和营销数据库服务所需的资金，它将在 5 月底关闭该服务。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「推动广泛采用一种在全球范围内以服务形式运行的新运营数据库需要大量资金。在当前的市场环境下，我们的董事会和投资者已确定不可能单独筹集实现该目标所需的资金。虽然我们将不再接受新客户，但现有的 Fauna 客户不会立即发生变化。我们将逐步让客户退出 Fauna，并致力于确保未来几个月内顺利完成这一过程。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; height=&quot;262&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ce52cf07537bfbb44698b63ccd43c383c6d.webp&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;该公司表示，所有 Fauna 企业客户都需要在太平洋时间 5 月 30 日中午之前将其应用程序和数据移出 Fauna。在此之后，所有 Fauna 帐户及其相关数据将被永久删除。关闭运营的举措预计将影响多家企业的 195 多个数据库和 3,000 多个开发团队。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;此外，Fauna 在通告中作出承诺，计划在之后发布 Fauna 核心数据库技术的开源版本以及现有的开源驱动程序和 CLI 工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「这确保了 Fauna 的独特功能（我们的事务功能、文档关系数据模型和我们的数据库语言 (FQL)）将可供社区使用。我们希望这既能成为数据库从业者的宝贵参考，又能为更广泛的开发者社区提供持续的价值。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Fauna 为受影响的客户提供了迁移期间的支持，详情可查看&lt;/span&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdocs.fauna.com%2Ffauna%2Fcurrent%2Fmigrate&quot; target=&quot;_blank&quot;&gt;迁移指南&lt;/a&gt;。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341068/the-future-of-fauna</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341068/the-future-of-fauna</guid>
            <pubDate>Sun, 23 Mar 2025 06:27:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>Cloudflare 支持远程 MCP 服务器部署</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Cloudflare&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fremote-model-context-protocol-servers-mcp%2F&quot; target=&quot;_blank&quot;&gt;宣布&lt;/a&gt;&lt;/u&gt;，开发者现在可以在他们的平台上构建和部署远程 MCP（模型上下文协议）服务器。这意味着你不再需要在本地电脑上运行这些服务器，而是可以把它们放到云端，让更多用户轻松访问。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/142009_bpL3_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Cloudflare 提供了四个核心组件，大大简化远程 MCP Server 的构建过程：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;workers-oauth-provider&lt;/strong&gt;：简化认证和授权&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;McpAgent&lt;/strong&gt;：处理远程传输&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;mcp-remote&lt;/strong&gt;：允许现有 MCP 客户端连接到远程服务器的适配器&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI playground&lt;/strong&gt;：作为远程 MCP 客户端， 一个带身份验证的聊天界面，可直接连接远程 MCP Server&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;想要开始构建自己的远程 MCP 服务器？只需几个简单步骤：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;访问 Cloudflare 的 MCP 服务器指南 -&amp;nbsp;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fdevelopers.cloudflare.com%2Fagents%2Fguides%2Fremote-mcp-server%2F&quot; target=&quot;_blank&quot;&gt;https://developers.cloudflare.com/agents/guides/remote-mcp-server/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;使用提供的模板创建你的第一个 MCP 服务器&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;自定义服务器功能&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;部署到 Cloudflare 的全球网络&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;与 AI 助手连接&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;详情查看：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fblog.cloudflare.com%2Fremote-model-context-protocol-servers-mcp%2F&quot; target=&quot;_blank&quot;&gt;https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341063/remote-model-context-protocol-servers-mcp</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341063/remote-model-context-protocol-servers-mcp</guid>
            <pubDate>Sun, 23 Mar 2025 06:20:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>智源发布关于被美国商务部列入实体清单的声明</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;针对被美国商务部工业与安全局将北京智源人工智能研究院（简称「智源」）列入实体清单一事。&lt;/p&gt; 
&lt;p&gt;智源研究院发布&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F1Miy6dODbT0X0tAjG8tCpA&quot; target=&quot;_blank&quot;&gt;声明称&lt;/a&gt;，「我们对于民办非营利科研机构被加入实体清单表示震惊，强烈反对这一毫无事实依据的错误决定，要求美国相关部门予以撤回。」&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;268&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4ed2791aab0b687e1345f168830cb44ab87.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;智源作为非营利科研机构，一直坚持开源开放的原则，所有科研技术成果向全球公开共享，并积极参与 AI 安全国际对话，推动人工智能增进社会福祉。人工智能是人类公器，如同电力等所有重大技术革命一样，开源开放是必然趋势，智能时代是全人类共建共享的时代。美国商务部的行为违背科技创新精神，严重损害全球人工智能领域的开放合作。我们呼吁国际社会共同构建开放、包容、合作的技术未来。&lt;/p&gt; 
 &lt;p&gt;智源打造了覆盖模型、算法、数据、评测、系统的大模型开源技术体系。截至目前，智源已累计开源约 200 个模型和近百个数据集，其中，模型全球总下载量近 6 亿次，开源数据集下载量近 39 万次，开源项目代码下载量超 95 万次，为人工智能技术普惠做出持续贡献。&lt;/p&gt; 
 &lt;p&gt;智源将继续坚持开源开放非营利的原则，向全球分享世界一流的大模型技术及人工智能领域的前沿探索，营造最佳的学术和技术创新生态，促进人类、环境和智能的可持续发展。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;相关阅读：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li style=&quot;text-align:start&quot;&gt;&lt;a href=&quot;https://www.oschina.net/news/340997&quot; target=&quot;_blank&quot;&gt;特朗普政府将多家中国科技公司列入 「实体清单」&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341061</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341061</guid>
            <pubDate>Sun, 23 Mar 2025 06:16:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>报告：开源解决方案继续主导可观测性策略</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 最新发布的一份可观测性调查报告&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgrafana.com%2Fobservability-survey%2F&quot; target=&quot;_blank&quot;&gt;指出&lt;/a&gt;，75% 受访者的表示他们在可观测性工作中使用开源解决方案。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;30% 的受访者表示他们只使用开源软件，36% 的受访者主要使用开源软件。另一方面，8% 的受访者只使用商业解决方案，16% 的受访者主要使用商业解决方案，10% 的受访者使用开源和商业解决方案的比例大致相等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;70% 的受访者在某种程度上使用了 Prometheus 和 OpenTelemetry，一半的受访者表示，他们对这两项技术的投资在去年有所增加。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;报告还发现，组织仍然依赖日志（Logging）和指标（Metrics），但追踪（Traces）和配置文件（Profiles）越来越受欢迎。57% 的受访者使用追踪，16% 的受访者使用配置文件，指标和日志分别有 95% 和 87% 的人使用。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;123&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d0ef509d2cbba28c981f44f12e8c64a7936.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;公司还在其堆栈中利用了许多不同的可观测性工具。Grafana Labs 发现，受访者使用了 101 种不同的可观测性工具，平均每家公司使用的工具数量为 8 种，比去年的平均 9 种有所下降。但是有 64% 的公司使用 5 种或更少的工具，只有 2% 的公司使用超过 50 种工具。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;规模较大的公司往往拥有更多的数据源，员工人数超过 5,000 人的公司平均拥有 24 个数据源，而员工人数不超过 10 人的公司平均拥有 6 个数据源。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;对于组织来说，最大的可观测性挑战是复杂性，而警报疲劳（alert fatigue）是更快响应事件的最大障碍。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 发现，虽然可观测性解决方案的成本是选择可观测性工具时最重要的因素，但它并不一定至关重要。不到三分之一的受访者担心可观测性成本，大多数人只是想确保他们从所投资的工具中获得价值。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;选择工具时的其他因素包括易用性、与其他工具的互操作性、是否开源、将来是否易于切换到其他工具、组织内部的熟悉程度以及 AI/ML 功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;Grafana Labs 首席技术官 Tom Wilkie 表示：「我们的 2025 年可观测性调查证实，组织正在采用多元化、以开源为中心的可观测性方法。随着团队管理的工具和数据源比以往任何时候都多，调查结果显示复杂性仍然是最大的挑战。我们正在努力直接解决这些痛点，方法是增强 OpenTelemetry 和 Prometheus 等技术之间的互操作性，通过人工智能功能减少认知负荷，并提供开箱即用的集成解决方案，如 Kubernetes 监控。」&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341059/grafana-observability-survey</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341059/grafana-observability-survey</guid>
            <pubDate>Sun, 23 Mar 2025 06:06:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>【直播】AutoDev 即 MCP 服务</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;div&gt; 
 &lt;p&gt;当我们想让 AI 辅助开发的时候，不仅仅是想要让它写代码，而是能像真人一样自如地「使用各种工具」，比如 AI 生成代码后，自动调用 Git 提交、触发 Jenkins 构建，并通过 Docker 部署到测试环境，等等。&lt;/p&gt; 
 &lt;p&gt;但实际上，当前主流 AI 编程工具确实主要聚焦于 IDE 内部的代码补全与建议功能，其核心能力基于当前编辑上下文进行代码生成，无法直接操作构建工具（如 Maven/Gradle）、测试框架（如 JUnit）或部署系统等外部工具链。&lt;/p&gt; 
 &lt;p&gt;不过，有了 MCP&lt;span style=&quot;background-color:#ffffff&quot;&gt;（Model Context Protocol）&lt;/span&gt;，一切都不一样了。&lt;span style=&quot;background-color:#ffffff&quot;&gt;MCP 是由 Anthropic 公司（Claude 模型） 推出的一个协议，它通过提供一种标准化的接口，LLM 应用就可以访问外部信息、工具和资源。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Thoughtworks AI 辅助开发负责人&lt;/strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;strong&gt;黄峰达花了一天时间，在 AutoDev 中实现了相关的功能&lt;/strong&gt;：即 AutoDev 作为一个 MCP 服务，可以被任何 Agent Tool 调用；AutoDev 作为一个 MCP 客户端，可以调用任何 MCP 服务。&lt;/span&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;283&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-c3e807d75bc0740ed7ca7429e859f6ad312.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;p&gt;AutoDev 是一个开源的 AI 辅助研发插件，在 Intellij IDEA 等 IDE 中，提供了类似于 Cursor Composer、Windsurf 的 AI 程序员自动编程能力。&lt;strong&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;3 月 31 日晚，黄峰达将做客开源中国直播间——「OSC 开源社区」视频号《技术领航》栏目，分享 &lt;/span&gt;AutoDev 如何辅助开发&lt;span style=&quot;background-color:#ffffff&quot;&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MCP 为什么会改变 AI 辅助开发？&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;第二代 AI IDE 的基本思路与架构，以及 AutoDev 的落地实现&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;实操演示：AutoDev 与 MCP 的双向服务&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;AutoDev 未来演进计划，以及正在实现的新功能&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;微信扫码，预约直播：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img height=&quot;715&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8329395a8e51db29496ab664de93d48c92.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播标题：&lt;/strong&gt;下一代 AI IDE：AutoDev x MCP 的双向服务&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播时间：&lt;/strong&gt;3 月 31 日（周一 ）19:00-20:00&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播平台：&lt;/strong&gt;视频号 「OSC 开源社区」&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;直播嘉宾：&lt;/strong&gt;黄峰达（Phodal）&lt;/p&gt; 
 &lt;div&gt; 
  &lt;div&gt; 
   &lt;p&gt;&lt;strong&gt;嘉宾介绍：&lt;/strong&gt;黄峰达（Phodal），Thoughtworks AI 辅助开发与开源解决方案负责人，开源 Unit Mesh AI 辅助研发方案的发起人，包含 AI IDE 插件 AutoDev 等工具；智能体编程语言 Shire 的创始人，架构治理平台 ArchGuard 的核心开发者。他在生成式 AI 辅助需求分析、开发和质量保障方面为多家金融和互联网企业提供落地支持，著有《前端架构：从入门到微前端》《自己动手设计物联网》等多本书籍。&lt;/p&gt; 
   &lt;hr&gt; 
   &lt;div&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;另外，我们还建了一个交流群，一起聊聊自己喜欢的开源项目～～当然啦，如果你有什么特别棒的开源项目，可以推荐过来呀～&lt;/p&gt; 
    &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;img height=&quot;300&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-0e7c43c0b0553350855a379af00c6c7c15d.jpg&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;div&gt; 
     &lt;hr&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;技术领航&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;是开源中国 OSCHINA 推出的一档直播栏目，旨在为&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;开源软件、商业产品、前沿技术、知名品牌活动等各类项目&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;提供一个展示平台，每周五晚上开播&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;栏目邀请项目的创始人、核心团队成员或资深用户作为嘉宾，通过路演式直播分享项目的亮点和经验，有助于提高项目的知名度，吸引更多的用户和开发者关注。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:left&quot;&gt;&lt;span&gt;&lt;span style=&quot;background-color:#ffffff&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;如果你手上也有好的项目，想要跟同行交流分享，欢迎联系我，栏目随时开放～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;p style=&quot;color:#333333; margin-left:0; margin-right:0; text-align:center&quot;&gt;&lt;img height=&quot;537&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-4dd54c1b0b817689ceefa15aa66d79cfae8.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/3859945/blog/18006529</link>
            <guid isPermaLink="false">https://my.oschina.net/u/3859945/blog/18006529</guid>
            <pubDate>Sun, 23 Mar 2025 03:56:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>宝马与阿里巴巴达成 AI 领域战略合作</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;宝马中国宣布与阿里达成 AI 领域战略合作，聚焦大语言模型等技术，阿里通义大模型将应用于中国市场的宝马新世代系列车型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;326&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-ae0f47ae0e235363ed9ac48a8bb6615d880.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;据了解，基于阿里巴巴通义大模型，以斑马元神 AI 为基础，全新 BMW 智能个人助理采用与阿里巴巴共同开发的宝马定制 AI 引擎，将于 2026 年率先搭载于中国生产的 BMW 新世代车型。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;其核心能力将包括拟人化沟通、多智能体协同及开放生态整合，能够实现精准意图捕捉、复杂指令解析、模糊语义理解及严谨逻辑推演，令互动体验更加自然流畅。宝马还将首次推出主动交互推荐功能，利用车内传感器和摄像头获取到的数据进行分析，主动给予客户服务与关怀，比如当客户遗落个人物品在座位时系统将主动提醒乘客。上述 AI 技术和体验将覆盖宝马全动力系统和全车型阵列，油电同智。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;日前，宝马还发布中国 360 度全链 AI 战略，包含 AI 聚焦提升用户体验，AI 赋能业务流程提质增效，供应链合作共赢 3 大支柱和 AI 企业理念。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;今年 2 月，阿里巴巴还与苹果公司达成合作，为国行版的 iPhone 用户提供 AI 功能。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341045</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341045</guid>
            <pubDate>Sun, 23 Mar 2025 03:55:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>全新开源！边缘设备也可运行的推理模型 RWKV7-G1 0.4B 正式发布</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;2025 年 3 月 25 日，RWKV 基金会开源了一个中低端设备也可以运行的推理模型（Reasoning Model）：&lt;strong&gt;RWKV7-G1&lt;/strong&gt; 0.4B。&lt;/p&gt; 
&lt;p&gt;RWKV7-G1 0.4B 具备其它同尺寸模型不具备的&lt;strong&gt;推理能力&lt;/strong&gt; ，同时还支持现实世界 100+ 种语言。在实际测试中，RWKV7-G1 0.4B 模型已经能够完成难度较高的&lt;strong&gt;多语言和代码任务&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;RWKV7-G1 0.4B 推理模型基于 World v3.5 数据集训练。它比此前发布的 RWKV7-G1 0.1B 更强，且性能超越了同参数量的 Transformer 架构模型。&lt;/p&gt; 
 &lt;p&gt;World v3.5 数据集包含更多小说、网页、数学、代码和 reasoning 数据，总数据为 5.16T tokens。我们随机采样了 2T token 的数据来训练 RWKV7-G1 0.4B。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;我们也&lt;strong&gt;开源了 RWKV 模型端聊天 APP&lt;/strong&gt;，方便大家体验 RWKV-7 模型。&lt;/p&gt; 
&lt;h2&gt;模型评测&lt;/h2&gt; 
&lt;h3&gt;英语和多语言能力&lt;/h3&gt; 
&lt;p&gt;RWKV7-G1 0.4B 英语和多语言能力&lt;strong&gt;显著领先&lt;/strong&gt;于同参数的开源模型：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;2025-03-25-RWKV7-G1-eval-en&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f4b63fb9cda392c8b9c1ce4afb3b56cefbd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;无法作弊的评测&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FJellyfish042%2FUncheatableEval&quot; target=&quot;_blank&quot;&gt;Uncheatable Eval&lt;/a&gt; 是&quot;无法作弊的评测&quot;，它使用最新的论文和新闻文章等实时数据，评估开源大语言模型的真实建模能力和泛化能力。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;RWKV7-G1 0.4B 的 Uncheatable Eval 综合得分&lt;strong&gt;在同参数规模的开源模型中处于领先地位&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV7-G1-Uncheatable-Eval&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d787fdf3f4b39c4b56fcf0b0ae0a310a2a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;RWKV7-G1 0.4B 甚至&lt;strong&gt;超越了部分 1.5B 模型&lt;/strong&gt;：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV-7 G1 0.4B 超越部分 1.5B 模型&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-45b50e8249cb35497eeb008f29cb005c91e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;模型实测&lt;/h2&gt; 
&lt;h3&gt;多语言能力&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;RWKV7-G1 0.4B 的多语言能力比 G1 0.1B 更强。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;下面是 G1 0.4B 把中文翻译为英语和德语的推理过程和翻译结果，&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;汉语到英语&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-d19025d44d8f04737b5df32096e42e1f57d.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;汉语到德语&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f1b9a3ef2b3edb2b4e3589f201bd6a0a6f9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;Hugging Face Gradio Demo&lt;/a&gt; 体验更多语言。&lt;/p&gt; 
&lt;h2&gt;代码能力&lt;/h2&gt; 
&lt;p&gt;RWKV7-G1 0.4B 已经拥有能准确完成一些进阶任务的能力，下面是使用 RWKV7-G1 0.4B 写归并排序的示例。 &lt;img alt=&quot;归并排序&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-1c8d6c1459b4c9e3fe3dfff81e6647a6064.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;模型试用&lt;/h2&gt; 
&lt;p&gt;我们提供了多个在线 demo ，也提供移动端聊天 APP。&lt;/p&gt; 
&lt;h2&gt;在线 demo（续写模式）&lt;/h2&gt; 
&lt;p&gt;可以在 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;Hugging Face Gradio Demo&lt;/a&gt; 试用 RWKV7-G1 0.4B 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hugging Face Gradio Demo：&lt;/strong&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FBlinkDL%2FRWKV-Gradio-2&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;RWKV G1 的整体 prompt 格式与 RWKV-7-World 模型类似，可选使用 &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; 标签开启 reasoning 功能：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;User: 我已经是全速前进了!

Assistant: &amp;lt;think&amp;gt;


&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;在线 demo（聊天模式）&lt;/h3&gt; 
&lt;p&gt;为了方便社区体验 RWKV-G1 模型，我们也提供了&lt;strong&gt;聊天模式&lt;/strong&gt;的在线 demo。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hugging Face&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2Fspaces%2FRWKV-Red-Team%2FRWKV-LatestSpace&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/spaces/RWKV-Red-Team/RWKV-LatestSpace&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;魔搭 demo&lt;/strong&gt;：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fstudios%2FRWKV-Red-Team%2FRWKV-LatestSpace%2Fsummary&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/studios/RWKV-Red-Team/RWKV-LatestSpace/summary&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可在此体验已完成训练的 RWKV-7 G1 0.1B 和 0.4B 模型，也可以切换到其他正在&lt;strong&gt;训练中&lt;/strong&gt;的 G1 模型，如 G1 1.5B/2.9B。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;chat-demo&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-3c5f79dcc16fccfaab0af74c3812b401026.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;这个精美的 RWKV 对话界面由 RWKV 社区成员 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fleoncat.top%2F&quot; target=&quot;_blank&quot;&gt;@Leon&lt;/a&gt; 开发，并在 GitHub 仓库 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FSolomonLeon%2Fweb-rwkv-realweb&quot; target=&quot;_blank&quot;&gt;web-rwkv-realweb&lt;/a&gt;中开源。&lt;/p&gt; 
&lt;h3&gt;RWKV 端侧聊天 APP&lt;/h3&gt; 
&lt;p&gt;我们也开发了处于内测阶段的 RWKV 端侧聊天 APP（Android 和 iOS 版本）。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;RWKV-7 G1 0.4B 扮演朋友&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-73017fcfb107a314eab6b36f0bcd4a6bfc9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;在下列地址下载 APP：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Android&lt;/strong&gt; : &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.pgyer.com%2Frwkvchat&quot; target=&quot;_blank&quot;&gt;https://www.pgyer.com/rwkvchat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iOS (TestFlight)&lt;/strong&gt; : &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Ftestflight.apple.com%2Fjoin%2FDaMqCNKh&quot; target=&quot;_blank&quot;&gt;https://testflight.apple.com/join/DaMqCNKh&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;贯彻开源开放的宗旨，RWKV 端侧聊天 APP 也已开源&lt;/strong&gt; ，在 GitHub &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2FMollySophia%2Frwkv_mobile_flutter&quot; target=&quot;_blank&quot;&gt;rwkv_mobile_flutter&lt;/a&gt; 仓库中可以看到项目代码。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;测试数据显示：经过 NPU 优化后，RWKV-7 1.5B 模型在高通 8Gen3 手机芯片实现了 &lt;strong&gt;62 token/s&lt;/strong&gt; 的推理速度，G1 0.1B 模型的推理速度则高达 &lt;strong&gt;170 token/s&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;模型下载&lt;/h2&gt; 
&lt;p&gt;下载已完成训练的 RWKV7-G1 0.1B/0.4B 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Frwkv7-g1%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/rwkv7-g1/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社区：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Frwkv7-g1%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/rwkv7-g1/files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WiseModel：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwisemodel.cn%2Fmodels%2Frwkv4fun%2FRWKV-7-G1%2Ffile&quot; target=&quot;_blank&quot;&gt;https://wisemodel.cn/models/rwkv4fun/RWKV-7-G1/file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载其他训练中的 RWKV7-G1 模型：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hugging Face：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fhuggingface.co%2FBlinkDL%2Ftemp-latest-training-models%2Ftree%2Fmain&quot; target=&quot;_blank&quot;&gt;https://huggingface.co/BlinkDL/temp-latest-training-models/tree/main&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;魔搭社区：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmodelscope.cn%2Fmodels%2FRWKV%2Ftemp-latest-training-models%2Ffiles&quot; target=&quot;_blank&quot;&gt;https://modelscope.cn/models/RWKV/temp-latest-training-models/files&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;G1 模型发布计划&lt;/h2&gt; 
&lt;p&gt;当前已发布 G1 0.1B/0.4B 模型，正在训练 G1 1.5B/2.9B，具体发布计划如下：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;发布计划&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-19b1612de03f0a59d6fb7a00335bad56ff4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;我们也在同时准备更大更优的数据集 &lt;strong&gt;World v3.7&lt;/strong&gt;，用于 G1 7B 训练。&lt;/p&gt; 
&lt;h2&gt;llama.cpp 已适配 RWKV-7&lt;/h2&gt; 
&lt;p&gt;随着 RWKV 社区开发者 Molly 的 &lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fggml-org%2Fllama.cpp%2Fpull%2F12412&quot; target=&quot;_blank&quot;&gt;PR 被合并&lt;/a&gt;，llama.cpp 现已支持 RWKV-7 模型。&lt;/p&gt; 
&lt;p&gt;我们也会继续向 llama.cpp 推送 RWKV-7 G1 模型的聊天模板，以支持 G1 模型，的推理（Reasoning）功能。&lt;/p&gt; 
&lt;h2&gt;加入 RWKV 社区&lt;/h2&gt; 
&lt;p&gt;欢迎大家加入 RWKV 社区，可以从 RWKV 中文官网了解 RWKV 模型，也可以加入 RWKV 论坛、QQ 频道和 QQ 群聊，一起探讨 RWKV 模型。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 RWKV 中文文档：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.rwkv.cn&quot; target=&quot;_blank&quot;&gt;https://www.rwkv.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 RWKV 论坛：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fcommunity.rwkv.cn%2F&quot; target=&quot;_blank&quot;&gt;https://community.rwkv.cn/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐧 QQ 频道：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fpd.qq.com%2Fs%2F9n21eravc&quot; target=&quot;_blank&quot;&gt;https://pd.qq.com/s/9n21eravc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📺 BiliBili 视频教程：&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fspace.bilibili.com%2F3546689096910933&quot; target=&quot;_blank&quot;&gt;https://space.bilibili.com/3546689096910933&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;欢迎大家基于 RWKV-7 进行创业、科研，我们也会为基于 RWKV 的项目提供技术支持。&lt;/p&gt; 
 &lt;p&gt;如果您的团队正在基于 RWKV 创业或开展研究，请联系我们！（在&quot;RWKV 元始智能&quot;微信公众号留言您的联系方式，或发送邮件到&quot;contact@rwkvos.com&quot;。）&lt;/p&gt; 
&lt;/blockquote&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341044</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341044</guid>
            <pubDate>Sun, 23 Mar 2025 03:50:00 GMT</pubDate>
            <author>来源: 投稿</author>
        </item>
        <item>
            <title>直播间互动框架性能优化与稳定性实践</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                                                                        &lt;h1&gt;导读&lt;/h1&gt; 
&lt;p&gt;直播间互动体验框架技术实践，揭秘性能与稳定性优化之道，快来探索吧！在百度直播间歌会红包等活动中，我们创新性地将红包互动与高质内容深度融合，通过技术架构升级与系统性优化，打造了&quot;音乐+红包&quot;（边听歌边抢红包）的沉浸式体验。本次实践显著提升了直播间的并发承载能力、实时互动响应速度和用户参与满意度，同时沉淀出可复用的技术方案，为后续大型直播活动奠定坚实基础。&lt;/p&gt; 
&lt;h1&gt;01&amp;nbsp;&lt;strong&gt;百度直播间歌会红包运营活动介绍&lt;/strong&gt;&lt;/h1&gt; 
&lt;p&gt;为提升直播内容质量和用户粘性，需注入多元化内容，增强直播间多样性和观赏性。同时，通过活动裂变扩大影响力，吸引特定用户群体，保持用户新鲜感和期待感，为平台长期发展奠定基础。&lt;/p&gt; 
&lt;p&gt;为落实直播歌会目标要求，需加快直播间互动体验框架建设，探索新型混合模式和沉淀通用能力，着力适配重点业务场景，打造&quot;音乐+红包&quot;的互动体验，提升直播间品质：&lt;/p&gt; 
&lt;p&gt;一是通用基础。主要包括组件复用、大图压缩等减少产物体积，页面异常、性能、白屏监控，BFF 服务编排扩缩、稳定性监控等。&lt;/p&gt; 
&lt;p&gt;二是访问保障。主要包括页面多域名容灾、开启强缓存；字体、图片、CSS、JS 等静态文件单独 CDN 强缓存域名，开启多级缓存等。&lt;/p&gt; 
&lt;p&gt;三是红包性能。主要包括页面预静态化、数据预加载、文档预取、资源预取、视图预渲染、动效降级等。&lt;/p&gt; 
&lt;p&gt;四是开发体验。主要基于直播前端一站式，建强队伍，确保项目开发流程规范统一，搭建增质增效的研发环境等。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a06a28d331513eaca8f04e99d8cdeb0e87a.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;02 体积&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;2.1 页面划分&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在大型产品需求中，通过合理的页面划分策略，实现高效开发与维护。面对产品需求中罗列的多样玩法功能和 19 种以上的红包状态，研发团队面临的首要挑战是如何将这些功能合理的拆解成多个页面承载。合理的页面划分不仅关乎用户体验的流畅性，更是减小产物体积、提升跨页面资源缓存利用率的关键。通过深入分析业务逻辑与用户行为路径，我们精心设计了页面边界，确保每个页面和组件都承载着唯一元素，同时避免了冗余代码的产生。此外，这一策略还极大地促进了开发团队的协作效率，明确的页面划分减少了代码冲突的可能性，使得团队成员可以高效并行集成，从而加速了开发迭代周期。在直播间端能力的规范化构建上，同样遵循了通用化这一原则。&lt;/p&gt; 
&lt;p&gt;在页面划分时，我们非常注重跨页面资源的最优利用，通过策略性地缓存 HTML、CSS 和 JavaScript 等资源，确保一旦用户在任意时刻首次触发了红包弹出事件，这些资源即可被全面缓存，使用户在后续的页面切换过程中无需再次加载这些核心资源。&lt;/p&gt; 
&lt;p&gt;通过一系列设计举措，划分多页应用（MPA）10+个、单页应用（SPA）20+个、红包组件状态（Component）19+个、规范化直播间端能力（Scheme）30+个，每一项都经过精心设计，共同作用于提升应用的整体性能，为用户带来更加轻盈、快速且协同良好的使用体验。&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.2&amp;nbsp;性能优化&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会抢红包运营活动中，Web 页占据了 80% 的比重，对于每一个依赖较多网络资源的玩法页面，在直播间中实现即时加载和快速展现确实面临较大挑战，尤其是在高并发、低延迟的场景下。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d5e35a55efae3715032ff0e568633c1d733.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△页面展现过程&lt;/p&gt; 
&lt;p&gt;为了有效应对这些挑战，通过深入分析页面展现过程中的各个环节，直播间互动框架提炼出七种通用的优化方案。旨在提升用户交互体验、增强系统的整体性能。并确保直播间玩法在高并发场景下依然能够流畅运行。这些优化方案覆盖了从页面加载、资源获取到实时交互的各个方面，形成了一个全方位的性能提升样板，具体方案如下：&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-691f932fd36dd48901276bce6434bfa98b5.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.3&amp;nbsp;页面预静态化（SSG）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会抢红包的场景中，所有不变的内容（如活动规则、活动主页框架等）使用 SSG 能够显著提高页面通用静态内容的加载速度，同时通过集成 CSR 可以实现部分动态内容的及时更新。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-0f6976513c5f401b3f75425663a7bc78360.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△框架原生 SSG Webpack 插件&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-f217081c740651f27fbd3fe8736d8fc59d7.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△图 1：活动规则 △图 2：攒百元半屏页 △图 3：支线攒碎片&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.4&amp;nbsp;页面静态化（SSR)&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会抢红包的场景中，节目单页作为用户获取歌曲节目信息的第一入口，其快速加载至关重要。SSR 提供快速的节目单页初始加载，后续通过客户端的 JavaScript 动态增强功能（如进度提醒、节目回放等）获得更丰富的交互体验。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-c8d4e5358f9b2488dd9dbdc7708913653ab.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.5&amp;nbsp;增量静态渲染（ISR）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会抢红包的场景中，对于实时性要求极高的红包抢夺场景，ISR 的动态更新和实时交互特性为活动的各个环节提供了实时回显的用户体验：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;首先，在全屏红包弹窗页（如初始红包、任务红包和裂变红包）中，ISR 使得页面无需刷新即可实时更新用户的红包状态。当用户参与活动或完成任务时，ISR 的快速响应确保用户能即时获得任务状态和奖励领取情况，增强了用户的参与感与互动性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;对于实时轮次切换功能，ISR 保障用户迅速在游戏阶段间切换，提升了同页面不同状态的连续性。当活动结束时，系统能够快速通知用户并更新活动状态为下线，避免误导用户继续参与。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在内容分享与社交互动方面，ISR 处理高效的页面加载与实时显示，如微信邀请和海报分享，保证用户能快速刷新助力进度。在邀请分享页，主态用户能立即看到受邀好友的参与情况和贡献，进一步增强社交互动体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-caeada216acb857ffbe6901babb24ff4074.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.6&lt;/strong&gt;&amp;nbsp;数据预取（&lt;strong&gt;Prefetch Data）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会抢红包的场景中，通过 NA 与 H5 之间的有效数据预取和缓存衔接，实现了端数据的复用，有效减少与服务器的交互频率，消除了数据加载的等待时间，确保了在直播环境中用户能够高效参与活动：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;预取皮肤元素配置，进入直播间后，NA 会预取皮肤元素配置，预加载与活动相关的皮肤素材，并将这些信息进行缓存，包括页面主题色和红包动画等。同时，前端 JavaScript 能够在页面弹出时，通过端能力或全局变量直接获取相关数据，用户不需要等待皮肤配置加载，界面视觉能够立即呈现，从而实现在操作上的流畅体验。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;攒百元红包的进度更新，在活动进行中，用户需要实时查看攒百元红包的进度，通过数据预取的方式，能够迅速更新至用户界面。在启动 WebView 的同时，NA 实现数据的并行获取。这意味着在用户点击挂件后，相关的数据请求会立即开始，前端 JavaScript 则能够在执行时通过端能力直接获取这些已经预取的数据，降低了数据延迟加载等待时间，增强了用户参与活动的效率。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-956e641a7cef65f27ac27b6f1f75e9fa42f.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.7&amp;nbsp;文档预取 (Prefetch HTML)&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在互动性较强的直播歌会抢红包的场景中，用户不仅可以观看演出，还能参与抢红包活动。为提供最佳的用户体验，确保用户在首次点击不同功能时能够快速上屏相关内容，采用文档预取能力在后台主动下载歌会相关 HTML 内容，如攒百元半屏页、节目单页等。当用户最终点击某个链接时，直接从内存中读取 HTML 文档内容，无需网络请求，从而显著提高页面加载速度，确保用户在直播间里的互动预期。&lt;/p&gt; 
&lt;p&gt;通过数据结果来看，文档预取的效果非常显著。在优化了节目单页的性能后，Android 用户的首屏加载时间从 3 秒级减少到 500 毫秒级，iOS 用户的首屏加载时间从 2.5 秒级减少到 500 毫秒级。这样的性能提升显然改善了用户体验，使得用户能够快速获取所需信息，进而积极参与到活动中，营造出活跃的直播间氛围。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-321ce9dfad640aac1a82e6ac3361f1663dd.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;△Prefetch SSR/CSR HTML&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-3e468dfa83832e491549cbc9e62ba8750d4.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;2.8&amp;nbsp;资源预取（&lt;strong&gt;Prefetch Resource）&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会的场景中，用户参与抢红包是一个关键的互动环节。在此过程中，确保红包弹出的多层动画和红包图能够迅速、完整地展示对于增强用户体验至关重要。为此，资源预取在这一场景中得到了有效应用，在正式直播活动开始前期，后台服务主动下载、缓存、更新关键资源，包括红包的动画文件和高质量的红包皮图像。以确保当红包正式弹出时，最新的文件已被准备妥当，用户能够立即看到完整的红包图和流畅的动画效果，避免了图片逐块加载造成的卡顿和不完整展示。&lt;/p&gt; 
&lt;p&gt;通过数据结果来看，资源预取的效果非常显著。Android 用户资源加载耗时提升幅度约 46.7%，iOS 用户资源加载耗时提升幅度达 86.1%，大幅提升了整体互动体验，使用户在关键时刻享受到快速且流畅的操作体验。&lt;/p&gt; 
&lt;p&gt;为了确保资源预取的有效性，需要注意以下几点：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;预取的资源应以用户行为的合理预测为基础，避免过度预取，从而造成带宽浪费。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;采用分模块的离线包设计，将每个模块的资源单独管理。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在活动结束后，应及时下线不再需要的资源，释放带宽和用户手机空间。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-432cea91c994b4897164e59311d45182bf1.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-280432b02417e32f6ec6fc85535f7f08a79.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;2.9&amp;nbsp;视图预渲染（&lt;strong&gt;Prerender WebView）&lt;/strong&gt;&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;在直播歌会的场景中，观众们期待快速响应的抢红包互动体验，此时视图预渲染能力发挥了重要作用。当用户进入直播间后，提前在后台加载并渲染抢红包页面内容，并注册页面可见性监听器。即使用户专注于观看直播，红包页面也已准备妥当。用户点击按钮，抢红包页面便迅速显示，无需等待加载和渲染时间，同时触发监听器实时更新数据。这样的即时反馈使得用户几乎可以瞬间查看抢红包的结果，极大提升了参与的积极性和体验感，进一步增强了直播的互动乐趣。&lt;/p&gt; 
&lt;p&gt;在预渲染过程中，仅对用户频繁访问的页面进行预渲染，避免资源浪费，确保当前视图性能不受影响。由于预渲染占用内存资源，因此需要控制 WebView 的数量，防止内存泄漏。在实施时应关注内存管理、时机选择、兼容性和安全性，以灵活适应具体应用场景。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-383b13dd43ff5d680e92e00fc4adc64519a.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-fa16963f047697d9fc6bfef362543f8d08f.gif&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h1&gt;03 稳定性&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;3.1 弹窗稳定性&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;保障直播间红包弹层的进退场稳定性，防止透明弹层卡住以致用户无法互动，是一项关键挑战。在直播间中，红包弹层通过覆盖全屏透明 WebView 实现，且与动画控制密切相关，用户在拆红包动画播放过程中无法进行任何交互，关闭按钮在动画结束后才会显示。这要求我们确保红包动画的持续时间和效果稳定，以便在合适的时机正确显示关闭按钮。为确保红包弹窗正常退出，尤其是在 H5 页面渲染异常或网络不稳定的情况下，用户也能得到一个状态友好的反馈。保障直播间抢红包互动的稳定性，我们设计了「一次握手」和「双重兜底」策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;一次握手，即 Web 内容健康检查：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;JavaScript 通过 WebContentLoaded 端能力，表示 H5 成功接管用户交互，并通知 Native 端取消 WebView 的超时销毁策略，以确保全屏红包弹窗能够稳定展示。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果 H5 接管未在规定时间内完成，Native 端将销毁上层全屏透明的 WebView。这一措施确保用户不会因弹窗问题而中断观看体验，从而能够持续与直播间进行交互。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;双重兜底，即 NA 兜底页和 H5 兜底页：&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;NA 兜底页，当 HTML 入口文件请求异常时，展示 Native 兜底页面，确保用户有可见的替代内容。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;H5 兜底页，在 JS 业务组件发生异常（例如接口请求异常、端能力调用失败、组件内部异常、重要资源缺失）时，展示 H5 兜底内容，为用户提供实质反馈。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a618284a079f94a36954256647ec878cc28.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-9643dfcee6987b9b6f75ca7a9978c27b0b5.png&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&amp;nbsp; &amp;nbsp;&lt;/p&gt; 
&lt;p&gt;△图 1：NA 兜底页 △图 2：H5__兜底页 △图 3：请求______兜底&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.2&amp;nbsp;动效降级&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;炫酷的动效的表现直接影响用户的体验，在直播歌会场景中，红包动效由复杂的元素组成，包括 Lottie 动画、AFX 透明视频和 CSS 动画。炫酷的动效虽然可以增强视觉吸引力，但在低端手机上可能导致卡顿。为确保所有用户可以顺畅参与活动，我们实施了分级动效降级策略：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;高性能设备（High）：在高性能设备上，展示完整的动画和丰富的动态效果，享受到丰富的视觉效果。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;低性能设备（Low）：对于低端手机，复杂的动效将被简化为静态图像或低复杂度的 CSS 动画。例如，红包拆开时只展示基本的静态图形，替代激烈的动态效果，确保用户能够正常阅读红包金额，而不至于因动效卡顿而影响体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;分级动效降级策略能够根据当前手机的实时性能情况，在用户点击拆红包时动态调整展示的动效级别，确保以最佳效果参与活。这种适应性有效地解决了不同设备用户在参与红包活动时可能遇到的性能问题，从而提升整体用户体验的品质。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7968ce45d177cbd1d1d3dd1b6d7f0c28f4b.jpg&quot; alt=&quot;图片&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-5c9ea82e15ec367fd493696b4b23d42eb40.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;3.3&amp;nbsp;组件响应&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;随着用户体验的不断优化，直播歌会抢红包活动中页面组件的运行环境日益复杂。特别是在复杂组件的开发中，组件开发者必须意识到各项适配工作的必要性，以确保用户体验与开发体验之间的平衡。为了有效满足用户需求并提升开发效率，我们需要综合考虑多个环境及其不同状态。至此，在一个组件的设计和实现过程中，需要针对以下五种状态进行响应和适配：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;SSG 环境（编译线环境）：组件在编译过程中，通过 Node.js 将公共的信息（如活动规则）提前生成静态内容，以提供快速响应时间。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;SSR 环境（服务端环境）：组件服务器集群上，通过 Node.js 根据用户请求动态生成相应的内容（如歌会节目单），减去客户端 JavaScript 加载执行时间，加快页面首屏展示速度。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ISR 环境（客户端环境）：组件在浏览器中，通过 JavaScript 进行动态渲染、响应用户点击、滑动等操作，通过异步接口获取最新数据（如红包金额、助力信息）并即时更新界面，保证用户体验的实时性和互动性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;页面可见（Visibility）：组件在浏览器中，通过 JavaScript 控制组件的渲染时机，仅在内容需要展示时才进行渲染（如播放红包动画），减少不必要的 DOM 操作，提升性能并降低资源消耗。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;动效级别（High / Low）：组件在浏览器中，通过 Native 端能力获取用户设备的性能，动态调整组件中的动效，在高性能设备上展示更炫酷的动效，在低性能设备上则展示更简单的动效，确保流畅体验。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;04 总结&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;沉淀直播框架能力&lt;/strong&gt;：通过优化直播间视图容器组件，并形成标准化的组合能力样板，拉升直播间活动页面的性能水准，这些方案具备良好复用性，适用于未来各种直播活动。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;系统稳定性保障&lt;/strong&gt;：组件复用、性能监控和容错机制，减少重复开发和维护成本，进行压力测试与优化，提升系统可靠性和用户体验，确保高峰流量下的稳定性。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;强化互动性体验&lt;/strong&gt;：在直播歌会中建立综合能力框架，特别是在抢红包等互动性强的活动中，确保用户在享受歌会演出的同时体验流畅的互动，鼓励积极参与&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;————END————&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247604026%26idx%3D1%26sn%3Db6c6367e9bcbe2dab70a1282140ea740%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度网盘防雪崩架构实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603987%26idx%3D1%26sn%3D4a88159ec791a37e75053139e0b4682c%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何在百度百舸部署满血版 DeepSeek-V3、DeepSeek-R1 模型&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603986%26idx%3D1%26sn%3Dc10b89bf5b0e34c616c8ba230b3405ae%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;首日调用客户破 1.5 万！DeepSeek-V3/R1 上线背后的超低推理成本技术揭秘&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603905%26idx%3D1%26sn%3D8a870420c3865822760331c3a62d1678%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;唤醒 AI 算力，专有云 ABC Stack 面向企业级智算平台的 GPU 提效实践&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg5MjU0NTI5OQ%3D%3D%26mid%3D2247603901%26idx%3D1%26sn%3D6d46e002ddb623aa67c0eaa2d804fea4%26scene%3D21%23wechat_redirect&quot; target=&quot;_blank&quot;&gt;百度 APP iOS 端磁盘优化实践（上）&lt;/a&gt;&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
            <link>https://my.oschina.net/u/4939618/blog/17679358</link>
            <guid isPermaLink="false">https://my.oschina.net/u/4939618/blog/17679358</guid>
            <pubDate>Sun, 23 Mar 2025 03:47:00 GMT</pubDate>
            <author>原创</author>
        </item>
        <item>
            <title>苹果向浙江大学捐赠 3000 万元，支持编程教育</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;Apple 今日宣布向浙江大学捐赠 3,000 万元人民币，深化其对中国下一代开发者的支持。该合作基于其对移动应用创新赛十年的支持，继续加强 Apple 在大中华区长期开展的学生和开发者的教育支持。&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;1458&quot; src=&quot;https://static.oschina.net/uploads/space/2025/0326/113851_E8YI_2720166.png&quot; width=&quot;2320&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Apple 将与移动应用创新赛的合作伙伴浙江大学共同设立 Apple 移动应用孵化基金，提供最前沿的技术培训，包括 app 开发、产品设计、市场营销和商业运营等专业课程。该基金将通过研讨会、实习和导师制等方式，建立学生开发者与行业领袖和投资者之间的联系，为他们提供更多商业培训，助其在不断发展的 iOS 应用经济中取得成功。&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://static.oschina.net/uploads/space/2025/0326/114039_pIPv_2720166.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Apple CEO Tim Cook 表示：「&lt;span style=&quot;color:#27ae60&quot;&gt;&lt;strong&gt;我们相信编程是一项强大的工具，它能让人们以全新的方式进行创造、交流和解决问题。我们很荣幸能深化与浙江大学长达十年的合作关系，为下一代开发者提供技能支持，帮助他们开发创新应用，创立充满生机的业务。&lt;/strong&gt;&lt;/span&gt;」&lt;/p&gt; 
&lt;p&gt;Apple 对移动应用创新大赛的支持已持续十年，累计共有大中华区近千所高校的 30,000 多名参赛者从中受益。许多参赛者成长为 app 工程师、企业家和教育工作者，不仅获得了个人发展的新机遇，且通过编程为所在社区带来积极的变化。&lt;/p&gt; 
&lt;p&gt;「我们很高兴与 Apple 继续紧密而深入地合作。」浙江大学党委书记任少波表示，「我们将发挥双方各自优势，通过 Apple 移动应用孵化基金，共同携手培育知识、能力、素质、人格全面发展的新质人才。」&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341040</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341040</guid>
            <pubDate>Sun, 23 Mar 2025 03:37:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>商汤合作归墟机器人，推出新一代具有情感陪伴功能的人形机器人</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;归墟机器人与商汤科技合作，&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FzwNQ15Ktqv1H9TwiBRHHDQ&quot; target=&quot;_blank&quot;&gt;推出&lt;/a&gt;新一代具有情感陪伴功能的人型机器人飞燕。该机器人搭载商汤日日新融合大模型交互版「SenseNova-5o」，具有情感陪伴和心理健康筛查干预功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「通过深度应用具备实时交互能力的融合大模型，飞燕具备了强大的全景视界感知能力和深度思考能力，可实现对整个物理世界的信息理解和交互，将推动智能健康和心智陪伴领域实现人机交互体验的突破，引领具身智能领域的创新发展。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;290&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-b8a5d350d8491fce8a473fe8166f6204cac.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;根据介绍，「SenseNova-5o」是商汤「日日新」融合大模型的交互版本，拥有强大的实时交互、视觉识别、记忆思考、持续对话和复杂推理等能力，帮助 AI 与人类更自然、更流畅地交流。基于「SenseNova-5o」，机器人已经实现全景视界感知，可结合空间感知理解能力，合理规划路径与物体交互动作。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;目前，飞燕机器人已经在江苏省第一人民医院投入应用，通过情绪识别、多模态感知与交互等技术，完成一系列心理健康筛查、个性化干预、情感支持等任务，不仅能减少用户在面对真人时的焦虑，还能借助「人形」更流畅地展开沟通。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341016</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341016</guid>
            <pubDate>Sun, 23 Mar 2025 02:30:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>树莓派推出 Raspberry Pi PoE+ 供电器</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;树莓派基金会日前与 Microchip 合作推出&lt;u&gt;&lt;a href=&quot;https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.raspberrypi.com%2Fproducts%2Fpoe-plus-injector%2F&quot; target=&quot;_blank&quot;&gt;适用于 Raspberry Pi 设备的 PoE+ 供电器&lt;/a&gt;&lt;/u&gt;，帮助那些不太容易连接电源的树莓派设备获得供电。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-f0a9e1c0c64406ff8549b5357bee63eebe8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;供电器由 Microchip 制造，设备本身提供 1 个电源连接器和 2 个网络接口。该供电器适用于 Raspberry Pi 3B+ 及更高版本，&lt;strong&gt;售价为 25 美元&lt;/strong&gt;（不包含网络线材）。&lt;/p&gt; 
&lt;p&gt;除此之外，树莓派还透露即将发布专为树莓派 5 设计的 Raspberry Pi PoE+ HAT+。这款新品被称为公司「最小、最高效」的受电设备（PD）配件。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341012/raspberrypi-poe-plus-injector</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341012/raspberrypi-poe-plus-injector</guid>
            <pubDate>Sun, 23 Mar 2025 02:24:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>快手：可灵 AI 累计营业收入超 1 亿元</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;3 月 25 日，快手科技发布 2024 年第四季度及全年业绩。全年营收达 1269 亿元，同比增长 11.8%。全年经调整净利润同比增长 72.5% 至 177 亿元，连续两年实现规模化盈利。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;第四季度营收为 354 亿元，同比增长 8.7%；调整后净利润 47.01 亿元，同比增长 7.8%。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;快手科技创始人兼首席执行官程一笑表示：&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「快手的视觉生成可灵 AI 大模型自从去年 6 月推出后持续迭代，保持全球领先的行业地位，深受国内外创作者好评。快手如今正处在人工智能技术和视频大模型重塑视频内容创作、提升用户体验并拓宽商业生态边界的行业变革前沿。展望未来，我们会始终坚定执行 AI 战略，深耕用户需求，建设基于信任社区的 AI 内容与商业生态，为用户、合作伙伴和股东创造长期价值。」&lt;/span&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;&lt;img height=&quot;337&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-62df1c7cdb5b88d4f6914a9276bb9481985.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;在快手 2024 年第四季度及全年业绩电话会上，程一笑称，2024 年第四季度，快手平台上的 AIGC 营销素材和虚拟数字人直播解决方案的日均消耗超过 3000 万元。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;程一笑表示，根据快手内部测算，AI 大模型预计可以把客户的短视频营销素材制作成本降低 60-70% 甚至更高。目前快手正致力于逐步把磁力引擎全面升级下一代的 AI 智能商业引擎。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;他还透露，自商业化以来截至 2025 年 2 月底，可灵 AI 的累计营业收入超 1 亿元。除了 C 端用户订阅，可灵 AI 也面向 B 端商家提供 API 接入等服务。目前，可灵 AI 已与包括小米、亚马逊云科技、Freepik、蓝色光标等在内的数千家国内外企业客户建立了合作关系。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/341004</link>
            <guid isPermaLink="false">https://www.oschina.net/news/341004</guid>
            <pubDate>Sun, 23 Mar 2025 02:17:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
        <item>
            <title>李开复称 DeepSeek 将中美 AI 差距缩小至 3 个月</title>
            <description>&lt;div class=&quot;content&quot;&gt;
                                                                                            &lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;新加坡《联合早报》报道称，中国初创企业零一万物首席执行官李开复说，在人工智能（AI）发展方面，中国已将与美国在某些领域的差距缩小至仅 3 个月，因为中国初创企业深度求索（DeepSeek）等公司已经研究出如何更有效地使用芯片和应用算法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height=&quot;164&quot; src=&quot;https://oscimg.oschina.net/oscnet/up-eb70519debbb9b97b1ee7ee16d5fbaf9f89.png&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李开复在香港接受路透社采访时说，DeepSeek 的推出表明，中国已经在基础设施软件工程等领域取得领先地位。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「之前我认为差距是 6 到 9 个月，在各方面都落后。现在我认为，在一些核心技术上可能落后 3 个月，但实际上在某些特定领域领先。」&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;李开复形容华盛顿的半导体制裁是一把「双刃剑」，既带来了短期挑战，也迫使中国企业在约束下进行创新，并提到中国企业如何开发自己的算法。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style=&quot;color:#000000&quot;&gt;「DeepSeek 能够通过一种新的强化学习方式来弄清楚思路链，这要么是在赶超美国，要么是在快速学习，甚至可能更具创新性。」（参考消息网）&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
            <link>https://www.oschina.net/news/340999</link>
            <guid isPermaLink="false">https://www.oschina.net/news/340999</guid>
            <pubDate>Sun, 23 Mar 2025 02:11:00 GMT</pubDate>
            <author>来源: OSCHINA</author>
        </item>
    </channel>
</rss>