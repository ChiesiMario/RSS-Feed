<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>oschina - industry - 简体中文</title>
    <link>https://www.oschina.net/news/industry</link>
    <atom:link href="http://127.0.0.1:30044/oschina/news/industry" rel="self" type="application/rss+xml"/>
    <description>已对该 RSS 进行格式化操作：中英字符之间插入空格、使用直角引号、标点符号修正</description>
    <generator>RSSHub</generator>
    <webMaster>contact@rsshub.app (RSSHub)</webMaster>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 18 Sep 2025 07:41:52 GMT</lastBuildDate>
    <ttl>5</ttl>
    <item>
      <title>阿里云爆款云服务器 68 元/年，2 核 2G 限时秒杀，超高性价比，立即抢购！</title>
      <description>覆盖 90%+通用业务场景，组合购买「专享活动价」。</description>
      <link>https://click.aliyun.com/m/1000406832/</link>
      <guid isPermaLink="false">https://click.aliyun.com/m/1000406832/</guid>
      <pubDate>Thu, 18 Sep 2025 07:32:50 GMT</pubDate>
    </item>
    <item>
      <title>蚂蚁百灵大模型团队开源高性能推理 MoE 模型 Ring-mini-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁百灵大模型团队正式发布 Ring-mini-2.0，一款基于 Ling-mini-2.0 架构深度优化的高性能推理型 MoE 模型（Thinking model）。&lt;/p&gt; 
&lt;p&gt;它在总参数量 16B、仅激活 1.4B 参数的情况下，即可达到 10B 级别以下 dense 模型的综合推理能力，尤其在逻辑推理、代码与数学任务中表现卓越，并支持 128K 长上下文及 300+ token/s 的高速生成。&lt;/p&gt; 
&lt;p&gt;&lt;img height="550" src="https://static.oschina.net/uploads/space/2025/0918/151311_MTTi_2720166.png" width="1080" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 以 Ling-mini-2.0-base 为基础继续训练，经过 Long-COT SFT、更稳定持续的大规模 RLVR 以及 RLHF 联合优化，显著提升了复杂推理的稳定性与泛化性。在多项高难度基准（LiveCodeBench、AIME 2025、GPQA、ARC-AGI-v1 等）中，在输出长度相当的情况下，性能显著超越 10B 以下 dense 模型，甚至媲美更大参数量的 MoE 模型（如 gpt-oss-20B-medium），在逻辑推理方面尤为突出。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/151413_jqOH_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;Ring-mini-2.0 已全面开源，模型权重、训练策略与数据配方将全部开放。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ring-mini-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ring-mini-2.0&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372966</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372966</guid>
      <pubDate>Thu, 18 Sep 2025 07:16:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>蚂蚁百灵大模型团队开源 MoE 大模型 Ling-flash-2.0</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;蚂蚁百灵大模型团队正式开源其最新 MoE 大模型 ——Ling-flash-2.0。&lt;/p&gt; 
&lt;p&gt;作为 Ling 2.0 架构系列的第三款模型，Ling-flash-2.0 以总参数 100B、激活仅 6.1B（non-embedding 激活 4.8B）的轻量级配置，在多个权威评测中展现出媲美甚至超越 40B 级别 Dense 模型和更大 MoE 模型的卓越性能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150130_epe3_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="634" src="https://static.oschina.net/uploads/space/2025/0918/150203_ryAo_2720166.jpg" width="1000" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据介绍，Ling-flash-2.0 在仅激活 6.1B 参数的前提下，实现了对 40B Dense 模型的性能超越，&lt;strong&gt;用最小激活参数，撬动最大任务性能&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;为此，团队在多个维度上 「做减法」 也 「做加法」：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1/32 激活比例：每次推理仅激活 6.1B 参数，计算量远低于同性能 Dense 模型&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;专家粒度调优：细化专家分工，减少冗余激活&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;共享专家机制：提升通用知识复用率&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;sigmoid 路由 + aux-loss free 策略：实现专家负载均衡，避免传统 MoE 的训练震荡&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MTP 层、QK-Norm、half-RoPE：在建模目标、注意力机制、位置编码等细节上实现经验最优&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/150338_KdT0_2720166.jpg" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;最终结果是：6.1B 激活参数，带来约 40B Dense 模型的等效性能，实现 7 倍以上的性能杠杆。&lt;/p&gt; 
&lt;p&gt;Ling-flash-2.0 基础版与对话版模型已同步上架 Hugging Face 与 ModelScope，采用 MIT 协议可商用。&lt;/p&gt; 
&lt;p&gt;HuggingFace：https://huggingface.co/inclusionAI/Ling-flash-2.0&lt;br&gt; ModelScope：https://modelscope.cn/models/inclusionAI/Ling-flash-2.0&lt;br&gt; GitHub：https://github.com/inclusionAI/Ling-V2&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372964</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372964</guid>
      <pubDate>Thu, 18 Sep 2025 07:07:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>拥抱新一代 Web 3D 引擎，Three.js 项目快速升级 Galacean 指南</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;blockquote&gt; 
 &lt;p&gt;作者： vivo 互联网前端团队- Su Ning&lt;/p&gt; 
 &lt;p&gt;本文从多个维度对比 Galacean 和 Three.js 两款 Web3D 引擎的差异，并介绍拟我形象项目从 Three.js 切换到 Galacean 以后带来的提升以及项目迁移的心得，为其他 Three.js 项目升级到 Galacean 提供参考。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;1 分钟看图掌握核心观点👇&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-844825cdee521dcf0dd15502276e842fe65.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;span id="OSC_h1_1"&gt;&lt;/span&gt; 
&lt;h1&gt;一、背景&lt;/h1&gt; 
&lt;p&gt;Web 3D 技术的发展日新月异，为我们带来了前所未有的沉浸式体验。从虚拟展示到游戏开发，从建筑可视化到教育模拟，Web 3D 技术的应用场景愈发广泛。而在这一领域，Three.js 作为一款广受欢迎的 JavaScript 3D 库，凭借其简洁易用的 API 和丰富的功能，帮助众多开发者实现了精彩的 3D 项目。&lt;/p&gt; 
&lt;p&gt;然而，随着项目复杂度的不断提升，以及用户对性能和体验要求的日益苛刻，Three.js 逐渐显露出一些局限性。比如在处理重负载时，很容易遇到性能瓶颈，出现卡顿、掉帧等问题。这就如同一位经验丰富的车手，驾驶着一辆曾经性能卓越的赛车，但在面对愈发复杂的赛道和激烈的竞争时，却发现车辆的动力和操控性渐渐力不从心。&lt;/p&gt; 
&lt;span id="OSC_h1_2"&gt;&lt;/span&gt; 
&lt;h1&gt;二、Galacean：新一代 Web 3D 引擎&lt;/h1&gt; 
&lt;span id="OSC_h2_3"&gt;&lt;/span&gt; 
&lt;h2&gt;2.1 业务简介&lt;/h2&gt; 
&lt;p&gt;拟我形象是 vivo 账号中的一个 3D 数字人功能，提供一种代表自由、个性、创新和时尚的虚拟形象，为用户提供更加生动、直观、有趣的交流方式。采用 Native+H5 混合的开发方式，其中 3D 渲染的部分基于 Three.js 进行开发。&lt;/p&gt; 
&lt;span id="OSC_h2_4"&gt;&lt;/span&gt; 
&lt;h2&gt;2.2 技术挑战与痛点&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能瓶颈：&lt;/strong&gt;人物模型包含大量形态键以实现多样化面部特征，导致模型加载解析耗时过长。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;线程阻塞：&lt;/strong&gt;受限于 JS 单线程特性，模型解析过程会造成页面短暂无响应。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;多模型渲染：&lt;/strong&gt;套装切换等场景下，多个模型同时渲染时性能问题尤为突出。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;阴影优化：&lt;/strong&gt;Three.js 的阴影渲染性能消耗大，不得不通过局部阴影和限制捕捉范围等折中方案来平衡画质与性能。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;span id="OSC_h2_5"&gt;&lt;/span&gt; 
&lt;h2&gt;2.3 Galacean 引擎核心优势&lt;/h2&gt; 
&lt;p&gt;Galacean 是一款开源的 Web 游戏引擎，致力于打造一个开放、易用、高效的游戏开发工具，可以通过在线编辑器或者纯代码的形式进行使用。&lt;/p&gt; 
&lt;p&gt;针对现存的技术挑战与痛点，Galacean 做了深度优化：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;多线程处理：&lt;/strong&gt;采用 Worker 避免主线程阻塞。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;移动端适配：&lt;/strong&gt;对大量常量进行近似取值优化，完美适配移动端。&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;性能突破：&lt;/strong&gt;优化数据传输链路，创新缓存设计，显著降低重负载场景下的卡顿现象。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-f7e8fd35268a9e4e6807d7a59d98c296eab.gif" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对比视频 1：加载速度&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" height="240" src="https://oscimg.oschina.net/oscnet/up-b7b3c633bc729e87048a7e7cbbd4c6374b4.gif" width="240" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;对比视频 2：套装切换&lt;/p&gt; 
&lt;p&gt;此外，Galacean 基于 EC（Entity-Component）架构设计，而非 Three.js 的面向对象，大幅提升了开发的灵活性。&lt;/p&gt; 
&lt;p&gt;近期我们将渲染引擎由 Three.js 切换为 Galacean。这一举措不仅解决了页面卡顿问题，还提升了浏览器兼容性（可支持到 chrome82），帧率表现更出色，画面质感也得到显著改善。整体切换过程较为平滑，但也遇到了一些问题。接下来，将与大家分享此次整体升级的相关经验。&lt;/p&gt; 
&lt;span id="OSC_h1_6"&gt;&lt;/span&gt; 
&lt;h1&gt;三、调优过程&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;任务拆解：&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;作为一个数字人项目，涉及到引擎升级的模块大致有&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;①环境初始化&lt;/strong&gt;（场景、相机、光线、引擎设置）&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;② 模型加载&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;骨架获取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;材质获取&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;动画获取&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;③妆容、穿搭还原&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;形态键修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;贴图、颜色修改&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型替换&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;头像（静态头像、动态头像）导出&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;壁纸（静态壁纸、动态壁纸、视差壁纸）导出&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;经过梳理，可以大致分为四类：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;初始化&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;模型加载&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;素材替换&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;动画状态&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;接下来我们对这几个部分进行分别的处理&lt;/p&gt; 
&lt;span id="OSC_h2_7"&gt;&lt;/span&gt; 
&lt;h2&gt;3.1 初始化&lt;/h2&gt; 
&lt;p&gt;有别于 Three.js 的渲染器创建，Galacean 的 engine 初始化是异步方法，所以后续用到用到 engine 的地方需要考虑加载的时序，以及 engine 存在状态的判断。另外，Three.js 中 renderer 的渲染行为需要手动调用，一般是使用 requestAnimationFrame 循环调用，而 Galacean 则不需要，引擎开始渲染只需要调用一次 engine.run 即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;renderer=new&amp;nbsp;THREE.WebGLRenderer({
&amp;nbsp;&amp;nbsp;alpha:&amp;nbsp;true,
&amp;nbsp;&amp;nbsp;antialias:&amp;nbsp;true,
})
document.body.appendChild(renderer.domElement)
const&amp;nbsp;scene =&amp;nbsp;new&amp;nbsp;THREE.Scene()
const&amp;nbsp;camera =&amp;nbsp;new&amp;nbsp;THREE.PerspectiveCamera(15,&amp;nbsp;window.innerWidth/window.innerHeight,&amp;nbsp;0.1,&amp;nbsp;100)
requestAnimationFrame(function&amp;nbsp;render() {
&amp;nbsp; renderer.render(scene, camera)
&amp;nbsp;&amp;nbsp;requestAnimationFrame(render)
})&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;const&amp;nbsp;engine =&amp;nbsp;await&amp;nbsp;WebGLEngine.create({
&amp;nbsp; canvas,
&amp;nbsp;&amp;nbsp;physics:&amp;nbsp;new&amp;nbsp;LitePhysics()
})
engine.run()&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中，尺寸单位统一以米为基准，无需额外进行特殊处理。不过在角度单位的使用上存在差异：Three.js 里，仅相机的 fov（视场角）采用角度单位，其他涉及角度的参数均以弧度计量；而 Galacean 则采用更为统一的设定，所有角度相关单位均为角度。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
camera.fov =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&amp;nbsp;* Math.PI/180

/** Galacean */
camera.fieldOfView =&amp;nbsp;15
item.rotation.y =&amp;nbsp;15&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中颜色的设置更加灵活，可以使用 16 进制或者 RGB 值来进行赋值，但是在 Galacean 中只能通过 RGB 来进行赋值，且有别于 0-255 的取值范围，Galacean 中的颜色范围是 0-1。从 Galacean1.5 版本开始，默认的色彩空间改为线性，在代码中需要手动转换一下。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
directLight.color=0xffffff
directLight.intensity=0.9

/** Galacean */
const&amp;nbsp;color =&amp;nbsp;new&amp;nbsp;Color(0.9,&amp;nbsp;0.9,&amp;nbsp;0.9,&amp;nbsp;1)
color.toLinear(color)
directLight.color = color&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_8"&gt;&lt;/span&gt; 
&lt;h2&gt;3.2 模型加载&lt;/h2&gt; 
&lt;p&gt;对于包含大量形态键和动画的模型，将模型打成 zip 包可以有效的压缩模型的体积，不论是 Three.js 还是 Galacean 都不支持加载 zip 包，但是我们可以自行扩展模型加载的链路，将 zip 下载后解压出的模型获取 ObjectUrl 再放到各自的加载器中加载，这样加载进度的获取也可以进行自定义，不需要进行额外的改造。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;exportclassModelLoader {
&amp;nbsp;&amp;nbsp;engine:&amp;nbsp;WebGLEngine
&amp;nbsp;&amp;nbsp;constructor(engine: WebGLEngine){
&amp;nbsp; &amp;nbsp;&amp;nbsp;this.engine&amp;nbsp;= engine
&amp;nbsp; }
&amp;nbsp;&amp;nbsp;async&amp;nbsp;load(src:&amp;nbsp;string) {
&amp;nbsp; &amp;nbsp;&amp;nbsp;const&amp;nbsp;url =&amp;nbsp;await&amp;nbsp;fileLoader(src)
&amp;nbsp; &amp;nbsp; returnthis.engine.resourceManager.load&amp;lt;GLTFResource&amp;gt;({
&amp;nbsp; &amp;nbsp; &amp;nbsp; url,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;type:&amp;nbsp;AssetType.GLTF
&amp;nbsp; &amp;nbsp; })
&amp;nbsp; }
}&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Three.js 解析 glTF 模型输出的数据结构较为简单，主要使用模型的场景和动画片段。由于后续需针对特定材质进行替换，所以要根据节点名获取特定节点，再取出节点中的材质信息，模型的骨架也通过这种方式获取。而 Galacean 输出的数据更为全面，除动画片段和实体信息外，模型中使用的材质、贴图、蒙皮和网格信息也会分门别类展示，需要对应内容时直接获取即可，相比 Three.js 更加方便。&lt;/p&gt; 
&lt;span id="OSC_h2_9"&gt;&lt;/span&gt; 
&lt;h2&gt;3.3 素材替换&lt;/h2&gt; 
&lt;p&gt;素材替换如上文总结分为四种，分别是颜色、贴图、形态键和模型的替换，颜色设置我们在初始化中已经讲解，而模型加载和展示也没有特别的内容，无非是节点/实体的添加和移除，这里我们讲下贴图和形态键修改的一些 tips。&lt;/p&gt; 
&lt;p&gt;在 Three.js 中修改材质贴图 map 可以直接直接使用 canvas 或者 image，修改后需要将材质 needsUpdate 属性设置为 true。而在 Galacean 需要先将图片加载为 texture，再进行赋值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
material.map=canvas
material.needsUpdate =&amp;nbsp;true

/** Galacean */
const&amp;nbsp;texture: Texture2D = await engine.resourceManager.load({
&amp;nbsp; url,
&amp;nbsp;&amp;nbsp;type: AssetType.Texture2D
})
material.baseTexture = texture&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;在 Three.js 中修改形态键，可以先通过网格中的 morphTargetDictionary 属性获取到需要修改的形态键的索引，然后修改 morphTargetInfluences 中对应索引的值即可。&lt;/p&gt; 
&lt;p&gt;在 Galacean 中网格渲染器中没有存储形态键的索引信息，而是存储在 MeshRenderer 下的 mesh 属性下的 blendShapes 属性中，通过获取对应名称的形态键在数组中的索引，修改网格渲染器中 blendShapeWeights 属性对应下标的值。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js */
const&amp;nbsp;index = morphTargetDictionary[keyName]

if&amp;nbsp;(index !==&amp;nbsp;undefined) {
&amp;nbsp; mesh.morphTargetInfluences[index] = value
}

/** Galacean */
const&amp;nbsp;blendShapes = skinMeshRenderer.mesh.blendShapes
const&amp;nbsp;index = blendShapes.findIndex(i=&amp;gt;i.name===keyName)
if&amp;nbsp;(index &amp;gt; -1){
&amp;nbsp; skinMeshRenderer.blendShapeWeights[index] = value
}&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h2_10"&gt;&lt;/span&gt; 
&lt;h2&gt;3.4 动画&lt;/h2&gt; 
&lt;p&gt;相较于 Three.js 的 AnimationMixer 和 AnimationClip，Galacean 拥有更加完善的面向组件的动画系统，支持，状态机、混合动画、时长压缩等，不同动画之间的切换与播放更加简单易维护。&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/** Three.js 播放动画片段 */
const&amp;nbsp;mixer =&amp;nbsp;new&amp;nbsp;THREE.AnimationMixer(scene)
const&amp;nbsp;action=mixer.clipAction(avatarClip)
action.play()
ticker.addEvent(delta =&amp;gt; {
&amp;nbsp; mixer.update(delta)
})

/** Galacean 添加状态机，播放完成回到待机状态 */
const&amp;nbsp;animationState = animator.findAnimatorState('action')
const&amp;nbsp;idleStatle = animator.findAnimatorState('idle')
const&amp;nbsp;transition =&amp;nbsp;new&amp;nbsp;AnimatorStateTransition()
transition.duration =&amp;nbsp;1
transition.offset =&amp;nbsp;0
transition.exitTime =&amp;nbsp;1
transition.destinationState = idleStatle
animationState.addTransition(transition)
animator.play('action')&lt;/code&gt;&lt;/pre&gt; 
&lt;span id="OSC_h1_11"&gt;&lt;/span&gt; 
&lt;h1&gt;四、结语&lt;/h1&gt; 
&lt;p&gt;Galacean 的出现，无疑为 Web 3D 开发领域带来了新的活力。它不仅解决了 Three.js 等传统技术在性能和功能上的诸多痛点，还以其卓越的性能、丰富的功能和易用性，为开发者打开了一扇通往更广阔创意空间的大门。&lt;/p&gt; 
&lt;p&gt;需要注意的是，Galacean 不同版本之间的 API 差异较大，需要进行甄别，同时开发文档及相关的案例也需要进一步完善。&lt;/p&gt; 
&lt;p&gt;对于全新的项目，Galacean 提供编码或在线编辑器两种方式保障创意的高效落地，详细的文档和案例也便于接触 Web3D 开发的新人快速上手。&lt;/p&gt; 
&lt;p&gt;对于存量的项目，Galacean 的迁移成本不高，且整个过程平滑可控，能够有效提升现有项目的画面表现和性能。为未来复杂度更高的需求提供性能保障。&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/vivotech/blog/18692286</link>
      <guid isPermaLink="false">https://my.oschina.net/vivotech/blog/18692286</guid>
      <pubDate>Thu, 18 Sep 2025 07:06:50 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>华为发布全球首个通算超节点</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;在华为全联接大会 2025 上，华为轮值董事长徐直军正式&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.huawei.com%2Fcn%2Fnews%2F2025%2F9%2Fhc-lingqu-ai-superpod" target="_blank"&gt;发布&lt;/a&gt;了全球首个通算超节点华为 Taishan 950 SuperPoD，计划 2026 年一季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直军称，其将能够彻底取代各种应用场景的大型机和小型机以及 Exadata 数据库一体机，将成为各类大型机、小型机的终结者。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-24f09fe6e041b3140f61e7f0fa4a12dc091.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;徐直军指出：「算力过去是，未来也将继续是人工智能的关键，更是中国人工智能的关键」。他认为，超节点在物理上由多台机器组成，但逻辑上以一台机器学习、思考、推理。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;此外，华为发布的最新超节点产品 Atlas 950 SuperPoD，算力规模 8192 卡，预计于 2026 年四季度上市。Atlas 960 SuperPoD 算力规模 15488 卡，预计 2027 年四季度上市。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;基于超节点，华为同时发布了全球最强超节点集群，分别是 Atlas 950 SuperCluster 和 Atlas 960 SuperCluster，算力规模分别超过 50 万卡和达到百万卡。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372960</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372960</guid>
      <pubDate>Thu, 18 Sep 2025 06:57:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 浏览器 Comet 将原生集成密码管理工具 1Password</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;1Password &lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2F1password.com%2Fpress%2F2025%2Fsep%2Fperplexity-partnership" target="_blank"&gt;宣布&lt;/a&gt;与 Perplexity 达成合作，将在 AI 浏览器 Comet 中集成 1Password 的密码管理与自动填充功能。Comet 用户可通过 1Password 浏览器扩展实现安全登录、加密存储及跨设备同步，提升 AI 驱动浏览体验的安全性与便利性。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-21e22de7314980f639afcbb6525a5fa2315.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;作为 Comet 的首个安全合作伙伴，1Password 提供端到端加密与零知识架构，确保用户隐私不被泄露，同时支持快速生成和保存强密码、2FA 验证及无缝设备间同步。&lt;/p&gt; 
&lt;p&gt;Perplexity 首席商务官 Dmitry Shevelenko 称，AI 浏览的高效体验必须建立在安全之上，而 1Password 的隐私、透明度与可用性优势使其成为理想合作伙伴。双方合作的目标是为用户打造「既强大又安全」的互联网体验 。&lt;/p&gt; 
&lt;p&gt;根据安排，现有 1Password 用户将收到邮件邀请，可优先体验 Comet 浏览器。1Password 强调，未来将继续扩展在 AI 场景中的安全应用，帮助用户在智能化时代安全高效地使用互联网。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372959</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372959</guid>
      <pubDate>Thu, 18 Sep 2025 06:48:50 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>国内 500 强企业 GenAI 采用率达 74.6%</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;市场调研机构 Omdia 发布《中国企业 GenAI（生成式 AI）采用格局，2025H1》报告指出，超 7 成的《财富》中国 500 强企业已采用 GenAI。报告称，当前中国 GenAI 正处于高速渗透和规模化应用阶段，本土云厂商提供的全栈 AI 服务以及中国开源模型，将成为市场增长的核心驱动力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;img height="359" src="https://oscimg.oschina.net/oscnet/up-214b4551cb660f989fe43d99eb32a9a19e6.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;据了解，以大模型为核心的生成式 AI 正加速进入中国的千行百业。报告显示，对于中国&amp;nbsp;500&amp;nbsp;强企业在 AI 基础设施、大模型、开发平台和 AI 应用的实际情况，74.6%&amp;nbsp;已经应用或部署生成式 AI，其中，阿里云渗透率为 53% 排名第一，DeepSeek51%、华为云 25%、百度云 22%、腾讯云 20%、火山引擎 9%，分列二至六位。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;Omdia 报告指出，在已使用 GenAI 的《财富》中国 500 强企业中，汽车和媒体文娱产业的渗透率高达 100%，90% 的银行、金融与保险企业（BFSI）以及 51% 的制造企业也已采用 GenAI。Omdia 指出，不同行业的企业对&amp;nbsp;GenAI&amp;nbsp;采用的成熟程度不同，但都积极地将&amp;nbsp;GenAI&amp;nbsp;应用到广泛的场景，包括提升员工生产力、客户服务响应、销售与营销以及流程优化等。到 2029 年，Omdia 预计国内语音助手、图像与视频内容分析、自动化代码开发等多个 GenAI 的核心应用场景的软件收入将实现 2 至 5 倍增长。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#4d4f53; margin-left:0; margin-right:0; text-align:start"&gt;&lt;span style="color:#000000"&gt;Omdia 认为，以阿里云为代表的本土云厂商，通过提供完善的生成式 AI 解决方案，极大地促进了中国企业采用生成式 AI 的进程，当前采用 GenAI 的《财富》中国 500 强企业普遍更倾向于采用本土厂商；另一方面，通义千问、DeepSeek 等中国开源模型，是中国 GenAI 市场爆发的又一关键原因。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372952</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372952</guid>
      <pubDate>Sun, 14 Sep 2025 06:37:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>ChatGPT 付费用户可为 GPT-5 Thinking 模式设定思考时长</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;OpenAI 在 X 平台&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FOpenAI%2Fstatus%2F1968395215536042241" target="_blank"&gt;宣布&lt;/a&gt;，鉴于用户反馈 GPT-5 思考时间有时过长，现针对 Plus、Pro 和 Business 用户，在 ChatGPT 网页版推出 GPT-5 思考时长调整功能。&lt;/p&gt; 
&lt;p&gt;&lt;img height="928" src="https://static.oschina.net/uploads/space/2025/0918/141204_J5Kj_2720166.png" width="1854" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;用户选择 GPT-5 with Thinking 模式后，在消息编辑框处可切换思考时长。其中，Plus、Pro 及 Business 用户可选择标准模式（新默认设置，平衡回复速度与智能程度）和扩展模式（Plus 版之前的默认模式，思考更深但耗时更久）。&lt;/p&gt; 
&lt;p&gt;Pro 用户还有额外选项，轻量模式能使 GPT-5 以最快速度回复；重度模式则让 GPT-5 进行深度思考，回复速度最慢。用户设置的思考时长，在网页版后续对话中保持不变，直至手动更改 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372947</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372947</guid>
      <pubDate>Sun, 14 Sep 2025 06:14:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>​微软斥资 62 亿美元租赁挪威 AI 计算能力</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微软公司日前宣布，将支付 62 亿美元租赁挪威的人工智能计算能力。这一重大投资是与英国数据中心公司 Nscale Global Holdings Ltd. 及挪威投资公司 Aker ASA 的合作成果。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;根据双方的声明，此项目将依托于 「保障的电网容量和完全可再生的电力」 来进行运作。这意味着，微软的 AI 计算将在环保方面做出积极的贡献。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="213" src="https://oscimg.oschina.net/oscnet/up-2464b7cc4919be5da3c739f110951f5ee82.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;此次合作的背景是在全球对人工智能技术的需求不断增长的情况下，尤其是在数据处理和机器学习等领域。微软希望通过这一投资来提升其在 AI 领域的竞争力，并为客户提供更为强大的计算能力。与 Nscale Global 和 Aker ASA 的合作，将使微软能够利用挪威丰富的可再生能源资源，满足日益增长的计算需求。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;挪威以其丰富的水力资源而闻名，能够提供稳定而清洁的电力供应，这对于运行大型数据中心至关重要。在确保电力来源的同时，微软还将关注其碳足迹，力求在推动技术发展的同时，兼顾环保责任。这一项目的成功实施，预计将为全球 AI 产业的发展提供重要支持。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;微软在人工智能领域的战略布局不仅仅体现在资金投入上，还包括技术研发、产品创新以及与全球领先公司的合作。通过这一投资，微软将进一步巩固其在全球科技市场的领导地位，并为客户提供更优质的服务。预计未来几年内，随着 AI 技术的持续进步和应用场景的不断拓展，这一合作将带来显著的经济效益。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372940</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372940</guid>
      <pubDate>Sun, 14 Sep 2025 06:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>IBM 发布 Granite-Docling-258M：开源企业级文档 AI 模型</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;IBM 正式发布了 Granite-Docling-258M，这是一个开源的视觉语言模型，专为端到端文档转换而设计。与传统的 OCR（光学字符识别）技术相比，Granite-Docling 注重保持文档的布局信息，能够有效提取表格、代码、公式、列表、标题等元素，并输出结构化的机器可读格式，而非简化的 Markdown 格式。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Granite-Docling 是 SmolDocling-256M 的改进版。IBM 对原有的技术架构进行了优化，采用了 Granite165M 语言模型，并升级了视觉编码器为 SigLIP2，同时保持了 Idefics3 风格的连接器。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;这一系列更新使得 Granite-Docling 的参数量达到了 258M，并在布局分析、全页 OCR、代码、公式及表格的精确度上都有显著提升。此外，IBM 还解决了在预览模型中发现的不稳定性问题，如重复令牌循环现象。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;Granite-Docling 采用了基于 Idefics3 的架构，使用了 nanoVLM 训练框架。其输出的 DocTags 是 IBM 开发的一种标记语言，能够清晰地表示文档结构，包括元素、座标和关系，方便后续工具将其转换为 Markdown、HTML 或 JSON 格式。这种结构化的输出方式，不仅保持了表格拓扑、数学公式、代码块及标题的顺序，还提高了数据索引的质量和增强了检索能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;&lt;img height="361" src="https://oscimg.oschina.net/oscnet/up-0b74074edcff37ca804f9eaa50858529b51.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span style="color:#000000"&gt;在多语言支持方面，Granite-Docling&amp;nbsp;首次增加了对日语、阿拉伯语和中文的实验性支持，但目前以英语为主要目标。IBM 建议用户将 Granite-Docling 与 Docling 集成，利用其 CLI/SDK 自动转换 PDF、办公文档及图片至多种格式。这款模型能够在 Transformers、vLLM、ONNX 和 MLX 等运行环境中流畅运行，特别为 Apple Silicon 进行了优化。&lt;/span&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372918</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372918</guid>
      <pubDate>Sun, 14 Sep 2025 03:25:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>CodeRabbit 发布面向终端的 AI 代码审查 CLI 工具</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 代码审查初创公司 CodeRabbit&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.coderabbit.ai%2Fblog%2Fcoderabbit-series-b-60-million-quality-gates-for-code-reviews%23heading-how-were-celebrating-by-announcing-coderabbit-cli" target="_blank"&gt;宣布&lt;/a&gt;推出「CodeRabbit CLI」，一款用于终端环境的 AI 代码审查工具，能与 Claude Code、Codex CLI、Cursor CLI、Gemini 等 AI 编码助手无缝协同。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-855b44fbe07e762afd8d359ffde67b8347a.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;CodeRabbit 表示，随着开发者越来越多地通过 CLI 编码助手编写代码，他们发现了一个关键需求：&lt;strong&gt;代码生成速度空前提升，但质量验证往往滞后至 PR 阶段才进行&lt;/strong&gt;。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;CodeRabbit CLI 通过将智能审查直接融入 CLI 工作流，在代码生成与验证之间建立实时反馈循环，彻底改变了这一现状。&lt;/p&gt; 
 &lt;p&gt;无论您是让 Claude Code 重构模块，还是使用 Cursor CLI 实现功能，CodeRabbit 都能即时审查输出结果：捕捉幻觉错误、标记安全隐患，甚至将上下文相关的修复方案反馈给 AI 助手。&lt;/p&gt; 
 &lt;p&gt;CodeRabbit CLI 正是缺失的协调层，它使 AI 生成的代码具备生产就绪能力，将自主开发的美好愿景化为现实。&lt;/p&gt; 
 &lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-3cf9f409139688d994f99832b6c49feec27.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;CodeRabbit CLI 可在任意终端后台运行，并能与 Claude Code、OpenAI Codex CLI、Cursor CLI、Gemini CLI 等主流 AI 编码 CLI 无缝集成。它提供预提交审查、一键修复或完整的 Agent 交接功能，并基于 40 余种来源进行上下文分析。产品提供有额度限制的免费档，Pro 订阅则解锁更高额度与额外功能。&lt;/p&gt; 
&lt;p&gt;详情查看：&lt;em&gt;https://www.coderabbit.ai/cli&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372917</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372917</guid>
      <pubDate>Sun, 14 Sep 2025 03:22:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>AI 推理领域明星创企 Groq 完成 7.5 亿美元融资，投后估值达 69 亿美元</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;AI 推理领域明星创企 Groq&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fx.com%2FGroqInc%2Fstatus%2F1968389894302249277" target="_blank"&gt;宣布&lt;/a&gt;完成 7.5 亿美元新一轮融资，投后估值达 69 亿美元。&lt;/p&gt; 
&lt;p&gt;&lt;img alt="" src="https://oscimg.oschina.net/oscnet/up-1f37323fafa865fba0a4ab33d0bf95bf202.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;本轮融资由 Disruptive 领投，贝莱德（BlackRock）、纽伯格伯曼（Neuberger Berman）、德国电信资本伙伴（Deutsche Telekom Capital Partners）以及一家美国西海岸大型共同基金参与了大额投资，三星、思科、D1、Altimeter、1789 Capital 和 Infinitum 等现有投资者继续跟投。其中，Disruptive 对 Groq 的投资近 3.5 亿美元。&lt;/p&gt; 
&lt;p&gt;Groq 致力于为全球超 200 万开发者及众多财富 500 强企业提供高效且低成本的算力支持，已在北美、欧洲和中东地区布局数据中心。&lt;/p&gt; 
&lt;p&gt;公司创始人兼首席执行官乔纳森·罗斯（Jonathan Ross）表示：「推理技术正定义当下 AI 时代，我们致力于打造高速、低成本的美国 AI 基础设施。」白宫近期发布行政令，推动美国 AI 技术栈出口，Groq 的美国造推理基础设施已为全球开发者和企业提供支持，在这一趋势中扮演关键角色。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/111108_i8dM_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;据悉，这笔资金将用于扩大数据中心规模，Groq 计划今年宣布其在亚太地区的首个布局点 。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372914/groq-raises-750-million-as-inference-demand-surges</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372914/groq-raises-750-million-as-inference-demand-surges</guid>
      <pubDate>Sun, 14 Sep 2025 03:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>KubeSphere 社区版即将发布</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;&lt;span style="color:#000000"&gt;KubeSphere 官方公众号&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FoXCtXJxi5fDBayFx3_bxtg" target="_blank"&gt;发文&lt;/a&gt;宣布，KubeSphere 社区版即将登场 —— 一款永久免费、开箱即用的云原生容器平台。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="398" src="https://oscimg.oschina.net/oscnet/up-700b0889e0eb1c56c121ba858f73d69fae1.png" width="300" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span style="color:#000000"&gt;根据介绍，社区办包含四大亮点：&lt;/span&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;永久免费：零成本无忧使用，持续迭代升级，构建云原生基石。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;简易安装：支持任意环境，在线/离线一键部署，扩容升级更省心。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;功能全面：多租户、可观测性、应用生命周期、DevOps 一应俱全。&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span style="color:#000000"&gt;灵活扩展：可插拔架构，轻松集成主流开源工具，像搭积木一样扩展能力。&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372912</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372912</guid>
      <pubDate>Sun, 14 Sep 2025 03:05:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>腾讯混元公布 SRPO 技术，解决大模型生图「过油」问题</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;腾讯混元团队&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FC3xS9EyvtOsE8x-6J9fplA" target="_blank"&gt;发布&lt;/a&gt;了最新研究成果 —— SRPO（Semantic Relative Preference Optimization，语义相对偏好优化），主要提供了文生图模型的强化算法，解决了开源文生图模型 Flux 的皮肤质感「过油」的问题，能让人像真实感提升 3 倍。&lt;/p&gt; 
&lt;p&gt;根据介绍，针对 Flux.dev.1 模型生成的人物质感「过油」的问题，SRPO 通过在线调整奖励偏好，优化早期生成轨迹等手段很好的解决了这个问题。&lt;/p&gt; 
&lt;p&gt;&lt;img height="313" src="https://oscimg.oschina.net/oscnet/up-f6af7ed86c7e9b248a810db540328ba083e.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="303" src="https://oscimg.oschina.net/oscnet/up-39826f1a005f0c9cea167db74a3ca08ad83.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img height="308" src="https://oscimg.oschina.net/oscnet/up-fcb6c0390cd8afa2083d678b847782d36f8.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;文生图领域传统的在线强化学习方法（如 ReFL，DRaFT）虽展现极高的训练效率，但强依赖一个预先训练好的奖励模型。这些奖励模型除了需要耗费大量的成本收集数据外，还面临泛化性差的问题，通常难以满足多样化，高质量的后训练需求。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;为了解决这个问题，腾讯混元团队联合香港中文大学（深圳）和清华大学提出了：语义相对偏好优化，通过语义偏好实现奖励模型的在线调整。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;具体来说，SRPO 通过为奖励模型添加特定的控制提示词（如「真实感」）来定向调整其优化目标。实验结果显示，这些控制词可以显著增强奖励模型在真实度等特定维度的优化能力。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="155" src="https://oscimg.oschina.net/oscnet/up-f78edc6a752e45e0d90a5e539f80e4e4827.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;研究人员进一步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;发现，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;单纯&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;语义&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;引导&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;仍&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;存在&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;奖励&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;破解&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;（&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;e&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;d&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;h&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;k&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;）&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;风险&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;针对&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;这一问题&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;团队&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;提出&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;创新&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;语义&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;相对&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏好&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;优化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;同时&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;使用&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;正向词&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;负向&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;词&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;作为&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;引导&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;信号&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;通过&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;负向&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;梯度&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;有效&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;中和&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;奖励&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;模型&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;一般性&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏差&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;同时&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;保留&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;语义&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;差异&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;中&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;特定&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;偏好&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="221" src="https://oscimg.oschina.net/oscnet/up-246675f35c7b1997651ffb946609fa6f322.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;并提出了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;D&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;r&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;e&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;-&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;l&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;策略&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;对&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;输入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;图像&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;进行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;可控&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;噪声&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;注入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;随后&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;通过&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;单步&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;推理&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;借助&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;预先&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;注入&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;噪声&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;作为&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;参考&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;锚点&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;」&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;进行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;图像&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;重建&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;这种&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;方法&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;显著&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;降低&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;了&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;重建&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;误差&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;实现&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;更精准&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;奖励&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;信号&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;传导&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;从而&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;支持&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;对&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;生成&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;轨迹&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;的&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;前&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;半段&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;进行&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;优化&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;解决&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;过拟合&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;问题&lt;/span&gt;&lt;/span&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="219" src="https://oscimg.oschina.net/oscnet/up-9d5a1dc47659cc8cead58d4db3a0f205586.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:#000000"&gt;SRPO 具有极高的训练效率，只需 10 分钟训练即可全面超越 DanceGRPO 的效果。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="345" src="https://oscimg.oschina.net/oscnet/up-53524d47ddd3d0886217055ddbde022d450.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;SRPO&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;span style="color:#000000"&gt;定量指标达 SOTA 水平，人类评估的真实度和美学优秀率提升超过 3 倍，训练时间相比 DanceGRPO 降低 75 倍。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:rgba(0, 0, 0, 0.9); margin-left:8px; margin-right:8px; text-align:justify"&gt;&lt;img height="306" src="https://oscimg.oschina.net/oscnet/up-ddf094079d4887628fefa724ca406fab313.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span style="color:rgba(0, 0, 0, 0.9)"&gt;论文链接：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Farxiv.org%2Fabs%2F2509.06942" target="_blank"&gt;Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ul&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372907</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372907</guid>
      <pubDate>Sun, 14 Sep 2025 02:52:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>Linus 发布「吉他效果器」开源项目 GuitarPedal</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;Linux 内核创始人&amp;nbsp;Linus Torvalds&amp;nbsp;昨天在 GitHub 开源了一个名为 GuitarPedal 的「吉他效果器」项目。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;img height="1448" src="https://static.oschina.net/uploads/space/2025/0918/103352_3UWd_2720166.png" width="1744" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;https://github.com/torvalds/GuitarPedal&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;仓库包含电路原理图与少量代码，并非可量产的成品，而是他出于对模拟电路的好奇——把玩运算放大器、JFET 等元件，把焊电路当成「成人乐高」。&lt;/p&gt; 
&lt;p&gt;Linus 写道：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;无论如何，在制作了许多传统的模拟吉他踏板套件之后，我决定去真正了解它们是如何工作的，因为我确实对模拟电路的经验非常有限。&lt;/p&gt; 
 &lt;p&gt;我做过一些非常有限的电子工作，但几乎都与计算机有关，它们要么是数字逻辑，要么是开关电源。&lt;/p&gt; 
 &lt;p&gt;此外，我在寻找一种不同的焊接体验，其中通过孔组件的腿剪断较少。我实际上喜欢焊接 SMT 组件，但这通常不是那些吉他踏板套件所做的事情。&lt;/p&gt; 
 &lt;p&gt;几年前，我用 kicad 进行了一些非常有限的 PCB 设计，所以我就决定开始更多地学习模拟电路。然后它就从这个基础上发展起来了。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Linus 不弹吉他，项目也与 Linux 内核无关，这是纯属个人兴趣的硬件「草图」。&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;BTW，这个仓库应该是「现场制作」，Linus 一个小时前还提交了新的 commit：&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0918/104620_rBPW_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;相关阅读：&lt;a href="https://www.oschina.net/news/329653/linus-torvalds-guitar-pedal-offer" target="_blank"&gt;Linus 变身 「手工林」—— 将亲自打造一套吉他效果器踏板赠送给内核开发者&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372904</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372904</guid>
      <pubDate>Sun, 14 Sep 2025 02:43:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>欣旺达动力加入星环 OS 开源项目指导委员会</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p&gt;2025 年 9 月 16 日，欣旺达动力科技股份有限公司（以下简称「欣旺达动力」）与北京罗克维尔斯科技有限公司（以下简称「罗克维尔斯」）正式签署《星环 OS 合作意向备忘录》。&lt;/p&gt; 
&lt;p&gt;双方宣布，欣旺达动力将作为合作伙伴加入星环 OS 开源项目指导委员会，共同推进智能汽车操作系统的技术演进与生态建设。&lt;/p&gt; 
&lt;p&gt;&lt;img height="765" src="https://static.oschina.net/uploads/space/2025/0918/102936_DGN3_2720166.png" width="1147" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;星环 OS 是由理想汽车发起并开源的全车级操作系统项目，旨在通过社区协作打造开放、高效、可靠的车载系统基础平台，推动汽车智能化功能的持续创新与产业协同发展。指导委员会作为星环 OS 的最高决策机构，负责制定社区治理规范、关键技术方向及生态合作策略。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://static.oschina.net/uploads/space/2025/0423/145233_2m1R_2720166.png" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;通过此次合作，欣旺达动力将成为星环 OS 指导委员会的初始成员单位，深度参与项目决策、技术规划与生态推广。双方将共同推动操作系统核心技术的研发与落地，促进供应链与整车能力的深度融合，为行业提供更开放、安全、可持续的智能汽车软件底座。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372902</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372902</guid>
      <pubDate>Sun, 14 Sep 2025 02:30:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>OpenTiny NEXT 内核新生：生成式 UI × MCP，重塑前端交互新范式！</title>
      <description>&lt;div class="content"&gt;
                                                                                                                    
                                                                                                                                                    &lt;p&gt;近期，我们推出 &lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; ------ OpenTiny 的下一代企业级前端智能开发解决方案。这不仅是一次技术升级，更是一场用户交互范式的变革：从传统的人机交互升级成为人机交互范式和智能体交互范式的融合。我们坚信，&lt;strong&gt;每一个企业应用都值得被 AI 理解，每一次用户交互都可以更自然、更智能。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;项目背景&lt;/h2&gt; 
&lt;p&gt;当前，大语言模型（LLM）正在深刻地改变人机交互的方式。用户期望通过自然语言完成更复杂、更智能化的操作。然而现有的企业应用（&lt;strong&gt;包括 Web 应用、桌面应用、移动应用等&lt;/strong&gt;）大多仍依赖于传统的图形用户界面（GUI）点击操作，无法直接响应 LLM 的指令，使得企业应用与智能体（Agent）之间形成了一道鸿沟。&lt;/p&gt; 
&lt;p&gt;随着 LLM 和 Agent 技术的发展，企业应用正逐步迈入"智能化"阶段。OpenTiny 作为一套成熟的企业前端开发解决方案，拥有 UI 组件库（TinyVue）和低代码引擎（TinyEngine）等产品，在服务传统前端开发场景的基础上，我们顺应 AI 时代需求，对 OpenTiny 进行一次代际升级，构建一套面向未来的"企业智能前端开发解决方案"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; 新的解决方案整合了 AI 技术与 OpenTiny 原有能力，支持企业应用允许 Agent 理解用户意图并自主完成任务，&lt;strong&gt;打造一个 Agent 主导的企业智能应用生态系统。&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;愿景与架构&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;OpenTiny NEXT&lt;/strong&gt; 旨在成为业界领先的企业智能前端开发解决方案，我们致力于为企业应用无缝注入"智驾"能力，打破人、AI 与应用之间的壁垒。&lt;/p&gt; 
&lt;p&gt;我们的愿景是：&lt;strong&gt;让每一个企业应用都能支持 AI 理解用户意图并自主完成任务，让自然语言成为企业应用的下一代交互范式。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;以下是 OpenTiny NEXT 的整体架构图：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-750503dfb19fa0be71b26e089eca9abe839.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;项目介绍&lt;/h2&gt; 
&lt;p&gt;OpenTiny NEXT 智能前端开发解决方案以生成式 UI + WebMCP 两大核心技术为依托，构建一个从后端服务、开发工具到前端 UI 完整的智能产品族。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;基础设施层 (IaaS)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;WebAgent: 连接 Agent 智能体与企业应用内置的 MCP 服务的手臂。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;开发工具层 (PaaS/SDKs)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;NEXT-SDKs: 提供跨前端框架、高可扩展的企业应用智能化开发工具库。&lt;/li&gt; 
   &lt;li&gt;TinyEngine NEXT: 可生成"智能"应用的智能低代码引擎。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;应用与组件层 (SaaS/UI)：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;TinyRobot : 面向最终企业用户的智能体对话入口。&lt;/li&gt; 
   &lt;li&gt;TinyVue NEXT: 承载生成式 UI 引擎的企业级智能组件库。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;门户与生态：&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;OpenTiny NEXT 官网: 产品的统一入口、文档和社区。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NEXT-SDKs：智能应用开发工具包&lt;/h3&gt; 
&lt;p&gt;NEXT-SDKs 是一套开发工具包，旨在简化 WebAgent 的集成与使用，支持多种编程语言和前端框架，帮助开发者快速实现智能化功能。&lt;/p&gt; 
&lt;p&gt;它的核心 SDK (包括 TypeScript, Python, Java 等版本)，提供简化的 API 封装与 WebAgent 服务的连接、认证等逻辑，同时提供易用的 API 让开发者将企业应用的前端功能声明为 MCP Server。针对不同前端框架（Vue、React、Angular、Vanilla）特性，它提供 API 以降低用户在特定前端框架中的使用 MCP Server 和连接 WebAgent 的难度。&lt;/p&gt; 
&lt;p&gt;此外，它还提供一个适配器层，可以将任意前端 AI 对话框组件（包括 TinyRobot 组件）快速接入 WebAgent 服务。并且它支持抹平不同 LLM 差异，支持文字、语音等多模态输入，使得 AI 对话框连接的 LLM 支持受控端的 MCP 工具调用。另外，它还提供动态生成二维码功能，让企业应用里的 MCP 服务成为 AI 对话框里可以让 Agent 调用的工具。&lt;/p&gt; 
&lt;p&gt;当前市面上的 MCP 服务都是后端服务，但是如果用户的后端服务 Api 想要改造成大模型可以理解的 MCP 服务，成本是非常高的，我们用这种逆向思维把 MCP Server 放在前端，这样用户是不需要对已有的后端 Api 进行改动，已有的业务逻辑如果已经封装成前端的 Api，则可以直接注册成 MCP Tool，前端的工具方法或者业务方法放在 MCP Tool 的回调里就完成了向 AI 提供工具的实现。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-8be2f2543afe47175e072bbb3afab00c699.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;WebAgent：智能体 MCP 服务代理&lt;/h3&gt; 
&lt;p&gt;WebAgent 是连接 Agent 智能体与企业应用内置的 MCP 服务的手臂。提供 MCP 市场和动态添加 MCP 插件能力，支持 Agent 调用多个授权企业应用里的 MCP 服务。基于 OAuth 2.1 协议的授权机制，受控的企业应用拥有者可以精细化授权给指定的遥控端 AI 应用。支持 MCP 插件化架构，可连接企业内部的云服务（如对象存储、数据库）或本地工具（如代码执行器），支持企业私有化部署，支持数据和模型调用均在企业内网，并提供多种维度的计费模型，支持用户注册、登录、角色权限分配及管理等。支持多语言版本，与 MCP 官方 SDKs 相对应，分为 TypeScript、Python、Java 等版本。&lt;/p&gt; 
&lt;p&gt;在浏览器运行的 Web 应用都可以接入 Web Agent Server：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-0e2947d8f922737d910fd58255504d470e3.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyRobot：企业智能体个人助手&lt;/h3&gt; 
&lt;p&gt;TinyRobot 是一个企业 AI 应用，支持 Agent 智能体识别用户意图，代替用户自主完成跨多个企业应用的任务。TinyRobot 可调用的 MCP 服务来自 WebAgent 的 MCP 市场和动态添加的 MCP 插件。TinyRobot 会调用 NEXT-SDKs 的能力，实现扫码动态添加 MCP 插件，以及抹平不同 LLM 差异实现 Agent 自主规划和完成任务。&lt;/p&gt; 
&lt;p&gt;同时它也可以作为对话框组件库使用，也可以当作浏览器扩展安装，助力开发者快速构建各种对话框场景页面。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-7cdc72736b59524c36def8e86f753637c3f.jpg" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyVue NEXT：生成式 UI 智能组件库&lt;/h3&gt; 
&lt;p&gt;TinyVue 智能组件库在传统组件库基础上，支持在生成式 UI 场景中使用，AI 智能体可以根据用户意图，按需灵活选择 TinyVue 的组件，呈现给用户可视化的效果，并支持实时互动和交互。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-6dd1a96dc063471b60ad37b80f7fcd23bfd.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h3&gt;TinyEngine NEXT：智能应用低代码引擎&lt;/h3&gt; 
&lt;p&gt;TinyEngine 智能低代码引擎集成 MCP 能力，支持自然语言或图片生成页面，并提供可视化手动编辑与 AI 智能优化双模式，帮助开发者快速构建应用。同时生成应用接入 OpenTiny NEXT，支持 LLM 直接操控，可助力企业应用实现智能化升级。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://oscimg.oschina.net/oscnet/up-258008e78027e24fd311a882b85849d380d.png" alt="" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;h2&gt;场景实践&lt;/h2&gt; 
&lt;p&gt;出差申请是企业高频的办公场景之一，却常因「填表多、流程长」被吐槽。这里我们以"出差申请"场景为例，接入 OpenTiny NEXT 技术后，只需四个步骤，就能实现通过 AI 让企业应用直接被操控，从而实现智能化，让用户直接输入指令，就能完成整个出差流程闭环。&lt;/p&gt; 
&lt;p&gt;【实操视频】&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1v7pMzpEY4%2F%3Fshare_source%3Dcopy_web%26vd_source%3Db20224008749f78db5628f8a1503a97f" target="_blank"&gt;https://www.bilibili.com/video/BV1v7pMzpEY4/?share_source=copy_web&amp;amp;vd_source=b20224008749f78db5628f8a1503a97f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;立即体验，共创智能前端未来&lt;/h2&gt; 
&lt;p&gt;OpenTiny NEXT 即将正式发布，官网、文档、示例、Demo 一站配齐：&lt;/p&gt; 
&lt;p&gt;🌐 官网：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fopentiny.design" target="_blank"&gt;https://opentiny.design&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;📦 GitHub：&lt;a href="https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fgithub.com%2Fopentiny" target="_blank"&gt;https://github.com/opentiny&lt;/a&gt; （欢迎 star）&lt;/p&gt; 
&lt;p&gt;💬 交流群：添加微信小助手 opentiny-official 回复【OpenTiny NEXT】&lt;/p&gt; 
&lt;p&gt;后续我们也会对 OpenTiny NEXT 技术做出详细解读，将陆续发布《&lt;strong&gt;一场 MCP 生态的变革 ------ 详解 OpenTiny NEXT 逆向思维的技术创新&lt;/strong&gt;》 技术文章，请大家敬请期待~&lt;/p&gt; 
&lt;p&gt;OpenTiny NEXT，让每一个企业应用都能支持 AI 理解用户意图并自主完成任务，让自然语言成为企业应用的下一代交互范式。&lt;/p&gt; 
&lt;p&gt;未来已来，欢迎上车！&lt;/p&gt; 
&lt;p&gt;同时欢迎大家进入代码仓库 Star🌟TinyEngine、TinyVue、TinyNG、TinyCLI、TinyEditor~ 如果你也想要共建，可以进入代码仓库，找到 good first issue 标签，一起参与开源贡献~&lt;/p&gt;
                                                                                    &lt;/div&gt;
                                                                            </description>
      <link>https://my.oschina.net/u/6769809/blog/18692067</link>
      <guid isPermaLink="false">https://my.oschina.net/u/6769809/blog/18692067</guid>
      <pubDate>Sun, 14 Sep 2025 02:17:00 GMT</pubDate>
      <author>原创</author>
    </item>
    <item>
      <title>深谋商业化一骑绝尘，人形机器人中标国网电力，大载重 eVTOL 即将首飞</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:left"&gt;在今年的世界人工智能大会 WAIC 上，因发布多模态多物理量智能感知、拟人动态视觉与力控、人形机器人脑机交互、压电式六维力传感器、基于能量的 AI 世界模型等新一代人形机器人核心技术，德国红点与美国缪斯双奖得主人形机器人美猴王而大放异彩的深谋科技，在商业化方面也一骑绝尘，宣布其融合多模态感知检测的人形机器人中标国网河北电力能源技术公司《电力设备智能带电检测机器人系统》项目。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;与当前业内不少与资本炒作有关，甚至有时候连具体用户场景都遮遮掩掩不敢说的所谓「大单」不同，深谋凭借新一代人形机器人硬核技术对垂直行业实际场景刚性需求的满足，首开人形机器人赋能电力行业智能带电检测场景之先河。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;深谋深耕的拟人视觉与力位混合控制技术、多模态传感与跨模态数据 AI 大模型融合技术、压电式六维力传感器、轻量化灵巧手，将应用于该项目的关键技术研究和装置研制。高自由度的智能人形机器人+多模态检测感知+AI 大模型+先进控制等核心技术与电力等对场景应用有极高要求的垂直行业相结合，真正为行业创造实际价值，摆脱人形机器人「跑跑跳跳、图个热闹」的怪圈，具有标志性的示范意义，相关成果也将对人形机器人与其它行业的结合提供重要借鉴。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;人形机器人有改变整个人类生活和工作方式的广阔前景，但是当下关键还在于破解真正满足行业刚需，实现商业化落地的老大难问题，靠资本炒出来的虚火泡沫，不管多大，多热闹，如果不回归技术和商业本质，终究会破灭。这次深谋中标国网电力，正是其迈向真正为人类创造价值的新人形机器人领跑者坚实的一步，喧嚣过后，会发现深谋这样潜心钻研能够场景落地人形机器人的企业才是具身智能领域笑到最后的真正王者。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;除人形机器人中标国网电力，深谋的另一个战略赛道深谋飞行器研发的最大载重达 200kg 的 eVTOL 曜眸 MX150E 无人机即将首飞并量产。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;曜眸 MX150E 采用极致轻量化纯电设计，标准载重 150kg，仅需 5×5 米场地即可起降，具备 3 分钟快速响应能力，其超低运营成本（1.2 元/吨公里）及单机成本较传统方案降低 60% 的优势，特别满足「一带一路」沿线国家打通物流运输、农林植保、应急救援、消防救灾「最后一公里」的需求，目前业界暂无竞品，已有相当海外意向订单，有望成为低空经济出海及商业化落地的销量冠军。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;如果把人形机器人比做满汉全席，eVTOL 比做法国大餐的话，普通人会认为做其中一个已属难能，双星闪耀怎么可能？ 其实这样的不被理解，早年的苹果、SpaceX 也曾有过，马斯克认为：「只要不违反物理定律，一切皆有可能」。深谋就偏偏要左手做「满汉全席」人形机器人，右手做「法国大餐」eVTOL，且偏偏两个赛道都取得突破性进展，结出丰硕的成果，开始领跑行业，这背后恰恰反映了深谋科技对具身智能这一跨学科领域的技术本质有着深刻的理解和把握，而同质化严重的行业现状，也正需要深谋这样与众不同的公司异军突起，改写具身智能的创新范式。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372898</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372898</guid>
      <pubDate>Sun, 14 Sep 2025 02:17:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
    <item>
      <title>DeepSeek 论文登上 Nature 封面，AI 大模型首次通过同行评审</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;span&gt;DeepSeek 团队凭借其关于&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;DeepSeek R1&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;的研究论文，成功登上了&lt;span&gt;顶级&lt;/span&gt;学术期刊《Nature》的封面，成为首个通过&lt;span&gt;权威&lt;/span&gt;同行评审的大语言模型。&lt;/span&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="188" src="https://oscimg.oschina.net/oscnet/up-0871738f7af920ae353da0834284847d489.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;《Nature》编辑部指出，在 AI 技术飞速发展、炒作泛滥的当下，DeepSeek 的做法为行业提供了一种有效的应对策略。通过严格的独立同行评审，AI 研究的透明度和可重复性得以提升，从而降低了未经证实的技术声明可能带来的社会风险。编辑们呼吁更多 AI 公司能够效仿 DeepSeek，以促进 AI 领域的健康发展。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;这篇论文详细介绍了 DeepSeek R1 创新的推理能力训练方法。与传统依赖人工标注进行微调不同，该模型完全不使用人工示例，而是通过强化学习（RL）在自主环境中自我演化，从而发展出复杂的推理能力。这种方法取得了显著成效，例如在 AIME2024 数学竞赛中，DeepSeek-R1 的表现从 15.6% 跃升至 71.0%，达到了与 OpenAI 模型相当的水平。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;img height="225" src="https://oscimg.oschina.net/oscnet/up-4bb3540fe8babfd00e6a6bc231adde433d2.png" width="500" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;&lt;em&gt;群体相对策略优化算法的示意图（来源：DeepSeek）&lt;/em&gt;&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;在长达数月的同行评审过程中，八位专家对该研究提出了宝贵建议，促使 DeepSeek 团队对技术细节进行了多次修改和完善。尽管研究成果显著，团队也坦承模型在可读性和语言混用等方面仍面临挑战。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;为解决这些问题，DeepSeek 采用了结合拒绝采样和监督微调的多阶段训练框架，进一步提升了模型的写作能力和整体表现。&lt;/p&gt; 
&lt;p style="color:#242424; margin-left:0; margin-right:0; text-align:left"&gt;DeepSeek R1 的成功发表标志着 AI 基础模型研究正在向更科学、更严谨和更可复现的方向迈进。这一突破为未来的 AI 研究提供了一个新范例，并有望推动整个行业走向更加透明和开放的发展道路。&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372895</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372895</guid>
      <pubDate>Sun, 14 Sep 2025 02:08:00 GMT</pubDate>
      <author>来源: OSCHINA</author>
    </item>
    <item>
      <title>2025 网安周丨「AI+安全」守护数智未来，绿盟科技精彩亮相昆明</title>
      <description>&lt;div class="content"&gt;
                                                                    
                                                        &lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="177" src="https://oscimg.oschina.net/oscnet//ba44f2045b85121e6fbc07209120fa66.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;9 月 15 日至 21 日，由中央宣传部、中央网信办等十个部门联合举办的 2025 年国家网络安全宣传周在全国范围内统一开展。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;9 月 17 日，绿盟科技积极参与 2025 年国家网络安全宣传周电信日——云南省信息通信网络安全实网演练暨技能竞赛总结大会、人工智能安全治理分论坛、云计算服务安全闭门会等活动，通过主题演讲、成果发布、展台展示等形式，传递 AI 安全理念，展现创新实践成果。&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;2025 年国家网络安全宣传周电信日——云南省信息通信网络安全实网演练暨技能竞赛总结大会&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;上午，在 2025 年国家网络安全宣传周电信日——云南省信息通信网络安全实网演练暨技能竞赛总结大会上，绿盟科技集团作为唯一受邀发言的安全厂商出席会议。会上，绿盟科技荣获「2025 年度优秀技术支撑单位」称号。集团运营商事业部总经理汤旭、云南代表处首席代表姜艳杰受邀参会，安全专家雷勇涛荣获「优秀支撑个人」称号。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//6b35d18e1c269246b9200cfef5e2231d.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//cb4def600e41c8245322355bb5d0ede7.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;绿盟科技集团运营商事业部总经理汤旭发表《AI 智御攻防实战：智能化安全防御体系构建与实践》主题演讲。他指出，大模型驱动的 AI 安全进入体系化发展阶段，从 L0 层通用基础大模型，历经 L1 层垂直行业预训练大模型，发展到 L2 层场景化微调模型，已逐步聚焦安全检测、安全运营、数据安全、蓝军对抗四大核心方向。面对这一趋势，绿盟科技构建以 「风云衞」 AI 安全能力平台为核心的 「AI + 攻防调度、AI + 任务规划、AI + 路径选择」 三层架构，赋能攻防对抗，打造自动化、体系化、智能化安全能力体系，目前已在百余家客户落地并经过多场实网演练检验。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="401" src="https://oscimg.oschina.net/oscnet//e3a7f97a2132ed61bd942f9860740a1c.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;大会现场，绿盟科技展台聚焦 AI 安全、数据安全、软件供应链安全等领域，集中展示解决方案与实践案例，全面展现公司在信息通信网络安全保障中的技术优势与价值。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="521" src="https://oscimg.oschina.net/oscnet//d8226fab914da8f9efbcbad89c06d6e0.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;人工智能安全治理分论坛&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;在人工智能安全治理分论坛上，绿盟科技参与了《人工智能安全行业自律倡议》的发布。该倡议围绕数据与算法安全、内容生态建设、技术创新与质量、价值观与伦理、交流合作等方面提出自律要求，旨在通过行业协同推动人工智能安全、可靠、可控发展。绿盟科技的参与，体现了企业在人工智能安全治理中的积极态度与责任担当，并与业界一道共同助力构建健康有序的人工智能产业生态。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="401" src="https://oscimg.oschina.net/oscnet//085f60faef825d70c7b9755978e46d85.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:start"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;云计算服务安全闭门会&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;&lt;strong&gt;&lt;span style="color:#004730"&gt;主题演讲：云上大模型驱动的威胁智能治理与对抗攻防&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p style="color:#000000; margin-left:0; margin-right:0; text-align:left"&gt;同日，绿盟科技集团首席创新官刘文懋博士在云计算服务安全闭门会上发表《云上大模型驱动的威胁智能治理与对抗攻防》主题演讲。刘文懋博士提到，云计算步入 「Cloud 3.0」 时代，大模型与云原生技术深度融合在加速 AI 应用落地时，带来新安全挑战。相较于传统云安全，云上大模型风险呈现多维性，包含模型越狱、提示词注入等问题。为此，他提出 「机密计算 +&amp;nbsp;全闭环可信 MLOps」 防御框架，机密计算利用 TEE 保障数据计算机密性与完整性，结合 Confidential Container 等实现防护；全闭环可信 MLOps 覆盖模型全链路安全控制。同时，在生态层面强调 AI 安全责任共担机制，多方协同治理构建新一代智能防护体系。&lt;/p&gt; 
&lt;p style="color:#000000; text-align:left"&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p style="color:#000000; text-align:center"&gt;&lt;img alt="" height="400" src="https://oscimg.oschina.net/oscnet//96c716a32ba52790b6a3cfd0e0d1b8e7.jpg" width="600" referrerpolicy="no-referrer"&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
                                                                                &lt;/div&gt;
                                                                            </description>
      <link>https://www.oschina.net/news/372888</link>
      <guid isPermaLink="false">https://www.oschina.net/news/372888</guid>
      <pubDate>Sun, 14 Sep 2025 01:21:00 GMT</pubDate>
      <author>作者: 开源科技</author>
    </item>
  </channel>
</rss>
